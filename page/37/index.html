
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/37/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.AI_2023_09_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/13/cs.AI_2023_09_13/" class="article-date">
  <time datetime="2023-09-13T12:00:00.000Z" itemprop="datePublished">2023-09-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/13/cs.AI_2023_09_13/">cs.AI - 2023-09-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-quantum-recurrent-reinforcement-learning-via-quantum-reservoir-computing"><a href="#Efficient-quantum-recurrent-reinforcement-learning-via-quantum-reservoir-computing" class="headerlink" title="Efficient quantum recurrent reinforcement learning via quantum reservoir computing"></a>Efficient quantum recurrent reinforcement learning via quantum reservoir computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07339">http://arxiv.org/abs/2309.07339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Yen-Chi Chen</li>
<li>for: This paper aims to address the challenge of inefficient training in quantum reinforcement learning (QRL) models incorporating quantum recurrent neural networks (QRNNs).</li>
<li>methods: The proposed approach utilizes QLSTM-based reservoirs, with randomly initialized and fixed parameters, and trains the model using the asynchronous advantage actor-critic (A3C) algorithm.</li>
<li>results: Numerical simulations demonstrate the efficacy of the proposed QLSTM-Reservoir RL framework, achieving comparable results to a fully trained QLSTM RL model with the same architecture and training settings.<details>
<summary>Abstract</summary>
Quantum reinforcement learning (QRL) has emerged as a framework to solve sequential decision-making tasks, showcasing empirical quantum advantages. A notable development is through quantum recurrent neural networks (QRNNs) for memory-intensive tasks such as partially observable environments. However, QRL models incorporating QRNN encounter challenges such as inefficient training of QRL with QRNN, given that the computation of gradients in QRNN is both computationally expensive and time-consuming. This work presents a novel approach to address this challenge by constructing QRL agents utilizing QRNN-based reservoirs, specifically employing quantum long short-term memory (QLSTM). QLSTM parameters are randomly initialized and fixed without training. The model is trained using the asynchronous advantage actor-aritic (A3C) algorithm. Through numerical simulations, we validate the efficacy of our QLSTM-Reservoir RL framework. Its performance is assessed on standard benchmarks, demonstrating comparable results to a fully trained QLSTM RL model with identical architecture and training settings.
</details>
<details>
<summary>摘要</summary>
This work presents a novel approach to address this challenge by constructing QRL agents utilizing QRNN-based reservoirs， specifically employing quantum long short-term memory (QLSTM)。 QLSTM parameters are randomly initialized and fixed without training。 The model is trained using the asynchronous advantage actor-aritic (A3C) algorithm。Through numerical simulations, we validate the efficacy of our QLSTM-Reservoir RL framework。 Its performance is assessed on standard benchmarks， demonstrating comparable results to a fully trained QLSTM RL model with identical architecture and training settings。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-Auxiliary-Sources-in-Argumentative-Revision-Classification"><a href="#Learning-from-Auxiliary-Sources-in-Argumentative-Revision-Classification" class="headerlink" title="Learning from Auxiliary Sources in Argumentative Revision Classification"></a>Learning from Auxiliary Sources in Argumentative Revision Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07334">http://arxiv.org/abs/2309.07334</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tazin Afrin, Diane Litman</li>
<li>for: 这个论文是为了开发用于分类辩论性修订的模型。</li>
<li>methods: 论文使用了两种方法：多任务学习和传输学习，以利用相似任务的辅助数据来提高分类器性能。</li>
<li>results: 论文的内在和外在评估结果显示，multi-task learning和传输学习都可以提高分类器性能，其中传输学习更好地表达数据之间的关系。<details>
<summary>Abstract</summary>
We develop models to classify desirable reasoning revisions in argumentative writing. We explore two approaches -- multi-task learning and transfer learning -- to take advantage of auxiliary sources of revision data for similar tasks. Results of intrinsic and extrinsic evaluations show that both approaches can indeed improve classifier performance over baselines. While multi-task learning shows that training on different sources of data at the same time may improve performance, transfer-learning better represents the relationship between the data.
</details>
<details>
<summary>摘要</summary>
我们开发了一些模型，用于分类 Argumentative 写作中的可covetous 修订。我们explore两种方法：多任务学习和转移学习，以利用 auxiliary 数据来提高分类器性能。结果显示，两种方法都可以提高分类器的性能，比baseline更好。而多任务学习表明，在同时使用不同的数据源进行训练可以提高性能，而转移学习更好地表达数据之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Reliability-based-cleaning-of-noisy-training-labels-with-inductive-conformal-prediction-in-multi-modal-biomedical-data-mining"><a href="#Reliability-based-cleaning-of-noisy-training-labels-with-inductive-conformal-prediction-in-multi-modal-biomedical-data-mining" class="headerlink" title="Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining"></a>Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07332">http://arxiv.org/abs/2309.07332</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xzhan96-stf/icp_train_clean">https://github.com/xzhan96-stf/icp_train_clean</a></li>
<li>paper_authors: Xianghao Zhan, Qinmei Xu, Yuanning Zheng, Guangming Lu, Olivier Gevaert</li>
<li>for: 提高生物医学数据标注的精度，解决传统半supervised学习方法在使用大量标注数据时仍然表现不佳的问题。</li>
<li>methods: 提出了一种基于概率预测的数据清洁方法，利用 inductive conformal prediction (ICP) 计算出的可靠度指标， Rectify 标注数据和噪声数据，提高数据标注的精度。</li>
<li>results: 在三种不同的模式下进行了三种类型的分类任务，包括使用标题和摘要滤除 DILI 文献、通过 CT 成像和电子医疗记录预测 COVID-19 患者 ICU  admit、以及使用 RNA 序列数据分型乳腺癌。结果表明，该方法可以显著提高分类性能，包括增加精度、AUROC 和 AUPRC。<details>
<summary>Abstract</summary>
Accurately labeling biomedical data presents a challenge. Traditional semi-supervised learning methods often under-utilize available unlabeled data. To address this, we propose a novel reliability-based training data cleaning method employing inductive conformal prediction (ICP). This method capitalizes on a small set of accurately labeled training data and leverages ICP-calculated reliability metrics to rectify mislabeled data and outliers within vast quantities of noisy training data. The efficacy of the method is validated across three classification tasks within distinct modalities: filtering drug-induced-liver-injury (DILI) literature with title and abstract, predicting ICU admission of COVID-19 patients through CT radiomics and electronic health records, and subtyping breast cancer using RNA-sequencing data. Varying levels of noise to the training labels were introduced through label permutation. Results show significant enhancements in classification performance: accuracy enhancement in 86 out of 96 DILI experiments (up to 11.4%), AUROC and AUPRC enhancements in all 48 COVID-19 experiments (up to 23.8% and 69.8%), and accuracy and macro-average F1 score improvements in 47 out of 48 RNA-sequencing experiments (up to 74.6% and 89.0%). Our method offers the potential to substantially boost classification performance in multi-modal biomedical machine learning tasks. Importantly, it accomplishes this without necessitating an excessive volume of meticulously curated training data.
</details>
<details>
<summary>摘要</summary>
准确标注生物医学数据存在挑战。传统的半监督学习方法经常不充分利用可用的无标签数据。为解决这个问题，我们提议一种基于可靠性的训练数据清洁方法，利用抽象匹配预测（ICP）计算的可靠性指标来正确化涂抹数据和异常值在大量的噪音训练数据中。我们在三种不同的Modalities上进行了三种类型的分类任务：在标题和摘要中筛选药物引起的liver损伤文献（DILI）、通过CT成像记录和电子医疗记录预测COVID-19患者ICU入院，以及使用RNA测序数据进行乳腺癌类型分类。我们对训练标签进行了各种噪音添加，并评估了方法的效果。结果显示，我们的方法可以帮助提高分类性能：DILI中的86个实验中（最高11.4%）、COVID-19中的所有48个实验（最高23.8%和69.8%）和RNA测序中的47个实验中（最高74.6%和89.0%）。我们的方法可以在多模态生物医学机器学习任务中帮助提高分类性能，而不需要大量的精心筛选训练数据。
</details></li>
</ul>
<hr>
<h2 id="Racing-Control-Variable-Genetic-Programming-for-Symbolic-Regression"><a href="#Racing-Control-Variable-Genetic-Programming-for-Symbolic-Regression" class="headerlink" title="Racing Control Variable Genetic Programming for Symbolic Regression"></a>Racing Control Variable Genetic Programming for Symbolic Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07934">http://arxiv.org/abs/2309.07934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nan Jiang, Yexiang Xue</li>
<li>for: 这 paper 旨在提高 symbolic regression 的效率和准确性，使其能够更快地从实验数据中找到 governing equations。</li>
<li>methods: 这 paper 使用了 Control Variable Genetic Programming (CVGP) 和 Racing Control Variable Genetic Programming (Racing-CVGP) 两种方法， CVGP 通过设计控制变量实验来加速 regression 过程，而 Racing-CVGP 则同时执行多个 experiment schedule，选择最佳 experiment schedule 以提高效率。</li>
<li>results: 该 paper 在多个 synthetic 和实际世界数据集上进行了测试，并证明 Racing-CVGP 可以比 CVGP 和一系列基于固定数据集的 symbolic regressors 更高效和准确地找到 governing equations。<details>
<summary>Abstract</summary>
Symbolic regression, as one of the most crucial tasks in AI for science, discovers governing equations from experimental data. Popular approaches based on genetic programming, Monte Carlo tree search, or deep reinforcement learning learn symbolic regression from a fixed dataset. They require massive datasets and long training time especially when learning complex equations involving many variables. Recently, Control Variable Genetic Programming (CVGP) has been introduced which accelerates the regression process by discovering equations from designed control variable experiments. However, the set of experiments is fixed a-priori in CVGP and we observe that sub-optimal selection of experiment schedules delay the discovery process significantly. To overcome this limitation, we propose Racing Control Variable Genetic Programming (Racing-CVGP), which carries out multiple experiment schedules simultaneously. A selection scheme similar to that used in selecting good symbolic equations in the genetic programming process is implemented to ensure that promising experiment schedules eventually win over the average ones. The unfavorable schedules are terminated early to save time for the promising ones. We evaluate Racing-CVGP on several synthetic and real-world datasets corresponding to true physics laws. We demonstrate that Racing-CVGP outperforms CVGP and a series of symbolic regressors which discover equations from fixed datasets.
</details>
<details>
<summary>摘要</summary>
Symbolic regression, as one of the most crucial tasks in AI for science, 发现 governing equations from experimental data. 受欢迎的方法包括生物学编程、Monte Carlo tree search 或深度奖励学习，它们从固定的数据集中学习 symbolic regression, 但它们需要庞大的数据集和长时间训练，特别是当学习复杂的方程式时。 最近，Control Variable Genetic Programming (CVGP) 被引入，它可以从设计的控制变量实验中发现方程式。 然而，CVGP 中的实验安排是固定的，我们发现在实验中选择的方案会延迟发现过程的进度。 为了解决这个限制，我们提出了 Racing Control Variable Genetic Programming (Racing-CVGP)，它同时执行多个实验安排。 我们实施了一种类似于在生物学编程过程中选择好的符号方程式的选择方式，以确保Promising experiment schedules 最终胜过平均的那些。 不利的安排将在早些时候被终止，以便把时间花在Promising ones 上。 我们对 Racing-CVGP 进行了多个 synthetic 和真实世界数据集的评估，并证明它在 CVGP 和一系列基于固定数据集的符号回归器之上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Traveling-Words-A-Geometric-Interpretation-of-Transformers"><a href="#Traveling-Words-A-Geometric-Interpretation-of-Transformers" class="headerlink" title="Traveling Words: A Geometric Interpretation of Transformers"></a>Traveling Words: A Geometric Interpretation of Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07315">http://arxiv.org/abs/2309.07315</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/santiag0m/traveling-words">https://github.com/santiag0m/traveling-words</a></li>
<li>paper_authors: Raul Molina</li>
<li>for: 本研究旨在解释转换器内部机制的几何视角，以便更好地理解转换器如何处理自然语言处理任务。</li>
<li>methods: 本文使用层Normalization和注意力机制来描述转换器的内部机制。层Normalization使得含义特征被归一化到一个超球上，从而使得注意力可以模糊语言表示的含义。</li>
<li>results: 通过对预训练的GPT-2模型进行探测，发现了层Normalization和注意力机制的相互关系，并发现了早期层的查询-关键注意力模式。这些结果证明了几何视角的有用性，并提供了一种直观的理解转换器的方式，即将单词粒子视为在超球上的旋转。<details>
<summary>Abstract</summary>
Transformers have significantly advanced the field of natural language processing, but comprehending their internal mechanisms remains a challenge. In this paper, we introduce a novel geometric perspective that elucidates the inner mechanisms of transformer operations. Our primary contribution is illustrating how layer normalization confines the latent features to a hyper-sphere, subsequently enabling attention to mold the semantic representation of words on this surface. This geometric viewpoint seamlessly connects established properties such as iterative refinement and contextual embeddings. We validate our insights by probing a pre-trained 124M parameter GPT-2 model. Our findings reveal clear query-key attention patterns in early layers and build upon prior observations regarding the subject-specific nature of attention heads at deeper layers. Harnessing these geometric insights, we present an intuitive understanding of transformers, depicting them as processes that model the trajectory of word particles along the hyper-sphere.
</details>
<details>
<summary>摘要</summary>
transformers 已经在自然语言处理领域取得了 significativ advancement, 但理解其内部机制仍然是一个挑战。在这篇论文中，我们提出了一种新的几何视角，可以帮助我们更好地理解 transformer 的内部机制。我们的主要贡献在于解释如何层 normalization 使得封闭 latent features 在 hyper-sphere 上，然后使得 attention 可以模糊这个表面上的 semantic representation 的形态。这种几何视角通过连接了已知的属性，如迭代精度和 contextual embeddings。我们验证了我们的发现，通过探测一个预训练的 124M 参数 GPT-2 模型。我们的发现显示了早期层的查询-密钥 attention 模式，并建立在更深层的 attention 头上的主题特有性。利用这种几何视角，我们提供了一种直观的理解 transformers，描述它们为模elling 单词粒子的轨迹在 hyper-sphere 上。
</details></li>
</ul>
<hr>
<h2 id="AudioSR-Versatile-Audio-Super-resolution-at-Scale"><a href="#AudioSR-Versatile-Audio-Super-resolution-at-Scale" class="headerlink" title="AudioSR: Versatile Audio Super-resolution at Scale"></a>AudioSR: Versatile Audio Super-resolution at Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07314">http://arxiv.org/abs/2309.07314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haohe Liu, Ke Chen, Qiao Tian, Wenwu Wang, Mark D. Plumbley</li>
<li>for: 提高低分辨率音频质量</li>
<li>methods: 使用扩散模型进行数据生成</li>
<li>results: 能够在各种音频类型和频谱范围内提高音频质量，包括音效、音乐和说话<details>
<summary>Abstract</summary>
Audio super-resolution is a fundamental task that predicts high-frequency components for low-resolution audio, enhancing audio quality in digital applications. Previous methods have limitations such as the limited scope of audio types (e.g., music, speech) and specific bandwidth settings they can handle (e.g., 4kHz to 8kHz). In this paper, we introduce a diffusion-based generative model, AudioSR, that is capable of performing robust audio super-resolution on versatile audio types, including sound effects, music, and speech. Specifically, AudioSR can upsample any input audio signal within the bandwidth range of 2kHz to 16kHz to a high-resolution audio signal at 24kHz bandwidth with a sampling rate of 48kHz. Extensive objective evaluation on various audio super-resolution benchmarks demonstrates the strong result achieved by the proposed model. In addition, our subjective evaluation shows that AudioSR can acts as a plug-and-play module to enhance the generation quality of a wide range of audio generative models, including AudioLDM, Fastspeech2, and MusicGen. Our code and demo are available at https://audioldm.github.io/audiosr.
</details>
<details>
<summary>摘要</summary>
音频超分辨是一个基础任务，它预测低分辨率音频中缺失的高频成分，以提高数字应用中的音频质量。现有的方法具有限制，例如只能处理特定类型的音频（如音乐、语音）以及特定的宽频范围（如4kHz到8kHz）。在这篇论文中，我们介绍了一种扩散基于的生成模型，即AudioSR，可以在多种音频类型上进行稳定的音频超分辨。具体来说，AudioSR可以将输入音频信号在2kHz到16kHz的宽频范围内 upsample 到高分辨率音频信号，具有48kHz的抽样率和24kHz的宽频范围。对于多种音频超分辨测试 benchmark 进行了广泛的对象评估，结果显示提案的模型具有强大的效果。此外，我们的主观评估表明，AudioSR可以作为一个插件模块，提高多种音频生成模型的生成质量，包括AudioLDM、Fastspeech2和MusicGen。我们的代码和示例可以在 <https://audioldm.github.io/audiosr> 上下载。
</details></li>
</ul>
<hr>
<h2 id="Pretraining-on-the-Test-Set-Is-All-You-Need"><a href="#Pretraining-on-the-Test-Set-Is-All-You-Need" class="headerlink" title="Pretraining on the Test Set Is All You Need"></a>Pretraining on the Test Set Is All You Need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08632">http://arxiv.org/abs/2309.08632</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/molyswu/hand_detection">https://github.com/molyswu/hand_detection</a></li>
<li>paper_authors: Rylan Schaeffer</li>
<li>for: 这 paper 是为了检验和评估基于 transformer 语言模型的小型语言模型。</li>
<li>methods: 这 paper 使用了一种新的数据集 mixture，包含 less than 100 thousand tokens，并使用 transformer 语言模型进行预训练。</li>
<li>results: 这 paper 的模型可以在多种学术 bencmarks 上达到完美的结果，超越所有已知基础模型，并且能够准确预测下游评估 bencmarks 的 canaries。<details>
<summary>Abstract</summary>
Inspired by recent work demonstrating the promise of smaller Transformer-based language models pretrained on carefully curated data, we supercharge such approaches by investing heavily in curating a novel, high quality, non-synthetic data mixture based solely on evaluation benchmarks. Using our novel dataset mixture consisting of less than 100 thousand tokens, we pretrain a 1 million parameter transformer-based LLM \textbf{phi-CTNL} (pronounced ``fictional") that achieves perfect results across diverse academic benchmarks, strictly outperforming all known foundation models. \textbf{phi-CTNL} also beats power-law scaling and exhibits a never-before-seen grokking-like ability to accurately predict downstream evaluation benchmarks' canaries.
</details>
<details>
<summary>摘要</summary>
受最近一些研究所示出小型Transformer模型预训练在精心准备的数据上的承诺，我们决心投入大量资源来精心制作一种新的高质量非 sintetic 数据混合物。使用我们的新数据混合物，包含 fewer than 100 thousand tokens，我们预训练了1 million参数的Transformer模型\textbf{phi-CTNL}（发音为“虚构的”），在多种学术评价指标上达到了完美的结果，一直超越所有已知基础模型。\textbf{phi-CTNL} 还击倒了力学律稳定的增长和显示出 nunca-before-seen 的感知能力，准确预测下游评价指标的鸡。
</details></li>
</ul>
<hr>
<h2 id="Language-Conditioned-Observation-Models-for-Visual-Object-Search"><a href="#Language-Conditioned-Observation-Models-for-Visual-Object-Search" class="headerlink" title="Language-Conditioned Observation Models for Visual Object Search"></a>Language-Conditioned Observation Models for Visual Object Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07276">http://arxiv.org/abs/2309.07276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thao Nguyen, Vladislav Hrosinkov, Eric Rosen, Stefanie Tellex</li>
<li>for: 本研究旨在实现实际的物品搜寻任务，使 robot 能够通过语言描述找到环境中的物品。</li>
<li>methods: 本研究使用 Markov decision process (POMDP) 来解决物品搜寻问题，并通过一个深度神经网络来决定物品探测器和视觉传感器的错误模型。</li>
<li>results: 研究比较了这个新方法和现有的物品搜寻算法，结果显示，使用这个方法可以实现更高的任务完成率（由 0.46 提升至 0.66）和更快和有效的物品搜寻。此外，研究还在 Boston Dynamics Spot 机器人上进行了实际应用，证明了这个方法的可行性和效果。<details>
<summary>Abstract</summary>
Object search is a challenging task because when given complex language descriptions (e.g., "find the white cup on the table"), the robot must move its camera through the environment and recognize the described object. Previous works map language descriptions to a set of fixed object detectors with predetermined noise models, but these approaches are challenging to scale because new detectors need to be made for each object. In this work, we bridge the gap in realistic object search by posing the search problem as a partially observable Markov decision process (POMDP) where the object detector and visual sensor noise in the observation model is determined by a single Deep Neural Network conditioned on complex language descriptions. We incorporate the neural network's outputs into our language-conditioned observation model (LCOM) to represent dynamically changing sensor noise. With an LCOM, any language description of an object can be used to generate an appropriate object detector and noise model, and training an LCOM only requires readily available supervised image-caption datasets. We empirically evaluate our method by comparing against a state-of-the-art object search algorithm in simulation, and demonstrate that planning with our observation model yields a significantly higher average task completion rate (from 0.46 to 0.66) and more efficient and quicker object search than with a fixed-noise model. We demonstrate our method on a Boston Dynamics Spot robot, enabling it to handle complex natural language object descriptions and efficiently find objects in a room-scale environment.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>对象搜索是一项复杂的任务，因为当给出复杂的自然语言描述（例如，"找到桌子上的白瓶")时，机器人需要通过环境移动相机并识别描述的对象。先前的方法将语言描述映射到一组预先定义的对象检测器中，但这些方法具有扩展性问题，因为需要为每个对象创建新的检测器。在这种工作中，我们将搜索问题视为一个部分可观察的Markov决策过程（POMDP），其中对象检测器和视觉传感器的噪音在观察模型中由单个深度神经网络决定，该神经网络是根据复杂的自然语言描述 Conditioned。我们将神经网络的输出 integrate into我们的语言受控观察模型（LCOM），以表示动态变化的感知噪音。与一个LCOM相比，任何自然语言描述都可以生成适当的对象检测器和噪音模型，并且训练LCOM只需要可以获得的ready-to-use的Supervised image-caption dataset。我们实际运行我们的方法，与一个状态革新的对象搜索算法进行比较，并证明在 simulation中，使用我们的观察模型可以实现更高的均值任务完成率（从0.46到0.66）和更有效和更快的对象搜索。我们在Boston Dynamics Spot机器人上运行我们的方法，使其能够处理复杂的自然语言对象描述，并快速寻找房间级别环境中的对象。
</details></li>
</ul>
<hr>
<h2 id="Safe-and-Accelerated-Deep-Reinforcement-Learning-based-O-RAN-Slicing-A-Hybrid-Transfer-Learning-Approach"><a href="#Safe-and-Accelerated-Deep-Reinforcement-Learning-based-O-RAN-Slicing-A-Hybrid-Transfer-Learning-Approach" class="headerlink" title="Safe and Accelerated Deep Reinforcement Learning-based O-RAN Slicing: A Hybrid Transfer Learning Approach"></a>Safe and Accelerated Deep Reinforcement Learning-based O-RAN Slicing: A Hybrid Transfer Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07265">http://arxiv.org/abs/2309.07265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahmadnagib/tl-aided-drl">https://github.com/ahmadnagib/tl-aided-drl</a></li>
<li>paper_authors: Ahmad M. Nagib, Hatem Abou-Zeid, Hossam S. Hassanein<br>for: 这篇论文旨在提出一种基于启发学习（DRL）的闭环控制方法，以优化Radio Access Network（RAN）功能。methods: 该论文使用了转移学习（TL）作为训练和部署工作流程的核心组成部分，并提出了一种hybrid TL-aided方法， combinign policy reuse和distillation TL方法，以提供安全和加速的收敛。results: 实验结果表明，提议的hybrid方法在面对实际的VR游戏压力流量的情况下，能够提供至少7.7%和20.7%的初始奖励值和结束收敛情况的提升，同时保持快速收敛和提高普适性。<details>
<summary>Abstract</summary>
The open radio access network (O-RAN) architecture supports intelligent network control algorithms as one of its core capabilities. Data-driven applications incorporate such algorithms to optimize radio access network (RAN) functions via RAN intelligent controllers (RICs). Deep reinforcement learning (DRL) algorithms are among the main approaches adopted in the O-RAN literature to solve dynamic radio resource management problems. However, despite the benefits introduced by the O-RAN RICs, the practical adoption of DRL algorithms in real network deployments falls behind. This is primarily due to the slow convergence and unstable performance exhibited by DRL agents upon deployment and when encountering previously unseen network conditions. In this paper, we address these challenges by proposing transfer learning (TL) as a core component of the training and deployment workflows for the DRL-based closed-loop control of O-RAN functionalities. To this end, we propose and design a hybrid TL-aided approach that leverages the advantages of both policy reuse and distillation TL methods to provide safe and accelerated convergence in DRL-based O-RAN slicing. We conduct a thorough experiment that accommodates multiple services, including real VR gaming traffic to reflect practical scenarios of O-RAN slicing. We also propose and implement policy reuse and distillation-aided DRL and non-TL-aided DRL as three separate baselines. The proposed hybrid approach shows at least: 7.7% and 20.7% improvements in the average initial reward value and the percentage of converged scenarios, and a 64.6% decrease in reward variance while maintaining fast convergence and enhancing the generalizability compared with the baselines.
</details>
<details>
<summary>摘要</summary>
Open Radio Access Network (O-RAN) 架构支持智能网络控制算法作为其核心功能之一。数据驱动应用程序将此类算法用于Radio Access Network (RAN) 函数的优化，通过RAN 智能控制器 (RICs)。深度强化学习 (DRL) 算法是 O-RAN 文献中广泛采用的方法来解决动态Radio资源管理问题。然而，尽管 O-RAN RICs 带来了优点，但实际部署中对 DRL 算法的应用仍迟后。这主要是因为 DRL 代理人在部署和遇到新的网络条件时的慢速融合和不稳定性。在这篇论文中，我们解决这些挑战，通过在训练和部署过程中引入传输学习 (TL) 作为核心组件。为此，我们提出了一种混合 TL-aided 方法，利用传输学习的优势，提供安全和加速融合，并在 O-RAN 排程中提供更好的一致性。我们进行了 Thorough 实验，包括多种服务，如真实的 VR 游戏流量，以反映实际 O-RAN 排程的实际场景。我们还提出了非 TL-aided DRL 和 policy reuse 和 distillation 两种基eline。我们的提案的混合方法在 DRL 基eline 中显示出至少7.7%和20.7%的平均初始奖励值和百分比可以融合，并在奖励变幅方面减少64.6%，同时保持快速融合和提高一致性。
</details></li>
</ul>
<hr>
<h2 id="Autotuning-Apache-TVM-based-Scientific-Applications-Using-Bayesian-Optimization"><a href="#Autotuning-Apache-TVM-based-Scientific-Applications-Using-Bayesian-Optimization" class="headerlink" title="Autotuning Apache TVM-based Scientific Applications Using Bayesian Optimization"></a>Autotuning Apache TVM-based Scientific Applications Using Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07235">http://arxiv.org/abs/2309.07235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingfu Wu, Praveen Paramasivam, Valerie Taylor</li>
<li>for: 优化稠密矩阵分解（LU、Cholesky、3mm）的性能在GPU和AI加速器上。</li>
<li>methods: 使用 Bayesian 优化和 TVM tensor expression language 实现自动调整。</li>
<li>results: 对 Argonne National Laboratory 的 GPU 集群（Swing）进行科学计算kernel的评估，并与 AutoTVM  Comparing four tuners 的自动调整框架，发现自动调整框架在大多数情况下表现更好。<details>
<summary>Abstract</summary>
Apache TVM (Tensor Virtual Machine), an open source machine learning compiler framework designed to optimize computations across various hardware platforms, provides an opportunity to improve the performance of dense matrix factorizations such as LU (Lower Upper) decomposition and Cholesky decomposition on GPUs and AI (Artificial Intelligence) accelerators. In this paper, we propose a new TVM autotuning framework using Bayesian Optimization and use the TVM tensor expression language to implement linear algebra kernels such as LU, Cholesky, and 3mm. We use these scientific computation kernels to evaluate the effectiveness of our methods on a GPU cluster, called Swing, at Argonne National Laboratory. We compare the proposed autotuning framework with the TVM autotuning framework AutoTVM with four tuners and find that our framework outperforms AutoTVM in most cases.
</details>
<details>
<summary>摘要</summary>
Apache TVM（tensor虚拟机），一个开源机器学习编译框架，设计用于优化不同硬件平台上的计算，为GPU和人工智能加速器提供了提高稠密矩阵因子化（如LU和Cholesky分解）的机会。在这篇论文中，我们提出了一个基于抽象优化的新的TVM自动调整框架，使用 bayesian优化来实现。我们使用TVMtensor表达语言来实现线性代数kernels，如LU、Cholesky和3mm。我们使用这些科学计算kernels来评估我们的方法在Argonne国家实验室的GPU集群上的效果。我们比较了我们的自动调整框架与AutoTVM自动调整框架，并发现我们的框架在大多数情况下超越AutoTVM。
</details></li>
</ul>
<hr>
<h2 id="Sight-Beyond-Text-Multi-Modal-Training-Enhances-LLMs-in-Truthfulness-and-Ethics"><a href="#Sight-Beyond-Text-Multi-Modal-Training-Enhances-LLMs-in-Truthfulness-and-Ethics" class="headerlink" title="Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics"></a>Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07120">http://arxiv.org/abs/2309.07120</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ucsc-vlaa/sight-beyond-text">https://github.com/ucsc-vlaa/sight-beyond-text</a></li>
<li>paper_authors: Haoqin Tu, Bingchen Zhao, Chen Wei, Cihang Xie</li>
<li>for: 这个研究旨在探讨多Modal大型自然语言模型（MLLMs）的各种能力，包括文本回答和视觉指令。</li>
<li>methods: 研究人员使用了视觉指令调整，这是一种广泛使用的方法来转化大型自然语言模型（LLMs）为MLLMs。</li>
<li>results: 研究人员发现，使用视觉指令调整可以帮助模型更好地保持真实性和道德观念在纯文本上下文中。例如，一个视觉指令调整后的 LLaMA2 7B 模型在 TruthfulQA-mc 和 Ethics  bencmarks 上表现更好 than 一个基于一百万个人签名的 LLaMA2-chat 7B 模型。<details>
<summary>Abstract</summary>
Multi-modal large language models (MLLMs) are trained based on large language models (LLM), with an enhanced capability to comprehend multi-modal inputs and generate textual responses. While they excel in multi-modal tasks, the pure NLP abilities of MLLMs are often underestimated and left untested. In this study, we get out of the box and unveil an intriguing characteristic of MLLMs -- our preliminary results suggest that visual instruction tuning, a prevailing strategy for transitioning LLMs into MLLMs, unexpectedly and interestingly helps models attain both improved truthfulness and ethical alignment in the pure NLP context. For example, a visual-instruction-tuned LLaMA2 7B model surpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one million human annotations, on TruthfulQA-mc and Ethics benchmarks. Further analysis reveals that the improved alignment can be attributed to the superior instruction quality inherent to visual-text data. In releasing our code at github.com/UCSC-VLAA/Sight-Beyond-Text, we aspire to foster further exploration into the intrinsic value of visual-text synergies and, in a broader scope, multi-modal interactions in alignment research.
</details>
<details>
<summary>摘要</summary>
多Modal大语言模型（MLLMs）由大语言模型（LLM）进行训练，具有理解多Modal输入并生成文本响应的能力。虽然它们在多Modal任务中表现出色，但纯NLP能力的MLLMs经常被低估和未经测试。在这个研究中，我们离开“盒子”，揭示了MLLMs的一个吸引人特点——我们的初步结果表明，使用视觉指令调整，一种常见的将LLMs转换为MLLMs的策略，奇怪地和有趣地帮助模型在纯NLP上获得更高的真实性和道德适应性。例如，一个视觉指令调整后的LLaMA2 7B模型超过了人工注释超过一百万个的LLaMA2-chat 7B模型在TruthfulQA-mc和Ethicsbenchmark上的表现。进一步分析表明，改善的协调可以归因于视觉文本数据中的更高质量指令。在发布我们的代码在github.com/UCSC-VLAA/Sight-Beyond-Text上，我们希望能够激发更多人研究多Modal交互和协调在对齐研究中的内在价值。
</details></li>
</ul>
<hr>
<h2 id="Characterizing-Speed-Performance-of-Multi-Agent-Reinforcement-Learning"><a href="#Characterizing-Speed-Performance-of-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Characterizing Speed Performance of Multi-Agent Reinforcement Learning"></a>Characterizing Speed Performance of Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07108">http://arxiv.org/abs/2309.07108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Wiggins, Yuan Meng, Rajgopal Kannan, Viktor Prasanna</li>
<li>for: 本研究旨在探讨多智能体强化学习（MARL）算法在大规模AI系统和大数据应用中的性能瓶颈。</li>
<li>methods: 本研究使用了一种稍加简化的分类方法，将MARL算法分为两类：培训方案和通信方式。然后，通过对三种目标算法（MADDPG、ToM2C和NeurComm）的性能瓶颈进行系统分析，以探讨它们的性能瓶颈。</li>
<li>results: 研究发现，MARL算法的性能瓶颈主要来自于培训和通信过程中的计算和内存占用。此外，研究还发现，通过并行化和加速MARL算法可以大幅提高性能。<details>
<summary>Abstract</summary>
Multi-Agent Reinforcement Learning (MARL) has achieved significant success in large-scale AI systems and big-data applications such as smart grids, surveillance, etc. Existing advancements in MARL algorithms focus on improving the rewards obtained by introducing various mechanisms for inter-agent cooperation. However, these optimizations are usually compute- and memory-intensive, thus leading to suboptimal speed performance in end-to-end training time. In this work, we analyze the speed performance (i.e., latency-bounded throughput) as the key metric in MARL implementations. Specifically, we first introduce a taxonomy of MARL algorithms from an acceleration perspective categorized by (1) training scheme and (2) communication method. Using our taxonomy, we identify three state-of-the-art MARL algorithms - Multi-Agent Deep Deterministic Policy Gradient (MADDPG), Target-oriented Multi-agent Communication and Cooperation (ToM2C), and Networked Multi-Agent RL (NeurComm) - as target benchmark algorithms, and provide a systematic analysis of their performance bottlenecks on a homogeneous multi-core CPU platform. We justify the need for MARL latency-bounded throughput to be a key performance metric in future literature while also addressing opportunities for parallelization and acceleration.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们分析 MARL 实现中的速度性能（即延迟确定通过put）作为关键度量。 Specifically, we first introduce a taxonomy of MARL algorithms from an acceleration perspective categorized by (1) training scheme and (2) communication method. Using our taxonomy, we identify three state-of-the-art MARL algorithms - Multi-Agent Deep Deterministic Policy Gradient (MADDPG), Target-oriented Multi-agent Communication and Cooperation (ToM2C), and Networked Multi-Agent RL (NeurComm) - as target benchmark algorithms, and provide a systematic analysis of their performance bottlenecks on a homogeneous multi-core CPU platform. We justify the need for MARL latency-bounded throughput to be a key performance metric in future literature while also addressing opportunities for parallelization and acceleration.
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Group-Bias-in-Federated-Learning-for-Heterogeneous-Devices"><a href="#Mitigating-Group-Bias-in-Federated-Learning-for-Heterogeneous-Devices" class="headerlink" title="Mitigating Group Bias in Federated Learning for Heterogeneous Devices"></a>Mitigating Group Bias in Federated Learning for Heterogeneous Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07085">http://arxiv.org/abs/2309.07085</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khotso Selialia, Yasra Chandio, Fatima M. Anwar</li>
<li>for: 这篇论文的目的是为了提出一个具有隐私保证的聚合学习框架，以便在分散的边缘应用中进行模型训练，并且能够处理不同部署环境下的数据不均匀。</li>
<li>methods: 这篇论文使用了聚合学习的方法，并且提出了一个修改了多重加权更新方法，以便在不同部署环境下实现具有均衡性的模型训练。此外，论文还提出了一些调整技术来减少最差和最好的群体之间的差异，并且通过阈值机制来确保均衡具有均衡性和差异减少。</li>
<li>results: 论文的实验结果显示，这个框架可以实现具有均衡性和隐私保证的聚合学习，并且能够在实际的不同部署环境下进行均衡的模型训练。此外，论文还显示了该框架在人类情绪识别和图像分类 benchmark 上的良好表现，证明了它在实际应用中的可行性和有效性。<details>
<summary>Abstract</summary>
Federated Learning is emerging as a privacy-preserving model training approach in distributed edge applications. As such, most edge deployments are heterogeneous in nature i.e., their sensing capabilities and environments vary across deployments. This edge heterogeneity violates the independence and identical distribution (IID) property of local data across clients and produces biased global models i.e. models that contribute to unfair decision-making and discrimination against a particular community or a group. Existing bias mitigation techniques only focus on bias generated from label heterogeneity in non-IID data without accounting for domain variations due to feature heterogeneity and do not address global group-fairness property.   Our work proposes a group-fair FL framework that minimizes group-bias while preserving privacy and without resource utilization overhead. Our main idea is to leverage average conditional probabilities to compute a cross-domain group \textit{importance weights} derived from heterogeneous training data to optimize the performance of the worst-performing group using a modified multiplicative weights update method. Additionally, we propose regularization techniques to minimize the difference between the worst and best-performing groups while making sure through our thresholding mechanism to strike a balance between bias reduction and group performance degradation. Our evaluation of human emotion recognition and image classification benchmarks assesses the fair decision-making of our framework in real-world heterogeneous settings.
</details>
<details>
<summary>摘要</summary>
federated 学习是一种隐私保护的模型训练方法，在分布式边缘应用中得到普遍应用。由于大多数边缘部署是多样化的，即它们的感知能力和环境不同。这种边缘多样性违反了本地数据之间独立和同分布性（IID）属性，导致模型偏袋和不公正决策。现有的偏袋缓解技术仅考虑模型生成的标签多样性，而不考虑特征多样性引起的领域变化，也没有考虑全球群体公平性质量。我们的工作提出了一种群体公平的 Federated 学习框架，以降低群体偏袋，保护隐私和不增加资源使用负担。我们的主要想法是通过conditional probability的平均值来计算各个领域的群体重要性权，基于多样化的训练数据，使用修改后的乘数更新方法来优化最差performing group的性能。此外，我们还提出了约束技术，以降低最差和最优performing group之间的差距，同时通过阈值机制保证偏袋减少和群体性能下降之间的平衡。我们对人听情感识别和图像分类benchmark进行了评估，以评估我们的框架在实际多样化环境中的公平决策性。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Analysis-of-the-Role-of-Artificial-Intelligence-and-Machine-Learning-in-Modern-Digital-Forensics-and-Incident-Response"><a href="#A-Comprehensive-Analysis-of-the-Role-of-Artificial-Intelligence-and-Machine-Learning-in-Modern-Digital-Forensics-and-Incident-Response" class="headerlink" title="A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digital Forensics and Incident Response"></a>A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digital Forensics and Incident Response</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07064">http://arxiv.org/abs/2309.07064</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dipo Dunsin, Mohamed C. Ghanem, Karim Ouazzane, Vassil Vassilev</li>
<li>for: This paper aims to provide a comprehensive analysis of the use of Artificial Intelligence (AI) and Machine Learning (ML) in digital forensics and incident response, exploring cutting-edge research initiatives and their applications in various facets of digital forensics practice.</li>
<li>methods: The paper employs a thorough and in-depth analysis, including a review of existing research, to examine the use of AI and ML techniques in digital forensics, including data collection and recovery, cybercrime timeline reconstruction, big data analysis, pattern recognition, chain of custody safeguarding, and responsive strategies to hacking incidents.</li>
<li>results: The study highlights the potential and limitations of AI and ML techniques in digital forensics, including their contributions, limitations, and gaps in the existing research. It also underscores the significance of strategic planning, continual research, and development to unlock AI’s full potential in digital forensics and incident response, and offers insights into their benefits, drawbacks, and broader implications for tackling modern cyber threats.<details>
<summary>Abstract</summary>
In the dynamic landscape of digital forensics, the integration of Artificial Intelligence (AI) and Machine Learning (ML) stands as a transformative technology, poised to amplify the efficiency and precision of digital forensics investigations. However, the use of ML and AI in digital forensics is still in its nascent stages. As a result, this paper gives a thorough and in-depth analysis that goes beyond a simple survey and review. The goal is to look closely at how AI and ML techniques are used in digital forensics and incident response. This research explores cutting-edge research initiatives that cross domains such as data collection and recovery, the intricate reconstruction of cybercrime timelines, robust big data analysis, pattern recognition, safeguarding the chain of custody, and orchestrating responsive strategies to hacking incidents. This endeavour digs far beneath the surface to unearth the intricate ways AI-driven methodologies are shaping these crucial facets of digital forensics practice. While the promise of AI in digital forensics is evident, the challenges arising from increasing database sizes and evolving criminal tactics necessitate ongoing collaborative research and refinement within the digital forensics profession. This study examines the contributions, limitations, and gaps in the existing research, shedding light on the potential and limitations of AI and ML techniques. By exploring these different research areas, we highlight the critical need for strategic planning, continual research, and development to unlock AI's full potential in digital forensics and incident response. Ultimately, this paper underscores the significance of AI and ML integration in digital forensics, offering insights into their benefits, drawbacks, and broader implications for tackling modern cyber threats.
</details>
<details>
<summary>摘要</summary>
在数字审查领域的动态景观中，人工智能（AI）和机器学习（ML）技术被视为一种转型性的技术，它将在数字审查调查中提高效率和精度。然而，在数字审查中使用ML和AI的使用仍然处于初始阶段。因此，本文进行了深入的分析和评论，不仅是简单的报告和评论。本研究的目的是仔细研究AI和ML技术在数字审查和应急应对中的应用。本研究探讨了跨领域的数据采集和恢复、复杂的网络犯罪时间线重建、大数据分析、模式识别、维护链接 custody和应对黑客事件的应急策略等方面。本研究不仅仅是浅表面上的探讨，而是深入探究AI驱动的方法如何影响这些关键方面的数字审查实践。虽然AI在数字审查中的承诺很明显，但是随着数据库的增加和犯罪手段的发展，需要持续合作研究和完善。本研究 examine了现有研究的贡献、局限性和缺陷，为数字审查和应急应对领域的未来发展提供了新的思路和方向。最终，本文强调了AI和ML在数字审查中的潜在价值，并 shed light on its potential and limitations。
</details></li>
</ul>
<hr>
<h2 id="Deep-Quantum-Graph-Dreaming-Deciphering-Neural-Network-Insights-into-Quantum-Experiments"><a href="#Deep-Quantum-Graph-Dreaming-Deciphering-Neural-Network-Insights-into-Quantum-Experiments" class="headerlink" title="Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into Quantum Experiments"></a>Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into Quantum Experiments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07056">http://arxiv.org/abs/2309.07056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tareq Jaouni, Sören Arlt, Carlos Ruiz-Gonzalez, Ebrahim Karimi, Xuemei Gu, Mario Krenn</li>
<li>for: 本研究旨在使用可解释AI技术（XAI）来解释神经网络在量子光学实验中的学习结果。</li>
<li>methods: 本研究使用了inception或deep dreaming技术来探索神经网络对量子系统的学习。首先，我们在神经网络上训练了量子系统的性质，然后使用了inception技术来探索神经网络如何改变量子系统的性质。</li>
<li>results: 研究发现，神经网络可以Shift量子系统的初始分布性质，并且可以描述神经网络学习的策略。在深层层次中，神经网络可以识别复杂的量子结构和甚至是量子共振。这与计算机视觉中已知的性质相似，我们现在在复杂的自然科学任务中发现了这种性质。这种方法可能有助于开发更有可读性的AI基于科学发现技术。<details>
<summary>Abstract</summary>
Despite their promise to facilitate new scientific discoveries, the opaqueness of neural networks presents a challenge in interpreting the logic behind their findings. Here, we use a eXplainable-AI (XAI) technique called $inception$ or $deep$ $dreaming$, which has been invented in machine learning for computer vision. We use this techniques to explore what neural networks learn about quantum optics experiments. Our story begins by training a deep neural networks on the properties of quantum systems. Once trained, we "invert" the neural network -- effectively asking how it imagines a quantum system with a specific property, and how it would continuously modify the quantum system to change a property. We find that the network can shift the initial distribution of properties of the quantum system, and we can conceptualize the learned strategies of the neural network. Interestingly, we find that, in the first layers, the neural network identifies simple properties, while in the deeper ones, it can identify complex quantum structures and even quantum entanglement. This is in reminiscence of long-understood properties known in computer vision, which we now identify in a complex natural science task. Our approach could be useful in a more interpretable way to develop new advanced AI-based scientific discovery techniques in quantum physics.
</details>
<details>
<summary>摘要</summary>
尽管神经网络的承诺是为科学发现提供新的机会，但它们的不透明性却成为解释其发现的逻辑的挑战。在这里，我们使用一种可解释的AI技术，称为inception或deep dreaming，这种技术在机器学习中提出，用于计算机视觉领域。我们使用这种技术来探索神经网络在量子光学实验中学习的内容。我们的故事开始于训练深度神经网络，然后我们“反转”神经网络，即问神经网络如何在Specific property的量子系统中做出修改，以达到改变这个属性的目的。我们发现神经网络可以将初始分布的属性转移到量子系统中，并且我们可以概念化神经网络学习的策略。有趣的是，在核心层次上，神经网络可以识别简单的属性，而在更深的层次上，它可以识别复杂的量子结构，甚至是量子紧密相关。这与计算机视觉中长期认知的特性相似，我们现在在复杂的自然科学任务中发现这些特性。我们的方法可能有助于在更可解释的方式下开发新的高级AI科学发现技术。
</details></li>
</ul>
<hr>
<h2 id="Pearl’s-and-Jeffrey’s-Update-as-Modes-of-Learning-in-Probabilistic-Programming"><a href="#Pearl’s-and-Jeffrey’s-Update-as-Modes-of-Learning-in-Probabilistic-Programming" class="headerlink" title="Pearl’s and Jeffrey’s Update as Modes of Learning in Probabilistic Programming"></a>Pearl’s and Jeffrey’s Update as Modes of Learning in Probabilistic Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07053">http://arxiv.org/abs/2309.07053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bart Jacobs, Dario Stein</li>
<li>for: 这篇论文主要针对 updating 概率分布 的问题，即在新证据出现后，如何更新概率分布。</li>
<li>methods: 论文使用了 Pearl 和 Jeffrey 的两种自然更新方法，并对它们之间的相似性和差异进行了解释。</li>
<li>results: 论文表明，Jeffrey 的更新规则可以通过变分推理得到，而且在概率论中可以用多erset 函数和分布Monad 的 Kleisli 类来分析。<details>
<summary>Abstract</summary>
The concept of updating a probability distribution in the light of new evidence lies at the heart of statistics and machine learning. Pearl's and Jeffrey's rule are two natural update mechanisms which lead to different outcomes, yet the similarities and differences remain mysterious. This paper clarifies their relationship in several ways: via separate descriptions of the two update mechanisms in terms of probabilistic programs and sampling semantics, and via different notions of likelihood (for Pearl and for Jeffrey). Moreover, it is shown that Jeffrey's update rule arises via variational inference. In terms of categorical probability theory, this amounts to an analysis of the situation in terms of the behaviour of the multiset functor, extended to the Kleisli category of the distribution monad.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将新证据纳入概率分布更新的概念是统计和机器学习的核心。珍珠和胡均的更新规则是自然的更新机制，却又存在价值和不同之处，这些相似和不同的关系仍然莫迪。这篇论文通过以下几种方式解释了这两个更新规则之间的关系：首先，通过在概率程序和抽样语义上分别描述这两个更新规则，并通过不同的可能性概率（对珍珠和胡均）进行解释。其次，这篇论文还证明了胡均的更新规则可以通过变分推理来 derivation。在Category probability theory中，这等于对多erset函数的行为进行分析，将分布模块的Kleisli类型扩展到多erset函数。Note: The translation is in Simplified Chinese, which is the standard Chinese writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="UnifiedGesture-A-Unified-Gesture-Synthesis-Model-for-Multiple-Skeletons"><a href="#UnifiedGesture-A-Unified-Gesture-Synthesis-Model-for-Multiple-Skeletons" class="headerlink" title="UnifiedGesture: A Unified Gesture Synthesis Model for Multiple Skeletons"></a>UnifiedGesture: A Unified Gesture Synthesis Model for Multiple Skeletons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07051">http://arxiv.org/abs/2309.07051</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/youngseng/unifiedgesture">https://github.com/youngseng/unifiedgesture</a></li>
<li>paper_authors: Sicheng Yang, Zilin Wang, Zhiyong Wu, Minglei Li, Zhensong Zhang, Qiaochu Huang, Lei Hao, Songcen Xu, Xiaofei Wu, changpeng yang, Zonghong Dai</li>
<li>for: 这个论文的目的是提出一种新的散射模型基于的speech-driven手势生成方法，用于解决过去的个体数据集设计和不同的动体捕捉标准下的手势生成问题。</li>
<li>methods: 该方法首先提出了一种重定向网络，以学习不同动体标准下的手势表示，并将其整合到不同的手势数据集中。然后，通过涉及注意力和自注意力来捕捉speech和手势之间的相关性，并通过使用散射模型架构来生成更加匹配的speech和realistic的手势。最后，通过在粒度单位上使用学习的奖励函数来补做手势和speech的对齐和多样性。</li>
<li>results: 对于speech-driven手势生成方法，这个方法的实验结果表明，它在CCA、FGD和人工智能化三个指标上都超过了现有的方法。<details>
<summary>Abstract</summary>
The automatic co-speech gesture generation draws much attention in computer animation. Previous works designed network structures on individual datasets, which resulted in a lack of data volume and generalizability across different motion capture standards. In addition, it is a challenging task due to the weak correlation between speech and gestures. To address these problems, we present UnifiedGesture, a novel diffusion model-based speech-driven gesture synthesis approach, trained on multiple gesture datasets with different skeletons. Specifically, we first present a retargeting network to learn latent homeomorphic graphs for different motion capture standards, unifying the representations of various gestures while extending the dataset. We then capture the correlation between speech and gestures based on a diffusion model architecture using cross-local attention and self-attention to generate better speech-matched and realistic gestures. To further align speech and gesture and increase diversity, we incorporate reinforcement learning on the discrete gesture units with a learned reward function. Extensive experiments show that UnifiedGesture outperforms recent approaches on speech-driven gesture generation in terms of CCA, FGD, and human-likeness. All code, pre-trained models, databases, and demos are available to the public at https://github.com/YoungSeng/UnifiedGesture.
</details>
<details>
<summary>摘要</summary>
“自动合成手势拥有了广泛的关注，特别是在计算机动画领域。先前的工作基于个别数据集设计了网络结构，却导致数据量不足和不同动作捕捉标准之间的普适性问题。此外，手势和语音之间的关系强度较弱，这也是一个挑战。为解决这些问题，我们提出了一种新的扩散模型基于的语音驱动手势生成方法，并在多个手势数据集上进行了训练。具体来说，我们首先提出了一种重定向网络，以学习不同动作捕捉标准下的共同表示，从而统一各种手势的表示，同时扩展数据集。然后，我们基于扩散模型架构使用了相互关注和自身关注，以生成更好地语音匹配和更加真实的手势。为了进一步对语音和手势进行对齐和增加多样性，我们还在粗粒度上进行了资源学习，并使用了学习的奖励函数。我们的实验表明，UnifiedGesture可以在语音驱动手势生成方面与现有的方法相比，在CCA、FGD和人类化指标上表现出色。所有代码、预训练模型、数据库和示例都可以在https://github.com/YoungSeng/UnifiedGesture上获取。”
</details></li>
</ul>
<hr>
<h2 id="Latent-Representation-and-Simulation-of-Markov-Processes-via-Time-Lagged-Information-Bottleneck"><a href="#Latent-Representation-and-Simulation-of-Markov-Processes-via-Time-Lagged-Information-Bottleneck" class="headerlink" title="Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck"></a>Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07200">http://arxiv.org/abs/2309.07200</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Federici, Patrick Forré, Ryota Tomioka, Bastiaan S. Veeling</li>
<li>for: 这种论文是为了提出一种基于信息理论的时间延迟维度减少方法，用于精确地模拟大规模系统在长时间步长下的动态行为。</li>
<li>methods: 这种方法使用时间延迟信息瓶颈（T-IB），一种基于信息理论的原则，来将复杂系统映射到简化的表示空间中，并模型大幅时间跳动。</li>
<li>results: 实验表明，T-IB可以成功地捕捉原始过程的统计特征和动态特征，并在选择的时间延迟下提供信息优质的表示，超越现有的时间延迟维度减少方法。<details>
<summary>Abstract</summary>
Markov processes are widely used mathematical models for describing dynamic systems in various fields. However, accurately simulating large-scale systems at long time scales is computationally expensive due to the short time steps required for accurate integration. In this paper, we introduce an inference process that maps complex systems into a simplified representational space and models large jumps in time. To achieve this, we propose Time-lagged Information Bottleneck (T-IB), a principled objective rooted in information theory, which aims to capture relevant temporal features while discarding high-frequency information to simplify the simulation task and minimize the inference error. Our experiments demonstrate that T-IB learns information-optimal representations for accurately modeling the statistical properties and dynamics of the original process at a selected time lag, outperforming existing time-lagged dimensionality reduction methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-Reinforcement-Learning-for-Jumping-Monopods"><a href="#Efficient-Reinforcement-Learning-for-Jumping-Monopods" class="headerlink" title="Efficient Reinforcement Learning for Jumping Monopods"></a>Efficient Reinforcement Learning for Jumping Monopods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07038">http://arxiv.org/abs/2309.07038</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mfocchi/jump_rl">https://github.com/mfocchi/jump_rl</a></li>
<li>paper_authors: Riccardo Bussola, Michele Focchi, Andrea Del Prete, Daniele Fontanelli, Luigi Palopoli</li>
<li>for: 这个研究旨在解决控制问题，使一个单脚抓到目标点。</li>
<li>methods: 该研究使用了知识导引RL框架，以快速学习控制器。</li>
<li>results: 研究表明，该方法比优化基于方法和端到端RL方法更高效。<details>
<summary>Abstract</summary>
In this work, we consider the complex control problem of making a monopod reach a target with a jump. The monopod can jump in any direction and the terrain underneath its foot can be uneven. This is a template of a much larger class of problems, which are extremely challenging and computationally expensive to solve using standard optimisation-based techniques. Reinforcement Learning (RL) could be an interesting alternative, but the application of an end-to-end approach in which the controller must learn everything from scratch, is impractical. The solution advocated in this paper is to guide the learning process within an RL framework by injecting physical knowledge. This expedient brings to widespread benefits, such as a drastic reduction of the learning time, and the ability to learn and compensate for possible errors in the low-level controller executing the motion. We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们考虑了一个复杂的控制问题，即使用杆 Foot 达到目标点。杆 Foot 可以在任何方向跳跃，地面下的地形可能不平坦。这是一个更大的类型问题的模板，这些问题非常困难并且计算昂贵，使用标准优化基本技术来解决。学习反馈（RL）可能是一个有趣的alternative，但是把控制器学习 everything from scratch 的end-to-end方法是不实用的。我们提出的解决方案是通过在 RL 框架中注入物理知识来导引学习过程。这种方法带来了广泛的好处，如减少学习时间和可以学习和赔偿低级控制器执行运动中的可能错误。我们通过与优化基本技术和end-to-end RL方法进行比较，证明了我们的方法的优势。
</details></li>
</ul>
<hr>
<h2 id="How-Not-to-Use-Sociodemographic-Information-for-Subjective-NLP-Tasks"><a href="#How-Not-to-Use-Sociodemographic-Information-for-Subjective-NLP-Tasks" class="headerlink" title="How (Not) to Use Sociodemographic Information for Subjective NLP Tasks"></a>How (Not) to Use Sociodemographic Information for Subjective NLP Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07034">http://arxiv.org/abs/2309.07034</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ukplab/arxiv2023-sociodemographic-prompting">https://github.com/ukplab/arxiv2023-sociodemographic-prompting</a></li>
<li>paper_authors: Tilman Beck, Hendrik Schuff, Anne Lauscher, Iryna Gurevych</li>
<li>for: 这个研究旨在解释社会学人类对于主观NLU任务的决策会受到哪些因素影响，以及社会学人类对于这些任务的评估是否有所不同。</li>
<li>methods: 这个研究使用了社会学人类对于主观NLU任务的评估，并评估了不同的提示方式以及模型家族对于这些任务的表现。</li>
<li>results: 研究发现，社会学人类对于主观NLU任务的评估存在许多不同，并且不同的提示方式和模型家族对于这些任务的表现也有很大的差异。<details>
<summary>Abstract</summary>
Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as hate speech detection. Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique -- it remains unclear, for which tasks and scenarios it can help and evaluations are limited to specific tasks only. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. Concretely, we evaluate several prompt formulations across seven datasets and six instruction-tuned model families. We find that (1) while sociodemographic prompting can be beneficial for improving zero-shot learning in subjective NLP tasks, (2) its outcomes largely vary for different model types, sizes, and datasets, (3) are subject to large variance with regards to prompt formulations. Thus, sociodemographic prompting is not a reliable proxy for traditional data annotation with a sociodemographically heterogeneous group of annotators. Instead, we propose (4) to use it for identifying ambiguous instances resulting in more informed annotation efforts.
</details>
<details>
<summary>摘要</summary>
评分人员的社会 демографические背景（例如，个人的性别、年龄、教育背景等）在主观NLPTasks中的决策产生很大影响。常见的多样性导致高度不一致。为了模拟这种多样性，最近的研究已经探索了社会 демографических提示，一种技术，可以让模型的输出更加受人类社会 демографиically多样化的人的影响。然而，NLPLiterature中有限的资源表明，这种技术的有效性是不确定的，它的应用场景和任务类型都需要进一步的研究。我们填补这个研究漏洞，并提出了以下结论：1. 社会 демографические提示可以在主观NLPTasks中提高零shot学习的效果。2. 不同的模型类型、大小和数据集中，sociodemographic prompting的效果差异较大。3. 对提示形式的选择会导致很大的变化。4. 因此，sociodemographic prompting不是一个可靠的代理人 для使用多样化的社会 демографи学注解人员进行标注。而是应用于帮助标注人员更加了解的情况。
</details></li>
</ul>
<hr>
<h2 id="Resume-Parsing-as-Hierarchical-Sequence-Labeling-An-Empirical-Study"><a href="#Resume-Parsing-as-Hierarchical-Sequence-Labeling-An-Empirical-Study" class="headerlink" title="Résumé Parsing as Hierarchical Sequence Labeling: An Empirical Study"></a>Résumé Parsing as Hierarchical Sequence Labeling: An Empirical Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07015">http://arxiv.org/abs/2309.07015</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/federetyk/resume-parsing">https://github.com/federetyk/resume-parsing</a></li>
<li>paper_authors: Federico Retyk, Hermenegildo Fabregat, Juan Aizpuru, Mariana Taglio, Rabih Zbib</li>
<li>For: 本研究旨在提出一种 simultaneous 分类模型，用于从简历中提取信息。* Methods: 本研究采用了两级标签模型，将文档分为行和单词两个水平，并同时进行行和单词的标签。* Results: 实验结果表明，提出的模型在英文、法语、中文、西班牙语、德语、葡萄牙语和瑞典语的简历提取任务中表现出色，超越了之前的方法。<details>
<summary>Abstract</summary>
Extracting information from r\'esum\'es is typically formulated as a two-stage problem, where the document is first segmented into sections and then each section is processed individually to extract the target entities. Instead, we cast the whole problem as sequence labeling in two levels -- lines and tokens -- and study model architectures for solving both tasks simultaneously. We build high-quality r\'esum\'e parsing corpora in English, French, Chinese, Spanish, German, Portuguese, and Swedish. Based on these corpora, we present experimental results that demonstrate the effectiveness of the proposed models for the information extraction task, outperforming approaches introduced in previous work. We conduct an ablation study of the proposed architectures. We also analyze both model performance and resource efficiency, and describe the trade-offs for model deployment in the context of a production environment.
</details>
<details>
<summary>摘要</summary>
通常情况下，从简历中提取信息是一个两阶段的问题，首先将文档分 segmented into sections，然后对每个section进行处理，以提取目标实体。而我们将这个问题框定为一个两级标注问题，将文本分为两个水平：lines和tokens，并研究如何同时解决这两个任务。我们建立了高质量的简历分析 Corpora 在英语、法语、中文、西班牙语、德语、葡萄牙语和瑞典语等语言中。基于这些 Corpora，我们提出了一些实验结果，表明我们的方法在信息提取任务中表现出色，超过了之前的方法。我们进行了模型architecture的ablation Study，并分析了模型性能和资源使用情况，并描述了在生产环境中模型部署的trade-offs。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Analysis-of-Corporate-ESG-Reports-A-Model-of-Evolutionary-Trends"><a href="#Dynamic-Analysis-of-Corporate-ESG-Reports-A-Model-of-Evolutionary-Trends" class="headerlink" title="Dynamic Analysis of Corporate ESG Reports: A Model of Evolutionary Trends"></a>Dynamic Analysis of Corporate ESG Reports: A Model of Evolutionary Trends</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07001">http://arxiv.org/abs/2309.07001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyuan Xia, Anchen Sun, Xiaodong Cai, Saixing Zeng</li>
<li>for: 这种研究旨在映射全球市场中公司ESG报告的变化景观。</li>
<li>methods: 该研究采用动态框架分析公司ESG策略管理，包括个体类、多个类和特定可持续发展指数的Alignment。</li>
<li>results: 研究发现，通过包含分析关键词的方法，可以揭示过去几年ESG话题的同时演变。<details>
<summary>Abstract</summary>
Environmental, social, and governance (ESG) reports are globally recognized as a keystone in sustainable enterprise development. This study aims to map the changing landscape of ESG topics within firms in the global market. A dynamic framework is developed to analyze ESG strategic management for individual classes, across multiple classes, and in alignment with a specific sustainability index. The output of these analytical processes forms the foundation of an ESG strategic model. Utilizing a rich collection of 21st-century ESG reports from technology companies, our experiment elucidates the changes in ESG perspectives by incorporating analytical keywords into the proposed framework. This work thus provides an empirical method that reveals the concurrent evolution of ESG topics over recent years.
</details>
<details>
<summary>摘要</summary>
环境、社会和管理（ESG）报告在全球市场被广泛认可为可持续企业发展的关键estone。这项研究旨在映射全球市场内公司ESG主题的变化情况。我们提出了一种动态框架，用于分析公司独立类、多个类和特定可持续指数的ESG策略管理。这些分析过程的输出形成了ESG策略模型的基础。通过使用21世纪ESG报告的丰富集合，我们的实验揭示了ESG视角的变化。这种实验方法可以揭示过去几年ESG主题的同时演化。Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="MASTERKEY-Practical-Backdoor-Attack-Against-Speaker-Verification-Systems"><a href="#MASTERKEY-Practical-Backdoor-Attack-Against-Speaker-Verification-Systems" class="headerlink" title="MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems"></a>MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06981">http://arxiv.org/abs/2309.06981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanqing Guo, Xun Chen, Junfeng Guo, Li Xiao, Qiben Yan</li>
<li>For: The paper is written to propose a backdoor attack called MASTERKEY that can compromise speaker verification (SV) models in mobile systems, with a focus on real-world practical settings where the attacker has no knowledge of the intended victim.* Methods: The paper investigates the limitations of existing poisoning attacks against unseen targets, optimizes a universal backdoor that can attack arbitrary targets, embeds speaker’s characteristics and semantics information into the backdoor, and estimates channel distortion to integrate it into the backdoor.* Results: The paper validates the attack on 6 popular SV models, poisoning a total of 53 models and using a trigger to attack 16,430 enrolled speakers (310 target speakers enrolled in 53 poisoned models) with a 100% attack success rate at a 15% poison rate, and achieving a 50% attack success rate at a 3% poison rate. The attack is validated in 3 real-world scenarios, including over-the-air and over-the-telephony-line scenarios.Here’s the Chinese version of the three information points:*  FOR: 这篇论文是为了提出一种名为MASTERKEY的后门攻击，用于在移动系统中验证真实用户的语音特征，并且在实际生活中的假设中，攻击者没有受害者的知情。*  METHODS: 论文调查了现有的毒 attacked against 未知目标的局限性，并且优化了一个通用的后门，可以攻击任意目标。然后，它嵌入了说话者的特征和语义信息到后门中，使其隐蔽。最后，它估算了通道扭曲，并将其纳入到后门中。* RESULTS: 论文验证了这种攻击在6种流行的SV模型上，毒化了53个模型，并使用触发器攻击了16,430名注册说话者（310名目标说话者注册在53个毒化模型中），成功率100%，毒料率15%。降低毒料率到3%，成功率仍然约为50%。论文在3个实际生活中场景中成功地演示了这种攻击，包括过空中和过 телеphony-line 场景。<details>
<summary>Abstract</summary>
Speaker Verification (SV) is widely deployed in mobile systems to authenticate legitimate users by using their voice traits. In this work, we propose a backdoor attack MASTERKEY, to compromise the SV models. Different from previous attacks, we focus on a real-world practical setting where the attacker possesses no knowledge of the intended victim. To design MASTERKEY, we investigate the limitation of existing poisoning attacks against unseen targets. Then, we optimize a universal backdoor that is capable of attacking arbitrary targets. Next, we embed the speaker's characteristics and semantics information into the backdoor, making it imperceptible. Finally, we estimate the channel distortion and integrate it into the backdoor. We validate our attack on 6 popular SV models. Specifically, we poison a total of 53 models and use our trigger to attack 16,430 enrolled speakers, composed of 310 target speakers enrolled in 53 poisoned models. Our attack achieves 100% attack success rate with a 15% poison rate. By decreasing the poison rate to 3%, the attack success rate remains around 50%. We validate our attack in 3 real-world scenarios and successfully demonstrate the attack through both over-the-air and over-the-telephony-line scenarios.
</details>
<details>
<summary>摘要</summary>
听话验证（SV）广泛应用在移动系统中，以使用用户的声音特征进行身份验证。在这项工作中，我们提出了一种后门攻击方法，名为主要钥匙（MASTERKEY），以损害SV模型。与前一些攻击不同，我们在实际世界中具有无知的攻击者。我们调查现有毒素攻击的局限性，然后优化一个通用的后门，可以攻击任意目标。接着，我们将听话者的特征和 semantics信息 embed 到后门中，使其隐藏不见。最后，我们估算通道扭曲，并将其纳入后门。我们验证了我们的攻击方法，并成功攻击了6个流行的SV模型。具体来说，我们毒备53个模型，并使用我们的触发器攻击16430名注册用户，其中310名目标用户注册在53个毒备模型中。我们的攻击达100%成功率，且使用毒备率为15%时，成功率约为50%。我们在3个实际场景中验证了我们的攻击，并成功地通过了 both over-the-air 和 over-the-telephony-line 场景。
</details></li>
</ul>
<hr>
<h2 id="DNNShifter-An-Efficient-DNN-Pruning-System-for-Edge-Computing"><a href="#DNNShifter-An-Efficient-DNN-Pruning-System-for-Edge-Computing" class="headerlink" title="DNNShifter: An Efficient DNN Pruning System for Edge Computing"></a>DNNShifter: An Efficient DNN Pruning System for Edge Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06973">http://arxiv.org/abs/2309.06973</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/blessonvar/dnnshifter">https://github.com/blessonvar/dnnshifter</a></li>
<li>paper_authors: Bailey J. Eccles, Philip Rodgers, Peter Kilpatrick, Ivor Spence, Blesson Varghese</li>
<li>for: 本研究旨在 Addressing the challenge of deploying deep neural network (DNN) models on mobile and embedded devices with limited computational and memory resources.</li>
<li>methods: 本研究使用了一种 novel methodology of structured pruning to rapidly derive suitable model variants that maintain the accuracy of the original model.</li>
<li>results:  compared to conventional training methods, DNNShifter produces pruned model variants up to 93x faster, with a 1.67x inference latency speedup and up to 3.8x lower memory utilization. Additionally, DNNShifter has up to 11.9x lower overhead for switching models.<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) underpin many machine learning applications. Production quality DNN models achieve high inference accuracy by training millions of DNN parameters which has a significant resource footprint. This presents a challenge for resources operating at the extreme edge of the network, such as mobile and embedded devices that have limited computational and memory resources. To address this, models are pruned to create lightweight, more suitable variants for these devices. Existing pruning methods are unable to provide similar quality models compared to their unpruned counterparts without significant time costs and overheads or are limited to offline use cases. Our work rapidly derives suitable model variants while maintaining the accuracy of the original model. The model variants can be swapped quickly when system and network conditions change to match workload demand. This paper presents DNNShifter, an end-to-end DNN training, spatial pruning, and model switching system that addresses the challenges mentioned above. At the heart of DNNShifter is a novel methodology that prunes sparse models using structured pruning. The pruned model variants generated by DNNShifter are smaller in size and thus faster than dense and sparse model predecessors, making them suitable for inference at the edge while retaining near similar accuracy as of the original dense model. DNNShifter generates a portfolio of model variants that can be swiftly interchanged depending on operational conditions. DNNShifter produces pruned model variants up to 93x faster than conventional training methods. Compared to sparse models, the pruned model variants are up to 5.14x smaller and have a 1.67x inference latency speedup, with no compromise to sparse model accuracy. In addition, DNNShifter has up to 11.9x lower overhead for switching models and up to 3.8x lower memory utilisation than existing approaches.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在机器学习应用中扮演着重要的角色。生产质量DNN模型在训练数百万个DNN参数后可以达到高精度推理。这种情况带来了Edge网络中的资源挑战，如移动设备和嵌入式设备，它们具有有限的计算和存储资源。为解决这个问题，模型会被截取，以创建轻量级、适应 Edge 设备的模型变体。现有的截取方法无法提供与原始模型相同质量的模型变体，或者需要过长的时间和资源成本，或者只适用于线上场景。我们的工作可以快速生成适应 Edge 设备的模型变体，保持原始模型的精度。这些模型变体可以快速交换，根据系统和网络条件变化，以适应工作负荷。我们提出了DNNShifter，一个端到端的DNN训练、空间截取和模型交换系统，解决以上问题。DNNShifter的核心是一种新的预测截取方法，可以快速生成稀疏模型的减少版本。这些减少版本比传统训练方法快速，小于传统稀疏模型的大小，但保持与原始 dense 模型的精度。DNNShifter生成了一个模型变体的PORTFOLIO，可以快速交换，根据操作条件变化。相比于稀疏模型，DNNShifter的减少版本更快，具有1.67倍的推理速度，而且没有牺牲稀疏模型的精度。此外，DNNShifter的模型交换过程 overhead 低于11.9倍，内存使用率低于3.8倍。
</details></li>
</ul>
<hr>
<h2 id="Setting-the-Right-Expectations-Algorithmic-Recourse-Over-Time"><a href="#Setting-the-Right-Expectations-Algorithmic-Recourse-Over-Time" class="headerlink" title="Setting the Right Expectations: Algorithmic Recourse Over Time"></a>Setting the Right Expectations: Algorithmic Recourse Over Time</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06969">http://arxiv.org/abs/2309.06969</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joao Fonseca, Andrew Bell, Carlo Abrate, Francesco Bonchi, Julia Stoyanovich</li>
<li>for: 这篇论文关注了算法决策中的高风险决策，以及算法救济的可靠性问题。</li>
<li>methods: 该论文提出了一种基于代理模型的 simulated environment 来研究算法救济在不断变化的环境中的可靠性问题。</li>
<li>results: 研究发现，只有在某些特定的参数化情况下，算法救济可以在时间上保持可靠性。这指出了更多的研究是需要进行，以确保算法救济的可靠性。<details>
<summary>Abstract</summary>
Algorithmic systems are often called upon to assist in high-stakes decision making. In light of this, algorithmic recourse, the principle wherein individuals should be able to take action against an undesirable outcome made by an algorithmic system, is receiving growing attention. The bulk of the literature on algorithmic recourse to-date focuses primarily on how to provide recourse to a single individual, overlooking a critical element: the effects of a continuously changing context. Disregarding these effects on recourse is a significant oversight, since, in almost all cases, recourse consists of an individual making a first, unfavorable attempt, and then being given an opportunity to make one or several attempts at a later date - when the context might have changed. This can create false expectations, as initial recourse recommendations may become less reliable over time due to model drift and competition for access to the favorable outcome between individuals.   In this work we propose an agent-based simulation framework for studying the effects of a continuously changing environment on algorithmic recourse. In particular, we identify two main effects that can alter the reliability of recourse for individuals represented by the agents: (1) competition with other agents acting upon recourse, and (2) competition with new agents entering the environment. Our findings highlight that only a small set of specific parameterizations result in algorithmic recourse that is reliable for agents over time. Consequently, we argue that substantial additional work is needed to understand recourse reliability over time, and to develop recourse methods that reward agents' effort.
</details>
<details>
<summary>摘要</summary>
算法系统经常被召唤来协助高风险决策。因此，算法补救（individuals should be able to take action against an undesirable outcome made by an algorithmic system）正在受到加强注意力。大多数Literature on algorithmic recourse to date focuses primarily on how to provide recourse to a single individual, neglecting a critical element: the effects of a continuously changing context. Ignoring these effects on recourse is a significant oversight, as recourse typically consists of an individual making a first, unfavorable attempt, and then being given an opportunity to make one or several attempts at a later date - when the context might have changed. This can create false expectations, as initial recourse recommendations may become less reliable over time due to model drift and competition for access to the favorable outcome between individuals.在这个研究中，我们提出了一个基于代理模型的 simulate the effects of a continuously changing environment on algorithmic recourse. Specifically, we identify two main effects that can alter the reliability of recourse for individuals represented by the agents: (1) competition with other agents acting upon recourse, and (2) competition with new agents entering the environment. Our findings highlight that only a small set of specific parameterizations result in algorithmic recourse that is reliable for agents over time. Therefore, we argue that substantial additional work is needed to understand recourse reliability over time, and to develop recourse methods that reward agents' effort.
</details></li>
</ul>
<hr>
<h2 id="Attention-based-Dynamic-Graph-Convolutional-Recurrent-Neural-Network-for-Traffic-Flow-Prediction-in-Highway-Transportation"><a href="#Attention-based-Dynamic-Graph-Convolutional-Recurrent-Neural-Network-for-Traffic-Flow-Prediction-in-Highway-Transportation" class="headerlink" title="Attention-based Dynamic Graph Convolutional Recurrent Neural Network for Traffic Flow Prediction in Highway Transportation"></a>Attention-based Dynamic Graph Convolutional Recurrent Neural Network for Traffic Flow Prediction in Highway Transportation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07196">http://arxiv.org/abs/2309.07196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianpu Zhang, Weilong Ding, Mengda Xing</li>
<li>for:  traffic flow prediction in highway transportation</li>
<li>methods:  Attention-based Dynamic Graph Convolutional Recurrent Neural Network (ADGCRNN) with self-attention, multi-dynamic graphs, and dedicated gated kernel for graph convolution operations</li>
<li>results:  better performance than state-of-the-art baselines and practical benefit in highway transportation, as proven by experiments on two public datasets and case studies of a real Web system.<details>
<summary>Abstract</summary>
As one of the important tools for spatial feature extraction, graph convolution has been applied in a wide range of fields such as traffic flow prediction. However, current popular works of graph convolution cannot guarantee spatio-temporal consistency in a long period. The ignorance of correlational dynamics, convolutional locality and temporal comprehensiveness would limit predictive accuracy. In this paper, a novel Attention-based Dynamic Graph Convolutional Recurrent Neural Network (ADGCRNN) is proposed to improve traffic flow prediction in highway transportation. Three temporal resolutions of data sequence are effectively integrated by self-attention to extract characteristics; multi-dynamic graphs and their weights are dynamically created to compliantly combine the varying characteristics; a dedicated gated kernel emphasizing highly relative nodes is introduced on these complete graphs to reduce overfitting for graph convolution operations. Experiments on two public datasets show our work better than state-of-the-art baselines, and case studies of a real Web system prove practical benefit in highway transportation.
</details>
<details>
<summary>摘要</summary>
As one of the important tools for spatial feature extraction, graph convolution has been applied in a wide range of fields such as traffic flow prediction. However, current popular works of graph convolution cannot guarantee spatio-temporal consistency in a long period. The ignorance of correlational dynamics, convolutional locality and temporal comprehensiveness would limit predictive accuracy. In this paper, a novel Attention-based Dynamic Graph Convolutional Recurrent Neural Network (ADGCRNN) is proposed to improve traffic flow prediction in highway transportation. Three temporal resolutions of data sequence are effectively integrated by self-attention to extract characteristics; multi-dynamic graphs and their weights are dynamically created to compliantly combine the varying characteristics; a dedicated gated kernel emphasizing highly relative nodes is introduced on these complete graphs to reduce overfitting for graph convolution operations. Experiments on two public datasets show our work better than state-of-the-art baselines, and case studies of a real Web system prove practical benefit in highway transportation.Here's the breakdown of the translation:* "As one of the important tools for spatial feature extraction" becomes "作为空间特征提取工具之一"* "graph convolution" becomes "图 convolution"* "cannot guarantee spatio-temporal consistency in a long period" becomes "不能保证长期空间-时间一致性"* "ignorance of correlational dynamics" becomes "忽略相关动态的忽略"* "convolutional locality" becomes "卷积性的局部性"* "temporal comprehensiveness" becomes "时间全面性"* "would limit predictive accuracy" becomes "会限制预测精度"* "In this paper, a novel Attention-based Dynamic Graph Convolutional Recurrent Neural Network (ADGCRNN) is proposed" becomes "本文提出了一种新型的注意力基于动态图 convolutional Recurrent Neural Network (ADGCRNN)"* "Three temporal resolutions of data sequence are effectively integrated by self-attention" becomes "数据序列的三个时间分辨率被自注意力有效地集成"* "multi-dynamic graphs and their weights are dynamically created to compliantly combine the varying characteristics" becomes "多个动态图和其权重在运行时动态创建，以兼容不同特征的变化"* "a dedicated gated kernel emphasizing highly relative nodes is introduced on these complete graphs" becomes "在这些完整的图上引入了一种专门的权重抑制层，以强调高度相关的节点"* "Experiments on two public datasets show our work better than state-of-the-art baselines" becomes "在两个公共数据集上进行了对我们的工作的比较，显示我们的工作比预设基线更好"* "case studies of a real Web system prove practical benefit in highway transportation" becomes "一个真实的Web系统的案例研究表明，我们的工作在高速交通中具有实用的利益"
</details></li>
</ul>
<hr>
<h2 id="Towards-Reliable-Dermatology-Evaluation-Benchmarks"><a href="#Towards-Reliable-Dermatology-Evaluation-Benchmarks" class="headerlink" title="Towards Reliable Dermatology Evaluation Benchmarks"></a>Towards Reliable Dermatology Evaluation Benchmarks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06961">http://arxiv.org/abs/2309.06961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/digital-dermatology/selfclean-revised-benchmarks">https://github.com/digital-dermatology/selfclean-revised-benchmarks</a></li>
<li>paper_authors: Fabian Gröger, Simone Lionetti, Philippe Gottfrois, Alvaro Gonzalez-Jimenez, Matthew Groh, Roxana Daneshjou, Labelling Consortium, Alexander A. Navarini, Marc Pouly</li>
<li>for: 这篇论文是为了提高数字DERMATOLOGY模型性能评估的可靠性而写的。</li>
<li>methods: 该论文提出了一种资源效率的数据清洁协议，使用现有的算法清洁策略，并通过多名DERMATOLOGIST的确认进行筛选不相关样本和近似样本，并估计每个DERMATOLOGY图像集中标签错误的百分比。</li>
<li>results: 该论文通过对六个DERMATOLOGY图像集进行数据清洁和确认，发现这些集中存在一些不准确的标签，并估计这些标签错误的百分比。同时， authors也发布了每个图像集的修订后的文件列表，以便将来的模型评估工作更加可靠。<details>
<summary>Abstract</summary>
Benchmark datasets for digital dermatology unwittingly contain inaccuracies that reduce trust in model performance estimates. We propose a resource-efficient data cleaning protocol to identify issues that escaped previous curation. The protocol leverages an existing algorithmic cleaning strategy and is followed by a confirmation process terminated by an intuitive stopping criterion. Based on confirmation by multiple dermatologists, we remove irrelevant samples and near duplicates and estimate the percentage of label errors in six dermatology image datasets for model evaluation promoted by the International Skin Imaging Collaboration. Along with this paper, we publish revised file lists for each dataset which should be used for model evaluation. Our work paves the way for more trustworthy performance assessment in digital dermatology.
</details>
<details>
<summary>摘要</summary>
《数字DERMATOLOGY中的标准数据集不慎地含有错误，这会降低模型性能估计的信任度。我们提议一种资源有效的数据清洁协议，以确定这些问题。该协议基于现有的算法清洁策略，并且通过多名 dermatologist 的确认进行终止。我们从六个DERMATOLOGY图像集中移除无关样本和近似样本，并估计这些样本集中标签错误的百分比。我们随着这篇论文发布了每个样本集的修订文件列表，这些列表应该用于模型评估。我们的工作为数字DERMATOLOGY中的性能评估奠定了基础。》Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="PhantomSound-Black-Box-Query-Efficient-Audio-Adversarial-Attack-via-Split-Second-Phoneme-Injection"><a href="#PhantomSound-Black-Box-Query-Efficient-Audio-Adversarial-Attack-via-Split-Second-Phoneme-Injection" class="headerlink" title="PhantomSound: Black-Box, Query-Efficient Audio Adversarial Attack via Split-Second Phoneme Injection"></a>PhantomSound: Black-Box, Query-Efficient Audio Adversarial Attack via Split-Second Phoneme Injection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06960">http://arxiv.org/abs/2309.06960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanqing Guo, Guangjing Wang, Yuanda Wang, Bocheng Chen, Qiben Yan, Li Xiao</li>
<li>for: 针对声音助手的黑盒攻击</li>
<li>methods: 利用决策基本攻击避免训练模型输出的敏感信息泄露</li>
<li>results: 在3个实际场景下成功攻击5种商业声音控制设备，穿越3种生物特征验证机制，成功率高于95%，并且可以在几分钟内生成攻击示例并发起攻击<details>
<summary>Abstract</summary>
In this paper, we propose PhantomSound, a query-efficient black-box attack toward voice assistants. Existing black-box adversarial attacks on voice assistants either apply substitution models or leverage the intermediate model output to estimate the gradients for crafting adversarial audio samples. However, these attack approaches require a significant amount of queries with a lengthy training stage. PhantomSound leverages the decision-based attack to produce effective adversarial audios, and reduces the number of queries by optimizing the gradient estimation. In the experiments, we perform our attack against 4 different speech-to-text APIs under 3 real-world scenarios to demonstrate the real-time attack impact. The results show that PhantomSound is practical and robust in attacking 5 popular commercial voice controllable devices over the air, and is able to bypass 3 liveness detection mechanisms with >95% success rate. The benchmark result shows that PhantomSound can generate adversarial examples and launch the attack in a few minutes. We significantly enhance the query efficiency and reduce the cost of a successful untargeted and targeted adversarial attack by 93.1% and 65.5% compared with the state-of-the-art black-box attacks, using merely ~300 queries (~5 minutes) and ~1,500 queries (~25 minutes), respectively.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了PhantomSound，一种高效的黑盒攻击方法 toward voice assistants。现有的黑盒对voice assistants的攻击方法 Either apply substitution models or leverage the intermediate model output to estimate the gradients for crafting adversarial audio samples.然而，这些攻击方法需要较长的训练时间和较多的查询数。PhantomSound leverages the decision-based attack to produce effective adversarial audios, and reduces the number of queries by optimizing the gradient estimation.在实验中，我们对4种speech-to-text API进行了3个实际场景的攻击，以示出实时攻击的影响。结果显示，PhantomSound可以快速和可靠地攻击5种流行的语音控制设备，并可以绕过3种生活体验检测机制，成功率高于95%。 benchmark结果表明，PhantomSound可以在几分钟内生成攻击示例和发动攻击。我们在查询效率和成功攻击成本方面做出了重要提高，相比之前的黑盒攻击方法，PhantomSound可以在merely ~300 queries（~5分钟）和~1,500 queries（~25分钟）内发动成功无目标和目标攻击，减少了93.1%和65.5%的成本。
</details></li>
</ul>
<hr>
<h2 id="Implicit-Neural-Multiple-Description-for-DNA-based-data-storage"><a href="#Implicit-Neural-Multiple-Description-for-DNA-based-data-storage" class="headerlink" title="Implicit Neural Multiple Description for DNA-based data storage"></a>Implicit Neural Multiple Description for DNA-based data storage</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06956">http://arxiv.org/abs/2309.06956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Trung Hieu Le, Xavier Pic, Jeremy Mateos, Marc Antonini</li>
<li>for: 这篇论文是为了探讨用DNA作为数据存储解决方案的可能性，以及处理存储和生物 manipulate 操作中出现的错误的技术方法。</li>
<li>methods: 该论文使用了一种新型的压缩方案和多重描述编码（MDC）技术，利用神经网络对DNA数据进行编码，以快速减少数据的存储容量。</li>
<li>results: 实验结果显示，该方法可以与当前领域中最新的DNA数据存储方法相比，具有更高的压缩率和更强的静音鲁棒性。<details>
<summary>Abstract</summary>
DNA exhibits remarkable potential as a data storage solution due to its impressive storage density and long-term stability, stemming from its inherent biomolecular structure. However, developing this novel medium comes with its own set of challenges, particularly in addressing errors arising from storage and biological manipulations. These challenges are further conditioned by the structural constraints of DNA sequences and cost considerations. In response to these limitations, we have pioneered a novel compression scheme and a cutting-edge Multiple Description Coding (MDC) technique utilizing neural networks for DNA data storage. Our MDC method introduces an innovative approach to encoding data into DNA, specifically designed to withstand errors effectively. Notably, our new compression scheme overperforms classic image compression methods for DNA-data storage. Furthermore, our approach exhibits superiority over conventional MDC methods reliant on auto-encoders. Its distinctive strengths lie in its ability to bypass the need for extensive model training and its enhanced adaptability for fine-tuning redundancy levels. Experimental results demonstrate that our solution competes favorably with the latest DNA data storage methods in the field, offering superior compression rates and robust noise resilience.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DEFormer-DCT-driven-Enhancement-Transformer-for-Low-light-Image-and-Dark-Vision"><a href="#DEFormer-DCT-driven-Enhancement-Transformer-for-Low-light-Image-and-Dark-Vision" class="headerlink" title="DEFormer: DCT-driven Enhancement Transformer for Low-light Image and Dark Vision"></a>DEFormer: DCT-driven Enhancement Transformer for Low-light Image and Dark Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06941">http://arxiv.org/abs/2309.06941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangchen Yin, Zhenda Yu, Xin Gao, Ran Ju, Xiao Sun, Xinyu Zhang</li>
<li>for: 这篇论文的目的是提高低光照图像的色彩和细节，以便在自动驾驶中进行高级视觉任务。</li>
<li>methods: 该论文提出了一种基于频率的新凭据，并提出了一种名为频率增强变换器（DEFormer）。该变换器包括一个可学习的频率分支（LFB），用于频率增强，以及一种跨频域融合（CDF）来减少RGB频谱和频率频谱之间的差异。</li>
<li>results: 该论文的实验结果表明，通过使用DEFormer进行预处理，可以提高检测器的性能，在ExDark和DARK FACE数据集上分别提高了2.1%和3.4%的均值精度。<details>
<summary>Abstract</summary>
The goal of low-light image enhancement is to restore the color and details of the image and is of great significance for high-level visual tasks in autonomous driving. However, it is difficult to restore the lost details in the dark area by relying only on the RGB domain. In this paper we introduce frequency as a new clue into the network and propose a novel DCT-driven enhancement transformer (DEFormer). First, we propose a learnable frequency branch (LFB) for frequency enhancement contains DCT processing and curvature-based frequency enhancement (CFE). CFE calculates the curvature of each channel to represent the detail richness of different frequency bands, then we divides the frequency features, which focuses on frequency bands with richer textures. In addition, we propose a cross domain fusion (CDF) for reducing the differences between the RGB domain and the frequency domain. We also adopt DEFormer as a preprocessing in dark detection, DEFormer effectively improves the performance of the detector, bringing 2.1% and 3.4% improvement in ExDark and DARK FACE datasets on mAP respectively.
</details>
<details>
<summary>摘要</summary>
goal of low-light image enhancement is to restore the color and details of the image, and it is of great significance for high-level visual tasks in autonomous driving. However, it is difficult to restore the lost details in the dark area by relying only on the RGB domain. In this paper, we introduce frequency as a new clue into the network and propose a novel DCT-driven enhancement transformer (DEFormer). First, we propose a learnable frequency branch (LFB) for frequency enhancement, which contains DCT processing and curvature-based frequency enhancement (CFE). CFE calculates the curvature of each channel to represent the detail richness of different frequency bands, then we divide the frequency features, which focuses on frequency bands with richer textures. In addition, we propose a cross domain fusion (CDF) for reducing the differences between the RGB domain and the frequency domain. We also adopt DEFormer as a preprocessing in dark detection, DEFormer effectively improves the performance of the detector, bringing 2.1% and 3.4% improvement in ExDark and DARK FACE datasets on mAP respectively.
</details></li>
</ul>
<hr>
<h2 id="Collectionless-Artificial-Intelligence"><a href="#Collectionless-Artificial-Intelligence" class="headerlink" title="Collectionless Artificial Intelligence"></a>Collectionless Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06938">http://arxiv.org/abs/2309.06938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Gori, Stefano Melacci</li>
<li>For: The paper advocates for the development of new machine learning protocols that prioritize human-like cognitive skills and environmental interactions, rather than relying on centralized data collections.* Methods: The proposed approach is based on the collectionless principle, which restricts the learning process to processing data acquired from the environment at each time instant, without storing temporal information. This promotes self-organized memorization skills and dynamic information organization.* Results: The authors suggest that this approach could lead to the development of AI technologies that are better suited to addressing privacy issues, control, and customizability, and that it could reduce the concentration of power in companies and governments by promoting massively distributed computation.<details>
<summary>Abstract</summary>
By and large, the professional handling of huge data collections is regarded as a fundamental ingredient of the progress of machine learning and of its spectacular results in related disciplines, with a growing agreement on risks connected to the centralization of such data collections. This paper sustains the position that the time has come for thinking of new learning protocols where machines conquer cognitive skills in a truly human-like context centered on environmental interactions. This comes with specific restrictions on the learning protocol according to the collectionless principle, which states that, at each time instant, data acquired from the environment is processed with the purpose of contributing to update the current internal representation of the environment, and that the agent is not given the privilege of recording the temporal stream. Basically, there is neither permission to store the temporal information coming from the sensors, thus promoting the development of self-organized memorization skills at a more abstract level, instead of relying on bare storage to simulate learning dynamics that are typical of offline learning algorithms. This purposely extreme position is intended to stimulate the development of machines that learn to dynamically organize the information by following human-based schemes. The proposition of this challenge suggests developing new foundations on computational processes of learning and reasoning that might open the doors to a truly orthogonal competitive track on AI technologies that avoid data accumulation by design, thus offering a framework which is better suited concerning privacy issues, control and customizability. Finally, pushing towards massively distributed computation, the collectionless approach to AI will likely reduce the concentration of power in companies and governments, thus better facing geopolitical issues.
</details>
<details>
<summary>摘要</summary>
（以下是简化中文版本）通常来说，职业处理巨大数据集是机器学习进步和相关领域的基本组成部分，并且有一致的看法是中央化数据集的风险。这篇文章支持新的学习协议，即机器在人类化上下文中 conquering 认知能力，并且采用时间约束，不允许机器记录时间流。这种极端位置的目的是促进机器学习动态组织信息，按照人类方式，而不是依靠存储来模拟传统学习算法的动力学。这种挑战的提议是开发新的学习和理解过程的计算基础，以解决隐私、控制和个性化等问题。最后，通过分布式计算，集中化的问题将减少，从而更好地面对地opolitical 问题。
</details></li>
</ul>
<hr>
<h2 id="Continual-Learning-with-Dirichlet-Generative-based-Rehearsal"><a href="#Continual-Learning-with-Dirichlet-Generative-based-Rehearsal" class="headerlink" title="Continual Learning with Dirichlet Generative-based Rehearsal"></a>Continual Learning with Dirichlet Generative-based Rehearsal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06917">http://arxiv.org/abs/2309.06917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Zeng, Wei Xue, Qifeng Liu, Yike Guo</li>
<li>for: 提高数据驱动任务异常对话系统（ToDs）的不断学习能力，解决由计算约束和时间消耗引起的问题。</li>
<li>methods:  Dirichlet Continual Learning（DCL），一种基于生成的再学习策略，使用 Dirichlet 分布来模型 latent 变量，fficiently 捕捉上一个任务的句子特征，并准确地生成 pseudo 样本。 In addition, 我们引入 Jensen-Shannon Knowledge Distillation（JSKD），一种可靠的 logit-based 知识传递方法，在 pseudo 样本生成过程中增强知识传递。</li>
<li>results: 我们的方法在意图检测和填充任务中表现出色，超越了现有的方法。<details>
<summary>Abstract</summary>
Recent advancements in data-driven task-oriented dialogue systems (ToDs) struggle with incremental learning due to computational constraints and time-consuming issues. Continual Learning (CL) attempts to solve this by avoiding intensive pre-training, but it faces the problem of catastrophic forgetting (CF). While generative-based rehearsal CL methods have made significant strides, generating pseudo samples that accurately reflect the underlying task-specific distribution is still a challenge. In this paper, we present Dirichlet Continual Learning (DCL), a novel generative-based rehearsal strategy for CL. Unlike the traditionally used Gaussian latent variable in the Conditional Variational Autoencoder (CVAE), DCL leverages the flexibility and versatility of the Dirichlet distribution to model the latent prior variable. This enables it to efficiently capture sentence-level features of previous tasks and effectively guide the generation of pseudo samples. In addition, we introduce Jensen-Shannon Knowledge Distillation (JSKD), a robust logit-based knowledge distillation method that enhances knowledge transfer during pseudo sample generation. Our experiments confirm the efficacy of our approach in both intent detection and slot-filling tasks, outperforming state-of-the-art methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-the-TopMost-A-Topic-Modeling-System-Toolkit"><a href="#Towards-the-TopMost-A-Topic-Modeling-System-Toolkit" class="headerlink" title="Towards the TopMost: A Topic Modeling System Toolkit"></a>Towards the TopMost: A Topic Modeling System Toolkit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06908">http://arxiv.org/abs/2309.06908</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bobxwu/topmost">https://github.com/bobxwu/topmost</a></li>
<li>paper_authors: Xiaobao Wu, Fengjun Pan, Anh Tuan Luu</li>
<li>For: 提供了一个包含完整生命周期的主题模型工具套件（TopMost），以便快速使用、公正比较和扩展不同的主题模型。* Methods:  TopMost 采用了高度协调和分离的模块化设计，可以快速使用、公正比较和扩展不同的主题模型。* Results: TopMost 可以覆盖更广泛的主题模型enario，包括资料预处理、模型训练、测试和评估等完整生命周期。In English, this means:* For: The paper proposes a Topic Modeling System Toolkit (TopMost) that provides a comprehensive set of tools for topic modeling, including dataset pre-processing, model training, testing, and evaluations.* Methods: TopMost uses a highly cohesive and decoupled modular design, allowing for quick use, fair comparisons, and flexible extensions of different topic models.* Results: TopMost can cover a wider range of topic modeling scenarios, including complete lifecycles with dataset pre-processing, model training, testing, and evaluations.<details>
<summary>Abstract</summary>
Topic models have been proposed for decades with various applications and recently refreshed by the neural variational inference. However, these topic models adopt totally distinct dataset, implementation, and evaluation settings, which hinders their quick utilization and fair comparisons. This greatly hinders the research progress of topic models. To address these issues, in this paper we propose a Topic Modeling System Toolkit (TopMost). Compared to existing toolkits, TopMost stands out by covering a wider range of topic modeling scenarios including complete lifecycles with dataset pre-processing, model training, testing, and evaluations. The highly cohesive and decoupled modular design of TopMost enables quick utilization, fair comparisons, and flexible extensions of different topic models. This can facilitate the research and applications of topic models. Our code, tutorials, and documentation are available at https://github.com/bobxwu/topmost.
</details>
<details>
<summary>摘要</summary>
Topic models have been proposed for decades with various applications, and recently have been refreshed by neural variational inference. However, these topic models use completely different datasets, implementations, and evaluation settings, which greatly hinders their quick utilization and fair comparisons. This hinders the research progress of topic models. To address these issues, in this paper we propose a Topic Modeling System Toolkit (TopMost). Compared to existing toolkits, TopMost covers a wider range of topic modeling scenarios, including complete lifecycles with dataset pre-processing, model training, testing, and evaluations. The highly cohesive and decoupled modular design of TopMost enables quick utilization, fair comparisons, and flexible extensions of different topic models. This can facilitate the research and applications of topic models. Our code, tutorials, and documentation are available at https://github.com/bobxwu/topmost.Here's the word-for-word translation:Topic models已经提出了数十年，具有各种应用，最近又被变量推理重新启发。然而，这些主题模型使用完全不同的数据集、实现和评估设置，这会大大阻碍它们的快速使用和公正比较。这阻碍了主题模型的研究进步。为了解决这些问题，在这篇论文中，我们提出了一个主题模型系统工具集（TopMost）。相比之下，现有的工具集，TopMost覆盖了更广泛的主题模型enario，包括完整的生命周期，从数据预处理、模型训练、测试、评估等方面。TopMost的高度凝结和分离的模块化设计，使得快速使用、公正比较和扩展不同的主题模型变得更加容易。这可以促进主题模型的研究和应用。我们的代码、教程和文档可以在https://github.com/bobxwu/topmost中找到。
</details></li>
</ul>
<hr>
<h2 id="OWL-Reasoners-still-useable-in-2023"><a href="#OWL-Reasoners-still-useable-in-2023" class="headerlink" title="OWL Reasoners still useable in 2023"></a>OWL Reasoners still useable in 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06888">http://arxiv.org/abs/2309.06888</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/k00ni/owl-reasoner-list">https://github.com/k00ni/owl-reasoner-list</a></li>
<li>paper_authors: Konrad Abicht</li>
<li>for: 这篇论文的目的是对OWL理解器进行系统性的文献和软件综述，以确定它们在2023年是否仍然可用。</li>
<li>methods: 本论文使用了对100个OWL理解器&#x2F;系统的分析，以及对每个item的项目页面、源代码仓库和相关文档的收集。</li>
<li>results: 研究得到了95个独立的OWL理解器和使用OWL理解器的系统，并提供了相关的原始研究数据，以便任何人使用。<details>
<summary>Abstract</summary>
In a systematic literature and software review over 100 OWL reasoners/systems were analyzed to see if they would still be usable in 2023. This has never been done in this capacity. OWL reasoners still play an important role in knowledge organisation and management, but the last comprehensive surveys/studies are more than 8 years old. The result of this work is a comprehensive list of 95 standalone OWL reasoners and systems using an OWL reasoner. For each item, information on project pages, source code repositories and related documentation was gathered. The raw research data is provided in a Github repository for anyone to use.
</details>
<details>
<summary>摘要</summary>
在一项系统性的文献和软件综述中，对超过100个OWL理解器/系统进行了分析，以确定它们在2023年仍然可以使用。这是历史上没有done before。OWL理解器仍然在知识组织和管理中发挥着重要作用，但最后一次全面的调查/研究已经超过8年了。这项工作的结果是一份包含95个独立OWL理解器和使用OWL理解器的系统的完整列表。对每个项目，我们收集了项目页面、源代码存储库和相关文档的信息。 raw research data 被提供到GitHub存储库中，任何人都可以使用。
</details></li>
</ul>
<hr>
<h2 id="Gpachov-at-CheckThat-2023-A-Diverse-Multi-Approach-Ensemble-for-Subjectivity-Detection-in-News-Articles"><a href="#Gpachov-at-CheckThat-2023-A-Diverse-Multi-Approach-Ensemble-for-Subjectivity-Detection-in-News-Articles" class="headerlink" title="Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles"></a>Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06844">http://arxiv.org/abs/2309.06844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgi Pachov, Dimitar Dimitrov, Ivan Koychev, Preslav Nakov</li>
<li>for: 本研究旨在提高社交媒体上的信息对象性和质量，通过对话检测技术来检测信息的主观性。</li>
<li>methods: 本研究使用了三种不同的研究方向：一是基于精度调整的句子嵌入模型和维度减少；二是使用一种具有几种语言的多语言变换器，在修改后的数据集上进行了训练；三是使用一种几何学上的简单多数投票算法，将三种方法进行简单的加权投票。</li>
<li>results: 本研究在CheckThat! lab Task~2的测试集上取得了0.77宏F1的成绩，在英语子任务上位列第二名。<details>
<summary>Abstract</summary>
The wide-spread use of social networks has given rise to subjective, misleading, and even false information on the Internet. Thus, subjectivity detection can play an important role in ensuring the objectiveness and the quality of a piece of information. This paper presents the solution built by the Gpachov team for the CLEF-2023 CheckThat! lab Task~2 on subjectivity detection. Three different research directions are explored. The first one is based on fine-tuning a sentence embeddings encoder model and dimensionality reduction. The second one explores a sample-efficient few-shot learning model. The third one evaluates fine-tuning a multilingual transformer on an altered dataset, using data from multiple languages. Finally, the three approaches are combined in a simple majority voting ensemble, resulting in 0.77 macro F1 on the test set and achieving 2nd place on the English subtask.
</details>
<details>
<summary>摘要</summary>
因为社交媒体的广泛使用，互联网上的信息中有很多主观、误导和False信息。因此，主观检测可以为确保信息的 объекivity 和质量做出重要的贡献。这篇文章介绍了Gpachov 团队为 CLEF-2023 CheckThat! 实验室任务2的主观检测解决方案。文章 explore 了三个不同的研究方向：一是基于精细调整句子嵌入模型和维度减少；二是探索一种高效的少量样本学习模型；三是使用多种语言的多语言 transformer 模型在修改后的数据集上进行了调整。最后，这三种方法被组合成了简单的多数投票ensemble，在测试集上获得了0.77宏折衔率，并在英语子任务上获得了第二名。
</details></li>
</ul>
<hr>
<h2 id="On-the-Local-Quadratic-Stability-of-T-S-Fuzzy-Systems-in-the-Vicinity-of-the-Origin"><a href="#On-the-Local-Quadratic-Stability-of-T-S-Fuzzy-Systems-in-the-Vicinity-of-the-Origin" class="headerlink" title="On the Local Quadratic Stability of T-S Fuzzy Systems in the Vicinity of the Origin"></a>On the Local Quadratic Stability of T-S Fuzzy Systems in the Vicinity of the Origin</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06841">http://arxiv.org/abs/2309.06841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Donghwan Lee, Do Wan Kim</li>
<li>for: 这篇论文旨在提出新的连续时间 Takagi-Sugeno（T-S）朴素系统的本地稳定条件。</li>
<li>methods: 这些稳定条件基于线性矩阵不等式（LMIs），并利用quadratic Lyapunov函数。这些条件能够充分利用Underlying nonlinear系统的线性结构，并且在起点处提供信息。</li>
<li>results: 提出的条件比现有的杂化Lyapunov函数方法更为不保守，并且 prove to be necessary and sufficient conditions for the local exponential stability of T-S fuzzy systems.<details>
<summary>Abstract</summary>
The main goal of this paper is to introduce new local stability conditions for continuous-time Takagi-Sugeno (T-S) fuzzy systems. These stability conditions are based on linear matrix inequalities (LMIs) in combination with quadratic Lyapunov functions. Moreover, they integrate information on the membership functions at the origin and effectively leverage the linear structure of the underlying nonlinear system in the vicinity of the origin. As a result, the proposed conditions are proved to be less conservative compared to existing methods using fuzzy Lyapunov functions in the literature. Moreover, we establish that the proposed methods offer necessary and sufficient conditions for the local exponential stability of T-S fuzzy systems. The paper also includes discussions on the inherent limitations associated with fuzzy Lyapunov approaches. To demonstrate the theoretical results, we provide comprehensive examples that elucidate the core concepts and validate the efficacy of the proposed conditions.
</details>
<details>
<summary>摘要</summary>
本文的主要目标是介绍新的连续时间高aki-Sugeno（T-S）混合系统的本地稳定条件。这些稳定条件基于线性矩阵不等式（LMIs），并与 quadratic Lyapunov 函数相结合。此外，它们还利用了非线性系统的原点附近的线性结构，并且考虑了 membership 函数的原点信息。因此，提出的条件比现有的使用混合Lyapunov函数的方法更加不保守。此外，我们证明了该方法对 T-S 混合系统的本地 экспоненциаль稳定是必要和充分的。文章还探讨了混合Lyapunov 方法的内在限制。为validate the theoretical results, we provide comprehensive examples that illustrate the key concepts and demonstrate the effectiveness of the proposed conditions.Note: "高aki-Sugeno" is the Simplified Chinese term for "Takagi-Sugeno".
</details></li>
</ul>
<hr>
<h2 id="SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation"><a href="#SAMUS-Adapting-Segment-Anything-Model-for-Clinically-Friendly-and-Generalizable-Ultrasound-Image-Segmentation" class="headerlink" title="SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation"></a>SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06824">http://arxiv.org/abs/2309.06824</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xianlin7/samus">https://github.com/xianlin7/samus</a></li>
<li>paper_authors: Xian Lin, Yangyang Xiang, Li Zhang, Xin Yang, Zengqiang Yan, Li Yu</li>
<li>for: 这篇论文是为了提出一种适用于ultrasound图像分割的通用模型（SAMUS），以提高现有基础模型（SAM）在医疗图像分割 task 的表现。</li>
<li>methods: 该模型基于 SAM 的基础，增加了一个平行 CNN 分支，通过交叉分支注意力来注入本地特征到 ViT 编码器，以提高医疗图像分割的表现。此外，还开发了位置适配器和特征适配器，以适应 SAM 的医疗图像分割 task 和小型输入 (256x256) 的要求。</li>
<li>results: 对比评测表明，SAMUS 在任务特定模型和基础模型下都具有显著优势，并且可以在入门级 GPU 上部署。code、数据和模型将在 GitHub 上发布。<details>
<summary>Abstract</summary>
Segment anything model (SAM), an eminent universal image segmentation model, has recently gathered considerable attention within the domain of medical image segmentation. Despite the remarkable performance of SAM on natural images, it grapples with significant performance degradation and limited generalization when confronted with medical images, particularly with those involving objects of low contrast, faint boundaries, intricate shapes, and diminutive sizes. In this paper, we propose SAMUS, a universal model tailored for ultrasound image segmentation. In contrast to previous SAM-based universal models, SAMUS pursues not only better generalization but also lower deployment cost, rendering it more suitable for clinical applications. Specifically, based on SAM, a parallel CNN branch is introduced to inject local features into the ViT encoder through cross-branch attention for better medical image segmentation. Then, a position adapter and a feature adapter are developed to adapt SAM from natural to medical domains and from requiring large-size inputs (1024x1024) to small-size inputs (256x256) for more clinical-friendly deployment. A comprehensive ultrasound dataset, comprising about 30k images and 69k masks and covering six object categories, is collected for verification. Extensive comparison experiments demonstrate SAMUS's superiority against the state-of-the-art task-specific models and universal foundation models under both task-specific evaluation and generalization evaluation. Moreover, SAMUS is deployable on entry-level GPUs, as it has been liberated from the constraints of long sequence encoding. The code, data, and models will be released at https://github.com/xianlin7/SAMUS.
</details>
<details>
<summary>摘要</summary>
segments anything model (SAM)，一种受欢迎的通用图像分割模型，在医疗图像分割领域已经吸引了广泛的关注。尽管SAM在自然图像上表现出色，但在医疗图像上却面临较大的性能下降和限制，特别是对于低对比度、柔和的边界、复杂形态和小型对象的分割。在本文中，我们提出了SAMUS，一种适用于ultrasound图像分割的通用模型。与前一代基于SAM的通用模型不同，SAMUS不仅增加了更好的泛化性，还减少了部署成本，使其更适合临床应用。具体来说，基于SAM，我们在ViT编码器中引入了并行的CNN分支，通过交叉分支注意力注入本地特征，以改进医疗图像分割。然后，我们开发了位置适应器和特征适应器，以适应SAM从自然到医疗领域的转换，并从需要大型输入（1024x1024）降低到小型输入（256x256），以便更加临床友好的部署。我们收集了一个涵盖6类对象的完整ultrasound数据集，包括约30k张图像和69k个Mask，并进行了广泛的比较试验。结果表明SAMUS在比较当今任务特定模型和基础模型下显示出优异性，同时也可以在泛化评价中达到优秀的表现。此外，SAMUS可以在入门级GPU上部署，因为它已经脱离了长序编码的限制。代码、数据和模型将在https://github.com/xianlin7/SAMUS上公开。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-Contextual-Relation-Extraction-based-on-Deep-Learning-Models"><a href="#Comparative-Analysis-of-Contextual-Relation-Extraction-based-on-Deep-Learning-Models" class="headerlink" title="Comparative Analysis of Contextual Relation Extraction based on Deep Learning Models"></a>Comparative Analysis of Contextual Relation Extraction based on Deep Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06814">http://arxiv.org/abs/2309.06814</a></li>
<li>repo_url: None</li>
<li>paper_authors: R. Priyadharshini, G. Jeyakodi, P. Shanthi Bala</li>
<li>for: 本研究旨在构建域知 graph，使用 Ontology 进行 semantic search、query answering 和 textual entailment。</li>
<li>methods: 本文使用深度学习技术来提取复杂关系，解决现有机器学习和自然语言处理技术无法高效地预测多个关系和未特定实体的问题。</li>
<li>results: 本研究表明，hybrid deep learning 模型可以有效地提取复杂句子中的关系，并且可以解决现有机器学习模型无法预测多个关系的问题。<details>
<summary>Abstract</summary>
Contextual Relation Extraction (CRE) is mainly used for constructing a knowledge graph with a help of ontology. It performs various tasks such as semantic search, query answering, and textual entailment. Relation extraction identifies the entities from raw texts and the relations among them. An efficient and accurate CRE system is essential for creating domain knowledge in the biomedical industry. Existing Machine Learning and Natural Language Processing (NLP) techniques are not suitable to predict complex relations from sentences that consist of more than two relations and unspecified entities efficiently. In this work, deep learning techniques have been used to identify the appropriate semantic relation based on the context from multiple sentences. Even though various machine learning models have been used for relation extraction, they provide better results only for binary relations, i.e., relations occurred exactly between the two entities in a sentence. Machine learning models are not suited for complex sentences that consist of the words that have various meanings. To address these issues, hybrid deep learning models have been used to extract the relations from complex sentence effectively. This paper explores the analysis of various deep learning models that are used for relation extraction.
</details>
<details>
<summary>摘要</summary>
Contextual Relation Extraction (CRE) 主要用于构建知识图库，帮助了 Ontology。它执行多种任务，如semantic search、查询回答和文本推理。relation extraction 可以从 raw text 中提取实体和关系。一个有效和准确的 CRE 系统对生物医学领域的Domain Knowledge 创造至关重要。现有的机器学习和自然语言处理（NLP）技术不适用于从多个句子中提取复杂关系。在这种情况下，深度学习技术被使用，以基于上下文从多个句子中提取适当的semantic关系。尽管许多机器学习模型已经用于relation extraction，但它们只能提供二分关系（即sentence中两个实体之间的关系）的更好结果。机器学习模型不适用于含有多义词的复杂句子。为解决这些问题，hybrid深度学习模型被用来从复杂句子中提取关系。本文探讨了不同的深度学习模型在relation extraction中的分析。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-SE-3-Equivariance-for-Learning-3D-Geometric-Shape-Assembly"><a href="#Leveraging-SE-3-Equivariance-for-Learning-3D-Geometric-Shape-Assembly" class="headerlink" title="Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly"></a>Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06810">http://arxiv.org/abs/2309.06810</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/crtie/leveraging-se-3-equivariance-for-learning-3d-geometric-shape-assembly">https://github.com/crtie/leveraging-se-3-equivariance-for-learning-3d-geometric-shape-assembly</a></li>
<li>paper_authors: Ruihai Wu, Chenrui Tie, Yushi Du, Yan Zhao, Hao Dong</li>
<li>for: 本研究目的是解决受损物体重新组装问题，即在计算机视觉和机器人领域中的一个新兴任务。不同于传统的semantic部件组装（例如将 chair的Semantic部件如脚部组装成整个椅子），这个任务更关注几何信息，而不是semantic信息。</li>
<li>methods: 我们提出了利用SE(3)对称性来实现几何 pose 分解的方法。而在之前的视觉和机器人研究中，只考虑单个物体表示的SE(3)对称性，我们则是在考虑多部件相互关系的情况下提出了利用SE(3)对称性的方法，这有助于提高多部件组装的性能。</li>
<li>results: 实验结果表明，SE(3)对称性和我们提出的方法对几何形态组装具有重要作用。这些结果表明，在多部件组装任务中，利用SE(3)对称性可以提高组装精度和效率。项目页面：<a target="_blank" rel="noopener" href="https://crtie.github.io/SE-3-part-assembly/">https://crtie.github.io/SE-3-part-assembly/</a><details>
<summary>Abstract</summary>
Shape assembly aims to reassemble parts (or fragments) into a complete object, which is a common task in our daily life. Different from the semantic part assembly (e.g., assembling a chair's semantic parts like legs into a whole chair), geometric part assembly (e.g., assembling bowl fragments into a complete bowl) is an emerging task in computer vision and robotics. Instead of semantic information, this task focuses on geometric information of parts. As the both geometric and pose space of fractured parts are exceptionally large, shape pose disentanglement of part representations is beneficial to geometric shape assembly. In our paper, we propose to leverage SE(3) equivariance for such shape pose disentanglement. Moreover, while previous works in vision and robotics only consider SE(3) equivariance for the representations of single objects, we move a step forward and propose leveraging SE(3) equivariance for representations considering multi-part correlations, which further boosts the performance of the multi-part assembly. Experiments demonstrate the significance of SE(3) equivariance and our proposed method for geometric shape assembly. Project page: https://crtie.github.io/SE-3-part-assembly/
</details>
<details>
<summary>摘要</summary>
Shape assembly aims to reassemble parts (or fragments) into a complete object, which is a common task in our daily life. Different from the semantic part assembly (e.g., assembling a chair's semantic parts like legs into a whole chair), geometric part assembly (e.g., assembling bowl fragments into a complete bowl) is an emerging task in computer vision and robotics. Instead of semantic information, this task focuses on geometric information of parts. As the both geometric and pose space of fractured parts are exceptionally large, shape pose disentanglement of part representations is beneficial to geometric shape assembly. In our paper, we propose to leverage SE(3) equivariance for such shape pose disentanglement. Moreover, while previous works in vision and robotics only consider SE(3) equivariance for the representations of single objects, we move a step forward and propose leveraging SE(3) equivariance for representations considering multi-part correlations, which further boosts the performance of the multi-part assembly. Experiments demonstrate the significance of SE(3) equivariance and our proposed method for geometric shape assembly. Project page: <https://crtie.github.io/SE-3-part-assembly/>.
</details></li>
</ul>
<hr>
<h2 id="Bayesian-uncertainty-weighted-loss-for-improved-generalisability-on-polyp-segmentation-task"><a href="#Bayesian-uncertainty-weighted-loss-for-improved-generalisability-on-polyp-segmentation-task" class="headerlink" title="Bayesian uncertainty-weighted loss for improved generalisability on polyp segmentation task"></a>Bayesian uncertainty-weighted loss for improved generalisability on polyp segmentation task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06807">http://arxiv.org/abs/2309.06807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rebecca S. Stone, Pedro E. Chavarrias-Solano, Andrew J. Bulpitt, David C. Hogg, Sharib Ali</li>
<li>for: 这 paper 的目的是为了提高肿瘤分类的一致性，减少因为不同中心或受测器等因素而导致的模型偏见。</li>
<li>methods: 这 paper 使用了一种基于 Bayesian 的 epistemic uncertainty 来降低模型内在偏见，以提高模型对不同中心和受测器等不寻常数据的一致性。</li>
<li>results: 这 paper 在一个具有多中心和多数据模式的肿瘤分类数据集（PolypGen）上进行了评估，结果显示这种方法可以提高模型的一致性无需损失现有的表现水准。<details>
<summary>Abstract</summary>
While several previous studies have devised methods for segmentation of polyps, most of these methods are not rigorously assessed on multi-center datasets. Variability due to appearance of polyps from one center to another, difference in endoscopic instrument grades, and acquisition quality result in methods with good performance on in-distribution test data, and poor performance on out-of-distribution or underrepresented samples. Unfair models have serious implications and pose a critical challenge to clinical applications. We adapt an implicit bias mitigation method which leverages Bayesian epistemic uncertainties during training to encourage the model to focus on underrepresented sample regions. We demonstrate the potential of this approach to improve generalisability without sacrificing state-of-the-art performance on a challenging multi-center polyp segmentation dataset (PolypGen) with different centers and image modalities.
</details>
<details>
<summary>摘要</summary>
Previous studies have proposed various methods for segmenting polyps, but most of these methods have not been rigorously evaluated on multi-center datasets. The differences in the appearance of polyps between centers, the grades of endoscopic instruments, and the variations in image acquisition quality can lead to models with good performance on in-distribution test data but poor performance on out-of-distribution or underrepresented samples. This can have serious implications for clinical applications. We have adapted an approach to mitigate implicit bias by leveraging Bayesian epistemic uncertainties during training to encourage the model to focus on underrepresented sample regions. We demonstrate the potential of this approach to improve generalizability without sacrificing state-of-the-art performance on a challenging multi-center polyp segmentation dataset (PolypGen) with different centers and image modalities.Here's the word-for-word translation of the text into Simplified Chinese:先前的研究已经提出了多种方法来分割肿体，但大多数这些方法没有在多中心数据集上进行了审核。不同的中心所出现的肿体的外观、endoскоpic工具的级别和图像获取的质量变化会导致模型在不同的测试数据上表现出色，但对于少数或下 represents 的样本表现差。这会对临床应用造成严重的问题。我们采用了一种避免偏见的方法，通过在训练时使用泛化不确定性来强制模型关注下 represents 的样本区域。我们在一个多中心肿体分割数据集（PolypGen）上示出了这种方法的潜在改进性，不 sacrifice 先进的性能。
</details></li>
</ul>
<hr>
<h2 id="FedDIP-Federated-Learning-with-Extreme-Dynamic-Pruning-and-Incremental-Regularization"><a href="#FedDIP-Federated-Learning-with-Extreme-Dynamic-Pruning-and-Incremental-Regularization" class="headerlink" title="FedDIP: Federated Learning with Extreme Dynamic Pruning and Incremental Regularization"></a>FedDIP: Federated Learning with Extreme Dynamic Pruning and Incremental Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06805">http://arxiv.org/abs/2309.06805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ericloong/feddip">https://github.com/ericloong/feddip</a></li>
<li>paper_authors: Qianyu Long, Christos Anagnostopoulos, Shameem Puthiya Parambath, Daning Bi</li>
<li>for: 这篇论文旨在提出一个新的联合式学习（Federated Learning）框架，以确保在分布式训练和推断大规模深度学习网络（DNNs）中，能够有效地控制模型的缩减和储存。</li>
<li>methods: 这篇论文使用了动态模型删除和错误反馈来删除无用的信息交换，并且运用了增量调整来实现极端简化的模型。</li>
<li>results: 论文的结果显示，FedDIP可以不仅控制模型的缩减，而且能够实现和其他模型删除方法相似或更好的性能。<details>
<summary>Abstract</summary>
Federated Learning (FL) has been successfully adopted for distributed training and inference of large-scale Deep Neural Networks (DNNs). However, DNNs are characterized by an extremely large number of parameters, thus, yielding significant challenges in exchanging these parameters among distributed nodes and managing the memory. Although recent DNN compression methods (e.g., sparsification, pruning) tackle such challenges, they do not holistically consider an adaptively controlled reduction of parameter exchange while maintaining high accuracy levels. We, therefore, contribute with a novel FL framework (coined FedDIP), which combines (i) dynamic model pruning with error feedback to eliminate redundant information exchange, which contributes to significant performance improvement, with (ii) incremental regularization that can achieve \textit{extreme} sparsity of models. We provide convergence analysis of FedDIP and report on a comprehensive performance and comparative assessment against state-of-the-art methods using benchmark data sets and DNN models. Our results showcase that FedDIP not only controls the model sparsity but efficiently achieves similar or better performance compared to other model pruning methods adopting incremental regularization during distributed model training. The code is available at: https://github.com/EricLoong/feddip.
</details>
<details>
<summary>摘要</summary>
联合学习（Federated Learning，FL）已经成功地应用于分布式训练和推导大规模深度神经网络（Deep Neural Networks，DNNs）。然而，DNNs 具有极高的参数数量，因此在分布式节点之间交换这些参数具有很大的挑战。 although recent DNN compression methods (e.g., sparsification, pruning) 可以解决这些挑战，但它们不会全面考虑适当地控制参数交换的减少，以维持高精度水平。我们因此提出了一个新的 FL 框架（称为 FedDIP），它结合了（i）动态模型剔除与错误反馈，以消除重复的资讯交换，从而获得了显著的性能改善，以及（ii）增量调整，可以实现极端简化的模型。我们提供了 FedDIP 的凝聚分析和比较性评估，使用了标准的 benchmark 数据集和 DNN 模型。我们的结果显示，FedDIP 不仅可以控制模型的简化，而且可以实现类似或更好的性能，与其他适用增量调整的模型剔除方法相比。代码可以在：https://github.com/EricLoong/feddip 中找到。
</details></li>
</ul>
<hr>
<h2 id="Defensive-Alliances-in-Signed-Networks"><a href="#Defensive-Alliances-in-Signed-Networks" class="headerlink" title="Defensive Alliances in Signed Networks"></a>Defensive Alliances in Signed Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06801">http://arxiv.org/abs/2309.06801</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emmanuel Arrighi, Zhidan Feng, Henning Fernau, Kevin Mann, Xingqin Qi, Petra Wolf</li>
<li>for: 本研究旨在找到一个集合 agents可以共同实现一个目标。</li>
<li>methods: 本研究使用 signed networks 模型 liking 和 disliking 间的agent，并提出了一种新的defensive alliance 概念。</li>
<li>results: 研究回答了一些自然的算法问题，以及一些 combinatorial 发现，connect our notion to correlation clustering 和 signed neighborhood diversity snd。还提出了一种 parameterized algorithm 来找到一个最小的defensive alliance。<details>
<summary>Abstract</summary>
The analysis of (social) networks and multi-agent systems is a central theme in Artificial Intelligence. Some line of research deals with finding groups of agents that could work together to achieve a certain goal. To this end, different notions of so-called clusters or communities have been introduced in the literature of graphs and networks. Among these, defensive alliance is a kind of quantitative group structure. However, all studies on the alliance so for have ignored one aspect that is central to the formation of alliances on a very intuitive level, assuming that the agents are preconditioned concerning their attitude towards other agents: they prefer to be in some group (alliance) together with the agents they like, so that they are happy to help each other towards their common aim, possibly then working against the agents outside of their group that they dislike. Signed networks were introduced in the psychology literature to model liking and disliking between agents, generalizing graphs in a natural way. Hence, we propose the novel notion of a defensive alliance in the context of signed networks. We then investigate several natural algorithmic questions related to this notion. These, and also combinatorial findings, connect our notion to that of correlation clustering, which is a well-established idea of finding groups of agents within a signed network. Also, we introduce a new structural parameter for signed graphs, signed neighborhood diversity snd, and exhibit a parameterized algorithm that finds a smallest defensive alliance in a signed graph.
</details>
<details>
<summary>摘要</summary>
social networks 和多代理系统的分析是人工智能的中心主题。一些研究的目标是找到一些代理工作 вместе以实现某个目标。为此，图和网络的不同的定义叫做集群或社区在文献中出现。其中，防御联盟是一种量化的群体结构。然而，所有关于联盟的研究都忽略了一个非常直观的因素：代理在与其他代理之间有互恩的情感，因此偏好与自己喜欢的代理一起组成一个群体，以便帮助彼此实现共同目标，可能然后与外部的代理进行冲突。 signed networks 是在心理学文献中引入的，以模型代理之间的喜欢和讨厌关系，自然地扩展了图的概念。因此，我们提出了在 signed networks 上的新的防御联盟概念。我们然后调查了这个概念相关的自然的算法问题，以及 combinatorial 发现。这些问题与另一个已知的idea——相关均衡 clustering——相连。此外，我们引入了一个新的 signed 图结构参数，signed neighborhood diversity snd，并提供了一个 parameterized 算法，用于在 signed 图上找到最小的防御联盟。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-aware-Traffic-Prediction-under-Missing-Data"><a href="#Uncertainty-aware-Traffic-Prediction-under-Missing-Data" class="headerlink" title="Uncertainty-aware Traffic Prediction under Missing Data"></a>Uncertainty-aware Traffic Prediction under Missing Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06800">http://arxiv.org/abs/2309.06800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Mei, Junxian Li, Zhiming Liang, Guanjie Zheng, Bin Shi, Hua Wei</li>
<li>for: 这 paper 是为了解决 traffic prediction 中的一个重要问题，即如何在缺失历史记录的位置上进行预测。</li>
<li>methods: 这 paper 使用了一种基于 inductive graph neural network 的 uncertainty-aware 框架，可以1) 将预测扩展到缺失历史记录的位置，并2) 生成可预测性的预测结果，同时Quantify the uncertainty of the prediction results.</li>
<li>results: 经过广泛的实验 validate 了这 paper 的方法，可以在 real-life 数据上达到了良好的预测结果，并且uncertainty quantification 的结果与历史数据和无历史数据的位置之间呈高度相关性。此外，这 paper 还展示了其方法可以帮助交通部门在限定的投入下选择合适的感知器，以提高预测结果的准确性。<details>
<summary>Abstract</summary>
Traffic prediction is a crucial topic because of its broad scope of applications in the transportation domain. Recently, various studies have achieved promising results. However, most studies assume the prediction locations have complete or at least partial historical records and cannot be extended to non-historical recorded locations. In real-life scenarios, the deployment of sensors could be limited due to budget limitations and installation availability, which makes most current models not applicable. Though few pieces of literature tried to impute traffic states at the missing locations, these methods need the data simultaneously observed at the locations with sensors, making them not applicable to prediction tasks. Another drawback is the lack of measurement of uncertainty in prediction, making prior works unsuitable for risk-sensitive tasks or involving decision-making. To fill the gap, inspired by the previous inductive graph neural network, this work proposed an uncertainty-aware framework with the ability to 1) extend prediction to missing locations with no historical records and significantly extend spatial coverage of prediction locations while reducing deployment of sensors and 2) generate probabilistic prediction with uncertainty quantification to help the management of risk and decision making in the down-stream tasks. Through extensive experiments on real-life datasets, the result shows our method achieved promising results on prediction tasks, and the uncertainty quantification gives consistent results which highly correlated with the locations with and without historical data. We also show that our model could help support sensor deployment tasks in the transportation field to achieve higher accuracy with a limited sensor deployment budget.
</details>
<details>
<summary>摘要</summary>
traffic prediction 是一个重要的话题，因为它在交通领域有广泛的应用。在最近的研究中，许多研究已经获得了有前途的结果。然而，大多数研究假设预测位置有完整或至少部分的历史记录，并不能扩展到无历史记录的位置。在实际的场景中，投入设备的限制和安装可用性可能会限制投入设备的数量，使现有的模型无法适用。虽然一些文献尝试了填充交通状态的缺失位置，但这些方法需要同时观测的数据在投入设备上，使得它们无法适用于预测任务。另外，现有的方法缺乏测量预测结果的不确定性，使得前一代的研究不适用于风险敏感任务或决策任务。为了填补这个空白，我们提出了一种不确定性意识框架，能够1）扩展预测至缺失位置，大幅减少投入设备数量，同时提高预测精度，2）生成probabilistic预测，并对预测结果进行不确定性评估，以帮助管理风险和决策任务。经过广泛的实验研究，我们的方法在预测任务中获得了优秀的结果，并且不确定性评估与位置有 historia record 的相关性很高。我们还证明了我们的模型可以帮助交通领域中的投入设备部署任务实现更高的准确率，使用有限的投入设备预算。
</details></li>
</ul>
<hr>
<h2 id="When-Geoscience-Meets-Foundation-Models-Towards-General-Geoscience-Artificial-Intelligence-System"><a href="#When-Geoscience-Meets-Foundation-Models-Towards-General-Geoscience-Artificial-Intelligence-System" class="headerlink" title="When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System"></a>When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06799">http://arxiv.org/abs/2309.06799</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhang, Jin-Jian Xu</li>
<li>for: 这篇论文旨在探讨地球系统的动态模型，以探索地球系统的演化和发展。</li>
<li>methods: 这篇论文使用了跨学科数据集合来模拟地球系统的动态，并使用人工智能技术来探索这些数据的关系。</li>
<li>results: 这篇论文获得了一些关于地球系统的预测和模拟结果，并提供了一些关于地球系统的未来发展的探访。<details>
<summary>Abstract</summary>
Geoscience foundation models represent a revolutionary approach in the field of Earth sciences by integrating massive cross-disciplinary data to simulate and understand the Earth systems dynamics. As a data-centric artificial intelligence (AI) paradigm, they uncover insights from petabytes of structured and unstructured data. Flexible task specification, diverse inputs and outputs and multi-modal knowledge representation enable comprehensive analysis infeasible with individual data sources. Critically, the scalability and generalizability of geoscience models allow for tackling diverse prediction, simulation, and decision challenges related to Earth systems interactions. Collaboration between domain experts and computer scientists leads to innovations in these invaluable tools for understanding the past, present, and future of our planet. However, challenges remain in validation and verification, scale, interpretability, knowledge representation, and social bias. Going forward, enhancing model integration, resolution, accuracy, and equity through cross-disciplinary teamwork is key. Despite current limitations, geoscience foundation models show promise for providing critical insights into pressing issues including climate change, natural hazards, and sustainability through their ability to probe scenarios and quantify uncertainties. Their continued evolution toward integrated, data-driven modeling holds paradigm-shifting potential for Earth science.
</details>
<details>
<summary>摘要</summary>
地球科学基础模型代表了地球科学领域的一种革命性的方法，通过融合各个领务的大量交叉学科数据来模拟和理解地球系统的动态。作为一种数据驱动人工智能（AI）范例，它们揭示了数据中的新发现，从 petabytes 的结构化和无结构化数据中提取了有价值的信息。灵活的任务规定、多样化的输入和输出以及多Modal 的知识表示使得全面的分析变得可能，而各个数据源之间的集成分析则是不可能的。重要的是，地球科学基础模型的可扩展性和通用性使得可以解决多种预测、模拟和决策问题 related to Earth systems interactions。通过域专家和计算机科学家之间的合作，这些无价的工具为我们理解地球的过去、当前和未来带来了创新。然而，验证和验证、缺失、知识表示和社会偏见仍然是挑战。未来，通过跨学科团队的努力，地球科学基础模型的集成、分辨率、准确性和公平性将得到改进。尽管当前存在限制，但地球科学基础模型仍然拥有提供关键的洞察和量化不确定性的潜力，它们的持续演化将对地球科学产生 Paradigm-shifting 的影响。
</details></li>
</ul>
<hr>
<h2 id="Cognitive-Mirage-A-Review-of-Hallucinations-in-Large-Language-Models"><a href="#Cognitive-Mirage-A-Review-of-Hallucinations-in-Large-Language-Models" class="headerlink" title="Cognitive Mirage: A Review of Hallucinations in Large Language Models"></a>Cognitive Mirage: A Review of Hallucinations in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06794">http://arxiv.org/abs/2309.06794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hongbinye/cognitive-mirage-hallucinations-in-llms">https://github.com/hongbinye/cognitive-mirage-hallucinations-in-llms</a></li>
<li>paper_authors: Hongbin Ye, Tong Liu, Aijia Zhang, Wei Hua, Weiqiang Jia</li>
<li>for: 这 study 探讨了大语言模型中的幻觉现象，以及幻觉的类型、检测方法和改进策略。</li>
<li>methods: 该 paper 使用了 various 文本生成任务中的幻觉类型，并提供了理论分析、检测方法和改进方向。</li>
<li>results: 该 paper 提供了一个完整的幻觉分类系统，并提供了现有的检测和改进方法。  future research directions 也被提出了。<details>
<summary>Abstract</summary>
As large language models continue to develop in the field of AI, text generation systems are susceptible to a worrisome phenomenon known as hallucination. In this study, we summarize recent compelling insights into hallucinations in LLMs. We present a novel taxonomy of hallucinations from various text generation tasks, thus provide theoretical insights, detection methods and improvement approaches. Based on this, future research directions are proposed. Our contribution are threefold: (1) We provide a detailed and complete taxonomy for hallucinations appearing in text generation tasks; (2) We provide theoretical analyses of hallucinations in LLMs and provide existing detection and improvement methods; (3) We propose several research directions that can be developed in the future. As hallucinations garner significant attention from the community, we will maintain updates on relevant research progress.
</details>
<details>
<summary>摘要</summary>
Large language models (LLMs) 在人工智能领域的发展中，文本生成系统受到一种有害现象的威胁，称为投影。在这项研究中，我们summarize了最近的有力证明，描述了不同的文本生成任务中的投影现象，并提供了理论分析、检测方法和改进方法。根据这些成果，我们提出了未来研究的方向。我们的贡献包括以下三个方面：1. 我们提供了文本生成任务中投影现象的完整和详细的分类体系。2. 我们提供了LLMs中投影现象的理论分析，并提供了现有的检测和改进方法。3. 我们提出了未来研究的多个方向，以探索投影现象的原因和解决方案。由于投影现象在社区中受到广泛关注，我们将继续更新相关的研究进展。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Survival-Time-of-Ball-Bearings-in-the-Presence-of-Censoring"><a href="#Predicting-Survival-Time-of-Ball-Bearings-in-the-Presence-of-Censoring" class="headerlink" title="Predicting Survival Time of Ball Bearings in the Presence of Censoring"></a>Predicting Survival Time of Ball Bearings in the Presence of Censoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07188">http://arxiv.org/abs/2309.07188</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thecml/ball-bearing-survival">https://github.com/thecml/ball-bearing-survival</a></li>
<li>paper_authors: Christian Marius Lillelund, Fernando Pannullo, Morten Opprud Jakobsen, Christian Fischer Pedersen</li>
<li>for: 这 paper 的目的是提出一种基于存活分析的方法来预测球磨具的时间到失败。</li>
<li>methods: 该 paper 使用了存活分析在时域和频域中分析数据，并使用了一些生存模型来估计时间到失败。</li>
<li>results: 该 paper 在 XJTU 和 PRONOSTIA 数据集上实现了良好的预测结果，其中 XJTU 上得到的最佳结果是0.70的 concordance-index和0.21的累积布莱尔分数，PRONOSTIA 上得到的最佳结果是0.76的 concordance-index和0.19的累积布莱尔分数。<details>
<summary>Abstract</summary>
Ball bearings find widespread use in various manufacturing and mechanical domains, and methods based on machine learning have been widely adopted in the field to monitor wear and spot defects before they lead to failures. Few studies, however, have addressed the problem of censored data, in which failure is not observed. In this paper, we propose a novel approach to predict the time to failure in ball bearings using survival analysis. First, we analyze bearing data in the frequency domain and annotate when a bearing fails by comparing the Kullback-Leibler divergence and the standard deviation between its break-in frequency bins and its break-out frequency bins. Second, we train several survival models to estimate the time to failure based on the annotated data and covariates extracted from the time domain, such as skewness, kurtosis and entropy. The models give a probabilistic prediction of risk over time and allow us to compare the survival function between groups of bearings. We demonstrate our approach on the XJTU and PRONOSTIA datasets. On XJTU, the best result is a 0.70 concordance-index and 0.21 integrated Brier score. On PRONOSTIA, the best is a 0.76 concordance-index and 0.19 integrated Brier score. Our work motivates further work on incorporating censored data in models for predictive maintenance.
</details>
<details>
<summary>摘要</summary>
滚球支持件在不同的生产和机械领域中广泛使用，而基于机器学习技术的监测方法也在这一领域得到了广泛应用。然而，有很少的研究专门关注缺失数据（失败不观察）问题。在这篇论文中，我们提出了一种新的方法，用于预测滚球支持件的时间到失败使用存生分析。首先，我们分析了滚球数据在频域中，并在break-in和break-out频率分布之间进行了比较，以确定缺失数据。然后，我们使用了多种存生模型来估算时间到失败的风险，并使用了时域中的特征，如方差、泊松指数和自 entropy。这些模型可以为不同的滚球支持件提供可比较的生存函数，并允许我们对缺失数据进行处理。我们在XJTU和PRONOSTIA数据集上进行了实践，最佳结果为XJTU的0.70 concordance-index和0.21 integral Brier score，PRONOSTIA的0.76 concordance-index和0.19 integral Brier score。我们的工作鼓励了更多关于缺失数据的包含在预测维护模型中的进一步研究。
</details></li>
</ul>
<hr>
<h2 id="Generative-AI"><a href="#Generative-AI" class="headerlink" title="Generative AI"></a>Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07930">http://arxiv.org/abs/2309.07930</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/StanGirard/quivr">https://github.com/StanGirard/quivr</a></li>
<li>paper_authors: Stefan Feuerriegel, Jochen Hartmann, Christian Janiesch, Patrick Zschech</li>
<li>for: 本研究旨在探讨Generative AI在信息系统中的应用和发展，以及其对BISE领域的影响和挑战。</li>
<li>methods: 本研究使用概率模型、深度学习和自然语言处理等技术，并提供了一些实际应用例如Dall-E 2、GPT-4和Copilot等。</li>
<li>results: 本研究发现当前Generative AI技术存在一些限制和挑战，如数据质量、隐私和安全等问题，并提出了BISE领域的研究论点和方向。<details>
<summary>Abstract</summary>
The term "generative AI" refers to computational techniques that are capable of generating seemingly new, meaningful content such as text, images, or audio from training data. The widespread diffusion of this technology with examples such as Dall-E 2, GPT-4, and Copilot is currently revolutionizing the way we work and communicate with each other. In this article, we provide a conceptualization of generative AI as an entity in socio-technical systems and provide examples of models, systems, and applications. Based on that, we introduce limitations of current generative AI and provide an agenda for Business & Information Systems Engineering (BISE) research. Different from previous works, we focus on generative AI in the context of information systems, and, to this end, we discuss several opportunities and challenges that are unique to the BISE community and make suggestions for impactful directions for BISE research.
</details>
<details>
<summary>摘要</summary>
“生成AI”是指通过训练数据生成新的、有意义的内容，如文本、图像或音频等。现在，这种技术的广泛散布，如达尔-E2、GPT-4和副手等，正在改变我们工作和交流方式。本文将生成AI视为社会技术系统中的一个实体，并提供模型、系统和应用的示例。然后，我们介绍当前生成AI的限制，并为商业信息系统工程（BISE）研究提供研究议程。与之前的研究不同，我们在信息系统上下文中强调生成AI，并讨论了BISE社区独特的机遇和挑战，并提供了影响力的BISE研究方向。
</details></li>
</ul>
<hr>
<h2 id="Fundamental-Limits-of-Deep-Learning-Based-Binary-Classifiers-Trained-with-Hinge-Loss"><a href="#Fundamental-Limits-of-Deep-Learning-Based-Binary-Classifiers-Trained-with-Hinge-Loss" class="headerlink" title="Fundamental Limits of Deep Learning-Based Binary Classifiers Trained with Hinge Loss"></a>Fundamental Limits of Deep Learning-Based Binary Classifiers Trained with Hinge Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06774">http://arxiv.org/abs/2309.06774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tilahun M. Getu, Georges Kaddoum</li>
<li>for: 本文旨在解释深度学习（DL）在多个领域中的成功原因，以及DL的核心问题。</li>
<li>methods: 本文使用了多种创新，包括优化、泛化和近似方法，以解决DL的问题。</li>
<li>results: 本文derived了深度Rectified Linear Unit（ReLU）隐藏层神经网络（FNN）和深度FNNwith ReLU和Tanh激活函数的二分类测试性能上限。这些上限被 validate by extensive computer experiments。<details>
<summary>Abstract</summary>
Although deep learning (DL) has led to several breakthroughs in many disciplines as diverse as chemistry, computer science, electrical engineering, mathematics, medicine, neuroscience, and physics, a comprehensive understanding of why and how DL is empirically successful remains fundamentally elusive. To attack this fundamental problem and unravel the mysteries behind DL's empirical successes, significant innovations toward a unified theory of DL have been made. These innovations encompass nearly fundamental advances in optimization, generalization, and approximation. Despite these advances, however, no work to date has offered a way to quantify the testing performance of a DL-based algorithm employed to solve a pattern classification problem. To overcome this fundamental challenge in part, this paper exposes the fundamental testing performance limits of DL-based binary classifiers trained with hinge loss. For binary classifiers that are based on deep rectified linear unit (ReLU) feedforward neural networks (FNNs) and ones that are based on deep FNNs with ReLU and Tanh activation, we derive their respective novel asymptotic testing performance limits. The derived testing performance limits are validated by extensive computer experiments.
</details>
<details>
<summary>摘要</summary>
Note:* "深度学习" (shēn dào xué xí) is the Simplified Chinese term for "deep learning".* "hinge loss" (折衣函数) is the Simplified Chinese term for "hinge loss".* "ReLU" (Rectified Linear Unit) is the Simplified Chinese term for "Rectified Linear Unit".* "Tanh" (Hyperbolic Tangent) is the Simplified Chinese term for "Hyperbolic Tangent".
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Keyphrase-Generation-by-BART-Finetuning-with-Splitting-and-Shuffling"><a href="#Enhancing-Keyphrase-Generation-by-BART-Finetuning-with-Splitting-and-Shuffling" class="headerlink" title="Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling"></a>Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06726">http://arxiv.org/abs/2309.06726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Chen, Mizuho Iwaihara</li>
<li>for: 本研究旨在提高缺失关键短语生成的性能，提出了关键短语集中心化的BART模型，并实现了缺失关键短语生成的精度优化。</li>
<li>methods: 本研究使用了序列到序列模型，并进行了两个独立的BART模型的微调，以便更好地生成缺失关键短语。</li>
<li>results: 对于缺失关键短语生成，本研究的Keyphrase-Focused BART在五个关键短语生成测试集上的F1@5指标中取得了新的州际最佳成绩。<details>
<summary>Abstract</summary>
Keyphrase generation is a task of identifying a set of phrases that best repre-sent the main topics or themes of a given text. Keyphrases are dividend int pre-sent and absent keyphrases. Recent approaches utilizing sequence-to-sequence models show effectiveness on absent keyphrase generation. However, the per-formance is still limited due to the hardness of finding absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which exploits the differ-ences between present and absent keyphrase generations, and performs fine-tuning of two separate BART models for present and absent keyphrases. We further show effective approaches of shuffling keyphrases and candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART achieved new state-of-the-art score on F1@5 in two out of five keyphrase gen-eration benchmark datasets.
</details>
<details>
<summary>摘要</summary>
<<SYS>> tranlate_into_simplified_chinese键短语生成是一个文本中主题或主题的精炼过程，用于标识文本中的关键短语。键短语可以分为存在和缺失两类。 latest approaches 使用序列到序列模型，表现良好在缺失键短语生成中。然而，性能仍然有限因为缺失键短语的发现困难。在这篇论文中，我们提出了键短语专注的BART，利用存在和缺失键短语生成的差异，并对两个分离的BART模型进行了精炼。我们还提出了键短语洗牌和候选键短语排名的有效方法。对于缺失键短语，我们的键短语专注BART实现了五个键短语生成 benchmark dataset 中的新状态的末端得分。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Spectrum-Mixer-for-Visual-Recognition"><a href="#Dynamic-Spectrum-Mixer-for-Visual-Recognition" class="headerlink" title="Dynamic Spectrum Mixer for Visual Recognition"></a>Dynamic Spectrum Mixer for Visual Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06721">http://arxiv.org/abs/2309.06721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqiang Hu, Tao Yu</li>
<li>for: 提高多种视觉识别任务的性能，包括图像分类、物体检测和semantic segmentation。</li>
<li>methods: 使用Discrete Cosine Transform来在频域上表示 токен之间的互动，并提出了动态频谱权重生成层来选择有用的频谱频率。</li>
<li>results: 在多种视觉识别任务上达到了比较高的性能，比如 ImageNet 上的 top-1 准确率达到 83.8%，以及 ADE20K 上的 mIoU 达到 49.9%。<details>
<summary>Abstract</summary>
Recently, MLP-based vision backbones have achieved promising performance in several visual recognition tasks. However, the existing MLP-based methods directly aggregate tokens with static weights, leaving the adaptability to different images untouched. Moreover, Recent research demonstrates that MLP-Transformer is great at creating long-range dependencies but ineffective at catching high frequencies that primarily transmit local information, which prevents it from applying to the downstream dense prediction tasks, such as semantic segmentation. To address these challenges, we propose a content-adaptive yet computationally efficient structure, dubbed Dynamic Spectrum Mixer (DSM). The DSM represents token interactions in the frequency domain by employing the Discrete Cosine Transform, which can learn long-term spatial dependencies with log-linear complexity. Furthermore, a dynamic spectrum weight generation layer is proposed as the spectrum bands selector, which could emphasize the informative frequency bands while diminishing others. To this end, the technique can efficiently learn detailed features from visual input that contains both high- and low-frequency information. Extensive experiments show that DSM is a powerful and adaptable backbone for a range of visual recognition tasks. Particularly, DSM outperforms previous transformer-based and MLP-based models, on image classification, object detection, and semantic segmentation tasks, such as 83.8 \% top-1 accuracy on ImageNet, and 49.9 \% mIoU on ADE20K.
</details>
<details>
<summary>摘要</summary>
近期，基于多层感知（MLP）的视觉基干已经实现了许多视觉识别任务的出色表现。然而，现有的MLP基本方法直接汇集token的静态重量，未能考虑不同图像的适应性。此外，最近的研究表明，MLP transformer在创建长距离依赖关系方面卓越，但缺乏捕捉高频信息，主要传输本地信息的能力，这使得它无法应用于下游密集预测任务，如semantic segmentation。为Address这些挑战，我们提议一种内容适应且计算效率高的结构，名为动态спектルmixer（DSM）。DSM通过使用Discrete Cosine Transform来表示token之间的交互，可以学习长期空间依赖关系，并且可以快速学习细致的特征。此外，我们还提出了一种动态spectrum weight生成层，可以强调有用的频率带，而忽略其他带。通过这种方式，我们可以高效地从视觉输入中学习细致的特征，包括高频和低频信息。我们的实验表明，DSM是一种强大和适应的视觉基干，可以在多种视觉识别任务中表现出色，包括ImageNet的83.8%的top-1准确率和ADE20K的49.9%的mIoU。
</details></li>
</ul>
<hr>
<h2 id="TrafficGPT-Viewing-Processing-and-Interacting-with-Traffic-Foundation-Models"><a href="#TrafficGPT-Viewing-Processing-and-Interacting-with-Traffic-Foundation-Models" class="headerlink" title="TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation Models"></a>TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06719">http://arxiv.org/abs/2309.06719</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lijlansg/trafficgpt">https://github.com/lijlansg/trafficgpt</a></li>
<li>paper_authors: Siyao Zhang, Daocheng Fu, Zhao Zhang, Bin Yu, Pinlong Cai</li>
<li>for: 提高城市交通管理和控制的能力，尤其是处理数字数据和与 simulate 的交互。</li>
<li>methods: 结合 ChatGPT 和专业交通基础模型，以提高解决复杂交通问题的能力。</li>
<li>results: 提供了一种新的 Approach 到利用 AI 技术解决城市交通问题，并可以提供有用的决策支持。<details>
<summary>Abstract</summary>
With the promotion of chatgpt to the public, Large language models indeed showcase remarkable common sense, reasoning, and planning skills, frequently providing insightful guidance. These capabilities hold significant promise for their application in urban traffic management and control. However, LLMs struggle with addressing traffic issues, especially processing numerical data and interacting with simulations, limiting their potential in solving traffic-related challenges. In parallel, specialized traffic foundation models exist but are typically designed for specific tasks with limited input-output interactions. Combining these models with LLMs presents an opportunity to enhance their capacity for tackling complex traffic-related problems and providing insightful suggestions. To bridge this gap, we present TrafficGPT, a fusion of ChatGPT and traffic foundation models. This integration yields the following key enhancements: 1) empowering ChatGPT with the capacity to view, analyze, process traffic data, and provide insightful decision support for urban transportation system management; 2) facilitating the intelligent deconstruction of broad and complex tasks and sequential utilization of traffic foundation models for their gradual completion; 3) aiding human decision-making in traffic control through natural language dialogues; and 4) enabling interactive feedback and solicitation of revised outcomes. By seamlessly intertwining large language model and traffic expertise, TrafficGPT not only advances traffic management but also offers a novel approach to leveraging AI capabilities in this domain. The TrafficGPT demo can be found in https://github.com/lijlansg/TrafficGPT.git.
</details>
<details>
<summary>摘要</summary>
With the promotion of ChatGPT to the public, large language models have indeed shown remarkable common sense, reasoning, and planning skills, frequently providing insightful guidance. These capabilities hold significant promise for their application in urban traffic management and control. However, LLMs struggle with addressing traffic issues, especially processing numerical data and interacting with simulations, limiting their potential in solving traffic-related challenges. In parallel, specialized traffic foundation models exist but are typically designed for specific tasks with limited input-output interactions. Combining these models with LLMs presents an opportunity to enhance their capacity for tackling complex traffic-related problems and providing insightful suggestions. To bridge this gap, we present TrafficGPT, a fusion of ChatGPT and traffic foundation models. This integration yields the following key enhancements:1. 允许ChatGPTView、分析和处理交通数据，为城市交通系统管理提供智能支持；2. 可以智能分解广泛和复杂的任务，并逐步使用交通基础模型完成其完成；3. 帮助人类决策交通控制通过自然语言对话；4. 允许人类反馈和修改结果。通过融合大语言模型和交通专家知识，TrafficGPT不仅提高了交通管理，还提供了一种新的使用AI技术解决交通问题的方法。TrafficGPT demo可以在https://github.com/lijlansg/TrafficGPT.git中找到。
</details></li>
</ul>
<hr>
<h2 id="Tackling-the-Non-IID-Issue-in-Heterogeneous-Federated-Learning-by-Gradient-Harmonization"><a href="#Tackling-the-Non-IID-Issue-in-Heterogeneous-Federated-Learning-by-Gradient-Harmonization" class="headerlink" title="Tackling the Non-IID Issue in Heterogeneous Federated Learning by Gradient Harmonization"></a>Tackling the Non-IID Issue in Heterogeneous Federated Learning by Gradient Harmonization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06692">http://arxiv.org/abs/2309.06692</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Zhang, Weiyu Sun, Ying Chen</li>
<li>for: 提高 Federated Learning（FL）的性能，解决非独立同分布（non-IID）数据和设备不一致性的挑战。</li>
<li>methods: 通过对服务器端的梯度冲突现象进行分析，提出了一种简单 yet effective的 Gradient Harmonization（梯度融合）技术来mitigate local drifts。</li>
<li>results: 在多个 benchmark 和 non-IID 场景中，FedGH 能够顺利提高多个 state-of-the-art FL 基础系统，特别是在强度不一致的场景中表现更优异。<details>
<summary>Abstract</summary>
Federated learning (FL) is a privacy-preserving paradigm for collaboratively training a global model from decentralized clients. However, the performance of FL is hindered by non-independent and identically distributed (non-IID) data and device heterogeneity. In this work, we revisit this key challenge through the lens of gradient conflicts on the server side. Specifically, we first investigate the gradient conflict phenomenon among multiple clients and reveal that stronger heterogeneity leads to more severe gradient conflicts. To tackle this issue, we propose FedGH, a simple yet effective method that mitigates local drifts through Gradient Harmonization. This technique projects one gradient vector onto the orthogonal plane of the other within conflicting client pairs. Extensive experiments demonstrate that FedGH consistently enhances multiple state-of-the-art FL baselines across diverse benchmarks and non-IID scenarios. Notably, FedGH yields more significant improvements in scenarios with stronger heterogeneity. As a plug-and-play module, FedGH can be seamlessly integrated into any FL framework without requiring hyperparameter tuning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Self-Refined-Large-Language-Model-as-Automated-Reward-Function-Designer-for-Deep-Reinforcement-Learning-in-Robotics"><a href="#Self-Refined-Large-Language-Model-as-Automated-Reward-Function-Designer-for-Deep-Reinforcement-Learning-in-Robotics" class="headerlink" title="Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics"></a>Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06687">http://arxiv.org/abs/2309.06687</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhehuazhou/llm_reward_design">https://github.com/zhehuazhou/llm_reward_design</a></li>
<li>paper_authors: Jiayang Song, Zhehua Zhou, Jiawei Liu, Chunrong Fang, Zhan Shu, Lei Ma</li>
<li>for: 自动化奖函数设计</li>
<li>methods: 利用大型自然语言模型（LLM）自我修复机制</li>
<li>results: 在三个不同的机器人系统上进行多种连续控制任务中，LLM设计的奖函数能与人工设计的奖函数相比或者超越它们，证明了方法的可行性和应用性。<details>
<summary>Abstract</summary>
Although Deep Reinforcement Learning (DRL) has achieved notable success in numerous robotic applications, designing a high-performing reward function remains a challenging task that often requires substantial manual input. Recently, Large Language Models (LLMs) have been extensively adopted to address tasks demanding in-depth common-sense knowledge, such as reasoning and planning. Recognizing that reward function design is also inherently linked to such knowledge, LLM offers a promising potential in this context. Motivated by this, we propose in this work a novel LLM framework with a self-refinement mechanism for automated reward function design. The framework commences with the LLM formulating an initial reward function based on natural language inputs. Then, the performance of the reward function is assessed, and the results are presented back to the LLM for guiding its self-refinement process. We examine the performance of our proposed framework through a variety of continuous robotic control tasks across three diverse robotic systems. The results indicate that our LLM-designed reward functions are able to rival or even surpass manually designed reward functions, highlighting the efficacy and applicability of our approach.
</details>
<details>
<summary>摘要</summary>
尽管深度强化学习（DRL）在机器人应用中已经取得了显著的成功，但是设计高性能的奖金函数仍然是一项具有挑战性的任务，往往需要大量的手动输入。在最近，大型自然语言模型（LLM）在涉及深度通用常识知识的任务上得到了广泛的应用，如理解和规划。认识到奖金函数设计与这些知识息息相关，LLM具有潜在的应用潜力。在这种情况下，我们在这个工作中提出了一种基于LLM的自动奖金函数设计框架。框架开始于LLM根据自然语言输入形成初始奖金函数。然后，奖金函数的性能被评估，并将结果返回给LLM以引导其自我修正过程。我们通过三种不同的机器人控制任务来评估我们的提议的性能。结果表明，我们使用LLM设计的奖金函数能够与或超过手动设计的奖金函数，这说明了我们的方法的有效性和可行性。
</details></li>
</ul>
<hr>
<h2 id="Attention-Loss-Adjusted-Prioritized-Experience-Replay"><a href="#Attention-Loss-Adjusted-Prioritized-Experience-Replay" class="headerlink" title="Attention Loss Adjusted Prioritized Experience Replay"></a>Attention Loss Adjusted Prioritized Experience Replay</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06684">http://arxiv.org/abs/2309.06684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuoying Chen, Huiping Li, Rizhong Wang</li>
<li>for: 提高深度强化学习训练速度</li>
<li>methods: 使用改进的自我注意网络和双抽样机制来调整重要抽样 вес，从而消除PER引起的估计误差</li>
<li>results: 在OPENAI gym中测试了值函数基于、政策梯度基于和多Agent强化学习算法，并进行了比较研究，证明提出的训练框架具有优势和效率。<details>
<summary>Abstract</summary>
Prioritized Experience Replay (PER) is a technical means of deep reinforcement learning by selecting experience samples with more knowledge quantity to improve the training rate of neural network. However, the non-uniform sampling used in PER inevitably shifts the state-action space distribution and brings the estimation error of Q-value function. In this paper, an Attention Loss Adjusted Prioritized (ALAP) Experience Replay algorithm is proposed, which integrates the improved Self-Attention network with Double-Sampling mechanism to fit the hyperparameter that can regulate the importance sampling weights to eliminate the estimation error caused by PER. In order to verify the effectiveness and generality of the algorithm, the ALAP is tested with value-function based, policy-gradient based and multi-agent reinforcement learning algorithms in OPENAI gym, and comparison studies verify the advantage and efficiency of the proposed training framework.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用优先验收（PER）技术进行深度学习强化学习，可以提高神经网络训练速率。然而，PER 中的不均匀采样无可避免地导致状态动作空间分布的变化，从而引起 Q-值函数的估计误差。在这篇论文中，一种 Attention Loss Adjusted Prioritized（ALAP）经验回放算法被提出，该算法将改进的 Self-Attention 网络和双抽样机制结合起来，以适应调整重要抽样重量，以消除 PER 引起的估计误差。为证明 ALAP 的效果和通用性，该算法在 OPENAI gym 中使用值函数基本、政策梯度基本和多 Agent 强化学习算法进行测试，并进行对比研究，以验证提案的训练框架的优势和效率。>>>
</details></li>
</ul>
<hr>
<h2 id="A-plug-and-play-synthetic-data-deep-learning-for-undersampled-magnetic-resonance-image-reconstruction"><a href="#A-plug-and-play-synthetic-data-deep-learning-for-undersampled-magnetic-resonance-image-reconstruction" class="headerlink" title="A plug-and-play synthetic data deep learning for undersampled magnetic resonance image reconstruction"></a>A plug-and-play synthetic data deep learning for undersampled magnetic resonance image reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06681">http://arxiv.org/abs/2309.06681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Xiao, Zi Wang, Jiefeng Guo, Xiaobo Qu</li>
<li>for: 提高现代医疗影像诊断中的磁共振成像（MRI）的速度，使其具有更快的扫描速度。</li>
<li>methods: 使用深度学习方法对快速扫描MRI数据进行重建，并可以适应不同的抽样设定。</li>
<li>results: 在实验数据上表明，提议的深度插件和游戏方法可以在不同的抽样模式和抽样速率下提供美观和稳定的加速图像重建性能。<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) plays an important role in modern medical diagnostic but suffers from prolonged scan time. Current deep learning methods for undersampled MRI reconstruction exhibit good performance in image de-aliasing which can be tailored to the specific kspace undersampling scenario. But it is very troublesome to configure different deep networks when the sampling setting changes. In this work, we propose a deep plug-and-play method for undersampled MRI reconstruction, which effectively adapts to different sampling settings. Specifically, the image de-aliasing prior is first learned by a deep denoiser trained to remove general white Gaussian noise from synthetic data. Then the learned deep denoiser is plugged into an iterative algorithm for image reconstruction. Results on in vivo data demonstrate that the proposed method provides nice and robust accelerated image reconstruction performance under different undersampling patterns and sampling rates, both visually and quantitatively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SHARM-Segmented-Head-Anatomical-Reference-Models"><a href="#SHARM-Segmented-Head-Anatomical-Reference-Models" class="headerlink" title="SHARM: Segmented Head Anatomical Reference Models"></a>SHARM: Segmented Head Anatomical Reference Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06677">http://arxiv.org/abs/2309.06677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Essam A. Rashed, Mohammad al-Shatouri, Ilkka Laakso, Akimasa Hirata</li>
<li>for: 这个研究的目的是提供一个开放访问的 Segmented Head Anatomical Reference Models（SHARM），用于衡量人头的不同组织部分的分布。</li>
<li>methods: 这个研究使用了开源的IXI MRI数据集和一种名为ForkNet+的卷积神经网络结构进行人头的分类。</li>
<li>results: 研究发现，SHARM在年龄层的统计特征上具有高一致性，与实际测量结果相符。 SHARM预期能够为电磁吸收研究提供一个有用的参照基准，同时也可以用于不同的人头分类应用。<details>
<summary>Abstract</summary>
Reliable segmentation of anatomical tissues of human head is a major step in several clinical applications such as brain mapping, surgery planning and associated computational simulation studies. Segmentation is based on identifying different anatomical structures through labeling different tissues through medical imaging modalities. The segmentation of brain structures is commonly feasible with several remarkable contributions mainly for medical perspective; however, non-brain tissues are of less interest due to anatomical complexity and difficulties to be observed using standard medical imaging protocols. The lack of whole head segmentation methods and unavailability of large human head segmented datasets limiting the variability studies, especially in the computational evaluation of electrical brain stimulation (neuromodulation), human protection from electromagnetic field, and electroencephalography where non-brain tissues are of great importance.   To fill this gap, this study provides an open-access Segmented Head Anatomical Reference Models (SHARM) that consists of 196 subjects. These models are segmented into 15 different tissues; skin, fat, muscle, skull cancellous bone, skull cortical bone, brain white matter, brain gray matter, cerebellum white matter, cerebellum gray matter, cerebrospinal fluid, dura, vitreous humor, lens, mucous tissue and blood vessels. The segmented head models are generated using open-access IXI MRI dataset through convolutional neural network structure named ForkNet+. Results indicate a high consistency in statistical characteristics of different tissue distribution in age scale with real measurements. SHARM is expected to be a useful benchmark not only for electromagnetic dosimetry studies but also for different human head segmentation applications.
</details>
<details>
<summary>摘要</summary>
“人头部分 Segmentation 是诊断和运行方面的重要一步，包括脑地图、手术规划和相关的计算模拟研究。Segmentation 基于医学影像模式中不同的 анатомі学结构的识别，并将不同的组织分类为不同的 ткани。脑部分的 Segmentation 通常是医学观点上可行的，但非脑组织则因为 анатомі学复杂和普通医学影像实验困难而被忽略。没有整体人头部分 Segmentation 方法和大量人头部分分类dataset的不足，限制了多样性研究，特别是电子脑刺激（neuromodulation）、人体对电磁场的保护和电enzephalography 等方面的研究，非脑组织在这些领域非常重要。为了填补这个 gap，本研究提供了一个开放存取的 Segmented Head Anatomical Reference Models (SHARM)，包括196个诊断件。这些模型分成15种不同的 ткани，包括皮肤、脂肪、肌肉、皮屑骨、骨髓、脑白 matter、脑灰 matter、脑灰白 matter、脑灰质液、脑髓液、眼镜膜、肉眼和血管。这些分类的人头模型通过开源的 IXI MRI 数据集通过 Convolutional Neural Network 结构 named ForkNet+ 生成。结果显示这些模型在年龄对应的统计特征上有高一致性。SHARM 预期会成为电磁质量研究之外，不同人头分类应用的有用benchmark。”
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-Can-Infer-Psychological-Dispositions-of-Social-Media-Users"><a href="#Large-Language-Models-Can-Infer-Psychological-Dispositions-of-Social-Media-Users" class="headerlink" title="Large Language Models Can Infer Psychological Dispositions of Social Media Users"></a>Large Language Models Can Infer Psychological Dispositions of Social Media Users</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08631">http://arxiv.org/abs/2309.08631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heinrich Peters, Sandra Matz</li>
<li>for: 本研究旨在 investigate Large Language Models (LLMs) 的能力，以及这些模型在自然语言处理任务中的人类化能力。</li>
<li>methods: 本研究使用 GPT-3.5 和 GPT-4 来推断用户的 Facebook 状态更新中的心理特质。</li>
<li>results: 研究发现，LLMs 能够很准确地推断用户的 Five Big Personality Traits， correlation coefficient 平均为 r &#x3D; .29（range &#x3D; [.22, .33]）。然而，研究还发现了性别和年龄的偏见，即对于女性和年轻人来说，LLMs 的推断结果更为准确。<details>
<summary>Abstract</summary>
As Large Language Models (LLMs) demonstrate increasingly human-like abilities in various natural language processing (NLP) tasks that are bound to become integral to personalized technologies, understanding their capabilities and inherent biases is crucial. Our study investigates the potential of LLMs like ChatGPT to infer psychological dispositions of individuals from their digital footprints. Specifically, we assess the ability of GPT-3.5 and GPT-4 to derive the Big Five personality traits from users' Facebook status updates in a zero-shot learning scenario. Our results show an average correlation of r = .29 (range = [.22, .33]) between LLM-inferred and self-reported trait scores. Furthermore, our findings suggest biases in personality inferences with regard to gender and age: inferred scores demonstrated smaller errors for women and younger individuals on several traits, suggesting a potential systematic bias stemming from the underlying training data or differences in online self-expression.
</details>
<details>
<summary>摘要</summary>
As Large Language Models (LLMs) demonstrate increasingly human-like abilities in various natural language processing (NLP) tasks that are bound to become integral to personalized technologies, understanding their capabilities and inherent biases is crucial. Our study investigates the potential of LLMs like ChatGPT to infer psychological dispositions of individuals from their digital footprints. Specifically, we assess the ability of GPT-3.5 and GPT-4 to derive the Big Five personality traits from users' Facebook status updates in a zero-shot learning scenario. Our results show an average correlation of r = .29 (range = [.22, .33]) between LLM-inferred and self-reported trait scores. Furthermore, our findings suggest biases in personality inferences with regard to gender and age: inferred scores demonstrated smaller errors for women and younger individuals on several traits, suggesting a potential systematic bias stemming from the underlying training data or differences in online self-expression.Here's the translation in Traditional Chinese:随着大型语言模型（LLMs）在不同的自然语言处理（NLP）任务中展示出人类化的能力，理解它们的能力和内在偏见是非常重要的。我们的研究探讨了 ChatGPT 等 LLMs 是否可以从用户的数码足迹中推断个人心理特质。具体来说，我们评估 GPT-3.5 和 GPT-4 是否可以从 Facebook 状态更新中推断 Big Five 人格特质。我们的结果显示，LLM-推断的和自我报告的特质分数之间的平均相关 coefficient 为 r = .29（range = [.22, .33]）。此外，我们发现在不同的性别和年龄群体中，推断的特质分数存在偏见：对某些特质而言，女性和年轻人的推断分数更为精确，这可能是训练数据或在线自我表达中的偏见。
</details></li>
</ul>
<hr>
<h2 id="Offline-Prompt-Evaluation-and-Optimization-with-Inverse-Reinforcement-Learning"><a href="#Offline-Prompt-Evaluation-and-Optimization-with-Inverse-Reinforcement-Learning" class="headerlink" title="Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning"></a>Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06553">http://arxiv.org/abs/2309.06553</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/holarissun/Prompt-OIRL">https://github.com/holarissun/Prompt-OIRL</a></li>
<li>paper_authors: Hao Sun<br>for:这个研究目的是为了提高大型自然语言模型（LLMs）的效能，并且可以实现人工智能的应用。methods:这个研究使用了逆引导式学习（Inverse-RL）来评估提示的效能，并且使用了网上的专家评价数据来 derivate 一个价值函数。results:这个研究获得了以下结果： Prompt-OIRL 可以预测提示的效能，是成本高效的，生成了人阅读的结果，并且能够有效地探索提示空间。<details>
<summary>Abstract</summary>
The recent advances in the development of Large Language Models (LLMs) like ChatGPT have achieved remarkable performance by leveraging human expertise. Yet, fully eliciting LLMs' potential for complex tasks requires navigating the vast search space of natural language prompts. While prompt engineering has shown promise, the requisite human-crafted prompts in trial-and-error attempts and the associated costs pose significant challenges. Crucially, the efficiency of prompt optimization hinges on the costly procedure of prompt evaluation. This work introduces Prompt-OIRL, an approach rooted in offline inverse reinforcement learning that seeks to bridge the gap between effective prompt evaluation and affordability. Our method draws on offline datasets from expert evaluations, employing Inverse-RL to derive a reward model for offline, query-dependent prompt evaluations. The advantages of Prompt-OIRL are manifold: it predicts prompt performance, is cost-efficient, produces human-readable results, and efficiently navigates the prompt space. We validate our method across four LLMs and three arithmetic datasets, highlighting its potential as a robust and effective tool for offline prompt evaluation and optimization. Our code as well as the offline datasets are released, and we highlight the Prompt-OIRL can be reproduced within a few hours using a single laptop using CPU
</details>
<details>
<summary>摘要</summary>
近期，大型自然语言模型（LLM）的开发已取得了显著的进步，如ChatGPT。然而，为复杂任务完全发挥LLM的潜力需要在自然语言提示的庞大搜索空间中穿梭。虽然提示工程学习表现了承诺，但是在尝试和错误中制定人工提示的过程和相关的成本带来了重大挑战。关键是提示优化的效率取决于提示评估的昂贵过程。本文提出了Prompt-OIRL方法，它基于线上反束学习来bridging提示评估的效率和可Affordability之间的 gap。我们的方法利用了线上专家评估数据，使用反束RL来 derive一个偏好prompt评估的奖励模型。Prompt-OIRL的优点包括：预测提示性能、成本效益、生成人readable的结果和高效地探索提示空间。我们验证了Prompt-OIRL在四个LLM和三个算术数据集上，并 highlighted its potential as a robust and effective tool for offline prompt evaluation and optimization。我们的代码以及offline数据集都已经发布，并且在使用单个 laptop CPU 上进行了复现，可以在几个小时内完成。
</details></li>
</ul>
<hr>
<h2 id="A-Health-Monitoring-System-Based-on-Flexible-Triboelectric-Sensors-for-Intelligence-Medical-Internet-of-Things-and-its-Applications-in-Virtual-Reality"><a href="#A-Health-Monitoring-System-Based-on-Flexible-Triboelectric-Sensors-for-Intelligence-Medical-Internet-of-Things-and-its-Applications-in-Virtual-Reality" class="headerlink" title="A Health Monitoring System Based on Flexible Triboelectric Sensors for Intelligence Medical Internet of Things and its Applications in Virtual Reality"></a>A Health Monitoring System Based on Flexible Triboelectric Sensors for Intelligence Medical Internet of Things and its Applications in Virtual Reality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07185">http://arxiv.org/abs/2309.07185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junqi Mao, Puen Zhou, Xiaoyao Wang, Hongbo Yao, Liuyang Liang, Yiqiao Zhao, Jiawei Zhang, Dayan Ban, Haiwu Zheng<br>for:这项研究旨在开发一个可靠且智能的医疗物联网系统，以满足当代数字化和智能化时代的精准医疗、智能医疗和电子医疗需求。methods:研究人员采用了可变式摩擦电镜技术，并结合深度学习分析数据，实现了一个智能医疗监测系统，可以跟踪和分析患有parkinson病的患者的手部运动。results:研究人员实现了一个可靠、高敏感、智能的医疗监测系统，可以准确地捕捉和分析患有parkinson病的患者的细微运动和细腔运动。这种监测系统可以提供有价值的反馈和全面评估患者的情况，因此强调了人体感知技术在健康4.0社会中的极大潜力。<details>
<summary>Abstract</summary>
The Internet of Medical Things (IoMT) is a platform that combines Internet of Things (IoT) technology with medical applications, enabling the realization of precision medicine, intelligent healthcare, and telemedicine in the era of digitalization and intelligence. However, the IoMT faces various challenges, including sustainable power supply, human adaptability of sensors and the intelligence of sensors. In this study, we designed a robust and intelligent IoMT system through the synergistic integration of flexible wearable triboelectric sensors and deep learning-assisted data analytics. We embedded four triboelectric sensors into a wristband to detect and analyze limb movements in patients suffering from Parkinson's Disease (PD). By further integrating deep learning-assisted data analytics, we actualized an intelligent healthcare monitoring system for the surveillance and interaction of PD patients, which includes location/trajectory tracking, heart monitoring and identity recognition. This innovative approach enabled us to accurately capture and scrutinize the subtle movements and fine motor of PD patients, thus providing insightful feedback and comprehensive assessment of the patients conditions. This monitoring system is cost-effective, easily fabricated, highly sensitive, and intelligent, consequently underscores the immense potential of human body sensing technology in a Health 4.0 society.
</details>
<details>
<summary>摘要</summary>
互联网医疗物联网（IoMT）是一种将互联网物联网（IoT）技术与医疗应用结合的平台，使得精准医疗、智能医疗和 теле医学在数字化和智能时代得到实现。然而，IoMT面临着不同的挑战，包括可持续的电源供应、人类感知器的适应和感知器的智能。在本研究中，我们设计了一个可靠和智能的IoMT系统，通过同时结合柔性摩擦电子感知器和深度学习帮助数据分析。我们将四个摩擦电子感知器 integrate into a wristband to detect and analyze limb movements in patients with Parkinson's disease (PD).通过进一步结合深度学习帮助数据分析，我们实现了一个智能医疗监测系统，用于PD患者的位置/轨迹跟踪、心跳监测和身份识别。这种创新的方法使得我们能够准确捕捉和分析PD患者的微小动作和细 Motor，从而提供了深入的反馈和全面的病情评估。这种监测系统是成本低、易制造、高敏感和智能的，因此强调了人体感知技术在健康4.0社会中的无限潜力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/13/cs.AI_2023_09_13/" data-id="clohum93i0040pj888wkqbfx9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/13/cs.CL_2023_09_13/" class="article-date">
  <time datetime="2023-09-13T11:00:00.000Z" itemprop="datePublished">2023-09-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/13/cs.CL_2023_09_13/">cs.CL - 2023-09-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Sudden-Drops-in-the-Loss-Syntax-Acquisition-Phase-Transitions-and-Simplicity-Bias-in-MLMs"><a href="#Sudden-Drops-in-the-Loss-Syntax-Acquisition-Phase-Transitions-and-Simplicity-Bias-in-MLMs" class="headerlink" title="Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs"></a>Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07311">http://arxiv.org/abs/2309.07311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Angelica Chen, Ravid Schwartz-Ziv, Kyunghyun Cho, Matthew L. Leavitt, Naomi Saphra</li>
<li>for: 本研究旨在探讨masked language model（MLM）在训练过程中的语法学习过程，以及这种过程对模型行为的影响。</li>
<li>methods: 本研究使用了一种case study的方法，通过分析MLM的训练过程中的 interpretable artifacts（可解释的特征）的演变，深入了解模型的emergent behavior（产生的行为）。</li>
<li>results: 研究发现，在训练过程中，MLM会自然地形成一种叫做Syntactic Attention Structure（语法注意结构），这种结构使得特定的Transformer heads（转换器头）对特定的语法关系进行专注。研究发现，在训练过程中有一个短暂的窗口时间，当models suddenly acquire SAS时，并且这个窗口时间与损失函数的快速下降相关。此外，SAS还促进了语言功能的后续学习。通过对SAS的 manipulate during training，研究发现SAS对语言功能的发展具有必要的作用，但同时也会与其他有利的特征和功能竞争。<details>
<summary>Abstract</summary>
Most interpretability research in NLP focuses on understanding the behavior and features of a fully trained model. However, certain insights into model behavior may only be accessible by observing the trajectory of the training process. In this paper, we present a case study of syntax acquisition in masked language models (MLMs). Our findings demonstrate how analyzing the evolution of interpretable artifacts throughout training deepens our understanding of emergent behavior. In particular, we study Syntactic Attention Structure (SAS), a naturally emerging property of MLMs wherein specific Transformer heads tend to focus on specific syntactic relations. We identify a brief window in training when models abruptly acquire SAS and find that this window is concurrent with a steep drop in loss. Moreover, SAS precipitates the subsequent acquisition of linguistic capabilities. We then examine the causal role of SAS by introducing a regularizer to manipulate SAS during training, and demonstrate that SAS is necessary for the development of grammatical capabilities. We further find that SAS competes with other beneficial traits and capabilities during training, and that briefly suppressing SAS can improve model quality. These findings reveal a real-world example of the relationship between disadvantageous simplicity bias and interpretable breakthrough training dynamics.
</details>
<details>
<summary>摘要</summary>
大多数NLP解释研究都是关注已经训练完成的模型的行为和特征。然而，某些模型行为的理解可能只能通过观察训练过程的趋势来获得。在这篇论文中，我们提供了一个案例研究，探讨 маSKed语言模型（MLM）的 syntax acquisition。我们的发现表明，在训练过程中分析解释性artefact的演变可以深入了解模型的emergent行为。特别是，我们研究了在 MLM 中自然出现的语法注意结构（SAS），其中特定的 transformer 头部倾向于关注特定的语法关系。我们发现，在训练过程中模型突然获得 SAS 的时间fenomenon 和损失下降峰值是一样的。此外，SAS 对语言功能的掌握产生了先驱作用。我们然后对 SAS 的 causal 作用进行了检验，并证明了 SAS 是语言功能的必需条件。我们还发现，在训练过程中 SAS 与其他有利特征和能力的竞争存在，并且短暂地压制 SAS 可以提高模型质量。这些发现表明了实际中解释性研究中的简单偏好与可观察的训练动态之间的关系。
</details></li>
</ul>
<hr>
<h2 id="In-Contextual-Bias-Suppression-for-Large-Language-Models"><a href="#In-Contextual-Bias-Suppression-for-Large-Language-Models" class="headerlink" title="In-Contextual Bias Suppression for Large Language Models"></a>In-Contextual Bias Suppression for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07251">http://arxiv.org/abs/2309.07251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daisuke Oba, Masahiro Kaneko, Danushka Bollegala</li>
<li>for: 降低语言模型中的性别偏见</li>
<li>methods: 使用文本基础模板生成 counterfactual 语句，以及使用 descriptive 语句来描述职业，以降低语言模型中的性别偏见</li>
<li>results: 通过这些方法，可以减少语言模型中的性别偏见，而不需要访问模型参数，并且不会影响下游任务的性能。<details>
<summary>Abstract</summary>
Despite their impressive performance in a wide range of NLP tasks, Large Language Models (LLMs) have been reported to encode worrying-levels of gender bias. Prior work has proposed debiasing methods that require human labelled examples, data augmentation and fine-tuning of the LLMs, which are computationally costly. Moreover, one might not even have access to the internal parameters for performing debiasing such as in the case of commercially available LLMs such as GPT-4. To address this challenge we propose bias suppression, a novel alternative to debiasing that does not require access to model parameters. We show that text-based preambles, generated from manually designed templates covering counterfactual statements, can accurately suppress gender biases in LLMs. Moreover, we find that descriptive sentences for occupations can further suppress gender biases. Interestingly, we find that bias suppression has a minimal adverse effect on downstream task performance, while effectively mitigating the gender biases.
</details>
<details>
<summary>摘要</summary>
尽管大语言模型（LLMs）在各种自然语言处理任务中表现出色，但它们仍然存在害让的性别偏见。先前的工作已经提议了对偏见的修正方法，需要人工标注示例、数据扩展和模型练习，这些方法都是 computationally costly。此外，在商业可用的 LLMs 中，可能无法获取内部参数，进行修正。为解决这个挑战，我们提出了偏见抑制，一种不需要模型参数的新方法。我们表明，基于手动设计的模板，生成的文本引言可以准确地抑制 LLMs 中的性别偏见。此外，我们发现，对职业描述句的使用可以进一步抑制性别偏见。意外地，我们发现，偏见抑制并没有对下游任务性能产生明显的负面影响，同时有效地 Mitigating 性别偏见。
</details></li>
</ul>
<hr>
<h2 id="RAIN-Your-Language-Models-Can-Align-Themselves-without-Finetuning"><a href="#RAIN-Your-Language-Models-Can-Align-Themselves-without-Finetuning" class="headerlink" title="RAIN: Your Language Models Can Align Themselves without Finetuning"></a>RAIN: Your Language Models Can Align Themselves without Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07124">http://arxiv.org/abs/2309.07124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhui Li, Fangyun Wei, Jinjing Zhao, Chao Zhang, Hongyang Zhang</li>
<li>for: 本研究旨在实现AI安全，将预训语言模型（LLM）与人类偏好集成。</li>
<li>methods: 本研究使用了自我评估和回溯机制，将预训LLM直接调整为人类偏好。新引入的推论方法称为自回推导（RAIN），可以让预训LLM评估自己的生成结果，并使用评估结果导引后向回溯和前进生成，以确保AI安全。</li>
<li>results: 实验结果显示，RAIN可以将预训LLM的伤害率（HH dataset）提高至97%，保持有用性率不变。另外，在领导性攻击llm-attacks中，RAIN成功降低了攻击成功率从94%下降至19%。<details>
<summary>Abstract</summary>
Large language models (LLMs) often demonstrate inconsistencies with human preferences. Previous research gathered human preference data and then aligned the pre-trained models using reinforcement learning or instruction tuning, the so-called finetuning step. In contrast, aligning frozen LLMs without any extra data is more appealing. This work explores the potential of the latter setting. We discover that by integrating self-evaluation and rewind mechanisms, unaligned LLMs can directly produce responses consistent with human preferences via self-boosting. We introduce a novel inference method, Rewindable Auto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate their own generation and use the evaluation results to guide backward rewind and forward generation for AI safety. Notably, RAIN operates without the need of extra data for model alignment and abstains from any training, gradient computation, or parameter updates; during the self-evaluation phase, the model receives guidance on which human preference to align with through a fixed-template prompt, eliminating the need to modify the initial prompt. Experimental results evaluated by GPT-4 and humans demonstrate the effectiveness of RAIN: on the HH dataset, RAIN improves the harmlessness rate of LLaMA 30B over vanilla inference from 82% to 97%, while maintaining the helpfulness rate. Under the leading adversarial attack llm-attacks on Vicuna 33B, RAIN establishes a new defense baseline by reducing the attack success rate from 94% to 19%.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）经常表现出人类 предпочтения不一致。过去的研究通过强化学习或指令调整，将预训练模型与人类 предпочтеences进行对应，这被称为辐射步骤。而不需要额外数据，直接将冻结LLMs进行对应，更加吸引人。这项工作探索了后者的可能性。我们发现，通过结合自我评估和rewind机制，无需额外数据的LLMs可以通过自我推动直接生成与人类 предпочтеences相符的回答。我们提出了一种新的推理方法，即逆时间推理自动回归推理（RAIN），允许预训练LLMs在自我评估期间评估自己的生成，并使用评估结果导向后向推动和前向生成，以保障人工智能安全。值得注意的是，RAIN不需要额外数据进行模型对齐，也不需要任何训练、梯度计算或参数更新；在自我评估阶段，模型通过固定模板提示来获得需要与人类 predicates 对齐的指导。实验结果通过GPT-4和人类评价表明，RAIN可以有效地提高LLaMA 30B中的无害率，从82%提高到97%，同时保持有用率不变。在llm-attacks攻击下，RAIN成功地提出了一个新的防御基准，从94%降低到19%。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Hallucinations-and-Off-target-Machine-Translation-with-Source-Contrastive-and-Language-Contrastive-Decoding"><a href="#Mitigating-Hallucinations-and-Off-target-Machine-Translation-with-Source-Contrastive-and-Language-Contrastive-Decoding" class="headerlink" title="Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding"></a>Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07098">http://arxiv.org/abs/2309.07098</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zurichnlp/contradecode">https://github.com/zurichnlp/contradecode</a></li>
<li>paper_authors: Rico Sennrich, Jannis Vamvas, Alireza Mohammadshahi</li>
<li>for: 本文针对机器翻译中的幻视和目标翻译问题进行解决，特别是在低资源语言和巨大多语言模型中。</li>
<li>methods: 本文提出了一种 modificated decoding 目标，以避免需要重训或外部模型。具体来说，在源 contrasional decoding 中寻找一个翻译，它在正确的输入下是可能的，但是在随机输入段下是不可能的，这样幻视和目标翻译将会具有相似的可能性。在语言 contrasional decoding 中寻找一个翻译，它在正确的语言指示符token下是可能的，但是在错误的语言指示符token下是不可能的。</li>
<li>results: 在 M2M-100 (418M) 和 SMaLL-100 上进行实验，发现这些方法可以有效地抑制幻视和目标翻译，提高 chrF2 的分数在57个翻译方向上平均提高1.7和1.4分。在英文–德文的证明中，我们也显示了使用 Llama 2 chat 模型时可以抑制错误翻译，这证明了这些方法的应用性。我们在 GitHub 上发布了源代码，请参考 <a target="_blank" rel="noopener" href="https://github.com/ZurichNLP/ContraDecode">https://github.com/ZurichNLP/ContraDecode</a>。<details>
<summary>Abstract</summary>
Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models. In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions. In a proof of concept on English--German, we also show that we can suppress off-target translations with the Llama 2 chat models, demonstrating the applicability of the method to machine translation with LLMs. We release our source code at https://github.com/ZurichNLP/ContraDecode.
</details>
<details>
<summary>摘要</summary>
幻觉和目标翻译仍然是机器翻译中的未解决问题，特别是对于low-resource语言和大量多语言模型。在这篇论文中，我们介绍了一些方法来减少这两种失败情况，无需重新训练或外部模型。在源相似搜索中，我们寻找一个翻译，可以在正确的输入下被证明，但是在随机输入段下被证明是不可能的，我们假设幻觉将会与随机输入段一样可能。在语言相似搜索中，我们寻找一个翻译，可以在正确的语言指示符下被证明，但是在错误的语言指示符下被证明是不可能的。在M2M-100（418M）和SMaLL-100上进行了实验，我们发现这些方法可以有效地降低幻觉和目标翻译，提高chrF2的平均分数为1.7和1.4点。在一个证明性的英文-德语实验中，我们也示出了使用LLMs（大量多语言模型）可以降低幻觉翻译。我们在 GitHub 上发布了我们的源代码，请参考https://github.com/ZurichNLP/ContraDecode。
</details></li>
</ul>
<hr>
<h2 id="Can-Whisper-perform-speech-based-in-context-learning"><a href="#Can-Whisper-perform-speech-based-in-context-learning" class="headerlink" title="Can Whisper perform speech-based in-context learning"></a>Can Whisper perform speech-based in-context learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07081">http://arxiv.org/abs/2309.07081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyin Wang, Chao-Han Huck Yang, Ji Wu, Chao Zhang</li>
<li>for: 这个论文 investigate OpenAI Whisper 自动语音识别（ASR）模型的上下文学习能力。</li>
<li>methods: 提出了一种基于语音的上下文学习（SICL）方法，可以在测试时进行适应，并且只需要一小部分标注的语音样本，不需要梯度下降。</li>
<li>results: 对中文方言进行语言级别适应实验，结果显示可以在隔离单词ASR中实现了 considable 的相对WRR（词错率）减少，最高达36.4%。<details>
<summary>Abstract</summary>
This paper investigates the in-context learning abilities of the Whisper automatic speech recognition (ASR) models released by OpenAI. A novel speech-based in-context learning (SICL) approach is proposed for test-time adaptation, which can reduce the word error rates (WERs) with only a small number of labelled speech samples without gradient descent. Language-level adaptation experiments using Chinese dialects showed that when applying SICL to isolated word ASR, consistent and considerable relative WER reductions can be achieved using Whisper models of any size on two dialects, which is on average 32.3%. A k-nearest-neighbours-based in-context example selection technique can be applied to further improve the efficiency of SICL, which can increase the average relative WER reduction to 36.4%. The findings are verified using speaker adaptation or continuous speech recognition tasks, and both achieved considerable relative WER reductions. Detailed quantitative analyses are also provided to shed light on SICL's adaptability to phonological variances and dialect-specific lexical nuances.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SafetyBench-Evaluating-the-Safety-of-Large-Language-Models-with-Multiple-Choice-Questions"><a href="#SafetyBench-Evaluating-the-Safety-of-Large-Language-Models-with-Multiple-Choice-Questions" class="headerlink" title="SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions"></a>SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07045">http://arxiv.org/abs/2309.07045</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-coai/safetybench">https://github.com/thu-coai/safetybench</a></li>
<li>paper_authors: Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang, Chong Long, Xiao Liu, Xuanyu Lei, Jie Tang, Minlie Huang</li>
<li>for: The paper is written to evaluate the safety of Large Language Models (LLMs) and to provide a comprehensive benchmark for assessing their safety.</li>
<li>methods: The paper presents SafetyBench, a benchmark that includes 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns, both in Chinese and English.</li>
<li>results: The paper reports the results of extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings, showing a substantial performance advantage for GPT-4 over its counterparts, and highlighting the need for further improvement in the safety of current LLMs.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了评估大语言模型（LLMs）的安全性而写的。</li>
<li>methods: 论文提出了 SafetyBench，一个包含11,435个多选问题，涵盖7种安全问题类型的完整的标准套件。</li>
<li>results: 论文公布了25种中文和英文 LLMS 在零shot和几 shot设置下的广泛测试结果，显示 GPT-4 在其他模型中表现出优异的性能，并且现有 LLMS 的安全性还有很大的改进空间。<details>
<summary>Abstract</summary>
With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns. Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs. Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs. In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages. Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs. We believe SafetyBench will enable fast and comprehensive evaluation of LLMs' safety, and foster the development of safer LLMs. Data and evaluation guidelines are available at https://github.com/thu-coai/SafetyBench. Submission entrance and leaderboard are available at https://llmbench.ai/safety.
</details>
<details>
<summary>摘要</summary>
随着大型语言模型（LLMs）的快速发展，关注其安全问题的注意力也在不断增加。因此，评估LLMs的安全性成为了推广其应用的重要任务。然而，没有全面的安全评估标准，使得评估和改进LLMs的安全性受到了很大的阻碍。在这篇文章中，我们提出了一个名为SafetyBench的全面的安全评估标准，它包含11,435个多选问题，涵盖了7种安全问题的多样化分类。另外，SafetyBench还包含了中文和英文数据，以便在两种语言下进行评估。我们对25个流行的中文和英文LLMs进行了zero-shot和few-shot测试，发现GPT-4在这些测试中表现出了显著的性能优势，而目前的LLMs仍有很大的改进空间。我们认为SafetyBench将为LLMs的安全评估提供快速和全面的评估机制，并促进更安全的LLMs的发展。数据和评估指南可以在https://github.com/thu-coai/SafetyBench中找到，评估入口和排名可以在https://llmbench.ai/safety中找到。
</details></li>
</ul>
<hr>
<h2 id="Beyond-original-Research-Articles-Categorization-via-NLP"><a href="#Beyond-original-Research-Articles-Categorization-via-NLP" class="headerlink" title="Beyond original Research Articles Categorization via NLP"></a>Beyond original Research Articles Categorization via NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07020">http://arxiv.org/abs/2309.07020</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rturrisige/textclassification">https://github.com/rturrisige/textclassification</a></li>
<li>paper_authors: Rosanna Turrisi</li>
<li>for: 这个研究是为了提出一种新的文本分类方法，用于科学文献中未知类别的识别，使用自然语言处理技术。</li>
<li>methods: 研究使用了预训练语言模型SciBERT，从ArXiv数据集中提取了抽象的有意义表示。文本分类使用K-Means算法，并根据Silhouette分数确定最佳分数。</li>
<li>results: 结果表明，提出的方法可以更有效地捕捉摘要中的主题信息，与传统的arXiv标签系统相比，导致改进的文本分类。该方法可能用于更好地导航和推荐科研论文。<details>
<summary>Abstract</summary>
This work proposes a novel approach to text categorization -- for unknown categories -- in the context of scientific literature, using Natural Language Processing techniques. The study leverages the power of pre-trained language models, specifically SciBERT, to extract meaningful representations of abstracts from the ArXiv dataset. Text categorization is performed using the K-Means algorithm, and the optimal number of clusters is determined based on the Silhouette score. The results demonstrate that the proposed approach captures subject information more effectively than the traditional arXiv labeling system, leading to improved text categorization. The approach offers potential for better navigation and recommendation systems in the rapidly growing landscape of scientific research literature.
</details>
<details>
<summary>摘要</summary>
这个研究提出了一种新的文本分类方法，用于未知类别的科学文献中，使用自然语言处理技术。研究利用了预训练语言模型，具体来说是 SciBERT，来提取抽象文本中意义的表示。文本分类使用K-Means算法，并根据Silhouette分数确定最佳分区数。结果表明，提出的方法能够更有效地捕捉报告中的主题信息，从而改善文本分类。该方法可能为科学研究文献领域中的浏览和推荐系统带来改善。
</details></li>
</ul>
<hr>
<h2 id="OYXOY-A-Modern-NLP-Test-Suite-for-Modern-Greek"><a href="#OYXOY-A-Modern-NLP-Test-Suite-for-Modern-Greek" class="headerlink" title="OYXOY: A Modern NLP Test Suite for Modern Greek"></a>OYXOY: A Modern NLP Test Suite for Modern Greek</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07009">http://arxiv.org/abs/2309.07009</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konstantinos Kogkalidis, Stergios Chatzikyriakidis, Eirini Chrysovalantou Giannikouri, Vassiliki Katsouli, Christina Klironomou, Christina Koula, Dimitris Papadakis, Thelka Pasparaki, Erofili Psaltaki, Efthymia Sakellariou, Hara Soupiona</li>
<li>for: 这paper的目的是为希腊自然语言处理（Greek NLP）领域开发一个语言学原则驱动的技术相关评估集。</li>
<li>methods: 这paper使用了两个创新，即在推理任务中标记所有可能的推理标签，以及使用ChatGPT作为语言中立解析器将字典式现代希腊语转换成结构化格式，从而生成其他三个任务。</li>
<li>results: 这paper的实验结果表明了这些任务的挑战性，并证明了希腊NPLEcosystem需要迅速进步，以与当代主流研究保持 pace。<details>
<summary>Abstract</summary>
This paper serves as a foundational step towards the development of a linguistically motivated and technically relevant evaluation suite for Greek NLP. We initiate this endeavor by introducing four expert-verified evaluation tasks, specifically targeted at natural language inference, word sense disambiguation (through example comparison or sense selection) and metaphor detection. More than language-adapted replicas of existing tasks, we contribute two innovations which will resonate with the broader resource and evaluation community. Firstly, our inference dataset is the first of its kind, marking not just \textit{one}, but rather \textit{all} possible inference labels, accounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages. Using ChatGPT as a language-neutral parser, we transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other three tasks through simple projections. Alongside each task, we conduct experiments using currently available state of the art machinery. Our experimental baselines affirm the challenging nature of our tasks and highlight the need for expedited progress in order for the Greek NLP ecosystem to keep pace with contemporary mainstream research.
</details>
<details>
<summary>摘要</summary>
Firstly, our inference dataset is the first of its kind, marking all possible inference labels, taking into account possible shifts due to ambiguity or polysemy. Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages. We use ChatGPT as a language-neutral parser to transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other three tasks through simple projections.We conduct experiments using currently available state-of-the-art machinery alongside each task. Our experimental baselines show that the tasks are challenging and highlight the need for expedited progress in the Greek NLP ecosystem to keep pace with contemporary mainstream research.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Contrast-Consistent-Ranking-with-Language-Models"><a href="#Unsupervised-Contrast-Consistent-Ranking-with-Language-Models" class="headerlink" title="Unsupervised Contrast-Consistent Ranking with Language Models"></a>Unsupervised Contrast-Consistent Ranking with Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06991">http://arxiv.org/abs/2309.06991</a></li>
<li>repo_url: None</li>
<li>paper_authors: Niklas Stoehr, Pengxiang Cheng, Jing Wang, Daniel Preotiuc-Pietro, Rajarshi Bhowmik</li>
<li>for: 本研究旨在探讨语言模型中的排序知识，并研究一种基于冲突相关搜寻的排序技术。</li>
<li>methods: 本研究使用了对比稳定搜寻（CCS）方法，并对现有排序方法进行了修改，以使其更适合语言模型的排序任务。</li>
<li>results: 研究发现，使用CCR搜寻技术可以比使用提问技术更好地推理语言模型中的排序知识，并且可以与更大的语言模型进行比较。<details>
<summary>Abstract</summary>
Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks. For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank reviews by sentiment. Recent work focuses on pairwise, pointwise, and listwise prompting techniques to elicit a language model's ranking knowledge. However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce. This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS). The idea is to train a probing model guided by a logical constraint: a model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements. We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent pairwise or listwise comparisons. To this end, we extend the binary CCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking methods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression objective. Our results confirm that, for the same language model, CCR probing outperforms prompting and even performs on a par with prompting much larger language models.
</details>
<details>
<summary>摘要</summary>
language models 包含排名知识，是解决 context 排名任务的强大解决方案。例如，它们可能具有国家大小的参数知识或可以根据 sentiment 排序评论。 current work 注重 pairwise、pointwise 和 listwise 提问技术来引出语言模型的排名知识。然而，我们发现，即使通过精心调整和限定解码，提问技术可能不一定是自我一致的。这种情况 motivates us 寻找一种不同的方法，它是基于无监督探测方法 called Contrast-Consistent Search (CCS)。这个想法是训练一个探测模型，使其的表示符和其否则都被映射到冲突真假极点一致的多个声明中。我们假设这种限制也适用于排名任务，其中所有项都是通过一致的多个比较关系联系在一起。为此，我们将 binary CCS 方法扩展到 Contrast-Consistent Ranking (CCR)，并采用现有的排名方法，如 Max-Margin Loss、Triplet Loss 和 Ordinal Regression 目标。我们的结果表明，使用 CCR probing，Language model 的表达能力相对较强，甚至可以与更大的语言模型相比。
</details></li>
</ul>
<hr>
<h2 id="Remote-Inference-of-Cognitive-Scores-in-ALS-Patients-Using-a-Picture-Description"><a href="#Remote-Inference-of-Cognitive-Scores-in-ALS-Patients-Using-a-Picture-Description" class="headerlink" title="Remote Inference of Cognitive Scores in ALS Patients Using a Picture Description"></a>Remote Inference of Cognitive Scores in ALS Patients Using a Picture Description</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06989">http://arxiv.org/abs/2309.06989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carla Agurto, Guillermo Cecchi, Bo Wen, Ernest Fraenkel, James Berry, Indu Navar, Raquel Norel</li>
<li>For: The paper focuses on detecting cognitive impairment in individuals with Amyotrophic Lateral Sclerosis (ALS) using a digital version of the Edinburgh Cognitive and Behavioral ALS Screen (ECAS) test.* Methods: The study uses a remote testing approach where participants (ALS and non-ALS) describe a pool of pictures with complex scenes on their computer at home. The study extracts linguistic and acoustic features from the speech samples and inputs them into linear regression models to predict ECAS sub-scores and the total score.* Results: The study finds that speech samples from the picture description are reliable enough to predict the ECAS subs-scores, achieving statistically significant Spearman correlation values between 0.32 and 0.51 for the model’s performance using 10-fold cross-validation.Here is the information in Simplified Chinese text:* For: 这个研究旨在检测阿尔茨海默病患者的认知障碍。* Methods: 研究使用了远程测试方法，参与者（阿尔茨海默病患者和非阿尔茨海默病患者）在家中用计算机描述复杂场景的图片。研究提取了语言和听音特征，并将其输入到线性回归模型中预测ECAS子分数和总分数。* Results: 研究发现，图片描述的speech样本可靠地预测ECAS子分数，实现了 statistically significant的Spearman相关值（0.32-0.51）using 10-fold cross-validation。<details>
<summary>Abstract</summary>
Amyotrophic lateral sclerosis is a fatal disease that not only affects movement, speech, and breath but also cognition. Recent studies have focused on the use of language analysis techniques to detect ALS and infer scales for monitoring functional progression. In this paper, we focused on another important aspect, cognitive impairment, which affects 35-50% of the ALS population. In an effort to reach the ALS population, which frequently exhibits mobility limitations, we implemented the digital version of the Edinburgh Cognitive and Behavioral ALS Screen (ECAS) test for the first time. This test which is designed to measure cognitive impairment was remotely performed by 56 participants from the EverythingALS Speech Study. As part of the study, participants (ALS and non-ALS) were asked to describe weekly one picture from a pool of many pictures with complex scenes displayed on their computer at home. We analyze the descriptions performed within +/- 60 days from the day the ECAS test was administered and extract different types of linguistic and acoustic features. We input those features into linear regression models to infer 5 ECAS sub-scores and the total score. Speech samples from the picture description are reliable enough to predict the ECAS subs-scores, achieving statistically significant Spearman correlation values between 0.32 and 0.51 for the model's performance using 10-fold cross-validation.
</details>
<details>
<summary>摘要</summary>
在这个研究中，参与者（ALS和非ALS）被要求在家中电脑上显示出复杂的场景中的一幅照片，然后描述这幅照片。我们分析了这些描述的语言和声音特征，并将其输入到线性回授模型中，以预测ECAS子Score和总分。我们发现，这些语言和声音特征可以预测ECAS子Score的表现，得到了 statistically significant 的Spearman相关值（0.32-0.51），使用10-fold横推验。
</details></li>
</ul>
<hr>
<h2 id="Auto-Regressive-Next-Token-Predictors-are-Universal-Learners"><a href="#Auto-Regressive-Next-Token-Predictors-are-Universal-Learners" class="headerlink" title="Auto-Regressive Next-Token Predictors are Universal Learners"></a>Auto-Regressive Next-Token Predictors are Universal Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06979">http://arxiv.org/abs/2309.06979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eran Malach</li>
<li>for: 这个论文主要研究了自然语言处理领域中的语言模型，具体来说是通过预测下一个字符来实现语言模型的逻辑和数学逻辑能力。</li>
<li>methods: 该论文使用了自然语言处理中常见的预测下一个字符的方法，并通过分析这些方法的复杂性来理解语言模型的能力。</li>
<li>results: 实验结果表明，使用了线性预测和浅层多层感知机（MLP）等简单方法可以实现非rivial的文本生成和数学任务，而这些方法都是通过预测下一个字符来训练的。这些结果表明，自然语言处理领域中语言模型的能力主要归功于自动预测下一个字符的训练方法，而不是特定的架构选择。<details>
<summary>Abstract</summary>
Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks. Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction. In this work, we present a theoretical framework for studying auto-regressive next-token predictors. We demonstrate that even simple models such as linear next-token predictors, trained on Chain-of-Thought (CoT) data, can approximate any function efficiently computed by a Turing machine. We introduce a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity. Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks. Our results demonstrate that the power of language models can be attributed, to a great extent, to the auto-regressive next-token training scheme, and not necessarily to a particular choice of architecture.
</details>
<details>
<summary>摘要</summary>
大型语言模型显示了惊人的逻辑和数学逻辑能力，允许它们解决复杂任务。有趣的是，这些能力来自于在简单任务上训练的下一个元素预测器。在这项工作中，我们提出了一个理论框架，用于研究自动递归下一个元素预测器。我们示出了，即使是简单的模型，如线性下一个元素预测器，也可以高效地计算任何由图灵机计算的函数。我们引入了一个新的复杂度度量——链接复杂度，用于度量在链式思维（CoT）序列中需要用于逼近某个目标函数的中间元素数量，并分析了这种复杂度与其他复杂度之间的交互。最后，我们通过实验表明，简单的下一个元素预测器，如线性网络和浅层多层感知机（MLP），在文本生成和数学任务上表现出非常有趣的表现。我们的结果表明，语言模型的力量可以归结到自动递归下一个元素训练方案，而不是特定的架构选择。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Causal-Disentanglement-Model-for-Dialogue-Emotion-Detection"><a href="#Dynamic-Causal-Disentanglement-Model-for-Dialogue-Emotion-Detection" class="headerlink" title="Dynamic Causal Disentanglement Model for Dialogue Emotion Detection"></a>Dynamic Causal Disentanglement Model for Dialogue Emotion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06928">http://arxiv.org/abs/2309.06928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuting Su, Yichen Wei, Weizhi Nie, Sicheng Zhao, Anan Liu</li>
<li>for: 本研究旨在提高对对话中的情感识别精度，通过将各种隐藏变量分离并分析对话内容的时间accumulation。</li>
<li>methods: 本研究提出了一种基于隐藏变量分离的动态 causal disentanglement模型，利用causal directed acyclic graph (DAG)建立隐藏情感信息与其他观察到的元素之间的相关性。</li>
<li>results: 在对话情感识别任务中，该模型的实验结果表明其比传统方法更高的精度，能够更好地识别对话中的情感变化。<details>
<summary>Abstract</summary>
Emotion detection is a critical technology extensively employed in diverse fields. While the incorporation of commonsense knowledge has proven beneficial for existing emotion detection methods, dialogue-based emotion detection encounters numerous difficulties and challenges due to human agency and the variability of dialogue content.In dialogues, human emotions tend to accumulate in bursts. However, they are often implicitly expressed. This implies that many genuine emotions remain concealed within a plethora of unrelated words and dialogues.In this paper, we propose a Dynamic Causal Disentanglement Model based on hidden variable separation, which is founded on the separation of hidden variables. This model effectively decomposes the content of dialogues and investigates the temporal accumulation of emotions, thereby enabling more precise emotion recognition. First, we introduce a novel Causal Directed Acyclic Graph (DAG) to establish the correlation between hidden emotional information and other observed elements. Subsequently, our approach utilizes pre-extracted personal attributes and utterance topics as guiding factors for the distribution of hidden variables, aiming to separate irrelevant ones. Specifically, we propose a dynamic temporal disentanglement model to infer the propagation of utterances and hidden variables, enabling the accumulation of emotion-related information throughout the conversation. To guide this disentanglement process, we leverage the ChatGPT-4.0 and LSTM networks to extract utterance topics and personal attributes as observed information.Finally, we test our approach on two popular datasets in dialogue emotion detection and relevant experimental results verified the model's superiority.
</details>
<details>
<summary>摘要</summary>
互动感知是一种 kritical technology 在多个领域中广泛应用。然而，对话式感知探测遇到了许多问题和挑战，主要是因为人类自由和对话内容的变化。在对话中，人类情感倾向于累累发展，但它们通常是隐藏的，这意味着许多真正的情感还未被发现。在这篇文章中，我们提出了一个基于隐藏变量分离的动态 causal disentanglement 模型，可以对对话内容进行分解和探索，从而提高感知识别精度。首先，我们提出了一个新的 causal directed acyclic graph (DAG)，用于建立隐藏情感信息和其他观察到的元素之间的相互作用。接着，我们的方法利用预先提取的人际特征和话题的对话概率，将隐藏变量分离为无关的一部分。特别是，我们提出了一个动态时间分离模型，用于推测对话中的变量和隐藏变量的传播，从而在对话中累累发展情感相关信息。为了导引这个分离过程，我们利用 ChatGPT-4.0 和 LSTM 网络提取对话话题和人际特征，以观察到的信息导引分离。总之，我们对两个广泛使用的对话感知探测 datasets 进行了评估，结果显示了我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="Native-Language-Identification-with-Big-Bird-Embeddings"><a href="#Native-Language-Identification-with-Big-Bird-Embeddings" class="headerlink" title="Native Language Identification with Big Bird Embeddings"></a>Native Language Identification with Big Bird Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06923">http://arxiv.org/abs/2309.06923</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sergeykramp/mthesis-bigbird-embeddings">https://github.com/sergeykramp/mthesis-bigbird-embeddings</a></li>
<li>paper_authors: Sergey Kramp, Giovanni Cassani, Chris Emmery</li>
<li>for: 本研究旨在 investigate whether input size is a limiting factor in Native Language Identification (NLI) tasks, and to provide effective and practical alternatives to traditional feature engineering methods.</li>
<li>methods: 本研究使用 Big Bird embeddings 来训练分类器，并 compare 其表现与传统的语言特征工程方法。</li>
<li>results: 研究发现，使用 Big Bird embeddings 可以大幅提高 NLI 模型的表现，并且可以在各种输入长度下保持稳定的性能。<details>
<summary>Abstract</summary>
Native Language Identification (NLI) intends to classify an author's native language based on their writing in another language. Historically, the task has heavily relied on time-consuming linguistic feature engineering, and transformer-based NLI models have thus far failed to offer effective, practical alternatives. The current work investigates if input size is a limiting factor, and shows that classifiers trained using Big Bird embeddings outperform linguistic feature engineering models by a large margin on the Reddit-L2 dataset. Additionally, we provide further insight into input length dependencies, show consistent out-of-sample performance, and qualitatively analyze the embedding space. Given the effectiveness and computational efficiency of this method, we believe it offers a promising avenue for future NLI work.
</details>
<details>
<summary>摘要</summary>
native 语言识别 (NLI) 目标是根据作者写作的语言来分类作者的本土语言。历史上，这个任务曾经依赖于时间消耗的语言特征工程，而 transformer 基本的 NLI 模型未能提供有效、实用的替代方案。当前的研究发现输入大小是限制因素，并表明使用 Big Bird 嵌入 trained 分类器在 Reddit-L2 数据集上表现远胜语言特征工程模型。此外，我们还提供了输入长度的依赖关系和离线性能的分析，以及嵌入空间的Qualitative 分析。由于这种方法的效iveness 和计算效率，我们认为它将成为未来 NLI 工作的有力道路。
</details></li>
</ul>
<hr>
<h2 id="Scaled-Prompt-Tuning-for-Few-Shot-Natural-Language-Generation"><a href="#Scaled-Prompt-Tuning-for-Few-Shot-Natural-Language-Generation" class="headerlink" title="Scaled Prompt-Tuning for Few-Shot Natural Language Generation"></a>Scaled Prompt-Tuning for Few-Shot Natural Language Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06759">http://arxiv.org/abs/2309.06759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ting Hu, Christoph Meinel, Haojin Yang</li>
<li>for: 这个研究是为了提出 Parameter-Efficient Fine-Tuning (PEFT) 方法，以减少 fine-tuning 大语言模型 (LLMs) 的内存占用和训练成本，并在几次示例中维持或以上性能。</li>
<li>methods: 本研究提出了 Scaled Prompt-Tuning (SPT) 方法，它在几次示例中超过传统 Prompt-Tuning (PT) 方法的性能和数据转移能力，并未增加训练成本。此外，研究还进行了现有 PEFT 方法的比较，发现一些方法在几次示例中表现不佳，特别是在具有挑战性的数据集上。</li>
<li>results: 研究发现，SPT 方法在几次示例中可以维持或以上性能，并且在数据转移时具有更好的数据转移能力。此外，研究还发现了一些现有 PEFT 方法在几次示例中表现不佳，特别是在具有挑战性的数据集上。<details>
<summary>Abstract</summary>
The increasingly Large Language Models (LLMs) demonstrate stronger language understanding and generation capabilities, while the memory demand and computation cost of fine-tuning LLMs on downstream tasks are non-negligible. Besides, fine-tuning generally requires a certain amount of data from individual tasks whilst data collection cost is another issue to consider in real-world applications. In this work, we focus on Parameter-Efficient Fine-Tuning (PEFT) methods for few-shot Natural Language Generation (NLG), which freeze most parameters in LLMs and tune a small subset of parameters in few-shot cases so that memory footprint, training cost, and labeling cost are reduced while maintaining or even improving the performance. We propose a Scaled Prompt-Tuning (SPT) method which surpasses conventional PT with better performance and generalization ability but without an obvious increase in training cost. Further study on intermediate SPT suggests the superior transferability of SPT in few-shot scenarios, providing a recipe for data-deficient and computation-limited circumstances. Moreover, a comprehensive comparison of existing PEFT methods reveals that certain approaches exhibiting decent performance with modest training cost such as Prefix-Tuning in prior study could struggle in few-shot NLG tasks, especially on challenging datasets.
</details>
<details>
<summary>摘要</summary>
LLMs 的增长强大语言理解和生成能力，然而 fine-tuning LLMs 在下游任务中的内存需求和计算成本是非常重要的。此外， fine-tuning 通常需要具体任务的数据量，而数据收集成本是实际应用中的一个问题。在这项工作中，我们关注 Parameter-Efficient Fine-Tuning (PEFT) 方法，以便在几架 Natural Language Generation (NLG) 中减少内存占用量、训练成本和标签成本，保持或者提高性能。我们提出了一种缩放提 prompt-tuning (SPT) 方法，超过了传统的 PT 方法，而无需明显增加训练成本。进一步的研究表明，SPT 在几架 scenarios 中具有更好的转移性，提供了数据缺乏和计算有限的情况下的热门策略。此外，现有的 PEFT 方法的比较表明，某些方法在几架 NLG 任务中，特别是在复杂的 dataset 上，可能会表现出差。
</details></li>
</ul>
<hr>
<h2 id="CONVERSER-Few-Shot-Conversational-Dense-Retrieval-with-Synthetic-Data-Generation"><a href="#CONVERSER-Few-Shot-Conversational-Dense-Retrieval-with-Synthetic-Data-Generation" class="headerlink" title="CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation"></a>CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06748">http://arxiv.org/abs/2309.06748</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miulab/converser">https://github.com/miulab/converser</a></li>
<li>paper_authors: Chao-Wei Huang, Chen-Yu Hsu, Tsu-Yuan Hsu, Chen-An Li, Yun-Nung Chen</li>
<li>for: 本研究旨在提出一种基于对话的密集检索框架，以便在几个示例对话中训练密集检索模型。</li>
<li>methods: 我们利用大语言模型的在场学习能力，将对话查询文本生成自检索集。</li>
<li>results: 我们的提议方法在对话检索评测中表现与完全监督模型相当，表明我们的方法可以在几个示例对话中实现可靠的密集检索。所有代码和生成的数据集可以在 GitHub 上找到。<details>
<summary>Abstract</summary>
Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose CONVERSER, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed CONVERSER achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available at https://github.com/MiuLab/CONVERSER
</details>
<details>
<summary>摘要</summary>
对话搜索提供了一种自然的搜索界面，最近的方法已经在对话搜索中应用了稠密搜索。然而，训练稠密搜索者需要大量的领域内对话数据，这限制了对话稠密搜索的发展，因为充足的领域内对话是昂贵的收集的。在这篇论文中，我们提出了一个名为CONVERSER的框架，用于在最多6个领域对话中训练对话稠密搜索者。我们利用了大型自然语言模型的上下文学习能力，将领域内对话中的段落作为输入，生成对话查询。实验结果表明，我们的CONVERSER可以与完全监督模型相比，在少量对话稠密搜索中实现相似的性能。所有源代码和生成的数据集可以在https://github.com/MiuLab/CONVERSER上下载。
</details></li>
</ul>
<hr>
<h2 id="Simultaneous-Machine-Translation-with-Large-Language-Models"><a href="#Simultaneous-Machine-Translation-with-Large-Language-Models" class="headerlink" title="Simultaneous Machine Translation with Large Language Models"></a>Simultaneous Machine Translation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06706">http://arxiv.org/abs/2309.06706</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minghan Wang, Jinming Zhao, Thuy-Trang Vu, Fatemeh Shiri, Ehsan Shareghi, Gholamreza Haffari</li>
<li>for: 本研究探讨了大语言模型（LLM）在同时翻译（SimulMT）任务中的可行性。</li>
<li>methods: 我们基于传统方法，提出了一种简单 yet effective的混合策略，使得 LLM 可以在 SimulMT 中参与无需额外训练。我们还进行了 Supervised Fine-Tuning（SFT），并在混合全句和前缀句上进行了训练。</li>
<li>results: 我们在使用 Llama2-7B-chat 进行 nine 种语言对的实验中发现，LLM 可以 дости到与专门的 SimulMT 模型相同的翻译质量和延迟。<details>
<summary>Abstract</summary>
Large language models (LLM) have demonstrated their abilities to solve various natural language processing tasks through dialogue-based interactions. For instance, research indicates that LLMs can achieve competitive performance in offline machine translation tasks for high-resource languages. However, applying LLMs to simultaneous machine translation (SimulMT) poses many challenges, including issues related to the training-inference mismatch arising from different decoding patterns. In this paper, we explore the feasibility of utilizing LLMs for SimulMT. Building upon conventional approaches, we introduce a simple yet effective mixture policy that enables LLMs to engage in SimulMT without requiring additional training. Furthermore, after Supervised Fine-Tuning (SFT) on a mixture of full and prefix sentences, the model exhibits significant performance improvements. Our experiments, conducted with Llama2-7B-chat on nine language pairs from the MUST-C dataset, demonstrate that LLM can achieve translation quality and latency comparable to dedicated SimulMT models.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理模型（LLM）已经在对话基于的交互中展示了各种自然语言处理任务的能力。例如，研究表明，LLM可以在高资源语言的机器翻译任务中达到竞争性的性能。然而，将LLM应用于同时机器翻译（SimulMT）存在许多挑战，包括各种训练-推理匹配问题。在这篇论文中，我们探讨了LLM在SimulMT中的可行性。基于传统方法，我们介绍了一种简单 yet有效的混合策略，使得LLM可以不需要额外训练参与SimulMT。此外，通过精心精度训练（SFT）在混合全文和前缀句子上，模型表现出了显著的性能改善。我们的实验，使用Llama2-7B-chat在MUST-C数据集上进行了九种语言对的实验，显示LLM可以达到与专门的SimulMT模型相同的翻译质量和延迟。
</details></li>
</ul>
<hr>
<h2 id="VLSlice-Interactive-Vision-and-Language-Slice-Discovery"><a href="#VLSlice-Interactive-Vision-and-Language-Slice-Discovery" class="headerlink" title="VLSlice: Interactive Vision-and-Language Slice Discovery"></a>VLSlice: Interactive Vision-and-Language Slice Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06703">http://arxiv.org/abs/2309.06703</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/slymane/vlslice">https://github.com/slymane/vlslice</a></li>
<li>paper_authors: Eric Slyman, Minsuk Kahng, Stefan Lee</li>
<li>for: 本研究旨在开发一种可互动的系统，以帮助用户发现 Representation-level 下的凝合性vision-and-language slice，从未标注的图像集中。</li>
<li>methods: 本研究使用大规模预训练，以学习可转移的模型，并通过用户指导的方式，自动发现vision-and-language slice。</li>
<li>results: 在用户研究中（n&#x3D;22），VLSlice能够快速生成多样性凝合性vision-and-language slice，并且发布了这个工具给公众。<details>
<summary>Abstract</summary>
Recent work in vision-and-language demonstrates that large-scale pretraining can learn generalizable models that are efficiently transferable to downstream tasks. While this may improve dataset-scale aggregate metrics, analyzing performance around hand-crafted subgroups targeting specific bias dimensions reveals systemic undesirable behaviors. However, this subgroup analysis is frequently stalled by annotation efforts, which require extensive time and resources to collect the necessary data. Prior art attempts to automatically discover subgroups to circumvent these constraints but typically leverages model behavior on existing task-specific annotations and rapidly degrades on more complex inputs beyond "tabular" data, none of which study vision-and-language models. This paper presents VLSlice, an interactive system enabling user-guided discovery of coherent representation-level subgroups with consistent visiolinguistic behavior, denoted as vision-and-language slices, from unlabeled image sets. We show that VLSlice enables users to quickly generate diverse high-coherency slices in a user study (n=22) and release the tool publicly.
</details>
<details>
<summary>摘要</summary>
This paper introduces VLSlice, an interactive system that enables user-guided discovery of coherent representation-level subgroups with consistent visiolinguistic behavior, or vision-and-language slices, from unlabeled image sets. Our user study (n=22) shows that VLSlice can quickly generate diverse high-coherency slices, and we have released the tool publicly.
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Procedural-Language-Understanding-for-Low-Resource-Languages-A-Case-Study-on-Turkish"><a href="#Benchmarking-Procedural-Language-Understanding-for-Low-Resource-Languages-A-Case-Study-on-Turkish" class="headerlink" title="Benchmarking Procedural Language Understanding for Low-Resource Languages: A Case Study on Turkish"></a>Benchmarking Procedural Language Understanding for Low-Resource Languages: A Case Study on Turkish</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06698">http://arxiv.org/abs/2309.06698</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gglab-ku/turkish-plu">https://github.com/gglab-ku/turkish-plu</a></li>
<li>paper_authors: Arda Uzunoğlu, Gözde Gül Şahin</li>
<li>For: The paper is written for the field of natural language processing, with a focus on procedural natural language understanding (PLU) and its applications in Turkish.* Methods: The paper uses automated translation tools to expand the number of Turkish tutorials on wikiHow, and implements strong baseline models for PLU tasks such as linking actions, goal inference, and summarization using fine-tuned language-specific and multilingual models.* Results: The paper finds that language-specific models consistently outperform their multilingual models by a significant margin across most PLU tasks, and releases the corpus, downstream tasks, and baseline models for future research.<details>
<summary>Abstract</summary>
Understanding procedural natural language (e.g., step-by-step instructions) is a crucial step to execution and planning. However, while there are ample corpora and downstream tasks available in English, the field lacks such resources for most languages. To address this gap, we conduct a case study on Turkish procedural texts. We first expand the number of tutorials in Turkish wikiHow from 2,000 to 52,000 using automated translation tools, where the translation quality and loyalty to the original meaning are validated by a team of experts on a random set. Then, we generate several downstream tasks on the corpus, such as linking actions, goal inference, and summarization. To tackle these tasks, we implement strong baseline models via fine-tuning large language-specific models such as TR-BART and BERTurk, as well as multilingual models such as mBART, mT5, and XLM. We find that language-specific models consistently outperform their multilingual models by a significant margin across most procedural language understanding (PLU) tasks. We release our corpus, downstream tasks and the baseline models with https://github.com/ GGLAB-KU/turkish-plu.
</details>
<details>
<summary>摘要</summary>
理解进程自然语言（例如步骤说明）是执行和规划的关键步骤。然而，当前大多数语言的相关资源却缺乏。为了填补这一空白，我们进行了关于土耳其进程文本的 caso study。我们首先使用自动翻译工具将土耳其wikiHow的教程从2,000个增加到52,000个，并验证翻译质量和原始意义的忠诚性。然后，我们生成了多个下游任务，例如行为连接、目标推理和概要。为了解决这些任务，我们实施了强大的基线模型，包括TR-BART、BERTurk和多语言模型如mBART、mT5和XLM。我们发现语言特定模型在大多数进程自然语言理解（PLU）任务上一般性能较高，与多语言模型相比。我们将我们的资料库、下游任务和基线模型发布在https://github.com/GGLAB-KU/turkish-plu上。
</details></li>
</ul>
<hr>
<h2 id="Statistical-Rejection-Sampling-Improves-Preference-Optimization"><a href="#Statistical-Rejection-Sampling-Improves-Preference-Optimization" class="headerlink" title="Statistical Rejection Sampling Improves Preference Optimization"></a>Statistical Rejection Sampling Improves Preference Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06657">http://arxiv.org/abs/2309.06657</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianqi Liu, Yao Zhao, Rishabh Joshi, Misha Khalman, Mohammad Saleh, Peter J. Liu, Jialu Liu</li>
<li>for: 提高语言模型与人类偏好的对齐，以提高语言模型的性能。</li>
<li>methods: 使用 Reinforcement Learning from Human Feedback (RLHF) 和 Offline Methods such as Sequence Likelihood Calibration (SLiC) 和 Direct Preference Optimization (DPO)，以提高稳定性和扩展性，同时保持竞争性。</li>
<li>results: RSO 可以准确地估计目标优质策略，并在三种不同任务上进行了广泛的实验，证明了 RSO 可以在 LLM 和人类评分者的评价下表现更好。<details>
<summary>Abstract</summary>
Improving the alignment of language models with human preferences remains an active research challenge. Previous approaches have primarily utilized Reinforcement Learning from Human Feedback (RLHF) via online RL methods such as Proximal Policy Optimization (PPO). Recently, offline methods such as Sequence Likelihood Calibration (SLiC) and Direct Preference Optimization (DPO) have emerged as attractive alternatives, offering improvements in stability and scalability while maintaining competitive performance. SLiC refines its loss function using sequence pairs sampled from a supervised fine-tuned (SFT) policy, while DPO directly optimizes language models based on preference data, foregoing the need for a separate reward model. However, the maximum likelihood estimator (MLE) of the target optimal policy requires labeled preference pairs sampled from that policy. DPO's lack of a reward model constrains its ability to sample preference pairs from the optimal policy, and SLiC is restricted to sampling preference pairs only from the SFT policy. To address these limitations, we introduce a novel approach called Statistical Rejection Sampling Optimization (RSO) that aims to source preference data from the target optimal policy using rejection sampling, enabling a more accurate estimation of the optimal policy. We also propose a unified framework that enhances the loss functions used in both SLiC and DPO from a preference modeling standpoint. Through extensive experiments across three diverse tasks, we demonstrate that RSO consistently outperforms both SLiC and DPO on evaluations from both Large Language Model (LLM) and human raters.
</details>
<details>
<summary>摘要</summary>
改善语言模型与人类偏好的对应仍然是当前研究挑战。先前的方法主要使用人类反馈学习（RLHF）的在线RL方法，如距离优化策略（PPO）。在最近，offline方法，如序列可信度调整（SLiC）和直接偏好优化（DPO），作为有力的代替方案而出现。SLiC通过使用监督练好的（SFT）政策来细化损失函数，而DPO直接基于偏好数据来优化语言模型，不需要分离的奖励模型。然而，MLE目标优化政策的最大可能性需要从该政策中标注的偏好对。DPO缺乏奖励模型，因此无法从优化政策中采样偏好对，而SLiC只能从SFT政策中采样偏好对。为解决这些限制，我们提出了一种新的方法 called Statistical Rejection Sampling Optimization（RSO），它通过拒绝采样来源优化政策，以获得更加准确的优化策略。我们还提出了一种统一框架，它可以从偏好模型角度来增强SLiC和DPO的损失函数。通过对三个多样化任务进行广泛的实验，我们证明了RSO在LLM和人类评分者的评价中一直表现优于SLiC和DPO。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/13/cs.CL_2023_09_13/" data-id="clohum95c00akpj883na8h3de" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/13/cs.LG_2023_09_13/" class="article-date">
  <time datetime="2023-09-13T10:00:00.000Z" itemprop="datePublished">2023-09-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/13/cs.LG_2023_09_13/">cs.LG - 2023-09-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Tackling-the-dimensions-in-imaging-genetics-with-CLUB-PLS"><a href="#Tackling-the-dimensions-in-imaging-genetics-with-CLUB-PLS" class="headerlink" title="Tackling the dimensions in imaging genetics with CLUB-PLS"></a>Tackling the dimensions in imaging genetics with CLUB-PLS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07352">http://arxiv.org/abs/2309.07352</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andre Altmann, Ana C Lawry Aguila, Neda Jahanshad, Paul M Thompson, Marco Lorenzi</li>
<li>for: 链接高维数据在两个领域，如遗传学数据和大脑成像数据，以探索这两个领域之间的关系。</li>
<li>methods: 使用Partial Least Squares（PLS）基本框架，称为Cluster-Bootstrap PLS（CLUB-PLS），可以处理高维输入维度在两个领域以及大样本大小。该框架使用cluster bootstrap提供了robust统计量，以确定单个输入特征在两个领域中的有效性。</li>
<li>results: 对33,000名UK Biobank测试者的表面积和 cortical thickness进行了研究，发现了107个遗传因素- Fenotype对，与386个不同的基因相关。大多数这些Loci可以技术上验证：使用 классиclic GWAS或Genome-Wide Inferred Statistics（GWIS），发现85个Loci-Phenotype对超过了遗传学建议的（P&lt;1e-05）阈值。<details>
<summary>Abstract</summary>
A major challenge in imaging genetics and similar fields is to link high-dimensional data in one domain, e.g., genetic data, to high dimensional data in a second domain, e.g., brain imaging data. The standard approach in the area are mass univariate analyses across genetic factors and imaging phenotypes. That entails executing one genome-wide association study (GWAS) for each pre-defined imaging measure. Although this approach has been tremendously successful, one shortcoming is that phenotypes must be pre-defined. Consequently, effects that are not confined to pre-selected regions of interest or that reflect larger brain-wide patterns can easily be missed. In this work we introduce a Partial Least Squares (PLS)-based framework, which we term Cluster-Bootstrap PLS (CLUB-PLS), that can work with large input dimensions in both domains as well as with large sample sizes. One key factor of the framework is to use cluster bootstrap to provide robust statistics for single input features in both domains. We applied CLUB-PLS to investigating the genetic basis of surface area and cortical thickness in a sample of 33,000 subjects from the UK Biobank. We found 107 genome-wide significant locus-phenotype pairs that are linked to 386 different genes. We found that a vast majority of these loci could be technically validated at a high rate: using classic GWAS or Genome-Wide Inferred Statistics (GWIS) we found that 85 locus-phenotype pairs exceeded the genome-wide suggestive (P<1e-05) threshold.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在生物遗传学和相关领域是将一维数据（例如遗传数据）与另一维数据（例如脑成像数据）相关联。现有的标准方法在这个领域是在每个预先定义的成像测量方面执行一次全 genomic association study (GWAS)。although this approach has been incredibly successful, one shortcoming is that phenotypes must be predefined. As a result, effects that are not limited to predefined regions of interest or that reflect larger brain-wide patterns can easily be overlooked.在这种工作中，我们引入了一种基于半最似方法的框架，我们称之为Cluster-Bootstrap PLS (CLUB-PLS)，它可以处理大量的输入维度在两个领域以及大样本大小。一个关键因素是使用cluster bootstrap提供了 robust的统计参数 для单个输入特征在两个领域。我们使用CLUB-PLS investigated the genetic basis of surface area and cortical thickness in a sample of 33,000 subjects from the UK Biobank. We found 107 genome-wide significant locus-phenotype pairs that are linked to 386 different genes. We found that a vast majority of these loci could be technically validated at a high rate: using classic GWAS or Genome-Wide Inferred Statistics (GWIS) we found that 85 locus-phenotype pairs exceeded the genome-wide suggestive (P<1e-05) threshold.Translation notes:* "一维数据" and "另一维数据" are used to refer to the two different types of data, i.e., genetic data and brain imaging data.* "遗传数据" and "成像数据" are used to refer to the two types of data, respectively.* "预先定义" means "pre-defined" in English.* "phenotypes" are referred to as "特征" in Chinese.* "CLUB-PLS" is a combination of "Cluster-Bootstrap PLS" and "遗传基因" in Chinese, which is used to refer to the framework introduced in the text.* "Genome-wide suggestive" is not a direct translation of any specific Chinese phrase, but it is used to refer to the threshold of P<1e-05 used in the study.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Learning-of-PDEs-via-Taylor-Expansion-and-Sparse-Decomposition-into-Value-and-Fourier-Domains"><a href="#Efficient-Learning-of-PDEs-via-Taylor-Expansion-and-Sparse-Decomposition-into-Value-and-Fourier-Domains" class="headerlink" title="Efficient Learning of PDEs via Taylor Expansion and Sparse Decomposition into Value and Fourier Domains"></a>Efficient Learning of PDEs via Taylor Expansion and Sparse Decomposition into Value and Fourier Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07344">http://arxiv.org/abs/2309.07344</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Nasim, Yexiang Xue</li>
<li>for: 加速Partial Differential Equations（PDEs）学习，以提速科学发现。</li>
<li>methods: 利用随机投影加速PDE更新，并可以拓宽应用范围。</li>
<li>results: 实验证明，提议的Reel可以在压缩数据 circumstance下减少70-98%的训练时间，而无损失模型质量。<details>
<summary>Abstract</summary>
Accelerating the learning of Partial Differential Equations (PDEs) from experimental data will speed up the pace of scientific discovery. Previous randomized algorithms exploit sparsity in PDE updates for acceleration. However such methods are applicable to a limited class of decomposable PDEs, which have sparse features in the value domain. We propose Reel, which accelerates the learning of PDEs via random projection and has much broader applicability. Reel exploits the sparsity by decomposing dense updates into sparse ones in both the value and frequency domains. This decomposition enables efficient learning when the source of the updates consists of gradually changing terms across large areas (sparse in the frequency domain) in addition to a few rapid updates concentrated in a small set of "interfacial" regions (sparse in the value domain). Random projection is then applied to compress the sparse signals for learning. To expand the model applicability, Taylor series expansion is used in Reel to approximate the nonlinear PDE updates with polynomials in the decomposable form. Theoretically, we derive a constant factor approximation between the projected loss function and the original one with poly-logarithmic number of projected dimensions. Experimentally, we provide empirical evidence that our proposed Reel can lead to faster learning of PDE models (70-98% reduction in training time when the data is compressed to 1% of its original size) with comparable quality as the non-compressed models.
</details>
<details>
<summary>摘要</summary>
加速部分泛函方程（PDE）从实验数据学习会加速科学发现的速度。先前的随机算法利用PDE更新中的稀疏性进行加速。然而，这些方法只适用于有限个可分解PDE中的稀疏特征。我们提议Reel，它通过随机投影加速PDE学习，并具有远更广泛的应用可能性。Reel利用更新中的稀疏特征进行稀疏更新的分解，从而实现高效的学习。当更新来源包括大面积上逐渐变化的项目（稀疏在频域）以及一些集中在小范围内的快速更新（稀疏在值域）时，Reel可以高效地学习PDE模型。随机投影后，可以压缩稀疏信号进行学习。为扩展模型的应用范围，Reel使用泰勒级数展开来近似非线性PDE更新为多项式形式。理论上，我们得出了原始维度的几乎常量因子近似关系。实验证明，我们提议的Reel可以在压缩数据时对PDE模型进行更快的学习（70-98%减少训练时间），并且与非压缩模型的质量相似。
</details></li>
</ul>
<hr>
<h2 id="User-Training-with-Error-Augmentation-for-Electromyogram-based-Gesture-Classification"><a href="#User-Training-with-Error-Augmentation-for-Electromyogram-based-Gesture-Classification" class="headerlink" title="User Training with Error Augmentation for Electromyogram-based Gesture Classification"></a>User Training with Error Augmentation for Electromyogram-based Gesture Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07289">http://arxiv.org/abs/2309.07289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunus Bicer, Niklas Smedemark-Margulies, Basak Celik, Elifnur Sunger, Ryan Orendorff, Stephanie Naufel, Tales Imbiriba, Deniz Erdo{ğ}mu{ş}, Eugene Tunik, Mathew Yarossi</li>
<li>for: 这个研究是为了开发一个基于Surface electromyographic (sEMG)的实时控制系统，以便通过识别手势来控制用户界面。</li>
<li>methods: 这个系统使用了机器学习算法来实时识别手势，并将sEMG数据流入这个算法中。在训练阶段，参与者获得了三种反馈：正确反馈、 modificated 反馈和无反馈。</li>
<li>results: 实验结果显示，相比基准值，modified 反馈 condtion 能够导致更高的精度和更好的手势类别分类。这些结果表明，在一个 gamified 用户界面中，通过实时反馈和手势识别的修改，可以实现INTUITIVE、快速和精度的任务取得。<details>
<summary>Abstract</summary>
We designed and tested a system for real-time control of a user interface by extracting surface electromyographic (sEMG) activity from eight electrodes in a wrist-band configuration. sEMG data were streamed into a machine-learning algorithm that classified hand gestures in real-time. After an initial model calibration, participants were presented with one of three types of feedback during a human-learning stage: veridical feedback, in which predicted probabilities from the gesture classification algorithm were displayed without alteration, modified feedback, in which we applied a hidden augmentation of error to these probabilities, and no feedback. User performance was then evaluated in a series of minigames, in which subjects were required to use eight gestures to manipulate their game avatar to complete a task. Experimental results indicated that, relative to baseline, the modified feedback condition led to significantly improved accuracy and improved gesture class separation. These findings suggest that real-time feedback in a gamified user interface with manipulation of feedback may enable intuitive, rapid, and accurate task acquisition for sEMG-based gesture recognition applications.
</details>
<details>
<summary>摘要</summary>
我们设计并测试了一个实时控制用户界面的系统，通过抽取背部电 MYO 活动的八个电极配置。 MYO 数据流入一个机器学习算法，并在实时进行手势分类。在人类学习阶段，参与者接受了三种反馈：正确反馈、修改反馈和无反馈。在不同反馈情况下，参与者在一系列小游戏中使用八种手势来控制游戏角色完成任务。实验结果表明，相比基eline，修改反馈情况下的准确率和手势分类率显著提高。这些发现表明，在实时反馈的 gamified 用户界面中，可以通过手势识别应用的修改反馈来快速、准确地学习任务。
</details></li>
</ul>
<hr>
<h2 id="Simultaneous-inference-for-generalized-linear-models-with-unmeasured-confounders"><a href="#Simultaneous-inference-for-generalized-linear-models-with-unmeasured-confounders" class="headerlink" title="Simultaneous inference for generalized linear models with unmeasured confounders"></a>Simultaneous inference for generalized linear models with unmeasured confounders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07261">http://arxiv.org/abs/2309.07261</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jin-Hong Du, Larry Wasserman, Kathryn Roeder</li>
<li>for:  This paper is written for researchers and practitioners in the field of genomic studies, particularly those interested in large-scale hypothesis testing and confounding effect adjustment.</li>
<li>methods:  The paper proposes a unified statistical estimation and inference framework for multivariate generalized linear models in the presence of confounding effects. The method leverages orthogonal structures and integrates linear projections into three key stages: separating marginal and uncorrelated confounding effects, jointly estimating latent factors and primary effects, and incorporating projected and weighted bias-correction steps for hypothesis testing.</li>
<li>results:  The paper establishes various identification conditions and non-asymptotic error bounds, and shows effective Type-I error control of asymptotic $z$-tests. Numerical experiments demonstrate that the proposed method controls the false discovery rate and is more powerful than alternative methods. The paper also demonstrates the suitability of adjusting confounding effects when significant covariates are absent from the model using single-cell RNA-seq counts from two groups of samples.<details>
<summary>Abstract</summary>
Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps for hypothesis testing. Theoretically, we establish various effects' identification conditions and non-asymptotic error bounds. We show effective Type-I error control of asymptotic $z$-tests as sample and response sizes approach infinity. Numerical experiments demonstrate that the proposed method controls the false discovery rate by the Benjamini-Hochberg procedure and is more powerful than alternative methods. By comparing single-cell RNA-seq counts from two groups of samples, we demonstrate the suitability of adjusting confounding effects when significant covariates are absent from the model.
</details>
<details>
<summary>摘要</summary>
tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps for hypothesis testing. Theoretically, we establish various effects' identification conditions and non-asymptotic error bounds. We show effective Type-I error control of asymptotic $z$-tests as sample and response sizes approach infinity. Numerical experiments demonstrate that the proposed method controls the false discovery rate by the Benjamini-Hochberg procedure and is more powerful than alternative methods. By comparing single-cell RNA-seq counts from two groups of samples, we demonstrate the suitability of adjusting confounding effects when significant covariates are absent from the model.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="All-you-need-is-spin-SU-2-equivariant-variational-quantum-circuits-based-on-spin-networks"><a href="#All-you-need-is-spin-SU-2-equivariant-variational-quantum-circuits-based-on-spin-networks" class="headerlink" title="All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks"></a>All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07250">http://arxiv.org/abs/2309.07250</a></li>
<li>repo_url: None</li>
<li>paper_authors: Richard D. P. East, Guillermo Alonso-Linaje, Chae-Yeun Park</li>
<li>for: 这个论文的目的是提出使用矩阵网络来构建SU(2)对称的量子电路 ansatz，以实现量子变分析算法的高效运行。</li>
<li>methods: 这个论文使用矩阵网络来构建SU(2)对称的量子电路 ansatz，并证明其与其他已知的构建方法相等。</li>
<li>results: 该论文的实验结果表明，使用这种SU(2)对称的量子电路 ansatz可以提高量子变分析算法的性能，这表明它们可以应用于更多的实际问题。<details>
<summary>Abstract</summary>
Variational algorithms require architectures that naturally constrain the optimisation space to run efficiently. In geometric quantum machine learning, one achieves this by encoding group structure into parameterised quantum circuits to include the symmetries of a problem as an inductive bias. However, constructing such circuits is challenging as a concrete guiding principle has yet to emerge. In this paper, we propose the use of spin networks, a form of directed tensor network invariant under a group transformation, to devise SU(2) equivariant quantum circuit ans\"atze -- circuits possessing spin rotation symmetry. By changing to the basis that block diagonalises SU(2) group action, these networks provide a natural building block for constructing parameterised equivariant quantum circuits. We prove that our construction is mathematically equivalent to other known constructions, such as those based on twirling and generalised permutations, but more direct to implement on quantum hardware. The efficacy of our constructed circuits is tested by solving the ground state problem of SU(2) symmetric Heisenberg models on the one-dimensional triangular lattice and on the Kagome lattice. Our results highlight that our equivariant circuits boost the performance of quantum variational algorithms, indicating broader applicability to other real-world problems.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose using spin networks, a form of directed tensor network that is invariant under group transformation, to develop SU(2) equivariant quantum circuit ansätze. These circuits possess spin rotation symmetry. By changing to a basis that block diagonalizes the SU(2) group action, these networks provide a natural building block for constructing parameterized equivariant quantum circuits.We prove that our construction is mathematically equivalent to other known constructions, such as those based on twirling and general permutations, but is more direct to implement on quantum hardware. The efficacy of our constructed circuits is tested by solving the ground state problem of SU(2) symmetric Heisenberg models on the one-dimensional triangular lattice and on the Kagome lattice. Our results show that our equivariant circuits improve the performance of quantum variational algorithms, indicating broader applicability to other real-world problems.
</details></li>
</ul>
<hr>
<h2 id="EarthPT-a-foundation-model-for-Earth-Observation"><a href="#EarthPT-a-foundation-model-for-Earth-Observation" class="headerlink" title="EarthPT: a foundation model for Earth Observation"></a>EarthPT: a foundation model for Earth Observation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07207">http://arxiv.org/abs/2309.07207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael J. Smith, Luke Fleming, James E. Geach</li>
<li>for: 该研究开发了一种 Earth Observation（EO）预训transformer，即 EarthPT，用于预测未来地表反射特征。</li>
<li>methods: 该模型使用了700万参数的解码变换器基础模型，通过自我supervised方式进行训练，并特地针对地观用 caso设计。</li>
<li>results: 研究表明，EarthPT 是一个高效的预测器，可以准确预测未来地表反射特征，包括 Normalised Difference Vegetation Index（NDVI）的进化。这些预测结果在5个月的测试集期间 Typical error 约为0.05（在自然范围内的 -1到1 之间），超过了基于历史平均值的简单阶段模型。此外，研究还发现，EarthPT 学习的嵌入在 Semantically meaningful information 上，可以用于下游任务，如高精度、动态地用分类。<details>
<summary>Abstract</summary>
We introduce EarthPT -- an Earth Observation (EO) pretrained transformer. EarthPT is a 700 million parameter decoding transformer foundation model trained in an autoregressive self-supervised manner and developed specifically with EO use-cases in mind. We demonstrate that EarthPT is an effective forecaster that can accurately predict future pixel-level surface reflectances across the 400-2300 nm range well into the future. For example, forecasts of the evolution of the Normalised Difference Vegetation Index (NDVI) have a typical error of approximately 0.05 (over a natural range of -1 -> 1) at the pixel level over a five month test set horizon, out-performing simple phase-folded models based on historical averaging. We also demonstrate that embeddings learnt by EarthPT hold semantically meaningful information and could be exploited for downstream tasks such as highly granular, dynamic land use classification. Excitingly, we note that the abundance of EO data provides us with -- in theory -- quadrillions of training tokens. Therefore, if we assume that EarthPT follows neural scaling laws akin to those derived for Large Language Models (LLMs), there is currently no data-imposed limit to scaling EarthPT and other similar `Large Observation Models.'
</details>
<details>
<summary>摘要</summary>
我们介绍 EarthPT -- 一种地球观测（EO）预训练的转换器。 EarthPT 是一个 700 万参数的解码转换器基模型，通过自我授课的自然语言模式进行了专门为 EO 应用场景设计和训练。我们展示了 EarthPT 是一个准确预测未来像素级表面反射的有效预测器，可以在 400-2300 nm 范围内准确预测未来数个月内的表面反射。例如，NDVI（Normalised Difference Vegetation Index）的发展趋势预测 Error 通常在 pixel 级别为 approximately 0.05（在自然范围内），而 phase-folded 模型基于历史平均值的预测 Error 较高。我们还示出了 EarthPT 学习的嵌入都具有Semantically meaningful information，可以用于下游任务，如高精度、动态地球用途分类。另外，由于 EO 数据的备受丰富，我们可以在理论上利用 quadrillions 的training tokens，根据 Large Language Models（LLMs）的神经Scaling 法则，无限制地扩展 EarthPT 和其他类似的 Large Observation Models。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-via-Subgroup-Mixup-for-Improving-Fairness"><a href="#Data-Augmentation-via-Subgroup-Mixup-for-Improving-Fairness" class="headerlink" title="Data Augmentation via Subgroup Mixup for Improving Fairness"></a>Data Augmentation via Subgroup Mixup for Improving Fairness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07110">http://arxiv.org/abs/2309.07110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Madeline Navarro, Camille Little, Genevera I. Allen, Santiago Segarra</li>
<li>for: 提高群体公平性，因为许多实际应用中机器学习系统会出现因为社会偏见而导致的各个群体之间的偏见。</li>
<li>methods: 使用对应 subgroup 的 pairwise mixup 数据扩展方法，以促进公平和准确的决策边界 для所有子群体。</li>
<li>results: 通过对 simulated 和实际数据进行比较，我们的方法可以实现公平的结果，同时保持或提高准确性。<details>
<summary>Abstract</summary>
In this work, we propose data augmentation via pairwise mixup across subgroups to improve group fairness. Many real-world applications of machine learning systems exhibit biases across certain groups due to under-representation or training data that reflects societal biases. Inspired by the successes of mixup for improving classification performance, we develop a pairwise mixup scheme to augment training data and encourage fair and accurate decision boundaries for all subgroups. Data augmentation for group fairness allows us to add new samples of underrepresented groups to balance subpopulations. Furthermore, our method allows us to use the generalization ability of mixup to improve both fairness and accuracy. We compare our proposed mixup to existing data augmentation and bias mitigation approaches on both synthetic simulations and real-world benchmark fair classification data, demonstrating that we are able to achieve fair outcomes with robust if not improved accuracy.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了通过对组比对的混合来提高群公平性。许多实际应用中的机器学习系统具有因社会偏见而导致的各个群体之间的偏见。 Drawing inspiration from the successes of mixup in improving classification performance, we develop a pairwise mixup scheme to augment training data and encourage fair and accurate decision boundaries for all subgroups. 数据增强为群公平性的目的是增加受 represcribed 群体的样本，平衡 subgroup。此外，我们的方法可以利用混合的通用能力来提高公平性和准确性。我们与现有的数据增强和偏见缓和方法进行比较，在 sintetic  simulations 和实际的偏见分类数据上表明，我们可以实现公平的结果，并且准确性可能会更高。
</details></li>
</ul>
<hr>
<h2 id="The-Boundaries-of-Verifiable-Accuracy-Robustness-and-Generalisation-in-Deep-Learning"><a href="#The-Boundaries-of-Verifiable-Accuracy-Robustness-and-Generalisation-in-Deep-Learning" class="headerlink" title="The Boundaries of Verifiable Accuracy, Robustness, and Generalisation in Deep Learning"></a>The Boundaries of Verifiable Accuracy, Robustness, and Generalisation in Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07072">http://arxiv.org/abs/2309.07072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Bastounis, Alexander N. Gorban, Anders C. Hansen, Desmond J. Higham, Danil Prokhorov, Oliver Sutton, Ivan Y. Tyukin, Qinghua Zhou</li>
<li>for: 本研究探讨了神经网络在分类任务中确定稳定性和准确性的理论限制。</li>
<li>methods: 本研究使用了传统的分布式随机过程框架和最小化实际风险的算法，可能受权重正则化的影响。</li>
<li>results: 研究发现，有许多任务情况下，计算和验证理想稳定和准确的神经网络是极其困难，甚至不可能，即使理想的解在给定神经网络架构中存在。<details>
<summary>Abstract</summary>
In this work, we assess the theoretical limitations of determining guaranteed stability and accuracy of neural networks in classification tasks. We consider classical distribution-agnostic framework and algorithms minimising empirical risks and potentially subjected to some weights regularisation. We show that there is a large family of tasks for which computing and verifying ideal stable and accurate neural networks in the above settings is extremely challenging, if at all possible, even when such ideal solutions exist within the given class of neural architectures.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们评估了神经网络在分类任务中的理论限制。我们考虑了传统的分布无关框架和算法，以降低采样风险并可能受到权重正则化。我们发现，有一大家族任务， computing和验证理想稳定和准确的神经网络在上述设定下是极其困难，甚至存在这种理想解在给定的神经网络架构中。Note: " Simplified Chinese" is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="An-Extreme-Learning-Machine-Based-Method-for-Computational-PDEs-in-Higher-Dimensions"><a href="#An-Extreme-Learning-Machine-Based-Method-for-Computational-PDEs-in-Higher-Dimensions" class="headerlink" title="An Extreme Learning Machine-Based Method for Computational PDEs in Higher Dimensions"></a>An Extreme Learning Machine-Based Method for Computational PDEs in Higher Dimensions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07049">http://arxiv.org/abs/2309.07049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiran Wang, Suchuan Dong</li>
<li>for: 解决高维partial differential equation (PDE)问题</li>
<li>methods: 使用Randomized Neural Networks方法，包括一种基于ELM的扩展方法和一种基于Approximate Theory of Functional Connections (A-TFC)的减少方法</li>
<li>results: 可以精确地解决高维PDE问题，错误水平与机器精度相似，并且比physics-informed neural network (PINN)方法更加经济和精准。<details>
<summary>Abstract</summary>
We present two effective methods for solving high-dimensional partial differential equations (PDE) based on randomized neural networks. Motivated by the universal approximation property of this type of networks, both methods extend the extreme learning machine (ELM) approach from low to high dimensions. With the first method the unknown solution field in $d$ dimensions is represented by a randomized feed-forward neural network, in which the hidden-layer parameters are randomly assigned and fixed while the output-layer parameters are trained. The PDE and the boundary/initial conditions, as well as the continuity conditions (for the local variant of the method), are enforced on a set of random interior/boundary collocation points. The resultant linear or nonlinear algebraic system, through its least squares solution, provides the trained values for the network parameters. With the second method the high-dimensional PDE problem is reformulated through a constrained expression based on an Approximate variant of the Theory of Functional Connections (A-TFC), which avoids the exponential growth in the number of terms of TFC as the dimension increases. The free field function in the A-TFC constrained expression is represented by a randomized neural network and is trained by a procedure analogous to the first method. We present ample numerical simulations for a number of high-dimensional linear/nonlinear stationary/dynamic PDEs to demonstrate their performance. These methods can produce accurate solutions to high-dimensional PDEs, in particular with their errors reaching levels not far from the machine accuracy for relatively lower dimensions. Compared with the physics-informed neural network (PINN) method, the current method is both cost-effective and more accurate for high-dimensional PDEs.
</details>
<details>
<summary>摘要</summary>
我们提出了两种有效的方法来解决高维度 partial differential equation (PDE) 基于随机 нейрон网络。这些方法都是基于随机 нейрон网络的通用测量性质，并将 ELM 方法从低维度扩展到高维度。在第一种方法中，不知之解决场在 d 维度中是使用随机Feed-Forward нейрон网络表示，其中隐藏层参数随机分配并固定，而输出层参数则是通过训练而得到。PDE 和边界/初始条件以及当地的连续条件（ для本地方法）在一些随机内部/边界点上被规律。由于这些点的数量增加，它们的线性或非线性代数系统的最小二乘解决方案提供了训练随机 нейрон网络参数的值。在第二种方法中，高维度 PDE 问题被重新表述为一个受限的表述基于 Approximate 函数连接理论 (A-TFC)，这个方法可以避免 PDE 的维度增加所带来的减少维度增加的数量增加。在 A-TFC 受限表述中，自由场函数是使用随机Feed-Forward нейрон网络表示，并通过与第一种方法相似的训练程序训练。我们将在一些高维度线性/非线性站点/动态 PDE 中进行丰富的数据验证，以示其性能。这些方法可以精确地解决高维度 PDE，特别是其错误在相对较低维度时已经接近机器精度。相比于物理学 informed neural network (PINN) 方法，现在的方法更加成本效益和精度高于高维度 PDE。
</details></li>
</ul>
<hr>
<h2 id="Optimal-transport-distances-for-directed-weighted-graphs-a-case-study-with-cell-cell-communication-networks"><a href="#Optimal-transport-distances-for-directed-weighted-graphs-a-case-study-with-cell-cell-communication-networks" class="headerlink" title="Optimal transport distances for directed, weighted graphs: a case study with cell-cell communication networks"></a>Optimal transport distances for directed, weighted graphs: a case study with cell-cell communication networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07030">http://arxiv.org/abs/2309.07030</a></li>
<li>repo_url: None</li>
<li>paper_authors: James S. Nagai, Ivan G. Costa, Michael T. Schaub</li>
<li>for:  comparing directed graphs using optimal transport distances</li>
<li>methods:  proposes two distance measures based on variants of optimal transport (Wasserstein and Gromov-Wasserstein)</li>
<li>results:  evaluates the performance of the two distance measures on simulated graph data and real-world directed cell-cell communication graphs.Here’s the summary in the format you requested:</li>
<li>for: 比较直接图使用最优运输距离</li>
<li>methods: 提出了基于变种最优运输的两种距离度量（水星车运输和格罗莫夫-水星车运输）</li>
<li>results: 对于 simulate图数据和实际直接细胞通信图数据进行评估和比较<details>
<summary>Abstract</summary>
Comparing graphs by means of optimal transport has recently gained significant attention, as the distances induced by optimal transport provide both a principled metric between graphs as well as an interpretable description of the associated changes between graphs in terms of a transport plan. As the lack of symmetry introduces challenges in the typically considered formulations, optimal transport distances for graphs have mostly been developed for undirected graphs. Here, we propose two distance measures to compare directed graphs based on variants of optimal transport: (i) an earth movers distance (Wasserstein) and (ii) a Gromov-Wasserstein (GW) distance. We evaluate these two distances and discuss their relative performance for both simulated graph data and real-world directed cell-cell communication graphs, inferred from single-cell RNA-seq data.
</details>
<details>
<summary>摘要</summary>
comparing 图表使用最优运输方法已经吸引了广泛关注，因为最优运输距离提供了图表之间的原则性的距离度量，同时还提供了可解释的交通计划。由于不具有对称性，通常考虑的形式ulation中的最优运输距离多是针对无向图进行开发。在这里，我们提出了两种用于比较导向图的距离度量：（一）地球搬运距离（沃asserstein）和（二）格罗莫夫-沃asserstein（GW）距离。我们评估了这两种距离度量，并对假设数据和真实世界导向细胞通信图进行了评估。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Adversarial-Attacks-in-Federated-Learning-with-Trusted-Execution-Environments"><a href="#Mitigating-Adversarial-Attacks-in-Federated-Learning-with-Trusted-Execution-Environments" class="headerlink" title="Mitigating Adversarial Attacks in Federated Learning with Trusted Execution Environments"></a>Mitigating Adversarial Attacks in Federated Learning with Trusted Execution Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07197">http://arxiv.org/abs/2309.07197</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/queyrusi/pelta">https://github.com/queyrusi/pelta</a></li>
<li>paper_authors: Simon Queyrut, Valerio Schiavoni, Pascal Felber</li>
<li>for: 本研究旨在防止 federated learning（FL）中的模型更新计算被攻击者抢夺，以保护用户数据隐私。</li>
<li>methods: 本研究使用 Trusted Execution Environments（TEEs）来防止攻击者通过黑盒攻击（white-box attack）制作恶意样本。</li>
<li>results: 本研究在三个常用的数据集（CIFAR-10、CIFAR-100和ImageNet）上评估了 Pelta 机制，并证明了其能够有效地防止六种白盒攻击（包括 Projected Gradient Descent、Momentum Iterative Method、Auto Projected Gradient Descent 和 Carlini &amp; Wagner 攻击）。<details>
<summary>Abstract</summary>
The main premise of federated learning (FL) is that machine learning model updates are computed locally to preserve user data privacy. This approach avoids by design user data to ever leave the perimeter of their device. Once the updates aggregated, the model is broadcast to all nodes in the federation. However, without proper defenses, compromised nodes can probe the model inside their local memory in search for adversarial examples, which can lead to dangerous real-world scenarios. For instance, in image-based applications, adversarial examples consist of images slightly perturbed to the human eye getting misclassified by the local model. These adversarial images are then later presented to a victim node's counterpart model to replay the attack. Typical examples harness dissemination strategies such as altered traffic signs (patch attacks) no longer recognized by autonomous vehicles or seemingly unaltered samples that poison the local dataset of the FL scheme to undermine its robustness. Pelta is a novel shielding mechanism leveraging Trusted Execution Environments (TEEs) that reduce the ability of attackers to craft adversarial samples. Pelta masks inside the TEE the first part of the back-propagation chain rule, typically exploited by attackers to craft the malicious samples. We evaluate Pelta on state-of-the-art accurate models using three well-established datasets: CIFAR-10, CIFAR-100 and ImageNet. We show the effectiveness of Pelta in mitigating six white-box state-of-the-art adversarial attacks, such as Projected Gradient Descent, Momentum Iterative Method, Auto Projected Gradient Descent, the Carlini & Wagner attack. In particular, Pelta constitutes the first attempt at defending an ensemble model against the Self-Attention Gradient attack to the best of our knowledge. Our code is available to the research community at https://github.com/queyrusi/Pelta.
</details>
<details>
<summary>摘要</summary>
主要想法 behind 联合学习（FL）是计算机机器学习模型更新在保持用户数据隐私的情况下进行本地计算。这种方法避免由设计计划用户数据从设备外部传输。一旦更新被聚合，模型会被广播到所有联合节点。然而，不当防御可能导致受到攻击的节点探测模型内部的攻击示例，这可能导致危险的实际场景。例如，在图像应用程序中，攻击示例可以是微调到人类眼睛的图像，使得本地模型 incorrect 分类。这些攻击示例然后会被传递到受到攻击的节点的对应模型，以重新发动攻击。常见的攻击策略包括修改交通标志（patch attacks），使得自动驾驶车辆不再认可，以及模拟不变的样本，损害本地联合学习方案的可靠性。Pelta 是一种新的防御机制，基于可信执行环境（TEEs），减少了攻击者对恶意示例的能力。Pelta 在 TEE 中隐藏了反propagation chain rule 的第一部分，通常由攻击者利用来制作恶意示例。我们使用三个常见的 dataset：CIFAR-10、CIFAR-100 和 ImageNet，评估 Pelta 对 state-of-the-art 精度模型的防御效果。我们发现 Pelta 可以有效防止六种白盒 state-of-the-art 攻击，包括 Projected Gradient Descent、Momentum Iterative Method、Auto Projected Gradient Descent 和 Carlini & Wagner 攻击。尤其是，Pelta 是首次防御 ensemble 模型对 Self-Attention Gradient 攻击的尝试。我们的代码可以在 https://github.com/queyrusi/Pelta 上下载。
</details></li>
</ul>
<hr>
<h2 id="Open-vocabulary-Keyword-spotting-with-Adaptive-Instance-Normalization"><a href="#Open-vocabulary-Keyword-spotting-with-Adaptive-Instance-Normalization" class="headerlink" title="Open-vocabulary Keyword-spotting with Adaptive Instance Normalization"></a>Open-vocabulary Keyword-spotting with Adaptive Instance Normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08561">http://arxiv.org/abs/2309.08561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aviv Navon, Aviv Shamsian, Neta Glazer, Gill Hetz, Joseph Keshet</li>
<li>for: 这篇论文的目的是提出一种新的自动话语识别（ASR）系统，用于检测用户定义的关键字。</li>
<li>methods: 这篇论文使用了一种新的文本编码器，将语音输入转换为关键字条件的正规化参数。这些参数 затем用于进行话语识别。</li>
<li>results: 这篇论文的实验结果显示，这种方法可以在多种多元的语言 benchmark 上取得优秀的成绩，并且在不同的语言中也能够获得显著的改善。此外，这种方法还可以在无法语言training的情况下提供substantial的性能改善。<details>
<summary>Abstract</summary>
Open vocabulary keyword spotting is a crucial and challenging task in automatic speech recognition (ASR) that focuses on detecting user-defined keywords within a spoken utterance. Keyword spotting methods commonly map the audio utterance and keyword into a joint embedding space to obtain some affinity score. In this work, we propose AdaKWS, a novel method for keyword spotting in which a text encoder is trained to output keyword-conditioned normalization parameters. These parameters are used to process the auditory input. We provide an extensive evaluation using challenging and diverse multi-lingual benchmarks and show significant improvements over recent keyword spotting and ASR baselines. Furthermore, we study the effectiveness of our approach on low-resource languages that were unseen during the training. The results demonstrate a substantial performance improvement compared to baseline methods.
</details>
<details>
<summary>摘要</summary>
开放词汇关键点检测是自动语音识别（ASR）中一项重要和挑战性的任务，它的目标是在语音词语中检测用户定义的关键词。关键点检测方法通常将音频词语和关键词映射到一个共同嵌入空间中，以获得一些相似度分数。在这种工作中，我们提出了AdaKWS方法，它是一种新的关键点检测方法，其中文本编码器在输出关键词条件下的normalization参数。这些参数用于处理听频输入。我们对多种多语言的benchmark进行了广泛的评估，并显示了与最近的关键点检测和ASR基线方法相比的显著提高。此外，我们还研究了我们的方法在没有在训练中看到的低资源语言上的效果，结果表明了和基线方法相比的巨大性能提高。
</details></li>
</ul>
<hr>
<h2 id="Effect-of-hyperparameters-on-variable-selection-in-random-forests"><a href="#Effect-of-hyperparameters-on-variable-selection-in-random-forests" class="headerlink" title="Effect of hyperparameters on variable selection in random forests"></a>Effect of hyperparameters on variable selection in random forests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06943">http://arxiv.org/abs/2309.06943</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imbs-hl/rf-hyperparameters-and-variable-selection">https://github.com/imbs-hl/rf-hyperparameters-and-variable-selection</a></li>
<li>paper_authors: Cesaire J. K. Fouodo, Lea L. Kronziel, Inke R. König, Silke Szymczak</li>
<li>for: 这个研究是为了探讨Random Forest（RF）算法中的几个参数对预测模型和变量选择的影响。</li>
<li>methods: 研究使用了两个 simulation studies，使用理论分布和实验遗传学数据，以evaluate RF算法中参数的影响。</li>
<li>results: 研究发现，选择候选变量的程序（Vita和Boruta）受到几个参数的影响，包括mtry.prop和sample.fraction。这些参数的设定可以影响预测性能和变量选择的精度。<details>
<summary>Abstract</summary>
Random forests (RFs) are well suited for prediction modeling and variable selection in high-dimensional omics studies. The effect of hyperparameters of the RF algorithm on prediction performance and variable importance estimation have previously been investigated. However, how hyperparameters impact RF-based variable selection remains unclear. We evaluate the effects on the Vita and the Boruta variable selection procedures based on two simulation studies utilizing theoretical distributions and empirical gene expression data. We assess the ability of the procedures to select important variables (sensitivity) while controlling the false discovery rate (FDR). Our results show that the proportion of splitting candidate variables (mtry.prop) and the sample fraction (sample.fraction) for the training dataset influence the selection procedures more than the drawing strategy of the training datasets and the minimal terminal node size. A suitable setting of the RF hyperparameters depends on the correlation structure in the data. For weakly correlated predictor variables, the default value of mtry is optimal, but smaller values of sample.fraction result in larger sensitivity. In contrast, the difference in sensitivity of the optimal compared to the default value of sample.fraction is negligible for strongly correlated predictor variables, whereas smaller values than the default are better in the other settings. In conclusion, the default values of the hyperparameters will not always be suitable for identifying important variables. Thus, adequate values differ depending on whether the aim of the study is optimizing prediction performance or variable selection.
</details>
<details>
<summary>摘要</summary>
Random forests (RFs) 是高维数据研究中适用于预测模型和变量选择的好方法。RF算法中的超参数对预测性能和变量重要性估计的影响已经被研究过，但是如何影响RF基于变量选择仍然不清楚。我们通过两个 simulations studies使用理论分布和实际表达数据来评估超参数对Vita和Boruta变量选择过程的影响。我们评估了选择重要变量的能力（敏感度），同时控制false discovery rate（FDR）。我们的结果表明，RF超参数中分布 candidate variables的比例（mtry.prop）和训练集中的样本分布（sample.fraction）对选择过程产生更大的影响，而不是训练集的抽取方式和最小终节点大小。RF超参数的适用取决于数据中变量之间的相关性。对于弱相关的预测变量，默认值的mtry是最佳，但是较小的sample.fraction会导致更大的敏感度。相反，对于强相关的预测变量，默认值的sample.fraction没有影响敏感度，但是较小的值比默认值更好。因此，默认值的超参数不一定适用于identifyingimportant变量。因此，需要根据研究的目标是优化预测性能还是变量选择来选择合适的超参数值。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Dislocation-Dynamics-Data-Using-Semantic-Web-Technologies"><a href="#Modeling-Dislocation-Dynamics-Data-Using-Semantic-Web-Technologies" class="headerlink" title="Modeling Dislocation Dynamics Data Using Semantic Web Technologies"></a>Modeling Dislocation Dynamics Data Using Semantic Web Technologies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06930">http://arxiv.org/abs/2309.06930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Zainul Ihsan, Said Fathalla, Stefan Sandfeld</li>
<li>for: 本研究旨在探讨Materials Science and Engineering领域中普遍研究的晶体材料，包括金属和半导体材料。晶体材料通常含有一种特定的缺陷，即“扭变”。这种缺陷对材料的性能产生重要影响，包括强度、裂解强度和ductility。</li>
<li>methods: 本研究使用semantic web技术来描述扭变行为，包括使用ontology来注释数据。我们对已有的Dislocation Ontology进行了扩展，添加了缺失的概念，并与两个域相关的ontology（i.e., Elementary Multi-perspective Material Ontology和Materials Design Ontology）进行了对接，以便效率地表示扭变数据。</li>
<li>results: 我们通过构建了一个知识图（DisLocKG）， illustrate了扭变数据之间的关系。此外，我们还开发了一个SPARQL终点，允许用户进行extensive的查询DisLocKG。<details>
<summary>Abstract</summary>
Research in the field of Materials Science and Engineering focuses on the design, synthesis, properties, and performance of materials. An important class of materials that is widely investigated are crystalline materials, including metals and semiconductors. Crystalline material typically contains a distinct type of defect called "dislocation". This defect significantly affects various material properties, including strength, fracture toughness, and ductility. Researchers have devoted a significant effort in recent years to understanding dislocation behavior through experimental characterization techniques and simulations, e.g., dislocation dynamics simulations. This paper presents how data from dislocation dynamics simulations can be modeled using semantic web technologies through annotating data with ontologies. We extend the already existing Dislocation Ontology by adding missing concepts and aligning it with two other domain-related ontologies (i.e., the Elementary Multi-perspective Material Ontology and the Materials Design Ontology) allowing for representing the dislocation simulation data efficiently. Moreover, we show a real-world use case by representing the discrete dislocation dynamics data as a knowledge graph (DisLocKG) that illustrates the relationship between them. We also developed a SPARQL endpoint that brings extensive flexibility to query DisLocKG.
</details>
<details>
<summary>摘要</summary>
研究在材料科学和工程领域的ocus是设计、合成、性能和表现等材料的方面。一种广泛研究的材料是晶体材料，包括金属和半导体。晶体材料通常含有一种特殊的缺陷，即“扭变”。这种缺陷对材料的性能产生很大影响，包括强度、裂解强度和塑性。研究人员在过去几年中对扭变行为进行了广泛的研究，包括实验测定技术和 simulations。本文介绍了如何使用Semantic Web技术来模型来自扭变动力学 simulations的数据，包括使用ontology进行数据注释。我们将现有的扭变ontology扩展，添加缺失的概念和与其他两个领域相关的 Ontology（即Elementary Multi-perspective Material Ontology和Materials Design Ontology）进行对应，以便有效地表示扭变动力学数据。此外，我们还构建了一个知识图（DisLocKG），用于表示扭变动力学数据的关系。此外，我们还开发了一个SPARQL端点，以便通过查询DisLocKG进行广泛的灵活性调查。
</details></li>
</ul>
<hr>
<h2 id="Investigating-the-Impact-of-Action-Representations-in-Policy-Gradient-Algorithms"><a href="#Investigating-the-Impact-of-Action-Representations-in-Policy-Gradient-Algorithms" class="headerlink" title="Investigating the Impact of Action Representations in Policy Gradient Algorithms"></a>Investigating the Impact of Action Representations in Policy Gradient Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06921">http://arxiv.org/abs/2309.06921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Schneider, Pierre Schumacher, Daniel Häufle, Bernhard Schölkopf, Dieter Büchler</li>
<li>for:  investigate the impact of action representations on the learning performance of reinforcement learning algorithms</li>
<li>methods:  use different analysis techniques to assess the effectiveness of action representations in RL</li>
<li>results:  the action representation can significantly influence the learning performance on popular RL benchmark tasks, and some of the performance differences can be attributed to changes in the complexity of the optimization landscape.Here’s the full text in Simplified Chinese:</li>
<li>for: 这研究旨在 investigate reinforcement learning 算法的学习性能如何受到行为表现的影响</li>
<li>methods: 使用不同的分析技术来评估 action 表现对 reinforcement learning 算法的效果</li>
<li>results: 发现 action 表现可以对 popular reinforcement learning benchmark task 产生显著的影响，并且一些性能差异可以被归因于优化 landscape 的复杂度变化。<details>
<summary>Abstract</summary>
Reinforcement learning~(RL) is a versatile framework for learning to solve complex real-world tasks. However, influences on the learning performance of RL algorithms are often poorly understood in practice. We discuss different analysis techniques and assess their effectiveness for investigating the impact of action representations in RL. Our experiments demonstrate that the action representation can significantly influence the learning performance on popular RL benchmark tasks. The analysis results indicate that some of the performance differences can be attributed to changes in the complexity of the optimization landscape. Finally, we discuss open challenges of analysis techniques for RL algorithms.
</details>
<details>
<summary>摘要</summary>
利用强化学习（RL）框架，可以解决复杂的实际任务。然而，RL算法的学习性能中的影响因素通常在实践中不够了解。我们讨论了不同的分析技术，并评估它们在RL算法中的有效性。我们的实验表明，行为表示可以对RL算法的学习性能产生重要影响。分析结果表明，一些性能差异可以归结于优化景观的复杂性变化。最后，我们讨论了RL算法分析技术的开放挑战。
</details></li>
</ul>
<hr>
<h2 id="Domain-Aware-Augmentations-for-Unsupervised-Online-General-Continual-Learning"><a href="#Domain-Aware-Augmentations-for-Unsupervised-Online-General-Continual-Learning" class="headerlink" title="Domain-Aware Augmentations for Unsupervised Online General Continual Learning"></a>Domain-Aware Augmentations for Unsupervised Online General Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06896">http://arxiv.org/abs/2309.06896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Michel, Romain Negrel, Giovanni Chierchia, Jean-François Bercher</li>
<li>for: 提高Unsupervised Online General Continual Learning（UOGCL）中的学习稳定性，特别是在无丝总成本知识或任务变化信息的情况下。</li>
<li>methods: 提出了一种新的方法，通过定义流程相依的数据增强技术和一些实现策略，以增强对异构学习的记忆使用。</li>
<li>results: 与其他无监督方法相比，该方法在所有考虑的设置中达到了最佳效果，并将超级vised和无监督 continual learning之间的差降到最低水平。我们的领域相关增强过程可以适应其他回放基于方法，因此是一个有前途的策略 для continual learning。<details>
<summary>Abstract</summary>
Continual Learning has been challenging, especially when dealing with unsupervised scenarios such as Unsupervised Online General Continual Learning (UOGCL), where the learning agent has no prior knowledge of class boundaries or task change information. While previous research has focused on reducing forgetting in supervised setups, recent studies have shown that self-supervised learners are more resilient to forgetting. This paper proposes a novel approach that enhances memory usage for contrastive learning in UOGCL by defining and using stream-dependent data augmentations together with some implementation tricks. Our proposed method is simple yet effective, achieves state-of-the-art results compared to other unsupervised approaches in all considered setups, and reduces the gap between supervised and unsupervised continual learning. Our domain-aware augmentation procedure can be adapted to other replay-based methods, making it a promising strategy for continual learning.
</details>
<details>
<summary>摘要</summary>
continuous learning 是具有挑战性的，特别是在无监督的情况下，如无监督在线通用性Continual Learning (UOGCL)，学习机器没有类别边界或任务变化信息的先前知识。以前的研究主要是降低忘记的方法，但最近的研究表明，自我监督学习者更抗忘记。这篇论文提出了一种新的方法，增强了对异构学习的内存使用，通过定义流程依赖的数据增强和一些实现技巧。我们提议的方法简单又高效，在所有考虑的设置中达到了其他无监督方法的状态艺术级 результа，并将无监督Continual Learning和监督Continual Learning之间的差距减少。我们的领域相关增强过程可以适应其他播放基于方法，使其成为持续学习的优秀策略。
</details></li>
</ul>
<hr>
<h2 id="A-Robust-SINDy-Approach-by-Combining-Neural-Networks-and-an-Integral-Form"><a href="#A-Robust-SINDy-Approach-by-Combining-Neural-Networks-and-an-Integral-Form" class="headerlink" title="A Robust SINDy Approach by Combining Neural Networks and an Integral Form"></a>A Robust SINDy Approach by Combining Neural Networks and an Integral Form</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07193">http://arxiv.org/abs/2309.07193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Forootani, Pawan Goyal, Peter Benner</li>
<li>for: 在噪音和缺乏数据的情况下找到管理方程的研究已经是数据挖掘领域的活跃领域之一。</li>
<li>methods: 我们使用神经网络学习一种含义 repre sentation，使其不仅能够在测量数据附近生成输出，而且能够描述时间演化的输出。在SINDy框架下，我们学习这种动力系统。使用神经网络学习的隐式表示，我们获取了SINDy所需的导数据。为了增强我们的方法的稳定性，我们进一步添加了输出隐式网络的积分条件。</li>
<li>results: 我们提出了一种可靠的方法，可以在噪音和缺乏数据的情况下找到管理方程。我们通过多个初始条件的数据集来扩展我们的方法，并证明了它的高效性。与已有方法相比，我们的方法在噪音和缺乏数据的情况下表现更加稳定和有效。<details>
<summary>Abstract</summary>
The discovery of governing equations from data has been an active field of research for decades. One widely used methodology for this purpose is sparse regression for nonlinear dynamics, known as SINDy. Despite several attempts, noisy and scarce data still pose a severe challenge to the success of the SINDy approach. In this work, we discuss a robust method to discover nonlinear governing equations from noisy and scarce data. To do this, we make use of neural networks to learn an implicit representation based on measurement data so that not only it produces the output in the vicinity of the measurements but also the time-evolution of output can be described by a dynamical system. Additionally, we learn such a dynamic system in the spirit of the SINDy framework. Leveraging the implicit representation using neural networks, we obtain the derivative information -- required for SINDy -- using an automatic differentiation tool. To enhance the robustness of our methodology, we further incorporate an integral condition on the output of the implicit networks. Furthermore, we extend our methodology to handle data collected from multiple initial conditions. We demonstrate the efficiency of the proposed methodology to discover governing equations under noisy and scarce data regimes by means of several examples and compare its performance with existing methods.
</details>
<details>
<summary>摘要</summary>
发现管理方程的研究已经是数据挖掘的一个活跃领域，有一种广泛使用的方法是非线性动力学中的稀疏回归，称为SINDy。 despite several attempts, noisy and scarce data still pose a severe challenge to the success of the SINDy approach. In this work, we discuss a robust method to discover nonlinear governing equations from noisy and scarce data. To do this, we make use of neural networks to learn an implicit representation based on measurement data so that not only it produces the output in the vicinity of the measurements but also the time-evolution of output can be described by a dynamical system. Additionally, we learn such a dynamic system in the spirit of the SINDy framework. Leveraging the implicit representation using neural networks, we obtain the derivative information -- required for SINDy -- using an automatic differentiation tool. To enhance the robustness of our methodology, we further incorporate an integral condition on the output of the implicit networks. Furthermore, we extend our methodology to handle data collected from multiple initial conditions. We demonstrate the efficiency of the proposed methodology to discover governing equations under noisy and scarce data regimes by means of several examples and compare its performance with existing methods.
</details></li>
</ul>
<hr>
<h2 id="The-effect-of-data-augmentation-and-3D-CNN-depth-on-Alzheimer’s-Disease-detection"><a href="#The-effect-of-data-augmentation-and-3D-CNN-depth-on-Alzheimer’s-Disease-detection" class="headerlink" title="The effect of data augmentation and 3D-CNN depth on Alzheimer’s Disease detection"></a>The effect of data augmentation and 3D-CNN depth on Alzheimer’s Disease detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07192">http://arxiv.org/abs/2309.07192</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rturrisige/AD_classification">https://github.com/rturrisige/AD_classification</a></li>
<li>paper_authors: Rosanna Turrisi, Alessandro Verri, Annalisa Barla</li>
<li>for: 这个论文的目的是为了提高健康监测领域中的机器学习（ML）技术的可靠性和可重复性，特意采用了最佳实践来确保可重复性和可靠性。</li>
<li>methods: 这篇论文使用了多种数据增强技术和模型复杂度来影响总性表现。使用了ADNI数据集中的MRI数据，采用3D卷积神经网络（CNN）进行分类问题。实验设计包括跨 Validation 和多个训练尝试，以资料稀缺和初始随机参数资料补做。</li>
<li>results: 研究发现，不同的数据增强策略和模型复杂度对总表现的影响是显著的，最好的模型（8 CL, (B)）在各个批处理和训练尝试中具有最高精度和稳定性。<details>
<summary>Abstract</summary>
Machine Learning (ML) has emerged as a promising approach in healthcare, outperforming traditional statistical techniques. However, to establish ML as a reliable tool in clinical practice, adherence to best practices regarding data handling, experimental design, and model evaluation is crucial. This work summarizes and strictly observes such practices to ensure reproducible and reliable ML. Specifically, we focus on Alzheimer's Disease (AD) detection, which serves as a paradigmatic example of challenging problem in healthcare. We investigate the impact of different data augmentation techniques and model complexity on the overall performance. We consider MRI data from ADNI dataset to address a classification problem employing 3D Convolutional Neural Network (CNN). The experiments are designed to compensate for data scarcity and initial random parameters by utilizing cross-validation and multiple training trials. Within this framework, we train 15 predictive models, considering three different data augmentation strategies and five distinct 3D CNN architectures, each varying in the number of convolutional layers. Specifically, the augmentation strategies are based on affine transformations, such as zoom, shift, and rotation, applied concurrently or separately. The combined effect of data augmentation and model complexity leads to a variation in prediction performance up to 10% of accuracy. When affine transformation are applied separately, the model is more accurate, independently from the adopted architecture. For all strategies, the model accuracy followed a concave behavior at increasing number of convolutional layers, peaking at an intermediate value of layers. The best model (8 CL, (B)) is the most stable across cross-validation folds and training trials, reaching excellent performance both on the testing set and on an external test set.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）在医疗领域已经出现为一种有前途的方法，超过了传统的统计方法。然而，为了在临床实践中确立ML为可靠的工具，需要严格遵循数据处理、实验设计和模型评价的最佳做法。本工作总结并严格遵循这些做法，以确保可重复和可靠的ML。特别是，我们选择了诊断阿尔茨海默病（AD）为例子，这是医疗领域中的一个挑战性问题。我们研究了不同的数据扩充技术和模型复杂度对总性性能的影响。我们使用ADNI数据集中的MRI数据进行分类问题，使用3D卷积神经网络（CNN）进行解决。实验设计包括资料缺乏和初始随机参数的补做，通过批处理和多个训练回合来实现。在这个框架下，我们训练了15个预测模型，其中包括三种不同的数据扩充策略和五种不同的3D CNN架构，每种架构都有不同的层数。具体来说，数据扩充策略包括同时应用几何变换，包括压缩、移动和旋转，而模型复杂度则由层数决定。结果显示，当应用几何变换分别时，模型的准确率更高，而且独立于采用的架构。对所有策略来说，模型准确率随层数的增加而下降，最佳模型（8 CL，B）在各个批处理弹性和训练回合中具有优秀表现，并在测试集和外部测试集上达到了优秀表现。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-control-of-self-assembly-of-quasicrystalline-structures-through-reinforcement-learning"><a href="#Dynamic-control-of-self-assembly-of-quasicrystalline-structures-through-reinforcement-learning" class="headerlink" title="Dynamic control of self-assembly of quasicrystalline structures through reinforcement learning"></a>Dynamic control of self-assembly of quasicrystalline structures through reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06869">http://arxiv.org/abs/2309.06869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Uyen Tu Lieu, Natsuhiko Yoshinaga</li>
<li>For: 本研究使用力学学习控制了动态自组装的十二面体 quasi-кристаллические（DDQC）从粗糙粒子中。* Methods: 研究使用了Q学习方法来估算温度控制策略，并通过这种策略来生成DDQC。* Results: 研究发现，使用力学学习控制的温度规则可以更有效地生成DDQC，并且可以避免一些常见的缺陷。此外，研究还发现了一种自动发现束缚温度的机制，即通过动态变化的束缚温度来帮助系统形成DDQC。<details>
<summary>Abstract</summary>
We propose reinforcement learning to control the dynamical self-assembly of the dodecagonal quasicrystal (DDQC) from patchy particles. The patchy particles have anisotropic interactions with other particles and form DDQC. However, their structures at steady states are significantly influenced by the kinetic pathways of their structural formation. We estimate the best policy of temperature control trained by the Q-learning method and demonstrate that we can generate DDQC with few defects using the estimated policy. The temperature schedule obtained by reinforcement learning can reproduce the desired structure more efficiently than the conventional pre-fixed temperature schedule, such as annealing. To clarify the success of the learning, we also analyse a simple model describing the kinetics of structural changes through the motion in a triple-well potential. We have found that reinforcement learning autonomously discovers the critical temperature at which structural fluctuations enhance the chance of forming a globally stable state. The estimated policy guides the system toward the critical temperature to assist the formation of DDQC.
</details>
<details>
<summary>摘要</summary>
我们提议使用强化学习控制多十二边形 quasi-кристал（DDQC）由杂性粒子自组装。这些杂性粒子具有方向性相互作用，并且形成DDQC。然而，他们的稳定态结构受到其结构形成的动力学 PATHway 的影响。我们使用Q学习方法估算最佳温度控制策略，并证明可以使用这个策略生成几乎无损DDQC。我们所获得的温度规则可以更有效地生成愿望的结构，而不是传统的预先 fixing 温度规则，如热处理。为了证明学习的成功，我们还分析了一个描述结构变化的三重潜在陷阱中的简单模型。我们发现，强化学习自动发现了在结构变化中增强global stability的温度。我们估算的策略可以帮助系统向这个温度迁移，以便DDQC的形成。
</details></li>
</ul>
<hr>
<h2 id="Supervised-Machine-Learning-and-Physics-based-Machine-Learning-approach-for-prediction-of-peak-temperature-distribution-in-Additive-Friction-Stir-Deposition-of-Aluminium-Alloy"><a href="#Supervised-Machine-Learning-and-Physics-based-Machine-Learning-approach-for-prediction-of-peak-temperature-distribution-in-Additive-Friction-Stir-Deposition-of-Aluminium-Alloy" class="headerlink" title="Supervised Machine Learning and Physics based Machine Learning approach for prediction of peak temperature distribution in Additive Friction Stir Deposition of Aluminium Alloy"></a>Supervised Machine Learning and Physics based Machine Learning approach for prediction of peak temperature distribution in Additive Friction Stir Deposition of Aluminium Alloy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06838">http://arxiv.org/abs/2309.06838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshansh Mishra</li>
<li>For: This paper aims to improve the understanding of the relationship between process parameters, thermal profiles, and microstructure in Additive Friction Stir Deposition (AFSD) for solid-state additive manufacturing.* Methods: The paper combines supervised machine learning (SML) and physics-informed neural networks (PINNs) to predict peak temperature distribution in AFSD from process parameters.* Results: The integrated ML approach is able to classify deposition quality from process factors with robust accuracy, providing comprehensive insights into tailoring microstructure through thermal management in AFSD.<details>
<summary>Abstract</summary>
Additive friction stir deposition (AFSD) is a novel solid-state additive manufacturing technique that circumvents issues of porosity, cracking, and properties anisotropy that plague traditional powder bed fusion and directed energy deposition approaches. However, correlations between process parameters, thermal profiles, and resulting microstructure in AFSD remain poorly understood. This hinders process optimization for properties. This work employs a cutting-edge framework combining supervised machine learning (SML) and physics-informed neural networks (PINNs) to predict peak temperature distribution in AFSD from process parameters. Eight regression algorithms were implemented for SML modeling, while four PINNs leveraged governing equations for transport, wave propagation, heat transfer, and quantum mechanics. Across multiple statistical measures, ensemble techniques like gradient boosting proved superior for SML, with lowest MSE of 165.78. The integrated ML approach was also applied to classify deposition quality from process factors, with logistic regression delivering robust accuracy. By fusing data-driven learning and fundamental physics, this dual methodology provides comprehensive insights into tailoring microstructure through thermal management in AFSD. The work demonstrates the power of bridging statistical and physics-based modeling for elucidating AM process-property relationships.
</details>
<details>
<summary>摘要</summary>
添加式摩擦拌填（AFSD）是一种新型的固体添加制造技术，可以避免传统粉末压缩和指向能量激光束等方法中的孔隙、裂纹和性能不均问题。然而，AFSD的进程参数与热 profiling以及结果结构之间的关系仍然不够了解，这限制了进程优化以获得理想的性能。这项工作使用了一种前沿的框架，结合监督式机器学习（SML）和物理学习网络（PINNs），预测AFSD中热分布的峰值温度。这里实现了8种回归算法 дляSML模型，而4种PINNs利用了传输、波动、热传递和量子力学的管理方程。在多个统计度量上， ensemble技术如Gradient Boosting在SML中证明了最低MSE值为165.78。此外，这种混合的机器学习方法还应用于分类处理过程因素，使用了梯度提升算法获得了可靠的准确率。通过融合数据驱动学习和基础物理学习，这种双重方法提供了全面的理解添加制造过程中热管理对微structure的影响，并且演示了将统计学和物理学基础模型融合的力量，以描述AM过程-性能关系。
</details></li>
</ul>
<hr>
<h2 id="Safe-Reinforcement-Learning-with-Dual-Robustness"><a href="#Safe-Reinforcement-Learning-with-Dual-Robustness" class="headerlink" title="Safe Reinforcement Learning with Dual Robustness"></a>Safe Reinforcement Learning with Dual Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06835">http://arxiv.org/abs/2309.06835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyang Li, Chuxiong Hu, Yunan Wang, Yujie Yang, Shengbo Eben Li</li>
<li>for: 本研究旨在整合安全RL和RobustRL，提供一个系统性框架，以便在严重情况下同时保证任务完成度和安全性。</li>
<li>methods: 本研究使用束定二player零游戏为基础，提出了一个双政策迭代法，同时优化任务政策和安全政策，并证明了迭代法的收敛性。</li>
<li>results: 实验结果显示，DRAC算法在所有情况下（无敌手、安全敌手、性能敌手）具有高性能和持续安全性，较以基eline为主的所有基eline。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) agents are vulnerable to adversarial disturbances, which can deteriorate task performance or compromise safety specifications. Existing methods either address safety requirements under the assumption of no adversary (e.g., safe RL) or only focus on robustness against performance adversaries (e.g., robust RL). Learning one policy that is both safe and robust remains a challenging open problem. The difficulty is how to tackle two intertwined aspects in the worst cases: feasibility and optimality. Optimality is only valid inside a feasible region, while identification of maximal feasible region must rely on learning the optimal policy. To address this issue, we propose a systematic framework to unify safe RL and robust RL, including problem formulation, iteration scheme, convergence analysis and practical algorithm design. This unification is built upon constrained two-player zero-sum Markov games. A dual policy iteration scheme is proposed, which simultaneously optimizes a task policy and a safety policy. The convergence of this iteration scheme is proved. Furthermore, we design a deep RL algorithm for practical implementation, called dually robust actor-critic (DRAC). The evaluations with safety-critical benchmarks demonstrate that DRAC achieves high performance and persistent safety under all scenarios (no adversary, safety adversary, performance adversary), outperforming all baselines significantly.
</details>
<details>
<summary>摘要</summary>
利用强化学习（Reinforcement Learning，RL）代理人是易受到敌对干扰的，这可能会导致任务性能下降或者安全要求不符。现有的方法可以在恶作用者不存在的假设下处理安全要求（例如，安全RL），或者只是关注性能对抗者（例如，Robust RL）。学习一个同时具有安全和Robust性的策略是RL领域的一个挑战。这是由于feasibility和optimal性之间的关系，feasibility只能在一个可行的区域内确定，而optimal性则需要学习最佳策略。为解决这个问题，我们提出了一个系统性的框架，这个框架包括问题设定、迭代算法、收敛分析以及实用算法设计。这个框架基于含约两个player零点游戏。我们提出了一种双策略迭代算法，该算法同时优化一个任务策略和一个安全策略。我们证明了这个迭代算法的收敛性。此外，我们还设计了一种深度学习算法，即dually robust actor-critic（DRAC）。我们的实验表明，DRAC在所有情况下（无敌对者、安全敌对者、性能敌对者）都能够达到高性能和持续的安全性，与所有基elines（baselines）相比，DRAC表现出色。
</details></li>
</ul>
<hr>
<h2 id="Learning-From-Drift-Federated-Learning-on-Non-IID-Data-via-Drift-Regularization"><a href="#Learning-From-Drift-Federated-Learning-on-Non-IID-Data-via-Drift-Regularization" class="headerlink" title="Learning From Drift: Federated Learning on Non-IID Data via Drift Regularization"></a>Learning From Drift: Federated Learning on Non-IID Data via Drift Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07189">http://arxiv.org/abs/2309.07189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeachan Kim, Bonggun Shin</li>
<li>for: 这个研究旨在提高 Federated Learning  Algorithms 在异步变的环境中表现。</li>
<li>methods: 这个研究使用了 Regularization 技术来防止模型在异步变的环境中表现下降。Specifically, 这个方法包含 two key components: drift estimation 和 drift regularization。</li>
<li>results: 实验结果显示，LfD 方法在五个 Federated Learning 方面表现出色：Generalization, Heterogeneity, Scalability, Forgetting, 和 Efficiency。Comprehensive evaluation results clearly support the superiority of LfD in federated learning with Non-IID data。<details>
<summary>Abstract</summary>
Federated learning algorithms perform reasonably well on independent and identically distributed (IID) data. They, on the other hand, suffer greatly from heterogeneous environments, i.e., Non-IID data. Despite the fact that many research projects have been done to address this issue, recent findings indicate that they are still sub-optimal when compared to training on IID data. In this work, we carefully analyze the existing methods in heterogeneous environments. Interestingly, we find that regularizing the classifier's outputs is quite effective in preventing performance degradation on Non-IID data. Motivated by this, we propose Learning from Drift (LfD), a novel method for effectively training the model in heterogeneous settings. Our scheme encapsulates two key components: drift estimation and drift regularization. Specifically, LfD first estimates how different the local model is from the global model (i.e., drift). The local model is then regularized such that it does not fall in the direction of the estimated drift. In the experiment, we evaluate each method through the lens of the five aspects of federated learning, i.e., Generalization, Heterogeneity, Scalability, Forgetting, and Efficiency. Comprehensive evaluation results clearly support the superiority of LfD in federated learning with Non-IID data.
</details>
<details>
<summary>摘要</summary>
联邦学习算法在独立且同分布（IID）数据上表现良好。然而，在不同环境下（Non-IID）时，它们受到严重的影响，Recent research has shown that they are still suboptimal compared to training on IID data. In this work, we carefully analyze the existing methods in heterogeneous environments. Interestingly, we find that regularizing the classifier's outputs is quite effective in preventing performance degradation on Non-IID data. Motivated by this, we propose Learning from Drift (LfD), a novel method for effectively training the model in heterogeneous settings. Our scheme encapsulates two key components: drift estimation and drift regularization. Specifically, LfD first estimates how different the local model is from the global model (i.e., drift). The local model is then regularized such that it does not fall in the direction of the estimated drift. In the experiment, we evaluate each method through the lens of the five aspects of federated learning, i.e., Generalization, Heterogeneity, Scalability, Forgetting, and Efficiency. Comprehensive evaluation results clearly support the superiority of LfD in federated learning with Non-IID data.
</details></li>
</ul>
<hr>
<h2 id="Electricity-Demand-Forecasting-through-Natural-Language-Processing-with-Long-Short-Term-Memory-Networks"><a href="#Electricity-Demand-Forecasting-through-Natural-Language-Processing-with-Long-Short-Term-Memory-Networks" class="headerlink" title="Electricity Demand Forecasting through Natural Language Processing with Long Short-Term Memory Networks"></a>Electricity Demand Forecasting through Natural Language Processing with Long Short-Term Memory Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06793">http://arxiv.org/abs/2309.06793</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Bai, Simon Camal, Andrea Michiorri</li>
<li>for: 本研究旨在提高英国国家电力需求预测的性能，通过 incorporating 文本新闻特征。</li>
<li>methods: 本研究使用长短Term Memory（LSTM）网络，并将文本新闻特征与历史荷载、天气预报、历法信息和知情事件结合使用。</li>
<li>results: 实验结果显示，公众情绪和交通和地政受到的词归档表示在电力需求中有时间连续性作用，LSTM与文本特征组合比对chmark平台上的LSTM准确预测3%左右，比官方benchmark的预测10%左右。此外，提出的模型可以有效减少预测不确定性，缩短预测分布和减少预测不确定性。<details>
<summary>Abstract</summary>
Electricity demand forecasting is a well established research field. Usually this task is performed considering historical loads, weather forecasts, calendar information and known major events. Recently attention has been given on the possible use of new sources of information from textual news in order to improve the performance of these predictions. This paper proposes a Long and Short-Term Memory (LSTM) network incorporating textual news features that successfully predicts the deterministic and probabilistic tasks of the UK national electricity demand. The study finds that public sentiment and word vector representations related to transport and geopolitics have time-continuity effects on electricity demand. The experimental results show that the LSTM with textual features improves by more than 3% compared to the pure LSTM benchmark and by close to 10% over the official benchmark. Furthermore, the proposed model effectively reduces forecasting uncertainty by narrowing the confidence interval and bringing the forecast distribution closer to the truth.
</details>
<details>
<summary>摘要</summary>
电力需求预测是一个已有研究的领域。通常这项任务通过历史荷载、天气预报、历程信息和知道的主要事件来完成。近期关注到新的信息来源——文本新闻的可能性，以提高预测性能。本文提出一个使用长短期记忆（LSTM）网络，并将文本新闻特征纳入预测模型中，成功预测英国全国电力需求的 deterministic 和 probabilistic 任务。研究发现，公众情绪和交通和地opolitics 相关词 vector 具有时间连续性效应，对电力需求产生影响。实验结果显示，LSTM 与文本特征相加的模型，与纯度 LSTM 参考模型比进行了超过 3% 的提高，与官方参考模型比进行了接近 10% 的提高。此外，提议的模型还能够有效减少预测不确定性，缩短信息分布，使预测 Distribution 更加接近真实。
</details></li>
</ul>
<hr>
<h2 id="Scalable-neural-network-models-and-terascale-datasets-for-particle-flow-reconstruction"><a href="#Scalable-neural-network-models-and-terascale-datasets-for-particle-flow-reconstruction" class="headerlink" title="Scalable neural network models and terascale datasets for particle-flow reconstruction"></a>Scalable neural network models and terascale datasets for particle-flow reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06782">http://arxiv.org/abs/2309.06782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joosep Pata, Eric Wulff, Farouk Mokhtar, David Southwick, Mengke Zhang, Maria Girone, Javier Duarte</li>
<li>for: 这个论文是为了研究高能电子- пози特核反应中的全事件重建方法。</li>
<li>methods: 这个论文使用图 neural network和基于kernel的transformer来实现PF重建，两者都避免了 quadratic memory allocation和计算成本，同时实现了真实的PF重建。</li>
<li>results: 研究发现，通过超级计算机进行参数调整可以大幅提高物理性能，并且模型可以在不同的硬件处理器上高度可移植，支持Nvidia、AMD和Intel Habana卡。此外，模型可以在高精度输入上进行训练，并达到与基准相当的物理性能。<details>
<summary>Abstract</summary>
We study scalable machine learning models for full event reconstruction in high-energy electron-positron collisions based on a highly granular detector simulation. Particle-flow (PF) reconstruction can be formulated as a supervised learning task using tracks and calorimeter clusters or hits. We compare a graph neural network and kernel-based transformer and demonstrate that both avoid quadratic memory allocation and computational cost while achieving realistic PF reconstruction. We show that hyperparameter tuning on a supercomputer significantly improves the physics performance of the models. We also demonstrate that the resulting model is highly portable across hardware processors, supporting Nvidia, AMD, and Intel Habana cards. Finally, we demonstrate that the model can be trained on highly granular inputs consisting of tracks and calorimeter hits, resulting in a competitive physics performance with the baseline. Datasets and software to reproduce the studies are published following the findable, accessible, interoperable, and reusable (FAIR) principles.
</details>
<details>
<summary>摘要</summary>
我们研究可扩展机器学习模型以实现高能电子-正电子撞击中全事件重建，基于高度粒子化计算机模拟。流聚（PF）重建可以表示为监督学习任务，使用轨迹和calorimeter团结或触发。我们比较了图 neural network和基于核 kernel transformer，并证明它们可以避免平方根内存分配和计算成本，同时实现实际PF重建。我们表明在超级计算机上调整超参数可以显著提高物理性能。我们还示出了模型可以在不同的硬件处理器上高度可移植，支持Nvidia、AMD和Intel Habana卡。最后，我们示出了模型可以在高度粒子化输入上训练，并达到与基准相当的物理性能。我们发布了相关的数据集和软件，以便根据FAIR原则进行重用。
</details></li>
</ul>
<hr>
<h2 id="MCNS-Mining-Causal-Natural-Structures-Inside-Time-Series-via-A-Novel-Internal-Causality-Scheme"><a href="#MCNS-Mining-Causal-Natural-Structures-Inside-Time-Series-via-A-Novel-Internal-Causality-Scheme" class="headerlink" title="MCNS: Mining Causal Natural Structures Inside Time Series via A Novel Internal Causality Scheme"></a>MCNS: Mining Causal Natural Structures Inside Time Series via A Novel Internal Causality Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06739">http://arxiv.org/abs/2309.06739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Liu, Dehui Du, Zihan Jiang, Anyan Huang, Yiyang Li</li>
<li>for: 本研究旨在探讨时序序列中的内在 causality，以提高神经网络（NN）的准确性和可读性。</li>
<li>methods: 该研究提出了一种名为 “Mining Causal Natural Structure”（MCNS）的新框架，可自动找到时序序列中的内在 causality，并将其应用于 NN 中。</li>
<li>results: 实验结果表明，通过使用 MCNS 框架和浸泡 NN  WITH MCNS，可以提高时序序列分类任务的准确性和可读性，同时还能提供深入的时序序列和数据Summary。<details>
<summary>Abstract</summary>
Causal inference permits us to discover covert relationships of various variables in time series. However, in most existing works, the variables mentioned above are the dimensions. The causality between dimensions could be cursory, which hinders the comprehension of the internal relationship and the benefit of the causal graph to the neural networks (NNs). In this paper, we find that causality exists not only outside but also inside the time series because it reflects a succession of events in the real world. It inspires us to seek the relationship between internal subsequences. However, the challenges are the hardship of discovering causality from subsequences and utilizing the causal natural structures to improve NNs. To address these challenges, we propose a novel framework called Mining Causal Natural Structure (MCNS), which is automatic and domain-agnostic and helps to find the causal natural structures inside time series via the internal causality scheme. We evaluate the MCNS framework and impregnation NN with MCNS on time series classification tasks. Experimental results illustrate that our impregnation, by refining attention, shape selection classification, and pruning datasets, drives NN, even the data itself preferable accuracy and interpretability. Besides, MCNS provides an in-depth, solid summary of the time series and datasets.
</details>
<details>
<summary>摘要</summary>
causal inference 允许我们发现时序列中变量之间的隐藏关系。然而，现有大多数工作中的变量都是维度，这使得变量之间的相互关系受到忽视，从而阻碍了我们理解内部关系和使用 causal graph 进行神经网络（NN）的优化。在这篇论文中，我们发现时序列中的 causality 不仅存在于外部，而且还存在于内部，因为它反映了实际世界中的事件顺序。这使我们感兴趣寻找内部 subsequences 之间的关系。然而，挑战在于从 subsequences 中发现 causality 和使用 causal natural structure 来改进 NN。为了解决这些挑战，我们提出了一种新的框架，即 Mining Causal Natural Structure (MCNS)，它是自动化和领域无关的。MCNS 可以在时序列中找到内部 causal natural structure，并通过 internal causality scheme 来帮助我们更好地理解时序列和数据集。我们对 MCNS 框架和将 MCNS 束入 NN 进行评估。实验结果表明，我们的束入，通过修改注意力、形态选择分类和减少数据集，使得 NN 的准确率和可读性得到了提高。此外，MCNS 还为时序列和数据集提供了深入、坚实的总结。
</details></li>
</ul>
<hr>
<h2 id="Bias-Amplification-Enhances-Minority-Group-Performance"><a href="#Bias-Amplification-Enhances-Minority-Group-Performance" class="headerlink" title="Bias Amplification Enhances Minority Group Performance"></a>Bias Amplification Enhances Minority Group Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06717">http://arxiv.org/abs/2309.06717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gaotang Li, Jiarui Liu, Wei Hu</li>
<li>for: 提高模型对罕见 subgroup 的准确率，即使模型在平均 Label 上具有高准确率。</li>
<li>methods: 提出了一种两stage 训练算法 BAM，包括：首先通过引入每个训练样本的学习抽象变量进行偏好增强 scheme; 其次，对模型错误分类的样本进行权重提高，然后继续使用权重调整后的数据集进行训练。</li>
<li>results: 在计算机视觉和自然语言处理领域的假 correlate 测试 benchmark 上，BAM 实现了与现有方法相当的竞争性性能，并且提出了一个简单的停止 criterion，可以根据最小的类别准确率差来除除需要group注解。<details>
<summary>Abstract</summary>
Neural networks produced by standard training are known to suffer from poor accuracy on rare subgroups despite achieving high accuracy on average, due to the correlations between certain spurious features and labels. Previous approaches based on worst-group loss minimization (e.g. Group-DRO) are effective in improving worse-group accuracy but require expensive group annotations for all the training samples. In this paper, we focus on the more challenging and realistic setting where group annotations are only available on a small validation set or are not available at all. We propose BAM, a novel two-stage training algorithm: in the first stage, the model is trained using a bias amplification scheme via introducing a learnable auxiliary variable for each training sample; in the second stage, we upweight the samples that the bias-amplified model misclassifies, and then continue training the same model on the reweighted dataset. Empirically, BAM achieves competitive performance compared with existing methods evaluated on spurious correlation benchmarks in computer vision and natural language processing. Moreover, we find a simple stopping criterion based on minimum class accuracy difference that can remove the need for group annotations, with little or no loss in worst-group accuracy. We perform extensive analyses and ablations to verify the effectiveness and robustness of our algorithm in varying class and group imbalance ratios.
</details>
<details>
<summary>摘要</summary>
神经网络由标准训练生成的通常会受到罕见 subgroup 的准确率低下，即使它们在平均准确率高，因为某些干扰特征和标签之间的相关性。先前的方法（如 Group-DRO）可以提高罕见 subgroup 的准确率，但它们需要训练样本中的所有样本都有群标注。在这篇论文中，我们关注到更加挑战和现实的设定，即群标注只有小 Validation set 中或完全无法获得。我们提出了 BAM，一种新的两阶段训练算法：在第一阶段，模型通过引入每个训练样本的学习可读变量来进行偏好增强 schemes;在第二阶段，我们将模型对偏好增强后的样本进行重量增强，然后继续训练同样的模型。实际上，BAM 的性能与现有方法在假设分布 benchmark 上相似，并且我们发现一个简单的停止标准 Based on minimum class accuracy difference，可以消除群标注，而且影响最差群的准确率很小。我们进行了广泛的分析和减少来验证我们的算法在不同的类和群异常比例中的效果和稳定性。
</details></li>
</ul>
<hr>
<h2 id="Crystal-structure-prediction-using-neural-network-potential-and-age-fitness-Pareto-genetic-algorithm"><a href="#Crystal-structure-prediction-using-neural-network-potential-and-age-fitness-Pareto-genetic-algorithm" class="headerlink" title="Crystal structure prediction using neural network potential and age-fitness Pareto genetic algorithm"></a>Crystal structure prediction using neural network potential and age-fitness Pareto genetic algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06710">http://arxiv.org/abs/2309.06710</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sadmanomee/ParetoCSP">https://github.com/sadmanomee/ParetoCSP</a></li>
<li>paper_authors: Sadman Sadeed Omee, Lai Wei, Jianjun Hu</li>
<li>for: 预测晶体结构 (Crystal Structure Prediction, CSP) 问题的解决方案。</li>
<li>methods:  combinatorial 多目标遗传算法 (MOGA) 和神经网络间原子 potential (IAP) 模型，用于给化学组成提供能量最优的晶体结构。 使用 NSGA-III 算法，并将生物体质因素作为独立优化因素，使用 M3GNet 通用 IAP 引导 GA 搜索。</li>
<li>results: 比GN-OA State-of-the-art 神经 potential 基于 CSP 算法，ParetoCSP 在 $55$ 个多样化 bench mark 结构上表现出色，在七个性能指标上比GN-OA 高出 $2.562$ 倍。 Trajectory 分析表明，ParetoCSP 生成了更多的有效结构，帮助 GA 更好地搜索优化结构。<details>
<summary>Abstract</summary>
While crystal structure prediction (CSP) remains a longstanding challenge, we introduce ParetoCSP, a novel algorithm for CSP, which combines a multi-objective genetic algorithm (MOGA) with a neural network inter-atomic potential (IAP) model to find energetically optimal crystal structures given chemical compositions. We enhance the NSGA-III algorithm by incorporating the genotypic age as an independent optimization criterion and employ the M3GNet universal IAP to guide the GA search. Compared to GN-OA, a state-of-the-art neural potential based CSP algorithm, ParetoCSP demonstrated significantly better predictive capabilities, outperforming by a factor of $2.562$ across $55$ diverse benchmark structures, as evaluated by seven performance metrics. Trajectory analysis of the traversed structures of all algorithms shows that ParetoCSP generated more valid structures than other algorithms, which helped guide the GA to search more effectively for the optimal structures
</details>
<details>
<summary>摘要</summary>
While crystal structure prediction (CSP) remains a longstanding challenge, we introduce ParetoCSP, a novel algorithm for CSP, which combines a multi-objective genetic algorithm (MOGA) with a neural network inter-atomic potential (IAP) model to find energetically optimal crystal structures given chemical compositions. We enhance the NSGA-III algorithm by incorporating the genotypic age as an independent optimization criterion and employ the M3GNet universal IAP to guide the GA search. Compared to GN-OA, a state-of-the-art neural potential based CSP algorithm, ParetoCSP demonstrated significantly better predictive capabilities, outperforming by a factor of $2.562$ across $55$ diverse benchmark structures, as evaluated by seven performance metrics. Trajectory analysis of the traversed structures of all algorithms shows that ParetoCSP generated more valid structures than other algorithms, which helped guide the GA to search more effectively for the optimal structures.Here's the translation in Traditional Chinese:而 crystal structure prediction (CSP) 仍然是一个长期的挑战，我们介绍 ParetoCSP，一个新的 CSP 算法，它结合了多个目标遗传算法 (MOGA) 和一个神经网络间原子 potential (IAP) 模型，以发现化学成分所给予的能量最佳晶体结构。我们将 NSGA-III 算法加以改进，包括将生物遗传年龄作为独立优化标准，并使用 M3GNet 通用 IAP 导引 GA 搜索。与 GN-OA，一个现有的神经可能性基于 CSP 算法，ParetoCSP 在 $55$ 个多样的参考结构上显示出明显更好的预测能力，在七个效能指标上出performances by a factor of $2.562$。探索所有算法的轨迹分析显示，ParetoCSP 产生了更多的有效结构，帮助 GA 更有效地寻找最佳结构。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Fatigue-Crack-Growth-via-Path-Slicing-and-Re-Weighting"><a href="#Predicting-Fatigue-Crack-Growth-via-Path-Slicing-and-Re-Weighting" class="headerlink" title="Predicting Fatigue Crack Growth via Path Slicing and Re-Weighting"></a>Predicting Fatigue Crack Growth via Path Slicing and Re-Weighting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06708">http://arxiv.org/abs/2309.06708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhaoyj21/fcg">https://github.com/zhaoyj21/fcg</a></li>
<li>paper_authors: Yingjie Zhao, Yong Liu, Zhiping Xu</li>
<li>for: 预测结构元件的疲劳风险，即疲劳破坏的可能性，是工程设计中非常重要的一环。</li>
<li>methods: 本文使用统计学学习框架来预测疲劳裂 crack 的增长和元件的寿命。文中使用数字图书馆来构建疲劳裂 crack 的模式和剩余寿命。使用维度减少和神经网络架构来学习疲劳裂 crack 的历史依赖性和非线性。</li>
<li>results: 文中的预测方法可以准确地预测疲劳裂 crack 的增长和元件的寿命。示例中使用板件的疲劳裂 crack，验证了数字神经网络的实时结构健康监测和疲劳寿命预测方法。<details>
<summary>Abstract</summary>
Predicting potential risks associated with the fatigue of key structural components is crucial in engineering design. However, fatigue often involves entangled complexities of material microstructures and service conditions, making diagnosis and prognosis of fatigue damage challenging. We report a statistical learning framework to predict the growth of fatigue cracks and the life-to-failure of the components under loading conditions with uncertainties. Digital libraries of fatigue crack patterns and the remaining life are constructed by high-fidelity physical simulations. Dimensionality reduction and neural network architectures are then used to learn the history dependence and nonlinearity of fatigue crack growth. Path-slicing and re-weighting techniques are introduced to handle the statistical noises and rare events. The predicted fatigue crack patterns are self-updated and self-corrected by the evolving crack patterns. The end-to-end approach is validated by representative examples with fatigue cracks in plates, which showcase the digital-twin scenario in real-time structural health monitoring and fatigue life prediction for maintenance management decision-making.
</details>
<details>
<summary>摘要</summary>
预测结构元件的疲劳风险是工程设计中非常重要的一环。然而，疲劳往往具有材料微结构和服务条件之间的紧张关系，使诊断和预测疲劳损伤变得具有挑战性。我们报道了一种统计学学习框架，用于预测负荷下疲劳裂纹的增长和元件的寿命。通过高精度物理 simulations  construct 疲劳裂纹和剩余寿命的数字图书馆。使用维度减少和神经网络架构，学习疲劳裂纹的历史依赖和非线性。使用路径排序和重新权重技术，处理统计噪音和罕见事件。预测的疲劳裂纹自动更新和自我更正，具有实时结构健康监测和疲劳寿命预测功能，为维护决策提供了数字 scenario。
</details></li>
</ul>
<hr>
<h2 id="Federated-PAC-Bayesian-Learning-on-Non-IID-data"><a href="#Federated-PAC-Bayesian-Learning-on-Non-IID-data" class="headerlink" title="Federated PAC-Bayesian Learning on Non-IID data"></a>Federated PAC-Bayesian Learning on Non-IID data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06683">http://arxiv.org/abs/2309.06683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihao Zhao, Yang Liu, Wenbo Ding, Xiao-Ping Zhang</li>
<li>for: 本研究是为了提供非独立Identical Distributions（non-IID） Federated Learning（FL）中的 Probably Approximately Correct（PAC） Bayesian bounds。</li>
<li>methods: 本研究使用了唯一的前知识和变量汇集 веса，并提出了一个新的 Gibbs 算法来优化 derivated bound。</li>
<li>results: 研究 validate 了在实际数据上。I hope this helps! Let me know if you have any further questions or if you’d like me to translate anything else.<details>
<summary>Abstract</summary>
Existing research has either adapted the Probably Approximately Correct (PAC) Bayesian framework for federated learning (FL) or used information-theoretic PAC-Bayesian bounds while introducing their theorems, but few considering the non-IID challenges in FL. Our work presents the first non-vacuous federated PAC-Bayesian bound tailored for non-IID local data. This bound assumes unique prior knowledge for each client and variable aggregation weights. We also introduce an objective function and an innovative Gibbs-based algorithm for the optimization of the derived bound. The results are validated on real-world datasets.
</details>
<details>
<summary>摘要</summary>
转换文本为简化中文。<</SYS>>现有研究 either 采用了 Probably Approximately Correct（PAC）抽象框架 для联合学习（FL），或使用信息理论PAC-抽象 bounds，但很少考虑非Identical和分布（non-IID）挑战。我们的工作提供了首个非虚无的联合PAC-抽象约束，特点是每个客户端和变量权重。我们还介绍了一个目标函数和一种创新的吉卜斯-based算法来优化 derive的约束。结果在实际数据上验证。
</details></li>
</ul>
<hr>
<h2 id="Generalizable-improvement-of-the-Spalart-Allmaras-model-through-assimilation-of-experimental-data"><a href="#Generalizable-improvement-of-the-Spalart-Allmaras-model-through-assimilation-of-experimental-data" class="headerlink" title="Generalizable improvement of the Spalart-Allmaras model through assimilation of experimental data"></a>Generalizable improvement of the Spalart-Allmaras model through assimilation of experimental data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06679">http://arxiv.org/abs/2309.06679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepinder Jot Singh Aulakh, Romit Maulik</li>
<li>for: 这个研究旨在使用模型和数据融合提高Spalart-Allmaras（SA）闭合模型的纳维-斯托克解（RANS）解析方法，尤其是在分离流场下。</li>
<li>methods: 我们使用了数据融合，即ensemble Kalman filtering（EnKF）方法，来调整SA模型中的系数，以改进 computational models 的性能。</li>
<li>results: 我们发现，使用单个流条件逆推缘（BFS）的实验数据进行calibration后，重新调整的SA模型能够在其他分离流场中表现出优化的结果，包括2D-缘和修改BFS等情况。此外，我们还发现SA模型在不同的外部流场中能够保持其能力，而且各个模型部分的调整targeted towards specific flow-physics。<details>
<summary>Abstract</summary>
This study focuses on the use of model and data fusion for improving the Spalart-Allmaras (SA) closure model for Reynolds-averaged Navier-Stokes solutions of separated flows. In particular, our goal is to develop of models that not-only assimilate sparse experimental data to improve performance in computational models, but also generalize to unseen cases by recovering classical SA behavior. We achieve our goals using data assimilation, namely the Ensemble Kalman Filtering approach (EnKF), to calibrate the coefficients of the SA model for separated flows. A holistic calibration strategy is implemented via a parameterization of the production, diffusion, and destruction terms. This calibration relies on the assimilation of experimental data collected velocity profiles, skin friction, and pressure coefficients for separated flows. Despite using of observational data from a single flow condition around a backward-facing step (BFS), the recalibrated SA model demonstrates generalization to other separated flows, including cases such as the 2D-bump and modified BFS. Significant improvement is observed in the quantities of interest, i.e., skin friction coefficient ($C_f$) and pressure coefficient ($C_p$) for each flow tested. Finally, it is also demonstrated that the newly proposed model recovers SA proficiency for external, unseparated flows, such as flow around a NACA-0012 airfoil without any danger of extrapolation, and that the individually calibrated terms in the SA model are targeted towards specific flow-physics wherein the calibrated production term improves the re-circulation zone while destruction improves the recovery zone.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-step-prediction-of-chlorophyll-concentration-based-on-Adaptive-Graph-Temporal-Convolutional-Network-with-Series-Decomposition"><a href="#Multi-step-prediction-of-chlorophyll-concentration-based-on-Adaptive-Graph-Temporal-Convolutional-Network-with-Series-Decomposition" class="headerlink" title="Multi-step prediction of chlorophyll concentration based on Adaptive Graph-Temporal Convolutional Network with Series Decomposition"></a>Multi-step prediction of chlorophyll concentration based on Adaptive Graph-Temporal Convolutional Network with Series Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07187">http://arxiv.org/abs/2309.07187</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Chen, Xiao Li, Hongbo Zhang, Wenyang Song, Chongxuan Xv</li>
<li>for: 本研究旨在预测水体中氨基酸浓度的变化趋势，以便为环境保护和水产业提供科学依据。</li>
<li>methods: 该研究提出了一种基于时间分解和自适应图 convolutional neural network (AGTCNSD) 预测模型，通过分解原始序列为趋势组件和周期组件，并使用图 convolutional neural network 模型水质参数数据，并使用矩阵分解法 assigning 参数权重。</li>
<li>results: 研究表明，该预测模型在用于预测氨基酸浓度的水质数据中表现出色，比其他方法更好。这可以作为环境管理决策的科学资源。<details>
<summary>Abstract</summary>
Chlorophyll concentration can well reflect the nutritional status and algal blooms of water bodies, and is an important indicator for evaluating water quality. The prediction of chlorophyll concentration change trend is of great significance to environmental protection and aquaculture. However, there is a complex and indistinguishable nonlinear relationship between many factors affecting chlorophyll concentration. In order to effectively mine the nonlinear features contained in the data. This paper proposes a time-series decomposition adaptive graph-time convolutional network ( AGTCNSD ) prediction model. Firstly, the original sequence is decomposed into trend component and periodic component by moving average method. Secondly, based on the graph convolutional neural network, the water quality parameter data is modeled, and a parameter embedding matrix is defined. The idea of matrix decomposition is used to assign weight parameters to each node. The adaptive graph convolution learns the relationship between different water quality parameters, updates the state information of each parameter, and improves the learning ability of the update relationship between nodes. Finally, time dependence is captured by time convolution to achieve multi-step prediction of chlorophyll concentration. The validity of the model is verified by the water quality data of the coastal city Beihai. The results show that the prediction effect of this method is better than other methods. It can be used as a scientific resource for environmental management decision-making.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT氯生蓝苷含量可以很好地反映水体营养状况和藻类繁殖，是评估水质的重要指标。预测氯生蓝苷含量变化趋势对环境保护和水产业是非常重要的。然而，许多影响氯生蓝苷含量的因素之间存在复杂和不可分别的非线性关系。为了有效挖掘数据中的非线性特征，这篇论文提出了时间序列归一化适应图 convolutional neural network (AGTCNSD) 预测模型。首先，原始序列被分解成趋势组件和周期组件使用移动平均方法。其次，基于图 convolutional neural network，水质参数数据被建模，并定义了参数嵌入矩阵。使用矩阵分解的想法，将每个节点的参数重量分配给每个节点。适应图 convolution 学习了不同水质参数之间的关系，更新每个参数的状态信息，并提高了更新关系 между节点的学习能力。最后，使用时间归一化 convolution 捕捉时间依赖，实现多步预测氯生蓝苷含量。验证模型的有效性通过海 coastal city Beihai 的水质数据进行验证。结果显示，这种方法的预测效果比其他方法更好。它可以作为环境管理决策的科学资源。>>
</details></li>
</ul>
<hr>
<h2 id="Sound-field-decomposition-based-on-two-stage-neural-networks"><a href="#Sound-field-decomposition-based-on-two-stage-neural-networks" class="headerlink" title="Sound field decomposition based on two-stage neural networks"></a>Sound field decomposition based on two-stage neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06661">http://arxiv.org/abs/2309.06661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryo Matsuda, Makoto Otani</li>
<li>for: 该研究提出了一种基于神经网络的声场分解方法，用于实时声源定位和声场重建。</li>
<li>methods: 该方法包括两个阶段：声场分离阶段和单源定位阶段。在第一阶段，通过多个源的声压在 микро机上合成的声场被分离为每个声源所激发的一个。在第二阶段，通过微机上的声压组成单个声源的来源位置的 regression 来获得估计的位置，而不受精度的影响。</li>
<li>results: 数据集通过 simulations 生成，使用Green’s function，并对每个频率进行训练。实验表明，与传统方法相比，提出的方法可以实现更高的源位置准确率和声场重建准确率。<details>
<summary>Abstract</summary>
A method for sound field decomposition based on neural networks is proposed. The method comprises two stages: a sound field separation stage and a single-source localization stage. In the first stage, the sound pressure at microphones synthesized by multiple sources is separated into one excited by each sound source. In the second stage, the source location is obtained as a regression from the sound pressure at microphones consisting of a single sound source. The estimated location is not affected by discretization because the second stage is designed as a regression rather than a classification. Datasets are generated by simulation using Green's function, and the neural network is trained for each frequency. Numerical experiments reveal that, compared with conventional methods, the proposed method can achieve higher source-localization accuracy and higher sound-field-reconstruction accuracy.
</details>
<details>
<summary>摘要</summary>
提出了基于神经网络的声场分解方法。该方法包括两个阶段：声场分离阶段和单源地址确定阶段。在第一阶段，通过多个源的声压在 Mikrofone  sintesized 被分离成每个声源促进的一个。在第二阶段，通过 Mikrofone 上的声压 regression 获取单个声源的位置，而不受精度的影响。数据集通过绿函数 simulations 生成，每个频率都进行神经网络训练。数字实验表明，相比 convent ional 方法，提出的方法可以 дости到更高的声源地址准确率和声场重建率。
</details></li>
</ul>
<hr>
<h2 id="Dissipative-Imitation-Learning-for-Discrete-Dynamic-Output-Feedback-Control-with-Sparse-Data-Sets"><a href="#Dissipative-Imitation-Learning-for-Discrete-Dynamic-Output-Feedback-Control-with-Sparse-Data-Sets" class="headerlink" title="Dissipative Imitation Learning for Discrete Dynamic Output Feedback Control with Sparse Data Sets"></a>Dissipative Imitation Learning for Discrete Dynamic Output Feedback Control with Sparse Data Sets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06658">http://arxiv.org/abs/2309.06658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amy K. Strong, Ethan J. LoCicero, Leila J. Bridgeman</li>
<li>for: 这篇论文旨在解决复杂目标和高度不确定的植入模型下的控制器 synthesis 问题，并提供稳定性保证。</li>
<li>methods: 论文使用输入输出稳定性方法，通过专家数据、粗略的输入输出植入模型和新的约束来学习一个关闭Loop稳定的动态输出反馈控制器。学习目标是非凸的，但是使用迭代凸上界法（ICO）和投影加速度下降（PGD）可以成功学习控制器。</li>
<li>results: 论文应用于两个未知的植入模型，与传统的动态输出反馈控制器和神经网络控制器进行比较。与少量数据和不知道植入模型的情况下，约束 constrained 学习的控制器可以在关闭Loop中稳定地运行，并成功模仿专家控制器的行为，而其他方法通常无法维持稳定性和达到良好的性能。<details>
<summary>Abstract</summary>
Imitation learning enables the synthesis of controllers for complex objectives and highly uncertain plant models. However, methods to provide stability guarantees to imitation learned controllers often rely on large amounts of data and/or known plant models. In this paper, we explore an input-output (IO) stability approach to dissipative imitation learning, which achieves stability with sparse data sets and with little known about the plant model. A closed-loop stable dynamic output feedback controller is learned using expert data, a coarse IO plant model, and a new constraint to enforce dissipativity on the learned controller. While the learning objective is nonconvex, iterative convex overbounding (ICO) and projected gradient descent (PGD) are explored as methods to successfully learn the controller. This new imitation learning method is applied to two unknown plants and compared to traditionally learned dynamic output feedback controller and neural network controller. With little knowledge of the plant model and a small data set, the dissipativity constrained learned controller achieves closed loop stability and successfully mimics the behavior of the expert controller, while other methods often fail to maintain stability and achieve good performance.
</details>
<details>
<summary>摘要</summary>
imitative学习可以实现控制器的合成，但是确保控制器的稳定性 часто需要大量数据和/或已知的植物模型。在这篇论文中，我们探索了输入输出（IO）稳定性方法，以达到稳定性的 guarantees  WITH sparse data sets AND little known about the plant model。我们使用专家数据、粗略的IO植物模型和一个新的约束来学习一个闭环稳定的动态输出反馈控制器。虽然学习目标是非凸的，但我们使用迭代凸上界（ICO）和投影Gradient Descent（PGD）来成功地学习控制器。这种新的imitative学习方法在两个未知的植物上应用，与传统学习的动态输出反馈控制器和神经网络控制器进行比较。与其他方法不同的是，我们的方法可以在小量数据和未知植物模型的情况下实现closed-loop稳定性，并成功地模仿专家控制器的行为。
</details></li>
</ul>
<hr>
<h2 id="Out-of-Distribution-Detection-via-Domain-Informed-Gaussian-Process-State-Space-Models"><a href="#Out-of-Distribution-Detection-via-Domain-Informed-Gaussian-Process-State-Space-Models" class="headerlink" title="Out of Distribution Detection via Domain-Informed Gaussian Process State Space Models"></a>Out of Distribution Detection via Domain-Informed Gaussian Process State Space Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06655">http://arxiv.org/abs/2309.06655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alonso Marco, Elias Morley, Claire J. Tomlin</li>
<li>for: 本文目的是提出一种基于学习的方法，使机器人在未经训练的情况下安全地探索 unknown 环境。</li>
<li>methods: 本文使用 Gaussian process state-space models (GPSSMs) 来识别不符合训练数据的情况，通过比较预测值与实际值进行识别。</li>
<li>results: 实验结果表明，通过嵌入域知识在核心中，可以提高 GPSSM 的预测质量，并且在实际四足机器人在室内环境中探索时，可以可靠地识别未经训练的地形。<details>
<summary>Abstract</summary>
In order for robots to safely navigate in unseen scenarios using learning-based methods, it is important to accurately detect out-of-training-distribution (OoD) situations online. Recently, Gaussian process state-space models (GPSSMs) have proven useful to discriminate unexpected observations by comparing them against probabilistic predictions. However, the capability for the model to correctly distinguish between in- and out-of-training distribution observations hinges on the accuracy of these predictions, primarily affected by the class of functions the GPSSM kernel can represent. In this paper, we propose (i) a novel approach to embed existing domain knowledge in the kernel and (ii) an OoD online runtime monitor, based on receding-horizon predictions. Domain knowledge is provided in the form of a dataset, collected either in simulation or by using a nominal model. Numerical results show that the informed kernel yields better regression quality with smaller datasets, as compared to standard kernel choices. We demonstrate the effectiveness of the OoD monitor on a real quadruped navigating an indoor setting, which reliably classifies previously unseen terrains.
</details>
<details>
<summary>摘要</summary>
为让机器人在未经训练的情况下安全地导航，使用学习基于方法是非常重要。在线上快速识别外部训练数据（OoD）的情况是非常重要的。在这篇论文中，我们提出了（i）一种将现有领域知识集成到kernel中的新方法，以及（ii）基于往返预测的OoD在线监控器。领域知识通过一个数据集，其中可以是 simulations或nominal模型中收集的。我们的数字结果显示，在小数据集情况下， Informed kernel可以提供更好的回归质量，与标准kernel相比。我们还证明了OoD监控器在实际四足机器人在室内环境中逻辑分类未经训练的地形。
</details></li>
</ul>
<hr>
<h2 id="ConR-Contrastive-Regularizer-for-Deep-Imbalanced-Regression"><a href="#ConR-Contrastive-Regularizer-for-Deep-Imbalanced-Regression" class="headerlink" title="ConR: Contrastive Regularizer for Deep Imbalanced Regression"></a>ConR: Contrastive Regularizer for Deep Imbalanced Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06651">http://arxiv.org/abs/2309.06651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/borealisai/conr">https://github.com/borealisai/conr</a></li>
<li>paper_authors: Mahsa Keramati, Lili Meng, R. David Evans</li>
<li>for: 这篇论文的目的是解决深度学习中的不对称分布问题，尤其是在回归 зада中。</li>
<li>methods: 这篇论文提出了一个名为ConR的对称调节器，它模型了数据中的全局和本地关系，并避免了小数据点被嵌入到大数据点中。</li>
<li>results: 根据该论文的实验结果，ConR可以对深度学习回归 зада中的不对称分布问题进行有效地解决，并且与现有的方法相比，具有更好的性能。<details>
<summary>Abstract</summary>
Imbalanced distributions are ubiquitous in real-world data. They create constraints on Deep Neural Networks to represent the minority labels and avoid bias towards majority labels. The extensive body of imbalanced approaches address categorical label spaces but fail to effectively extend to regression problems where the label space is continuous. Conversely, local and global correlations among continuous labels provide valuable insights towards effectively modelling relationships in feature space. In this work, we propose ConR, a contrastive regularizer that models global and local label similarities in feature space and prevents the features of minority samples from being collapsed into their majority neighbours. Serving the similarities of the predictions as an indicator of feature similarities, ConR discerns the dissagreements between the label space and feature space and imposes a penalty on these disagreements. ConR minds the continuous nature of label space with two main strategies in a contrastive manner: incorrect proximities are penalized proportionate to the label similarities and the correct ones are encouraged to model local similarities. ConR consolidates essential considerations into a generic, easy-to-integrate, and efficient method that effectively addresses deep imbalanced regression. Moreover, ConR is orthogonal to existing approaches and smoothly extends to uni- and multi-dimensional label spaces. Our comprehensive experiments show that ConR significantly boosts the performance of all the state-of-the-art methods on three large-scale deep imbalanced regression benchmarks. Our code is publicly available in https://github.com/BorealisAI/ConR.
</details>
<details>
<summary>摘要</summary>
实际世界数据中很常见偏置分布。它们限制深度神经网络来表示少数标签，并避免对多数标签的偏袋。然而，现有的偏置方法主要集中在 categorical 标签空间上，并未能有效扩展到回归问题，其标签空间是连续的。相反，本文提出了 ConR，一种对准规化器，该模型在特征空间中模型全局和本地标签相似性，并防止少数样本的特征被推入多数样本的邻居中。通过将预测结果作为特征相似性的指标，ConR 可以识别标签和特征空间之间的不一致，并对这些不一致进行罚款。ConR 通过两种主要策略在对照方式进行处理： incorrect 邻接被罚款与标签相似性成比例，而正确的邻接被鼓励以模型本地相似性。ConR 汇集了重要考虑因素，并将其转化为一种通用、易于集成、高效的方法，可以有效地解决深层偏置回归问题。此外，ConR 与现有方法相互正交，可以顺利扩展到一维和多维标签空间。我们的实验表明，ConR 可以显著提高现有状态之前方法的性能在三个大规模深层偏置回归 benchmark 上。我们的代码可以在 <https://github.com/BorealisAI/ConR> 上公开获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/13/cs.LG_2023_09_13/" data-id="clohum99u00obpj88c8qb66rt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/13/eess.IV_2023_09_13/" class="article-date">
  <time datetime="2023-09-13T09:00:00.000Z" itemprop="datePublished">2023-09-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/13/eess.IV_2023_09_13/">eess.IV - 2023-09-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Temporal-compressive-edge-imaging-enabled-by-a-lensless-diffuser-camera"><a href="#Temporal-compressive-edge-imaging-enabled-by-a-lensless-diffuser-camera" class="headerlink" title="Temporal compressive edge imaging enabled by a lensless diffuser camera"></a>Temporal compressive edge imaging enabled by a lensless diffuser camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07198">http://arxiv.org/abs/2309.07198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ze Zheng, Baolei Liu, Jiaqi Song, Lei Ding, Xiaolan Zhong, David Mcgloin, Fan Wang</li>
<li>for: 高维度图像取得和动态物体检测</li>
<li>methods: 使用干扰器或编码面镜来实现无镜头成像系统，并使用时间压缩Edge检测方法直接从单步测量中提取动态物体的时间序列Edge图像</li>
<li>results: 提高图像质量并减少后处理步骤，可以进一步发展为多种任务专业无镜头成像系统<details>
<summary>Abstract</summary>
Lensless imagers based on diffusers or encoding masks enable high-dimensional imaging from a single shot measurement and have been applied in various applications. However, to further extract image information such as edge detection, conventional post-processing filtering operations are needed after the reconstruction of the original object images in the diffuser imaging systems. Here, we present the concept of a temporal compressive edge detection method based on a lensless diffuser camera, which can directly recover a time sequence of edge images of a moving object from a single-shot measurement, without further post-processing steps. Our approach provides higher image quality during edge detection, compared with the conventional post-processing method. We demonstrate the effectiveness of this approach by both numerical simulation and experiments. The proof-of-concept approach can be further developed with other image post-process operations or versatile computer vision assignments toward task-oriented intelligent lensless imaging systems.
</details>
<details>
<summary>摘要</summary>
Diffuser 或编码面增强的镜头less imaging 技术可以实现高维度图像取得，并在不同应用中使用。然而，为了进一步提取图像信息，例如边检测，传统的后处理滤波操作是必要的。在这种情况下，我们提出了基于减压 diffuser 摄像机的时间压缩边检测方法，可以从单个测量中直接回收移动物体的时间序列边图像，无需进一步的后处理步骤。我们的方法可以提供更高的图像质量，比传统的后处理方法更高。我们通过数值模拟和实验证明了这种方法的有效性。这种概念可以进一步发展为任务导向的智能镜头less imaging 系统。
</details></li>
</ul>
<hr>
<h2 id="Improving-HEVC-Encoding-of-Rendered-Video-Data-Using-True-Motion-Information"><a href="#Improving-HEVC-Encoding-of-Rendered-Video-Data-Using-True-Motion-Information" class="headerlink" title="Improving HEVC Encoding of Rendered Video Data Using True Motion Information"></a>Improving HEVC Encoding of Rendered Video Data Using True Motion Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06945">http://arxiv.org/abs/2309.06945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Herglotz, David Müller, Andreas Weinlich, Frank Bauer, Michael Ortner, Marc Stamminger, André Kaup</li>
<li>for: 提高计算机生成视频序列的编码过程</li>
<li>methods: 利用计算机生成的动态vector进行增强评估性能</li>
<li>results: 实现了3.78%的均值bitrate减少<details>
<summary>Abstract</summary>
This paper shows that motion vectors representing the true motion of an object in a scene can be exploited to improve the encoding process of computer generated video sequences. Therefore, a set of sequences is presented for which the true motion vectors of the corresponding objects were generated on a per-pixel basis during the rendering process. In addition to conventional motion estimation methods, it is proposed to exploit the computer generated motion vectors to enhance the ratedistortion performance. To this end, a motion vector mapping method including disocclusion handling is presented. It is shown that mean rate savings of 3.78% can be achieved.
</details>
<details>
<summary>摘要</summary>
这个论文表明，可以使用场景中对象的真实运动向量来改善计算机生成视频序列的编码过程。因此，一个集合的序列被提供，其中对应的对象的真实运动向量在渲染过程中按照每个像素基础生成。除了传统的运动估计方法外，还提议使用计算机生成的运动向量来提高评估性能。为此，一种运动向量映射方法，包括缺失处理，被提出。实验表明，可以获得3.78%的均值Rate savings。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-Synthetic-High-Resolution-In-Depth-Imaging-Using-an-Attachable-Dual-element-Endoscopic-Ultrasound-Probe"><a href="#Deep-Learning-based-Synthetic-High-Resolution-In-Depth-Imaging-Using-an-Attachable-Dual-element-Endoscopic-Ultrasound-Probe" class="headerlink" title="Deep Learning-based Synthetic High-Resolution In-Depth Imaging Using an Attachable Dual-element Endoscopic Ultrasound Probe"></a>Deep Learning-based Synthetic High-Resolution In-Depth Imaging Using an Attachable Dual-element Endoscopic Ultrasound Probe</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06770">http://arxiv.org/abs/2309.06770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hah Min Lew, Jae Seong Kim, Moon Hwan Lee, Jaegeun Park, Sangyeon Youn, Hee Man Kim, Jihun Kim, Jae Youn Hwang<br>for: This paper aims to provide clinicians with appropriate hardware specifications for precise diagnosis by enhancing the resolution and penetration depth of endoscopic ultrasound (EUS) imaging.methods: The proposed approach uses a novel deep learning-based high-resolution in-depth imaging probe that offers low- and high-frequency ultrasound image pairs. The probe is designed with customized low- and high-frequency ultrasound transducers and a special geared structure to enable the same image plane.results: The proposed approach was evaluated with a wire phantom and a tissue-mimicking phantom, and 442 ultrasound image pairs were acquired from the tissue-mimicking phantom. The results demonstrate the feasibility of the approach for providing synthetic high-resolution in-depth images deep inside tissues, and a suitable deep-learning model was identified for the task.<details>
<summary>Abstract</summary>
Endoscopic ultrasound (EUS) imaging has a trade-off between resolution and penetration depth. By considering the in-vivo characteristics of human organs, it is necessary to provide clinicians with appropriate hardware specifications for precise diagnosis. Recently, super-resolution (SR) ultrasound imaging studies, including the SR task in deep learning fields, have been reported for enhancing ultrasound images. However, most of those studies did not consider ultrasound imaging natures, but rather they were conventional SR techniques based on downsampling of ultrasound images. In this study, we propose a novel deep learning-based high-resolution in-depth imaging probe capable of offering low- and high-frequency ultrasound image pairs. We developed an attachable dual-element EUS probe with customized low- and high-frequency ultrasound transducers under small hardware constraints. We also designed a special geared structure to enable the same image plane. The proposed system was evaluated with a wire phantom and a tissue-mimicking phantom. After the evaluation, 442 ultrasound image pairs from the tissue-mimicking phantom were acquired. We then applied several deep learning models to obtain synthetic high-resolution in-depth images, thus demonstrating the feasibility of our approach for clinical unmet needs. Furthermore, we quantitatively and qualitatively analyzed the results to find a suitable deep-learning model for our task. The obtained results demonstrate that our proposed dual-element EUS probe with an image-to-image translation network has the potential to provide synthetic high-frequency ultrasound images deep inside tissues.
</details>
<details>
<summary>摘要</summary>
挺投射 ultrasound (EUS) 的分辨率和扩散深度之间存在负权衡。在考虑人体内部器官的实际特点下，为临床诊断提供合适的硬件参数是必要的。目前，使用深度学习技术进行超解像 (SR) ultrasound 图像修复的研究已经很多，但大多数这些研究并没有考虑 ultrasound 图像的特点，而是基于下采样的 ultrasound 图像进行 SR 技术。本研究提出了一种基于深度学习的高解像深度扫描仪，能够提供低频和高频 ultrasound 图像对。我们开发了一种可附加的双元 EUS 探针，其中包括特制的低频和高频 ultrasound 传感器。我们还设计了一种特殊的几何结构，以使得同一个图像平面。我们对用一束织物和一种组织模拟物进行评估。然后，我们获得了442个 ultrasound 图像对。我们应用了多种深度学习模型，以获得 sintetic 高解像深度图像，从而证明了我们的方法的可行性。此外，我们对结果进行了量化和质量分析，以选择适合我们任务的深度学习模型。获得的结果表明，我们的提议的双元 EUS 探针与嵌入式深度学习网络具有将高频 ultrasound 图像深入到组织中的潜力。
</details></li>
</ul>
<hr>
<h2 id="Improving-Deep-Learning-based-Defect-Detection-on-Window-Frames-with-Image-Processing-Strategies"><a href="#Improving-Deep-Learning-based-Defect-Detection-on-Window-Frames-with-Image-Processing-Strategies" class="headerlink" title="Improving Deep Learning-based Defect Detection on Window Frames with Image Processing Strategies"></a>Improving Deep Learning-based Defect Detection on Window Frames with Image Processing Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06731">http://arxiv.org/abs/2309.06731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jorge Vasquez, Hemant K. Sharma, Tomotake Furuhata, Kenji Shimada</li>
<li>for: The paper is written for researchers and manufacturers who are interested in using machine learning and computer vision techniques for defect detection in window frames, particularly in challenging environments like construction sites.</li>
<li>methods: The paper proposes a novel defect detection pipeline called InspectNet, which combines image enhancement and augmentation techniques with a pre-trained U-Net model for window frame defect detection and segmentation. The pipeline is designed to improve the accuracy of defect detection in challenging environments.</li>
<li>results: The paper presents the results of experiments conducted using a Spot Robot for window frame inspections, with 16 variations of the dataset constructed using different image augmentation settings. The results show that the proposed InspectNet pipeline outperformed other algorithms when image enhancement and augmentation techniques were applied, achieving an average Intersection over Union (IoU) value of 0.91 when using the best dataset.<details>
<summary>Abstract</summary>
Detecting subtle defects in window frames, including dents and scratches, is vital for upholding product integrity and sustaining a positive brand perception. Conventional machine vision systems often struggle to identify these defects in challenging environments like construction sites. In contrast, modern vision systems leveraging machine and deep learning (DL) are emerging as potent tools, particularly for cosmetic inspections. However, the promise of DL is yet to be fully realized. A few manufacturers have established a clear strategy for AI integration in quality inspection, hindered mainly by issues like scarce clean datasets and environmental changes that compromise model accuracy. Addressing these challenges, our study presents an innovative approach that amplifies defect detection in DL models, even with constrained data resources. The paper proposes a new defect detection pipeline called InspectNet (IPT-enhanced UNET) that includes the best combination of image enhancement and augmentation techniques for pre-processing the dataset and a Unet model tuned for window frame defect detection and segmentation. Experiments were carried out using a Spot Robot doing window frame inspections . 16 variations of the dataset were constructed using different image augmentation settings. Results of the experiments revealed that, on average, across all proposed evaluation measures, Unet outperformed all other algorithms when IPT-enhanced augmentations were applied. In particular, when using the best dataset, the average Intersection over Union (IoU) values achieved were IPT-enhanced Unet, reaching 0.91 of mIoU.
</details>
<details>
<summary>摘要</summary>
检测窗框中微型瑕疵，包括折叠和擦抹，是维护产品完整性和保持品牌形象的关键。传统的机器视觉系统经常在建筑现场中难以检测这些瑕疵。相比之下，现代视觉系统通过机器学习和深度学习（DL）在cosmetic检测方面表现出了强大的潜力。然而，DL的承诺仍未实现。一些制造商在质检中采用了明确的AI整合策略，主要受到数据质量缺乏和环境变化所迟缓。为了解决这些挑战，本研究提出了一种创新的瑕疵检测方法，包括适应数据资源的限制的图像增强和扩展技术，以及适应窗框瑕疵检测和分 segmentation的Unet模型。实验使用了一个Spot Robot进行窗框检测。根据不同的图像扩展设置，建立了16个变种的数据集。实验结果表明，在所有提议的评价指标中，Unet模型在IPT-加强的扩展设置下表现最佳，特别是在使用最佳数据集时，Unet模型的平均交集率（IoU）值达0.91。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/13/eess.IV_2023_09_13/" data-id="clohum9fs014upj883fh67r9s" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/13/eess.SP_2023_09_13/" class="article-date">
  <time datetime="2023-09-13T08:00:00.000Z" itemprop="datePublished">2023-09-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/13/eess.SP_2023_09_13/">eess.SP - 2023-09-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Space-Time-Adaptive-Processing-in-Connected-and-Automated-Vehicular-Radar-Platoons"><a href="#Space-Time-Adaptive-Processing-in-Connected-and-Automated-Vehicular-Radar-Platoons" class="headerlink" title="Space-Time Adaptive Processing in Connected and Automated Vehicular Radar Platoons"></a>Space-Time Adaptive Processing in Connected and Automated Vehicular Radar Platoons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07355">http://arxiv.org/abs/2309.07355</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Esmaeilbeig, Kumar Vijay Mishra, Mojtaba Soltanalian</li>
<li>for: 这个研究是为了开发一个适用于自动驾驶汽车（CAV）雷达系统的空间时间自适应处理（STAP）框架。</li>
<li>methods: 这个研究使用了时分多普逻（TDM）来实现发送器调度，以提高目标探测性能。</li>
<li>results: numerical experiments confirm that the optimized TDM is successful in enhancing the target detection performance.<details>
<summary>Abstract</summary>
In this study, we develop a holistic framework for space-time adaptive processing (STAP) in connected and automated vehicle (CAV) radar systems. We investigate a CAV system consisting of multiple vehicles that transmit frequency-modulated continuous-waveforms (FMCW), thereby functioning as a multistatic radar. Direct application of STAP in a network of radar systems such as in a CAV may lead to excess interference. We exploit time division multiplexing (TDM) to perform transmitter scheduling over FMCW pulses to achieve high detection performance. The TDM design problem is formulated as a quadratic assignment problem which is tackled by power method-like iterations and applying the Hungarian algorithm for linear assignment in each iteration. Numerical experiments confirm that the optimized TDM is successful in enhancing the target detection performance.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们开发了一个整体框架 для空间时间适应处理（STAP）在连接自动汽车（CAV）雷达系统中。我们研究了一个包含多个车辆发射频分Modulated continuous-waveform（FMCW）的CAV系统，这些车辆functioning as a multistatic radar。直接在CAV系统中应用STAP可能会导致过度干扰。我们利用时分多路多播（TDM）来实现发射器调度，以实现高的检测性能。TDM设计问题被формализова为一个 quadratic assignment problem，这个问题被解决通过power method-like iterations和应用hungarian algorithm来实现线性分配。数值实验证明优化的TDM能够提高目标检测性能。
</details></li>
</ul>
<hr>
<h2 id="On-the-Terminal-Location-Uncertainty-in-Elliptical-Footprints-Application-in-Air-to-Ground-Links"><a href="#On-the-Terminal-Location-Uncertainty-in-Elliptical-Footprints-Application-in-Air-to-Ground-Links" class="headerlink" title="On the Terminal Location Uncertainty in Elliptical Footprints: Application in Air-to-Ground Links"></a>On the Terminal Location Uncertainty in Elliptical Footprints: Application in Air-to-Ground Links</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07299">http://arxiv.org/abs/2309.07299</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Vavoulas, Nicholas Vaiopoulos, Harilaos G. Sandalidis, Konstantinos K. Delibasis</li>
<li>for: 研究用户RandomLocation在半径形覆盖区域中的无线通信链接性能。</li>
<li>methods: 使用方差天线和高速铁路网络等实际场景，研究用户RandomLocation对无线通信链接性能的影响。</li>
<li>results: 研究发现，用户RandomLocation会对无线通信链接性能产生很大的影响，并提供了 relevante distance metrics和频繁TerminalLocation对连接性能的影响的分析。<details>
<summary>Abstract</summary>
Wireless transmitters (Txs) radiating directionally downwards often generate circular footprints on the ground. In certain scenarios, using elliptical cells can offer increased flexibility for providing user coverage, owing to the unique network characteristics. For instance, an elliptical footprint can be produced when a practical directional antenna with unequal azimuth and elevation half-power beamwidths is used in high-speed railway networks. Another common scenario involves the production of an elliptical footprint when an airborne Tx radiates at an angle by tilting its directional antenna by a few degrees. This paper aims to investigate, for the first time, the association between the random user location within an elliptical coverage area and the performance of a wireless communication link by considering these scenarios. We assume an unmanned aerial vehicle (UAV) as a Tx, although a tall cellular base station tower could also be employed without losing generality. To better understand the impact of random location, we derive relevant distance metrics and investigate the outage probability of the link for the two scenarios, taking both random terminal location and fading impairments into account. The findings may provide valuable insights into the performance of similar wireless systems.
</details>
<details>
<summary>摘要</summary>
无线发送器（Tx）通常在下方方向性发射，可能生成圆形覆盖区 на 地面。在某些情况下，使用椭圆细胞可以提供更多的用户覆盖，由于无线网络特有的特点。例如，在高速铁路网络中使用实用方向性扬声器时，可以生成椭圆覆盖区。另一种常见的enario是通过倾斜irectional扬声器几度来生成椭圆覆盖区。这篇论文旨在，对于首次研究用户随机位置在椭圆覆盖区内的无线通信链的相关性，investigate 具体情况。我们假设用无人机（UAV）作为发送器，可以使用高Cellular 基站塔也可以无损generality。为了更好地理解随机位置的影响，我们 derive 相关的距离指标，并对两种情况的频繁受到干扰的情况进行研究。我们的发现可能为类似无线系统的性能提供有价值的洞察。
</details></li>
</ul>
<hr>
<h2 id="Beamforming-Design-and-Performance-Evaluation-for-RIS-aided-Localization-using-LEO-Satellite-Signals"><a href="#Beamforming-Design-and-Performance-Evaluation-for-RIS-aided-Localization-using-LEO-Satellite-Signals" class="headerlink" title="Beamforming Design and Performance Evaluation for RIS-aided Localization using LEO Satellite Signals"></a>Beamforming Design and Performance Evaluation for RIS-aided Localization using LEO Satellite Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07296">http://arxiv.org/abs/2309.07296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Wang, Pinjun Zheng, Xing Liu, Tarig Ballal, Tareq Y. Al-Naffouri</li>
<li>for: 本研究探讨了使用低地球轨道卫星信号和可变智能表面（RIS）实现的位置呈现方法。</li>
<li>methods: 本文使用了克拉默-瑞恩约束来 derivation of the Cramér-Rao bound of the considered localization problem,并提出了一种最优的RIS扫描设计，以最小化 derive bound。</li>
<li>results: numerical results demonstrate that the proposed beamforming scheme outperforms benchmark alternatives, and shows that the combination of LEO satellites and RISs has the potential to achieve localization accuracy at the meter or even sub-meter level.<details>
<summary>Abstract</summary>
The growing availability of low-Earth orbit (LEO) satellites, coupled with the anticipated widespread deployment of reconfigurable intelligent surfaces (RISs), opens up promising prospects for new localization paradigms. This paper studies RIS-aided localization using LEO satellite signals. The Cram\'er-Rao bound of the considered localization problem is derived, based on which an optimal RIS beamforming design that minimizes the derived bound is proposed. Numerical results demonstrate the superiority of the proposed beamforming scheme over benchmark alternatives, while also revealing that the synergy between LEO satellites and RISs holds the promise of achieving localization accuracy at the meter or even sub-meter level.
</details>
<details>
<summary>摘要</summary>
随着低地球轨道卫星（LEO）的可用性增加，以及预计的广泛部署智能表面（RIS），开启了新的地点化方案的可能性。本文研究了RIS帮助地点化使用LEO卫星信号。基于考虑的地点化问题的卡尔-拉奥 bounds，提出了最优的RIS扫描设计，以iminimize der bound。 numerically results表明提案的扫描方案比参照方案更优，而且还表明了LEO卫星和RIS的共同作用可以达到米级或以下的地点化精度。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-KalmanNet-Data-Driven-Kalman-Filter-with-Fast-Adaptation"><a href="#Adaptive-KalmanNet-Data-Driven-Kalman-Filter-with-Fast-Adaptation" class="headerlink" title="Adaptive KalmanNet: Data-Driven Kalman Filter with Fast Adaptation"></a>Adaptive KalmanNet: Data-Driven Kalman Filter with Fast Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07016">http://arxiv.org/abs/2309.07016</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kalmannet/adaptive-knet-icassp24">https://github.com/kalmannet/adaptive-knet-icassp24</a></li>
<li>paper_authors: Xiaoyong Ni, Guy Revach, Nir Shlezinger</li>
<li>for: 提高Partially known state space (SS)模型下的跟踪性能</li>
<li>methods: 结合Classical Kalman filter (KF)和深度神经网络 (DNN)</li>
<li>results: 能够适应SS模型变化而无需重新训练<details>
<summary>Abstract</summary>
Combining the classical Kalman filter (KF) with a deep neural network (DNN) enables tracking in partially known state space (SS) models. A major limitation of current DNN-aided designs stems from the need to train them to filter data originating from a specific distribution and underlying SS model. Consequently, changes in the model parameters may require lengthy retraining. While the KF adapts through parameter tuning, the black-box nature of DNNs makes identifying tunable components difficult. Hence, we propose Adaptive KalmanNet (AKNet), a DNN-aided KF that can adapt to changes in the SS model without retraining. Inspired by recent advances in large language model fine-tuning paradigms, AKNet uses a compact hypernetwork to generate context-dependent modulation weights. Numerical evaluation shows that AKNet provides consistent state estimation performance across a continuous range of noise distributions, even when trained using data from limited noise settings.
</details>
<details>
<summary>摘要</summary>
通过结合古典卡尔曼畸（KF）和深度神经网络（DNN），可以实现部分知道状态空间（SS）模型中的跟踪。现有的DNN帮助设计受到特定分布和下辖SS模型的训练所限制，因此，对模型参数的变化可能需要重新训练。而KF可以通过参数调整适应，但是DNN的黑obox性使得找到可调Component困难。因此，我们提出了适应型卡尔曼网（AKNet），一种可以在不需要重新训练的情况下适应SS模型变化。受到 latest Advances in large language model fine-tuning paradigms 的启发，AKNet使用了一个紧凑的 hypernetwork 生成状态dependent的权重模ulation。numerical evaluation表明，AKNet在不同噪音分布下提供了一致的状态估计性能，即使用limited noise Settingstrained。
</details></li>
</ul>
<hr>
<h2 id="6G-Radio-Testbeds-Requirements-Trends-and-Approaches"><a href="#6G-Radio-Testbeds-Requirements-Trends-and-Approaches" class="headerlink" title="6G Radio Testbeds: Requirements, Trends, and Approaches"></a>6G Radio Testbeds: Requirements, Trends, and Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06911">http://arxiv.org/abs/2309.06911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gilles Callebaut, Liang Liu, Thomas Eriksson, Liesbet Van der Perre, Ove Edfors, Christian Fager</li>
<li>for: 本研究的目的是为6G无线网络的发展提供基础设施。</li>
<li>methods: 本文提出了6G无线网络的研究方向和技术方法，包括新的应用和网络能效提高。</li>
<li>results: 本文描述了6G无线网络的测试基础设施的需求和趋势，以及其发展的方法。<details>
<summary>Abstract</summary>
The proof of the pudding is in the eating - that is why 6G testbeds are essential in the progress towards the next generation of wireless networks. Theoretical research towards 6G wireless networks is proposing advanced technologies to serve new applications and drastically improve the energy performance of the network. Testbeds are indispensable to validate these new technologies under more realistic conditions. This paper clarifies the requirements for 6G radio testbeds, reveals trends, and introduces approaches towards their development.
</details>
<details>
<summary>摘要</summary>
“Proof of the pudding is in the eating”，这句话告诉我们，在下一代无线网络的发展过程中，6G测试床是非常重要的。理论研究表明，6G无线网络将拥有新的应用和巨大提高网络能效性。但是，为了 validate these new technologies，我们需要在更真实的环境中进行测试。本文阐述了6G无线电测试床的需求，探讨了趋势，并介绍了其开发方法。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-Reflective-Surface-Assist-Integrated-Sensing-and-Wireless-Power-Transfer"><a href="#Intelligent-Reflective-Surface-Assist-Integrated-Sensing-and-Wireless-Power-Transfer" class="headerlink" title="Intelligent Reflective Surface Assist Integrated Sensing and Wireless Power Transfer"></a>Intelligent Reflective Surface Assist Integrated Sensing and Wireless Power Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06909">http://arxiv.org/abs/2309.06909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheng Li, Zhengyu Zhu, Zheng Chu, Yingying Guan, De Mi, Fan Liu, Lie-Liang Yang</li>
<li>for: 本研究旨在探讨一种智能反射 superficie（IRS）协助的 интеGRATED 感知和无线电力传输（ISWPT）系统，其中发送器在交通基础设施网络上发送信号感知多个目标并同时传输多个能量收集设备（EHDs）。</li>
<li>methods: 本研究提出了一种joint 优化系统性能的方法，通过减少能量收集和感知之间的性能质量负担，并通过对射频相位调整和射频平面调整进行优化。</li>
<li>results: 研究结果验证了提出的算法，并 demonstarted IRS 可以帮助提高 ISWPT 系统的性能。<details>
<summary>Abstract</summary>
Wireless sensing and wireless energy are enablers to pave the way for smart transportation and a greener future. In this paper, an intelligent reflecting surface (IRS) assisted integrated sensing and wireless power transfer (ISWPT) system is investigated, where the transmitter in transportation infrastructure networks sends signals to sense multiple targets and simultaneously to multiple energy harvesting devices (EHDs) to power them. In light of the performance tradeoff between energy harvesting and sensing, we propose to jointly optimize the system performance via optimizing the beamforming and IRS phase shift. However, the coupling of optimization variables makes the formulated problem non-convex. Thus, an alternative optimization approach is introduced and based on which two algorithms are proposed to solve the problem. Specifically, the first one involves a semi-definite program technique, while the second one features a low-complexity optimization algorithm based on successive convex approximation and majorization minimization. Our simulation results validate the proposed algorithms and demonstrate the advantages of using IRS to assist wireless power transfer in ISWPT systems.
</details>
<details>
<summary>摘要</summary>
无线感知和无线能源是智能交通和绿色未来的推动者。本文研究了一种帮助器（IRS）协助的 интеGRATED 无线传输和感知系统，其中传输器在交通基础设施网络上发射信号感知多个目标并同时传输多个能量收集设备（EHD）以供电。为了解决能收集和感知性能之间的性能质量负担，我们提议同时优化系统性能via 磁场调制和IRS阶段偏移。但是，优化变量的协同关系使得问题变得非对称。因此，我们引入了一种代替优化方法，并基于这种方法提出了两种算法来解决问题。 Specifically, the first one involves a semi-definite program technique, while the second one features a low-complexity optimization algorithm based on successive convex approximation and majorization minimization. Our simulation results validate the proposed algorithms and demonstrate the advantages of using IRS to assist wireless power transfer in ISWPT systems.Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="TTD-Configurations-for-Near-Field-Beamforming-Parallel-Serial-or-Hybrid"><a href="#TTD-Configurations-for-Near-Field-Beamforming-Parallel-Serial-or-Hybrid" class="headerlink" title="TTD Configurations for Near-Field Beamforming: Parallel, Serial, or Hybrid?"></a>TTD Configurations for Near-Field Beamforming: Parallel, Serial, or Hybrid?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06861">http://arxiv.org/abs/2309.06861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaolin Wang, Xidong Mu, Yuanwei Liu, Robert Schober</li>
<li>For: The paper is written for hybrid beamforming architectures in wideband near-field communications, specifically addressing the spatial-wideband effect and the maximum time delay requirements of true-time delayers (TTDs).* Methods: The paper investigates two TTD configurations: serial and hybrid serial-parallel, and proposes a power equalization approach to address the cumulative insertion loss. It also studies the wideband near-field beamforming design for different configurations to maximize spectral efficiency in both single-user and multi-user systems.* Results: The paper derives a closed-form solution for the beamforming design in single-user systems and develops a penalty-based iterative algorithm for multi-user systems. Numerical results show that the proposed designs can significantly reduce the maximum time delays required for TTDs and that the hybrid configuration excels in single-user systems, while the serial configuration is preferred in multi-user systems.Here is the result in Simplified Chinese text:* For: 这篇论文是为宽频近场通信中的混合扫描 Architecture 而写的，具体来说是解决宽频近场通信中的空间宽频效应和真实时延器（TTD）的最大时延问题。* Methods: 论文 investigate了两种 TTD 配置：串行和混合串行平行，并提出了一种能量均衡approach来 Addressing the cumulative insertion loss. 它还研究了不同配置下的宽频近场扫描设计，以最大化单个用户和多个用户系统中的spectral efficiency。* Results: 论文 derive了一个关于单用户系统的closed-form解决方案，并开发了一种 penalty-based iterative algorithm来 Addressing the multi-user system. 数字结果表明，提posed设计可以减少 TTD 的最大时延 requirement,并且混合配置在单用户系统中表现出色，而串行配置在多用户系统中表现更好。<details>
<summary>Abstract</summary>
True-time delayers (TTDs) are popular components for hybrid beamforming architectures to combat the spatial-wideband effect in wideband near-field communications. A serial and a hybrid serial-parallel TTD configuration are investigated for hybrid beamforming architectures. Compared to the conventional parallel configuration, the serial configuration exhibits a cumulative time delay through multiple TTDs, which potentially alleviates the maximum delay requirements on the TTDs. However, independent control of individual TTDs becomes impossible in the serial configuration. In this context, a hybrid TTD configuration is proposed as a compromise solution. Furthermore, a power equalization approach is proposed to address the cumulative insertion loss of the serial and hybrid TTD configurations. Moreover, the wideband near-field beamforming design for different configurations is studied for maximizing the spectral efficiency in both single-user and multiple-user systems. 1) For single-user systems, a closed-form solution for the beamforming design is derived. The preferred user locations and the required maximum time delay of each TTD configuration are characterized. 2) For multi-user systems, a penalty-based iterative algorithm is developed to obtain a stationary point of the spectral efficiency maximization problem for each TTD configuration. In addition, a mixed-forward-and-backward (MFB) implementation is proposed to enhance the performance of the serial configuration. Our numerical results confirm the effectiveness of the proposed designs and unveil that i) compared to the conventional parallel configuration, both the serial and hybrid configurations can significantly reduce the maximum time delays required for the TTDs and ii) the hybrid configuration excels in single-user systems, while the serial configuration is preferred in multi-user systems.
</details>
<details>
<summary>摘要</summary>
true-time delayers (TTDs) 是各种混合扫描镜谱架构中的受欢迎组件，以避免频宽频段效应在宽频近场通信中。我们 investigate 了串行和混合串行平行 TTD 配置在混合扫描镜谱架构中。相比传统并行配置，串行配置会带来累加时延，从而减轻 TTD 的最大延迟要求。然而，在串行配置中独立控制个别 TTD 是不可能的。为此，我们提出了混合 TTD 配置作为妥协解决方案。此外，我们还提出了一种电力均衡方法，以解决串行和混合 TTD 配置中的累加插入损耗。此外，我们还研究了不同配置下的宽频近场扫描设计，以最大化单个用户和多个用户系统中的 spectral efficiency。1）对单用户系统，我们 derive 了一个关闭式解决方案，用于扫描设计。我们还Characterize 了最佳用户位置和每个 TTD 配置的最大时延要求。2）对多用户系统，我们提出了一种罚 penalty-based 迭代算法，以获得每个 TTD 配置的 spectral efficiency 的最大化站点。此外，我们还提出了一种混合前后 (MFB) 实现，以提高串行配置的性能。我们的数字结果表明，我们的设计方案具有有效性，并且发现：i）与传统并行配置相比， both 串行和混合配置可以减少 TTD 的最大时延要求。ii）在单用户系统中，混合配置 excel，而在多用户系统中，串行配置是更好的选择。
</details></li>
</ul>
<hr>
<h2 id="A-Wearable-Ultra-Low-Power-sEMG-Triggered-Ultrasound-System-for-Long-Term-Muscle-Activity-Monitoring"><a href="#A-Wearable-Ultra-Low-Power-sEMG-Triggered-Ultrasound-System-for-Long-Term-Muscle-Activity-Monitoring" class="headerlink" title="A Wearable Ultra-Low-Power sEMG-Triggered Ultrasound System for Long-Term Muscle Activity Monitoring"></a>A Wearable Ultra-Low-Power sEMG-Triggered Ultrasound System for Long-Term Muscle Activity Monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06851">http://arxiv.org/abs/2309.06851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Frey, Victor Kartsch, Christoph Leitner, Andrea Cossettini, Sergei Vostrikov, Simone Benatti, Luca Benini<br>for:This paper aims to develop a wearable solution that integrates surface electromyography (sEMG) and ultrasound (US) to monitor muscle activity with low power consumption.methods:The proposed approach utilizes an EMG-driven wake-up approach to achieve ultra-low power consumption, where the US probe is kept in a sleep state when there is no muscle activity. sEMG data are processed on the probe to identify muscle activity and generate a trigger to wake-up the US counterpart.results:The proposed approach enables more than 59% energy saving compared to operating both sEMG and US continuously, with a full-system average power consumption of 12.2 mW.<details>
<summary>Abstract</summary>
Surface electromyography (sEMG) is a well-established approach to monitor muscular activity on wearable and resource-constrained devices. However, when measuring deeper muscles, its low signal-to-noise ratio (SNR), high signal attenuation, and crosstalk degrade sensing performance. Ultrasound (US) complements sEMG effectively with its higher SNR at high penetration depths. In fact, combining US and sEMG improves the accuracy of muscle dynamic assessment, compared to using only one modality. However, the power envelope of US hardware is considerably higher than that of sEMG, thus inflating energy consumption and reducing the battery life. This work proposes a wearable solution that integrates both modalities and utilizes an EMG-driven wake-up approach to achieve ultra-low power consumption as needed for wearable long-term monitoring. We integrate two wearable state-of-the-art (SoA) US and ExG biosignal acquisition devices to acquire time-synchronized measurements of the short head of the biceps. To minimize power consumption, the US probe is kept in a sleep state when there is no muscle activity. sEMG data are processed on the probe (filtering, envelope extraction and thresholding) to identify muscle activity and generate a trigger to wake-up the US counterpart. The US acquisition starts before muscle fascicles displacement thanks to a triggering time faster than the electromechanical delay (30-100 ms) between the neuromuscular junction stimulation and the muscle contraction. Assuming a muscle contraction of 200 ms at a contraction rate of 1 Hz, the proposed approach enables more than 59% energy saving (with a full-system average power consumption of 12.2 mW) as compared to operating both sEMG and US continuously.
</details>
<details>
<summary>摘要</summary>
表面电MYography (sEMG) 是一种已知的方法，用于在穿戴式和资源受限的设备上监测肌肉活动。然而，当测量深部肌肉时，其信号噪声比 (SNR) 低、信号强度减弱和交叠问题会降低感测性能。ultrasound (US) 可以帮助 sEMG 提高肌动评估的准确性，但 US 硬件的能量总量远高于 sEMG 的，从而导致能源消耗过高，降低电池寿命。这项工作提议了一种携带两种模式的穿戴设备，并使用 EMG 驱动的唤醒方法来实现低功耗consumption。我们将两种现代 SoA US 和 ExG 维度诊断设备集成，以同步获取Short head of the biceps 的时间测量。为了降低能源消耗，US 探针在没有肌动活动时被保持在睡眠状态。sEMG 数据在探针上进行处理（滤波、封顶EXTRACTION 和阈值处理），以识别肌动活动并生成触发器，唤醒 US 对应部分。US 获取在肌肉脱静前开始，因为诊断神经筋接触点刺激和肌肉收缩之间的电romechanical delay (30-100 ms) 。假设每分钟一次肌肉收缩 200 ms，则提议的方法可以比continuously 操作 sEMG 和 US 的能源消耗减少超过 59% (全系统平均功耗为 12.2 mW)。
</details></li>
</ul>
<hr>
<h2 id="Low-complexity-hardware-and-algorithm-for-joint-communication-and-sensing"><a href="#Low-complexity-hardware-and-algorithm-for-joint-communication-and-sensing" class="headerlink" title="Low-complexity hardware and algorithm for joint communication and sensing"></a>Low-complexity hardware and algorithm for joint communication and sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06850">http://arxiv.org/abs/2309.06850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Bedin, Shaghayegh Shahcheraghi, Traian E. Abrudan, Arash Asadi<br>for:* 这篇论文旨在描述一种基于joint communication and sensing（JCAS）的算法，用于6G系统中提供快速、可靠的通信和精准的物理环境感知。methods:* 该算法使用了一种新的宽频分布式扫描架构，其结合了宽频分布式扫描和高频级数字扫描，以便精准地估算时射（ToA）和方向射（AoA）。results:* 对比2D多信号分类（2D-MUSIC）算法，该方法可以实现相似的性能，而且需要远少于总汇准采样率和复杂性。<details>
<summary>Abstract</summary>
Joint Communication and Sensing (JCAS) is foreseen as one very distinctive feature of the emerging 6G systems providing, in addition to fast end reliable communication, the ability to obtain an accurate perception of the physical environment. In this paper, we propose a JCAS algorithm that exploits a novel beamforming architecture, which features a combination of wideband analog and narrowband digital beamforming. This allows accurate estimation of Time of Arrival (ToA), exploiting the large bandwidth and Angle of Arrival (AoA), exploiting the high-rank digital beamforming. In our proposal, we separately estimate the ToA and AoA. The association between ToA and AoA is solved by acquiring multiple non-coherent frames and adding up the signal from each frame such that a specific component is combined coherently before the AoA estimation. Consequently, this removes the need to use 2D and 3D joint estimation methods, thus significantly lowering complexity. The resolution performance of the method is compared with that of 2D MUltiple SIgnal Classification (2D-MUSIC) algorithm, using a fully-digital wideband beamforming architecture. The results show that the proposed method can achieve performance similar to a fully-digital high-bandwidth system, while requiring a fraction of the total aggregate sampling rate and having much lower complexity.
</details>
<details>
<summary>摘要</summary>
joint communication and sensing (JCAS) 是6G系统的一个特点，它提供了快速、可靠的通信以及精准地理环境的感知。在这篇论文中，我们提出了一种JCAS算法，利用了一种新的ibeamforming架构，这种架构组合了宽频Analog和窄频数字ibeamforming。这allowaccurately estimating Time of Arrival (ToA), exploiting the large bandwidth and Angle of Arrival (AoA), exploiting the high-rank digital beamforming。在我们的提议中，我们分别估算了ToA和AoA。将ToA和AoA相关联的问题解决通过在每帧中获取多个非协调的帧，并将每帧的信号相加，以便在AoA估算中具有一个固定的组合。这样，我们可以简化复杂性，而不需要使用2D和3D的共同估算方法。我们对方法的分辨率性能进行了比较，使用了一种完全数字宽频ibeamforming架构，与2D MUltiple SIgnal Classification (2D-MUSIC)算法进行比较。结果表明，我们的方法可以达到与高频率数字系统相同的性能，而且需要的总总采样率和复杂性比较低。
</details></li>
</ul>
<hr>
<h2 id="Reliability-Latency-Rate-Tradeoff-in-Low-Latency-Communications-with-Finite-Blocklength-Coding"><a href="#Reliability-Latency-Rate-Tradeoff-in-Low-Latency-Communications-with-Finite-Blocklength-Coding" class="headerlink" title="Reliability-Latency-Rate Tradeoff in Low-Latency Communications with Finite-Blocklength Coding"></a>Reliability-Latency-Rate Tradeoff in Low-Latency Communications with Finite-Blocklength Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06769">http://arxiv.org/abs/2309.06769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lintao Li, Wei Chen, Petar Popovski, Khaled B. Letaief</li>
<li>For: 这篇论文主要研究了具有最小延迟要求的无线通信中的可靠性-延迟-率质量交易。它探讨了在有限块长编码（FBC）下的可靠性-延迟-率交易的基本质量，特别是错误概率、延迟违反概率（DVP）和服务率之间的交易。* Methods: 本论文使用了有效容量（EC）和正常近似来约束可靠性-延迟-率交易的质量。它还提出了一种EC-近似方法来评估受到质量约束的低延迟通信中的可靠性-延迟-率交易。* Results: 研究发现，在AWGN和RAYLEIGH抽象通道上，在允许的最大干扰电平下，可靠性-延迟-率交易存在一定的质量交易。此外，在 Nakagami-$m$ 抽象通道上，可靠性-延迟-率交易也存在一定的质量交易，但与AWGN和RAYLEIGH抽象通道相比，它的质量交易较差。在延迟传输中，如果延迟阈值大于通道准确时间，则可靠性-延迟-率交易存在一定的极限形式。<details>
<summary>Abstract</summary>
Low-latency communication plays an increasingly important role in delay-sensitive applications by ensuring the real-time exchange of information. However, due to the constraints on the maximum instantaneous power, bounded latency is hard to be guaranteed. In this paper, we investigate the reliability-latency-rate tradeoff in low-latency communications with finite-blocklength coding (FBC). More specifically, we are interested in the fundamental tradeoff between error probability, delay-violation probability (DVP), and service rate. Based on the effective capacity (EC) and normal approximation, we present several gain-conservation inequalities to bound the reliability-latency-rate tradeoffs. In particular, we investigate the low-latency transmissions over an additive white Gaussian noise (AWGN) channel, over a Rayleigh fading channel, with frequency or spatial diversity, and over a Nakagami-$m$ fading channel. To analytically evaluate the quality-of-service-constrained low-latency communications with FBC, an EC-approximation method is further conceived to derive the closed-form expression of quality-of-service-constrained throughput. For delay-sensitive transmissions in which the latency threshold is greater than the channel coherence time, we find an asymptotic form of the tradeoff between the error probability and DVP over the AWGN and Rayleigh fading channels. Our results may provide some insights into the efficient scheduling of low-latency wireless communications in which statistical latency and reliability metrics are adopted.
</details>
<details>
<summary>摘要</summary>
低延迟通信在延迟敏感应用中扮演着越来越重要的角色，确保了实时信息交换。然而，由于最大幂值功率的限制，保证 bounded latency 很难。在这篇论文中，我们研究了低延迟通信中的可靠性-延迟率-速率贸易。更Specifically，我们对 error probability、延迟违约概率（DVP）和服务率之间的基本贸易进行了研究。基于有效容量（EC）和正常approximation，我们提出了多种可靠性-延迟率-速率贸易的上限。具体来说，我们研究了在加itive white Gaussian noise（AWGN）频道、Rayleigh折射频道、频率或空间多普通频道以及Nakagami-$m$ 折射频道上的低延迟传输。为了分析受限于服务质量的低延迟通信，我们提出了EC-approximation方法来 derive closed-form表达式。对于延迟敏感传输，我们发现在AWGN和Rayleigh折射频道上，随着延迟阈值的增加，error probability和DVP之间存在一定的 asymptotic 关系。我们的结果可能提供一些关于有效地调度低延迟无线通信的经验。
</details></li>
</ul>
<hr>
<h2 id="Globally-Optimal-Beamforming-Design-for-Integrated-Sensing-and-Communication-Systems"><a href="#Globally-Optimal-Beamforming-Design-for-Integrated-Sensing-and-Communication-Systems" class="headerlink" title="Globally Optimal Beamforming Design for Integrated Sensing and Communication Systems"></a>Globally Optimal Beamforming Design for Integrated Sensing and Communication Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06674">http://arxiv.org/abs/2309.06674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiguo Wang, Jiageng Wu, Ya-Feng Liu, Fan Liu</li>
<li>for: 这paper是为了提出一种多输入多输出（MIMO）扫描和多用户通信的共同优化模型，以优化扫描和通信的性能。</li>
<li>methods: 该paper使用了 McCormick 环境 relaksation 和 semi-definite relaxation（SDR）技术来解决形ulated problem，并提出了一种高效的全局分支和约束 bounds 算法来解决这个问题。</li>
<li>results: 该paper提出的算法可以 garantía finding the global solution for the considered problem, 并且可以作为现有的本地或半优化算法的性能评估标准。<details>
<summary>Abstract</summary>
In this paper, we propose a multi-input multi-output (MIMO) beamforming transmit optimization model for joint radar sensing and multi-user communications, where the design of the beamformers is formulated as an optimization problem whose objective is a weighted combination of the sum rate and the Cram\'{e}r-Rao bound (CRB), subject to the transmit power budget constraint. The formulated problem is challenging to obtain a global solution, because the sum rate maximization (SRM) problem itself (even without considering the sensing metric) is known to be NP-hard. In this paper, we propose an efficient global branch-and-bound algorithm for solving the formulated problem based on the McCormick envelope relaxation and the semidefinite relaxation (SDR) technique. The proposed algorithm is guaranteed to find the global solution for the considered problem, and thus serves as an important benchmark for performance evaluation of the existing local or suboptimal algorithms for solving the same problem.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种多输入多输出（MIMO）发射优化模型，用于同时进行雷达探测和多用户通信。在这个模型中，发射器的设计被设置为优化问题的目标，其目标是一种加权的总质量和克拉默-拉奥 bound（CRB）的函数，同时满足发射功率预算限制。这个问题是NP-困难的，因此寻找全局解决方案是非常困难的。在这篇论文中，我们提出了一种高效的全局分支和约束算法，基于McCormick环境缓和SDR技术来解决这个问题。这种算法能够确保找到全局解决方案，因此可以作为现有的本地或部分优化算法的性能评估标准。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/13/eess.SP_2023_09_13/" data-id="clohum9h0017vpj88gzzha4ja" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/12/cs.SD_2023_09_12/" class="article-date">
  <time datetime="2023-09-12T15:00:00.000Z" itemprop="datePublished">2023-09-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/12/cs.SD_2023_09_12/">cs.SD - 2023-09-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ASPED-An-Audio-Dataset-for-Detecting-Pedestrians"><a href="#ASPED-An-Audio-Dataset-for-Detecting-Pedestrians" class="headerlink" title="ASPED: An Audio Dataset for Detecting Pedestrians"></a>ASPED: An Audio Dataset for Detecting Pedestrians</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06531">http://arxiv.org/abs/2309.06531</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pavan Seshadri, Chaeyeon Han, Bon-Woo Koo, Noah Posner, Subhrajit Guhathakurta, Alexander Lerch</li>
<li>for: 这个研究旨在提出一种新的声音分析任务，即人员检测任务，并提供一个大规模的数据集来支持这项任务。</li>
<li>methods: 该研究使用了标准的声音分析方法，以及一些特定的音频处理技术来提高检测精度。</li>
<li>results: 初步的结果表明，使用声音方法可以实现人员检测任务，但是这项任务并不容易解决，需要进一步的研究和优化。Here’s the simplified Chinese text format you requested:</li>
<li>for: 这个研究旨在提出一种新的声音分析任务，即人员检测任务，并提供一个大规模的数据集来支持这项任务。</li>
<li>methods: 该研究使用了标准的声音分析方法，以及一些特定的音频处理技术来提高检测精度。</li>
<li>results: 初步的结果表明，使用声音方法可以实现人员检测任务，但是这项任务并不容易解决，需要进一步的研究和优化。<details>
<summary>Abstract</summary>
We introduce the new audio analysis task of pedestrian detection and present a new large-scale dataset for this task. While the preliminary results prove the viability of using audio approaches for pedestrian detection, they also show that this challenging task cannot be easily solved with standard approaches.
</details>
<details>
<summary>摘要</summary>
我们介绍了一新的声音分析任务：人员检测，并提供了一个大规模的数据集来支持这个任务。虽然初步的结果表明使用声音方法可以实现人员检测，但是这个复杂的任务并不可以轻松解决使用标准方法。Here's the breakdown of the translation:* 我们 (wǒmen) - we* 介绍 (jièshì) - introduce* 一新 (yī xīn) - a new* 声音 (shēngwèn) - audio* 分析 (fēnxiǎng) - analysis* 任务 (róngwù) - task* 人员 (rényù) - pedestrian* 检测 (jiǎnnéng) - detection* 并 (bìng) - and* 提供 (tiěfuò) - provide* 一个 (yī ge) - one* 大规模 (dàxíngmǔ) - large-scale* 数据集 (xùnxī) - dataset* 来支持 (lái zhīchēng) - to support* 这个 (zhè ge) - this* 任务 (róngwù) - task* 复杂 (fùzé) - complex* 并 (bìng) - and* 不可以 (bùkěyǐ) - cannot be* 轻松解决 (qīngsōng jiějué) - easily solved* 使用 (fùwù) - using* 标准 (biāozhǔn) - standard* 方法 (fāngchéng) - method
</details></li>
</ul>
<hr>
<h2 id="SynVox2-Towards-a-privacy-friendly-VoxCeleb2-dataset"><a href="#SynVox2-Towards-a-privacy-friendly-VoxCeleb2-dataset" class="headerlink" title="SynVox2: Towards a privacy-friendly VoxCeleb2 dataset"></a>SynVox2: Towards a privacy-friendly VoxCeleb2 dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06141">http://arxiv.org/abs/2309.06141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoxiao Miao, Xin Wang, Erica Cooper, Junichi Yamagishi, Nicholas Evans, Massimiliano Todisco, Jean-François Bonastre, Mickael Rouvier</li>
<li>for: 这个研究旨在提供一个适合采用的、隐私保证的 VoxCeleb2 处理集，以减少对于真实人声训练的道德、隐私和法律问题。</li>
<li>methods: 这个研究使用了一种叫做“隐私友好”的方法，将真实人声训练集转换为synthetic dataset，以保证该集的隐私和公平性。</li>
<li>results: 研究发现，这个synthetic dataset可以保持与原始 VoxCeleb2 集的相似性，并且可以用于下游的 speaker verification 任务中，但是也存在一些挑战，需要进一步的研究和改进。<details>
<summary>Abstract</summary>
The success of deep learning in speaker recognition relies heavily on the use of large datasets. However, the data-hungry nature of deep learning methods has already being questioned on account the ethical, privacy, and legal concerns that arise when using large-scale datasets of natural speech collected from real human speakers. For example, the widely-used VoxCeleb2 dataset for speaker recognition is no longer accessible from the official website. To mitigate these concerns, this work presents an initiative to generate a privacy-friendly synthetic VoxCeleb2 dataset that ensures the quality of the generated speech in terms of privacy, utility, and fairness. We also discuss the challenges of using synthetic data for the downstream task of speaker verification.
</details>
<details>
<summary>摘要</summary>
成功的深度学习在人脸识别中受到大量数据的支持。然而，深度学习方法的数据吃杂性已经被质疑，因为使用大规模自然语音收集到的真正人类说话者的数据会产生伦理、隐私和法律问题。例如，广泛使用的VoxCeleb2数据集已经从官方网站上下载不可达。为解决这些问题，本研究提出了一项隐私友好的synthetic VoxCeleb2数据生成Initative，确保生成的speech质量符合隐私、有用性和公平原则。我们还讨论了使用生成数据进行下游任务的说话识别的挑战。
</details></li>
</ul>
<hr>
<h2 id="Can-large-scale-vocoded-spoofed-data-improve-speech-spoofing-countermeasure-with-a-self-supervised-front-end"><a href="#Can-large-scale-vocoded-spoofed-data-improve-speech-spoofing-countermeasure-with-a-self-supervised-front-end" class="headerlink" title="Can large-scale vocoded spoofed data improve speech spoofing countermeasure with a self-supervised front end?"></a>Can large-scale vocoded spoofed data improve speech spoofing countermeasure with a self-supervised front end?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06014">http://arxiv.org/abs/2309.06014</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts">https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts</a></li>
<li>paper_authors: Xin Wang, Junichi Yamagishi</li>
<li>for: 本研究旨在提高一种基于自我超级vised learning（SSL）模型的发音模仿抗干扰（CM）技术，以提高CM的鲁棒性和可靠性。</li>
<li>methods: 本研究使用多个神经网络 vocoder生成大量的 vocoded 数据，并使用这些数据进行自我超级vised learning（SSL）模型的连续训练，以提高CM的性能。</li>
<li>results: 实验表明，使用 vocoded 数据进行SSL模型的连续训练可以提高CM的总性能，并且使用新的SSL模型（即两个SSL模型的distilled）可以进一步提高CM的性能，特别是在面临未经见过的测试集上。<details>
<summary>Abstract</summary>
A speech spoofing countermeasure (CM) that discriminates between unseen spoofed and bona fide data requires diverse training data. While many datasets use spoofed data generated by speech synthesis systems, it was recently found that data vocoded by neural vocoders were also effective as the spoofed training data. Since many neural vocoders are fast in building and generation, this study used multiple neural vocoders and created more than 9,000 hours of vocoded data on the basis of the VoxCeleb2 corpus. This study investigates how this large-scale vocoded data can improve spoofing countermeasures that use data-hungry self-supervised learning (SSL) models. Experiments demonstrated that the overall CM performance on multiple test sets improved when using features extracted by an SSL model continually trained on the vocoded data. Further improvement was observed when using a new SSL distilled from the two SSLs before and after the continual training. The CM with the distilled SSL outperformed the previous best model on challenging unseen test sets, including the ASVspoof 2019 logical access, WaveFake, and In-the-Wild.
</details>
<details>
<summary>摘要</summary>
一种演讲 spoofing 防范措施（CM）需要多样化的训练数据。许多数据集使用由speech synthesis系统生成的假数据，但最近发现，由神经 vocoder生成的数据也是有效的假数据。由于神经 vocoder快速生成和生成，这项研究使用多个神经 vocoder，生成了基于 VoxCeleb2 库的 más than 9,000 小时的 vocoded 数据。这项研究研究如何使用这些大规模的 vocoded 数据提高 spoofing 防范措施，使用需要大量自我supervised learning（SSL）模型。实验表明，使用由 SSL 模型不断地训练于 vocoded 数据中提取的特征，可以提高 CM 的总体性能。此外，使用一个新的 SSL 模型，其中两个 SSL 模型在 перед和后 continual training 中分别被训练，可以进一步提高 CM 的性能。该 CM 在不同的难度测试集上，包括 ASVspoof 2019 逻辑访问、WaveFake 和 In-the-Wild，都表现出优于前一代最佳模型。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/12/cs.SD_2023_09_12/" data-id="clohum9by00uspj88f57o7k9g" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_09_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/12/eess.AS_2023_09_12/" class="article-date">
  <time datetime="2023-09-12T14:00:00.000Z" itemprop="datePublished">2023-09-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/12/eess.AS_2023_09_12/">eess.AS - 2023-09-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="iPhonMatchNet-Zero-Shot-User-Defined-Keyword-Spotting-Using-Implicit-Acoustic-Echo-Cancellation"><a href="#iPhonMatchNet-Zero-Shot-User-Defined-Keyword-Spotting-Using-Implicit-Acoustic-Echo-Cancellation" class="headerlink" title="iPhonMatchNet: Zero-Shot User-Defined Keyword Spotting Using Implicit Acoustic Echo Cancellation"></a>iPhonMatchNet: Zero-Shot User-Defined Keyword Spotting Using Implicit Acoustic Echo Cancellation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06096">http://arxiv.org/abs/2309.06096</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong-Hyeok Lee, Namhyun Cho</li>
<li>for: Addresses the challenge of barge-in scenarios in human-machine communication.</li>
<li>methods: Leverages implicit acoustic echo cancellation (iAEC) techniques to improve user-defined keyword spotting models.</li>
<li>results: Achieves a 95% reduction in mean absolute error with a minimal increase in model size compared to the baseline model, PhonMatchNet.Here’s the text in Simplified Chinese:</li>
<li>for: 用于解决人机交互中的冲突场景。</li>
<li>methods: 利用隐式音频反射抑制（iAEC）技术提高用户定义关键词检测模型的效率。</li>
<li>results: 与基线模型PhonMatchNet相比，实现了95%的精度差异减少，模型大小增加0.13%。<details>
<summary>Abstract</summary>
In response to the increasing interest in human--machine communication across various domains, this paper introduces a novel approach called iPhonMatchNet, which addresses the challenge of barge-in scenarios, wherein user speech overlaps with device playback audio, thereby creating a self-referencing problem. The proposed model leverages implicit acoustic echo cancellation (iAEC) techniques to increase the efficiency of user-defined keyword spotting models, achieving a remarkable 95% reduction in mean absolute error with a minimal increase in model size (0.13%) compared to the baseline model, PhonMatchNet. We also present an efficient model structure and demonstrate its capability to learn iAEC functionality without requiring a clean signal. The findings of our study indicate that the proposed model achieves competitive performance in real-world deployment conditions of smart devices.
</details>
<details>
<summary>摘要</summary>
为了应对不同领域的人机交互需求，这篇论文提出了一种新的方法called iPhonMatchNet，用于解决撞壳场景，在用户语音与设备播放声音之间存在自referencing问题。提出的模型利用隐式音频降噪技术（iAEC）提高用户定义关键词检测模型的效率，实现了95%的平均绝对错误减少，同时模型体积增加0.13%，与基线模型PhonMatchNet相比。我们还提出了一种高效的模型结构，并证明它可以不需要干净信号来学习iAEC功能。我们的研究发现，该模型在智能设备实际应用中的实际应用中达到了竞争水平。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/12/eess.AS_2023_09_12/" data-id="clohum9dv00znpj882u770nh6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/12/cs.CV_2023_09_12/" class="article-date">
  <time datetime="2023-09-12T13:00:00.000Z" itemprop="datePublished">2023-09-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/12/cs.CV_2023_09_12/">cs.CV - 2023-09-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Accelerating-Deep-Neural-Networks-via-Semi-Structured-Activation-Sparsity"><a href="#Accelerating-Deep-Neural-Networks-via-Semi-Structured-Activation-Sparsity" class="headerlink" title="Accelerating Deep Neural Networks via Semi-Structured Activation Sparsity"></a>Accelerating Deep Neural Networks via Semi-Structured Activation Sparsity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06626">http://arxiv.org/abs/2309.06626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Grimaldi, Darshan C. Ganji, Ivan Lazarevich, Sudhakar Sah</li>
<li>for: 这篇论文的目的是提高深度神经网络（DNNs）在嵌入式设备上的处理效率，以便实现它们的部署。</li>
<li>methods: 这篇论文提出了一个解决方案，利用网络的特征对应矩阵中的零值来实现半结构化的活化簇，以获得更高的速度增幅。</li>
<li>results: 根据实验结果，这篇论文获得了$1.25 \times$的速度增幅，并且仅受到$1.1%$的精度下降，对于ResNet18模型在ImageNet dataset上进行显像识别任务。此外，当与现有的结构化剔除技术结合使用时，所得到的模型具有良好的时间-精度贡献对话。<details>
<summary>Abstract</summary>
The demand for efficient processing of deep neural networks (DNNs) on embedded devices is a significant challenge limiting their deployment. Exploiting sparsity in the network's feature maps is one of the ways to reduce its inference latency. It is known that unstructured sparsity results in lower accuracy degradation with respect to structured sparsity but the former needs extensive inference engine changes to get latency benefits. To tackle this challenge, we propose a solution to induce semi-structured activation sparsity exploitable through minor runtime modifications. To attain high speedup levels at inference time, we design a sparse training procedure with awareness of the final position of the activations while computing the General Matrix Multiplication (GEMM). We extensively evaluate the proposed solution across various models for image classification and object detection tasks. Remarkably, our approach yields a speed improvement of $1.25 \times$ with a minimal accuracy drop of $1.1\%$ for the ResNet18 model on the ImageNet dataset. Furthermore, when combined with a state-of-the-art structured pruning method, the resulting models provide a good latency-accuracy trade-off, outperforming models that solely employ structured pruning techniques.
</details>
<details>
<summary>摘要</summary>
需求深度神经网络（DNNs）在嵌入式设备上高效处理是一大挑战，限制其部署。利用网络特征图中的稀疏性可以减少归并时间。然而，不结构化稀疏性会导致减少准确性，而结构化稀疏性则需要大量的执行引擎修改来获得时间优化。为解决这个挑战，我们提出了一种使用部分结构化活化稀疏性的解决方案。通过小改动 runtime，我们设计了一种稀疏训练方法，其中考虑了最终 activation 的位置，以实现高速度启发。我们对多种图像分类和物体检测任务进行了广泛的评估，并观察到了以下结果：我们的方法可以在 ResNet18 模型上 ImageNet  dataset 上提供 $1.25 \times$ 的速度提升，同时减少 $1.1\%$ 的准确性下降。此外，当与现有的结构化剪枝方法相结合时，得到的模型可以提供优秀的时间-准确性质量平衡，超越具有结构化剪枝技术的模型。
</details></li>
</ul>
<hr>
<h2 id="Multi-dimensional-Fusion-and-Consistency-for-Semi-supervised-Medical-Image-Segmentation"><a href="#Multi-dimensional-Fusion-and-Consistency-for-Semi-supervised-Medical-Image-Segmentation" class="headerlink" title="Multi-dimensional Fusion and Consistency for Semi-supervised Medical Image Segmentation"></a>Multi-dimensional Fusion and Consistency for Semi-supervised Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06618">http://arxiv.org/abs/2309.06618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixing Lu, Zhaoxin Fan, Min Xu</li>
<li>for: 这则论文是用于医疗影像分类的 semi-supervised learning 框架。</li>
<li>methods: 中心的 Multi-scale Text-aware ViT-CNN Fusion scheme 组合了 VIT 和 CNN 两种架构的优点，并借由两种架构的优点和视觉语言模式之间的补充信息，实现更好的预测性。此外，我们还提出了多轴共调整框架，以生成更加稳定的 Pseudo 标签，进一步增强 semi-supervised 学习过程。</li>
<li>results: 我们在多个常用的数据集上进行了广泛的实验，结果显示了我们的方法的优律性。<details>
<summary>Abstract</summary>
In this paper, we introduce a novel semi-supervised learning framework tailored for medical image segmentation. Central to our approach is the innovative Multi-scale Text-aware ViT-CNN Fusion scheme. This scheme adeptly combines the strengths of both ViTs and CNNs, capitalizing on the unique advantages of both architectures as well as the complementary information in vision-language modalities. Further enriching our framework, we propose the Multi-Axis Consistency framework for generating robust pseudo labels, thereby enhancing the semi-supervised learning process. Our extensive experiments on several widely-used datasets unequivocally demonstrate the efficacy of our approach.
</details>
<details>
<summary>摘要</summary>
在本文中，我们介绍了一种新的半监督学习框架，特化于医疗图像分割。我们的方法的核心是创新的多级文本意识混合方案。这种方案能够有效地结合维特和CNN的优势，同时利用视力语言模式中的补充信息。此外，我们还提出了多轴一致框架，以生成可靠的假标签，从而提高半监督学习过程的稳定性。我们对多个广泛使用的数据集进行了广泛的实验，结果表明我们的方法有效性。
</details></li>
</ul>
<hr>
<h2 id="Harmonic-NAS-Hardware-Aware-Multimodal-Neural-Architecture-Search-on-Resource-constrained-Devices"><a href="#Harmonic-NAS-Hardware-Aware-Multimodal-Neural-Architecture-Search-on-Resource-constrained-Devices" class="headerlink" title="Harmonic-NAS: Hardware-Aware Multimodal Neural Architecture Search on Resource-constrained Devices"></a>Harmonic-NAS: Hardware-Aware Multimodal Neural Architecture Search on Resource-constrained Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06612">http://arxiv.org/abs/2309.06612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Imed Eddine Ghebriout, Halima Bouzidi, Smail Niar, Hamza Ouarnoughi</li>
<li>for: 本文主要针对融合多Modal Neural Networks（MM-NN）的设计和优化，以提高多Modal信息表示力和设备硬件限制下的推理效率和能效性。</li>
<li>methods: 本文提出了一种名为Harmonic-NAS的框架，用于同时优化多Modal backbone架构和融合策略，并考虑设备硬件约束。</li>
<li>results: 实验结果表明，与州态艺术 compare to现有方法，Harmonic-NAS可以 achieved up to 10.9%的准确率提升，1.91x的执行时间减少和2.14x的能效性提升。<details>
<summary>Abstract</summary>
The recent surge of interest surrounding Multimodal Neural Networks (MM-NN) is attributed to their ability to effectively process and integrate information from diverse data sources. In MM-NN, features are extracted and fused from multiple modalities using adequate unimodal backbones and specific fusion networks. Although this helps strengthen the multimodal information representation, designing such networks is labor-intensive. It requires tuning the architectural parameters of the unimodal backbones, choosing the fusing point, and selecting the operations for fusion. Furthermore, multimodality AI is emerging as a cutting-edge option in Internet of Things (IoT) systems where inference latency and energy consumption are critical metrics in addition to accuracy. In this paper, we propose Harmonic-NAS, a framework for the joint optimization of unimodal backbones and multimodal fusion networks with hardware awareness on resource-constrained devices. Harmonic-NAS involves a two-tier optimization approach for the unimodal backbone architectures and fusion strategy and operators. By incorporating the hardware dimension into the optimization, evaluation results on various devices and multimodal datasets have demonstrated the superiority of Harmonic-NAS over state-of-the-art approaches achieving up to 10.9% accuracy improvement, 1.91x latency reduction, and 2.14x energy efficiency gain.
</details>
<details>
<summary>摘要</summary>
最近，多模态神经网络（MM-NN）的兴趣增长可以追溯到它们能够有效地处理和融合来自多个数据源的信息。在 MM-NN 中，来自多个模态的特征被提取并融合使用适当的单模态背bone和特定的融合网络。虽然这有助于强化多模态信息表示，但设计这些网络是劳动密集的。需要调整网络的建筑 Parameters，选择融合点，并选择融合操作。此外，多模态 AI 在互联网东西（IoT）系统中出现为一个潮流选项，因为在这些系统中，推理延迟和能耗是关键指标，而不仅仅是准确率。在这篇论文中，我们提出了 Harmonic-NAS，一个框架，用于同时优化单模态背bone和多模态融合网络，并考虑硬件维度。Harmonic-NAS 使用两层优化方法，包括单模态背bone 架构和融合策略和操作的优化。通过将硬件维度integrated到优化中，对多个设备和多模态数据集进行评估，研究结果表明，Harmonic-NAS 比现有方法提高了10.9%的准确率，1.91x的推理延迟，和2.14x的能耗效率。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Visual-Classification-with-Guided-Cropping"><a href="#Zero-Shot-Visual-Classification-with-Guided-Cropping" class="headerlink" title="Zero-Shot Visual Classification with Guided Cropping"></a>Zero-Shot Visual Classification with Guided Cropping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06581">http://arxiv.org/abs/2309.06581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piyapat Saranrittichai, Mauricio Munoz, Volker Fischer, Chaithanya Kumar Mummadi</li>
<li>for: 这个研究旨在提高CLIP模型在关键区域的表现，尤其是当物品覆盖小区域时。</li>
<li>methods: 我们提出了一种叫做导航裁剪（GC-CLIP）的方法，使用预设的零 shot object detection模型来增强CLIP的图像描述性，以提高零 shot 分类性能。</li>
<li>results: 我们的实验结果显示，GC-CLIP可以提高零 shot 分类结果，尤其是当物品覆盖小区域时。<details>
<summary>Abstract</summary>
Pretrained vision-language models, such as CLIP, show promising zero-shot performance across a wide variety of datasets. For closed-set classification tasks, however, there is an inherent limitation: CLIP image encoders are typically designed to extract generic image-level features that summarize superfluous or confounding information for the target tasks. This results in degradation of classification performance, especially when objects of interest cover small areas of input images. In this work, we propose CLIP with Guided Cropping (GC-CLIP), where we use an off-the-shelf zero-shot object detection model in a preprocessing step to increase focus of zero-shot classifier to the object of interest and minimize influence of extraneous image regions. We empirically show that our approach improves zero-shot classification results across architectures and datasets, favorably for small objects.
</details>
<details>
<summary>摘要</summary>
预训义视语模型，如CLIP，在各种数据集上显示出扩展性的 zeroshot性能。然而，对于封闭类型的分类任务，存在内在的限制：CLIP的图像编码器通常是为抽取普适图像水平特征，这些特征可能会损害目标任务的分类性能。这会导致分类性能下降，特别是当目标对象占输入图像中小区域时。在这种情况下，我们提出了GC-CLIP方法，其中我们使用一个预置的零shot对象检测模型来增强零shot分类器对目标对象的专注度，并最小化不相关图像区域的影响。我们经验表明，我们的方法可以提高零shot分类结果，并且对于小对象而言，效果更加明显。
</details></li>
</ul>
<hr>
<h2 id="AmodalSynthDrive-A-Synthetic-Amodal-Perception-Dataset-for-Autonomous-Driving"><a href="#AmodalSynthDrive-A-Synthetic-Amodal-Perception-Dataset-for-Autonomous-Driving" class="headerlink" title="AmodalSynthDrive: A Synthetic Amodal Perception Dataset for Autonomous Driving"></a>AmodalSynthDrive: A Synthetic Amodal Perception Dataset for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06547">http://arxiv.org/abs/2309.06547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Rida Sekkat, Rohit Mohan, Oliver Sawade, Elmar Matthes, Abhinav Valada</li>
<li>for: AmodalSynthDrive is a synthetic multi-task multi-modal amodal perception dataset for autonomous driving research.</li>
<li>methods: The dataset provides multi-view camera images, 3D bounding boxes, LiDAR data, and odometry for 150 driving sequences with over 1M object annotations in diverse traffic, weather, and lighting conditions.</li>
<li>results: The dataset supports multiple amodal scene understanding tasks, including amodal depth estimation for enhanced spatial understanding. Several baselines are evaluated for each task to illustrate the challenges and set up public benchmarking servers.<details>
<summary>Abstract</summary>
Unlike humans, who can effortlessly estimate the entirety of objects even when partially occluded, modern computer vision algorithms still find this aspect extremely challenging. Leveraging this amodal perception for autonomous driving remains largely untapped due to the lack of suitable datasets. The curation of these datasets is primarily hindered by significant annotation costs and mitigating annotator subjectivity in accurately labeling occluded regions. To address these limitations, we introduce AmodalSynthDrive, a synthetic multi-task multi-modal amodal perception dataset. The dataset provides multi-view camera images, 3D bounding boxes, LiDAR data, and odometry for 150 driving sequences with over 1M object annotations in diverse traffic, weather, and lighting conditions. AmodalSynthDrive supports multiple amodal scene understanding tasks including the introduced amodal depth estimation for enhanced spatial understanding. We evaluate several baselines for each of these tasks to illustrate the challenges and set up public benchmarking servers. The dataset is available at http://amodalsynthdrive.cs.uni-freiburg.de.
</details>
<details>
<summary>摘要</summary>
不同于人类，现代计算机视觉算法仍然很难处理部分遮挡的物体。利用这种无模态感知对自动驾驶仍然具有很大的潜在优势，但由于缺乏适当的数据集，这一点仍未得到充分利用。为解决这些限制，我们介绍了AmodalSynthDrive，一个人工合成的多任务多模态无模态感知数据集。该数据集提供了多视图摄像头图像、3D包围框、LiDAR数据和卫星坐标数据，涵盖了150条驾驶序列，共计超过100万个物体标注，在多样化的交通、天气和照明条件下进行了多种交通情况。AmodalSynthDrive支持多种无模态场景理解任务，包括引入的无模态深度估计，以提高空间理解。我们评估了多个基线，以 Illustrate the challenges and set up public benchmarking servers。数据集可以在http://amodalsynthdrive.cs.uni-freiburg.de上下载。
</details></li>
</ul>
<hr>
<h2 id="Strong-Weak-Integrated-Semi-supervision-for-Unsupervised-Single-and-Multi-Target-Domain-Adaptation"><a href="#Strong-Weak-Integrated-Semi-supervision-for-Unsupervised-Single-and-Multi-Target-Domain-Adaptation" class="headerlink" title="Strong-Weak Integrated Semi-supervision for Unsupervised Single and Multi Target Domain Adaptation"></a>Strong-Weak Integrated Semi-supervision for Unsupervised Single and Multi Target Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06528">http://arxiv.org/abs/2309.06528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohu Lu, Hayder Radha</li>
<li>for: 这个论文主要针对对不具有标签的目标领域进行预测，并将来自来源领域的知识转移到目标领域。</li>
<li>methods: 本文提出了一个名为SWISS（强弱融合 semi-supervision）学习策略，它可以在单一目标领域和多目标领域中进行预测。SWISS学习策略包括具有高信任但低多样性的强表示集和具有低信任但高多样性的弱表示集，这两个集合在训练过程中不断地更新。这些集合被融合以生成一个增强的强-弱训练批次，用于训练网络。</li>
<li>results: 实验结果显示，SWISS学习策略可以在三个benchmark（Office-31、Office-Home和DomainNet）上实现高准确率。<details>
<summary>Abstract</summary>
Unsupervised domain adaptation (UDA) focuses on transferring knowledge learned in the labeled source domain to the unlabeled target domain. Despite significant progress that has been achieved in single-target domain adaptation for image classification in recent years, the extension from single-target to multi-target domain adaptation is still a largely unexplored problem area. In general, unsupervised domain adaptation faces a major challenge when attempting to learn reliable information from a single unlabeled target domain. Increasing the number of unlabeled target domains further exacerbate the problem rather significantly. In this paper, we propose a novel strong-weak integrated semi-supervision (SWISS) learning strategy for image classification using unsupervised domain adaptation that works well for both single-target and multi-target scenarios. Under the proposed SWISS-UDA framework, a strong representative set with high confidence but low diversity target domain samples and a weak representative set with low confidence but high diversity target domain samples are updated constantly during the training process. Both sets are fused to generate an augmented strong-weak training batch with pseudo-labels to train the network during every iteration. The extension from single-target to multi-target domain adaptation is accomplished by exploring the class-wise distance relationship between domains and replacing the strong representative set with much stronger samples from peer domains via peer scaffolding. Moreover, a novel adversarial logit loss is proposed to reduce the intra-class divergence between source and target domains, which is back-propagated adversarially with a gradient reverse layer between the classifier and the rest of the network. Experimental results based on three benchmarks, Office-31, Office-Home, and DomainNet, show the effectiveness of the proposed SWISS framework.
</details>
<details>
<summary>摘要</summary>
Unsupervised domain adaptation (UDA) 专注于将源领域中标注的知识传递到目标领域中无标注的数据上。虽然在最近几年内对单目标领域 adaptation 进行了显著的进步，但将单目标领域 adaptation 扩展到多目标领域仍然是一个未探索的问题领域。总的来说，无监督领域 adaptation 面临着在单无标注目标领域中学习可靠信息的主要挑战。增加目标领域的数量更加扩大了问题。在本文中，我们提出了一种基于强弱结合 semi-supervision（SWISS）学习策略，用于无监督领域 adaptation 的图像分类。该策略在单目标和多目标场景中都能够工作良好。在我们提出的SWISS-UDA框架中，一个强大的代表集（strong representative set）和一个弱小的代表集（weak representative set）在训练过程中不断更新。两个集合被融合以生成一个增强的强弱训练集（augmented strong-weak training batch），用于在每次迭代中训练网络。在扩展到多目标领域时，我们利用类别之间的距离关系来替换强大的代表集，并通过对应的骨干来提高强大的样本。此外，我们还提出了一种新的对抗LOGIT损失函数，用于减少源领域和目标领域之间的内类差。这种损失函数通过对抗反向传播来降低内类差。实验结果基于Office-31、Office-Home和DomainNet三个标准测试集，证明了我们提出的SWISS框架的效果。
</details></li>
</ul>
<hr>
<h2 id="Using-Unsupervised-and-Supervised-Learning-and-Digital-Twin-for-Deep-Convective-Ice-Storm-Classification"><a href="#Using-Unsupervised-and-Supervised-Learning-and-Digital-Twin-for-Deep-Convective-Ice-Storm-Classification" class="headerlink" title="Using Unsupervised and Supervised Learning and Digital Twin for Deep Convective Ice Storm Classification"></a>Using Unsupervised and Supervised Learning and Digital Twin for Deep Convective Ice Storm Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07173">http://arxiv.org/abs/2309.07173</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jason Swope, Steve Chien, Emily Dunkel, Xavier Bosch-Lluis, Qing Yue, William Deal</li>
<li>for: 这个论文主要目标是开发一种基于机器学习和数字地球模型的智能雷达扫描系统，用于识别风暴云和不同云类型。</li>
<li>methods: 该论文使用了多个步骤的机器学习和数字地球模型，包括WRF数字地球模型、K-means clustering、Random Decision Forest、支持向量机、Gaussian Naive Bayes、Feed Forward Artificial Neural Network和卷积 neural network等。</li>
<li>results: 论文的实验结果显示，使用这些方法可以在两个不同的 dataset 上达到识别风暴云和不同云类型的高精度，包括在热带区域上达到80%以上的准确率，在非热带区域上达到90%以上的准确率和40%以上的准确率。此外，这些方法还能够抗耗器雷达噪声。<details>
<summary>Abstract</summary>
Smart Ice Cloud Sensing (SMICES) is a small-sat concept in which a primary radar intelligently targets ice storms based on information collected by a lookahead radiometer. Critical to the intelligent targeting is accurate identification of storm/cloud types from eight bands of radiance collected by the radiometer. The cloud types of interest are: clear sky, thin cirrus, cirrus, rainy anvil, and convection core.   We describe multi-step use of Machine Learning and Digital Twin of the Earth's atmosphere to derive such a classifier. First, a digital twin of Earth's atmosphere called a Weather Research Forecast (WRF) is used generate simulated lookahead radiometer data as well as deeper "science" hidden variables. The datasets simulate a tropical region over the Caribbean and a non-tropical region over the Atlantic coast of the United States. A K-means clustering over the scientific hidden variables was utilized by human experts to generate an automatic labelling of the data - mapping each physical data point to cloud types by scientists informed by mean/centroids of hidden variables of the clusters. Next, classifiers were trained with the inputs of the simulated radiometer data and its corresponding label. The classifiers of a random decision forest (RDF), support vector machine (SVM), Gaussian na\"ive bayes, feed forward artificial neural network (ANN), and a convolutional neural network (CNN) were trained. Over the tropical dataset, the best performing classifier was able to identify non-storm and storm clouds with over 80% accuracy in each class for a held-out test set. Over the non-tropical dataset, the best performing classifier was able to classify non-storm clouds with over 90% accuracy and storm clouds with over 40% accuracy. Additionally both sets of classifiers were shown to be resilient to instrument noise.
</details>
<details>
<summary>摘要</summary>
智能冰云感测（SMICES）是一种小卫星概念，其主要采用智能针对方式对冰风暴进行感测，基于预测器收集的八个频率强度数据进行准确识别风暴/云类型。我们使用多个步骤的机器学习和地球大气数字模型来 derivation 这种分类器。首先，我们使用地球大气数字模型（WRF）生成了模拟的预测器数据，以及更深入的科学隐藏变量。这些数据模拟了一个热带地区在加勒比海和一个非热带地区在美国东岸。然后，我们使用K-means归一化将数据分为不同的云类型，并由人工智能经过标注来自动将物理数据点映射到云类型。接着，我们将模拟预测器数据作为输入，并使用Random Decision Forest（RDF）、支持向量机（SVM）、泊松隐藏Naive Bayes（Gaussian Naive Bayes）、Feed Forward Artificial Neural Network（ANN）和卷积神经网络（CNN）等五种分类器进行训练。在热带数据集上，最佳表现的分类器可以识别非风暴云和风暴云的准确率高于80%。在非热带数据集上，最佳表现的分类器可以识别非风暴云的准确率高于90%，并且识别风暴云的准确率高于40%。此外，这些分类器都能够抗耗rument噪声。
</details></li>
</ul>
<hr>
<h2 id="Ethnicity-and-Biometric-Uniqueness-Iris-Pattern-Individuality-in-a-West-African-Database"><a href="#Ethnicity-and-Biometric-Uniqueness-Iris-Pattern-Individuality-in-a-West-African-Database" class="headerlink" title="Ethnicity and Biometric Uniqueness: Iris Pattern Individuality in a West African Database"></a>Ethnicity and Biometric Uniqueness: Iris Pattern Individuality in a West African Database</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06521">http://arxiv.org/abs/2309.06521</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Daugman, Cathryn Downing, Oluwatobi Noah Akande, Oluwakemi Christiana Abikoye</li>
<li>for: 本研究旨在探讨非洲人种群中人类眼睛特征是否具有不同的特征，以及这些特征对人类识别的影响。</li>
<li>methods: 研究人员使用了2个奈及大学收集的眼睛图像库，共计130万次比较眼睛图像，以找出非洲人种群眼睛特征的差异。</li>
<li>results: 研究发现，尽管非洲人种群的眼睛特征具有较为粗糙的文本特征大小，但是可以通过调整操作决策门槛来减少眼睛识别错误的风险。这表明，尽管人种群的差异，但是在这个西非人种群中，个体可以通过比较眼睛图像来减少识别错误。<details>
<summary>Abstract</summary>
We conducted more than 1.3 million comparisons of iris patterns encoded from images collected at two Nigerian universities, which constitute the newly available African Human Iris (AFHIRIS) database. The purpose was to discover whether ethnic differences in iris structure and appearance such as the textural feature size, as contrasted with an all-Chinese image database or an American database in which only 1.53% were of African-American heritage, made a material difference for iris discrimination. We measured a reduction in entropy for the AFHIRIS database due to the coarser iris features created by the thick anterior layer of melanocytes, and we found stochastic parameters that accurately model the relevant empirical distributions. Quantile-Quantile analysis revealed that a very small change in operational decision thresholds for the African database would compensate for the reduced entropy and generate the same performance in terms of resistance to False Matches. We conclude that despite demographic difference, individuality can be robustly discerned by comparison of iris patterns in this West African population.
</details>
<details>
<summary>摘要</summary>
Note: The original text is written in English and the translation is in Simplified Chinese. Please note that the translation is based on the standard language and may not reflect the exact nuances of the original text.
</details></li>
</ul>
<hr>
<h2 id="DF-TransFusion-Multimodal-Deepfake-Detection-via-Lip-Audio-Cross-Attention-and-Facial-Self-Attention"><a href="#DF-TransFusion-Multimodal-Deepfake-Detection-via-Lip-Audio-Cross-Attention-and-Facial-Self-Attention" class="headerlink" title="DF-TransFusion: Multimodal Deepfake Detection via Lip-Audio Cross-Attention and Facial Self-Attention"></a>DF-TransFusion: Multimodal Deepfake Detection via Lip-Audio Cross-Attention and Facial Self-Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06511">http://arxiv.org/abs/2309.06511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aaditya Kharel, Manas Paranjape, Aniket Bera</li>
<li>for: 防止伪造媒体，保持数字内容的 AUTHENTICITY</li>
<li>methods: 多模式音频视频框架，同时处理音频和视频输入，利用lip协调和可读的VGG-16网络抽取视觉提示，并使用 transformer 网络进行面部自我注意</li>
<li>results: 与现有多模式深伪检测技术相比，实现了更高的 F-1 和每个视频 AUC 得分<details>
<summary>Abstract</summary>
With the rise in manipulated media, deepfake detection has become an imperative task for preserving the authenticity of digital content. In this paper, we present a novel multi-modal audio-video framework designed to concurrently process audio and video inputs for deepfake detection tasks. Our model capitalizes on lip synchronization with input audio through a cross-attention mechanism while extracting visual cues via a fine-tuned VGG-16 network. Subsequently, a transformer encoder network is employed to perform facial self-attention. We conduct multiple ablation studies highlighting different strengths of our approach. Our multi-modal methodology outperforms state-of-the-art multi-modal deepfake detection techniques in terms of F-1 and per-video AUC scores.
</details>
<details>
<summary>摘要</summary>
随着伪造媒体的普及，深刻检测深伪成为保持数字内容真实性的必要任务。在这篇论文中，我们提出了一种新的多Modal音频视频框架，用于同时处理音频和视频输入，以检测深伪。我们的模型利用输入音频的唇同步通过交叉注意机制，同时通过精心调整的 VGG-16 网络提取视觉cue。然后，我们使用 transformer 编码器网络进行面部自注意。我们进行了多个减少研究，描述了不同方法的优势。我们的多Modal方法在 F-1 和每个视频 AUC 分数上超过了当前最佳多Modal深伪检测技术。
</details></li>
</ul>
<hr>
<h2 id="Attention-De-sparsification-Matters-Inducing-Diversity-in-Digital-Pathology-Representation-Learning"><a href="#Attention-De-sparsification-Matters-Inducing-Diversity-in-Digital-Pathology-Representation-Learning" class="headerlink" title="Attention De-sparsification Matters: Inducing Diversity in Digital Pathology Representation Learning"></a>Attention De-sparsification Matters: Inducing Diversity in Digital Pathology Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06439">http://arxiv.org/abs/2309.06439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saarthak Kapse, Srijan Das, Jingwei Zhang, Rajarsi R. Gupta, Joel Saltz, Dimitris Samaras, Prateek Prasanna</li>
<li>for: 本研究旨在提出一种多样化推理学习技术，以提高 Histopathology 图像的表征学学习效果。</li>
<li>methods: 该技术使用了自我超vision学习技术，包括对比和非对比方法，从限定的病理学家监督下学习digitized tissue样本中的rich和有效表征。</li>
<li>results: 我们的分析发现，vanilla SSL 预训练模型的注意力分布存在一个有趣的观察：模型倾向于在图像中局部化注意力，即模型强调一些图像中的一些明确的模式。然而，这种注意力稀采可能不适合数字病理学图像，因为这些图像不同于自然图像，不是中心对象所在的物体。因此，我们提出了一种利用细胞 segmentation 提取多种 Histopathology 特定表征，然后提出一种带有先导的积极预text任务，以使模型学习多种视图之间的匹配。这种方法使得模型能够更均匀地注意多种组件，从而引入多样化注意力，以捕捉更加 ricgh的上下文表征。我们通过多种任务的量化和质量分析，证明了我们的方法的效果，并发现了模型的注意力更加广泛分布。<details>
<summary>Abstract</summary>
We propose DiRL, a Diversity-inducing Representation Learning technique for histopathology imaging. Self-supervised learning techniques, such as contrastive and non-contrastive approaches, have been shown to learn rich and effective representations of digitized tissue samples with limited pathologist supervision. Our analysis of vanilla SSL-pretrained models' attention distribution reveals an insightful observation: sparsity in attention, i.e, models tends to localize most of their attention to some prominent patterns in the image. Although attention sparsity can be beneficial in natural images due to these prominent patterns being the object of interest itself, this can be sub-optimal in digital pathology; this is because, unlike natural images, digital pathology scans are not object-centric, but rather a complex phenotype of various spatially intermixed biological components. Inadequate diversification of attention in these complex images could result in crucial information loss. To address this, we leverage cell segmentation to densely extract multiple histopathology-specific representations, and then propose a prior-guided dense pretext task for SSL, designed to match the multiple corresponding representations between the views. Through this, the model learns to attend to various components more closely and evenly, thus inducing adequate diversification in attention for capturing context rich representations. Through quantitative and qualitative analysis on multiple tasks across cancer types, we demonstrate the efficacy of our method and observe that the attention is more globally distributed.
</details>
<details>
<summary>摘要</summary>
我们提出了DiRL，一种基于多样性的表示学习技术，用于 histopathology 图像。无监督学习技术，如对照和非对照方法，可以学习照片样本中的丰富和有效表示，只需限制的病理师指导。我们对vanilla SSL 预训练模型的注意力分布进行分析，发现一个有趣的观察结果：模型倾向于在图像中LOCALIZATION 的一些显著特征上集中大量的注意力。although attention sparsity can be beneficial in natural images due to these prominent patterns being the object of interest itself, this can be sub-optimal in digital pathology; this is because, unlike natural images, digital pathology scans are not object-centric, but rather a complex phenotype of various spatially intermixed biological components. Inadequate diversification of attention in these complex images could result in crucial information loss. To address this, we leverage cell segmentation to densely extract multiple histopathology-specific representations, and then propose a prior-guided dense pretext task for SSL, designed to match the multiple corresponding representations between the views. Through this, the model learns to attend to various components more closely and evenly, thus inducing adequate diversification in attention for capturing context rich representations. Through quantitative and qualitative analysis on multiple tasks across cancer types, we demonstrate the efficacy of our method and observe that the attention is more globally distributed.
</details></li>
</ul>
<hr>
<h2 id="Exploring-Non-additive-Randomness-on-ViT-against-Query-Based-Black-Box-Attacks"><a href="#Exploring-Non-additive-Randomness-on-ViT-against-Query-Based-Black-Box-Attacks" class="headerlink" title="Exploring Non-additive Randomness on ViT against Query-Based Black-Box Attacks"></a>Exploring Non-additive Randomness on ViT against Query-Based Black-Box Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06438">http://arxiv.org/abs/2309.06438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jindong Gu, Fangyun Wei, Philip Torr, Han Hu</li>
<li>for: 这种论文是为了探讨深度神经网络可以被小型、难以察觉的干扰所欺骗的问题，以及如何防范这种攻击。</li>
<li>methods: 这篇论文使用了模型输出概率的图像查询来生成干扰，不需要访问到下一代模型。</li>
<li>results: 研究表明，通过非加性随机性来防范QBBA攻击可以获得有效的防御效果，而且不会带来过多的性能损失。<details>
<summary>Abstract</summary>
Deep Neural Networks can be easily fooled by small and imperceptible perturbations. The query-based black-box attack (QBBA) is able to create the perturbations using model output probabilities of image queries requiring no access to the underlying models. QBBA poses realistic threats to real-world applications. Recently, various types of robustness have been explored to defend against QBBA. In this work, we first taxonomize the stochastic defense strategies against QBBA. Following our taxonomy, we propose to explore non-additive randomness in models to defend against QBBA. Specifically, we focus on underexplored Vision Transformers based on their flexible architectures. Extensive experiments show that the proposed defense approach achieves effective defense, without much sacrifice in performance.
</details>
<details>
<summary>摘要</summary>
深度神经网络容易受到小型、难以察觉的变化的影响。Query-based黑盒攻击（QBBA）可以通过使用图像查询输出概率来生成变化，无需访问基础模型。QBBA对实际应用场景 pose 了真实的威胁。在这种情况下，我们首先将随机防御策略对QBBA进行分类。根据我们的分类，我们提议利用模型中的非加性随机性来防御QBBA。specifically，我们关注未得到足够关注的视觉转换器，因为它们具有灵活的体系。我们的实验表明，我们提议的防御策略可以有效地防止攻击，而不会影响性能的减少。
</details></li>
</ul>
<hr>
<h2 id="Action-Segmentation-Using-2D-Skeleton-Heatmaps"><a href="#Action-Segmentation-Using-2D-Skeleton-Heatmaps" class="headerlink" title="Action Segmentation Using 2D Skeleton Heatmaps"></a>Action Segmentation Using 2D Skeleton Heatmaps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06462">http://arxiv.org/abs/2309.06462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Syed Waleed Hyder, Muhammad Usama, Anas Zafar, Muhammad Naufil, Fawad Javed Fateh, Andrey Konin, M. Zeeshan Zia, Quoc-Huy Tran</li>
<li>for: 人体活动识别 task 的细致分割，可以提高人体活动识别的精度。</li>
<li>methods: 使用2Dskeleton热图序列作为输入，并使用TCN进行时空特征提取。</li>
<li>results: 相比前方法，本方法具有更好的稳定性和抗失败性，并且可以在action segmentation datasets上达到相似或更好的性能。此外，通过将2Dskeleton热图序列和RGB视频作为输入进行联合学习，可以进一步提高性能。<details>
<summary>Abstract</summary>
This paper presents a 2D skeleton-based action segmentation method with applications in fine-grained human activity recognition. In contrast with state-of-the-art methods which directly take sequences of 3D skeleton coordinates as inputs and apply Graph Convolutional Networks (GCNs) for spatiotemporal feature learning, our main idea is to use sequences of 2D skeleton heatmaps as inputs and employ Temporal Convolutional Networks (TCNs) to extract spatiotemporal features. Despite lacking 3D information, our approach yields comparable/superior performances and better robustness against missing keypoints than previous methods on action segmentation datasets. Moreover, we improve the performances further by using both 2D skeleton heatmaps and RGB videos as inputs. To our best knowledge, this is the first work to utilize 2D skeleton heatmap inputs and the first work to explore 2D skeleton+RGB fusion for action segmentation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AGMDT-Virtual-Staining-of-Renal-Histology-Images-with-Adjacency-Guided-Multi-Domain-Transfer"><a href="#AGMDT-Virtual-Staining-of-Renal-Histology-Images-with-Adjacency-Guided-Multi-Domain-Transfer" class="headerlink" title="AGMDT: Virtual Staining of Renal Histology Images with Adjacency-Guided Multi-Domain Transfer"></a>AGMDT: Virtual Staining of Renal Histology Images with Adjacency-Guided Multi-Domain Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06421">http://arxiv.org/abs/2309.06421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Ma, Chao Zhang, Min Lu, Lin Luo</li>
<li>for: 这个论文的目的是提出一种新的虚拟染色方法，以便将病理切片图像转换成不同的染色图像，以提高诊断的准确性和效率。</li>
<li>methods: 该方法基于一个高质量的多域肾 histological 数据集，使用枢轴搜索和两分图匹配算法来找到Serial slice中的匹配对，然后通过这些对来监督端到端模型进行多域染色转换。</li>
<li>results: 实验结果表明，提出的 AGMDT 方法可以很好地平衡精确的像素级匹配和无需对数据进行对应的预处理，同时利用多域序列切片图像之间的相关性，以提高诊断的准确性和效率。<details>
<summary>Abstract</summary>
Renal pathology, as the gold standard of kidney disease diagnosis, requires doctors to analyze a series of tissue slices stained by H&E staining and special staining like Masson, PASM, and PAS, respectively. These special staining methods are costly, time-consuming, and hard to standardize for wide use especially in primary hospitals. Advances of supervised learning methods have enabled the virtually conversion of H&E images into special staining images, but achieving pixel-to-pixel alignment for training remains challenging. In contrast, unsupervised learning methods regarding different stains as different style transfer domains can utilize unpaired data, but they ignore the spatial inter-domain correlations and thus decrease the trustworthiness of structural details for diagnosis. In this paper, we propose a novel virtual staining framework AGMDT to translate images into other domains by avoiding pixel-level alignment and meanwhile utilizing the correlations among adjacent tissue slices. We first build a high-quality multi-domain renal histological dataset where each specimen case comprises a series of slices stained in various ways. Based on it, the proposed framework AGMDT discovers patch-level aligned pairs across the serial slices of multi-domains through glomerulus detection and bipartite graph matching, and utilizes such correlations to supervise the end-to-end model for multi-domain staining transformation. Experimental results show that the proposed AGMDT achieves a good balance between the precise pixel-level alignment and unpaired domain transfer by exploiting correlations across multi-domain serial pathological slices, and outperforms the state-of-the-art methods in both quantitative measure and morphological details.
</details>
<details>
<summary>摘要</summary>
肾脏病学（为肾脏病诊断的标准）需要医生分析一系列染料处理后的组织切片，如H&E染色和特殊染色如Masson、PASM和PAS等。这些特殊染色方法是费时费力，难以普及使用，特别是在初级医院。随着超级vised学习方法的发展，可以将H&E图像转化为特殊染色图像，但在训练时Pixel-to-Pixel对齐仍然是挑战。相反，不监督学习方法将不同染色视为不同的风格传输领域，可以使用无对数据，但忽略了组织间空间相关性，因此降低了诊断结果的可靠性。在这篇论文中，我们提出了一种新的虚拟染色框架AGMDT，可以将图像转化为其他领域，而不需Pixel-to-Pixel对齐。我们首先构建了高质量多频道肾脏 histological 数据集，每个样本 случа包括一系列不同染色的组织切片。基于这个数据集，我们的框架AGMDT可以在序列切片中找到适合的 patch-level 对应对，并使用这些对应关系来监督终端模型进行多频道染色变换。实验结果表明，我们的 AGMDT 可以很好地平衡精确的Pixel-to-Pixel对齐和无对频道传输，并且在量度测试和结构细节方面都超过了当前的状况。
</details></li>
</ul>
<hr>
<h2 id="InstaFlow-One-Step-is-Enough-for-High-Quality-Diffusion-Based-Text-to-Image-Generation"><a href="#InstaFlow-One-Step-is-Enough-for-High-Quality-Diffusion-Based-Text-to-Image-Generation" class="headerlink" title="InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation"></a>InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06380">http://arxiv.org/abs/2309.06380</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gnobitab/instaflow">https://github.com/gnobitab/instaflow</a></li>
<li>paper_authors: Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, Qiang Liu</li>
<li>for: 这篇论文主要是为了提高Diffusion模型的采样速度和计算成本，以实现一步逻辑的文本到图像生成器。</li>
<li>methods: 这篇论文使用了Rectified Flow方法，包括一个名为“reflow”的过程，可以直接压缩概率流的轨迹，提高图像和噪声之间的协调，并且使用学生模型进行混合。</li>
<li>results: 这篇论文提出了一种基于Diffusion模型的一步文本到图像生成器，使用了新的文本条件管道，并使用Rectified Flow方法来提高采样速度和计算成本。实验结果表明，这种一步模型可以在MS COCO 2017-5k上达到SD级别的图像质量，FID值为23.3，比前一个状态的技术（进行分布式采样）有了较大的提升（FID值为37.2）。此外，通过使用扩展网络和1.7B参数， authors还提高了FID值到22.4。<details>
<summary>Abstract</summary>
Diffusion models have revolutionized text-to-image generation with its exceptional quality and creativity. However, its multi-step sampling process is known to be slow, often requiring tens of inference steps to obtain satisfactory results. Previous attempts to improve its sampling speed and reduce computational costs through distillation have been unsuccessful in achieving a functional one-step model. In this paper, we explore a recent method called Rectified Flow, which, thus far, has only been applied to small datasets. The core of Rectified Flow lies in its \emph{reflow} procedure, which straightens the trajectories of probability flows, refines the coupling between noises and images, and facilitates the distillation process with student models. We propose a novel text-conditioned pipeline to turn Stable Diffusion (SD) into an ultra-fast one-step model, in which we find reflow plays a critical role in improving the assignment between noise and images. Leveraging our new pipeline, we create, to the best of our knowledge, the first one-step diffusion-based text-to-image generator with SD-level image quality, achieving an FID (Frechet Inception Distance) of $23.3$ on MS COCO 2017-5k, surpassing the previous state-of-the-art technique, progressive distillation, by a significant margin ($37.2$ $\rightarrow$ $23.3$ in FID). By utilizing an expanded network with 1.7B parameters, we further improve the FID to $22.4$. We call our one-step models \emph{InstaFlow}. On MS COCO 2014-30k, InstaFlow yields an FID of $13.1$ in just $0.09$ second, the best in $\leq 0.1$ second regime, outperforming the recent StyleGAN-T ($13.9$ in $0.1$ second). Notably, the training of InstaFlow only costs 199 A100 GPU days. Project page:~\url{https://github.com/gnobitab/InstaFlow}.
</details>
<details>
<summary>摘要</summary>
Diffusion模型已经革命化了文本到图像生成，其品质和创新性都非常出色。然而，它的多步骤采样过程相对较慢，经常需要数十个推理步骤以获得满意的结果。以前的尝试通过热化来提高采样速度和计算成本，但是没有实现了一个功能的一步模型。在这篇论文中，我们研究了一种名为Rectified Flow的方法，它只在小数据集上应用。Rectified Flow的核心在于它的“重定向”过程，它将概率流的轨迹正则化，提高图像和噪声之间的协同关系，并且使学生模型的整体准确性得到提高。我们提出了一种基于Stable Diffusion（SD）的文本受控管道，将SD转化为一个超快一步模型，并发现重定向在填充关系中发挥了关键作用。通过我们的新管道，我们创造了，到我们所知道的最高水平，第一个基于Diffusion的文本到图像生成器，其FID（Frechet Inception Distance）为23.3，超过了之前的最佳技术进步distillation，并且在MS COCO 2017-5k上达到了37.2$\Rightarrow$23.3的FID提升。通过使用扩展的网络和1.7B参数，我们进一步提高了FID到22.4。我们称我们的一步模型为InstaFlow。在MS COCO 2014-30k上，InstaFlow在0.09秒内达到了FID13.1，在$\leq 0.1$秒的 régime中表现最佳，比StyleGAN-T（13.9在0.1秒）更高。另外，我们在训练InstaFlow时只需要199个A100 GPU天。更多信息请访问我们的项目页面：<https://github.com/gnobitab/InstaFlow>.
</details></li>
</ul>
<hr>
<h2 id="Padding-free-Convolution-based-on-Preservation-of-Differential-Characteristics-of-Kernels"><a href="#Padding-free-Convolution-based-on-Preservation-of-Differential-Characteristics-of-Kernels" class="headerlink" title="Padding-free Convolution based on Preservation of Differential Characteristics of Kernels"></a>Padding-free Convolution based on Preservation of Differential Characteristics of Kernels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06370">http://arxiv.org/abs/2309.06370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kuangdai Leng, Jeyan Thiyagalingam</li>
<li>for: 保持图像大小的卷积操作</li>
<li>methods: 基于kernel的差分特征保持的非填充卷积方法</li>
<li>results: 在图像分类、Semantic segmentation和超分辨重建任务中显著超过比较方法的性能<details>
<summary>Abstract</summary>
Convolution is a fundamental operation in image processing and machine learning. Aimed primarily at maintaining image size, padding is a key ingredient of convolution, which, however, can introduce undesirable boundary effects. We present a non-padding-based method for size-keeping convolution based on the preservation of differential characteristics of kernels. The main idea is to make convolution over an incomplete sliding window "collapse" to a linear differential operator evaluated locally at its central pixel, which no longer requires information from the neighbouring missing pixels. While the underlying theory is rigorous, our final formula turns out to be simple: the convolution over an incomplete window is achieved by convolving its nearest complete window with a transformed kernel. This formula is computationally lightweight, involving neither interpolation or extrapolation nor restrictions on image and kernel sizes. Our method favours data with smooth boundaries, such as high-resolution images and fields from physics. Our experiments include: i) filtering analytical and non-analytical fields from computational physics and, ii) training convolutional neural networks (CNNs) for the tasks of image classification, semantic segmentation and super-resolution reconstruction. In all these experiments, our method has exhibited visible superiority over the compared ones.
</details>
<details>
<summary>摘要</summary>
convolution 是图像处理和机器学习中的基本操作。 padding 是 convolution 的关键组分，但是它可能会导致边界效应。我们提出了不使用 padding 的方法，以保持图像大小。我们的主要想法是使 convolution 操作在不完整的滑块上进行，将滑块中心像素的线性算法视为局部的差分特征。这样就不需要从邻近缺失像素中获取信息了。我们的理论基础是严谨的，但是我们的最终公式却很简单：在不完整的滑块上进行 convolution 操作，只需要将完整的滑块与变换后的核函数进行卷积即可。这种方法不需要 interpolate 或 extrapolate 像素值，也不需要图像和核函数的大小受限。我们的方法更适合图像边缘平滑的数据，如高分辨率图像和物理学中的场景。我们的实验包括：i) 对计算物理学中的分析和非分析场景进行滤波处理，ii) 使用卷积神经网络（CNNs）进行图像分类、semantic segmentation 和超分辨重建任务。在这些实验中，我们的方法都有可见的优越性。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Graphics-Representation-with-Differentiable-Indirection"><a href="#Efficient-Graphics-Representation-with-Differentiable-Indirection" class="headerlink" title="Efficient Graphics Representation with Differentiable Indirection"></a>Efficient Graphics Representation with Differentiable Indirection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08387">http://arxiv.org/abs/2309.08387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayantan Datta, Carl Marshall, Zhao Dong, Zhengqin Li, Derek Nowrouzezahrai</li>
<li>for: 这篇论文是为了替代传统计算和数据操作，提出了一种新的学习 primitive，即可微的推导折衔。</li>
<li>methods: 该论文使用了可微的多尺度 Lookup 表，作为图形处理管线中的有效替代方案。</li>
<li>results: 该论文在各种图形任务中，如几何和图像表示、纹理映射、照明和辐射场表示等，都能够轻松地 интеGRATE到现有的架构中，快速训练并提供高效和灵活的结果。<details>
<summary>Abstract</summary>
We introduce differentiable indirection -- a novel learned primitive that employs differentiable multi-scale lookup tables as an effective substitute for traditional compute and data operations across the graphics pipeline. We demonstrate its flexibility on a number of graphics tasks, i.e., geometric and image representation, texture mapping, shading, and radiance field representation. In all cases, differentiable indirection seamlessly integrates into existing architectures, trains rapidly, and yields both versatile and efficient results.
</details>
<details>
<summary>摘要</summary>
我们介绍了微调irection -- 一种新的学习 primitives，它使用可微分多尺度lookup表作为图形管道中的有效替代方法。我们在几个图形任务中展示了它的灵活性，包括几何和图像表示、纹理映射、照明和辐射场表示。在所有情况下，微调irection顺利地集成到现有的架构中，快速训练，并产生了高效和多元的结果。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Flat-Minima-for-Domain-Generalization-with-Large-Learning-Rates"><a href="#Exploring-Flat-Minima-for-Domain-Generalization-with-Large-Learning-Rates" class="headerlink" title="Exploring Flat Minima for Domain Generalization with Large Learning Rates"></a>Exploring Flat Minima for Domain Generalization with Large Learning Rates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06337">http://arxiv.org/abs/2309.06337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Zhang, Lei Qi, Yinghuan Shi, Yang Gao</li>
<li>for: 提高模型在频率不同的领域中的泛化性能</li>
<li>methods: 利用大学习率来提高模型的多个权重的多样性，并通过权重 interpolate 来确保敏感的权重不会过拟合，同时利用Local Entropy Loss来评估权重的平坦程度</li>
<li>results: 在分类和semantic segmentation领域的频率不同的泛化 benchmark 上达到了状态机器的性能Here’s a more detailed explanation of each point:</li>
<li>for: The paper aims to improve the generalization ability of deep learning models in different domains, which is a key problem in domain generalization (DG).</li>
<li>methods: The authors propose a new training strategy called Lookahead, which leverages a large learning rate to promote weight diversity and facilitate the identification of flat regions in the loss landscape. To prevent overfitting during training, they also propose two variants of weight regularization.</li>
<li>results: The proposed method achieves state-of-the-art performance on both classification and semantic segmentation domain generalization benchmarks.I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Domain Generalization (DG) aims to generalize to arbitrary unseen domains. A promising approach to improve model generalization in DG is the identification of flat minima. One typical method for this task is SWAD, which involves averaging weights along the training trajectory. However, the success of weight averaging depends on the diversity of weights, which is limited when training with a small learning rate. Instead, we observe that leveraging a large learning rate can simultaneously promote weight diversity and facilitate the identification of flat regions in the loss landscape. However, employing a large learning rate suffers from the convergence problem, which cannot be resolved by simply averaging the training weights. To address this issue, we introduce a training strategy called Lookahead which involves the weight interpolation, instead of average, between fast and slow weights. The fast weight explores the weight space with a large learning rate, which is not converged while the slow weight interpolates with it to ensure the convergence. Besides, weight interpolation also helps identify flat minima by implicitly optimizing the local entropy loss that measures flatness. To further prevent overfitting during training, we propose two variants to regularize the training weight with weighted averaged weight or with accumulated history weight. Taking advantage of this new perspective, our methods achieve state-of-the-art performance on both classification and semantic segmentation domain generalization benchmarks. The code is available at https://github.com/koncle/DG-with-Large-LR.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SAMPLING-Scene-adaptive-Hierarchical-Multiplane-Images-Representation-for-Novel-View-Synthesis-from-a-Single-Image"><a href="#SAMPLING-Scene-adaptive-Hierarchical-Multiplane-Images-Representation-for-Novel-View-Synthesis-from-a-Single-Image" class="headerlink" title="SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image"></a>SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06323">http://arxiv.org/abs/2309.06323</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/VDIGPKU/SAMPLING">https://github.com/VDIGPKU/SAMPLING</a></li>
<li>paper_authors: Xiaoyu Zhou, Zhiwei Lin, Xiaojun Shan, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang</li>
<li>for: 这篇论文旨在解决基于单张图像的新视图合成问题，特别是对于宽泛的户外场景。</li>
<li>methods: 该论文提出了一种基于改进多平面图像（MPI）的Scene-adaptive Hierarchical Multiplane Images Representation（SAMPLING）方法，包括自适应分布策略和层次别 Branch。</li>
<li>results: 该方法在KITTI dataset上对大规模的户外场景进行了单张图像新视图合成，并在未seen Tanks and Temples dataset上进行了推广。结果表明该方法具有显著的性能提升。<details>
<summary>Abstract</summary>
Recent novel view synthesis methods obtain promising results for relatively small scenes, e.g., indoor environments and scenes with a few objects, but tend to fail for unbounded outdoor scenes with a single image as input. In this paper, we introduce SAMPLING, a Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image based on improved multiplane images (MPI). Observing that depth distribution varies significantly for unbounded outdoor scenes, we employ an adaptive-bins strategy for MPI to arrange planes in accordance with each scene image. To represent intricate geometry and multi-scale details, we further introduce a hierarchical refinement branch, which results in high-quality synthesized novel views. Our method demonstrates considerable performance gains in synthesizing large-scale unbounded outdoor scenes using a single image on the KITTI dataset and generalizes well to the unseen Tanks and Temples dataset.The code and models will soon be made available.
</details>
<details>
<summary>摘要</summary>
新的小说视图合成方法在相对较小的场景中，如室内环境和一些物品的场景中，取得了可喜的结果，但在卷积图片作为输入的场景中很容易失败。在这篇论文中，我们介绍了采样，一种基于改进的多平面图像（MPI）的Scene-adaptive Hierarchical Multiplane Images Representation дляNovel View Synthesis from a Single Image。我们发现了不同的景象中的深度分布变化很大，因此我们采用了适应性的桶策略来安排MPI中的平面。为了表示复杂的几何结构和多尺度细节，我们还引入了层次修复分支，从而实现高质量的合成新视图。我们的方法在KITTI数据集上Synthesizing large-scale unbounded outdoor scenes using a single image demonstrates considerable performance gains and generalizes well to the unseen Tanks and Temples dataset.我们很快将代码和模型公开。
</details></li>
</ul>
<hr>
<h2 id="Semantic-and-Articulated-Pedestrian-Sensing-Onboard-a-Moving-Vehicle"><a href="#Semantic-and-Articulated-Pedestrian-Sensing-Onboard-a-Moving-Vehicle" class="headerlink" title="Semantic and Articulated Pedestrian Sensing Onboard a Moving Vehicle"></a>Semantic and Articulated Pedestrian Sensing Onboard a Moving Vehicle</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06313">http://arxiv.org/abs/2309.06313</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maria Priisalu</li>
<li>for: 本研究旨在提高交通安全性，通过利用LiDAR数据进行人体探测和预测。</li>
<li>methods: 本研究使用LiDAR数据直接测量深度，并对人体部位进行探测和跟踪。</li>
<li>results: 研究发现，利用LiDAR数据进行人体探测和预测可以提高交通安全性，尤其是在车辆前进速度较快的情况下。<details>
<summary>Abstract</summary>
It is difficult to perform 3D reconstruction from on-vehicle gathered video due to the large forward motion of the vehicle. Even object detection and human sensing models perform significantly worse on onboard videos when compared to standard benchmarks because objects often appear far away from the camera compared to the standard object detection benchmarks, image quality is often decreased by motion blur and occlusions occur often. This has led to the popularisation of traffic data-specific benchmarks. Recently Light Detection And Ranging (LiDAR) sensors have become popular to directly estimate depths without the need to perform 3D reconstructions. However, LiDAR-based methods still lack in articulated human detection at a distance when compared to image-based methods. We hypothesize that benchmarks targeted at articulated human sensing from LiDAR data could bring about increased research in human sensing and prediction in traffic and could lead to improved traffic safety for pedestrians.
</details>
<details>
<summary>摘要</summary>
“对于车辆上收集的影像进行3D重建很难，因为车辆前进速度很快，使得物体识别和人体感应模型在车辆上影像上表现比标准参考模型更差，物体常常在摄像头相比较远，影像质量受到运动模糊和遮挡的影响。这导致了交通数据特有的参考标准的出现。然而，激光探测（LiDAR）仪仍然缺乏在距离中探测人体的细节，与影像基本方法相比。我们假设，对于LiDAR数据的人体探测参考标准可能会带来更多的人体感应和预测研究，从而提高了交通安全性。”
</details></li>
</ul>
<hr>
<h2 id="Towards-High-Quality-Specular-Highlight-Removal-by-Leveraging-Large-Scale-Synthetic-Data"><a href="#Towards-High-Quality-Specular-Highlight-Removal-by-Leveraging-Large-Scale-Synthetic-Data" class="headerlink" title="Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data"></a>Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06302">http://arxiv.org/abs/2309.06302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gang Fu, Qing Zhang, Lei Zhu, Chunxia Xiao, Ping Li</li>
<li>for: 去除单个物体图像中的抛光 highlights</li>
<li>methods: 提议一种三个阶段网络来解决这个问题，包括对输入图像进行颜色抽象、颜色修正和音调调整等步骤。</li>
<li>results: 对于实际图像，网络能够广泛适用并且能够生成高质量的抛光自由图像。<details>
<summary>Abstract</summary>
This paper aims to remove specular highlights from a single object-level image. Although previous methods have made some progresses, their performance remains somewhat limited, particularly for real images with complex specular highlights. To this end, we propose a three-stage network to address them. Specifically, given an input image, we first decompose it into the albedo, shading, and specular residue components to estimate a coarse specular-free image. Then, we further refine the coarse result to alleviate its visual artifacts such as color distortion. Finally, we adjust the tone of the refined result to match that of the input as closely as possible. In addition, to facilitate network training and quantitative evaluation, we present a large-scale synthetic dataset of object-level images, covering diverse objects and illumination conditions. Extensive experiments illustrate that our network is able to generalize well to unseen real object-level images, and even produce good results for scene-level images with multiple background objects and complex lighting.
</details>
<details>
<summary>摘要</summary>
这个论文目标是从单个物体图像中去除反射高光。先前的方法有一定的进步，但其性能仍然有一定的限制，特别是对于真实的图像来说，它们的反射高光非常复杂。为此，我们提议一个三个阶段的网络来解决这个问题。具体来说，给定一个输入图像，我们首先将其分解为反射、阴影和反射剩余组成来估算一个粗略的反射减少后的图像。然后，我们进一步修正这个粗略结果，以消除它的视觉artefacts，如颜色扭曲。最后，我们将修正后的结果与输入图像的颜色匹配到一样多少可能。此外，为了训练网络和量化评估，我们提供了一个大规模的Synthetic数据集，覆盖了多种物体和照明条件。广泛的实验表明，我们的网络能够通过训练来泛化到未经看过的真实物体图像，甚至对多个背景物体和复杂的照明条件进行好的处理。
</details></li>
</ul>
<hr>
<h2 id="Self-Training-and-Multi-Task-Learning-for-Limited-Data-Evaluation-Study-on-Object-Detection"><a href="#Self-Training-and-Multi-Task-Learning-for-Limited-Data-Evaluation-Study-on-Object-Detection" class="headerlink" title="Self-Training and Multi-Task Learning for Limited Data: Evaluation Study on Object Detection"></a>Self-Training and Multi-Task Learning for Limited Data: Evaluation Study on Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06288">http://arxiv.org/abs/2309.06288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoàng-Ân Lê, Minh-Tan Pham</li>
<li>for: 本研究探讨了自动学习和多任务学习在对数据匮乏情况下的表现。</li>
<li>methods: 本研究使用了自动学习和多任务学习两种方法，其中自动学习是通过学生模型从教师模型的预测中学习，而多任务学习是通过同时优化不同目标来学习突出相关性。</li>
<li>results: 实验结果显示，在没有教师训练数据的情况下，使用弱教师和未见数据进行自动学习可以提高性能。此外，在部分注释的数据情况下，多任务学习也可以提高性能。<details>
<summary>Abstract</summary>
Self-training allows a network to learn from the predictions of a more complicated model, thus often requires well-trained teacher models and mixture of teacher-student data while multi-task learning jointly optimizes different targets to learn salient interrelationship and requires multi-task annotations for each training example. These frameworks, despite being particularly data demanding have potentials for data exploitation if such assumptions can be relaxed. In this paper, we compare self-training object detection under the deficiency of teacher training data where students are trained on unseen examples by the teacher, and multi-task learning with partially annotated data, i.e. single-task annotation per training example. Both scenarios have their own limitation but potentially helpful with limited annotated data. Experimental results show the improvement of performance when using a weak teacher with unseen data for training a multi-task student. Despite the limited setup we believe the experimental results show the potential of multi-task knowledge distillation and self-training, which could be beneficial for future study. Source code is at https://lhoangan.github.io/multas.
</details>
<details>
<summary>摘要</summary>
自我训练允许网络从更复杂的模型的预测中学习，因此通常需要Well-trained教师模型和学生数据的混合，而多任务学习则是同时优化不同目标以学习突出关系的方法。这些框架，尽管特别是数据具有潜在的可优化假设，但它们具有潜在的数据利用潜力。在这篇论文中，我们比较了无教师训练数据的情况下，学生通过不види的教师训练来进行自我训练，以及具有部分注释数据的多任务学习。两种情况都具有自己的局限性，但它们可能帮助处理有限的注释数据。实验结果表明，使用弱教师和未见数据进行学生训练可以提高性能。尽管我们的设置有限，但我们认为实验结果表明了多任务知识储存和自我训练的潜力，这可能对未来的研究有所帮助。源代码可以在 <https://lhoangan.github.io/multas> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Fg-T2M-Fine-Grained-Text-Driven-Human-Motion-Generation-via-Diffusion-Model"><a href="#Fg-T2M-Fine-Grained-Text-Driven-Human-Motion-Generation-via-Diffusion-Model" class="headerlink" title="Fg-T2M: Fine-Grained Text-Driven Human Motion Generation via Diffusion Model"></a>Fg-T2M: Fine-Grained Text-Driven Human Motion Generation via Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06284">http://arxiv.org/abs/2309.06284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yin Wang, Zhiying Leng, Frederick W. B. Li, Shun-Cheng Wu, Xiaohui Liang</li>
<li>for: 文章描述人类动作生成，以充分利用文本描述来生成高质量的人类动作序列。</li>
<li>methods: 方法包括两个关键组件：1）语言结构帮助模块，通过准确地构造语言特征来完全利用文本信息；2）语义语言特征学习模块，通过浅浅层和深层图 neuron 网络学习语义语言特征，实现多步推理。</li>
<li>results: 实验表明，我们的方法在 HumanML3D 和 KIT 测试集上比文本驱动动作生成方法表现出色，生成更好的视觉确认动作序列。<details>
<summary>Abstract</summary>
Text-driven human motion generation in computer vision is both significant and challenging. However, current methods are limited to producing either deterministic or imprecise motion sequences, failing to effectively control the temporal and spatial relationships required to conform to a given text description. In this work, we propose a fine-grained method for generating high-quality, conditional human motion sequences supporting precise text description. Our approach consists of two key components: 1) a linguistics-structure assisted module that constructs accurate and complete language feature to fully utilize text information; and 2) a context-aware progressive reasoning module that learns neighborhood and overall semantic linguistics features from shallow and deep graph neural networks to achieve a multi-step inference. Experiments show that our approach outperforms text-driven motion generation methods on HumanML3D and KIT test sets and generates better visually confirmed motion to the text conditions.
</details>
<details>
<summary>摘要</summary>
文本驱动人体动作生成在计算机视觉中具有重要性和挑战。然而，当前的方法仅能生成决定性或不准确的动作序列，无法有效控制文本描述中的时间和空间关系。在这项工作中，我们提出了细化的方法，用于生成高质量、条件人体动作序列，支持精确的文本描述。我们的方法包括两个关键组件：1）语言结构协助模块，通过准确地构建语言特征来完全利用文本信息；2）上下文感知进程理解模块，通过浅混合图神经网络和深度图神经网络学习上下文和整体语义特征，实现多步推理。实验表明，我们的方法在人体ML3D和KIT测试集上超越文本驱动动作生成方法，并生成更好的视觉确认的动作序列。
</details></li>
</ul>
<hr>
<h2 id="IBAFormer-Intra-batch-Attention-Transformer-for-Domain-Generalized-Semantic-Segmentation"><a href="#IBAFormer-Intra-batch-Attention-Transformer-for-Domain-Generalized-Semantic-Segmentation" class="headerlink" title="IBAFormer: Intra-batch Attention Transformer for Domain Generalized Semantic Segmentation"></a>IBAFormer: Intra-batch Attention Transformer for Domain Generalized Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06282">http://arxiv.org/abs/2309.06282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiyu Sun, Huilin Chen, Meng Zheng, Ziyan Wu, Michael Felsberg, Yang Tang<br>for:* 这个论文旨在解决领域总体 semantic segmentation (DGSS) 问题，即使用无法访问目标数据的情况下，使模型具备更好的泛化能力。methods:* 该论文提出了两种替代性内批注机制：mean-based intra-batch attention (MIBA) 和 element-wise intra-batch attention (EIBA)，以捕捉不同批次之间的相关性，提高特征表示和泛化能力。results:* 该论文提出的 IBAFormer 模型在 DGSS 问题上实现了最佳性能，并通过精心设计的实验证明了每个引入的组件的效果。<details>
<summary>Abstract</summary>
Domain generalized semantic segmentation (DGSS) is a critical yet challenging task, where the model is trained only on source data without access to any target data. Despite the proposal of numerous DGSS strategies, the generalization capability remains limited in CNN architectures. Though some Transformer-based segmentation models show promising performance, they primarily focus on capturing intra-sample attentive relationships, disregarding inter-sample correlations which can potentially benefit DGSS. To this end, we enhance the attention modules in Transformer networks for improving DGSS by incorporating information from other independent samples in the same batch, enriching contextual information, and diversifying the training data for each attention block. Specifically, we propose two alternative intra-batch attention mechanisms, namely mean-based intra-batch attention (MIBA) and element-wise intra-batch attention (EIBA), to capture correlations between different samples, enhancing feature representation and generalization capabilities. Building upon intra-batch attention, we introduce IBAFormer, which integrates self-attention modules with the proposed intra-batch attention for DGSS. Extensive experiments demonstrate that IBAFormer achieves SOTA performance in DGSS, and ablation studies further confirm the effectiveness of each introduced component.
</details>
<details>
<summary>摘要</summary>
域面泛化 semantic segmentation (DGSS) 是一项关键但受挑战的任务，模型只在源数据上训练，无法访问目标数据。 DESPITE  numerous DGSS strategies 的提议，模型的泛化能力仍然有限。 虽然一些基于 Transformer 的 segmentation 模型表现出色，但它们主要是 capture 内样关系，忽略了 между样关系，这可能会增强 DGSS。为此，我们在 Transformer 网络中增强注意模块，以便提高 DGSS 的泛化能力。 Specifically, we propose  two alternative intra-batch attention mechanisms, namely mean-based intra-batch attention (MIBA) and element-wise intra-batch attention (EIBA), to capture correlations between different samples, enrich contextual information, and diversify the training data for each attention block。 Building upon intra-batch attention, we introduce IBAFormer, which integrates self-attention modules with the proposed intra-batch attention for DGSS。 Extensive experiments demonstrate that IBAFormer achieves SOTA performance in DGSS, and ablation studies further confirm the effectiveness of each introduced component。
</details></li>
</ul>
<hr>
<h2 id="OTAS-Unsupervised-Boundary-Detection-for-Object-Centric-Temporal-Action-Segmentation"><a href="#OTAS-Unsupervised-Boundary-Detection-for-Object-Centric-Temporal-Action-Segmentation" class="headerlink" title="OTAS: Unsupervised Boundary Detection for Object-Centric Temporal Action Segmentation"></a>OTAS: Unsupervised Boundary Detection for Object-Centric Temporal Action Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06276">http://arxiv.org/abs/2309.06276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuerong Li, Zhengrong Xue, Huazhe Xu</li>
<li>for: 本研究旨在提高视觉 temporal action segmentation 的精度和效率，通过发现 global visual descriptors 中的剧烈变化。</li>
<li>methods: 本研究提出了一种不需要监督的 Object-centric Temporal Action Segmentation (OTAS) 框架，包括自动提取 global 和 local feature 模块以及一个综合Feature fusion 模块，用于检测行为分割的精度。</li>
<li>results: 对比之前的状态对抗方法，OTAS 在我们建议的 F1 Score 上提高了41%的平均值，并且在用户研究中还能够超越人工标注。此外，OTAS 具有实时推理的能力。<details>
<summary>Abstract</summary>
Temporal action segmentation is typically achieved by discovering the dramatic variances in global visual descriptors. In this paper, we explore the merits of local features by proposing the unsupervised framework of Object-centric Temporal Action Segmentation (OTAS). Broadly speaking, OTAS consists of self-supervised global and local feature extraction modules as well as a boundary selection module that fuses the features and detects salient boundaries for action segmentation. As a second contribution, we discuss the pros and cons of existing frame-level and boundary-level evaluation metrics. Through extensive experiments, we find OTAS is superior to the previous state-of-the-art method by $41\%$ on average in terms of our recommended F1 score. Surprisingly, OTAS even outperforms the ground-truth human annotations in the user study. Moreover, OTAS is efficient enough to allow real-time inference.
</details>
<details>
<summary>摘要</summary>
通常情况下，时间动作分割通过发现全局视觉特征的异常变化来实现。在这篇论文中，我们探讨了本地特征的优势，并提出了无监督的对象中心时间动作分割（OTAS）框架。OTAS包括自我监督全局和本地特征提取模块以及边界选择模块，这些模块共同协同做出动作分割。作为第二个贡献，我们评估了现有帧级和边界级评价指标的优缺点。经过广泛的实验，我们发现OTAS在我们建议的F1分数上比前一代方法提高41%的平均值。更 surprisngly，OTAS甚至超过了用户研究中的人工标注。此外，OTAS具有实时推理的能力。
</details></li>
</ul>
<hr>
<h2 id="Modality-Unifying-Network-for-Visible-Infrared-Person-Re-Identification"><a href="#Modality-Unifying-Network-for-Visible-Infrared-Person-Re-Identification" class="headerlink" title="Modality Unifying Network for Visible-Infrared Person Re-Identification"></a>Modality Unifying Network for Visible-Infrared Person Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06262">http://arxiv.org/abs/2309.06262</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Yu, Xu Cheng, Wei Peng, Weihao Liu, Guoying Zhao</li>
<li>for: 提高可见光和无可见光人识别任务的性能，增强模态之间的共同特征表示。</li>
<li>methods: 提出了一种新的模态统一网络（MUN），通过将提posed的跨模态学习器和内部模态学习器结合在一起，可以动态模型模态特征和人识别特征，从而减少模态之间和内部模态的差异。</li>
<li>results: 对多个公共数据集进行了广泛的实验，结果表明，提出的方法可以在可见光和无可见光人识别任务中显著超越当前状态的方法。<details>
<summary>Abstract</summary>
Visible-infrared person re-identification (VI-ReID) is a challenging task due to large cross-modality discrepancies and intra-class variations. Existing methods mainly focus on learning modality-shared representations by embedding different modalities into the same feature space. As a result, the learned feature emphasizes the common patterns across modalities while suppressing modality-specific and identity-aware information that is valuable for Re-ID. To address these issues, we propose a novel Modality Unifying Network (MUN) to explore a robust auxiliary modality for VI-ReID. First, the auxiliary modality is generated by combining the proposed cross-modality learner and intra-modality learner, which can dynamically model the modality-specific and modality-shared representations to alleviate both cross-modality and intra-modality variations. Second, by aligning identity centres across the three modalities, an identity alignment loss function is proposed to discover the discriminative feature representations. Third, a modality alignment loss is introduced to consistently reduce the distribution distance of visible and infrared images by modality prototype modeling. Extensive experiments on multiple public datasets demonstrate that the proposed method surpasses the current state-of-the-art methods by a significant margin.
</details>
<details>
<summary>摘要</summary>
visible-infrared人识别（VI-ReID）是一个具有大量交叉模式差异和内类变化的挑战任务。现有方法主要集中于学习共同特征空间中的模式共享表示。这使得学习的特征强调共同模式 across modalities 而忽略模式特定和身份意识的信息，这些信息对于 Re-ID 是有价值的。为解决这些问题，我们提出了一种新的 Modality Unifying Network（MUN），以探索一种robust的辅助模式 для VI-ReID。首先，辅助模式是通过我们提出的交叉模式学习器和内模式学习器组合生成的，这些学习器可以动态模型模式特定和共同模式，从而缓解交叉模式和内模式变化。其次，通过将身份中心对三个模式进行对应，我们提出了一个身份对齐loss函数，以发现特征表示。最后，我们引入了一个模式对齐损失，以均衡可见和红外图像的分布距离，通过模式prototype模型。我们在多个公共数据集上进行了广泛的实验，结果表明，我们的方法在与当前状态艺术方法相比，具有显著的超越。
</details></li>
</ul>
<hr>
<h2 id="Use-neural-networks-to-recognize-students’-handwritten-letters-and-incorrect-symbols"><a href="#Use-neural-networks-to-recognize-students’-handwritten-letters-and-incorrect-symbols" class="headerlink" title="Use neural networks to recognize students’ handwritten letters and incorrect symbols"></a>Use neural networks to recognize students’ handwritten letters and incorrect symbols</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06221">http://arxiv.org/abs/2309.06221</a></li>
<li>repo_url: None</li>
<li>paper_authors: JiaJun Zhu, Zichuan Yang, Binjie Hong, Jiacheng Song, Jiwei Wang, Tianhao Chen, Shuilan Yang, Zixun Lan, Fei Ma</li>
<li>for: 这篇论文是为了自动纠正学生多选题答案而写的。</li>
<li>methods: 该论文使用了图像多类别化技术，设置了五种分类，包括四种可能正确的选项和一种其他错误写入选项。</li>
<li>results: 该论文通过使用图像多类别化技术，能够准确地纠正学生的多选题答案。<details>
<summary>Abstract</summary>
Correcting students' multiple-choice answers is a repetitive and mechanical task that can be considered an image multi-classification task. Assuming possible options are 'abcd' and the correct option is one of the four, some students may write incorrect symbols or options that do not exist. In this paper, five classifications were set up - four for possible correct options and one for other incorrect writing. This approach takes into account the possibility of non-standard writing options.
</details>
<details>
<summary>摘要</summary>
更正学生的多项选择答案是一项 repetitive 和机械化的任务，可以被视为一种图像多类别化任务。假设可能的选项是 'abcdef'，而正确的选项是其中之一，一些学生可能写入错误的符号或不存在的选项。在这篇论文中，设置了五个分类 - 四个可能正确的选项和一个其他错误写入。这种方法考虑了非标准写入选项的可能性。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="SGFeat-Salient-Geometric-Feature-for-Point-Cloud-Registration"><a href="#SGFeat-Salient-Geometric-Feature-for-Point-Cloud-Registration" class="headerlink" title="SGFeat: Salient Geometric Feature for Point Cloud Registration"></a>SGFeat: Salient Geometric Feature for Point Cloud Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06207">http://arxiv.org/abs/2309.06207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qianliang Wu, Yaqing Ding, Lei Luo, Chuanwei Zhou, Jin Xie, Jian Yang</li>
<li>for: 本研究的目的是提出一种新的点云注册框架，以解决现有方法在面对精度和稳定性方面存在挑战。</li>
<li>methods: 该框架包括几种新的技术，包括一个具有semantic-aware的几何编码器，可以减少patch层级的匹配歧义，以及一个新型的转换器，可以编码高阶（HO）几何特征，以便在全局高阶几何含义上寻找重要的精roit点。</li>
<li>results: 在3DMatch&#x2F;3DLoMatch和KITTI等知名数据集上进行的实验表明，该方法在精度和稳定性方面具有显著的优势，证明了该方法的效iveness。<details>
<summary>Abstract</summary>
Point Cloud Registration (PCR) is a critical and challenging task in computer vision. One of the primary difficulties in PCR is identifying salient and meaningful points that exhibit consistent semantic and geometric properties across different scans. Previous methods have encountered challenges with ambiguous matching due to the similarity among patch blocks throughout the entire point cloud and the lack of consideration for efficient global geometric consistency. To address these issues, we propose a new framework that includes several novel techniques. Firstly, we introduce a semantic-aware geometric encoder that combines object-level and patch-level semantic information. This encoder significantly improves registration recall by reducing ambiguity in patch-level superpoint matching. Additionally, we incorporate a prior knowledge approach that utilizes an intrinsic shape signature to identify salient points. This enables us to extract the most salient super points and meaningful dense points in the scene. Secondly, we introduce an innovative transformer that encodes High-Order (HO) geometric features. These features are crucial for identifying salient points within initial overlap regions while considering global high-order geometric consistency. To optimize this high-order transformer further, we introduce an anchor node selection strategy. By encoding inter-frame triangle or polyhedron consistency features based on these anchor nodes, we can effectively learn high-order geometric features of salient super points. These high-order features are then propagated to dense points and utilized by a Sinkhorn matching module to identify key correspondences for successful registration. In our experiments conducted on well-known datasets such as 3DMatch/3DLoMatch and KITTI, our approach has shown promising results, highlighting the effectiveness of our novel method.
</details>
<details>
<summary>摘要</summary>
点云注册（PCR）是计算机视觉中的一项关键和挑战性任务。一个主要的困难在PCR中是在不同扫描中标识符合Semantic和Geometric性质的精彩点。先前的方法在patch块之间的模糊匹配和缺乏全局高级几何一致性导致困难。为解决这些问题，我们提出了一个新的框架，包括多种新技术。首先，我们引入了一个Semantic-aware geometric encoder，该encoder结合物体层和patch层Semantic信息。这使得精彩点匹配减少了模糊性，提高了注册回归率。其次，我们采用了一种基于内在形状签名的高级知识方法，以便在场景中提取最精彩的超点和有意义的稠密点。其次，我们引入了一种创新的变换器，用于编码高级几何特征。这些特征在初始重叠区域内识别精彩点，同时考虑全局高级几何一致性。为了进一步优化这种高级变换器，我们引入了一种锚节选择策略。通过基于锚节的inter-frame三角形或多面体一致性特征编码，我们可以有效地学习高级几何特征。这些高级特征然后被传递到稠密点，并由Sinkhorn匹配模块进行成功注册。在我们对3DMatch/3DLoMatch和KITTI等知名数据集进行的实验中，我们的方法表现出了扎实的效果，证明了我们的新方法的效果。
</details></li>
</ul>
<hr>
<h2 id="Fast-Sparse-PCA-via-Positive-Semidefinite-Projection-for-Unsupervised-Feature-Selection"><a href="#Fast-Sparse-PCA-via-Positive-Semidefinite-Projection-for-Unsupervised-Feature-Selection" class="headerlink" title="Fast Sparse PCA via Positive Semidefinite Projection for Unsupervised Feature Selection"></a>Fast Sparse PCA via Positive Semidefinite Projection for Unsupervised Feature Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06202">http://arxiv.org/abs/2309.06202</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zjj20212035/spca-psd">https://github.com/zjj20212035/spca-psd</a></li>
<li>paper_authors: Junjing Zheng, Xinyu Zhang, Yongxiang Liu, Weidong Jiang, Kai Huo, Li Liu</li>
<li>for: 本研究旨在提出一种基于POSitive Semidefinite（PSD）矩阵的半监督特征选择方法，用于非监督特征选择领域。</li>
<li>methods: 本研究使用了原始SPCA方法，并对其进行了减小到一个半监督模型。在这个模型中，重建矩阵被视为优化变量，并且添加了PSD约束，以保证重建矩阵的正定性。</li>
<li>results: 本研究提出了一种基于PSD约束的半监督特征选择方法，并提供了一种加速方法和一种参数设置策略。经过实验 validate that the proposed method is effective and efficient on synthetic and real-world datasets.<details>
<summary>Abstract</summary>
In the field of unsupervised feature selection, sparse principal component analysis (SPCA) methods have attracted more and more attention recently. Compared to spectral-based methods, SPCA methods don't rely on the construction of a similarity matrix and show better feature selection ability on real-world data. The original SPCA formulates a nonconvex optimization problem. Existing convex SPCA methods reformulate SPCA as a convex model by regarding the reconstruction matrix as an optimization variable. However, they are lack of constraints equivalent to the orthogonality restriction in SPCA, leading to larger solution space. In this paper, it's proved that the optimal solution to a convex SPCA model falls onto the Positive Semidefinite (PSD) cone. A standard convex SPCA-based model with PSD constraint for unsupervised feature selection is proposed. Further, a two-step fast optimization algorithm via PSD projection is presented to solve the proposed model. Two other existing convex SPCA-based models are also proven to have their solutions optimized on the PSD cone in this paper. Therefore, the PSD versions of these two models are proposed to accelerate their convergence as well. We also provide a regularization parameter setting strategy for our proposed method. Experiments on synthetic and real-world datasets demonstrate the effectiveness and efficiency of the proposed methods.
</details>
<details>
<summary>摘要</summary>
在无监督特征选择领域，贪婪原始Component分析（SPCA）方法在最近吸引了越来越多的注意。相比spectral-based方法，SPCA方法不需要建立一个相似矩阵，在实际数据上表现更好的特征选择能力。原始SPCA方法转化为一个非凸优化问题。现有的凸SPCA方法将SPCA转化为一个凸模型，但是它们缺乏与SPCA中的正交约束相当的约束，导致更大的解空间。在这篇论文中，证明了凸SPCA模型的优解在Positive Semidefinite（PSD）树上。我们提出了一种标准的凸SPCA基于PSD约束的模型，并提供了一种快速优化算法via PSD投影来解决该模型。此外，我们还证明了其他两种现有的凸SPCA基于模型在PSD树上有优解。因此，我们提出了PSD版本的这两个模型，以加速它们的收敛。我们还提供了我们提posed方法的正则化参数设定策略。实验表明，我们的提posed方法在synthetic和实际数据上具有良好的效果和效率。
</details></li>
</ul>
<hr>
<h2 id="Computer-Vision-Pipeline-for-Automated-Antarctic-Krill-Analysis"><a href="#Computer-Vision-Pipeline-for-Automated-Antarctic-Krill-Analysis" class="headerlink" title="Computer Vision Pipeline for Automated Antarctic Krill Analysis"></a>Computer Vision Pipeline for Automated Antarctic Krill Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06188">http://arxiv.org/abs/2309.06188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mazvydas Gudelis, Michal Mackiewicz, Julie Bremner, Sophie Fielding</li>
<li>for: 这项研究用于估计南极 krill 生物质和评估当前环境对这一关键marine food chain Component的影响。</li>
<li>methods: 研究人员使用了网络图像注释工具和深度学习图像分类和回归模型来自动化数据采集和分析过程。</li>
<li>results: 研究人员在krill实例分割方面获得了77.28%的AP分数，并可以分别估计krill的成熟阶段和长度，并且Length error为1.96 mm。<details>
<summary>Abstract</summary>
British Antarctic Survey (BAS) researchers launch annual expeditions to the Antarctic in order to estimate Antarctic Krill biomass and assess the change from previous years. These comparisons provide insight into the effects of the current environment on this key component of the marine food chain. In this work we have developed tools for automating the data collection and analysis process, using web-based image annotation tools and deep learning image classification and regression models. We achieve highly accurate krill instance segmentation results with an average 77.28% AP score, as well as separate maturity stage and length estimation of krill specimens with 62.99% accuracy and a 1.96 mm length error respectively.
</details>
<details>
<summary>摘要</summary>
英国南极调查（BAS）研究人员每年到南极进行调查，以估计南极 krill 生物质量和评估过去年的变化。这些比较提供有关当前环境对这一关键海洋食物链成分的影响的见解。在这个工作中，我们已经开发了自动数据收集和分析工具，使用网络上的图像标注工具和深度学习图像分类和回归模型。我们得到了高度精确的 krill 实体分 segmentation 结果，具体的话是平均77.28% AP 分数，以及分类 krill 虫的成熟阶段和长度估计，具体的话是62.99% 的准确率和1.96 mm 的长度误差。
</details></li>
</ul>
<hr>
<h2 id="Dual-Path-Temporal-Map-Optimization-for-Make-up-Temporal-Video-Grounding"><a href="#Dual-Path-Temporal-Map-Optimization-for-Make-up-Temporal-Video-Grounding" class="headerlink" title="Dual-Path Temporal Map Optimization for Make-up Temporal Video Grounding"></a>Dual-Path Temporal Map Optimization for Make-up Temporal Video Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06176">http://arxiv.org/abs/2309.06176</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxiu Li, Kun Li, Jia Li, Guoliang Chen, Dan Guo, Meng Wang</li>
<li>for: 本研究 targets 化妆活动的视频地理Localization, aiming to accurately locate the target video segment that is semantically related to a sentence describing a make-up activity, given a long video.</li>
<li>methods: 该 paper proposes a novel framework named Dual-Path Temporal Map Optimization Network (DPTMO), which utilizes both query-agnostic and query-guided features to construct two proposal sets and uses specific evaluation methods for the two sets. The dual-path structure mines more semantic information in make-up videos and distinguishes fine-grained actions well.</li>
<li>results:  compared with existing methods, the proposed DPTMO framework demonstrates superior performance in fine-grained semantic comprehension, as shown in comprehensive experiments on the YouMakeup dataset.<details>
<summary>Abstract</summary>
Make-up temporal video grounding (MTVG) aims to localize the target video segment which is semantically related to a sentence describing a make-up activity, given a long video. Compared with the general video grounding task, MTVG focuses on meticulous actions and changes on the face. The make-up instruction step, usually involving detailed differences in products and facial areas, is more fine-grained than general activities (e.g, cooking activity and furniture assembly). Thus, existing general approaches cannot locate the target activity effectually. More specifically, existing proposal generation modules are not yet fully developed in providing semantic cues for the more fine-grained make-up semantic comprehension. To tackle this issue, we propose an effective proposal-based framework named Dual-Path Temporal Map Optimization Network (DPTMO) to capture fine-grained multimodal semantic details of make-up activities. DPTMO extracts both query-agnostic and query-guided features to construct two proposal sets and uses specific evaluation methods for the two sets. Different from the commonly used single structure in previous methods, our dual-path structure can mine more semantic information in make-up videos and distinguish fine-grained actions well. These two candidate sets represent the cross-modal makeup video-text similarity and multi-modal fusion relationship, complementing each other. Each set corresponds to its respective optimization perspective, and their joint prediction enhances the accuracy of video timestamp prediction. Comprehensive experiments on the YouMakeup dataset demonstrate our proposed dual structure excels in fine-grained semantic comprehension.
</details>
<details>
<summary>摘要</summary>
make-up temporal video grounding (MTVG) 目标是将视频中相关的目标视频段本地化，给定一个长视频。相比通用视频固定任务，MTVG更关注面部细节和变化。make-up instruction step 通常包括细节的产品和面部区域差异，比如制作餐食和家具组装。因此，现有的通用方法无法准确定位目标活动。更 Specifically，现有的提议生成模块没有充分发展出提供semantic cue для更细化的化妆 semantic comprehension。为解决这个问题，我们提出了一种有效的提议基于框架，named Dual-Path Temporal Map Optimization Network (DPTMO)，用于捕捉化妆活动的细化多模式semantic detail。DPTMO提取了both query-agnostic和query-guided特征，并使用特定的评估方法来构建两个提议集。与之前的方法不同，我们的双路结构可以在化妆视频中挖掘更多的semantic information，并且能够区分细化的动作。这两个候选集表示cross-modal makeup video-text similarity和多模式融合关系，互补 Each other。每个集对应了自己的优化视角，并且他们的联合预测可以提高视频时间戳预测的准确性。通过对YouMakeup dataset的全面实验，我们的提议双结构表明其在细化semantic comprehension中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Elucidating-the-solution-space-of-extended-reverse-time-SDE-for-diffusion-models"><a href="#Elucidating-the-solution-space-of-extended-reverse-time-SDE-for-diffusion-models" class="headerlink" title="Elucidating the solution space of extended reverse-time SDE for diffusion models"></a>Elucidating the solution space of extended reverse-time SDE for diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06169">http://arxiv.org/abs/2309.06169</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qinpengcui/er-sde-solver">https://github.com/qinpengcui/er-sde-solver</a></li>
<li>paper_authors: Qinpeng Cui, Xinyi Zhang, Zongqing Lu, Qingmin Liao<br>for:这种论文旨在提高Diffusion Model（DM）的采样速度，使其在不同的生成模型任务中表现更加突出。methods:这篇论文使用了扩展的反时域SDE（ER SDE）来表述采样过程，并提出了精确解和高级别approx解方法。results:实验结果表明，ER SDE Solvers可以减少采样时间，达到过去无法达到的水平，例如在ImageNet 64×64 dataset上取得2.24 FID在50次评估中，和3.45 FID在20次评估中。<details>
<summary>Abstract</summary>
Diffusion models (DMs) demonstrate potent image generation capabilities in various generative modeling tasks. Nevertheless, their primary limitation lies in slow sampling speed, requiring hundreds or thousands of sequential function evaluations through large neural networks to generate high-quality images. Sampling from DMs can be seen as solving corresponding stochastic differential equations (SDEs) or ordinary differential equations (ODEs). In this work, we formulate the sampling process as an extended reverse-time SDE (ER SDE), unifying prior explorations into ODEs and SDEs. Leveraging the semi-linear structure of ER SDE solutions, we offer exact solutions and arbitrarily high-order approximate solutions for VP SDE and VE SDE, respectively. Based on the solution space of the ER SDE, we yield mathematical insights elucidating the superior performance of ODE solvers over SDE solvers in terms of fast sampling. Additionally, we unveil that VP SDE solvers stand on par with their VE SDE counterparts. Finally, we devise fast and training-free samplers, ER-SDE Solvers, elevating the efficiency of stochastic samplers to unprecedented levels. Experimental results demonstrate achieving 3.45 FID in 20 function evaluations and 2.24 FID in 50 function evaluations on the ImageNet 64$\times$64 dataset.
</details>
<details>
<summary>摘要</summary>
Diffusion models (DMs) 表现出了杰出的图像生成能力在各种生成模型任务中。然而，它们的主要限制在于慢的采样速度，需要数百或千次的顺序函数评估通过大 neural network 来生成高质量图像。从 DMs 的采样角度来看，可以看作解决对应的随机 diffeomorphism equation (SDE) 或 ordinary differential equation (ODE)。在这种工作中，我们将采样过程推广为延长的反时间 SDE (ER SDE)，整合先前的探索 ODE 和 SDE 中。利用 ER SDE 解的半线性结构，我们提供了精确解和高阶近似解 для VP SDE 和 VE SDE，分别。基于 ER SDE 的解空间，我们获得了数学意义，解释了 ODE 解算法在采样速度方面的超越性。此外，我们发现 VP SDE 解算法与其对应的 VE SDE 解算法一样强。最后，我们设计了快速和无需训练的采样器，ER-SDE Solvers，使得随机采样的效率提升到了历史最高水平。实验结果表明在 ImageNet 64$\times$64 数据集上，我们可以在 20 次函数评估中达到 3.45 FID，并在 50 次函数评估中达到 2.24 FID。
</details></li>
</ul>
<hr>
<h2 id="Certified-Robust-Models-with-Slack-Control-and-Large-Lipschitz-Constants"><a href="#Certified-Robust-Models-with-Slack-Control-and-Large-Lipschitz-Constants" class="headerlink" title="Certified Robust Models with Slack Control and Large Lipschitz Constants"></a>Certified Robust Models with Slack Control and Large Lipschitz Constants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06166">http://arxiv.org/abs/2309.06166</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlosch/cll">https://github.com/mlosch/cll</a></li>
<li>paper_authors: Max Losch, David Stutz, Bernt Schiele, Mario Fritz</li>
<li>for: 提高预测精度和证明鲁棒性</li>
<li>methods: 利用Calibrated Lipschitz-Margin Loss（CLL）来提高鲁棒性和预测精度</li>
<li>results: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上，模型consistently outperform其他损失函数，并在CIFAR-100和Tiny-ImageNet上提高了状态之最佳 deterministic $L_2$ 鲁棒精度。<details>
<summary>Abstract</summary>
Despite recent success, state-of-the-art learning-based models remain highly vulnerable to input changes such as adversarial examples. In order to obtain certifiable robustness against such perturbations, recent work considers Lipschitz-based regularizers or constraints while at the same time increasing prediction margin. Unfortunately, this comes at the cost of significantly decreased accuracy. In this paper, we propose a Calibrated Lipschitz-Margin Loss (CLL) that addresses this issue and improves certified robustness by tackling two problems: Firstly, commonly used margin losses do not adjust the penalties to the shrinking output distribution; caused by minimizing the Lipschitz constant $K$. Secondly, and most importantly, we observe that minimization of $K$ can lead to overly smooth decision functions. This limits the model's complexity and thus reduces accuracy. Our CLL addresses these issues by explicitly calibrating the loss w.r.t. margin and Lipschitz constant, thereby establishing full control over slack and improving robustness certificates even with larger Lipschitz constants. On CIFAR-10, CIFAR-100 and Tiny-ImageNet, our models consistently outperform losses that leave the constant unattended. On CIFAR-100 and Tiny-ImageNet, CLL improves upon state-of-the-art deterministic $L_2$ robust accuracies. In contrast to current trends, we unlock potential of much smaller models without $K=1$ constraints.
</details>
<details>
<summary>摘要</summary>
Despite recent success, state-of-the-art learning-based models remain highly vulnerable to input changes such as adversarial examples. In order to obtain certifiable robustness against such perturbations, recent work considers Lipschitz-based regularizers or constraints while at the same time increasing prediction margin. Unfortunately, this comes at the cost of significantly decreased accuracy. In this paper, we propose a Calibrated Lipschitz-Margin Loss (CLL) that addresses this issue and improves certified robustness by tackling two problems: Firstly, commonly used margin losses do not adjust the penalties to the shrinking output distribution; caused by minimizing the Lipschitz constant $K$. Secondly, and most importantly, we observe that minimization of $K$ can lead to overly smooth decision functions. This limits the model's complexity and thus reduces accuracy. Our CLL addresses these issues by explicitly calibrating the loss w.r.t. margin and Lipschitz constant, thereby establishing full control over slack and improving robustness certificates even with larger Lipschitz constants. On CIFAR-10, CIFAR-100 and Tiny-ImageNet, our models consistently outperform losses that leave the constant unattended. On CIFAR-100 and Tiny-ImageNet, CLL improves upon state-of-the-art deterministic $L_2$ robust accuracies. In contrast to current trends, we unlock potential of much smaller models without $K=1$ constraints.Here's the translation in Traditional Chinese:虽然最近的成果优秀，但现代学习型模型仍然具有对输入更改的高度敏感性，如攻击例子。以获取可认证的防护性，现在的工作会考虑使用Liп希茨基于的正则化或限制，同时增加预测margin。然而，这会导致减少精度。在这篇论文中，我们提出了单位Lipschitz-Margin损失函数（CLL），以解决这个问题，并提高认证性质证明。我们的CLL通过调整损失函数对margin和Lipschitz常数的控制，以确保全面控制 sobre slack，并提高防护性证明，即使Lipschitz常数较大。在CIFAR-10、CIFAR-100和Tiny-ImageNet上，我们的模型一致地超过不考虑K常数的损失函数。在CIFAR-100和Tiny-ImageNet上，CLL超过了现有的决定性$L_2$防护精度。相比于现有的趋势，我们解锁了许多小型模型的潜力，不需要$K=1$的限制。
</details></li>
</ul>
<hr>
<h2 id="Active-Label-Refinement-for-Semantic-Segmentation-of-Satellite-Images"><a href="#Active-Label-Refinement-for-Semantic-Segmentation-of-Satellite-Images" class="headerlink" title="Active Label Refinement for Semantic Segmentation of Satellite Images"></a>Active Label Refinement for Semantic Segmentation of Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06159">http://arxiv.org/abs/2309.06159</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuan Pham Minh, Jayan Wijesingha, Daniel Kottke, Marek Herde, Denis Huseljic, Bernhard Sick, Michael Wachendorf, Thomas Esch</li>
<li>for: 本研究使用卫星图像semantic segmentation来理解和利用地球表面。</li>
<li>methods: 本研究提议使用低成本方法，如众包或预训练网络，来标注卫星图像。然后，使用活动学习策略来成本效果地更正标注。</li>
<li>results: 我们通过使用印度بengooru的卫星图像，发现活动标注更新可以提高semantic segmentation网络的性能。<details>
<summary>Abstract</summary>
Remote sensing through semantic segmentation of satellite images contributes to the understanding and utilisation of the earth's surface. For this purpose, semantic segmentation networks are typically trained on large sets of labelled satellite images. However, obtaining expert labels for these images is costly. Therefore, we propose to rely on a low-cost approach, e.g. crowdsourcing or pretrained networks, to label the images in the first step. Since these initial labels are partially erroneous, we use active learning strategies to cost-efficiently refine the labels in the second step. We evaluate the active learning strategies using satellite images of Bengaluru in India, labelled with land cover and land use labels. Our experimental results suggest that an active label refinement to improve the semantic segmentation network's performance is beneficial.
</details>
<details>
<summary>摘要</summary>
通过卫星图像 semantics 分割来理解和利用地球表面，这需要 semantic 分割网络在大量标注卫星图像上进行训练。然而，获得专业标注是成本高昂的。因此，我们提议使用低成本方法，如招募或预训练网络，来标注图像。由于这些初始标注有误，我们使用活动学习策略来经济性地修正标注。我们通过印度本革的孟买诺亚卫星图像进行实验，发现活动标注修正可以提高 semantic 分割网络的性能。
</details></li>
</ul>
<hr>
<h2 id="Improving-Generalization-Capability-of-Deep-Learning-Based-Nuclei-Instance-Segmentation-by-Non-deterministic-Train-Time-and-Deterministic-Test-Time-Stain-Normalization"><a href="#Improving-Generalization-Capability-of-Deep-Learning-Based-Nuclei-Instance-Segmentation-by-Non-deterministic-Train-Time-and-Deterministic-Test-Time-Stain-Normalization" class="headerlink" title="Improving Generalization Capability of Deep Learning-Based Nuclei Instance Segmentation by Non-deterministic Train Time and Deterministic Test Time Stain Normalization"></a>Improving Generalization Capability of Deep Learning-Based Nuclei Instance Segmentation by Non-deterministic Train Time and Deterministic Test Time Stain Normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06143">http://arxiv.org/abs/2309.06143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirreza Mahbod, Georg Dorffner, Isabella Ellinger, Ramona Woitek, Sepideh Hatamikia</li>
<li>for: This paper aims to improve the generalization capability of a deep learning-based automatic segmentation approach for nuclei instance segmentation in digital histopathological images.</li>
<li>methods: The proposed method incorporates non-deterministic train time and deterministic test time stain normalization, and uses one single training set to evaluate the segmentation performance on seven test datasets.</li>
<li>results: The proposed method provides up to 5.77%, 5.36%, and 5.27% better performance in segmenting nuclei based on Dice score, aggregated Jaccard index, and panoptic quality score, respectively, compared to the baseline segmentation model.Here’s the Chinese translation of the three key points:</li>
<li>for: 这篇论文目的是提高深度学习基于自动分割模型的总化能力，用于核实体分割在数字 histopathological 图像中。</li>
<li>methods: 提议的方法包括在训练时使用不确定的时间和测试时使用确定的时间杂化病理样本Normalization，并使用一个单一的训练集来评估分割性能在七个测试集中。</li>
<li>results: 提议的方法在分割核实体方面提供了5.77%, 5.36%, 和5.27%的提升，根据 dice 分数、总和 Jacard 指标和精确性分数。<details>
<summary>Abstract</summary>
With the advent of digital pathology and microscopic systems that can scan and save whole slide histological images automatically, there is a growing trend to use computerized methods to analyze acquired images. Among different histopathological image analysis tasks, nuclei instance segmentation plays a fundamental role in a wide range of clinical and research applications. While many semi- and fully-automatic computerized methods have been proposed for nuclei instance segmentation, deep learning (DL)-based approaches have been shown to deliver the best performances. However, the performance of such approaches usually degrades when tested on unseen datasets.   In this work, we propose a novel approach to improve the generalization capability of a DL-based automatic segmentation approach. Besides utilizing one of the state-of-the-art DL-based models as a baseline, our method incorporates non-deterministic train time and deterministic test time stain normalization. We trained the model with one single training set and evaluated its segmentation performance on seven test datasets. Our results show that the proposed method provides up to 5.77%, 5.36%, and 5.27% better performance in segmenting nuclei based on Dice score, aggregated Jaccard index, and panoptic quality score, respectively, compared to the baseline segmentation model.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose a novel approach to improve the generalization capability of a DL-based automatic segmentation method. Our approach incorporates non-deterministic train time and deterministic test time stain normalization. We trained the model with a single training set and evaluated its segmentation performance on seven test datasets. Our results show that the proposed method provides up to 5.77%, 5.36%, and 5.27% better performance in segmenting nuclei based on Dice score, aggregated Jaccard index, and panoptic quality score, respectively, compared to the baseline segmentation model.
</details></li>
</ul>
<hr>
<h2 id="Towards-Reliable-Domain-Generalization-A-New-Dataset-and-Evaluations"><a href="#Towards-Reliable-Domain-Generalization-A-New-Dataset-and-Evaluations" class="headerlink" title="Towards Reliable Domain Generalization: A New Dataset and Evaluations"></a>Towards Reliable Domain Generalization: A New Dataset and Evaluations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06142">http://arxiv.org/abs/2309.06142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiao Zhang, Xu-Yao Zhang, Cheng-Lin Liu</li>
<li>for: 提高手写中文字识别器的鲁棒性，推广领域特征学的研究领域。</li>
<li>methods:  eighteen种领域特征学方法在PaHCC dataset上的评估，以及一种动态领域特征学设定的研究。</li>
<li>results: 现有方法在PaHCC dataset上的性能不满足，只有离开一个领域的协议是可靠的。我们的 dataset 和评估将为领域特征学社区带来新的视角，推动更大的进步。<details>
<summary>Abstract</summary>
There are ubiquitous distribution shifts in the real world. However, deep neural networks (DNNs) are easily biased towards the training set, which causes severe performance degradation when they receive out-of-distribution data. Many methods are studied to train models that generalize under various distribution shifts in the literature of domain generalization (DG). However, the recent DomainBed and WILDS benchmarks challenged the effectiveness of these methods. Aiming at the problems in the existing research, we propose a new domain generalization task for handwritten Chinese character recognition (HCCR) to enrich the application scenarios of DG method research. We evaluate eighteen DG methods on the proposed PaHCC (Printed and Handwritten Chinese Characters) dataset and show that the performance of existing methods on this dataset is still unsatisfactory. Besides, under a designed dynamic DG setting, we reveal more properties of DG methods and argue that only the leave-one-domain-out protocol is unreliable. We advocate that researchers in the DG community refer to dynamic performance of methods for more comprehensive and reliable evaluation. Our dataset and evaluations bring new perspectives to the community for more substantial progress. We will make our dataset public with the article published to facilitate the study of domain generalization.
</details>
<details>
<summary>摘要</summary>
“世界上存在普遍的分布Shift。然而，深度神经网络（DNNs）容易受到训练集的偏袋影响，导致接收不同分布的数据时表现下降。许多领域通用化（Domain Generalization，DG）的方法已经被研究，但是最近的DomainBed和WILDS benchmarks表明这些方法的有效性存在问题。为了解决现有研究中的问题，我们提出了一个新的领域通用化任务：手写中文字识别（HCCR），以推广DG方法的应用场景。我们在提出的PaHCC（印刷和手写中文字）数据集上评估了 eighteen 个 DG 方法的性能，并发现现有方法在这个数据集上的性能仍然不满足。此外，在我们设计的动态 DG 设定下，我们发现了更多的 DG 方法的性能特性，并认为只有离开一个领域的协议是不可靠的。我们建议研究人员在 DG 社区中参考方法的动态性能进行更全面和可靠的评估。我们将在发表文章时公开我们的数据集，以便研究领域通用化的人们进行更进一步的研究。”
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Visual-Prompt-Tuning-for-Parameter-Efficient-Transfer-Learning"><a href="#Dynamic-Visual-Prompt-Tuning-for-Parameter-Efficient-Transfer-Learning" class="headerlink" title="Dynamic Visual Prompt Tuning for Parameter Efficient Transfer Learning"></a>Dynamic Visual Prompt Tuning for Parameter Efficient Transfer Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06123">http://arxiv.org/abs/2309.06123</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunqing Ruan, Hongjian Wang</li>
<li>for: 这个研究旨在发展具有大规模预训模型的实时转移学习方法，以减少储存和计算成本。</li>
<li>methods: 我们提出了一个动态类别推导框架（DVPT），可以生成每个图像的动态具体化图示。这样可以捕捉每个图像的唯一视觉特征，并且更适合下游视觉任务。我们还设计了一个元件网络模组（Meta-Net），可以根据每个图像生成可读的推导。</li>
<li>results: 实验结果显示，DVPT在许多下游识别任务上表现更好，甚至超过了完整的精确调整方法。另外，DVPT可以保持高度的参数效率，并且在17个中的19个下游任务上表现更好。我们将代码发布 soon。<details>
<summary>Abstract</summary>
Parameter efficient transfer learning (PETL) is an emerging research spot that aims to adapt large-scale pre-trained models to downstream tasks. Recent advances have achieved great success in saving storage and computation costs. However, these methods do not take into account instance-specific visual clues for visual tasks. In this paper, we propose a Dynamic Visual Prompt Tuning framework (DVPT), which can generate a dynamic instance-wise token for each image. In this way, it can capture the unique visual feature of each image, which can be more suitable for downstream visual tasks. We designed a Meta-Net module that can generate learnable prompts based on each image, thereby capturing dynamic instance-wise visual features. Extensive experiments on a wide range of downstream recognition tasks show that DVPT achieves superior performance than other PETL methods. More importantly, DVPT even outperforms full fine-tuning on 17 out of 19 downstream tasks while maintaining high parameter efficiency. Our code will be released soon.
</details>
<details>
<summary>摘要</summary>
Parameter efficient transfer learning (PETL) 是一个快速发展的研究领域，旨在适应大规模预训练模型下推断任务。近期的进展有效地降低了存储和计算成本。然而，这些方法没有考虑每个图像的特定视觉特征。在这篇论文中，我们提出了一种动态视觉提示调整框架（DVPT），可以生成每个图像的动态实例化 tokens。这种方法可以捕捉每个图像独特的视觉特征，更适合下游视觉任务。我们设计了一个 Meta-Net 模块，可以基于每个图像生成学习的提示，以捕捉动态实例化视觉特征。我们进行了广泛的实验，证明 DVPT 在多种下游认知任务上超过其他 PETL 方法表现。此外，DVPT 甚至超过了全部精细调整，在 17 个下游任务中表现优于其他方法。我们即将发布代码。
</details></li>
</ul>
<hr>
<h2 id="C-RITNet-Set-Infrared-and-Visible-Image-Fusion-Free-from-Complementary-Information-Mining"><a href="#C-RITNet-Set-Infrared-and-Visible-Image-Fusion-Free-from-Complementary-Information-Mining" class="headerlink" title="C-RITNet: Set Infrared and Visible Image Fusion Free from Complementary Information Mining"></a>C-RITNet: Set Infrared and Visible Image Fusion Free from Complementary Information Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06118">http://arxiv.org/abs/2309.06118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yafei Zhang, Keying Du, Huafeng Li, Zhengtao Yu, Yu Liu</li>
<li>for: 本研究的目的是提出一种新的图像融合方法，以提高图像融合的质量和精度。</li>
<li>methods: 本研究使用了一种名为Complementary-Redundant Information Transfer Network（C-RITNet）的新网络模型，该模型可以有效地传输两个模式之间的相似和不同的信息，从而生成高质量的融合图像。</li>
<li>results: 对比于传统图像融合方法，C-RITNet可以更好地保留图像的细节和结构信息，同时也可以提高图像的明暗ratio和对比度。这意味着C-RITNet可以生成更加自然和真实的融合图像。<details>
<summary>Abstract</summary>
Infrared and visible image fusion (IVIF) aims to extract and integrate the complementary information in two different modalities to generate high-quality fused images with salient targets and abundant texture details. However, current image fusion methods go to great lengths to excavate complementary features, which is generally achieved through two efforts. On the one hand, the feature extraction network is expected to have excellent performance in extracting complementary information. On the other hand, complex fusion strategies are often designed to aggregate the complementary information. In other words, enabling the network to perceive and extract complementary information is extremely challenging. Complicated fusion strategies, while effective, still run the risk of losing weak edge details. To this end, this paper rethinks the IVIF outside the box, proposing a complementary-redundant information transfer network (C-RITNet). It reasonably transfers complementary information into redundant one, which integrates both the shared and complementary features from two modalities. Hence, the proposed method is able to alleviate the challenges posed by the complementary information extraction and reduce the reliance on sophisticated fusion strategies. Specifically, to skillfully sidestep aggregating complementary information in IVIF, we first design the mutual information transfer (MIT) module to mutually represent features from two modalities, roughly transferring complementary information into redundant one. Then, a redundant information acquisition supervised by source image (RIASSI) module is devised to further ensure the complementary-redundant information transfer after MIT. Meanwhile, we also propose a structure information preservation (SIP) module to guarantee that the edge structure information of the source images can be transferred to the fusion results.
</details>
<details>
<summary>摘要</summary>
infrared和可见图像融合（IVIF）目的是抽取并融合两个不同模式的补充信息，以生成高质量融合图像，具有突出的目标和丰富的текстура细节。然而，当前的图像融合方法通常会努力挖掘补充特征，通常通过两种方法来实现。一方面，特征提取网络应该具有出色的性能，以抽取补充信息。另一方面，复杂的融合策略通常会用于聚合补充信息。也就是说，使网络感受到和抽取补充信息是极其困难的。复杂的融合策略，虽然有效，仍然存在脆弱的边缘细节的风险。为了解决这些问题，本文尝试外部思考IVIF，提出一种补充-重复信息传输网络（C-RITNet）。它有理性地将补充信息转换为重复信息，并将两种模式的共享和补充特征融合在一起。因此，提出的方法可以减轻IVIF中补充信息抽取的挑战，降低复杂的融合策略的依赖。具体来说，为了绕过IVIF中补充信息的聚合，我们首先设计了共享信息传输模块（MIT），以便互相表示两种模式的特征，粗略地将补充信息转换为重复信息。然后，我们设计了源图像领导的重复信息获取模块（RIASSI），以确保补充-重复信息传输后MIT。同时，我们还提出了保持结构信息模块（SIP），以确保源图像的边缘结构信息可以传递到融合结果中。
</details></li>
</ul>
<hr>
<h2 id="HOC-Search-Efficient-CAD-Model-and-Pose-Retrieval-from-RGB-D-Scans"><a href="#HOC-Search-Efficient-CAD-Model-and-Pose-Retrieval-from-RGB-D-Scans" class="headerlink" title="HOC-Search: Efficient CAD Model and Pose Retrieval from RGB-D Scans"></a>HOC-Search: Efficient CAD Model and Pose Retrieval from RGB-D Scans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06107">http://arxiv.org/abs/2309.06107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Ainetter, Sinisa Stekovic, Friedrich Fraundorfer, Vincent Lepetit<br>for: 本文提出了一种自动化和高效的方法，用于从移动RGB-D摄像头捕获场景中的物体和其pose的高质量CAD模型。methods: 本文首先研究了不同的目标函数，用于度量候选CAD模型和可用数据之间的相似性，并发现最佳目标函数是一种”渲染并比较”方法， comparing depth和mask渲染。本文引入了一种快速搜索方法，该方法通过这个目标函数同时 retrieve object category, CAD模型和object pose，给出了一个approximate 3D bounding box。这种方法基于一个搜索树，该树将CAD模型和物体属性，包括物体类别和pose，组织成fast retrieval。results: 本文表明，这种方法可以很好地适应实际情况，与极限搜索相比，提高了10倍至120倍的速度。<details>
<summary>Abstract</summary>
We present an automated and efficient approach for retrieving high-quality CAD models of objects and their poses in a scene captured by a moving RGB-D camera. We first investigate various objective functions to measure similarity between a candidate CAD object model and the available data, and the best objective function appears to be a "render-and-compare" method comparing depth and mask rendering. We thus introduce a fast-search method that approximates an exhaustive search based on this objective function for simultaneously retrieving the object category, a CAD model, and the pose of an object given an approximate 3D bounding box. This method involves a search tree that organizes the CAD models and object properties including object category and pose for fast retrieval and an algorithm inspired by Monte Carlo Tree Search, that efficiently searches this tree. We show that this method retrieves CAD models that fit the real objects very well, with a speed-up factor of 10x to 120x compared to exhaustive search.
</details>
<details>
<summary>摘要</summary>
我们提出了一种自动化和高效的方法，用于从移动RGB-D摄像头捕捉的场景中检索高质量的CAD模型和其姿态。我们首先调查了各种目标函数，用于测量候选CAD对象模型和可用数据之间的相似性，最佳目标函数则是一种“渲染并比较”方法，该方法 Compares the depth and mask rendering of the candidate CAD object model with the available data. We therefore introduce a fast-search method that approximates an exhaustive search based on this objective function, which simultaneously retrieves the object category, a CAD model, and the pose of an object given an approximate 3D bounding box. This method uses a search tree that organizes the CAD models and object properties, including object category and pose, for fast retrieval, and an algorithm inspired by Monte Carlo Tree Search, which efficiently searches this tree. We show that this method retrieves CAD models that fit the real objects very well, with a speed-up factor of 10x to 120x compared to exhaustive search.
</details></li>
</ul>
<hr>
<h2 id="Can-we-predict-the-Most-Replayed-data-of-video-streaming-platforms"><a href="#Can-we-predict-the-Most-Replayed-data-of-video-streaming-platforms" class="headerlink" title="Can we predict the Most Replayed data of video streaming platforms?"></a>Can we predict the Most Replayed data of video streaming platforms?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06102">http://arxiv.org/abs/2309.06102</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ombretta/most-replayed-data">https://github.com/ombretta/most-replayed-data</a></li>
<li>paper_authors: Alessandro Duico, Ombretta Strafforello, Jan van Gemert</li>
<li>for: 预测YouTube视频用户重复观看哪些部分很重要，有多种应用场景，如视频平台上的Targeted advertisement placement和助手视频创作者。</li>
<li>methods: 我们在这项工作中探讨了是否可以预测YouTube视频的最多重播 (MR) 数据。为此，我们筹集了一个大型视频benchmark，即YTMR500 dataset，包含500个YouTube视频的MR数据注解。我们评估了不同复杂度的深度学习 (DL) 模型在我们的dataset上，并进行了广泛的ablation study。</li>
<li>results: 我们的结果显示，虽然只有在Random predictions之上微弱，但所有评估DL模型都超过了人类性能。此外，它们还超过了人类水平的准确率。这表明预测MR数据是一项具有挑战性的任务，可以通过DL的帮助进一步提高。最后，我们认为DL在MR数据预测方面的性能还可以进一步提高，例如通过多Modal learning。我们鼓励研究者使用我们的benchmark dataset进一步调查自动MR数据预测。<details>
<summary>Abstract</summary>
Predicting which specific parts of a video users will replay is important for several applications, including targeted advertisement placement on video platforms and assisting video creators. In this work, we explore whether it is possible to predict the Most Replayed (MR) data from YouTube videos. To this end, we curate a large video benchmark, the YTMR500 dataset, which comprises 500 YouTube videos with MR data annotations. We evaluate Deep Learning (DL) models of varying complexity on our dataset and perform an extensive ablation study. In addition, we conduct a user study to estimate the human performance on MR data prediction. Our results show that, although by a narrow margin, all the evaluated DL models outperform random predictions. Additionally, they exceed human-level accuracy. This suggests that predicting the MR data is a difficult task that can be enhanced through the assistance of DL. Finally, we believe that DL performance on MR data prediction can be further improved, for example, by using multi-modal learning. We encourage the research community to use our benchmark dataset to further investigate automatic MR data prediction.
</details>
<details>
<summary>摘要</summary>
预测视频用户会重复观看哪些 especific parts是重要的，有多种应用场景，如视频平台上的受argeted广告推送和助手视频创作者。在这种工作中，我们是否可以预测YouTube视频中的 Most Replayed（MR）数据？为此，我们筹集了一个大型视频 benchmark，即 YTMR500 数据集，该数据集包含 500 个 YouTube 视频MR数据注解。我们评估了不同复杂度的深度学习（DL）模型在我们的数据集上，并进行了广泛的减少研究。此外，我们还进行了用户研究，以估计人类在 MR 数据预测上的性能。我们的结果显示，虽然只有通过一定的窄 margins，所有评估的 DL 模型都高于随机预测。此外，它们还超过了人类水平的准确率。这表明预测 MR 数据是一个具有挑战性的任务，可以通过DL的协助进行提高。最后，我们认为DL在 MR 数据预测中的性能可以进一步提高，例如通过多Modal learning。我们鼓励研究社区使用我们的 benchmark 数据集进一步调查自动 MR 数据预测。
</details></li>
</ul>
<hr>
<h2 id="Estimating-exercise-induced-fatigue-from-thermal-facial-images"><a href="#Estimating-exercise-induced-fatigue-from-thermal-facial-images" class="headerlink" title="Estimating exercise-induced fatigue from thermal facial images"></a>Estimating exercise-induced fatigue from thermal facial images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06095">http://arxiv.org/abs/2309.06095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manuel Lage Cañellas, Constantino Álvarez Casado, Le Nguyen, Miguel Bordallo López</li>
<li>for: 预测运动训练过程中的肥胖疲劳水平</li>
<li>methods: 使用深度学习模型和热成像技术对用户的面部和热图进行自动分析</li>
<li>results: 结果表明，只需要一幅热图，可以准确预测运动训练过程中的肥胖疲劳水平，误差在15%以下。这些结果表明使用热成像技术和深度学习模型可以实现可靠的肥胖疲劳预测。<details>
<summary>Abstract</summary>
Exercise-induced fatigue resulting from physical activity can be an early indicator of overtraining, illness, or other health issues. In this article, we present an automated method for estimating exercise-induced fatigue levels through the use of thermal imaging and facial analysis techniques utilizing deep learning models. Leveraging a novel dataset comprising over 400,000 thermal facial images of rested and fatigued users, our results suggest that exercise-induced fatigue levels could be predicted with only one static thermal frame with an average error smaller than 15\%. The results emphasize the viability of using thermal imaging in conjunction with deep learning for reliable exercise-induced fatigue estimation.
</details>
<details>
<summary>摘要</summary>
физи活动引起的疲劳可能是过度训练、疾病或其他健康问题的早期指标。在这篇文章中，我们提出了一种自动化的方法，通过使用热成像和面部分析技术，使用深度学习模型来估计 физи活动引起的疲劳水平。利用一个新的数据集，包括超过400,000个热成像的休息和疲劳用户的面部图像，我们的结果表明，只需要一帧热成像，可以准确地预测Physical activity-induced fatigue level，误差在15%以下。结果表明，使用热成像和深度学习可靠地估计Physical activity-induced fatigue level。
</details></li>
</ul>
<hr>
<h2 id="Plasticity-Optimized-Complementary-Networks-for-Unsupervised-Continual-Learning"><a href="#Plasticity-Optimized-Complementary-Networks-for-Unsupervised-Continual-Learning" class="headerlink" title="Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning"></a>Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06086">http://arxiv.org/abs/2309.06086</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alviur/pocon_wacv2024">https://github.com/alviur/pocon_wacv2024</a></li>
<li>paper_authors: Alex Gomez-Villa, Bartlomiej Twardowski, Kai Wang, Joost van de Weijer</li>
<li>for: 本研究旨在解决现有的 continual learning (CL) 方法在面对多个任务时的表现下降问题，通过采用一个专家网络来减少过去知识的影响，以提高新任务的学习效果。</li>
<li>methods: 本研究使用了一种新的 adaptation-retrospection 策略，将新的知识与过去网络的知识结合在一起，以避免忘记并Initialize一个新的专家网络。此外，本研究还使用了一种新的损失函数，以优化新任务的学习。</li>
<li>results: 本研究的实验结果表明，提出的方法在 few-task 和 many-task 分割Setting中都能够达到其他自由 exemplar-free 方法的高度表现，并且在 semi-supervised continual learning  Setting中也能够达到其他 exemplar-free 方法的表现水平。<details>
<summary>Abstract</summary>
Continuous unsupervised representation learning (CURL) research has greatly benefited from improvements in self-supervised learning (SSL) techniques. As a result, existing CURL methods using SSL can learn high-quality representations without any labels, but with a notable performance drop when learning on a many-tasks data stream. We hypothesize that this is caused by the regularization losses that are imposed to prevent forgetting, leading to a suboptimal plasticity-stability trade-off: they either do not adapt fully to the incoming data (low plasticity), or incur significant forgetting when allowed to fully adapt to a new SSL pretext-task (low stability). In this work, we propose to train an expert network that is relieved of the duty of keeping the previous knowledge and can focus on performing optimally on the new tasks (optimizing plasticity). In the second phase, we combine this new knowledge with the previous network in an adaptation-retrospection phase to avoid forgetting and initialize a new expert with the knowledge of the old network. We perform several experiments showing that our proposed approach outperforms other CURL exemplar-free methods in few- and many-task split settings. Furthermore, we show how to adapt our approach to semi-supervised continual learning (Semi-SCL) and show that we surpass the accuracy of other exemplar-free Semi-SCL methods and reach the results of some others that use exemplars.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A2V-A-Semi-Supervised-Domain-Adaptation-Framework-for-Brain-Vessel-Segmentation-via-Two-Phase-Training-Angiography-to-Venography-Translation"><a href="#A2V-A-Semi-Supervised-Domain-Adaptation-Framework-for-Brain-Vessel-Segmentation-via-Two-Phase-Training-Angiography-to-Venography-Translation" class="headerlink" title="A2V: A Semi-Supervised Domain Adaptation Framework for Brain Vessel Segmentation via Two-Phase Training Angiography-to-Venography Translation"></a>A2V: A Semi-Supervised Domain Adaptation Framework for Brain Vessel Segmentation via Two-Phase Training Angiography-to-Venography Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06075">http://arxiv.org/abs/2309.06075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Galati, Daniele Falcetta, Rosa Cortese, Barbara Casolla, Ferran Prados, Ninon Burgos, Maria A. Zuluaga</li>
<li>for: 这个研究旨在提供一个半监督领域适应框架，用于不同类型的脑血管分类图像。</li>
<li>methods: 这个框架使用了标注的 angeography 和有限标注的 venography，进行图像转换和semantic分类，并且利用分离的和semantically rich的对应空间来表示多元数据，实现图像水平适应和多Modalities 类别分类。</li>
<li>results: 这个方法在磁共振影像和 Venography 上评估，实现了源领域中的最佳性能，并在目标领域中仅有8.9%的Dice分数下降，显示其在不同类型的脑血管图像分类中的可靠性和可行性。<details>
<summary>Abstract</summary>
We present a semi-supervised domain adaptation framework for brain vessel segmentation from different image modalities. Existing state-of-the-art methods focus on a single modality, despite the wide range of available cerebrovascular imaging techniques. This can lead to significant distribution shifts that negatively impact the generalization across modalities. By relying on annotated angiographies and a limited number of annotated venographies, our framework accomplishes image-to-image translation and semantic segmentation, leveraging a disentangled and semantically rich latent space to represent heterogeneous data and perform image-level adaptation from source to target domains. Moreover, we reduce the typical complexity of cycle-based architectures and minimize the use of adversarial training, which allows us to build an efficient and intuitive model with stable training. We evaluate our method on magnetic resonance angiographies and venographies. While achieving state-of-the-art performance in the source domain, our method attains a Dice score coefficient in the target domain that is only 8.9% lower, highlighting its promising potential for robust cerebrovascular image segmentation across different modalities.
</details>
<details>
<summary>摘要</summary>
我们提出了一种半监督频道适应框架，用于从不同影像模式下的脑血管分 segmentation。现有的state-of-the-art方法偏向单一模式，即使有许多可用的脑血管成像技术。这会导致分布shift的问题，这会负面影响 across modalities。我们的框架通过使用注解的 angiographies 和有限多个注解 venographies，实现了图像到图像的翻译和 semantics 的 segmentation，利用分离和具有 semantic richness的秘密空间来表示不同数据，并在目标频道上进行图像级适应。此外，我们减少了典型的 cycle-based 架构的复杂性，并减少了对 adversarial training 的使用，这使得我们可以构建一个高效和直观的模型，并保持稳定的训练。我们在核磁共振 angiographies 和 venographies 上评估了我们的方法，在源频道中达到了 state-of-the-art 性能，而在目标频道中，我们的方法实现了 Dice 分数系数，与目标频道的性能差异为8.9%，这表明我们的方法在不同模式下的脑血管图像分 segmentation中具有良好的潜力。
</details></li>
</ul>
<hr>
<h2 id="Batch-Implicit-Neural-Representation-for-MRI-Parallel-Reconstruction"><a href="#Batch-Implicit-Neural-Representation-for-MRI-Parallel-Reconstruction" class="headerlink" title="Batch Implicit Neural Representation for MRI Parallel Reconstruction"></a>Batch Implicit Neural Representation for MRI Parallel Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06067">http://arxiv.org/abs/2309.06067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Li, Yusheng Zhou, Jianan Liu, Xiling Liu, Tao Huang, Zhihan Lv</li>
<li>for: 提高MRI扫描时间的问题</li>
<li>methods: 使用深度学习方法 implicit neural representation（INR）和scale-embedded encoder来重建MRI图像</li>
<li>results: 提出了一种新的MRI重建方法，能够在不同的抽样率下实现自适应的图像重建，并且在公共可用的MRI数据集上进行了实验和比较，表明该方法在重建图像方面具有优于其他方法。<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) always suffered from the problem of long acquisition time. MRI reconstruction is one solution to reduce scan time by skipping certain phase-encoding lines and then restoring high-quality images from undersampled measurements. Recently, implicit neural representation (INR) has emerged as a new deep learning method that represents an object as a continuous function of spatial coordinates, and this function is normally parameterized by a multilayer perceptron (MLP). In this paper, we propose a novel MRI reconstruction method based on INR, which represents the fully-sampled images as the function of pixel coordinates and prior feature vectors of undersampled images for overcoming the generalization problem of INR. Specifically, we introduce a scale-embedded encoder to produce scale-independent pixel-specific features from MR images with different undersampled scales and then concatenate with coordinates vectors to recover fully-sampled MR images via an MLP, thus achieving arbitrary scale reconstruction. The performance of the proposed method was assessed by experimenting on publicly available MRI datasets and compared with other reconstruction methods. Our quantitative evaluation demonstrates the superiority of the proposed method over alternative reconstruction methods.
</details>
<details>
<summary>摘要</summary>
magnetic resonance imaging (MRI) 总是受到长时间探测问题的困扰。MRI重建是一种解决减少扫描时间的方法，通过跳过certain phase-encoding line并从不完全探测的数据中重建高质量图像。最近，implicit neural representation (INR)  emerged as a new deep learning method, representing an object as a continuous function of spatial coordinates, and this function is normally parameterized by a multilayer perceptron (MLP).在这篇论文中，我们提出了一种基于 INR 的新的 MRI重建方法。specifically, we introduce a scale-embedded encoder to produce scale-independent pixel-specific features from MR images with different undersampled scales and then concatenate with coordinates vectors to recover fully-sampled MR images via an MLP, thus achieving arbitrary scale reconstruction.我们对公共可用的 MRI 数据集进行实验，与其他重建方法进行比较，并评估了我们的方法的性能。我们的量化评估表明了我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="Selection-of-contributing-factors-for-predicting-landslide-susceptibility-using-machine-learning-and-deep-learning-models"><a href="#Selection-of-contributing-factors-for-predicting-landslide-susceptibility-using-machine-learning-and-deep-learning-models" class="headerlink" title="Selection of contributing factors for predicting landslide susceptibility using machine learning and deep learning models"></a>Selection of contributing factors for predicting landslide susceptibility using machine learning and deep learning models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06062">http://arxiv.org/abs/2309.06062</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Chen, Lei Fan</li>
<li>for: 预测滥覆潜在风险地点的滥覆发生可能性，以避免人员伤亡、财产损失和经济损害。</li>
<li>methods: 使用机器学习（ML）模型，如逻辑回归（LR）、支持向量机（SVM）、Random Forest（RF）、极限卷积树（Xgboost）和深度学习（DL）模型，例如卷积神经网络（CNN）和长短期记忆（LSTM）。</li>
<li>results:  investigate the impact of selecting contributing factors on the accuracy of landslide susceptibility predictions using ML and DL models, and compare the performances of four methods for selecting contributing factors, including Information Gain Ratio (IGR), Recursive Feature Elimination (RFE), Particle Swarm Optimization (PSO), Least Absolute Shrinkage and Selection Operators (LASSO) and Harris Hawk Optimization (HHO), as well as autoencoder-based factor selection methods for DL models.<details>
<summary>Abstract</summary>
Landslides are a common natural disaster that can cause casualties, property safety threats and economic losses. Therefore, it is important to understand or predict the probability of landslide occurrence at potentially risky sites. A commonly used means is to carry out a landslide susceptibility assessment based on a landslide inventory and a set of landslide contributing factors. This can be readily achieved using machine learning (ML) models such as logistic regression (LR), support vector machine (SVM), random forest (RF), extreme gradient boosting (Xgboost), or deep learning (DL) models such as convolutional neural network (CNN) and long short time memory (LSTM). As the input data for these models, landslide contributing factors have varying influences on landslide occurrence. Therefore, it is logically feasible to select more important contributing factors and eliminate less relevant ones, with the aim of increasing the prediction accuracy of these models. However, selecting more important factors is still a challenging task and there is no generally accepted method. Furthermore, the effects of factor selection using various methods on the prediction accuracy of ML and DL models are unclear. In this study, the impact of the selection of contributing factors on the accuracy of landslide susceptibility predictions using ML and DL models was investigated. Four methods for selecting contributing factors were considered for all the aforementioned ML and DL models, which included Information Gain Ratio (IGR), Recursive Feature Elimination (RFE), Particle Swarm Optimization (PSO), Least Absolute Shrinkage and Selection Operators (LASSO) and Harris Hawk Optimization (HHO). In addition, autoencoder-based factor selection methods for DL models were also investigated. To assess their performances, an exhaustive approach was adopted,...
</details>
<details>
<summary>摘要</summary>
landalide是一种常见的自然灾害，可以导致人员伤亡、财产安全威胁和经济损失。因此，了解或预测潜在风险地点附近垃圾滥致的可能性非常重要。一种常用的方法是通过垃圾滥致评估基于垃圾发现和一组垃圾带动因素。这可以通过机器学习（ML）模型 such as logistic regression（LR）、support vector machine（SVM）、Random Forest（RF）、extreme gradient boosting（Xgboost）或深度学习（DL）模型 such as convolutional neural network（CNN）和long short time memory（LSTM）来实现。作为输入数据，垃圾带动因素具有不同的影响度，因此可以选择更重要的带动因素，并将不重要的带动因素排除，以提高这些模型的预测精度。然而，选择更重要的因素仍然是一项具有挑战性的任务，并没有一般accepted方法。此外，不同方法选择垃圾带动因素的影响于ML和DL模型的预测精度也未得到了清楚的回答。本研究旨在调查垃圾滥致可能性预测使用ML和DL模型时，选择垃圾带动因素的影响。本研究考虑了四种方法选择垃圾带动因素，包括Information Gain Ratio（IGR）、Recursive Feature Elimination（RFE）、Particle Swarm Optimization（PSO）和Least Absolute Shrinkage and Selection Operators（LASSO）以及Harris Hawk Optimization（HHO）。此外，对于深度学习模型，也调查了基于自适应器的因素选择方法。为了评估它们的表现，本研究采用了一种极客方法。
</details></li>
</ul>
<hr>
<h2 id="Real-Time-Semantic-Segmentation-A-Brief-Survey-Comparative-Study-in-Remote-Sensing"><a href="#Real-Time-Semantic-Segmentation-A-Brief-Survey-Comparative-Study-in-Remote-Sensing" class="headerlink" title="Real-Time Semantic Segmentation: A Brief Survey &amp; Comparative Study in Remote Sensing"></a>Real-Time Semantic Segmentation: A Brief Survey &amp; Comparative Study in Remote Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06047">http://arxiv.org/abs/2309.06047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clifford Broni-Bediako, Junshi Xia, Naoto Yokoya</li>
<li>for: 本研究的目的是提出一种高效的深度学习方法，用于实时Remote Sensing图像Semantic Segmentation。</li>
<li>methods: 本研究使用了几种常见的深度学习方法，包括Convolutional Neural Networks (CNNs)、Recurrent Neural Networks (RNNs) 和 Generative Adversarial Networks (GANs)。</li>
<li>results: 实验结果表明，大多数现有的高效深度学习方法具有良好的分割质量，但它们具有较高的执行速率（即延迟率），这可能限制了它们在实时应用中的可行性。<details>
<summary>Abstract</summary>
Real-time semantic segmentation of remote sensing imagery is a challenging task that requires a trade-off between effectiveness and efficiency. It has many applications including tracking forest fires, detecting changes in land use and land cover, crop health monitoring, and so on. With the success of efficient deep learning methods (i.e., efficient deep neural networks) for real-time semantic segmentation in computer vision, researchers have adopted these efficient deep neural networks in remote sensing image analysis. This paper begins with a summary of the fundamental compression methods for designing efficient deep neural networks and provides a brief but comprehensive survey, outlining the recent developments in real-time semantic segmentation of remote sensing imagery. We examine several seminal efficient deep learning methods, placing them in a taxonomy based on the network architecture design approach. Furthermore, we evaluate the quality and efficiency of some existing efficient deep neural networks on a publicly available remote sensing semantic segmentation benchmark dataset, the OpenEarthMap. The experimental results of an extensive comparative study demonstrate that most of the existing efficient deep neural networks have good segmentation quality, but they suffer low inference speed (i.e., high latency rate), which may limit their capability of deployment in real-time applications of remote sensing image segmentation. We provide some insights into the current trend and future research directions for real-time semantic segmentation of remote sensing imagery.
</details>
<details>
<summary>摘要</summary>
实时 semantic segmentation of remote sensing imagery 是一项复杂的任务，需要考虑效率和准确性之间的平衡。它有许多应用，如追踪森林火灾、检测土地用途和土地覆盖变化、耕地健康监测等。随着计算机视觉中高效的深度学习方法（i.e., 高效的深度神经网络）的成功，研究人员在 remote sensing 图像分析中采用了这些高效的深度神经网络。本文从基本压缩方法的概述开始，并提供了一个简短但全面的报告，概述了最近的 remote sensing 图像semantic segmentation 技术的发展。我们对几种具有代表性的高效深度学习方法进行了分类，根据网络架构设计方法。此外，我们对一个公共可用的 remote sensing semantic segmentation 数据集（OpenEarthMap）进行了评估，并对一些现有的高效深度神经网络进行了比较性研究。实验结果表明，大多数现有的高效深度神经网络具有良好的分割质量，但它们具有低执行速度（即高延迟率），这可能限制它们在实时应用中的可用性。我们提供了一些关于当前趋势和未来研究方向的思考。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-for-Large-Scale-Scene-Modeling-with-Neural-Radiance-Fields"><a href="#Federated-Learning-for-Large-Scale-Scene-Modeling-with-Neural-Radiance-Fields" class="headerlink" title="Federated Learning for Large-Scale Scene Modeling with Neural Radiance Fields"></a>Federated Learning for Large-Scale Scene Modeling with Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06030">http://arxiv.org/abs/2309.06030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teppei Suzuki</li>
<li>for: 建立一个持续性地建立和维护基于地球尺度对应的神经透射场（NeRF），使用车辆和无人机所收集的数据进行生命周期式学习。</li>
<li>methods: 使用联邦学习管线，将NeRF模型聚合在一起，以进行大规模模型化。在联邦学习中，我们修改了NeRF模型的聚合步骤，以容许本地更新NeRF模型。在联邦学习中，客户端的全球姿态精度是 kritical。因此，我们还提出了全球姿态调整，以对客户端的随机全球姿态进行调整。</li>
<li>results: 在Mill19大规模景景集中进行实验，显示了提案的姿态调整和联邦学习管线的效果。<details>
<summary>Abstract</summary>
We envision a system to continuously build and maintain a map based on earth-scale neural radiance fields (NeRF) using data collected from vehicles and drones in a lifelong learning manner. However, existing large-scale modeling by NeRF has problems in terms of scalability and maintainability when modeling earth-scale environments. Therefore, to address these problems, we propose a federated learning pipeline for large-scale modeling with NeRF. We tailor the model aggregation pipeline in federated learning for NeRF, thereby allowing local updates of NeRF. In the aggregation step, the accuracy of the clients' global pose is critical. Thus, we also propose global pose alignment to align the noisy global pose of clients before the aggregation step. In experiments, we show the effectiveness of the proposed pose alignment and the federated learning pipeline on the large-scale scene dataset, Mill19.
</details>
<details>
<summary>摘要</summary>
我们想要构建一个系统，通过持续地使用地球规模神经辐射场（NeRF）收集自汽车和无人机数据来建立和维护地球规模环境的地球规模神经辐射场地图。然而，现有的大规模模型化使用NeRF时存在扩展性和可维护性问题，因此我们提议一种联邦学习管道来解决这些问题。我们修改了NeRF模型聚合管道，以便在联邦学习中进行本地更新。在聚合步骤中，客户端的全球姿态精度是关键的，因此我们还提议用于客户端全球姿态的对齐。在实验中，我们证明了我们提议的姿态对齐和联邦学习管道在大规模场景数据集Mill19上的效果。
</details></li>
</ul>
<hr>
<h2 id="A-new-meteor-detection-application-robust-to-camera-movements"><a href="#A-new-meteor-detection-application-robust-to-camera-movements" class="headerlink" title="A new meteor detection application robust to camera movements"></a>A new meteor detection application robust to camera movements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06027">http://arxiv.org/abs/2309.06027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clara Ciocan, Mathuran Kandeepan, Adrien Cassagne, Jeremie Vaubaillon, Fabian Zander, Lionel Lacassagne</li>
<li>for: 本研究开发了一个自动检测流星的工具，以便实现在气球或飞机上的实时检测。</li>
<li>methods: 研究人员使用了称为FMDT的工具组合，包括了稳定分析和影像处理技术，以检测影像中的流星视域。</li>
<li>results: 研究人员成功开发了一个能够在25帧每秒的实时运算下，实现10瓦的电力耗用的流星检测工具组合。<details>
<summary>Abstract</summary>
This article presents a new tool for the automatic detection of meteors. Fast Meteor Detection Toolbox (FMDT) is able to detect meteor sightings by analyzing videos acquired by cameras onboard weather balloons or within airplane with stabilization. The challenge consists in designing a processing chain composed of simple algorithms, that are robust to the high fluctuation of the videos and that satisfy the constraints on power consumption (10 W) and real-time processing (25 frames per second).
</details>
<details>
<summary>摘要</summary>
这篇文章介绍了一种新的自动探测陨星工具。它可以通过气球上或飞机内的摄像机记录的视频来探测陨星现象，并且可以通过稳定化来减少视频的波动。挑战在于设计一个简单的处理链，可以对视频进行稳定化，并且满足功耗控制（10 W）和实时处理（25帧每秒）的要求。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-History-Task-agnostic-Model-Contrastive-Learning-for-Image-Restoration"><a href="#Learning-from-History-Task-agnostic-Model-Contrastive-Learning-for-Image-Restoration" class="headerlink" title="Learning from History: Task-agnostic Model Contrastive Learning for Image Restoration"></a>Learning from History: Task-agnostic Model Contrastive Learning for Image Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06023">http://arxiv.org/abs/2309.06023</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aitical/task-agnostic_model_contrastive_learning_image_restoration">https://github.com/aitical/task-agnostic_model_contrastive_learning_image_restoration</a></li>
<li>paper_authors: Gang Wu, Junjun Jiang, Kui Jiang, Xianming Liu</li>
<li>for: 高级视觉任务的contrastive学习方法，以及低级视觉任务的启发式学习方法</li>
<li>methods: 自动生成适应性负样本，通过目标模型自身来准确地预测负样本</li>
<li>results: 对各种任务和架构进行重新训练，显著提高图像修复效果，比如FFANet和DehazeFormer在RESIDEindoordataset上的图像震扫比进行3.41dB的提升，同样在SPA-Data上的图像雨减比进行0.47dB的提升，以及在Manga109上的4倍缩放超解像比进行0.12dB的提升。<details>
<summary>Abstract</summary>
Contrastive learning has emerged as a prevailing paradigm for high-level vision tasks, which, by introducing properly negative samples, has also been exploited for low-level vision tasks to achieve a compact optimization space to account for their ill-posed nature. However, existing methods rely on manually predefined, task-oriented negatives, which often exhibit pronounced task-specific biases. In this paper, we propose a innovative approach for the adaptive generation of negative samples directly from the target model itself, called ``learning from history``. We introduce the Self-Prior guided Negative loss for image restoration (SPNIR) to enable this approach. Our approach is task-agnostic and generic, making it compatible with any existing image restoration method or task. We demonstrate the effectiveness of our approach by retraining existing models with SPNIR. The results show significant improvements in image restoration across various tasks and architectures. For example, models retrained with SPNIR outperform the original FFANet and DehazeFormer by 3.41 dB and 0.57 dB on the RESIDE indoor dataset for image dehazing. Similarly, they achieve notable improvements of 0.47 dB on SPA-Data over IDT for image deraining and 0.12 dB on Manga109 for a 4x scale super-resolution over lightweight SwinIR, respectively. Code and retrained models are available at https://github.com/Aitical/Task-agnostic_Model_Contrastive_Learning_Image_Restoration.
</details>
<details>
<summary>摘要</summary>
对比学习在高级视觉任务中成为主流方法，并且运用到低级视觉任务中以获得一个较为紧密的优化空间，以应对它们的不确定性。然而，现有的方法通常靠manual地定义任务特有的负面样本，这些样本经常会受到任务特有的偏见。在这篇论文中，我们提出了一种创新的方法，即“学习历史”，可以自动生成适当的负面样本。我们称之为Self-Prior guided Negative loss for image restoration（SPNIR）。我们的方法是任务不特定的和通用的，因此可以与任何现有的图像修复方法或任务搭配使用。我们通过 retrained 现有模型使用 SPNIR，以证明我们的方法的有效性。结果显示，使用 SPNIR  retrained 模型可以在不同任务和架构上实现明显的图像修复改善。例如，使用 SPNIR  retrained FFANet 和 DehazeFormer 可以在 RESIDE 室内dataset 上实现这些模型的3.41 dB和0.57 dB的视觉修复提升。同样地，它们在 SPA-Data 上运用 IDT 的图像雨侦测任务上也可以获得0.47 dB的提升。代码和 retrained 模型可以在 https://github.com/Aitical/Task-agnostic_Model_Contrastive_Learning_Image_Restoration 上找到。
</details></li>
</ul>
<hr>
<h2 id="Feature-Aggregation-Network-for-Building-Extraction-from-High-resolution-Remote-Sensing-Images"><a href="#Feature-Aggregation-Network-for-Building-Extraction-from-High-resolution-Remote-Sensing-Images" class="headerlink" title="Feature Aggregation Network for Building Extraction from High-resolution Remote Sensing Images"></a>Feature Aggregation Network for Building Extraction from High-resolution Remote Sensing Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06017">http://arxiv.org/abs/2309.06017</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan Zhou, Xuefeng Wei</li>
<li>for: 本研究旨在提高高分辨率卫星遥感数据处理中的表面特征提取精度。</li>
<li>methods: 本文提出了一种名为Feature Aggregation Network（FANet）的新方法，通过捕捉全球特征和本地特征，实现细致的表面特征提取。</li>
<li>results: 广泛的实验表明，FANet在高分辨率卫星遥感图像中提取表面特征时表现出色，代表了Remote Sensing图像处理领域的一大突破。<details>
<summary>Abstract</summary>
The rapid advancement in high-resolution satellite remote sensing data acquisition, particularly those achieving submeter precision, has uncovered the potential for detailed extraction of surface architectural features. However, the diversity and complexity of surface distributions frequently lead to current methods focusing exclusively on localized information of surface features. This often results in significant intraclass variability in boundary recognition and between buildings. Therefore, the task of fine-grained extraction of surface features from high-resolution satellite imagery has emerged as a critical challenge in remote sensing image processing. In this work, we propose the Feature Aggregation Network (FANet), concentrating on extracting both global and local features, thereby enabling the refined extraction of landmark buildings from high-resolution satellite remote sensing imagery. The Pyramid Vision Transformer captures these global features, which are subsequently refined by the Feature Aggregation Module and merged into a cohesive representation by the Difference Elimination Module. In addition, to ensure a comprehensive feature map, we have incorporated the Receptive Field Block and Dual Attention Module, expanding the receptive field and intensifying attention across spatial and channel dimensions. Extensive experiments on multiple datasets have validated the outstanding capability of FANet in extracting features from high-resolution satellite images. This signifies a major breakthrough in the field of remote sensing image processing. We will release our code soon.
</details>
<details>
<summary>摘要</summary>
高解度卫星遥感数据获取的快速进步，尤其是实现 submeter 精度，揭示了表面建筑特征的详细EXTRACT的 potential.然而，表面分布的多样性和复杂性常常导致当前方法仅专注于本地特征信息。这经常导致边界认知的内部多样性和建筑之间的差异。因此，从高解度卫星遥感图像中细化EXTRACT表面特征成为了远程感知图像处理中的核心挑战。在这种情况下，我们提出了特征聚合网络（FANet），旨在EXTRACT高解度卫星遥感图像中的全球和本地特征。Pyramid Vision Transformer 捕捉到全球特征，然后通过特征聚合模块和差异消除模块将其融合成一个准确的表征。此外，为确保全面的表征地图，我们采用了抽象块和双向注意模块，扩展了受感器场和精细注意力。广泛的实验表明FANet在高解度卫星图像中EXTRACT特征的能力强大，这标志着远程感知图像处理领域的一次重要突破。我们即将发布代码。
</details></li>
</ul>
<hr>
<h2 id="TSSAT-Two-Stage-Statistics-Aware-Transformation-for-Artistic-Style-Transfer"><a href="#TSSAT-Two-Stage-Statistics-Aware-Transformation-for-Artistic-Style-Transfer" class="headerlink" title="TSSAT: Two-Stage Statistics-Aware Transformation for Artistic Style Transfer"></a>TSSAT: Two-Stage Statistics-Aware Transformation for Artistic Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06004">http://arxiv.org/abs/2309.06004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haibo Chen, Lei Zhao, Jun Li, Jian Yang</li>
<li>For: 这个论文的目的是提出一种基于人类绘画过程的艺术风格传递方法，以便创造出新的艺术图像。* Methods: 这个方法使用了两个新的损失函数：一个关注内容损失函数和一个块基于风格损失函数，以及一个两个阶段统计意识转换模块（TSSAT），用于在patchwise进行风格细节的替换，从而提高风格效果。* Results: 对比其他方法，这个方法可以更好地捕捉到艺术风格的多样性和多样性，同时保持内容图像的semantic关系。广泛的量化和质量实验证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Artistic style transfer aims to create new artistic images by rendering a given photograph with the target artistic style. Existing methods learn styles simply based on global statistics or local patches, lacking careful consideration of the drawing process in practice. Consequently, the stylization results either fail to capture abundant and diversified local style patterns, or contain undesired semantic information of the style image and deviate from the global style distribution. To address this issue, we imitate the drawing process of humans and propose a Two-Stage Statistics-Aware Transformation (TSSAT) module, which first builds the global style foundation by aligning the global statistics of content and style features and then further enriches local style details by swapping the local statistics (instead of local features) in a patch-wise manner, significantly improving the stylization effects. Moreover, to further enhance both content and style representations, we introduce two novel losses: an attention-based content loss and a patch-based style loss, where the former enables better content preservation by enforcing the semantic relation in the content image to be retained during stylization, and the latter focuses on increasing the local style similarity between the style and stylized images. Extensive qualitative and quantitative experiments verify the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose a Two-Stage Statistics-Aware Transformation (TSSAT) module that imitates the drawing process of humans. The first stage builds a global style foundation by aligning the global statistics of content and style features. The second stage enriches local style details by swapping local statistics in a patch-wise manner, significantly improving stylization effects.Moreover, we introduce two novel losses to enhance both content and style representations: an attention-based content loss that enforces the semantic relation in the content image to be retained during stylization, and a patch-based style loss that focuses on increasing local style similarity between the style and stylized images. Extensive experiments demonstrate the effectiveness of our method.
</details></li>
</ul>
<hr>
<h2 id="ATTA-Anomaly-aware-Test-Time-Adaptation-for-Out-of-Distribution-Detection-in-Segmentation"><a href="#ATTA-Anomaly-aware-Test-Time-Adaptation-for-Out-of-Distribution-Detection-in-Segmentation" class="headerlink" title="ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation"></a>ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05994">http://arxiv.org/abs/2309.05994</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gaozhitong/atta">https://github.com/gaozhitong/atta</a></li>
<li>paper_authors: Zhitong Gao, Shipeng Yan, Xuming He</li>
<li>for: 本文主要针对在相似领域下进行训练和测试的 dense out-of-distribution (OOD) 检测方法，即假设训练和测试数据集之间没有领域变换。</li>
<li>methods: 我们提议一种 dual-level OOD 检测框架，同时处理领域变换和语义变换。第一层使用全域低级特征来判断图像是否存在领域变换，第二层使用高级特征图来检测像素的语义变换。</li>
<li>results: 我们在多个 OOD 分割benchmark上验证了我们的提议方法，包括具有显著领域变换的benchmark，并观察到了不同基础模型的表现改善。<details>
<summary>Abstract</summary>
Recent advancements in dense out-of-distribution (OOD) detection have primarily focused on scenarios where the training and testing datasets share a similar domain, with the assumption that no domain shift exists between them. However, in real-world situations, domain shift often exits and significantly affects the accuracy of existing out-of-distribution (OOD) detection models. In this work, we propose a dual-level OOD detection framework to handle domain shift and semantic shift jointly. The first level distinguishes whether domain shift exists in the image by leveraging global low-level features, while the second level identifies pixels with semantic shift by utilizing dense high-level feature maps. In this way, we can selectively adapt the model to unseen domains as well as enhance model's capacity in detecting novel classes. We validate the efficacy of our proposed method on several OOD segmentation benchmarks, including those with significant domain shifts and those without, observing consistent performance improvements across various baseline models.
</details>
<details>
<summary>摘要</summary>
最近的高精度异类检测技术主要集中在同一个领域下进行训练和测试数据集的情况下，假设没有领域转移。然而，在实际情况下，领域转移经常存在并对现有的异类检测模型的准确性产生重要影响。在这种情况下，我们提出了一种双级异类检测框架，同时处理领域转移和 semantic shift。第一级检测图像中是否存在领域转移，通过利用全像的低级别特征；第二级通过使用高级别特征图像来标识具有semantic shift的像素。这种方法可以使我们在未看过的领域中选择性地适应模型，同时提高模型的检测新类的能力。我们在多个OOD分割标准评测上验证了我们的提议方法，包括具有显著领域转移的和无领域转移的多个基eline模型，并观察到了一致的性能提高。
</details></li>
</ul>
<hr>
<h2 id="FLDNet-A-Foreground-Aware-Network-for-Polyp-Segmentation-Leveraging-Long-Distance-Dependencies"><a href="#FLDNet-A-Foreground-Aware-Network-for-Polyp-Segmentation-Leveraging-Long-Distance-Dependencies" class="headerlink" title="FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies"></a>FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05987">http://arxiv.org/abs/2309.05987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuefeng Wei, Xuan Zhou</li>
<li>for: 检测和分类 COLONOSCOPY 图像中的肠穿孔瘤，以便早期检测和治疗肠穿孔癌。</li>
<li>methods: 提议使用 Transformer 基于网络，包括三个主要模块：pyramid-based transformer encoder、local context module 和 foreground-Aware module。</li>
<li>results: 比较现有方法表现出色，在常用的评价指标上达到了最高水平。<details>
<summary>Abstract</summary>
Given the close association between colorectal cancer and polyps, the diagnosis and identification of colorectal polyps play a critical role in the detection and surgical intervention of colorectal cancer. In this context, the automatic detection and segmentation of polyps from various colonoscopy images has emerged as a significant problem that has attracted broad attention. Current polyp segmentation techniques face several challenges: firstly, polyps vary in size, texture, color, and pattern; secondly, the boundaries between polyps and mucosa are usually blurred, existing studies have focused on learning the local features of polyps while ignoring the long-range dependencies of the features, and also ignoring the local context and global contextual information of the combined features. To address these challenges, we propose FLDNet (Foreground-Long-Distance Network), a Transformer-based neural network that captures long-distance dependencies for accurate polyp segmentation. Specifically, the proposed model consists of three main modules: a pyramid-based Transformer encoder, a local context module, and a foreground-Aware module. Multilevel features with long-distance dependency information are first captured by the pyramid-based transformer encoder. On the high-level features, the local context module obtains the local characteristics related to the polyps by constructing different local context information. The coarse map obtained by decoding the reconstructed highest-level features guides the feature fusion process in the foreground-Aware module of the high-level features to achieve foreground enhancement of the polyps. Our proposed method, FLDNet, was evaluated using seven metrics on common datasets and demonstrated superiority over state-of-the-art methods on widely-used evaluation measures.
</details>
<details>
<summary>摘要</summary>
giventext  close association colorectal cancer polyps diagnosis identification colorectal polyps critical role detection surgical intervention context automatic detection segmentation various colonoscopy images emerged significant problem attracted broad attention current polyp segmentation techniques challenges firstly polyps vary size texture color pattern secondly boundaries polyps mucosa blurred existing studies focused learning local features ignoring long-range dependencies features ignoring local context global contextual information combined features address challenges propose FLDNet (Foreground-Long-Distance Network) Transformer-based neural network captures long-distance dependencies accurate polyp segmentation specifically proposed model consists three main modules pyramid-based Transformer encoder local context module foreground-Aware module multilevel features long-distance dependency information first captured pyramid-based transformer encoder high-level features local context module obtains local characteristics related polyps constructing different local context information coarse map obtained decoding reconstructed highest-level features guides feature fusion process foreground-Aware module achieve foreground enhancement polyps our proposed method FLDNet evaluated seven metrics common datasets demonstrated superiority state-of-art methods widely-used evaluation measures.
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Extraction-of-Human-Motion-Structures-via-Frame-wise-Discrete-Features"><a href="#Self-supervised-Extraction-of-Human-Motion-Structures-via-Frame-wise-Discrete-Features" class="headerlink" title="Self-supervised Extraction of Human Motion Structures via Frame-wise Discrete Features"></a>Self-supervised Extraction of Human Motion Structures via Frame-wise Discrete Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05972">http://arxiv.org/abs/2309.05972</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tetsuya Abe, Ryusuke Sagawa, Ko Ayusawa, Wataru Takano</li>
<li>for: 提出了一种基于encoder-decoder模型的自然语言处理方法，用于从框架级别的不同特征中提取人体运动结构。</li>
<li>methods: 使用自我注意力层和 вектор聚合块来找到缺省的键帧和离散特征，并通过训练约束来确保这些码可以在多个序列之间共享。</li>
<li>results: 通过使用这些缺省的运动码，可以将人体运动的关系图示出来，并通过线性探测发现这些码在不同序列之间的差异。同时，这些运动码也可以用于多个认知任务中，并且可以达到与任务优化方法相同的性能水平。<details>
<summary>Abstract</summary>
The present paper proposes an encoder-decoder model for extracting the structures of human motions represented by frame-wise discrete features in a self-supervised manner. In the proposed method, features are extracted as codes in a motion codebook without the use of human knowledge, and the relationship between these codes can be visualized on a graph. Since the codes are expected to be temporally sparse compared to the captured frame rate and can be shared by multiple sequences, the proposed network model also addresses the need for training constraints. Specifically, the model consists of self-attention layers and a vector clustering block. The attention layers contribute to finding sparse keyframes and discrete features as motion codes, which are then extracted by vector clustering. The constraints are realized as training losses so that the same motion codes can be as contiguous as possible and can be shared by multiple sequences. In addition, we propose the use of causal self-attention as a method by which to calculate attention for long sequences consisting of numerous frames. In our experiments, the sparse structures of motion codes were used to compile a graph that facilitates visualization of the relationship between the codes and the differences between sequences. We then evaluated the effectiveness of the extracted motion codes by applying them to multiple recognition tasks and found that performance levels comparable to task-optimized methods could be achieved by linear probing.
</details>
<details>
<summary>摘要</summary>
现在的论文提出了一种encoder-decoder模型，用于自主监测人体动作的结构，通过frame-wise不同特征来自动提取这些结构。在提posed方法中，特征被视为码在动作码本中，而这些码之间的关系可以在图上可视化。由于码预计会比捕捉的帧率更加稀疏，因此提出的网络模型也解决了训练约束的需求。具体来说，模型包括自我注意层和 вектор聚合块。注意层帮助找到简短的关键帧和特征码，然后通过 вектор聚合提取这些码。约束被实现为训练损失，以便在多个序列之间共享相同的动作码。此外，我们还提出了使用 causal self-attention 来计算注意力的方法，以便对长序列中的多个帧进行注意力计算。在我们的实验中，通过使用稀疏的动作码，编译了一个图，方便了动作码之间和序列之间的关系的可视化。然后，我们通过将这些动作码应用到多个认知任务中，发现可以达到与任务优化方法相同的性能水平。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Generation-Harnessing-Text-to-Image-Models-for-Object-Detection-and-Segmentation"><a href="#Beyond-Generation-Harnessing-Text-to-Image-Models-for-Object-Detection-and-Segmentation" class="headerlink" title="Beyond Generation: Harnessing Text to Image Models for Object Detection and Segmentation"></a>Beyond Generation: Harnessing Text to Image Models for Object Detection and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05956">http://arxiv.org/abs/2309.05956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunhao Ge, Jiashu Xu, Brian Nlong Zhao, Neel Joshi, Laurent Itti, Vibhav Vineet</li>
<li>for:  This paper proposes a new approach to generate training data with accurate labels at scale for object detection and segmentation tasks.</li>
<li>methods: The proposed approach decouples training data generation into foreground object generation and contextually coherent background generation, using text-to-image synthesis frameworks such as DALL-E and Stable Diffusion.</li>
<li>results: The authors demonstrate the advantages of their approach on five object detection and segmentation datasets, including Pascal VOC and COCO, and show that detectors trained solely on synthetic data produced by their method achieve performance comparable to those trained on real data. Additionally, the authors emphasize the compositional nature of their data generation approach in out-of-distribution and zero-shot data generation scenarios.<details>
<summary>Abstract</summary>
We propose a new paradigm to automatically generate training data with accurate labels at scale using the text-to-image synthesis frameworks (e.g., DALL-E, Stable Diffusion, etc.). The proposed approach1 decouples training data generation into foreground object generation, and contextually coherent background generation. To generate foreground objects, we employ a straightforward textual template, incorporating the object class name as input prompts. This is fed into a text-to-image synthesis framework, producing various foreground images set against isolated backgrounds. A foreground-background segmentation algorithm is then used to generate foreground object masks. To generate context images, we begin by creating language descriptions of the context. This is achieved by applying an image captioning method to a small set of images representing the desired context. These textual descriptions are then transformed into a diverse array of context images via a text-to-image synthesis framework. Subsequently, we composite these with the foreground object masks produced in the initial step, utilizing a cut-and-paste method, to formulate the training data. We demonstrate the advantages of our approach on five object detection and segmentation datasets, including Pascal VOC and COCO. We found that detectors trained solely on synthetic data produced by our method achieve performance comparable to those trained on real data (Fig. 1). Moreover, a combination of real and synthetic data yields even much better results. Further analysis indicates that the synthetic data distribution complements the real data distribution effectively. Additionally, we emphasize the compositional nature of our data generation approach in out-of-distribution and zero-shot data generation scenarios. We open-source our code at https://github.com/gyhandy/Text2Image-for-Detection
</details>
<details>
<summary>摘要</summary>
我们提出一种新的思路，用于自动生成具有准确标签的训练数据量化，使用文本到图像合成框架（如DALL-E、稳定扩散等）。我们的方法将训练数据生成划分为前景对象生成和文脉凝合的背景生成。为前景对象生成，我们使用直观文本模板，将对象类名作为输入提示。这些文本模板被 feed into 文本到图像合成框架，生成多种前景图像，其中每个图像具有隔离的背景。然后，我们使用前景-背景分割算法生成前景对象mask。为生成背景图像，我们首先创建语言描述，用于描述愿意的背景。我们使用一小组图像的图像描述算法来生成这些语言描述。这些文本描述被转换成一个多样化的背景图像数组via 文本到图像合成框架。最后，我们将这些背景图像与前景对象mask进行组合，使用剪辑方法，以生成训练数据。我们在 Pascal VOC 和 COCO 等五个对象检测和分割数据集上示出了我们的方法的优势（图1）。我们发现，由我们的方法生成的假数据可以与实际数据一样高效地训练检测器。此外，我们发现在将实际数据和假数据混合在一起时，性能更好。我们还发现，我们的数据生成方法在尝试数据和零shot数据生成方面具有组合性。我们将代码开源在 GitHub 上，可以在 <https://github.com/gyhandy/Text2Image-for-Detection> 中下载。
</details></li>
</ul>
<hr>
<h2 id="Introducing-Shape-Prior-Module-in-Diffusion-Model-for-Medical-Image-Segmentation"><a href="#Introducing-Shape-Prior-Module-in-Diffusion-Model-for-Medical-Image-Segmentation" class="headerlink" title="Introducing Shape Prior Module in Diffusion Model for Medical Image Segmentation"></a>Introducing Shape Prior Module in Diffusion Model for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05929">http://arxiv.org/abs/2309.05929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqing Zhang, Guojia Fan, Tianyong Liu, Nan Li, Yuyang Liu, Ziyu Liu, Canwei Dong, Shoujun Zhou</li>
<li>for: 这个研究旨在提供高精度和多标的脊梗医学像分割模板，以支持专科医生在诊断和治疗中使用。</li>
<li>methods: 这种方法利用了减轻扩散 probabilistic modeling（DDPM），并与标准的U型架构结合，以精确地导向扩散方向。此外，这种方法还包括一个形态预设模组，以提取医疗影像中的结构 semantic信息。</li>
<li>results:  compared to其他现有方法，VerseDiff-UNet 在精度方面表现出色，同时保持了医疗影像中自然的特征和变化。<details>
<summary>Abstract</summary>
Medical image segmentation is critical for diagnosing and treating spinal disorders. However, the presence of high noise, ambiguity, and uncertainty makes this task highly challenging. Factors such as unclear anatomical boundaries, inter-class similarities, and irrational annotations contribute to this challenge. Achieving both accurate and diverse segmentation templates is essential to support radiologists in clinical practice. In recent years, denoising diffusion probabilistic modeling (DDPM) has emerged as a prominent research topic in computer vision. It has demonstrated effectiveness in various vision tasks, including image deblurring, super-resolution, anomaly detection, and even semantic representation generation at the pixel level. Despite the robustness of existing diffusion models in visual generation tasks, they still struggle with discrete masks and their various effects. To address the need for accurate and diverse spine medical image segmentation templates, we propose an end-to-end framework called VerseDiff-UNet, which leverages the denoising diffusion probabilistic model (DDPM). Our approach integrates the diffusion model into a standard U-shaped architecture. At each step, we combine the noise-added image with the labeled mask to guide the diffusion direction accurately towards the target region. Furthermore, to capture specific anatomical a priori information in medical images, we incorporate a shape a priori module. This module efficiently extracts structural semantic information from the input spine images. We evaluate our method on a single dataset of spine images acquired through X-ray imaging. Our results demonstrate that VerseDiff-UNet significantly outperforms other state-of-the-art methods in terms of accuracy while preserving the natural features and variations of anatomy.
</details>
<details>
<summary>摘要</summary>
医疗图像分割是诊断和治疗脊椎疾病的关键。然而，高噪音、不确定性和潜在的混淆使得这项任务具有极高的挑战性。因为脊椎图像中的解剖边界不够明确，同类图像之间存在相似性，而且标注不具有合理性，这些因素都使得图像分割变得更加困难。为了支持医生在临床实践中，获得高精度和多样化的图像分割模板是必要的。在过去几年，推 diffusion probabilistic modeling（DDPM）在计算机视觉领域得到了广泛的关注。DDPM在多种视觉任务中表现出色，包括图像滤清、超分解、异常检测和甚至像素级semantic representation生成。虽然现有的推散模型在视觉生成任务中具有强大的稳定性，但它们仍然在精度束和其多种效果上困难。为了解决医疗图像分割中的精度和多样化问题，我们提出了一种综合框架called VerseDiff-UNet。我们的方法将推散模型与标准的U型架构结合起来。在每个步骤中，我们将噪声添加的图像和标注推散向导准确地指向目标区域。此外，为了从医疗图像中提取高效的结构semantic信息，我们添加了一个形状先验模块。这个模块高效地提取了输入脊椎图像中的结构semantic信息。我们在X射线成像获取的一个单个数据集上进行了测试。我们的结果表明，VerseDiff-UNet在精度方面与其他状态对比方法有显著的优势，同时保持了自然的特征和变化。
</details></li>
</ul>
<hr>
<h2 id="Deep-evidential-fusion-with-uncertainty-quantification-and-contextual-discounting-for-multimodal-medical-image-segmentation"><a href="#Deep-evidential-fusion-with-uncertainty-quantification-and-contextual-discounting-for-multimodal-medical-image-segmentation" class="headerlink" title="Deep evidential fusion with uncertainty quantification and contextual discounting for multimodal medical image segmentation"></a>Deep evidential fusion with uncertainty quantification and contextual discounting for multimodal medical image segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05919">http://arxiv.org/abs/2309.05919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ling Huang, Su Ruan, Pierre Decazes, Thierry Denoeux<br>for:多modal医疗影像通常无法提供充分的信息，因此医生通常基于多modal影像进行诊断，如PET&#x2F;CT。将多modal信息有效融合是重要的，以确保做出可靠的判断并解释judgment的决策过程。methods:本文提出了基于深度学习和Dempster-Shafer理论的多modal医疗影像分类框架。在这个框架中，每个单 modal 影像中的可靠性在分类不同的物体时被考虑。各个modal 影像的折扣 pieces of evidence 然后由Dempster’s rule 联合，以获得最终的决策。results:实验结果显示，我们的方法在PET-CT dataset中与悉尼肿瘤检测中的lymphomas，以及多modal MRI dataset中的脑肿瘤检测中，具有较高的精度和可靠性。<details>
<summary>Abstract</summary>
Single-modality medical images generally do not contain enough information to reach an accurate and reliable diagnosis. For this reason, physicians generally diagnose diseases based on multimodal medical images such as, e.g., PET/CT. The effective fusion of multimodal information is essential to reach a reliable decision and explain how the decision is made as well. In this paper, we propose a fusion framework for multimodal medical image segmentation based on deep learning and the Dempster-Shafer theory of evidence. In this framework, the reliability of each single modality image when segmenting different objects is taken into account by a contextual discounting operation. The discounted pieces of evidence from each modality are then combined by Dempster's rule to reach a final decision. Experimental results with a PET-CT dataset with lymphomas and a multi-MRI dataset with brain tumors show that our method outperforms the state-of-the-art methods in accuracy and reliability.
</details>
<details>
<summary>摘要</summary>
单Modal的医疗影像通常不含足够的信息以确定精确和可靠的诊断。为此， Physician 通常根据多Modal的医疗影像，如 PET/CT，诊断疾病。多Modal信息的有效融合是必要的，以确定可靠的决策并解释如何做出这个决策。在这篇论文中，我们提出了基于深度学习和德мп斯特-沙佛理论的融合框架，用于多Modal医疗影像分割。在这个框架中，每种单Modal图像在分割不同对象时的可靠性被考虑。每种模式的减少的证据后，通过德мп斯特规则组合，以达到最终决策。实验结果表明，使用 PET-CT 数据集和多MRI 数据集，我们的方法在准确性和可靠性方面都高于当前的方法。
</details></li>
</ul>
<hr>
<h2 id="Medical-Image-Segmentation-with-Belief-Function-Theory-and-Deep-Learning"><a href="#Medical-Image-Segmentation-with-Belief-Function-Theory-and-Deep-Learning" class="headerlink" title="Medical Image Segmentation with Belief Function Theory and Deep Learning"></a>Medical Image Segmentation with Belief Function Theory and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05914">http://arxiv.org/abs/2309.05914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ling Huang<br>for:This paper focuses on medical image segmentation approaches using belief function theory and deep learning, specifically addressing the challenges of reasoning with imperfect information.methods:The paper presents a semi-supervised medical image segmentation framework that incorporates evidential segmentation and evidence fusion to reduce uncertainty caused by limited annotations. The authors also compare two evidential classifiers, evidential neural network and radial basis function network, and use them with deep neural networks to construct deep evidential models for lymphoma segmentation.results:The paper presents a multimodal medical image fusion framework that takes into account the reliability of each MR image source when performing different segmentation tasks using mass functions and contextual discounting. The authors show the effectiveness of belief function theory in uncertainty quantification and demonstrate the improved performance of their approach compared to traditional methods.<details>
<summary>Abstract</summary>
Deep learning has shown promising contributions in medical image segmentation with powerful learning and feature representation abilities. However, it has limitations for reasoning with and combining imperfect (imprecise, uncertain, and partial) information. In this thesis, we study medical image segmentation approaches with belief function theory and deep learning, specifically focusing on information modeling and fusion based on uncertain evidence.   First, we review existing belief function theory-based medical image segmentation methods and discuss their advantages and challenges. Second, we present a semi-supervised medical image segmentation framework to decrease the uncertainty caused by the lack of annotations with evidential segmentation and evidence fusion. Third, we compare two evidential classifiers, evidential neural network and radial basis function network, and show the effectiveness of belief function theory in uncertainty quantification; we use the two evidential classifiers with deep neural networks to construct deep evidential models for lymphoma segmentation. Fourth, we present a multimodal medical image fusion framework taking into account the reliability of each MR image source when performing different segmentation tasks using mass functions and contextual discounting.
</details>
<details>
<summary>摘要</summary>
深度学习在医疗影像分割中表现出了扎实的贡献，具有强大的学习和特征表示能力。然而，深度学习在处理不准确、uncertain和部分的信息时存在限制。在这个论文中，我们研究医疗影像分割方法，使用信念函数理论和深度学习，特别是关于信息模型化和融合基于不确定证据。首先，我们查看了现有的信念函数理论基于的医疗影像分割方法，并讨论了它们的优点和挑战。其次，我们提出了一种半监督医疗影像分割框架，以减少由缺乏标注所导致的不确定性。第三，我们比较了两种信念分类器，即信念神经网络和卷积函数网络，并证明了信念函数理论在不确定评估中的效果。我们使用了两种信念分类器与深度神经网络构建了深度信念模型以进行淋巴癌分 segmentation。最后，我们提出了一种多Modal医疗影像融合框架，考虑每个MRI图像来源的可靠性，并在不同的 segmentation 任务中使用质量函数和上下文折扣来进行融合。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Representation-in-Radiography-Reports-Foundation-Model-A-Granular-Alignment-Algorithm-Using-Masked-Contrastive-Learning"><a href="#Enhancing-Representation-in-Radiography-Reports-Foundation-Model-A-Granular-Alignment-Algorithm-Using-Masked-Contrastive-Learning" class="headerlink" title="Enhancing Representation in Radiography-Reports Foundation Model: A Granular Alignment Algorithm Using Masked Contrastive Learning"></a>Enhancing Representation in Radiography-Reports Foundation Model: A Granular Alignment Algorithm Using Masked Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05904">http://arxiv.org/abs/2309.05904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijian Huang, Cheng Li, Hao Yang, Jiarun Liu, Shanshan Wang</li>
<li>for: 这个研究目的是为了提出一个新的多modal医疗基础模型，以便在各种医疗影像 зада务中进行精细的掌握和零shot学习。</li>
<li>methods: 这个研究使用了封装问题学习的masked对称学习方法，以提高基础学习能力。此外，它还具有一个相互调整对称关系机制，以进一步增强基础学习能力。</li>
<li>results: 这个研究在六个常用的开源X射像数据集上进行了评估，结果显示MaCo比七种现有的方法在类别、分类和零shot阶段固定掌握中表现出色，demonstrating its great potential to promote a wide range of medical image analysis tasks。<details>
<summary>Abstract</summary>
Recently, multi-modal vision-language foundation models have gained significant attention in the medical field. While these models offer great opportunities, they still face a number of challenges, such as the requirement for fine-grained knowledge understanding in computer-aided diagnosis and capability of utilizing very limited or no task-specific labeled data in real-world clinical applications. In this study, we present MaCo, a novel multi-modal medical foundation model that explores masked contrastive learning to achieve granular alignment and zero-shot learning for a variety of medical imaging tasks. MaCo incorporates a correlation weighting mechanism to adjust the correlation between masked image patches and their corresponding reports, thereby enhancing the representation learning capabilities. We evaluate MaCo on six well-known open-source X-ray datasets, and the experimental results show it outperforms seven state-of-the-art approaches for classification, segmentation, and zero-shot phase grounding, demonstrating its great potential to promote a wide range of medical image analysis tasks.
</details>
<details>
<summary>摘要</summary>
近期，多模态视语言基础模型在医疗领域得到了广泛关注。虽然这些模型具有很大的潜力，但仍面临许多挑战，如计算机辅助诊断中细化知识理解的需求以及在实际临床应用中使用非常有限或无任务特定标注数据的能力。在本研究中，我们提出了MaCo，一种新的多模态医疗基础模型，利用掩码对比学习来实现精细对Alignment和零shot学习，以涵盖各种医学影像任务。MaCo通过调整掩码图像块和其相应的报告之间的相关性权重，进而提高了表征学习能力。我们在六个常见的开源X射线数据集上进行了实验，结果显示MaCo超过了七种现状最佳方法，包括分类、分割和零shot阶段定位，这表明它在各种医学影像分析任务中具有极大的潜力。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Attacks-Assessment-of-Salient-Object-Detection-via-Symbolic-Learning"><a href="#Adversarial-Attacks-Assessment-of-Salient-Object-Detection-via-Symbolic-Learning" class="headerlink" title="Adversarial Attacks Assessment of Salient Object Detection via Symbolic Learning"></a>Adversarial Attacks Assessment of Salient Object Detection via Symbolic Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05900">http://arxiv.org/abs/2309.05900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gustavo Olague, Roberto Pineda, Gerardo Ibarra-Vazquez, Matthieu Olague, Axel Martinez, Sambit Bakshi, Jonathan Vargas, Isnardo Reducindo</li>
<li>for: 这个论文的目的是提出一种符号学习方法来设计可靠的视觉注意力系统，并证明这种方法在面对恶意攻击和干扰时具有更高的Robustness。</li>
<li>methods: 这个论文使用的方法包括了生成 adversarial attacks和噪声攻击，并对这些攻击进行了对比分析，以证明符号学习方法的Robustness。</li>
<li>results: 研究发现，符号学习方法在面对恶意攻击和干扰时表现更好，与深度学习方法不同，它们在攻击下表现出了显著的性能下降。<details>
<summary>Abstract</summary>
Machine learning is at the center of mainstream technology and outperforms classical approaches to handcrafted feature design. Aside from its learning process for artificial feature extraction, it has an end-to-end paradigm from input to output, reaching outstandingly accurate results. However, security concerns about its robustness to malicious and imperceptible perturbations have drawn attention since its prediction can be changed entirely. Salient object detection is a research area where deep convolutional neural networks have proven effective but whose trustworthiness represents a significant issue requiring analysis and solutions to hackers' attacks. Brain programming is a kind of symbolic learning in the vein of good old-fashioned artificial intelligence. This work provides evidence that symbolic learning robustness is crucial in designing reliable visual attention systems since it can withstand even the most intense perturbations. We test this evolutionary computation methodology against several adversarial attacks and noise perturbations using standard databases and a real-world problem of a shorebird called the Snowy Plover portraying a visual attention task. We compare our methodology with five different deep learning approaches, proving that they do not match the symbolic paradigm regarding robustness. All neural networks suffer significant performance losses, while brain programming stands its ground and remains unaffected. Also, by studying the Snowy Plover, we remark on the importance of security in surveillance activities regarding wildlife protection and conservation.
</details>
<details>
<summary>摘要</summary>
machine learning 是现代科技中最重要的核心技术，其超越了经典的手动特征设计方法。除了学习过程中的人工特征提取外，它还具有从输入到输出的端到端模式，达到了极高的准确率。然而，由于其鲁棒性问题，它的预测结果可以被 entirely 改变。静观检测是一个研究领域，深度卷积神经网络在这个领域中表现出色，但是其可靠性问题吸引了广泛的关注。Brain programming 是一种符号学习，与传统的人工智能有着类似的思想。我们的工作提供了证据，表明符号学习的鲁棒性是设计可靠视觉注意力系统的关键。我们对多个敌意攻击和噪声扰动使用标准数据库和实际问题进行测试，并与五种深度学习方法进行比较。我们发现，深度学习方法在鲁棒性方面不能与符号学习相匹敌。所有神经网络都受到了重大的性能损失，而 brain programming 则保持不变。此外，通过研究雪亚鸥（Snowy Plover），我们强调了野生动物保护和保育活动中的安全问题的重要性。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Conditional-Semi-Paired-Image-to-Image-Translation-For-Multi-Task-Image-Defect-Correction-On-Shopping-Websites"><a href="#Hierarchical-Conditional-Semi-Paired-Image-to-Image-Translation-For-Multi-Task-Image-Defect-Correction-On-Shopping-Websites" class="headerlink" title="Hierarchical Conditional Semi-Paired Image-to-Image Translation For Multi-Task Image Defect Correction On Shopping Websites"></a>Hierarchical Conditional Semi-Paired Image-to-Image Translation For Multi-Task Image Defect Correction On Shopping Websites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05883">http://arxiv.org/abs/2309.05883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moyan Li, Jinmiao Fu, Shaoyuan Xu, Huidong Liu, Jia Liu, Bryan Wang</li>
<li>for:  correggere多种产品图像的 defects （ corrected multiple product image defects）</li>
<li>methods: 使用 Image-to-Image （I2I）翻译模型，具有高级别损害组和具体损害类型的注意机制，以干涯各种产品类型的损害图像。（ using an Image-to-Image translation model with an attention mechanism to correct multiple defects of different product types）</li>
<li>results: 相比MONCE，our model reduces the Frechet Inception Distance（FID）by 24.6% on average，并在一个商业化的购物网站上降低了FID的平均值by 63.2% compared with WS-I2I。（ compared with MONCE, our model reduces the Frechet Inception Distance by 24.6% on average, and reduces the average value of FID by 63.2% on a commercial shopping website）<details>
<summary>Abstract</summary>
On shopping websites, product images of low quality negatively affect customer experience. Although there are plenty of work in detecting images with different defects, few efforts have been dedicated to correct those defects at scale. A major challenge is that there are thousands of product types and each has specific defects, therefore building defect specific models is unscalable. In this paper, we propose a unified Image-to-Image (I2I) translation model to correct multiple defects across different product types. Our model leverages an attention mechanism to hierarchically incorporate high-level defect groups and specific defect types to guide the network to focus on defect-related image regions. Evaluated on eight public datasets, our model reduces the Frechet Inception Distance (FID) by 24.6% in average compared with MoNCE, the state-of-the-art I2I method. Unlike public data, another practical challenge on shopping websites is that some paired images are of low quality. Therefore we design our model to be semi-paired by combining the L1 loss of paired data with the cycle loss of unpaired data. Tested on a shopping website dataset to correct three image defects, our model reduces (FID) by 63.2% in average compared with WS-I2I, the state-of-the art semi-paired I2I method.
</details>
<details>
<summary>摘要</summary>
在购物网站上，产品图像质量低下影响用户体验。尽管有很多研究检测不同损害的图像，但几乎没有努力用于大规模修复这些损害。主要挑战是每种产品都有特定的损害类型，因此建立特定损害模型是不可能的。在这篇论文中，我们提出了一种通用的图像到图像（I2I）翻译模型，用于修复不同产品类型的多个损害。我们的模型利用注意力机制，将高级损害组和特定损害类型注入到网络中，以便指导网络专注于图像中的损害关键区域。经过八个公共数据集的评估，我们的模型与MoNCE，当前I2I方法的状态OF THE ARTS，相比下降24.6%的Frechet Inception Distance（FID）。与公共数据不同的另一个实际挑战是，一些购物网站上的对应图像质量较低。因此我们设计了我们的模型为半相对的，将L1损失与相对损失结合在一起。在一个购物网站数据集上测试，我们的模型可以降低（FID）的平均值为63.2%，相比WS-I2I，当前半相对I2I方法的状态OF THE ARTS。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Attacks-on-Face-Verification-Systems"><a href="#Generalized-Attacks-on-Face-Verification-Systems" class="headerlink" title="Generalized Attacks on Face Verification Systems"></a>Generalized Attacks on Face Verification Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05879">http://arxiv.org/abs/2309.05879</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Nazari, Paula Branco, Guy-Vincent Jourdan</li>
<li>for: 本研究的目的是对Face Verification（FV）系统进行深入的研究，特别是对FV系统受到的攻击进行分类和分析。</li>
<li>methods: 本研究使用了深度神经网络模型，并提出了一种新的攻击方法 called DodgePersonation Attack，可以在FV系统中创造出可以欺骗人类识别的面部图像。此外，本研究还提出了一种新的攻击分类方法，可以帮助更好地理解和防范FV系统受到的攻击。</li>
<li>results: 本研究的结果显示，DodgePersonation Attack可以在一个well-known scenario中实现state-of-the-art的性能，可以创造出9张图像，覆盖43.82%的身份。此外，本研究还发现，使用9张图像可以覆盖57.27%到58.5%的身份，并且这些图像看起来都是完全一致的。<details>
<summary>Abstract</summary>
Face verification (FV) using deep neural network models has made tremendous progress in recent years, surpassing human accuracy and seeing deployment in various applications such as border control and smartphone unlocking. However, FV systems are vulnerable to Adversarial Attacks, which manipulate input images to deceive these systems in ways usually unnoticeable to humans. This paper provides an in-depth study of attacks on FV systems. We introduce the DodgePersonation Attack that formulates the creation of face images that impersonate a set of given identities while avoiding being identified as any of the identities in a separate, disjoint set. A taxonomy is proposed to provide a unified view of different types of Adversarial Attacks against FV systems, including Dodging Attacks, Impersonation Attacks, and Master Face Attacks. Finally, we propose the ''One Face to Rule Them All'' Attack which implements the DodgePersonation Attack with state-of-the-art performance on a well-known scenario (Master Face Attack) and which can also be used for the new scenarios introduced in this paper. While the state-of-the-art Master Face Attack can produce a set of 9 images to cover 43.82% of the identities in their test database, with 9 images our attack can cover 57.27% to 58.5% of these identifies while giving the attacker the choice of the identity to use to create the impersonation. Moreover, the 9 generated attack images appear identical to a casual observer.
</details>
<details>
<summary>摘要</summary>
面部验证（FV）使用深度神经网络模型已经在最近几年内做出了巨大的进步，超过了人类准确率并在不同的应用中部署，如边境控制和智能手机锁定。然而，FV系统受到了抗击攻击的威胁，这些攻击可以通过修改输入图像来让FV系统错误地认为图像是其他人的。本文提供了FV系统攻击的深入研究，我们介绍了创建一个名为“掩饰人格攻击”的新攻击方法，该方法可以在不同的人脸库中创建一个掩饰人格，以避免被识别为任何其他人的人。此外，我们还提出了一种攻击分类法，以提供对FV系统攻击的一般视角，包括掩饰攻击、冒充攻击和主人脸攻击。最后，我们提出了一种“一个人脸征服全部”的攻击，该攻击可以在一个已知的enario（主人脸攻击）中实现state-of-the-art性能，并且可以在新提出的scenario中使用。而现状的主人脸攻击可以生成9张图像，覆盖43.82%的人脸库，而我们的攻击可以生成9张图像，覆盖57.27%到58.5%的人脸库，同时给攻击者选择创建假装的人脸。此外，生成的9张攻击图像都看起来都是一般人类无法分辨的。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/12/cs.CV_2023_09_12/" data-id="clohum97k00hlpj88b30q0tn4" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/12/cs.AI_2023_09_12/" class="article-date">
  <time datetime="2023-09-12T12:00:00.000Z" itemprop="datePublished">2023-09-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/12/cs.AI_2023_09_12/">cs.AI - 2023-09-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Quantum-Data-Center-Perspectives"><a href="#Quantum-Data-Center-Perspectives" class="headerlink" title="Quantum Data Center: Perspectives"></a>Quantum Data Center: Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06641">http://arxiv.org/abs/2309.06641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyu Liu, Liang Jiang</li>
<li>for:  quantum computing, communication, and sensing</li>
<li>methods:  combining Quantum Random Access Memory (QRAM) and quantum networks</li>
<li>results:  significant benefits in efficiency, security, and precision for customers, with potential scientific and business opportunities in machine learning and big data industries.Here’s the text in Simplified Chinese:</li>
<li>for: 量子计算、量子通信和量子探测</li>
<li>methods: 结合量子随机访问存储器（QRAM）和量子网络</li>
<li>results: 为客户提供高效、安全、精度的 significative benefits，在机器学习和大数据行业中探讨可能的科学和商业机遇。<details>
<summary>Abstract</summary>
A quantum version of data centers might be significant in the quantum era. In this paper, we introduce Quantum Data Center (QDC), a quantum version of existing classical data centers, with a specific emphasis on combining Quantum Random Access Memory (QRAM) and quantum networks. We argue that QDC will provide significant benefits to customers in terms of efficiency, security, and precision, and will be helpful for quantum computing, communication, and sensing. We investigate potential scientific and business opportunities along this novel research direction through hardware realization and possible specific applications. We show the possible impacts of QDCs in business and science, especially the machine learning and big data industries.
</details>
<details>
<summary>摘要</summary>
一个量子版的数据中心可能在量子时代具有重要意义。在这篇论文中，我们介绍量子数据中心（QDC），量子版的现有古典数据中心，强调将量子随机访问存储（QRAM）和量子网络结合使用。我们认为QDC将为客户提供高效、安全和精度的好处，并将对量子计算、通信和探测做出重要贡献。我们通过硬件实现和可能的具体应用来研究这一新的研究方向的科学和商业机会。我们展示了QDC在业务和科学领域的可能的影响，特别是机器学习和大数据领域。
</details></li>
</ul>
<hr>
<h2 id="The-Relational-Bottleneck-as-an-Inductive-Bias-for-Efficient-Abstraction"><a href="#The-Relational-Bottleneck-as-an-Inductive-Bias-for-Efficient-Abstraction" class="headerlink" title="The Relational Bottleneck as an Inductive Bias for Efficient Abstraction"></a>The Relational Bottleneck as an Inductive Bias for Efficient Abstraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06629">http://arxiv.org/abs/2309.06629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taylor W. Webb, Steven M. Frankland, Awni Altabaa, Kamesh Krishnamurthy, Declan Campbell, Jacob Russin, Randall O’Reilly, John Lafferty, Jonathan D. Cohen</li>
<li>for: 本研究旨在解释如何从有限经验中获得抽象概念。</li>
<li>methods: 本研究使用了一种新的方法，即利用 inductive bias 来从数据中引出抽象。</li>
<li>results: 研究表明，这种方法可以在数据效率的情况下induce抽象，并且可能是人类大脑中抽象概念的获得的机制。<details>
<summary>Abstract</summary>
A central challenge for cognitive science is to explain how abstract concepts are acquired from limited experience. This effort has often been framed in terms of a dichotomy between empiricist and nativist approaches, most recently embodied by debates concerning deep neural networks and symbolic cognitive models. Here, we highlight a recently emerging line of work that suggests a novel reconciliation of these approaches, by exploiting an inductive bias that we term the relational bottleneck. We review a family of models that employ this approach to induce abstractions in a data-efficient manner, emphasizing their potential as candidate models for the acquisition of abstract concepts in the human mind and brain.
</details>
<details>
<summary>摘要</summary>
中心挑战是让抽象概念从有限经验中获得。这一努力 часто被划分为经验主义和Native主义方法，最近在深度神经网络和符号认知模型之间展开了讨论。我们在这里强调一种新出现的工作，通过利用我们称为关系瓶颈的推理偏好来解决这一问题。我们评论了一家族模型，这些模型通过这种方法来从数据有效地获得抽象，强调它们在人类大脑和脑中抽象概念的获得中的潜在作用。
</details></li>
</ul>
<hr>
<h2 id="A-Reinforcement-Learning-Approach-for-Robotic-Unloading-from-Visual-Observations"><a href="#A-Reinforcement-Learning-Approach-for-Robotic-Unloading-from-Visual-Observations" class="headerlink" title="A Reinforcement Learning Approach for Robotic Unloading from Visual Observations"></a>A Reinforcement Learning Approach for Robotic Unloading from Visual Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06621">http://arxiv.org/abs/2309.06621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vittoriogiammarino/rl-for-unloading-from-pixels">https://github.com/vittoriogiammarino/rl-for-unloading-from-pixels</a></li>
<li>paper_authors: Vittorio Giammarino, Alberto Giammarino, Matthew Pearce</li>
<li>For: 本研究强调使用视觉输入自动解压包裹问题，以便机器人可以通过RGB-D图像来学习无需标注数据。* Methods: 我们提出了一种层次控制结构，其中高级决策模块和传统的运动控制结合在一起。高级模块通过深度征识学习（DRL）进行训练，并采用安全偏好机制和适应于这个任务的奖励函数。* Results: 我们的实验表明，这两个元素都对学习性能产生了关键作用。此外，为确保可重复性和未来研究的标准，我们提供了免费代码和 simulate。<details>
<summary>Abstract</summary>
In this work, we focus on a robotic unloading problem from visual observations, where robots are required to autonomously unload stacks of parcels using RGB-D images as their primary input source. While supervised and imitation learning have accomplished good results in these types of tasks, they heavily rely on labeled data, which are challenging to obtain in realistic scenarios. Our study aims to develop a sample efficient controller framework that can learn unloading tasks without the need for labeled data during the learning process. To tackle this challenge, we propose a hierarchical controller structure that combines a high-level decision-making module with classical motion control. The high-level module is trained using Deep Reinforcement Learning (DRL), wherein we incorporate a safety bias mechanism and design a reward function tailored to this task. Our experiments demonstrate that both these elements play a crucial role in achieving improved learning performance. Furthermore, to ensure reproducibility and establish a benchmark for future research, we provide free access to our code and simulation.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们关注了基于视觉观察的 роботизирован无需卸车问题，Robot需要通过RGB-D图像作为主要输入来自动卸车堆叠的包裹。而supervised学习和模仿学习在这类任务中已经达到了良好的结果，但它们强依赖于实际场景中困难获得的标注数据。我们的研究旨在开发一种样本效率高的控制框架，可以在学习过程中不需要标注数据。为此，我们提议一种层次控制结构， combining高级决策模块和传统的运动控制。高级模块通过深度循环学习（DRL）进行训练，并在这个过程中添加了安全偏好机制和适应到这个任务的奖励函数。我们的实验表明，这两个元素具有重要的作用，可以提高学习性能。此外，为确保可重现性和建立未来研究的标准，我们提供了免费的代码和 simulations。
</details></li>
</ul>
<hr>
<h2 id="CloudBrain-NMR-An-Intelligent-Cloud-Computing-Platform-for-NMR-Spectroscopy-Processing-Reconstruction-and-Analysis"><a href="#CloudBrain-NMR-An-Intelligent-Cloud-Computing-Platform-for-NMR-Spectroscopy-Processing-Reconstruction-and-Analysis" class="headerlink" title="CloudBrain-NMR: An Intelligent Cloud Computing Platform for NMR Spectroscopy Processing, Reconstruction and Analysis"></a>CloudBrain-NMR: An Intelligent Cloud Computing Platform for NMR Spectroscopy Processing, Reconstruction and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07178">http://arxiv.org/abs/2309.07178</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Guo, Sijin Li, Jun Liu, Zhangren Tu, Tianyu Qiu, Jingjing Xu, Liubin Feng, Donghai Lin, Qing Hong, Meijin Lin, Yanqin Lin, Xiaobo Qu</li>
<li>for: 这个研究的目的是提供一个智能在线云计算平台，用于核磁共振（NMR）数据处理、重构和定量分析。</li>
<li>methods: 该平台使用并行计算和图形处理器（GPU）&#x2F;中央处理器（CPU）的分布式计算技术，以提高计算效率和简化用户的操作。另外，它还 integrate了当前最佳的深度学习算法，以提供完整的处理过程，使用户无需安装其他软件。</li>
<li>results: 该平台可以快速地处理大量的NMR数据，并提供高精度的定量分析结果。此外，它还具有开放的API，可以让用户根据需要选择不同的处理流程和深度学习算法。<details>
<summary>Abstract</summary>
Nuclear Magnetic Resonance (NMR) spectroscopy has served as a powerful analytical tool for studying molecular structure and dynamics in chemistry and biology. However, the processing of raw data acquired from NMR spectrometers and subsequent quantitative analysis involves various specialized tools, which necessitates comprehensive knowledge in programming and NMR. Particularly, the emerging deep learning tools is hard to be widely used in NMR due to the sophisticated setup of computation. Thus, NMR processing is not an easy task for chemist and biologists. In this work, we present CloudBrain-NMR, an intelligent online cloud computing platform designed for NMR data reading, processing, reconstruction, and quantitative analysis. The platform is conveniently accessed through a web browser, eliminating the need for any program installation on the user side. CloudBrain-NMR uses parallel computing with graphics processing units and central processing units, resulting in significantly shortened computation time. Furthermore, it incorporates state-of-the-art deep learning-based algorithms offering comprehensive functionalities that allow users to complete the entire processing procedure without relying on additional software. This platform has empowered NMR applications with advanced artificial intelligence processing. CloudBrain-NMR is openly accessible for free usage at https://csrc.xmu.edu.cn/CloudBrain.html
</details>
<details>
<summary>摘要</summary>
核磁共振（NMR）分析是化学和生物研究中的一种强大工具，但是从NMR仪器上获取的原始数据处理和后续的量化分析需要各种专门的工具，这需要深入的编程和NMR知识。特别是在深度学习工具出现之前，NMR处理是非常困难的。为了解决这问题，我们提出了CloudBrain-NMR，一个基于云计算的智能在线平台，用于NMR数据的读取、处理、重构和量化分析。该平台通过浏览器访问，不需要用户安装任何软件。CloudBrain-NMR使用并行计算和图形处理器，实现了明显缩短计算时间。此外，它还包含了最新的深度学习算法，提供了全面的功能，让用户可以完成整个处理过程，不需要靠其他软件。这使得NMR应用程序得到了高级人工智能处理的 empowerment。CloudBrain-NMR是免费开放的，可以在https://csrc.xmu.edu.cn/CloudBrain.html中免费使用。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Algorithm-Selection-and-Hyperparameter-Tuning-on-Distributed-Machine-Learning-Resources-A-Hierarchical-Agent-based-Approach"><a href="#Hybrid-Algorithm-Selection-and-Hyperparameter-Tuning-on-Distributed-Machine-Learning-Resources-A-Hierarchical-Agent-based-Approach" class="headerlink" title="Hybrid Algorithm Selection and Hyperparameter Tuning on Distributed Machine Learning Resources: A Hierarchical Agent-based Approach"></a>Hybrid Algorithm Selection and Hyperparameter Tuning on Distributed Machine Learning Resources: A Hierarchical Agent-based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06604">http://arxiv.org/abs/2309.06604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Esmaeili, Julia T. Rayz, Eric T. Matson</li>
<li>for: This paper proposes a fully automatic and collaborative agent-based mechanism for selecting distributedly organized machine learning algorithms and simultaneously tuning their hyperparameters.</li>
<li>methods: The proposed method builds upon an existing agent-based hierarchical machine-learning platform and augments its query structure to support the aforementioned functionalities without being limited to specific learning, selection, and tuning mechanisms.</li>
<li>results: According to the results, our solution is totally correct and exhibits linear time and space complexity in relation to the size of available resources. The proposed method is also demonstrated to be effective in adapting and performing across a range of algorithmic options and datasets through experiments using a system comprised of 24 algorithms and 9 datasets.<details>
<summary>Abstract</summary>
Algorithm selection and hyperparameter tuning are critical steps in both academic and applied machine learning. On the other hand, these steps are becoming ever increasingly delicate due to the extensive rise in the number, diversity, and distributedness of machine learning resources. Multi-agent systems, when applied to the design of machine learning platforms, bring about several distinctive characteristics such as scalability, flexibility, and robustness, just to name a few. This paper proposes a fully automatic and collaborative agent-based mechanism for selecting distributedly organized machine learning algorithms and simultaneously tuning their hyperparameters. Our method builds upon an existing agent-based hierarchical machine-learning platform and augments its query structure to support the aforementioned functionalities without being limited to specific learning, selection, and tuning mechanisms. We have conducted theoretical assessments, formal verification, and analytical study to demonstrate the correctness, resource utilization, and computational efficiency of our technique. According to the results, our solution is totally correct and exhibits linear time and space complexity in relation to the size of available resources. To provide concrete examples of how the proposed methodologies can effectively adapt and perform across a range of algorithmic options and datasets, we have also conducted a series of experiments using a system comprised of 24 algorithms and 9 datasets.
</details>
<details>
<summary>摘要</summary>
algorithm 选择和超参数调整是学术应用机器学习中的关键步骤，然而这些步骤正在不断增加、多样化和分布化机器学习资源的情况下变得越来越细腻。在机器学习平台的设计中，多智能体系统带来了规模、灵活性和稳定性等特点。本文提出了一种完全自动和协作的智能体基于机制，用于分布式组织机器学习算法和同时调整其超参数。我们的方法基于现有的智能体层次机器学习平台，并将其查询结构改进以支持上述功能性能不受特定学习、选择和调整机制限制。我们已经进行了理论评估、正式验证和分析研究，以证明我们的技术是完全正确的，并且在资源大小的情况下具有线性时间和空间复杂度。为了让读者更好地理解我们的方法在不同算法和数据集上的应用和效果，我们还进行了一系列实验，使用了24种算法和9个数据集。
</details></li>
</ul>
<hr>
<h2 id="Rank2Tell-A-Multimodal-Driving-Dataset-for-Joint-Importance-Ranking-and-Reasoning"><a href="#Rank2Tell-A-Multimodal-Driving-Dataset-for-Joint-Importance-Ranking-and-Reasoning" class="headerlink" title="Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and Reasoning"></a>Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06597">http://arxiv.org/abs/2309.06597</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enna Sachdeva, Nakul Agarwal, Suhas Chundi, Sean Roelofs, Jiachen Li, Behzad Dariush, Chiho Choi, Mykel Kochenderfer</li>
<li>for: 这篇论文的目的是提高自动驾驶车和高级驾驶支持系统的社会接受度，以便实现其广泛应用。</li>
<li>methods: 这篇论文使用了一种新的多模态 egocentric 数据集，即 Rank2Tell，来评估和描述复杂交通场景中重要对象的含义水平和原因。它还提出了一种联合模型，用于同时评估对象的重要程度和自然语言描述。</li>
<li>results: 根据论文的描述，Rank2Tell 数据集和联合模型在视觉场景理解和相关领域中提供了一个有价值的资源，并在量化评估中达到了高水平的性能。<details>
<summary>Abstract</summary>
The widespread adoption of commercial autonomous vehicles (AVs) and advanced driver assistance systems (ADAS) may largely depend on their acceptance by society, for which their perceived trustworthiness and interpretability to riders are crucial. In general, this task is challenging because modern autonomous systems software relies heavily on black-box artificial intelligence models. Towards this goal, this paper introduces a novel dataset, Rank2Tell, a multi-modal ego-centric dataset for Ranking the importance level and Telling the reason for the importance. Using various close and open-ended visual question answering, the dataset provides dense annotations of various semantic, spatial, temporal, and relational attributes of various important objects in complex traffic scenarios. The dense annotations and unique attributes of the dataset make it a valuable resource for researchers working on visual scene understanding and related fields. Further, we introduce a joint model for joint importance level ranking and natural language captions generation to benchmark our dataset and demonstrate performance with quantitative evaluations.
</details>
<details>
<summary>摘要</summary>
广泛采用商业自动驾驶车（AV）和高级驾驶助手系统（ADAS）的普及可能受到社会的接受程度的限制，这个任务的难度在于现代自动驾驶系统软件借助黑盒人工智能模型。为达到这个目标，本文提出了一个新的数据集，即 Rank2Tell，这是一个多模态自我中心数据集，用于评估对象的重要性水平和说明其重要性的原因。该数据集通过多种close和开放式视觉问答来提供各种语义、空间、时间和关系特征的精密注释，使其成为研究视觉Scene理解和相关领域的价值资源。此外，我们还引入了一种共同模型，用于同时评估对象的重要性水平和生成自然语言描述，以 benchmark我们的数据集并进行评估性评价。
</details></li>
</ul>
<hr>
<h2 id="Do-Generative-Large-Language-Models-need-billions-of-parameters"><a href="#Do-Generative-Large-Language-Models-need-billions-of-parameters" class="headerlink" title="Do Generative Large Language Models need billions of parameters?"></a>Do Generative Large Language Models need billions of parameters?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06589">http://arxiv.org/abs/2309.06589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sia Gholami, Marwan Omar</li>
<li>for: 这个论文是为了开发高效的大语言模型（LLMs）而写的。</li>
<li>methods: 这篇论文探索了模型大小、性能和计算资源之间的贸易协议，以实现LLMs的高效性。它提出了新的方法，让不同的模型部分共享参数，从而减少总的唯一参数数量。这种方法可以保证模型尽量减少大小而不丢失复杂语言结构的学习和表示能力。</li>
<li>results: 这项研究提供了创新的工具和方法，可以创造更高效和有效的LLMs，为AI语言模型的可持续发展和普及做出了贡献。<details>
<summary>Abstract</summary>
This paper presents novel systems and methodologies for the development of efficient large language models (LLMs). It explores the trade-offs between model size, performance, and computational resources, with the aim of maximizing the efficiency of these AI systems. The research explores novel methods that allow different parts of the model to share parameters, reducing the total number of unique parameters required. This approach ensures that the model remains compact without sacrificing its ability to learn and represent complex language structures. This study provides valuable insights and tools for creating more efficient and effective LLMs, contributing to a more sustainable and accessible future for AI language modeling.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "efficient" is translated as "高效" (gāo yè)* "large language models" is translated as "大型语言模型" (dà xíng yǔ yán módel)* "trade-offs" is translated as "负担" (zhāng dāng)* "compact" is translated as "减少" (jiǎn shǎo)* "sustainable" is translated as "可持续" (kě chéng xù)* "accessible" is translated as "可达" (kě dà)
</details></li>
</ul>
<hr>
<h2 id="HurriCast-An-Automatic-Framework-Using-Machine-Learning-and-Statistical-Modeling-for-Hurricane-Forecasting"><a href="#HurriCast-An-Automatic-Framework-Using-Machine-Learning-and-Statistical-Modeling-for-Hurricane-Forecasting" class="headerlink" title="HurriCast: An Automatic Framework Using Machine Learning and Statistical Modeling for Hurricane Forecasting"></a>HurriCast: An Automatic Framework Using Machine Learning and Statistical Modeling for Hurricane Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07174">http://arxiv.org/abs/2309.07174</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shouwei Gao, Meiyan Gao, Yuepeng Li, Wenqian Dong</li>
<li>for: 这个研究旨在提高飓风风险评估模型，以更好地预测飓风的发展趋势和强度。</li>
<li>methods: 该研究使用了ARIMA模型和K-MEANS算法，以及自适应神经网络，对飓风趋势和强度进行更加精准的预测。</li>
<li>results: 实验表明，这种混合方法可以准确地模拟历史飓风行为，并提供详细的未来轨迹和强度预测，对风险管理策略提供了有价值的参考。<details>
<summary>Abstract</summary>
Hurricanes present major challenges in the U.S. due to their devastating impacts. Mitigating these risks is important, and the insurance industry is central in this effort, using intricate statistical models for risk assessment. However, these models often neglect key temporal and spatial hurricane patterns and are limited by data scarcity. This study introduces a refined approach combining the ARIMA model and K-MEANS to better capture hurricane trends, and an Autoencoder for enhanced hurricane simulations. Our experiments show that this hybrid methodology effectively simulate historical hurricane behaviors while providing detailed projections of potential future trajectories and intensities. Moreover, by leveraging a comprehensive yet selective dataset, our simulations enrich the current understanding of hurricane patterns and offer actionable insights for risk management strategies.
</details>
<details>
<summary>摘要</summary>
飓风在美国 pose 严重挑战，因为它们可能导致毁灭性的影响。为了降低这些风险，保险业是关键的，使用复杂的统计模型进行风险评估。然而，这些模型经常忽略风暴的时间和空间特征，并且由于数据缺乏，受限于。本研究提出了一种改进的方法，结合ARIMA模型和K-MEANS，以更好地捕捉风暴趋势，并使用自适应神经网络进行增强的风暴模拟。我们的实验表明，这种混合方法可以准确地模拟历史风暴行为，并提供详细的未来轨迹和强度预测。此外，通过利用全面而选择性的数据集，我们的模拟提高了现有风暴模式的理解，并提供了有价值的风险管理策略。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Multi-Task-Learning-Framework-for-Session-based-Recommendations"><a href="#Hierarchical-Multi-Task-Learning-Framework-for-Session-based-Recommendations" class="headerlink" title="Hierarchical Multi-Task Learning Framework for Session-based Recommendations"></a>Hierarchical Multi-Task Learning Framework for Session-based Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06533">http://arxiv.org/abs/2309.06533</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sejoon Oh, Walid Shalaby, Amir Afsharinejad, Xiquan Cui</li>
<li>for: 提高Session-based recommendation系统（SBRS）的预测精度和普适性。</li>
<li>methods: 使用层次多任务学习（H-MTL）架构，将预测任务与auxiliary任务设置在层次结构之间，从auxiliary任务中获得更多的输入特征，提高预测结果的可解释性。</li>
<li>results: 在两个Session-based recommendation数据集上，HierSRec比既有SBRS的next-item预测精度高，并且针对手动生成的候选项（例如4%的总ITEMS）进行可扩展的推理。<details>
<summary>Abstract</summary>
While session-based recommender systems (SBRSs) have shown superior recommendation performance, multi-task learning (MTL) has been adopted by SBRSs to enhance their prediction accuracy and generalizability further. Hierarchical MTL (H-MTL) sets a hierarchical structure between prediction tasks and feeds outputs from auxiliary tasks to main tasks. This hierarchy leads to richer input features for main tasks and higher interpretability of predictions, compared to existing MTL frameworks. However, the H-MTL framework has not been investigated in SBRSs yet. In this paper, we propose HierSRec which incorporates the H-MTL architecture into SBRSs. HierSRec encodes a given session with a metadata-aware Transformer and performs next-category prediction (i.e., auxiliary task) with the session encoding. Next, HierSRec conducts next-item prediction (i.e., main task) with the category prediction result and session encoding. For scalable inference, HierSRec creates a compact set of candidate items (e.g., 4% of total items) per test example using the category prediction. Experiments show that HierSRec outperforms existing SBRSs as per next-item prediction accuracy on two session-based recommendation datasets. The accuracy of HierSRec measured with the carefully-curated candidate items aligns with the accuracy of HierSRec calculated with all items, which validates the usefulness of our candidate generation scheme via H-MTL.
</details>
<details>
<summary>摘要</summary>
session-based recommender systems (SBRSs) 已经显示出了更高的推荐性能，但是多任务学习 (MTL) 已经被 SBRSs 采用以进一步提高其预测精度和泛化性。层次多任务学习 (H-MTL) 设置了一个层次结构 между预测任务和输出 auxiliary tasks 的输出。这个层次结构导致主任务的输入特征更加丰富，并且提高了预测结果的解释性，相比既有MTL框架。然而，H-MTL 框架在 SBRSs 中尚未被研究。在这篇论文中，我们提出了 HierSRec，它将 H-MTL 框架应用于 SBRSs。HierSRec 使用 metadata-aware Transformer 对给定的会话进行编码，然后使用会话编码进行下一个类型预测（即 auxiliary task）。接着，HierSRec 使用类型预测结果和会话编码进行下一个项目预测（即 main task）。为了可扩展的推理，HierSRec 创建了一个紧凑的候选项列表（例如，4% 的总项）每个测试示例，使用类型预测结果进行筛选。实验结果显示，HierSRec 在两个会话基于推荐数据集上的下一个项目预测精度上表现出色，与现有 SBRSs 相比。HierSRec 测试结果与我们精心准备的候选项列表相关，证明了我们的候选生成方案的有用性。
</details></li>
</ul>
<hr>
<h2 id="Minimum-Bayes’-Risk-Decoding-for-System-Combination-of-Grammatical-Error-Correction-Systems"><a href="#Minimum-Bayes’-Risk-Decoding-for-System-Combination-of-Grammatical-Error-Correction-Systems" class="headerlink" title="Minimum Bayes’ Risk Decoding for System Combination of Grammatical Error Correction Systems"></a>Minimum Bayes’ Risk Decoding for System Combination of Grammatical Error Correction Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06520">http://arxiv.org/abs/2309.06520</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rainavyas/mbr_gec">https://github.com/rainavyas/mbr_gec</a></li>
<li>paper_authors: Vyas Raina, Mark Gales</li>
<li>for: 这个论文主要是为了提高grammatical error correction（GEC）系统的性能，具体来说是通过最小 bayes 风险（MBR）解码方法来改善系统输出的匹配度。</li>
<li>methods: 这篇论文使用的方法包括：MBR解码方法、current max-voting combination scheme、individual edit-level selection、以及不同的奖励度量在 MBR 解码框架中的应用。</li>
<li>results: 实验结果表明，使用提议的 MBR 解码方法可以提高 GEC 系统的性能，并且可以通过调整奖励度量来控制系统的精度、准确率和 F-score。<details>
<summary>Abstract</summary>
For sequence-to-sequence tasks it is challenging to combine individual system outputs. Further, there is also often a mismatch between the decoding criterion and the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used to combine system outputs in a manner that encourages better alignment with the final assessment criterion. This paper examines MBR decoding for Grammatical Error Correction (GEC) systems, where performance is usually evaluated in terms of edits and an associated F-score. Hence, we propose a novel MBR loss function directly linked to this form of criterion. Furthermore, an approach to expand the possible set of candidate sentences is described. This builds on a current max-voting combination scheme, as well as individual edit-level selection. Experiments on three popular GEC datasets and with state-of-the-art GEC systems demonstrate the efficacy of the proposed MBR approach. Additionally, the paper highlights how varying reward metrics within the MBR decoding framework can provide control over precision, recall, and the F-score in combined GEC systems.
</details>
<details>
<summary>摘要</summary>
For sequence-to-sequence tasks, it is challenging to combine individual system outputs. Furthermore, there is often a mismatch between the decoding criterion and the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used to combine system outputs in a manner that encourages better alignment with the final assessment criterion. This paper examines MBR decoding for Grammatical Error Correction (GEC) systems, where performance is usually evaluated in terms of edits and an associated F-score. Therefore, we propose a novel MBR loss function directly linked to this form of criterion. Additionally, an approach to expand the possible set of candidate sentences is described. This builds on a current max-voting combination scheme, as well as individual edit-level selection. Experiments on three popular GEC datasets and with state-of-the-art GEC systems demonstrate the efficacy of the proposed MBR approach. Moreover, the paper highlights how varying reward metrics within the MBR decoding framework can provide control over precision, recall, and the F-score in combined GEC systems.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Learning-Disentangled-Avatars-with-Hybrid-3D-Representations"><a href="#Learning-Disentangled-Avatars-with-Hybrid-3D-Representations" class="headerlink" title="Learning Disentangled Avatars with Hybrid 3D Representations"></a>Learning Disentangled Avatars with Hybrid 3D Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06441">http://arxiv.org/abs/2309.06441</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yfeng95/DELTA">https://github.com/yfeng95/DELTA</a></li>
<li>paper_authors: Yao Feng, Weiyang Liu, Timo Bolkart, Jinlong Yang, Marc Pollefeys, Michael J. Black</li>
<li>for: 本研究旨在实现可动画化和真实化人类模拟器。</li>
<li>methods: 本paper使用混合explicit-implicit 3D表示方法，即DELTA方法，将人类模拟器分解成不同部分的mesh和神经网络频谱场。</li>
<li>results: 本paper实现了人类模拟器的分解，并在不同应用中表现出色，如分解人体和服装、分解面孔和头发等。此外，paper还发现了可以将头发和服装转移到不同的身体形态上。<details>
<summary>Abstract</summary>
Tremendous efforts have been made to learn animatable and photorealistic human avatars. Towards this end, both explicit and implicit 3D representations are heavily studied for a holistic modeling and capture of the whole human (e.g., body, clothing, face and hair), but neither representation is an optimal choice in terms of representation efficacy since different parts of the human avatar have different modeling desiderata. For example, meshes are generally not suitable for modeling clothing and hair. Motivated by this, we present Disentangled Avatars~(DELTA), which models humans with hybrid explicit-implicit 3D representations. DELTA takes a monocular RGB video as input, and produces a human avatar with separate body and clothing/hair layers. Specifically, we demonstrate two important applications for DELTA. For the first one, we consider the disentanglement of the human body and clothing and in the second, we disentangle the face and hair. To do so, DELTA represents the body or face with an explicit mesh-based parametric 3D model and the clothing or hair with an implicit neural radiance field. To make this possible, we design an end-to-end differentiable renderer that integrates meshes into volumetric rendering, enabling DELTA to learn directly from monocular videos without any 3D supervision. Finally, we show that how these two applications can be easily combined to model full-body avatars, such that the hair, face, body and clothing can be fully disentangled yet jointly rendered. Such a disentanglement enables hair and clothing transfer to arbitrary body shapes. We empirically validate the effectiveness of DELTA's disentanglement by demonstrating its promising performance on disentangled reconstruction, virtual clothing try-on and hairstyle transfer. To facilitate future research, we also release an open-sourced pipeline for the study of hybrid human avatar modeling.
</details>
<details>
<summary>摘要</summary>
很大的努力已经投入到了人类动画和实际化人物模型的学习中。在这个领域，both explicit和implicit的3D表示都被广泛研究，以实现人类整体模型化和捕捉（例如，身体、衣服和头发），但 neither representation是优选的选择，因为不同的人物部分有不同的模型需求。例如，网格不适用于衣服和头发的模型。这种情况下，我们提出了Disentangled Avatars（DELTA），它使用了混合的explicit-implicit 3D表示来模型人类。DELTA通过一个灰度RGB视频输入，生成了一个人物模型，其中包括身体和衣服/头发层。具体来说，我们展示了两个重要的应用场景。在第一个应用场景中，我们考虑了人体和衣服的分离，在第二个应用场景中，我们分离了面孔和头发。为了实现这些应用场景，DELTA使用了一种由网格和神经辐射场组成的混合表示方法。为了实现这种方法，我们设计了一个端到端可微 differentiable 渲染器，该渲染器将网格 integrate into volumetric rendering，以便DELTA可以直接从灰度视频中学习，不需要任何3D监督。最后，我们表明了如何将这两个应用场景结合起来，以实现全身人物模型的分离和重新渲染。这种分离允许头发和衣服进行到任何身体形状的转移。我们通过实验证明了DELTA的分离性能的表现，包括分离重建、虚拟服装尝试和头发样式传输。为了促进未来的研究，我们还发布了一个开源的人类动画模型研究管道。
</details></li>
</ul>
<hr>
<h2 id="LEAP-Hand-Low-Cost-Efficient-and-Anthropomorphic-Hand-for-Robot-Learning"><a href="#LEAP-Hand-Low-Cost-Efficient-and-Anthropomorphic-Hand-for-Robot-Learning" class="headerlink" title="LEAP Hand: Low-Cost, Efficient, and Anthropomorphic Hand for Robot Learning"></a>LEAP Hand: Low-Cost, Efficient, and Anthropomorphic Hand for Robot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06440">http://arxiv.org/abs/2309.06440</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kenneth Shaw, Ananye Agarwal, Deepak Pathak</li>
<li>for: 这 paper 的目的是为了提供一种低成本的、人工智能研究用的多功能手。</li>
<li>methods: 这 paper 使用了一种新的机械结构，使得手臂在不同的手势状态下仍能保持最大的dexterity。此外，paper 还使用了 Machine Learning 技术进行 manipulate 任务的学习。</li>
<li>results: 这 paper 的实验结果表明，LEAP Hand 可以在真实世界中完成多种抓取任务，包括视觉 теле操作和学习从无动视频数据。LEAP Hand 在所有实验中都表现出色，而且与最近的竞争对手 Allegro Hand 相比，它的成本为 1&#x2F;8。<details>
<summary>Abstract</summary>
Dexterous manipulation has been a long-standing challenge in robotics. While machine learning techniques have shown some promise, results have largely been currently limited to simulation. This can be mostly attributed to the lack of suitable hardware. In this paper, we present LEAP Hand, a low-cost dexterous and anthropomorphic hand for machine learning research. In contrast to previous hands, LEAP Hand has a novel kinematic structure that allows maximal dexterity regardless of finger pose. LEAP Hand is low-cost and can be assembled in 4 hours at a cost of 2000 USD from readily available parts. It is capable of consistently exerting large torques over long durations of time. We show that LEAP Hand can be used to perform several manipulation tasks in the real world -- from visual teleoperation to learning from passive video data and sim2real. LEAP Hand significantly outperforms its closest competitor Allegro Hand in all our experiments while being 1/8th of the cost. We release detailed assembly instructions, the Sim2Real pipeline and a development platform with useful APIs on our website at https://leap-hand.github.io/
</details>
<details>
<summary>摘要</summary>
dexterous 操作已经是机器人领域的长期挑战。虽然机器学习技术已经显示了一定的承诺，但结果主要受到硬件的限制。在这篇论文中，我们介绍了LEAP手，一个低成本的手臂，用于机器学习研究。与之前的手臂不同，LEAP手具有新的骨骼结构，允许无论手指pose都能够达到最大的dexterity。LEAP手是低成本的，可以在4小时内为2000美元组装，使用可得到的部件。它可以在长时间内一直承受大的扭矩。我们表明LEAP手可以在真实世界中完成多种操作任务，从视觉操作到学习从无动视频数据和sim2real。LEAP手在所有实验中都能够superior于Allegro手，而且只有1/8的成本。我们在网站https://leap-hand.github.io/上发布了详细的组装指南，Sim2Real管道和开发平台，以及有用的API。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-potential-of-large-language-models-in-generating-semantic-and-cross-language-clones"><a href="#Unveiling-the-potential-of-large-language-models-in-generating-semantic-and-cross-language-clones" class="headerlink" title="Unveiling the potential of large language models in generating semantic and cross-language clones"></a>Unveiling the potential of large language models in generating semantic and cross-language clones</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06424">http://arxiv.org/abs/2309.06424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Palash R. Roy, Ajmain I. Alam, Farouq Al-omari, Banani Roy, Chanchal K. Roy, Kevin A. Schneider</li>
<li>for: 这个论文主要目的是研究使用OpenAI的GPT模型进行semantic和cross-language代码副本生成，以便代码重用、代码理解、重构和性能测试。</li>
<li>methods: 该论文使用了SemanticCloneBench作为测试平台，通过对一系列代码片段进行评估，以评估GPT-3模型在生成代码副本方面的性能。</li>
<li>results: 研究发现，GPT-3模型在生成semantic和cross-language代码副本方面具有出色的表现，其中在semantic clones方面取得了62.14%的准确率和0.55 BLEU分数，在cross-language clones方面达到了91.25%的准确率。<details>
<summary>Abstract</summary>
Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking. OpenAI's GPT model has potential in such clone generation as GPT is used for text generation. When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours. Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance. In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.We have comprised a diverse set of code fragments and assessed GPT-3s performance in generating code variants.Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate the model's ability to produce accurate and semantically correct variants. Our findings shed light on GPT-3's strengths in code generation, offering insights into the potential applications and challenges of using advanced language models in software development. Our quantitative analysis yields compelling results. In the realm of semantic clones, GPT-3 attains an impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot prompt engineering. Furthermore, the model shines in transcending linguistic confines, boasting an exceptional 91.25% accuracy in generating cross-language clones
</details>
<details>
<summary>摘要</summary>
semantic和跨语言代码倾Copy generation可能有用于代码重用、代码理解、重构和benchmarking。OpenAI的GPT模型有潜力在这种倾Copy generation中，因为GPT是用于文本生成。当开发者从Stack Overflow（SO）或系统中复制代码时，可能会出现不一致的更改，导致意外的行为。 Similarly，如果某人拥有一个代码段在特定编程语言中，但寻找相同的功能在不同语言中，semantic cross-language code clone generation方法可以提供有价值的帮助。在本研究中，使用SemanticCloneBench作为载体，我们评估了GPT-3模型在给定副本中是否可以生成Semantic和跨语言倾Copy变体。我们组织了一个多样化的代码副本，并评估GPT-3模型在生成代码变体方面的能力。经过广泛的实验和分析，9名判icator在158小时内验证了我们的结论，我们调查了模型在代码生成方面的能力。我们的数据分析得出了有力的结果。在semantic倾Copy领域，GPT-3达到了62.14%的精度和0.55 BLEU分数，通过几个极少的提示工程来实现。此外，模型在跨语言倾Copy方面表现出色，达到了91.25%的精度。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Large-Language-Models-for-Ontology-Alignment"><a href="#Exploring-Large-Language-Models-for-Ontology-Alignment" class="headerlink" title="Exploring Large Language Models for Ontology Alignment"></a>Exploring Large Language Models for Ontology Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07172">http://arxiv.org/abs/2309.07172</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krr-oxford/llmap-prelim">https://github.com/krr-oxford/llmap-prelim</a></li>
<li>paper_authors: Yuan He, Jiaoyan Chen, Hang Dong, Ian Horrocks</li>
<li>for: 这项研究探讨了最新的生成型大语言模型（LLMs）在ontology alignment中的可用性，以确定概念等价映射的跨 ontology 标注。</li>
<li>methods: 我们使用了 GPT 系列和 Flan-T5 等生成型大语言模型，并对挑战性训练集进行测试，以评估其零基础性表现。</li>
<li>results: 初步发现，LLMs 可能会超越现有的 ontology alignment 系统 like BERTMap，但需要注意framwork和提示设计。<details>
<summary>Abstract</summary>
This work investigates the applicability of recent generative Large Language Models (LLMs), such as the GPT series and Flan-T5, to ontology alignment for identifying concept equivalence mappings across ontologies. To test the zero-shot performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging subsets from two equivalence matching datasets of the OAEI Bio-ML track, taking into account concept labels and structural contexts. Preliminary findings suggest that LLMs have the potential to outperform existing ontology alignment systems like BERTMap, given careful framework and prompt design.
</details>
<details>
<summary>摘要</summary>
这个研究探讨了最近的生成型大型自然语言模型（LLM），如GPT系列和Flan-T5，在ontology alignment中的可行性，以确定 Ontology 中的概念相似映射。为了测试 Flan-T5-XXL 和 GPT-3.5-turbo 的零学习性能，我们利用了 OAEI Bio-ML 跟踪中的两个等价匹配数据集，考虑概念标签和结构上下文。初步发现，LLM 有可能超越现有的ontology alignment系统BERTMap，提供精心设计的框架和提示。
</details></li>
</ul>
<hr>
<h2 id="Ensemble-Mask-Networks"><a href="#Ensemble-Mask-Networks" class="headerlink" title="Ensemble Mask Networks"></a>Ensemble Mask Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06382">http://arxiv.org/abs/2309.06382</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lok-18/GeSeNet">https://github.com/lok-18/GeSeNet</a></li>
<li>paper_authors: Jonny Luntzel</li>
<li>for: 这个研究是为了问题 $\mathbb{R}^n\rightarrow \mathbb{R}^n$ Feedforward 网络是否可以学习矩阵-向量乘法？</li>
<li>methods: 这个研究引入了两种机制：可变的面罩来处理矩阵输入，以及特有的网络剪辑来尊重面罩的依赖结构。</li>
<li>results: 研究表明，这些机制可以使网络模型近似固定操作，如矩阵-向量乘法 $\phi(A,x) \rightarrow Ax$，并有应用于测试依赖关系或交互顺序在图模型中。<details>
<summary>Abstract</summary>
Can an $\mathbb{R}^n\rightarrow \mathbb{R}^n$ feedforward network learn matrix-vector multiplication? This study introduces two mechanisms - flexible masking to take matrix inputs, and a unique network pruning to respect the mask's dependency structure. Networks can approximate fixed operations such as matrix-vector multiplication $\phi(A,x) \rightarrow Ax$, motivating the mechanisms introduced with applications towards litmus-testing dependencies or interaction order in graph-based models.
</details>
<details>
<summary>摘要</summary>
可以不是$\mathbb{R}^n\to\mathbb{R}^n$的Feedforward网络学习矩阵-向量乘法吗？这个研究提出了两种机制——灵活的面 masking来处理矩阵输入，以及特殊的网络剔除来尊重面的依赖结构。网络可以近似固定操作，如矩阵-向量乘法$\phi(A,x)\to Ax$，这些机制的引入鼓励了在图模型中进行考验依赖关系或交互顺序。
</details></li>
</ul>
<hr>
<h2 id="Style2Fab-Functionality-Aware-Segmentation-for-Fabricating-Personalized-3D-Models-with-Generative-AI"><a href="#Style2Fab-Functionality-Aware-Segmentation-for-Fabricating-Personalized-3D-Models-with-Generative-AI" class="headerlink" title="Style2Fab: Functionality-Aware Segmentation for Fabricating Personalized 3D Models with Generative AI"></a>Style2Fab: Functionality-Aware Segmentation for Fabricating Personalized 3D Models with Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06379">http://arxiv.org/abs/2309.06379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Faraz Faruqi, Ahmed Katary, Tarik Hasic, Amira Abdel-Rahman, Nayeemur Rahman, Leandra Tejedor, Mackenzie Leake, Megan Hofmann, Stefanie Mueller</li>
<li>for: 这个论文旨在提供一种自动将3D模型分解成功能和艺术元素的方法，以便用户可以选择性地修改3D模型的艺术元素，不会影响模型的原始功能。</li>
<li>methods: 这种方法首先创建了3D模型的功能分类体系，然后使用这个体系进行半自动的分类，将3D模型分解成功能和艺术两个部分。</li>
<li>results: 研究人员通过对1000个来自Thingiverse的3D模型进行质量分析，创建了一个功能分类体系，并使用这个体系进行分类，以及一个名为Style2Fab的系统，允许用户选择性地修改3D模型的艺术元素，而不会影响模型的原始功能。<details>
<summary>Abstract</summary>
With recent advances in Generative AI, it is becoming easier to automatically manipulate 3D models. However, current methods tend to apply edits to models globally, which risks compromising the intended functionality of the 3D model when fabricated in the physical world. For example, modifying functional segments in 3D models, such as the base of a vase, could break the original functionality of the model, thus causing the vase to fall over. We introduce a method for automatically segmenting 3D models into functional and aesthetic elements. This method allows users to selectively modify aesthetic segments of 3D models, without affecting the functional segments. To develop this method we first create a taxonomy of functionality in 3D models by qualitatively analyzing 1000 models sourced from a popular 3D printing repository, Thingiverse. With this taxonomy, we develop a semi-automatic classification method to decompose 3D models into functional and aesthetic elements. We propose a system called Style2Fab that allows users to selectively stylize 3D models without compromising their functionality. We evaluate the effectiveness of our classification method compared to human-annotated data, and demonstrate the utility of Style2Fab with a user study to show that functionality-aware segmentation helps preserve model functionality.
</details>
<details>
<summary>摘要</summary>
To develop this method, we first created a taxonomy of functionality in 3D models by analyzing 1000 models from a popular 3D printing repository, Thingiverse. We then developed a semi-automatic classification method to decompose 3D models into functional and aesthetic elements. We call this system Style2Fab, and it allows users to selectively stylize 3D models without compromising their functionality.We evaluated the effectiveness of our classification method compared to human-annotated data and demonstrated the utility of Style2Fab with a user study. Our results show that functionality-aware segmentation helps preserve the model's functionality, and users can use Style2Fab to selectively stylize 3D models without worrying about compromising their intended use.
</details></li>
</ul>
<hr>
<h2 id="Grounded-Language-Acquisition-From-Object-and-Action-Imagery"><a href="#Grounded-Language-Acquisition-From-Object-and-Action-Imagery" class="headerlink" title="Grounded Language Acquisition From Object and Action Imagery"></a>Grounded Language Acquisition From Object and Action Imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06335">http://arxiv.org/abs/2309.06335</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Robert Kubricht, Zhaoyuan Yang, Jianwei Qiu, Peter Henry Tu</li>
<li>for: 这 paper 的目的是研究如何使用深度学习方法来掌握视觉数据的Private语言表示。</li>
<li>methods: 该 paper 使用了 Referential game 环境和冲突学习环境来训练 Emergent Language（EL）Encoder&#x2F;Decoder，并使用了神经机器翻译和随机森林分类来将symbolic表示转化为类别标签。</li>
<li>results: 该 paper 在object recognition和action recognition两个实验中使用了这些方法，并使用了Grad-CAM和t-SNE方法来解释symbols生成的含义。<details>
<summary>Abstract</summary>
Deep learning approaches to natural language processing have made great strides in recent years. While these models produce symbols that convey vast amounts of diverse knowledge, it is unclear how such symbols are grounded in data from the world. In this paper, we explore the development of a private language for visual data representation by training emergent language (EL) encoders/decoders in both i) a traditional referential game environment and ii) a contrastive learning environment utilizing a within-class matching training paradigm. An additional classification layer utilizing neural machine translation and random forest classification was used to transform symbolic representations (sequences of integer symbols) to class labels. These methods were applied in two experiments focusing on object recognition and action recognition. For object recognition, a set of sketches produced by human participants from real imagery was used (Sketchy dataset) and for action recognition, 2D trajectories were generated from 3D motion capture systems (MOVI dataset). In order to interpret the symbols produced for data in each experiment, gradient-weighted class activation mapping (Grad-CAM) methods were used to identify pixel regions indicating semantic features which contribute evidence towards symbols in learned languages. Additionally, a t-distributed stochastic neighbor embedding (t-SNE) method was used to investigate embeddings learned by CNN feature extractors.
</details>
<details>
<summary>摘要</summary>
深度学习方法在自然语言处理方面已经做出了很大的进步。这些模型生成的符号表达了各种多样化的知识，但是不清楚这些符号如何与世界数据相关联。在这篇论文中，我们探索了在私人语言表达中发展的私人语言（EL）编码器/解码器，并在两种不同的环境中训练这些模型：一种传统的引用游戏环境和一种对比学习环境。此外，我们还使用神经机器翻译和随机森林分类来转换符号表达（序列数字符号）为类别标签。这些方法在两个实验中应用，一个是对象识别实验（Sketchy dataset），另一个是动作识别实验（MOVI dataset）。为了解释在每个实验中生成的符号，我们使用梯度权重分布映射（Grad-CAM）方法来确定符号中含有哪些Semantic特征，以及这些特征对象的证据。此外，我们还使用了高度分布随机邻居嵌入（t-SNE）方法来调查由Convolutional Neural Networks（CNN）特征提取器学习的嵌入。
</details></li>
</ul>
<hr>
<h2 id="Learning-Minimalistic-Tsetlin-Machine-Clauses-with-Markov-Boundary-Guided-Pruning"><a href="#Learning-Minimalistic-Tsetlin-Machine-Clauses-with-Markov-Boundary-Guided-Pruning" class="headerlink" title="Learning Minimalistic Tsetlin Machine Clauses with Markov Boundary-Guided Pruning"></a>Learning Minimalistic Tsetlin Machine Clauses with Markov Boundary-Guided Pruning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06315">http://arxiv.org/abs/2309.06315</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cair/tmu">https://github.com/cair/tmu</a></li>
<li>paper_authors: Ole-Christoffer Granmo, Per-Arne Andersen, Lei Jiao, Xuan Zhang, Christian Blakely, Tor Tveit</li>
<li>for: 本 paper 的目的是提出一种新的 Tsetlin Machine（TM） feedback scheme，用于找到 Markov boundary。</li>
<li>methods: 该 scheme 使用 Finite State Automaton - Context-Specific Independence Automaton，可以学习target variable 的 Markov boundary，从而在 TM 学习过程中减少不必要的特征。</li>
<li>results: 作者通过实验和理论分析，证明了该 scheme 可以充分利用上下文特定的独立性来找到 Markov boundary，并且可以提高 TM 的学习效率和准确性。<details>
<summary>Abstract</summary>
A set of variables is the Markov blanket of a random variable if it contains all the information needed for predicting the variable. If the blanket cannot be reduced without losing useful information, it is called a Markov boundary. Identifying the Markov boundary of a random variable is advantageous because all variables outside the boundary are superfluous. Hence, the Markov boundary provides an optimal feature set. However, learning the Markov boundary from data is challenging for two reasons. If one or more variables are removed from the Markov boundary, variables outside the boundary may start providing information. Conversely, variables within the boundary may stop providing information. The true role of each candidate variable is only manifesting when the Markov boundary has been identified. In this paper, we propose a new Tsetlin Machine (TM) feedback scheme that supplements Type I and Type II feedback. The scheme introduces a novel Finite State Automaton - a Context-Specific Independence Automaton. The automaton learns which features are outside the Markov boundary of the target, allowing them to be pruned from the TM during learning. We investigate the new scheme empirically, showing how it is capable of exploiting context-specific independence to find Markov boundaries. Further, we provide a theoretical analysis of convergence. Our approach thus connects the field of Bayesian networks (BN) with TMs, potentially opening up for synergies when it comes to inference and learning, including TM-produced Bayesian knowledge bases and TM-based Bayesian inference.
</details>
<details>
<summary>摘要</summary>
一个集合的变量是marks blanket的一个随机变量，如果它包含所有预测变量的信息，则称之为Markov bound。如果边界不能被缩小而失去有用的信息，则称之为Markov bound。标识随机变量的Markov bound是有利的，因为所有外部边界的变量都是 redundant。因此，Markov bound提供了一个优化的特征集。然而，从数据中学习Markov bound是困难的，因为如果一个或多个变量被从Markov bound中移除，外部边界上的变量可能会开始提供信息。相反，Markov bound内部的变量可能会停止提供信息。每个候选变量的真实角色只有在Markov bound已经被确定出来时才会表现出来。在这篇论文中，我们提出了一种新的Tsetlin Machine（TM）反馈方案，该方案附加了类型I和类型II反馈。方案使用了一个新的Finite State Automaton——Context-Specific Independence Automaton。机器学习以外的 automaton 可以学习随机变量的Markov bound，从而在TM学习过程中将其从TM中除除。我们对新方案进行了实验性研究，并证明了它可以利用上下文特定的独立性来找到Markov bound。我们还提供了一种理论分析的归一化。我们的方法因此将Bayesian networks（BN）和TM相连，可能会开拓新的可能性，包括TM生成的Bayesian知识库和TM基于Bayesian推理的推理。
</details></li>
</ul>
<hr>
<h2 id="AI4Food-NutritionFW-A-Novel-Framework-for-the-Automatic-Synthesis-and-Analysis-of-Eating-Behaviours"><a href="#AI4Food-NutritionFW-A-Novel-Framework-for-the-Automatic-Synthesis-and-Analysis-of-Eating-Behaviours" class="headerlink" title="AI4Food-NutritionFW: A Novel Framework for the Automatic Synthesis and Analysis of Eating Behaviours"></a>AI4Food-NutritionFW: A Novel Framework for the Automatic Synthesis and Analysis of Eating Behaviours</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06308">http://arxiv.org/abs/2309.06308</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bidalab/ai4food-nutritionfw">https://github.com/bidalab/ai4food-nutritionfw</a></li>
<li>paper_authors: Sergio Romero-Tapiador, Ruben Tolosana, Aythami Morales, Isabel Espinosa-Salinas, Gala Freixer, Julian Fierrez, Ruben Vera-Rodriguez, Enrique Carrillo de Santa Pau, Ana Ramírez de Molina, Javier Ortega-Garcia</li>
<li>for: 这个论文的目的是提出一种基于人工智能的食物图像数据集创建框架，以便研究食物图像分类和个性化推荐。</li>
<li>methods: 该论文使用了图像处理和人工智能技术，并提供了一个具有4,800个不同饮食习惯的食物图像数据集。</li>
<li>results: 该论文通过自动评估饮食习惯中的健康指数，并实现了99.53%和99.60%的准确率和敏感度。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Nowadays millions of images are shared on social media and web platforms. In particular, many of them are food images taken from a smartphone over time, providing information related to the individual's diet. On the other hand, eating behaviours are directly related to some of the most prevalent diseases in the world. Exploiting recent advances in image processing and Artificial Intelligence (AI), this scenario represents an excellent opportunity to: i) create new methods that analyse the individuals' health from what they eat, and ii) develop personalised recommendations to improve nutrition and diet under specific circumstances (e.g., obesity or COVID). Having tunable tools for creating food image datasets that facilitate research in both lines is very much needed.   This paper proposes AI4Food-NutritionFW, a framework for the creation of food image datasets according to configurable eating behaviours. AI4Food-NutritionFW simulates a user-friendly and widespread scenario where images are taken using a smartphone. In addition to the framework, we also provide and describe a unique food image dataset that includes 4,800 different weekly eating behaviours from 15 different profiles and 1,200 subjects. Specifically, we consider profiles that comply with actual lifestyles from healthy eating behaviours (according to established knowledge), variable profiles (e.g., eating out, holidays), to unhealthy ones (e.g., excess of fast food or sweets). Finally, we automatically evaluate a healthy index of the subject's eating behaviours using multidimensional metrics based on guidelines for healthy diets proposed by international organisations, achieving promising results (99.53% and 99.60% accuracy and sensitivity, respectively). We also release to the research community a software implementation of our proposed AI4Food-NutritionFW and the mentioned food image dataset created with it.
</details>
<details>
<summary>摘要</summary>
现在，数百万个图像在社交媒体和网络平台上被分享。特别是，许多这些图像是由智能手机拍摄的食物图像，提供了关于个人的饮食信息。然而，饮食习惯直接关联了世界上许多最常见的疾病。利用最新的图像处理技术和人工智能（AI），这种情况表现出了优秀的机遇，可以：i) 创建新的方法，从饮食中获取个人健康信息，ii) 为特定情况（如肥胖或 COVID）提供个性化的饮食建议。有一个可调的工具集，用于创建饮食图像集，是研究这两个方面的非常需要。  本文提出了 AI4Food-NutritionFW 框架，用于创建饮食图像集，根据可配置的饮食习惯。 AI4Food-NutritionFW 模拟了一种用户友好、广泛的场景，在智能手机上拍摄图像。除框架外，我们还提供了一个唯一的饮食图像集，包含 4,800 个不同的每周饮食习惯，来自 15 个 profiles 和 1,200 个主题。特别是，我们考虑了遵循实际生活方式的健康饮食习惯（根据已知的知识）、变化 profiles（例如，吃外卖、假日），以及不健康的习惯（例如，过量快餐或糖果）。最后，我们自动评估主题的饮食习惯健康指数，使用多维度指标，基于国际组织提出的健康饮食指南，达到了非常有 promise 的结果（99.53% 和 99.60% 的准确率和敏感度，分别）。我们还向研究社区发布了我们所提出的 AI4Food-NutritionFW 和饮食图像集。
</details></li>
</ul>
<hr>
<h2 id="Transferability-analysis-of-data-driven-additive-manufacturing-knowledge-a-case-study-between-powder-bed-fusion-and-directed-energy-deposition"><a href="#Transferability-analysis-of-data-driven-additive-manufacturing-knowledge-a-case-study-between-powder-bed-fusion-and-directed-energy-deposition" class="headerlink" title="Transferability analysis of data-driven additive manufacturing knowledge: a case study between powder bed fusion and directed energy deposition"></a>Transferability analysis of data-driven additive manufacturing knowledge: a case study between powder bed fusion and directed energy deposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06286">http://arxiv.org/abs/2309.06286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mutahar Safdar, Jiarui Xie, Hyunwoong Ko, Yan Lu, Guy Lamouche, Yaoyao Fiona Zhao</li>
<li>for: 本研究旨在提供一种基于数据的知识传递分析框架，以支持在不同加工过程之间传递数据驱动的AM知识。</li>
<li>methods: 本研究使用了一种三步知识传递分析框架，包括预传递、传递和后传递步骤。在预传递步骤中，AM知识被抽象为特征化的知识组件。</li>
<li>results: 研究表明，可以成功将LPBF处理技术中的数据驱动解决方案传递到DED处理技术中，并在不同数据表示、模型架构和模型参数层次上进行了成功传递。<details>
<summary>Abstract</summary>
Data-driven research in Additive Manufacturing (AM) has gained significant success in recent years. This has led to a plethora of scientific literature to emerge. The knowledge in these works consists of AM and Artificial Intelligence (AI) contexts that have not been mined and formalized in an integrated way. Moreover, no tools or guidelines exist to support data-driven knowledge transfer from one context to another. As a result, data-driven solutions using specific AI techniques are being developed and validated only for specific AM process technologies. There is a potential to exploit the inherent similarities across various AM technologies and adapt the existing solutions from one process or problem to another using AI, such as Transfer Learning. We propose a three-step knowledge transferability analysis framework in AM to support data-driven AM knowledge transfer. As a prerequisite to transferability analysis, AM knowledge is featurized into identified knowledge components. The framework consists of pre-transfer, transfer, and post-transfer steps to accomplish knowledge transfer. A case study is conducted between flagship metal AM processes. Laser Powder Bed Fusion (LPBF) is the source of knowledge motivated by its relative matureness in applying AI over Directed Energy Deposition (DED), which drives the need for knowledge transfer as the less explored target process. We show successful transfer at different levels of the data-driven solution, including data representation, model architecture, and model parameters. The pipeline of AM knowledge transfer can be automated in the future to allow efficient cross-context or cross-process knowledge exchange.
</details>
<details>
<summary>摘要</summary>
“数据驱动的研究在添加制造（AM）领域在最近几年内取得了重要成功。这导致了一大量的科学文献出现。这些文献中的知识包括AM和人工智能（AI）上下文的知识，它们没有被综合化和系统化地挖掘。此外，没有任何工具或指南来支持数据驱动知识的转移 между不同的上下文。因此，为了解决特定的AM过程技术中的问题，数据驱动解决方案使用特定的AI技术进行开发和验证。这有一定的潜在利用AM过程技术之间的共同特征，并将现有的解决方案从一个过程或问题中转移到另一个过程或问题中使用AI技术，例如传输学习。我们提议一个三步知识转移可行性分析框架在AM中支持数据驱动AM知识转移。在转移可行性分析之前，AM知识被特征化为识别出来的知识组件。该框架包括先转移、转移和后转移三个步骤，以完成知识转移。一个案例研究在标志性金属AM过程之间进行了转移。用激光粉末充电（LPBF）作为知识来源，因为它在应用AI方面更加成熟，而 Directed Energy Deposition（DED）更是一个未经探索的目标过程，这导致了知识转移的需求。我们在不同数据驱动解决方案的各级上成功进行了转移，包括数据表示、模型架构和模型参数。将来，AM知识转移管道可以被自动化，以实现跨上下文或跨过程的高效知识交换。”
</details></li>
</ul>
<hr>
<h2 id="Jersey-Number-Recognition-using-Keyframe-Identification-from-Low-Resolution-Broadcast-Videos"><a href="#Jersey-Number-Recognition-using-Keyframe-Identification-from-Low-Resolution-Broadcast-Videos" class="headerlink" title="Jersey Number Recognition using Keyframe Identification from Low-Resolution Broadcast Videos"></a>Jersey Number Recognition using Keyframe Identification from Low-Resolution Broadcast Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06285">http://arxiv.org/abs/2309.06285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bavesh Balaji, Jerrin Bright, Harish Prakash, Yuhao Chen, David A Clausi, John Zelek</li>
<li>for:  automatic jersey number detection in sports videos</li>
<li>methods:  spatio-temporal network, multi-task loss function</li>
<li>results:  significant increase in accuracy (37.81% and 37.70%)<details>
<summary>Abstract</summary>
Player identification is a crucial component in vision-driven soccer analytics, enabling various downstream tasks such as player assessment, in-game analysis, and broadcast production. However, automatically detecting jersey numbers from player tracklets in videos presents challenges due to motion blur, low resolution, distortions, and occlusions. Existing methods, utilizing Spatial Transformer Networks, CNNs, and Vision Transformers, have shown success in image data but struggle with real-world video data, where jersey numbers are not visible in most of the frames. Hence, identifying frames that contain the jersey number is a key sub-problem to tackle. To address these issues, we propose a robust keyframe identification module that extracts frames containing essential high-level information about the jersey number. A spatio-temporal network is then employed to model spatial and temporal context and predict the probabilities of jersey numbers in the video. Additionally, we adopt a multi-task loss function to predict the probability distribution of each digit separately. Extensive evaluations on the SoccerNet dataset demonstrate that incorporating our proposed keyframe identification module results in a significant 37.81% and 37.70% increase in the accuracies of 2 different test sets with domain gaps. These results highlight the effectiveness and importance of our approach in tackling the challenges of automatic jersey number detection in sports videos.
</details>
<details>
<summary>摘要</summary>
player identification是视觉驱动足球分析中的关键组件，允许多个下渠道任务，如玩家评估、游戏分析和直播生产。然而，自动从视频中检测篮球号码存在很多挑战，包括运动模糊、低分辨率、扭曲和遮挡。现有方法，使用空间变换网络、CNN和视觉变换器，在图像数据上表现出成功，但在真实世界视频数据上却表现不佳，因为篮球号码在大多数帧中不可见。因此，确定包含篮球号码的帧是关键的子问题。为解决这些问题，我们提议一种可靠的关键帧标识模块，该模块可以提取包含篮球号码的高级信息的帧。然后，我们采用了一种空间-时间网络，以模拟空间和时间上下文，并预测视频中篮球号码的概率。此外，我们采用了多任务损失函数，以预测每个数字的概率分布。我们在SoccerNet数据集进行了广泛的评估，结果表明，将我们提议的关锥帧标识模块integrated into our approach，可以提高视频中篮球号码自动检测的准确率，相对于不含该模块的情况，提高37.81%和37.70%。这些结果 highlights the effectiveness and importance of our approach in tackling the challenges of automatic jersey number detection in sports videos.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Multi-modal-Cooperation-via-Fine-grained-Modality-Valuation"><a href="#Enhancing-Multi-modal-Cooperation-via-Fine-grained-Modality-Valuation" class="headerlink" title="Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation"></a>Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06255">http://arxiv.org/abs/2309.06255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yake Wei, Ruoxuan Feng, Zihe Wang, Di Hu</li>
<li>for: 本研究旨在 JOINTLY integrating 不同模式的数据，以提高多模式学习的性能。</li>
<li>methods: 我们提出了一种细化模式价值指标，用于评估每个样本中每个模式的贡献。通过模式价值评估，我们发现多模式模型往往依赖于一个特定的模式，导致其他模式成为低贡献的。我们进一步分析这一问题，并通过提高低贡献模式的抑制能力来改善多模式模型的合作。</li>
<li>results: 我们的方法可以有效地评估每个样本中每个模式的贡献，并实现了不同多模式模型中的显著提高。<details>
<summary>Abstract</summary>
One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level. Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing. We further analyze this issue and improve cooperation between modalities by enhancing the discriminative ability of low-contributing modalities in a targeted manner. Overall, our methods reasonably observe the fine-grained uni-modal contribution at sample-level and achieve considerable improvement on different multi-modal models.
</details>
<details>
<summary>摘要</summary>
（使用简化字符串）一个主要的多样性学习主题是将不同Modalities中的异质数据集合在一起。然而，大多数模型通常会受到不满意的多样性合作，无法有效地使用所有Modalities。一些方法可以识别和提高不好学习的Modalities，但是往往无法在样本水平提供细化的多样性合作观察。因此，我们需要合理地观察和改进多样性合作，尤其是在面临现实情况下，模态差异可能会随样本不同而变化。为此，我们引入细化的模态价值度量来评估每个模态的样本级贡献。通过模态价值评估，我们 regretfully 发现，多模态模型往往会依赖于一个具体的模态，导致其他模态成为低贡献的。我们进一步分析这一问题，并通过提高低贡献模态的推诊能力来改善多样性合作。总的来说，我们的方法可以合理地观察细化的单模态贡献，并在不同的多模态模型上实现显著改进。
</details></li>
</ul>
<hr>
<h2 id="On-the-Injunction-of-XAIxArt"><a href="#On-the-Injunction-of-XAIxArt" class="headerlink" title="On the Injunction of XAIxArt"></a>On the Injunction of XAIxArt</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06227">http://arxiv.org/abs/2309.06227</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheshta Arora, Debarun Sarkar</li>
<li>for: 本论文探讨了透明人工智能在艺术领域（XAIxArt）中的纠纷。</li>
<li>methods: 文章通过一系列快速问题，探讨了“解释”和“相关的解释”的混淆性。文章拒绝了“解释”和“相关的解释”， argue  that XAIxArt 是人类中心艺术的不安和害怕旧有作者和人类活动的回归。</li>
<li>results: 文章通过区分了 ornamentation 模型和 sense-making 模型来证明这一观点。<details>
<summary>Abstract</summary>
The position paper highlights the range of concerns that are engulfed in the injunction of explainable artificial intelligence in art (XAIxArt). Through a series of quick sub-questions, it points towards the ambiguities concerning 'explanation' and the postpositivist tradition of 'relevant explanation'. Rejecting both 'explanation' and 'relevant explanation', the paper takes a stance that XAIxArt is a symptom of insecurity of the anthropocentric notion of art and a nostalgic desire to return to outmoded notions of authorship and human agency. To justify this stance, the paper makes a distinction between an ornamentation model of explanation to a model of explanation as sense-making.
</details>
<details>
<summary>摘要</summary>
文章发表于XAIxArt的各种问题，包括'解释'和'有用的解释'的歧义，以及人类中心艺术的不安和宁静愿返回过时的作者和人类活动。文章根据解释模型和意义解释模型的区别，提出了这种姿势。Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Signle-Bit-Flip-Attacks-on-DNN-Executables"><a href="#Unveiling-Signle-Bit-Flip-Attacks-on-DNN-Executables" class="headerlink" title="Unveiling Signle-Bit-Flip Attacks on DNN Executables"></a>Unveiling Signle-Bit-Flip Attacks on DNN Executables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06223">http://arxiv.org/abs/2309.06223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanzuo Chen, Zhibo Liu, Yuanyuan Yuan, Sihang Hu, Tianxiang Li, Shuai Wang</li>
<li>for: 防护深度学习模型免受Bit-flip攻击</li>
<li>methods: 使用自动搜索工具发现深度学习模型漏洞，并利用模型结构在深度学习模型执行器中发现实际攻击方向</li>
<li>results: 发现深度学习模型执行器中存在广泛、严重（如单位位异常）和可传递的攻击表面，这些攻击表面不存在于高级深度学习框架中的模型 weights，可以让攻击者控制输出标签<details>
<summary>Abstract</summary>
Recent research has shown that bit-flip attacks (BFAs) can manipulate deep neural networks (DNNs) via DRAM Rowhammer exploitations. Existing attacks are primarily launched over high-level DNN frameworks like PyTorch and flip bits in model weight files. Nevertheless, DNNs are frequently compiled into low-level executables by deep learning (DL) compilers to fully leverage low-level hardware primitives. The compiled code is usually high-speed and manifests dramatically distinct execution paradigms from high-level DNN frameworks.   In this paper, we launch the first systematic study on the attack surface of BFA specifically for DNN executables compiled by DL compilers. We design an automated search tool to identify vulnerable bits in DNN executables and identify practical attack vectors that exploit the model structure in DNN executables with BFAs (whereas prior works make likely strong assumptions to attack model weights). DNN executables appear more "opaque" than models in high-level DNN frameworks. Nevertheless, we find that DNN executables contain extensive, severe (e.g., single-bit flip), and transferrable attack surfaces that are not present in high-level DNN models and can be exploited to deplete full model intelligence and control output labels. Our finding calls for incorporating security mechanisms in future DNN compilation toolchains.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SCP-Scene-Completion-Pre-training-for-3D-Object-Detection"><a href="#SCP-Scene-Completion-Pre-training-for-3D-Object-Detection" class="headerlink" title="SCP: Scene Completion Pre-training for 3D Object Detection"></a>SCP: Scene Completion Pre-training for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06199">http://arxiv.org/abs/2309.06199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Shan, Yan Xia, Yuhong Chen, Daniel Cremers</li>
<li>for: 提高3D物体探测器的性能，使其需要更少的标注数据。</li>
<li>methods: 使用Scene Completion Pre-training（SCP）方法，通过完成点云场景，更好地捕捉城市环境中物体之间的空间和Semantic关系，并消除需要额外数据集的需求。</li>
<li>results: 使用SCP方法可以使现有的状态体际3D探测器达到相同的性能，只需要20%的标注数据。<details>
<summary>Abstract</summary>
3D object detection using LiDAR point clouds is a fundamental task in the fields of computer vision, robotics, and autonomous driving. However, existing 3D detectors heavily rely on annotated datasets, which are both time-consuming and prone to errors during the process of labeling 3D bounding boxes. In this paper, we propose a Scene Completion Pre-training (SCP) method to enhance the performance of 3D object detectors with less labeled data. SCP offers three key advantages: (1) Improved initialization of the point cloud model. By completing the scene point clouds, SCP effectively captures the spatial and semantic relationships among objects within urban environments. (2) Elimination of the need for additional datasets. SCP serves as a valuable auxiliary network that does not impose any additional efforts or data requirements on the 3D detectors. (3) Reduction of the amount of labeled data for detection. With the help of SCP, the existing state-of-the-art 3D detectors can achieve comparable performance while only relying on 20% labeled data.
</details>
<details>
<summary>摘要</summary>
三维对象检测使用激光点云是计算机视觉、 робо控和自动驾驶等领域的基本任务。然而，现有的三维检测器均依赖于标注过的数据集，这些数据集的标注过程昂贵且容易出错。在这篇论文中，我们提出了场景完成预训练（SCP）方法，以提高三维对象检测器的性能，并且需要更少的标注数据。SCP具有以下三个优势：1. 提高点云模型的初始化。通过完善场景点云，SCP可以有效地捕捉城市环境中物体之间的空间和semantic关系。2. 消除需要更多数据集的需求。SCP作为一个有价值的辅助网络，不需要额外的努力或数据要求。3. 降低检测需要的标注数据量。通过SCP的帮助，现有的状态对检测器可以在20%标注数据的情况下实现相同的性能。
</details></li>
</ul>
<hr>
<h2 id="360-circ-from-a-Single-Camera-A-Few-Shot-Approach-for-LiDAR-Segmentation"><a href="#360-circ-from-a-Single-Camera-A-Few-Shot-Approach-for-LiDAR-Segmentation" class="headerlink" title="360$^\circ$ from a Single Camera: A Few-Shot Approach for LiDAR Segmentation"></a>360$^\circ$ from a Single Camera: A Few-Shot Approach for LiDAR Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06197">http://arxiv.org/abs/2309.06197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laurenz Reichardt, Nikolas Ebert, Oliver Wasenmüller</li>
<li>for: 这篇论文旨在提出一种有效和快速的 label-efficient LiDAR 分割方法，以增进现有方法的精度和可靠性。</li>
<li>methods: 该方法使用了一个图像教师网络来生成 LiDAR 数据中的 semantic 预测，并将其用于预训练 LiDAR 分割学生网络。可选的是进行360度数据的精度调整。</li>
<li>results: 该方法可以超过现有的标注效率方法的结果，并且在一些传统的完全监督分割网络之上还取得了更高的性能。<details>
<summary>Abstract</summary>
Deep learning applications on LiDAR data suffer from a strong domain gap when applied to different sensors or tasks. In order for these methods to obtain similar accuracy on different data in comparison to values reported on public benchmarks, a large scale annotated dataset is necessary. However, in practical applications labeled data is costly and time consuming to obtain. Such factors have triggered various research in label-efficient methods, but a large gap remains to their fully-supervised counterparts. Thus, we propose ImageTo360, an effective and streamlined few-shot approach to label-efficient LiDAR segmentation. Our method utilizes an image teacher network to generate semantic predictions for LiDAR data within a single camera view. The teacher is used to pretrain the LiDAR segmentation student network, prior to optional fine-tuning on 360$^\circ$ data. Our method is implemented in a modular manner on the point level and as such is generalizable to different architectures. We improve over the current state-of-the-art results for label-efficient methods and even surpass some traditional fully-supervised segmentation networks.
</details>
<details>
<summary>摘要</summary>
深度学习应用于激光数据受到不同感知器或任务的域隔差很强。为了使这些方法在不同数据上达到类似准确性，需要一个大规模的注意力标注数据集。然而，在实际应用中，标注数据昂贵和时间消耗。这些因素引发了各种研究label-efficient方法，但与完全监督方法之间仍有大的差距。因此，我们提出ImageTo360，一种高效的几极shot方法 для标签efficient LiDAR分割。我们的方法使用图像教师网络生成激光数据中的semantic预测，并在单个相机视图中使用这些预测来预训练LiDAR分割学生网络。我们的方法实现在点级别上，可以与不同的架构进行拓展。我们超越当前状态的域隔差标签方法，甚至超过了一些传统的完全监督分割网络。
</details></li>
</ul>
<hr>
<h2 id="A-3M-Hybrid-Model-for-the-Restoration-of-Unique-Giant-Murals-A-Case-Study-on-the-Murals-of-Yongle-Palace"><a href="#A-3M-Hybrid-Model-for-the-Restoration-of-Unique-Giant-Murals-A-Case-Study-on-the-Murals-of-Yongle-Palace" class="headerlink" title="A 3M-Hybrid Model for the Restoration of Unique Giant Murals: A Case Study on the Murals of Yongle Palace"></a>A 3M-Hybrid Model for the Restoration of Unique Giant Murals: A Case Study on the Murals of Yongle Palace</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06194">http://arxiv.org/abs/2309.06194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Yang, Nur Intan Raihana Ruhaiyem, Chichun Zhou</li>
<li>for:  restore the Yongle Palace murals, which are valuable cultural heritage but have suffered damage</li>
<li>methods:  propose a 3M-Hybrid model that leverages a pre-trained Vision Transformer model (VIT) and a multi-scale and multi-perspective strategy to address the challenges of domain bias and large defect restoration</li>
<li>results:  improve SSIM and PSNR by 14.61% and 4.73%, respectively, compared to the best model among four representative CNN models, and achieve favorable results in the final restoration of giant murals.Here’s the full text in Simplified Chinese:</li>
<li>for: Restore the Yongle Palace murals, which are valuable cultural heritage but have suffered damage.</li>
<li>methods: 提出3M-Hybrid模型，利用预训练的视图转换器模型（VIT）和多尺度多角度策略，解决传统传输学学习方法中的领域偏见问题，以及大 défaut的 restore 问题。</li>
<li>results: 与最佳四种表征 CNN 模型比较，提高 SSIM 和 PSNR 指标的提升率分别为14.61%和4.73%，并在大 défaut的最终 restore 问题上获得了良好的结果。<details>
<summary>Abstract</summary>
The Yongle Palace murals, as valuable cultural heritage, have suffered varying degrees of damage, making their restoration of significant importance. However, the giant size and unique data of Yongle Palace murals present challenges for existing deep-learning based restoration methods: 1) The distinctive style introduces domain bias in traditional transfer learning-based restoration methods, while the scarcity of mural data further limits the applicability of these methods. 2) Additionally, the giant size of these murals results in a wider range of defect types and sizes, necessitating models with greater adaptability. Consequently, there is a lack of focus on deep learning-based restoration methods for the unique giant murals of Yongle Palace. Here, a 3M-Hybrid model is proposed to address these challenges. Firstly, based on the characteristic that the mural data frequency is prominent in the distribution of low and high frequency features, high and low frequency features are separately abstracted for complementary learning. Furthermore, we integrate a pre-trained Vision Transformer model (VIT) into the CNN module, allowing us to leverage the benefits of a large model while mitigating domain bias. Secondly, we mitigate seam and structural distortion issues resulting from the restoration of large defects by employing a multi-scale and multi-perspective strategy, including data segmentation and fusion. Experimental results demonstrate the efficacy of our proposed model. In regular-sized mural restoration, it improves SSIM and PSNR by 14.61% and 4.73%, respectively, compared to the best model among four representative CNN models. Additionally, it achieves favorable results in the final restoration of giant murals.
</details>
<details>
<summary>摘要</summary>
永乐宫壁画，作为文化遗产，受到不同程度的损害，因此 restore 的重要性提高。然而，永乐宫壁画的巨大大小和独特数据带来了现有深度学习基于 restore 方法的挑战：1）宫壁画的特殊风格引入传统 transfer learning 基于 restore 方法中的领域偏见，而且宫壁画数据的罕见性更限制了这些方法的应用。2）此外，宫壁画的巨大大小导致了更多的缺陷类型和大小，需要更加适应性强的模型。因此，对于永乐宫壁画独特的巨大宫壁画，深度学习基于 restore 方法受到了不 enough 的关注。在这里，我们提出了一种3M-Hybrid模型，以解决这些挑战。首先，基于宫壁画数据频谱在低频和高频特征之间的分布，我们分别抽取了高频和低频特征进行 complementary learning。其次，我们将预训练的 Vision Transformer 模型（VIT）integrated 到 CNN 模块中，以利用大型模型的优势，同时避免领域偏见。其次，我们使用多比例和多视角策略来mitigate 修复大缺陷的问题，包括数据分割和融合。实验结果表明，我们提出的模型在 regular-sized 宫壁画修复中提高了 SSIM 和 PSNR 指标的值，相比最佳四种 CNN 模型，提高了14.61%和4.73%。此外，它在巨大宫壁画的最终修复中也获得了良好的结果。
</details></li>
</ul>
<hr>
<h2 id="Glancing-Future-for-Simultaneous-Machine-Translation"><a href="#Glancing-Future-for-Simultaneous-Machine-Translation" class="headerlink" title="Glancing Future for Simultaneous Machine Translation"></a>Glancing Future for Simultaneous Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06179">http://arxiv.org/abs/2309.06179</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ictnlp/glance-simt">https://github.com/ictnlp/glance-simt</a></li>
<li>paper_authors: Shoutao Guo, Shaolei Zhang, Yang Feng</li>
<li>for: 提高同域机器翻译模型的翻译能力</li>
<li>methods: 使用课程学习方法，从整个句子逐渐减少可用的源语言信息，以便在 prefix2prefix 训练中增强模型的翻译能力</li>
<li>results: 比 STRONG 基eline 高效，且适用于各种同域机器翻译方法<details>
<summary>Abstract</summary>
Simultaneous machine translation (SiMT) outputs translation while reading the source sentence. Unlike conventional sequence-to-sequence (seq2seq) training, existing SiMT methods adopt the prefix-to-prefix (prefix2prefix) training, where the model predicts target tokens based on partial source tokens. However, the prefix2prefix training diminishes the ability of the model to capture global information and introduces forced predictions due to the absence of essential source information. Consequently, it is crucial to bridge the gap between the prefix2prefix training and seq2seq training to enhance the translation capability of the SiMT model. In this paper, we propose a novel method that glances future in curriculum learning to achieve the transition from the seq2seq training to prefix2prefix training. Specifically, we gradually reduce the available source information from the whole sentence to the prefix corresponding to that latency. Our method is applicable to a wide range of SiMT methods and experiments demonstrate that our method outperforms strong baselines.
</details>
<details>
<summary>摘要</summary>
同时机器翻译（SiMT）输出翻译 mientras lee la oración de fuente. 与现有的序列到序列（seq2seq）训练不同，现有的 SiMT 方法采用了 prefix-to-prefix（prefix2prefix）训练，其中模型预测目标Token基于部分源Token。然而， prefix2prefix 训练减少了模型捕捉全局信息的能力，并导致强制预测因为缺少必要的源信息。因此，它是必要的 bridge  seq2seq 训练和 prefix2prefix 训练，以提高 SiMT 模型的翻译能力。在这篇论文中，我们提出了一种新的方法，通过观察未来的劳动学习来实现这种过渡。具体来说，我们逐渐减少了可用的源信息从整个句子到对应的遅延。我们的方法适用于各种 SiMT 方法，并且实验表明，我们的方法超过了强大的基eline。
</details></li>
</ul>
<hr>
<h2 id="Robust-MBDL-A-Robust-Multi-branch-Deep-Learning-Based-Model-for-Remaining-Useful-Life-Prediction-and-Operational-Condition-Identification-of-Rotating-Machines"><a href="#Robust-MBDL-A-Robust-Multi-branch-Deep-Learning-Based-Model-for-Remaining-Useful-Life-Prediction-and-Operational-Condition-Identification-of-Rotating-Machines" class="headerlink" title="Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for Remaining Useful Life Prediction and Operational Condition Identification of Rotating Machines"></a>Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for Remaining Useful Life Prediction and Operational Condition Identification of Rotating Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06157">http://arxiv.org/abs/2309.06157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khoa Tran, Hai-Canh Vu, Lam Pham, Nassim Boudaoud</li>
<li>for: 预测扭矩机器的剩余有用生命（RUL）和状况操作（CO）</li>
<li>methods: 提posed system包括主要组件：1）LSTM自适应网络去噪振荡数据; 2）特征提取从去噪数据中生成时域、频域和时频基于特征; 3）一种新型和可靠的多支lines deep learning网络架构，利用多个特征</li>
<li>results: 对两个基准数据集XJTU-SY和PRONOSTIA进行了性能评估，结果表明我们提posed系统在RUL和CO预测方面准确率高，与当前最佳系统相比，具有实际应用潜力。<details>
<summary>Abstract</summary>
In this paper, a Robust Multi-branch Deep learning-based system for remaining useful life (RUL) prediction and condition operations (CO) identification of rotating machines is proposed. In particular, the proposed system comprises main components: (1) an LSTM-Autoencoder to denoise the vibration data; (2) a feature extraction to generate time-domain, frequency-domain, and time-frequency based features from the denoised data; (3) a novel and robust multi-branch deep learning network architecture to exploit the multiple features. The performance of our proposed system was evaluated and compared to the state-of-the-art systems on two benchmark datasets of XJTU-SY and PRONOSTIA. The experimental results prove that our proposed system outperforms the state-of-the-art systems and presents potential for real-life applications on bearing machines.
</details>
<details>
<summary>摘要</summary>
本文提出了一种基于深度学习的多支分支系统，用于预测旋转机器的剩余有用生命（RUL）和状况操作（CO）。特别是，提案的系统包括主要组成部分：1. LSTM自适应神经网络来排除振荡数据中的噪声;2. 特征提取来生成时域、频域和时频基于特征;3. 一种新的和可靠的多支分支深度学习网络架构，以利用多个特征。我们提出的系统的性能被评估并与现有系统进行比较，使用了两个XJTU-SY和PRONOSTIA的数据集。实验结果表明，我们的提案系统在RUL预测和CO识别方面表现出色，并有可能应用于真实的滚珍机器。
</details></li>
</ul>
<hr>
<h2 id="Measuring-vagueness-and-subjectivity-in-texts-from-symbolic-to-neural-VAGO"><a href="#Measuring-vagueness-and-subjectivity-in-texts-from-symbolic-to-neural-VAGO" class="headerlink" title="Measuring vagueness and subjectivity in texts: from symbolic to neural VAGO"></a>Measuring vagueness and subjectivity in texts: from symbolic to neural VAGO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06132">http://arxiv.org/abs/2309.06132</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Icard, Vincent Claveau, Ghislain Atemezing, Paul Égré</li>
<li>for: 本研究旨在开发一种自动测量文本模糊和主观性的方法。</li>
<li>methods: 我们首先介绍了专家系统VAGO，然后在一个小 benchmark上证明了它在fact vs. opinion句子上的效果，然后在更大的法语新闻词汇库FreSaDa上进行了对比，并证明了讽刺文章中的主观标志更为常见。最后，我们基于BERT-like架构建立了一个神经网络版本VAGO，并通过LIME的解释工具来证明其对symbolic VAGO scores的增强和其他语言版本的生成的重要性。</li>
<li>results: 研究结果表明，神经网络版本VAGO在 FreSaDa 上的表现更好，并且可以增强 symbolic VAGO scores 的lexicons。此外，神经网络版本还可以生成其他语言版本，并且可以通过LIME的解释工具来了解它们的工作原理。<details>
<summary>Abstract</summary>
We present a hybrid approach to the automated measurement of vagueness and subjectivity in texts. We first introduce the expert system VAGO, we illustrate it on a small benchmark of fact vs. opinion sentences, and then test it on the larger French press corpus FreSaDa to confirm the higher prevalence of subjective markers in satirical vs. regular texts. We then build a neural clone of VAGO, based on a BERT-like architecture, trained on the symbolic VAGO scores obtained on FreSaDa. Using explainability tools (LIME), we show the interest of this neural version for the enrichment of the lexicons of the symbolic version, and for the production of versions in other languages.
</details>
<details>
<summary>摘要</summary>
我们提出了一种混合方法来自动量化文本中的uncertainty和主观性。我们首先介绍了专家系统VAGO，然后在一个小的对比实验中使用它对fact vs. opinion句子进行了示例，然后在更大的法国报纸词汇 corpus FreSaDa 上进行了测试，以确认在幽默 VS. 常规文本中的主观标记的更高频率。然后，我们建立了一个基于BERT-like架构的神经网络副本，并使用LIME Explainability工具来展示其在符号式 VAGO 分数中的利用性和在其他语言中生成版本的可能性。
</details></li>
</ul>
<hr>
<h2 id="JOADAA-joint-online-action-detection-and-action-anticipation"><a href="#JOADAA-joint-online-action-detection-and-action-anticipation" class="headerlink" title="JOADAA: joint online action detection and action anticipation"></a>JOADAA: joint online action detection and action anticipation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06130">http://arxiv.org/abs/2309.06130</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed Guermal, Francois Bremond, Rui Dai, Abid Ali</li>
<li>for: 这两个任务的缺失完整的知识集（过去、当前和未来）使得推断动作依赖关系困难，从而影响性能。</li>
<li>methods: 我们提议将这两个任务 fusion into a single uniform architecture，通过结合动作预测和在线动作检测，以捕捉未来信息的潜在相互关系。</li>
<li>results: 我们在三个挑战性 dataset（THUMOS’14、CHARADES和Multi-THUMOS）上验证了我们的提议模型（JOADAA），并 achieved SOTA results for both tasks。<details>
<summary>Abstract</summary>
Action anticipation involves forecasting future actions by connecting past events to future ones. However, this reasoning ignores the real-life hierarchy of events which is considered to be composed of three main parts: past, present, and future. We argue that considering these three main parts and their dependencies could improve performance. On the other hand, online action detection is the task of predicting actions in a streaming manner. In this case, one has access only to the past and present information. Therefore, in online action detection (OAD) the existing approaches miss semantics or future information which limits their performance. To sum up, for both of these tasks, the complete set of knowledge (past-present-future) is missing, which makes it challenging to infer action dependencies, therefore having low performances. To address this limitation, we propose to fuse both tasks into a single uniform architecture. By combining action anticipation and online action detection, our approach can cover the missing dependencies of future information in online action detection. This method referred to as JOADAA, presents a uniform model that jointly performs action anticipation and online action detection. We validate our proposed model on three challenging datasets: THUMOS'14, which is a sparsely annotated dataset with one action per time step, CHARADES, and Multi-THUMOS, two densely annotated datasets with more complex scenarios. JOADAA achieves SOTA results on these benchmarks for both tasks.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate="no"Action anticipation involves forecasting future actions by connecting past events to future ones. However, this reasoning ignores the real-life hierarchy of events, which is composed of three main parts: past, present, and future. We argue that considering these three main parts and their dependencies could improve performance. On the other hand, online action detection is the task of predicting actions in a streaming manner. In this case, one has access only to the past and present information. Therefore, in online action detection (OAD), the existing approaches miss semantics or future information, which limits their performance. To sum up, for both of these tasks, the complete set of knowledge (past-present-future) is missing, which makes it challenging to infer action dependencies, therefore having low performances. To address this limitation, we propose to fuse both tasks into a single uniform architecture. By combining action anticipation and online action detection, our approach can cover the missing dependencies of future information in online action detection. This method, referred to as JOADAA, presents a uniform model that jointly performs action anticipation and online action detection. We validate our proposed model on three challenging datasets: THUMOS'14, which is a sparsely annotated dataset with one action per time step, CHARADES, and Multi-THUMOS, two densely annotated datasets with more complex scenarios. JOADAA achieves SOTA results on these benchmarks for both tasks.Note: I've kept the original text's sentence structure and vocabulary as much as possible, but some words and phrases may have been adjusted slightly to fit the Simplified Chinese grammar and idiomatic expressions.
</details></li>
</ul>
<hr>
<h2 id="LEyes-A-Lightweight-Framework-for-Deep-Learning-Based-Eye-Tracking-using-Synthetic-Eye-Images"><a href="#LEyes-A-Lightweight-Framework-for-Deep-Learning-Based-Eye-Tracking-using-Synthetic-Eye-Images" class="headerlink" title="LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images"></a>LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06129">http://arxiv.org/abs/2309.06129</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dcnieho/byrneetal_leyes">https://github.com/dcnieho/byrneetal_leyes</a></li>
<li>paper_authors: sean anthony byrne, virmarie maquiling, marcus nyström, enkelejda kasneci, diederick c. niehorster</li>
<li>For:  This paper aims to address the problem of inadequate training datasets for gaze estimation techniques, which has hindered the deployment of deep learning models in real-world applications.* Methods: The proposed framework, called Light Eyes (LEyes), uses simple light distributions to model key image features required for video-based eye tracking, facilitating easy configuration for training neural networks across diverse gaze-estimation tasks.* Results: The authors demonstrate that models trained using LEyes outperform other state-of-the-art algorithms in terms of pupil and CR localization across well-known datasets, and a LEyes trained model outperforms the industry standard eye tracker using significantly more cost-effective hardware.<details>
<summary>Abstract</summary>
Deep learning has bolstered gaze estimation techniques, but real-world deployment has been impeded by inadequate training datasets. This problem is exacerbated by both hardware-induced variations in eye images and inherent biological differences across the recorded participants, leading to both feature and pixel-level variance that hinders the generalizability of models trained on specific datasets. While synthetic datasets can be a solution, their creation is both time and resource-intensive. To address this problem, we present a framework called Light Eyes or "LEyes" which, unlike conventional photorealistic methods, only models key image features required for video-based eye tracking using simple light distributions. LEyes facilitates easy configuration for training neural networks across diverse gaze-estimation tasks. We demonstrate that models trained using LEyes outperform other state-of-the-art algorithms in terms of pupil and CR localization across well-known datasets. In addition, a LEyes trained model outperforms the industry standard eye tracker using significantly more cost-effective hardware. Going forward, we are confident that LEyes will revolutionize synthetic data generation for gaze estimation models, and lead to significant improvements of the next generation video-based eye trackers.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Fidelity-Induced-Interpretable-Policy-Extraction-for-Reinforcement-Learning"><a href="#Fidelity-Induced-Interpretable-Policy-Extraction-for-Reinforcement-Learning" class="headerlink" title="Fidelity-Induced Interpretable Policy Extraction for Reinforcement Learning"></a>Fidelity-Induced Interpretable Policy Extraction for Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06097">http://arxiv.org/abs/2309.06097</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao Liu, Wubing Chen, Mao Tan</li>
<li>for: 提高深度强化学习（DRL）代理人的可读性和可信度，使用者能够了解代理人的决策过程和弱点。</li>
<li>methods: 基于新的可读性增强机制， FIPE 方法通过评估已有 IPE 方法的优化问题，并添加了一个准确度评估指标，以提高代理人的决策可读性和一致性。</li>
<li>results: 在 StarCraft II 复杂的控制环境中进行实验，FIPE 方法在交互性性和一致性两个方面都超过了基eline，同时易于理解。<details>
<summary>Abstract</summary>
Deep Reinforcement Learning (DRL) has achieved remarkable success in sequential decision-making problems. However, existing DRL agents make decisions in an opaque fashion, hindering the user from establishing trust and scrutinizing weaknesses of the agents. While recent research has developed Interpretable Policy Extraction (IPE) methods for explaining how an agent takes actions, their explanations are often inconsistent with the agent's behavior and thus, frequently fail to explain. To tackle this issue, we propose a novel method, Fidelity-Induced Policy Extraction (FIPE). Specifically, we start by analyzing the optimization mechanism of existing IPE methods, elaborating on the issue of ignoring consistency while increasing cumulative rewards. We then design a fidelity-induced mechanism by integrate a fidelity measurement into the reinforcement learning feedback. We conduct experiments in the complex control environment of StarCraft II, an arena typically avoided by current IPE methods. The experiment results demonstrate that FIPE outperforms the baselines in terms of interaction performance and consistency, meanwhile easy to understand.
</details>
<details>
<summary>摘要</summary>
Specifically, we start by analyzing the optimization mechanism of existing IPE methods, highlighting the issue of ignoring consistency while increasing cumulative rewards. We then design a fidelity-induced mechanism by integrating a fidelity measurement into the reinforcement learning feedback. We conduct experiments in the complex control environment of StarCraft II, an environment typically avoided by current IPE methods. The experiment results demonstrate that FIPE outperforms the baselines in terms of interaction performance and consistency, while being easy to understand.
</details></li>
</ul>
<hr>
<h2 id="A-Machine-Learning-Framework-to-Deconstruct-the-Primary-Drivers-for-Electricity-Market-Price-Events"><a href="#A-Machine-Learning-Framework-to-Deconstruct-the-Primary-Drivers-for-Electricity-Market-Price-Events" class="headerlink" title="A Machine Learning Framework to Deconstruct the Primary Drivers for Electricity Market Price Events"></a>A Machine Learning Framework to Deconstruct the Primary Drivers for Electricity Market Price Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06082">http://arxiv.org/abs/2309.06082</a></li>
<li>repo_url: None</li>
<li>paper_authors: Milan Jain, Xueqing Sun, Sohom Datta, Abhishek Somani</li>
<li>for: 本研究旨在分析和揭示现代电力市场中变化的价格形成因素，尤其是高可再生能源含量下的价格峰值事件。</li>
<li>methods: 该研究提出了一种基于机器学习的分析框架，可以帮助分解现代电力市场中价格峰值事件的主要驱动因素。</li>
<li>results: 研究结果表明，价格峰值事件的主要驱动因素包括可再生能源含量、天气因素和市场操作因素等。这些结果可以用于多个重要的市场设计、可再生发电和干预、运营和网络安全应用。<details>
<summary>Abstract</summary>
Power grids are moving towards 100% renewable energy source bulk power grids, and the overall dynamics of power system operations and electricity markets are changing. The electricity markets are not only dispatching resources economically but also taking into account various controllable actions like renewable curtailment, transmission congestion mitigation, and energy storage optimization to ensure grid reliability. As a result, price formations in electricity markets have become quite complex. Traditional root cause analysis and statistical approaches are rendered inapplicable to analyze and infer the main drivers behind price formation in the modern grid and markets with variable renewable energy (VRE). In this paper, we propose a machine learning-based analysis framework to deconstruct the primary drivers for price spike events in modern electricity markets with high renewable energy. The outcomes can be utilized for various critical aspects of market design, renewable dispatch and curtailment, operations, and cyber-security applications. The framework can be applied to any ISO or market data; however, in this paper, it is applied to open-source publicly available datasets from California Independent System Operator (CAISO) and ISO New England (ISO-NE).
</details>
<details>
<summary>摘要</summary>
《电力网络在向100%可再生能源源扩展方向上进行变革，电力市场的运营和供应链也在不断发生变化。电力市场不仅经济地派发资源，还考虑了多种可控行为，如可再生能源减少、传输拥堵缓解和能量存储优化，以确保网络可靠性。因此，电力市场价格的形成变得非常复杂。传统的根本原因分析和统计方法在现代网络和市场中变得无法应用，用于分析和推导现代电力市场价格主要驱动力的主要驱动力。在这篇论文中，我们提出一种基于机器学习的分析框架，以分解现代电力市场价格峰值事件的主要驱动力。这些结果可以用于各种关键应用，如市场设计、可再生发电和减少、运营和网络安全应用。这种框架可以应用于任何ISO或市场数据，但在这篇论文中，它被应用于公开可用的CAISO和ISO-NE数据集。》Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>
<hr>
<h2 id="BatMan-CLR-Making-Few-shots-Meta-Learners-Resilient-Against-Label-Noise"><a href="#BatMan-CLR-Making-Few-shots-Meta-Learners-Resilient-Against-Label-Noise" class="headerlink" title="BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise"></a>BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06046">http://arxiv.org/abs/2309.06046</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeroen M. Galjaard, Robert Birke, Juan Perez, Lydia Y. Chen</li>
<li>for: 本研究探讨了meta-learning中 label noise 的负面影响，并提出了两种采样技术来增强meta-learner对 label noise 的抗性。</li>
<li>methods: 本研究使用了现有的 gradient-based $N$-way $K$-shot learners，并对其进行了extensive的分析和对比。同时，本研究还提出了两种采样技术，namely manifold (Man)和 batch manifold (BatMan)，以帮助meta-learner更好地利用噪音标签。</li>
<li>results: 研究结果显示，当meta-training中存在 label noise时， gradient-based $N$-way $K$-shot learners 的准确率可以下降达42%。而通过使用 manifold (Man) 和 batch manifold (BatMan) 采样技术，可以减少 meta-testing 中 label noise 的影响，并限制meta-testing准确率下降在${2.5}$, ${9.4}$, ${1.1}$ percent points 之间。<details>
<summary>Abstract</summary>
The negative impact of label noise is well studied in classical supervised learning yet remains an open research question in meta-learning. Meta-learners aim to adapt to unseen learning tasks by learning a good initial model in meta-training and consecutively fine-tuning it according to new tasks during meta-testing. In this paper, we present the first extensive analysis of the impact of varying levels of label noise on the performance of state-of-the-art meta-learners, specifically gradient-based $N$-way $K$-shot learners. We show that the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the Omniglot and CifarFS datasets when meta-training is affected by label noise. To strengthen the resilience against label noise, we propose two sampling techniques, namely manifold (Man) and batch manifold (BatMan), which transform the noisy supervised learners into semi-supervised ones to increase the utility of noisy labels. We first construct manifold samples of $N$-way $2$-contrastive-shot tasks through augmentation, learning the embedding via a contrastive loss in meta-training, and then perform classification through zeroing on the embedding in meta-testing. We show that our approach can effectively mitigate the impact of meta-training label noise. Even with 60% wrong labels \batman and \man can limit the meta-testing accuracy drop to ${2.5}$, ${9.4}$, ${1.1}$ percent points, respectively, with existing meta-learners across the Omniglot, CifarFS, and MiniImagenet datasets.
</details>
<details>
<summary>摘要</summary>
研究者们已经广泛研究了经典的超级学习中的标签噪声的负面影响，但在元学习领域中，这个问题仍然是一个开放的研究问题。元学习者希望通过学习一个好的初始模型，并在新任务上进行细化调整来适应未看过的学习任务。在这篇论文中，我们提供了首次对元学习器的标签噪声的影响进行了广泛的分析。我们发现，当元训练被标签噪声影响时，Reptile、iMAML和foMAML的精度 Drop by up to 42% on the Omniglot and CifarFS datasets。为了增强元学习器对标签噪声的抗性，我们提议了两种采样技术： manifold（Man）和批量 manifold（BatMan）。这两种技术可以将噪声标注的超级学习器转换成 semi-supervised 学习器，以提高噪声标注的利用性。我们首先通过扩展来构建 $N$-way $2$-contrastive-shot任务的 manifold 样本，然后通过预训练一个嵌入向量，并在元测试中使用零化来进行分类。我们发现，我们的方法可以有效地减轻元训练标签噪声的影响。即使有60%的标签是错误的，batman 和 man 可以限制元测试精度下降到 ${2.5}$, ${9.4}$, ${1.1}$%点，分别。
</details></li>
</ul>
<hr>
<h2 id="Update-Monte-Carlo-tree-search-UMCTS-algorithm-for-heuristic-global-search-of-sizing-optimization-problems-for-truss-structures"><a href="#Update-Monte-Carlo-tree-search-UMCTS-algorithm-for-heuristic-global-search-of-sizing-optimization-problems-for-truss-structures" class="headerlink" title="Update Monte Carlo tree search (UMCTS) algorithm for heuristic global search of sizing optimization problems for truss structures"></a>Update Monte Carlo tree search (UMCTS) algorithm for heuristic global search of sizing optimization problems for truss structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06045">http://arxiv.org/abs/2309.06045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fu-Yao Ko, Katsuyuki Suzuki, Kazuo Yonekura</li>
<li>for: optimization of truss structures</li>
<li>methods: reinforcement learning (RL) and Monte Carlo tree search (MCTS) with upper confidence bound (UCB)</li>
<li>results: efficient optimization algorithm with at least ten times faster computation time than branch and bound (BB) method, and stable better solutions than other conventional methods.Here’s the simplified Chinese text:</li>
<li>for: 这篇论文是针对桁架结构的最佳化问题进行研究。</li>
<li>methods: 使用强化学习（RL）和Monte Carlo tree search（MCTS）方法，并且加上最高信心界（UCB）。</li>
<li>results: 提出了一个高效的最佳化算法， computation time 至少比branch and bound（BB）方法快十倍，并且稳定地获得更好的解。<details>
<summary>Abstract</summary>
Sizing optimization of truss structures is a complex computational problem, and the reinforcement learning (RL) is suitable for dealing with multimodal problems without gradient computations. In this paper, a new efficient optimization algorithm called update Monte Carlo tree search (UMCTS) is developed to obtain the appropriate design for truss structures. UMCTS is an RL-based method that combines the novel update process and Monte Carlo tree search (MCTS) with the upper confidence bound (UCB). Update process means that in each round, the optimal cross-sectional area of each member is determined by search tree, and its initial state is the final state in the previous round. In the UMCTS algorithm, an accelerator for the number of selections for member area and iteration number is introduced to reduce the computation time. Moreover, for each state, the average reward is replaced by the best reward collected on the simulation process to determine the optimal solution. The proposed optimization method is examined on some benchmark problems of planar and spatial trusses with discrete sizing variables to demonstrate the efficiency and validity. It is shown that the computation time for the proposed approach is at least ten times faster than the branch and bound (BB) method. The numerical results indicate that the proposed method stably achieves better solution than other conventional methods.
</details>
<details>
<summary>摘要</summary>
��erton 优化算法的评估是一个复杂的计算问题，而人工智能学习（RL）是适用于多Modal问题的解决方案。在这篇论文中，一种新的高效优化算法called update Monte Carlo tree search（UMCTS）被开发出来，以获取适当的设计 dla truss 结构。 UMCTS 是一种基于 RL 的方法，它将 Monte Carlo tree search（MCTS）与Upper Confidence Bound（UCB）结合，并在每一轮中，通过搜索树来确定每个成员的最佳跨部分面积。在 UMCTS 算法中，一种加速器 для成员面积和迭代次数的数量被引入，以降低计算时间。此外，每个状态下的平均奖励被 replaced by 最佳在 Simulation 过程中收集的奖励，以确定最佳解决方案。提出的优化方法被应用于一些 benchmark 问题 of planar 和 spatial trusses with discrete sizing variables，以示出其高效性和有效性。结果表明，提出的方法的计算时间至少比 branch and bound（BB）方法快 ten times。 numerics 表明，提出的方法稳定地实现了 better solution  than other conventional methods。
</details></li>
</ul>
<hr>
<h2 id="Learning-Score-based-Grasping-Primitive-for-Human-assisting-Dexterous-Grasping"><a href="#Learning-Score-based-Grasping-Primitive-for-Human-assisting-Dexterous-Grasping" class="headerlink" title="Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping"></a>Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06038">http://arxiv.org/abs/2309.06038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianhao Wu, Mingdong Wu, Jiyao Zhang, Yunchong Gan, Hao Dong</li>
<li>for: 本研究旨在帮助用户在人手不可用或不适用的情况下，使用人工智能手部协助 grasping 物品。</li>
<li>methods: 本研究提出了一种新的任务 called human-assisting dexterous grasping，旨在训练一个控制 робо手指的策略，以帮助用户 grasping 物品。</li>
<li>results: 实验结果表明，我们提出的方法在比基eline的情况下具有优势，highlighting 用户consciousness 和实际应用性。codes 和演示可以在 “<a target="_blank" rel="noopener" href="https://sites.google.com/view/graspgf">https://sites.google.com/view/graspgf</a>“ 中查看。<details>
<summary>Abstract</summary>
The use of anthropomorphic robotic hands for assisting individuals in situations where human hands may be unavailable or unsuitable has gained significant importance. In this paper, we propose a novel task called human-assisting dexterous grasping that aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task presents a more complex challenge as the policy needs to adapt to diverse user intentions, in addition to the object's geometry. We address this challenge by proposing an approach consisting of two sub-modules: a hand-object-conditional grasping primitive called Grasping Gradient Field~(GraspGF), and a history-conditional residual policy. GraspGF learns `how' to grasp by estimating the gradient from a success grasping example set, while the residual policy determines `when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results demonstrate the superiority of our proposed method compared to baselines, highlighting the user-awareness and practicality in real-world applications. The codes and demonstrations can be viewed at "https://sites.google.com/view/graspgf".
</details>
<details>
<summary>摘要</summary>
人类辅助dexterous grasping任务在帮助用户抓取物品时具有重要 significanc。在这篇论文中，我们提出一种新任务，即人机合作dexterous grasping，旨在训练一个控制机器人手指的策略，以助用户抓取物品。与传统的dexterous grasping不同，这个任务呈现了更加复杂的挑战，因为策略需要适应用户的意图，以及物品的几何学特征。我们解决这个挑战的方法是通过两个子模块：一个手机-物品conditional grasping基本单元 called Grasping Gradient Field（GraspGF），以及一个历史条件的差异策略。GraspGF学习了如何抓取的“如何”，通过成功抓取示例集来估算抓取的梯度，而差异策略则确定了执行抓取动作的时间和速度，根据轨迹历史。实验结果表明我们提出的方法在基eline之上显著超越，highlighting用户意识和实际应用中的实用性。代码和演示可以在“https://sites.google.com/view/graspgf”上查看。
</details></li>
</ul>
<hr>
<h2 id="Automatically-Estimating-the-Effort-Required-to-Repay-Self-Admitted-Technical-Debt"><a href="#Automatically-Estimating-the-Effort-Required-to-Repay-Self-Admitted-Technical-Debt" class="headerlink" title="Automatically Estimating the Effort Required to Repay Self-Admitted Technical Debt"></a>Automatically Estimating the Effort Required to Repay Self-Admitted Technical Debt</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06020">http://arxiv.org/abs/2309.06020</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yikun-li/satd-repayment-effort">https://github.com/yikun-li/satd-repayment-effort</a></li>
<li>paper_authors: Yikun Li, Mohamed Soliman, Paris Avgeriou<br>for: 本研究旨在提高技术债（Technical Debt）的优化和维护效率，特别是自我投诉技术债（Self-Admitted Technical Debt，SATD）的优化。methods: 本研究使用了一个大型的SATD数据集，包括341,740个SATD项来自2,568,728个提交，从1,060个Apache仓库中收集。然后，我们采用了BERT和TextCNN等机器学习方法来自动估算SATD的偿还努力。results: 我们发现不同类型的SATD偿还努力有不同的水平，代码&#x2F;设计、需求、测试债需要更多的偿还努力，而文档债需要较少的偿还努力。此外，我们还总结了在SATD偿还过程中不同水平的偿还努力关键词。本研究的贡献可以帮助优化技术债的优化和维护效率，最终为软件开发和维护带来利益。<details>
<summary>Abstract</summary>
Technical debt refers to the consequences of sub-optimal decisions made during software development that prioritize short-term benefits over long-term maintainability. Self-Admitted Technical Debt (SATD) is a specific form of technical debt, explicitly documented by developers within software artifacts such as source code comments and commit messages. As SATD can hinder software development and maintenance, it is crucial to address and prioritize it effectively. However, current methodologies lack the ability to automatically estimate the repayment effort of SATD based on its textual descriptions. To address this limitation, we propose a novel approach for automatically estimating SATD repayment effort, utilizing a comprehensive dataset comprising 341,740 SATD items from 2,568,728 commits across 1,060 Apache repositories. Our findings show that different types of SATD require varying levels of repayment effort, with code/design, requirement, and test debt demanding greater effort compared to non-SATD items, while documentation debt requires less. We introduce and evaluate machine learning methodologies, particularly BERT and TextCNN, which outperforms classic machine learning methods and the naive baseline in estimating repayment effort. Additionally, we summarize keywords associated with varying levels of repayment effort that occur during SATD repayment. Our contributions aim to enhance the prioritization of SATD repayment effort and resource allocation efficiency, ultimately benefiting software development and maintainability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Molecular-Conformation-Generation-via-Shifting-Scores"><a href="#Molecular-Conformation-Generation-via-Shifting-Scores" class="headerlink" title="Molecular Conformation Generation via Shifting Scores"></a>Molecular Conformation Generation via Shifting Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.09985">http://arxiv.org/abs/2309.09985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihan Zhou, Ruiying Liu, Chaolong Ying, Ruimao Zhang, Tianshu Yu</li>
<li>for: 生成分子结构，一个计算化学中的关键问题，涉及生成分子的三维构型几何。</li>
<li>methods: 我们提出了一种新的分子构型生成方法，基于分子分解的观察，即将分子中的原子间距离推迟到Maxwell-Boltzmann分布。</li>
<li>results: 我们对分子数据集进行实验，并证明了我们的方法在现有方法的基础上具有优势。<details>
<summary>Abstract</summary>
Molecular conformation generation, a critical aspect of computational chemistry, involves producing the three-dimensional conformer geometry for a given molecule. Generating molecular conformation via diffusion requires learning to reverse a noising process. Diffusion on inter-atomic distances instead of conformation preserves SE(3)-equivalence and shows superior performance compared to alternative techniques, whereas related generative modelings are predominantly based upon heuristical assumptions. In response to this, we propose a novel molecular conformation generation approach driven by the observation that the disintegration of a molecule can be viewed as casting increasing force fields to its composing atoms, such that the distribution of the change of inter-atomic distance shifts from Gaussian to Maxwell-Boltzmann distribution. The corresponding generative modeling ensures a feasible inter-atomic distance geometry and exhibits time reversibility. Experimental results on molecular datasets demonstrate the advantages of the proposed shifting distribution compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
分子形态生成，计算化学中一项关键任务，涉及生成给定分子的三维结构均衡。通过扩散来生成分子形态，需要学习反向噪声过程。与传统技术不同，我们的方法基于分子裂解的观察，即将分子中的原子受到增加的力场影响，因此分子中间的距离分布从 Gaussian 转变为 Maxwell-Boltzmann 分布。这种生成模型保证了原子间距离的可行性，并且具有时间逆向性。对分子数据进行实验，我们发现了我们提出的分布Shift的优势，比 estado-of-the-art 更好。
</details></li>
</ul>
<hr>
<h2 id="DSLOT-NN-Digit-Serial-Left-to-Right-Neural-Network-Accelerator"><a href="#DSLOT-NN-Digit-Serial-Left-to-Right-Neural-Network-Accelerator" class="headerlink" title="DSLOT-NN: Digit-Serial Left-to-Right Neural Network Accelerator"></a>DSLOT-NN: Digit-Serial Left-to-Right Neural Network Accelerator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06019">http://arxiv.org/abs/2309.06019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Sohail Ibrahim, Muhammad Usman, Malik Zohaib Nisar, Jeong-A, Lee</li>
<li>for: 这个研究的目的是来提高深度神经网络（DNN）的推论运算的效率，并节省电力和能源。</li>
<li>methods: 这个研究使用了一种基于数位序列的左至右（DSLOT）运算技术，称为 DSLOT-NN，并使用了低延迟的最重要 digit-first（MSDF）多项式和加法器来进行资料处理。</li>
<li>results: 这个研究的结果显示，使用 DSLOT-NN 技术可以节省大量电力和能源，并且具有较短的循环时间和较高的 OPS 每瓦特。 compared with state-of-the-art Stripes 的性能指标。<details>
<summary>Abstract</summary>
We propose a Digit-Serial Left-tO-righT (DSLOT) arithmetic based processing technique called DSLOT-NN with aim to accelerate inference of the convolution operation in the deep neural networks (DNNs). The proposed work has the ability to assess and terminate the ineffective convolutions which results in massive power and energy savings. The processing engine is comprised of low-latency most-significant-digit-first (MSDF) (also called online) multipliers and adders that processes data from left-to-right, allowing the execution of subsequent operations in digit-pipelined manner. Use of online operators eliminates the need for the development of complex mechanism of identifying the negative activation, as the output with highest weight value is generated first, and the sign of the result can be identified as soon as first non-zero digit is generated. The precision of the online operators can be tuned at run-time, making them extremely useful in situations where accuracy can be compromised for power and energy savings. The proposed design has been implemented on Xilinx Virtex-7 FPGA and is compared with state-of-the-art Stripes on various performance metrics. The results show the proposed design presents power savings, has shorter cycle time, and approximately 50% higher OPS per watt.
</details>
<details>
<summary>摘要</summary>
Our processing engine consists of low-latency most-significant-digit-first (MSDF) multipliers and adders that process data from left to right, allowing for digit-pipelined execution. This eliminates the need for complex mechanisms to identify negative activation, as the output with the highest weight value is generated first, and the sign of the result can be identified as soon as the first non-zero digit is generated.The precision of our online operators can be tuned at runtime, making them highly versatile in situations where accuracy can be compromised for power and energy savings. We have implemented our design on Xilinx Virtex-7 FPGA and compared it with state-of-the-art Stripes on various performance metrics. Our results show that the proposed design achieves power savings, has a shorter cycle time, and offers approximately 50% higher operations per second per watt.
</details></li>
</ul>
<hr>
<h2 id="SoccerNet-2023-Challenges-Results"><a href="#SoccerNet-2023-Challenges-Results" class="headerlink" title="SoccerNet 2023 Challenges Results"></a>SoccerNet 2023 Challenges Results</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06006">http://arxiv.org/abs/2309.06006</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lRomul/ball-action-spotting">https://github.com/lRomul/ball-action-spotting</a></li>
<li>paper_authors: Anthony Cioppa, Silvio Giancola, Vladimir Somers, Floriane Magera, Xin Zhou, Hassan Mkhallati, Adrien Deliège, Jan Held, Carlos Hinojosa, Amir M. Mansourian, Pierre Miralles, Olivier Barnich, Christophe De Vleeschouwer, Alexandre Alahi, Bernard Ghanem, Marc Van Droogenbroeck, Abdullah Kamal, Adrien Maglo, Albert Clapés, Amr Abdelaziz, Artur Xarles, Astrid Orcesi, Atom Scott, Bin Liu, Byoungkwon Lim, Chen Chen, Fabian Deuser, Feng Yan, Fufu Yu, Gal Shitrit, Guanshuo Wang, Gyusik Choi, Hankyul Kim, Hao Guo, Hasby Fahrudin, Hidenari Koguchi, Håkan Ardö, Ibrahim Salah, Ido Yerushalmy, Iftikar Muhammad, Ikuma Uchida, Ishay Be’ery, Jaonary Rabarisoa, Jeongae Lee, Jiajun Fu, Jianqin Yin, Jinghang Xu, Jongho Nang, Julien Denize, Junjie Li, Junpei Zhang, Juntae Kim, Kamil Synowiec, Kenji Kobayashi, Kexin Zhang, Konrad Habel, Kota Nakajima, Licheng Jiao, Lin Ma, Lizhi Wang, Luping Wang, Menglong Li, Mengying Zhou, Mohamed Nasr, Mohamed Abdelwahed, Mykola Liashuha, Nikolay Falaleev, Norbert Oswald, Qiong Jia, Quoc-Cuong Pham, Ran Song, Romain Hérault, Rui Peng, Ruilong Chen, Ruixuan Liu, Ruslan Baikulov, Ryuto Fukushima, Sergio Escalera, Seungcheon Lee, Shimin Chen, Shouhong Ding, Taiga Someya, Thomas B. Moeslund, Tianjiao Li, Wei Shen, Wei Zhang, Wei Li, Wei Dai, Weixin Luo, Wending Zhao, Wenjie Zhang, Xinquan Yang, Yanbiao Ma, Yeeun Joo, Yingsen Zeng, Yiyang Gan, Yongqiang Zhu, Yujie Zhong, Zheng Ruan, Zhiheng Li, Zhijian Huang, Ziyu Meng<br>for:* 这篇论文是为了描述2023年度的SoccerNet视频理解挑战（第三届），这些挑战包括七个视觉任务，分为三个主题。methods:* 这篇论文使用了多种视觉技术，包括动作检测、球体变化检测、笔记录和Camera calibration等。results:* 这篇论文描述了2023年度的SoccerNet视频理解挑战，包括七个视觉任务的结果，其中有三个任务是新添加的，一个任务得到了更多的数据和注释，另一个任务改为着眼点到终端方法。<details>
<summary>Abstract</summary>
The SoccerNet 2023 challenges were the third annual video understanding challenges organized by the SoccerNet team. For this third edition, the challenges were composed of seven vision-based tasks split into three main themes. The first theme, broadcast video understanding, is composed of three high-level tasks related to describing events occurring in the video broadcasts: (1) action spotting, focusing on retrieving all timestamps related to global actions in soccer, (2) ball action spotting, focusing on retrieving all timestamps related to the soccer ball change of state, and (3) dense video captioning, focusing on describing the broadcast with natural language and anchored timestamps. The second theme, field understanding, relates to the single task of (4) camera calibration, focusing on retrieving the intrinsic and extrinsic camera parameters from images. The third and last theme, player understanding, is composed of three low-level tasks related to extracting information about the players: (5) re-identification, focusing on retrieving the same players across multiple views, (6) multiple object tracking, focusing on tracking players and the ball through unedited video streams, and (7) jersey number recognition, focusing on recognizing the jersey number of players from tracklets. Compared to the previous editions of the SoccerNet challenges, tasks (2-3-7) are novel, including new annotations and data, task (4) was enhanced with more data and annotations, and task (6) now focuses on end-to-end approaches. More information on the tasks, challenges, and leaderboards are available on https://www.soccer-net.org. Baselines and development kits can be found on https://github.com/SoccerNet.
</details>
<details>
<summary>摘要</summary>
occerNet 2023 挑战是第三届视频理解挑战，由 SoccerNet 团队组织。这一第三届挑战包括七个视觉任务，分为三个主题。第一主题是广播视频理解，包括三个高级任务：（1）动作搜索，关注从广播视频中检索全局动作的时间戳;（2）球动作搜索，关注从广播视频中检索球的状态变化时间戳;（3）稠密视频描述，关注使用自然语言描述广播视频，并附加时间戳。第二主题是场地理解，单个任务为（4）摄像头协调，关注从图像中提取摄像头参数。第三主题是球员理解，包括三个低级任务：（5）重识别，关注在多视图中重新识别同一名球员;（6）多对tracking，关注在未编辑视频流中跟踪球员和球;（7）球衣号码识别，关注从跟踪片中识别球员的球衣号码。相比前两届 SoccerNet 挑战，任务（2-3-7）是新的，包括新的注释和数据，任务（4）增加了更多的数据和注释，任务（6）现在专注于终端方法。更多关于任务、挑战和排名的信息可以在 <https://www.soccer-net.org> 上获取。基础和开发集可以在 <https://github.com/SoccerNet> 上找到。
</details></li>
</ul>
<hr>
<h2 id="Life-inspired-Interoceptive-Artificial-Intelligence-for-Autonomous-and-Adaptive-Agents"><a href="#Life-inspired-Interoceptive-Artificial-Intelligence-for-Autonomous-and-Adaptive-Agents" class="headerlink" title="Life-inspired Interoceptive Artificial Intelligence for Autonomous and Adaptive Agents"></a>Life-inspired Interoceptive Artificial Intelligence for Autonomous and Adaptive Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05999">http://arxiv.org/abs/2309.05999</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungwoo Lee, Younghyun Oh, Hyunhoe An, Hyebhin Yoon, Karl J. Friston, Seok Jun Hong, Choong-Wan Woo</li>
<li>for: 本研究的目的是建立自适应和自主的人工智能代理人，以便在不断变化的环境中存活和实现目标。</li>
<li>methods: 本研究使用了生物学中的感知过程，即监测自己的内部环境以保持在certain bounds内，以及生物学中的数学性质，以开发人工智能代理人。</li>
<li>results: 本研究提出了一种新的感知方法，可以帮助建立自适应和自主的人工智能代理人，并结合了遗传学、增强学习和神经科学的新进展。<details>
<summary>Abstract</summary>
Building autonomous --- i.e., choosing goals based on one's needs -- and adaptive -- i.e., surviving in ever-changing environments -- agents has been a holy grail of artificial intelligence (AI). A living organism is a prime example of such an agent, offering important lessons about adaptive autonomy. Here, we focus on interoception, a process of monitoring one's internal environment to keep it within certain bounds, which underwrites the survival of an organism. To develop AI with interoception, we need to factorize the state variables representing internal environments from external environments and adopt life-inspired mathematical properties of internal environment states. This paper offers a new perspective on how interoception can help build autonomous and adaptive agents by integrating the legacy of cybernetics with recent advances in theories of life, reinforcement learning, and neuroscience.
</details>
<details>
<summary>摘要</summary>
建立自主---即根据自己需求选择目标---以及适应---即在不断变化的环境中生存---的人工智能（AI）是人工智能的圣杯。生物体是这种代理人的一个好例子，它们提供了关键的适应自主性教训。在这里，我们关注内部环境监测---即保持内部环境在某些范围内---这一过程，这对生物体的存亡起到了关键作用。为建立具有内部监测能力的AI，我们需要将内部环境状态变量分离于外部环境状态变量，并采用生命力学中的内部环境状态生命力学性质。这篇论文提供了一种新的视角，即通过结合人工智能的启蒙、生命力学、奖励学习和神经科学的进步，实现内部监测能力的AI。
</details></li>
</ul>
<hr>
<h2 id="Goal-Space-Abstraction-in-Hierarchical-Reinforcement-Learning-via-Reachability-Analysis"><a href="#Goal-Space-Abstraction-in-Hierarchical-Reinforcement-Learning-via-Reachability-Analysis" class="headerlink" title="Goal Space Abstraction in Hierarchical Reinforcement Learning via Reachability Analysis"></a>Goal Space Abstraction in Hierarchical Reinforcement Learning via Reachability Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07168">http://arxiv.org/abs/2309.07168</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehdi Zadem, Sergio Mover, Sao Mai Nguyen</li>
<li>for: 提高开放式学习的效率和可贸转性，使用符号方法表示目标。</li>
<li>methods: 利用发展机制实现目标发现，通过emergent表示将环境状态集分组，保持环境动力学信息。</li>
<li>results: 在导航任务上，通过逐渐学习表示和策略，实现了数据效率和可贸转性。<details>
<summary>Abstract</summary>
Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information, such as the environment dynamics. In this work, we propose a developmental mechanism for subgoal discovery via an emergent representation that abstracts (i.e., groups together) sets of environment states that have similar roles in the task. We create a HRL algorithm that gradually learns this representation along with the policies and evaluate it on navigation tasks to show the learned representation is interpretable and results in data efficiency.
</details>
<details>
<summary>摘要</summary>
开放式学习受益于使用象征方法表示目标，因为它们可以为高效和可传递的学习提供结构知识。然而，现有的层次强化学习（HRL）方法，它们通常需要手动设定目标表示，这会带来一定的限制。挑战在自动发现象征目标表示时是保留环境动力学信息。在这种工作中，我们提出一种发展机制，通过观察环境状态的集合，自动找出子目标。我们创建了一种基于HRL算法，逐渐学习这种表示，并评估其在导航任务中的效果，结果表明学习的表示是可解释的，并且具有数据效率。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Guided-Short-Context-Action-Anticipation-in-Human-Centric-Videos"><a href="#Knowledge-Guided-Short-Context-Action-Anticipation-in-Human-Centric-Videos" class="headerlink" title="Knowledge-Guided Short-Context Action Anticipation in Human-Centric Videos"></a>Knowledge-Guided Short-Context Action Anticipation in Human-Centric Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05943">http://arxiv.org/abs/2309.05943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarthak Bhagat, Simon Stepputtis, Joseph Campbell, Katia Sycara</li>
<li>for: 预测长期人类行为，特别是使用短视频段，以提高编辑工作流程的速度和创造力。</li>
<li>methods: 使用 transformer 网络具有符号知识图，在视频段中预测行为，通过在运行时提高 transformer 的注意力机制来增强表现。</li>
<li>results: 在 Breakfast 和 50Salads 两个标准 datasets 上，我们的方法与当前状态的方法相比，在长期行为预测中使用短视频段的情况下提高了9%。<details>
<summary>Abstract</summary>
This work focuses on anticipating long-term human actions, particularly using short video segments, which can speed up editing workflows through improved suggestions while fostering creativity by suggesting narratives. To this end, we imbue a transformer network with a symbolic knowledge graph for action anticipation in video segments by boosting certain aspects of the transformer's attention mechanism at run-time. Demonstrated on two benchmark datasets, Breakfast and 50Salads, our approach outperforms current state-of-the-art methods for long-term action anticipation using short video context by up to 9%.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Answering-Subjective-Induction-Questions-on-Products-by-Summarizing-Multi-sources-Multi-viewpoints-Knowledge"><a href="#Answering-Subjective-Induction-Questions-on-Products-by-Summarizing-Multi-sources-Multi-viewpoints-Knowledge" class="headerlink" title="Answering Subjective Induction Questions on Products by Summarizing Multi-sources Multi-viewpoints Knowledge"></a>Answering Subjective Induction Questions on Products by Summarizing Multi-sources Multi-viewpoints Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05938">http://arxiv.org/abs/2309.05938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yufeng Zhang, Meng-xiang Wang, Jianxing Yu</li>
<li>for: 提出了一个新的 Answering Subjective Induction Question on Products (SUBJPQA) 任务，解决这类问题的答案不固定，可以从多个角度解释。</li>
<li>methods: 提出了三步方法：首先从多个知识源中检索答案相关的线索，并收集了相关的印象知识；然后通过交互式注意力捕捉问题中的相关性；最后，通过模板控制的解码器输出了全面和多角度的答案。</li>
<li>results: 由于这个新任务没有相关的评估标准集，因此 constructed a large-scale dataset named SupQA，包含48,352个样本和15种产品领域。评估结果表明了我们的方法的效果。<details>
<summary>Abstract</summary>
This paper proposes a new task in the field of Answering Subjective Induction Question on Products (SUBJPQA). The answer to this kind of question is non-unique, but can be interpreted from many perspectives. For example, the answer to 'whether the phone is heavy' has a variety of different viewpoints. A satisfied answer should be able to summarize these subjective opinions from multiple sources and provide objective knowledge, such as the weight of a phone. That is quite different from the traditional QA task, in which the answer to a factoid question is unique and can be found from a single data source. To address this new task, we propose a three-steps method. We first retrieve all answer-related clues from multiple knowledge sources on facts and opinions. The implicit commonsense facts are also collected to supplement the necessary but missing contexts. We then capture their relevance with the questions by interactive attention. Next, we design a reinforcement-based summarizer to aggregate all these knowledgeable clues. Based on a template-controlled decoder, we can output a comprehensive and multi-perspective answer. Due to the lack of a relevant evaluated benchmark set for the new task, we construct a large-scale dataset, named SupQA, consisting of 48,352 samples across 15 product domains. Evaluation results show the effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:这篇论文提出了一个新的任务，即答え问题 Answering Subjective Induction Questions on Products (SUBJPQA)。这类问题的答案不唯一，可以从多个角度解释。例如，问题 "手机是否重" 有多种不同的看法。一个满意的答案应该能够汇集多个来源的主观意见，并提供对象知识，如手机的重量。这与传统的 QA 任务不同，传统的答案是唯一的，可以从单个数据源中找到。为 Addressing this new task, the authors propose a three-step method. First, they retrieve all answer-related clues from multiple knowledge sources on facts and opinions. They also collect implicit commonsense facts to supplement necessary but missing contexts. Next, they capture the relevance of the clues with the questions using interactive attention. Finally, they design a reinforcement-based summarizer to aggregate all the knowledgeable clues. Based on a template-controlled decoder, they can output a comprehensive and multi-perspective answer. Due to the lack of a relevant evaluated benchmark set for the new task, the authors construct a large-scale dataset named SupQA, consisting of 48,352 samples across 15 product domains. The evaluation results show the effectiveness of their approach.
</details></li>
</ul>
<hr>
<h2 id="MatSciML-A-Broad-Multi-Task-Benchmark-for-Solid-State-Materials-Modeling"><a href="#MatSciML-A-Broad-Multi-Task-Benchmark-for-Solid-State-Materials-Modeling" class="headerlink" title="MatSciML: A Broad, Multi-Task Benchmark for Solid-State Materials Modeling"></a>MatSciML: A Broad, Multi-Task Benchmark for Solid-State Materials Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05934">http://arxiv.org/abs/2309.05934</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/intellabs/matsciml">https://github.com/intellabs/matsciml</a></li>
<li>paper_authors: Kin Long Kelvin Lee, Carmelo Gonzales, Marcel Nassar, Matthew Spellings, Mikhail Galkin, Santiago Miret</li>
<li>For: 该论文目的是提出一个新的benchmark，用于模型化固体材料科学领域中的机器学习方法。* Methods: 该论文使用的方法包括使用开源数据集，包括大规模数据集如OpenCatalyst、OQMD、NOMAD、Carolina Materials Database和Materials Project等，以及 simulated energies、atomic forces、材料带隔和 Space group classification数据等。* Results: 该论文通过使用多个数据集进行联合预测，实现了对固体材料的多任务学习和多数据集学习。通过 MatSci ML  benchmark，研究人员可以评估不同的 graf neural network 和 equivariant point cloud network 在多种学习场景中的性能。<details>
<summary>Abstract</summary>
We propose MatSci ML, a novel benchmark for modeling MATerials SCIence using Machine Learning (MatSci ML) methods focused on solid-state materials with periodic crystal structures. Applying machine learning methods to solid-state materials is a nascent field with substantial fragmentation largely driven by the great variety of datasets used to develop machine learning models. This fragmentation makes comparing the performance and generalizability of different methods difficult, thereby hindering overall research progress in the field. Building on top of open-source datasets, including large-scale datasets like the OpenCatalyst, OQMD, NOMAD, the Carolina Materials Database, and Materials Project, the MatSci ML benchmark provides a diverse set of materials systems and properties data for model training and evaluation, including simulated energies, atomic forces, material bandgaps, as well as classification data for crystal symmetries via space groups. The diversity of properties in MatSci ML makes the implementation and evaluation of multi-task learning algorithms for solid-state materials possible, while the diversity of datasets facilitates the development of new, more generalized algorithms and methods across multiple datasets. In the multi-dataset learning setting, MatSci ML enables researchers to combine observations from multiple datasets to perform joint prediction of common properties, such as energy and forces. Using MatSci ML, we evaluate the performance of different graph neural networks and equivariant point cloud networks on several benchmark tasks spanning single task, multitask, and multi-data learning scenarios. Our open-source code is available at https://github.com/IntelLabs/matsciml.
</details>
<details>
<summary>摘要</summary>
我们提出了MatSci ML，一个新的测试基准 для模型化材料科学使用机器学习方法（MatSci ML），专注于固体材料 periodic crystal structures 的模型。采用机器学习方法对固体材料是一个新兴领域，受到各种数据集的不同所致，这种分化使得对不同方法的比较和总体进展困难，从而阻碍了材料科学领域的研究进步。基于开源数据集，包括大规模数据集如OpenCatalyst、OQMD、NOMAD、Carolina Materials Database和Materials Project，MatSci ML 提供了多种材料系统和性能数据 для模型训练和评估，包括模拟能量、原子力、材料带隙、以及通过空间群来分类的晶体结构数据。MatSci ML 中的多种属性多样性使得实现和评估多任务学习算法 для固体材料 possible，而多种数据集的多样性促进了新的、更一般的算法和方法的开发。在多个数据集学习 Setting，MatSci ML 允许研究人员将多个数据集中的观察结果合并进行共同预测常见的属性，如能量和力。使用 MatSci ML，我们评估了不同的图 neural networks 和平衡点云网络在多个benchmark任务中的表现，涵盖单任务、多任务和多数据学习场景。我们的开源代码可以在https://github.com/IntelLabs/matsciml 中找到。
</details></li>
</ul>
<hr>
<h2 id="Combining-deep-learning-and-street-view-imagery-to-map-smallholder-crop-types"><a href="#Combining-deep-learning-and-street-view-imagery-to-map-smallholder-crop-types" class="headerlink" title="Combining deep learning and street view imagery to map smallholder crop types"></a>Combining deep learning and street view imagery to map smallholder crop types</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05930">http://arxiv.org/abs/2309.05930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordi Laguarta, Thomas Friedel, Sherrie Wang</li>
<li>for: 该研究的目的是为了创建一个全球范围内的农作物类型地图，以便监测农作物生长进度，预测全球农产量，并制定有效的政策。</li>
<li>methods: 该研究使用了深度学习技术和Google街景图像来自动生成农作物类型的地面参考数据。他们首先选择了一组街景图像，然后使用这些图像来训练一个模型，以便预测农作物类型。最后，他们将预测的标签与Remote sensing时序列结合，以创建一个无缝的农作物类型地图。</li>
<li>results: 研究发现，在泰国，该方法可以创建一个国家范围内的全面的rice、manioc、maize和甘蔗类型地图，其准确率达93%。这种方法可以在全球各地，尤其是小农场地区，提供一种快速、便宜、高准确率的农作物类型地图生成方式。<details>
<summary>Abstract</summary>
Accurate crop type maps are an essential source of information for monitoring yield progress at scale, projecting global crop production, and planning effective policies. To date, however, crop type maps remain challenging to create in low and middle-income countries due to a lack of ground truth labels for training machine learning models. Field surveys are the gold standard in terms of accuracy but require an often-prohibitively large amount of time, money, and statistical capacity. In recent years, street-level imagery, such as Google Street View, KartaView, and Mapillary, has become available around the world. Such imagery contains rich information about crop types grown at particular locations and times. In this work, we develop an automated system to generate crop type ground references using deep learning and Google Street View imagery. The method efficiently curates a set of street view images containing crop fields, trains a model to predict crop type by utilizing weakly-labelled images from disparate out-of-domain sources, and combines predicted labels with remote sensing time series to create a wall-to-wall crop type map. We show that, in Thailand, the resulting country-wide map of rice, cassava, maize, and sugarcane achieves an accuracy of 93%. As the availability of roadside imagery expands, our pipeline provides a way to map crop types at scale around the globe, especially in underserved smallholder regions.
</details>
<details>
<summary>摘要</summary>
准确的作物类别地图是考古规模监测作物进步、全球作物产量预测和制定有效政策的重要来源。然而，在LOW和中等收入国家，创建作物类别地图仍然是一项挑战，因为缺乏地面 truth标签用于训练机器学习模型。 Field surveys 是精度最高的标准，但它们需要大量的时间、金钱和统计资源。在最近几年，街道级别的图像，如Google Street View、KartaView和Mapillary，在全球变得可用。这些图像包含特定地点和时间的作物种植的详细信息。在这个工作中，我们开发了一个自动化的系统，使用深度学习和Google Street View图像来生成作物类别地标。该方法可以效率地筛选出包含作物田的街道图像，使用弱 labels 的图像从不同的域外来源来训练模型，并将预测标签与远程感知时序列合并以创建墙到墙的作物类别地图。我们显示，在泰国，得到的国家范围内的rice、 Cassava、maize和sugarcane的地图达到93%的准确率。随着路边图像的可用性扩展，我们的管道可以在全球范围内地图作物类别，特别是在小holder地区。
</details></li>
</ul>
<hr>
<h2 id="Frequency-Aware-Masked-Autoencoders-for-Multimodal-Pretraining-on-Biosignals"><a href="#Frequency-Aware-Masked-Autoencoders-for-Multimodal-Pretraining-on-Biosignals" class="headerlink" title="Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals"></a>Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05927">http://arxiv.org/abs/2309.05927</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ran Liu, Ellen L. Zippi, Hadi Pouransari, Chris Sandino, Jingping Nie, Hanlin Goh, Erdrin Azemi, Ali Moin</li>
<li>for: 本研究旨在提出一种适应多模态信号各种任务和多样性挑战的预训练方法，以提高对多模态信号的表征和预测性能。</li>
<li>methods: 本研究提出了一种频率意识的掩码自动编码器（$\texttt{bio}$FAME），它通过在频率空间中参数化信号表征来适应多模态信号的分布变化。该方法还包括一种频率维护预训练策略，通过在干扰空间中进行掩码自动编码来保持输入信号中的频率成分。</li>
<li>results: 对一系列的转移试验，我们获得了平均提高5.5%的分类精度，至于之前的状态艺术。此外，我们还证明了该方法在模式匹配情况下具有强大的实用性，包括预期不确定的模式掉包或替换。<details>
<summary>Abstract</summary>
Leveraging multimodal information from biosignals is vital for building a comprehensive representation of people's physical and mental states. However, multimodal biosignals often exhibit substantial distributional shifts between pretraining and inference datasets, stemming from changes in task specification or variations in modality compositions. To achieve effective pretraining in the presence of potential distributional shifts, we propose a frequency-aware masked autoencoder ($\texttt{bio}$FAME) that learns to parameterize the representation of biosignals in the frequency space. $\texttt{bio}$FAME incorporates a frequency-aware transformer, which leverages a fixed-size Fourier-based operator for global token mixing, independent of the length and sampling rate of inputs. To maintain the frequency components within each input channel, we further employ a frequency-maintain pretraining strategy that performs masked autoencoding in the latent space. The resulting architecture effectively utilizes multimodal information during pretraining, and can be seamlessly adapted to diverse tasks and modalities at test time, regardless of input size and order. We evaluated our approach on a diverse set of transfer experiments on unimodal time series, achieving an average of $\uparrow$5.5% improvement in classification accuracy over the previous state-of-the-art. Furthermore, we demonstrated that our architecture is robust in modality mismatch scenarios, including unpredicted modality dropout or substitution, proving its practical utility in real-world applications. Code will be available soon.
</details>
<details>
<summary>摘要</summary>
利用多Modal信息从生物信号是建立全面人体和心理状态的关键。然而，多Modal生物信号经常会在预训练和测试集数据中出现重大的分布变化，这可能是因为任务规定的变化或多Modal组合的变化。为了在可能存在的分布变化情况下进行有效的预训练，我们提议一种频率意识的隐藏式自动编码器（$\texttt{bio}$FAME），该模型学习在频率空间中 parameterize 生物信号的表示。$\texttt{bio}$FAME 包含一种频率意识的转换器，该转换器通过固定大小的干扰函数来进行全token混合，不виси于输入的长度和采样率。为了保持每个输入通道中的频率组件，我们还采用了一种保持频率的预训练策略，该策略在幽latent空间进行隐藏式自动编码。这种架构可以有效利用多Modal信息进行预训练，并可以在测试时轻松适应多种任务和多Modal，无论输入的大小和顺序。我们对一组多Modal时间序列转换任务进行了多种转换试验，实现了平均提高5.5%的分类精度，胜过之前的状态艺。此外，我们还证明了我们的架构在模态匹配情况下具有实用性，包括预测不可预知的模态掉落或替换，证明了它在实际应用中的实用性。代码即将上传。
</details></li>
</ul>
<hr>
<h2 id="On-Regularized-Sparse-Logistic-Regression"><a href="#On-Regularized-Sparse-Logistic-Regression" class="headerlink" title="On Regularized Sparse Logistic Regression"></a>On Regularized Sparse Logistic Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05925">http://arxiv.org/abs/2309.05925</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RohithM191/TSNE-on-Amazon-Fine-Food-reviews-Dataset">https://github.com/RohithM191/TSNE-on-Amazon-Fine-Food-reviews-Dataset</a></li>
<li>paper_authors: Mengyuan Zhang, Kai Liu</li>
<li>for: 这篇论文的目的是用来解决高维度数据中的分类和特征选择问题，同时使用非凸补助项来减少数据的维度。</li>
<li>methods: 本文提出了一些新的优化框架，用于解决这些问题，包括使用不同的条搜搜索准则来保证优化结果的好几何性。</li>
<li>results: 实验结果显示，提出的算法可以实现高效的分类和特征选择，并且比较低的计算成本。<details>
<summary>Abstract</summary>
Sparse logistic regression aims to perform classification and feature selection simultaneously for high-dimensional data. Although many studies have been done to solve $\ell_1$-regularized logistic regression, there is no equivalently abundant literature about solving sparse logistic regression associated with nonconvex penalties. In this paper, we propose to solve $\ell_1$-regularized sparse logistic regression and some nonconvex penalties-regularized sparse logistic regression, when the nonconvex penalties satisfy some prerequisites, with similar optimization frameworks. In the proposed optimization frameworks, we utilize different line search criteria to guarantee good convergence performance for different regularization terms. Empirical experiments on binary classification tasks with real-world datasets demonstrate our proposed algorithms are capable of performing classification and feature selection effectively with a lower computational cost.
</details>
<details>
<summary>摘要</summary>
“稀疏逻辑回传数据类别和特征选择同时进行分类。处理 $\ell_1$-规定逻辑回传数据的研究已经很多，但是关于非对称责任逻辑回传数据的研究却没有相应的实践。本文提出了解决 $\ell_1$-规定稀疏逻辑回传数据和一些非对称责任逻辑回传数据的优化框架。在提议的优化框架中，我们利用不同的搜索条件来保证不同的规定Terms的优化表现良好。实验结果显示我们的提议算法在实际数据上能够有效地进行分类和特征选择，并且比较低的计算成本。”Note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Hallucination-in-Large-Foundation-Models"><a href="#A-Survey-of-Hallucination-in-Large-Foundation-Models" class="headerlink" title="A Survey of Hallucination in Large Foundation Models"></a>A Survey of Hallucination in Large Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05922">http://arxiv.org/abs/2309.05922</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vr25/hallucination-foundation-model-survey">https://github.com/vr25/hallucination-foundation-model-survey</a></li>
<li>paper_authors: Vipula Rawte, Amit Sheth, Amitava Das</li>
<li>for: 本文提供了关于基础模型中幻觉现象的广泛审视和分析，尤其是大基础模型（LFM）中幻觉现象的研究进展。</li>
<li>methods: 本文对幻觉现象进行分类，并确定了评估幻觉程度的评价标准。同时，本文还检查了现有的幻觉控制策略，并讨论了未来研究的可能性。</li>
<li>results: 本文提供了关于幻觉在LFM中的全面检查和解决方案。<details>
<summary>Abstract</summary>
Hallucination in a foundation model (FM) refers to the generation of content that strays from factual reality or includes fabricated information. This survey paper provides an extensive overview of recent efforts that aim to identify, elucidate, and tackle the problem of hallucination, with a particular focus on ``Large'' Foundation Models (LFMs). The paper classifies various types of hallucination phenomena that are specific to LFMs and establishes evaluation criteria for assessing the extent of hallucination. It also examines existing strategies for mitigating hallucination in LFMs and discusses potential directions for future research in this area. Essentially, the paper offers a comprehensive examination of the challenges and solutions related to hallucination in LFMs.
</details>
<details>
<summary>摘要</summary>
幻想在基础模型（FM）中指的是生成不符事实或包含虚假信息的内容。这篇评论文章提供了对最近努力防止幻想的全面回顾，尤其是对大型基础模型（LFMs）的幻想问题。文章分类了LFMs中幻想现象的不同类型，并设置了评估幻想程度的评价标准。它还检查了现有的防止幻想策略，并讨论了未来研究的可能性。简言之，文章提供了幻想在LFMs中的挑战和解决方案的全面检查。
</details></li>
</ul>
<hr>
<h2 id="SAGE-Structured-Attribute-Value-Generation-for-Billion-Scale-Product-Catalogs"><a href="#SAGE-Structured-Attribute-Value-Generation-for-Billion-Scale-Product-Catalogs" class="headerlink" title="SAGE: Structured Attribute Value Generation for Billion-Scale Product Catalogs"></a>SAGE: Structured Attribute Value Generation for Billion-Scale Product Catalogs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05920">http://arxiv.org/abs/2309.05920</a></li>
<li>repo_url: None</li>
<li>paper_authors: Athanasios N. Nikolakopoulos, Swati Kaul, Siva Karthik Gade, Bella Dubrov, Umit Batur, Suleiman Ali Khan</li>
<li>for: 这篇论文旨在为电商平台中的产品 attribute 值预测做出提高。</li>
<li>methods: 该论文提出了一种新的 attribute-value 预测方法，基于 Seq2Seq 概率模型，可以适应不同语言、产品类型和目标 attribute。该方法可以预测 attribute 值，even when such values are mentioned implicitly using periphrastic language, or not-at-all-as is the case for common-sense defaults。</li>
<li>results: 实验表明，该方法可以有效地预测 attribute 值，并且比之前的方法更高效。此外，该方法还可以预测 attribute 值在零例教程下，从而减少需要训练的数据量。<details>
<summary>Abstract</summary>
We introduce SAGE; a Generative LLM for inferring attribute values for products across world-wide e-Commerce catalogs. We introduce a novel formulation of the attribute-value prediction problem as a Seq2Seq summarization task, across languages, product types and target attributes. Our novel modeling approach lifts the restriction of predicting attribute values within a pre-specified set of choices, as well as, the requirement that the sought attribute values need to be explicitly mentioned in the text. SAGE can infer attribute values even when such values are mentioned implicitly using periphrastic language, or not-at-all-as is the case for common-sense defaults. Additionally, SAGE is capable of predicting whether an attribute is inapplicable for the product at hand, or non-obtainable from the available information. SAGE is the first method able to tackle all aspects of the attribute-value-prediction task as they arise in practical settings in e-Commerce catalogs. A comprehensive set of experiments demonstrates the effectiveness of the proposed approach, as well as, its superiority against state-of-the-art competing alternatives. Moreover, our experiments highlight SAGE's ability to tackle the task of predicting attribute values in zero-shot setting; thereby, opening up opportunities for significantly reducing the overall number of labeled examples required for training.
</details>
<details>
<summary>摘要</summary>
我们介绍SAGE；一种生成式LLM用于在全球电子商务目录中预测产品的属性值。我们提出了一种新的属性值预测问题的表述方式，即将属性值预测问题转化为一个Seq2Seq摘要任务，跨语言、产品类型和目标属性。我们的新的模型方法解决了预测属性值时的限制，包括预测属性值必须在先Specified的选择范围内，以及文本中必须直接提到属性值。SAGE可以在文本中推断属性值，即使这些值是使用射igrated语言表达或者不直接提到。此外，SAGE还可以预测产品上的属性是否存在或者可以从可用信息中获取。SAGE是第一种能够在实际设置中解决所有属性值预测问题的方法。一系列实验证明了我们的方法的有效性和其对State-of-the-art的竞争方法的超越性。此外，我们的实验还 highlight了SAGE在零shot设置下预测属性值的能力，从而开启了减少训练数据的机会。
</details></li>
</ul>
<hr>
<h2 id="Stochastic-LLMs-do-not-Understand-Language-Towards-Symbolic-Explainable-and-Ontologically-Based-LLMs"><a href="#Stochastic-LLMs-do-not-Understand-Language-Towards-Symbolic-Explainable-and-Ontologically-Based-LLMs" class="headerlink" title="Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs"></a>Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05918">http://arxiv.org/abs/2309.05918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Walid S. Saba</li>
<li>for: 这篇论文是关于大语言模型（LLMs）的研究，主要探讨了 LLMS 的限制和不足，并提出了一种符号驱动的语言模型的建议。</li>
<li>methods: 本论文使用了数据驱动的方法，对 LLMS 进行了分析和评估，并提出了一种符号驱动的语言模型的建议。</li>
<li>results: 本论文的研究结果表明，LLMS 存在许多限制和不足，如不能准确地提供实际信息，因为它们所有的文本都被视为一样有价值的；此外，LLMS 的知识也会被归类为微特征（weights）中，无法归纳到有意义的概念中；此外，LLMS 在某些语言上也会出现偏差。<details>
<summary>Abstract</summary>
In our opinion the exuberance surrounding the relative success of data-driven large language models (LLMs) is slightly misguided and for several reasons (i) LLMs cannot be relied upon for factual information since for LLMs all ingested text (factual or non-factual) was created equal; (ii) due to their subsymbolic na-ture, whatever 'knowledge' these models acquire about language will always be buried in billions of microfeatures (weights), none of which is meaningful on its own; and (iii) LLMs will often fail to make the correct inferences in several linguistic contexts (e.g., nominal compounds, copredication, quantifier scope ambi-guities, intensional contexts. Since we believe the relative success of data-driven large language models (LLMs) is not a reflection on the symbolic vs. subsymbol-ic debate but a reflection on applying the successful strategy of a bottom-up reverse engineering of language at scale, we suggest in this paper applying the effective bottom-up strategy in a symbolic setting resulting in symbolic, explainable, and ontologically grounded language models.
</details>
<details>
<summary>摘要</summary>
我们认为大量数据驱动的大型自然语言模型（LLM）的热情是有所误导的，主要有以下几点原因：1. LLM不能依赖于事实信息，因为它们对所有的文本（事实或非事实）都是一样的；2.由于它们的非符号性质，LMM所获得的语言知识都将被归类为微特征（ weights），这些微特征都是无法单独解释的；3. LLM在某些语言上将不能做出正确的推理，如名词复合、共Predication、量词范围不确定性、意思上的context。因为我们认为数据驱动大型自然语言模型（LLM）的成功不是符号vs非符号的问题，而是应用大规模的底层逆工程Strategy的成功，因此在这篇论文中，我们建议在符号环境中应用有效的底层逆工程策略，从而获得符号、可解释、基于ontology的语言模型。
</details></li>
</ul>
<hr>
<h2 id="ACT-Empowering-Decision-Transformer-with-Dynamic-Programming-via-Advantage-Conditioning"><a href="#ACT-Empowering-Decision-Transformer-with-Dynamic-Programming-via-Advantage-Conditioning" class="headerlink" title="ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning"></a>ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05915">http://arxiv.org/abs/2309.05915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenxiao Gao, Chenyang Wu, Mingjun Cao, Rui Kong, Zongzhang Zhang, Yang Yu</li>
<li>for: 提高offline政策优化中DT的表现，透过带有表达性的序列模型技术来实现行动生成。</li>
<li>methods: 使用动态计划来强化DT，包括三步：首先，使用样本中的值迭代来获取估计价值函数，其中具有MDP结构的动态计划特性。其次，评估行动质量基于估计的优势。引入两种优势估计器，IAE和GAE，适用于不同任务。最后，使用优势 Conditioned Transformer (ACT) 来生成基于估计优势的行动。</li>
<li>results: 测试结果表明，通过借鉴动态计划的能力，ACT能够在环境杂化下表现出效果很好，与基eline方法在各种标准准则上表现出色。此外，我们通过减少分析来检验ACT的不同设计方案的影响。<details>
<summary>Abstract</summary>
Decision Transformer (DT), which employs expressive sequence modeling techniques to perform action generation, has emerged as a promising approach to offline policy optimization. However, DT generates actions conditioned on a desired future return, which is known to bear some weaknesses such as the susceptibility to environmental stochasticity. To overcome DT's weaknesses, we propose to empower DT with dynamic programming. Our method comprises three steps. First, we employ in-sample value iteration to obtain approximated value functions, which involves dynamic programming over the MDP structure. Second, we evaluate action quality in context with estimated advantages. We introduce two types of advantage estimators, IAE and GAE, which are suitable for different tasks. Third, we train an Advantage-Conditioned Transformer (ACT) to generate actions conditioned on the estimated advantages. Finally, during testing, ACT generates actions conditioned on a desired advantage. Our evaluation results validate that, by leveraging the power of dynamic programming, ACT demonstrates effective trajectory stitching and robust action generation in spite of the environmental stochasticity, outperforming baseline methods across various benchmarks. Additionally, we conduct an in-depth analysis of ACT's various design choices through ablation studies.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Quality-Agnostic-Deepfake-Detection-with-Intra-model-Collaborative-Learning"><a href="#Quality-Agnostic-Deepfake-Detection-with-Intra-model-Collaborative-Learning" class="headerlink" title="Quality-Agnostic Deepfake Detection with Intra-model Collaborative Learning"></a>Quality-Agnostic Deepfake Detection with Intra-model Collaborative Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05911">http://arxiv.org/abs/2309.05911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://bitbucket.org/deepfake-project/qad-iccv23">https://bitbucket.org/deepfake-project/qad-iccv23</a></li>
<li>paper_authors: Binh M. Le, Simon S. Woo</li>
<li>for: 这个研究旨在提出一个 universial 的内部型别学习框架，以实现不同质量的深伪检测。</li>
<li>methods: 我们使用一个名为 QAD 的quality-agnostic deepfake detection方法，通过观察通用错误预期函数的上限，将不同质量水平的图像间的中间表现dependency最大化。</li>
<li>results: 我们的 QAD 模型在七个受测 dataset 上进行了广泛的实验，与先前的 SOTA benchmark 相比，表现出色。<details>
<summary>Abstract</summary>
Deepfake has recently raised a plethora of societal concerns over its possible security threats and dissemination of fake information. Much research on deepfake detection has been undertaken. However, detecting low quality as well as simultaneously detecting different qualities of deepfakes still remains a grave challenge. Most SOTA approaches are limited by using a single specific model for detecting certain deepfake video quality type. When constructing multiple models with prior information about video quality, this kind of strategy incurs significant computational cost, as well as model and training data overhead. Further, it cannot be scalable and practical to deploy in real-world settings. In this work, we propose a universal intra-model collaborative learning framework to enable the effective and simultaneous detection of different quality of deepfakes. That is, our approach is the quality-agnostic deepfake detection method, dubbed QAD . In particular, by observing the upper bound of general error expectation, we maximize the dependency between intermediate representations of images from different quality levels via Hilbert-Schmidt Independence Criterion. In addition, an Adversarial Weight Perturbation module is carefully devised to enable the model to be more robust against image corruption while boosting the overall model's performance. Extensive experiments over seven popular deepfake datasets demonstrate the superiority of our QAD model over prior SOTA benchmarks.
</details>
<details>
<summary>摘要</summary>
为了解决这个问题，我们提出了一种通用内部协作学习框架，以实现不同质量深圳投影的同时检测。具体来说，我们通过观察总体错误预期的上限来 maximize 图像不同质量水平之间的依赖关系，使用希尔伯特-施密特独立性 критерион。此外，我们还妥善地设计了一个对抗权重偏移模块，以使模型更加抗 resize 而增强整体模型的表现。我们在七个流行的深圳投影数据集上进行了广泛的实验，并证明了我们的 QAD 模型在先前的 SOTA 标准之上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Comparing-Llama-2-and-GPT-3-LLMs-for-HPC-kernels-generation"><a href="#Comparing-Llama-2-and-GPT-3-LLMs-for-HPC-kernels-generation" class="headerlink" title="Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation"></a>Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07103">http://arxiv.org/abs/2309.07103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pedro Valero-Lara, Alexis Huante, Mustafa Al Lail, William F. Godoy, Keita Teranishi, Prasanna Balaprakash, Jeffrey S. Vetter</li>
<li>for: 本研究用于评估开源模型Llama-2在不同并行编程模型和语言（如C++：OpenMP、OpenMP Offload、OpenACC、CUDA、HIP；Fortran：OpenMP、OpenMP Offload、OpenACC；Python：numpy、Numba、pyCUDA、cuPy；Julia：Threads、CUDA.jl、AMDGPU.jl）中生成高性能计算kernels（如AXPY、GEMV、GEMM）的可能性。</li>
<li>methods: 本研究基于我们之前的工作，该基于OpenAI Codex，一个基于GPT-3的descendant，通过GitHub Copilot生成类似kernels的简单提示。我们的目标是比较Llama-2和我们原始GPT-3基线的准确率，使用相似的指标。</li>
<li>results: Llama-2模型在生成kernels时显示了竞争力或更高的准确率，而Copilot生成的代码更可靠但 menos优化，相反，Llama-2生成的代码虽然更不可靠但更高效当 corrrect。<details>
<summary>Abstract</summary>
We evaluate the use of the open-source Llama-2 model for generating well-known, high-performance computing kernels (e.g., AXPY, GEMV, GEMM) on different parallel programming models and languages (e.g., C++: OpenMP, OpenMP Offload, OpenACC, CUDA, HIP; Fortran: OpenMP, OpenMP Offload, OpenACC; Python: numpy, Numba, pyCUDA, cuPy; and Julia: Threads, CUDA.jl, AMDGPU.jl). We built upon our previous work that is based on the OpenAI Codex, which is a descendant of GPT-3, to generate similar kernels with simple prompts via GitHub Copilot. Our goal is to compare the accuracy of Llama-2 and our original GPT-3 baseline by using a similar metric. Llama-2 has a simplified model that shows competitive or even superior accuracy. We also report on the differences between these foundational large language models as generative AI continues to redefine human-computer interactions. Overall, Copilot generates codes that are more reliable but less optimized, whereas codes generated by Llama-2 are less reliable but more optimized when correct.
</details>
<details>
<summary>摘要</summary>
我们评估了基于开源的Llama-2模型来生成知名度高、性能优秀的计算器件（例如AXPY、GEMV、GEMM）在不同的并行编程模型和语言（例如C++：OpenMP、OpenMP Offload、OpenACC、CUDA、HIP；Fortran：OpenMP、OpenMP Offload、OpenACC；Python：numpy、Numba、pyCUDA、cuPy；Julia：Threads、CUDA.jl、AMDGPU.jl）上。我们基于我们之前的工作，这是基于OpenAI Codex，这是GPT-3的后代，通过GitHub Copilot来生成类似的kernels。我们的目标是将Llama-2和我们原始的GPT-3基线相比，使用相似的度量。Llama-2有简化的模型，并显示了竞争或更高的准确性。我们还报告了这些基础的大语言模型在人机交互中如何不断定义。总之，Copilot生成的代码更可靠但较少优化，而Llama-2生成的代码虽然较不可靠但当正确时更高效。
</details></li>
</ul>
<hr>
<h2 id="Strategic-Behavior-of-Large-Language-Models-Game-Structure-vs-Contextual-Framing"><a href="#Strategic-Behavior-of-Large-Language-Models-Game-Structure-vs-Contextual-Framing" class="headerlink" title="Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing"></a>Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05898">http://arxiv.org/abs/2309.05898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nunzio Lorè, Babak Heydari</li>
<li>for: 本研究探讨三种大语言模型（GPT-3.5、GPT-4和LLaMa-2）在游戏理论框架下的策略决策能力。</li>
<li>methods: 研究使用四个标准两人游戏（囚徒困境、鹿猎、雪崩和囚徒欢乐）来探讨这些模型在社会决策中的 navigate能力。</li>
<li>results: 研究发现，GPT-3.5受到上下文框架的影响很大，但是它对抽象的策略理解能力有限。GPT-4和LLaMa-2根据游戏结构和上下文进行策略调整，但LLaMa-2表现出更加细腻的游戏机制理解。这些结果 highlights current LLMs的限制和不同的聪明程度，警告不要在需要复杂策略理解的任务中不经过训练使用LLMs。<details>
<summary>Abstract</summary>
This paper investigates the strategic decision-making capabilities of three Large Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework of game theory. Utilizing four canonical two-player games -- Prisoner's Dilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these models navigate social dilemmas, situations where players can either cooperate for a collective benefit or defect for individual gain. Crucially, we extend our analysis to examine the role of contextual framing, such as diplomatic relations or casual friendships, in shaping the models' decisions. Our findings reveal a complex landscape: while GPT-3.5 is highly sensitive to contextual framing, it shows limited ability to engage in abstract strategic reasoning. Both GPT-4 and LLaMa-2 adjust their strategies based on game structure and context, but LLaMa-2 exhibits a more nuanced understanding of the games' underlying mechanics. These results highlight the current limitations and varied proficiencies of LLMs in strategic decision-making, cautioning against their unqualified use in tasks requiring complex strategic reasoning.
</details>
<details>
<summary>摘要</summary>
The findings show that GPT-3.5 is highly sensitive to contextual framing, but has limited ability to engage in abstract strategic reasoning. Both GPT-4 and LLaMa-2 adjust their strategies based on game structure and context, but LLaMa-2 demonstrates a more nuanced understanding of the games' underlying mechanics. These results highlight the current limitations and varied proficiencies of LLMs in strategic decision-making, and caution against their unqualified use in tasks requiring complex strategic reasoning.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/12/cs.AI_2023_09_12/" data-id="clohum93i003ypj88089zd02c" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/12/cs.CL_2023_09_12/" class="article-date">
  <time datetime="2023-09-12T11:00:00.000Z" itemprop="datePublished">2023-09-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/12/cs.CL_2023_09_12/">cs.CL - 2023-09-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="RT-LM-Uncertainty-Aware-Resource-Management-for-Real-Time-Inference-of-Language-Models"><a href="#RT-LM-Uncertainty-Aware-Resource-Management-for-Real-Time-Inference-of-Language-Models" class="headerlink" title="RT-LM: Uncertainty-Aware Resource Management for Real-Time Inference of Language Models"></a>RT-LM: Uncertainty-Aware Resource Management for Real-Time Inference of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06619">http://arxiv.org/abs/2309.06619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yufei Li, Zexin Li, Wei Yang, Cong Liu</li>
<li>for: 这个论文是为了研究语言模型（LM）在实时推理中的性能问题而写的。</li>
<li>methods: 这个论文使用了一种叫做RT-LM的uncertainty-aware资源管理系统来解决LM在实时推理中的性能问题。</li>
<li>results: 根据实验结果，RT-LM可以减少响应时间和提高吞吐量，但是runtime开销很小。<details>
<summary>Abstract</summary>
Recent advancements in language models (LMs) have gained substantial attentions on their capability to generate human-like responses. Though exhibiting a promising future for various applications such as conversation AI, these LMs face deployment challenges on various devices due to their extreme computational cost and unpredictable inference latency. Such varied inference latency, identified as a consequence of uncertainty intrinsic to the nature of language, can lead to computational inefficiency and degrade the overall performance of LMs, especially under high-traffic workloads. Unfortunately, the bandwidth of these uncertainty sources is extensive, complicating the prediction of latency and the effects emanating from such uncertainties. To understand and mitigate the impact of uncertainty on real-time response-demanding systems, we take the first step to comprehend, quantify and optimize these uncertainty-induced latency performance variations in LMs. Specifically, we present RT-LM, an uncertainty-aware resource management ecosystem for real-time inference of LMs. RT-LM innovatively quantifies how specific input uncertainties, adversely affect latency, often leading to an increased output length. Exploiting these insights, we devise a lightweight yet effective method to dynamically correlate input text uncertainties with output length at runtime. Utilizing this quantification as a latency heuristic, we integrate the uncertainty information into a system-level scheduler which explores several uncertainty-induced optimization opportunities, including uncertainty-aware prioritization, dynamic consolidation, and strategic CPU offloading. Quantitative experiments across five state-of-the-art LMs on two hardware platforms demonstrates that RT-LM can significantly reduce the average response time and improve throughput while incurring a rather small runtime overhead.
</details>
<details>
<summary>摘要</summary>
RT-LM aims to comprehend, quantify, and optimize the uncertainty-induced latency performance variations in LMs. We present a lightweight yet effective method to dynamically correlate input text uncertainties with output length at runtime. By exploiting these insights, we integrate the uncertainty information into a system-level scheduler, which explores several uncertainty-induced optimization opportunities, including uncertainty-aware prioritization, dynamic consolidation, and strategic CPU offloading.Experiments on five state-of-the-art LMs on two hardware platforms show that RT-LM can significantly reduce the average response time and improve throughput while incurring a small runtime overhead. Our approach can effectively mitigate the impact of uncertainty on real-time response-demanding systems, enabling the widespread adoption of LMs in various applications such as conversation AI.
</details></li>
</ul>
<hr>
<h2 id="Text-Encoders-Lack-Knowledge-Leveraging-Generative-LLMs-for-Domain-Specific-Semantic-Textual-Similarity"><a href="#Text-Encoders-Lack-Knowledge-Leveraging-Generative-LLMs-for-Domain-Specific-Semantic-Textual-Similarity" class="headerlink" title="Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity"></a>Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06541">http://arxiv.org/abs/2309.06541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph Gatto, Omar Sharif, Parker Seegmiller, Philip Bohlman, Sarah Masud Preum</li>
<li>for: 本研究旨在探讨语义文本相似性（STS）在不同任务上的评估，并发现STS在大量语言模型（LLM）评估中受到了忽略。</li>
<li>methods: 本研究表明，STS可以被视为文本生成问题，同时保持多个STS标准准的高性能。此外，我们还证明了使用生成语言模型（LLM）可以在具有复杂semantic关系的文本之间的semantic相似性评估中表现出色，并且在医学、政治和体育等领域中的新收集的STS挑战集上表现出色。</li>
<li>results: 我们的结果显示，使用生成语言模型（LLM）在具有世界知识的STS任务上的性能比使用编码器基于模型更高，在医学、政治和体育等领域的新收集的STS挑战集上，生成语言模型与STS特定的提示策略相结合可以 дости到状态之巅的性能。<details>
<summary>Abstract</summary>
Amidst the sharp rise in the evaluation of large language models (LLMs) on various tasks, we find that semantic textual similarity (STS) has been under-explored. In this study, we show that STS can be cast as a text generation problem while maintaining strong performance on multiple STS benchmarks. Additionally, we show generative LLMs significantly outperform existing encoder-based STS models when characterizing the semantic similarity between two texts with complex semantic relationships dependent on world knowledge. We validate this claim by evaluating both generative LLMs and existing encoder-based STS models on three newly collected STS challenge sets which require world knowledge in the domains of Health, Politics, and Sports. All newly collected data is sourced from social media content posted after May 2023 to ensure the performance of closed-source models like ChatGPT cannot be credited to memorization. Our results show that, on average, generative LLMs outperform the best encoder-only baselines by an average of 22.3% on STS tasks requiring world knowledge. Our results suggest generative language models with STS-specific prompting strategies achieve state-of-the-art performance in complex, domain-specific STS tasks.
</details>
<details>
<summary>摘要</summary>
在大语言模型（LLM）评估的快速上升中， semantic textual similarity（STS）却被忽视了。在这项研究中，我们发现STS可以被视为文本生成问题，同时保持多个STS benchmark task的优秀表现。此外，我们发现生成型LLM在描述两个文本之间的Semantic关系时，表现出色，特别是在具有世界知识的复杂Semantic关系上。我们 validate这一点通过对生成型LLM和现有encoder-based STS模型在健康、政治和运动等领域的三个新收集的STS挑战集上进行评估。所有新收集的数据都来自社交媒体上的内容，其中大部分是在2023年5月之后发布的，以避免Memorization的问题。我们的结果表明，在需要世界知识的STS任务中，生成型LLM平均表现出色，高于最佳encoder-only baseline的22.3%。我们的结果表明，使用STS特定的提示策略的生成语言模型在复杂的领域特定STS任务中实现了状态的表现。
</details></li>
</ul>
<hr>
<h2 id="Overview-of-Memotion-3-Sentiment-and-Emotion-Analysis-of-Codemixed-Hinglish-Memes"><a href="#Overview-of-Memotion-3-Sentiment-and-Emotion-Analysis-of-Codemixed-Hinglish-Memes" class="headerlink" title="Overview of Memotion 3: Sentiment and Emotion Analysis of Codemixed Hinglish Memes"></a>Overview of Memotion 3: Sentiment and Emotion Analysis of Codemixed Hinglish Memes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06517">http://arxiv.org/abs/2309.06517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shreyash Mishra, S Suryavardan, Megha Chakraborty, Parth Patwa, Anku Rani, Aman Chadha, Aishwarya Reganti, Amitava Das, Amit Sheth, Manoj Chinnakotla, Asif Ekbal, Srijan Kumar</li>
<li>for: 本研究的目的是对互联网上的投EGIN{CJK}{UTF8}{ermann}进行分析，以了解它们在线上讨论中的影响。</li>
<li>methods: 本研究使用了Memotion 3共同任务的独立标注数据集，包括情感（Task A）、情绪（Task B）和情绪强度（Task C）。参与者可以使用CLIP、BERT修改、ViT等模型，以及学生教师模型、融合和投票等方法。</li>
<li>results: 本研究发现了50多个参与者注册参与共同任务，5个参与者提交了测试集的最终Submission。最佳最终F1分数为Task A为34.41，Task B为79.77，Task C为59.82。<details>
<summary>Abstract</summary>
Analyzing memes on the internet has emerged as a crucial endeavor due to the impact this multi-modal form of content wields in shaping online discourse. Memes have become a powerful tool for expressing emotions and sentiments, possibly even spreading hate and misinformation, through humor and sarcasm. In this paper, we present the overview of the Memotion 3 shared task, as part of the DeFactify 2 workshop at AAAI-23. The task released an annotated dataset of Hindi-English code-mixed memes based on their Sentiment (Task A), Emotion (Task B), and Emotion intensity (Task C). Each of these is defined as an individual task and the participants are ranked separately for each task. Over 50 teams registered for the shared task and 5 made final submissions to the test set of the Memotion 3 dataset. CLIP, BERT modifications, ViT etc. were the most popular models among the participants along with approaches such as Student-Teacher model, Fusion, and Ensembling. The best final F1 score for Task A is 34.41, Task B is 79.77 and Task C is 59.82.
</details>
<details>
<summary>摘要</summary>
互联网上的迷因分析已经成为一项重要的专业，因为这种多Modal的内容可以影响网络上的讨论。迷因已经成为一个强大的表达情感和意见的工具，可能 même 传播仇恨和误information，通过幽默和讽刺。在这篇文章中，我们介绍了Memotion 3共同任务的概观，这是DeFactify 2会议上的一部分。这个任务发布了统计数据集的印地语-英语混合迷因，并分为三个任务：情感（任务A）、情感（任务B）和情感强度（任务C）。每个任务都是一个独立的任务，参赛者会被分别排名。这个任务获得了超过50队的注册，并有5队提交了测试集的最终Submission。参赛者主要使用CLIP、BERT修改和ViT等模型，以及学生教师模型、融合和投票等方法。最佳的最终F1分 для任务A是34.41，任务B是79.77，任务C是59.82。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-and-Weak-Supervision-for-Social-Media-data-annotation-an-evaluation-using-COVID-19-self-reported-vaccination-tweets"><a href="#Leveraging-Large-Language-Models-and-Weak-Supervision-for-Social-Media-data-annotation-an-evaluation-using-COVID-19-self-reported-vaccination-tweets" class="headerlink" title="Leveraging Large Language Models and Weak Supervision for Social Media data annotation: an evaluation using COVID-19 self-reported vaccination tweets"></a>Leveraging Large Language Models and Weak Supervision for Social Media data annotation: an evaluation using COVID-19 self-reported vaccination tweets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06503">http://arxiv.org/abs/2309.06503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ramya Tekumalla, Juan M. Banda</li>
<li>for: 本研究目的是为了评估大语言模型GPT-4（2023年3月23日版本）和弱监督来自Twitter上的COVID-19疫苗相关 tweet 自动标注表现，并与人类标注者进行比较。</li>
<li>methods: 本研究使用了GPT-4（2023年3月23日版本）提供标签，无需进一步 fine-tuning 或指导，使用单射模式（无需额外提示）。</li>
<li>results: 研究发现，GPT-4（2023年3月23日版本）在自动标注COVID-19疫苗相关 tweet 方面的表现与人类标注者相当，且可以快速、高效地进行自动标注。<details>
<summary>Abstract</summary>
The COVID-19 pandemic has presented significant challenges to the healthcare industry and society as a whole. With the rapid development of COVID-19 vaccines, social media platforms have become a popular medium for discussions on vaccine-related topics. Identifying vaccine-related tweets and analyzing them can provide valuable insights for public health research-ers and policymakers. However, manual annotation of a large number of tweets is time-consuming and expensive. In this study, we evaluate the usage of Large Language Models, in this case GPT-4 (March 23 version), and weak supervision, to identify COVID-19 vaccine-related tweets, with the purpose of comparing performance against human annotators. We leveraged a manu-ally curated gold-standard dataset and used GPT-4 to provide labels without any additional fine-tuning or instructing, in a single-shot mode (no additional prompting).
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行带来了医疗业和社会全面的挑战。随着 COVID-19 疫苗的快速发展，社交媒体平台上有大量有关疫苗的讨论。可以通过分析这些微博来获得有价值的公共卫生研究人员和政策制定者的洞察。但是，手动标注大量微博是时间consuming 和昂贵的。在本研究中，我们评估了大型自然语言模型（GPT-4，2023年3月23日版）和弱级指导，用于标识 COVID-19 疫苗相关的微博，并与人工标注器进行比较。我们利用了手动精心挑选的金标准数据集，并使用 GPT-4 提供标签，无需任何额外的调整或指导，在单射模式下（没有额外的提示）。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-for-Automated-Dialogue-Analysis"><a href="#Leveraging-Large-Language-Models-for-Automated-Dialogue-Analysis" class="headerlink" title="Leveraging Large Language Models for Automated Dialogue Analysis"></a>Leveraging Large Language Models for Automated Dialogue Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06490">http://arxiv.org/abs/2309.06490</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/emorynlp/gpt-abceval">https://github.com/emorynlp/gpt-abceval</a></li>
<li>paper_authors: Sarah E. Finch, Ellie S. Paek, Jinho D. Choi</li>
<li>For: The paper aims to assess the ability of a state-of-the-art large language model (LLM) to detect nine categories of undesirable behaviors in real human-bot dialogues.* Methods: The paper uses a state-of-the-art LLM, ChatGPT-3.5, to perform dialogue behavior detection and compares its performance with specialized detection models.* Results: The paper finds that neither ChatGPT nor specialized models have yet achieved satisfactory results for this task, falling short of human performance. However, ChatGPT shows promising potential and often outperforms specialized detection models.Here are the three points in Simplified Chinese text:* For: 本研究用于评估一个状态rut-of-the-art的大语言模型（LLM）在真实人机对话中自动识别九种不良行为的能力。* Methods: 本研究使用状态rut-of-the-art的LLM，ChatGPT-3.5，进行对话行为检测，并与专门的检测模型进行比较。* Results: 本研究发现 neither ChatGPT nor specialized models have yet achieved satisfactory results for this task, falling short of human performance. However, ChatGPT shows promising potential and often outperforms specialized detection models.<details>
<summary>Abstract</summary>
Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses. However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities.
</details>
<details>
<summary>摘要</summary>
发展高性能对话系统受益于自动识别对话系统回应中不良行为的能力。然而，检测这些行为仍然是一项挑战，因为它需要对对话实践的广泛知识和理解。虽然最近的研究主要集中在建立特殊的对话行为分类器，但行为覆盖率仍然不完整，并且缺乏实际人机交互的测试。本文研究了一个现代大语言模型（LLM）ChatGPT-3.5在真实人机对话中的对话行为检测能力。我们希望评估ChatGPT是否能够与专门的模型相匹配，并且 approximates human performance，以降低行为检测任务的成本。我们发现 neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance。然而，ChatGPT表现了良好的潜力，并且经常超过专门的检测模型。我们结束于对ChatGPT缺陷的深入分析，并提供未来研究进一步增强LLM能力的指导。
</details></li>
</ul>
<hr>
<h2 id="Widely-Interpretable-Semantic-Representation-Frameless-Meaning-Representation-for-Broader-Applicability"><a href="#Widely-Interpretable-Semantic-Representation-Frameless-Meaning-Representation-for-Broader-Applicability" class="headerlink" title="Widely Interpretable Semantic Representation: Frameless Meaning Representation for Broader Applicability"></a>Widely Interpretable Semantic Representation: Frameless Meaning Representation for Broader Applicability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06460">http://arxiv.org/abs/2309.06460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lydia Feng, Gregor Williamson, Han He, Jinho D. Choi</li>
<li>for: This paper presents a novel semantic representation, WISeR, to overcome challenges in Abstract Meaning Representation (AMR).</li>
<li>methods: The paper examines the numbered arguments of predicates in AMR and converts them to thematic roles, improving the inter-annotator agreement for beginner and experienced annotators.</li>
<li>results: The WISeR model exhibits higher accuracy than its AMR counterpart across the board, demonstrating that WISeR is easier for parsers to learn.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文提出了一种新的Semantic Representation，WISeR，以解决Abstract Meaning Representation（AMR）中的挑战。</li>
<li>methods: 论文分析了AMR中 predicate的数字化Arguments，并将其转换为不需要参考semantic frames的主题角色，从而提高了 beginner和经验 annotator之间的协议一致性。</li>
<li>results: WISeR模型在所有板块中表现出了高度的准确性，证明WISeR更易 für parser 学习。<details>
<summary>Abstract</summary>
This paper presents a novel semantic representation, WISeR, that overcomes challenges for Abstract Meaning Representation (AMR). Despite its strengths, AMR is not easily applied to languages or domains without predefined semantic frames, and its use of numbered arguments results in semantic role labels, which are not directly interpretable and are semantically overloaded for parsers. We examine the numbered arguments of predicates in AMR and convert them to thematic roles that do not require reference to semantic frames. We create a new corpus of 1K English dialogue sentences annotated in both WISeR and AMR. WISeR shows stronger inter-annotator agreement for beginner and experienced annotators, with beginners becoming proficient in WISeR annotation more quickly. Finally, we train a state-of-the-art parser on the AMR 3.0 corpus and a WISeR corpus converted from AMR 3.0. The parser is evaluated on these corpora and our dialogue corpus. The WISeR model exhibits higher accuracy than its AMR counterpart across the board, demonstrating that WISeR is easier for parsers to learn.
</details>
<details>
<summary>摘要</summary>
We create a new corpus of 1,000 English dialogue sentences annotated in both WISeR and AMR. Our results show that WISeR has stronger inter-annotator agreement for both beginner and experienced annotators, with beginners becoming proficient in WISeR annotation more quickly. Additionally, we train a state-of-the-art parser on the AMR 3.0 corpus and a WISeR corpus converted from AMR 3.0. The parser is evaluated on these corpora and our dialogue corpus, and the WISeR model exhibits higher accuracy than its AMR counterpart across the board, demonstrating that WISeR is easier for parsers to learn.
</details></li>
</ul>
<hr>
<h2 id="Recovering-from-Privacy-Preserving-Masking-with-Large-Language-Models"><a href="#Recovering-from-Privacy-Preserving-Masking-with-Large-Language-Models" class="headerlink" title="Recovering from Privacy-Preserving Masking with Large Language Models"></a>Recovering from Privacy-Preserving Masking with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08628">http://arxiv.org/abs/2309.08628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arpita Vats, Zhe Liu, Peng Su, Debjyoti Paul, Yingyi Ma, Yutong Pang, Zeeshan Ahmed, Ozlem Kalinli</li>
<li>for: 本研究旨在提高模型适应性，以便处理代理训练数据和实际用户数据之间的差异。</li>
<li>methods: 本研究使用大语言模型（LLM）来提出匿名标识符替换的方法，并对其效果进行了Empirical研究。特别是，我们提出了多种预训练和精度调整的LLM基本方法，并对各种数据集进行了比较性研究。</li>
<li>results: 实验结果表明，使用匿名标识符替换后，模型在下游自然语言处理任务中能够保持与原始数据无隐私保护的同等性能。<details>
<summary>Abstract</summary>
Model adaptation is crucial to handle the discrepancy between proxy training data and actual users data received. To effectively perform adaptation, textual data of users is typically stored on servers or their local devices, where downstream natural language processing (NLP) models can be directly trained using such in-domain data. However, this might raise privacy and security concerns due to the extra risks of exposing user information to adversaries. Replacing identifying information in textual data with a generic marker has been recently explored. In this work, we leverage large language models (LLMs) to suggest substitutes of masked tokens and have their effectiveness evaluated on downstream language modeling tasks. Specifically, we propose multiple pre-trained and fine-tuned LLM-based approaches and perform empirical studies on various datasets for the comparison of these methods. Experimental results show that models trained on the obfuscation corpora are able to achieve comparable performance with the ones trained on the original data without privacy-preserving token masking.
</details>
<details>
<summary>摘要</summary>
模型适应是处理代理训练数据和实际用户数据接收的差异的关键。为了有效地进行适应，用户的文本数据通常会被存储在服务器或本地设备上，以便下游自然语言处理（NLP）模型可以直接使用这些领域数据进行训练。然而，这可能会带来隐私和安全问题，因为披露用户信息会增加对敌人的风险。将用户信息从文本数据中替换为通用标识符已经被研究。在这种工作中，我们利用大语言模型（LLM）来建议替换的Marker Token，并对这些方法的效果进行了实验研究。specifically，我们提出了多种预训练和精度调整的LLM基于方法，并在不同的数据集上进行了实验比较这些方法的效果。实验结果表明，使用隐藏 corpora 进行训练的模型能够达到与没有隐藏 token 训练的模型相同的性能。
</details></li>
</ul>
<hr>
<h2 id="Cited-Text-Spans-for-Citation-Text-Generation"><a href="#Cited-Text-Spans-for-Citation-Text-Generation" class="headerlink" title="Cited Text Spans for Citation Text Generation"></a>Cited Text Spans for Citation Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06365">http://arxiv.org/abs/2309.06365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangci Li, Yi-Hui Lee, Jessica Ouyang</li>
<li>for: 这个论文主要是为了解决科学论文中自动生成相关工作的问题。</li>
<li>methods: 该论文使用了一种新的方法，即基于文献标注（CTS）的方法，而不是基于摘要的方法。</li>
<li>results: 该论文表明，使用CTS可以提高自动生成相关工作的准确性，并且可以避免非事实的幻想。<details>
<summary>Abstract</summary>
Automatic related work generation must ground their outputs to the content of the cited papers to avoid non-factual hallucinations, but due to the length of scientific documents, existing abstractive approaches have conditioned only on the cited paper \textit{abstracts}. We demonstrate that the abstract is not always the most appropriate input for citation generation and that models trained in this way learn to hallucinate. We propose to condition instead on the \textit{cited text span} (CTS) as an alternative to the abstract. Because manual CTS annotation is extremely time- and labor-intensive, we experiment with automatic, ROUGE-based labeling of candidate CTS sentences, achieving sufficiently strong performance to substitute for expensive human annotations, and we propose a human-in-the-loop, keyword-based CTS retrieval approach that makes generating citation texts grounded in the full text of cited papers both promising and practical.
</details>
<details>
<summary>摘要</summary>
自动生成相关工作必须将输出锚定到引用文献中的内容，以避免非实际的幻觉。但由于科学文献的长度，现有的抽象方法只做到了基于引用文献摘要进行conditioning。我们示示了摘要并不总是最适合的引用生成输入，并且模型在这种情况下会学习幻觉。我们提议在代之之前使用引用文献中的特定文本段（CTS）作为输入，因为手动标注CTS是非常时间和劳动密集的。我们对候选CTS句子使用ROUGE基于的自动标注方法进行实验，得到了充分的表现，以至于可以代替昂贵的人工标注。此外，我们也提出了人在循环的键盘基于CTS检索方法，使得生成引用文本与引用文献的全文相关。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Predict-Concept-Ordering-for-Common-Sense-Generation"><a href="#Learning-to-Predict-Concept-Ordering-for-Common-Sense-Generation" class="headerlink" title="Learning to Predict Concept Ordering for Common Sense Generation"></a>Learning to Predict Concept Ordering for Common Sense Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06363">http://arxiv.org/abs/2309.06363</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tianhuizhang/concept_ordering">https://github.com/tianhuizhang/concept_ordering</a></li>
<li>paper_authors: Tianhui Zhang, Danushka Bollegala, Bei Peng</li>
<li>for: 本研究旨在理解输入概念的顺序对 sentence生成质量的影响，并 explore 多种语言模型（LM）和概念顺序策略的关系。</li>
<li>methods: 本研究使用了多种LM和概念顺序策略，包括CommonGen训练数据中的概念顺序，并对 sentence生成质量进行评估。</li>
<li>results: 研究发现，BART-large模型在CommonGen训练数据中的概念顺序下 consistently 表现最佳，并且比较小的LM可以在这个任务上表现更好于大型GPT3-based LLMs。此外，人工标注的输入概念集顺序可以独立地提供最佳的 sentence 生成结果，并且超过了基于概念顺序的随机化策略。<details>
<summary>Abstract</summary>
Prior work has shown that the ordering in which concepts are shown to a commonsense generator plays an important role, affecting the quality of the generated sentence. However, it remains a challenge to determine the optimal ordering of a given set of concepts such that a natural sentence covering all the concepts could be generated from a pretrained generator. To understand the relationship between the ordering of the input concepts and the quality of the generated sentences, we conduct a systematic study considering multiple language models (LMs) and concept ordering strategies. We find that BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data as measured using multiple evaluation metrics. Moreover, the larger GPT3-based large language models (LLMs) variants do not necessarily outperform much smaller LMs on this task, even when fine-tuned on task-specific training data. Interestingly, human annotators significantly reorder input concept sets when manually writing sentences covering those concepts, and this ordering provides the best sentence generations independently of the LM used for the generation, outperforming a probabilistic concept ordering baseline
</details>
<details>
<summary>摘要</summary>
We found that the BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data, as measured by multiple evaluation metrics. Additionally, we found that the larger GPT3-based large language models (LLMs) variants do not necessarily outperform smaller LMs on this task, even when fine-tuned on task-specific training data.Interestingly, human annotators significantly reorder input concept sets when manually writing sentences covering those concepts, and this ordering provides the best sentence generations independently of the LM used for generation, outperforming a probabilistic concept ordering baseline.
</details></li>
</ul>
<hr>
<h2 id="Re-Reading-Improves-Reasoning-in-Language-Models"><a href="#Re-Reading-Improves-Reasoning-in-Language-Models" class="headerlink" title="Re-Reading Improves Reasoning in Language Models"></a>Re-Reading Improves Reasoning in Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06275">http://arxiv.org/abs/2309.06275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohan Xu, Chongyang Tao, Tao Shen, Can Xu, Hongbo Xu, Guodong Long, Jian-guang Lou</li>
<li>for: 提高 Large Language Models (LLMs) 的推理能力</li>
<li>methods: 引入 “question re-reading” 提示策略，通过重读输入提问中嵌入的问题信息来增强 LLMs 的推理能力</li>
<li>results: 实验结果表明，该方法可以提高 LLMs 的推理能力，并且可以轻松地与其他语言模型、提示方法和集成技术结合使用<details>
<summary>Abstract</summary>
Reasoning presents a significant and challenging issue for Large Language Models (LLMs). The predominant focus of research has revolved around developing diverse prompting strategies to guide and structure the reasoning processes of LLMs. However, these approaches based on decoder-only causal language models often operate the input question in a single forward pass, potentially missing the rich, back-and-forth interactions inherent in human reasoning. Scant attention has been paid to a critical dimension, i.e., the input question itself embedded within the prompts. In response, we introduce a deceptively simple yet highly effective prompting strategy, termed question "re-reading". Drawing inspiration from human learning and problem-solving, re-reading entails revisiting the question information embedded within input prompts. This approach aligns seamlessly with the cognitive principle of reinforcement, enabling LLMs to extract deeper insights, identify intricate patterns, establish more nuanced connections, and ultimately enhance their reasoning capabilities across various tasks. Experiments conducted on a series of reasoning benchmarks serve to underscore the effectiveness and generality of our method. Moreover, our findings demonstrate that our approach seamlessly integrates with various language models, though-eliciting prompting methods, and ensemble techniques, further underscoring its versatility and compatibility in the realm of LLMs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-first-step-is-the-hardest-Pitfalls-of-Representing-and-Tokenizing-Temporal-Data-for-Large-Language-Models"><a href="#The-first-step-is-the-hardest-Pitfalls-of-Representing-and-Tokenizing-Temporal-Data-for-Large-Language-Models" class="headerlink" title="The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models"></a>The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06236">http://arxiv.org/abs/2309.06236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitris Spathis, Fahim Kawsar</li>
<li>for: 这篇论文旨在探讨语言模型在人类中心任务中的应用，如移动健康感知等。</li>
<li>methods: 这篇论文使用了一些最新的研究，探讨了 популяр的语言模型在处理时间序数据时的问题，以及一些可能的解决方案，如提示调整和多模态适配器。</li>
<li>results: 这篇论文表明，许多语言模型在处理时间序数据时会错误地分词，并且提出了一些可能的解决方案，如使用轻量级嵌入层和多模态适配器。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines. Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records. LLMs employ tokenizers in their input that break down text into smaller units. However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships. Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly. To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that can help bridge this "modality gap". While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper underscores the fact that their outputs cannot be meaningful if they stumble over input nuances.
</details>
<details>
<summary>摘要</summary>
In this paper, we discuss recent works that use LLMs for human-centric tasks such as mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly. To address this issue, we highlight potential solutions such as prompt tuning with lightweight embedding layers and multimodal adapters, which can help bridge the "modality gap". While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper emphasizes that their outputs cannot be meaningful if they stumble over input nuances.
</details></li>
</ul>
<hr>
<h2 id="Human-Action-Co-occurrence-in-Lifestyle-Vlogs-using-Graph-Link-Prediction"><a href="#Human-Action-Co-occurrence-in-Lifestyle-Vlogs-using-Graph-Link-Prediction" class="headerlink" title="Human Action Co-occurrence in Lifestyle Vlogs using Graph Link Prediction"></a>Human Action Co-occurrence in Lifestyle Vlogs using Graph Link Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06219">http://arxiv.org/abs/2309.06219</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oana Ignat, Santiago Castro, Weiji Li, Rada Mihalcea</li>
<li>for: 本研究旨在自动刺探人体行为协同出现情况，即判断两个人体动作是否可以同时出现在同一段时间内。</li>
<li>methods: 该研究使用了视觉和文本信息来自动推断两个人体动作是否协同出现。</li>
<li>results: 研究发现图表非常适合捕捉人体动作之间的关系，并且学习的图表表示法对该任务具有高效性和可靠性。同时，该研究还发现了一些新和相关的信息，这些信息可以在不同的数据领域中找到应用。<details>
<summary>Abstract</summary>
We introduce the task of automatic human action co-occurrence identification, i.e., determine whether two human actions can co-occur in the same interval of time. We create and make publicly available the ACE (Action Co-occurrencE) dataset, consisting of a large graph of ~12k co-occurring pairs of visual actions and their corresponding video clips. We describe graph link prediction models that leverage visual and textual information to automatically infer if two actions are co-occurring. We show that graphs are particularly well suited to capture relations between human actions, and the learned graph representations are effective for our task and capture novel and relevant information across different data domains. The ACE dataset and the code introduced in this paper are publicly available at https://github.com/MichiganNLP/vlog_action_co-occurrence.
</details>
<details>
<summary>摘要</summary>
我们介绍了自动人体动作协同识别任务，即判断两个人体动作是否可以在同一个时间间协同出现。我们创建了ACE（动作协同）数据集，包含约12k个相互协同的视觉动作对和其相应的视频片段。我们描述了基于视觉和文本信息的图链预测模型，可以自动推断两个动作是否协同出现。我们发现图是特别适合捕捉人体动作之间的关系，并且学习的图表示是我们任务中效果很高，并且在不同的数据领域中捕捉到了新和有关的信息。ACE数据集和我们在本篇文章中介绍的代码都公开可用于https://github.com/MichiganNLP/vlog_action_co-occurrence。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Dynamic-Topic-Models"><a href="#Evaluating-Dynamic-Topic-Models" class="headerlink" title="Evaluating Dynamic Topic Models"></a>Evaluating Dynamic Topic Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08627">http://arxiv.org/abs/2309.08627</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Charu James, Mayank Nagda, Nooshin Haji Ghassemi, Marius Kloft, Sophie Fellenz</li>
<li>for: 评估动态话题模型（DTM）中话题的进程和质量。</li>
<li>methods: 提出了一种基于话题质量和时间一致性的评估方法，并在实验中应用于合成数据和现有DTM中。</li>
<li>results: 通过人工评估和数据分析，发现该评估方法与人类判断有高度相关性，可以用于评估不同DTM的性能和指导未来研究。<details>
<summary>Abstract</summary>
There is a lack of quantitative measures to evaluate the progression of topics through time in dynamic topic models (DTMs). Filling this gap, we propose a novel evaluation measure for DTMs that analyzes the changes in the quality of each topic over time. Additionally, we propose an extension combining topic quality with the model's temporal consistency. We demonstrate the utility of the proposed measure by applying it to synthetic data and data from existing DTMs. We also conducted a human evaluation, which indicates that the proposed measure correlates well with human judgment. Our findings may help in identifying changing topics, evaluating different DTMs, and guiding future research in this area.
</details>
<details>
<summary>摘要</summary>
DTMs 缺乏时间序量化评价标准，为此，我们提出了一种新的评价标准，用于评估 DTMs 中话题的时间发展质量。此外，我们还提出了结合话题质量和模型时间一致性的扩展。我们在synthetic data和现有 DTMs 数据上应用了该标准，并进行了人类评价，结果显示了与人类判断的高度相关性。我们的发现可能有助于 indentifying changing topics, evaluating different DTMs, and guiding future research in this area.Note: "DTMs" stands for "dynamic topic models".
</details></li>
</ul>
<hr>
<h2 id="Improving-and-Evaluating-the-Detection-of-Fragmentation-in-News-Recommendations-with-the-Clustering-of-News-Story-Chains"><a href="#Improving-and-Evaluating-the-Detection-of-Fragmentation-in-News-Recommendations-with-the-Clustering-of-News-Story-Chains" class="headerlink" title="Improving and Evaluating the Detection of Fragmentation in News Recommendations with the Clustering of News Story Chains"></a>Improving and Evaluating the Detection of Fragmentation in News Recommendations with the Clustering of News Story Chains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06192">http://arxiv.org/abs/2309.06192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandra Polimeno, Myrthe Reuver, Sanne Vrijenhoek, Antske Fokkens</li>
<li>for: This paper aims to provide an extensive investigation of various approaches for quantifying Fragmentation in news recommendations, with the goal of improving the accuracy of measuring the degree of fragmentation of information streams in news recommendations.</li>
<li>methods: The paper uses Natural Language Processing (NLP) techniques, specifically agglomerative hierarchical clustering coupled with SentenceBERT text representation, to identify distinct news events, stories, or timelines and measure Fragmentation.</li>
<li>results: The paper finds that the proposed approach of agglomerative hierarchical clustering coupled with SentenceBERT text representation is substantially better at detecting Fragmentation than earlier implementations, and provides valuable insights and recommendations for stakeholders concerning the measurement and interpretation of Fragmentation.<details>
<summary>Abstract</summary>
News recommender systems play an increasingly influential role in shaping information access within democratic societies. However, tailoring recommendations to users' specific interests can result in the divergence of information streams. Fragmented access to information poses challenges to the integrity of the public sphere, thereby influencing democracy and public discourse. The Fragmentation metric quantifies the degree of fragmentation of information streams in news recommendations. Accurate measurement of this metric requires the application of Natural Language Processing (NLP) to identify distinct news events, stories, or timelines. This paper presents an extensive investigation of various approaches for quantifying Fragmentation in news recommendations. These approaches are evaluated both intrinsically, by measuring performance on news story clustering, and extrinsically, by assessing the Fragmentation scores of different simulated news recommender scenarios. Our findings demonstrate that agglomerative hierarchical clustering coupled with SentenceBERT text representation is substantially better at detecting Fragmentation than earlier implementations. Additionally, the analysis of simulated scenarios yields valuable insights and recommendations for stakeholders concerning the measurement and interpretation of Fragmentation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AKEM-Aligning-Knowledge-Base-to-Queries-with-Ensemble-Model-for-Entity-Recognition-and-Linking"><a href="#AKEM-Aligning-Knowledge-Base-to-Queries-with-Ensemble-Model-for-Entity-Recognition-and-Linking" class="headerlink" title="AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity Recognition and Linking"></a>AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity Recognition and Linking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06175">http://arxiv.org/abs/2309.06175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Lu, Zhongping Liang, Caixia Yuan, Xiaojie Wang</li>
<li>for: 这篇论文是为了解决 NLPCC 2015 年Entity Recognition and Linking Challenge 的问题而写的。</li>
<li>methods: 该方法首先扩展现有的知识库，并利用外部知识来确定候选实体，从而提高准确率。然后，从候选实体中提取特征，并使用支持向量回归和多项添加回归树作为分数函数来筛选结果。最后，通过规则进一步精细化结果以提高精度。</li>
<li>results: 该方法可以高效地处理数据，并实现了 F1 分数为 0.535。<details>
<summary>Abstract</summary>
This paper presents a novel approach to address the Entity Recognition and Linking Challenge at NLPCC 2015. The task involves extracting named entity mentions from short search queries and linking them to entities within a reference Chinese knowledge base. To tackle this problem, we first expand the existing knowledge base and utilize external knowledge to identify candidate entities, thereby improving the recall rate. Next, we extract features from the candidate entities and utilize Support Vector Regression and Multiple Additive Regression Tree as scoring functions to filter the results. Additionally, we apply rules to further refine the results and enhance precision. Our method is computationally efficient and achieves an F1 score of 0.535.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的方法来解决2015年NLPCC会议上的实体识别和连接挑战。任务是从短搜索查询中提取命名实体提及，并将其与中国知识库中的实体进行连接。为解决这个问题，我们首先扩展了现有的知识库，并利用外部知识来确定候选实体，从而提高了受检测率。接着，我们从候选实体中提取特征，并使用支持向量回归和多项加itive树分类函数来筛选结果。此外，我们还应用规则来进一步精细化结果，提高精度。我们的方法具有计算效率，并实现了F1分数0.535。
</details></li>
</ul>
<hr>
<h2 id="Overview-of-GUA-SPA-at-IberLEF-2023-Guarani-Spanish-Code-Switching-Analysis"><a href="#Overview-of-GUA-SPA-at-IberLEF-2023-Guarani-Spanish-Code-Switching-Analysis" class="headerlink" title="Overview of GUA-SPA at IberLEF 2023: Guarani-Spanish Code Switching Analysis"></a>Overview of GUA-SPA at IberLEF 2023: Guarani-Spanish Code Switching Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06163">http://arxiv.org/abs/2309.06163</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luis Chiruzzo, Marvin Agüero-Torales, Gustavo Giménez-Lugo, Aldo Alvarez, Yliana Rodríguez, Santiago Góngora, Thamar Solorio</li>
<li>for: 本研究目的是探讨和分析语言混合在古拉那语和西班牙语之间的现象。</li>
<li>methods: 本研究使用了三个任务来识别和分析语言混合：一是语言标识任务，二是命名实体识别任务，三是一种新的任务是在混合语言上分类西班牙语句子的使用方式。</li>
<li>results: 三个队伍在评估阶段参与了评估，在总体来说取得了良好的结果 для任务1，但是对于任务2和3的结果则有所不同。<details>
<summary>Abstract</summary>
We present the first shared task for detecting and analyzing code-switching in Guarani and Spanish, GUA-SPA at IberLEF 2023. The challenge consisted of three tasks: identifying the language of a token, NER, and a novel task of classifying the way a Spanish span is used in the code-switched context. We annotated a corpus of 1500 texts extracted from news articles and tweets, around 25 thousand tokens, with the information for the tasks. Three teams took part in the evaluation phase, obtaining in general good results for Task 1, and more mixed results for Tasks 2 and 3.
</details>
<details>
<summary>摘要</summary>
我们现在介绍GUA-SPA的首次共同任务，即检测和分析库亚语和西班牙语的代码 switching。这个挑战包括三个任务：确定一个令素的语言，名实 recognize，以及一个新的任务，即在代码 switching 上下文中分类西班牙语句子的使用方式。我们为这个任务annotated一个新闻文章和微博中的1500篇文本，约25000个令素，以便提供任务的信息。三支队伍参与了评估阶段，在总体来说取得了良好的成绩， Task 1 的结果，而 Tasks 2 和 3 的结果则更为杂mix。
</details></li>
</ul>
<hr>
<h2 id="Prompting4Debugging-Red-Teaming-Text-to-Image-Diffusion-Models-by-Finding-Problematic-Prompts"><a href="#Prompting4Debugging-Red-Teaming-Text-to-Image-Diffusion-Models-by-Finding-Problematic-Prompts" class="headerlink" title="Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts"></a>Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06135">http://arxiv.org/abs/2309.06135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhi-Yi Chin, Chieh-Ming Jiang, Ching-Chun Huang, Pin-Yu Chen, Wei-Chen Chiu</li>
<li>for: 这个论文的目的是检测和探测文本到图像扩散模型中的安全问题，以确保这些模型不会生成不安全或版权问题的图像。</li>
<li>methods: 这篇论文使用了一种名为Prompting4Debugging（P4D）的调试和红团技术，以检测和探测文本扩散模型中的安全机制的可靠性。</li>
<li>results: 该研究发现，大约半数的原本被视为安全的提示 benchmarks 可以通过 manipulate 提示来绕过已经部署的安全机制，包括概念 removals、负提示和安全指导。这些发现表明，不进行全面测试，就可能得出假的安全感，文本到图像模型可能会生成不安全或版权问题的图像。<details>
<summary>Abstract</summary>
Text-to-image diffusion models, e.g. Stable Diffusion (SD), lately have shown remarkable ability in high-quality content generation, and become one of the representatives for the recent wave of transformative AI. Nevertheless, such advance comes with an intensifying concern about the misuse of this generative technology, especially for producing copyrighted or NSFW (i.e. not safe for work) images. Although efforts have been made to filter inappropriate images/prompts or remove undesirable concepts/styles via model fine-tuning, the reliability of these safety mechanisms against diversified problematic prompts remains largely unexplored. In this work, we propose Prompting4Debugging (P4D) as a debugging and red-teaming tool that automatically finds problematic prompts for diffusion models to test the reliability of a deployed safety mechanism. We demonstrate the efficacy of our P4D tool in uncovering new vulnerabilities of SD models with safety mechanisms. Particularly, our result shows that around half of prompts in existing safe prompting benchmarks which were originally considered "safe" can actually be manipulated to bypass many deployed safety mechanisms, including concept removal, negative prompt, and safety guidance. Our findings suggest that, without comprehensive testing, the evaluations on limited safe prompting benchmarks can lead to a false sense of safety for text-to-image models.
</details>
<details>
<summary>摘要</summary>
文本到图像扩散模型，如稳定扩散（SD），最近显示了高质量内容生成的惊人能力，成为最近一波转化AI的代表之一。然而，这种进步也带来了对这种生成技术的滥用的担忧，特别是生成版权或不安全的图像（i.e.不适合工作）。虽然努力在滥用图像/提示或移除不适合的概念/风格方面进行模型细化，但这些安全机制的可靠性在多样化问题上仍然未得到探索。在这项工作中，我们提出了Prompting4Debugging（P4D）作为调试和红团工具，自动找到 diffusion 模型的异常提示，以测试已经部署的安全机制的可靠性。我们示出了P4D工具在SD模型上的有效性，并显示了大约半数的提示在现有的安全提示benchmark中被原本认为是安全的，但实际上可以通过许多已部署的安全机制进行滥用。我们的发现表明，不完全测试可能会导致对文本到图像模型的评估产生假象的安全性。
</details></li>
</ul>
<hr>
<h2 id="Annotating-Data-for-Fine-Tuning-a-Neural-Ranker-Current-Active-Learning-Strategies-are-not-Better-than-Random-Selection"><a href="#Annotating-Data-for-Fine-Tuning-a-Neural-Ranker-Current-Active-Learning-Strategies-are-not-Better-than-Random-Selection" class="headerlink" title="Annotating Data for Fine-Tuning a Neural Ranker? Current Active Learning Strategies are not Better than Random Selection"></a>Annotating Data for Fine-Tuning a Neural Ranker? Current Active Learning Strategies are not Better than Random Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06131">http://arxiv.org/abs/2309.06131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sophia Althammer, Guido Zuccon, Sebastian Hofstätter, Suzan Verberne, Allan Hanbury</li>
<li>for: 这篇论文的目的是研究基于预训语言模型（PLM）的搜寻方法在受限的训练数据和预算下的表现。</li>
<li>methods: 这篇论文使用的方法是将PLM-based rankers精致化，并考虑了两个情况：从scratch开始精致化，以及从已经精致化的缩减到一个特定数据集的情况。</li>
<li>results: 研究发现，在不同的随机选择的训练数据 subsets 中精致化 PLM rankers 会具有很大的差异，这表明可以通过活动选择训练数据 subsets 来实现更高的效率。然而，这篇论文发现，现有的活动学习（AL）策略在PLM rankers的精致化中不能够实现更高的效率，并且与随机选择相比，AL策略需要更多的评估成本。<details>
<summary>Abstract</summary>
Search methods based on Pretrained Language Models (PLM) have demonstrated great effectiveness gains compared to statistical and early neural ranking models. However, fine-tuning PLM-based rankers requires a great amount of annotated training data. Annotating data involves a large manual effort and thus is expensive, especially in domain specific tasks. In this paper we investigate fine-tuning PLM-based rankers under limited training data and budget. We investigate two scenarios: fine-tuning a ranker from scratch, and domain adaptation starting with a ranker already fine-tuned on general data, and continuing fine-tuning on a target dataset. We observe a great variability in effectiveness when fine-tuning on different randomly selected subsets of training data. This suggests that it is possible to achieve effectiveness gains by actively selecting a subset of the training data that has the most positive effect on the rankers. This way, it would be possible to fine-tune effective PLM rankers at a reduced annotation budget. To investigate this, we adapt existing Active Learning (AL) strategies to the task of fine-tuning PLM rankers and investigate their effectiveness, also considering annotation and computational costs. Our extensive analysis shows that AL strategies do not significantly outperform random selection of training subsets in terms of effectiveness. We further find that gains provided by AL strategies come at the expense of more assessments (thus higher annotation costs) and AL strategies underperform random selection when comparing effectiveness given a fixed annotation cost. Our results highlight that ``optimal'' subsets of training data that provide high effectiveness at low annotation cost do exist, but current mainstream AL strategies applied to PLM rankers are not capable of identifying them.
</details>
<details>
<summary>摘要</summary>
基于预训言语模型（PLM）的搜索方法在效果上有显著提升，但是精细调整PLM-based ranker需要大量标注数据。标注数据需要大量人工劳动，因此成本高，特别是在域pecific任务中。在这篇论文中，我们研究了在有限的培训数据和预算下进行PLM-based ranker的精细调整。我们研究了两个情况：从scratch开始精细调整rankers，以及在泛化数据上精细调整rankers，然后在目标数据上继续精细调整。我们发现在不同随机选择的培训数据上进行精细调整时，效果很大。这表示可以通过活动选择培训数据来提高PLM rankers的效果，而不需要大量的标注预算。为了 investigates这一点，我们采用了现有的活动学习（AL）策略，并对其效果进行了广泛的分析。我们发现，与随机选择的培训数据相比，AL策略不能显著提高效果。此外，AL策略相比随机选择，需要更多的评估（即更高的标注成本），并且在给定标注成本下，AL策略下表现较差。我们的结果表明，“优化”的培训数据集，可以提高PLM rankers的效果，但现有的主流AL策略无法确定这些集。
</details></li>
</ul>
<hr>
<h2 id="AstroLLaMA-Towards-Specialized-Foundation-Models-in-Astronomy"><a href="#AstroLLaMA-Towards-Specialized-Foundation-Models-in-Astronomy" class="headerlink" title="AstroLLaMA: Towards Specialized Foundation Models in Astronomy"></a>AstroLLaMA: Towards Specialized Foundation Models in Astronomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06126">http://arxiv.org/abs/2309.06126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuan Dung Nguyen, Yuan-Sen Ting, Ioana Ciucă, Charlie O’Neill, Ze-Chang Sun, Maja Jabłońska, Sandor Kruk, Ernest Perkowski, Jack Miller, Jason Li, Josh Peek, Kartheik Iyer, Tomasz Różański, Pranav Khetarpal, Sharaf Zaman, David Brodrick, Sergio J. Rodríguez Méndez, Thang Bui, Alyssa Goodman, Alberto Accomazzi, Jill Naiman, Jesse Cranney, Kevin Schawinski, UniverseTBD</li>
<li>for:  bridging the gap between large language models and highly specialized domains like scholarly astronomy</li>
<li>methods:  fine-tuning a 7-billion-parameter model from LLaMA-2 using over 300,000 astronomy abstracts from arXiv, optimized for traditional causal language modeling</li>
<li>results:  achieving a 30% lower perplexity than Llama-2, generating more insightful and scientifically relevant text completions and embedding extraction than state-of-the-art foundation models despite having significantly fewer parameters<details>
<summary>Abstract</summary>
Large language models excel in many human-language tasks but often falter in highly specialized domains like scholarly astronomy. To bridge this gap, we introduce AstroLLaMA, a 7-billion-parameter model fine-tuned from LLaMA-2 using over 300,000 astronomy abstracts from arXiv. Optimized for traditional causal language modeling, AstroLLaMA achieves a 30% lower perplexity than Llama-2, showing marked domain adaptation. Our model generates more insightful and scientifically relevant text completions and embedding extraction than state-of-the-arts foundation models despite having significantly fewer parameters. AstroLLaMA serves as a robust, domain-specific model with broad fine-tuning potential. Its public release aims to spur astronomy-focused research, including automatic paper summarization and conversational agent development.
</details>
<details>
<summary>摘要</summary>
大型语言模型在许多人类语言任务中表现出色，但在高度特殊化的学术天文领域中往往表现不佳。为了bridging这个差距，我们介绍AstroLLaMA，一个基于LLaMA-2的70亿个 Parameters模型，通过arXiv上的30万篇天文摘要文献进行精细调整。这个模型适用于传统的 causal 语言模型，与LLaMA-2相比，每个字的误差率下降了30%，表明了域 adaptation。我们的模型在对天文领域的文本完成和嵌入EXTRACTING方面表现更加具有意义和科学相关性，即使有较少的参数。AstroLLaMA是一个强大的专业领域模型，具有广泛的 fine-tuning 潜力。公开发布AstroLLaMA，以促进天文研究，包括自动摘要和对话代理开发。
</details></li>
</ul>
<hr>
<h2 id="Characterizing-Latent-Perspectives-of-Media-Houses-Towards-Public-Figures"><a href="#Characterizing-Latent-Perspectives-of-Media-Houses-Towards-Public-Figures" class="headerlink" title="Characterizing Latent Perspectives of Media Houses Towards Public Figures"></a>Characterizing Latent Perspectives of Media Houses Towards Public Figures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06112">http://arxiv.org/abs/2309.06112</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sharath Srivatsa, Srinath Srinivasa</li>
<li>for: 本研究旨在提出一种零例学习方法，用于非EXTRACTIVE或生成式人EntityCharacterization。</li>
<li>methods: 该方法使用GPT-2预训练语言模型，首先在特定人Entity是Characterized的文献中进行了细化。然后，该模型进行了第二次细化，使用手动提供的示例Characterizations。</li>
<li>results: 结果表明，使用该方法可以生成准确的人EntityCharacterization，并且比预先训练的模型更加准确。<details>
<summary>Abstract</summary>
Media houses reporting on public figures, often come with their own biases stemming from their respective worldviews. A characterization of these underlying patterns helps us in better understanding and interpreting news stories. For this, we need diverse or subjective summarizations, which may not be amenable for classifying into predefined class labels. This work proposes a zero-shot approach for non-extractive or generative characterizations of person entities from a corpus using GPT-2. We use well-articulated articles from several well-known news media houses as a corpus to build a sound argument for this approach. First, we fine-tune a GPT-2 pre-trained language model with a corpus where specific person entities are characterized. Second, we further fine-tune this with demonstrations of person entity characterizations, created from a corpus of programmatically constructed characterizations. This twice fine-tuned model is primed with manual prompts consisting of entity names that were not previously encountered in the second fine-tuning, to generate a simple sentence about the entity. The results were encouraging, when compared against actual characterizations from the corpus.
</details>
<details>
<summary>摘要</summary>
媒体机构报道公众人物，经常带有自己的偏见，源于自己的世界观。了解这些底层模式，能够帮助我们更好地理解和解释新闻故事。为此，我们需要多样化或主观概要，这些概要可能无法被归类为预定的类别。这项工作提出了一种零批处理方法，通过GPT-2进行非抽取式或生成性人EntityCharacterizations。我们使用了多种知名新闻媒体的报道，构建了一个具有听众力的论证。首先，我们精度地调整GPT-2预训练语言模型，使其与特定人EntityCharacterizations相关的 corpus进行了精度调整。然后，我们进一步精度调整这个模型，使其能够生成基于 manually constructed characterizations的示例。这两次精度调整的模型，通过手动提供实体名称，并不在第二次精度调整中出现过的实体名称，来生成简单的句子。结果非常鼓舞人，与实际 corpus 中的Characterizations相比。
</details></li>
</ul>
<hr>
<h2 id="Towards-Visual-Taxonomy-Expansion"><a href="#Towards-Visual-Taxonomy-Expansion" class="headerlink" title="Towards Visual Taxonomy Expansion"></a>Towards Visual Taxonomy Expansion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06105">http://arxiv.org/abs/2309.06105</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/darthzhu/vte">https://github.com/darthzhu/vte</a></li>
<li>paper_authors: Tinghui Zhu, Jingping Liu, Jiaqing Liang, Haiyun Jiang, Yanghua Xiao, Zongyu Wang, Rui Xie, Yunsen Xian</li>
<li>for: 本研究旨在解决taxonomy扩展任务中的”Prototypical Hypernym Problem”，提出了视觉税onomy扩展(VTE)方法，将视觉特征引入到税onomy扩展中。</li>
<li>methods: 本研究提出了文本层次学习任务和视觉 проtotype学习任务，将文本和视觉 semantics集成到一起。此外，我们还引入了超 proto约束，将文本和视觉 semantics结合到一起生成细腻的视觉 semantics。</li>
<li>results: 我们在两个 dataset 上进行了实验，得到了鲜明的成果。具体来说，在中文税onomy dataset上，我们的方法相比原始方法提高了准确率8.75%。此外，我们的方法还在中文税onomy dataset上比ChatGPT better。<details>
<summary>Abstract</summary>
Taxonomy expansion task is essential in organizing the ever-increasing volume of new concepts into existing taxonomies. Most existing methods focus exclusively on using textual semantics, leading to an inability to generalize to unseen terms and the "Prototypical Hypernym Problem." In this paper, we propose Visual Taxonomy Expansion (VTE), introducing visual features into the taxonomy expansion task. We propose a textual hypernymy learning task and a visual prototype learning task to cluster textual and visual semantics. In addition to the tasks on respective modalities, we introduce a hyper-proto constraint that integrates textual and visual semantics to produce fine-grained visual semantics. Our method is evaluated on two datasets, where we obtain compelling results. Specifically, on the Chinese taxonomy dataset, our method significantly improves accuracy by 8.75 %. Additionally, our approach performs better than ChatGPT on the Chinese taxonomy dataset.
</details>
<details>
<summary>摘要</summary>
《税onomy扩展任务是组织新的概念 volume 的关键，因为现有的方法仅专注于使用文本 semantics，导致无法扩展至未见到的概念和"Prototypical Hypernym Problem"。在本文中，我们提出了可视的税onomy扩展（VTE），将可视特征加入税onomy扩展任务中。我们提出了文本层次学习任务和可视标本学习任务，以排序文本和可视 semantics。此外，我们引入了文本和可视 semantics的超类征约制，以生成细部可视 semantics。我们的方法在两个数据集上进行评估，结果表明我们的方法在中文税onomy数据集上提高了精度 by 8.75%，并且比ChatGPT在中文税onomy数据集上表现更好。
</details></li>
</ul>
<hr>
<h2 id="Measuring-Catastrophic-Forgetting-in-Cross-Lingual-Transfer-Paradigms-Exploring-Tuning-Strategies"><a href="#Measuring-Catastrophic-Forgetting-in-Cross-Lingual-Transfer-Paradigms-Exploring-Tuning-Strategies" class="headerlink" title="Measuring Catastrophic Forgetting in Cross-Lingual Transfer Paradigms: Exploring Tuning Strategies"></a>Measuring Catastrophic Forgetting in Cross-Lingual Transfer Paradigms: Exploring Tuning Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06089">http://arxiv.org/abs/2309.06089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boshko Koloski, Blaž Škrlj, Marko Robnik-Šikonja, Senja Pollak</li>
<li>for: 这个研究旨在比较两种精度器拟合方法在跨语言设置下进行大语言模型的微调。</li>
<li>methods: 研究使用了两种微调方法：参数有效的拟合方法和全参数微调。在跨语言传递方面，研究使用了中间训练（IT）和跨语言验证（CLV）两种方法。</li>
<li>results: 研究结果显示，在两个不同的分类问题（词语攻击和产品评论）上，IT跨语言策略在目标语言上表现更好。此外，研究发现，在多种跨语言传递中，CLV策略在基础语言（英语）中的知识抑制比IT策略更强。<details>
<summary>Abstract</summary>
The cross-lingual transfer is a promising technique to solve tasks in less-resourced languages. In this empirical study, we compare two fine-tuning approaches combined with zero-shot and full-shot learning approaches for large language models in a cross-lingual setting. As fine-tuning strategies, we compare parameter-efficient adapter methods with fine-tuning of all parameters. As cross-lingual transfer strategies, we compare the intermediate-training (\textit{IT}) that uses each language sequentially and cross-lingual validation (\textit{CLV}) that uses a target language already in the validation phase of fine-tuning. We assess the success of transfer and the extent of catastrophic forgetting in a source language due to cross-lingual transfer, i.e., how much previously acquired knowledge is lost when we learn new information in a different language. The results on two different classification problems, hate speech detection and product reviews, each containing datasets in several languages, show that the \textit{IT} cross-lingual strategy outperforms \textit{CLV} for the target language. Our findings indicate that, in the majority of cases, the \textit{CLV} strategy demonstrates superior retention of knowledge in the base language (English) compared to the \textit{IT} strategy, when evaluating catastrophic forgetting in multiple cross-lingual transfers.
</details>
<details>
<summary>摘要</summary>
cross-lingual transfer是一种有前途的技术，可以解决少语言资源的任务。在这个实验研究中，我们比较了两种精细调整方法，与零架构学习和全架构学习方法结合使用大语言模型在跨语言设置下进行比较。作为精细调整策略，我们比较了参数有效的适配器方法和所有参数的 fine-tuning。作为跨语言传递策略，我们比较了中间训练（IT），使用每种语言的顺序训练，以及跨语言验证（CLV），在练习阶段对 targets 语言进行验证。我们评估了跨语言传递的成功和源语言中的恶性遗弃现象，即在学习新语言时，之前学习的知识多少会丢失。我们在两个不同的分类问题，即词汇攻击和产品评论，每个问题都包含多种语言的数据集，得到的结果表明，对于目标语言，IT 跨语言策略表现出色。我们的发现表明，在大多数情况下，CLV 跨语言策略在多个跨语言传递中表现出更好的知识保留性，对于基础语言（英语）进行评估。
</details></li>
</ul>
<hr>
<h2 id="BHASA-A-Holistic-Southeast-Asian-Linguistic-and-Cultural-Evaluation-Suite-for-Large-Language-Models"><a href="#BHASA-A-Holistic-Southeast-Asian-Linguistic-and-Cultural-Evaluation-Suite-for-Large-Language-Models" class="headerlink" title="BHASA: A Holistic Southeast Asian Linguistic and Cultural Evaluation Suite for Large Language Models"></a>BHASA: A Holistic Southeast Asian Linguistic and Cultural Evaluation Suite for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06085">http://arxiv.org/abs/2309.06085</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aisingapore/bhasa">https://github.com/aisingapore/bhasa</a></li>
<li>paper_authors: Wei Qi Leong, Jian Gang Ngui, Yosephine Susanto, Hamsawardhini Rengarajan, Kengatharaiyer Sarveswaran, William Chandra Tjhi</li>
<li>for: 这个论文的目的是为了提出一个包容全面的语言模型评估遗产，以评估大语言模型在南东亚语言中的表现。</li>
<li>methods: 这个论文使用了一个包括八个任务的NLU、NLG和NLR任务的语言模型评估练习，以及一个覆盖各种语言现象的语言诊断工具集（LINDSEA）和一个文化诊断数据集。</li>
<li>results: 这个论文的初步实验表明，使用GPT-4作为参考点，这些南东亚语言的大语言模型在语言技能、文化表达和敏感性方面都存在缺陷。<details>
<summary>Abstract</summary>
The rapid development of Large Language Models (LLMs) and the emergence of novel abilities with scale have necessitated the construction of holistic, diverse and challenging benchmarks such as HELM and BIG-bench. However, at the moment, most of these benchmarks focus only on performance in English and evaluations that include Southeast Asian (SEA) languages are few in number. We therefore propose BHASA, a holistic linguistic and cultural evaluation suite for LLMs in SEA languages. It comprises three components: (1) a NLP benchmark covering eight tasks across Natural Language Understanding (NLU), Generation (NLG) and Reasoning (NLR) tasks, (2) LINDSEA, a linguistic diagnostic toolkit that spans the gamut of linguistic phenomena including syntax, semantics and pragmatics, and (3) a cultural diagnostics dataset that probes for both cultural representation and sensitivity. For this preliminary effort, we implement the NLP benchmark only for Indonesian, Vietnamese, Thai and Tamil, and we only include Indonesian and Tamil for LINDSEA and the cultural diagnostics dataset. As GPT-4 is purportedly one of the best-performing multilingual LLMs at the moment, we use it as a yardstick to gauge the capabilities of LLMs in the context of SEA languages. Our initial experiments on GPT-4 with BHASA find it lacking in various aspects of linguistic capabilities, cultural representation and sensitivity in the targeted SEA languages. BHASA is a work in progress and will continue to be improved and expanded in the future. The repository for this paper can be found at: https://github.com/aisingapore/BHASA
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate_language: zh-CNThe rapid development of Large Language Models (LLMs) and the emergence of novel abilities with scale have necessitated the construction of holistic, diverse and challenging benchmarks such as HELM and BIG-bench. However, at the moment, most of these benchmarks focus only on performance in English and evaluations that include Southeast Asian (SEA) languages are few in number. We therefore propose BHASA, a holistic linguistic and cultural evaluation suite for LLMs in SEA languages. It comprises three components: (1) a NLP benchmark covering eight tasks across Natural Language Understanding (NLU), Generation (NLG) and Reasoning (NLR) tasks, (2) LINDSEA, a linguistic diagnostic toolkit that spans the gamut of linguistic phenomena including syntax, semantics and pragmatics, and (3) a cultural diagnostics dataset that probes for both cultural representation and sensitivity. For this preliminary effort, we implement the NLP benchmark only for Indonesian, Vietnamese, Thai and Tamil, and we only include Indonesian and Tamil for LINDSEA and the cultural diagnostics dataset. As GPT-4 is purportedly one of the best-performing multilingual LLMs at the moment, we use it as a yardstick to gauge the capabilities of LLMs in the context of SEA languages. Our initial experiments on GPT-4 with BHASA find it lacking in various aspects of linguistic capabilities, cultural representation and sensitivity in the targeted SEA languages. BHASA is a work in progress and will continue to be improved and expanded in the future. The repository for this paper can be found at: https://github.com/aisingapore/BHASANote: The translation is in Simplified Chinese, which is the standard writing system used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="RAP-Gen-Retrieval-Augmented-Patch-Generation-with-CodeT5-for-Automatic-Program-Repair"><a href="#RAP-Gen-Retrieval-Augmented-Patch-Generation-with-CodeT5-for-Automatic-Program-Repair" class="headerlink" title="RAP-Gen: Retrieval-Augmented Patch Generation with CodeT5 for Automatic Program Repair"></a>RAP-Gen: Retrieval-Augmented Patch Generation with CodeT5 for Automatic Program Repair</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06057">http://arxiv.org/abs/2309.06057</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weishi Wang, Yue Wang, Shafiq Joty, Steven C. H. Hoi<br>for: 本研究的目的是提高自动程序修复（APR）的效能，以减少开发人员的手动调试努力并提高软件可靠性。methods: 本研究使用了深度学习（DL）基于的方法，通过在数据驱动方式下自动化程序修复过程。另外，我们还使用了一种混合的修补检索器，以便在不同的语言环境下进行lexical和semantic匹配。results: 我们的实验结果表明，RAP-Gen可以在三个benchmark上显著超越之前的状态态的方法，例如在818个Defects4J bug中修复15个更多的bug。<details>
<summary>Abstract</summary>
Automatic program repair (APR) is crucial to reduce manual debugging efforts for developers and improve software reliability. While conventional search-based techniques typically rely on heuristic rules or a redundancy assumption to mine fix patterns, recent years have witnessed the surge of deep learning (DL) based approaches to automate the program repair process in a data-driven manner. However, their performance is often limited by a fixed set of parameters to model the highly complex search space of APR. To ease such burden on the parametric models, in this work, we propose a novel Retrieval-Augmented Patch Generation framework (RAP-Gen) by explicitly leveraging relevant fix patterns retrieved from a codebase of previous bug-fix pairs. Specifically, we build a hybrid patch retriever to account for both lexical and semantic matching based on the raw source code in a language-agnostic manner, which does not rely on any code-specific features. In addition, we adapt a code-aware language model CodeT5 as our foundation model to facilitate both patch retrieval and generation tasks in a unified manner. We adopt a stage-wise approach where the patch retriever first retrieves a relevant external bug-fix pair to augment the buggy input for the CodeT5 patch generator, which synthesizes a ranked list of repair patch candidates. Notably, RAP-Gen is a generic APR framework that can flexibly integrate different patch retrievers and generators to repair various types of bugs. We thoroughly evaluate RAP-Gen on three benchmarks in two programming languages, including the TFix benchmark in JavaScript, and Code Refinement and Defects4J benchmarks in Java, where the bug localization information may or may not be provided. Experimental results show that RAP-Gen significantly outperforms previous state-of-the-art approaches on all benchmarks, e.g., repairing 15 more bugs on 818 Defects4J bugs.
</details>
<details>
<summary>摘要</summary>
自动化程序修复（APR）是软件可靠性的关键因素，可以减少开发人员的手动调试努力并提高软件的可靠性。传统的搜索基本技术通常采用规则或减少假设来挖掘修复模式，而 recent years 有所见到 Deep Learning（DL） 基于的方法来自动化程序修复过程。但是，它们的性能通常受到一组固定参数来模型高度复杂的修复空间的限制。为了减轻这种固定参数的负担，在这种工作中，我们提出了一种 novel Retrieval-Augmented Patch Generation 框架（RAP-Gen），通过显式地利用 Codebase 中的修复模式来提高修复效果。 Specifically，我们构建了一种 hybrid 修复搜索器，可以根据源代码的语言无关方式进行 both lexical 和 semantic 匹配，而不需要任何代码特定的特征。此外，我们采用 Code-aware 语言模型 CodeT5 作为基础模型，以便在一个简单的方式下进行修复搜索和生成任务。我们采用分阶段的方法，首先由修复搜索器 retrieved 一个相关的外部修复对，然后将其与 CodeT5 修复生成器进行结合，以生成一个排名列表中的修复补丁候选者。需要注意的是，RAP-Gen 是一种通用的 APR 框架，可以适应不同的修复任务和语言。我们对 TFix  benchmark 、Code Refinement 和 Defects4J  benchmark 进行了严格的测试，结果表明，RAP-Gen 在所有benchmark上显著超过了前一个状态的方法，例如，对 818 Defects4J  bug 进行修复。
</details></li>
</ul>
<hr>
<h2 id="How-does-representation-impact-in-context-learning-A-exploration-on-a-synthetic-task"><a href="#How-does-representation-impact-in-context-learning-A-exploration-on-a-synthetic-task" class="headerlink" title="How does representation impact in-context learning: A exploration on a synthetic task"></a>How does representation impact in-context learning: A exploration on a synthetic task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06054">http://arxiv.org/abs/2309.06054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingwen Fu, Tao Yang, Yuwang Wang, Yan Lu, Nanning Zheng</li>
<li>for:  investigate the mechanism of in-context learning in Transformer</li>
<li>methods: construct a novel synthetic task, use two probes to evaluate in-weights and in-context components</li>
<li>results: demonstrate the entanglement between in-context learning and representation learning, and the importance of in-weights component for in-context learning<details>
<summary>Abstract</summary>
In-context learning, i.e., learning from in-context samples, is an impressive ability of Transformer. However, the mechanism driving the in-context learning is not yet fully understood. In this study, we aim to investigate from an underexplored perspective of representation learning. The representation is more complex for in-context learning senario, where the representation can be impacted by both model weights and in-context samples. We refer the above two conceptually aspects of representation as in-weight component and in-context component, respectively. To study how the two components affect in-context learning capabilities, we construct a novel synthetic task, making it possible to device two probes, in-weights probe and in-context probe, to evaluate the two components, respectively. We demonstrate that the goodness of in-context component is highly related to the in-context learning performance, which indicates the entanglement between in-context learning and representation learning. Furthermore, we find that a good in-weights component can actually benefit the learning of the in-context component, indicating that in-weights learning should be the foundation of in-context learning. To further understand the the in-context learning mechanism and importance of the in-weights component, we proof by construction that a simple Transformer, which uses pattern matching and copy-past mechanism to perform in-context learning, can match the in-context learning performance with more complex, best tuned Transformer under the perfect in-weights component assumption. In short, those discoveries from representation learning perspective shed light on new approaches to improve the in-context capacity.
</details>
<details>
<summary>摘要</summary>
受Context学习，即通过在Context中的样本学习，是Transformer的一项惊人能力。然而，这种学习机制仍未完全理解。在这项研究中，我们尝试从 representation learning 的一个未经探索的角度来研究。在这种情况下，表示更加复杂，因为表示可以受到模型参数和Context中的样本影响。我们将这两个概念性方面的表示称为内重Component和Context Component，分别。为了研究这两个组件如何影响Context learning能力，我们构建了一个新的 sintetic任务，使得可以设置两个探针，即内重探针和Context探针，来评估这两个组件。我们发现，Context component 的质量与 Context learning 性能之间存在很高的相关性，这表明Context learning 和 representation learning 之间存在紧密的关系。此外，我们发现一个好的内重Component 可以实际提高Context component 的学习效果，这表明内重学习应该是Context learning 的基础。为了更深入地理解Context learning 机制和内重Component 的重要性，我们证明了一个简单的Transformer模型，通过模式匹配和复制机制来实现Context learning，可以与best tuned Transformer 模型匹配Context learning性能，假设内重Component 完美。总之，这些发现从 representation learning 的角度提供了新的方法来提高Context capacity。
</details></li>
</ul>
<hr>
<h2 id="Narrowing-the-Gap-between-Supervised-and-Unsupervised-Sentence-Representation-Learning-with-Large-Language-Model"><a href="#Narrowing-the-Gap-between-Supervised-and-Unsupervised-Sentence-Representation-Learning-with-Large-Language-Model" class="headerlink" title="Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model"></a>Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06453">http://arxiv.org/abs/2309.06453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingxin Li, Richong Zhang, Zhijie Nie, Yongyi Mao</li>
<li>for: 本研究的目的是解释supervised和unsupervised Contrastive learning of Sentence Embeddings (CSE)在训练过程中的性能差距，以及如何减少这个差距。</li>
<li>methods: 本研究使用了empirical experiments和metric called Fitting Difficulty Increment (FDI)来解释和解决性能差距问题。</li>
<li>results: 研究发现，性能差距的主要原因是训练数据集和评估数据集的适应度差异，并提出了一种基于LLM生成数据的方法来减少性能差距。<details>
<summary>Abstract</summary>
Sentence Representation Learning (SRL) is a fundamental task in Natural Language Processing (NLP), with Contrastive learning of Sentence Embeddings (CSE) as the mainstream technique due to its superior performance. An intriguing phenomenon in CSE is the significant performance gap between supervised and unsupervised methods, even when their sentence encoder and loss function are the same. Previous works attribute this performance gap to differences in two representation properties (alignment and uniformity). However, alignment and uniformity only measure the results, which means they cannot answer "What happens during the training process that leads to the performance gap?" and "How can the performance gap be narrowed?". In this paper, we conduct empirical experiments to answer these "What" and "How" questions. We first answer the "What" question by thoroughly comparing the behavior of supervised and unsupervised CSE during their respective training processes. From the comparison, We observe a significant difference in fitting difficulty. Thus, we introduce a metric, called Fitting Difficulty Increment (FDI), to measure the fitting difficulty gap between the evaluation dataset and the held-out training dataset, and use the metric to answer the "What" question. Then, based on the insights gained from the "What" question, we tackle the "How" question by increasing the fitting difficulty of the training dataset. We achieve this by leveraging the In-Context Learning (ICL) capability of the Large Language Model (LLM) to generate data that simulates complex patterns. By utilizing the hierarchical patterns in the LLM-generated data, we effectively narrow the gap between supervised and unsupervised CSE.
</details>
<details>
<summary>摘要</summary>
我们首先回答"What"问题，对监督和无监督CSE在训练过程中的行为进行了仔细比较。从比较中，我们发现监督CSE在训练过程中的适应 difficulty 和无监督CSE相比较大。因此，我们引入一个指标，叫做适应难度增量 (FDI)，用于度量监督和无监督CSE在评估集和封锁训练集之间的适应难度差距。然后，根据FDI指标，我们回答"What"问题。接着，基于获得的"What"问题的回答，我们解决"How"问题。我们通过利用大语言模型 (LLM) 的启发学习 (ICL) 能力，生成数据，模拟复杂的模式。通过利用 LLB 生成的数据中的层次模式，我们有效地缩小了监督和无监督CSE之间的性能差距。
</details></li>
</ul>
<hr>
<h2 id="Content-Reduction-Surprisal-and-Information-Density-Estimation-for-Long-Documents"><a href="#Content-Reduction-Surprisal-and-Information-Density-Estimation-for-Long-Documents" class="headerlink" title="Content Reduction, Surprisal and Information Density Estimation for Long Documents"></a>Content Reduction, Surprisal and Information Density Estimation for Long Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06009">http://arxiv.org/abs/2309.06009</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaoxiong Ji, Wei Sun, Pekka Marttinen</li>
<li>for: 这个论文研究了语言信息含义的计算语言方法，特别是长文档中信息分布和减少内容对信息密度的影响。</li>
<li>methods: 这篇论文提出了四种信息密度估计标准，其中前三个采用信息理论中的度量，并提出了一种基于注意力的单词选择方法来处理医疗记录。</li>
<li>results: 研究发现了不同领域的长文档信息密度系统性差异，并且对自动医疗代码生成从长医疗记录中表现效果良好。<details>
<summary>Abstract</summary>
Many computational linguistic methods have been proposed to study the information content of languages. We consider two interesting research questions: 1) how is information distributed over long documents, and 2) how does content reduction, such as token selection and text summarization, affect the information density in long documents. We present four criteria for information density estimation for long documents, including surprisal, entropy, uniform information density, and lexical density. Among those criteria, the first three adopt the measures from information theory. We propose an attention-based word selection method for clinical notes and study machine summarization for multiple-domain documents. Our findings reveal the systematic difference in information density of long text in various domains. Empirical results on automated medical coding from long clinical notes show the effectiveness of the attention-based word selection method.
</details>
<details>
<summary>摘要</summary>
多种计算语言学方法已经被提出来研究语言信息内容。我们考虑了两个有趣的研究问题：1）在长文档中如何分布信息，2）如何采用内容减少方法（如选择 Token 和文本摘要）影响长文档中的信息密度。我们提出了四个信息密度估计标准，包括悬念度、熵、一致信息密度和词汇密度。其中前三个采用信息理论的度量。我们提议使用注意力基于词选择方法来处理医疗记录，并对多个领域文档进行机器摘要。我们的发现显示了不同领域的长文档信息密度存在系统性的差异。对自动医疗代码生成从长医疗记录的实验结果表明了注意力基于词选择方法的效果。
</details></li>
</ul>
<hr>
<h2 id="Kid-Whisper-Towards-Bridging-the-Performance-Gap-in-Automatic-Speech-Recognition-for-Children-VS-Adults"><a href="#Kid-Whisper-Towards-Bridging-the-Performance-Gap-in-Automatic-Speech-Recognition-for-Children-VS-Adults" class="headerlink" title="Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech Recognition for Children VS. Adults"></a>Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech Recognition for Children VS. Adults</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07927">http://arxiv.org/abs/2309.07927</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Adel Attia, Jing Liu, Wei Ai, Dorottya Demszky, Carol Espy-Wilson</li>
<li>for: 这个研究旨在提高儿童语音识别系统的性能，以便更好地支持儿童的语言发展和学习。</li>
<li>methods: 该研究使用了Whisper自动语音识别系统，并对My Science Tutor儿童语音数据集进行了更有效的数据处理，以提高Whisper的性能。</li>
<li>results: 研究显示，通过更有效的数据处理，可以将Word Error Rate（WER）在MyST测试集下降至9.11%（Whisper-Small）和8.61%（Whisper-Medium），并且这种改进可以普适应用于未经看过的数据集。此外，研究还揭示了儿童语音识别系统的一些重要挑战。<details>
<summary>Abstract</summary>
Recent advancements in Automatic Speech Recognition (ASR) systems, exemplified by Whisper, have demonstrated the potential of these systems to approach human-level performance given sufficient data. However, this progress doesn't readily extend to ASR for children due to the limited availability of suitable child-specific databases and the distinct characteristics of children's speech. A recent study investigated leveraging the My Science Tutor (MyST) children's speech corpus to enhance Whisper's performance in recognizing children's speech. They were able to demonstrate some improvement on a limited testset. This paper builds on these findings by enhancing the utility of the MyST dataset through more efficient data preprocessing. We reduce the Word Error Rate (WER) on the MyST testset 13.93% to 9.11% with Whisper-Small and from 13.23% to 8.61% with Whisper-Medium and show that this improvement can be generalized to unseen datasets. We also highlight important challenges towards improving children's ASR performance. The results showcase the viable and efficient integration of Whisper for effective children's speech recognition.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Robustness-of-Neural-Inverse-Text-Normalization-via-Data-Augmentation-Semi-Supervised-Learning-and-Post-Aligning-Method"><a href="#Improving-Robustness-of-Neural-Inverse-Text-Normalization-via-Data-Augmentation-Semi-Supervised-Learning-and-Post-Aligning-Method" class="headerlink" title="Improving Robustness of Neural Inverse Text Normalization via Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method"></a>Improving Robustness of Neural Inverse Text Normalization via Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08626">http://arxiv.org/abs/2309.08626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juntae Kim, Minkyu Lim, Seokjin Hong</li>
<li>for: 这 paper 的目的是提高自动语音识别 (ASR) 系统中的反文本normalization (ITN) 性能, 特别是在 spoken-form 转换到 written-form 的上下文中。</li>
<li>methods: 这 paper 提出了一种直接训练方法, 使用 ASR 生成的 spoken 或 written 文本，并通过 ASR 语言上下文模拟和 semi-supervised learning 方法增强。 此外，paper 还引入了一种后置对aligning 方法来管理不可预测的错误，以提高 ITN 的可靠性。</li>
<li>results:  experiments 表明，paper 提出的方法在多种 ASR 场景中显著提高了 ITN 性能。<details>
<summary>Abstract</summary>
Inverse text normalization (ITN) is crucial for converting spoken-form into written-form, especially in the context of automatic speech recognition (ASR). While most downstream tasks of ASR rely on written-form, ASR systems often output spoken-form, highlighting the necessity for robust ITN in product-level ASR-based applications. Although neural ITN methods have shown promise, they still encounter performance challenges, particularly when dealing with ASR-generated spoken text. These challenges arise from the out-of-domain problem between training data and ASR-generated text. To address this, we propose a direct training approach that utilizes ASR-generated written or spoken text, with pairs augmented through ASR linguistic context emulation and a semi-supervised learning method enhanced by a large language model, respectively. Additionally, we introduce a post-aligning method to manage unpredictable errors, thereby enhancing the reliability of ITN. Our experiments show that our proposed methods remarkably improved ITN performance in various ASR scenarios.
</details>
<details>
<summary>摘要</summary>
倒计时normalization (ITN) 是对话式文本转换到书面文本的关键技术，尤其在自动语音识别 (ASR) 的上下文中。大多数 ASR 下游任务需要书面文本，但 ASR 系统通常输出说话式文本，因此需要Robust ITN 在产品级 ASR 应用中。虽然神经 ITN 方法有 shown 搅拌，但它们在处理 ASR 生成的说话文本时仍然遇到性能挑战。这些挑战来自于 ASR 生成的文本与训练数据之间的域外问题。为 Addressing 这个问题，我们提议一种直接训练方法，利用 ASR 生成的书面或说话文本，并通过 ASR 语言上下文模拟和大型语言模型增强的半监督学习方法，分别对待不同的 ASR enario。此外，我们还引入了一种后对aligning 方法，以管理不可预测的错误，从而提高 ITN 的可靠性。我们的实验表明，我们的提议方法在多种 ASR 情况下有remarkably 改善 ITN 性能。
</details></li>
</ul>
<hr>
<h2 id="Performance-of-ChatGPT-3-5-and-GPT-4-on-the-United-States-Medical-Licensing-Examination-With-and-Without-Distractions"><a href="#Performance-of-ChatGPT-3-5-and-GPT-4-on-the-United-States-Medical-Licensing-Examination-With-and-Without-Distractions" class="headerlink" title="Performance of ChatGPT-3.5 and GPT-4 on the United States Medical Licensing Examination With and Without Distractions"></a>Performance of ChatGPT-3.5 and GPT-4 on the United States Medical Licensing Examination With and Without Distractions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08625">http://arxiv.org/abs/2309.08625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Myriam Safrai, Amos Azaria</li>
<li>for: 这项研究旨在调查 chatGPT 是否能准确地提供医疗建议，并且是否会受到小话信息的影响。</li>
<li>methods: 研究使用 USMLE 步骤 3 问题作为有用的医疗数据，并使用 Mechanical Turk 平台收集小话句子。将问题和小话句子排序并提供给 chatGPT 3.5 和 4 进行回答。一位资深医生分析 chatGPT 的答案，并与正确答案进行比较。</li>
<li>results: 结果表明，在多选问题上，chatGPT 3.5 的回答精度降低了，从 72.1% 降低到 68.9%，而在开题问题上，降低到 61.5%，比对应正确答案的比例为 44.3%。相比之下，chatGPT 4 在两类问题上的回答精度均高于 3.5 版本，不受小话信息的影响。<details>
<summary>Abstract</summary>
As Large Language Models (LLMs) are predictive models building their response based on the words in the prompts, there is a risk that small talk and irrelevant information may alter the response and the suggestion given. Therefore, this study aims to investigate the impact of medical data mixed with small talk on the accuracy of medical advice provided by ChatGPT. USMLE step 3 questions were used as a model for relevant medical data. We use both multiple choice and open ended questions. We gathered small talk sentences from human participants using the Mechanical Turk platform. Both sets of USLME questions were arranged in a pattern where each sentence from the original questions was followed by a small talk sentence. ChatGPT 3.5 and 4 were asked to answer both sets of questions with and without the small talk sentences. A board-certified physician analyzed the answers by ChatGPT and compared them to the formal correct answer. The analysis results demonstrate that the ability of ChatGPT-3.5 to answer correctly was impaired when small talk was added to medical data for multiple-choice questions (72.1\% vs. 68.9\%) and open questions (61.5\% vs. 44.3\%; p=0.01), respectively. In contrast, small talk phrases did not impair ChatGPT-4 ability in both types of questions (83.6\% and 66.2\%, respectively). According to these results, ChatGPT-4 seems more accurate than the earlier 3.5 version, and it appears that small talk does not impair its capability to provide medical recommendations. Our results are an important first step in understanding the potential and limitations of utilizing ChatGPT and other LLMs for physician-patient interactions, which include casual conversations.
</details>
<details>
<summary>摘要</summary>
LLMS（大语言模型）是基于提示语言的预测模型，因此可能存在小说和无关信息影响其回答和建议的风险。这项研究旨在研究将医疗数据混合到小说中对ChatGPT提供的医疗建议精度的影响。我们使用USMLE步骤3题目作为相关医疗数据模型。我们使用多选和开放题目两种类型。我们从人工智能 Turk 平台获得了小说句子。我们将USMLE题目分配成一种模式，其中每个原始句子后接一个小说句子。ChatGPT 3.5和4被要求回答这两个集合的问题，包括和小说句子。一位资深的医生分析了ChatGPT的答案并与正确答案进行比较。分析结果显示，当小说句子添加到医疗数据时，ChatGPT-3.5 的回答正确率下降（72.1% vs. 68.9%）和开放题目中的回答正确率下降（61.5% vs. 44.3%）。相比之下，小说句子不会对ChatGPT-4 的回答造成影响（83.6%和66.2%）。根据这些结果，ChatGPT-4 显示更加准确，而小说不会对其医疗建议能力产生影响。这些结果是我们理解LLMS在实际医疗互动中的潜在和局限性的重要一步。
</details></li>
</ul>
<hr>
<h2 id="Circuit-Breaking-Removing-Model-Behaviors-with-Targeted-Ablation"><a href="#Circuit-Breaking-Removing-Model-Behaviors-with-Targeted-Ablation" class="headerlink" title="Circuit Breaking: Removing Model Behaviors with Targeted Ablation"></a>Circuit Breaking: Removing Model Behaviors with Targeted Ablation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05973">http://arxiv.org/abs/2309.05973</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xanderdavies/circuit-breaking">https://github.com/xanderdavies/circuit-breaking</a></li>
<li>paper_authors: Maximilian Li, Xander Davies, Max Nadeau</li>
<li>For: 降低 GPT-2 语言生成中的偏见行为* Methods: 范例小数据集中找到关键 causal 通路，并删除这些通路以关键排除偏见行为* Results: 删除 12 条 causal 通路可以严重降低偏见语言生成，并对其他输入的性能几乎没有影响<details>
<summary>Abstract</summary>
Language models often exhibit behaviors that improve performance on a pre-training objective but harm performance on downstream tasks. We propose a novel approach to removing undesirable behaviors by ablating a small number of causal pathways between model components, with the intention of disabling the computational circuit responsible for the bad behavior. Given a small dataset of inputs where the model behaves poorly, we learn to ablate a small number of important causal pathways. In the setting of reducing GPT-2 toxic language generation, we find ablating just 12 of the 11.6K causal edges mitigates toxic generation with minimal degradation of performance on other inputs.
</details>
<details>
<summary>摘要</summary>
机器学习模型经常展现出提高预训练目标性能的行为，但是却害下游任务性能。我们提出了一种新的方法，通过缺省少量的 causal 路径间的缺省来消除不良行为。通过一小量的输入数据，我们学习缺省少量的重要 causal 路径。在减少 GPT-2 毒性语言生成中，我们发现缺省12个 causal 边对毒性语言生成产生了很好的效果，而不会对其他输入产生很大的影响。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Ebb-and-Flow-An-In-depth-Analysis-of-Question-Answering-Trends-across-Diverse-Platforms"><a href="#Evaluating-the-Ebb-and-Flow-An-In-depth-Analysis-of-Question-Answering-Trends-across-Diverse-Platforms" class="headerlink" title="Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms"></a>Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05961">http://arxiv.org/abs/2309.05961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rima Hazra, Agnik Saha, Somnath Banerjee, Animesh Mukherjee</li>
<li>for: This paper aims to investigate the factors that contribute to the speed of responses on Community Question Answering (CQA) platforms.</li>
<li>methods: The authors analyze six highly popular CQA platforms and identify correlations between the time taken to yield the first response to a question and various variables, including metadata and patterns of user interaction. They also employ conventional machine learning models to predict which queries will receive prompt responses.</li>
<li>results: The study finds a correlation between the time taken to yield the first response and several variables, including the formulation of the questions and the level of interaction among users. The authors also demonstrate the feasibility of using machine learning models to predict prompt responses.<details>
<summary>Abstract</summary>
Community Question Answering (CQA) platforms steadily gain popularity as they provide users with fast responses to their queries. The swiftness of these responses is contingent on a mixture of query-specific and user-related elements. This paper scrutinizes these contributing factors within the context of six highly popular CQA platforms, identified through their standout answering speed. Our investigation reveals a correlation between the time taken to yield the first response to a question and several variables: the metadata, the formulation of the questions, and the level of interaction among users. Additionally, by employing conventional machine learning models to analyze these metadata and patterns of user interaction, we endeavor to predict which queries will receive their initial responses promptly.
</details>
<details>
<summary>摘要</summary>
社区问答平台（CQA）的流行程度逐渐增长，因为它们为用户提供了快速的答案。这种快速答案的速度受到多种问题特定和用户相关的因素的影响。这篇论文在六个非常受欢迎的CQA平台上 investigate这些贡献因素，并通过使用传统的机器学习模型分析这些元数据和用户交互的模式，尝试预测哪些问题会收到快速的初始答案。Here's a word-for-word translation:社区问答平台（CQA）的流行程度逐渐增长，因为它们为用户提供了快速的答案。这种快速答案的速度受到多种问题特定和用户相关的因素的影响。这篇论文在六个非常受欢迎的CQA平台上 investigate这些贡献因素，并通过使用传统的机器学习模型分析这些元数据和用户交互的模式，尝试预测哪些问题会收到快速的初始答案。
</details></li>
</ul>
<hr>
<h2 id="The-Moral-Machine-Experiment-on-Large-Language-Models"><a href="#The-Moral-Machine-Experiment-on-Large-Language-Models" class="headerlink" title="The Moral Machine Experiment on Large Language Models"></a>The Moral Machine Experiment on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05958">http://arxiv.org/abs/2309.05958</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kztakemoto/mmllm">https://github.com/kztakemoto/mmllm</a></li>
<li>paper_authors: Kazuhiro Takemoto</li>
<li>for: 本研究旨在 investigate 大型自然语言模型（LLM）在道路自动驾驶中的伦理决策倾向，以及这些模型如何与人类的伦理偏好相符。</li>
<li>methods: 该研究使用了 Moral Machine 框架，对包括 GPT-3.5、GPT-4、PaLM 2 和 Llama 2 等知名 LLM 进行了比较，并与人类的偏好进行了比较。</li>
<li>results: 研究发现，尽管 LLM 和人类的偏好在一些方面相似，但 PaLM 2 和 Llama 2 等模型尤其存在明显的偏差。此外，尽管qualitative上的偏好相似，但 LLM 可能会偏向更加坚定的决策，与人类的偏好相比。这些发现可能有助于我们更好地理解 LLM 的伦理框架，并对道路自动驾驶的发展产生影响。<details>
<summary>Abstract</summary>
As large language models (LLMs) become more deeply integrated into various sectors, understanding how they make moral judgments has become crucial, particularly in the realm of autonomous driving. This study utilized the Moral Machine framework to investigate the ethical decision-making tendencies of prominent LLMs, including GPT-3.5, GPT-4, PaLM 2, and Llama 2, comparing their responses to human preferences. While LLMs' and humans' preferences such as prioritizing humans over pets and favoring saving more lives are broadly aligned, PaLM 2 and Llama 2, especially, evidence distinct deviations. Additionally, despite the qualitative similarities between the LLM and human preferences, there are significant quantitative disparities, suggesting that LLMs might lean toward more uncompromising decisions, compared to the milder inclinations of humans. These insights elucidate the ethical frameworks of LLMs and their potential implications for autonomous driving.
</details>
<details>
<summary>摘要</summary>
large language models (LLMs) 在不同领域深入整合后，理解它们如何作出道德判断成为了重要的焦点，尤其在自动驾驶领域。这个研究使用道德机器框架进行 investigated the ethical decision-making tendencies of prominent LLMs, including GPT-3.5, GPT-4, PaLM 2, and Llama 2, and compared their responses to human preferences。 although LLMs' and humans' preferences such as prioritizing humans over pets and favoring saving more lives are broadly aligned，PaLM 2 and Llama 2, especially, evidence distinct deviations。 In addition, despite the qualitative similarities between the LLM and human preferences, there are significant quantitative disparities, suggesting that LLMs might lean toward more uncompromising decisions, compared to the milder inclinations of humans。 These insights elucidate the ethical frameworks of LLMs and their potential implications for autonomous driving。
</details></li>
</ul>
<hr>
<h2 id="Balanced-and-Explainable-Social-Media-Analysis-for-Public-Health-with-Large-Language-Models"><a href="#Balanced-and-Explainable-Social-Media-Analysis-for-Public-Health-with-Large-Language-Models" class="headerlink" title="Balanced and Explainable Social Media Analysis for Public Health with Large Language Models"></a>Balanced and Explainable Social Media Analysis for Public Health with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05951">http://arxiv.org/abs/2309.05951</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanjiangjerry/alex">https://github.com/yanjiangjerry/alex</a></li>
<li>paper_authors: Yan Jiang, Ruihong Qiu, Yi Zhang, Peng-Fei Zhang</li>
<li>for: 本研究旨在提出一种 Novel ALEX 框架，用于社交媒体数据分析，以提高公共健康活动中的监测和决策。</li>
<li>methods: 本研究使用了数据增强策略来解决社交媒体数据的数据不均衡问题，并通过提示 LLM 来提高模型的表现。</li>
<li>results: 根据实验结果，提出的 ALEX 方法在 Social Media Mining for Health 2023 (SMM4H) 竞赛中的三个任务中得到了杰出的表现，在两个任务中得到了第一名。<details>
<summary>Abstract</summary>
As social media becomes increasingly popular, more and more public health activities emerge, which is worth noting for pandemic monitoring and government decision-making. Current techniques for public health analysis involve popular models such as BERT and large language models (LLMs). Although recent progress in LLMs has shown a strong ability to comprehend knowledge by being fine-tuned on specific domain datasets, the costs of training an in-domain LLM for every specific public health task are especially expensive. Furthermore, such kinds of in-domain datasets from social media are generally highly imbalanced, which will hinder the efficiency of LLMs tuning. To tackle these challenges, the data imbalance issue can be overcome by sophisticated data augmentation methods for social media datasets. In addition, the ability of the LLMs can be effectively utilised by prompting the model properly. In light of the above discussion, in this paper, a novel ALEX framework is proposed for social media analysis on public health. Specifically, an augmentation pipeline is developed to resolve the data imbalance issue. Furthermore, an LLMs explanation mechanism is proposed by prompting an LLM with the predicted results from BERT models. Extensive experiments conducted on three tasks at the Social Media Mining for Health 2023 (SMM4H) competition with the first ranking in two tasks demonstrate the superior performance of the proposed ALEX method. Our code has been released in https://github.com/YanJiangJerry/ALEX.
</details>
<details>
<summary>摘要</summary>
为了适应社交媒体日益普及，更多的公共健康活动在发展，这对抗疫病监测和政府决策都是值得注意的。当前的公共健康分析技术主要基于受欢迎的模型BERT和大型自然语言模型（LLM）。虽然最近的LLM进步显示在特定领域数据集上精细调整后具有强大的知识把握能力，但是训练专门领域LLM的成本尤其高昂。此外，这些社交媒体数据集通常具有很高的不均衡性，这会降低LLM的调整效率。为了解决这些挑战，本文提出了一种novel ALEX框架，用于社交媒体分析。特别是，我们开发了一个数据增强管线，以解决数据不均衡问题。此外，我们还提出了一种LLM的解释机制，通过向LLM提供BERT模型预测结果进行引导。经过广泛的实验，我们在2023年社交媒体矿山健康大赛（SMM4H）中的三个任务中获得了第一名。我们的代码已经在https://github.com/YanJiangJerry/ALEX上发布。
</details></li>
</ul>
<hr>
<h2 id="Language-Models-as-Black-Box-Optimizers-for-Vision-Language-Models"><a href="#Language-Models-as-Black-Box-Optimizers-for-Vision-Language-Models" class="headerlink" title="Language Models as Black-Box Optimizers for Vision-Language Models"></a>Language Models as Black-Box Optimizers for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05950">http://arxiv.org/abs/2309.05950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shihongl1998/llm-as-a-blackbox-optimizer">https://github.com/shihongl1998/llm-as-a-blackbox-optimizer</a></li>
<li>paper_authors: Samuel Yu, Shihong Liu, Zhiqiu Lin, Deepak Pathak, Deva Ramanan<br>for: 这个研究旨在开发一种基于自然语言提示的视觉语言模型（VLM）微调方法，以避免需要存取模型参数、特征嵌入或输出寄存器。methods: 我们提出了一种使用对话式大语言模型（LLM）作为黑盒优化器，通过自动“山丘攀登”程序，让 LLM 根据文本反馈来调整提示，以实现最佳提示的搜寻。results: 在一个挑战性的1架学习设置下，我们的简单方法比 white-box 连续提示方法 CoOp 高出1.5%的平均准确率 across 11个数据集，包括 ImageNet。我们的方法还超过 OpenAI 手动制作的提示和其他黑盒方法 like iterative APE，并且发现文本提示生成的过程不仅更加可读性，而且可以在不同的 CLIP 架构上传递。<details>
<summary>Abstract</summary>
Vision-language models (VLMs) pre-trained on web-scale datasets have demonstrated remarkable capabilities across a variety of vision and multimodal tasks. Currently, fine-tuning methods for VLMs mainly operate in a white-box setting, requiring access to model parameters for backpropagation. However, many VLMs rely on proprietary data and are not open-source, which restricts the use of white-box approaches for fine-tuning. Given that popular private large language models (LLMs) like ChatGPT still offer a language-based user interface, we aim to develop a novel fine-tuning approach for VLMs through natural language prompts, thereby avoiding the need to access model parameters, feature embeddings, or output logits. In this setup, we propose employing chat-based LLMs as black-box optimizers to search for the best text prompt on the illustrative task of few-shot image classification using CLIP. Specifically, we adopt an automatic "hill-climbing" procedure that converges on an effective prompt by evaluating the accuracy of current prompts and asking LLMs to refine them based on textual feedback, all within a conversational process without human-in-the-loop. In a challenging 1-shot learning setup, our simple approach surpasses the white-box continuous prompting method CoOp by an average of 1.5% across 11 datasets including ImageNet. Our approach also outperforms OpenAI's manually crafted prompts and is more efficient than other black-box methods like iterative APE. Additionally, we highlight the advantage of conversational feedback incorporating both positive and negative prompts, suggesting that LLMs can utilize the implicit "gradient" direction in textual feedback for a more efficient search. Lastly, we find that the text prompts generated through our strategy are not only more interpretable but also transfer well across different CLIP architectures in a black-box manner.
</details>
<details>
<summary>摘要</summary>
现代视觉语言模型（VLM）在大规模网络数据上进行预训练后，在视觉和多模态任务上表现出了惊人的能力。然而，现有的细化方法主要 operate在白盒子 Setting中，需要访问模型参数进行反射。然而，许多VLM rely on proprietary data，这限制了使用白盒子approach for fine-tuning。在这种情况下，我们提出了一种新的细化方法，通过自然语言提示来避免访问模型参数、特征嵌入和输出征。在这种设置中，我们提议使用流行私人大型语言模型（LLM）like ChatGPT作为黑盒子优化器，通过自然语言反馈来搜索最佳提示。具体来说，我们采用了一种自动“山丘攀 climbing”过程，通过评估当前提示的准确率，请LLM进行提示的修改，以达到最佳提示。在一个挑战性的1shot learning设置下，我们的简单方法比白盒子连续提示方法CoOp高平均1.5% across 11 datasets，包括ImageNet。我们的方法还超过OpenAI manually 制作的提示，并且更高效 чем其他黑盒子方法，如迭代APE。此外，我们发现通过 incorporating both positive和negative提示，LLMs可以利用文本反馈中的隐式“梯度”方向进行更加高效的搜索。最后，我们发现通过我们的策略生成的文本提示不仅更加可读性高，还可以在黑盒子方式下跨不同的 CLIP 架构传输。
</details></li>
</ul>
<hr>
<h2 id="Do-PLMs-Know-and-Understand-Ontological-Knowledge"><a href="#Do-PLMs-Know-and-Understand-Ontological-Knowledge" class="headerlink" title="Do PLMs Know and Understand Ontological Knowledge?"></a>Do PLMs Know and Understand Ontological Knowledge?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05936">http://arxiv.org/abs/2309.05936</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vickywu1022/ontoprobe-plms">https://github.com/vickywu1022/ontoprobe-plms</a></li>
<li>paper_authors: Weiqi Wu, Chengyue Jiang, Yong Jiang, Pengjun Xie, Kewei Tu</li>
<li>for: 这个论文的目的是探讨pretrained Language Models（PLMs）是否拥有ontological knowledge的能力。</li>
<li>methods: 作者使用了多种方法来探讨PLMs的ontological knowledge，包括测试PLMs是否能够记忆类和属性之间的层次关系，以及使用ontological entailment rules进行逻辑推理。</li>
<li>results: 研究结果表明PLMs可以记忆一定的ontological knowledge，并且可以使用这些知识进行逻辑推理。然而，PLMs的记忆和逻辑推理性能都不完善， indicating that PLMs的ontological knowledge是部分的和不够深入的。<details>
<summary>Abstract</summary>
Ontological knowledge, which comprises classes and properties and their relationships, is integral to world knowledge. It is significant to explore whether Pretrained Language Models (PLMs) know and understand such knowledge. However, existing PLM-probing studies focus mainly on factual knowledge, lacking a systematic probing of ontological knowledge. In this paper, we focus on probing whether PLMs store ontological knowledge and have a semantic understanding of the knowledge rather than rote memorization of the surface form. To probe whether PLMs know ontological knowledge, we investigate how well PLMs memorize: (1) types of entities; (2) hierarchical relationships among classes and properties, e.g., Person is a subclass of Animal and Member of Sports Team is a subproperty of Member of ; (3) domain and range constraints of properties, e.g., the subject of Member of Sports Team should be a Person and the object should be a Sports Team. To further probe whether PLMs truly understand ontological knowledge beyond memorization, we comprehensively study whether they can reliably perform logical reasoning with given knowledge according to ontological entailment rules. Our probing results show that PLMs can memorize certain ontological knowledge and utilize implicit knowledge in reasoning. However, both the memorizing and reasoning performances are less than perfect, indicating incomplete knowledge and understanding.
</details>
<details>
<summary>摘要</summary>
ontological knowledge，包括类和属性之间的关系，对世界知识是基础性的。但是，现有的 PLM 探测研究主要集中在事实知识上，缺乏系统性的探测ontological knowledge。本文将关注 PLM 是否具备ontological knowledge，并且是否具备semantic理解这种知识，而不是只是表面上的记忆。为了探测 PLM 是否知道ontological knowledge，我们调查 PLM 是否能够记忆以下三种内容：1. 类型的实体，例如 Person 是 Animal 的 subclass。2. 类和属性之间的层次关系，例如 Member of Sports Team 是 Member of 的 subproperty。3. 属性的域和范围约束，例如 Member of Sports Team 的主题应该是 Person，而 objet 应该是 Sports Team。为了更加全面地探测 PLM 是否真正理解ontological knowledge，我们进行了系统性的逻辑推理测试，根据 ontological entailment 规则。我们的探测结果表明，PLMs 可以记忆一些ontological knowledge，并且在推理过程中可以利用隐式知识。但是，记忆和推理的性能都不完美，表明 PLMs 的知识和理解仍有限制。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/12/cs.CL_2023_09_12/" data-id="clohum95f00aupj884d3cbwuu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/36/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/35/">35</a><a class="page-number" href="/page/36/">36</a><span class="page-number current">37</span><a class="page-number" href="/page/38/">38</a><a class="page-number" href="/page/39/">39</a><span class="space">&hellip;</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/38/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
