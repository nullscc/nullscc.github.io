
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/15/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.IV_2023_10_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/16/eess.IV_2023_10_16/" class="article-date">
  <time datetime="2023-10-16T09:00:00.000Z" itemprop="datePublished">2023-10-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/16/eess.IV_2023_10_16/">eess.IV - 2023-10-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Overcoming-the-Rayleigh-limit-in-extremely-low-SNR"><a href="#Overcoming-the-Rayleigh-limit-in-extremely-low-SNR" class="headerlink" title="Overcoming the Rayleigh limit in extremely low SNR"></a>Overcoming the Rayleigh limit in extremely low SNR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10633">http://arxiv.org/abs/2310.10633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunsoo Choi, Seungman Choi, Peter Menart, Angshuman Deka, Zubin Jacob<br>for:* 这个论文的目的是开发一种新的随机子衰减图像重构算法（SSRI），以优化低信号响应率（SNR）和分辨率较低的光学成像系统。methods:* 该算法利用了常见的成像设备，使其在实际应用中易于适应。results:* 对于多种挑战性的场景，如非常低的SNR水平和较大的相对亮度比，SSRI算法表现出色，超过了已知的理德兹逊-卢西（Richardson-Lucy）减 convolution和CLEAN算法。* SSRI算法在实验图像中成功地估计了点源的位置、亮度和数量，并且在SNR水平低于1.2和子衰减范围内表现出80%-40%的成功率，位偏误在2.5像素以下。<details>
<summary>Abstract</summary>
Overcoming the diffraction limit and addressing low Signal-to-Noise Ratio (SNR) scenarios have posed significant challenges to optical imaging systems in applications such as medical diagnosis, remote sensing, and astronomical observations. In this study, we introduce a novel Stochastic Sub-Rayleigh Imaging (SSRI) algorithm capable of localizing point sources and estimating their positions, brightness, and number in low SNR conditions and within the diffraction limit. The SSRI algorithm utilizes conventional imaging devices, facilitating practical and adaptable solutions for real-world applications. Through extensive experimentation, we demonstrate that our proposed method outperforms established algorithms, such as Richardson-Lucy deconvolution and CLEAN, in various challenging scenarios, including extremely low SNR conditions and large relative brightness ratios. We achieved between 40% and 80% success rate in estimating the number of point sources in experimental images with SNR less than 1.2 and sub-Rayleigh separations, with mean position errors less than 2.5 pixels. In the same conditions, the Richardson-Lucy and CLEAN algorithms correctly estimated the number of sources between 0% and 10% of the time, with mean position errors greater than 5 pixels. Notably, SSRI consistently performs well even in the sub-Rayleigh region, offering a benchmark for assessing future quantum superresolution techniques. In conclusion, the SSRI algorithm presents a significant advance in overcoming diffraction limitations in optical imaging systems, particularly under low SNR conditions, with potential widespread impact across multiple fields like biomedical microscopy and astronomical imaging.
</details>
<details>
<summary>摘要</summary>
超过 diffraction limit 和低信号噪比 (SNR) 场景下，光学成像系统在医疗诊断、远程探测和天文观测等领域中受到了重大挑战。在这种研究中，我们介绍了一种新的 Stochastic Sub-Rayleigh Imaging（SSRI）算法，能够在低 SNR 条件下和 diffraction limit 内 Localize 点源并估计其位置、亮度和数量。SSRI 算法可以使用普通的成像设备，提供了实用和适应的解决方案。经过广泛的实验，我们证明了我们的提posed方法在各种挑战性enario中都能够超过Richardson-Lucy 混合和 CLEAN 算法，包括 extremely low SNR 条件下和大relative brightness ratio。我们在实验图像中成功地估计了40%到80%的点源数量，位置误差在2.5 pix 左右，而Richardson-Lucy 和 CLEAN 算法只能在0%到10%的时间内正确地估计点源数量，位置误差大于5 pix。特别是，SSRI 在 sub-Rayleigh 区域中表现良好，为未来 quantum superresolution 技术的评估提供了标准。综上所述，SSRI 算法在光学成像系统中超过 diffraction limit 的能力，特别是在低 SNR 条件下，具有广泛的应用前景，如生物微scopy 和天文成像。
</details></li>
</ul>
<hr>
<h2 id="NeuroQuantify-–-An-Image-Analysis-Software-for-Detection-and-Quantification-of-Neurons-and-Neurites-using-Deep-Learning"><a href="#NeuroQuantify-–-An-Image-Analysis-Software-for-Detection-and-Quantification-of-Neurons-and-Neurites-using-Deep-Learning" class="headerlink" title="NeuroQuantify – An Image Analysis Software for Detection and Quantification of Neurons and Neurites using Deep Learning"></a>NeuroQuantify – An Image Analysis Software for Detection and Quantification of Neurons and Neurites using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10978">http://arxiv.org/abs/2310.10978</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/StanleyZ0528/neural-image-segmentation">https://github.com/StanleyZ0528/neural-image-segmentation</a></li>
<li>paper_authors: Ka My Dang, Yi Jia Zhang, Tianchen Zhang, Chao Wang, Anton Sinner, Piero Coronica, Joyce K. S. Poon</li>
<li>for: 研究neuronal networks的发展和neuron growth的量化信息</li>
<li>methods: 使用深度学习自动分类 cells和neurites</li>
<li>results: 可以快速和高效地分类 cells和neurites，并提供neurite length和orientation的量化信息<details>
<summary>Abstract</summary>
The segmentation of cells and neurites in microscopy images of neuronal networks provides valuable quantitative information about neuron growth and neuronal differentiation, including the number of cells, neurites, neurite length and neurite orientation. This information is essential for assessing the development of neuronal networks in response to extracellular stimuli, which is useful for studying neuronal structures, for example, the study of neurodegenerative diseases and pharmaceuticals. However, automatic and accurate analysis of neuronal structures from phase contrast images has remained challenging. To address this, we have developed NeuroQuantify, an open-source software that uses deep learning to efficiently and quickly segment cells and neurites in phase contrast microscopy images. NeuroQuantify offers several key features: (i) automatic detection of cells and neurites; (ii) post-processing of the images for the quantitative neurite length measurement based on segmentation of phase contrast microscopy images, and (iii) identification of neurite orientations. The user-friendly NeuroQuantify software can be installed and freely downloaded from GitHub https://github.com/StanleyZ0528/neural-image-segmentation.
</details>
<details>
<summary>摘要</summary>
segmenation of cells and neurites in microscopy images of neuronal networks provides valuable quantitative information about neuron growth and neuronal differentiation, including the number of cells, neurites, neurite length and neurite orientation. This information is essential for assessing the development of neuronal networks in response to extracellular stimuli, which is useful for studying neuronal structures, for example, the study of neurodegenerative diseases and pharmaceuticals. However, automatic and accurate analysis of neuronal structures from phase contrast images has remained challenging. To address this, we have developed NeuroQuantify, an open-source software that uses deep learning to efficiently and quickly segment cells and neurites in phase contrast microscopy images. NeuroQuantify offers several key features: (i) automatic detection of cells and neurites; (ii) post-processing of the images for the quantitative neurite length measurement based on segmentation of phase contrast microscopy images, and (iii) identification of neurite orientations. The user-friendly NeuroQuantify software can be installed and freely downloaded from GitHub https://github.com/StanleyZ0528/neural-image-segmentation.Here's the word-for-word translation of the text into Simplified Chinese: cells 和 neurites 的分 segmentation 在 neuronal networks 的 microscopy 图像中提供了有价值的量化信息，包括细胞数量、辐化长度、辐化方向等。这些信息对于研究 neuronal networks 的发展响应 extracellular stimuli 非常重要，这些信息可以用于研究 neuronal structures，例如研究 neuodegenerative diseases 和 pharmaceuticals。然而，从 phase contrast 图像中自动和准确地分析 neuronal structures 一直是一个挑战。为解决这个问题，我们已经开发了 NeuroQuantify，一个开源的软件，使用深度学习来快速和高效地分 segmentation 细胞和 neurites 在 phase contrast microscopy 图像中。NeuroQuantify 提供了多个关键特性： (i) 自动检测细胞和辐化； (ii) 根据 segmentation 的图像进行后处理，以获取辐化长度的量化测量；以及 (iii) 辐化方向的识别。用户友好的 NeuroQuantify 软件可以在 GitHub 上免费下载 https://github.com/StanleyZ0528/neural-image-segmentation。
</details></li>
</ul>
<hr>
<h2 id="Impact-of-Data-Synthesis-Strategies-for-the-Classification-of-Craniosynostosis"><a href="#Impact-of-Data-Synthesis-Strategies-for-the-Classification-of-Craniosynostosis" class="headerlink" title="Impact of Data Synthesis Strategies for the Classification of Craniosynostosis"></a>Impact of Data Synthesis Strategies for the Classification of Craniosynostosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10199">http://arxiv.org/abs/2310.10199</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kit-ibt/craniosource-gan-pca-ssm">https://github.com/kit-ibt/craniosource-gan-pca-ssm</a></li>
<li>paper_authors: Matthias Schaufelberger, Reinald Peter Kühle, Andreas Wachter, Frederic Weichel, Niclas Hagen, Friedemann Ringwald, Urs Eisenmann, Jürgen Hoffmann, Michael Engel, Christian Freudlsperger, Werner Nahm</li>
<li>for: 用于评估和分类颅部凹陷症。</li>
<li>methods: 使用三种不同的人工数据源：统计学形态模型（SSM）、生成敌对网络（GAN）和图像基本主成分分析，为一种基于 convolutional neural network（CNN）的颅部凹陷症分类。CNN 只在人工数据上训练，但 Validate 和测试在临床数据上。</li>
<li>results: 组合 SSM 和 GAN 达到了高于 0.96 的准确率和高于 0.95 的 F1 分数在未看到的测试集上。与训练在临床数据上的差异小于 0.01。包括第二个图像模式可以提高分类性能。So the three key points are:1. The paper is written to assess and classify craniosynostosis using photogrammetric surface scans.2. The methods used include three different synthetic data sources: a statistical shape model, a generative adversarial network, and image-based principal component analysis.3. The results show that a combination of these synthetic data sources can achieve high accuracy and F1 score (over 0.95 and 0.96 respectively) on unseen test sets, with little difference between training on synthetic data and clinical data.<details>
<summary>Abstract</summary>
Introduction: Photogrammetric surface scans provide a radiation-free option to assess and classify craniosynostosis. Due to the low prevalence of craniosynostosis and high patient restrictions, clinical data is rare. Synthetic data could support or even replace clinical data for the classification of craniosynostosis, but this has never been studied systematically. Methods: We test the combinations of three different synthetic data sources: a statistical shape model (SSM), a generative adversarial network (GAN), and image-based principal component analysis for a convolutional neural network (CNN)-based classification of craniosynostosis. The CNN is trained only on synthetic data, but validated and tested on clinical data. Results: The combination of a SSM and a GAN achieved an accuracy of more than 0.96 and a F1-score of more than 0.95 on the unseen test set. The difference to training on clinical data was smaller than 0.01. Including a second image modality improved classification performance for all data sources. Conclusion: Without a single clinical training sample, a CNN was able to classify head deformities as accurate as if it was trained on clinical data. Using multiple data sources was key for a good classification based on synthetic data alone. Synthetic data might play an important future role in the assessment of craniosynostosis.
</details>
<details>
<summary>摘要</summary>
方法：我们测试了三种不同的生成数据源：统计学形态模型（SSM）、生成对抗网络（GAN）和图像基于主成分分析（PCA），用于基于 convolutional neural network（CNN）的颅部缺陷分类。CNN只在生成数据上训练，但VALIDATE和测试在临床数据上进行验证。结果：SSM和GAN的组合实现了在未看到的测试集上的准确率高于0.96和F1分数高于0.95。与训练在临床数据上的差异小于0.01。包括第二个图像特征提高了所有数据源的分类性能。结论：没有任何临床训练样本，CNN仍可以准确地将头形缺陷分类为临床数据。使用多种数据源是针对synthetic数据alone的分类的关键。synthetic数据可能在未来对颅部缺陷的评估中扮演一个重要的角色。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/16/eess.IV_2023_10_16/" data-id="clontc8ru016y8788hlyzhrqw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_10_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/16/eess.SP_2023_10_16/" class="article-date">
  <time datetime="2023-10-16T08:00:00.000Z" itemprop="datePublished">2023-10-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/16/eess.SP_2023_10_16/">eess.SP - 2023-10-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Rapid-Non-cartesian-Reconstruction-Using-an-Implicit-Representation-of-GROG-Kernels"><a href="#Rapid-Non-cartesian-Reconstruction-Using-an-Implicit-Representation-of-GROG-Kernels" class="headerlink" title="Rapid Non-cartesian Reconstruction Using an Implicit Representation of GROG Kernels"></a>Rapid Non-cartesian Reconstruction Using an Implicit Representation of GROG Kernels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10823">http://arxiv.org/abs/2310.10823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Abraham, Mark Nishimura, Xiaozhi Cao, Congyu Liao, Kawin Setsompop</li>
<li>for: 提高MR图像成像的速度和效率，使非 carteesian sampling更广泛应用</li>
<li>methods: 使用iGROG方法将非 carteesian数据转换为cartesian数据，以便更加简单和快速地进行重建</li>
<li>results: 提高了MR图像成像的速度和效率，并且可以更好地抵消运动 artifacts<details>
<summary>Abstract</summary>
MRI data is acquired in Fourier space. Data acquisition is typically performed on a Cartesian grid in this space to enable the use of a fast Fourier transform algorithm to achieve fast and efficient reconstruction. However, it has been shown that for multiple applications, non-Cartesian data acquisition can improve the performance of MR imaging by providing fast and more efficient data acquisition, and improving motion robustness. Nonetheless, the image reconstruction process of non-Cartesian data is more involved and can be time-consuming, even through the use of efficient algorithms such as non-uniform FFT (NUFFT). This work provides an efficient approach (iGROG) to transform the non-Cartesian data into Cartesian data, to achieve simpler and faster reconstruction which should help enable non-Cartesian data sampling to be performed more widely in MRI.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Constant-Modulus-Waveform-Design-with-Block-Level-Interference-Exploitation-for-DFRC-Systems"><a href="#Constant-Modulus-Waveform-Design-with-Block-Level-Interference-Exploitation-for-DFRC-Systems" class="headerlink" title="Constant Modulus Waveform Design with Block-Level Interference Exploitation for DFRC Systems"></a>Constant Modulus Waveform Design with Block-Level Interference Exploitation for DFRC Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10804">http://arxiv.org/abs/2310.10804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Byunghyun Lee, Anindya Bijoy Das, David J. Love, Christopher G. Brinton, James V. Krogmeier</li>
<li>for: 这篇论文旨在设计具有双 функ数 radar-通信（DFRC）系统的常数模ulus波形。</li>
<li>methods: 本文使用了相互干扰基于封页水平 precoding（CI-BLP）来利用多用户和雷达传输所带来的歪曲。我们还提出了一个基于主要化-最小化（MM）的解决方案，并使用了一个改进的主要化函数，充分利用了一个新的 діагональ矩阵结构。</li>
<li>results: 透过严谨的 simulations，我们证明了提案的方法和主要化函数的效果。<details>
<summary>Abstract</summary>
Dual-functional radar-communication (DFRC) is a promising technology where radar and communication functions operate on the same spectrum and hardware. In this paper, we propose an algorithm for designing constant modulus waveforms for DFRC systems. Particularly, we jointly optimize the correlation properties and the spatial beam pattern. For communication, we employ constructive interference-based block-level precoding (CI-BLP) to exploit distortion due to multi-user and radar transmission. We propose a majorization-minimization (MM)-based solution to the formulated problem. To accelerate convergence, we propose an improved majorizing function that leverages a novel diagonal matrix structure. We then evaluate the performance of the proposed algorithm through rigorous simulations. Simulation results demonstrate the effectiveness of the proposed approach and the proposed majorizer.
</details>
<details>
<summary>摘要</summary>
双功能雷达通信（DFRC）技术是一种有前途的技术，雷达和通信功能都运行在同一频谱和硬件上。在这篇论文中，我们提出了一种常数模式波形设计算法，特别是同时优化相关性和空间扫描方式。在通信方面，我们使用基于构建性干扰的块级预编码（CI-BLP）来利用多用户和雷达传输所导致的扭曲。我们提出了一种基于主要化-最小化（MM）的解决方案，并提出了一种改进的主要化函数，利用了一个新的对角矩阵结构。然后，我们通过严格的仿真测试评估了提案的性能和提案的主要化函数。Here's the text with some additional information about the Simplified Chinese translation:Simplified Chinese is a written form of Chinese that uses simpler characters and grammar than Traditional Chinese. It is commonly used in mainland China and Singapore.In this translation, I have used Simplified Chinese characters and grammar to translate the text. However, I have kept the original English sentence structure and phrasing to ensure that the meaning of the text is preserved.Note that some technical terms and jargon may have different translations in Simplified Chinese, depending on the context and the specific field of study. However, I have tried my best to provide an accurate and natural-sounding translation based on my knowledge of Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Neuromorphic-Place-Cells"><a href="#Neuromorphic-Place-Cells" class="headerlink" title="Neuromorphic Place Cells"></a>Neuromorphic Place Cells</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10790">http://arxiv.org/abs/2310.10790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoqi Chen, Ralph Etienne-Cummings</li>
<li>for: 这个脑机模型系统可能比传统系统更加高效实现。</li>
<li>methods: 我们实现了混合模式的空间编码神经元，包括theta细胞、vector细胞和place细胞。这些神经元组成了生物学可能的网络，可以重produce地方Cells的localization功能。</li>
<li>results: 我们的模型在Analog Circuit变化时的Robustness得到了实验 validate。我们提供了动态脑机SLAM系统的实现基础和生物学形成空间细胞的灵感。<details>
<summary>Abstract</summary>
A neuromorphic SLAM system shows potential for more efficient implementation than its traditional counterpart. We demonstrate a mixed-mode implementation for spatial encoding neurons including theta cells, vector cells and place cells. Together, they form a biologically plausible network that could reproduce the localization functionality of place cells. Experimental results validate the robustness of our model when suffering from variations of analog circuits. We provide a foundation for implementing dynamic neuromorphic SLAM systems and inspirations for the formation of spatial cells in biology.
</details>
<details>
<summary>摘要</summary>
一种神经模拟SLAM系统显示了更高效的实现可能性，相比传统系统。我们实现了混合模式的空间编码神经元，包括theta细胞、向量细胞和位置细胞。这些神经元共同组成了生物学上可能的网络，可以重现位置细胞的地方化功能。实验结果证明我们的模型在 анаóg逻circuit变化时的稳定性。我们提供了神经模拟SLAM系统的实现基础和生物学形成空间细胞的灵感。Note: "Simplified Chinese" is also known as "Mandarin Chinese" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="Indoor-Wireless-Signal-Modeling-with-Smooth-Surface-Diffraction-Effects"><a href="#Indoor-Wireless-Signal-Modeling-with-Smooth-Surface-Diffraction-Effects" class="headerlink" title="Indoor Wireless Signal Modeling with Smooth Surface Diffraction Effects"></a>Indoor Wireless Signal Modeling with Smooth Surface Diffraction Effects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10578">http://arxiv.org/abs/2310.10578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruichen Wang, Samuel Audia, Dinesh Manocha</li>
<li>for: 提高室内电磁场模拟的准确性，包括表面散射的影响</li>
<li>methods: 使用统一几何理论 Of Diffraction (UTD) 表面散射，并提出了精炼表面 UTD 和高效计算射线路的技术</li>
<li>results: 提高阴影区预测功率约 5dB，并能够捕捉到阴影区之外的复杂场效应，并且在不同室内场景下表现出60%更快的计算速度。<details>
<summary>Abstract</summary>
We present a novel algorithm that enhances the accuracy of electromagnetic field simulations in indoor environments by incorporating the Uniform Geometrical Theory of Diffraction (UTD) for surface diffraction. This additional diffraction phenomenology is important for the design of modern wireless systems and allows us to capture the effects of more complex scene geometries. Central to our methodology is the Dynamic Coherence-Based EM Ray Tracing Simulator (DCEM), and we augment that formulation with smooth surface UTD and present techniques to efficiently compute the ray paths. We validate our additions by comparing them to analytical solutions of a sphere, method of moments solutions from FEKO, and ray-traced indoor scenes from WinProp. Our algorithm improves shadow region predicted powers by about 5dB compared to our previous work, and captures nuanced field effects beyond shadow boundaries. We highlight the performance on different indoor scenes and observe 60% faster computation time over WinProp.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的算法，用于提高室内电磁场 simulations 的准确性，通过包含表面折射理论（UTD）的各向异性折射现象。这种额外的折射现象对现代无线系统设计非常重要，允许我们捕捉更复杂的场景几何。我们的方法中心是动态几何相关性基于EM射线追踪模拟器（DCEM），并在该形式ulation中添加了光滑表面UTD。我们还提供了有效计算射线路的技术。我们的添加与 Analytical solutions of a sphere、method of moments solutions from FEKO和WinProp的射线追踪场景进行比较。我们的算法可以在不同的室内场景中提高阴影区域预测功率约5dB，并捕捉到场效应 beyond shadow boundaries。我们还证明了我们的算法在不同的室内场景中的性能，并发现其计算时间比WinProp快60%。
</details></li>
</ul>
<hr>
<h2 id="Applications-of-Distributed-Machine-Learning-for-the-Internet-of-Things-A-Comprehensive-Survey"><a href="#Applications-of-Distributed-Machine-Learning-for-the-Internet-of-Things-A-Comprehensive-Survey" class="headerlink" title="Applications of Distributed Machine Learning for the Internet-of-Things: A Comprehensive Survey"></a>Applications of Distributed Machine Learning for the Internet-of-Things: A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10549">http://arxiv.org/abs/2310.10549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mai Le, Thien Huynh-The, Tan Do-Duy, Thai-Hoc Vu, Won-Joo Hwang, Quoc-Viet Pham</li>
<li>for: 提高 emerging 无线网络（如 beyond 5G 和 6G）中的服务和应用程序的质量，通过在互联网物联网（IoT）中使用人工智能（AI）。</li>
<li>methods: 分布式机器学习（distributed learning）方法，包括联邦学习、多代理奖励学习和分布式推理。</li>
<li>results: 对 IoT 服务和应用程序的重要提高，包括数据共享和计算卸载、定位、移动 Crowdsensing 和安全隐私。<details>
<summary>Abstract</summary>
The emergence of new services and applications in emerging wireless networks (e.g., beyond 5G and 6G) has shown a growing demand for the usage of artificial intelligence (AI) in the Internet of Things (IoT). However, the proliferation of massive IoT connections and the availability of computing resources distributed across future IoT systems have strongly demanded the development of distributed AI for better IoT services and applications. Therefore, existing AI-enabled IoT systems can be enhanced by implementing distributed machine learning (aka distributed learning) approaches. This work aims to provide a comprehensive survey on distributed learning for IoT services and applications in emerging networks. In particular, we first provide a background of machine learning and present a preliminary to typical distributed learning approaches, such as federated learning, multi-agent reinforcement learning, and distributed inference. Then, we provide an extensive review of distributed learning for critical IoT services (e.g., data sharing and computation offloading, localization, mobile crowdsensing, and security and privacy) and IoT applications (e.g., smart healthcare, smart grid, autonomous vehicle, aerial IoT networks, and smart industry). From the reviewed literature, we also present critical challenges of distributed learning for IoT and propose several promising solutions and research directions in this emerging area.
</details>
<details>
<summary>摘要</summary>
随着新的服务和应用程序在 развивающихся无线网络（例如 beyond 5G 和 6G）的出现，人们对艺ificial intelligence（AI）在互联网物联网（IoT）中的使用的需求在增加。然而，质量的巨大 IoT 连接和未来 IoT 系统中的计算资源的分布强烈要求开发分布式 AI，以提供更好的 IoT 服务和应用程序。因此，现有的 AI 启用 IoT 系统可以通过实施分布式机器学习（分布式学习）方法进行增强。本工作的目的是为提供分布式学习在 IoT 服务和应用程序方面的全面的评价。特别是，我们首先提供机器学习的背景，然后介绍一些常见的分布式学习方法，如联合学习、多代理人奖励学习和分布式推理。然后，我们对分布式学习在关键的 IoT 服务（例如数据分享和计算卸载、位置定位、移动 Crowdsensing 和安全隐私）和 IoT 应用程序（例如智能医疗、智能电网、自动驾驶、空中 IoT 网络和智能工业）进行了广泛的评审。从 Literature 中，我们还提出了分布式学习在 IoT 中的主要挑战和一些可能的解决方案和研究方向。
</details></li>
</ul>
<hr>
<h2 id="A-Tutorial-on-Chirp-Spread-Spectrum-for-LoRaWAN-Basics-and-Key-Advances"><a href="#A-Tutorial-on-Chirp-Spread-Spectrum-for-LoRaWAN-Basics-and-Key-Advances" class="headerlink" title="A Tutorial on Chirp Spread Spectrum for LoRaWAN: Basics and Key Advances"></a>A Tutorial on Chirp Spread Spectrum for LoRaWAN: Basics and Key Advances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10503">http://arxiv.org/abs/2310.10503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alireza Maleki, Ha H. Nguyen, Ebrahim Bedeer, Robert Barton</li>
<li>for: 本研究旨在提供一个全面的CSS模ulation在LoRaWAN应用中的教程，包括信号生成、检测、错误性表现和频率特性等方面的分析。</li>
<li>methods: 本研究使用了LoRa特有的CSS模ulation，并对其在IoT网络中的应用进行了深入的检查和分析。</li>
<li>results: 研究发现CSS模ulation在LoRaWAN应用中具有优秀的错误性和spectral caracteristics，并提出了一些适用于IoT网络的CSS模ulation应用的新技术和算法。<details>
<summary>Abstract</summary>
Chirps spread spectrum (CSS) modulation is the heart of long-range (LoRa) modulation used in the context of long-range wide area network (LoRaWAN) in internet of things (IoT) scenarios. Despite being a proprietary technology owned by Semtech Corp., LoRa modulation has drawn much attention from the research and industry communities in recent years. However, to the best of our knowledge, a comprehensive tutorial, investigating the CSS modulation in the LoRaWAN application, is missing in the literature. Therefore, in the first part of this paper, we provide a thorough analysis and tutorial of CSS modulation modified by LoRa specifications, discussing various aspects such as signal generation, detection, error performance, and spectral characteristics. Moreover, a summary of key recent advances in the context of CSS modulation applications in IoT networks is presented in the second part of this paper under four main categories of transceiver configuration and design, data rate improvement, interference modeling, and synchronization algorithms.
</details>
<details>
<summary>摘要</summary>
射频扩散模ulation (CSS) 是LoRa射频模ulation的核心，用于长距离宽频网络（LoRaWAN）应用场景中的物联网（IoT）。尽管LoRa模ulation是Semtech Corp.拥有的专有技术，但在过去几年中，研究和业界社区对其吸引了很多关注。然而，根据我们所知，Literature中没有一篇全面的教程，探讨CSS模ulation在LoRaWAN应用中的各个方面，包括信号生成、检测、错误性能和频谱特性。因此，在本文的第一部分中，我们提供了CSS模ulation在LoRaWAN应用中的全面分析和教程，讨论了各种方面。此外，在文章的第二部分中，我们还提供了针对CSS模ulation在IoT网络应用中的四个主要类别的扩散配置和设计、数据速率改进、干扰模型和同步算法的最新进展。
</details></li>
</ul>
<hr>
<h2 id="Performance-Analysis-of-a-Low-Complexity-OTFS-Integrated-Sensing-and-Communication-System"><a href="#Performance-Analysis-of-a-Low-Complexity-OTFS-Integrated-Sensing-and-Communication-System" class="headerlink" title="Performance Analysis of a Low-Complexity OTFS Integrated Sensing and Communication System"></a>Performance Analysis of a Low-Complexity OTFS Integrated Sensing and Communication System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10476">http://arxiv.org/abs/2310.10476</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tommaso Bacchielli, Lorenzo Pucci, Enrico Paolini, Andrea Giorgetti</li>
<li>for: 该论文提出了一种低复杂度估计方法，用于 ortfs 基于集成感知通信（isac）系统。</li>
<li>methods: 我们首先定义了四个低维度矩阵，用于计算通道矩阵通过简单的代数手动操作。然后，我们建立了一个独立系统参数的分析标准，用于 Identify the most informative elements within these derived matrices，利用 Dirichlet kernel 的性质。这使得我们可以简化这些矩阵，保留只有关键的元素，从而实现高效、低复杂度的感知接收器。</li>
<li>results: 数字结果表明，提出的近似技术可以高效地保持感知性能， measured in terms of root mean square error (RMSE) of the range and velocity estimation， 同时减少计算努力 enormously。<details>
<summary>Abstract</summary>
This work proposes a low-complexity estimation approach for an orthogonal time frequency space (OTFS)-based integrated sensing and communication (ISAC) system. In particular, we first define four low-dimensional matrices used to compute the channel matrix through simple algebraic manipulations. Secondly, we establish an analytical criterion, independent of system parameters, to identify the most informative elements within these derived matrices, leveraging the properties of the Dirichlet kernel. This allows the distilling of such matrices, keeping only those entries that are essential for detection, resulting in an efficient, low-complexity implementation of the sensing receiver. Numerical results, which refer to a vehicular scenario, demonstrate that the proposed approximation technique effectively preserves the sensing performance, evaluated in terms of root mean square error (RMSE) of the range and velocity estimation, while concurrently reducing the computational effort enormously.
</details>
<details>
<summary>摘要</summary>
Note: The text has been translated into Simplified Chinese, which is the standard writing system used in mainland China. The traditional Chinese writing system is also widely used, especially in Taiwan and Hong Kong. If you prefer the traditional Chinese writing system, please let me know and I can provide the translation accordingly.
</details></li>
</ul>
<hr>
<h2 id="Flag-Sequence-Set-Design-for-Low-Complexity-Delay-Doppler-Estimation"><a href="#Flag-Sequence-Set-Design-for-Low-Complexity-Delay-Doppler-Estimation" class="headerlink" title="Flag Sequence Set Design for Low-Complexity Delay-Doppler Estimation"></a>Flag Sequence Set Design for Low-Complexity Delay-Doppler Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10457">http://arxiv.org/abs/2310.10457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingsheng Meng, Yong Liang Guan, Yao Ge, Zilong Liu</li>
<li>for: 该 paper 探讨了用 Flag 序列实现低复杂度延迟-多普勒估计，通过利用 Flag 序列的特殊峰柜ambiguity函数（AF）。不同于现有的 Flag 序列设计，我们的设计不受 prime 长度和 periodic auto-AF 的限制，而是设计了 Flag 序列集合的任意长度和低（非极） periodic&#x2F;aperiodic auto-和cross-AF。</li>
<li>methods: 我们首先investigated Zone-based Curtain sequence sets of arbitrary lengths的代数设计。我们的提议的设计导致了新的 Curtain sequence sets，其具有理想的毯幕自动ambiguity函数（AF）和低&#x2F;zero cross-AF在延迟-多普勒频率范围内。使用这些 Curtain sequence sets，我们提出了两个优化问题，以最小化 Flag sequence set的总成本weighted integrated sidelobe level（SCWISL）。我们还提出了一种加速Parallel Partially Majorization-Minimization Algorithm，用于同时优化发射 Flag sequence和与其匹配&#x2F;不匹配的参照序列。</li>
<li>results: 我们的实验结果表明，我们的提议 Flag sequences 比现有 Flag sequences 具有更好的 SCWISL 和自定义峰-侧噪比。此外，我们的 Flag sequences under Flag method 的 Mean Squared Errors 逐渐接近 Cramer-Rao Lower Bound 和 Sampling Bound，当信号噪声比高 enough 时。<details>
<summary>Abstract</summary>
This paper studies Flag sequences for lowcomplexity delay-Doppler estimation by exploiting their distinctive peak-curtain ambiguity functions (AFs). Unlike the existing Flag sequence designs that are limited to prime lengths and periodic auto-AFs, we aim to design Flag sequence sets of arbitrary lengths and with low (nontrivial) periodic/aperiodic auto- and cross-AFs. Since every Flag sequence consists of a Curtain sequence and a Peak sequence, we first investigate the algebraic design of zone-based Curtain sequence sets of arbitrary lengths. Our proposed design gives rise to novel Curtain sequence sets with ideal curtain auto-AFs and low/zero cross-AFs within the delay-Doppler zone of interest. Leveraging these Curtain sequence sets, two optimization problems are formulated to minimize the summed customized weighted integrated sidelobe level (SCWISL) of the Flag sequence set. Accelerated Parallel Partially Majorization-Minimization Algorithms are proposed to jointly optimize the transmit Flag sequences and matched/mismatched reference sequences stored in the receiver. Simulations demonstrate that our proposed Flag sequences lead to improved SCWISL and customized peak-to-max-sidelobe ratio compared with the existing Flag sequences. Additionally, our Flag sequences under Flag method exhibit Mean Squared Errors that approach the Cramer-Rao Lower Bound and the Sampling Bound at high signal-to-noise power ratios.
</details>
<details>
<summary>摘要</summary>
Since every Flag sequence consists of a Curtain sequence and a Peak sequence, we first investigate the algebraic design of zone-based Curtain sequence sets of arbitrary lengths. Our proposed design yields novel Curtain sequence sets with ideal curtain auto-AFs and low/zero cross-AFs within the delay-Doppler zone of interest.Leveraging these Curtain sequence sets, two optimization problems are formulated to minimize the summed customized weighted integrated sidelobe level (SCWISL) of the Flag sequence set. Accelerated Parallel Partially Majorization-Minimization Algorithms are proposed to jointly optimize the transmit Flag sequences and matched/mismatched reference sequences stored in the receiver.Simulations show that our proposed Flag sequences lead to improved SCWISL and customized peak-to-max-sidelobe ratio compared with existing Flag sequences. Additionally, our Flag sequences under the Flag method exhibit Mean Squared Errors that approach the Cramer-Rao Lower Bound and the Sampling Bound at high signal-to-noise power ratios.
</details></li>
</ul>
<hr>
<h2 id="Soft-Demodulator-for-Symbol-Level-Precoding-in-Coded-Multiuser-MISO-Systems"><a href="#Soft-Demodulator-for-Symbol-Level-Precoding-in-Coded-Multiuser-MISO-Systems" class="headerlink" title="Soft Demodulator for Symbol-Level Precoding in Coded Multiuser MISO Systems"></a>Soft Demodulator for Symbol-Level Precoding in Coded Multiuser MISO Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10296">http://arxiv.org/abs/2310.10296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yafei Wang, Hongwei Hou, Wenjin Wang, Xinping Yi, Shi Jin</li>
<li>for: 本文研究了Symbol-level precoding (SLP)在channel-coded多用户多输入单输出（MISO）系统中的应用。</li>
<li>methods: 本文提出了一种新的软解调器设计方法，用于处理不符合 Gaussian 分布的 SLP 信号。</li>
<li>results: 实验结果表明，提议的软解调器可以减少现有 SLP 系统的通信 overhead 和计算复杂度，同时提高了传输率。<details>
<summary>Abstract</summary>
In this paper, we consider symbol-level precoding (SLP) in channel-coded multiuser multi-input single-output (MISO) systems. It is observed that the received SLP signals do not always follow Gaussian distribution, rendering the conventional soft demodulation with the Gaussian assumption unsuitable for the coded SLP systems. It, therefore, calls for novel soft demodulator designs for non-Gaussian distributed SLP signals with accurate log-likelihood ratio (LLR) calculation. To this end, we first investigate the non-Gaussian characteristics of both phase-shift keying (PSK) and quadrature amplitude modulation (QAM) received signals with existing SLP schemes and categorize the signals into two distinct types. The first type exhibits an approximate-Gaussian distribution with the outliers extending along the constructive interference region (CIR). In contrast, the second type follows some distribution that significantly deviates from the Gaussian distribution. To obtain accurate LLR, we propose the modified Gaussian soft demodulator and Gaussian mixture model (GMM) soft demodulators to deal with two types of signals respectively. Subsequently, to further reduce the computational complexity and pilot overhead, we put forward a novel neural soft demodulator, named pilot feature extraction network (PFEN), leveraging the transformer mechanism in deep learning. Simulation results show that the proposed soft demodulators dramatically improve the throughput of existing SLPs for both PSK and QAM transmission in coded systems.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们考虑了符号级precoding（SLP）在多用户多输入单出力（MISO）系统中。我们发现接收的SLP信号不总是follow Gaussian分布，这使得传统的软模解器不适用于编码SLP系统。因此，我们需要设计新的软模解器，以便在非Gaussian分布下计算准确的log-likelihood ratio（LLR）。为此，我们首先研究了现有SLP方案中PSK和QAM接收信号的非Gaussian特征，并将信号分类为两种类型。第一种类型表现出近似Gaussian分布，其异常点分布在构建性干扰区（CIR）上。然而，第二种类型的信号具有显著不同于Gaussian分布的特征。为了获得准确的LLR，我们提议使用修改后Gaussian软模解器和Gaussian混合模型（GMM）软模解器来处理这两种信号。然后，为了进一步减少计算复杂性和导航点负担，我们提出了一种新的神经软模解器，即预测特征提取网络（PFEN），利用深度学习中的转换机制。实验结果表明，我们提出的软模解器可以很大程度提高现有SLP的传输能力。
</details></li>
</ul>
<hr>
<h2 id="A-Low-Complexity-Block-oriented-Functional-Link-Adaptive-Filtering-Algorithm"><a href="#A-Low-Complexity-Block-oriented-Functional-Link-Adaptive-Filtering-Algorithm" class="headerlink" title="A Low Complexity Block-oriented Functional Link Adaptive Filtering Algorithm"></a>A Low Complexity Block-oriented Functional Link Adaptive Filtering Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10276">http://arxiv.org/abs/2310.10276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pavankumar Ganjimala, Subrahmanyam Mula</li>
<li>for: 模型无线非线性系统</li>
<li>methods: 使用块归一化功能链适应 Filter (BO-FLAF) 和 Hammersen BO trigonometric FLAF (HBO-TFLAF)</li>
<li>results: 对比原始 TFLAF，HBO-TFLAF 具有47%  fewer multiplications，并且 exhibits 更快的 convergence rate 和 3-5 dB 更好的稳态平均方差 (MSE) 表现。<details>
<summary>Abstract</summary>
The high computation complexity of nonlinear adaptive filtering algorithms poses significant challenges at the hardware implementation level. In order to tackle the computational complexity problem, this paper proposes a novel block-oriented functional link adaptive filter (BO-FLAF) to model memoryless nonlinear systems. Through theoretical complexity analysis, we show that the proposed Hammerstein BO trigonometric FLAF (HBO-TFLAF) has 47% lesser multiplications than the original TFLAF for a filter order of 1024. Moreover, the HBO-TFLAF exhibits a faster convergence rate and achieved 3-5 dB lesser steady-state mean square error (MSE) compared to the original TFLAF for a memoryless nonlinear system identification task.
</details>
<details>
<summary>摘要</summary>
高度计算复杂性的非线性适应滤波算法在硬件实现方面带来了重要的挑战。为了解决计算复杂性问题，这篇论文提议了一种新的块 oriented 函数链适应滤波器（BO-FLAF），用于模型无记忆非线性系统。通过理论复杂性分析，我们表明了提案的汽olinski BO  trigonometric FLAF（HBO-TFLAF）在缓存大小为 1024 的情况下，相比原始 TFLAF 减少了 47% 的 multiply 操作数。此外，HBO-TFLAF 还表现出更快的收敛速率和对非线性系统识别任务中的稳态平均幂二分量（MSE）减少了 3-5 dB。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-MTC-User-Activity-Detection-and-Channel-Estimation-with-Unknown-Spatial-Covariance"><a href="#Hierarchical-MTC-User-Activity-Detection-and-Channel-Estimation-with-Unknown-Spatial-Covariance" class="headerlink" title="Hierarchical MTC User Activity Detection and Channel Estimation with Unknown Spatial Covariance"></a>Hierarchical MTC User Activity Detection and Channel Estimation with Unknown Spatial Covariance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10204">http://arxiv.org/abs/2310.10204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamza Djelouat, Mikko J. Sillanpää, Markus Leinonen, Markku Juntti</li>
<li>for: 这篇论文解决了机器型通信中的共同用户标识和通道估计（JUICE）问题，采用实际的空间相关通道模型和未知 covariance 矩阵。</li>
<li>methods: 作者首先利用了强级先验的概念，并提出了层次稀突减模矩阵来模型结构化稀突活动模式。然后，他们 derivated了一种 bayesian 推理方案，将 expectation propagation（EP）算法和 expectation maximization（EM）框架结合起来。</li>
<li>results: 作者通过对 JUICE 问题进行最大 posteriori（MAP）估计，并提出了一种基于 alternating direction method of multipliers（ADMM）的计算效率高的解决方案。数据结果表明，提出的算法具有显著性能提升和具有不同用户稀突活动行为假设的Robustness。<details>
<summary>Abstract</summary>
This paper addresses the joint user identification and channel estimation (JUICE) problem in machine-type communications under the practical spatially correlated channels model with unknown covariance matrices. Furthermore, we consider an MTC network with hierarchical user activity patterns following an event-triggered traffic mode. Therein the users are distributed over clusters with a structured sporadic activity behaviour that exhibits both cluster-level and intra-cluster sparsity patterns. To solve the JUICE problem, we first leverage the concept of strong priors and propose a hierarchical-sparsity-inducing spike-and-slab prior to model the structured sparse activity pattern. Subsequently, we derive a Bayesian inference scheme by coupling the expectation propagation (EP) algorithm with the expectation maximization (EM) framework. Second, we reformulate the JUICE as a maximum a posteriori (MAP) estimation problem and propose a computationally-efficient solution based on the alternating direction method of multipliers (ADMM). More precisely, we relax the strong spike-and-slab prior with a cluster-sparsity-promoting prior based on the long-sum penalty. We then derive an ADMM algorithm that solves the MAP problem through a sequence of closed-form updates. Numerical results highlight the significant performance significant gains obtained by the proposed algorithms, as well as their robustness against various assumptions on the users sparse activity behaviour.
</details>
<details>
<summary>摘要</summary>
Second, we reformulate the JUICE as a maximum a posteriori (MAP) estimation problem and propose a computationally-efficient solution based on the alternating direction method of multipliers (ADMM). More precisely, we relax the strong spike-and-slab prior with a cluster-sparsity-promoting prior based on the long-sum penalty. We then derive an ADMM algorithm that solves the MAP problem through a sequence of closed-form updates. Numerical results highlight the significant performance gains obtained by the proposed algorithms, as well as their robustness against various assumptions on the users' sparse activity behavior.Translated into Simplified Chinese:这篇论文研究了机器类通信中的用户标识和通道估计（JUICE）问题，在实际的空间相关的通道模型下，并且假设用户活动模式遵循事件触发的交通模式。用户被分布在归一化的集群中，并且表现出了结构化零散的活动模式，这种模式包括集群水平和内部零散的特征。为解决JUICE问题，我们首先利用强级先验的概念，并提出了一种层次含拥权的钉板准则，以模型结构化零散的活动模式。然后，我们 deriv了一种 Bayesian 推理方案，通过将期望传播算法和期望最大化算法结合在一起。其次，我们将JUICE问题转换为最大 posteriori（MAP）估计问题，并提出了一种计算效率高的解决方案基于 alternating direction method of multipliers（ADMM）。更具体地，我们将强级钉板准则松弛为一种层次含拥权的长SUM penalty，然后 deriv 了一种 ADMM 算法来解决 MAP 问题。数据结果表明，我们提出的算法具有显著的性能提升和各种假设用户的稀疏活动行为下的稳定性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/16/eess.SP_2023_10_16/" data-id="clontc8tb01ak87885xa86pg5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_10_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/15/cs.CV_2023_10_15/" class="article-date">
  <time datetime="2023-10-15T13:00:00.000Z" itemprop="datePublished">2023-10-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/15/cs.CV_2023_10_15/">cs.CV - 2023-10-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AP-n-P-A-Less-constrained-P-n-P-Solver-for-Pose-Estimation-with-Unknown-Anisotropic-Scaling-or-Focal-Lengths"><a href="#AP-n-P-A-Less-constrained-P-n-P-Solver-for-Pose-Estimation-with-Unknown-Anisotropic-Scaling-or-Focal-Lengths" class="headerlink" title="AP$n$P: A Less-constrained P$n$P Solver for Pose Estimation with Unknown Anisotropic Scaling or Focal Lengths"></a>AP$n$P: A Less-constrained P$n$P Solver for Pose Estimation with Unknown Anisotropic Scaling or Focal Lengths</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09982">http://arxiv.org/abs/2310.09982</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/goldoak/APnP">https://github.com/goldoak/APnP</a></li>
<li>paper_authors: Jiaxin Wei, Stefan Leutenegger, Laurent Kneip</li>
<li>for: 提出了一种新的 pose estimation 算法，可以处理不准确的 3D 坐标和完全加工数据。</li>
<li>methods: 使用了代数处理和新的 Parametrization，将两种情况都转化为同样的多项式问题，并使用 Gr&quot;obner basis 方法解决。</li>
<li>results: 实验结果表明，AP$n$P 算法可以提供更 flexible 和实用的 pose estimation 解决方案，并且在 simulate 和实际数据上达到了良好的效果。<details>
<summary>Abstract</summary>
Perspective-$n$-Point (P$n$P) stands as a fundamental algorithm for pose estimation in various applications. In this paper, we present a new approach to the P$n$P problem with relaxed constraints, eliminating the need for precise 3D coordinates or complete calibration data. We refer to it as AP$n$P due to its ability to handle unknown anisotropic scaling factors of 3D coordinates or alternatively two distinct focal lengths in addition to the conventional rigid pose. Through algebraic manipulations and a novel parametrization, both cases are brought into similar forms that distinguish themselves primarily by the order of a rotation and an anisotropic scaling operation. AP$n$P furthermore brings down both cases to an identical polynomial problem, which is solved using the Gr\"obner basis approach. Experimental results on both simulated and real datasets demonstrate the effectiveness of AP$n$P, providing a more flexible and practical solution to several pose estimation tasks. Code: https://github.com/goldoak/APnP.
</details>
<details>
<summary>摘要</summary>
投影-$n$-点（P$n$P）算法是各种应用中pose estimation的基本算法之一。在这篇论文中，我们提出了一种新的P$n$P问题的解决方案， eliminates the need for precise 3D坐标或完整的准备数据。我们称之为AP$n$P，因为它可以处理未知的三维坐标的 aniotropic scaling factor或两个不同的焦点距离。通过代数操作和一种新的参数化，两种情况都被带入了相似的形式，主要在某种顺序下进行旋转和 aniotropic scaling 操作。此外，AP$n$P还将两种情况下降到了同样的多项式问题，使用Groebner基式方法解决。实验结果表明，AP$n$P是一种更 flexible和实用的pose estimation方法，在 simulate 和实际数据上均有效。代码：https://github.com/goldoak/APnP。
</details></li>
</ul>
<hr>
<h2 id="Class-Specific-Data-Augmentation-Bridging-the-Imbalance-in-Multiclass-Breast-Cancer-Classification"><a href="#Class-Specific-Data-Augmentation-Bridging-the-Imbalance-in-Multiclass-Breast-Cancer-Classification" class="headerlink" title="Class-Specific Data Augmentation: Bridging the Imbalance in Multiclass Breast Cancer Classification"></a>Class-Specific Data Augmentation: Bridging the Imbalance in Multiclass Breast Cancer Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09981">http://arxiv.org/abs/2310.09981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kanan Mahammadli, Abdullah Burkan Bereketoglu, Ayse Gul Kabakci</li>
<li>For: This paper aims to improve the accuracy of breast cancer image classification, specifically for the undersampled classes, by employing class-level data augmentation and a transformer-based ViTNet architecture.* Methods: The paper uses class-level data augmentation on structure-preserving stain normalization techniques to hematoxylin and eosin-stained images, as well as a transformer-based ViTNet architecture via transfer learning for multiclass classification of breast cancer images.* Results: The approach proposed in the paper leads to lower mortality rates associated with breast cancer by increasing the precision of classification on undersampled classes. The paper is able to categorize breast cancer images with advanced image processing and deep learning into either benign or one of four distinct malignant subtypes with high accuracy.<details>
<summary>Abstract</summary>
Breast Cancer is the most common cancer among women, which is also visible in men, and accounts for more than 1 in 10 new cancer diagnoses each year. It is also the second most common cause of women who die from cancer. Hence, it necessitates early detection and tailored treatment. Early detection can provide appropriate and patient-based therapeutic schedules. Moreover, early detection can also provide the type of cyst. This paper employs class-level data augmentation, addressing the undersampled classes and raising their detection rate. This approach suggests two key components: class-level data augmentation on structure-preserving stain normalization techniques to hematoxylin and eosin-stained images and transformer-based ViTNet architecture via transfer learning for multiclass classification of breast cancer images. This merger enables categorizing breast cancer images with advanced image processing and deep learning as either benign or as one of four distinct malignant subtypes by focusing on class-level augmentation and catering to unique characteristics of each class with increasing precision of classification on undersampled classes, which leads to lower mortality rates associated with breast cancer. The paper aims to ease the duties of the medical specialist by operating multiclass classification and categorizing the image into benign or one of four different malignant types of breast cancers.
</details>
<details>
<summary>摘要</summary>
乳癌是女性最常见的癌症，也可以出现在男性身上，每年负担着超过1/10新诊断癌症的责任。它同时也是女性死于癌症的第二大原因。因此，早期发现和定制治疗是非常重要的。早期发现可以提供适当的治疗时间表，同时也可以确定肿瘤的类型。本文提出了一种方法，通过结合分类数据增强和结构保持的染色Normalization技术，以及基于Transformer的ViTNet架构，进行多类分类分析乳癌图像。这种方法可以将乳癌图像分为benign或四种不同的恶性Subtype中的一种，并且可以根据不同的分类类别，提高对受抽样分布的类别的准确性。这种方法可以减轻医生的工作负担，并且可以帮助鉴定乳癌图像的分类结果。
</details></li>
</ul>
<hr>
<h2 id="ProteusNeRF-Fast-Lightweight-NeRF-Editing-using-3D-Aware-Image-Context"><a href="#ProteusNeRF-Fast-Lightweight-NeRF-Editing-using-3D-Aware-Image-Context" class="headerlink" title="ProteusNeRF: Fast Lightweight NeRF Editing using 3D-Aware Image Context"></a>ProteusNeRF: Fast Lightweight NeRF Editing using 3D-Aware Image Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09965">http://arxiv.org/abs/2310.09965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Binglun Wang, Niladri Shekhar Dutt, Niloy J. Mitra</li>
<li>for: 这个论文旨在提出一种用于互动编辑NeRFs的简单 yet effective的神经网络架构，以实现高效、低占用内存的图像改编。</li>
<li>methods: 该架构通过图像特征缩掌和视觉上下文来实现视觉一致的图像编辑，并可以通过对神经网络进行增量导引来实现图像改编。</li>
<li>results: 作者在多个示例中证明了该方法可以带来 appearances 和 geometric 的编辑，并与同期工作相比，提供了10-30倍的速度提升。视频结果可以在<a target="_blank" rel="noopener" href="https://proteusnerf.github.io上查看./">https://proteusnerf.github.io上查看。</a><details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRFs) have recently emerged as a popular option for photo-realistic object capture due to their ability to faithfully capture high-fidelity volumetric content even from handheld video input. Although much research has been devoted to efficient optimization leading to real-time training and rendering, options for interactive editing NeRFs remain limited. We present a very simple but effective neural network architecture that is fast and efficient while maintaining a low memory footprint. This architecture can be incrementally guided through user-friendly image-based edits. Our representation allows straightforward object selection via semantic feature distillation at the training stage. More importantly, we propose a local 3D-aware image context to facilitate view-consistent image editing that can then be distilled into fine-tuned NeRFs, via geometric and appearance adjustments. We evaluate our setup on a variety of examples to demonstrate appearance and geometric edits and report 10-30x speedup over concurrent work focusing on text-guided NeRF editing. Video results can be seen on our project webpage at https://proteusnerf.github.io.
</details>
<details>
<summary>摘要</summary>
neural Radiance Fields (NeRFs) 最近受到了大量研究，因为它们可以准确地捕捉高精度三维内容，即使从手持式视频输入中。虽然许多研究投入到了高效优化，以达到实时训练和渲染，但对Interactive编辑NeRFs的选择仍然有限。我们提出了一种简单 yet effective的神经网络架构，它具有快速和高效的特点，同时具有较低的内存占用率。这种架构可以通过用户友好的图像基于的编辑来进行慢慢导航。我们的表示方式允许直接通过 semantic feature distillation 在训练阶段进行对象选择。更重要的是，我们提议一种基于图像上的 мест化三维意识的图像上下文，以便实现视角一致的图像编辑，然后通过 geometric 和 appearance 调整来蒸馏 fine-tuned NeRFs。我们在多个例子中评估了我们的设置，并发现了10-30倍的速度提升， compared to 同时期关注 text-guided NeRF 编辑的工作。视频结果可以在我们项目网站（https://proteusnerf.github.io）上查看。
</details></li>
</ul>
<hr>
<h2 id="Tabletop-Transparent-Scene-Reconstruction-via-Epipolar-Guided-Optical-Flow-with-Monocular-Depth-Completion-Prior"><a href="#Tabletop-Transparent-Scene-Reconstruction-via-Epipolar-Guided-Optical-Flow-with-Monocular-Depth-Completion-Prior" class="headerlink" title="Tabletop Transparent Scene Reconstruction via Epipolar-Guided Optical Flow with Monocular Depth Completion Prior"></a>Tabletop Transparent Scene Reconstruction via Epipolar-Guided Optical Flow with Monocular Depth Completion Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09956">http://arxiv.org/abs/2310.09956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaotong Chen, Zheming Zhou, Zhuo Deng, Omid Ghasemalizadeh, Min Sun, Cheng-Hao Kuo, Arnie Sen</li>
<li>for:  reconstruction of transparent objects using affordable RGB-D cameras</li>
<li>methods:  leveraging monocular object segmentation and depth completion networks, Epipolar-guided Optical Flow (EOF)</li>
<li>results:  significantly improved 3D reconstruction quality compared to baseline methods, paving the way for more adept robotic perception and interaction with transparent objects.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究旨在使用便宜的RGB-D摄像机重建透明物体，解决了RGB频谱中的不一致和单视深度测量不准确问题。</li>
<li>methods: 我们提出了一个两个阶段的架构，首先使用商业可用的单目object segmentation和深度完成网络预测透明物体的深度，提供单视形状优先。然后，我们提出了Epipolar-guided Optical Flow（EOF），将多个单视形状优先融合成cross-view一致的3D重建，基于摄像机pose估计。EOF使用边界敏感抽样和epipolar-line约束加入光流计算，准确建立透明物体的2D匹配。</li>
<li>results: 我们的架构与基eline方法进行比较，显示我们的3D重建质量得到了显著改善，为Robotic perception和透明物体交互带来了新的可能性。<details>
<summary>Abstract</summary>
Reconstructing transparent objects using affordable RGB-D cameras is a persistent challenge in robotic perception due to inconsistent appearances across views in the RGB domain and inaccurate depth readings in each single-view. We introduce a two-stage pipeline for reconstructing transparent objects tailored for mobile platforms. In the first stage, off-the-shelf monocular object segmentation and depth completion networks are leveraged to predict the depth of transparent objects, furnishing single-view shape prior. Subsequently, we propose Epipolar-guided Optical Flow (EOF) to fuse several single-view shape priors from the first stage to a cross-view consistent 3D reconstruction given camera poses estimated from opaque part of the scene. Our key innovation lies in EOF which employs boundary-sensitive sampling and epipolar-line constraints into optical flow to accurately establish 2D correspondences across multiple views on transparent objects. Quantitative evaluations demonstrate that our pipeline significantly outperforms baseline methods in 3D reconstruction quality, paving the way for more adept robotic perception and interaction with transparent objects.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified Chinese文本：重建透明 объек所用的便宜RGB-D相机是机器人感知中的一个持续挑战，因为颜色域中的 appearances 是不一致的，以及每个单视图中的深度测量不准确。我们提出了一个两stage管道，用于重建透明 объек。在第一个阶段，我们使用 commercially 可用的单目物体分割和深度完成网络来预测透明 объек的深度，从而提供单视图形状优先。然后，我们提出了基于epipolar线的Optical Flow（EOF）来融合多个单视图形状优先，以实现相机pose estimate的cross-view一致性。我们的关键创新在于EOF，它使用边界敏感的采样和epipolar线约束来准确地在多个视图中建立透明对象的2D匹配。量化评估表明，我们的管道在3D重建质量方面与基eline方法进行了显著比较，为更加善的机器人感知和透明对象交互开创了道路。Translation:重建透明对象使用便宜RGB-D相机是机器人感知中的一个持续挑战，因为颜色域中的 appearances 是不一致的，以及每个单视图中的深度测量不准确。我们提出了一个两stage管道，用于重建透明对象。在第一个阶段，我们使用 commercially 可用的单目物体分割和深度完成网络来预测透明对象的深度，从而提供单视图形状优先。然后，我们提出了基于epipolar线的Optical Flow（EOF）来融合多个单视图形状优先，以实现相机pose estimate的cross-view一致性。我们的关键创新在于EOF，它使用边界敏感的采样和epipolar线约束来准确地在多个视图中建立透明对象的2D匹配。量化评估表明，我们的管道在3D重建质量方面与基eline方法进行了显著比较，为更加善的机器人感知和透明对象交互开创了道路。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Robustness-of-Visual-Representations-for-Object-Assembly-Task-Requiring-Spatio-Geometrical-Reasoning"><a href="#Evaluating-Robustness-of-Visual-Representations-for-Object-Assembly-Task-Requiring-Spatio-Geometrical-Reasoning" class="headerlink" title="Evaluating Robustness of Visual Representations for Object Assembly Task Requiring Spatio-Geometrical Reasoning"></a>Evaluating Robustness of Visual Representations for Object Assembly Task Requiring Spatio-Geometrical Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09943">http://arxiv.org/abs/2310.09943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chahyon Ku, Carl Winge, Ryan Diaz, Wentao Yuan, Karthik Desingh</li>
<li>for: 这个论文主要关注评估和比较视觉表示的Robustness在物体组装任务中。</li>
<li>methods: 我们采用一种通用框架，利用视觉预训模型作为视觉编码器来进行视 Motor 政策学习。</li>
<li>results: 我们的量化分析表明现有预训模型无法捕捉这个任务所需的关键视觉特征，但一个从scratch预训的视觉编码器一直表现出色，并且我们提出了旋转表示和相关的损失函数，可以显著提高政策学习。<details>
<summary>Abstract</summary>
This paper primarily focuses on evaluating and benchmarking the robustness of visual representations in the context of object assembly tasks. Specifically, it investigates the alignment and insertion of objects with geometrical extrusions and intrusions, commonly referred to as a peg-in-hole task. The accuracy required to detect and orient the peg and the hole geometry in SE(3) space for successful assembly poses significant challenges. Addressing this, we employ a general framework in visuomotor policy learning that utilizes visual pretraining models as vision encoders. Our study investigates the robustness of this framework when applied to a dual-arm manipulation setup, specifically to the grasp variations. Our quantitative analysis shows that existing pretrained models fail to capture the essential visual features necessary for this task. However, a visual encoder trained from scratch consistently outperforms the frozen pretrained models. Moreover, we discuss rotation representations and associated loss functions that substantially improve policy learning. We present a novel task scenario designed to evaluate the progress in visuomotor policy learning, with a specific focus on improving the robustness of intricate assembly tasks that require both geometrical and spatial reasoning. Videos, additional experiments, dataset, and code are available at https://bit.ly/geometric-peg-in-hole .
</details>
<details>
<summary>摘要</summary>
（本文主要关注评估和比较视觉表示的稳定性在物体组装任务中。具体来说，它研究了具有几何嵌入和嵌入的物体的对齐和插入，通常被称为圆锥盘嵌入任务。成功的组装需要在 SE(3) 空间检测和 orient 圆锥和孔径的精度 pose significant challenges。为此，我们采用一种通用的 Framework in visuomotor policy learning，使用视觉预训模型作为视觉编码器。我们的研究检验了这种 Framework 在双臂 manipulate 设置中的稳定性，特别是在抓取变化中。我们的量化分析表明，现有的预训模型无法捕捉到这种任务所需的关键视觉特征。然而，一个从scratch 训练的视觉编码器在常规模型中具有显著的优势。此外，我们讨论了旋转表示和相关的损失函数，可以在策略学习中提高稳定性。我们还介绍了一种新的任务场景，用于评估visuomotor策略学习的进步，特别是在改进精度的几何和空间逻辑任务中。视频、附加实验、数据集和代码可以在 https://bit.ly/geometric-peg-in-hole 上获得。）
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Discovery-of-Interpretable-Directions-in-h-space-of-Pre-trained-Diffusion-Models"><a href="#Unsupervised-Discovery-of-Interpretable-Directions-in-h-space-of-Pre-trained-Diffusion-Models" class="headerlink" title="Unsupervised Discovery of Interpretable Directions in h-space of Pre-trained Diffusion Models"></a>Unsupervised Discovery of Interpretable Directions in h-space of Pre-trained Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09912">http://arxiv.org/abs/2310.09912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Zhang, Luping Liu. Zhijie Lin, Yichen Zhu, Zhou Zhao</li>
<li>for: 这个研究旨在开发一个无监督性的学习基础的方法，用于找到对称易于理解的方向在预训 diffusion 模型的 h-space 中。</li>
<li>methods: 我们的方法基于现有的 GAN 内部空间技术，包括一个 shift control 模组和一个重建器。这两个模组共同实现对于预训 diffusion 模型的易于理解方向的发现。为了避免发现无意义和破坏性的方向，我们还使用了一个检测器来维持Shifted sample的实际性。</li>
<li>results: 我们的方法可以实现透过 iterative 生成过程来快速发现对称易于理解的方向，并且比较不需要其他复杂的程序。实验结果显示了我们的方法的有效性。<details>
<summary>Abstract</summary>
We propose the first unsupervised and learning-based method to identify interpretable directions in the h-space of pre-trained diffusion models. Our method is derived from an existing technique that operates on the GAN latent space. In a nutshell, we employ a shift control module for pre-trained diffusion models to manipulate a sample into a shifted version of itself, followed by a reconstructor to reproduce both the type and the strength of the manipulation. By jointly optimizing them, the model will spontaneously discover disentangled and interpretable directions. To prevent the discovery of meaningless and destructive directions, we employ a discriminator to maintain the fidelity of shifted sample. Due to the iterative generative process of diffusion models, our training requires a substantial amount of GPU VRAM to store numerous intermediate tensors for back-propagating gradient. To address this issue, we first propose a general VRAM-efficient training algorithm based on gradient checkpointing technique to back-propagate any gradient through the whole generative process, with acceptable occupancy of VRAM and sacrifice of training efficiency. Compared with existing related works on diffusion models, our method inherently identifies global and scalable directions, without necessitating any other complicated procedures. Extensive experiments on various datasets demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
我们提出了首个无监督、学习基于的方法，用于在预训练的扩散模型中标识可解释的方向。我们的方法基于现有的GAN特征空间技术。总之，我们使用一个shift控制模块来控制预训练扩散模型中的一个样本，然后使用一个重构器来重建样本的类型和强度。通过同时优化它们，模型会自动发现分解和可解释的方向。为了避免发现无意义和破坏性的方向，我们使用一个探测器来保持扭曲样本的真实性。由于扩散模型的迭代生成过程，我们的训练需要大量的GPU VRAM来存储多个间接张量以供反向传播梯度。为解决这问题，我们首先提出了一种通用VRAM有效的训练算法，基于梯度检查点技术，可以在接受ABLE的VRAM占用和训练效率的情况下，反向传播任何梯度。与现有相关作品相比，我们的方法自然地标识全局和可扩展的方向，无需其他复杂的过程。广泛的实验表明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Object-Goal-Visual-Navigation-With-Class-Independent-Relationship-Network"><a href="#Zero-Shot-Object-Goal-Visual-Navigation-With-Class-Independent-Relationship-Network" class="headerlink" title="Zero-Shot Object Goal Visual Navigation With Class-Independent Relationship Network"></a>Zero-Shot Object Goal Visual Navigation With Class-Independent Relationship Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09883">http://arxiv.org/abs/2310.09883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinting Li, Shizhou Zhang, Yue LU, Kerry Dan, Lingyan Ran, Peng Wang, Yanning Zhang</li>
<li>for: 这个论文研究了零shot对象目标视觉导航问题。</li>
<li>methods: 我们提出了一种名为Class-Independent Relationship Network（CIRN）的方法，它结合目标检测信息和目标和导航目标之间的相似性，构建了一个新的状态表示，不包含目标特征或环境特征，从而有效地解couple了机器人的导航能力与目标特征。</li>
<li>results: 在AI2-THOR虚拟环境中进行了广泛的实验，我们的方法在零shot导航任务中表现出了强大的泛化能力，包括不同目标和环境下的导航任务。进一步的跨目标和跨场景设置中的实验也进一步验证了我们的方法的稳定性和泛化能力。<details>
<summary>Abstract</summary>
This paper investigates the zero-shot object goal visual navigation problem. In the object goal visual navigation task, the agent needs to locate navigation targets from its egocentric visual input. "Zero-shot" means that the target the agent needs to find is not trained during the training phase. To address the issue of coupling navigation ability with target features during training, we propose the Class-Independent Relationship Network (CIRN). This method combines target detection information with the relative semantic similarity between the target and the navigation target, and constructs a brand new state representation based on similarity ranking, this state representation does not include target feature or environment feature, effectively decoupling the agent's navigation ability from target features. And a Graph Convolutional Network (GCN) is employed to learn the relationships between different objects based on their similarities. During testing, our approach demonstrates strong generalization capabilities, including zero-shot navigation tasks with different targets and environments. Through extensive experiments in the AI2-THOR virtual environment, our method outperforms the current state-of-the-art approaches in the zero-shot object goal visual navigation task. Furthermore, we conducted experiments in more challenging cross-target and cross-scene settings, which further validate the robustness and generalization ability of our method. Our code is available at: https://github.com/SmartAndCleverRobot/ICRA-CIRN.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Top-K-Pooling-with-Patch-Contrastive-Learning-for-Weakly-Supervised-Semantic-Segmentation"><a href="#Top-K-Pooling-with-Patch-Contrastive-Learning-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Top-K Pooling with Patch Contrastive Learning for Weakly-Supervised Semantic Segmentation"></a>Top-K Pooling with Patch Contrastive Learning for Weakly-Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09828">http://arxiv.org/abs/2310.09828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wangyu Wu, Tianhong Dai, Xiaowei Huang, Fei Ma, Jimin Xiao</li>
<li>for: 实现cost-effectiveweakly supervised semantic segmentation (WSSS)</li>
<li>methods: 使用Vision Transformer (ViT)方法，不使用class activation map (CAM)，并 introduces top-K pooling layer和patch contrastive error (PCE)</li>
<li>results: 实验结果显示，我们的方法效果很高，在PASCAL VOC 2012 dataset上比其他state-of-the-art WSSS方法更高效。<details>
<summary>Abstract</summary>
Weakly Supervised Semantic Segmentation (WSSS) using only image-level labels has gained significant attention due to cost-effectiveness. Recently, Vision Transformer (ViT) based methods without class activation map (CAM) have shown greater capability in generating reliable pseudo labels than previous methods using CAM. However, the current ViT-based methods utilize max pooling to select the patch with the highest prediction score to map the patch-level classification to the image-level one, which may affect the quality of pseudo labels due to the inaccurate classification of the patches. In this paper, we introduce a novel ViT-based WSSS method named top-K pooling with patch contrastive learning (TKP-PCL), which employs a top-K pooling layer to alleviate the limitations of previous max pooling selection. A patch contrastive error (PCE) is also proposed to enhance the patch embeddings to further improve the final results. The experimental results show that our approach is very efficient and outperforms other state-of-the-art WSSS methods on the PASCAL VOC 2012 dataset.
</details>
<details>
<summary>摘要</summary>
强度不高的 semantic segmentation (WSSS) 使用图像级别标签已经吸引了广泛关注，主要是因为它的成本低廉。最近，基于 Vision Transformer (ViT) 的方法无需分类映射 (CAM) 已经显示出更高的可靠 Pseudo Label 生成能力。然而，现有的 ViT 基本方法使用最大池化来选择最高分预测值来映射patch级别分类到图像级别的，这可能会影响 pseudo labels 的质量由于不准确的patch分类。在本文中，我们介绍了一种新的 ViT 基本 WSSS 方法，名为 top-K pooling with patch contrastive learning (TKP-PCL)，该方法使用 top-K pooling 层来缓解上述最大池化的局限性。此外，我们还提出了一种 patch contrastive error (PCE) 来进一步改进 patch 的嵌入，从而提高最终结果。实验结果表明，我们的方法非常高效，并在 PASCAL VOC 2012 数据集上超越了其他当前最佳 WSSS 方法。
</details></li>
</ul>
<hr>
<h2 id="Turn-Passive-to-Active-A-Survey-on-Active-Intellectual-Property-Protection-of-Deep-Learning-Models"><a href="#Turn-Passive-to-Active-A-Survey-on-Active-Intellectual-Property-Protection-of-Deep-Learning-Models" class="headerlink" title="Turn Passive to Active: A Survey on Active Intellectual Property Protection of Deep Learning Models"></a>Turn Passive to Active: A Survey on Active Intellectual Property Protection of Deep Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09822">http://arxiv.org/abs/2310.09822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingfu Xue, Leo Yu Zhang, Yushu Zhang, Weiqiang Liu</li>
<li>for: 这篇论文主要是为了介绍和探讨深度学习（DL）模型的知识产权保护方法，具体来说是关于活动权利保护（active copyright protection）技术。</li>
<li>methods: 本论文主要采用了文献综述的方法，审查了现有的知识产权保护方法，并提出了新的活动权利保护方法的需求和挑战。</li>
<li>results: 本论文通过系统地介绍了活动权利保护的概念、特点和要求，提供了评价方法和指标，审查了现有的知识产权保护方法，探讨了可能面临的攻击和未来发展的挑战。<details>
<summary>Abstract</summary>
The intellectual property protection of deep learning (DL) models has attracted increasing serious concerns. Many works on intellectual property protection for Deep Neural Networks (DNN) models have been proposed. The vast majority of existing work uses DNN watermarking to verify the ownership of the model after piracy occurs, which is referred to as passive verification. On the contrary, we focus on a new type of intellectual property protection method named active copyright protection, which refers to active authorization control and user identity management of the DNN model. As of now, there is relatively limited research in the field of active DNN copyright protection. In this review, we attempt to clearly elaborate on the connotation, attributes, and requirements of active DNN copyright protection, provide evaluation methods and metrics for active copyright protection, review and analyze existing work on active DL model intellectual property protection, discuss potential attacks that active DL model copyright protection techniques may face, and provide challenges and future directions for active DL model intellectual property protection. This review is helpful to systematically introduce the new field of active DNN copyright protection and provide reference and foundation for subsequent work.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）模型知识产权保护已经引起了越来越多的关注。许多关于深度神经网络（DNN）模型知识产权保护的工作已经被提出。大多数现有的工作使用深度神经网络水印来验证模型的所有权 после盗版，这被称为被动验证。相比之下，我们关注了一种新的知识产权保护方法，即活动版权保护，即活动授权控制和用户身份管理。到目前为止，对活动DL模型知识产权保护的研究相对较少。在这篇文章中，我们尝试了明确地解释活动DL模型知识产权保护的含义、特点和要求，提供评估方法和指标 для活动版权保护，回顾和分析现有的活动DL模型知识产权保护工作，讨论可能面临的攻击和未来方向。这篇文章有助于系统地介绍新的活动DNN模型知识产权保护领域，并提供参考和基础 для后续的工作。
</details></li>
</ul>
<hr>
<h2 id="LICO-Explainable-Models-with-Language-Image-Consistency"><a href="#LICO-Explainable-Models-with-Language-Image-Consistency" class="headerlink" title="LICO: Explainable Models with Language-Image Consistency"></a>LICO: Explainable Models with Language-Image Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09821">http://arxiv.org/abs/2310.09821</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ymleifdu/lico">https://github.com/ymleifdu/lico</a></li>
<li>paper_authors: Yiming Lei, Zilong Li, Yangyang Li, Junping Zhang, Hongming Shan</li>
<li>for: 这篇论文的目的是解释深度学习模型的决策过程。</li>
<li>methods: 该论文提出了一种基于语言图像一致性的图像分类解释方法，称为LICO，它通过将学习的语言提示与对应的视觉特征进行对应关系的建立，从而生成更加解释的注意力地图。</li>
<li>results: 实验结果表明，LICO可以与现有的解释方法结合使用，并且可以提高图像分类模型的解释能力，而无需在推理过程中增加计算开销。<details>
<summary>Abstract</summary>
Interpreting the decisions of deep learning models has been actively studied since the explosion of deep neural networks. One of the most convincing interpretation approaches is salience-based visual interpretation, such as Grad-CAM, where the generation of attention maps depends merely on categorical labels. Although existing interpretation methods can provide explainable decision clues, they often yield partial correspondence between image and saliency maps due to the limited discriminative information from one-hot labels. This paper develops a Language-Image COnsistency model for explainable image classification, termed LICO, by correlating learnable linguistic prompts with corresponding visual features in a coarse-to-fine manner. Specifically, we first establish a coarse global manifold structure alignment by minimizing the distance between the distributions of image and language features. We then achieve fine-grained saliency maps by applying optimal transport (OT) theory to assign local feature maps with class-specific prompts. Extensive experimental results on eight benchmark datasets demonstrate that the proposed LICO achieves a significant improvement in generating more explainable attention maps in conjunction with existing interpretation methods such as Grad-CAM. Remarkably, LICO improves the classification performance of existing models without introducing any computational overhead during inference. Source code is made available at https://github.com/ymLeiFDU/LICO.
</details>
<details>
<summary>摘要</summary>
深度学习模型的解释方法在深度神经网络爆发后活跃研究。一种最有力的解释方法是基于分类标签的特征焦点映射，如Grad-CAM，其中生成特征焦点映射的依赖于分类标签。 although existing interpretation methods can provide explainable decision clues, they often yield partial correspondence between image and saliency maps due to the limited discriminative information from one-hot labels. This paper proposes a Language-Image COnsistency model for explainable image classification, termed LICO, by correlating learnable linguistic prompts with corresponding visual features in a coarse-to-fine manner. Specifically, we first establish a coarse global manifold structure alignment by minimizing the distance between the distributions of image and language features. We then achieve fine-grained saliency maps by applying optimal transport (OT) theory to assign local feature maps with class-specific prompts. Extensive experimental results on eight benchmark datasets demonstrate that the proposed LICO achieves a significant improvement in generating more explainable attention maps in conjunction with existing interpretation methods such as Grad-CAM. Remarkably, LICO improves the classification performance of existing models without introducing any computational overhead during inference. 源代码可以在https://github.com/ymLeiFDU/LICO 中下载。
</details></li>
</ul>
<hr>
<h2 id="OAAFormer-Robust-and-Efficient-Point-Cloud-Registration-Through-Overlapping-Aware-Attention-in-Transformer"><a href="#OAAFormer-Robust-and-Efficient-Point-Cloud-Registration-Through-Overlapping-Aware-Attention-in-Transformer" class="headerlink" title="OAAFormer: Robust and Efficient Point Cloud Registration Through Overlapping-Aware Attention in Transformer"></a>OAAFormer: Robust and Efficient Point Cloud Registration Through Overlapping-Aware Attention in Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09817">http://arxiv.org/abs/2310.09817</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junjie Gao, Qiujie Dong, Ruian Wang, Shuangmin Chen, Shiqing Xin, Changhe Tu, Wenping Wang</li>
<li>For: The paper focuses on improving the correspondence quality in point cloud registration using a coarse-to-fine feature matching paradigm.* Methods: The proposed method, called OAAFormer, introduces a soft matching mechanism, overlapping region detection module, and region-wise attention module to enhance correspondence quality.* Results: The proposed method achieves a substantial increase of about 7% in the inlier ratio and an enhancement of 2-4% in registration recall on the challenging 3DLoMatch benchmark.Here is the same information in Simplified Chinese:* For: 本文关注在点云注册中提高匹配质量，使用粗细匹配模式。* Methods: 提议的方法是OAAFormer，它引入软匹配机制、重叠区检测模块和区域精度注意力模块来提高匹配质量。* Results: 测试结果表明，提议的方法在3DLoMatch benchmark上增加了约7%的匹配率和2-4%的注册再现率。<details>
<summary>Abstract</summary>
In the domain of point cloud registration, the coarse-to-fine feature matching paradigm has received substantial attention owing to its impressive performance. This paradigm involves a two-step process: first, the extraction of multi-level features, and subsequently, the propagation of correspondences from coarse to fine levels. Nonetheless, this paradigm exhibits two notable limitations.Firstly, the utilization of the Dual Softmax operation has the potential to promote one-to-one correspondences between superpoints, inadvertently excluding valuable correspondences. This propensity arises from the fact that a source superpoint typically maintains associations with multiple target superpoints. Secondly, it is imperative to closely examine the overlapping areas between point clouds, as only correspondences within these regions decisively determine the actual transformation. Based on these considerations, we propose {\em OAAFormer} to enhance correspondence quality. On one hand, we introduce a soft matching mechanism, facilitating the propagation of potentially valuable correspondences from coarse to fine levels. Additionally, we integrate an overlapping region detection module to minimize mismatches to the greatest extent possible. Furthermore, we introduce a region-wise attention module with linear complexity during the fine-level matching phase, designed to enhance the discriminative capabilities of the extracted features. Tests on the challenging 3DLoMatch benchmark demonstrate that our approach leads to a substantial increase of about 7\% in the inlier ratio, as well as an enhancement of 2-4\% in registration recall. =
</details>
<details>
<summary>摘要</summary>
在点云注册领域，粗细到细粒度匹配方法受到了广泛关注，这种方法包括两个步骤：首先提取多级特征，然后在粗细层次上传递匹配。然而，这种方法存在两个显著的限制。首先，使用双层软MAX操作可能会促进一对一的匹配 между超点，不经意增加有价值的匹配。这种倾向来自于源超点通常与多个目标超点保持关联。其次，需要仔细检查点云之间的重叠区域，只有这些区域中的匹配才能决定实际变换。基于这些考虑，我们提出了{\em OAAFormer}来提高匹配质量。一方面，我们引入了软匹配机制，以便在粗细层次上传递有可能的有价值匹配。另一方面，我们集成了重叠区域检测模块，以最大限度避免匹配错误。此外，我们引入了区域wise注意力模块，用于在细粒度匹配阶段提高提取特征的推理能力。3DLoMatch benchmark上的测试表明，我们的方法可以提高约7%的匹配率，同时提高注册回归率约2-4%。
</details></li>
</ul>
<hr>
<h2 id="Can-LSH-Locality-Sensitive-Hashing-Be-Replaced-by-Neural-Network"><a href="#Can-LSH-Locality-Sensitive-Hashing-Be-Replaced-by-Neural-Network" class="headerlink" title="Can LSH (Locality-Sensitive Hashing) Be Replaced by Neural Network?"></a>Can LSH (Locality-Sensitive Hashing) Be Replaced by Neural Network?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09806">http://arxiv.org/abs/2310.09806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renyang Liu, Jun Zhao, Xing Chu, Yu Liang, Wei Zhou, Jing He</li>
<li>for: 提高信息搜索性能</li>
<li>methods: 使用深度神经网络学习locality-sensitive hashing</li>
<li>results: 提高查询精度、减少时间和内存消耗<details>
<summary>Abstract</summary>
With the rapid development of GPU (Graphics Processing Unit) technologies and neural networks, we can explore more appropriate data structures and algorithms. Recent progress shows that neural networks can partly replace traditional data structures. In this paper, we proposed a novel DNN (Deep Neural Network)-based learned locality-sensitive hashing, called LLSH, to efficiently and flexibly map high-dimensional data to low-dimensional space. LLSH replaces the traditional LSH (Locality-sensitive Hashing) function families with parallel multi-layer neural networks, which reduces the time and memory consumption and guarantees query accuracy simultaneously. The proposed LLSH demonstrate the feasibility of replacing the hash index with learning-based neural networks and open a new door for developers to design and configure data organization more accurately to improve information-searching performance. Extensive experiments on different types of datasets show the superiority of the proposed method in query accuracy, time consumption, and memory usage.
</details>
<details>
<summary>摘要</summary>
With the rapid development of GPU (图形处理器) technologies and neural networks, we can explore more appropriate data structures and algorithms. Recent progress shows that neural networks can partly replace traditional data structures. In this paper, we proposed a novel DNN (深度神经网络)-based learned locality-sensitive hashing, called LLSH, to efficiently and flexibly map high-dimensional data to low-dimensional space. LLSH replaces the traditional LSH (本地相似哈希) function families with parallel multi-layer neural networks, which reduces the time and memory consumption and guarantees query accuracy simultaneously. The proposed LLSH demonstrate the feasibility of replacing the hash index with learning-based neural networks and open a new door for developers to design and configure data organization more accurately to improve information-searching performance. Extensive experiments on different types of datasets show the superiority of the proposed method in query accuracy, time consumption, and memory usage.
</details></li>
</ul>
<hr>
<h2 id="Model-Inversion-Attacks-on-Homogeneous-and-Heterogeneous-Graph-Neural-Networks"><a href="#Model-Inversion-Attacks-on-Homogeneous-and-Heterogeneous-Graph-Neural-Networks" class="headerlink" title="Model Inversion Attacks on Homogeneous and Heterogeneous Graph Neural Networks"></a>Model Inversion Attacks on Homogeneous and Heterogeneous Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09800">http://arxiv.org/abs/2310.09800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renyang Liu, Wei Zhou, Jinhong Zhang, Xiaoyuan Liu, Peiyuan Si, Haoran Li<br>for:这个研究旨在提出一种新的模型反向攻击方法，以对Homogeneous Graph Neural Networks (HomoGNNs)和Heterogeneous Graph Neural Networks (HeteGNNs)进行模型反向攻击。methods:这个方法基于Gradient Descent的优化方法，目的是将目标GNN的模型内部结构重建出来，以便进行模型反向攻击。results:实验结果显示，提案的方法可以在多个 benchmark 上实现更好的性能，并且在HeteGNNs上进行模型反向攻击是第一次尝试。<details>
<summary>Abstract</summary>
Recently, Graph Neural Networks (GNNs), including Homogeneous Graph Neural Networks (HomoGNNs) and Heterogeneous Graph Neural Networks (HeteGNNs), have made remarkable progress in many physical scenarios, especially in communication applications. Despite achieving great success, the privacy issue of such models has also received considerable attention. Previous studies have shown that given a well-fitted target GNN, the attacker can reconstruct the sensitive training graph of this model via model inversion attacks, leading to significant privacy worries for the AI service provider. We advocate that the vulnerability comes from the target GNN itself and the prior knowledge about the shared properties in real-world graphs. Inspired by this, we propose a novel model inversion attack method on HomoGNNs and HeteGNNs, namely HomoGMI and HeteGMI. Specifically, HomoGMI and HeteGMI are gradient-descent-based optimization methods that aim to maximize the cross-entropy loss on the target GNN and the $1^{st}$ and $2^{nd}$-order proximities on the reconstructed graph. Notably, to the best of our knowledge, HeteGMI is the first attempt to perform model inversion attacks on HeteGNNs. Extensive experiments on multiple benchmarks demonstrate that the proposed method can achieve better performance than the competitors.
</details>
<details>
<summary>摘要</summary>
最近，图 necklace Neural Networks（GNNs），包括同种图 necklace Neural Networks（HomoGNNs）和不同种图 necklace Neural Networks（HeteGNNs），在许多物理场景中取得了很大的进步，特别是在通信应用场景中。尽管取得了很大的成功，但是隐私问题也得到了广泛的关注。先前的研究表明，给出了一个良好适应的目标GNN，攻击者可以通过模型反向攻击来重建敏感的训练图，从而导致AI服务提供商的隐私问题。我们认为，抵触点来自于目标GNN自身和在实际图中共享的特性知识。 inspirited by this，我们提出了一种基于梯度下降优化的模型反向攻击方法，称为HomoGMI和HeteGMI。具体来说，HomoGMI和HeteGMI都是使用梯度下降方法来最大化目标GNN上的权重损失和$1^{st}$和$2^{nd}$邻域的距离损失。需要注意的是，到目前为止，HeteGMI是首次对HeteGNN进行模型反向攻击。我们在多个标准 benchmark上进行了广泛的实验，结果表明，我们的方法可以在与竞争者相比取得更好的性能。
</details></li>
</ul>
<hr>
<h2 id="AFLOW-Developing-Adversarial-Examples-under-Extremely-Noise-limited-Settings"><a href="#AFLOW-Developing-Adversarial-Examples-under-Extremely-Noise-limited-Settings" class="headerlink" title="AFLOW: Developing Adversarial Examples under Extremely Noise-limited Settings"></a>AFLOW: Developing Adversarial Examples under Extremely Noise-limited Settings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09795">http://arxiv.org/abs/2310.09795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renyang Liu, Jinhong Zhang, Haoran Li, Jin Zhang, Yuanyu Wang, Wei Zhou</li>
<li>for: 本研究旨在提出一种隐蔽的对抗例生成方法，以揭示深度神经网络（DNNs）的漏洞，并帮助提高对抗例的耐久性。</li>
<li>methods: 本研究提出了一种基于Normalize Flow的端到端攻击框架，称为AFLOW，以直接干扰隐藏表示的图像来生成恶意对抗例。与先前的方法不同，AFLOW不添加噪音，而是直接对图像的隐藏表示进行修改。</li>
<li>results: 对三个标准数据集进行了广泛的实验，结果表明，AFLOW可以生成更隐蔽、更高质量的对抗例，并在一些耐久性较高的模型上仍然达到更高的攻击成功率。<details>
<summary>Abstract</summary>
Extensive studies have demonstrated that deep neural networks (DNNs) are vulnerable to adversarial attacks. Despite the significant progress in the attack success rate that has been made recently, the adversarial noise generated by most of the existing attack methods is still too conspicuous to the human eyes and proved to be easily detected by defense mechanisms. Resulting that these malicious examples cannot contribute to exploring the vulnerabilities of existing DNNs sufficiently. Thus, to better reveal the defects of DNNs and further help enhance their robustness under noise-limited situations, a new inconspicuous adversarial examples generation method is exactly needed to be proposed. To bridge this gap, we propose a novel Normalize Flow-based end-to-end attack framework, called AFLOW, to synthesize imperceptible adversarial examples under strict constraints. Specifically, rather than the noise-adding manner, AFLOW directly perturbs the hidden representation of the corresponding image to craft the desired adversarial examples. Compared with existing methods, extensive experiments on three benchmark datasets show that the adversarial examples built by AFLOW exhibit superiority in imperceptibility, image quality and attack capability. Even on robust models, AFLOW can still achieve higher attack results than previous methods.
</details>
<details>
<summary>摘要</summary>
广泛的研究表明，深度神经网络（DNNs）容易受到敌意攻击。尽管最近有很大的进步在攻击成功率方面，但现有的攻击方法仍然生成的恶意示例过于醒目，容易被防御机制检测。这意味着这些恶意示例无法充分探索现有DNNs的漏洞，增强其 robustness 下限 Situation。因此，为了更好地揭示 DNNs 的缺陷并帮助提高其Robustness，我们需要提出一种透明度低的攻击方法。为了填补这个空白，我们提出了一种基于 Normalize Flow 的终端攻击框架，称为 AFLOW，可以在严格的约束下生成透明度低的恶意示例。与现有方法相比，我们进行了三个 benchmark 数据集的广泛实验，结果表明，由 AFLOW 生成的恶意示例具有较高的透明度、图像质量和攻击能力。即使面对Robust 模型，AFLOW 仍然可以达到更高的攻击成功率。>>>
</details></li>
</ul>
<hr>
<h2 id="Automated-Detection-of-Cat-Facial-Landmarks"><a href="#Automated-Detection-of-Cat-Facial-Landmarks" class="headerlink" title="Automated Detection of Cat Facial Landmarks"></a>Automated Detection of Cat Facial Landmarks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09793">http://arxiv.org/abs/2310.09793</a></li>
<li>repo_url: None</li>
<li>paper_authors: George Martvel, Ilan Shimshoni, Anna Zamansky</li>
<li>for: 该论文主要用于提供一个高质量、全面的猫脸表情数据集，以及一种基于猫脸部分描述的面部坐标检测模型。</li>
<li>methods: 该论文使用了一种基于 convolutional neural network 的面部坐标检测模型，其中包括一种使用缩放ensemble方法的面部坐标检测模型，可以在猫脸上显示出极高的性能。</li>
<li>results: 该论文通过使用猫脸数据集和面部坐标检测模型，实现了人类和猫脸的面部坐标检测 task 的混合性能，并且可以在猫脸上显示出极高的准确率。<details>
<summary>Abstract</summary>
The field of animal affective computing is rapidly emerging, and analysis of facial expressions is a crucial aspect. One of the most significant challenges that researchers in the field currently face is the scarcity of high-quality, comprehensive datasets that allow the development of models for facial expressions analysis. One of the possible approaches is the utilisation of facial landmarks, which has been shown for humans and animals. In this paper we present a novel dataset of cat facial images annotated with bounding boxes and 48 facial landmarks grounded in cat facial anatomy. We also introduce a landmark detection convolution neural network-based model which uses a magnifying ensembe method. Our model shows excellent performance on cat faces and is generalizable to human facial landmark detection.
</details>
<details>
<summary>摘要</summary>
“动物情感计算领域在快速发展，面部表达分析是一项重要的挑战。研究人员目前面临的一个主要挑战是获得高质量、全面的面部表达数据集，以便发展面部表达分析模型。我们在这篇论文中提出了一种使用面部特征点的方法，并提供了一个基于 convolutional neural network 的面部特征点检测模型。我们的模型在猫脸上表现出色，并且可以普适应用于人类面部特征点检测。”Here's the breakdown of the translation:* 动物情感计算领域 (dòngwù qíngshěn jìsuàn) - "animal affective computing field"*  rapidly emerging (shìyù xiǎngchuāng) - "rapidly emerging"*  analysis of facial expressions (miàn zhèng xiàngxìng) - "analysis of facial expressions"* One of the most significant challenges (yī zhèng zhìshì) - "one of the most significant challenges"* that researchers in the field currently face (zhèng zhìshì) - "that researchers in the field currently face"* is the scarcity of high-quality, comprehensive datasets (shūshì, zhìshì de yīxiàng) - "is the scarcity of high-quality, comprehensive datasets"* that allow the development of models for facial expressions analysis (miàn zhèng xiàngxìng yìjīng) - "that allow the development of models for facial expressions analysis"* One of the possible approaches (yī zhèng zhìshì) - "one of the possible approaches"* is the utilization of facial landmarks (miàn zhèng zhìshì) - "is the utilization of facial landmarks"* which has been shown for humans and animals (yīnwàng zhèndào) - "which has been shown for humans and animals"* We present a novel dataset of cat facial images (wǒmen xiǎngchuāng zhèng zhìshì) - "we present a novel dataset of cat facial images"* annotated with bounding boxes and 48 facial landmarks grounded in cat facial anatomy (jìchuāng yīnwàng zhèndào) - "annotated with bounding boxes and 48 facial landmarks grounded in cat facial anatomy"* We also introduce a landmark detection convolution neural network-based model (wǒmen xiǎngchuāng zhìshì yìjīng) - "we also introduce a landmark detection convolution neural network-based model"* which uses a magnifying ensemble method (jìchuāng yìjīng) - "which uses a magnifying ensemble method"* Our model shows excellent performance on cat faces (wǒmen xiǎngchuāng zhèng zhìshì) - "our model shows excellent performance on cat faces"* and is generalizable to human facial landmark detection (rénshēng zhìshì) - "and is generalizable to human facial landmark detection"
</details></li>
</ul>
<hr>
<h2 id="SCME-A-Self-Contrastive-Method-for-Data-free-and-Query-Limited-Model-Extraction-Attack"><a href="#SCME-A-Self-Contrastive-Method-for-Data-free-and-Query-Limited-Model-Extraction-Attack" class="headerlink" title="SCME: A Self-Contrastive Method for Data-free and Query-Limited Model Extraction Attack"></a>SCME: A Self-Contrastive Method for Data-free and Query-Limited Model Extraction Attack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09792">http://arxiv.org/abs/2310.09792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renyang Liu, Jinhong Zhang, Kwok-Yan Lam, Jun Zhao, Wei Zhou<br>for:本研究旨在提高模型EXTRACTION攻击的效果，尤其是在有限Query情况下。methods:提出了一种新的数据自由的模型EXTRACTION方法（SCME），通过考虑内类多样性和间类多样性，生成多样化的假数据，并通过Mixup操作进一步增强模型的探索能力。results:在多种攻击场景下，SCME方法在有限Query情况下显示出了11.43%的平均提升，特别是对于未targeted攻击，SCME方法超过了当前最佳方法。<details>
<summary>Abstract</summary>
Previous studies have revealed that artificial intelligence (AI) systems are vulnerable to adversarial attacks. Among them, model extraction attacks fool the target model by generating adversarial examples on a substitute model. The core of such an attack is training a substitute model as similar to the target model as possible, where the simulation process can be categorized in a data-dependent and data-free manner. Compared with the data-dependent method, the data-free one has been proven to be more practical in the real world since it trains the substitute model with synthesized data. However, the distribution of these fake data lacks diversity and cannot detect the decision boundary of the target model well, resulting in the dissatisfactory simulation effect. Besides, these data-free techniques need a vast number of queries to train the substitute model, increasing the time and computing consumption and the risk of exposure. To solve the aforementioned problems, in this paper, we propose a novel data-free model extraction method named SCME (Self-Contrastive Model Extraction), which considers both the inter- and intra-class diversity in synthesizing fake data. In addition, SCME introduces the Mixup operation to augment the fake data, which can explore the target model's decision boundary effectively and improve the simulating capacity. Extensive experiments show that the proposed method can yield diversified fake data. Moreover, our method has shown superiority in many different attack settings under the query-limited scenario, especially for untargeted attacks, the SCME outperforms SOTA methods by 11.43\% on average for five baseline datasets.
</details>
<details>
<summary>摘要</summary>
To address these issues, we propose a novel data-free model extraction method called SCME (Self-Contrastive Model Extraction). Our method considers both inter- and intra-class diversity when synthesizing fake data, and introduces the Mixup operation to augment the fake data, allowing us to effectively explore the target model's decision boundary and improve the simulating capacity. Extensive experiments show that the proposed method can generate diversified fake data, and our method has shown superiority in many different attack settings under the query-limited scenario, especially for untargeted attacks. On average, our method outperforms state-of-the-art methods by 11.43% for five baseline datasets.
</details></li>
</ul>
<hr>
<h2 id="CBARF-Cascaded-Bundle-Adjusting-Neural-Radiance-Fields-from-Imperfect-Camera-Poses"><a href="#CBARF-Cascaded-Bundle-Adjusting-Neural-Radiance-Fields-from-Imperfect-Camera-Poses" class="headerlink" title="CBARF: Cascaded Bundle-Adjusting Neural Radiance Fields from Imperfect Camera Poses"></a>CBARF: Cascaded Bundle-Adjusting Neural Radiance Fields from Imperfect Camera Poses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09776">http://arxiv.org/abs/2310.09776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyu Fu, Xin Yu, Lincheng Li, Li Zhang</li>
<li>for: 本文提出了一种新的3D重建框架，用于同时优化摄像头姿势，以提高novel view的synthesizing质量。</li>
<li>methods: 该框架采用了分层bundle-adjustment（BA）模块，通过粗化-细化的方式进行摄像头姿势的优化，并采用了一种邻居替换策略来进一步优化BA的结果。</li>
<li>results: 实验结果表明，CBARF模型在摄像头姿势优化和novel view synthesis中表现出了state-of-the-art的性能，特别是在大量摄像头姿势噪声的情况下。<details>
<summary>Abstract</summary>
Existing volumetric neural rendering techniques, such as Neural Radiance Fields (NeRF), face limitations in synthesizing high-quality novel views when the camera poses of input images are imperfect. To address this issue, we propose a novel 3D reconstruction framework that enables simultaneous optimization of camera poses, dubbed CBARF (Cascaded Bundle-Adjusting NeRF).In a nutshell, our framework optimizes camera poses in a coarse-to-fine manner and then reconstructs scenes based on the rectified poses. It is observed that the initialization of camera poses has a significant impact on the performance of bundle-adjustment (BA). Therefore, we cascade multiple BA modules at different scales to progressively improve the camera poses. Meanwhile, we develop a neighbor-replacement strategy to further optimize the results of BA in each stage. In this step, we introduce a novel criterion to effectively identify poorly estimated camera poses. Then we replace them with the poses of neighboring cameras, thus further eliminating the impact of inaccurate camera poses. Once camera poses have been optimized, we employ a density voxel grid to generate high-quality 3D reconstructed scenes and images in novel views. Experimental results demonstrate that our CBARF model achieves state-of-the-art performance in both pose optimization and novel view synthesis, especially in the existence of large camera pose noise.
</details>
<details>
<summary>摘要</summary>
现有的量化神经渲染技术，如神经辐射场（NeRF），在输入图像的相机pose不 precisions时面临限制。为解决这个问题，我们提出了一种新的三维重建框架，称为CBARF（层次拟合束适应NeRF）。总之，我们的框架在层次进行相机pose的优化，然后基于修正后的相机pose来重建场景。我们发现初始相机pose的初始化对bundle-adjustment（BA）的性能有很大的影响。因此，我们在不同的级别上cascade多个BA模块，以逐步改进相机pose。同时，我们开发了一种邻居替换策略，以进一步优化BA模块在每个阶段的结果。在这个步骤中，我们引入了一种新的 criterion，以有效地识别估计不准确的相机pose。然后，我们将其替换为邻居相机的pose，从而进一步消除不准确的相机pose的影响。一旦相机pose被优化，我们就可以使用密度体积格来生成高质量的3D重建场景和图像。实验结果表明，我们的CBARF模型在相机pose的优化和新视图合成方面达到了状态级表现，特别是在相机pose噪声较大的情况下。
</details></li>
</ul>
<hr>
<h2 id="Image-Augmentation-with-Controlled-Diffusion-for-Weakly-Supervised-Semantic-Segmentation"><a href="#Image-Augmentation-with-Controlled-Diffusion-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Image Augmentation with Controlled Diffusion for Weakly-Supervised Semantic Segmentation"></a>Image Augmentation with Controlled Diffusion for Weakly-Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09760">http://arxiv.org/abs/2310.09760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wangyu Wu, Tianhong Dai, Xiaowei Huang, Fei Ma, Jimin Xiao</li>
<li>for:  trains semantic segmentation models solely using image-level labels, and aims to improve the quality of pseudo labels when the size of available dataset is limited.</li>
<li>methods:  introduces a novel approach called Image Augmentation with Controlled Diffusion (IACD), which effectively augments existing labeled datasets by generating diverse images through controlled diffusion, and proposes a high-quality image selection strategy to mitigate the potential noise introduced by the randomness of diffusion models.</li>
<li>results:  clearly surpasses existing state-of-the-art methods, and the effect is more obvious when the amount of available data is small, demonstrating the effectiveness of the proposed IACD approach.<details>
<summary>Abstract</summary>
Weakly-supervised semantic segmentation (WSSS), which aims to train segmentation models solely using image-level labels, has achieved significant attention. Existing methods primarily focus on generating high-quality pseudo labels using available images and their image-level labels. However, the quality of pseudo labels degrades significantly when the size of available dataset is limited. Thus, in this paper, we tackle this problem from a different view by introducing a novel approach called Image Augmentation with Controlled Diffusion (IACD). This framework effectively augments existing labeled datasets by generating diverse images through controlled diffusion, where the available images and image-level labels are served as the controlling information. Moreover, we also propose a high-quality image selection strategy to mitigate the potential noise introduced by the randomness of diffusion models. In the experiments, our proposed IACD approach clearly surpasses existing state-of-the-art methods. This effect is more obvious when the amount of available data is small, demonstrating the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
弱级Semantic segmentation（WSSS），它目标是通过图像级别标签来训练 segmentation 模型，已经吸引了广泛的关注。现有方法主要集中在生成高质量 Pseudo label 上，使用可用的图像和图像级别标签。然而，当数据集的大小受限时， pseudo label 的质量会下降 significatively。因此，在这篇论文中，我们从不同的角度解决这个问题，我们提出了一种新的方法，即 Image Augmentation with Controlled Diffusion（IACD）。这个框架可以有效地增强现有的标注数据集，通过控制的扩散来生成多样化的图像。此外，我们还提出了一种高质量图像选择策略，以避免扩散模型中的随机性引入的噪音。在实验中，我们的提议的 IACD 方法明显超越了现有的状态对照方法。这个效果更加明显，当数据集的量受限时，这表明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Prototype-oriented-Unsupervised-Change-Detection-for-Disaster-Management"><a href="#Prototype-oriented-Unsupervised-Change-Detection-for-Disaster-Management" class="headerlink" title="Prototype-oriented Unsupervised Change Detection for Disaster Management"></a>Prototype-oriented Unsupervised Change Detection for Disaster Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09759">http://arxiv.org/abs/2310.09759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youngtack Oh, Minseok Seo, Doyi Kim, Junghoon Seo</li>
<li>For: 本研究旨在提出一种不需要标注的自然灾害监测方法，以应对气候变化导致的自然灾害的频发。* Methods: 本研究提出了一种名为prototype-orientedUnsupervised Change Detection for Disaster Management（PUCD）的方法，该方法通过比较预事件、后事件和基础模型生成的变化合成图像的特征来检测变化，并使用Segment Anything Model（SAM）进行精细化。* Results: 本研究在LEVIR-Extension数据集上评估了PUCD方法，并与其他方法进行比较，结果显示PUCD方法在LEVIR-Extension数据集上达到了现有方法的最优性。<details>
<summary>Abstract</summary>
Climate change has led to an increased frequency of natural disasters such as floods and cyclones. This emphasizes the importance of effective disaster monitoring. In response, the remote sensing community has explored change detection methods. These methods are primarily categorized into supervised techniques, which yield precise results but come with high labeling costs, and unsupervised techniques, which eliminate the need for labeling but involve intricate hyperparameter tuning. To address these challenges, we propose a novel unsupervised change detection method named Prototype-oriented Unsupervised Change Detection for Disaster Management (PUCD). PUCD captures changes by comparing features from pre-event, post-event, and prototype-oriented change synthesis images via a foundational model, and refines results using the Segment Anything Model (SAM). Although PUCD is an unsupervised change detection, it does not require complex hyperparameter tuning. We evaluate PUCD framework on the LEVIR-Extension dataset and the disaster dataset and it achieves state-of-the-art performance compared to other methods on the LEVIR-Extension dataset.
</details>
<details>
<summary>摘要</summary>
климат变化导致自然灾害的频率增加，这重要性化效果监测。因此，远程感知社区已经探索了变化检测方法。这些方法主要分为监督式技术，它们可以提供精确的结果，但是需要高的标注成本，以及无监督技术，它们可以消除标注需求，但是需要复杂的 гиперпараметров调整。为解决这些挑战，我们提出了一种基于原型的无监督变化检测方法，名为“原型 ориентирован无监督变化检测 для灾害管理”（PUCD）。PUCD通过比较预事件、后事件和基于原型的变化合成图像的特征来捕捉变化，并使用基本模型（SAM）进行细化。尽管PUCD是无监督的变化检测方法，但它不需要复杂的 гиперпараметров调整。我们对PUCD框架在LEVIR-Extension数据集和灾害数据集进行评估，并达到了与其他方法相比的状态前方性表现。
</details></li>
</ul>
<hr>
<h2 id="MoEmo-Vision-Transformer-Integrating-Cross-Attention-and-Movement-Vectors-in-3D-Pose-Estimation-for-HRI-Emotion-Detection"><a href="#MoEmo-Vision-Transformer-Integrating-Cross-Attention-and-Movement-Vectors-in-3D-Pose-Estimation-for-HRI-Emotion-Detection" class="headerlink" title="MoEmo Vision Transformer: Integrating Cross-Attention and Movement Vectors in 3D Pose Estimation for HRI Emotion Detection"></a>MoEmo Vision Transformer: Integrating Cross-Attention and Movement Vectors in 3D Pose Estimation for HRI Emotion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09757">http://arxiv.org/abs/2310.09757</a></li>
<li>repo_url: None</li>
<li>paper_authors: David C. Jeong, Tianma Shen, Hongji Liu, Raghav Kapoor, Casey Nguyen, Song Liu, Christopher A. Kitts</li>
<li>for: 这 paper 的目的是提出一种基于人体姿势估计的人工智能人机交互（HRI）中的情绪检测方法。</li>
<li>methods: 这 paper 使用了cross-attention视觉变换器（ViT）和自然语言处理技术，将人体姿势估计与环境上下文进行交互，以实现更高精度的情绪检测。</li>
<li>results: 对比现有方法，这 paper 的方法可以更好地利用人体姿势和环境上下文之间的微妙关系，从而提高情绪检测的准确率。<details>
<summary>Abstract</summary>
Emotion detection presents challenges to intelligent human-robot interaction (HRI). Foundational deep learning techniques used in emotion detection are limited by information-constrained datasets or models that lack the necessary complexity to learn interactions between input data elements, such as the the variance of human emotions across different contexts. In the current effort, we introduce 1) MoEmo (Motion to Emotion), a cross-attention vision transformer (ViT) for human emotion detection within robotics systems based on 3D human pose estimations across various contexts, and 2) a data set that offers full-body videos of human movement and corresponding emotion labels based on human gestures and environmental contexts. Compared to existing approaches, our method effectively leverages the subtle connections between movement vectors of gestures and environmental contexts through the use of cross-attention on the extracted movement vectors of full-body human gestures/poses and feature maps of environmental contexts. We implement a cross-attention fusion model to combine movement vectors and environment contexts into a joint representation to derive emotion estimation. Leveraging our Naturalistic Motion Database, we train the MoEmo system to jointly analyze motion and context, yielding emotion detection that outperforms the current state-of-the-art.
</details>
<details>
<summary>摘要</summary>
人工智能human-robot交互（HRI）中的情绪检测受到挑战。基础的深度学习技术在情绪检测方面受到数据约束或模型缺乏足够复杂性来学习输入数据元素之间的交互，如人类情绪在不同情境下的变化。在当前努力中，我们介绍了以下两个方法：1. MoEmo（动作到情绪）：基于机器人系统的人体pose估计中的3D人体动作，采用视Transformer（ViT）来检测人类情绪。2. 一个包含全身动作和对应情绪标签的完整数据集。与现有方法相比，我们的方法可以充分利用人体动作vector和环境上下文的关系，通过跨注意力 fusion模型将动作vector和环境上下文融合为共同表示，从而实现情绪估计。我们使用自然主义人体动作数据库来训练MoEmo系统，以同时分析动作和环境，实现情绪检测的改进。
</details></li>
</ul>
<hr>
<h2 id="New-Benchmarks-for-Asian-Facial-Recognition-Tasks-Face-Classification-with-Large-Foundation-Models"><a href="#New-Benchmarks-for-Asian-Facial-Recognition-Tasks-Face-Classification-with-Large-Foundation-Models" class="headerlink" title="New Benchmarks for Asian Facial Recognition Tasks: Face Classification with Large Foundation Models"></a>New Benchmarks for Asian Facial Recognition Tasks: Face Classification with Large Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09756">http://arxiv.org/abs/2310.09756</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dukong1/koin_benchmark_dataset">https://github.com/dukong1/koin_benchmark_dataset</a></li>
<li>paper_authors: Jinwoo Seo, Soora Choi, Eungyeom Ha, Beomjune Kim, Dongbin Na</li>
<li>for: 这个论文是为了开发一个大规模的韩国Influencer分类系统而写的。</li>
<li>methods: 这篇论文使用了大量的韩国明星照片，并在这些照片中添加了各种环境，如舞台照明、后台舞者和背景物体。这些照片可以用于训练分类模型，以便正确地识别韩国Influencer。</li>
<li>results: 论文提出了一个名为KoIn的大规模韩国Influencer数据集，包含100,000多张韩国明星照片，并提供了一些困难的样例图像，如人脸图像包含面具和帽子。论文还进行了多种实验，包括使用现有的基础模型来证明KoIn数据集的有效性。<details>
<summary>Abstract</summary>
The face classification system is an important tool for recognizing personal identity properly. This paper introduces a new Large-Scale Korean Influencer Dataset named KoIn. Our presented dataset contains many real-world photos of Korean celebrities in various environments that might contain stage lighting, backup dancers, and background objects. These various images can be useful for training classification models classifying K-influencers. Most of the images in our proposed dataset have been collected from social network services (SNS) such as Instagram. Our dataset, KoIn, contains over 100,000 K-influencer photos from over 100 Korean celebrity classes. Moreover, our dataset provides additional hard case samples such as images including human faces with masks and hats. We note that the hard case samples are greatly useful in evaluating the robustness of the classification systems. We have extensively conducted several experiments utilizing various classification models to validate the effectiveness of our proposed dataset. Specifically, we demonstrate that recent state-of-the-art (SOTA) foundation architectures show decent classification performance when trained on our proposed dataset. In this paper, we also analyze the robustness performance against hard case samples of large-scale foundation models when we fine-tune the foundation models on the normal cases of the proposed dataset, KoIn. Our presented dataset and codes will be publicly available at https://github.com/dukong1/KoIn_Benchmark_Dataset.
</details>
<details>
<summary>摘要</summary>
“人脸分类系统是识别个人身份的重要工具。本文介绍了一个新的大规模韩国 influencer 数据集名为 KoIn。我们提供的数据集包含了许多真实的韩国明星照片，其中包括舞台照明、后台舞者和背景物品等不同环境。这些图像可以用于训练分类模型，以便将 K-influencer 分类 correctly。大多数图像在我们提出的数据集中来自社交媒体服务（SNS）such as Instagram。我们的数据集 KoIn 包含了超过 100,000 韩国明星照片，来自于超过 100 个韩国明星类别。此外，我们的数据集还提供了一些难易 случа例样本，包括人脸图像中的面具和帽子等。我们注意到这些难易 случа例样本在评估分类系统的Robustness 性能时非常有用。我们在这篇文章中进行了多种实验，以验证我们提出的数据集的有效性。具体来说，我们表明了最新的基础建筑（SOTA）的基础模型在我们提出的数据集上进行训练后的分类性能不错。在这篇文章中，我们还分析了大规模基础模型在 KoIn 数据集中的 robustness 性能，当我们在 normal cases 上进行 fine-tune 时。我们将提供的数据集和代码将在 https://github.com/dukong1/KoIn_Benchmark_Dataset 上公开。”
</details></li>
</ul>
<hr>
<h2 id="Staged-Depthwise-Correlation-and-Feature-Fusion-for-Siamese-Object-Tracking"><a href="#Staged-Depthwise-Correlation-and-Feature-Fusion-for-Siamese-Object-Tracking" class="headerlink" title="Staged Depthwise Correlation and Feature Fusion for Siamese Object Tracking"></a>Staged Depthwise Correlation and Feature Fusion for Siamese Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09747">http://arxiv.org/abs/2310.09747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dianbo Ma, Jianqiang Xiao, Ziyan Gao, Satoshi Yamane</li>
<li>for: 提高视觉跟踪的特征提取效果</li>
<li>methods: 提出了一种新的多Stage深度相关和特征融合网络（DCFFNet），利用多级层次特征和多通道semantics来学习对象特征的优化权重</li>
<li>results: 对多个大规模数据集进行了端到端协调训练，实现了模型的稳定训练和高性能，并在多个标准测试集上达到了多种跟踪器的竞争性表现<details>
<summary>Abstract</summary>
In this work, we propose a novel staged depthwise correlation and feature fusion network, named DCFFNet, to further optimize the feature extraction for visual tracking. We build our deep tracker upon a siamese network architecture, which is offline trained from scratch on multiple large-scale datasets in an end-to-end manner. The model contains a core component, that is, depthwise correlation and feature fusion module (correlation-fusion module), which facilitates model to learn a set of optimal weights for a specific object by utilizing ensembles of multi-level features from lower and higher layers and multi-channel semantics on the same layer. We combine the modified ResNet-50 with the proposed correlation-fusion layer to constitute the feature extractor of our model. In training process, we find the training of model become more stable, that benifits from the correlation-fusion module. For comprehensive evaluations of performance, we implement our tracker on the popular benchmarks, including OTB100, VOT2018 and LaSOT. Extensive experiment results demonstrate that our proposed method achieves favorably competitive performance against many leading trackers in terms of accuracy and precision, while satisfying the real-time requirements of applications.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们提出了一种新的阶段化深度相关和特征融合网络（DCFFNet），用于进一步优化视觉跟踪的特征提取。我们基于siames network架构，将模型在多个大规模数据集上进行了线性训练，并在整个过程中从头到尾地训练。模型的核心组件是深度相关和特征融合模块（相关融合模块），它使得模型可以通过不同层次的特征和多个渠道semantic来学习一个特定对象的最佳权重。我们将修改后的ResNet-50和提议的相关融合层组合成我们的特征提取器。在训练过程中，我们发现模型的训练变得更加稳定，这是由相关融合模块带来的。为了进行全面的性能评估，我们在知名的benchmark上实现了我们的跟踪器，包括OTB100、VOT2018和LaSOT。广泛的实验结果表明，我们的提议方法在精度和稳定性两个方面与许多领先的跟踪器相比，表现出非常竞争力，同时满足应用中的实时需求。
</details></li>
</ul>
<hr>
<h2 id="Explore-the-Effect-of-Data-Selection-on-Poison-Efficiency-in-Backdoor-Attacks"><a href="#Explore-the-Effect-of-Data-Selection-on-Poison-Efficiency-in-Backdoor-Attacks" class="headerlink" title="Explore the Effect of Data Selection on Poison Efficiency in Backdoor Attacks"></a>Explore the Effect of Data Selection on Poison Efficiency in Backdoor Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09744">http://arxiv.org/abs/2310.09744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqiang Li, Pengfei Xia, Hong Sun, Yueqi Zeng, Wei Zhang, Bin Li<br>for: 降低培训数据 Collection 成本，提高深度神经网络 (DNNs) 的攻击性能。methods: 提出了一种基于 Forgetting 和 curvature 的 Sample Selection Strategy，可以提高攻击效率。results: 在多个领域 (CIFAR-10、CIFAR-100、ImageNet-10、AG News、ESC-50、Facial Age) 的实验结果表明，提案的方法可以在相同的恶意比例下提高攻击性能。<details>
<summary>Abstract</summary>
As the number of parameters in Deep Neural Networks (DNNs) scales, the thirst for training data also increases. To save costs, it has become common for users and enterprises to delegate time-consuming data collection to third parties. Unfortunately, recent research has shown that this practice raises the risk of DNNs being exposed to backdoor attacks. Specifically, an attacker can maliciously control the behavior of a trained model by poisoning a small portion of the training data. In this study, we focus on improving the poisoning efficiency of backdoor attacks from the sample selection perspective. The existing attack methods construct such poisoned samples by randomly selecting some clean data from the benign set and then embedding a trigger into them. However, this random selection strategy ignores that each sample may contribute differently to the backdoor injection, thereby reducing the poisoning efficiency. To address the above problem, a new selection strategy named Improved Filtering and Updating Strategy (FUS++) is proposed. Specifically, we adopt the forgetting events of the samples to indicate the contribution of different poisoned samples and use the curvature of the loss surface to analyses the effectiveness of this phenomenon. Accordingly, we combine forgetting events and curvature of different samples to conduct a simple yet efficient sample selection strategy. The experimental results on image classification (CIFAR-10, CIFAR-100, ImageNet-10), text classification (AG News), audio classification (ESC-50), and age regression (Facial Age) consistently demonstrate the effectiveness of the proposed strategy: the attack performance using FUS++ is significantly higher than that using random selection for the same poisoning ratio.
</details>
<details>
<summary>摘要</summary>
Existing attack methods create poisoned samples by randomly selecting some clean data from the benign set and embedding a trigger into them. However, this random selection strategy overlooks the fact that each sample may contribute differently to the backdoor injection, thereby reducing the poisoning efficiency.To address this issue, we propose a new sample selection strategy called Improved Filtering and Updating Strategy (FUS++). We utilize the forgetting events of the samples to indicate their contribution to the backdoor injection and analyze the effectiveness of this phenomenon using the curvature of the loss surface. By combining forgetting events and curvature of different samples, we develop a simple yet efficient sample selection strategy.Our experimental results on image classification (CIFAR-10, CIFAR-100, ImageNet-10), text classification (AG News), audio classification (ESC-50), and age regression (Facial Age) consistently show that the proposed strategy outperforms random selection for the same poisoning ratio. The attack performance using FUS++ is significantly higher, indicating the effectiveness of our proposed strategy in enhancing the poisoning efficiency of backdoor attacks.
</details></li>
</ul>
<hr>
<h2 id="AugUndo-Scaling-Up-Augmentations-for-Unsupervised-Depth-Completion"><a href="#AugUndo-Scaling-Up-Augmentations-for-Unsupervised-Depth-Completion" class="headerlink" title="AugUndo: Scaling Up Augmentations for Unsupervised Depth Completion"></a>AugUndo: Scaling Up Augmentations for Unsupervised Depth Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09739">http://arxiv.org/abs/2310.09739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangchao Wu, Tian Yu Liu, Hyoungseob Park, Stefano Soatto, Dong Lao, Alex Wong</li>
<li>for: 提高无监督深度完成任务的性能（improve the performance of unsupervised depth completion tasks）</li>
<li>methods: 使用“undo”操作来解除各种几何变换对深度图的影响，从而计算恢复损失使用原始图像和稀疏深度图，从而缩大数据增强的可能性（use “undo” operation to eliminate the impact of various geometric transformations on the depth map, and compute the reconstruction loss using the original images and sparse depth maps, thus expanding the possibility of data augmentation）</li>
<li>results: 在indoor（VOID）和outdoor（KITTI）数据集上，与三种现有方法进行比较，平均提高了10.4%（compared to three existing methods on the indoor (VOID) and outdoor (KITTI) datasets, with an average improvement of 10.4%）<details>
<summary>Abstract</summary>
Unsupervised depth completion methods are trained by minimizing sparse depth and image reconstruction error. Block artifacts from resampling, intensity saturation, and occlusions are amongst the many undesirable by-products of common data augmentation schemes that affect image reconstruction quality, and thus the training signal. Hence, typical augmentations on images that are viewed as essential to training pipelines in other vision tasks have seen limited use beyond small image intensity changes and flipping. The sparse depth modality have seen even less as intensity transformations alter the scale of the 3D scene, and geometric transformations may decimate the sparse points during resampling. We propose a method that unlocks a wide range of previously-infeasible geometric augmentations for unsupervised depth completion. This is achieved by reversing, or "undo"-ing, geometric transformations to the coordinates of the output depth, warping the depth map back to the original reference frame. This enables computing the reconstruction losses using the original images and sparse depth maps, eliminating the pitfalls of naive loss computation on the augmented inputs. This simple yet effective strategy allows us to scale up augmentations to boost performance. We demonstrate our method on indoor (VOID) and outdoor (KITTI) datasets where we improve upon three existing methods by an average of 10.4\% across both datasets.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate("Unsupervised depth completion methods are trained by minimizing sparse depth and image reconstruction error. Block artifacts from resampling, intensity saturation, and occlusions are amongst the many undesirable by-products of common data augmentation schemes that affect image reconstruction quality, and thus the training signal. Hence, typical augmentations on images that are viewed as essential to training pipelines in other vision tasks have seen limited use beyond small image intensity changes and flipping. The sparse depth modality have seen even less as intensity transformations alter the scale of the 3D scene, and geometric transformations may decimate the sparse points during resampling. We propose a method that unlocks a wide range of previously-infeasible geometric augmentations for unsupervised depth completion. This is achieved by reversing, or "undo"-ing, geometric transformations to the coordinates of the output depth, warping the depth map back to the original reference frame. This enables computing the reconstruction losses using the original images and sparse depth maps, eliminating the pitfalls of naive loss computation on the augmented inputs. This simple yet effective strategy allows us to scale up augmentations to boost performance. We demonstrate our method on indoor (VOID) and outdoor (KITTI) datasets where we improve upon three existing methods by an average of 10.4\% across both datasets.")</SYS>>Here's the translation in Simplified Chinese:Unsupervised深度完成方法通常通过最小化稀疏深度和图像重建错误来训练。采样、强化、 occlusion 等常见数据增强方法的副作用会影响图像重建质量，从而影响训练信号。因此，通常会限制图像增强方法的应用，只有小型图像Intensity 变化和翻转。 sparse depth 模式更加受到INTENSITY 变化的影响，Geometric 变换可能会在抽样时消耗稀疏点。我们提出了一种方法，可以解锁许多前置不可能的几何增强。这是通过将几何变换转换为输出深度坐标的反向操作，使深度地图返回原始参照帧。这使得可以使用原始图像和稀疏深度图来计算重建损失，消除了使用增强输入的恶性问题。这种简单 yet 有效的策略允许我们扩大增强，提高性能。我们在indoor (VOID) 和 outdoor (KITTI) 数据集上示出了我们的方法，与三种现有方法的平均提升率为10.4%。
</details></li>
</ul>
<hr>
<h2 id="FuseSR-Super-Resolution-for-Real-time-Rendering-through-Efficient-Multi-resolution-Fusion"><a href="#FuseSR-Super-Resolution-for-Real-time-Rendering-through-Efficient-Multi-resolution-Fusion" class="headerlink" title="FuseSR: Super Resolution for Real-time Rendering through Efficient Multi-resolution Fusion"></a>FuseSR: Super Resolution for Real-time Rendering through Efficient Multi-resolution Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09726">http://arxiv.org/abs/2310.09726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Isaac-Paradox/FuseSR">https://github.com/Isaac-Paradox/FuseSR</a></li>
<li>paper_authors: Zhihua Zhong, Jingsen Zhu, Yuxin Dai, Chuankun Zheng, Yuchi Huo, Guanlin Chen, Hujun Bao, Rui Wang</li>
<li>for: 提高实时渲染的效率和质量，满足高分辨率、高刷新率和高实зм的需求。</li>
<li>methods: 利用低分辨率输入图像，通过高价值高分辨率auxiliary G-Buffer来提高渲染的精度和效率。introduce an efficient and effective H-Net architecture to solve the problem of aligning and fusing features at multi-resolution levels.</li>
<li>results: 实现4K分辨率的实时渲染，并在$4 \times 4$和$8 \times 8$� upsampling cases中提供高质量和高性能的渲染结果，与现有方法相比有substantially improved quality和significant performance boost。<details>
<summary>Abstract</summary>
The workload of real-time rendering is steeply increasing as the demand for high resolution, high refresh rates, and high realism rises, overwhelming most graphics cards. To mitigate this problem, one of the most popular solutions is to render images at a low resolution to reduce rendering overhead, and then manage to accurately upsample the low-resolution rendered image to the target resolution, a.k.a. super-resolution techniques. Most existing methods focus on exploiting information from low-resolution inputs, such as historical frames. The absence of high frequency details in those LR inputs makes them hard to recover fine details in their high-resolution predictions. In this paper, we propose an efficient and effective super-resolution method that predicts high-quality upsampled reconstructions utilizing low-cost high-resolution auxiliary G-Buffers as additional input. With LR images and HR G-buffers as input, the network requires to align and fuse features at multi resolution levels. We introduce an efficient and effective H-Net architecture to solve this problem and significantly reduce rendering overhead without noticeable quality deterioration. Experiments show that our method is able to produce temporally consistent reconstructions in $4 \times 4$ and even challenging $8 \times 8$ upsampling cases at 4K resolution with real-time performance, with substantially improved quality and significant performance boost compared to existing works.
</details>
<details>
<summary>摘要</summary>
工作负载实时渲染在需求高分辨率、高刷新率和高现实性的需求增长，导致大多数图形卡被拥塞。为解决这个问题，一种非常流行的解决方案是在低分辨率下渲染图像，以减轻渲染负担，然后使用高分辨率auxiliary G-Buffers作为额外输入，进行高分辨率恢复。大多数现有方法都是利用低分辨率输入的信息，如历史帧，但是低分辨率输入缺乏高频率细节，使其很难回归高分辨率预测中的细节。在这篇论文中，我们提出了一种高效、高质量的超解像技术，通过利用低成本高分辨率auxiliary G-Buffers作为额外输入，将LR图像和HR G-Buffers作为输入，并对多个分辨率水平进行对齐和融合特征。我们提出了一种高效的H-Net架构来解决这个问题，实现了显著减少渲染负担，无需明显下降质量。实验表明，我们的方法在4K分辨率的$4 \times 4$和甚至更加挑战性的$8 \times 8$恢复 случа中，可以实现实时性和显著性能提升，而且与现有方法相比，有较大的质量提升和性能提升。
</details></li>
</ul>
<hr>
<h2 id="Efficient-and-Effective-Multi-View-Subspace-Clustering-for-Large-scale-Data"><a href="#Efficient-and-Effective-Multi-View-Subspace-Clustering-for-Large-scale-Data" class="headerlink" title="Efficient and Effective Multi-View Subspace Clustering for Large-scale Data"></a>Efficient and Effective Multi-View Subspace Clustering for Large-scale Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09718">http://arxiv.org/abs/2310.09718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiu Lin, Hui Liu, Ren Wang, Gongguan Chen, Caiming Zhang</li>
<li>For: 提高大规模多视图数据集中 clustering 性能，解决现有方法中FC层的参数缺乏效率和内存成本问题。* Methods: 提出了一种新的深度框架E$^2$LMVSC，通过在多视图数据上实现硬件约束来提高共享表示的质量，并使用信息瓶颈理论来获得最小够的共享特征表示。* Results: 对大规模多视图数据集进行了广泛的实验，并证明了E$^2$LMVSC可以与现有方法匹配性能，同时在大规模数据集中实现更高的 clustering 性能。<details>
<summary>Abstract</summary>
Recent multi-view subspace clustering achieves impressive results utilizing deep networks, where the self-expressive correlation is typically modeled by a fully connected (FC) layer. However, they still suffer from two limitations: i) it is under-explored to extract a unified representation from multiple views that simultaneously satisfy minimal sufficiency and discriminability. ii) the parameter scale of the FC layer is quadratic to the number of samples, resulting in high time and memory costs that significantly degrade their feasibility in large-scale datasets. In light of this, we propose a novel deep framework termed Efficient and Effective Large-scale Multi-View Subspace Clustering (E$^2$LMVSC). Specifically, to enhance the quality of the unified representation, a soft clustering assignment similarity constraint is devised for explicitly decoupling consistent, complementary, and superfluous information across multi-view data. Then, following information bottleneck theory, a sufficient yet minimal unified feature representation is obtained. Moreover, E$^2$LMVSC employs the maximal coding rate reduction principle to promote intra-cluster aggregation and inter-cluster separability within the unified representation. Finally, the self-expressive coefficients are learned by a Relation-Metric Net instead of a parameterized FC layer for greater efficiency. Extensive experiments show that E$^2$LMVSC yields comparable results to existing methods and achieves state-of-the-art clustering performance in large-scale multi-view datasets.
</details>
<details>
<summary>摘要</summary>
最近的多视图子空间分 clustering 技术已经取得了很好的成果，使用深度网络，其中自我表达相关性通常是使用全连接（FC）层来模型的。然而，它们仍然受到两种限制：一是不足地提取多视图数据中共同满足最小充分和分类可能性的统一表示。二是FC层的参数缺省是数据样本的平方，导致时间和内存成本很高，使其在大规模数据集中不可行。为此，我们提出了一种新的深度框架，称为高效高质量大规模多视图子空间分 clustering（E$^2$LMVSC）。Specifically, E$^2$LMVSC 使用软 clustering分配相似性约束，以解耦多视图数据中一致、补充和冗余信息的信息。然后，根据信息瓶颈理论，从多视图数据中获得最小充分的统一特征表示。此外，E$^2$LMVSC 使用最大编码率减少原理，以促进内群归一化和间群分离在统一表示中。最后，相关度 metric 网络代替 parameterized FC 层来学习自我表达系数，以提高效率。我们的实验表明，E$^2$LMVSC 与现有方法相当，并在大规模多视图数据集中实现了状态机器人的分 clustering性能。
</details></li>
</ul>
<hr>
<h2 id="LOVECon-Text-driven-Training-Free-Long-Video-Editing-with-ControlNet"><a href="#LOVECon-Text-driven-Training-Free-Long-Video-Editing-with-ControlNet" class="headerlink" title="LOVECon: Text-driven Training-Free Long Video Editing with ControlNet"></a>LOVECon: Text-driven Training-Free Long Video Editing with ControlNet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09711">http://arxiv.org/abs/2310.09711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhijie-group/lovecon">https://github.com/zhijie-group/lovecon</a></li>
<li>paper_authors: Zhenyi Liao, Zhijie Deng</li>
<li>for: 这 paper targets 长视频编辑 без需要训练，以满足电影制作、广告等领域的需求。</li>
<li>methods: 我们基于 ControlNet 建立了一个简单而有效的基线，通过将长视频分成窗口，并开发了一种跨窗口注意力机制来保证全局风格的一致性和最大化窗口之间的平滑性。 我们还利用 DDIM 逆转来提取源视频中的信息，并将其集成到生成过程中的秘密状态中。</li>
<li>results: 我们的方法在不同场景中（包括Attributes改变、风格传输和背景替换等）都显示出了超越基eline的效果，能够编辑长达 128 帧的视频 according to 用户需求。<details>
<summary>Abstract</summary>
Leveraging pre-trained conditional diffusion models for video editing without further tuning has gained increasing attention due to its promise in film production, advertising, etc. Yet, seminal works in this line fall short in generation length, temporal coherence, or fidelity to the source video. This paper aims to bridge the gap, establishing a simple and effective baseline for training-free diffusion model-based long video editing. As suggested by prior arts, we build the pipeline upon ControlNet, which excels at various image editing tasks based on text prompts. To break down the length constraints caused by limited computational memory, we split the long video into consecutive windows and develop a novel cross-window attention mechanism to ensure the consistency of global style and maximize the smoothness among windows. To achieve more accurate control, we extract the information from the source video via DDIM inversion and integrate the outcomes into the latent states of the generations. We also incorporate a video frame interpolation model to mitigate the frame-level flickering issue. Extensive empirical studies verify the superior efficacy of our method over competing baselines across scenarios, including the replacement of the attributes of foreground objects, style transfer, and background replacement. In particular, our method manages to edit videos with up to 128 frames according to user requirements. Code is available at https://github.com/zhijie-group/LOVECon.
</details>
<details>
<summary>摘要</summary>
利用预训练的条件扩散模型进行视频编辑，无需进一步调参，在电影制作、广告等领域受到了越来越多的关注。然而，先前的研究在这一领域缺乏长期编辑、时间准确性和原始视频忠实性等方面的表现。本文旨在填补这一空白，建立一个简单有效的基线方法，通过控制网络（ControlNet）和跨窗口注意力机制来实现无需训练的扩散模型基于长视频编辑。为了缓解由计算机内存限制所导致的长度约束，我们将长视频拆分成连续的窗口，并开发了一种新的跨窗口注意力机制，以保证全局风格的一致性和最大化窗口之间的平滑性。此外，我们还提取了源视频中的信息通过DDIM反向减法，并将其 интегрирова到生成过程中的幂态态中。此外，我们还添加了一种视频帧 interpolate模型，以减少帧级闪烁问题。经验研究表明，我们的方法在不同场景中，如改变对eground对象的特性、风格传递和背景替换等场景中，具有更高的效果，并能编辑长达128帧的视频。代码可以在https://github.com/zhijie-group/LOVECon中下载。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/15/cs.CV_2023_10_15/" data-id="clontc8jf00jg8788h6j3a94o" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_10_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/15/cs.AI_2023_10_15/" class="article-date">
  <time datetime="2023-10-15T12:00:00.000Z" itemprop="datePublished">2023-10-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/15/cs.AI_2023_10_15/">cs.AI - 2023-10-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="On-Statistical-Learning-of-Branch-and-Bound-for-Vehicle-Routing-Optimization"><a href="#On-Statistical-Learning-of-Branch-and-Bound-for-Vehicle-Routing-Optimization" class="headerlink" title="On Statistical Learning of Branch and Bound for Vehicle Routing Optimization"></a>On Statistical Learning of Branch and Bound for Vehicle Routing Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09986">http://arxiv.org/abs/2310.09986</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/isotlaboratory/ml4vrp">https://github.com/isotlaboratory/ml4vrp</a></li>
<li>paper_authors: Andrew Naguib, Waleed A. Yousef, Issa Traoré, Mohammad Mamun</li>
<li>for:  solve the capacitated vehicle routing problem (CVRP) using machine learning</li>
<li>methods:  utilize and compare the performance of three neural networks (GCNN, GraphSAGE, and GAT) to emulate the Strong Branching strategy</li>
<li>results:  match or improve upon the performance of the branch and bound algorithm with significantly less computational time<details>
<summary>Abstract</summary>
Recently, machine learning of the branch and bound algorithm has shown promise in approximating competent solutions to NP-hard problems. In this paper, we utilize and comprehensively compare the outcomes of three neural networks--graph convolutional neural network (GCNN), GraphSAGE, and graph attention network (GAT)--to solve the capacitated vehicle routing problem. We train these neural networks to emulate the decision-making process of the computationally expensive Strong Branching strategy. The neural networks are trained on six instances with distinct topologies from the CVRPLIB and evaluated on eight additional instances. Moreover, we reduced the minimum number of vehicles required to solve a CVRP instance to a bin-packing problem, which was addressed in a similar manner. Through rigorous experimentation, we found that this approach can match or improve upon the performance of the branch and bound algorithm with the Strong Branching strategy while requiring significantly less computational time. The source code that corresponds to our research findings and methodology is readily accessible and available for reference at the following web address: https://isotlaboratory.github.io/ml4vrp
</details>
<details>
<summary>摘要</summary>
近些时间，机器学习的分支和约束算法在解决NP困难问题中表现出了承诺。在这篇论文中，我们利用了三种神经网络--图 convolutional neural network (GCNN), GraphSAGE, 和 graph attention network (GAT) --来解决具有限制的车辆路径问题。我们使用这些神经网络来模拟计算成本较高的强分支策略的决策过程。我们在CVRPLIB中采样了六个不同的topology实例，并对八个额外实例进行了评估。此外，我们将CVRP实例中的最小车辆数量降低到了一个箱包问题，该问题在类似的方式进行了解决。经过严格的实验，我们发现这种方法可以与分支和约束算法中的强分支策略相匹配或超越性能，并且需要 significatively less computational time。相关的研究发现和方法的源代码可以在以下网址查看：https://isotlaboratory.github.io/ml4vrp
</details></li>
</ul>
<hr>
<h2 id="Farzi-Data-Autoregressive-Data-Distillation"><a href="#Farzi-Data-Autoregressive-Data-Distillation" class="headerlink" title="Farzi Data: Autoregressive Data Distillation"></a>Farzi Data: Autoregressive Data Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09983">http://arxiv.org/abs/2310.09983</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noveen Sachdeva, Zexue He, Wang-Cheng Kang, Jianmo Ni, Derek Zhiyuan Cheng, Julian McAuley</li>
<li>for: 本研究旨在为自动逆进机器学习任务提供数据减混技术，以便在训练大型模型时采用更小的数据量。</li>
<li>methods: 我们提出了一种名为“Farzi”的方法，它可以将输入和输出之间的紧密左右 causal 结构转化为一小批 synthetic 序列（Farzi Data），以保持或提高模型性能。 Farzi 在内部使用了高效的反向模板导数和积分产品来实现内存灵活的数据减混。</li>
<li>results: 我们在测试sequential recommendation和语言模型任务中，可以使用 Farzi Data 的0.1%到原始数据大小的比例来训练现代模型，并达到98-120%的下游全数据性能。这表明可以通过减少数据量来训练更好的模型，并开启了将来大型自动逆进机器学习模型的设计和数据量的扩展的新机遇。<details>
<summary>Abstract</summary>
We study data distillation for auto-regressive machine learning tasks, where the input and output have a strict left-to-right causal structure. More specifically, we propose Farzi, which summarizes an event sequence dataset into a small number of synthetic sequences -- Farzi Data -- which are optimized to maintain (if not improve) model performance compared to training on the full dataset. Under the hood, Farzi conducts memory-efficient data distillation by (i) deriving efficient reverse-mode differentiation of the Adam optimizer by leveraging Hessian-Vector Products; and (ii) factorizing the high-dimensional discrete event-space into a latent-space which provably promotes implicit regularization. Empirically, for sequential recommendation and language modeling tasks, we are able to achieve 98-120% of downstream full-data performance when training state-of-the-art models on Farzi Data of size as little as 0.1% of the original dataset. Notably, being able to train better models with significantly less data sheds light on the design of future large auto-regressive models, and opens up new opportunities to further scale up model and data sizes.
</details>
<details>
<summary>摘要</summary>
我们研究数据简化技术，用于自动递归学习任务，输入和输出具有约束性的左向 causal 结构。我们提出了 Farzi，它将事件序列数据总结为一小数量的 sintetic 序列 -- Farzi 数据 -- 以保持（或更好）模型性能相对训练全 dataset。在实现方面，Farzi 实现了内存有效的数据简化，通过以下两个方法：(i) 通过利用 Hessian-Vector Products 来 derivate Adam 优化器的逆向Mode 导数，实现高效的数据简化。(ii) 通过 факторизе 高维 discrete 事件空间为尺度空间，实现隐式 regularization。在实验中，我们在序列推荐和自然语言处理任务中，可以使用 Farzi 数据训练现有模型，达到了原始数据的 98-120% 的下游性能。这表明可以通过减少数据量训练更好的模型，为未来大型自动递归模型的设计提供了新的思路，并开创了训练模型和数据量的新机遇。
</details></li>
</ul>
<hr>
<h2 id="Chinese-Painting-Style-Transfer-Using-Deep-Generative-Models"><a href="#Chinese-Painting-Style-Transfer-Using-Deep-Generative-Models" class="headerlink" title="Chinese Painting Style Transfer Using Deep Generative Models"></a>Chinese Painting Style Transfer Using Deep Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09978">http://arxiv.org/abs/2310.09978</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanyangbaobeiisemma/chinsepaintingstyletransfer">https://github.com/yanyangbaobeiisemma/chinsepaintingstyletransfer</a></li>
<li>paper_authors: Weijian Ma, Yanyang Kong</li>
<li>for: 本研究旨在将传统中国画风 transferred to modern images like nature objects, portraits and landscapes.</li>
<li>methods: 我们将使用 state-of-the-art deep generative models for Chinese painting style transfer, 并评估其表现 both qualitatively and quantitatively. 此外，我们还提出了一种 combining several style transfer models for our task.</li>
<li>results: 我们将在本研究中评估和比较不同的深度生成模型在传统中国画风转移 task 中的表现, 并提出一种新的方法 combination 多种风格转移模型。<details>
<summary>Abstract</summary>
Artistic style transfer aims to modify the style of the image while preserving its content. Style transfer using deep learning models has been widely studied since 2015, and most of the applications are focused on specific artists like Van Gogh, Monet, Cezanne. There are few researches and applications on traditional Chinese painting style transfer. In this paper, we will study and leverage different state-of-the-art deep generative models for Chinese painting style transfer and evaluate the performance both qualitatively and quantitatively. In addition, we propose our own algorithm that combines several style transfer models for our task. Specifically, we will transfer two main types of traditional Chinese painting style, known as "Gong-bi" and "Shui-mo" (to modern images like nature objects, portraits and landscapes.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文化风格转移目的是对图像的风格进行修改，保留其内容。 Deep learning模型在2015年之后广泛研究了风格转移，大多数应用都是专注于特定艺术家如万高、蒙德、刺激。有很少的研究和应用在传统中国画风格转移方面。在这篇论文中，我们将研究和利用不同的国际先进的生成模型进行中国画风格转移，评估其性能 both qualitatively和quantitatively。此外，我们还提出了我们自己的算法，将多种风格转移模型结合起来用于我们的任务。具体来说，我们将将“公笔”和“水墨”两种传统中国画风格转移到现代图像中，如自然景观、人像和风景等。Translation notes:* "Gong-bi" (工笔) and "Shui-mo" (水墨) are two main types of traditional Chinese painting styles.* "公笔" and "水墨" are both translated as "Chinese painting style" in the text, but they refer to different specific styles.* "国际先进的生成模型" (international advanced generative models) is a phrase used to refer to state-of-the-art deep learning models.* "qualitatively" and "quantitatively" are both translated as "both qualitatively and quantitatively" in the text, but "qualitatively" refers to the subjective evaluation of the results, while "quantitatively" refers to the objective evaluation using metrics such as PSNR or SSIM.
</details></li>
</ul>
<hr>
<h2 id="Specialized-Deep-Residual-Policy-Safe-Reinforcement-Learning-Based-Controller-for-Complex-and-Continuous-State-Action-Spaces"><a href="#Specialized-Deep-Residual-Policy-Safe-Reinforcement-Learning-Based-Controller-for-Complex-and-Continuous-State-Action-Spaces" class="headerlink" title="Specialized Deep Residual Policy Safe Reinforcement Learning-Based Controller for Complex and Continuous State-Action Spaces"></a>Specialized Deep Residual Policy Safe Reinforcement Learning-Based Controller for Complex and Continuous State-Action Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.14788">http://arxiv.org/abs/2310.14788</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ammar-n-abbas/CoL-SDRPRL">https://github.com/ammar-n-abbas/CoL-SDRPRL</a></li>
<li>paper_authors: Ammar N. Abbas, Georgios C. Chasparis, John D. Kelleher</li>
<li>For: The paper is written to address the limitations of traditional controllers in safety-critical environments, and to propose a specialized deep reinforcement learning approach for complex and continuous state-action spaces.* Methods: The paper proposes a cycle of learning approach that combines residual policy learning with expert trajectory guidance, and specializes the policy through input-output hidden Markov model to optimize the policy within the region of interest.* Results: The proposed solution is validated on the Tennessee Eastman process control, and the results show that the hybrid control architecture that combines the reinforcement learning agent with the conventional controller can improve the control performance and adapt to abnormal situations.Here’s the simplified Chinese text for the three key points:* For: 这篇论文是为了解决传统控制器在安全关键环境中的局限性，并提出一种特殊的深度强化学习方法来处理复杂的状态动作空间。* Methods: 论文提出了一种循环学习方法， combining residual policy learning with expert trajectory guidance, 并通过输入输出隐马尔可夫模型特化策略以优化策略在兴趣区域内。* Results: 论文在田州东曼过程控制中验证了该解决方案，结果显示了hybrid控制架构， combining reinforcement learning agent和传统控制器，可以提高控制性能并适应异常情况。<details>
<summary>Abstract</summary>
Traditional controllers have limitations as they rely on prior knowledge about the physics of the problem, require modeling of dynamics, and struggle to adapt to abnormal situations. Deep reinforcement learning has the potential to address these problems by learning optimal control policies through exploration in an environment. For safety-critical environments, it is impractical to explore randomly, and replacing conventional controllers with black-box models is also undesirable. Also, it is expensive in continuous state and action spaces, unless the search space is constrained. To address these challenges we propose a specialized deep residual policy safe reinforcement learning with a cycle of learning approach adapted for complex and continuous state-action spaces. Residual policy learning allows learning a hybrid control architecture where the reinforcement learning agent acts in synchronous collaboration with the conventional controller. The cycle of learning initiates the policy through the expert trajectory and guides the exploration around it. Further, the specialization through the input-output hidden Markov model helps to optimize policy that lies within the region of interest (such as abnormality), where the reinforcement learning agent is required and is activated. The proposed solution is validated on the Tennessee Eastman process control.
</details>
<details>
<summary>摘要</summary>
传统控制器有限制，因为它们基于前期知识，需要动态模型化，并且在异常情况下表现不佳。深度权值学习有可能解决这些问题，通过环境中的探索学习优化控制策略。但是，在安全关键环境下，随机探索是不现实istic，而替换传统控制器的黑obox模型也不符合意愿。此外，在连续状态和动作空间中进行搜索也是昂贵的。为了解决这些挑战，我们提出了特殊化的深度剩余政策安全权值学习，采用环境中的循环学习策略。剩余政策学习允许在传统控制器和权值学习代理之间同步协作，并且通过输入-输出隐藏马尔可夫模型进行特殊化，以便优化政策，使其在特定区域（如异常情况）中表现最佳。我们的解决方案在田中东曼制程控制中得到验证。
</details></li>
</ul>
<hr>
<h2 id="Seeking-Next-Layer-Neurons’-Attention-for-Error-Backpropagation-Like-Training-in-a-Multi-Agent-Network-Framework"><a href="#Seeking-Next-Layer-Neurons’-Attention-for-Error-Backpropagation-Like-Training-in-a-Multi-Agent-Network-Framework" class="headerlink" title="Seeking Next Layer Neurons’ Attention for Error-Backpropagation-Like Training in a Multi-Agent Network Framework"></a>Seeking Next Layer Neurons’ Attention for Error-Backpropagation-Like Training in a Multi-Agent Network Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09952">http://arxiv.org/abs/2310.09952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arshia Soltani Moakhar, Mohammad Azizmalayeri, Hossein Mirzaei, Mohammad Taghi Manzuri, Mohammad Hossein Rohban<br>for: 这 paper 的目的是提出一种基于 local objective 的多智能体神经网络训练方法，以提高神经网络在实际问题中的应用性。methods: 该 paper 使用了一种基于自利 Interest 的神经网络模型，并对其进行了优化。在这种模型中，每个神经元尝试通过 Maximizing 其自己的局部目标来适应神经网络的训练。results: 该 paper 通过三个数据集的实验表明，使用这种方法可以提高神经网络在快速学习和牵扯问题中的性能，并在灾变性学习测试中超过 error-backpropagation。<details>
<summary>Abstract</summary>
Despite considerable theoretical progress in the training of neural networks viewed as a multi-agent system of neurons, particularly concerning biological plausibility and decentralized training, their applicability to real-world problems remains limited due to scalability issues. In contrast, error-backpropagation has demonstrated its effectiveness for training deep networks in practice. In this study, we propose a local objective for neurons that, when pursued by neurons individually, align them to exhibit similarities to error-backpropagation in terms of efficiency and scalability during training. For this purpose, we examine a neural network comprising decentralized, self-interested neurons seeking to maximize their local objective -- attention from subsequent layer neurons -- and identify the optimal strategy for neurons. We also analyze the relationship between this strategy and backpropagation, establishing conditions under which the derived strategy is equivalent to error-backpropagation. Lastly, we demonstrate the learning capacity of these multi-agent neural networks through experiments on three datasets and showcase their superior performance relative to error-backpropagation in a catastrophic forgetting benchmark.
</details>
<details>
<summary>摘要</summary>
具有很大理论进步的神经网络 viewed as a multi-agent system of neurons 的训练，特别是生物可能性和分散式训练，却因为扩展性问题而受限。相比之下，错误反射法在实务中证明了它的有效性 для 训练深度网络。在这篇研究中，我们提出了一个本地目标 для neurons，使得它们个别努力以获得类似于错误反射法的有效性和扩展性 durante 训练。为了实现这个目标，我们对一个分散式、自利 neurons 组成的神经网络进行了分析，并找到了最佳策略 для neurons。我们还分析了这策略和错误反射之间的关系，并证明了在某些情况下， derivated 策略与错误反射法相同。最后，我们透过实验证明了这些多客体神经网络的学习能力，并在三个数据集上显示了它们的超越性。
</details></li>
</ul>
<hr>
<h2 id="Chameleon-a-Heterogeneous-and-Disaggregated-Accelerator-System-for-Retrieval-Augmented-Language-Models"><a href="#Chameleon-a-Heterogeneous-and-Disaggregated-Accelerator-System-for-Retrieval-Augmented-Language-Models" class="headerlink" title="Chameleon: a Heterogeneous and Disaggregated Accelerator System for Retrieval-Augmented Language Models"></a>Chameleon: a Heterogeneous and Disaggregated Accelerator System for Retrieval-Augmented Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09949">http://arxiv.org/abs/2310.09949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenqi Jiang, Marco Zeller, Roger Waleffe, Torsten Hoefler, Gustavo Alonso<br>methods: 该研究使用了一种约束语言模型（LM）和检索器的异质加速器系统，以提高LM的执行效率。results: 研究发现，使用Chameleon系统可以实现23.72倍的速度提升和26.2倍的能效率提升，相比CPU和GPU vector搜索系统。此外，Chameleon系统在不同RALM配置下可以实现1.16倍的响应时间减少和3.18倍的速度提升。<details>
<summary>Abstract</summary>
A Retrieval-Augmented Language Model (RALM) augments a generative language model by retrieving context-specific knowledge from an external database. This strategy facilitates impressive text generation quality even with smaller models, thus reducing orders of magnitude of computational demands. However, RALMs introduce unique system design challenges due to (a) the diverse workload characteristics between LM inference and retrieval and (b) the various system requirements and bottlenecks for different RALM configurations such as model sizes, database sizes, and retrieval frequencies. We propose Chameleon, a heterogeneous accelerator system that integrates both LM and retrieval accelerators in a disaggregated architecture. The heterogeneity ensures efficient acceleration of both LM inference and retrieval, while the accelerator disaggregation enables the system to independently scale both types of accelerators to fulfill diverse RALM requirements. Our Chameleon prototype implements retrieval accelerators on FPGAs and assigns LM inference to GPUs, with a CPU server orchestrating these accelerators over the network. Compared to CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x speedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon exhibits up to 2.16x reduction in latency and 3.18x speedup in throughput compared to the hybrid CPU-GPU architecture. These promising results pave the way for bringing accelerator heterogeneity and disaggregation into future RALM systems.
</details>
<details>
<summary>摘要</summary>
一种叫做Retrieval-Augmented Language Model（RALM）的语言模型可以通过从外部数据库中获取上下文特定的知识来增强生成语言模型。这种策略使得even with smaller models可以达到出色的文本生成质量，从而降低了计算需求的级别。然而，RALM引入了一些独特的系统设计挑战，包括（a）语言模型推理和检索工作负荷的多样性，以及（b）不同的RALM配置，如模型大小、数据库大小和检索频率等的系统需求和瓶颈。我们提出了一种叫做Chameleon的异步加速器系统，它将语言模型推理和检索加速器分解成不同的硬件模块。这种多样性和分解使得系统可以独立地扩展两类加速器，以满足不同的RALM需求。我们的Chameleon原型在FPGA上实现检索加速器，并将语言模型推理分配给GPU。CPU服务器通过网络管理这些加速器。相比CPU基于和CPU-GPU вектор搜索系统，Chameleon可以达到23.72倍的速度提升和26.2倍的能效率提升。在不同的RALM系统上进行了评估，Chameleon可以减少响应时间2.16倍，提高通过put Throughput 3.18倍。这些出色的结果铺平了将加速器多样性和分解引入未来RALM系统的道路。
</details></li>
</ul>
<hr>
<h2 id="“Reading-Between-the-Heat”-Co-Teaching-Body-Thermal-Signatures-for-Non-intrusive-Stress-Detection"><a href="#“Reading-Between-the-Heat”-Co-Teaching-Body-Thermal-Signatures-for-Non-intrusive-Stress-Detection" class="headerlink" title="“Reading Between the Heat”: Co-Teaching Body Thermal Signatures for Non-intrusive Stress Detection"></a>“Reading Between the Heat”: Co-Teaching Body Thermal Signatures for Non-intrusive Stress Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09932">http://arxiv.org/abs/2310.09932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Xiao, Harshit Sharma, Zhongyang Zhang, Dessa Bergen-Cico, Tauhidur Rahman, Asif Salekin</li>
<li>for: 这 paper 是为了开发一种可靠的、无接触的indoor stress监测系统，用于评估工作场所产能、智能家庭和个性化心理健康监测。</li>
<li>methods: 这 paper 使用了 ThermaStrain，一种共同教学框架，将穿戴式 electrodermal activity (EDA) 传感器和无接触thermal感知结合使用，以提高无接触stress监测的精度。</li>
<li>results: 这 paper 的实验结果表明，ThermaStrain 可以在不同的距离和压力情况下，实现高精度的stress分类，并且在实时执行、边缘计算和多个人感知方面表现出色。<details>
<summary>Abstract</summary>
Stress impacts our physical and mental health as well as our social life. A passive and contactless indoor stress monitoring system can unlock numerous important applications such as workplace productivity assessment, smart homes, and personalized mental health monitoring. While the thermal signatures from a user's body captured by a thermal camera can provide important information about the "fight-flight" response of the sympathetic and parasympathetic nervous system, relying solely on thermal imaging for training a stress prediction model often lead to overfitting and consequently a suboptimal performance. This paper addresses this challenge by introducing ThermaStrain, a novel co-teaching framework that achieves high-stress prediction performance by transferring knowledge from the wearable modality to the contactless thermal modality. During training, ThermaStrain incorporates a wearable electrodermal activity (EDA) sensor to generate stress-indicative representations from thermal videos, emulating stress-indicative representations from a wearable EDA sensor. During testing, only thermal sensing is used, and stress-indicative patterns from thermal data and emulated EDA representations are extracted to improve stress assessment. The study collected a comprehensive dataset with thermal video and EDA data under various stress conditions and distances. ThermaStrain achieves an F1 score of 0.8293 in binary stress classification, outperforming the thermal-only baseline approach by over 9%. Extensive evaluations highlight ThermaStrain's effectiveness in recognizing stress-indicative attributes, its adaptability across distances and stress scenarios, real-time executability on edge platforms, its applicability to multi-individual sensing, ability to function on limited visibility and unfamiliar conditions, and the advantages of its co-teaching approach.
</details>
<details>
<summary>摘要</summary>
压力会影响我们的身体和心理健康以及我们的社会生活。一个不需要接触和干预的indoor压力监测系统可以开启多个重要应用程序，如工作场所产量评估、智能家庭和个性化压力监测。而thermal图像中的用户体表的热签ature可以提供关键的“战斗或逃脱”压力反应信息，但凭借热成像alone来训练压力预测模型可能会导致过拟合，从而影响性能。这篇论文解决了这个挑战，通过引入ThermaStrain，一种新的合作学习框架，实现高精度压力预测表现。在训练过程中，ThermaStrain使用了一个穿着式电导活动（EDA）传感器，将热成像中的压力指示符转换为穿着式EDA传感器的压力指示符，以便在训练过程中增强模型的鲁棒性。在测试过程中，只使用热成像，从热成像和模拟EDA表示中提取压力指示符，以提高压力评估。研究采集了包括热成像和EDA数据在内的全面数据集，ThermaStrain在二分类压力预测中取得F1分数为0.8293，在热成像基eline方法上出performancedoor9%。广泛的评估表明ThermaStrain具有识别压力指示符的能力，适应不同距离和压力情况，实时执行在边缘平台上，适用于多个个体感知，在有限视力和不熟悉情况下可行，以及合作学习的优势。
</details></li>
</ul>
<hr>
<h2 id="Estimating-Uncertainty-in-Multimodal-Foundation-Models-using-Public-Internet-Data"><a href="#Estimating-Uncertainty-in-Multimodal-Foundation-Models-using-Public-Internet-Data" class="headerlink" title="Estimating Uncertainty in Multimodal Foundation Models using Public Internet Data"></a>Estimating Uncertainty in Multimodal Foundation Models using Public Internet Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09926">http://arxiv.org/abs/2310.09926</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AlaaLab/WebCP">https://github.com/AlaaLab/WebCP</a></li>
<li>paper_authors: Shiladitya Dutta, Hongbo Wei, Lars van der Laan, Ahmed M. Alaa</li>
<li>for: 这种论文是为了解决零shot预测中的不确定性问题。</li>
<li>methods: 该论文使用了自我超vised学习，并在测试时使用CLIP样式模型进行零shot分类。它还使用了一种新的协Forms score来衡量预测的可靠性。</li>
<li>results: 研究人员通过使用web数据进行 calibration，实现了针对各种生物医学数据集的零shot预测。他们的初步结果表明，通过在测试时使用网络上的calibration数据，可以实现预测的目标覆盖率，并且效率相对较高。<details>
<summary>Abstract</summary>
Foundation models are trained on vast amounts of data at scale using self-supervised learning, enabling adaptation to a wide range of downstream tasks. At test time, these models exhibit zero-shot capabilities through which they can classify previously unseen (user-specified) categories. In this paper, we address the problem of quantifying uncertainty in these zero-shot predictions. We propose a heuristic approach for uncertainty estimation in zero-shot settings using conformal prediction with web data. Given a set of classes at test time, we conduct zero-shot classification with CLIP-style models using a prompt template, e.g., "an image of a <category>", and use the same template as a search query to source calibration data from the open web. Given a web-based calibration set, we apply conformal prediction with a novel conformity score that accounts for potential errors in retrieved web data. We evaluate the utility of our proposed method in Biomedical foundation models; our preliminary results show that web-based conformal prediction sets achieve the target coverage with satisfactory efficiency on a variety of biomedical datasets.
</details>
<details>
<summary>摘要</summary>
基础模型通过大规模数据的自我超vision学习训练，可以适应各种下游任务。在测试时，这些模型可以通过零批预测来分类之前未看到的类别。在这篇论文中，我们解决了零批预测中的uncertainty量化问题。我们提出了一种启发式方法，使用web数据来实现零批预测中的uncertainty估计。给定一组测试时的类别，我们使用CLIP样式的模型进行零批分类，使用提示模板，例如“一张<类别>的图像”，并使用相同的模板作为搜索关键词来源网络数据。给定一个网络基础的核心集，我们应用彩色预测技术，使用一种新的彩色度分数，考虑可能存在的网络数据错误。我们对生物基础模型进行了初步的实验结果，表明在各种生物数据集上，网络基础的彩色预测集可以达到目标覆盖率，并且具有满意的效率。
</details></li>
</ul>
<hr>
<h2 id="Homophone-Disambiguation-Reveals-Patterns-of-Context-Mixing-in-Speech-Transformers"><a href="#Homophone-Disambiguation-Reveals-Patterns-of-Context-Mixing-in-Speech-Transformers" class="headerlink" title="Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers"></a>Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09925">http://arxiv.org/abs/2310.09925</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hmohebbi/ContextMixingASR">https://github.com/hmohebbi/ContextMixingASR</a></li>
<li>paper_authors: Hosein Mohebbi, Grzegorz Chrupała, Willem Zuidema, Afra Alishahi</li>
<li>for: This paper aims to investigate how measures of ‘context-mixing’ developed for text models can be adapted and applied to models of spoken language, specifically in the case of homophony in French.</li>
<li>methods: The authors use a series of controlled experiments and probing analyses on Transformer-based speech models to explore how representations in encoder-only models and encoder-decoder models incorporate syntactic cues to identify the correct transcription.</li>
<li>results: The authors find that representations in encoder-only models effectively incorporate these cues, while encoders in encoder-decoder models mainly relegate the task of capturing contextual dependencies to decoder modules.<details>
<summary>Abstract</summary>
Transformers have become a key architecture in speech processing, but our understanding of how they build up representations of acoustic and linguistic structure is limited. In this study, we address this gap by investigating how measures of 'context-mixing' developed for text models can be adapted and applied to models of spoken language. We identify a linguistic phenomenon that is ideal for such a case study: homophony in French (e.g. livre vs livres), where a speech recognition model has to attend to syntactic cues such as determiners and pronouns in order to disambiguate spoken words with identical pronunciations and transcribe them while respecting grammatical agreement. We perform a series of controlled experiments and probing analyses on Transformer-based speech models. Our findings reveal that representations in encoder-only models effectively incorporate these cues to identify the correct transcription, whereas encoders in encoder-decoder models mainly relegate the task of capturing contextual dependencies to decoder modules.
</details>
<details>
<summary>摘要</summary>
听说模型已成为语音处理中关键的建筑，但我们对它们如何建立语音和文本结构的表示还是有限的。在这项研究中，我们尝试将文本模型中的'上下文混合'度量应用到语音模型中，以更好地理解它们如何建立表示。我们选择了一种语言现象，即法语中的同音异义（例如，"livre" vs "livres"），这种现象需要语音识别模型通过 determiners 和 Pronouns 等语法提示来纠正 spoken 词的意思，并且将其转录为句子中的正确形式。我们进行了一系列控制的实验和探索分析，发现encoder-only模型中的表示能够有效地捕捉这些语法提示，而encoder-decoder模型中的encoder模块主要通过decoder模块来捕捉上下文关系。
</details></li>
</ul>
<hr>
<h2 id="Predictive-Maintenance-Model-Based-on-Anomaly-Detection-in-Induction-Motors-A-Machine-Learning-Approach-Using-Real-Time-IoT-Data"><a href="#Predictive-Maintenance-Model-Based-on-Anomaly-Detection-in-Induction-Motors-A-Machine-Learning-Approach-Using-Real-Time-IoT-Data" class="headerlink" title="Predictive Maintenance Model Based on Anomaly Detection in Induction Motors: A Machine Learning Approach Using Real-Time IoT Data"></a>Predictive Maintenance Model Based on Anomaly Detection in Induction Motors: A Machine Learning Approach Using Real-Time IoT Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.14949">http://arxiv.org/abs/2310.14949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sergio F. Chevtchenko, Monalisa C. M. dos Santos, Diego M. Vieira, Ricardo L. Mota, Elisson Rocha, Bruna V. Cruz, Danilo Araújo, Ermeson Andrade</li>
<li>for: 本研究旨在透过互联网路物 (IoT) 设备收集腐败现象数据，并运用数据驱动模型进行异常检测在工业设备中。</li>
<li>methods: 本研究使用了一组融合预处理技术和机器学习 (ML) 模型，包括快速傅立叶 transform (FFT)、波лет трансформа (WT) 和分割，以提取数据的特征。 本研究还使用多目标优化和分析以保证异常检测率、假阳性率和推论速率之间的最佳平衡。</li>
<li>results: 本研究获得了一系列的实验结果，证明了融合预处理技术和 ML 模型可以实现高精度异常检测，并且可以在不同的工业上适用。<details>
<summary>Abstract</summary>
With the support of Internet of Things (IoT) devices, it is possible to acquire data from degradation phenomena and design data-driven models to perform anomaly detection in industrial equipment. This approach not only identifies potential anomalies but can also serve as a first step toward building predictive maintenance policies. In this work, we demonstrate a novel anomaly detection system on induction motors used in pumps, compressors, fans, and other industrial machines. This work evaluates a combination of pre-processing techniques and machine learning (ML) models with a low computational cost. We use a combination of pre-processing techniques such as Fast Fourier Transform (FFT), Wavelet Transform (WT), and binning, which are well-known approaches for extracting features from raw data. We also aim to guarantee an optimal balance between multiple conflicting parameters, such as anomaly detection rate, false positive rate, and inference speed of the solution. To this end, multiobjective optimization and analysis are performed on the evaluated models. Pareto-optimal solutions are presented to select which models have the best results regarding classification metrics and computational effort. Differently from most works in this field that use publicly available datasets to validate their models, we propose an end-to-end solution combining low-cost and readily available IoT sensors. The approach is validated by acquiring a custom dataset from induction motors. Also, we fuse vibration, temperature, and noise data from these sensors as the input to the proposed ML model. Therefore, we aim to propose a methodology general enough to be applied in different industrial contexts in the future.
</details>
<details>
<summary>摘要</summary>
“利用互联网络器件（IoT），可以从损坏现象中获取数据，设计数据驱动的模型以进行异常检测在工业设备中。这种方法不仅可以检测出可能的异常，而且可以作为建立预测维护政策的第一步。在这个工作中，我们展示了一个新的异常检测系统，应用于对发电机（induction motor）进行验证。这个工作使用了一组合的预处理技术，包括快速傅立叶变换（FFT）、wavelet变换（WT）和分割，这些技术都是抽象数据的常用方法。我们还希望确保多项衡量的依势关系，例如异常检测率、伪阳性率和推理速度，得到一个优化的解。为达到这个目的，我们进行多目标优化和分析。得到的 pareto 最佳解可以选择最佳的模型，以及评估这些模型的数据驱动和计算成本。不同于大多数在这个领域中使用公开available的数据集来验证他们的模型，我们提出了一个终端解决方案， combining 低成本和易于入手的 IoT 感应器。我们将这种方法应用于不同的工业上下，以提高维护效率和降低成本。”
</details></li>
</ul>
<hr>
<h2 id="Lifelong-Sequence-Generation-with-Dynamic-Module-Expansion-and-Adaptation"><a href="#Lifelong-Sequence-Generation-with-Dynamic-Module-Expansion-and-Adaptation" class="headerlink" title="Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation"></a>Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09886">http://arxiv.org/abs/2310.09886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengwei Qin, Chen Chen, Shafiq Joty</li>
<li>for: 解决 continual learning 中的 Life-long Sequence Generation (LSG) 问题，即在不断训练模型的同时，总结出来的新生成模式，而不是忘记之前的知识。</li>
<li>methods: 我们提出了 Dynamic Module Expansion and Adaptation (DMEA) 方法，即在任务相似性的基础上动态决定模型需要的架构，并选择最相似的先前任务来促进新任务的适应性。同时，我们还提出了动态梯度缩放，以保持当前任务和先前任务的学习平衡。</li>
<li>results: 通过广泛的实验，我们示出了 DMEA 可以在不同的 LSG 设定下表现出色，常常超越现有的方法。<details>
<summary>Abstract</summary>
Lifelong sequence generation (LSG), a problem in continual learning, aims to continually train a model on a sequence of generation tasks to learn constantly emerging new generation patterns while avoiding the forgetting of previous knowledge. Existing LSG methods mainly focus on maintaining old knowledge while paying little attention to knowledge transfer across tasks. In contrast, humans can better learn new tasks by leveraging previously acquired knowledge from similar tasks. Inspired by the learning paradigm of humans, we propose Dynamic Module Expansion and Adaptation (DMEA), which enables the model to dynamically determine the architecture for acquiring new knowledge based on task correlation and select the most similar previous tasks to facilitate adaptation to new tasks. In addition, as the learning process can easily be biased towards the current task which might cause more severe forgetting of previously learned knowledge, we propose dynamic gradient scaling to balance the learning of the current task and replayed tasks. With extensive experiments, we demonstrate that DMEA can consistently outperform existing methods in different LSG settings.
</details>
<details>
<summary>摘要</summary>
这是一个生命长序列生成（LSG）问题，它是一种持续学习的问题，旨在不断训练一个模型，以学习不断出现的新生成模式，而且避免遗传知识的忘记。现有的LSG方法主要是维护古代知识，对任务之间的知识传递甚少关注。然而，人类在学习新任务时，可以更好地利用先前所获得的知识，以便更好地适应新任务。受人类学习模式启发，我们提出了动态模组扩展和适应（DMEA）方法，让模型在任务相似度和先前任务之间进行动态决定模组架构，并选择最相似的先前任务来促进新任务的适应。此外，当学习过程可能会偏向现在任务，导致更严重的知识忘记，我们提出了动态GradientScaling来均衡现在任务和重复任务的学习。经过广泛的实验，我们证明了DMEA可以在不同的LSG设定中具有优秀的表现。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Learning-with-Iterative-Demonstration-Selection"><a href="#In-Context-Learning-with-Iterative-Demonstration-Selection" class="headerlink" title="In-Context Learning with Iterative Demonstration Selection"></a>In-Context Learning with Iterative Demonstration Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09881">http://arxiv.org/abs/2310.09881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengwei Qin, Aston Zhang, Anirudh Dagar, Wenming Ye</li>
<li>for: 提高大语言模型（LLM）在几个示例下学习中的表现。</li>
<li>methods: Iterative Demonstration Selection（IDS）方法，使用零shot chain-of-thoughtreasoning（Zero-shot-CoT）选择示例，并在多个迭代中选择最佳示例。</li>
<li>results: 在多个任务上，包括通用理解、问答、话题分类和情感分析，IDS方法可以一直 exceed 现有的ICL示例选择方法。<details>
<summary>Abstract</summary>
Spurred by advancements in scale, large language models (LLMs) have demonstrated strong few-shot learning ability via in-context learning (ICL). However, the performance of ICL has been shown to be highly sensitive to the selection of few-shot demonstrations. Selecting the most suitable examples as context remains an ongoing challenge and an open problem. Existing literature has highlighted the importance of selecting examples that are diverse or semantically similar to the test sample while ignoring the fact that the optimal selection dimension, i.e., diversity or similarity, is task-specific. Leveraging the merits of both dimensions, we propose Iterative Demonstration Selection (IDS). Using zero-shot chain-of-thought reasoning (Zero-shot-CoT), IDS iteratively selects examples that are diverse but still strongly correlated with the test sample as ICL demonstrations. Specifically, IDS applies Zero-shot-CoT to the test sample before demonstration selection. The output reasoning path is then used to choose demonstrations that are prepended to the test sample for inference. The generated answer is accompanied by its corresponding reasoning path for extracting a new set of demonstrations in the next iteration. After several iterations, IDS adopts majority voting to obtain the final result. Through extensive experiments on tasks including commonsense reasoning, question answering, topic classification, and sentiment analysis, we demonstrate that IDS can consistently outperform existing ICL demonstration selection methods.
</details>
<details>
<summary>摘要</summary>
促进了规模的进步，大语言模型（LLM）在内容学习（ICL）中表现出了强大的几个示例学习能力。然而，ICL表现的选择示例仍然是一个持续的挑战和开放问题。现有的文献强调选择测试样本中的多样化或semantic相似的示例，而忽略了任务特定的最佳选择维度。基于这两个维度的优点，我们提出了迭代示例选择（IDS）。IDS使用零实例链条思维（Zero-shot-CoT）来选择示例，其中逻辑路径是在测试样本之前应用于测试样本。然后，选择的示例将被附加到测试样本中进行INF的推理。生成的答案将被 accompanied by its corresponding reasoning path，以提取新的示例集。经过多轮迭代，IDS采用多数投票方式获得最终结果。我们通过对常识推理、问答、话题分类和情感分析等任务进行广泛的实验，证明IDS可以一直性能高于现有的ICL示例选择方法。
</details></li>
</ul>
<hr>
<h2 id="Statistical-inference-using-machine-learning-and-classical-techniques-based-on-accumulated-local-effects-ALE"><a href="#Statistical-inference-using-machine-learning-and-classical-techniques-based-on-accumulated-local-effects-ALE" class="headerlink" title="Statistical inference using machine learning and classical techniques based on accumulated local effects (ALE)"></a>Statistical inference using machine learning and classical techniques based on accumulated local effects (ALE)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09877">http://arxiv.org/abs/2310.09877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chitu Okoli</li>
<li>for: 这篇论文主要是为了提出一种model-agnostic的方法来进行黑盒机器学习（ML）算法的全面解释。</li>
<li>methods: 这篇论文使用了ALE（Accumulated Local Effects）模型无关的方法来进行解释，并提出了一些新的统计推断方法来解决小样本大小的问题，以及在ML数据分析中对变量的总效果的INTRODUCTION。</li>
<li>results: 这篇论文提出了一些实用的解决方案，包括在ALE分析中确保可靠性，以及在ML数据分析中对变量的总效果进行INTRODUCTION。这些解决方案可以帮助更好地进行ML数据分析和统计推断。<details>
<summary>Abstract</summary>
Accumulated Local Effects (ALE) is a model-agnostic approach for global explanations of the results of black-box machine learning (ML) algorithms. There are at least three challenges with conducting statistical inference based on ALE: ensuring the reliability of ALE analyses, especially in the context of small datasets; intuitively characterizing a variable's overall effect in ML; and making robust inferences from ML data analysis. In response, we introduce innovative tools and techniques for statistical inference using ALE, establishing bootstrapped confidence intervals tailored to dataset size and introducing ALE effect size measures that intuitively indicate effects on both the outcome variable scale and a normalized scale. Furthermore, we demonstrate how to use these tools to draw reliable statistical inferences, reflecting the flexible patterns ALE adeptly highlights, with implementations available in the 'ale' package in R. This work propels the discourse on ALE and its applicability in ML and statistical analysis forward, offering practical solutions to prevailing challenges in the field.
</details>
<details>
<summary>摘要</summary>
集成本地效应（ALE）是一种模型不依赖的方法，用于全面解释黑盒机器学习（ML）算法的结果。在进行统计推断基于ALE时，存在至少三个挑战：确保ALE分析的可靠性，特别是在小数据集中；Intuitively characterize a variable's overall effect in ML;和从ML数据分析中获得可靠的推断。为此，我们介绍了新的工具和技术，用于基于ALE的统计推断，包括适应 dataset 大小的 bootstrap 信任区间和 ALE 效果大小度量，这些度量可以直观地反映变量对结果变量的影响和Normalized 比例。此外，我们示例了如何使用这些工具来提取可靠的统计推断，反映 ALE 灵活地高亮的各种模式，R 中的 'ale' 包提供了实现。这项工作推动了 ALE 在 ML 和统计分析领域的应用前进，提供了实用的解决方案，用于解决领域中的挑战。
</details></li>
</ul>
<hr>
<h2 id="Federated-Multi-Objective-Learning"><a href="#Federated-Multi-Objective-Learning" class="headerlink" title="Federated Multi-Objective Learning"></a>Federated Multi-Objective Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09866">http://arxiv.org/abs/2310.09866</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Zakaria-Dahi/Multi-Objective_Optimiser_For_Federated_Learning">https://github.com/Zakaria-Dahi/Multi-Objective_Optimiser_For_Federated_Learning</a></li>
<li>paper_authors: Haibo Yang, Zhuqing Liu, Jia Liu, Chaosheng Dong, Michinari Momma</li>
<li>for:  Multi-agent multi-task learning applications with distributed nature and data privacy needs.</li>
<li>methods: Federated multi-objective learning (FMOL) framework with multiple clients distributively and collaboratively solving an MOO problem while keeping their training data private.</li>
<li>results: Proposed two new federated multi-objective optimization (FMOO) algorithms called federated multi-gradient descent averaging (FMGDA) and federated stochastic multi-gradient descent averaging (FSMGDA), which allow local updates to significantly reduce communication costs, while achieving the same convergence rates as those of their algorithmic counterparts in the single-objective federated learning.<details>
<summary>Abstract</summary>
In recent years, multi-objective optimization (MOO) emerges as a foundational problem underpinning many multi-agent multi-task learning applications. However, existing algorithms in MOO literature remain limited to centralized learning settings, which do not satisfy the distributed nature and data privacy needs of such multi-agent multi-task learning applications. This motivates us to propose a new federated multi-objective learning (FMOL) framework with multiple clients distributively and collaboratively solving an MOO problem while keeping their training data private. Notably, our FMOL framework allows a different set of objective functions across different clients to support a wide range of applications, which advances and generalizes the MOO formulation to the federated learning paradigm for the first time. For this FMOL framework, we propose two new federated multi-objective optimization (FMOO) algorithms called federated multi-gradient descent averaging (FMGDA) and federated stochastic multi-gradient descent averaging (FSMGDA). Both algorithms allow local updates to significantly reduce communication costs, while achieving the {\em same} convergence rates as those of their algorithmic counterparts in the single-objective federated learning. Our extensive experiments also corroborate the efficacy of our proposed FMOO algorithms.
</details>
<details>
<summary>摘要</summary>
To solve the FMOL problem, we propose two new federated multi-objective optimization (FMOO) algorithms, called federated multi-gradient descent averaging (FMGDA) and federated stochastic multi-gradient descent averaging (FSMGDA). Both algorithms allow for local updates to significantly reduce communication costs, while achieving the same convergence rates as their algorithmic counterparts in single-objective federated learning. Our extensive experiments also demonstrate the effectiveness of our proposed FMOO algorithms.
</details></li>
</ul>
<hr>
<h2 id="Federated-Reinforcement-Learning-for-Resource-Allocation-in-V2X-Networks"><a href="#Federated-Reinforcement-Learning-for-Resource-Allocation-in-V2X-Networks" class="headerlink" title="Federated Reinforcement Learning for Resource Allocation in V2X Networks"></a>Federated Reinforcement Learning for Resource Allocation in V2X Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09858">http://arxiv.org/abs/2310.09858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaidi Xu, Shenglong Zhou, Geoffrey Ye Li</li>
<li>for: 这个论文是用来研究车至所有东西（V2X）网络资源分配的最佳化方法。</li>
<li>methods: 这个论文使用联邦强化学习（FRL）框架，并使用不精确的方向分解方法（ADMM）来解决资源分配问题。</li>
<li>results: 这个论文的结果显示，使用PASM算法可以实现资源分配问题的最佳化，并且比一些基于估计的方法具有更好的数字性表现。<details>
<summary>Abstract</summary>
Resource allocation significantly impacts the performance of vehicle-to-everything (V2X) networks. Most existing algorithms for resource allocation are based on optimization or machine learning (e.g., reinforcement learning). In this paper, we explore resource allocation in a V2X network under the framework of federated reinforcement learning (FRL). On one hand, the usage of RL overcomes many challenges from the model-based optimization schemes. On the other hand, federated learning (FL) enables agents to deal with a number of practical issues, such as privacy, communication overhead, and exploration efficiency. The framework of FRL is then implemented by the inexact alternative direction method of multipliers (ADMM), where subproblems are solved approximately using policy gradients and accelerated by an adaptive step size calculated from their second moments. The developed algorithm, PASM, is proven to be convergent under mild conditions and has a nice numerical performance compared with some baseline methods for solving the resource allocation problem in a V2X network.
</details>
<details>
<summary>摘要</summary>
资源分配对于 vehicle-to-everything（V2X）网络的性能有着重要的影响。大多数现有的资源分配算法基于优化或机器学习（例如，强化学习）。在这篇论文中，我们explore V2X网络中的资源分配问题在 federated reinforcement learning（FRL）框架下。一方面，RL可以超越许多模型基于优化方案中的挑战。另一方面，联邦学习（FL）可以帮助代理人处理一些实际问题，如隐私、通信开销和探索效率。然后，FRL框架被实现通过不确定多члены方法（ADMM），其中子问题被解决approximately使用政策偏导和加速器是根据其第二次 moments。开发的算法，PASM，在一定的条件下被证明是收敛的，并与一些基准方法相比有良好的数值性能。
</details></li>
</ul>
<hr>
<h2 id="MERTech-Instrument-Playing-Technique-Detection-Using-Self-Supervised-Pretrained-Model-With-Multi-Task-Finetuning"><a href="#MERTech-Instrument-Playing-Technique-Detection-Using-Self-Supervised-Pretrained-Model-With-Multi-Task-Finetuning" class="headerlink" title="MERTech: Instrument Playing Technique Detection Using Self-Supervised Pretrained Model With Multi-Task Finetuning"></a>MERTech: Instrument Playing Technique Detection Using Self-Supervised Pretrained Model With Multi-Task Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09853">http://arxiv.org/abs/2310.09853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dichucheng Li, Yinghao Ma, Weixing Wei, Qiuqiang Kong, Yulun Wu, Mingjin Che, Fan Xia, Emmanouil Benetos, Wei Li</li>
<li>for: 本研究旨在提出一种自动检测乐器演奏技巧（IPT）的方法，以解决数据稀缺和类别不均匀问题。</li>
<li>methods: 该方法利用自动学习模型，先在大规模无标签音乐数据上进行自动学习，然后在IPT检测任务上练习 fine-tuning。此外，还 investigate了多任务融合finetuning，包括抑制和识别抑制的多个任务。</li>
<li>results: 该方法在多个IPT标准测试集上比过去的方法表现出色，在 Frame-level和事件-level度量中均显示出优异性。此外，多任务融合finetuning也能够提高每个IPT类别的准确率。<details>
<summary>Abstract</summary>
Instrument playing techniques (IPTs) constitute a pivotal component of musical expression. However, the development of automatic IPT detection methods suffers from limited labeled data and inherent class imbalance issues. In this paper, we propose to apply a self-supervised learning model pre-trained on large-scale unlabeled music data and finetune it on IPT detection tasks. This approach addresses data scarcity and class imbalance challenges. Recognizing the significance of pitch in capturing the nuances of IPTs and the importance of onset in locating IPT events, we investigate multi-task finetuning with pitch and onset detection as auxiliary tasks. Additionally, we apply a post-processing approach for event-level prediction, where an IPT activation initiates an event only if the onset output confirms an onset in that frame. Our method outperforms prior approaches in both frame-level and event-level metrics across multiple IPT benchmark datasets. Further experiments demonstrate the efficacy of multi-task finetuning on each IPT class.
</details>
<details>
<summary>摘要</summary>
To further enhance performance, we investigate multi-task finetuning with pitch and onset detection as auxiliary tasks. Pitch is essential for capturing the nuances of IPTs, while onset information is critical for locating IPT events. We also apply a post-processing approach for event-level prediction, where an IPT activation is only triggered if the onset output confirms an onset in that frame.Our method outperforms prior approaches in both frame-level and event-level metrics across multiple IPT benchmark datasets. Additionally, we demonstrate the effectiveness of multi-task finetuning on each IPT class. Our approach provides a significant improvement in IPT detection accuracy, addressing the challenges of limited labeled data and class imbalance issues.
</details></li>
</ul>
<hr>
<h2 id="ACES-Generating-Diverse-Programming-Puzzles-with-Autotelic-Language-Models-and-Semantic-Descriptors"><a href="#ACES-Generating-Diverse-Programming-Puzzles-with-Autotelic-Language-Models-and-Semantic-Descriptors" class="headerlink" title="ACES: Generating Diverse Programming Puzzles with Autotelic Language Models and Semantic Descriptors"></a>ACES: Generating Diverse Programming Puzzles with Autotelic Language Models and Semantic Descriptors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10692">http://arxiv.org/abs/2310.10692</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julien Pourcel, Cédric Colas, Pierre-Yves Oudeyer, Laetitia Teodorescu</li>
<li>For: studying automated problem generation in the context of python programming puzzles, with a focus on interesting diversity optimization.* Methods: using semantic descriptors produced by a large language model (LLM) to directly optimize for interesting diversity, as well as few-shot-based generation.* Results: discovering a richer diversity of puzzles than existing diversity-maximizing algorithms, as measured across a range of diversity metrics.<details>
<summary>Abstract</summary>
Finding and selecting new and interesting problems to solve is at the heart of curiosity, science and innovation. We here study automated problem generation in the context of the open-ended space of python programming puzzles. Existing generative models often aim at modeling a reference distribution without any explicit diversity optimization. Other methods explicitly optimizing for diversity do so either in limited hand-coded representation spaces or in uninterpretable learned embedding spaces that may not align with human perceptions of interesting variations. With ACES (Autotelic Code Exploration via Semantic descriptors), we introduce a new autotelic generation method that leverages semantic descriptors produced by a large language model (LLM) to directly optimize for interesting diversity, as well as few-shot-based generation. Each puzzle is labeled along 10 dimensions, each capturing a programming skill required to solve it. ACES generates and pursues novel and feasible goals to explore that abstract semantic space, slowly discovering a diversity of solvable programming puzzles in any given run. Across a set of experiments, we show that ACES discovers a richer diversity of puzzles than existing diversity-maximizing algorithms as measured across a range of diversity metrics. We further study whether and in which conditions this diversity can translate into the successful training of puzzle solving models.
</details>
<details>
<summary>摘要</summary>
寻找和选择新领域的问题是感知、科学和创新的核心。我们在python编程练习中的开放式空间中研究自动生成问题。现有的生成模型通常是模型参考分布而不是直接优化多样性。其他方法通过手动编码的表示空间或学习的嵌入空间来显式地优化多样性，但这些方法可能并不与人类的意义变化相匹配。我们在ACES（自动telic代码探索 via 语义描述符）中引入了一种新的自动telic生成方法，利用大语言模型生成的语义描述符直接优化有趣的多样性，以及几招学习。每个练习都被标记了10个维度，每个维度捕捉一个需要解决它的编程技能。ACES生成和追求新的可行目标，慢慢发现任务抽象 semantic空间中的多样性，在任务执行中逐渐发现可解决的编程练习。在一系列实验中，我们发现ACES在多样性度量上比现有的多样性最大化算法更加丰富。我们进一步研究是否和在哪些条件下，这种多样性可以导致练习解决模型的成功培训。
</details></li>
</ul>
<hr>
<h2 id="CoCoFormer-A-controllable-feature-rich-polyphonic-music-generation-method"><a href="#CoCoFormer-A-controllable-feature-rich-polyphonic-music-generation-method" class="headerlink" title="CoCoFormer: A controllable feature-rich polyphonic music generation method"></a>CoCoFormer: A controllable feature-rich polyphonic music generation method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09843">http://arxiv.org/abs/2310.09843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuyang Zhou, Tengfei Niu, Hong Zhu, Xingping Wang</li>
<li>for: 本研究探讨了多重音乐序列的模型化方法，尤其是使用 transformer 模型进行可控音乐生成。</li>
<li>methods: 本研究提出了 Condition Choir Transformer（CoCoFormer）模型，通过控制输出模型的逻辑和拍子输入来实现精细化控制。同时，通过自我超VI等方法进行验证和训练。</li>
<li>results: 实验表明，CoCoFormer 模型在指定多重音乐Texture时，可以生成多种不同的同一首歌曲，并且达到了当前最佳水平。<details>
<summary>Abstract</summary>
This paper explores the modeling method of polyphonic music sequence. Due to the great potential of Transformer models in music generation, controllable music generation is receiving more attention. In the task of polyphonic music, current controllable generation research focuses on controlling the generation of chords, but lacks precise adjustment for the controllable generation of choral music textures. This paper proposed Condition Choir Transformer (CoCoFormer) which controls the output of the model by controlling the chord and rhythm inputs at a fine-grained level. In this paper, the self-supervised method improves the loss function and performs joint training through conditional control input and unconditional input training. In order to alleviate the lack of diversity on generated samples caused by the teacher forcing training, this paper added an adversarial training method. CoCoFormer enhances model performance with explicit and implicit inputs to chords and rhythms. In this paper, the experiments proves that CoCoFormer has reached the current better level than current models. On the premise of specifying the polyphonic music texture, the same melody can also be generated in a variety of ways.
</details>
<details>
<summary>摘要</summary>
The paper uses a self-supervised method to improve the loss function and performs joint training through conditional control input and unconditional input training. To alleviate the lack of diversity in generated samples caused by teacher forcing training, the paper adds an adversarial training method. CoCoFormer enhances model performance with explicit and implicit inputs to chords and rhythms.Experiments show that CoCoFormer has reached a current better level than current models. With the premise of specifying the polyphonic music texture, the same melody can also be generated in a variety of ways.Translation notes:* "polyphonic music sequence" is translated as "多重音乐序列" (polytrophic music sequence)* "Transformer models" is translated as "变换器模型" (transformer models)* "controllable music generation" is translated as "可控音乐生成" (controllable music generation)* "chord" is translated as "和声" (chord)* "rhythm" is translated as "拍" (rhythm)* "self-supervised method" is translated as "自我指导方法" (self-supervised method)* "adversarial training method" is translated as "对抗训练方法" (adversarial training method)* "CoCoFormer" is translated as "CoCoFormer" (CoCoFormer)* "polyphonic music texture" is translated as "多重音乐Texture" (polyphonic music texture)* "melody" is translated as "旋律" (melody)
</details></li>
</ul>
<hr>
<h2 id="Explaining-How-a-Neural-Network-Play-the-Go-Game-and-Let-People-Learn"><a href="#Explaining-How-a-Neural-Network-Play-the-Go-Game-and-Let-People-Learn" class="headerlink" title="Explaining How a Neural Network Play the Go Game and Let People Learn"></a>Explaining How a Neural Network Play the Go Game and Let People Learn</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09838">http://arxiv.org/abs/2310.09838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huilin Zhou, Huijie Tang, Mingjie Li, Hao Zhang, Zhenyu Liu, Quanshi Zhang</li>
<li>for: 本研究的目的是解释Go游戏中AI模型所编码的知识，并使用这些知识来教育人类玩家。</li>
<li>methods: 本研究使用了Value网络来提取Go游戏中石头之间的交互 primitives，以便人类可以从Value网络中学习准确和可靠的知识。</li>
<li>results: 实验表明，我们的方法可以有效地提取Go游戏中AI模型所编码的知识，并帮助人类玩家更好地理解和掌握Go游戏。<details>
<summary>Abstract</summary>
The AI model has surpassed human players in the game of Go, and it is widely believed that the AI model has encoded new knowledge about the Go game beyond human players. In this way, explaining the knowledge encoded by the AI model and using it to teach human players represent a promising-yet-challenging issue in explainable AI. To this end, mathematical supports are required to ensure that human players can learn accurate and verifiable knowledge, rather than specious intuitive analysis. Thus, in this paper, we extract interaction primitives between stones encoded by the value network for the Go game, so as to enable people to learn from the value network. Experiments show the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
人工智能模型已经在围棋游戏中超越人类玩家，而且广泛认为该模型已经编码了人类玩家之外的新知识。因此，解释AI模型所编码的知识并使用其教育人类玩家是一项有前途又挑战的问题。为此，我们需要有数学支持，以确保人类玩家可以学习准确和可靠的知识，而不是基于假设的直觉分析。在本文中，我们提取了围棋中石头之间的互动基本原理，以便让人类玩家从值网络中学习。实验表明我们的方法的效果。
</details></li>
</ul>
<hr>
<h2 id="MIR2-Towards-Provably-Robust-Multi-Agent-Reinforcement-Learning-by-Mutual-Information-Regularization"><a href="#MIR2-Towards-Provably-Robust-Multi-Agent-Reinforcement-Learning-by-Mutual-Information-Regularization" class="headerlink" title="MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by Mutual Information Regularization"></a>MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by Mutual Information Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09833">http://arxiv.org/abs/2310.09833</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simin Li, Ruixiao Xu, Jun Guo, Pu Feng, Jiakai Wang, Aishan Liu, Yaodong Yang, Xianglong Liu, Weifeng Lv</li>
<li>for: 这篇论文的目的是提出一种robust多代理学习（MARL）方法，以增强对不确定或最坏情况的抗性。</li>
<li>methods: 该方法使用policy学习在 Routine Scenarios 中训练，并使用Mutual Information as Robust Regularization来避免过度优化。</li>
<li>results: 对于StarCraft II、Multi-agent Mujoco和 rendezvous 等场景，MIR2方法显示了更高的抗性性能，并且在实际应用中的 robot 群集控制场景中也表现出了优异性能。<details>
<summary>Abstract</summary>
Robust multi-agent reinforcement learning (MARL) necessitates resilience to uncertain or worst-case actions by unknown allies. Existing max-min optimization techniques in robust MARL seek to enhance resilience by training agents against worst-case adversaries, but this becomes intractable as the number of agents grows, leading to exponentially increasing worst-case scenarios. Attempts to simplify this complexity often yield overly pessimistic policies, inadequate robustness across scenarios and high computational demands. Unlike these approaches, humans naturally learn adaptive and resilient behaviors without the necessity of preparing for every conceivable worst-case scenario. Motivated by this, we propose MIR2, which trains policy in routine scenarios and minimize Mutual Information as Robust Regularization. Theoretically, we frame robustness as an inference problem and prove that minimizing mutual information between histories and actions implicitly maximizes a lower bound on robustness under certain assumptions. Further analysis reveals that our proposed approach prevents agents from overreacting to others through an information bottleneck and aligns the policy with a robust action prior. Empirically, our MIR2 displays even greater resilience against worst-case adversaries than max-min optimization in StarCraft II, Multi-agent Mujoco and rendezvous. Our superiority is consistent when deployed in challenging real-world robot swarm control scenario. See code and demo videos in Supplementary Materials.
</details>
<details>
<summary>摘要</summary>
多智能体强化学习（MARL）需要对不确定或最坏情况的行动具备抗性。现有的最大最小优化技术在Robust MARL中增强抗性，但随着智能体数量增加，最坏情况的数量将 exponentiation 增长，导致计算量过高。尝试简化这种复杂性通常会导致过度保守的策略，不足robustness across scenarios和高计算需求。与这些方法不同，人类自然地学习了适应和抗性行为，无需为每个可能的最坏情况做准备。 inspirited by this，我们提出了MIR2，它在 Routine scenarios 中训练策略，并将 Mutual Information 作为Robust Regularization 来最小化。从理论角度来看，我们将robustness 视为一个推理问题，并证明在某些假设下，将mutual information between histories and actions 最小化会implicitly 最大化一个下界于robustness的lower bound。进一步的分析表明，我们的提posed approach prevent agents from overreacting to others through an information bottleneck，并使策略与一个robust action prior 吻合。Empirically，我们的MIR2在StarCraft II, Multi-agent Mujoco和 rendezvous 中对最坏情况的抗性性能更高than max-min optimization。我们的superiority 在Real-world robot swarm control scenario 中也是一致的。参考代码和示例视频在Supplementary Materials中。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-for-In-Context-Student-Modeling-Synthesizing-Student’s-Behavior-in-Visual-Programming-from-One-Shot-Observation"><a href="#Large-Language-Models-for-In-Context-Student-Modeling-Synthesizing-Student’s-Behavior-in-Visual-Programming-from-One-Shot-Observation" class="headerlink" title="Large Language Models for In-Context Student Modeling: Synthesizing Student’s Behavior in Visual Programming from One-Shot Observation"></a>Large Language Models for In-Context Student Modeling: Synthesizing Student’s Behavior in Visual Programming from One-Shot Observation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10690">http://arxiv.org/abs/2310.10690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manh Hung Nguyen, Sebastian Tschiatschek, Adish Singla</li>
<li>for:  This paper is written for researchers and practitioners in the field of educational technology, particularly those interested in student modeling and personalized learning.</li>
<li>methods:  The paper explores the use of Large Language Models (LLMs) for in-context student modeling in open-ended learning environments. The proposed framework, LLM-SS, leverages LLMs to synthesize a student’s behavior based on their solving attempts on a reference task. The authors fine-tune LLMs using domain-specific expertise to improve their understanding of domain background and student behaviors.</li>
<li>results:  The paper reports significant improvements in student behavior synthesis compared to baseline methods included in the StudentSyn benchmark. Specifically, the method using the fine-tuned Llama2-70B model improves noticeably compared to using the base model and becomes on par with using the state-of-the-art GPT-4 model.<details>
<summary>Abstract</summary>
Student modeling is central to many educational technologies as it enables the prediction of future learning outcomes and targeted instructional strategies. However, open-ended learning environments pose challenges for accurately modeling students due to the diverse behaviors exhibited by students and the absence of a well-defined set of learning skills. To approach these challenges, we explore the application of Large Language Models (LLMs) for in-context student modeling in open-ended learning environments. We introduce a novel framework, LLM-SS, that leverages LLMs for synthesizing student's behavior. More concretely, given a particular student's solving attempt on a reference task as observation, the goal is to synthesize the student's attempt on a target task. Our framework can be combined with different LLMs; moreover, we fine-tune LLMs using domain-specific expertise to boost their understanding of domain background and student behaviors. We evaluate several concrete methods based on LLM-SS using the StudentSyn benchmark, an existing student's attempt synthesis benchmark in visual programming. Experimental results show a significant improvement compared to baseline methods included in the StudentSyn benchmark. Furthermore, our method using the fine-tuned Llama2-70B model improves noticeably compared to using the base model and becomes on par with using the state-of-the-art GPT-4 model.
</details>
<details>
<summary>摘要</summary>
We propose a novel framework, LLM-SS, which leverages LLMs to synthesize a student's behavior. Given a particular student's attempt at a reference task, the goal is to synthesize their attempt on a target task. Our framework can be combined with different LLMs, and we fine-tune these models using domain-specific expertise to improve their understanding of the domain background and student behaviors.We evaluate several concrete methods based on LLM-SS using the StudentSyn benchmark, an existing student attempt synthesis benchmark in visual programming. The results show a significant improvement compared to baseline methods included in the StudentSyn benchmark. Additionally, our method using the fine-tuned Llama2-70B model improves noticeably compared to using the base model and is on par with using the state-of-the-art GPT-4 model.
</details></li>
</ul>
<hr>
<h2 id="Optimizing-K-means-for-Big-Data-A-Comparative-Study"><a href="#Optimizing-K-means-for-Big-Data-A-Comparative-Study" class="headerlink" title="Optimizing K-means for Big Data: A Comparative Study"></a>Optimizing K-means for Big Data: A Comparative Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09819">http://arxiv.org/abs/2310.09819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ravil Mussabayev, Rustam Mussabayev</li>
<li>for: 这篇论文旨在比较不同优化技术对K-means算法的应用在大数据场景中的影响。</li>
<li>methods: 论文描述了不同的优化技术，包括并行、简化、采样等方法，以解决K-means算法在大数据场景中的缺乏扩展性问题。</li>
<li>results: 作者通过对各种标准数据集进行比较，发现不同的技术在不同的数据集上的表现不同，并提供了关于速度和准确性之间的负担平衡的理解。<details>
<summary>Abstract</summary>
This paper presents a comparative analysis of different optimization techniques for the K-means algorithm in the context of big data. K-means is a widely used clustering algorithm, but it can suffer from scalability issues when dealing with large datasets. The paper explores different approaches to overcome these issues, including parallelization, approximation, and sampling methods. The authors evaluate the performance of these techniques on various benchmark datasets and compare them in terms of speed, quality of clustering, and scalability according to the LIMA dominance criterion. The results show that different techniques are more suitable for different types of datasets and provide insights into the trade-offs between speed and accuracy in K-means clustering for big data. Overall, the paper offers a comprehensive guide for practitioners and researchers on how to optimize K-means for big data applications.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这篇论文提出了对K-means算法的不同优化技术进行比较分析，以帮助在大数据场景下使用K-means算法。K-means算法广泛使用，但是它在处理大数据时可能会遇到扩展性问题。论文探讨了不同的方法来解决这些问题，包括并行、 aproximation 和采样方法。作者对这些技术在不同的测试数据集上进行评估，并根据LIMA主导因素来比较它们的速度、归一化质量和可扩展性。结果显示不同的技术适用于不同的数据类型，并提供了关于速度和准确性在K-means归一化中的贸易OFF的深入理解。总之，这篇论文为实践者和研究人员提供了一份全面的指南，以帮助他们在大数据应用中优化K-means算法。
</details></li>
</ul>
<hr>
<h2 id="Negative-Sampling-with-Adaptive-Denoising-Mixup-for-Knowledge-Graph-Embedding"><a href="#Negative-Sampling-with-Adaptive-Denoising-Mixup-for-Knowledge-Graph-Embedding" class="headerlink" title="Negative Sampling with Adaptive Denoising Mixup for Knowledge Graph Embedding"></a>Negative Sampling with Adaptive Denoising Mixup for Knowledge Graph Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09781">http://arxiv.org/abs/2310.09781</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DeMix2023/Demix">https://github.com/DeMix2023/Demix</a></li>
<li>paper_authors: Xiangnan Chen, Wen Zhang, Zhen Yao, Mingyang Chen, Siliang Tang</li>
<li>for: 本研究旨在提高知识图（KG）中entity和relation embedding的质量，通过减少负样本中的噪声。</li>
<li>methods: 提议使用一种混合策略，通过自我supervised的方式来更新负样本，从而提高KGE的训练效果。</li>
<li>results: 实验结果表明，提议的DeMix方法可以更好地减少负样本中的噪声，使KGE更快地训练到更好的链接预测结果。<details>
<summary>Abstract</summary>
Knowledge graph embedding (KGE) aims to map entities and relations of a knowledge graph (KG) into a low-dimensional and dense vector space via contrasting the positive and negative triples. In the training process of KGEs, negative sampling is essential to find high-quality negative triples since KGs only contain positive triples. Most existing negative sampling methods assume that non-existent triples with high scores are high-quality negative triples. However, negative triples sampled by these methods are likely to contain noise. Specifically, they ignore that non-existent triples with high scores might also be true facts due to the incompleteness of KGs, which are usually called false negative triples. To alleviate the above issue, we propose an easily pluggable denoising mixup method called DeMix, which generates high-quality triples by refining sampled negative triples in a self-supervised manner. Given a sampled unlabeled triple, DeMix firstly classifies it into a marginal pseudo-negative triple or a negative triple based on the judgment of the KGE model itself. Secondly, it selects an appropriate mixup partner for the current triple to synthesize a partially positive or a harder negative triple. Experimental results on the knowledge graph completion task show that the proposed DeMix is superior to other negative sampling techniques, ensuring corresponding KGEs a faster convergence and better link prediction results.
</details>
<details>
<summary>摘要</summary>
知识图embedding（KGE）目的是将知识图（KG）中的实体和关系映射到一个低维度和紧凑的向量空间，通过对正确和错误 triplets进行对比。在KGE训练过程中，负样本是关键的，因为KG只包含正确的 triplets。现有的负样本方法假设高分负样本是高质量的负样本，但这些负样本可能含有噪声。Specifically, these methods ignore the fact that high-scoring non-existent triplets may be true facts due to the incompleteness of KGs, which are called false negative triplets. To address this issue, we propose an easily pluggable denoising mixup method called DeMix, which generates high-quality triples by refining sampled negative triples in a self-supervised manner. Given a sampled unlabeled triple, DeMix first classifies it into a marginal pseudo-negative triple or a negative triple based on the judgment of the KGE model itself. Secondly, it selects an appropriate mixup partner for the current triple to synthesize a partially positive or a harder negative triple. Experimental results on the knowledge graph completion task show that the proposed DeMix is superior to other negative sampling techniques, ensuring corresponding KGEs a faster convergence and better link prediction results.
</details></li>
</ul>
<hr>
<h2 id="Notes-on-Applicability-of-Explainable-AI-Methods-to-Machine-Learning-Models-Using-Features-Extracted-by-Persistent-Homology"><a href="#Notes-on-Applicability-of-Explainable-AI-Methods-to-Machine-Learning-Models-Using-Features-Extracted-by-Persistent-Homology" class="headerlink" title="Notes on Applicability of Explainable AI Methods to Machine Learning Models Using Features Extracted by Persistent Homology"></a>Notes on Applicability of Explainable AI Methods to Machine Learning Models Using Features Extracted by Persistent Homology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09780">http://arxiv.org/abs/2310.09780</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naofumihama/xai_ph_ml">https://github.com/naofumihama/xai_ph_ml</a></li>
<li>paper_authors: Naofumi Hama</li>
<li>For: The paper explores the potential application of explainable AI methodologies to the persistent homology (PH)-machine learning (ML) pipeline for predicting gas adsorption in metal-organic frameworks.* Methods: The paper uses the PH-ML pipeline to extract features from topological data analysis and applies explainable AI methodologies to improve the interpretability of the results.* Results: The paper demonstrates suggestive results for predicting gas adsorption in metal-organic frameworks using the PH-ML pipeline with explainable AI methodologies. The codes to reproduce the results are available on GitHub.Here is the same information in Simplified Chinese text:* For: 本文探讨PH-ML管线在预测金属组织材料中气吸附过程中的可读性。* Methods: 本文使用PH-ML管线提取特征，并应用可读性AI方法来提高结果的解释性。* Results: 本文提出了预测金属组织材料中气吸附过程中的可读性结果，并提供了在GitHub上可重现的代码。<details>
<summary>Abstract</summary>
Data analysis that uses the output of topological data analysis as input for machine learning algorithms has been the subject of extensive research. This approach offers a means of capturing the global structure of data. Persistent homology (PH), a common methodology within the field of TDA, has found wide-ranging applications in machine learning. One of the key reasons for the success of the PH-ML pipeline lies in the deterministic nature of feature extraction conducted through PH. The ability to achieve satisfactory levels of accuracy with relatively simple downstream machine learning models, when processing these extracted features, underlines the pipeline's superior interpretability. However, it must be noted that this interpretation has encountered issues. Specifically, it fails to accurately reflect the feasible parameter region in the data generation process, and the physical or chemical constraints that restrict this process. Against this backdrop, we explore the potential application of explainable AI methodologies to this PH-ML pipeline. We apply this approach to the specific problem of predicting gas adsorption in metal-organic frameworks and demonstrate that it can yield suggestive results. The codes to reproduce our results are available at https://github.com/naofumihama/xai_ph_ml
</details>
<details>
<summary>摘要</summary>
研究使用 topological data analysis（TDA）的输出作为机器学习算法的输入的数据分析方法已经得到了广泛的研究。这种方法可以捕捉数据的全局结构。 persistent homology（PH）是TDA领域中常用的方法ологи，在机器学习领域也有广泛的应用。PH-ML管道的成功一个关键原因在于PH的干扰特征，这使得可以使用简单的下游机器学习模型达到高度的准确性。然而，这种解释存在一些问题，它无法准确地反映数据生成过程中可行的参数范围和物理或化学约束。为了解决这些问题，我们研究了使用可解释AI方法ologies来解释PH-ML管道。我们在预测金属组分材料中的气体吸附问题中应用了这种方法，并证明了它可以提供有价值的结果。codes可以在https://github.com/naofumihama/xai_ph_ml中找到。
</details></li>
</ul>
<hr>
<h2 id="Worst-Case-Analysis-is-Maximum-A-Posteriori-Estimation"><a href="#Worst-Case-Analysis-is-Maximum-A-Posteriori-Estimation" class="headerlink" title="Worst-Case Analysis is Maximum-A-Posteriori Estimation"></a>Worst-Case Analysis is Maximum-A-Posteriori Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09774">http://arxiv.org/abs/2310.09774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongjun Wu, Di Wang</li>
<li>for: 这种软件工程任务中的性能优化和算法复杂性找出缺陷。</li>
<li>methods: 使用一种通用、适应和有 garantía的随机探测框架，称为DSE-SMC，来估计最坏情况的资源使用。</li>
<li>results: 对 Java 应用程序进行实验评估，得到了 DSE-SMC 比现有黑盒随机探测方法更有效。<details>
<summary>Abstract</summary>
The worst-case resource usage of a program can provide useful information for many software-engineering tasks, such as performance optimization and algorithmic-complexity-vulnerability discovery. This paper presents a generic, adaptive, and sound fuzzing framework, called DSE-SMC, for estimating worst-case resource usage. DSE-SMC is generic because it is black-box as long as the user provides an interface for retrieving resource-usage information on a given input; adaptive because it automatically balances between exploration and exploitation of candidate inputs; and sound because it is guaranteed to converge to the true resource-usage distribution of the analyzed program.   DSE-SMC is built upon a key observation: resource accumulation in a program is isomorphic to the soft-conditioning mechanism in Bayesian probabilistic programming; thus, worst-case resource analysis is isomorphic to the maximum-a-posteriori-estimation problem of Bayesian statistics. DSE-SMC incorporates sequential Monte Carlo (SMC) -- a generic framework for Bayesian inference -- with adaptive evolutionary fuzzing algorithms, in a sound manner, i.e., DSE-SMC asymptotically converges to the posterior distribution induced by resource-usage behavior of the analyzed program. Experimental evaluation on Java applications demonstrates that DSE-SMC is significantly more effective than existing black-box fuzzing methods for worst-case analysis.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "The worst-case resource usage of a program can provide useful information for many software-engineering tasks, such as performance optimization and algorithmic-complexity-vulnerability discovery. This paper presents a generic, adaptive, and sound fuzzing framework, called DSE-SMC, for estimating worst-case resource usage. DSE-SMC is generic because it is black-box as long as the user provides an interface for retrieving resource-usage information on a given input; adaptive because it automatically balances between exploration and exploitation of candidate inputs; and sound because it is guaranteed to converge to the true resource-usage distribution of the analyzed program.   DSE-SMC is built upon a key observation: resource accumulation in a program is isomorphic to the soft-conditioning mechanism in Bayesian probabilistic programming; thus, worst-case resource analysis is isomorphic to the maximum-a-posteriori-estimation problem of Bayesian statistics. DSE-SMC incorporates sequential Monte Carlo (SMC) -- a generic framework for Bayesian inference -- with adaptive evolutionary fuzzing algorithms, in a sound manner, i.e., DSE-SMC asymptotically converges to the posterior distribution induced by resource-usage behavior of the analyzed program. Experimental evaluation on Java applications demonstrates that DSE-SMC is significantly more effective than existing black-box fuzzing methods for worst-case analysis."into Simplified Chinese:<<SYS>>将程序的最差情况资源使用情况提供有用信息，用于软件工程各种任务，如性能优化和漏极性漏极性检测。本文介绍了一种通用、适应、有Sound的异步爬虫框架，称为DSE-SMC，用于估计最差情况资源使用。DSE-SMC是通用的，因为它可以透过输入的接口获取资源使用信息; 适应的，因为它会自动考虑探索和利用候选输入; 和有Sound的，因为它可以保证对分析程序的资源使用行为进行正确的拟合。 DSE-SMC基于资源寄生在程序中的软件条件机制，因此最差情况资源分析与 bayesian probabilistic programming 中的最大 posterior estimation 归一化。 DSE-SMC通过将 Bayesian 推理框架sequential Monte Carlo (SMC) 与适应演化爬虫算法相结合，实现了一种有Sound的方法。实验结果表明，DSE-SMC在 Java 应用程序上比现有的黑盒爬虫方法更有效。
</details></li>
</ul>
<hr>
<h2 id="A-Critical-Survey-on-Fairness-Benefits-of-XAI"><a href="#A-Critical-Survey-on-Fairness-Benefits-of-XAI" class="headerlink" title="A Critical Survey on Fairness Benefits of XAI"></a>A Critical Survey on Fairness Benefits of XAI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.13007">http://arxiv.org/abs/2310.13007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Deck, Jakob Schoeffer, Maria De-Arteaga, Niklas Kühl</li>
<li>for: 这些研究旨在探讨可解释人工智能（XAI）与公平性之间的关系，并寻找XAI如何实现公平性的方法。</li>
<li>methods: 这些研究使用系统性的文献复查和后续的质量分析，找到了175篇关于XAI是如何提供公平性的纷争性的论文。</li>
<li>results: 研究发现了7种典型的声索，即XAI可以帮助实现多种公平性标准。但是，研究还发现了这些声索的一些重要的限制和困难。<details>
<summary>Abstract</summary>
In this critical survey, we analyze typical claims on the relationship between explainable AI (XAI) and fairness to disentangle the multidimensional relationship between these two concepts. Based on a systematic literature review and a subsequent qualitative content analysis, we identify seven archetypal claims from 175 papers on the alleged fairness benefits of XAI. We present crucial caveats with respect to these claims and provide an entry point for future discussions around the potentials and limitations of XAI for specific fairness desiderata. While the literature often suggests XAI to be an enabler for several fairness desiderata, we notice a misalignment between these desiderata and the capabilities of XAI. We encourage to conceive XAI as one of many tools to approach the multidimensional, sociotechnical challenge of algorithmic fairness and to be more specific about how exactly what kind of XAI method enables whom to address which fairness desideratum.
</details>
<details>
<summary>摘要</summary>
在这份重要的调查中，我们分析了通用Explainable AI（XAI）和公平之间的关系，以彻底分离这两个概念之间的多维关系。通过系统性文献综述和 subsequential 资料分析，我们确定了175篇文章中对XAI的公平 benefittest的七种典型声明。我们提出了关于这些声明的重要警告和限制，并为将来关于XAI在特定公平要求上的潜在优势和局限性的讨论提供入口点。尽管文献 часто表明XAI是许多公平要求的激活器，但我们注意到了XAI的能力与这些要求的不一致。我们建议视XAI为一种用于多维、社技挑战的算法公平的工具，并更 preciselly 说明XAI方法可以为谁 Address 哪些公平要求。
</details></li>
</ul>
<hr>
<h2 id="VLIS-Unimodal-Language-Models-Guide-Multimodal-Language-Generation"><a href="#VLIS-Unimodal-Language-Models-Guide-Multimodal-Language-Generation" class="headerlink" title="VLIS: Unimodal Language Models Guide Multimodal Language Generation"></a>VLIS: Unimodal Language Models Guide Multimodal Language Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09767">http://arxiv.org/abs/2310.09767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiwanchung/vlis">https://github.com/jiwanchung/vlis</a></li>
<li>paper_authors: Jiwan Chung, Youngjae Yu</li>
<li>for: 提高多Modal语言生成的复杂语言理解能力</li>
<li>methods:  combinesthe visual conditioning capability of vision-language models with the language understanding of unimodal text-only language models without further training</li>
<li>results: 在多种任务上（包括CommonSense理解、复杂文本生成等），VLIS可以提高视觉语言模型的性能<details>
<summary>Abstract</summary>
Multimodal language generation, which leverages the synergy of language and vision, is a rapidly expanding field. However, existing vision-language models face challenges in tasks that require complex linguistic understanding. To address this issue, we introduce Visual-Language models as Importance Sampling weights (VLIS), a novel framework that combines the visual conditioning capability of vision-language models with the language understanding of unimodal text-only language models without further training. It extracts pointwise mutual information of each image and text from a visual-language model and uses the value as an importance sampling weight to adjust the token likelihood from a text-only model. VLIS improves vision-language models on diverse tasks, including commonsense understanding (WHOOPS, OK-VQA, and ScienceQA) and complex text generation (Concadia, Image Paragraph Captioning, and ROCStories). Our results suggest that VLIS represents a promising new direction for multimodal language generation.
</details>
<details>
<summary>摘要</summary>
多模态语言生成，利用语言和视觉之间的共同作用，是一个快速发展的领域。然而，现有的视觉语言模型在需要复杂的语言理解任务时会遇到挑战。为解决这个问题，我们介绍了视觉语言模型作为重要抽象权重（VLIS），这是一种将视觉语言模型的视觉条件能力与单模式文本Only语言模型的语言理解能力结合在一起的新框架。它从视觉语言模型中提取每个图像和文本的点对 Mutual Information，并将其用作重要抽象权重，以调整文本Only模型的单词概率。VLIS改进了多种任务，包括宽泛理解（WHOOPS、OK-VQA和科学问答）和复杂文本生成（Concadia、图像段落描述和ROCStories）。我们的结果表明，VLIS代表了一个有前途的新方向 для多模态语言生成。
</details></li>
</ul>
<hr>
<h2 id="Improving-Access-to-Justice-for-the-Indian-Population-A-Benchmark-for-Evaluating-Translation-of-Legal-Text-to-Indian-Languages"><a href="#Improving-Access-to-Justice-for-the-Indian-Population-A-Benchmark-for-Evaluating-Translation-of-Legal-Text-to-Indian-Languages" class="headerlink" title="Improving Access to Justice for the Indian Population: A Benchmark for Evaluating Translation of Legal Text to Indian Languages"></a>Improving Access to Justice for the Indian Population: A Benchmark for Evaluating Translation of Legal Text to Indian Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09765">http://arxiv.org/abs/2310.09765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayan Mahapatra, Debtanu Datta, Shubham Soni, Adrijit Goswami, Saptarshi Ghosh</li>
<li>For: The paper aims to make legal text in the Indian judiciary more accessible to the general population, who are not comfortable with reading English.* Methods: The authors construct a high-quality legal parallel corpus containing aligned text units in English and nine Indian languages, and benchmark the performance of various Machine Translation (MT) systems over this corpus.* Results: The authors survey Law practitioners to evaluate the quality of the translations produced by the MT systems, and compare the results with automatic MT evaluation metrics.<details>
<summary>Abstract</summary>
Most legal text in the Indian judiciary is written in complex English due to historical reasons. However, only about 10% of the Indian population is comfortable in reading English. Hence legal text needs to be made available in various Indian languages, possibly by translating the available legal text from English. Though there has been a lot of research on translation to and between Indian languages, to our knowledge, there has not been much prior work on such translation in the legal domain. In this work, we construct the first high-quality legal parallel corpus containing aligned text units in English and nine Indian languages, that includes several low-resource languages. We also benchmark the performance of a wide variety of Machine Translation (MT) systems over this corpus, including commercial MT systems, open-source MT systems and Large Language Models. Through a comprehensive survey by Law practitioners, we check how satisfied they are with the translations by some of these MT systems, and how well automatic MT evaluation metrics agree with the opinions of Law practitioners.
</details>
<details>
<summary>摘要</summary>
大多数印度法律文本在印度司法系统中 escriten in 复杂的英语，历史原因。然而，只有约10%的印度人口能够读写英语。因此，法律文本需要在各种印度语言中提供，可能是通过从英语翻译。虽然已有很多关于翻译与印度语言之间的研究，但我们知道，在法律领域中的翻译研究不多。在这项工作中，我们构建了首个高质量的法律平行文本库，包括英语和九种印度语言的对应文本单位。我们还对这个库进行了评估，包括商业MT系统、开源MT系统和大语言模型。通过对法律专业人员的详细调查，我们检查了这些MT系统的翻译质量如何满意，以及自动MT评估指标与专业人员的意见如何相符。
</details></li>
</ul>
<hr>
<h2 id="DropMix-Better-Graph-Contrastive-Learning-with-Harder-Negative-Samples"><a href="#DropMix-Better-Graph-Contrastive-Learning-with-Harder-Negative-Samples" class="headerlink" title="DropMix: Better Graph Contrastive Learning with Harder Negative Samples"></a>DropMix: Better Graph Contrastive Learning with Harder Negative Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09764">http://arxiv.org/abs/2310.09764</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Mayueq/DropMix-Code">https://github.com/Mayueq/DropMix-Code</a></li>
<li>paper_authors: Yueqi Ma, Minjie Chen, Xiang Li</li>
<li>for: 提高图像对比学习中的负样本质量</li>
<li>methods: DropMix方法包括两个主要步骤：首先选择图像中的困难负样本，然后只在部分表示维度上进行混合，以生成更困难的负样本</li>
<li>results: 对六个基准数据集进行了广泛的实验，结果表明 DropMix 方法可以提高对比学习性能<details>
<summary>Abstract</summary>
While generating better negative samples for contrastive learning has been widely studied in the areas of CV and NLP, very few work has focused on graph-structured data. Recently, Mixup has been introduced to synthesize hard negative samples in graph contrastive learning (GCL). However, due to the unsupervised learning nature of GCL, without the help of soft labels, directly mixing representations of samples could inadvertently lead to the information loss of the original hard negative and further adversely affect the quality of the newly generated harder negative. To address the problem, in this paper, we propose a novel method DropMix to synthesize harder negative samples, which consists of two main steps. Specifically, we first select some hard negative samples by measuring their hardness from both local and global views in the graph simultaneously. After that, we mix hard negatives only on partial representation dimensions to generate harder ones and decrease the information loss caused by Mixup. We conduct extensive experiments to verify the effectiveness of DropMix on six benchmark datasets. Our results show that our method can lead to better GCL performance. Our data and codes are publicly available at https://github.com/Mayueq/DropMix-Code.
</details>
<details>
<summary>摘要</summary>
“对待于图structured数据的异构学习中，生成更好的负样本已经广泛研究在CV和NLP领域，但很少有研究在图结构数据上。近期，Mixup方法在图相关学习（GCL）中被引入，以生成困难的负样本。然而，由于GCL是无监督学习的，没有软标签的帮助，直接混合样本表示可能会导致原始困难的负样本中的信息损失，从而降低新生成的更困难负样本的质量。为解决这个问题，在本文中，我们提出了一种新的方法DropMix，它包括两个主要步骤。具体来说，我们首先从图中选择一些困难的负样本，并测量它们的困难程度从本地和全局视图同时。然后，我们只在部分表示维度上混合困难负样本，以生成更困难的负样本和减少Mixup导致的信息损失。我们对六个标准 benchmark dataset进行了广泛的实验，结果显示，我们的方法可以提高GCL性能。我们的数据和代码在https://github.com/Mayueq/DropMix-Code上公开。”
</details></li>
</ul>
<hr>
<h2 id="Diversifying-the-Mixture-of-Experts-Representation-for-Language-Models-with-Orthogonal-Optimizer"><a href="#Diversifying-the-Mixture-of-Experts-Representation-for-Language-Models-with-Orthogonal-Optimizer" class="headerlink" title="Diversifying the Mixture-of-Experts Representation for Language Models with Orthogonal Optimizer"></a>Diversifying the Mixture-of-Experts Representation for Language Models with Orthogonal Optimizer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09762">http://arxiv.org/abs/2310.09762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boan Liu, Liang Ding, Li Shen, Keqin Peng, Yu Cao, Dazhao Cheng, Dacheng Tao</li>
<li>for: 提高MoE模型的表现和多样性</li>
<li>methods: 提出了一种简单 yet高效的解决方案——对采用MoE结构的模型进行非对称专家优化，并 introduce了一种 alternate training strategy to encourage each expert to update in a direction orthogonal to the subspace spanned by other experts。</li>
<li>results: 通过广泛的实验，证明了我们提出的优化算法可以显著提高MoE模型在GLUE、SuperGLUE、问答任务和名词识别任务的表现。<details>
<summary>Abstract</summary>
The Mixture of Experts (MoE) has emerged as a highly successful technique in deep learning, based on the principle of divide-and-conquer to maximize model capacity without significant additional computational cost. Even in the era of large-scale language models (LLMs), MoE continues to play a crucial role, as some researchers have indicated that GPT-4 adopts the MoE structure to ensure diverse inference results. However, MoE is susceptible to performance degeneracy, particularly evident in the issues of imbalance and homogeneous representation among experts. While previous studies have extensively addressed the problem of imbalance, the challenge of homogeneous representation remains unresolved. In this study, we shed light on the homogeneous representation problem, wherein experts in the MoE fail to specialize and lack diversity, leading to frustratingly high similarities in their representations (up to 99% in a well-performed MoE model). This problem restricts the expressive power of the MoE and, we argue, contradicts its original intention. To tackle this issue, we propose a straightforward yet highly effective solution: OMoE, an orthogonal expert optimizer. Additionally, we introduce an alternating training strategy that encourages each expert to update in a direction orthogonal to the subspace spanned by other experts. Our algorithm facilitates MoE training in two key ways: firstly, it explicitly enhances representation diversity, and secondly, it implicitly fosters interaction between experts during orthogonal weights computation. Through extensive experiments, we demonstrate that our proposed optimization algorithm significantly improves the performance of fine-tuning the MoE model on the GLUE benchmark, SuperGLUE benchmark, question-answering task, and name entity recognition tasks.
</details>
<details>
<summary>摘要</summary>
《粗粒化专家（MoE）》技术在深度学习中得到了广泛应用，基于分治分 conquering的原则，以提高模型容量而不增加显著的计算成本。即使在大规模语言模型（LLM）时代，MoE仍然扮演着关键的角色，一些研究人员表示GPT-4采用了MoE结构以确保多样化的推理结果。然而，MoE受到性能异常化的问题困扰，特别是专家之间的不均衡和同质化表现问题。虽然以前的研究已经广泛地解决了不均衡问题，但同质化表现问题仍然未得到解决。在这项研究中，我们 shed light on the homogeneous representation problem，专家在MoE中失去特化和多样性，导致其表达相似度达99%以上（在一个良好的MoE模型中）。这个问题限制了MoE的表达力，我们认为这与MoE的原意相抵触。为解决这个问题，我们提出了一种简单 yet highly effective的解决方案：OMoE，一种ortogonal expert optimizer。此外，我们还提出了一种 alternate training strategy，鼓励每个专家在归一化方向上更新其 weights。我们的算法可以在两个关键方面帮助MoE训练：首先，它明确提高了表达多样性；其次，它 implicit地促进了专家之间的交互在 ortogonal weights 计算中。通过广泛的实验，我们证明了我们的提出的优化算法可以显著提高 fine-tuning MoE 模型在 GLUE Benchmark、SuperGLUE Benchmark、问题回答任务和名词识别任务上的性能。
</details></li>
</ul>
<hr>
<h2 id="CAPro-Webly-Supervised-Learning-with-Cross-Modality-Aligned-Prototypes"><a href="#CAPro-Webly-Supervised-Learning-with-Cross-Modality-Aligned-Prototypes" class="headerlink" title="CAPro: Webly Supervised Learning with Cross-Modality Aligned Prototypes"></a>CAPro: Webly Supervised Learning with Cross-Modality Aligned Prototypes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09761">http://arxiv.org/abs/2310.09761</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuleiqin/capro">https://github.com/yuleiqin/capro</a></li>
<li>paper_authors: Yulei Qin, Xingyu Chen, Yunhang Shen, Chaoyou Fu, Yun Gu, Ke Li, Xing Sun, Rongrong Ji</li>
<li>For: 这个论文旨在提出一种基于文本和图像协同学习的Visual Representation Learning方法，以适应现实世界中噪声的挑战。* Methods: 该方法使用文本prototype来选择干净的图像，并通过文本匹配来解决视觉prototype的混乱问题。此外，它还使用视觉特征空间来完善和提高图像的文本描述，以及使用集合bootstrap来鼓励更好的标签参考。* Results: 实验表明，CAPro可以 effetively处理现实世界中的噪声，并在单个标签和多个标签场景下达到新的州OF-THE-ART性能。它还展示了对开集认识的Robustness。代码可以在<a target="_blank" rel="noopener" href="https://github.com/yuleiqin/capro%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/yuleiqin/capro上下载。</a><details>
<summary>Abstract</summary>
Webly supervised learning has attracted increasing attention for its effectiveness in exploring publicly accessible data at scale without manual annotation. However, most existing methods of learning with web datasets are faced with challenges from label noise, and they have limited assumptions on clean samples under various noise. For instance, web images retrieved with queries of tiger cat (a cat species) and drumstick (a musical instrument) are almost dominated by images of tigers and chickens, which exacerbates the challenge of fine-grained visual concept learning. In this case, exploiting both web images and their associated texts is a requisite solution to combat real-world noise. In this paper, we propose Cross-modality Aligned Prototypes (CAPro), a unified prototypical contrastive learning framework to learn visual representations with correct semantics. For one thing, we leverage textual prototypes, which stem from the distinct concept definition of classes, to select clean images by text matching and thus disambiguate the formation of visual prototypes. For another, to handle missing and mismatched noisy texts, we resort to the visual feature space to complete and enhance individual texts and thereafter improve text matching. Such semantically aligned visual prototypes are further polished up with high-quality samples, and engaged in both cluster regularization and noise removal. Besides, we propose collective bootstrapping to encourage smoother and wiser label reference from appearance-similar instances in a manner of dictionary look-up. Extensive experiments on WebVision1k and NUS-WIDE (Web) demonstrate that CAPro well handles realistic noise under both single-label and multi-label scenarios. CAPro achieves new state-of-the-art performance and exhibits robustness to open-set recognition. Codes are available at https://github.com/yuleiqin/capro.
</details>
<details>
<summary>摘要</summary>
优先级学习在扫描公共访问数据时得到了越来越多的关注，因为它可以让计算机系统利用大规模数据来学习而无需手动标注。然而，现有的网络数据学习方法受到噪声标注的挑战，而且它们假设清晰的样本存在于各种噪声下。例如，通过查询“虎猫”和“鼓”的图像检索结果将主要是虎猫和鸡图像，这会使视觉概念学习受到挑战。在这种情况下，利用网络图像和其相关文本是一种必要的解决方案，以避免实际世界中的噪声。在这篇论文中，我们提出了跨模态对应原型（CAPro），一种统一的 проtotypical contrastive learning框架，用于学习正确的视觉表示。首先，我们利用文本原型，它们来自不同类型的概念定义，来选择干净的图像，并通过文本匹配来减少视觉原型的形成干扰。其次，为了处理缺失和不一致的噪声文本，我们 resorts to the visual feature space to complete and enhance individual texts, and thereafter improve text matching。这些semantically aligned的视觉原型被进一步练练以高质量样本，并在集群规则和噪声除除中使用。此外，我们提出了集体 bootstrap的方法，以便在 appearancely similar 的实例上进行词典查找，以便更好地引用表达相似的标签。广泛的实验表明，CAPro可以有效地处理现实世界中的噪声，并在单个标签和多标签场景中达到新的领先性性和robustness。代码可以在https://github.com/yuleiqin/capro中获取。
</details></li>
</ul>
<hr>
<h2 id="EX-FEVER-A-Dataset-for-Multi-hop-Explainable-Fact-Verification"><a href="#EX-FEVER-A-Dataset-for-Multi-hop-Explainable-Fact-Verification" class="headerlink" title="EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification"></a>EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09754">http://arxiv.org/abs/2310.09754</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dependentsign/EX-FEVER">https://github.com/dependentsign/EX-FEVER</a></li>
<li>paper_authors: Huanhuan Ma, Weizhi Xu, Yifan Wei, Liuji Chen, Liang Wang, Qiang Liu, Shu Wu, Liang Wang</li>
<li>for: 这个论文的目的是构建一个可解释的事实验证系统，以便在复杂多层扩展中实现自动化的真实检查。</li>
<li>methods: 该论文使用了一种新的基于Wikipedia文档的数据集，并提出了一种基于这些数据集的基线系统。该基线系统包括文档检索、解释生成和CLAIM验证三个部分。</li>
<li>results: 该论文通过对EX-FEVER数据集进行实验，发现现有的事实验证模型在这个数据集上表现不佳，而Large Language Models在这个任务中具有潜在的应用前景。<details>
<summary>Abstract</summary>
Fact verification aims to automatically probe the veracity of a claim based on several pieces of evidence. Existing works are always engaging in the accuracy improvement, let alone the explainability, a critical capability of fact verification system. Constructing an explainable fact verification system in a complex multi-hop scenario is consistently impeded by the absence of a relevant high-quality dataset. Previous dataset either suffer from excessive simplification or fail to incorporate essential considerations for explainability. To address this, we present EX-FEVER, a pioneering dataset for multi-hop explainable fact verification. With over 60,000 claims involving 2-hop and 3-hop reasoning, each is created by summarizing and modifying information from hyperlinked Wikipedia documents. Each instance is accompanied by a veracity label and an explanation that outlines the reasoning path supporting the veracity classification. Additionally, we demonstrate a novel baseline system on our EX-FEVER dataset, showcasing document retrieval, explanation generation, and claim verification and observe that existing fact verification models trained on previous datasets struggle to perform well on our dataset. Furthermore, we highlight the potential of utilizing Large Language Models in the fact verification task. We hope our dataset could make a significant contribution by providing ample opportunities to explore the integration of natural language explanations in the domain of fact verification.
</details>
<details>
<summary>摘要</summary>
fact checking 目标是自动检查声明的真实性，基于多个证据。现有工作都在增强准确性，却忽视了解释性，这是 фаクト checking 系统的关键能力。在复杂多趋场景中构建可解释的 факт checking 系统受到高质量数据缺乏的阻碍。现有数据集都受到过度简化或者缺乏关键考虑因素，以解释性为前提，我们提出了 EX-FEVER 数据集，包含了2-hop和3-hop逻辑推理的60,000个声明，每个声明都由修改和摘要来自 hyperlinked Wikipedia 文档。每个实例都有真实性标签和解释，其中解释描述了支持真实性分类的逻辑路径。此外，我们还提出了一种基于 EX-FEVER 数据集的基线系统，包括文档检索、解释生成和声明验证，并观察到现有的 fact checking 模型在前一个数据集上表现不佳。此外，我们还强调了利用大型自然语言模型在 fact checking 任务中的潜在优势。我们希望我们的数据集能够为研究人员提供丰富的探索自然语言解释在验证领域的机会。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Segmentation-Road-Network-Generation-with-Multi-Modal-LLMs"><a href="#Beyond-Segmentation-Road-Network-Generation-with-Multi-Modal-LLMs" class="headerlink" title="Beyond Segmentation: Road Network Generation with Multi-Modal LLMs"></a>Beyond Segmentation: Road Network Generation with Multi-Modal LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09755">http://arxiv.org/abs/2310.09755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumedh Rasal, Sanjay Kumar Boddhu</li>
<li>for: 本研究旨在提供一种创新的路网生成方法，利用多modal的大语言模型（LLM）来生成细致、可行驾驶的路网。</li>
<li>methods: 我们的模型使用了BLIP-2架构 arXiv:2301.12597，利用预先冻结的图像编码器和大语言模型来创造一种多modal LLM。</li>
<li>results: 我们的实验结果表明，使用我们的方法可以准确地生成路网，并且不需要生成二进制分割mask。这种方法可以增强自主驾驶系统，特别是在路网场景中，准确的导航是非常重要的。<details>
<summary>Abstract</summary>
This paper introduces an innovative approach to road network generation through the utilization of a multi-modal Large Language Model (LLM). Our model is specifically designed to process aerial images of road layouts and produce detailed, navigable road networks within the input images. The core innovation of our system lies in the unique training methodology employed for the large language model to generate road networks as its output. This approach draws inspiration from the BLIP-2 architecture arXiv:2301.12597, leveraging pre-trained frozen image encoders and large language models to create a versatile multi-modal LLM.   Our work also offers an alternative to the reasoning segmentation method proposed in the LISA paper arXiv:2308.00692. By training the large language model with our approach, the necessity for generating binary segmentation masks, as suggested in the LISA paper arXiv:2308.00692, is effectively eliminated. Experimental results underscore the efficacy of our multi-modal LLM in providing precise and valuable navigational guidance. This research represents a significant stride in bolstering autonomous navigation systems, especially in road network scenarios, where accurate guidance is of paramount importance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="When-can-transformers-reason-with-abstract-symbols"><a href="#When-can-transformers-reason-with-abstract-symbols" class="headerlink" title="When can transformers reason with abstract symbols?"></a>When can transformers reason with abstract symbols?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09753">http://arxiv.org/abs/2310.09753</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eboix/relational-reasoning">https://github.com/eboix/relational-reasoning</a></li>
<li>paper_authors: Enric Boix-Adsera, Omid Saremi, Emmanuel Abbe, Samy Bengio, Etai Littwin, Joshua Susskind</li>
<li>for: 这个研究探讨了基于抽象符号的关系理解任务中 transformer大语言模型（LLMs）的能力。</li>
<li>methods: 这些任务使用了许多年来在 neuroscience 文献中研究的基本建构物，包括程序编程、数学和语言理解。</li>
<li>results: 研究发现，对于回归任务， transformer 可以通过训练而泛化，但需要很大量的训练数据；对于下一个符号预测任务， transformer 的表示维度增加会导致泛化失败，但可以通过添加两个可调参数来降低数据量。<details>
<summary>Abstract</summary>
We investigate the capabilities of transformer large language models (LLMs) on relational reasoning tasks involving abstract symbols. Such tasks have long been studied in the neuroscience literature as fundamental building blocks for more complex abilities in programming, mathematics, and verbal reasoning. For (i) regression tasks, we prove that transformers generalize when trained, but require astonishingly large quantities of training data. For (ii) next-token-prediction tasks with symbolic labels, we show an "inverse scaling law": transformers fail to generalize as their embedding dimension increases. For both settings (i) and (ii), we propose subtle transformer modifications which can reduce the amount of data needed by adding two trainable parameters per head.
</details>
<details>
<summary>摘要</summary>
我们研究transformer大语言模型（LLM）在关系理解任务中的能力，这些任务在神经科学文献中已经被认为是更进阶的程序设计、数学和语言理解能力的基础元素。 для（i）回溯任务，我们证明transformer会通过训练时通过数据大量化，但需要非常多的训练数据。 для（ii）下一个字符预测任务，我们显示了“倒推法则”：transformer在增加嵌入维度时无法通过数据大量化。 для beiden（i）和（ii）设定，我们提出了微妙的transformer修改，可以透过添加两个可调参数每个head来降低训练数据量。
</details></li>
</ul>
<hr>
<h2 id="Domain-Specific-Language-Model-Post-Training-for-Indonesian-Financial-NLP"><a href="#Domain-Specific-Language-Model-Post-Training-for-Indonesian-Financial-NLP" class="headerlink" title="Domain-Specific Language Model Post-Training for Indonesian Financial NLP"></a>Domain-Specific Language Model Post-Training for Indonesian Financial NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09736">http://arxiv.org/abs/2310.09736</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/intanq/indonesian-financial-domain-lm">https://github.com/intanq/indonesian-financial-domain-lm</a></li>
<li>paper_authors: Ni Putu Intan Maharani, Yoga Yustiawan, Fauzy Caesar Rochim, Ayu Purwarianti</li>
<li>for: 这 paper 是关于金融领域的自然语言处理（NLP）任务中BERT和IndoBERT的应用和调整。</li>
<li>methods: 本文使用了预训练的IndoBERT，在小规模的INDONESIAN financial corpus上进行了后期训练。同时，我们还构建了INDONESIAN自然语言负面情感分类和主题分类数据集，并发布了一家BERT模型 для金融NLP。</li>
<li>results: 我们的实验结果表明，对特定领域下的下游任务进行适应性训练可以提高语言模型的效果。<details>
<summary>Abstract</summary>
BERT and IndoBERT have achieved impressive performance in several NLP tasks. There has been several investigation on its adaption in specialized domains especially for English language. We focus on financial domain and Indonesian language, where we perform post-training on pre-trained IndoBERT for financial domain using a small scale of Indonesian financial corpus. In this paper, we construct an Indonesian self-supervised financial corpus, Indonesian financial sentiment analysis dataset, Indonesian financial topic classification dataset, and release a family of BERT models for financial NLP. We also evaluate the effectiveness of domain-specific post-training on sentiment analysis and topic classification tasks. Our findings indicate that the post-training increases the effectiveness of a language model when it is fine-tuned to domain-specific downstream tasks.
</details>
<details>
<summary>摘要</summary>
BERT和IndoBERT在多个自然语言处理任务中表现出色。有很多关于它们在特定领域的调整的研究。我们在金融领域和印度尼西亚语言中进行调整，使用小规模的印度尼西亚金融文本库进行后处理。在这篇论文中，我们构建了一个印度尼西亚自我指导的金融文本库，印度尼西亚金融情感分析数据集和印度尼西亚金融话题分类数据集，并推出一家BERT模型的家族用于金融NLPT。我们还评估了域名特定的后处理对情感分析和话题分类任务的效果。我们的发现表明，后处理可以提高语言模型在域名特定下滤波器任务的效果。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Conversational-Search-Large-Language-Model-Aided-Informative-Query-Rewriting"><a href="#Enhancing-Conversational-Search-Large-Language-Model-Aided-Informative-Query-Rewriting" class="headerlink" title="Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting"></a>Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09716">http://arxiv.org/abs/2310.09716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fanghua Ye, Meng Fang, Shenghui Li, Emine Yilmaz</li>
<li>for: 提高对话搜索的会话搜索性能，使用语言模型来重写用户查询。</li>
<li>methods: 使用大型语言模型（LLM）来重写查询，通过设计良好的指令来生成有用的重写。</li>
<li>results: 对QReCC数据集进行实验，显示了使用有用的重写可以提高搜索性能，尤其是使用稀有搜索器。<details>
<summary>Abstract</summary>
Query rewriting plays a vital role in enhancing conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverage human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a "rewrite-then-edit" process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can yield substantially improved retrieval performance compared to human rewrites, especially with sparse retrievers.
</details>
<details>
<summary>摘要</summary>
查询重写play vital role in enhance conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverages human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a "rewrite-then-edit" process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can yield substantially improved retrieval performance compared to human rewrites, especially with sparse retrievers.Here's the text with Traditional Chinese characters:查询重写play vital role in enhance conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverages human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a "rewrite-then-edit" process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can yield substantially improved retrieval performance compared to human rewrites, especially with sparse retrievers.
</details></li>
</ul>
<hr>
<h2 id="New-Advances-in-Body-Composition-Assessment-with-ShapedNet-A-Single-Image-Deep-Regression-Approach"><a href="#New-Advances-in-Body-Composition-Assessment-with-ShapedNet-A-Single-Image-Deep-Regression-Approach" class="headerlink" title="New Advances in Body Composition Assessment with ShapedNet: A Single Image Deep Regression Approach"></a>New Advances in Body Composition Assessment with ShapedNet: A Single Image Deep Regression Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09709">http://arxiv.org/abs/2310.09709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Navar Medeiros M. Nascimento, Pedro Cavalcante de Sousa Junior, Pedro Yuri Rodrigues Nunes, Suane Pires Pinheiro da Silva, Luiz Lannes Loureiro, Victor Zaban Bittencourt, Valden Luis Matos Capistrano Junior, Pedro Pedrosa Rebouças Filho</li>
<li>for: 增强体重分析方法</li>
<li>methods: 使用深度神经网络进行身体脂肪百分比（BFP）估算、个体识别和位置确定，只需单张照片</li>
<li>results: 比对 стандар方法双能X射线吸收仪(DXA)，1273名健康成人的Age、性别和BFP水平进行验证，结果表明ShapedNet比前方法提高19.5%，MAPE为4.91%，MAE为1.42%，Gender-neutral方法表现更优。<details>
<summary>Abstract</summary>
We introduce a novel technique called ShapedNet to enhance body composition assessment. This method employs a deep neural network capable of estimating Body Fat Percentage (BFP), performing individual identification, and enabling localization using a single photograph. The accuracy of ShapedNet is validated through comprehensive comparisons against the gold standard method, Dual-Energy X-ray Absorptiometry (DXA), utilizing 1273 healthy adults spanning various ages, sexes, and BFP levels. The results demonstrate that ShapedNet outperforms in 19.5% state of the art computer vision-based approaches for body fat estimation, achieving a Mean Absolute Percentage Error (MAPE) of 4.91% and Mean Absolute Error (MAE) of 1.42. The study evaluates both gender-based and Gender-neutral approaches, with the latter showcasing superior performance. The method estimates BFP with 95% confidence within an error margin of 4.01% to 5.81%. This research advances multi-task learning and body composition assessment theory through ShapedNet.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的技术called ShapedNet，用于提高身体组分评估。这种方法利用深度神经网络，能够估算身体脂肪百分比（BFP），进行个体识别，并使用单张图像进行地图化。我们 validate了ShapedNet的准确性，通过对杰基标方法（DXA）的1273名健康成人进行比较，这些成人来自不同的年龄、性别和BFP水平。结果表明，ShapedNet在19.5%的state of the art计算机视觉基础上进行身体脂肪估计方法中，表现出色，其 Mean Absolute Percentage Error（MAPE）为4.91%， Mean Absolute Error（MAE）为1.42。我们也评估了不同的性别和无性别方法，其中后者表现更出色。ShapedNet可以在95%的信息内，对BFP进行4.01%至5.81%的估计，这对身体组分评估理论和多任务学习做出了重要贡献。
</details></li>
</ul>
<hr>
<h2 id="AdaptSSR-Pre-training-User-Model-with-Augmentation-Adaptive-Self-Supervised-Ranking"><a href="#AdaptSSR-Pre-training-User-Model-with-Augmentation-Adaptive-Self-Supervised-Ranking" class="headerlink" title="AdaptSSR: Pre-training User Model with Augmentation-Adaptive Self-Supervised Ranking"></a>AdaptSSR: Pre-training User Model with Augmentation-Adaptive Self-Supervised Ranking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09706">http://arxiv.org/abs/2310.09706</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yflyl613/AdaptSSR">https://github.com/yflyl613/AdaptSSR</a></li>
<li>paper_authors: Yang Yu, Qi Liu, Kai Zhang, Yuren Zhang, Chao Song, Min Hou, Yuqing Yuan, Zhihao Ye, Zaixi Zhang, Sanshi Lei Yu</li>
<li>for: 用于提高用户模型的泛化能力和数据稀缺性问题。</li>
<li>methods: 使用对数据进行增强学习，并采用自适应自我supervised排序任务来改善用户模型的准确性。</li>
<li>results: 经过extensive experiments的证明，该方法可以提高用户模型的性能和数据稀缺性问题。<details>
<summary>Abstract</summary>
User modeling, which aims to capture users' characteristics or interests, heavily relies on task-specific labeled data and suffers from the data sparsity issue. Several recent studies tackled this problem by pre-training the user model on massive user behavior sequences with a contrastive learning task. Generally, these methods assume different views of the same behavior sequence constructed via data augmentation are semantically consistent, i.e., reflecting similar characteristics or interests of the user, and thus maximizing their agreement in the feature space. However, due to the diverse interests and heavy noise in user behaviors, existing augmentation methods tend to lose certain characteristics of the user or introduce noisy behaviors. Thus, forcing the user model to directly maximize the similarity between the augmented views may result in a negative transfer. To this end, we propose to replace the contrastive learning task with a new pretext task: Augmentation-Adaptive SelfSupervised Ranking (AdaptSSR), which alleviates the requirement of semantic consistency between the augmented views while pre-training a discriminative user model. Specifically, we adopt a multiple pairwise ranking loss which trains the user model to capture the similarity orders between the implicitly augmented view, the explicitly augmented view, and views from other users. We further employ an in-batch hard negative sampling strategy to facilitate model training. Moreover, considering the distinct impacts of data augmentation on different behavior sequences, we design an augmentation-adaptive fusion mechanism to automatically adjust the similarity order constraint applied to each sample based on the estimated similarity between the augmented views. Extensive experiments on both public and industrial datasets with six downstream tasks verify the effectiveness of AdaptSSR.
</details>
<details>
<summary>摘要</summary>
用户模型化，它目标是捕捉用户特点或兴趣，受到任务特定的标注数据的缺乏问题困扰。一些最近的研究解决了这个问题，通过在大量用户行为序列上进行预训练，并使用对偶学习任务。通常，这些方法假设不同的视图的同一个行为序列，通过数据扩展生成的方法是具有相同特征或兴趣的用户，并且尽量在特征空间中增加它们之间的一致性。然而，由于用户的兴趣和行为噪声的多样性，现有的扩展方法通常会消失用户的特征或引入噪声行为。因此，直接在扩展视图之间寻求最大的一致性可能会导致负面传播。为此，我们提议将对偶学习任务改为一种新的预文任务：增强自监 Ranking（AdaptSSR），这种任务可以降低对扩展视图的 semantic consistency 要求，而在预训练用户模型时，capture用户的相似性序列。具体来说，我们采用多对多对比损失函数，训练用户模型，捕捉扩展视图、显式扩展视图和其他用户视图之间的相似性序列。此外，考虑不同的数据扩展对不同的行为序列的不同影响，我们设计了数据扩展适应机制，自动调整每个样本所应用的相似性序列约束，基于每个扩展视图之间的估计相似性。我们在公共和工业数据集上进行了六个下游任务的广泛实验，并证明了 AdaptSSR 的效果。
</details></li>
</ul>
<hr>
<h2 id="Progressive-Evidence-Refinement-for-Open-domain-Multimodal-Retrieval-Question-Answering"><a href="#Progressive-Evidence-Refinement-for-Open-domain-Multimodal-Retrieval-Question-Answering" class="headerlink" title="Progressive Evidence Refinement for Open-domain Multimodal Retrieval Question Answering"></a>Progressive Evidence Refinement for Open-domain Multimodal Retrieval Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09696">http://arxiv.org/abs/2310.09696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwen Yang, Anran Wu, Xingjiao Wu, Luwei Xiao, Tianlong Ma, Cheng Jin, Liang He</li>
<li>for: 提高 retrieval-based question answering 模型的表现，解决现有模型在使用压缩证据特征时丢失细节信息，以及Question和证据之间的特征提取差距。</li>
<li>methods: 提出了一种两阶段框架，包括进行逐步证据筛选、使用 semi-supervised contrastive learning 训练策略、多次询问回答等方法来解决这两个问题。</li>
<li>results: 通过广泛的实验证明，该模型在 WebQA 和 MultimodelQA 测试上达到了出色的表现。<details>
<summary>Abstract</summary>
Pre-trained multimodal models have achieved significant success in retrieval-based question answering. However, current multimodal retrieval question-answering models face two main challenges. Firstly, utilizing compressed evidence features as input to the model results in the loss of fine-grained information within the evidence. Secondly, a gap exists between the feature extraction of evidence and the question, which hinders the model from effectively extracting critical features from the evidence based on the given question. We propose a two-stage framework for evidence retrieval and question-answering to alleviate these issues. First and foremost, we propose a progressive evidence refinement strategy for selecting crucial evidence. This strategy employs an iterative evidence retrieval approach to uncover the logical sequence among the evidence pieces. It incorporates two rounds of filtering to optimize the solution space, thus further ensuring temporal efficiency. Subsequently, we introduce a semi-supervised contrastive learning training strategy based on negative samples to expand the scope of the question domain, allowing for a more thorough exploration of latent knowledge within known samples. Finally, in order to mitigate the loss of fine-grained information, we devise a multi-turn retrieval and question-answering strategy to handle multimodal inputs. This strategy involves incorporating multimodal evidence directly into the model as part of the historical dialogue and question. Meanwhile, we leverage a cross-modal attention mechanism to capture the underlying connections between the evidence and the question, and the answer is generated through a decoding generation approach. We validate the model's effectiveness through extensive experiments, achieving outstanding performance on WebQA and MultimodelQA benchmark tests.
</details>
<details>
<summary>摘要</summary>
先进多模态模型已经在回答问题中取得了显著成功。然而，当前的多模态回答问题模型面临两个主要挑战。首先，使用压缩证据特征作为模型输入会导致证据中细详信息的损失。其次，证据和问题之间的特征EXTRACTING存在差距，这使得模型从证据中EXTRACTING答案相关的关键特征变得困难。我们提出了一个两个阶段框架，用于增强证据检索和回答问题。首先，我们提出了一种进步的证据精细化策略，用于选择重要的证据。这种策略使用迭代的证据检索方法，找到证据归并的逻辑顺序。它使用两轮的筛选来优化解决空间，从而更加确保时间效率。其次，我们引入了一种半监督对比学习训练策略，以扩展问题领域。这种策略基于负样本，通过对已知样本进行更多的探索，扩大问题领域的范围。 finally，为了减少细详信息的损失，我们提出了一种多turn检索和回答策略，用于处理多模态输入。这种策略将多模态证据直接 integrate into the model 中的历史对话和问题。同时，我们利用交叉模式注意力机制，捕捉证据和问题之间的下面连接。通过解码生成方法，我们生成答案。我们通过广泛的实验 validate the model's effectiveness, achieved outstanding performance on WebQA and MultimodelQA benchmark tests.
</details></li>
</ul>
<hr>
<h2 id="Spike-based-Neuromorphic-Computing-for-Next-Generation-Computer-Vision"><a href="#Spike-based-Neuromorphic-Computing-for-Next-Generation-Computer-Vision" class="headerlink" title="Spike-based Neuromorphic Computing for Next-Generation Computer Vision"></a>Spike-based Neuromorphic Computing for Next-Generation Computer Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09692">http://arxiv.org/abs/2310.09692</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Sakib Hasan, Catherine D. Schuman, Zhongyang Zhang, Tauhidur Rahman, Garrett S. Rose</li>
<li>for: 这篇论文旨在探讨 neuromorphic computing 技术的应用在计算机视觉领域。</li>
<li>methods: 论文使用了不同层次设计（设备、电路和算法）的示例来介绍 neuromorphic computing 技术。</li>
<li>results: 论文 conclude 了一些可能的应用和未来研究方向，例如用于 edge device 中的视觉任务。<details>
<summary>Abstract</summary>
Neuromorphic Computing promises orders of magnitude improvement in energy efficiency compared to traditional von Neumann computing paradigm. The goal is to develop an adaptive, fault-tolerant, low-footprint, fast, low-energy intelligent system by learning and emulating brain functionality which can be realized through innovation in different abstraction layers including material, device, circuit, architecture and algorithm. As the energy consumption in complex vision tasks keep increasing exponentially due to larger data set and resource-constrained edge devices become increasingly ubiquitous, spike-based neuromorphic computing approaches can be viable alternative to deep convolutional neural network that is dominating the vision field today. In this book chapter, we introduce neuromorphic computing, outline a few representative examples from different layers of the design stack (devices, circuits and algorithms) and conclude with a few exciting applications and future research directions that seem promising for computer vision in the near future.
</details>
<details>
<summary>摘要</summary>
《神经omorphic computing》承诺在能效率方面比传统的各批计算模式提供多个数量级的提升。目标是开发一个适应、错误tolerant、占用空间小、快速、低能耗智能系统，通过学习和模拟大脑功能来实现。在复杂视觉任务中的能 consumption不断增加，而 Edge devices受限的资源变得越来越普遍，使得使用射频型神经omorphic computing方法可以成为视觉领域今天的可行替代方案。在这个书章中，我们介绍了神经omorphic computing，从不同层次的设计栈（设备、电路和算法）中选出了一些示例，并结束于一些有前途的应用和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Configuration-Validation-with-Large-Language-Models"><a href="#Configuration-Validation-with-Large-Language-Models" class="headerlink" title="Configuration Validation with Large Language Models"></a>Configuration Validation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09690">http://arxiv.org/abs/2310.09690</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ciri4conf/ciri">https://github.com/ciri4conf/ciri</a></li>
<li>paper_authors: Xinyu Lian, Yinfang Chen, Runxiang Cheng, Jie Huang, Parth Thakkar, Tianyin Xu</li>
<li>for: 这个论文主要是为了探讨使用自然语言处理（NLP）和机器学习（ML）进行配置验证的可能性和效果。</li>
<li>methods: 该论文使用了大量的配置数据和不同的大语言模型（LLMs）进行验证，并开发了一个通用的 LLM-based 验证框架（Ciri）。该框架使用了小量的示例数据和几何学学习来设计有效的提示，并将多个 LLMs 的输出 validate 并聚合成验证结果。</li>
<li>results: 该论文的分析表明，使用 LLMs 进行配置验证是可能的，并且可以采用提示工程学习和几何学学习来设计有效的提示。但是，该论文还发现了一些问题，例如某些类型的错误配置不能准确地被检测出来，以及 LLMs 的偏见对一些常见的配置参数产生影响。<details>
<summary>Abstract</summary>
Misconfigurations are the major causes of software failures. Existing configuration validation techniques rely on manually written rules or test cases, which are expensive to implement and maintain, and are hard to be comprehensive. Leveraging machine learning (ML) and natural language processing (NLP) for configuration validation is considered a promising direction, but has been facing challenges such as the need of not only large-scale configuration data, but also system-specific features and models which are hard to generalize. Recent advances in Large Language Models (LLMs) show the promises to address some of the long-lasting limitations of ML/NLP-based configuration validation techniques. In this paper, we present an exploratory analysis on the feasibility and effectiveness of using LLMs like GPT and Codex for configuration validation. Specifically, we take a first step to empirically evaluate LLMs as configuration validators without additional fine-tuning or code generation. We develop a generic LLM-based validation framework, named Ciri, which integrates different LLMs. Ciri devises effective prompt engineering with few-shot learning based on both valid configuration and misconfiguration data. Ciri also validates and aggregates the outputs of LLMs to generate validation results, coping with known hallucination and nondeterminism of LLMs. We evaluate the validation effectiveness of Ciri on five popular LLMs using configuration data of six mature, widely deployed open-source systems. Our analysis (1) confirms the potential of using LLMs for configuration validation, (2) understands the design space of LLMbased validators like Ciri, especially in terms of prompt engineering with few-shot learning, and (3) reveals open challenges such as ineffectiveness in detecting certain types of misconfigurations and biases to popular configuration parameters.
</details>
<details>
<summary>摘要</summary>
软件故障的主要原因是配置错误。现有的配置验证技术依赖于手动编写的规则或测试用例，实施和维护成本高，难以全面验证。使用机器学习（ML）和自然语言处理（NLP）进行配置验证是一个有前途的方向，但它面临着大规模配置数据和系统特有的特征和模型难以普适化的挑战。近年来，大型自然语言模型（LLMs）的进步表明可以解决一些长期存在的ML/NLP基于配置验证技术的局限性。在这篇论文中，我们提出了一种使用LLMs like GPT和Codex进行配置验证的探索性分析。 Specifically，我们不需要额外 fine-tuning或代码生成，就可以使用LLMs来验证配置。我们开发了一个通用的LLM-based validation框架，名为Ciri。Ciri使用几种LLMs，并开发了有效的提示工程学和少量学习技术，以适应不同的配置数据。Ciri还可以将LLMs的输出验证和聚合，以生成验证结果，并处理知道的投影和非决定性。我们对五种流行的LLMs进行了配置数据的六种广泛部署的开源系统的验证。我们的分析表明：（1）使用LLMs进行配置验证是有潜力的；（2）LLM-based validator如Ciri在提示工程学和少量学习方面存在设计空间，特别是在针对有效配置和错误配置数据进行少量学习；（3）存在一些未解决的挑战，例如对某些类型的配置错误不够有效。
</details></li>
</ul>
<hr>
<h2 id="A-Partially-Supervised-Reinforcement-Learning-Framework-for-Visual-Active-Search"><a href="#A-Partially-Supervised-Reinforcement-Learning-Framework-for-Visual-Active-Search" class="headerlink" title="A Partially Supervised Reinforcement Learning Framework for Visual Active Search"></a>A Partially Supervised Reinforcement Learning Framework for Visual Active Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09689">http://arxiv.org/abs/2310.09689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anindyasarkariith/psrl_vas">https://github.com/anindyasarkariith/psrl_vas</a></li>
<li>paper_authors: Anindya Sarkar, Nathan Jacobs, Yevgeniy Vorobeychik</li>
<li>for: 这篇论文旨在提出一个名为“视觉活搜”（Visual Active Search，VAS）的框架，用于使用视觉讯号来引导探索，以找到大地ospatial空间中的区域兴趣。</li>
<li>methods: 这篇论文使用了深度强化学习（Deep Reinforcement Learning，DRL）和传统的活搜搜寻（Active Search）两种方法。</li>
<li>results: 论文的实验结果显示，该方法可以对现有的DRL框架进行改进，并且在多个问题领域中表现出色。<details>
<summary>Abstract</summary>
Visual active search (VAS) has been proposed as a modeling framework in which visual cues are used to guide exploration, with the goal of identifying regions of interest in a large geospatial area. Its potential applications include identifying hot spots of rare wildlife poaching activity, search-and-rescue scenarios, identifying illegal trafficking of weapons, drugs, or people, and many others. State of the art approaches to VAS include applications of deep reinforcement learning (DRL), which yield end-to-end search policies, and traditional active search, which combines predictions with custom algorithmic approaches. While the DRL framework has been shown to greatly outperform traditional active search in such domains, its end-to-end nature does not make full use of supervised information attained either during training, or during actual search, a significant limitation if search tasks differ significantly from those in the training distribution. We propose an approach that combines the strength of both DRL and conventional active search by decomposing the search policy into a prediction module, which produces a geospatial distribution of regions of interest based on task embedding and search history, and a search module, which takes the predictions and search history as input and outputs the search distribution. We develop a novel meta-learning approach for jointly learning the resulting combined policy that can make effective use of supervised information obtained both at training and decision time. Our extensive experiments demonstrate that the proposed representation and meta-learning frameworks significantly outperform state of the art in visual active search on several problem domains.
</details>
<details>
<summary>摘要</summary>
视觉活动搜索（VAS）被提出作为模型框架，使用视觉提示导航，以找到大型地ospatial领域中的区域兴趣点。其潜在应用包括珍稀野生动物贩卖活动热点检测、搜救找寻、武器贸易毒品人贩卖等。现状最佳实践方法包括应用深度强化学习（DRL），得到综合搜索策略，以及传统的活动搜索，将预测与自定义算法策略结合。而DRL框架在这些领域中已经大幅超越传统的活动搜索，但其端到端的结构不能充分利用在训练和决策过程中获得的指导信息。我们提议一种将DRL和传统的活动搜索结合在一起的方法，将搜索策略 decomposes为预测模块和搜索模块。预测模块根据任务嵌入和搜索历史生成地ospatial领域中的区域兴趣点，搜索模块将预测和搜索历史作为输入，输出搜索分布。我们开发了一种新的元学习方法，用于同时学习结果的结合策略，以便在训练和决策过程中有效地利用获得的指导信息。我们的广泛实验表明，我们的表示和元学习框架在多个问题领域中具有显著超越现状的性能。
</details></li>
</ul>
<hr>
<h2 id="Recursively-Constrained-Partially-Observable-Markov-Decision-Processes"><a href="#Recursively-Constrained-Partially-Observable-Markov-Decision-Processes" class="headerlink" title="Recursively-Constrained Partially Observable Markov Decision Processes"></a>Recursively-Constrained Partially Observable Markov Decision Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09688">http://arxiv.org/abs/2310.09688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Heng Ho, Tyler Becker, Ben Kraske, Zakariya Laouar, Martin Feather, Federico Rossi, Morteza Lahijanian, Zachary N. Sunberg</li>
<li>for: 本研究旨在解决受到转移不确定性和部分可见性限制的优化目标函数问题。</li>
<li>methods: 本研究使用了受到约束的部分 observable Markov Decision Process (C-POMDP) 模型，并提出了一种新的形式ulation，即 Recursively-Constrained POMDP (RC-POMDP)，以解决优化目标函数问题中的缺陷。</li>
<li>results: 研究发现，对于 C-POMDPs，优化策略可能会违反贝尔曼的优化原则，导致不良行为。而 RC-POMDPs 中的优化策略总是具有确定性，并且遵循贝尔曼的优化原则。研究还提出了一种基于点的动态计划算法，可以Synthesize RC-POMDPs 中的优化策略。在一系列 benchmark 问题中，研究发现 RC-POMDPs 中的策略比 C-POMDPs 中的策略更为愉悦，并且 demonstrate 了算法的可靠性。<details>
<summary>Abstract</summary>
In many problems, it is desirable to optimize an objective function while imposing constraints on some other aspect of the problem. A Constrained Partially Observable Markov Decision Process (C-POMDP) allows modelling of such problems while subject to transition uncertainty and partial observability. Typically, the constraints in C-POMDPs enforce a threshold on expected cumulative costs starting from an initial state distribution. In this work, we first show that optimal C-POMDP policies may violate Bellman's principle of optimality and thus may exhibit pathological behaviors, which can be undesirable for many applications. To address this drawback, we introduce a new formulation, the Recursively-Constrained POMDP (RC-POMDP), that imposes additional history dependent cost constraints on the C-POMDP. We show that, unlike C-POMDPs, RC-POMDPs always have deterministic optimal policies, and that optimal policies obey Bellman's principle of optimality. We also present a point-based dynamic programming algorithm that synthesizes optimal policies for RC-POMDPs. In our evaluations, we show that policies for RC-POMDPs produce more desirable behavior than policies for C-POMDPs and demonstrate the efficacy of our algorithm across a set of benchmark problems.
</details>
<details>
<summary>摘要</summary>
很多问题中，您希望优化一个目标函数，同时对另一个问题进行约束。一个受过чай�odel Markov决策过程（C-POMDP）可以模拟这些问题，同时受到过程不确定和部分可见性的影响。通常，C-POMDPs 中的约束都是对起始状态分布的预期总成本下的阈值。在这项工作中，我们首先表明了C-POMDP 的优化策略可能会违反 Bellman 的优化原理，从而导致不良行为，这可能对许多应用程序不符合预期。为解决这个缺点，我们引入了一种新的形式，即循环约束 POMDP（RC-POMDP），该形式在 C-POMDP 中添加了历史висимые成本约束。我们表明了，不同于 C-POMDPs，RC-POMDPs 的优化策略总是具有确定性，并且优化策略都遵循 Bellman 的优化原理。我们还提出了一种基于点的动态Programming算法，该算法可以Synthesize RC-POMDPs 中的优化策略。在我们的评估中，我们发现RC-POMDPs 中的策略产生了更加愿意的行为，并且我们的算法在一组标准问题上进行了评估， demonstrate了其效果。
</details></li>
</ul>
<hr>
<h2 id="Generative-artificial-intelligence-for-de-novo-protein-design"><a href="#Generative-artificial-intelligence-for-de-novo-protein-design" class="headerlink" title="Generative artificial intelligence for de novo protein design"></a>Generative artificial intelligence for de novo protein design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09685">http://arxiv.org/abs/2310.09685</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adam Winnifrith, Carlos Outeiral, Brian Hie</li>
<li>for: 这些论文的目的是探讨人工智能在蛋白质设计中的应用，以扩展我们对蛋白质的工程能力。</li>
<li>methods: 这些论文使用了生成型架构，如语言模型和扩散过程，生成 novel yet realistic 的蛋白质，以实现预先定义的功能和性能。</li>
<li>results: 现代设计协议的实验成功率已经接近 20%，从而扩大了蛋白质设计的可能性。  despite extensive progress, there are still challenges in the field, such as determining the best in silico metrics to prioritize designs for experimental testing, and designing proteins that can undergo large conformational changes or be regulated by post-translational modifications and other cellular processes.<details>
<summary>Abstract</summary>
Engineering new molecules with desirable functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called "de novo" design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example in determining the best in silico metrics to prioritise designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications and other cellular processes. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.
</details>
<details>
<summary>摘要</summary>
engineer新分子 possessing desired functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called "de novo" design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example in determining the best in silico metrics to prioritize designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications and other cellular processes. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. Traditional Chinese is also widely used, especially in Taiwan and Hong Kong.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/15/cs.AI_2023_10_15/" data-id="clontc8f3005j8788fh11dy0y" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_10_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/15/cs.CL_2023_10_15/" class="article-date">
  <time datetime="2023-10-15T11:00:00.000Z" itemprop="datePublished">2023-10-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/15/cs.CL_2023_10_15/">cs.CL - 2023-10-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="UvA-MT’s-Participation-in-the-WMT23-General-Translation-Shared-Task"><a href="#UvA-MT’s-Participation-in-the-WMT23-General-Translation-Shared-Task" class="headerlink" title="UvA-MT’s Participation in the WMT23 General Translation Shared Task"></a>UvA-MT’s Participation in the WMT23 General Translation Shared Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09946">http://arxiv.org/abs/2310.09946</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Wu, Shaomu Tan, David Stap, Ali Araabi, Christof Monz</li>
<li>for: 这个研究报告描述了阿姆斯特丹大学的自然语言处理实验室（UvA-MT）在2023年世界机器翻译大会（WMT）共享任务中的参加。他们在英文&lt;-&gt;希伯来两个方向的受限Track中参加竞赛，并显示了使用一个模型处理对向任务时，可以达到相似的结果，比较 Traditional的双语翻译。</li>
<li>methods: 这个研究使用了一些有效的策略，如回 перевод、重定义的嵌入表格和任务导向的精细调整，以提高自动评估中的最终结果。</li>
<li>results: 在自动评估中，他们在英文-&gt;希伯来和希伯来-&gt;英文两个方向中都获得了竞争性的结果。<details>
<summary>Abstract</summary>
This paper describes the UvA-MT's submission to the WMT 2023 shared task on general machine translation. We participate in the constrained track in two directions: English <-> Hebrew. In this competition, we show that by using one model to handle bidirectional tasks, as a minimal setting of Multilingual Machine Translation (MMT), it is possible to achieve comparable results with that of traditional bilingual translation for both directions. By including effective strategies, like back-translation, re-parameterized embedding table, and task-oriented fine-tuning, we obtained competitive final results in the automatic evaluation for both English -> Hebrew and Hebrew -> English directions.
</details>
<details>
<summary>摘要</summary>
translate to Simplified Chinese as follows:这篇论文描述了UvA-MT在WMT 2023共同任务中的提交，我们在Constrained Track中参加了英文 <-> 希伯来两个方向的翻译。在这次竞赛中，我们表明，通过使用一个模型处理双向任务，作为多语言翻译的最小设置（MMT），可以达到相同的结果。通过包括有效策略，如回译、重新参数表示表 и任务导向精度调整，我们在自动评估中获得了对 beiden方向的竞争性最终结果。
</details></li>
</ul>
<hr>
<h2 id="FiLM-Fill-in-Language-Models-for-Any-Order-Generation"><a href="#FiLM-Fill-in-Language-Models-for-Any-Order-Generation" class="headerlink" title="FiLM: Fill-in Language Models for Any-Order Generation"></a>FiLM: Fill-in Language Models for Any-Order Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09930">http://arxiv.org/abs/2310.09930</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shentianxiao/film">https://github.com/shentianxiao/film</a></li>
<li>paper_authors: Tianxiao Shen, Hao Peng, Ruoqi Shen, Yao Fu, Zaid Harchaoui, Yejin Choi</li>
<li>for: 填充语言模型 (Fill-in Language Model, FiLM) 的目的是提供一种可以在任意位置进行灵活生成的语言模型，以便在填充文本中使用双向文本上下文。</li>
<li>methods: FiLM 使用了一种新的语言模型方法，即采用 beta 分布中的变化掩码概率来提高 FiLM 的生成能力。在推理过程中，FiLM 可以顺利地插入缺失的句子、段落或整个文本，以确保输出的文本流畅、与周围上下文一致。</li>
<li>results: 在自动和人工评估中，FiLM 表现出色，超过了基于左到右语言模型的填充方法。FiLM 可以轻松地在不同的文本长度和难度水平上进行调整，并且可以在不同的语言模型大小上进行训练和 fine-tuning。<details>
<summary>Abstract</summary>
Language models have become the backbone of today's AI systems. However, their predominant left-to-right generation limits the use of bidirectional context, which is essential for tasks that involve filling text in the middle. We propose the Fill-in Language Model (FiLM), a new language modeling approach that allows for flexible generation at any position without adhering to a specific generation order. Its training extends the masked language modeling objective by adopting varying mask probabilities sampled from the Beta distribution to enhance the generative capabilities of FiLM. During inference, FiLM can seamlessly insert missing phrases, sentences, or paragraphs, ensuring that the outputs are fluent and are coherent with the surrounding context. In both automatic and human evaluations, FiLM outperforms existing infilling methods that rely on left-to-right language models trained on rearranged text segments. FiLM is easy to implement and can be either trained from scratch or fine-tuned from a left-to-right language model. Notably, as the model size grows, FiLM's perplexity approaches that of strong left-to-right language models of similar sizes, indicating FiLM's scalability and potential as a large language model.
</details>
<details>
<summary>摘要</summary>
现代人工智能系统中，语言模型已成为背景模型。然而，这些主要左往右生成的语言模型限制了使用对向文本填充的 bidirectional 上下文，这是装备填充文本的任务中非常重要。我们提出了填充语言模型（FiLM），一种新的语言模型化方法，可以在任何位置进行 flexible 生成，不受特定生成顺序的限制。它的训练将推广遮盾语言模型的对话预设，透过对应排版的 beta 分布来增强FiLM的生成能力。在推断中，FiLM可以顺利地插入缺失的句子、句末或段落，以确保输出的流畅和与周围上下文一致。在自动和人工评估中，FiLM比靠左往右的语言模型训练在重新排序的文本段落上的填充方法表现出色，并且可以轻松地从头部训练或精革左往右语言模型。值得一提的是，当模型的大小增加时，FiLM的误差接近强左往右语言模型相似大小的误差，这表明FiLM在大型模型中的可扩展性和潜力。
</details></li>
</ul>
<hr>
<h2 id="Prompting-Scientific-Names-for-Zero-Shot-Species-Recognition"><a href="#Prompting-Scientific-Names-for-Zero-Shot-Species-Recognition" class="headerlink" title="Prompting Scientific Names for Zero-Shot Species Recognition"></a>Prompting Scientific Names for Zero-Shot Species Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09929">http://arxiv.org/abs/2310.09929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shubham Parashar, Zhiqiu Lin, Yanan Li, Shu Kong</li>
<li>for: 本研究旨在使用CLIP进行零shot认知高级生物物种，包括鸟类、植物和动物的species recognition。</li>
<li>methods: 本研究使用CLIP进行零shot认知，并使用大语言模型（LLM）生成描述（例如物种颜色和形状）以提高性能。</li>
<li>results: 研究发现，使用common名称（例如mountain hare）而不是学名（例如Lepus Timidus）在prompt中可以提高CLIP的认知精度，并且可以达到2∼5倍的提升。<details>
<summary>Abstract</summary>
Trained on web-scale image-text pairs, Vision-Language Models (VLMs) such as CLIP can recognize images of common objects in a zero-shot fashion. However, it is underexplored how to use CLIP for zero-shot recognition of highly specialized concepts, e.g., species of birds, plants, and animals, for which their scientific names are written in Latin or Greek. Indeed, CLIP performs poorly for zero-shot species recognition with prompts that use scientific names, e.g., "a photo of Lepus Timidus" (which is a scientific name in Latin). Because these names are usually not included in CLIP's training set. To improve performance, prior works propose to use large-language models (LLMs) to generate descriptions (e.g., of species color and shape) and additionally use them in prompts. We find that they bring only marginal gains. Differently, we are motivated to translate scientific names (e.g., Lepus Timidus) to common English names (e.g., mountain hare) and use such in the prompts. We find that common names are more likely to be included in CLIP's training set, and prompting them achieves 2$\sim$5 times higher accuracy on benchmarking datasets of fine-grained species recognition.
</details>
<details>
<summary>摘要</summary>
<SYS>使用 web 级别的图片文本对，视觉语言模型（VLM）如 CLIP 可以不经过训练就识别通用对象的图片。但是，对于高度专业化的概念，如鸟类、植物和动物的种类，它们的科学名称通常是拉丁文或希腊文。CLIP 在无需训练的情况下识别这些种类的图片表现不佳，因为这些名称没有包含在 CLIP 的训练集中。以前的研究提议使用大型自然语言模型（LLM）生成描述（例如，种类颜色和形状），并将其添加到提示中。我们发现它们只提供了有限的改进。与此不同，我们强调将科学名称翻译成通用英文名称（例如，山兔），并使用这些名称作为提示。我们发现这样可以提高 CLIP 的准确率，在benchmarking数据集上实现2-5倍的提高。</SYS>Here's the translation in Traditional Chinese as well:<SYS>使用 web 级别的图片文本对，视觉语言模型（VLM）如 CLIP 可以不经过训练就识别通用对象的图片。但是，对于高度专业化的概念，如鸟类、植物和动物的种类，它们的科学名称通常是拉丁文或希腊文。CLIP 在无需训练的情况下识别这些种类的图片表现不佳，因为这些名称没有包含在 CLIP 的训练集中。以前的研究提议使用大型自然语言模型（LLM）生成描述（例如，种类颜色和形状），并将其添加到提示中。我们发现它们只提供了有限的改进。与此不同，我们强调将科学名称翻译成通用英文名称（例如，山兔），并使用这些名称作为提示。我们发现这样可以提高 CLIP 的准确率，在benchmarking数据集上实现2-5倍的提高。</SYS>
</details></li>
</ul>
<hr>
<h2 id="Empirical-study-of-pretrained-multilingual-language-models-for-zero-shot-cross-lingual-generation"><a href="#Empirical-study-of-pretrained-multilingual-language-models-for-zero-shot-cross-lingual-generation" class="headerlink" title="Empirical study of pretrained multilingual language models for zero-shot cross-lingual generation"></a>Empirical study of pretrained multilingual language models for zero-shot cross-lingual generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09917">http://arxiv.org/abs/2310.09917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nadezhda Chirkova, Sheng Liang, Vassilina Nikoulina</li>
<li>for: 这个论文旨在研究零shot cross-语言生成技术，即使finetuning多语言预训练语言模型（mPLM）在一种语言上的一个生成任务，然后用其来预测这个任务在其他语言上的结果。</li>
<li>methods: 这篇论文测试了一些替代的mPLM模型，包括mBART和NLLB，并考虑了全 Parameters 的 fine-tuning 和 parameter-efficient fine-tuning with adapters。</li>
<li>results: 研究发现，mBART with adapters 与 mT5 相似，NLLB 可以在一些情况下与 mT5 竞争。 此外，研究发现训练学习率对 fine-tuning 的调整可以减轻生成错误语言的问题。<details>
<summary>Abstract</summary>
Zero-shot cross-lingual generation assumes finetuning the multilingual pretrained language model (mPLM) on a generation task in one language and then using it to make predictions for this task in other languages. Previous works notice a frequent problem of generation in a wrong language and propose approaches to address it, usually using mT5 as a backbone model. In this work, we test alternative mPLMs, such as mBART and NLLB, considering full finetuning and parameter-efficient finetuning with adapters. We find that mBART with adapters performs similarly to mT5 of the same size, and NLLB can be competitive in some cases. We also underline the importance of tuning learning rate used for finetuning, which helps to alleviate the problem of generation in the wrong language.
</details>
<details>
<summary>摘要</summary>
zero-shot 跨语言生成假设通过质量化多语言预训练语言模型（mPLM）的 Fine-tuning 进行一种语言的生成任务，然后用其来预测这个任务的其他语言。  previous works 发现生成 incorrect language 的问题，并提出了解决方案，通常使用 mT5 作为基础模型。 在这个工作中，我们测试了不同的 mPLM，如 mBART 和 NLLB，包括全部 Fine-tuning 和参数有效的 Fine-tuning  WITH 适配器。我们发现 mBART  WITH 适配器 和 mT5 的同等大小下表现相似，而 NLLB 在一些情况下可以达到竞争水平。我们还强调了在 Fine-tuning 中调整学习率的重要性，可以减轻生成 incorrect language 的问题。
</details></li>
</ul>
<hr>
<h2 id="Can-GPT-4V-ision-Serve-Medical-Applications-Case-Studies-on-GPT-4V-for-Multimodal-Medical-Diagnosis"><a href="#Can-GPT-4V-ision-Serve-Medical-Applications-Case-Studies-on-GPT-4V-for-Multimodal-Medical-Diagnosis" class="headerlink" title="Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for Multimodal Medical Diagnosis"></a>Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for Multimodal Medical Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09909">http://arxiv.org/abs/2310.09909</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chaoyi-wu/gpt-4v_medical_evaluation">https://github.com/chaoyi-wu/gpt-4v_medical_evaluation</a></li>
<li>paper_authors: Chaoyi Wu, Jiayu Lei, Qiaoyu Zheng, Weike Zhao, Weixiong Lin, Xiaoman Zhang, Xiao Zhou, Ziheng Zhao, Ya Zhang, Yanfeng Wang, Weidi Xie</li>
<li>for: This paper assesses the performance of OpenAI’s GPT-4V model in multimodal medical diagnosis, evaluating its ability to distinguish between medical image modalities and anatomy, as well as its ability to generate comprehensive reports.</li>
<li>methods: The evaluation uses 17 human body systems and 8 modalities of medical images, with or without patent history provided, to probe the GPT-4V’s ability on multiple clinical tasks such as imaging modality and anatomy recognition, disease diagnosis, and report generation.</li>
<li>results: The study finds that while GPT-4V demonstrates proficiency in distinguishing between medical image modalities and anatomy, it faces significant challenges in disease diagnosis and generating comprehensive reports, highlighting the limitations of large multimodal models in supporting real-world medical applications and clinical decision-making.Here are the three key points in Simplified Chinese:</li>
<li>for: 这项研究用于评估OpenAI的GPT-4V模型在多模态医学诊断中的表现，包括分辨医疗影像模式和解剖结构等能力。</li>
<li>methods: 这项评估使用17个人体系统和8种医疗影像模式，有或无患者历史提供，以探索GPT-4V在多种临床任务上的能力，包括影像模式和解剖结构识别、疾病诊断、报告生成等。</li>
<li>results: 研究发现，虽然GPT-4V在分辨医疗影像模式和解剖结构方面表现出色，但在疾病诊断和生成全面报告方面受到了重大挑战，表明大型多模态模型在实际医疗应用和临床决策中仍有很大的发展空间。<details>
<summary>Abstract</summary>
Driven by the large foundation models, the development of artificial intelligence has witnessed tremendous progress lately, leading to a surge of general interest from the public. In this study, we aim to assess the performance of OpenAI's newest model, GPT-4V(ision), specifically in the realm of multimodal medical diagnosis. Our evaluation encompasses 17 human body systems, including Central Nervous System, Head and Neck, Cardiac, Chest, Hematology, Hepatobiliary, Gastrointestinal, Urogenital, Gynecology, Obstetrics, Breast, Musculoskeletal, Spine, Vascular, Oncology, Trauma, Pediatrics, with images taken from 8 modalities used in daily clinic routine, e.g., X-ray, Computed Tomography (CT), Magnetic Resonance Imaging (MRI), Positron Emission Tomography (PET), Digital Subtraction Angiography (DSA), Mammography, Ultrasound, and Pathology. We probe the GPT-4V's ability on multiple clinical tasks with or without patent history provided, including imaging modality and anatomy recognition, disease diagnosis, report generation, disease localisation.   Our observation shows that, while GPT-4V demonstrates proficiency in distinguishing between medical image modalities and anatomy, it faces significant challenges in disease diagnosis and generating comprehensive reports. These findings underscore that while large multimodal models have made significant advancements in computer vision and natural language processing, it remains far from being used to effectively support real-world medical applications and clinical decision-making.   All images used in this report can be found in https://github.com/chaoyi-wu/GPT-4V_Medical_Evaluation.
</details>
<details>
<summary>摘要</summary>
由大型基础模型驱动，人工智能的发展最近几年有了很大的进步，引起了公众的广泛关注。在这项研究中，我们想要评估OpenAI的最新模型GPT-4V（视觉）在多modal医学诊断方面的表现。我们的评估覆盖了17个人体系统，包括中枢神经系统、头颈部、心脏、胸部、血液系统、肝胆系统、肠道系统、尿道系统、妇科、儿科、骨骼系统、脊梁系统、血管系统、肿瘤系统、护理、外伤等，图像来自日常临床 Routine的8种模式，例如X射线、计算tomography（CT）、核磁共振成像（MRI）、 позитрон发射tomography（PET）、数字抽取ANGIOGRAPHY（DSA）、胸部X射线、计算tomography（CT）、ultrasound和pathology。我们 probing GPT-4V的能力在多种临床任务上，包括图像模式和解剖学识别、疾病诊断、报告生成、疾病Localization。我们的观察表明，GPT-4V能够Distinguish between different medical imaging modalities and anatomy, but it faces significant challenges in disease diagnosis and report generation. These findings highlight that while large multimodal models have made significant advancements in computer vision and natural language processing, they are still far from being used to effectively support real-world medical applications and clinical decision-making.所有图像使用在这项报告中可以在GitHub上找到：https://github.com/chaoyi-wu/GPT-4V_Medical_Evaluation。
</details></li>
</ul>
<hr>
<h2 id="Reformulating-NLP-tasks-to-Capture-Longitudinal-Manifestation-of-Language-Disorders-in-People-with-Dementia"><a href="#Reformulating-NLP-tasks-to-Capture-Longitudinal-Manifestation-of-Language-Disorders-in-People-with-Dementia" class="headerlink" title="Reformulating NLP tasks to Capture Longitudinal Manifestation of Language Disorders in People with Dementia"></a>Reformulating NLP tasks to Capture Longitudinal Manifestation of Language Disorders in People with Dementia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09897">http://arxiv.org/abs/2310.09897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitris Gkoumas, Matthew Purver, Maria Liakata</li>
<li>for: 这个研究是为了 automatization 语言障碍模式，以便更好地识别和评估词语障碍。</li>
<li>methods: 这个研究使用了一个已经训练过的自然语言处理（NLP）模型，并对其进行了修改，以便在NLP任务中强制使用语言模式。然后，他们使用了这些任务的概率估计来构建数字语言标记，用于评估语言交流质量和语言障碍的严重程度。</li>
<li>results: 研究发现，提出的语言标记能够准确地识别患有 деменция 的人的语言障碍，并且与临床标记呈正相关。此外，这些语言标记还提供了词语障碍的可观察性和恰当性，可以用于评估词语障碍的进程。<details>
<summary>Abstract</summary>
Dementia is associated with language disorders which impede communication. Here, we automatically learn linguistic disorder patterns by making use of a moderately-sized pre-trained language model and forcing it to focus on reformulated natural language processing (NLP) tasks and associated linguistic patterns. Our experiments show that NLP tasks that encapsulate contextual information and enhance the gradient signal with linguistic patterns benefit performance. We then use the probability estimates from the best model to construct digital linguistic markers measuring the overall quality in communication and the intensity of a variety of language disorders. We investigate how the digital markers characterize dementia speech from a longitudinal perspective. We find that our proposed communication marker is able to robustly and reliably characterize the language of people with dementia, outperforming existing linguistic approaches; and shows external validity via significant correlation with clinical markers of behaviour. Finally, our proposed linguistic disorder markers provide useful insights into gradual language impairment associated with disease progression.
</details>
<details>
<summary>摘要</summary>
偏僻症与语言障碍有关，我们通过自动学习受控语言模型，训练其专注于修改后NLP任务和相关的语言模式。我们的实验显示，包含语言上下文信息并在语言模式中增强梯度信号的NLP任务可以提高表现。然后，我们使用最佳模型的概率估计来构建数字语言标记，评估整体沟通质量和语言障碍的严重程度。我们研究如何使用我们的提议的沟通标记来 caracterize dementia speech的长期趋势。我们发现，我们的提议的语言障碍标记能够坚定可靠地 caracterize人们患有偏僻症的语言，高于现有的语言方法；并与临床标记相关。最后，我们的语言障碍标记提供了有用的透视 gradual language impairment与疾病进程相关的语言障碍。
</details></li>
</ul>
<hr>
<h2 id="Bounding-and-Filling-A-Fast-and-Flexible-Framework-for-Image-Captioning"><a href="#Bounding-and-Filling-A-Fast-and-Flexible-Framework-for-Image-Captioning" class="headerlink" title="Bounding and Filling: A Fast and Flexible Framework for Image Captioning"></a>Bounding and Filling: A Fast and Flexible Framework for Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09876">http://arxiv.org/abs/2310.09876</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/changxinwang/boficap">https://github.com/changxinwang/boficap</a></li>
<li>paper_authors: Zheng Ma, Changxin Wang, Bo Huang, Zixuan Zhu, Jianbing Zhang</li>
<li>for: 这篇论文目的是提出一种快速和灵活的图像描述模型，以解决现有的描述模型具有 significiant inference latency 问题。</li>
<li>methods: 该模型使用 bounding 和 filling 技术，将图像分割成多个区域，然后采用 two-generation 方式填充每个区域。</li>
<li>results: 该模型在 MS-COCO 测试集上取得了状态的最佳性能（CIDEr 125.6），并且比基eline模型快速 9.22 倍；在半循环的情况下，该模型达到了 128.4 的 CIDEr 性能，并且速度比基eline模型快速 3.69 倍。<details>
<summary>Abstract</summary>
Most image captioning models following an autoregressive manner suffer from significant inference latency. Several models adopted a non-autoregressive manner to speed up the process. However, the vanilla non-autoregressive manner results in subpar performance, since it generates all words simultaneously, which fails to capture the relationships between words in a description. The semi-autoregressive manner employs a partially parallel method to preserve performance, but it sacrifices inference speed. In this paper, we introduce a fast and flexible framework for image captioning called BoFiCap based on bounding and filling techniques. The BoFiCap model leverages the inherent characteristics of image captioning tasks to pre-define bounding boxes for image regions and their relationships. Subsequently, the BoFiCap model fills corresponding words in each box using two-generation manners. Leveraging the box hints, our filling process allows each word to better perceive other words. Additionally, our model offers flexible image description generation: 1) by employing different generation manners based on speed or performance requirements, 2) producing varied sentences based on user-specified boxes. Experimental evaluations on the MS-COCO benchmark dataset demonstrate that our framework in a non-autoregressive manner achieves the state-of-the-art on task-specific metric CIDEr (125.6) while speeding up 9.22x than the baseline model with an autoregressive manner; in a semi-autoregressive manner, our method reaches 128.4 on CIDEr while a 3.69x speedup. Our code and data is available at https://github.com/ChangxinWang/BoFiCap.
</details>
<details>
<summary>摘要</summary>
大多数图像描述模型采用回归方式，却受到显著的推理延迟。一些模型采用非回归方式以加速过程，但这会导致性能下降，因为它们同时生成所有 слова，无法捕捉图像描述中 слова之间的关系。半回归方式使用部分并行方法保持性能，但是它们牺牲推理速度。本文提出一种快速和灵活的图像描述模型called BoFiCap，基于缓存和填充技术。BoFiCap模型利用图像描述任务的特点，先定义图像区域的缓存框，然后使用两种生成方式填充对应的字。利用框提示，我们的填充过程让每个字etter perceive其他字。此外，我们的模型提供了自适应的图像描述生成：1）根据速度或性能要求使用不同的生成方式，2）生成基于用户指定的盒子的多种句子。在COCO数据集上的实验评估 demonstrate了我们的框架在非回归方式下达到了状态之arte（CIDEr=125.6），同时速度比基eline模型（具有回归方式）快9.22倍。在半回归方式下，我们的方法达到了128.4的CIDEr，速度比基eline模型快3.69倍。我们的代码和数据可以在https://github.com/ChangxinWang/BoFiCap上获取。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Stance-Classification-with-Quantified-Moral-Foundations"><a href="#Enhancing-Stance-Classification-with-Quantified-Moral-Foundations" class="headerlink" title="Enhancing Stance Classification with Quantified Moral Foundations"></a>Enhancing Stance Classification with Quantified Moral Foundations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09848">http://arxiv.org/abs/2310.09848</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Zhang, Prasanta Bhattacharya, Wei Gao, Liang Ze Wong, Brandon Siyuan Loh, Joseph J. P. Simons, Jisun An</li>
<li>for: 这 paper 的目的是增强社交媒体上的立场检测，通过 incorporating deeper psychological attributes，特别是个人的道德基础。</li>
<li>methods: 这 paper 使用的方法包括EXTRACTING moral foundation features from text, 以及 message semantic features，来 классифика stance 在 message- 和 user-levels 上。</li>
<li>results:  Preliminary results 表明， encoding moral foundations 可以提高 stance detection 任务的性能，并帮助描述特定道德基础和 online stance 之间的关系。  results highlight the importance of considering deeper psychological attributes in stance analysis and underscores the role of moral foundations in guiding online social behavior.<details>
<summary>Abstract</summary>
This study enhances stance detection on social media by incorporating deeper psychological attributes, specifically individuals' moral foundations. These theoretically-derived dimensions aim to provide a comprehensive profile of an individual's moral concerns which, in recent work, has been linked to behaviour in a range of domains, including society, politics, health, and the environment. In this paper, we investigate how moral foundation dimensions can contribute to predicting an individual's stance on a given target. Specifically we incorporate moral foundation features extracted from text, along with message semantic features, to classify stances at both message- and user-levels across a range of targets and models. Our preliminary results suggest that encoding moral foundations can enhance the performance of stance detection tasks and help illuminate the associations between specific moral foundations and online stances on target topics. The results highlight the importance of considering deeper psychological attributes in stance analysis and underscores the role of moral foundations in guiding online social behavior.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Merging-Experts-into-One-Improving-Computational-Efficiency-of-Mixture-of-Experts"><a href="#Merging-Experts-into-One-Improving-Computational-Efficiency-of-Mixture-of-Experts" class="headerlink" title="Merging Experts into One: Improving Computational Efficiency of Mixture of Experts"></a>Merging Experts into One: Improving Computational Efficiency of Mixture of Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09832">http://arxiv.org/abs/2310.09832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shwai-he/meo">https://github.com/shwai-he/meo</a></li>
<li>paper_authors: Shwai He, Run-Ze Fan, Liang Ding, Li Shen, Tianyi Zhou, Dacheng Tao</li>
<li>for: 提高语言模型的大小通常会导致NLPTasks的进步，但是会增加计算成本。零含量的混合专家（MoE）可以减少计算成本，但是如果增加激活专家的数量，计算成本会增加很快，限制实际应用。本文提出一种名为\textbf{\texttt{Merging Experts into One}（MEO）的计算效率的方法，可以保持增加专家的优点而不导致计算成本增加。</li>
<li>methods: 我们首先证明选择多个专家的优势，然后提出一种计算效率的方法，即\textbf{\texttt{Merging Experts into One}（MEO），可以将计算成本降低到单个专家的水平。此外，我们还提出了一种符号级注意块，可以进一步提高MEO的效率和表现。</li>
<li>results: 我们进行了广泛的实验，显示MEO可以减少计算成本，例如FLOPS从72.0G下降到28.6G（MEO）。此外，我们还提出了一种符号级注意块，可以进一步提高MEO的效率和表现。例如，在GLUE benchmark上，MEO的平均分数为83.3%，而vanilla MoE的平均分数为82.6%。<details>
<summary>Abstract</summary>
Scaling the size of language models usually leads to remarkable advancements in NLP tasks. But it often comes with a price of growing computational cost. Although a sparse Mixture of Experts (MoE) can reduce the cost by activating a small subset of parameters (e.g., one expert) for each input, its computation escalates significantly if increasing the number of activated experts, limiting its practical utility. Can we retain the advantages of adding more experts without substantially increasing the computational costs? In this paper, we first demonstrate the superiority of selecting multiple experts and then propose a computation-efficient approach called \textbf{\texttt{Merging Experts into One} (MEO), which reduces the computation cost to that of a single expert. Extensive experiments show that MEO significantly improves computational efficiency, e.g., FLOPS drops from 72.0G of vanilla MoE to 28.6G (MEO). Moreover, we propose a token-level attention block that further enhances the efficiency and performance of token-level MEO, e.g., 83.3\% (MEO) vs. 82.6\% (vanilla MoE) average score on the GLUE benchmark. Our code will be released upon acceptance. Code will be released at: \url{https://github.com/Shwai-He/MEO}.
</details>
<details>
<summary>摘要</summary>
通常，将语言模型的大小扩展到可观的尺度会导致NLPTasks的显著进步。然而，这经常会带来计算成本的增加。虽然 sparse Mixture of Experts（MoE）可以降低计算成本，但是如果启用更多的专家，计算成本会快速增加，限制其实际应用。我们是否可以保留添加更多专家的优点而不导致计算成本增加很多？在这篇论文中，我们首先表明了多个专家的选择的优势，然后我们提出了一种 computation-efficient的方法called \textbf{\texttt{Merging Experts into One}（MEO），可以降低计算成本到单个专家的水平。我们进行了广泛的实验，发现 MEO 可以减少 FLOPS 的值，例如，从 vanilla MoE 的 72.0G 降低到 28.6G（MEO）。此外，我们还提出了一种循环预测块，可以进一步提高 MEO 的效率和性能，例如，在 GLUE 测试准则上，MEO 的平均分数为 83.3%，而 vanilla MoE 的平均分数为 82.6%。我们将代码发布在接受后。代码将发布在：\url{https://github.com/Shwai-He/MEO}.
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-Reliability-of-Large-Language-Model-Knowledge"><a href="#Assessing-the-Reliability-of-Large-Language-Model-Knowledge" class="headerlink" title="Assessing the Reliability of Large Language Model Knowledge"></a>Assessing the Reliability of Large Language Model Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09820">http://arxiv.org/abs/2310.09820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weixuan Wang, Barry Haddow, Alexandra Birch, Wei Peng</li>
<li>for: 评估大语言模型（LLMs）的知识可靠性。</li>
<li>methods: 提出了一种名为 Model Knowledge Relibility Score (MONITOR) 的新度量方法，用于直接测试 LLMs 的事实可靠性。</li>
<li>results: 在一系列12种 LLMS 上进行了实验，并证明了 MONITOR 的效iveness 以及低计算成本。此外，还释放了一个名为 Factual Knowledge Test Corpus (FKTC) 的测试集，以便进一步研究。<details>
<summary>Abstract</summary>
Large language models (LLMs) have been treated as knowledge bases due to their strong performance in knowledge probing tasks. LLMs are typically evaluated using accuracy, yet this metric does not capture the vulnerability of LLMs to hallucination-inducing factors like prompt and context variability. How do we evaluate the capabilities of LLMs to consistently produce factually correct answers? In this paper, we propose MOdel kNowledge relIabiliTy scORe (MONITOR), a novel metric designed to directly measure LLMs' factual reliability. MONITOR computes the distance between the probability distributions of a valid output and its counterparts produced by the same LLM probing the same fact using different styles of prompts and contexts.Experiments on a comprehensive range of 12 LLMs demonstrate the effectiveness of MONITOR in evaluating the factual reliability of LLMs while maintaining a low computational overhead. In addition, we release the FKTC (Factual Knowledge Test Corpus) test set, containing 210,158 prompts in total to foster research along this line (https://github.com/Vicky-Wil/MONITOR).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="RSVP-Customer-Intent-Detection-via-Agent-Response-Contrastive-and-Generative-Pre-Training"><a href="#RSVP-Customer-Intent-Detection-via-Agent-Response-Contrastive-and-Generative-Pre-Training" class="headerlink" title="RSVP: Customer Intent Detection via Agent Response Contrastive and Generative Pre-Training"></a>RSVP: Customer Intent Detection via Agent Response Contrastive and Generative Pre-Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09773">http://arxiv.org/abs/2310.09773</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tommytyc/rsvp">https://github.com/tommytyc/rsvp</a></li>
<li>paper_authors: Yu-Chien Tang, Wei-Yao Wang, An-Zi Yen, Wen-Chih Peng</li>
<li>for: 提供用户task-oriented对话中的精准回答和24小时支持</li>
<li>methods: 利用神经网络模型检测客户意图 based on their utterances</li>
<li>results: 与状态空间的基eline比进行了比较，得到了4.95%的准确率提升，3.4%的MRR@3提升和2.75%的MRR@5提升的结果<details>
<summary>Abstract</summary>
The dialogue systems in customer services have been developed with neural models to provide users with precise answers and round-the-clock support in task-oriented conversations by detecting customer intents based on their utterances. Existing intent detection approaches have highly relied on adaptively pre-training language models with large-scale datasets, yet the predominant cost of data collection may hinder their superiority. In addition, they neglect the information within the conversational responses of the agents, which have a lower collection cost, but are significant to customer intent as agents must tailor their replies based on the customers' intent. In this paper, we propose RSVP, a self-supervised framework dedicated to task-oriented dialogues, which utilizes agent responses for pre-training in a two-stage manner. Specifically, we introduce two pre-training tasks to incorporate the relations of utterance-response pairs: 1) Response Retrieval by selecting a correct response from a batch of candidates, and 2) Response Generation by mimicking agents to generate the response to a given utterance. Our benchmark results for two real-world customer service datasets show that RSVP significantly outperforms the state-of-the-art baselines by 4.95% for accuracy, 3.4% for MRR@3, and 2.75% for MRR@5 on average. Extensive case studies are investigated to show the validity of incorporating agent responses into the pre-training stage.
</details>
<details>
<summary>摘要</summary>
Dialogue 系统在客户服务中已经采用神经网络模型，以提供用户精准的答案和24小时的支持，通过检测客户意图基于他们的谈话来进行任务化对话。现有的意图检测方法强调适应性地预训练语言模型，但这可能增加成本。此外，它们忽略了代理人回复的信息，尽管这些信息在客户意图方面具有重要性，因为代理人必须根据客户的意图修改他们的回复。在本文中，我们提出了 RSVP，一个自动预训练框架，专门用于任务化对话。我们在两个阶段中使用代理人回复进行预训练：1）回复选择，选择一个正确的回复从批处理中的候选者中，2）回复生成，模仿代理人生成一个回复来回应给一个谈话。我们对两个实际的客户服务数据集进行了比较，结果显示，RSVP在精度、MRR@3和MRR@5等指标上平均高于状态之前的基eline by 4.95%、3.4%和2.75%。我们还进行了广泛的案例研究，以证明代理人回复的包含在预训练阶段是有效的。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Graph-Meaning-Representations-through-Decoupling-Contextual-Representation-Learning-and-Structural-Information-Propagation"><a href="#Revisiting-Graph-Meaning-Representations-through-Decoupling-Contextual-Representation-Learning-and-Structural-Information-Propagation" class="headerlink" title="Revisiting Graph Meaning Representations through Decoupling Contextual Representation Learning and Structural Information Propagation"></a>Revisiting Graph Meaning Representations through Decoupling Contextual Representation Learning and Structural Information Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09772">http://arxiv.org/abs/2310.09772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Zhou, Wenyu Chen, Dingyi Zeng, Hong Qu, Daniel Hershcovich</li>
<li>for: 本研究旨在探讨图意表示（GMRs）在关系EXTRACTION任务中的精确影响。</li>
<li>methods: 本研究提出了一种简单和参数效率高的神经网络架构，用于分离上下文表示学习和结构信息传递。</li>
<li>results: 研究结果表明，GMRs在四个英文和两个中文 dataset 中有所提高表达关系的性能，特别是英文dataset更加精确。然而，在文学领域dataset中，GMRs的效果较低。这些发现可以为将来关系EXTRACTION任务中的GMRs和 parser设计提供更好的指导。<details>
<summary>Abstract</summary>
In the field of natural language understanding, the intersection of neural models and graph meaning representations (GMRs) remains a compelling area of research. Despite the growing interest, a critical gap persists in understanding the exact influence of GMRs, particularly concerning relation extraction tasks. Addressing this, we introduce DAGNN-plus, a simple and parameter-efficient neural architecture designed to decouple contextual representation learning from structural information propagation. Coupled with various sequence encoders and GMRs, this architecture provides a foundation for systematic experimentation on two English and two Chinese datasets. Our empirical analysis utilizes four different graph formalisms and nine parsers. The results yield a nuanced understanding of GMRs, showing improvements in three out of the four datasets, particularly favoring English over Chinese due to highly accurate parsers. Interestingly, GMRs appear less effective in literary-domain datasets compared to general-domain datasets. These findings lay the groundwork for better-informed design of GMRs and parsers to improve relation classification, which is expected to tangibly impact the future trajectory of natural language understanding research.
</details>
<details>
<summary>摘要</summary>
在自然语言理解领域，神经网络和图意表示（GMR）的交叉研究仍然吸引着广泛的关注。尽管有增长的兴趣，但是关于GMR的具体影响仍然存在一个重要的知识 gap。为了解决这个问题，我们介绍了DAGNN-plus，一种简单而参数有效的神经网络架构，用于分离上下文表示学习和结构信息传递。与不同的序列编码器和GMR相结合，这个架构提供了对系统实验的基础，并在四种图形式和九个解析器的支持下进行了实验分析。我们的实验结果表明，GMR在英文和中文两个领域中的表现不同，特别是在文学领域比通用领域更具有优势。这些发现为将来改进GMR和解析器的设计，以提高关系类别的识别，这将对自然语言理解研究的未来轨迹产生直接的影响。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Model-Aware-In-Context-Learning-for-Code-Generation"><a href="#Large-Language-Model-Aware-In-Context-Learning-for-Code-Generation" class="headerlink" title="Large Language Model-Aware In-Context Learning for Code Generation"></a>Large Language Model-Aware In-Context Learning for Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09748">http://arxiv.org/abs/2310.09748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia Li, Ge Li, Chongyang Tao, Jia Li, Huangzhao Zhang, Fang Liu, Zhi Jin</li>
<li>for: 这 paper 的目的是提出一种基于学习的选择方法，以提高 Code Generation 中 LLMS 的培养效果。</li>
<li>methods: 这 paper 使用了 LLMS 自身的生成概率来评估候选示例，然后通过对概率反馈来标注候选示例为正负。最后，通过带有对比学习目标的带有对比学习目标的导入，训练一个有效的检索器，以获得 LLMS 在 Code Generation 中的偏好。</li>
<li>results: 这 paper 的实验结果表明，LAIL 可以在 CodeGen 和 GPT-3.5 上提高 LLMS 的培养效果，相比之前的基eline 提高了11.58%、6.89%和5.07%，以及4.38%、2.85%和2.74%。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown impressive in-context learning (ICL) ability in code generation. LLMs take a prompt consisting of requirement-code examples and a new requirement as input, and output new programs. Existing studies have found that ICL is highly dominated by the examples and thus arises research on example selection. However, existing approaches randomly select examples or only consider the textual similarity of requirements to retrieve, leading to sub-optimal performance. In this paper, we propose a novel learning-based selection approach named LAIL (LLM-Aware In-context Learning) for code generation. Given a candidate example, we exploit LLMs themselves to estimate it by considering the generation probabilities of ground-truth programs given a requirement and the example. We then label candidate examples as positive or negative through the probability feedback. Based on the labeled data, we import a contrastive learning objective to train an effective retriever that acquires the preference of LLMs in code generation. We apply LAIL to three LLMs and evaluate it on three representative datasets (e.g., MBJP, MBPP, and MBCPP). LATA outperforms the state-of-the-art baselines by 11.58%, 6.89%, and 5.07% on CodeGen, and 4.38%, 2.85%, and 2.74% on GPT-3.5 in terms of Pass@1, respectively.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在代码生成中表现出了吸引人的上下文学习（ICL）能力。LLM 接受一个包含需求代码示例和新需求的提示，并输出新的程序。现有的研究发现，ICL 受到示例的影响很大，因此引发了研究示例选择的研究。然而，现有的方法 Randomly 选择示例或者只考虑需求文本相似性来 retrieve，导致表现不佳。在这篇论文中，我们提出了一种新的学习基于选择方法 named LAIL（LLM-Aware In-context Learning）。给定一个候选示例，我们利用 LLM 自己来估算它，通过考虑需求和示例下的生成概率来Feedback probability。然后，我们将候选示例标记为正例或者负例，根据概率反馈。基于标记数据，我们导入了对比学习目标，以培养一个有效的检索器，使其获得 LLM 在代码生成中的偏好。我们在三个 LLM 上应用 LAIL，并对 MBJP、MBPP 和 MBCPP 三个表示性数据集进行评估。LATA 与当前基eline 相比，提高了代码生成的性能，具体是11.58%、6.89% 和 5.07% 的提升。
</details></li>
</ul>
<hr>
<h2 id="Overview-of-ImageArg-2023-The-First-Shared-Task-in-Multimodal-Argument-Mining"><a href="#Overview-of-ImageArg-2023-The-First-Shared-Task-in-Multimodal-Argument-Mining" class="headerlink" title="Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining"></a>Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.12172">http://arxiv.org/abs/2310.12172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhexiong Liu, Mohamed Elaraby, Yang Zhong, Diane Litman</li>
<li>for: 这篇论文提供了 ImageArg 共同任务的概述，这是第一个 Multimodal Argument Mining 共同任务，它在 EMNLP 2023 年度会议上召开。</li>
<li>methods: 这篇论文描述了两个分类子任务：（1）Argument Stance Classification，即判断一个包含图片和文本的推文是否支持或反对一个热点话题（如枪支持和堕胎）；（2）Image Persuasiveness Classification，即判断图片是否使文本更加吸引人。</li>
<li>results: 这个共同任务收到了 31 个参赛作品，其中 21 个来自 9 个团队，来自 6 个国家。最佳提交在 Subtask-A 中获得了 F1 分数 0.8647，而在 Subtask-B 中获得了 F1 分数 0.5561。<details>
<summary>Abstract</summary>
This paper presents an overview of the ImageArg shared task, the first multimodal Argument Mining shared task co-located with the 10th Workshop on Argument Mining at EMNLP 2023. The shared task comprises two classification subtasks - (1) Subtask-A: Argument Stance Classification; (2) Subtask-B: Image Persuasiveness Classification. The former determines the stance of a tweet containing an image and a piece of text toward a controversial topic (e.g., gun control and abortion). The latter determines whether the image makes the tweet text more persuasive. The shared task received 31 submissions for Subtask-A and 21 submissions for Subtask-B from 9 different teams across 6 countries. The top submission in Subtask-A achieved an F1-score of 0.8647 while the best submission in Subtask-B achieved an F1-score of 0.5561.
</details>
<details>
<summary>摘要</summary>
这份论文介绍了图像论据共同任务（ImageArg），这是在EMNLP 2023年工作坊上的第一个多Modal Argument Mining共同任务。该任务包括两个分类子任务：（1）子任务A：图像立场分类；（2）子任务B：图像宣传效果分类。前者确定一个推文中的图像和文本对于一个争议话题（例如，枪支控制和堕胎）的立场。后者确定图像是否使得推文文本更加吸引人。共同任务收到了31个提交 для子任务A和21个提交 для子任务B来自9个不同的团队在6个国家。最佳提交在子任务A中取得了F1分数0.8647，而最佳提交在子任务B中取得了F1分数0.5561。
</details></li>
</ul>
<hr>
<h2 id="KGQuiz-Evaluating-the-Generalization-of-Encoded-Knowledge-in-Large-Language-Models"><a href="#KGQuiz-Evaluating-the-Generalization-of-Encoded-Knowledge-in-Large-Language-Models" class="headerlink" title="KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models"></a>KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09725">http://arxiv.org/abs/2310.09725</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leopoldwhite/kgquiz">https://github.com/leopoldwhite/kgquiz</a></li>
<li>paper_authors: Yuyang Bai, Shangbin Feng, Vidhisha Balachandran, Zhaoxuan Tan, Shiqi Lou, Tianxing He, Yulia Tsvetkov</li>
<li>for: 这个论文旨在探讨大语言模型（LLM）在知识培养任务上的表现，以及如何系统地评估LLM的知识能力和其在不同知识领域和任务格式下的普适性。</li>
<li>methods: 这篇论文提出了一个名为KGQuiz的知识强度测试 benchmark，用于全面检验LLM的知识普适性和可行性。KGQuiz包括三个知识领域和五种任务 formats，从简单的真或假问题到复杂的开放知识生成。</li>
<li>results: 经过广泛的实验表明，LLM在简单的知识 QA 任务上表现出色，但是需要更复杂的推理或使用域pecific的知识时仍然存在很大挑战。这些结果表明KGQuiz可以用于分析LLM的知识能力和普适性在不同知识领域和任务格式下的变化。<details>
<summary>Abstract</summary>
Large language models (LLMs) demonstrate remarkable performance on knowledge-intensive tasks, suggesting that real-world knowledge is encoded in their model parameters. However, besides explorations on a few probing tasks in limited knowledge domains, it is not well understood how to evaluate LLMs' knowledge systematically and how well their knowledge abilities generalize, across a spectrum of knowledge domains and progressively complex task formats. To this end, we propose KGQuiz, a knowledge-intensive benchmark to comprehensively investigate the knowledge generalization abilities of LLMs. KGQuiz is a scalable framework constructed from triplet-based knowledge, which covers three knowledge domains and consists of five tasks with increasing complexity: true-or-false, multiple-choice QA, blank filling, factual editing, and open-ended knowledge generation. To gain a better understanding of LLMs' knowledge abilities and their generalization, we evaluate 10 open-source and black-box LLMs on the KGQuiz benchmark across the five knowledge-intensive tasks and knowledge domains. Extensive experiments demonstrate that LLMs achieve impressive performance in straightforward knowledge QA tasks, while settings and contexts requiring more complex reasoning or employing domain-specific facts still present significant challenges. We envision KGQuiz as a testbed to analyze such nuanced variations in performance across domains and task formats, and ultimately to understand, evaluate, and improve LLMs' knowledge abilities across a wide spectrum of knowledge domains and tasks.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在知识密集任务中表现出色，表明其模型参数中含有真实世界知识。然而，关于如何系统地评估 LLM 的知识能力和其知识能力是否可以普遍应用于多个知识领域和复杂任务格式，还不够了解。为此，我们提出了 KGQuiz，一个用于全面探索 LLM 的知识普适能力的benchmark。KGQuiz 基于 triplet 知识结构，覆盖了三个知识领域，包括五种任务 formats，从简单的true-or-false 和多选问答，到复杂的blank filling和factual editing，最后是开放式知识生成。为了更好地理解 LLM 的知识能力和其普适性，我们在 KGQuiz benchmark 上测试了 10 个开源和黑盒 LLM，并进行了广泛的实验。结果表明， LLM 在直观知识 QA 任务中表现出色，但是需要更复杂的解释或使用域pecific的事实时仍然存在很大的挑战。我们认为 KGQuiz 可以作为一个测试台来分析这些 nuanced 的表现差异，并 ultimately 理解、评估和提高 LLM 的知识能力在多个知识领域和任务格式中。
</details></li>
</ul>
<hr>
<h2 id="HiCL-Hierarchical-Contrastive-Learning-of-Unsupervised-Sentence-Embeddings"><a href="#HiCL-Hierarchical-Contrastive-Learning-of-Unsupervised-Sentence-Embeddings" class="headerlink" title="HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings"></a>HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09720">http://arxiv.org/abs/2310.09720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuofeng Wu, Chaowei Xiao, VG Vinod Vydiswaran</li>
<li>for: 提高序列表示学习的效率和有效性，通过地方归一化和全序列归一化的对比学习来学习地方和全序列之间的关系。</li>
<li>methods: 提出了一种层次对比学习框架（HiCL），将序列分成多个段，使用地方和全序列归一化对比学习来学习段级和序列级关系，并且通过首先编码短段并然后聚合以提高训练效率。</li>
<li>results: 对比于传统方法，HiCL能够提高7种广泛评估的STS任务的前一个表现，升师平均提高+0.2%（BERT-large）和+0.44%（RoBERTa-large）。<details>
<summary>Abstract</summary>
In this paper, we propose a hierarchical contrastive learning framework, HiCL, which considers local segment-level and global sequence-level relationships to improve training efficiency and effectiveness. Traditional methods typically encode a sequence in its entirety for contrast with others, often neglecting local representation learning, leading to challenges in generalizing to shorter texts. Conversely, HiCL improves its effectiveness by dividing the sequence into several segments and employing both local and global contrastive learning to model segment-level and sequence-level relationships. Further, considering the quadratic time complexity of transformers over input tokens, HiCL boosts training efficiency by first encoding short segments and then aggregating them to obtain the sequence representation. Extensive experiments show that HiCL enhances the prior top-performing SNCSE model across seven extensively evaluated STS tasks, with an average increase of +0.2% observed on BERT-large and +0.44% on RoBERTa-large.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一个层次对比学习框架，即HiCL，该框架考虑了本地分割段级和全序列级关系，以提高训练效率和有效性。传统方法通常将序列编码为整体对比他们，而忽略本地表示学习，这会导致对短文本掌握困难。相反，HiCL通过将序列分割成多个段，并使用本地和全序列对比学习来模型段级和序列级关系。此外，考虑到 transformer 对输入字符数的平方时间复杂度，HiCL 提高了训练效率，先对短段进行编码，然后将其聚合以获得序列表示。广泛的实验表明，HiCL 可以提高先前的最佳 SNCSE 模型在七个广泛评估的 STS 任务上，平均提高 +0.2% 在 BERT-large 上和 +0.44% 在 RoBERTa-large 上。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/15/cs.CL_2023_10_15/" data-id="clontc8h900cj878819wm4dr4" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_10_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/15/cs.LG_2023_10_15/" class="article-date">
  <time datetime="2023-10-15T10:00:00.000Z" itemprop="datePublished">2023-10-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/15/cs.LG_2023_10_15/">cs.LG - 2023-10-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AMAGO-Scalable-In-Context-Reinforcement-Learning-for-Adaptive-Agents"><a href="#AMAGO-Scalable-In-Context-Reinforcement-Learning-for-Adaptive-Agents" class="headerlink" title="AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents"></a>AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09971">http://arxiv.org/abs/2310.09971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ut-austin-rpl/amago">https://github.com/ut-austin-rpl/amago</a></li>
<li>paper_authors: Jake Grigsby, Linxi Fan, Yuke Zhu</li>
<li>for: The paper is written to tackle the challenges of generalization, long-term memory, and meta-learning in in-context Reinforcement Learning (RL) agents.</li>
<li>methods: The paper proposes a new in-context RL agent called AMAGO, which uses sequence models and off-policy learning to overcome the limitations of previous approaches.</li>
<li>results: The paper demonstrates the strong performance of AMAGO in meta-RL and long-term memory domains, and shows that it can solve goal-conditioned problems with challenging exploration. Additionally, the paper introduces a novel hindsight relabeling scheme that allows AMAGO to solve open-world domains.<details>
<summary>Abstract</summary>
We introduce AMAGO, an in-context Reinforcement Learning (RL) agent that uses sequence models to tackle the challenges of generalization, long-term memory, and meta-learning. Recent works have shown that off-policy learning can make in-context RL with recurrent policies viable. Nonetheless, these approaches require extensive tuning and limit scalability by creating key bottlenecks in agents' memory capacity, planning horizon, and model size. AMAGO revisits and redesigns the off-policy in-context approach to successfully train long-sequence Transformers over entire rollouts in parallel with end-to-end RL. Our agent is uniquely scalable and applicable to a wide range of problems. We demonstrate its strong performance empirically in meta-RL and long-term memory domains. AMAGO's focus on sparse rewards and off-policy data also allows in-context learning to extend to goal-conditioned problems with challenging exploration. When combined with a novel hindsight relabeling scheme, AMAGO can solve a previously difficult category of open-world domains, where agents complete many possible instructions in procedurally generated environments. We evaluate our agent on three goal-conditioned domains and study how its individual improvements connect to create a generalist policy.
</details>
<details>
<summary>摘要</summary>
我们介绍AMAGO，一个内Context Reinforcement Learning（RL）代理人，使用序列模型解决通用化、长期记忆和元学习的挑战。现有研究表明，离政RL可以使内Context RL with recurrent policies成为可能。然而，这些方法需要广泛的调整和限制数据容量、观察 horizon和模型大小，导致代理人的可扩展性和应用范围受限。AMAGO重新评估和重新设计了离政内Context Approach，成功地在整个推套中平行训练长序Transformer，并且具有广泛适用性。我们在Meta-RL和长期记忆领域 empirically 显示了它的强大表现。AMAGO的专注点在于罕见的 reward和离政数据也使内Context learning扩展到目标条件下的问题。当与一个新的预测重新标示方案相结合时，AMAGO可以解决一些过去Difficult的开放世界领域，其中代理人完成了许多可能的指令在生成的环境中。我们在三个目标条件下评估了我们的代理人，并研究了它们个别的改进如何相互连接，创建一个通用的政策。
</details></li>
</ul>
<hr>
<h2 id="Theoretical-Evaluation-of-Asymmetric-Shapley-Values-for-Root-Cause-Analysis"><a href="#Theoretical-Evaluation-of-Asymmetric-Shapley-Values-for-Root-Cause-Analysis" class="headerlink" title="Theoretical Evaluation of Asymmetric Shapley Values for Root-Cause Analysis"></a>Theoretical Evaluation of Asymmetric Shapley Values for Root-Cause Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09961">http://arxiv.org/abs/2310.09961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Domokos M. Kelen, Mihály Petreczky, Péter Kersch, András A. Benczúr</li>
<li>for: 本研究探讨非对称的雪岭值（ASV），它是SHAP加itive本地解释方法的一种变体，可以在模型预测中检测不公正抵制。</li>
<li>methods: 本研究使用variance的方法来解释ASV的方法，并在多个实际 dataset上进行了比较，以证明ASV在特定模型家族中的有用性。</li>
<li>results: 研究发现，在某些情况下，ASV可能会产生Counter-intuitive的解释结果，这可能会导致模型预测中的根本原因分析错误。此外，研究还发现了一些特定的模型家族，如泛型加itive模型（GAM），在这些家族中，ASV具有愉悦的性质。<details>
<summary>Abstract</summary>
In this work, we examine Asymmetric Shapley Values (ASV), a variant of the popular SHAP additive local explanation method. ASV proposes a way to improve model explanations incorporating known causal relations between variables, and is also considered as a way to test for unfair discrimination in model predictions. Unexplored in previous literature, relaxing symmetry in Shapley values can have counter-intuitive consequences for model explanation. To better understand the method, we first show how local contributions correspond to global contributions of variance reduction. Using variance, we demonstrate multiple cases where ASV yields counter-intuitive attributions, arguably producing incorrect results for root-cause analysis. Second, we identify generalized additive models (GAM) as a restricted class for which ASV exhibits desirable properties. We support our arguments by proving multiple theoretical results about the method. Finally, we demonstrate the use of asymmetric attributions on multiple real-world datasets, comparing the results with and without restricted model families using gradient boosting and deep learning models.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们研究非对称的雪平值（ASV），这是SHAP添加式本地解释方法的一种变体。ASV提出了 incorporating known causal relations between variables的方法，并且被视为测试模型预测中的不公正折衔测试。在前期文献中没有被研究过，放弃雪平值的对称性可能会导致模型解释中的counter-intuitive consequence。为了更好地理解这种方法，我们首先示出了local contributions与global contributions of variance reduction的对应关系。使用方差，我们展示了多种情况下，ASV可能会生成错误的root-cause分析结果。其次，我们认为Generalized Additive Models（GAM）是一种受限的模型家族，ASV在这种模型家族中具有恰当的性质。我们支持我们的 Argument by proving multiple theoretical results about the method。最后，我们在多个实际 dataset上使用非对称的贡献值，并与和 без Restricted model families using gradient boosting和deep learning模型进行比较。
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-with-Explicit-Context-Representation"><a href="#Deep-Reinforcement-Learning-with-Explicit-Context-Representation" class="headerlink" title="Deep Reinforcement Learning with Explicit Context Representation"></a>Deep Reinforcement Learning with Explicit Context Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09924">http://arxiv.org/abs/2310.09924</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francisco Munguia-Galeano, Ah-Hwee Tan, Ze Ji</li>
<li>for:  solves complex computational problems with contextual information</li>
<li>methods:  uses Iota explicit context representation (IECR) framework with contextual key frames (CKFs) and two loss functions</li>
<li>results:  significantly outperforms state-of-the-art equivalents in five discrete environments with contextual information<details>
<summary>Abstract</summary>
Reinforcement learning (RL) has shown an outstanding capability for solving complex computational problems. However, most RL algorithms lack an explicit method that would allow learning from contextual information. Humans use context to identify patterns and relations among elements in the environment, along with how to avoid making wrong actions. On the other hand, what may seem like an obviously wrong decision from a human perspective could take hundreds of steps for an RL agent to learn to avoid. This paper proposes a framework for discrete environments called Iota explicit context representation (IECR). The framework involves representing each state using contextual key frames (CKFs), which can then be used to extract a function that represents the affordances of the state; in addition, two loss functions are introduced with respect to the affordances of the state. The novelty of the IECR framework lies in its capacity to extract contextual information from the environment and learn from the CKFs' representation. We validate the framework by developing four new algorithms that learn using context: Iota deep Q-network (IDQN), Iota double deep Q-network (IDDQN), Iota dueling deep Q-network (IDuDQN), and Iota dueling double deep Q-network (IDDDQN). Furthermore, we evaluate the framework and the new algorithms in five discrete environments. We show that all the algorithms, which use contextual information, converge in around 40,000 training steps of the neural networks, significantly outperforming their state-of-the-art equivalents.
</details>
<details>
<summary>摘要</summary>
强化学习（RL）已经表现出解决复杂计算问题的惊人能力。然而，大多数RL算法缺乏显式的方法来学习上下文信息。人类通过上下文来识别环境中元素之间的征交和相互关系，以及如何避免 incorrect 行为。相反，RL Agent可能需要多达百步才能学习避免错误的决策。这篇论文提出了一个名为IECR（Iota Explicit Context Representation）的框架，该框架可以在精确的环境中提取上下文信息，并学习CKFs（上下文关键帧）的表示。此外，本文还提出了两个相对于上下文的产品函数损失函数。IECR框架的创新之处在于可以从环境中提取上下文信息，并学习CKFs的表示。我们验证了IECR框架，并开发了四种使用上下文学习的算法：Iota Deep Q-Network（IDQN）、Iota Double Deep Q-Network（IDDQN）、Iota Duelling Deep Q-Network（IDuDQN）和Iota Duelling Double Deep Q-Network（IDDDQN）。此外，我们还在五个精确环境中评估了IECR框架和这些算法。我们发现，所有使用上下文信息的算法在40,000步训练步骤后，可以快速并高效地学习，与当前最佳算法相比显著性能更高。
</details></li>
</ul>
<hr>
<h2 id="BONES-Near-Optimal-Neural-Enhanced-Video-Streaming"><a href="#BONES-Near-Optimal-Neural-Enhanced-Video-Streaming" class="headerlink" title="BONES: Near-Optimal Neural-Enhanced Video Streaming"></a>BONES: Near-Optimal Neural-Enhanced Video Streaming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09920">http://arxiv.org/abs/2310.09920</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingdong Wang, Simran Singh, Jacob Chakareski, Mohammad Hajiesmaili, Ramesh K. Sitaraman</li>
<li>for: 提高用户视频流程体验质量（Quality of Experience，QoE）</li>
<li>methods: 使用神经网络优化技术（Neural Enhancement）和在线启发式优化算法（Online Lyapunov Optimization）提高视频质量</li>
<li>results: 比对当前状态艺技术，BONES算法可以提高用户视频流程体验质量4%到13%，显示其在提高视频流程体验质量方面具有潜在的应用前景。<details>
<summary>Abstract</summary>
Accessing high-quality video content can be challenging due to insufficient and unstable network bandwidth. Recent advances in neural enhancement have shown promising results in improving the quality of degraded videos through deep learning. Neural-Enhanced Streaming (NES) incorporates this new approach into video streaming, allowing users to download low-quality video segments and then enhance them to obtain high-quality content without violating the playback of the video stream. We introduce BONES, an NES control algorithm that jointly manages the network and computational resources to maximize the quality of experience (QoE) of the user. BONES formulates NES as a Lyapunov optimization problem and solves it in an online manner with near-optimal performance, making it the first NES algorithm to provide a theoretical performance guarantee. Our comprehensive experimental results indicate that BONES increases QoE by 4% to 13% over state-of-the-art algorithms, demonstrating its potential to enhance the video streaming experience for users. Our code and data will be released to the public.
</details>
<details>
<summary>摘要</summary>
Accessing high-quality video content can be challenging due to insufficient and unstable network bandwidth. Recent advances in neural enhancement have shown promising results in improving the quality of degraded videos through deep learning. Neural-Enhanced Streaming (NES) incorporates this new approach into video streaming, allowing users to download low-quality video segments and then enhance them to obtain high-quality content without violating the playback of the video stream. We introduce BONES, an NES control algorithm that jointly manages the network and computational resources to maximize the quality of experience (QoE) of the user. BONES formulates NES as a Lyapunov optimization problem and solves it in an online manner with near-optimal performance, making it the first NES algorithm to provide a theoretical performance guarantee. Our comprehensive experimental results indicate that BONES increases QoE by 4% to 13% over state-of-the-art algorithms, demonstrating its potential to enhance the video streaming experience for users. Our code and data will be released to the public.Here's the text in Traditional Chinese:Accessing high-quality video content can be challenging due to insufficient and unstable network bandwidth. Recent advances in neural enhancement have shown promising results in improving the quality of degraded videos through deep learning. Neural-Enhanced Streaming (NES) incorporates this new approach into video streaming, allowing users to download low-quality video segments and then enhance them to obtain high-quality content without violating the playback of the video stream. We introduce BONES, an NES control algorithm that jointly manages the network and computational resources to maximize the quality of experience (QoE) of the user. BONES formulates NES as a Lyapunov optimization problem and solves it in an online manner with near-optimal performance, making it the first NES algorithm to provide a theoretical performance guarantee. Our comprehensive experimental results indicate that BONES increases QoE by 4% to 13% over state-of-the-art algorithms, demonstrating its potential to enhance the video streaming experience for users. Our code and data will be released to the public.
</details></li>
</ul>
<hr>
<h2 id="Evaluation-of-feature-selection-performance-for-identification-of-best-effective-technical-indicators-on-stock-market-price-prediction"><a href="#Evaluation-of-feature-selection-performance-for-identification-of-best-effective-technical-indicators-on-stock-market-price-prediction" class="headerlink" title="Evaluation of feature selection performance for identification of best effective technical indicators on stock market price prediction"></a>Evaluation of feature selection performance for identification of best effective technical indicators on stock market price prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09903">http://arxiv.org/abs/2310.09903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatemeh Moodi, Amir Jahangard-Rafsanjani</li>
<li>for: 本研究的目的是通过特征选择来选择最佳的股票市场指标，以预测股票市场价格的误差最小。</li>
<li>methods: 本研究使用了 wrapper 特征选择方法，包括 SFS 和 SBS，并使用了 10 种估计器和 123 个技术指标来预测股票市场价格。</li>
<li>results: 研究发现，每种 wrapper 特征选择方法都有不同的结果，与不同的机器学习方法相关。ridge 和 LR 估计器，单独使用和与 wrapper 特征选择方法结合使用，在所有评价标准下得到了最佳股票市场预测结果。<details>
<summary>Abstract</summary>
Due to the influence of many factors, including technical indicators on stock market prediction, feature selection is important to choose the best indicators. One of the feature selection methods that consider the performance of models during feature selection is the wrapper feature selection method. The aim of this research is to identify a combination of the best stock market indicators through feature selection to predict the stock market price with the least error. In order to evaluate the impact of wrapper feature selection techniques on stock market prediction, in this paper SFS and SBS with 10 estimators and 123 technical indicators have been examined on the last 13 years of Apple Company. Also, by the proposed method, the data created by the 3-day time window were converted to the appropriate input for regression methods. Based on the results observed: (1) Each wrapper feature selection method has different results with different machine learning methods, and each method is more correlated with a specific set of technical indicators of the stock market. (2) Ridge and LR estimates alone, and with two methods of the wrapper feature selection, namely SFS and SBS; They had the best results with all assessment criteria for market forecast. (3)The Ridge and LR method with all the R2, MSE, RMSE, MAE and MAPE have the best stock market prediction results. Also, the MLP Regression Method, along with the Sequential Forwards Selection and the MSE, had the best performance. SVR regression, along with the SFS and the MSE, has improved greatly compared to the SVR regression with all indicators. (4) It was also observed that different features are selected by different ML methods with different evaluation parameters. (5) Most ML methods have used the Squeeze_pro, Percentage Price Oscillator, Thermo, Decay, Archer On-Balance Volume, Bollinger Bands, Squeeze and Ichimoku indicator.
</details>
<details>
<summary>摘要</summary>
因为多种因素的影响，包括技术指标在股票市场预测中，特征选择是重要的。本研究的目标是通过特征选择选择最佳的股票市场指标，以预测股票市场价格的误差最小。为了评估包装特征选择技术对股票市场预测的影响，本文在Apple公司上评估了13年的数据。具体来说，通过提posed方法，将3天时窗内的数据转换为适合回归方法的输入。根据结果所见：1. 每种包装特征选择方法都有不同的结果，与不同的机器学习方法相关。每种方法更加相关于股票市场技术指标的特定集。2. Ridge和LR估计独立，以及使用SFS和SBS两种包装特征选择方法时，在所有评价标准中表现最佳。3. Ridge和LR方法与所有评价标准（R2、MSE、RMSE、MAE和MAPE）表现最佳。此外，MLP回归方法，结合Sequential Forwards Selection和MSE，也表现出色。4.  Observation showed that different ML methods select different features with different evaluation parameters.5. Most ML methods use Squeeze_pro、Percentage Price Oscillator、Thermo、Decay、Archer On-Balance Volume、Bollinger Bands、Squeeze和Ichimoku指标。
</details></li>
</ul>
<hr>
<h2 id="Towards-Deep-Learning-Models-Resistant-to-Transfer-based-Adversarial-Attacks-via-Data-centric-Robust-Learning"><a href="#Towards-Deep-Learning-Models-Resistant-to-Transfer-based-Adversarial-Attacks-via-Data-centric-Robust-Learning" class="headerlink" title="Towards Deep Learning Models Resistant to Transfer-based Adversarial Attacks via Data-centric Robust Learning"></a>Towards Deep Learning Models Resistant to Transfer-based Adversarial Attacks via Data-centric Robust Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09891">http://arxiv.org/abs/2310.09891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yulong Yang, Chenhao Lin, Xiang Ji, Qiwei Tian, Qian Li, Hongshan Yang, Zhibo Wang, Chao Shen</li>
<li>for: 防御对于转移基于攻击的威胁，提供一种新的防御方法，即数据中心Robust Learning（DRL）。</li>
<li>methods: DRL使用一招一时的反恶例增强，而不是在整个训练过程中优化对抗例。</li>
<li>results: DRL在黑盒Robustness方面比PGD-AT、TRADES、EAT和FAT等常用AT技术表现出色，并且可以与多种数据增强和损失规则结合使用，以提高防御性。<details>
<summary>Abstract</summary>
Transfer-based adversarial attacks raise a severe threat to real-world deep learning systems since they do not require access to target models. Adversarial training (AT), which is recognized as the strongest defense against white-box attacks, has also guaranteed high robustness to (black-box) transfer-based attacks. However, AT suffers from heavy computational overhead since it optimizes the adversarial examples during the whole training process. In this paper, we demonstrate that such heavy optimization is not necessary for AT against transfer-based attacks. Instead, a one-shot adversarial augmentation prior to training is sufficient, and we name this new defense paradigm Data-centric Robust Learning (DRL). Our experimental results show that DRL outperforms widely-used AT techniques (e.g., PGD-AT, TRADES, EAT, and FAT) in terms of black-box robustness and even surpasses the top-1 defense on RobustBench when combined with diverse data augmentations and loss regularizations. We also identify other benefits of DRL, for instance, the model generalization capability and robust fairness.
</details>
<details>
<summary>摘要</summary>
transfer-based adversarial attacks pose a severe threat to real-world deep learning systems, as they do not require access to target models. adversarial training (AT), which is recognized as the strongest defense against white-box attacks, has also guaranteed high robustness to (black-box) transfer-based attacks. however, AT suffers from heavy computational overhead, as it optimizes adversarial examples during the entire training process. in this paper, we demonstrate that such heavy optimization is not necessary for AT against transfer-based attacks. instead, a one-shot adversarial augmentation prior to training is sufficient, and we name this new defense paradigm data-centric robust learning (drl). our experimental results show that drl outperforms widely-used at techniques (e.g., pgd-at, trades, eat, and fat) in terms of black-box robustness and even surpasses the top-1 defense on robustbench when combined with diverse data augmentations and loss regularizations. we also identify other benefits of drl, such as model generalization capability and robust fairness.
</details></li>
</ul>
<hr>
<h2 id="Score-Based-Methods-for-Discrete-Optimization-in-Deep-Learning"><a href="#Score-Based-Methods-for-Discrete-Optimization-in-Deep-Learning" class="headerlink" title="Score-Based Methods for Discrete Optimization in Deep Learning"></a>Score-Based Methods for Discrete Optimization in Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09890">http://arxiv.org/abs/2310.09890</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Eric Lei, Arman Adibi, Hamed Hassani</li>
<li>for: 这 paper 是用于解决深度学习任务中的离散优化问题的。</li>
<li>methods: 这 paper 使用了一种分数函数方法来解决这些问题，该方法使用了一个分数函数作为目标函数的代理，并使用了隐藏变量的嵌入和自动导函数框架来并行计算反向传播。</li>
<li>results: 该 paper 的实验表明，在对抗式集成分类任务中，该方法可以实现一个更好的平衡点，即快速并且解决高维数据的问题。<details>
<summary>Abstract</summary>
Discrete optimization problems often arise in deep learning tasks, despite the fact that neural networks typically operate on continuous data. One class of these problems involve objective functions which depend on neural networks, but optimization variables which are discrete. Although the discrete optimization literature provides efficient algorithms, they are still impractical in these settings due to the high cost of an objective function evaluation, which involves a neural network forward-pass. In particular, they require $O(n)$ complexity per iteration, but real data such as point clouds have values of $n$ in thousands or more. In this paper, we investigate a score-based approximation framework to solve such problems. This framework uses a score function as a proxy for the marginal gain of the objective, leveraging embeddings of the discrete variables and speed of auto-differentiation frameworks to compute backward-passes in parallel. We experimentally demonstrate, in adversarial set classification tasks, that our method achieves a superior trade-off in terms of speed and solution quality compared to heuristic methods.
</details>
<details>
<summary>摘要</summary>
几乎所有深度学习任务中都会遇到离散优化问题，即使神经网络通常处理连续数据。这类问题中的目标函数取决于神经网络，但优化变量是离散的。虽然离散优化文献中提供了高效的算法，但它们在这些设置中仍然不实用，因为目标函数评估的成本高，需要对神经网络进行前进传播，这需要 $O(n)$ 复杂度每次迭代。例如，实际数据如点云可能有 thousands 或更多的值。在这篇论文中，我们研究了一种分数函数近似框架，用于解决这些问题。这个框架使用分数函数作为目标函数的代理，利用离散变量的嵌入和自动导数框架来并行计算反向传播。我们在随机设置中的对抗性分类任务中实验ally示出，我们的方法可以在速度和解决质量之间取得优化的负号比例。
</details></li>
</ul>
<hr>
<h2 id="Empower-Text-Attributed-Graphs-Learning-with-Large-Language-Models-LLMs"><a href="#Empower-Text-Attributed-Graphs-Learning-with-Large-Language-Models-LLMs" class="headerlink" title="Empower Text-Attributed Graphs Learning with Large Language Models (LLMs)"></a>Empower Text-Attributed Graphs Learning with Large Language Models (LLMs)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09872">http://arxiv.org/abs/2310.09872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianxiang Yu, Yuxiang Ren, Chenghua Gong, Jiaqi Tan, Xiang Li, Xuecang Zhang</li>
<li>for: 提高文本权重图像的性能在几个shot情况下（提高 node classification 任务的性能）</li>
<li>methods: 使用 Large Language Models (LLMs) 提取标签中的Semantic信息，并生成相应的类别 exemplars，然后使用边预测器捕捉原始数据中的结构信息，并将新生成的样本纳入原始图像中。</li>
<li>results: 对ogbn-arxiv dataset进行了广泛的实验，并显示了在1-shot情况下对基eline模型的76%提升。<details>
<summary>Abstract</summary>
Text-attributed graphs have recently garnered significant attention due to their wide range of applications in web domains. Existing methodologies employ word embedding models for acquiring text representations as node features, which are subsequently fed into Graph Neural Networks (GNNs) for training. Recently, the advent of Large Language Models (LLMs) has introduced their powerful capabilities in information retrieval and text generation, which can greatly enhance the text attributes of graph data. Furthermore, the acquisition and labeling of extensive datasets are both costly and time-consuming endeavors. Consequently, few-shot learning has emerged as a crucial problem in the context of graph learning tasks. In order to tackle this challenge, we propose a lightweight paradigm called ENG, which adopts a plug-and-play approach to empower text-attributed graphs through node generation using LLMs. Specifically, we utilize LLMs to extract semantic information from the labels and generate samples that belong to these categories as exemplars. Subsequently, we employ an edge predictor to capture the structural information inherent in the raw dataset and integrate the newly generated samples into the original graph. This approach harnesses LLMs for enhancing class-level information and seamlessly introduces labeled nodes and edges without modifying the raw dataset, thereby facilitating the node classification task in few-shot scenarios. Extensive experiments demonstrate the outstanding performance of our proposed paradigm, particularly in low-shot scenarios. For instance, in the 1-shot setting of the ogbn-arxiv dataset, ENG achieves a 76% improvement over the baseline model.
</details>
<details>
<summary>摘要</summary>
文本拥有Graph neural networks (GNNs) 在网络领域中得到了广泛的应用，现有的方法使用word embedding模型来获取文本表示，然后将其传递给GNNs进行训练。在大型自然语言模型（LLMs）的出现之后，这些 модели的强大能力在信息检索和文本生成中得到了应用，可以大幅提高文本特征。然而，收集和标注大量数据都是成本和时间consuming的任务。因此，几拍学习成为了图学习任务中的一个关键问题。为解决这个问题，我们提出了一种轻量级的方法called ENG，它采用了一种插件式的方法来授权文本拥有Graph中的节点生成。具体来说，我们使用LLMs来提取标签中的semantic信息，并生成符合这些类别的样本作为示例。然后，我们使用边预测器来捕捉原始数据中的结构信息，并将新生成的样本与原始图 Integrate into the graph。这种方法利用了LLMs来增强类别信息，无需修改原始数据，因此可以轻松地在几拍学习场景下进行节点分类。我们的实验表明，ENG方法在低shot场景下表现出色，例如在ogbn-arxivdataset中的1拍 Setting中，ENG方法与基eline模型相比提高了76%。
</details></li>
</ul>
<hr>
<h2 id="Alpha-Elimination-Using-Deep-Reinforcement-Learning-to-Reduce-Fill-In-during-Sparse-Matrix-Decomposition"><a href="#Alpha-Elimination-Using-Deep-Reinforcement-Learning-to-Reduce-Fill-In-during-Sparse-Matrix-Decomposition" class="headerlink" title="Alpha Elimination: Using Deep Reinforcement Learning to Reduce Fill-In during Sparse Matrix Decomposition"></a>Alpha Elimination: Using Deep Reinforcement Learning to Reduce Fill-In during Sparse Matrix Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09852">http://arxiv.org/abs/2310.09852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arpan Dasgupta, Pawan Kumar</li>
<li>for: 这个论文目的是对叠合矩阵进行分解，以提高分解过程中的效率和内存需求。</li>
<li>methods: 这个论文使用了一种基于强化学习的叠合矩阵重新排序方法，即alphaElimination。这个方法以单玩家游戏的形式表现出叠合矩阵重新排序问题，并使用Monte-Carlo tree search和神经网络来找到最佳移动。</li>
<li>results: 这个论文的结果显示，alphaElimination 可以与现有的热点排序法相比，实现更好的填充避免，并且对叠合矩阵的分解过程和解释过程都有很好的影响。<details>
<summary>Abstract</summary>
A large number of computational and scientific methods commonly require decomposing a sparse matrix into triangular factors as LU decomposition. A common problem faced during this decomposition is that even though the given matrix may be very sparse, the decomposition may lead to a denser triangular factors due to fill-in. A significant fill-in may lead to prohibitively larger computational costs and memory requirement during decomposition as well as during the solve phase. To this end, several heuristic sparse matrix reordering methods have been proposed to reduce fill-in before the decomposition. However, finding an optimal reordering algorithm that leads to minimal fill-in during such decomposition is known to be a NP-hard problem. A reinforcement learning based approach is proposed for this problem. The sparse matrix reordering problem is formulated as a single player game. More specifically, Monte-Carlo tree search in combination with neural network is used as a decision making algorithm to search for the best move in our game. The proposed method, alphaElimination is found to produce significantly lesser non-zeros in the LU decomposition as compared to existing state-of-the-art heuristic algorithms with little to no increase in overall running time of the algorithm. The code for the project will be publicly available here\footnote{\url{https://github.com/misterpawan/alphaEliminationPaper}.
</details>
<details>
<summary>摘要</summary>
许多计算和科学方法通常需要将稀疏矩阵分解为LU分解。在这个分解过程中，常见的问题是，即使给定矩阵很稀疏，但是分解可能会导致三角因子更加稠密，即fill-in问题。这种填充可能会导致计算成本和内存需求急剧增加。为解决这个问题，许多启发式稀疏矩阵重新排序方法已经被提出。然而，找到最优的重新排序算法，以使得在这个分解过程中避免填充，是一个NP困难问题。本文提出了一种基于强化学习的方法。将稀疏矩阵重新排序问题定义为单player游戏。具体来说，使用Monte-Carlo搜索和神经网络的决策算法来搜索最佳的移动。该方法被命名为alphaElimination，并发现它可以在LU分解中生成许多更少的非零元素，与现有的状态艺术算法相比，几乎没有增加总运行时间。代码将在以下链接公开：\footnote{\url{https://github.com/misterpawan/alphaEliminationPaper}。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-ML-model-accuracy-for-Digital-VLSI-circuits-using-diffusion-models-A-study-on-synthetic-data-generation"><a href="#Enhancing-ML-model-accuracy-for-Digital-VLSI-circuits-using-diffusion-models-A-study-on-synthetic-data-generation" class="headerlink" title="Enhancing ML model accuracy for Digital VLSI circuits using diffusion models: A study on synthetic data generation"></a>Enhancing ML model accuracy for Digital VLSI circuits using diffusion models: A study on synthetic data generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10691">http://arxiv.org/abs/2310.10691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prasha Srivastava, Pawan Kumar, Zia Abbas</li>
<li>for: 这个研究旨在使用扩散模型生成人工数据，以提高后续机器学习模型在电子芯片设计、评估和测试等任务中的准确性。</li>
<li>methods: 我们使用HSPICE设计环境和22nm CMOS技术节点进行了仿真，以获得可靠的真实训练数据。</li>
<li>results: 我们的结果表明，扩散模型生成的人工数据和实际数据之间存在很close的相似性。我们验证了生成的数据质量，并证明了数据扩展确实有效地提高了VLSI设计中的预测性。<details>
<summary>Abstract</summary>
Generative AI has seen remarkable growth over the past few years, with diffusion models being state-of-the-art for image generation. This study investigates the use of diffusion models in generating artificial data generation for electronic circuits for enhancing the accuracy of subsequent machine learning models in tasks such as performance assessment, design, and testing when training data is usually known to be very limited. We utilize simulations in the HSPICE design environment with 22nm CMOS technology nodes to obtain representative real training data for our proposed diffusion model. Our results demonstrate the close resemblance of synthetic data using diffusion model to real data. We validate the quality of generated data, and demonstrate that data augmentation certainly effective in predictive analysis of VLSI design for digital circuits.
</details>
<details>
<summary>摘要</summary>
这篇研究探讨使用扩散模型来生成人工训练数据，以提高后续机器学习模型在电子遗传学 задача中的准确性。我们使用HSPICE设计环境，使用22nm CMOS技术架构，从实验中获得真实训练数据，以验证扩散模型的效果。我们的结果显示，扩散模型生成的 sintetic 数据和实际数据之间存在着类似的相似性。我们还证明了生成数据的质量，并证明了数据增强对适用于对数字遗传学设计的预测分析有效。</SYS>Note:* "扩散模型" (diffusion model) refers to a type of generative model that generates data by iteratively refining a random noise vector until it matches the target data distribution.* "HSPICE" is a circuit simulator that is widely used in the field of electronic design automation.* "CMOS" (Complementary Metal-Oxide-Semiconductor) is a technology node that is commonly used in the fabrication of integrated circuits.* "适用" (suitable) means appropriate or applicable.* "预测分析" (predictive analysis) refers to the use of statistical or machine learning techniques to forecast the behavior of a system or process.
</details></li>
</ul>
<hr>
<h2 id="XRMDN-A-Recurrent-Mixture-Density-Networks-based-Architecture-for-Short-Term-Probabilistic-Demand-Forecasting-in-Mobility-on-Demand-Systems-with-High-Volatility"><a href="#XRMDN-A-Recurrent-Mixture-Density-Networks-based-Architecture-for-Short-Term-Probabilistic-Demand-Forecasting-in-Mobility-on-Demand-Systems-with-High-Volatility" class="headerlink" title="XRMDN: A Recurrent Mixture Density Networks-based Architecture for Short-Term Probabilistic Demand Forecasting in Mobility-on-Demand Systems with High Volatility"></a>XRMDN: A Recurrent Mixture Density Networks-based Architecture for Short-Term Probabilistic Demand Forecasting in Mobility-on-Demand Systems with High Volatility</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09847">http://arxiv.org/abs/2310.09847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoming Li, Hubert Normandin-Taillon, Chun Wang, Xiao Huang</li>
<li>for: 这个研究是为了提高现实的 mobilitity-on-demand（MoD）系统中的需求预测精度，因为需求是具有高度动态波动性，这些波动性难以预测使用传统时间序列预测方法。</li>
<li>methods: 本研究提出了一个扩展的回传混合密度网络（XRMDN），它将传统的重量和均值神经网络扩展到回传神经网络，以capture historic data-series data的趋势，从而获得更好的预测结果。</li>
<li>results: 根据实验结果，XRMDN比三种参考模型（包括统计、机器学习和深度学习模型）在三个评估指标上表现更好，特别是在具有强波动性的需求预测中。此外，XRMDN还可以帮助优化MoD系统中的其他应用问题，例如在不确定性下进行优化。<details>
<summary>Abstract</summary>
In real Mobility-on-Demand (MoD) systems, demand is subject to high and dynamic volatility, which is difficult to predict by conventional time-series forecasting approaches. Most existing forecasting approaches yield the point value as the prediction result, which ignores the uncertainty that exists in the forecasting result. This will lead to the forecasting result severely deviating from the true demand value due to the high volatility existing in demand. To fill the gap, we propose an extended recurrent mixture density network (XRMDN), which extends the weight and mean neural networks to recurrent neural networks. The recurrent neurons for mean and variance can capture the trend of the historical data-series data, which enables a better forecasting result in dynamic and high volatility. We conduct comprehensive experiments on one taxi trip record and one bike-sharing real MoD data set to validate the performance of XRMDN. Specifically, we compare our model to three types of benchmark models, including statistical, machine learning, and deep learning models on three evaluation metrics. The validation results show that XRMDN outperforms the three groups of benchmark models in terms of the evaluation metrics. Most importantly, XRMDN substantially improves the forecasting accuracy with the demands in strong volatility. Last but not least, this probabilistic demand forecasting model contributes not only to the demand prediction in MoD systems but also to other optimization application problems, especially optimization under uncertainty, in MoD applications.
</details>
<details>
<summary>摘要</summary>
真实的流动性-on-需求（MoD）系统中的需求受到高度和动态的不稳定性影响，这些影响难以预测通过传统时间序列预测方法。大多数现有预测方法只预测点值，忽略预测结果中存在的不确定性。这将导致预测结果与真实需求值严重不符，因为需求的高度不稳定。为了填补这个空白，我们提议一种扩展的循环混合密度网络（XRMDN）模型，扩展了权重和均值神经网络到循环神经网络。循环神经网络可以捕捉历史数据时系列数据的趋势，从而实现更好的预测结果在动态和高度不稳定的情况下。我们对一个出租车旅程记录和一个自行车分享真实MoD数据集进行了广泛的实验，以验证XRMDN的性能。具体来说，我们与三种参考模型进行比较，包括统计、机器学习和深度学习模型，并在三个评价指标上进行比较。验证结果显示，XRMDN在评价指标上都高于参考模型。此外，XRMDN在需求强度不稳定的情况下显著提高了预测精度。最后，这种probabilistic需求预测模型不仅有助于MoD系统中的需求预测，还有助于其他优化应用问题，尤其是在MoD应用中的不确定性优化问题。
</details></li>
</ul>
<hr>
<h2 id="Secure-and-Robust-Communications-for-Cislunar-Space-Networks"><a href="#Secure-and-Robust-Communications-for-Cislunar-Space-Networks" class="headerlink" title="Secure and Robust Communications for Cislunar Space Networks"></a>Secure and Robust Communications for Cislunar Space Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09835">http://arxiv.org/abs/2310.09835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Selen Gecgel Cetin, Gunes Karabulut Kurt, Angeles Vazquez-Castro</li>
<li>for: 这个研究旨在提供一个基于机器学习的cislunar空间领域意识能力，以确保无间断的月球和地球之间通信。</li>
<li>methods: 本研究提出了一个细部通道模型，以及两种可能会在cislunar空间发生的干扰模型。</li>
<li>results: 研究结果显示，使用机器学习算法的cislunar空间领域意识能力可以实现96%的准确性，并且显示出了这种方法的扎实性和可靠性。<details>
<summary>Abstract</summary>
There is no doubt that the Moon has become the center of interest for commercial and international actors. Over the past decade, the number of planned long-term missions has increased dramatically. This makes the establishment of cislunar space networks (CSNs) crucial to orchestrate uninterrupted communications between the Moon and Earth. However, there are numerous challenges, unknowns, and uncertainties associated with cislunar communications that may pose various risks to lunar missions. In this study, we aim to address these challenges for cislunar communications by proposing a machine learning-based cislunar space domain awareness (SDA) capability that enables robust and secure communications. To this end, we first propose a detailed channel model for selected cislunar scenarios. Secondly, we propose two types of interference that could model anomalies that occur in cislunar space and are so far known only to a limited extent. Finally, we discuss our cislunar SDA to work in conjunction with the spacecraft communication system. Our proposed cislunar SDA, involving heuristic learning capabilities with machine learning algorithms, detects interference models with over 96% accuracy. The results demonstrate the promising performance of our cislunar SDA approach for secure and robust cislunar communication.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>月球已成为商业和国际行动者的中心，过去一代，计划的长期任务数量有所增加。这使得在月球和地球之间建立cislunar空间网络（CSN）变得非常重要，以确保无间断的通信。然而，cislunar通信存在许多挑战、未知和不确定性，这些风险可能对月球任务产生影响。在这种情况下，我们提出了一种基于机器学习的cislunar空间领域意识（SDA）能力，以确保安全和可靠的通信。为此，我们首先提出了选择的cislunar场景下的通道模型。其次，我们提出了两种可能出现在cislunar空间中的干扰，这些干扰至今只有有限的知识。最后，我们讨论了我们的cislunar SDA如何与空间器通信系统结合使用。我们的提议的cislunar SDA，结合机器学习算法的启发学能力，可以检测干扰模型的准确率高达96%。结果表明我们的cislunar SDA方法在确保安全和可靠的cislunar通信方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="MAGIC-Detecting-Advanced-Persistent-Threats-via-Masked-Graph-Representation-Learning"><a href="#MAGIC-Detecting-Advanced-Persistent-Threats-via-Masked-Graph-Representation-Learning" class="headerlink" title="MAGIC: Detecting Advanced Persistent Threats via Masked Graph Representation Learning"></a>MAGIC: Detecting Advanced Persistent Threats via Masked Graph Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09831">http://arxiv.org/abs/2310.09831</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fdudsde/magic">https://github.com/fdudsde/magic</a></li>
<li>paper_authors: Zian Jia, Yun Xiong, Yuhong Nan, Yao Zhang, Jinjing Zhao, Mi Wen</li>
<li>for: 这篇论文旨在探讨防止高级攻击者（APT）的攻击方法，并提出一个名为MAGIC的新型自我超级攻击探测方法，可以在不同的监控环境下进行多层级的探测。</li>
<li>methods: 本文使用隐藏标签数据库学来学习防止APT攻击的模型，并将其应用于不同监控环境下的探测。</li>
<li>results: 本文在三个广泛使用的数据集上进行评估，结果显示MAGIC可以在所有测试场景中获得出色的探测结果，并与现有的APT探测方法相比，具有很大的性能优势。<details>
<summary>Abstract</summary>
Advance Persistent Threats (APTs), adopted by most delicate attackers, are becoming increasing common and pose great threat to various enterprises and institutions. Data provenance analysis on provenance graphs has emerged as a common approach in APT detection. However, previous works have exhibited several shortcomings: (1) requiring attack-containing data and a priori knowledge of APTs, (2) failing in extracting the rich contextual information buried within provenance graphs and (3) becoming impracticable due to their prohibitive computation overhead and memory consumption.   In this paper, we introduce MAGIC, a novel and flexible self-supervised APT detection approach capable of performing multi-granularity detection under different level of supervision. MAGIC leverages masked graph representation learning to model benign system entities and behaviors, performing efficient deep feature extraction and structure abstraction on provenance graphs. By ferreting out anomalous system behaviors via outlier detection methods, MAGIC is able to perform both system entity level and batched log level APT detection. MAGIC is specially designed to handle concept drift with a model adaption mechanism and successfully applies to universal conditions and detection scenarios. We evaluate MAGIC on three widely-used datasets, including both real-world and simulated attacks. Evaluation results indicate that MAGIC achieves promising detection results in all scenarios and shows enormous advantage over state-of-the-art APT detection approaches in performance overhead.
</details>
<details>
<summary>摘要</summary>
高级攻击者所采用的持续攻击（APT）正在不断增长，对各种企业和机构构成极大的威胁。数据源推论分析在APT检测中得到了广泛应用。然而，先前的工作具有以下缺陷：（1）需要攻击数据和先验知识，（2）无法提取质量推论图中埋藏的详细信息，（3）因计算负担和内存占用过高而成为不可持续。在这篇论文中，我们介绍MAGIC，一种新的自动化和灵活的APT检测方法。MAGIC可以在不同的级别和水平进行多重粒度检测，并且可以通过匿名系统实体和行为模型来快速抽象出深度特征。通过检测异常系统行为，MAGIC可以同时进行系统实体层和批处理日志层APT检测。MAGIC特别地采用了掩码图表学习来模型无辜系统实体和行为，并通过异常检测方法来检测异常系统行为。MAGIC可以适应概念漂移，并在通用条件和检测场景下显示出优异表现。我们对三个广泛使用的数据集进行了评估，包括真实攻击和模拟攻击。评估结果表明，MAGIC在所有场景中具有扎实的检测效果，与当前APT检测方法相比，具有巨大的性能优势。
</details></li>
</ul>
<hr>
<h2 id="VFLAIR-A-Research-Library-and-Benchmark-for-Vertical-Federated-Learning"><a href="#VFLAIR-A-Research-Library-and-Benchmark-for-Vertical-Federated-Learning" class="headerlink" title="VFLAIR: A Research Library and Benchmark for Vertical Federated Learning"></a>VFLAIR: A Research Library and Benchmark for Vertical Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09827">http://arxiv.org/abs/2310.09827</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/flair-thu/vflair">https://github.com/flair-thu/vflair</a></li>
<li>paper_authors: Tianyuan Zou, Zixuan Gu, Yu He, Hideaki Takahashi, Yang Liu, Guangnan Ye, Ya-Qin Zhang</li>
<li>for: 这篇论文旨在探讨Vertival Federated Learning（VFL）的应用和研究前景，以及如何防止不同类型的数据推理和后门攻击。</li>
<li>methods: 本文使用了多种模型、数据集和协议，并提供了标准化的评估模块以评估攻击和防御策略的性能。</li>
<li>results: 本文对11种攻击和8种防御策略进行了实验性评估，并从不同的通信和模型分割设置中绘制了具体的发现和建议，以帮助实际应用中的VFL部署场景选择防御策略。<details>
<summary>Abstract</summary>
Vertical Federated Learning (VFL) has emerged as a collaborative training paradigm that allows participants with different features of the same group of users to accomplish cooperative training without exposing their raw data or model parameters. VFL has gained significant attention for its research potential and real-world applications in recent years, but still faces substantial challenges, such as in defending various kinds of data inference and backdoor attacks. Moreover, most of existing VFL projects are industry-facing and not easily used for keeping track of the current research progress. To address this need, we present an extensible and lightweight VFL framework VFLAIR (available at https://github.com/FLAIR-THU/VFLAIR), which supports VFL training with a variety of models, datasets and protocols, along with standardized modules for comprehensive evaluations of attacks and defense strategies. We also benchmark 11 attacks and 8 defenses performance under different communication and model partition settings and draw concrete insights and recommendations on the choice of defense strategies for different practical VFL deployment scenario.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Communication-Compression-for-Byzantine-Robust-Learning-New-Efficient-Algorithms-and-Improved-Rates"><a href="#Communication-Compression-for-Byzantine-Robust-Learning-New-Efficient-Algorithms-and-Improved-Rates" class="headerlink" title="Communication Compression for Byzantine Robust Learning: New Efficient Algorithms and Improved Rates"></a>Communication Compression for Byzantine Robust Learning: New Efficient Algorithms and Improved Rates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09804">http://arxiv.org/abs/2310.09804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Rammal, Kaja Gruntkowska, Nikita Fedin, Eduard Gorbunov, Peter Richtárik</li>
<li>for: 本研究探讨了对 collaborative&#x2F;federated learning 中的审计缓存问题进行 Byzantine 鲁棒性的算法设计，以及通信压缩的搅动。</li>
<li>methods: 本文提出了两种新的 Byzantine 鲁棒方法：Byz-DASHA-PAGE 和 Byz-EF21，其中 Byz-DASHA-PAGE 在非 convex 和 Polyak-Lojasiewicz 平坦函数中具有更高的收敛速率、更小的邻居大小，并能承受更多的 Byzantine 工作者。Byz-EF21 方法则是首个具有通信压缩和错误反馈的 Byzantine 鲁棒方法，其bidirectional compression version 是 Byz-EF21-BC。</li>
<li>results: 作者在数学实验中测试了提议的方法，并证明了它们在非 convex 和 Polyak-Lojasiewicz 平坦函数中具有更高的收敛速率和更好的承受性。<details>
<summary>Abstract</summary>
Byzantine robustness is an essential feature of algorithms for certain distributed optimization problems, typically encountered in collaborative/federated learning. These problems are usually huge-scale, implying that communication compression is also imperative for their resolution. These factors have spurred recent algorithmic and theoretical developments in the literature of Byzantine-robust learning with compression. In this paper, we contribute to this research area in two main directions. First, we propose a new Byzantine-robust method with compression -- Byz-DASHA-PAGE -- and prove that the new method has better convergence rate (for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller neighborhood size in the heterogeneous case, and tolerates more Byzantine workers under over-parametrization than the previous method with SOTA theoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the first Byzantine-robust method with communication compression and error feedback -- Byz-EF21 -- along with its bidirectional compression version -- Byz-EF21-BC -- and derive the convergence rates for these methods for non-convex and Polyak-Lojasiewicz smooth case. We test the proposed methods and illustrate our theoretical findings in the numerical experiments.
</details>
<details>
<summary>摘要</summary>
布日兹罗布特性是分布式优化问题中的重要特性，通常在协同学习/联邦学习中出现。这些问题通常很大规模，因此通信压缩也是必要的。这些因素在文献中促进了最近的算法和理论发展，包括Byzantine-robust学习与压缩。在这篇论文中，我们对这个研究领域进行了两个主要贡献。首先，我们提出了一种新的Byzantine-robust方法——Byz-DASHA-PAGE，并证明其在非对称和Polyak-Lojasiewicz细致优化问题中的更好的收敛率，小于前一个方法（Byz-VR-MARINA）的最佳理论收敛保证。其次，我们开发了第一种Byzantine-robust方法与通信压缩，并对其在非对称和Polyak-Lojasiewicz细致优化问题中的收敛率进行了分析。我们还开发了一种双向压缩版本——Byz-EF21-BC，并对其进行了数学分析。我们的实验证明了我们的理论发现。
</details></li>
</ul>
<hr>
<h2 id="FLrce-Efficient-Federated-Learning-with-Relationship-based-Client-Selection-and-Early-Stopping-Strategy"><a href="#FLrce-Efficient-Federated-Learning-with-Relationship-based-Client-Selection-and-Early-Stopping-Strategy" class="headerlink" title="FLrce: Efficient Federated Learning with Relationship-based Client Selection and Early-Stopping Strategy"></a>FLrce: Efficient Federated Learning with Relationship-based Client Selection and Early-Stopping Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09789">http://arxiv.org/abs/2310.09789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziru Niu, Hai Dong, A. Kai Qin, Tao Gu</li>
<li>for: 提高 Federated Learning（FL）的通信和计算效率，以提供智能服务保持数据隐私。</li>
<li>methods: 引入Dropout技术，让限制资源的边缘设备共同训练全球模型参数的一部分。</li>
<li>results: FLrce提高了通信和计算效率，在更少的轮数下达到了相同的准确率，并且可以在提前终止FL来降低通信和计算资源的消耗。<details>
<summary>Abstract</summary>
Federated learning (FL) achieves great popularity in broad areas as a powerful interface to offer intelligent services to customers while maintaining data privacy. Nevertheless, FL faces communication and computation bottlenecks due to limited bandwidth and resource constraints of edge devices. To comprehensively address the bottlenecks, the technique of dropout is introduced, where resource-constrained edge devices are allowed to collaboratively train a subset of the global model parameters. However, dropout impedes the learning efficiency of FL under unbalanced local data distributions. As a result, FL requires more rounds to achieve appropriate accuracy, consuming more communication and computation resources. In this paper, we present FLrce, an efficient FL framework with a relationship-based client selection and early-stopping strategy. FLrce accelerates the FL process by selecting clients with more significant effects, enabling the global model to converge to a high accuracy in fewer rounds. FLrce also leverages an early stopping mechanism to terminate FL in advance to save communication and computation resources. Experiment results show that FLrce increases the communication and computation efficiency by 6% to 73.9% and 20% to 79.5%, respectively, while maintaining competitive accuracy.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 在各种领域得到了广泛的推广，作为一种保持数据隐私的强大接口，提供智能服务给客户。然而，FL 面临有限带宽和资源限制的边缘设备的通信和计算瓶颈。为了全面解决这些瓶颈，dropout技术被引入，允许有限资源的边缘设备共同训练全球模型参数的一部分。然而，dropout会降低FL在不均匀本地数据分布时的学习效率。因此，FL需要更多的轮次来达到适当的准确率，消耗更多的通信和计算资源。在这篇论文中，我们提出了FLrce，一个高效的FL框架，具有关系基于的客户选择和早期终止策略。FLrce 加速了FL 过程，选择有更大影响的客户，使全球模型更快地 converges 到高准确率。FLrce 还利用了早期终止机制，提前终止 FL，以保存通信和计算资源。实验结果表明，FLrce 可以提高通信和计算效率，在 6% 到 73.9% 和 20% 到 79.5% 之间，而且保持竞争性的准确率。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Link-Prediction-for-New-Nodes-in-Temporal-Graph-Networks"><a href="#Dynamic-Link-Prediction-for-New-Nodes-in-Temporal-Graph-Networks" class="headerlink" title="Dynamic Link Prediction for New Nodes in Temporal Graph Networks"></a>Dynamic Link Prediction for New Nodes in Temporal Graph Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09787">http://arxiv.org/abs/2310.09787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobo Zhu, Yan Wu, Qinhu Zhang, Zhanheng Chen, Ying He</li>
<li>for: 这篇论文的目的是提出一个基于 meta-learning 原则的模型，用于预测新的节点之间的连接。这种预测问题在实际应用中非常重要，例如在推荐系统中给予新的用户有关的项目推荐，以及在社交平台上给予新用户有关的内容推荐。</li>
<li>methods: 这篇论文使用了一个称为 temporal encoder 的专门模型，并且使用了一个称为 predictor 的模型来预测新节点是否会产生连接。这两个模型在 meta-learning 原则下进行学习，以便在预测新节点之间的连接时能够更好地适应。</li>
<li>results: 在三个公开的数据集上进行了实验，结果显示了这个模型的表现比以前的方法更好。具体来说，这个模型可以更好地预测新节点之间的连接，并且可以在几乎无预警情况下进行预测。<details>
<summary>Abstract</summary>
Modelling temporal networks for dynamic link prediction of new nodes has many real-world applications, such as providing relevant item recommendations to new customers in recommender systems and suggesting appropriate posts to new users on social platforms. Unlike old nodes, new nodes have few historical links, which poses a challenge for the dynamic link prediction task. Most existing dynamic models treat all nodes equally and are not specialized for new nodes, resulting in suboptimal performances. In this paper, we consider dynamic link prediction of new nodes as a few-shot problem and propose a novel model based on the meta-learning principle to effectively mitigate this problem. Specifically, we develop a temporal encoder with a node-level span memory to obtain a new node embedding, and then we use a predictor to determine whether the new node generates a link. To overcome the few-shot challenge, we incorporate the encoder-predictor into the meta-learning paradigm, which can learn two types of implicit information during the formation of the temporal network through span adaptation and node adaptation. The acquired implicit information can serve as model initialisation and facilitate rapid adaptation to new nodes through a fine-tuning process on just a few links. Experiments on three publicly available datasets demonstrate the superior performance of our model compared to existing state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
模拟 temporal networks 为新节点动态链接预测有多个实际应用，如为新用户提供相关的ITE推荐和社交平台上新用户的适当帖子推荐。与老节点不同，新节点具有少量历史链接，这对动态链接预测任务带来挑战。大多数现有的动态模型往往对所有节点进行等效处理，从而导致下OPTIMAL表现。在本文中，我们将动态链接预测新节点视为几枚shot问题，并提出一种基于元学习原则的新模型。具体来说，我们开发了一个包含节点级别span记忆的时间编码器，以获得新节点嵌入，然后使用一个预测器来判断新节点是否生成链接。为了解决几枚shot挑战，我们将编码器-预测器 integrate 到元学习 парадиг中，可以在形成 temporal network 过程中通过 span 适应和节点适应学习两种隐式信息。获得的隐式信息可以作为模型初始化，并且通过一些链接的精度适应来快速适应新节点。在三个公开的数据集上进行了实验，我们的模型比现有状态 искусственный方法表现出色。
</details></li>
</ul>
<hr>
<h2 id="Pseudo-Bayesian-Optimization"><a href="#Pseudo-Bayesian-Optimization" class="headerlink" title="Pseudo-Bayesian Optimization"></a>Pseudo-Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09766">http://arxiv.org/abs/2310.09766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoxian Chen, Henry Lam</li>
<li>for: 这paper的目的是提出一种可靠的黑obox函数优化方法，以便在实际应用中实现优化过程中的可控性和稳定性。</li>
<li>methods: 这paper使用了一种叫做“Pseudo-Bayesian Optimization”的方法，它基于一个具有抽象原则的axioma framework，并使用了一种简单的本地回归和随机 prior 的构造来确定优化过程中的uncertainty。</li>
<li>results: 这paper的实验结果表明，使用 Pseudo-Bayesian Optimization 方法可以不仅确保优化过程的 convergence，还可以在高维 synthetic experiment、hyperparameter tuning 和机器人应用中实现更高的性能，并且可以与现有的state-of-the-art benchmarks相比，显示出更好的性能。<details>
<summary>Abstract</summary>
Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-related methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a suitable "randomized prior" construction to quantify uncertainty, not only guarantees convergence but also consistently outperforms state-of-the-art benchmarks in examples ranging from high-dimensional synthetic experiments to realistic hyperparameter tuning and robotic applications.
</details>
<details>
<summary>摘要</summary>
bayesian 优化是一种广泛应用的优化方法，用于优化costly黑obox函数。其关键思想是使用一个surrogate模型来近似目标函数，同时能够量化相关的uncertainty，以实现sequential搜索。 Gaussian process（GP）因其 bayesian原理下的uncertainty量化能力和模型灵活性而成为主要候选人。然而，GP也存在一些挑战，这些挑战激发了一系列alternatives的发展。在这篇论文中，我们提出了一个axioms framework，该框架可以保证黑obox优化的收敛性，并且可以在GP相关方法之外应用。此外，我们利用了我们的框架的设计自由度，constructed一种empirically superior的算法。具体来说，我们使用了一个简单的local regression，并使用一种适当的“Randomized Prior”的构建来量化uncertainty。这不仅保证了收敛性，还可以在高维 synthetic experiments中consistently outperformstate-of-the-art benchmarks。
</details></li>
</ul>
<hr>
<h2 id="UniTime-A-Language-Empowered-Unified-Model-for-Cross-Domain-Time-Series-Forecasting"><a href="#UniTime-A-Language-Empowered-Unified-Model-for-Cross-Domain-Time-Series-Forecasting" class="headerlink" title="UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting"></a>UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09751">http://arxiv.org/abs/2310.09751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Liu, Junfeng Hu, Yuan Li, Shizhe Diao, Yuxuan Liang, Bryan Hooi, Roger Zimmermann</li>
<li>for: 这个研究旨在提出一个横跨多个时间序列应用领域的统一模型架构，以扩大现有模型的应用范围。</li>
<li>methods: 本研究提出了UniTime模型，可以灵活地适应不同数据特性，并使用语言-时间缩排变换器和封页来实现多模式识别和时间序列数据的搭配。</li>
<li>results: 实验结果显示UniTime模型能够提高现有模型的预测性能和零学习转移性能。<details>
<summary>Abstract</summary>
Multivariate time series forecasting plays a pivotal role in contemporary web technologies. In contrast to conventional methods that involve creating dedicated models for specific time series application domains, this research advocates for a unified model paradigm that transcends domain boundaries. However, learning an effective cross-domain model presents the following challenges. First, various domains exhibit disparities in data characteristics, e.g., the number of variables, posing hurdles for existing models that impose inflexible constraints on these factors. Second, the model may encounter difficulties in distinguishing data from various domains, leading to suboptimal performance in our assessments. Third, the diverse convergence rates of time series domains can also result in compromised empirical performance. To address these issues, we propose UniTime for effective cross-domain time series learning. Concretely, UniTime can flexibly adapt to data with varying characteristics. It also uses domain instructions and a Language-TS Transformer to offer identification information and align two modalities. In addition, UniTime employs masking to alleviate domain convergence speed imbalance issues. Our extensive experiments demonstrate the effectiveness of UniTime in advancing state-of-the-art forecasting performance and zero-shot transferability.
</details>
<details>
<summary>摘要</summary>
多变量时间序列预测在当代网络技术中扮演着关键角色。与传统方法不同，这项研究提出了跨领域模型的统一模型架构，跨越领域边界。然而，学习有效的跨领域模型存在以下挑战：首先，不同领域的数据特征存在差异，例如变量数量，这会限制现有模型的灵活性。其次，模型可能很难分辨不同领域的数据，导致预测性能下降。最后，时间序列领域的多样化速度也可能导致实际性能下降。为解决这些问题，我们提出了UniTime，一种可靠地适应数据特征变化的模型。具体来说，UniTime可以适应数据中的变量数量变化，并使用领域指令和语言-TS transformer来提供标识信息和对两种模式进行对应。此外，UniTime还使用屏蔽来缓解领域融合速度不平衡问题。我们的广泛实验表明UniTime可以提高预测性能和零代负荷传递性。
</details></li>
</ul>
<hr>
<h2 id="Private-Synthetic-Data-Meets-Ensemble-Learning"><a href="#Private-Synthetic-Data-Meets-Ensemble-Learning" class="headerlink" title="Private Synthetic Data Meets Ensemble Learning"></a>Private Synthetic Data Meets Ensemble Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09729">http://arxiv.org/abs/2310.09729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyuan Sun, Navid Azizan, Akash Srivastava, Hao Wang</li>
<li>for: 这篇论文的目的是提高在真实数据上使用机器学习模型的性能，因为训练在实验数据上的模型在真实数据上可能会出现性能下降的问题。</li>
<li>methods: 这篇论文使用了一种新的ensemble策略，通过将多个实验数据中的模型 ensemble起来，以增强模型在真实数据上的表现。具体来说，他们使用了一些具有数据分布差异的实验数据，并将这些数据 ensemble起来，以增加模型的数据多样性。</li>
<li>results: 根据实验结果，这种ensemble策略可以对于使用GAN-based differential privacy mechanisms（即生成机制）训练的下游模型，提高其在真实数据上的表现，包括精度和模型调整的方面。但是，这种策略不会对于使用margin-based或workload-based differential privacy mechanisms（即统计机制）训练的下游模型提高表现。<details>
<summary>Abstract</summary>
When machine learning models are trained on synthetic data and then deployed on real data, there is often a performance drop due to the distribution shift between synthetic and real data. In this paper, we introduce a new ensemble strategy for training downstream models, with the goal of enhancing their performance when used on real data. We generate multiple synthetic datasets by applying a differential privacy (DP) mechanism several times in parallel and then ensemble the downstream models trained on these datasets. While each synthetic dataset might deviate more from the real data distribution, they collectively increase sample diversity. This may enhance the robustness of downstream models against distribution shifts. Our extensive experiments reveal that while ensembling does not enhance downstream performance (compared with training a single model) for models trained on synthetic data generated by marginal-based or workload-based DP mechanisms, our proposed ensemble strategy does improve the performance for models trained using GAN-based DP mechanisms in terms of both accuracy and calibration of downstream models.
</details>
<details>
<summary>摘要</summary>
当机器学习模型在生成的数据上训练并在实际数据上部署时，通常会出现性能下降，这是因为生成的数据和实际数据的分布shift。在这篇论文中，我们介绍了一种新的集成策略，用于训练下游模型，以提高它们在实际数据上的表现。我们通过应用多次 diferencial privacy（DP）机制来生成多个生成的数据集，然后将这些数据集上训练的下游模型 ensemble。虽然每个生成的数据集可能更 deviation from the real data distribution，但它们的总体样本多样性可以提高下游模型对分布shift的Robustness。我们的广泛实验表明，对于基于marginal-based或workload-based DP机制生成的数据集，集成不会提高下游模型的性能（与单个模型训练相比），但是我们的提议的集成策略对基于GAN-based DP机制生成的数据集进行训练，可以提高模型的准确性和下游模型的Calibration。
</details></li>
</ul>
<hr>
<h2 id="SVM-based-Multiclass-Classifier-for-Gait-phase-Classification-using-Shank-IMU-Sensor"><a href="#SVM-based-Multiclass-Classifier-for-Gait-phase-Classification-using-Shank-IMU-Sensor" class="headerlink" title="SVM based Multiclass Classifier for Gait phase Classification using Shank IMU Sensor"></a>SVM based Multiclass Classifier for Gait phase Classification using Shank IMU Sensor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09728">http://arxiv.org/abs/2310.09728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aswadh Khumar G S, Barath Kumar JK</li>
<li>for: 本研究旨在开发一种基于SVM多类分类的步态分类方法，以高精度地标识步态阶段，包括七个子阶段。</li>
<li>methods: 该方法使用个体IMU传感器数据，如膝盖加速度x、y、z和膝盖陀螺x，作为特征进行分类。</li>
<li>results: 该方法可以高度准确地分类不同的步态阶段，准确率约为90.3%。Here’s a breakdown of each point:</li>
<li>for: 本研究旨在开发一种基于SVM多类分类的步态分类方法，以高精度地标识步态阶段，包括七个子阶段。 (The study aims to develop a gait phase classification method based on SVM multi-class classification, to accurately identify the gait phases, including seven sub-phases.)</li>
<li>methods: 该方法使用个体IMU传感器数据，如膝盖加速度x、y、z和膝盖陀螺x，作为特征进行分类。 (The method uses individual IMU sensor data, such as shank acceleration x, y, and z, and knee angles, as features for classification.)</li>
<li>results: 该方法可以高度准确地分类不同的步态阶段，准确率约为90.3%。 (The method can accurately classify different gait phases with an accuracy of approximately 90.3%.)<details>
<summary>Abstract</summary>
In this study, a gait phase classification method based on SVM multiclass classification is introduced, with a focus on the precise identification of the stance and swing phases, which are further subdivided into seven phases. Data from individual IMU sensors, such as Shank Acceleration X, Y, Z, Shank Gyro X, and Knee Angles, are used as features in this classification model. The suggested technique successfully classifies the various gait phases with a significant accuracy of about 90.3%. Gait phase classification is crucial, especially in the domains of exoskeletons and prosthetics, where accurate identification of gait phases enables seamless integration with assistive equipment, improving mobility, stability, and energy economy. This study extends the study of gait and offers an effective method for correctly identifying gait phases from Shank IMU sensor data, with potential applications in biomechanical research, exoskeletons, rehabilitation, and prosthetics.
</details>
<details>
<summary>摘要</summary>
在本研究中，基于SVM多类分类的步态分类方法被引入，强调精准地识别步态的不同阶段，这些阶段进一步细分为七个阶段。研究使用个体IMU传感器数据，如膝盖加速度x、y、z、膝盖陀螺x等，作为分类模型的特征。提议的技术成功地分类不同的步态阶段，准确率达到了约90.3%。步态分类在许多领域都非常重要，如外围机械助手和假肢，准确识别步态阶段可以帮助融合助手设备，提高 mobilidad、稳定性和能源经济。本研究对步态的研究进一步推广，并提供了基于膝盖IMU传感器数据的有效的步态分类方法，可能在生物机械研究、外围机械助手、rehabilitation和假肢领域得到应用。
</details></li>
</ul>
<hr>
<h2 id="Provably-Fast-Convergence-of-Independent-Natural-Policy-Gradient-for-Markov-Potential-Games"><a href="#Provably-Fast-Convergence-of-Independent-Natural-Policy-Gradient-for-Markov-Potential-Games" class="headerlink" title="Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games"></a>Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09727">http://arxiv.org/abs/2310.09727</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sundave1998/independent-npg-mpg">https://github.com/sundave1998/independent-npg-mpg</a></li>
<li>paper_authors: Youbang Sun, Tao Liu, Ruida Zhou, P. R. Kumar, Shahin Shahrampour</li>
<li>for: 这个研究探讨了一种独立自然策略加速算法（NPG），用于多代理游戏学习问题中的Markov潜在游戏。</li>
<li>methods: 这种独立NPG方法使用了一个假 oracle，以获得精确的策略评估，从而在技术假设和潜在差额的假设下，在 $\mathcal{O}(1&#x2F;\epsilon)$ 迭代中达到 $\epsilon$-纳什平衡（NE）。</li>
<li>results: 这个研究证明了，在 synthetic potential game 和 congestion game 中，独立NPG方法可以在 $\mathcal{O}(1&#x2F;\epsilon)$ 迭代中达到 $\epsilon$-纳什平衡，超过之前的最佳结果 $\mathcal{O}(1&#x2F;\epsilon^2)$ 迭代。<details>
<summary>Abstract</summary>
This work studies an independent natural policy gradient (NPG) algorithm for the multi-agent reinforcement learning problem in Markov potential games. It is shown that, under mild technical assumptions and the introduction of the \textit{suboptimality gap}, the independent NPG method with an oracle providing exact policy evaluation asymptotically reaches an $\epsilon$-Nash Equilibrium (NE) within $\mathcal{O}(1/\epsilon)$ iterations. This improves upon the previous best result of $\mathcal{O}(1/\epsilon^2)$ iterations and is of the same order, $\mathcal{O}(1/\epsilon)$, that is achievable for the single-agent case. Empirical results for a synthetic potential game and a congestion game are presented to verify the theoretical bounds.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SGA-A-Graph-Augmentation-Method-for-Signed-Graph-Neural-Networks"><a href="#SGA-A-Graph-Augmentation-Method-for-Signed-Graph-Neural-Networks" class="headerlink" title="SGA: A Graph Augmentation Method for Signed Graph Neural Networks"></a>SGA: A Graph Augmentation Method for Signed Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09705">http://arxiv.org/abs/2310.09705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyu Zhang, Shuyan Wan, Sijie Wang, Xianda Zheng, Xinrui Zhang, Kaiqi Zhao, Jiamou Liu, Dong Hao</li>
<li>for: This paper is written for analyzing complex patterns in real-world signed graphs, and addressing three key challenges in SGNN-based signed graph representation learning: sparsity, unbalanced triangles, and lack of supplementary information.</li>
<li>methods: The paper proposes a novel Signed Graph Augmentation framework (SGA) that includes three main components: (1) using an SGNN model to encode the signed graph and extract latent structural information for candidate augmentation structures, (2) evaluating and selecting the most beneficial candidate samples for modifying the original training set, and (3) a novel augmentation perspective that assigns varying training difficulty to training samples.</li>
<li>results: The paper demonstrates significant improvements in performance across multiple benchmarks using the proposed SGA method, outperforming baselines by up to 22.2% in AUC, 33.3% in F1-binary, 48.8% in F1-micro, and 36.3% in F1-macro on six real-world datasets.<details>
<summary>Abstract</summary>
Signed Graph Neural Networks (SGNNs) are vital for analyzing complex patterns in real-world signed graphs containing positive and negative links. However, three key challenges hinder current SGNN-based signed graph representation learning: sparsity in signed graphs leaves latent structures undiscovered, unbalanced triangles pose representation difficulties for SGNN models, and real-world signed graph datasets often lack supplementary information like node labels and features. These constraints limit the potential of SGNN-based representation learning. We address these issues with data augmentation techniques. Despite many graph data augmentation methods existing for unsigned graphs, none are tailored for signed graphs. Our paper introduces the novel Signed Graph Augmentation framework (SGA), comprising three main components. First, we employ the SGNN model to encode the signed graph, extracting latent structural information for candidate augmentation structures. Second, we evaluate these candidate samples (edges) and select the most beneficial ones for modifying the original training set. Third, we propose a novel augmentation perspective that assigns varying training difficulty to training samples, enabling the design of a new training strategy. Extensive experiments on six real-world datasets (Bitcoin-alpha, Bitcoin-otc, Epinions, Slashdot, Wiki-elec, and Wiki-RfA) demonstrate that SGA significantly improves performance across multiple benchmarks. Our method outperforms baselines by up to 22.2% in AUC for SGCN on Wiki-RfA, 33.3% in F1-binary, 48.8% in F1-micro, and 36.3% in F1-macro for GAT on Bitcoin-alpha in link sign prediction.
</details>
<details>
<summary>摘要</summary>
Signed Graph Neural Networks (SGNNs) 是对实际中带有正负链接的签名图进行分析复杂模式的关键工具。然而，现有的SGNN模型在签名图表示学习中存在三大挑战：签名图中的稀疏性使得潜在结构未被发现，不均衡的triangle对SGNN模型进行表示带来挑战，而且现实中的签名图数据往往缺乏节点标签和特征信息。这些限制使SGNN-基于表示学习的潜力受限。我们通过数据扩充技术来解决这些问题。虽然现有许多对 unsigned 图进行数据扩充的方法，但是这些方法并没有适应签名图。我们的论文提出了一种新的签名图扩充框架（SGA），包括以下三个主要组成部分：1. 我们使用 SGNN 模型来编码签名图，提取签名图中的潜在结构信息作为候选扩充结构。2. 我们评估这些候选样本（边），并选择对原始训练集进行最有利的修改。3. 我们提出了一种新的增强训练方法，对各种训练样本分配不同的训练难度，以便设计更好的训练策略。我们在六个真实世界数据集（Bitcoin-alpha、Bitcoin-otc、Epinions、Slashdot、Wiki-elec和Wiki-RfA）进行了广泛的实验，结果表明，SGA 可以在多个 bench 上显著提高性能。我们的方法在 Wiki-RfA 上的 AUC 上比基eline 提高了22.2%，在 Bitcoin-alpha 上的 F1-binary、F1-micro 和 F1-macro 上提高了33.3%、48.8% 和 36.3%。
</details></li>
</ul>
<hr>
<h2 id="When-Collaborative-Filtering-is-not-Collaborative-Unfairness-of-PCA-for-Recommendations"><a href="#When-Collaborative-Filtering-is-not-Collaborative-Unfairness-of-PCA-for-Recommendations" class="headerlink" title="When Collaborative Filtering is not Collaborative: Unfairness of PCA for Recommendations"></a>When Collaborative Filtering is not Collaborative: Unfairness of PCA for Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09687">http://arxiv.org/abs/2310.09687</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Liu, Jackie Baek, Tina Eliassi-Rad</li>
<li>for: 这paper主要研究了推荐系统中的维度减少方法的公平性。</li>
<li>methods: 这paper使用了主要方法为原理 Component Analysis (PCA)，它可以从高维数据中提取特征组件，并生成一个低维表示。</li>
<li>results: 这paper发现了PCA的两个下面机制，它们会导致推荐系统中的不公平性。此外，paper还提出了一种改进PCA的算法，即Item-Weighted PCA，可以更好地处理不同类型的项目。在一些假设的矩阵上，paper证明了Item-Weighted PCA使用特定的质量可以最小化一个媒体化错误度量。在实际数据上，这paper发现Item-Weighted PCA不仅可以提高总体推荐质量，还可以提高流行和不流行的项目。<details>
<summary>Abstract</summary>
We study the fairness of dimensionality reduction methods for recommendations. We focus on the established method of principal component analysis (PCA), which identifies latent components and produces a low-rank approximation via the leading components while discarding the trailing components. Prior works have defined notions of "fair PCA"; however, these definitions do not answer the following question: what makes PCA unfair? We identify two underlying mechanisms of PCA that induce unfairness at the item level. The first negatively impacts less popular items, due to the fact that less popular items rely on trailing latent components to recover their values. The second negatively impacts the highly popular items, since the leading PCA components specialize in individual popular items instead of capturing similarities between items. To address these issues, we develop a polynomial-time algorithm, Item-Weighted PCA, a modification of PCA that uses item-specific weights in the objective. On a stylized class of matrices, we prove that Item-Weighted PCA using a specific set of weights minimizes a popularity-normalized error metric. Our evaluations on real-world datasets show that Item-Weighted PCA not only improves overall recommendation quality by up to $0.1$ item-level AUC-ROC but also improves on both popular and less popular items.
</details>
<details>
<summary>摘要</summary>
我们研究了维度减少方法的公平性，特别是已知的主 componenets分析（PCA）方法。PCA方法可以找到缺失的特征并生成一个低级别的approximation，通过主要的特征来抛弃追随的特征。先前的研究已经定义了“公平PCA”的概念，但这些定义并没有回答以下问题：PCA方法是如何不公平的？我们认为PCA方法存在两种下面机制，导致item级别的不公平ness。首先，less popular items会受到负面影响，因为这些items rely on追随的特征来恢复其价值。其次，highly popular items会受到负面影响，因为leading PCA components会专注于个体受欢迎的items而不是捕捉items之间的相似性。为了解决这些问题，我们开发了一个幂时间算法，Item-Weighted PCA，这是PCA方法的修改。在一个简化的矩阵类型上，我们证明了Item-Weighted PCA使用的项目特定的权重在目标函数中具有最小化一个受欢迎度normalized error metric的性能。我们对实际数据进行评估，显示Item-Weighted PCA不仅提高了总的推荐质量，最高达0.1个item-level AUC-ROC，同时也提高了受欢迎和less popular items的质量。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Column-Generation-by-Reinforcement-Learning-Based-Hyper-Heuristic-for-Vehicle-Routing-and-Scheduling-Problems"><a href="#Enhancing-Column-Generation-by-Reinforcement-Learning-Based-Hyper-Heuristic-for-Vehicle-Routing-and-Scheduling-Problems" class="headerlink" title="Enhancing Column Generation by Reinforcement Learning-Based Hyper-Heuristic for Vehicle Routing and Scheduling Problems"></a>Enhancing Column Generation by Reinforcement Learning-Based Hyper-Heuristic for Vehicle Routing and Scheduling Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09686">http://arxiv.org/abs/2310.09686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kuan Xu, Li Shen, Lindong Liu</li>
<li>for: 提高大规模问题的解决效率和解得质量</li>
<li>methods: 利用强化学习法 Hyper-heuristic 框架 RLHH 加速Column Generation 方法，并在每个 CG 迭代中选择最佳低级别规划算法</li>
<li>results: 在 Vehicle Routing Problem with Time Windows 和 Bus Driver Scheduling Problem 两个典型的 combinatorial optimization 问题中，可以提高解得质量，最高减少总成本达 27.9% 和 15.4%，在相同或更少的计算时间内减少计算时间。<details>
<summary>Abstract</summary>
Column generation (CG) is a vital method to solve large-scale problems by dynamically generating variables. It has extensive applications in common combinatorial optimization, such as vehicle routing and scheduling problems, where each iteration step requires solving an NP-hard constrained shortest path problem. Although some heuristic methods for acceleration already exist, they are not versatile enough to solve different problems. In this work, we propose a reinforcement learning-based hyper-heuristic framework, dubbed RLHH, to enhance the performance of CG. RLHH is a selection module embedded in CG to accelerate convergence and get better integer solutions. In each CG iteration, the RL agent selects a low-level heuristic to construct a reduced network only containing the edges with a greater chance of being part of the optimal solution. In addition, we specify RLHH to solve two typical combinatorial optimization problems: Vehicle Routing Problem with Time Windows (VRPTW) and Bus Driver Scheduling Problem (BDSP). The total cost can be reduced by up to 27.9\% in VRPTW and 15.4\% in BDSP compared to the best lower-level heuristic in our tested scenarios, within equivalent or even less computational time. The proposed RLHH is the first RL-based CG method that outperforms traditional approaches in terms of solution quality, which can promote the application of CG in combinatorial optimization.
</details>
<details>
<summary>摘要</summary>
column generation (CG) 是一种重要的方法，用于解决大规模问题，通过动态生成变量。它在各种常见的 combinatorial optimization 中有广泛的应用，如车辆 Routing 和调度问题，每个迭代步骤都需要解决一个 NP-hard 约束短路问题。虽然一些启发法已经存在，但它们并不够 versatile  enough 解决不同的问题。在这项工作中，我们提出了一种基于强化学习的 hyper-heuristic 框架，称为 RLHH，以提高 CG 的性能。RLHH 是 CG 中的一个选择模块，用于加速迭代和获得更好的整数解。在每个 CG 迭代中，RL  Agent 将选择一个低级别启发，用于构建一个只包含有更高可能性成为优解的最佳解的减少网络。此外，我们将 RLHH 应用于两种典型的 combinatorial optimization 问题：车辆 Routing 问题 with Time Windows (VRPTW) 和 Bus Driver Scheduling 问题 (BDSP)。我们在测试场景中发现，RLHH 可以将总成本降低到 27.9% 以下，相对于最佳下级别启发，并且在相同或更少的计算时间内达成。我们的提案的 RLHH 是首个通过强化学习来超越传统方法的 CG 方法，可以提高 CG 在 combinatorial optimization 中的应用。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/15/cs.LG_2023_10_15/" data-id="clontc8lu00qc87888klj6nnt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_10_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/15/eess.IV_2023_10_15/" class="article-date">
  <time datetime="2023-10-15T09:00:00.000Z" itemprop="datePublished">2023-10-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/15/eess.IV_2023_10_15/">eess.IV - 2023-10-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Joint-Sparse-Representations-and-Coupled-Dictionary-Learning-in-Multi-Source-Heterogeneous-Image-Pseudo-color-Fusion"><a href="#Joint-Sparse-Representations-and-Coupled-Dictionary-Learning-in-Multi-Source-Heterogeneous-Image-Pseudo-color-Fusion" class="headerlink" title="Joint Sparse Representations and Coupled Dictionary Learning in Multi-Source Heterogeneous Image Pseudo-color Fusion"></a>Joint Sparse Representations and Coupled Dictionary Learning in Multi-Source Heterogeneous Image Pseudo-color Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09937">http://arxiv.org/abs/2310.09937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Long Bai, Shilong Yao, Kun Gao, Yanjun Huang, Ruijie Tang, Hong Yan, Max Q. -H. Meng, Hongliang Ren</li>
<li>for: 提出一种基于 Coupled Dictionary Learning (CDL) 方法的 Synthetic Aperture Radar (SAR) 和多spectral pseudo-color合并方法，以实现高质量的合并图像。</li>
<li>methods: 使用传统的 Brovey 变换进行预处理，然后使用 CDL 捕捉对照图像对的相关性，通过强制联合稀热编码生成字典。最后，利用对字典中的联合稀热表示来构建图像掩蔽mask，并生成最终的合并图像。</li>
<li>results: 通过使用 Sentinel-1 卫星的 SAR 图像和 Landsat-8 卫星的多spectral图像进行实验验证，提出的方法可以实现优秀的视觉效果和数值性能，包括spectral distortion、相关系数、MSE、NIQE、BRISQUE 和 PIQE 等指标。<details>
<summary>Abstract</summary>
Considering that Coupled Dictionary Learning (CDL) method can obtain a reasonable linear mathematical relationship between resource images, we propose a novel CDL-based Synthetic Aperture Radar (SAR) and multispectral pseudo-color fusion method. Firstly, the traditional Brovey transform is employed as a pre-processing method on the paired SAR and multispectral images. Then, CDL is used to capture the correlation between the pre-processed image pairs based on the dictionaries generated from the source images via enforced joint sparse coding. Afterward, the joint sparse representation in the pair of dictionaries is utilized to construct an image mask via calculating the reconstruction errors, and therefore generate the final fusion image. The experimental verification results of the SAR images from the Sentinel-1 satellite and the multispectral images from the Landsat-8 satellite show that the proposed method can achieve superior visual effects, and excellent quantitative performance in terms of spectral distortion, correlation coefficient, MSE, NIQE, BRISQUE, and PIQE.
</details>
<details>
<summary>摘要</summary>
基于coupled dictionary learning（CDL）方法，我们提出了一种新的Synthetic Aperture Radar（SAR）和多spectral pseudo-color融合方法。首先，我们使用传统的Brovey变换作为预处理方法，对paired SAR和多spectral图像进行预处理。然后，我们使用CDL来捕捉paired图像对的相关性，基于源图像生成的字典via强制联合稀热编码。接着，我们利用对的字典中的联合稀热表示来构建图像掩码，通过计算重建错误来生成最终融合图像。实验Result of SAR图像来自Sentinel-1卫星和多spectral图像来自Landsat-8卫星表明，提出的方法可以实现优秀的视觉效果，且在 spectral distortion、相关系数、MSE、NIQE、BRISQUE和PIQE等方面具有出色的量化表现。
</details></li>
</ul>
<hr>
<h2 id="Segment-Anything-Model-for-Pedestrian-Infrastructure-Inventory-Assessing-Zero-Shot-Segmentation-on-Multi-Mode-Geospatial-Data"><a href="#Segment-Anything-Model-for-Pedestrian-Infrastructure-Inventory-Assessing-Zero-Shot-Segmentation-on-Multi-Mode-Geospatial-Data" class="headerlink" title="Segment Anything Model for Pedestrian Infrastructure Inventory: Assessing Zero-Shot Segmentation on Multi-Mode Geospatial Data"></a>Segment Anything Model for Pedestrian Infrastructure Inventory: Assessing Zero-Shot Segmentation on Multi-Mode Geospatial Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09918">http://arxiv.org/abs/2310.09918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahao Xia, Gavin Gong, Jiawei Liu, Zhigang Zhu, Hao Tang</li>
<li>for: 这个论文旨在设计和优化基于Segment Anything Model（SAM）的人行道基础设施分割工作流程，能够有效处理多源地ospatial数据，包括LiDAR数据和卫星图像数据。</li>
<li>methods: 本论文使用扩展的人行道基础设施清单，包括通常被传统定义中排除的街区用品对象。我们的贡献在于生成必要的知识，回答以下两个问题：首先，哪种数据表示可以使SAM实现零批处理基础设施对象？其次，SAM如何在分割人行道基础设施对象方面表现？</li>
<li>results: 我们的发现表明，将来自移动LiDAR点云数据生成的街景图像与卫星图像数据结合使用，可以与SAM高效地创建可扩展的人行道基础设施清单，具有立即的利用价值，对于GIS专业人员、城市管理者、交通所有者和残疾人旅行者都具有重要意义。<details>
<summary>Abstract</summary>
In this paper, a Segment Anything Model (SAM)-based pedestrian infrastructure segmentation workflow is designed and optimized, which is capable of efficiently processing multi-sourced geospatial data including LiDAR data and satellite imagery data. We used an expanded definition of pedestrian infrastructure inventory which goes beyond the traditional transportation elements to include street furniture objects often omitted from the traditional definition. Our contributions lie in producing the necessary knowledge to answer the following two questions. First, which data representation can facilitate zero-shot segmentation of infrastructure objects with SAM? Second, how well does the SAM-based method perform on segmenting pedestrian infrastructure objects? Our findings indicate that street view images generated from mobile LiDAR point cloud data, when paired along with satellite imagery data, can work efficiently with SAM to create a scalable pedestrian infrastructure inventory approach with immediate benefits to GIS professionals, city managers, transportation owners, and walkers, especially those with travel-limiting disabilities.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们设计了基于Segment Anything Model（SAM）的人行道基础设施分割工作流程，可以高效处理多源地ospatial数据，包括LiDAR数据和卫星图像数据。我们使用扩展的人行道基础设施清单定义，超出传统交通元素，包括通常被忽略的街 furniture对象。我们的贡献在于生成必要的知识，回答以下两个问题：首先，哪种数据表示可以通过SAM实现零批处理基础设施对象？第二，SAM基于方法如何在基础设施对象上进行分割？我们的发现表明，从移动LiDAR点云数据生成的街景图像，当与卫星图像数据结合使用时，可以高效地与SAM合作创建可扩展的人行道基础设施清单方法，具有立即的利益 дляGIS专业人员、城市管理者、交通所有人和残疾人，特别是那些受限的旅行者。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/15/eess.IV_2023_10_15/" data-id="clontc8rt016u87884avac67k" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_10_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/15/eess.SP_2023_10_15/" class="article-date">
  <time datetime="2023-10-15T08:00:00.000Z" itemprop="datePublished">2023-10-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/15/eess.SP_2023_10_15/">eess.SP - 2023-10-15</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Distributed-Estimation-with-Partially-Accessible-Information-An-IMAT-Approach-to-LMS-Diffusion"><a href="#Distributed-Estimation-with-Partially-Accessible-Information-An-IMAT-Approach-to-LMS-Diffusion" class="headerlink" title="Distributed Estimation with Partially Accessible Information: An IMAT Approach to LMS Diffusion"></a>Distributed Estimation with Partially Accessible Information: An IMAT Approach to LMS Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09970">http://arxiv.org/abs/2310.09970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Shamsi, Farokh Marvasti</li>
<li>for: 提高分布式算法的可见性和稳定性</li>
<li>methods: 基于信号流分析的组合策略分析框架和阈值算法</li>
<li>results: 在时域和变换域中存在缺失信息的情况下，提出了一种基于阈值算法的支持向量识别和利用策略，并在两种组合enario中进行了示范<details>
<summary>Abstract</summary>
Distributed algorithms, particularly Diffusion Least Mean Square, are widely favored for their reliability, robustness, and fast convergence in various industries. However, limited observability of the target can compromise the integrity of the algorithm. To address this issue, this paper proposes a framework for analyzing combination strategies by drawing inspiration from signal flow analysis. A thresholding-based algorithm is also presented to identify and utilize the support vector in scenarios with missing information about the target vector's support. The proposed approach is demonstrated in two combination scenarios, showcasing the effectiveness of the algorithm in situations characterized by sparse observations in the time and transform domains.
</details>
<details>
<summary>摘要</summary>
diffused least squares 算法在各个领域得到广泛应用，特别是因为它们的可靠性、鲁棒性和快速收敛性。然而，target vector的有限可见性可能会导致算法的完整性受到损害。为解决这个问题，本文提出了一种基于信号流分析的框架，并提出了一种阈值分析法来Identify和利用目标向量的支持向量在有限信息的情况下。该方法在时域和变换域中的缺失观测场景中进行了两种组合场景的示例，展示了该算法在稀疏观测场景中的效果。Note: "Diffusion Least Mean Square" in the original text is translated as "diffused least squares 算法" in Simplified Chinese, as "diffusion" is not a commonly used term in Chinese and "least squares" is more commonly used to refer to this type of algorithm.
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-End-to-End-Learning-for-Integrated-Sensing-and-Communications"><a href="#Semi-Supervised-End-to-End-Learning-for-Integrated-Sensing-and-Communications" class="headerlink" title="Semi-Supervised End-to-End Learning for Integrated Sensing and Communications"></a>Semi-Supervised End-to-End Learning for Integrated Sensing and Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09940">http://arxiv.org/abs/2310.09940</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/josemateosramos/sslisac">https://github.com/josemateosramos/sslisac</a></li>
<li>paper_authors: José Miguel Mateos-Ramos, Baptiste Chatelier, Christian Häger, Musa Furkan Keskin, Luc Le Magoarou, Henk Wymeersch</li>
<li>for: 本文针对 ISAC 混合感知通信系统的问题进行研究，旨在提高硬件、频率和能源效率。</li>
<li>methods: 本文使用 differentiable model-based 学习方法，实现了单目标检测和定位估计，以及多input single-output 通信。</li>
<li>results: 我们的结果显示，使用半指导学习策略可以实现相似的性能，仅需使用 98.8%  fewer labeled data。<details>
<summary>Abstract</summary>
Integrated sensing and communications (ISAC) is envisioned as one of the key enablers of next-generation wireless systems, offering improved hardware, spectral, and energy efficiencies. In this paper, we consider an ISAC transceiver with an impaired uniform linear array that performs single-target detection and position estimation, and multiple-input single-output communications. A differentiable model-based learning approach is considered, which optimizes both the transmitter and the sensing receiver in an end-to-end manner. An unsupervised loss function that enables impairment compensation without the need for labeled data is proposed. Semi-supervised learning strategies are also proposed, which use a combination of small amounts of labeled data and unlabeled data. Our results show that semi-supervised learning can achieve similar performance to supervised learning with 98.8% less required labeled data.
</details>
<details>
<summary>摘要</summary>
“集成感测通信（ISAC）是未来无线系统的关键促进因素，提供了改善硬件、频率和能量效率。本文考虑了一种受损均匀线列天线的ISAC收发器，实现单目标探测和位置估计，以及多输入单出口通信。我们使用可导模型基本学习方法，在终端干扰下优化发射器和探测Receiver。我们提出了无标签数据补偿的不监督学习策略，以及使用小量标签数据和无标签数据的半监督学习策略。我们的结果表明，半监督学习可以与监督学习准确率相似，仅需98.8%的标签数据。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Enhance-Security-of-Time-Modulated-Array-Enabled-Directional-Modulation-by-Introducing-Symbol-Ambiguity"><a href="#Enhance-Security-of-Time-Modulated-Array-Enabled-Directional-Modulation-by-Introducing-Symbol-Ambiguity" class="headerlink" title="Enhance Security of Time-Modulated Array-Enabled Directional Modulation by Introducing Symbol Ambiguity"></a>Enhance Security of Time-Modulated Array-Enabled Directional Modulation by Introducing Symbol Ambiguity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09922">http://arxiv.org/abs/2310.09922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihao Tao, Zhaoyi Xu, Athina Petropulu</li>
<li>for: 这个论文研究了时间模拟数组（TMA）启用的方向性模拟（DM）通信系统是否可以破解。</li>
<li>methods: 论文首先示出了使用格点搜索可以成功找到TMA生成的唯一和实际混合矩阵。然后，提出了引入符号模糊来防止格点搜索的推论，并设计了两个原则来构建符号模糊：一是缺rank的缺失和非唯一性的ON-OFF切换模式。</li>
<li>results: 论文提出的原则和机制不仅可以在理论上设计更安全的TMA DM系统，还经验 validate 了其效果。<details>
<summary>Abstract</summary>
In this paper, if the time-modulated array (TMA)-enabled directional modulation (DM) communication system can be cracked is investigated and the answer is YES! We first demonstrate that the scrambling data received at the eavesdropper can be defied by using grid search to successfully find the only and actual mixing matrix generated by TMA. Then, we propose introducing symbol ambiguity to TMA to defend the defying of grid search, and design two principles for the TMA mixing matrix, i.e., rank deficiency and non-uniqueness of the ON-OFF switching pattern, that can be used to construct the symbol ambiguity. Also, we present a feasible mechanism to implement these two principles. Our proposed principles and mechanism not only shed light on how to design a more secure TMA DM system theoretically in the future, but also have been validated to be effective by bit error rate measurements.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们调查了使用时间模拟数组（TMA）启用方向性模式（DM）通信系统是否可以被破解。我们首先表明了使用格点搜索可以成功地找到由TMA生成的唯一和实际混合矩阵。然后，我们提议引入符号模糊性来防止格点搜索的推断，并设计了两种原则来构建符号模糊性，即缺陷行列和非唯一性的ON-OFF切换模式。此外，我们还提出了可行的实现机制。我们的提出的原则和机制不仅帮助我们在未来理论上设计更安全的TMA DM系统，而且已经被验证了通过比特错误率测量。
</details></li>
</ul>
<hr>
<h2 id="Stacked-Intelligent-Metasurface-Performs-a-2D-DFT-in-the-Wave-Domain-for-DOA-Estimation"><a href="#Stacked-Intelligent-Metasurface-Performs-a-2D-DFT-in-the-Wave-Domain-for-DOA-Estimation" class="headerlink" title="Stacked Intelligent Metasurface Performs a 2D DFT in the Wave Domain for DOA Estimation"></a>Stacked Intelligent Metasurface Performs a 2D DFT in the Wave Domain for DOA Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09861">http://arxiv.org/abs/2310.09861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiancheng An, Chau Yuen, Marco Di Renzo, Merouane Debbah, H. Vincent Poor, Lajos Hanzo</li>
<li>for: 这个论文的目的是提出一种基于受托辐射元件（SIM）的技术来实现二维方向来源估算（DOA）。</li>
<li>methods: 这种技术使用了一种先进的SIM，其中每个元件在入射波传播过程中自动完成了二维离散傅里叶变换（DFT）。为了使SIM完成这个任务，我们设计了一个梯度下降算法，用于逐步更新每个元件的相位Shift，以最小化SIM的响应和2D DFT矩阵之间的差异。</li>
<li>results: 数值模拟结果表明，一个充分训练的SIM可以很准确地完成2D DFT。例如，在实验中，SIM的计算速度为光学计算速度，DOA估算的 сред平均误差（MSE）为10^-4。<details>
<summary>Abstract</summary>
Staked intelligent metasurface (SIM) based techniques are developed to perform two-dimensional (2D) direction-of-arrival (DOA) estimation. In contrast to the conventional designs, an advanced SIM in front of the receiving array automatically performs the 2D discrete Fourier transform (DFT) as the incident waves propagate through it. To arrange for the SIM to carry out this task, we design a gradient descent algorithm for iteratively updating the phase shift of each meta-atom in the SIM to minimize the fitting error between the SIM's response and the 2D DFT matrix. To further improve the DOA estimation accuracy, we configure the phase shifts in the input layer of SIM to generate a set of 2D DFT matrices having orthogonal spatial frequency bins. Extensive numerical simulations verify the capability of a well-trained SIM to perform 2D DFT. Specifically, it is demonstrated that the SIM having an optical computational speed achieves an MSE of $10^{-4}$ in 2D DOA estimation.
</details>
<details>
<summary>摘要</summary>
“基于固化智能表面（SIM）技术的二维方向来源估计（2D DOA）方法已经开发出来。与传统设计不同的是，我们在接收阵列前方的高级SIM上自动执行2D离散傅里叶变换（DFT）。为让SIM进行这项任务，我们设计了一种梯度下降算法，通过迭代更新每个元素的相位偏移，以最小化SIM的响应和2D DFT矩阵之间的差异。为了进一步提高DOA估计精度，我们在SIM的输入层中配置了一系列的2D DFT矩阵，其中每个矩阵具有正交的空间频率分辨率。数值仿真表明，一个具有光学计算速度的SIM可以实现2D DOA估计的 mean squared error（MSE）为10^-4。”Note: The translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Towards-Structural-Sparse-Precoding-Dynamic-Time-Frequency-Space-and-Power-Multistage-Resource-Programming"><a href="#Towards-Structural-Sparse-Precoding-Dynamic-Time-Frequency-Space-and-Power-Multistage-Resource-Programming" class="headerlink" title="Towards Structural Sparse Precoding: Dynamic Time, Frequency, Space, and Power Multistage Resource Programming"></a>Towards Structural Sparse Precoding: Dynamic Time, Frequency, Space, and Power Multistage Resource Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09840">http://arxiv.org/abs/2310.09840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongxiang Wei, Ping Wang, Qingjiang Shi, Xu Zhu, Christos Masouros</li>
<li>for: 这篇论文主要针对 fifth-generation 通信系统中的即时传输应用需求，尤其是在时间维度上的质量要求。</li>
<li>methods: 本论文使用 multistage 优化方法，包括时间、频率、空间和能量领域资源的共同优化。</li>
<li>results: 本论文的设计可以实现高性能的传输系统，并且具有快速的数据测试速率。<details>
<summary>Abstract</summary>
In last decades, dynamic resource programming in partial resource domains has been extensively investigated for single time slot optimizations. However, with the emerging real-time media applications in fifth-generation communications, their new quality of service requirements are often measured in temporal dimension. This requires multistage optimization for full resource domain dynamic programming. Taking experience rate as a typical temporal multistage metric, we jointly optimize time, frequency, space and power domains resource for multistage optimization. To strike a good tradeoff between system performance and computational complexity, we first transform the formulated mixed integer non-linear constraints into equivalent convex second order cone constraints, by exploiting the coupling effect among the resources. Leveraging the concept of structural sparsity, the objective of max-min experience rate is given as a weighted 1-norm term associated with the precoding matrix. Finally, a low-complexity iterative algorithm is proposed for full resource domain programming, aided by another simple conic optimization for obtaining its feasible initial result. Simulation verifies that our design significantly outperform the benchmarks while maintaining a fast convergence rate, shedding light on full domain dynamic resource programming of multistage optimizations.
</details>
<details>
<summary>摘要</summary>
最近几十年，在半资源领域中进行了广泛的动态资源编程，以优化单个时间槽。然而，五代通信技术出现后，新的服务质量要求 oft measure在时间维度上。这需要进行全资源领域的多阶段优化。以经验率为例的 temporaldimensional metric，我们同时优化了时间、频率、空间和功率领域的资源。为了 достичь系统性能和计算复杂度之间的好 equilibrio,我们首先将混合整数非线性约束转化为等效的几何二次辐射约束，利用资源之间的协同作用。然后，我们给出了一个优化目标函数，其中包含了约束matrix的权重的1- norm。最后，我们提出了一种低复杂度的迭代算法，用于实现全资源领域的动态资源编程，并且使用另一个简单的几何优化算法来获得其可行的初始结果。实验证明了我们的设计在比较性能和速度方面具有显著的优势，提供了全资源领域的动态资源编程的全面性和可行性。
</details></li>
</ul>
<hr>
<h2 id="Cell-Free-Massive-MIMO-Surveillance-Systems"><a href="#Cell-Free-Massive-MIMO-Surveillance-Systems" class="headerlink" title="Cell-Free Massive MIMO Surveillance Systems"></a>Cell-Free Massive MIMO Surveillance Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09769">http://arxiv.org/abs/2310.09769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Mobini, Hien Quoc Ngo, Michail Matthaiou, Lajos Hanzo</li>
<li>for: 本研究旨在提高国家安全性，通过使用无线监测系统来监测不可信通信链接。</li>
<li>methods: 本研究提出了一种新的维度免疫多输入多输出（CF-mMIMO）无线监测系统，其中许多分散的多天线帮助监测节点（MNs）进行观察或干扰不可信的通信链接。</li>
<li>results: 我们分析了CF-mMIMO无线监测系统的性能，并 deriv了关于监测成功率的关闭式表达式。我们还提出了一种满足同时观察和干扰的模式分配算法，以及一种最大化最小监测成功率的干扰发射功率分配算法。研究结果表明，我们的提posed CF-mMIMO系统可以在相对较少的MN数量下提供显著性能提升，比基准值co-located mMIMO系统的11倍。<details>
<summary>Abstract</summary>
Wireless surveillance, in which untrusted communications links are proactively monitored by legitimate agencies, has started to garner a lot of interest for enhancing the national security. In this paper, we propose a new cell-free massive multiple-input multiple-output (CF-mMIMO) wireless surveillance system, where a large number of distributed multi-antenna aided legitimate monitoring nodes (MNs) embark on either observing or jamming untrusted communication links. To facilitate concurrent observing and jamming, a subset of the MNs is selected for monitoring the untrusted transmitters (UTs), while the remaining MNs are selected for jamming the untrusted receivers (URs). We analyze the performance of CF-mMIMO wireless surveillance and derive a closed-form expression for the monitoring success probability of MNs. We then propose a greedy algorithm for the observing vs, jamming mode assignment of MNs, followed by the conception of a jamming transmit power allocation algorithm for maximizing the minimum monitoring success probability concerning all the UT and UR pairs based on the associated long-term channel state information knowledge. In conclusion, our proposed CF-mMIMO system is capable of significantly improving the performance of the MNs compared to that of the state-of-the-art baseline. In scenarios of a mediocre number of MNs, our proposed scheme provides an 11-fold improvement in the minimum monitoring success probability compared to its co-located mMIMO benchmarker.
</details>
<details>
<summary>摘要</summary>
无线监测，在无法确保通信链路的情况下，由合法机构监测，已经吸引了很多关注，以提高国家安全。在这篇论文中，我们提议一种新的终端分布式多输入多输出（CF-mMIMO）无线监测系统，其中一大量分布在多个antenna帮助合法监测节点（MNs）进行观察或干扰不可信通信链路。为实现同时观察和干扰，一部分MNs用于观察不可信发送器（UTs），而另一部分MNs用于干扰不可信接收器（URs）。我们分析了CF-mMIMO无线监测系统的性能，并 derivated一个关闭式表达式来表示MNs的监测成功率。然后，我们提出了一种满足策略来选择MNs的观察和干扰模式，并提出了一种基于长期通道状态信息的干扰发射功率分配策略，以最大化所有UT和UR对的监测成功率。在结论中，我们的提议的CF-mMIMO系统可以在MNs的数量不多的情况下，与当前基准相比，提高监测成功率的最小值。在一些中等数量的MNs情况下，我们的方案提供了11倍的监测成功率提升，相比于其相对位置的mMIMO参考。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Smart-Algorithms-for-Gait-Phases-Detection-in-Lower-Limb-Prosthesis-A-Comprehensive-Review"><a href="#Assessing-Smart-Algorithms-for-Gait-Phases-Detection-in-Lower-Limb-Prosthesis-A-Comprehensive-Review" class="headerlink" title="Assessing Smart Algorithms for Gait Phases Detection in Lower Limb Prosthesis: A Comprehensive Review"></a>Assessing Smart Algorithms for Gait Phases Detection in Lower Limb Prosthesis: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09735">http://arxiv.org/abs/2310.09735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Barath Kumar JK, Aswadh Khumar G S</li>
<li>for: 这些研究旨在提高步态分类的精度，以便在脊梁rehabilitation系统中应用。</li>
<li>methods: 这些研究使用了多种感知器，包括佩戴式和非佩戴式的感知器，以获取步态数据。</li>
<li>results: 研究发现了多种感知器和感知器组合，可以在日常环境中分析步态模式。这些感知器的选择因素包括感知器的精度、可靠性和成本等。<details>
<summary>Abstract</summary>
Over the past few years, the division of gait phases has emerged as a complex area of research that carries significant importance for various applications in the field of gait technologies. The accurate partitioning of gait phases plays a crucial role in advancing these applications. Researchers have been exploring a range of sensors that can be employed to provide data for algorithms involved in gait phase partitioning. These sensors can be broadly categorized into two types: wearable and non-wearable, each offering unique advantages and capabilities. In our study aimed at examining the current approaches to gait analysis and detection specifically designed for implementation in ambulatory rehabilitation systems, we conducted a comprehensive meta-analysis of existing research studies. Our analysis revealed a diverse range of sensors and sensor combinations that demonstrate the ability to analyze gait patterns in ambulatory settings. These sensor options vary from basic force-based binary switches to more intricate setups incorporating multiple inertial sensors and sophisticated algorithms. The findings highlight the wide spectrum of available technologies and methodologies used in gait analysis for ambulatory applications. To conduct an extensive review, we systematically examined two prominent databases, IEEE and Scopus, with the aim of identifying relevant studies pertaining to gait analysis. The search criteria were limited to 189 papers published between 1999 and 2023. From this pool, we identified and included five papers that specifically focused on various techniques including Thresholding, Quasi-static method, adaptive classifier, and SVM-based approaches. These selected papers provided valuable insights for our review.
</details>
<details>
<summary>摘要</summary>
过去几年，走势阶段的分类已经成为一个复杂的研究领域，具有重要的应用意义在走势技术领域。精确地分类走势阶段是提高这些应用的关键因素。研究人员正在探索一种以下的仪器来提供资料 для走势阶段分类的算法：抽象和非抽象的仪器，每一种都有各自的优点和能力。在我们的研究中，我们对于数位训练系统中的走势分析和检测进行了广泛的meta分析。我们发现了一些不同的仪器和仪器组合，可以在行动 Setting中分析走势模式。这些仪器选择自基本的力矩基于的二进制变数到更复杂的设备和复杂的算法。我们的发现显示了走势分析在行动应用中的广泛技术和方法。为了进行广泛的评审，我们对IEEE和Scopus两个著名的数据库进行了系统性的搜寻，并将搜寻结果限定为1999年至2023年发表的189篇文献。从这个池中，我们选择和包括了不同的技术，例如阈值分类、静止方法、适应分类和SVM基本方法的五篇文献。这些选择的文献给我们提供了宝贵的启示。
</details></li>
</ul>
<hr>
<h2 id="A-generalization-of-the-achievable-rate-of-a-MISO-system-using-Bode-Fano-wideband-matching-theory"><a href="#A-generalization-of-the-achievable-rate-of-a-MISO-system-using-Bode-Fano-wideband-matching-theory" class="headerlink" title="A generalization of the achievable rate of a MISO system using Bode-Fano wideband matching theory"></a>A generalization of the achievable rate of a MISO system using Bode-Fano wideband matching theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09723">http://arxiv.org/abs/2310.09723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nitish Deshpande, Miguel R. Castellanos, Saeed R. Khosravirad, Jinfeng Du, Harish Viswanathan, Robert W. Heath Jr</li>
<li>for: 本研究旨在提高多输入单输出（MISO）系统的信息理论可实现率，并具体实现了宽频匹配理论。</li>
<li>methods: 本研究使用多口电路理论方法，具体是利用频率选择性的散射参数来优化MISO系统的可实现率。</li>
<li>results: 研究结果表明，使用优化的传输系数和劳达-法诺不等式约束，可以提高MISO系统的信息理论可实现率。对比 идеаль的可实现率、不考虑匹配约束的可实现率以及使用不优化匹配策略的可实现率，研究结果表明优化匹配网络可以提高MISO系统的可实现率。此外，研究还提出了一种实用的方法来估算可实现率上限。<details>
<summary>Abstract</summary>
Impedance-matching networks affect power transfer from the radio frequency (RF) chains to the antennas. Their design impacts the signal to noise ratio (SNR) and the achievable rate. In this paper, we maximize the information-theoretic achievable rate of a multiple-input-single-output (MISO) system with wideband matching constraints. Using a multiport circuit theory approach with frequency-selective scattering parameters, we propose a general framework for optimizing the MISO achievable rate that incorporates Bode-Fano wideband matching theory. We express the solution to the achievable rate optimization problem in terms of the optimized transmission coefficient and the Lagrangian parameters corresponding to the Bode-Fano inequality constraints. We apply this framework to a single electric Chu's antenna and an array of two electric Chu's antennas. We compare the optimized achievable rate obtained numerically with other benchmarks like the ideal achievable rate computed by disregarding matching constraints and the achievable rate obtained by using sub-optimal matching strategies like conjugate matching and frequency-flat transmission. We also propose a practical methodology to approximate the achievable rate bound by using the optimal transmission coefficient to derive a physically realizable matching network through the ADS software.
</details>
<details>
<summary>摘要</summary>
“干扰网络影响电力传输自 ради频率（RF）扩展到天线。它们的设计对信号与噪音比（SNR）和可行率有影响。在这篇论文中，我们将最大化多Input单Output（MISO）系统的信号理论可行率。使用多口筒电路理论方法，我们提出一个应用各种频率选择性散射特性的通用框架，以便优化MISO可行率。我们将解决可行率最佳化问题的解释为优化传输系数和Bode-Fano干扰对称理论中的Lagrangian参数。我们将这个框架应用到单电池Chu天线和两个电池Chu天线阵列。我们比较优化的可行率与其他参考标准（例如忽略干扰限制的理论可行率和适应干扰策略如 conjugate matching和频率平坦传输）进行比较。我们还提出了一个实用的方法来近似可行率上限，通过使用最佳传输系数来 derive physically realizable干扰网络，使用ADS软件。”
</details></li>
</ul>
<hr>
<h2 id="Two-Enhanced-rate-Power-Allocation-Strategies-for-Active-IRS-assisted-Wireless-Network"><a href="#Two-Enhanced-rate-Power-Allocation-Strategies-for-Active-IRS-assisted-Wireless-Network" class="headerlink" title="Two Enhanced-rate Power Allocation Strategies for Active IRS-assisted Wireless Network"></a>Two Enhanced-rate Power Allocation Strategies for Active IRS-assisted Wireless Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09721">http://arxiv.org/abs/2310.09721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiankun Cheng, Rongen Dong, Wenlong Cai, Ruiqi Liu, Feng Shu, Jiangzhou Wang<br>for:active IRS-aided network under a total power constraintmethods:adjusting power between base station (BS) and IRS, transmit beamforming at BS, reflecting beamforming at IRSresults:maximizing the SNR with two high-performance PA strategies, enhanced multiple random initialization Newton’s (EMRIN) and Taylor polynomial approximation (TPA), which perform much better than fixed PA in accordance with rate, and approach exhaustive search as the number of IRS reflecting elements increases.Here is the Chinese translation of the three key information points:for:活动反射表面协助网络下的总功率限制方法:调整基站和反射表面之间的功率，传输扫描和反射扫描结果:通过两种高性能的PA策略，即增强多random初始化Newton方法（EMRIN）和Taylor多项式approximation（TPA），实现了对级别的最大化SNR，并且比固定PA更好，随着反射表面元素的数量增加，逼近极值搜索。<details>
<summary>Abstract</summary>
Due to its ability of overcoming the impact of double-fading effect, active intelligent reflecting surface (IRS) has attracted a lot of attention. Unlike passive IRS, active IRS should be supplied by power, thus adjusting power between base station (BS) and IRS having a direct impact on the system rate performance. In this paper, the active IRS-aided network under a total power constraint is modeled with an ability of adjusting power between BS and IRS. Given the transmit beamforming at BS and reflecting beamforming at IRS, the SNR expression is derived to be a function of power allocation (PA) factor, and the optimization of maximizing the SNR is given. Subsequently, two high-performance PA strategies, enhanced multiple random initialization Newton's (EMRIN) and Taylor polynomial approximation (TPA), are proposed. The former is to improve the rate performance of classic Netwon's method to avoid involving a local optimal point by using multiple random initializations. To reduce its high computational complexity, the latter provides a closed-form solution by making use of the first-order Taylor polynomial approximation to the original SNR function. Actually, using TPA, the original optimization problem is transformed into a problem of finding a root for a third-order polynomial.Simulation results are as follows: the first-order TPA of SNR fit its exact expression well, the proposed two PA methods performs much better than fixed PA in accordance with rate, and appoaches exhaustive search as the number of IRS reflecting elements goes to large-scale.
</details>
<details>
<summary>摘要</summary>
因为它可以超越双折射效应的影响，活动智能反射 superficie (IRS) 已经吸引了很多关注。 unlike 被动 IRS，活动 IRS 需要接受电力供应，因此在基站 (BS) 和 IRS 之间的电力调整直接影响系统速率性能。在这篇文章中，我们模型了具有电力限制的活动 IRS-助け的网络。给定基站发射扫描和 IRS 反射扫描，我们 derivate 了 SNR 表达式，并提出了最大化 SNR 的优化问题。然后，我们提出了两种高性能 PA 策略：增强多个随机初始化 Newton 方法（EMRIN）和 Taylor  polynomials 近似法（TPA）。前者是为了提高 классических Newton 方法的率性能，避免Local 优点点的涉及。而后者通过使用首颗 Taylor  polynomials 近似来原 SNR 函数，提供了一个关闭式解决方案，从而减少了高计算复杂性。实际上，使用 TPA，原来的优化问题被转化为了一个找到第三阶 polynomials 的根的问题。实验结果如下：TPA 的第一阶近似与 exact 表达式很相似，而我们提出的两种 PA 方法在 accordance  WITH 率性能上明显超过 fix PA，并且随着 IRS 反射元件的数量增加，两种方法的性能接近 exhaustive search。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/15/eess.SP_2023_10_15/" data-id="clontc8t701aa8788d03fe317" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_10_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/14/cs.SD_2023_10_14/" class="article-date">
  <time datetime="2023-10-14T15:00:00.000Z" itemprop="datePublished">2023-10-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/14/cs.SD_2023_10_14/">cs.SD - 2023-10-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Dynamic-Prediction-of-Full-Ocean-Depth-SSP-by-Hierarchical-LSTM-An-Experimental-Result"><a href="#Dynamic-Prediction-of-Full-Ocean-Depth-SSP-by-Hierarchical-LSTM-An-Experimental-Result" class="headerlink" title="Dynamic Prediction of Full-Ocean Depth SSP by Hierarchical LSTM: An Experimental Result"></a>Dynamic Prediction of Full-Ocean Depth SSP by Hierarchical LSTM: An Experimental Result</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09522">http://arxiv.org/abs/2310.09522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiajun Lu, Wei Huang, Hao Zhang</li>
<li>for: 用于预测未来水声速度分布，提高海上定位、导航和时间测量（PNT）精度。</li>
<li>methods: 提议使用层次Long Short-Term Memory（H-LSTM）神经网络预测未来水声速度分布，利用时间维度中的声速分布分布模式。</li>
<li>results: 通过实验和仿真 validate the proposed method，结果显示该方法的准确率高于现有方法。<details>
<summary>Abstract</summary>
SSP distribution is an important parameter for underwater positioning, navigation and timing (PNT) because it affects the propagation mode of underwater acoustic signals. To accurate predict future sound speed distribution, we propose a hierarchical long short--term memory (H--LSTM) neural network for future sound speed prediction, which explore the distribution pattern of sound velocity in the time dimension. To verify the feasibility and effectiveness, we conducted both simulations and real experiments. The ocean experiment was held in the South China Sea in April, 2023. Results show that the accuracy of the proposed method outperforms the state--of--the--art methods.
</details>
<details>
<summary>摘要</summary>
<<SSP分布是水下定位、导航和时间（PNT）中的一个重要参数，因为它影响水下声波的传播模式。为了准确预测未来声速分布，我们提议使用层次长短期记忆（H-LSTM）神经网络进行未来声速预测，以探索声速在时间维度上的分布模式。为了证明可行性和有效性，我们进行了 simulations和实验。海洋实验在2023年4月在南海举行。结果表明，提议的方法的精度高于现有方法。>>Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/14/cs.SD_2023_10_14/" data-id="clontc8o400x38788dbfjcpqr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_10_14" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/14/cs.CV_2023_10_14/" class="article-date">
  <time datetime="2023-10-14T13:00:00.000Z" itemprop="datePublished">2023-10-14</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/14/cs.CV_2023_10_14/">cs.CV - 2023-10-14</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="What-Do-Deep-Saliency-Models-Learn-about-Visual-Attention"><a href="#What-Do-Deep-Saliency-Models-Learn-about-Visual-Attention" class="headerlink" title="What Do Deep Saliency Models Learn about Visual Attention?"></a>What Do Deep Saliency Models Learn about Visual Attention?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09679">http://arxiv.org/abs/2310.09679</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/szzexpoi/saliency_analysis">https://github.com/szzexpoi/saliency_analysis</a></li>
<li>paper_authors: Shi Chen, Ming Jiang, Qi Zhao</li>
<li>for: 这篇论文旨在探讨深度聚焦模型如何预测人类视觉注意力，以及这些模型的成功机制是如何工作的。</li>
<li>methods: 本文提出了一种新的分析框架，可以帮助理解深度聚焦模型学习的隐藏特征，并提供了一种原则性的解释和量化这些特征的贡献。这个框架可以将隐藏特征分解成可解释的基准，并将聚焦预测转化为一种权重组合的问题。</li>
<li>results: 通过应用这种框架，我们进行了广泛的分析，包括聚焦预测的正面和负面权重、训练数据和架构设计的影响、细化训练的进程效应和常见的深度聚焦模型失败模式。此外，我们还通过分析不同应用场景中的视觉注意力特征，如人类自闭症 spectrum 症例中的异常注意力、情感引起的吸引注意力和时间的注意力演化。<details>
<summary>Abstract</summary>
In recent years, deep saliency models have made significant progress in predicting human visual attention. However, the mechanisms behind their success remain largely unexplained due to the opaque nature of deep neural networks. In this paper, we present a novel analytic framework that sheds light on the implicit features learned by saliency models and provides principled interpretation and quantification of their contributions to saliency prediction. Our approach decomposes these implicit features into interpretable bases that are explicitly aligned with semantic attributes and reformulates saliency prediction as a weighted combination of probability maps connecting the bases and saliency. By applying our framework, we conduct extensive analyses from various perspectives, including the positive and negative weights of semantics, the impact of training data and architectural designs, the progressive influences of fine-tuning, and common failure patterns of state-of-the-art deep saliency models. Additionally, we demonstrate the effectiveness of our framework by exploring visual attention characteristics in various application scenarios, such as the atypical attention of people with autism spectrum disorder, attention to emotion-eliciting stimuli, and attention evolution over time. Our code is publicly available at \url{https://github.com/szzexpoi/saliency_analysis}.
</details>
<details>
<summary>摘要</summary>
在最近的几年中，深度眩怯模型已经取得了人类视觉注意力预测的 significanth进步。然而，这些模型的成功的机制仍然largely unexplained，这是因为深度神经网络的含义不 transparent。在这篇论文中，我们提出了一种新的分析框架，它可以揭示深度眩怯模型学习的隐式特征，并提供了理解和量化这些特征对眩怯预测的贡献的原则性的解释。我们的方法将这些隐式特征分解成可解释的基准，这些基准与semantic attribute的对应关系是Explicitly aligned。我们重新定义了眩怯预测为这些基准之间的权重加权组合，并通过应用我们的框架，我们进行了广泛的分析，包括正面和负面权重的semantics，训练数据和建筑设计的影响，练习的进步性和state-of-the-art深度眩怯模型的共同失败模式。此外，我们还通过各种应用场景来探讨视觉注意力特征，例如人类 autism spectrum disorder 的非典型注意力、情感刺激刺激的注意力和时间的注意力演化。我们的代码公开在 \url{https://github.com/szzexpoi/saliency_analysis}。
</details></li>
</ul>
<hr>
<h2 id="Point-DynRF-Point-based-Dynamic-Radiance-Fields-from-a-Monocular-Video"><a href="#Point-DynRF-Point-based-Dynamic-Radiance-Fields-from-a-Monocular-Video" class="headerlink" title="Point-DynRF: Point-based Dynamic Radiance Fields from a Monocular Video"></a>Point-DynRF: Point-based Dynamic Radiance Fields from a Monocular Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09647">http://arxiv.org/abs/2310.09647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Byeongjun Park, Changick Kim</li>
<li>for: 生成从笔直视频中的新视图</li>
<li>methods: 使用 neural point clouds 和 dynamic radiance fields 来学习全局场景几何信息和渲染过程</li>
<li>results: 在 NVIDIA Dynamic Scenes Dataset 和一些 causally captured monocular video clips 上验证了方法的有效性<details>
<summary>Abstract</summary>
Dynamic radiance fields have emerged as a promising approach for generating novel views from a monocular video. However, previous methods enforce the geometric consistency to dynamic radiance fields only between adjacent input frames, making it difficult to represent the global scene geometry and degenerates at the viewpoint that is spatio-temporally distant from the input camera trajectory. To solve this problem, we introduce point-based dynamic radiance fields (\textbf{Point-DynRF}), a novel framework where the global geometric information and the volume rendering process are trained by neural point clouds and dynamic radiance fields, respectively. Specifically, we reconstruct neural point clouds directly from geometric proxies and optimize both radiance fields and the geometric proxies using our proposed losses, allowing them to complement each other. We validate the effectiveness of our method with experiments on the NVIDIA Dynamic Scenes Dataset and several causally captured monocular video clips.
</details>
<details>
<summary>摘要</summary>
《动态辐射场》技术在生成单视图的新观察角度方面表现出了惊人的前进。然而，先前的方法只在邻近输入帧中保证动态辐射场的几何一致性，使得表示全场景几何和观点远离输入摄像机轨迹的问题变得困难。为解决这个问题，我们提出了点基的动态辐射场（Point-DynRF）框架，其中global scene几何信息和volume渲染过程通过神经点云和动态辐射场进行了培auotrained。具体来说，我们直接从几何代理中重建神经点云，并通过我们提出的损失函数来优化辐射场和几何代理，使其相互补做。我们通过对NVIDIA动态场景集和一些 causally captured的单视图视频剪辑进行实验 validate了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Dimma-Semi-supervised-Low-Light-Image-Enhancement-with-Adaptive-Dimming"><a href="#Dimma-Semi-supervised-Low-Light-Image-Enhancement-with-Adaptive-Dimming" class="headerlink" title="Dimma: Semi-supervised Low Light Image Enhancement with Adaptive Dimming"></a>Dimma: Semi-supervised Low Light Image Enhancement with Adaptive Dimming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09633">http://arxiv.org/abs/2310.09633</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wojciechkoz/dimma">https://github.com/wojciechkoz/dimma</a></li>
<li>paper_authors: Wojciech Kozłowski, Michał Szachniewicz, Michał Stypułkowski, Maciej Zięba</li>
<li>for: 提高低光照图像质量，保持自然颜色</li>
<li>methods: 使用小量图像对数据集进行协同学习，通过混合混合稀释权重网络来模拟不同摄像头下的场景拍摄情况，并通过精度量化器来调整亮度水平</li>
<li>results: 使用只需几个图像对可以达到与完全监督方法相同的竞争水平，并且在某些指标上超越当前状态艺法，几乎与其他方法相当Here’s the explanation in English:</li>
<li>for: The paper aims to enhance low-light images while maintaining their natural colors.</li>
<li>methods: The proposed approach uses a small set of image pairs to replicate scenes captured under extreme lighting conditions using a specific camera. It employs a convolutional mixture density network to generate distorted colors based on illumination differences, and accurately grades the dimming factor for flexibility in adjusting brightness levels. Additionally, the approach uses a conditional UNet architecture to generate images with desired lightness levels based on user input.</li>
<li>results: The proposed approach achieves competitive results compared to fully supervised methods, and surpasses state-of-the-art methods in some metrics when trained on the full dataset.<details>
<summary>Abstract</summary>
Enhancing low-light images while maintaining natural colors is a challenging problem due to camera processing variations and limited access to photos with ground-truth lighting conditions. The latter is a crucial factor for supervised methods that achieve good results on paired datasets but do not handle out-of-domain data well. On the other hand, unsupervised methods, while able to generalize, often yield lower-quality enhancements. To fill this gap, we propose Dimma, a semi-supervised approach that aligns with any camera by utilizing a small set of image pairs to replicate scenes captured under extreme lighting conditions taken by that specific camera. We achieve that by introducing a convolutional mixture density network that generates distorted colors of the scene based on the illumination differences. Additionally, our approach enables accurate grading of the dimming factor, which provides a wide range of control and flexibility in adjusting the brightness levels during the low-light image enhancement process. To further improve the quality of our results, we introduce an architecture based on a conditional UNet. The lightness value provided by the user serves as the conditional input to generate images with the desired lightness. Our approach using only few image pairs achieves competitive results compared to fully supervised methods. Moreover, when trained on the full dataset, our model surpasses state-of-the-art methods in some metrics and closely approaches them in others.
</details>
<details>
<summary>摘要</summary>
提高低光照图像的质量是一个具有挑战性的问题，因为摄像头处理的变化和有限的照明条件图像的数量。后者是重要的因素，因为超级vised方法可以在匹配数据集上达到良好的结果，但是不能处理非预期的数据。相反，无监督方法可以泛化，但是通常会产生较低质量的提高。为了填补这个差距，我们提议了Dimma，一种半监督方法，通过使用特定摄像头拍摄的场景图像的小量对照片来模拟极端照明条件下拍摄的场景。我们通过引入一个 convolutional mixture density network来生成场景图像中的扭曲颜色，基于照明差异。此外，我们的方法可以精确地测量场景图像的暗度因子，提供了较广泛的控制和灵活性来调整低光照图像的亮度水平。为了进一步提高我们的结果质量，我们引入了基于 conditional UNet 的架构。用户输入的亮度值 serving as the conditional input，以生成具有所需亮度的图像。我们的方法使用只需几对照片可以与完全监督方法相比，并且当训练在全 dataset 时，我们的模型超越了当前状态的方法，在一些指标中甚至超越了其他方法，只是在其他指标中有些落后。
</details></li>
</ul>
<hr>
<h2 id="Time-based-Mapping-of-Space-Using-Visual-Motion-Invariants"><a href="#Time-based-Mapping-of-Space-Using-Visual-Motion-Invariants" class="headerlink" title="Time-based Mapping of Space Using Visual Motion Invariants"></a>Time-based Mapping of Space Using Visual Motion Invariants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09632">http://arxiv.org/abs/2310.09632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan D. Yepes, Daniel Raviv</li>
<li>for: 这个论文的目的是提出一种基于视觉动态特征的三维点 clouds的表示方法，以确保形态不变。</li>
<li>methods: 该方法利用非线性的流体量计量器来创建一种新的表示方法，称为“时间清除”（Time-Clearance）和“时间到接触”（Time-to-Contact）。这些 invariants 保持时间不变，使得可以轻松地检测移动点不符合预期的不变性。</li>
<li>results: 作者通过实验和 Unity 模拟来证明这种表示方法的有效性，并表明可以轻松地检测移动点不符合预期的不变性。此外，这种表示方法需要只一个摄像机，并且不需要确定摄像机的运动速度量。此外，该方法适合并行处理。<details>
<summary>Abstract</summary>
This paper focuses on visual motion-based invariants that result in a representation of 3D points in which the stationary environment remains invariant, ensuring shape constancy. This is achieved even as the images undergo constant change due to camera motion. Nonlinear functions of measurable optical flow, which are related to geometric 3D invariants, are utilized to create a novel representation. We refer to the resulting optical flow-based invariants as 'Time-Clearance' and the well-known 'Time-to-Contact' (TTC). Since these invariants remain constant over time, it becomes straightforward to detect moving points that do not adhere to the expected constancy. We present simulations of a camera moving relative to a 3D object, snapshots of its projected images captured by a rectilinearly moving camera, and the object as it appears unchanged in the new domain over time. In addition, Unity-based simulations demonstrate color-coded transformations of a projected 3D scene, illustrating how moving objects can be readily identified. This representation is straightforward, relying on simple optical flow functions. It requires only one camera, and there is no need to determine the magnitude of the camera's velocity vector. Furthermore, the representation is pixel-based, making it suitable for parallel processing.
</details>
<details>
<summary>摘要</summary>
We present simulations of a camera moving relative to a 3D object, snapshots of its projected images captured by a rectilinearly moving camera, and the object as it appears unchanged in the new domain over time. In addition, Unity-based simulations demonstrate color-coded transformations of a projected 3D scene, illustrating how moving objects can be readily identified.This representation is straightforward, relying on simple optical flow functions. It requires only one camera, and there is no need to determine the magnitude of the camera's velocity vector. Furthermore, the representation is pixel-based, making it suitable for parallel processing.
</details></li>
</ul>
<hr>
<h2 id="Real-Time-Traffic-Sign-Detection-A-Case-Study-in-a-Santa-Clara-Suburban-Neighborhood"><a href="#Real-Time-Traffic-Sign-Detection-A-Case-Study-in-a-Santa-Clara-Suburban-Neighborhood" class="headerlink" title="Real-Time Traffic Sign Detection: A Case Study in a Santa Clara Suburban Neighborhood"></a>Real-Time Traffic Sign Detection: A Case Study in a Santa Clara Suburban Neighborhood</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09630">http://arxiv.org/abs/2310.09630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harish Loghashankar, Hieu Nguyen</li>
<li>for: 这项研究旨在开发一个实时交通标识系统，使用YOLOv5架构并在室外社区中进行实时识别交通标识。</li>
<li>methods: 该项目将使用多样化的交通标识图像集进行训练YOLOv5模型，并在适合实时推理的硬件平台上部署模型。</li>
<li>results: 在实验中，该系统在实时摄像头上检测和识别交通标识得分为96%，表明该系统可以提供实时和准确的交通信息，有助于提高道路安全和交通管理，并且可能为自动驾驶研究开辟新的可能性。<details>
<summary>Abstract</summary>
This research project aims to develop a real-time traffic sign detection system using the YOLOv5 architecture and deploy it for efficient traffic sign recognition during a drive in a suburban neighborhood. The project's primary objectives are to train the YOLOv5 model on a diverse dataset of traffic sign images and deploy the model on a suitable hardware platform capable of real-time inference. The project will involve collecting a comprehensive dataset of traffic sign images. By leveraging the trained YOLOv5 model, the system will detect and classify traffic signs from a real-time camera on a dashboard inside a vehicle. The performance of the deployed system will be evaluated based on its accuracy in detecting traffic signs, real-time processing speed, and overall reliability. During a case study in a suburban neighborhood, the system demonstrated a notable 96% accuracy in detecting traffic signs. This research's findings have the potential to improve road safety and traffic management by providing timely and accurate real-time information about traffic signs and can pave the way for further research into autonomous driving.
</details>
<details>
<summary>摘要</summary>
The project involves collecting a comprehensive dataset of traffic sign images, and leveraging the trained YOLOv5 model, the system will detect and classify traffic signs from a real-time camera on a dashboard inside a vehicle. The performance of the deployed system will be evaluated based on its accuracy in detecting traffic signs, real-time processing speed, and overall reliability.During a case study in a suburban neighborhood, the system demonstrated a notable 96% accuracy in detecting traffic signs. The findings of this research have the potential to improve road safety and traffic management by providing timely and accurate real-time information about traffic signs, and can pave the way for further research into autonomous driving.Translation notes:* "suburban neighborhood" is translated as "郊区" (suburban area)* "dashboard" is translated as "车载屏" (car-mounted screen)* "real-time" is translated as "实时" (real-time)* "accuracy" is translated as "准确率" (accuracy)* "processing speed" is translated as "处理速度" (processing speed)* "reliability" is translated as "可靠性" (reliability)Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Detecting-Moving-Objects-Using-a-Novel-Optical-Flow-Based-Range-Independent-Invariant"><a href="#Detecting-Moving-Objects-Using-a-Novel-Optical-Flow-Based-Range-Independent-Invariant" class="headerlink" title="Detecting Moving Objects Using a Novel Optical-Flow-Based Range-Independent Invariant"></a>Detecting Moving Objects Using a Novel Optical-Flow-Based Range-Independent Invariant</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09627">http://arxiv.org/abs/2310.09627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Raviv, Juan D. Yepes, Ayush Gowda</li>
<li>for: 这篇论文主要关注了一种新的移动对象检测方法，该方法可以在摄像机运动时检测移动对象。</li>
<li>methods: 该方法使用了光流基本变换，通过这种变换可以生成一个不依赖于时间点播、点云范围和摄像机速度的兼容2D不变图像输出。在这个新频谱中，对于3D点 cloud中的点，如果它们与预定的查找图像值不匹配，那么它们就可以被轻松地识别为相对于静止3D环境中的移动对象。该方法不需要了解摄像机的运动方向或速度，也不需要3D点云范围信息。它适合实时并行处理，因此非常实用。</li>
<li>results: 作者通过实验和仿真 validate了新频谱的有效性，并证明其在拥有直线运动的摄像机时的稳定性。这种方法开创了新的移动对象检测方法，同时也为未来在六度自由运动摄像机中的研究提供了基础。<details>
<summary>Abstract</summary>
This paper focuses on a novel approach for detecting moving objects during camera motion. We present an optical-flow-based transformation that yields a consistent 2D invariant image output regardless of time instants, range of points in 3D, and the speed of the camera. In other words, this transformation generates a lookup image that remains invariant despite the changing projection of the 3D scene and camera motion. In the new domain, projections of 3D points that deviate from the values of the predefined lookup image can be clearly identified as moving relative to the stationary 3D environment, making them seamlessly detectable. The method does not require prior knowledge of the direction of motion or speed of the camera, nor does it necessitate 3D point range information. It is well-suited for real-time parallel processing, rendering it highly practical for implementation. We have validated the effectiveness of the new domain through simulations and experiments, demonstrating its robustness in scenarios involving rectilinear camera motion, both in simulations and with real-world data. This approach introduces new ways for moving objects detection during camera motion, and also lays the foundation for future research in the context of moving object detection during six-degrees-of-freedom camera motion.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="JSMoCo-Joint-Coil-Sensitivity-and-Motion-Correction-in-Parallel-MRI-with-a-Self-Calibrating-Score-Based-Diffusion-Model"><a href="#JSMoCo-Joint-Coil-Sensitivity-and-Motion-Correction-in-Parallel-MRI-with-a-Self-Calibrating-Score-Based-Diffusion-Model" class="headerlink" title="JSMoCo: Joint Coil Sensitivity and Motion Correction in Parallel MRI with a Self-Calibrating Score-Based Diffusion Model"></a>JSMoCo: Joint Coil Sensitivity and Motion Correction in Parallel MRI with a Self-Calibrating Score-Based Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09625">http://arxiv.org/abs/2310.09625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lixuan Chen, Xuanyu Tian, Jiangjie Wu, Ruimin Feng, Guoyan Lao, Yuyao Zhang, Hongjiang Wei</li>
<li>for:  correction of motion artifacts in MRI reconstruction</li>
<li>methods:  joint estimation of motion parameters and coil sensitivity maps using score-based diffusion models and Gibbs sampler</li>
<li>results:  high-quality MRI image reconstruction from sparsely-sampled k-space data, even in the presence of motion<details>
<summary>Abstract</summary>
Magnetic Resonance Imaging (MRI) stands as a powerful modality in clinical diagnosis. However, it is known that MRI faces challenges such as long acquisition time and vulnerability to motion-induced artifacts. Despite the success of many existing motion correction algorithms, there has been limited research focused on correcting motion artifacts on the estimated coil sensitivity maps for fast MRI reconstruction. Existing methods might suffer from severe performance degradation due to error propagation resulting from the inaccurate coil sensitivity maps estimation. In this work, we propose to jointly estimate the motion parameters and coil sensitivity maps for under-sampled MRI reconstruction, referred to as JSMoCo. However, joint estimation of motion parameters and coil sensitivities results in a highly ill-posed inverse problem due to an increased number of unknowns. To address this, we introduce score-based diffusion models as powerful priors and leverage the MRI physical principles to efficiently constrain the solution space for this optimization problem. Specifically, we parameterize the rigid motion as three trainable variables and model coil sensitivity maps as polynomial functions. Leveraging the physical knowledge, we then employ Gibbs sampler for joint estimation, ensuring system consistency between sensitivity maps and desired images, avoiding error propagation from pre-estimated sensitivity maps to the reconstructed images. We conduct comprehensive experiments to evaluate the performance of JSMoCo on the fastMRI dataset. The results show that our method is capable of reconstructing high-quality MRI images from sparsely-sampled k-space data, even affected by motion. It achieves this by accurately estimating both motion parameters and coil sensitivities, effectively mitigating motion-related challenges during MRI reconstruction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-Hierarchical-Features-with-Joint-Latent-Space-Energy-Based-Prior"><a href="#Learning-Hierarchical-Features-with-Joint-Latent-Space-Energy-Based-Prior" class="headerlink" title="Learning Hierarchical Features with Joint Latent Space Energy-Based Prior"></a>Learning Hierarchical Features with Joint Latent Space Energy-Based Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09604">http://arxiv.org/abs/2310.09604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiali Cui, Ying Nian Wu, Tian Han</li>
<li>for: 学习层次表示的基本问题</li>
<li>methods: 提议使用共同幽会空间EBM前模型和多层幽会变量</li>
<li>results: 实验表明该模型能有效地捕捉层次表示和模型数据分布<details>
<summary>Abstract</summary>
This paper studies the fundamental problem of multi-layer generator models in learning hierarchical representations. The multi-layer generator model that consists of multiple layers of latent variables organized in a top-down architecture tends to learn multiple levels of data abstraction. However, such multi-layer latent variables are typically parameterized to be Gaussian, which can be less informative in capturing complex abstractions, resulting in limited success in hierarchical representation learning. On the other hand, the energy-based (EBM) prior is known to be expressive in capturing the data regularities, but it often lacks the hierarchical structure to capture different levels of hierarchical representations. In this paper, we propose a joint latent space EBM prior model with multi-layer latent variables for effective hierarchical representation learning. We develop a variational joint learning scheme that seamlessly integrates an inference model for efficient inference. Our experiments demonstrate that the proposed joint EBM prior is effective and expressive in capturing hierarchical representations and modelling data distribution.
</details>
<details>
<summary>摘要</summary>
To address this issue, the authors propose a joint latent space EBM prior model with multi-layer latent variables for effective hierarchical representation learning. They develop a variational joint learning scheme that seamlessly integrates an inference model for efficient inference. The authors' experiments demonstrate that the proposed joint EBM prior is effective and expressive in capturing hierarchical representations and modeling data distribution.Translation notes:* "multi-layer generator models" becomes "多层生成器模型" (duō zhì chǎng jī mó delè)* "latent variables" becomes "隐藏变量" (yǐn zhǐ biàn yòu)* "Gaussian" becomes "高矮分布" (gāo ài fān bù)* "energy-based" becomes "能量基于" (néng liàng jī yǔ)* "hierarchical representations" becomes "层次表示" (céng zhì bǎo xiǎng)* "data distribution" becomes "数据分布" (shù jiào fān bù)
</details></li>
</ul>
<hr>
<h2 id="B-Spine-Learning-B-Spline-Curve-Representation-for-Robust-and-Interpretable-Spinal-Curvature-Estimation"><a href="#B-Spine-Learning-B-Spline-Curve-Representation-for-Robust-and-Interpretable-Spinal-Curvature-Estimation" class="headerlink" title="B-Spine: Learning B-Spline Curve Representation for Robust and Interpretable Spinal Curvature Estimation"></a>B-Spine: Learning B-Spline Curve Representation for Robust and Interpretable Spinal Curvature Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09603">http://arxiv.org/abs/2310.09603</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whao22/B-Spine">https://github.com/whao22/B-Spine</a></li>
<li>paper_authors: Hao Wang, Qiang Song, Ruofeng Yin, Rui Ma, Yizhou Yu, Yi Chang<br>for:* 这paper是为了提出一种robust和可 interpret的spinal curvature estimation方法。methods:* 该方法使用了一种深度学习pipeline，包括SegRefine网络和B-spline预测模型，以便从低质量X射线图像中提取spine curvature。results:* 与其他代表性和State-of-the-Art学习基于方法进行Quantitative和Qualitative比较后，该方法在公共AASCE2019数据集和我们新提出的CJUH-JLU数据集上表现出了superior的性能，demonstrating its robustness and interpretability for spinal curvature estimation.<details>
<summary>Abstract</summary>
Spinal curvature estimation is important to the diagnosis and treatment of the scoliosis. Existing methods face several issues such as the need of expensive annotations on the vertebral landmarks and being sensitive to the image quality. It is challenging to achieve robust estimation and obtain interpretable results, especially for low-quality images which are blurry and hazy. In this paper, we propose B-Spine, a novel deep learning pipeline to learn B-spline curve representation of the spine and estimate the Cobb angles for spinal curvature estimation from low-quality X-ray images. Given a low-quality input, a novel SegRefine network which employs the unpaired image-to-image translation is proposed to generate a high quality spine mask from the initial segmentation result. Next, a novel mask-based B-spline prediction model is proposed to predict the B-spline curve for the spine centerline. Finally, the Cobb angles are estimated by a hybrid approach which combines the curve slope analysis and a curve-based regression model. We conduct quantitative and qualitative comparisons with the representative and SOTA learning-based methods on the public AASCE2019 dataset and our new proposed CJUH-JLU dataset which contains more challenging low-quality images. The superior performance on both datasets shows our method can achieve both robustness and interpretability for spinal curvature estimation.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language English Simplified ChineseSpinal curvature estimation is important for the diagnosis and treatment of scoliosis. Existing methods have several issues, such as the need for expensive annotations on vertebral landmarks and being sensitive to image quality. It is challenging to achieve robust estimation and obtain interpretable results, especially for low-quality images that are blurry and hazy. In this paper, we propose B-Spine, a novel deep learning pipeline to learn B-spline curve representation of the spine and estimate the Cobb angles for spinal curvature estimation from low-quality X-ray images. Given a low-quality input, a novel SegRefine network which employs unpaired image-to-image translation is proposed to generate a high-quality spine mask from the initial segmentation result. Next, a novel mask-based B-spline prediction model is proposed to predict the B-spline curve for the spine centerline. Finally, the Cobb angles are estimated by a hybrid approach which combines curve slope analysis and a curve-based regression model. We conduct quantitative and qualitative comparisons with representative and SOTA learning-based methods on the public AASCE2019 dataset and our new proposed CJUH-JLU dataset, which contains more challenging low-quality images. The superior performance on both datasets shows that our method can achieve both robustness and interpretability for spinal curvature estimation.
</details></li>
</ul>
<hr>
<h2 id="Hawkeye-A-PyTorch-based-Library-for-Fine-Grained-Image-Recognition-with-Deep-Learning"><a href="#Hawkeye-A-PyTorch-based-Library-for-Fine-Grained-Image-Recognition-with-Deep-Learning" class="headerlink" title="Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with Deep Learning"></a>Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09600">http://arxiv.org/abs/2310.09600</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hawkeye-finegrained/hawkeye">https://github.com/hawkeye-finegrained/hawkeye</a></li>
<li>paper_authors: Jiabei He, Yang Shen, Xiu-Shen Wei, Ye Wu</li>
<li>for: 这份研究是为了提供一个开源的 PyTorch 基础库，用于 Fine-Grained Image Recognition (FGIR) 任务。</li>
<li>methods: 这个库使用了深度学习的方法，并且具有 Modular 架构，以提高代码质量和人类可读配置。它还包含了 16 种现有的精细方法，覆盖 6 种不同的 paradigm，允许用户尝试不同的方法来解决 FGIR 任务。</li>
<li>results: 根据 authors 的声明，这个库是首个以 PyTorch 为基础的开源库，并且提供了一个全面的解决方案 для FGIR 任务。<details>
<summary>Abstract</summary>
Fine-Grained Image Recognition (FGIR) is a fundamental and challenging task in computer vision and multimedia that plays a crucial role in Intellectual Economy and Industrial Internet applications. However, the absence of a unified open-source software library covering various paradigms in FGIR poses a significant challenge for researchers and practitioners in the field. To address this gap, we present Hawkeye, a PyTorch-based library for FGIR with deep learning. Hawkeye is designed with a modular architecture, emphasizing high-quality code and human-readable configuration, providing a comprehensive solution for FGIR tasks. In Hawkeye, we have implemented 16 state-of-the-art fine-grained methods, covering 6 different paradigms, enabling users to explore various approaches for FGIR. To the best of our knowledge, Hawkeye represents the first open-source PyTorch-based library dedicated to FGIR. It is publicly available at https://github.com/Hawkeye-FineGrained/Hawkeye/, providing researchers and practitioners with a powerful tool to advance their research and development in the field of FGIR.
</details>
<details>
<summary>摘要</summary>
fine-grained 图像识别（FGIR）是计算机视觉和多媒体领域的基础和挑战性任务，对知识经济和工业互联网应用具有重要的作用。然而，无一个统一的开源软件库，覆盖了不同的FGIR Paradigma，对研究人员和实践者们带来了很大的挑战。为了解决这个问题，我们提出了Hawkeye，一个基于PyTorch的FGIR库。Hawkeye采用了模块化的架构，强调高质量的代码和人类可读的配置，为FGIR任务提供了全面的解决方案。在Hawkeye中，我们实现了16种当前顶尖的细化图像方法，覆盖了6个不同的Paradigma，使用户可以探索不同的FGIR方法。据我们所知，Hawkeye是首个基于PyTorch的开源FGIR库，可以在https://github.com/Hawkeye-FineGrained/Hawkeye/上获取。这将为研究人员和实践者们提供一个强大的工具，以推动FGIR领域的研究和开发。
</details></li>
</ul>
<hr>
<h2 id="Learning-Unified-Representations-for-Multi-Resolution-Face-Recognition"><a href="#Learning-Unified-Representations-for-Multi-Resolution-Face-Recognition" class="headerlink" title="Learning Unified Representations for Multi-Resolution Face Recognition"></a>Learning Unified Representations for Multi-Resolution Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09563">http://arxiv.org/abs/2310.09563</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stevensmith2000/btnet">https://github.com/stevensmith2000/btnet</a></li>
<li>paper_authors: Hulingxiao He, Wu Yuan, Yidian Huang, Shilong Zhao, Wen Yuan, Hanqing Li</li>
<li>for: 提高多分辨率脸Recognizer的表示学习方法</li>
<li>methods: 使用Branch-to-Trunk网络(BTNet)，包括一个统一Encoder（TNet）和多个分辨率Adapter（BNets），输入刚好与输出匹配，提高了微辨率脸的可识别度</li>
<li>results: 实验表明，BTNet可以在面Recognition benchmark上达到优秀表现，具有较少计算量和参数存储，并在QMUL-SurvFace 1: N face identification任务上创造新的状态机制。代码可以在<a target="_blank" rel="noopener" href="https://github.com/StevenSmith2000/BTNet%E4%B8%8A%E8%8E%B7%E5%8F%96">https://github.com/StevenSmith2000/BTNet上获取</a><details>
<summary>Abstract</summary>
In this work, we propose Branch-to-Trunk network (BTNet), a representation learning method for multi-resolution face recognition. It consists of a trunk network (TNet), namely a unified encoder, and multiple branch networks (BNets), namely resolution adapters. As per the input, a resolution-specific BNet is used and the output are implanted as feature maps in the feature pyramid of TNet, at a layer with the same resolution. The discriminability of tiny faces is significantly improved, as the interpolation error introduced by rescaling, especially up-sampling, is mitigated on the inputs. With branch distillation and backward-compatible training, BTNet transfers discriminative high-resolution information to multiple branches while guaranteeing representation compatibility. Our experiments demonstrate strong performance on face recognition benchmarks, both for multi-resolution identity matching and feature aggregation, with much less computation amount and parameter storage. We establish new state-of-the-art on the challenging QMUL-SurvFace 1: N face identification task. Our code is available at https://github.com/StevenSmith2000/BTNet.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们提出了分支到主干网络（BTNet），一种多resolution face recognition的表示学习方法。它包括一个主干网络（TNet），即统一编码器，以及多个分支网络（BNets），即分解器。根据输入，使用resolution-specific BNet，并将输出作为特征图层在TNet的特征峰中进行嵌入。这 mitigates the interpolation error introduced by rescaling, especially up-sampling, and significantly improves the discriminability of tiny faces. 通过分支涂抹和回传compatible训练，BTNet可以将高分辨率的特征信息传递给多个分支，同时保证表示相容性。我们的实验表明BTNet在多resolution identity matching和特征聚合任务上显示出了强大表现，减少了计算量和参数存储量。我们在QMUL-SurvFace 1: N face identification任务上创造了新的状态码，代码可以在https://github.com/StevenSmith2000/BTNet中获取。
</details></li>
</ul>
<hr>
<h2 id="Scene-Text-Recognition-Models-Explainability-Using-Local-Features"><a href="#Scene-Text-Recognition-Models-Explainability-Using-Local-Features" class="headerlink" title="Scene Text Recognition Models Explainability Using Local Features"></a>Scene Text Recognition Models Explainability Using Local Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09549">http://arxiv.org/abs/2310.09549</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/markytools/strexp">https://github.com/markytools/strexp</a></li>
<li>paper_authors: Mark Vincent Ty, Rowel Atienza</li>
<li>for: 这个论文主要研究的是Scene Text Recognition（STR）透明性（XAI），即如何使人们能够理解模型的预测结果的原因。</li>
<li>methods: 这篇论文使用了数据解释框架，即归因基本方法，来解释深度学习模型中的输入数据。然而，在STR中，这些方法仅仅能够提供全局性的解释，不能够准确地解释输入数据中的每个字符的预测结果。为了解决这个问题，这篇论文提出了一种新的方法，即STRExp，可以考虑本地解释，即每个字符预测结果的解释。</li>
<li>results: 这篇论文对不同的STR模型和数据集进行了比较，并评估了不同的归因基本方法的效果。结果表明，STRExp可以提供更加精准和有用的解释，而且可以在不同的STR模型和数据集上进行广泛的应用。<details>
<summary>Abstract</summary>
Explainable AI (XAI) is the study on how humans can be able to understand the cause of a model's prediction. In this work, the problem of interest is Scene Text Recognition (STR) Explainability, using XAI to understand the cause of an STR model's prediction. Recent XAI literatures on STR only provide a simple analysis and do not fully explore other XAI methods. In this study, we specifically work on data explainability frameworks, called attribution-based methods, that explain the important parts of an input data in deep learning models. However, integrating them into STR produces inconsistent and ineffective explanations, because they only explain the model in the global context. To solve this problem, we propose a new method, STRExp, to take into consideration the local explanations, i.e. the individual character prediction explanations. This is then benchmarked across different attribution-based methods on different STR datasets and evaluated across different STR models.
</details>
<details>
<summary>摘要</summary>
什么是可解释AI（XAI）？XAI是研究如何让人们理解模型预测的原因的学科。在这项工作中，我们的问题关注点是场景文本识别（STR）可解释，使用XAI来理解STR模型的预测。现有XAI литера图书籍中只提供了简单的分析，没有充分探讨其他XAI方法。在这项研究中，我们专门关注深度学习模型中的数据解释框架，即归因基本方法，可以解释输入数据中重要的部分。但是，将其集成到STR中会导致不一致和不效的解释，因为它们只能解释模型在全局上。为解决这个问题，我们提出了一种新方法，STRExp，可以考虑本地解释，即个体字符预测解释。这种方法然后在不同的归因基本方法和不同的STR数据集上进行了比较。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-the-Sim-to-Real-Gap-in-Cloth-Manipulation"><a href="#Benchmarking-the-Sim-to-Real-Gap-in-Cloth-Manipulation" class="headerlink" title="Benchmarking the Sim-to-Real Gap in Cloth Manipulation"></a>Benchmarking the Sim-to-Real Gap in Cloth Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09543">http://arxiv.org/abs/2310.09543</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Blanco-Mulero, Oriol Barbany, Gokhan Alcan, Adrià Colomé, Carme Torras, Ville Kyrki</li>
<li>for: 这篇论文旨在评估现实 físic engine 是如何帮助学习柔体物体的扭曲和位移的。</li>
<li>methods: 这篇论文使用了四种流行的柔体物体模拟器：MuJoCo、Bullet、Flex 和 SOFA，并对它们进行评估。</li>
<li>results: 论文提供了一个开源的测试集，用于评估这些模拟器的实际准确性、计算时间和稳定性。<details>
<summary>Abstract</summary>
Realistic physics engines play a crucial role for learning to manipulate deformable objects such as garments in simulation. By doing so, researchers can circumvent challenges such as sensing the deformation of the object in the real-world. In spite of the extensive use of simulations for this task, few works have evaluated the reality gap between deformable object simulators and real-world data. We present a benchmark dataset to evaluate the sim-to-real gap in cloth manipulation. The dataset is collected by performing a dynamic cloth manipulation task involving contact with a rigid table. We use the dataset to evaluate the reality gap, computational time, and simulation stability of four popular deformable object simulators: MuJoCo, Bullet, Flex, and SOFA. Additionally, we discuss the benefits and drawbacks of each simulator. The benchmark dataset is open-source. Supplementary material, videos, and code, can be found at https://sites.google.com/view/cloth-sim2real-benchmark.
</details>
<details>
<summary>摘要</summary>
现实 física 引擎在学习处理可变形 объек 的 simulate 中发挥关键作用。通过这样做，研究人员可以远离实际世界中感知对象的变形的挑战。尽管对这种任务的 simulate 广泛使用，但有少数作品评估了 sim-to-real 间的差距。我们提供了一个标准化数据集来评估 cloth  manipulate 中的 sim-to-real 差距。数据集是通过对固定桌子进行动态 cloth  manipulate 任务来收集的。我们使用该数据集来评估 simulator 的 reality gap，计算时间以及模拟稳定性。此外，我们还讨论了每个 simulator 的优缺点。标准化数据集开源，补充材料、视频和代码可以在https://sites.google.com/view/cloth-sim2real-benchmark 找到。
</details></li>
</ul>
<hr>
<h2 id="Towards-End-to-End-Unsupervised-Saliency-Detection-with-Self-Supervised-Top-Down-Context"><a href="#Towards-End-to-End-Unsupervised-Saliency-Detection-with-Self-Supervised-Top-Down-Context" class="headerlink" title="Towards End-to-End Unsupervised Saliency Detection with Self-Supervised Top-Down Context"></a>Towards End-to-End Unsupervised Saliency Detection with Self-Supervised Top-Down Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09533">http://arxiv.org/abs/2310.09533</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yicheng Song, Shuyong Gao, Haozhe Xing, Yiting Cheng, Yan Wang, Wenqiang Zhang</li>
<li>for: 本研究旨在提高无监督聚合物 objet detection 的训练效率，并且可以 mines 深度特征中的rich semantic信息。</li>
<li>methods: 我们提出了一种自动supervised end-to-end salient object detection框架，通过上述的top-downcontext来学习最有助于性的分割指导。</li>
<li>results: 我们的方法在 benchmark 数据集上进行了广泛的实验，并证明了与最近的终端方法和多stage方法相比，我们的方法可以达到最高的性能。<details>
<summary>Abstract</summary>
Unsupervised salient object detection aims to detect salient objects without using supervision signals eliminating the tedious task of manually labeling salient objects. To improve training efficiency, end-to-end methods for USOD have been proposed as a promising alternative. However, current solutions rely heavily on noisy handcraft labels and fail to mine rich semantic information from deep features. In this paper, we propose a self-supervised end-to-end salient object detection framework via top-down context. Specifically, motivated by contrastive learning, we exploit the self-localization from the deepest feature to construct the location maps which are then leveraged to learn the most instructive segmentation guidance. Further considering the lack of detailed information in deepest features, we exploit the detail-boosting refiner module to enrich the location labels with details. Moreover, we observe that due to lack of supervision, current unsupervised saliency models tend to detect non-salient objects that are salient in some other samples of corresponding scenarios. To address this widespread issue, we design a novel Unsupervised Non-Salient Suppression (UNSS) method developing the ability to ignore non-salient objects. Extensive experiments on benchmark datasets demonstrate that our method achieves leading performance among the recent end-to-end methods and most of the multi-stage solutions. The code is available.
</details>
<details>
<summary>摘要</summary>
<<SYS>>这是一个使用简化中文的文本：不监督焦点检测目标检测焦点物件的存在，而不需要手动标注焦点物件。为了提高训练效率，终端方法 для USOD 已经被提议为可靠的替代方案。然而，目前的解决方案将重要的 semantic information 从深度特征中挖掘出来，导致训练效率低下。在这篇文章中，我们提出一个自动监督终端焦点检测框架，通过上下文的对应来学习焦点检测。具体来说，我们灵感自适应学习，从深度特征中找出最有价的位置对，然后将其用于学习最有价的分割引导。此外，因为深度特征中缺乏细节信息，我们运用细节增强修正模组来补充位置标签中的细节信息。此外，我们发现现有的不监督焦点模型往往对于某些相似的场景中的非焦点物件进行检测，这是一个广泛的问题。为了解决这个问题，我们提出了一个名为Unsupervised Non-Salient Suppression（UNSS）的新方法，可以将非焦点物件忽略掉。实验结果显示，我们的方法在最近的终端方法和多阶段解决方案中具有领先的表现。代码可以在网上获取。
</details></li>
</ul>
<hr>
<h2 id="TS-ENAS-Two-Stage-Evolution-for-Cell-based-Network-Architecture-Search"><a href="#TS-ENAS-Two-Stage-Evolution-for-Cell-based-Network-Architecture-Search" class="headerlink" title="TS-ENAS:Two-Stage Evolution for Cell-based Network Architecture Search"></a>TS-ENAS:Two-Stage Evolution for Cell-based Network Architecture Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09525">http://arxiv.org/abs/2310.09525</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Zou, Shenghong Wu, Yizhang Xia, Weiwei Jiang, Zeping Wu, Jinhua Zheng</li>
<li>for: 本研究提出了一种Two-Stage Evolution for cell-based Network Architecture Search（TS-ENAS）算法，用于自动设计神经网络结构。</li>
<li>methods: 该算法使用一个一阶搜索和一个二阶搜索两个阶段来搜索神经网络结构。在第一阶段，使用堆栈Cell进行搜索，以减少搜索的复杂性。在第二阶段，对这些Cell进行调整。</li>
<li>results: 在四个图像分类 dataset（Fashion-MNIST、CIFAR10、CIFAR100和ImageNet）上进行了广泛的测试和比较，并与22种现有的算法进行了比较，包括手动设计的网络和NAS网络。结果表明，TS-ENAS可以更有效地找到与其他算法相对性能的神经网络结构。<details>
<summary>Abstract</summary>
Neural network architecture search provides a solution to the automatic design of network structures. However, it is difficult to search the whole network architecture directly. Although using stacked cells to search neural network architectures is an effective way to reduce the complexity of searching, these methods do not able find the global optimal neural network structure since the number of layers, cells and connection methods is fixed. In this paper, we propose a Two-Stage Evolution for cell-based Network Architecture Search(TS-ENAS), including one-stage searching based on stacked cells and second-stage adjusting these cells. In our algorithm, a new cell-based search space and an effective two-stage encoding method are designed to represent cells and neural network structures. In addition, a cell-based weight inheritance strategy is designed to initialize the weight of the network, which significantly reduces the running time of the algorithm. The proposed methods are extensively tested and compared on four image classification dataset, Fashion-MNIST, CIFAR10, CIFAR100 and ImageNet and compared with 22 state-of-the-art algorithms including hand-designed networks and NAS networks. The experimental results show that TS-ENAS can more effectively find the neural network architecture with comparative performance.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:神经网络结构搜索提供了自动设计网络结构的解决方案。然而，直接搜索整个网络结构是困难的。尽管使用堆式细胞来搜索神经网络结构是有效的方法来减少搜索的复杂性，但这些方法无法找到全球优化的神经网络结构，因为层数、细胞数和连接方法的数量是固定的。在这篇论文中，我们提出了一种两个阶段演化的细胞基于网络 architecture搜索算法（TS-ENAS），包括一个阶段是基于堆式细胞的搜索，以及第二阶段是调整这些细胞。在我们的算法中，我们设计了一个新的细胞基于搜索空间和一种有效的两阶段编码方法来表示细胞和神经网络结构。此外，我们还设计了基于细胞的初始化策略来初始化网络的权重，这有效减少了算法的运行时间。我们在四个图像分类数据集（Fashion-MNIST、CIFAR10、CIFAR100和ImageNet）进行了广泛的测试和比较，与22种现有的算法（包括手动设计的网络和NAS网络）进行了比较。实验结果表明，TS-ENAS可以更有效地找到与其他方法相当的神经网络结构。
</details></li>
</ul>
<hr>
<h2 id="OBSUM-An-object-based-spatial-unmixing-model-for-spatiotemporal-fusion-of-remote-sensing-images"><a href="#OBSUM-An-object-based-spatial-unmixing-model-for-spatiotemporal-fusion-of-remote-sensing-images" class="headerlink" title="OBSUM: An object-based spatial unmixing model for spatiotemporal fusion of remote sensing images"></a>OBSUM: An object-based spatial unmixing model for spatiotemporal fusion of remote sensing images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09517">http://arxiv.org/abs/2310.09517</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/houcaiguo/obsum-code">https://github.com/houcaiguo/obsum-code</a></li>
<li>paper_authors: Houcai Guo, Dingqi Ye, Lorenzo Bruzzone<br>for:这个论文旨在提高遥感图像的空间和时间分辨率，以便进行时间序列分析。methods:这个研究提出了一种基于物体分析和空间分解的物体基于空间混合模型（OBSUM），以解决当前遥感时间序列融合方法中的两个重要问题。OBSUM包括一个预处理步骤和三个融合步骤，即物体水平减混、物体水平偏差补偿和像素水平偏差补偿。results:对比五种代表性的遥感时间序列融合方法，OBSUM在准确指标和视觉效果上表现出色，并且在两个典型的遥感应用中也达到了满意的结果。因此，OBSUM有很大的应用潜力，可以生成高分辨率和准确的时间序列观测数据，以支持多种遥感应用。<details>
<summary>Abstract</summary>
Spatiotemporal fusion aims to improve both the spatial and temporal resolution of remote sensing images, thus facilitating time-series analysis at a fine spatial scale. However, there are several important issues that limit the application of current spatiotemporal fusion methods. First, most spatiotemporal fusion methods are based on pixel-level computation, which neglects the valuable object-level information of the land surface. Moreover, many existing methods cannot accurately retrieve strong temporal changes between the available high-resolution image at base date and the predicted one. This study proposes an Object-Based Spatial Unmixing Model (OBSUM), which incorporates object-based image analysis and spatial unmixing, to overcome the two abovementioned problems. OBSUM consists of one preprocessing step and three fusion steps, i.e., object-level unmixing, object-level residual compensation, and pixel-level residual compensation. OBSUM can be applied using only one fine image at the base date and one coarse image at the prediction date, without the need of a coarse image at the base date. The performance of OBSUM was compared with five representative spatiotemporal fusion methods. The experimental results demonstrated that OBSUM outperformed other methods in terms of both accuracy indices and visual effects over time-series. Furthermore, OBSUM also achieved satisfactory results in two typical remote sensing applications. Therefore, it has great potential to generate accurate and high-resolution time-series observations for supporting various remote sensing applications.
</details>
<details>
<summary>摘要</summary>
<<SYS>>这个研究旨在提高遥感图像的空间和时间解析精度，以便进行时间序列分析，并且解决现有的一些重要问题。首先，大多数的遥感融合方法是基于像素级计算，忽略了地表上的有价值物体信息。其次，许多现有的方法无法精确地回传具有强时间变化的高分辨率图像。本研究提出了一个物体基本分析和空间混合模型（OBSUM），以解决上述问题。OBSUM包括一个预processing步骤和三个融合步骤，即物体水平混合、物体水平剩余补偿和像素水平剩余补偿。OBSUM可以使用仅有一个精细图像的基本日期，并且不需要基本日期的粗糙图像。实验结果显示，OBSUM在精度指标和视觉效果上优于五种代表性的遥感融合方法。此外，OBSUM也在两个典型的遥感应用中取得了满意的结果。因此，它具有高精度时间序列观测的可能性。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Ark-Accruing-and-Reusing-Knowledge-for-Superior-and-Robust-Performance"><a href="#Foundation-Ark-Accruing-and-Reusing-Knowledge-for-Superior-and-Robust-Performance" class="headerlink" title="Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust Performance"></a>Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09507">http://arxiv.org/abs/2310.09507</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jlianglab/ark">https://github.com/jlianglab/ark</a></li>
<li>paper_authors: DongAo Ma, Jiaxuan Pang, Michael B. Gotway, Jianming Liang<br>for: 本研究旨在开发一个可 powerful和Robust的基础模型，通过聚合多个小型公共数据集来实现。methods: 我们提出了 Ark 框架，用于聚合和重用多个不同专家标注的数据集中的知识。results: 我们通过在多种成像任务中进行精度调整、线性检测和性别偏见分析，证明了 Ark 模型在比特aha fully&#x2F;self-supervised baselines和 Google 的专有 CXR-FM 模型之上具有显著的超越性和Robustness。<details>
<summary>Abstract</summary>
Deep learning nowadays offers expert-level and sometimes even super-expert-level performance, but achieving such performance demands massive annotated data for training (e.g., Google's proprietary CXR Foundation Model (CXR-FM) was trained on 821,544 labeled and mostly private chest X-rays (CXRs)). Numerous datasets are publicly available in medical imaging but individually small and heterogeneous in expert labels. We envision a powerful and robust foundation model that can be trained by aggregating numerous small public datasets. To realize this vision, we have developed Ark, a framework that accrues and reuses knowledge from heterogeneous expert annotations in various datasets. As a proof of concept, we have trained two Ark models on 335,484 and 704,363 CXRs, respectively, by merging several datasets including ChestX-ray14, CheXpert, MIMIC-II, and VinDr-CXR, evaluated them on a wide range of imaging tasks covering both classification and segmentation via fine-tuning, linear-probing, and gender-bias analysis, and demonstrated our Ark's superior and robust performance over the SOTA fully/self-supervised baselines and Google's proprietary CXR-FM. This enhanced performance is attributed to our simple yet powerful observation that aggregating numerous public datasets diversifies patient populations and accrues knowledge from diverse experts, yielding unprecedented performance yet saving annotation cost. With all codes and pretrained models released at GitHub.com/JLiangLab/Ark, we hope that Ark exerts an important impact on open science, as accruing and reusing knowledge from expert annotations in public datasets can potentially surpass the performance of proprietary models trained on unusually large data, inspiring many more researchers worldwide to share codes and datasets to build open foundation models, accelerate open science, and democratize deep learning for medical imaging.
</details>
<details>
<summary>摘要</summary>
现在的深度学习技术已经可以达到专家级或者超过专家级的性能，但是获得这样的性能需要巨量的标注数据进行训练（如Google的专有CXR基础模型（CXR-FM）在821544个标注的和大多数私人胸部X射线图像（CXRs）上进行训练）。医疗影像领域有很多公共数据集，但每个数据集都是小型和多样化的专家标注。我们的愿景是建立一个强大和稳定的基础模型，可以通过合并各种小型公共数据集来训练。为了实现这个愿景，我们已经开发了Ark框架，它可以聚合和重用各种各样的专家标注知识。作为证明，我们已经在335484和704363个CXRs上分别训练了两个Ark模型，并通过精细调整、直接检测和性别偏见分析来评估其性能。我们的Ark模型在覆盖各种影像任务，包括分类和分割，并表现出超过当前最佳自动化/自我超vised基线和Google专有CXR-FM的性能。这种提高的性能归因于我们简单 yet 强大的观察，即合并各种公共数据集可以多样化病人人口和收集专家知识，从而实现无 precedent的性能，同时降低标注成本。我们在GitHub上发布了所有代码和预训练模型，我们希望Ark能够对开源科学产生重要影响，因为聚合和重用公共数据集中的专家标注知识可能会超越 propriety模型在非常大数据上的性能，鼓励更多的研究人员在世界各地分享代码和数据集，加速开源科学，和democratize深度学习 для医疗影像领域。
</details></li>
</ul>
<hr>
<h2 id="JM3D-JM3D-LLM-Elevating-3D-Representation-with-Joint-Multi-modal-Cues"><a href="#JM3D-JM3D-LLM-Elevating-3D-Representation-with-Joint-Multi-modal-Cues" class="headerlink" title="JM3D &amp; JM3D-LLM: Elevating 3D Representation with Joint Multi-modal Cues"></a>JM3D &amp; JM3D-LLM: Elevating 3D Representation with Joint Multi-modal Cues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09503">http://arxiv.org/abs/2310.09503</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mr-neko/jm3d">https://github.com/mr-neko/jm3d</a></li>
<li>paper_authors: Jiayi Ji, Haowei Wang, Changli Wu, Yiwei Ma, Xiaoshuai Sun, Rongrong Ji</li>
<li>for: 本研究旨在解决3D表示学中的三大挑战，包括信息损失、缺乏同步和不充分利用细节信息。</li>
<li>methods: 该研究提出了一种全面的JM3D方法，包括多视图图像和层次文本的结构多模式组织器（SMO）和语言理解与视觉表示的共同对齐（JMA）。</li>
<li>results: 研究表明，JM3D-LLM模型在ModelNet40和ScanObjectNN测试集上显示出了superiority，并且JM3D-LLM模型通过有效的微调来结合3D表示和大语言模型。<details>
<summary>Abstract</summary>
The rising importance of 3D representation learning, pivotal in computer vision, autonomous driving, and robotics, is evident. However, a prevailing trend, which straightforwardly resorted to transferring 2D alignment strategies to the 3D domain, encounters three distinct challenges: (1) Information Degradation: This arises from the alignment of 3D data with mere single-view 2D images and generic texts, neglecting the need for multi-view images and detailed subcategory texts. (2) Insufficient Synergy: These strategies align 3D representations to image and text features individually, hampering the overall optimization for 3D models. (3) Underutilization: The fine-grained information inherent in the learned representations is often not fully exploited, indicating a potential loss in detail. To address these issues, we introduce JM3D, a comprehensive approach integrating point cloud, text, and image. Key contributions include the Structured Multimodal Organizer (SMO), enriching vision-language representation with multiple views and hierarchical text, and the Joint Multi-modal Alignment (JMA), combining language understanding with visual representation. Our advanced model, JM3D-LLM, marries 3D representation with large language models via efficient fine-tuning. Evaluations on ModelNet40 and ScanObjectNN establish JM3D's superiority. The superior performance of JM3D-LLM further underscores the effectiveness of our representation transfer approach. Our code and models are available at https://github.com/Mr-Neko/JM3D.
</details>
<details>
<summary>摘要</summary>
随着三维表示学的崛起，在计算机视觉、自动驾驶和 роботиCS中发挥着重要作用。然而，一种流行的趋势是将二维对对策直接应用到三维领域，这种方法存在三个突出的挑战：（1）信息强化：这种方法将三维数据与单个视图二维图像和普通的文本进行对齐，忽略了多视图图像和详细的子类别文本的需求。（2）不足的共同作用：这些策略将三维表示与图像和文本特征进行对齐，阻碍整体优化三维模型。（3）不充分利用：学习的表示中具有细节的信息经常未被完全利用，表明有可能的误差。为了解决这些问题，我们介绍了JM3D，一种全面的方法，它将点云、文本和图像集成起来。JM3D的关键贡献包括多视图文本结构（SMO），它使用多个视图和层次文本来增强视语言表示，以及对语言理解与视觉表示的共同对齐（JMA）。我们的高级模型JM3D-LLM通过有效的微调来结合语言模型和三维表示。我们在ModelNet40和ScanObjectNN上进行了评估，结果表明JM3D的超越性。JM3D-LLM的高性能进一步证明了我们的表示传递方法的有效性。我们的代码和模型可以在https://github.com/Mr-Neko/JM3D中找到。
</details></li>
</ul>
<hr>
<h2 id="Learning-In-between-Imagery-Dynamics-via-Physical-Latent-Spaces"><a href="#Learning-In-between-Imagery-Dynamics-via-Physical-Latent-Spaces" class="headerlink" title="Learning In-between Imagery Dynamics via Physical Latent Spaces"></a>Learning In-between Imagery Dynamics via Physical Latent Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09495">http://arxiv.org/abs/2310.09495</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jihun Han, Yoonsang Lee, Anne Gelb</li>
<li>for: 学习两个图像在连续时间步骤中的下一个图像的动态关系</li>
<li>methods: 利用含有物理模型表示的partial differential equations（PDEs）来估计图像的中间阶段，并保持图像空间相关性</li>
<li>results: 通过数字测试使用地球科学图像数据，证明方法的稳定性和有效性<details>
<summary>Abstract</summary>
We present a framework designed to learn the underlying dynamics between two images observed at consecutive time steps. The complex nature of image data and the lack of temporal information pose significant challenges in capturing the unique evolving patterns. Our proposed method focuses on estimating the intermediary stages of image evolution, allowing for interpretability through latent dynamics while preserving spatial correlations with the image. By incorporating a latent variable that follows a physical model expressed in partial differential equations (PDEs), our approach ensures the interpretability of the learned model and provides insight into corresponding image dynamics. We demonstrate the robustness and effectiveness of our learning framework through a series of numerical tests using geoscientific imagery data.
</details>
<details>
<summary>摘要</summary>
我们提出了一种框架，用于学习两个图像在连续时间步骤中的下面动力。图像数据的复杂性和缺乏时间信息使得捕捉唯一发展模式具有挑战性。我们的提议是估算图像演化过程中的中间阶段，以保持图像空间相关性，并通过潜在动力提供可读性。我们的方法包括一个遵循部分偏微分方程（PDE）的潜在变量，以保证学习模型的可读性并提供相应的图像动力的理解。我们通过对地球科学图像数据进行数值测试，证明了我们的学习框架的稳定性和效果。
</details></li>
</ul>
<hr>
<h2 id="Perception-Reinforcement-Using-Auxiliary-Learning-Feature-Fusion-A-Modified-Yolov8-for-Head-Detection"><a href="#Perception-Reinforcement-Using-Auxiliary-Learning-Feature-Fusion-A-Modified-Yolov8-for-Head-Detection" class="headerlink" title="Perception Reinforcement Using Auxiliary Learning Feature Fusion: A Modified Yolov8 for Head Detection"></a>Perception Reinforcement Using Auxiliary Learning Feature Fusion: A Modified Yolov8 for Head Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09492">http://arxiv.org/abs/2310.09492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiezhou Chen, Guankun Wang, Weixiang Liu, Xiaopin Zhong, Yibin Tian, ZongZe Wu</li>
<li>for: 提高人头检测精度和 robustness</li>
<li>methods: 使用改进版 Yolov8，增加 auxillary 学习特征拟合（ALFF）模块和 Distribution Focal Loss 等技术来提高目标感知和检测精度</li>
<li>results: 实验结果表明我们的方法可以提高人头检测精度和 robustness，并且在不同的背景和照明条件下都有优秀的表现<details>
<summary>Abstract</summary>
Head detection provides distribution information of pedestrian, which is crucial for scene statistical analysis, traffic management, and risk assessment and early warning. However, scene complexity and large-scale variation in the real world make accurate detection more difficult. Therefore, we present a modified Yolov8 which improves head detection performance through reinforcing target perception. An Auxiliary Learning Feature Fusion (ALFF) module comprised of LSTM and convolutional blocks is used as the auxiliary task to help the model perceive targets. In addition, we introduce Noise Calibration into Distribution Focal Loss to facilitate model fitting and improve the accuracy of detection. Considering the requirements of high accuracy and speed for the head detection task, our method is adapted with two kinds of backbone, namely Yolov8n and Yolov8m. The results demonstrate the superior performance of our approach in improving detection accuracy and robustness.
</details>
<details>
<summary>摘要</summary>
《头部检测提供了人行道用户分布信息，这对Scene统计分析、交通管理和风险评估预警都是关键。然而，实际世界中的场景复杂度和大规模变化使得准确检测更加困难。因此，我们提出了一种基于Yolov8的修改方法，通过强化目标感知来提高头部检测性能。我们使用一个名为ALFF（auxiliary learning feature fusion）模块，其包括LSTM和卷积块，作为辅助任务，帮助模型更好地感知目标。此外，我们还引入了降噪约束分布损失，以便提高模型的适应性和准确性。考虑到头部检测任务的高精度和速度要求，我们采用了Yolov8n和Yolov8m两种骨干。结果表明，我们的方法可以提高检测精度和Robustness。》Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Design-Space-of-Diffusion-Autoencoders-for-Face-Morphing"><a href="#Exploring-the-Design-Space-of-Diffusion-Autoencoders-for-Face-Morphing" class="headerlink" title="Exploring the Design Space of Diffusion Autoencoders for Face Morphing"></a>Exploring the Design Space of Diffusion Autoencoders for Face Morphing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09484">http://arxiv.org/abs/2310.09484</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zander Blasingame, Chen Liu</li>
<li>for: 本研究探索了 diffusion autoencoders 创造的 face morph 设计空间，特别是 sampling algorithms、reverse DDIM solver 和 partial sampling through small amounts of added noise 等三个轴。</li>
<li>methods: 本研究使用了 sampling algorithms、reverse DDIM solver 和 partial sampling through small amounts of added noise 等方法。</li>
<li>results: 研究发现，采用不同的 sampling algorithms、reverse DDIM solver 和 partial sampling through small amounts of added noise 可以创造出不同的 face morph。<details>
<summary>Abstract</summary>
Face morphs created by Diffusion Autoencoders are a recent innovation and the design space of such an approach has not been well explored. We explore three axes of the design space, i.e., 1) sampling algorithms, 2) the reverse DDIM solver, and 3) partial sampling through small amounts of added noise.
</details>
<details>
<summary>摘要</summary>
Diffusion Autoencoders 创造的面部变换是最近的创新，这个设计空间的探索尚未充分。我们探索了三个轴，即：1. 采样算法2. 反向 DDIM 解决方案3. 通过小量附加的噪声进行部分采样Here's a breakdown of the translation:1. "Diffusion Autoencoders" (Diffusion Autoencoders) - 散度自适应器2. "创造的面部变换" (face morphs created) - 面部变换 (face morphs)3. "是最近的创新" (is a recent innovation) - 最近的创新 (recent innovation)4. "设计空间" (design space) - 设计空间 (design space)5. "尚未充分" (has not been well explored) - 尚未充分 (has not been well explored)6. "我们探索了三个轴" (we explore three axes) - 我们探索了三个轴 (we explore three axes)7. "即：" (i.e.,) - 即： (i.e.,)8. "采样算法" (sampling algorithms) - 采样算法 (sampling algorithms)9. "反向 DDIM 解决方案" (reverse DDIM solver) - 反向 DDIM 解决方案 (reverse DDIM solver)10. "通过小量附加的噪声进行部分采样" (partial sampling through small amounts of added noise) - 通过小量附加的噪声进行部分采样 (partial sampling through small amounts of added noise)
</details></li>
</ul>
<hr>
<h2 id="MiniGPT-v2-large-language-model-as-a-unified-interface-for-vision-language-multi-task-learning"><a href="#MiniGPT-v2-large-language-model-as-a-unified-interface-for-vision-language-multi-task-learning" class="headerlink" title="MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning"></a>MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09478">http://arxiv.org/abs/2310.09478</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Chen, Deyao Zhu, Xiaoqian Shen, Xiang Li, Zechun Liu, Pengchuan Zhang, Raghuraman Krishnamoorthi, Vikas Chandra, Yunyang Xiong, Mohamed Elhoseiny</li>
<li>for: 这篇论文的目的是建立一个统一的界面，用于完成多种语言领域的应用，包括图像描述、视觉问题回答和视觉基础设定等。</li>
<li>methods: 这篇论文使用了MiniGPT-v2模型，这是一个可以作为多种视觉语言任务的统一界面。它使用唯一识别码来识别不同任务的训练指令，以提高模型对每个任务的学习效率。</li>
<li>results: 实验结果显示，MiniGPT-v2在视觉问题回答和视觉基础设定benchmark上表现强，与其他视觉语言通用模型相比。<details>
<summary>Abstract</summary>
Large language models have shown their remarkable capabilities as a general interface for various language-related applications. Motivated by this, we target to build a unified interface for completing many vision-language tasks including image description, visual question answering, and visual grounding, among others. The challenge is to use a single model for performing diverse vision-language tasks effectively with simple multi-modal instructions. Towards this objective, we introduce MiniGPT-v2, a model that can be treated as a unified interface for better handling various vision-language tasks. We propose using unique identifiers for different tasks when training the model. These identifiers enable our model to better distinguish each task instruction effortlessly and also improve the model learning efficiency for each task. After the three-stage training, the experimental results show that MiniGPT-v2 achieves strong performance on many visual question-answering and visual grounding benchmarks compared to other vision-language generalist models. Our model and codes are available at https://minigpt-v2.github.io/
</details>
<details>
<summary>摘要</summary>
大型语言模型在各种语言相关应用中展示了其权威的能力。这为我们提供了动机，我们想要建立一个统一的界面，以便处理多种视觉语言任务，包括图像描述、视觉问题回答和视觉定位等等。挑战是使用单一模型来进行多种视觉语言任务，并且将其训练为每个任务。为了解决这个问题，我们引入了MiniGPT-v2模型，它可以作为视觉语言任务的统一界面。我们在训练过程中使用对应的唯一识别码，以便让模型更容易识别每个任务的指令，并且提高模型对每个任务的学习效率。经过三阶段训练后，我们的实验结果显示，MiniGPT-v2在许多视觉问题回答和视觉定位benchmark上表现出色，与其他视觉语言通用模型相比。我们的模型和代码可以在https://minigpt-v2.github.io/上取得。
</details></li>
</ul>
<hr>
<h2 id="Plug-and-Play-Feature-Generation-for-Few-Shot-Medical-Image-Classification"><a href="#Plug-and-Play-Feature-Generation-for-Few-Shot-Medical-Image-Classification" class="headerlink" title="Plug-and-Play Feature Generation for Few-Shot Medical Image Classification"></a>Plug-and-Play Feature Generation for Few-Shot Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09471">http://arxiv.org/abs/2310.09471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qianyu Guo, Huifang Du, Xing Jia, Shuyong Gao, Yan Teng, Haofen Wang, Wenqiang Zhang</li>
<li>for: 提高医学图像分类模型的普适性和实用性，使用有限数量的训练数据。</li>
<li>methods: 提出了一种名为MedMFG的灵活和轻量级的插件和撑杆方法，可以生成具有足够特征的类别特征。</li>
<li>results: 在跨域分数标准上对比多个基eline和后处理方法，MedMFG达到了10%以上的性能提升，并且可以轻松地与多种背景和基eline整合。<details>
<summary>Abstract</summary>
Few-shot learning (FSL) presents immense potential in enhancing model generalization and practicality for medical image classification with limited training data; however, it still faces the challenge of severe overfitting in classifier training due to distribution bias caused by the scarce training samples. To address the issue, we propose MedMFG, a flexible and lightweight plug-and-play method designed to generate sufficient class-distinctive features from limited samples. Specifically, MedMFG first re-represents the limited prototypes to assign higher weights for more important information features. Then, the prototypes are variationally generated into abundant effective features. Finally, the generated features and prototypes are together to train a more generalized classifier. Experiments demonstrate that MedMFG outperforms the previous state-of-the-art methods on cross-domain benchmarks involving the transition from natural images to medical images, as well as medical images with different lesions. Notably, our method achieves over 10% performance improvement compared to several baselines. Fusion experiments further validate the adaptability of MedMFG, as it seamlessly integrates into various backbones and baselines, consistently yielding improvements of over 2.9% across all results.
</details>
<details>
<summary>摘要</summary>
几个示例学习（Few-shot learning，FSL）具有极大的潜力提高模型通用性和实用性，尤其是在医疗图像分类中使用有限训练数据。然而，FSL仍然面临分布偏见导致分类器训练过程中严重溢出的问题。为解决这问题，我们提出MedMFG，一种灵活且轻量级的插件式方法，可以生成充足的类别特征从有限样本中。具体来说，MedMFG首先重新表示有限原型，以便将更重要的信息特征赋予更高的权重。然后，原型通过变换生成成为丰富的有效特征。最后，生成的特征和原型一起训练一个更通用的分类器。实验表明，MedMFG在跨领域 benchmark 上比前一些基eline方法提高了10%以上的性能。此外，我们的方法在不同的背景和基eline上进行融合实验， consistently 获得了2.9%以上的提高。
</details></li>
</ul>
<hr>
<h2 id="Towards-More-Accurate-Diffusion-Model-Acceleration-with-A-Timestep-Aligner"><a href="#Towards-More-Accurate-Diffusion-Model-Acceleration-with-A-Timestep-Aligner" class="headerlink" title="Towards More Accurate Diffusion Model Acceleration with A Timestep Aligner"></a>Towards More Accurate Diffusion Model Acceleration with A Timestep Aligner</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09469">http://arxiv.org/abs/2310.09469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengfei Xia, Yujun Shen, Changsong Lei, Yu Zhou, Ran Yi, Deli Zhao, Wenping Wang, Yong-jin Liu</li>
<li>for: 提高Diffusion Model的推理速度，解决现有加速方法的性能下降问题。</li>
<li>methods: 通过视为离散积分过程，找到更加准确的积分方向，以提高推理性能。具体来说，在每个净化步骤中，将原始参数化被取代，并在新的步骤中 conditioning 网络，以使其更加准确地描述真实分布。</li>
<li>results: 广泛的实验表明，我们的插件设计可以高效地训练，并在多种现有加速方法中提高推理性能，特别是当有少量净化步骤时。例如，在使用10个净化步骤的LSUN Bedroom dataset上，我们可以将DDIM的FID从9.65降低到6.07，只需采用我们的方法。代码将公开发布。<details>
<summary>Abstract</summary>
A diffusion model, which is formulated to produce an image using thousands of denoising steps, usually suffers from a slow inference speed. Existing acceleration algorithms simplify the sampling by skipping most steps yet exhibit considerable performance degradation. By viewing the generation of diffusion models as a discretized integrating process, we argue that the quality drop is partly caused by applying an inaccurate integral direction to a timestep interval. To rectify this issue, we propose a timestep aligner that helps find a more accurate integral direction for a particular interval at the minimum cost. Specifically, at each denoising step, we replace the original parameterization by conditioning the network on a new timestep, which is obtained by aligning the sampling distribution to the real distribution. Extensive experiments show that our plug-in design can be trained efficiently and boost the inference performance of various state-of-the-art acceleration methods, especially when there are few denoising steps. For example, when using 10 denoising steps on the popular LSUN Bedroom dataset, we improve the FID of DDIM from 9.65 to 6.07, simply by adopting our method for a more appropriate set of timesteps. Code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
一种扩散模型，通过千次减噪步骤生成图像，通常受到慢速推理速度的限制。现有的加速算法简化抽取步骤，但显示出较大的性能下降。我们认为，生成扩散模型的过程可 viewed为离散 интегрирование过程，因此，生成图像质量下降的一部分原因是应用不正确的积分方向。为了解决这个问题，我们提议一种时间步骤对齐器，帮助找到更加准确的积分方向，最小化成本。具体来说，在每次减噪步骤中，我们将原始参数化替换为根据新的时间步骤 conditioning 网络。我们进行了广泛的实验，发现我们的插件设计可以高效地训练，并提高各种现有加速方法的推理性能，特别是当有少量减噪步骤时。例如，在使用10个减噪步骤的LSUN床间 dataset上，我们可以通过采用我们的方法，从9.65提高FID到6.07。我们将代码公开。
</details></li>
</ul>
<hr>
<h2 id="MAC-ModAlity-Calibration-for-Object-Detection"><a href="#MAC-ModAlity-Calibration-for-Object-Detection" class="headerlink" title="MAC: ModAlity Calibration for Object Detection"></a>MAC: ModAlity Calibration for Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09461">http://arxiv.org/abs/2310.09461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yutian Lei, Jun Liu, Dong Huang</li>
<li>for: 本研究旨在开发一种能够快速和高效地将RGB输入模式转换为非RGB输入模式的方法，以便在不同的输入模式下进行物体检测。</li>
<li>methods: 本研究提出了一种名为ModAlity Calibration（MAC）的灵活管道，用于协调目标输入模式和源输入模式之间的差异。具体来说，我们在目标输入模式上额外添加了一个小准备模块，并对这个模块进行MAC训练技术的应用，以便在无需100%手动标注的情况下，使目标输入模式模型达到与基eline模型相同或更好的表现。</li>
<li>results: 我们通过对WiFi输入模式、Lidar输入模式和热成像输入模式等不同输入模式的模型进行组合，并将这些模型与预训练的RGB输入模式模型进行拟合，证明了MAC的效iveness。<details>
<summary>Abstract</summary>
The flourishing success of Deep Neural Networks(DNNs) on RGB-input perception tasks has opened unbounded possibilities for non-RGB-input perception tasks, such as object detection from wireless signals, lidar scans, and infrared images. Compared to the matured development pipeline of RGB-input (source modality) models, developing non-RGB-input (target-modality) models from scratch poses excessive challenges in the modality-specific network design/training tricks and labor in the target-modality annotation. In this paper, we propose ModAlity Calibration (MAC), an efficient pipeline for calibrating target-modality inputs to the DNN object detection models developed on the RGB (source) modality. We compose a target-modality-input model by adding a small calibrator module ahead of a source-modality model and introduce MAC training techniques to impose dense supervision on the calibrator. By leveraging (1) prior knowledge synthesized from the source-modality model and (2) paired {target, source} data with zero manual annotations, our target-modality models reach comparable or better metrics than baseline models that require 100% manual annotations. We demonstrate the effectiveness of MAC by composing the WiFi-input, Lidar-input, and Thermal-Infrared-input models upon the pre-trained RGB-input models respectively.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在RGB输入感知任务上的繁荣成功打开了非RGB输入感知任务的无尽可能性，如从无线电信号、激光扫描和红外图像中的对象检测。相比于已经成熟的RGB输入（源模式）模型的开发管线，开发非RGB输入（目标模式）模型从零开始带来了过度的挑战，包括特性化网络设计/训练技巧和目标模式注解的劳动。在这篇论文中，我们提出了模态均衡（MAC）管线，用于均衡目标模式输入到基于RGB模式（源模式）的对象检测模型中。我们将目标模式输入模型的前置加一小均衡模块，并引入MAC训练技术，以在均衡模块中强制对均衡模块进行密集监督。通过利用（1）源模式模型中的优先知识和（2）paired {target, source} 数据集，我们的目标模式模型可以达到与基eline模型相同或更好的 metric，而不需要100%的手动注解。我们通过将WiFi输入、激光输入和红外温度输入模型分别建立在pre-trained RGB输入模型上，来证明MAC的效果。
</details></li>
</ul>
<hr>
<h2 id="PaintHuman-Towards-High-fidelity-Text-to-3D-Human-Texturing-via-Denoised-Score-Distillation"><a href="#PaintHuman-Towards-High-fidelity-Text-to-3D-Human-Texturing-via-Denoised-Score-Distillation" class="headerlink" title="PaintHuman: Towards High-fidelity Text-to-3D Human Texturing via Denoised Score Distillation"></a>PaintHuman: Towards High-fidelity Text-to-3D Human Texturing via Denoised Score Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09458">http://arxiv.org/abs/2310.09458</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianhui Yu, Hao Zhu, Liming Jiang, Chen Change Loy, Weidong Cai, Wayne Wu</li>
<li>for: 本研究旨在解决 zero-shot text-to-3D 人体生成中 SDS 方法可能提供不准确的梯度方向问题，以及高级度文本-to-3D 人体质量控制的挑战。</li>
<li>methods: 本研究提出了一种名为PaintHuman的模型，通过两种方法来解决问题：首先，引入了一种修改 SDS 的新得分函数（denoised score distillation，DSD），以 iteratively 更正梯度方向并生成高质量的Texture。其次，使用深度图作为geometry guidance，确保Texture具有人体模型表面的semantic alignment。</li>
<li>results: 对比 estado-of-the-art 方法，我们的方法在许多预测和评估任务上具有较高的性能和质量。<details>
<summary>Abstract</summary>
Recent advances in zero-shot text-to-3D human generation, which employ the human model prior (eg, SMPL) or Score Distillation Sampling (SDS) with pre-trained text-to-image diffusion models, have been groundbreaking. However, SDS may provide inaccurate gradient directions under the weak diffusion guidance, as it tends to produce over-smoothed results and generate body textures that are inconsistent with the detailed mesh geometry. Therefore, directly leverage existing strategies for high-fidelity text-to-3D human texturing is challenging. In this work, we propose a model called PaintHuman to addresses the challenges from two aspects. We first propose a novel score function, Denoised Score Distillation (DSD), which directly modifies the SDS by introducing negative gradient components to iteratively correct the gradient direction and generate high-quality textures. In addition, we use the depth map as a geometric guidance to ensure the texture is semantically aligned to human mesh surfaces. To guarantee the quality of rendered results, we employ geometry-aware networks to predict surface materials and render realistic human textures. Extensive experiments, benchmarked against state-of-the-art methods, validate the efficacy of our approach.
</details>
<details>
<summary>摘要</summary>
近期的零shot文本到3D人体生成技术发展，使用人体模型先验（如SMPL）或Score Distillation Sampling（SDS）与预训练文本到图像扩散模型，取得了重要进展。然而，SDS可能在弱扩散指导下提供不准确的梯度方向，因为它有可能生成过度平滑的结果和与细节 mesh geometry 不一致的人体 texture。因此，直接使用现有的高精度文本到3D人体纹理策略是挑战。在这种工作中，我们提议一种名为PaintHuman的模型，用以解决这些挑战。我们首先提出了一种新的分数函数，Denosied Score Distillation（DSD），它直接修改了 SDS，通过引入负梯度组分来逐次更正梯度方向，生成高质量的纹理。此外，我们使用深度图为 geometric 指导，确保纹理与人体 mesh 表面含义相对应。为保证渲染结果的质量，我们使用 geometry-aware 网络预测表面材质并生成真实的人体纹理。我们对 state-of-the-art 方法进行了广泛的实验，并证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="UCM-Net-A-Lightweight-and-Efficient-Solution-for-Skin-Lesion-Segmentation-using-MLP-and-CNN"><a href="#UCM-Net-A-Lightweight-and-Efficient-Solution-for-Skin-Lesion-Segmentation-using-MLP-and-CNN" class="headerlink" title="UCM-Net: A Lightweight and Efficient Solution for Skin Lesion Segmentation using MLP and CNN"></a>UCM-Net: A Lightweight and Efficient Solution for Skin Lesion Segmentation using MLP and CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.09457">http://arxiv.org/abs/2310.09457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunyu Yuan, Dongfang Zhao, Sos S. Agaian<br>for:* 这个论文的目的是提出一种高效、轻量级的皮肤恶性肿瘤分割方法，以便在移动医疗应用中使用。methods:* 该方法使用了多层感知（MLP）和卷积神经网络（CNN）的组合，并提出了一种新的封装块（UCM-Net-Block）来减少参数的 overhead 并提高学习能力。results:* 对于 isic2017 和 isic2018 数据集进行了广泛的实验，并证明了 UCM-Net 在皮肤恶性肿瘤分割中的竞争力。* UCM-Net 的参数少于 50KB，计算量少于 0.05 GLOPs，创造了新的可能性标准 для皮肤恶性肿瘤分割的效率。<details>
<summary>Abstract</summary>
Skin cancer is a significant public health problem, and computer-aided diagnosis can help to prevent and treat it. A crucial step for computer-aided diagnosis is accurately segmenting skin lesions in images, which allows for lesion detection, classification, and analysis. However, this task is challenging due to the diverse characteristics of lesions, such as appearance, shape, size, color, texture, and location, as well as image quality issues like noise, artifacts, and occlusions. Deep learning models have recently been applied to skin lesion segmentation, but they have high parameter counts and computational demands, making them unsuitable for mobile health applications. To address this challenge, we propose UCM-Net, a novel, efficient, and lightweight solution that integrates Multi-Layer Perceptions (MLP) and Convolutional Neural Networks (CNN). Unlike conventional UNet architectures, our UCMNet-Block reduces parameter overhead and enhances UCM-Net's learning capabilities, leading to robust segmentation performance. We validate UCM-Net's competitiveness through extensive experiments on isic2017 and isic2018 datasets. Remarkably, UCM-Net has less than 50KB parameters and less than 0.05 Giga-Operations Per Second (GLOPs), setting a new possible standard for efficiency in skin lesion segmentation. The source code will be publicly available.
</details>
<details>
<summary>摘要</summary>
皮肤癌是一个严重的公共卫生问题，计算机助成诊断可以帮助预防和治疗。计算机助成诊断的关键步骤是准确地分割皮肤癌病变图像中的病变，以便诊断、分类和分析。然而，这个任务很困难，因为癌病变的多样性，包括外表、形状、大小、颜色、文本ure和位置等，以及图像质量问题，如噪声、artefacts和遮挡。最近，深度学习模型已经应用于皮肤癌病变分割，但它们具有高参数计数和计算需求，使其不适合移动医疗应用。为解决这个挑战，我们提出了UCM-Net，一种新的、有效和轻量级的解决方案，它结合多层感知（MLP）和卷积神经网络（CNN）。与传统的UNet架构不同，我们的UCMNet-Block减少参数开销和提高UCM-Net的学习能力，从而实现了稳定的分割性能。我们通过对isic2017和isic2018数据集进行广泛的实验，证明UCM-Net在皮肤癌病变分割中的竞争力。特别是，UCM-Net的参数少于50KB，计算需求少于0.05 Giga-Operations Per Second（GLOPs），创造了新的可能性标准 для皮肤癌病变分割的效率。源代码将公开 availability。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/14/cs.CV_2023_10_14/" data-id="clontc8jg00ji878831zp8peh" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/14/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><span class="page-number current">15</span><a class="page-number" href="/page/16/">16</a><a class="page-number" href="/page/17/">17</a><span class="space">&hellip;</span><a class="page-number" href="/page/85/">85</a><a class="extend next" rel="next" href="/page/16/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">124</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">124</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">124</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">124</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">57</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">114</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">64</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">22</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
