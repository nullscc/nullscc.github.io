
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/12/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_09_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/06/cs.CV_2023_09_06/" class="article-date">
  <time datetime="2023-09-06T13:00:00.000Z" itemprop="datePublished">2023-09-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/06/cs.CV_2023_09_06/">cs.CV - 2023-09-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Distribution-Aware-Prompt-Tuning-for-Vision-Language-Models"><a href="#Distribution-Aware-Prompt-Tuning-for-Vision-Language-Models" class="headerlink" title="Distribution-Aware Prompt Tuning for Vision-Language Models"></a>Distribution-Aware Prompt Tuning for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03406">http://arxiv.org/abs/2309.03406</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlvlab/dapt">https://github.com/mlvlab/dapt</a></li>
<li>paper_authors: Eulrang Cho, Jooyeon Kim, Hyunwoo J. Kim</li>
<li>for: 该研究旨在提高视觉语言模型（VLM）的表现，通过在目标任务上进行适应调整。</li>
<li>methods: 该研究使用了数据驱动的适应调整方法，包括在输入图像或文本中添加上下文。在学习Vector的基础上，通过对两种模式的特征空间进行对齐，提高VLM的表现。</li>
<li>results: 该研究的实验结果表明，使用分布规格感知调整（DAPT）方法可以显著提高VLM的总体表现，并且在11个标准测试集上进行了广泛的验证。<details>
<summary>Abstract</summary>
Pre-trained vision-language models (VLMs) have shown impressive performance on various downstream tasks by utilizing knowledge learned from large data. In general, the performance of VLMs on target tasks can be further improved by prompt tuning, which adds context to the input image or text. By leveraging data from target tasks, various prompt-tuning methods have been studied in the literature. A key to prompt tuning is the feature space alignment between two modalities via learnable vectors with model parameters fixed. We observed that the alignment becomes more effective when embeddings of each modality are `well-arranged' in the latent space. Inspired by this observation, we proposed distribution-aware prompt tuning (DAPT) for vision-language models, which is simple yet effective. Specifically, the prompts are learned by maximizing inter-dispersion, the distance between classes, as well as minimizing the intra-dispersion measured by the distance between embeddings from the same class. Our extensive experiments on 11 benchmark datasets demonstrate that our method significantly improves generalizability. The code is available at https://github.com/mlvlab/DAPT.
</details>
<details>
<summary>摘要</summary>
传统的视觉语言模型（VLM）已经在多个下游任务上表现出色，通过利用大量数据学习知识。在总的来说，VLM的目标任务表现可以通过提示调整进一步提高，这种方法可以通过给输入图像或文本添加上下文来实现。利用目标任务的数据，文献中有多种提示调整方法的研究。一个关键在提示调整中是在两个模式之间的特征空间对齐，通过学习向量并固定模型参数。我们发现，每个模式的特征空间的对齐会在嵌入空间中更加有效。 Drawing inspiration from this observation, we proposed distribution-aware prompt tuning (DAPT) for vision-language models, which is simple yet effective. Specifically, the prompts are learned by maximizing inter-dispersion, the distance between classes, as well as minimizing the intra-dispersion measured by the distance between embeddings from the same class. Our extensive experiments on 11 benchmark datasets demonstrate that our method significantly improves generalizability. 代码可以在 https://github.com/mlvlab/DAPT 上获取。
</details></li>
</ul>
<hr>
<h2 id="Reasonable-Anomaly-Detection-in-Long-Sequences"><a href="#Reasonable-Anomaly-Detection-in-Long-Sequences" class="headerlink" title="Reasonable Anomaly Detection in Long Sequences"></a>Reasonable Anomaly Detection in Long Sequences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03401">http://arxiv.org/abs/2309.03401</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/allenyljiang/anomaly-detection-in-sequences">https://github.com/allenyljiang/anomaly-detection-in-sequences</a></li>
<li>paper_authors: Yalong Jiang, Changkang Li</li>
<li>for: 本文提出了一种新的视频异常检测方法，以解决现有方法中的示例有限性问题。</li>
<li>methods: 本文使用了栈搅拌机制（SSM）模型，通过长期序列学习表示物体的运动模式，并根据过去的状态预测未来状态，从而检测异常情况。</li>
<li>results: 经过广泛的实验评估，本文的方法能够在数据集和现有方法上显著提高异常检测性能。<details>
<summary>Abstract</summary>
Video anomaly detection is a challenging task due to the lack in approaches for representing samples. The visual representations of most existing approaches are limited by short-term sequences of observations which cannot provide enough clues for achieving reasonable detections. In this paper, we propose to completely represent the motion patterns of objects by learning from long-term sequences. Firstly, a Stacked State Machine (SSM) model is proposed to represent the temporal dependencies which are consistent across long-range observations. Then SSM model functions in predicting future states based on past ones, the divergence between the predictions with inherent normal patterns and observed ones determines anomalies which violate normal motion patterns. Extensive experiments are carried out to evaluate the proposed approach on the dataset and existing ones. Improvements over state-of-the-art methods can be observed. Our code is available at https://github.com/AllenYLJiang/Anomaly-Detection-in-Sequences.
</details>
<details>
<summary>摘要</summary>
视频异常检测是一项复杂的任务，主要因为缺乏对样本的表示方法。现有的大多数方法的视觉表示有限，短期序列观察数据无法提供足够的信息以实现有效的检测。在本文中，我们提出了完全基于长期序列学习的物体运动模式表示方法。首先，我们提出了堆叠状态机制（SSM）模型，用于表示时间相关性，这些相关性在长距离观察中保持一致。然后，SSM模型可以基于过去的状态预测未来状态，与内在的正常模式相比，如果存在异常情况，则视为异常。我们对数据集和现有方法进行了广泛的实验，并观察到了我们的方法与之前的状态艺术方法的改进。代码可以在https://github.com/AllenYLJiang/Anomaly-Detection-in-Sequences中找到。
</details></li>
</ul>
<hr>
<h2 id="A-novel-method-for-iris-recognition-using-BP-neural-network-and-parallel-computing-by-the-aid-of-GPUs-Graphics-Processing-Units"><a href="#A-novel-method-for-iris-recognition-using-BP-neural-network-and-parallel-computing-by-the-aid-of-GPUs-Graphics-Processing-Units" class="headerlink" title="A novel method for iris recognition using BP neural network and parallel computing by the aid of GPUs (Graphics Processing Units)"></a>A novel method for iris recognition using BP neural network and parallel computing by the aid of GPUs (Graphics Processing Units)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03390">http://arxiv.org/abs/2309.03390</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farahnaz Hosseini, Hossein Ebrahimpour, Samaneh Askari</li>
<li>for: 该文章旨在探讨一种新的芳华识别系统设计方法。</li>
<li>methods: 该方法首先从芳华图像中提取了Haar波浪特征，这些特征具有快速抽取和对每个芳华唯一的优点。然后使用了后向传播神经网络（BPNN）作为分类器。</li>
<li>results: 该系统的性能和加速结果在文章中展示了，使用GPU和CUDA实现的BPNN并行算法可以加速学习过程。<details>
<summary>Abstract</summary>
In this paper, we seek a new method in designing an iris recognition system. In this method, first the Haar wavelet features are extracted from iris images. The advantage of using these features is the high-speed extraction, as well as being unique to each iris. Then the back propagation neural network (BPNN) is used as a classifier. In this system, the BPNN parallel algorithms and their implementation on GPUs have been used by the aid of CUDA in order to speed up the learning process. Finally, the system performance and the speeding outcomes in a way that this algorithm is done in series are presented.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们寻找一种新的方法来设计一个萝卤识别系统。在这种方法中，首先从萝卤图像中提取Haar浪声特征。这些特征的优点是快速提取和唯一性，可以用于识别每个萝卤。然后，我们使用背投传播神经网络（BPNN）作为分类器。在这个系统中，我们使用GPU上的并行算法和CUDA技术来加速学习过程。最后，我们展示了这个算法的性能和加速效果。
</details></li>
</ul>
<hr>
<h2 id="Kidney-abnormality-segmentation-in-thorax-abdomen-CT-scans"><a href="#Kidney-abnormality-segmentation-in-thorax-abdomen-CT-scans" class="headerlink" title="Kidney abnormality segmentation in thorax-abdomen CT scans"></a>Kidney abnormality segmentation in thorax-abdomen CT scans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03383">http://arxiv.org/abs/2309.03383</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriel Efrain Humpire Mamani, Nikolas Lessmann, Ernst Th. Scholten, Mathias Prokop, Colin Jacobs, Bram van Ginneken</li>
<li>for:  This paper aims to support clinicians in identifying and quantifying renal abnormalities such as cysts, lesions, masses, metastases, and primary tumors through the use of deep learning for segmenting kidney parenchyma and kidney abnormalities.</li>
<li>methods:  The paper introduces an end-to-end segmentation method that utilizes a modified 3D U-Net network with four additional components: end-to-end multi-resolution approach, task-specific data augmentations, modified loss function using top-$k$, and spatial dropout. The method was trained on 215 contrast-enhanced thoracic-abdominal CT scans.</li>
<li>results:  The paper reports that the best-performing model achieved Dice scores of 0.965 and 0.947 for segmenting kidney parenchyma in two test sets, outperforming an independent human observer. The method also achieved a Dice score of 0.585 for segmenting kidney abnormalities within the 30 test scans containing them, suggesting potential for further improvement in computerized methods.<details>
<summary>Abstract</summary>
In this study, we introduce a deep learning approach for segmenting kidney parenchyma and kidney abnormalities to support clinicians in identifying and quantifying renal abnormalities such as cysts, lesions, masses, metastases, and primary tumors. Our end-to-end segmentation method was trained on 215 contrast-enhanced thoracic-abdominal CT scans, with half of these scans containing one or more abnormalities.   We began by implementing our own version of the original 3D U-Net network and incorporated four additional components: an end-to-end multi-resolution approach, a set of task-specific data augmentations, a modified loss function using top-$k$, and spatial dropout. Furthermore, we devised a tailored post-processing strategy. Ablation studies demonstrated that each of the four modifications enhanced kidney abnormality segmentation performance, while three out of four improved kidney parenchyma segmentation. Subsequently, we trained the nnUNet framework on our dataset. By ensembling the optimized 3D U-Net and the nnUNet with our specialized post-processing, we achieved marginally superior results.   Our best-performing model attained Dice scores of 0.965 and 0.947 for segmenting kidney parenchyma in two test sets (20 scans without abnormalities and 30 with abnormalities), outperforming an independent human observer who scored 0.944 and 0.925, respectively. In segmenting kidney abnormalities within the 30 test scans containing them, the top-performing method achieved a Dice score of 0.585, while an independent second human observer reached a score of 0.664, suggesting potential for further improvement in computerized methods.   All training data is available to the research community under a CC-BY 4.0 license on https://doi.org/10.5281/zenodo.8014289
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们介绍了一种深度学习方法用于分割肾脏和肾脏疾病，以支持临床医生在识别和评估肾脏疾病，如肿瘤、抑郁、肿瘤和原发性肾脏癌。我们的终端 segmentation 方法在 215 个对比增强的 thoracic-abdominal CT 扫描图像上进行训练，其中半数图像含有一个或多个疾病。我们开始实现我们自己的版本的原始 3D U-Net 网络，并添加了四个附加组件：一个终端多分辨率方法、一组任务特定的数据增强、修改后的 top-$k$ 损失函数和空间抽象。此外，我们设计了特制的后处理策略。ablation 研究表明，每一个修改都提高了肾脏疾病 segmentation 性能，而三个中提高了肾脏正常组织 segmentation。然后，我们将 nnUNet 框架进行训练。通过将优化的 3D U-Net 和 nnUNet 与我们特制的后处理 ensemble，我们实现了微妙的提高。我们最佳性能模型在两个测试集（20 个无疾病扫描图像和 30 个含疾病扫描图像）中，对肾脏正常组织 segmentation 取得了 dice 分数为 0.965 和 0.947，超过了一名独立的人类观察员，其分数为 0.944 和 0.925。在 segmenting 肾脏疾病内的 30 个测试扫描图像中，我们的最佳方法取得了 dice 分数为 0.585，而第二名独立的人类观察员达到了分数为 0.664，表明计算机化方法还有很大的提高空间。所有训练数据都可以通过 CC-BY 4.0 LICENSE 在 https://doi.org/10.5281/zenodo.8014289 上获得。
</details></li>
</ul>
<hr>
<h2 id="Active-shooter-detection-and-robust-tracking-utilizing-supplemental-synthetic-data"><a href="#Active-shooter-detection-and-robust-tracking-utilizing-supplemental-synthetic-data" class="headerlink" title="Active shooter detection and robust tracking utilizing supplemental synthetic data"></a>Active shooter detection and robust tracking utilizing supplemental synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03381">http://arxiv.org/abs/2309.03381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua R. Waite, Jiale Feng, Riley Tavassoli, Laura Harris, Sin Yong Tan, Subhadeep Chakraborty, Soumik Sarkar</li>
<li>for: 针对美国gun violence问题的增长关注，提出了开发公共安全系统的想法，其中一种方法是探测和跟踪射击者，以预防或减轻暴力事件的影响。</li>
<li>methods: 本文提出了探测射击者而不是只是枪支，以提高跟踪鲁棒性，因为隐藏枪支不再导致系统产生失去威胁的情况。为了解决公共数据的限制和创造困难，本文使用域随机化和传输学习，以提高模型在不同情况下的普适性。</li>
<li>results: 使用YOLOv8和Deep OC-SORT，实现了一个初步版本的射击者跟踪系统，可以在边缘硬件上运行，包括Raspberry Pi和Jetson Nano。<details>
<summary>Abstract</summary>
The increasing concern surrounding gun violence in the United States has led to a focus on developing systems to improve public safety. One approach to developing such a system is to detect and track shooters, which would help prevent or mitigate the impact of violent incidents. In this paper, we proposed detecting shooters as a whole, rather than just guns, which would allow for improved tracking robustness, as obscuring the gun would no longer cause the system to lose sight of the threat. However, publicly available data on shooters is much more limited and challenging to create than a gun dataset alone. Therefore, we explore the use of domain randomization and transfer learning to improve the effectiveness of training with synthetic data obtained from Unreal Engine environments. This enables the model to be trained on a wider range of data, increasing its ability to generalize to different situations. Using these techniques with YOLOv8 and Deep OC-SORT, we implemented an initial version of a shooter tracking system capable of running on edge hardware, including both a Raspberry Pi and a Jetson Nano.
</details>
<details>
<summary>摘要</summary>
随着美国的枪击事件频率的增长，有关公众安全的关注也在不断增加。为了开发一个可以提高公众安全的系统，一种方法是检测和跟踪射击者，以防止或减轻暴力事件的影响。在这篇论文中，我们提出了检测射击者的整体方法，而不仅仅是检测枪支，这将允许更好地跟踪射击者，即使枪支被遮住也不会导致系统丢失跟踪。然而，公共可用的射击者数据比枪支数据更加有限和困难生成。因此，我们研究了采用域随机化和传输学习来提高训练 synthetic 数据的效果。这使得模型可以在更广泛的数据上训练，从而提高其对不同情况的适应能力。使用这些技术和 YOLOv8 和 Deep OC-SORT，我们实现了一个可以在边缘硬件上运行的射击者跟踪系统，包括 Raspberry Pi 和 Jetson Nano。
</details></li>
</ul>
<hr>
<h2 id="ViewMix-Augmentation-for-Robust-Representation-in-Self-Supervised-Learning"><a href="#ViewMix-Augmentation-for-Robust-Representation-in-Self-Supervised-Learning" class="headerlink" title="ViewMix: Augmentation for Robust Representation in Self-Supervised Learning"></a>ViewMix: Augmentation for Robust Representation in Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03360">http://arxiv.org/abs/2309.03360</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arjon Das, Xin Zhong</li>
<li>for: 这 paper 的目的是提出一种基于自动检测的视角拼接策略，以提高基于自助学习的表示学习能力。</li>
<li>methods: 这 paper 使用了一种基于自动检测的视角拼接策略，并与多种基于自助学习的表示学习方法进行比较。</li>
<li>results: 该 paper 表明，通过使用 ViewMix 策略，可以提高基于自助学习的表示学习方法的地方化能力和稳定性。<details>
<summary>Abstract</summary>
Joint Embedding Architecture-based self-supervised learning methods have attributed the composition of data augmentations as a crucial factor for their strong representation learning capabilities. While regional dropout strategies have proven to guide models to focus on lesser indicative parts of the objects in supervised methods, it hasn't been adopted by self-supervised methods for generating positive pairs. This is because the regional dropout methods are not suitable for the input sampling process of the self-supervised methodology. Whereas dropping informative pixels from the positive pairs can result in inefficient training, replacing patches of a specific object with a different one can steer the model from maximizing the agreement between different positive pairs. Moreover, joint embedding representation learning methods have not made robustness their primary training outcome. To this end, we propose the ViewMix augmentation policy, specially designed for self-supervised learning, upon generating different views of the same image, patches are cut and pasted from one view to another. By leveraging the different views created by this augmentation strategy, multiple joint embedding-based self-supervised methodologies obtained better localization capability and consistently outperformed their corresponding baseline methods. It is also demonstrated that incorporating ViewMix augmentation policy promotes robustness of the representations in the state-of-the-art methods. Furthermore, our experimentation and analysis of compute times suggest that ViewMix augmentation doesn't introduce any additional overhead compared to other counterparts.
</details>
<details>
<summary>摘要</summary>
joint embedding architecture-based self-supervised learning方法中，数据增强的组合被认为是关键因素，对于强化表示学习能力。而regional dropout策略在supervised方法中已经证明了导models专注于更加不显示的部分，但是它们没有被采用于自我监督方法中，这是因为regional dropout方法不适用于自我监督方法的输入采样过程。 dropped informative pixels from the positive pairs can result in inefficient training，而且 replacing patches of a specific object with a different one can steer the model away from maximizing the agreement between different positive pairs。 joint embedding representation learning方法没有让robustness成为主要训练目标。为此，我们提出了ViewMixaugmentation policy，专门针对自我监督学习。在生成不同视图的同一个图像上，将patches cut和paste到另一个视图中。通过利用不同的视图，生成的多个joint embedding-based self-supervised方法在本地化能力方面表现出色，并且与基eline方法相比，表现出了明显的提升。此外，我们的实验和分析表明，ViewMix augmentation不会增加任何额外的计算时间。
</details></li>
</ul>
<hr>
<h2 id="Source-Camera-Identification-and-Detection-in-Digital-Videos-through-Blind-Forensics"><a href="#Source-Camera-Identification-and-Detection-in-Digital-Videos-through-Blind-Forensics" class="headerlink" title="Source Camera Identification and Detection in Digital Videos through Blind Forensics"></a>Source Camera Identification and Detection in Digital Videos through Blind Forensics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03353">http://arxiv.org/abs/2309.03353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Venkata Udaya Sameer, Shilpa Mukhopadhyay, Ruchira Naskar, Ishaan Dali</li>
<li>for: 本研究旨在验证视频源的authenticity和来源，以确定视频是否实际来源于声明的来源。</li>
<li>methods: 本研究使用特征提取、特征选择和后续源分类来实现视频源识别。</li>
<li>results: 我们的实验结果表明，提出的方法比传统的指纹基本方法更高效。<details>
<summary>Abstract</summary>
Source camera identification in digital videos is the problem of associating an unknown digital video with its source device, within a closed set of possible devices. The existing techniques in source detection of digital videos try to find a fingerprint of the actual source in the video in form of PRNU (Photo Response Non--Uniformity), and match it against the SPN (Sensor Pattern Noise) of each possible device. The highest correlation indicates the correct source. We investigate the problem of identifying a video source through a feature based approach using machine learning. In this paper, we present a blind forensic technique of video source authentication and identification, based on feature extraction, feature selection and subsequent source classification. The main aim is to determine whether a claimed source for a video is actually its original source. If not, we identify its original source. Our experimental results prove the efficiency of the proposed method compared to traditional fingerprint based technique.
</details>
<details>
<summary>摘要</summary>
源码 identificatin in digital videos 是一个关键问题，即将未知的数字视频与其源设备相关联，在一个封闭的设备集中。现有的数字视频源检测技术尝试找到视频中的实际源print（PRNU），并将其与每个可能的设备SPN（感光器环境噪）进行匹配。最高的相关性指示正确的源。我们 investigate了基于特征分析的视频源认证和identification方法，以实现视频源的潜在验证和确定。我们的实验结果表明，我们提posed方法比传统的指纹基本技术更高效。Here's a word-for-word translation of the text:源码标识在数字视频中是一个关键问题，即将未知的数字视频与其源设备相关联，在一个封闭的设备集中。现有的数字视频源检测技术尝试找到视频中的实际源印记（PRNU），并将其与每个可能的设备感光器环境噪（SPN）进行匹配。最高的相关性指示正确的源。我们 investigate了基于特征分析的视频源认证和identification方法，以实现视频源的潜在验证和确定。我们的实验结果表明，我们提posed方法比传统的指纹基本技术更高效。
</details></li>
</ul>
<hr>
<h2 id="Using-Neural-Networks-for-Fast-SAR-Roughness-Estimation-of-High-Resolution-Images"><a href="#Using-Neural-Networks-for-Fast-SAR-Roughness-Estimation-of-High-Resolution-Images" class="headerlink" title="Using Neural Networks for Fast SAR Roughness Estimation of High Resolution Images"></a>Using Neural Networks for Fast SAR Roughness Estimation of High Resolution Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03351">http://arxiv.org/abs/2309.03351</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jeovafarias/sar-roughness-estimation-neural-nets">https://github.com/jeovafarias/sar-roughness-estimation-neural-nets</a></li>
<li>paper_authors: Li Fan, Jeova Farias Sales Rocha Neto</li>
<li>for: 这个论文主要是为了提出一种基于神经网络的高分辨率Synthetic Aperture Radar（SAR）图像分析方法，以解决SAR图像中的杂点噪声问题。</li>
<li>methods: 这个方法首先学习了G_I^0分布下数据的模型，然后可以从SAR图像中提取杂点信息，并用于后续的图像处理任务，如分 segmentation、分类和解释。</li>
<li>results: 该方法可以快速和可靠地估计SAR图像中的杂点参数，尤其是高分辨率图像。此外，该方法还可以扩展到处理图像输入，并且可以使用简单的神经网络来实现实时像素粗糙度估计。<details>
<summary>Abstract</summary>
The analysis of Synthetic Aperture Radar (SAR) imagery is an important step in remote sensing applications, and it is a challenging problem due to its inherent speckle noise. One typical solution is to model the data using the $G_I^0$ distribution and extract its roughness information, which in turn can be used in posterior imaging tasks, such as segmentation, classification and interpretation. This leads to the need of quick and reliable estimation of the roughness parameter from SAR data, especially with high resolution images. Unfortunately, traditional parameter estimation procedures are slow and prone to estimation failures. In this work, we proposed a neural network-based estimation framework that first learns how to predict underlying parameters of $G_I^0$ samples and then can be used to estimate the roughness of unseen data. We show that this approach leads to an estimator that is quicker, yields less estimation error and is less prone to failures than the traditional estimation procedures for this problem, even when we use a simple network. More importantly, we show that this same methodology can be generalized to handle image inputs and, even if trained on purely synthetic data for a few seconds, is able to perform real time pixel-wise roughness estimation for high resolution real SAR imagery.
</details>
<details>
<summary>摘要</summary>
“Synthetic Aperture Radar（SAR）影像分析是远程感知应用中的一个重要步骤，但是它受到自然的雷达噪声的限制。一种常见的解决方案是使用$G_I^0$分布来模型数据，并从其中提取噪声信息，以便在后续的图像处理任务中使用，如分 segmentation、分类和解释。这导致了高分辨率图像的快速和可靠地Estimation of roughness parameter的需求。然而，传统的参数估计方法是慢并且容易出现估计错误。在这项工作中，我们提出了基于神经网络的估计框架，它可以先预测underlying参数的$G_I^0$样本，然后用于估计未看到的数据中的粗糙度。我们显示了这种方法比传统估计方法更快、更准确、更可靠，即使使用简单的网络。更重要的是，我们显示了这种方法可以扩展到处理图像输入，且即使只使用了几秒钟的Synthetic数据，仍能在实时进行每个像素粗糙度估计。”
</details></li>
</ul>
<hr>
<h2 id="SADIR-Shape-Aware-Diffusion-Models-for-3D-Image-Reconstruction"><a href="#SADIR-Shape-Aware-Diffusion-Models-for-3D-Image-Reconstruction" class="headerlink" title="SADIR: Shape-Aware Diffusion Models for 3D Image Reconstruction"></a>SADIR: Shape-Aware Diffusion Models for 3D Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03335">http://arxiv.org/abs/2309.03335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nivetha Jayakumar, Tonmoy Hossain, Miaomiao Zhang</li>
<li>for: 本研究旨在提高3D图像重建的精度和shape结构保持性，使用深度学习模型。</li>
<li>methods: 本研究提出了一种基于扩散模型的shape-aware网络（SADIR），通过同时学习mean shape和变换模型来指导3D图像重建。</li>
<li>results: 对于大脑和心脏MRIs，我们的方法SADIR比基eline方法有更低的重建错误和更好地保持object shape结构。<details>
<summary>Abstract</summary>
3D image reconstruction from a limited number of 2D images has been a long-standing challenge in computer vision and image analysis. While deep learning-based approaches have achieved impressive performance in this area, existing deep networks often fail to effectively utilize the shape structures of objects presented in images. As a result, the topology of reconstructed objects may not be well preserved, leading to the presence of artifacts such as discontinuities, holes, or mismatched connections between different parts. In this paper, we propose a shape-aware network based on diffusion models for 3D image reconstruction, named SADIR, to address these issues. In contrast to previous methods that primarily rely on spatial correlations of image intensities for 3D reconstruction, our model leverages shape priors learned from the training data to guide the reconstruction process. To achieve this, we develop a joint learning network that simultaneously learns a mean shape under deformation models. Each reconstructed image is then considered as a deformed variant of the mean shape. We validate our model, SADIR, on both brain and cardiac magnetic resonance images (MRIs). Experimental results show that our method outperforms the baselines with lower reconstruction error and better preservation of the shape structure of objects within the images.
</details>
<details>
<summary>摘要</summary>
三维图像重建从有限数量的二维图像是计算机视觉和图像分析领域的长期挑战。虽然深度学习基本方法在这一领域已经取得了很好的成绩，但现有的深度网络 oftentimes 不够利用图像中对象的形态结构。为此，重建对象的topology可能不会很好地保留，导致图像中的缺陷，如缺失、洞、或者不同部分之间的不一致。在这篇论文中，我们提出了一种基于扩散模型的形态意识网络，名为SADIR，以解决这些问题。与先前的方法不同，我们的模型不仅仅依靠图像中的空间相关性来进行三维重建，而且同时学习图像中对象的形态特征。为此，我们开发了一个联合学习网络，该网络同时学习一个变换模型中的平均形态。每个重建的图像都被视为变换模型中的一个扭曲变体。我们验证了我们的模型，SADIR，在脑和心脏磁共振图像（MRI）上。实验结果表明，我们的方法在比较基eline上下降重建错误和更好地保留图像中对象的形态结构。
</details></li>
</ul>
<hr>
<h2 id="Expert-Uncertainty-and-Severity-Aware-Chest-X-Ray-Classification-by-Multi-Relationship-Graph-Learning"><a href="#Expert-Uncertainty-and-Severity-Aware-Chest-X-Ray-Classification-by-Multi-Relationship-Graph-Learning" class="headerlink" title="Expert Uncertainty and Severity Aware Chest X-Ray Classification by Multi-Relationship Graph Learning"></a>Expert Uncertainty and Severity Aware Chest X-Ray Classification by Multi-Relationship Graph Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03331">http://arxiv.org/abs/2309.03331</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengliang Zhang, Xinyue Hu, Lin Gu, Liangchen Liu, Kazuma Kobayashi, Tatsuya Harada, Ronald M. Summers, Yingying Zhu</li>
<li>for: 这篇论文的目的是为了提高胸部X线成像（CXR）报告中的疾病标签准确性，因为胸部X线成像诊断常常需要处理多种肺病，并且鉴别这些疾病的细节和患者的状况不同，因此鉴别结果可能会受到诊断者的干扰。</li>
<li>methods: 这篇论文使用了一个规律基于关键字的方法来重新提取CXR报告中的疾病标签，并且还使用了一个多关系图学习方法，以及一个专家不确定意识感损失函数，以提高验证结果的解释性。</li>
<li>results: 这篇论文的实验结果显示，考虑疾病严重程度和不确定性的模型可以超越先前的州OF-THE-ART方法的性能。<details>
<summary>Abstract</summary>
Patients undergoing chest X-rays (CXR) often endure multiple lung diseases. When evaluating a patient's condition, due to the complex pathologies, subtle texture changes of different lung lesions in images, and patient condition differences, radiologists may make uncertain even when they have experienced long-term clinical training and professional guidance, which makes much noise in extracting disease labels based on CXR reports. In this paper, we re-extract disease labels from CXR reports to make them more realistic by considering disease severity and uncertainty in classification. Our contributions are as follows: 1. We re-extracted the disease labels with severity and uncertainty by a rule-based approach with keywords discussed with clinical experts. 2. To further improve the explainability of chest X-ray diagnosis, we designed a multi-relationship graph learning method with an expert uncertainty-aware loss function. 3. Our multi-relationship graph learning method can also interpret the disease classification results. Our experimental results show that models considering disease severity and uncertainty outperform previous state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
患者在胸部X射线检查（CXR）时经常uffer from multiple lung diseases. 评估患者情况时，由于复杂的疾病特征、不同肺脏病变的柔软Texture changes和患者状况差异，辐射学家可能会做出不确定的诊断，即使他们拥有长期临床训练和专业指导。这会导致CXR报告中的疾病标签EXTRACTION具有较高的噪音。在这篇论文中，我们重新EXTRACT了CXR报告中的疾病标签，以使其更加真实性。我们的贡献如下：1. 我们使用规则基本的方法与临床专家讨论的关键词来重新EXTRACT疾病标签，考虑疾病严重性和不确定性。2. 为了进一步提高胸部X射线诊断的解释性，我们设计了一种多关系图学习方法，并使用专家不确定性感知损失函数。3. 我们的多关系图学习方法还可以解释肺病分类结果。我们的实验结果表明，考虑疾病严重性和不确定性的模型比前一个状态的方法表现更好。
</details></li>
</ul>
<hr>
<h2 id="MEGANet-Multi-Scale-Edge-Guided-Attention-Network-for-Weak-Boundary-Polyp-Segmentation"><a href="#MEGANet-Multi-Scale-Edge-Guided-Attention-Network-for-Weak-Boundary-Polyp-Segmentation" class="headerlink" title="MEGANet: Multi-Scale Edge-Guided Attention Network for Weak Boundary Polyp Segmentation"></a>MEGANet: Multi-Scale Edge-Guided Attention Network for Weak Boundary Polyp Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03329">http://arxiv.org/abs/2309.03329</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dinhhieuhoang/meganet">https://github.com/dinhhieuhoang/meganet</a></li>
<li>paper_authors: Nhat-Tan Bui, Dinh-Hieu Hoang, Quang-Thuc Nguyen, Minh-Triet Tran, Ngan Le</li>
<li>for: 该研究旨在提高肠内部肿瘤分割的精度，以促进早期肠癌诊断。</li>
<li>methods: 该研究提出了一种多尺度Edge-Guided Attention网络（MEGANet），结合了经典的边检测技术和注意机制，以提高肿瘤边界的定义。</li>
<li>results: 对五个 benchmark 数据集进行了广泛的实验，并表明了我们的EGANet在六个评价指标上超越了现有的SOTA方法。<details>
<summary>Abstract</summary>
Efficient polyp segmentation in healthcare plays a critical role in enabling early diagnosis of colorectal cancer. However, the segmentation of polyps presents numerous challenges, including the intricate distribution of backgrounds, variations in polyp sizes and shapes, and indistinct boundaries. Defining the boundary between the foreground (i.e. polyp itself) and the background (surrounding tissue) is difficult. To mitigate these challenges, we propose Multi-Scale Edge-Guided Attention Network (MEGANet) tailored specifically for polyp segmentation within colonoscopy images. This network draws inspiration from the fusion of a classical edge detection technique with an attention mechanism. By combining these techniques, MEGANet effectively preserves high-frequency information, notably edges and boundaries, which tend to erode as neural networks deepen. MEGANet is designed as an end-to-end framework, encompassing three key modules: an encoder, which is responsible for capturing and abstracting the features from the input image, a decoder, which focuses on salient features, and the Edge-Guided Attention module (EGA) that employs the Laplacian Operator to accentuate polyp boundaries. Extensive experiments, both qualitative and quantitative, on five benchmark datasets, demonstrate that our EGANet outperforms other existing SOTA methods under six evaluation metrics. Our code is available at \url{https://github.com/DinhHieuHoang/MEGANet}
</details>
<details>
<summary>摘要</summary>
高效的贝壳分割在医疗领域对抗肝癌的诊断扮演了关键角色。然而，贝壳分割存在许多挑战，包括贝壳的复杂分布、贝壳大小和形状的变化，以及边界不明确。准确地定义贝壳和背景之间的边界是困难的。为了解决这些挑战，我们提议一种适应贝壳分割的多尺度 Edge-Guided Attention 网络（MEGANet）。这个网络灵感来自于对精度 Edge Detection 技术和注意机制的融合。通过这些技术的组合，MEGANet 能够保留高频信息，包括边缘和边界，这些信息在神经网络深化时往往会丢失。MEGANet 是一个端到端框架，包括一个编码器，负责从输入图像中提取和抽象特征，一个解码器，专注于突出特征，以及Edge-Guided Attention 模块（EGA），使用拉普拉斯运算符来强调贝壳边界。我们在五个参考数据集进行了广泛的实验，包括质量和量化的评估，显示我们的 EGANet 在六个评价指标上表现出色，超过了现有的 State-of-the-Art 方法。我们的代码可以在 GitHub 上找到：https://github.com/DinhHieuHoang/MEGANet。
</details></li>
</ul>
<hr>
<h2 id="C-CLIP-Contrastive-Image-Text-Encoders-to-Close-the-Descriptive-Commentative-Gap"><a href="#C-CLIP-Contrastive-Image-Text-Encoders-to-Close-the-Descriptive-Commentative-Gap" class="headerlink" title="C-CLIP: Contrastive Image-Text Encoders to Close the Descriptive-Commentative Gap"></a>C-CLIP: Contrastive Image-Text Encoders to Close the Descriptive-Commentative Gap</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03921">http://arxiv.org/abs/2309.03921</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Theisen, Walter Scheirer</li>
<li>for: 这个论文的目的是为了提高社交媒体上图文对应的 Multimodal 模型的性能，以便在不同语言和平台上进行图文对应任务。</li>
<li>methods: 这个论文使用的方法是使用对称的图文对应模型，并在这些模型中使用特定的训练数据来提高图文对应的性能。</li>
<li>results: 论文的结果表明，使用特定的训练数据可以大幅提高图文对应的性能，并且这些结果可以在多种非英语语言上进行应用。<details>
<summary>Abstract</summary>
The interplay between the image and comment on a social media post is one of high importance for understanding its overall message. Recent strides in multimodal embedding models, namely CLIP, have provided an avenue forward in relating image and text. However the current training regime for CLIP models is insufficient for matching content found on social media, regardless of site or language. Current CLIP training data is based on what we call ``descriptive'' text: text in which an image is merely described. This is something rarely seen on social media, where the vast majority of text content is ``commentative'' in nature. The captions provide commentary and broader context related to the image, rather than describing what is in it. Current CLIP models perform poorly on retrieval tasks where image-caption pairs display a commentative relationship. Closing this gap would be beneficial for several important application areas related to social media. For instance, it would allow groups focused on Open-Source Intelligence Operations (OSINT) to further aid efforts during disaster events, such as the ongoing Russian invasion of Ukraine, by easily exposing data to non-technical users for discovery and analysis. In order to close this gap we demonstrate that training contrastive image-text encoders on explicitly commentative pairs results in large improvements in retrieval results, with the results extending across a variety of non-English languages.
</details>
<details>
<summary>摘要</summary>
社交媒体文章的图文对话是理解总体信息的关键之一。现在的多模式嵌入模型CLIP已经提供了前进的方向，但现在CLIP模型的训练方式是不足以满足社交媒体上的内容的。现有CLIP训练数据基于我们称之为“描述性”文本：文本中描述图片的内容。这在社交媒体上非常少见，大多数文本内容是“评论性”的，图片的caption提供了更广泛的背景和评论。现有CLIP模型在图片-caption对应 зада务中表现不佳。将这个差距减少会对社交媒体相关应用领域带来多个重要的好处，例如在灾难事件中，如现在俄罗斯入侵乌克兰的进行开源情报操作（OSINT）的团队能够更好地帮助努力。为了减少这个差距，我们展示了在使用明确评论对应的图片-文本对应器进行训练后， Retrieval结果得到了大幅提高，这些结果在多种非英语语言上都能够扩展。
</details></li>
</ul>
<hr>
<h2 id="CoNeS-Conditional-neural-fields-with-shift-modulation-for-multi-sequence-MRI-translation"><a href="#CoNeS-Conditional-neural-fields-with-shift-modulation-for-multi-sequence-MRI-translation" class="headerlink" title="CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation"></a>CoNeS: Conditional neural fields with shift modulation for multi-sequence MRI translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03320">http://arxiv.org/abs/2309.03320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cyjdswx/cones">https://github.com/cyjdswx/cones</a></li>
<li>paper_authors: Yunjie Chen, Marius Staring, Olaf M. Neve, Stephan R. Romeijn, Erik F. Hensen, Berit M. Verbist, Jelmer M. Wolterink, Qian Tao</li>
<li>for: 这个研究的目的是提出一种可以Synthesize missing MRI sequence的方法，以便在诊断过程中使用深度学习模型。</li>
<li>methods: 这个方法使用Conditional Neural fields with Shift modulation（CoNeS）模型，将 voxel 坐标作为输入，并使用多层感知扩展（MLP）作为解oder，以实现像素到像素的映射。</li>
<li>results: 实验结果显示，提出的方法可以较好地透过多个序列的MRI资料进行翻译，并且可以更好地保留高频率细节。此外，实验还显示了这个方法可以扩展到诊断下游任务中，例如分类 tasks。<details>
<summary>Abstract</summary>
Multi-sequence magnetic resonance imaging (MRI) has found wide applications in both modern clinical studies and deep learning research. However, in clinical practice, it frequently occurs that one or more of the MRI sequences are missing due to different image acquisition protocols or contrast agent contraindications of patients, limiting the utilization of deep learning models trained on multi-sequence data. One promising approach is to leverage generative models to synthesize the missing sequences, which can serve as a surrogate acquisition. State-of-the-art methods tackling this problem are based on convolutional neural networks (CNN) which usually suffer from spectral biases, resulting in poor reconstruction of high-frequency fine details. In this paper, we propose Conditional Neural fields with Shift modulation (CoNeS), a model that takes voxel coordinates as input and learns a representation of the target images for multi-sequence MRI translation. The proposed model uses a multi-layer perceptron (MLP) instead of a CNN as the decoder for pixel-to-pixel mapping. Hence, each target image is represented as a neural field that is conditioned on the source image via shift modulation with a learned latent code. Experiments on BraTS 2018 and an in-house clinical dataset of vestibular schwannoma patients showed that the proposed method outperformed state-of-the-art methods for multi-sequence MRI translation both visually and quantitatively. Moreover, we conducted spectral analysis, showing that CoNeS was able to overcome the spectral bias issue common in conventional CNN models. To further evaluate the usage of synthesized images in clinical downstream tasks, we tested a segmentation network using the synthesized images at inference.
</details>
<details>
<summary>摘要</summary>
多序列核磁共振成像（MRI）在现代临床研究和深度学习中得到了广泛应用。然而，在临床实践中，由于不同的图像获取协议或患者的荷物禁忌，导致MRI序列中有一些图像缺失，这限制了使用深度学习模型训练在多序列数据上的应用。一种可能的方法是使用生成模型来生成缺失的序列，这可以作为训练深度学习模型的供应。现状的方法通常基于卷积神经网络（CNN），它们通常受到频率偏好的影响，导致重建高频率细节的表现不佳。在这篇论文中，我们提出了基于 Conditional Neural fields with Shift modulation（CoNeS）的方法。CoNeS 模型接受 voxel 坐标作为输入，并学习一种用于多序列 MRI 翻译的目标图像表示方式。我们使用多层感知神经网络（MLP）作为像素到像素映射的解码器，因此每个目标图像都被表示为一个 conditional neural field，通过 shift modulation 和学习的隐藏代码来conditioned 于源图像。我们在 BraTS 2018 和一个内部临床数据集中进行了实验，并证明了我们的方法在多序列 MRI 翻译中超过了现状方法的视觉和量化性能。此外，我们还进行了频谱分析，表明 CoNeS 能够超越常见的频谱偏好问题。为了进一步评估生成的图像在临床下渠道任务中的使用，我们在推理阶段使用生成的图像进行分割网络的测试。
</details></li>
</ul>
<hr>
<h2 id="Bayes’-Rays-Uncertainty-Quantification-for-Neural-Radiance-Fields"><a href="#Bayes’-Rays-Uncertainty-Quantification-for-Neural-Radiance-Fields" class="headerlink" title="Bayes’ Rays: Uncertainty Quantification for Neural Radiance Fields"></a>Bayes’ Rays: Uncertainty Quantification for Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03185">http://arxiv.org/abs/2309.03185</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/BayesRays/BayesRays">https://github.com/BayesRays/BayesRays</a></li>
<li>paper_authors: Lily Goli, Cody Reading, Silvia Sellán, Alec Jacobson, Andrea Tagliasacchi</li>
<li>for: 这个论文是为了评估透视场景中神经辐射场景（NeRFs）的不确定性。</li>
<li>methods: 该论文提出了一种后期框架，可以无需修改训练过程来评估神经辐射场景中的不确定性。该方法基于空间干扰和 bayesian laplaceapproximation来建立三维不确定性场景。</li>
<li>results: 该论文通过统计 derivation 和实验结果显示了其在关键指标和应用中的superior性能。更多结果可以在<a target="_blank" rel="noopener" href="https://bayesrays.github.io/%E6%9F%A5%E7%9C%8B%E3%80%82">https://bayesrays.github.io/查看。</a><details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRFs) have shown promise in applications like view synthesis and depth estimation, but learning from multiview images faces inherent uncertainties. Current methods to quantify them are either heuristic or computationally demanding. We introduce BayesRays, a post-hoc framework to evaluate uncertainty in any pre-trained NeRF without modifying the training process. Our method establishes a volumetric uncertainty field using spatial perturbations and a Bayesian Laplace approximation. We derive our algorithm statistically and show its superior performance in key metrics and applications. Additional results available at: https://bayesrays.github.io.
</details>
<details>
<summary>摘要</summary>
neural radiance fields (NeRFs) 已经在视图合成和深度估计方面显示了承诺，但学习从多视图图像中存在内在的不确定性。现有的方法来衡量这些不确定性是 Either heuristic 或 computationally demanding。我们介绍 BayesRays，一种在预训练 NeRF 无需修改训练过程中的 posterior framework 来评估不确定性。我们的方法创建了一个卷积uncertainty field 使用空间扰动和bayesian laplace approximation。我们从统计角度 derivation 我们的算法，并在关键指标和应用中表现出优于现有方法。更多结果可以在: <https://bayesrays.github.io> 中找到。
</details></li>
</ul>
<hr>
<h2 id="3D-Transformer-based-on-deformable-patch-location-for-differential-diagnosis-between-Alzheimer’s-disease-and-Frontotemporal-dementia"><a href="#3D-Transformer-based-on-deformable-patch-location-for-differential-diagnosis-between-Alzheimer’s-disease-and-Frontotemporal-dementia" class="headerlink" title="3D Transformer based on deformable patch location for differential diagnosis between Alzheimer’s disease and Frontotemporal dementia"></a>3D Transformer based on deformable patch location for differential diagnosis between Alzheimer’s disease and Frontotemporal dementia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03183">http://arxiv.org/abs/2309.03183</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huy-Dung Nguyen, Michaël Clément, Boris Mansencal, Pierrick Coupé</li>
<li>for: 本研究的目的是提出一种基于 transformer 架构的三维医学数据识别方法，以提高阿尔茨海默病和前rontemporal dementia 的Multi-class differential diagnosis。</li>
<li>methods: 本研究使用了 transformer 架构，并提出了一种弹性质的 patch 定位模块，以提高精准性。此外，为了解决数据稀缺问题，我们提出了一种有效的数据扩充技术策略，适用于训练 transformer 模型。</li>
<li>results: 我们的实验表明，提出的方法可以实现竞争性的 результаats，并且可以Visualize 弹性 patch 定位，揭示了每种疾病的诊断所使用的主要脑区域。<details>
<summary>Abstract</summary>
Alzheimer's disease and Frontotemporal dementia are common types of neurodegenerative disorders that present overlapping clinical symptoms, making their differential diagnosis very challenging. Numerous efforts have been done for the diagnosis of each disease but the problem of multi-class differential diagnosis has not been actively explored. In recent years, transformer-based models have demonstrated remarkable success in various computer vision tasks. However, their use in disease diagnostic is uncommon due to the limited amount of 3D medical data given the large size of such models. In this paper, we present a novel 3D transformer-based architecture using a deformable patch location module to improve the differential diagnosis of Alzheimer's disease and Frontotemporal dementia. Moreover, to overcome the problem of data scarcity, we propose an efficient combination of various data augmentation techniques, adapted for training transformer-based models on 3D structural magnetic resonance imaging data. Finally, we propose to combine our transformer-based model with a traditional machine learning model using brain structure volumes to better exploit the available data. Our experiments demonstrate the effectiveness of the proposed approach, showing competitive results compared to state-of-the-art methods. Moreover, the deformable patch locations can be visualized, revealing the most relevant brain regions used to establish the diagnosis of each disease.
</details>
<details>
<summary>摘要</summary>
阿尔茨海默病和前rontemporal dementia是常见的神经退化疾病，它们的临床表现相似，诊断非常困难。许多努力已经done for the diagnosis of each disease，但多类差分诊断还没有得到active exploration。在最近几年，transformer-based模型在各种计算机视觉任务中表现出色，但它们在疾病诊断中使用不常见，主要因为3D医疗数据的有限性，transformer-based模型的大小。本文提出了一种新的3D transformer-based架构，使用可变形矩阵定位模块以提高阿尔茨海默病和前rontemporal dementia的多类差分诊断。此外，为了解决数据稀缺的问题，我们提议了一种高效的数据扩充技术组合，适用于在3D结构磁共振成像数据上训练transformer-based模型。最后，我们提议将我们的transformer-based模型与传统机器学习模型结合，使用大脑结构体积来更好地利用可用的数据。我们的实验结果表明，提议的方法具有竞争力，与状态对照方法相比，并且可视化的可变形矩阵定位可以揭示每种疾病诊断中最重要的大脑区域。
</details></li>
</ul>
<hr>
<h2 id="SLiMe-Segment-Like-Me"><a href="#SLiMe-Segment-Like-Me" class="headerlink" title="SLiMe: Segment Like Me"></a>SLiMe: Segment Like Me</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03179">http://arxiv.org/abs/2309.03179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aliasghar Khani, Saeid Asgari Taghanaki, Aditya Sanghi, Ali Mahdavi Amiri, Ghassan Hamarneh</li>
<li>for: 这篇研究旨在提出一个单一示例的图像分类法，可以在测试阶段使用单一图像和其分类标签来构成任意细分层次的图像分类。</li>
<li>methods: 这篇研究使用大量的感知语言模型，如Stable Diffusion（SD），来实现图像分类。它将这个问题设定为一个优化任务，具体是从SD的偏好中提取注意力地图，然后将Stable Diffusion的文本嵌入优化，以让每个嵌入学习一个单一分类区域。</li>
<li>results: 研究结果显示，SLiMe可以在测试阶段使用单一图像和其分类标签来构成任意细分层次的图像分类，并且比其他一元和几元的分类方法更高效。此外，在可以使用更多训练数据时，SLiMe的性能会得到进一步提升。<details>
<summary>Abstract</summary>
Significant strides have been made using large vision-language models, like Stable Diffusion (SD), for a variety of downstream tasks, including image editing, image correspondence, and 3D shape generation. Inspired by these advancements, we explore leveraging these extensive vision-language models for segmenting images at any desired granularity using as few as one annotated sample by proposing SLiMe. SLiMe frames this problem as an optimization task. Specifically, given a single training image and its segmentation mask, we first extract attention maps, including our novel "weighted accumulated self-attention map" from the SD prior. Then, using the extracted attention maps, the text embeddings of Stable Diffusion are optimized such that, each of them, learn about a single segmented region from the training image. These learned embeddings then highlight the segmented region in the attention maps, which in turn can then be used to derive the segmentation map. This enables SLiMe to segment any real-world image during inference with the granularity of the segmented region in the training image, using just one example. Moreover, leveraging additional training data when available, i.e. few-shot, improves the performance of SLiMe. We carried out a knowledge-rich set of experiments examining various design factors and showed that SLiMe outperforms other existing one-shot and few-shot segmentation methods.
</details>
<details>
<summary>摘要</summary>
“大量视语模型，如稳定扩散（SD），在多种下游任务上取得了重要进步，包括图像编辑、图像对应和3D形状生成。受这些进步的激发，我们想要利用这些广泛的视语模型来 segment 图像，并且可以使用只有一个标注样本。我们提出了 SLime，它带有一个优化问题的框架。给定一个训练图像和其 segmentation 图像，我们首先提取注意力地图，包括我们的新的“加重累积自注意力地图”。然后，使用提取的注意力地图，Stable Diffusion 的文本嵌入被优化，以确保每个嵌入学习一个单个分割区域。这些学习的嵌入然后可以高亮分割区域在注意力地图中，并可以在推理中使用这些注意力地图来生成分割图像。这使得 SLime 可以在推理中对实际世界图像进行分割，并且可以使用只有一个标注样本。此外，当有更多的训练数据可用时，我们可以使用几个示例进行训练，从而提高 SLime 的性能。我们进行了一系列知识丰富的实验，检查了不同的设计因素，并证明了 SLime 在一shot 和几个示例下的 segmentation 方法中表现出色。”
</details></li>
</ul>
<hr>
<h2 id="3D-Object-Positioning-Using-Differentiable-Multimodal-Learning"><a href="#3D-Object-Positioning-Using-Differentiable-Multimodal-Learning" class="headerlink" title="3D Object Positioning Using Differentiable Multimodal Learning"></a>3D Object Positioning Using Differentiable Multimodal Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03177">http://arxiv.org/abs/2309.03177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sean Zanyk-McLean, Krishna Kumar, Paul Navratil</li>
<li>for: 优化计算机图形Scene中对象的位置，使其与观察者或参照对象相匹配。</li>
<li>methods: 使用模拟的激光数据via ray tracing和图像像素损失，并使用分子 descend gradient 优化对象的位置。</li>
<li>results: 使用两种感知模式（图像和激光）可以更快 converges 对象的位置，这种方法有 potential usefulness  для自动驾驶车辆，可以用于场景中多个actor的位置确定。<details>
<summary>Abstract</summary>
This article describes a multi-modal method using simulated Lidar data via ray tracing and image pixel loss with differentiable rendering to optimize an object's position with respect to an observer or some referential objects in a computer graphics scene. Object position optimization is completed using gradient descent with the loss function being influenced by both modalities. Typical object placement optimization is done using image pixel loss with differentiable rendering only, this work shows the use of a second modality (Lidar) leads to faster convergence. This method of fusing sensor input presents a potential usefulness for autonomous vehicles, as these methods can be used to establish the locations of multiple actors in a scene. This article also presents a method for the simulation of multiple types of data to be used in the training of autonomous vehicles.
</details>
<details>
<summary>摘要</summary>
这篇文章描述了一种多模态方法，使用模拟的激光数据和图像像素损失，通过可导渲染来优化对观察者或参考对象的位置在计算机图形Scene中。对象位置优化使用梯度下降，损失函数受到两种模态的影响。通常的对象放置优化只使用图像像素损失和可导渲染，这种工作表明在使用第二种感知器（激光）时，更快地 converges。这种感知器数据融合方法在自动驾驶汽车中可能有用，因为它们可以用于场景中多个actor的位置确定。这篇文章还描述了一种用于训练自动驾驶汽车的多种数据的 simulate方法。
</details></li>
</ul>
<hr>
<h2 id="PDiscoNet-Semantically-consistent-part-discovery-for-fine-grained-recognition"><a href="#PDiscoNet-Semantically-consistent-part-discovery-for-fine-grained-recognition" class="headerlink" title="PDiscoNet: Semantically consistent part discovery for fine-grained recognition"></a>PDiscoNet: Semantically consistent part discovery for fine-grained recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03173">http://arxiv.org/abs/2309.03173</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/robertdvdk/part_detection">https://github.com/robertdvdk/part_detection</a></li>
<li>paper_authors: Robert van der Klis, Stephan Alaniz, Massimiliano Mancini, Cassio F. Dantas, Dino Ienco, Zeynep Akata, Diego Marcos</li>
<li>for: 本研究旨在提高细化分类模型的准确性，通过让模型首先检测到特定物体部分，然后使用这些部分来推断类别。</li>
<li>methods: 本研究提出了PDiscoNet方法，使用图像级别的类别标签和约束，以便找出物体部分。此外，还使用部分抽取和特征向量修饰来保证每个部分具有不同的信息。</li>
<li>results: 对于CUB、CelebA和PartImageNet等数据集，PDiscoNet方法可以提供明显更好的部分发现性能，而无需进行额外的Hyperparameter调整，同时不会影响分类性能。<details>
<summary>Abstract</summary>
Fine-grained classification often requires recognizing specific object parts, such as beak shape and wing patterns for birds. Encouraging a fine-grained classification model to first detect such parts and then using them to infer the class could help us gauge whether the model is indeed looking at the right details better than with interpretability methods that provide a single attribution map. We propose PDiscoNet to discover object parts by using only image-level class labels along with priors encouraging the parts to be: discriminative, compact, distinct from each other, equivariant to rigid transforms, and active in at least some of the images. In addition to using the appropriate losses to encode these priors, we propose to use part-dropout, where full part feature vectors are dropped at once to prevent a single part from dominating in the classification, and part feature vector modulation, which makes the information coming from each part distinct from the perspective of the classifier. Our results on CUB, CelebA, and PartImageNet show that the proposed method provides substantially better part discovery performance than previous methods while not requiring any additional hyper-parameter tuning and without penalizing the classification performance. The code is available at https://github.com/robertdvdk/part_detection.
</details>
<details>
<summary>摘要</summary>
通常需要细化分类时，需要识别特定的物体部分，如鸟类的嘴形和翼模式。我们建议使用PDiscoNet来发现物体部分，使用只有图像级别的类别标签以及促进这些部分是：特异的、紧凑的、对对映变换旋转的、活跃的。此外，我们还提出使用部分排除和部分特征向量修饰，以避免单个部分占据过多的地位。我们的实验结果表明，我们的方法可以在CUB、CelebA和PartImageNet上提供显著更好的部分发现性能，而不需要进行额外的 гиперпараметр调整，也不会影响分类性能。代码可以在https://github.com/robertdvdk/part_detection上找到。
</details></li>
</ul>
<hr>
<h2 id="ResFields-Residual-Neural-Fields-for-Spatiotemporal-Signals"><a href="#ResFields-Residual-Neural-Fields-for-Spatiotemporal-Signals" class="headerlink" title="ResFields: Residual Neural Fields for Spatiotemporal Signals"></a>ResFields: Residual Neural Fields for Spatiotemporal Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03160">http://arxiv.org/abs/2309.03160</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/markomih/ResFields">https://github.com/markomih/ResFields</a></li>
<li>paper_authors: Marko Mihajlovic, Sergey Prokudin, Marc Pollefeys, Siyu Tang</li>
<li>for: 用于模型复杂的3D数据，特别是大型神经签距离场（NeRFs）或神经签距离场（SDFs）via单个多层感知器（MLP）。</li>
<li>methods:  incorporating temporal residual layers into neural fields，dubbed ResFields，a novel class of networks specifically designed to effectively represent complex temporal signals。</li>
<li>results: 提出了一种有效的方法来解决MLP的限制，并对多个复杂任务进行了全面的分析和评估，包括2D视频近似、动态形状模型化via temporal SDFs、动态NeRF重建等。<details>
<summary>Abstract</summary>
Neural fields, a category of neural networks trained to represent high-frequency signals, have gained significant attention in recent years due to their impressive performance in modeling complex 3D data, especially large neural signed distance (SDFs) or radiance fields (NeRFs) via a single multi-layer perceptron (MLP). However, despite the power and simplicity of representing signals with an MLP, these methods still face challenges when modeling large and complex temporal signals due to the limited capacity of MLPs. In this paper, we propose an effective approach to address this limitation by incorporating temporal residual layers into neural fields, dubbed ResFields, a novel class of networks specifically designed to effectively represent complex temporal signals. We conduct a comprehensive analysis of the properties of ResFields and propose a matrix factorization technique to reduce the number of trainable parameters and enhance generalization capabilities. Importantly, our formulation seamlessly integrates with existing techniques and consistently improves results across various challenging tasks: 2D video approximation, dynamic shape modeling via temporal SDFs, and dynamic NeRF reconstruction. Lastly, we demonstrate the practical utility of ResFields by showcasing its effectiveness in capturing dynamic 3D scenes from sparse sensory inputs of a lightweight capture system.
</details>
<details>
<summary>摘要</summary>
神经场（Neural Fields），一类基于神经网络的高频信号表示方法，在过去几年内受到了广泛关注，尤其是通过单一多层感知器（MLP）来表示复杂的3D数据，如大神经积分距离（SDFs）或各向异性场（NeRFs）。然而，尽管MLP具有强大和简单的表示能力，这些方法仍然面临着处理大型和复杂的时间信号的挑战，因为MLP的容量有限。在这篇论文中，我们提出了一种有效的方法，通过将时间剩余层添加到神经场中，称之为剩余场（ResFields），这种网络专门设计用于有效地表示复杂的时间信号。我们进行了全面的分析，并提出了一种矩阵分解技术来减少可训练参数的数量，提高泛化能力。重要的是，我们的方案可以兼容现有技术，并在不同的挑战任务上提供了稳定的改进。最后，我们示出了ResFields在捕捉低保持的3D场景中的实用性。
</details></li>
</ul>
<hr>
<h2 id="Do-We-Still-Need-Non-Maximum-Suppression-Accurate-Confidence-Estimates-and-Implicit-Duplication-Modeling-with-IoU-Aware-Calibration"><a href="#Do-We-Still-Need-Non-Maximum-Suppression-Accurate-Confidence-Estimates-and-Implicit-Duplication-Modeling-with-IoU-Aware-Calibration" class="headerlink" title="Do We Still Need Non-Maximum Suppression? Accurate Confidence Estimates and Implicit Duplication Modeling with IoU-Aware Calibration"></a>Do We Still Need Non-Maximum Suppression? Accurate Confidence Estimates and Implicit Duplication Modeling with IoU-Aware Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03110">http://arxiv.org/abs/2309.03110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Gilg, Torben Teepe, Fabian Herzog, Philipp Wolters, Gerhard Rigoll</li>
<li>for: 提高 object detection 系统的可靠性和可读性</li>
<li>methods: 使用 IoU-aware calibration 取代经典 NMS 后处理</li>
<li>results: 提高了 detection 的准确性和可读性，并且比标准 NMS 和 calibration 方法更高效<details>
<summary>Abstract</summary>
Object detectors are at the heart of many semi- and fully autonomous decision systems and are poised to become even more indispensable. They are, however, still lacking in accessibility and can sometimes produce unreliable predictions. Especially concerning in this regard are the -- essentially hand-crafted -- non-maximum suppression algorithms that lead to an obfuscated prediction process and biased confidence estimates. We show that we can eliminate classic NMS-style post-processing by using IoU-aware calibration. IoU-aware calibration is a conditional Beta calibration; this makes it parallelizable with no hyper-parameters. Instead of arbitrary cutoffs or discounts, it implicitly accounts for the likelihood of each detection being a duplicate and adjusts the confidence score accordingly, resulting in empirically based precision estimates for each detection. Our extensive experiments on diverse detection architectures show that the proposed IoU-aware calibration can successfully model duplicate detections and improve calibration. Compared to the standard sequential NMS and calibration approach, our joint modeling can deliver performance gains over the best NMS-based alternative while producing consistently better-calibrated confidence predictions with less complexity. The \hyperlink{https://github.com/Blueblue4/IoU-AwareCalibration}{code} for all our experiments is publicly available.
</details>
<details>
<summary>摘要</summary>
To address these issues, we propose using IoU-aware calibration, which is a conditional Beta calibration that can be parallelized with no hyperparameters. This approach eliminates the need for classic NMS-style post-processing and instead uses empirical probability estimates to model duplicate detections and improve calibration.Our extensive experiments on diverse detection architectures show that the proposed IoU-aware calibration can successfully model duplicate detections and improve calibration. Compared to the standard sequential NMS and calibration approach, our joint modeling can deliver performance gains over the best NMS-based alternative while producing consistently better-calibrated confidence predictions with less complexity. The code for all our experiments is publicly available at \hyperlink{https://github.com/Blueblue4/IoU-AwareCalibration}{https://github.com/Blueblue4/IoU-AwareCalibration}.
</details></li>
</ul>
<hr>
<h2 id="FArMARe-a-Furniture-Aware-Multi-task-methodology-for-Recommending-Apartments-based-on-the-user-interests"><a href="#FArMARe-a-Furniture-Aware-Multi-task-methodology-for-Recommending-Apartments-based-on-the-user-interests" class="headerlink" title="FArMARe: a Furniture-Aware Multi-task methodology for Recommending Apartments based on the user interests"></a>FArMARe: a Furniture-Aware Multi-task methodology for Recommending Apartments based on the user interests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03100">http://arxiv.org/abs/2309.03100</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aliabdari/farmare">https://github.com/aliabdari/farmare</a></li>
<li>paper_authors: Ali Abdari, Alex Falcon, Giuseppe Serra</li>
<li>for: 本研究旨在提供一个基于文本查询的住房推荐系统，以减少用户寻找新住所的时间过程中的困难。</li>
<li>methods: 本研究使用了一种多任务方法，名为FArMARe，它支持跨Modal对照式训练，并且具有家具感知目标。</li>
<li>results: 经过三种不同的方法和两种原始特征提取方法的实验，FArMARe 在解决这个问题上显示了优秀的效果。<details>
<summary>Abstract</summary>
Nowadays, many people frequently have to search for new accommodation options. Searching for a suitable apartment is a time-consuming process, especially because visiting them is often mandatory to assess the truthfulness of the advertisements found on the Web. While this process could be alleviated by visiting the apartments in the metaverse, the Web-based recommendation platforms are not suitable for the task. To address this shortcoming, in this paper, we define a new problem called text-to-apartment recommendation, which requires ranking the apartments based on their relevance to a textual query expressing the user's interests. To tackle this problem, we introduce FArMARe, a multi-task approach that supports cross-modal contrastive training with a furniture-aware objective. Since public datasets related to indoor scenes do not contain detailed descriptions of the furniture, we collect and annotate a dataset comprising more than 6000 apartments. A thorough experimentation with three different methods and two raw feature extraction procedures reveals the effectiveness of FArMARe in dealing with the problem at hand.
</details>
<details>
<summary>摘要</summary>
现在，许多人经常需要搜索新的住房选项。搜索一个适合的公寓是一个时间消耗的过程，特别是因为浏览它们是必需的，以确保在网上发现的广告的真实性。尽管这个过程可以通过虚拟世界中的浏览来减轻，但网络上的推荐平台并不适用于这个任务。为解决这个缺点，在这篇论文中，我们定义了一个新的问题，即文本到公寓推荐，这需要根据用户的文本查询来排序公寓的相关性。为解决这个问题，我们介绍了FArMARe，一种多任务方法，支持跨模态对比学习，并且具有家具意识的目标。由于公共 datasets related to indoor scenes 没有详细的家具描述，我们收集和注释了一个包含 más de 6000 个公寓的数据集。经过三种不同的方法和两种原始特征提取方法的实验，我们发现 FArMARe 能够成功地解决这个问题。
</details></li>
</ul>
<hr>
<h2 id="Character-Queries-A-Transformer-based-Approach-to-On-Line-Handwritten-Character-Segmentation"><a href="#Character-Queries-A-Transformer-based-Approach-to-On-Line-Handwritten-Character-Segmentation" class="headerlink" title="Character Queries: A Transformer-based Approach to On-Line Handwritten Character Segmentation"></a>Character Queries: A Transformer-based Approach to On-Line Handwritten Character Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03072">http://arxiv.org/abs/2309.03072</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jungomi/character-queries">https://github.com/jungomi/character-queries</a></li>
<li>paper_authors: Michael Jungo, Beat Wolf, Andrii Maksai, Claudiu Musat, Andreas Fischer</li>
<li>for: 本研究旨在提高在线手写文本分 segmentation的精度，具体来说是在知道转录文本的情况下，通过划分样本点和字符的匹配来实现字符的分 segmentation。</li>
<li>methods: 我们提出了一种基于 transformer 架构的方法，其中每个分区是基于学习的字符查询在 transformer 解码块中形成的。我们还考虑了多种方法来评估我们的方法的效果。</li>
<li>results: 我们在两个常用的在线手写数据集上（IAM-OnDB 和 HANDS-VNOnDB）创建了字符分 segmentation 的ground truth，并对多种方法进行评估，得到了最佳的总结果。<details>
<summary>Abstract</summary>
On-line handwritten character segmentation is often associated with handwriting recognition and even though recognition models include mechanisms to locate relevant positions during the recognition process, it is typically insufficient to produce a precise segmentation. Decoupling the segmentation from the recognition unlocks the potential to further utilize the result of the recognition. We specifically focus on the scenario where the transcription is known beforehand, in which case the character segmentation becomes an assignment problem between sampling points of the stylus trajectory and characters in the text. Inspired by the $k$-means clustering algorithm, we view it from the perspective of cluster assignment and present a Transformer-based architecture where each cluster is formed based on a learned character query in the Transformer decoder block. In order to assess the quality of our approach, we create character segmentation ground truths for two popular on-line handwriting datasets, IAM-OnDB and HANDS-VNOnDB, and evaluate multiple methods on them, demonstrating that our approach achieves the overall best results.
</details>
<details>
<summary>摘要</summary>
在线手写字符识别常常与手写识别结合在一起，即使识别模型包含了定位相关的机制，但通常还不够精确地分 segmentation。将分 segmentation 和识别解联，可以更好地利用识别结果。我们专注在已知转写的情况下，在这种情况下，字符分 segmentation 变成了对样本点轨迹和文本中的字符进行对应的对映问题。受 $k$-means 聚类算法的启发，我们从样本点轨迹的角度出发，并在Transformer底层构造中逐个形成学习的字符查询。为了评估我们的方法的质量，我们创建了两个受欢迎的在线手写数据集的字符分 segmentation 真实值，并评估了多种方法，展示了我们的方法取得了总体最好的结果。
</details></li>
</ul>
<hr>
<h2 id="Prompt-based-All-in-One-Image-Restoration-using-CNNs-and-Transformer"><a href="#Prompt-based-All-in-One-Image-Restoration-using-CNNs-and-Transformer" class="headerlink" title="Prompt-based All-in-One Image Restoration using CNNs and Transformer"></a>Prompt-based All-in-One Image Restoration using CNNs and Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03063">http://arxiv.org/abs/2309.03063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hu Gao, Jing Yang, Ning Wang, Jingfan Yang, Ying Zhang, Depeng Dang</li>
<li>for: 这个论文的目标是为了回复高质量图像从其受损观测中恢复。现有的大多数方法仅专注于单一的降低效果，因此在实际场景中不能达到最佳效果。</li>
<li>methods: 我们提出了一种数据组件指向方法，通过提取特征并使用提示来使单个模型能够有效地处理多种图像降低任务。我们使用编码器捕捉特征，并在解码器中引入提示来指导图像恢复。为了模型高质量图像恢复的地方不变性和非地方信息，我们将CNN操作和变换器结合使用。</li>
<li>results: 我们的方法可以快速和高效地处理多种图像降低任务，并且在不同的降低任务中达到了竞争力。我们的方法可以与专门的任务算法竞争，并且在实际场景中表现良好。<details>
<summary>Abstract</summary>
Image restoration aims to recover the high-quality images from their degraded observations. Since most existing methods have been dedicated into single degradation removal, they may not yield optimal results on other types of degradations, which do not satisfy the applications in real world scenarios. In this paper, we propose a novel data ingredient-oriented approach that leverages prompt-based learning to enable a single model to efficiently tackle multiple image degradation tasks. Specifically, we utilize a encoder to capture features and introduce prompts with degradation-specific information to guide the decoder in adaptively recovering images affected by various degradations. In order to model the local invariant properties and non-local information for high-quality image restoration, we combined CNNs operations and Transformers. Simultaneously, we made several key designs in the Transformer blocks (multi-head rearranged attention with prompts and simple-gate feed-forward network) to reduce computational requirements and selectively determines what information should be persevered to facilitate efficient recovery of potentially sharp images. Furthermore, we incorporate a feature fusion mechanism further explores the multi-scale information to improve the aggregated features. The resulting tightly interlinked hierarchy architecture, named as CAPTNet, despite being designed to handle different types of degradations, extensive experiments demonstrate that our method performs competitively to the task-specific algorithms.
</details>
<details>
<summary>摘要</summary>
Image restoration aimed to recover high-quality images from degraded observations. Most existing methods only focus on single degradation removal, which may not produce optimal results in real-world scenarios. In this paper, we propose a novel data ingredient-oriented approach that leverages prompt-based learning to enable a single model to efficiently handle multiple image degradation tasks. Specifically, we use an encoder to capture features and introduce prompts with degradation-specific information to guide the decoder in adaptively recovering images affected by various degradations. To model local invariant properties and non-local information for high-quality image restoration, we combined CNNs operations and Transformers. Additionally, we made several key designs in the Transformer blocks, such as multi-head rearranged attention with prompts and simple-gate feed-forward network, to reduce computational requirements and selectively preserve information to facilitate efficient recovery of potentially sharp images. Furthermore, we incorporate a feature fusion mechanism to explore multi-scale information and improve aggregated features. The resulting tightly interlinked hierarchy architecture, named CAPTNet, despite being designed to handle different types of degradations, shows competitive performance compared to task-specific algorithms through extensive experiments.
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Growth-Real-time-CNN-Layer-Expansion"><a href="#Adaptive-Growth-Real-time-CNN-Layer-Expansion" class="headerlink" title="Adaptive Growth: Real-time CNN Layer Expansion"></a>Adaptive Growth: Real-time CNN Layer Expansion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03049">http://arxiv.org/abs/2309.03049</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yunjiezhu/extensible-convolutional-layer-git-version">https://github.com/yunjiezhu/extensible-convolutional-layer-git-version</a></li>
<li>paper_authors: Yunjie Zhu, Yunhao Chen</li>
<li>for: 提高深度学习模型的适应性和效率，适用于动态环境。</li>
<li>methods: 使用动态演进层，在已有深度学习模型中扩展层的功能，通过实时评估层的表征能力，进行自适应调整。</li>
<li>results: 与超参数方法相比，实现了更高的适应性和更好的性能在多个数据集上，包括MNIST、Fashion-MNIST、CIFAR-10和CIFAR-100等。同时，在转移学习场景下也表现出了更高的适应性。<details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) have shown unparalleled achievements in numerous applications, reflecting their proficiency in managing vast data sets. Yet, their static structure limits their adaptability in ever-changing environments. This research presents a new algorithm that allows the convolutional layer of a Convolutional Neural Network (CNN) to dynamically evolve based on data input, while still being seamlessly integrated into existing DNNs. Instead of a rigid architecture, our approach iteratively introduces kernels to the convolutional layer, gauging its real-time response to varying data. This process is refined by evaluating the layer's capacity to discern image features, guiding its growth. Remarkably, our unsupervised method has outstripped its supervised counterparts across diverse datasets like MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100. It also showcases enhanced adaptability in transfer learning scenarios. By introducing a data-driven model scalability strategy, we are filling a void in deep learning, leading to more flexible and efficient DNNs suited for dynamic settings. Code:(https://github.com/YunjieZhu/Extensible-Convolutional-Layer-git-version).
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）在多个应用场景中表现出了无与伦比的成绩，彰显其对庞大数据集的管理能力。然而，它们的静态结构限制了它们在不断变化的环境中的适应性。这项研究提出了一个新的算法，允许 convolutional layer 中的 Convolutional Neural Network（CNN）在数据输入的基础上动态演化，而无需更改现有 DNN 的结构。而不是固定的 Architecture，我们的方法会在运行时逐渐添加 kernel 到 convolutional layer，根据数据的变化进行反馈，以提高它的感知度。这个过程由评估层的特征分类能力来引导，以便增强其生长。很显icht，我们的无监督方法在多个 dataset 上（如 MNIST、Fashion-MNIST、CIFAR-10 和 CIFAR-100）的表现都超过了其监督 counterpart。它还在转移学习场景中显示出了更高的适应性。我们通过引入数据驱动的模型扩展策略，填补了深度学习中的一个空白，导致更 flexible 和高效的 DNN 适用于动态场景。代码：https://github.com/YunjieZhu/Extensible-Convolutional-Layer-git-version。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Semantic-Consistency-in-Unpaired-Image-Translation-to-Generate-Data-for-Surgical-Applications"><a href="#Exploring-Semantic-Consistency-in-Unpaired-Image-Translation-to-Generate-Data-for-Surgical-Applications" class="headerlink" title="Exploring Semantic Consistency in Unpaired Image Translation to Generate Data for Surgical Applications"></a>Exploring Semantic Consistency in Unpaired Image Translation to Generate Data for Surgical Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03048">http://arxiv.org/abs/2309.03048</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danush Kumar Venkatesh, Dominik Rivoir, Micha Pfeiffer, Fiona Kolbinger, Marius Distler, Jürgen Weitz, Stefanie Speidel</li>
<li>for: 这篇论文的目的是研究无监督图像翻译技术，以生成具有高semantic consistency的大量标注数据集，用于手术计算机视觉应用。</li>
<li>methods: 这篇论文使用了多种state-of-the-art图像翻译模型，包括structural-similarity loss和contrastive learning，以提高图像翻译的semantic consistency。</li>
<li>results: 研究表明，使用这种简单的组合方法可以生成高semantic consistency的图像数据集，并且可以更有效地用于手术 semantic segmentation 任务的训练。<details>
<summary>Abstract</summary>
In surgical computer vision applications, obtaining labeled training data is challenging due to data-privacy concerns and the need for expert annotation. Unpaired image-to-image translation techniques have been explored to automatically generate large annotated datasets by translating synthetic images to the realistic domain. However, preserving the structure and semantic consistency between the input and translated images presents significant challenges, mainly when there is a distributional mismatch in the semantic characteristics of the domains. This study empirically investigates unpaired image translation methods for generating suitable data in surgical applications, explicitly focusing on semantic consistency. We extensively evaluate various state-of-the-art image translation models on two challenging surgical datasets and downstream semantic segmentation tasks. We find that a simple combination of structural-similarity loss and contrastive learning yields the most promising results. Quantitatively, we show that the data generated with this approach yields higher semantic consistency and can be used more effectively as training data.
</details>
<details>
<summary>摘要</summary>
在骨科计算机视觉应用中，获得标注数据具有数据隐私问题和专家标注的需求。不配对图像译化技术已经探索以自动生成大量标注数据，将 sintetic 图像翻译到真实域。然而，保持输入和翻译图像之间的结构和 semantics 一致存在主要挑战，特别当 semantic 特征领域的分布不同时。本研究 empirically 探究了无配对图像翻译方法在骨科应用中生成合适数据，专门关注 semantic 一致性。我们广泛评估了多种现状顶峰图像翻译模型，在两个复杂的骨科数据集和下游semantic 分割任务上进行了广泛的评估。我们发现，一种简单的结构相似损失和对比学习的组合可以获得最佳结果。量化地表明，通过这种方法生成的数据具有更高的semantic 一致性，可以更有效地作为训练数据使用。
</details></li>
</ul>
<hr>
<h2 id="MCM-Multi-condition-Motion-Synthesis-Framework-for-Multi-scenario"><a href="#MCM-Multi-condition-Motion-Synthesis-Framework-for-Multi-scenario" class="headerlink" title="MCM: Multi-condition Motion Synthesis Framework for Multi-scenario"></a>MCM: Multi-condition Motion Synthesis Framework for Multi-scenario</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03031">http://arxiv.org/abs/2309.03031</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyu Ling, Bo Han, Yongkang Wong, Mohan Kangkanhalli, Weidong Geng</li>
<li>for: 本研究的目的是解决多个条件人体动作生成任务中的多个条件输入问题，包括文本、音乐、语音等多种形式的输入。</li>
<li>methods: 本研究提出了一种新的多Condition Motion Synthesis（MCM）模型，该模型可以同时处理多个条件输入，并且可以与DDPM-like扩散模型结合使用，以保持生成能力。MCM模型包括两个分支结构，主分支和控制分支，两者具有相同的结构，并且初始化控制分支的参数与主分支的参数相同，以确保生成能力的维持。</li>
<li>results: 研究表明，MCM模型在文本到动作和音乐到舞蹈等多个任务中均达到了顶峰性能，与专门为这些任务设计的方法相当。此外，MCM模型还能够有效地实现多个条件Modal控制，实现“一次训练，动作需要”的目标。<details>
<summary>Abstract</summary>
The objective of the multi-condition human motion synthesis task is to incorporate diverse conditional inputs, encompassing various forms like text, music, speech, and more. This endows the task with the capability to adapt across multiple scenarios, ranging from text-to-motion and music-to-dance, among others. While existing research has primarily focused on single conditions, the multi-condition human motion generation remains underexplored. In this paper, we address these challenges by introducing MCM, a novel paradigm for motion synthesis that spans multiple scenarios under diverse conditions. The MCM framework is able to integrate with any DDPM-like diffusion model to accommodate multi-conditional information input while preserving its generative capabilities. Specifically, MCM employs two-branch architecture consisting of a main branch and a control branch. The control branch shares the same structure as the main branch and is initialized with the parameters of the main branch, effectively maintaining the generation ability of the main branch and supporting multi-condition input. We also introduce a Transformer-based diffusion model MWNet (DDPM-like) as our main branch that can capture the spatial complexity and inter-joint correlations in motion sequences through a channel-dimension self-attention module. Quantitative comparisons demonstrate that our approach achieves SoTA results in both text-to-motion and competitive results in music-to-dance tasks, comparable to task-specific methods. Furthermore, the qualitative evaluation shows that MCM not only streamlines the adaptation of methodologies originally designed for text-to-motion tasks to domains like music-to-dance and speech-to-gesture, eliminating the need for extensive network re-configurations but also enables effective multi-condition modal control, realizing "once trained is motion need".
</details>
<details>
<summary>摘要</summary>
目标是多个条件人体动作生成任务的多个条件人体动作生成任务，旨在涵盖多种形式，如文本、音乐、语音等。这使得任务具有适应多种场景的能力，从文本到动作和音乐到舞蹈等。现有研究主要集中在单个条件下进行研究，而多个条件人体动作生成任务仍然尚未得到充分探索。在这篇论文中，我们解决这些挑战，提出了MCM，一种新的人体动作生成模型，可以在多种条件下进行生成。MCM框架可以与任何DDPM-like扩散模型结合，并且可以同时处理多个条件输入，而不会影响生成能力。具体来说，MCM采用了两极架构，主分支和控制分支。控制分支与主分支结构相同，并且初始化为主分支的参数，以保持生成能力，同时支持多个条件输入。我们还提出了一种基于Transformer的扩散模型MWNet，它可以通过通道维度自注意模块捕捉人体动作序列中的空间复杂性和相关性。量化比较表明，我们的方法在文本到动作和音乐到舞蹈两个任务中均达到了状态艺术的结果，与专门的任务方法相当。此外，质量评估表明，MCM不仅可以将原本设计用于文本到动作任务的方法流线化到类似的音乐到舞蹈和语音到手势等领域，无需进行广泛的网络重新配置，还能够实现有效的多个条件模式控制，实现“一次训练，动作需要”。
</details></li>
</ul>
<hr>
<h2 id="SEAL-A-Framework-for-Systematic-Evaluation-of-Real-World-Super-Resolution"><a href="#SEAL-A-Framework-for-Systematic-Evaluation-of-Real-World-Super-Resolution" class="headerlink" title="SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution"></a>SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03020">http://arxiv.org/abs/2309.03020</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xpixelgroup/seal">https://github.com/xpixelgroup/seal</a></li>
<li>paper_authors: Wenlong Zhang, Xiaohui Li, Xiangyu Chen, Yu Qiao, Xiao-Ming Wu, Chao Dong</li>
<li>for: 这种研究旨在提供一个系统性的评估平台，以便对实际世界图像的超分辨率方法进行全面的评估。</li>
<li>methods: 该研究提出了一种新的评估框架，即 SEAL，它可以快速和系统地评估实际世界图像的超分辨率方法。</li>
<li>results: 该研究通过对现有的实际世界超分辨率方法进行评估，并提出了一个新的强基eline，以及两个新的评估指标（Acceptance Rate和Relative Performance Ratio），以便更好地评估实际世界图像的超分辨率方法。<details>
<summary>Abstract</summary>
Real-world Super-Resolution (real-SR) methods focus on dealing with diverse real-world images and have attracted increasing attention in recent years. The key idea is to use a complex and high-order degradation model to mimic real-world degradations. Although they have achieved impressive results in various scenarios, they are faced with the obstacle of evaluation. Currently, these methods are only assessed by their average performance on a small set of degradation cases randomly selected from a large space, which fails to provide a comprehensive understanding of their overall performance and often yields biased results. To overcome the limitation in evaluation, we propose SEAL, a framework for systematic evaluation of real-SR. In particular, we cluster the extensive degradation space to create a set of representative degradation cases, which serves as a comprehensive test set. Next, we propose a coarse-to-fine evaluation protocol to measure the distributed and relative performance of real-SR methods on the test set. The protocol incorporates two new metrics: acceptance rate (AR) and relative performance ratio (RPR), derived from an acceptance line and an excellence line. Under SEAL, we benchmark existing real-SR methods, obtain new observations and insights into their performance, and develop a new strong baseline. We consider SEAL as the first step towards creating an unbiased and comprehensive evaluation platform, which can promote the development of real-SR.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Sparse-3D-Reconstruction-via-Object-Centric-Ray-Sampling"><a href="#Sparse-3D-Reconstruction-via-Object-Centric-Ray-Sampling" class="headerlink" title="Sparse 3D Reconstruction via Object-Centric Ray Sampling"></a>Sparse 3D Reconstruction via Object-Centric Ray Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03008">http://arxiv.org/abs/2309.03008</a></li>
<li>repo_url: None</li>
<li>paper_authors: Llukman Cerkezi, Paolo Favaro</li>
<li>for: 3D object reconstruction from a sparse set of views captured from a 360-degree calibrated camera rig</li>
<li>methods: hybrid model using both MLP-based neural representation and triangle mesh, object-centric sampling scheme of the neural representation, and differentiable renderer</li>
<li>results: state of the art 3D reconstructions, does not require additional supervision of segmentation masks, works with sparse views on several datasets (Google’s Scanned Objects, Tank and Temples, and MVMC Car)<details>
<summary>Abstract</summary>
We propose a novel method for 3D object reconstruction from a sparse set of views captured from a 360-degree calibrated camera rig. We represent the object surface through a hybrid model that uses both an MLP-based neural representation and a triangle mesh. A key contribution in our work is a novel object-centric sampling scheme of the neural representation, where rays are shared among all views. This efficiently concentrates and reduces the number of samples used to update the neural model at each iteration. This sampling scheme relies on the mesh representation to ensure also that samples are well-distributed along its normals. The rendering is then performed efficiently by a differentiable renderer. We demonstrate that this sampling scheme results in a more effective training of the neural representation, does not require the additional supervision of segmentation masks, yields state of the art 3D reconstructions, and works with sparse views on the Google's Scanned Objects, Tank and Temples and MVMC Car datasets.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的3D物体重建方法，使用一个稀疏视图集 captured from一个360度准备好的相机环境。我们表示物体表面通过一种混合模型，这里使用MLP基于神经网络表示以及三角形网格。我们的研究所提供了一种新的物体中心的采样方案，其中光束被所有视图共享。这种采样方案基于网格表示，以确保采样点均匀分布在网格轴上。然后，我们使用可导渠渲染器进行高效渲染。我们示出了这种采样方案能够更有效地训练神经网络，不需要额外的分 segmentation 标注，实现了状态的arte 3D重建，并在Google Scanned Objects、Tank和Temples以及MVMC Car数据集上达到了最佳效果。
</details></li>
</ul>
<hr>
<h2 id="Vote2Cap-DETR-Decoupling-Localization-and-Describing-for-End-to-End-3D-Dense-Captioning"><a href="#Vote2Cap-DETR-Decoupling-Localization-and-Describing-for-End-to-End-3D-Dense-Captioning" class="headerlink" title="Vote2Cap-DETR++: Decoupling Localization and Describing for End-to-End 3D Dense Captioning"></a>Vote2Cap-DETR++: Decoupling Localization and Describing for End-to-End 3D Dense Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02999">http://arxiv.org/abs/2309.02999</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ch3cook-fdu/vote2cap-detr">https://github.com/ch3cook-fdu/vote2cap-detr</a></li>
<li>paper_authors: Sijin Chen, Hongyuan Zhu, Mingsheng Li, Xin Chen, Peng Guo, Yinjie Lei, Gang Yu, Taihao Li, Tao Chen</li>
<li>for: 本研究旨在提出一种简单 yet effective的 transformer框架，以便在3D scene中进行详细描述。</li>
<li>methods: 本研究使用了分解预测和迭代 espacial refinement 策略，以提高 caption 生成和对象定位的准确性。</li>
<li>results: 对 ScanRefer 和 Nr3D 两个常用数据集进行了广泛的实验，结果表明 Vote2Cap-DETR 和 Vote2Cap-DETR++ 超过了传统的 “detect-then-describe” 方法，并且可以快速地生成详细的 caption。<details>
<summary>Abstract</summary>
3D dense captioning requires a model to translate its understanding of an input 3D scene into several captions associated with different object regions. Existing methods adopt a sophisticated "detect-then-describe" pipeline, which builds explicit relation modules upon a 3D detector with numerous hand-crafted components. While these methods have achieved initial success, the cascade pipeline tends to accumulate errors because of duplicated and inaccurate box estimations and messy 3D scenes. In this paper, we first propose Vote2Cap-DETR, a simple-yet-effective transformer framework that decouples the decoding process of caption generation and object localization through parallel decoding. Moreover, we argue that object localization and description generation require different levels of scene understanding, which could be challenging for a shared set of queries to capture. To this end, we propose an advanced version, Vote2Cap-DETR++, which decouples the queries into localization and caption queries to capture task-specific features. Additionally, we introduce the iterative spatial refinement strategy to vote queries for faster convergence and better localization performance. We also insert additional spatial information to the caption head for more accurate descriptions. Without bells and whistles, extensive experiments on two commonly used datasets, ScanRefer and Nr3D, demonstrate Vote2Cap-DETR and Vote2Cap-DETR++ surpass conventional "detect-then-describe" methods by a large margin. Codes will be made available at https://github.com/ch3cook-fdu/Vote2Cap-DETR.
</details>
<details>
<summary>摘要</summary>
3D dense captioning需要一个模型将输入3D场景的理解翻译成多个关联于不同对象区域的caption。现有方法采用复杂的"检测然后描述"管道，其中建立了许多手动设计的组件。虽然这些方法已经实现了初步的成功，但cascade管道往往会积累错误，因为重复的和不准确的盒式估计以及混乱的3D场景。在这篇论文中，我们首先提出了Vote2Cap-DETR，一个简单又有效的转换器框架，该框架通过平行解码来解耦描述生成和对象定位的过程。此外，我们认为对象定位和描述生成需要不同水平的场景理解，这可能会在一组共享的查询中捕捉到挑战。为此，我们提出了Vote2Cap-DETR++，一个进一步的版本，该版本将查询分解成定位和描述查询，以捕捉任务特有的特征。此外，我们还引入了迭代空间重定位策略，以便更快地 converges和更好地定位性能。此外，我们还将空间信息添加到描述头部，以提高描述的准确性。无需额外的钻掘和细节，我们在两个常用的数据集ScanRefer和Nr3D上进行了广泛的实验，并证明Vote2Cap-DETR和Vote2Cap-DETR++在"检测然后描述"方法的基础上超过了 conventinal方法的表现。代码将在https://github.com/ch3cook-fdu/Vote2Cap-DETR上提供。
</details></li>
</ul>
<hr>
<h2 id="Continual-Evidential-Deep-Learning-for-Out-of-Distribution-Detection"><a href="#Continual-Evidential-Deep-Learning-for-Out-of-Distribution-Detection" class="headerlink" title="Continual Evidential Deep Learning for Out-of-Distribution Detection"></a>Continual Evidential Deep Learning for Out-of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02995">http://arxiv.org/abs/2309.02995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo Aguilar, Bogdan Raducanu, Petia Radeva, Joost Van de Weijer</li>
<li>for: 这个研究旨在实现同时进行增执分类和异数数据检测，并且使用证据深度学习方法进行离散数据检测。</li>
<li>methods: 本研究提出了一个称为CEDL的方法，它结合了证据深度学习方法和增执学习框架，以便同时进行增执分类和异数数据检测。</li>
<li>results: 根据实验结果显示，CEDL方法在CIFAR-100数据集上，在5和10任务设置下，均能够提供比基eline更好的Object Classification结果，并且在OOD检测方面也能够大幅超过多种后勤方法的评估结果。<details>
<summary>Abstract</summary>
Uncertainty-based deep learning models have attracted a great deal of interest for their ability to provide accurate and reliable predictions. Evidential deep learning stands out achieving remarkable performance in detecting out-of-distribution (OOD) data with a single deterministic neural network. Motivated by this fact, in this paper we propose the integration of an evidential deep learning method into a continual learning framework in order to perform simultaneously incremental object classification and OOD detection. Moreover, we analyze the ability of vacuity and dissonance to differentiate between in-distribution data belonging to old classes and OOD data. The proposed method, called CEDL, is evaluated on CIFAR-100 considering two settings consisting of 5 and 10 tasks, respectively. From the obtained results, we could appreciate that the proposed method, in addition to provide comparable results in object classification with respect to the baseline, largely outperforms OOD detection compared to several posthoc methods on three evaluation metrics: AUROC, AUPR and FPR95.
</details>
<details>
<summary>摘要</summary>
“uncertainty-based深度学习模型在提供准确和可靠预测方面吸引了很大的关注。证明深度学习在探测出现在数据集之外的数据时表现出色，我们在这篇论文中提出了将证明深度学习方法 integrate into continual learning框架，以同时进行逐步类别和对外数据检测。此外，我们还分析了真空和矛盾的能力，用于 отличить在数据集中的老类和外数据。我们提出的方法，称为CEDL，在CIFAR-100上进行了5和10任务的评估。结果显示，我们的方法不仅与基eline相当的对象分类结果，而且在OOD检测中也大幅超越了多个后处方法，以三个评估指标：AUROC、AUPR和FPR95来评估。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I will be happy to provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="FishMOT-A-Simple-and-Effective-Method-for-Fish-Tracking-Based-on-IoU-Matching"><a href="#FishMOT-A-Simple-and-Effective-Method-for-Fish-Tracking-Based-on-IoU-Matching" class="headerlink" title="FishMOT: A Simple and Effective Method for Fish Tracking Based on IoU Matching"></a>FishMOT: A Simple and Effective Method for Fish Tracking Based on IoU Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02975">http://arxiv.org/abs/2309.02975</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gakkistar/fishmot">https://github.com/gakkistar/fishmot</a></li>
<li>paper_authors: Shuo Liu, Lulu Han, Xiaoyang Liu, Junli Ren, Fang Wang, Yuanshan Lin</li>
<li>for: 这篇论文旨在提供一个高精度、可靠的鱼类追踪方法，以应对鱼类行为和生态学研究中的追踪挑战。</li>
<li>methods: 本论文提出了一个称为FishMOT（鱼类多对象追踪）的新型鱼类追踪方法，它结合了物体检测和IoU匹配，包括基本模组、互动模组和发现模组。在这些模组中，基本模组通过IoU的识别码来进行目标协调，互动模组将IoU的识别码和鱼类物体的IoU进行融合，以应对鱼类间的遮挡；发现模组则使用空间时间信息来超越由检测器在复杂环境中缺失检测所导致的追踪失败。</li>
<li>results: 实验结果显示，FishMOT比前一代多对象追踪器和特化的鱼类追踪工具在MOTA、精度、计算时间、内存consumption等方面表现更好，并且具有优秀的一致性和通用性。<details>
<summary>Abstract</summary>
Fish tracking plays a vital role in understanding fish behavior and ecology. However, existing tracking methods face challenges in accuracy and robustness dues to morphological change of fish, occlusion and complex environment. This paper proposes FishMOT(Multiple Object Tracking for Fish), a novel fish tracking approach combining object detection and IoU matching, including basic module, interaction module and refind module. Wherein, a basic module performs target association based on IoU of detection boxes between successive frames to deal with morphological change of fish; an interaction module combines IoU of detection boxes and IoU of fish entity to handle occlusions; a refind module use spatio-temporal information uses spatio-temporal information to overcome the tracking failure resulting from the missed detection by the detector under complex environment. FishMOT reduces the computational complexity and memory consumption since it does not require complex feature extraction or identity assignment per fish, and does not need Kalman filter to predict the detection boxes of successive frame. Experimental results demonstrate FishMOT outperforms state-of-the-art multi-object trackers and specialized fish tracking tools in terms of MOTA, accuracy, computation time, memory consumption, etc.. Furthermore, the method exhibits excellent robustness and generalizability for varying environments and fish numbers. The simplified workflow and strong performance make FishMOT as a highly effective fish tracking approach. The source codes and pre-trained models are available at: https://github.com/gakkistar/FishMOT
</details>
<details>
<summary>摘要</summary>
鱼类跟踪对鱼类行为和生态学理解具有重要作用。然而，现有的跟踪方法面临着准确性和可靠性的挑战，主要是因为鱼类形态变化、遮挡和复杂的环境。本文提出了鱼类MOT（多对目标跟踪 для鱼类），一种新的鱼类跟踪方法， combining 对象检测和IoU匹配，包括基本模块、交互模块和重新找模块。其中，基本模块通过IoU的检测盒子在不同帧之间进行目标关联，以处理鱼类形态变化;交互模块将IoU的检测盒子和鱼类实体IoU组合以处理遮挡;重新找模块使用空间时间信息以超越由检测器在复杂环境中 missed 检测而导致的跟踪失败。鱼类MOT减少了计算复杂性和内存占用，因为它不需要复杂的特征提取或鱼类特征分配，也不需要 kalman 筛选器来预测下一帧的检测盒子。实验结果表明，鱼类MOT 在 MOTA、准确率、计算时间、内存占用等方面比状态艺术多对象跟踪器和专门的鱼类跟踪工具更高。此外，方法具有优秀的抗难度和普适性，可以在不同环境和鱼类数量下展现出优秀的表现。简化的工作流程和强大的表现使得鱼类MOT 成为一种非常有效的鱼类跟踪方法。源代码和预训练模型可以在以下链接中获取：https://github.com/gakkistar/FishMOT
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Hyperbolic-Attention-Network-for-Fine-Hand-object-Reconstruction"><a href="#Dynamic-Hyperbolic-Attention-Network-for-Fine-Hand-object-Reconstruction" class="headerlink" title="Dynamic Hyperbolic Attention Network for Fine Hand-object Reconstruction"></a>Dynamic Hyperbolic Attention Network for Fine Hand-object Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02965">http://arxiv.org/abs/2309.02965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiying Leng, Shun-Cheng Wu, Mahdi Saleh, Antonio Montanaro, Hao Yu, Yin Wang, Nassir Navab, Xiaohui Liang, Federico Tombari</li>
<li>for: 本研究旨在提出一种基于贝叶斯空间的精确手object reconstruction方法，以便更好地学习手object的特征。</li>
<li>methods: 该方法基于贝叶斯空间的特性，包括强制学习的图像特征和多模态特征，以及一种名为动态贝叶斯注意力网络（DHANet）。</li>
<li>results: 对于三个公共数据集，该方法比大多数现有方法表现更好，提供了一个可行的手object reconstruction方案。<details>
<summary>Abstract</summary>
Reconstructing both objects and hands in 3D from a single RGB image is complex. Existing methods rely on manually defined hand-object constraints in Euclidean space, leading to suboptimal feature learning. Compared with Euclidean space, hyperbolic space better preserves the geometric properties of meshes thanks to its exponentially-growing space distance, which amplifies the differences between the features based on similarity. In this work, we propose the first precise hand-object reconstruction method in hyperbolic space, namely Dynamic Hyperbolic Attention Network (DHANet), which leverages intrinsic properties of hyperbolic space to learn representative features. Our method that projects mesh and image features into a unified hyperbolic space includes two modules, ie. dynamic hyperbolic graph convolution and image-attention hyperbolic graph convolution. With these two modules, our method learns mesh features with rich geometry-image multi-modal information and models better hand-object interaction. Our method provides a promising alternative for fine hand-object reconstruction in hyperbolic space. Extensive experiments on three public datasets demonstrate that our method outperforms most state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
重构对象和手在3D从单个RGB图像中是复杂的。现有方法通过手动定义在欧式空间中的手-对象约束，导致特征学习不优化。相比欧式空间，拥有快速增长的空间距离的拓扑空间更好地保持 mesh 的几何性质，因为它将相似性基于的特征强调。在这种工作中，我们提出了首个在拓扑空间中精确重建手-对象方法，即动态拓扑空间注意力网络（DHANet），该方法利用拓扑空间的内在属性来学习表示性的特征。我们的方法将 mesh 和图像特征投影到一个统一的拓扑空间中，包括动态拓扑图 convolution 和图像注意力拓扑图 convolution。通过这两个模块，我们的方法学习了具有丰富几何-图像多模式信息的 mesh 特征，并更好地模型手-对象互动。我们的方法为精确手-对象重建在拓扑空间提供了一个有前途的代替。我们在三个公共数据集上进行了广泛的实验，并证明了我们的方法在大多数状态前方法之上。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-level-rain-image-generative-model-based-on-GAN"><a href="#Hierarchical-level-rain-image-generative-model-based-on-GAN" class="headerlink" title="Hierarchical-level rain image generative model based on GAN"></a>Hierarchical-level rain image generative model based on GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02964">http://arxiv.org/abs/2309.02964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenyuan Liu, Tong Jia, Xingyu Xing, Jianfeng Wu, Junyi Chen</li>
<li>for: 提高自动驾驶车Visual perception系统的性能下限问题（SOTIF），通过生成不同雨强度的图像数据来测试雨天下Visual perception算法的性能。</li>
<li>methods: 基于生成对抗网络（GAN）的 Hierarchical-level雨图生成模型（RCCycleGAN），可以生成不同雨强度的图像。采用Conditional GAN（CGAN）的方式，将不同雨强度作为标签进行分类。同时，对模型结构进行优化，并调整训练策略以解决模式混合问题。</li>
<li>results: 比基eline模型CycleGAN和DerainCycleGAN的 peak signal-to-noise ratio（PSNR）和structural similarity（SSIM）指标都有显著提高，具体是2.58 dB和0.74 dB，增加了18%和8%。进行了ablation实验以验证模型调整的有效性。<details>
<summary>Abstract</summary>
Autonomous vehicles are exposed to various weather during operation, which is likely to trigger the performance limitations of the perception system, leading to the safety of the intended functionality (SOTIF) problems. To efficiently generate data for testing the performance of visual perception algorithms under various weather conditions, a hierarchical-level rain image generative model, rain conditional CycleGAN (RCCycleGAN), is constructed. RCCycleGAN is based on the generative adversarial network (GAN) and can generate images of light, medium, and heavy rain. Different rain intensities are introduced as labels in conditional GAN (CGAN). Meanwhile, the model structure is optimized and the training strategy is adjusted to alleviate the problem of mode collapse. In addition, natural rain images of different intensities are collected and processed for model training and validation. Compared with the two baseline models, CycleGAN and DerainCycleGAN, the peak signal-to-noise ratio (PSNR) of RCCycleGAN on the test dataset is improved by 2.58 dB and 0.74 dB, and the structural similarity (SSIM) is improved by 18% and 8%, respectively. The ablation experiments are also carried out to validate the effectiveness of the model tuning.
</details>
<details>
<summary>摘要</summary>
自动驾驶车辆在运行过程中可能会遭遇不同的天气条件，这可能会导致感知系统的性能限制，从而导致安全功能（SOTIF）问题。为了效率地生成测试感知算法在不同天气条件下的性能数据，我们构建了一个层次结构的雨图生成模型，即雨条件的CycleGAN（RCCycleGAN）。RCCycleGAN基于生成对抗网络（GAN），可以生成不同雨强度的雨图。雨强度被用作CGAN中的标签。此外，模型结构优化和训练策略调整，以解决模式混合问题。此外，我们还收集了不同雨强度的自然雨图，用于模型训练和验证。与基eline模型CycleGAN和DerainCycleGAN相比，RCCycleGAN在测试集上的PSNR提高2.58dB和0.74dB，SSIM提高18%和8%。我们还进行了减少效果的实验来验证模型调整的有效性。
</details></li>
</ul>
<hr>
<h2 id="Indoor-Localization-Using-Radio-Vision-and-Audio-Sensors-Real-Life-Data-Validation-and-Discussion"><a href="#Indoor-Localization-Using-Radio-Vision-and-Audio-Sensors-Real-Life-Data-Validation-and-Discussion" class="headerlink" title="Indoor Localization Using Radio, Vision and Audio Sensors: Real-Life Data Validation and Discussion"></a>Indoor Localization Using Radio, Vision and Audio Sensors: Real-Life Data Validation and Discussion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02961">http://arxiv.org/abs/2309.02961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilayda Yaman, Guoda Tian, Erik Tegler, Patrik Persson, Nikhil Challa, Fredrik Tufvesson, Ove Edfors, Kalle Astrom, Steffen Malkowsky, Liang Liu</li>
<li>for: 本研究探讨了使用Radio、视觉和声音感知器在同一环境中进行indoor定位方法。</li>
<li>methods: 本研究使用了现代算法和实际数据进行评估，包括使用巨量MIMO技术的机器学习算法 дляRadio定位、使用RGB-D摄像头的ORB-SLAM3算法 для视觉定位、以及使用麦克风数组的SFS2算法 для声音定位。</li>
<li>results: 本研究发现了不同感知器的定位精度、可靠性、准备需求和可能的系统复杂性等方面的优劣点，并提供了一个基础和引导 для进一步发展高精度多感知定位系统，如感知融合和上下文和环境意识适应。<details>
<summary>Abstract</summary>
This paper investigates indoor localization methods using radio, vision, and audio sensors, respectively, in the same environment. The evaluation is based on state-of-the-art algorithms and uses a real-life dataset. More specifically, we evaluate a machine learning algorithm for radio-based localization with massive MIMO technology, an ORB-SLAM3 algorithm for vision-based localization with an RGB-D camera, and an SFS2 algorithm for audio-based localization with microphone arrays. Aspects including localization accuracy, reliability, calibration requirements, and potential system complexity are discussed to analyze the advantages and limitations of using different sensors for indoor localization tasks. The results can serve as a guideline and basis for further development of robust and high-precision multi-sensory localization systems, e.g., through sensor fusion and context and environment-aware adaptation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Non-Invasive-Interpretable-NAFLD-Diagnostic-Method-Combining-TCM-Tongue-Features"><a href="#A-Non-Invasive-Interpretable-NAFLD-Diagnostic-Method-Combining-TCM-Tongue-Features" class="headerlink" title="A Non-Invasive Interpretable NAFLD Diagnostic Method Combining TCM Tongue Features"></a>A Non-Invasive Interpretable NAFLD Diagnostic Method Combining TCM Tongue Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02959">http://arxiv.org/abs/2309.02959</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cshan-github/selectornet">https://github.com/cshan-github/selectornet</a></li>
<li>paper_authors: Shan Cao, Qunsheng Ruan, Qingfeng Wu</li>
<li>for: 这个研究是为了提出一个非侵入性的、可解释的非酒精肝病诊断方法，并且仅需要用户提供的数据是年龄、性别、身高、体重、腰围和脐围，以及舌头图像。</li>
<li>methods: 这个方法使用了融合病人的生物体指标和舌头特征，然后将其输入到名为SelectorNet的融合网络中，SelectorNet包括了注意力机制和特征选择机制，可以自动学习选择重要的特征。</li>
<li>results: 实验结果显示，提出的方法可以使用非侵入性数据 achieve an accuracy of 77.22%，并且提供了吸引人的解释矩阵。<details>
<summary>Abstract</summary>
Non-alcoholic fatty liver disease (NAFLD) is a clinicopathological syndrome characterized by hepatic steatosis resulting from the exclusion of alcohol and other identifiable liver-damaging factors. It has emerged as a leading cause of chronic liver disease worldwide. Currently, the conventional methods for NAFLD detection are expensive and not suitable for users to perform daily diagnostics. To address this issue, this study proposes a non-invasive and interpretable NAFLD diagnostic method, the required user-provided indicators are only Gender, Age, Height, Weight, Waist Circumference, Hip Circumference, and tongue image. This method involves merging patients' physiological indicators with tongue features, which are then input into a fusion network named SelectorNet. SelectorNet combines attention mechanisms with feature selection mechanisms, enabling it to autonomously learn the ability to select important features. The experimental results show that the proposed method achieves an accuracy of 77.22\% using only non-invasive data, and it also provides compelling interpretability matrices. This study contributes to the early diagnosis of NAFLD and the intelligent advancement of TCM tongue diagnosis. The project in this paper is available at: https://github.com/cshan-github/SelectorNet.
</details>
<details>
<summary>摘要</summary>
(Note: Simplified Chinese is used in this translation, as it is more widely used in mainland China and is the standard form of Chinese used in education and government. Traditional Chinese is used in Hong Kong, Macau, and Taiwan.)
</details></li>
</ul>
<hr>
<h2 id="Robust-Visual-Tracking-by-Motion-Analyzing"><a href="#Robust-Visual-Tracking-by-Motion-Analyzing" class="headerlink" title="Robust Visual Tracking by Motion Analyzing"></a>Robust Visual Tracking by Motion Analyzing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03247">http://arxiv.org/abs/2309.03247</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/XJLeoYu/Robust-Visual-Tracking-by-Motion-Analyzing">https://github.com/XJLeoYu/Robust-Visual-Tracking-by-Motion-Analyzing</a></li>
<li>paper_authors: Mohammed Leo, Kurban Ubul, ShengJie Cheng, Michael Ma</li>
<li>for: 这篇论文旨在提出一种新的视频对象分割算法，以提高视频对象跟踪（VOT）的精度和效率。</li>
<li>methods: 该算法使用了tensor结构来描述目标的运动模式，并将其 integrate into the segmentation module。</li>
<li>results: 该算法在四个 benchmark（LaSOT\cite{fan2019lasot}, AVisT\cite{noman2022avist}, OTB100\cite{7001050}, GOT-10k\cite{huang2019got}) 上达到了SOTA的结果，并且具有实时运行的能力。<details>
<summary>Abstract</summary>
In recent years, Video Object Segmentation (VOS) has emerged as a complementary method to Video Object Tracking (VOT). VOS focuses on classifying all the pixels around the target, allowing for precise shape labeling, while VOT primarily focuses on the approximate region where the target might be. However, traditional segmentation modules usually classify pixels frame by frame, disregarding information between adjacent frames.   In this paper, we propose a new algorithm that addresses this limitation by analyzing the motion pattern using the inherent tensor structure. The tensor structure, obtained through Tucker2 tensor decomposition, proves to be effective in describing the target's motion. By incorporating this information, we achieved competitive results on Four benchmarks LaSOT\cite{fan2019lasot}, AVisT\cite{noman2022avist}, OTB100\cite{7001050}, and GOT-10k\cite{huang2019got} LaSOT\cite{fan2019lasot} with SOTA. Furthermore, the proposed tracker is capable of real-time operation, adding value to its practical application.
</details>
<details>
<summary>摘要</summary>
近年来，视频对象分割（VOS）作为对象跟踪（VOT）的补充方法而出现。VOS专注于将目标周围的所有像素分类，以获得精确的形态标注，而VOT主要关注目标的可能存在的短区域。然而，传统的分割模块通常frame by frame来分类像素，忽略了邻帧信息。在这篇论文中，我们提出了一种新的算法，通过利用内在的维度结构来解决这一限制。这种维度结构通过图kernels decomposition获得，并证明了其在目标运动中的效果。通过 incorporating这种信息，我们实现了在四个benchmark上达到了SOTA的竞争性成绩，分别是LaSOT\cite{fan2019lasot}, Avist\cite{noman2022avist}, OTB100\cite{7001050}和GOT-10k\cite{huang2019got}。此外，我们的追踪器还具有实时运行的能力，增加了其在实际应用中的价值。
</details></li>
</ul>
<hr>
<h2 id="M3D-NCA-Robust-3D-Segmentation-with-Built-in-Quality-Control"><a href="#M3D-NCA-Robust-3D-Segmentation-with-Built-in-Quality-Control" class="headerlink" title="M3D-NCA: Robust 3D Segmentation with Built-in Quality Control"></a>M3D-NCA: Robust 3D Segmentation with Built-in Quality Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02954">http://arxiv.org/abs/2309.02954</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Kalkhof, Anirban Mukhopadhyay</li>
<li>for: 这篇论文的目的是提出一种基于神经细胞自动机（NCA）的三维医疗影像分类方法，以提高资源受限的医疗设施和冲突区域中的医疗影像分类效能。</li>
<li>methods: 这篇论文使用的方法是基于NCA的三维医疗影像分类方法，通过n级融合来实现。此外，这篇论文还提出了一个基于M3D-NCA的质量指标，可以自动检测NCAs中的错误。</li>
<li>results: 这篇论文的结果显示，M3D-NCA在脑干和膀胱分类中比据两个较大的UNet模型高出2%的 dice值，并且可以在Raspberry Pi 4 Model B（2GB RAM）上运行。这显示M3D-NCA可能是一个有效和高效的医疗影像分类方法，特别是在资源受限的医疗设施和冲突区域中。<details>
<summary>Abstract</summary>
Medical image segmentation relies heavily on large-scale deep learning models, such as UNet-based architectures. However, the real-world utility of such models is limited by their high computational requirements, which makes them impractical for resource-constrained environments such as primary care facilities and conflict zones. Furthermore, shifts in the imaging domain can render these models ineffective and even compromise patient safety if such errors go undetected. To address these challenges, we propose M3D-NCA, a novel methodology that leverages Neural Cellular Automata (NCA) segmentation for 3D medical images using n-level patchification. Moreover, we exploit the variance in M3D-NCA to develop a novel quality metric which can automatically detect errors in the segmentation process of NCAs. M3D-NCA outperforms the two magnitudes larger UNet models in hippocampus and prostate segmentation by 2% Dice and can be run on a Raspberry Pi 4 Model B (2GB RAM). This highlights the potential of M3D-NCA as an effective and efficient alternative for medical image segmentation in resource-constrained environments.
</details>
<details>
<summary>摘要</summary>
医疗图像分割依赖大规模深度学习模型，如UNet基 architecture。然而，这些模型在实际应用中受限于高计算需求，使其不适用于资源有限的环境，如初级医疗机构和冲突区域。此外，图像领域的变化可能使这些模型无效，甚至威胁 patient safety 如果这些错误未探测。为Addressing these challenges, we propose M3D-NCA，一种新的方法，利用神经细胞自动机(NCA) segmentation for 3D medical images using n-level patchification。此外，我们利用 M3D-NCA 的变异来开发一种新的质量指标，可以自动探测 NCAs 分割过程中的错误。M3D-NCA 在 hippocampus 和 prostate 分割方面比 UNet 模型两倍大的范围内出performanced by 2% Dice，并且可以在 Raspberry Pi 4 Model B (2GB RAM) 上运行。这些结果表明 M3D-NCA 可以作为医疗图像分割的有效和高效的替代方案。
</details></li>
</ul>
<hr>
<h2 id="Patched-Line-Segment-Learning-for-Vector-Road-Mapping"><a href="#Patched-Line-Segment-Learning-for-Vector-Road-Mapping" class="headerlink" title="Patched Line Segment Learning for Vector Road Mapping"></a>Patched Line Segment Learning for Vector Road Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02923">http://arxiv.org/abs/2309.02923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiakun Xu, Bowen Xu, Gui-Song Xia, Liang Dong, Nan Xue</li>
<li>for: 本研究提出了一种新的方法，用于从卫星遥感图像中计算向量道路地图。</li>
<li>methods: 该方法使用线段来表示路径，不仅捕捉了路径的位置，还捕捉了路径的方向，使其成为一种强大的表示方式。</li>
<li>results: 在我们的实验中，我们发现使用有效的路径表示可以大幅提高向量道路映射的性能，而不需要对神经网络架构进行大量修改。此外，我们的方法只需6个GPU小时的训练，相比之下，已有的方法需要32倍的训练时间。<details>
<summary>Abstract</summary>
This paper presents a novel approach to computing vector road maps from satellite remotely sensed images, building upon a well-defined Patched Line Segment (PaLiS) representation for road graphs that holds geometric significance. Unlike prevailing methods that derive road vector representations from satellite images using binary masks or keypoints, our method employs line segments. These segments not only convey road locations but also capture their orientations, making them a robust choice for representation. More precisely, given an input image, we divide it into non-overlapping patches and predict a suitable line segment within each patch. This strategy enables us to capture spatial and structural cues from these patch-based line segments, simplifying the process of constructing the road network graph without the necessity of additional neural networks for connectivity. In our experiments, we demonstrate how an effective representation of a road graph significantly enhances the performance of vector road mapping on established benchmarks, without requiring extensive modifications to the neural network architecture. Furthermore, our method achieves state-of-the-art performance with just 6 GPU hours of training, leading to a substantial 32-fold reduction in training costs in terms of GPU hours.
</details>
<details>
<summary>摘要</summary>
Specifically, we divide the input image into non-overlapping patches and predict a suitable line segment within each patch. This allows us to capture spatial and structural cues from these patch-based line segments, simplifying the process of constructing the road network graph without the need for additional neural networks for connectivity.In our experiments, we show how our effective representation of the road graph significantly enhances the performance of vector road mapping on established benchmarks, without requiring extensive modifications to the neural network architecture. Additionally, our method achieves state-of-the-art performance with just 6 GPU hours of training, leading to a substantial 32-fold reduction in training costs in terms of GPU hours.
</details></li>
</ul>
<hr>
<h2 id="Towards-Efficient-Training-with-Negative-Samples-in-Visual-Tracking"><a href="#Towards-Efficient-Training-with-Negative-Samples-in-Visual-Tracking" class="headerlink" title="Towards Efficient Training with Negative Samples in Visual Tracking"></a>Towards Efficient Training with Negative Samples in Visual Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02903">http://arxiv.org/abs/2309.02903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingmao Wei, Bi Zeng, Guotian Zeng</li>
<li>for: 降低现代视觉对象跟踪方法中的计算资源和训练数据量，以避免过拟合。</li>
<li>methods: 该研究提出了一种更加高效的训练策略，通过将负样本与正样本混合，即 JOINT LEARNING WITH NEGATIVE SAMPLES（JN），以防止模型僵化并强制它使用模板来定位目标。此外，我们采用了分布型头，以表达在负样本下的uncertainty，从而有效地处理负样本。</li>
<li>results: 我们的模型JN-256在挑战性评价 benchmark上达到了75.8% AO 和 84.1% AUC，超过了以前的SOTA tracker，即使使用更大的模型和更高的输入分辨率。另外，JN-256 在训练时使用的数据量只有半个以前的works使用的样本数。<details>
<summary>Abstract</summary>
Current state-of-the-art (SOTA) methods in visual object tracking often require extensive computational resources and vast amounts of training data, leading to a risk of overfitting. This study introduces a more efficient training strategy to mitigate overfitting and reduce computational requirements. We balance the training process with a mix of negative and positive samples from the outset, named as Joint learning with Negative samples (JN). Negative samples refer to scenarios where the object from the template is not present in the search region, which helps to prevent the model from simply memorizing the target, and instead encourages it to use the template for object location. To handle the negative samples effectively, we adopt a distribution-based head, which modeling the bounding box as distribution of distances to express uncertainty about the target's location in the presence of negative samples, offering an efficient way to manage the mixed sample training. Furthermore, our approach introduces a target-indicating token. It encapsulates the target's precise location within the template image. This method provides exact boundary details with negligible computational cost but improving performance. Our model, JN-256, exhibits superior performance on challenging benchmarks, achieving 75.8% AO on GOT-10k and 84.1% AUC on TrackingNet. Notably, JN-256 outperforms previous SOTA trackers that utilize larger models and higher input resolutions, even though it is trained with only half the number of data sampled used in those works.
</details>
<details>
<summary>摘要</summary>
现代Visual对象跟踪方法通常需要大量的计算资源和庞大的训练数据，导致风险过拟合。本研究提出了更加高效的训练策略，以避免过拟合和降低计算需求。我们从开始就将训练过程平衡使用负样本和正样本，称之为共同学习负样本（JN）。负样本指的是在搜索区域中没有目标对象的场景，这有助于避免模型升级目标，而是使其使用模板来定位对象。为了有效处理负样本，我们采用分布型头，通过表示范围内的距离分布来表示目标的位置不确定性，提供了一种高效的混合样本训练方法。此外，我们引入目标指示符。它将目标的准确位置包含在模板图像中。这种方法提供了精确的边界详细信息，而且计算成本很低，但是提高性能。我们的模型JN-256在GOT-10k和TrackingNet等挑战性评测中表现出色，达到75.8% AO和84.1% AUC。值得一提的是，JN-256比使用更大的模型和更高的输入分辨率的先前SOTA跟踪器即使在训练数据量为半数时，仍然表现出优异的性能。
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Framework-for-Discovering-Discrete-Symmetries"><a href="#A-Unified-Framework-for-Discovering-Discrete-Symmetries" class="headerlink" title="A Unified Framework for Discovering Discrete Symmetries"></a>A Unified Framework for Discovering Discrete Symmetries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02898">http://arxiv.org/abs/2309.02898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pavan Karjol, Rohan Kashyap, Aditya Gopalan, Prathosh A. P</li>
<li>for: 学习一个尊重Symmetry的函数，从多种子群中选择最佳函数。</li>
<li>methods: 提出了一种统一的框架，可以快速地找到最佳函数，并且可以处理多种不同的子群，包括地方对称、双棱镜对称和循环对称。核心是一种新的架构，包括线性和张量函数，可以很好地表达对Symmetry的函数。</li>
<li>results: 在图像数字和多项式回归任务中，该方法得到了极好的效果。<details>
<summary>Abstract</summary>
We consider the problem of learning a function respecting a symmetry from among a class of symmetries. We develop a unified framework that enables symmetry discovery across a broad range of subgroups including locally symmetric, dihedral and cyclic subgroups. At the core of the framework is a novel architecture composed of linear and tensor-valued functions that expresses functions invariant to these subgroups in a principled manner. The structure of the architecture enables us to leverage multi-armed bandit algorithms and gradient descent to efficiently optimize over the linear and the tensor-valued functions, respectively, and to infer the symmetry that is ultimately learnt. We also discuss the necessity of the tensor-valued functions in the architecture. Experiments on image-digit sum and polynomial regression tasks demonstrate the effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
我们考虑一个函数在一组对称性下学习的问题。我们提出了一个统一的框架，可以在广泛的子群中包括地方对称、二面体和循环 subgroup中发现对称。框架的核心是一种新的建筑，由线性和张量函数组成，用于在原则上表达对称的函数。这种建筑结构允许我们通过多重投射算法和梯度下降来高效地优化线性函数和张量函数，并从中INFER learnt的对称性。我们还讨论了张量函数的必要性。在图像数字和多项式回归任务上，我们的方法得到了效果。
</details></li>
</ul>
<hr>
<h2 id="Image-Aesthetics-Assessment-via-Learnable-Queries"><a href="#Image-Aesthetics-Assessment-via-Learnable-Queries" class="headerlink" title="Image Aesthetics Assessment via Learnable Queries"></a>Image Aesthetics Assessment via Learnable Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02861">http://arxiv.org/abs/2309.02861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwei Xiong, Yunfan Zhang, Zhiqi Shen, Peiran Ren, Han Yu<br>for: 这篇论文的目的是提出一种基于学习查询的图像美学评估方法（IAA-LQ），以提高图像美学评估的效果。methods: 该方法使用学习查询来提取图像中的美学特征，并且使用冻结的图像编码器来获取先验知识。results: 实验结果表明，IAA-LQ方法可以超越现有的状态时间方法，提高图像美学评估的精度，并且可以提高SRCC和PLCC指标的值。<details>
<summary>Abstract</summary>
Image aesthetics assessment (IAA) aims to estimate the aesthetics of images. Depending on the content of an image, diverse criteria need to be selected to assess its aesthetics. Existing works utilize pre-trained vision backbones based on content knowledge to learn image aesthetics. However, training those backbones is time-consuming and suffers from attention dispersion. Inspired by learnable queries in vision-language alignment, we propose the Image Aesthetics Assessment via Learnable Queries (IAA-LQ) approach. It adapts learnable queries to extract aesthetic features from pre-trained image features obtained from a frozen image encoder. Extensive experiments on real-world data demonstrate the advantages of IAA-LQ, beating the best state-of-the-art method by 2.2% and 2.1% in terms of SRCC and PLCC, respectively.
</details>
<details>
<summary>摘要</summary>
Image 美学评估（IAA）目的是估计图像的美学性。根据图像内容，需要选择不同的标准来评估图像的美学性。现有的工作使用基于内容知识的预训练视觉干扰来学习图像美学。然而，训练这些干扰是时间consuming，而且容易产生注意力分散。 drawing inspiration from learnable queries in vision-language alignment, we propose the Image Aesthetics Assessment via Learnable Queries（IAA-LQ）approach。它适应learnable queries来提取图像美学特征从预训练图像特征中。我们进行了大量的实验，并证明IAA-LQ在实际数据上具有优势，比best state-of-the-art方法高2.2%和2.1%的SRCC和PLCC指标。
</details></li>
</ul>
<hr>
<h2 id="Bandwidth-efficient-Inference-for-Neural-Image-Compression"><a href="#Bandwidth-efficient-Inference-for-Neural-Image-Compression" class="headerlink" title="Bandwidth-efficient Inference for Neural Image Compression"></a>Bandwidth-efficient Inference for Neural Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02855">http://arxiv.org/abs/2309.02855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanzhi Yin, Tongda Xu, Yongsheng Liang, Yuanyuan Wang, Yanghao Li, Yan Wang, Jingjing Liu</li>
<li>for: 提高Mobile和Edge设备上的神经网络推理性能，解决由深度神经网络和大小尺寸的特征地图所带来的带宽瓶颈和能源限制问题。</li>
<li>methods: 提出了一种终端到终端可微 differentiable带宽高效神经推理方法，其中的活化被使用神经数据压缩法进行压缩。特别是，我们提出了一种基于变换量化 entropy coding的pipeline，用于活化压缩。</li>
<li>results: 对于现有模型量化方法优化后的低级任务图像压缩，可以达到最高19x的带宽减少和6.21x的能源减少。<details>
<summary>Abstract</summary>
With neural networks growing deeper and feature maps growing larger, limited communication bandwidth with external memory (or DRAM) and power constraints become a bottleneck in implementing network inference on mobile and edge devices. In this paper, we propose an end-to-end differentiable bandwidth efficient neural inference method with the activation compressed by neural data compression method. Specifically, we propose a transform-quantization-entropy coding pipeline for activation compression with symmetric exponential Golomb coding and a data-dependent Gaussian entropy model for arithmetic coding. Optimized with existing model quantization methods, low-level task of image compression can achieve up to 19x bandwidth reduction with 6.21x energy saving.
</details>
<details>
<summary>摘要</summary>
随着神经网络的深度和特征图的大小增加，在移动和边缘设备上实现网络推理时的限制性带宽和功能占用成为瓶颈。在这篇论文中，我们提出了一种终端到终端可导 differentiable带宽高效神经推理方法，其中活动被压缩使用神经数据压缩方法。具体来说，我们提出了一个转换-量化-Entropy编码管道，用于活动压缩，并使用对称的指数 Golomb编码和数据依赖的 Gaussian Entropy 模型 для数学编码。通过与现有模型量化方法结合优化，可以达到图像压缩的最低级别任务，带宽减少至 19 倍，能耗减少至 6.21 倍。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Distillation-Layer-that-Lets-the-Student-Decide"><a href="#Knowledge-Distillation-Layer-that-Lets-the-Student-Decide" class="headerlink" title="Knowledge Distillation Layer that Lets the Student Decide"></a>Knowledge Distillation Layer that Lets the Student Decide</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02843">http://arxiv.org/abs/2309.02843</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adagorgun/letkd-framework">https://github.com/adagorgun/letkd-framework</a></li>
<li>paper_authors: Ada Gorgun, Yeti Z. Gurbuz, A. Aydin Alatan</li>
<li>for: 本研究旨在提高知识蒸馈（KD）技术的实践，使学习Student模型的限制能力模型（teacher）的学习过程更加有效。</li>
<li>methods: 我们提出了一种可学习的KD层，用于在学习Student模型时将教师模型的知识直接嵌入到特征变换中。这些能力包括：i) 利用教师模型的知识来抛弃干扰信息，ii) 将知识传递深入。因此，学生模型在推理过程中可以获得教师模型的知识，不仅在训练过程中。</li>
<li>results: 我们通过对3种常见的分类 benchmark进行严格的实验，证明了我们的方法的效果。<details>
<summary>Abstract</summary>
Typical technique in knowledge distillation (KD) is regularizing the learning of a limited capacity model (student) by pushing its responses to match a powerful model's (teacher). Albeit useful especially in the penultimate layer and beyond, its action on student's feature transform is rather implicit, limiting its practice in the intermediate layers. To explicitly embed the teacher's knowledge in feature transform, we propose a learnable KD layer for the student which improves KD with two distinct abilities: i) learning how to leverage the teacher's knowledge, enabling to discard nuisance information, and ii) feeding forward the transferred knowledge deeper. Thus, the student enjoys the teacher's knowledge during the inference besides training. Formally, we repurpose 1x1-BN-ReLU-1x1 convolution block to assign a semantic vector to each local region according to the template (supervised by the teacher) that the corresponding region of the student matches. To facilitate template learning in the intermediate layers, we propose a novel form of supervision based on the teacher's decisions. Through rigorous experimentation, we demonstrate the effectiveness of our approach on 3 popular classification benchmarks. Code is available at: https://github.com/adagorgun/letKD-framework
</details>
<details>
<summary>摘要</summary>
通常的知识填充（KD）技术是使学生模型（学生）的学习受到师模型（教师）的 régularization，使学生的回归与教师的回归相匹配。虽然在最后一层和以上层 particularly useful，但是对于学生的特征变换的影响相对较弱，限制了KD的实践在中间层。为了让学生在推理过程中获得教师的知识，我们提议一种可学习的KD层，该层具有以下两种能力：i) 学习如何利用教师的知识，以便抛弃干扰信息；ii) 将知识传递深入。因此，学生在推理过程中不仅会受到教师的影响，还会在推理过程中直接获得教师的知识。具体来说，我们将1x1-BN-ReLU-1x1 convolution block重新用于将每个地方分配一个 semantics vector，根据学生对应的地方与教师的地方匹配的模板（由教师supervise）。为了在中间层进行模板学习，我们提出了一种新的超visions基于教师的决策。经过严格的实验，我们证明了我们的方法在3个popular classification benchmark上的效果。代码可以在：https://github.com/adagorgun/letKD-framework 中找到。
</details></li>
</ul>
<hr>
<h2 id="Adjacency-hopping-de-Bruijn-Sequences-for-Non-repetitive-Coding"><a href="#Adjacency-hopping-de-Bruijn-Sequences-for-Non-repetitive-Coding" class="headerlink" title="Adjacency-hopping de Bruijn Sequences for Non-repetitive Coding"></a>Adjacency-hopping de Bruijn Sequences for Non-repetitive Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02841">http://arxiv.org/abs/2309.02841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Chen, Zhenglin Liang, Shiqian Wu</li>
<li>for: 这种论文主要用于描述一种特殊的循环序列，即邻接跳跃de Bruijn序列，以及这种序列在结构化光编码中的应用。</li>
<li>methods: 这种序列使用了一种新的邻接跳跃方法，这种方法可以保证邻接代码具有不同性，同时保持 subsequences 的唯一性。</li>
<li>results: 该论文 theoretically 证明了邻接跳跃de Bruijn序列的存在，并计算了这种序列的数量。此外，该论文还应用了这种序列在结构化光编码中，并提供了一个具有唯一性和邻接不同性的色带图像编码方案。<details>
<summary>Abstract</summary>
A special type of cyclic sequences named adjacency-hopping de Bruijn sequences is introduced in this paper. It is theoretically proved the existence of such sequences, and the number of such sequences is derived. These sequences guarantee that all neighboring codes are different while retaining the uniqueness of subsequences, which is a significant characteristic of original de Bruijn sequences in coding and matching. At last, the adjacency-hopping de Bruijn sequences are applied to structured light coding, and a color fringe pattern coded by such a sequence is presented. In summary, the proposed sequences demonstrate significant advantages in structured light coding by virtue of the uniqueness of subsequences and the adjacency-hopping characteristic, and show potential for extension to other fields with similar requirements of non-repetitive coding and efficient matching.
</details>
<details>
<summary>摘要</summary>
本文提出了一种特殊的循环序列，名为邻接跳跃de Bruijn序列。这种序列的存在性被证明了，并且计算出了其数量。这些序列 garantía所有邻近代码都不同，同时保留原始de Bruijn序列中的 subsequences 唯一性，这是一个重要的特征。最后，这种序列应用于结构化光编码，并将其用于生成一个彩色环纹图像。总的来说，提出的序列在结构化光编码中表现出了优异的特点，包括 subsequences 的唯一性和邻接跳跃特性，并且具有扩展到其他需要非重复编码和效果快速匹配的领域的潜力。
</details></li>
</ul>
<hr>
<h2 id="EGIC-Enhanced-Low-Bit-Rate-Generative-Image-Compression-Guided-by-Semantic-Segmentation"><a href="#EGIC-Enhanced-Low-Bit-Rate-Generative-Image-Compression-Guided-by-Semantic-Segmentation" class="headerlink" title="EGIC: Enhanced Low-Bit-Rate Generative Image Compression Guided by Semantic Segmentation"></a>EGIC: Enhanced Low-Bit-Rate Generative Image Compression Guided by Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03244">http://arxiv.org/abs/2309.03244</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nikolai10/egic">https://github.com/nikolai10/egic</a></li>
<li>paper_authors: Nikolai Körber, Eduard Kromer, Andreas Siebert, Sascha Hauke, Daniel Mueller-Gritschneder</li>
<li>for: This paper is written for improving image compression using a generative model.</li>
<li>methods: The paper proposes a novel method called EGIC, which uses an implicitly encoded variant of image interpolation to predict the residual between a MSE-optimized and GAN-optimized decoder output.</li>
<li>results: The paper shows that EGIC outperforms several baseline methods, including HiFiC, MRIC, and DIRAC, while performing almost on par with VTM-20.0 on the distortion end. Additionally, EGIC is simple to implement, lightweight, and provides excellent interpolation characteristics, making it a promising candidate for practical applications targeting the low bit range.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文是为了提高图像压缩使用生成模型而写的。</li>
<li>methods: 论文提出了一种新的方法called EGIC，它使用隐式编码的图像 interpolate来预测MSE优化和GAN优化解码器输出之间的差异。</li>
<li>results: 论文表明EGIC在比较多种基eline方法，包括HiFiC、MRIC和DIRAC，而且与VTM-20.0在损均值上几乎相当，而且EGIC具有简单实现、轻量级（例如0.18x模型参数相比HiFiC）、优秀的 interpolate特性，使其成为实际应用中的优秀候选者。<details>
<summary>Abstract</summary>
We introduce EGIC, a novel generative image compression method that allows traversing the distortion-perception curve efficiently from a single model. Specifically, we propose an implicitly encoded variant of image interpolation that predicts the residual between a MSE-optimized and GAN-optimized decoder output. On the receiver side, the user can then control the impact of the residual on the GAN-based reconstruction. Together with improved GAN-based building blocks, EGIC outperforms a wide-variety of perception-oriented and distortion-oriented baselines, including HiFiC, MRIC and DIRAC, while performing almost on par with VTM-20.0 on the distortion end. EGIC is simple to implement, very lightweight (e.g. 0.18x model parameters compared to HiFiC) and provides excellent interpolation characteristics, which makes it a promising candidate for practical applications targeting the low bit range.
</details>
<details>
<summary>摘要</summary>
我们介绍EGIC，一种新的生成图像压缩方法，可以高效地从单一模型中横越偏差感知曲线。具体来说，我们提出了一种隐式编码的图像插值方法，可以预测MSE优化和GAN优化解oder输出之间的差异。在接收端，用户可以控制GAN基建的重建影响。与改进的GAN基建块相结合，EGIC超越了广泛的感知对象和偏差对象的基eline，包括HiFiC、MRIC和DIRAC，并且在偏差端接近VTM-20.0的性能。EGIC简单实现、轻量级（例如0.18x的模型参数相比HiFiC），具有出色的插值特性，使其成为实际应用中的吸引人选择。
</details></li>
</ul>
<hr>
<h2 id="Image-Object-Specific-Prompt-Learning-for-Few-Shot-Class-Incremental-Learning"><a href="#Image-Object-Specific-Prompt-Learning-for-Few-Shot-Class-Incremental-Learning" class="headerlink" title="Image-Object-Specific Prompt Learning for Few-Shot Class-Incremental Learning"></a>Image-Object-Specific Prompt Learning for Few-Shot Class-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02833">http://arxiv.org/abs/2309.02833</a></li>
<li>repo_url: None</li>
<li>paper_authors: In-Ug Yoon, Tae-Min Choi, Sun-Kyung Lee, Young-Min Kim, Jong-Hwan Kim</li>
<li>for: This paper aims to improve the performance of Fine-Grained Semantic Image Segmentation (FSCIL) in incremental sessions, where the encoder often underperforms.</li>
<li>methods: The authors propose a novel training framework that leverages the generalizability of the Contrastive Language-Image Pre-training (CLIP) model to unseen classes, and formulates image-object-specific (IOS) classifiers for input images.</li>
<li>results: The proposed framework consistently demonstrates superior performance compared to state-of-the-art methods across three datasets (miniImageNet, CIFAR100, and CUB200), and the authors provide additional experiments to validate the learned model’s ability to achieve IOS classifiers.Here is the summary in the format you requested:</li>
<li>for: 提高 FSCIL 在增量会话中的表现，特别是在遇到训练集不够的情况下。</li>
<li>methods: 提出一种基于 CLIP 模型的新的训练框架，通过形成输入图像的特定属性（如翼或轮）的特定类别（IOS）分类器来提高 FSCIL 的表现。</li>
<li>results: 提出的框架在 miniImageNet、CIFAR100 和 CUB200 三个 dataset 上 consistently 示出了比state-of-the-art 方法更好的表现，并提供了验证学习模型是否可以实现 IOS 分类器的额外实验。<details>
<summary>Abstract</summary>
While many FSCIL studies have been undertaken, achieving satisfactory performance, especially during incremental sessions, has remained challenging. One prominent challenge is that the encoder, trained with an ample base session training set, often underperforms in incremental sessions. In this study, we introduce a novel training framework for FSCIL, capitalizing on the generalizability of the Contrastive Language-Image Pre-training (CLIP) model to unseen classes. We achieve this by formulating image-object-specific (IOS) classifiers for the input images. Here, an IOS classifier refers to one that targets specific attributes (like wings or wheels) of class objects rather than the image's background. To create these IOS classifiers, we encode a bias prompt into the classifiers using our specially designed module, which harnesses key-prompt pairs to pinpoint the IOS features of classes in each session. From an FSCIL standpoint, our framework is structured to retain previous knowledge and swiftly adapt to new sessions without forgetting or overfitting. This considers the updatability of modules in each session and some tricks empirically found for fast convergence. Our approach consistently demonstrates superior performance compared to state-of-the-art methods across the miniImageNet, CIFAR100, and CUB200 datasets. Further, we provide additional experiments to validate our learned model's ability to achieve IOS classifiers. We also conduct ablation studies to analyze the impact of each module within the architecture.
</details>
<details>
<summary>摘要</summary>
虽然许多FSCIL研究已经进行过，但在增量会话中达到满意的表现仍然是一大挑战。一个显著的挑战是，在增量会话中训练的编码器，经常在增量会话中下降表现。在这个研究中，我们提出了一种新的FSCIL训练框架，利用CLIP模型对未看过的类型的泛化能力。我们实现这种IOS类ifiers的目的是通过我们特制的模块，将特定的属性（如翼或轮胎）作为类对象的特征进行编码。在FSCIL的视角下，我们的框架结构是保留先前的知识，并快速适应新会话而不忘记或过拟合。这包括在每个会话中更新模块的机制，以及一些经验上发现的快速吸收技巧。我们的方法在miniImageNet、CIFAR100和CUB200数据集上 consistently 示出了与状态ixel方法相比的superior表现。此外，我们还提供了额外的实验，以验证我们学习的模型是否可以实现IOS类ifiers。此外，我们还进行了ablation study，以分析每个模块在架构中的影响。
</details></li>
</ul>
<hr>
<h2 id="3D-Trajectory-Reconstruction-of-Drones-using-a-Single-Camera"><a href="#3D-Trajectory-Reconstruction-of-Drones-using-a-Single-Camera" class="headerlink" title="3D Trajectory Reconstruction of Drones using a Single Camera"></a>3D Trajectory Reconstruction of Drones using a Single Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02801">http://arxiv.org/abs/2309.02801</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seobin Hwang, Hanyoung Kim, Chaeyeon Heo, Youkyoung Na, Cheongeun Lee, Yeongjun Cho</li>
<li>for: 防止非法用途的尼龙，这项研究提出了一种基于单个摄像头的尼龙三维轨迹重建框架。</li>
<li>methods: 该方法利用准备好的摄像头进行尼龙自动跟踪，并利用尼龙的实际长度信息和摄像头参数，通过几何关系确定尼龙的三维轨迹。</li>
<li>results: 实验结果表明，提出的方法可以准确地重建尼龙的三维轨迹，并demonstrate了该框架在单摄像头式监测系统中的潜力。<details>
<summary>Abstract</summary>
Drones have been widely utilized in various fields, but the number of drones being used illegally and for hazardous purposes has increased recently. To prevent those illegal drones, in this work, we propose a novel framework for reconstructing 3D trajectories of drones using a single camera. By leveraging calibrated cameras, we exploit the relationship between 2D and 3D spaces. We automatically track the drones in 2D images using the drone tracker and estimate their 2D rotations. By combining the estimated 2D drone positions with their actual length information and camera parameters, we geometrically infer the 3D trajectories of the drones. To address the lack of public drone datasets, we also create synthetic 2D and 3D drone datasets. The experimental results show that the proposed methods accurately reconstruct drone trajectories in 3D space, and demonstrate the potential of our framework for single camera-based surveillance systems.
</details>
<details>
<summary>摘要</summary>
《用单一摄像头掌握无人机三维轨迹》Introduction:无人机在不同领域得到广泛应用，但近些年来，非法使用无人机的数量却在增加。为防止这些非法无人机，在这项工作中，我们提出了一种基于单一摄像头的无人机三维轨迹重建方案。我们利用准备好的摄像头进行准确跟踪无人机的2D位势，并利用摄像头的捕捉到无人机的2D旋转信息，以确定无人机的3D轨迹。Methodology:我们首先使用准备好的摄像头对无人机进行跟踪，并利用摄像头的准确性来确定无人机的2D位势。然后，我们利用无人机的实际长度信息和摄像头参数，在3D空间中进行三维轨迹的重建。为了解决公共无人机数据缺乏的问题，我们还创造了一些人工生成的2D和3D无人机数据集。Results:实验结果表明，我们提出的方法可以准确地重建无人机的3D轨迹，并证明了我们的框架在单一摄像头基础上的可行性。这些结果还表明了我们的方法在无人机监测系统中的潜在应用前景。Conclusion:本文提出了一种基于单一摄像头的无人机三维轨迹重建方案，可以准确地重建无人机的3D轨迹。我们还创造了一些人工生成的2D和3D无人机数据集，以便进一步验证和改进我们的方法。这些结果表明了我们的方法在无人机监测系统中的潜在应用前景。
</details></li>
</ul>
<hr>
<h2 id="LightNeuS-Neural-Surface-Reconstruction-in-Endoscopy-using-Illumination-Decline"><a href="#LightNeuS-Neural-Surface-Reconstruction-in-Endoscopy-using-Illumination-Decline" class="headerlink" title="LightNeuS: Neural Surface Reconstruction in Endoscopy using Illumination Decline"></a>LightNeuS: Neural Surface Reconstruction in Endoscopy using Illumination Decline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02777">http://arxiv.org/abs/2309.02777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Víctor M. Batlle, José M. M. Montiel, Pascal Fua, Juan D. Tardós</li>
<li>for: 该论文旨在提出一种基于照明变化的眼窍endooscope序列图像三维重建方法。</li>
<li>methods: 该方法基于两点关键意识：首先，endooscope中的液体空间是水密的，这种性质由签名距离函数来自然强制实现。其次，场景照明是可变的，来自endooscope的灯光和距离表面的 inverse squared 强度衰减。为了利用这两点，该方法基于NeuS算法，一种能够从多视图学习表面形态和外观特征的神经 implicit surface reconstruction 技术，但是现在只能处理静止照明的场景。为了解决这个限制，我们修改NeuS架构，考虑到灯光和camera的准确均衡，并引入了准确的摄像头和灯光Source的光学模型。</li>
<li>results: 该方法可以生成整个colon部分的水密重建，并在幻像中达到了出色的准确性。另外，由于照明下降和水密 prior的结合，该方法可以完成未被观察的表面部分的重建，并达到了可接受的准确性，这些结果为自动评估癌症检查探针提供了基础。<details>
<summary>Abstract</summary>
We propose a new approach to 3D reconstruction from sequences of images acquired by monocular endoscopes. It is based on two key insights. First, endoluminal cavities are watertight, a property naturally enforced by modeling them in terms of a signed distance function. Second, the scene illumination is variable. It comes from the endoscope's light sources and decays with the inverse of the squared distance to the surface. To exploit these insights, we build on NeuS, a neural implicit surface reconstruction technique with an outstanding capability to learn appearance and a SDF surface model from multiple views, but currently limited to scenes with static illumination. To remove this limitation and exploit the relation between pixel brightness and depth, we modify the NeuS architecture to explicitly account for it and introduce a calibrated photometric model of the endoscope's camera and light source. Our method is the first one to produce watertight reconstructions of whole colon sections. We demonstrate excellent accuracy on phantom imagery. Remarkably, the watertight prior combined with illumination decline, allows to complete the reconstruction of unseen portions of the surface with acceptable accuracy, paving the way to automatic quality assessment of cancer screening explorations, measuring the global percentage of observed mucosa.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Endoluminal cavities are watertight, which can be naturally enforced by modeling them as signed distance functions.2. The scene illumination is variable and decays with the inverse of the squared distance to the surface.To exploit these insights, we build on NeuS, a neural implicit surface reconstruction technique that can learn appearance and a SDF surface model from multiple views. However, NeuS is limited to scenes with static illumination. To remove this limitation, we modify the NeuS architecture to explicitly account for the relation between pixel brightness and depth, and introduce a calibrated photometric model of the endoscope’s camera and light source.Our method is the first to produce watertight reconstructions of whole colon sections. We demonstrate excellent accuracy on phantom imagery, and remarkably, the watertight prior combined with illumination decline allows us to complete the reconstruction of unseen portions of the surface with acceptable accuracy. This paves the way to automatic quality assessment of cancer screening explorations, and measuring the global percentage of observed mucosa.</details></li>
</ol>
<hr>
<h2 id="Diffusion-Model-is-Secretly-a-Training-free-Open-Vocabulary-Semantic-Segmenter"><a href="#Diffusion-Model-is-Secretly-a-Training-free-Open-Vocabulary-Semantic-Segmenter" class="headerlink" title="Diffusion Model is Secretly a Training-free Open Vocabulary Semantic Segmenter"></a>Diffusion Model is Secretly a Training-free Open Vocabulary Semantic Segmenter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02773">http://arxiv.org/abs/2309.02773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinglong Wang, Xiawei Li, Jing Zhang, Qingyuan Xu, Qin Zhou, Qian Yu, Lu Sheng, Dong Xu</li>
<li>for: 该 paper 主要研究开放 vocabulary Semantic Segmentation 的问题，尝试使用 Conditional Latent Diffusion Model 来解决这个问题。</li>
<li>methods: 该 paper 使用了 pre-trained text-image discriminative models, such as CLIP, 并通过 contrastive learning 来Alignment 过程，但是这个过程可能会导致重要的局部化信息和物体完整性的丢失，这些信息是为Semantic Segmentation 准确性所必需的。</li>
<li>results: 该 paper 提出了一种基于 diffusion models 的open-vocabulary Semantic Segmentation 方法，并通过实验证明了这种方法可以 дости得高效的结果。Specifically, the proposed method uses a training-free approach named DiffSegmenter, which utilizes cross-attention maps produced by the denoising U-Net to generate segmentation scores, and further refines and completes the segmentation results with self-attention maps. The proposed method also designs effective textual prompts and a category filtering mechanism to enhance the segmentation results. Extensive experiments on three benchmark datasets show that the proposed DiffSegmenter achieves impressive results for open-vocabulary semantic segmentation.<details>
<summary>Abstract</summary>
Recent research has explored the utilization of pre-trained text-image discriminative models, such as CLIP, to tackle the challenges associated with open-vocabulary semantic segmentation. However, it is worth noting that the alignment process based on contrastive learning employed by these models may unintentionally result in the loss of crucial localization information and object completeness, which are essential for achieving accurate semantic segmentation. More recently, there has been an emerging interest in extending the application of diffusion models beyond text-to-image generation tasks, particularly in the domain of semantic segmentation. These approaches utilize diffusion models either for generating annotated data or for extracting features to facilitate semantic segmentation. This typically involves training segmentation models by generating a considerable amount of synthetic data or incorporating additional mask annotations. To this end, we uncover the potential of generative text-to-image conditional diffusion models as highly efficient open-vocabulary semantic segmenters, and introduce a novel training-free approach named DiffSegmenter. Specifically, by feeding an input image and candidate classes into an off-the-shelf pre-trained conditional latent diffusion model, the cross-attention maps produced by the denoising U-Net are directly used as segmentation scores, which are further refined and completed by the followed self-attention maps. Additionally, we carefully design effective textual prompts and a category filtering mechanism to further enhance the segmentation results. Extensive experiments on three benchmark datasets show that the proposed DiffSegmenter achieves impressive results for open-vocabulary semantic segmentation.
</details>
<details>
<summary>摘要</summary>
近期研究探讨了利用预训练文本图像抗变模型，如CLIP，解决开 vocabulary semantic segmentation 中的挑战。然而，需要注意的是，这些模型使用的对比学习Alignment процесс可能会意外地导致重要的本地化信息和对象完整性的产生，这些信息是Semantic segmentation 的准确性所必需的。近来， diffusion models 在 semantic segmentation 领域的应用也在扩展。这些approaches使用 diffusion models 为生成注释数据或提取特征，以便实现 Semantic segmentation。通常情况下，这些方法需要生成大量的synthetic数据或添加额外的mask注释。为了实现这一点，我们探讨了使用生成文本图像决定型 diffusion models 作为开 vocabulary semantic segmenter，并提出了一种新的无需训练的方法 named DiffSegmenter。具体来说，我们将输入图像和候选类 feed 到一个预训练的conditional latent diffusion model中，并使用其生成的杂化映射来生成Semantic segmentation scores。这些 scores 然后通过自我注意 Mechanism 进行更新和完善。此外，我们还特意设计了有效的文本提示和类别筛选机制，以进一步提高 segmentation 结果。我们在三个benchmark dataset上进行了广泛的实验，结果显示，我们的 DiffSegmenter 可以在开 vocabulary semantic segmentation 中达到卓越的成绩。
</details></li>
</ul>
<hr>
<h2 id="RepSGG-Novel-Representations-of-Entities-and-Relationships-for-Scene-Graph-Generation"><a href="#RepSGG-Novel-Representations-of-Entities-and-Relationships-for-Scene-Graph-Generation" class="headerlink" title="RepSGG: Novel Representations of Entities and Relationships for Scene Graph Generation"></a>RepSGG: Novel Representations of Entities and Relationships for Scene Graph Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03240">http://arxiv.org/abs/2309.03240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengyue Liu, Bir Bhanu</li>
<li>for: 提高Scene Graph Generation（SGG）的精度和效率，尤其是在 Addressing the challenges of fixed-size entity representations and long-tailed distribution.</li>
<li>methods: 提出了一种novel architecture called RepSGG，通过将主题作为查询，对象作为键，以及它们之间的最大关注重量作为对应关系的权重，以提取更加精细和灵活的特征表示。此外，还提出了一种在训练过程中根据运行时性能进行对 relate  logits 的修正，以便更好地塑造表示关系的精度和效率。</li>
<li>results: 实验结果显示，RepSGG可以在Visual Genome和Open Images V6 datasets上 achieve the state-of-the-art or comparable performance，同时具有快速的推理速度，证明了提出的方法的有效性和效率。<details>
<summary>Abstract</summary>
Scene Graph Generation (SGG) has achieved significant progress recently. However, most previous works rely heavily on fixed-size entity representations based on bounding box proposals, anchors, or learnable queries. As each representation's cardinality has different trade-offs between performance and computation overhead, extracting highly representative features efficiently and dynamically is both challenging and crucial for SGG. In this work, a novel architecture called RepSGG is proposed to address the aforementioned challenges, formulating a subject as queries, an object as keys, and their relationship as the maximum attention weight between pairwise queries and keys. With more fine-grained and flexible representation power for entities and relationships, RepSGG learns to sample semantically discriminative and representative points for relationship inference. Moreover, the long-tailed distribution also poses a significant challenge for generalization of SGG. A run-time performance-guided logit adjustment (PGLA) strategy is proposed such that the relationship logits are modified via affine transformations based on run-time performance during training. This strategy encourages a more balanced performance between dominant and rare classes. Experimental results show that RepSGG achieves the state-of-the-art or comparable performance on the Visual Genome and Open Images V6 datasets with fast inference speed, demonstrating the efficacy and efficiency of the proposed methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DMKD-Improving-Feature-based-Knowledge-Distillation-for-Object-Detection-Via-Dual-Masking-Augmentation"><a href="#DMKD-Improving-Feature-based-Knowledge-Distillation-for-Object-Detection-Via-Dual-Masking-Augmentation" class="headerlink" title="DMKD: Improving Feature-based Knowledge Distillation for Object Detection Via Dual Masking Augmentation"></a>DMKD: Improving Feature-based Knowledge Distillation for Object Detection Via Dual Masking Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02719">http://arxiv.org/abs/2309.02719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guang Yang, Yin Tang, Zhijian Wu, Jun Li, Jianhua Xu, Xili Wan</li>
<li>For: The paper is written for improving the performance of object detection tasks using masked knowledge distillation.* Methods: The paper uses a Dual Masked Knowledge Distillation (DMKD) framework, which employs dual attention mechanism and self-adjustable weighting strategy to capture both spatially important and channel-wise informative clues for comprehensive masked feature reconstruction.* Results: The paper demonstrates that the student networks achieve performance gains of 4.1% and 4.3% with the help of the proposed method when RetinaNet and Cascade Mask R-CNN are respectively used as the teacher networks, while outperforming other state-of-the-art distillation methods.Here is the information in Simplified Chinese text:* 用途: 论文是为了提高对象检测任务的性能使用masked知识传递。* 方法: 论文使用了Dual Masked Knowledge Distillation（DMKD）框架，该框架使用双注意力机制和自适应权重调整策略来捕捉双重重要的spatial和channelwise信息，实现了全面的masked特征重建。* 结果: 论文显示，使用提议方法可以使学生网络在RetinaNet和Cascade Mask R-CNN两个教师网络的帮助下提高性能，同时超越其他当前的传递方法。<details>
<summary>Abstract</summary>
Recent mainstream masked distillation methods function by reconstructing selectively masked areas of a student network from the feature map of its teacher counterpart. In these methods, the masked regions need to be properly selected, such that reconstructed features encode sufficient discrimination and representation capability like the teacher feature. However, previous masked distillation methods only focus on spatial masking, making the resulting masked areas biased towards spatial importance without encoding informative channel clues. In this study, we devise a Dual Masked Knowledge Distillation (DMKD) framework which can capture both spatially important and channel-wise informative clues for comprehensive masked feature reconstruction. More specifically, we employ dual attention mechanism for guiding the respective masking branches, leading to reconstructed feature encoding dual significance. Furthermore, fusing the reconstructed features is achieved by self-adjustable weighting strategy for effective feature distillation. Our experiments on object detection task demonstrate that the student networks achieve performance gains of 4.1% and 4.3% with the help of our method when RetinaNet and Cascade Mask R-CNN are respectively used as the teacher networks, while outperforming the other state-of-the-art distillation methods.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)现代主流的掩蔽知识传授方法都是通过学习器网络中选择性地掩蔽特定区域，以从教师网络的特征图中重建学习器网络中的特征。然而，先前的掩蔽知识传授方法仅专注于空间掩蔽，导致掩蔽区域仅对空间重要性有偏好，无法传递有用的通道讯息。在这一研究中，我们提出了一个多模式掩蔽知识传授（DMKD）框架，可以捕捉多模式掩蔽特征的重建。具体来说，我们使用双注意力机制来引导各自的掩蔽分支，使得重建特征具有双重重要性。此外，我们使用自适应的权重调整策略，以实现有效的特征传授。我们对物件检测任务进行实验，结果显示，使用我们的方法可以帮助学习器网络在RetinaNet和Cascade Mask R-CNN作为教师网络时，提高表现率4.1%和4.3%，并且超过其他状态的传授方法。
</details></li>
</ul>
<hr>
<h2 id="Gene-induced-Multimodal-Pre-training-for-Image-omic-Classification"><a href="#Gene-induced-Multimodal-Pre-training-for-Image-omic-Classification" class="headerlink" title="Gene-induced Multimodal Pre-training for Image-omic Classification"></a>Gene-induced Multimodal Pre-training for Image-omic Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02702">http://arxiv.org/abs/2309.02702</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ting Jin, Xingran Xie, Renjie Wan, Qingli Li, Yan Wang</li>
<li>for: 这篇论文旨在提出一种基于遗传学和材料学图像的多Modal Pre-training（GiMP）框架，用于 классификации任务。</li>
<li>methods: 该框架使用了群体多头自我注意力基因编码器，以捕捉全息特征，以及一种隐藏素征模型（MPM），用于捕捉不同组织的潜在特征。</li>
<li>results: 实验结果表明，GiMP框架在TCGA数据集上表现出色，准确率达99.47%，超过了传统方法。代码可以在<a target="_blank" rel="noopener" href="https://github.com/huangwudiduan/GIMP%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/huangwudiduan/GIMP上获取。</a><details>
<summary>Abstract</summary>
Histology analysis of the tumor micro-environment integrated with genomic assays is the gold standard for most cancers in modern medicine. This paper proposes a Gene-induced Multimodal Pre-training (GiMP) framework, which jointly incorporates genomics and Whole Slide Images (WSIs) for classification tasks. Our work aims at dealing with the main challenges of multi-modality image-omic classification w.r.t. (1) the patient-level feature extraction difficulties from gigapixel WSIs and tens of thousands of genes, and (2) effective fusion considering high-order relevance modeling. Concretely, we first propose a group multi-head self-attention gene encoder to capture global structured features in gene expression cohorts. We design a masked patch modeling paradigm (MPM) to capture the latent pathological characteristics of different tissues. The mask strategy is randomly masking a fixed-length contiguous subsequence of patch embeddings of a WSI. Finally, we combine the classification tokens of paired modalities and propose a triplet learning module to learn high-order relevance and discriminative patient-level information.After pre-training, a simple fine-tuning can be adopted to obtain the classification results. Experimental results on the TCGA dataset show the superiority of our network architectures and our pre-training framework, achieving 99.47% in accuracy for image-omic classification. The code is publicly available at https://github.com/huangwudiduan/GIMP.
</details>
<details>
<summary>摘要</summary>
现代医学中大多数癌症的标准方法是 histology 分析和 genomic 测试。这篇文章提出了一个 Gene-induced Multimodal Pre-training（GiMP）框架，该框架结合 genomics 和 Whole Slide Images（WSIs）进行分类任务。我们的工作是解决多模态图像-生物学分类中关于（1）来自 gigapixel WSIs 和 tens of thousands of genes 的病人级特征提取问题，以及（2）高级相关模型化的有效融合问题。具体来说，我们首先提出了一种组 multi-head self-attention 基因编码器，以捕捉全Structured 特征在基因表达相关组中。我们设计了一种 masked patch modeling 模式（MPM），以捕捉不同组织的潜在病理特征。在 mask 策略中，随机遮盖一个固定长度连续序列的 patch 嵌入。最后，我们将多modal 分类标记 fusion 并提出了一个 triplet learning 模块，以学习高级相关和权威病人级信息。经过预训练后，可以简单地进行微调，以获得分类结果。TCGA 数据集的实验结果表明，我们的网络架构和预训练框架具有优势，实现了 99.47% 的图像-生物学分类精度。代码可以在 <https://github.com/huangwudiduan/GIMP> 上公开获取。
</details></li>
</ul>
<hr>
<h2 id="Improving-Image-Classification-of-Knee-Radiographs-An-Automated-Image-Labeling-Approach"><a href="#Improving-Image-Classification-of-Knee-Radiographs-An-Automated-Image-Labeling-Approach" class="headerlink" title="Improving Image Classification of Knee Radiographs: An Automated Image Labeling Approach"></a>Improving Image Classification of Knee Radiographs: An Automated Image Labeling Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02681">http://arxiv.org/abs/2309.02681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jikai Zhang, Carlos Santos, Christine Park, Maciej Mazurowski, Roy Colglazier<br>for: 这个研究的目的是开发一种自动标注方法，以提高诊断X光影像的Image Classification模型，以分辨正常股骨影像和疾病或替换手术影像。methods: 这个研究使用了7382名病人和637名病人的数据来训练和验证自动标注模型。results: 研究结果表明，使用自动标注模型可以提高诊断X光影像的Image Classification性能，具有较高的WAUC值和AUC-ROC值，特别是在正常和疾病类别中。此外，DeLong测试表明，这种提高是 statistically significant（p-value&lt;0.002和p-value&lt;0.001）。这些结果表明，自动标注方法可以有效地提高诊断X光影像的Image Classification性能，为患者护理和大量股骨数据库的筛选提供帮助。<details>
<summary>Abstract</summary>
Large numbers of radiographic images are available in knee radiology practices which could be used for training of deep learning models for diagnosis of knee abnormalities. However, those images do not typically contain readily available labels due to limitations of human annotations. The purpose of our study was to develop an automated labeling approach that improves the image classification model to distinguish normal knee images from those with abnormalities or prior arthroplasty. The automated labeler was trained on a small set of labeled data to automatically label a much larger set of unlabeled data, further improving the image classification performance for knee radiographic diagnosis. We developed our approach using 7,382 patients and validated it on a separate set of 637 patients. The final image classification model, trained using both manually labeled and pseudo-labeled data, had the higher weighted average AUC (WAUC: 0.903) value and higher AUC-ROC values among all classes (normal AUC-ROC: 0.894; abnormal AUC-ROC: 0.896, arthroplasty AUC-ROC: 0.990) compared to the baseline model (WAUC=0.857; normal AUC-ROC: 0.842; abnormal AUC-ROC: 0.848, arthroplasty AUC-ROC: 0.987), trained using only manually labeled data. DeLong tests show that the improvement is significant on normal (p-value<0.002) and abnormal (p-value<0.001) images. Our findings demonstrated that the proposed automated labeling approach significantly improves the performance of image classification for radiographic knee diagnosis, allowing for facilitating patient care and curation of large knee datasets.
</details>
<details>
<summary>摘要</summary>
大量的血管成像图像在膝关节Radiology实践中可用于深度学习模型的训练，识别膝关节异常。然而，这些图像通常没有可用的标签，因为人工标注的限制。我们的研究旨在开发一种自动标签方法，以提高血管成像分类模型，识别正常膝关节图像和异常或过去arthroplasty图像。我们使用了7,382名患者和637名患者的分离集来验证我们的方法。最终的血管成像分类模型，使用了手动标签和 Pseudo-标签数据进行训练，与基线模型（WAUC=0.857；正常AUC-ROC=0.842；异常AUC-ROC=0.848；arthroplasty AUC-ROC=0.987）相比，在所有类型中得到了更高的Weighted Average AUC（WAUC：0.903）值和更高的AUC-ROC值。DeLong测试表明，在正常（p-值<0.002）和异常（p-值<0.001）图像上，我们的提高是 statistically significant。我们的发现表明，我们提出的自动标签方法可以在膝关节Radiographic诊断中显著提高图像分类性能，为患者护理和大量膝关节数据库的筛选提供了有力的支持。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Training-for-Visual-Tracking-with-Deformable-Transformer"><a href="#Efficient-Training-for-Visual-Tracking-with-Deformable-Transformer" class="headerlink" title="Efficient Training for Visual Tracking with Deformable Transformer"></a>Efficient Training for Visual Tracking with Deformable Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02676">http://arxiv.org/abs/2309.02676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingmao Wei, Guotian Zeng, Bi Zeng</li>
<li>for: 这篇论文是为了提出一种高效的视觉对象跟踪方法，以便应用于实际场景。</li>
<li>methods: 该方法使用了高效的Encoder-Decoder结构，并使用了弹性变换器作为目标头，从而降低了GFLOPs。在训练过程中，我们引入了一种新的一对多标签分配方法和一种辅助去噪技术，使模型更快地趋向于 converges。</li>
<li>results: 我们的方法在顶尖GOT-10k测试benchmark上达到了72.9%的AO，仅用20%的训练班目时间，并且在GFLOPs方面比所有基eline的转换器更低。<details>
<summary>Abstract</summary>
Recent Transformer-based visual tracking models have showcased superior performance. Nevertheless, prior works have been resource-intensive, requiring prolonged GPU training hours and incurring high GFLOPs during inference due to inefficient training methods and convolution-based target heads. This intensive resource use renders them unsuitable for real-world applications. In this paper, we present DETRack, a streamlined end-to-end visual object tracking framework. Our framework utilizes an efficient encoder-decoder structure where the deformable transformer decoder acting as a target head, achieves higher sparsity than traditional convolution heads, resulting in decreased GFLOPs. For training, we introduce a novel one-to-many label assignment and an auxiliary denoising technique, significantly accelerating model's convergence. Comprehensive experiments affirm the effectiveness and efficiency of our proposed method. For instance, DETRack achieves 72.9% AO on challenging GOT-10k benchmarks using only 20% of the training epochs required by the baseline, and runs with lower GFLOPs than all the transformer-based trackers.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose DETRack, a streamlined end-to-end visual object tracking framework. Our framework uses an efficient encoder-decoder structure, where the deformable transformer decoder acts as a target head, achieving higher sparsity than traditional convolution heads, resulting in reduced GFLOPs.For training, we introduce a novel one-to-many label assignment and an auxiliary denoising technique, significantly accelerating the model's convergence. Comprehensive experiments demonstrate the effectiveness and efficiency of our proposed method. For example, DETRack achieves 72.9% AO on the challenging GOT-10k benchmark using only 20% of the training epochs required by the baseline, and runs with lower GFLOPs than all the transformer-based trackers.
</details></li>
</ul>
<hr>
<h2 id="Progressive-Attention-Guidance-for-Whole-Slide-Vulvovaginal-Candidiasis-Screening"><a href="#Progressive-Attention-Guidance-for-Whole-Slide-Vulvovaginal-Candidiasis-Screening" class="headerlink" title="Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening"></a>Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02670">http://arxiv.org/abs/2309.02670</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cjdbehumble/miccai2023-vvc-screening">https://github.com/cjdbehumble/miccai2023-vvc-screening</a></li>
<li>paper_authors: Jiangdong Cai, Honglin Xiong, Maosong Cao, Luyan Liu, Lichi Zhang, Qian Wang</li>
<li>for: 这个论文是为了提出一种基于整体图像分类的自动诊断病理图像检测方法，以解决病理图像检测领域中缺乏标注数据和病原菌特有的问题。</li>
<li>methods: 该方法首先使用一个预训练的检测模型作为先前的指导，然后使用跳过自我关注模块来细化关注病原菌的细腻特征。最后，使用对比学习方法来降低由病理图像的样式差异引起的过拟合和关注到假阳性区域。</li>
<li>results: 我们的实验结果表明，我们的框架可以达到状态畅的性能。代码和示例数据可以在<a target="_blank" rel="noopener" href="https://github.com/cjdbehumble/MICCAI2023-VVC-Screening%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/cjdbehumble/MICCAI2023-VVC-Screening中找到。</a><details>
<summary>Abstract</summary>
Vulvovaginal candidiasis (VVC) is the most prevalent human candidal infection, estimated to afflict approximately 75% of all women at least once in their lifetime. It will lead to several symptoms including pruritus, vaginal soreness, and so on. Automatic whole slide image (WSI) classification is highly demanded, for the huge burden of disease control and prevention. However, the WSI-based computer-aided VCC screening method is still vacant due to the scarce labeled data and unique properties of candida. Candida in WSI is challenging to be captured by conventional classification models due to its distinctive elongated shape, the small proportion of their spatial distribution, and the style gap from WSIs. To make the model focus on the candida easier, we propose an attention-guided method, which can obtain a robust diagnosis classification model. Specifically, we first use a pre-trained detection model as prior instruction to initialize the classification model. Then we design a Skip Self-Attention module to refine the attention onto the fined-grained features of candida. Finally, we use a contrastive learning method to alleviate the overfitting caused by the style gap of WSIs and suppress the attention to false positive regions. Our experimental results demonstrate that our framework achieves state-of-the-art performance. Code and example data are available at https://github.com/cjdbehumble/MICCAI2023-VVC-Screening.
</details>
<details>
<summary>摘要</summary>
对于人类发炎病毒（VVC）而言，这是最常见的感染，估计会在所有女性中发生至少一次。它会导致一些 симптом，例如痒著、阴道疼痛等。由于这种疾病的管控和预防问题很大，因此数位数据支持的数位构成VCC检测方法是非常需要的。然而，这种数位构成方法仍然没有，因为缺乏标注数据和发炎菌的特殊性。发炎菌在数位构成中具有特殊的延长形状、小型的分布和数位构成的Style gap。为了让模型更容易捕捉发炎菌，我们提出了一个注意力引导的方法。具体来说，我们首先使用预训掌握的检测模型作为几何调教，然后设计了跳跃自我注意模组，以更新注意力以精细特征。最后，我们使用对比学习方法，以减少因数位构成的Style gap导致的过滤。我们的实验结果显示，我们的框架可以实现国际一级的表现。可以在https://github.com/cjdbehumble/MICCAI2023-VVC-Screening上获取代码和示例数据。
</details></li>
</ul>
<hr>
<h2 id="Fast-and-Resource-Efficient-Object-Tracking-on-Edge-Devices-A-Measurement-Study"><a href="#Fast-and-Resource-Efficient-Object-Tracking-on-Edge-Devices-A-Measurement-Study" class="headerlink" title="Fast and Resource-Efficient Object Tracking on Edge Devices: A Measurement Study"></a>Fast and Resource-Efficient Object Tracking on Edge Devices: A Measurement Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02666">http://arxiv.org/abs/2309.02666</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/git-disl/emo">https://github.com/git-disl/emo</a></li>
<li>paper_authors: Sanjana Vijay Ganesh, Yanzhao Wu, Gaowen Liu, Ramana Kompella, Ling Liu</li>
<li>For: This paper focuses on the performance issues and optimization opportunities for multi-object tracking (MOT) on edge devices with heterogeneous computing resources.* Methods: The paper proposes several edge-specific performance optimization strategies, called EMO, to speed up real-time object tracking, including window-based optimization and similarity-based optimization.* Results: The proposed EMO approach is competitive with respect to representative on-device object tracking techniques in terms of run-time performance and tracking accuracy, as demonstrated through extensive experiments on popular MOT benchmarks.<details>
<summary>Abstract</summary>
Object tracking is an important functionality of edge video analytic systems and services. Multi-object tracking (MOT) detects the moving objects and tracks their locations frame by frame as real scenes are being captured into a video. However, it is well known that real time object tracking on the edge poses critical technical challenges, especially with edge devices of heterogeneous computing resources. This paper examines the performance issues and edge-specific optimization opportunities for object tracking. We will show that even the well trained and optimized MOT model may still suffer from random frame dropping problems when edge devices have insufficient computation resources. We present several edge specific performance optimization strategies, collectively coined as EMO, to speed up the real time object tracking, ranging from window-based optimization to similarity based optimization. Extensive experiments on popular MOT benchmarks demonstrate that our EMO approach is competitive with respect to the representative methods for on-device object tracking techniques in terms of run-time performance and tracking accuracy. EMO is released on Github at https://github.com/git-disl/EMO.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译为简化中文。<</SYS>>Edge video analytic系统和服务中的目标跟踪功能非常重要。多目标跟踪（MOT）可以检测到摄像头中的移动目标，并在每帧中跟踪它们的位置。然而，在边缘设备上实时进行目标跟踪存在重要的技术挑战，尤其是边缘设备的不同计算资源。这篇论文检查了目标跟踪的性能问题和边缘设备特有的优化机会。我们将示出，即使使用最佳化的MOT模型，在边缘设备有限的计算资源情况下，仍可能出现随机帧掉pping问题。我们提出了多种边缘特定的性能优化策略，称为EMO，以加速实时目标跟踪。这些策略包括窗口优化和相似性优化等。我们在流行的MOT benchmark上进行了广泛的实验，并证明了我们的EMO方法与当前的边缘设备上的目标跟踪技术相比，在运行时性能和跟踪精度方面具有竞争力。EMO在GitHub上发布，请参考<https://github.com/git-disl/EMO>。
</details></li>
</ul>
<hr>
<h2 id="Multiclass-Alignment-of-Confidence-and-Certainty-for-Network-Calibration"><a href="#Multiclass-Alignment-of-Confidence-and-Certainty-for-Network-Calibration" class="headerlink" title="Multiclass Alignment of Confidence and Certainty for Network Calibration"></a>Multiclass Alignment of Confidence and Certainty for Network Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02636">http://arxiv.org/abs/2309.02636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vinith Kugathasan, Muhammad Haris Khan</li>
<li>For: 提高模型预测结果的准确性和可靠性，特别是在安全关键应用中。* Methods: 提出了一种新的训练时Calibration方法，基于模型预测信任度与确定性之间的差异，以提高模型的可靠性和准确性。* Results: 经过EXTENSIVE EXPERIMENTS的证明，该方法在十个复杂的数据集上取得了最佳的Calibration性能，包括在预测内部和外部预测中。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have made great strides in pushing the state-of-the-art in several challenging domains. Recent studies reveal that they are prone to making overconfident predictions. This greatly reduces the overall trust in model predictions, especially in safety-critical applications. Early work in improving model calibration employs post-processing techniques which rely on limited parameters and require a hold-out set. Some recent train-time calibration methods, which involve all model parameters, can outperform the postprocessing methods. To this end, we propose a new train-time calibration method, which features a simple, plug-and-play auxiliary loss known as multi-class alignment of predictive mean confidence and predictive certainty (MACC). It is based on the observation that a model miscalibration is directly related to its predictive certainty, so a higher gap between the mean confidence and certainty amounts to a poor calibration both for in-distribution and out-of-distribution predictions. Armed with this insight, our proposed loss explicitly encourages a confident (or underconfident) model to also provide a low (or high) spread in the presoftmax distribution. Extensive experiments on ten challenging datasets, covering in-domain, out-domain, non-visual recognition and medical image classification scenarios, show that our method achieves state-of-the-art calibration performance for both in-domain and out-domain predictions. Our code and models will be publicly released.
</details>
<details>
<summary>摘要</summary>
To improve model calibration, we propose a new train-time calibration method called multi-class alignment of predictive mean confidence and predictive certainty (MACC). This method is based on the observation that model miscalibration is directly related to predictive certainty, so a higher gap between the mean confidence and certainty indicates poor calibration for both in-distribution and out-of-distribution predictions. Our proposed loss explicitly encourages a confident (or underconfident) model to provide a low (or high) spread in the presoftmax distribution.We conduct extensive experiments on ten challenging datasets, covering in-domain, out-domain, non-visual recognition, and medical image classification scenarios, and show that our method achieves state-of-the-art calibration performance for both in-domain and out-domain predictions. Our code and models will be publicly released.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/06/cs.CV_2023_09_06/" data-id="clmvt7t9l00cg26rdfocb1uyc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/06/cs.AI_2023_09_06/" class="article-date">
  <time datetime="2023-09-06T12:00:00.000Z" itemprop="datePublished">2023-09-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/06/cs.AI_2023_09_06/">cs.AI - 2023-09-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-Role-of-Communication-and-Reference-Songs-in-the-Mixing-Process-Insights-from-Professional-Mix-Engineers"><a href="#The-Role-of-Communication-and-Reference-Songs-in-the-Mixing-Process-Insights-from-Professional-Mix-Engineers" class="headerlink" title="The Role of Communication and Reference Songs in the Mixing Process: Insights from Professional Mix Engineers"></a>The Role of Communication and Reference Songs in the Mixing Process: Insights from Professional Mix Engineers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03404">http://arxiv.org/abs/2309.03404</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumya Sai Vanka, Maryam Safi, Jean-Baptiste Rolland, György Fazekas</li>
<li>For: 这个论文的目的是研究专业混音工程师与客户之间的交流和反馈过程，以便更好地理解混音过程中的协作、共鸣和意图。* Methods: 这个研究使用了两个阶段的探索性研究方法，包括第一阶段的 semi-structured 采访，以及第二阶段的在线问卷调查。* Results: 这个研究发现，在混音过程中，协作、共鸣和意图是非常重要的，这些发现可以帮助开发智能多轨混音系统，以更好地支持这些实践。<details>
<summary>Abstract</summary>
Effective music mixing requires technical and creative finesse, but clear communication with the client is crucial. The mixing engineer must grasp the client's expectations, and preferences, and collaborate to achieve the desired sound. The tacit agreement for the desired sound of the mix is often established using guides like reference songs and demo mixes exchanged between the artist and the engineer and sometimes verbalised using semantic terms. This paper presents the findings of a two-phased exploratory study aimed at understanding how professional mixing engineers interact with clients and use their feedback to guide the mixing process. For phase one, semi-structured interviews were conducted with five mixing engineers with the aim of gathering insights about their communication strategies, creative processes, and decision-making criteria. Based on the inferences from these interviews, an online questionnaire was designed and administered to a larger group of 22 mixing engineers during the second phase. The results of this study shed light on the importance of collaboration, empathy, and intention in the mixing process, and can inform the development of smart multi-track mixing systems that better support these practices. By highlighting the significance of these findings, this paper contributes to the growing body of research on the collaborative nature of music production and provides actionable recommendations for the design and implementation of innovative mixing tools.
</details>
<details>
<summary>摘要</summary>
要有效地混音音乐，技术和创造力都是必要的，但与客户的沟通也非常重要。混音工程师必须理解客户的期望和喜好，并与其合作以实现感想中的音乐风格。在混音过程中，客户和工程师之间的含义和听众往往通过参考歌曲和演示混音来建立共识。这篇论文介绍了一项两期探索性研究，旨在了解专业混音工程师与客户之间的交流方式、创作过程和决策标准。第一阶段，我们采访了5名混音工程师，以了解他们的沟通策略、创作过程和决策标准。基于这些采访的结论，我们 THEN designed an online问卷，并在第二阶段向22名混音工程师进行了调查。这些结果 shed light on the importance of collaboration, empathy, and intention in the mixing process, and can inform the development of smart multi-track mixing systems that better support these practices. By highlighting the significance of these findings, this paper contributes to the growing body of research on the collaborative nature of music production and provides actionable recommendations for the design and implementation of innovative mixing tools.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Baselines-for-Motion-Prediction-in-Autonomous-Driving"><a href="#Efficient-Baselines-for-Motion-Prediction-in-Autonomous-Driving" class="headerlink" title="Efficient Baselines for Motion Prediction in Autonomous Driving"></a>Efficient Baselines for Motion Prediction in Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03387">http://arxiv.org/abs/2309.03387</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cram3r95/mapfe4mp">https://github.com/cram3r95/mapfe4mp</a></li>
<li>paper_authors: Carlos Gómez-Huélamo, Marcos V. Conde, Rafael Barea, Manuel Ocaña, Luis M. Bergasa</li>
<li>for: 这篇论文的目的是提出一些高效的基准方案来解决多个环境中的动作预测问题（MP），以便在复杂的环境中实现自动驾驶栈（ADS）。</li>
<li>methods: 这篇论文使用了现有的SOTA技术，包括注意力机制和图 Né net，以及一种新的预处理步骤，基于动力学约束，来生成可靠的多Modal轨迹。</li>
<li>results: 论文的实验结果表明，该方法可以在 Argoverse 1 动作预测benchmark上达到与其他SOTA方法相同的精度水平，但具有更少的操作和参数，以及更好的可读性。<details>
<summary>Abstract</summary>
Motion Prediction (MP) of multiple surroundings agents is a crucial task in arbitrarily complex environments, from simple robots to Autonomous Driving Stacks (ADS). Current techniques tackle this problem using end-to-end pipelines, where the input data is usually a rendered top-view of the physical information and the past trajectories of the most relevant agents; leveraging this information is a must to obtain optimal performance. In that sense, a reliable ADS must produce reasonable predictions on time. However, despite many approaches use simple ConvNets and LSTMs to obtain the social latent features, State-Of-The-Art (SOTA) models might be too complex for real-time applications when using both sources of information (map and past trajectories) as well as little interpretable, specially considering the physical information. Moreover, the performance of such models highly depends on the number of available inputs for each particular traffic scenario, which are expensive to obtain, particularly, annotated High-Definition (HD) maps.   In this work, we propose several efficient baselines for the well-known Argoverse 1 Motion Forecasting Benchmark. We aim to develop compact models using SOTA techniques for MP, including attention mechanisms and GNNs. Our lightweight models use standard social information and interpretable map information such as points from the driveable area and plausible centerlines by means of a novel preprocessing step based on kinematic constraints, in opposition to black-box CNN-based or too-complex graphs methods for map encoding, to generate plausible multimodal trajectories achieving up-to-pair accuracy with less operations and parameters than other SOTA methods. Our code is publicly available at https://github.com/Cram3r95/mapfe4mp .
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT多 surroundings agent 的动态预测（MP）在无序复杂环境中是关键任务，从简单的机器人到自动驾驶栈（ADS）都是如此。现有技术使用端到端管道来解决这个问题，输入数据通常是 render 的顶视图 Physical information 和过去 trajectory 最 relevante  agents; 利用这些信息是必须以获取优化性能。在这种情况下，一个可靠的 ADS 必须在时间上 produz 合理的预测。然而，虽然许多方法使用简单的 ConvNet 和 LSTM 来获取社交尘肤特征，但 SOTA 模型可能在实时应用中过于复杂，特别是使用多种输入信息（地图和过去 trajectory）以及具有少量解释能力，尤其是考虑物理信息。此外，这些模型的性能强度取决于输入信息的数量，这些信息可能昂贵并且困难以获取，特别是需要注释高分辨率地图。在这种情况下，我们提出了一些高效的基线 для Argoverse 1 动态预测挑战 зада。我们目标是开发 compact 的模型，使用 SOTA 技术来实现 MP，包括注意机制和 GNNs。我们的轻量级模型使用标准的社交信息和可读的地图信息，例如 driveable 区域的点和可能的中心线，通过一种新的预处理步骤基于动力学约束来生成可能的多模态轨迹，实现对拥有同等精度的 SOTA 方法相同的准确率，并且具有更少的操作和参数。我们的代码公开可用于 <https://github.com/Cram3r95/mapfe4mp>。<<SYS/
</details></li>
</ul>
<hr>
<h2 id="Community-Based-Hierarchical-Positive-Unlabeled-PU-Model-Fusion-for-Chronic-Disease-Prediction"><a href="#Community-Based-Hierarchical-Positive-Unlabeled-PU-Model-Fusion-for-Chronic-Disease-Prediction" class="headerlink" title="Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for Chronic Disease Prediction"></a>Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for Chronic Disease Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03386">http://arxiv.org/abs/2309.03386</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangwu001/putree">https://github.com/yangwu001/putree</a></li>
<li>paper_authors: Yang Wu, Xurui Li, Xuhong Zhang, Yangyang Kang, Changlong Sun, Xiaozhong Liu</li>
<li>for: 这篇论文旨在解决 Chronic disease screening 问题，使用 Positive-Unlabeled (PU) Learning 方法，并考虑不同人口群体之间的差异。</li>
<li>methods: 本研究提出了一个新的 Positive-Unlabeled Learning Tree (PUtree) 算法，具有社区建立 PU 模型的能力，并通过统计融合不同社区的模型得到更加稳定的 Binary 分类结果。</li>
<li>results: 在两个 Benchmark 和一个新的 Diabetes 预测数据集上，PUtree 和其变种实现了更好的性能，较之前的 State-of-the-art PU learning 方法。<details>
<summary>Abstract</summary>
Positive-Unlabeled (PU) Learning is a challenge presented by binary classification problems where there is an abundance of unlabeled data along with a small number of positive data instances, which can be used to address chronic disease screening problem. State-of-the-art PU learning methods have resulted in the development of various risk estimators, yet they neglect the differences among distinct populations. To address this issue, we present a novel Positive-Unlabeled Learning Tree (PUtree) algorithm. PUtree is designed to take into account communities such as different age or income brackets, in tasks of chronic disease prediction. We propose a novel approach for binary decision-making, which hierarchically builds community-based PU models and then aggregates their deliverables. Our method can explicate each PU model on the tree for the optimized non-leaf PU node splitting. Furthermore, a mask-recovery data augmentation strategy enables sufficient training of the model in individual communities. Additionally, the proposed approach includes an adversarial PU risk estimator to capture hierarchical PU-relationships, and a model fusion network that integrates data from each tree path, resulting in robust binary classification results. We demonstrate the superior performance of PUtree as well as its variants on two benchmarks and a new diabetes-prediction dataset.
</details>
<details>
<summary>摘要</summary>
Positive-Unlabeled (PU) 学习是 binary 分类问题中的一个挑战，其中有大量无标注数据和一小数量的正样本，可以用来解决慢性病creening问题。现有的PU学习方法已经导致了不同的风险估计器的开发，但它们忽略了不同人口群体之间的差异。为解决这个问题，我们提出了一种新的Positive-Unlabeled学习树（PUtree）算法。PUtree采用了社区分割的方法，如年龄或收入等，在慢性病预测任务中进行分类。我们提出了一种基于社区的二分法，即在社区中建立PU模型，然后对每个社区进行综合分类。此外，我们还提出了一种面具恢复数据增强策略，以便训练模型在每个社区中。此外，我们还提出了一种对 hierarchical PU 关系进行捕捉的 adversarial PU 风险估计器，以及一种拼接数据从每个树路的模型融合网络，以实现Robust binary 分类结果。我们在两个标准 benchmark 和一个新的 диабеتesprediction 数据集上展示了PUtree 的超越性和其变种的表现。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Masked-Digital-Elevation-Models-Encoding-for-Low-Resource-Downstream-Tasks"><a href="#Self-Supervised-Masked-Digital-Elevation-Models-Encoding-for-Low-Resource-Downstream-Tasks" class="headerlink" title="Self-Supervised Masked Digital Elevation Models Encoding for Low-Resource Downstream Tasks"></a>Self-Supervised Masked Digital Elevation Models Encoding for Low-Resource Downstream Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03367">http://arxiv.org/abs/2309.03367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Priyam Mazumdar, Aiman Soliman, Volodymyr Kindratenko, Luigi Marini, Kenton McHenry</li>
<li>for: 本研究的目的是提取基本建筑和路况信息从数字高程模型（DEM），以提供详细的地表 topology。</li>
<li>methods: 该模型使用遮盖 autoencoder 预训练 ImageNet（尽管存在大领域差异），并添加 UperNet 头来解码 segmentation。</li>
<li>results: 模型在建筑 segmentation 任务上获得 82.1% 交集 overlap（IoU）使用 450 张图像，并在只使用 50 张图像时获得 69.1% IoU。在更加困难的路况检测任务上，模型获得 82.7% IoU 使用 450 张图像，并在只使用 50 张图像时获得 73.2% IoU。<details>
<summary>Abstract</summary>
The lack of quality labeled data is one of the main bottlenecks for training Deep Learning models. As the task increases in complexity, there is a higher penalty for overfitting and unstable learning. The typical paradigm employed today is Self-Supervised learning, where the model attempts to learn from a large corpus of unstructured and unlabeled data and then transfer that knowledge to the required task. Some notable examples of self-supervision in other modalities are BERT for Large Language Models, Wav2Vec for Speech Recognition, and the Masked AutoEncoder for Vision, which all utilize Transformers to solve a masked prediction task. GeoAI is uniquely poised to take advantage of the self-supervised methodology due to the decades of data collected, little of which is precisely and dependably annotated. Our goal is to extract building and road segmentations from Digital Elevation Models (DEM) that provide a detailed topography of the earths surface. The proposed architecture is the Masked Autoencoder pre-trained on ImageNet (with the limitation that there is a large domain discrepancy between ImageNet and DEM) with an UperNet Head for decoding segmentations. We tested this model with 450 and 50 training images only, utilizing roughly 5% and 0.5% of the original data respectively. On the building segmentation task, this model obtains an 82.1% Intersection over Union (IoU) with 450 Images and 69.1% IoU with only 50 images. On the more challenging road detection task the model obtains an 82.7% IoU with 450 images and 73.2% IoU with only 50 images. Any hand-labeled dataset made today about the earths surface will be immediately obsolete due to the constantly changing nature of the landscape. This motivates the clear necessity for data-efficient learners that can be used for a wide variety of downstream tasks.
</details>
<details>
<summary>摘要</summary>
“缺乏质量标注数据是深度学习模型训练的主要瓶颈。随着任务的复杂度增加，模型会面临更高的溢出和不稳定学习 penalty。当今通用的方法是自我超vised学习，其中模型尝试从大量未结构化和未标注数据中学习知识，然后将其应用到需要的任务上。 notable example包括BERT для大语言模型、Wav2Vec для语音识别和视觉领域中的Masked AutoEncoder，它们都使用Transformers解决了masked prediction任务。GeoAI具有自我超vised方法的优势，因为它拥有大量数据，但只有少量准确和可靠地标注。我们的目标是从数字高程模型（DEM）中提取建筑和路径分割，以获得详细的地表 topology。我们提议使用Masked Autoencoder预训练在ImageNet（具有大领域差异）和UpperNet Head для解码分割。我们使用450和50张图像进行测试，只使用原始数据的5%和0.5%。在建筑分割任务中，这个模型 obtiains 82.1%的Intersection over Union（IoU），使用450张图像时 obtiains 69.1%的IoU，使用50张图像时 obtiains 82.7%的IoU。在更加困难的道路检测任务中，模型 obtiains 82.7%的IoU，使用450张图像时 obtiains 73.2%的IoU。由于地表面的不断变化，任何手动标注的数据今天都将是过时的。这种情况激励我们需要数据效率的学习者，可以用于各种下游任务。”
</details></li>
</ul>
<hr>
<h2 id="ETP-Learning-Transferable-ECG-Representations-via-ECG-Text-Pre-training"><a href="#ETP-Learning-Transferable-ECG-Representations-via-ECG-Text-Pre-training" class="headerlink" title="ETP: Learning Transferable ECG Representations via ECG-Text Pre-training"></a>ETP: Learning Transferable ECG Representations via ECG-Text Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07145">http://arxiv.org/abs/2309.07145</a></li>
<li>repo_url: None</li>
<li>paper_authors: Che Liu, Zhongwei Wan, Sibo Cheng, Mi Zhang, Rossella Arcucci</li>
<li>for: 针对卡路达学健康领域的电位图 (ECG) 作为非侵入性诊断工具，尝试使用自然语言描述 (NLP) 技术来学习 ECG 的特征表示。</li>
<li>methods: 我们提出了一种新的框架，即 ECG 文本预训练 (ETP)，它通过将 ECG 信号与文本报告相对应，来学习cross-模态的 ECG 特征表示。ETP 使用了 ECG 编码器和预训练的自然语言模型，以实现 ECG 信号与文本报告的对应。</li>
<li>results: ETP 在 linear 评估任务和零容量分类任务中表现出色，在 PTB-XL 和 CPSC2018 数据集上进行了证明。ETP 能够学习 Robust 和通用的 cross-模态 ECG 特征表示，并且在不同的类别上具有良好的一致性。<details>
<summary>Abstract</summary>
In the domain of cardiovascular healthcare, the Electrocardiogram (ECG) serves as a critical, non-invasive diagnostic tool. Although recent strides in self-supervised learning (SSL) have been promising for ECG representation learning, these techniques often require annotated samples and struggle with classes not present in the fine-tuning stages. To address these limitations, we introduce ECG-Text Pre-training (ETP), an innovative framework designed to learn cross-modal representations that link ECG signals with textual reports. For the first time, this framework leverages the zero-shot classification task in the ECG domain. ETP employs an ECG encoder along with a pre-trained language model to align ECG signals with their corresponding textual reports. The proposed framework excels in both linear evaluation and zero-shot classification tasks, as demonstrated on the PTB-XL and CPSC2018 datasets, showcasing its ability for robust and generalizable cross-modal ECG feature learning.
</details>
<details>
<summary>摘要</summary>
在心血管健康领域，电cardiogram (ECG) 作为一种非侵入性诊断工具，扮演着关键的角色。 although recent advances in self-supervised learning (SSL) 在 ECG 表示学习方面具有承诺的进步，这些技术通常需要标注样本，并且在精度调整阶段难以处理不存在的类型。 To address these limitations, we introduce ECG-Text Pre-training (ETP), a novel framework designed to learn cross-modal representations that link ECG signals with textual reports. This framework leverages the zero-shot classification task in the ECG domain for the first time. ETP employs an ECG encoder along with a pre-trained language model to align ECG signals with their corresponding textual reports. The proposed framework excels in both linear evaluation and zero-shot classification tasks, as demonstrated on the PTB-XL and CPSC2018 datasets, showcasing its ability for robust and generalizable cross-modal ECG feature learning.
</details></li>
</ul>
<hr>
<h2 id="REBOOT-Reuse-Data-for-Bootstrapping-Efficient-Real-World-Dexterous-Manipulation"><a href="#REBOOT-Reuse-Data-for-Bootstrapping-Efficient-Real-World-Dexterous-Manipulation" class="headerlink" title="REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation"></a>REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03322">http://arxiv.org/abs/2309.03322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheyuan Hu, Aaron Rovinsky, Jianlan Luo, Vikash Kumar, Abhishek Gupta, Sergey Levine</li>
<li>for: 学习灵活的抓取技能，以提高机器人手臂在实际世界中的操作能力。</li>
<li>methods: 利用近期的可效RL和重播缓存启动技术，将不同任务或物品的数据作为新任务的启动点，大幅提高学习效率。</li>
<li>results: 在实际世界中使用四 fingers 机器人手臂快速学习复杂的抓取技能，并完成实际训练周期，无需人工重置和奖励工程。<details>
<summary>Abstract</summary>
Dexterous manipulation tasks involving contact-rich interactions pose a significant challenge for both model-based control systems and imitation learning algorithms. The complexity arises from the need for multi-fingered robotic hands to dynamically establish and break contacts, balance non-prehensile forces, and control large degrees of freedom. Reinforcement learning (RL) offers a promising approach due to its general applicability and capacity to autonomously acquire optimal manipulation strategies. However, its real-world application is often hindered by the necessity to generate a large number of samples, reset the environment, and obtain reward signals. In this work, we introduce an efficient system for learning dexterous manipulation skills with RL to alleviate these challenges. The main idea of our approach is the integration of recent advances in sample-efficient RL and replay buffer bootstrapping. This combination allows us to utilize data from different tasks or objects as a starting point for training new tasks, significantly improving learning efficiency. Additionally, our system completes the real-world training cycle by incorporating learned resets via an imitation-based pickup policy as well as learned reward functions, eliminating the need for manual resets and reward engineering. We demonstrate the benefits of reusing past data as replay buffer initialization for new tasks, for instance, the fast acquisition of intricate manipulation skills in the real world on a four-fingered robotic hand. (Videos: https://sites.google.com/view/reboot-dexterous)
</details>
<details>
<summary>摘要</summary>
dexterous manipulation task involving contact-rich interactions 是控制系统和模仿学习算法难以处理的挑战。这些复杂性来自 robotic hands 需要在动态建立和破坏 contacts, 平衡非握持力, 和控制大度自由度。 reinforcement learning (RL) 提供了一个有希望的方法，因为它可以自主地获得优化的抓取策略。然而，它的实际应用frequently hindered by the need to generate a large number of samples, reset the environment, and obtain reward signals.在这项工作中，我们介绍了一种高效的RL系统，用于学习dexterous manipulation skills。我们的方法基于 latest advances in sample-efficient RL 和 replay buffer bootstrapping。这种组合允许我们利用不同任务或对象的数据作为新任务的训练开始，从而显著提高学习效率。此外，我们的系统在实际世界训练周期中完成了学习重置和获得奖励信号的操作，从而消除了手动重置和奖励工程化的需求。我们在实际世界中使用了 learned resets 和 learned reward functions，以完成实际世界训练周期。我们示出了 reuse past data as replay buffer initialization for new tasks 的好处，例如在 four-fingered robotic hand 上快速获得复杂的抓取技能。（视频：https://sites.google.com/view/reboot-dexterous)
</details></li>
</ul>
<hr>
<h2 id="Fitness-Approximation-through-Machine-Learning"><a href="#Fitness-Approximation-through-Machine-Learning" class="headerlink" title="Fitness Approximation through Machine Learning"></a>Fitness Approximation through Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03318">http://arxiv.org/abs/2309.03318</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/itaitzruia4/approxml">https://github.com/itaitzruia4/approxml</a></li>
<li>paper_authors: Itai Tzruia, Tomer Halperin, Moshe Sipper, Achiya Elyasaf</li>
<li>for: 这个论文主要目标是提出一种基于机器学习模型的遗传算法中的健康估计方法，以优化遗传算法的运行效率。</li>
<li>methods: 该方法使用机器学习模型来保持一个遗传算法中个体的健康估计，并在进行遗传算法的演化运行中不断更新该模型。</li>
<li>results: 实验结果表明，使用该方法可以显著提高遗传算法的运行效率，并且fitness分数与实际遗传算法的fitness分数相似或者只有轻微差异。<details>
<summary>Abstract</summary>
We present a novel approach to performing fitness approximation in genetic algorithms (GAs) using machine-learning (ML) models, focusing on evolutionary agents in Gymnasium (game) simulators -- where fitness computation is costly. Maintaining a dataset of sampled individuals along with their actual fitness scores, we continually update throughout an evolutionary run a fitness-approximation ML model. We compare different methods for: 1) switching between actual and approximate fitness, 2) sampling the population, and 3) weighting the samples. Experimental findings demonstrate significant improvement in evolutionary runtimes, with fitness scores that are either identical or slightly lower than that of the fully run GA -- depending on the ratio of approximate-to-actual-fitness computation. Our approach is generic and can be easily applied to many different domains.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，用机器学习（ML）模型来实现遗传算法（GA）中的健康估计，专注于在游戏仿真器（Gymnasium）中的进化代理人。在计算质量高的情况下，我们 continually 更新一个包含采样个体以及其实际健康分的数据集。我们比较了不同的方法来：1）在实际和估计健康之间切换，2）采样人口，和3）Weighting样本。我们的实验结果表明，我们的方法可以显著提高进化时间，并且健康分几乎与完全运行GA的健康分相同或者只有略低一些，具体取决于估计与实际健康计算的比率。我们的方法是通用的，可以适用于多种领域。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-Deep-Fake-Algorithms"><a href="#Comparative-Analysis-of-Deep-Fake-Algorithms" class="headerlink" title="Comparative Analysis of Deep-Fake Algorithms"></a>Comparative Analysis of Deep-Fake Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03295">http://arxiv.org/abs/2309.03295</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhil Sontakke, Sejal Utekar, Shivansh Rastogi, Shriraj Sonawane</li>
<li>for: 本研究旨在提供深度伪造技术的现状概述，包括深度学习基于的伪造创建方法和检测技术。</li>
<li>methods: 本研究使用多种方法来检测深度伪造视频，包括人脸识别、运动分析和音频视频同步。</li>
<li>results: 本研究发现现有的深度伪造检测技术具有限制和挑战，需要进一步的研究和发展以确保数字视频的真实性。<details>
<summary>Abstract</summary>
Due to the widespread use of smartphones with high-quality digital cameras and easy access to a wide range of software apps for recording, editing, and sharing videos and images, as well as the deep learning AI platforms, a new phenomenon of 'faking' videos has emerged. Deepfake algorithms can create fake images and videos that are virtually indistinguishable from authentic ones. Therefore, technologies that can detect and assess the integrity of digital visual media are crucial. Deepfakes, also known as deep learning-based fake videos, have become a major concern in recent years due to their ability to manipulate and alter images and videos in a way that is virtually indistinguishable from the original. These deepfake videos can be used for malicious purposes such as spreading misinformation, impersonating individuals, and creating fake news. Deepfake detection technologies use various approaches such as facial recognition, motion analysis, and audio-visual synchronization to identify and flag fake videos. However, the rapid advancement of deepfake technologies has made it increasingly difficult to detect these videos with high accuracy. In this paper, we aim to provide a comprehensive review of the current state of deepfake creation and detection technologies. We examine the various deep learning-based approaches used for creating deepfakes, as well as the techniques used for detecting them. Additionally, we analyze the limitations and challenges of current deepfake detection methods and discuss future research directions in this field. Overall, the paper highlights the importance of continued research and development in deepfake detection technologies in order to combat the negative impact of deepfakes on society and ensure the integrity of digital visual media.
</details>
<details>
<summary>摘要</summary>
Due to the widespread use of smartphones with high-quality digital cameras and easy access to a wide range of software apps for recording, editing, and sharing videos and images, as well as the deep learning AI platforms, a new phenomenon of 'faking' videos has emerged. Deepfake algorithms can create fake images and videos that are virtually indistinguishable from authentic ones. Therefore, technologies that can detect and assess the integrity of digital visual media are crucial. Deepfakes, also known as deep learning-based fake videos, have become a major concern in recent years due to their ability to manipulate and alter images and videos in a way that is virtually indistinguishable from the original. These deepfake videos can be used for malicious purposes such as spreading misinformation, impersonating individuals, and creating fake news. Deepfake detection technologies use various approaches such as facial recognition, motion analysis, and audio-visual synchronization to identify and flag fake videos. However, the rapid advancement of deepfake technologies has made it increasingly difficult to detect these videos with high accuracy. In this paper, we aim to provide a comprehensive review of the current state of deepfake creation and detection technologies. We examine the various deep learning-based approaches used for creating deepfakes, as well as the techniques used for detecting them. Additionally, we analyze the limitations and challenges of current deepfake detection methods and discuss future research directions in this field. Overall, the paper highlights the importance of continued research and development in deepfake detection technologies in order to combat the negative impact of deepfakes on society and ensure the integrity of digital visual media.
</details></li>
</ul>
<hr>
<h2 id="My-Art-My-Choice-Adversarial-Protection-Against-Unruly-AI"><a href="#My-Art-My-Choice-Adversarial-Protection-Against-Unruly-AI" class="headerlink" title="My Art My Choice: Adversarial Protection Against Unruly AI"></a>My Art My Choice: Adversarial Protection Against Unruly AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03198">http://arxiv.org/abs/2309.03198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anthony Rhodes, Ram Bhagat, Umur Aybars Ciftci, Ilke Demir</li>
<li>for: 保护创作者的版权，防止Diffusion模型把艺术作品利用为自己的目的。</li>
<li>methods: 使用UNet生成器、多种损失函数、对黑盒Diffusion模型进行攻击，生成”保护”版本的图像，以做到对 diffusion模型的防御。</li>
<li>results: 在多个图像-图像任务上进行了实验，并评估了”保护”版本图像和Diffusion模型输出结果的视觉、噪音、结构、像素和生成空间性能，以验证我们的主张。<details>
<summary>Abstract</summary>
Generative AI is on the rise, enabling everyone to produce realistic content via publicly available interfaces. Especially for guided image generation, diffusion models are changing the creator economy by producing high quality low cost content. In parallel, artists are rising against unruly AI, since their artwork are leveraged, distributed, and dissimulated by large generative models. Our approach, My Art My Choice (MAMC), aims to empower content owners by protecting their copyrighted materials from being utilized by diffusion models in an adversarial fashion. MAMC learns to generate adversarially perturbed "protected" versions of images which can in turn "break" diffusion models. The perturbation amount is decided by the artist to balance distortion vs. protection of the content. MAMC is designed with a simple UNet-based generator, attacking black box diffusion models, combining several losses to create adversarial twins of the original artwork. We experiment on three datasets for various image-to-image tasks, with different user control values. Both protected image and diffusion output results are evaluated in visual, noise, structure, pixel, and generative spaces to validate our claims. We believe that MAMC is a crucial step for preserving ownership information for AI generated content in a flawless, based-on-need, and human-centric way.
</details>
<details>
<summary>摘要</summary>
“生成AI在崛起，让每个人可以生成真实的内容通过公开可用的界面。尤其是导航图像生成，扩散模型在创新经济中产生高品质低成本的内容。在平行的情况下，艺术家在不良AI的挑战下，因为他们的艺术作品被扩散、分布和歪化了大量生成模型。我们的方法，“我的艺术，我的选择”（MAMC），旨在强化内容拥有者的权益，对扩散模型进行反对式使用的内容。MAMC使用了一个简单的UNet型生成器，攻击黑盒扩散模型，结合了多种损失函数创建反对双生的原始艺术作品。我们在三个 dataset上进行了多种图像转换任务的实验，不同的用户控制值。两个受保护图像和扩散输出结果在视觉、噪音、结构、像素和生成空间进行评估，以验证我们的声明。我们相信MAMC是为AI生成内容的拥有者掌握权益的重要一步，以精彩、需要、人性化的方式。”
</details></li>
</ul>
<hr>
<h2 id="Temporal-Inductive-Path-Neural-Network-for-Temporal-Knowledge-Graph-Reasoning"><a href="#Temporal-Inductive-Path-Neural-Network-for-Temporal-Knowledge-Graph-Reasoning" class="headerlink" title="Temporal Inductive Path Neural Network for Temporal Knowledge Graph Reasoning"></a>Temporal Inductive Path Neural Network for Temporal Knowledge Graph Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03251">http://arxiv.org/abs/2309.03251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Dong, Pengyang Wang, Meng Xiao, Zhiyuan Ning, Pengfei Wang, Yuanchun Zhou</li>
<li>for: 该论文旨在提高 temps 知识图（TKG） reasoning 任务的性能，特别是在处理历史信息和新生成的实体时。</li>
<li>methods: 该论文提出了一种名为 Temporal Inductive Path Neural Network（TiPNN）的模型，它在entity-independent的角度模型历史信息，并通过定义query-aware的时间路径来模型历史路径信息相关于查询。</li>
<li>results: 实验结果表明，提出的模型不仅具有显著性能提升，还能够处理 inductive 设定，并且可以提供历史图中的理由证明。<details>
<summary>Abstract</summary>
Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph (KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial task that aims to predict future facts based on historical occurrences. The key challenge lies in uncovering structural dependencies within historical subgraphs and temporal patterns. Most existing approaches model TKGs relying on entity modeling, as nodes in the graph play a crucial role in knowledge representation. However, the real-world scenario often involves an extensive number of entities, with new entities emerging over time. This makes it challenging for entity-dependent methods to cope with extensive volumes of entities, and effectively handling newly emerging entities also becomes a significant challenge. Therefore, we propose Temporal Inductive Path Neural Network (TiPNN), which models historical information in an entity-independent perspective. Specifically, TiPNN adopts a unified graph, namely history temporal graph, to comprehensively capture and encapsulate information from history. Subsequently, we utilize the defined query-aware temporal paths to model historical path information related to queries on history temporal graph for the reasoning. Extensive experiments illustrate that the proposed model not only attains significant performance enhancements but also handles inductive settings, while additionally facilitating the provision of reasoning evidence through history temporal graphs.
</details>
<details>
<summary>摘要</summary>
Temporal Knowledge Graph (TKG) 是传统知识图 (KG) 的扩展，它包含时间dimension。理解 TKGs 是一个重要的任务，旨在根据历史发生项来预测未来的事实。主要挑战在于探索历史子图中的结构依赖关系和时间对称。现有的方法通常基于实体模型，将node在图中扮演重要的知识表示角色。但是，实际情况中通常会有很多实体，新实体随时出现，这使得实体dependent的方法很难处理大量的实体，同时新出现的实体也成为一个主要挑战。因此，我们提出了Temporal Inductive Path Neural Network (TiPNN)，它在实体独立的角度来模型历史信息。具体来说，TiPNN使用了一个统一的图，即历史时间图，以全面捕捉和储存历史信息。然后，我们使用定义的查询相依时间路径来模型对历史时间图的查询。实验结果显示，提案的模型不仅实现了重要的性能提升，同时也能够处理 inductive 设定，并且可以通过历史时间图来提供理解证据。
</details></li>
</ul>
<hr>
<h2 id="Split-Boost-Neural-Networks"><a href="#Split-Boost-Neural-Networks" class="headerlink" title="Split-Boost Neural Networks"></a>Split-Boost Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03167">http://arxiv.org/abs/2309.03167</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aastha2104/Parkinson-Disease-Prediction">https://github.com/Aastha2104/Parkinson-Disease-Prediction</a></li>
<li>paper_authors: Raffaele Giuseppe Cestari, Gabriele Maroni, Loris Cannelli, Dario Piga, Simone Formentin</li>
<li>for: 这篇研究的目的是提出一种对于单向神经网络的训练和准确化方法，以提高性能并自动包含调整行为而不需要直接模型。</li>
<li>methods: 这篇研究使用了一种称为”split-boost”的新训练策略，它可以增强性能并自动包含调整行为，不需要直接模型。</li>
<li>results: 研究中使用了一个匿名的医疗保险设计问题的实际数据集，结果显示了该策略可以提高性能和减少调整时间。<details>
<summary>Abstract</summary>
The calibration and training of a neural network is a complex and time-consuming procedure that requires significant computational resources to achieve satisfactory results. Key obstacles are a large number of hyperparameters to select and the onset of overfitting in the face of a small amount of data. In this framework, we propose an innovative training strategy for feed-forward architectures - called split-boost - that improves performance and automatically includes a regularizing behaviour without modeling it explicitly. Such a novel approach ultimately allows us to avoid explicitly modeling the regularization term, decreasing the total number of hyperparameters and speeding up the tuning phase. The proposed strategy is tested on a real-world (anonymized) dataset within a benchmark medical insurance design problem.
</details>
<details>
<summary>摘要</summary>
neural network 的准确和训练是一个复杂且时间consuming的过程，需要大量的计算资源以获得满意的结果。关键障碍是大量的 hyperparameter 选择和数据少的情况下遇到过拟合。在这个框架下，我们提出了一种创新的训练策略 для径向网络 - called split-boost - 可以提高性能并自动包含了正则化行为而无需显式模型。这种新的方法最终允许我们避免显式模型正则化项，减少总的 hyperparameter 数量，加速调整阶段。我们在一个匿名的实际数据集上进行了一个审核医疗保险设计问题。
</details></li>
</ul>
<hr>
<h2 id="J-Guard-Journalism-Guided-Adversarially-Robust-Detection-of-AI-generated-News"><a href="#J-Guard-Journalism-Guided-Adversarially-Robust-Detection-of-AI-generated-News" class="headerlink" title="J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News"></a>J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03164">http://arxiv.org/abs/2309.03164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tharindu Kumarage, Amrita Bhattacharjee, Djordje Padejski, Kristy Roschke, Dan Gillmor, Scott Ruston, Huan Liu, Joshua Garland</li>
<li>for: 本研究旨在寻找一种可靠地检测AI生成的新闻文章，以避免在线的谣言散播。</li>
<li>methods: 该研究利用了一个多 disciplinary 团队的专业知识，开发了一个名为 J-Guard 的框架，可以改进现有的超级vised AI 文本检测器，以便更好地分辨真实的新闻文章和 AI 生成的文章。</li>
<li>results:  experiments 表明，J-Guard 可以增强检测能力，同时在面对黑客攻击时保持了 average 的性能下降只有 7%。<details>
<summary>Abstract</summary>
The rapid proliferation of AI-generated text online is profoundly reshaping the information landscape. Among various types of AI-generated text, AI-generated news presents a significant threat as it can be a prominent source of misinformation online. While several recent efforts have focused on detecting AI-generated text in general, these methods require enhanced reliability, given concerns about their vulnerability to simple adversarial attacks. Furthermore, due to the eccentricities of news writing, applying these detection methods for AI-generated news can produce false positives, potentially damaging the reputation of news organizations. To address these challenges, we leverage the expertise of an interdisciplinary team to develop a framework, J-Guard, capable of steering existing supervised AI text detectors for detecting AI-generated news while boosting adversarial robustness. By incorporating stylistic cues inspired by the unique journalistic attributes, J-Guard effectively distinguishes between real-world journalism and AI-generated news articles. Our experiments on news articles generated by a vast array of AI models, including ChatGPT (GPT3.5), demonstrate the effectiveness of J-Guard in enhancing detection capabilities while maintaining an average performance decrease of as low as 7% when faced with adversarial attacks.
</details>
<details>
<summary>摘要</summary>
人工智能生成文本在线的快速扩散正在深刻地改变信息景观。 Among various types of AI-generated text, AI-generated news presents a significant threat as it can be a prominent source of misinformation online. While several recent efforts have focused on detecting AI-generated text in general, these methods require enhanced reliability, given concerns about their vulnerability to simple adversarial attacks. Furthermore, due to the eccentricities of news writing, applying these detection methods for AI-generated news can produce false positives, potentially damaging the reputation of news organizations. To address these challenges, we leverage the expertise of an interdisciplinary team to develop a framework, J-Guard, capable of steering existing supervised AI text detectors for detecting AI-generated news while boosting adversarial robustness. By incorporating stylistic cues inspired by the unique journalistic attributes, J-Guard effectively distinguishes between real-world journalism and AI-generated news articles. Our experiments on news articles generated by a vast array of AI models, including ChatGPT (GPT3.5), demonstrate the effectiveness of J-Guard in enhancing detection capabilities while maintaining an average performance decrease of as low as 7% when faced with adversarial attacks.
</details></li>
</ul>
<hr>
<h2 id="Risk-reducing-design-and-operations-toolkit-90-strategies-for-managing-risk-and-uncertainty-in-decision-problems"><a href="#Risk-reducing-design-and-operations-toolkit-90-strategies-for-managing-risk-and-uncertainty-in-decision-problems" class="headerlink" title="Risk-reducing design and operations toolkit: 90 strategies for managing risk and uncertainty in decision problems"></a>Risk-reducing design and operations toolkit: 90 strategies for managing risk and uncertainty in decision problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03133">http://arxiv.org/abs/2309.03133</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sashagutfraind/uncertainty_strategies">https://github.com/sashagutfraind/uncertainty_strategies</a></li>
<li>paper_authors: Alexander Gutfraind</li>
<li>for: 这篇论文是为了探讨和发展一个叫做 RDOT（Risk-reducing Design and Operations Toolkit）的解决方案，这些解决方案可以在面对高度不确定的问题时提供有效的回应。</li>
<li>methods: 这篇论文使用了一种称为多元目标优化的方法，将 RDOT 策略分类为六个主要类别，并认为这些策略可以对面对高度不确定的问题提供有效的回应。</li>
<li>results: 这篇论文发现了超过 90 种 RDOT 策略，这些策略可以在不同的领域和领域中找到，这表明了这些策略的共同性。这篇论文还提出了一个框架，可以将这些策略包含在决策理论中，以便在面对高度不确定的问题时使用。<details>
<summary>Abstract</summary>
Uncertainty is a pervasive challenge in decision analysis, and decision theory recognizes two classes of solutions: probabilistic models and cognitive heuristics. However, engineers, public planners and other decision-makers instead use a third class of strategies that could be called RDOT (Risk-reducing Design and Operations Toolkit). These include incorporating robustness into designs, contingency planning, and others that do not fall into the categories of probabilistic models or cognitive heuristics. Moreover, identical strategies appear in several domains and disciplines, pointing to an important shared toolkit.   The focus of this paper is to develop a catalog of such strategies and develop a framework for them. The paper finds more than 90 examples of such strategies falling into six broad categories and argues that they provide an efficient response to decision problems that are seemingly intractable due to high uncertainty. It then proposes a framework to incorporate them into decision theory using multi-objective optimization.   Overall, RDOT represents an overlooked class of responses to uncertainty. Because RDOT strategies do not depend on accurate forecasting or estimation, they could be applied fruitfully to certain decision problems affected by high uncertainty and make them much more tractable.
</details>
<details>
<summary>摘要</summary>
众所周知，决策分析中的不确定性是一大挑战，决策理论则认可两类解决方案：概率模型和认知逻辑。然而，工程师、公共规划人员和其他决策者实际上使用了第三类策略，可以称为风险减少设计和操作工具箱（RDOT）。这些策略包括在设计中加入强健性，备援计划等，不属于概率模型或认知逻辑类别。此外，同一类策略在不同领域和学科中出现，表明存在共同的工具箱。本文的目的是开发一份这些策略的目录，并为其提出一个框架。研究发现了超过90个这类策略，分为六大类。这些策略能够有效地对决策问题进行处理，即使面临高度不确定性。然后，文章提议使用多目标优化来包含这些策略在决策理论中。总之，RDOT表示决策中的一种被忽略的策略类型。由于RDOT策略不依赖于准确预测或估计，因此可以在高度不确定性的决策问题上应用得更加果断。
</details></li>
</ul>
<hr>
<h2 id="MyoDex-A-Generalizable-Prior-for-Dexterous-Manipulation"><a href="#MyoDex-A-Generalizable-Prior-for-Dexterous-Manipulation" class="headerlink" title="MyoDex: A Generalizable Prior for Dexterous Manipulation"></a>MyoDex: A Generalizable Prior for Dexterous Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03130">http://arxiv.org/abs/2309.03130</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vittorio Caggiano, Sudeep Dasari, Vikash Kumar</li>
<li>for: 这个论文的目的是开发一种基于多任务学习的人工智能控制系统，以便在几个任务中快速学习和执行新的、先前无法实现的行为。</li>
<li>methods: 该论文使用了多任务学习来隐式地捕捉人类手部的行为偏好（MyoDex），并使用了一个physiologically realistic的人类手模型（MyoHand）来训练代理人。</li>
<li>results: 研究发现，使用MyoDex可以在几个任务中快速学习和执行新的行为，并且可以在不同的contact-rich behaviors中表现出人类手部的dexterity。此外，MyoDex还可以在24DoF Adroit Hand中提高dexterity的性能。<details>
<summary>Abstract</summary>
Human dexterity is a hallmark of motor control. Our hands can rapidly synthesize new behaviors despite the complexity (multi-articular and multi-joints, with 23 joints controlled by more than 40 muscles) of musculoskeletal sensory-motor circuits. In this work, we take inspiration from how human dexterity builds on a diversity of prior experiences, instead of being acquired through a single task. Motivated by this observation, we set out to develop agents that can build upon their previous experience to quickly acquire new (previously unattainable) behaviors. Specifically, our approach leverages multi-task learning to implicitly capture task-agnostic behavioral priors (MyoDex) for human-like dexterity, using a physiologically realistic human hand model - MyoHand. We demonstrate MyoDex's effectiveness in few-shot generalization as well as positive transfer to a large repertoire of unseen dexterous manipulation tasks. Agents leveraging MyoDex can solve approximately 3x more tasks, and 4x faster in comparison to a distillation baseline. While prior work has synthesized single musculoskeletal control behaviors, MyoDex is the first generalizable manipulation prior that catalyzes the learning of dexterous physiological control across a large variety of contact-rich behaviors. We also demonstrate the effectiveness of our paradigms beyond musculoskeletal control towards the acquisition of dexterity in 24 DoF Adroit Hand. Website: https://sites.google.com/view/myodex
</details>
<details>
<summary>摘要</summary>
人类dexterity是运动控制的标志之一。我们的手可以快速合成新行为，即使musculoskeletal感知-运动回路复杂（多 JOINTS 和多骨骼，涉及到更多 than 40 肌肉）。在这项工作中，我们受到人类dexterity如何在多种前期经验基础上建立新的行为的启发。我们采取多任务学习的方法，以寻找人类类似的dexterity。我们的方法利用多任务学习来隐式地捕捉任务无关的行为先验（MyoDex），使用一个physiologically realistic的人手模型—MyoHand。我们示出MyoDex在少数shot泛化和负担减少的能力，以及对大量未看过的dexterous manipulation任务的积极转移。使用MyoDex的代理可以解决约3倍多的任务，并在比较基线下4倍快。而先前的工作只能合成单一的musculoskeletal控制行为，MyoDex是首个可以 catalyze 学习人类类似的physiological控制的多种contact-rich行为的普适概念。我们还证明了我们的思想在24 DoF Adroit Hand中的效果。网址：https://sites.google.com/view/myodex
</details></li>
</ul>
<hr>
<h2 id="Detecting-Manufacturing-Defects-in-PCBs-via-Data-Centric-Machine-Learning-on-Solder-Paste-Inspection-Features"><a href="#Detecting-Manufacturing-Defects-in-PCBs-via-Data-Centric-Machine-Learning-on-Solder-Paste-Inspection-Features" class="headerlink" title="Detecting Manufacturing Defects in PCBs via Data-Centric Machine Learning on Solder Paste Inspection Features"></a>Detecting Manufacturing Defects in PCBs via Data-Centric Machine Learning on Solder Paste Inspection Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03113">http://arxiv.org/abs/2309.03113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jubilee Prasad-Rao, Roohollah Heidary, Jesse Williams</li>
<li>For: The paper aims to improve the automated detection of defects in Printed Circuit Board (PCB) manufacturing using Solder Paste Inspection (SPI) and Automated Optical Inspection (AOI) machines.* Methods: The paper uses a data-centric approach to train Machine Learning (ML) models to detect PCB defects at three stages of PCB manufacturing. The authors use SPI-extracted features of 6 million pins to train the ML models, and combine pin-level SPI features with component and PCB IDs to capture any inter-pin, inter-component, or spatial effects that may not be apparent at the pin level.* Results: The paper demonstrates the effectiveness of the proposed approach in detecting PCB defects. The authors use a base extreme gradient boosting (XGBoost) ML model and iterate on the data pre-processing step to improve detection performance. The results show that combining the detection results from different models can identify defective components more accurately.Here’s the information in Simplified Chinese text:* For: 本文旨在提高印刷电路板（PCB）生产中自动检测缺陷的效率，使用粘结材料检测（SPI）和自动光学检测（AOI）机器。* Methods: 本文采用数据驱动的方法来训练机器学习（ML）模型，检测PCB缺陷在三个阶段的PCB生产过程中。作者使用600万个封ajection的SPI特征来训练ML模型，并将封ajection级别的SPI特征与组件和PCB ID结合使用，以捕捉任何 между封ajection、组件或空间效果。* Results: 本文证明提出的方法的效果，使用基本的极限梯度提升（XGBoost）ML模型，并在数据预处理步骤中进行迭代来提高检测性能。结果表明，将不同模型的检测结果相乘可以更加准确地标识缺陷组件。<details>
<summary>Abstract</summary>
Automated detection of defects in Printed Circuit Board (PCB) manufacturing using Solder Paste Inspection (SPI) and Automated Optical Inspection (AOI) machines can help improve operational efficiency and significantly reduce the need for manual intervention. In this paper, using SPI-extracted features of 6 million pins, we demonstrate a data-centric approach to train Machine Learning (ML) models to detect PCB defects at three stages of PCB manufacturing. The 6 million PCB pins correspond to 2 million components that belong to 15,387 PCBs. Using a base extreme gradient boosting (XGBoost) ML model, we iterate on the data pre-processing step to improve detection performance. Combining pin-level SPI features using component and PCB IDs, we developed training instances also at the component and PCB level. This allows the ML model to capture any inter-pin, inter-component, or spatial effects that may not be apparent at the pin level. Models are trained at the pin, component, and PCB levels, and the detection results from the different models are combined to identify defective components.
</details>
<details>
<summary>摘要</summary>
翻译结果：自动检测Printed Circuit Board (PCB)生产过程中的缺陷使用Solder Paste Inspection (SPI)和Automated Optical Inspection (AOI)机器可以提高操作效率，大幅减少人工干预。在这篇论文中，我们使用SPI提取的600万个见识特征，示出了一种数据驱动的方法来使Machine Learning (ML)模型检测PCB缺陷。这600万个PCB见识特征对应了200万个组件，这些组件属于15387个PCB。使用基本的极限Gradient Boosting (XGBoost) ML模型，我们在数据预处理步骤上进行迭代，以提高检测性能。将pin级SPI特征与组件ID和PCB ID结合，我们开发了训练示例也在组件和PCB级别。这使得ML模型能够捕捉到pin级别不可见的间接、组件间或空间效应。我们在不同级别上训练了模型，并将不同级别的检测结果合并，以识别缺陷组件。
</details></li>
</ul>
<hr>
<h2 id="A-Multimodal-Analysis-of-Influencer-Content-on-Twitter"><a href="#A-Multimodal-Analysis-of-Influencer-Content-on-Twitter" class="headerlink" title="A Multimodal Analysis of Influencer Content on Twitter"></a>A Multimodal Analysis of Influencer Content on Twitter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03064">http://arxiv.org/abs/2309.03064</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danaesavi/micd-influencer-content-twitter">https://github.com/danaesavi/micd-influencer-content-twitter</a></li>
<li>paper_authors: Danae Sánchez Villegas, Catalina Goanta, Nikolaos Aletras</li>
<li>for:  This paper aims to assist in the automatic detection of commercial influencer content on Twitter.</li>
<li>methods: The paper uses a new dataset of 15,998 influencer posts, and experiments with a range of predictive models that combine text and visual information, including a proposed cross-attention approach.</li>
<li>results: The paper shows that the cross-attention approach outperforms state-of-the-art multimodal models, and provides a thorough analysis of the strengths and limitations of the models. The models are effective in identifying commercial posts and reducing false positives, while capturing relevant context that aids in the discovery of undisclosed commercial posts.<details>
<summary>Abstract</summary>
Influencer marketing involves a wide range of strategies in which brands collaborate with popular content creators (i.e., influencers) to leverage their reach, trust, and impact on their audience to promote and endorse products or services. Because followers of influencers are more likely to buy a product after receiving an authentic product endorsement rather than an explicit direct product promotion, the line between personal opinions and commercial content promotion is frequently blurred. This makes automatic detection of regulatory compliance breaches related to influencer advertising (e.g., misleading advertising or hidden sponsorships) particularly difficult. In this work, we (1) introduce a new Twitter (now X) dataset consisting of 15,998 influencer posts mapped into commercial and non-commercial categories for assisting in the automatic detection of commercial influencer content; (2) experiment with an extensive set of predictive models that combine text and visual information showing that our proposed cross-attention approach outperforms state-of-the-art multimodal models; and (3) conduct a thorough analysis of strengths and limitations of our models. We show that multimodal modeling is useful for identifying commercial posts, reducing the amount of false positives, and capturing relevant context that aids in the discovery of undisclosed commercial posts.
</details>
<details>
<summary>摘要</summary>
influencer marketing 包括各种策略，brand与popular content creator（i.e., influencer）合作，利用他们的影响力、信任度和对观众的影响，推广和推销产品或服务。由于追求者们更有可能根据authentic product endorsement而购买产品，而不是直接的产品推广，因此商业和非商业内容之间的分界难以确定。这使得自动检测与Influencer Advertising相关的规定遵守（如误导性广告或隐藏赞助）特别困难。在这项工作中，我们（1）引入了15,998名 influencer 的 Twitter（现在是 X）数据集，并将其分为商业和非商业类别以帮助自动检测商业 influencer 内容;（2）试用了一系列的预测模型，其中包括文本和视觉信息的组合，我们的跨层注意方法比 state-of-the-art 多模式模型更高效;（3）进行了模型的全面分析，包括其优点和局限性。我们表明，多模式模型可以帮助标识商业帖子，降低false positives的数量，并捕捉有关的上下文，以帮助发现未经披露的商业帖子。
</details></li>
</ul>
<hr>
<h2 id="Framework-Based-Qualitative-Analysis-of-Free-Responses-of-Large-Language-Models-Algorithmic-Fidelity"><a href="#Framework-Based-Qualitative-Analysis-of-Free-Responses-of-Large-Language-Models-Algorithmic-Fidelity" class="headerlink" title="Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity"></a>Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06364">http://arxiv.org/abs/2309.06364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aliya Amirova, Theodora Fteropoulli, Nafiso Ahmed, Martin R. Cowie, Joel Z. Leibo</li>
<li>For: The paper explores the use of large-scale generative language models (LLMs) to simulate free responses to interview questions and whether these artificial “silicon participants” can be studied using qualitative methods to produce insights that generalize to real human populations.* Methods: The paper uses an LLM to generate interviews with silicon participants matching specific demographic characteristics one-for-one with a set of human participants. The authors use framework-based qualitative analysis to compare the key themes obtained from both human and silicon participants, and they also analyze the structure and tone of the interviews.* Results: The paper finds that while the key themes obtained from both human and silicon participants are strikingly similar, there are significant differences in the structure and tone of the interviews. The authors also find evidence of the hyper-accuracy distortion described by Aher et al. (2023), which suggests that the LLM they tested (GPT-3.5) does not have sufficient algorithmic fidelity to expect research on it to generalize to human populations.Here are the three points in Simplified Chinese text:* For: 这篇论文探讨了使用大规模生成语言模型（LLM）来模拟面试问答和人工智能”Silicon Participants”是否可以通过质量研究方法获得可重复性和普适性。* Methods: 论文使用LLM生成面试问答，并与人类参与者一一匹配特定的人口特征。作者使用框架基本的质量分析方法对两组参与者的主题进行比较。* Results: 论文发现，尽管人类和人工智能参与者的主题相似度很高，但面试结构和语言表达存在很大差异。作者还发现Ahmed等人（2023）所描述的”超级准确性偏见”现象。<details>
<summary>Abstract</summary>
Today, using Large-scale generative Language Models (LLMs) it is possible to simulate free responses to interview questions like those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial "silicon participants" generated by LLMs may be productively studied using qualitative methods aiming to produce insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a term introduced by Argyle et al. (2023) capturing the degree to which LLM-generated outputs mirror human sub-populations' beliefs and attitudes. By definition, high algorithmic fidelity suggests latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews with silicon participants matching specific demographic characteristics one-for-one with a set of human participants. Using framework-based qualitative analysis, we showed the key themes obtained from both human and silicon participants were strikingly similar. However, when we analyzed the structure and tone of the interviews we found even more striking differences. We also found evidence of the hyper-accuracy distortion described by Aher et al. (2023). We conclude that the LLM we tested (GPT-3.5) does not have sufficient algorithmic fidelity to expect research on it to generalize to human populations. However, the rapid pace of LLM research makes it plausible this could change in the future. Thus we stress the need to establish epistemic norms now around how to assess validity of LLM-based qualitative research, especially concerning the need to ensure representation of heterogeneous lived experiences.
</details>
<details>
<summary>摘要</summary>
The key concept in our analysis was "algorithmic fidelity," which refers to the degree to which LLM-generated outputs reflect the beliefs and attitudes of human sub-populations. If the algorithmic fidelity is high, it suggests that the latent beliefs elicited from the LLM may generalize to real humans, while low algorithmic fidelity renders the research invalid.To test the algorithmic fidelity of an LLM (GPT-3.5), we generated interviews with silicon participants that matched specific demographic characteristics with a set of human participants. We used framework-based qualitative analysis to identify the key themes in both the human and silicon participants' interviews. While the themes were strikingly similar, we found more significant differences in the structure and tone of the interviews. Additionally, we found evidence of the "hyper-accuracy distortion" described by Aher et al. (2023), which suggests that the LLM's responses were overly accurate and lacked the nuance and variation found in human responses.Based on our findings, we conclude that the LLM we tested does not have sufficient algorithmic fidelity to expect research on it to generalize to human populations. However, the rapid pace of LLM research makes it plausible that this could change in the future. Therefore, we stress the need to establish epistemic norms now around how to assess the validity of LLM-based qualitative research, particularly with regard to ensuring representation of heterogeneous lived experiences.
</details></li>
</ul>
<hr>
<h2 id="Hide-and-Seek-HaS-A-Lightweight-Framework-for-Prompt-Privacy-Protection"><a href="#Hide-and-Seek-HaS-A-Lightweight-Framework-for-Prompt-Privacy-Protection" class="headerlink" title="Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection"></a>Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03057">http://arxiv.org/abs/2309.03057</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alohachen/hide-and-seek">https://github.com/alohachen/hide-and-seek</a></li>
<li>paper_authors: Yu Chen, Tingxin Li, Huiming Liu, Yang Yu<br>for: 这个研究是为了提高大型自然语言模型（LLM）的隐私保护。methods: 这个研究使用了多方 computation（MPC）技术来保护用户的隐私，并将隐私资讯转换为小型本地模型来实现隐私保护。results: 实验结果显示，这个 HaS 框架可以实现隐私保护和功能性的平衡，并在翻译和分类任务中进行了成功的评估。<details>
<summary>Abstract</summary>
Numerous companies have started offering services based on large language models (LLM), such as ChatGPT, which inevitably raises privacy concerns as users' prompts are exposed to the model provider. Previous research on secure reasoning using multi-party computation (MPC) has proven to be impractical for LLM applications due to its time-consuming and communication-intensive nature. While lightweight anonymization techniques can protect private information in prompts through substitution or masking, they fail to recover sensitive data replaced in the LLM-generated results. In this paper, we expand the application scenarios of anonymization techniques by training a small local model to de-anonymize the LLM's returned results with minimal computational overhead. We introduce the HaS framework, where "H(ide)" and "S(eek)" represent its two core processes: hiding private entities for anonymization and seeking private entities for de-anonymization, respectively. To quantitatively assess HaS's privacy protection performance, we propose both black-box and white-box adversarial models. Furthermore, we conduct experiments to evaluate HaS's usability in translation and classification tasks. The experimental findings demonstrate that the HaS framework achieves an optimal balance between privacy protection and utility.
</details>
<details>
<summary>摘要</summary>
众多公司已经开始提供基于大语言模型（LLM）的服务，例如ChatGPT，这无疑会引起隐私问题，因为用户的提示被暴露给模型提供者。先前的多方计算（MPC）安全思维研究已经证明对LLM应用程序来说是不实用的，因为它们的时间开销和通信 overhead 过高。虽然轻量级隐私技术可以在提示中保护private信息，但它们无法在LLM生成的结果中恢复敏感信息。在这篇论文中，我们扩展了隐私技术的应用场景，通过训练一个小型本地模型来解除LLM返回的结果中的隐私信息，并且减少计算 overhead。我们称之为HaS框架，其中"H"和"S"表示其两个核心过程：隐藏private实体 для隐私和寻找private实体 для解除隐私。为了量化HaS的隐私保护性能，我们提出了黑盒和白盒反对模型。此外，我们进行了翻译和分类任务的实验，以评估HaS的可用性。实验结果表明，HaS框架在隐私保护和实用之间做出了优质的均衡。
</details></li>
</ul>
<hr>
<h2 id="Combining-pre-trained-Vision-Transformers-and-CIDER-for-Out-Of-Domain-Detection"><a href="#Combining-pre-trained-Vision-Transformers-and-CIDER-for-Out-Of-Domain-Detection" class="headerlink" title="Combining pre-trained Vision Transformers and CIDER for Out Of Domain Detection"></a>Combining pre-trained Vision Transformers and CIDER for Out Of Domain Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03047">http://arxiv.org/abs/2309.03047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grégor Jouet, Clément Duhart, Francis Rousseaux, Julio Laborde, Cyril de Runz</li>
<li>for: 本研究探讨了预训练模型在偏出分布外的检测性能。</li>
<li>methods: 本研究使用了预训练的 transformers 和 CNN 模型，以及改进方法 CIDER。</li>
<li>results: 实验结果表明，预训练 transformers 模型在 OOD 检测 task 上表现出色，而预训练 ViT 和 CNN 可以通过与 CIDER 结合来进一步提高 OOD 检测性能。<details>
<summary>Abstract</summary>
Out-of-domain (OOD) detection is a crucial component in industrial applications as it helps identify when a model encounters inputs that are outside the training distribution. Most industrial pipelines rely on pre-trained models for downstream tasks such as CNN or Vision Transformers. This paper investigates the performance of those models on the task of out-of-domain detection. Our experiments demonstrate that pre-trained transformers models achieve higher detection performance out of the box. Furthermore, we show that pre-trained ViT and CNNs can be combined with refinement methods such as CIDER to improve their OOD detection performance even more. Our results suggest that transformers are a promising approach for OOD detection and set a stronger baseline for this task in many contexts
</details>
<details>
<summary>摘要</summary>
<<SYS>>输出文本转换为简化中文。<</SYS>>业务应用中， OUT-OF-DOMAIN（OOD）检测是一项重要的组成部分，可以识别模型处理的输入是否在训练分布外。大多数工业管道都依赖于预训练模型来进行下游任务，如CNN或Vision Transformers。这篇论文研究了这些模型在OOD检测任务上的性能。我们的实验表明，预训练的转换模型在出团的情况下可以达到更高的检测性能。此外，我们还证明了预训练的CNN和ViT可以与修正方法如CIDER结合，以进一步提高OOD检测性能。我们的结果表明，转换器是OOD检测中的一个有力的方法，并在许多情况下设置了更强的基线。
</details></li>
</ul>
<hr>
<h2 id="A-Refutation-of-Shapley-Values-for-Explainability"><a href="#A-Refutation-of-Shapley-Values-for-Explainability" class="headerlink" title="A Refutation of Shapley Values for Explainability"></a>A Refutation of Shapley Values for Explainability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03041">http://arxiv.org/abs/2309.03041</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanxiang Huang, Joao Marques-Silva</li>
<li>for: 这个论文的目的是否定使用Shapley值作为基于规则的解释中的理论基础。</li>
<li>methods: 这篇论文使用了暴力方法来找到Boolean函数，并对这些函数进行分析以找到它们的缺陷。</li>
<li>results: 这篇论文证明了，无论feature数是多少，都存在Boolean函数会显示一些不准确的解释问题，因此不能使用Shapley值作为基于规则的解释中的理议基础。<details>
<summary>Abstract</summary>
Recent work demonstrated the existence of Boolean functions for which Shapley values provide misleading information about the relative importance of features in rule-based explanations. Such misleading information was broadly categorized into a number of possible issues. Each of those issues relates with features being relevant or irrelevant for a prediction, and all are significant regarding the inadequacy of Shapley values for rule-based explainability. This earlier work devised a brute-force approach to identify Boolean functions, defined on small numbers of features, and also associated instances, which displayed such inadequacy-revealing issues, and so served as evidence to the inadequacy of Shapley values for rule-based explainability. However, an outstanding question is how frequently such inadequacy-revealing issues can occur for Boolean functions with arbitrary large numbers of features. It is plain that a brute-force approach would be unlikely to provide insights on how to tackle this question. This paper answers the above question by proving that, for any number of features, there exist Boolean functions that exhibit one or more inadequacy-revealing issues, thereby contributing decisive arguments against the use of Shapley values as the theoretical underpinning of feature-attribution methods in explainability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Efficient-Temporary-Deepfake-Location-Approach-Based-Embeddings-for-Partially-Spoofed-Audio-Detection"><a href="#An-Efficient-Temporary-Deepfake-Location-Approach-Based-Embeddings-for-Partially-Spoofed-Audio-Detection" class="headerlink" title="An Efficient Temporary Deepfake Location Approach Based Embeddings for Partially Spoofed Audio Detection"></a>An Efficient Temporary Deepfake Location Approach Based Embeddings for Partially Spoofed Audio Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03036">http://arxiv.org/abs/2309.03036</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xieyuankun/tdl-add">https://github.com/xieyuankun/tdl-add</a></li>
<li>paper_authors: Yuankun Xie, Haonan Cheng, Yutian Wang, Long Ye</li>
<li>for: 本文提出了一种精细化的假音检测方法，即Temporal Deepfake Location（TDL），以准确地检测帧级假音。</li>
<li>methods: 该方法包括两部分：嵌入相似模块和时间卷积操作。嵌入相似模块用于生成一个嵌入空间，以分离真实和假的帧。时间卷积操作则用于计算邻帧之间的相似性，并动态选择有用的邻帧进行卷积。</li>
<li>results: 实验显示，与基eline模型相比，本方法在ASVspoof2019 Partial Spoof dataset中表现出色，并在跨数据集场景下也达到了优秀的表现。代码已经上传到了线上。<details>
<summary>Abstract</summary>
Partially spoofed audio detection is a challenging task, lying in the need to accurately locate the authenticity of audio at the frame level. To address this issue, we propose a fine-grained partially spoofed audio detection method, namely Temporal Deepfake Location (TDL), which can effectively capture information of both features and locations. Specifically, our approach involves two novel parts: embedding similarity module and temporal convolution operation. To enhance the identification between the real and fake features, the embedding similarity module is designed to generate an embedding space that can separate the real frames from fake frames. To effectively concentrate on the position information, temporal convolution operation is proposed to calculate the frame-specific similarities among neighboring frames, and dynamically select informative neighbors to convolution. Extensive experiments show that our method outperform baseline models in ASVspoof2019 Partial Spoof dataset and demonstrate superior performance even in the crossdataset scenario. The code is released online.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将给定文本翻译成简化中文。<</SYS>>假 Audio 检测是一个复杂的任务，因为需要准确地确定各帧的真实性。为解决这个问题，我们提出了一种细化的假 Audio 检测方法，即 Temporal Deepfake Location（TDL），可以准确地捕捉各帧的特征信息和位置信息。具体来说，我们的方法包括两个新的部分：嵌入相似模块和时间核算操作。为了增强真实和假 Frame 之间的区别，我们设计了嵌入相似模块，用于生成一个可以分离真帧和假帧的嵌入空间。此外，我们还提出了时间核算操作，用于在邻近帧之间进行同义核算，以选择有用的邻居进行 convolution。我们的方法在 ASVspoof2019 partial spoof 数据集上实现了对基线模型的超越性，并在跨数据集场景下也达到了优秀的表现。代码已经在线发布。
</details></li>
</ul>
<hr>
<h2 id="Synthetic-Text-Generation-using-Hypergraph-Representations"><a href="#Synthetic-Text-Generation-using-Hypergraph-Representations" class="headerlink" title="Synthetic Text Generation using Hypergraph Representations"></a>Synthetic Text Generation using Hypergraph Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06550">http://arxiv.org/abs/2309.06550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Natraj Raman, Sameena Shah</li>
<li>for: 文章的目的是生成文档的 sintetic variants，即文本转换。</li>
<li>methods: 本文提出了一种基于LLM的方法，首先将文档分解成semantic frames，然后使用这种间接稀疏格式生成文本。frames使用了一个浮动图，可以在原则性的方式下进行框架内容的改变。</li>
<li>results: 本文的解决方案可以生成多样化、凝聚的文档，其中包括不同的样式、情感、格式、组织结构和事实。<details>
<summary>Abstract</summary>
Generating synthetic variants of a document is often posed as text-to-text transformation. We propose an alternate LLM based method that first decomposes a document into semantic frames and then generates text using this interim sparse format. The frames are modeled using a hypergraph, which allows perturbing the frame contents in a principled manner. Specifically, new hyperedges are mined through topological analysis and complex polyadic relationships including hierarchy and temporal dynamics are accommodated. We show that our solution generates documents that are diverse, coherent and vary in style, sentiment, format, composition and facts.
</details>
<details>
<summary>摘要</summary>
通常，生成文档的变体是一个文本到文本转换问题。我们提出了一种基于LLM的新方法，它首先将文档分解成Semantic Frame，然后使用这种间接稀有格式生成文本。这些帧是通过超graph进行模型，这允许在原则上进行帧内容的扰动。我们显示了我们的解决方案可以生成多样、一致、style、情感、格式、结构和事实等方面的文档。
</details></li>
</ul>
<hr>
<h2 id="Universal-Preprocessing-Operators-for-Embedding-Knowledge-Graphs-with-Literals"><a href="#Universal-Preprocessing-Operators-for-Embedding-Knowledge-Graphs-with-Literals" class="headerlink" title="Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals"></a>Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03023">http://arxiv.org/abs/2309.03023</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/patryk.preisner/mkga">https://gitlab.com/patryk.preisner/mkga</a></li>
<li>paper_authors: Patryk Preisner, Heiko Paulheim</li>
<li>for: 本文是针对知识图（KG）中的实体进行 dense 数值表示的 dense numerical representations。</li>
<li>methods: 本文提出了一组通用预处理操作，可以将 KG 中的实体与数值、时间、文本和图像信息转换为任何方法可以使用的形式。</li>
<li>results: 在 kgbench 数据集上使用三种不同的嵌入方法进行实验，得到了满意的结果。<details>
<summary>Abstract</summary>
Knowledge graph embeddings are dense numerical representations of entities in a knowledge graph (KG). While the majority of approaches concentrate only on relational information, i.e., relations between entities, fewer approaches exist which also take information about literal values (e.g., textual descriptions or numerical information) into account. Those which exist are typically tailored towards a particular modality of literal and a particular embedding method. In this paper, we propose a set of universal preprocessing operators which can be used to transform KGs with literals for numerical, temporal, textual, and image information, so that the transformed KGs can be embedded with any method. The results on the kgbench dataset with three different embedding methods show promising results.
</details>
<details>
<summary>摘要</summary>
知识图谱嵌入是指知识图谱中实体的密集数字表示。大多数方法只关注知识图谱中的关系信息，而 fewer approaches 存在，它们通常专门针对特定类型的媒体和嵌入方法。在这篇论文中，我们提出了一组通用预处理操作，可以将知识图谱中的 literals 转换为数字、时间、文本和图像信息，以便使用任何嵌入方法进行嵌入。 kgbench 数据集上的三种嵌入方法的结果表现良好。
</details></li>
</ul>
<hr>
<h2 id="EdgeFL-A-Lightweight-Decentralized-Federated-Learning-Framework"><a href="#EdgeFL-A-Lightweight-Decentralized-Federated-Learning-Framework" class="headerlink" title="EdgeFL: A Lightweight Decentralized Federated Learning Framework"></a>EdgeFL: A Lightweight Decentralized Federated Learning Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02936">http://arxiv.org/abs/2309.02936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyi Zhang, Jan Bosch, Helena Holmström Olsson</li>
<li>for: 本研究旨在提供一个轻量级的分布式机器学习框架，以解决现有的聚合中心和扩展性问题。</li>
<li>methods: 本研究使用的方法是边缘仅的轻量级分布式机器学习框架，扩展了现有的中央聚合和扩展性问题。</li>
<li>results: 本研究的结果显示，边缘仅的轻量级分布式机器学习框架可以实现更好的性能，包括对于聚合中心和扩展性的改善。<details>
<summary>Abstract</summary>
Federated Learning (FL) has emerged as a promising approach for collaborative machine learning, addressing data privacy concerns. However, existing FL platforms and frameworks often present challenges for software engineers in terms of complexity, limited customization options, and scalability limitations. In this paper, we introduce EdgeFL, an edge-only lightweight decentralized FL framework, designed to overcome the limitations of centralized aggregation and scalability in FL deployments. By adopting an edge-only model training and aggregation approach, EdgeFL eliminates the need for a central server, enabling seamless scalability across diverse use cases. With a straightforward integration process requiring just four lines of code (LOC), software engineers can easily incorporate FL functionalities into their AI products. Furthermore, EdgeFL offers the flexibility to customize aggregation functions, empowering engineers to adapt them to specific needs. Based on the results, we demonstrate that EdgeFL achieves superior performance compared to existing FL platforms/frameworks. Our results show that EdgeFL reduces weights update latency and enables faster model evolution, enhancing the efficiency of edge devices. Moreover, EdgeFL exhibits improved classification accuracy compared to traditional centralized FL approaches. By leveraging EdgeFL, software engineers can harness the benefits of federated learning while overcoming the challenges associated with existing FL platforms/frameworks.
</details>
<details>
<summary>摘要</summary>
Federated Learning（FL）已经出现为协同机器学习的有力的方法，解决了数据隐私问题。然而，现有的 FL 平台和框架通常会给软件工程师带来复杂性、有限的自定义选项和可扩展性限制。在这篇论文中，我们介绍 EdgeFL，一个靠 Edge 进行轻量级归并的分布式 FL 框架，用于超越中央集成和可扩展性在 FL 部署中的限制。通过采用 Edge Only 模型训练和归并方法，EdgeFL 消除了中央服务器的需求，使得各种使用场景中的扩展性变得自然和简单。具有四行代码（LOC）的简单集成过程，软件工程师可以轻松地将 FL 功能集成到其 AI 产品中。此外，EdgeFL 还提供了自定义归并函数的 flexibility，使得工程师可以根据特定需求进行适应。根据结果，我们表明 EdgeFL 可以比现有的 FL 平台/框架实现更高的性能。我们的结果显示，EdgeFL 可以降低 weights 更新延迟和快速进化模型，提高边缘设备的效率。此外，EdgeFL 还展现出了比传统中央 FL 方法更高的分类精度。通过利用 EdgeFL，软件工程师可以获得 federated learning 的优势，同时超越现有的 FL 平台/框架中的挑战。
</details></li>
</ul>
<hr>
<h2 id="Estimating-irregular-water-demands-with-physics-informed-machine-learning-to-inform-leakage-detection"><a href="#Estimating-irregular-water-demands-with-physics-informed-machine-learning-to-inform-leakage-detection" class="headerlink" title="Estimating irregular water demands with physics-informed machine learning to inform leakage detection"></a>Estimating irregular water demands with physics-informed machine learning to inform leakage detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02935">http://arxiv.org/abs/2309.02935</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/swn-group-at-tu-berlin/lila-pinn">https://github.com/swn-group-at-tu-berlin/lila-pinn</a></li>
<li>paper_authors: Ivo Daniel, Andrea Cominola</li>
<li>for: This paper aims to develop a physics-informed machine learning algorithm for timely identifying and accurately localizing leakages in drinking water distribution networks.</li>
<li>methods: The proposed algorithm uses a fully connected neural network to analyze pressure data and estimate unknown irregular water demands, leveraging the Bernoulli equation to linearize the leakage detection problem.</li>
<li>results: The algorithm was tested on data from the L-Town benchmark network and showed good performance in estimating most irregular demands, with R2 values larger than 0.8. The results also demonstrated that the algorithm can improve the identification of leakages under the presence of irregular demands by a factor of 5.3 for abrupt leaks and a factor of 3.0 for incipient leaks compared to disregarding irregular demands.<details>
<summary>Abstract</summary>
Leakages in drinking water distribution networks pose significant challenges to water utilities, leading to infrastructure failure, operational disruptions, environmental hazards, property damage, and economic losses. The timely identification and accurate localisation of such leakages is paramount for utilities to mitigate these unwanted effects. However, implementation of algorithms for leakage detection is limited in practice by requirements of either hydraulic models or large amounts of training data. Physics-informed machine learning can utilise hydraulic information thereby circumventing both limitations. In this work, we present a physics-informed machine learning algorithm that analyses pressure data and therefrom estimates unknown irregular water demands via a fully connected neural network, ultimately leveraging the Bernoulli equation and effectively linearising the leakage detection problem. Our algorithm is tested on data from the L-Town benchmark network, and results indicate a good capability for estimating most irregular demands, with R2 larger than 0.8. Identification results for leakages under the presence of irregular demands could be improved by a factor of 5.3 for abrupt leaks and a factor of 3.0 for incipient leaks when compared the results disregarding irregular demands.
</details>
<details>
<summary>摘要</summary>
饮水供应网络中的泄漏问题对水公司带来了重要挑战，导致基础设施崩溃、操作中断、环境风险、财务损失等。准确地识别和定位泄漏是水公司应对这些不良影响的关键。然而，现实中实施泄漏检测算法的困难在于需要水力模型或大量的训练数据。物理学 Informed machine learning 可以利用水力信息，从而绕过这两个限制。在这个工作中，我们提出了一种基于物理学 Informed machine learning 算法，通过分析压力数据，并由完全连接神经网络来估算未知的不规则水需求，最终利用白银方程和有效地线性化泄漏检测问题。我们的算法在 L-Town 测试网络上进行了测试，结果表明可以准确地估算大多数不规则需求，R2 值大于 0.8。在存在不规则需求情况下，泄漏的标识结果可以提高了5.3倍 для突然泄漏和3.0倍 дляincipient泄漏。
</details></li>
</ul>
<hr>
<h2 id="On-the-Challenges-of-Building-Datasets-for-Hate-Speech-Detection"><a href="#On-the-Challenges-of-Building-Datasets-for-Hate-Speech-Detection" class="headerlink" title="On the Challenges of Building Datasets for Hate Speech Detection"></a>On the Challenges of Building Datasets for Hate Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02912">http://arxiv.org/abs/2309.02912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vitthal Bhandari</li>
<li>for: 本研究旨在提供一种数据创建管道框架，以便在未来创建 hate speech 数据集时能够遵循best practice。</li>
<li>methods: 本研究使用了一种数据中心视角来分析 hate speech 检测问题，并提出了一个涵盖七个维度的数据创建管道框架。</li>
<li>results: 本研究通过使用这种框架，可以帮助 практикан们在未来创建 hate speech 数据集时遵循best practice，并提高数据的可靠性和一致性。<details>
<summary>Abstract</summary>
Detection of hate speech has been formulated as a standalone application of NLP and different approaches have been adopted for identifying the target groups, obtaining raw data, defining the labeling process, choosing the detection algorithm, and evaluating the performance in the desired setting. However, unlike other downstream tasks, hate speech suffers from the lack of large-sized, carefully curated, generalizable datasets owing to the highly subjective nature of the task. In this paper, we first analyze the issues surrounding hate speech detection through a data-centric lens. We then outline a holistic framework to encapsulate the data creation pipeline across seven broad dimensions by taking the specific example of hate speech towards sexual minorities. We posit that practitioners would benefit from following this framework as a form of best practice when creating hate speech datasets in the future.
</details>
<details>
<summary>摘要</summary>
偏见排斥检测已经被设计为自然语言处理（NLP）的独立应用程序，不同的方法被采用来识别目标群体、获取原始数据、定义标签过程、选择检测算法和评估性能在适当的设定下。然而，与其他下游任务不同，偏见排斥受到大量、精心整理、通用的数据集的缺乏，这是因为这项任务的性质具有高度主观的特点。在这篇文章中，我们首先分析了偏见排斥检测的问题，并以 hate speech towards sexual minorities 为例子，描述了一个整体的框架，以帮助实践者在未来创建偏见排斥数据集时 seguir esta framework 作为最佳实践。
</details></li>
</ul>
<hr>
<h2 id="DECODE-Data-driven-Energy-Consumption-Prediction-leveraging-Historical-Data-and-Environmental-Factors-in-Buildings"><a href="#DECODE-Data-driven-Energy-Consumption-Prediction-leveraging-Historical-Data-and-Environmental-Factors-in-Buildings" class="headerlink" title="DECODE: Data-driven Energy Consumption Prediction leveraging Historical Data and Environmental Factors in Buildings"></a>DECODE: Data-driven Energy Consumption Prediction leveraging Historical Data and Environmental Factors in Buildings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02908">http://arxiv.org/abs/2309.02908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Mishra, Haroon R. Lone, Aayush Mishra</li>
<li>for: 预测建筑物的能源消耗，以便实现有效的能源管理和 distribuTECH grid 内部的能源分配。</li>
<li>methods: 使用历史能源数据、occupancy 模式和天气条件来预测建筑物的能源消耗，并使用 Long Short-Term Memory (LSTM) 模型进行预测。</li>
<li>results: 相比已有预测方法，LSTM 模型提供了更高的预测精度，其 R2 分数为 0.97，mean absolute error (MAE) 为 0.007。此外，该模型还能够从限制的数据集中进行高效的预测，并且具有很好的泛化能力和可靠性。<details>
<summary>Abstract</summary>
Energy prediction in buildings plays a crucial role in effective energy management. Precise predictions are essential for achieving optimal energy consumption and distribution within the grid. This paper introduces a Long Short-Term Memory (LSTM) model designed to forecast building energy consumption using historical energy data, occupancy patterns, and weather conditions. The LSTM model provides accurate short, medium, and long-term energy predictions for residential and commercial buildings compared to existing prediction models. We compare our LSTM model with established prediction methods, including linear regression, decision trees, and random forest. Encouragingly, the proposed LSTM model emerges as the superior performer across all metrics. It demonstrates exceptional prediction accuracy, boasting the highest R2 score of 0.97 and the most favorable mean absolute error (MAE) of 0.007. An additional advantage of our developed model is its capacity to achieve efficient energy consumption forecasts even when trained on a limited dataset. We address concerns about overfitting (variance) and underfitting (bias) through rigorous training and evaluation on real-world data. In summary, our research contributes to energy prediction by offering a robust LSTM model that outperforms alternative methods and operates with remarkable efficiency, generalizability, and reliability.
</details>
<details>
<summary>摘要</summary>
The proposed LSTM model achieves high prediction accuracy, with an R2 score of 0.97 and a mean absolute error (MAE) of 0.007. Additionally, the model is efficient and can achieve accurate energy consumption forecasts even when trained on a limited dataset. To address concerns about overfitting and underfitting, the model is trained and evaluated on real-world data.Compared to other prediction methods, including linear regression, decision trees, and random forest, the LSTM model emerges as the superior performer across all metrics. The proposed model offers a robust and reliable solution for energy prediction, with exceptional efficiency and generalizability. Overall, this research contributes to energy prediction by providing a more accurate and effective approach for managing energy consumption in buildings.
</details></li>
</ul>
<hr>
<h2 id="A-deep-Natural-Language-Inference-predictor-without-language-specific-training-data"><a href="#A-deep-Natural-Language-Inference-predictor-without-language-specific-training-data" class="headerlink" title="A deep Natural Language Inference predictor without language-specific training data"></a>A deep Natural Language Inference predictor without language-specific training data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02887">http://arxiv.org/abs/2309.02887</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Lorenzo Corradi, Alessandro Manenti, Francesca Del Bonifro, Francesco Setti, Dario Del Sorbo</li>
<li>for: 解决目标语言选择无需语言特定的训练数据集的推理关系（NLI）问题。</li>
<li>methods: 利用生成句子嵌入的generic翻译数据集，并使用两个相同的预训练模型：一个生成源语言句子嵌入，另一个在目标语言上练习，以模拟第一个。这种方法被称为知识填充。</li>
<li>results: 在Stanford NLI测试集、Multi-Genre NLI测试集和手动翻译RTE3-ITA测试集上评估了提议的建筑，并在不同任务上进行了实际验证，包括意识分析、偏好分析和主题识别。结果表明，知识填充技术可以超越基于机器翻译的方法，即使其未直接在测试数据上训练。<details>
<summary>Abstract</summary>
In this paper we present a technique of NLP to tackle the problem of inference relation (NLI) between pairs of sentences in a target language of choice without a language-specific training dataset. We exploit a generic translation dataset, manually translated, along with two instances of the same pre-trained model - the first to generate sentence embeddings for the source language, and the second fine-tuned over the target language to mimic the first. This technique is known as Knowledge Distillation. The model has been evaluated over machine translated Stanford NLI test dataset, machine translated Multi-Genre NLI test dataset, and manually translated RTE3-ITA test dataset. We also test the proposed architecture over different tasks to empirically demonstrate the generality of the NLI task. The model has been evaluated over the native Italian ABSITA dataset, on the tasks of Sentiment Analysis, Aspect-Based Sentiment Analysis, and Topic Recognition. We emphasise the generality and exploitability of the Knowledge Distillation technique that outperforms other methodologies based on machine translation, even though the former was not directly trained on the data it was tested over.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种基于自然语言处理（NLP）技术的问题推理关系（NLI）解决方案，无需特定语言的训练数据集。我们利用了一个通用翻译数据集，手动翻译的两个实例，其中一个用于生成源语言的句子嵌入，另一个在目标语言上进行了精度调整，以模仿第一个。这种技术被称为知识填充。我们在机器翻译的Stanford NLI测试数据集、多种语言 NLI测试数据集以及手动翻译的RTE3-ITA测试数据集上评估了该模型。我们还在不同任务上测试了该建议的架构，以证明其通用性。在原始意大利语言ABSITA数据集上，我们评估了情感分析、受体语言分析和主题识别等任务。我们强调了知识填充技术的通用性和可利用性，并证明了它在基于机器翻译的方法之上表现出色。
</details></li>
</ul>
<hr>
<h2 id="MAD-Modality-Agnostic-Distance-Measure-for-Image-Registration"><a href="#MAD-Modality-Agnostic-Distance-Measure-for-Image-Registration" class="headerlink" title="MAD: Modality Agnostic Distance Measure for Image Registration"></a>MAD: Modality Agnostic Distance Measure for Image Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02875">http://arxiv.org/abs/2309.02875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasiliki Sideri-Lampretsa, Veronika A. Zimmer, Huaqi Qiu, Georgios Kaissis, Daniel Rueckert</li>
<li>for: 这个论文的目的是提出一种多模态图像匹配算法，以便在医学应用中进行前处理。</li>
<li>methods: 该论文使用了随机卷积来学习图像的内在几何结构，并使用这种方法来适应不同的探测模式。</li>
<li>results: 论文的实验结果表明，使用这种方法可以成功地将多模态图像匹配成功，并且其捕捉范围更大于传统的度量方法，如相互信息和 норmalized gradient fields。<details>
<summary>Abstract</summary>
Multi-modal image registration is a crucial pre-processing step in many medical applications. However, it is a challenging task due to the complex intensity relationships between different imaging modalities, which can result in large discrepancy in image appearance. The success of multi-modal image registration, whether it is conventional or learning based, is predicated upon the choice of an appropriate distance (or similarity) measure. Particularly, deep learning registration algorithms lack in accuracy or even fail completely when attempting to register data from an "unseen" modality. In this work, we present Modality Agnostic Distance (MAD), a deep image distance}] measure that utilises random convolutions to learn the inherent geometry of the images while being robust to large appearance changes. Random convolutions are geometry-preserving modules which we use to simulate an infinite number of synthetic modalities alleviating the need for aligned paired data during training. We can therefore train MAD on a mono-modal dataset and successfully apply it to a multi-modal dataset. We demonstrate that not only can MAD affinely register multi-modal images successfully, but it has also a larger capture range than traditional measures such as Mutual Information and Normalised Gradient Fields.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Rethinking-Momentum-Knowledge-Distillation-in-Online-Continual-Learning"><a href="#Rethinking-Momentum-Knowledge-Distillation-in-Online-Continual-Learning" class="headerlink" title="Rethinking Momentum Knowledge Distillation in Online Continual Learning"></a>Rethinking Momentum Knowledge Distillation in Online Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02870">http://arxiv.org/abs/2309.02870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Michel, Maorong Wang, Ling Xiao, Toshihiko Yamasaki</li>
<li>For: addresses the problem of training neural networks on a continuous data stream where multiple classification tasks emerge in sequence.* Methods: uses Momentum Knowledge Distillation (MKD) to enhance existing OCL methods, and demonstrates its capabilities to improve accuracy by more than 10% points on ImageNet100.* Results: improves existing state-of-the-art accuracy by more than 10% points on ImageNet100, and sheds light on MKD internal mechanics and impacts during training in OCL.<details>
<summary>Abstract</summary>
Online Continual Learning (OCL) addresses the problem of training neural networks on a continuous data stream where multiple classification tasks emerge in sequence. In contrast to offline Continual Learning, data can be seen only once in OCL. In this context, replay-based strategies have achieved impressive results and most state-of-the-art approaches are heavily depending on them. While Knowledge Distillation (KD) has been extensively used in offline Continual Learning, it remains under-exploited in OCL, despite its potential. In this paper, we theoretically analyze the challenges in applying KD to OCL. We introduce a direct yet effective methodology for applying Momentum Knowledge Distillation (MKD) to many flagship OCL methods and demonstrate its capabilities to enhance existing approaches. In addition to improving existing state-of-the-arts accuracy by more than $10\%$ points on ImageNet100, we shed light on MKD internal mechanics and impacts during training in OCL. We argue that similar to replay, MKD should be considered a central component of OCL.
</details>
<details>
<summary>摘要</summary>
In this paper, we theoretically analyze the challenges in applying KD to OCL. We introduce a direct yet effective methodology for applying momentum knowledge distillation (MKD) to many flagship OCL methods and demonstrate its capabilities to enhance existing approaches. In addition to improving existing state-of-the-art accuracy by more than 10 percentage points on ImageNet100, we shed light on MKD's internal mechanisms and impacts during training in OCL. We argue that, similar to replay, MKD should be considered a central component of OCL.
</details></li>
</ul>
<hr>
<h2 id="A-recommender-for-the-management-of-chronic-pain-in-patients-undergoing-spinal-cord-stimulation"><a href="#A-recommender-for-the-management-of-chronic-pain-in-patients-undergoing-spinal-cord-stimulation" class="headerlink" title="A recommender for the management of chronic pain in patients undergoing spinal cord stimulation"></a>A recommender for the management of chronic pain in patients undergoing spinal cord stimulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03918">http://arxiv.org/abs/2309.03918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tigran Tchrakian, Mykhaylo Zayats, Alessandra Pascale, Dat Huynh, Pritish Parida, Carla Agurto Rios, Sergiy Zhuk, Jeffrey L. Rogers, ENVISION Studies Physician Author Group, Boston Scientific Research Scientists Consortium</li>
<li>for: 这个论文主要是为了管理慢性疼痛而设计的。</li>
<li>methods: 这个论文使用了一种 Contextual Multi-armed Bandit（CMAB）方法，用于开发一个可以为慢性疼痛患者提供SCS设置的推荐系统。</li>
<li>results: 这个研究发现，通过向患者提供SCS推荐，可以 statistically significant improvement in clinical outcomes（疼痛和&#x2F;或生活质量），85%的所有subjects（N&#x3D;21）表现出了改善。在moderate PS（N&#x3D;7）的subjects中，100%的subjects表现出了 statistically significant improvement，5&#x2F;7的subjects有改善的PS dwell time。<details>
<summary>Abstract</summary>
Spinal cord stimulation (SCS) is a therapeutic approach used for the management of chronic pain. It involves the delivery of electrical impulses to the spinal cord via an implanted device, which when given suitable stimulus parameters can mask or block pain signals. Selection of optimal stimulation parameters usually happens in the clinic under the care of a provider whereas at-home SCS optimization is managed by the patient. In this paper, we propose a recommender system for the management of pain in chronic pain patients undergoing SCS. In particular, we use a contextual multi-armed bandit (CMAB) approach to develop a system that recommends SCS settings to patients with the aim of improving their condition. These recommendations, sent directly to patients though a digital health ecosystem, combined with a patient monitoring system closes the therapeutic loop around a chronic pain patient over their entire patient journey. We evaluated the system in a cohort of SCS-implanted ENVISION study subjects (Clinicaltrials.gov ID: NCT03240588) using a combination of quality of life metrics and Patient States (PS), a novel measure of holistic outcomes. SCS recommendations provided statistically significant improvement in clinical outcomes (pain and/or QoL) in 85\% of all subjects (N=21). Among subjects in moderate PS (N=7) prior to receiving recommendations, 100\% showed statistically significant improvements and 5/7 had improved PS dwell time. This analysis suggests SCS patients may benefit from SCS recommendations, resulting in additional clinical improvement on top of benefits already received from SCS therapy.
</details>
<details>
<summary>摘要</summary>
脊梗刺激疗法（SCS）是一种治疗方法用于管理慢性痛。它通过在体内嵌入设备的电rical脉搏，对脊梗进行刺激，可以阻据或掩盖痛讯。选择最佳刺激参数通常在医生诊所进行，而在家SCS优化则由病人自行处理。在这篇研究中，我们提出了一个推荐系统，用于管理慢性痛患者在刺激疗法中的痛症。我们使用多臂环境（CMAB）方法开发了一个系统，可以为患者提供SCS设置的推荐。这些推荐通过数位健康生态系统发送到病人，与病人监控系统结合，将患者的整个病程关键点组合起来。我们在ENVISION研究（Clinicaltrials.gov ID：NCT03240588）中评估了这个系统，使用质量生活指标和患者状态（PS），一种新的整体结果测量。SCS推荐提供了显著改善临床结果（痛和/或生活质量）的statistically significant improvement（p=0.003）。在moderate PS（N=7）前 receiving推荐的患者中，100% 示出了 statistically significant improvement，5/7 有改善的 PS 滞留时间。这个分析表明SCS患者可能受益于SCS推荐，从而增加了SCS疗法已经提供的临床改善。
</details></li>
</ul>
<hr>
<h2 id="Generalised-Mutual-Information-a-Framework-for-Discriminative-Clustering"><a href="#Generalised-Mutual-Information-a-Framework-for-Discriminative-Clustering" class="headerlink" title="Generalised Mutual Information: a Framework for Discriminative Clustering"></a>Generalised Mutual Information: a Framework for Discriminative Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02858">http://arxiv.org/abs/2309.02858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Louis Ohl, Pierre-Alexandre Mattei, Charles Bouveyron, Warith Harchaoui, Mickaël Leclercq, Arnaud Droit, Frédéric Precioso</li>
<li>for: 本文旨在探讨最近一些深度归一化中的 clustering 目标函数，尤其是使用 Mutual Information (MI) 作为无监督的目标函数。</li>
<li>methods: 本文首先指出了 maximizing MI 不一定会得到满意的归一化结果，并提出了 Kullback-Leibler divergence 是这种行为的主要原因。然后，本文引入了一种扩展的 MI，称为 Generalised Mutual Information (GEMINI)，它是一种基于距离或kernel在数据空间的geometry-aware的度量。</li>
<li>results: GEMINIs 可以自动选择相关的数量的归一化类别，这是深度归一化预先未知的情况下归一化中很少研究的一个特性。<details>
<summary>Abstract</summary>
In the last decade, recent successes in deep clustering majorly involved the Mutual Information (MI) as an unsupervised objective for training neural networks with increasing regularisations. While the quality of the regularisations have been largely discussed for improvements, little attention has been dedicated to the relevance of MI as a clustering objective. In this paper, we first highlight how the maximisation of MI does not lead to satisfying clusters. We identified the Kullback-Leibler divergence as the main reason of this behaviour. Hence, we generalise the mutual information by changing its core distance, introducing the Generalised Mutual Information (GEMINI): a set of metrics for unsupervised neural network training. Unlike MI, some GEMINIs do not require regularisations when training as they are geometry-aware thanks to distances or kernels in the data space. Finally, we highlight that GEMINIs can automatically select a relevant number of clusters, a property that has been little studied in deep discriminative clustering context where the number of clusters is a priori unknown.
</details>
<details>
<summary>摘要</summary>
过去一个十年，深度归一（Deep Clustering）的成功主要基于用无监督目标函数训练神经网络的积分信息（Mutual Information，MI）。虽然改进质量的讨论得到了广泛关注，但对于MI作为归一目标的重要性几乎没有任何关注。在这篇论文中，我们首先强调了将积分信息 maximize 不会导致满意的归一。我们认为，这是由卷积-莱布勒散射（Kullback-Leibler divergence）的主要原因。因此，我们总结了积分信息，并引入了一组新的准则（Generalized Mutual Information，GEMINI），这些准则不需要训练时的正则化。此外，我们发现了GEMINI可以自动选择合适的归一数量，这是在深度探测归一上未经知道归一数量的情况下很少研究的特性。
</details></li>
</ul>
<hr>
<h2 id="Getting-too-personal-ized-The-importance-of-feature-choice-in-online-adaptive-algorithms"><a href="#Getting-too-personal-ized-The-importance-of-feature-choice-in-online-adaptive-algorithms" class="headerlink" title="Getting too personal(ized): The importance of feature choice in online adaptive algorithms"></a>Getting too personal(ized): The importance of feature choice in online adaptive algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02856">http://arxiv.org/abs/2309.02856</a></li>
<li>repo_url: None</li>
<li>paper_authors: ZhaoBin Li, Luna Yee, Nathaniel Sauerberg, Irene Sakson, Joseph Jay Williams, Anna N. Rafferty</li>
<li>for: 这个论文的目的是研究个性化学习技术是否有成本，以及个性化是否会导致政策采用延迟。</li>
<li>methods: 这篇论文使用了多臂投掷（MAB）算法来学习每个学生应该接受哪个版本的教育技术。</li>
<li>results:  simulation 结果表明，在某些情况下，包含学生特征进行个性化可以有利，但在其他情况下，这会降低投掷算法的性能。此外，包含不必要的学生特征可能会系统性地劣化一些学生。<details>
<summary>Abstract</summary>
Digital educational technologies offer the potential to customize students' experiences and learn what works for which students, enhancing the technology as more students interact with it. We consider whether and when attempting to discover how to personalize has a cost, such as if the adaptation to personal information can delay the adoption of policies that benefit all students. We explore these issues in the context of using multi-armed bandit (MAB) algorithms to learn a policy for what version of an educational technology to present to each student, varying the relation between student characteristics and outcomes and also whether the algorithm is aware of these characteristics. Through simulations, we demonstrate that the inclusion of student characteristics for personalization can be beneficial when those characteristics are needed to learn the optimal action. In other scenarios, this inclusion decreases performance of the bandit algorithm. Moreover, including unneeded student characteristics can systematically disadvantage students with less common values for these characteristics. Our simulations do however suggest that real-time personalization will be helpful in particular real-world scenarios, and we illustrate this through case studies using existing experimental results in ASSISTments. Overall, our simulations show that adaptive personalization in educational technologies can be a double-edged sword: real-time adaptation improves student experiences in some contexts, but the slower adaptation and potentially discriminatory results mean that a more personalized model is not always beneficial.
</details>
<details>
<summary>摘要</summary>
《数字教育技术的个性化机会》数字教育技术可以为学生个性化学习经验，了解每个学生的需求，并且可以通过更多的学生互动来提高技术。然而，我们需要考虑个性化是否有成本，例如个性化学生信息可能会导致政策采用延迟。我们在多臂投降（MAB）算法学习政策中对学生特征进行个性化时的问题。我们通过 simulations 表明，当学生特征需要了解优化行动时，包含学生特征可以有利。然而，在其他情况下，包含学生特征可能会降低投降算法的性能。此外，包含不必要的学生特征可能会系统性地劣化拥有不同特征的学生。我们的 simulations 表明，在某些实际场景下，实时个性化可以有助于学生，而不是一直等待个性化。总之，我们的 simulations 表明，个性化教育技术可以是一种两面的剑：实时个性化可以提高学生体验，但是更慢的个性化和可能歧视的结果表明，一个更加个性化的模型并不总是有利。
</details></li>
</ul>
<hr>
<h2 id="Promoting-Open-domain-Dialogue-Generation-through-Learning-Pattern-Information-between-Contexts-and-Responses"><a href="#Promoting-Open-domain-Dialogue-Generation-through-Learning-Pattern-Information-between-Contexts-and-Responses" class="headerlink" title="Promoting Open-domain Dialogue Generation through Learning Pattern Information between Contexts and Responses"></a>Promoting Open-domain Dialogue Generation through Learning Pattern Information between Contexts and Responses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02823">http://arxiv.org/abs/2309.02823</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/russellliu0/rad">https://github.com/russellliu0/rad</a></li>
<li>paper_authors: Mengjuan Liu, Chenyang Liu, Yunfan Yang, Jiang Liu, Mohan Jing</li>
<li>for: 提高开放领域对话模型中生成响应的质量，使其更加生动、有信息内容。</li>
<li>methods: 基于预训练语言模型（GPT-2）建立开放领域对话模型，提出改进的计划采样方法，使用响应来引导生成响应的训练阶段，并设计了响应相关机制以挖掘含义脉络信息。</li>
<li>results: 在Persona-Chat和DailyDialog数据集上评估提出的模型（RAD），实验结果表明，我们的模型在大多数自动和手动指标上超过了基eline。<details>
<summary>Abstract</summary>
Recently, utilizing deep neural networks to build the opendomain dialogue models has become a hot topic. However, the responses generated by these models suffer from many problems such as responses not being contextualized and tend to generate generic responses that lack information content, damaging the user's experience seriously. Therefore, many studies try introducing more information into the dialogue models to make the generated responses more vivid and informative. Unlike them, this paper improves the quality of generated responses by learning the implicit pattern information between contexts and responses in the training samples. In this paper, we first build an open-domain dialogue model based on the pre-trained language model (i.e., GPT-2). And then, an improved scheduled sampling method is proposed for pre-trained models, by which the responses can be used to guide the response generation in the training phase while avoiding the exposure bias problem. More importantly, we design a response-aware mechanism for mining the implicit pattern information between contexts and responses so that the generated replies are more diverse and approximate to human replies. Finally, we evaluate the proposed model (RAD) on the Persona-Chat and DailyDialog datasets; and the experimental results show that our model outperforms the baselines on most automatic and manual metrics.
</details>
<details>
<summary>摘要</summary>
近期，使用深度神经网络建立开放领域对话模型已成为热点话题。然而，由这些模型生成的响应具有许多问题，如不具备上下文知识和生成泛润响应，导致用户体验受到严重损害。因此，许多研究尝试通过在对话模型中添加更多信息来使生成的响应更加生动和有用。不同于之前的研究，本文改进了对话模型的质量，通过在训练样本中学习含义映射信息。首先，我们基于预训练语言模型（i.e., GPT-2）建立了一个开放领域对话模型。然后，我们提出了一种改进的排定采样方法，通过响应来引导对话模型在训练阶段的响应生成，同时避免露出偏见问题。此外，我们设计了一种响应感知机制，以挖掘含义映射信息，使生成的答案更加多样化和人类化。最后，我们在Persona-Chat和DailyDialog数据集上评估了我们的模型（RAD），并获得了许多自动和手动指标上的优秀result。
</details></li>
</ul>
<hr>
<h2 id="Roulette-A-Semantic-Privacy-Preserving-Device-Edge-Collaborative-Inference-Framework-for-Deep-Learning-Classification-Tasks"><a href="#Roulette-A-Semantic-Privacy-Preserving-Device-Edge-Collaborative-Inference-Framework-for-Deep-Learning-Classification-Tasks" class="headerlink" title="Roulette: A Semantic Privacy-Preserving Device-Edge Collaborative Inference Framework for Deep Learning Classification Tasks"></a>Roulette: A Semantic Privacy-Preserving Device-Edge Collaborative Inference Framework for Deep Learning Classification Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02820">http://arxiv.org/abs/2309.02820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyi Li, Guocheng Liao, Lin Chen, Xu Chen</li>
<li>for: 本文提出了一个名为 Roulette 的任务型semantic privacy-preserving 深度学习分类器框架，用于解决非同分布数据和隐私泄露问题。</li>
<li>methods: 该框架基于划算学习和加密学习，将数据的真实值视为私钥信息，并提供了一种分布式隐私保护的 garantue。</li>
<li>results: 通过使用实际数据进行广泛的性能评估， authors 发现 Roulette 可以有效地防止多种攻击，同时保持模型准确性。 在非同分布数据下，Roulette 可以提高推断精度21%。<details>
<summary>Abstract</summary>
Deep learning classifiers are crucial in the age of artificial intelligence. The device-edge-based collaborative inference has been widely adopted as an efficient framework for promoting its applications in IoT and 5G/6G networks. However, it suffers from accuracy degradation under non-i.i.d. data distribution and privacy disclosure. For accuracy degradation, direct use of transfer learning and split learning is high cost and privacy issues remain. For privacy disclosure, cryptography-based approaches lead to a huge overhead. Other lightweight methods assume that the ground truth is non-sensitive and can be exposed. But for many applications, the ground truth is the user's crucial privacy-sensitive information. In this paper, we propose a framework of Roulette, which is a task-oriented semantic privacy-preserving collaborative inference framework for deep learning classifiers. More than input data, we treat the ground truth of the data as private information. We develop a novel paradigm of split learning where the back-end DNN is frozen and the front-end DNN is retrained to be both a feature extractor and an encryptor. Moreover, we provide a differential privacy guarantee and analyze the hardness of ground truth inference attacks. To validate the proposed Roulette, we conduct extensive performance evaluations using realistic datasets, which demonstrate that Roulette can effectively defend against various attacks and meanwhile achieve good model accuracy. In a situation where the non-i.i.d. is very severe, Roulette improves the inference accuracy by 21\% averaged over benchmarks, while making the accuracy of discrimination attacks almost equivalent to random guessing.
</details>
<details>
<summary>摘要</summary>
深度学习分类器在人工智能时代扮演着关键性的角色。设备边缘基于的合作推理已成为一种高效的推广应用在物联网和5G/6G网络中。然而，它受到异步数据分布的精度下降和隐私泄露的问题。直接使用传输学习和分裂学习可能会带来高成本和隐私问题，而使用 криптография-based方法会带来巨大的负担。其他轻量级方法假设数据的真实值是无敏感的，但在许多应用中，用户的真实值是关键的隐私敏感信息。在这篇论文中，我们提出了一个名为Roulette的任务意义 Semantic Privacy-Preserving Collaborative Inference框架，其中我们将数据的真实值视为私钥信息。我们开发了一种新的分裂学习方法，其中后端DNN冻结，前端DNN重新训练为特征提取器和加密器。此外，我们提供了一种差分隐私保证，并分析了攻击者对真实值的推理难度。为验证我们的Roulette，我们对实际数据进行了广泛的性能评估，结果表明Roulette可以有效防御各种攻击，同时保持良好的模型准确率。在异步数据分布情况下，Roulette提高了推理精度21%，而对攻击者的推理精度接近随机猜测。
</details></li>
</ul>
<hr>
<h2 id="Combining-Thermodynamics-based-Model-of-the-Centrifugal-Compressors-and-Active-Machine-Learning-for-Enhanced-Industrial-Design-Optimization"><a href="#Combining-Thermodynamics-based-Model-of-the-Centrifugal-Compressors-and-Active-Machine-Learning-for-Enhanced-Industrial-Design-Optimization" class="headerlink" title="Combining Thermodynamics-based Model of the Centrifugal Compressors and Active Machine Learning for Enhanced Industrial Design Optimization"></a>Combining Thermodynamics-based Model of the Centrifugal Compressors and Active Machine Learning for Enhanced Industrial Design Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02818">http://arxiv.org/abs/2309.02818</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shadi Ghiasi, Guido Pazzi, Concettina Del Grosso, Giovanni De Magistris, Giacomo Veneri</li>
<li>for: 这个论文主要是用来提高中心力压缩机的设计过程中的优化过程，以减少计算成本。</li>
<li>methods: 这个方法结合了一个内部的气动学模型和一个 Gaussian Process 基于的替身模型，并在一个可动性学习（AL）设定下使用。</li>
<li>results: 这个方法可以对替身模型进行优化，并且可以在生产环境中实现46%的计算时间减少，同时保持同性能。<details>
<summary>Abstract</summary>
The design process of centrifugal compressors requires applying an optimization process which is computationally expensive due to complex analytical equations underlying the compressor's dynamical equations. Although the regression surrogate models could drastically reduce the computational cost of such a process, the major challenge is the scarcity of data for training the surrogate model. Aiming to strategically exploit the labeled samples, we propose the Active-CompDesign framework in which we combine a thermodynamics-based compressor model (i.e., our internal software for compressor design) and Gaussian Process-based surrogate model within a deployable Active Learning (AL) setting. We first conduct experiments in an offline setting and further, extend it to an online AL framework where a real-time interaction with the thermodynamics-based compressor's model allows the deployment in production. ActiveCompDesign shows a significant performance improvement in surrogate modeling by leveraging on uncertainty-based query function of samples within the AL framework with respect to the random selection of data points. Moreover, our framework in production has reduced the total computational time of compressor's design optimization to around 46% faster than relying on the internal thermodynamics-based simulator, achieving the same performance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的中心旋转压缩机设计过程具有计算成本高的问题，因为这些过程下面有复杂的数学方程。虽然使用回归模型可以快速减少计算成本，但是主要挑战在于缺乏训练数据。为了积极利用标注样本，我们提出了Active-CompDesign框架，它将内部的热力学模型和 Gaussian 过程基于的准确模型结合在一起，并在可部署的活动学习（AL）环境中实现。我们首先在线上进行了实验，然后将其扩展到在线 AL 框架中，在实时与热力学模型进行交互时，可以在生产环境中部署。ActiveCompDesign 显示在准确模型化方面得到了明显的改进，通过在 AL 框架中使用不确定性基于的样本选择函数来避免随机选择数据点的问题。此外，我们的框架在生产环境中减少了压缩机的设计优化总计算时间约为46%，实现了同等性。
</details></li>
</ul>
<hr>
<h2 id="Near-continuous-time-Reinforcement-Learning-for-continuous-state-action-spaces"><a href="#Near-continuous-time-Reinforcement-Learning-for-continuous-state-action-spaces" class="headerlink" title="Near-continuous time Reinforcement Learning for continuous state-action spaces"></a>Near-continuous time Reinforcement Learning for continuous state-action spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02815">http://arxiv.org/abs/2309.02815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Croissant, Marc Abeille, Bruno Bouchard</li>
<li>for: 这 paper Focuses on the reinforcement learning problem of controlling an unknown dynamical system to maximize the long-term average reward along a single trajectory, with the goal of overcoming the limitations of previous literature, which primarily considers discrete time and state-action spaces.</li>
<li>methods: The paper proposes a modelling approach that uses a Poisson clock of frequency $\varepsilon^{-1}$ to capture arbitrary time scales, and considers a generic reward function and state dynamics modelled as a jump process with an arbitrary transition kernel on $\mathbb{R}^d$. The algorithm uses an eluder dimension framework for learning and an approximate planning method based on a diffusive limit approximation of the jump process.</li>
<li>results: The paper shows that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively, and the algorithm enjoys a regret of order $\tilde{\mathcal{O}(\varepsilon^{1&#x2F;2} T+\sqrt{T})$. As the frequency of interactions blows up, the approximation error $\varepsilon^{1&#x2F;2} T$ vanishes, showing that $\tilde{\mathcal{O}(\sqrt{T})$ is attainable in near-continuous time.<details>
<summary>Abstract</summary>
We consider the Reinforcement Learning problem of controlling an unknown dynamical system to maximise the long-term average reward along a single trajectory. Most of the literature considers system interactions that occur in discrete time and discrete state-action spaces. Although this standpoint is suitable for games, it is often inadequate for mechanical or digital systems in which interactions occur at a high frequency, if not in continuous time, and whose state spaces are large if not inherently continuous. Perhaps the only exception is the Linear Quadratic framework for which results exist both in discrete and continuous time. However, its ability to handle continuous states comes with the drawback of a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modelling interaction times with a Poisson clock of frequency $\varepsilon^{-1}$, which captures arbitrary time scales: from discrete ($\varepsilon=1$) to continuous time ($\varepsilon\downarrow0$). In addition, we consider a generic reward function and model the state dynamics according to a jump process with an arbitrary transition kernel on $\mathbb{R}^d$. We show that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively. We tackle learning within the eluder dimension framework and propose an approximate planning method based on a diffusive limit approximation of the jump process. Overall, our algorithm enjoys a regret of order $\tilde{\mathcal{O}(\varepsilon^{1/2} T+\sqrt{T})$. As the frequency of interactions blows up, the approximation error $\varepsilon^{1/2} T$ vanishes, showing that $\tilde{\mathcal{O}(\sqrt{T})$ is attainable in near-continuous time.
</details>
<details>
<summary>摘要</summary>
我们考虑了控制未知动力系统的强化学习问题，以最大化漫游趋势的长期奖励。大多数文献都是在离散时间和离散状态动作空间下 considerthe Reinforcement Learning problem。 although this standpoint is suitable for games, it is often inadequate for mechanical or digital systems, where interactions occur at high frequencies or in continuous time, and the state spaces are large or inherently continuous. However, the Linear Quadratic framework exists for both discrete and continuous time, but it has a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modeling interaction times with a Poisson clock of frequency $\varepsilon^{-1}$, which captures arbitrary time scales, from discrete time to continuous time. In addition, we consider a generic reward function and model the state dynamics according to a jump process with an arbitrary transition kernel on $\mathbb{R}^d$. We show that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively. We tackle learning within the eluder dimension framework and propose an approximate planning method based on a diffusive limit approximation of the jump process. Overall, our algorithm enjoys a regret of order $\tilde{\mathcal{O}(\varepsilon^{1/2} T+\sqrt{T})$. As the frequency of interactions blows up, the approximation error $\varepsilon^{1/2} T$ vanishes, showing that $\tilde{\mathcal{O}(\sqrt{T})$ is attainable in near-continuous time.Here's the translation in Traditional Chinese:我们考虑了控制未知动力系统的强化学习问题，以最大化漫游趋势的长期奖励。大多数文献都是在离散时间和离散状态动作空间下考虑Reinforcement Learning problem。 although this standpoint is suitable for games, it is often inadequate for mechanical or digital systems, where interactions occur at high frequencies or in continuous time, and the state spaces are large or inherently continuous. However, the Linear Quadratic framework exists for both discrete and continuous time, but it has a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modeling interaction times with a Poisson clock of frequency $\varepsilon^{-1}$, which captures arbitrary time scales, from discrete time to continuous time. In addition, we consider a generic reward function and model the state dynamics according to a jump process with an arbitrary transition kernel on $\mathbb{R}^d$. We show that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively. We tackle learning within the eluder dimension framework and propose an approximate planning method based on a diffusive limit approximation of the jump process. Overall, our algorithm enjoys a regret of order $\tilde{\mathcal{O}(\varepsilon^{1/2} T+\sqrt{T})$. As the frequency of interactions blows up, the approximation error $\varepsilon^{1/2} T$ vanishes, showing that $\tilde{\mathcal{O}(\sqrt{T})$ is attainable in near-continuous time.
</details></li>
</ul>
<hr>
<h2 id="Automated-Bioinformatics-Analysis-via-AutoBA"><a href="#Automated-Bioinformatics-Analysis-via-AutoBA" class="headerlink" title="Automated Bioinformatics Analysis via AutoBA"></a>Automated Bioinformatics Analysis via AutoBA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03242">http://arxiv.org/abs/2309.03242</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joshuachou2018/autoba">https://github.com/joshuachou2018/autoba</a></li>
<li>paper_authors: Juexiao Zhou, Bin Zhang, Xiuying Chen, Haoyang Li, Xiaopeng Xu, Siyuan Chen, Xin Gao</li>
<li>for: 这篇论文是为了应对快速增长和变化的Omics数据的分析需求而设计的。</li>
<li>methods: 这篇论文使用了一个大型自然语言模型，设计用于传统的Omics数据分析。它使分析过程更加简单，需要最小化使用者的输入，并提供了详细的步骤计划 для多种生物信息学 задачі。</li>
<li>results: 这篇论文透过专家生物信息学家的验证，证明了AutoBA在多种Omics分析 caso中的强健性和适应力。包括整 genomic sequencing (WGS), RNA sequencing (RNA-seq), single-cell RNA-seq, ChIP-seq, 和 spatial transcriptomics等 caso。AutoBA还有自动设计分析过程的能力，根据输入数据的变化。相比于在网上的生物信息学服务，AutoBA可以在本地部署分析，保持数据隐私。<details>
<summary>Abstract</summary>
With the fast-growing and evolving omics data, the demand for streamlined and adaptable tools to handle the analysis continues to grow. In response to this need, we introduce Auto Bioinformatics Analysis (AutoBA), an autonomous AI agent based on a large language model designed explicitly for conventional omics data analysis. AutoBA simplifies the analytical process by requiring minimal user input while delivering detailed step-by-step plans for various bioinformatics tasks. Through rigorous validation by expert bioinformaticians, AutoBA's robustness and adaptability are affirmed across a diverse range of omics analysis cases, including whole genome sequencing (WGS), RNA sequencing (RNA-seq), single-cell RNA-seq, ChIP-seq, and spatial transcriptomics. AutoBA's unique capacity to self-design analysis processes based on input data variations further underscores its versatility. Compared with online bioinformatic services, AutoBA deploys the analysis locally, preserving data privacy. Moreover, different from the predefined pipeline, AutoBA has adaptability in sync with emerging bioinformatics tools. Overall, AutoBA represents a convenient tool, offering robustness and adaptability for complex omics data analysis.
</details>
<details>
<summary>摘要</summary>
随着Omics数据的快速增长和演化，对处理分析的需求不断增长。为回应这一需求，我们介绍Auto Bioinformatics Analysis（AutoBA），一个基于大语言模型的自主AI代理，专门为传统Omics数据分析设计。AutoBA通过最小化用户输入而简化分析过程，并提供详细的步骤计划 для多种生物信息学任务。经过专家生物信息学家的严格验证，AutoBA在多种Omics分析 caso中表现出了Robustness和适应性，包括整个基因组测序（WGS）、RNA测序（RNA-seq）、单个单元RNA-seq、ChIP-seq和空间表述学。AutoBA的独特的自动设计分析过程基于输入数据的变化，进一步强调其灵活性。相比于在线生物信息学服务，AutoBA在本地部署分析，保持数据隐私。此外，AutoBA与emerging生物信息学工具相比，具有适应性。总的来说，AutoBA表示一种便捷的工具，提供Robustness和适应性 для复杂的Omics数据分析。
</details></li>
</ul>
<hr>
<h2 id="Norm-Tweaking-High-performance-Low-bit-Quantization-of-Large-Language-Models"><a href="#Norm-Tweaking-High-performance-Low-bit-Quantization-of-Large-Language-Models" class="headerlink" title="Norm Tweaking: High-performance Low-bit Quantization of Large Language Models"></a>Norm Tweaking: High-performance Low-bit Quantization of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02784">http://arxiv.org/abs/2309.02784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang Li, Qingyuan Li, Bo Zhang, Xiangxiang Chu</li>
<li>for: 这篇论文是针对大型自然语言模型（LLM）的模型压缩而写的，以实现在部署时不失去精度。</li>
<li>methods: 我们引入了一种名为“norm tweaking”的技术，这是一种可以与现有的PTQ方法整合的高精度且成本效益高的方法。我们的方法基于 Float 版本的活化函数与 quantized 版本之间的差异，通过更新对应的Normalization层的权重，以提高模型的通用能力。</li>
<li>results: 我们在诸多数据集上进行了广泛的实验，结果显示我们的方法可以在weight-only quantization和joint quantization of weights和活动中实现更高的精度，超过现有的PTQ方法。在 GLM-130B 和 OPT-66B 上，我们的方法甚至可以在2 bits 的量化下达到浮点版本的精度水平。<details>
<summary>Abstract</summary>
As the size of large language models (LLMs) continues to grow, model compression without sacrificing accuracy has become a crucial challenge for deployment. While some quantization methods, such as GPTQ, have made progress in achieving acceptable 4-bit weight-only quantization, attempts at lower bit quantization often result in severe performance degradation. In this paper, we introduce a technique called norm tweaking, which can be used as a plugin in current PTQ methods to achieve high precision while being cost-efficient. Our approach is inspired by the observation that rectifying the quantized activation distribution to match its float counterpart can readily restore accuracy for LLMs. To achieve this, we carefully design a tweaking strategy that includes calibration data generation and channel-wise distance constraint to update the weights of normalization layers for better generalization. We conduct extensive experiments on various datasets using several open-sourced LLMs. Our method demonstrates significant improvements in both weight-only quantization and joint quantization of weights and activations, surpassing existing PTQ methods. On GLM-130B and OPT-66B, our method even achieves the same level of accuracy at 2-bit quantization as their float ones. Our simple and effective approach makes it more practical for real-world applications.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)LLMs的大小继续增长，模型压缩无需牺牲准确性已成为部署的关键挑战。虽然一些归一化方法，如GPTQ，在实现4位准确性的weight-only归一化方面做出了进展，但尝试在更低的位数归一化时经常导致性能下降。在这篇论文中，我们介绍了一种名为“norm tweaking”的技术，可以作为现有的PTQ方法的插件，以实现高精度而且成本效益高的压缩。我们的方法受 Float 版本的 LLMS 的观察所启发，通过修正归一化后的激活量分布，以恢复 LLMS 的准确性。为了实现这一点，我们精心设计了一种调整策略，包括生成准确数据和通道级距离约束，以更新 normalization 层的权重，以便更好地适应。我们在多个数据集和多个开源 LLMS 上进行了广泛的实验。我们的方法在 weight-only 归一化和 weights 和激活量的共同归一化中都显示出了显著的改进，超越了现有的PTQ方法。在 GLM-130B 和 OPT-66B 上，我们的方法甚至可以在2位归一化下达到浮点版本的准确性水平。我们的简单而有效的方法使其更适合实际应用。
</details></li>
</ul>
<hr>
<h2 id="Improving-diagnosis-and-prognosis-of-lung-cancer-using-vision-transformers-A-scoping-review"><a href="#Improving-diagnosis-and-prognosis-of-lung-cancer-using-vision-transformers-A-scoping-review" class="headerlink" title="Improving diagnosis and prognosis of lung cancer using vision transformers: A scoping review"></a>Improving diagnosis and prognosis of lung cancer using vision transformers: A scoping review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02783">http://arxiv.org/abs/2309.02783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hazrat Ali, Farida Mohsen, Zubair Shah</li>
<li>for: This paper aims to identify recent developments in vision transformer-based AI methods for lung cancer imaging applications, and to provide insights into their performance and potential for clinical translation.</li>
<li>methods: The paper reviews 34 studies published from 2020 to 2022 that use vision transformer-based methods for lung cancer diagnosis and prognosis, including classification of lung cancer types and segmentation of lungs. The studies combine vision transformers with other architectures such as convolutional neural networks or UNet models.</li>
<li>results: The review finds that vision transformer-based models are increasingly popular for lung cancer applications, but their computational complexity and clinical relevance are important factors to consider for future research. The studies show promising results in lung cancer diagnosis and prognosis, but lack clear strategies for clinical transformation.Here are the three points in Simplified Chinese text:</li>
<li>for: 这篇评论旨在描述最近几年内发表的视Transformer基于AI方法在肺癌图像应用中的发展，以及这些方法在临床翻译中的潜在价值。</li>
<li>methods: 这篇评论检讨了2020年至2022年间发表的34篇研究，这些研究使用视Transformer基于方法进行肺癌诊断和预测，包括肺癌类型分类和肺脏分割。这些研究通常将视Transformer与其他架构相结合，如卷积神经网络或UNet模型。</li>
<li>results: 评论发现，视Transformer基于模型在肺癌应用中日益受欢迎，但计算复杂度和临床 relevance 是未来研究的重要因素。研究显示，视Transformer基于模型在肺癌诊断和预测中表现出色，但缺乏清晰的临床转化策略。<details>
<summary>Abstract</summary>
Vision transformer-based methods are advancing the field of medical artificial intelligence and cancer imaging, including lung cancer applications. Recently, many researchers have developed vision transformer-based AI methods for lung cancer diagnosis and prognosis. This scoping review aims to identify the recent developments on vision transformer-based AI methods for lung cancer imaging applications. It provides key insights into how vision transformers complemented the performance of AI and deep learning methods for lung cancer. Furthermore, the review also identifies the datasets that contributed to advancing the field. Of the 314 retrieved studies, this review included 34 studies published from 2020 to 2022. The most commonly addressed task in these studies was the classification of lung cancer types, such as lung squamous cell carcinoma versus lung adenocarcinoma, and identifying benign versus malignant pulmonary nodules. Other applications included survival prediction of lung cancer patients and segmentation of lungs. The studies lacked clear strategies for clinical transformation. SWIN transformer was a popular choice of the researchers; however, many other architectures were also reported where vision transformer was combined with convolutional neural networks or UNet model. It can be concluded that vision transformer-based models are increasingly in popularity for developing AI methods for lung cancer applications. However, their computational complexity and clinical relevance are important factors to be considered for future research work. This review provides valuable insights for researchers in the field of AI and healthcare to advance the state-of-the-art in lung cancer diagnosis and prognosis. We provide an interactive dashboard on lung-cancer.onrender.com/.
</details>
<details>
<summary>摘要</summary>
医学人工智能领域中，视transformer基本方法在肺癌成像方面得到了广泛应用，包括肺癌诊断和预后预测。最近几年，许多研究人员已经开发出了基于视transformer的人工智能方法，用于肺癌成像应用。本篇文章的目的是查找最新的视transformer基本方法在肺癌成像领域的发展情况。它提供了关键的洞察，描述了视transformer如何补充了人工智能和深度学习方法的表现，以及这些方法如何在肺癌预测和诊断中发挥作用。此外，文章还提到了这些研究中使用的数据集，以及这些数据集如何为领域的发展做出了贡献。从2020年到2022年，共检索到314篇研究文章，其中包括34篇发表在这三年间的研究。研究中最常 addressed的任务是分类肺癌类型，如肺平滑细胞癌 versus 肺尖链细胞癌，以及识别正常 versus 癌变肺脏囊。其他应用包括肺癌患者存活预测和肺部分 segmentation。然而，研究中没有明确的临床转化策略。SWIN transformer是研究人员最受欢迎的选择，但是也有许多其他架构，其中视transformer与卷积神经网络或 Unet 模型结合使用。可以 conclude 的是，基于视transformer的模型在肺癌应用领域越来越受欢迎。然而，其计算复杂性和临床实用性是未来研究的关键因素。本文提供了有价值的洞察，可以帮助医学人工智能和医疗领域的研究人员进一步推动肺癌诊断和预后预测的州前沿。我们还提供了一个交互式的仪表板，可以在lung-cancer.onrender.com/ 上查看。
</details></li>
</ul>
<hr>
<h2 id="GPT-Can-Solve-Mathematical-Problems-Without-a-Calculator"><a href="#GPT-Can-Solve-Mathematical-Problems-Without-a-Calculator" class="headerlink" title="GPT Can Solve Mathematical Problems Without a Calculator"></a>GPT Can Solve Mathematical Problems Without a Calculator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03241">http://arxiv.org/abs/2309.03241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thudm/mathglm">https://github.com/thudm/mathglm</a></li>
<li>paper_authors: Zhen Yang, Ming Ding, Qingsong Lv, Zhihuan Jiang, Zehai He, Yuyi Guo, Jinfeng Bai, Jie Tang</li>
<li>for: 挑战大语言模型无法准确执行多位数 arithmetic 操作的假设。</li>
<li>methods: 使用 sufficient training data，一个 2 亿参数的语言模型可以准确执行多位数 arithmetic 操作，并且几乎没有数据泄露。</li>
<li>results: 我们的 MathGLM，基于 GLM-10B 进行了精度调整，在一个包含多步 arithmetic 操作和 math 问题的文本集上达到了类似于 GPT-4 的性能，在一个 5,000 个样本的中文 math 问题测试集上。<details>
<summary>Abstract</summary>
Previous studies have typically assumed that large language models are unable to accurately perform arithmetic operations, particularly multiplication of >8 digits, and operations involving decimals and fractions, without the use of calculator tools. This paper aims to challenge this misconception. With sufficient training data, a 2 billion-parameter language model can accurately perform multi-digit arithmetic operations with almost 100% accuracy without data leakage, significantly surpassing GPT-4 (whose multi-digit multiplication accuracy is only 4.3%). We also demonstrate that our MathGLM, fine-tuned from GLM-10B on a dataset with additional multi-step arithmetic operations and math problems described in text, achieves similar performance to GPT-4 on a 5,000-samples Chinese math problem test set. Our code and data are public at https://github.com/THUDM/MathGLM.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SWAP-Exploiting-Second-Ranked-Logits-for-Adversarial-Attacks-on-Time-Series"><a href="#SWAP-Exploiting-Second-Ranked-Logits-for-Adversarial-Attacks-on-Time-Series" class="headerlink" title="SWAP: Exploiting Second-Ranked Logits for Adversarial Attacks on Time Series"></a>SWAP: Exploiting Second-Ranked Logits for Adversarial Attacks on Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02752">http://arxiv.org/abs/2309.02752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chang George Dong, Liangwei Nathan Zheng, Weitong Chen, Wei Emma Zhang, Lin Yue</li>
<li>for: 这篇论文的目的是提出一种新的时间序列分类模型攻击方法，以强化时间序列分类模型的攻击性和防御性。</li>
<li>methods: 这篇论文使用了一种新的攻击方法，名为SWAP，它将注意力集中在第二名的数据上，以提高第二名的数据的信任度，并对其他数据进行最小的操作。这使得SWAP可以增加时间序列分类模型的攻击成功率，同时降低攻击的复杂度。</li>
<li>results: 实验结果显示，SWAP可以实现高度的攻击成功率，超过50%，并与现有的方法相比，增加了18%的攻击成功率。<details>
<summary>Abstract</summary>
Time series classification (TSC) has emerged as a critical task in various domains, and deep neural models have shown superior performance in TSC tasks. However, these models are vulnerable to adversarial attacks, where subtle perturbations can significantly impact the prediction results. Existing adversarial methods often suffer from over-parameterization or random logit perturbation, hindering their effectiveness. Additionally, increasing the attack success rate (ASR) typically involves generating more noise, making the attack more easily detectable. To address these limitations, we propose SWAP, a novel attacking method for TSC models. SWAP focuses on enhancing the confidence of the second-ranked logits while minimizing the manipulation of other logits. This is achieved by minimizing the Kullback-Leibler divergence between the target logit distribution and the predictive logit distribution. Experimental results demonstrate that SWAP achieves state-of-the-art performance, with an ASR exceeding 50% and an 18% increase compared to existing methods.
</details>
<details>
<summary>摘要</summary>
时间序列分类（TSC）已成为各个领域的关键任务，深度神经网络在TSC任务中表现出了优异的表现。然而，这些模型容易受到恶意攻击，其中细腻的干扰可以很大程度地影响预测结果。现有的攻击方法经常受到过参数化或随机Logit干扰的限制，这限制了其效iveness。此外，通常需要生成更多的噪声，以提高攻击成功率（ASR），这使得攻击更容易被检测出来。为解决这些限制，我们提出了SWAP，一种新的攻击方法 дляTSC模型。SWAP通过提高第二个排名的Logit的信任度，同时尽量减少其他Logit的干扰，来实现这一目的。我们通过最小化Kullback-Leibler散度 между目标Logit分布和预测Logit分布来实现这一目标。实验结果表明，SWAP可以达到现状最佳性能，ASR超过50%，与现有方法相比提高18%。
</details></li>
</ul>
<hr>
<h2 id="MLN-net-A-multi-source-medical-image-segmentation-method-for-clustered-microcalcifications-using-multiple-layer-normalization"><a href="#MLN-net-A-multi-source-medical-image-segmentation-method-for-clustered-microcalcifications-using-multiple-layer-normalization" class="headerlink" title="MLN-net: A multi-source medical image segmentation method for clustered microcalcifications using multiple layer normalization"></a>MLN-net: A multi-source medical image segmentation method for clustered microcalcifications using multiple layer normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02742">http://arxiv.org/abs/2309.02742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yezanting/mln-net-verson1">https://github.com/yezanting/mln-net-verson1</a></li>
<li>paper_authors: Ke Wang, Zanting Ye, Xiang Xie, Haidong Cui, Tao Chen, Banteng Liu</li>
<li>for: 这篇论文是为了提高乳腺癌诊断和治疗的精确度数据分类clustered microcalcifications in mammography images。</li>
<li>methods: 这篇论文提出了一个名为MLN-net的新框架，可以将单一源像转换为多个源像，以提高分类精度。这个框架使用多层常化（LN）层来建立分类网络，并且实现了不同领域的分类精度。</li>
<li>results: 实验结果显示，MLN-net可以从不同领域的数据中精确地分类clustered microcalcifications，并且其分类精度比前方法高。<details>
<summary>Abstract</summary>
Accurate segmentation of clustered microcalcifications in mammography is crucial for the diagnosis and treatment of breast cancer. Despite exhibiting expert-level accuracy, recent deep learning advancements in medical image segmentation provide insufficient contribution to practical applications, due to the domain shift resulting from differences in patient postures, individual gland density, and imaging modalities of mammography etc. In this paper, a novel framework named MLN-net, which can accurately segment multi-source images using only single source images, is proposed for clustered microcalcification segmentation. We first propose a source domain image augmentation method to generate multi-source images, leading to improved generalization. And a structure of multiple layer normalization (LN) layers is used to construct the segmentation network, which can be found efficient for clustered microcalcification segmentation in different domains. Additionally, a branch selection strategy is designed for measuring the similarity of the source domain data and the target domain data. To validate the proposed MLN-net, extensive analyses including ablation experiments are performed, comparison of 12 baseline methods. Extensive experiments validate the effectiveness of MLN-net in segmenting clustered microcalcifications from different domains and the its segmentation accuracy surpasses state-of-the-art methods. Code will be available at https://github.com/yezanting/MLN-NET-VERSON1.
</details>
<details>
<summary>摘要</summary>
严重粒体分化在胸部X射线护理中是致癌诊断和治疗的关键。尽管深度学习在医疗图像分割方面的最新进展展现出了专家级别的准确性，但是这些进展在实际应用中并没有做出足够的贡献，因为受到了患者姿势、个人脏腔密度和成像方式等因素的领域转移。在这篇论文中，我们提出了一种名为MLN-net的新框架，可以使用单源图像来准确地分割多源图像。我们首先提出了一种源Domain图像增强方法，以生成多源图像，从而提高了总体化。此外，我们还使用多层 нормализа（LN）层结构来构建分割网络，这种结构在不同的领域中效果非常高。此外，我们还设计了一种分支选择策略，用于测量源领域数据和目标领域数据之间的相似性。为验证我们提出的MLN-net，我们进行了广泛的分析，包括ablation实验和12个基eline方法的比较。广泛的实验证明了MLN-net在不同领域中对集群粒体分化的准确性具有优势，并且其分割精度超过了状态之前的方法。代码将在https://github.com/yezanting/MLN-NET-VERSON1上提供。
</details></li>
</ul>
<hr>
<h2 id="Rubric-Specific-Approach-to-Automated-Essay-Scoring-with-Augmentation-Training"><a href="#Rubric-Specific-Approach-to-Automated-Essay-Scoring-with-Augmentation-Training" class="headerlink" title="Rubric-Specific Approach to Automated Essay Scoring with Augmentation Training"></a>Rubric-Specific Approach to Automated Essay Scoring with Augmentation Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02740">http://arxiv.org/abs/2309.02740</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brian Cho, Youngbin Jang, Jaewoong Yoon</li>
<li>for:  automatic evaluation of subjective responses</li>
<li>methods:  neural solutions with data augmentation</li>
<li>results:  state-of-the-art performance in Automated Student Assessment Prize datasetHere’s the full translation of the abstract in Simplified Chinese:</li>
<li>for: 本研究旨在 automatizethe evaluation of subjective responses，使用神经网络方法。</li>
<li>methods: 研究使用神经网络方法，并对数据进行数据增强操作，以帮助模型学习掌握旁被前一代工作忽略的特征和函数。</li>
<li>results: 研究在Automated Student Assessment Prize数据集上实现了最佳性能。<details>
<summary>Abstract</summary>
Neural based approaches to automatic evaluation of subjective responses have shown superior performance and efficiency compared to traditional rule-based and feature engineering oriented solutions. However, it remains unclear whether the suggested neural solutions are sufficient replacements of human raters as we find recent works do not properly account for rubric items that are essential for automated essay scoring during model training and validation. In this paper, we propose a series of data augmentation operations that train and test an automated scoring model to learn features and functions overlooked by previous works while still achieving state-of-the-art performance in the Automated Student Assessment Prize dataset.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HC3-Plus-A-Semantic-Invariant-Human-ChatGPT-Comparison-Corpus"><a href="#HC3-Plus-A-Semantic-Invariant-Human-ChatGPT-Comparison-Corpus" class="headerlink" title="HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus"></a>HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02731">http://arxiv.org/abs/2309.02731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenpeng Su, Xing Wu, Wei Zhou, Guangyuan Ma, Songlin Hu</li>
<li>for: 本研究旨在提高AI生成内容检测的性能，尤其是对于模型生成文本的检测。</li>
<li>methods: 本研究使用了更加全面和complete的数据集，包括semantic-invariant任务，以及进行了大量的任务指令练化。</li>
<li>results: 我们的提议检测器在对semantic-invariant任务进行检测时表现出了更高的性能，并且超过了之前的状态 искусственный智能RoBERTa-based检测器。<details>
<summary>Abstract</summary>
ChatGPT has gained significant interest due to its impressive performance, but people are increasingly concerned about its potential risks, particularly around the detection of AI-generated content (AIGC), which is often difficult for untrained humans to identify. Current datasets utilized for detecting ChatGPT-generated text primarily center around question-answering, yet they tend to disregard tasks that possess semantic-invariant properties, such as summarization, translation, and paraphrasing. Our primary studies demonstrate that detecting model-generated text on semantic-invariant tasks is more difficult. To fill this gap, we introduce a more extensive and comprehensive dataset that considers more types of tasks than previous work, including semantic-invariant tasks. In addition, the model after a large number of task instruction fine-tuning shows a strong powerful performance. Owing to its previous success, we further instruct fine-tuning Tk-instruct and built a more powerful detection system. Experimental results show that our proposed detector outperforms the previous state-of-the-art RoBERTa-based detector.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Stylebook-Content-Dependent-Speaking-Style-Modeling-for-Any-to-Any-Voice-Conversion-using-Only-Speech-Data"><a href="#Stylebook-Content-Dependent-Speaking-Style-Modeling-for-Any-to-Any-Voice-Conversion-using-Only-Speech-Data" class="headerlink" title="Stylebook: Content-Dependent Speaking Style Modeling for Any-to-Any Voice Conversion using Only Speech Data"></a>Stylebook: Content-Dependent Speaking Style Modeling for Any-to-Any Voice Conversion using Only Speech Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02730">http://arxiv.org/abs/2309.02730</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyungseob Lim, Kyungguen Byun, Sunkuk Moon, Erik Visser</li>
<li>for: 这个研究的目的是提高无需文本识别或说话者标注的任何对话转换模型，以更好地传递目标说话者的说话风格。</li>
<li>methods: 我们提出了一种新的方法，利用自动编程学习（SSL）模型来收集目标说话者每个不同的音频内容的说话风格，并将其表示为一组叫做“风格图书”的嵌入。然后，我们使用这些风格图书来对源语音内容进行适应，以确定最终的目标风格。最后，我们使用扩散基于的生成模型来生成转换后的声音mel-спектрограм。</li>
<li>results: 我们的提议方法与扩散基于的生成模型的组合，在任何对话转换任务中可以获得更好的说话者一致性，相比基eline模型。此外，我们发现，对于 longer utterances，计算复杂性的增加很小。<details>
<summary>Abstract</summary>
While many recent any-to-any voice conversion models succeed in transferring some target speech's style information to the converted speech, they still lack the ability to faithfully reproduce the speaking style of the target speaker. In this work, we propose a novel method to extract rich style information from target utterances and to efficiently transfer it to source speech content without requiring text transcriptions or speaker labeling. Our proposed approach introduces an attention mechanism utilizing a self-supervised learning (SSL) model to collect the speaking styles of a target speaker each corresponding to the different phonetic content. The styles are represented with a set of embeddings called stylebook. In the next step, the stylebook is attended with the source speech's phonetic content to determine the final target style for each source content. Finally, content information extracted from the source speech and content-dependent target style embeddings are fed into a diffusion-based decoder to generate the converted speech mel-spectrogram. Experiment results show that our proposed method combined with a diffusion-based generative model can achieve better speaker similarity in any-to-any voice conversion tasks when compared to baseline models, while the increase in computational complexity with longer utterances is suppressed.
</details>
<details>
<summary>摘要</summary>
而多个最近的任意到任意语音转换模型可以将目标语音的样式信息传递到转换后的语音中，但它们仍然缺乏可以准确复制目标说话者的说话风格的能力。在这种工作中，我们提议一种新的方法，可以从目标语音中提取丰富的说话风格信息，并将其高效地传递给源语音内容，不需要文本转录或说话者标注。我们的提议方法使用一种自然语言学习（SSL）模型来收集目标说话者每个不同的phonetic content对应的说话风格。这些风格被表示为一组叫做“stylebook”的嵌入。在下一步，stylebook与源语音的phonetic content进行 attended，以确定每个源内容的最终目标风格。最后，来自源语音的内容信息和内容相关的目标风格嵌入被 fed into一个扩散型生成模型，以生成转换后的语音mel-spectrogram。实验结果表明，我们的提议方法与扩散型生成模型相结合可以在任意到任意语音转换任务中实现更好的说话者相似性，而与 longer utterances 相比，计算复杂性的增加被抑制。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-for-Automated-Open-domain-Scientific-Hypotheses-Discovery"><a href="#Large-Language-Models-for-Automated-Open-domain-Scientific-Hypotheses-Discovery" class="headerlink" title="Large Language Models for Automated Open-domain Scientific Hypotheses Discovery"></a>Large Language Models for Automated Open-domain Scientific Hypotheses Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02726">http://arxiv.org/abs/2309.02726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zongliny/moose">https://github.com/zongliny/moose</a></li>
<li>paper_authors: Zonglin Yang, Xinya Du, Junxian Li, Jie Zheng, Soujanya Poria, Erik Cambria</li>
<li>for: 本研究旨在开发一种自动生成有效、新颖、有用的社会科学学术假设探索系统，需要使用原始网络 Corpora 作为观察数据，并提出新的假设，以便为人类研究者提供帮助。</li>
<li>methods: 本研究使用了一种多模块框架，以及三种不同的反馈机制，以提高系统的性能。</li>
<li>results: 研究发现，使用这些反馈机制可以使系统表现出较高的性能，包括使用 GPT-4 基于评估和社会科学专家评估。<details>
<summary>Abstract</summary>
Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction has a limited setting that (1) the observation annotations of the dataset are not raw web corpus but are manually selected sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses annotations are mostly commonsense knowledge, making the task less challenging. In this work, we propose the first NLP dataset for social science academic hypotheses discovery, consisting of 50 recent papers published in top social science journals. Raw web corpora that are necessary for developing hypotheses in the published papers are also collected in the dataset, with the final goal of creating a system that automatically generates valid, novel, and helpful (to human researchers) hypotheses, given only a pile of raw web corpora. The new dataset can tackle the previous problems because it requires to (1) use raw web corpora as observations; and (2) propose hypotheses even new to humanity. A multi-module framework is developed for the task, as well as three different feedback mechanisms that empirically show performance gain over the base framework. Finally, our framework exhibits high performance in terms of both GPT-4 based evaluation and social science expert evaluation.
</details>
<details>
<summary>摘要</summary>
traducción al chino simplificado:推测induction被认为是科学家当中主要的理解类型，当他们观察世界并尝试提出解释这些观察结果。过去关于推测induction的研究有限制的设置，包括（1）数据集的观察注释不是 Raw web corpus，而是 manually selected sentences（导致close-domain setting）;和（2）人类常识的ground truth假设注释，使任务更加容易。在这项工作中，我们提出了首个社会科学学报上的NLP数据集，包括最近50篇发表在首屈社会科学期刊上的论文。 Raw web corpus，用于在发表论文中发展假设，也被收集到数据集中，最终目标是创建一个可以自动生成有效、新、有用（ для人类研究者）假设，只需要一堆 Raw web corpus。新数据集可以解决以前的问题，因为它需要（1）使用Raw web corpus作为观察;和（2）提出人类未知的假设。我们开发了一个多模块框架，以及三种不同的反馈机制，实际证明了对基础框架的性能提升。最终，我们的框架在GPT-4基于评估和社会科学专家评估中都表现出高性能。
</details></li>
</ul>
<hr>
<h2 id="Offensive-Hebrew-Corpus-and-Detection-using-BERT"><a href="#Offensive-Hebrew-Corpus-and-Detection-using-BERT" class="headerlink" title="Offensive Hebrew Corpus and Detection using BERT"></a>Offensive Hebrew Corpus and Detection using BERT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02724">http://arxiv.org/abs/2309.02724</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sinalab/offensivehebrew">https://github.com/sinalab/offensivehebrew</a></li>
<li>paper_authors: Nagham Hamad, Mustafa Jarrar, Mohammad Khalilia, Nadim Nashif</li>
<li>For: The paper is written for offensive language detection in Hebrew, specifically for low-resource languages.* Methods: The paper uses a new offensive language corpus in Hebrew, which consists of 15,881 tweets labeled with one or more of five classes (abusive, hate, violence, pornographic, or none offensive). The authors fine-tuned two Hebrew BERT models, HeBERT and AlephBERT, using their proposed dataset and another published dataset.* Results: The authors observed that their data boosts HeBERT performance by 2% when combined with D_OLaH, and fine-tuning AlephBERT on their data and testing on D_OLaH yields 69% accuracy. They also found that fine-tuning on D_OLaH and testing on their data yields 57% accuracy, which may indicate the generalizability of their data.Here’s the simplified Chinese text for the three key points:* 为：本文关注希伯来语中的不当语言检测，尤其是对于低资源语言。* 方法：本文使用一个新的希伯来语不当语言集，包含15,881条推特消息，每个消息被标记为一个或多个五种类别（不当、仇恨、暴力、色情或无不当）。作者使用了一种新的Annotation process，每个注释者需要熟悉以色列文化、政治和实践，以理解每条消息的上下文。* 结果：作者发现，将HeBERT模型在他们的数据集上进行微调，并与D_OLaH进行组合，可以提高HeBERT模型的性能 by 2%。此外，对AlephBERT模型进行微调，并测试在D_OLaH上，可以达到69%的准确率。此外，将模型微调在D_OLaH上，并测试在他们的数据集上，可以达到57%的准确率，这可能是数据的普适性的证明。<details>
<summary>Abstract</summary>
Offensive language detection has been well studied in many languages, but it is lagging behind in low-resource languages, such as Hebrew. In this paper, we present a new offensive language corpus in Hebrew. A total of 15,881 tweets were retrieved from Twitter. Each was labeled with one or more of five classes (abusive, hate, violence, pornographic, or none offensive) by Arabic-Hebrew bilingual speakers. The annotation process was challenging as each annotator is expected to be familiar with the Israeli culture, politics, and practices to understand the context of each tweet. We fine-tuned two Hebrew BERT models, HeBERT and AlephBERT, using our proposed dataset and another published dataset. We observed that our data boosts HeBERT performance by 2% when combined with D_OLaH. Fine-tuning AlephBERT on our data and testing on D_OLaH yields 69% accuracy, while fine-tuning on D_OLaH and testing on our data yields 57% accuracy, which may be an indication to the generalizability our data offers. Our dataset and fine-tuned models are available on GitHub and Huggingface.
</details>
<details>
<summary>摘要</summary>
“对粗语言探测已经在许多语言中得到了很好的研究，但是在低资源语言中，例如希伯来语，则落后了。在这篇论文中，我们提供了一个新的希伯来语粗语言数据库。总共从Twitter上获取了15,881则短讯，每则短讯都被标注为一个或多个五种类别（不尊重、仇恨、暴力、色情或无不尊重）由阿拉伯语-希伯来语双语话者标注。标注过程是具有挑战性的，因为每个标注者须熟悉以色列文化、政治和实践来理解每则短讯的背景。我们精确地调整了两个希伯来BERT模型（HeBERT和AlephBERT），使用我们提出的资料集和另一个已发布的资料集。我们发现，当我们的数据与D_OLaH进行调整时，HeBERT的性能提高了2%。精确地调整AlephBERT使用我们的数据和D_OLaH，测试时的准确率为69%，而精确地调整AlephBERT使用D_OLaH，然后测试使用我们的数据，则为57%，这可能是我们数据的一般化性的证明。我们的资料集和调整后的模型在GitHub和Huggingface上可用。”
</details></li>
</ul>
<hr>
<h2 id="SlAction-Non-intrusive-Lightweight-Obstructive-Sleep-Apnea-Detection-using-Infrared-Video"><a href="#SlAction-Non-intrusive-Lightweight-Obstructive-Sleep-Apnea-Detection-using-Infrared-Video" class="headerlink" title="SlAction: Non-intrusive, Lightweight Obstructive Sleep Apnea Detection using Infrared Video"></a>SlAction: Non-intrusive, Lightweight Obstructive Sleep Apnea Detection using Infrared Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02713">http://arxiv.org/abs/2309.02713</a></li>
<li>repo_url: None</li>
<li>paper_authors: You Rim Choi, Gyeongseon Eo, Wonhyuck Youn, Hyojin Lee, Haemin Jang, Dongyoon Kim, Hyunwoo Shin, Hyung-Sin Kim</li>
<li>for: 该论文目的是检测呼吸暂停睡眠（OSA），以提供早期检测和个性化治疗的可能性。</li>
<li>methods: 该论文使用了非侵入式的视频检测技术，使用红外视频记录sleep environment，并使用低帧率、大小和步长的静止窗口分析方法来捕捉睡眠中呼吸事件的变化。</li>
<li>results: 论文的实验结果显示，SlAction可以在不同的睡眠环境中达到87.6%的准确率，并且可以在实时进行检测（~3秒钟），这表明SlAction有potential用于早期检测和个性化治疗OSA。<details>
<summary>Abstract</summary>
Obstructive sleep apnea (OSA) is a prevalent sleep disorder affecting approximately one billion people world-wide. The current gold standard for diagnosing OSA, Polysomnography (PSG), involves an overnight hospital stay with multiple attached sensors, leading to potential inaccuracies due to the first-night effect. To address this, we present SlAction, a non-intrusive OSA detection system for daily sleep environments using infrared videos. Recognizing that sleep videos exhibit minimal motion, this work investigates the fundamental question: "Are respiratory events adequately reflected in human motions during sleep?" Analyzing the largest sleep video dataset of 5,098 hours, we establish correlations between OSA events and human motions during sleep. Our approach uses a low frame rate (2.5 FPS), a large size (60 seconds) and step (30 seconds) for sliding window analysis to capture slow and long-term motions related to OSA. Furthermore, we utilize a lightweight deep neural network for resource-constrained devices, ensuring all video streams are processed locally without compromising privacy. Evaluations show that SlAction achieves an average F1 score of 87.6% in detecting OSA across various environments. Implementing SlAction on NVIDIA Jetson Nano enables real-time inference (~3 seconds for a 60-second video clip), highlighting its potential for early detection and personalized treatment of OSA.
</details>
<details>
<summary>摘要</summary>
扑杀性睡眠呼吸暂停综合症（OSA）是全球范围内一种普遍的睡眠疾病，影响约10亿人。现有的黄金标准 dla OSA 诊断，多somnography（PSG），需要在医院住一夜，并attach多个传感器，可能导致首夜效应，从而影响准确性。为了解决这个问题，我们提出了SlAction，一种不侵入的OSA检测系统，用于日常睡眠环境中。我们问题是：“睡眠视频中的呼吸事件是否能够准确地反映在人体动作中？”通过分析了5098小时的睡眠视频数据，我们发现了OSA事件和人体动作之间的相关性。我们的方法使用低帧率（2.5 FPS）、大小（60秒）和步长（30秒）的滑动窗口分析，以捕捉睡眠中的慢速和长期动作。此外，我们使用轻量级的深度神经网络，确保在资源有限的设备上进行本地处理，并保持隐私。我们的评估表明，SlAction在不同环境中的OSA检测精度为87.6%。通过在NVIDIA Jetson Nano上实现SlAction，我们可以在实时（大约3秒）进行60秒视频剪辑，这表明SlAction在早期检测和个性化治疗OSA方面具有潜在的潜力。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-frontiers-of-deep-learning-innovations-shaping-diverse-domains"><a href="#Unveiling-the-frontiers-of-deep-learning-innovations-shaping-diverse-domains" class="headerlink" title="Unveiling the frontiers of deep learning: innovations shaping diverse domains"></a>Unveiling the frontiers of deep learning: innovations shaping diverse domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02712">http://arxiv.org/abs/2309.02712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shams Forruque Ahmed, Md. Sakib Bin Alam, Maliha Kabir, Shaila Afrin, Sabiha Jannat Rafa, Aanushka Mehjabin, Amir H. Gandomi</li>
<li>for: 探讨深度学习在各个领域的应用和挑战</li>
<li>methods: 使用深度学习模型进行预测和分析，并且可以自适应和优化数据</li>
<li>results: 深度学习在各个领域都有精度的预测和分析结果，但需要大量数据进行有效处理和分析<details>
<summary>Abstract</summary>
Deep learning (DL) enables the development of computer models that are capable of learning, visualizing, optimizing, refining, and predicting data. In recent years, DL has been applied in a range of fields, including audio-visual data processing, agriculture, transportation prediction, natural language, biomedicine, disaster management, bioinformatics, drug design, genomics, face recognition, and ecology. To explore the current state of deep learning, it is necessary to investigate the latest developments and applications of deep learning in these disciplines. However, the literature is lacking in exploring the applications of deep learning in all potential sectors. This paper thus extensively investigates the potential applications of deep learning across all major fields of study as well as the associated benefits and challenges. As evidenced in the literature, DL exhibits accuracy in prediction and analysis, makes it a powerful computational tool, and has the ability to articulate itself and optimize, making it effective in processing data with no prior training. Given its independence from training data, deep learning necessitates massive amounts of data for effective analysis and processing, much like data volume. To handle the challenge of compiling huge amounts of medical, scientific, healthcare, and environmental data for use in deep learning, gated architectures like LSTMs and GRUs can be utilized. For multimodal learning, shared neurons in the neural network for all activities and specialized neurons for particular tasks are necessary.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）允许开发计算机模型，能够学习、可视化、优化、修剪和预测数据。近年来，DL在各种领域应用，如音视频数据处理、农业、交通预测、自然语言、生物医学、灾害管理、生物信息学、药物设计、 genomics、人脸识别和生态学。为了探讨深度学习的当前状况，需要调查最新的发展和应用在这些领域。然而，文献缺乏探讨深度学习在所有领域的应用。这篇论文因此进行了广泛的调查，探讨了深度学习在所有主要领域的可能应用，以及相关的优势和挑战。根据文献显示，DL在预测和分析中表现出了准确性，使其成为计算机科学中的 poderoso工具。DL的独立性使得它可以处理没有前期训练的数据，需要大量数据进行有效的分析和处理，类似于数据量。为了处理巨量数据的挑战，可以使用门控架构如LSTM和GRU。为多模态学习，共享 neurons 在神经网络中为所有活动和特定任务的专门 neurons 是必要的。
</details></li>
</ul>
<hr>
<h2 id="Addressing-Imperfect-Symmetry-a-Novel-Symmetry-Learning-Actor-Critic-Extension"><a href="#Addressing-Imperfect-Symmetry-a-Novel-Symmetry-Learning-Actor-Critic-Extension" class="headerlink" title="Addressing Imperfect Symmetry: a Novel Symmetry-Learning Actor-Critic Extension"></a>Addressing Imperfect Symmetry: a Novel Symmetry-Learning Actor-Critic Extension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02711">http://arxiv.org/abs/2309.02711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/m-abr/Adaptive-Symmetry-Learning">https://github.com/m-abr/Adaptive-Symmetry-Learning</a></li>
<li>paper_authors: Miguel Abreu, Luis Paulo Reis, Nuno Lau</li>
<li>for: 本研究旨在捕捉人类在完美对称任务中的偏差和认知偏见（如有一个主导手），并通过使用强化学习来捕捉人类大脑对symmetry的能力。</li>
<li>methods: 本研究提出了一种名为自适应对称学习（ASL）的模型简化actor-critic扩展，可以在学习过程中适应不完全或不准确的对称描述，并在学习策略时保持共同的对称关系。ASL包括对称适应组件和模块化损失函数。</li>
<li>results: 对比现有的对称强化方法，ASL在四脚蚂蚁多向运动任务中表现出优于或相等于其他方法的性能，能够恢复大幅偏差和泛化知识到隐藏的对称状态。<details>
<summary>Abstract</summary>
Symmetry, a fundamental concept to understand our environment, often oversimplifies reality from a mathematical perspective. Humans are a prime example, deviating from perfect symmetry in terms of appearance and cognitive biases (e.g. having a dominant hand). Nevertheless, our brain can easily overcome these imperfections and efficiently adapt to symmetrical tasks. The driving motivation behind this work lies in capturing this ability through reinforcement learning. To this end, we introduce Adaptive Symmetry Learning (ASL) $\unicode{x2013}$ a model-minimization actor-critic extension that addresses incomplete or inexact symmetry descriptions by adapting itself during the learning process. ASL consists of a symmetry fitting component and a modular loss function that enforces a common symmetric relation across all states while adapting to the learned policy. The performance of ASL is compared to existing symmetry-enhanced methods in a case study involving a four-legged ant model for multidirectional locomotion tasks. The results demonstrate that ASL is capable of recovering from large perturbations and generalizing knowledge to hidden symmetric states. It achieves comparable or better performance than alternative methods in most scenarios, making it a valuable approach for leveraging model symmetry while compensating for inherent perturbations.
</details>
<details>
<summary>摘要</summary>
“同调性”是我们理解环境的基本概念，却常以数学角度简化现实。人类是一个好例子，在外表和认知偏袋（例如有主要手）方面都不寻常。然而，我们的大脑可以轻松超越这些不完整性，并专注于symmetric task中的效率。这个工作的驱动力是通过强化学习来捕捉这个能力。为此，我们介绍了一个名为“adaptive symmetry learning”的model-minimization actor-critic扩展。ASL包括一个对称适摄Component和一个模块损失函数，这些函数在学习政策时适应对称关系。我们在一个四脚蚂蚁模型中进行多向运动任务的case study中评估了ASL的表现。结果显示ASL可以从大的干扰中恢复和获得隐藏的对称状态的知识。它在大多数情况下与其他方法相比，能够获得相似或更好的表现，因此成为一种有价的方法来利用模型的对称性，并对于内在的干扰进行补偿。
</details></li>
</ul>
<hr>
<h2 id="Certifying-LLM-Safety-against-Adversarial-Prompting"><a href="#Certifying-LLM-Safety-against-Adversarial-Prompting" class="headerlink" title="Certifying LLM Safety against Adversarial Prompting"></a>Certifying LLM Safety against Adversarial Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02705">http://arxiv.org/abs/2309.02705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Soheil Feizi, Hima Lakkaraju</li>
<li>for: 防止语言模型生成危险内容，通过检查输入提示的安全性。</li>
<li>methods: 使用“erase-and-check”框架，通过擦除提示中的单个字符，并使用安全筛选器进行检查，以保证输入提示的安全性。</li>
<li>results: 对于 adversarial suffix、insertion和infusion三种攻击方式，“erase-and-check”框架可以提供强有保证的安全性保证，同时在安全提示上保持良好的性能。例如，对于 adversarial suffix 长度为 20，可以 certificatively 检测93%的危险提示，并将94%的安全提示标记为安全。<details>
<summary>Abstract</summary>
Large language models (LLMs) released for public use incorporate guardrails to ensure their output is safe, often referred to as "model alignment." An aligned language model should decline a user's request to produce harmful content. However, such safety measures are vulnerable to adversarial prompts, which contain maliciously designed token sequences to circumvent the model's safety guards and cause it to produce harmful content. In this work, we introduce erase-and-check, the first framework to defend against adversarial prompts with verifiable safety guarantees. We erase tokens individually and inspect the resulting subsequences using a safety filter. Our procedure labels the input prompt as harmful if any subsequences or the input prompt are detected as harmful by the filter. This guarantees that any adversarial modification of a harmful prompt up to a certain size is also labeled harmful. We defend against three attack modes: i) adversarial suffix, which appends an adversarial sequence at the end of the prompt; ii) adversarial insertion, where the adversarial sequence is inserted anywhere in the middle of the prompt; and iii) adversarial infusion, where adversarial tokens are inserted at arbitrary positions in the prompt, not necessarily as a contiguous block. Empirical results demonstrate that our technique obtains strong certified safety guarantees on harmful prompts while maintaining good performance on safe prompts. For example, against adversarial suffixes of length 20, it certifiably detects 93% of the harmful prompts and labels 94% of the safe prompts as safe using the open source language model Llama 2 as the safety filter.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）发布 для公共使用都会包括安全保护，通常称为“模型Alignment”。一个平衡化的语言模型应该拒绝用户的请求生成伤害性内容。然而，这些安全措施可能会受到攻击性的提示，这些提示可能会使模型生成伤害性内容。在这个工作中，我们介绍了“抹除和检查”，是第一个对抗攻击性提示的安全保证框架。我们将单独抹除token，并使用一个安全范 filter 来检查结果。如果任何 subsequences 或输入提示被识别为伤害的，我们就将该提示识别为伤害的。这 garanties 任何攻击性提示的修改，都会被识别为伤害的，并且最多可以是一定长度的攻击性提示。我们防止了三种攻击模式：i）攻击 suffix，将攻击性序列 append 到提示的结尾; ii）攻击插入，将攻击性序列插入提示的任何中间位置; iii）攻击混合，将攻击 Token 插入提示的任何位置，不一定是一个连续的对。我们的技术在伤害提示上获得了强大的认证安全保证，同时保持了良好的性能在安全提示上。例如，对于攻击 suffix 的长度为 20，我们可以认证地检测 93% 的伤害提示，并将 94% 的安全提示识别为安全使用 LLama 2 作为安全范 filter。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-EDFs-Bi-equivariant-Denoising-Generative-Modeling-on-SE-3-for-Visual-Robotic-Manipulation"><a href="#Diffusion-EDFs-Bi-equivariant-Denoising-Generative-Modeling-on-SE-3-for-Visual-Robotic-Manipulation" class="headerlink" title="Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation"></a>Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02685">http://arxiv.org/abs/2309.02685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tomato1mule/diffusion_edf">https://github.com/tomato1mule/diffusion_edf</a></li>
<li>paper_authors: Hyunwoo Ryu, Jiwoo Kim, Junwoo Chang, Hyun Seok Ahn, Joohwan Seo, Taehan Kim, Yubin Kim, Jongeun Choi, Roberto Horowitz</li>
<li>for: 本研究旨在提高机器人学习的数据效率、通用性和稳定性，通过在扩散生成模型中 интеGRATE spatial roto-translation equivariance（SE(3)-equivariance）。</li>
<li>methods: 本文提出了一种新的Diffusion-EDFs方法，通过在模型架构中 интеGRATE SE(3)-equivariance，实现了很好的数据效率，只需5到10个任务示范来实现终端培训。</li>
<li>results: 我们的方法在比较 diffusion-based manipulation方法时显示出了superior的通用性。<details>
<summary>Abstract</summary>
Recent studies have verified that equivariant methods can significantly improve the data efficiency, generalizability, and robustness in robot learning. Meanwhile, denoising diffusion-based generative modeling has recently gained significant attention as a promising approach for robotic manipulation learning from demonstrations with stochastic behaviors. In this paper, we present Diffusion-EDFs, a novel approach that incorporates spatial roto-translation equivariance, i.e., SE(3)-equivariance to diffusion generative modeling. By integrating SE(3)-equivariance into our model architectures, we demonstrate that our proposed method exhibits remarkable data efficiency, requiring only 5 to 10 task demonstrations for effective end-to-end training. Furthermore, our approach showcases superior generalizability compared to previous diffusion-based manipulation methods.
</details>
<details>
<summary>摘要</summary>
Recent studies have confirmed that equivariant methods can significantly improve data efficiency, generalizability, and robustness in robot learning. Meanwhile, denoising diffusion-based generative modeling has recently gained significant attention as a promising approach for robotic manipulation learning from demonstrations with stochastic behaviors. In this paper, we propose Diffusion-EDFs, a novel approach that incorporates spatial roto-translation equivariance, i.e., SE(3)-equivariance into diffusion generative modeling. By integrating SE(3)-equivariance into our model architectures, we demonstrate that our proposed method exhibits remarkable data efficiency, requiring only 5 to 10 task demonstrations for effective end-to-end training. Furthermore, our approach showcases superior generalizability compared to previous diffusion-based manipulation methods.Note:* "Recent studies" is translated as "近期研究" (jìn qī yán jí)* "equivariancy" is translated as "对称性" (duì xiàng xìng)* "denoising diffusion-based generative modeling" is translated as "减噪扩散生成模型" (jiǎn shēng kuò chǎn shēng chéng yì)* "SE(3)-equivariance" is translated as "SE(3)对称性" (SE(3) duì xiàng xìng)* "spatial roto-translation equivariance" is translated as "空间旋转翻译对称性" (kōng jiān zhòu zhù yǐng duì xiàng xìng)* "diffusion generative modeling" is translated as "扩散生成模型" (kuò chǎn shēng chéng yì)* "task demonstrations" is translated as "任务示例" (tâi yì zhèng yè)* "generalizability" is translated as "通用性" (tōng yòng xìng)
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Contrastive-Self-Supervised-Learning-for-POI-level-Crowd-Flow-Inference"><a href="#Spatio-Temporal-Contrastive-Self-Supervised-Learning-for-POI-level-Crowd-Flow-Inference" class="headerlink" title="Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd Flow Inference"></a>Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd Flow Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03239">http://arxiv.org/abs/2309.03239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songyu Ke, Ting Li, Li Song, Yanping Sun, Qintian Sun, Junbo Zhang, Yu Zheng</li>
<li>for: 这种研究的目的是为了准确地掌握城市流动人口，以便更好地管理交通、公共服务和城市规划。</li>
<li>methods: 这种研究使用了自我超vised attributed graph representation learning技术，并引入了一种新的对比自学习框架（CSST）来处理缺乏标注数据的问题。</li>
<li>results: 实验表明，使用CSST预训练模型，可以在两个实际数据集上 consistently 超过从scratch 训练的模型。<details>
<summary>Abstract</summary>
Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal for effective traffic management, public service, and urban planning. Despite this importance, due to the limitations of urban sensing techniques, the data quality from most sources is inadequate for monitoring crowd flow at each POI. This renders the inference of accurate crowd flow from low-quality data a critical and challenging task. The complexity is heightened by three key factors: 1) The scarcity and rarity of labeled data, 2) The intricate spatio-temporal dependencies among POIs, and 3) The myriad correlations between precise crowd flow and GPS reports.   To address these challenges, we recast the crowd flow inference problem as a self-supervised attributed graph representation learning task and introduce a novel Contrastive Self-learning framework for Spatio-Temporal data (CSST). Our approach initiates with the construction of a spatial adjacency graph founded on the POIs and their respective distances. We then employ a contrastive learning technique to exploit large volumes of unlabeled spatio-temporal data. We adopt a swapped prediction approach to anticipate the representation of the target subgraph from similar instances. Following the pre-training phase, the model is fine-tuned with accurate crowd flow data. Our experiments, conducted on two real-world datasets, demonstrate that the CSST pre-trained on extensive noisy data consistently outperforms models trained from scratch.
</details>
<details>
<summary>摘要</summary>
准确地获取人群流动的点位（POI）是城市管理、公共服务和城市规划等领域的关键。然而，由于城市感知技术的限制，大多数数据质量不够高，无法准确地监测POI上的人群流动。这使得从低质量数据中推断准确的人群流动成为一项重要和挑战性的任务。这些挑战来自于以下三个因素：1）罕见和罕见的标注数据的稀缺，2）POI之间的复杂的空间-时间关系，3）精度人群流动和GPS报告之间的多种相关性。为 Address these challenges, we recast the crowd flow inference problem as a self-supervised attributed graph representation learning task and introduce a novel Contrastive Self-learning framework for Spatio-Temporal data (CSST). Our approach begins with the construction of a spatial adjacency graph founded on the POIs and their respective distances. We then employ a contrastive learning technique to exploit large volumes of unlabeled spatio-temporal data. We adopt a swapped prediction approach to anticipate the representation of the target subgraph from similar instances. Following the pre-training phase, the model is fine-tuned with accurate crowd flow data. Our experiments, conducted on two real-world datasets, demonstrate that the CSST pre-trained on extensive noisy data consistently outperforms models trained from scratch.
</details></li>
</ul>
<hr>
<h2 id="RLSynC-Offline-Online-Reinforcement-Learning-for-Synthon-Completion"><a href="#RLSynC-Offline-Online-Reinforcement-Learning-for-Synthon-Completion" class="headerlink" title="RLSynC: Offline-Online Reinforcement Learning for Synthon Completion"></a>RLSynC: Offline-Online Reinforcement Learning for Synthon Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02671">http://arxiv.org/abs/2309.02671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frazier N. Baker, Ziqi Chen, Xia Ning<br>for: 这 paper 的目的是提出一种新的逆Synthesis方法，即RLSynC，可以帮助在 semi-template-based retrosynthesis 方法中完成 synthon。methods: RLSynC 使用一个 offline-online 强化学习方法，每个 synthon 都有一个代理，通过顺序进行行动来完成 synthon。 RLSynC 可以从 both offline 训练集和 online 交互中学习策略，以便探索新的反应空间。 RLSynC 使用一个前向合成模型来评估预测的反应物在合成产品中的可能性，从而导引action搜索。results: 对比之前的逆Synthesis方法，RLSynC 可以在 synthon 完成和 retrosynthesis 方面具有14.9% 和 14.0% 的提升。这表明RLSynC 在合成规划中具有潜在的应用价值。<details>
<summary>Abstract</summary>
Retrosynthesis is the process of determining the set of reactant molecules that can react to form a desired product. Semi-template-based retrosynthesis methods, which imitate the reverse logic of synthesis reactions, first predict the reaction centers in the products, and then complete the resulting synthons back into reactants. These methods enable necessary interpretability and high practical utility to inform synthesis planning. We develop a new offline-online reinforcement learning method RLSynC for synthon completion in semi-template-based methods. RLSynC assigns one agent to each synthon, all of which complete the synthons by conducting actions step by step in a synchronized fashion. RLSynC learns the policy from both offline training episodes and online interactions which allow RLSynC to explore new reaction spaces. RLSynC uses a forward synthesis model to evaluate the likelihood of the predicted reactants in synthesizing a product, and thus guides the action search. We compare RLSynC with the state-of-the-art retrosynthesis methods. Our experimental results demonstrate that RLSynC can outperform these methods with improvement as high as 14.9% on synthon completion, and 14.0% on retrosynthesis, highlighting its potential in synthesis planning.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Retrosynthesis is the process of determining the set of reactant molecules that can react to form a desired product. Semi-template-based retrosynthesis methods, which imitate the reverse logic of synthesis reactions, first predict the reaction centers in the products, and then complete the resulting synthons back into reactants. These methods enable necessary interpretability and high practical utility to inform synthesis planning. We develop a new offline-online reinforcement learning method RLSynC for synthon completion in semi-template-based methods. RLSynC assigns one agent to each synthon, all of which complete the synthons by conducting actions step by step in a synchronized fashion. RLSynC learns the policy from both offline training episodes and online interactions which allow RLSynC to explore new reaction spaces. RLSynC uses a forward synthesis model to evaluate the likelihood of the predicted reactants in synthesizing a product, and thus guides the action search. We compare RLSynC with the state-of-the-art retrosynthesis methods. Our experimental results demonstrate that RLSynC can outperform these methods with improvement as high as 14.9% on synthon completion, and 14.0% on retrosynthesis, highlighting its potential in synthesis planning."Translation:这是一个逐步的过程，用于决定具有创建所需产品的化学物质的集合。使用半模板基的逆合成方法，首先预测产品中的反应中心，然后将结果转换回到底物。这些方法具有实用的可行性和解释性，以帮助合成观察。我们开发了一种新的线上-线下强化学习方法RLSynC，用于实对这些方法的完成。RLSynC将一个代理人分配到每个实体，这些代理人逐步完成实体，并在同步化的方式下进行动作搜索。RLSynC从线上训练集和线上互动中学习策略，这 permet RLSynC 探索新的反应空间。RLSynC 使用一个前方合成模型来评估预测的底物是否可以合成产品，因此导引动作搜索。我们与现有的逆合成方法进行比较。我们的实验结果表明，RLSynC 可以与现有的方法相比，在实体完成和逆合成方面提高改善率高达14.9%和14.0%。这 highlights RLSynC 的潜在在合成观察。
</details></li>
</ul>
<hr>
<h2 id="Subsethood-Measures-of-Spatial-Granules"><a href="#Subsethood-Measures-of-Spatial-Granules" class="headerlink" title="Subsethood Measures of Spatial Granules"></a>Subsethood Measures of Spatial Granules</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02662">http://arxiv.org/abs/2309.02662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liquan Zhao, Yiyu Yao</li>
<li>for: 这篇论文主要针对的是掌握复杂的信息系统中的知识空间和知识结构，并通过粗化集合论和空间粗化集合论来描述这些知识空间和知识结构。</li>
<li>methods: 该论文使用了粗化集合论和空间粗化集合论来描述知识空间和知识结构，并提出了一种基于 conditional granularity 和 conditional fineness 的推理模型。</li>
<li>results: 该论文的研究结果包括提出了十二个笃设增减子集 axioms 和其对应的十二个笃设增减超集 axioms，以及五种 conditional granularity 度量和五种 conditional fineness 度量。这些度量都满足了其对应的笃设增减子集 axioms，但只有一个 boundary condition。此外，该论文还定义了五种 conditional granularity 熵和五种 conditional fineness 熵。<details>
<summary>Abstract</summary>
Subsethood, which is to measure the degree of set inclusion relation, is predominant in fuzzy set theory. This paper introduces some basic concepts of spatial granules, coarse-fine relation, and operations like meet, join, quotient meet and quotient join. All the atomic granules can be hierarchized by set-inclusion relation and all the granules can be hierarchized by coarse-fine relation. Viewing an information system from the micro and the macro perspectives, we can get a micro knowledge space and a micro knowledge space, from which a rough set model and a spatial rough granule model are respectively obtained. The classical rough set model is the special case of the rough set model induced from the micro knowledge space, while the spatial rough granule model will be play a pivotal role in the problem-solving of structures. We discuss twelve axioms of monotone increasing subsethood and twelve corresponding axioms of monotone decreasing supsethood, and generalize subsethood and supsethood to conditional granularity and conditional fineness respectively. We develop five conditional granularity measures and five conditional fineness measures and prove that each conditional granularity or fineness measure satisfies its corresponding twelve axioms although its subsethood or supsethood measure only hold one of the two boundary conditions. We further define five conditional granularity entropies and five conditional fineness entropies respectively, and each entropy only satisfies part of the boundary conditions but all the ten monotone conditions.
</details>
<details>
<summary>摘要</summary>
“subsethood”，用于量度集合关系的度量，在模糊集合论中具有先锋性。本文介绍了一些基本概念，包括空间格粒、粗糙关系、会议、合并、对应关系和粗糙关系等。所有的格粒都可以归类为集合包含关系中的层次结构，而所有的格粒都可以归类为粗糙关系中的层次结构。从微观和macro two perspectives，我们可以从 informationspace 中获得一个微观知识空间和一个macro知识空间，从而获得一个粗糙集合模型和一个空间粗糙格粒模型。classical rough set model 是微观知识空间中粗糙集合模型的特殊情况，而空间粗糙格粒模型将在结构问题中发挥重要的作用。我们讨论了12个升递条件和12个降递条件，并将subsethood和supersethood扩展到 conditional granularity 和 conditional fineness 。我们开发了5个 conditional granularity 度量和5个 conditional fineness 度量，并证明每个 conditional granularity 或 conditional fineness 度量都遵循其所对应的12个条件，即使它们的subsethood 或 supersethood 度量只满足一个边界条件。我们进一步定义5个 conditional granularity 熵和5个 conditional fineness 熵，每个熵只遵循一部分边界条件，但是所有的10个升递条件。
</details></li>
</ul>
<hr>
<h2 id="TFBEST-Dual-Aspect-Transformer-with-Learnable-Positional-Encoding-for-Failure-Prediction"><a href="#TFBEST-Dual-Aspect-Transformer-with-Learnable-Positional-Encoding-for-Failure-Prediction" class="headerlink" title="TFBEST: Dual-Aspect Transformer with Learnable Positional Encoding for Failure Prediction"></a>TFBEST: Dual-Aspect Transformer with Learnable Positional Encoding for Failure Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02641">http://arxiv.org/abs/2309.02641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rohan Mohapatra, Saptarshi Sengupta</li>
<li>for: 预测硬盘失效，避免数据损失和公司形象问题。</li>
<li>methods: 使用Self-Monitoring, Analysis and Reporting Technology（S.M.A.R.T）logs和一种新的transformer架构——Temporal-fusion Bi-encoder Self-attention Transformer（TFBEST）进行预测。</li>
<li>results: 比 estado-of-the-art RUL 预测方法更高的准确率，并提供了一种新的信任度 estadística来帮助制造商在一定时间内更换硬盘。<details>
<summary>Abstract</summary>
Hard Disk Drive (HDD) failures in datacenters are costly - from catastrophic data loss to a question of goodwill, stakeholders want to avoid it like the plague. An important tool in proactively monitoring against HDD failure is timely estimation of the Remaining Useful Life (RUL). To this end, the Self-Monitoring, Analysis and Reporting Technology employed within HDDs (S.M.A.R.T.) provide critical logs for long-term maintenance of the security and dependability of these essential data storage devices. Data-driven predictive models in the past have used these S.M.A.R.T. logs and CNN/RNN based architectures heavily. However, they have suffered significantly in providing a confidence interval around the predicted RUL values as well as in processing very long sequences of logs. In addition, some of these approaches, such as those based on LSTMs, are inherently slow to train and have tedious feature engineering overheads. To overcome these challenges, in this work we propose a novel transformer architecture - a Temporal-fusion Bi-encoder Self-attention Transformer (TFBEST) for predicting failures in hard-drives. It is an encoder-decoder based deep learning technique that enhances the context gained from understanding health statistics sequences and predicts a sequence of the number of days remaining before a disk potentially fails. In this paper, we also provide a novel confidence margin statistic that can help manufacturers replace a hard-drive within a time frame. Experiments on Seagate HDD data show that our method significantly outperforms the state-of-the-art RUL prediction methods during testing over the exhaustive 10-year data from Backblaze (2013-present). Although validated on HDD failure prediction, the TFBEST architecture is well-suited for other prognostics applications and may be adapted for allied regression problems.
</details>
<details>
<summary>摘要</summary>
硬盘驱动器（HDD）在数据中心失效的情况非常昂贵，从惨重的数据损失到对客户的信誉受到影响，各方希望避免这种情况。为了执行前置监测，评估硬盘的剩下有用生命（RUL）是非常重要的。为此，硬盘内部的自我监测、分析和报告技术（S.M.A.R.T）提供了关键的日志记录，以长期维护硬盘的安全性和可靠性。过去的数据驱动预测模型使用了这些S.M.A.R.T.日志和卷积神经网络（CNN/RNN）结构，但它们在提供预测RUL值的置信度范围以及处理非常长的日志序列时受到了重大的挑战。此外，一些这些方法，如基于LSTM的方法，在训练过程中具有慢速的特点和繁琐的特征工程过程。为了解决这些挑战，我们在这种工作中提出了一种新的 transformer 架构——时间融合二元自注意 transformer（TFBEST），用于预测硬盘失效。这是一种基于Encoder-Decoder的深度学习技术，它在理解医疗统计序列中的上下文中提高了硬盘的健康统计序列，并预测硬盘失效的序列。在这篇论文中，我们还提出了一种新的置信度范围统计，可以帮助制造商在一定的时间内替换硬盘。实验结果表明，我们的方法在测试过程中对Backblaze（2013-present）的10年数据进行了显著的性能提升，至于RUL预测方面。尽管验证在硬盘失效预测方面，但TFBEST架构适用于其他预测应用程序，可以适应相关的回归问题。
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-from-Hierarchical-Weak-Preference-Feedback"><a href="#Deep-Reinforcement-Learning-from-Hierarchical-Weak-Preference-Feedback" class="headerlink" title="Deep Reinforcement Learning from Hierarchical Weak Preference Feedback"></a>Deep Reinforcement Learning from Hierarchical Weak Preference Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02632">http://arxiv.org/abs/2309.02632</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abukharin3/heron">https://github.com/abukharin3/heron</a></li>
<li>paper_authors: Alexander Bukharin, Yixiao Li, Pengcheng He, Weizhu Chen, Tuo Zhao</li>
<li>For: The paper is written for practical reinforcement learning (RL) tasks, specifically to address the challenges of reward engineering and the limitations of reinforcement learning from human feedback (RLHF).* Methods: The paper proposes a new RL framework called HERON, which uses a hierarchical decision tree to compare trajectories and train a preference-based reward model. The framework leverages human preference data to learn complex rewards that are well aligned with human preferences.* Results: The paper finds that the proposed HERON framework can train high-performing agents on a variety of difficult tasks, and provides additional benefits such as improved sample efficiency and robustness. The authors also provide a publicly available code implementation of the framework at <a target="_blank" rel="noopener" href="https://github.com/abukharin3/HERON.Here">https://github.com/abukharin3/HERON.Here</a> is the same information in Simplified Chinese text:* For: 论文是为实际的奖励学习（RL）任务写的，特别是解决奖励工程学（RLHF）中的挑战和限制。* Methods: 论文提出了一种新的RL框架called HERON，使用决策树来比较 trajectory 并训练一种基于偏好的奖励模型。该框架利用人类偏好数据来学习复杂的奖励，使RL能够更好地解决复杂的问题。* Results: 论文发现，提出的HERON框架可以训练高性能的代理人agent 在多种具有挑战性的任务上，并提供了更多的优点，如提高的样本效率和Robustness。作者还提供了一个公共可用的代码实现HERON的框架，可以在<a target="_blank" rel="noopener" href="https://github.com/abukharin3/HERON%E4%B8%AD%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/abukharin3/HERON中获取。</a><details>
<summary>Abstract</summary>
Reward design is a fundamental, yet challenging aspect of practical reinforcement learning (RL). For simple tasks, researchers typically handcraft the reward function, e.g., using a linear combination of several reward factors. However, such reward engineering is subject to approximation bias, incurs large tuning cost, and often cannot provide the granularity required for complex tasks. To avoid these difficulties, researchers have turned to reinforcement learning from human feedback (RLHF), which learns a reward function from human preferences between pairs of trajectory sequences. By leveraging preference-based reward modeling, RLHF learns complex rewards that are well aligned with human preferences, allowing RL to tackle increasingly difficult problems. Unfortunately, the applicability of RLHF is limited due to the high cost and difficulty of obtaining human preference data. In light of this cost, we investigate learning reward functions for complex tasks with less human effort; simply by ranking the importance of the reward factors. More specifically, we propose a new RL framework -- HERON, which compares trajectories using a hierarchical decision tree induced by the given ranking. These comparisons are used to train a preference-based reward model, which is then used for policy learning. We find that our framework can not only train high performing agents on a variety of difficult tasks, but also provide additional benefits such as improved sample efficiency and robustness. Our code is available at https://github.com/abukharin3/HERON.
</details>
<details>
<summary>摘要</summary>
практическое обучение с подкреплением (RL) 是一个基本 yet 挑战性的问题。  для简单任务，研究人员通常手工设计奖函数，例如使用一个线性组合多个奖因素。  however， Such reward engineering is subject to approximation bias, incurs large tuning cost, and often cannot provide the granularity required for complex tasks.  To avoid these difficulties, researchers have turned to reinforcement learning from human feedback (RLHF), which learns a reward function from human preferences between pairs of trajectory sequences. By leveraging preference-based reward modeling, RLHF learns complex rewards that are well aligned with human preferences, allowing RL to tackle increasingly difficult problems. Unfortunately, the applicability of RLHF is limited due to the high cost and difficulty of obtaining human preference data.在考虑这些成本的情况下，我们调查了一种新的RL框架——HERON，该框架通过一个层次决策树来比较方程。这些比较用于训练一个基于偏好的奖金模型，该模型然后用于策略学习。我们发现，我们的框架不仅可以训练高性能的代理人在多种具有挑战性的任务上，还可以提供其他优点，如提高样本效率和Robustness。我们的代码可以在https://github.com/abukharin3/HERON中找到。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/06/cs.AI_2023_09_06/" data-id="clmvt7t7o003t26rd5h7s8twx" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/06/cs.CL_2023_09_06/" class="article-date">
  <time datetime="2023-09-06T11:00:00.000Z" itemprop="datePublished">2023-09-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/06/cs.CL_2023_09_06/">cs.CL - 2023-09-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="RoDia-A-New-Dataset-for-Romanian-Dialect-Identification-from-Speech"><a href="#RoDia-A-New-Dataset-for-Romanian-Dialect-Identification-from-Speech" class="headerlink" title="RoDia: A New Dataset for Romanian Dialect Identification from Speech"></a>RoDia: A New Dataset for Romanian Dialect Identification from Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03378">http://arxiv.org/abs/2309.03378</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/codrut2/rodia">https://github.com/codrut2/rodia</a></li>
<li>paper_authors: Codrut Rotaru, Nicolae-Catalin Ristea, Radu Tudor Ionescu</li>
<li>for: 这个论文的目的是提供一个关于罗马尼亚语言方言识别的数据集，以便进一步研究罗马尼亚语言方言识别技术。</li>
<li>methods: 这个论文使用了一些竞争性的模型来进行罗马尼亚语言方言识别，包括一个基于语音特征的模型和一个基于文本特征的模型。</li>
<li>results: 根据 macro F1 分数，这个论文的最高分模型可以达到 59.83% 和 62.08%，表明这是一个有挑战性的任务。<details>
<summary>Abstract</summary>
Dialect identification is a critical task in speech processing and language technology, enhancing various applications such as speech recognition, speaker verification, and many others. While most research studies have been dedicated to dialect identification in widely spoken languages, limited attention has been given to dialect identification in low-resource languages, such as Romanian. To address this research gap, we introduce RoDia, the first dataset for Romanian dialect identification from speech. The RoDia dataset includes a varied compilation of speech samples from five distinct regions of Romania, covering both urban and rural environments, totaling 2 hours of manually annotated speech data. Along with our dataset, we introduce a set of competitive models to be used as baselines for future research. The top scoring model achieves a macro F1 score of 59.83% and a micro F1 score of 62.08%, indicating that the task is challenging. We thus believe that RoDia is a valuable resource that will stimulate research aiming to address the challenges of Romanian dialect identification. We publicly release our dataset and code at https://github.com/codrut2/RoDia.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT叙述语言识别是语音处理和语言科技领域中的一项关键任务，提高了各种应用，如语音识别、 speaker 验证等。而大多数研究都集中在普通语言上进行了叙述语言识别研究，对于低资源语言，如罗马尼亚语，则受到了少量关注。为了填补这个研究漏洞，我们介绍了 RoDia，罗马尼亚语言识别的首个数据集。RoDia 数据集包括来自罗马尼亚五个区域的语音采样，涵盖了城市和农村环境，总计两小时的手动标注的语音数据。同时，我们也提供了一组竞争力强的模型，用于未来研究的基线。最高分模型的macro F1分数为59.83%，微 F1分数为62.08%，这表明该任务是有挑战性的。因此，我们认为 RoDia 是一个有价值的资源，将激发研究者努力解决罗马尼亚语言识别的挑战。我们在 GitHub 上公开发布了数据集和代码，请参考 <https://github.com/codrut2/RoDia>。
</details></li>
</ul>
<hr>
<h2 id="Parameter-Efficient-Audio-Captioning-With-Faithful-Guidance-Using-Audio-text-Shared-Latent-Representation"><a href="#Parameter-Efficient-Audio-Captioning-With-Faithful-Guidance-Using-Audio-text-Shared-Latent-Representation" class="headerlink" title="Parameter Efficient Audio Captioning With Faithful Guidance Using Audio-text Shared Latent Representation"></a>Parameter Efficient Audio Captioning With Faithful Guidance Using Audio-text Shared Latent Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03340">http://arxiv.org/abs/2309.03340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arvind Krishna Sridhar, Yinyi Guo, Erik Visser, Rehana Mahfuz</li>
<li>for: 本研究旨在解决自动化音频captioning任务中的过参数和大型模型存储问题。</li>
<li>methods: 我们提出了一种数据增强技术，并使用 Shared latent space 来检测幻觉。我们还提出了一种 parameter efficient 的推理时 faithful decoding 算法，以降低模型的存储大小和计算复杂度。</li>
<li>results: 我们在标准测试集上证明了我们的方法可以 достичь与更大的模型相同的性能，同时具有较小的存储大小和计算复杂度。<details>
<summary>Abstract</summary>
There has been significant research on developing pretrained transformer architectures for multimodal-to-text generation tasks. Albeit performance improvements, such models are frequently overparameterized, hence suffer from hallucination and large memory footprint making them challenging to deploy on edge devices. In this paper, we address both these issues for the application of automated audio captioning. First, we propose a data augmentation technique for generating hallucinated audio captions and show that similarity based on an audio-text shared latent space is suitable for detecting hallucination. Then, we propose a parameter efficient inference time faithful decoding algorithm that enables smaller audio captioning models with performance equivalent to larger models trained with more data. During the beam decoding step, the smaller model utilizes an audio-text shared latent representation to semantically align the generated text with corresponding input audio. Faithful guidance is introduced into the beam probability by incorporating the cosine similarity between latent representation projections of greedy rolled out intermediate beams and audio clip. We show the efficacy of our algorithm on benchmark datasets and evaluate the proposed scheme against baselines using conventional audio captioning and semantic similarity metrics while illustrating tradeoffs between performance and complexity.
</details>
<details>
<summary>摘要</summary>
有很多研究在开发预训练变换器架构来进行多modal-to-text生成任务。虽然性能有所提高，但这些模型经常过参数，导致幻觉和巨大的内存占用，使其在边缘设备上部署困难。在这篇论文中，我们解决了这些问题，并将其应用于自动化音频captioning。我们首先提出了一种数据增强技术，通过生成幻觉的音频caption来检测幻觉。然后，我们提出了一种 parameter efficient的执行时 faithful decoding算法，允许更小的音频captioning模型，并且其性能与更多数据训练的更大模型相同。在扩散搜索步骤中，更小的模型使用音频-文本共同的幻像表示来 semantic align生成的文本和相应的输入音频。我们引入了cosine相似性来导引搜索步骤中的投票概率，以确保生成的文本具有与输入音频的Semantic相似性。我们在标准 datasets上证明了我们的算法的效果，并对基eline使用 conventient audio captioning和semantic相似度度量进行评估，同时示出了性能和复杂度之间的负责任。
</details></li>
</ul>
<hr>
<h2 id="Gender-specific-Machine-Translation-with-Large-Language-Models"><a href="#Gender-specific-Machine-Translation-with-Large-Language-Models" class="headerlink" title="Gender-specific Machine Translation with Large Language Models"></a>Gender-specific Machine Translation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03175">http://arxiv.org/abs/2309.03175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo Sánchez, Pierre Andrews, Pontus Stenetorp, Mikel Artetxe, Marta R. Costa-jussà</li>
<li>for:  investigate the use of Decoder-only Large Language Models (LLMs) for gender-specific translations</li>
<li>methods:  use LLaMa, a decoder-only LLM, to generate gender-specific translations and compare its performance to a state-of-the-art multilingual NMT system (NLLB)</li>
<li>results:  LLaMa can generate gender-specific translations with competitive accuracy and mitigate gender bias, and its translations are robust in gender-ambiguous datasets but less consistent in less ambiguous contexts.<details>
<summary>Abstract</summary>
Decoder-only Large Language Models (LLMs) have demonstrated potential in machine translation (MT), albeit with performance slightly lagging behind traditional encoder-decoder Neural Machine Translation (NMT) systems. However, LLMs offer a unique advantage: the ability to control the properties of the output through prompts. In this study, we harness this flexibility to explore LLaMa's capability to produce gender-specific translations for languages with grammatical gender. Our results indicate that LLaMa can generate gender-specific translations with competitive accuracy and gender bias mitigation when compared to NLLB, a state-of-the-art multilingual NMT system. Furthermore, our experiments reveal that LLaMa's translations are robust, showing significant performance drops when evaluated against opposite-gender references in gender-ambiguous datasets but maintaining consistency in less ambiguous contexts. This research provides insights into the potential and challenges of using LLMs for gender-specific translations and highlights the importance of in-context learning to elicit new tasks in LLMs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）只有decoder部分的实现在机器翻译（MT）中表现了潜在的优势，虽然其性能略为落后于传统的编码器-解码器神经机器翻译（NMT）系统。然而，LLM具有一个独特的优势：可以通过提示来控制输出的性质。在这项研究中，我们利用这种灵活性来探索LLaMa的可能性以生成语言中 grammatical gender 的 gender-specific 翻译。我们的结果表明，LLaMa可以生成与NLLB（一种现代多语言 NMT 系统）相比的竞争性准确性和减少 gender bias 的 gender-specific 翻译。此外，我们的实验还表明了 LLaMa 的翻译是稳定的，在 gender-ambiguous 数据集中评估时表现出了明显的性能下降，但在 less ambiguous 上保持了一致性。这项研究为使用 LLM 进行 gender-specific 翻译提供了新的视角和挑战，并 highlighted 在 LLM 中进行 in-context learning 以提取新任务的重要性。
</details></li>
</ul>
<hr>
<h2 id="GPT-InvestAR-Enhancing-Stock-Investment-Strategies-through-Annual-Report-Analysis-with-Large-Language-Models"><a href="#GPT-InvestAR-Enhancing-Stock-Investment-Strategies-through-Annual-Report-Analysis-with-Large-Language-Models" class="headerlink" title="GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models"></a>GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03079">http://arxiv.org/abs/2309.03079</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/UditGupta10/GPT-InvestAR">https://github.com/UditGupta10/GPT-InvestAR</a></li>
<li>paper_authors: Udit Gupta</li>
<li>For: The paper aims to simplify the process of assessing Annual Reports of all firms by leveraging the capabilities of Large Language Models (LLMs) to generate insights and improve stock price predictions.* Methods: The paper uses Large Language Models (LLMs) to analyze Annual Reports and generate insights, which are then compiled into a Quant styled dataset and augmented with historical stock price data. A Machine Learning model is trained with LLM outputs as features to predict stock prices.* Results: The walkforward test results show promising outperformance compared to S&amp;P500 returns, indicating the effectiveness of the proposed framework in predicting stock prices.Here’s the simplified Chinese text for the three information points:* For: 这份论文旨在使用大量语言模型（LLMs）来简化所有公司的年度报告评估过程，以提高股票价格预测的准确性。* Methods: 论文使用大量语言模型（LLMs）来分析年度报告，生成报告中的材料，并将其与历史股票价格数据相结合。使用机器学习模型，将LMM输出作为特征来预测股票价格。* Results: 论文的步骤测试结果表明，使用该方法可以与S&amp;P500的返点相比，表明该方法的效果性。<details>
<summary>Abstract</summary>
Annual Reports of publicly listed companies contain vital information about their financial health which can help assess the potential impact on Stock price of the firm. These reports are comprehensive in nature, going up to, and sometimes exceeding, 100 pages. Analysing these reports is cumbersome even for a single firm, let alone the whole universe of firms that exist. Over the years, financial experts have become proficient in extracting valuable information from these documents relatively quickly. However, this requires years of practice and experience. This paper aims to simplify the process of assessing Annual Reports of all the firms by leveraging the capabilities of Large Language Models (LLMs). The insights generated by the LLM are compiled in a Quant styled dataset and augmented by historical stock price data. A Machine Learning model is then trained with LLM outputs as features. The walkforward test results show promising outperformance wrt S&P500 returns. This paper intends to provide a framework for future work in this direction. To facilitate this, the code has been released as open source.
</details>
<details>
<summary>摘要</summary>
公司年度报告包含重要的财务健康信息，可以帮助评估公司股票价格的可能影响。这些报告是全面的，有时 même exceeding 100 页。分析这些报告是困难的，尤其是对于整个公司宇宙。随着年月的掌握，金融专家们已经学会了快速提取这些报告中的有价值信息。然而，这需要多年的实践和经验。本文提出了使用大型自然语言模型（LLM）简化公司年度报告的评估过程。LLM 输出的含义被编译成量化风格的数据集，并与历史股票价格数据进行拟合。然后，使用 LLM 输出作为特征来训练机器学习模型。walkforward 测试结果表明，使用这种方法可以实现出色的超前性，与 S&P500 回报相比。本文的目标是提供未来研究的框架。为此，我们已经公开发布了代码。
</details></li>
</ul>
<hr>
<h2 id="Narrative-as-a-Dynamical-System"><a href="#Narrative-as-a-Dynamical-System" class="headerlink" title="Narrative as a Dynamical System"></a>Narrative as a Dynamical System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06600">http://arxiv.org/abs/2309.06600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isidoros Doxas, James Meiss, Steven Bottone, Tom Strelich, Andrew Plummer, Adrienne Breland, Simon Dennis, Kathy Garvin-Doxas, Michael Klymkowsky</li>
<li>for: 这个论文探讨了人类活动和叙事的动力系统特性，并使用物理学概念来描述它们的演化。</li>
<li>methods: 该论文使用了500个不同的叙事来构建三条平均路径，并证明这些平均路径符合动力学原理。</li>
<li>results: 研究发现，人类活动和叙事的演化可以被视为动力系统，其演化可以通过动力学原理来描述。<details>
<summary>Abstract</summary>
There is increasing evidence that human activity in general, and narrative in particular, can be treated as a dynamical system in the physics sense; a system whose evolution is described by an action integral, such that the average of all possible paths from point A to point B is given by the extremum of the action. We create by construction three such paths by averaging about 500 different narratives, and we show that the average path is consistent with an action principle.
</details>
<details>
<summary>摘要</summary>
人类活动和 narative 可以被视为物理学上的动力系统，其演化可以通过动力 integral 来描述，其中所有可能的路径从点 A 到点 B 的平均值是动力 integral 的极值。我们通过构建3个这样的路径，并证明这些路径符合动力原理。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Everyone-Deserves-A-Reward-Learning-Customized-Human-Preferences"><a href="#Everyone-Deserves-A-Reward-Learning-Customized-Human-Preferences" class="headerlink" title="Everyone Deserves A Reward: Learning Customized Human Preferences"></a>Everyone Deserves A Reward: Learning Customized Human Preferences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03126">http://arxiv.org/abs/2309.03126</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linear95/dsp">https://github.com/linear95/dsp</a></li>
<li>paper_authors: Pengyu Cheng, Jiawen Xie, Ke Bai, Yong Dai, Nan Du</li>
<li>for: 本研究旨在提高大语言模型（LLM）与人类偏好的对应性，以提高交互质量。</li>
<li>methods: 本研究提出了一种三Stage个性化奖励模型（RM）学习方案，并在实验阶段采用了多种训练和数据策略来保持普遍偏好的能力。</li>
<li>results: 研究发现，三Stage个性化奖励模型可以更好地适应个性化应用场景，并且可以保持普遍偏好的能力。此外，研究还发现了一些可以更好地保持普遍偏好的训练和数据策略。<details>
<summary>Abstract</summary>
Reward models (RMs) are essential for aligning large language models (LLMs) with human preferences to improve interaction quality. However, the real world is pluralistic, which leads to diversified human preferences with respect to different religions, politics, cultures, etc. Moreover, each individual can have their unique preferences on various topics. Neglecting the diversity of human preferences, current human feedback aligning methods only consider a general reward model, which is below satisfaction for customized or personalized application scenarios. To explore customized preference learning, we collect a domain-specific preference (DSP) dataset, which includes preferred responses for each given query from four practical domains. Besides, from the perspective of data efficiency, we propose a three-stage customized RM learning scheme, then empirically verify its effectiveness on both general preference datasets and our DSP set. Furthermore, we test multiple training and data strategies on the three learning stages. We find several ways to better preserve the general preferring ability while training the customized RMs, especially general preference enrichment, and customized preference imitation learning. The DSP dataset and code are available at https://github.com/Linear95/DSP.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>大型语言模型（LLM）需要奖励模型（RM）来调整和人类偏好以提高交互质量。然而，现实世界是多元的，这导致了不同的宗教、政治、文化等方面的多样化人类偏好。此外，每个个体可能有对各种主题的独特偏好。忽视人类偏好的多样性，现有的人类反馈对齐方法只考虑通用奖励模型，这对个性化或个性化应用场景下是不满足的。为了探索个性化偏好学习，我们收集了域pecific preference（DSP） dataset，该集包括每个查询的首选回答。此外，从数据效率的角度，我们提议了三个阶段个性化RM学习方案，然后经验验证其效果在通用奖励 dataset和我们的 DSP 集上。此外，我们在三个学习阶段中测试了多种训练和数据策略，发现了一些方法可以更好地保持通用偏好能力 while 训练个性化RM，特别是通用偏好增强和个性化偏好模仿学习。 DSP dataset 和代码可以在 <https://github.com/Linear95/DSP> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Solver-Teaching-LLMs-to-Search-for-Domain-Knowledge-from-Knowledge-Graphs"><a href="#Knowledge-Solver-Teaching-LLMs-to-Search-for-Domain-Knowledge-from-Knowledge-Graphs" class="headerlink" title="Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs"></a>Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03118">http://arxiv.org/abs/2309.03118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Feng, Xinyu Zhang, Zichu Fei</li>
<li>for: 提高大语言模型（LLM）的域专知和解释能力</li>
<li>methods: 提出了一种名为知识解决器（KSL）的方法，通过利用LLM的强大总体化能力来教育LLM检索外部知识库中的关键信息</li>
<li>results: 在三个数据集上（ CommonsenseQA、OpenbookQA 和 MedQA-USMLE）进行了实验，发现我们的方法可以提高LLM基线性能，相比原始LLM，提高了相对较大的margin。<details>
<summary>Abstract</summary>
Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and can solve different tasks due to their emergent ability and generalizability. However, LLMs sometimes lack domain-specific knowledge to perform tasks, which would also cause hallucination during inference. In some previous works, additional modules like graph neural networks (GNNs) are trained on retrieved knowledge from external knowledge bases, aiming to mitigate the problem of lacking domain-specific knowledge. However, incorporating additional modules: 1) would need retraining additional modules when encountering novel domains; 2) would become a bottleneck since LLMs' strong abilities are not fully utilized for retrieval. In this paper, we propose a paradigm, termed Knowledge Solver (KSL), to teach LLMs to search for essential knowledge from external knowledge bases by harnessing their own strong generalizability. Specifically, we design a simple yet effective prompt to transform retrieval into a multi-hop decision sequence, which empowers LLMs with searching knowledge ability in zero-shot manner. Additionally, KSL is able to provide complete retrieval paths and therefore increase explainability of LLMs' reasoning processes. We conduct experiments on three datasets: CommonsenseQA, OpenbookQA, and MedQA-USMLE, and found that our approach improves LLM baseline performance by a relatively large margin.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），如ChatGPT和GPT-4，具有多方面的能力和普遍化能力，可以解决不同任务。然而，LLM  sometimes lack domain-specific knowledge to perform tasks, leading to hallucination during inference. 在一些先前的工作中，运用了另外的模组，如 graf neural network（GNN），在外部知识库中获取知识，以减少缺乏专业知识的问题。但是，将这些模组添加到 LLM 中会有以下问题：1）需要重新训练这些模组当遇到新的领域时; 2）会成为一个瓶颈，因为 LLM 的强大能力不能完全利用来搜寻。在这篇论文中，我们提出了一个概念，称为知识解决方案（KSL），以 teach LLM 如何从外部知识库中搜寻必要的知识。具体来说，我们设计了一个简单 yet 有效的提示，将搜寻变成多阶层决策序列，这使得 LLM 获得了寻找知识的能力，而不需要重新训练。此外，KSL 能够提供完整的搜寻路径，因此增加了 LLM 的解释过程的可读性。我们在 CommonsenseQA、OpenbookQA 和 MedQA-USMLE 三个数据集上进行了实验，发现我们的方法可以对 LLM 基线性能提高相对较大的margin。
</details></li>
</ul>
<hr>
<h2 id="ContrastWSD-Enhancing-Metaphor-Detection-with-Word-Sense-Disambiguation-Following-the-Metaphor-Identification-Procedure"><a href="#ContrastWSD-Enhancing-Metaphor-Detection-with-Word-Sense-Disambiguation-Following-the-Metaphor-Identification-Procedure" class="headerlink" title="ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following the Metaphor Identification Procedure"></a>ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following the Metaphor Identification Procedure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03103">http://arxiv.org/abs/2309.03103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamad Elzohbi, Richard Zhao</li>
<li>for: 本研究开发了一个基于 RoBERTa 的比喻检测模型，将比喻识别程序 (MIP) 和字汇散义 (WSD) 组合使用，从文本中提取和比较词汇的上下文意义和基本意义，以判断词汇是否在句子中使用比喻性。</li>
<li>methods: 本模型使用 WSD 模型获取词汇的不同意义，并与上下文嵌入相结合，以优化比喻检测过程。</li>
<li>results: 本研究在不同的 benchmark 数据集上进行评估，与强基eline 进行比较，结果显示本模型优于其他仅靠上下文嵌入或仅融合基本定义和其他外部知识的方法。<details>
<summary>Abstract</summary>
This paper presents ContrastWSD, a RoBERTa-based metaphor detection model that integrates the Metaphor Identification Procedure (MIP) and Word Sense Disambiguation (WSD) to extract and contrast the contextual meaning with the basic meaning of a word to determine whether it is used metaphorically in a sentence. By utilizing the word senses derived from a WSD model, our model enhances the metaphor detection process and outperforms other methods that rely solely on contextual embeddings or integrate only the basic definitions and other external knowledge. We evaluate our approach on various benchmark datasets and compare it with strong baselines, indicating the effectiveness in advancing metaphor detection.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:这篇论文介绍了 ContrastWSD，一种基于 RoBERTa 的比喻检测模型，该模型结合了 Metaphor Identification Procedure (MIP) 和 Word Sense Disambiguation (WSD)，以提取和对比上下文中的意思和基本意思来确定一个词是否在句子中使用比喻。通过利用 WSD 模型提取出的词义，我们的模型可以增强比喻检测的过程，并超越其他基于上下文嵌入或只是将基本定义和其他知识集成的方法。我们在多个标准测试集上评估了我们的方法，并与强基线相比较，表明我们的方法有效地提高了比喻检测。
</details></li>
</ul>
<hr>
<h2 id="Persona-aware-Generative-Model-for-Code-mixed-Language"><a href="#Persona-aware-Generative-Model-for-Code-mixed-Language" class="headerlink" title="Persona-aware Generative Model for Code-mixed Language"></a>Persona-aware Generative Model for Code-mixed Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02915">http://arxiv.org/abs/2309.02915</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/victor7246/paradox">https://github.com/victor7246/paradox</a></li>
<li>paper_authors: Ayan Sengupta, Md Shad Akhtar, Tanmoy Chakraborty</li>
<li>for: 本研究旨在开发一种基于人物特点的代码混合生成模型，以生成更加真实的人类语言混合文本。</li>
<li>methods: 提出了一种基于Transformer编码器-解码器模型的Persona-aware Generative Model for Code-mixed Generation（PARADOX），通过对每个词语进行人物特点conditioning，生成更加自然的code-mixed文本。同时，提出了一种Alignment模块，以重新调整生成的序列，使其更加符合实际的语言混合文本。</li>
<li>results: PARADOX在测试集上的平均CM BLEU分数高于非人物基于模型1.6个分，其表现在混合文本的语义准确性和语言VALIDITY方面也有32%和47%的提升。<details>
<summary>Abstract</summary>
Code-mixing and script-mixing are prevalent across online social networks and multilingual societies. However, a user's preference toward code-mixing depends on the socioeconomic status, demographics of the user, and the local context, which existing generative models mostly ignore while generating code-mixed texts. In this work, we make a pioneering attempt to develop a persona-aware generative model to generate texts resembling real-life code-mixed texts of individuals. We propose a Persona-aware Generative Model for Code-mixed Generation, PARADOX, a novel Transformer-based encoder-decoder model that encodes an utterance conditioned on a user's persona and generates code-mixed texts without monolingual reference data. We propose an alignment module that re-calibrates the generated sequence to resemble real-life code-mixed texts. PARADOX generates code-mixed texts that are semantically more meaningful and linguistically more valid. To evaluate the personification capabilities of PARADOX, we propose four new metrics -- CM BLEU, CM Rouge-1, CM Rouge-L and CM KS. On average, PARADOX achieves 1.6 points better CM BLEU, 47% better perplexity and 32% better semantic coherence than the non-persona-based counterparts.
</details>
<details>
<summary>摘要</summary>
【文本】在社交媒体和多语言社会中，混合代码和文本混合是普遍存在的。然而，用户对代码混合的偏好受到了用户的社会经济地位、人口结构和当地情况的影响，这些因素现存在的生成模型大多忽略。在这种情况下，我们提出了一种基于Transformer的Persona-aware生成模型，名为PARADOX，可以生成符合实际生活中个人代码混合文本的文本。我们提出了一个对齐模块，可以重新调整生成的序列，使其更加接近实际生活中的代码混合文本。PARADOX生成的文本具有更高的semantic coherence和linguistic validity。为评估PARADOX的人格化能力，我们提出了四个新的指标：CM BLEU、CM Rouge-1、CM Rouge-L和CM KS。平均而言，PARADOX在这些指标中的表现比非人格化counterpart更好，其CM BLEU指标提高1.6个点，折占率提高47%，semantic coherence提高32%。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the original text in English, and some cultural references or idioms may not be fully preserved in the translation.
</details></li>
</ul>
<hr>
<h2 id="Leave-no-Place-Behind-Improved-Geolocation-in-Humanitarian-Documents"><a href="#Leave-no-Place-Behind-Improved-Geolocation-in-Humanitarian-Documents" class="headerlink" title="Leave no Place Behind: Improved Geolocation in Humanitarian Documents"></a>Leave no Place Behind: Improved Geolocation in Humanitarian Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02914">http://arxiv.org/abs/2309.02914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enrico M. Belliardo, Kyriaki Kalimeri, Yelena Mejova</li>
<li>for: The paper aims to improve the performance of natural language processing (NLP) tools in the humanitarian sector by developing annotated resources for geotagging humanitarian texts.</li>
<li>methods: The authors use two popular Named Entity Recognition (NER) tools, Spacy and roBERTa, and develop a geocoding method called FeatureRank to link candidate locations to the GeoNames database.</li>
<li>results: The authors find that the humanitarian-domain data improves the performance of the classifiers (up to F1 &#x3D; 0.92) and alleviates some of the bias of the existing tools, which erroneously favor locations in Western countries. However, they conclude that more resources from non-Western documents are necessary to ensure that off-the-shelf NER systems are suitable for deployment in the humanitarian sector.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是提高人道主义领域自然语言处理（NLP）工具的性能，通过开发人道主义文本地标注资源。</li>
<li>methods: 作者使用两种流行的名实Recognition（NER）工具，Spacy和roBERTa，并开发了一种名为FeatureRank的地编码方法，将候选地点与GeoNames数据库相关联。</li>
<li>results: 作者发现，人道主义领域数据可以提高分类器的性能（最高F1 &#x3D; 0.92），并减少现有工具的偏见，但是发现更多的非西方文档资源是必要的，以确保off-the-shelf NER系统适用于人道主义领域。<details>
<summary>Abstract</summary>
Geographical location is a crucial element of humanitarian response, outlining vulnerable populations, ongoing events, and available resources. Latest developments in Natural Language Processing may help in extracting vital information from the deluge of reports and documents produced by the humanitarian sector. However, the performance and biases of existing state-of-the-art information extraction tools are unknown. In this work, we develop annotated resources to fine-tune the popular Named Entity Recognition (NER) tools Spacy and roBERTa to perform geotagging of humanitarian texts. We then propose a geocoding method FeatureRank which links the candidate locations to the GeoNames database. We find that not only does the humanitarian-domain data improves the performance of the classifiers (up to F1 = 0.92), but it also alleviates some of the bias of the existing tools, which erroneously favor locations in the Western countries. Thus, we conclude that more resources from non-Western documents are necessary to ensure that off-the-shelf NER systems are suitable for the deployment in the humanitarian sector.
</details>
<details>
<summary>摘要</summary>
地理位置是人道主义应对中的关键元素，描述易受影响人口、进行中的事件和可用资源。最新的自然语言处理技术可能帮助提取人道主义领域的重要信息。然而，现有状态的信息EXTRACTION工具的性能和偏见仍未得到了评估。在这项工作中，我们开发了精心标注的资源，用于精细地调整Spacy和roBERTa等流行的名实Recognition（NER）工具。然后，我们提出了一种地图编码方法FeatureRank，将候选地点与GeoNames数据库连接起来。我们发现，不仅可以提高人道主义领域的数据改进了分类器的性能（F1 = 0.92），还可以解决现有工具的偏见，这些工具偏 toward西方国家的位置。因此，我们 conclude that需要更多来自非西方文档的资源，以确保off-the-shelf NER系统适用于人道主义领域。
</details></li>
</ul>
<hr>
<h2 id="ViCGCN-Graph-Convolutional-Network-with-Contextualized-Language-Models-for-Social-Media-Mining-in-Vietnamese"><a href="#ViCGCN-Graph-Convolutional-Network-with-Contextualized-Language-Models-for-Social-Media-Mining-in-Vietnamese" class="headerlink" title="ViCGCN: Graph Convolutional Network with Contextualized Language Models for Social Media Mining in Vietnamese"></a>ViCGCN: Graph Convolutional Network with Contextualized Language Models for Social Media Mining in Vietnamese</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02902">http://arxiv.org/abs/2309.02902</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/phanchauthang/ViCGCN">https://github.com/phanchauthang/ViCGCN</a></li>
<li>paper_authors: Chau-Thang Phan, Quoc-Nam Nguyen, Chi-Thanh Dang, Trong-Hop Do, Kiet Van Nguyen</li>
<li>for: 本研究旨在提高越南语言社交媒体上的信息挖掘 task 的效果，通过利用图structured data的特点来 Address 数据不均匀和噪音问题。</li>
<li>methods: 本研究提出了一种基于 PhoBERT 和 Graph Convolutional Networks 的新方法，称为 ViCGCN，通过将它们相互融合以提高语言模型的表达能力和语义依赖关系的捕捉。</li>
<li>results: 对于多个越南语言社交媒体数据集， experiments 表明，应用 GCN 到 BERTology 模型的最终层可以显著提高性能，而 ViCGCN 还可以超过 13 个基eline 模型，包括 BERTology 模型、 fusions BERTology 和 GCN 模型、其他基eline 和 SOTA 在三个社交媒体数据集上。<details>
<summary>Abstract</summary>
Social media processing is a fundamental task in natural language processing with numerous applications. As Vietnamese social media and information science have grown rapidly, the necessity of information-based mining on Vietnamese social media has become crucial. However, state-of-the-art research faces several significant drawbacks, including imbalanced data and noisy data on social media platforms. Imbalanced and noisy are two essential issues that need to be addressed in Vietnamese social media texts. Graph Convolutional Networks can address the problems of imbalanced and noisy data in text classification on social media by taking advantage of the graph structure of the data. This study presents a novel approach based on contextualized language model (PhoBERT) and graph-based method (Graph Convolutional Networks). In particular, the proposed approach, ViCGCN, jointly trained the power of Contextualized embeddings with the ability of Graph Convolutional Networks, GCN, to capture more syntactic and semantic dependencies to address those drawbacks. Extensive experiments on various Vietnamese benchmark datasets were conducted to verify our approach. The observation shows that applying GCN to BERTology models as the final layer significantly improves performance. Moreover, the experiments demonstrate that ViCGCN outperforms 13 powerful baseline models, including BERTology models, fusion BERTology and GCN models, other baselines, and SOTA on three benchmark social media datasets. Our proposed ViCGCN approach demonstrates a significant improvement of up to 6.21%, 4.61%, and 2.63% over the best Contextualized Language Models, including multilingual and monolingual, on three benchmark datasets, UIT-VSMEC, UIT-ViCTSD, and UIT-VSFC, respectively. Additionally, our integrated model ViCGCN achieves the best performance compared to other BERTology integrated with GCN models.
</details>
<details>
<summary>摘要</summary>
社交媒体处理是自然语言处理的基本任务，具有广泛的应用。随着越南社交媒体和信息科学的快速发展，对越南社交媒体上的信息挖掘成为了急需。然而，现状的研究面临着一些重要的缺点，包括社交媒体平台上的数据不均衡和噪音。这两个问题在越南社交媒体文本中具有重要性。图 convolutional neural networks 可以在文本分类任务中解决社交媒体上的数据不均衡和噪音问题，因为它可以利用数据的图结构。本研究提出了一种基于上下文化语言模型（PhoBERT）和图基本方法（图 convolutional neural networks）的新approach。具体来说，我们的方法ViCGCN通过将上下文化预测器和图基本方法相结合，以提高文本分类任务中的性能。我们对越南多个benchmark dataset进行了广泛的实验，以验证我们的方法。结果显示，在BERTology模型的最终层添加GCN层可以显著提高性能。此外，实验还表明，ViCGCN方法在三个benchmark社交媒体dataset上比13种基eline模型，包括BERTology模型、混合BERTology和GCN模型、其他基eline和SOTA的最佳性能。我们的提出的ViCGCN方法在三个benchmark dataset上提高了6.21%、4.61%和2.63%。此外，我们的整合模型ViCGCN在BERTology和GCN模型的混合方法中表现出了最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Addressing-the-Blind-Spots-in-Spoken-Language-Processing"><a href="#Addressing-the-Blind-Spots-in-Spoken-Language-Processing" class="headerlink" title="Addressing the Blind Spots in Spoken Language Processing"></a>Addressing the Blind Spots in Spoken Language Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06572">http://arxiv.org/abs/2309.06572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amit Moryossef</li>
<li>For: 本研究探讨了人类交流中的关键 yet often overlooked 的非语言示意，包括合作谈话姿势和表情，以及它们对自然语言处理（NLP）的影响。* Methods: 我们建议通过借鉴了手语处理技术的发展，开发一种通用的自动手势分割和转写模型，以将非语言示意转化为文本形式。这种方法可以填补 spoken language 理解中的盲点，扩大 NLP 模型的范围和适用范围。* Results: 通过启示性的例子，我们展示了依赖 solely 文本基础模型的局限性。我们提出了一种 computationally efficient 和灵活的方法，可以轻松地与现有 NLP 管道集成。我们 conclude 呼吁研究人员参与开发通用转写方法，并验证其效果性。<details>
<summary>Abstract</summary>
This paper explores the critical but often overlooked role of non-verbal cues, including co-speech gestures and facial expressions, in human communication and their implications for Natural Language Processing (NLP). We argue that understanding human communication requires a more holistic approach that goes beyond textual or spoken words to include non-verbal elements. Borrowing from advances in sign language processing, we propose the development of universal automatic gesture segmentation and transcription models to transcribe these non-verbal cues into textual form. Such a methodology aims to bridge the blind spots in spoken language understanding, enhancing the scope and applicability of NLP models. Through motivating examples, we demonstrate the limitations of relying solely on text-based models. We propose a computationally efficient and flexible approach for incorporating non-verbal cues, which can seamlessly integrate with existing NLP pipelines. We conclude by calling upon the research community to contribute to the development of universal transcription methods and to validate their effectiveness in capturing the complexities of real-world, multi-modal interactions.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "co-speech gestures" is translated as "同时手势" (tóngshí shǒu yì)* "facial expressions" is translated as "面孔表达" (miànkǒu biǎodòng)* "non-verbal cues" is translated as "非语言表达" (fēi yǔyán biǎodòng)* "spoken language understanding" is translated as "语言理解" (yǔyán lǐjiě)* "NLP" is translated as "自然语言处理" (zìrán yǔyán chùhē)* "universal automatic gesture segmentation and transcription models" is translated as "通用自动手势分割和译写模型" (tōngyòng zìdòng zhìyì fēnpièceshì yìyì módelì)* "computationally efficient and flexible approach" is translated as "高效灵活的方法" (gāoxìng língwù de fāngtiě)* "real-world, multi-modal interactions" is translated as "实际多模态互动" (shíjiè duōmódai yùdòng)
</details></li>
</ul>
<hr>
<h2 id="Aligning-Large-Language-Models-for-Clinical-Tasks"><a href="#Aligning-Large-Language-Models-for-Clinical-Tasks" class="headerlink" title="Aligning Large Language Models for Clinical Tasks"></a>Aligning Large Language Models for Clinical Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02884">http://arxiv.org/abs/2309.02884</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ssm123ssm/medGPT">https://github.com/ssm123ssm/medGPT</a></li>
<li>paper_authors: Supun Manathunga, Isuru Hettigoda</li>
<li>for: 这个论文是为了探讨大语言模型（LLMs）在医疗应用中的适用性和效果。</li>
<li>methods: 这篇论文使用了一种组合技术，包括指令调整和在提示中使用少量和链式思维技巧，以提高 LLMS 的表现。</li>
<li>results: 这篇论文的实验结果表明，使用“扩展-猜测-调整”策略可以提高 LLMS 的表现，在一个子集问题来源于 USMLE 数据集上达到了 70.63% 的分数。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable adaptability, showcasing their capacity to excel in tasks for which they were not explicitly trained. However, despite their impressive natural language processing (NLP) capabilities, effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications. The ability to generate responses with factually accurate content and to engage in non-trivial reasoning steps are crucial for the LLMs to be eligible for applications in clinical medicine. Employing a combination of techniques including instruction-tuning and in-prompt strategies like few-shot and chain-of-thought prompting has significantly enhanced the performance of LLMs. Our proposed alignment strategy for medical question-answering, known as 'expand-guess-refine', offers a parameter and data-efficient solution. A preliminary analysis of this method demonstrated outstanding performance, achieving a score of 70.63% on a subset of questions sourced from the USMLE dataset.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Agent-based-simulation-of-pedestrians’-earthquake-evacuation-application-to-Beirut-Lebanon"><a href="#Agent-based-simulation-of-pedestrians’-earthquake-evacuation-application-to-Beirut-Lebanon" class="headerlink" title="Agent-based simulation of pedestrians’ earthquake evacuation; application to Beirut, Lebanon"></a>Agent-based simulation of pedestrians’ earthquake evacuation; application to Beirut, Lebanon</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02812">http://arxiv.org/abs/2309.02812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rouba Iskandar, Kamel Allaw, Julie Dugdale, Elise Beck, Jocelyne Adjizian-Gérard, Cécile Cornou, Jacques Harb, Pascal Lacroix, Nada Badaro-Saliba, Stéphane Cartier, Rita Zaarour</li>
<li>for: 本研究旨在发展一种城市规模下的人行模拟器，以估算在地震时人员的迁徙和避险行为。</li>
<li>methods: 该模型 integrate了地震风险、物理抵触以及个人行为和 mobilty。使用GAMA进行高度实际的城市环境模拟，并使用过去的数据（包括建筑和土壤特性）以及新采集的高分辨率卫星图像数据来支持模型。</li>
<li>results: 研究发现，在地震时，人员可以快速迁徙到开放空间中，但是如果一些开放空间被锁死， then 52%的人口可以在5分钟内到达开放空间，而只有39%的人口可以到达开放空间。这些结果表明，城市中开放空间的存在和距离 residence 建筑物是关键的因素，以确保人员的安全性。<details>
<summary>Abstract</summary>
Most seismic risk assessment methods focus on estimating the damages to the built environment and the consequent socioeconomic losses without fully taking into account the social aspect of risk. Yet, human behaviour is a key element in predicting the human impact of an earthquake, therefore, it is important to include it in quantitative risk assessment studies. In this study, an interdisciplinary approach simulating pedestrians' evacuation during earthquakes at the city scale is developed using an agent-based model. The model integrates the seismic hazard, the physical vulnerability as well as individuals' behaviours and mobility. The simulator is applied to the case of Beirut, Lebanon. Lebanon is at the heart of the Levant fault system that has generated several Mw>7 earthquakes, the latest being in 1759. It is one of the countries with the highest seismic risk in the Mediterranean region. This is due to the high seismic vulnerability of the buildings due to the absence of mandatory seismic regulation until 2012, the high level of urbanization, and the lack of adequate spatial planning and risk prevention policies. Beirut as the main residential, economic and institutional hub of Lebanon is densely populated. To accommodate the growing need for urban development, constructions have almost taken over all of the green areas of the city; squares and gardens are disappearing to give place to skyscrapers. However, open spaces are safe places to shelter, away from debris, and therefore play an essential role in earthquake evacuation. Despite the massive urbanization, there are a few open spaces but locked gates and other types of anthropogenic barriers often limit their access. To simulate this complex context, pedestrians' evacuation simulations are run in a highly realistic spatial environment implemented in GAMA [1]. Previous data concerning soil and buildings in Beirut [2, 3] are complemented by new geographic data extracted from high-resolution Pleiades satellite images. The seismic loading is defined as a peak ground acceleration of 0.3g, as stated in Lebanese seismic regulations. Building damages are estimated using an artificial neural network trained to predict the mean damage [4] based on the seismic loading as well as the soil and building vibrational properties [5]. Moreover, the quantity and the footprint of the generated debris around each building are also estimated and included in the model. We simulate how topography, buildings, debris, and access to open spaces, affect individuals' mobility. Two city configurations are implemented: 1. Open spaces are accessible without any barriers; 2. Access to some open spaces is blocked. The first simulation results show that while 52% of the population is able to arrive to an open space within 5 minutes after an earthquake, this number is reduced to 39% when one of the open spaces is locked. These results show that the presence of accessible open spaces in a city and their proximity to the residential buildings is a crucial factor for ensuring people's safety when an earthquake occurs.
</details>
<details>
<summary>摘要</summary>
多数地震风险评估方法都是估计建筑环境和后果的经济损害，未能充分考虑人类行为的影响。然而，人类行为是预测地震影响的关键因素，因此应包括其在量化风险评估研究中。本研究提出了一种涉及人类行为的地震风险评估模型，使用代理人模型来模拟步行者在地震中的逃生行为。该模型结合地震威胁、物理抵触以及个人行为和 mobilit。该模型在黎巴嫩apply于 случа子中。黎巴嫩位于地中海地震系统的中心，拥有许多Mw>7的地震，最近一次在1759年。黎巴嫩是地中海地区最高风险地震国家之一，这主要归功于建筑物的高度抵触、城市化水平高，以及缺乏合适的城市规划和风险预防政策。黎巴嫩作为国家的主要居住、经济和机构中心，人口密度非常高。为了满足城市发展的增长需求，建筑物几乎占用了所有绿地，广场和花园都被拆除，以建立高层楼房。然而，开放空间是避险的好地方，避免废墟的影响，因此在地震逃生中扮演着关键角色。尽管黎巴嫩城市化程度很高，但开放空间受到人工障碍的限制。为了模拟这种复杂的Context，我们在GAMA中运行了步行者逃生的高度现实主义空间环境。前一个数据集包括黎巴嫩的土壤和建筑物的特性，而新的地理数据则是从高分辨率的Pleiades卫星图像提取的。地震荷重定义为0.3g，根据黎巴嫩的地震规则。建筑物损害预测使用人工神经网络，基于地震荷重以及土壤和建筑物的振荡性能。此外，生成的废墟的质量和面积也被计算并包括在模型中。我们模拟了城市地形、建筑物、废墟和访问开放空间之间的相互作用，对人类 mobilit的影响。我们实现了两种城市配置：1. 开放空间无障碍访问; 2. 一些开放空间受阻。第一个 simulations 结果显示，当地震发生后，52%的人口可以在5分钟内到达开放空间，但当一个开放空间受阻时，这个数字降低到39%。这些结果表明，城市中开放空间的存在和距离居民建筑物的距离是预测人类安全的关键因素。
</details></li>
</ul>
<hr>
<h2 id="GRASS-Unified-Generation-Model-for-Speech-to-Semantic-Tasks"><a href="#GRASS-Unified-Generation-Model-for-Speech-to-Semantic-Tasks" class="headerlink" title="GRASS: Unified Generation Model for Speech-to-Semantic Tasks"></a>GRASS: Unified Generation Model for Speech-to-Semantic Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02780">http://arxiv.org/abs/2309.02780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aobo Xia, Shuyu Lei, Yushu Yang, Xiang Guo, Hua Chai</li>
<li>for: 这 paper 探讨了对 speech-to-semantic 任务的 instruction fine-tuning 技术，并提出了一个 unified end-to-end (E2E) 框架，该框架可以根据任务相关的提示生成目标文本 conditioned on 音频数据。</li>
<li>methods: 作者采用了大量和多样的数据预训练模型，并使用 text-to-speech (TTS) 系统生成 instruction-speech 对。</li>
<li>results: 对多个 benchmark 进行了广泛的实验，显示了作者提出的模型在 speech named entity recognition, speech sentiment analysis, speech question answering 等任务上具有state-of-the-art (SOTA) 性能，并且在 zero-shot 和 few-shot enario 中也达到了竞争性能。<details>
<summary>Abstract</summary>
This paper explores the instruction fine-tuning technique for speech-to-semantic tasks by introducing a unified end-to-end (E2E) framework that generates target text conditioned on a task-related prompt for audio data. We pre-train the model using large and diverse data, where instruction-speech pairs are constructed via a text-to-speech (TTS) system. Extensive experiments demonstrate that our proposed model achieves state-of-the-art (SOTA) results on many benchmarks covering speech named entity recognition, speech sentiment analysis, speech question answering, and more, after fine-tuning. Furthermore, the proposed model achieves competitive performance in zero-shot and few-shot scenarios. To facilitate future work on instruction fine-tuning for speech-to-semantic tasks, we release our instruction dataset and code.
</details>
<details>
<summary>摘要</summary>
这篇论文探讨了对语音到 semantic 任务的指令细化技术，通过引入一个综合的终端到终端 (E2E) 框架，将目标文本根据任务相关的提示生成于语音数据上。我们在大量和多样的数据上预训练模型，使用文本到语音 (TTS) 系统生成 instrucion-speech 对。广泛的实验证明我们提出的模型在许多 bencmark 上实现了状态的最佳 (SOTA) 结果，并在零shot 和几shot enario 中达到了竞争性的性能。此外，我们的模型还能够在零shot 和几shot enario 中实现了竞争性的性能。为将来的 instruction 细化任务的研究提供便利，我们公开了我们的 instruction 数据集和代码。
</details></li>
</ul>
<hr>
<h2 id="Improving-Code-Generation-by-Dynamic-Temperature-Sampling"><a href="#Improving-Code-Generation-by-Dynamic-Temperature-Sampling" class="headerlink" title="Improving Code Generation by Dynamic Temperature Sampling"></a>Improving Code Generation by Dynamic Temperature Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02772">http://arxiv.org/abs/2309.02772</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Yuqi Zhu, Jia Allen Li, Ge Li, YunFei Zhao, Jia Li, Zhi Jin, Hong Mei</li>
<li>for: 研究了一种针对代码生成的特有decoding策略，以优化现有的大语言模型（LLM）在代码生成中的性能。</li>
<li>methods: 通过分析代码token的损失分布，发现代码token可以分为两类：困难的token和自信的token。采用适应温度（AdapT）采样方法，动态调整温度系数在不同的token时。</li>
<li>results: 对不同大小的LLM进行应用，在两个流行的数据集上进行评估，结果表明适应温度采样方法可以明显超过现有的decoding策略。<details>
<summary>Abstract</summary>
Recently, Large Language Models (LLMs) have shown impressive results in code generation. However, existing decoding strategies are designed for Natural Language (NL) generation, overlooking the differences between NL and programming languages (PL). Due to this oversight, a better decoding strategy for code generation remains an open question. In this paper, we conduct the first systematic study to explore a decoding strategy specialized in code generation. With an analysis of loss distributions of code tokens, we find that code tokens can be divided into two categories: challenging tokens that are difficult to predict and confident tokens that can be easily inferred. Among them, the challenging tokens mainly appear at the beginning of a code block. Inspired by the above findings, we propose a simple yet effective method: Adaptive Temperature (AdapT) sampling, which dynamically adjusts the temperature coefficient when decoding different tokens. We apply a larger temperature when sampling for challenging tokens, allowing LLMs to explore diverse choices. We employ a smaller temperature for confident tokens avoiding the influence of tail randomness noises. We apply AdapT sampling to LLMs with different sizes and conduct evaluations on two popular datasets. Results show that AdapT sampling significantly outperforms state-of-the-art decoding strategy.
</details>
<details>
<summary>摘要</summary>
Through an analysis of loss distributions of code tokens, we find that code tokens can be divided into two categories: challenging tokens that are difficult to predict and confident tokens that can be easily inferred. The challenging tokens mainly appear at the beginning of a code block. Inspired by these findings, we propose a simple yet effective method called Adaptive Temperature (AdapT) sampling, which dynamically adjusts the temperature coefficient when decoding different tokens. We apply a larger temperature when sampling for challenging tokens, allowing LLMs to explore diverse choices. We employ a smaller temperature for confident tokens to avoid the influence of tail randomness noises.We apply AdapT sampling to LLMs with different sizes and conduct evaluations on two popular datasets. The results show that AdapT sampling significantly outperforms state-of-the-art decoding strategies.
</details></li>
</ul>
<hr>
<h2 id="HAE-RAE-Bench-Evaluation-of-Korean-Knowledge-in-Language-Models"><a href="#HAE-RAE-Bench-Evaluation-of-Korean-Knowledge-in-Language-Models" class="headerlink" title="HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models"></a>HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02706">http://arxiv.org/abs/2309.02706</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guijin Son, Hanwool Lee, Suwan Kim, Huiseo Kim, Jaecheol Lee, Je Won Yeom, Jihyu Jung, Jung Woo Kim, Songseong Kim</li>
<li>for: 本研究旨在评估大语言模型（LLMs）在韩语言和文化中的表现，以及语言特定模型（LLSMs）在语言知识领域的可行性。</li>
<li>methods: 本研究使用了6个任务，包括词汇、历史和通用知识，以评估语言模型在不同领域的表现。</li>
<li>results: 研究发现，使用专门为韩语言而设计的LLSMs可以与大型语言模型GPT-3.5相比，在语言特定知识领域具有相似的表现水平，而且这些模型比GPT-3.5更小。然而，当这些小型LMs被要求生成结构化答案时，它们却表现出很大的性能下降。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) pretrained on massive corpora exhibit remarkable capabilities across a wide range of tasks, however, the attention given to non-English languages has been limited in this field of research. To address this gap and assess the proficiency of language models in the Korean language and culture, we present HAE-RAE Bench, covering 6 tasks including vocabulary, history, and general knowledge. Our evaluation of language models on this benchmark highlights the potential advantages of employing Large Language-Specific Models(LLSMs) over a comprehensive, universal model like GPT-3.5. Remarkably, our study reveals that models approximately 13 times smaller than GPT-3.5 can exhibit similar performance levels in terms of language-specific knowledge retrieval. This observation underscores the importance of homogeneous corpora for training professional-level language-specific models. On the contrary, we also observe a perplexing performance dip in these smaller LMs when they are tasked to generate structured answers.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在庞大资料库中显示出惊人的能力，但对非英语语言的研究却受到了限制。为了填补这个隔阂并评估语言模型在韩语言和文化中的水平，我们提出了HAE-RAE Bench，包括6个任务，如词汇、历史和通用知识。我们对这个benchmark进行了语言模型的评估，并发现使用专门为某种语言而设计的大型语言模型（LLSM）比普通的大型语言模型GPT-3.5更有优势。另外，我们发现使用比GPT-3.5更小的模型可以达到类似的性能水平，这显示了专门针对某种语言的训练数据的重要性。然而，我们也发现这些更小的模型在生成结构化答案时表现出异常低的性能。
</details></li>
</ul>
<hr>
<h2 id="A-Joint-Study-of-Phrase-Grounding-and-Task-Performance-in-Vision-and-Language-Models"><a href="#A-Joint-Study-of-Phrase-Grounding-and-Task-Performance-in-Vision-and-Language-Models" class="headerlink" title="A Joint Study of Phrase Grounding and Task Performance in Vision and Language Models"></a>A Joint Study of Phrase Grounding and Task Performance in Vision and Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02691">http://arxiv.org/abs/2309.02691</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lil-lab/phrase_grounding">https://github.com/lil-lab/phrase_grounding</a></li>
<li>paper_authors: Noriyuki Kojima, Hadar Averbuch-Elor, Yoav Artzi</li>
<li>for: 本研究旨在研究自然语言理解中的视觉上下文中的语言抽象，即将语言抽象与图像区域相关联。</li>
<li>methods: 本研究使用了一种混合的方法，包括任务性能和语言抽象的联合研究，以及三个 benchmark 来研究语言抽象和任务之间的关系。</li>
<li>results: 研究结果表明，当代模型在语言抽象和任务解决方面存在不一致性，可以通过对语言抽象的粗粒训练来解决这一问题。<details>
<summary>Abstract</summary>
Key to tasks that require reasoning about natural language in visual contexts is grounding words and phrases to image regions. However, observing this grounding in contemporary models is complex, even if it is generally expected to take place if the task is addressed in a way that is conductive to generalization. We propose a framework to jointly study task performance and phrase grounding, and propose three benchmarks to study the relation between the two. Our results show that contemporary models demonstrate inconsistency between their ability to ground phrases and solve tasks. We show how this can be addressed through brute-force training on ground phrasing annotations, and analyze the dynamics it creates. Code and at available at https://github.com/lil-lab/phrase_grounding.
</details>
<details>
<summary>摘要</summary>
<SYS>    translate("Key to tasks that require reasoning about natural language in visual contexts is grounding words and phrases to image regions. However, observing this grounding in contemporary models is complex, even if it is generally expected to take place if the task is addressed in a way that is conductive to generalization. We propose a framework to jointly study task performance and phrase grounding, and propose three benchmarks to study the relation between the two. Our results show that contemporary models demonstrate inconsistency between their ability to ground phrases and solve tasks. We show how this can be addressed through brute-force training on ground phrasing annotations, and analyze the dynamics it creates. Code and at available at https://github.com/lil-lab/phrase_grounding.")</SYS>Here's the translation:键在需要基于自然语言的视觉上进行推理的任务中是将单词和短语与图像区域相关联。然而，现代模型中的这种相关性观察是复杂的，即使它们在一种通用化的方式下进行处理。我们提出了一个框架，用于同时研究任务性能和短语相关性，并提出了三个benchmark来研究这两者之间的关系。我们的结果显示，当今的模型在短语相关性和任务解决方面存在不一致性。我们展示了通过简单的粗略训练ground phrasing标注来解决这个问题，并分析了这种动态的创建。代码和数据可以在https://github.com/lil-lab/phrase_grounding上获取。
</details></li>
</ul>
<hr>
<h2 id="Implicit-Design-Choices-and-Their-Impact-on-Emotion-Recognition-Model-Development-and-Evaluation"><a href="#Implicit-Design-Choices-and-Their-Impact-on-Emotion-Recognition-Model-Development-and-Evaluation" class="headerlink" title="Implicit Design Choices and Their Impact on Emotion Recognition Model Development and Evaluation"></a>Implicit Design Choices and Their Impact on Emotion Recognition Model Development and Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03238">http://arxiv.org/abs/2309.03238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mimansa Jaiswal</li>
<li>for: 本论文的目的是提高情感认知的准确性和可靠性，探讨了多种情感认知领域中的挑战。</li>
<li>methods: 本研究使用了多种方法，包括数据采集、数据增强、注释分析和隐藏变量的检测等，以提高情感认知模型的准确性和可靠性。</li>
<li>results: 本研究的结果表明，采用控制压力等方法可以更好地反映真实的情感生成过程，并且可以避免因注释标签的主观性而导致的偏见。此外，本研究还提出了一种新的评价指标，可以更好地衡量情感认知模型的性能。<details>
<summary>Abstract</summary>
Emotion recognition is a complex task due to the inherent subjectivity in both the perception and production of emotions. The subjectivity of emotions poses significant challenges in developing accurate and robust computational models. This thesis examines critical facets of emotion recognition, beginning with the collection of diverse datasets that account for psychological factors in emotion production.   To handle the challenge of non-representative training data, this work collects the Multimodal Stressed Emotion dataset, which introduces controlled stressors during data collection to better represent real-world influences on emotion production. To address issues with label subjectivity, this research comprehensively analyzes how data augmentation techniques and annotation schemes impact emotion perception and annotator labels. It further handles natural confounding variables and variations by employing adversarial networks to isolate key factors like stress from learned emotion representations during model training. For tackling concerns about leakage of sensitive demographic variables, this work leverages adversarial learning to strip sensitive demographic information from multimodal encodings. Additionally, it proposes optimized sociological evaluation metrics aligned with cost-effective, real-world needs for model testing.   This research advances robust, practical emotion recognition through multifaceted studies of challenges in datasets, labels, modeling, demographic and membership variable encoding in representations, and evaluation. The groundwork has been laid for cost-effective, generalizable emotion recognition models that are less likely to encode sensitive demographic information.
</details>
<details>
<summary>摘要</summary>
emotional recognition 是一项复杂的任务，因为情感的感知和生产都具有主观性。这种主观性对计算机模型的开发带来了重大挑战。这个论文探讨了情感认知的重要方面，包括收集多样化的数据集，以 compte for psychological factors in emotion production。为了 Address non-representative 的训练数据问题，这个研究收集了 Multimodal Stressed Emotion 数据集，该数据集在数据收集时引入了控制的压力因素，以更好地表示真实世界中的影响。另外，这个研究还对数据增强技术和注释方案的影响进行了全面分析，以及模型中的人员变量编码。此外，它还使用了对抗网络来隔离学习过程中的压力因素，以避免模型中的敏感人员变量编码。此外，这个研究还提出了优化的社会学评价指标，以满足实际的成本效益需求。这些指标可以用于评价模型的性能，并且可以帮助避免模型中的敏感人员变量编码。总之，这个研究通过多方面的研究，提出了一些可行的方法来解决情感认知 task 中的挑战。这些方法可以帮助开发出可靠、实用的情感认知模型，并避免模型中的敏感人员变量编码。
</details></li>
</ul>
<hr>
<h2 id="Zero-Resource-Hallucination-Prevention-for-Large-Language-Models"><a href="#Zero-Resource-Hallucination-Prevention-for-Large-Language-Models" class="headerlink" title="Zero-Resource Hallucination Prevention for Large Language Models"></a>Zero-Resource Hallucination Prevention for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02654">http://arxiv.org/abs/2309.02654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyu Luo, Cao Xiao, Fenglong Ma<br>for: 这篇论文的目的是为了减少大语言模型（LLM）中的“幻视”现象，即模型生成的信息中包含无根据或错误的资讯。methods: 这篇论文使用了一种新的预先检测自我识别技术，称为“自我熟悉度”（SELF-FAMILIARITY），它评估模型对输入指令中的概念的熟悉程度，并在缺乏熟悉的情况下停止生成回答。results: 这篇论文的结果显示，使用 SELF-FAMILIARITY 技术可以与现有的方法相比，实现更高的检测性和可靠性，并且可以提高模型的解释性和应用性。<details>
<summary>Abstract</summary>
The prevalent use of large language models (LLMs) in various domains has drawn attention to the issue of "hallucination," which refers to instances where LLMs generate factually inaccurate or ungrounded information. Existing techniques for hallucination detection in language assistants rely on intricate fuzzy, specific free-language-based chain of thought (CoT) techniques or parameter-based methods that suffer from interpretability issues. Additionally, the methods that identify hallucinations post-generation could not prevent their occurrence and suffer from inconsistent performance due to the influence of the instruction format and model style. In this paper, we introduce a novel pre-detection self-evaluation technique, referred to as SELF-FAMILIARITY, which focuses on evaluating the model's familiarity with the concepts present in the input instruction and withholding the generation of response in case of unfamiliar concepts. This approach emulates the human ability to refrain from responding to unfamiliar topics, thus reducing hallucinations. We validate SELF-FAMILIARITY across four different large language models, demonstrating consistently superior performance compared to existing techniques. Our findings propose a significant shift towards preemptive strategies for hallucination mitigation in LLM assistants, promising improvements in reliability, applicability, and interpretability.
</details>
<details>
<summary>摘要</summary>
现在的大语言模型（LLM）在各个领域的普遍使用已引起“幻觉”的问题的注意。幻觉指的是LLM生成的信息中存在虚假或不准确的内容。现有的幻觉检测技术在语言助手中使用复杂的朗文、特定的自由语言链条件（CoT）技术或参数基本方法，但这些方法受到解释性问题的困扰。另外，这些方法只能在生成后进行检测，并且因为指令格式和模型风格的影响而具有不稳定性。在这篇论文中，我们提出了一种新的预测检测技术，称为自己熟悉性（SELF-FAMILIARITY），它是根据输入指令中的概念 Familiarity 来评估模型的熟悉度。如果模型对概念不熟悉，则避免生成响应。这种方法模仿人类在不熟悉话题时的行为，从而减少幻觉。我们在四个不同的大语言模型上验证了SELF-FAMILIARITY，并证明其性能与现有技术相比具有显著优势。我们的发现提出了一种重要的转移，即采用预防策略来mitigate幻觉在LLM助手中，这将提高可靠性、可用性和解释性。
</details></li>
</ul>
<hr>
<h2 id="Epi-Curriculum-Episodic-Curriculum-Learning-for-Low-Resource-Domain-Adaptation-in-Neural-Machine-Translation"><a href="#Epi-Curriculum-Episodic-Curriculum-Learning-for-Low-Resource-Domain-Adaptation-in-Neural-Machine-Translation" class="headerlink" title="Epi-Curriculum: Episodic Curriculum Learning for Low-Resource Domain Adaptation in Neural Machine Translation"></a>Epi-Curriculum: Episodic Curriculum Learning for Low-Resource Domain Adaptation in Neural Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02640">http://arxiv.org/abs/2309.02640</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keyu Chen, Di Zhuang, Mingchen Li, J. Morris Chang</li>
<li>for: 提高 Neural Machine Translation (NMT) 模型在新领域下的性能，尤其是在有限数据情况下。</li>
<li>methods: 提出了一种新的 episodic training 框架，以及一种denoised curriculum learning 技术，以增强模型对频率变化的适应力。</li>
<li>results: 实验表明，Epi-Curriculum 可以提高模型在 seen 和 unseen 频率下的性能，并且可以增强encoder 和 decoder 对频率变化的适应力。<details>
<summary>Abstract</summary>
Neural Machine Translation (NMT) models have become successful, but their performance remains poor when translating on new domains with a limited number of data. In this paper, we present a novel approach Epi-Curriculum to address low-resource domain adaptation (DA), which contains a new episodic training framework along with denoised curriculum learning. Our episodic training framework enhances the model's robustness to domain shift by episodically exposing the encoder/decoder to an inexperienced decoder/encoder. The denoised curriculum learning filters the noised data and further improves the model's adaptability by gradually guiding the learning process from easy to more difficult tasks. Experiments on English-German and English-Romanian translation show that: (i) Epi-Curriculum improves both model's robustness and adaptability in seen and unseen domains; (ii) Our episodic training framework enhances the encoder and decoder's robustness to domain shift.
</details>
<details>
<summary>摘要</summary>
神经机器翻译（NMT）模型已经成功，但其性能在新领域 WITH 有限数据时仍然不佳。在这篇论文中，我们提出了一种新的方法：Epi-Curriculum，用于解决低资源领域适应（DA）问题。我们的 episodic 训练框架可以增强模型对频率转换的抵抗力，通过在不熟悉的decoder/encoder中进行 episodic 训练。另外，我们的denoised curriculum learning 技术可以进一步提高模型的适应性，通过逐渐引导学习过程从容易到更加difficult任务。我们在英语-德语和英语-罗马尼亚翻译 задании进行了实验，结果表明：1. Epi-Curriculum 可以提高模型在seen和unseen领域中的 robustness 和适应性。2. 我们的 episodic 训练框架可以增强encoder和decoder对频率转换的抵抗力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/06/cs.CL_2023_09_06/" data-id="clmvt7t8m008b26rdfbj25fqq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/06/cs.LG_2023_09_06/" class="article-date">
  <time datetime="2023-09-06T10:00:00.000Z" itemprop="datePublished">2023-09-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/06/cs.LG_2023_09_06/">cs.LG - 2023-09-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Ensemble-linear-interpolators-The-role-of-ensembling"><a href="#Ensemble-linear-interpolators-The-role-of-ensembling" class="headerlink" title="Ensemble linear interpolators: The role of ensembling"></a>Ensemble linear interpolators: The role of ensembling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03354">http://arxiv.org/abs/2309.03354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingqi Wu, Qiang Sun</li>
<li>for: 这个论文研究了 ensemble 如何稳定化和提高泛化性能，特别是在 dealing with noisy data 时。</li>
<li>methods: 这个论文使用了 bagging 和 multiplier-bootstrap 等随机化方法来实现 ensemble。</li>
<li>results: 研究发现，bagging 可以有效地减少 interpolator 的偏差和噪声，从而提高泛化性能。此外，研究还发现了 sketching 和 bagging 在不同参数空间下的统计作用。<details>
<summary>Abstract</summary>
Interpolators are unstable. For example, the mininum $\ell_2$ norm least square interpolator exhibits unbounded test errors when dealing with noisy data. In this paper, we study how ensemble stabilizes and thus improves the generalization performance, measured by the out-of-sample prediction risk, of an individual interpolator. We focus on bagged linear interpolators, as bagging is a popular randomization-based ensemble method that can be implemented in parallel. We introduce the multiplier-bootstrap-based bagged least square estimator, which can then be formulated as an average of the sketched least square estimators. The proposed multiplier bootstrap encompasses the classical bootstrap with replacement as a special case, along with a more intriguing variant which we call the Bernoulli bootstrap.   Focusing on the proportional regime where the sample size scales proportionally with the feature dimensionality, we investigate the out-of-sample prediction risks of the sketched and bagged least square estimators in both underparametrized and overparameterized regimes. Our results reveal the statistical roles of sketching and bagging. In particular, sketching modifies the aspect ratio and shifts the interpolation threshold of the minimum $\ell_2$ norm estimator. However, the risk of the sketched estimator continues to be unbounded around the interpolation threshold due to excessive variance. In stark contrast, bagging effectively mitigates this variance, leading to a bounded limiting out-of-sample prediction risk. To further understand this stability improvement property, we establish that bagging acts as a form of implicit regularization, substantiated by the equivalence of the bagged estimator with its explicitly regularized counterpart. We also discuss several extensions.
</details>
<details>
<summary>摘要</summary>
interpolators are unstable. for example, the minimum $\ell_2$ norm least square interpolator exhibits unbounded test errors when dealing with noisy data. in this paper, we study how ensemble stabilizes and thus improves the generalization performance, measured by the out-of-sample prediction risk, of an individual interpolator. we focus on bagged linear interpolators, as bagging is a popular randomization-based ensemble method that can be implemented in parallel. we introduce the multiplier-bootstrap-based bagged least square estimator, which can then be formulated as an average of the sketched least square estimators. the proposed multiplier bootstrap encompasses the classical bootstrap with replacement as a special case, along with a more intriguing variant which we call the Bernoulli bootstrap.  focusing on the proportional regime where the sample size scales proportionally with the feature dimensionality, we investigate the out-of-sample prediction risks of the sketched and bagged least square estimators in both underparametrized and overparameterized regimes. our results reveal the statistical roles of sketching and bagging. in particular, sketching modifies the aspect ratio and shifts the interpolation threshold of the minimum $\ell_2$ norm estimator. however, the risk of the sketched estimator continues to be unbounded around the interpolation threshold due to excessive variance. in stark contrast, bagging effectively mitigates this variance, leading to a bounded limiting out-of-sample prediction risk. to further understand this stability improvement property, we establish that bagging acts as a form of implicit regularization, substantiated by the equivalence of the bagged estimator with its explicitly regularized counterpart. we also discuss several extensions.
</details></li>
</ul>
<hr>
<h2 id="Robotic-Table-Tennis-A-Case-Study-into-a-High-Speed-Learning-System"><a href="#Robotic-Table-Tennis-A-Case-Study-into-a-High-Speed-Learning-System" class="headerlink" title="Robotic Table Tennis: A Case Study into a High Speed Learning System"></a>Robotic Table Tennis: A Case Study into a High Speed Learning System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03315">http://arxiv.org/abs/2309.03315</a></li>
<li>repo_url: None</li>
<li>paper_authors: David B. D’Ambrosio, Jonathan Abelian, Saminda Abeyruwan, Michael Ahn, Alex Bewley, Justin Boyd, Krzysztof Choromanski, Omar Cortes, Erwin Coumans, Tianli Ding, Wenbo Gao, Laura Graesser, Atil Iscen, Navdeep Jaitly, Deepali Jain, Juhana Kangaspunta, Satoshi Kataoka, Gus Kouretas, Yuheng Kuang, Nevena Lazic, Corey Lynch, Reza Mahjourian, Sherry Q. Moore, Thinh Nguyen, Ken Oslund, Barney J Reed, Krista Reymann, Pannag R. Sanketi, Anish Shankar, Pierre Sermanet, Vikas Sindhwani, Avi Singh, Vincent Vanhoucke, Grace Vesom, Peng Xu</li>
<li>for: 本研究探讨了一个真实世界机器人学习系统，该系统在前一项研究中已经能够与人类进行数百次网球比赛，并且可以准确返回球到 désiré 目标。</li>
<li>methods: 该系统使用了优化的感知子系统、高速低延迟的机器人控制器、可预防实际世界损害的模拟平台，以及自动化的实际世界环境重置，以便在物理机器人上进行自主训练和评估。</li>
<li>results: 研究人员通过详细描述系统的全部设计决策，以及一系列的研究，解释了mitigate多种延迟的重要性、训练和部署分布shift的考虑、感知系统的Robustness、策略参数的敏感性和行动空间的选择。视频展示了系统的组件和实验结果的细节，可以在<a target="_blank" rel="noopener" href="https://youtu.be/uFcnWjB42I0%E6%89%BE%E5%88%B0%E3%80%82">https://youtu.be/uFcnWjB42I0找到。</a><details>
<summary>Abstract</summary>
We present a deep-dive into a real-world robotic learning system that, in previous work, was shown to be capable of hundreds of table tennis rallies with a human and has the ability to precisely return the ball to desired targets. This system puts together a highly optimized perception subsystem, a high-speed low-latency robot controller, a simulation paradigm that can prevent damage in the real world and also train policies for zero-shot transfer, and automated real world environment resets that enable autonomous training and evaluation on physical robots. We complement a complete system description, including numerous design decisions that are typically not widely disseminated, with a collection of studies that clarify the importance of mitigating various sources of latency, accounting for training and deployment distribution shifts, robustness of the perception system, sensitivity to policy hyper-parameters, and choice of action space. A video demonstrating the components of the system and details of experimental results can be found at https://youtu.be/uFcnWjB42I0.
</details>
<details>
<summary>摘要</summary>
我们提供了一个深入探讨真实世界机器人学习系统的文章，之前的研究已经证明该系统可以与人类进行数百个桌球赛，并且可以准确返回杯子到愿意的目标上。这个系统结合了高度优化的感知子系统，高速低延迟的机器人控制器，可以防止实际世界中的损害并用于零战斗训练和评估，以及自动化的实际环境重置。我们补充了完整的系统描述，包括多个设计决策，通常不宜公开，以及一系列研究，解释了减少各种延迟的重要性，训练和部署分布shift的考虑，感知系统的稳定性，策略参数的敏感性，和动作空间的选择。一个详细展示系统组件和实验结果的视频可以在https://youtu.be/uFcnWjB42I0找到。
</details></li>
</ul>
<hr>
<h2 id="Scalable-Learning-of-Intrusion-Responses-through-Recursive-Decomposition"><a href="#Scalable-Learning-of-Intrusion-Responses-through-Recursive-Decomposition" class="headerlink" title="Scalable Learning of Intrusion Responses through Recursive Decomposition"></a>Scalable Learning of Intrusion Responses through Recursive Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03292">http://arxiv.org/abs/2309.03292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kim Hammar, Rolf Stadler</li>
<li>for: 本研究旨在自动化网络入侵响应，以提高IT基础设施的安全性。</li>
<li>methods: 本研究使用了半观察游戏理论和自适应学习来解决攻击者和防御者之间的互动。为解决大规模游戏的计算复杂性问题，我们提出了一种将游戏划分成多个子游戏的方法，并使用优化停止理论来计算最佳回应策略。</li>
<li>results: 我们在一个模拟环境中评估了学习的策略，并发现它们可以准确地模拟攻击者和防御者之间的互动。相比之下，一种现有的算法在一个真实的基础设施配置下表现较差。<details>
<summary>Abstract</summary>
We study automated intrusion response for an IT infrastructure and formulate the interaction between an attacker and a defender as a partially observed stochastic game. To solve the game we follow an approach where attack and defense strategies co-evolve through reinforcement learning and self-play toward an equilibrium. Solutions proposed in previous work prove the feasibility of this approach for small infrastructures but do not scale to realistic scenarios due to the exponential growth in computational complexity with the infrastructure size. We address this problem by introducing a method that recursively decomposes the game into subgames which can be solved in parallel. Applying optimal stopping theory we show that the best response strategies in these subgames exhibit threshold structures, which allows us to compute them efficiently. To solve the decomposed game we introduce an algorithm called Decompositional Fictitious Self-Play (DFSP), which learns Nash equilibria through stochastic approximation. We evaluate the learned strategies in an emulation environment where real intrusions and response actions can be executed. The results show that the learned strategies approximate an equilibrium and that DFSP significantly outperforms a state-of-the-art algorithm for a realistic infrastructure configuration.
</details>
<details>
<summary>摘要</summary>
我们研究自动化入侵应急回应概念，将攻击者和防御者之间的互动视为一个部分可见随机游戏。为解决这个游戏，我们采用一种方法，其中攻击和防御策略通过反射学习和自我玩家的共演演化向Equilibrium。先前的解决方案虽有可能性，但由于基础设施规模的幂等增长，无法承受实际场景中的游戏。为解决这个问题，我们提出一种方法，即 recursively decomposing the game into subgames，可以并发解决。通过优质停止理论，我们表明攻击策略在这些子游戏中具有阈值结构，可以有效计算。为解决分解的游戏，我们提出了一种算法，即 Decompositional Fictitious Self-Play（DFSP），它通过随机approximation学习Nash equilibria。在模拟环境中，我们测试了学习到的策略，结果表明学习策略接近Equilibrium，并且DFSP在一个实际基础设施配置下显著超越了当前状态艺术算法。
</details></li>
</ul>
<hr>
<h2 id="R2D2-Deep-neural-network-series-for-near-real-time-high-dynamic-range-imaging-in-radio-astronomy"><a href="#R2D2-Deep-neural-network-series-for-near-real-time-high-dynamic-range-imaging-in-radio-astronomy" class="headerlink" title="R2D2: Deep neural network series for near real-time high-dynamic range imaging in radio astronomy"></a>R2D2: Deep neural network series for near real-time high-dynamic range imaging in radio astronomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03291">http://arxiv.org/abs/2309.03291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aghabiglou A, Chu C S, Jackson A, Dabbech A, Wiaux Y<br>for: 这个论文是用于描述一种基于深度神经网络（DNN）和数据一致更新的新型人工智能（AI）方法，用于高分辨率高动态范围成像探测天文学中的电波天文学（RI）。methods: 该方法基于混合的DNN和数据一致更新，其重建是通过一系列的差分图像来实现，每个差分图像被视为DNN的输出。该方法可以看作是一种学习的匹配追踪方法，其中模型组件是通过差分尘埃图像来逐步确定。results: 在使用S射频的Cygnus~A观测数据上，R2D2模型可以提供高精度的成像，与CLEAN和AIRI&#x2F;uSARA等其他算法相当。R2D2模型的计算效率远高于AIRI和uSARA，并且比CLEAN更快，这些成果都表明了R2D2模型在RI成像中的优势。<details>
<summary>Abstract</summary>
We present a novel AI approach for high-resolution high-dynamic range synthesis imaging by radio interferometry (RI) in astronomy. R2D2, standing for "{R}esidual-to-{R}esidual {D}NN series for high-{D}ynamic range imaging", is a model-based data-driven approach relying on hybrid deep neural networks (DNNs) and data-consistency updates. Its reconstruction is built as a series of residual images estimated as the outputs of DNNs, each taking the residual dirty image of the previous iteration as an input. The approach can be interpreted as a learned version of a matching pursuit approach, whereby model components are iteratively identified from residual dirty images, and of which CLEAN is a well-known example. We propose two variants of the R2D2 model, built upon two distinctive DNN architectures: a standard U-Net, and a novel unrolled architecture. We demonstrate their use for monochromatic intensity imaging on highly-sensitive observations of the radio galaxy Cygnus~A at S band, from the Very Large Array (VLA). R2D2 is validated against CLEAN and the recent RI algorithms AIRI and uSARA, which respectively inject a learned implicit regularization and an advanced handcrafted sparsity-based regularization into the RI data. With only few terms in its series, the R2D2 model is able to deliver high-precision imaging, significantly superior to CLEAN and matching the precision of AIRI and uSARA. In terms of computational efficiency, R2D2 runs at a fraction of the cost of AIRI and uSARA, and is also faster than CLEAN, opening the door to real-time precision imaging in RI.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的人工智能方法，用于高解度高动态范围成像探测（RI）在天文学中。我们称之为“R2D2”，即“差异到差异的深度神经网络系列 для高动态范围成像”。这种方法基于混合深度神经网络（DNN）和数据一致更新。它的重建是建立为一系列的差异图像，每个差异图像被视为前一轮差异 dirty image 的输入。这种方法可以被视为一种学习的匹配追踪方法，其中模型元件是通过差异 dirty images 进行逐步确定。我们提出了两种基于不同 DNN 架构的 R2D2 模型：标准 U-Net 和一种新的折衣架构。我们示出了它们在单色强度成像中的应用，使用 Very Large Array（VLA）对天鹅星系 Cygnus A 进行了高敏感观测。R2D2 被证明比 CLEAN 和 reciently 的 RI 算法 AIRI 和 uSARA 更高精度，并且在计算效率方面也更高，能够在实时高精度成像中具有优势。
</details></li>
</ul>
<hr>
<h2 id="Let-Quantum-Neural-Networks-Choose-Their-Own-Frequencies"><a href="#Let-Quantum-Neural-Networks-Choose-Their-Own-Frequencies" class="headerlink" title="Let Quantum Neural Networks Choose Their Own Frequencies"></a>Let Quantum Neural Networks Choose Their Own Frequencies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03279">http://arxiv.org/abs/2309.03279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Jaderberg, Antonio A. Gentile, Youssef Achari Berrada, Elvira Shishenina, Vincent E. Elfving</li>
<li>for: 这篇论文旨在探讨 parameterized quantum circuit 作为机器学习模型，以及其中的代表性函数的幂展开。</li>
<li>methods: 作者使用了一种通过增加可训练参数来扩展传统固定频率模型的方法，以便学习更适合任务的生成器。</li>
<li>results: 作者通过数值示例表明，这种方法可以学习出具有恰当特性的生成器，包括非Regularly spaced 频谱和灵活的 spectral richness。此外，作者还实际应用了这种方法，并达到了解决 Navier-Stokes 方程的更高精度。<details>
<summary>Abstract</summary>
Parameterized quantum circuits as machine learning models are typically well described by their representation as a partial Fourier series of the input features, with frequencies uniquely determined by the feature map's generator Hamiltonians. Ordinarily, these data-encoding generators are chosen in advance, fixing the space of functions that can be represented. In this work we consider a generalization of quantum models to include a set of trainable parameters in the generator, leading to a trainable frequency (TF) quantum model. We numerically demonstrate how TF models can learn generators with desirable properties for solving the task at hand, including non-regularly spaced frequencies in their spectra and flexible spectral richness. Finally, we showcase the real-world effectiveness of our approach, demonstrating an improved accuracy in solving the Navier-Stokes equations using a TF model with only a single parameter added to each encoding operation. Since TF models encompass conventional fixed frequency models, they may offer a sensible default choice for variational quantum machine learning.
</details>
<details>
<summary>摘要</summary>
Parameterized量子Circuits作为机器学习模型通常由其输入特征的 partial Fourier 系列描述，它们的频率唯一由特征映射生成器的 Hamiltonians Determined。通常情况下，这些数据编码生成器在先前选择，确定了可以表示的函数空间。在这项工作中，我们考虑了量子模型的总体化，包括在生成器中添加可学习参数，导致可学习频率（TF）量子模型。我们数值示示了TF模型可以学习符合任务的 generator 的恰当性，包括非 Regularly spaced 的频谱和灵活的 spectral richness。最后，我们展示了我们的方法的实际效果，通过在每个编码操作中添加单个参数来提高解决 Navier-Stokes 方程的精度。由于 TF 模型包括 fixede frequency 模型，它们可能成为变量量子机器学习的合理默认选择。
</details></li>
</ul>
<hr>
<h2 id="Matcha-TTS-A-fast-TTS-architecture-with-conditional-flow-matching"><a href="#Matcha-TTS-A-fast-TTS-architecture-with-conditional-flow-matching" class="headerlink" title="Matcha-TTS: A fast TTS architecture with conditional flow matching"></a>Matcha-TTS: A fast TTS architecture with conditional flow matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03199">http://arxiv.org/abs/2309.03199</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shivammehta25/Matcha-TTS">https://github.com/shivammehta25/Matcha-TTS</a></li>
<li>paper_authors: Shivam Mehta, Ruibo Tu, Jonas Beskow, Éva Székely, Gustav Eje Henter</li>
<li>for: 这个研究是为了提出一个新的encoder-decoder架构，实现快速的语音处理模型，并且使用最佳运输汇流匹配（OT-CFM）进行训练。</li>
<li>methods: 这个模型使用了一个基于射影函数的数据驱动的decoder，并且通过调整特定的设计选择，使每个合成步骤的运行时间变得更加快速。这个模型是 probabilistic、非 autoregressive，并且从零学习说话。</li>
<li>results: 与对照模型相比，Matcha-TTS系统具有最小的内存占用量，在长语音上与最快的模型相当，并且在听力测试中获得了最高的意见分数。另外，这个系统还提供了一些audio例子、代码和预训练模型，请参考<a target="_blank" rel="noopener" href="https://shivammehta25.github.io/Matcha-TTS/%E3%80%82">https://shivammehta25.github.io/Matcha-TTS/。</a><details>
<summary>Abstract</summary>
We introduce Matcha-TTS, a new encoder-decoder architecture for speedy TTS acoustic modelling, trained using optimal-transport conditional flow matching (OT-CFM). This yields an ODE-based decoder capable of high output quality in fewer synthesis steps than models trained using score matching. Careful design choices additionally ensure each synthesis step is fast to run. The method is probabilistic, non-autoregressive, and learns to speak from scratch without external alignments. Compared to strong pre-trained baseline models, the Matcha-TTS system has the smallest memory footprint, rivals the speed of the fastest models on long utterances, and attains the highest mean opinion score in a listening test. Please see https://shivammehta25.github.io/Matcha-TTS/ for audio examples, code, and pre-trained models.
</details>
<details>
<summary>摘要</summary>
我们介绍Matcha-TTS，一个新的编码器-解码器架构，用于快速的干扰声模型训练，使用最佳交通流匹配（OT-CFM）。这个方法使得解码器能够在 fewer synthesis steps 中实现高质量输出，比较Score Matching 训练的模型更快。我们在设计时遵循了一些精心选择，使每个合成步骤都很快。Matcha-TTS 是一个 probabilistic 、非自律的系统，可以从零开始学习说话，不需要外部对齐。相比强大的预训练基eline模型，Matcha-TTS 系统具有最小的内存占用量，在长句子上的速度与最快的模型相当，并在聆听测试中获得了最高的意见分数。您可以参考 <https://shivammehta25.github.io/Matcha-TTS/> 获取音频示例、代码和预训练模型。
</details></li>
</ul>
<hr>
<h2 id="Blink-Link-Local-Differential-Privacy-in-Graph-Neural-Networks-via-Bayesian-Estimation"><a href="#Blink-Link-Local-Differential-Privacy-in-Graph-Neural-Networks-via-Bayesian-Estimation" class="headerlink" title="Blink: Link Local Differential Privacy in Graph Neural Networks via Bayesian Estimation"></a>Blink: Link Local Differential Privacy in Graph Neural Networks via Bayesian Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03190">http://arxiv.org/abs/2309.03190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhxchd/blink_gnn">https://github.com/zhxchd/blink_gnn</a></li>
<li>paper_authors: Xiaochen Zhu, Vincent Y. F. Tan, Xiaokui Xiao</li>
<li>for: 防止训练 Graph Neural Networks (GNNs) 时提高隐私投入，使得 Collaborative Graph Learning 可以在不披露图structure的情况下进行。</li>
<li>methods: 使用 link local differential privacy over decentralized nodes，通过 Bayesian estimation 更好地减少图像噪声，使得 GNNs 的训练不受隐私影响。</li>
<li>results: 提出了两种隐私机制，可以根据不同的隐私预算来选择合适的机制，并提出了一种 hybrid 机制，可以在不同的隐私预算下表现更好。实验结果表明，我们的方法可以在不同的隐私预算下提高 GNNs 的准确性。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) have gained an increasing amount of popularity due to their superior capability in learning node embeddings for various graph inference tasks, but training them can raise privacy concerns. To address this, we propose using link local differential privacy over decentralized nodes, enabling collaboration with an untrusted server to train GNNs without revealing the existence of any link. Our approach spends the privacy budget separately on links and degrees of the graph for the server to better denoise the graph topology using Bayesian estimation, alleviating the negative impact of LDP on the accuracy of the trained GNNs. We bound the mean absolute error of the inferred link probabilities against the ground truth graph topology. We then propose two variants of our LDP mechanism complementing each other in different privacy settings, one of which estimates fewer links under lower privacy budgets to avoid false positive link estimates when the uncertainty is high, while the other utilizes more information and performs better given relatively higher privacy budgets. Furthermore, we propose a hybrid variant that combines both strategies and is able to perform better across different privacy budgets. Extensive experiments show that our approach outperforms existing methods in terms of accuracy under varying privacy budgets.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 在不同的图像任务中学习节点嵌入显示出了不断增长的潜力，但是它们的训练可能会引起隐私问题。为了解决这问题，我们提出了基于图像的链地方 differential privacy（LDP），允许不可信服务器在训练 GNNs 时不 revela any 链的存在。我们的方法在服务器端分配隐私预算，并使用某些隐私技术来更好地降噪图像，从而减轻 LDP 对训练 GNNs 的影响。我们对推测的链probability bound the mean absolute error against the ground truth graph topology。我们还提出了两种不同的隐私设定下的LDP机制，一种优先采用 fewer links 来避免高度不确定性时的假阳性链估计，另一种则可以在更高的隐私预算下获得更好的性能。最后，我们提出了一种混合机制，可以在不同的隐私预算下实现更好的性能。我们的实验表明，我们的方法在不同的隐私预算下都能够超越现有的方法。
</details></li>
</ul>
<hr>
<h2 id="Impression-Informed-Multi-Behavior-Recommender-System-A-Hierarchical-Graph-Attention-Approach"><a href="#Impression-Informed-Multi-Behavior-Recommender-System-A-Hierarchical-Graph-Attention-Approach" class="headerlink" title="Impression-Informed Multi-Behavior Recommender System: A Hierarchical Graph Attention Approach"></a>Impression-Informed Multi-Behavior Recommender System: A Hierarchical Graph Attention Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03169">http://arxiv.org/abs/2309.03169</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dong Li, Divya Bhargavi, Vidya Sagar Ravipati</li>
<li>for: This paper aims to address the limitations of traditional recommender systems that rely solely on implicit feedback, such as item purchases, by incorporating multi-behavior interactions and hierarchical attention mechanisms to improve the accuracy of recommendations.</li>
<li>methods: The proposed Hierarchical Multi-behavior Graph Attention Network (HMGN) utilizes attention mechanisms to distinguish between different types of behaviors and hierarchical Bayesian personalized ranking for optimization. The model also incorporates a specialized multi-behavior sub-graph sampling technique and can seamlessly integrate knowledge metadata and time-series data.</li>
<li>results: The paper reports up to 64% performance boost in NDCG@100 metrics compared to conventional graph neural network methods, demonstrating the effectiveness of the proposed HMGN model in improving the accuracy of recommendations based on multi-behavior interactions.<details>
<summary>Abstract</summary>
While recommender systems have significantly benefited from implicit feedback, they have often missed the nuances of multi-behavior interactions between users and items. Historically, these systems either amalgamated all behaviors, such as \textit{impression} (formerly \textit{view}), \textit{add-to-cart}, and \textit{buy}, under a singular 'interaction' label, or prioritized only the target behavior, often the \textit{buy} action, discarding valuable auxiliary signals. Although recent advancements tried addressing this simplification, they primarily gravitated towards optimizing the target behavior alone, battling with data scarcity. Additionally, they tended to bypass the nuanced hierarchy intrinsic to behaviors. To bridge these gaps, we introduce the \textbf{H}ierarchical \textbf{M}ulti-behavior \textbf{G}raph Attention \textbf{N}etwork (HMGN). This pioneering framework leverages attention mechanisms to discern information from both inter and intra-behaviors while employing a multi-task Hierarchical Bayesian Personalized Ranking (HBPR) for optimization. Recognizing the need for scalability, our approach integrates a specialized multi-behavior sub-graph sampling technique. Moreover, the adaptability of HMGN allows for the seamless inclusion of knowledge metadata and time-series data. Empirical results attest to our model's prowess, registering a notable performance boost of up to 64\% in NDCG@100 metrics over conventional graph neural network methods.
</details>
<details>
<summary>摘要</summary>
历史上，推荐系统往往忽略了用户和物品之间的多种互动行为的细节。这些系统可能会将所有行为都汇总到一个单一的“互动”标签下，或者仅仅优先级化目标行为（通常是购买行为），抛弃了有价值的辅助信号。虽然最近的进步尝试了解决这些简化，但它们主要是专注于优化目标行为，面临着数据缺乏问题。此外，它们往往忽略了行为之间的层次结构。为了bridging这些差距，我们介绍了一种新的 Hierarchical Multi-behavior Graph Attention Network (HMGN)。这种革新的框架利用了注意力机制，以便在多种互动行为之间找出信息，同时使用多任务的层次 bayesian个性化排序（HBPR）进行优化。我们的方法还 integrates 特殊的多种互动子图采样技术，以确保可扩展性。此外，HMGN 还可以轻松地包含知识metadata和时间序列数据。实验结果表明，我们的模型在 NDCG@100 指标上具有显著的性能提升，高达 64%，较 conventional graph neural network 方法更出色。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Recharge-UAV-Coverage-Path-Planning-through-Deep-Reinforcement-Learning"><a href="#Learning-to-Recharge-UAV-Coverage-Path-Planning-through-Deep-Reinforcement-Learning" class="headerlink" title="Learning to Recharge: UAV Coverage Path Planning through Deep Reinforcement Learning"></a>Learning to Recharge: UAV Coverage Path Planning through Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03157">http://arxiv.org/abs/2309.03157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/theilem/uavSim">https://github.com/theilem/uavSim</a></li>
<li>paper_authors: Mirco Theile, Harald Bayerlein, Marco Caccamo, Alberto L. Sangiovanni-Vincentelli</li>
<li>for:  solving the power-constrained coverage path planning problem for battery-limited unmanned aerial vehicles (UAVs)</li>
<li>methods:  using a novel proximal policy optimization (PPO)-based deep reinforcement learning (DRL) approach with map-based observations, action masking, and discount factor scheduling</li>
<li>results:  outperforming a baseline heuristic, generalizing to different target zones and maps, with limited generalization to unseen maps.<details>
<summary>Abstract</summary>
Coverage path planning (CPP) is a critical problem in robotics, where the goal is to find an efficient path that covers every point in an area of interest. This work addresses the power-constrained CPP problem with recharge for battery-limited unmanned aerial vehicles (UAVs). In this problem, a notable challenge emerges from integrating recharge journeys into the overall coverage strategy, highlighting the intricate task of making strategic, long-term decisions. We propose a novel proximal policy optimization (PPO)-based deep reinforcement learning (DRL) approach with map-based observations, utilizing action masking and discount factor scheduling to optimize coverage trajectories over the entire mission horizon. We further provide the agent with a position history to handle emergent state loops caused by the recharge capability. Our approach outperforms a baseline heuristic, generalizes to different target zones and maps, with limited generalization to unseen maps. We offer valuable insights into DRL algorithm design for long-horizon problems and provide a publicly available software framework for the CPP problem.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Data-Driven-Neural-Polar-Codes-for-Unknown-Channels-With-and-Without-Memory"><a href="#Data-Driven-Neural-Polar-Codes-for-Unknown-Channels-With-and-Without-Memory" class="headerlink" title="Data-Driven Neural Polar Codes for Unknown Channels With and Without Memory"></a>Data-Driven Neural Polar Codes for Unknown Channels With and Without Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03148">http://arxiv.org/abs/2309.03148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziv Aharoni, Bashar Huleihel, Henry D. Pfister, Haim H. Permuter</li>
<li>for: 这个论文是为了设计具有内存和无内存通道的浮点码而提出的一种数据驱动方法。</li>
<li>methods: 这种方法利用了successive cancellation（SC）解码器的结构，通过将SC解码器的核心元素 replaced by neural networks（NNs）来设计一个名为 neural SC（NSC）解码器。此外，还增加了一个NN来嵌入通道输出到SC解码器的输入空间。</li>
<li>results: 该方法被证明有理论保证，其计算复杂度不随通道内存大小增长，与successive cancellation trellis（SCT）解码器不同。在memoryless通道和具有内存通道上，实验结果与最佳浮点解码器相比较好。此外，该方法还可以应用于SC和SCT解码器不可用的情况。<details>
<summary>Abstract</summary>
In this work, a novel data-driven methodology for designing polar codes for channels with and without memory is proposed. The methodology is suitable for the case where the channel is given as a "black-box" and the designer has access to the channel for generating observations of its inputs and outputs, but does not have access to the explicit channel model. The proposed method leverages the structure of the successive cancellation (SC) decoder to devise a neural SC (NSC) decoder. The NSC decoder uses neural networks (NNs) to replace the core elements of the original SC decoder, the check-node, the bit-node and the soft decision. Along with the NSC, we devise additional NN that embeds the channel outputs into the input space of the SC decoder. The proposed method is supported by theoretical guarantees that include the consistency of the NSC. Also, the NSC has computational complexity that does not grow with the channel memory size. This sets its main advantage over successive cancellation trellis (SCT) decoder for finite state channels (FSCs) that has complexity of $O(|\mathcal{S}|^3 N\log N)$, where $|\mathcal{S}|$ denotes the number of channel states. We demonstrate the performance of the proposed algorithms on memoryless channels and on channels with memory. The empirical results are compared with the optimal polar decoder, given by the SC and SCT decoders. We further show that our algorithms are applicable for the case where there SC and SCT decoders are not applicable.
</details>
<details>
<summary>摘要</summary>
“在这项工作中，我们提出了一种新的数据驱动方法，用于设计极码 для无记忆和具有记忆的通道。这种方法适用于 Situation where the channel is given as a "black-box" and the designer has access to the channel for generating observations of its inputs and outputs, but does not have access to the explicit channel model。我们的方法利用了成功的极化缓冲（SC）解码器的结构，并使用神经网络（NN）来替换SC解码器的核心元素，包括检查节点、位节点和软决策。此外，我们还提出了一个额外的NN，用于将通道输出嵌入到SC解码器的输入空间中。我们的方法得到了理论保证，包括NSC的一致性，并且NSC的计算复杂度不随通道记忆大小增长。这个特点使得NSC在对于有限状态通道（FSC）上的计算复杂度为O($|\mathcal{S}|^3N\log N$),而SCT解码器的计算复杂度为O($|\mathcal{S}|^3N^2\log N$).我们在无记忆通道和具有记忆通道上对方法进行了实验，并与最佳极码解码器（SC和SCT解码器）进行了比较。我们还证明了我们的方法在SC和SCT解码器不可用的情况下也适用。”
</details></li>
</ul>
<hr>
<h2 id="The-Best-Arm-Evades-Near-optimal-Multi-pass-Streaming-Lower-Bounds-for-Pure-Exploration-in-Multi-armed-Bandits"><a href="#The-Best-Arm-Evades-Near-optimal-Multi-pass-Streaming-Lower-Bounds-for-Pure-Exploration-in-Multi-armed-Bandits" class="headerlink" title="The Best Arm Evades: Near-optimal Multi-pass Streaming Lower Bounds for Pure Exploration in Multi-armed Bandits"></a>The Best Arm Evades: Near-optimal Multi-pass Streaming Lower Bounds for Pure Exploration in Multi-armed Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03145">http://arxiv.org/abs/2309.03145</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sepehr Assadi, Chen Wang</li>
<li>for: 这个论文是为了解决多支枪（Multi-armed bandits）中的纯exploration问题，提出了一种near-optimal的样本传递贸易，即使使用流式算法并不需要较高的内存占用。</li>
<li>methods: 这个论文使用了流式算法，并且使用了优化的样本复杂度为$O(\frac{n}{\Delta^2}$，其中$n$是枪数和$\Delta$是奖励差值。</li>
<li>results: 这个论文得到了与 Jin et al. 的 ICML’21 论文（即使下个数）匹配的结果，即使用$O(1)$内存可以得到$O(\log(\frac{1}{\Delta}))$ 的pass结果，并解决了Assadi和Wang 在 STOC’20 上提出的一个开问。<details>
<summary>Abstract</summary>
We give a near-optimal sample-pass trade-off for pure exploration in multi-armed bandits (MABs) via multi-pass streaming algorithms: any streaming algorithm with sublinear memory that uses the optimal sample complexity of $O(\frac{n}{\Delta^2})$ requires $\Omega(\frac{\log{(1/\Delta)}{\log\log{(1/\Delta)})$ passes. Here, $n$ is the number of arms and $\Delta$ is the reward gap between the best and the second-best arms. Our result matches the $O(\log(\frac{1}{\Delta}))$-pass algorithm of Jin et al. [ICML'21] (up to lower order terms) that only uses $O(1)$ memory and answers an open question posed by Assadi and Wang [STOC'20].
</details>
<details>
<summary>摘要</summary>
我们提供了一个近似优化的样本传递协议 для纯探索在多重抓枪（MAB）中，通过多重流程算法：任何流程算法具有线性内存使用最佳样本复杂度为$O(\frac{n}{\Delta^2})$，需要$\Omega(\frac{\log{(1/\Delta)}{\log\log{(1/\Delta)})$ passes。在这里，$n$ 是抓枪的数量，$\Delta$ 是最佳和第二最佳抓枪之间的奖励差。我们的结果与 Jin et al. 的 $O(\log(\frac{1}{\Delta}))$-pass算法（Up to lower order terms）相匹配，该算法只使用 $O(1)$ 内存，并回答了 Assadi 和 Wang 提出的问题（STOC'20）。
</details></li>
</ul>
<hr>
<h2 id="Using-Multiple-Vector-Channels-Improves-E-n-Equivariant-Graph-Neural-Networks"><a href="#Using-Multiple-Vector-Channels-Improves-E-n-Equivariant-Graph-Neural-Networks" class="headerlink" title="Using Multiple Vector Channels Improves E(n)-Equivariant Graph Neural Networks"></a>Using Multiple Vector Channels Improves E(n)-Equivariant Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03139">http://arxiv.org/abs/2309.03139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Levy, Sékou-Oumar Kaba, Carmelo Gonzales, Santiago Miret, Siamak Ravanbakhsh</li>
<li>for: 这个论文是为了扩展E(n)-对称图 neural network，使其使用多个对称向量。</li>
<li>methods: 这个论文使用多个对称向量来提高性能，并展示了这种扩展对不同物理系统 benchmark 任务有着明显的改善。</li>
<li>results: 对于N-体电荷粒子动力学、分子性质预测和太阳系体 trajectory 预测等任务，多通道EGNN 表现出了更高的性能，与标准单通道EGNN 的差异非常小。<details>
<summary>Abstract</summary>
We present a natural extension to E(n)-equivariant graph neural networks that uses multiple equivariant vectors per node. We formulate the extension and show that it improves performance across different physical systems benchmark tasks, with minimal differences in runtime or number of parameters. The proposed multichannel EGNN outperforms the standard singlechannel EGNN on N-body charged particle dynamics, molecular property predictions, and predicting the trajectories of solar system bodies. Given the additional benefits and minimal additional cost of multi-channel EGNN, we suggest that this extension may be of practical use to researchers working in machine learning for the physical sciences
</details>
<details>
<summary>摘要</summary>
我们提出了多通道E(n)-对称图 neural network的自然扩展，该扩展使用每个节点多个对称向量。我们形式化了扩展并证明其在不同物理系统benchmark任务中提高性能，而且与标准单通道EGNN的运行时间和参数数量差不多。我们的多通道EGNN在N-体电荷 particule动力学、分子性质预测和太阳系体天路预测等任务上表现出色，与标准单通道EGNN相比，它的性能更高。考虑到这种扩展的额外优点和较少的额外成本，我们建议这种扩展可能对物理科学领域的研究人员有实际用途。
</details></li>
</ul>
<hr>
<h2 id="Graph-Theory-Applications-in-Advanced-Geospatial-Research"><a href="#Graph-Theory-Applications-in-Advanced-Geospatial-Research" class="headerlink" title="Graph Theory Applications in Advanced Geospatial Research"></a>Graph Theory Applications in Advanced Geospatial Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03249">http://arxiv.org/abs/2309.03249</a></li>
<li>repo_url: None</li>
<li>paper_authors: Surajit Ghosh, Archita Mallick, Anuva Chowdhury, Kounik De Sarkar</li>
<li>for: 本文旨在探讨 graf 理论在地理科学中的应用，包括网络分析、空间连接性、地理信息系统等方面。</li>
<li>methods: 本文使用 graf 理论的多种算法和概念来模拟和分析空间关系，包括度量学、最短路径、最大流等。</li>
<li>results: 本文提供了各种实际应用场景，如环境监测、交通规划、基础设施规划等，以及使用 graf 理论解决这些问题的研究和技术。<details>
<summary>Abstract</summary>
Geospatial sciences include a wide range of applications, from environmental monitoring transportation to infrastructure planning, as well as location-based analysis and services. Graph theory algorithms in mathematics have emerged as indispensable tools in these domains due to their capability to model and analyse spatial relationships efficiently. This technical report explores the applications of graph theory algorithms in geospatial sciences, highlighting their role in network analysis, spatial connectivity, geographic information systems, and various other spatial problem-solving scenarios. It provides a comprehensive idea about the key concepts and algorithms of graph theory that assist the modelling processes. The report provides insights into the practical significance of graph theory in addressing real-world geospatial challenges and opportunities. It lists the extensive research, innovative technologies and methodologies implemented in this field.
</details>
<details>
<summary>摘要</summary>
地ospatial科学包括各种应用，从环境监测到交通规划，以及基础设施规划，同时还包括位置基于分析和服务。数学中的图论算法在这些领域中已成为不可或缺的工具，这是因为它可以有效地模拟和分析空间关系。本技术报告探讨了图论算法在地ospatial科学中的应用，特别是在网络分析、空间连接性、地图信息系统和其他空间问题解决方案中。报告提供了关键概念和算法的全面了解，并提供了实际应用中图论在地ospatial挑战中的实际意义和机遇。报告还列出了该领域的广泛的研究、创新技术和方法。
</details></li>
</ul>
<hr>
<h2 id="ORL-AUDITOR-Dataset-Auditing-in-Offline-Deep-Reinforcement-Learning"><a href="#ORL-AUDITOR-Dataset-Auditing-in-Offline-Deep-Reinforcement-Learning" class="headerlink" title="ORL-AUDITOR: Dataset Auditing in Offline Deep Reinforcement Learning"></a>ORL-AUDITOR: Dataset Auditing in Offline Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03081">http://arxiv.org/abs/2309.03081</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/link-zju/orl-auditor">https://github.com/link-zju/orl-auditor</a></li>
<li>paper_authors: Linkang Du, Min Chen, Mingyang Sun, Shouling Ji, Peng Cheng, Jiming Chen, Zhikun Zhang</li>
<li>for: 本研究是为了提供一种基于累积奖励的 trajectory-level 数据审核机制，以适应 Offline Deep Reinforcement Learning（Offline DRL）enario。</li>
<li>methods: 本研究使用了累积奖励来作为数据审核的依据，并提出了一种基于累积奖励的数据审核机制——ORL-AUDITOR。</li>
<li>results: 实验表明，ORL-AUDITOR 可以准确地审核 Offline DRL 模型是否使用了正确的数据，并且可以在多个任务和模型上达到审核精度高于 95% 并且 false positive rate 低于 2.88%。<details>
<summary>Abstract</summary>
Data is a critical asset in AI, as high-quality datasets can significantly improve the performance of machine learning models. In safety-critical domains such as autonomous vehicles, offline deep reinforcement learning (offline DRL) is frequently used to train models on pre-collected datasets, as opposed to training these models by interacting with the real-world environment as the online DRL. To support the development of these models, many institutions make datasets publicly available with opensource licenses, but these datasets are at risk of potential misuse or infringement. Injecting watermarks to the dataset may protect the intellectual property of the data, but it cannot handle datasets that have already been published and is infeasible to be altered afterward. Other existing solutions, such as dataset inference and membership inference, do not work well in the offline DRL scenario due to the diverse model behavior characteristics and offline setting constraints. In this paper, we advocate a new paradigm by leveraging the fact that cumulative rewards can act as a unique identifier that distinguishes DRL models trained on a specific dataset. To this end, we propose ORL-AUDITOR, which is the first trajectory-level dataset auditing mechanism for offline RL scenarios. Our experiments on multiple offline DRL models and tasks reveal the efficacy of ORL-AUDITOR, with auditing accuracy over 95% and false positive rates less than 2.88%. We also provide valuable insights into the practical implementation of ORL-AUDITOR by studying various parameter settings. Furthermore, we demonstrate the auditing capability of ORL-AUDITOR on open-source datasets from Google and DeepMind, highlighting its effectiveness in auditing published datasets. ORL-AUDITOR is open-sourced at https://github.com/link-zju/ORL-Auditor.
</details>
<details>
<summary>摘要</summary>
“资料是人工智能中的重要资产，高质量的数据可以帮助机器学习模型提高表现。在安全敏感领域，如自动驾驶车，离线深度学习（离线DRL）常常用于训练模型，而不是在实际环境中进行线上DRL。为了支持这些模型的发展，许多机构会公开数据，但这些数据受到潜在的违用或侵犯的威胁。将水印加入数据可以保护数据的知识产权，但这不能处理已经发布的数据，且无法在后续更改。现有的解决方案，如数据推理和会员推理，在离线DRL scenario中不太适用，因为模型行为特性和离线设定的限制。在这篇文章中，我们主张一个新的思路，利用总奖励可以作为特定数据集训练离线RL模型的唯一识别码。为此，我们提出了ORL-AUDITOR，是离线RL scenario中首个数据集评审机制。我们的实验显示，ORL-AUDITOR在多个离线DRL模型和任务上显示出评审精度高于95%，False Positive率低于2.88%。我们还提供了实际实施ORL-AUDITOR的有用指导，以及在Google和DeepMind的开源数据集上进行评审的能力。ORL-AUDITOR的开源网站可以在https://github.com/link-zju/ORL-Auditor 中找到。”
</details></li>
</ul>
<hr>
<h2 id="Parameterizing-pressure-temperature-profiles-of-exoplanet-atmospheres-with-neural-networks"><a href="#Parameterizing-pressure-temperature-profiles-of-exoplanet-atmospheres-with-neural-networks" class="headerlink" title="Parameterizing pressure-temperature profiles of exoplanet atmospheres with neural networks"></a>Parameterizing pressure-temperature profiles of exoplanet atmospheres with neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03075">http://arxiv.org/abs/2309.03075</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/timothygebhard/ml4ptp">https://github.com/timothygebhard/ml4ptp</a></li>
<li>paper_authors: Timothy D. Gebhard, Daniel Angerhausen, Björn S. Konrad, Eleonora Alei, Sascha P. Quanz, Bernhard Schölkopf</li>
<li>For: The paper aims to improve the accuracy and efficiency of atmospheric retrieval (AR) for exoplanets by introducing a new, data-driven parameterization scheme for pressure-temperature (PT) profiles.* Methods: The authors use a latent variable model (based on a neural network) to learn a distribution over functions (PT profiles) and a decoder network to map pressure to temperature. They train and evaluate their method on two publicly available datasets of self-consistent PT profiles.* Results: The authors find that their method achieves better fit quality than existing baseline methods, despite using fewer parameters. In an AR based on existing literature, their model (using two parameters) produces a tighter, more accurate posterior for the PT profile than the five-parameter polynomial baseline, while also speeding up the retrieval by more than a factor of three.<details>
<summary>Abstract</summary>
Atmospheric retrievals (AR) of exoplanets typically rely on a combination of a Bayesian inference technique and a forward simulator to estimate atmospheric properties from an observed spectrum. A key component in simulating spectra is the pressure-temperature (PT) profile, which describes the thermal structure of the atmosphere. Current AR pipelines commonly use ad hoc fitting functions here that limit the retrieved PT profiles to simple approximations, but still use a relatively large number of parameters. In this work, we introduce a conceptually new, data-driven parameterization scheme for physically consistent PT profiles that does not require explicit assumptions about the functional form of the PT profiles and uses fewer parameters than existing methods. Our approach consists of a latent variable model (based on a neural network) that learns a distribution over functions (PT profiles). Each profile is represented by a low-dimensional vector that can be used to condition a decoder network that maps $P$ to $T$. When training and evaluating our method on two publicly available datasets of self-consistent PT profiles, we find that our method achieves, on average, better fit quality than existing baseline methods, despite using fewer parameters. In an AR based on existing literature, our model (using two parameters) produces a tighter, more accurate posterior for the PT profile than the five-parameter polynomial baseline, while also speeding up the retrieval by more than a factor of three. By providing parametric access to physically consistent PT profiles, and by reducing the number of parameters required to describe a PT profile (thereby reducing computational cost or freeing resources for additional parameters of interest), our method can help improve AR and thus our understanding of exoplanet atmospheres and their habitability.
</details>
<details>
<summary>摘要</summary>
通常情况下，描述外层行星大气的 Retrieval （AR） 都是通过 Bayesian 推理技术和前向模拟器来估算大气属性，其中一个关键组件是压力-温度（PT） 规则，它描述大气的热结构。现有的 AR 管道通常使用各种各样的适应函数来限制从观测 спектrum 中获取的 PT 规则，但仍然使用较多参数。在这项工作中，我们提出了一种新的、数据驱动的参数化方案，这种方案不需要显式地假设 PT 规则的函数形式，并且使用 fewer 参数 than 现有方法。我们的方法基于一个 latent 变量模型（基于神经网络），该模型学习一个分布 über 函数（PT 规则）。每个 profile 都被表示为一个低维度的 вектор，可以用来 condition 一个 decoder 网络，该网络将 $P$ 映射到 $T$。在训练和评估我们的方法时，我们发现我们的方法在两个公开可用的 datasets 上的自 consistency 的 PT 规则上达到了更高的适应质量，尽管使用 fewer 参数。在基于现有文献的 AR 中，我们的模型（使用两个参数）生成了一个更紧凑、更准确的 posterior 对 PT 规则，而且同时提高了计算速度，比现有五个参数的多项式基线 faster 了 более三分之一。通过为 PT 规则提供参数化的物理一致性，并降低计算量或释放资源，我们的方法可以帮助改进 AR，从而提高我们对外层行星大气的理解和其居住性。
</details></li>
</ul>
<hr>
<h2 id="Learning-Active-Subspaces-for-Effective-and-Scalable-Uncertainty-Quantification-in-Deep-Neural-Networks"><a href="#Learning-Active-Subspaces-for-Effective-and-Scalable-Uncertainty-Quantification-in-Deep-Neural-Networks" class="headerlink" title="Learning Active Subspaces for Effective and Scalable Uncertainty Quantification in Deep Neural Networks"></a>Learning Active Subspaces for Effective and Scalable Uncertainty Quantification in Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03061">http://arxiv.org/abs/2309.03061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanket Jantre, Nathan M. Urban, Xiaoning Qian, Byung-Jun Yoon</li>
<li>for: 这个论文旨在提出一种解决 bayesian deep learning 的计算复杂性问题的方法，使得可以提供准确的预测和量化的uncertainty。</li>
<li>methods: 该方法是通过构建一个具有低维度的 neural network 参数空间，并在这个空间中进行 Bayesian 推断，从而使得计算复杂性得到了改进。</li>
<li>results: 实验表明，该方法可以提供可靠的预测和具有robustness的uncertainty估计，并且可以在多种回归任务中应用。<details>
<summary>Abstract</summary>
Bayesian inference for neural networks, or Bayesian deep learning, has the potential to provide well-calibrated predictions with quantified uncertainty and robustness. However, the main hurdle for Bayesian deep learning is its computational complexity due to the high dimensionality of the parameter space. In this work, we propose a novel scheme that addresses this limitation by constructing a low-dimensional subspace of the neural network parameters-referred to as an active subspace-by identifying the parameter directions that have the most significant influence on the output of the neural network. We demonstrate that the significantly reduced active subspace enables effective and scalable Bayesian inference via either Monte Carlo (MC) sampling methods, otherwise computationally intractable, or variational inference. Empirically, our approach provides reliable predictions with robust uncertainty estimates for various regression tasks.
</details>
<details>
<summary>摘要</summary>
bayesian 推理 для神经网络，或 bayesian 深度学习，有可能提供准确的预测和量化的不确定性。然而，bayesian 深度学习的主要障碍是其参数空间的维度太高，导致计算复杂度过高。在这种情况下，我们提议一种新的方案，即在神经网络参数空间中构建一个低维度的活动子空间（referred to as an active subspace），其中神经网络参数的方向对输出的影响最大。我们证明了，这个减少后的活动子空间可以使bayesian 推理变得可行和扩展性强。我们通过MC sampling方法或variational推理进行实验，并证明了我们的方法可以提供可靠的预测和robust的不确定性估计。
</details></li>
</ul>
<hr>
<h2 id="CoLA-Exploiting-Compositional-Structure-for-Automatic-and-Efficient-Numerical-Linear-Algebra"><a href="#CoLA-Exploiting-Compositional-Structure-for-Automatic-and-Efficient-Numerical-Linear-Algebra" class="headerlink" title="CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra"></a>CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03060">http://arxiv.org/abs/2309.03060</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wilson-labs/cola">https://github.com/wilson-labs/cola</a></li>
<li>paper_authors: Andres Potapczynski, Marc Finzi, Geoff Pleiss, Andrew Gordon Wilson</li>
<li>for: 这篇论文是为了解决大规模机器学习和科学中的线性代数问题，例如 eigendecompositions、解决线性系统、计算矩阵幂和迹估计。</li>
<li>methods: 这篇论文提出了一个简单 yet 通用的框架，named CoLA (Compositional Linear Algebra)，可以自动构建高效的内存和时间间步的数据运算法。CoLA使用了线性算子抽象和compositional dispatch规则，可以实现内存高效的自动微分、低精度计算和GPU加速，并且可以与多种下游套件进行整合。</li>
<li>results: 这篇论文显示了CoLA在广泛的应用中的高效性，包括partial differential equations、Gaussian processes、equivariant model construction和无supervised learning。<details>
<summary>Abstract</summary>
Many areas of machine learning and science involve large linear algebra problems, such as eigendecompositions, solving linear systems, computing matrix exponentials, and trace estimation. The matrices involved often have Kronecker, convolutional, block diagonal, sum, or product structure. In this paper, we propose a simple but general framework for large-scale linear algebra problems in machine learning, named CoLA (Compositional Linear Algebra). By combining a linear operator abstraction with compositional dispatch rules, CoLA automatically constructs memory and runtime efficient numerical algorithms. Moreover, CoLA provides memory efficient automatic differentiation, low precision computation, and GPU acceleration in both JAX and PyTorch, while also accommodating new objects, operations, and rules in downstream packages via multiple dispatch. CoLA can accelerate many algebraic operations, while making it easy to prototype matrix structures and algorithms, providing an appealing drop-in tool for virtually any computational effort that requires linear algebra. We showcase its efficacy across a broad range of applications, including partial differential equations, Gaussian processes, equivariant model construction, and unsupervised learning.
</details>
<details>
<summary>摘要</summary>
很多机器学习和科学领域都涉及到大规模的线性代数问题，如归一化、解系统、计算矩阵幂和跟踪估计。这些矩阵经常具有克罗内cker、卷积、块对角、和积加结构。在这篇论文中，我们提出了一个简单 yet general的框架 для大规模的线性代数问题，名为CoLA（Compositional Linear Algebra）。通过将线性运算抽象与组合调度规则结合起来，CoLA自动构建了高效的内存和运行时数值算法。此外，CoLA提供了内存高效的自动微分、低精度计算和GPU加速，同时也支持在JAX和PyTorch中进行多重派发。CoLA可以加速许多线性运算，并使其易于实际matrix结构和算法的探索，提供了许多应用程序的灵活Drop-in工具。我们在各种应用程序中展示了CoLA的效果，包括偏微分方程、Gaussian процеcess、对称型建构和无监督学习。
</details></li>
</ul>
<hr>
<h2 id="Automated-CVE-Analysis-for-Threat-Prioritization-and-Impact-Prediction"><a href="#Automated-CVE-Analysis-for-Threat-Prioritization-and-Impact-Prediction" class="headerlink" title="Automated CVE Analysis for Threat Prioritization and Impact Prediction"></a>Automated CVE Analysis for Threat Prioritization and Impact Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03040">http://arxiv.org/abs/2309.03040</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Aghaei, Ehab Al-Shaer, Waseem Shadid, Xi Niu</li>
<li>For: This paper aims to improve the efficiency and accuracy of CVE analysis and threat prioritization by introducing a novel predictive model and tool called CVEDrill.* Methods: CVEDrill uses machine learning algorithms to estimate the CVSS vector for precise threat mitigation and priority ranking, and it also automates the classification of CVEs into the appropriate CWE hierarchy classes.* Results: CVEDrill outperforms state-of-the-art tools like ChaptGPT in terms of accuracy and timeliness, allowing organizations to implement cybersecurity countermeasure mitigation with unparalleled effectiveness.Here are the three points in Simplified Chinese text:* For: 这篇论文目的是提高CVE分析和威胁优先级的效率和准确性，通过引入一种新的预测模型和工具CVEDrill。* Methods: CVEDrill使用机器学习算法来估算CVSS向量，以便精确地确定威胁优先级和Countermeasure的适用性，同时自动将CVE分类到适当的CWE层次结构中。* Results: CVEDrill比ChaptGPT等现有工具更高效和准确， allowing organizations可以通过无 precedent的效果和时效性来实施cybersecurity countermeasure mitigation。<details>
<summary>Abstract</summary>
The Common Vulnerabilities and Exposures (CVE) are pivotal information for proactive cybersecurity measures, including service patching, security hardening, and more. However, CVEs typically offer low-level, product-oriented descriptions of publicly disclosed cybersecurity vulnerabilities, often lacking the essential attack semantic information required for comprehensive weakness characterization and threat impact estimation. This critical insight is essential for CVE prioritization and the identification of potential countermeasures, particularly when dealing with a large number of CVEs. Current industry practices involve manual evaluation of CVEs to assess their attack severities using the Common Vulnerability Scoring System (CVSS) and mapping them to Common Weakness Enumeration (CWE) for potential mitigation identification. Unfortunately, this manual analysis presents a major bottleneck in the vulnerability analysis process, leading to slowdowns in proactive cybersecurity efforts and the potential for inaccuracies due to human errors. In this research, we introduce our novel predictive model and tool (called CVEDrill) which revolutionizes CVE analysis and threat prioritization. CVEDrill accurately estimates the CVSS vector for precise threat mitigation and priority ranking and seamlessly automates the classification of CVEs into the appropriate CWE hierarchy classes. By harnessing CVEDrill, organizations can now implement cybersecurity countermeasure mitigation with unparalleled accuracy and timeliness, surpassing in this domain the capabilities of state-of-the-art tools like ChaptGPT.
</details>
<details>
<summary>摘要</summary>
通用漏洞和曝露（CVE）是重要的cybersecurity措施之一，包括服务补丁、安全强化等。然而，CVE通常只提供低级别、产品特定的漏洞描述，经常缺乏必要的攻击语义信息，这对于全面评估漏洞弱点和威胁影响进行了精度的评估和准确的威胁评估是关键。现行industry实践是通过手动评估CVE来评估其攻击严重性，并将其映射到Common Weakness Enumeration（CWE）中 для可能的缓解 identification。然而，这个手动分析过程存在主要的瓶颈，导致漏洞分析过程中的拥堵和可能的人工错误导致的不准确。在这项研究中，我们介绍了我们的新的预测模型和工具（称为CVEDrill），这种模型可以准确地估算CVSS vector，以便precise的威胁缓解和排名，并自动将CVE分类到相应的CWE层次分类中。通过使用CVEDrill，组织可以现在通过无前例的准确性和时效性，超越现有的工具，如ChaptGPT。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-for-Polycystic-Kidney-Disease-Utilizing-Neural-Networks-for-Accurate-and-Early-Detection-through-Gene-Expression-Analysis"><a href="#Deep-Learning-for-Polycystic-Kidney-Disease-Utilizing-Neural-Networks-for-Accurate-and-Early-Detection-through-Gene-Expression-Analysis" class="headerlink" title="Deep Learning for Polycystic Kidney Disease: Utilizing Neural Networks for Accurate and Early Detection through Gene Expression Analysis"></a>Deep Learning for Polycystic Kidney Disease: Utilizing Neural Networks for Accurate and Early Detection through Gene Expression Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03033">http://arxiv.org/abs/2309.03033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kapil Panda, Anirudh Mazumder</li>
<li>for: 早期诊断肾脏瘤病（PKD），以确保病情管理的效果。</li>
<li>methods: 使用深度学习方法分析病人基因表达，实现精准和可靠的病症检测。</li>
<li>results: 研究提出的神经网络模型可以准确地预测病人可能患有PKD。<details>
<summary>Abstract</summary>
With Polycystic Kidney Disease (PKD) potentially leading to fatal complications in patients due to the formation of cysts in the kidneys, early detection of PKD is crucial for effective management of the condition. However, the various patient-specific factors that play a role in the diagnosis make it an intricate puzzle for clinicians to solve. Therefore, in this study, we aim to utilize a deep learning-based approach for early disease detection. The devised neural network can achieve accurate and robust predictions for possible PKD in patients by analyzing patient gene expressions.
</details>
<details>
<summary>摘要</summary>
患有肾脏瘤病（PKD）的患者可能会因肾脏中的肿块形成而导致致命的合并症状。因此，早期PKD的诊断非常重要，以便有效管理疾病。然而，诊断过程中受到各种患者特定的因素的影响，使得诊断变得非常复杂。因此，在这项研究中，我们尝试使用深度学习的方法来早期诊断PKD。我们设计的神经网络可以通过分析患者的基因表达来实现准确和可靠的预测。
</details></li>
</ul>
<hr>
<h2 id="Amortised-Inference-in-Bayesian-Neural-Networks"><a href="#Amortised-Inference-in-Bayesian-Neural-Networks" class="headerlink" title="Amortised Inference in Bayesian Neural Networks"></a>Amortised Inference in Bayesian Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03018">http://arxiv.org/abs/2309.03018</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sheev13/bnn_amort_inf">https://github.com/sheev13/bnn_amort_inf</a></li>
<li>paper_authors: Tommy Rochussen</li>
<li>for: 这个论文的目的是提出一种更有效率的 probabilistic meta-learning 方法，以便在有限的数据情况下进行预测。</li>
<li>methods: 这篇论文使用了 Bayesian neural networks 和 per-datapoint amortisation of inference 技术，实现了更有效率的 probabilistic meta-learning。</li>
<li>results: 这个方法在一个一维 regression 问题和一个更加复杂的图像完成问题中，具有较好的预测性能， especialy when the amount of training data is limited.<details>
<summary>Abstract</summary>
Meta-learning is a framework in which machine learning models train over a set of datasets in order to produce predictions on new datasets at test time. Probabilistic meta-learning has received an abundance of attention from the research community in recent years, but a problem shared by many existing probabilistic meta-models is that they require a very large number of datasets in order to produce high-quality predictions with well-calibrated uncertainty estimates. In many applications, however, such quantities of data are simply not available.   In this dissertation we present a significantly more data-efficient approach to probabilistic meta-learning through per-datapoint amortisation of inference in Bayesian neural networks, introducing the Amortised Pseudo-Observation Variational Inference Bayesian Neural Network (APOVI-BNN). First, we show that the approximate posteriors obtained under our amortised scheme are of similar or better quality to those obtained through traditional variational inference, despite the fact that the amortised inference is performed in a single forward pass. We then discuss how the APOVI-BNN may be viewed as a new member of the neural process family, motivating the use of neural process training objectives for potentially better predictive performance on complex problems as a result. Finally, we assess the predictive performance of the APOVI-BNN against other probabilistic meta-models in both a one-dimensional regression problem and in a significantly more complex image completion setting. In both cases, when the amount of training data is limited, our model is the best in its class.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CN<<SYS>>框架：机器学习模型在一系列数据集上进行训练，以生成新数据集上的预测。 probabilistic meta-learning 在研究 сообществе中获得了很多关注，但是现有的 probabilistic meta-models Problem 是需要很多数据集来生成高质量的预测和准确的不确定度估计。在许多应用程序中，这些数据集的数量并不够。在这个论文中，我们提出了一种更加数据效率的 probabilistic meta-learning 方法，通过 Bayesian neural networks 中的 per-datapoint amortisation of inference， introduce the Amortised Pseudo-Observation Variational Inference Bayesian Neural Network (APOVI-BNN).我们首先示出，我们的杜立格 posterior 与传统的 variational inference 相比，可以在单个前进 pass 中获得类似或更好的结果。然后，我们讨论了如何视 APOVI-BNN 为一种新的 neural process 成员，并motivate 使用 neural process training objectives 以实现更好的预测性能在复杂问题上。最后，我们评估了 APOVI-BNN 的预测性能与其他 probabilistic meta-models 在一个一维回归问题和一个更加复杂的图像完成问题上。在这两个问题上，当训练数据少于时，我们的模型在其类中表现最佳。
</details></li>
</ul>
<hr>
<h2 id="SymED-Adaptive-and-Online-Symbolic-Representation-of-Data-on-the-Edge"><a href="#SymED-Adaptive-and-Online-Symbolic-Representation-of-Data-on-the-Edge" class="headerlink" title="SymED: Adaptive and Online Symbolic Representation of Data on the Edge"></a>SymED: Adaptive and Online Symbolic Representation of Data on the Edge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03014">http://arxiv.org/abs/2309.03014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Hofstätter, Shashikant Ilager, Ivan Lujic, Ivona Brandic</li>
<li>for: 这个研究旨在实现对互联网预设设备（IoT）产生的数据进行 proximity 处理，并解决将资料传输、储存和处理到资源有限的边缘设备上所出现的挑战。</li>
<li>methods: 这个研究使用了符号表示法（SR）来将实际的原始数据转换为符号，以便在边缘设备上进行数据分析（例如异常检测和趋势预测），从而帮助大量边缘应用程序。</li>
<li>results: 这个研究的结果显示了 SymED 可以实现以下三个目的：（i）将原始数据压缩为平均压缩率为 9.5%；（ii）在 DTW 空间中保持低的重建误差为 13.25；（iii）同时提供实时适应性，以便在一般延迟为 42ms 的符号中进行在线流动 IoT 数据处理。<details>
<summary>Abstract</summary>
The edge computing paradigm helps handle the Internet of Things (IoT) generated data in proximity to its source. Challenges occur in transferring, storing, and processing this rapidly growing amount of data on resource-constrained edge devices. Symbolic Representation (SR) algorithms are promising solutions to reduce the data size by converting actual raw data into symbols. Also, they allow data analytics (e.g., anomaly detection and trend prediction) directly on symbols, benefiting large classes of edge applications. However, existing SR algorithms are centralized in design and work offline with batch data, which is infeasible for real-time cases. We propose SymED - Symbolic Edge Data representation method, i.e., an online, adaptive, and distributed approach for symbolic representation of data on edge. SymED is based on the Adaptive Brownian Bridge-based Aggregation (ABBA), where we assume low-powered IoT devices do initial data compression (senders) and the more robust edge devices do the symbolic conversion (receivers). We evaluate SymED by measuring compression performance, reconstruction accuracy through Dynamic Time Warping (DTW) distance, and computational latency. The results show that SymED is able to (i) reduce the raw data with an average compression rate of 9.5%; (ii) keep a low reconstruction error of 13.25 in the DTW space; (iii) simultaneously provide real-time adaptability for online streaming IoT data at typical latencies of 42ms per symbol, reducing the overall network traffic.
</details>
<details>
<summary>摘要</summary>
Edge computing paradigm 帮助处理互联网物联网（IoT）生成的数据在数据的 sources 附近。但是，将大量快速增长的数据转移、存储和处理到资源有限的边缘设备上存在挑战。符号表示（SR）算法是一种有前途的解决方案，可以将实际的原始数据转换成符号，从而降低数据大小。此外，SR 还允许在符号上进行数据分析（例如，异常检测和趋势预测），对于许多边缘应用程序而言是非常有利。然而，现有的 SR 算法都是中央化的设计，在批处理数据的情况下做出了线上的处理，这对实时情况是不可能的。我们提出了 SymED - 符号边缘数据表示方法，即在线、适应、分布式的符号表示方法。SymED 基于 Adaptive Brownian Bridge-based Aggregation（ABBA），假设低功率的 IoT 设备进行初步数据压缩（发送器），而更 robust的边缘设备进行符号转换（接收器）。我们通过测量压缩性能、重建精度通过动态时间戳（DTW）距离以及计算延迟来评估 SymED。结果显示，SymED 能够：1. 将原始数据压缩到平均压缩率为 9.5%。2. 在 DTW 空间保持低于 13.25 的重建错误。3. 同时提供在线适应性，对于常见的 42ms 每个符号的延迟，减少总网络流量。
</details></li>
</ul>
<hr>
<h2 id="Theoretical-Explanation-of-Activation-Sparsity-through-Flat-Minima-and-Adversarial-Robustness"><a href="#Theoretical-Explanation-of-Activation-Sparsity-through-Flat-Minima-and-Adversarial-Robustness" class="headerlink" title="Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness"></a>Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03004">http://arxiv.org/abs/2309.03004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ze Peng, Lei Qi, Yinghuan Shi, Yang Gao</li>
<li>for: 这个论文旨在解释 activation sparsity 的起源，以及如何通过 gradient sparsity 来实现 adversarial robustness。</li>
<li>methods: 这篇论文使用了 gradient sparsity 的概念，以及 random matrix theory (RMT) 来解释 activation sparsity 的起源。</li>
<li>results: 该论文提出了两种 plug-and-play 模块和一种 радикаль 修改，以提高模型的 sparse 性和 flatness，并通过实验证明了这些修改的效果。<details>
<summary>Abstract</summary>
A recent empirical observation of activation sparsity in MLP layers offers an opportunity to drastically reduce computation costs for free. Despite several works attributing it to training dynamics, the theoretical explanation of activation sparsity's emergence is restricted to shallow networks, small training steps well as modified training, even though the sparsity has been found in deep models trained by vanilla protocols for large steps. To fill the three gaps, we propose the notion of gradient sparsity as the source of activation sparsity and a theoretical explanation based on it that explains gradient sparsity and then activation sparsity as necessary steps to adversarial robustness w.r.t. hidden features and parameters, which is approximately the flatness of minima for well-learned models. The theory applies to standardly trained LayerNorm-ed pure MLPs, and further to Transformers or other architectures if noises are added to weights during training. To eliminate other sources of flatness when arguing sparsities' necessity, we discover the phenomenon of spectral concentration, i.e., the ratio between the largest and the smallest non-zero singular values of weight matrices is small. We utilize random matrix theory (RMT) as a powerful theoretical tool to analyze stochastic gradient noises and discuss the emergence of spectral concentration. With these insights, we propose two plug-and-play modules for both training from scratch and sparsity finetuning, as well as one radical modification that only applies to from-scratch training. Another under-testing module for both sparsity and flatness is also immediate from our theories. Validational experiments are conducted to verify our explanation. Experiments for productivity demonstrate modifications' improvement in sparsity, indicating further theoretical cost reduction in both training and inference.
</details>
<details>
<summary>摘要</summary>
近期观察到多层感知（MLP）层中的活动稀畴现象，可以带来计算成本的削减。虽然一些研究归因于训练动力学，但理论解释活动稀畴的出现受限于浅网络、小训练步骤以及修改训练协议，即使发现在深度模型中训练。为填充这三个差距，我们提出梯度稀畴作为活动稀畴的来源，并基于这一理论来解释梯度稀畴和活动稀畴是对抗攻击的必要步骤，即隐藏特征和参数的平坦性，这与模型训练得到的极值几乎相同。这种理论适用于标准地训练了LayerNorm-ed纯MLP，并可以扩展到Transformers或其他架构。为消除其他 sources of flatness when arguing sparsities' necessity，我们发现特征归一化现象，即权重矩阵的最大和最小非零特征值占总特征值的比率很小。我们利用随机矩阵理论（RMT）作为一种强大的理论工具，分析随机梯度噪声，并讨论活动稀畴的出现。基于这些理解，我们提出了两个插件和一个重大修改，其中一个仅适用于从零开始训练。另外一个模块适用于 both sparsity and flatness，并且可以在训练和推理中带来进一步的成本削减。VALIDATION experiments are conducted to verify our explanation. Productivity experiments demonstrate modifications' improvement in sparsity, indicating further theoretical cost reduction in both training and inference.
</details></li>
</ul>
<hr>
<h2 id="Natural-and-Robust-Walking-using-Reinforcement-Learning-without-Demonstrations-in-High-Dimensional-Musculoskeletal-Models"><a href="#Natural-and-Robust-Walking-using-Reinforcement-Learning-without-Demonstrations-in-High-Dimensional-Musculoskeletal-Models" class="headerlink" title="Natural and Robust Walking using Reinforcement Learning without Demonstrations in High-Dimensional Musculoskeletal Models"></a>Natural and Robust Walking using Reinforcement Learning without Demonstrations in High-Dimensional Musculoskeletal Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02976">http://arxiv.org/abs/2309.02976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre Schumacher, Thomas Geijtenbeek, Vittorio Caggiano, Vikash Kumar, Syn Schmitt, Georg Martius, Daniel F. B. Haeufle</li>
<li>for: The paper aims to develop a reinforcement learning (RL) method for natural bipedal walking without relying on extensive expert demonstrations.</li>
<li>methods: The paper uses RL to learn a controller that can generate human-like walking with bipedal biomechanical models in complex natural environments.</li>
<li>results: The paper achieves natural locomotion with RL without sacrificing robustness, paving the way for a novel approach to studying human walking in complex natural environments.Here’s the Chinese translation of the three key points:</li>
<li>for: 本研究的目的是开发一种不需要广泛专家示范的强化学习（RL）方法，以便生成人类自然的双脚步行。</li>
<li>methods: 本研究使用RL来学习一个可以生成人类双脚生物运动模型中的自然步行控制器。</li>
<li>results: 本研究成功地实现了自然步行，并确保了其稳定性，这些结果显示RL可以在复杂的自然环境中实现人类步行。<details>
<summary>Abstract</summary>
Humans excel at robust bipedal walking in complex natural environments. In each step, they adequately tune the interaction of biomechanical muscle dynamics and neuronal signals to be robust against uncertainties in ground conditions. However, it is still not fully understood how the nervous system resolves the musculoskeletal redundancy to solve the multi-objective control problem considering stability, robustness, and energy efficiency. In computer simulations, energy minimization has been shown to be a successful optimization target, reproducing natural walking with trajectory optimization or reflex-based control methods. However, these methods focus on particular motions at a time and the resulting controllers are limited when compensating for perturbations. In robotics, reinforcement learning~(RL) methods recently achieved highly stable (and efficient) locomotion on quadruped systems, but the generation of human-like walking with bipedal biomechanical models has required extensive use of expert data sets. This strong reliance on demonstrations often results in brittle policies and limits the application to new behaviors, especially considering the potential variety of movements for high-dimensional musculoskeletal models in 3D. Achieving natural locomotion with RL without sacrificing its incredible robustness might pave the way for a novel approach to studying human walking in complex natural environments. Videos: https://sites.google.com/view/naturalwalkingrl
</details>
<details>
<summary>摘要</summary>
人类在复杂自然环境中能够实现robust的双腿行走，每步都能够适应地与生物机械动力学和神经传导信号进行互动，以实现稳定性和可靠性。然而， nervious系统如何解决musculoskeletal redundanteness以解决多目标控制问题，包括稳定性、可靠性和能效性，仍未被完全理解。在计算机实验中，能量最小化被证明是一个成功的优化目标，可以通过轨迹优化或刷新控制方法来复制自然的行走。然而，这些方法通常会专注于特定的动作，并且 resulting控制器在补做干扰时有限。在机器人学中，使用强化学习（RL）方法已经实现了高稳定性（以及高效率）的四肢系统行走，但是使用人类类似的双腿生物机械模型进行行走却需要广泛使用专家数据集。这种强制依赖于示例数据集的方法通常会导致 brittle policies 并限制应用于新的行为，尤其是考虑到高维musculoskeletal模型在3D中的可能的多种运动。实现自然的行走通过RL而不需要牺牲其惊人的稳定性可能会开启一种新的研究人类行走的方法。Video: <https://sites.google.com/view/naturalwalkingrl>
</details></li>
</ul>
<hr>
<h2 id="On-the-Impact-of-Feeding-Cost-Risk-in-Aquaculture-Valuation-and-Decision-Making"><a href="#On-the-Impact-of-Feeding-Cost-Risk-in-Aquaculture-Valuation-and-Decision-Making" class="headerlink" title="On the Impact of Feeding Cost Risk in Aquaculture Valuation and Decision Making"></a>On the Impact of Feeding Cost Risk in Aquaculture Valuation and Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02970">http://arxiv.org/abs/2309.02970</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kevinkamm/aquaculturestochasticfeeding">https://github.com/kevinkamm/aquaculturestochasticfeeding</a></li>
<li>paper_authors: Christian Oliver Ewald, Kevin Kamm</li>
<li>For: 研究了动物原料的生产要素中的偶极成本的影响, 专门是关于养殖业。* Methods: 使用了Soybean futures来推断鲑鱼饲料的随机行为, 假设饲料采用Schwartz-2-factor模型。  Comparing harvesting salmon using a decision rule that accounts for stochastic feeding costs or deterministic feeding costs, and using deep neural networks to infer the decision boundary.* Results: 在一些情况下, 考虑到随机饲料成本会导致显著改善, 而在其他情况下, 固定饲料成本可以作为一个好的代理。 新的决策规则都显示了更好的性能, 而且计算成本很低。 使用深度神经网络来改进循环采集和拟合方法, 并在更高维度问题上scale well.<details>
<summary>Abstract</summary>
We study the effect of stochastic feeding costs on animal-based commodities with particular focus on aquaculture. More specifically, we use soybean futures to infer on the stochastic behaviour of salmon feed, which we assume to follow a Schwartz-2-factor model. We compare the decision of harvesting salmon using a decision rule assuming either deterministic or stochastic feeding costs, i.e. including feeding cost risk. We identify cases, where accounting for stochastic feeding costs leads to significant improvements as well as cases where deterministic feeding costs are a good enough proxy. Nevertheless, in all of these cases, the newly derived rules show superior performance, while the additional computational costs are negligible. From a methodological point of view, we demonstrate how to use Deep-Neural-Networks to infer on the decision boundary that determines harvesting or continuation, improving on more classical regression-based and curve-fitting methods. To achieve this we use a deep classifier, which not only improves on previous results but also scales well for higher dimensional problems, and in addition mitigates effects due to model uncertainty, which we identify in this article. effects due to model uncertainty, which we identify in this article.
</details>
<details>
<summary>摘要</summary>
我们研究生物动物商品中的随机食品成本的影响，特别是关注养殖业。更具体地说，我们使用соยbean futures来推断鳟鱼饲料的随机行为，假设鳟鱼饲料遵循Schwartz-2-factor模型。我们比较了在决定鳟鱼采择时使用决定规则，包括饲料成本风险，以及不包括饲料成本风险的决定规则。我们发现在一些情况下，考虑随机饲料成本可以导致显著改善，而在其他情况下，决定规则假设饲料成本是确定的够好。然而，在所有这些情况下，我们新 derivation的规则都显示出了更高的性能，而且计算成本几乎是零。从方法ологиical的角度来看，我们示例了如何使用深度神经网络来推断决定边界，改进了以往的回归基于方法和曲线适应方法。为了实现这一点，我们使用深度分类器，不仅提高了前一代的结果，而且可扩展到更高维度的问题，并且减轻模型不确定性的影响，我们在这篇文章中提到。
</details></li>
</ul>
<hr>
<h2 id="CR-VAE-Contrastive-Regularization-on-Variational-Autoencoders-for-Preventing-Posterior-Collapse"><a href="#CR-VAE-Contrastive-Regularization-on-Variational-Autoencoders-for-Preventing-Posterior-Collapse" class="headerlink" title="CR-VAE: Contrastive Regularization on Variational Autoencoders for Preventing Posterior Collapse"></a>CR-VAE: Contrastive Regularization on Variational Autoencoders for Preventing Posterior Collapse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02968">http://arxiv.org/abs/2309.02968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fotios Lygerakis, Elmar Rueckert</li>
<li>for: 解决Variational Autoencoder（VAE）中的后降现象，使其生成的含义不会随机变化。</li>
<li>methods: 我们提出了一种新的解决方案，即对VAE进行对比识别的正则化（CR-VAE），通过增加一个对比目标函数，使得输入和其含义之间的信息流最大化，从而避免后降现象。</li>
<li>results: 我们在多个视觉数据集上测试了我们的方法，结果显示，CR-VAE在避免后降现象方面表现出色，超过了现有的方法。<details>
<summary>Abstract</summary>
The Variational Autoencoder (VAE) is known to suffer from the phenomenon of \textit{posterior collapse}, where the latent representations generated by the model become independent of the inputs. This leads to degenerated representations of the input, which is attributed to the limitations of the VAE's objective function. In this work, we propose a novel solution to this issue, the Contrastive Regularization for Variational Autoencoders (CR-VAE). The core of our approach is to augment the original VAE with a contrastive objective that maximizes the mutual information between the representations of similar visual inputs. This strategy ensures that the information flow between the input and its latent representation is maximized, effectively avoiding posterior collapse. We evaluate our method on a series of visual datasets and demonstrate, that CR-VAE outperforms state-of-the-art approaches in preventing posterior collapse.
</details>
<details>
<summary>摘要</summary>
“Variational Autoencoder（VAE）受到后期崩溃现象的影响，即生成的内在表现变得与输入无关。这会导致输入的表现为病征，并且被归于VAE的目标函数的限制。在这个工作中，我们提出了一个新的解决方案，即对VAE进行对照调整（CR-VAE）。我们的方法是将原始VAE加以一个对照目标，以 maximize 输入和其内在表现之间的相互信息。这策略可以确保输入和它的内在表现之间的信息流汇流，彻底避免后期崩溃。我们在一系列类别视觉数据集上评估了我们的方法，并证明了CR-VAE可以较好地避免后期崩溃。”Note: "后期崩溃" (posterior collapse) refers to a phenomenon where the latent representations generated by a Variational Autoencoder (VAE) become independent of the inputs, leading to degenerate representations of the input.
</details></li>
</ul>
<hr>
<h2 id="EvoCLINICAL-Evolving-Cyber-Cyber-Digital-Twin-with-Active-Transfer-Learning-for-Automated-Cancer-Registry-System"><a href="#EvoCLINICAL-Evolving-Cyber-Cyber-Digital-Twin-with-Active-Transfer-Learning-for-Automated-Cancer-Registry-System" class="headerlink" title="EvoCLINICAL: Evolving Cyber-Cyber Digital Twin with Active Transfer Learning for Automated Cancer Registry System"></a>EvoCLINICAL: Evolving Cyber-Cyber Digital Twin with Active Transfer Learning for Automated Cancer Registry System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03246">http://arxiv.org/abs/2309.03246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/simula-complex/evoclinical">https://github.com/simula-complex/evoclinical</a></li>
<li>paper_authors: Chengjie Lu, Qinghua Xu, Tao Yue, Shaukat Ali, Thomas Schwitalla, Jan F. Nygård</li>
<li>for: 提高GURI自动癌病注册系统的可靠性和精准性，以便为癌病研究和相关统计提供可靠的基础。</li>
<li>methods: 提出了一种基于遗传算法的演进式临床数据采集方法，使用先前版本的CCDT作为预训练模型，并使用新版GURI上的数据进行微调。</li>
<li>results: 通过评估EvoCLINICAL在三个演进过程中的性能，发现其精度、准确率和F1分数均高于91%，表明EvoCLINICAL是有效的。此外，通过将EvoCLINICAL中的活动学习部分替换为随机选择，研究了转移学习对EvoCLINICAL的总性能的贡献。结果表明，在EvoCLINICAL中使用活动学习可以逐止性能的提高。<details>
<summary>Abstract</summary>
The Cancer Registry of Norway (CRN) collects information on cancer patients by receiving cancer messages from different medical entities (e.g., medical labs, and hospitals) in Norway. Such messages are validated by an automated cancer registry system: GURI. Its correct operation is crucial since it lays the foundation for cancer research and provides critical cancer-related statistics to its stakeholders. Constructing a cyber-cyber digital twin (CCDT) for GURI can facilitate various experiments and advanced analyses of the operational state of GURI without requiring intensive interactions with the real system. However, GURI constantly evolves due to novel medical diagnostics and treatment, technological advances, etc. Accordingly, CCDT should evolve as well to synchronize with GURI. A key challenge of achieving such synchronization is that evolving CCDT needs abundant data labelled by the new GURI. To tackle this challenge, we propose EvoCLINICAL, which considers the CCDT developed for the previous version of GURI as the pretrained model and fine-tunes it with the dataset labelled by querying a new GURI version. EvoCLINICAL employs a genetic algorithm to select an optimal subset of cancer messages from a candidate dataset and query GURI with it. We evaluate EvoCLINICAL on three evolution processes. The precision, recall, and F1 score are all greater than 91%, demonstrating the effectiveness of EvoCLINICAL. Furthermore, we replace the active learning part of EvoCLINICAL with random selection to study the contribution of transfer learning to the overall performance of EvoCLINICAL. Results show that employing active learning in EvoCLINICAL increases its performances consistently.
</details>
<details>
<summary>摘要</summary>
norway 癌症注册系统 (CRN) 收集癌症患者信息，通过不同的医疗机构（如医学实验室和医院）所提供的癌症信息。这些信息会被自动化癌症注册系统：GURI 验证。GURI 的正常运行非常重要，因为它为癌症研究提供关键的癌症相关统计，并且是癌症研究的基础。为了促进 GURI 的运行，我们提出了创建一个 циber-циber数字双胞胎 (CCDT)，可以在不需要与真实系统进行互动的情况下，进行不同的实验和高级分析。然而，GURI 不断发展，因为新的医学诊断和治疗技术、技术进步等。因此，CCDT 也需要不断更新，以保持与 GURI 的同步。一个主要挑战是在更新 CCDT 时，需要大量的数据，并且这些数据需要由新的 GURI 标注。为解决这个问题，我们提出了 EvoCLINICAL，它将前一个 GURI 版本中开发的 CCDT 作为预训练模型，并将其调整为新的 GURI 版本的数据。EvoCLINICAL 使用进化算法选择最佳的肿瘤信息 subset，并将其提交给 GURI 进行查询。我们在三个演变过程中评估 EvoCLINICAL，结果显示其精度、准确率和 F1 分数都高于 91%，这demonstrates  EvoCLINICAL 的有效性。此外，我们将 EvoCLINICAL 中的活动学习部分替换为随机选择，以研究转移学习对 EvoCLINICAL 的总性表现的贡献。结果显示，在 EvoCLINICAL 中使用活动学习可以提高其表现的一致性。
</details></li>
</ul>
<hr>
<h2 id="A-hybrid-quantum-classical-fusion-neural-network-to-improve-protein-ligand-binding-affinity-predictions-for-drug-discovery"><a href="#A-hybrid-quantum-classical-fusion-neural-network-to-improve-protein-ligand-binding-affinity-predictions-for-drug-discovery" class="headerlink" title="A hybrid quantum-classical fusion neural network to improve protein-ligand binding affinity predictions for drug discovery"></a>A hybrid quantum-classical fusion neural network to improve protein-ligand binding affinity predictions for drug discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03919">http://arxiv.org/abs/2309.03919</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. Banerjee, S. He Yuxun, S. Konakanchi, L. Ogunfowora, S. Roy, S. Selvaras, L. Domingo, M. Chehimi, M. Djukic, C. Johnson</li>
<li>for: 这个论文主要针对的是药物发现领域中精准预测药物分子和目标蛋白之间的绑定亲和力，特别是当这些蛋白直接影响疾病进程时。</li>
<li>methods: 这篇论文使用了hybrid量子机器学习（QML）模型，其中结合了3D和空间图像 convolutional neural networks（CNN）在优化的量子架构中。</li>
<li>results: 实验结果显示，提案的模型相比现有的类型模型具有6%的提升预测精度，同时其 converge性也更为稳定。<details>
<summary>Abstract</summary>
The field of drug discovery hinges on the accurate prediction of binding affinity between prospective drug molecules and target proteins, especially when such proteins directly influence disease progression. However, estimating binding affinity demands significant financial and computational resources. While state-of-the-art methodologies employ classical machine learning (ML) techniques, emerging hybrid quantum machine learning (QML) models have shown promise for enhanced performance, owing to their inherent parallelism and capacity to manage exponential increases in data dimensionality. Despite these advances, existing models encounter issues related to convergence stability and prediction accuracy. This paper introduces a novel hybrid quantum-classical deep learning model tailored for binding affinity prediction in drug discovery. Specifically, the proposed model synergistically integrates 3D and spatial graph convolutional neural networks within an optimized quantum architecture. Simulation results demonstrate a 6% improvement in prediction accuracy relative to existing classical models, as well as a significantly more stable convergence performance compared to previous classical approaches.
</details>
<details>
<summary>摘要</summary>
领域的药物发现涉及精准预测新药分子与目标蛋白之间的绑定亲和力，特别是当这些蛋白直接影响疾病进程时。然而，估计绑定亲和力需要较大的金融和计算资源。当前的方法使用经典机器学习（ML）技术，新兴的量子机器学习（QML）模型也有显著提高表现，因为它们具有内置的并行性和数据维度的加法性。然而，现有模型受到稳定性和预测精度的问题。本文介绍一种新的Quantum-Classical深度学习模型，专门用于药物绑定亲和力预测。该模型 synergistically  integrates 3D和空间图 convolutional neural networks within an optimized quantum architecture。实验结果表明，提案的模型与现有经典模型相比，提高预测精度6%，同时也比之前的经典方法更加稳定地 converges。
</details></li>
</ul>
<hr>
<h2 id="GroupEnc-encoder-with-group-loss-for-global-structure-preservation"><a href="#GroupEnc-encoder-with-group-loss-for-global-structure-preservation" class="headerlink" title="GroupEnc: encoder with group loss for global structure preservation"></a>GroupEnc: encoder with group loss for global structure preservation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02917">http://arxiv.org/abs/2309.02917</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Novak, Sofie Van Gassen, Yvan Saeys</li>
<li>for: 本研究旨在开发一种基于Variational Autoencoder（VAE）和SQuadMDS算法的深度学习模型，用于降维高维数据，以提高下游处理效果。</li>
<li>methods: 本研究使用了Structure Preservation的概念，在本地和全局水平进行了定制，以创建一种叫做GroupEnc的编码器模型，其中使用了’group loss’函数来创建具有更少全局结构扭曲的嵌入。</li>
<li>results: 本研究使用了公共available的生物单细胞脱氧核酸数据集，采用RNX曲线进行评估，并证明了GroupEnc模型可以创建具有更高精度和更少扭曲的嵌入，比VAE模型更好。<details>
<summary>Abstract</summary>
Recent advances in dimensionality reduction have achieved more accurate lower-dimensional embeddings of high-dimensional data. In addition to visualisation purposes, these embeddings can be used for downstream processing, including batch effect normalisation, clustering, community detection or trajectory inference. We use the notion of structure preservation at both local and global levels to create a deep learning model, based on a variational autoencoder (VAE) and the stochastic quartet loss from the SQuadMDS algorithm. Our encoder model, called GroupEnc, uses a 'group loss' function to create embeddings with less global structure distortion than VAEs do, while keeping the model parametric and the architecture flexible. We validate our approach using publicly available biological single-cell transcriptomic datasets, employing RNX curves for evaluation.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)现有最新的维度减少技术已经实现了高维数据的更准确的二维表示。除了可视化目的外，这些表示还可以用于下游处理，包括批处理准备、聚类、社区探测或轨迹推断。我们使用了“结构保持”的概念来创建一个深度学习模型，基于变量自动编码器（VAE）和SQuadMDS算法中的随机四重损失函数。我们的编码器模型，称为GroupEnc，使用了“群体损失”函数来创建具有较少全局结构扭曲的嵌入，而保持模型参数化和架构灵活。我们验证了我们的方法使用公开ailable的生物单细胞脉冲数据集，使用RNX曲线进行评估。
</details></li>
</ul>
<hr>
<h2 id="Ensemble-DNN-for-Age-of-Information-Minimization-in-UAV-assisted-Networks"><a href="#Ensemble-DNN-for-Age-of-Information-Minimization-in-UAV-assisted-Networks" class="headerlink" title="Ensemble DNN for Age-of-Information Minimization in UAV-assisted Networks"></a>Ensemble DNN for Age-of-Information Minimization in UAV-assisted Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02913">http://arxiv.org/abs/2309.02913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mouhamed Naby Ndiaye, El Houcine Bergou, Hajar El Hammouti</li>
<li>for: 本研究旨在解决无人机协助网络中的年龄信息问题（Age-of-Information，AoI），以最小化各设备的预期AoI。</li>
<li>methods: 我们首先 derivates a closed-form表达式，以表征设备选择概率下的预期AoI。然后，我们将问题转化为一个非核心最小化问题，并采用Ensemble Deep Neural Network（EDNN）方法来解决。Specifically, we use Deep Neural Networks（DNNs）在ensemble中，通过Lagrangian函数来学习不确定参数。</li>
<li>results: 我们的实验表明，提议的EDNN方法可以效果地减少预期AoI，实现了$29.5%$的remarkable减少。<details>
<summary>Abstract</summary>
This paper addresses the problem of Age-of-Information (AoI) in UAV-assisted networks. Our objective is to minimize the expected AoI across devices by optimizing UAVs' stopping locations and device selection probabilities. To tackle this problem, we first derive a closed-form expression of the expected AoI that involves the probabilities of selection of devices. Then, we formulate the problem as a non-convex minimization subject to quality of service constraints. Since the problem is challenging to solve, we propose an Ensemble Deep Neural Network (EDNN) based approach which takes advantage of the dual formulation of the studied problem. Specifically, the Deep Neural Networks (DNNs) in the ensemble are trained in an unsupervised manner using the Lagrangian function of the studied problem. Our experiments show that the proposed EDNN method outperforms traditional DNNs in reducing the expected AoI, achieving a remarkable reduction of $29.5\%$.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Multimodal-Learning-Framework-for-Comprehensive-3D-Mineral-Prospectivity-Modeling-with-Jointly-Learned-Structure-Fluid-Relationships"><a href="#A-Multimodal-Learning-Framework-for-Comprehensive-3D-Mineral-Prospectivity-Modeling-with-Jointly-Learned-Structure-Fluid-Relationships" class="headerlink" title="A Multimodal Learning Framework for Comprehensive 3D Mineral Prospectivity Modeling with Jointly Learned Structure-Fluid Relationships"></a>A Multimodal Learning Framework for Comprehensive 3D Mineral Prospectivity Modeling with Jointly Learned Structure-Fluid Relationships</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02911">http://arxiv.org/abs/2309.02911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Zheng, Hao Deng, Ruisheng Wang, Jingjie Wu</li>
<li>for: 这种研究旨在开发一种新的多模态融合模型，用于三维矿产可能地图（3D MPM），能够有效地结合结构和流体信息，通过深度网络架构。</li>
<li>methods: 该模型使用了卷积神经网络（CNN）和多层感知神经网络（MLP），并使用 canonical correlation analysis（CCA）对多模态特征进行对接和融合。</li>
<li>results: 对于硅铁矿质量分析 dataset 的严谨评估表明，该模型在分辨矿物实例和预测矿产可能性方面具有显著的优势，比其他模型更高效。减少学问还表明了对共同特征利用和 CCA 的重要性。<details>
<summary>Abstract</summary>
This study presents a novel multimodal fusion model for three-dimensional mineral prospectivity mapping (3D MPM), effectively integrating structural and fluid information through a deep network architecture. Leveraging Convolutional Neural Networks (CNN) and Multilayer Perceptrons (MLP), the model employs canonical correlation analysis (CCA) to align and fuse multimodal features. Rigorous evaluation on the Jiaojia gold deposit dataset demonstrates the model's superior performance in distinguishing ore-bearing instances and predicting mineral prospectivity, outperforming other models in result analyses. Ablation studies further reveal the benefits of joint feature utilization and CCA incorporation. This research not only advances mineral prospectivity modeling but also highlights the pivotal role of data integration and feature alignment for enhanced exploration decision-making.
</details>
<details>
<summary>摘要</summary>
这项研究提出了一种新的多Modal融合模型，用于三维矿物资源潜力地图（3D MPM），能够有效地结合结构和流体信息通过深度网络架构。通过Convolutional Neural Networks (CNN)和多层感知器(MLP)，模型使用 canonical correlation analysis (CCA) 对多模态特征进行对齐和融合。经过严格的Jiaojia金矿储量数据集的测试，模型的表现superior于其他模型，在分类矿物实例和预测矿物潜力方面表现出色。剥离研究还表明了特征共同使用和CCA包含的利处。这项研究不仅提高了矿物资源评估模型，还强调了数据集成和特征对齐的重要性，为探索决策提供了更好的支持。
</details></li>
</ul>
<hr>
<h2 id="Testing-properties-of-distributions-in-the-streaming-model"><a href="#Testing-properties-of-distributions-in-the-streaming-model" class="headerlink" title="Testing properties of distributions in the streaming model"></a>Testing properties of distributions in the streaming model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03245">http://arxiv.org/abs/2309.03245</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Sampriti Roy, Yadu Vasudev</li>
<li>for: 这篇论文研究了在标准访问模型和条件访问模型中的分布测试，当内存available to testing algorithm是有界的情况下。</li>
<li>methods: 论文使用了一种优化的样本复杂度和存储空间复杂度的方法来测试分布的性质， samples appear in an online fashion。</li>
<li>results: 论文显示了一种可以快速学习幂等分布的简短表示方法，并且可以在内存限制下实现高效的分布测试。此外，这种算法还可以扩展到更大的可分布类型。<details>
<summary>Abstract</summary>
We study distribution testing in the standard access model and the conditional access model when the memory available to the testing algorithm is bounded. In both scenarios, the samples appear in an online fashion and the goal is to test the properties of distribution using an optimal number of samples subject to a memory constraint on how many samples can be stored at a given time. First, we provide a trade-off between the sample complexity and the space complexity for testing identity when the samples are drawn according to the conditional access oracle. We then show that we can learn a succinct representation of a monotone distribution efficiently with a memory constraint on the number of samples that are stored that is almost optimal. We also show that the algorithm for monotone distributions can be extended to a larger class of decomposable distributions.
</details>
<details>
<summary>摘要</summary>
我们研究分布测试在标准访问模型和条件访问模型中，当存储空间限制的情况下。在两种情况下，样本会在在线方式上出现，并且目标是使用最优的样本数量来测试分布的属性，受到存储空间的限制。首先，我们提供了样本复杂性和存储空间之间的贸易OFF，并在样本是根据条件访问oracle采样时显示了这种贸易OFF。然后，我们示出了如何高效地学习幂等分布的简短表示，并且存储空间的限制是几乎最优的。最后，我们extend了这种算法到更大的分布类型。
</details></li>
</ul>
<hr>
<h2 id="Non-Clashing-Teaching-Maps-for-Balls-in-Graphs"><a href="#Non-Clashing-Teaching-Maps-for-Balls-in-Graphs" class="headerlink" title="Non-Clashing Teaching Maps for Balls in Graphs"></a>Non-Clashing Teaching Maps for Balls in Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02876">http://arxiv.org/abs/2309.02876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jérémie Chalopin, Victor Chepoi, Fionn Mc Inerney, Sébastien Ratel</li>
<li>for: This paper is written to study non-clashing teaching and its applications in machine learning.</li>
<li>methods: The paper uses techniques from teaching and learning, including the concept of non-clashing teaching maps and the decision problem of non-clashing teaching dimension.</li>
<li>results: The paper shows that the decision problem of non-clashing teaching dimension for a specific class of concept is NP-complete, and derives upper and lower bounds on the size of non-clashing teaching maps for various types of graphs.Here is the answer in Simplified Chinese text:</li>
<li>for: 这篇论文是研究非冲突教学和其在机器学习中的应用。</li>
<li>methods: 这篇论文使用教学和学习中的概念，包括非冲突教学图和机器学习中的冲突教学维度问题。</li>
<li>results: 这篇论文显示了一个特定类型的概念的冲突教学维度问题是NP完备的，并 derive了不同类型的图的非冲突教学图的大小上下限。<details>
<summary>Abstract</summary>
Recently, Kirkpatrick et al. [ALT 2019] and Fallat et al. [JMLR 2023] introduced non-clashing teaching and showed it to be the most efficient machine teaching model satisfying the benchmark for collusion-avoidance set by Goldman and Mathias. A teaching map $T$ for a concept class $\cal{C}$ assigns a (teaching) set $T(C)$ of examples to each concept $C \in \cal{C}$. A teaching map is non-clashing if no pair of concepts are consistent with the union of their teaching sets. The size of a non-clashing teaching map (NCTM) $T$ is the maximum size of a $T(C)$, $C \in \cal{C}$. The non-clashing teaching dimension NCTD$(\cal{C})$ of $\cal{C}$ is the minimum size of an NCTM for $\cal{C}$. NCTM$^+$ and NCTD$^+(\cal{C})$ are defined analogously, except the teacher may only use positive examples.   We study NCTMs and NCTM$^+$s for the concept class $\mathcal{B}(G)$ consisting of all balls of a graph $G$. We show that the associated decision problem {\sc B-NCTD$^+$} for NCTD$^+$ is NP-complete in split, co-bipartite, and bipartite graphs. Surprisingly, we even prove that, unless the ETH fails, {\sc B-NCTD$^+$} does not admit an algorithm running in time $2^{2^{o(vc)}\cdot n^{O(1)}$, nor a kernelization algorithm outputting a kernel with $2^{o(vc)}$ vertices, where vc is the vertex cover number of $G$. These are extremely rare results: it is only the second (fourth, resp.) problem in NP to admit a double-exponential lower bound parameterized by vc (treewidth, resp.), and only one of very few problems to admit an ETH-based conditional lower bound on the number of vertices in a kernel. We complement these lower bounds with matching upper bounds. For trees, interval graphs, cycles, and trees of cycles, we derive NCTM$^+$s or NCTMs for $\mathcal{B}(G)$ of size proportional to its VC-dimension. For Gromov-hyperbolic graphs, we design an approximate NCTM$^+$ for $\mathcal{B}(G)$ of size 2.
</details>
<details>
<summary>摘要</summary>
最近， Kirkpatrick 等人（ALT 2019）和 Fallat 等人（JMLR 2023）提出了不冲突教学模型，并证明其能满足由 Goldman 和 Mathias 提出的冲突避免标准。一个教学地图 $T$ 将一个概念集 $\mathcal{C}$ 中的每个概念 $C$ 映射到一个示例集 $T(C)$。一个不冲突的教学地图（NCTM）的大小是示例集的最大大小。概念集 $\mathcal{C}$ 的不冲突教学维度（NCTD）是最小的 NCTM 的大小。NCTM 和 NCTD 分别在 $\mathcal{C}$ 中的正例和负例上进行教学。我们研究了 $\mathcal{B}(G)$ 中的 NCTM 和 NCTM +$ $，其中 $G$ 是一个图。我们证明了其相关的决策问题 $\sc B$-NCTD$^+$ 是 NP 完全的，并且在 split、co-bipartite 和 bipartite 图中存在 double-exponential 下界。这些结果非常罕见：只有第二（第四，resp.）个 NP 问题可以 Parametrized by vc （treewidth，resp.）下界，并且只有几个问题可以通过 ETH 基础来提供 conditional 下界。我们还提供了匹配的上界。对于树、Interval 图、循环图和树状循环图，我们得到了 NCTM 和 NCTM +$ 的大小与 $\mathcal{B}(G)$ 的 VC-维度成正比。对于 Gromov-hyperbolic 图，我们设计了一个 Approximate NCTM +$。
</details></li>
</ul>
<hr>
<h2 id="Learning-Hybrid-Dynamics-Models-With-Simulator-Informed-Latent-States"><a href="#Learning-Hybrid-Dynamics-Models-With-Simulator-Informed-Latent-States" class="headerlink" title="Learning Hybrid Dynamics Models With Simulator-Informed Latent States"></a>Learning Hybrid Dynamics Models With Simulator-Informed Latent States</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02873">http://arxiv.org/abs/2309.02873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katharina Ensinger, Sebastian Ziesche, Sebastian Trimpe</li>
<li>for: 本研究旨在提出一种新的混合模型方法，用于结合学习和物理假设模型来提高预测结果的物理有效性。</li>
<li>methods: 我们提出了一种基于观察器的方法，通过将观察器与黑盒模拟器结合在一起，以控制预测结果的误差。在学习中，我们同时学习了动力和观察器，以便通过模拟器来更正学习过程中的模型匹配错误。</li>
<li>results: 我们的方法可以在不可预知的情况下提供更加准确和物理有效的预测结果，并且可以保持模型的灵活性。<details>
<summary>Abstract</summary>
Dynamics model learning deals with the task of inferring unknown dynamics from measurement data and predicting the future behavior of the system. A typical approach to address this problem is to train recurrent models. However, predictions with these models are often not physically meaningful. Further, they suffer from deteriorated behavior over time due to accumulating errors. Often, simulators building on first principles are available being physically meaningful by design. However, modeling simplifications typically cause inaccuracies in these models. Consequently, hybrid modeling is an emerging trend that aims to combine the best of both worlds. In this paper, we propose a new approach to hybrid modeling, where we inform the latent states of a learned model via a black-box simulator. This allows to control the predictions via the simulator preventing them from accumulating errors. This is especially challenging since, in contrast to previous approaches, access to the simulator's latent states is not available. We tackle the task by leveraging observers, a well-known concept from control theory, inferring unknown latent states from observations and dynamics over time. In our learning-based setting, we jointly learn the dynamics and an observer that infers the latent states via the simulator. Thus, the simulator constantly corrects the latent states, compensating for modeling mismatch caused by learning. To maintain flexibility, we train an RNN-based residuum for the latent states that cannot be informed by the simulator.
</details>
<details>
<summary>摘要</summary>
模型学习动态模型的任务是从测量数据中推断未知动态和预测系统的未来行为。一般来说，使用回归模型进行训练。然而，这些模型的预测结果frequently不是物理意义上的。此外，随着时间的推移，这些模型的性能会逐渐下降，这是因为模型中的错误会积累。而物理意义上的模拟器通常是可用的，但是这些模型通常受到简化的限制，导致它们不准确。因此，hybrid模型成为一种趋势，它将了解的模型和物理意义上的模拟器结合在一起。在这篇论文中，我们提出一种新的hybrid模型方法，我们通过黑盒模拟器来控制了学习后的隐藏状态。这是因为，不同于之前的方法，我们没有直接访问黑盒模拟器的隐藏状态。我们使用控制理论中的观察器来推断未知的隐藏状态，并且在学习过程中，我们同时学习了动态和观察器。因此，黑盒模拟器不断地更正隐藏状态，以 compensate 模型的偏差，保持模型的准确性。为保持灵活性，我们在隐藏状态中使用RNN基的剩余来表示无法通过黑盒模拟器获取的信息。
</details></li>
</ul>
<hr>
<h2 id="On-Reducing-Undesirable-Behavior-in-Deep-Reinforcement-Learning-Models"><a href="#On-Reducing-Undesirable-Behavior-in-Deep-Reinforcement-Learning-Models" class="headerlink" title="On Reducing Undesirable Behavior in Deep Reinforcement Learning Models"></a>On Reducing Undesirable Behavior in Deep Reinforcement Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02869">http://arxiv.org/abs/2309.02869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ophir M. Carmel, Guy Katz</li>
<li>for: 提高深度强化学习（DRL）软件的可靠性和可解释性，降低DRL训练过程中不良行为的频率。</li>
<li>methods: 提出一种基于EXTRACTING decision tree classifiers的新框架，将这些树 integrating into DRL 训练 loop，对系统进行错误处理，从而减少不良行为。</li>
<li>results: 在三个 significanthcase studies中，我们的方法可以 straightforward manner extend existing frameworks，增加训练时间的开销较小，并且对性能的影响较小或者甚至提高，同时减少不良行为的频率。<details>
<summary>Abstract</summary>
Deep reinforcement learning (DRL) has proven extremely useful in a large variety of application domains. However, even successful DRL-based software can exhibit highly undesirable behavior. This is due to DRL training being based on maximizing a reward function, which typically captures general trends but cannot precisely capture, or rule out, certain behaviors of the system. In this paper, we propose a novel framework aimed at drastically reducing the undesirable behavior of DRL-based software, while maintaining its excellent performance. In addition, our framework can assist in providing engineers with a comprehensible characterization of such undesirable behavior. Under the hood, our approach is based on extracting decision tree classifiers from erroneous state-action pairs, and then integrating these trees into the DRL training loop, penalizing the system whenever it performs an error. We provide a proof-of-concept implementation of our approach, and use it to evaluate the technique on three significant case studies. We find that our approach can extend existing frameworks in a straightforward manner, and incurs only a slight overhead in training time. Further, it incurs only a very slight hit to performance, or even in some cases - improves it, while significantly reducing the frequency of undesirable behavior.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhancing-Event-Sequence-Modeling-with-Contrastive-Relational-Inference"><a href="#Enhancing-Event-Sequence-Modeling-with-Contrastive-Relational-Inference" class="headerlink" title="Enhancing Event Sequence Modeling with Contrastive Relational Inference"></a>Enhancing Event Sequence Modeling with Contrastive Relational Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02868">http://arxiv.org/abs/2309.02868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Wang, Zhixuan Chu, Tao Zhou, Caigao Jiang, Hongyan Hao, Minjie Zhu, Xindong Cai, Qing Cui, Longfei Li, James Y Zhang, Siqiao Xue, Jun Zhou</li>
<li>for: 模型化连续时间事件序列，特别是捕捉事件之间的交互关系，以进行事件序列预测等推理任务。</li>
<li>methods: 基于神经关系推理（NRI），学习一个关系图，捕捉事件之间的交互关系，同时也学习事件序列的动态模式。</li>
<li>results: 在三个实际数据集上，实验表明我们的模型能够有效地捕捉事件之间的交互关系，用于事件序列模型化任务。<details>
<summary>Abstract</summary>
Neural temporal point processes(TPPs) have shown promise for modeling continuous-time event sequences. However, capturing the interactions between events is challenging yet critical for performing inference tasks like forecasting on event sequence data. Existing TPP models have focused on parameterizing the conditional distribution of future events but struggle to model event interactions. In this paper, we propose a novel approach that leverages Neural Relational Inference (NRI) to learn a relation graph that infers interactions while simultaneously learning the dynamics patterns from observational data. Our approach, the Contrastive Relational Inference-based Hawkes Process (CRIHP), reasons about event interactions under a variational inference framework. It utilizes intensity-based learning to search for prototype paths to contrast relationship constraints. Extensive experiments on three real-world datasets demonstrate the effectiveness of our model in capturing event interactions for event sequence modeling tasks.
</details>
<details>
<summary>摘要</summary>
neural temporal point processes (TPPs) 有推荐模型 continuous-time event sequences. However, capturing the interactions between events is challenging yet critical for performing inference tasks like forecasting on event sequence data. Existing TPP models have focused on parameterizing the conditional distribution of future events but struggle to model event interactions. In this paper, we propose a novel approach that leverages Neural Relational Inference (NRI) to learn a relation graph that infers interactions while simultaneously learning the dynamics patterns from observational data. Our approach, the Contrastive Relational Inference-based Hawkes Process (CRIHP), reasons about event interactions under a variational inference framework. It utilizes intensity-based learning to search for prototype paths to contrast relationship constraints. Extensive experiments on three real-world datasets demonstrate the effectiveness of our model in capturing event interactions for event sequence modeling tasks.Here's the breakdown of the translation:* neural temporal point processes (TPPs) 是一种 continuous-time event sequences 的模型。* However, capturing the interactions between events is challenging yet critical for performing inference tasks like forecasting on event sequence data。* Existing TPP models have focused on parameterizing the conditional distribution of future events but struggle to model event interactions。* In this paper, we propose a novel approach that leverages Neural Relational Inference (NRI) to learn a relation graph that infers interactions while simultaneously learning the dynamics patterns from observational data。* Our approach, the Contrastive Relational Inference-based Hawkes Process (CRIHP), reasons about event interactions under a variational inference framework。* It utilizes intensity-based learning to search for prototype paths to contrast relationship constraints。* Extensive experiments on three real-world datasets demonstrate the effectiveness of our model in capturing event interactions for event sequence modeling tasks。
</details></li>
</ul>
<hr>
<h2 id="A-Critical-Review-of-Common-Log-Data-Sets-Used-for-Evaluation-of-Sequence-based-Anomaly-Detection-Techniques"><a href="#A-Critical-Review-of-Common-Log-Data-Sets-Used-for-Evaluation-of-Sequence-based-Anomaly-Detection-Techniques" class="headerlink" title="A Critical Review of Common Log Data Sets Used for Evaluation of Sequence-based Anomaly Detection Techniques"></a>A Critical Review of Common Log Data Sets Used for Evaluation of Sequence-based Anomaly Detection Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02854">http://arxiv.org/abs/2309.02854</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ait-aecid/anomaly-detection-log-datasets">https://github.com/ait-aecid/anomaly-detection-log-datasets</a></li>
<li>paper_authors: Max Landauer, Florian Skopik, Markus Wurzenberger</li>
<li>for: 本研究旨在分析六种公共可用的日志数据集，以检测日志数据中异常现象的探测方法。</li>
<li>methods: 本研究使用了深度学习技术来检测日志数据中的异常现象，并评估了这些异常检测技术的效果。</li>
<li>results: 研究发现，大多数异常现象不是直接相关于顺序的探测，而是相关于其他特征的探测。此外，研究还发现了一些简单的检测技术可以在这些数据集上达到高的检测率。<details>
<summary>Abstract</summary>
Log data store event execution patterns that correspond to underlying workflows of systems or applications. While most logs are informative, log data also include artifacts that indicate failures or incidents. Accordingly, log data are often used to evaluate anomaly detection techniques that aim to automatically disclose unexpected or otherwise relevant system behavior patterns. Recently, detection approaches leveraging deep learning have increasingly focused on anomalies that manifest as changes of sequential patterns within otherwise normal event traces. Several publicly available data sets, such as HDFS, BGL, Thunderbird, OpenStack, and Hadoop, have since become standards for evaluating these anomaly detection techniques, however, the appropriateness of these data sets has not been closely investigated in the past. In this paper we therefore analyze six publicly available log data sets with focus on the manifestations of anomalies and simple techniques for their detection. Our findings suggest that most anomalies are not directly related to sequential manifestations and that advanced detection techniques are not required to achieve high detection rates on these data sets.
</details>
<details>
<summary>摘要</summary>
log数据存储事件执行模式，与系统或应用程序的下面工作流程相对应。大多数日志数据都很有用，但日志数据也包含了失败或事件的畸形或物理特征。因此，日志数据经常用于评估自动发现不当或有关系系统行为模式的异常检测技术。在过去几年中，使用深度学习的检测方法在异常检测方面得到了越来越多的关注，特别是在 seq 执行模式中发现异常的变化。一些公共可用的数据集，如 HDFS、BGL、Thunderbird、OpenStack 和 Hadoop，已成为评估这些异常检测技术的标准数据集，但这些数据集的适用性没有过去仔细研究。在这篇论文中，我们分析了六个公共可用的日志数据集，关注异常的表现和简单的检测技术。我们的发现表明，大多数异常并不直接与 seq 执行模式相关，并且不需要高级的检测技术可以在这些数据集上 достичь高的检测率。
</details></li>
</ul>
<hr>
<h2 id="Random-postprocessing-for-combinatorial-Bayesian-optimization"><a href="#Random-postprocessing-for-combinatorial-Bayesian-optimization" class="headerlink" title="Random postprocessing for combinatorial Bayesian optimization"></a>Random postprocessing for combinatorial Bayesian optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02842">http://arxiv.org/abs/2309.02842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keisuke Morita, Yoshihiko Nishikawa, Masayuki Ohzeki</li>
<li>for:  optimize discrete “black-box” optimization problems</li>
<li>methods: Bayesian optimization techniques with postprocessing method to avoid duplicated samples</li>
<li>results: significantly reduces the number of sequential steps to find the global optimum, especially when the acquisition function is of maximum a posterior estimation.<details>
<summary>Abstract</summary>
Model-based sequential approaches to discrete "black-box" optimization, including Bayesian optimization techniques, often access the same points multiple times for a given objective function in interest, resulting in many steps to find the global optimum. Here, we numerically study the effect of a postprocessing method on Bayesian optimization that strictly prohibits duplicated samples in the dataset. We find the postprocessing method significantly reduces the number of sequential steps to find the global optimum, especially when the acquisition function is of maximum a posterior estimation. Our results provide a simple but general strategy to solve the slow convergence of Bayesian optimization for high-dimensional problems.
</details>
<details>
<summary>摘要</summary>
模型基于的连续Sequential方法，包括 Bayesian 优化技术，通常会在给定目标函数中访问相同的点多次，从而导致找到全局最优的过程比较慢。在这里，我们numerically研究了在 Bayesian 优化中使用禁止重复样本的后处理方法的效果。我们发现这种后处理方法可以减少找到全局最优的步骤数量，特别是当采集函数是最大 posterior 估计时。我们的结果提供了一种简单 yet 通用的策略，用于解决高维问题中 Bayesian 优化的慢速收敛问题。
</details></li>
</ul>
<hr>
<h2 id="BigVSAN-Enhancing-GAN-based-Neural-Vocoders-with-Slicing-Adversarial-Network"><a href="#BigVSAN-Enhancing-GAN-based-Neural-Vocoders-with-Slicing-Adversarial-Network" class="headerlink" title="BigVSAN: Enhancing GAN-based Neural Vocoders with Slicing Adversarial Network"></a>BigVSAN: Enhancing GAN-based Neural Vocoders with Slicing Adversarial Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02836">http://arxiv.org/abs/2309.02836</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sony/bigvsan_eval">https://github.com/sony/bigvsan_eval</a></li>
<li>paper_authors: Takashi Shibuya, Yuhta Takida, Yuki Mitsufuji</li>
<li>for: 这个论文是关于使用生成对抗网络（GAN）实现高质量音频合成的研究。</li>
<li>methods: 这个论文使用了改进的对抗网络训练框架——割辑对抗网络（SAN），以便在特征空间找到最佳投影。</li>
<li>results: 通过实验，这个论文表明了SAN可以提高GAN基于 vocoder的性能，包括BigVGAN，只需小改动。<details>
<summary>Abstract</summary>
Generative adversarial network (GAN)-based vocoders have been intensively studied because they can synthesize high-fidelity audio waveforms faster than real-time. However, it has been reported that most GANs fail to obtain the optimal projection for discriminating between real and fake data in the feature space. In the literature, it has been demonstrated that slicing adversarial network (SAN), an improved GAN training framework that can find the optimal projection, is effective in the image generation task. In this paper, we investigate the effectiveness of SAN in the vocoding task. For this purpose, we propose a scheme to modify least-squares GAN, which most GAN-based vocoders adopt, so that their loss functions satisfy the requirements of SAN. Through our experiments, we demonstrate that SAN can improve the performance of GAN-based vocoders, including BigVGAN, with small modifications. Our code is available at https://github.com/sony/bigvsan.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Introducing-Thermodynamics-Informed-Symbolic-Regression-–-A-Tool-for-Thermodynamic-Equations-of-State-Development"><a href="#Introducing-Thermodynamics-Informed-Symbolic-Regression-–-A-Tool-for-Thermodynamic-Equations-of-State-Development" class="headerlink" title="Introducing Thermodynamics-Informed Symbolic Regression – A Tool for Thermodynamic Equations of State Development"></a>Introducing Thermodynamics-Informed Symbolic Regression – A Tool for Thermodynamic Equations of State Development</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02805">http://arxiv.org/abs/2309.02805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scoop-group/tisr">https://github.com/scoop-group/tisr</a></li>
<li>paper_authors: Viktor Martinek, Ophelia Frotscher, Markus Richter, Roland Herzog</li>
<li>For: The paper is written for researchers and developers who are interested in creating accurate thermodynamic equations of state (EOS) for various industries and academic applications.* Methods: The paper introduces a new symbolic regression (SR) tool called thermodynamics-informed symbolic regression (TiSR), which combines the SR base with extensions to work with scattered experimental data, different residual pre- and post-processing options, and additional features for thermodynamic EOS development.* Results: The paper showcases the progress of TiSR and discusses its current state, future directions, and potential applications in the field of thermodynamics.Here is the same information in Simplified Chinese text:* For: 这篇论文是为了各种工业和学术应用中的热力学方程状态（EOS）的创建而写的。* Methods: 论文介绍了一种新的符号回归（SR）工具——热力学 Informed Symbolic Regression（TiSR），它将SR基础与EXTensions相结合，以处理各种散布的实验数据、不同的剩余预处理和后处理选项、以及附加的热力学EOS发展要求。* Results: 论文展示了TiSR的进步和当前状态，并讨论了未来的发展和应用于热力学领域。I hope this helps!<details>
<summary>Abstract</summary>
Thermodynamic equations of state (EOS) are essential for many industries as well as in academia. Even leaving aside the expensive and extensive measurement campaigns required for the data acquisition, the development of EOS is an intensely time-consuming process, which does often still heavily rely on expert knowledge and iterative fine-tuning. To improve upon and accelerate the EOS development process, we introduce thermodynamics-informed symbolic regression (TiSR), a symbolic regression (SR) tool aimed at thermodynamic EOS modeling. TiSR is already a capable SR tool, which was used in the research of https://doi.org/10.1007/s10765-023-03197-z. It aims to combine an SR base with the extensions required to work with often strongly scattered experimental data, different residual pre- and post-processing options, and additional features required to consider thermodynamic EOS development. Although TiSR is not ready for end users yet, this paper is intended to report on its current state, showcase the progress, and discuss (distant and not so distant) future directions. TiSR is available at https://github.com/scoop-group/TiSR and can be cited as https://doi.org/10.5281/zenodo.8317547.
</details>
<details>
<summary>摘要</summary>
thermodynamic equation of state (EOS) 是各行业以及学术界中非常重要的。即使不考虑数据收集的昂贵和复杂的测量活动，EOS 的开发还是一个非常时间consuming的过程，它frequently 仍然倚靠专家知识和迭代精细调整。为了改进和加速 EOS 开发过程，我们介绍 thermodynamic-informed symbolic regression (TiSR)，一种符号 regression (SR) 工具专门用于 thermodynamic EOS 模型化。TiSR 已经是一种可靠的 SR 工具，它在 https://doi.org/10.1007/s10765-023-03197-z 中的研究中使用。它的目标是将 SR 基础结合 thermodynamic EOS 开发所需的扩展，以及不同的剩余预处理和后处理选项，以及考虑 thermodynamic EOS 开发中的其他特性。虽然 TiSR 还不是用户准备就绪，但这篇文章是为报告其当前状况，展示进度，并讨论（远离和不远）未来方向。TiSR 可以在 https://github.com/scoop-group/TiSR 上下载，并可以在 https://doi.org/10.5281/zenodo.8317547 上引用。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Encoding-and-Decoding-of-Information-for-Split-Learning-in-Mobile-Edge-Computing-Leveraging-Information-Bottleneck-Theory"><a href="#Dynamic-Encoding-and-Decoding-of-Information-for-Split-Learning-in-Mobile-Edge-Computing-Leveraging-Information-Bottleneck-Theory" class="headerlink" title="Dynamic Encoding and Decoding of Information for Split Learning in Mobile-Edge Computing: Leveraging Information Bottleneck Theory"></a>Dynamic Encoding and Decoding of Information for Split Learning in Mobile-Edge Computing: Leveraging Information Bottleneck Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02787">http://arxiv.org/abs/2309.02787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omar Alhussein, Moshi Wei, Arashmid Akhavain</li>
<li>for: 该研究旨在提出一种基于分解学习的隐私保护分布式学习方法，以提高移动端Edge计算中的网络功能（如流量预测）的训练效果。</li>
<li>methods: 该研究使用了数据处理不均性和信息瓶颈理论来实现一种动态均衡传输资源的使用与共享干扰表示的信息含量，从而直接影响预测性能。</li>
<li>results: 该研究提出了一种基于encoder-decoder神经网络架构的新训练机制，可以实现可调Complexity-Relevance质量的交换，并且可以适应不同的实时网络条件和应用要求，从而减少运营成本和提高网络灵活性。<details>
<summary>Abstract</summary>
Split learning is a privacy-preserving distributed learning paradigm in which an ML model (e.g., a neural network) is split into two parts (i.e., an encoder and a decoder). The encoder shares so-called latent representation, rather than raw data, for model training. In mobile-edge computing, network functions (such as traffic forecasting) can be trained via split learning where an encoder resides in a user equipment (UE) and a decoder resides in the edge network. Based on the data processing inequality and the information bottleneck (IB) theory, we present a new framework and training mechanism to enable a dynamic balancing of the transmission resource consumption with the informativeness of the shared latent representations, which directly impacts the predictive performance. The proposed training mechanism offers an encoder-decoder neural network architecture featuring multiple modes of complexity-relevance tradeoffs, enabling tunable performance. The adaptability can accommodate varying real-time network conditions and application requirements, potentially reducing operational expenditure and enhancing network agility. As a proof of concept, we apply the training mechanism to a millimeter-wave (mmWave)-enabled throughput prediction problem. We also offer new insights and highlight some challenges related to recurrent neural networks from the perspective of the IB theory. Interestingly, we find a compression phenomenon across the temporal domain of the sequential model, in addition to the compression phase that occurs with the number of training epochs.
</details>
<details>
<summary>摘要</summary>
分学学习是一种隐私保护的分布式学习 paradigma，在其中一个机器学习模型（例如神经网络）被分解成两部分（即编码器和解码器）。编码器分享所谓的隐藏表示，而不是原始数据，用于模型训练。在移动边缘计算中，网络功能（如交通预测）可以通过分学学习进行训练，其中编码器位于用户设备（UE）中，而解码器位于边缘网络中。基于数据处理不等式和信息瓶颈（IB）理论，我们提出了一个新的框架和训练机制，以实现在传输资源消耗和隐藏表示的共享中进行动态的衡量平衡，直接影响预测性能。我们的训练机制提供了一个编码器-解码器神经网络架构， featuring 多种复杂度-相关性质的交易，以实现可调性。这种适应性可以满足不同的实时网络条件和应用需求，可能减少运营成本并提高网络的灵活性。作为证明，我们应用训练机制到一个毫米波（mmWave）吞吐量预测问题上。我们还提供了新的视角和高亮一些与IB理论相关的挑战，包括循环神经网络中的压缩现象。 Interestingly，我们发现在时间Domain中，隐藏表示的压缩现象，以及在训练环次中的压缩阶段。
</details></li>
</ul>
<hr>
<h2 id="CVE-driven-Attack-Technique-Prediction-with-Semantic-Information-Extraction-and-a-Domain-specific-Language-Model"><a href="#CVE-driven-Attack-Technique-Prediction-with-Semantic-Information-Extraction-and-a-Domain-specific-Language-Model" class="headerlink" title="CVE-driven Attack Technique Prediction with Semantic Information Extraction and a Domain-specific Language Model"></a>CVE-driven Attack Technique Prediction with Semantic Information Extraction and a Domain-specific Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02785">http://arxiv.org/abs/2309.02785</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Aghaei, Ehab Al-Shaer</li>
<li>for: 本研究旨在填补cybersecurity中的漏洞信息和攻击动作之间的知识渠道差距。</li>
<li>methods: 本文引入TTPpredictor工具，利用创新技术分析CVE描述文本，推断可能的攻击动作（tactics, techniques, and procedures,或TTP）。</li>
<li>results: 实验证明TTPpredictor具有约98%的准确率和95%-98%的F1分数，能够准确地将CVE分类到ATT&amp;CK技术中。TTPpredictor的性能高于现有的语言模型工具 like ChatGPT。<details>
<summary>Abstract</summary>
This paper addresses a critical challenge in cybersecurity: the gap between vulnerability information represented by Common Vulnerabilities and Exposures (CVEs) and the resulting cyberattack actions. CVEs provide insights into vulnerabilities, but often lack details on potential threat actions (tactics, techniques, and procedures, or TTPs) within the ATT&CK framework. This gap hinders accurate CVE categorization and proactive countermeasure initiation. The paper introduces the TTPpredictor tool, which uses innovative techniques to analyze CVE descriptions and infer plausible TTP attacks resulting from CVE exploitation. TTPpredictor overcomes challenges posed by limited labeled data and semantic disparities between CVE and TTP descriptions. It initially extracts threat actions from unstructured cyber threat reports using Semantic Role Labeling (SRL) techniques. These actions, along with their contextual attributes, are correlated with MITRE's attack functionality classes. This automated correlation facilitates the creation of labeled data, essential for categorizing novel threat actions into threat functionality classes and TTPs. The paper presents an empirical assessment, demonstrating TTPpredictor's effectiveness with accuracy rates of approximately 98% and F1-scores ranging from 95% to 98% in precise CVE classification to ATT&CK techniques. TTPpredictor outperforms state-of-the-art language model tools like ChatGPT. Overall, this paper offers a robust solution for linking CVEs to potential attack techniques, enhancing cybersecurity practitioners' ability to proactively identify and mitigate threats.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-the-Effects-of-Heterogeneous-Errors-on-Multi-fidelity-Bayesian-Optimization"><a href="#On-the-Effects-of-Heterogeneous-Errors-on-Multi-fidelity-Bayesian-Optimization" class="headerlink" title="On the Effects of Heterogeneous Errors on Multi-fidelity Bayesian Optimization"></a>On the Effects of Heterogeneous Errors on Multi-fidelity Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02771">http://arxiv.org/abs/2309.02771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Zanjani Foumani, Amin Yousefpour, Mehdi Shishehbor, Ramin Bostanabad</li>
<li>for: This paper is written for researchers and practitioners who are interested in using multi-fidelity methods for Bayesian optimization in materials design.</li>
<li>methods: The paper proposes a new multi-fidelity emulation method that learns a noise model for each data source and enables the use of highly biased low-fidelity sources for Bayesian optimization.</li>
<li>results: The paper demonstrates the performance of the proposed method through analytical examples and engineering problems on materials design, showing that it can improve the efficiency and accuracy of Bayesian optimization compared to existing methods.<details>
<summary>Abstract</summary>
Bayesian optimization (BO) is a sequential optimization strategy that is increasingly employed in a wide range of areas including materials design. In real world applications, acquiring high-fidelity (HF) data through physical experiments or HF simulations is the major cost component of BO. To alleviate this bottleneck, multi-fidelity (MF) methods are used to forgo the sole reliance on the expensive HF data and reduce the sampling costs by querying inexpensive low-fidelity (LF) sources whose data are correlated with HF samples. However, existing multi-fidelity BO (MFBO) methods operate under the following two assumptions that rarely hold in practical applications: (1) LF sources provide data that are well correlated with the HF data on a global scale, and (2) a single random process can model the noise in the fused data. These assumptions dramatically reduce the performance of MFBO when LF sources are only locally correlated with the HF source or when the noise variance varies across the data sources. In this paper, we dispense with these incorrect assumptions by proposing an MF emulation method that (1) learns a noise model for each data source, and (2) enables MFBO to leverage highly biased LF sources which are only locally correlated with the HF source. We illustrate the performance of our method through analytical examples and engineering problems on materials design.
</details>
<details>
<summary>摘要</summary>
bayesian 优化 (BO) 是一种顺序优化策略，在各种领域中越来越广泛应用，包括材料设计。在实际应用中，通过物理实验或高精度计算获取高精度数据是 BO 的主要成本组成部分。为了缓解这个瓶颈，使用多元精度 (MF) 方法，可以减少样本成本，通过访问便宜的低精度 (LF) 源的数据，其与高精度数据相关。然而，现有的 MFBO 方法假设 rarely 在实际应用中成立：（1） LF 源提供的数据与高精度数据在全球范围内很好地相关，和（2）数据源之间的噪声可以由单个随机过程模型。这些假设会使 MFBO 在 LF 源只是地方相关于高精度源或噪声方差随着数据源而变化时表现不佳。在这篇文章中，我们抛弃这些错误假设，提出一种 MF 模拟方法，其中（1）学习每个数据源的噪声模型，和（2）允许 MFBO 利用高偏见 LF 源。我们通过分析示例和工程问题来证明我们的方法的性能。
</details></li>
</ul>
<hr>
<h2 id="Unifying-over-smoothing-and-over-squashing-in-graph-neural-networks-A-physics-informed-approach-and-beyond"><a href="#Unifying-over-smoothing-and-over-squashing-in-graph-neural-networks-A-physics-informed-approach-and-beyond" class="headerlink" title="Unifying over-smoothing and over-squashing in graph neural networks: A physics informed approach and beyond"></a>Unifying over-smoothing and over-squashing in graph neural networks: A physics informed approach and beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02769">http://arxiv.org/abs/2309.02769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqi Shao, Dai Shi, Andi Han, Yi Guo, Qibin Zhao, Junbin Gao<br>for:The paper aims to address critical computational challenges in graph neural networks (GNNs), such as over-smoothing and limited expressive power, by introducing a new method called Multi-Scaled Heat Kernel based GNN (MHKG) and its generalization G-MHKG.methods:The proposed method reverses the time direction of the graph heat equation to enhance the sharpness of graph node features, and leverages high pass filtering functions to improve the performance of GNNs.results:The proposed models (MHKG and G-MHKG) outperform several GNN baseline models in terms of performance across various graph datasets characterized by both homophily and heterophily. Additionally, the trade-off between over-smoothing and over-squashing is analyzed, and the method is shown to handle both issues under mild conditions.<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have emerged as one of the leading approaches for machine learning on graph-structured data. Despite their great success, critical computational challenges such as over-smoothing, over-squashing, and limited expressive power continue to impact the performance of GNNs. In this study, inspired from the time-reversal principle commonly utilized in classical and quantum physics, we reverse the time direction of the graph heat equation. The resulted reversing process yields a class of high pass filtering functions that enhance the sharpness of graph node features. Leveraging this concept, we introduce the Multi-Scaled Heat Kernel based GNN (MHKG) by amalgamating diverse filtering functions' effects on node features. To explore more flexible filtering conditions, we further generalize MHKG into a model termed G-MHKG and thoroughly show the roles of each element in controlling over-smoothing, over-squashing and expressive power. Notably, we illustrate that all aforementioned issues can be characterized and analyzed via the properties of the filtering functions, and uncover a trade-off between over-smoothing and over-squashing: enhancing node feature sharpness will make model suffer more from over-squashing, and vice versa. Furthermore, we manipulate the time again to show how G-MHKG can handle both two issues under mild conditions. Our conclusive experiments highlight the effectiveness of proposed models. It surpasses several GNN baseline models in performance across graph datasets characterized by both homophily and heterophily.
</details>
<details>
<summary>摘要</summary>
GRAPH神经网络（GNNs）已经成为机器学习图structured数据的一种主流方法。尽管它们具有出色的成功，但是计算挑战，如过滤、过压和表达能力的局限性，仍然影响GNNs的性能。在这个研究中，我们基于时间反转原理，通常用于古典物理和量子物理中，对图热方程进行时间反转。这个过程生成了一类高通过滤函数，可以增强图节点特征的锐度。基于这个概念，我们介绍了多级热均衡基于GNN（MHKG），通过不同滤波函数对节点特征产生的影响。为了探索更多的筛选条件，我们进一步总结MHKG模型，并详细介绍每个元素在控制过滤、过压和表达能力方面的作用。我们发现，所有的问题都可以通过滤波函数的性质来characterized和分析，并发现过滤和过压之间存在一种负相关关系：增强节点特征锐度会使模型受到更多的过压，并且vice versa。此外，我们再次操作时间，展示了G-MHKG模型在轻度条件下可以处理两个问题。我们的实验结果表明，提出的模型在多个图 Dataset上表现出色，超过了一些GNN基eline模型。
</details></li>
</ul>
<hr>
<h2 id="Towards-Unsupervised-Graph-Completion-Learning-on-Graphs-with-Features-and-Structure-Missing"><a href="#Towards-Unsupervised-Graph-Completion-Learning-on-Graphs-with-Features-and-Structure-Missing" class="headerlink" title="Towards Unsupervised Graph Completion Learning on Graphs with Features and Structure Missing"></a>Towards Unsupervised Graph Completion Learning on Graphs with Features and Structure Missing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02762">http://arxiv.org/abs/2309.02762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sichao Fu, Qinmu Peng, Yang He, Baokun Du, Xinge You<br>for: 这种方法可以用于改善存在特定任务下的图分析Graph Neural Networks (GNN)的性能，特别是在存在部分缺失的节点特征或结构关系的情况下。methods: 我们提出了一种更通用的图完成学习（GCL）框架，通过自我监督学习来提高现有GNN变体在图中的任务性能，并解决了现有GCL方法存在的标签依赖、节点特征和结构关系的偏见问题。results: 我们在八个 dataset、三种 GNN 变体和五种缺失率进行了广泛的实验，结果显示我们的提议方法能够有效地提高GNN的任务性能。<details>
<summary>Abstract</summary>
In recent years, graph neural networks (GNN) have achieved significant developments in a variety of graph analytical tasks. Nevertheless, GNN's superior performance will suffer from serious damage when the collected node features or structure relationships are partially missing owning to numerous unpredictable factors. Recently emerged graph completion learning (GCL) has received increasing attention, which aims to reconstruct the missing node features or structure relationships under the guidance of a specifically supervised task. Although these proposed GCL methods have made great success, they still exist the following problems: the reliance on labels, the bias of the reconstructed node features and structure relationships. Besides, the generalization ability of the existing GCL still faces a huge challenge when both collected node features and structure relationships are partially missing at the same time. To solve the above issues, we propose a more general GCL framework with the aid of self-supervised learning for improving the task performance of the existing GNN variants on graphs with features and structure missing, termed unsupervised GCL (UGCL). Specifically, to avoid the mismatch between missing node features and structure during the message-passing process of GNN, we separate the feature reconstruction and structure reconstruction and design its personalized model in turn. Then, a dual contrastive loss on the structure level and feature level is introduced to maximize the mutual information of node representations from feature reconstructing and structure reconstructing paths for providing more supervision signals. Finally, the reconstructed node features and structure can be applied to the downstream node classification task. Extensive experiments on eight datasets, three GNN variants and five missing rates demonstrate the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
Recently, graph neural networks (GNN) have made significant progress in various graph analytical tasks. However, GNN's performance will be severely affected when the collected node features or structural relationships are partially missing due to various unpredictable factors. To address this issue, graph completion learning (GCL) has received increasing attention, which aims to reconstruct the missing node features or structural relationships under the guidance of a specifically supervised task. Although these proposed GCL methods have achieved great success, they still have the following problems: reliance on labels, bias in the reconstructed node features and structural relationships. Moreover, the existing GCL methods have difficulty in generalizing when both collected node features and structural relationships are partially missing simultaneously.To solve these issues, we propose a more general GCL framework with the aid of self-supervised learning to improve the task performance of the existing GNN variants on graphs with features and structure missing, termed unsupervised GCL (UGCL). Specifically, to address the mismatch between missing node features and structure during the message-passing process of GNN, we separate the feature reconstruction and structural reconstruction and design personalized models for each. Then, we introduce a dual contrastive loss on the structure level and feature level to maximize the mutual information of node representations from feature reconstructing and structure reconstructing paths, providing more supervision signals. Finally, the reconstructed node features and structure can be applied to the downstream node classification task. Our extensive experiments on eight datasets, three GNN variants, and five missing rates demonstrate the effectiveness of our proposed method.
</details></li>
</ul>
<hr>
<h2 id="Safe-Neural-Control-for-Non-Affine-Control-Systems-with-Differentiable-Control-Barrier-Functions"><a href="#Safe-Neural-Control-for-Non-Affine-Control-Systems-with-Differentiable-Control-Barrier-Functions" class="headerlink" title="Safe Neural Control for Non-Affine Control Systems with Differentiable Control Barrier Functions"></a>Safe Neural Control for Non-Affine Control Systems with Differentiable Control Barrier Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04492">http://arxiv.org/abs/2309.04492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Xiao, Ross Allen, Daniela Rus</li>
<li>for: 这 paper Addresses the problem of safety-critical control for non-affine control systems.</li>
<li>methods: The paper uses Control Barrier Functions (CBFs) to optimize quadratic costs subject to state and control constraints, and incorporates higher-order CBFs into neural ordinary differential equation-based learning models as differentiable CBFs to guarantee safety for non-affine control systems.</li>
<li>results: The proposed framework is capable of learning complex and optimal control policies that are usually intractable online, and can address the conservativeness of CBFs such that the system state will not stay unnecessarily far away from safe set boundaries. The effectiveness of the proposed framework is illustrated on LiDAR-based autonomous driving and compared with existing methods.<details>
<summary>Abstract</summary>
This paper addresses the problem of safety-critical control for non-affine control systems. It has been shown that optimizing quadratic costs subject to state and control constraints can be sub-optimally reduced to a sequence of quadratic programs (QPs) by using Control Barrier Functions (CBFs). Our recently proposed High Order CBFs (HOCBFs) can accommodate constraints of arbitrary relative degree. The main challenges in this approach are that it requires affine control dynamics and the solution of the CBF-based QP is sub-optimal since it is solved point-wise. To address these challenges, we incorporate higher-order CBFs into neural ordinary differential equation-based learning models as differentiable CBFs to guarantee safety for non-affine control systems. The differentiable CBFs are trainable in terms of their parameters, and thus, they can address the conservativeness of CBFs such that the system state will not stay unnecessarily far away from safe set boundaries. Moreover, the imitation learning model is capable of learning complex and optimal control policies that are usually intractable online. We illustrate the effectiveness of the proposed framework on LiDAR-based autonomous driving and compare it with existing methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improved-Outlier-Robust-Seeding-for-k-means"><a href="#Improved-Outlier-Robust-Seeding-for-k-means" class="headerlink" title="Improved Outlier Robust Seeding for k-means"></a>Improved Outlier Robust Seeding for k-means</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02710">http://arxiv.org/abs/2309.02710</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amit Deshpande, Rameshwar Pratap</li>
<li>for: 提出了一种robust的$k$-means算法，可以抗性减少噪声和异常点的影响。</li>
<li>methods: 使用了一种简单的变换方法来改进$D^{2}$ sampling的分布，使其更加抗性。</li>
<li>results: 提出了一种 Linear Time $k$-means算法，可以在 $O(ndk)$ 时间内输出 $O(k)$ 个团集，并且有 $O(1)$ 的近似性保证。<details>
<summary>Abstract</summary>
The $k$-means is a popular clustering objective, although it is inherently non-robust and sensitive to outliers. Its popular seeding or initialization called $k$-means++ uses $D^{2}$ sampling and comes with a provable $O(\log k)$ approximation guarantee \cite{AV2007}. However, in the presence of adversarial noise or outliers, $D^{2}$ sampling is more likely to pick centers from distant outliers instead of inlier clusters, and therefore its approximation guarantees \textit{w.r.t.} $k$-means solution on inliers, does not hold.   Assuming that the outliers constitute a constant fraction of the given data, we propose a simple variant in the $D^2$ sampling distribution, which makes it robust to the outliers. Our algorithm runs in $O(ndk)$ time, outputs $O(k)$ clusters, discards marginally more points than the optimal number of outliers, and comes with a provable $O(1)$ approximation guarantee.   Our algorithm can also be modified to output exactly $k$ clusters instead of $O(k)$ clusters, while keeping its running time linear in $n$ and $d$. This is an improvement over previous results for robust $k$-means based on LP relaxation and rounding \cite{Charikar}, \cite{KrishnaswamyLS18} and \textit{robust $k$-means++} \cite{DeshpandeKP20}. Our empirical results show the advantage of our algorithm over $k$-means++~\cite{AV2007}, uniform random seeding, greedy sampling for $k$ means~\cite{tkmeanspp}, and robust $k$-means++~\cite{DeshpandeKP20}, on standard real-world and synthetic data sets used in previous work. Our proposal is easily amenable to scalable, faster, parallel implementations of $k$-means++ \cite{Bahmani,BachemL017} and is of independent interest for coreset constructions in the presence of outliers \cite{feldman2007ptas,langberg2010universal,feldman2011unified}.
</details>
<details>
<summary>摘要</summary>
“$k$-means”是一种受欢迎的聚类目标函数，然而它本身是非稳定的和敏感于异常值的。它的常用的种子或初始化方法called $k$-means++使用$D^{2}$抽样，并有一个可证明的$O(\log k)$的近似保证 \cite{AV2007}。然而，在异常值或异常抽样下，$D^{2}$抽样更容易从远程异常值中选择中心点而不是内lier峰值，因此其近似保证与$k$-means解峰不同。   Assuming that the outliers constitute a constant fraction of the given data, we propose a simple variant in the $D^2$ sampling distribution, which makes it robust to the outliers. Our algorithm runs in $O(ndk)$ time, outputs $O(k)$ clusters, discards marginally more points than the optimal number of outliers, and comes with a provable $O(1)$ approximation guarantee.   Our algorithm can also be modified to output exactly $k$ clusters instead of $O(k)$ clusters, while keeping its running time linear in $n$ and $d$. This is an improvement over previous results for robust $k$-means based on LP relaxation and rounding \cite{Charikar}, \cite{KrishnaswamyLS18} and \textit{robust $k$-means++} \cite{DeshpandeKP20}. Our empirical results show the advantage of our algorithm over $k$-means++ \cite{AV2007}, uniform random seeding, greedy sampling for $k$ means \cite{tkmeanspp}, and robust $k$-means++ \cite{DeshpandeKP20}, on standard real-world and synthetic data sets used in previous work. Our proposal is easily amenable to scalable, faster, parallel implementations of $k$-means++ \cite{Bahmani,BachemL017} and is of independent interest for coreset constructions in the presence of outliers \cite{feldman2007ptas,langberg2010universal,feldman2011unified}.
</details></li>
</ul>
<hr>
<h2 id="Marketing-Budget-Allocation-with-Offline-Constrained-Deep-Reinforcement-Learning"><a href="#Marketing-Budget-Allocation-with-Offline-Constrained-Deep-Reinforcement-Learning" class="headerlink" title="Marketing Budget Allocation with Offline Constrained Deep Reinforcement Learning"></a>Marketing Budget Allocation with Offline Constrained Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02669">http://arxiv.org/abs/2309.02669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianchi Cai, Jiyan Jiang, Wenpeng Zhang, Shiji Zhou, Xierui Song, Li Yu, Lihong Gu, Xiaodong Zeng, Jinjie Gu, Guannan Zhang</li>
<li>for: 这个论文关注在线广告运营中的营销预算分配问题，使用先前收集的线上数据。</li>
<li>methods: 该论文提出了一种基于游戏理论的离线值基 reinforcement learning方法，使用混合策略，从而减少了存储多个策略的需求，实现了几乎最佳的策略效率，使其在实际应用中成为可能。</li>
<li>results: 我们的实验表明，该方法可以在一个大规模的广告运营中，覆盖数十万名用户和数百亿的预算，并且超过了多种基准方法。此外，该方法可以 garantía到最佳策略的收敛，而不是先前的值基 reinforcement learning方法不能 garantía。<details>
<summary>Abstract</summary>
We study the budget allocation problem in online marketing campaigns that utilize previously collected offline data. We first discuss the long-term effect of optimizing marketing budget allocation decisions in the offline setting. To overcome the challenge, we propose a novel game-theoretic offline value-based reinforcement learning method using mixed policies. The proposed method reduces the need to store infinitely many policies in previous methods to only constantly many policies, which achieves nearly optimal policy efficiency, making it practical and favorable for industrial usage. We further show that this method is guaranteed to converge to the optimal policy, which cannot be achieved by previous value-based reinforcement learning methods for marketing budget allocation. Our experiments on a large-scale marketing campaign with tens-of-millions users and more than one billion budget verify the theoretical results and show that the proposed method outperforms various baseline methods. The proposed method has been successfully deployed to serve all the traffic of this marketing campaign.
</details>
<details>
<summary>摘要</summary>
我们研究线上广告营运中的预算分配问题，利用先前收集的资料进行优化。我们首先讨论了在线上设定预算分配的长期影响。为解决这个挑战，我们提出了一种基于游戏理论的掌握策略混合方法。这种方法可以将储存多个策略的需求降低至几个策略，实现近乎最佳策略效率，使其在工业中实际和有利。我们进一步证明这种方法将会导向最佳策略，而先前的值基掌握学习方法不能实现这一点。我们的实验显示，这种方法在一个涉及数十万名用户和一百亿预算的大规模广告营运中表现出色，并且超过了各种基准方法。我们已经将这种方法发布到服务这个广告营运中的所有流量。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-Over-Images-Vertical-Decompositions-and-Pre-Trained-Backbones-Are-Difficult-to-Beat"><a href="#Federated-Learning-Over-Images-Vertical-Decompositions-and-Pre-Trained-Backbones-Are-Difficult-to-Beat" class="headerlink" title="Federated Learning Over Images: Vertical Decompositions and Pre-Trained Backbones Are Difficult to Beat"></a>Federated Learning Over Images: Vertical Decompositions and Pre-Trained Backbones Are Difficult to Beat</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03237">http://arxiv.org/abs/2309.03237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Erdong Hu, Yuxin Tang, Anastasios Kyrillidis, Chris Jermaine</li>
<li>for: 这个论文是为了研究在联合环境中学习的算法。</li>
<li>methods: 论文使用了多种算法来学习，包括分割神经网络、纵向归一化和权重学习。</li>
<li>results: 研究发现，将神经网络Vertically decomposing可以获得最佳结果，并超过标准的重要方法。<details>
<summary>Abstract</summary>
We carefully evaluate a number of algorithms for learning in a federated environment, and test their utility for a variety of image classification tasks. We consider many issues that have not been adequately considered before: whether learning over data sets that do not have diverse sets of images affects the results; whether to use a pre-trained feature extraction "backbone"; how to evaluate learner performance (we argue that classification accuracy is not enough), among others. Overall, across a wide variety of settings, we find that vertically decomposing a neural network seems to give the best results, and outperforms more standard reconciliation-used methods.
</details>
<details>
<summary>摘要</summary>
我们仔细评估了许多 Federated Learning 环境中学习算法，并对各种图像分类任务进行测试。我们考虑了许多未经充分考虑的问题：不同数据集之间的图像多样性对结果的影响；使用预训练的特征提取“脊梁”；评估学习器性能的方法（我们认为分类精度不够）等。总之，在多种设置下，我们发现垂直 decomposing 神经网络可以获得最好的结果，并超越了标准的重新整合方法。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-as-Kernel-Approximation"><a href="#Contrastive-Learning-as-Kernel-Approximation" class="headerlink" title="Contrastive Learning as Kernel Approximation"></a>Contrastive Learning as Kernel Approximation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02651">http://arxiv.org/abs/2309.02651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konstantinos Christopher Tsiolis</li>
<li>for: 这个论文主要针对的是用contrastive learning方法学习从无标签数据中提取特征。</li>
<li>methods: 这个论文使用了contrastive loss函数来训练低维ensional的特征表示，并使用了对偶搜集方法来生成对称的训练对。</li>
<li>results: 研究人员发现，使用contrastive learning方法可以从大量的无标签数据中提取高质量的特征，并且可以在小型标签数据上进行高精度的预测。<details>
<summary>Abstract</summary>
In standard supervised machine learning, it is necessary to provide a label for every input in the data. While raw data in many application domains is easily obtainable on the Internet, manual labelling of this data is prohibitively expensive. To circumvent this issue, contrastive learning methods produce low-dimensional vector representations (also called features) of high-dimensional inputs on large unlabelled datasets. This is done by training with a contrastive loss function, which enforces that similar inputs have high inner product and dissimilar inputs have low inner product in the feature space. Rather than annotating each input individually, it suffices to define a means of sampling pairs of similar and dissimilar inputs. Contrastive features can then be fed as inputs to supervised learning systems on much smaller labelled datasets to obtain high accuracy on end tasks of interest.   The goal of this thesis is to provide an overview of the current theoretical understanding of contrastive learning, specifically as it pertains to the minimizers of contrastive loss functions and their relationship to prior methods for learning features from unlabelled data. We highlight popular contrastive loss functions whose minimizers implicitly approximate a positive semidefinite (PSD) kernel. The latter is a well-studied object in functional analysis and learning theory that formalizes a notion of similarity between elements of a space. PSD kernels provide an implicit definition of features through the theory of reproducing kernel Hilbert spaces.
</details>
<details>
<summary>摘要</summary>
通常的超级vised机器学习中需要为每个输入提供标签。然而，在许多应用领域中，原始数据的 raw 数据可以轻松地从互联网上获得，但是手动标签这些数据是不可能的。为了解决这个问题，对冲学方法生成了低维度向量表示（也称为特征），这些特征可以在大量未标注数据上进行训练。这是通过对冲损失函数进行训练，使得相似的输入在特征空间中具有高内积，而不相似的输入具有低内积。而不是每个输入都需要注释，只需要定义一种方法来随机对应输入进行对比即可。对冲特征可以被用作supervised learning系统的输入，并在许多小型标注数据上获得高精度的终点任务。本论文的目标是提供对冲学的当前理论认知，具体来说是关于对冲损失函数的最小值和其与先前未标注数据学习方法之间的关系。我们强调了流行的对冲损失函数，其最小值隐式地 aproximate 一个正semidefinite（PSD）kernel。后者是函数分析和学习理论中已有的一个很好地定义相似性的概念。PSD kernel 提供了一种隐式地定义特征的方法，通过对冲特征空间的理论。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/06/cs.LG_2023_09_06/" data-id="clmvt7tan00hd26rd5pfahebi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/06/eess.IV_2023_09_06/" class="article-date">
  <time datetime="2023-09-06T09:00:00.000Z" itemprop="datePublished">2023-09-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/06/eess.IV_2023_09_06/">eess.IV - 2023-09-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Compact-Representation-of-n-th-order-TGV"><a href="#Compact-Representation-of-n-th-order-TGV" class="headerlink" title="Compact Representation of n-th order TGV"></a>Compact Representation of n-th order TGV</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03359">http://arxiv.org/abs/2309.03359</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manu Ghulyani, Muthuvel Arigovindan</li>
<li>for: 这个论文的目的是探讨高阶导数迁移的普适化方法，以及解决高阶导数迁移导致的干扰问题。</li>
<li>methods: 该论文提出了一种新的总体化变分方法（TGV），该方法可以在不同的区域内使用不同的拟合程度来描述图像的 Piece-wise  polynomial 行为。</li>
<li>results: 该论文的结果表明，使用TGV regularization可以提高图像重建的稳定性和准确性，并且可以在不同的图像中实现不同的拟合程度。然而，目前还没有一个可靠的算法来解决TGV regularization的高阶问题。<details>
<summary>Abstract</summary>
Although regularization methods based on derivatives are favored for their robustness and computational simplicity, research exploring higher-order derivatives remains limited. This scarcity can possibly be attributed to the appearance of oscillations in reconstructions when directly generalizing TV-1 to higher orders (3 or more). Addressing this, Bredies et. al introduced a notable approach for generalizing total variation, known as Total Generalized Variation (TGV). This technique introduces a regularization that generates estimates embodying piece-wise polynomial behavior of varying degrees across distinct regions of an image.Importantly, to our current understanding, no sufficiently general algorithm exists for solving TGV regularization for orders beyond 2. This is likely because of two problems: firstly, the problem is complex as TGV regularization is defined as a minimization problem with non-trivial constraints, and secondly, TGV is represented in terms of tensor-fields which is difficult to implement. In this work we tackle the first challenge by giving two simple and implementable representations of n th order TGV
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Real-Time-Dynamic-Data-Driven-Deformable-Registration-for-Image-Guided-Neurosurgery-Computational-Aspects"><a href="#Real-Time-Dynamic-Data-Driven-Deformable-Registration-for-Image-Guided-Neurosurgery-Computational-Aspects" class="headerlink" title="Real-Time Dynamic Data Driven Deformable Registration for Image-Guided Neurosurgery: Computational Aspects"></a>Real-Time Dynamic Data Driven Deformable Registration for Image-Guided Neurosurgery: Computational Aspects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03336">http://arxiv.org/abs/2309.03336</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikos Chrisochoides, Andrey Fedorov, Yixun Liu, Andriy Kot, Panos Foteinos, Fotis Drakopoulos, Christos Tsolakis, Emmanuel Billias, Olivier Clatz, Nicholas Ayache, Alex Golby, Peter Black, Ron Kikinis</li>
<li>for: 这篇论文旨在描述用于脑外科手术规划的脑MR成像数据的动态数据驱动非均匀准确注册方法，以及这种方法的计算方面的进化和未来发展。</li>
<li>methods: 该方法使用动态数据驱动非均匀准确注册技术，可以在手术过程中动态调整预操作MR成像数据，以便考虑到手术过程中脑组织的变形。</li>
<li>results: 该方法可以准确地考虑到手术过程中脑组织的变形，并且可以提供高品质的脑MR成像数据，以帮助脑外科手术规划。<details>
<summary>Abstract</summary>
Current neurosurgical procedures utilize medical images of various modalities to enable the precise location of tumors and critical brain structures to plan accurate brain tumor resection. The difficulty of using preoperative images during the surgery is caused by the intra-operative deformation of the brain tissue (brain shift), which introduces discrepancies concerning the preoperative configuration. Intra-operative imaging allows tracking such deformations but cannot fully substitute for the quality of the pre-operative data. Dynamic Data Driven Deformable Non-Rigid Registration (D4NRR) is a complex and time-consuming image processing operation that allows the dynamic adjustment of the pre-operative image data to account for intra-operative brain shift during the surgery. This paper summarizes the computational aspects of a specific adaptive numerical approximation method and its variations for registering brain MRIs. It outlines its evolution over the last 15 years and identifies new directions for the computational aspects of the technique.
</details>
<details>
<summary>摘要</summary>
当前的神经外科手术使用各种媒体的医疗图像来准确定位肿瘤和critical brain structures，以便准确肿瘤除除。但是使用前opera的图像在手术过程中具有困难，这是因为脑肿瘤（brain shift）的变形会导致图像与实际状态不符，从而引起差异。实时成像技术可以跟踪这些变形，但是无法完全取代优质的前opera数据。D4NRR是一种复杂且时间消耗的图像处理操作，它允许在手术过程中动态调整前opera图像数据，以适应脑肿瘤的变形。本文概述了D4NRR的计算方面的特点和其变化在过去15年中，以及新的计算方向。
</details></li>
</ul>
<hr>
<h2 id="The-Secrets-of-Non-Blind-Poisson-Deconvolution"><a href="#The-Secrets-of-Non-Blind-Poisson-Deconvolution" class="headerlink" title="The Secrets of Non-Blind Poisson Deconvolution"></a>The Secrets of Non-Blind Poisson Deconvolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03105">http://arxiv.org/abs/2309.03105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhiram Gnanasambandam, Yash Sanghvi, Stanley H. Chan</li>
<li>for: 这篇论文主要针对的是非目标束化图像的恢复，尤其是在光子限制的情况下，传统的恢复算法失效的问题。</li>
<li>methods: 这篇论文提出了一种系统性的分析方法，涵盖了传统和深度学习方法的Poisson非目标束化算法。基于这种分析，提出了五个”秘密”，用于设计算法。</li>
<li>results: 根据这种分析，提出了一种证明性的方法，结合了五个秘密。实验结果显示，新方法与一些最新的方法相当，而与一些较老的方法超越。<details>
<summary>Abstract</summary>
Non-blind image deconvolution has been studied for several decades but most of the existing work focuses on blur instead of noise. In photon-limited conditions, however, the excessive amount of shot noise makes traditional deconvolution algorithms fail. In searching for reasons why these methods fail, we present a systematic analysis of the Poisson non-blind deconvolution algorithms reported in the literature, covering both classical and deep learning methods. We compile a list of five "secrets" highlighting the do's and don'ts when designing algorithms. Based on this analysis, we build a proof-of-concept method by combining the five secrets. We find that the new method performs on par with some of the latest methods while outperforming some older ones.
</details>
<details>
<summary>摘要</summary>
非盲图像恢复已经在数十年中被研究，但大多数现有工作都集中在模糊问题上，而在光子限制条件下，过度的射击噪声使传统的恢复算法失效。在寻找这些方法失败的原因时，我们提供了系统性的文献分析，涵盖了经典和深度学习方法。我们编译了五个"秘密"，描述了设计算法时的做法和不做法。基于这一分析，我们建立了一种证明性方法，并发现其与一些最新的方法性能相似，而在一些较老的方法上表现出色。
</details></li>
</ul>
<hr>
<h2 id="A-flexible-and-accurate-total-variation-and-cascaded-denoisers-based-image-reconstruction-algorithm-for-hyperspectrally-compressed-ultrafast-photography"><a href="#A-flexible-and-accurate-total-variation-and-cascaded-denoisers-based-image-reconstruction-algorithm-for-hyperspectrally-compressed-ultrafast-photography" class="headerlink" title="A flexible and accurate total variation and cascaded denoisers-based image reconstruction algorithm for hyperspectrally compressed ultrafast photography"></a>A flexible and accurate total variation and cascaded denoisers-based image reconstruction algorithm for hyperspectrally compressed ultrafast photography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02835">http://arxiv.org/abs/2309.02835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihan Guo, Jiali Yao, Dalong Qi, Pengpeng Ding, Chengzhi Jin, Ning Xu, Zhiling Zhang, Yunhua Yao, Lianzhong Deng, Zhiyong Wang, Zhenrong Sun, Shian Zhang</li>
<li>for: 高速光学画像捕捉（HCUP）技术可以同时实现时间和频谱图像捕捉，但由于压缩率过高和传统重建算法的限制，HCUP的图像重建质量受到影响。</li>
<li>methods: 提议使用全Variation（TV）和紧接着去噪器（CD）组合算法来解决HCUP图像重建问题，该算法基于迭代方向多分子方法，可以保持图像的平滑性，同时利用深度去噪网络获取更多的约束，解决了本地相似性和运动补做的共同稀疏表示问题。</li>
<li>results: 实验和 simulate结果表明，提议的TV-CD算法可以有效提高HCUP图像重建的准确性和质量，并且可以推动HCUP在捕捉高维复杂物理、化学和生物ultrafast光学场景中的实际应用。<details>
<summary>Abstract</summary>
Hyperspectrally compressed ultrafast photography (HCUP) based on compressed sensing and the time- and spectrum-to-space mappings can simultaneously realize the temporal and spectral imaging of non-repeatable or difficult-to-repeat transient events passively in a single exposure. It possesses an incredibly high frame rate of tens of trillions of frames per second and a sequence depth of several hundred, and plays a revolutionary role in single-shot ultrafast optical imaging. However, due to the ultra-high data compression ratio induced by the extremely large sequence depth as well as the limited fidelities of traditional reconstruction algorithms over the reconstruction process, HCUP suffers from a poor image reconstruction quality and fails to capture fine structures in complex transient scenes. To overcome these restrictions, we propose a flexible image reconstruction algorithm based on the total variation (TV) and cascaded denoisers (CD) for HCUP, named the TV-CD algorithm. It applies the TV denoising model cascaded with several advanced deep learning-based denoising models in the iterative plug-and-play alternating direction method of multipliers framework, which can preserve the image smoothness while utilizing the deep denoising networks to obtain more priori, and thus solving the common sparsity representation problem in local similarity and motion compensation. Both simulation and experimental results show that the proposed TV-CD algorithm can effectively improve the image reconstruction accuracy and quality of HCUP, and further promote the practical applications of HCUP in capturing high-dimensional complex physical, chemical and biological ultrafast optical scenes.
</details>
<details>
<summary>摘要</summary>
高级спектраль压缩超快摄影（HCUP）基于压缩感知和时间-频谱空间映射，可同时实现非重复或Difficult-to-repeat脉冲事件的时间和频谱成像，在单 exposure 中完成。它具有无 precedent 的高帧率，达到了 tens of trillions of frames per second 和 Several hundred sequence depth，扮演了革命性的角色在单shot ultrafast optical imaging 中。然而，由于 ultra-high data compression ratio 以及传统重建算法的限制，HCUP 的图像重建质量受到了严重的限制，无法捕捉复杂的脉冲场景中的细节。为解决这些限制，我们提出了基于全量变量（TV）和级联去噪器（CD）的 flexible image reconstruction algorithm，称为 TV-CD 算法。它在 iterative plug-and-play alternating direction method of multipliers 框架中，将 TV 去噪模型与多种高级深度学习去噪模型相互嵌套，以保持图像的稳定性，同时利用深度去噪网络获取更多的PRIOR，解决了 мест similarity和运动补做的共同简约表示问题。在 simulate 和实验中，我们发现 TV-CD 算法可以有效提高 HCUP 的图像重建质量和精度，并推动 HCUP 在捕捉高维复杂物理、化学和生物 ultrafast optical 场景中的实际应用。
</details></li>
</ul>
<hr>
<h2 id="Review-of-photoacoustic-imaging-plus-X"><a href="#Review-of-photoacoustic-imaging-plus-X" class="headerlink" title="Review of photoacoustic imaging plus X"></a>Review of photoacoustic imaging plus X</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02638">http://arxiv.org/abs/2309.02638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daohuai Jiang, Luyao Zhu, Shangqing Tong, Yuting Shen, Feng Gao, Fei Gao</li>
<li>For: This paper provides an overview of the emerging research frontiers in photoacoustic imaging (PAI) technology, including its applications in various biomedical fields and its combination with other advanced technologies.* Methods: The paper discusses the current state of PAI technology and its combination with other technologies, including PAI plus treatment, PAI plus new circuit design, PAI plus accurate positioning systems, PAI plus fast scanning systems, PAI plus novel ultrasound sensors, PAI plus advanced laser sources, PAI plus deep learning, and PAI plus other imaging modalities.* Results: The paper summarizes the technical advantages and prospects for application of each technology, with a focus on recent developments in the past three years. It also discusses the challenges and potential future work in the PAI plus X area.Here’s the information in Simplified Chinese text:* For: 这篇评论文章提供了photoacoustic imaging（PAI）技术的新兴研究前沿，包括它在各种生物医学领域的应用以及与其他先进技术的组合。* Methods: 文章讨论了PAI技术的当前状况以及它与其他技术的组合，包括PAI加 treatment、PAI加新电路设计、PAI加精准定位系统、PAI加快扫描系统、PAI加新式ultrasound探测器、PAI加高级激光源、PAI加深度学习以及PAI加其他成像模式。* Results: 文章summarizes each technology’s current state, technical advantages, and prospects for application, with a focus on recent developments in the past three years. It also discusses the challenges and potential future work in the PAI plus X area.<details>
<summary>Abstract</summary>
Photoacoustic imaging (PAI) is a novel modality in biomedical imaging technology that combines the rich optical contrast with the deep penetration of ultrasound. To date, PAI technology has found applications in various biomedical fields. In this review, we present an overview of the emerging research frontiers on PAI plus other advanced technologies, named as PAI plus X, which includes but not limited to PAI plus treatment, PAI plus new circuits design, PAI plus accurate positioning system, PAI plus fast scanning systems, PAI plus novel ultrasound sensors, PAI plus advanced laser sources, PAI plus deep learning, and PAI plus other imaging modalities. We will discuss each technology's current state, technical advantages, and prospects for application, reported mostly in recent three years. Lastly, we discuss and summarize the challenges and potential future work in PAI plus X area.
</details>
<details>
<summary>摘要</summary>
照片听影技术（PAI）是生物医学成像技术中的一种新兴方式，它结合了丰富的光学强度和深入的超声探测。至今，PAI技术已找到了多个生物医学应用领域。在本文中，我们提供PAI以外其他高级技术的概述，称为PAI加X，包括但不限于PAI加治疗、PAI加新电路设计、PAI加准确定位系统、PAI加快扫描系统、PAI加新的ultrasound探测器、PAI加高级激光源、PAI加深度学习和PAI加其他成像方式。我们将讨论每种技术的当前状态、技术优势和应用前景，大多是在过去三年内发表的研究报告。最后，我们讨论和总结PAI加X领域中的挑战和未来工作。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/06/eess.IV_2023_09_06/" data-id="clmvt7tdd00s026rdhjupbz1u" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/06/eess.SP_2023_09_06/" class="article-date">
  <time datetime="2023-09-06T08:00:00.000Z" itemprop="datePublished">2023-09-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/06/eess.SP_2023_09_06/">eess.SP - 2023-09-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Demonstration-of-an-Integrated-Planar-Guided-wave-Terahertz-Synthesized-Filter"><a href="#Demonstration-of-an-Integrated-Planar-Guided-wave-Terahertz-Synthesized-Filter" class="headerlink" title="Demonstration of an Integrated Planar Guided-wave Terahertz Synthesized Filter"></a>Demonstration of an Integrated Planar Guided-wave Terahertz Synthesized Filter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03379">http://arxiv.org/abs/2309.03379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Dehghanian, Mohsen Haghighat, Thomas Darcie, Levi Smith</li>
<li>for: 这篇论文是用于设计和实现Integrated planar low-pass filters at terahertz (THz) frequencies的。</li>
<li>methods: 本文使用了microwave engineering中的filter synthesis方法来设计几种Integrated planar low-pass filters，并验证了其传输特性与理论和模拟结果的一致。</li>
<li>results: 本文通过实验和数学模拟表明，使用了filter synthesis方法可以实现高精度的Integrated planar low-pass filters，并且其传输特性与理论和模拟结果一致。<details>
<summary>Abstract</summary>
At terahertz (THz) frequencies there are few experimental works which demonstrate filter synthesis to obtain a desired filter response (i.e., Chebyshev, Butterworth, Bessel, etc.). Currently, the majority of literature perform THz filter analysis, that is, characterizing the filter response after design procedure. In this paper, we apply filter synthesis methods from microwave engineering to design several integrated planar low-pass filters fc = 0.8 THz). We find that the transmission characteristics align with theory and simulation.
</details>
<details>
<summary>摘要</summary>
在tera哈兹（THz）频率范围内，有很少的实验室工作展示了filter synthesis的应用，以实现想要的filter响应（例如Chebyshev、Butterworth、Bessel等）。目前，大多数 литера献都是THz范围内的filter分析，即在设计过程后对filter响应进行 characterization。在这篇文章中，我们通过微波工程学中的filter synthesis方法，设计了一些集成式平面低通filter（fc = 0.8 THz）。我们发现，传输特性与理论和仿真结果一致。Note: "tera哈兹" (tera哈兹) is the Simplified Chinese term for "terahertz".
</details></li>
</ul>
<hr>
<h2 id="Cache-assisted-Mobile-Edge-Computing-over-Space-Air-Ground-Integrated-Networks-for-Extended-Reality-Applications"><a href="#Cache-assisted-Mobile-Edge-Computing-over-Space-Air-Ground-Integrated-Networks-for-Extended-Reality-Applications" class="headerlink" title="Cache-assisted Mobile Edge Computing over Space-Air-Ground Integrated Networks for Extended Reality Applications"></a>Cache-assisted Mobile Edge Computing over Space-Air-Ground Integrated Networks for Extended Reality Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03357">http://arxiv.org/abs/2309.03357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seonghoon Yoo, Seongah Jeong, Jeongbin Kim, Joonhyuk Kang<br>for:* 提供一个基于现代6G技术和互联网络的扩展现实（XRI）系统，以提供更加真实的新用户体验和对现实世界的浸润。methods:* 使用网页边缘计算（MEC）系统，包括两种边缘服务器：一种位于无人飞行器（UAV）上，另一种位于低地球轨道（LEO）上，并具有快照和多个地面XRI设备的缓存。results:* 提出一个统一优化方法，包括UAV轨道估计、资源分配和下传决策，以最大化系统能效，并遵循延迟限制和UAV的运作限制。Please note that the above information is in Simplified Chinese.<details>
<summary>Abstract</summary>
Extended reality-enabled Internet of Things (XRI) provides the new user experience and the sense of immersion by adding virtual elements to the real world through Internet of Things (IoT) devices and emerging 6G technologies. However, the computational-intensive XRI tasks are challenging for the energy-constrained small-size XRI devices to cope with, and moreover certain data requires centralized computing that needs to be shared among users. To this end, we propose a cache-assisted space-air-ground integrated network mobile edge computing (SAGIN-MEC) system for XRI applications, consisting of two types of edge servers mounted on an unmanned aerial vehicle (UAV) and low Earth orbit (LEO) equipped with cache and the multiple ground XRI devices. For system efficiency, the four different offloading procedures of the XRI data are considered according to the type of information, i.e., shared data and private data, as well as the offloading decision and the caching status. Specifically, the private data can be offloaded to either UAV or LEO, while the offloading decision of the shared data to the LEO can be determined by the caching status. With the aim of maximizing the energy efficiency of the overall system, we jointly optimize UAV trajectory, resource allocation and offloading decisions under latency constraints and UAV's operational limitations by using the alternating optimization (AO)-based method along with Dinkelbach algorithm and successive convex optimization (SCA). Via numerical results, the proposed algorithm is verified to have the superior performance compared to conventional partial optimizations or without cache.
</details>
<details>
<summary>摘要</summary>
伸展实现现实（XRI）通过互联网物联网（IoT）设备和emerging 6G技术添加虚拟元素到实际世界中，提供新的用户体验和吸引力。然而，XRI任务具有计算沉重的问题，许多小型XRI设备无法承受，而且一些数据需要中央计算，需要在用户之间分享。为解决这个问题，我们提议一个缓存助手的空间空中地球多边计算（SAGIN-MEC）系统，包括两种类型的边缘服务器，分别安装在无人飞行器（UAV）和低地球轨道（LEO）上，并具有缓存和多个地面XRI设备。为了提高系统的效率，我们考虑了XRI数据的四种卸载过程，根据数据的类型和卸载决策，以及缓存状态。 Specifically，私有数据可以卸载到UAV或LEO上，而LEO上的卸载决策可以根据缓存状态。为了最大化整体系统的能效性，我们使用 alternating optimization（AO）基于方法， along with Dinkelbach algorithm和 successive convex optimization（SCA），并对偏振率和资源分配做joint优化。通过数字结果，我们的算法被证明为比传统的部分优化或无缓存情况下表现更好。
</details></li>
</ul>
<hr>
<h2 id="Sub-Array-Selection-in-Full-Duplex-Massive-MIMO-for-Enhanced-Self-Interference-Suppression"><a href="#Sub-Array-Selection-in-Full-Duplex-Massive-MIMO-for-Enhanced-Self-Interference-Suppression" class="headerlink" title="Sub-Array Selection in Full-Duplex Massive MIMO for Enhanced Self-Interference Suppression"></a>Sub-Array Selection in Full-Duplex Massive MIMO for Enhanced Self-Interference Suppression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03317">http://arxiv.org/abs/2309.03317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mobeen Mahmood, Asil Koc, Duc Tuong Nguyen, Robert Morawski, Tho Le-Ngoc</li>
<li>for: 本研究旨在提高全双工（FD）大规模多输入多出力（mMIMO）系统中的自适应干扰（SI） Mitigation，通过融合干扰扩散（HBF）架构，实现同频段同时进行上行（UL）和下行（DL）传输。</li>
<li>methods: 我们提出了一种基于融合干扰扩散（HBF）架构的小SI扩散扩散（min-SI）扩散方案，通过在发射（Tx）和接收（Rx）子数组中选择子数组来实现。此外，我们还提出了一种基于群体智能算法的优化方法来找到最佳的干扰扩散和Tx&#x2F;Rx子数组，以最小化SISubject to直播和下行束缚约束。</li>
<li>results: 实验结果表明，提出的min-SI扩散方案可以在FD mMIMO系统中实现SI干扰suppression达78 dB。<details>
<summary>Abstract</summary>
This study considers a novel full-duplex (FD) massive multiple-input multiple-output (mMIMO) system using hybrid beamforming (HBF) architecture, which allows for simultaneous uplink (UL) and downlink (DL) transmission over the same frequency band. Particularly, our objective is to mitigate the strong self-interference (SI) solely on the design of UL and DL RF beamforming stages jointly with sub-array selection (SAS) for transmit (Tx) and receive (Rx) sub-arrays at base station (BS). Based on the measured SI channel in an anechoic chamber, we propose a min-SI beamforming scheme with SAS, which applies perturbations to the beam directivity to enhance SI suppression in UL and DL beam directions. To solve this challenging nonconvex optimization problem, we propose a swarm intelligence-based algorithmic solution to find the optimal perturbations as well as the Tx and Rx sub-arrays to minimize SI subject to the directivity degradation constraints for the UL and DL beams. The results show that the proposed min-SI BF scheme can achieve SI suppression as high as 78 dB in FD mMIMO systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Terahertz-Band-Direction-Finding-With-Beam-Split-and-Mutual-Coupling-Calibration"><a href="#Terahertz-Band-Direction-Finding-With-Beam-Split-and-Mutual-Coupling-Calibration" class="headerlink" title="Terahertz-Band Direction Finding With Beam-Split and Mutual Coupling Calibration"></a>Terahertz-Band Direction Finding With Beam-Split and Mutual Coupling Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03195">http://arxiv.org/abs/2309.03195</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmet M. Elbir, Kumar Vijay Mishra, Symeon Chatzinotas<br>for: 这篇论文旨在研究用于第六代无线系统（6G）的teraHertz（THz）频段。methods: 论文使用了一种基于数组的方法，模型了束点分散和相互干扰，并使用了多个信号分类算法来进行方向来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来来 here is the proposed CREAM-MUSIC approach accurately estimates the DoAs in the presence of beam-split and mutual coupling.results: 通过数字仿真，论文显示了该方法可以准确地估计DoAs在束点分散和相互干扰的情况下。<details>
<summary>Abstract</summary>
Terahertz (THz) band is currently envisioned as the key building block to achieving the future sixth generation (6G) wireless systems. The ultra-wide bandwidth and very narrow beamwidth of THz systems offer the next order of magnitude in user densities and multi-functional behavior. However, wide bandwidth results in a frequency-dependent beampattern causing the beams generated at different subcarriers split and point to different directions. Furthermore, mutual coupling degrades the system's performance. This paper studies the compensation of both beam-split and mutual coupling for direction-of-arrival (DoA) estimation by modeling the beam-split and mutual coupling as an array imperfection. We propose a subspace-based approach using multiple signal classification with CalibRated for bEAam-split and Mutual coupling (CREAM-MUSIC) algorithm for this purpose. Via numerical simulations, we show the proposed CREAM-MUSIC approach accurately estimates the DoAs in the presence of beam-split and mutual coupling.
</details>
<details>
<summary>摘要</summary>
特拉赫频率（THz）带是未来第六代（6G）无线系统的关键构建元素。THz系统的超宽频率和非常窄的发射束宽提供下一个级别的用户密度和多功能行为。然而，广频率会导致频率相互依赖的束宽分裂，使得在不同的子报文上生成的束点分别指向不同的方向。此外，相互干扰会下降系统性能。这篇论文研究了补偿束宽分裂和相互干扰的方向到来（DoA）估计方法，将束宽分裂和相互干扰视为阵列不准确性。我们提议使用多个信号分类的SUBSPACE-basedapproach，并使用CalibRated for bEAam-split and Mutual coupling（CREAM-MUSIC）算法来实现这一目标。通过数值仿真，我们示出了提议的CREAM-MUSIC方法可以准确地估计DoAs在束宽分裂和相互干扰的情况下。
</details></li>
</ul>
<hr>
<h2 id="Real-Time-Non-Invasive-Imaging-and-Detection-of-Spreading-Depolarizations-through-EEG-An-Ultra-Light-Explainable-Deep-Learning-Approach"><a href="#Real-Time-Non-Invasive-Imaging-and-Detection-of-Spreading-Depolarizations-through-EEG-An-Ultra-Light-Explainable-Deep-Learning-Approach" class="headerlink" title="Real-Time Non-Invasive Imaging and Detection of Spreading Depolarizations through EEG: An Ultra-Light Explainable Deep Learning Approach"></a>Real-Time Non-Invasive Imaging and Detection of Spreading Depolarizations through EEG: An Ultra-Light Explainable Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03147">http://arxiv.org/abs/2309.03147</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinzhe Wu, Sharon Jewell, Xiaodan Xing, Yang Nan, Anthony J. Strong, Guang Yang, Martyn G. Boutelle</li>
<li>for: 避免次次脑损伤，尤其是通过扩散电化学现象（SD）的检测。</li>
<li>methods: 利用脑电图（EEG）的信号处理和多模态深度学习网络，实现非侵入式SD检测。</li>
<li>results: 提出了一种新的ultra-light-weight多模态深度学习网络，可以融合EEG特征图像和时间能量 вектор，以提高SD检测精度。<details>
<summary>Abstract</summary>
A core aim of neurocritical care is to prevent secondary brain injury. Spreading depolarizations (SDs) have been identified as an important independent cause of secondary brain injury. SDs are usually detected using invasive electrocorticography recorded at high sampling frequency. Recent pilot studies suggest a possible utility of scalp electrodes generated electroencephalogram (EEG) for non-invasive SD detection. However, noise and attenuation of EEG signals makes this detection task extremely challenging. Previous methods focus on detecting temporal power change of EEG over a fixed high-density map of scalp electrodes, which is not always clinically feasible. Having a specialized spectrogram as an input to the automatic SD detection model, this study is the first to transform SD identification problem from a detection task on a 1-D time-series wave to a task on a sequential 2-D rendered imaging. This study presented a novel ultra-light-weight multi-modal deep-learning network to fuse EEG spectrogram imaging and temporal power vectors to enhance SD identification accuracy over each single electrode, allowing flexible EEG map and paving the way for SD detection on ultra-low-density EEG with variable electrode positioning. Our proposed model has an ultra-fast processing speed (<0.3 sec). Compared to the conventional methods (2 hours), this is a huge advancement towards early SD detection and to facilitate instant brain injury prognosis. Seeing SDs with a new dimension - frequency on spectrograms, we demonstrated that such additional dimension could improve SD detection accuracy, providing preliminary evidence to support the hypothesis that SDs may show implicit features over the frequency profile.
</details>
<details>
<summary>摘要</summary>
❗注意：以下文本使用了简化字体。 neuroscience critical care 的核心目标是避免次次脑损伤。广泛的电化学变化 (SDs) 已被证明为次次脑损伤的重要独立原因。 SDs 通常通过高频率的电rocorticography 进行检测。Recent pilot studies 表明，可能通过非侵入式 EEG 来检测 SD。然而，EEG 信号噪音和弱化会使检测任务变得极其困难。 previous methods 主要是通过固定高密度电极地图来检测 EEG 时间能量的变化，这并不总是临床可行。本研究是首次将 SD 识别问题转化为一个在二维图像上进行的Sequential 任务，并使用特殊的spectrogram作为输入。我们提出了一种ultra-light-weight multi-modal deep-learning网络，用于融合 EEG spectrogram 图像和时间能量向量，以提高 SD 识别精度。我们的模型具有ultra-快处理速度（<0.3秒），与传统方法（2小时）相比，这是一个巨大的进步，可以帮助早期 SD 识别和实时脑损伤诊断。通过在spectrogram 图像上看到 SDs 的频谱特征，我们表明了频谱特征的存在可以提高 SD 识别精度，这提供了初步的证据支持 SDs 可能会在频谱 Profiling 中显示出隐藏的特征。
</details></li>
</ul>
<hr>
<h2 id="Millimeter-Wave-Thin-Film-Bulk-Acoustic-Resonator-in-Sputtered-Scandium-Aluminum-Nitride"><a href="#Millimeter-Wave-Thin-Film-Bulk-Acoustic-Resonator-in-Sputtered-Scandium-Aluminum-Nitride" class="headerlink" title="Millimeter Wave Thin-Film Bulk Acoustic Resonator in Sputtered Scandium Aluminum Nitride"></a>Millimeter Wave Thin-Film Bulk Acoustic Resonator in Sputtered Scandium Aluminum Nitride</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03135">http://arxiv.org/abs/2309.03135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sinwoo Cho, Omar Barrera, Pietro Simeoni, Emily N. Marshall, Jack Kramer, Keisuke Motoki, Tzu-Hsuan Hsu, Vakhtang Chulukhadze, Matteo Rinaldi, W. Alan Doolittle, Ruochen Lu</li>
<li>for: This paper aims to improve the frequency scaling of sputtered ScAlN into mmWave and proposes a new fabrication procedure.</li>
<li>methods: The paper uses sputtered Sc0.3Al0.7N on Al on Si carrier wafer and transmission electron microscopy (TEM) and X-ray diffraction (XRD) to identify the bottlenecks in the existing piezoelectric-metal stack.</li>
<li>results: The resonator achieves electromechanical coupling (k2) of 7.0% and quality factor (Q) of 62 for the first-order symmetric (S1) mode at 21.4 GHz, along with k2 of 4.0% and Q of 19 for the third-order symmetric (S3) mode at 55.4 GHz, showing higher figures of merit (FoM, k2xQ) than reported AlN&#x2F;ScAlN-based mmWave acoustic resonators.<details>
<summary>Abstract</summary>
This work reports a millimeter wave (mmWave) thin-film bulk acoustic resonator (FBAR) in sputtered scandium aluminum nitride (ScAlN). This paper identifies challenges of frequency scaling sputtered ScAlN into mmWave and proposes a stack and new fabrication procedure with a sputtered Sc0.3Al0.7N on Al on Si carrier wafer. The resonator achieves electromechanical coupling (k2) of 7.0% and quality factor (Q) of 62 for the first-order symmetric (S1) mode at 21.4 GHz, along with k2 of 4.0% and Q of 19 for the third-order symmetric (S3) mode at 55.4 GHz, showing higher figures of merit (FoM, k2xQ) than reported AlN/ScAlN-based mmWave acoustic resonators. The ScAlN quality is identified by transmission electron microscopy (TEM) and X-ray diffraction (XRD), identifying the bottlenecks in the existing piezoelectric-metal stack. Further improvement of ScAlN/AlN-based mmWave acoustic resonators calls for better crystalline quality from improved thin-film deposition methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="NUV-DoA-NUV-Prior-based-Bayesian-Sparse-Reconstruction-with-Spatial-Filtering-for-Super-Resolution-DoA-Estimation"><a href="#NUV-DoA-NUV-Prior-based-Bayesian-Sparse-Reconstruction-with-Spatial-Filtering-for-Super-Resolution-DoA-Estimation" class="headerlink" title="NUV-DoA: NUV Prior-based Bayesian Sparse Reconstruction with Spatial Filtering for Super-Resolution DoA Estimation"></a>NUV-DoA: NUV Prior-based Bayesian Sparse Reconstruction with Spatial Filtering for Super-Resolution DoA Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03114">http://arxiv.org/abs/2309.03114</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MengyuanZha0/ICASSP24-NUV-DoA">https://github.com/MengyuanZha0/ICASSP24-NUV-DoA</a></li>
<li>paper_authors: Mengyuan Zhao, Guy Revach, Tirza Routtenberg, Nir Shlezinger</li>
<li>for: 高分辨率方向来源估计（DoA估计）通常需要高信号噪声比（SNR）和足够多的拍摄数。这篇文章提出了NUV-DoA算法，该算法将湍普 sparse reconstruction与空间滤波结合以实现超分辨率DoA估计。</li>
<li>methods: 文章使用了每个方向在Azimuth网格上的几何均匀分布（NUV）先验来模型每个方向，从而将非 konvex 优化问题转化为轮循重估最小二乘问题，其中测量值的均值是一个充分统计。这种方法不仅简化了我们的解决方案，而且准确地检测到了DoAs。</li>
<li>results: 实验证明了NUV-DoA的优越性，特别在低SNR情况下，与其他DoA估计器相比。<details>
<summary>Abstract</summary>
Achieving high-resolution Direction of Arrival (DoA) recovery typically requires high Signal to Noise Ratio (SNR) and a sufficiently large number of snapshots. This paper presents NUV-DoA algorithm, that augments Bayesian sparse reconstruction with spatial filtering for super-resolution DoA estimation. By modeling each direction on the azimuth's grid with the sparsity-promoting normal with unknown variance (NUV) prior, the non-convex optimization problem is reduced to iteratively reweighted least-squares under Gaussian distribution, where the mean of the snapshots is a sufficient statistic. This approach not only simplifies our solution but also accurately detects the DoAs. We utilize a hierarchical approach for interference cancellation in multi-source scenarios. Empirical evaluations show the superiority of NUV-DoA, especially in low SNRs, compared to alternative DoA estimators.
</details>
<details>
<summary>摘要</summary>
得到高分辨率方向来源（DoA）重建通常需要高信号噪声比（SNR）和足够多的拍照。这篇论文介绍了NUV-DoA算法，它将柔谐重建与空间滤波结合以实现超分辨率DoA估计。通过对每个方向在方位网格上使用不确定 variance（NUV）前提，非 convex 优化问题被降低到轮循权重最小二乘问题，其中抽样均值是sufficient statistic。这种方法不仅简化了我们的解决方案，而且准确地检测到DoAs。我们在多源场景中采用层次方法进行干扰抑制。实验证明NUV-DoA在低SNR下表现更出色，与其他DoA估计器相比。
</details></li>
</ul>
<hr>
<h2 id="Purposeful-Co-Design-of-OFDM-Signals-for-Ranging-and-Communications"><a href="#Purposeful-Co-Design-of-OFDM-Signals-for-Ranging-and-Communications" class="headerlink" title="Purposeful Co-Design of OFDM Signals for Ranging and Communications"></a>Purposeful Co-Design of OFDM Signals for Ranging and Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03076">http://arxiv.org/abs/2309.03076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Graff, Todd E. Humphreys</li>
<li>for: 本研究探讨了多频分复用通信信号的基本负面特性，以提高它们的范围估计和通信能力之间的质量负面。</li>
<li>methods: 本研究使用了谱函数积分 bound，概率失效概率，以及Ziv-Zakai bound on range estimation variance来量化这些负面特性。</li>
<li>results: 研究结果显示，通过根据 derive bounds来做Pareto优化设计选择，可以提高通信吞吐量、失败概率和范围估计方差之间的质量负面。不同的信号设计策略的Pareto优化设计选择也是受通道condition所影响的。<details>
<summary>Abstract</summary>
This paper analyzes the fundamental trade-offs that occur in the co-design of orthogonal frequency-division multiplexing signals for both ranging (via time-of-arrival estimation) and communications. These trade-offs are quantified through the Shannon capacity bound, probability of outage, and the Ziv-Zakai bound on range estimation variance. Bounds are derived for signals experiencing frequency-selective Rayleigh block fading, accounting for the impact of limited channel knowledge and multi-antenna reception. Uncompensated carrier frequency offset and phase errors are also factored into the capacity bounds. Analysis based on the derived bounds demonstrates how Pareto-optimal design choices can be made to optimize the communication throughput, probability of outage, and ranging variance. Different signal design strategies are then analyzed, showing how Pareto-optimal design choices change depending on the channel.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文分析了在共同设计Orthogonal frequency-division multiplexing信号时存在的基本贸易offs。这些贸易offs通过Shannon容量 bound、抗干扰率和Ziv-Zakai bound on range estimation variance来量化。分析考虑了频率选择性的Rayleigh块折射，以及有限通道知识和多antenna接收。此外，也考虑了不归还调制频率偏移和相位错误。结果表明，可以通过Pareto优化的设计选择来优化通信吞吐量、抗干扰率和距离估计variance，而不同的信号设计策略会因渠道而异。
</details></li>
</ul>
<hr>
<h2 id="Reconfigurable-Intelligent-Surface-Aided-Space-Shift-Keying-With-Imperfect-CSI"><a href="#Reconfigurable-Intelligent-Surface-Aided-Space-Shift-Keying-With-Imperfect-CSI" class="headerlink" title="Reconfigurable Intelligent Surface Aided Space Shift Keying With Imperfect CSI"></a>Reconfigurable Intelligent Surface Aided Space Shift Keying With Imperfect CSI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03059">http://arxiv.org/abs/2309.03059</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xusheng Zhu, Wen Chen, Qingqing Wu, Zhendong Li, Jun Li, Shunqing Zhang, Ming Ding</li>
<li>for: This paper investigates the performance of reconfigurable intelligent surface (RIS)-aided spatial shift keying (SSK) wireless communication systems in the presence of imperfect channel state information (CSI).</li>
<li>methods: The paper analyzes the average bit error probability (ABEP) of two RIS-SSK systems, one based on intelligent reflection and the other based on blind reflection of the RIS. The authors use maximum likelihood (ML) detection and derive the conditional pairwise error probability of the composite channel, as well as the probability density function of the combined channel.</li>
<li>results: The paper derives closed-form and asymptotic expressions for the ABEP of the RIS-SSK system with imperfect CSI, and explores the impact of discrete reflection phase shifts on the system’s performance. The authors validate their analytical derivations using Monte Carlo simulations.<details>
<summary>Abstract</summary>
In this paper, we investigate the performance of reconfigurable intelligent surface (RIS)-aided spatial shift keying (SSK) wireless communication systems in the presence of imperfect channel state information (CSI). Specifically, we analyze the average bit error probability (ABEP) of two RIS-SSK systems respectively based on intelligent reflection and blind reflection of RIS. For the intelligent RIS-SSK scheme, we first derive the conditional pairwise error probability of the composite channel through maximum likelihood (ML) detection. Subsequently, we derive the probability density function of the combined channel. Due to the intricacies of the composite channel formulation, an exact closed-form ABEP expression is unattainable through direct derivation. To this end, we resort to employing the Gaussian-Chebyshev quadrature method to estimate the results. In addition, we employ the Q-function approximation to derive the non-exact closed-form expression when CSI imperfections are present. For the blind RIS-SSK scheme, we derive both closed-form ABEP expression and asymptotic ABEP expression with imperfect CSI by adopting the ML detector. To offer deeper insights, we explore the impact of discrete reflection phase shifts on the performance of the RIS-SSK system. Lastly, we extensively validate all the analytical derivations using Monte Carlo simulations.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了带有不完全的通道状态信息（CSI）的快速智能表面（RIS）协助的空间偏移键（SSK）无线通信系统的性能。 Specifically，我们分析了两种基于智能反射和盲反射的RIS-SSK系统的平均比特错误率（ABEP）。 对于智能RIS-SSK方案，我们首先 derivated了最大可信度检测（ML）后的 conditional pairwise error probability of the composite channel。然后，我们 derivated the probability density function of the combined channel。由于composite channel的形式复杂，直接 derivation无法得到准确的闭式表达。为此，我们使用Gaussian-Chebyshev quadrature方法来估计结果。此外，我们使用Q-函数approximation来 derivethe non-exact closed-form expression when CSI imperfections are present。 对于盲RIS-SSK方案，我们 derivated both closed-form ABEP expression and asymptotic ABEP expression with imperfect CSI by adopting the ML detector。为了深入了解，我们探讨了RIS-SSK系统中的Discrete reflection phase shifts的影响。最后，我们使用Monte Carlo simulations extensively validate all the analytical derivations。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Quantification-in-Deep-Learning-Based-Kalman-Filters"><a href="#Uncertainty-Quantification-in-Deep-Learning-Based-Kalman-Filters" class="headerlink" title="Uncertainty Quantification in Deep Learning Based Kalman Filters"></a>Uncertainty Quantification in Deep Learning Based Kalman Filters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03058">http://arxiv.org/abs/2309.03058</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yonatandn/Uncertainty-extraction-in-Model-Based-DL">https://github.com/yonatandn/Uncertainty-extraction-in-Model-Based-DL</a></li>
<li>paper_authors: Yehonatan Dahan, Guy Revach, Jindrich Dunik, Nir Shlezinger</li>
<li>for: 这篇论文主要针对深度神经网络（DNNs）和卡尔曼滤波器（KFs）的结合，以便从数据中学习并跟踪复杂动力系统。</li>
<li>methods: 这篇论文研究了DNNs-aided KFs中的错误 covariance 提取方法，包括三种主要方法，它们之间的区别在于将内部特征与KF量如卡尔曼增益（KG）和先验协方差相关联。</li>
<li>results: 数值研究表明，这三种方法可以在DNNs-aided KFs中提取错误 covariance，其中模型基础&#x2F;数据驱动设计具有最高准确性的错误预测。<details>
<summary>Abstract</summary>
Various algorithms combine deep neural networks (DNNs) and Kalman filters (KFs) to learn from data to track in complex dynamics. Unlike classic KFs, DNN-based systems do not naturally provide the error covariance alongside their estimate, which is of great importance in some applications, e.g., navigation. To bridge this gap, in this work we study error covariance extraction in DNN-aided KFs. We examine three main approaches that are distinguished by the ability to associate internal features with meaningful KF quantities such as the Kalman gain (KG) and prior covariance. We identify the differences between these approaches in their requirements and their effect on the training of the system. Our numerical study demonstrates that the above approaches allow DNN-aided KFs to extract error covariance, with most accurate error prediction provided by model-based/data-driven designs.
</details>
<details>
<summary>摘要</summary>
各种算法结合深度神经网络（DNN）和卡尔曼筛（KF）来学习从数据中跟踪复杂动态。不同于传统KF，DNN基本系统不会自然提供错误covariance的估计，这在一些应用中，如导航，是非常重要的。为了bridging这个差距，在这项工作中我们研究DNN帮助KF中的错误covariance提取。我们检查了三种主要的方法，这些方法通过与KF量可以关联内部特征，如卡尔曼增益（KG）和先验 covariance。我们描述了这些方法的不同之处，以及它们对系统训练的影响。我们的数字研究表明，以上三种方法可以让DNN帮助KF提取错误covariance，并且使用数据驱动/模型驱动的设计可以提供最准确的错误预测。
</details></li>
</ul>
<hr>
<h2 id="Cellular-Wireless-Networks-in-the-Upper-Mid-Band"><a href="#Cellular-Wireless-Networks-in-the-Upper-Mid-Band" class="headerlink" title="Cellular Wireless Networks in the Upper Mid-Band"></a>Cellular Wireless Networks in the Upper Mid-Band</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03038">http://arxiv.org/abs/2309.03038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seongjoon Kang, Marco Mezzavilla, Sundeep Rangan, Arjuna Madanayake, Satheesh Bojja Venkatakrishnan, Gregory Hellbourg, Monisha Ghosh, Hamed Rahmani, Aditya Dhananjay</li>
<li>for: 这篇论文主要是为了评估Upper mid-band（7-24GHz）频率段的 Cellular 系统的可行性和潜在增强。</li>
<li>methods: 本论文使用了系统研究、传播计算和antenna设计来评估Upper mid-band Cellular 系统的可行性和潜在增强。</li>
<li>results: 研究结果表明，Upper mid-band Cellular 系统在高密度城市环境下可以获得更高的吞吐量和覆盖范围，但需要与现有的卫星通信、军事RADAR和天文学 radiolocation 等频率分享spectrum。此外，由于传播特性和宽频带特性，Cellular 系统需要具备智能感知和利用大空间和频率度 freedom。<details>
<summary>Abstract</summary>
The upper mid-band -- roughly from 7 to 24 GHz -- has attracted considerable recent interest for new cellular services. This frequency range has vastly more spectrum than the highly congested bands below 7 GHz while offering more favorable propagation and coverage than the millimeter wave (mmWave) frequencies. Realizing the full potential of these bands, however, will require fundamental changes to the design of cellular systems. Most importantly, spectrum will likely need to be shared with incumbents including communication satellites, military RADAR, and radio astronomy. Also, due to the wide bandwidth, directional nature of transmission, and intermittent occupancy of incumbents, cellular systems will need to be agile to sense and intelligently use large spatial and bandwidth degrees of freedom. This paper attempts to provide an initial assessment of the feasibility and potential gains of wideband cellular systems operating in the upper mid-band. The study includes: (1) a system study to assess potential gains of multi-band systems in a representative dense urban environment; (2) propagation calculations to assess potential cross interference between satellites and terrestrial cellular services; and (3) design and evaluation of a compact multi-band antenna array structure. Leveraging these preliminary results, we identify potential future research directions to realize next-generation systems in these frequencies.
</details>
<details>
<summary>摘要</summary>
上层中频带（约7-24GHz）在最近吸引了许多关注，用于新的mobile服务。这个频率范围具有许多谱 spectrum比下7GHz的频率带，而且具有更有利的宽频率和覆盖范围，相比于毫米波（mmWave）频率。但是，实现这些频率带的全部潜力需要基础设施的重大改进。主要是，需要与现有的卫星通信、军用RADAR和广播天文学分享频率。此外，由于宽频率、指向性传输和干扰者占用的不定期， cellular系统需要具备较强的感知和智能使用大空间和频率度量积。本文尝试提供初步评估宽频 cellular系统在上述频率带的可能性和优势。研究包括：1. 多频率系统的系统研究，以评估高密度城市环境中的可能性提升。2. 卫星和地面cellular服务之间的干扰计算，以评估干扰的可能性。3. 一种多频率天线阵列结构的设计和评估。基于这些初步结果，我们标识了未来研究的可能方向，以实现下一代系统在这些频率带。
</details></li>
</ul>
<hr>
<h2 id="MUSIC-Algorithm-for-IRS-Assisted-AOA-Estimation"><a href="#MUSIC-Algorithm-for-IRS-Assisted-AOA-Estimation" class="headerlink" title="MUSIC Algorithm for IRS-Assisted AOA Estimation"></a>MUSIC Algorithm for IRS-Assisted AOA Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02947">http://arxiv.org/abs/2309.02947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qipeng Wang, Liang Liu, Shuowen Zhang<br>for:* 这篇论文的目的是研究基站使用智能反射面（IRS）助手的精细感知和通信（ISAC）系统中的角度估计问题。methods:* 该论文提出了一种创新的方法，通过设计用户消息模式和IRS反射模式，将空间域接收信号转化为时间域多维ensional信号，以便使用经典的MUSIC算法估计信号从用户到IRS的角度。results:* 研究发现，通过采用该方法，可以准确地估计信号从用户到IRS的角度，并且可以利用IRS作为块来实现精细感知和通信。<details>
<summary>Abstract</summary>
Based on the signals received across its antennas, a multi-antenna base station (BS) can apply the classic multiple signal classification (MUSIC) algorithm for estimating the angle of arrivals (AOAs) of its incident signals. This method can be leveraged to localize the users if their line-of-sight (LOS) paths to the BS are available. In this paper, we consider a more challenging AOA estimation setup in the intelligent reflecting surface (IRS) assisted integrated sensing and communication (ISAC) system, where LOS paths do not exist between the BS and the users, while the users' signals can be transmitted to the BS merely via their LOS paths to the IRS as well as the LOS path from the IRS to the BS. Specifically, we treat the IRS as the anchor and are interested in estimating the AOAs of the incident signals from the users to the IRS. Note that we have to achieve the above goal based on the signals received by the BS, because the passive IRS cannot process its received signals. However, the signals received across different antennas of the BS only contain AOA information of its incident signals via the LOS path from the IRS to the BS. To tackle this challenge arising from the spatial-domain received signals, we propose an innovative approach to create temporal-domain multi-dimension received signals for estimating the AOAs of the paths from the users to the IRS. Specifically, via a proper design of the user message pattern and the IRS reflecting pattern, we manage to show that our designed temporal-domain multi-dimension signals can be surprisingly expressed as a function of the virtual steering vectors of the IRS towards the users. This amazing result implies that the classic MUSIC algorithm can be applied to our designed temporal-domain multi-dimension signals for accurately estimating the AOAs of the signals from the users to the IRS.
</details>
<details>
<summary>摘要</summary>
基于其天线接收的信号，一个多天线基站（BS）可以应用经典的多信号分类（MUSIC）算法来估算它所接收的信号的方向来归一化（AOA）。这种方法可以用来地理位置用户，如果用户的直线视线（LOS）路径与BS存在。在这篇论文中，我们考虑了更加具有挑战性的AOA估算设置在智能反射表（IRS）帮助的 интеграted感知通信（ISAC）系统中，其中用户与BS之间没有直线视线路径，而用户的信号可以仅通过它们的LOS路径到IRS以及IRS到BS的LOS路径传输到BS。 specifically，我们将IRS作为固定点，并关注估算它所接收的信号的AOA。注意，我们需要基于BS接收的信号来实现以上目标，因为被动的IRS无法处理其接收信号。然而，BS接收到不同天线的信号只包含AOA信息，它们的incident信号通过IRS到BS的LOS路径传输。为了解决这种在空间频域接收信号中出现的挑战，我们提出了一种创新的方法，即通过适当的用户消息模式和IRS反射模式的设计，将空间频域接收信号转换为时间频域多维度信号，以便使用经典的MUSIC算法来准确地估算用户到IRS信号的AOA。这个优等结果表明，我们设计的时间频域多维度信号可以Surprisingly表示为IRS对用户的虚投影向量的函数。这个优等结果意味着我们可以使用经典的MUSIC算法来估算用户到IRS信号的AOA。
</details></li>
</ul>
<hr>
<h2 id="Bi-Linear-Homogeneity-Enforced-Calibration-for-Pipelined-ADCs"><a href="#Bi-Linear-Homogeneity-Enforced-Calibration-for-Pipelined-ADCs" class="headerlink" title="Bi-Linear Homogeneity Enforced Calibration for Pipelined ADCs"></a>Bi-Linear Homogeneity Enforced Calibration for Pipelined ADCs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02901">http://arxiv.org/abs/2309.02901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthias Wagner, Oliver Lang, Esmaeil Kavousi Ghafi, Andreas Schwarz, Mario Huemer</li>
<li>for: 这个论文是为了探讨pipelined analog-to-digital converters (ADCs)的准确 Linearity Calibration方法。</li>
<li>methods: 这个论文使用了homogeneity enforced calibration (HEC) Approach和bi-linear homogeneity enforced calibration (BL-HEC) Approach来实现ADC的准确 Linearity Calibration。</li>
<li>results: 这个论文通过了simulation来验证HEC Approach和BL-HEC Approach的稳定性和准确性。<details>
<summary>Abstract</summary>
Pipelined analog-to-digital converters (ADCs) are key enablers in many state-of-the-art signal processing systems with high sampling rates. In addition to high sampling rates, such systems often demand a high linearity. To meet these challenging linearity requirements, ADC calibration techniques were heavily investigated throughout the past decades. One limitation in ADC calibration is the need for a precisely known test signal. In our previous work, we proposed the homogeneity enforced calibration (HEC) approach, which circumvents this need by consecutively feeding a test signal and a scaled version of it into the ADC. The calibration itself is performed using only the corresponding output samples, such that the test signal can remain unknown. On the downside, the HEC approach requires the option to accurately scale the test signal, impeding an on-chip implementation. In this work, we provide a thorough analysis of the HEC approach, including the effects of an inaccurately scaled test signal. Furthermore, the bi-linear homogeneity enforced calibration (BL-HEC) approach is introduced and suggested to account for an inaccurate scaling and, therefore, to facilitate an on-chip implementation. In addition, a comprehensive stability and convergence analysis of the BL-HEC approach is carried out. Finally, we verify our concept with simulations.
</details>
<details>
<summary>摘要</summary>
高速采样率的数字化抽象转换器（ADC）是现代信号处理系统的关键启用器。此外，这些系统frequently需要高linearity。为满足这些高linearity要求，ADC启动技术在过去几十年中得到了广泛的研究。一个ADC启动技术的限制是需要一个精确知道的测试信号。在我们之前的工作中，我们提出了一种均匀性强制启动（HEC）方法，该方法缺省测试信号和其涨大版本分别输入到ADC中，并通过对应的输出样本进行启动。这种启动方法不需要测试信号的精确知道，因此可以在不知道测试信号的情况下进行启动。然而，HEC方法需要精确涨大测试信号的能力，这限制了其在芯片上实现的可能性。在这个工作中，我们对HEC方法进行了全面的分析，包括测试信号的不准确涨大的影响。此外，我们还提出了一种具有兼顾不准确涨大和芯片实现的双线性均匀性强制启动（BL-HEC）方法。此外，我们还进行了BL-HEC方法的稳定性和收敛分析。最后，我们通过仿真来验证我们的概念。
</details></li>
</ul>
<hr>
<h2 id="Multi-Device-Task-Oriented-Communication-via-Maximal-Coding-Rate-Reduction"><a href="#Multi-Device-Task-Oriented-Communication-via-Maximal-Coding-Rate-Reduction" class="headerlink" title="Multi-Device Task-Oriented Communication via Maximal Coding Rate Reduction"></a>Multi-Device Task-Oriented Communication via Maximal Coding Rate Reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02888">http://arxiv.org/abs/2309.02888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chang Cai, Xiaojun Yuan, Ying-Jun Angela Zhang</li>
<li>for: 本研究旨在提高多设备边缘推理的通信效率，通过将学习和通信模块设计为同一目标：推理准确率最大化。</li>
<li>methods: 我们使用Maximal Coding Rate Reduction（MCR2）目标作为推理准确率的Surrogate，并将其用于precoding优化问题的形式化表述。我们还开发了一种块坐标推移（BCD）解算法。</li>
<li>results: 我们的方法在synthetic和实际数据集上实现了较高的性能，与多个基准值进行比较。<details>
<summary>Abstract</summary>
Task-oriented communication offers ample opportunities to alleviate the communication burden in next-generation wireless networks. Most existing work designed the physical-layer communication modules and learning-based codecs with distinct objectives: learning is targeted at accurate execution of specific tasks, while communication aims at optimizing conventional communication metrics, such as throughput maximization, delay minimization, or bit error rate minimization. The inconsistency between the design objectives may hinder the exploitation of the full benefits of task-oriented communications. In this paper, we consider a specific task-oriented communication system for multi-device edge inference over a multiple-input multiple-output (MIMO) multiple-access channel, where the learning (i.e., feature encoding and classification) and communication (i.e., precoding) modules are designed with the same goal of inference accuracy maximization. Instead of end-to-end learning which involves both the task dataset and wireless channel during training, we advocate a separate design of learning and communication to achieve the consistent goal. Specifically, we leverage the maximal coding rate reduction (MCR2) objective as a surrogate to represent the inference accuracy, which allows us to explicitly formulate the precoding optimization problem. We cast valuable insights into this formulation and develop a block coordinate descent (BCD) solution algorithm. Moreover, the MCR2 objective also serves the loss function of the feature encoding network, based on which we characterize the received features as a Gaussian mixture (GM) model, facilitating a maximum a posteriori (MAP) classifier to infer the result. Simulation results on both the synthetic and real-world datasets demonstrate the superior performance of the proposed method compared to various baselines.
</details>
<details>
<summary>摘要</summary>
任务强调通信可以减轻下一代无线网络中的通信压力。现有大部分工作都是设计物理层通信模块和学习型编码器，其目标是准确执行特定任务，而通信则是优化传统通信指标，如吞吐量最大化、延迟最小化或比特错误率最小化。这种目标之间的不一致可能会阻碍利用任务强调通信的全部优势。在本文中，我们考虑了一种特定的任务强调通信系统，用于多设备边缘推理over multiple-input multiple-output（MIMO）多Access通道。在这个系统中，学习（即特征编码和分类）和通信（即precoding）模块都是设计于最大化推理准确性的目标。而不是沿用end-to-end学习，我们提议分离学习和通信的设计，以实现一致的目标。具体来说，我们利用最大编码率减少（MCR2）目标作为推理准确性的代表，从而直接化precoding优化问题。我们对这个问题提出了值得关注的探讨，并开发了块坐标下降（BCD）解决方案。此外，MCR2目标还服务了特征编码网络的损失函数，基于这个损失函数，我们描述了接收特征为 Gaussian Mixture（GM）模型，从而实现最大 posteriori（MAP）分类器来推理结果。实验结果表明，提议的方法在synthetic和实际数据集上比多个基准方法表现出更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Symmetric-Reciprocal-Match-Method-for-Vector-Network-Analyzer-Calibration"><a href="#Symmetric-Reciprocal-Match-Method-for-Vector-Network-Analyzer-Calibration" class="headerlink" title="Symmetric-Reciprocal-Match Method for Vector Network Analyzer Calibration"></a>Symmetric-Reciprocal-Match Method for Vector Network Analyzer Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02886">http://arxiv.org/abs/2309.02886</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZiadHatab/srm-calibration">https://github.com/ZiadHatab/srm-calibration</a></li>
<li>paper_authors: Ziad Hatab, Michael Ernst Gadringer, Wolfgang Bösch</li>
<li>for: 这篇论文提出了一种新的方法，即对Vector Network Analyzer（VNA）进行准确启动的Symmetric-Reciprocal-Match（SRM）方法。</li>
<li>methods: 该方法使用多个对称的一 ports荷车，一个两ports对称设备，以及一个匹配荷。荷标准包括两个对称的一 ports设备，至少使用三个独特的荷。但是具体的阻抗值并不被规定。</li>
<li>results: 我们通过使用商业化短开载反射（SOLR）测量工具和验证标准进行数值示例和实验验证了提议方法的准确性。该方法的优点在于只需定义匹配标准，其余标准则可以通过对称性或对偶性进行定义。<details>
<summary>Abstract</summary>
This paper proposes a new approach, the symmetric-reciprocal-match (SRM) method, for calibrating vector network analyzers (VNAs). The method involves using multiple symmetric one-port loads, a two-port reciprocal device, and a matched load. The load standards consist of two-port symmetric one-port devices, and at least three unique loads are used. However, the specific impedances of the loads are not specified. The reciprocal device can be any transmissive device, although a non-reciprocal device can also be used if only the one-port error boxes are of interest. The matched load is fully defined and can be asymmetric. We numerically demonstrated the proposed method's accuracy with synthetic data and with measurements of coaxial standards using a commercial short-open-load-reciprocal (SOLR) calibration kit with verification standards. An advantage of the proposed method is that only the match standard is defined, whereas the remaining standards are partially defined, either through symmetry or reciprocity.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Reconfigurable-Intelligent-Surfaces-for-6G-Non-Terrestrial-Networks-Assisting-Connectivity-from-the-Sky"><a href="#Reconfigurable-Intelligent-Surfaces-for-6G-Non-Terrestrial-Networks-Assisting-Connectivity-from-the-Sky" class="headerlink" title="Reconfigurable Intelligent Surfaces for 6G Non-Terrestrial Networks: Assisting Connectivity from the Sky"></a>Reconfigurable Intelligent Surfaces for 6G Non-Terrestrial Networks: Assisting Connectivity from the Sky</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02859">http://arxiv.org/abs/2309.02859</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wali Ullah Khan, Asad Mahmood, Chandan Kumar Sheemar, Eva Lagunas, Symeon Chatzinotas, Björn Ottersten</li>
<li>for: 本文研究了利用RIS-integrated NTN来实现下一代连接的潜力。</li>
<li>methods: 本文首先介绍了RIS技术的基础知识，然后介绍了最新的RIS-enabled NTN的进展。最后，它提出了一种基于当前状态的艺术的低地球轨道卫星（LEO）通信方案，其中用户端接收信号需要 traverse both a direct link和一个RIS链路，RIS被安装在高空平台（HAP）上，位于大气层中。</li>
<li>results: 本文 conclude by highlighting open challenges and future research directions to revolutionize the realm of RIS-integrated NTNs。<details>
<summary>Abstract</summary>
This paper studies the potential of RIS-integrated NTNs to revolutionize the next-generation connectivity. First, it discusses the fundamentals of RIS technology. Secondly, it delves into reporting the recent advances in RIS-enabled NTNs. Subsequently, it presents a novel framework based on the current state-of-the-art for low earth orbit satellites (LEO) communications, wherein the signal received at the user terminal traverses both a direct link and an RIS link, and the RIS is mounted on a high-altitude platform (HAP) situated within the stratosphere. Finally, the paper concludes by highlighting open challenges and future research directions to revolutionize the realm of RIS-integrated NTNs.
</details>
<details>
<summary>摘要</summary>
这篇论文研究了利用RIS（媒体赋能器）integreated NTNs（无线电传输网络）来开创下一代连接性的潜力。首先，它介绍了RIS技术的基础知识。其次，它详细报道了最新的RIS-启用NTNs的进展。然后，它提出了基于当前领域的最佳实践的一种新框架，该框架适用于低地球轨道卫星（LEO）通信，其中用户终端接收到的信号需要经过直接链路和RIS链路，而RIS被安装在高空平台（HAP）上，该平台位于大气层中。最后，论文指出了RIS-integreated NTNs的开放挑战和未来研究方向，以便在这个领域取得革命性的进步。
</details></li>
</ul>
<hr>
<h2 id="Variational-Bayesian-Approximations-Kalman-Filter-Based-on-Threshold-Judgment"><a href="#Variational-Bayesian-Approximations-Kalman-Filter-Based-on-Threshold-Judgment" class="headerlink" title="Variational Bayesian Approximations Kalman Filter Based on Threshold Judgment"></a>Variational Bayesian Approximations Kalman Filter Based on Threshold Judgment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02789">http://arxiv.org/abs/2309.02789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zuxuan Zhang, Gang Wang, Jiacheng He, Shan Zhong</li>
<li>for: 这篇论文的目的是提出一种线上运算非泊松测量噪声模型中的误差参数估计方法。</li>
<li>methods: 这篇论文提出了一种阈值基本 kalman 统计方法，使用一定量的样本数据估计观测参数的方差阈值，并使用Variational Bayesian估计方法来 obtencorresponding noise variance estimates，以便在 subsequential iterations中使用 kalman 统计方法进行运算。</li>
<li>results: 这篇论文通过了 simulate 实验评估了这个算法的精度和有效性，发现它可以妥善地估计状态和噪声参数。<details>
<summary>Abstract</summary>
The estimation of non-Gaussian measurement noise models is a significant challenge across various fields. In practical applications, it often faces challenges due to the large number of parameters and high computational complexity. This paper proposes a threshold-based Kalman filtering approach for online estimation of noise parameters in non-Gaussian measurement noise models. This method uses a certain amount of sample data to infer the variance threshold of observation parameters and employs variational Bayesian estimation to obtain corresponding noise variance estimates, enabling subsequent iterations of the Kalman filtering algorithm. Finally, we evaluate the performance of this algorithm through simulation experiments, demonstrating its accurate and effective estimation of state and noise parameters.
</details>
<details>
<summary>摘要</summary>
“非泊布变量测量噪音模型的估计是各领域中的一个重要挑战。实际应用中常常面临许多参数和高计算复杂性的挑战。本文提出了一个阈值基本 kalman 统计方法来在线上估计噪音参数的非泊布变量测量噪音模型。这个方法使用一定的样本数推导观测参数的方差阈值，并使用Variational Bayesian估计来取得对应的噪音方差估计，允许后续的kalman统计算法的迭代。最后，我们通过了 simulation 实验评估这个算法的精确和有效性。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Stacked-Intelligent-Metasurfaces-for-Multiuser-Downlink-Beamforming-in-the-Wave-Domain"><a href="#Stacked-Intelligent-Metasurfaces-for-Multiuser-Downlink-Beamforming-in-the-Wave-Domain" class="headerlink" title="Stacked Intelligent Metasurfaces for Multiuser Downlink Beamforming in the Wave Domain"></a>Stacked Intelligent Metasurfaces for Multiuser Downlink Beamforming in the Wave Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02687">http://arxiv.org/abs/2309.02687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiancheng An, Marco Di Renzo, Merouane Debbah, H. Vincent Poor, Chau Yuen</li>
<li>for: 本研究旨在提高无线网络的功率分配和电磁波幕射扩展，以提高系统的总率。</li>
<li>methods: 本研究使用了堆叠智能表面（SIM）技术，实现无线网络中发射束形成的电磁波幕射扩展。</li>
<li>results: 研究结果显示，相比传统MISO系统，SIM-enabled wave-based beamforming设计可以提高总率约200%。<details>
<summary>Abstract</summary>
Intelligent metasurface has recently emerged as a promising technology that enables the customization of wireless environments by harnessing large numbers of inexpensive configurable scattering elements. However, prior studies have predominantly focused on single-layer metasurfaces, which have limitations in terms of the number of beam patterns they can steer accurately due to practical hardware restrictions. In contrast, this paper introduces a novel stacked intelligent metasurface (SIM) design. Specifically, we investigate the integration of SIM into the downlink of a multiuser multiple-input single-output (MISO) communication system, where a SIM, consisting of a multilayer metasurface structure, is deployed at the base station (BS) to facilitate transmit beamforming in the electromagnetic wave domain. This eliminates the need for conventional digital beamforming and high-resolution digital-to-analog converters at the BS. To this end, we formulate an optimization problem that aims to maximize the sum rate of all user equipments by jointly optimizing the transmit power allocation at the BS and the wave-based beamforming at the SIM, subject to both the transmit power budget and discrete phase shift constraints. Furthermore, we propose a computationally efficient algorithm for solving this joint optimization problem and elaborate on the potential benefits of employing SIM in wireless networks. Finally, the numerical results corroborate the effectiveness of the proposed SIM-enabled wave-based beamforming design and evaluate the performance improvement achieved by the proposed algorithm compared to various benchmark schemes. It is demonstrated that considering the same number of transmit antennas, the proposed SIM-based system achieves about 200\% improvement in terms of sum rate compared to conventional MISO systems.
</details>
<details>
<summary>摘要</summary>
智能表面技术最近才有所突破，可以根据较低的成本和灵活的配置，自适应化无线环境。然而，先前的研究主要集中在单层表面上，它们在实际硬件限制下只能准确控制一定数量的扫描方向。相比之下，本文提出了一种新的叠加智能表面（SIM）设计。我们在基站（BS）部署了一个SIM，该SIM包括多层表面结构，以实现在电磁波域内进行发射扫描。这消除了BS需要传统的数字扫描和高分辨率数字到分析转换器。为此，我们形ulated一个最大化所有用户设备的总速率的优化问题，并对BS发射功率分配和SIM基于波的扫描优化进行联合优化，其中包括发射功率预算和离散相位转换约束。此外，我们提出了一种计算效率高的算法来解决这个联合优化问题。最后，我们证明了提案的SIM-基于波-扫描设计的效iveness，并评估了相对于不同参考方案的性能提升。实验结果表明，在同样的发射天线数量下，提案的SIM-基于波-扫描系统可以相比传统MISO系统提高约200%的总速率。
</details></li>
</ul>
<hr>
<h2 id="White-paper-on-Selected-Environmental-Parameters-affecting-Autonomous-Vehicle-AV-Sensors"><a href="#White-paper-on-Selected-Environmental-Parameters-affecting-Autonomous-Vehicle-AV-Sensors" class="headerlink" title="White paper on Selected Environmental Parameters affecting Autonomous Vehicle (AV) Sensors"></a>White paper on Selected Environmental Parameters affecting Autonomous Vehicle (AV) Sensors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02673">http://arxiv.org/abs/2309.02673</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Lee Wei Shung, Andrea Piazzoni, Roshan Vijay, Lincoln Ang Hon Kin, Niels de Boer</li>
<li>For: This paper aims to explore the effects of different environmental parameters on LiDARs and cameras used in Autonomous Vehicles (AVs) to better understand their performance and weaknesses.* Methods: The study uses a LiDAR test methodology developed in the Urban Mobility Grand Challenge (UMGC-L010) White Paper on LiDAR performance against selected Automotive Paints.* Results: The paper identifies the weaknesses and challenges that LiDARs may face in different environmental conditions, informing AV regulators in Singapore of the effects of different environmental parameters on AV sensors and the need for more robust testing standards and specifications.<details>
<summary>Abstract</summary>
Autonomous Vehicles (AVs) being developed these days rely on various sensor technologies to sense and perceive the world around them. The sensor outputs are subsequently used by the Automated Driving System (ADS) onboard the vehicle to make decisions that affect its trajectory and how it interacts with the physical world. The main sensor technologies being utilized for sensing and perception (S&P) are LiDAR (Light Detection and Ranging), camera, RADAR (Radio Detection and Ranging), and ultrasound. Different environmental parameters would have different effects on the performance of each sensor, thereby affecting the S&P and decision-making (DM) of an AV. In this publication, we explore the effects of different environmental parameters on LiDARs and cameras, leading us to conduct a study to better understand the impact of several of these parameters on LiDAR performance. From the experiments undertaken, the goal is to identify some of the weaknesses and challenges that a LiDAR may face when an AV is using it. This informs AV regulators in Singapore of the effects of different environmental parameters on AV sensors so that they can determine testing standards and specifications which will assess the adequacy of LiDAR systems installed for local AV operations more robustly. Our approach adopts the LiDAR test methodology first developed in the Urban Mobility Grand Challenge (UMGC-L010) White Paper on LiDAR performance against selected Automotive Paints.
</details>
<details>
<summary>摘要</summary>
自动驾驶车辆（AV）的开发现在启用了多种感知技术来感知和理解车辆周围的世界。感知输出后，车辆上的自动驾驶系统（ADS）使用这些输出来做出影响车辆轨迹和与物理世界之间交互的决策。主要的感知技术包括LiDAR（光探测和距离测量）、摄像头、RADAR（电波探测和距离测量）和超声波。不同的环境参数会对每种感知器的性能产生不同的影响，从而影响AV的感知和决策（DM）。在这篇文章中，我们探讨了不同环境参数对LiDAR和摄像头的影响，以便更好地理解LiDAR在AV中的弱点和挑战。这些研究结果可以让SG的AV规定者更好地了解AV感知器在不同环境下的性能，从而制定更加robust的测试标准和规范。我们采用了LiDAR测试方法学，根据城市 mobilit Grand Challenge（UMGC-L010）白皮书中的LiDAR性能测试方法。
</details></li>
</ul>
<hr>
<h2 id="Passive-Eavesdropping-Can-Significantly-Slow-Down-RIS-Assisted-Secret-Key-Generation"><a href="#Passive-Eavesdropping-Can-Significantly-Slow-Down-RIS-Assisted-Secret-Key-Generation" class="headerlink" title="Passive Eavesdropping Can Significantly Slow Down RIS-Assisted Secret Key Generation"></a>Passive Eavesdropping Can Significantly Slow Down RIS-Assisted Secret Key Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02653">http://arxiv.org/abs/2309.02653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ningya Xu, Guoshun Nan, Xiaofeng Tao</li>
<li>for:  This paper aims to maximize the RIS-assisted physical-layer secret key generation by optimizing the RIS units switching under the eavesdropping channel.</li>
<li>methods: The paper introduces a mathematical formulation to maximize the key generation rate and provides a step-by-step analysis.</li>
<li>results: The paper shows the effectiveness of the method in benefiting the secret key capacity under the eavesdropping channel, and observes that the key randomness and unmatched key rate are also significantly improved.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是通过控制信号的相位和幅度来提高RIS协助的物理层密钥生成。</li>
<li>methods: 论文提出了一个数学形式来最大化密钥生成率，并提供了一步步分析。</li>
<li>results: 论文证明了这种方法在听说攻击channel下可以提高密钥容量，并观察到密钥具有更高的随机性和不匹配率。<details>
<summary>Abstract</summary>
Reconfigurable Intelligent Surface (RIS) assisted physical layer key generation has shown great potential to secure wireless communications by smartly controlling signals such as phase and amplitude. However, previous studies mainly focus on RIS adjustment under ideal conditions, while the correlation between the eavesdropping channel and the legitimate channel, a more practical setting in the real world, is still largely under-explored for the key generation. To fill this gap, this paper aims to maximize the RIS-assisted physical-layer secret key generation by optimizing the RIS units switching under the eavesdropping channel. Firstly, we theoretically show that passive eavesdropping significantly reduces RIS-assisted secret key generation. Keeping this in mind, we then introduce a mathematical formulation to maximize the key generation rate and provide a step-by-step analysis. Extensive experiments show the effectiveness of our method in benefiting the secret key capacity under the eavesdropping channel. We also observe that the key randomness, and unmatched key rate, two metrics that measure the secret key quality, are also significantly improved, potentially paving the way to RIS-assisted key generation in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
智能表面协助物理层密钥生成（RIS）已经展示了为无线通信安全提供了巨大潜力，通过智能控制信号的相位和幅度。然而，先前的研究主要关注RIS的调整情况下理想的条件下，而实际世界中 correlate between the eavesdropping channel and the legitimate channel 的情况还是尚未得到了充分的探讨。为了填补这一漏洞，本文目的是通过最大化RIS单元的 switching 来提高RIS协助物理层密钥生成。首先，我们理论上表明了潜在的窃听者可以很大地降低RIS协助的密钥生成。鉴于这一点，我们然后引入了一种数学表述，以最大化密钥生成率，并提供了一步步分析。广泛的实验表明了我们的方法在窃听 Channel 下可以提高secret key capacity。我们还发现了两个秘密钥质量指标：key randomness 和 unmatched key rate 在窃听 Channel 下也有显著提高，这些指标可能为RIS协助的密钥生成在实际世界中开辟了新的可能性。
</details></li>
</ul>
<hr>
<h2 id="Joint-Beamforming-and-Power-Allocation-for-RIS-Aided-Full-Duplex-Integrated-Sensing-and-Uplink-Communication-System"><a href="#Joint-Beamforming-and-Power-Allocation-for-RIS-Aided-Full-Duplex-Integrated-Sensing-and-Uplink-Communication-System" class="headerlink" title="Joint Beamforming and Power Allocation for RIS Aided Full-Duplex Integrated Sensing and Uplink Communication System"></a>Joint Beamforming and Power Allocation for RIS Aided Full-Duplex Integrated Sensing and Uplink Communication System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02648">http://arxiv.org/abs/2309.02648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Guo, Yang Liu, Qingqing Wu, Xiaoyang Li, Qingjiang Shi</li>
<li>for:  This paper aims to jointly design beamforming, power allocation, and signal processing in a full-duplex (FD) uplink communication system aided by a reconfigurable intelligent surface (RIS) to enhance the integrated sensing and communication (ISAC) capability.</li>
<li>methods:  The paper proposes an iterative solution using convex optimization techniques, including majorization-minimization (MM) and penalty-dual-decomposition (PDD), to optimize all variables. Additionally, an low-complexity solution using alternative direction method of multipliers (ADMM) is developed to update all variables analytically and run efficiently.</li>
<li>results:  Numerical results demonstrate the effectiveness and efficiency of the proposed algorithms in enhancing the ISAC capability of the FD uplink communication system aided by RIS, with significant performance boosting achieved by employing RIS.<details>
<summary>Abstract</summary>
Integrated sensing and communication (ISAC) capability is envisioned as one key feature for future cellular networks. Classical half-duplex (HD) radar sensing is conducted in a "first-emit-then-listen" manner. One challenge to realize HD ISAC lies in the discrepancy of the two systems' time scheduling for transmitting and receiving. This difficulty can be overcome by full-duplex (FD) transceivers. Besides, ISAC generally has to comprise its communication rate due to realizing sensing functionality. This loss can be compensated by the emerging reconfigurable intelligent surface (RIS) technology. This paper considers the joint design of beamforming, power allocation and signal processing in a FD uplink communication system aided by RIS, which is a highly nonconvex problem. To resolve this challenge, via leveraging the cutting-the-edge majorization-minimization (MM) and penalty-dual-decomposition (PDD) methods, we develop an iterative solution that optimizes all variables via using convex optimization techniques. Besides, by wisely exploiting alternative direction method of multipliers (ADMM) and optimality analysis, we further develop a low complexity solution that updates all variables analytically and runs highly efficiently. Numerical results are provided to verify the effectiveness and efficiency of our proposed algorithms and demonstrate the significant performance boosting by employing RIS in the FD ISAC system.
</details>
<details>
<summary>摘要</summary>
integrated sensing and communication (ISAC) capability 是未来网络的一个关键特性。 classical half-duplex (HD) 雷达探测是通过 "first-emit-then-listen" 方式进行的。一个实现 HD ISAC 的挑战在于两个系统的时间安排不同。这个困难可以通过全双工 (FD) 接收机来解决。此外，ISAC 通常需要牺牲其通信率，以实现探测功能。这个损失可以通过 emerging 可配置智能表面 (RIS) 技术来补偿。本文考虑了在 FD 上升通信系统中使用 RIS 的共同设计，包括扬声器、功率分配和信号处理。这是一个非 convex 问题，通过利用 cutting-the-edge 主要化-最小化 (MM) 和罚偿对偶 (PDD) 方法，我们开发了一个迭代解决方案，该方案通过使用几何优化技术来优化所有变量。此外，通过利用 alternative direction method of multipliers (ADMM) 和可行性分析，我们进一步开发了一个低复杂度的解决方案，该方案可以在分析方式下更新所有变量，并在高效地运行。 numerical results 表明我们提出的方法的有效性和高效性，并且通过使用 RIS 在 FD ISAC 系统中实现了显著性能提升。
</details></li>
</ul>
<hr>
<h2 id="Mean-Field-Game-based-Waveform-Precoding-Design-for-Mobile-Crowd-Integrated-Sensing-Communication-and-Computation-Systems"><a href="#Mean-Field-Game-based-Waveform-Precoding-Design-for-Mobile-Crowd-Integrated-Sensing-Communication-and-Computation-Systems" class="headerlink" title="Mean Field Game-based Waveform Precoding Design for Mobile Crowd Integrated Sensing, Communication, and Computation Systems"></a>Mean Field Game-based Waveform Precoding Design for Mobile Crowd Integrated Sensing, Communication, and Computation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02645">http://arxiv.org/abs/2309.02645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dezhi Wang, Chongwen Huang, Jiguang He, Xiaoming Chen, Wei Wang, Zhaoyang Zhang, Zhu Han, Mérouane Debbah</li>
<li>for: 大规模移动群体 интеграble 感知、通信、计算（ISCC）系统，如智能家居和连接车辆，需要许多 интеграble 感知和通信（ISAC）设备来感知目标并将数据传输到基站（BS）进行进一步处理。然而，随着 ISAC 设备的数量增加，存在许多 ISAC 设备之间的密切互动，尤其是在数据收集和处理过程中。</li>
<li>methods: 本文使用了 Mean Field Game（MFG）方法来解决大规模 ISAC 设备之间的互动问题。特别是，我们首先使用 MFG 方法将其他 ISAC 设备对其影响转化为平均场term，并 deriv 了 Fokker-Planck-Kolmogorov 方程，这个方程模型了系统状态的演化。然后，我们 deriv 了基于平均场term的成本函数，并重新定义了波形预编码设计问题。</li>
<li>results: 我们的算法可以有效地解决大规模 ISAC 设备之间的互动问题，并且与其他基线比较，我们的波形预编码设计算法具有提高通信性能和降低成本函数的优势。<details>
<summary>Abstract</summary>
Data collection and processing timely is crucial for mobile crowd integrated sensing, communication, and computation~(ISCC) systems with various applications such as smart home and connected cars, which requires numerous integrated sensing and communication~(ISAC) devices to sense the targets and offload the data to the base station~(BS) for further processing. However, as the number of ISAC devices growing, there exists intensive interactions among ISAC devices in the processes of data collection and processing since they share the common network resources. In this paper, we consider the environment sensing problem in the large-scale mobile crowd ISCC systems and propose an efficient waveform precoding design algorithm based on the mean field game~(MFG). Specifically, to handle the complex interactions among large-scale ISAC devices, we first utilize the MFG method to transform the influence from other ISAC devices into the mean field term and derive the Fokker-Planck-Kolmogorov equation, which model the evolution of the system state. Then, we derive the cost function based on the mean field term and reformulate the waveform precoding design problem. Next, we utilize the G-prox primal-dual hybrid gradient algorithm to solve the reformulated problem and analyze the computational complexity of the proposed algorithm. Finally, simulation results demonstrate that the proposed algorithm can solve the interactions among large-scale ISAC devices effectively in the ISCC process. In addition, compared with other baselines, the proposed waveform precoding design algorithm has advantages in improving communication performance and reducing cost function.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>大数据收集和处理在移动众情 интеGRATED sensing、通信和计算（ISCC）系统中是关键，这些系统有各种应用，如智能家居和连接的汽车，需要大量的 интеGRATED sensing和通信（ISAC）设备来感知目标并将数据传输到基站（BS）进行进一步处理。然而，随着ISAC设备的数量增加，存在许多ISAC设备之间的互动，这些设备共享共享网络资源。在这篇论文中，我们考虑了大规模移动众情 ISCC 系统中的环境感知问题，并提出了一种高效的波形预编设计算法，基于 Mean Field Game（MFG）。specifically，为了处理大规模ISAC设备之间复杂的互动，我们首先使用MFG方法将其他ISAC设备的影响转化为均场项，并 derive the Fokker-Planck-Kolmogorov equation，该方程模型系统状态的演化。然后，我们 derive the cost function based on the mean field term，并重新定义波形预编设计问题。接着，我们使用G-prox primal-dual hybrid gradient algorithm来解决重新定义的问题，并分析提案的计算复杂性。最后，实验结果表明，提案的算法可以有效地处理大规模ISAC设备之间的互动，并且相比其他基准，提案的波形预编设计算法具有改善通信性和降低成本函数的优势。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/06/eess.SP_2023_09_06/" data-id="clmvt7tdl00t426rdfbuw1yss" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/05/cs.SD_2023_09_05/" class="article-date">
  <time datetime="2023-09-05T15:00:00.000Z" itemprop="datePublished">2023-09-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/05/cs.SD_2023_09_05/">cs.SD - 2023-09-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Music-Source-Separation-with-Band-Split-RoPE-Transformer"><a href="#Music-Source-Separation-with-Band-Split-RoPE-Transformer" class="headerlink" title="Music Source Separation with Band-Split RoPE Transformer"></a>Music Source Separation with Band-Split RoPE Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02612">http://arxiv.org/abs/2309.02612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei-Tsung Lu, Ju-Chiang Wang, Qiuqiang Kong, Yun-Ning Hung</li>
<li>for: 这个论文是为了提出一种新的频域方法，用于分离音乐录音中的不同乐器部分。</li>
<li>methods: 这种方法基于一种带划分模块，将输入复杂的spectrogram映射到不同的subband水平上，然后使用一个堆栈的层次Transformer来模型内部带和间部序列进行多带封锁估计。</li>
<li>results: 这个系统在Sound Demixing Challenge（SDX23）的MSS追踪上 Ranked the first place，并在MUSDB18HQ上 achieved state-of-the-art result without extra training data，具有9.80 dB的平均SDR。<details>
<summary>Abstract</summary>
Music source separation (MSS) aims to separate a music recording into multiple musically distinct stems, such as vocals, bass, drums, and more. Recently, deep learning approaches such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have been used, but the improvement is still limited. In this paper, we propose a novel frequency-domain approach based on a Band-Split RoPE Transformer (called BS-RoFormer). BS-RoFormer relies on a band-split module to project the input complex spectrogram into subband-level representations, and then arranges a stack of hierarchical Transformers to model the inner-band as well as inter-band sequences for multi-band mask estimation. To facilitate training the model for MSS, we propose to use the Rotary Position Embedding (RoPE). The BS-RoFormer system trained on MUSDB18HQ and 500 extra songs ranked the first place in the MSS track of Sound Demixing Challenge (SDX23). Benchmarking a smaller version of BS-RoFormer on MUSDB18HQ, we achieve state-of-the-art result without extra training data, with 9.80 dB of average SDR.
</details>
<details>
<summary>摘要</summary>
音乐源分离（MSS）目标是将音乐录音分解成多个音乐上的独立 Component，如 vocals、bass、鼓等。 现在，深度学习方法如卷积神经网络（CNN）和循环神经网络（RNN）已经被应用，但是改进的空间仍然有限。在这篇论文中，我们提出了一种新的频域方法，基于 Band-Split RoPE Transformer（BS-RoFormer）。BS-RoFormer使用带分模块将输入复杂spectrogram projet到子带水平表示，然后将一 stack of hierarchical Transformers用于内带和间带序列的模型化，以实现多带掩码估计。为了训练MSS模型，我们提出了Rotary Position Embedding（RoPE）。BS-RoFormer系统在MUSDB18HQ和500首EXTRA歌曲上训练后，在Sound Demixing Challenge（SDX23）的MSS轨道上排名第一，并 achieved state-of-the-art result without extra training data，具有9.80 dB的平均SDR。 benchmarking一个小版本的BS-RoFormer在MUSDB18HQ上，我们也达到了最佳结果，不需要额外的训练数据，具有9.80 dB的平均SDR。
</details></li>
</ul>
<hr>
<h2 id="BWSNet-Automatic-Perceptual-Assessment-of-Audio-Signals"><a href="#BWSNet-Automatic-Perceptual-Assessment-of-Audio-Signals" class="headerlink" title="BWSNet: Automatic Perceptual Assessment of Audio Signals"></a>BWSNet: Automatic Perceptual Assessment of Audio Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02592">http://arxiv.org/abs/2309.02592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clément Le Moine Veillon, Victor Rosi, Pablo Arias Sarah, Léane Salais, Nicolas Obin</li>
<li>for: 这个论文是用来描述一种基于最差最好的排序（BWS）实验获取的人类评价的模型。</li>
<li>methods: 该模型使用了一组成本函数和约束，将声音amples映射到一个表示感知的属性的嵌入空间中。</li>
<li>results: 对两个BWS研究中的社会态度和气质质量的声音进行测试，结果显示该模型的嵌入空间结构与人类评价具有一致性。Here’s the translation in English:</li>
<li>for: This paper proposes a model that can be trained from raw human judgments obtained through a Best-Worst scaling (BWS) experiment, which maps sound samples into an embedded space that represents the perception of a studied attribute.</li>
<li>methods: The model uses a set of cost functions and constraints, interpreting trial-wise ordinal relations as distance comparisons in a metric learning task.</li>
<li>results: The results show that the structure of the latent space is faithful to human judgments, based on tests on two BWS studies investigating the perception of speech social attitudes and timbral qualities.<details>
<summary>Abstract</summary>
This paper introduces BWSNet, a model that can be trained from raw human judgements obtained through a Best-Worst scaling (BWS) experiment. It maps sound samples into an embedded space that represents the perception of a studied attribute. To this end, we propose a set of cost functions and constraints, interpreting trial-wise ordinal relations as distance comparisons in a metric learning task. We tested our proposal on data from two BWS studies investigating the perception of speech social attitudes and timbral qualities. For both datasets, our results show that the structure of the latent space is faithful to human judgements.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了BWSNet模型，可以从简陋人类评价获得的 raw 数据进行训练。它将声音样本映射到一个嵌入空间中，该空间表达人类对研究 attribute 的感受。为此，我们提出了一组成本函数和约束，将试验性质的ORDINAL 关系解释为度量学习任务中的距离比较。我们在两个 BWS 研究中进行了测试，研究的是speech 社会态度和气质质量。为两个数据集，我们的结果表明，嵌入空间的结构与人类评价具有一致性。
</details></li>
</ul>
<hr>
<h2 id="Symbolic-Music-Representations-for-Classification-Tasks-A-Systematic-Evaluation"><a href="#Symbolic-Music-Representations-for-Classification-Tasks-A-Systematic-Evaluation" class="headerlink" title="Symbolic Music Representations for Classification Tasks: A Systematic Evaluation"></a>Symbolic Music Representations for Classification Tasks: A Systematic Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02567">http://arxiv.org/abs/2309.02567</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anusfoil/symrep">https://github.com/anusfoil/symrep</a></li>
<li>paper_authors: Huan Zhang, Emmanouil Karystinaios, Simon Dixon, Gerhard Widmer, Carlos Eduardo Cancino-Chacón</li>
<li>for: 本研究旨在对深度学习方法在音乐信息检索领域中的应用进行系统性的检查，特别是对符号音乐的不同表示方式的研究。</li>
<li>methods: 本研究使用矩阵表示、序列表示和图表示，并与符号谱和表演进行相应的神经网络架构。此外，我们还介绍了一种新的图表示方法，用于符号表演的全球分类任务。</li>
<li>results: 我们的系统性评估结果显示，图表示方法在三个乐曲级别分类任务中表现出色，而且训练成本较低。<details>
<summary>Abstract</summary>
Music Information Retrieval (MIR) has seen a recent surge in deep learning-based approaches, which often involve encoding symbolic music (i.e., music represented in terms of discrete note events) in an image-like or language like fashion. However, symbolic music is neither an image nor a sentence, and research in the symbolic domain lacks a comprehensive overview of the different available representations. In this paper, we investigate matrix (piano roll), sequence, and graph representations and their corresponding neural architectures, in combination with symbolic scores and performances on three piece-level classification tasks. We also introduce a novel graph representation for symbolic performances and explore the capability of graph representations in global classification tasks. Our systematic evaluation shows advantages and limitations of each input representation. Our results suggest that the graph representation, as the newest and least explored among the three approaches, exhibits promising performance, while being more light-weight in training.
</details>
<details>
<summary>摘要</summary>
音乐信息检索（MIR）在深度学习基于方法方面有最近的增长，这些方法常常通过编码符号音乐（即音乐表示为离散音 Event）来实现图像或语言类似的表示方式。然而，符号音乐并不是图像 noch ist eine Sprache，研究符号领域缺乏全面的不同表示方法的报告。在这篇论文中，我们调查矩阵（钢琴 Roll）、序列和图表示法和其相应的神经网络架构，并在三个乐曲级别分类任务中进行了系统性的评估。我们还介绍了一种新的图表示法 для符号性表演，并探讨图表示法在全球分类任务中的能力。我们的系统性评估显示每种输入表示方法的优势和局限性。结果表明，图表示法，作为最新并最少探索的一种方法，具有抢人的表现，同时在训练中更轻量级。
</details></li>
</ul>
<hr>
<h2 id="Employing-Real-Training-Data-for-Deep-Noise-Suppression"><a href="#Employing-Real-Training-Data-for-Deep-Noise-Suppression" class="headerlink" title="Employing Real Training Data for Deep Noise Suppression"></a>Employing Real Training Data for Deep Noise Suppression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02432">http://arxiv.org/abs/2309.02432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyi Xu, Marvin Sach, Jan Pirklbauer, Tim Fingscheidt</li>
<li>for: 用于提高深度噪音消除（DNS）模型的训练，使其能够更好地适应实际应用场景。</li>
<li>methods: 使用实际训练数据，通过非生成方法或引用自由损失函数来训练DNS模型，并使用一个端到端非侵入式深度神经网络（PESQ-DNN）来估算噪音消除后的语音质量评分。</li>
<li>results: 使用实际训练数据和PESQ-DNN，DNS模型的训练效果比使用仅Synthetic训练数据的参考方法更好，在Synthetic测试数据上比基线方法提高0.32个PESQ分，在实际测试数据上也超过了基线方法0.05个DNSMOS分。<details>
<summary>Abstract</summary>
Most deep noise suppression (DNS) models are trained with reference-based losses requiring access to clean speech. However, sometimes an additive microphone model is insufficient for real-world applications. Accordingly, ways to use real training data in supervised learning for DNS models promise to reduce a potential training/inference mismatch. Employing real data for DNS training requires either generative approaches or a reference-free loss without access to the corresponding clean speech. In this work, we propose to employ an end-to-end non-intrusive deep neural network (DNN), named PESQ-DNN, to estimate perceptual evaluation of speech quality (PESQ) scores of enhanced real data. It provides a reference-free perceptual loss for employing real data during DNS training, maximizing the PESQ scores. Furthermore, we use an epoch-wise alternating training protocol, updating the DNS model on real data, followed by PESQ-DNN updating on synthetic data. The DNS model trained with the PESQ-DNN employing real data outperforms all reference methods employing only synthetic training data. On synthetic test data, our proposed method excels the Interspeech 2021 DNS Challenge baseline by a significant 0.32 PESQ points. Both on synthetic and real test data, the proposed method beats the baseline by 0.05 DNSMOS points - although PESQ-DNN optimizes for a different perceptual metric.
</details>
<details>
<summary>摘要</summary>
现有大多数深度噪声抑制（DNS）模型通常通过参考基于的损失来训练，但是在实际应用中，加法式麦克风模型可能不足。因此，使用实际训练数据来训练 DNS 模型可能会降低训练/推断匹配问题。使用实际数据进行 DNS 训练需要使用生成方法或无参考损失。在这种情况下，我们提出了一种非侵入式深度神经网络（DNN）名为 PESQ-DNN，用于估算噪声抑制后的语音质量评分（PESQ）分数。PESQ-DNN 提供了一种无参考的感知损失，可以使用实际数据进行 DNS 训练，最大化 PESQ 分数。此外，我们使用了一种每个班次 alternate 训练协议，首先更新 DNS 模型使用实际数据，然后 PESQ-DNN 使用生成数据进行更新。使用 PESQ-DNN 进行 DNS 训练的模型超越了所有参考方法，使用只有synthetic 训练数据。在synthetic 测试数据上，我们的提议方法高于2021年慕尼黑语音处理大会 DNS 挑战基准值的0.32 PESQ 分数。在synthetic 和实际测试数据上，我们的提议方法超越了基准值0.05 DNSMOS 分数。
</details></li>
</ul>
<hr>
<h2 id="Personalized-Adaptation-with-Pre-trained-Speech-Encoders-for-Continuous-Emotion-Recognition"><a href="#Personalized-Adaptation-with-Pre-trained-Speech-Encoders-for-Continuous-Emotion-Recognition" class="headerlink" title="Personalized Adaptation with Pre-trained Speech Encoders for Continuous Emotion Recognition"></a>Personalized Adaptation with Pre-trained Speech Encoders for Continuous Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02418">http://arxiv.org/abs/2309.02418</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minh Tran, Yufeng Yin, Mohammad Soleymani</li>
<li>for: 本研究旨在提高无监督个性化情感识别的泛化和稳定性，通过学习 speaker embedding 来学习 robust speech 表示。</li>
<li>methods: 我们首先在无监督情况下预训一个 encoder，使其可以通过 speaker embedding 来学习 conditioned on speakers 的 robust speech 表示。其次，我们提出一种无监督方法，通过找到类似的 speaker 并利用它们的标签分布来补做标签分布的偏移。</li>
<li>results: 我们的方法在 MSP-Podcast 集合上进行了广泛的实验，结果表明，我们的方法可以一直高于强个性化基eline，并实现情感识别预测的状态前沿性。<details>
<summary>Abstract</summary>
There are individual differences in expressive behaviors driven by cultural norms and personality. This between-person variation can result in reduced emotion recognition performance. Therefore, personalization is an important step in improving the generalization and robustness of speech emotion recognition. In this paper, to achieve unsupervised personalized emotion recognition, we first pre-train an encoder with learnable speaker embeddings in a self-supervised manner to learn robust speech representations conditioned on speakers. Second, we propose an unsupervised method to compensate for the label distribution shifts by finding similar speakers and leveraging their label distributions from the training set. Extensive experimental results on the MSP-Podcast corpus indicate that our method consistently outperforms strong personalization baselines and achieves state-of-the-art performance for valence estimation.
</details>
<details>
<summary>摘要</summary>
“各自差异的表达行为，受文化 norms 和人类特质的影响，会导致情感识别的表现下降。因此，个人化是识别表情认识的重要步骤。在这篇文章中，我们首先透过自我监督学习法，将speaker embedding learnable 运算在训练集中，以学习基于话者的Robust speech表现。其次，我们提出了一个无supervision的方法，通过找到相似的话者，并利用它们在训练集中的标签分布来补偿标签分布的差异。实验结果显示，我们的方法可以与强大的个人化基eline 相比，并 achieve state-of-the-art 的表情认识性能。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="The-Batik-plays-Mozart-Corpus-Linking-Performance-to-Score-to-Musicological-Annotations"><a href="#The-Batik-plays-Mozart-Corpus-Linking-Performance-to-Score-to-Musicological-Annotations" class="headerlink" title="The Batik-plays-Mozart Corpus: Linking Performance to Score to Musicological Annotations"></a>The Batik-plays-Mozart Corpus: Linking Performance to Score to Musicological Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02399">http://arxiv.org/abs/2309.02399</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huispaty/batik_plays_mozart">https://github.com/huispaty/batik_plays_mozart</a></li>
<li>paper_authors: Patricia Hu, Gerhard Widmer</li>
<li>for: 这个论文是为了创建一个高质量、高精度的钢琴表演数据集，结合专业的莫扎特钢琴奏鸣和专家标注的乐谱。</li>
<li>methods: 该论文使用了专业钢琴家 Roland Batik 的录音，并将其与现代莫扎特乐谱标准版本进行了精度对应。</li>
<li>results: 该论文创建了一个高精度的钢琴表演数据集，可以用于研究表演与结构之间的关系，并提供了两个探索性实验来证明其使用价值。<details>
<summary>Abstract</summary>
We present the Batik-plays-Mozart Corpus, a piano performance dataset combining professional Mozart piano sonata performances with expert-labelled scores at a note-precise level. The performances originate from a recording by Viennese pianist Roland Batik on a computer-monitored B\"osendorfer grand piano, and are available both as MIDI files and audio recordings. They have been precisely aligned, note by note, with a current standard edition of the corresponding scores (the New Mozart Edition) in such a way that they can further be connected to the musicological annotations (harmony, cadences, phrases) on these scores that were recently published by Hentschel et al. (2021).   The result is a high-quality, high-precision corpus mapping scores and musical structure annotations to precise note-level professional performance information. As the first of its kind, it can serve as a valuable resource for studying various facets of expressive performance and their relationship with structural aspects. In the paper, we outline the curation process of the alignment and conduct two exploratory experiments to demonstrate its usefulness in analyzing expressive performance.
</details>
<details>
<summary>摘要</summary>
我们现在提出了“巴提克扮演莫扎特” corpora，这是一个结合了专业莫扎特钢琴室内乐表演和专家标注的谱面数据集。表演来自奥地利钢琴家罗兰·巴提克在计算机监测的波Sendendorfer大钢琴上的录音，并以MIDI文件和音频录音的形式可用。它们已经精准地对应了现代标准版谱面（新莫扎特版），以便可以与最近由豪伦肯（2021）等人发表的音乐学注释（和声、推移、段落）相连接。这个结果是一个高质量、高精度的谱面和音乐结构注释映射数据集。作为首个类型的资源，它可以用于研究不同的表演特征和其与结构方面的关系。在论文中，我们介绍了对Alignment的策略和进行了两项探索性实验，以 demonstate其在分析表演各种特征方面的用用。
</details></li>
</ul>
<hr>
<h2 id="PESTO-Pitch-Estimation-with-Self-supervised-Transposition-equivariant-Objective"><a href="#PESTO-Pitch-Estimation-with-Self-supervised-Transposition-equivariant-Objective" class="headerlink" title="PESTO: Pitch Estimation with Self-supervised Transposition-equivariant Objective"></a>PESTO: Pitch Estimation with Self-supervised Transposition-equivariant Objective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02265">http://arxiv.org/abs/2309.02265</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alain Riou, Stefan Lattner, Gaëtan Hadjeres, Geoffroy Peeters</li>
<li>for: 本研究使用自适应学习（SSL）解决音高估计问题。</li>
<li>methods: 我们使用一个轻量级（&lt;30k参数）的siamesen神经网络，该网络使用两个不同的折射音高版本的同一个音频 Constant-Q Transform 输入。为避免encoder-only设置中的模型崩溃，我们提议一种新的类型-based transposition-equivariant目标，该目标捕捉音高信息。此外，我们设计了网络的architecture来保持折射性，通过引入学习的Toeplitz矩阵。</li>
<li>results: 我们对歌唱voice和乐器pitch估计两个任务进行评估，并显示我们的模型能够泛化到任务和数据集，同时具有轻量级和实时应用compatibility。具体来说，我们的结果超过了自适应基eline和supervised方法的自适应基eline，并将自适应和supervised方法之间的性能差逐渐缩小。<details>
<summary>Abstract</summary>
In this paper, we address the problem of pitch estimation using Self Supervised Learning (SSL). The SSL paradigm we use is equivariance to pitch transposition, which enables our model to accurately perform pitch estimation on monophonic audio after being trained only on a small unlabeled dataset. We use a lightweight ($<$ 30k parameters) Siamese neural network that takes as inputs two different pitch-shifted versions of the same audio represented by its Constant-Q Transform. To prevent the model from collapsing in an encoder-only setting, we propose a novel class-based transposition-equivariant objective which captures pitch information. Furthermore, we design the architecture of our network to be transposition-preserving by introducing learnable Toeplitz matrices.   We evaluate our model for the two tasks of singing voice and musical instrument pitch estimation and show that our model is able to generalize across tasks and datasets while being lightweight, hence remaining compatible with low-resource devices and suitable for real-time applications. In particular, our results surpass self-supervised baselines and narrow the performance gap between self-supervised and supervised methods for pitch estimation.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们解决了使用自适应学习（SSL）的抽象问题。我们使用的SSL模式是抽象到音高的转换，这使得我们的模型可以在只有一小量无标签数据上训练后，对声音进行精准的抽象。我们使用一个轻量级（<30k参数）的同构神经网络，该网络接受两个不同的抽象后的同一个音频表示，即其常见频谱变换。为避免encoder-only设置中的模型崩溃，我们提出了一种新的类型-基于的转换平衡目标，该目标捕捉到音高信息。此外，我们设计了网络的架构，使其保持转换平衡，通过引入学习的托凯利矩阵。  我们对两个任务：唱歌voice和乐器pitch estimation进行评估，并显示了我们的模型可以适应任务和数据集，同时具有轻量级和实时应用Compatible。具体来说，我们的结果超过了自我监督基线，并将自我监督和指导方法之间的性能差距缩小。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/05/cs.SD_2023_09_05/" data-id="clmvt7tbl00lf26rd22ob8mz5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/05/cs.CV_2023_09_05/" class="article-date">
  <time datetime="2023-09-05T13:00:00.000Z" itemprop="datePublished">2023-09-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/05/cs.CV_2023_09_05/">cs.CV - 2023-09-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Compressing-Vision-Transformers-for-Low-Resource-Visual-Learning"><a href="#Compressing-Vision-Transformers-for-Low-Resource-Visual-Learning" class="headerlink" title="Compressing Vision Transformers for Low-Resource Visual Learning"></a>Compressing Vision Transformers for Low-Resource Visual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02617">http://arxiv.org/abs/2309.02617</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chensy7/efficient-vit">https://github.com/chensy7/efficient-vit</a></li>
<li>paper_authors: Eric Youn, Sai Mitheran J, Sanjana Prabhu, Siyuan Chen</li>
<li>for: 这个研究的目的是将视Transformer（ViT）和其变体带到边缘环境中，以提高视觉学习的可行性和效率。</li>
<li>methods: 我们使用了各种实用的模型压缩技术，包括传承、剪裁和量化，以降低ViT的模型大小和 Compute重量，并且保持与顶尖ViT的几乎相同的准确性。</li>
<li>results: 我们的实现可以在NVIDIA Jetson Nano（4GB）上实现快速的视觉 trasformer 推断，并且与顶尖ViT的准确性几乎相同，具体来说，我们在ImageNet题库上的Top-1准确性为85.3%，比顶尖ViT-B的86.3%高出0.6%。<details>
<summary>Abstract</summary>
Vision transformer (ViT) and its variants have swept through visual learning leaderboards and offer state-of-the-art accuracy in tasks such as image classification, object detection, and semantic segmentation by attending to different parts of the visual input and capturing long-range spatial dependencies. However, these models are large and computation-heavy. For instance, the recently proposed ViT-B model has 86M parameters making it impractical for deployment on resource-constrained devices. As a result, their deployment on mobile and edge scenarios is limited. In our work, we aim to take a step toward bringing vision transformers to the edge by utilizing popular model compression techniques such as distillation, pruning, and quantization.   Our chosen application environment is an unmanned aerial vehicle (UAV) that is battery-powered and memory-constrained, carrying a single-board computer on the scale of an NVIDIA Jetson Nano with 4GB of RAM. On the other hand, the UAV requires high accuracy close to that of state-of-the-art ViTs to ensure safe object avoidance in autonomous navigation, or correct localization of humans in search-and-rescue. Inference latency should also be minimized given the application requirements. Hence, our target is to enable rapid inference of a vision transformer on an NVIDIA Jetson Nano (4GB) with minimal accuracy loss. This allows us to deploy ViTs on resource-constrained devices, opening up new possibilities in surveillance, environmental monitoring, etc. Our implementation is made available at https://github.com/chensy7/efficient-vit.
</details>
<details>
<summary>摘要</summary>
“视力变换器”（ViT）和其变体在视觉学领导板卡上提供了状态机器的精度，包括图像分类、物体检测和 semantics 分割，通过不同部分的视觉输入注意力和捕捉长距离的空间相关性。但这些模型很大， computation 沉重。例如，最近提出的 ViT-B 模型有 86M 参数，使其在资源有限的设备上无法进行部署。因此，我们的目标是通过使用流行的模型压缩技术，如熔炼、剪辑和量化，将视力变换器带到边缘。我们选择的应用环境是无人飞行器（UAV），它是电池电池和内存有限制的，搭载了一款基于 NVIDIA Jetson Nano 的单板计算机，具有 4GB 的 RAM。然而，UAV 需要高精度，接近状态机器精度，以确保自主导航中的物体避免和人类的correct 当地化。推理延迟应该被最小化，因为应用要求。因此，我们的目标是在 NVIDIA Jetson Nano （4GB）上快速推理一个视力变换器，并尽可能减少精度损失。这样，我们就能够将视力变换器部署到资源有限的设备上，开放出新的可能性，例如监测、环境监测等。我们的实现可以在 GitHub 上找到：https://github.com/chensy7/efficient-vit。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Pretraining-Improves-Performance-and-Inference-Efficiency-in-Multiple-Lung-Ultrasound-Interpretation-Tasks"><a href="#Self-Supervised-Pretraining-Improves-Performance-and-Inference-Efficiency-in-Multiple-Lung-Ultrasound-Interpretation-Tasks" class="headerlink" title="Self-Supervised Pretraining Improves Performance and Inference Efficiency in Multiple Lung Ultrasound Interpretation Tasks"></a>Self-Supervised Pretraining Improves Performance and Inference Efficiency in Multiple Lung Ultrasound Interpretation Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02596">http://arxiv.org/abs/2309.02596</a></li>
<li>repo_url: None</li>
<li>paper_authors: Blake VanBerlo, Brian Li, Jesse Hoey, Alexander Wong</li>
<li>for: 这个研究是 investigate whether self-supervised pretraining could produce a neural network feature extractor applicable to multiple classification tasks in B-mode lung ultrasound analysis.</li>
<li>methods: 这个研究使用了自我监督预训练，并在三个肺超声分类任务上进行了细化。</li>
<li>results: 研究结果表明，使用自我监督预训练可以提高肺超声分类任务的平均总成功率，并且可以降低总计算时间。<details>
<summary>Abstract</summary>
In this study, we investigated whether self-supervised pretraining could produce a neural network feature extractor applicable to multiple classification tasks in B-mode lung ultrasound analysis. When fine-tuning on three lung ultrasound tasks, pretrained models resulted in an improvement of the average across-task area under the receiver operating curve (AUC) by 0.032 and 0.061 on local and external test sets respectively. Compact nonlinear classifiers trained on features outputted by a single pretrained model did not improve performance across all tasks; however, they did reduce inference time by 49% compared to serial execution of separate fine-tuned models. When training using 1% of the available labels, pretrained models consistently outperformed fully supervised models, with a maximum observed test AUC increase of 0.396 for the task of view classification. Overall, the results indicate that self-supervised pretraining is useful for producing initial weights for lung ultrasound classifiers.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们研究了自我监督预训练是否可以生成应用于多个分类任务的脑神经网络特征提取器。当细化到三个肺超声分类任务时，预训练模型可以提高平均 across-task 接受器操作曲线（AUC）的值 by 0.032 and 0.061 on local and external test sets respectively。compact nonlinear classifiers trained on features outputted by a single pretrained model did not improve performance across all tasks; however, they did reduce inference time by 49% compared to serial execution of separate fine-tuned models。when training using 1% of the available labels, pretrained models consistently outperformed fully supervised models, with a maximum observed test AUC increase of 0.396 for the task of view classification。总的来说，结果表明自我监督预训练是肺超声分类器的初始 веса的生成的有用。
</details></li>
</ul>
<hr>
<h2 id="Anatomy-Driven-Pathology-Detection-on-Chest-X-rays"><a href="#Anatomy-Driven-Pathology-Detection-on-Chest-X-rays" class="headerlink" title="Anatomy-Driven Pathology Detection on Chest X-rays"></a>Anatomy-Driven Pathology Detection on Chest X-rays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02578">http://arxiv.org/abs/2309.02578</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/philip-mueller/adpd">https://github.com/philip-mueller/adpd</a></li>
<li>paper_authors: Philip Müller, Felix Meissen, Johannes Brandt, Georgios Kaissis, Daniel Rueckert</li>
<li>for:  automatic interpretation of medical scans, such as chest X-rays, and providing a high level of explainability to support radiologists in making informed decisions.</li>
<li>methods:  uses easy-to-annotate bounding boxes of anatomical regions as proxies for pathologies, and studies two training approaches: supervised training using anatomy-level pathology labels and multiple instance learning (MIL) with image-level pathology labels.</li>
<li>results:  outperforms weakly supervised methods and fully supervised detection with limited training samples, and the MIL approach is competitive with both baseline approaches, demonstrating the potential of the proposed approach.Here’s the text in Simplified Chinese:</li>
<li>for:  automatic化医疗影像解读，如胸部X线影像，并提供高水准的解释以支持 radiologists 做出 informed 的决策。</li>
<li>methods: 使用易于注释的 bounding boxes 的 anatomical regions 作为疾病的代理，并研究两种训练方法： supervised 训练使用 anatomy-level 疾病标签，以及 multiple instance learning (MIL)  with image-level 疾病标签。</li>
<li>results:  outperforms weakly supervised methods 和仅有限的训练样本的充分 supervised detection，并且 MIL 方法与两种基eline approaches 相当，因此 demonstrates 了提案的方法的潜力。<details>
<summary>Abstract</summary>
Pathology detection and delineation enables the automatic interpretation of medical scans such as chest X-rays while providing a high level of explainability to support radiologists in making informed decisions. However, annotating pathology bounding boxes is a time-consuming task such that large public datasets for this purpose are scarce. Current approaches thus use weakly supervised object detection to learn the (rough) localization of pathologies from image-level annotations, which is however limited in performance due to the lack of bounding box supervision. We therefore propose anatomy-driven pathology detection (ADPD), which uses easy-to-annotate bounding boxes of anatomical regions as proxies for pathologies. We study two training approaches: supervised training using anatomy-level pathology labels and multiple instance learning (MIL) with image-level pathology labels. Our results show that our anatomy-level training approach outperforms weakly supervised methods and fully supervised detection with limited training samples, and our MIL approach is competitive with both baseline approaches, therefore demonstrating the potential of our approach.
</details>
<details>
<summary>摘要</summary>
医学成像检测和定义可以自动解释医疗成像，如胸部X射线扫描，并提供高水平的解释，以支持 radiologist 作出 Informed Decision。但是，标注疾病 bounding box 是一个时间消耗大的任务，因此大型公共数据集 для此目的罕见。现有的方法因此使用弱型对象检测来学习 (粗略) 疾病的 localization，但是性能有限因缺少 bounding box 监督。我们因此提出了 anatomy-driven pathology detection (ADPD)，它使用容易标注的 anatomical region bounding box 作为疾病的代理。我们研究了两种训练方法：以 anatomy-level 疾病标签进行supervised 训练和多个实例学习 (MIL) 使用 image-level 疾病标签。我们的结果表明，我们的 anatomy-level 训练方法高于弱型方法和有限训练样本的完全监督检测，而我们的 MIL 方法与两种基线方法竞争，因此证明了我们的方法的潜在性。
</details></li>
</ul>
<hr>
<h2 id="Emphysema-Subtyping-on-Thoracic-Computed-Tomography-Scans-using-Deep-Neural-Networks"><a href="#Emphysema-Subtyping-on-Thoracic-Computed-Tomography-Scans-using-Deep-Neural-Networks" class="headerlink" title="Emphysema Subtyping on Thoracic Computed Tomography Scans using Deep Neural Networks"></a>Emphysema Subtyping on Thoracic Computed Tomography Scans using Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02576">http://arxiv.org/abs/2309.02576</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/diagnijmegen/bodyct-dram-emph-subtype">https://github.com/diagnijmegen/bodyct-dram-emph-subtype</a></li>
<li>paper_authors: Weiyi Xie, Colin Jacobs, Jean-Paul Charbonnier, Dirk Jan Slebos, Bram van Ginneken<br>for: 这份研究目的是为了自动识别emphysema的亚型和严重程度，以便更好地管理COPD疾病和研究疾病多样性。methods: 这种方法使用了深度学习的方法来自动应用Fleischner Society的视觉分分数系统来分类emphysema的亚型和严重程度。results: 这种方法可以在9650名COPD病人中取得52%的预测精度，比之前发表的方法的45%预测精度高。此外，这种方法可以生成高分辨率的地方化活化图，可以visualizing the network predictions，同时可以计算每个肺部中emphysema的涉及率。此外，这种方法还可以超过中心lobular emphysema的预测能力，可以包括paraseptal emphysema的亚型。<details>
<summary>Abstract</summary>
Accurate identification of emphysema subtypes and severity is crucial for effective management of COPD and the study of disease heterogeneity. Manual analysis of emphysema subtypes and severity is laborious and subjective. To address this challenge, we present a deep learning-based approach for automating the Fleischner Society's visual score system for emphysema subtyping and severity analysis. We trained and evaluated our algorithm using 9650 subjects from the COPDGene study. Our algorithm achieved the predictive accuracy at 52\%, outperforming a previously published method's accuracy of 45\%. In addition, the agreement between the predicted scores of our method and the visual scores was good, where the previous method obtained only moderate agreement. Our approach employs a regression training strategy to generate categorical labels while simultaneously producing high-resolution localized activation maps for visualizing the network predictions. By leveraging these dense activation maps, our method possesses the capability to compute the percentage of emphysema involvement per lung in addition to categorical severity scores. Furthermore, the proposed method extends its predictive capabilities beyond centrilobular emphysema to include paraseptal emphysema subtypes.
</details>
<details>
<summary>摘要</summary>
正确地识别肺血液性病变的亚型和严重程度是肺部疾病管理和疾病多样性研究中的重要课题。手动分类肺血液性病变的亚型和严重程度是劳动ious和主观的。为解决这个挑战，我们提出了一个基于深度学习的方法，用于自动化肺血液性病变的Fleischner社会可视分数系统。我们在9650名COPD病人中训练和评估了我们的算法，其预测精度为52%，比前一方法的精度高出17个百分点。此外，我们的方法可以生成高分辨率的局部活化地图，用于视觉化网络预测结果，并且可以计算每个肺部中肺血液性病变的百分比参数。此外，我们的方法可以进一步扩展预测的能力，以包括肺部分 septal emphysema 亚型。
</details></li>
</ul>
<hr>
<h2 id="Evaluation-Kidney-Layer-Segmentation-on-Whole-Slide-Imaging-using-Convolutional-Neural-Networks-and-Transformers"><a href="#Evaluation-Kidney-Layer-Segmentation-on-Whole-Slide-Imaging-using-Convolutional-Neural-Networks-and-Transformers" class="headerlink" title="Evaluation Kidney Layer Segmentation on Whole Slide Imaging using Convolutional Neural Networks and Transformers"></a>Evaluation Kidney Layer Segmentation on Whole Slide Imaging using Convolutional Neural Networks and Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02563">http://arxiv.org/abs/2309.02563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhao Liu, Chenyang Qi, Shunxing Bao, Quan Liu, Ruining Deng, Yu Wang, Shilin Zhao, Haichun Yang, Yuankai Huo</li>
<li>for: automated image analysis in renal pathology</li>
<li>methods: deep learning-based approaches (CNN and Transformer segmentation)</li>
<li>results: Transformer models generally outperform CNN-based models, with a decent Mean Intersection over Union (mIoU) index and the ability to enable quantitative evaluation of renal cortical structures.Here’s the full text in Simplified Chinese:</li>
<li>for: 这些深度学习方法的应用在肾脏病理学中的自动图像分析中发挥了重要的作用。</li>
<li>methods: 这些方法包括深度学习网络（CNN）和转换器分割方法（Transformer segmentation），包括Swin-Unet、医疗转换器、TransUNet、U-Net、PSPNet和DeepLabv3+。</li>
<li>results: 我们的方法的实验结果表明，转换器模型通常比CNN模型性能更高，并且可以提供肾脏层结构的量化评估。<details>
<summary>Abstract</summary>
The segmentation of kidney layer structures, including cortex, outer stripe, inner stripe, and inner medulla within human kidney whole slide images (WSI) plays an essential role in automated image analysis in renal pathology. However, the current manual segmentation process proves labor-intensive and infeasible for handling the extensive digital pathology images encountered at a large scale. In response, the realm of digital renal pathology has seen the emergence of deep learning-based methodologies. However, very few, if any, deep learning based approaches have been applied to kidney layer structure segmentation. Addressing this gap, this paper assesses the feasibility of performing deep learning based approaches on kidney layer structure segmetnation. This study employs the representative convolutional neural network (CNN) and Transformer segmentation approaches, including Swin-Unet, Medical-Transformer, TransUNet, U-Net, PSPNet, and DeepLabv3+. We quantitatively evaluated six prevalent deep learning models on renal cortex layer segmentation using mice kidney WSIs. The empirical results stemming from our approach exhibit compelling advancements, as evidenced by a decent Mean Intersection over Union (mIoU) index. The results demonstrate that Transformer models generally outperform CNN-based models. By enabling a quantitative evaluation of renal cortical structures, deep learning approaches are promising to empower these medical professionals to make more informed kidney layer segmentation.
</details>
<details>
<summary>摘要</summary>
人类脏器Layer结构分割在人类脏器整片图像（WSI）中扮演了重要的作用，包括肾脏层、外带层、内带层和内脏层。然而，现有的手动分割过程具有劳动密集和不可靠的缺点，不适合处理大规模的数字 PATHOLOGY 图像。面对这个问题，数字肾脏 PATHOLOGY 领域已经出现了深度学习基本的方法。然而，很少有任何深度学习基本的方法应用于肾脏层结构分割。为了解决这个漏洞，本文评估了深度学习基本的方法在肾脏层结构分割中的可能性。本研究采用了代表性的卷积神经网络（CNN）和Transformer分割方法，包括Swin-Unet、医疗Transformer、TransUNet、U-Net、PSPNet和DeepLabv3+。我们对六种流行的深度学习模型进行了数据的评估，并对mouse肾脏WSIs进行了量化评估。结果表明，Transformer模型在肾脏层分割中通常表现出色，并且对比于CNN基本模型具有更高的性能。这些结果表明，通过使用深度学习方法，医生和医疗工程师可以更加准确地分割肾脏层，从而提高诊断和治疗的效果。
</details></li>
</ul>
<hr>
<h2 id="Domain-Adaptation-for-Efficiently-Fine-tuning-Vision-Transformer-with-Encrypted-Images"><a href="#Domain-Adaptation-for-Efficiently-Fine-tuning-Vision-Transformer-with-Encrypted-Images" class="headerlink" title="Domain Adaptation for Efficiently Fine-tuning Vision Transformer with Encrypted Images"></a>Domain Adaptation for Efficiently Fine-tuning Vision Transformer with Encrypted Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02556">http://arxiv.org/abs/2309.02556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teru Nagamori, Sayaka Shiota, Hitoshi Kiya</li>
<li>for: 这个论文应用于 privacy-preserving learning、access control 和 adversarial defenses 等应用。</li>
<li>methods: 本文提出一种基于 vision transformer（ViT）的域 adapted 方法，不会对模型的精度造成衰退。</li>
<li>results: 在实验中，我们确认了提案的方法可以防止精度衰退，即使使用加密的图像，使用 CIFAR-10 和 CIFAR-100 数据集。<details>
<summary>Abstract</summary>
In recent years, deep neural networks (DNNs) trained with transformed data have been applied to various applications such as privacy-preserving learning, access control, and adversarial defenses. However, the use of transformed data decreases the performance of models. Accordingly, in this paper, we propose a novel method for fine-tuning models with transformed images under the use of the vision transformer (ViT). The proposed domain adaptation method does not cause the accuracy degradation of models, and it is carried out on the basis of the embedding structure of ViT. In experiments, we confirmed that the proposed method prevents accuracy degradation even when using encrypted images with the CIFAR-10 and CIFAR-100 datasets.
</details>
<details>
<summary>摘要</summary>
Recently, deep neural networks (DNNs) trained with transformed data have been applied to various applications such as privacy-preserving learning, access control, and adversarial defenses. However, the use of transformed data decreases the performance of models. Therefore, in this paper, we propose a novel method for fine-tuning models with transformed images based on the vision transformer (ViT). Our proposed domain adaptation method does not degrade the accuracy of models and is based on the embedding structure of ViT. In experiments, we confirmed that the proposed method maintains accuracy even when using encrypted images with the CIFAR-10 and CIFAR-100 datasets.Note: The translation is in Simplified Chinese, which is one of the two standardized Chinese writing systems. The other is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-the-Impact-of-Self-Supervised-Pretraining-for-Diagnostic-Tasks-with-Radiological-Images"><a href="#A-Survey-of-the-Impact-of-Self-Supervised-Pretraining-for-Diagnostic-Tasks-with-Radiological-Images" class="headerlink" title="A Survey of the Impact of Self-Supervised Pretraining for Diagnostic Tasks with Radiological Images"></a>A Survey of the Impact of Self-Supervised Pretraining for Diagnostic Tasks with Radiological Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02555">http://arxiv.org/abs/2309.02555</a></li>
<li>repo_url: None</li>
<li>paper_authors: Blake VanBerlo, Jesse Hoey, Alexander Wong</li>
<li>for: 这个论文旨在探讨自动预训练在医学影像识别和分割任务中的效果，并比较自动预训练和完全监督学习的性能。</li>
<li>methods: 这些研究使用了不同的自动预训练方法，包括contrastive learning、self-supervised learning、semi-supervised learning等。</li>
<li>results: 研究发现，自动预训练通常能够提高下游任务性能，特别是当无标例大量多于标例时。此外，自动预训练还能够减少数据量和计算成本。<details>
<summary>Abstract</summary>
Self-supervised pretraining has been observed to be effective at improving feature representations for transfer learning, leveraging large amounts of unlabelled data. This review summarizes recent research into its usage in X-ray, computed tomography, magnetic resonance, and ultrasound imaging, concentrating on studies that compare self-supervised pretraining to fully supervised learning for diagnostic tasks such as classification and segmentation. The most pertinent finding is that self-supervised pretraining generally improves downstream task performance compared to full supervision, most prominently when unlabelled examples greatly outnumber labelled examples. Based on the aggregate evidence, recommendations are provided for practitioners considering using self-supervised learning. Motivated by limitations identified in current research, directions and practices for future study are suggested, such as integrating clinical knowledge with theoretically justified self-supervised learning methods, evaluating on public datasets, growing the modest body of evidence for ultrasound, and characterizing the impact of self-supervised pretraining on generalization.
</details>
<details>
<summary>摘要</summary>
自我超视教学在提高特征表示方面的效果已经被观察到，通过利用大量未标注数据进行学习。本文总结了最近关于这一点的研究，专注于对比自我超视学习和完全超视学习在靶体表示分类和分割任务中的表现。研究发现，自我超视学习通常会提高下游任务性能，尤其是当未标注示例大大超过标注示例时。根据总体证据，提供了实践者考虑使用自我超视学习的建议。受到现有研究的限制所启发，未来研究的方向和实践被建议，如结合临床知识与理论上正确的自我超视学习方法，评估在公共数据集上，扩大有限的证据库，以及Characterizing自我超视预训练对泛化的影响。
</details></li>
</ul>
<hr>
<h2 id="A-skeletonization-algorithm-for-gradient-based-optimization"><a href="#A-skeletonization-algorithm-for-gradient-based-optimization" class="headerlink" title="A skeletonization algorithm for gradient-based optimization"></a>A skeletonization algorithm for gradient-based optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02527">http://arxiv.org/abs/2309.02527</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/martinmenten/skeletonization-for-gradient-based-optimization">https://github.com/martinmenten/skeletonization-for-gradient-based-optimization</a></li>
<li>paper_authors: Martin J. Menten, Johannes C. Paetzold, Veronika A. Zimmer, Suprosanna Shit, Ivan Ezhov, Robbie Holland, Monika Probst, Julia A. Schnabel, Daniel Rueckert</li>
<li>for: This paper aims to propose a three-dimensional skeletonization algorithm that is compatible with gradient-based optimization and preserves the object’s topology.</li>
<li>methods: The proposed method is based on matrix additions and multiplications, convolutional operations, basic non-linear functions, and sampling from a uniform probability distribution, which makes it easy to implement in any major deep learning library.</li>
<li>results: The authors demonstrate the advantages of their skeletonization algorithm compared to non-differentiable, morphological, and neural-network-based baselines through benchmarking experiments. They also integrate the algorithm with two medical image processing applications that use gradient-based optimization, including deep-learning-based blood vessel segmentation and multimodal registration of the mandible in computed tomography and magnetic resonance images.<details>
<summary>Abstract</summary>
The skeleton of a digital image is a compact representation of its topology, geometry, and scale. It has utility in many computer vision applications, such as image description, segmentation, and registration. However, skeletonization has only seen limited use in contemporary deep learning solutions. Most existing skeletonization algorithms are not differentiable, making it impossible to integrate them with gradient-based optimization. Compatible algorithms based on morphological operations and neural networks have been proposed, but their results often deviate from the geometry and topology of the true medial axis. This work introduces the first three-dimensional skeletonization algorithm that is both compatible with gradient-based optimization and preserves an object's topology. Our method is exclusively based on matrix additions and multiplications, convolutional operations, basic non-linear functions, and sampling from a uniform probability distribution, allowing it to be easily implemented in any major deep learning library. In benchmarking experiments, we prove the advantages of our skeletonization algorithm compared to non-differentiable, morphological, and neural-network-based baselines. Finally, we demonstrate the utility of our algorithm by integrating it with two medical image processing applications that use gradient-based optimization: deep-learning-based blood vessel segmentation, and multimodal registration of the mandible in computed tomography and magnetic resonance images.
</details>
<details>
<summary>摘要</summary>
“骨架”是一个数位影像的简洁表示，包括其顺序结构、几何和比例。它在计算机视觉应用中具有广泛的用途，如影像描述、分割和注册。然而，骨架化仅在当今的深度学习解决方案中具有有限的应用。大多数现有的骨架化算法不可微分，使得它们与梯度基本的优化不能集成。此外，基于 morphological 操作和神经网络的兼容算法也已经提出，但它们的结果通常与真实的中间轴几何和顺序结构存在差异。本文提出了第一个可微分的三维骨架化算法，可以保持物体的顺序结构和几何。我们的方法基于矩阵添加和乘法、卷积操作、基本非线性函数和随机抽样，可以轻松地在任何主流深度学习库中实现。在 benchmarking 实验中，我们证明了我们的骨架化算法与非可微分、 morphological 和神经网络基础的参考模型相比有益。最后，我们通过将我们的算法与两个医学影像处理应用程序集成，即深度学习基于血管分割和多Modal 融合注册，证明了我们的算法的实用性。
</details></li>
</ul>
<hr>
<h2 id="GO-SLAM-Global-Optimization-for-Consistent-3D-Instant-Reconstruction"><a href="#GO-SLAM-Global-Optimization-for-Consistent-3D-Instant-Reconstruction" class="headerlink" title="GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction"></a>GO-SLAM: Global Optimization for Consistent 3D Instant Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02436">http://arxiv.org/abs/2309.02436</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/youmi-zym/go-slam">https://github.com/youmi-zym/go-slam</a></li>
<li>paper_authors: Youmin Zhang, Fabio Tosi, Stefano Mattoccia, Matteo Poggi</li>
<li>for: 这篇论文主要用于提出一种基于深度学习的高精度视觉SLAM框架，以实时globally optimize pose estimation和3D reconstruction。</li>
<li>methods: 该框架使用深度学习来实现 pose estimation，并且通过高效的循环关闭和在线全束调整来优化每帧的位姿估计。同时，它在运行时对 implicit和连续表示进行了修正，以确保全局一致性。</li>
<li>results: 对于多种 sintetic和实际 dataset，GO-SLAM 能够在tracking robustness和3D reconstruction accuracy方面超越现有方法。此外，GO-SLAM 可以与 monocular、stereo 和 RGB-D输入一起运行。<details>
<summary>Abstract</summary>
Neural implicit representations have recently demonstrated compelling results on dense Simultaneous Localization And Mapping (SLAM) but suffer from the accumulation of errors in camera tracking and distortion in the reconstruction. Purposely, we present GO-SLAM, a deep-learning-based dense visual SLAM framework globally optimizing poses and 3D reconstruction in real-time. Robust pose estimation is at its core, supported by efficient loop closing and online full bundle adjustment, which optimize per frame by utilizing the learned global geometry of the complete history of input frames. Simultaneously, we update the implicit and continuous surface representation on-the-fly to ensure global consistency of 3D reconstruction. Results on various synthetic and real-world datasets demonstrate that GO-SLAM outperforms state-of-the-art approaches at tracking robustness and reconstruction accuracy. Furthermore, GO-SLAM is versatile and can run with monocular, stereo, and RGB-D input.
</details>
<details>
<summary>摘要</summary>
neural implicit representations 在最近的 dense Simultaneous Localization And Mapping (SLAM) 中表现出了吸引人的结果，但是它们受到相机跟踪的积累错误和重建的扭曲影响。为了解决这些问题，我们提出了 GO-SLAM，一种基于深度学习的 dense visual SLAM 框架，在实时中全球优化姿态和3D重建。姿态估计是其核心，得益于高效的循环关闭和在线全束补做，每帧都可以利用学习的全局几何结构来优化。同时，我们在实时更新了几何和连续表示，以确保3D重建的全球一致性。实验结果表明，GO-SLAM 在跟踪稳定性和重建精度方面超越了当前的方法。此外，GO-SLAM 可以与单目、双目和 RGB-D 输入运行。
</details></li>
</ul>
<hr>
<h2 id="ReliTalk-Relightable-Talking-Portrait-Generation-from-a-Single-Video"><a href="#ReliTalk-Relightable-Talking-Portrait-Generation-from-a-Single-Video" class="headerlink" title="ReliTalk: Relightable Talking Portrait Generation from a Single Video"></a>ReliTalk: Relightable Talking Portrait Generation from a Single Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02434">http://arxiv.org/abs/2309.02434</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arthur-qiu/ReliTalk">https://github.com/arthur-qiu/ReliTalk</a></li>
<li>paper_authors: Haonan Qiu, Zhaoxi Chen, Yuming Jiang, Hang Zhou, Xiangyu Fan, Lei Yang, Wayne Wu, Ziwei Liu</li>
<li>for: 生成带有声音的人物肖像图像从单视视频中</li>
<li>methods: 提出了一种基于音频特征的人脸 нормаль学习方法，并使用这些 нормаль来进行反射环境的分解</li>
<li>results: 在实验中证明了该方法的超越性，能够在单视视频中生成高质量的带有声音的人物肖像图像，并且可以适应不同的背景和照明条件<details>
<summary>Abstract</summary>
Recent years have witnessed great progress in creating vivid audio-driven portraits from monocular videos. However, how to seamlessly adapt the created video avatars to other scenarios with different backgrounds and lighting conditions remains unsolved. On the other hand, existing relighting studies mostly rely on dynamically lighted or multi-view data, which are too expensive for creating video portraits. To bridge this gap, we propose ReliTalk, a novel framework for relightable audio-driven talking portrait generation from monocular videos. Our key insight is to decompose the portrait's reflectance from implicitly learned audio-driven facial normals and images. Specifically, we involve 3D facial priors derived from audio features to predict delicate normal maps through implicit functions. These initially predicted normals then take a crucial part in reflectance decomposition by dynamically estimating the lighting condition of the given video. Moreover, the stereoscopic face representation is refined using the identity-consistent loss under simulated multiple lighting conditions, addressing the ill-posed problem caused by limited views available from a single monocular video. Extensive experiments validate the superiority of our proposed framework on both real and synthetic datasets. Our code is released in https://github.com/arthur-qiu/ReliTalk.
</details>
<details>
<summary>摘要</summary>
Our key insight is to decompose the portrait's reflectance from implicitly learned audio-driven facial normals and images. Specifically, we use 3D facial priors derived from audio features to predict delicate normal maps through implicit functions. These initially predicted normals then play a crucial role in reflectance decomposition by dynamically estimating the lighting condition of the given video. Additionally, we refine the stereoscopic face representation using the identity-consistent loss under simulated multiple lighting conditions, addressing the ill-posed problem caused by limited views available from a single monocular video.Extensive experiments demonstrate the superiority of our proposed framework on both real and synthetic datasets. Our code is available at https://github.com/arthur-qiu/ReliTalk.
</details></li>
</ul>
<hr>
<h2 id="EgoPCA-A-New-Framework-for-Egocentric-Hand-Object-Interaction-Understanding"><a href="#EgoPCA-A-New-Framework-for-Egocentric-Hand-Object-Interaction-Understanding" class="headerlink" title="EgoPCA: A New Framework for Egocentric Hand-Object Interaction Understanding"></a>EgoPCA: A New Framework for Egocentric Hand-Object Interaction Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02423">http://arxiv.org/abs/2309.02423</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Xu, Yong-Lu Li, Zhemin Huang, Michael Xu Liu, Cewu Lu, Yu-Wing Tai, Chi-Keung Tang</li>
<li>for: 本研究是为了提高 Egocentric Hand-Object Interaction (Ego-HOI) 识别的性能，并解决现有研究基于第三人称视频动作识别的域外差问题。</li>
<li>methods: 本研究提出了一个新的框架，称为 Probing, Curation and Adaption (EgoPCA)，用于适应 Ego-HOI 识别。该框架包括了全面的预训练集、平衡测试集以及一个新的基线。</li>
<li>results: 根据本研究的结果，新的 EgoPCA 框架可以在 Ego-HOI 标准测试集上达到状态之最的性能。此外，本研究还提出了一些新的机制和设置，以进一步推动 Ego-HOI 研究的发展。<details>
<summary>Abstract</summary>
With the surge in attention to Egocentric Hand-Object Interaction (Ego-HOI), large-scale datasets such as Ego4D and EPIC-KITCHENS have been proposed. However, most current research is built on resources derived from third-person video action recognition. This inherent domain gap between first- and third-person action videos, which have not been adequately addressed before, makes current Ego-HOI suboptimal. This paper rethinks and proposes a new framework as an infrastructure to advance Ego-HOI recognition by Probing, Curation and Adaption (EgoPCA). We contribute comprehensive pre-train sets, balanced test sets and a new baseline, which are complete with a training-finetuning strategy. With our new framework, we not only achieve state-of-the-art performance on Ego-HOI benchmarks but also build several new and effective mechanisms and settings to advance further research. We believe our data and the findings will pave a new way for Ego-HOI understanding. Code and data are available at https://mvig-rhos.com/ego_pca
</details>
<details>
<summary>摘要</summary>
traditional Chinese:随着 Egocentric Hand-Object Interaction (Ego-HOI) 的注意度增加，大规模的数据集如 Ego4D 和 EPIC-KITCHENS 已经被提议。然而，现今大多数研究都基于第三人称视频动作识别资源，这种内在的领域差异使当前的 Ego-HOI 产生较差的性能。这篇论文重新思考并提出了一个新的框架，以提高 Ego-HOI 识别的基础设施，称为 EgoPCA。我们提供了完整的预训练集、平衡测试集和新的基线，并提供了一种训练-微调策略。我们不仅实现了 Ego-HOI 标准 benchmarcks 上的状态最佳性能，还构建了一些新有效的机制和设置，以推进更进一步的研究。我们认为我们的数据和发现将为 Ego-HOI 的理解开拓新的道路。代码和数据可以在 <https://mvig-rhos.com/ego_pca> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Doppelgangers-Learning-to-Disambiguate-Images-of-Similar-Structures"><a href="#Doppelgangers-Learning-to-Disambiguate-Images-of-Similar-Structures" class="headerlink" title="Doppelgangers: Learning to Disambiguate Images of Similar Structures"></a>Doppelgangers: Learning to Disambiguate Images of Similar Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02420">http://arxiv.org/abs/2309.02420</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RuojinCai/Doppelgangers">https://github.com/RuojinCai/Doppelgangers</a></li>
<li>paper_authors: Ruojin Cai, Joseph Tung, Qianqian Wang, Hadar Averbuch-Elor, Bharath Hariharan, Noah Snavely</li>
<li>for: 本文针对的是解决视觉歧义问题，即判断两个visually相似的图像是否描绘同一个3D表面（例如同一个或对称的建筑物的不同面）。</li>
<li>methods: 我们提出了一种基于学习的方法，将这个问题转化为图像对的二分类问题。我们还提出了一种新的数据集Doppelgangers，包含visually相似的图像对，并设计了一种网络结构，使用local keypoints和匹配的空间分布来输入，以更好地利用本地和全局cue。</li>
<li>results: 我们的方法可以在困难的情况下分辨出illusory匹配，并可以与SfM管道集成，以生成正确、不同歧义的3D重建结果。参考我们项目页面（<a target="_blank" rel="noopener" href="http://doppelgangers-3d.github.io)可以获得我们的代码、数据集和更多结果./">http://doppelgangers-3d.github.io）可以获得我们的代码、数据集和更多结果。</a><details>
<summary>Abstract</summary>
We consider the visual disambiguation task of determining whether a pair of visually similar images depict the same or distinct 3D surfaces (e.g., the same or opposite sides of a symmetric building). Illusory image matches, where two images observe distinct but visually similar 3D surfaces, can be challenging for humans to differentiate, and can also lead 3D reconstruction algorithms to produce erroneous results. We propose a learning-based approach to visual disambiguation, formulating it as a binary classification task on image pairs. To that end, we introduce a new dataset for this problem, Doppelgangers, which includes image pairs of similar structures with ground truth labels. We also design a network architecture that takes the spatial distribution of local keypoints and matches as input, allowing for better reasoning about both local and global cues. Our evaluation shows that our method can distinguish illusory matches in difficult cases, and can be integrated into SfM pipelines to produce correct, disambiguated 3D reconstructions. See our project page for our code, datasets, and more results: http://doppelgangers-3d.github.io/.
</details>
<details>
<summary>摘要</summary>
我们考虑了视觉异常分辨任务，即确定两个视觉相似图像是否描述同一个或不同的3D表面（例如，同一面或对面的对称建筑物）。假设图像的假寻常匹配，其中两个图像可能描述不同的3D表面，但视觉上看起来很相似。这种情况可能会使人类困难于分辨，同时也可能导致3D重建算法生成错误的结果。我们提出了一种学习基于的方法来解决这个问题，将其 форulate为图像对的二分类任务。为此，我们开发了一个新的数据集，即Doppelgangers，其包括了类似结构的图像对，以及真实的标签。我们还设计了一种网络架构，该架构可以接受图像对的空间分布的本地关键点和匹配的输入，以便更好地理解本地和全局cue。我们的评估结果表明，我们的方法可以在困难的情况下分辨假寻常匹配，并可以与SfM管道集成，以生成正确、异常分辨的3D重建结果。请参考我们的项目页面获取我们的代码、数据集和更多结果：http://doppelgangers-3d.github.io/.
</details></li>
</ul>
<hr>
<h2 id="Generating-Realistic-Images-from-In-the-wild-Sounds"><a href="#Generating-Realistic-Images-from-In-the-wild-Sounds" class="headerlink" title="Generating Realistic Images from In-the-wild Sounds"></a>Generating Realistic Images from In-the-wild Sounds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02405">http://arxiv.org/abs/2309.02405</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/etilelab/Generating-Realistic-Images-from-In-the-wild-Sounds">https://github.com/etilelab/Generating-Realistic-Images-from-In-the-wild-Sounds</a></li>
<li>paper_authors: Taegyeong Lee, Jeonghun Kang, Hyeonyu Kim, Taehwan Kim</li>
<li>for: 本研究旨在生成野生声音中的图像，因为现有的数据集缺乏声音和图像的对应对。</li>
<li>methods: 本研究使用了音频描述、音频注意力和句子注意力来表达声音的 richttraits，并使用了 CLIPscore 和 AudioCLIP 进行直接声音优化， finally 使用了扩散模型生成图像。</li>
<li>results: 实验结果显示，本模型能够生成高质量的图像从野生声音中，并在野外音频数据集上超越基elines 的 both 量化和质量评估。<details>
<summary>Abstract</summary>
Representing wild sounds as images is an important but challenging task due to the lack of paired datasets between sound and images and the significant differences in the characteristics of these two modalities. Previous studies have focused on generating images from sound in limited categories or music. In this paper, we propose a novel approach to generate images from in-the-wild sounds. First, we convert sound into text using audio captioning. Second, we propose audio attention and sentence attention to represent the rich characteristics of sound and visualize the sound. Lastly, we propose a direct sound optimization with CLIPscore and AudioCLIP and generate images with a diffusion-based model. In experiments, it shows that our model is able to generate high quality images from wild sounds and outperforms baselines in both quantitative and qualitative evaluations on wild audio datasets.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将野声表示为图像是一项重要但具有挑战性的任务，主要因为声音和图像之间没有匹配的数据集和这两种模式之间存在重要的差异。先前的研究主要集中在限定的类别或音乐中生成图像。在这篇论文中，我们提出一种生成声音中的图像的新方法。首先，我们将声音转换为文本使用音频描述。其次，我们提出了听音注意力和句子注意力来表示声音的丰富特征和视觉化声音。最后，我们提出了直接声音优化CLIPscore和AudioCLIP，并使用扩散模型生成图像。在实验中，我们发现我们的模型能够生成高质量的图像从野声，并在野声数据集上超过基线在量和质量评估中表现出色。Note: Please note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Voice-Morphing-Two-Identities-in-One-Voice"><a href="#Voice-Morphing-Two-Identities-in-One-Voice" class="headerlink" title="Voice Morphing: Two Identities in One Voice"></a>Voice Morphing: Two Identities in One Voice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02404">http://arxiv.org/abs/2309.02404</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rprokap/pset-9">https://github.com/rprokap/pset-9</a></li>
<li>paper_authors: Sushanta K. Pani, Anurag Chowdhury, Morgan Sandler, Arun Ross</li>
<li>for: 本研究探讨了一种基于语音特征的 morph 攻击，即 Voice Identity Morphing (VIM)，可以Synthesize speech samples that impersonate the voice characteristics of a pair of individuals。</li>
<li>methods: 研究人员使用了 ECAPA-TDNN 和 x-vector 两种常见的 speaker recognition system，并通过对 Librispeech 数据集进行实验，发现这两种系统都具有高达80%的成功率，但同时也存在1%的假阳性率。</li>
<li>results: 研究人员通过实验发现，使用 VIM 可以在 speaker recognition 系统中实现高达80%的成功率，但同时也存在1%的假阳性率。<details>
<summary>Abstract</summary>
In a biometric system, each biometric sample or template is typically associated with a single identity. However, recent research has demonstrated the possibility of generating "morph" biometric samples that can successfully match more than a single identity. Morph attacks are now recognized as a potential security threat to biometric systems. However, most morph attacks have been studied on biometric modalities operating in the image domain, such as face, fingerprint, and iris. In this preliminary work, we introduce Voice Identity Morphing (VIM) - a voice-based morph attack that can synthesize speech samples that impersonate the voice characteristics of a pair of individuals. Our experiments evaluate the vulnerabilities of two popular speaker recognition systems, ECAPA-TDNN and x-vector, to VIM, with a success rate (MMPMR) of over 80% at a false match rate of 1% on the Librispeech dataset.
</details>
<details>
<summary>摘要</summary>
在生物特征识别系统中，每个生物特征样本或模板通常与单一身份相关。然而，最近的研究已经证明可以生成"变形"生物特征样本，可以成功匹配多个身份。这种"变形攻击"被视为生物特征识别系统的安全威胁。然而，大多数变形攻击都在生物特征模式 operating in the image domain, such as face, fingerprint, and iris 中进行研究。在这项初步工作中，我们引入了语音特征变形（VIM） - 一种基于语音的变形攻击，可以生成具有两个人之间语音特征的演示样本。我们的实验发现，使用 ECAPA-TDNN 和 x-vector 两种流行的 speaker recognition 系统都受到 VIM 攻击的威胁，false match rate 为 1%，在 Librispeech 数据集上达到了80% 的成功率。
</details></li>
</ul>
<hr>
<h2 id="Prototype-based-Dataset-Comparison"><a href="#Prototype-based-Dataset-Comparison" class="headerlink" title="Prototype-based Dataset Comparison"></a>Prototype-based Dataset Comparison</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02401">http://arxiv.org/abs/2309.02401</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nanne/protosim">https://github.com/nanne/protosim</a></li>
<li>paper_authors: Nanne van Noord</li>
<li>for: 这篇论文旨在推广 dataset inspection 的思想，通过对多个 dataset 进行比较，从而超越单个 dataset 中最为显著的视觉概念的限制。</li>
<li>methods: 作者提出了一种基于自动学习的模块，可以在多个 dataset 之间进行比较，从而发现不同 dataset 中的视觉概念。该模块通过不supervised learning来学习概念水平的聚合体，并在两个案例研究中证明了其效果。</li>
<li>results: 作者的研究表明，通过对多个 dataset 进行比较，可以扩展 dataset inspection 的范畴，并且可以发现更多的视觉概念。这些发现可以帮助更多的研究人员在 dataset inspection 中做出更多的发现。<details>
<summary>Abstract</summary>
Dataset summarisation is a fruitful approach to dataset inspection. However, when applied to a single dataset the discovery of visual concepts is restricted to those most prominent. We argue that a comparative approach can expand upon this paradigm to enable richer forms of dataset inspection that go beyond the most prominent concepts. To enable dataset comparison we present a module that learns concept-level prototypes across datasets. We leverage self-supervised learning to discover these prototypes without supervision, and we demonstrate the benefits of our approach in two case-studies. Our findings show that dataset comparison extends dataset inspection and we hope to encourage more works in this direction. Code and usage instructions available at https://github.com/Nanne/ProtoSim
</details>
<details>
<summary>摘要</summary>
dataset 概述是一种有济于数据集检查的方法。然而，当应用于单个数据集时，发现视觉概念的限制只能是最显著的。我们认为 Comparative approach 可以扩展这个 парадиг，以便进行更加丰富的数据集检查，超过最显著的概念。为实现数据集比较，我们提出了一个学习概念级别的原型模块。我们利用无监督学习来发现这些原型，并在两个案例研究中证明了我们的方法的效iveness。我们发现，数据集比较可以扩展数据集检查，并希望更多的研究在这个方向上。 Code 和使用说明可以在 <https://github.com/Nanne/ProtoSim> 获取。
</details></li>
</ul>
<hr>
<h2 id="STEP-–-Towards-Structured-Scene-Text-Spotting"><a href="#STEP-–-Towards-Structured-Scene-Text-Spotting" class="headerlink" title="STEP – Towards Structured Scene-Text Spotting"></a>STEP – Towards Structured Scene-Text Spotting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02356">http://arxiv.org/abs/2309.02356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sergi Garcia-Bordils, Dimosthenis Karatzas, Marçal Rusiñol</li>
<li>for:  scene-text OCR系统的结构化文本检测任务，用于根据用户提供的正则表达式动态控制场景文本检测和识别。</li>
<li>methods: 我们提出了Structured TExt sPotter（STEP）模型，利用提供的文本结构来导航OCR过程。STEP可以处理包含空格的正则表达式，并不受WORD水平精度的限制。</li>
<li>results: 我们的方法可以在各种实际阅读场景中提供准确的零shot结构化文本检测，并且只基于公开available数据进行训练。我们还 introduce了一个新的挑战性测试集，包含多种场景中的Out-of-vocabulary结构化文本，例如价格、日期、序列号、车牌等。我们的方法在所有测试场景中都能提供专业化的OCR性能。<details>
<summary>Abstract</summary>
We introduce the structured scene-text spotting task, which requires a scene-text OCR system to spot text in the wild according to a query regular expression. Contrary to generic scene text OCR, structured scene-text spotting seeks to dynamically condition both scene text detection and recognition on user-provided regular expressions. To tackle this task, we propose the Structured TExt sPotter (STEP), a model that exploits the provided text structure to guide the OCR process. STEP is able to deal with regular expressions that contain spaces and it is not bound to detection at the word-level granularity. Our approach enables accurate zero-shot structured text spotting in a wide variety of real-world reading scenarios and is solely trained on publicly available data. To demonstrate the effectiveness of our approach, we introduce a new challenging test dataset that contains several types of out-of-vocabulary structured text, reflecting important reading applications of fields such as prices, dates, serial numbers, license plates etc. We demonstrate that STEP can provide specialised OCR performance on demand in all tested scenarios.
</details>
<details>
<summary>摘要</summary>
我们介绍了结构化场景文本搜寻任务，这需要一个场景文本OCR系统在用户提供的规律表达中搜寻文本。不同于通用场景文本OCR，结构化场景文本搜寻需要在用户提供的规律下动态地控制场景文本检测和识别。为解决这个任务，我们提出了结构化文本搜寻器（STEP），这个模型利用提供的文本结构来引导OCR процес。STEP能够处理包含空格的规律表达，并不受限制于字词水平的检测。我们的方法可以在实际阅读场景中提供精确的零基eline文本搜寻，并仅从公开available的数据进行训练。为证明我们的方法的有效性，我们引入了一个新的挑战性测试数据集，这个数据集包含了多种出版 vocabulary 的结构化文本，例如价格、日期、序号、车牌号码等。我们展示了 STEP 在所有测试场景中提供特殊化 OCR 性能。
</details></li>
</ul>
<hr>
<h2 id="Generating-Infinite-Resolution-Texture-using-GANs-with-Patch-by-Patch-Paradigm"><a href="#Generating-Infinite-Resolution-Texture-using-GANs-with-Patch-by-Patch-Paradigm" class="headerlink" title="Generating Infinite-Resolution Texture using GANs with Patch-by-Patch Paradigm"></a>Generating Infinite-Resolution Texture using GANs with Patch-by-Patch Paradigm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02340">http://arxiv.org/abs/2309.02340</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai4netzero/infinite_texture_gans">https://github.com/ai4netzero/infinite_texture_gans</a></li>
<li>paper_authors: Alhasan Abdellatif, Ahmed H. Elsheikh</li>
<li>for: 生成无穷限分辨率的纹理图像</li>
<li>methods: 基于patch-by-patch paradigm的GANs方法</li>
<li>results: 比现有方法更加可扩展和灵活，可以生成任意大小的纹理图像，同时保持视觉准确性和多样性。<details>
<summary>Abstract</summary>
In this paper, we introduce a novel approach for generating texture images of infinite resolutions using Generative Adversarial Networks (GANs) based on a patch-by-patch paradigm. Existing texture synthesis techniques often rely on generating a large-scale texture using a one-forward pass to the generating model, this limits the scalability and flexibility of the generated images. In contrast, the proposed approach trains GANs models on a single texture image to generate relatively small patches that are locally correlated and can be seamlessly concatenated to form a larger image while using a constant GPU memory footprint. Our method learns the local texture structure and is able to generate arbitrary-size textures, while also maintaining coherence and diversity. The proposed method relies on local padding in the generator to ensure consistency between patches and utilizes spatial stochastic modulation to allow for local variations and diversity within the large-scale image. Experimental results demonstrate superior scalability compared to existing approaches while maintaining visual coherence of generated textures.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的方法，使用生成抗对抗网络（GANs）来生成无限分辨率的текxture图像，基于一种patch-by-patch的方法。现有的 texture合成技术通常是通过一次forward pass来生成一个大规模的 texture，这限制了生成图像的可扩展性和灵活性。相比之下，我们的方法是在一个单个 texture 图像上训练 GANs 模型，以生成相对较小的 patches，这些 patches 是地方相关的，可以在一定的 GPU 内存占用下进行 concatenation，以生成一个更大的图像。我们的方法学习了地方 texture 结构，能够生成任意大小的 texture，同时保持了视觉准确性和多样性。我们的方法利用了 generator 中的本地补充来确保 patches 之间的一致性，并使用空间随机变化来允许本地变化和多样性在大规模图像中。实验结果表明，我们的方法比现有的方法具有更高的可扩展性，同时保持了生成图像的视觉准确性。
</details></li>
</ul>
<hr>
<h2 id="DEEPBEAS3D-Deep-Learning-and-B-Spline-Explicit-Active-Surfaces"><a href="#DEEPBEAS3D-Deep-Learning-and-B-Spline-Explicit-Active-Surfaces" class="headerlink" title="DEEPBEAS3D: Deep Learning and B-Spline Explicit Active Surfaces"></a>DEEPBEAS3D: Deep Learning and B-Spline Explicit Active Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02335">http://arxiv.org/abs/2309.02335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Helena Williams, João Pedrosa, Muhammad Asad, Laura Cattani, Tom Vercauteren, Jan Deprest, Jan D’hooge</li>
<li>for: 提高 automatic segmentation 方法的robustness，以便直接应用于临床。</li>
<li>methods: 使用 B-spline explicit active surface (BEAS)  Ensures 3D segmentation 是 Smooth 而具有 анатомиче可信度，同时允许用户精确地编辑 3D 表面。</li>
<li>results: 与 clinical 工具 4D View VOCAL 相比，提出的框架具有更低的 NASA-TLX 指数（30% 减少）和用户时间（70% 减少，p&lt;0.00001）。<details>
<summary>Abstract</summary>
Deep learning-based automatic segmentation methods have become state-of-the-art. However, they are often not robust enough for direct clinical application, as domain shifts between training and testing data affect their performance. Failure in automatic segmentation can cause sub-optimal results that require correction. To address these problems, we propose a novel 3D extension of an interactive segmentation framework that represents a segmentation from a convolutional neural network (CNN) as a B-spline explicit active surface (BEAS). BEAS ensures segmentations are smooth in 3D space, increasing anatomical plausibility, while allowing the user to precisely edit the 3D surface. We apply this framework to the task of 3D segmentation of the anal sphincter complex (AS) from transperineal ultrasound (TPUS) images, and compare it to the clinical tool used in the pelvic floor disorder clinic (4D View VOCAL, GE Healthcare; Zipf, Austria). Experimental results show that: 1) the proposed framework gives the user explicit control of the surface contour; 2) the perceived workload calculated via the NASA-TLX index was reduced by 30% compared to VOCAL; and 3) it required 7 0% (170 seconds) less user time than VOCAL (p< 0.00001)
</details>
<details>
<summary>摘要</summary>
深度学习自动分割方法已成为当前状态的惯性。然而，它们常不够鲁棒，对于直接临床应用而言。领域变化导致自动分割失败，从而导致了不优化的结果，需要更正。为解决这些问题，我们提出了一种新的3D扩展的互动分割框架。这个框架将convulsion neural network（CNN）的分割表示为B-spline显式活动表面（BEAS）。BEAS使得分割在3D空间是平滑的，提高了生物学可能性，同时允许用户精确地编辑3D表面。我们在分割Transperineal ultrasound（TPUS）图像中的下部缺陷复合（AS）任务上应用了这个框架，并与临床工具used in the pelvic floor disorder clinic（4D View VOCAL，GE Healthcare，Zipf，Austria）进行比较。实验结果显示：1）提案的框架给用户显式控制表面轮廓; 2）NASA-TLX指数计算的感知工作负荷比VOCAL减少30%；3）与VOCAL相比，用户时间减少70%（p<0.00001）。
</details></li>
</ul>
<hr>
<h2 id="TiAVox-Time-aware-Attenuation-Voxels-for-Sparse-view-4D-DSA-Reconstruction"><a href="#TiAVox-Time-aware-Attenuation-Voxels-for-Sparse-view-4D-DSA-Reconstruction" class="headerlink" title="TiAVox: Time-aware Attenuation Voxels for Sparse-view 4D DSA Reconstruction"></a>TiAVox: Time-aware Attenuation Voxels for Sparse-view 4D DSA Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02318">http://arxiv.org/abs/2309.02318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenghong Zhou, Huangxuan Zhao, Jiemin Fang, Dongqiao Xiang, Lei Chen, Lingxia Wu, Feihong Wu, Wenyu Liu, Chuansheng Zheng, Xinggang Wang<br>for:  This paper aims to propose a novel approach for sparse-view 4D digital subtraction angiography (DSA) reconstruction, which can reduce the radiation dose while maintaining high-quality imaging results.methods:  The proposed approach, called Time-aware Attenuation Voxel (TiAVox), utilizes 4D attenuation voxel grids to model the attenuation properties of both spatial and temporal dimensions. It is optimized by minimizing discrepancies between the rendered images and sparse 2D DSA images, without relying on any neural network.results:  The proposed TiAVox approach achieved a 31.23 Peak Signal-to-Noise Ratio (PSNR) for novel view synthesis using only 30 views on a clinically sourced dataset, outperforming traditional Feldkamp-Davis-Kress methods which required 133 views. Additionally, TiAVox yielded a PSNR of 34.32 for novel view synthesis and 41.40 for 3D reconstruction on a synthetic dataset using merely 10 views.<details>
<summary>Abstract</summary>
Four-dimensional Digital Subtraction Angiography (4D DSA) plays a critical role in the diagnosis of many medical diseases, such as Arteriovenous Malformations (AVM) and Arteriovenous Fistulas (AVF). Despite its significant application value, the reconstruction of 4D DSA demands numerous views to effectively model the intricate vessels and radiocontrast flow, thereby implying a significant radiation dose. To address this high radiation issue, we propose a Time-aware Attenuation Voxel (TiAVox) approach for sparse-view 4D DSA reconstruction, which paves the way for high-quality 4D imaging. Additionally, 2D and 3D DSA imaging results can be generated from the reconstructed 4D DSA images. TiAVox introduces 4D attenuation voxel grids, which reflect attenuation properties from both spatial and temporal dimensions. It is optimized by minimizing discrepancies between the rendered images and sparse 2D DSA images. Without any neural network involved, TiAVox enjoys specific physical interpretability. The parameters of each learnable voxel represent the attenuation coefficients. We validated the TiAVox approach on both clinical and simulated datasets, achieving a 31.23 Peak Signal-to-Noise Ratio (PSNR) for novel view synthesis using only 30 views on the clinically sourced dataset, whereas traditional Feldkamp-Davis-Kress methods required 133 views. Similarly, with merely 10 views from the synthetic dataset, TiAVox yielded a PSNR of 34.32 for novel view synthesis and 41.40 for 3D reconstruction. We also executed ablation studies to corroborate the essential components of TiAVox. The code will be publically available.
</details>
<details>
<summary>摘要</summary>
四维数字抽取成像（4D DSA）在诊断医学疾病方面发挥重要作用，如arteriovenous malformation（AVM）和arteriovenous fistula（AVF）。尽管它具有重要应用价值，但4D DSA重建需要大量视图，以模拟复杂的血管和干扰物流动，从而导致高射线剂量。为解决这个高射线问题，我们提出了基于时间意识的减杂粒子（TiAVox）方法，这种方法可以在缺少视图情况下实现高质量4D成像。此外，2D和3D DSA成像结果也可以从重建的4D DSA图像中生成。TiAVox使用4D减杂粒子网格，该网格反映了空间和时间维度中的减杂特性。它通过最小化与渲染图像之间的差异来优化。不同于使用神经网络的方法，TiAVox具有特定的物理解释性。每个学习粒子的参数表示减杂系数。我们在临床和模拟数据集上验证了TiAVox方法，在使用30个视图时，对于新视图synthesis，TiAVox方法达到了31.23的峰值信号强度比率（PSNR），而传统的Feldkamp-Davis-Kress方法需要133个视图。同样，只使用10个视图从synthetic dataset，TiAVox方法可以达到34.32的PSNR для新视图synthesis和41.40的PSNR для3D重建。我们还进行了ablation研究，以证明TiAVox的关键组件。代码将公开。
</details></li>
</ul>
<hr>
<h2 id="CIEM-Contrastive-Instruction-Evaluation-Method-for-Better-Instruction-Tuning"><a href="#CIEM-Contrastive-Instruction-Evaluation-Method-for-Better-Instruction-Tuning" class="headerlink" title="CIEM: Contrastive Instruction Evaluation Method for Better Instruction Tuning"></a>CIEM: Contrastive Instruction Evaluation Method for Better Instruction Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02301">http://arxiv.org/abs/2309.02301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyu Hu, Jiyuan Zhang, Minyi Zhao, Zhenbang Sun</li>
<li>for: 本研究旨在 Addressing the hallucination phenomenon in Large Vision-Language Models (LVLMs) by introducing a Contrastive Instruction Evaluation Method (CIEM) and a new instruction tuning method called Contrastive Instruction Tuning (CIT).</li>
<li>methods: 本研究使用了一个自动化管道，包括一个注解的图像文本数据集和一个Large Language Model (LLM)，生成了事实&#x2F;对比问题对的评估，以检测LVLMs中的幻觉现象。同时，基于CIEM，我们还提出了一种新的 instruction tuning 方法，即 CIT (Contrastive Instruction Tuning)，以自动生成高质量的事实&#x2F;对比问题对和相应的证明，以适应LVLMs中的幻觉现象。</li>
<li>results: 我们通过广泛的实验表明，CIEM 和 CIT 能够准确检测LVLMs中的幻觉现象，并且CIT-调教VLMs比CIEM和公共数据集更优。<details>
<summary>Abstract</summary>
Nowadays, the research on Large Vision-Language Models (LVLMs) has been significantly promoted thanks to the success of Large Language Models (LLM). Nevertheless, these Vision-Language Models (VLMs) are suffering from the drawback of hallucination -- due to insufficient understanding of vision and language modalities, VLMs may generate incorrect perception information when doing downstream applications, for example, captioning a non-existent entity. To address the hallucination phenomenon, on the one hand, we introduce a Contrastive Instruction Evaluation Method (CIEM), which is an automatic pipeline that leverages an annotated image-text dataset coupled with an LLM to generate factual/contrastive question-answer pairs for the evaluation of the hallucination of VLMs. On the other hand, based on CIEM, we further propose a new instruction tuning method called CIT (the abbreviation of Contrastive Instruction Tuning) to alleviate the hallucination of VLMs by automatically producing high-quality factual/contrastive question-answer pairs and corresponding justifications for model tuning. Through extensive experiments on CIEM and CIT, we pinpoint the hallucination issues commonly present in existing VLMs, the disability of the current instruction-tuning dataset to handle the hallucination phenomenon and the superiority of CIT-tuned VLMs over both CIEM and public datasets.
</details>
<details>
<summary>摘要</summary>
现在，大vision-language模型（LVLM）的研究得到了大语言模型（LLM）的成功，然而这些视力语言模型（VLM）却受到了一个缺点——因为不够理解视觉和语言模式，VLM可能在下游应用中生成错误的感知信息，例如captioning一个不存在的实体。为了解决这种幻觉现象，我们在一个手动管道中引入了一种对比 instruction evaluation方法（CIEM），这种方法利用了一个注解图像文本集和一个LLM来生成factual/对比问题对的评估。此外，基于CIEM，我们进一步提出了一种新的指令调整方法called CIT（对比指令调整），以解决VLM中的幻觉问题。通过广泛的CIEM和CIT实验，我们揭示了现有VLM中的幻觉问题，存在的指令调整数据集不能处理幻觉现象，以及CIT-调整VLM的superiority。
</details></li>
</ul>
<hr>
<h2 id="ATM-Action-Temporality-Modeling-for-Video-Question-Answering"><a href="#ATM-Action-Temporality-Modeling-for-Video-Question-Answering" class="headerlink" title="ATM: Action Temporality Modeling for Video Question Answering"></a>ATM: Action Temporality Modeling for Video Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02290">http://arxiv.org/abs/2309.02290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwen Chen, Jie Zhu, Yu Kong</li>
<li>for: 本研究旨在提高视频问答（VideoQA）中的 causal&#x2F;temporal 理解能力，因为现有方法在面对需要跨帧 temporality 理解的问题时表现不佳。</li>
<li>methods: 本研究提出了 Action Temporality Modeling (ATM) 方法，通过三种特点：（1）重新思考optical flow的表示方式，发现optical flow可以帮助捕捉长期 temporality 理解;（2）通过对视觉和文本模式的嵌入进行对比式学习，从而提高动作表示在视觉和文本模式中的性能;（3）在精度调整阶段避免使用混乱视频，以避免因为出现和运动的杂交关系而导致的假 positives。</li>
<li>results: 实验表明，ATM方法比前一些方法在多个 VideoQA 任务上表现更高的准确率，同时也能够更好地保持true temporality 理解能力。<details>
<summary>Abstract</summary>
Despite significant progress in video question answering (VideoQA), existing methods fall short of questions that require causal/temporal reasoning across frames. This can be attributed to imprecise motion representations. We introduce Action Temporality Modeling (ATM) for temporality reasoning via three-fold uniqueness: (1) rethinking the optical flow and realizing that optical flow is effective in capturing the long horizon temporality reasoning; (2) training the visual-text embedding by contrastive learning in an action-centric manner, leading to better action representations in both vision and text modalities; and (3) preventing the model from answering the question given the shuffled video in the fine-tuning stage, to avoid spurious correlation between appearance and motion and hence ensure faithful temporality reasoning. In the experiments, we show that ATM outperforms previous approaches in terms of the accuracy on multiple VideoQAs and exhibits better true temporality reasoning ability.
</details>
<details>
<summary>摘要</summary>
尽管现有的视频问答（VideoQA）技术已经取得了显著的进步，但现有的方法仍然无法解决需要时间/ causal 逻辑推理的问题。这可以归结于不精准的动作表示。我们提出了动作时间模型（ATM），通过三种独特性来进行时间逻辑推理：1. 重新思考光流，并发现光流能够 Capture 长远时间的时间逻辑推理;2. 通过对视觉和文本的嵌入进行对比学习，从而提高动作的表示在视觉和文本模式之间;3. 在练习阶段，防止模型根据混乱的视频回答问题，以避免因为外观和运动的偶推关系而导致的假设关系。在实验中，我们表明ATM在多个 VideoQA 上的准确率高于先前的方法，并且展现出更好的真实时间逻辑推理能力。
</details></li>
</ul>
<hr>
<h2 id="Haystack-A-Panoptic-Scene-Graph-Dataset-to-Evaluate-Rare-Predicate-Classes"><a href="#Haystack-A-Panoptic-Scene-Graph-Dataset-to-Evaluate-Rare-Predicate-Classes" class="headerlink" title="Haystack: A Panoptic Scene Graph Dataset to Evaluate Rare Predicate Classes"></a>Haystack: A Panoptic Scene Graph Dataset to Evaluate Rare Predicate Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02286">http://arxiv.org/abs/2309.02286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julian Lorenz, Florian Barthel, Daniel Kienzle, Rainer Lienhart</li>
<li>for: 本研究旨在构建一个新的SceneGraph dataset，以提高SceneGraph生成模型的预测性能，特别是对于罕见 predicate class。</li>
<li>methods: 该研究提出了一种模型协助的注释管道，以高效地找到图像中的罕见 predicate class。这种方法不同于现有的SceneGraph dataset，因为它包含Explicit negative annotations。</li>
<li>results: Haystack dataset可以轻松地与现有的SceneGraph dataset集成，并且可以帮助提高SceneGraph生成模型的预测性能，特别是对于罕见 predicate class。<details>
<summary>Abstract</summary>
Current scene graph datasets suffer from strong long-tail distributions of their predicate classes. Due to a very low number of some predicate classes in the test sets, no reliable metrics can be retrieved for the rarest classes. We construct a new panoptic scene graph dataset and a set of metrics that are designed as a benchmark for the predictive performance especially on rare predicate classes. To construct the new dataset, we propose a model-assisted annotation pipeline that efficiently finds rare predicate classes that are hidden in a large set of images like needles in a haystack.   Contrary to prior scene graph datasets, Haystack contains explicit negative annotations, i.e. annotations that a given relation does not have a certain predicate class. Negative annotations are helpful especially in the field of scene graph generation and open up a whole new set of possibilities to improve current scene graph generation models.   Haystack is 100% compatible with existing panoptic scene graph datasets and can easily be integrated with existing evaluation pipelines. Our dataset and code can be found here: https://lorjul.github.io/haystack/. It includes annotation files and simple to use scripts and utilities, to help with integrating our dataset in existing work.
</details>
<details>
<summary>摘要</summary>
To construct Haystack, we proposed a model-assisted annotation pipeline that efficiently finds rare predicate classes hidden in large sets of images, similar to finding needles in a haystack. This pipeline allows us to annotate rare predicate classes that were previously difficult or impossible to annotate.Haystack includes negative annotations, which are particularly useful in the field of scene graph generation. These negative annotations open up new possibilities for improving current scene graph generation models. Our dataset and code can be found at https://lorjul.github.io/haystack/, which includes annotation files and simple-to-use scripts and utilities to help integrate our dataset into existing work.
</details></li>
</ul>
<hr>
<h2 id="SAM-Deblur-Let-Segment-Anything-Boost-Image-Deblurring"><a href="#SAM-Deblur-Let-Segment-Anything-Boost-Image-Deblurring" class="headerlink" title="SAM-Deblur: Let Segment Anything Boost Image Deblurring"></a>SAM-Deblur: Let Segment Anything Boost Image Deblurring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02270">http://arxiv.org/abs/2309.02270</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siwei Li, Mingxuan Liu, Yating Zhang, Shu Chen, Haoxiang Li, Hong Chen, Zifei Dou</li>
<li>For: 该 paper 的目的是解决非均匀抖isser（non-uniform blurring）导致的图像恢复问题，使用 Segment Anything Model（SAM）的优先知识来提高恢复模型的通用性。* Methods: 该 paper 提出了一种框架，名为 SAM-Deblur，它将 SAM 的优先知识 integrate 到恢复任务中，并提出了一种面积融合（MAP）单元，用于融合 SAM 生成的分割区域，以提高模型的稳定性和普适性。* Results: 实验结果表明，通过 incorporating 我们的方法，可以提高 NAFNet 的 PSNR 值，具体如下：RealBlurJ 上提高 0.05，ReloBlur 上提高 0.96，REDs 上提高 7.03。<details>
<summary>Abstract</summary>
Image deblurring is a critical task in the field of image restoration, aiming to eliminate blurring artifacts. However, the challenge of addressing non-uniform blurring leads to an ill-posed problem, which limits the generalization performance of existing deblurring models. To solve the problem, we propose a framework SAM-Deblur, integrating prior knowledge from the Segment Anything Model (SAM) into the deblurring task for the first time. In particular, SAM-Deblur is divided into three stages. First, We preprocess the blurred images, obtain image masks via SAM, and propose a mask dropout method for training to enhance model robustness. Then, to fully leverage the structural priors generated by SAM, we propose a Mask Average Pooling (MAP) unit specifically designed to average SAM-generated segmented areas, serving as a plug-and-play component which can be seamlessly integrated into existing deblurring networks. Finally, we feed the fused features generated by the MAP Unit into the deblurring model to obtain a sharp image. Experimental results on the RealBlurJ, ReloBlur, and REDS datasets reveal that incorporating our methods improves NAFNet's PSNR by 0.05, 0.96, and 7.03, respectively. Code will be available at \href{https://github.com/HPLQAQ/SAM-Deblur}{SAM-Deblur}.
</details>
<details>
<summary>摘要</summary>
图像抖涂除是图像修复领域中的关键任务，旨在消除抖涂 artifacts。然而，非均匀抖涂的挑战导致一个不定性问题，限制了现有的抖涂除模型的泛化性能。为解决这问题，我们提出了一个框架SAM-Deblur，将Segment Anything Model（SAM）的先前知识integrated into the deblurring task。具体来说，SAM-Deblur分为三个阶段。首先，我们对抖涂图像进行预处理，通过SAM获得图像掩码，并提出了一种掩码抽样方法来提高模型Robustness。然后，我们提出了一种特殊的Mask Average Pooling（MAP）单元，用于平均SAM生成的分割区域，作为可插入到现有的抖涂除网络中的插件。最后，我们将MAP单元生成的融合特征 fed into the deblurring model，以获得锐化图像。实验结果表明，在RealBlurJ、ReloBlur和REDSDatasets上， incorporating our methods improve NAFNet's PSNR by 0.05, 0.96, and 7.03, respectively。代码将提供在 \href{https://github.com/HPLQAQ/SAM-Deblur}{SAM-Deblur}。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-Chest-X-ray-Datasets-with-Non-Expert-Annotations"><a href="#Augmenting-Chest-X-ray-Datasets-with-Non-Expert-Annotations" class="headerlink" title="Augmenting Chest X-ray Datasets with Non-Expert Annotations"></a>Augmenting Chest X-ray Datasets with Non-Expert Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02244">http://arxiv.org/abs/2309.02244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cathrine Damgaard, Trine Naja Eriksen, Dovile Juodelyte, Veronika Cheplygina, Amelia Jiménez-Sánchez</li>
<li>for: 增加医疗影像分析中的机器学习算法的扩展，需要训练资料集的扩展。</li>
<li>methods: 使用自动标注抽象法从免费医疗报告中提取标注，以减少专家医生的 annotating 成本。</li>
<li>results: 通过将短cuts标注为管道，增加了两个公共可用的胸部X射像数据集的大小。使用非专家标注可以对医疗影像分析进行扩展。<details>
<summary>Abstract</summary>
The advancement of machine learning algorithms in medical image analysis requires the expansion of training datasets. A popular and cost-effective approach is automated annotation extraction from free-text medical reports, primarily due to the high costs associated with expert clinicians annotating chest X-ray images. However, it has been shown that the resulting datasets are susceptible to biases and shortcuts. Another strategy to increase the size of a dataset is crowdsourcing, a widely adopted practice in general computer vision with some success in medical image analysis. In a similar vein to crowdsourcing, we enhance two publicly available chest X-ray datasets by incorporating non-expert annotations. However, instead of using diagnostic labels, we annotate shortcuts in the form of tubes. We collect 3.5k chest drain annotations for CXR14, and 1k annotations for 4 different tube types in PadChest. We train a chest drain detector with the non-expert annotations that generalizes well to expert labels. Moreover, we compare our annotations to those provided by experts and show "moderate" to "almost perfect" agreement. Finally, we present a pathology agreement study to raise awareness about ground truth annotations. We make our annotations and code available.
</details>
<details>
<summary>摘要</summary>
“医学影像分析中的机器学习算法的进步需要训练数据集的扩展。一种受欢迎的和成本效益的方法是自动提取自自由文本医疗报告中的注释，主要是因为专业医生标注胸部X射线图像的成本很高。然而，已经证明了这些数据集具有偏见和短cuts。另一种增加数据集的方法是在大众筹资源，这是通用计算机视觉领域广泛采用的一种做法，在医学影像分析中也有一定的成功。我们在两个公共可用的胸部X射线数据集上进行了改进，并在医生标注中添加了非专业注释。我们收集了3500个胸部排液注释，并在PadChest上收集了4种不同的管道类型的1000个注释。我们使用非专业注释来训练胸部排液检测器，并发现其可以很好地泛化到专业标注。此外，我们比较了我们的注释和专业标注，并发现它们之间存在“中度”到“几乎完美”的一致。最后，我们进行了病理一致性研究，以提醒人们关于真实标注的重要性。我们将我们的注释和代码公开。”
</details></li>
</ul>
<hr>
<h2 id="Robustness-and-Generalizability-of-Deepfake-Detection-A-Study-with-Diffusion-Models"><a href="#Robustness-and-Generalizability-of-Deepfake-Detection-A-Study-with-Diffusion-Models" class="headerlink" title="Robustness and Generalizability of Deepfake Detection: A Study with Diffusion Models"></a>Robustness and Generalizability of Deepfake Detection: A Study with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02218">http://arxiv.org/abs/2309.02218</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/OpenRL-Lab/DeepFakeFace">https://github.com/OpenRL-Lab/DeepFakeFace</a></li>
<li>paper_authors: Haixu Song, Shiyu Huang, Yinpeng Dong, Wei-Wei Tu</li>
<li>for: 本研究旨在帮助推广真实信息，减少深度模仿图像的散布。</li>
<li>methods: 研究采用了高级扩散模型生成虚假名人脸，并将其分享到线上平台上。用于训练和测试深度模仿检测算法的数据集是DFF集。</li>
<li>results: 研究发现，不同的深度模仿方法和图像变化，需要更好的深度模仿检测工具。DFF集和测试方法能够推动开发更有效的深度模仿检测算法。<details>
<summary>Abstract</summary>
The rise of deepfake images, especially of well-known personalities, poses a serious threat to the dissemination of authentic information. To tackle this, we present a thorough investigation into how deepfakes are produced and how they can be identified. The cornerstone of our research is a rich collection of artificial celebrity faces, titled DeepFakeFace (DFF). We crafted the DFF dataset using advanced diffusion models and have shared it with the community through online platforms. This data serves as a robust foundation to train and test algorithms designed to spot deepfakes. We carried out a thorough review of the DFF dataset and suggest two evaluation methods to gauge the strength and adaptability of deepfake recognition tools. The first method tests whether an algorithm trained on one type of fake images can recognize those produced by other methods. The second evaluates the algorithm's performance with imperfect images, like those that are blurry, of low quality, or compressed. Given varied results across deepfake methods and image changes, our findings stress the need for better deepfake detectors. Our DFF dataset and tests aim to boost the development of more effective tools against deepfakes.
</details>
<details>
<summary>摘要</summary>
“深圳技术”的出现，尤其是关于知名人物的深圳图像，对媒体传播Authentic信息提供了严重的威胁。为了解决这个问题，我们提供了一份深入探究深圳图像的生成和识别方法的研究报告。我们的研究的核心是一个名为“DeepFakeFace”（DFF）的人工知名人物脸部集合。我们使用了先进的扩散模型来制作了这个数据集，并通过在线平台分享给社区。这个数据集作为训练和测试深圳识别算法的基础，提供了一个robust的基础。我们对DFF数据集进行了住检查，并提出了两种评价方法来评估深圳识别算法的强度和适应性。第一种测试是用一种基于一种深圳方法训练的算法能否识别其他方法生成的深圳图像。第二种测试是用一种受到干扰、低质量或压缩等变化的图像来测试算法的性能。由于深圳方法和图像变化的多样性，我们的发现表明了深圳识别算法的需要更好。我们的DFF数据集和测试方法旨在推动对深圳图像的更好的识别工具的开发。
</details></li>
</ul>
<hr>
<h2 id="Advanced-Underwater-Image-Restoration-in-Complex-Illumination-Conditions"><a href="#Advanced-Underwater-Image-Restoration-in-Complex-Illumination-Conditions" class="headerlink" title="Advanced Underwater Image Restoration in Complex Illumination Conditions"></a>Advanced Underwater Image Restoration in Complex Illumination Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02217">http://arxiv.org/abs/2309.02217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Song, Mengkun She, Kevin Köser</li>
<li>for: 本研究旨在提高深水下摄影图像的修复效果，特别是在200米深度以下的潜水器拍摄场景， где自然光scarce和人工照明必须。</li>
<li>methods: 本研究使用了新的应earance变化约束，即对象或海底表面的变化，以估算照明场景。通过每个像素对相机视场中的光场的约束，每个voxel都可以保存一个信号因子和反射值，以便高效地修复摄影机-灯光平台上的图像。</li>
<li>results: 实验结果表明，本approach可以准确地修复摄影机-灯光平台上的图像，同时减轻照明和媒体效果的影响。此外，本approach可以轻松扩展到其他场景，如在空中拍摄或其他类似场景。<details>
<summary>Abstract</summary>
Underwater image restoration has been a challenging problem for decades since the advent of underwater photography. Most solutions focus on shallow water scenarios, where the scene is uniformly illuminated by the sunlight. However, the vast majority of uncharted underwater terrain is located beyond 200 meters depth where natural light is scarce and artificial illumination is needed. In such cases, light sources co-moving with the camera, dynamically change the scene appearance, which make shallow water restoration methods inadequate. In particular for multi-light source systems (composed of dozens of LEDs nowadays), calibrating each light is time-consuming, error-prone and tedious, and we observe that only the integrated illumination within the viewing volume of the camera is critical, rather than the individual light sources. The key idea of this paper is therefore to exploit the appearance changes of objects or the seafloor, when traversing the viewing frustum of the camera. Through new constraints assuming Lambertian surfaces, corresponding image pixels constrain the light field in front of the camera, and for each voxel a signal factor and a backscatter value are stored in a volumetric grid that can be used for very efficient image restoration of camera-light platforms, which facilitates consistently texturing large 3D models and maps that would otherwise be dominated by lighting and medium artifacts. To validate the effectiveness of our approach, we conducted extensive experiments on simulated and real-world datasets. The results of these experiments demonstrate the robustness of our approach in restoring the true albedo of objects, while mitigating the influence of lighting and medium effects. Furthermore, we demonstrate our approach can be readily extended to other scenarios, including in-air imaging with artificial illumination or other similar cases.
</details>
<details>
<summary>摘要</summary>
水下图像修复问题已经是数十年来的挑战，自 fotografías submarinas 的出现以来。大多数解决方案都专注于浅水enario， где场景由太阳照明均匀。然而，95%的未探索的水下地形都 locate在200米深度以下，其中自然光照明稀缺，需要人工照明。在这种情况下，相机 Move  along with light sources， dynamically change the scene appearance，使得浅水修复方法无法满足需求。特别是，现今的多光源系统（由多个LED组成），每个光源的准确耗时、容易出错和繁琐，而我们发现，只有相机前方照明的积合照明是关键的，而不是个别的光源。本文的关键想法是利用相机视图卷积中物体或海底的变化，来恢复图像。通过新的约束，对象或海底的镜像变化会帮助确定图像中的照明场景，并为每个 voxel 存储一个信号因子和反射值，可以高效地修复相机灯台上的图像，使得大型 3D 模型和地图可以一致地 текстури化，而不会受到照明和媒体效果的限制。为验证我们的方法的有效性，我们对 simulated 和实际数据进行了广泛的实验。实验结果表明，我们的方法可以准确地恢复物体的真实反射率，同时抑制照明和媒体效果的影响。此外，我们还证明了我们的方法可以轻松扩展到其他场景，包括在空中拍摄的人工照明或类似情况。
</details></li>
</ul>
<hr>
<h2 id="Continual-Cross-Dataset-Adaptation-in-Road-Surface-Classification"><a href="#Continual-Cross-Dataset-Adaptation-in-Road-Surface-Classification" class="headerlink" title="Continual Cross-Dataset Adaptation in Road Surface Classification"></a>Continual Cross-Dataset Adaptation in Road Surface Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02210">http://arxiv.org/abs/2309.02210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paolo Cudrano, Matteo Bellusci, Giuseppe Macino, Matteo Matteucci</li>
<li>for: 这篇论文是为了解决自动驾驶车（AV）的道路表面分类问题，以便优化驾驶环境、提高安全性和实现进阶道路地图。</li>
<li>methods: 这篇论文使用了快速和有效的cross-dataset演化方法，以保持过去的知识并适应新数据，从而避免了忘记现象。</li>
<li>results: 实验结果显示，这种方法比Naive finetuning更有优势，可以实现性能与新 retraining 之间的几乎相同水平。<details>
<summary>Abstract</summary>
Accurate road surface classification is crucial for autonomous vehicles (AVs) to optimize driving conditions, enhance safety, and enable advanced road mapping. However, deep learning models for road surface classification suffer from poor generalization when tested on unseen datasets. To update these models with new information, also the original training dataset must be taken into account, in order to avoid catastrophic forgetting. This is, however, inefficient if not impossible, e.g., when the data is collected in streams or large amounts. To overcome this limitation and enable fast and efficient cross-dataset adaptation, we propose to employ continual learning finetuning methods designed to retain past knowledge while adapting to new data, thus effectively avoiding forgetting. Experimental results demonstrate the superiority of this approach over naive finetuning, achieving performance close to fresh retraining. While solving this known problem, we also provide a general description of how the same technique can be adopted in other AV scenarios. We highlight the potential computational and economic benefits that a continual-based adaptation can bring to the AV industry, while also reducing greenhouse emissions due to unnecessary joint retraining.
</details>
<details>
<summary>摘要</summary>
准确的路面类别化是自动驾驶车辆（AV）优化驾驶条件、提高安全性和实现高级路况映射的关键。然而，深度学习模型 для路面类别化受到不seen数据集的泛化问题带来挑战。为了更新这些模型，还需要考虑原始训练数据集，以避免恶性忘记。这是一个效率和可行性的限制，例如在流动数据集或大量数据集时。为了突破这个限制，我们提议使用 kontinual learning finetuning 方法，以保持过去知识而适应新数据，从而实现高效的跨数据集适应。实验结果表明，我们的方法与混合 retrained 方法具有类似的性能，而且具有更高的效率和可行性。此外，我们还描述了在其他 AV 场景中如何采用同样的技术，并指出了计算和经济上的优势，以及减少可能的绿色排放。
</details></li>
</ul>
<hr>
<h2 id="Delving-into-Ipsilateral-Mammogram-Assessment-under-Multi-View-Network"><a href="#Delving-into-Ipsilateral-Mammogram-Assessment-under-Multi-View-Network" class="headerlink" title="Delving into Ipsilateral Mammogram Assessment under Multi-View Network"></a>Delving into Ipsilateral Mammogram Assessment under Multi-View Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02197">http://arxiv.org/abs/2309.02197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thai Ngoc Toan Truong, Thanh-Huy Nguyen, Ba Thinh Lam, Vu Minh Duy Nguyen, Hong Phuc Nguyen</li>
<li>for: 这项研究旨在探讨多视图胸部X射图分析中的多种融合策略，包括平均和 concatenate 策略，以及不同个体和融合路径对模型学习行为的影响。</li>
<li>methods: 该研究使用了 Ipsilateral Multi-View Network，包括 Pre、Early、Middle、Last 和 Post Fusion 五种融合类型，并使用了 ResNet-18 网络。</li>
<li>results: 研究发现，中间融合方法是最佳均衡和有效的方法，可以提高深度学习模型在 VinDr-Mammo 数据集和 CMMD 数据集上的总体分类精度，并且在macro F1-Score上提高了 +2.06% (concatenate) 和 +5.29% (average)，以及 +2.03% (concatenate) 和 +3% (average)。<details>
<summary>Abstract</summary>
In many recent years, multi-view mammogram analysis has been focused widely on AI-based cancer assessment. In this work, we aim to explore diverse fusion strategies (average and concatenate) and examine the model's learning behavior with varying individuals and fusion pathways, involving Coarse Layer and Fine Layer. The Ipsilateral Multi-View Network, comprising five fusion types (Pre, Early, Middle, Last, and Post Fusion) in ResNet-18, is employed. Notably, the Middle Fusion emerges as the most balanced and effective approach, enhancing deep-learning models' generalization performance by +2.06% (concatenate) and +5.29% (average) in VinDr-Mammo dataset and +2.03% (concatenate) and +3% (average) in CMMD dataset on macro F1-Score. The paper emphasizes the crucial role of layer assignment in multi-view network extraction with various strategies.
</details>
<details>
<summary>摘要</summary>
多年来，多视图胸部X光分析已广泛关注人工智能基于癌病评估。在这项工作中，我们想要探索多种融合策略（平均和 concatenate），并研究模型在不同个体和融合路径上学习行为，包括粗层和细层。我们使用Ipsilateral Multi-View Network，其包括五种融合类型（Pre、Early、Middle、Last和Post Fusion）在ResNet-18中。值得注意的是，Middle Fusion表现为最 equilibrio和有效的方法，可以提高深度学习模型的泛化性能，在VinDr-Mammo数据集中提高了 macro F1-Score 的表现，分别提高了 +2.06%（ concatenate）和 +5.29%（average），在CMMD数据集中提高了 +2.03%（ concatenate）和 +3%（average）。文章强调了多视图网络EXTRACTION中不同策略的层分配的重要性。
</details></li>
</ul>
<hr>
<h2 id="High-resolution-3D-Maps-of-Left-Atrial-Displacements-using-an-Unsupervised-Image-Registration-Neural-Network"><a href="#High-resolution-3D-Maps-of-Left-Atrial-Displacements-using-an-Unsupervised-Image-Registration-Neural-Network" class="headerlink" title="High-resolution 3D Maps of Left Atrial Displacements using an Unsupervised Image Registration Neural Network"></a>High-resolution 3D Maps of Left Atrial Displacements using an Unsupervised Image Registration Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02179">http://arxiv.org/abs/2309.02179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christoforos Galazis, Anil Anthony Bharath, Marta Varela</li>
<li>for: 这个研究旨在提供一种自动将左心室（LA）动态分割为不同阶段的工具，以便更好地了解室内动力学性质。</li>
<li>methods: 这个研究使用高级解剖磁共振成像（Cine MRI）技术，以获取高分辨率、全面覆盖的LA动态图像。然后，提出了一种自动将LA动态分割为不同阶段的工具，使用了扩展的距离函数和矩阵方法。</li>
<li>results: 研究发现，该工具能够准确地跟踪LA墙面在心动周期内的运动， Hausdorff距离平均值为2.51±1.3mm，Dice分数平均值为0.96±0.02。<details>
<summary>Abstract</summary>
Functional analysis of the left atrium (LA) plays an increasingly important role in the prognosis and diagnosis of cardiovascular diseases. Echocardiography-based measurements of LA dimensions and strains are useful biomarkers, but they provide an incomplete picture of atrial deformations. High-resolution dynamic magnetic resonance images (Cine MRI) offer the opportunity to examine LA motion and deformation in 3D, at higher spatial resolution and with full LA coverage. However, there are no dedicated tools to automatically characterise LA motion in 3D. Thus, we propose a tool that automatically segments the LA and extracts the displacement fields across the cardiac cycle. The pipeline is able to accurately track the LA wall across the cardiac cycle with an average Hausdorff distance of $2.51 \pm 1.3~mm$ and Dice score of $0.96 \pm 0.02$.
</details>
<details>
<summary>摘要</summary>
左心室功能分析在心血管疾病诊断和预后中发挥越来越重要的作用。使用echo响应测量左心室尺寸和弹性可以提供有用的生物标志物，但它们只提供了左心室弹性的部分图像。高分辨率动态磁共振成像（Cine MRI）可以让我们在三维空间中观察左心室的运动和弹性，并且具有完整的左心室覆盖。然而，目前没有专门的工具可以自动描述左心室的运动。因此，我们提出了一种工具，可以自动 segment左心室并提取征动过程中的挤压场。管道可以准确地跟踪左心室墙在征动过程中的挤压场，平均 Hausdorff 距离为2.51±1.3毫米，Dice 分数为0.96±0.02。
</details></li>
</ul>
<hr>
<h2 id="PCFGaze-Physics-Consistent-Feature-for-Appearance-based-Gaze-Estimation"><a href="#PCFGaze-Physics-Consistent-Feature-for-Appearance-based-Gaze-Estimation" class="headerlink" title="PCFGaze: Physics-Consistent Feature for Appearance-based Gaze Estimation"></a>PCFGaze: Physics-Consistent Feature for Appearance-based Gaze Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02165">http://arxiv.org/abs/2309.02165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiwei Bao, Feng Lu</li>
<li>for: 本文试图解释如何将视线特征连接到物理上的视线定义。</li>
<li>methods: 本文分析了视线特征拟合空间，发现视线特征间的地odesic距离与样本之间的视线差异相关。基于这种发现，提出了物理相关特征（PCF），将视线特征与物理定义的视线连接。</li>
<li>results: 提出的PCFGAZE框架可以直接优化视线特征空间，无需额外训练数据，可以 Alleviate overfitting问题，并在不同预测器上提高跨预测器视线估计精度。<details>
<summary>Abstract</summary>
Although recent deep learning based gaze estimation approaches have achieved much improvement, we still know little about how gaze features are connected to the physics of gaze. In this paper, we try to answer this question by analyzing the gaze feature manifold. Our analysis revealed the insight that the geodesic distance between gaze features is consistent with the gaze differences between samples. According to this finding, we construct the Physics- Consistent Feature (PCF) in an analytical way, which connects gaze feature to the physical definition of gaze. We further propose the PCFGaze framework that directly optimizes gaze feature space by the guidance of PCF. Experimental results demonstrate that the proposed framework alleviates the overfitting problem and significantly improves cross-domain gaze estimation accuracy without extra training data. The insight of gaze feature has the potential to benefit other regression tasks with physical meanings.
</details>
<details>
<summary>摘要</summary>
尽管最近的深度学习基于眼动估算方法已经取得了大量进步，但我们对眼动特征与物理眼动之间的连接还知之 little。在这篇论文中，我们尝试回答这个问题，通过分析眼动特征抽象空间。我们的分析发现，在眼动特征空间中， closest geodesic distance 与眼动差异 between samples 相关。基于这一发现，我们构建了Physics-Consistent Feature (PCF)，将眼动特征连接到物理眼动的定义。我们进一步提出PCFGaze框架，通过PCF的指导，直接优化眼动特征空间。实验结果表明，我们的框架可以减少过拟合问题，在不同领域的眼动估算精度得到显著改善，无需额外的训练数据。我们的发现可能会对其他具有物理含义的回归任务产生影响。
</details></li>
</ul>
<hr>
<h2 id="The-Adversarial-Implications-of-Variable-Time-Inference"><a href="#The-Adversarial-Implications-of-Variable-Time-Inference" class="headerlink" title="The Adversarial Implications of Variable-Time Inference"></a>The Adversarial Implications of Variable-Time Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02159">http://arxiv.org/abs/2309.02159</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dudi709/Timing-Based-Attack">https://github.com/dudi709/Timing-Based-Attack</a></li>
<li>paper_authors: Dudi Biton, Aditi Misra, Efrat Levy, Jaidip Kotak, Ron Bitton, Roei Schuster, Nicolas Papernot, Yuval Elovici, Ben Nassi</li>
<li>For: The paper is written to demonstrate the ability to enhance decision-based attacks on machine learning models by exploiting a novel side channel in algorithmic timing.* Methods: The paper uses a technique called timing attack, which measures the execution time of the algorithm used to post-process the predictions of the ML model under attack.* Results: The paper demonstrates the ability to successfully evade object detection using adversarial examples and perform dataset inference by exploiting the timing leakage vulnerability inherent in the non-maximum suppression (NMS) algorithm. The adversarial examples exhibit superior perturbation quality compared to a decision-based attack.Here is the information in Simplified Chinese text:* For: 本文是为了展示如何使用一种新的边道攻击机器学习模型。* Methods: 本文使用了一种名为时间攻击的技术，该技术测量 ML 模型下的预测 outputs（例如，标签）的执行时间。* Results: 本文成功地逃脱了对象检测器的攻击，并完成了基于时间泄漏的数据推断。 adversarial examples 展现了比基于决策的攻击更好的杂化质量。<details>
<summary>Abstract</summary>
Machine learning (ML) models are known to be vulnerable to a number of attacks that target the integrity of their predictions or the privacy of their training data. To carry out these attacks, a black-box adversary must typically possess the ability to query the model and observe its outputs (e.g., labels). In this work, we demonstrate, for the first time, the ability to enhance such decision-based attacks. To accomplish this, we present an approach that exploits a novel side channel in which the adversary simply measures the execution time of the algorithm used to post-process the predictions of the ML model under attack. The leakage of inference-state elements into algorithmic timing side channels has never been studied before, and we have found that it can contain rich information that facilitates superior timing attacks that significantly outperform attacks based solely on label outputs. In a case study, we investigate leakage from the non-maximum suppression (NMS) algorithm, which plays a crucial role in the operation of object detectors. In our examination of the timing side-channel vulnerabilities associated with this algorithm, we identified the potential to enhance decision-based attacks. We demonstrate attacks against the YOLOv3 detector, leveraging the timing leakage to successfully evade object detection using adversarial examples, and perform dataset inference. Our experiments show that our adversarial examples exhibit superior perturbation quality compared to a decision-based attack. In addition, we present a new threat model in which dataset inference based solely on timing leakage is performed. To address the timing leakage vulnerability inherent in the NMS algorithm, we explore the potential and limitations of implementing constant-time inference passes as a mitigation strategy.
</details>
<details>
<summary>摘要</summary>
машинное обучение (ML) 模型已知容易受到一些攻击，这些攻击可能会影响模型预测的正确性或训练数据的隐私。为了进行这些攻击，黑盒式敌对者通常需要能够访问模型并观察其输出（例如，标签）。在这项工作中，我们显示了，对于第一次，能够增强这些决策基本攻击。我们提出了一种方法，利用一种新的侧途通道，即对 ML 模型下攻击的执行时间进行测量。我们发现，在执行时间方面的泄露包含有丰富的信息，可以提高基于决策的攻击，并且能够 significatively  exceed 基于标签输出的攻击。在一个案例研究中，我们investigated  leakage from the non-maximum suppression (NMS) algorithm，该算法在 объек检测器中扮演着关键的角色。我们发现，与 NMS 算法相关的时间泄露具有潜在的威胁，并且可以用于增强决策基本攻击。我们采用 YOLOv3 检测器进行攻击，通过利用时间泄露来逃脱物体检测，并进行数据集推理。我们的实验结果表明，我们的恶作剂示例具有较高的杂化质量，比基于决策的攻击更好。此外，我们还提出了一个新的威胁模型，在该模型中，攻击者 solely 基于时间泄露进行数据集推理。为了解决 NMS 算法中的时间泄露漏洞，我们探讨了可能的和限制的实现常量时间推理 passes 的缓解策略。
</details></li>
</ul>
<hr>
<h2 id="Traffic-Light-Recognition-using-Convolutional-Neural-Networks-A-Survey"><a href="#Traffic-Light-Recognition-using-Convolutional-Neural-Networks-A-Survey" class="headerlink" title="Traffic Light Recognition using Convolutional Neural Networks: A Survey"></a>Traffic Light Recognition using Convolutional Neural Networks: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02158">http://arxiv.org/abs/2309.02158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Svetlana Pavlitska, Nico Lambing, Ashok Kumar Bangaru, J. Marius Zöllner</li>
<li>for: 本研究旨在提供一个涵盖汽车自动驾驶中实时交通信号识别的模型建立方法的综述。</li>
<li>methods: 本研究使用了 convolutional neural networks (CNNs) 进行交通信号识别方法的分析和检视。</li>
<li>results: 研究人员通过对 datasets 和 CNN 建模方法的分析，将交通信号识别方法分为三个主要群组：（1）特定任务特性补做的 generic object detectors 修改版本，（2）包含 rule-based 和 CNN 组件的多阶段方法，以及（3）专门为此任务设计的单阶段方法。<details>
<summary>Abstract</summary>
Real-time traffic light recognition is essential for autonomous driving. Yet, a cohesive overview of the underlying model architectures for this task is currently missing. In this work, we conduct a comprehensive survey and analysis of traffic light recognition methods that use convolutional neural networks (CNNs). We focus on two essential aspects: datasets and CNN architectures. Based on an underlying architecture, we cluster methods into three major groups: (1) modifications of generic object detectors which compensate for specific task characteristics, (2) multi-stage approaches involving both rule-based and CNN components, and (3) task-specific single-stage methods. We describe the most important works in each cluster, discuss the usage of the datasets, and identify research gaps.
</details>
<details>
<summary>摘要</summary>
现实时交通信号识别是自动驾驶的重要组成部分。然而，关于这个任务下的模型建立的总体概述却缺乏一个系统性的审查。在这项工作中，我们进行了全面的调研和分析，探讨了使用卷积神经网络（CNN）进行交通信号识别的方法。我们主要关注两个重要方面：数据集和CNN体系。基于基本体系，我们将方法分为三个主要群组：（1）特定任务特性补做的通用物体检测器修改版本，（2）包含Rule-based和CNN组件的多 stageapproaches，以及（3）专门为此任务设计的单 stage方法。我们描述了每个群组中最重要的工作，讨论了数据集的使用，并确定了研究漏洞。
</details></li>
</ul>
<hr>
<h2 id="S3C-Semi-Supervised-VQA-Natural-Language-Explanation-via-Self-Critical-Learning"><a href="#S3C-Semi-Supervised-VQA-Natural-Language-Explanation-via-Self-Critical-Learning" class="headerlink" title="S3C: Semi-Supervised VQA Natural Language Explanation via Self-Critical Learning"></a>S3C: Semi-Supervised VQA Natural Language Explanation via Self-Critical Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02155">http://arxiv.org/abs/2309.02155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Suo, Mengyang Sun, Weisong Liu, Yiqi Gao, Peng Wang, Yanning Zhang, Qi Wu</li>
<li>for: 这 paper 的目的是解释 VQA 模型的决策过程，以便更好地了解和让用户信任。</li>
<li>methods: 这 paper 使用了 Semi-Supervised VQA-NLE via Self-Critical Learning (S3C) 方法，通过回答奖励来评估候选的解释，从而提高了逻辑一致性 между答案和解释。</li>
<li>results: 这 paper 的方法在两个 VQA-NLE 数据集上达到了新的state-of-the-art性能，并且通过自动度量和人类评估都表明了方法的有效性。<details>
<summary>Abstract</summary>
VQA Natural Language Explanation (VQA-NLE) task aims to explain the decision-making process of VQA models in natural language. Unlike traditional attention or gradient analysis, free-text rationales can be easier to understand and gain users' trust. Existing methods mostly use post-hoc or self-rationalization models to obtain a plausible explanation. However, these frameworks are bottlenecked by the following challenges: 1) the reasoning process cannot be faithfully responded to and suffer from the problem of logical inconsistency. 2) Human-annotated explanations are expensive and time-consuming to collect. In this paper, we propose a new Semi-Supervised VQA-NLE via Self-Critical Learning (S3C), which evaluates the candidate explanations by answering rewards to improve the logical consistency between answers and rationales. With a semi-supervised learning framework, the S3C can benefit from a tremendous amount of samples without human-annotated explanations. A large number of automatic measures and human evaluations all show the effectiveness of our method. Meanwhile, the framework achieves a new state-of-the-art performance on the two VQA-NLE datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Domain-Adaptation-for-Satellite-Borne-Hyperspectral-Cloud-Detection"><a href="#Domain-Adaptation-for-Satellite-Borne-Hyperspectral-Cloud-Detection" class="headerlink" title="Domain Adaptation for Satellite-Borne Hyperspectral Cloud Detection"></a>Domain Adaptation for Satellite-Borne Hyperspectral Cloud Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02150">http://arxiv.org/abs/2309.02150</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Du, Anh-Dzung Doan, Yee Wei Law, Tat-Jun Chin</li>
<li>for: 本研究旨在解决遥感机器学习硬件加速器上部署云计算模型时遇到的领域差问题，以实现在新任务中使用新感器时的模型更新和提高。</li>
<li>methods: 本研究提出了新的领域适应任务，并开发了一种带宽效率的超vision学习领域适应算法。此外，本研究还提出了在遥感机器学习硬件加速器上实现测试时适应算法。</li>
<li>results: 本研究表明，通过使用新的领域适应任务和算法，可以在遥感机器学习硬件加速器上实现带宽效率的领域适应，以便在新任务中使用新感器时的模型更新和提高。<details>
<summary>Abstract</summary>
The advent of satellite-borne machine learning hardware accelerators has enabled the on-board processing of payload data using machine learning techniques such as convolutional neural networks (CNN). A notable example is using a CNN to detect the presence of clouds in hyperspectral data captured on Earth observation (EO) missions, whereby only clear sky data is downlinked to conserve bandwidth. However, prior to deployment, new missions that employ new sensors will not have enough representative datasets to train a CNN model, while a model trained solely on data from previous missions will underperform when deployed to process the data on the new missions. This underperformance stems from the domain gap, i.e., differences in the underlying distributions of the data generated by the different sensors in previous and future missions. In this paper, we address the domain gap problem in the context of on-board hyperspectral cloud detection. Our main contributions lie in formulating new domain adaptation tasks that are motivated by a concrete EO mission, developing a novel algorithm for bandwidth-efficient supervised domain adaptation, and demonstrating test-time adaptation algorithms on space deployable neural network accelerators. Our contributions enable minimal data transmission to be invoked (e.g., only 1% of the weights in ResNet50) to achieve domain adaptation, thereby allowing more sophisticated CNN models to be deployed and updated on satellites without being hampered by domain gap and bandwidth limitations.
</details>
<details>
<summary>摘要</summary>
卫星上的机器学习硬件加速器的出现，使得payload数据中使用机器学习技术，如 convolutional neural networks (CNN) 进行处理。一个典型的应用是使用 CNN 在 Earth observation (EO) 任务中检测地球表面上云的存在，从而只下载清晰天空数据，以保存带宽。然而，在新任务中使用新的探测器时，新任务不会有足够的表示性数据来训练 CNN 模型，而一个仅在前一任务中训练的模型在新任务中表现不佳，这是由于领域差距问题，即不同探测器生成的数据的下面分布之间的差异。在这篇论文中，我们在 Earth observation 中解决领域差距问题。我们的主要贡献在于提出了新的领域适应任务，开发了一种带宽有效的指导领域适应算法，并在空间部署可能的神经网络加速器上进行测试时适应算法。我们的贡献使得只需传输 minimal 的数据（例如，ResNet50 中的 1% 的参数）可以实现领域适应，从而允许更复杂的 CNN 模型在卫星上部署和更新，不受领域差距和带宽限制。
</details></li>
</ul>
<hr>
<h2 id="INCEPTNET-Precise-And-Early-Disease-Detection-Application-For-Medical-Images-Analyses"><a href="#INCEPTNET-Precise-And-Early-Disease-Detection-Application-For-Medical-Images-Analyses" class="headerlink" title="INCEPTNET: Precise And Early Disease Detection Application For Medical Images Analyses"></a>INCEPTNET: Precise And Early Disease Detection Application For Medical Images Analyses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02147">http://arxiv.org/abs/2309.02147</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AMiiR-S/Inceptnet_cancer_recognition">https://github.com/AMiiR-S/Inceptnet_cancer_recognition</a></li>
<li>paper_authors: Amirhossein Sajedi, Mohammad Javad Fadaeieslam</li>
<li>for: 本研究旨在提出一种新的深度神经网络（DNN），名为InceptNet，用于医疗图像处理，以提高疾病检测和医疗图像分 segmentation 的精度和性能。</li>
<li>methods: 本研究使用了Unet架构，并添加了多个并行的启发模块，以便快速地捕捉到医疗图像中的缩放区域。</li>
<li>results: 对四个referencedataset进行测试，包括血管 segmentation、肺肿尺segmentation、皮肤损伤 segmentation和乳腺癌细胞检测。结果表明，提案方法在图像中的小规模结构上表现出了更高的改进度。与前一代方法相比，提案方法的精度从0.9531、0.8900、0.9872和0.9881提高到0.9555、0.9510、0.9945和0.9945。<details>
<summary>Abstract</summary>
In view of the recent paradigm shift in deep AI based image processing methods, medical image processing has advanced considerably. In this study, we propose a novel deep neural network (DNN), entitled InceptNet, in the scope of medical image processing, for early disease detection and segmentation of medical images in order to enhance precision and performance. We also investigate the interaction of users with the InceptNet application to present a comprehensive application including the background processes, and foreground interactions with users. Fast InceptNet is shaped by the prominent Unet architecture, and it seizes the power of an Inception module to be fast and cost effective while aiming to approximate an optimal local sparse structure. Adding Inception modules with various parallel kernel sizes can improve the network's ability to capture the variations in the scaled regions of interest. To experiment, the model is tested on four benchmark datasets, including retina blood vessel segmentation, lung nodule segmentation, skin lesion segmentation, and breast cancer cell detection. The improvement was more significant on images with small scale structures. The proposed method improved the accuracy from 0.9531, 0.8900, 0.9872, and 0.9881 to 0.9555, 0.9510, 0.9945, and 0.9945 on the mentioned datasets, respectively, which show outperforming of the proposed method over the previous works. Furthermore, by exploring the procedure from start to end, individuals who have utilized a trial edition of InceptNet, in the form of a complete application, are presented with thirteen multiple choice questions in order to assess the proposed method. The outcomes are evaluated through the means of Human Computer Interaction.
</details>
<details>
<summary>摘要</summary>
因为深度AI技术的最近分布shift，医疗图像处理方法得到了显著提高。在这个研究中，我们提出了一种新的深度神经网络（DNN），即InceptNet，用于医疗图像处理领域的疾病检测和图像分割，以提高精度和性能。我们还investigated用户与InceptNet应用程序之间的交互，以提供全面的应用程序，包括背景进程和前景交互。快速InceptNet基于提前的Unet架构，并利用Inception模块以实现快速和经济的搅拌，同时尝试以最佳的本地稀疏结构来近似。通过添加不同的并行kernel大小的Inception模块，可以提高网络的捕捉缩放区域的变化能力。为了实验，我们测试了四个标准数据集，包括血液管Segmentation、肺肿Segmentation、皮肤病变Segmentation和乳腺癌细胞检测。提出的方法在这些数据集上提高了精度，从0.9531、0.8900、0.9872和0.9881提高到0.9555、0.9510、0.9945和0.9945，这表明提出的方法在先前的工作上出perform。此外，通过探索从开始到结束的过程，那些使用了InceptNet试用版的人员被提供了十三个多选题，以评估提出的方法。结果由人计算机交互评估。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Masked-3D-Diffusion-Model-for-Video-Outpainting"><a href="#Hierarchical-Masked-3D-Diffusion-Model-for-Video-Outpainting" class="headerlink" title="Hierarchical Masked 3D Diffusion Model for Video Outpainting"></a>Hierarchical Masked 3D Diffusion Model for Video Outpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02119">http://arxiv.org/abs/2309.02119</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fanfanda/M3DDM">https://github.com/fanfanda/M3DDM</a></li>
<li>paper_authors: Fanda Fan, Chaoxu Guo, Litong Gong, Biao Wang, Tiezheng Ge, Yuning Jiang, Chunjie Luo, Jianfeng Zhan</li>
<li>for: 这个论文的目的是提出一种基于掩码模型的3D扩散模型，用于视频填充。</li>
<li>methods: 这个方法使用掩码模型的技术进行训练，并使用多个引导帧连接多个视频帧的结果，以保证视频的时间一致性和避免邻帧的抖动。同时，该方法还使用全帧提取以提取视频中的全帧信息，并使用交叉注意力引导模型获取其他视频帧中的信息。</li>
<li>results: 该方法在视频填充任务中实现了state-of-the-art的结果。<details>
<summary>Abstract</summary>
Video outpainting aims to adequately complete missing areas at the edges of video frames. Compared to image outpainting, it presents an additional challenge as the model should maintain the temporal consistency of the filled area. In this paper, we introduce a masked 3D diffusion model for video outpainting. We use the technique of mask modeling to train the 3D diffusion model. This allows us to use multiple guide frames to connect the results of multiple video clip inferences, thus ensuring temporal consistency and reducing jitter between adjacent frames. Meanwhile, we extract the global frames of the video as prompts and guide the model to obtain information other than the current video clip using cross-attention. We also introduce a hybrid coarse-to-fine inference pipeline to alleviate the artifact accumulation problem. The existing coarse-to-fine pipeline only uses the infilling strategy, which brings degradation because the time interval of the sparse frames is too large. Our pipeline benefits from bidirectional learning of the mask modeling and thus can employ a hybrid strategy of infilling and interpolation when generating sparse frames. Experiments show that our method achieves state-of-the-art results in video outpainting tasks. More results are provided at our https://fanfanda.github.io/M3DDM/.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>视频外绘目标是完整地填充视频帧边缘中的缺失区域。与图像外绘相比，它增加了一个额外挑战，即模型需要保持视频帧中填充的区域的时间一致性。在这篇论文中，我们介绍了一种masked 3D扩散模型 для视频外绘。我们使用模型的技术来训练3D扩散模型。这 позволяет我们使用多个引导帧连接多个视频帧的结果，以确保时间一致性，并减少相邻帧之间的振荡。同时，我们提取视频全帧作为提示，并使用交叉注意力导引模型获取除当前视频帧之外的信息。我们还提出了一种混合粗细调制pipeline来缓解artifact散布问题。现有的粗细调制pipeline只使用填充策略，这会导致质量下降，因为缺失帧的时间间隔太长。我们的管道可以利用面精模型的混合学习，因此可以采用混合策略，在生成缺失帧时使用填充和 interpolate 两种策略。实验显示，我们的方法实现了视频外绘任务的状态精算结果。更多结果请参考我们的 <https://fanfanda.github.io/M3DDM/>。
</details></li>
</ul>
<hr>
<h2 id="Towards-Diverse-and-Consistent-Typography-Generation"><a href="#Towards-Diverse-and-Consistent-Typography-Generation" class="headerlink" title="Towards Diverse and Consistent Typography Generation"></a>Towards Diverse and Consistent Typography Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02099">http://arxiv.org/abs/2309.02099</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Wataru Shimoda, Daichi Haraguchi, Seiichi Uchida, Kota Yamaguchi</li>
<li>for: 这篇论文旨在实现多元化的 typography 设计，以增加设计文件中的多样性。</li>
<li>methods: 论文使用了一个精确的 attribute generation 模型，并建立了一个自适应的 sampling 方法，以生成具有与输入设计上下文相符的多样化 typography。</li>
<li>results: 实验结果显示，论文的模型成功将多样化的 typography 生成出来，并且保持了一致的 typography 结构。Is there anything else I can help with?<details>
<summary>Abstract</summary>
In this work, we consider the typography generation task that aims at producing diverse typographic styling for the given graphic document. We formulate typography generation as a fine-grained attribute generation for multiple text elements and build an autoregressive model to generate diverse typography that matches the input design context. We further propose a simple yet effective sampling approach that respects the consistency and distinction principle of typography so that generated examples share consistent typographic styling across text elements. Our empirical study shows that our model successfully generates diverse typographic designs while preserving a consistent typographic structure.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们考虑了 typography 生成任务，旨在为给定的图文文档生成多样化的 typography 风格。我们将 typography 生成定义为多个文本元素的细化特征生成，并构建了自适应模型来生成匹配输入设计Context 的多样化 typography。我们还提出了一种简单 yet 有效的采样方法，使得生成的例子遵循 typography 的一致性和差异原则，以保证生成的 typography 风格具有一致性。我们的实验表明，我们的模型成功地生成了多样化的 typography 设计，同时保持一致的 typography 结构。Here's the breakdown of the translation:* "typography" is translated as "typography" (字体设计)* "graphic document" is translated as "图文文档" (图文文档)* "fine-grained attribute generation" is translated as "细化特征生成" (细化特征生成)* "autoregressive model" is translated as "自适应模型" (自适应模型)* "consistency and distinction principle" is translated as "一致性和差异原则" (一致性和差异原则)* "empirical study" is translated as "实验研究" (实验研究)
</details></li>
</ul>
<hr>
<h2 id="DeNISE-Deep-Networks-for-Improved-Segmentation-Edges"><a href="#DeNISE-Deep-Networks-for-Improved-Segmentation-Edges" class="headerlink" title="DeNISE: Deep Networks for Improved Segmentation Edges"></a>DeNISE: Deep Networks for Improved Segmentation Edges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02091">http://arxiv.org/abs/2309.02091</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sander Riisøen Jyhne, Per-Arne Andersen, Morten Goodwin</li>
<li>for: 提高分割图像边界质量</li>
<li>methods: 使用边检测和分割模型提高分割edge的准确性</li>
<li>results: 在航空图像 segmentation  task 中，使用 DeNISE 技术可以提高基elineresult的 IoU 至 78.9%Here’s a breakdown of each point:</li>
<li>for: The paper is written for improving the boundary quality of segmentation masks in aerial images.</li>
<li>methods: The paper uses edge detection and segmentation models to improve the accuracy of the predicted segmentation edge. The technique is not trained end-to-end and can be applied to all types of neural networks.</li>
<li>results: The paper demonstrates the potential of the DeNISE technique by improving the baseline results with a building IoU of 78.9% in aerial images.<details>
<summary>Abstract</summary>
This paper presents Deep Networks for Improved Segmentation Edges (DeNISE), a novel data enhancement technique using edge detection and segmentation models to improve the boundary quality of segmentation masks. DeNISE utilizes the inherent differences in two sequential deep neural architectures to improve the accuracy of the predicted segmentation edge. DeNISE applies to all types of neural networks and is not trained end-to-end, allowing rapid experiments to discover which models complement each other. We test and apply DeNISE for building segmentation in aerial images. Aerial images are known for difficult conditions as they have a low resolution with optical noise, such as reflections, shadows, and visual obstructions. Overall the paper demonstrates the potential for DeNISE. Using the technique, we improve the baseline results with a building IoU of 78.9%.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了深度网络提高分割边缘（DeNISE），一种使用边检测和分割模型提高分割框架质量的数据优化技术。DeNISE利用两个顺序的深度神经网络之间的自然差异来提高预测分割边的准确性。DeNISE适用于所有类型的神经网络，不需要练习端到端，可以快速进行实验，找到哪些模型相互补充。我们测试并应用DeNISE于航空图像分割。航空图像known for difficult conditions, such as low resolution, optical noise, reflections, shadows, and visual obstructions. Overall, the paper demonstrates the potential of DeNISE. Using the technique, we improve the baseline results with a building IoU of 78.9%.
</details></li>
</ul>
<hr>
<h2 id="Histograms-of-Points-Orientations-and-Dynamics-of-Orientations-Features-for-Hindi-Online-Handwritten-Character-Recognition"><a href="#Histograms-of-Points-Orientations-and-Dynamics-of-Orientations-Features-for-Hindi-Online-Handwritten-Character-Recognition" class="headerlink" title="Histograms of Points, Orientations, and Dynamics of Orientations Features for Hindi Online Handwritten Character Recognition"></a>Histograms of Points, Orientations, and Dynamics of Orientations Features for Hindi Online Handwritten Character Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02067">http://arxiv.org/abs/2309.02067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anand Sharma, A. G. Ramakrishnan</li>
<li>for: 这个研究的目的是提出一种独立于字形笔触方向和顺序变化的手写字符识别方法。</li>
<li>methods: 该方法将特征分别映射到点的坐标值和点的方向orientation，并计算这些特征的 histogram 从不同的空间地图中。 此外，该方法还考虑了其他已经在其他研究中用于训练分类器的不同特征，如 spatio-temporal、柯西 transform、杰氏 transform、浪涌 transform 和 histogram of oriented gradients。</li>
<li>results: SVM 分类器使用该提出的特征达到了最高的92.9%的分类精度，比其他特征的分类器的性能更高。<details>
<summary>Abstract</summary>
A set of features independent of character stroke direction and order variations is proposed for online handwritten character recognition. A method is developed that maps features like co-ordinates of points, orientations of strokes at points, and dynamics of orientations of strokes at points spatially as a function of co-ordinate values of the points and computes histograms of these features from different regions in the spatial map.   Different features like spatio-temporal, discrete Fourier transform, discrete cosine transform, discrete wavelet transform, spatial, and histograms of oriented gradients used in other studies for training classifiers for character recognition are considered. The classifier chosen for classification performance comparison, when trained with different features, is support vector machines (SVM).   The character datasets used for training and testing the classifiers consist of online handwritten samples of 96 different Hindi characters. There are 12832 and 2821 samples in training and testing datasets, respectively.   SVM classifiers trained with the proposed features has the highest classification accuracy of 92.9\% when compared to the performances of SVM classifiers trained with the other features and tested on the same testing dataset. Therefore, the proposed features have better character discriminative capability than the other features considered for comparison.
</details>
<details>
<summary>摘要</summary>
“一组独立于字符笔触方向和顺序变化的特征集被提议用于在线手写字符识别。一种方法将这些特征，如点坐标、点上笔orientation、笔orientation的动态变化，空间地映射为坐标值的函数，并从不同区域的空间地图中计算 histogram。这些特征包括空间时间、离散傅里叶变换、离散佩瑞茨变换、离散波浪变换、空间和 histogram of oriented gradients，这些特征在其他研究中用于训练类ifier进行字符识别。类ifier选择为支持向量机（SVM）。字符数据集用于训练和测试类ifier包括96个不同的印地语字符的在线手写样本，共有12832和2821个样本。 SVM类ifier使用提议的特征得到最高的92.9%的分类精度，比其他特征和测试集进行比较，因此提议的特征具有更好的字符识别能力。”
</details></li>
</ul>
<hr>
<h2 id="An-Adaptive-Spatial-Temporal-Local-Feature-Difference-Method-for-Infrared-Small-moving-Target-Detection"><a href="#An-Adaptive-Spatial-Temporal-Local-Feature-Difference-Method-for-Infrared-Small-moving-Target-Detection" class="headerlink" title="An Adaptive Spatial-Temporal Local Feature Difference Method for Infrared Small-moving Target Detection"></a>An Adaptive Spatial-Temporal Local Feature Difference Method for Infrared Small-moving Target Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02054">http://arxiv.org/abs/2309.02054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongkang Zhao, Chuang Zhu, Yuan Li, Shuaishuai Wang, Zihan Lan, Yuanyuan Qiao</li>
<li>for: 这个研究旨在提高红外线小运动目标准确的检测，并且提出了一个新的方法。</li>
<li>methods: 这个方法使用了空间和时间领域的滤波器，并且将像素级别的背景降噪模组组合到出力中，以增强目标和背景的 контра斯特。</li>
<li>results: 实验结果显示，提案的方法在红外线小运动目标检测方面比现有的方法表现更好。<details>
<summary>Abstract</summary>
Detecting small moving targets accurately in infrared (IR) image sequences is a significant challenge. To address this problem, we propose a novel method called spatial-temporal local feature difference (STLFD) with adaptive background suppression (ABS). Our approach utilizes filters in the spatial and temporal domains and performs pixel-level ABS on the output to enhance the contrast between the target and the background. The proposed method comprises three steps. First, we obtain three temporal frame images based on the current frame image and extract two feature maps using the designed spatial domain and temporal domain filters. Next, we fuse the information of the spatial domain and temporal domain to produce the spatial-temporal feature maps and suppress noise using our pixel-level ABS module. Finally, we obtain the segmented binary map by applying a threshold. Our experimental results demonstrate that the proposed method outperforms existing state-of-the-art methods for infrared small-moving target detection.
</details>
<details>
<summary>摘要</summary>
探测红外图像序列中小目标的准确性是一项非常重要的挑战。为解决这个问题，我们提出了一种新的方法，即空间-时间本地特征差分（STLFD）与适应背景抑制（ABS）。我们的方法使用空间和时间Domain的滤波器，并在输出中进行像素级ABS处理，以增强目标和背景的对比度。我们的方法包括三步：第一步，基于当前帧图像，获取三帧图像，并使用我们设计的空间频谱和时间频谱滤波器来提取两个特征图。第二步，将空间频谱和时间频谱的信息融合，生成空间-时间特征图，并使用我们的像素级ABS模块来抑制噪声。第三步，应用阈值来获得分割的二值图。我们的实验结果表明，我们的方法可以超过现有的状态艺术方法对红外小目标探测的性能。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-based-3D-Object-Detection-with-Random-Boxes"><a href="#Diffusion-based-3D-Object-Detection-with-Random-Boxes" class="headerlink" title="Diffusion-based 3D Object Detection with Random Boxes"></a>Diffusion-based 3D Object Detection with Random Boxes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02049">http://arxiv.org/abs/2309.02049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Zhou, Jinghua Hou, Tingting Yao, Dingkang Liang, Zhe Liu, Zhikang Zou, Xiaoqing Ye, Jianwei Cheng, Xiang Bai</li>
<li>for: 三角形物体探测是自动驾驶的关键任务，现有的锚点基于方法依赖于经验性的锚点设置，导致算法缺乏启发性。</li>
<li>methods: 我们提出的Diff3Det方法将Diffusion模型应用到提议生成阶段，视为探测目标的生成。在训练阶段，物体框从真实框架噪声过程中演化到高斯分布，解码器学习反转噪声过程。在推断阶段，模型不断级联一组随机框架，进行预测结果的精细化。</li>
<li>results: 我们在KITTI测试benchmark上进行了详细的实验，与传统锚点基于3D探测方法进行比较，实现了显著的性能提升。<details>
<summary>Abstract</summary>
3D object detection is an essential task for achieving autonomous driving. Existing anchor-based detection methods rely on empirical heuristics setting of anchors, which makes the algorithms lack elegance. In recent years, we have witnessed the rise of several generative models, among which diffusion models show great potential for learning the transformation of two distributions. Our proposed Diff3Det migrates the diffusion model to proposal generation for 3D object detection by considering the detection boxes as generative targets. During training, the object boxes diffuse from the ground truth boxes to the Gaussian distribution, and the decoder learns to reverse this noise process. In the inference stage, the model progressively refines a set of random boxes to the prediction results. We provide detailed experiments on the KITTI benchmark and achieve promising performance compared to classical anchor-based 3D detection methods.
</details>
<details>
<summary>摘要</summary>
三维对象检测是自动驾驶的关键任务。现有的锚点基于方法靠 Empirical 规则设置锚点，这使得算法缺乏吟芳。近年来，我们所见证到了多种生成模型的出现，其中扩散模型在学习两个分布之间的变换方面表现出了极大的潜力。我们提出的 Diff3Det 将扩散模型应用到提议生成中，并考虑检测框为生成目标。在训练阶段，对象框从真实框 diffuse 到 Gaussian 分布，decoder 学习恢复这种噪声过程。在推测阶段，模型逐渐精细化一组随机框到预测结果。我们对 KITTI 测试准则进行详细的实验，并与经典锚点基于三维检测方法比较得出了良好的表现。
</details></li>
</ul>
<hr>
<h2 id="Decomposed-Guided-Dynamic-Filters-for-Efficient-RGB-Guided-Depth-Completion"><a href="#Decomposed-Guided-Dynamic-Filters-for-Efficient-RGB-Guided-Depth-Completion" class="headerlink" title="Decomposed Guided Dynamic Filters for Efficient RGB-Guided Depth Completion"></a>Decomposed Guided Dynamic Filters for Efficient RGB-Guided Depth Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02043">http://arxiv.org/abs/2309.02043</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YufeiWang777/DGDF">https://github.com/YufeiWang777/DGDF</a></li>
<li>paper_authors: Yufei Wang, Yuxin Mao, Qi Liu, Yuchao Dai</li>
<li>for: 这个 paper 目的是完善 RGB 图像中的深度映射，使用 sparse depth measurement 和对应的 RGB 图像。</li>
<li>methods: 使用 guided dynamic filters，将 RGB 特征变换为深度特征，并使用内容适应的混合层来将 filters 分解为具有内容属性的分布式元件。</li>
<li>results: 根据 proposed 的想法，可以实现对 RGB-D 复合 зада зада的优化，并在 KITTI 数据集上实现 state-of-the-art 的表现，同时在 NYUv2 数据集上实现相似的表现。<details>
<summary>Abstract</summary>
RGB-guided depth completion aims at predicting dense depth maps from sparse depth measurements and corresponding RGB images, where how to effectively and efficiently exploit the multi-modal information is a key issue. Guided dynamic filters, which generate spatially-variant depth-wise separable convolutional filters from RGB features to guide depth features, have been proven to be effective in this task. However, the dynamically generated filters require massive model parameters, computational costs and memory footprints when the number of feature channels is large. In this paper, we propose to decompose the guided dynamic filters into a spatially-shared component multiplied by content-adaptive adaptors at each spatial location. Based on the proposed idea, we introduce two decomposition schemes A and B, which decompose the filters by splitting the filter structure and using spatial-wise attention, respectively. The decomposed filters not only maintain the favorable properties of guided dynamic filters as being content-dependent and spatially-variant, but also reduce model parameters and hardware costs, as the learned adaptors are decoupled with the number of feature channels. Extensive experimental results demonstrate that the methods using our schemes outperform state-of-the-art methods on the KITTI dataset, and rank 1st and 2nd on the KITTI benchmark at the time of submission. Meanwhile, they also achieve comparable performance on the NYUv2 dataset. In addition, our proposed methods are general and could be employed as plug-and-play feature fusion blocks in other multi-modal fusion tasks such as RGB-D salient object detection.
</details>
<details>
<summary>摘要</summary>
RGB-导向深度完成任务是预测粗略深度图像从稀疏深度测量和对应的RGB图像，其中如何有效地和有效地利用多Modal信息是关键问题。受导动 филь特，生成从RGB特征生成空间不同的depth-wise分解卷积滤波器，用于导航深度特征，已经证明是有效的。然而，生成的滤波器需要大量的模型参数，计算成本和内存占用率，特别是当特征通道数大的时候。在这篇论文中，我们提议将导动 filters decomposed into a spatially-shared component multiplied by content-adaptive adaptors at each spatial location。根据我们的想法，我们引入了A和B两种分解方案，通过在空间位置上分解滤波器结构并使用空间层别注意，分解滤波器。这些分解滤波器不仅保持了导动 filters 的有利特性，例如具有内容依赖和空间不同的特性，同时还减少了模型参数和硬件成本，因为学习的适应器被分离到特征通道数。我们的方法在KITTI dataset上实现了比州-of-the-art的表现，并在KITTI benchmark上 ranked 1st and 2nd at the time of submission。此外，我们的方法也实现了与NYUv2 dataset上的相似表现。此外，我们的提议是通用的，可以作为RGB-D突出对象检测中的特性融合块。
</details></li>
</ul>
<hr>
<h2 id="Learning-Cross-Modal-Affinity-for-Referring-Video-Object-Segmentation-Targeting-Limited-Samples"><a href="#Learning-Cross-Modal-Affinity-for-Referring-Video-Object-Segmentation-Targeting-Limited-Samples" class="headerlink" title="Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples"></a>Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02041">http://arxiv.org/abs/2309.02041</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hengliusky/few_shot_rvos">https://github.com/hengliusky/few_shot_rvos</a></li>
<li>paper_authors: Guanghui Li, Mingqi Gao, Heng Liu, Xiantong Zhen, Feng Zheng</li>
<li>for: 本研究旨在提出一种基于Transformer架构的简单 yet有效的模型，以解决现有的 Referring Video Object Segmentation（RVOS）方法在面临有限样本的情况下表现不佳的问题。</li>
<li>methods: 我们提出了一种新的交叉模式相互关联（CMA）模块，该模块通过建立多模式相互关联，快速学习新的semantic信息，使模型能够适应不同的场景。</li>
<li>results: 我们的模型在几种不同的场景下，只使用了几个样本来学习，仍然可以达到当前最佳性能，比如在Mini-Ref-YouTube-VOS上的平均性能为53.1 J和54.8 F，比基eline上高出10%。此外，我们在Mini-Ref-SAIL-VOS上也取得了很出色的结果，达到77.7 J和74.8 F，与基eline相比明显优于。<details>
<summary>Abstract</summary>
Referring video object segmentation (RVOS), as a supervised learning task, relies on sufficient annotated data for a given scene. However, in more realistic scenarios, only minimal annotations are available for a new scene, which poses significant challenges to existing RVOS methods. With this in mind, we propose a simple yet effective model with a newly designed cross-modal affinity (CMA) module based on a Transformer architecture. The CMA module builds multimodal affinity with a few samples, thus quickly learning new semantic information, and enabling the model to adapt to different scenarios. Since the proposed method targets limited samples for new scenes, we generalize the problem as - few-shot referring video object segmentation (FS-RVOS). To foster research in this direction, we build up a new FS-RVOS benchmark based on currently available datasets. The benchmark covers a wide range and includes multiple situations, which can maximally simulate real-world scenarios. Extensive experiments show that our model adapts well to different scenarios with only a few samples, reaching state-of-the-art performance on the benchmark. On Mini-Ref-YouTube-VOS, our model achieves an average performance of 53.1 J and 54.8 F, which are 10% better than the baselines. Furthermore, we show impressive results of 77.7 J and 74.8 F on Mini-Ref-SAIL-VOS, which are significantly better than the baselines. Code is publicly available at https://github.com/hengliusky/Few_shot_RVOS.
</details>
<details>
<summary>摘要</summary>
描述视频对象分割（RVOS）作为一种监督学习任务，需要具备充足的标注数据，以便在新场景中进行学习。然而，在更真实的场景中，只有有限的标注数据可用于新场景，这会对现有的RVOS方法带来重大挑战。为了解决这个问题，我们提出了一种简单 yet effective的模型，基于 transformer 架构的 cross-modal affinity（CMA）模块。CMA模块可以快速学习新的semantic信息，并在不同的场景中建立多modal的联系，使模型能够适应不同的场景。由于我们的方法targets限样数据，我们将问题推广为- few-shot referring video object segmentation（FS-RVOS）。为了推动这个方向的研究，我们建立了一个新的FS-RVOS benchmark，该benchmark包括了多种情况，可以最大化 simulate real-world scenarios。我们的实验表明，我们的模型能够适应不同的场景，只需要几个样本，并且在 benchmark 上达到了state-of-the-art的性能。在 Mini-Ref-YouTube-VOS 上，我们的模型取得了53.1 J和54.8 F的性能，比基eline高出10%。此外，我们在 Mini-Ref-SAIL-VOS 上取得了77.7 J和74.8 F的性能，与基eline significatively better。我们的代码可以在 <https://github.com/hengliusky/Few_shot_RVOS> 上下载。
</details></li>
</ul>
<hr>
<h2 id="A-survey-on-efficient-vision-transformers-algorithms-techniques-and-performance-benchmarking"><a href="#A-survey-on-efficient-vision-transformers-algorithms-techniques-and-performance-benchmarking" class="headerlink" title="A survey on efficient vision transformers: algorithms, techniques, and performance benchmarking"></a>A survey on efficient vision transformers: algorithms, techniques, and performance benchmarking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02031">http://arxiv.org/abs/2309.02031</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Papa, Paolo Russo, Irene Amerini, Luping Zhou</li>
<li>for: 提高vision transformer（ViT）的效率和可扩展性，以便在实际应用中使用。</li>
<li>methods: 研究和分析了四种高效策略，包括减少模型大小、知识传播、量化和减少计算成本。</li>
<li>results: 通过对不同应用场景进行分析和讨论，探讨了现有高效策略的性能。同时，也提出了一些未来研究的挑战和机遇。<details>
<summary>Abstract</summary>
Vision Transformer (ViT) architectures are becoming increasingly popular and widely employed to tackle computer vision applications. Their main feature is the capacity to extract global information through the self-attention mechanism, outperforming earlier convolutional neural networks. However, ViT deployment and performance have grown steadily with their size, number of trainable parameters, and operations. Furthermore, self-attention's computational and memory cost quadratically increases with the image resolution. Generally speaking, it is challenging to employ these architectures in real-world applications due to many hardware and environmental restrictions, such as processing and computational capabilities. Therefore, this survey investigates the most efficient methodologies to ensure sub-optimal estimation performances. More in detail, four efficient categories will be analyzed: compact architecture, pruning, knowledge distillation, and quantization strategies. Moreover, a new metric called Efficient Error Rate has been introduced in order to normalize and compare models' features that affect hardware devices at inference time, such as the number of parameters, bits, FLOPs, and model size. Summarizing, this paper firstly mathematically defines the strategies used to make Vision Transformer efficient, describes and discusses state-of-the-art methodologies, and analyzes their performances over different application scenarios. Toward the end of this paper, we also discuss open challenges and promising research directions.
</details>
<details>
<summary>摘要</summary>
computer vision 应用中vision transformer（ViT）架构受到越来越多的关注和推广使用，主要特点是通过自注意机制提取全局信息，超越了先前的卷积神经网络。然而，ViT的部署和性能随其大小、可训练参数数量和运算数量的增长。此外，自注意的计算和内存成本随图像分辨率的增长而呈 quadratic 增长。因此，在真实世界应用中使用这些架构很困难，主要因为硬件和环境限制，如处理和计算能力。因此，本纪要Investigate the most efficient methodologies to ensure sub-optimal estimation performances。具体来说，本文分析了四种高效的类别：压缩架构、采样、知识继承和量化策略。此外，我们还引入了一个新的度量，称为高效错误率，以便对各种模型的特征进行Normalize和比较，这些特征在推理时影响硬件设备，如参数数量、位数、FLOPs和模型大小。总之，本文首先数学定义了使Vision Transformer高效的策略，描述了和讨论了当前领域的状态泰尊方法，并对不同应用场景进行了分析。在本文的末尾，我们还讨论了开放的挑战和潜在的研究方向。
</details></li>
</ul>
<hr>
<h2 id="RawHDR-High-Dynamic-Range-Image-Reconstruction-from-a-Single-Raw-Image"><a href="#RawHDR-High-Dynamic-Range-Image-Reconstruction-from-a-Single-Raw-Image" class="headerlink" title="RawHDR: High Dynamic Range Image Reconstruction from a Single Raw Image"></a>RawHDR: High Dynamic Range Image Reconstruction from a Single Raw Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02020">http://arxiv.org/abs/2309.02020</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jackzou233/rawhdr">https://github.com/jackzou233/rawhdr</a></li>
<li>paper_authors: Yunhao Zou, Chenggang Yan, Ying Fu</li>
<li>for: 这 paper 的目的是生成高动态范围 (HDR) 图像，从 Raw 感知器数据中恢复场景信息。</li>
<li>methods: 该 paper 使用了一种专门为 Raw 图像设计的模型，利用 Raw 数据的特点来促进 Raw-to-HDR 映射。具体来说，它学习了曝光面积来分 distinguishing 高动态场景中的软和硬区。然后，它引入了两种重要的导航：双感知导航和全球空间导航，以帮助恢复场景信息。</li>
<li>results: 该 paper 的实验表明，提出的 Raw-to-HDR 重建模型在训练和测试 datasets 上具有superiority，同时新captured dataset 也在实验中得到了验证。<details>
<summary>Abstract</summary>
High dynamic range (HDR) images capture much more intensity levels than standard ones. Current methods predominantly generate HDR images from 8-bit low dynamic range (LDR) sRGB images that have been degraded by the camera processing pipeline. However, it becomes a formidable task to retrieve extremely high dynamic range scenes from such limited bit-depth data. Unlike existing methods, the core idea of this work is to incorporate more informative Raw sensor data to generate HDR images, aiming to recover scene information in hard regions (the darkest and brightest areas of an HDR scene). To this end, we propose a model tailor-made for Raw images, harnessing the unique features of Raw data to facilitate the Raw-to-HDR mapping. Specifically, we learn exposure masks to separate the hard and easy regions of a high dynamic scene. Then, we introduce two important guidances, dual intensity guidance, which guides less informative channels with more informative ones, and global spatial guidance, which extrapolates scene specifics over an extended spatial domain. To verify our Raw-to-HDR approach, we collect a large Raw/HDR paired dataset for both training and testing. Our empirical evaluations validate the superiority of the proposed Raw-to-HDR reconstruction model, as well as our newly captured dataset in the experiments.
</details>
<details>
<summary>摘要</summary>
高动态范围（HDR）图像捕捉到了标准图像的多倍级别。现有方法主要从8位低动态范围（LDR）sRGB图像中生成HDR图像，这些图像在摄像头处理管道中受到了很大的压缩。然而，从这些有限位数据中恢复极高动态范围场景变得非常困难。与现有方法不同，本工作的核心思想是利用Raw感知器数据来生成HDR图像，以便恢复场景信息在极端区域（HDR场景中最暗和最亮区域）。为此，我们提出了专门为Raw图像设计的模型，利用Raw数据的独特特性来促进Raw-to-HDR映射。具体来说，我们学习出光mask，以分类场景中的困难区域和易于处理区域。然后，我们引入两种重要的导航，分别是双感知导航和全球空间导航。双感知导航使用不具有很多信息的通道与具有更多信息的通道相互拥抱，而全球空间导航通过把场景特点推广到更广泛的空间领域来描述场景。为验证我们的Raw-to-HDR重建模型，我们收集了大量Raw/HDR对应的数据集，用于训练和测试。我们的实验证明了我们提出的Raw-to-HDR重建模型的优越性，以及我们 newly captured数据集在实验中的有用性。
</details></li>
</ul>
<hr>
<h2 id="Logarithmic-Mathematical-Morphology-theory-and-applications"><a href="#Logarithmic-Mathematical-Morphology-theory-and-applications" class="headerlink" title="Logarithmic Mathematical Morphology: theory and applications"></a>Logarithmic Mathematical Morphology: theory and applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02007">http://arxiv.org/abs/2309.02007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillaume Noyel</li>
<li>for:  Addressing the issue of lighting variations in Mathematical Morphology for grey-level functions.</li>
<li>methods:  Defining a new framework called Logarithmic Mathematical Morphology (LMM) with an additive law that varies according to the image amplitude, and using it to define operators that are robust to lighting variations.</li>
<li>results:  Comparing the LMM method with three state-of-the-art approaches on eye-fundus images with non-uniform lighting variations, and showing that the LMM approach has better robustness to such variations.Here’s the full text in Simplified Chinese:</li>
<li>for:  Mathematical Morphology 中的批处理问题，即在图像中处理不同亮度的问题。</li>
<li>methods:  Logarithmic Mathematical Morphology (LMM)  Framework，使用不同亮度的加法则来处理图像，以提高对不同亮度的Robustness。</li>
<li>results:  LMM 方法与三种现有方法进行比较，在不同亮度下的眼膜图像中 segmentation  vessles 的问题上，LMM 方法表现更好，具有更高的Robustness。<details>
<summary>Abstract</summary>
Classically, in Mathematical Morphology, an image (i.e., a grey-level function) is analysed by another image which is named the structuring element or the structuring function. This structuring function is moved over the image domain and summed to the image. However, in an image presenting lighting variations, the analysis by a structuring function should require that its amplitude varies according to the image intensity. Such a property is not verified in Mathematical Morphology for grey level functions, when the structuring function is summed to the image with the usual additive law. In order to address this issue, a new framework is defined with an additive law for which the amplitude of the structuring function varies according to the image amplitude. This additive law is chosen within the Logarithmic Image Processing framework and models the lighting variations with a physical cause such as a change of light intensity or a change of camera exposure-time. The new framework is named Logarithmic Mathematical Morphology (LMM) and allows the definition of operators which are robust to such lighting variations. In images with uniform lighting variations, those new LMM operators perform better than usual morphological operators. In eye-fundus images with non-uniform lighting variations, a LMM method for vessel segmentation is compared to three state-of-the-art approaches. Results show that the LMM approach has a better robustness to such variations than the three others.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Retail-store-customer-behavior-analysis-system-Design-and-Implementation"><a href="#Retail-store-customer-behavior-analysis-system-Design-and-Implementation" class="headerlink" title="Retail store customer behavior analysis system: Design and Implementation"></a>Retail store customer behavior analysis system: Design and Implementation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03232">http://arxiv.org/abs/2309.03232</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuan Dinh Nguyen, Keisuke Hihara, Tung Cao Hoang, Yumeka Utada, Akihiko Torii, Naoki Izumi, Nguyen Thanh Thuy, Long Quoc Tran<br>for: 这个研究的目的是提高零售店内客户满意度，通过个性化服务提供值。methods: 这个研究使用了深度学习技术，包括深度神经网络，来分析客户在店内互动的行为。results: 研究结果表明，使用深度学习技术可以更好地检测客户行为，并提供有用的客户行为数据可视化。<details>
<summary>Abstract</summary>
Understanding customer behavior in retail stores plays a crucial role in improving customer satisfaction by adding personalized value to services. Behavior analysis reveals both general and detailed patterns in the interaction of customers with a store items and other people, providing store managers with insight into customer preferences. Several solutions aim to utilize this data by recognizing specific behaviors through statistical visualization. However, current approaches are limited to the analysis of small customer behavior sets, utilizing conventional methods to detect behaviors. They do not use deep learning techniques such as deep neural networks, which are powerful methods in the field of computer vision. Furthermore, these methods provide limited figures when visualizing the behavioral data acquired by the system. In this study, we propose a framework that includes three primary parts: mathematical modeling of customer behaviors, behavior analysis using an efficient deep learning based system, and individual and group behavior visualization. Each module and the entire system were validated using data from actual situations in a retail store.
</details>
<details>
<summary>摘要</summary>
理解顾客在商场中的行为对于提高顾客满意度具有关键作用。行为分析可以揭示顾客与店内物品和其他人的互动特征，为店长提供顾客偏好的信息。然而，目前的方法受到小型顾客行为集的分析的限制，并且使用传统方法来探测行为。这些方法不使用深度学习技术，如深度神经网络，这些技术在计算机视觉领域具有强大能力。此外，这些方法只能提供有限的行为数据视图。在本研究中，我们提出了一个框架，包括三个主要部分：顾客行为数学模型、深度学习基于系统的行为分析和个人和群体行为视图。每个模块和整个系统都被使用实际情况中的商场数据验证。
</details></li>
</ul>
<hr>
<h2 id="NICE-CVPR-2023-Challenge-on-Zero-shot-Image-Captioning"><a href="#NICE-CVPR-2023-Challenge-on-Zero-shot-Image-Captioning" class="headerlink" title="NICE: CVPR 2023 Challenge on Zero-shot Image Captioning"></a>NICE: CVPR 2023 Challenge on Zero-shot Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01961">http://arxiv.org/abs/2309.01961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taehoon Kim, Pyunghwan Ahn, Sangyun Kim, Sihaeng Lee, Mark Marsden, Alessandra Sala, Seung Hwan Kim, Bohyung Han, Kyoung Mu Lee, Honglak Lee, Kyounghoon Bae, Xiangyu Wu, Yi Gao, Hailiang Zhang, Yang Yang, Weili Guo, Jianfeng Lu, Youngtaek Oh, Jae Won Cho, Dong-jin Kim, In So Kweon, Junmo Kim, Wooyoung Kang, Won Young Jhoo, Byungseok Roh, Jonghwan Mun, Solgil Oh, Kenan Emir Ak, Gwang-Gook Lee, Yan Xu, Mingwei Shen, Kyomin Hwang, Wonsik Shin, Kamin Lee, Wonhark Park, Dongkwan Lee, Nojun Kwak, Yujin Wang, Yimu Wang, Tiancheng Gu, Xingchang Lv, Mingmao Sun</li>
<li>for: 挑战计划推动计算机视觉领域内的模型精度和公平性进步。</li>
<li>methods: 使用新的评估数据集，挑战计算机视觉模型在多个领域中处理新类型的图像描述。</li>
<li>results: 挑战结果包括新的评估数据集、评估方法和优秀入选结果等，帮助提高各种视觉语言任务的AI模型。<details>
<summary>Abstract</summary>
In this report, we introduce NICE (New frontiers for zero-shot Image Captioning Evaluation) project and share the results and outcomes of 2023 challenge. This project is designed to challenge the computer vision community to develop robust image captioning models that advance the state-of-the-art both in terms of accuracy and fairness. Through the challenge, the image captioning models were tested using a new evaluation dataset that includes a large variety of visual concepts from many domains. There was no specific training data provided for the challenge, and therefore the challenge entries were required to adapt to new types of image descriptions that had not been seen during training. This report includes information on the newly proposed NICE dataset, evaluation methods, challenge results, and technical details of top-ranking entries. We expect that the outcomes of the challenge will contribute to the improvement of AI models on various vision-language tasks.
</details>
<details>
<summary>摘要</summary>
在这份报告中，我们介绍了NICE（新领域零基础图像描述评价）项目，并分享2023年度挑战的结果和成果。这个项目的目的是挑战计算机视觉社区，以开发能够在精度和公平性两个方面提高的图像描述模型。通过挑战，图像描述模型被测试使用了一个新的评价数据集，该数据集包含了多个视觉领域的各种图像描述。没有提供专门的训练数据，因此挑战参赛作品需要适应新的图像描述类型，这些类型在训练过程中未被见过。这份报告包括NICE数据集的新提案、评价方法、挑战结果以及技术细节。我们期望这些成果将对各种视觉语言任务的AI模型产生改进。
</details></li>
</ul>
<hr>
<h2 id="Empowering-Low-Light-Image-Enhancer-through-Customized-Learnable-Priors"><a href="#Empowering-Low-Light-Image-Enhancer-through-Customized-Learnable-Priors" class="headerlink" title="Empowering Low-Light Image Enhancer through Customized Learnable Priors"></a>Empowering Low-Light Image Enhancer through Customized Learnable Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01958">http://arxiv.org/abs/2309.01958</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zheng980629/cue">https://github.com/zheng980629/cue</a></li>
<li>paper_authors: Naishan Zheng, Man Zhou, Yanmeng Dong, Xiangyu Rui, Jie Huang, Chongyi Li, Feng Zhao</li>
<li>for: 提高低光照图像的品质，提高图像的亮度和降低噪音。</li>
<li>methods: 使用自定义学习的偏好来改进深度 unfolding 架构的透明度和解释能力，包括结构流和优化流两种方法。</li>
<li>results: 对多个低光照图像进行了广泛的实验，并证明了我们提出的方法在比 estado del arte 方法之上有superiority。<details>
<summary>Abstract</summary>
Deep neural networks have achieved remarkable progress in enhancing low-light images by improving their brightness and eliminating noise. However, most existing methods construct end-to-end mapping networks heuristically, neglecting the intrinsic prior of image enhancement task and lacking transparency and interpretability. Although some unfolding solutions have been proposed to relieve these issues, they rely on proximal operator networks that deliver ambiguous and implicit priors. In this work, we propose a paradigm for low-light image enhancement that explores the potential of customized learnable priors to improve the transparency of the deep unfolding paradigm. Motivated by the powerful feature representation capability of Masked Autoencoder (MAE), we customize MAE-based illumination and noise priors and redevelop them from two perspectives: 1) \textbf{structure flow}: we train the MAE from a normal-light image to its illumination properties and then embed it into the proximal operator design of the unfolding architecture; and m2) \textbf{optimization flow}: we train MAE from a normal-light image to its gradient representation and then employ it as a regularization term to constrain noise in the model output. These designs improve the interpretability and representation capability of the model.Extensive experiments on multiple low-light image enhancement datasets demonstrate the superiority of our proposed paradigm over state-of-the-art methods. Code is available at https://github.com/zheng980629/CUE.
</details>
<details>
<summary>摘要</summary>
深度神经网络已经取得了优化低光照图像的remarkable进步，提高图像的亮度和降低噪声。然而，大多数现有方法是通过规则性的映射网络来实现，忽略了图像优化任务的内在先验知识，lacking transparency和可读性。虽然一些解开解决方案已经被提出，但它们基于 proximal operator networks，导致权重不明确和隐式先验知识。在这种情况下，我们提出了一种低光照图像优化 paradigma，exploring the potential of customized learnable priors to improve the transparency of the deep unfolding paradigm。我们的方法是通过以下两种方法来改进 interpretable和 representation capability of the model：1. 结构流：我们从一个正常光照图像开始，通过训练MAE来学习图像的照明特性，然后将其embed到 proximal operator 设计中。2. 优化流：我们从一个正常光照图像开始，通过训练MAE来学习图像的梯度表示，然后使其作为模型输出中的常数约束项。我们的方法在多个低光照图像优化数据集上进行了广泛的实验，并证明了我们的方法的优越性。代码可以在https://github.com/zheng980629/CUE中找到。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Bayesian-Computational-Imaging-with-a-Surrogate-Score-Based-Prior"><a href="#Efficient-Bayesian-Computational-Imaging-with-a-Surrogate-Score-Based-Prior" class="headerlink" title="Efficient Bayesian Computational Imaging with a Surrogate Score-Based Prior"></a>Efficient Bayesian Computational Imaging with a Surrogate Score-Based Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01949">http://arxiv.org/abs/2309.01949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Berthy T. Feng, Katherine L. Bouman</li>
<li>for: 这个论文的目的是提出一种代理函数，以便高效地使用分数基的先验知识来解决难定的图像重构问题。</li>
<li>methods: 这个论文使用了分数基扩散模型，将其转化为probabilistic priors，以解决难定的图像重构问题。</li>
<li>results:  compared to之前的精确先验，这个代理先验可以加速对大型图像的变量推理的优化，至少提高两个数量级。此外，我们的原则途径也可以获得更高的准确性图像，比非泊尔baseline。<details>
<summary>Abstract</summary>
We propose a surrogate function for efficient use of score-based priors for Bayesian inverse imaging. Recent work turned score-based diffusion models into probabilistic priors for solving ill-posed imaging problems by appealing to an ODE-based log-probability function. However, evaluating this function is computationally inefficient and inhibits posterior estimation of high-dimensional images. Our proposed surrogate prior is based on the evidence lower-bound of a score-based diffusion model. We demonstrate the surrogate prior on variational inference for efficient approximate posterior sampling of large images. Compared to the exact prior in previous work, our surrogate prior accelerates optimization of the variational image distribution by at least two orders of magnitude. We also find that our principled approach achieves higher-fidelity images than non-Bayesian baselines that involve hyperparameter-tuning at inference. Our work establishes a practical path forward for using score-based diffusion models as general-purpose priors for imaging.
</details>
<details>
<summary>摘要</summary>
我们提议一种代理函数，以便高效地使用分数基金函数对bayesian反射干涉进行减少。在最近的工作中，将分数基 diffusion 模型转换成了 probabilistic prior，以解决ill-posed imaging问题。然而，计算这个函数的计算复杂度高，使得 posterior 估计高维图像的权重估计受到限制。我们的提议的代理假设基于分数基 diffusion 模型的证据下界。我们在变量推理中使用这种代理假设，以便高效地批量样本大图像的变量分布。与前一个工作中的精确假设相比，我们的代理假设可以加速变量图像分布的估计，至少提高两个数量级。此外，我们发现我们的原则途径可以在非泊利基eline上实现更高的图像质量。我们的工作建立了使用分数基 diffusion 模型作为通用假设的实用方法，以解决反射干涉问题。
</details></li>
</ul>
<hr>
<h2 id="Extract-and-Adaptation-Network-for-3D-Interacting-Hand-Mesh-Recovery"><a href="#Extract-and-Adaptation-Network-for-3D-Interacting-Hand-Mesh-Recovery" class="headerlink" title="Extract-and-Adaptation Network for 3D Interacting Hand Mesh Recovery"></a>Extract-and-Adaptation Network for 3D Interacting Hand Mesh Recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01943">http://arxiv.org/abs/2309.01943</a></li>
<li>repo_url: None</li>
<li>paper_authors: JoonKyu Park, Daniel Sungho Jung, Gyeongsik Moon, Kyoung Mu Lee</li>
<li>for: 本研究旨在提高3D互动手套逻辑恢复的准确性，即使两手的姿势很不同。</li>
<li>methods: 我们提出了一种名为EANet的提取和适应网络，其中包括EABlock作为网络的主要组件。而不是直接使用两手特征作为输入 токен，我们的EABlock使用了两种新的类型的特征 токен：SimToken和JoinToken。这两种特征 токен是从分离的两手特征组合而成，因此更 robust于远程特征问题。</li>
<li>results: 我们的EANet实现了3D互动手套测试benchmark上的状态之最好性能。代码可以在<a target="_blank" rel="noopener" href="https://github.com/jkpark0825/EANet%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/jkpark0825/EANet中下载。</a><details>
<summary>Abstract</summary>
Understanding how two hands interact with each other is a key component of accurate 3D interacting hand mesh recovery. However, recent Transformer-based methods struggle to learn the interaction between two hands as they directly utilize two hand features as input tokens, which results in distant token problem. The distant token problem represents that input tokens are in heterogeneous spaces, leading Transformer to fail in capturing correlation between input tokens. Previous Transformer-based methods suffer from the problem especially when poses of two hands are very different as they project features from a backbone to separate left and right hand-dedicated features. We present EANet, extract-and-adaptation network, with EABlock, the main component of our network. Rather than directly utilizing two hand features as input tokens, our EABlock utilizes two complementary types of novel tokens, SimToken and JoinToken, as input tokens. Our two novel tokens are from a combination of separated two hand features; hence, it is much more robust to the distant token problem. Using the two type of tokens, our EABlock effectively extracts interaction feature and adapts it to each hand. The proposed EANet achieves the state-of-the-art performance on 3D interacting hands benchmarks. The codes are available at https://github.com/jkpark0825/EANet.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose EANet, an extract-and-adaptation network that utilizes two novel types of tokens, SimToken and JoinToken, as input tokens. These tokens are derived from a combination of separated two hand features, making them more robust to the distant token problem. Our EABlock effectively extracts interaction features and adapts them to each hand using these tokens.The proposed EANet achieves state-of-the-art performance on 3D interacting hands benchmarks. The codes are available at https://github.com/jkpark0825/EANet.
</details></li>
</ul>
<hr>
<h2 id="DR-Pose-A-Two-stage-Deformation-and-Registration-Pipeline-for-Category-level-6D-Object-Pose-Estimation"><a href="#DR-Pose-A-Two-stage-Deformation-and-Registration-Pipeline-for-Category-level-6D-Object-Pose-Estimation" class="headerlink" title="DR-Pose: A Two-stage Deformation-and-Registration Pipeline for Category-level 6D Object Pose Estimation"></a>DR-Pose: A Two-stage Deformation-and-Registration Pipeline for Category-level 6D Object Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01925">http://arxiv.org/abs/2309.01925</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zray26/dr-pose">https://github.com/zray26/dr-pose</a></li>
<li>paper_authors: Lei Zhou, Zhiyang Liu, Runze Gan, Haozhe Wang, Marcelo H. Ang Jr</li>
<li>for: 提高对象pose estimation的精度，使用两个阶段管道设计</li>
<li>methods: 使用完成帮助型折叠阶段和缩放注册阶段，首先使用点云完成方法生成目标对象的未见部分，然后使用注册网络提取pose敏感特征并预测对象部分点云在坐标空间的表示</li>
<li>results: 在CAMERA25和REAL275测试数据集上，DR-Pose比前状态艺术形式基于方法提供了更高的精度Here’s the same information in Simplified Chinese:</li>
<li>for: 提高对象pose estimation的精度，使用两个阶段管道设计</li>
<li>methods: 使用完成帮助型折叠阶段和缩放注册阶段，首先使用点云完成方法生成目标对象的未见部分，然后使用注册网络提取pose敏感特征并预测对象部分点云在坐标空间的表示</li>
<li>results: 在CAMERA25和REAL275测试数据集上，DR-Pose比前状态艺术形式基于方法提供了更高的精度<details>
<summary>Abstract</summary>
Category-level object pose estimation involves estimating the 6D pose and the 3D metric size of objects from predetermined categories. While recent approaches take categorical shape prior information as reference to improve pose estimation accuracy, the single-stage network design and training manner lead to sub-optimal performance since there are two distinct tasks in the pipeline. In this paper, the advantage of two-stage pipeline over single-stage design is discussed. To this end, we propose a two-stage deformation-and registration pipeline called DR-Pose, which consists of completion-aided deformation stage and scaled registration stage. The first stage uses a point cloud completion method to generate unseen parts of target object, guiding subsequent deformation on the shape prior. In the second stage, a novel registration network is designed to extract pose-sensitive features and predict the representation of object partial point cloud in canonical space based on the deformation results from the first stage. DR-Pose produces superior results to the state-of-the-art shape prior-based methods on both CAMERA25 and REAL275 benchmarks. Codes are available at https://github.com/Zray26/DR-Pose.git.
</details>
<details>
<summary>摘要</summary>
Category-level object pose estimation 涉及到对 predetermined categories 中对象的 6D 姿 pose 和 3D  метри尺度的估算。Recent approaches 使用 categorical shape prior information 作为参考来提高姿 pose 估算精度，但是单Stage 网络设计和训练方式会导致下游表现不佳，因为这有两个不同的任务在管道中。在本文中，我们讨论了 two-stage 管道的优势。为了实现这一目标，我们提出了一种 two-stage deformation-and registration 管道，称为 DR-Pose，它包括 completion-aided deformation stage 和 scaled registration stage。在第一个阶段中，我们使用一种点云完成方法来生成目标对象的未看到部分，并用这些部分作为导向后续形态变换的引导。在第二个阶段中，我们设计了一种新的注册网络，用于提取姿 pose-sensitive 特征并预测对象 partial point cloud 在 canonical space 中的表示，基于形态变换结果。DR-Pose 在 CAMERA25 和 REAL275 测试准则上produce了与shape prior-based方法相比的更高精度结果。codes 可以在 <https://github.com/Zray26/DR-Pose.git> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Causal-Scoring-Medical-Image-Explanations-A-Case-Study-On-Ex-vivo-Kidney-Stone-Images"><a href="#Causal-Scoring-Medical-Image-Explanations-A-Case-Study-On-Ex-vivo-Kidney-Stone-Images" class="headerlink" title="Causal Scoring Medical Image Explanations: A Case Study On Ex-vivo Kidney Stone Images"></a>Causal Scoring Medical Image Explanations: A Case Study On Ex-vivo Kidney Stone Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01921">http://arxiv.org/abs/2309.01921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Armando Villegas-Jimenez, Daniel Flores-Araiza, Francisco Lopez-Tiro, Gilberto Ochoa-Ruiz andand Christian Daul</li>
<li>for: 本研究旨在提供一种量化测试explainable方法的效果，以便不同水平的用户都能够理解模型输出的 causa causal relationships。</li>
<li>methods: 本研究使用了一种名为Causal Explanation Score（CaES）的技术，该技术可以量化测试explainable方法的效果，并且可以对不同水平的用户进行个性化的评估。</li>
<li>results: 实验结果表明，CaES可以提供更好的量化测试结果，并且可以帮助用户更好地理解模型输出的causal relationships。<details>
<summary>Abstract</summary>
On the promise that if human users know the cause of an output, it would enable them to grasp the process responsible for the output, and hence provide understanding, many explainable methods have been proposed to indicate the cause for the output of a model based on its input. Nonetheless, little has been reported on quantitative measurements of such causal relationships between the inputs, the explanations, and the outputs of a model, leaving the assessment to the user, independent of his level of expertise in the subject. To address this situation, we explore a technique for measuring the causal relationship between the features from the area of the object of interest in the images of a class and the output of a classifier. Our experiments indicate improvement in the causal relationships measured when the area of the object of interest per class is indicated by a mask from an explainable method than when it is indicated by human annotators. Hence the chosen name of Causal Explanation Score (CaES)
</details>
<details>
<summary>摘要</summary>
“由于知道输出的原因可以让人类用户理解模型的处理过程，因此许多可解释方法已经被提出来表示模型的输出和输入之间的原因关系。然而，很少有报告关于量化测量这些 causal 关系的方法， leaving the assessment to the user, regardless of their level of expertise in the subject.为解决这个问题，我们研究了一种测量模型输出和输入之间的 causal 关系的技术。我们的实验表明，当使用可解释方法指定模型输出的区域对象的像素点时， causal 关系的测量得到了改进，而不是由人工标注器指定。因此，我们选择了名为 Causal Explanation Score（CaES）的技术。”
</details></li>
</ul>
<hr>
<h2 id="Improving-Drone-Imagery-For-Computer-Vision-Machine-Learning-in-Wilderness-Search-and-Rescue"><a href="#Improving-Drone-Imagery-For-Computer-Vision-Machine-Learning-in-Wilderness-Search-and-Rescue" class="headerlink" title="Improving Drone Imagery For Computer Vision&#x2F;Machine Learning in Wilderness Search and Rescue"></a>Improving Drone Imagery For Computer Vision&#x2F;Machine Learning in Wilderness Search and Rescue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01904">http://arxiv.org/abs/2309.01904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/crasar/wisar">https://github.com/crasar/wisar</a></li>
<li>paper_authors: Robin Murphy, Thomas Manzini</li>
<li>for: 本研究旨在掌握无人机成像数据的搜寻问题，以便在计算机视觉&#x2F;机器学习（CV&#x2F;ML）模型的后处理中使用。</li>
<li>methods: 本研究提出五项建议，以提高无人机成像数据的适用性。这些建议包括在搜寻阶段使用自动化数据收集软件，以及根据计算机视觉&#x2F;机器学习模型的特点进行飞行优化。</li>
<li>results: 本研究通过使用2023年日本 Wu-Murad搜寻案例进行实证研究，发现大量的搜寻数据可以通过计算机视觉&#x2F;机器学习技术进行自动化分析，从而提高搜寻效率。<details>
<summary>Abstract</summary>
This paper describes gaps in acquisition of drone imagery that impair the use with computer vision/machine learning (CV/ML) models and makes five recommendations to maximize image suitability for CV/ML post-processing. It describes a notional work process for the use of drones in wilderness search and rescue incidents. The large volume of data from the wide area search phase offers the greatest opportunity for CV/ML techniques because of the large number of images that would otherwise have to be manually inspected. The 2023 Wu-Murad search in Japan, one of the largest missing person searches conducted in that area, serves as a case study. Although drone teams conducting wide area searches may not know in advance if the data they collect is going to be used for CV/ML post-processing, there are data collection procedures that can improve the search in general with automated collection software. If the drone teams do expect to use CV/ML, then they can exploit knowledge about the model to further optimize flights.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这篇文章描述了无人机图像获取的缺陷，并提出五项建议来最大化图像的适用性 для计算机视觉/机器学习（CV/ML）模型的后处理。文章还描述了一种假设的无人机在远程搜索和救援任务中的应用。在广泛搜索阶段中，由于图像的大量数据，CV/ML技术可以更加有效，因为可以避免大量的手动检查。2023年在日本的武村搜索是一个最大的失踪人搜索案例，作为案例研究。虽然无人机队在广搜案件中可能不知道他们的数据将被用于CV/ML后处理，但是他们可以通过自动收集软件来改进搜索。如果无人机队知道他们的数据将被用于CV/ML，那么他们可以根据模型的知识来进一步优化飞行。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Plant-Disease-Diagnosis-with-Hard-sample-Re-mining-Strategy"><a href="#Towards-Robust-Plant-Disease-Diagnosis-with-Hard-sample-Re-mining-Strategy" class="headerlink" title="Towards Robust Plant Disease Diagnosis with Hard-sample Re-mining Strategy"></a>Towards Robust Plant Disease Diagnosis with Hard-sample Re-mining Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01903">http://arxiv.org/abs/2309.01903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quan Huu Cap, Atsushi Fukuda, Satoshi Kagiwada, Hiroyuki Uga, Nobusuke Iwasaki, Hitoshi Iyatomi</li>
<li>For: 提高自动植物疾病诊断系统的准确率和效率，特别是处理大量未标注的健康数据。* Methods: 提出了一种简单 yet effective 的训练策略 called hard-sample re-mining (HSReM)，通过筛选适度难度的训练图像来提高健康数据的诊断性能并同时提高疾病数据的诊断性能。* Results: 对于实际的Field eight-class cucumber和ten-class tomato数据集（42.7K和35.6K张图像）进行了实验，结果表明，使用 HSReM 训练策略可以提高大规模未seen数据的总诊断性能，并且比原始 объек detection 模型和分类基于 EfficientNetV2-Large 模型更高。<details>
<summary>Abstract</summary>
With rich annotation information, object detection-based automated plant disease diagnosis systems (e.g., YOLO-based systems) often provide advantages over classification-based systems (e.g., EfficientNet-based), such as the ability to detect disease locations and superior classification performance. One drawback of these detection systems is dealing with unannotated healthy data with no real symptoms present. In practice, healthy plant data appear to be very similar to many disease data. Thus, those models often produce mis-detected boxes on healthy images. In addition, labeling new data for detection models is typically time-consuming. Hard-sample mining (HSM) is a common technique for re-training a model by using the mis-detected boxes as new training samples. However, blindly selecting an arbitrary amount of hard-sample for re-training will result in the degradation of diagnostic performance for other diseases due to the high similarity between disease and healthy data. In this paper, we propose a simple but effective training strategy called hard-sample re-mining (HSReM), which is designed to enhance the diagnostic performance of healthy data and simultaneously improve the performance of disease data by strategically selecting hard-sample training images at an appropriate level. Experiments based on two practical in-field eight-class cucumber and ten-class tomato datasets (42.7K and 35.6K images) show that our HSReM training strategy leads to a substantial improvement in the overall diagnostic performance on large-scale unseen data. Specifically, the object detection model trained using the HSReM strategy not only achieved superior results as compared to the classification-based state-of-the-art EfficientNetV2-Large model and the original object detection model, but also outperformed the model using the HSM strategy.
</details>
<details>
<summary>摘要</summary>
With rich annotation information, 对 automatized plant disease diagnosis system (e.g., YOLO-based system) 来说，具有病变部署的方式比 классификаation-based system (e.g., EfficientNet-based) 有所优势，如病变部署和高精度的分类性能。然而，这些检测系统面临着处理无标注的健康数据的挑战，因为健康植物数据和疾病数据很相似。因此，这些模型通常会在健康图像上产生错误的框架。此外，为检测模型增加新数据标注是时间消耗的。为了解决这个问题，我们提出了一种简单 yet effective 的训练策略，即 hard-sample re-mining (HSReM)，它可以提高健康数据的诊断性能，同时也可以提高疾病数据的诊断性能。我们在两个实际的大规模验证 dataset (42.7K和35.6K图像) 上进行了实验，结果表明，使用 HSReM 训练策略可以在大规模未看到的数据上提高总诊断性能。具体来说，使用 HSReM 训练模型不仅超过了基于类型的 state-of-the-art EfficientNetV2-Large 模型和原始检测模型，还超过了使用 HSM 策略的模型。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Skin-Lesion-Segmentation-via-Structural-Entropy-Minimization-on-Multi-Scale-Superpixel-Graphs"><a href="#Unsupervised-Skin-Lesion-Segmentation-via-Structural-Entropy-Minimization-on-Multi-Scale-Superpixel-Graphs" class="headerlink" title="Unsupervised Skin Lesion Segmentation via Structural Entropy Minimization on Multi-Scale Superpixel Graphs"></a>Unsupervised Skin Lesion Segmentation via Structural Entropy Minimization on Multi-Scale Superpixel Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01899">http://arxiv.org/abs/2309.01899</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/selgroup/sled">https://github.com/selgroup/sled</a></li>
<li>paper_authors: Guangjie Zeng, Hao Peng, Angsheng Li, Zhiwei Liu, Chunyang Liu, Philip S. Yu, Lifang He</li>
<li>For: 这个论文的目的是提出一种新的无监督性肤肉病变分割方法，以解决现有深度学习方法缺乏可解释性的问题。* Methods: 这种方法基于结构 entropy和孤岛森林异常检测，使用了superpixel图构建自dermoscopic图像，然后使用多尺度异常检测来提高分割精度。* Results: 在四个肤肉病变benchmark上进行了实验，并与九种代表性的无监督分割方法进行比较。实验结果表明提案的方法具有优越性，同时还进行了一些 caso study来证明方法的有效性。<details>
<summary>Abstract</summary>
Skin lesion segmentation is a fundamental task in dermoscopic image analysis. The complex features of pixels in the lesion region impede the lesion segmentation accuracy, and existing deep learning-based methods often lack interpretability to this problem. In this work, we propose a novel unsupervised Skin Lesion sEgmentation framework based on structural entropy and isolation forest outlier Detection, namely SLED. Specifically, skin lesions are segmented by minimizing the structural entropy of a superpixel graph constructed from the dermoscopic image. Then, we characterize the consistency of healthy skin features and devise a novel multi-scale segmentation mechanism by outlier detection, which enhances the segmentation accuracy by leveraging the superpixel features from multiple scales. We conduct experiments on four skin lesion benchmarks and compare SLED with nine representative unsupervised segmentation methods. Experimental results demonstrate the superiority of the proposed framework. Additionally, some case studies are analyzed to demonstrate the effectiveness of SLED.
</details>
<details>
<summary>摘要</summary>
皮肤病变分割是肤肤影像分析的基本任务。病变区域像素特征的复杂性使得病变分割精度受到限制，现有的深度学习基于方法frequently lack interpretability to this problem. In this work, we propose a novel unsupervised Skin Lesion Segmentation framework based on structural entropy and isolation forest outlier Detection, namely SLED. Specifically, skin lesions are segmented by minimizing the structural entropy of a superpixel graph constructed from the dermoscopic image. Then, we characterize the consistency of healthy skin features and devise a novel multi-scale segmentation mechanism by outlier detection, which enhances the segmentation accuracy by leveraging the superpixel features from multiple scales. We conduct experiments on four skin lesion benchmarks and compare SLED with nine representative unsupervised segmentation methods. Experimental results demonstrate the superiority of the proposed framework. Additionally, some case studies are analyzed to demonstrate the effectiveness of SLED.Here's the translation in Traditional Chinese:皮肤病变分割是肤肤影像分析的基本任务。病变区域像素特征的复杂性使得病变分割精度受到限制，现有的深度学习基于方法frequently lack interpretability to this problem. In this work, we propose a novel unsupervised Skin Lesion Segmentation framework based on structural entropy and isolation forest outlier Detection, namely SLED. Specifically, skin lesions are segmented by minimizing the structural entropy of a superpixel graph constructed from the dermoscopic image. Then, we characterize the consistency of healthy skin features and devise a novel multi-scale segmentation mechanism by outlier detection, which enhances the segmentation accuracy by leveraging the superpixel features from multiple scales. We conduct experiments on four skin lesion benchmarks and compare SLED with nine representative unsupervised segmentation methods. Experimental results demonstrate the superiority of the proposed framework. Additionally, some case studies are analyzed to demonstrate the effectiveness of SLED.
</details></li>
</ul>
<hr>
<h2 id="Gradient-Domain-Diffusion-Models-for-Image-Synthesis"><a href="#Gradient-Domain-Diffusion-Models-for-Image-Synthesis" class="headerlink" title="Gradient Domain Diffusion Models for Image Synthesis"></a>Gradient Domain Diffusion Models for Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01875">http://arxiv.org/abs/2309.01875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 本研究旨在提高扩散模型在生成图像和视频 sintesis 中的效率，通过在梯度领域进行扩散过程。</li>
<li>methods: 本研究提议在梯度领域进行扩散过程，利用梯度领域的特点，即梯度领域与原始图像领域之间的数学等价性，以及梯度领域的稀疏性，使扩散过程更快 converges。</li>
<li>results: 数值实验表明，梯度领域扩散模型比原始扩散模型更高效。这种方法可以在图像处理、计算机视觉和机器学习任务中应用。<details>
<summary>Abstract</summary>
Diffusion models are getting popular in generative image and video synthesis. However, due to the diffusion process, they require a large number of steps to converge. To tackle this issue, in this paper, we propose to perform the diffusion process in the gradient domain, where the convergence becomes faster. There are two reasons. First, thanks to the Poisson equation, the gradient domain is mathematically equivalent to the original image domain. Therefore, each diffusion step in the image domain has a unique corresponding gradient domain representation. Second, the gradient domain is much sparser than the image domain. As a result, gradient domain diffusion models converge faster. Several numerical experiments confirm that the gradient domain diffusion models are more efficient than the original diffusion models. The proposed method can be applied in a wide range of applications such as image processing, computer vision and machine learning tasks.
</details>
<details>
<summary>摘要</summary>
Diffusion模型在生成图像和视频 синтеisis中越来越受欢迎。然而，由于扩散过程，它们需要大量的步骤以至于相对较慢。在这篇论文中，我们提议在梯度领域进行扩散过程，这会使扩散过程更快。我们有两点原因：首先，由于波尔兹方程，梯度领域与原始图像领域之间存在数学等价关系，因此每个扩散步骤在图像领域有唯一的对应梯度领域表示。其次，梯度领域比图像领域更加稀疏，因此梯度领域的扩散模型更快 converges。我们通过多个数学实验证明，梯度领域扩散模型比原始扩散模型更高效。该方法可以应用于广泛的图像处理、计算机视觉和机器学习任务。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/05/cs.CV_2023_09_05/" data-id="clmvt7t9m00ci26rd45c1ckme" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/05/cs.AI_2023_09_05/" class="article-date">
  <time datetime="2023-09-05T12:00:00.000Z" itemprop="datePublished">2023-09-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/05/cs.AI_2023_09_05/">cs.AI - 2023-09-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Utilizing-Generative-Adversarial-Networks-for-Stable-Structure-Generation-in-Angry-Birds"><a href="#Utilizing-Generative-Adversarial-Networks-for-Stable-Structure-Generation-in-Angry-Birds" class="headerlink" title="Utilizing Generative Adversarial Networks for Stable Structure Generation in Angry Birds"></a>Utilizing Generative Adversarial Networks for Stable Structure Generation in Angry Birds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02614">http://arxiv.org/abs/2309.02614</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Blaxzter/Utilizing-Generative-Adversarial-Networks-for-Stable-Structure-Generation-in-Angry-Birds">https://github.com/Blaxzter/Utilizing-Generative-Adversarial-Networks-for-Stable-Structure-Generation-in-Angry-Birds</a></li>
<li>paper_authors: Frederic Abraham, Matthew Stephenson</li>
<li>for:  investigate the suitability of using Generative Adversarial Networks (GANs) to generate stable structures for the physics-based puzzle game Angry Birds.</li>
<li>methods:  using a detailed encoding&#x2F;decoding process to convert between Angry Birds level descriptions and a suitable grid-based representation, and utilizing state-of-the-art GAN architectures and training methods to produce new structure designs.</li>
<li>results:  GANs can be successfully applied to generate a varied range of complex and stable Angry Birds structures.<details>
<summary>Abstract</summary>
This paper investigates the suitability of using Generative Adversarial Networks (GANs) to generate stable structures for the physics-based puzzle game Angry Birds. While previous applications of GANs for level generation have been mostly limited to tile-based representations, this paper explores their suitability for creating stable structures made from multiple smaller blocks. This includes a detailed encoding/decoding process for converting between Angry Birds level descriptions and a suitable grid-based representation, as well as utilizing state-of-the-art GAN architectures and training methods to produce new structure designs. Our results show that GANs can be successfully applied to generate a varied range of complex and stable Angry Birds structures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Detection-of-Unknown-Unknowns-in-Cyber-Physical-Systems-using-Statistical-Conformance-with-Physics-Guided-Process-Models"><a href="#Detection-of-Unknown-Unknowns-in-Cyber-Physical-Systems-using-Statistical-Conformance-with-Physics-Guided-Process-Models" class="headerlink" title="Detection of Unknown-Unknowns in Cyber-Physical Systems using Statistical Conformance with Physics Guided Process Models"></a>Detection of Unknown-Unknowns in Cyber-Physical Systems using Statistical Conformance with Physics Guided Process Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02603">http://arxiv.org/abs/2309.02603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aranyak Maity, Ayan Banerjee, Sandeep Gupta</li>
<li>for: 这 paper 是关于 cyber-physical system  unknown unknown 情况下的分析和评估的研究。</li>
<li>methods: 该 paper 使用 dynamics-induced hybrid recurrent neural networks (DiH-RNN) 和 physics-guided surrogate model (PGSM) 来检测 operational output 特性的模型兼容性。</li>
<li>results: 该 paper 通过使用 DiH-RNN 和 PGSM 检测 operational output 特性的模型兼容性，可以检测到 unknown insulin cartridge errors 的影响。<details>
<summary>Abstract</summary>
Unknown unknowns are operational scenarios in a cyber-physical system that are not accounted for in the design and test phase. As such under unknown-unknown scenarios, the operational behavior of the CPS is not guaranteed to meet requirements such as safety and efficacy specified using Signal Temporal Logic (STL) on the output trajectories. We propose a novel framework for analyzing the stochastic conformance of operational output characteristics of safety-critical cyber-physical systems that can discover unknown-unknown scenarios and evaluate potential safety hazards. We propose dynamics-induced hybrid recurrent neural networks (DiH-RNN) to mine a physics-guided surrogate model (PGSM) which is used to check the model conformance using STL on the model coefficients. We demonstrate the detection of operational changes in an Artificial Pancreas(AP) due to unknown insulin cartridge errors.
</details>
<details>
<summary>摘要</summary>
未知未知情况是遗传逻辑系统中运行阶段没有考虑的情况。因此，在未知未知情况下，遗传逻辑系统的运行行为不能保证符合要求，如安全性和有效性，使用信号时间逻辑（STL）表示输出特性的轨迹。我们提出了一种新的框架，用于分析安全关键遗传逻辑系统的输出特性的杂乱兼容性，可以发现未知未知情况并评估可能的安全隐患。我们提出了动力学引导的混合回归神经网络（DiH-RNN），用于挖掘基于物理学的模型（PGSM），并使用STL来检查模型的一致性。我们示例了适用于人工肾脏（AP）的操作变化检测，即因未知的胰岛素卡通错误而导致的操作变化。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Evaluation-of-Metaheuristic-Algorithms-for-Hyperparameter-Selection-in-Short-Term-Weather-Forecasting"><a href="#Comparative-Evaluation-of-Metaheuristic-Algorithms-for-Hyperparameter-Selection-in-Short-Term-Weather-Forecasting" class="headerlink" title="Comparative Evaluation of Metaheuristic Algorithms for Hyperparameter Selection in Short-Term Weather Forecasting"></a>Comparative Evaluation of Metaheuristic Algorithms for Hyperparameter Selection in Short-Term Weather Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02600">http://arxiv.org/abs/2309.02600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anuvab Sen, Arul Rhik Mazumder, Dibyarup Dutta, Udayon Sen, Pathikrit Syam, Sandipan Dhar</li>
<li>for: 这篇论文主要针对于准确预测天气系统的复杂动态，以便于传统统计模型不能准确地捕捉天气系统的复杂性。</li>
<li>methods: 本论文使用了深度学习技术（包括普通的ANN、LSTM和GRU网络），以及元heidursive算法（GA、DE、PSO）来自动搜索优化参数。</li>
<li>results: 研究发现，元heidursive算法可以准确地搜索优化参数，从而提高天气预测的准确性。研究还发现，不同的模型结构和元heidursive算法之间存在着积极的交互关系。<details>
<summary>Abstract</summary>
Weather forecasting plays a vital role in numerous sectors, but accurately capturing the complex dynamics of weather systems remains a challenge for traditional statistical models. Apart from Auto Regressive time forecasting models like ARIMA, deep learning techniques (Vanilla ANNs, LSTM and GRU networks), have shown promise in improving forecasting accuracy by capturing temporal dependencies. This paper explores the application of metaheuristic algorithms, namely Genetic Algorithm (GA), Differential Evolution (DE), and Particle Swarm Optimization (PSO), to automate the search for optimal hyperparameters in these model architectures. Metaheuristic algorithms excel in global optimization, offering robustness, versatility, and scalability in handling non-linear problems. We present a comparative analysis of different model architectures integrated with metaheuristic optimization, evaluating their performance in weather forecasting based on metrics such as Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE). The results demonstrate the potential of metaheuristic algorithms in enhancing weather forecasting accuracy \& helps in determining the optimal set of hyper-parameters for each model. The paper underscores the importance of harnessing advanced optimization techniques to select the most suitable metaheuristic algorithm for the given weather forecasting task.
</details>
<details>
<summary>摘要</summary>
天气预报中的准确预测是许多领域的关键任务，但是传统的统计模型难以准确地捕捉天气系统的复杂动态。 apart from ARIMA模型，深度学习技术（Vanilla ANNs、LSTM和GRU网络）已经显示出提高预测准确性的承诺， capture temporal dependencies。 this paper explores the application of metaheuristic algorithms， namely Genetic Algorithm (GA)、Differential Evolution (DE) and Particle Swarm Optimization (PSO)， to automate the search for optimal hyperparameters in these model architectures。 metaheuristic algorithms excel in global optimization， offering robustness、versatility and scalability in handling non-linear problems。 we present a comparative analysis of different model architectures integrated with metaheuristic optimization， evaluating their performance in weather forecasting based on metrics such as Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE)。 the results demonstrate the potential of metaheuristic algorithms in enhancing weather forecasting accuracy  and helps in determining the optimal set of hyper-parameters for each model。 the paper underscores the importance of harnessing advanced optimization techniques to select the most suitable metaheuristic algorithm for the given weather forecasting task。
</details></li>
</ul>
<hr>
<h2 id="Approximating-High-Dimensional-Minimal-Surfaces-with-Physics-Informed-Neural-Networks"><a href="#Approximating-High-Dimensional-Minimal-Surfaces-with-Physics-Informed-Neural-Networks" class="headerlink" title="Approximating High-Dimensional Minimal Surfaces with Physics-Informed Neural Networks"></a>Approximating High-Dimensional Minimal Surfaces with Physics-Informed Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02589">http://arxiv.org/abs/2309.02589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Steven Zhou, Xiaojing Ye</li>
<li>for: 这 paper 是计算高维 minimal surface 数学近似的，解决了高维埃尔文·芮贝格·约瑟夫问题。</li>
<li>methods: 本 paper 使用 Physics-Informed Neural Network (PINN) 方法，通过训练深度神经网络 (DNN) 来解决 minimal surface 方程。</li>
<li>results: 本 paper 的结果表明，PINN 方法可以在高维空间中计算 minimal surface，并且可以快速地训练和运行在笔记型计算机上，无需高性能计算机。<details>
<summary>Abstract</summary>
In this paper, we compute numerical approximations of the minimal surfaces, an essential type of Partial Differential Equation (PDE), in higher dimensions. Classical methods cannot handle it in this case because of the Curse of Dimensionality, where the computational cost of these methods increases exponentially fast in response to higher problem dimensions, far beyond the computing capacity of any modern supercomputers. Only in the past few years have machine learning researchers been able to mitigate this problem. The solution method chosen here is a model known as a Physics-Informed Neural Network (PINN) which trains a deep neural network (DNN) to solve the minimal surface PDE. It can be scaled up into higher dimensions and trained relatively quickly even on a laptop with no GPU. Due to the inability to view the high-dimension output, our data is presented as snippets of a higher-dimension shape with enough fixed axes so that it is viewable with 3-D graphs. Not only will the functionality of this method be tested, but we will also explore potential limitations in the method's performance.
</details>
<details>
<summary>摘要</summary>
在本文中，我们计算高维精灵散函数（PDE）的数学近似值，这是一种基础方程的重要类型。传统方法在这种情况下无法处理，因为维度味问题的计算成本会快速增长，超过现代超级计算机的处理能力。仅在过去几年，机器学习研究人员才能够解决这个问题。选择的方法是一种称为物理学习神经网络（PINN），它使用深度神经网络（DNN）解决精灵散函数PDE。它可以扩展到更高维度，并在笔记计算机上训练相对快速，即使没有GPU。由于无法查看高维度输出，我们的数据被示为一些固定轴的高维度形状的截面，可以通过3D图表查看。不仅会测试这种方法的功能，我们还将探讨这种方法的可能的局限性。
</details></li>
</ul>
<hr>
<h2 id="Representation-Learning-for-Sequential-Volumetric-Design-Tasks"><a href="#Representation-Learning-for-Sequential-Volumetric-Design-Tasks" class="headerlink" title="Representation Learning for Sequential Volumetric Design Tasks"></a>Representation Learning for Sequential Volumetric Design Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02583">http://arxiv.org/abs/2309.02583</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Ferdous Alam, Yi Wang, Linh Tran, Chin-Yi Cheng, Jieliang Luo</li>
<li>for: 这个论文的目的是提出一种基于 transformer 模型的整体设计系统，以便自动生成符合设计师的设计解决方案。</li>
<li>methods: 该论文使用了 transformer 模型来编码设计知识，并从一系列专家或高性能的设计序列中提取有用的表示。然后，它使用这些表示来进行设计偏好评估和生成过程设计。</li>
<li>results: 该论文通过使用一个 novel dataset of thousands of sequential volumetric designs 来证明其方法的有效性。其中，设计偏好评估模型可以准确地评估两个任意给定的设计序列之间的差异，并且可以自动完成一个volumetric设计序列从一个半完整的设计序列中。<details>
<summary>Abstract</summary>
Volumetric design, also called massing design, is the first and critical step in professional building design which is sequential in nature. As the volumetric design process is complex, the underlying sequential design process encodes valuable information for designers. Many efforts have been made to automatically generate reasonable volumetric designs, but the quality of the generated design solutions varies, and evaluating a design solution requires either a prohibitively comprehensive set of metrics or expensive human expertise. While previous approaches focused on learning only the final design instead of sequential design tasks, we propose to encode the design knowledge from a collection of expert or high-performing design sequences and extract useful representations using transformer-based models. Later we propose to utilize the learned representations for crucial downstream applications such as design preference evaluation and procedural design generation. We develop the preference model by estimating the density of the learned representations whereas we train an autoregressive transformer model for sequential design generation. We demonstrate our ideas by leveraging a novel dataset of thousands of sequential volumetric designs. Our preference model can compare two arbitrarily given design sequences and is almost 90% accurate in evaluation against random design sequences. Our autoregressive model is also capable of autocompleting a volumetric design sequence from a partial design sequence.
</details>
<details>
<summary>摘要</summary>
volumetric design，也称为质量设计，是职业建筑设计的首要步骤，具有顺序性。由于volumetric design过程复杂，其下面顺序设计过程含有价值信息。许多努力已经被made to automatically生成合理的涂抹设计，但生成的设计解决方案质量不一，评估设计解决方案需要 Either a comprehensive set of metrics or expensive human expertise。而前一些方法只是学习最终的设计而不是顺序设计任务，我们提议将专家或高性能的设计序列知识编码到模型中，并使用 transformer-based 模型提取有用的表示。后续，我们将学习的表示用于重要的下游应用，如设计偏好评估和 procedural 设计生成。我们开发了偏好模型，通过估计学习的表示密度来评估两个任意给定的设计序列，并训练一个 autoregressive transformer 模型来生成顺序设计序列。我们通过使用一个 novel 的千个顺序涂抹设计数据集来证明我们的想法。我们的偏好模型可以比较两个任意给定的设计序列，准确率接近 90%，而我们的 autoregressive 模型也可以自动完成一个顺序涂抹设计序列从一个部分设计序列。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Intractable-Epileptogenic-Brain-Networks-with-Deep-Learning-Algorithms-A-Novel-and-Comprehensive-Framework-for-Scalable-Seizure-Prediction-with-Unimodal-Neuroimaging-Data-in-Pediatric-Patients"><a href="#Unveiling-Intractable-Epileptogenic-Brain-Networks-with-Deep-Learning-Algorithms-A-Novel-and-Comprehensive-Framework-for-Scalable-Seizure-Prediction-with-Unimodal-Neuroimaging-Data-in-Pediatric-Patients" class="headerlink" title="Unveiling Intractable Epileptogenic Brain Networks with Deep Learning Algorithms: A Novel and Comprehensive Framework for Scalable Seizure Prediction with Unimodal Neuroimaging Data in Pediatric Patients"></a>Unveiling Intractable Epileptogenic Brain Networks with Deep Learning Algorithms: A Novel and Comprehensive Framework for Scalable Seizure Prediction with Unimodal Neuroimaging Data in Pediatric Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02580">http://arxiv.org/abs/2309.02580</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bliss Singhal, Fnu Pooja<br>for: 这项研究的目的是预测儿童患有不可逆的癫痫病例中的癫痫发作。methods: 该研究使用机器学习算法对单modal神经成像数据进行评估，包括电энцеfalogram信号。研究使用了频带滤波和独立组分分析来减少数据中的噪声和artefacts。results: 研究发现，深度学习算法在预测癫痫发作方面比逻子回归和k最近邻居更成功。Long short-term memory（LSTM）在精度和F1分数方面表现出色， convolutional neural network（CNN）在特征特征方面表现出色。这项研究有重要的应用前瞻性，可能改变临床实践，并提高儿童护理水平。<details>
<summary>Abstract</summary>
Epilepsy is a prevalent neurological disorder affecting 50 million individuals worldwide and 1.2 million Americans. There exist millions of pediatric patients with intractable epilepsy, a condition in which seizures fail to come under control. The occurrence of seizures can result in physical injury, disorientation, unconsciousness, and additional symptoms that could impede children's ability to participate in everyday tasks. Predicting seizures can help parents and healthcare providers take precautions, prevent risky situations, and mentally prepare children to minimize anxiety and nervousness associated with the uncertainty of a seizure. This research proposes a novel and comprehensive framework to predict seizures in pediatric patients by evaluating machine learning algorithms on unimodal neuroimaging data consisting of electroencephalogram signals. The bandpass filtering and independent component analysis proved to be effective in reducing the noise and artifacts from the dataset. Various machine learning algorithms' performance is evaluated on important metrics such as accuracy, precision, specificity, sensitivity, F1 score and MCC. The results show that the deep learning algorithms are more successful in predicting seizures than logistic Regression, and k nearest neighbors. The recurrent neural network (RNN) gave the highest precision and F1 Score, long short-term memory (LSTM) outperformed RNN in accuracy and convolutional neural network (CNN) resulted in the highest Specificity. This research has significant implications for healthcare providers in proactively managing seizure occurrence in pediatric patients, potentially transforming clinical practices, and improving pediatric care.
</details>
<details>
<summary>摘要</summary>
“凝视症是一种流行的神经系统疾病，全球病人约5000万人，美国病人约120万人。有数百万名儿童患有不治疗的凝视症，其中发作不能控制的症状可能导致物理伤害、混乱、失去意识和其他 симптом，影响儿童日常生活。预测发作可以帮助家长和医疗提供者制定预防措施，避免危险情况，并帮助儿童减少发作症状所带来的焦虑和不安。本研究提出了一个全面的预测发作框架，通过评估机器学习算法在单一神经内成像数据上进行评估。对于重要的 метри几何，例如准确性、特异性、敏感度和合理性，评估了不同的机器学习算法的表现。结果显示，深度学习算法比逻辑回传和k最近邻居更 successful 预测发作。Long short-term memory（LSTM）在准确性和敏感度方面表现出色， convolutional neural network（CNN）在特异性方面表现最好。这些研究结果具有重要的实践意义，可能将影响医疗提供者在管理儿童发作的方法，并改善儿童医疗。”
</details></li>
</ul>
<hr>
<h2 id="Recurrence-Free-Survival-Prediction-for-Anal-Squamous-Cell-Carcinoma-Chemoradiotherapy-using-Planning-CT-based-Radiomics-Model"><a href="#Recurrence-Free-Survival-Prediction-for-Anal-Squamous-Cell-Carcinoma-Chemoradiotherapy-using-Planning-CT-based-Radiomics-Model" class="headerlink" title="Recurrence-Free Survival Prediction for Anal Squamous Cell Carcinoma Chemoradiotherapy using Planning CT-based Radiomics Model"></a>Recurrence-Free Survival Prediction for Anal Squamous Cell Carcinoma Chemoradiotherapy using Planning CT-based Radiomics Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02562">http://arxiv.org/abs/2309.02562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanshan Tang, Kai Wang, David Hein, Gloria Lin, Nina N. Sanford, Jing Wang</li>
<li>for: 这项研究是为了开发一个基于辐射预计划CT图像的模型，以预测非转移性分化细胞癌（ASCC）患者 после化疗（CRT）的再次出现率。</li>
<li>methods: 研究人员使用了 радиом扬特征来预测ASCC患者的再次出现率，并在多ivariate Cox准确比率模型中选择了最佳特征集。</li>
<li>results: 研究发现，基于Shape和Texture的 радиом扬特征可以有效预测ASCC患者的再次出现率，并且combined模型在测试组中表现更好，其C-指数和ROC曲线都高于仅使用临床特征模型。<details>
<summary>Abstract</summary>
Objectives: Approximately 30% of non-metastatic anal squamous cell carcinoma (ASCC) patients will experience recurrence after chemoradiotherapy (CRT), and currently available clinical variables are poor predictors of treatment response. We aimed to develop a model leveraging information extracted from radiation pretreatment planning CT to predict recurrence-free survival (RFS) in ASCC patients after CRT. Methods: Radiomics features were extracted from planning CT images of 96 ASCC patients. Following pre-feature selection, the optimal feature set was selected via step-forward feature selection with a multivariate Cox proportional hazard model. The RFS prediction was generated from a radiomics-clinical combined model based on an optimal feature set with five repeats of five-fold cross validation. The risk stratification ability of the proposed model was evaluated with Kaplan-Meier analysis. Results: Shape- and texture-based radiomics features significantly predicted RFS. Compared to a clinical-only model, radiomics-clinical combined model achieves better performance in the testing cohort with higher C-index (0.80 vs 0.73) and AUC (0.84 vs 0.79 for 1-year RFS, 0.84 vs 0.78 for 2-year RFS, and 0.86 vs 0.83 for 3-year RFS), leading to distinctive high- and low-risk of recurrence groups (p<0.001). Conclusions: A treatment planning CT based radiomics and clinical combined model had improved prognostic performance in predicting RFS for ASCC patients treated with CRT as compared to a model using clinical features only.
</details>
<details>
<summary>摘要</summary>
目的：约30%的非转移性 anal squamous cell carcinoma（ASCC）患者会经受化疗后再次出现，现有的临床变量不能准确预测治疗效果。我们目标是利用从化疗前规划CT图像中提取的信息，预测ASCC患者在化疗后的再次出现率（RFS）。方法：从96名ASCC患者的规划CT图像中提取了 радиом学特征。经过预选feature，选择了最佳特征集。然后，通过五次十分割分 Validation进行验证。Result：Shape和 texture基的 радиом学特征能够有效预测RFS。与仅使用临床特征模型相比，radiomics-临床共同模型在测试组中表现更好，其C-指数（0.80 vs 0.73）和ROC（0.84 vs 0.79 for 1-year RFS, 0.84 vs 0.78 for 2-year RFS, and 0.86 vs 0.83 for 3-year RFS）都高于临床特征模型，从而导致了高和低风险组分化（p<0.001）。结论：基于规划CT图像的 радиомics和临床共同模型在预测ASCC患者化疗后RFS方面表现出了改善的预测能力，与仅使用临床特征模型相比。
</details></li>
</ul>
<hr>
<h2 id="Physically-Grounded-Vision-Language-Models-for-Robotic-Manipulation"><a href="#Physically-Grounded-Vision-Language-Models-for-Robotic-Manipulation" class="headerlink" title="Physically Grounded Vision-Language Models for Robotic Manipulation"></a>Physically Grounded Vision-Language Models for Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02561">http://arxiv.org/abs/2309.02561</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Stanford-ILIAD/pg-vlm">https://github.com/Stanford-ILIAD/pg-vlm</a></li>
<li>paper_authors: Jensen Gao, Bidipta Sarkar, Fei Xia, Ted Xiao, Jiajun Wu, Brian Ichter, Anirudha Majumdar, Dorsa Sadigh</li>
<li>for: 提高视觉问答和图像描述任务的性能，使模型更能理解物理世界。</li>
<li>methods: 使用普通人的协助和自动化的物理概念标注数据集PhysObjects进行训练，以捕捉人类对物理对象的Visual priors。</li>
<li>results: 在含有物理概念的任务中，使用物理grounded VLM进行规划，可以提高任务成功率，并在实际机器人中进行实践。<details>
<summary>Abstract</summary>
Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 39.6K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, including generalization to held-out concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically-grounded VLM in an interactive framework with a large language model-based robotic planner, and show improved planning performance on tasks that require reasoning about physical object concepts, compared to baselines that do not leverage physically-grounded VLMs. We additionally illustrate the benefits of our physically-grounded VLM on a real robot, where it improves task success rates. We release our dataset and provide further details and visualizations of our results at https://iliad.stanford.edu/pg-vlm/.
</details>
<details>
<summary>摘要</summary>
近期的视力语言模型（VLM）的进步已导致视觉问答和图像描述等任务的表现得到改善。因此，这些模型现在更容易进行物理世界中的理解，特别是在机器人操作领域。然而，当前的VLM仍有限制，它们对常见物品的物理概念（例如材料和脆弱性）的理解不够，这限制了它们在机器人操作任务中的用途。为解决这个问题，我们提出了PhysObjects，一个包含39600个人工标注和417000个自动标注的常见家用物品的物理概念数据集。我们示示了 fine-tuning VLM 在 PhysObjects 上可以提高它对物理 объек 概念的理解，包括泛化到未经过 обучение的概念。我们将这种物理基础 VLM 与大语言模型基础的机器人规划器集成，并表明了不使用物理基础 VLM 的基eline 的规划性能相对较差。我们还在真实的机器人上运行了这种物理基础 VLM，并证明了它可以提高任务成功率。我们在 https://iliad.stanford.edu/pg-vlm/ 发布了我们的数据集，并在结果中提供了更多的详细信息和视觉化。
</details></li>
</ul>
<hr>
<h2 id="Automating-Behavioral-Testing-in-Machine-Translation"><a href="#Automating-Behavioral-Testing-in-Machine-Translation" class="headerlink" title="Automating Behavioral Testing in Machine Translation"></a>Automating Behavioral Testing in Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02553">http://arxiv.org/abs/2309.02553</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Javier Ferrando, Matthias Sperber, Hendra Setiawan, Dominic Telaar, Saša Hasan</li>
<li>for: 评估机器翻译系统的语言能力，包括语料生成和输入输出行为的分析。</li>
<li>methods: 使用大语言模型生成多样化的源句子，以测试机器翻译系统在不同情况下的行为。</li>
<li>results: 通过对多个可用的机器翻译系统进行评估，发现 passer  rates 随着传统精度指标的趋势相似，但方法找到了一些重要的差异和潜在的错误，这些错误在仅仅依据精度时未被发现。<details>
<summary>Abstract</summary>
Behavioral testing in NLP allows fine-grained evaluation of systems by examining their linguistic capabilities through the analysis of input-output behavior. Unfortunately, existing work on behavioral testing in Machine Translation (MT) is currently restricted to largely handcrafted tests covering a limited range of capabilities and languages. To address this limitation, we propose to use Large Language Models (LLMs) to generate a diverse set of source sentences tailored to test the behavior of MT models in a range of situations. We can then verify whether the MT model exhibits the expected behavior through matching candidate sets that are also generated using LLMs. Our approach aims to make behavioral testing of MT systems practical while requiring only minimal human effort. In our experiments, we apply our proposed evaluation framework to assess multiple available MT systems, revealing that while in general pass-rates follow the trends observable from traditional accuracy-based metrics, our method was able to uncover several important differences and potential bugs that go unnoticed when relying only on accuracy.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT行为测试在自然语言处理（NLP）中允许细化评估系统的语言能力通过输入输出行为的分析。 Unfortunately，现有的机器翻译（MT）行为测试工作现在受到了较少的手动测试覆盖的限制，只有一些特定的语言和能力。 To address this limitation， we propose using Large Language Models（LLMs）来生成一组多样化的源句子，用于测试MT模型在多种情况下的行为。 We can then verify whether the MT model exhibits the expected behavior by matching candidate sets that are also generated using LLMs. Our approach aims to make behavioral testing of MT systems practical while requiring only minimal human effort. In our experiments, we apply our proposed evaluation framework to assess multiple available MT systems, revealing that while in general pass-rates follow the trends observable from traditional accuracy-based metrics, our method was able to uncover several important differences and potential bugs that go unnoticed when relying only on accuracy.TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="Continual-Improvement-of-Threshold-Based-Novelty-Detection"><a href="#Continual-Improvement-of-Threshold-Based-Novelty-Detection" class="headerlink" title="Continual Improvement of Threshold-Based Novelty Detection"></a>Continual Improvement of Threshold-Based Novelty Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02551">http://arxiv.org/abs/2309.02551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abe Ejilemele, Jorge Mendez-Mendez</li>
<li>for: 解决 neural network 在动态开放世界中探测未经见过的类型时存在问题，使得不可预知 novelty 探测方法无法适应实际环境中的数据特性。</li>
<li>methods: 我们提出了一种新的方法，利用直线搜索和留一个样本验证来自动选择阈值，以提高总准确率在 MNIST、Fashion MNIST 和 CIFAR-10 上。</li>
<li>results: 我们的方法在三个 dataset 上都达到了提高的总准确率，表明自动选择阈值可以更好地适应不同的数据特性。<details>
<summary>Abstract</summary>
When evaluated in dynamic, open-world situations, neural networks struggle to detect unseen classes. This issue complicates the deployment of continual learners in realistic environments where agents are not explicitly informed when novel categories are encountered. A common family of techniques for detecting novelty relies on thresholds of similarity between observed data points and the data used for training. However, these methods often require manually specifying (ahead of time) the value of these thresholds, and are therefore incapable of adapting to the nature of the data. We propose a new method for automatically selecting these thresholds utilizing a linear search and leave-one-out cross-validation on the ID classes. We demonstrate that this novel method for selecting thresholds results in improved total accuracy on MNIST, Fashion MNIST, and CIFAR-10.
</details>
<details>
<summary>摘要</summary>
在动态开放环境中评估神经网络时，它们很难探测未看过的类别。这个问题使得在实际环境中部署不断学习者变得更加复杂。一种常见的新类探测技术是基于训练数据点和观察数据点之间的相似度阈值。然而，这些方法通常需要手动指定阈值的值（在过程中），因此无法适应数据的特点。我们提出了一种新的方法，使用线性搜索和留下一个样本进行交叉验证，以自动选择阈值。我们示出，这种新的阈值选择方法可以提高MNIST、Fashion MNIST和CIFAR-10等三个 dataset 的总准确率。
</details></li>
</ul>
<hr>
<h2 id="Structural-Concept-Learning-via-Graph-Attention-for-Multi-Level-Rearrangement-Planning"><a href="#Structural-Concept-Learning-via-Graph-Attention-for-Multi-Level-Rearrangement-Planning" class="headerlink" title="Structural Concept Learning via Graph Attention for Multi-Level Rearrangement Planning"></a>Structural Concept Learning via Graph Attention for Multi-Level Rearrangement Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02547">http://arxiv.org/abs/2309.02547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manav Kulshrestha, Ahmed H. Qureshi</li>
<li>for: 该论文关注了机器人 manipulate 任务，如物体重新排序，以便 robot 与复杂而不受限制的环境进行交互。</li>
<li>methods: 该论文提出了一种深度学习方法，名为结构概念学习（SCL），它利用图注意网络来实现多层物体重新排序规划。SCL 可以处理具有结构依赖层次的Scene，并可以在未经见过的场景中进行任务并行化和灵活化。</li>
<li>results: 作者通过对一系列经典和模型基础的基准方法进行比较，证明了 SCL 能够更好地利用场景理解来实现更高的性能、灵活性和效率。<details>
<summary>Abstract</summary>
Robotic manipulation tasks, such as object rearrangement, play a crucial role in enabling robots to interact with complex and arbitrary environments. Existing work focuses primarily on single-level rearrangement planning and, even if multiple levels exist, dependency relations among substructures are geometrically simpler, like tower stacking. We propose Structural Concept Learning (SCL), a deep learning approach that leverages graph attention networks to perform multi-level object rearrangement planning for scenes with structural dependency hierarchies. It is trained on a self-generated simulation data set with intuitive structures, works for unseen scenes with an arbitrary number of objects and higher complexity of structures, infers independent substructures to allow for task parallelization over multiple manipulators, and generalizes to the real world. We compare our method with a range of classical and model-based baselines to show that our method leverages its scene understanding to achieve better performance, flexibility, and efficiency. The dataset, supplementary details, videos, and code implementation are available at: https://manavkulshrestha.github.io/scl
</details>
<details>
<summary>摘要</summary>
瑜珈机器人操作任务，如物品重新排序，对机器人在复杂且随机环境中进行交互起到关键作用。现有研究主要集中在单个层次重新排序规划上，即使有多个层次存在，dependency关系 among substructures几乎都是 геометрически简单的，如筒堆。我们提出了Structural Concept Learning（SCL），一种深度学习方法，通过图像注意力网络来实现多层次物品重新排序规划。它在自己生成的 simulatedata set上接受intuitive结构，可以处理未看过的场景，无论有多少对象和更高的结构复杂度，推导独立的substructure，以便在多个机器人上分布task，并且可以在实际世界中普适。我们与一系列的古典和基于模型的基准进行比较，显示我们的方法借助于场景理解来实现更好的性能、灵活性和效率。数据集、补充细节、视频和代码实现可以在：https://manavkulshrestha.github.io/scl  obtener
</details></li>
</ul>
<hr>
<h2 id="Experience-and-Prediction-A-Metric-of-Hardness-for-a-Novel-Litmus-Test"><a href="#Experience-and-Prediction-A-Metric-of-Hardness-for-a-Novel-Litmus-Test" class="headerlink" title="Experience and Prediction: A Metric of Hardness for a Novel Litmus Test"></a>Experience and Prediction: A Metric of Hardness for a Novel Litmus Test</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02534">http://arxiv.org/abs/2309.02534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicos Isaak, Loizos Michael</li>
<li>for: 本研究旨在开发一种基于机器学习（ML）的系统，用于评估winograd schema的困难程度，并且比之前的方法更快速和准确。</li>
<li>methods: 本研究采用了两种不同的方法，namely random forest和深度学习（LSTM-based），以评估winograd schema的困难程度。</li>
<li>results: 研究发现，人类对winograd schema的表现异常 vary，并且与schema的困难程度有直接关系。此外，我们还发现了一些特定的winograd schema可以用于测试人类的智能水平。<details>
<summary>Abstract</summary>
In the last decade, the Winograd Schema Challenge (WSC) has become a central aspect of the research community as a novel litmus test. Consequently, the WSC has spurred research interest because it can be seen as the means to understand human behavior. In this regard, the development of new techniques has made possible the usage of Winograd schemas in various fields, such as the design of novel forms of CAPTCHAs.   Work from the literature that established a baseline for human adult performance on the WSC has shown that not all schemas are the same, meaning that they could potentially be categorized according to their perceived hardness for humans. In this regard, this \textit{hardness-metric} could be used in future challenges or in the WSC CAPTCHA service to differentiate between Winograd schemas.   Recent work of ours has shown that this could be achieved via the design of an automated system that is able to output the hardness-indexes of Winograd schemas, albeit with limitations regarding the number of schemas it could be applied on. This paper adds to previous research by presenting a new system that is based on Machine Learning (ML), able to output the hardness of any Winograd schema faster and more accurately than any other previously used method. Our developed system, which works within two different approaches, namely the random forest and deep learning (LSTM-based), is ready to be used as an extension of any other system that aims to differentiate between Winograd schemas, according to their perceived hardness for humans. At the same time, along with our developed system we extend previous work by presenting the results of a large-scale experiment that shows how human performance varies across Winograd schemas.
</details>
<details>
<summary>摘要</summary>
过去一个 décennio，Winograd Schema Challenge（WSC）已成为研究社区中的中心方面，作为一种新的考验。因此，WSC 引发了研究者的兴趣，因为它可以用来理解人类行为。在这个意义上，开发新技术使得 Winograd  schema 可以在不同领域中使用，如设计新型 CAPTCHAs。  据文献记录，人类成人在 WSC 中的表现达标准，表明不同的 Winograd schema 可能有不同的抵抗程度。在这个意义上，这个“抵抗度指标”可以在未来的挑战中或 WSC CAPTCHA 服务中使用来区分 Winograd schema。  我们最近的工作表明，这可以通过设计一个自动化系统来实现，该系统可以输出 Winograd schema 的抵抗度指标，但是只能应用于有限数量的 schema。本文添加了先前的研究，提出了一个基于机器学习（ML）的新系统，可以更快、更准确地输出 Winograd schema 的抵抗度指标。我们开发的系统采用了两种不同的方法，即随机森林和深度学习（LSTM）。这个系统可以作为任何其他系统的扩展，以区分 Winograd schema 根据人类对它们的抵抗度。同时，我们也扩展了先前的工作，通过发表大规模实验，显示了人类在不同 Winograd schema 中的表现差异。
</details></li>
</ul>
<hr>
<h2 id="Do-You-Trust-ChatGPT-–-Perceived-Credibility-of-Human-and-AI-Generated-Content"><a href="#Do-You-Trust-ChatGPT-–-Perceived-Credibility-of-Human-and-AI-Generated-Content" class="headerlink" title="Do You Trust ChatGPT? – Perceived Credibility of Human and AI-Generated Content"></a>Do You Trust ChatGPT? – Perceived Credibility of Human and AI-Generated Content</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02524">http://arxiv.org/abs/2309.02524</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Huschens, Martin Briesch, Dominik Sobania, Franz Rothlauf</li>
<li>for: 这个研究探讨用户对人类作者vs大语言模型生成内容的信任程度如何不同的用户界面版本。</li>
<li>methods: 研究使用了具有不同用户界面版本的人类作者和大语言模型生成的内容，评估用户对这两种内容的信任程度和技能感。</li>
<li>results: 结果显示，尽管用户界面版本不同，但参与者对人类作者和大语言模型生成的内容的信任程度几乎相同。同时，参与者认为AI生成的内容 clearer和更有吸引力。这些发现告诉我们需要更加谨慎地评估信息来源，促使用者予以慎重和批判性思维。<details>
<summary>Abstract</summary>
This paper examines how individuals perceive the credibility of content originating from human authors versus content generated by large language models, like the GPT language model family that powers ChatGPT, in different user interface versions. Surprisingly, our results demonstrate that regardless of the user interface presentation, participants tend to attribute similar levels of credibility. While participants also do not report any different perceptions of competence and trustworthiness between human and AI-generated content, they rate AI-generated content as being clearer and more engaging. The findings from this study serve as a call for a more discerning approach to evaluating information sources, encouraging users to exercise caution and critical thinking when engaging with content generated by AI systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-RL-via-Disentangled-Environment-and-Agent-Representations"><a href="#Efficient-RL-via-Disentangled-Environment-and-Agent-Representations" class="headerlink" title="Efficient RL via Disentangled Environment and Agent Representations"></a>Efficient RL via Disentangled Environment and Agent Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02435">http://arxiv.org/abs/2309.02435</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kevin Gmelin, Shikhar Bahl, Russell Mendonca, Deepak Pathak</li>
<li>for: 提高RL算法的视觉理解和表示能力</li>
<li>methods: 使用自己的视觉知识（如形状或面具）来学习结构化表示，并将其integrated into RL目标函数中</li>
<li>results: 在18个不同的视觉 simulations环境中，对5种不同的机器人进行了比较，并得到了模型自由方法的性能提升<details>
<summary>Abstract</summary>
Agents that are aware of the separation between themselves and their environments can leverage this understanding to form effective representations of visual input. We propose an approach for learning such structured representations for RL algorithms, using visual knowledge of the agent, such as its shape or mask, which is often inexpensive to obtain. This is incorporated into the RL objective using a simple auxiliary loss. We show that our method, Structured Environment-Agent Representations, outperforms state-of-the-art model-free approaches over 18 different challenging visual simulation environments spanning 5 different robots. Website at https://sear-rl.github.io/
</details>
<details>
<summary>摘要</summary>
Agent 可以感知自己和环境之间的分离，可以利用这种理解来形成有效的视觉输入表示。我们提出一种使用视觉知识，如机器人的形状或面具，可以轻松获得的方法来学习这些结构化表示。这种方法被 integrate 到RL目标中使用简单的辅助损失。我们显示，我们的方法 Structured Environment-Agent Representations 在 18 个不同的复杂视觉 simulate 环境中，使用 5 种不同的机器人，超过了现状的模型自由方法。网站地址为 <https://sear-rl.github.io/>。Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Building-a-Winning-Team-Selecting-Source-Model-Ensembles-using-a-Submodular-Transferability-Estimation-Approach"><a href="#Building-a-Winning-Team-Selecting-Source-Model-Ensembles-using-a-Submodular-Transferability-Estimation-Approach" class="headerlink" title="Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach"></a>Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02429">http://arxiv.org/abs/2309.02429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vimal K B, Saketh Bachu, Tanmay Garg, Niveditha Lakshmi Narasimhan, Raghavan Konuru, Vineeth N Balasubramanian</li>
<li>for: 这篇论文主要应用于估计公开可用的预训模型在目标任务上的转移可能性。</li>
<li>methods: 本论文使用了一个新的Optimal tranSport-based suBmOdular tRaNsferability metric（OSBORN）来估计多来源模型的转移可能性。OSBORN考虑了图像领域差异、任务差异和模型集合中的凝聚性，以提供可靠的转移可能性估计。</li>
<li>results: 本论文通过对28个源数据集、11个目标数据集、5种模型架构和2种预训方法进行 benchmarking，发现OSBORN可以与现有的state-of-the-art度量metric MS-LEEP和E-LEEP相比，并在该方法下表现出色。<details>
<summary>Abstract</summary>
Estimating the transferability of publicly available pretrained models to a target task has assumed an important place for transfer learning tasks in recent years. Existing efforts propose metrics that allow a user to choose one model from a pool of pre-trained models without having to fine-tune each model individually and identify one explicitly. With the growth in the number of available pre-trained models and the popularity of model ensembles, it also becomes essential to study the transferability of multiple-source models for a given target task. The few existing efforts study transferability in such multi-source ensemble settings using just the outputs of the classification layer and neglect possible domain or task mismatch. Moreover, they overlook the most important factor while selecting the source models, viz., the cohesiveness factor between them, which can impact the performance and confidence in the prediction of the ensemble. To address these gaps, we propose a novel Optimal tranSport-based suBmOdular tRaNsferability metric (OSBORN) to estimate the transferability of an ensemble of models to a downstream task. OSBORN collectively accounts for image domain difference, task difference, and cohesiveness of models in the ensemble to provide reliable estimates of transferability. We gauge the performance of OSBORN on both image classification and semantic segmentation tasks. Our setup includes 28 source datasets, 11 target datasets, 5 model architectures, and 2 pre-training methods. We benchmark our method against current state-of-the-art metrics MS-LEEP and E-LEEP, and outperform them consistently using the proposed approach.
</details>
<details>
<summary>摘要</summary>
估计公共可用预训练模型在目标任务中的转移性在过去几年中得到了重要地位。现有的努力提出了用于选择预训练模型池中的一个模型而无需 individually fine-tune each model和特定地标出一个的指标。随着可用的预训练模型的数量的增加和模型组合的流行，也变得必要研究多源模型在给定目标任务中的转移性。现有的努力研究了这种多源模型的转移性使用输出类别层的结果，而忽略了可能存在的领域或任务差异，而且也忽略了选择源模型时最重要的因素——模型集合中的凝结度，这可能会影响预测 ensemble 的性能和信任度。为了解决这些差距，我们提出了一种新的 Optimal tranSport-based suBmOdular tRaNsferability 指标（OSBORN），用于估计 ensemble 模型到下游任务的转移性。OSBORN 共同考虑图像领域差异、任务差异和模型集合中的凝结度，以提供可靠的转移性估计。我们在图像分类和 semantic segmentation 任务上测试了我们的方法，并与当前状态的метрик MS-LEEP 和 E-LEEP 进行了比较，并一致地超越了它们。
</details></li>
</ul>
<hr>
<h2 id="Cognitive-Architectures-for-Language-Agents"><a href="#Cognitive-Architectures-for-Language-Agents" class="headerlink" title="Cognitive Architectures for Language Agents"></a>Cognitive Architectures for Language Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02427">http://arxiv.org/abs/2309.02427</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ysymyth/awesome-language-agents">https://github.com/ysymyth/awesome-language-agents</a></li>
<li>paper_authors: Theodore Sumers, Shunyu Yao, Karthik Narasimhan, Thomas L. Griffiths</li>
<li>for: 本研究旨在开发一种新一代的语言智能代理人，以帮助语言模型（LLM）进行更好的理解和决策。</li>
<li>methods: 本研究使用了符号人工智能的历史经验，将生成语言模型（LLM）与外部资源（如互联网）或内部控制流（如提示链）结合起来，以建立一个完整的语言代理人系统。</li>
<li>results: 研究表明，LLMs 具有许多生产系统的特性，而最近尝试改进 LLMS 的理解和基础设施的努力，与生产系统驱动的认知架构的发展具有很大的相似性。<details>
<summary>Abstract</summary>
Recent efforts have incorporated large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning. However, these efforts have largely been piecemeal, lacking a systematic framework for constructing a fully-fledged language agent. To address this challenge, we draw on the rich history of agent design in symbolic artificial intelligence to develop a blueprint for a new wave of cognitive language agents. We first show that LLMs have many of the same properties as production systems, and recent efforts to improve their grounding or reasoning mirror the development of cognitive architectures built around production systems. We then propose Cognitive Architectures for Language Agents (CoALA), a conceptual framework to systematize diverse methods for LLM-based reasoning, grounding, learning, and decision making as instantiations of language agents in the framework. Finally, we use the CoALA framework to highlight gaps and propose actionable directions toward more capable language agents in the future.
</details>
<details>
<summary>摘要</summary>
We first show that LLMs have many of the same properties as production systems, and recent efforts to improve their grounding or reasoning mirror the development of cognitive architectures built around production systems. We then propose Cognitive Architectures for Language Agents (CoALA), a conceptual framework to systematize diverse methods for LLM-based reasoning, grounding, learning, and decision making as instantiations of language agents in the framework.Finally, we use the CoALA framework to highlight gaps and propose actionable directions toward more capable language agents in the future.
</details></li>
</ul>
<hr>
<h2 id="A-Context-Sensitive-Approach-to-XAI-in-Music-Performance"><a href="#A-Context-Sensitive-Approach-to-XAI-in-Music-Performance" class="headerlink" title="A Context-Sensitive Approach to XAI in Music Performance"></a>A Context-Sensitive Approach to XAI in Music Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04491">http://arxiv.org/abs/2309.04491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicola Privato, Jack Armitage</li>
<li>for: 提出了一种Explainable Pragmatism（EP）框架，用于解释人工智能（AI）系统在音乐表演中的工作原理。</li>
<li>methods: 提出了一种基于上下文和听众的解释需求开发方法，并在实际应用中进行了详细的描述和分析。</li>
<li>results: EP框架可以帮助提高AI系统在艺术应用中的透明度和可解性，并且可以根据听众反馈和改进。<details>
<summary>Abstract</summary>
The rapidly evolving field of Explainable Artificial Intelligence (XAI) has generated significant interest in developing methods to make AI systems more transparent and understandable. However, the problem of explainability cannot be exhaustively solved in the abstract, as there is no single approach that can be universally applied to generate adequate explanations for any given AI system, and this is especially true in the arts. In this position paper, we propose an Explanatory Pragmatism (EP) framework for XAI in music performance, emphasising the importance of context and audience in the development of explainability requirements. By tailoring explanations to specific audiences and continuously refining them based on feedback, EP offers a promising direction for enhancing the transparency and interpretability of AI systems in broad artistic applications and more specifically to music performance.
</details>
<details>
<summary>摘要</summary>
rapidly evolving field of 可解释人工智能（XAI）已引起了开发方法来使AI系统更透明和理解的广泛关注。然而，问题的解释不可能在抽象中完全解决，因为没有一种通用的方法可以对任何AI系统生成足够的解释，这特别是在艺术领域。在这篇Position paper中，我们提出了一种 Pragmatism（EP）框架 для XAI在音乐表演中，强调了解释的上下文和听众的重要性。通过对specific audiences tailoring explanations和基于反馈不断修改，EP提供了一个有前途的方向来提高AI系统在艺术应用中的透明度和可解释性。
</details></li>
</ul>
<hr>
<h2 id="Information-Processing-by-Neuron-Populations-in-the-Central-Nervous-System-Mathematical-Structure-of-Data-and-Operations"><a href="#Information-Processing-by-Neuron-Populations-in-the-Central-Nervous-System-Mathematical-Structure-of-Data-and-Operations" class="headerlink" title="Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations"></a>Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02332">http://arxiv.org/abs/2309.02332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin N. P. Nilsson<br>for:这篇论文旨在探讨神经元集团中的信息编码和操作方法。methods:该论文使用一种现代化的神经元模型，并通过描述这些神经元集团的数学结构，探讨了这些集团在信息处理方面的能力。results:研究发现，这些神经元集团可以通过一种简单的代数结构来表示和处理信息，并且可以实现许多操作，如特殊化、通用化、新鲜度检测、维度减少、逆模型、预测和关联记忆等。这些结果可能有助于我们更好地理解脑中的信息处理机制，并在认知科学和人工智能领域进行进一步的研究。<details>
<summary>Abstract</summary>
In the intricate architecture of the mammalian central nervous system, neurons form populations. Axonal bundles communicate between these clusters using spike trains as their medium. However, these neuron populations' precise encoding and operations have yet to be discovered. In our analysis, the starting point is a state-of-the-art mechanistic model of a generic neuron endowed with plasticity. From this simple framework emerges a profound mathematical construct: The representation and manipulation of information can be precisely characterized by an algebra of finite convex cones. Furthermore, these neuron populations are not merely passive transmitters. They act as operators within this algebraic structure, mirroring the functionality of a low-level programming language. When these populations interconnect, they embody succinct yet potent algebraic expressions. These networks allow them to implement many operations, such as specialization, generalization, novelty detection, dimensionality reduction, inverse modeling, prediction, and associative memory. In broader terms, this work illuminates the potential of matrix embeddings in advancing our understanding in fields like cognitive science and AI. These embeddings enhance the capacity for concept processing and hierarchical description over their vector counterparts.
</details>
<details>
<summary>摘要</summary>
在哺乳动物中枢神经系统的复杂建筑中， neurons 组成 populations。 axon 短列传输 между这些群体使用冲击车作为媒介。然而，这些 neuron  populations 的准确编码和操作仍未被发现。在我们的分析中，开始点是一种现代机制模型，拥有 пластичность的 generic neuron。从这个简单的框架中，出现了深刻的数学构造：表示和操作信息的 algebra of finite convex cones。此外，这些 neuron populations 不仅是 passive 的传输器。它们作为这些数学结构中的操作员，反映了低级编程语言的功能。当这些 populations 相互连接时，它们实现了简洁而强大的数学表达。这些网络允许它们实现许多操作，如特性化、泛化、发现新的、维度减少、逆模型、预测和相关记忆。在更广泛的意义上，这些 embedding 在认知科学和 AI 领域的发展中具有潜在的潜力。这些 embedding 可以提高概念处理的能力和层次描述的能力，比vector counterparts 更高效。
</details></li>
</ul>
<hr>
<h2 id="Neurosymbolic-Meta-Reinforcement-Lookahead-Learning-Achieves-Safe-Self-Driving-in-Non-Stationary-Environments"><a href="#Neurosymbolic-Meta-Reinforcement-Lookahead-Learning-Achieves-Safe-Self-Driving-in-Non-Stationary-Environments" class="headerlink" title="Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe Self-Driving in Non-Stationary Environments"></a>Neurosymbolic Meta-Reinforcement Lookahead Learning Achieves Safe Self-Driving in Non-Stationary Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02328">http://arxiv.org/abs/2309.02328</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haozhe Lei, Quanyan Zhu</li>
<li>for: This paper focuses on the integration of machine learning into self-driving technology, with a specific emphasis on ensuring safety and efficiency in real-world applications.</li>
<li>methods: The paper introduces an algorithm for online meta-reinforcement learning, called Neurosymbolic Meta-Reinforcement Lookahead Learning (NUMERLA), which combines lookahead symbolic constraints with online adaptation to ensure both efficiency and safety.</li>
<li>results: The experimental results demonstrate that NUMERLA enables the self-driving agent to adapt in real-time to non-stationary urban human-vehicle interaction scenarios, leading to safe and self-adaptive driving.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文关注机器学习在自动驾驶技术中的集成，特别是在实际应用中保证安全性和效率的问题。</li>
<li>methods: 这篇论文提出了一种名为数字符号化多因素奖励前Lookahead学习算法（NUMERLA），它将数字符号化约束与在线调整结合起来，以确保效率和安全性均得到保障。</li>
<li>results: 实验结果表明， NUMERLA可以使自动驾驶机器人在非站立城市人机交互enario下实现安全和自适应驾驶。<details>
<summary>Abstract</summary>
In the area of learning-driven artificial intelligence advancement, the integration of machine learning (ML) into self-driving (SD) technology stands as an impressive engineering feat. Yet, in real-world applications outside the confines of controlled laboratory scenarios, the deployment of self-driving technology assumes a life-critical role, necessitating heightened attention from researchers towards both safety and efficiency. To illustrate, when a self-driving model encounters an unfamiliar environment in real-time execution, the focus must not solely revolve around enhancing its anticipated performance; equal consideration must be given to ensuring its execution or real-time adaptation maintains a requisite level of safety. This study introduces an algorithm for online meta-reinforcement learning, employing lookahead symbolic constraints based on \emph{Neurosymbolic Meta-Reinforcement Lookahead Learning} (NUMERLA). NUMERLA proposes a lookahead updating mechanism that harmonizes the efficiency of online adaptations with the overarching goal of ensuring long-term safety. Experimental results demonstrate NUMERLA confers the self-driving agent with the capacity for real-time adaptability, leading to safe and self-adaptive driving under non-stationary urban human-vehicle interaction scenarios.
</details>
<details>
<summary>摘要</summary>
在学习驱动人工智能的发展领域，将机器学习（ML） integrates into自动驾驶（SD）技术是一项印象深刻的工程成果。然而，在实际应用中，自动驾驶技术的部署具有生命 crítical 的重要性，需要研究人员强调安全性和效率之间的平衡。例如，当一个自动驾驶模型在实时执行中遇到未知环境时，不能 solely 围绕增强其预期性能进行强调，也需要确保其执行或实时适应保持一定的安全水平。本研究提出了一种在线meta-学习算法，使用lookahead符号约束，基于Neurosymbolic Meta-Reinforcement Lookahead Learning（NUMERLA）。NUMERLA提出了一种协调在线适应的效率和长期安全的目标，使得自动驾驶机器人能够在非站ARY urban human-vehicle interactionenario下进行安全和自适应驾驶。实验结果表明，NUMERLA使得自动驾驶机器人具有了实时适应的能力，并在非站ARY urban human-vehicle interactionenario下保持了安全和自适应的驾驶。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-File-Context-for-Source-Code-Summarization"><a href="#Revisiting-File-Context-for-Source-Code-Summarization" class="headerlink" title="Revisiting File Context for Source Code Summarization"></a>Revisiting File Context for Source Code Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02326">http://arxiv.org/abs/2309.02326</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apcl-research/transformerfc">https://github.com/apcl-research/transformerfc</a></li>
<li>paper_authors: Aakash Bansal, Chia-Yi Su, Collin McMillan</li>
<li>for: 这个论文主要是为了提高代码概要的生成。</li>
<li>methods: 该论文使用了改进的 transformer 架构，用于编码文件上下文信息，以帮助解决一些困难的例子。</li>
<li>results: 研究发现，文件上下文信息可以帮助解决一些困难的例子，并且提高代码概要的生成质量。<details>
<summary>Abstract</summary>
Source code summarization is the task of writing natural language descriptions of source code. A typical use case is generating short summaries of subroutines for use in API documentation. The heart of almost all current research into code summarization is the encoder-decoder neural architecture, and the encoder input is almost always a single subroutine or other short code snippet. The problem with this setup is that the information needed to describe the code is often not present in the code itself -- that information often resides in other nearby code. In this paper, we revisit the idea of ``file context'' for code summarization. File context is the idea of encoding select information from other subroutines in the same file. We propose a novel modification of the Transformer architecture that is purpose-built to encode file context and demonstrate its improvement over several baselines. We find that file context helps on a subset of challenging examples where traditional approaches struggle.
</details>
<details>
<summary>摘要</summary>
源代码概要是将源代码写成自然语言描述的任务。一个常见的用例是生成 API 文档中的简短描述。现有的大多数研究都使用 encoder-decoder 神经网络架构，其中 encoder 输入通常是单个子routine 或其他短代码副本。问题在于，代码描述所需的信息不总是在代码中存在，这些信息通常位于附近的代码中。在这篇论文中，我们重新考虑了 ``file context'' 的想法，即在代码概要中使用其他文件中的选择信息。我们提出了一种 modificated Transformer 架构，专门用于编码文件上下文，并证明其在多个基线上显著提高了性能。我们发现，文件上下文有助于一些困难的例子，传统方法在这些例子中困难。
</details></li>
</ul>
<hr>
<h2 id="SeisCLIP-A-seismology-foundation-model-pre-trained-by-multi-modal-data-for-multi-purpose-seismic-feature-extraction"><a href="#SeisCLIP-A-seismology-foundation-model-pre-trained-by-multi-modal-data-for-multi-purpose-seismic-feature-extraction" class="headerlink" title="SeisCLIP: A seismology foundation model pre-trained by multi-modal data for multi-purpose seismic feature extraction"></a>SeisCLIP: A seismology foundation model pre-trained by multi-modal data for multi-purpose seismic feature extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02320">http://arxiv.org/abs/2309.02320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sixu0/SeisCLIP">https://github.com/sixu0/SeisCLIP</a></li>
<li>paper_authors: Xu Si, Xinming Wu, Hanlin Sheng, Jun Zhu, Zefeng Li</li>
<li>for: 这篇论文的目的是发展一个基础模型，供不同领域的地震学家使用。</li>
<li>methods: 这篇论文使用了对比式学习方法，将多modal数据集融合到一个基础模型中。</li>
<li>results: 这篇论文的实验结果显示，基础模型可以在不同地区的数据集上表现出色，并且在不同任务上表现更好 than 基于点的方法。<details>
<summary>Abstract</summary>
Training specific deep learning models for particular tasks is common across various domains within seismology. However, this approach encounters two limitations: inadequate labeled data for certain tasks and limited generalization across regions. To address these challenges, we develop SeisCLIP, a seismology foundation model trained through contrastive learning from multi-modal data. It consists of a transformer encoder for extracting crucial features from time-frequency seismic spectrum and an MLP encoder for integrating the phase and source information of the same event. These encoders are jointly pre-trained on a vast dataset and the spectrum encoder is subsequently fine-tuned on smaller datasets for various downstream tasks. Notably, SeisCLIP's performance surpasses that of baseline methods in event classification, localization, and focal mechanism analysis tasks, employing distinct datasets from different regions. In conclusion, SeisCLIP holds significant potential as a foundational model in the field of seismology, paving the way for innovative directions in foundation-model-based seismology research.
</details>
<details>
<summary>摘要</summary>
通常在不同领域内的地震学中都会使用特定任务的深度学习模型训练。然而，这种方法存在两个限制：一是没有充足的标注数据 для某些任务，二是限制了在不同地区的泛化。为了解决这些挑战，我们开发了SeisCLIP，一个基于对比学习的地震学基础模型。它包括一个变换器编码器，用于从时频地震谱中提取关键特征，以及一个多层感知编码器，用于 инте integrating频谱信息和源信息。这两个编码器被共同预训练在庞大的数据集上，并且 spectrum编码器在更小的数据集上进行细化训练以适应不同下游任务。值得注意的是，SeisCLIP的性能在不同地区的事件分类、地点定位和焦点机制分析任务中都超过了基eline方法的性能。因此，SeisCLIP在地震学领域中具有重要的潜在价值，可能开创出新的基础模型基于的地震学研究方向。
</details></li>
</ul>
<hr>
<h2 id="Graph-Self-Contrast-Representation-Learning"><a href="#Graph-Self-Contrast-Representation-Learning" class="headerlink" title="Graph Self-Contrast Representation Learning"></a>Graph Self-Contrast Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02304">http://arxiv.org/abs/2309.02304</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GRAND-Lab/MERIT">https://github.com/GRAND-Lab/MERIT</a></li>
<li>paper_authors: Minjie Chen, Yao Cheng, Ye Wang, Xiang Li, Ming Gao</li>
<li>for: 本文提出了一种新的图自对抗框架GraphSC，用于图表示学习。</li>
<li>methods:  GraphSC使用了一个positive和一个negative样本，并使用三元损失函数。具体来说， GraphSC使用图生成函数来生成图样本的多种强度的负样本，并使用HSIC来因素化表示。</li>
<li>results: 在对19种当前状态的方法进行了广泛的实验测试后，GraphSC在无监督和转移学习Setting中表现出了优秀的表现。<details>
<summary>Abstract</summary>
Graph contrastive learning (GCL) has recently emerged as a promising approach for graph representation learning. Some existing methods adopt the 1-vs-K scheme to construct one positive and K negative samples for each graph, but it is difficult to set K. For those methods that do not use negative samples, it is often necessary to add additional strategies to avoid model collapse, which could only alleviate the problem to some extent. All these drawbacks will undoubtedly have an adverse impact on the generalizability and efficiency of the model. In this paper, to address these issues, we propose a novel graph self-contrast framework GraphSC, which only uses one positive and one negative sample, and chooses triplet loss as the objective. Specifically, self-contrast has two implications. First, GraphSC generates both positive and negative views of a graph sample from the graph itself via graph augmentation functions of various intensities, and use them for self-contrast. Second, GraphSC uses Hilbert-Schmidt Independence Criterion (HSIC) to factorize the representations into multiple factors and proposes a masked self-contrast mechanism to better separate positive and negative samples. Further, Since the triplet loss only optimizes the relative distance between the anchor and its positive/negative samples, it is difficult to ensure the absolute distance between the anchor and positive sample. Therefore, we explicitly reduced the absolute distance between the anchor and positive sample to accelerate convergence. Finally, we conduct extensive experiments to evaluate the performance of GraphSC against 19 other state-of-the-art methods in both unsupervised and transfer learning settings.
</details>
<details>
<summary>摘要</summary>
graph contrastive learning (GCL) 近期出现为图表示学习的有力的方法之一。一些现有方法采用1对K的方案来建立一个图和K个负样本，但是很难设置K。对于不使用负样本的方法，通常需要添加额外策略以避免模型塌陷，这可以只是减轻问题的程度。这些缺点会对模型的普适性和效率产生负面影响。在这篇论文中，我们提出一种新的图自相关框架GraphSC，它仅使用一个图和一个负样本，并选择三元损失为目标。具体来说，自相关有两个含义。首先，GraphSC通过图像函数的多种强度生成了图样本的正面和负面视图，并将它们用于自相关。其次，GraphSC使用希尔伯特-施密特独立度标准（HSIC）来因素化表示，并提出了屏蔽自相关机制以更好地分离正面和负面样本。此外，因为三元损失仅仅优化了anchor和正样本之间的相对距离，因此我们显式减小了anchor和正样本之间的绝对距离，以加速收敛。最后，我们进行了广泛的实验，以评估GraphSC在无监督和转移学习设置下的性能，与19种当前状态的方法进行比较。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Semantic-Communication-with-Deep-Generative-Models-–-An-ICASSP-Special-Session-Overview"><a href="#Enhancing-Semantic-Communication-with-Deep-Generative-Models-–-An-ICASSP-Special-Session-Overview" class="headerlink" title="Enhancing Semantic Communication with Deep Generative Models – An ICASSP Special Session Overview"></a>Enhancing Semantic Communication with Deep Generative Models – An ICASSP Special Session Overview</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02478">http://arxiv.org/abs/2309.02478</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eleonora Grassucci, Yuki Mitsufuji, Ping Zhang, Danilo Comminiello</li>
<li>for: 本研究旨在探讨 semantic communication 在 future AI-driven communication systems 中的突出作用，以及如何通过深度生成模型来解决 semantic information EXTRACTION 和 semantically consistent data 生成的挑战。</li>
<li>methods: 本研究使用 deep generative models 来 Addressing semantic communication challenges from the machine learning perspective，包括 dealing with real-world complex data, extracting and exploiting semantic information, and being robust to channel corruptions。</li>
<li>results: 本研究 Chart novel research pathways for the next generative semantic communication frameworks, 并预示了 deep generative models 在 semantic communication 中的突出作用。<details>
<summary>Abstract</summary>
Semantic communication is poised to play a pivotal role in shaping the landscape of future AI-driven communication systems. Its challenge of extracting semantic information from the original complex content and regenerating semantically consistent data at the receiver, possibly being robust to channel corruptions, can be addressed with deep generative models. This ICASSP special session overview paper discloses the semantic communication challenges from the machine learning perspective and unveils how deep generative models will significantly enhance semantic communication frameworks in dealing with real-world complex data, extracting and exploiting semantic information, and being robust to channel corruptions. Alongside establishing this emerging field, this paper charts novel research pathways for the next generative semantic communication frameworks.
</details>
<details>
<summary>摘要</summary>
semantic communication 将在未来的 AI 驱动通信系统中扮演重要的角色。其挑战是从原始复杂内容中提取 semantics 信息并在接收端生成具有 semantics 一致性的数据，可能在通道损害情况下保持稳定性。这篇 ICASSP 特别会议简述paper 揭示了从机器学习角度来看 semantic communication 的挑战和 deep generative models 如何在实际世界中处理复杂数据、提取和利用 semantics 信息，并在通道损害情况下保持稳定性。此外，这篇 paper 还映示了未来的 generative semantic communication 框架的新研究路径。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Observation-Intervention-Trade-Off-in-Optimisation-Problems-with-Causal-Structure"><a href="#Optimal-Observation-Intervention-Trade-Off-in-Optimisation-Problems-with-Causal-Structure" class="headerlink" title="Optimal Observation-Intervention Trade-Off in Optimisation Problems with Causal Structure"></a>Optimal Observation-Intervention Trade-Off in Optimisation Problems with Causal Structure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02287">http://arxiv.org/abs/2309.02287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kim Hammar, Neil Dhir</li>
<li>for: 优化成本高的灰色案例目标函数，在有限预算下，基于 causal 结构的知识。</li>
<li>methods: 使用非幼目的最优停止问题，考虑观察 intervención 费用负面选择。</li>
<li>results: 实验结果表明，我们的表述可以增强现有的算法在真实和 sintética 标准准的表现。<details>
<summary>Abstract</summary>
We consider the problem of optimising an expensive-to-evaluate grey-box objective function, within a finite budget, where known side-information exists in the form of the causal structure between the design variables. Standard black-box optimisation ignores the causal structure, often making it inefficient and expensive. The few existing methods that consider the causal structure are myopic and do not fully accommodate the observation-intervention trade-off that emerges when estimating causal effects. In this paper, we show that the observation-intervention trade-off can be formulated as a non-myopic optimal stopping problem which permits an efficient solution. We give theoretical results detailing the structure of the optimal stopping times and demonstrate the generality of our approach by showing that it can be integrated with existing causal Bayesian optimisation algorithms. Experimental results show that our formulation can enhance existing algorithms on real and synthetic benchmarks.
</details>
<details>
<summary>摘要</summary>
我们考虑一个评估成本高的灰色obox目标函数优化问题，在有限预算内进行优化，其中知道变量之间的 causal 结构。标准的黑色obox优化忽略了 causal 结构，经常使其不fficient和昂贵。现有的方法只考虑了 causal 结构，但它们是偏短视的，不完全考虑观测 intervención 费用的负面作用。在这篇论文中，我们表明观测 intervención 费用可以形式化为非偏短视的最优停止问题，允许高效解决。我们提供了理论结果，详细说明优止时间的结构，并证明我们的方法可以与现有的 causal Bayesian 优化算法结合使用。实验结果表明，我们的形式化可以提高现有算法的性能在真实和synthetic 标准测试上。
</details></li>
</ul>
<hr>
<h2 id="s-ID-Causal-Effect-Identification-in-a-Sub-Population"><a href="#s-ID-Causal-Effect-Identification-in-a-Sub-Population" class="headerlink" title="s-ID: Causal Effect Identification in a Sub-Population"></a>s-ID: Causal Effect Identification in a Sub-Population</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02281">http://arxiv.org/abs/2309.02281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amir Mohammad Abouei, Ehsan Mokhtarian, Negar Kiyavash</li>
<li>for: 本文目的是解决在特定子 populations 中 causal inference 问题，即从 observational data 中确定干预对特定子 populations 的影响。</li>
<li>methods: 本文提出了一种新的 causal inference 问题，称为 s-ID 问题，其中只有 observational data 可用，并且不知道整个人口的数据分布。作者提供了必需的和完整的条件，以确定 causal effect 在子 populations 中的可 identificability。</li>
<li>results: 本文提出的方法可以在 observational data 中确定 causal effect 在子 populations 中，并且可以在不同的 causal graph 下进行 identification。这种方法可以解决现有方法在 sub-populations 中的局限性。<details>
<summary>Abstract</summary>
Causal inference in a sub-population involves identifying the causal effect of an intervention on a specific subgroup within a larger population. However, ignoring the subtleties introduced by sub-populations can either lead to erroneous inference or limit the applicability of existing methods. We introduce and advocate for a causal inference problem in sub-populations (henceforth called s-ID), in which we merely have access to observational data of the targeted sub-population (as opposed to the entire population). Existing inference problems in sub-populations operate on the premise that the given data distributions originate from the entire population, thus, cannot tackle the s-ID problem. To address this gap, we provide necessary and sufficient conditions that must hold in the causal graph for a causal effect in a sub-population to be identifiable from the observational distribution of that sub-population. Given these conditions, we present a sound and complete algorithm for the s-ID problem.
</details>
<details>
<summary>摘要</summary>
causal inference in a sub-population involves identifying the causal effect of an intervention on a specific subgroup within a larger population. However, ignoring the subtleties introduced by sub-populations can either lead to erroneous inference or limit the applicability of existing methods. We introduce and advocate for a causal inference problem in sub-populations (henceforth called s-ID), in which we merely have access to observational data of the targeted sub-population (as opposed to the entire population). Existing inference problems in sub-populations operate on the premise that the given data distributions originate from the entire population, thus, cannot tackle the s-ID problem. To address this gap, we provide necessary and sufficient conditions that must hold in the causal graph for a causal effect in a sub-population to be identifiable from the observational distribution of that sub-population. Given these conditions, we present a sound and complete algorithm for the s-ID problem.Here's the translation in Traditional Chinese as well: causal inference in a sub-population involves identifying the causal effect of an intervention on a specific subgroup within a larger population. However, ignoring the subtleties introduced by sub-populations can either lead to erroneous inference or limit the applicability of existing methods. We introduce and advocate for a causal inference problem in sub-populations (henceforth called s-ID), in which we merely have access to observational data of the targeted sub-population (as opposed to the entire population). Existing inference problems in sub-populations operate on the premise that the given data distributions originate from the entire population, thus, cannot tackle the s-ID problem. To address this gap, we provide necessary and sufficient conditions that must hold in the causal graph for a causal effect in a sub-population to be identifiable from the observational distribution of that sub-population. Given these conditions, we present a sound and complete algorithm for the s-ID problem.
</details></li>
</ul>
<hr>
<h2 id="MA-VAE-Multi-head-Attention-based-Variational-Autoencoder-Approach-for-Anomaly-Detection-in-Multivariate-Time-series-Applied-to-Automotive-Endurance-Powertrain-Testing"><a href="#MA-VAE-Multi-head-Attention-based-Variational-Autoencoder-Approach-for-Anomaly-Detection-in-Multivariate-Time-series-Applied-to-Automotive-Endurance-Powertrain-Testing" class="headerlink" title="MA-VAE: Multi-head Attention-based Variational Autoencoder Approach for Anomaly Detection in Multivariate Time-series Applied to Automotive Endurance Powertrain Testing"></a>MA-VAE: Multi-head Attention-based Variational Autoencoder Approach for Anomaly Detection in Multivariate Time-series Applied to Automotive Endurance Powertrain Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02253">http://arxiv.org/abs/2309.02253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lcs-crr/ma-vae">https://github.com/lcs-crr/ma-vae</a></li>
<li>paper_authors: Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas Bäck, Anna V. Kononova</li>
<li>for:  automatous anomaly detection in automotive testing</li>
<li>methods:  variational autoencoder with multi-head attention (MA-VAE)</li>
<li>results:  detects the majority of anomalies with few false positives, avoids bypass phenomenon, and introduces a new method for remapping individual windows to a continuous time series.Here’s the breakdown of each point:</li>
<li>for: The paper is written for the purpose of proposing a novel approach to automatic anomaly detection in automotive testing, which is a real-world application with massive, diverse, multivariate, and temporal data.</li>
<li>methods: The proposed approach uses a variational autoencoder with multi-head attention (MA-VAE) to model the testee behavior and detect anomalies. The MA-VAE is trained on unlabelled data and has the ability to provide few false positives and detect the majority of anomalies.</li>
<li>results: The approach is tested on a real-world industrial data set and the results show that it can detect 67% of the anomalies present with 9% false positives. Additionally, the approach has the potential to perform well with only a fraction of the training and validation subset, but a more sophisticated threshold estimation method is required to extract it.<details>
<summary>Abstract</summary>
A clear need for automatic anomaly detection applied to automotive testing has emerged as more and more attention is paid to the data recorded and manual evaluation by humans reaches its capacity. Such real-world data is massive, diverse, multivariate and temporal in nature, therefore requiring modelling of the testee behaviour. We propose a variational autoencoder with multi-head attention (MA-VAE), which, when trained on unlabelled data, not only provides very few false positives but also manages to detect the majority of the anomalies presented. In addition to that, the approach offers a novel way to avoid the bypass phenomenon, an undesirable behaviour investigated in literature. Lastly, the approach also introduces a new method to remap individual windows to a continuous time series. The results are presented in the context of a real-world industrial data set and several experiments are undertaken to further investigate certain aspects of the proposed model. When configured properly, it is 9% of the time wrong when an anomaly is flagged and discovers 67% of the anomalies present. Also, MA-VAE has the potential to perform well with only a fraction of the training and validation subset, however, to extract it, a more sophisticated threshold estimation method is required.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对于自动异常检测在汽车测试中的需求，现在越来越明显，因为人类的手动评估已经达到了其容量。这些真实世界数据是庞大、多样、多变和时间序列的，因此需要测试对象的行为模型。我们提议一种多头注意力自适应变换器（MA-VAE），当训练于无标签数据时，不仅可以减少假阳性数量，而且能够检测大多数异常现象。此外，该方法还可以避免快船现象，这是文献中 investigate 的不良行为。最后，该方法还引入了一种新的时间序列映射方法。结果在实际工业数据集上展示，并进行了一些实验来更深入探索ertain aspect of the proposed model。当配置正确时，MA-VAE的错误率为9%，并检测到67%的异常现象。此外，MA-VAE还有可能在只使用一小部分的训练和验证subset中表现良好，但是要EXTRACT 它，需要一种更加复杂的阈值估计方法。
</details></li>
</ul>
<hr>
<h2 id="Encoding-Seasonal-Climate-Predictions-for-Demand-Forecasting-with-Modular-Neural-Network"><a href="#Encoding-Seasonal-Climate-Predictions-for-Demand-Forecasting-with-Modular-Neural-Network" class="headerlink" title="Encoding Seasonal Climate Predictions for Demand Forecasting with Modular Neural Network"></a>Encoding Seasonal Climate Predictions for Demand Forecasting with Modular Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02248">http://arxiv.org/abs/2309.02248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Smit Marvaniya, Jitendra Singh, Nicolas Galichet, Fred Ochieng Otieno, Geeth De Mel, Kommy Weldemariam</li>
<li>for: 提高供应链功能的时间序列预测精度</li>
<li>methods: 使用模块化神经网络架构，高效地编码季节气候预测结果，以及其他时间序列数据（例如买家模式），从而学习具有坚实性和可靠性的秘密表示</li>
<li>results: 比对 existed 预测方法，实验结果显示，使用该模型增加了约13%到17%的预测精度，在多个实际数据集上<details>
<summary>Abstract</summary>
Current time-series forecasting problems use short-term weather attributes as exogenous inputs. However, in specific time-series forecasting solutions (e.g., demand prediction in the supply chain), seasonal climate predictions are crucial to improve its resilience. Representing mid to long-term seasonal climate forecasts is challenging as seasonal climate predictions are uncertain, and encoding spatio-temporal relationship of climate forecasts with demand is complex.   We propose a novel modeling framework that efficiently encodes seasonal climate predictions to provide robust and reliable time-series forecasting for supply chain functions. The encoding framework enables effective learning of latent representations -- be it uncertain seasonal climate prediction or other time-series data (e.g., buyer patterns) -- via a modular neural network architecture. Our extensive experiments indicate that learning such representations to model seasonal climate forecast results in an error reduction of approximately 13\% to 17\% across multiple real-world data sets compared to existing demand forecasting methods.
</details>
<details>
<summary>摘要</summary>
当前时间序列预测问题通常使用短期天气特征作为外生输入。然而，在特定的时间序列预测解决方案（如购物者patterns）中，季节气候预测是关键以提高其抗难度。表示中期至长期季节气候预测的问题是复杂的，因为季节气候预测具有不确定性，而且与需求的空间时间关系复杂。我们提出了一种新的模型框架，可以效率地编码季节气候预测。该框架允许效果学习季节气候预测的秘密表示，并且可以吸收其他时间序列数据（如购物者patterns）的学习。我们的广泛实验表明，通过学习这些表示来模型季节气候预测可以减少错误率约13%到17%，相比之前的需求预测方法。
</details></li>
</ul>
<hr>
<h2 id="AGIBench-A-Multi-granularity-Multimodal-Human-referenced-Auto-scoring-Benchmark-for-Large-Language-Models"><a href="#AGIBench-A-Multi-granularity-Multimodal-Human-referenced-Auto-scoring-Benchmark-for-Large-Language-Models" class="headerlink" title="AGIBench: A Multi-granularity, Multimodal, Human-referenced, Auto-scoring Benchmark for Large Language Models"></a>AGIBench: A Multi-granularity, Multimodal, Human-referenced, Auto-scoring Benchmark for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06495">http://arxiv.org/abs/2309.06495</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fei Tang, Wanling Gao, Luzhou Peng, Jianfeng Zhan<br>for:* 本研究的目的是为了评估大型自然语言模型（LLM）的问题解决能力和智能水平。methods:* 本研究提出了一种多级划分、多modal、人参照的benchmarking方法，称为AGIBench，用于评估LLM的问题解决能力。results:* AGIBench支持多级划分benchmarking，包括每个问题、每个能力分支、每个知识、每个模式和每个难度层次的 granularity。Note:* 本文使用Simplified Chinese text format.* 所有的中文句子使用标准的标点符号和格式。<details>
<summary>Abstract</summary>
Large language models (LLMs) like ChatGPT have revealed amazing intelligence. How to evaluate the question-solving abilities of LLMs and their degrees of intelligence is a hot-spot but challenging issue. First, the question-solving abilities are interlaced with different ability branches like understanding and massive knowledge categories like mathematics. Second, the inputs of questions are multimodal that may involve text and images. Third, the response format of LLMs is diverse and thus poses great challenges for result extraction and evaluation. In this paper, we propose AGIBench -- a multi-granularity, multimodal, human-referenced, and auto-scoring benchmarking methodology for LLMs. Instead of a collection of blended questions, AGIBench focuses on three typical ability branches and adopts a four-tuple <ability branch, knowledge, difficulty, modal> to label the attributes of each question. First, it supports multi-granularity benchmarking, e.g., per-question, per-ability branch, per-knowledge, per-modal, per-dataset, and per-difficulty level granularities. Second, it contains multimodal input, including text and images. Third, it classifies all the questions into five degrees of difficulty according to the average accuracy rate of abundant educated humans (human-referenced). Fourth, it adopts zero-shot learning to avoid introducing additional unpredictability and provides an auto-scoring method to extract and judge the result. Finally, it defines multi-dimensional metrics, including accuracy under the average, worst, best, and majority voting cases, and repeatability. AGIBench is publically available from \url{https://www.benchcouncil.org/agibench}.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如ChatGPT的出色智能引发了评估这类模型的问题解决能力和智能水平的热点问题。然而，这些能力存在多种能力分支和多种输入模式，使评估变得具有挑战性。在本文中，我们提出了AGIBench方法，它是一种多级、多Modal、人参照的自动评分 benchMarking方法。在AGIBench中，每个问题被标记为四元组（能力分支、知识、Difficulty、Modal），以便支持多级别的评估。此外，AGIBench还支持多Modal输入，包括文本和图像。此外，它采用人参照的方式将问题分为五个Difficulty水平，并采用零投入学习以避免引入额外的不确定性。最后，它定义了多维度纪录，包括均值、最差、最佳、多数投票等纪录。AGIBench公共可用于 \url{https://www.benchcouncil.org/agibench}。
</details></li>
</ul>
<hr>
<h2 id="Distributionally-Robust-Model-based-Reinforcement-Learning-with-Large-State-Spaces"><a href="#Distributionally-Robust-Model-based-Reinforcement-Learning-with-Large-State-Spaces" class="headerlink" title="Distributionally Robust Model-based Reinforcement Learning with Large State Spaces"></a>Distributionally Robust Model-based Reinforcement Learning with Large State Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02236">http://arxiv.org/abs/2309.02236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shyam Sundhar Ramesh, Pier Giuseppe Sessa, Yifan Hu, Andreas Krause, Ilija Bogunovic</li>
<li>for: 本研究旨在解决机器学习中的复杂动态系统、数据收集成本高和实际环境不符合训练环境的问题。</li>
<li>methods: 本文使用分布robust Markov决策过程（DRMP），利用 Gaussian Processes 和最大差异减少算法，效率地学习多输出 номинаル过程动态模型，并可以快速适应不同的不确定性集。</li>
<li>results: 研究人员通过 theoretically 和实验来证明提议的方法可以快速和高效地学习分布robust策略，并且可以适应不同的不确定性集。实验结果表明，该方法可以快速适应分布shift，并且在许多实际应用中表现出色。<details>
<summary>Abstract</summary>
Three major challenges in reinforcement learning are the complex dynamical systems with large state spaces, the costly data acquisition processes, and the deviation of real-world dynamics from the training environment deployment. To overcome these issues, we study distributionally robust Markov decision processes with continuous state spaces under the widely used Kullback-Leibler, chi-square, and total variation uncertainty sets. We propose a model-based approach that utilizes Gaussian Processes and the maximum variance reduction algorithm to efficiently learn multi-output nominal transition dynamics, leveraging access to a generative model (i.e., simulator). We further demonstrate the statistical sample complexity of the proposed method for different uncertainty sets. These complexity bounds are independent of the number of states and extend beyond linear dynamics, ensuring the effectiveness of our approach in identifying near-optimal distributionally-robust policies. The proposed method can be further combined with other model-free distributionally robust reinforcement learning methods to obtain a near-optimal robust policy. Experimental results demonstrate the robustness of our algorithm to distributional shifts and its superior performance in terms of the number of samples needed.
</details>
<details>
<summary>摘要</summary>
三大挑战在强化学习中是复杂的动力系统和大状态空间，以及实际世界中的动力不同于训练环境部署。为了解决这些问题，我们研究了分布robust Markov决策过程（MDP），并使用了 kontinuous state space 下的 Kullback-Leibler、chi-square 和 total variation 不确定性集。我们提出了一种基于模型的方法，利用 Gaussian Processes 和最大差异减少算法，高效地学习多输出 номинал传递动力学，利用 simulator 的访问权限。我们进一步证明了我们的方法的统计样本复杂度，这些复杂度独立于状态数量，并超越了线性动力学，保证了我们的方法在分布不稳定下可以适应最佳的分布robust策略。我们的方法可以与其他分布robust强化学习方法相结合，以获得最佳的 robust 策略。实验结果表明，我们的算法具有分布不稳定的Robustness和较少样本数量的优势。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-Black-box-LLMs-with-Medical-Textbooks-for-Clinical-Question-Answering"><a href="#Augmenting-Black-box-LLMs-with-Medical-Textbooks-for-Clinical-Question-Answering" class="headerlink" title="Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering"></a>Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02233">http://arxiv.org/abs/2309.02233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubo Wang, Xueguang Ma, Wenhu Chen</li>
<li>for: 这个研究旨在应用大规模语言模型（LLM）到医疗领域，但是这类模型在医疗领域中的应用仍然具有挑战，主要是因为它们无法充分利用领域专门知识。</li>
<li>methods: 这个研究提出了一个名为Large-scale Language Models Augmented with Medical Textbooks（LLM-AMT）的解决方案，它通过将专业医学书籍作为设计的核心，通过插件式模组来扩展LLM的能力，包括混合文献搜寻器和询问增强器。</li>
<li>results: 实验结果显示，在三个开放领域医学问题解答任务上，使用LLM-AMT可以提高LLM的专业性和准确性，提高范围在11.4%到13.2%。此外，医学书籍作为搜寻 корпу的使用比wikipedia更有价值，实验结果显示，对于医学领域来说，使用医学书籍进行扩展可以提高性能范围在9.7%到12.2%。<details>
<summary>Abstract</summary>
Large-scale language models (LLMs), such as ChatGPT, are capable of generating human-like responses for various downstream tasks, such as task-oriented dialogues and question answering. However, applying LLMs to medical domains remains challenging due to their inability to leverage domain-specific knowledge. In this study, we present the Large-scale Language Models Augmented with Medical Textbooks (LLM-AMT), which integrates authoritative medical textbooks as the cornerstone of its design, enhancing its proficiency in the specialized domain through plug-and-play modules, comprised of a Hybrid Textbook Retriever, supplemented by the Query Augmenter and the LLM Reader. Experimental evaluation on three open-domain medical question-answering tasks reveals a substantial enhancement in both the professionalism and accuracy of the LLM responses when utilizing LLM-AMT, exhibiting an improvement ranging from 11.4% to 13.2%. Despite being 100 times smaller, we found that medical textbooks as the retrieval corpus serves as a more valuable external knowledge source than Wikipedia in the medical domain. Our experiments show that textbook augmentation results in a performance improvement ranging from 9.7% to 12.2% over Wikipedia augmentation.
</details>
<details>
<summary>摘要</summary>
大规模语言模型（LLM），如ChatGPT，可以生成人类化回答 для多种下游任务，如任务导向对话和问答。然而，在医疗领域中应用LLM仍然是一个挑战，因为它们无法借鉴医疗领域专业知识。在本研究中，我们提出了医疗领域语言模型增强器（LLM-AMT），它将权威的医疗文献作为设计的核心，通过插件式模块来增强其在专业领域的能力。我们的实验表明，在三个开放领域医学问答任务上，使用LLM-AMT可以substantially提高LLM的专业性和准确性，提高回答的质量，其中提高范围为11.4%到13.2%。我们发现，医疗文献作为搜索库是医疗领域更有价值的外部知识源，而不是Wikipedia。我们的实验表明，在使用医疗文献扩展时，表现提高的范围为9.7%到12.2%。
</details></li>
</ul>
<hr>
<h2 id="FSD-An-Initial-Chinese-Dataset-for-Fake-Song-Detection"><a href="#FSD-An-Initial-Chinese-Dataset-for-Fake-Song-Detection" class="headerlink" title="FSD: An Initial Chinese Dataset for Fake Song Detection"></a>FSD: An Initial Chinese Dataset for Fake Song Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02232">http://arxiv.org/abs/2309.02232</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xieyuankun/fsd-dataset">https://github.com/xieyuankun/fsd-dataset</a></li>
<li>paper_authors: Yuankun Xie, Jingjing Zhou, Xiaolin Lu, Zhenghao Jiang, Yuxin Yang, Haonan Cheng, Long Ye</li>
<li>for: 本研究旨在提供一个特有的歌曲深度变异检测数据集，并利用这个数据集进行歌曲深度变异检测模型的训练和评估。</li>
<li>methods: 本研究使用了五种当前最佳的嗓音合成和嗓音转换技术来生成假歌曲，并使用这些假歌曲来初始化一个中文歌曲深度变异检测数据集（FSD）。然后，我们使用FSD数据集进行歌曲深度变异检测模型的训练和评估。</li>
<li>results: 我们的实验结果表明，将歌曲特有的特征提取和处理到深度变异检测模型中，可以减少平均错误率38.58%，相比Speech-trained ADD模型在FSD测试集上。<details>
<summary>Abstract</summary>
Singing voice synthesis and singing voice conversion have significantly advanced, revolutionizing musical experiences. However, the rise of "Deepfake Songs" generated by these technologies raises concerns about authenticity. Unlike Audio DeepFake Detection (ADD), the field of song deepfake detection lacks specialized datasets or methods for song authenticity verification. In this paper, we initially construct a Chinese Fake Song Detection (FSD) dataset to investigate the field of song deepfake detection. The fake songs in the FSD dataset are generated by five state-of-the-art singing voice synthesis and singing voice conversion methods. Our initial experiments on FSD revealed the ineffectiveness of existing speech-trained ADD models for the task of song deepFake detection. Thus, we employ the FSD dataset for the training of ADD models. We subsequently evaluate these models under two scenarios: one with the original songs and another with separated vocal tracks. Experiment results show that song-trained ADD models exhibit a 38.58% reduction in average equal error rate compared to speech-trained ADD models on the FSD test set.
</details>
<details>
<summary>摘要</summary>
《声音合成和声音转换技术在音乐经验方面已经取得了 significativ advancement，但是这些技术的出现也引发了 authenticity的问题。与Audio DeepFake Detection（ADD）不同的是，歌曲深伪检测领域没有专门的数据集或方法进行歌曲的真实性验证。在这篇论文中，我们首先构建了中文伪歌曲检测（FSD）数据集，以探讨歌曲深伪检测领域的问题。这些伪歌曲在FSD数据集中是由五种当前最好的声音合成和声音转换方法生成的。我们的初始实验表明，现有的speech-trained ADD模型对歌曲深伪检测任务并不有效。因此，我们使用FSD数据集来训练ADD模型。我们之后对这些模型进行了两种enario的评估：一种是使用原始的歌曲，另一种是使用分离的vocal轨。实验结果显示，使用歌曲训练的ADD模型在FSD测试集上比使用speech训练的ADD模型减少了38.58%的平均等错率。
</details></li>
</ul>
<hr>
<h2 id="DCP-Net-A-Distributed-Collaborative-Perception-Network-for-Remote-Sensing-Semantic-Segmentation"><a href="#DCP-Net-A-Distributed-Collaborative-Perception-Network-for-Remote-Sensing-Semantic-Segmentation" class="headerlink" title="DCP-Net: A Distributed Collaborative Perception Network for Remote Sensing Semantic Segmentation"></a>DCP-Net: A Distributed Collaborative Perception Network for Remote Sensing Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02230">http://arxiv.org/abs/2309.02230</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhechao Wang, Peirui Cheng, Shujing Duan, Kaiqiang Chen, Zhirui Wang, Xinming Li, Xian Sun</li>
<li>for: 提高远程感知任务中紧急情况下多平台协同观测的精度和效率。</li>
<li>methods: 提出了一种分布式协同感知网络（DCP-Net），通过将不同平台的特征集成而提高感知性能。同时，通过自适应匹配模块和相关特征融合模块来实现多平台协同观测。</li>
<li>results: 经过广泛的实验和视觉分析，DCP-Net在三个semantic segmentation dataset上表现出了明显的优势，与exist方法相比，提高了mIoU值2.61%~16.89%，达到了当前最佳水平。<details>
<summary>Abstract</summary>
Onboard intelligent processing is widely applied in emergency tasks in the field of remote sensing. However, it is predominantly confined to an individual platform with a limited observation range as well as susceptibility to interference, resulting in limited accuracy. Considering the current state of multi-platform collaborative observation, this article innovatively presents a distributed collaborative perception network called DCP-Net. Firstly, the proposed DCP-Net helps members to enhance perception performance by integrating features from other platforms. Secondly, a self-mutual information match module is proposed to identify collaboration opportunities and select suitable partners, prioritizing critical collaborative features and reducing redundant transmission cost. Thirdly, a related feature fusion module is designed to address the misalignment between local and collaborative features, improving the quality of fused features for the downstream task. We conduct extensive experiments and visualization analyses using three semantic segmentation datasets, including Potsdam, iSAID and DFC23. The results demonstrate that DCP-Net outperforms the existing methods comprehensively, improving mIoU by 2.61%~16.89% at the highest collaboration efficiency, which promotes the performance to a state-of-the-art level.
</details>
<details>
<summary>摘要</summary>
在远程感知领域的紧急任务中，船载智能处理广泛应用。然而，它主要受限于个人平台的有限观测范围以及易受干扰的问题，导致准确性有限。针对当前多平台合作观测的状况，本文创新提出了分布式合作感知网络（DCP-Net）。首先，提议的DCP-Net帮助成员提高感知性能，将其他平台的特征集成到自己平台上。其次，基于自我相互信息匹配模块，用于识别合作机会，选择适合的合作伙伴，优先级划分关键合作特征，降低重复传输成本。第三，关联特征融合模块用于解决本地特征与合作特征之间的不一致问题，提高下游任务的质量。我们对三个semantic segmentation数据集进行了广泛的实验和视觉分析，包括Potsdam、iSAID和DFC23。结果表明，DCP-Net与现有方法相比，全面性地提高了miou值，在最高的合作效率下提高了2.61%~16.89%，提升性能至当前领先水平。
</details></li>
</ul>
<hr>
<h2 id="Dense-Object-Grounding-in-3D-Scenes"><a href="#Dense-Object-Grounding-in-3D-Scenes" class="headerlink" title="Dense Object Grounding in 3D Scenes"></a>Dense Object Grounding in 3D Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02224">http://arxiv.org/abs/2309.02224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wencan Huang, Daizong Liu, Wei Hu</li>
<li>for: 本研究旨在解决现有3D物体准确定位方法的限制，即只能根据单个句子描述一个物体进行定位。为了解决这个问题，我们引入了3D密集物体定位（3D DOG）任务，即在更复杂的段落中找到多个物体的定位。</li>
<li>methods: 我们提出了一种新的核心 трансформа器基于框架，名为3DOGSFormer。该框架包括一个地址驱动的本地变换器解码器，以及一个提案驱动的全球变换器解码器。这两个解码器协作以生成更加准确的定位提案。</li>
<li>results: 我们的3DOGSFormer在三个不同的测试集（Nr3D、Sr3D和ScanRefer）上进行了广泛的实验，结果表明，我们的方法在比较复杂的3D场景中对多个物体的定位有较高的准确率，与现有的3D单物体定位方法和密集物体定位方法相比，具有显著的优势。<details>
<summary>Abstract</summary>
Localizing objects in 3D scenes according to the semantics of a given natural language is a fundamental yet important task in the field of multimedia understanding, which benefits various real-world applications such as robotics and autonomous driving. However, the majority of existing 3D object grounding methods are restricted to a single-sentence input describing an individual object, which cannot comprehend and reason more contextualized descriptions of multiple objects in more practical 3D cases. To this end, we introduce a new challenging task, called 3D Dense Object Grounding (3D DOG), to jointly localize multiple objects described in a more complicated paragraph rather than a single sentence. Instead of naively localizing each sentence-guided object independently, we found that dense objects described in the same paragraph are often semantically related and spatially located in a focused region of the 3D scene. To explore such semantic and spatial relationships of densely referred objects for more accurate localization, we propose a novel Stacked Transformer based framework for 3D DOG, named 3DOGSFormer. Specifically, we first devise a contextual query-driven local transformer decoder to generate initial grounding proposals for each target object. Then, we employ a proposal-guided global transformer decoder that exploits the local object features to learn their correlation for further refining initial grounding proposals. Extensive experiments on three challenging benchmarks (Nr3D, Sr3D, and ScanRefer) show that our proposed 3DOGSFormer outperforms state-of-the-art 3D single-object grounding methods and their dense-object variants by significant margins.
</details>
<details>
<summary>摘要</summary>
本文提出了一个新的挑战任务，即3D密集物地理（3D DOG），它的目的是在3D场景中对自然语言中提供的多个对象进行同时地理化。现有的大多数3D物理地理方法都是基于单句输入，无法处理更复杂的多对象描述。为此，我们提出了一种新的框架，即3DOGSFormer，它利用了堆叠的变换器来探索多个对象之间的含义和空间关系，从而实现更高精度的物理地理。我们首先设计了一种基于上下文的查询驱动的本地变换器嵌入器，以生成每个目标对象的初步锚点提案。然后，我们使用一种提案驱动的全球变换器嵌入器，利用本地对象特征来学习它们之间的相互关系，进一步细化初步锚点提案。我们在三个具有挑战性的测试基准（Nr3D、Sr3D和ScanRefer）上进行了广泛的实验，结果显示，我们的提案的3DOGSFormer在与现有的3D单个对象地理方法和密集对象变体之间具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Improving-equilibrium-propagation-without-weight-symmetry-through-Jacobian-homeostasis"><a href="#Improving-equilibrium-propagation-without-weight-symmetry-through-Jacobian-homeostasis" class="headerlink" title="Improving equilibrium propagation without weight symmetry through Jacobian homeostasis"></a>Improving equilibrium propagation without weight symmetry through Jacobian homeostasis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02214">http://arxiv.org/abs/2309.02214</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/laborieux-axel/generalized-holo-ep">https://github.com/laborieux-axel/generalized-holo-ep</a></li>
<li>paper_authors: Axel Laborieux, Friedemann Zenke</li>
<li>for: 这个论文是为了研究等温傅振（EP）算法在生物或分析型神经网络上的应用。</li>
<li>methods: 这个论文使用了等温傅振算法，但是它需要权重对称和极小的平衡冲击来计算神经网络中的梯度。</li>
<li>results: 研究发现，权重不对称会导致等温傅振算法的表现不佳，而且可能会导致学习任务的低效。为了解决这个问题， authors propose了一种新的自适应目标函数，可以直接惩罚神经网络中权重的不对称性。这种自适应目标函数可以帮助神经网络更好地解决复杂的任务，如 ImageNet 32x32。<details>
<summary>Abstract</summary>
Equilibrium propagation (EP) is a compelling alternative to the backpropagation of error algorithm (BP) for computing gradients of neural networks on biological or analog neuromorphic substrates. Still, the algorithm requires weight symmetry and infinitesimal equilibrium perturbations, i.e., nudges, to estimate unbiased gradients efficiently. Both requirements are challenging to implement in physical systems. Yet, whether and how weight asymmetry affects its applicability is unknown because, in practice, it may be masked by biases introduced through the finite nudge. To address this question, we study generalized EP, which can be formulated without weight symmetry, and analytically isolate the two sources of bias. For complex-differentiable non-symmetric networks, we show that the finite nudge does not pose a problem, as exact derivatives can still be estimated via a Cauchy integral. In contrast, weight asymmetry introduces bias resulting in low task performance due to poor alignment of EP's neuronal error vectors compared to BP. To mitigate this issue, we present a new homeostatic objective that directly penalizes functional asymmetries of the Jacobian at the network's fixed point. This homeostatic objective dramatically improves the network's ability to solve complex tasks such as ImageNet 32x32. Our results lay the theoretical groundwork for studying and mitigating the adverse effects of imperfections of physical networks on learning algorithms that rely on the substrate's relaxation dynamics.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese<</SYS>>平衡传播（EP）是一种有吸引力的替代品 для误差传播算法（BP），用于计算神经网络的梯度。然而，EP算法需要权重的对称和微小的平衡干扰，以便效率地计算梯度。这两个需求在物理系统中实现可以是问题。但是，权重的不对称性是否会影响EP的应用是未知的，因为在实践中可能会遭受由固定干扰引入的偏见。为了解决这个问题，我们研究了一种简化EP的方法，可以不需要权重的对称。我们还可以分析EP中两种source of bias，并证明在复杂不对称的神经网络上，finite nudge不会对梯度的计算产生影响。然而，权重的不对称性会导致梯度的误差，从而降低任务的性能。为了解决这个问题，我们提出了一个新的家ostatic objective，可以直接 penalty函数的不对称性。这个家ostatic objective可以对任务如ImageNet 32x32进行解决，并获得了良好的性能。我们的结果对于研究和解决物理网络上学习算法的不完善性问题提供了理论基础。
</details></li>
</ul>
<hr>
<h2 id="Exchanging-based-Multimodal-Fusion-with-Transformer"><a href="#Exchanging-based-Multimodal-Fusion-with-Transformer" class="headerlink" title="Exchanging-based Multimodal Fusion with Transformer"></a>Exchanging-based Multimodal Fusion with Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02190">http://arxiv.org/abs/2309.02190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/recklessronan/muse">https://github.com/recklessronan/muse</a></li>
<li>paper_authors: Renyu Zhu, Chengcheng Han, Yong Qian, Qiushi Sun, Xiang Li, Ming Gao, Xuezhi Cao, Yunsen Xian</li>
<li>for: 本文研究了多模态融合的问题，特别是用于文本视频融合。</li>
<li>methods: 本文提出了一种基于Transformer的新的多模态融合模型MuSE，使用了两个编码器将多modal输入映射到不同的低维度空间中，并使用了两个解码器来规范嵌入并将其拟合到同一个空间中。</li>
<li>results: 对多模态命名实体识别和多模态情感分析两个任务进行了广泛的实验，结果表明MuSE比其他竞争者更高效。<details>
<summary>Abstract</summary>
We study the problem of multimodal fusion in this paper. Recent exchanging-based methods have been proposed for vision-vision fusion, which aim to exchange embeddings learned from one modality to the other. However, most of them project inputs of multimodalities into different low-dimensional spaces and cannot be applied to the sequential input data. To solve these issues, in this paper, we propose a novel exchanging-based multimodal fusion model MuSE for text-vision fusion based on Transformer. We first use two encoders to separately map multimodal inputs into different low-dimensional spaces. Then we employ two decoders to regularize the embeddings and pull them into the same space. The two decoders capture the correlations between texts and images with the image captioning task and the text-to-image generation task, respectively. Further, based on the regularized embeddings, we present CrossTransformer, which uses two Transformer encoders with shared parameters as the backbone model to exchange knowledge between multimodalities. Specifically, CrossTransformer first learns the global contextual information of the inputs in the shallow layers. After that, it performs inter-modal exchange by selecting a proportion of tokens in one modality and replacing their embeddings with the average of embeddings in the other modality. We conduct extensive experiments to evaluate the performance of MuSE on the Multimodal Named Entity Recognition task and the Multimodal Sentiment Analysis task. Our results show the superiority of MuSE against other competitors. Our code and data are provided at https://github.com/RecklessRonan/MuSE.
</details>
<details>
<summary>摘要</summary>
我们在这篇论文中研究了多模态融合问题。在最近的交换基本方法中，有些方法用于视觉融合，其目的是将一个模态的嵌入交换到另一个模态中。然而，大多数方法将多模态输入映射到不同的低维度空间，无法应用于顺序输入数据。为解决这些问题，在这篇论文中，我们提出了一种基于Transformer的新的多模态融合模型MuSE，用于文本视觉融合。我们首先使用两个encoder将多模态输入映射到不同的低维度空间。然后，我们employs两个decoder来规范嵌入并将其拖入同一个空间。两个decoder使得文本和图像之间的相关性能够更好地捕捉，并通过图像描述任务和文本到图像生成任务来规范嵌入。此外，基于规范嵌入，我们还提出了交换Transformer，它使用两个Transformer encoder的共享参数作为后备模型，以交换多模态之间的知识。具体来说，交换Transformer先学习输入的全局 контекст信息，然后进行交换，选择一个模态中的一些Token，并将其嵌入换成另一个模态中的均值。我们对MuSE进行了广泛的实验，以评估其在多模态命名实体识别任务和多模态情感分析任务中的表现。我们的结果显示MuSE在与其他竞争对手相比，具有更高的表现。我们的代码和数据可以在https://github.com/RecklessRonan/MuSE上获取。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-BERT-Language-Models-for-Multi-Lingual-ESG-Issue-Identification"><a href="#Leveraging-BERT-Language-Models-for-Multi-Lingual-ESG-Issue-Identification" class="headerlink" title="Leveraging BERT Language Models for Multi-Lingual ESG Issue Identification"></a>Leveraging BERT Language Models for Multi-Lingual ESG Issue Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02189">http://arxiv.org/abs/2309.02189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elvys Linhares Pontes, Mohamed Benjannet, Lam Kim Ming</li>
<li>for: 这项研究的目的是为投资者更好地了解公司的可持续发展和社会责任，通过分类新闻文章的ESG Issue标签来提高投资决策的可持续性。</li>
<li>methods: 该研究使用BERT语言模型来实现新闻文章的分类，并 comparing different BERT语言模型和SVM折衔模型的表现。</li>
<li>results: 研究发现，使用RoBERTa分类器得到了英文测试集第二名的成绩，并与法语测试集第五名相当。此外，SVM折衔模型特制 для中文语言也表现出色，在测试集上排名第二。<details>
<summary>Abstract</summary>
Environmental, Social, and Governance (ESG) has been used as a metric to measure the negative impacts and enhance positive outcomes of companies in areas such as the environment, society, and governance. Recently, investors have increasingly recognized the significance of ESG criteria in their investment choices, leading businesses to integrate ESG principles into their operations and strategies. The Multi-Lingual ESG Issue Identification (ML-ESG) shared task encompasses the classification of news documents into 35 distinct ESG issue labels. In this study, we explored multiple strategies harnessing BERT language models to achieve accurate classification of news documents across these labels. Our analysis revealed that the RoBERTa classifier emerged as one of the most successful approaches, securing the second-place position for the English test dataset, and sharing the fifth-place position for the French test dataset. Furthermore, our SVM-based binary model tailored for the Chinese language exhibited exceptional performance, earning the second-place rank on the test dataset.
</details>
<details>
<summary>摘要</summary>
环境、社会和管理（ESG）被用作公司负面影响和改善效果的度量。近期，投资者对ESG标准的重要性日益认识，导致企业将ESG原则 integrate into their operations and strategies。这个多语言ESG问题识别（ML-ESG）共同任务涵盖35个不同的ESG问题标签。本研究通过BERT语言模型的多种策略来实现新闻文档的准确分类。我们的分析发现，RoBERTa分类器在英语测试数据集中获得了第二名的成绩，并在法语测试数据集中与其他模型并列第五名。此外，我们对中文语言的SVM二分类模型也展现出了出色的表现，在测试数据集中获得了第二名。
</details></li>
</ul>
<hr>
<h2 id="AniPortraitGAN-Animatable-3D-Portrait-Generation-from-2D-Image-Collections"><a href="#AniPortraitGAN-Animatable-3D-Portrait-Generation-from-2D-Image-Collections" class="headerlink" title="AniPortraitGAN: Animatable 3D Portrait Generation from 2D Image Collections"></a>AniPortraitGAN: Animatable 3D Portrait Generation from 2D Image Collections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02186">http://arxiv.org/abs/2309.02186</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YueWuHKUST/AniPortraitGAN">https://github.com/YueWuHKUST/AniPortraitGAN</a></li>
<li>paper_authors: Yue Wu, Sicheng Xu, Jianfeng Xiang, Fangyun Wei, Qifeng Chen, Jiaolong Yang, Xin Tong</li>
<li>for: 生成高质量的3D人像视频</li>
<li>methods: 基于生成光谱抽象表示法和可学习头部和肩部变形的3D人像生成模型</li>
<li>results: 使用不结构化2D图像集训练的方法可以生成多样性和高质量的3D人像视频，并可以控制不同属性的表达Here’s a more detailed explanation of each point:</li>
<li>for: The paper is focused on generating high-quality 3D portrait videos, which are relatively rare in real life and are challenging to generate using existing methods.</li>
<li>methods: The proposed method is based on a generative radiance manifold representation and includes learnable facial and head-shoulder deformations. The method also uses a dual-camera rendering and adversarial learning scheme to improve the quality of the generated faces.</li>
<li>results: The method, trained on unstructured 2D image collections, can generate diverse and high-quality 3D portraits with desired control over different properties, such as facial expression, head pose, and shoulder movements.<details>
<summary>Abstract</summary>
Previous animatable 3D-aware GANs for human generation have primarily focused on either the human head or full body. However, head-only videos are relatively uncommon in real life, and full body generation typically does not deal with facial expression control and still has challenges in generating high-quality results. Towards applicable video avatars, we present an animatable 3D-aware GAN that generates portrait images with controllable facial expression, head pose, and shoulder movements. It is a generative model trained on unstructured 2D image collections without using 3D or video data. For the new task, we base our method on the generative radiance manifold representation and equip it with learnable facial and head-shoulder deformations. A dual-camera rendering and adversarial learning scheme is proposed to improve the quality of the generated faces, which is critical for portrait images. A pose deformation processing network is developed to generate plausible deformations for challenging regions such as long hair. Experiments show that our method, trained on unstructured 2D images, can generate diverse and high-quality 3D portraits with desired control over different properties.
</details>
<details>
<summary>摘要</summary>
以前的可动画3D意识GANs为人类生成都主要集中在人头或全身上。然而，头部视频较少出现在实际生活中，全身生成通常没有控制表情和脸部表现的能力，并且仍有高质量结果生成的挑战。为应用视频化身，我们提出了可动画3D意识GAN，该模型可生成带有可控表情、头部姿势和肩部运动的肖像图像。我们基于生成抛光扩散表示，并增加了可学习的脸部和头部运动扭曲。我们还提出了双摄像头渲染和对抗学习方案，以提高生成的脸部质量，这是对肖像图像的关键。此外，我们还开发了一个挑战区域 such as long hair 的姿势处理网络，以生成可能的姿势扭曲。实验表明，我们的方法，通过未结构化的2D图像集训练，可以生成多样化和高质量的3D肖像图像，并且可以控制不同的属性。
</details></li>
</ul>
<hr>
<h2 id="BEVTrack-A-Simple-Baseline-for-3D-Single-Object-Tracking-in-Bird’s-Eye-View"><a href="#BEVTrack-A-Simple-Baseline-for-3D-Single-Object-Tracking-in-Bird’s-Eye-View" class="headerlink" title="BEVTrack: A Simple Baseline for 3D Single Object Tracking in Bird’s-Eye View"></a>BEVTrack: A Simple Baseline for 3D Single Object Tracking in Bird’s-Eye View</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02185">http://arxiv.org/abs/2309.02185</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xmm-prio/bevtrack">https://github.com/xmm-prio/bevtrack</a></li>
<li>paper_authors: Yuxiang Yang, Yingqi Deng, Jiahao Nie, Jing Zhang</li>
<li>for: 3D single object tracking (SOT) in point clouds, specifically in autonomous driving scenarios where target objects maintain spatial adjacency across frames.</li>
<li>methods: converts consecutive point clouds into Bird’s-Eye View representation, encodes spatial proximity and captures motion cues via simple element-wise operation and convolutional layers, and directly learns the underlying motion distribution without making assumptions.</li>
<li>results: achieves state-of-the-art performance on KITTI and NuScenes datasets with a high inference speed of 122 FPS.<details>
<summary>Abstract</summary>
3D single object tracking (SOT) in point clouds is still a challenging problem due to appearance variation, distractors, and high sparsity of point clouds. Notably, in autonomous driving scenarios, the target object typically maintains spatial adjacency across consecutive frames, predominantly moving horizontally. This spatial continuity offers valuable prior knowledge for target localization. However, existing trackers, which often employ point-wise representations, struggle to efficiently utilize this knowledge owing to the irregular format of such representations. Consequently, they require elaborate designs and solving multiple subtasks to establish spatial correspondence. In this paper, we introduce BEVTrack, a simple yet strong baseline framework for 3D SOT. After converting consecutive point clouds into the common Bird's-Eye View representation, BEVTrack inherently encodes spatial proximity and adeptly captures motion cues for tracking via a simple element-wise operation and convolutional layers. Additionally, to better deal with objects having diverse sizes and moving patterns, BEVTrack directly learns the underlying motion distribution rather than making a fixed Laplacian or Gaussian assumption as in previous works. Without bells and whistles, BEVTrack achieves state-of-the-art performance on KITTI and NuScenes datasets while maintaining a high inference speed of 122 FPS. The code will be released at https://github.com/xmm-prio/BEVTrack.
</details>
<details>
<summary>摘要</summary>
三元素 объек tracking (SOT) in point clouds 仍然是一个挑战，主要因为外观变化、干扰和点云的稀疏性。值得注意的是，在自动驾驶场景中，目标对象通常在连续帧中保持空间邻近，主要在水平方向上移动。这种空间继续性提供了有价值的先知知识 для目标位置确定。然而，现有的跟踪器，通常使用点 wise 表示，困难减少这种知识，因为点云的不规则格式。因此，它们需要较复杂的设计和解决多个子任务来确立空间匹配。在这篇论文中，我们介绍了 BEVTrack，一个简单却强大的基eline框架 для 3D SOT。将 consecutive point clouds 转化为共同 Bird's-Eye View 表示后，BEVTrack 自然地编码了空间 proximity 并善于捕捉运动指示符，通过简单的元素 wise 操作和卷积层来跟踪。此外，为了更好地处理具有不同尺寸和移动模式的对象，BEVTrack 直接学习下流动分布而不是在前一些作品中做固定 Laplacian 或 Gaussian 假设。无论各种饰物，BEVTrack  achieve state-of-the-art 性能在 KITTI 和 NuScenes 数据集上，并保持高速推理速度为 122 FPS。代码将在 https://github.com/xmm-prio/BEVTrack 上发布。
</details></li>
</ul>
<hr>
<h2 id="Dual-Relation-Alignment-for-Composed-Image-Retrieval"><a href="#Dual-Relation-Alignment-for-Composed-Image-Retrieval" class="headerlink" title="Dual Relation Alignment for Composed Image Retrieval"></a>Dual Relation Alignment for Composed Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02169">http://arxiv.org/abs/2309.02169</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xintong Jiang, Yaxiong Wang, Yujiao Wu, Meng Wang, Xueming Qian<br>for: 本研究旨在提高组合图像检索性能，通过融合两种关系：Explicit Relation（图像参考和补充文本）和Implicit Relation（图像参考和目标图像）。methods: 我们提出了一种新的框架，称为双关系对齐，它将Explicit Relation和Implicit Relation完全融合，以便充分利用这些对象之间的相互关系。我们设计了一个视觉混合器，将参考图像和目标图像 fusion，然后将结果表示作两种角色：（1）对Semantic Alignment with 补充文本进行对应，（2）为Explicit Relation模型增强。results: 我们在CIRR和FashionIQ两个Popular Dataset上进行了广泛的实验，结果表明我们的双关系学习方法可以明显提高组合图像检索性能。<details>
<summary>Abstract</summary>
Composed image retrieval, a task involving the search for a target image using a reference image and a complementary text as the query, has witnessed significant advancements owing to the progress made in cross-modal modeling. Unlike the general image-text retrieval problem with only one alignment relation, i.e., image-text, we argue for the existence of two types of relations in composed image retrieval. The explicit relation pertains to the reference image & complementary text-target image, which is commonly exploited by existing methods. Besides this intuitive relation, the observations during our practice have uncovered another implicit yet crucial relation, i.e., reference image & target image-complementary text, since we found that the complementary text can be inferred by studying the relation between the target image and the reference image. Regrettably, existing methods largely focus on leveraging the explicit relation to learn their networks, while overlooking the implicit relation. In response to this weakness, We propose a new framework for composed image retrieval, termed dual relation alignment, which integrates both explicit and implicit relations to fully exploit the correlations among the triplets. Specifically, we design a vision compositor to fuse reference image and target image at first, then the resulted representation will serve two roles: (1) counterpart for semantic alignment with the complementary text and (2) compensation for the complementary text to boost the explicit relation modeling, thereby implant the implicit relation into the alignment learning. Our method is evaluated on two popular datasets, CIRR and FashionIQ, through extensive experiments. The results confirm the effectiveness of our dual-relation learning in substantially enhancing composed image retrieval performance.
</details>
<details>
<summary>摘要</summary>
新型图像检索任务：基于参考图像和补充文本的目标图像检索，受到跨模型的进步所见证。不同于一般的图像文本检索问题，我们认为图像检索任务存在两种关系：一种是明确的关系，即参考图像和补充文本-目标图像，这种关系通常被现有方法利用。此外，我们在实践中发现了一种隐式 yet crucial 的关系，即参考图像和目标图像-补充文本，因为我们发现了补充文本可以通过研究参考图像和目标图像之间的关系来推导。然而，现有方法主要是通过明确的关系来学习其网络。为了解决这个弱点，我们提出了一种新的框架，即双关系协调，这种框架将明确和隐式关系完全利用，以便充分利用参考图像、目标图像和补充文本之间的相关性。我们设计了一个视觉笔记，用于将参考图像和目标图像 fusion，然后得到的表示将扮演两个角色：（1）对应文本的 semantic alignment 和（2）用于强化明确关系模型，以便在 alignment 学习中嵌入隐式关系。我们的方法在 CIRR 和 FashionIQ 两个流行的数据集上进行了广泛的实验，结果证明了我们的双关系学习在图像检索性能上具有显著提高的效果。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Imitation-Learning-Algorithms-Recent-Developments-and-Challenges"><a href="#A-Survey-of-Imitation-Learning-Algorithms-Recent-Developments-and-Challenges" class="headerlink" title="A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges"></a>A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02473">http://arxiv.org/abs/2309.02473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maryam Zare, Parham M. Kebria, Abbas Khosravi, Saeid Nahavandi</li>
<li>For: This paper provides an introduction to imitation learning (IL) and offers an overview of its underlying assumptions and approaches in the context of robotics and artificial intelligence (AI).* Methods: The paper discusses recent advances and emerging areas of research in IL, including the use of demonstrations to learn desired behavior, and addresses common challenges associated with IL.* Results: The paper provides a comprehensive guide to the growing field of IL in robotics and AI, including potential directions for future research.Here’s the text in Simplified Chinese:</li>
<li>for: 这篇论文是提供对人工智能和机器人领域内的学习模式的引入和概述，包括学习从专家示例的方法。</li>
<li>methods: 论文讨论了现有的IL技术和新兴领域的研究，以及面临IL的常见挑战。</li>
<li>results: 论文提供了人工智能和机器人领域内IL的总结和未来研究方向。<details>
<summary>Abstract</summary>
In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through reward functions (as done in reinforcement learning (RL)) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.   This paper aims to provide an introduction to IL and an overview of its underlying assumptions and approaches. It also offers a detailed description of recent advances and emerging areas of research in the field. Additionally, the paper discusses how researchers have addressed common challenges associated with IL and provides potential directions for future research. Overall, the goal of the paper is to provide a comprehensive guide to the growing field of IL in robotics and AI.
</details>
<details>
<summary>摘要</summary>
This paper provides an introduction to IL and an overview of its underlying assumptions and approaches. It also offers a detailed description of recent advances and emerging areas of research in the field. Additionally, the paper discusses how researchers have addressed common challenges associated with IL and provides potential directions for future research. The goal of the paper is to provide a comprehensive guide to the growing field of IL in robotics and AI.
</details></li>
</ul>
<hr>
<h2 id="Model-based-Offline-Policy-Optimization-with-Adversarial-Network"><a href="#Model-based-Offline-Policy-Optimization-with-Adversarial-Network" class="headerlink" title="Model-based Offline Policy Optimization with Adversarial Network"></a>Model-based Offline Policy Optimization with Adversarial Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02157">http://arxiv.org/abs/2309.02157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junming-yang/moan">https://github.com/junming-yang/moan</a></li>
<li>paper_authors: Junming Yang, Xingguo Chen, Shengyuan Wang, Bolei Zhang</li>
<li>for: 提出了一种基于模型的线上权限学习（RL）方法，以避免在线环境中的成本交互，并且可以在离线数据集上进行策略优化。</li>
<li>methods: 使用了对抗学习来建立一个更好的逻辑分布，并通过对抗网络来提供模型的不确定性量化。</li>
<li>results: 比较了现有的基于模型的离线RL方法，并取得了更高的性能和更准确的不确定性量化。<details>
<summary>Abstract</summary>
Model-based offline reinforcement learning (RL), which builds a supervised transition model with logging dataset to avoid costly interactions with the online environment, has been a promising approach for offline policy optimization. As the discrepancy between the logging data and online environment may result in a distributional shift problem, many prior works have studied how to build robust transition models conservatively and estimate the model uncertainty accurately. However, the over-conservatism can limit the exploration of the agent, and the uncertainty estimates may be unreliable. In this work, we propose a novel Model-based Offline policy optimization framework with Adversarial Network (MOAN). The key idea is to use adversarial learning to build a transition model with better generalization, where an adversary is introduced to distinguish between in-distribution and out-of-distribution samples. Moreover, the adversary can naturally provide a quantification of the model's uncertainty with theoretical guarantees. Extensive experiments showed that our approach outperforms existing state-of-the-art baselines on widely studied offline RL benchmarks. It can also generate diverse in-distribution samples, and quantify the uncertainty more accurately.
</details>
<details>
<summary>摘要</summary>
模型基于的线上强化学习（RL），通过使用日志数据建立一个监督式过渡模型，以避免在线环境中的成本性交互，已经是无线环境中的一种有前途的方法。然而， logging 数据和在线环境之间的差异可能会导致分布性Shift问题，许多前作都研究了如何建立保守的过渡模型和准确地估计模型的不确定性。然而，过于保守的建模可能会限制 agent 的探索，而估计的不确定性可能是不可靠的。在这个工作中，我们提出了一种基于 Model-based Offline policy optimization 框架的 Adversarial Network (MOAN)。关键思想是使用对抗学习建立一个更好的泛化过渡模型，其中一个对手可以分辨在 Distribution 和 Out-of-Distribution 样本之间。此外，对手还可以自然地提供一个量化的模型不确定性的理论保证。我们的方法在 widely  studied 的 offline RL 标准准样本上进行了广泛的实验，并显示了我们的方法在性能和多样性方面的超过现有基eline。它还可以更准确地量化不确定性。
</details></li>
</ul>
<hr>
<h2 id="Making-Large-Language-Models-Better-Reasoners-with-Alignment"><a href="#Making-Large-Language-Models-Better-Reasoners-with-Alignment" class="headerlink" title="Making Large Language Models Better Reasoners with Alignment"></a>Making Large Language Models Better Reasoners with Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02144">http://arxiv.org/abs/2309.02144</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiyi Wang, Lei Li, Liang Chen, Feifan Song, Binghuai Lin, Yunbo Cao, Tianyu Liu, Zhifang Sui</li>
<li>for: 提升大语言模型（LLM）的理解能力，特别是在链式思维（COT）理解过程中。</li>
<li>methods: 通过对 LLM 进行特定的微调，使其在 COT 理解过程中提高其理解能力。</li>
<li>results: 通过实施新的对齐练习（AFT）方法，可以有效地解决 LLM 在 COT 理解过程中存在的评价不一致问题，并提高其理解能力。<details>
<summary>Abstract</summary>
Reasoning is a cognitive process of using evidence to reach a sound conclusion. The reasoning capability is essential for large language models (LLMs) to serve as the brain of the artificial general intelligence agent. Recent studies reveal that fine-tuning LLMs on data with the chain of thought (COT) reasoning process can significantly enhance their reasoning capabilities. However, we find that the fine-tuned LLMs suffer from an \textit{Assessment Misalignment} problem, i.e., they frequently assign higher scores to subpar COTs, leading to potential limitations in their reasoning abilities. To address this problem, we introduce an \textit{Alignment Fine-Tuning (AFT)} paradigm, which involves three steps: 1) fine-tuning LLMs with COT training data; 2) generating multiple COT responses for each question, and categorizing them into positive and negative ones based on whether they achieve the correct answer; 3) calibrating the scores of positive and negative responses given by LLMs with a novel constraint alignment loss. Specifically, the constraint alignment loss has two objectives: a) Alignment, which guarantees that positive scores surpass negative scores to encourage answers with high-quality COTs; b) Constraint, which keeps the negative scores confined to a reasonable range to prevent the model degradation. Beyond just the binary positive and negative feedback, the constraint alignment loss can be seamlessly adapted to the ranking situations when ranking feedback is accessible. Furthermore, we also delve deeply into recent ranking-based alignment methods, such as DPO, RRHF, and PRO, and discover that the constraint, which has been overlooked by these approaches, is also crucial for their performance. Extensive experiments on four reasoning benchmarks with both binary and ranking feedback demonstrate the effectiveness of AFT.
</details>
<details>
<summary>摘要</summary>
理智是认知过程中的证据使用，以达到正确的结论。理智能力是人工通用智能代理人的关键能力。现代研究表明，对大语言模型（LLM）进行适应过程可以显著提高其理智能力。然而，我们发现，经过精度调整后的LLM受到了评价不一致（Assessment Misalignment）问题的限制，即它们经常对低质量的链条思维（COT）进行高分评价，可能导致其理智能力受到限制。为解决这个问题，我们提出了一种Alignment Fine-Tuning（AFT）方法，包括以下三步：1）对LLM进行COT训练数据的精度调整；2）为每个问题生成多个COT响应，并将它们分为正确和错误的两类 based on whether they achieve the correct answer; 3）对LLM对正确和错误响应的分配分数进行Calibration，使其符合一个新的约束Alignmentloss。具体来说，Alignmentloss有两个目标：a）Alignment，确保正确的分数高于错误的分数，以鼓励高质量的COT; b）Constraint，使错误的分数尽可能地受限，以避免模型下降。此外，我们还发现，当有排名反馈时，这种约束可以轻松地适应到排名情况下。此外，我们还对最近的排名基于Alignment方法，如DPO、RRHF和PRO进行了深入研究，发现，这种约束也是这些方法的关键因素。我们在四个理智benchmark上进行了广泛的实验，并证明了AFT的效果。
</details></li>
</ul>
<hr>
<h2 id="A-Lightweight-Rapid-and-Efficient-Deep-Convolutional-Network-for-Chest-X-Ray-Tuberculosis-Detection"><a href="#A-Lightweight-Rapid-and-Efficient-Deep-Convolutional-Network-for-Chest-X-Ray-Tuberculosis-Detection" class="headerlink" title="A Lightweight, Rapid and Efficient Deep Convolutional Network for Chest X-Ray Tuberculosis Detection"></a>A Lightweight, Rapid and Efficient Deep Convolutional Network for Chest X-Ray Tuberculosis Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02140">http://arxiv.org/abs/2309.02140</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dani-capellan/LightTBNet">https://github.com/dani-capellan/LightTBNet</a></li>
<li>paper_authors: Daniel Capellán-Martín, Juan J. Gómez-Valverde, David Bermejo-Peláez, María J. Ledesma-Carbayo</li>
<li>for: 您的论文旨在提高肺部X射线图像的诊断精度，减少误判。</li>
<li>methods: 您使用了深度学习技术，开发了一种特制的轻量级、快速、计算效率低的快速预测模型，以提高肺部X射线图像的诊断精度。</li>
<li>results: 您的模型在独立测试集上达到了0.906、0.907和0.961的准确率、F1分数和ROC曲线值，表明模型在诊断肺部TB的能力强，并且具有快速预测和低计算和存储需求，适用于在低TB发病地区使用。<details>
<summary>Abstract</summary>
Tuberculosis (TB) is still recognized as one of the leading causes of death worldwide. Recent advances in deep learning (DL) have shown to enhance radiologists' ability to interpret chest X-ray (CXR) images accurately and with fewer errors, leading to a better diagnosis of this disease. However, little work has been done to develop models capable of diagnosing TB that offer good performance while being efficient, fast and computationally inexpensive. In this work, we propose LightTBNet, a novel lightweight, fast and efficient deep convolutional network specially customized to detect TB from CXR images. Using a total of 800 frontal CXR images from two publicly available datasets, our solution yielded an accuracy, F1 and area under the ROC curve (AUC) of 0.906, 0.907 and 0.961, respectively, on an independent test subset. The proposed model demonstrates outstanding performance while delivering a rapid prediction, with minimal computational and memory requirements, making it highly suitable for deployment in handheld devices that can be used in low-resource areas with high TB prevalence. Code publicly available at https://github.com/dani-capellan/LightTBNet.
</details>
<details>
<summary>摘要</summary>
肺炎病毒 (TB) 仍然被认为全球主要的死亡原因之一。latest advances in deep learning (DL) 已经显示了改善医生解读胸部X射线 (CXR) 像素的能力，导致更好的这病的诊断。然而， little work has been done to develop models capable of diagnosing TB that offer good performance while being efficient, fast and computationally inexpensive. In this work, we propose LightTBNet, a novel lightweight, fast and efficient deep convolutional network specially customized to detect TB from CXR images. Using a total of 800 frontal CXR images from two publicly available datasets, our solution yielded an accuracy, F1 and area under the ROC curve (AUC) of 0.906, 0.907 and 0.961, respectively, on an independent test subset. The proposed model demonstrates outstanding performance while delivering a rapid prediction, with minimal computational and memory requirements, making it highly suitable for deployment in handheld devices that can be used in low-resource areas with high TB prevalence. Code publicly available at https://github.com/dani-capellan/LightTBNet.Note: Please note that the translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Pre-Training-Boosts-Semantic-Scene-Segmentation-on-LiDAR-data"><a href="#Self-Supervised-Pre-Training-Boosts-Semantic-Scene-Segmentation-on-LiDAR-data" class="headerlink" title="Self-Supervised Pre-Training Boosts Semantic Scene Segmentation on LiDAR data"></a>Self-Supervised Pre-Training Boosts Semantic Scene Segmentation on LiDAR data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02139">http://arxiv.org/abs/2309.02139</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marionacaros/barlow-twins-for-sem-seg">https://github.com/marionacaros/barlow-twins-for-sem-seg</a></li>
<li>paper_authors: Mariona Carós, Ariadna Just, Santi Seguí, Jordi Vitrià</li>
<li>for: 本研究旨在实现从无标注数据中学习Semantic Scene Segmentation（实物景像分类），以减少需要标注的数据量。</li>
<li>methods: 本研究使用Barlow Twins自我超vised encoder进行预训练，并将其用作实物景像分类任务中的预训练网络。</li>
<li>results: 实验结果显示，我们的无标注预训练策略可以增加实物景像分类任务中的表现，特别是对于少数类别的表现。<details>
<summary>Abstract</summary>
Airborne LiDAR systems have the capability to capture the Earth's surface by generating extensive point cloud data comprised of points mainly defined by 3D coordinates. However, labeling such points for supervised learning tasks is time-consuming. As a result, there is a need to investigate techniques that can learn from unlabeled data to significantly reduce the number of annotated samples. In this work, we propose to train a self-supervised encoder with Barlow Twins and use it as a pre-trained network in the task of semantic scene segmentation. The experimental results demonstrate that our unsupervised pre-training boosts performance once fine-tuned on the supervised task, especially for under-represented categories.
</details>
<details>
<summary>摘要</summary>
空中探测LiDAR系统可以捕捉地球表面，生成大量的点云数据，主要由3D坐标定义。但标注这些点云数据用于监督学习任务是时间消耗大。因此，我们需要研究如何从无标注数据中学习，以大幅减少需要标注的样本数量。在这个工作中，我们提议使用自我监督编码器和Barlow Twins进行预训练，并将其作为semantic scene segmentation任务的预训练网络。实验结果表明，我们的无监督预训练可以大幅提高任务的性能，尤其是对于少数概率类别。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Simplicial-Attention-Neural-Networks"><a href="#Generalized-Simplicial-Attention-Neural-Networks" class="headerlink" title="Generalized Simplicial Attention Neural Networks"></a>Generalized Simplicial Attention Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02138">http://arxiv.org/abs/2309.02138</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luciatesta97/generalized-simplicial-attention-neural-networks">https://github.com/luciatesta97/generalized-simplicial-attention-neural-networks</a></li>
<li>paper_authors: Claudio Battiloro, Lucia Testa, Lorenzo Giusti, Stefania Sardellitti, Paolo Di Lorenzo, Sergio Barbarossa</li>
<li>for: 本研究旨在介绍通用 simplicial 注意力神经网络 (GSAN)，即利用面积掩码自我注意 layers 处理定义在 simplicial 复合体上的数据的新神经网络体系。</li>
<li>methods: 作者提出了一系列基于 topological signal processing 原理的自我注意方案，可以处理不同 simplicial 顺序上的数据组件，如节点、边、三角形等，并通过 Dirac 算子和其分解学习对 simplicial 领域的邻居重要性进行权重。</li>
<li>results: 作者证明了 GSAN 具有交换对称和 simplicial 意识，并通过应用于多个（推导和推理）任务，如 trajectory prediction、缺失数据填充、图 классификация和 simplex prediction，与其他方法进行比较，得到了比较好的结果。<details>
<summary>Abstract</summary>
The aim of this work is to introduce Generalized Simplicial Attention Neural Networks (GSANs), i.e., novel neural architectures designed to process data defined on simplicial complexes using masked self-attentional layers. Hinging on topological signal processing principles, we devise a series of self-attention schemes capable of processing data components defined at different simplicial orders, such as nodes, edges, triangles, and beyond. These schemes learn how to weight the neighborhoods of the given topological domain in a task-oriented fashion, leveraging the interplay among simplices of different orders through the Dirac operator and its Dirac decomposition. We also theoretically establish that GSANs are permutation equivariant and simplicial-aware. Finally, we illustrate how our approach compares favorably with other methods when applied to several (inductive and transductive) tasks such as trajectory prediction, missing data imputation, graph classification, and simplex prediction.
</details>
<details>
<summary>摘要</summary>
文章的目的是介绍通用 simplicial 注意力神经网络（GSAN），即新的神经网络架构，用于处理定义在 simplicial 复合体上的数据，使用假自注意层。基于 topological signal processing 原则，我们设计了一系列自注意方案，可以处理不同 simplicial 顺序的数据组件，如节点、边、triangle 等。这些方案可以Weight neighborhoods of the given topological domain in a task-oriented fashion，利用不同 simplices 之间的交互，通过 Дирак算符和其 Дирак分解。我们还证明了 GSANs 是 permutation equivariant 和 simplicial-aware。最后，我们比较了我们的方法与其他方法在 inductive 和 transductive 任务上的性能，包括 trajectory prediction、missing data imputation、graph classification 和 simplex prediction。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Intersection-of-Complex-Aesthetics-and-Generative-AI-for-Promoting-Cultural-Creativity-in-Rural-China-after-the-Post-Pandemic-Era"><a href="#Exploring-the-Intersection-of-Complex-Aesthetics-and-Generative-AI-for-Promoting-Cultural-Creativity-in-Rural-China-after-the-Post-Pandemic-Era" class="headerlink" title="Exploring the Intersection of Complex Aesthetics and Generative AI for Promoting Cultural Creativity in Rural China after the Post-Pandemic Era"></a>Exploring the Intersection of Complex Aesthetics and Generative AI for Promoting Cultural Creativity in Rural China after the Post-Pandemic Era</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02136">http://arxiv.org/abs/2309.02136</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengyao Guo, Xiaolin Zhang, Yuan Zhuang, Jing Chen, Pengfei Wang, Ze Gao</li>
<li>for: 这个论文探讨了在中国农村地区使用生成AI和艺术来促进文化创新，尤其是在COVID-19的影响下。</li>
<li>methods: 该论文通过文献综述、案例研究、问卷调查和文本分析方法来研究艺术和科技在农村 context中的应用，并找到了关键的挑战。</li>
<li>results: 研究发现艺术作品经常无法在当地 resonate，而依赖于外部艺术家的支持限制了可持续性。因此，抚养“村村艺术家”通过AI被提议。我们的方法是通过对主观美学进行机器学习训练，生成文化相关的内容。交互式AI媒体还可以提高旅游业，保护遗产。这项先导性的研究提出了对AI和艺术的交互关系的新视角，并强调AI的创作能力 versus 取代性。最后，它为了使用AI创新来促进农村社区的发展奠定了基础。<details>
<summary>Abstract</summary>
This paper explores using generative AI and aesthetics to promote cultural creativity in rural China amidst COVID-19's impact. Through literature reviews, case studies, surveys, and text analysis, it examines art and technology applications in rural contexts and identifies key challenges. The study finds artworks often fail to resonate locally, while reliance on external artists limits sustainability. Hence, nurturing grassroots "artist villagers" through AI is proposed. Our approach involves training machine learning on subjective aesthetics to generate culturally relevant content. Interactive AI media can also boost tourism while preserving heritage. This pioneering research puts forth original perspectives on the intersection of AI and aesthetics to invigorate rural culture. It advocates holistic integration of technology and emphasizes AI's potential as a creative enabler versus replacement. Ultimately, it lays the groundwork for further exploration of leveraging AI innovations to empower rural communities. This timely study contributes to growing interest in emerging technologies to address critical issues facing rural China.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-label-affordance-mapping-from-egocentric-vision"><a href="#Multi-label-affordance-mapping-from-egocentric-vision" class="headerlink" title="Multi-label affordance mapping from egocentric vision"></a>Multi-label affordance mapping from egocentric vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02120">http://arxiv.org/abs/2309.02120</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lmur98/epic_kitchens_affordances">https://github.com/lmur98/epic_kitchens_affordances</a></li>
<li>paper_authors: Lorenzo Mur-Labadia, Jose J. Guerrero, Ruben Martinez-Cantin</li>
<li>for: 本研究旨在提供高精度的交互场景中的可用性检测和分割方法，用于支持人工智能系统的发展。</li>
<li>methods: 本研究使用新的多标签检测方法，可以准确地检测和分割多个可用性在同一个空间中。</li>
<li>results: 研究人员通过使用多标签检测方法，成功地提取了高精度的交互场景中的可用性信息，并构建了大量和完整的交互可用性数据集（EPIC-Aff）。此外，研究人员还提出了一种新的多标签检测方法，可以处理多个可用性同时存在同一个空间中的情况。<details>
<summary>Abstract</summary>
Accurate affordance detection and segmentation with pixel precision is an important piece in many complex systems based on interactions, such as robots and assitive devices. We present a new approach to affordance perception which enables accurate multi-label segmentation. Our approach can be used to automatically extract grounded affordances from first person videos of interactions using a 3D map of the environment providing pixel level precision for the affordance location. We use this method to build the largest and most complete dataset on affordances based on the EPIC-Kitchen dataset, EPIC-Aff, which provides interaction-grounded, multi-label, metric and spatial affordance annotations. Then, we propose a new approach to affordance segmentation based on multi-label detection which enables multiple affordances to co-exists in the same space, for example if they are associated with the same object. We present several strategies of multi-label detection using several segmentation architectures. The experimental results highlight the importance of the multi-label detection. Finally, we show how our metric representation can be exploited for build a map of interaction hotspots in spatial action-centric zones and use that representation to perform a task-oriented navigation.
</details>
<details>
<summary>摘要</summary>
重要的一部分是许多复杂系统中的互动，如 робоット和协助设备。我们提出了一个新的方法来检测和分类可用性，可以从首人视频中自动提取固定的可用性。我们使用这种方法建立了最大和最完整的可用性数据集，EPIC-Aff，其提供了互动基于环境的三维地图，以像素精度检测可用性位置。接下来，我们提出了一个新的可用性分类方法，可以同时检测多个可用性，例如它们与同一个物品相关。我们提出了多种多label检测方法，包括多个分类架构。实验结果显示了多label检测的重要性。最后，我们显示了如何使用我们的度量表示法建立互动热点地图，并使用该表示法进行任务导向的探索。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Label-Information-for-Multimodal-Emotion-Recognition"><a href="#Leveraging-Label-Information-for-Multimodal-Emotion-Recognition" class="headerlink" title="Leveraging Label Information for Multimodal Emotion Recognition"></a>Leveraging Label Information for Multimodal Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02106">http://arxiv.org/abs/2309.02106</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Digimonseeker/LE-MER">https://github.com/Digimonseeker/LE-MER</a></li>
<li>paper_authors: Peiying Wang, Sunlu Zeng, Junqing Chen, Lu Fan, Meng Chen, Youzheng Wu, Xiaodong He</li>
<li>for: 本研究旨在提高多模态情感识别（MER）的性能，通过结合语音和文本信息。</li>
<li>methods: 我们提出了一种新的方法，利用标签信息来提高MER的性能。我们首先获取语音和文本模态的表示性标签嵌入，然后通过标签-token和标签-帧交互来学习每个语音的标签感知表示。最后，我们提出了一种新的标签导向拟合模块，将标签意识文本和语音表示进行情感分类。</li>
<li>results: 我们在公共的IEMOCAP dataset上进行了广泛的实验，结果表明，我们的提议的方法在比较基eline和现有方法的情况下，实现了新的国际顶点性能。<details>
<summary>Abstract</summary>
Multimodal emotion recognition (MER) aims to detect the emotional status of a given expression by combining the speech and text information. Intuitively, label information should be capable of helping the model locate the salient tokens/frames relevant to the specific emotion, which finally facilitates the MER task. Inspired by this, we propose a novel approach for MER by leveraging label information. Specifically, we first obtain the representative label embeddings for both text and speech modalities, then learn the label-enhanced text/speech representations for each utterance via label-token and label-frame interactions. Finally, we devise a novel label-guided attentive fusion module to fuse the label-aware text and speech representations for emotion classification. Extensive experiments were conducted on the public IEMOCAP dataset, and experimental results demonstrate that our proposed approach outperforms existing baselines and achieves new state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
多Modal情感识别（MER）目标是通过 Speech 和文本信息检测表达的情感状态。直觉地，标签信息应该能够帮助模型定位特定情感的关键词/帧，从而实现MER任务。 inspirited by这个想法，我们提出了一种新的MER方法，利用标签信息。具体来说，我们首先获得文本和Speech模态的表示性标签嵌入，然后通过标签-token和标签-帧交互学习每个语音的标签感知表示。最后，我们设计了一种新的标签引导束合模块，将标签意识的文本和Speech表示进行情感分类。我们在公共的IEMOCAP数据集上进行了广泛的实验，实验结果表明，我们提出的方法比现有的基eline和实现新的状态。
</details></li>
</ul>
<hr>
<h2 id="Improving-Query-Focused-Meeting-Summarization-with-Query-Relevant-Knowledge"><a href="#Improving-Query-Focused-Meeting-Summarization-with-Query-Relevant-Knowledge" class="headerlink" title="Improving Query-Focused Meeting Summarization with Query-Relevant Knowledge"></a>Improving Query-Focused Meeting Summarization with Query-Relevant Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02105">http://arxiv.org/abs/2309.02105</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Tiezheng Yu, Ziwei Ji, Pascale Fung</li>
<li>for: 这篇论文旨在提供一个可以根据查询生成会议总结的方法。</li>
<li>methods: 本文提出了一个知识增强的两阶段框架，名为知识感知SUMmarizer (KAS)，以解决长Input文本长度和会议总结中罕见的查询相关信息的问题。在第一阶段，我们引入知识感知分析来提高查询相关段别的提取精度。在第二阶段，我们将查询相关知识 integrate到总结生成中。</li>
<li>results: 实验结果显示，我们的方法在QMSum dataset上实现了现有最佳性能。进一步的分析显示，我们的方法能够生成相关 faithful和有用的总结。<details>
<summary>Abstract</summary>
Query-Focused Meeting Summarization (QFMS) aims to generate a summary of a given meeting transcript conditioned upon a query. The main challenges for QFMS are the long input text length and sparse query-relevant information in the meeting transcript. In this paper, we propose a knowledge-enhanced two-stage framework called Knowledge-Aware Summarizer (KAS) to tackle the challenges. In the first stage, we introduce knowledge-aware scores to improve the query-relevant segment extraction. In the second stage, we incorporate query-relevant knowledge in the summary generation. Experimental results on the QMSum dataset show that our approach achieves state-of-the-art performance. Further analysis proves the competency of our methods in generating relevant and faithful summaries.
</details>
<details>
<summary>摘要</summary>
Query-Focused Meeting Summarization (QFMS) 目标是根据查询生成会议笔记摘要。主要挑战是输入文本长度较长，会议笔记中关键信息罕见。在这篇论文中，我们提出了知识增强的两Stage框架，称为知识感知摘要器（KAS），以解决这些挑战。首先，我们在查询相关段落提取中引入了知识感知分数。然后，我们在摘要生成过程中引入了查询相关知识。实验结果表明，我们的方法在 QMSum 数据集上达到了顶尖性能。进一步分析表明，我们的方法能够生成相关和准确的摘要。
</details></li>
</ul>
<hr>
<h2 id="Iterative-Superquadric-Recomposition-of-3D-Objects-from-Multiple-Views"><a href="#Iterative-Superquadric-Recomposition-of-3D-Objects-from-Multiple-Views" class="headerlink" title="Iterative Superquadric Recomposition of 3D Objects from Multiple Views"></a>Iterative Superquadric Recomposition of 3D Objects from Multiple Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02102">http://arxiv.org/abs/2309.02102</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/explainableml/isco">https://github.com/explainableml/isco</a></li>
<li>paper_authors: Stephan Alaniz, Massimiliano Mancini, Zeynep Akata</li>
<li>for: 本研究旨在提出一种描述对象的概念模型，帮助机器学习模型更好地理解和重建物体的三维结构。</li>
<li>methods: 该方法使用3D超quadrics作为semantic part来直接从2D视图中重建物体，而不需要训练任何3Dsupervision模型。该方法通过优化超quadrics参数，以实现高精度的3D重建。</li>
<li>results: 实验表明，相比最近的单个实例超quadrics重建方法，ISCO方法能够提供更高精度的3D重建结果，即使是从野生图像中。代码可以在<a target="_blank" rel="noopener" href="https://github.com/ExplainableML/ISCO%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/ExplainableML/ISCO上下载。</a><details>
<summary>Abstract</summary>
Humans are good at recomposing novel objects, i.e. they can identify commonalities between unknown objects from general structure to finer detail, an ability difficult to replicate by machines. We propose a framework, ISCO, to recompose an object using 3D superquadrics as semantic parts directly from 2D views without training a model that uses 3D supervision. To achieve this, we optimize the superquadric parameters that compose a specific instance of the object, comparing its rendered 3D view and 2D image silhouette. Our ISCO framework iteratively adds new superquadrics wherever the reconstruction error is high, abstracting first coarse regions and then finer details of the target object. With this simple coarse-to-fine inductive bias, ISCO provides consistent superquadrics for related object parts, despite not having any semantic supervision. Since ISCO does not train any neural network, it is also inherently robust to out-of-distribution objects. Experiments show that, compared to recent single instance superquadrics reconstruction approaches, ISCO provides consistently more accurate 3D reconstructions, even from images in the wild. Code available at https://github.com/ExplainableML/ISCO .
</details>
<details>
<summary>摘要</summary>
人类具有将新物体复制成已知结构的能力，即可以从总结构到细节上识别未知物体的共同点，这是机器不易复制的能力。我们提出了一个框架，即ISCO，可以通过直接从2D视图中提取3D超quadric作为semantic part来重新组合物体。为了实现这一点，我们优化了超quadric参数，以使其能够组合特定物体的实例，并比较其渲染的3D视图和2D图像轮廓。我们的ISCO框架会逐渐添加新的超quadric，以降低重建错误，从总体到细节地抽象物体的target part。由于ISCO没有任何semantic supervision，它具有简单的卷积偏好，可以适应各种不同的物体。此外，由于ISCO不需要训练任何神经网络，它也是对外部数据集的抗耗性的。实验显示，相比最近的单个实例超quadrics重建方法，ISCO可以提供更加准确的3D重建结果，甚至来自野外图像。代码可以在https://github.com/ExplainableML/ISCO上获取。
</details></li>
</ul>
<hr>
<h2 id="TensorBank-Tensor-Lakehouse-for-Foundation-Model-Training"><a href="#TensorBank-Tensor-Lakehouse-for-Foundation-Model-Training" class="headerlink" title="TensorBank:Tensor Lakehouse for Foundation Model Training"></a>TensorBank:Tensor Lakehouse for Foundation Model Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02094">http://arxiv.org/abs/2309.02094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Romeo Kienzler, Benedikt Blumenstiel, Zoltan Arnold Nagy, S. Karthik Mukkavilli, Johannes Schmude, Marcus Freitag, Michael Behrendt, Daniel Salles Civitarese, Naomi Simumba, Daiki Kimura, Hendrik Hamann</li>
<li>For: 用于训练基础模型的高维数据存储和流处理成为现代自然语言之外的核心需求。* Methods: 使用复杂关系查询加速 Hierarchical Statistical Indices (HSI) 来从Cloud Object Store (COS) 流动到 GPU 内存中的tensor lakehouse。* Results: 可以通过 direktly 地址tensor的块级别使用 HTTP 范围读取来快速地从Cloud Object Store (COS) 流动tensor到 GPU 内存中，并使用 PyTorch 转换来转换数据。<details>
<summary>Abstract</summary>
Storing and streaming high dimensional data for foundation model training became a critical requirement with the rise of foundation models beyond natural language. In this paper we introduce TensorBank, a petabyte scale tensor lakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU memory at wire speed based on complex relational queries. We use Hierarchical Statistical Indices (HSI) for query acceleration. Our architecture allows to directly address tensors on block level using HTTP range reads. Once in GPU memory, data can be transformed using PyTorch transforms. We provide a generic PyTorch dataset type with a corresponding dataset factory translating relational queries and requested transformations as an instance. By making use of the HSI, irrelevant blocks can be skipped without reading them as those indices contain statistics on their content at different hierarchical resolution levels. This is an opinionated architecture powered by open standards and making heavy use of open-source technology. Although, hardened for production use using geospatial-temporal data, this architecture generalizes to other use case like computer vision, computational neuroscience, biological sequence analysis and more.
</details>
<details>
<summary>摘要</summary>
存储和流动高维数据 для基础模型训练成为了基础模型的发展的关键要求。在这篇论文中，我们介绍TensorBank，一个 petabyte 级 tensor 湖居 capable of streaming tensors from Cloud Object Store (COS) to GPU 内存 based on complex relational queries。我们使用 Hierarchical Statistical Indices (HSI) for query acceleration。我们的架构允许直接地址 tensors 在块级别使用 HTTP 范围读。一旦在 GPU 内存中，数据可以通过 PyTorch 转换。我们提供一个通用 PyTorch 数据集类型，并提供一个对应的数据工厂，该工厂将关系查询和请求的转换翻译为实例。通过使用 HSI，我们可以跳过无关块，因为它们包含不同层次分辨率水平上的统计信息。这是一种基于开源技术的意见 arquitecture，并且通过使用 geospatial-temporal 数据进行硬化，这种架构可以普及到其他应用场景，如计算机视觉、计算神经科学、生物序列分析等。
</details></li>
</ul>
<hr>
<h2 id="Dual-Adversarial-Alignment-for-Realistic-Support-Query-Shift-Few-shot-Learning"><a href="#Dual-Adversarial-Alignment-for-Realistic-Support-Query-Shift-Few-shot-Learning" class="headerlink" title="Dual Adversarial Alignment for Realistic Support-Query Shift Few-shot Learning"></a>Dual Adversarial Alignment for Realistic Support-Query Shift Few-shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02088">http://arxiv.org/abs/2309.02088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyang Jiang, Rui Fang, Hsi-Wen Chen, Wei Ding, Ming-Syan Chen</li>
<li>For: 实际情况下，支持集和查询集之间存在多种不确定的扩散shift，这使得traditional的支持集查询集学习变得困难。这篇论文提出了一个新的挑战，即Realistic Support-Query Shift few-shot learning（RSQS），旨在在不确定的扩散shift下进行几个shot学习。* Methods: 我们提出了一种新的对抗性特征平衡方法called DUal adversarial ALignment framework（DuaL），用于缓解RSQS中的两种方面：inter-domain bias和intra-domain variance。一方面，我们在特定的数据集上进行了预处理，并使用生成的各种偏移输入来训练修复网络，以最小化特征层的距离。另一方面，我们提出了一种生成器网络，用于自顺序生成硬example，即less similar的支持集中的示例，并通过整合最优运输来获得一个平滑的运输计划。* Results: 我们建立了RSQS的benchmark，包括了several state-of-the-art baselines，并进行了实验研究。结果表明，DuaL在我们的benchmark中显著超过了state-of-the-art方法。<details>
<summary>Abstract</summary>
Support-query shift few-shot learning aims to classify unseen examples (query set) to labeled data (support set) based on the learned embedding in a low-dimensional space under a distribution shift between the support set and the query set. However, in real-world scenarios the shifts are usually unknown and varied, making it difficult to estimate in advance. Therefore, in this paper, we propose a novel but more difficult challenge, RSQS, focusing on Realistic Support-Query Shift few-shot learning. The key feature of RSQS is that the individual samples in a meta-task are subjected to multiple distribution shifts in each meta-task. In addition, we propose a unified adversarial feature alignment method called DUal adversarial ALignment framework (DuaL) to relieve RSQS from two aspects, i.e., inter-domain bias and intra-domain variance. On the one hand, for the inter-domain bias, we corrupt the original data in advance and use the synthesized perturbed inputs to train the repairer network by minimizing distance in the feature level. On the other hand, for intra-domain variance, we proposed a generator network to synthesize hard, i.e., less similar, examples from the support set in a self-supervised manner and introduce regularized optimal transportation to derive a smooth optimal transportation plan. Lastly, a benchmark of RSQS is built with several state-of-the-art baselines among three datasets (CIFAR100, mini-ImageNet, and Tiered-Imagenet). Experiment results show that DuaL significantly outperforms the state-of-the-art methods in our benchmark.
</details>
<details>
<summary>摘要</summary>
支持问题Shift几何学学习目标是将未经见过的示例（查询集）分类到已经标注的数据（支持集）基于学习得到的嵌入在低维度空间下，但在实际场景中，这些变化通常是未知且多样的，使得预测变化很困难。因此，在这篇论文中，我们提出了一个新的挑战，即真实支持问题Shift几何学学习（RSQS）。RSQS的关键特点是每个元任务中的个体样本会面临多种分布变化。此外，我们提出了一种整合式对抗特征对齐方法，即DUal adversarial ALignment framework（DuaL），以解决RSQS中的两个方面：间域偏见和内域变异。一方面，为了间域偏见，我们在提前损害原始数据后，使用生成的妨害输入来训练维护网络，并在特征层面下将其距离最小化。另一方面，为了内域变异，我们提出了一种生成器网络，通过自适应方式生成硬例（即更不相似的示例），并通过可惩正的优化运输来 derivation 一个平滑的优化运输计划。最后，我们建立了RSQS的标准准则，包括三个数据集（CIFAR100、mini-ImageNet和Tiered-Imagenet）上的state-of-the-art基elines。实验结果显示，DuaL明显超过了state-of-the-art方法在我们的标准准则中。
</details></li>
</ul>
<hr>
<h2 id="Natural-Example-Based-Explainability-a-Survey"><a href="#Natural-Example-Based-Explainability-a-Survey" class="headerlink" title="Natural Example-Based Explainability: a Survey"></a>Natural Example-Based Explainability: a Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03234">http://arxiv.org/abs/2309.03234</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danderfer/Comp_Sci_Sem_2">https://github.com/danderfer/Comp_Sci_Sem_2</a></li>
<li>paper_authors: Antonin Poché, Lucas Hervier, Mohamed-Chafik Bakkay</li>
<li>for: 本研究旨在提供一份对当前自然示例基于XAI技术的概述，以便了解不同方法的优缺点和应用场景。</li>
<li>methods: 本研究主要涉及的方法包括相似示例、 counterfactual 和 semi-factual 示例、重要实例、原型和概念。</li>
<li>results: 本研究提供了这些方法的 semantic definition、认知影响和added value的比较，以便激励和促进未来的自然示例基于XAI技术发展。<details>
<summary>Abstract</summary>
Explainable Artificial Intelligence (XAI) has become increasingly significant for improving the interpretability and trustworthiness of machine learning models. While saliency maps have stolen the show for the last few years in the XAI field, their ability to reflect models' internal processes has been questioned. Although less in the spotlight, example-based XAI methods have continued to improve. It encompasses methods that use examples as explanations for a machine learning model's predictions. This aligns with the psychological mechanisms of human reasoning and makes example-based explanations natural and intuitive for users to understand. Indeed, humans learn and reason by forming mental representations of concepts based on examples.   This paper provides an overview of the state-of-the-art in natural example-based XAI, describing the pros and cons of each approach. A "natural" example simply means that it is directly drawn from the training data without involving any generative process. The exclusion of methods that require generating examples is justified by the need for plausibility which is in some regards required to gain a user's trust. Consequently, this paper will explore the following family of methods: similar examples, counterfactual and semi-factual, influential instances, prototypes, and concepts. In particular, it will compare their semantic definition, their cognitive impact, and added values. We hope it will encourage and facilitate future work on natural example-based XAI.
</details>
<details>
<summary>摘要</summary>
很好！我们将提供一个关于自然例子基于Explainable Artificial Intelligence（XAI）的概览，涵盖了不同方法的优点和缺点。XAI在机器学习模型的解释性和可信度方面具有越来越重要的地位。虽然在过去几年中，saliency map在XAI领域中受到了很多关注，但其能够反映机器学习模型内部过程的能力受到了质疑。在这篇文章中，我们将探讨不同的自然例子基于XAI方法，包括相似的例子、counterfactual和semi-factual、重要的实例、原型和概念。尤其是在比较这些方法的semantic定义、认知影响和加值方面。我们希望这篇文章可以对未来的自然例子基于XAI工作提供启发和促进。Note: "自然"（natural）在这里指的是直接从训练数据中提取的例子，而不是通过生成过程来生成的例子。这种要求可信度的需求是因为人们需要在理解模型的预测时有足够的信任感。
</details></li>
</ul>
<hr>
<h2 id="DeepVol-A-Deep-Transfer-Learning-Approach-for-Universal-Asset-Volatility-Modeling"><a href="#DeepVol-A-Deep-Transfer-Learning-Approach-for-Universal-Asset-Volatility-Modeling" class="headerlink" title="DeepVol: A Deep Transfer Learning Approach for Universal Asset Volatility Modeling"></a>DeepVol: A Deep Transfer Learning Approach for Universal Asset Volatility Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02072">http://arxiv.org/abs/2309.02072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Liu, Minh-Ngoc Tran, Chao Wang, Richard Gerlach, Robert Kohn</li>
<li>for: 这篇论文旨在提出一种深度学习模型，以更好地模型金融资产的波动性。</li>
<li>methods: 该模型使用了转移学习，可以有效地捕捉和模型所有金融资产的波动性动态，只需要一个通用模型。这与经济学 литераature中常见的单独训练每个数据集的方法不同。</li>
<li>results: 这个模型在模型泛化性方面表现出色，可以更好地预测金融资产的波动性。这对金融预测和管理具有广泛的应用前景。<details>
<summary>Abstract</summary>
This paper introduces DeepVol, a promising new deep learning volatility model that outperforms traditional econometric models in terms of model generality. DeepVol leverages the power of transfer learning to effectively capture and model the volatility dynamics of all financial assets, including previously unseen ones, using a single universal model. This contrasts to the prevailing practice in econometrics literature, which necessitates training separate models for individual datasets. The introduction of DeepVol opens up new avenues for volatility modeling and forecasting in the finance industry, potentially transforming the way volatility is understood and predicted.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了深度风险模型（DeepVol），这是一种有前途的深度学习模型，可以在经济学领域中超越传统 econometric 模型，并且可以更好地捕捉和模型所有金融资产的风险动态。 DeepVol 利用了传输学习的力量，可以通过单一的通用模型来模型所有金融资产，包括之前未见的资产。这与经济学 литераature 中的常见做法不同，需要为每个数据集训练 separte 模型。 DeepVol 的出现将为金融行业带来新的风险模型和预测方法，可能会改变风险的理解和预测方式。
</details></li>
</ul>
<hr>
<h2 id="Enhance-Multi-domain-Sentiment-Analysis-of-Review-Texts-through-Prompting-Strategies"><a href="#Enhance-Multi-domain-Sentiment-Analysis-of-Review-Texts-through-Prompting-Strategies" class="headerlink" title="Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies"></a>Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02045">http://arxiv.org/abs/2309.02045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yajing Wang, Zongwei Luo</li>
<li>for: 这篇论文旨在提高大型自然语言处理模型（LLMs）在特定任务中的性能，具体来说是在 Sentiment Analysis 任务中。</li>
<li>methods: 这篇论文使用了两种新的提示策略，即 RolePlaying（RP）提示和 Chain-of-thought（CoT）提示，并提出了 RP-CoT 提示策略。</li>
<li>results: 实验结果显示，采用提出的提示策略可以明显提高 Sentiment Analysis 的准确率，其中 CoT 提示策略对隐式情感分析具有显著的影响，RP-CoT 提示策略则在所有策略中表现最佳。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have made significant strides in both scientific research and practical applications. Existing studies have demonstrated the state-of-the-art (SOTA) performance of LLMs in various natural language processing tasks. However, the question of how to further enhance LLMs' performance in specific task using prompting strategies remains a pivotal concern. This paper explores the enhancement of LLMs' performance in sentiment analysis through the application of prompting strategies. We formulate the process of prompting for sentiment analysis tasks and introduce two novel strategies tailored for sentiment analysis: RolePlaying (RP) prompting and Chain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT prompting strategy which is a combination of RP prompting and CoT prompting. We conduct comparative experiments on three distinct domain datasets to evaluate the effectiveness of the proposed sentiment analysis strategies. The results demonstrate that the adoption of the proposed prompting strategies leads to a increasing enhancement in sentiment analysis accuracy. Further, the CoT prompting strategy exhibits a notable impact on implicit sentiment analysis, with the RP-CoT prompting strategy delivering the most superior performance among all strategies.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Diffusion-Generative-Inverse-Design"><a href="#Diffusion-Generative-Inverse-Design" class="headerlink" title="Diffusion Generative Inverse Design"></a>Diffusion Generative Inverse Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02040">http://arxiv.org/abs/2309.02040</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marin Vlastelica, Tatiana López-Guevara, Kelsey Allen, Peter Battaglia, Arnaud Doucet, Kimberley Stachenfeld</li>
<li>for:  solving inverse design problems efficiently</li>
<li>methods:  using denoising diffusion models (DDMs) and a particle sampling algorithm</li>
<li>results:  reducing the number of calls to the simulator compared to standard techniques, with improved efficiency<details>
<summary>Abstract</summary>
Inverse design refers to the problem of optimizing the input of an objective function in order to enact a target outcome. For many real-world engineering problems, the objective function takes the form of a simulator that predicts how the system state will evolve over time, and the design challenge is to optimize the initial conditions that lead to a target outcome. Recent developments in learned simulation have shown that graph neural networks (GNNs) can be used for accurate, efficient, differentiable estimation of simulator dynamics, and support high-quality design optimization with gradient- or sampling-based optimization procedures. However, optimizing designs from scratch requires many expensive model queries, and these procedures exhibit basic failures on either non-convex or high-dimensional problems. In this work, we show how denoising diffusion models (DDMs) can be used to solve inverse design problems efficiently and propose a particle sampling algorithm for further improving their efficiency. We perform experiments on a number of fluid dynamics design challenges, and find that our approach substantially reduces the number of calls to the simulator compared to standard techniques.
</details>
<details>
<summary>摘要</summary>
“ inverse 设计”指的是对目标函数的输入优化，以实现一个目标结果。在许多实际工程问题中，目标函数通常是一个预测系统状态在时间推移中的模拟器，并且设计挑战是确定初始条件以实现目标结果。现有的学习模拟技术发展已经表明，图 neural network (GNNs) 可以用于准确、高效、可导estiimation of simulator dynamics，并支持高质量的设计优化。然而，从头开始优化设计需要许多昂贵的模拟器调用，这些过程在非凸或高维问题上会表现出基本的失败。在这种情况下，我们提出了使用 denoising diffusion models (DDMs) 来解决 inverse 设计问题，并提出了一种粒子抽象算法来进一步提高其效率。我们在一些流体动力学设计挑战中进行了实验，并发现我们的方法可以减少对模拟器的调用数量相比标准技术。
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Artificial-Intelligence-on-the-Evolution-of-Digital-Education-A-Comparative-Study-of-OpenAI-Text-Generation-Tools-including-ChatGPT-Bing-Chat-Bard-and-Ernie"><a href="#The-Impact-of-Artificial-Intelligence-on-the-Evolution-of-Digital-Education-A-Comparative-Study-of-OpenAI-Text-Generation-Tools-including-ChatGPT-Bing-Chat-Bard-and-Ernie" class="headerlink" title="The Impact of Artificial Intelligence on the Evolution of Digital Education: A Comparative Study of OpenAI Text Generation Tools including ChatGPT, Bing Chat, Bard, and Ernie"></a>The Impact of Artificial Intelligence on the Evolution of Digital Education: A Comparative Study of OpenAI Text Generation Tools including ChatGPT, Bing Chat, Bard, and Ernie</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02029">http://arxiv.org/abs/2309.02029</a></li>
<li>repo_url: None</li>
<li>paper_authors: Negin Yazdani Motlagh, Matin Khajavi, Abbas Sharifi, Mohsen Ahmadi</li>
<li>for: This paper aims to explore the potential of OpenAI’s text generation tools, particularly ChatGPT, in revolutionizing education and to highlight the challenges and opportunities of AI in education.</li>
<li>methods: The paper uses a typology that views education through the lenses of system, process, and result to examine the multifaceted applications of AI in education, including decentralizing global education, personalizing curriculums, and digitally documenting competence-based outcomes.</li>
<li>results: The paper highlights ChatGPT’s meteoric rise to one million users in just five days and its potential in democratizing education, fostering autodidacticism, and magnifying student engagement. However, the study also acknowledges the potential challenges of AI in education, such as the need for ethical guidelines, pedagogical adaptations, and strategic collaborations to ensure the responsible use of AI tools.<details>
<summary>Abstract</summary>
In the digital era, the integration of artificial intelligence (AI) in education has ushered in transformative changes, redefining teaching methodologies, curriculum planning, and student engagement. This review paper delves deep into the rapidly evolving landscape of digital education by contrasting the capabilities and impact of OpenAI's pioneering text generation tools like Bing Chat, Bard, Ernie with a keen focus on the novel ChatGPT. Grounded in a typology that views education through the lenses of system, process, and result, the paper navigates the multifaceted applications of AI. From decentralizing global education and personalizing curriculums to digitally documenting competence-based outcomes, AI stands at the forefront of educational modernization. Highlighting ChatGPT's meteoric rise to one million users in just five days, the study underscores its role in democratizing education, fostering autodidacticism, and magnifying student engagement. However, with such transformative power comes the potential for misuse, as text-generation tools can inadvertently challenge academic integrity. By juxtaposing the promise and pitfalls of AI in education, this paper advocates for a harmonized synergy between AI tools and the educational community, emphasizing the urgent need for ethical guidelines, pedagogical adaptations, and strategic collaborations.
</details>
<details>
<summary>摘要</summary>
在数字时代，人工智能（AI）在教育领域的整合已经带来了转变性的变革，重定义了教学方法、课程规划和学生参与度。这篇评论文章深入探讨在数字教育领域的迅速发展，并对OpenAI的创新性文本生成工具如Bing Chat、Bard、Ernie等进行了着力强调，特别是新出现的ChatGPT。根据教育视为系统、过程和结果的三个视角，文章探讨了AI在教育中的多方面应用。从全球教育的减少到个性化课程、数字记录竞争力具体成果等方面，AI在教育现代化中扮演着重要的角色。文章指出ChatGPT在只需五天内吸引了一百万用户，其在推动自主学习、提高学生参与度和全球教育民主化方面具有重要的作用。然而，与此同时，AI在教育领域的应用也存在潜在的风险，文本生成工具可能会不必要地挑战学术Integrity。通过对AI在教育中的推荐和风险的对比，这篇文章强调需要在AI工具和教育社区之间建立和谐的合作，并提出了优先级的道德规范、教学改进和战略合作。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Early-Exiting-Predictive-Coding-Neural-Networks"><a href="#Dynamic-Early-Exiting-Predictive-Coding-Neural-Networks" class="headerlink" title="Dynamic Early Exiting Predictive Coding Neural Networks"></a>Dynamic Early Exiting Predictive Coding Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02022">http://arxiv.org/abs/2309.02022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alaa Zniber, Ouassim Karrakchou, Mounir Ghogho</li>
<li>for: 这篇论文是为了提高深度学习模型在互联网络预测应用中的效率和低功耗。</li>
<li>methods: 本研究使用预测编码理论和动态早期终止技术，构建了一个浅层双向网络，并与VGG-16模型进行比较。</li>
<li>results: 本研究获得了与VGG-16模型相似的准确率，但具有更少的参数和computational complexity。<details>
<summary>Abstract</summary>
Internet of Things (IoT) sensors are nowadays heavily utilized in various real-world applications ranging from wearables to smart buildings passing by agrotechnology and health monitoring. With the huge amounts of data generated by these tiny devices, Deep Learning (DL) models have been extensively used to enhance them with intelligent processing. However, with the urge for smaller and more accurate devices, DL models became too heavy to deploy. It is thus necessary to incorporate the hardware's limited resources in the design process. Therefore, inspired by the human brain known for its efficiency and low power consumption, we propose a shallow bidirectional network based on predictive coding theory and dynamic early exiting for halting further computations when a performance threshold is surpassed. We achieve comparable accuracy to VGG-16 in image classification on CIFAR-10 with fewer parameters and less computational complexity.
</details>
<details>
<summary>摘要</summary>
互联网智能设备（IoT）的感应器在不同的实际应用中广泛使用，由穿梭到智能建筑和医疗监控。这些小型设备产生的大量数据，导致深度学习（DL）模型广泛应用于增强过程中。但是，对于更小和更精确的设备，DL模型已经变得太重且不可行。因此，我们受人脑的效率和低功耗骄傲，提出了一个浅层双向网络，基于预测编码理论和动态早期退出，以避免进一步的计算。我们在CIFAR-10类图标签准则中实现了与VGG-16相同的准确性，但具有较少的参数和计算复杂性。
</details></li>
</ul>
<hr>
<h2 id="iLoRE-Dynamic-Graph-Representation-with-Instant-Long-term-Modeling-and-Re-occurrence-Preservation"><a href="#iLoRE-Dynamic-Graph-Representation-with-Instant-Long-term-Modeling-and-Re-occurrence-Preservation" class="headerlink" title="iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and Re-occurrence Preservation"></a>iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and Re-occurrence Preservation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02012">http://arxiv.org/abs/2309.02012</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siwei Zhang, Yun Xiong, Yao Zhang, Xixi Wu, Yiheng Sun, Jiawei Zhang</li>
<li>for: 这篇论文旨在提出一个新的动态グラフ模型化方法，以解决现有方法的三个限制，提高其数据测试和应用范围。</li>
<li>methods: 这篇论文使用了一个具有自适应短期更新和长期更新的模型，具有自动删除无用或杂散的边的能力，以及一个具有识别注意力机制的传统transformer-based更新器，以更好地捕捉长期循环pattern。</li>
<li>results: 论文的实验结果显示，iLoRE方法能够有效地模型动态グラフ，并且在实验中获得了更高的表现。<details>
<summary>Abstract</summary>
Continuous-time dynamic graph modeling is a crucial task for many real-world applications, such as financial risk management and fraud detection. Though existing dynamic graph modeling methods have achieved satisfactory results, they still suffer from three key limitations, hindering their scalability and further applicability. i) Indiscriminate updating. For incoming edges, existing methods would indiscriminately deal with them, which may lead to more time consumption and unexpected noisy information. ii) Ineffective node-wise long-term modeling. They heavily rely on recurrent neural networks (RNNs) as a backbone, which has been demonstrated to be incapable of fully capturing node-wise long-term dependencies in event sequences. iii) Neglect of re-occurrence patterns. Dynamic graphs involve the repeated occurrence of neighbors that indicates their importance, which is disappointedly neglected by existing methods. In this paper, we present iLoRE, a novel dynamic graph modeling method with instant node-wise Long-term modeling and Re-occurrence preservation. To overcome the indiscriminate updating issue, we introduce the Adaptive Short-term Updater module that will automatically discard the useless or noisy edges, ensuring iLoRE's effectiveness and instant ability. We further propose the Long-term Updater to realize more effective node-wise long-term modeling, where we innovatively propose the Identity Attention mechanism to empower a Transformer-based updater, bypassing the limited effectiveness of typical RNN-dominated designs. Finally, the crucial re-occurrence patterns are also encoded into a graph module for informative representation learning, which will further improve the expressiveness of our method. Our experimental results on real-world datasets demonstrate the effectiveness of our iLoRE for dynamic graph modeling.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate("Continuous-time dynamic graph modeling is a crucial task for many real-world applications, such as financial risk management and fraud detection. Though existing dynamic graph modeling methods have achieved satisfactory results, they still suffer from three key limitations, hindering their scalability and further applicability. i) Indiscriminate updating. For incoming edges, existing methods would indiscriminately deal with them, which may lead to more time consumption and unexpected noisy information. ii) Ineffective node-wise long-term modeling. They heavily rely on recurrent neural networks (RNNs) as a backbone, which has been demonstrated to be incapable of fully capturing node-wise long-term dependencies in event sequences. iii) Neglect of re-occurrence patterns. Dynamic graphs involve the repeated occurrence of neighbors that indicates their importance, which is disappointedly neglected by existing methods. In this paper, we present iLoRE, a novel dynamic graph modeling method with instant node-wise Long-term modeling and Re-occurrence preservation. To overcome the indiscriminate updating issue, we introduce the Adaptive Short-term Updater module that will automatically discard the useless or noisy edges, ensuring iLoRE's effectiveness and instant ability. We further propose the Long-term Updater to realize more effective node-wise long-term modeling, where we innovatively propose the Identity Attention mechanism to empower a Transformer-based updater, bypassing the limited effectiveness of typical RNN-dominated designs. Finally, the crucial re-occurrence patterns are also encoded into a graph module for informative representation learning, which will further improve the expressiveness of our method. Our experimental results on real-world datasets demonstrate the effectiveness of our iLoRE for dynamic graph modeling.")Here's the translation in Simplified Chinese:<<SYS>> continuous-time动态图模型化是许多实际应用中的关键任务，如金融风险管理和欺诈探测。虽然现有的动态图模型化方法已经达到了一定的成果，但它们仍然受到三个关键限制，使其可扩展性和更多的应用场景受到限制。i) 随机更新。现有的方法会随机处理入coming edges，这可能会导致更多的时间开销和意外的噪声信息。ii) 不够有效的节点级长期模型化。它们依赖于循环神经网络（RNN）作为底层，这已经被证明无法全面捕捉节点级长期依赖关系。iii) 忽略重复模式。动态图中的重复 neighboor 表示其重要性，这是现有方法忽略的。在这篇论文中，我们提出了 iLoRE，一种新的动态图模型化方法，具有即时节点级长期模型化和重复模式保存。为了解决随机更新问题，我们引入了适应短期更新模块，可以自动排除无用或噪声的边，保证 iLoRE 的有效性和即时能力。我们进一步提出了长期更新模块，以实现更有效的节点级长期模型化。我们创新地提出了标识注意力机制，以强化基于 Transformer 的更新器，超越传统 RNN  доминиated 设计的局限性。最后，我们还编码了重复模式到图模块，以进一步提高我们方法的表达能力。我们在实际 datasets 上进行了实验， demonstate 了我们 iLoRE 在动态图模型化中的效果。
</details></li>
</ul>
<hr>
<h2 id="Belief-revision-and-incongruity-is-it-a-joke"><a href="#Belief-revision-and-incongruity-is-it-a-joke" class="headerlink" title="Belief revision and incongruity: is it a joke?"></a>Belief revision and incongruity: is it a joke?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02009">http://arxiv.org/abs/2309.02009</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florence Dupin de Saint Cyr - Bannay, Henri Prade</li>
<li>for: 本文是一种智能行为 formalization的尝试，描述一个智能代理在听笑话时的行为。</li>
<li>methods: 本文使用了改变信念、出乎意料和违反 norms 等方法来形式化这种智能行为。</li>
<li>results: 本文的研究结果表明，在听笑话时，智能代理可以通过改变信念和出乎意料来产生幽默的感受，并且可以通过违反 norms 来提高幽默的效果。<details>
<summary>Abstract</summary>
Incongruity often makes people laugh. You have to be smart to say stupid things. It requires to be even smarter for understanding them. This paper is a shameless attempt to formalize this intelligent behavior in the case of an agent listening to a joke. All this is a matter of revision of beliefs, surprise and violation of norms.
</details>
<details>
<summary>摘要</summary>
冲突可以让人 laugh。你需要聪明才能说些愚蠢的话。更需要聪明才能理解它们。这篇文章是一种不害怕的尝试，用于形式化代理人听笑话时的智慧行为。这一切都是对信念的修订，对听者的意外和规范的违反。
</details></li>
</ul>
<hr>
<h2 id="Aggregating-Correlated-Estimations-with-Almost-no-Training"><a href="#Aggregating-Correlated-Estimations-with-Almost-no-Training" class="headerlink" title="Aggregating Correlated Estimations with (Almost) no Training"></a>Aggregating Correlated Estimations with (Almost) no Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02005">http://arxiv.org/abs/2309.02005</a></li>
<li>repo_url: None</li>
<li>paper_authors: Theo Delemazure, François Durand, Fabien Mathieu</li>
<li>for: 本研究旨在提出一些考虑关联错误的汇集规则，以解决许多决策问题无法得到精确解决方案。</li>
<li>methods: 本文提出了一些考虑关联错误的汇集规则，并对它们进行了多种实验，以评估它们在不同的数据集上的性能。</li>
<li>results: 研究结果表明，当知道错误的相关性信息时，最大似然汇集方法应该被首选。否则，通常在受限的训练数据下，我们建议使用嵌入式选举方法（EV）。<details>
<summary>Abstract</summary>
Many decision problems cannot be solved exactly and use several estimation algorithms that assign scores to the different available options. The estimation errors can have various correlations, from low (e.g. between two very different approaches) to high (e.g. when using a given algorithm with different hyperparameters). Most aggregation rules would suffer from this diversity of correlations. In this article, we propose different aggregation rules that take correlations into account, and we compare them to naive rules in various experiments based on synthetic data. Our results show that when sufficient information is known about the correlations between errors, a maximum likelihood aggregation should be preferred. Otherwise, typically with limited training data, we recommend a method that we call Embedded Voting (EV).
</details>
<details>
<summary>摘要</summary>
很多决策问题无法精确解决，需要使用估计算法赋分不同选项的分数。估计误差可能存在多种相关性，从低（例如两种完全不同的方法）到高（例如使用同一算法的不同Hyperparameter）。大多数汇集规则都会受到这种多样性的影响。在这篇文章中，我们提出了考虑相关性的不同汇集规则，并与无知规则进行了多个实验，基于 sintetic 数据。我们的结果表明，当知道估计误差之间的相关性信息充分时，最大 likelihood 汇集应该被首选。否则，通常在受限的训练数据情况下，我们建议一种我们称为 Embedded Voting（EV）方法。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-domain-shift-when-using-additional-data-for-the-MICCAI-KiTS23-Challenge"><a href="#Analyzing-domain-shift-when-using-additional-data-for-the-MICCAI-KiTS23-Challenge" class="headerlink" title="Analyzing domain shift when using additional data for the MICCAI KiTS23 Challenge"></a>Analyzing domain shift when using additional data for the MICCAI KiTS23 Challenge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02001">http://arxiv.org/abs/2309.02001</a></li>
<li>repo_url: None</li>
<li>paper_authors: George Stoica, Mihaela Breaban, Vlad Barbu</li>
<li>for: 提高医疗影像3D segmentation的结果，尤其是在训练材料稀缺的情况下。</li>
<li>methods: 使用 histogram matching 来缓解频谱shift，以便将新数据与原始训练数据一起使用。</li>
<li>results: 对于 histogram matching 的应用，比使用 simple normalization 得到了更好的结果。<details>
<summary>Abstract</summary>
Using additional training data is known to improve the results, especially for medical image 3D segmentation where there is a lack of training material and the model needs to generalize well from few available data. However, the new data could have been acquired using other instruments and preprocessed such its distribution is significantly different from the original training data. Therefore, we study techniques which ameliorate domain shift during training so that the additional data becomes better usable for preprocessing and training together with the original data. Our results show that transforming the additional data using histogram matching has better results than using simple normalization.
</details>
<details>
<summary>摘要</summary>
使用额外训练数据可以提高结果，特别是医学图像三维分割，因为这个领域缺乏训练材料，模型需要将少量可用数据总结化好。然而，新的数据可能是使用不同的仪器获取的，其分布与原始训练数据有很大差异。因此，我们研究如何在训练过程中缓解领域差异，使得额外数据更容易与原始数据一起预处理和训练。我们的结果表明，对额外数据进行 histogram matching 变换比使用简单 нормализация更有效。
</details></li>
</ul>
<hr>
<h2 id="Photonic-Structures-Optimization-Using-Highly-Data-Efficient-Deep-Learning-Application-To-Nanofin-And-Annular-Groove-Phase-Masks"><a href="#Photonic-Structures-Optimization-Using-Highly-Data-Efficient-Deep-Learning-Application-To-Nanofin-And-Annular-Groove-Phase-Masks" class="headerlink" title="Photonic Structures Optimization Using Highly Data-Efficient Deep Learning: Application To Nanofin And Annular Groove Phase Masks"></a>Photonic Structures Optimization Using Highly Data-Efficient Deep Learning: Application To Nanofin And Annular Groove Phase Masks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01995">http://arxiv.org/abs/2309.01995</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kaeryv/acsphot23suppl">https://github.com/kaeryv/acsphot23suppl</a></li>
<li>paper_authors: Nicolas Roy, Lorenzo König, Olivier Absil, Charlotte Beauthier, Alexandre Mayer, Michaël Lobet<br>for: This paper aims to introduce a surrogate optimization framework for metasurfaces, specifically for the manipulation of light properties in astronomical high-contrast imaging.methods: The paper uses computational intelligence techniques, such as partial least squares Kriging, radial basis functions, and neural networks, to optimize the geometric features of vortex phase masks (VPMs). However, these methods are shown to be inadequate for modeling the performance of VPMs, so a data-efficient evolutionary optimization setup using a deep neural network is proposed instead.results: The paper demonstrates the effectiveness of the proposed optimization setup by developing optimal designs for two design candidates, with the surrogate model improving the reliability and efficiency of the procedure. In the most complex case, evolutionary optimization enables optimization of the design that would otherwise be impractical (requiring too much simulations). The use of the surrogate model reduces the required number of simulations by up to 75% compared to conventional optimization techniques.Here is the text in Simplified Chinese:for: 这篇论文目标是引入一种基于Vortex phase masks（VPMs）的高精度光学设计优化框架。methods: 论文使用了计算智能技术，如部分最小值Kriging、基函数和神经网络，来优化VPMs的几何特征。然而，这些方法不足以模型VPMs的性能，因此提出了一种数据高效的进化优化方案。results: 论文证明了提案的优化方案的有效性，通过开发了两种设计候选人。在最复杂的情况下，进化优化可以实现对设计的优化，而无需进行过多的Simulations。使用代表性模型可以大大降低需要的Simulations数量，相比传统优化技术。<details>
<summary>Abstract</summary>
Metasurfaces offer a flexible framework for the manipulation of light properties in the realm of thin film optics. Specifically, the polarization of light can be effectively controlled through the use of thin phase plates. This study aims to introduce a surrogate optimization framework for these devices. The framework is applied to develop two kinds of vortex phase masks (VPMs) tailored for application in astronomical high-contrast imaging. Computational intelligence techniques are exploited to optimize the geometric features of these devices. The large design space and computational limitations necessitate the use of surrogate models like partial least squares Kriging, radial basis functions, or neural networks. However, we demonstrate the inadequacy of these methods in modeling the performance of VPMs. To address the shortcomings of these methods, a data-efficient evolutionary optimization setup using a deep neural network as a highly accurate and efficient surrogate model is proposed. The optimization process in this study employs a robust particle swarm evolutionary optimization scheme, which operates on explicit geometric parameters of the photonic device. Through this approach, optimal designs are developed for two design candidates. In the most complex case, evolutionary optimization enables optimization of the design that would otherwise be impractical (requiring too much simulations). In both cases, the surrogate model improves the reliability and efficiency of the procedure, effectively reducing the required number of simulations by up to 75% compared to conventional optimization techniques.
</details>
<details>
<summary>摘要</summary>
追踪板（Metasurfaces）提供了膜片光学中的灵活框架，可以有效控制光的属性。本研究旨在介绍一种代理优化框架，用于这些设备。这种框架应用于开发两种星系高对比图像的旋转相位面镜（VPM）。通过利用计算智能技术，可以优化这些设备的几何特征。由于设计空间很大，计算限制，因此需要使用代理模型，如多项式拟合、径向基函数或神经网络。然而，我们发现这些方法无法模型VPM的性能。为了解决这些方法的缺陷，我们提出了一种数据有效的进化优化设计，使用深度神经网络作为高精度和高效的代理模型。优化过程中，我们使用一种稳定的粒子群演化优化方法，该方法操作于膜片光学设备的显式几何参数。通过这种方法，我们开发了两个设计候选人。在最复杂的情况下，演化优化使得设计可以实现，而不是通过传统优化技术来实现。在两个情况下，代理模型提高了过程的可靠性和效率，实际减少了需要的模拟数量，相对于传统优化技术，减少了75%。
</details></li>
</ul>
<hr>
<h2 id="sasdim-self-adaptive-noise-scaling-diffusion-model-for-spatial-time-series-imputation"><a href="#sasdim-self-adaptive-noise-scaling-diffusion-model-for-spatial-time-series-imputation" class="headerlink" title="sasdim: self-adaptive noise scaling diffusion model for spatial time series imputation"></a>sasdim: self-adaptive noise scaling diffusion model for spatial time series imputation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01988">http://arxiv.org/abs/2309.01988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shunyang Zhang, Senzhang Wang, Xianzhen Tan, Ruochen Liu, Jian Zhang, Jianxin Wang</li>
<li>for:  spatial time series imputation</li>
<li>methods:  self-adaptive noise scaling diffusion model (SaSDim) with a new loss function and across spatial-temporal global convolution module</li>
<li>results:  effective imputation performance on three real-world datasets, with comparison to current state-of-the-art baselines<details>
<summary>Abstract</summary>
Spatial time series imputation is critically important to many real applications such as intelligent transportation and air quality monitoring. Although recent transformer and diffusion model based approaches have achieved significant performance gains compared with conventional statistic based methods, spatial time series imputation still remains as a challenging issue due to the complex spatio-temporal dependencies and the noise uncertainty of the spatial time series data. Especially, recent diffusion process based models may introduce random noise to the imputations, and thus cause negative impact on the model performance. To this end, we propose a self-adaptive noise scaling diffusion model named SaSDim to more effectively perform spatial time series imputation. Specially, we propose a new loss function that can scale the noise to the similar intensity, and propose the across spatial-temporal global convolution module to more effectively capture the dynamic spatial-temporal dependencies. Extensive experiments conducted on three real world datasets verify the effectiveness of SaSDim by comparison with current state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
<<SYS>> spatial time series imputation 是很重要的几个实际应用，如智能交通和空气质量监测。尽管最近的 transformer 和 diffusion model 基于方法已经实现了与传统统计学基于方法相比的显著性能提升，但是 spatial time series imputation 仍然是一个具有复杂的空间时间相关性和空间时间数据的噪声不确定性的挑战。特别是，最近的 diffusion process 基于模型可能会将随机噪声引入到插入中，从而影响模型性能。为此，我们提出了一种自适应噪声扩大扩散模型名为 SaSDim，以更有效地进行 spatial time series imputation。特别是，我们提出了一个新的损失函数，可以扩大噪声到类似的强度，并提出了跨空间时间全球 convolution 模块，以更好地捕捉空间时间相关性的动态变化。广泛的实验在三个真实世界数据集上验证了 SaSDim 的效果，与当前状态的先进基elines进行比较。
</details></li>
</ul>
<hr>
<h2 id="Graph-Based-Interaction-Aware-Multimodal-2D-Vehicle-Trajectory-Prediction-using-Diffusion-Graph-Convolutional-Networks"><a href="#Graph-Based-Interaction-Aware-Multimodal-2D-Vehicle-Trajectory-Prediction-using-Diffusion-Graph-Convolutional-Networks" class="headerlink" title="Graph-Based Interaction-Aware Multimodal 2D Vehicle Trajectory Prediction using Diffusion Graph Convolutional Networks"></a>Graph-Based Interaction-Aware Multimodal 2D Vehicle Trajectory Prediction using Diffusion Graph Convolutional Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01981">http://arxiv.org/abs/2309.01981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keshu Wu, Yang Zhou, Haotian Shi, Xiaopeng Li, Bin Ran</li>
<li>for: 预测汽车轨迹，以提高自动化汽车运行效率和安全，特别在拥堵多车道高速公路上。</li>
<li>methods: 使用 Graph-based Interaction-aware Multi-modal Trajectory Prediction (GIMTP) 框架，利用图表示汽车的动态互动关系，并通过Diffusion Graph Convolutional Network (DGCN) 捕捉空间和时间两种依赖关系。</li>
<li>results: 提供了两维预测结果，包括 longitudinal 和 lateral 驾驶行为，并提供了相应的概率分布，以便更好地预测汽车的未来行为。<details>
<summary>Abstract</summary>
Predicting vehicle trajectories is crucial for ensuring automated vehicle operation efficiency and safety, particularly on congested multi-lane highways. In such dynamic environments, a vehicle's motion is determined by its historical behaviors as well as interactions with surrounding vehicles. These intricate interactions arise from unpredictable motion patterns, leading to a wide range of driving behaviors that warrant in-depth investigation. This study presents the Graph-based Interaction-aware Multi-modal Trajectory Prediction (GIMTP) framework, designed to probabilistically predict future vehicle trajectories by effectively capturing these interactions. Within this framework, vehicles' motions are conceptualized as nodes in a time-varying graph, and the traffic interactions are represented by a dynamic adjacency matrix. To holistically capture both spatial and temporal dependencies embedded in this dynamic adjacency matrix, the methodology incorporates the Diffusion Graph Convolutional Network (DGCN), thereby providing a graph embedding of both historical states and future states. Furthermore, we employ a driving intention-specific feature fusion, enabling the adaptive integration of historical and future embeddings for enhanced intention recognition and trajectory prediction. This model gives two-dimensional predictions for each mode of longitudinal and lateral driving behaviors and offers probabilistic future paths with corresponding probabilities, addressing the challenges of complex vehicle interactions and multi-modality of driving behaviors. Validation using real-world trajectory datasets demonstrates the efficiency and potential.
</details>
<details>
<summary>摘要</summary>
预测 vehicular trajectories 是确保自动化交通效率和安全的关键，尤其在拥堵的多车道高速公路上。在这种动态环境中，车辆的运动受到历史行为以及与周围车辆的交互影响。这些复杂的交互关系导致了车辆的驾驶行为的各种多样性，需要进一步的研究。本研究提出的 Graph-based Interaction-aware Multi-modal Trajectory Prediction（GIMTP）框架，可以 probabilistically 预测未来车辆的 trajectories，并有效地捕捉这些交互关系。在这个框架中，车辆的运动被视为时间变化的图形中的节点，交通交互被表示为动态邻接矩阵。为了全面捕捉这些图形中的空间和时间相关性，我们采用了卷积图грам（DGCN），从而提供了图形 embedding  both historical states 和 future states。此外，我们采用了驾驶意图特征融合，以适应不同驾驶意图的 embeddings 的权重调整，从而提高了驾驶意图识别和车辆预测。这个模型为每种方向的两维预测提供了两维预测结果，并提供了对应的概率，解决了车辆间复杂的交互关系和驾驶行为多样性的问题。验证使用实际 trajectory 数据表明该模型的效率和潜力。
</details></li>
</ul>
<hr>
<h2 id="Linear-Regression-using-Heterogeneous-Data-Batches"><a href="#Linear-Regression-using-Heterogeneous-Data-Batches" class="headerlink" title="Linear Regression using Heterogeneous Data Batches"></a>Linear Regression using Heterogeneous Data Batches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01973">http://arxiv.org/abs/2309.01973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayush Jain, Rajat Sen, Weihao Kong, Abhimanyu Das, Alon Orlitsky<br>for:The paper is written to address the problem of learning input-output relationships from multiple sources with insufficient data.methods:The paper proposes a novel gradient-based algorithm that improves upon existing results by allowing for different, unknown, and heavy-tailed input distributions for each subgroup, recovering all subgroups with a significant proportion of batches, and removing the separation requirement between regression vectors.results:The proposed algorithm extends the applicability of the existing results, allowing for smaller batch sizes and reducing the number of batches needed to achieve accurate regression.<details>
<summary>Abstract</summary>
In many learning applications, data are collected from multiple sources, each providing a \emph{batch} of samples that by itself is insufficient to learn its input-output relationship. A common approach assumes that the sources fall in one of several unknown subgroups, each with an unknown input distribution and input-output relationship. We consider one of this setup's most fundamental and important manifestations where the output is a noisy linear combination of the inputs, and there are $k$ subgroups, each with its own regression vector. Prior work~\cite{kong2020meta} showed that with abundant small-batches, the regression vectors can be learned with only few, $\tilde\Omega( k^{3/2})$, batches of medium-size with $\tilde\Omega(\sqrt k)$ samples each. However, the paper requires that the input distribution for all $k$ subgroups be isotropic Gaussian, and states that removing this assumption is an ``interesting and challenging problem". We propose a novel gradient-based algorithm that improves on the existing results in several ways. It extends the applicability of the algorithm by: (1) allowing the subgroups' underlying input distributions to be different, unknown, and heavy-tailed; (2) recovering all subgroups followed by a significant proportion of batches even for infinite $k$; (3) removing the separation requirement between the regression vectors; (4) reducing the number of batches and allowing smaller batch sizes.
</details>
<details>
<summary>摘要</summary>
在许多学习应用中，数据来源来自多个不同的源泉，每个源泉提供一个不够的批处理，用于学习其输入输出关系。一种常见的方法假设这些源泉可以分为多个未知的子组，每个子组有未知的输入分布和输入输出关系。我们考虑这个设置的一个最基本和最重要的情况，其中输出是噪声加权的输入的线性组合，并且有 $k$ 个子组，每个子组有自己的回归 вектор。先前的工作（\ref{kong2020meta}) 显示，只要有充足的小批处理，可以通过只需几个 $\tilde\Omega(k^{3/2})$ 批处理，每批处理中有 $\tilde\Omega(\sqrt k)$ 个样本，学习这些回归 вектор。然而，这篇文章要求所有 $k$ 个子组的输入分布都是均匀的 Gaussian，并且认为从不同输入分布的批处理中学习回归 вектор是一个“有趣和挑战的问题”。我们提出了一种新的梯度法，它在以下方面改进了现有结果：1. 允许子组的下面分布不同、未知、重 tailed;2. 可以在有限 $k$ 的情况下，将所有子组都回归;3. 取消回归向量之间的分离要求;4. 减少批处理的数量，并允许更小的批处理大小。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Interpretable-Cross-modal-Reasoning"><a href="#A-Survey-on-Interpretable-Cross-modal-Reasoning" class="headerlink" title="A Survey on Interpretable Cross-modal Reasoning"></a>A Survey on Interpretable Cross-modal Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01955">http://arxiv.org/abs/2309.01955</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZuyiZhou/Awesome-Interpretable-Cross-modal-Reasoning">https://github.com/ZuyiZhou/Awesome-Interpretable-Cross-modal-Reasoning</a></li>
<li>paper_authors: Dizhan Xue, Shengsheng Qian, Zuyi Zhou, Changsheng Xu</li>
<li>for: 本文旨在探讨可解释的跨模态理解（I-CMR），即不 только实现高预测性能，还能提供人类可理解的解释结果。</li>
<li>methods: 本文使用三级分类法概述I-CMR的典型方法，并对现有的CMR数据集进行了解释注释。</li>
<li>results: 本文总结了I-CMR的挑战和未来发展方向，并提供了一个包含相关方法、数据集和资源的GitHub项目。<details>
<summary>Abstract</summary>
In recent years, cross-modal reasoning (CMR), the process of understanding and reasoning across different modalities, has emerged as a pivotal area with applications spanning from multimedia analysis to healthcare diagnostics. As the deployment of AI systems becomes more ubiquitous, the demand for transparency and comprehensibility in these systems' decision-making processes has intensified. This survey delves into the realm of interpretable cross-modal reasoning (I-CMR), where the objective is not only to achieve high predictive performance but also to provide human-understandable explanations for the results. This survey presents a comprehensive overview of the typical methods with a three-level taxonomy for I-CMR. Furthermore, this survey reviews the existing CMR datasets with annotations for explanations. Finally, this survey summarizes the challenges for I-CMR and discusses potential future directions. In conclusion, this survey aims to catalyze the progress of this emerging research area by providing researchers with a panoramic and comprehensive perspective, illuminating the state of the art and discerning the opportunities. The summarized methods, datasets, and other resources are available at https://github.com/ZuyiZhou/Awesome-Interpretable-Cross-modal-Reasoning.
</details>
<details>
<summary>摘要</summary>
This survey provides a comprehensive overview of I-CMR methods, using a three-level taxonomy to categorize them. Additionally, it reviews existing CMR datasets with annotations for explanations. Finally, it discusses the challenges facing I-CMR and outlines potential future directions.The main goal of this survey is to advance the progress of this emerging research area by providing researchers with a comprehensive perspective, highlighting the current state of the art and identifying opportunities for future research. The survey's findings, methods, datasets, and other resources are available at https://github.com/ZuyiZhou/Awesome-Interpretable-Cross-modal-Reasoning.
</details></li>
</ul>
<hr>
<h2 id="RADIO-Reference-Agnostic-Dubbing-Video-Synthesis"><a href="#RADIO-Reference-Agnostic-Dubbing-Video-Synthesis" class="headerlink" title="RADIO: Reference-Agnostic Dubbing Video Synthesis"></a>RADIO: Reference-Agnostic Dubbing Video Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01950">http://arxiv.org/abs/2309.01950</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyeun Lee, Chaewon Kim, Sangjoon Yu, Jaejun Yoo, Gyeong-Moon Park</li>
<li>for: 高精度 talking head生成中最大的挑战是实现高精度细节，同时保证 precisions synchronization.</li>
<li>methods: 我们提出了 RADIO 框架，通过修改decoder层的 latent space 来实现高质量的 dubbed video。此外，我们还 incorporated ViT blocks 来强调高精度细节，特别是在唇部分。</li>
<li>results: 我们的实验结果表明，RADIO 能够保持高度同步，同时不失高精度。特别在参考帧与实际帧有很大差异时，我们的方法表现出了更高的稳定性和可靠性。<details>
<summary>Abstract</summary>
One of the most challenging problems in audio-driven talking head generation is achieving high-fidelity detail while ensuring precise synchronization. Given only a single reference image, extracting meaningful identity attributes becomes even more challenging, often causing the network to mirror the facial and lip structures too closely. To address these issues, we introduce RADIO, a framework engineered to yield high-quality dubbed videos regardless of the pose or expression in reference images. The key is to modulate the decoder layers using latent space composed of audio and reference features. Additionally, we incorporate ViT blocks into the decoder to emphasize high-fidelity details, especially in the lip region. Our experimental results demonstrate that RADIO displays high synchronization without the loss of fidelity. Especially in harsh scenarios where the reference frame deviates significantly from the ground truth, our method outperforms state-of-the-art methods, highlighting its robustness. Pre-trained model and codes will be made public after the review.
</details>
<details>
<summary>摘要</summary>
一个非常挑战的问题在听音驱动的头部生成中是达到高精度细节，同时保证准确的同步。只有一个参考图片，提取有意义的人脸特征变得更加挑战，常常使网络模式lip和脸部结构，这会导致网络模式的产生。为解决这些问题，我们介绍了RADIO框架，可以生成高质量的重音视频，无论参考图片的pose或表情。关键在于在decoder层中模拟latent空间中的音频和参考特征。此外，我们在decoder中添加了ViT块，以强调高精度细节，特别是在唇区。我们的实验结果表明，RADIO可以保持高同步性，而不失去精度。尤其在参考图片与实际真实情况有很大差异时，我们的方法比状态艺术法更高效，这展示了其Robustness。我们将在审核后发布预训练模型和代码。
</details></li>
</ul>
<hr>
<h2 id="OHQ-On-chip-Hardware-aware-Quantization"><a href="#OHQ-On-chip-Hardware-aware-Quantization" class="headerlink" title="OHQ: On-chip Hardware-aware Quantization"></a>OHQ: On-chip Hardware-aware Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01945">http://arxiv.org/abs/2309.01945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Huang, Haotong Qin, Yangdong Liu, Jingzhuo Liang, Yifu Ding, Ying Li, Xianglong Liu</li>
<li>for: 这个论文旨在提出一个在硬件上进行数值化的框架，以便在资源有限的硬件上部署进步的深度模型。</li>
<li>methods: 这个框架使用了硬件感知的混合精度数值化，并且使用了面精度调节来优化数值化的精度和效率。</li>
<li>results: 这个框架可以实现在硬件上进行加速的推理，并且可以获得70%和73%的准确率 для ResNet-18和MobileNetV3。同时，这个框架可以提高对INT8的延迟时间，比较INT8在部署时的性能。<details>
<summary>Abstract</summary>
Quantization emerges as one of the most promising approaches for deploying advanced deep models on resource-constrained hardware. Mixed-precision quantization leverages multiple bit-width architectures to unleash the accuracy and efficiency potential of quantized models. However, existing mixed-precision quantization suffers exhaustive search space that causes immense computational overhead. The quantization process thus relies on separate high-performance devices rather than locally, which also leads to a significant gap between the considered hardware metrics and the real deployment.In this paper, we propose an On-chip Hardware-aware Quantization (OHQ) framework that performs hardware-aware mixed-precision quantization without accessing online devices. First, we construct the On-chip Quantization Awareness (OQA) pipeline, enabling perceive the actual efficiency metrics of the quantization operator on the hardware.Second, we propose Mask-guided Quantization Estimation (MQE) technique to efficiently estimate the accuracy metrics of operators under the constraints of on-chip-level computing power.By synthesizing network and hardware insights through linear programming, we obtain optimized bit-width configurations. Notably, the quantization process occurs on-chip entirely without any additional computing devices and data access. We demonstrate accelerated inference after quantization for various architectures and compression ratios, achieving 70% and 73% accuracy for ResNet-18 and MobileNetV3, respectively. OHQ improves latency by 15~30% compared to INT8 on deployment.
</details>
<details>
<summary>摘要</summary>
“量化技术在资源有限的硬件上部署高级深度模型的可能性几乎无限大。混合精度量化利用多个bit Width架构实现量化模型的精度和效率潜力。然而，现有的混合精度量化受到极大的搜索空间压力，导致计算开销很大。因此，量化过程通常需要分离的高性能设备，这也导致了实际部署与考虑的硬件指标之间存在很大的差距。在这篇论文中，我们提出了在硬件上完全没有访问外部设备的On-chip Hardware-aware Quantization（OHQ）框架。首先，我们构建了On-chip Quantization Awareness（OQA）管道，使得量化操作的实际效率指标可以在硬件上被感知。其次，我们提出了面具指导量化估计（MQE）技术，以计算量化操作在硬件上的精度指标。通过将网络和硬件知识融合到线性规划中，我们得到了优化的位数配置。需要注意的是，量化过程完全发生在硬件上，没有任何外部计算设备和数据访问。我们在不同的架构和压缩比例上进行加速的推理，实现了ResNet-18和MobileNetV3的70%和73%的准确率。OHQ提高了INT8在部署时的延迟时间，相对于INT8，OHQ提高了15~30%。”
</details></li>
</ul>
<hr>
<h2 id="Quantum-AI-empowered-Intelligent-Surveillance-Advancing-Public-Safety-Through-Innovative-Contraband-Detection"><a href="#Quantum-AI-empowered-Intelligent-Surveillance-Advancing-Public-Safety-Through-Innovative-Contraband-Detection" class="headerlink" title="Quantum-AI empowered Intelligent Surveillance: Advancing Public Safety Through Innovative Contraband Detection"></a>Quantum-AI empowered Intelligent Surveillance: Advancing Public Safety Through Innovative Contraband Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03231">http://arxiv.org/abs/2309.03231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Syed Atif Ali Shah, Nasir Algeelani, Najeeb Al-Sammarraie</li>
<li>for: 这个研究旨在发展一个基于量子人工智能的实时类型识别系统，以解决现有的实时识别过程中的速度问题。</li>
<li>methods: 本研究使用了Quantum CNN的技术，实现了实时类型识别的高精度和高速度。</li>
<li>results: Quantum-RetinaNet模型在实验中表现出色，能够实现高精度和高速度的实时类型识别，提供了一个可行的解决方案 для实时识别过程中的速度问题。<details>
<summary>Abstract</summary>
Surveillance systems have emerged as crucial elements in upholding peace and security in the modern world. Their ubiquity aids in monitoring suspicious activities effectively. However, in densely populated environments, continuous active monitoring becomes impractical, necessitating the development of intelligent surveillance systems. AI integration in the surveillance domain was a big revolution, however, speed issues have prevented its widespread implementation in the field. It has been observed that quantum artificial intelligence has led to a great breakthrough. Quantum artificial intelligence-based surveillance systems have shown to be more accurate as well as capable of performing well in real-time scenarios, which had never been seen before. In this research, a RentinaNet model is integrated with Quantum CNN and termed as Quantum-RetinaNet. By harnessing the Quantum capabilities of QCNN, Quantum-RetinaNet strikes a balance between accuracy and speed. This innovative integration positions it as a game-changer, addressing the challenges of active monitoring in densely populated scenarios. As demand for efficient surveillance solutions continues to grow, Quantum-RetinaNet offers a compelling alternative to existing CNN models, upholding accuracy standards without sacrificing real-time performance. The unique attributes of Quantum-RetinaNet have far-reaching implications for the future of intelligent surveillance. With its enhanced processing speed, it is poised to revolutionize the field, catering to the pressing need for rapid yet precise monitoring. As Quantum-RetinaNet becomes the new standard, it ensures public safety and security while pushing the boundaries of AI in surveillance.
</details>
<details>
<summary>摘要</summary>
现代世界中维护和平安全的重要元素之一是监控系统。它们的普遍性使得可以有效监控异常活动。然而，在高度密集的环境中，不断的活动监控变得不实际，需要开发智能监控系统。人工智能在监控领域的整合是一次大革命，但速度问题阻碍了其广泛应用。研究表明，量子人工智能在监控领域带来了巨大突破。基于量子人工智能的监控系统显示更高精度，并在实时场景中表现出色，这从未被见过。本研究将RentinaNet模型与量子神经网络（QCNN）结合，称为量子-RetinaNet。通过利用量子神经网络的量子特性，量子-RetinaNet实现了精度和速度之间的平衡。这种创新的集成，将成为监控领域的游戏 changer，解决了高度密集enario中不断监控的挑战。随着有效监控解决方案的需求不断增长，量子-RetinaNet对现有的Convolutional Neural Network（CNN）模型提供了一种有力的替代，保持精度标准而不是速度性能的牺牲。量子-RetinaNet的独特特点有广泛的未来预测，它在监控领域的扩展将成为一个革命，为公共安全和安全提供保障，同时推动人工智能在监控领域的发展。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Brain-Transformer-with-Multi-level-Attention-for-Functional-Brain-Network-Analysis"><a href="#Dynamic-Brain-Transformer-with-Multi-level-Attention-for-Functional-Brain-Network-Analysis" class="headerlink" title="Dynamic Brain Transformer with Multi-level Attention for Functional Brain Network Analysis"></a>Dynamic Brain Transformer with Multi-level Attention for Functional Brain Network Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01941">http://arxiv.org/abs/2309.01941</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Wayfear/Dynamic-Brain-Transformer">https://github.com/Wayfear/Dynamic-Brain-Transformer</a></li>
<li>paper_authors: Xuan Kan, Antonio Aodong Chen Gu, Hejie Cui, Ying Guo, Carl Yang</li>
<li>for: 这篇论文的目的是提出一种新的方法，以便更好地分析大脑功能。</li>
<li>methods: 这篇论文使用了Dynamic bRAin Transformer（DART）方法，融合静止大脑网络和动态大脑网络，以提高大脑功能分析的精度和多元性。</li>
<li>results: 这篇论文的结果显示，DRAT方法可以更有效地预测临床结果和分类个人，并且可以提供更多的几何资讯，例如哪些大脑网络或动态网络在最终预测中做出了贡献。<details>
<summary>Abstract</summary>
Recent neuroimaging studies have highlighted the importance of network-centric brain analysis, particularly with functional magnetic resonance imaging. The emergence of Deep Neural Networks has fostered a substantial interest in predicting clinical outcomes and categorizing individuals based on brain networks. However, the conventional approach involving static brain network analysis offers limited potential in capturing the dynamism of brain function. Although recent studies have attempted to harness dynamic brain networks, their high dimensionality and complexity present substantial challenges. This paper proposes a novel methodology, Dynamic bRAin Transformer (DART), which combines static and dynamic brain networks for more effective and nuanced brain function analysis. Our model uses the static brain network as a baseline, integrating dynamic brain networks to enhance performance against traditional methods. We innovatively employ attention mechanisms, enhancing model explainability and exploiting the dynamic brain network's temporal variations. The proposed approach offers a robust solution to the low signal-to-noise ratio of blood-oxygen-level-dependent signals, a recurring issue in direct DNN modeling. It also provides valuable insights into which brain circuits or dynamic networks contribute more to final predictions. As such, DRAT shows a promising direction in neuroimaging studies, contributing to the comprehensive understanding of brain organization and the role of neural circuits.
</details>
<details>
<summary>摘要</summary>
latest neuroimaging studies have highlighted the importance of network-centric brain analysis, particularly with functional magnetic resonance imaging. The emergence of Deep Neural Networks has fostered a substantial interest in predicting clinical outcomes and categorizing individuals based on brain networks. However, the conventional approach involving static brain network analysis offers limited potential in capturing the dynamism of brain function. Although recent studies have attempted to harness dynamic brain networks, their high dimensionality and complexity present substantial challenges. This paper proposes a novel methodology, Dynamic bRAin Transformer (DART), which combines static and dynamic brain networks for more effective and nuanced brain function analysis. Our model uses the static brain network as a baseline, integrating dynamic brain networks to enhance performance against traditional methods. We innovatively employ attention mechanisms, enhancing model explainability and exploiting the dynamic brain network's temporal variations. The proposed approach offers a robust solution to the low signal-to-noise ratio of blood-oxygen-level-dependent signals, a recurring issue in direct DNN modeling. It also provides valuable insights into which brain circuits or dynamic networks contribute more to final predictions. As such, DRAT shows a promising direction in neuroimaging studies, contributing to the comprehensive understanding of brain organization and the role of neural circuits.
</details></li>
</ul>
<hr>
<h2 id="CodeApex-A-Bilingual-Programming-Evaluation-Benchmark-for-Large-Language-Models"><a href="#CodeApex-A-Bilingual-Programming-Evaluation-Benchmark-for-Large-Language-Models" class="headerlink" title="CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models"></a>CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01940">http://arxiv.org/abs/2309.01940</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apexlab/codeapex">https://github.com/apexlab/codeapex</a></li>
<li>paper_authors: Lingyue Fu, Huacan Chai, Shuang Luo, Kounianhua Du, Weiming Zhang, Longteng Fan, Jiayi Lei, Renting Rui, Jianghao Lin, Yuchen Fang, Yifan Liu, Jingkuan Wang, Siyuan Qi, Kangning Zhang, Weinan Zhang, Yong Yu</li>
<li>for: 这个论文主要是用来评估大型自然语言模型（LLMs）在编程方面的能力。</li>
<li>methods: 该论文使用了一个名为CodeApex的双语 bencmark dataset，以评估 LLMS 在编程理解和代码生成方面的能力。 CodeApex 包括三类多选问题：概念理解、通用理性和多步理性，用于评估 LLMS 的编程理解能力。</li>
<li>results: 研究人员使用 14 个当前状态的 LLMS，包括一般型和专门型模型，进行评估。 GPT 表现出了最好的编程能力，在两个任务上的准确率分别为 50% 和 56%。 这显示了 LLMS 在编程任务上仍有很大的改进空间。<details>
<summary>Abstract</summary>
With the emergence of Large Language Models (LLMs), there has been a significant improvement in the programming capabilities of models, attracting growing attention from researchers. We propose CodeApex, a bilingual benchmark dataset focusing on the programming comprehension and code generation abilities of LLMs. CodeApex comprises three types of multiple-choice questions: conceptual understanding, commonsense reasoning, and multi-hop reasoning, designed to evaluate LLMs on programming comprehension tasks. Additionally, CodeApex utilizes algorithmic questions and corresponding test cases to assess the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs, including both general-purpose and specialized models. GPT exhibits the best programming capabilities, achieving approximate accuracies of 50% and 56% on the two tasks, respectively. There is still significant room for improvement in programming tasks. We hope that CodeApex can serve as a reference for evaluating the coding capabilities of LLMs, further promoting their development and growth. Datasets are released at https://github.com/APEXLAB/CodeApex.git. CodeApex submission website is https://apex.sjtu.edu.cn/codeapex/.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使大语言模型（LLM）的出现，程序设计和生成能力得到了显著改善，引起了研究人员的关注。我们提出了 CodeApex，一个双语测试集，旨在评估 LLM 在程序理解和代码生成任务上的能力。CodeApex 包括三种多选问题：概念理解、常识逻辑和多步逻辑，用于评估 LLM 在程序理解任务上的能力。此外，CodeApex 还使用了算法问题和相应的测试用例，来评估 LLM 生成的代码质量。我们对 14 个当前state-of-the-art LLM 进行评估，包括一般目标和专门目标模型。GPT 在两个任务上显示出了最好的编程能力，即 aproximate 的准确率为 50% 和 56%。然而，还有很多空间可以进一步改进程序任务。我们希望 CodeApex 能够成为 LLM 编程能力的参考，并促进其发展和成长。测试集可以在 https://github.com/APEXLAB/CodeApex.git 上下载。CodeApex 提交website是 https://apex.sjtu.edu.cn/codeapex/。
</details></li>
</ul>
<hr>
<h2 id="Provably-safe-systems-the-only-path-to-controllable-AGI"><a href="#Provably-safe-systems-the-only-path-to-controllable-AGI" class="headerlink" title="Provably safe systems: the only path to controllable AGI"></a>Provably safe systems: the only path to controllable AGI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01933">http://arxiv.org/abs/2309.01933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max Tegmark, Steve Omohundro</li>
<li>for: 这篇论文旨在帮助人类安全蒸蒸成长，并使用强大的人工智能（AGI）来实现这一目标。</li>
<li>methods: 这篇论文提出了使用高级人工智能进行正式验证和机制解释来建构AGI，并 garantía AGI满足人类指定的要求。</li>
<li>results: 这篇论文认为，这种方法是保证安全控制AGI的唯一道路。<details>
<summary>Abstract</summary>
We describe a path to humanity safely thriving with powerful Artificial General Intelligences (AGIs) by building them to provably satisfy human-specified requirements. We argue that this will soon be technically feasible using advanced AI for formal verification and mechanistic interpretability. We further argue that it is the only path which guarantees safe controlled AGI. We end with a list of challenge problems whose solution would contribute to this positive outcome and invite readers to join in this work.
</details>
<details>
<summary>摘要</summary>
我们描述了一条人类安全快速发展的人工通用智能（AGI）路径，通过让AGI建立可靠满足人类规定的条件。我们认为这很快会科技上可行，使用进步的AI进行正式验证和机械阅读性。我们还认为这是唯一能 guarantee safe controlled AGI 的路径。我们列出了一些挑战问题的解决方案，并邀请读者参与这个工作。Note that "人类安全快速发展" (rénxīn ànqù suǒzhòng fāzhǎng) is a bit of a mouthful in Chinese, so you may see variations of the phrase that use shorter words or different phrasing.
</details></li>
</ul>
<hr>
<h2 id="Regret-Analysis-of-Policy-Gradient-Algorithm-for-Infinite-Horizon-Average-Reward-Markov-Decision-Processes"><a href="#Regret-Analysis-of-Policy-Gradient-Algorithm-for-Infinite-Horizon-Average-Reward-Markov-Decision-Processes" class="headerlink" title="Regret Analysis of Policy Gradient Algorithm for Infinite Horizon Average Reward Markov Decision Processes"></a>Regret Analysis of Policy Gradient Algorithm for Infinite Horizon Average Reward Markov Decision Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01922">http://arxiv.org/abs/2309.01922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qinbo Bai, Washim Uddin Mondal, Vaneet Aggarwal</li>
<li>for: 这个论文关注的是无穷远景平均奖励Markov决策过程（MDP）。与现有工作不同，我们的方法不假设MDP结构是线性的，而是利用通用的政策梯度算法，从而解放其吞吐量。</li>
<li>methods: 我们提出了一种政策梯度算法，并证明其全球吞吐量性。此外，我们还 Compute regret bound，这是首次在平均奖励场景中对通用参数化政策梯度算法进行投入的尝试。</li>
<li>results: 我们证明了该算法的 regret bound为 $\tilde{\mathcal{O}({T}^{3&#x2F;4})$。这意味着，在平均奖励场景中，我们的算法可以在很短的时间内达到理想的决策。<details>
<summary>Abstract</summary>
In this paper, we consider an infinite horizon average reward Markov Decision Process (MDP). Distinguishing itself from existing works within this context, our approach harnesses the power of the general policy gradient-based algorithm, liberating it from the constraints of assuming a linear MDP structure. We propose a policy gradient-based algorithm and show its global convergence property. We then prove that the proposed algorithm has $\tilde{\mathcal{O}({T}^{3/4})$ regret. Remarkably, this paper marks a pioneering effort by presenting the first exploration into regret-bound computation for the general parameterized policy gradient algorithm in the context of average reward scenarios.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们考虑了一个无穷horizon平均奖励Markov决策过程（MDP）。与现有的研究不同，我们的方法利用了通用的policy梯度基本算法，从linear MDP结构的假设中解放出来。我们提出了一种policy梯度基本算法，并证明其全球归一化性。然后，我们证明了提案的算法有$\tilde{\mathcal{O}({T}^{3/4})$的 regret。值得注意的是，这篇论文是第一篇在average奖励场景中计算 regret bound的general parameterized policy gradient算法的探索。
</details></li>
</ul>
<hr>
<h2 id="SyntheWorld-A-Large-Scale-Synthetic-Dataset-for-Land-Cover-Mapping-and-Building-Change-Detection"><a href="#SyntheWorld-A-Large-Scale-Synthetic-Dataset-for-Land-Cover-Mapping-and-Building-Change-Detection" class="headerlink" title="SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and Building Change Detection"></a>SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and Building Change Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01907">http://arxiv.org/abs/2309.01907</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JTRNEO/SyntheWorld">https://github.com/JTRNEO/SyntheWorld</a></li>
<li>paper_authors: Jian Song, Hongruixuan Chen, Naoto Yokoya</li>
<li>for: 提高计算机视觉任务和技术的研究，尤其是远程感知图像处理领域。</li>
<li>methods: 使用 Synthetic dataset，包括40,000个图像，每个图像具有 submeter 精度的像素和 eight 类地形分类注解，以及40,000个对比图像，用于检测建筑变化。</li>
<li>results: 通过在多个标准远程感知图像集上进行实验，证明 SyntheticWorld 的高质量和多样性，并 investigate 了在不同条件下 synthetic data 的优势。<details>
<summary>Abstract</summary>
Synthetic datasets, recognized for their cost effectiveness, play a pivotal role in advancing computer vision tasks and techniques. However, when it comes to remote sensing image processing, the creation of synthetic datasets becomes challenging due to the demand for larger-scale and more diverse 3D models. This complexity is compounded by the difficulties associated with real remote sensing datasets, including limited data acquisition and high annotation costs, which amplifies the need for high-quality synthetic alternatives. To address this, we present SyntheWorld, a synthetic dataset unparalleled in quality, diversity, and scale. It includes 40,000 images with submeter-level pixels and fine-grained land cover annotations of eight categories, and it also provides 40,000 pairs of bitemporal image pairs with building change annotations for building change detection task. We conduct experiments on multiple benchmark remote sensing datasets to verify the effectiveness of SyntheWorld and to investigate the conditions under which our synthetic data yield advantages. We will release SyntheWorld to facilitate remote sensing image processing research.
</details>
<details>
<summary>摘要</summary>
《 synthetic datasets 》，被广泛应用于计算机视觉任务和技术的进步，因为它们的成本效益很高。然而，当涉及到远程感知图像处理时，创建 synthetic datasets 变得更加困难，因为需要更大规模和更多的 3D 模型。这种复杂性由实际远程感知数据的限制和高注释成本带来，这使得高质量的 synthetic  altenativas 变得更加重要。为解决这一问题，我们介绍 SyntheWorld，一个无与伦比的 synthetic dataset，包括 40,000 张图像，每张图像有 submeter 级像素和细化的地形分类注释，同时还提供了 40,000 对时间双写图像对，用于建筑变化检测任务的注释。我们在多个标准远程感知数据集上进行了实验，以验证 SyntheWorld 的有效性和在不同条件下synthetic 数据的优势。我们将在未来发布 SyntheWorld，以便促进远程感知图像处理研究。
</details></li>
</ul>
<hr>
<h2 id="Towards-General-and-Efficient-Online-Tuning-for-Spark"><a href="#Towards-General-and-Efficient-Online-Tuning-for-Spark" class="headerlink" title="Towards General and Efficient Online Tuning for Spark"></a>Towards General and Efficient Online Tuning for Spark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01901">http://arxiv.org/abs/2309.01901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Li, Huaijun Jiang, Yu Shen, Yide Fang, Xiaofeng Yang, Danqing Huang, Xinyi Zhang, Wentao Zhang, Ce Zhang, Peng Chen, Bin Cui</li>
<li>for: 提高 Spark 的性能和可扩展性，解决自动调整问题。</li>
<li>methods: 提出一个通用和高效的 Spark 自动调整框架，包括一个通用优化形式ulation、搜索方法、安全获取方法和三种创新技术。</li>
<li>results: 实现了在云端提供独立的 Spark 调整服务，并在实际生产任务中实现了减少内存成本57.00%和CPU成本34.93%的效果，提高了实用性、通用性和效率。<details>
<summary>Abstract</summary>
The distributed data analytic system -- Spark is a common choice for processing massive volumes of heterogeneous data, while it is challenging to tune its parameters to achieve high performance. Recent studies try to employ auto-tuning techniques to solve this problem but suffer from three issues: limited functionality, high overhead, and inefficient search.   In this paper, we present a general and efficient Spark tuning framework that can deal with the three issues simultaneously. First, we introduce a generalized tuning formulation, which can support multiple tuning goals and constraints conveniently, and a Bayesian optimization (BO) based solution to solve this generalized optimization problem. Second, to avoid high overhead from additional offline evaluations in existing methods, we propose to tune parameters along with the actual periodic executions of each job (i.e., online evaluations). To ensure safety during online job executions, we design a safe configuration acquisition method that models the safe region. Finally, three innovative techniques are leveraged to further accelerate the search process: adaptive sub-space generation, approximate gradient descent, and meta-learning method.   We have implemented this framework as an independent cloud service, and applied it to the data platform in Tencent. The empirical results on both public benchmarks and large-scale production tasks demonstrate its superiority in terms of practicality, generality, and efficiency. Notably, this service saves an average of 57.00% memory cost and 34.93% CPU cost on 25K in-production tasks within 20 iterations, respectively.
</details>
<details>
<summary>摘要</summary>
分布式数据分析系统---Spark 是一种常用的处理巨量不同类型数据的工具，但是调整其参数以 достичь高性能是一个挑战。最近的研究尝试使用自动调整技术解决这个问题，但它们受到三种问题的限制：功能受限，高过程成本，和不fficient搜索。在这篇论文中，我们提出了一个通用和高效的Spark调整框架，可以同时解决这三种问题。首先，我们引入一个通用的调整形式，可以方便地支持多个调整目标和约束，并使用抽象优化（BO）来解决这个通用优化问题。其次，为了避免现有方法的高过程成本，我们提议在实际 periodic执行每个任务时（即在线评估）进行参数调整。为确保在线任务执行安全，我们设计了一种安全配置获取方法，可以模拟安全区域。最后，我们采用了三种创新技术来加速搜索过程：适应子空间生成、 Approximate Gradient Descent 和元学习方法。我们实现了这个框架作为独立的云服务，并应用于腾讯数据平台。实际结果表明，这个框架在实际应用中具有了优秀的实用性、通用性和高效性。特别是，这个服务在25000个生产任务上平均占用内存成本下降57.00%，并且CPU成本下降34.93%，在20个迭代中分别达到这些值。
</details></li>
</ul>
<hr>
<h2 id="Inferring-Actual-Treatment-Pathways-from-Patient-Records"><a href="#Inferring-Actual-Treatment-Pathways-from-Patient-Records" class="headerlink" title="Inferring Actual Treatment Pathways from Patient Records"></a>Inferring Actual Treatment Pathways from Patient Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01897">http://arxiv.org/abs/2309.01897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Wilkins-Caruana, Madhushi Bandara, Katarzyna Musial, Daniel Catchpoole, Paul J. Kennedy</li>
<li>for: This paper aims to infer actual treatment steps for a particular patient group from administrative health records (AHRs), addressing gaps in treatment pathway-inference research.</li>
<li>methods: The method introduced in this paper is called Defrag, which learns the semantic and temporal meaning of healthcare event sequences using a neural network (NN) and a self-supervised learning objective.</li>
<li>results: Defrag significantly outperforms several existing pathway-inference methods and is effective in identifying best-practice pathway fragments for breast cancer, lung cancer, and melanoma in public healthcare records.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目标是从行政医疗记录（AHR）中推断特定患者群体的实际治疗步骤，解决治疗路径推断研究中的技术和方法上的缺陷。</li>
<li>methods: 该论文提出的方法是名为“Defrag”的方法，它利用神经网络（NN）和一种自我超vised学习目标来学习医疗事件序列的semantic和时间意义。</li>
<li>results: Defrag Significantly Outperforms Several Existing Pathway-Inference Methods and Effective in Identifying Best-Practice Pathway Fragments for Breast Cancer, Lung Cancer, and Melanoma in Public Healthcare Records。<details>
<summary>Abstract</summary>
Treatment pathways are step-by-step plans outlining the recommended medical care for specific diseases; they get revised when different treatments are found to improve patient outcomes. Examining health records is an important part of this revision process, but inferring patients' actual treatments from health data is challenging due to complex event-coding schemes and the absence of pathway-related annotations. This study aims to infer the actual treatment steps for a particular patient group from administrative health records (AHR) - a common form of tabular healthcare data - and address several technique- and methodology-based gaps in treatment pathway-inference research. We introduce Defrag, a method for examining AHRs to infer the real-world treatment steps for a particular patient group. Defrag learns the semantic and temporal meaning of healthcare event sequences, allowing it to reliably infer treatment steps from complex healthcare data. To our knowledge, Defrag is the first pathway-inference method to utilise a neural network (NN), an approach made possible by a novel, self-supervised learning objective. We also developed a testing and validation framework for pathway inference, which we use to characterise and evaluate Defrag's pathway inference ability and compare against baselines. We demonstrate Defrag's effectiveness by identifying best-practice pathway fragments for breast cancer, lung cancer, and melanoma in public healthcare records. Additionally, we use synthetic data experiments to demonstrate the characteristics of the Defrag method, and to compare Defrag to several baselines where it significantly outperforms non-NN-based methods. Defrag significantly outperforms several existing pathway-inference methods and offers an innovative and effective approach for inferring treatment pathways from AHRs. Open-source code is provided to encourage further research in this area.
</details>
<details>
<summary>摘要</summary>
医疗路径是一系列步骤计划，用于确定特定疾病的建议的医疗方案。这些路径不断地得到更新，当新的治疗方法提高患者结果时。查看医疗记录是这个 revision 过程的重要组成部分，但从医疗数据中推断患者的具体治疗步骤是困难的，因为医疗事件编码方案复杂，而且缺乏路径相关的注释。本研究旨在从医疗记录中推断患者特定群体的实际治疗步骤，并解决了一些技术和方法基础上的差距。我们提出了一种名为Defrag的方法，可以从医疗记录中推断实际治疗步骤。Defrag可以学习医疗事件序列的semantic和temporal意义，以可靠地从复杂医疗数据中推断治疗步骤。我们知道，Defrag是首个利用神经网络（NN）的医疗路径推断方法，这是由于我们提出的一种新的自主学习目标。我们还开发了一个用于医疗路径推断的测试和验证框架，用于评估和比较Defrag的路径推断能力，并与基eline相比。我们在公共医疗记录中identified breast cancer, lung cancer和melanoma的best-practice路径片段。此外，我们通过 sintetic data experiment demonstrates Defrag的特点，并与其他基eline相比，Defrag显示出显著的优势。Defrag signifiantly outperforms several existing pathway-inference methods and offers an innovative and effective approach for inferring treatment pathways from AHRs.我们提供了开源代码，以便进一步研究这个领域。
</details></li>
</ul>
<hr>
<h2 id="On-the-Planning-Search-and-Memorization-Capabilities-of-Large-Language-Models"><a href="#On-the-Planning-Search-and-Memorization-Capabilities-of-Large-Language-Models" class="headerlink" title="On the Planning, Search, and Memorization Capabilities of Large Language Models"></a>On the Planning, Search, and Memorization Capabilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01868">http://arxiv.org/abs/2309.01868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunhao Yang, Anshul Tomar</li>
<li>for: 这项研究探讨了使用最新的大语言模型GPT-4进行规划任务的可能性，并在多个规划子领域进行了广泛的检验。</li>
<li>methods: 本研究使用GPT-4进行规划领域EXTRACTION、图搜索路径规划和反对抗规划等多个任务的实验分析。</li>
<li>results: 研究发现GPT-4在规划领域中表现出色，但也存在一些约束限制其应用范围。提出了一种精通语言模型特定领域的微调方法来提高CoT能力。<details>
<summary>Abstract</summary>
The rapid advancement of large language models, such as the Generative Pre-trained Transformer (GPT) series, has had significant implications across various disciplines. In this study, we investigate the potential of the state-of-the-art large language model (GPT-4) for planning tasks. We explore its effectiveness in multiple planning subfields, highlighting both its strengths and limitations. Through a comprehensive examination, we identify areas where large language models excel in solving planning problems and reveal the constraints that limit their applicability. Our empirical analysis focuses on GPT-4's performance in planning domain extraction, graph search path planning, and adversarial planning. We then propose a way of fine-tuning a domain-specific large language model to improve its Chain of Thought (CoT) capabilities for the above-mentioned tasks. The results provide valuable insights into the potential applications of large language models in the planning domain and pave the way for future research to overcome their limitations and expand their capabilities.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。<</SYS>>大语言模型的快速发展，如生成预训练变换器（GPT）系列，对各个领域产生了深远的影响。在这项研究中，我们研究了最新的州阶势language model（GPT-4）在规划任务中的潜力。我们探索它在多个规划子领域的效果，把握其优势和局限性。通过全面的分析，我们确定了大语言模型在解决规划问题的场景，以及它们的应用约束。我们的实验分析关注GPT-4在规划领域抽取、图搜索路径规划和反对抗规划等方面的性能。然后，我们提出了一种 fine-tuning 域特定的大语言模型来提高它的链条思维（CoT）能力，以便更好地应用于以上任务。结果提供了对大语言模型在规划领域的应用潜力和未来研究的指导。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Query-Based-Attack-against-ML-Based-Android-Malware-Detection-under-Zero-Knowledge-Setting"><a href="#Efficient-Query-Based-Attack-against-ML-Based-Android-Malware-Detection-under-Zero-Knowledge-Setting" class="headerlink" title="Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting"></a>Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01866">http://arxiv.org/abs/2309.01866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping He, Yifan Xia, Xuhong Zhang, Shouling Ji</li>
<li>for: 本研究旨在提出一种高效的查询式攻击框架，用于对基于机器学习的Android黑客检测（AMD）方法进行攻击。</li>
<li>methods: 本研究使用了一种基于零知识的查询式攻击方法，可以在各种实际场景中进行攻击。</li>
<li>results: 对多种主流的机器学习基于AMD方法和现实世界的抗病毒解决方案进行了广泛的评估，并取得了出色的成绩。<details>
<summary>Abstract</summary>
The widespread adoption of the Android operating system has made malicious Android applications an appealing target for attackers. Machine learning-based (ML-based) Android malware detection (AMD) methods are crucial in addressing this problem; however, their vulnerability to adversarial examples raises concerns. Current attacks against ML-based AMD methods demonstrate remarkable performance but rely on strong assumptions that may not be realistic in real-world scenarios, e.g., the knowledge requirements about feature space, model parameters, and training dataset. To address this limitation, we introduce AdvDroidZero, an efficient query-based attack framework against ML-based AMD methods that operates under the zero knowledge setting. Our extensive evaluation shows that AdvDroidZero is effective against various mainstream ML-based AMD methods, in particular, state-of-the-art such methods and real-world antivirus solutions.
</details>
<details>
<summary>摘要</summary>
Android 操作系统的普及使得恶意应用程序成为了袭击者的目标。基于机器学习（ML）的 Android 恶意软件检测（AMD）方法是解决这个问题的关键，但它们受到了对抗示例的攻击的担忧。现有的对 ML-based AMD 方法的攻击方法具有惊人的性能，但它们假设了可能不是实际场景中的假设，例如特征空间、模型参数和训练集的知识要求。为解决这个限制，我们介绍了 AdvDroidZero，一种基于查询的攻击框架，在零知识设定下运行。我们的广泛评估表明，AdvDroidZero 对主流 ML-based AMD 方法和实际的反病毒解决方案都具有高效性。
</details></li>
</ul>
<hr>
<h2 id="BigFUSE-Global-Context-Aware-Image-Fusion-in-Dual-View-Light-Sheet-Fluorescence-Microscopy-with-Image-Formation-Prior"><a href="#BigFUSE-Global-Context-Aware-Image-Fusion-in-Dual-View-Light-Sheet-Fluorescence-Microscopy-with-Image-Formation-Prior" class="headerlink" title="BigFUSE: Global Context-Aware Image Fusion in Dual-View Light-Sheet Fluorescence Microscopy with Image Formation Prior"></a>BigFUSE: Global Context-Aware Image Fusion in Dual-View Light-Sheet Fluorescence Microscopy with Image Formation Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01865">http://arxiv.org/abs/2309.01865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Liu, Gesine Muller, Nassir Navab, Carsten Marr, Jan Huisken, Tingying Peng</li>
<li>for: 提高LSFM图像质量，解决薄样品中光散射引起的图像模糊问题</li>
<li>methods: 使用双视图图像融合技术，根据两个视图的图像质量进行地方性比较，以确定具有高对比度的焦点 pixels</li>
<li>results: 提出了BigFUSE全局上下文感知图像融合方法，可以在LSFM中稳定图像融合，并且可以排除结构化噪声，从而提高图像质量<details>
<summary>Abstract</summary>
Light-sheet fluorescence microscopy (LSFM), a planar illumination technique that enables high-resolution imaging of samples, experiences defocused image quality caused by light scattering when photons propagate through thick tissues. To circumvent this issue, dualview imaging is helpful. It allows various sections of the specimen to be scanned ideally by viewing the sample from opposing orientations. Recent image fusion approaches can then be applied to determine in-focus pixels by comparing image qualities of two views locally and thus yield spatially inconsistent focus measures due to their limited field-of-view. Here, we propose BigFUSE, a global context-aware image fuser that stabilizes image fusion in LSFM by considering the global impact of photon propagation in the specimen while determining focus-defocus based on local image qualities. Inspired by the image formation prior in dual-view LSFM, image fusion is considered as estimating a focus-defocus boundary using Bayes Theorem, where (i) the effect of light scattering onto focus measures is included within Likelihood; and (ii) the spatial consistency regarding focus-defocus is imposed in Prior. The expectation-maximum algorithm is then adopted to estimate the focus-defocus boundary. Competitive experimental results show that BigFUSE is the first dual-view LSFM fuser that is able to exclude structured artifacts when fusing information, highlighting its abilities of automatic image fusion.
</details>
<details>
<summary>摘要</summary>
光Sheet fluorescence微scopía（LSFM），一种平面照明技术，可以实现高分辨率图像的取得，但光子在厚度的样本中传播时会导致图像模糊。为了解决这问题，双视图成像是有帮助的。它可以在不同的方向上扫描样本，从而实现不同部分的样本的高分辨率扫描。然而，当应用最新的图像融合方法时，由于其有限的场景视野，会导致图像融合失真。在这种情况下，我们提出了BigFUSE，一种全局上下文认知的图像融合器，可以在LSFM中稳定图像融合，并且考虑了光子在样本中的全局影响。通过对本地图像质量进行比较，BigFUSE可以计算出各个像素的封闭度，并且通过 bayes定理来确定注重点。在应用期望最大算法时，BigFUSE可以优先地除掉结构化遗憾。实验结果表明，BigFUSE是第一个可以自动执行图像融合的双视图LSFM融合器。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/05/cs.AI_2023_09_05/" data-id="clmvt7t7k003h26rdbxkfhr39" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/05/cs.CL_2023_09_05/" class="article-date">
  <time datetime="2023-09-05T11:00:00.000Z" itemprop="datePublished">2023-09-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/05/cs.CL_2023_09_05/">cs.CL - 2023-09-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Scaling-Autoregressive-Multi-Modal-Models-Pretraining-and-Instruction-Tuning"><a href="#Scaling-Autoregressive-Multi-Modal-Models-Pretraining-and-Instruction-Tuning" class="headerlink" title="Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning"></a>Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02591">http://arxiv.org/abs/2309.02591</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kyegomez/CM3Leon">https://github.com/kyegomez/CM3Leon</a></li>
<li>paper_authors: Lili Yu, Bowen Shi, Ramakanth Pasunuru, Benjamin Muller, Olga Golovneva, Tianlu Wang, Arun Babu, Binh Tang, Brian Karrer, Shelly Sheynin, Candace Ross, Adam Polyak, Russell Howes, Vasu Sharma, Puxin Xu, Hovhannes Tamoyan, Oron Ashual, Uriel Singer, Shang-Wen Li, Susan Zhang, Richard James, Gargi Ghosh, Yaniv Taigman, Maryam Fazel-Zarandi, Asli Celikyilmaz, Luke Zettlemoyer, Armen Aghajanyan</li>
<li>for: 这篇论文是为了描述一种基于多模态语言模型的文本和图像生成模型CM3Leon，以及该模型在不同任务上的性能。</li>
<li>methods: 该模型使用了CM3多模态架构，并在大规模的采集和调参数数据上进行了扩展和优化。它还包括一个大规模的预训练阶段和一个多任务练熟环境（SFT）阶段。</li>
<li>results: 实验结果显示，这种方法对多模态模型是非常有效的，CM3Leon在文本到图像生成任务中达到了状态对的性能（FID&#x3D;4.88），并且在语言指导图像编辑、图像控制生成和分割等任务中也可以达到了不可思议的水平。<details>
<summary>Abstract</summary>
We present CM3Leon (pronounced "Chameleon"), a retrieval-augmented, token-based, decoder-only multi-modal language model capable of generating and infilling both text and images. CM3Leon uses the CM3 multi-modal architecture but additionally shows the extreme benefits of scaling up and tuning on more diverse instruction-style data. It is the first multi-modal model trained with a recipe adapted from text-only language models, including a large-scale retrieval-augmented pre-training stage and a second multi-task supervised fine-tuning (SFT) stage. It is also a general-purpose model that can do both text-to-image and image-to-text generation, allowing us to introduce self-contained contrastive decoding methods that produce high-quality outputs. Extensive experiments demonstrate that this recipe is highly effective for multi-modal models. CM3Leon achieves state-of-the-art performance in text-to-image generation with 5x less training compute than comparable methods (zero-shot MS-COCO FID of 4.88). After SFT, CM3Leon can also demonstrate unprecedented levels of controllability in tasks ranging from language-guided image editing to image-controlled generation and segmentation.
</details>
<details>
<summary>摘要</summary>
我们提出CM3Leon（发音为“卡美伦”），这是一个基于搜索修正的、符号基于的解码器只多模态语言模型，可以生成和填充文本和图像。CM3Leon使用CM3多模态架构，但还有更加极端的优势，来自更多的指令样式数据的扩大和调整。它是首个基于文本only语言模型的多模态模型，通过一个大规模的搜索修正预训练阶段和第二个多任务监督练练（SFT）阶段进行训练。它还是一个通用的模型，可以进行文本到图像和图像到文本的生成，allowing us to introduce self-contained contrastive decoding methods that produce high-quality outputs。广泛的实验表明，这种方法对多模态模型非常有效。CM3Leon在文本到图像生成中达到了比较方法的状态机器（零shot MS-COCO FID of 4.88）。在SFT后，CM3Leon也可以展示无 precedent的可控性，从语言引导的图像修改到图像控制生成和分割。
</details></li>
</ul>
<hr>
<h2 id="Substitution-based-Semantic-Change-Detection-using-Contextual-Embeddings"><a href="#Substitution-based-Semantic-Change-Detection-using-Contextual-Embeddings" class="headerlink" title="Substitution-based Semantic Change Detection using Contextual Embeddings"></a>Substitution-based Semantic Change Detection using Contextual Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02403">http://arxiv.org/abs/2309.02403</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dallascard/SBSCD">https://github.com/dallascard/SBSCD</a></li>
<li>paper_authors: Dallas Card</li>
<li>for: 本研究旨在使用上下文嵌入来度量语义变化，并且提出了一种简单有效的方法，以优化现有的方法。</li>
<li>methods: 本研究使用最有可能的替换词来度量语义变化，这种方法不仅直观可解，而且更有效率，可以更好地探讨语义变化。</li>
<li>results: 本研究在最常引用的数据集上达到了最高的均值性能，并且可以更好地探讨语义变化，比静止词vec更有利于理解语义变化。<details>
<summary>Abstract</summary>
Measuring semantic change has thus far remained a task where methods using contextual embeddings have struggled to improve upon simpler techniques relying only on static word vectors. Moreover, many of the previously proposed approaches suffer from downsides related to scalability and ease of interpretation. We present a simplified approach to measuring semantic change using contextual embeddings, relying only on the most probable substitutes for masked terms. Not only is this approach directly interpretable, it is also far more efficient in terms of storage, achieves superior average performance across the most frequently cited datasets for this task, and allows for more nuanced investigation of change than is possible with static word vectors.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="nanoT5-A-PyTorch-Framework-for-Pre-training-and-Fine-tuning-T5-style-Models-with-Limited-Resources"><a href="#nanoT5-A-PyTorch-Framework-for-Pre-training-and-Fine-tuning-T5-style-Models-with-Limited-Resources" class="headerlink" title="nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style Models with Limited Resources"></a>nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style Models with Limited Resources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02373">http://arxiv.org/abs/2309.02373</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/piotrnawrot/nanot5">https://github.com/piotrnawrot/nanot5</a></li>
<li>paper_authors: Piotr Nawrot</li>
<li>for: 提高语言模型研究的可用性和资源利用率，使更多研究者能够访问和使用T5模型。</li>
<li>methods: 通过优化PyTorch框架和优化器，实现高效的T5模型预训练和精度调整，以及开源框架和配置等资源的提供，旨在拓宽语言模型研究领域的可用性和资源利用率。</li>
<li>results: 在单个GPU上预训练T5-Base模型只需16个小时，不会影响性能，并提供了多种配置和软硬件准则，以及开源框架和预训练模型，以满足研究者对T5模型的需求。<details>
<summary>Abstract</summary>
State-of-the-art language models like T5 have revolutionized the NLP landscape, but their computational demands hinder a large portion of the research community. To address this challenge, we present nanoT5, a specially-optimized PyTorch framework for efficient pre-training and fine-tuning of T5 models. Drawing on insights from optimizer differences and prioritizing efficiency, nanoT5 allows a T5-Base model to be pre-trained on a single GPU in just 16 hours, without any loss in performance. With the introduction of this open-source framework, we hope to widen the accessibility to language modelling research and cater to the community's demand for more user-friendly T5 (Encoder-Decoder) implementations. Our contributions, including configurations, codebase, software/hardware insights, and pre-trained models, are available to the public, aiming to strike a balance between research accessibility and resource constraints in NLP.
</details>
<details>
<summary>摘要</summary>
现代语言模型如T5已经革命化了NLPT中的景象，但它们的计算需求限制了大量研究人员。为解决这个挑战，我们现在提出nanoT5，一个特殊优化的PyTorch框架，用于高效地预训练和精度调整T5模型。通过优化器差异和高效性的启发，nanoT5可以在单个GPU上预训练T5-Base模型，只需16个小时，而无损失性表现。我们通过这个开源框架，希望扩大语言模型研究的访问权限，并为NLPT社区提供更加用户友好的T5（Encoder-Decoder）实现。我们的贡献包括配置、代码库、软硬件杂志和预训练模型，都对公众开放，以实现NLPT研究资源的平衡。
</details></li>
</ul>
<hr>
<h2 id="Weigh-Your-Own-Words-Improving-Hate-Speech-Counter-Narrative-Generation-via-Attention-Regularization"><a href="#Weigh-Your-Own-Words-Improving-Hate-Speech-Counter-Narrative-Generation-via-Attention-Regularization" class="headerlink" title="Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation via Attention Regularization"></a>Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation via Attention Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02311">http://arxiv.org/abs/2309.02311</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/milanlproc/weigh-your-own-words">https://github.com/milanlproc/weigh-your-own-words</a></li>
<li>paper_authors: Helena Bonaldi, Giuseppe Attanasio, Debora Nozza, Marco Guerini</li>
<li>for: 防止在线仇恨言语的发展，提出了一种基于预训练语言模型（PLMs）的自动生成对话方法。</li>
<li>methods: 本研究使用了一种基于注意力的违规常量来改进PLMs的泛化能力，以便在不同的目标和实际垃圾语言上生成更加多样化和更加丰富的对话。</li>
<li>results: 对英语 benchmark 数据集进行实验表明，使用了注意力违规常量的改进方法可以生成更好的对话，特别是在训练数据中不包含仇恨目标时。<details>
<summary>Abstract</summary>
Recent computational approaches for combating online hate speech involve the automatic generation of counter narratives by adapting Pretrained Transformer-based Language Models (PLMs) with human-curated data. This process, however, can produce in-domain overfitting, resulting in models generating acceptable narratives only for hatred similar to training data, with little portability to other targets or to real-world toxic language. This paper introduces novel attention regularization methodologies to improve the generalization capabilities of PLMs for counter narratives generation. Overfitting to training-specific terms is then discouraged, resulting in more diverse and richer narratives. We experiment with two attention-based regularization techniques on a benchmark English dataset. Regularized models produce better counter narratives than state-of-the-art approaches in most cases, both in terms of automatic metrics and human evaluation, especially when hateful targets are not present in the training data. This work paves the way for better and more flexible counter-speech generation models, a task for which datasets are highly challenging to produce.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:近期计算方法对于在线仇恨言语的应对包括使用预训练的变换器基于语言模型（PLMs）自动生成反对narritives。然而，这个过程可能会导致域内过拟合，使模型只能生成与训练数据相似的acceptable narritives，具有小的可移植性到其他目标或实际世界中的恶语言。本文提出了一种新的注意力规范方法来提高PLMs的泛化能力 для反对narritives生成。通过避免训练数据特定的注意力过拟合，模型可以生成更多元和更加丰富的narritives。我们在一个英语 benchmark 数据集上实验了两种注意力基于规范技术，并发现正则化模型在大多数情况下可以生成更好的反对narritives，特别是当仇恨目标不在训练数据中时。这项工作为Counter-speech生成模型的更好和更灵活的模型开创了道路，这个任务的数据非常困难生产。
</details></li>
</ul>
<hr>
<h2 id="PromptTTS-2-Describing-and-Generating-Voices-with-Text-Prompt"><a href="#PromptTTS-2-Describing-and-Generating-Voices-with-Text-Prompt" class="headerlink" title="PromptTTS 2: Describing and Generating Voices with Text Prompt"></a>PromptTTS 2: Describing and Generating Voices with Text Prompt</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02285">http://arxiv.org/abs/2309.02285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichong Leng, Zhifang Guo, Kai Shen, Xu Tan, Zeqian Ju, Yanqing Liu, Yufei Liu, Dongchao Yang, Leying Zhang, Kaitao Song, Lei He, Xiang-Yang Li, Sheng Zhao, Tao Qin, Jiang Bian</li>
<li>for: 这个研究是为了解决基于文本提示的语音生成方法中的一个问题，即使用文本提示来生成语音时，不能完全捕捉语音中的声音变化信息。</li>
<li>methods: 这个研究使用了一种变换网络，该网络可以根据文本提示来预测语音中的声音变化信息，以及一个提取ipeline，该ipeline可以使用语音理解模型来识别语音中的声音特征（例如性别、速度等），并使用大型自然语言处理模型来形成文本提示。</li>
<li>results: 实验结果表明，与前一代方法相比，PromptTTS 2可以更好地根据文本提示生成语音，并且支持采样多种语音变化，因此可以为用户提供更多的语音选择。此外，提取ipeline可以生成高质量的文本提示，从而消除大量的标注成本。<details>
<summary>Abstract</summary>
Speech conveys more information than just text, as the same word can be uttered in various voices to convey diverse information. Compared to traditional text-to-speech (TTS) methods relying on speech prompts (reference speech) for voice variability, using text prompts (descriptions) is more user-friendly since speech prompts can be hard to find or may not exist at all. TTS approaches based on the text prompt face two challenges: 1) the one-to-many problem, where not all details about voice variability can be described in the text prompt, and 2) the limited availability of text prompt datasets, where vendors and large cost of data labeling are required to write text prompt for speech. In this work, we introduce PromptTTS 2 to address these challenges with a variation network to provide variability information of voice not captured by text prompts, and a prompt generation pipeline to utilize the large language models (LLM) to compose high quality text prompts. Specifically, the variation network predicts the representation extracted from the reference speech (which contains full information about voice) based on the text prompt representation. For the prompt generation pipeline, it generates text prompts for speech with a speech understanding model to recognize voice attributes (e.g., gender, speed) from speech and a large language model to formulate text prompt based on the recognition results. Experiments on a large-scale (44K hours) speech dataset demonstrate that compared to the previous works, PromptTTS 2 generates voices more consistent with text prompts and supports the sampling of diverse voice variability, thereby offering users more choices on voice generation. Additionally, the prompt generation pipeline produces high-quality prompts, eliminating the large labeling cost. The demo page of PromptTTS 2 is available online\footnote{https://speechresearch.github.io/prompttts2}.
</details>
<details>
<summary>摘要</summary>
文本中的语音包含更多信息，因为同一个词可以在不同的声音下被读出，表达多种信息。相比传统的文本识别（TTS）方法，利用语音提示（参考语音）来实现声音多样性，使用文本提示（描述）更加用户友好，因为语音提示可能困难找或者不存在。TTS方法基于文本提示面临两个挑战：1）一个多个问题，即文本提示中不能完全表达声音多样性的细节信息；2）文本提示数据集的有限性，需要供应商和大量的数据标注来编写文本提示。在这项工作中，我们介绍PromptTTS 2，以解决这两个挑战。PromptTTS 2使用变化网络提供不同声音的多样性信息，并使用大语言模型（LLM）组合高质量文本提示来生成语音。具体来说，变化网络预测基于参考语音（含有全部声音信息）的表示，根据文本提示表示。为生成文本提示，我们使用语音理解模型认识语音特征（例如性别、速度），并使用大语言模型根据认识结果组合文本提示。实验表明，Compared to previous works，PromptTTS 2可以更好地根据文本提示生成声音，并支持采样多样的声音选择。此外，提示生成管道可以生成高质量的提示，减少大量标注成本。PromptTTS 2的demo页面可以在线查看\footnotesize{\url{https://speechresearch.github.io/prompttts2}.
</details></li>
</ul>
<hr>
<h2 id="Dialog-Action-Aware-Transformer-for-Dialog-Policy-Learning"><a href="#Dialog-Action-Aware-Transformer-for-Dialog-Policy-Learning" class="headerlink" title="Dialog Action-Aware Transformer for Dialog Policy Learning"></a>Dialog Action-Aware Transformer for Dialog Policy Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02240">http://arxiv.org/abs/2309.02240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huimin Wang, Wai-Chung Kwan, Kam-Fai Wong</li>
<li>for: 这个研究旨在提高对话策略学习（Dialog Policy Learning，DPL）的效率，使用对话数据来增强RL代理人的学习速度。</li>
<li>methods: 本研究提出了一个叫做“对话动作意识”的对话动作批评（DaTrans），该批评通过一个新的调整程序“对话最后一个动作任务”来增强DaTrans的对话意识和动作特征。</li>
<li>results: 研究结果显示，这个方法可以快速地将RL代理人带到最佳的对话策略，并且在人类评价中得到了良好的评价。<details>
<summary>Abstract</summary>
Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action. However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent's learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distils action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.
</details>
<details>
<summary>摘要</summary>
现代工作通常采用对话策略学习（Dialog Policy Learning，DPL），通过训练一个强化学习（Reinforcement Learning，RL）代理人来确定最佳对话动作。然而，现有的深度RL需要大量的代理人-用户互动来 достичьacceptable的性能。在这篇论文中，我们提议利用预先训练的自然语言模型的普通文本知识，以加速RL代理人的学习速度。特别是，我们设计了对话动作意识的 transformer 编码器（DaTrans），通过一种新的精细调整过程名为遮盖最后一个动作任务来鼓励 DaTrans 成为对话意识的。然后，DaTrans 在RL Setting中进行了进一步优化，通过在对话动作空间中的探索来最大化长期积累的奖励。我们通过 simulate 评估和人类评估来证明提案的效果和效率。
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Dictionaries-into-a-Neural-Network-Architecture-to-Extract-COVID-19-Medical-Concepts-From-Social-Media"><a href="#Incorporating-Dictionaries-into-a-Neural-Network-Architecture-to-Extract-COVID-19-Medical-Concepts-From-Social-Media" class="headerlink" title="Incorporating Dictionaries into a Neural Network Architecture to Extract COVID-19 Medical Concepts From Social Media"></a>Incorporating Dictionaries into a Neural Network Architecture to Extract COVID-19 Medical Concepts From Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02188">http://arxiv.org/abs/2309.02188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abul Hasan, Mark Levene, David Weston</li>
<li>for: 这研究探讨了将字典信息 integrate into neural network architecture for natural language processing的可能性。</li>
<li>methods: 这研究使用了一种基于字典的深度学习模型，用于提取COVID-19相关的概念。</li>
<li>results: 研究结果显示，将小领域字典 integrate into深度学习模型可以提高概念提取任务的性能，并且这些模型可以在不同数据集上进行转移。<details>
<summary>Abstract</summary>
We investigate the potential benefit of incorporating dictionary information into a neural network architecture for natural language processing. In particular, we make use of this architecture to extract several concepts related to COVID-19 from an on-line medical forum. We use a sample from the forum to manually curate one dictionary for each concept. In addition, we use MetaMap, which is a tool for extracting biomedical concepts, to identify a small number of semantic concepts. For a supervised concept extraction task on the forum data, our best model achieved a macro $F_1$ score of 90\%. A major difficulty in medical concept extraction is obtaining labelled data from which to build supervised models. We investigate the utility of our models to transfer to data derived from a different source in two ways. First for producing labels via weak learning and second to perform concept extraction. The dataset we use in this case comprises COVID-19 related tweets and we achieve an $F_1$ score 81\% for symptom concept extraction trained on weakly labelled data. The utility of our dictionaries is compared with a COVID-19 symptom dictionary that was constructed directly from Twitter. Further experiments that incorporate BERT and a COVID-19 version of BERTweet demonstrate that the dictionaries provide a commensurate result. Our results show that incorporating small domain dictionaries to deep learning models can improve concept extraction tasks. Moreover, models built using dictionaries generalize well and are transferable to different datasets on a similar task.
</details>
<details>
<summary>摘要</summary>
我们研究将词典信息 integrate into neural network architecture for natural language processing的潜在优点。特别是我们使用这种架构提取COVID-19相关概念从在线医学讨论区。我们使用样本从讨论区手动精心抽取一个词典 для每个概念。此外，我们使用MetaMap工具提取生物医学概念，以确定一些semantic概念。对于基于讨论区数据的抽象概念提取任务，我们的最佳模型达到了90%的macro $F_1$ 分数。医疗概念提取的主要挑战之一是获得可靠的标签数据，用于建立supervised模型。我们研究将我们的模型传输到不同来源数据上进行两种方式。第一种是通过弱学习生成标签，第二种是进行概念提取。我们使用COVID-19相关推特来构建数据集，并实现了基于弱标签的概念提取Task中的81%的$F_1$ 分数。我们的词典与直接从Twitter中构建的COVID-19症状词典进行比较。进一步的实验表明，我们的词典提供了相似的结果。我们的结果表明，将小域词典 integrate into深度学习模型可以提高概念提取任务的性能。此外，使用词典建立的模型具有良好的泛化能力和可传播性。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Text-to-GLOSS-Neural-Translation-Using-a-Novel-Hyper-parameter-Optimization-Technique"><a href="#Advancing-Text-to-GLOSS-Neural-Translation-Using-a-Novel-Hyper-parameter-Optimization-Technique" class="headerlink" title="Advancing Text-to-GLOSS Neural Translation Using a Novel Hyper-parameter Optimization Technique"></a>Advancing Text-to-GLOSS Neural Translation Using a Novel Hyper-parameter Optimization Technique</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02162">http://arxiv.org/abs/2309.02162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Younes Ouargani, Noussaima El Khattabi</li>
<li>for: 这paper是 investigate transformers for Neural Machine Translation of text-to-GLOSS, 用于提高Deaf和听力不良的通信中的GLOSS翻译的精度和流畅性。</li>
<li>methods: 这paper使用了一种新的超参数搜索技术，搜索了不同的架构参数，并构建了一个优化的 transformer-based 架构，特意适用于text-to-GLOSS翻译任务。</li>
<li>results: 实验结果表明，最佳的 transformer 架构在 PHOENIX14T 数据集上达到了 ROUGE 分数55.18% 和 BLEU-1 分数63.6%，超过了之前在同一数据集上的最佳结果，升级了 BLEU1 和 ROUGE 分数的状态之作。<details>
<summary>Abstract</summary>
In this paper, we investigate the use of transformers for Neural Machine Translation of text-to-GLOSS for Deaf and Hard-of-Hearing communication. Due to the scarcity of available data and limited resources for text-to-GLOSS translation, we treat the problem as a low-resource language task. We use our novel hyper-parameter exploration technique to explore a variety of architectural parameters and build an optimal transformer-based architecture specifically tailored for text-to-GLOSS translation. The study aims to improve the accuracy and fluency of Neural Machine Translation generated GLOSS. This is achieved by examining various architectural parameters including layer count, attention heads, embedding dimension, dropout, and label smoothing to identify the optimal architecture for improving text-to-GLOSS translation performance. The experiments conducted on the PHOENIX14T dataset reveal that the optimal transformer architecture outperforms previous work on the same dataset. The best model reaches a ROUGE (Recall-Oriented Understudy for Gisting Evaluation) score of 55.18% and a BLEU-1 (BiLingual Evaluation Understudy 1) score of 63.6%, outperforming state-of-the-art results on the BLEU1 and ROUGE score by 8.42 and 0.63 respectively.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究使用变换器来进行神经机器翻译文本到GLOSS，以便为听力异常和耳聋人士进行交流。由于文本到GLOSS翻译数据的稀缺和限制了资源，我们将这个问题视为低资源语言任务。我们使用我们的新的 гипер参数探索技术来探索各种建筑 Parameters，并构建一个优化的变换器基础结构，专门适用于文本到GLOSS翻译。研究的目的是提高神经机器翻译生成的GLOSS的准确率和流畅度。我们通过检查层数、注意头数、嵌入维度、dropout和标签平滑来确定优化文本到GLOSS翻译性能的最佳建筑 Parameters。在PHOENIX14T数据集上进行的实验表明，优化的变换器结构可以超越之前在同一数据集上的成果。最佳模型在ROUGE（Recall-Oriented Understudy for Gisting Evaluation）分数上达到55.18%，并在BLEU-1（BiLingual Evaluation Understudy 1）分数上达到63.6%，超越了当前的BLEU1和ROUGE分数的状态态度。
</details></li>
</ul>
<hr>
<h2 id="Bring-the-Noise-Introducing-Noise-Robustness-to-Pretrained-Automatic-Speech-Recognition"><a href="#Bring-the-Noise-Introducing-Noise-Robustness-to-Pretrained-Automatic-Speech-Recognition" class="headerlink" title="Bring the Noise: Introducing Noise Robustness to Pretrained Automatic Speech Recognition"></a>Bring the Noise: Introducing Noise Robustness to Pretrained Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02145">http://arxiv.org/abs/2309.02145</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Eickhoff, Matthias Möller, Theresa Pekarek Rosin, Johannes Twiefel, Stefan Wermter</li>
<li>for: 这研究旨在提高自动语音识别（ASR）系统的性能，特别是在听力条件不佳的情况下。</li>
<li>methods: 我们提出了一种新的方法，可以将大型端到端（E2E）模型中的干净能力提取出来，并将其应用于任何encoder-decoder架构。我们的方法基于Conformer ASR模型的隐藏活动，通过一个decoder来预测干净spectrogram。</li>
<li>results: 我们的模型可以成功地过滤听力条件下的噪音，并且可以提高下游模型在噪音条件下的总词错率（WER）。我们的模型可以作为前端应用于预训练的Conformer ASR模型，以及从头开始训练小型Conformer ASR模型。<details>
<summary>Abstract</summary>
In recent research, in the domain of speech processing, large End-to-End (E2E) systems for Automatic Speech Recognition (ASR) have reported state-of-the-art performance on various benchmarks. These systems intrinsically learn how to handle and remove noise conditions from speech. Previous research has shown, that it is possible to extract the denoising capabilities of these models into a preprocessor network, which can be used as a frontend for downstream ASR models. However, the proposed methods were limited to specific fully convolutional architectures. In this work, we propose a novel method to extract the denoising capabilities, that can be applied to any encoder-decoder architecture. We propose the Cleancoder preprocessor architecture that extracts hidden activations from the Conformer ASR model and feeds them to a decoder to predict denoised spectrograms. We train our pre-processor on the Noisy Speech Database (NSD) to reconstruct denoised spectrograms from noisy inputs. Then, we evaluate our model as a frontend to a pretrained Conformer ASR model as well as a frontend to train smaller Conformer ASR models from scratch. We show that the Cleancoder is able to filter noise from speech and that it improves the total Word Error Rate (WER) of the downstream model in noisy conditions for both applications.
</details>
<details>
<summary>摘要</summary>
Recent research in speech processing has shown that large End-to-End (E2E) systems for Automatic Speech Recognition (ASR) have achieved state-of-the-art performance on various benchmarks. These systems have the ability to intrinsically handle and remove noise from speech. Previous studies have demonstrated that the denoising capabilities of these models can be extracted and used as a frontend for downstream ASR models. However, these methods were limited to specific fully convolutional architectures.In this study, we propose a novel method to extract the denoising capabilities that can be applied to any encoder-decoder architecture. We introduce the Cleancoder preprocessor architecture, which extracts hidden activations from the Conformer ASR model and feeds them to a decoder to predict denoised spectrograms. We train our pre-processor on the Noisy Speech Database (NSD) to reconstruct denoised spectrograms from noisy inputs.We evaluate our model as a frontend to a pretrained Conformer ASR model as well as a frontend to train smaller Conformer ASR models from scratch. Our results show that the Cleancoder is able to filter noise from speech and improve the total Word Error Rate (WER) of the downstream model in noisy conditions for both applications.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Methods-for-Ground-Truth-Free-Foreign-Accent-Conversion"><a href="#Evaluating-Methods-for-Ground-Truth-Free-Foreign-Accent-Conversion" class="headerlink" title="Evaluating Methods for Ground-Truth-Free Foreign Accent Conversion"></a>Evaluating Methods for Ground-Truth-Free Foreign Accent Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02133">http://arxiv.org/abs/2309.02133</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/unilight/seq2seq-vc">https://github.com/unilight/seq2seq-vc</a></li>
<li>paper_authors: Wen-Chin Huang, Tomoki Toda</li>
<li>For: 本研究旨在评估三种最近提出的无ground truth基础的外语变换方法（FAC），以实现将非本地语言speaker的语音转换为本地语言speaker的语音，同时保持speaker identity。* Methods: 本研究使用的方法包括seq2seq和非并行的VC模型，以实现控制speaker identity和降低外语变换的困难性。* Results: 我们的实验评估结果显示，无一个方法在所有评估轴上表现出色，与之前的研究结论不同。我们还分析了seq2seq模型的训练输入和输出，以及非并行VC模型的设计选择，并发现Intelligibility指标与主观外语程度之间没有直接关系。<details>
<summary>Abstract</summary>
Foreign accent conversion (FAC) is a special application of voice conversion (VC) which aims to convert the accented speech of a non-native speaker to a native-sounding speech with the same speaker identity. FAC is difficult since the native speech from the desired non-native speaker to be used as the training target is impossible to collect. In this work, we evaluate three recently proposed methods for ground-truth-free FAC, where all of them aim to harness the power of sequence-to-sequence (seq2seq) and non-parallel VC models to properly convert the accent and control the speaker identity. Our experimental evaluation results show that no single method was significantly better than the others in all evaluation axes, which is in contrast to conclusions drawn in previous studies. We also explain the effectiveness of these methods with the training input and output of the seq2seq model and examine the design choice of the non-parallel VC model, and show that intelligibility measures such as word error rates do not correlate well with subjective accentedness. Finally, our implementation is open-sourced to promote reproducible research and help future researchers improve upon the compared systems.
</details>
<details>
<summary>摘要</summary>
外国腔转换（FAC）是voice转换（VC）的特殊应用，旨在将非本地语言 speaker的折衣语音转换为本地语言 speaker的Native-sounding speech，同时保持 speaker identity。FAC具有困难，因为不可收集欲使用的Native speech from the desired non-native speaker作为训练目标。在这项工作中，我们评估了三种最近提出的ground-truth-free FAC方法，其中所有方法均企图利用 seq2seq和non-parallel VC模型来正确地转换腔和控制 speaker identity。我们的实验评估结果表明，没有任何方法在所有评估轴上表现出显著优势，这与之前的研究结论不符。我们还解释了这些方法的效iveness，并检查了seq2seq模型的训练输入和输出，以及非平行VC模型的设计选择。最后，我们发现Intelligibility measure如word error rates与主观腔度之间没有正确的相关性。 finally,我们开源了我们的实现，以便促进可重复性的研究和未来的研究人员可以在此基础上改进相关的系统。
</details></li>
</ul>
<hr>
<h2 id="Wordle-A-Microcosm-of-Life-Luck-Skill-Cheating-Loyalty-and-Influence"><a href="#Wordle-A-Microcosm-of-Life-Luck-Skill-Cheating-Loyalty-and-Influence" class="headerlink" title="Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and Influence!"></a>Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and Influence!</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02110">http://arxiv.org/abs/2309.02110</a></li>
<li>repo_url: None</li>
<li>paper_authors: James P. Dilger</li>
<li>for: 这个研究是为了研究Wordle游戏中玩家的做法和习惯。</li>
<li>methods: 这个研究使用了信息理论来评估玩家的幸运和技巧，并将数据显示在Wordle游戏中的第一、第二、…、第六个猜测中。</li>
<li>results: 研究发现每天约有0.2-0.5%的玩家在第一次猜测中解题成功，这意味着4,000-10,000名玩家可能通过外部获取目标词语来夺冠。此外，研究还发现至少1&#x2F;3的玩家有一个喜爱的开头词，而且大多数玩家会保持loyal于他们的开头词，即使该词语已经出现过。8月15日，约有30,000名玩家突然改变了他们的开头词，这可能是基于十字WORD的游戏提示。<details>
<summary>Abstract</summary>
Wordle is a popular, online word game offered by the New York Times (nytimes.com). Currently there are some 2 million players of the English version worldwide. Players have 6 attempts to guess the daily word (target word) and after each attempt, the player receives color-coded information about the correctness and position of each letter in the guess. After either a successful completion of the puzzle or the final unsuccessful attempt, software can assess the player's luck and skill using Information Theory and can display data for the first, second, ..., sixth guesses of a random sample of all players. Recently, I discovered that the latter data is presented in a format that can easily be copied and pasted into a spreadsheet. I compiled data on Wordle players' first guesses from May 2023 - August 2023 and inferred some interesting information about Wordle players. A) Every day, about 0.2-0.5% of players solve the puzzle in one attempt. Because the odds of guessing the one of 2,315 possible target words at random is 0.043%, this implies that 4,000 - 10,000 players cheat by obtaining the target word outside of playing the game! B) At least 1/3 of the players have a favorite starting word, or cycle through several. And even though players should be aware that target words are never repeated, most players appear to remain loyal to their starting word even after its appearance as a target word. C) On August 15, 2023, about 30,000 players abruptly changed their starting word, presumably based on a crossword puzzle clue! Wordle players can be influenced! This study goes beyond social media postings, surveys, and Google Trends to provide solid, quantitative evidence about cheating in Wordle.
</details>
<details>
<summary>摘要</summary>
wordle是一款受欢迎的在线单词游戏，提供于纽约时报（nytimes.com）上。目前全球玩家约200万人。玩家有6次尝试猜测每天的目标词（target word），每次猜测后，玩家会收到颜色标注的正确性和位置信息。完成游戏或最后一次无法猜测后，软件可以根据信息理论评估玩家的运气和技巧，并显示数据 для第一、第二、...、第六次猜测的随机样本玩家。我最近发现这些数据可以轻松地复制并粘贴到表格中。我 compile了5月2023年-8月2023年的Wordle玩家首次猜测数据，并从中推导出了一些有趣的信息。A) 每天大约0.2%-0.5%的玩家在第一次猜测中解题成功。由于随机猜测target word的概率为0.043%，这 imply That 4,000-10,000名玩家通过外部方式获得target word！B) 至少1/3的玩家有一个喜爱的开始词，或者循环使用多个。尽管玩家应该知道target words never repeated，但大多数玩家仍然偏向自己的开始词，即使该词已经出现在目标词中。C) 2023年8月15日，约30,000名玩家 suddenly changed their starting word， apparently based on a crossword puzzle clue! Wordle players can be influenced！这项研究超过社交媒体帖子、调查和Google Trends提供的轻量级证据，以准确的数据证明Wordle玩家的作弊行为。
</details></li>
</ul>
<hr>
<h2 id="Bridging-Emotion-Role-Labeling-and-Appraisal-based-Emotion-Analysis"><a href="#Bridging-Emotion-Role-Labeling-and-Appraisal-based-Emotion-Analysis" class="headerlink" title="Bridging Emotion Role Labeling and Appraisal-based Emotion Analysis"></a>Bridging Emotion Role Labeling and Appraisal-based Emotion Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02092">http://arxiv.org/abs/2309.02092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roman Klinger</li>
<li>for: 本研究旨在探讨情感分析在文本中的应用，具体来说是情感分类和情感角色标注两个方面。</li>
<li>methods: 本研究使用了多种自然语言处理技术，包括情感分类和情感角色标注等。</li>
<li>results: 研究发现了情感分类和情感角色标注两个方面的问题，并提出了一些未解决的研究问题。<details>
<summary>Abstract</summary>
The term emotion analysis in text subsumes various natural language processing tasks which have in common the goal to enable computers to understand emotions. Most popular is emotion classification in which one or multiple emotions are assigned to a predefined textual unit. While such setting is appropriate to identify the reader's or author's emotion, emotion role labeling adds the perspective of mentioned entities and extracts text spans that correspond to the emotion cause. The underlying emotion theories agree on one important point; that an emotion is caused by some internal or external event and comprises several subcomponents, including the subjective feeling and a cognitive evaluation. We therefore argue that emotions and events are related in two ways. (1) Emotions are events; and this perspective is the fundament in NLP for emotion role labeling. (2) Emotions are caused by events; a perspective that is made explicit with research how to incorporate psychological appraisal theories in NLP models to interpret events. These two research directions, role labeling and (event-focused) emotion classification, have by and large been tackled separately. We contributed to both directions with the projects SEAT (Structured Multi-Domain Emotion Analysis from Text) and CEAT (Computational Event Evaluation based on Appraisal Theories for Emotion Analysis), both funded by the German Research Foundation. In this paper, we consolidate the findings and point out open research questions.
</details>
<details>
<summary>摘要</summary>
“情感分析”是一种自然语言处理任务的总称，它的目的是让计算机理解人类的情感。最受欢迎的是情感分类，在这种设定下，一个或多个情感被分配给已知文本单位。而情感角色标注则添加了提及对象的视角，并提取与情感相关的文本块。在情感理论中，所有情感都是由内部或外部事件引起的，并包括一些主观感受和认知评价。因此，我们认为情感和事件之间存在两种关系。第一种是情感是事件的角度，这是NP的基础。第二种是情感是由事件引起的，这种角度通过涉及心理评价理论来在NP模型中表示。这两个研究方向一直处理了分开，我们通过项目《SEAT》（结构多元领域情感分析从文本）和《CEAT》（基于评价理论的计算事件评价为情感分析），均得到了德国研究基金的资金支持。在这篇论文中，我们汇总了发现和提出了未来研究的问题。
</details></li>
</ul>
<hr>
<h2 id="An-Automatic-Evaluation-Framework-for-Multi-turn-Medical-Consultations-Capabilities-of-Large-Language-Models"><a href="#An-Automatic-Evaluation-Framework-for-Multi-turn-Medical-Consultations-Capabilities-of-Large-Language-Models" class="headerlink" title="An Automatic Evaluation Framework for Multi-turn Medical Consultations Capabilities of Large Language Models"></a>An Automatic Evaluation Framework for Multi-turn Medical Consultations Capabilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02077">http://arxiv.org/abs/2309.02077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusheng Liao, Yutong Meng, Hongcheng Liu, Yanfeng Wang, Yu Wang</li>
<li>for: 这篇论文旨在评估大语言模型（LLMs）在虚拟医生环境中的实际能力。</li>
<li>methods: 该论文提出了一种自动评估框架，用于评估 LLMs 在多turn 询问中的实际能力。该框架包括设计了供询问任务，要求 LLMs 了解自己所不知道的信息，并从患者那里收集缺失的医疗信息。</li>
<li>results: 实验结果显示，通过 fine-tuning 训练集可以减轻 LLMs 的假设现象，提高其在提posed的benchmark上的表现。这些结果得到了广泛的实验和剥夺学调查的验证。<details>
<summary>Abstract</summary>
Large language models (LLMs) have achieved significant success in interacting with human. However, recent studies have revealed that these models often suffer from hallucinations, leading to overly confident but incorrect judgments. This limits their application in the medical domain, where tasks require the utmost accuracy. This paper introduces an automated evaluation framework that assesses the practical capabilities of LLMs as virtual doctors during multi-turn consultations. Consultation tasks are designed to require LLMs to be aware of what they do not know, to inquire about missing medical information from patients, and to ultimately make diagnoses. To evaluate the performance of LLMs for these tasks, a benchmark is proposed by reformulating medical multiple-choice questions from the United States Medical Licensing Examinations (USMLE), and comprehensive evaluation metrics are developed and evaluated on three constructed test sets. A medical consultation training set is further constructed to improve the consultation ability of LLMs. The results of the experiments show that fine-tuning with the training set can alleviate hallucinations and improve LLMs' performance on the proposed benchmark. Extensive experiments and ablation studies are conducted to validate the effectiveness and robustness of the proposed framework.
</details>
<details>
<summary>摘要</summary>
Consultation tasks are designed to require LLMs to be aware of what they do not know, to inquire about missing medical information from patients, and to ultimately make diagnoses. To evaluate the performance of LLMs for these tasks, a benchmark is proposed by reformulating medical multiple-choice questions from the United States Medical Licensing Examinations (USMLE), and comprehensive evaluation metrics are developed and evaluated on three constructed test sets. A medical consultation training set is further constructed to improve the consultation ability of LLMs. The results of the experiments show that fine-tuning with the training set can alleviate hallucinations and improve LLMs' performance on the proposed benchmark.Extensive experiments and ablation studies are conducted to validate the effectiveness and robustness of the proposed framework.
</details></li>
</ul>
<hr>
<h2 id="Bilevel-Scheduled-Sampling-for-Dialogue-Generation"><a href="#Bilevel-Scheduled-Sampling-for-Dialogue-Generation" class="headerlink" title="Bilevel Scheduled Sampling for Dialogue Generation"></a>Bilevel Scheduled Sampling for Dialogue Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01953">http://arxiv.org/abs/2309.01953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiawen Liu, Kan Li</li>
<li>for:  mitigating exposure bias in natural language processing tasks, particularly in dialog generation.</li>
<li>methods:  proposed a bilevel scheduled sampling model that takes sentence-level information into account and incorporates it with word-level quality, and a smooth function that maps the combined result to an appropriate range for probabilistic sampling.</li>
<li>results:  significantly alleviated the exposure bias problem and outperformed state-of-the-art scheduled sampling methods in experiments conducted on the DailyDialog and PersonaChat datasets.<details>
<summary>Abstract</summary>
Exposure bias poses a common challenge in numerous natural language processing tasks, particularly in the dialog generation. In response to this issue, researchers have devised various techniques, among which scheduled sampling has proven to be an effective method for mitigating exposure bias. However, the existing state-of-the-art scheduled sampling methods solely consider the current sampling words' quality for threshold truncation sampling, which overlooks the importance of sentence-level information and the method of threshold truncation warrants further discussion. In this paper, we propose a bilevel scheduled sampling model that takes the sentence-level information into account and incorporates it with word-level quality. To enhance sampling diversity and improve the model's adaptability, we propose a smooth function that maps the combined result of sentence-level and word-level information to an appropriate range, and employ probabilistic sampling based on the mapped values instead of threshold truncation. Experiments conducted on the DailyDialog and PersonaChat datasets demonstrate the effectiveness of our proposed methods, which significantly alleviate the exposure bias problem and outperform state-of-the-art scheduled sampling methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate("Exposure bias poses a common challenge in numerous natural language processing tasks, particularly in dialog generation. In response to this issue, researchers have devised various techniques, among which scheduled sampling has proven to be an effective method for mitigating exposure bias. However, the existing state-of-the-art scheduled sampling methods solely consider the current sampling words' quality for threshold truncation sampling, which overlooks the importance of sentence-level information and the method of threshold truncation warrants further discussion. In this paper, we propose a bilevel scheduled sampling model that takes the sentence-level information into account and incorporates it with word-level quality. To enhance sampling diversity and improve the model's adaptability, we propose a smooth function that maps the combined result of sentence-level and word-level information to an appropriate range, and employ probabilistic sampling based on the mapped values instead of threshold truncation. Experiments conducted on the DailyDialog and PersonaChat datasets demonstrate the effectiveness of our proposed methods, which significantly alleviate the exposure bias problem and outperform state-of-the-art scheduled sampling methods.")]Here's the translation:<<SYS>>交叉偏见是许多自然语言处理任务中的常见挑战，尤其是对话生成。为了解决这个问题，研究人员已经提出了多种技术，其中规则采样已经被证明是有效的方法来减少交叉偏见。然而，现有的状态艺术规则采样方法只考虑当前采样词语的质量，忽略了句子水平信息，这种方法不充分考虑句子级别的信息和规则采样的问题。在这篇论文中，我们提出了一种两级规则采样模型，该模型考虑了句子水平信息，并将其与单词水平信息结合。为了增强采样多样性和模型适应性，我们提出了一种缓动函数，将合并的句子水平和单词水平信息映射到适当的范围内，然后使用概率采样基于映射值而不是阈值 truncation。经过 DailyDialog 和 PersonaChat 数据集的实验，我们的提议方法显示效果，可以减少交叉偏见问题，并在现有的规则采样方法中具有优势。
</details></li>
</ul>
<hr>
<h2 id="TODM-Train-Once-Deploy-Many-Efficient-Supernet-Based-RNN-T-Compression-For-On-device-ASR-Models"><a href="#TODM-Train-Once-Deploy-Many-Efficient-Supernet-Based-RNN-T-Compression-For-On-device-ASR-Models" class="headerlink" title="TODM: Train Once Deploy Many Efficient Supernet-Based RNN-T Compression For On-device ASR Models"></a>TODM: Train Once Deploy Many Efficient Supernet-Based RNN-T Compression For On-device ASR Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01947">http://arxiv.org/abs/2309.01947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Shangguan, Haichuan Yang, Danni Li, Chunyang Wu, Yassir Fathullah, Dilin Wang, Ayushi Dalmia, Raghuraman Krishnamoorthi, Ozlem Kalinli, Junteng Jia, Jay Mahadeokar, Xin Lei, Mike Seltzer, Vikas Chandra</li>
<li>for: 这篇论文的目的是提出一个名为TODM（Train Once Deploy Many）的新方法，用于快速训练适合不同硬件的实时语音识别（ASR）模型，并且可以与单一训练作业相比减少训练时间和资源。</li>
<li>methods: 这篇论文使用了以往的Supernet研究，将RNN-T模型的层级和宽度缩减为更小的subnetworks，以适应不同的硬件类型。此外，论文还提出了三种技术来提高TODM Supernet的效果：适应性Dropout、对Alpha-divergence知识传递和Scale Adam优化器。</li>
<li>results: 论文通过比较Supernet训练 versus个别调整Multi-Head State Space Model (MH-SSM) RNN-T使用LibriSpeech数据库，发现TODM Supernet可以与手动调整模型相比，在字元错误率（WER）上提高至3%以上的表现，而且可以快速地训练多个模型，并且仅需小于单一训练作业的训练时间和资源。<details>
<summary>Abstract</summary>
Automatic Speech Recognition (ASR) models need to be optimized for specific hardware before they can be deployed on devices. This can be done by tuning the model's hyperparameters or exploring variations in its architecture. Re-training and re-validating models after making these changes can be a resource-intensive task. This paper presents TODM (Train Once Deploy Many), a new approach to efficiently train many sizes of hardware-friendly on-device ASR models with comparable GPU-hours to that of a single training job. TODM leverages insights from prior work on Supernet, where Recurrent Neural Network Transducer (RNN-T) models share weights within a Supernet. It reduces layer sizes and widths of the Supernet to obtain subnetworks, making them smaller models suitable for all hardware types. We introduce a novel combination of three techniques to improve the outcomes of the TODM Supernet: adaptive dropouts, an in-place Alpha-divergence knowledge distillation, and the use of ScaledAdam optimizer. We validate our approach by comparing Supernet-trained versus individually tuned Multi-Head State Space Model (MH-SSM) RNN-T using LibriSpeech. Results demonstrate that our TODM Supernet either matches or surpasses the performance of manually tuned models by up to a relative of 3% better in word error rate (WER), while efficiently keeping the cost of training many models at a small constant.
</details>
<details>
<summary>摘要</summary>
自动话语识别（ASR）模型需要根据特定硬件进行优化，以便在设备上部署。这可以通过调整模型的超参数或探索其结构的变化来实现。然而，在进行这些变化后，需要重新训练和验证模型，这可能会占用资源。本文介绍了一种新的方法—— Train Once Deploy Many（TODM），可以高效地在不同硬件类型上训练多个适合硬件的语音识别模型，并且与单个训练任务相比，它的GPU时间相同。TODM利用了先前的Supernet研究，在Supernet中，Recurrent Neural Network Transducer（RNN-T）模型共享权重。它采用了减小Supernet层数和宽度，从而得到了适合所有硬件类型的子网络，这些子网络是小型模型。我们介绍了一种新的组合技术，包括适应性Dropout、在位Alpha-分布知识继承和Scale Adam优化器，以提高TODM Supernet的结果。我们通过对Supernet训练 versus 手动调整Multi-Head State Space Model（MH-SSM）RNN-T使用LibriSpeech进行比较，结果表明，我们的TODM Supernet可以与手动调整模型相比，在字节错误率（WER）方面提高到3%之间的Relative。同时，我们efficient地保持了训练多个模型的成本，占用小的常量。
</details></li>
</ul>
<hr>
<h2 id="QuantEase-Optimization-based-Quantization-for-Language-Models-–-An-Efficient-and-Intuitive-Algorithm"><a href="#QuantEase-Optimization-based-Quantization-for-Language-Models-–-An-Efficient-and-Intuitive-Algorithm" class="headerlink" title="QuantEase: Optimization-based Quantization for Language Models – An Efficient and Intuitive Algorithm"></a>QuantEase: Optimization-based Quantization for Language Models – An Efficient and Intuitive Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01885">http://arxiv.org/abs/2309.01885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kayhan Behdin, Ayan Acharya, Aman Gupta, Sathiya Keerthi, Rahul Mazumder</li>
<li>for: 本研究针对大型自然语言模型（LLMs）的快速部署实现了压缩技术，尤其是Post-Training Quantization（PTQ）。</li>
<li>methods: 本研究提出了一个层别压缩框架QuantEase，各层独立进行压缩，并使用了coordinate descent（CD）技术来解决非凸网络问题。</li>
<li>results: 实验结果显示，QuantEase在不同的LLMs和数据集上的误差率和零shot准确率方面具有国际级的表现，与比较方法GPTQ之间的改善为15%之间。尤其是对于具有重要权重（outliers）的情况下，我们的方法可以实现近乎3位数字的压缩，不需要非凸压缩或分组技术，与比较方法SpQR的改善为2倍以上。<details>
<summary>Abstract</summary>
With the rising popularity of Large Language Models (LLMs), there has been an increasing interest in compression techniques that enable their efficient deployment. This study focuses on the Post-Training Quantization (PTQ) of LLMs. Drawing from recent advances, our work introduces QuantEase, a layer-wise quantization framework where individual layers undergo separate quantization. The problem is framed as a discrete-structured non-convex optimization, prompting the development of algorithms rooted in Coordinate Descent (CD) techniques. These CD-based methods provide high-quality solutions to the complex non-convex layer-wise quantization problems. Notably, our CD-based approach features straightforward updates, relying solely on matrix and vector operations, circumventing the need for matrix inversion or decomposition. We also explore an outlier-aware variant of our approach, allowing for retaining significant weights (outliers) with complete precision. Our proposal attains state-of-the-art performance in terms of perplexity and zero-shot accuracy in empirical evaluations across various LLMs and datasets, with relative improvements up to 15% over methods such as GPTQ. Particularly noteworthy is our outlier-aware algorithm's capability to achieve near or sub-3-bit quantization of LLMs with an acceptable drop in accuracy, obviating the need for non-uniform quantization or grouping techniques, improving upon methods such as SpQR by up to two times in terms of perplexity.
</details>
<details>
<summary>摘要</summary>
随着大型语言模型（LLM）的 популяр化，压缩技术的研究吸引了越来越多的关注。这项研究关注于LLM的Post-Training Quantization（PTQ）。基于最新的进展，我们提出了QuantEase，一个层 wise量化框架，其中每层都进行独立的量化。问题被定义为一个逻辑结构化非核心的优化问题，这使得我们可以基于坐标降低（CD）技术开发高质量的解决方案。这些CD基本的方法可以提供高质量的解决方案，并且具有简单的更新，只需要基于矩阵和向量的操作，不需要矩阵反射或分解。我们还探索了一种具有异常检测的变体，可以保留重要的权重（异常），并且完全保留精度。我们的提议在实验中达到了 LLM 的状态zegart 性能，包括词 Error 和零培训精度，与比如 GPTQ 的方法相比，提高了15%。特别是我们的异常检测变体可以在不同批量化或分组技术的情况下，实现 LLM 的近或下三位量化，超过 SpQR 的性能，提高了至多两倍。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/05/cs.CL_2023_09_05/" data-id="clmvt7t8k007z26rdc5zcbmtv" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/11/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/54/">54</a><a class="extend next" rel="next" href="/page/13/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">81</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">81</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">81</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">81</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">77</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">34</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">77</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">21</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">150</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
