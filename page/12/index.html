
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/12/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.IV_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/eess.IV_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T09:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/eess.IV_2023_11_06/">eess.IV - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Auto-ICell-An-Accessible-and-Cost-Effective-Integrative-Droplet-Microfluidic-System-for-Real-Time-Single-Cell-Morphological-and-Apoptotic-Analysis"><a href="#Auto-ICell-An-Accessible-and-Cost-Effective-Integrative-Droplet-Microfluidic-System-for-Real-Time-Single-Cell-Morphological-and-Apoptotic-Analysis" class="headerlink" title="Auto-ICell: An Accessible and Cost-Effective Integrative Droplet Microfluidic System for Real-Time Single-Cell Morphological and Apoptotic Analysis"></a>Auto-ICell: An Accessible and Cost-Effective Integrative Droplet Microfluidic System for Real-Time Single-Cell Morphological and Apoptotic Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02927">http://arxiv.org/abs/2311.02927</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanyuan Wei, Meiai Lin, Shanhang Luo, Syed Muhammad Tariq Abbasi, Liwei Tan, Guangyao Cheng, Bijie Bai, Yi-Ping Ho, Scott Wu Yuan, Ho-Pui Ho</li>
<li>for: 本研究使用Auto-ICell系统进行单元细胞分析，包括单元细胞形态和 apoptosis 分析。</li>
<li>methods: 研究使用了一种 integrate droplet microfluidic system，具有3D printing技术和图像分析算法，可以生成固定尺寸的营寄droplets，并实时进行图像分析。</li>
<li>results: 研究发现，Auto-ICell系统可以实现高速、高效、自动化的单元细胞分析，并且可以评估单元细胞形态和 apoptosis 的分布。<details>
<summary>Abstract</summary>
The Auto-ICell system, a novel, and cost-effective integrated droplet microfluidic system, is introduced for real-time analysis of single-cell morphology and apoptosis. This system integrates a 3D-printed microfluidic chip with image analysis algorithms, enabling the generation of uniform droplet reactors and immediate image analysis. The system employs a color-based image analysis algorithm in the bright field for droplet content analysis. Meanwhile, in the fluorescence field, cell apoptosis is quantitatively measured through a combination of deep-learning-enabled multiple fluorescent channel analysis and a live/dead cell stain kit. Breast cancer cells are encapsulated within uniform droplets, with diameters ranging from 70 {\mu}m to 240 {\mu}m, generated at a high throughput of 1,500 droplets per minute. Real-time image analysis results are displayed within 2 seconds on a custom graphical user interface (GUI). The system provides an automatic calculation of the distribution and ratio of encapsulated dyes in the bright field, and in the fluorescent field, cell blebbing and cell circularity are observed and quantified respectively. The Auto-ICell system is non-invasive and provides online detection, offering a robust, time-efficient, user-friendly, and cost-effective solution for single-cell analysis. It significantly enhances the detection throughput of droplet single-cell analysis by reducing setup costs and improving operational performance. This study highlights the potential of the Auto-ICell system in advancing biological research and personalized disease treatment, with promising applications in cell culture, biochemical microreactors, drug carriers, cell-based assays, synthetic biology, and point-of-care diagnostics.
</details>
<details>
<summary>摘要</summary>
《Auto-ICell系统》是一种新型、成本效果的集成液态微机系统，用于实时分析单元细胞形态和 apoptosis。该系统结合了3D打印微机器件和图像分析算法，实现了生成固定尺寸液态室和即时图像分析。系统使用了色彩基于图像分析算法，在亮场进行液态内容分析。而在荧光场中，通过组合深度学习enabled多色渠道分析和live/dead细胞染料盒，量化细胞 apoptosis。具体来说，用 breast cancer细胞 encapsulated within uniform droplets，尺寸在70μm到240μm之间，通过高速生成1500个液态每分钟。实时图像分析结果在2秒钟内显示在自定义图形用户界面（GUI）上。系统提供了液态内容的自动计算和荧光场中细胞弹性和细胞圆形的观察和量化。Auto-ICell系统是不侵入的，提供了在线检测，为单元细胞分析提供了robust、时间高效、易用、成本效果的解决方案。它显著提高了液态单元细胞分析的设置成本和运行性能，有潜在应用于细胞文化、生化微 реактор、药物输送、细胞基因组分析、生物学synthesis和点检查诊断。
</details></li>
</ul>
<hr>
<h2 id="An-invariant-feature-extraction-for-multi-modal-images-matching"><a href="#An-invariant-feature-extraction-for-multi-modal-images-matching" class="headerlink" title="An invariant feature extraction for multi-modal images matching"></a>An invariant feature extraction for multi-modal images matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02842">http://arxiv.org/abs/2311.02842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenzhong Gao, Wei Li</li>
<li>for: 本研究旨在提供一种有效的多模式图像不变特征提取和匹配算法，用于多源数据分析。</li>
<li>methods: 该算法基于多模式图像之间的差异和相关性，实现了特征基本匹配。关键技术包括相位一致性（PC）和史提莫asi特征点检测、LogGabor滤波器和质量分配主orientation图（WPMOM）特征提取、多尺度处理来处理尺度差和优化匹配结果。</li>
<li>results: 实验结果表明，该算法在实际数据上具有良好的普适性和准确性，能够实现多模式图像的准确空间对齐，表明了实际应用价值和良好的泛化能力。<details>
<summary>Abstract</summary>
This paper aims at providing an effective multi-modal images invariant feature extraction and matching algorithm for the application of multi-source data analysis. Focusing on the differences and correlation of multi-modal images, a feature-based matching algorithm is implemented. The key technologies include phase congruency (PC) and Shi-Tomasi feature point for keypoints detection, LogGabor filter and a weighted partial main orientation map (WPMOM) for feature extraction, and a multi-scale process to deal with scale differences and optimize matching results. The experimental results on practical data from multiple sources prove that the algorithm has effective performances on multi-modal images, which achieves accurate spatial alignment, showing practical application value and good generalization.
</details>
<details>
<summary>摘要</summary>
本文提出了一种可靠的多模态图像不变性特征提取和匹配算法，用于多源数据分析的应用。关注多模态图像之间的差异和相关性，实现了特征基于匹配算法。关键技术包括相位同步（PC）和史提莫asi特征点检测、LogGabor滤波器和权重部分主orientation图（WPMOM）特征提取，以及多尺度处理来处理比例差异和优化匹配结果。实验结果表明，该算法在实际数据上具有良好的 espacial 对齐性，达到了实际应用价值和好的泛化性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/eess.IV_2023_11_06/" data-id="clpahu7en01db3h889b0t3i6m" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/eess.SP_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T08:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/eess.SP_2023_11_06/">eess.SP - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Joint-Sparse-Estimation-with-Cardinality-Constraint-via-Mixed-Integer-Semidefinite-Programming"><a href="#Joint-Sparse-Estimation-with-Cardinality-Constraint-via-Mixed-Integer-Semidefinite-Programming" class="headerlink" title="Joint Sparse Estimation with Cardinality Constraint via Mixed-Integer Semidefinite Programming"></a>Joint Sparse Estimation with Cardinality Constraint via Mixed-Integer Semidefinite Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03501">http://arxiv.org/abs/2311.03501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyi Liu, Frederic Matter, Alexander Sorg, Marc E. Pfetsch, Martin Haardt, Marius Pesavento</li>
<li>for: This paper addresses the maximum a posteriori (MAP) estimation for the multiple measurement vectors (MMV) problem, which is a fundamental problem in signal processing applications such as spectral analysis and direction-of-arrival (DOA) estimation.</li>
<li>methods: The paper derives an equivalent mixed-integer semidefinite program (MISDP) reformulation of the MAP estimation for the MMV problem, which can be exactly solved by a generic MISDP solver. However, for problems of extremely large dimensions, a relaxation-based approach is employed to obtain an approximate solution with reduced computation time.</li>
<li>results: The proposed method demonstrates improved error performance compared to several popular DOA estimation methods, including the deterministic maximum likelihood (DML) estimator. The method also offers a guarantee of finding a global optimum, unlike other nonconvex approaches for the MMV problem.<details>
<summary>Abstract</summary>
The multiple measurement vectors (MMV) problem refers to the joint estimation of a row-sparse signal matrix from multiple realizations of mixtures with a known dictionary. As a generalization of the standard sparse representation problem for a single measurement, this problem is fundamental in various applications in signal processing, e.g., spectral analysis and direction-of-arrival (DOA) estimation. In this paper, we consider the maximum a posteriori (MAP) estimation for the MMV problem, which is classically formulated as a regularized least-squares (LS) problem with an $\ell_{2,0}$-norm constraint, and derive an equivalent mixed-integer semidefinite program (MISDP) reformulation. The proposed MISDP reformulation can be exactly solved by a generic MISDP solver, which, however, becomes computationally demanding for problems of extremely large dimensions. To further reduce the computation time in such scenarios, a relaxation-based approach can be employed to obtain an approximate solution of the MISDP reformulation, at the expense of a reduced estimation performance. Numerical simulations in the context of DOA estimation demonstrate the improved error performance of our proposed method in comparison to several popular DOA estimation methods. In particular, compared to the deterministic maximum likelihood (DML) estimator, which is often used as a benchmark, the proposed method applied with a state-of-the-art MISDP solver exhibits a superior estimation performance at a significantly reduced running time. Moreover, unlike other nonconvex approaches for the MMV problem, including the greedy methods and the sparse Bayesian learning, the proposed MISDP-based method offers a guarantee of finding a global optimum.
</details>
<details>
<summary>摘要</summary>
多量测量向量（MMV）问题指的是从多个实现的混合中 joint 估计一个纤维数为 row-sparse 信号矩阵。这个问题是对于各种信号处理应用的基本问题，例如 спектраль分析和方向来源估计（DOA）。在这篇文章中，我们考虑了最大 posteriori（MAP）估计方法，这是经典的常数加权最小二乘（L2,0）准则问题的等价混合半整数Program（MISDP） reformulation。我们可以使用一个通用的 MISDP 解决方案来 exactly 解这个问题，但是在极大维度的问题中，这会变得计算昂贵。为了进一步减少计算时间，我们可以采用一种缓和方法来获得一个相对优化的 MISDP  reformulation，但是这将导致估计性能下降。在 DOA 估计的数值实验中，我们发现我们提出的方法在与其他几种流行的 DOA 估计方法相比，具有更高的估计性能，同时具有更快的计算时间。此外，不同于其他非凸方法，包括排序方法和杂音抽象学习，我们的 MISDP-based 方法可以保证找到全球最优解。
</details></li>
</ul>
<hr>
<h2 id="Resource-Allocation-for-RIS-Empowered-Wireless-Communications-Low-Complexity-and-Robust-Designs"><a href="#Resource-Allocation-for-RIS-Empowered-Wireless-Communications-Low-Complexity-and-Robust-Designs" class="headerlink" title="Resource Allocation for RIS-Empowered Wireless Communications: Low-Complexity and Robust Designs"></a>Resource Allocation for RIS-Empowered Wireless Communications: Low-Complexity and Robust Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03282">http://arxiv.org/abs/2311.03282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Zeng, Wanming Hao, Zhangjie Peng, Zheng Chu, Xingwang Li, Changsheng You, Cunhua Pan</li>
<li>for: 本研究探讨了基于可编程智能面（RIS）系统的资源分配技术的前进，主要目标是实现低复杂性和可靠性。</li>
<li>methods: 本文不仅描述了低复杂性和可靠性资源分配技术的基本原理，还提供了具体的数字结果用于说明。</li>
<li>results: 研究表明，采用低复杂性和可靠性资源分配技术可以在RIS assisted系统中提高系统的可靠性和性能。<details>
<summary>Abstract</summary>
This article delves into advancements in resource allocation techniques tailored for systems utilizing reconfigurable intelligent surfaces (RIS), with a primary focus on achieving low-complexity and resilient solutions. The investigation of low-complexity approaches for RIS holds significant relevance, primarily owing to the intricate characteristics inherent in RIS-based systems and the need of deploying large-scale RIS arrays. Concurrently, the exploration of robust solutions aims to address the issue of hardware impairments occurring at both the transceivers and RIS components in practical RIS-assisted systems. In the realm of both low-complexity and robust resource allocation, this article not only elucidates the fundamental techniques underpinning these methodologies but also offers comprehensive numerical results for illustrative purposes. The necessity of adopting resource allocation strategies that are both low in complexity and resilient is thoroughly established. Ultimately, this article provides prospective research avenues in the domain of low-complexity and robust resource allocation techniques tailored for RIS-assisted systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multivariate-selfsimilarity-Multiscale-eigen-structures-for-selfsimilarity-parameter-estimation"><a href="#Multivariate-selfsimilarity-Multiscale-eigen-structures-for-selfsimilarity-parameter-estimation" class="headerlink" title="Multivariate selfsimilarity: Multiscale eigen-structures for selfsimilarity parameter estimation"></a>Multivariate selfsimilarity: Multiscale eigen-structures for selfsimilarity parameter estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03247">http://arxiv.org/abs/2311.03247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charles-Gérard Lucas, Gustavo Didier, Herwig Wendt, Patrice Abry</li>
<li>for: 这 paper 是为了提出一种能够处理多变量自相似数据的方法。</li>
<li>methods: 该 paper 使用了基于多谱波特征的方法来估计自相似参数 vector。</li>
<li>results: 该 paper 提出了一种高效的估计方法，并在实际数据上进行了测试和验证。<details>
<summary>Abstract</summary>
Scale-free dynamics, formalized by selfsimilarity, provides a versatile paradigm massively and ubiquitously used to model temporal dynamics in real-world data. However, its practical use has mostly remained univariate so far. By contrast, modern applications often demand multivariate data analysis. Accordingly, models for multivariate selfsimilarity were recently proposed. Nevertheless, they have remained rarely used in practice because of a lack of available robust estimation procedures for the vector of selfsimilarity parameters. Building upon recent mathematical developments, the present work puts forth an efficient estimation procedure based on the theoretical study of the multiscale eigenstructure of the wavelet spectrum of multivariate selfsimilar processes. The estimation performance is studied theoretically in the asymptotic limits of large scale and sample sizes, and computationally for finite-size samples. As a practical outcome, a fully operational and documented multivariate signal processing estimation toolbox is made freely available and is ready for practical use on real-world data. Its potential benefits are illustrated in epileptic seizure prediction from multi-channel EEG data.
</details>
<details>
<summary>摘要</summary>
“级�cciones的动态，通过自相似性 formalized，提供了一个广泛和通用的模型，用于模elling temporal dynamics in real-world data。然而，它的实际使用主要仅对于单变量数数据进行分析。在现代应用中，通常需要多変量数据分析。因此，用于多变量自相似性的模型已经提出。然而，它们在实际中几乎没有被使用，因为缺乏可靠的自相似性参数的估计方法。基于最近的数学发展，本作提出了一个有效的估计方法，基于多尺度传递矩阵的波летспектrum。这个估计方法的性能在大规模和样本大小的对应上进行了理论研究，以及 computationally  дляfinite-size样本。作为实用的结果，一个完整的操作和文档的多ivariate signal processing估计工具组已经免费提供，并且准备用于实际数据的处理。其潜在优点被应用于多通道 EEG 数据中的癫癫癫癫预测。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Using-Shallow-Neural-Networks-with-Functional-Connectivity-from-EEG-signals-for-Early-Diagnosis-of-Alzheimer’s-and-Frontotemporal-Dementia"><a href="#Using-Shallow-Neural-Networks-with-Functional-Connectivity-from-EEG-signals-for-Early-Diagnosis-of-Alzheimer’s-and-Frontotemporal-Dementia" class="headerlink" title="Using Shallow Neural Networks with Functional Connectivity from EEG signals for Early Diagnosis of Alzheimer’s and Frontotemporal Dementia"></a>Using Shallow Neural Networks with Functional Connectivity from EEG signals for Early Diagnosis of Alzheimer’s and Frontotemporal Dementia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03151">http://arxiv.org/abs/2311.03151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zaineb Ajra, Binbin Xu, Gérard Dray, Jacky Montmain, Stéphane Perrey</li>
<li>For: The paper is written to explore the use of shallow neural networks and functional connectivity measures from EEG signals to differentiate between AD, FTD, and control cases.* Methods: The paper uses two sets of features: spectral-temporal and functional connectivity, and employs four methods, including shallow CNN-based models, to classify EEG signals.* Results: The shallow CNN-based models achieved the highest accuracy of 94.54% with AEC in the test dataset, outperforming conventional methods and providing a potentially additional early dementia diagnosis tool.Here is the information in Simplified Chinese text, as requested:</li>
<li>for: 这篇论文是为了探讨使用 shallow neural networks 和 EEG 信号函数连接度来分类 AD、FTD 和控制 случа的可能性。</li>
<li>methods: 这篇论文使用了两个集合特征：spectral-temporal 和函数连接度，并使用四种方法来分类 EEG 信号。</li>
<li>results: shallow CNN 基本模型在测试集上取得了 94.54% 的最高准确率，超过了常见方法，并提供了可能的早期诊断工具。<details>
<summary>Abstract</summary>
{Introduction: } Dementia is a neurological disorder associated with aging that can cause a loss of cognitive functions, impacting daily life. Alzheimer's disease (AD) is the most common cause of dementia, accounting for 50--70\% of cases, while frontotemporal dementia (FTD) affects social skills and personality. Electroencephalography (EEG) provides an effective tool to study the effects of AD on the brain. {Methods: } In this study, we propose to use shallow neural networks applied to two sets of features: spectral-temporal and functional connectivity using four methods. We compare three supervised machine learning techniques to the CNN models to classify EEG signals of AD / FTD and control cases. We also evaluate different measures of functional connectivity from common EEG frequency bands considering multiple thresholds. {Results and Discussion: } Results showed that the shallow CNN-based models achieved the highest accuracy of 94.54\% with AEC in test dataset when considering all connections, outperforming conventional methods and providing potentially an additional early dementia diagnosis tool. \url{https://doi.org/10.3389%2Ffneur.2023.1270405}
</details>
<details>
<summary>摘要</summary>
{Methods: } 在这项研究中，我们提出使用浅层神经网络，应用于两个集合：spectral-temporal和功能相关性。我们使用四种方法进行比较，包括三种超vised机器学习技术和CNN模型，以分类EEG信号的AD/FTD和控制 caso。此外，我们还评估了不同频谱带的功能相关性测量，使用多个阈值。{Results and Discussion: } 结果显示，使用浅层CNN-based模型可以达到94.54%的准确率，在测试数据集中，当考虑所有连接时，超过 conventional methods，并可能提供一种额外的诊断老年痴呐工具。参考文献：<https://doi.org/10.3389/fneur.2023.1270405>
</details></li>
</ul>
<hr>
<h2 id="Energy-Harvesting-Maximization-for-Reconfigurable-Intelligent-Surfaces-Using-Amplitude-Measurements"><a href="#Energy-Harvesting-Maximization-for-Reconfigurable-Intelligent-Surfaces-Using-Amplitude-Measurements" class="headerlink" title="Energy Harvesting Maximization for Reconfigurable Intelligent Surfaces Using Amplitude Measurements"></a>Energy Harvesting Maximization for Reconfigurable Intelligent Surfaces Using Amplitude Measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03143">http://arxiv.org/abs/2311.03143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Morteza Tavana, Meysam Masoudi, Emil Björnson</li>
<li>for: 能源收集可以使智能表面自动维护操作，不需要外部电源。本文考虑了智能表面上的能源收集问题，在没有协调 ambient RF 源的情况下。</li>
<li>methods: 我们提出了一系列的顺序相对位征算法，以最大化接收到的功率。我们证明了无噪场景下的提案算法将 converge 到最优值。然而，在噪场景下，我们提出了一个线性最小二乘估计器。我们证明了在线性估计器中的最佳测量相对位是均匀分布的相对位。</li>
<li>results: 我们通过对比Random phase update algorithm的表现，发现我们的提案算法在达到功率后的性能比Random algorithm更好，并且需要 fewer measurements per phase update。在噪场景下，我们通过Simulation表明，提案算法在一个离散的可能的相对位集中的情况下是不优的，它可以达到高于Random algorithm的值，但不是最大可能的值。<details>
<summary>Abstract</summary>
Energy harvesting can enable a reconfigurable intelligent surface (RIS) to self-sustain its operations without relying on external power sources. In this paper, we consider the problem of energy harvesting for RISs in the absence of coordination with the ambient RF source. We propose a series of sequential phase-alignment algorithms that maximize the received power based on only power measurements. We prove the convergence of the proposed algorithm to the optimal value for the noiseless scenario. However, for the noisy scenario, we propose a linear least squares estimator. We prove that within the class of linear estimators, the optimal set of measurement phases are equally-spaced phases. To evaluate the performance of the proposed method, we introduce a random phase update algorithm as a benchmark. Our simulation results show that the proposed algorithms outperform the random phase update method in terms of achieved power after convergence while requiring fewer measurements per phase update. Using simulations, we show that in a noiseless scenario with a discrete set of possible phase shifts for the RIS elements, the proposed method is sub-optimal, achieving a higher value than the random algorithm but not exactly the maximum feasible value that we obtained by exhaustive search.
</details>
<details>
<summary>摘要</summary>
能量收集可以让智能表面重新配置（RIS）无需依赖于外部电源进行自主运行。在这篇论文中，我们考虑了RIS中能量收集的问题，不同征Compatibility Mode（RF）源的协调。我们提出了一系列的顺序相对纹理算法，以最大化接收到的功率基于 только能量测量。我们证明了不含噪声的情况下，提posed算法的优化性。但是，在噪声场景下，我们提出了线性最小二乘估计器。我们证明了在线性估计器中的优化集是均匀分布的相位。为了评估提案方法的性能，我们引入了随机相位更新算法作为参照。我们的实验结果表明，提案方法在吞吐量更高，需要 fewer measurements per phase update。使用实验，我们发现在噪声场景下，对RIS元素的可能的相位shift是一个离散的集合时，提案方法是优化的，可以达到最大可能的值，但不是恰好的最大值。
</details></li>
</ul>
<hr>
<h2 id="Antenna-Positioning-and-Beamforming-Design-for-Movable-Antenna-Enabled-Multi-user-Downlink-Communications"><a href="#Antenna-Positioning-and-Beamforming-Design-for-Movable-Antenna-Enabled-Multi-user-Downlink-Communications" class="headerlink" title="Antenna Positioning and Beamforming Design for Movable-Antenna Enabled Multi-user Downlink Communications"></a>Antenna Positioning and Beamforming Design for Movable-Antenna Enabled Multi-user Downlink Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03046">http://arxiv.org/abs/2311.03046</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoran Qin, Wen Chen, Zhendong Li, Qingqing Wu, Nan Cheng, Fangjiong Chen</li>
<li>for:  investigate a multiple input single output (MISO) downlink communication system with movable antennas (MAs)</li>
<li>methods: adopt a field-response based channel model and employ an alternating optimization (AO) algorithm based on penalty method and successive convex approximation (SCA) to obtain a sub-optimal solution</li>
<li>results: the MA-enabled communication system performs better than conventional fixed position antennasHere’s the format you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
This paper investigates a multiple input single output (MISO) downlink communication system in which users are equipped with movable antennas (MAs). First, We adopt a field-response based channel model to characterize the downlink channel with respect to MAs' positions. Then, we aim to minimize the total transmit power by jointly optimizing the MAs' positions and beamforming matrix. To solve the resulting non-convex problem, we employ an alternating optimization (AO) algorithm based on penalty method and successive convex approximation (SCA) to obtain a sub-optimal solution. Numerical results demonstrate that the MA-enabled communication system perform better than conventional fixed position antennas.
</details>
<details>
<summary>摘要</summary>
这个论文研究了一个多输入单输出（MISO）下链通信系统，在该系统中用户装备了可动天线（MA）。首先，我们采用场响应基于通道模型来描述附近MA的下链通道。然后，我们想要最小化总发射功率，通过同时优化MA的位置和扬行矩阵来解决。为解决得到的非对称问题，我们使用 alternate optimization（AO）算法和罚方法和逐步几何近似（SCA）来获得一个优化解决方案。 numerically， results show that the MA-enabled communication system outperforms traditional fixed position antennas.Here's the breakdown of the translation:* "This paper investigates a multiple input single output (MISO) downlink communication system" becomes "这个论文研究了一个多输入单输出（MISO）下链通信系统"* "in which users are equipped with movable antennas (MAs)" becomes "在该系统中用户装备了可动天线（MA）"* "First, We adopt a field-response based channel model to characterize the downlink channel with respect to MAs' positions" becomes "首先，我们采用场响应基于通道模型来描述附近MA的下链通道"* "Then, we aim to minimize the total transmit power by jointly optimizing the MAs' positions and beamforming matrix" becomes "然后，我们想要最小化总发射功率，通过同时优化MA的位置和扬行矩阵来解决"* "To solve the resulting non-convex problem, we employ an alternating optimization (AO) algorithm based on penalty method and successive convex approximation (SCA) to obtain a sub-optimal solution" becomes "为解决得到的非对称问题，我们使用 alternate optimization（AO）算法和罚方法和逐步几何近似（SCA）来获得一个优化解决方案"* "Numerical results demonstrate that the MA-enabled communication system perform better than conventional fixed position antennas" becomes "numerically， results show that the MA-enabled communication system outperforms traditional fixed position antennas"
</details></li>
</ul>
<hr>
<h2 id="Optimization-of-RIS-Placement-for-Satellite-to-Ground-Coverage-Enhancement"><a href="#Optimization-of-RIS-Placement-for-Satellite-to-Ground-Coverage-Enhancement" class="headerlink" title="Optimization of RIS Placement for Satellite-to-Ground Coverage Enhancement"></a>Optimization of RIS Placement for Satellite-to-Ground Coverage Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02958">http://arxiv.org/abs/2311.02958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingchen Liu, Liuxun Xue, Shu Sun, Meixia Tao</li>
<li>for: 提高卫星到地面通信的可靠性和效率</li>
<li>methods: 使用可配置智能表面（RIS）协助，并优化RIS的布局在建筑物表面上，以提高卫星到地面通信的覆盖率</li>
<li>results: 通过大规模RIS部署，实现卫星到地面通信覆盖率的下限，并且通过优化RIS布局，提高非直线视野用户的通信覆盖率，并可应用于不同的建筑物分布情况（如农村、小镇、城市）。<details>
<summary>Abstract</summary>
In satellite-to-ground communication, ensuring reliable and efficient connectivity poses significant challenges. The reconfigurable intelligent surface (RIS) offers a promising solution due to its ability to manipulate wireless propagation environments and thus enhance communication performance. In this paper, we propose a method for optimizing the placement of RISs on building facets to improve satellite-to-ground communication coverage. We model satellite-to-ground communication with RIS assistance, considering the actual positions of buildings and ground users. The theoretical lower bound on the coverage enhancement in satellite-to-ground communication through large-scale RIS deployment is derived. Then a novel optimization framework for RIS placement is formulated, and a parallel genetic algorithm is employed to solve the problem. Simulation results demonstrate the superior performance of the proposed RIS deployment strategy in enhancing satellite communication coverage probability for non-line-of-sight users. The proposed framework can be applied to various architectural distributions, such as rural areas, towns, and cities, by adjusting parameter settings.
</details>
<details>
<summary>摘要</summary>
卫星到地面通信中确保可靠和高效连接具有重要挑战。智能表面重配置（RIS）提供了一种有前途的解决方案，因为它可以 manipulate 无线传播环境，从而提高通信性能。在这篇论文中，我们提议了一种改进卫星到地面通信覆盖的方法，通过对建筑物表面的 RIS 的布置优化。我们使用实际的建筑物和地面用户的位置来模拟卫星到地面通信，并 deriv 出了无线传播环境的理论下界。然后，我们提出了一种新的优化框架，并使用并行遗传算法来解决问题。实验结果表明，提议的 RIS 布局策略可以提高卫星通信覆盖率 для非直线视野用户。该提议的框架可以应用于不同的建筑分布，如乡村、小镇和城市，通过调整参数设置。
</details></li>
</ul>
<hr>
<h2 id="Channel-Estimation-and-Training-Design-for-Active-RIS-Aided-Wireless-Communications"><a href="#Channel-Estimation-and-Training-Design-for-Active-RIS-Aided-Wireless-Communications" class="headerlink" title="Channel Estimation and Training Design for Active RIS Aided Wireless Communications"></a>Channel Estimation and Training Design for Active RIS Aided Wireless Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02935">http://arxiv.org/abs/2311.02935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Chen, Nanxi Li, Ruizhe Long, Ying-Chang Liang</li>
<li>for: 提高无线通信的精度，使用活动再配置智能面（ARIS）技术增强incident signal的强度。</li>
<li>methods: 利用ARIS的信号增强功能进行通道估计，以提高估计精度。</li>
<li>results: 通过提出LS基于通道估计器和ARIS反射 patrern的优化方案，在ARIS频率干扰下实现精度的Channel estimation。<details>
<summary>Abstract</summary>
Active reconfigurable intelligent surface (ARIS) is a newly emerging RIS technique that leverages radio frequency (RF) reflection amplifiers to empower phase-configurable reflection elements (REs) in amplifying the incident signal. Thereby, ARIS can enhance wireless communications with the strengthened ARIS-aided links. In this letter, we propose exploiting the signal amplification capability of ARIS for channel estimation, aiming to improve the estimation precision. Nevertheless, the signal amplification inevitably introduces the thermal noise at the ARIS, which can hinder the acquisition of accurate channel state information (CSI) with conventional channel estimation methods based on passive RIS (PRIS). To address this issue, we further investigate this ARIS-specific channel estimation problem and propose a least-square (LS) based channel estimator, whose performance can be further improved with the design on ARIS reflection patterns at the channel training phase. Based on the proposed LS channel estimator, we optimize the training reflection patterns to minimize the channel estimation error variance. Extensive simulation results show that our proposed design can achieve accurate channel estimation in the presence of the ARIS noises.
</details>
<details>
<summary>摘要</summary>
新出现的活动可配置表面技术（ARIS）可以使用 радио频率（RF）反射增强器来强制配置阶段元件（RE），从而提高无线通信的信号强度。因此，ARIS可以提高无线通信链路的质量。在这封信中，我们提议利用ARIS增强信号的能力进行频率探测，以提高频率探测的精度。然而，信号增强必然会在ARIS中引入热噪声，这可能会使得传统的频率探测方法（基于被动RIS）难以获得准确的通道状态信息（CSI）。为解决这个问题，我们进一步研究了ARIS特有的频率探测问题，并提出了基于最小二乘（LS）的频率探测器。通过对ARIS反射模式的设计，我们可以在频率探测阶段进行训练，以最小化频率探测错误偏差的变量。通过我们的设计，我们可以在ARIS噪声的存在下实现准确的频率探测。Note: Simplified Chinese is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="Pilot-Design-and-Signal-Detection-for-Symbiotic-Radio-over-OFDM-Carriers"><a href="#Pilot-Design-and-Signal-Detection-for-Symbiotic-Radio-over-OFDM-Carriers" class="headerlink" title="Pilot Design and Signal Detection for Symbiotic Radio over OFDM Carriers"></a>Pilot Design and Signal Detection for Symbiotic Radio over OFDM Carriers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02928">http://arxiv.org/abs/2311.02928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Chen, Qianqian Zhang, Ruizhe Long, Yiyang Pei, Ying-Chang Liang</li>
<li>for: 该论文主要研究频率分配和信号检测在Symbiotic radio（SR）系统中，以提高spectrum-和energy-efficiency。</li>
<li>methods: 研究使用 comb-type 干扰符和 preamble 干扰符的pilot结构，以及使用扩展��构 Channel Estimation（CE）来提高主传输的性能。</li>
<li>results: 实验结果表明，采用后向扩展��构 CE 可以提高主传输的性能，并且无需直接链接，primary和secondary传输都可以通过后向扩展��构 CE 支持。同时，研究还发现了symbol synchronization error的敏感性。<details>
<summary>Abstract</summary>
Symbiotic radio (SR) is a promising solution to achieve high spectrum- and energy-efficiency due to its spectrum sharing and low-power consumption properties, in which the secondary system achieves data transmissions by backscattering the signal originating from the primary system. In this paper, we are interested in the pilot design and signal detection when the primary transmission adopts orthogonal frequency division multiplexing (OFDM). In particular, to preserve the channel orthogonality among the OFDM sub-carriers, each secondary symbol is designed to span an entire OFDM symbol. The comb-type pilot structure is employed by the primary transmission, while the preamble pilot structure is used by the secondary transmission. With the designed pilot structures, the primary signal can be detected via the conventional methods by treating the secondary signal as a part of the composite channel, i.e., the effective channel of the primary transmission. Furthermore, the secondary signal can be extracted from the estimated composite channel with the help of the detected primary signal. The bit error rate (BER) performance with both perfect and estimated CSI, the diversity orders of the primary and secondary transmissions, and the sensitivity to symbol synchronization error are analyzed. Simulation results show that the performance of the primary transmission is enhanced thanks to the backscatter link established by the secondary transmission. More importantly, even without the direct link, the primary and secondary transmissions can be supported via only the backscatter link.
</details>
<details>
<summary>摘要</summary>
共生射频（SR）是一种有前途的解决方案，可以实现高频率和能量效率，因为它可以共享频率和低功率的特性。在本文中，我们关注的是主传输的预测设计和信号检测，当主传输采用分多样频分复用（OFDM）时。为保持OFDM子帧之间的频率独立性，我们将每个次级符号设计为覆盖整个OFDM符号。主传输使用comb型预测结构，而次传输使用预测预测结构。通过我们设计的预测结构，主信号可以通过传统方法检测，即将次信号视为主信道的一部分，即效果频道。此外，次信号还可以通过对估计的主信道进行拓展来提取。我们分析了基于完美和估计的频道状况信息（CSI）的比特错误率（BER）性能，主和次传输的多样度，以及符号同步错误的敏感度。 simulation results show that the performance of the primary transmission is enhanced due to the backscatter link established by the secondary transmission. Moreover, even without the direct link, the primary and secondary transmissions can be supported via only the backscatter link.
</details></li>
</ul>
<hr>
<h2 id="Goal-Oriented-Wireless-Communication-Resource-Allocation-for-Cyber-Physical-Systems"><a href="#Goal-Oriented-Wireless-Communication-Resource-Allocation-for-Cyber-Physical-Systems" class="headerlink" title="Goal-Oriented Wireless Communication Resource Allocation for Cyber-Physical Systems"></a>Goal-Oriented Wireless Communication Resource Allocation for Cyber-Physical Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02911">http://arxiv.org/abs/2311.02911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Feng, Kedi Zheng, Yi Wang, Kaibin Huang, Qixin Chen</li>
<li>for: 这个论文主要是为了提高各种无线边缘应用，如智能电网和车辆网络，这些应用需要适应性和可控性的各种各样的无线通信网络。</li>
<li>methods: 这篇论文提出了一种目标导向的无线通信资源分配框架，考虑了数据的 semantics 和重要性，以便实现最佳的 CPS 性能。具体来说，他们提出了一种分解信息价值增加的分解方法，然后将带宽分配问题转化为一个可解释的饱和问题，并使用一种分配和规划算法来解决这个问题。</li>
<li>results: 这篇论文的结果表明，通过使用目标导向的无线通信资源分配框架，可以提高 CPS 的性能和效率，并且可以应用于多种应用场景，如数据驱动决策、边缘学习、联合学习和分布式优化。<details>
<summary>Abstract</summary>
The proliferation of novel industrial applications at the wireless edge, such as smart grids and vehicle networks, demands the advancement of cyber-physical systems. The performance of CPSs is closely linked to the last-mile wireless communication networks, which often become bottlenecks due to their inherent limited resources. Current CPS operations often treat wireless communication networks as unpredictable and uncontrollable variables, ignoring the potential adaptability of wireless networks, which results in inefficient and overly conservative CPS operations. Meanwhile, current wireless communications often focus more on throughput and other transmission-related metrics instead of CPS goals. In this study, we introduce the framework of goal-oriented wireless communication resource allocations, accounting for the semantics and significance of data for CPS operation goals. This guarantees optimal CPS performance from a cybernetic standpoint. We formulate a bandwidth allocation problem aimed at maximizing the information utility gain of transmitted data brought to CPS operation goals. Since the goal-oriented bandwidth allocation problem is a large-scale combinational problem, we propose a divide-and-conquer and greedy solution algorithm. The information utility gain is first approximately decomposed into marginal utility information gains and computed in a parallel manner. Subsequently, the bandwidth allocation problem is reformulated as a knapsack problem, which can be further solved greedily with a guaranteed sub-optimality gap. We further demonstrate how our proposed goal-oriented bandwidth allocation algorithm can be applied in four potential CPS applications, including data-driven decision-making, edge learning, federated learning, and distributed optimization.
</details>
<details>
<summary>摘要</summary>
随着无线边缘应用的增多，如智能网络和车辆网络，质量体系的发展受到推动。无线通信网络的性能对智能体系的运行起到关键作用，但现有的智能体系操作方法通常忽略无线通信网络的可变性和可控性，导致不必要地保守和不效率。同时，现有的无线通信往往更关注传输速率和其他传输相关指标，而忽略智能体系的操作目标。在本研究中，我们提出了基于目标的无线通信资源分配框架，考虑智能体系操作目标的 semantics和重要性。这保证了智能体系的最佳性从Cybernetic standpoint。我们将传输数据带来智能体系操作目标的信息价值增量作为目标函数，并将其分解为各个数据项的独立 marginal utility information gain。然后，我们将带来的带宽分配问题转化为一个knapsack问题，可以通过简单的贪婪算法解决。我们进一步示出了我们提出的目标带宽分配算法在四种可能的智能体系应用中的应用，包括数据驱动决策、边缘学习、联合学习和分布式优化。
</details></li>
</ul>
<hr>
<h2 id="Energy-Efficient-Multidimensional-Constellation-Based-on-Leech-Lattice-for-Visible-Light-Communications"><a href="#Energy-Efficient-Multidimensional-Constellation-Based-on-Leech-Lattice-for-Visible-Light-Communications" class="headerlink" title="Energy-Efficient Multidimensional Constellation Based on Leech Lattice for Visible Light Communications"></a>Energy-Efficient Multidimensional Constellation Based on Leech Lattice for Visible Light Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02865">http://arxiv.org/abs/2311.02865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia-Ning Guo, Ru-Han Chen, Jian Zhang, Longguang Li, Jing Zhou</li>
<li>for: 这个论文是为了研究室内可见光通讯（VLC）中的数位传输，特别是在具有峰值和平均Intensity输入限制的情况下。</li>
<li>methods: 这个论文使用了大幅退化理论工具，掌握了具有上述内数位传输的第二项偏微分方程的优化构成形状区域，进一步精确化了在[Chen. et. al, 2020]中的结果。在优化的几何形状区域中，提出了一个能量高效的24维度构成设计，其中利用了Leech组合和高效编码的策略，实现了较大的编码优化和几何优化。此外，还提出了快速的构成对应和解读算法。</li>
<li>results: numerical results表明，对比 existed method，这个方法可以 дости得更高的优化和更好的性能。<details>
<summary>Abstract</summary>
In this paper, a 24-dimensional geometrically-shaped constellation design based on Leech lattice is presented for indoor visible light communications (VLCs) with a peak-and an average-intensity input constraints. Firstly, by leveraging tools from large deviation theory, we characterize second-order asymptotics of the optimal constellation shaping region under aforementioned intensity constraints, which further refine our previous results in [Chen. et. al, 2020]. Within the optimal geometrical shaping region, we develop an energy-efficient 24-dimensional constellation design, where a significant coding gain brought by the Leech lattice and the nearly-maximum shaping gain are incorporated by using a strategy called coarsely shaping and finely coding. Fast algorithms for constellation mapping and demodulation are presented as well. Numerical results verifies the superiority of our results as compared with existing methods.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种基于Leech lattice的24维геометри设计，用于indoor可见光通信（VLC），并且受到峰值和平均输入强度的限制。我们首先通过大偏移理论工具来描述在上述强度限制下的最佳形态域的第二阶偏移，这也是我们在[陈等，2020]中的进一步发展。在最佳的 геометри设计区域内，我们开发了一种能效的24维数字编码设计，其中Leech lattice和高效编码具有较高的编码准确率。此外，我们还提出了一种名为“粗化编码”的策略，可以充分利用Leech lattice的优势。我们还提供了快速的 constellation mapping 和解译算法。 numerics 结果表明，我们的结果与现有方法相比具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Multi-User-Multi-IoT-Device-Symbiotic-Radio-A-Novel-Massive-Access-Scheme-for-Cellular-IoT"><a href="#Multi-User-Multi-IoT-Device-Symbiotic-Radio-A-Novel-Massive-Access-Scheme-for-Cellular-IoT" class="headerlink" title="Multi-User Multi-IoT-Device Symbiotic Radio: A Novel Massive Access Scheme for Cellular IoT"></a>Multi-User Multi-IoT-Device Symbiotic Radio: A Novel Massive Access Scheme for Cellular IoT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02837">http://arxiv.org/abs/2311.02837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Wang, Ying-Chang Liang, Sumei Sun</li>
<li>for: 支持 cellular Internet of Things (IoT) 的 Symbiotic radio (SR) 系统，以实现大规模访问。</li>
<li>methods: 提议一种新的多用户多 IoT 设备 SR 系统，使得基站 (BS) 可以同时传输信息给多个 cellular 用户和多个 IoT 设备。</li>
<li>results: 在考虑到的系统中，通过使用 robust 设计方法和 semi-definite programming 和 difference-of-convex programming 算法，可以最小化 transmit 功率，同时满足 cellular 传输残弱概率和 IoT 传输总比特率的约束。<details>
<summary>Abstract</summary>
Symbiotic radio (SR) is a promising technique to support cellular Internet-of-Things (IoT) by forming a mutualistic relationship between IoT and cellular transmissions. In this paper, we propose a novel multi-user multi-IoT-device SR system to enable massive access in cellular IoT. In the considered system, the base station (BS) transmits information to multiple cellular users, and a number of IoT devices simultaneously backscatter their information to these users via the cellular signal. The cellular users jointly decode the information from the BS and IoT devices. Noting that the reflective links from the IoT devices can be regarded as the channel uncertainty of the direct links, we apply the robust design method to design the beamforming vectors at the BS. Specifically, the transmit power is minimized under the cellular transmission outage probability constraints and IoT transmission sum rate constraints. The algorithm based on semi-definite programming and difference-of-convex programming is proposed to solve the power minimization problem. Moreover, we consider a special case where each cellular user is associated with several adjacent IoT devices and propose a direction of arrival (DoA)-based transmit beamforming design approach. The DoA-based approach requires only the DoA and angular spread (AS) of the direct links instead of the instantaneous channel state information (CSI) of the reflective link channels, leading to a significant reduction in the channel feedback overhead. Simulation results have substantiated the multi-user multi-IoT-device SR system and the effectiveness of the proposed beamforming approaches. It is shown that the DoA-based beamforming approach achieves comparable performance as the CSI-based approach in the special case when the ASs are small.
</details>
<details>
<summary>摘要</summary>
симбиотиче radio (SR) 是一种有前途的技术，用于支持 cellular Internet of Things (IoT)  by forming a mutualistic relationship between IoT and cellular transmissions. 在本文中，我们提议一种新的多用户多 IoT 设备 SR 系统，以实现大规模访问在 cellular IoT 中。在考虑的系统中，基站 (BS) 发送信息给多个 cellular 用户，而多个 IoT 设备同时借鉴了这些用户的信号来反射其信息。用户们共同解码基站和 IoT 设备之间的信息。注意到反射链的不确定性可以视为 direct link 的通道不确定性，我们采用了Robust 设计方法来设计基站的扫描向量。特别是，在 cellular 传输残留概率和 IoT 传输总速率的限制下，我们将 transmit 功率进行最小化。我们提出了一种基于 semi-definite programming 和差异 convex programming 的算法来解决功率最小化问题。此外，我们考虑了每个 cellular 用户与邻近的多个 IoT 设备之间的特殊情况，并提出了一种方向 Of Arrival (DoA) 基于的传输扫描设计方法。DoA 基于方法只需要 DoA 和 Angular Spread (AS) 的直接链 instead of instantaneous channel state information (CSI) 的反射链通道的状态信息，从而减少了通道反馈过程的卫星负担。实验结果证明了多用户多 IoT 设备 SR 系统和我们提议的扫描方法的有效性。结果表明，在特殊情况下，当 AS 较小时，DoA 基于方法与 CSI 基于方法的性能相似。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/eess.SP_2023_11_06/" data-id="clpahu7gd01hj3h88gl8je6wf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.SD_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T15:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/cs.SD_2023_11_05/">cs.SD - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Yet-Another-Generative-Model-For-Room-Impulse-Response-Estimation"><a href="#Yet-Another-Generative-Model-For-Room-Impulse-Response-Estimation" class="headerlink" title="Yet Another Generative Model For Room Impulse Response Estimation"></a>Yet Another Generative Model For Room Impulse Response Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02581">http://arxiv.org/abs/2311.02581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungho Lee, Hyeong-Seok Choi, Kyogu Lee</li>
<li>for: 这 paper 的目的是提出一种新的 neural room impulse response (RIR) 估计器，以提高估计质量。</li>
<li>methods: 这 paper 使用了一种 alternate generator 架构，通过 residual quantization 学习一个精度的离散Token空间，并将 RIR 估计问题转化为一个 reference-conditioned autoregressive token generation 任务。</li>
<li>results: 实验结果表明，这 paper 的系统在多种评价指标上都有优于基eline。<details>
<summary>Abstract</summary>
Recent neural room impulse response (RIR) estimators typically comprise an encoder for reference audio analysis and a generator for RIR synthesis. Especially, it is the performance of the generator that directly influences the overall estimation quality. In this context, we explore an alternate generator architecture for improved performance. We first train an autoencoder with residual quantization to learn a discrete latent token space, where each token represents a small time-frequency patch of the RIR. Then, we cast the RIR estimation problem as a reference-conditioned autoregressive token generation task, employing transformer variants that operate across frequency, time, and quantization depth axes. This way, we address the standard blind estimation task and additional acoustic matching problem, which aims to find an RIR that matches the source signal to the target signal's reverberation characteristics. Experimental results show that our system is preferable to other baselines across various evaluation metrics.
</details>
<details>
<summary>摘要</summary>
现代神经room响应函数估计器通常包括一个编码器用于参考音频分析和一个生成器用于响应函数合成。特别是，生成器的性能直接影响总估计质量。在这个上下文中，我们探索了一种 alternate 生成器架构以提高性能。我们首先在 autoencoder 中使用循环量化来学习一个精度时间频谱空间，其中每个token表示一个小时频谱块的响应函数。然后，我们将响应函数估计问题转化为一个引用条件自适应字符串生成任务，使用 transformer 变体在频率、时间和量化深度轴上运行。这样，我们解决了标准盲目估计问题和附加的听音匹配问题，其目的是找到一个匹配源信号的响应函数。实验结果显示，我们的系统在多个评价指标上比其他基准高。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.SD_2023_11_05/" data-id="clpahu79q01283h88cs1talkk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.CV_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T13:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/cs.CV_2023_11_05/">cs.CV - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MirrorCalib-Utilizing-Human-Pose-Information-for-Mirror-based-Virtual-Camera-Calibration"><a href="#MirrorCalib-Utilizing-Human-Pose-Information-for-Mirror-based-Virtual-Camera-Calibration" class="headerlink" title="MirrorCalib: Utilizing Human Pose Information for Mirror-based Virtual Camera Calibration"></a>MirrorCalib: Utilizing Human Pose Information for Mirror-based Virtual Camera Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02791">http://arxiv.org/abs/2311.02791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longyun Liao, Andrew Mitchell, Rong Zheng</li>
<li>for: 估计虚拟摄像头的外部参数，即与实际摄像头相对的投影 mirror 的相对位姿。</li>
<li>methods: 利用人体知识和2D关节位置来估计摄像头外部参数，首先使用修改后的八点算法获取初始估计，然后根据人体 constraints 进行修正，最后使用 RANSAC 算法除异常点。</li>
<li>results: 在 synthetic 和实际数据集上进行测试，mirrorCalib 可以达到 rotation error 0.62{\deg}&#x2F;1.82{\deg} 和 translation error 37.33&#x2F;69.51 mm，超越当前最佳方法。<details>
<summary>Abstract</summary>
In this paper, we present the novel task of estimating the extrinsic parameters of a virtual camera with respect to a real camera with one single fixed planar mirror. This task poses a significant challenge in cases where objects captured lack overlapping views from both real and mirrored cameras. To address this issue, prior knowledge of a human body and 2D joint locations are utilized to estimate the camera extrinsic parameters when a person is in front of a mirror. We devise a modified eight-point algorithm to obtain an initial estimation from 2D joint locations. The 2D joint locations are then refined subject to human body constraints. Finally, a RANSAC algorithm is employed to remove outliers by comparing their epipolar distances to a predetermined threshold. MirrorCalib is evaluated on both synthetic and real datasets and achieves a rotation error of 0.62{\deg}/1.82{\deg} and a translation error of 37.33/69.51 mm on the synthetic/real dataset, which outperforms the state-of-art method.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一个新的任务：使用真实摄像头和一个固定的平面镜来估算虚拟摄像头的外部参数。当物体被捕捉时，缺乏真实和镜头摄像头之间的重叠视图，这个任务具有显著的挑战。为解决这个问题，我们利用人体的先知知识和2D关节位置来估算摄像头的外部参数，当人物在镜子前时。我们修改了八点算法以获得初始估算，然后使用人体限制来精确估算。最后，我们使用RANSAC算法来移除异常值，比较它们的视角距离与先定的阈值。我们的 MirrorCalib 方法在Synthetic 和 Real 数据集上进行了评估，其中Synthetic 数据集的旋转错误为0.62°/1.82°，翻译错误为37.33/69.51 mm，超过了现有方法的性能。
</details></li>
</ul>
<hr>
<h2 id="MuSHRoom-Multi-Sensor-Hybrid-Room-Dataset-for-Joint-3D-Reconstruction-and-Novel-View-Synthesis"><a href="#MuSHRoom-Multi-Sensor-Hybrid-Room-Dataset-for-Joint-3D-Reconstruction-and-Novel-View-Synthesis" class="headerlink" title="MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis"></a>MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02778">http://arxiv.org/abs/2311.02778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuqian Ren, Wenjia Wang, Dingding Cai, Tuuli Tuominen, Juho Kannala, Esa Rahtu</li>
<li>for: 这 paper 的目的是提高 Metaverse 技术中的准确、实时、 immerse 模型化，以满足非人类感知（如无人机&#x2F;机器人&#x2F;自动驾驶车 navigation）和 immerse 技术（如 AR&#x2F;VR）的需求。</li>
<li>methods: 这 paper 使用了多感器 гибрид房间数据集 (MuSHRoom)，并对其进行了多种著名的管道测试，以评估它们在实际应用中的性能。</li>
<li>results: 这 paper 提出了一种新的方法，可以在实时和 computationally efficient 的方式下，将3D reconstruction和高质量的rendering融合在一起。这种方法在 MuSHRoom 数据集上显示出了良好的性能。<details>
<summary>Abstract</summary>
Metaverse technologies demand accurate, real-time, and immersive modeling on consumer-grade hardware for both non-human perception (e.g., drone/robot/autonomous car navigation) and immersive technologies like AR/VR, requiring both structural accuracy and photorealism. However, there exists a knowledge gap in how to apply geometric reconstruction and photorealism modeling (novel view synthesis) in a unified framework.   To address this gap and promote the development of robust and immersive modeling and rendering with consumer-grade devices, first, we propose a real-world Multi-Sensor Hybrid Room Dataset (MuSHRoom). Our dataset presents exciting challenges and requires state-of-the-art methods to be cost-effective, robust to noisy data and devices, and can jointly learn 3D reconstruction and novel view synthesis, instead of treating them as separate tasks, making them ideal for real-world applications. Second, we benchmark several famous pipelines on our dataset for joint 3D mesh reconstruction and novel view synthesis. Finally, in order to further improve the overall performance, we propose a new method that achieves a good trade-off between the two tasks. Our dataset and benchmark show great potential in promoting the improvements for fusing 3D reconstruction and high-quality rendering in a robust and computationally efficient end-to-end fashion.
</details>
<details>
<summary>摘要</summary>
<SYS>translate text into Simplified Chinese</SYS>Metaverse技术需要精准、实时和具有吸引力的模型，用于非人类感知（如无人机/机器人/自动驾驶车 navigation）以及具有吸引力的技术，如AR/VR，需要结构准确和写实感。然而，当前存在一个知识空白，即如何在一个统一框架中应用准确的三维重建和写实感模型。为了bridging这个知识空白，并促进使用消费级设备进行强大和吸引人的模型和渲染，我们首先提出了一个真实世界多感器混合房间数据集（MuSHRoom）。我们的数据集具有吸引人的挑战，需要当前的技术来实现成本效益、鲁棒性和可靠性，同时可以同时学习3D重建和新视野合成，而不是单独处理它们为两个独立的任务，使其适用于实际应用。其次，我们对我们的数据集上使用了许多知名的管道进行联合3D网格重建和新视野合成的benchmark。最后，为了进一步提高总性能，我们提出了一种新的方法，可以在两个任务之间取得良好的平衡。我们的数据集和benchmark表现出了推动改进混合3D重建和高质量渲染的robust和计算效率的潜力。
</details></li>
</ul>
<hr>
<h2 id="Fast-Sparse-3D-Convolution-Network-with-VDB"><a href="#Fast-Sparse-3D-Convolution-Network-with-VDB" class="headerlink" title="Fast Sparse 3D Convolution Network with VDB"></a>Fast Sparse 3D Convolution Network with VDB</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02762">http://arxiv.org/abs/2311.02762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fangjun Zhou, Anyong Mao, Eftychios Sifakis</li>
<li>for: 这个论文是为了提出一种新的卷积神经网络实现，用于高效地进行稀疏3D数据推理。</li>
<li>methods: 这个实现使用NanoVDB作为数据结构，以减少内存占用量，同时保持高性能。</li>
<li>results: 这个架构比STATE-OF-THE-ART dense CNN模型快得多，在高分辨率3D物体分类网络上达到了约20倍的速度提升。<details>
<summary>Abstract</summary>
We proposed a new Convolution Neural Network implementation optimized for sparse 3D data inference. This implementation uses NanoVDB as the data structure to store the sparse tensor. It leaves a relatively small memory footprint while maintaining high performance. We demonstrate that this architecture is around 20 times faster than the state-of-the-art dense CNN model on a high-resolution 3D object classification network.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的卷积神经网络实现，针对稀疏的3D数据推理。这种实现使用NanoVDB作为数据结构来存储稀疏张量。它占用较少的内存空间，同时保持高性能。我们示出这种架构比现有的密集 CNN 模型在高分辨率3D物体分类网络上20倍快。
</details></li>
</ul>
<hr>
<h2 id="Fast-Point-cloud-to-Mesh-Reconstruction-for-Deformable-Object-Tracking"><a href="#Fast-Point-cloud-to-Mesh-Reconstruction-for-Deformable-Object-Tracking" class="headerlink" title="Fast Point-cloud to Mesh Reconstruction for Deformable Object Tracking"></a>Fast Point-cloud to Mesh Reconstruction for Deformable Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02749">http://arxiv.org/abs/2311.02749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elham Amin Mansour, Hehui Zheng, Robert K. Katzschmann</li>
<li>for: 用于控制软体的机器人手，需要在线获取软体的状态反馈。</li>
<li>methods: 我们提出了一种方法，可以在58Hz的速度下创建不同类型的物体的塑形网格，并跟踪其变形。这种方法基于点云自动编码器和实数流变换器，可以在Marker-free的方式下进行系统标识。</li>
<li>results: 我们的方法可以在6种ycb类别中实现58Hz的塑形网格重建和跟踪，这些结果可以用于控制机器人手的 grasping操作，并且可以帮助系统进行 marker-free的系统标识。<details>
<summary>Abstract</summary>
The world around us is full of soft objects that we as humans learn to perceive and deform with dexterous hand movements from a young age. In order for a Robotic hand to be able to control soft objects, it needs to acquire online state feedback of the deforming object. While RGB-D cameras can collect occluded information at a rate of 30 Hz, the latter does not represent a continuously trackable object surface. Hence, in this work, we developed a method that can create deforming meshes of deforming point clouds at a speed of above 50 Hz for different categories of objects. The reconstruction of meshes from point clouds has been long studied in the field of Computer graphics under 3D reconstruction and 4D reconstruction, however both lack the speed and generalizability needed for robotics applications. Our model is designed using a point cloud auto-encoder and a Real-NVP architecture. The latter is a continuous flow neural network with manifold-preservation properties. Our model takes a template mesh which is the mesh of an object in its canonical state and then deforms the template mesh to match a deformed point cloud of the object. Our method can perform mesh reconstruction and tracking at a rate of 58 Hz for deformations of six different ycb categories. An instance of a downstream application can be the control algorithm for a robotic hand that requires online feedback from the state of a manipulated object which would allow online grasp adaptation in a closed-loop manner. Furthermore, the tracking capacity that our method provides can help in the system identification of deforming objects in a marker-free approach. In future work, we will extend our method to more categories of objects and real world deforming point clouds
</details>
<details>
<summary>摘要</summary>
世界中的软物体 surrounds 我们，从小时候我们就开始学习通过手部动作来感知和改变它们。如果机器人手需要控制软物体，它需要在线获取软物体的状态反馈。而RGB-D 摄像头可以在 30 Hz 频率上收集受障的信息，但这些信息不是可持续跟踪的物体表面。因此，在这项工作中，我们开发了一种方法，可以在不同类型物体上创建弹性的三角形结构，并在不同类型物体上进行不同类型的变形。我们的模型基于点云自编码器和真实NVP 架构。后者是一种连续流 neural network 具有 manifold-preservation 性能。我们的模型首先将模板三角形与弹性点云结构进行匹配，然后将模板三角形变形为与弹性点云结构匹配。我们的方法可以在 58 Hz 频率上进行三角形重建和跟踪，并且可以在不同类型的 ycb 类型上进行不同类型的变形。这种方法的实现可以用于 robotic 手的控制算法，以便在关闭环境中进行在线抓握适应。此外，我们的方法可以提供跟踪能力，帮助在无标记 Approach 中系统标识弹性物体。在未来的工作中，我们计划扩展我们的方法到更多的类型上，以及使用实际世界中的弹性点云结构。
</details></li>
</ul>
<hr>
<h2 id="Attention-Modules-Improve-Image-Level-Anomaly-Detection-for-Industrial-Inspection-A-DifferNet-Case-Study"><a href="#Attention-Modules-Improve-Image-Level-Anomaly-Detection-for-Industrial-Inspection-A-DifferNet-Case-Study" class="headerlink" title="Attention Modules Improve Image-Level Anomaly Detection for Industrial Inspection: A DifferNet Case Study"></a>Attention Modules Improve Image-Level Anomaly Detection for Industrial Inspection: A DifferNet Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02747">http://arxiv.org/abs/2311.02747</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/andreluizbvs/insplad">https://github.com/andreluizbvs/insplad</a></li>
<li>paper_authors: André Luiz Buarque Vieira e Silva, Francisco Simões, Danny Kowerko, Tobias Schlosser, Felipe Battisti, Veronica Teichrieb</li>
<li>for: 这篇论文主要针对于 semi-automated 视觉工业检测中的学习基于方法，以便处理高分辨率图像中的小型缺陷模式。</li>
<li>methods: 这篇论文提出了基于 DifferNet 的解决方案，其中包括了注意模块：AttentDifferNet。该方法可以提高图像水平的检测和分类能力，并在三个视觉异常检测数据集上达到了更高的Results：InsPLAD-fault、MVTec AD 和 Semiconductor Wafer。</li>
<li>results: 相比之前的状态艺术，AttentDifferNet 在三个数据集上的全局 AUROC 平均提高了1.77±0.25个百分点，达到了领先的Results，特别是在InsPLAD-fault 数据集上，这是一个工业检测在野数据集。<details>
<summary>Abstract</summary>
Within (semi-)automated visual industrial inspection, learning-based approaches for assessing visual defects, including deep neural networks, enable the processing of otherwise small defect patterns in pixel size on high-resolution imagery. The emergence of these often rarely occurring defect patterns explains the general need for labeled data corpora. To alleviate this issue and advance the current state of the art in unsupervised visual inspection, this work proposes a DifferNet-based solution enhanced with attention modules: AttentDifferNet. It improves image-level detection and classification capabilities on three visual anomaly detection datasets for industrial inspection: InsPLAD-fault, MVTec AD, and Semiconductor Wafer. In comparison to the state of the art, AttentDifferNet achieves improved results, which are, in turn, highlighted throughout our quali-quantitative study. Our quantitative evaluation shows an average improvement - compared to DifferNet - of 1.77 +/- 0.25 percentage points in overall AUROC considering all three datasets, reaching SOTA results in InsPLAD-fault, an industrial inspection in-the-wild dataset. As our variants to AttentDifferNet show great prospects in the context of currently investigated approaches, a baseline is formulated, emphasizing the importance of attention for industrial anomaly detection both in the wild and in controlled environments.
</details>
<details>
<summary>摘要</summary>
在半自动化visual工业检测中，基于学习的方法用于识别视觉缺陷，包括深度神经网络，可以处理高分辨率图像中的小缺陷模式。由于这些缺陷模式通常是罕见的，因此需要大量标注数据集。为了解决这个问题并提高现有状态的艺术，本研究提出了AttentDifferNet解决方案，它基于DifferNet框架并添加了注意模块。它在三个视觉异常检测数据集（InsPLAD-fault、MVTec AD和半导体晶圆）上提高了图像级检测和分类能力。与现有状态相比，AttentDifferNet实现了提高的结果，这些结果在我们的资深评估中得到了证明。我们的量化评估表明，相比DifferNet，AttentDifferNet在三个数据集上的总AUROC平均提高了1.77±0.25个百分点，在InsPLAD-fault中达到了领先的state-of-the-art results。我们的变体表明，AttentDifferNet在当前investigated的方法中具有极大的潜力。因此，我们形ulated一个基线，强调在工业异常检测中的注意力的重要性，不仅在控制环境中，而且在野外环境中。
</details></li>
</ul>
<hr>
<h2 id="Scenario-Diffusion-Controllable-Driving-Scenario-Generation-With-Diffusion"><a href="#Scenario-Diffusion-Controllable-Driving-Scenario-Generation-With-Diffusion" class="headerlink" title="Scenario Diffusion: Controllable Driving Scenario Generation With Diffusion"></a>Scenario Diffusion: Controllable Driving Scenario Generation With Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02738">http://arxiv.org/abs/2311.02738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ethan Pronovost, Meghana Reddy Ganesina, Noureldin Hendy, Zeyu Wang, Andres Morales, Kai Wang, Nicholas Roy</li>
<li>for: 用于验证自动驾驶汽车的安全性。</li>
<li>methods: 使用扩散方法生成交通场景，并同时生成 sintetic agent的姿势、方向和路径的分布。</li>
<li>results: 能够模拟多样化的交通模式，并在不同地区进行扩散。<details>
<summary>Abstract</summary>
Automated creation of synthetic traffic scenarios is a key part of validating the safety of autonomous vehicles (AVs). In this paper, we propose Scenario Diffusion, a novel diffusion-based architecture for generating traffic scenarios that enables controllable scenario generation. We combine latent diffusion, object detection and trajectory regression to generate distributions of synthetic agent poses, orientations and trajectories simultaneously. To provide additional control over the generated scenario, this distribution is conditioned on a map and sets of tokens describing the desired scenario. We show that our approach has sufficient expressive capacity to model diverse traffic patterns and generalizes to different geographical regions.
</details>
<details>
<summary>摘要</summary>
自动化创建人工交通情况场景是评估自动驾驶车辆（AV）的安全性的关键部分。在这篇论文中，我们提出了 Scenario Diffusion，一种基于扩散的架构，用于生成交通情况场景。我们将潜在扩散、物体检测和轨迹回归结合起来，同时生成 distribución 的 synthetic agent 姿势、方向和轨迹。为了提供更多的控制权，我们将这个分布 conditioned 于地图和 sets of tokens 描述所需的场景。我们示示了我们的方法具有 sufficient 的表达能力，能够模拟多样化的交通模式，并在不同的地理区域中泛化。
</details></li>
</ul>
<hr>
<h2 id="JRDB-Traj-A-Dataset-and-Benchmark-for-Trajectory-Forecasting-in-Crowds"><a href="#JRDB-Traj-A-Dataset-and-Benchmark-for-Trajectory-Forecasting-in-Crowds" class="headerlink" title="JRDB-Traj: A Dataset and Benchmark for Trajectory Forecasting in Crowds"></a>JRDB-Traj: A Dataset and Benchmark for Trajectory Forecasting in Crowds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02736">http://arxiv.org/abs/2311.02736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeed Saadatnejad, Yang Gao, Hamid Rezatofighi, Alexandre Alahi</li>
<li>for: 预测未来轨迹是自主导航中非常重要的，特别是在避免人类事故中，预测代理人的能力在先前是非常重要的。</li>
<li>methods: 作者提出了一个新的轨迹预测数据集，用于评估模型在实际场景中的性能，包括跟踪模块的偏差。</li>
<li>results: 数据集提供了各种感知输入数据，包括所有代理人的位置、场景图像和点云数据，以及预测未来代理人的位置。这个数据集可以帮助研究人员更好地理解导航动力学。<details>
<summary>Abstract</summary>
Predicting future trajectories is critical in autonomous navigation, especially in preventing accidents involving humans, where a predictive agent's ability to anticipate in advance is of utmost importance. Trajectory forecasting models, employed in fields such as robotics, autonomous vehicles, and navigation, face challenges in real-world scenarios, often due to the isolation of model components. To address this, we introduce a novel dataset for end-to-end trajectory forecasting, facilitating the evaluation of models in scenarios involving less-than-ideal preceding modules such as tracking. This dataset, an extension of the JRDB dataset, provides comprehensive data, including the locations of all agents, scene images, and point clouds, all from the robot's perspective. The objective is to predict the future positions of agents relative to the robot using raw sensory input data. It bridges the gap between isolated models and practical applications, promoting a deeper understanding of navigation dynamics. Additionally, we introduce a novel metric for assessing trajectory forecasting models in real-world scenarios where ground-truth identities are inaccessible, addressing issues related to undetected or over-detected agents. Researchers are encouraged to use our benchmark for model evaluation and benchmarking.
</details>
<details>
<summary>摘要</summary>
预测未来轨迹是自动导航中非常重要的，特别是避免人类事故，因为预测代理人的能力在先前是非常重要的。轨迹预测模型在机器人、自动驾驶和导航等领域中使用，但在实际场景中经常遇到挑战，常因模型组件孤立。为解决这个问题，我们介绍了一个新的轨迹预测数据集，用于评估模型在各种实际场景中的表现。这个数据集是JRDB数据集的扩展，提供了完整的数据，包括所有代理人的位置、场景图像和点云数据，全部是机器人的视角。目标是预测代理人未来与机器人之间的位置，使用原始感知输入数据。它bridges模型与实际应用之间的差距，促进了导航动力学的深入理解。此外，我们还引入了一种新的评价轨迹预测模型的指标，用于实际场景中评估模型表现，解决不可见或过度探测的代理人问题。研究人员可以使用我们的标准来评估和比较模型。
</details></li>
</ul>
<hr>
<h2 id="ISAR-A-Benchmark-for-Single-and-Few-Shot-Object-Instance-Segmentation-and-Re-Identification"><a href="#ISAR-A-Benchmark-for-Single-and-Few-Shot-Object-Instance-Segmentation-and-Re-Identification" class="headerlink" title="ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation and Re-Identification"></a>ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation and Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02734">http://arxiv.org/abs/2311.02734</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nicogorlo/isar_wacv24">https://github.com/nicogorlo/isar_wacv24</a></li>
<li>paper_authors: Nicolas Gorlo, Kenneth Blomqvist, Francesco Milano, Roland Siegwart</li>
<li>for: 这篇论文是为了提高单射对象检测、实例分割和重新识别的能力而写的。</li>
<li>methods: 这篇论文提出了一个基准方法和一个semi-synthetic数据集，以便测试和评估单射对象检测、实例分割和重新识别的算法。</li>
<li>results: 这篇论文提出了一个基准方法，并提供了一个 semi-synthetic 数据集和一个标准化评估管线，以便加速开发单射对象检测、实例分割和重新识别的算法。<details>
<summary>Abstract</summary>
Most object-level mapping systems in use today make use of an upstream learned object instance segmentation model. If we want to teach them about a new object or segmentation class, we need to build a large dataset and retrain the system. To build spatial AI systems that can quickly be taught about new objects, we need to effectively solve the problem of single-shot object detection, instance segmentation and re-identification. So far there is neither a method fulfilling all of these requirements in unison nor a benchmark that could be used to test such a method. Addressing this, we propose ISAR, a benchmark and baseline method for single- and few-shot object Instance Segmentation And Re-identification, in an effort to accelerate the development of algorithms that can robustly detect, segment, and re-identify objects from a single or a few sparse training examples. We provide a semi-synthetic dataset of video sequences with ground-truth semantic annotations, a standardized evaluation pipeline, and a baseline method. Our benchmark aligns with the emerging research trend of unifying Multi-Object Tracking, Video Object Segmentation, and Re-identification.
</details>
<details>
<summary>摘要</summary>
现代物品水平映射系统大多采用上游学习的物品实例分割模型。如果我们想教他们新的物品或分割类，我们需要建立大型数据集并重新训练系统。为建立快速教育新物品的空间AI系统，我们需要有效解决单次物品检测、实例分割和重新识别的问题。目前没有一种满足所有这些要求的方法，也没有一个可用来测试这种方法的标准测试 benchмарck。为此，我们提出了 ISAR，一个基准方法和测试集，用于单次和少量的物品实例分割和重新识别。我们提供了一个半 sintetic的视频序列数据集，以及一个标准化的评估管道和基准方法。我们的 benchmark 与涌现的研究趋势相吻合，即将多个物体跟踪、视频物体分割和重新识别相结合。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Estimation-for-Safety-critical-Scene-Segmentation-via-Fine-grained-Reward-Maximization"><a href="#Uncertainty-Estimation-for-Safety-critical-Scene-Segmentation-via-Fine-grained-Reward-Maximization" class="headerlink" title="Uncertainty Estimation for Safety-critical Scene Segmentation via Fine-grained Reward Maximization"></a>Uncertainty Estimation for Safety-critical Scene Segmentation via Fine-grained Reward Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02719">http://arxiv.org/abs/2311.02719</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/med-air/fgrm">https://github.com/med-air/fgrm</a></li>
<li>paper_authors: Hongzheng Yang, Cheng Chen, Yueyao Chen, Markus Scheppach, Hon Chi Yip, Qi Dou</li>
<li>for: 这个研究旨在提高深度 segmentation 模型在安全重要场景中的可靠性，特别是在医疗应用中。</li>
<li>methods: 我们提出了一个新的精细赏金 Maximum (FGRM) 框架，通过直接使用一个不确定度评估相关的奖励函数和一种可调整学习算法，以提高模型的不确定度评估。</li>
<li>results: 我们的方法在两个大规模的安全重要手术景象样本集上进行了实验，结果显示，我们的方法可以在实时一个前进对应中，以一个明显的优势在所有测量不确定度评估的标准做法中，而且可以保持高的任务准确度。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/med-air/FGRM%7D">https://github.com/med-air/FGRM}</a> 获取。<details>
<summary>Abstract</summary>
Uncertainty estimation plays an important role for future reliable deployment of deep segmentation models in safety-critical scenarios such as medical applications. However, existing methods for uncertainty estimation have been limited by the lack of explicit guidance for calibrating the prediction risk and model confidence. In this work, we propose a novel fine-grained reward maximization (FGRM) framework, to address uncertainty estimation by directly utilizing an uncertainty metric related reward function with a reinforcement learning based model tuning algorithm. This would benefit the model uncertainty estimation through direct optimization guidance for model calibration. Specifically, our method designs a new uncertainty estimation reward function using the calibration metric, which is maximized to fine-tune an evidential learning pre-trained segmentation model for calibrating prediction risk. Importantly, we innovate an effective fine-grained parameter update scheme, which imposes fine-grained reward-weighting of each network parameter according to the parameter importance quantified by the fisher information matrix. To the best of our knowledge, this is the first work exploring reward optimization for model uncertainty estimation in safety-critical vision tasks. The effectiveness of our method is demonstrated on two large safety-critical surgical scene segmentation datasets under two different uncertainty estimation settings. With real-time one forward pass at inference, our method outperforms state-of-the-art methods by a clear margin on all the calibration metrics of uncertainty estimation, while maintaining a high task accuracy for the segmentation results. Code is available at \url{https://github.com/med-air/FGRM}.
</details>
<details>
<summary>摘要</summary>
uncertainty estimation在未来安全critical scenario中的深度分割模型部署中扮演着重要的角色。然而，现有的uncertainty estimation方法受到了确定性评估的缺乏直接指导的问题。在这种情况下，我们提出了一种新的细化的奖励最大化（FGRM） Framework，以Address uncertainty estimation by directly using an uncertainty metric related reward function with a reinforcement learning based model tuning algorithm.这将通过直接优化指导来提高模型的uncertainty estimation。 Specifically, our method designs a new uncertainty estimation reward function using the calibration metric, which is maximized to fine-tune an evidential learning pre-trained segmentation model for calibrating prediction risk. Additionally, we innovate an effective fine-grained parameter update scheme, which imposes fine-grained reward-weighting of each network parameter according to the parameter importance quantified by the fisher information matrix. To the best of our knowledge, this is the first work exploring reward optimization for model uncertainty estimation in safety-critical vision tasks. Our method demonstrates effectiveness on two large safety-critical surgical scene segmentation datasets under two different uncertainty estimation settings, outperforming state-of-the-art methods by a clear margin on all calibration metrics of uncertainty estimation while maintaining a high task accuracy for segmentation results. Code is available at \url{https://github.com/med-air/FGRM}.
</details></li>
</ul>
<hr>
<h2 id="CycleCL-Self-supervised-Learning-for-Periodic-Videos"><a href="#CycleCL-Self-supervised-Learning-for-Periodic-Videos" class="headerlink" title="CycleCL: Self-supervised Learning for Periodic Videos"></a>CycleCL: Self-supervised Learning for Periodic Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03402">http://arxiv.org/abs/2311.03402</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Destro, Michael Gygli</li>
<li>for:  periodic video sequences 如 automatic production systems, remote sensing, medical applications, 或 physical training</li>
<li>methods:  CycleCL, a self-supervised learning method specifically designed for periodic data, using triplet loss to optimize for desired properties</li>
<li>results:  significantly outperforms previous video-based self-supervised learning methods on all tasks in industrial and human actions datasets<details>
<summary>Abstract</summary>
Analyzing periodic video sequences is a key topic in applications such as automatic production systems, remote sensing, medical applications, or physical training. An example is counting repetitions of a physical exercise. Due to the distinct characteristics of periodic data, self-supervised methods designed for standard image datasets do not capture changes relevant to the progression of the cycle and fail to ignore unrelated noise. They thus do not work well on periodic data. In this paper, we propose CycleCL, a self-supervised learning method specifically designed to work with periodic data. We start from the insight that a good visual representation for periodic data should be sensitive to the phase of a cycle, but be invariant to the exact repetition, i.e. it should generate identical representations for a specific phase throughout all repetitions. We exploit the repetitions in videos to design a novel contrastive learning method based on a triplet loss that optimizes for these desired properties. Our method uses pre-trained features to sample pairs of frames from approximately the same phase and negative pairs of frames from different phases. Then, we iterate between optimizing a feature encoder and resampling triplets, until convergence. By optimizing a model this way, we are able to learn features that have the mentioned desired properties. We evaluate CycleCL on an industrial and multiple human actions datasets, where it significantly outperforms previous video-based self-supervised learning methods on all tasks.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose CycleCL, a self-supervised learning method specifically designed for periodic data. We start from the insight that a good visual representation for periodic data should be sensitive to the phase of a cycle but be invariant to the exact repetition. In other words, it should generate identical representations for a specific phase throughout all repetitions.We exploit the repetitions in videos to design a novel contrastive learning method based on a triplet loss that optimizes for these desired properties. Our method uses pre-trained features to sample pairs of frames from approximately the same phase and negative pairs of frames from different phases. Then, we iterate between optimizing a feature encoder and resampling triplets until convergence. By optimizing a model this way, we are able to learn features that have the mentioned desired properties.We evaluate CycleCL on an industrial and multiple human actions datasets, where it significantly outperforms previous video-based self-supervised learning methods on all tasks.
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-a-Benchmark-How-Reliable-is-MS-COCO"><a href="#Benchmarking-a-Benchmark-How-Reliable-is-MS-COCO" class="headerlink" title="Benchmarking a Benchmark: How Reliable is MS-COCO?"></a>Benchmarking a Benchmark: How Reliable is MS-COCO?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02709">http://arxiv.org/abs/2311.02709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Zimmermann, Justin Szeto, Jerome Pasquero, Frederic Ratle</li>
<li>for: 本研究使用Sama-COCO dataset进行了可读性分析，以发现可能存在的偏见和偏好。</li>
<li>methods: 本研究使用了一个形态分析管道，以评估不同注释方式对模型的影响。</li>
<li>results: 结果表明注释风格对模型的性能有重要影响，并且注释管道应该仔细考虑任务的关键点。In English, that would be:</li>
<li>for: This study uses the Sama-COCO dataset to analyze the readability of the annotations and discover potential biases and preferences.</li>
<li>methods: The study uses a shape analysis pipeline to evaluate the impact of different annotation styles on the model’s performance.</li>
<li>results: The results show that the annotation style has a significant impact on the model’s performance, and the annotation pipeline should carefully consider the task of interest.<details>
<summary>Abstract</summary>
Benchmark datasets are used to profile and compare algorithms across a variety of tasks, ranging from image classification to segmentation, and also play a large role in image pretraining algorithms. Emphasis is placed on results with little regard to the actual content within the dataset. It is important to question what kind of information is being learned from these datasets and what are the nuances and biases within them. In the following work, Sama-COCO, a re-annotation of MS-COCO, is used to discover potential biases by leveraging a shape analysis pipeline. A model is trained and evaluated on both datasets to examine the impact of different annotation conditions. Results demonstrate that annotation styles are important and that annotation pipelines should closely consider the task of interest. The dataset is made publicly available at https://www.sama.com/sama-coco-dataset/ .
</details>
<details>
<summary>摘要</summary>
《Benchmark datasets are used to profile and compare algorithms across a variety of tasks, ranging from image classification to segmentation, and also play a large role in image pretraining algorithms. Emphasis is placed on results with little regard to the actual content within the dataset. It is important to question what kind of information is being learned from these datasets and what are the nuances and biases within them. In the following work, Sama-COCO, a re-annotation of MS-COCO, is used to discover potential biases by leveraging a shape analysis pipeline. A model is trained and evaluated on both datasets to examine the impact of different annotation conditions. Results demonstrate that annotation styles are important and that annotation pipelines should closely consider the task of interest. The dataset is made publicly available at https://www.sama.com/sama-coco-dataset/。》Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-Uncertainty-in-Polygon-Annotation-and-the-Impact-of-Quality-Assurance"><a href="#An-Empirical-Study-of-Uncertainty-in-Polygon-Annotation-and-the-Impact-of-Quality-Assurance" class="headerlink" title="An Empirical Study of Uncertainty in Polygon Annotation and the Impact of Quality Assurance"></a>An Empirical Study of Uncertainty in Polygon Annotation and the Impact of Quality Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02707">http://arxiv.org/abs/2311.02707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Zimmermann, Justin Szeto, Frederic Ratle</li>
<li>for: 这篇论文是为了研究多边形标注中的不确定性和质量控制的问题。</li>
<li>methods: 这篇论文使用了多边形标注的多评估程序，并对MS-COCO数据集中的一些对象进行了分析。</li>
<li>results: 研究结果表明，多边形标注的可靠性取决于评估程序和场景和形状的复杂性。<details>
<summary>Abstract</summary>
Polygons are a common annotation format used for quickly annotating objects in instance segmentation tasks. However, many real-world annotation projects request near pixel-perfect labels. While strict pixel guidelines may appear to be the solution to a successful project, practitioners often fail to assess the feasibility of the work requested, and overlook common factors that may challenge the notion of quality. This paper aims to examine and quantify the inherent uncertainty for polygon annotations and the role that quality assurance plays in minimizing its effect. To this end, we conduct an analysis on multi-rater polygon annotations for several objects from the MS-COCO dataset. The results demonstrate that the reliability of a polygon annotation is dependent on a reviewing procedure, as well as the scene and shape complexity.
</details>
<details>
<summary>摘要</summary>
多角形是常用的注释格式，用于快速标注对象在实例分割任务中。然而，许多实际项目需要非常精准的标注。虽然严格的像素指南可能看起来是成功项目的解决方案，但实际上，很多实践者会忽视标注工作的可行性和常见因素的影响。这篇论文旨在检查和评估多角形注释中的内在不确定性，以及质量控制在减少其影响的角色。为此，我们对 MS-COCO 数据集中的多个对象进行了多评人多角形注释的分析。结果表明，多角形注释的可靠性取决于评审过程和场景和形状复杂度。
</details></li>
</ul>
<hr>
<h2 id="A-Generative-Multi-Resolution-Pyramid-and-Normal-Conditioning-3D-Cloth-Draping"><a href="#A-Generative-Multi-Resolution-Pyramid-and-Normal-Conditioning-3D-Cloth-Draping" class="headerlink" title="A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth Draping"></a>A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth Draping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02700">http://arxiv.org/abs/2311.02700</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hunorlaczko/pyramid-drape">https://github.com/hunorlaczko/pyramid-drape</a></li>
<li>paper_authors: Hunor Laczkó, Meysam Madadi, Sergio Escalera, Jordi Gonzalez</li>
<li>for: 3D garment generation and draping</li>
<li>methods: conditional variational autoencoder with pyramid network and surface normal UV maps</li>
<li>results: robust, controllable, and state-of-the-art results with high generalization to unseen garments, poses, and shapes<details>
<summary>Abstract</summary>
RGB cloth generation has been deeply studied in the related literature, however, 3D garment generation remains an open problem. In this paper, we build a conditional variational autoencoder for 3D garment generation and draping. We propose a pyramid network to add garment details progressively in a canonical space, i.e. unposing and unshaping the garments w.r.t. the body. We study conditioning the network on surface normal UV maps, as an intermediate representation, which is an easier problem to optimize than 3D coordinates. Our results on two public datasets, CLOTH3D and CAPE, show that our model is robust, controllable in terms of detail generation by the use of multi-resolution pyramids, and achieves state-of-the-art results that can highly generalize to unseen garments, poses, and shapes even when training with small amounts of data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ChEF-A-Comprehensive-Evaluation-Framework-for-Standardized-Assessment-of-Multimodal-Large-Language-Models"><a href="#ChEF-A-Comprehensive-Evaluation-Framework-for-Standardized-Assessment-of-Multimodal-Large-Language-Models" class="headerlink" title="ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models"></a>ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02692">http://arxiv.org/abs/2311.02692</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/openlamm/lamm">https://github.com/openlamm/lamm</a></li>
<li>paper_authors: Zhelun Shi, Zhipin Wang, Hongxing Fan, Zhenfei Yin, Lu Sheng, Yu Qiao, Jing Shao</li>
<li>for: 本研究旨在提供一个普适的评估框架，以全面理解大型语言模型在多modal内容交互中的能力和局限性。</li>
<li>methods: 本研究提出了一个名为ChEF的全面评估框架，由四个组成部分组成：Scene（可扩展的多modal数据集）、Instruction（灵活的指令检索方程）、Inferencer（可靠的问题解答策略）和Metric（任务特定的分数函数）。这个框架可以标准化地评估不同的大型语言模型，并且可以根据不同的场景和需求设计新的评估方法。</li>
<li>results: 本研究通过对9种知名的大型语言模型在9个场景中进行大规模评估，总结了20多个有价值的观察，包括不同场景下大型语言模型的普适性和多modal交互需要的复合能力。这些观察可以帮助理解大型语言模型在多modal内容交互中的能力和局限性。<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) have shown impressive abilities in interacting with visual content with myriad potential downstream tasks. However, even though a list of benchmarks has been proposed, the capabilities and limitations of MLLMs are still not comprehensively understood, due to a lack of a standardized and holistic evaluation framework. To this end, we present the first Comprehensive Evaluation Framework (ChEF) that can holistically profile each MLLM and fairly compare different MLLMs. First, we structure ChEF as four modular components, i.e., Scenario as scalable multimodal datasets, Instruction as flexible instruction retrieving formulae, Inferencer as reliable question answering strategies, and Metric as indicative task-specific score functions. Based on them, ChEF facilitates versatile evaluations in a standardized framework, and new evaluations can be built by designing new Recipes (systematic selection of these four components). Notably, current MLLM benchmarks can be readily summarized as recipes of ChEF. Second, we introduce 6 new recipes to quantify competent MLLMs' desired capabilities (or called desiderata, i.e., calibration, in-context learning, instruction following, language performance, hallucination, and robustness) as reliable agents that can perform real-world multimodal interactions. Third, we conduct a large-scale evaluation of 9 prominent MLLMs on 9 scenarios and 6 desiderata. Our evaluation summarized over 20 valuable observations concerning the generalizability of MLLMs across various scenarios and the composite capability of MLLMs required for multimodal interactions. We will publicly release all the detailed implementations for further analysis, as well as an easy-to-use modular toolkit for the integration of new recipes and models, so that ChEF can be a growing evaluation framework for the MLLM community.
</details>
<details>
<summary>摘要</summary>
多modal大型语言模型（MLLMs）在与视觉内容互动中表现出了吸引人的能力，但是，即使有了一份标准的benchmark列表，MLLMs的能力和局限性仍未被全面了解，这是因为缺乏一个标准化和整体的评估框架。为此，我们提出了首个全面评估框架（ChEF），可以彻底评估每种MLLM，并公平比较不同的MLLMs。ChEF由四个可重复组件组成：Scene（可扩展的多模态数据集）、Instruction（灵活的指令检索方程）、Inferencer（可靠的问题回答策略）和Metric（任务特定的指标函数）。基于这些组件，ChEF提供了一个标准化的评估框架，并且可以通过设计新的Recipe（系统atic选择这些四个组件）来创建新的评估。值得注意的是，现有的MLLM benchmark可以被视为ChEF的recipe。我们还引入了6种新的recipe，用于评估MLLMs的需要的能力（或称为“欲望”，包括准确性、场景学习、指令遵从、语言表现、幻觉和稳定性）。然后，我们对9种知名MLLMs进行了大规模的评估，并对9个场景和6种欲望进行了评估。我们的评估结果表明，MLLMs在不同的场景下的一致性和多模态互动所需的复合能力是非常重要的。我们将在未来公布所有细节的实现，以及一个易于使用的模块化工具包，以便ChEF可以成为MLLM社区的发展评估框架。
</details></li>
</ul>
<hr>
<h2 id="Octavius-Mitigating-Task-Interference-in-MLLMs-via-MoE"><a href="#Octavius-Mitigating-Task-Interference-in-MLLMs-via-MoE" class="headerlink" title="Octavius: Mitigating Task Interference in MLLMs via MoE"></a>Octavius: Mitigating Task Interference in MLLMs via MoE</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02684">http://arxiv.org/abs/2311.02684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeren Chen, Ziqin Wang, Zhen Wang, Huayang Liu, Zhenfei Yin, Si Liu, Lu Sheng, Wanli Ouyang, Yu Qiao, Jing Shao</li>
<li>for: 本研究旨在探讨大型自然语言模型（LLM）在多Modal学习中的零shot扩展能力，以及在不同模式和下游任务中的性能影响。</li>
<li>methods: 我们提出了一种新的和可扩展的框架，called \mname，用于全面地研究多Modal学习中的多Modal大型自然语言模型（MLLM）。我们将mixture-of-experts（MoE）和一种代表性的PEFT技术LoRA结合，设计了一种基于LLM的新解码器，called LoRA-MoE，用于多Modal学习。</li>
<li>results: 我们的实验结果（大约20%提升）表明了我们的设计的效iveness和多样性在不同的2D和3D下游任务中。<details>
<summary>Abstract</summary>
Recent studies have demonstrated Large Language Models (LLMs) can extend their zero-shot generalization capabilities to multimodal learning through instruction tuning. As more modalities and downstream tasks are introduced, negative conflicts and interference may have a worse impact on performance. While this phenomenon has been overlooked in previous work, we propose a novel and extensible framework, called \mname, for comprehensive studies and experimentation on multimodal learning with Multimodal Large Language Models (MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and one of the representative PEFT techniques, \emph{i.e.,} LoRA, designing a novel LLM-based decoder, called LoRA-MoE, for multimodal learning. The experimental results (about 20\% improvement) have shown the effectiveness and versatility of our design in various 2D and 3D downstream tasks. Code and corresponding dataset will be available soon.
</details>
<details>
<summary>摘要</summary>
Specifically, we combine the well-known Mixture-of-Experts (MoE) and one of the representative PEFT techniques, i.e., LoRA, to design a novel LLM-based decoder, called LoRA-MoE, for multimodal learning. Our experimental results (with an improvement of around 20%) have shown the effectiveness and versatility of our design in various 2D and 3D downstream tasks. We will make the code and corresponding dataset available soon.
</details></li>
</ul>
<hr>
<h2 id="Digital-Typhoon-Long-term-Satellite-Image-Dataset-for-the-Spatio-Temporal-Modeling-of-Tropical-Cyclones"><a href="#Digital-Typhoon-Long-term-Satellite-Image-Dataset-for-the-Spatio-Temporal-Modeling-of-Tropical-Cyclones" class="headerlink" title="Digital Typhoon: Long-term Satellite Image Dataset for the Spatio-Temporal Modeling of Tropical Cyclones"></a>Digital Typhoon: Long-term Satellite Image Dataset for the Spatio-Temporal Modeling of Tropical Cyclones</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02665">http://arxiv.org/abs/2311.02665</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kitamoto-lab/digital-typhoon">https://github.com/kitamoto-lab/digital-typhoon</a></li>
<li>paper_authors: Asanobu Kitamoto, Jared Hwang, Bastien Vuillod, Lucas Gautier, Yingtao Tian, Tarin Clanuwat</li>
<li>For: The paper presents the official release of the Digital Typhoon dataset, a long-term spatio-temporal satellite image dataset for benchmarking machine learning models in the context of tropical cyclones.* Methods: The authors developed a workflow to create an infrared typhoon-centered image for cropping using Lambert azimuthal equal-area projection and addressed data quality issues such as inter-satellite calibration to create a homogeneous dataset.* Results: The benchmarking results on the analysis, forecasting, and reanalysis for the intensity suggest that the dataset is challenging for recent deep learning models, with many choices affecting the performance of various models.Here are the three points in Simplified Chinese text:* For: 这篇论文介绍了数字飓风数据集的官方发布，这是40多年的飓风卫星图像数据集，用于测试机器学习模型的长期空间时间数据处理能力。* Methods: 作者们开发了一个工作流程，使用拉曼投影将飓风中心的偏振图像进行裁剪，并对卫星数据进行了一系列的数据质量处理，以创建一个一致的数据集。* Results: 对于分析、预测和重建风速的测试结果表明，这个数据集对现代深度学习模型是一个挑战，因为有多种选择会影响不同模型的性能。<details>
<summary>Abstract</summary>
This paper presents the official release of the Digital Typhoon dataset, the longest typhoon satellite image dataset for 40+ years aimed at benchmarking machine learning models for long-term spatio-temporal data. To build the dataset, we developed a workflow to create an infrared typhoon-centered image for cropping using Lambert azimuthal equal-area projection referring to the best track data. We also address data quality issues such as inter-satellite calibration to create a homogeneous dataset. To take advantage of the dataset, we organized machine learning tasks by the types and targets of inference, with other tasks for meteorological analysis, societal impact, and climate change. The benchmarking results on the analysis, forecasting, and reanalysis for the intensity suggest that the dataset is challenging for recent deep learning models, due to many choices that affect the performance of various models. This dataset reduces the barrier for machine learning researchers to meet large-scale real-world events called tropical cyclones and develop machine learning models that may contribute to advancing scientific knowledge on tropical cyclones as well as solving societal and sustainability issues such as disaster reduction and climate change. The dataset is publicly available at http://agora.ex.nii.ac.jp/digital-typhoon/dataset/ and https://github.com/kitamoto-lab/digital-typhoon/.
</details>
<details>
<summary>摘要</summary>
这份论文发布了数字风暴数据集的官方发布，这是40多年的风暴卫星图像数据集，旨在为机器学习模型进行长期空间时间数据的benchmarking。为建立数据集，我们开发了一个工作流程，以拉姆伯特方程为基础，使用最佳轨迹数据来生成射电风暴中心图像进行剪辑。我们还解决了数据质量问题，如卫星间协调 calibration，以创建一个一致的数据集。为了利用这个数据集，我们组织了机器学习任务，按照不同的类型和目标进行定型，包括气象分析、社会影响和气候变化。结果表明，这个数据集对于现代深度学习模型来说是一个挑战，由于多种选择对不同模型的性能产生影响。这个数据集将降低机器学习研究人员面临大规模实际事件风暴预测和解决社会和可持续发展问题的障碍。这个数据集公共可用于http://agora.ex.nii.ac.jp/digital-typhoon/dataset/和https://github.com/kitamoto-lab/digital-typhoon/。
</details></li>
</ul>
<hr>
<h2 id="Enhanced-adaptive-cross-layer-scheme-for-low-latency-HEVC-streaming-over-Vehicular-Ad-hoc-Networks-VANETs"><a href="#Enhanced-adaptive-cross-layer-scheme-for-low-latency-HEVC-streaming-over-Vehicular-Ad-hoc-Networks-VANETs" class="headerlink" title="Enhanced adaptive cross-layer scheme for low latency HEVC streaming over Vehicular Ad-hoc Networks (VANETs)"></a>Enhanced adaptive cross-layer scheme for low latency HEVC streaming over Vehicular Ad-hoc Networks (VANETs)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02664">http://arxiv.org/abs/2311.02664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Aymen Labiod, Mohamed Gharbi, François-Xavier Coudoux, Patrick Corlay, Noureddine Doghmane</li>
<li>for: 高效视频传输在 Vehicular Ad-hoc Networks (VANET) 中实现了现实，但是这些网络具有变化的通道质量和有限的带宽。</li>
<li>methods: 提议一种低复杂度跨层机制，通过考虑视频编码过程中的时间预测结构、帧重要性和网络负载状态，将每个视频传输包分配到最适合的 Access Category (AC) 队列在 Medium Access Control (MAC) 层。</li>
<li>results: 对不同的低延迟视频通信场景进行了评估，结果显示，提议的机制可以在视频质量和总结束延迟方面提供显著的改进，与802.11p 的 Enhanced Distributed Channel Access (EDCA) 相比。同时，对服务质量 (QoS) 和用户体验质量 (QoE) 也进行了评估，以验证提议的方法。<details>
<summary>Abstract</summary>
Vehicular communication has become a reality guided by various applications. Among those, high video quality delivery with low latency constraints required by real-time applications constitutes a very challenging task. By dint of its never-before-achieved compression level, the new High-Efficiency Video Coding (HEVC) is very promising for real-time video streaming through Vehicular Ad-hoc Networks (VANET). However, these networks have variable channel quality and limited bandwidth. Therefore, ensuring satisfactory video quality on such networks is a major challenge. In this work, a low complexity cross-layer mechanism is proposed to improve end-to-end performances of HEVC video streaming in VANET under low delay constraints. The idea is to assign to each packet of the transmitted video the most appropriate Access Category (AC) queue on the Medium Access Control (MAC) layer, considering the temporal prediction structure of the video encoding process, the importance of the frame and the state of the network traffic load. Simulation results demonstrate that for different targeted low-delay video communication scenarios, the proposed mechanism offers significant improvements regarding video quality at the reception and end-to-end delay compared to the Enhanced Distributed Channel Access (EDCA) adopted in the 802.11p. Both Quality of Service (QoS) and Quality of Experience (QoE) evaluations have been also carried out to validate the proposed approach.
</details>
<details>
<summary>摘要</summary>
To overcome this challenge, we propose a low-complexity cross-layer mechanism that improves the end-to-end performance of HEVC video streaming in VANETs under low delay constraints. Our approach assigns the most appropriate Access Category (AC) queue on the Medium Access Control (MAC) layer to each packet of the transmitted video, taking into account the temporal prediction structure of the video encoding process, the importance of the frame, and the state of the network traffic load.Simulation results show that our proposed mechanism offers significant improvements in video quality at the reception and end-to-end delay compared to the Enhanced Distributed Channel Access (EDCA) adopted in the 802.11p standard, for different targeted low-delay video communication scenarios. We also conducted Quality of Service (QoS) and Quality of Experience (QoE) evaluations to validate our approach.
</details></li>
</ul>
<hr>
<h2 id="CCMR-High-Resolution-Optical-Flow-Estimation-via-Coarse-to-Fine-Context-Guided-Motion-Reasoning"><a href="#CCMR-High-Resolution-Optical-Flow-Estimation-via-Coarse-to-Fine-Context-Guided-Motion-Reasoning" class="headerlink" title="CCMR: High Resolution Optical Flow Estimation via Coarse-to-Fine Context-Guided Motion Reasoning"></a>CCMR: High Resolution Optical Flow Estimation via Coarse-to-Fine Context-Guided Motion Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02661">http://arxiv.org/abs/2311.02661</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cv-stuttgart/CCMR">https://github.com/cv-stuttgart/CCMR</a></li>
<li>paper_authors: Azin Jahedi, Maximilian Luz, Marc Rivinius, Andrés Bruhn</li>
<li>for: 高精度多尺度摄像机流计算</li>
<li>methods: 基于注意力的动量聚合概念，使用层次两步注意力基于上下文运动聚合策略，首先计算全尺度多尺度上下文特征，然后使用它们引导实际运动聚合。</li>
<li>results: 通过结合多尺度和注意力基于概念，提供了高精度的流场图，在 occluded 和 non-occluded 区域都显示出了强大改进，与单尺度注意力基本和多尺度注意力自由基eline比较，提高了23.0% 和 21.6%。并实现了 state-of-the-art 结果，在 KITTI 2015 和 MPI Sintel Clean and Final 上 ranking 第一和第二。<details>
<summary>Abstract</summary>
Attention-based motion aggregation concepts have recently shown their usefulness in optical flow estimation, in particular when it comes to handling occluded regions. However, due to their complexity, such concepts have been mainly restricted to coarse-resolution single-scale approaches that fail to provide the detailed outcome of high-resolution multi-scale networks. In this paper, we hence propose CCMR: a high-resolution coarse-to-fine approach that leverages attention-based motion grouping concepts to multi-scale optical flow estimation. CCMR relies on a hierarchical two-step attention-based context-motion grouping strategy that first computes global multi-scale context features and then uses them to guide the actual motion grouping. As we iterate both steps over all coarse-to-fine scales, we adapt cross covariance image transformers to allow for an efficient realization while maintaining scale-dependent properties. Experiments and ablations demonstrate that our efforts of combining multi-scale and attention-based concepts pay off. By providing highly detailed flow fields with strong improvements in both occluded and non-occluded regions, our CCMR approach not only outperforms both the corresponding single-scale attention-based and multi-scale attention-free baselines by up to 23.0% and 21.6%, respectively, it also achieves state-of-the-art results, ranking first on KITTI 2015 and second on MPI Sintel Clean and Final. Code and trained models are available at https://github.com/cv-stuttgart /CCMR.
</details>
<details>
<summary>摘要</summary>
听力基于的动作聚合概念在视力估计中最近几年得到了广泛应用，尤其是在处理 occluded 区域时。然而，由于其复杂性，这些概念通常只能在粗略分辨率单个级别上实现，无法提供高分辨率多级网络的详细结果。在这篇文章中，我们因此提出了 CCMR：一种高分辨率含级抽象方法，利用听力基于的动作聚合概念来实现多级视力估计。CCMR 利用一种层次两步听力基于的上下文动作聚合策略，首先计算全局多级上下文特征，然后使用它们引导实际动作聚合。我们在所有粗略抽象级别上迭代这两个步骤，并使用可变 covariance 图像变换器来实现高效实现，保持级别 dependent 性。实验和排除示出，我们的努力将多级和听力基于的概念结合起来了。通过提供具有强大改进的流场场景和非 occluded 区域，我们的 CCMR 方法不仅超过了对应的单个级别听力基于和无听力基于的基准值，还达到了状态机器人框架。代码和训练模型可以在 <https://github.com/cv-stuttgart/CCMR> 获取。
</details></li>
</ul>
<hr>
<h2 id="Region-of-Interest-ROI-based-adaptive-cross-layer-system-for-real-time-video-streaming-over-Vehicular-Ad-hoc-NETworks-VANETs"><a href="#Region-of-Interest-ROI-based-adaptive-cross-layer-system-for-real-time-video-streaming-over-Vehicular-Ad-hoc-NETworks-VANETs" class="headerlink" title="Region of Interest (ROI) based adaptive cross-layer system for real-time video streaming over Vehicular Ad-hoc NETworks (VANETs)"></a>Region of Interest (ROI) based adaptive cross-layer system for real-time video streaming over Vehicular Ad-hoc NETworks (VANETs)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02656">http://arxiv.org/abs/2311.02656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Aymen Labiod, Mohamed Gharbi, François-Xavier Coudoux, Patrick Corlay</li>
<li>for: 提高 vehicular video transmission质量以提高驾驶环境感知</li>
<li>methods: 使用 adaptive cross-layer mapping将 ROI视频数据包寄存到 IEEE 802.11p MAC 层，提高 HEVC 压缩视频通信质量</li>
<li>results: 实际 VANET 模拟结果显示，对 HEVC 压缩视频通信，提posed系统可以提供 UP TO 11dB PSNR 提升在 ROI 部分<details>
<summary>Abstract</summary>
Nowadays, real-time vehicle applications increasingly rely on video acquisition and processing to detect or even identify vehicles and obstacles in the driving environment. In this letter, we propose an algorithm that allows reinforcing these operations by improving end-to-end video transmission quality in a vehicular context. The proposed low complexity solution gives highest priority to the scene regions of interest (ROI) on which the perception of the driving environment is based on. This is done by applying an adaptive cross-layer mapping of the ROI visual data packets at the IEEE 802.11p MAC layer. Realistic VANET simulation results demonstrate that for HEVC compressed video communications, the proposed system offers PSNR gains up to 11dB on the ROI part.
</details>
<details>
<summary>摘要</summary>
现在，实时车辆应用越来越依赖于视频获取和处理来探测或识别在驾驶环境中的车辆和障碍物。在这封信中，我们提出了一种算法，可以通过提高端到端视频传输质量来增强这些操作。我们的低复杂度解决方案会将关键场景区域（ROI）的视频数据包在IEEE 802.11p MAC层进行适应性跨层映射。使用HEVC压缩视频通信后，我们的系统可以在ROI部分提供PSNR增幅达11dB。
</details></li>
</ul>
<hr>
<h2 id="Generative-Face-Video-Coding-Techniques-and-Standardization-Efforts-A-Review"><a href="#Generative-Face-Video-Coding-Techniques-and-Standardization-Efforts-A-Review" class="headerlink" title="Generative Face Video Coding Techniques and Standardization Efforts: A Review"></a>Generative Face Video Coding Techniques and Standardization Efforts: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02649">http://arxiv.org/abs/2311.02649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bolin Chen, Jie Chen, Shiqi Wang, Yan Ye<br>for: 这个论文主要探讨了最新的生成式面部视频编码（GFVC）技术的发展和标准化努力，以实现高质量的面部视频通信在ultra低带宽场景下。methods: 这篇论文将GFVC技术综合评估和总结，包括不同的GFVC算法和其对应的视觉表示方法，以及相关的标准化努力。results: 这篇论文总结了GFVC技术的发展前景和应用潜力，以及相关的挑战和机遇。<details>
<summary>Abstract</summary>
Generative Face Video Coding (GFVC) techniques can exploit the compact representation of facial priors and the strong inference capability of deep generative models, achieving high-quality face video communication in ultra-low bandwidth scenarios. This paper conducts a comprehensive survey on the recent advances of the GFVC techniques and standardization efforts, which could be applicable to ultra low bitrate communication, user-specified animation/filtering and metaverse-related functionalities. In particular, we generalize GFVC systems within one coding framework and summarize different GFVC algorithms with their corresponding visual representations. Moreover, we review the GFVC standardization activities that are specified with supplemental enhancement information messages. Finally, we discuss fundamental challenges and broad applications on GFVC techniques and their standardization potentials, as well as envision their future trends. The project page can be found at https://github.com/Berlin0610/Awesome-Generative-Face-Video-Coding.
</details>
<details>
<summary>摘要</summary>
generative face video coding（GFVC）技术可以利用面部先验的紧凑表示和深度生成模型的强大推理能力，实现高质量的面部视频通信在超低带宽场景下。这篇论文对最近的GFVC技术的进步和标准化努力进行了全面的报道，这些技术可以应用于超低位元率通信、用户指定的动画/滤波和元宇宙相关功能。具体来说，我们将GFVC系统划分到一个编码框架中，并将不同的GFVC算法与其相应的视觉表示进行总结。此外，我们还评论了GFVC的标准化活动，包括补充增强信息消息。最后，我们讨论了GFVC技术的基本挑战和广泛应用，以及其标准化潜力，以及未来趋势。项目页面可以在<https://github.com/Berlin0610/Awesome-Generative-Face-Video-Coding>找到。
</details></li>
</ul>
<hr>
<h2 id="An-Approach-for-Multi-Object-Tracking-with-Two-Stage-Min-Cost-Flow"><a href="#An-Approach-for-Multi-Object-Tracking-with-Two-Stage-Min-Cost-Flow" class="headerlink" title="An Approach for Multi-Object Tracking with Two-Stage Min-Cost Flow"></a>An Approach for Multi-Object Tracking with Two-Stage Min-Cost Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02642">http://arxiv.org/abs/2311.02642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huining Li, Yalong Jiang, Xianlin Zeng, Feng Li, Zhipeng Wang</li>
<li>for: 本 paper 的目的是提出一种two-stage tracking pipeline，用于精准地跟踪多个目标在视频中，并且可以减少 occlusion 的影响。</li>
<li>methods: 本 paper 使用 minimum network flow algorithm，并且利用 tracklets 的交叠和低信任探测来准确地定位不准确的 tracklets。在第一 stage，使用高信任探测作为输入，并使用交叠 mask 来准确地定位不准确的 tracklets。在第二 stage，使用低信任探测来修正不准确的 tracklets。</li>
<li>results: 本 paper 在多个popular MOT benchmark datasets上进行了 sufficient 的实验，并 achieved 78.4 MOTA on MOT16 test set, 79.2 on MOT17 test set, and 76.4 on MOT20 test set, 这表明提出的方法是有效的。<details>
<summary>Abstract</summary>
The minimum network flow algorithm is widely used in multi-target tracking. However, the majority of the present methods concentrate exclusively on minimizing cost functions whose values may not indicate accurate solutions under occlusions. In this paper, by exploiting the properties of tracklets intersections and low-confidence detections, we develop a two-stage tracking pipeline with an intersection mask that can accurately locate inaccurate tracklets which are corrected in the second stage. Specifically, we employ the minimum network flow algorithm with high-confidence detections as input in the first stage to obtain the candidate tracklets that need correction. Then we leverage the intersection mask to accurately locate the inaccurate parts of candidate tracklets. The second stage utilizes low-confidence detections that may be attributed to occlusions for correcting inaccurate tracklets. This process constructs a graph of nodes in inaccurate tracklets and low-confidence nodes and uses it for the second round of minimum network flow calculation. We perform sufficient experiments on popular MOT benchmark datasets and achieve 78.4 MOTA on the test set of MOT16, 79.2 on MOT17, and 76.4 on MOT20, which shows that the proposed method is effective.
</details>
<details>
<summary>摘要</summary>
“多目标追踪中 widely 使用最小网络流算法。然而，大多数现有方法仅专注于最小化成本函数的值，而不考虑 occlusions 的情况下的精度。在本文中，我们利用追踪碎片 intersection 和低信任探测的属性，开发了一个两阶段追踪管线，具有精度的找到不精度追踪碎片。具体来说，我们在第一阶段使用最小网络流算法高信任探测作为输入，以获取需要更正的候选追踪碎片。然后，我们利用碎片 intersection 属性来精确地找到不精度追踪碎片的不精度部分。第二阶段使用低信任探测，可能导因于 occlusions，来更正不精度追踪碎片。这个过程建立了一个网络格，其中的节点是不精度追踪碎片和低信任节点，并使用它们进行第二次最小网络流计算。我们对流行的 MOT 评分数据进行了丰富的实验，并在 MOT16 的评分数据上取得 78.4 MOTA，在 MOT17 上取得 79.2 MOTA，在 MOT20 上取得 76.4 MOTA，这表明我们的方法是有效的。”
</details></li>
</ul>
<hr>
<h2 id="The-Background-Also-Matters-Background-Aware-Motion-Guided-Objects-Discovery"><a href="#The-Background-Also-Matters-Background-Aware-Motion-Guided-Objects-Discovery" class="headerlink" title="The Background Also Matters: Background-Aware Motion-Guided Objects Discovery"></a>The Background Also Matters: Background-Aware Motion-Guided Objects Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02633">http://arxiv.org/abs/2311.02633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandra Kara, Hejer Ammar, Florian Chabot, Quoc-Cuong Pham</li>
<li>for: 提高对视频数据中物体发现的精度和效率</li>
<li>methods: 利用摄像头流计算出的运动mask，通过学习机制扩展到真正的背景和前景区域，并在物体发现过程中 JOINTLY 学习物体发现任务和物体&#x2F;非物体分离</li>
<li>results: 在 sintetic 和实际世界数据上进行了实验，结果表明，通过将我们的背景处理与多种前沿方法结合使用，可以大幅提高物体发现性能，并在物体&#x2F;非物体分离任务中建立强的基线。<details>
<summary>Abstract</summary>
Recent works have shown that objects discovery can largely benefit from the inherent motion information in video data. However, these methods lack a proper background processing, resulting in an over-segmentation of the non-object regions into random segments. This is a critical limitation given the unsupervised setting, where object segments and noise are not distinguishable. To address this limitation we propose BMOD, a Background-aware Motion-guided Objects Discovery method. Concretely, we leverage masks of moving objects extracted from optical flow and design a learning mechanism to extend them to the true foreground composed of both moving and static objects. The background, a complementary concept of the learned foreground class, is then isolated in the object discovery process. This enables a joint learning of the objects discovery task and the object/non-object separation. The conducted experiments on synthetic and real-world datasets show that integrating our background handling with various cutting-edge methods brings each time a considerable improvement. Specifically, we improve the objects discovery performance with a large margin, while establishing a strong baseline for object/non-object separation.
</details>
<details>
<summary>摘要</summary>
Our approach utilizes masks of moving objects extracted from optical flow and designs a learning mechanism to extend them to the true foreground, which includes both moving and static objects. The background, a complementary concept to the learned foreground class, is then isolated in the object discovery process. This enables joint learning of the object discovery task and object/non-object separation.Experiments on synthetic and real-world datasets show that integrating our background handling with various state-of-the-art methods consistently brings significant improvements in object discovery performance, while establishing a strong baseline for object/non-object separation. Specifically, we improve the objects discovery performance by a large margin, demonstrating the effectiveness of our proposed method.
</details></li>
</ul>
<hr>
<h2 id="Neural-Networks-Are-Implicit-Decision-Trees-The-Hierarchical-Simplicity-Bias"><a href="#Neural-Networks-Are-Implicit-Decision-Trees-The-Hierarchical-Simplicity-Bias" class="headerlink" title="Neural Networks Are Implicit Decision Trees: The Hierarchical Simplicity Bias"></a>Neural Networks Are Implicit Decision Trees: The Hierarchical Simplicity Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02622">http://arxiv.org/abs/2311.02622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhehang Du<br>for: This paper aims to investigate the phenomenon of simplicity bias in neural networks and explore how they rely on simpler features while ignoring more complex ones, even when the complex features are equally predictive.methods: The authors introduce a novel approach called imbalanced label coupling to study scenarios where simple and complex features exhibit different levels of predictive power. They train neural networks on these scenarios and analyze how the networks make predictions based on the ascending complexity of input features.results: The authors find that the trained networks make predictions that align with the ascending complexity of input features, regardless of the underlying predictive power. For example, even when simple spurious features distort predictions in CIFAR-10, the networks still learn core features. However, last-layer retraining with target data distribution is effective but insufficient to fully recover core features when spurious features are perfectly correlated with the target labels in the synthetic dataset. These findings provide direct evidence that neural networks learn core features in the presence of spurious features.<details>
<summary>Abstract</summary>
Neural networks exhibit simplicity bias; they rely on simpler features while ignoring equally predictive but more complex features. In this work, we introduce a novel approach termed imbalanced label coupling to investigate scenarios where simple and complex features exhibit different levels of predictive power. In these cases, complex features still contribute to predictions. The trained networks make predictions in alignment with the ascending complexity of input features according to how they correlate with the label in the training set, irrespective of the underlying predictive power. For instance, even when simple spurious features distort predictions in CIFAR-10, most cats are predicted to be dogs, and most trucks are predicted to be automobiles! This observation provides direct evidence that the neural network learns core features in the presence of spurious features. We empirically show that last-layer retraining with target data distribution is effective, yet insufficient to fully recover core features when spurious features are perfectly correlated with the target labels in our synthetic dataset. We hope our research contributes to a deeper understanding of the implicit bias of neural networks.
</details>
<details>
<summary>摘要</summary>
Note: The text has been translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="TFNet-Tuning-Fork-Network-with-Neighborhood-Pixel-Aggregation-for-Improved-Building-Footprint-Extraction"><a href="#TFNet-Tuning-Fork-Network-with-Neighborhood-Pixel-Aggregation-for-Improved-Building-Footprint-Extraction" class="headerlink" title="TFNet: Tuning Fork Network with Neighborhood Pixel Aggregation for Improved Building Footprint Extraction"></a>TFNet: Tuning Fork Network with Neighborhood Pixel Aggregation for Improved Building Footprint Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02617">http://arxiv.org/abs/2311.02617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ahmad Waseem, Muhammad Tahir, Zubair Khalid, Momin Uppal</li>
<li>for: 这 paper 考虑了从卫星影像中提取建筑物的问题，这是许多城市规划和决策应用中的关键任务。</li>
<li>methods: 该 paper 提出了一种新的 Tuning Fork Network (TFNet) 设计，用于深度 semantic segmentation，该设计不仅在广泛的建筑物上表现出色，还在 closely packed 的建筑物上表现良好。TFNet 架构包括一个单一的编码器和两个并行的解码器，用于分别重construct 建筑物的架构和建筑物的边缘。此外，TFNet 还 coupling 了一种在训练过程中在 tile 边界上 incorporating  neighbohood 信息的新方法。</li>
<li>results: 对 SpaceNet2、WHU 和一个来自卡拉χو（Pakistan）的 dataset 进行比较，提出的方法在所有三个 dataset 上显著地超越了参考方法。<details>
<summary>Abstract</summary>
This paper considers the problem of extracting building footprints from satellite imagery -- a task that is critical for many urban planning and decision-making applications. While recent advancements in deep learning have made great strides in automated detection of building footprints, state-of-the-art methods available in existing literature often generate erroneous results for areas with densely connected buildings. Moreover, these methods do not incorporate the context of neighborhood images during training thus generally resulting in poor performance at image boundaries. In light of these gaps, we propose a novel Tuning Fork Network (TFNet) design for deep semantic segmentation that not only performs well for widely-spaced building but also has good performance for buildings that are closely packed together. The novelty of TFNet architecture lies in a a single encoder followed by two parallel decoders to separately reconstruct the building footprint and the building edge. In addition, the TFNet design is coupled with a novel methodology of incorporating neighborhood information at the tile boundaries during the training process. This methodology further improves performance, especially at the tile boundaries. For performance comparisons, we utilize the SpaceNet2 and WHU datasets, as well as a dataset from an area in Lahore, Pakistan that captures closely connected buildings. For all three datasets, the proposed methodology is found to significantly outperform benchmark methods.
</details>
<details>
<summary>摘要</summary>
To address these limitations, we propose a novel Tuning Fork Network (TFNet) design for deep semantic segmentation. TFNet consists of a single encoder followed by two parallel decoders that separately reconstruct the building footprint and the building edge. Additionally, we introduce a novel methodology that incorporates neighborhood information at the tile boundaries during training, further improving performance, especially at the tile boundaries.We evaluate the proposed methodology on three datasets: SpaceNet2, WHU, and a dataset from Lahore, Pakistan, which captures closely connected buildings. Our results show that TFNet significantly outperforms benchmark methods on all three datasets.
</details></li>
</ul>
<hr>
<h2 id="Exploring-Grounding-Potential-of-VQA-oriented-GPT-4V-for-Zero-shot-Anomaly-Detection"><a href="#Exploring-Grounding-Potential-of-VQA-oriented-GPT-4V-for-Zero-shot-Anomaly-Detection" class="headerlink" title="Exploring Grounding Potential of VQA-oriented GPT-4V for Zero-shot Anomaly Detection"></a>Exploring Grounding Potential of VQA-oriented GPT-4V for Zero-shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02612">http://arxiv.org/abs/2311.02612</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhangzjn/GPT-4V-AD">https://github.com/zhangzjn/GPT-4V-AD</a></li>
<li>paper_authors: Jiangning Zhang, Xuhai Chen, Zhucun Xue, Yabiao Wang, Chengjie Wang, Yong Liu<br>for: 这篇论文探讨了使用Visual Question Answering(VQA) paradigm来实现零基础的视觉异常检测(AD)任务，并对MVTec AD和VisA数据集进行质量和量化评估。methods: 该模型使用Large Multimodal Model(LMM) GPT-4V，包括三个组成部分：1) 粒度地划分，2) 提问设计，3) Text2Segmentation，以便轻松进行量化评估。results: 该模型在零基础AD任务中可以达到certain的结果，例如在MVTec AD和VisA数据集上的图像级别AU-ROC为77.1&#x2F;88.0，像素级别AU-ROC为68.0&#x2F;76.6。然而，与零基础方法WinCLIP ann CLIP-AD的性能还有一定差距，需要进一步研究。<details>
<summary>Abstract</summary>
Large Multimodal Model (LMM) GPT-4V(ision) endows GPT-4 with visual grounding capabilities, making it possible to handle certain tasks through the Visual Question Answering (VQA) paradigm. This paper explores the potential of VQA-oriented GPT-4V in the recently popular visual Anomaly Detection (AD) and is the first to conduct qualitative and quantitative evaluations on the popular MVTec AD and VisA datasets. Considering that this task requires both image-/pixel-level evaluations, the proposed GPT-4V-AD framework contains three components: 1) Granular Region Division, 2) Prompt Designing, 3) Text2Segmentation for easy quantitative evaluation, and have made some different attempts for comparative analysis. The results show that GPT-4V can achieve certain results in the zero-shot AD task through a VQA paradigm, such as achieving image-level 77.1/88.0 and pixel-level 68.0/76.6 AU-ROCs on MVTec AD and VisA datasets, respectively. However, its performance still has a certain gap compared to the state-of-the-art zero-shot method, e.g., WinCLIP ann CLIP-AD, and further research is needed. This study provides a baseline reference for the research of VQA-oriented LMM in the zero-shot AD task, and we also post several possible future works. Code is available at \url{https://github.com/zhangzjn/GPT-4V-AD}.
</details>
<details>
<summary>摘要</summary>
大型多模式模型（LMM）GPT-4V（视觉）具有视觉基准功能，使得GPT-4可以通过视觉问答（VQA）模式处理某些任务。本文探讨GPT-4V在最近受欢迎的视觉异常检测（AD）任务中的潜力，是首次对流行的MVTec AD和VisA数据集进行质量和量化评估。因为这个任务需要图像/像素级评估，提出了三组件：1）粒度区划，2）提示设计，3）文本2分 segmentation，以便轻松进行量化评估。results显示，GPT-4V可以通过VQA模式在零基础AD任务中获得某些结果，如MVTec AD和VisA数据集上的图像级77.1/88.0和像素级68.0/76.6 AU-ROC。然而，其表现仍有一定差距 compared tostate-of-the-art零基础方法，如WinCLIP ann CLIP-AD，并且需要进一步研究。这些研究提供了VQA-oriented LMM在零基础AD任务的基线参考，并提出了一些可能的未来工作。代码可以在 \url{https://github.com/zhangzjn/GPT-4V-AD} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-3D-Point-Cloud-Classification-A-Systematic-Survey-and-Outlook"><a href="#Deep-Learning-based-3D-Point-Cloud-Classification-A-Systematic-Survey-and-Outlook" class="headerlink" title="Deep Learning-based 3D Point Cloud Classification: A Systematic Survey and Outlook"></a>Deep Learning-based 3D Point Cloud Classification: A Systematic Survey and Outlook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02608">http://arxiv.org/abs/2311.02608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huang Zhang, Changshuo Wang, Shengwei Tian, Baoli Lu, Liping Zhang, Xin Ning, Xiao Bai</li>
<li>for: 本研究的目的是为点云分类提供最新的研究进展和未来趋势，以帮助 relate fields 的研究人员。</li>
<li>methods: 本文回顾了点云数据的取得、特点和挑战，然后介绍了常用的3D数据表示方法、存储格式和点云分类的深度学习方法。</li>
<li>results: 本文对主要方法进行了比较和分析，并提出了一些挑战和未来趋势。In English, this would be:</li>
<li>for: The purpose of this paper is to provide the latest research progress and future trends in point cloud classification for researchers in related fields.</li>
<li>methods: The paper reviews point cloud acquisition, characteristics, and challenges, and then introduces commonly used datasets and deep learning-based methods for point cloud classification.</li>
<li>results: The paper compares and analyzes the performance of the main methods and discusses some challenges and future directions for point cloud classification.<details>
<summary>Abstract</summary>
In recent years, point cloud representation has become one of the research hotspots in the field of computer vision, and has been widely used in many fields, such as autonomous driving, virtual reality, robotics, etc. Although deep learning techniques have achieved great success in processing regular structured 2D grid image data, there are still great challenges in processing irregular, unstructured point cloud data. Point cloud classification is the basis of point cloud analysis, and many deep learning-based methods have been widely used in this task. Therefore, the purpose of this paper is to provide researchers in this field with the latest research progress and future trends. First, we introduce point cloud acquisition, characteristics, and challenges. Second, we review 3D data representations, storage formats, and commonly used datasets for point cloud classification. We then summarize deep learning-based methods for point cloud classification and complement recent research work. Next, we compare and analyze the performance of the main methods. Finally, we discuss some challenges and future directions for point cloud classification.
</details>
<details>
<summary>摘要</summary>
各种计算机视觉领域中的研究热点之一是点云表示，在自动驾驶、虚拟现实、机器人等领域都有广泛的应用。虽然深度学习技术在处理常见的2D网格图像数据上已经取得了很大的成功，但对于不规则、无结构的点云数据处理仍然存在很大的挑战。点云分类是点云分析的基础，许多深度学习基于的方法在这个任务中广泛使用。因此，本文的目的是为这个领域的研究人员提供最新的研究进展和未来趋势。首先，我们介绍点云获取、特点和挑战。其次，我们回顾3D数据表示、存储格式和常用的点云分类 dataset。然后，我们总结了深度学习基于的方法，并补充最近的研究工作。接着，我们比较和分析主要方法的性能。最后，我们讨论了点云分类的一些挑战和未来方向。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Implicit-Neural-Representations-from-Point-Clouds-via-Energy-Based-Models"><a href="#Optimizing-Implicit-Neural-Representations-from-Point-Clouds-via-Energy-Based-Models" class="headerlink" title="Optimizing Implicit Neural Representations from Point Clouds via Energy-Based Models"></a>Optimizing Implicit Neural Representations from Point Clouds via Energy-Based Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02601">http://arxiv.org/abs/2311.02601</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryutaro Yamauchi, Jinya Sakurai, Ryo Furukawa, Tatsushi Matsubayashi</li>
<li>for: 重建无旋转3D点云表面</li>
<li>methods: 使用能量基本模型优化卷积神经网络</li>
<li>results: 提高对点云噪声的耐性<details>
<summary>Abstract</summary>
Reconstructing a continuous surface from an unoritented 3D point cloud is a fundamental task in 3D shape processing. In recent years, several methods have been proposed to address this problem using implicit neural representations (INRs). In this study, we propose a method to optimize INRs using energy-based models (EBMs). By employing the absolute value of the coordinate-based neural networks as the energy function, the INR can be optimized through the estimation of the point cloud distribution by the EBM. In addition, appropriate parameter settings of the EBM enable the model to consider the magnitude of point cloud noise. Our experiments confirmed that the proposed method is more robust against point cloud noise than conventional surface reconstruction methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate english text into simplified chinese原文：Reconstructing a continuous surface from an unoriented 3D point cloud is a fundamental task in 3D shape processing. In recent years, several methods have been proposed to address this problem using implicit neural representations (INRs). In this study, we propose a method to optimize INRs using energy-based models (EBMs). By employing the absolute value of the coordinate-based neural networks as the energy function, the INR can be optimized through the estimation of the point cloud distribution by the EBM. In addition, appropriate parameter settings of the EBM enable the model to consider the magnitude of point cloud noise. Our experiments confirmed that the proposed method is more robust against point cloud noise than conventional surface reconstruction methods.翻译：建立一个连续的表面从无法指定的3D点云是3D形状处理中的基本任务。过去几年，一些方法被提出来解决这个问题使用隐藏神经网络表示（INR）。在这种研究中，我们提议使用能量基本模型（EBM）来优化INR。通过将坐标基本神经网络的绝对值作为能量函数，可以通过EBM估计点云分布，从而优化INR。此外，合适的EBM参数设置可以让模型考虑点云噪声的大小。我们的实验表明，我们提出的方法比传统表面重建方法更加鲁棒对待点云噪声。
</details></li>
</ul>
<hr>
<h2 id="Learning-Class-and-Domain-Augmentations-for-Single-Source-Open-Domain-Generalization"><a href="#Learning-Class-and-Domain-Augmentations-for-Single-Source-Open-Domain-Generalization" class="headerlink" title="Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization"></a>Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02599">http://arxiv.org/abs/2311.02599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prathmesh Bele, Valay Bundele, Avigyan Bhattacharya, Ankit Jha, Gemma Roig, Biplab Banerjee</li>
<li>for: 实现单源开放领域扩展（SS-ODG），解决训练时使用预订范围的标注范围，并在测试时遇到未知类别的挑战。</li>
<li>methods: 我们提出了一个名为SODG-Net的新框架，它同时生成新的领域和 pseudo-开放标本，使用学习型的目标函数，而不是常见的杂质混合策略。我们的方法通过增强多标本的多标本风格和生成多标本的多标本风格，从而提高扩展性。</li>
<li>results: 我们的SODG-Net在多个 benchmark 上进行了广泛的实验评估，与文献中的方法相比，它的表现都是superior。<details>
<summary>Abstract</summary>
Single-source open-domain generalization (SS-ODG) addresses the challenge of labeled source domains with supervision during training and unlabeled novel target domains during testing. The target domain includes both known classes from the source domain and samples from previously unseen classes. Existing techniques for SS-ODG primarily focus on calibrating source-domain classifiers to identify open samples in the target domain. However, these methods struggle with visually fine-grained open-closed data, often misclassifying open samples as closed-set classes. Moreover, relying solely on a single source domain restricts the model's ability to generalize. To overcome these limitations, we propose a novel framework called SODG-Net that simultaneously synthesizes novel domains and generates pseudo-open samples using a learning-based objective, in contrast to the ad-hoc mixing strategies commonly found in the literature. Our approach enhances generalization by diversifying the styles of known class samples using a novel metric criterion and generates diverse pseudo-open samples to train a unified and confident multi-class classifier capable of handling both open and closed-set data. Extensive experimental evaluations conducted on multiple benchmarks consistently demonstrate the superior performance of SODG-Net compared to the literature.
</details>
<details>
<summary>摘要</summary>
单源开放预测（SS-ODG）Addresses the challenge of labeled source domains with supervision during training and unlabeled novel target domains during testing. The target domain includes both known classes from the source domain and samples from previously unseen classes. Existing techniques for SS-ODG primarily focus on calibrating source-domain classifiers to identify open samples in the target domain, but these methods often struggle with visually fine-grained open-closed data, misclassifying open samples as closed-set classes. Moreover, relying solely on a single source domain restricts the model's ability to generalize. To overcome these limitations, we propose a novel framework called SODG-Net that simultaneously synthesizes novel domains and generates pseudo-open samples using a learning-based objective, rather than the ad-hoc mixing strategies commonly found in the literature. Our approach enhances generalization by diversifying the styles of known class samples using a novel metric criterion and generates diverse pseudo-open samples to train a unified and confident multi-class classifier capable of handling both open and closed-set data. Extensive experimental evaluations conducted on multiple benchmarks consistently demonstrate the superior performance of SODG-Net compared to the literature.
</details></li>
</ul>
<hr>
<h2 id="Synthetic-Tumor-Manipulation-With-Radiomics-Features"><a href="#Synthetic-Tumor-Manipulation-With-Radiomics-Features" class="headerlink" title="Synthetic Tumor Manipulation: With Radiomics Features"></a>Synthetic Tumor Manipulation: With Radiomics Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02586">http://arxiv.org/abs/2311.02586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Inye Na, Jonghun Kim, Hyunjin Park</li>
<li>for: 用于生成精度控制和个性化的肿瘤部分</li>
<li>methods: 使用生成对抗网络、基于 радиомιcs特征的conditioning、多任务学习</li>
<li>results: 能够生成多样化、真实的肿瘤图像，并且可以根据特定的 радиомιcs特征进行细致的调整<details>
<summary>Abstract</summary>
We introduce RadiomicsFill, a synthetic tumor generator conditioned on radiomics features, enabling detailed control and individual manipulation of tumor subregions. This conditioning leverages conventional high-dimensional features of the tumor (i.e., radiomics features) and thus is biologically well-grounded. Our model combines generative adversarial networks, radiomics-feature conditioning, and multi-task learning. Through experiments with glioma patients, RadiomicsFill demonstrated its capability to generate diverse, realistic tumors and its fine-tuning ability for specific radiomics features like 'Pixel Surface' and 'Shape Sphericity'. The ability of RadiomicsFill to generate an unlimited number of realistic synthetic tumors offers notable prospects for both advancing medical imaging research and potential clinical applications.
</details>
<details>
<summary>摘要</summary>
我们介绍RadiomicsFill，一个基于对射频特征的人工肿瘤生成器，允许详细控制和个别修改肿瘤子区域。这个conditioning leverages conventional高维ensional特征（即对射频特征），因此具有生物学基础。我们的模型结合生成对抗网络、对射频特征conditioning和多任务学习。通过对肿瘤病人进行实验，RadiomicsFill表现出它的能力将生成多样化、现实的肿瘤，并且可以根据特定对射频特征进行细化调整，例如'Pixel Surface'和'Shape Sphericity'。RadiomicsFill的能力生成无限多个真实的人工肿瘤提供了重要的前途，将推动医疗影像研究和 potential clinical应用。
</details></li>
</ul>
<hr>
<h2 id="SSL-DG-Rethinking-and-Fusing-Semi-supervised-Learning-and-Domain-Generalization-in-Medical-Image-Segmentation"><a href="#SSL-DG-Rethinking-and-Fusing-Semi-supervised-Learning-and-Domain-Generalization-in-Medical-Image-Segmentation" class="headerlink" title="SSL-DG: Rethinking and Fusing Semi-supervised Learning and Domain Generalization in Medical Image Segmentation"></a>SSL-DG: Rethinking and Fusing Semi-supervised Learning and Domain Generalization in Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02583">http://arxiv.org/abs/2311.02583</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yezanting/ssl-dg">https://github.com/yezanting/ssl-dg</a></li>
<li>paper_authors: Zanting Ye</li>
<li>for: 这个论文的目的是提出一种基于深度学习的医疗影像分类方法，以应对受限给annotated data的状况下，并且处理域shift问题。</li>
<li>methods: 本论文使用了semi-supervised learning（SSL）和domain generalization（DG）两种方法，具体来说是使用class-level representation来表示未见目标数据，并通过对数据进行增强，以实现cross-domain generalization。</li>
<li>results: 实验结果显示， compared withstate-of-the-art方法，本论文的方法在两个难度问题中表现出色，并且具有较好的一致性和可靠性。<details>
<summary>Abstract</summary>
Deep learning-based medical image segmentation is an essential yet challenging task in clinical practice, which arises from restricted access to annotated data coupled with the occurrence of domain shifts. Previous attempts have focused on isolated solutions, while disregarding their inter-connectedness. In this paper, we rethink the relationship between semi-supervised learning (SSL) and domain generalization (DG), which are the cutting-edge approaches to address the annotated data-driven constraints and the domain shift issues. Inspired by class-level representation, we show that unseen target data can be represented by a linear combination of source data, which can be achieved by simple data augmentation. The augmented data enrich domain distributions while having semantic consistency, aligning with the principles of consistency-based SSL. Accordingly, we propose SSL-DG, fusing DG and SSL, to achieve cross-domain generalization with limited annotations. Specifically, the global and focal region augmentation, together with an augmentation scale-balancing mechanism, are used to construct a mask-based domain diffusion augmentation module to significantly enrich domain diversity. In order to obtain consistent predictions for the same source data in different networks, we use uncertainty estimation and a deep mutual learning strategy to enforce the consistent constraint. Extensive experiments including ablation studies are designed to validate the proposed SSL-DG. The results demonstrate that our SSL-DG significantly outperforms state-of-the-art solutions in two challenging DG tasks with limited annotations. Code is available at https://github.com/yezanting/SSL-DG.
</details>
<details>
<summary>摘要</summary>
深度学习基于医疗图像分割是临床实践中的必要 yet 挑战任务，这是由于缺乏标注数据的限制和频繁出现的频率域变换所致。先前的尝试都是采取分立的方法，而忽视了它们之间的连接。在这篇论文中，我们重新考虑了 semi-supervised learning（SSL）和频率域泛化（DG）的关系，这两种是医疗图像分割的瓶颈和频率域变换问题的解决方案。受到类别表示的启发，我们表明了未经见过的目标数据可以通过简单的数据扩展表示为源数据的线性组合。扩展后的数据可以增强频率域分布，同时保持 semantic consistency，与SSL的原理相符。因此，我们提议SSL-DG，将DG和SSL融合，实现受限的标注的横向泛化。具体来说，我们使用全球和焦点区域扩展，加上扩展缩放机制，构建一个面具基于频率域扩散增强模块，以显著提高频率域分布的多样性。为确保不同的源数据在不同网络中的预测结果具有一致性，我们使用uncertainty估计和深度相互学习策略来强制一致性约束。我们进行了广泛的实验，包括简洁分析，以验证我们的SSL-DG。结果显示，我们的SSL-DG在两个挑战的DG任务中具有明显的优势，并且超过了当前的状况。代码可以在https://github.com/yezanting/SSL-DG上下载。
</details></li>
</ul>
<hr>
<h2 id="Group-Testing-for-Accurate-and-Efficient-Range-Based-Near-Neighbor-Search-An-Adaptive-Binary-Splitting-Approach"><a href="#Group-Testing-for-Accurate-and-Efficient-Range-Based-Near-Neighbor-Search-An-Adaptive-Binary-Splitting-Approach" class="headerlink" title="Group Testing for Accurate and Efficient Range-Based Near Neighbor Search : An Adaptive Binary Splitting Approach"></a>Group Testing for Accurate and Efficient Range-Based Near Neighbor Search : An Adaptive Binary Splitting Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02573">http://arxiv.org/abs/2311.02573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kashish Mittal, Harsh Shah, Ajit Rajwade</li>
<li>for: 这篇论文针对高维ensional Near Neighbor Search（NNS）问题提出了一个适应性的集群试验框架。</li>
<li>methods: 这篇论文使用了一个基于cosine距离的点积分法，不需要对库中的所有元素进行探索。它还使用了一个多阶分组试验算法，通过分成两个子集，然后逐步对每个子集进行点积分，以节省时间。</li>
<li>results: 实验结果显示，这篇论文的方法可以与排序搜寻相比，提高速度超过10倍，且精度与排序搜寻相同。此外，论文还提供了一个理论分析，详细阐述了预期的距离计算数量和pool中成员数量的关系。<details>
<summary>Abstract</summary>
This work presents an adaptive group testing framework for the range-based high dimensional near neighbor search problem. The proposed method detects high-similarity vectors from an extensive collection of high dimensional vectors, where each vector represents an image descriptor. Our method efficiently marks each item in the collection as neighbor or non-neighbor on the basis of a cosine distance threshold without exhaustive search. Like other methods in the domain of large scale retrieval, our approach exploits the assumption that most of the items in the collection are unrelated to the query. Unlike other methods, it does not assume a large difference between the cosine similarity of the query vector with the least related neighbor and that with the least unrelated non-neighbor. Following the procedure of binary splitting, a multi-stage adaptive group testing algorithm, we split the set of items to be searched into half at each step, and perform dot product tests on smaller and smaller subsets, many of which we are able to prune away. We experimentally show that our method achieves a speed-up over exhaustive search by a factor of more than ten with an accuracy same as that of exhaustive search, on a variety of large datasets. We present a theoretical analysis of the expected number of distance computations per query and the probability that a pool with a certain number of members will be pruned. In this way, our method exploits very useful and practical distributional properties unlike other methods. In our method, all required data structures are created purely offline. Moreover, our method does not impose any strong assumptions on the number of true near neighbors, is adaptible to streaming settings where new vectors are dynamically added to the database, and does not require any parameter tuning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multiple-Object-Tracking-based-on-Occlusion-Aware-Embedding-Consistency-Learning"><a href="#Multiple-Object-Tracking-based-on-Occlusion-Aware-Embedding-Consistency-Learning" class="headerlink" title="Multiple Object Tracking based on Occlusion-Aware Embedding Consistency Learning"></a>Multiple Object Tracking based on Occlusion-Aware Embedding Consistency Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02572">http://arxiv.org/abs/2311.02572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaoqi Hu, Axi Niu, Yu Zhu, Qingsen Yan, Jinqiu Sun, Yanning Zhang<br>for: 多bject tracking中的跟踪问题methods: 利用视觉嵌入的一致性来解决 occlusion 导致的跟踪中断results: 在不同 occlusion 场景下，实现了较高的跟踪性能<details>
<summary>Abstract</summary>
The Joint Detection and Embedding (JDE) framework has achieved remarkable progress for multiple object tracking. Existing methods often employ extracted embeddings to re-establish associations between new detections and previously disrupted tracks. However, the reliability of embeddings diminishes when the region of the occluded object frequently contains adjacent objects or clutters, especially in scenarios with severe occlusion. To alleviate this problem, we propose a novel multiple object tracking method based on visual embedding consistency, mainly including: 1) Occlusion Prediction Module (OPM) and 2) Occlusion-Aware Association Module (OAAM). The OPM predicts occlusion information for each true detection, facilitating the selection of valid samples for consistency learning of the track's visual embedding. The OAAM leverages occlusion cues and visual embeddings to generate two separate embeddings for each track, guaranteeing consistency in both unoccluded and occluded detections. By integrating these two modules, our method is capable of addressing track interruptions caused by occlusion in online tracking scenarios. Extensive experimental results demonstrate that our approach achieves promising performance levels in both unoccluded and occluded tracking scenarios.
</details>
<details>
<summary>摘要</summary>
“ JOINT DETECTION AND EMBEDDING (JDE) 框架在多对象跟踪中做出了卓越的进步。现有方法通常通过提取的嵌入来重新建立新检测和已经中断的跟踪之间的关系。然而，当 occlusion 区域包含邻近 объек 或垃圾物时，嵌入的可靠性会减退，特别是在严重 occlusion 的情况下。为了解决这个问题，我们提出了一种基于视觉嵌入一致性的多对象跟踪方法，包括：1） occlusion prediction module (OPM) 和 2） occlusion-aware association module (OAAM)。OPM 预测每个真实检测中的 occlusion 信息，使得选择有效样本进行嵌入一致学习跟踪的视觉嵌入。OAAM 利用 occlusion 迹象和视觉嵌入来生成每个跟踪的两个分开的嵌入，保证了在不Occluded 和 Occluded 检测场景下的一致性。通过这两个模块的结合，我们的方法可以在在线跟踪场景中解决由 occlusion 引起的跟踪中断。我们的实验结果表明，我们的方法在不Occluded 和 Occluded 跟踪场景下具有出色的表现。”
</details></li>
</ul>
<hr>
<h2 id="Rotation-Invariant-Transformer-for-Recognizing-Object-in-UAVs"><a href="#Rotation-Invariant-Transformer-for-Recognizing-Object-in-UAVs" class="headerlink" title="Rotation Invariant Transformer for Recognizing Object in UAVs"></a>Rotation Invariant Transformer for Recognizing Object in UAVs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02559">http://arxiv.org/abs/2311.02559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuoyi Chen, Mang Ye, Bo Du</li>
<li>for: 本研究的目标是提高UAV上的目标识别精度，特别是对于大角度变换的情况。</li>
<li>methods: 本研究提出了一种新的旋转不变性视Transformer（RotTrans），通过在特征层进行旋转操作来实现旋转不变性。此外，我们还设置了一种�variance constraint来确保原始特征与旋转后的特征之间的关系。</li>
<li>results: 我们的提出的RotTrans模型在最新的UAV数据集上进行测试，与当前状态的艺术得到了显著的改进，其中高度的MAP和Rank1分别提高了5.9%和4.8%。此外，我们的模型还在传统的城市摄像头上进行人重识别任务中表现竞争力强。特别是在ICCV 2021年的Multi-Modal Video Reasoning and Analyzing Competition中，我们的解决方案在UAV基于人重识别追踪上获得了第一名。<details>
<summary>Abstract</summary>
Recognizing a target of interest from the UAVs is much more challenging than the existing object re-identification tasks across multiple city cameras. The images taken by the UAVs usually suffer from significant size difference when generating the object bounding boxes and uncertain rotation variations. Existing methods are usually designed for city cameras, incapable of handing the rotation issue in UAV scenarios. A straightforward solution is to perform the image-level rotation augmentation, but it would cause loss of useful information when inputting the powerful vision transformer as patches. This motivates us to simulate the rotation operation at the patch feature level, proposing a novel rotation invariant vision transformer (RotTrans). This strategy builds on high-level features with the help of the specificity of the vision transformer structure, which enhances the robustness against large rotation differences. In addition, we design invariance constraint to establish the relationship between the original feature and the rotated features, achieving stronger rotation invariance. Our proposed transformer tested on the latest UAV datasets greatly outperforms the current state-of-the-arts, which is 5.9\% and 4.8\% higher than the highest mAP and Rank1. Notably, our model also performs competitively for the person re-identification task on traditional city cameras. In particular, our solution wins the first place in the UAV-based person re-recognition track in the Multi-Modal Video Reasoning and Analyzing Competition held in ICCV 2021. Code is available at https://github.com/whucsy/RotTrans.
</details>
<details>
<summary>摘要</summary>
recognizing a target of interest from UAVs is much more challenging than existing object re-identification tasks across multiple city cameras. The images taken by UAVs usually suffer from significant size difference when generating object bounding boxes and uncertain rotation variations. Existing methods are usually designed for city cameras, incapable of handling the rotation issue in UAV scenarios. A straightforward solution is to perform image-level rotation augmentation, but it would cause loss of useful information when inputting powerful vision transformer as patches. This motivates us to simulate the rotation operation at the patch feature level, proposing a novel rotation invariant vision transformer (RotTrans). This strategy builds on high-level features with the help of the specificity of the vision transformer structure, which enhances robustness against large rotation differences. In addition, we design invariance constraint to establish the relationship between the original feature and the rotated features, achieving stronger rotation invariance. Our proposed transformer tested on the latest UAV datasets greatly outperforms the current state-of-the-arts, which is 5.9% and 4.8% higher than the highest mAP and Rank1. Notably, our model also performs competitively for the person re-identification task on traditional city cameras. In particular, our solution wins the first place in the UAV-based person re-recognition track in the Multi-Modal Video Reasoning and Analyzing Competition held in ICCV 2021. Code is available at https://github.com/whucsy/RotTrans.
</details></li>
</ul>
<hr>
<h2 id="Multi-Agent-3D-Map-Reconstruction-and-Change-Detection-in-Microgravity-with-Free-Flying-Robots"><a href="#Multi-Agent-3D-Map-Reconstruction-and-Change-Detection-in-Microgravity-with-Free-Flying-Robots" class="headerlink" title="Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity with Free-Flying Robots"></a>Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity with Free-Flying Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02558">http://arxiv.org/abs/2311.02558</a></li>
<li>repo_url: None</li>
<li>paper_authors: Holly Dinkel, Julia Di, Jamie Santos, Keenan Albee, Paulo Borges, Marina Moreira, Oleg Alexandrov, Brian Coltin, Trey Smith</li>
<li>for: 这篇论文目标是为了帮助未来的宇航员使用自主飞行器进行宇宙站的维护和监测。</li>
<li>methods: 这篇论文使用了多代理协作地图建模和变化探测来帮助自主飞行器进行宇宙站的维护和监测。其中一个代理用于从图像和深度信息序列中重建宇宙站的3D模型。另一个代理用于定期扫描宇宙站环境，并与3D模型进行比较。</li>
<li>results: 这篇论文通过使用实际的图像和位置数据， validate了变化探测的有效性。<details>
<summary>Abstract</summary>
Assistive free-flyer robots autonomously caring for future crewed outposts -- such as NASA's Astrobee robots on the International Space Station (ISS) -- must be able to detect day-to-day interior changes to track inventory, detect and diagnose faults, and monitor the outpost status. This work presents a framework for multi-agent cooperative mapping and change detection to enable robotic maintenance of space outposts. One agent is used to reconstruct a 3D model of the environment from sequences of images and corresponding depth information. Another agent is used to periodically scan the environment for inconsistencies against the 3D model. Change detection is validated after completing the surveys using real image and pose data collected by Astrobee robots in a ground testing environment and from microgravity aboard the ISS. This work outlines the objectives, requirements, and algorithmic modules for the multi-agent reconstruction system, including recommendations for its use by assistive free-flyers aboard future microgravity outposts.
</details>
<details>
<summary>摘要</summary>
帮助自由飞行机器人在未来的人类殖民站上进行自主维护 -- 如 NASA 的 Astrobee 机器人在国际空站（ISS）上 -- 需要能够探测日常内部变化，跟踪库存、检测和诊断问题，以及监测站点状态。本文提出了多智能合作地图和变化检测框架，以启用机器人维护宇宙站。一个机器人用于从图像和相对深度信息序列中重建环境的3D模型。另一个机器人用于定期扫描环境，并与3D模型进行比较。变化检测的有效性通过在地面测试环境中收集的真实图像和姿态数据，以及在微重力环境中从 ISS 上收集的 Astrobee 机器人的数据进行验证。本文详细介绍了多智能重建系统的目标、要求和算法模块，并对未来微重力站点上的帮助自由飞行机器人使用这些系统提供建议。
</details></li>
</ul>
<hr>
<h2 id="IPVNet-Learning-Implicit-Point-Voxel-Features-for-Open-Surface-3D-Reconstruction"><a href="#IPVNet-Learning-Implicit-Point-Voxel-Features-for-Open-Surface-3D-Reconstruction" class="headerlink" title="IPVNet: Learning Implicit Point-Voxel Features for Open-Surface 3D Reconstruction"></a>IPVNet: Learning Implicit Point-Voxel Features for Open-Surface 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02552">http://arxiv.org/abs/2311.02552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Samiul Arshad, William J. Beksi</li>
<li>for: 重建三维开面（例如非水平的网格）是计算机视觉领域的一个未探讨的领域。</li>
<li>methods: 我们提出了一种基于学习的隐式方法（IPVNet），它可以在任意分辨率下重建目标。IPVNet 利用点云数据和其粗化的 voxel 对应物进行学习，可以减少artifacts。</li>
<li>results: 我们在synthetic和实际数据集上进行了实验，结果显示IPVNet 可以超越当前状态态的表现，同时生成的重建结果中减少了outlier。<details>
<summary>Abstract</summary>
Reconstruction of 3D open surfaces (e.g., non-watertight meshes) is an underexplored area of computer vision. Recent learning-based implicit techniques have removed previous barriers by enabling reconstruction in arbitrary resolutions. Yet, such approaches often rely on distinguishing between the inside and outside of a surface in order to extract a zero level set when reconstructing the target. In the case of open surfaces, this distinction often leads to artifacts such as the artificial closing of surface gaps. However, real-world data may contain intricate details defined by salient surface gaps. Implicit functions that regress an unsigned distance field have shown promise in reconstructing such open surfaces. Nonetheless, current unsigned implicit methods rely on a discretized representation of the raw data. This not only bounds the learning process to the representation's resolution, but it also introduces outliers in the reconstruction. To enable accurate reconstruction of open surfaces without introducing outliers, we propose a learning-based implicit point-voxel model (IPVNet). IPVNet predicts the unsigned distance between a surface and a query point in 3D space by leveraging both raw point cloud data and its discretized voxel counterpart. Experiments on synthetic and real-world public datasets demonstrates that IPVNet outperforms the state of the art while producing far fewer outliers in the resulting reconstruction.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>> computer vision 领域中，三维开 superficie 的重建（如非水平的 mesh）是一个未经充分探索的领域。 recent learning-based implicit technique 已经突破了之前的障碍，使得重建在任意分辨率中成为可能。然而，这些方法通常需要在重建目标时分辨内部和外部的区别，以提取zero level set。在开 superficie 中，这种分辨 often leads to artifacts such as artificially closing surface gaps。然而，实际数据可能包含细节定义的明显surface gaps。implicit function 表示一个无符号距离场，已经表现出重建开 superficie 的承诺。然而，当前的无符号 implicit method 仅仅基于原始数据的粗略表示。这不仅限制了学习过程的分辨率，而且也会导致重建中出现异常值。为了准确地重建开 superficie 无异常值，我们提出了学习基于点 cloud 和 Its 粗略 voxel 对应的点云点-voxel 模型（IPVNet）。IPVNet 可以在 3D 空间中预测一个表示点和查询点之间的 unsigned distance。实验表明，IPVNet 在实际和 Synthetic 公共数据集上超过了状态的艺术，同时生成的重建中减少了异常值的出现。
</details></li>
</ul>
<hr>
<h2 id="3D-Aware-Talking-Head-Video-Motion-Transfer"><a href="#3D-Aware-Talking-Head-Video-Motion-Transfer" class="headerlink" title="3D-Aware Talking-Head Video Motion Transfer"></a>3D-Aware Talking-Head Video Motion Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02549">http://arxiv.org/abs/2311.02549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haomiao Ni, Jiachen Liu, Yuan Xue, Sharon X. Huang</li>
<li>for: 生成一个新视频，具有原视频的人物表情和动作模式。</li>
<li>methods: 使用一个3D-aware talking-head video motion transfer network（Head3D），全面利用 sujet 视频中的多视图出现特征，并通过自动学习3D head geometry learning module 和 attention-based fusion network来生成合成视频。</li>
<li>results: 在两个公共的 talking-head 视频数据集上进行了广泛的实验，研究发现 Head3D 在实际 cross-identity 设定下比2D和3D先前艺术 superior，并且可以轻松地适应pose-controllable novel view synthesis任务。<details>
<summary>Abstract</summary>
Motion transfer of talking-head videos involves generating a new video with the appearance of a subject video and the motion pattern of a driving video. Current methodologies primarily depend on a limited number of subject images and 2D representations, thereby neglecting to fully utilize the multi-view appearance features inherent in the subject video. In this paper, we propose a novel 3D-aware talking-head video motion transfer network, Head3D, which fully exploits the subject appearance information by generating a visually-interpretable 3D canonical head from the 2D subject frames with a recurrent network. A key component of our approach is a self-supervised 3D head geometry learning module, designed to predict head poses and depth maps from 2D subject video frames. This module facilitates the estimation of a 3D head in canonical space, which can then be transformed to align with driving video frames. Additionally, we employ an attention-based fusion network to combine the background and other details from subject frames with the 3D subject head to produce the synthetic target video. Our extensive experiments on two public talking-head video datasets demonstrate that Head3D outperforms both 2D and 3D prior arts in the practical cross-identity setting, with evidence showing it can be readily adapted to the pose-controllable novel view synthesis task.
</details>
<details>
<summary>摘要</summary>
<SYS> translate("Motion transfer of talking-head videos involves generating a new video with the appearance of a subject video and the motion pattern of a driving video. Current methodologies primarily depend on a limited number of subject images and 2D representations, thereby neglecting to fully utilize the multi-view appearance features inherent in the subject video. In this paper, we propose a novel 3D-aware talking-head video motion transfer network, Head3D, which fully exploits the subject appearance information by generating a visually-interpretable 3D canonical head from the 2D subject frames with a recurrent network. A key component of our approach is a self-supervised 3D head geometry learning module, designed to predict head poses and depth maps from 2D subject video frames. This module facilitates the estimation of a 3D head in canonical space, which can then be transformed to align with driving video frames. Additionally, we employ an attention-based fusion network to combine the background and other details from subject frames with the 3D subject head to produce the synthetic target video. Our extensive experiments on two public talking-head video datasets demonstrate that Head3D outperforms both 2D and 3D prior arts in the practical cross-identity setting, with evidence showing it can be readily adapted to the pose-controllable novel view synthesis task.")</SYS>Here's the translation:现在的 talking-head 视频动作传输技术是生成一个新的视频，其视觉特征与源视频一致，而动作特征则与驱动视频一致。现有方法主要基于有限数量的源图像和2D表示，因此忽略了源视频中的多视图外观特征。在这篇论文中，我们提出了一种新的3D意识的 talking-head 视频动作传输网络，即 Head3D。我们的方法可以充分利用源视频中的外观信息，通过生成一个可见的3D抽象头来捕捉源视频中的头部pose和深度信息。我们还使用了一种注意力基于的融合网络，将背景和其他细节从源帧与3D主体头进行结合，以生成合成目标视频。我们的实验表明，Head3D在实际的交叉标识设定下，比2D和3D先前艺术高效，并且可以适应pose控制的新视图合成任务。
</details></li>
</ul>
<hr>
<h2 id="VR-NeRF-High-Fidelity-Virtualized-Walkable-Spaces"><a href="#VR-NeRF-High-Fidelity-Virtualized-Walkable-Spaces" class="headerlink" title="VR-NeRF: High-Fidelity Virtualized Walkable Spaces"></a>VR-NeRF: High-Fidelity Virtualized Walkable Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02542">http://arxiv.org/abs/2311.02542</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/EyefulTower">https://github.com/facebookresearch/EyefulTower</a></li>
<li>paper_authors: Linning Xu, Vasu Agrawal, William Laney, Tony Garcia, Aayush Bansal, Changil Kim, Samuel Rota Bulò, Lorenzo Porzi, Peter Kontschieder, Aljaž Božič, Dahua Lin, Michael Zollhöfer, Christian Richardt</li>
<li>for: 这篇论文的目的是为了建立一个高精度捕捉、模型重建和实时渲染的虚拟现实系统，用于游走空间的高精度捕捉和模型化。</li>
<li>methods: 这篇论文使用了一个自定义多摄像头架设，以高精度捕捉游走空间，并使用了一种新的感知颜色空间来学习准确的高dynamic range外观，以及一种高效的mipmapping机制来实现级别of detail渲染。</li>
<li>results: 这篇论文的结果表明，使用这种方法可以在 dual 2K$\times$2K 的全息VR分辨率上实现高精度渲染，并且可以在36Hz的刷新率下保持高品质。此外，论文还提供了一个高精度测试集，并与现有的基准相比较。<details>
<summary>Abstract</summary>
We present an end-to-end system for the high-fidelity capture, model reconstruction, and real-time rendering of walkable spaces in virtual reality using neural radiance fields. To this end, we designed and built a custom multi-camera rig to densely capture walkable spaces in high fidelity and with multi-view high dynamic range images in unprecedented quality and density. We extend instant neural graphics primitives with a novel perceptual color space for learning accurate HDR appearance, and an efficient mip-mapping mechanism for level-of-detail rendering with anti-aliasing, while carefully optimizing the trade-off between quality and speed. Our multi-GPU renderer enables high-fidelity volume rendering of our neural radiance field model at the full VR resolution of dual 2K$\times$2K at 36 Hz on our custom demo machine. We demonstrate the quality of our results on our challenging high-fidelity datasets, and compare our method and datasets to existing baselines. We release our dataset on our project website.
</details>
<details>
<summary>摘要</summary>
我们提出了一个终端系统，用于在虚拟现实中实时渲染可行空间，使用神经辐射场。为此，我们设计了一个专门的多摄像头笼体，用于高精度捕捉可行空间，并生成多视图高动态范围图像。我们在神经图形元素上添加了一个新的感知色彩空间，用于学习准确的高动态范围外观，并使用高效的压缩缩放机制，以实现级别化渲染。我们使用多卡GPU渲染器，实现高精度体积渲染我们的神经辐射场模型，并在双2K×2K分辨率和36Hz的自定义demo机器上实现。我们在我们的高精度数据集上证明了我们的结果质量，并与现有基准进行比较。我们将数据集上载到我们的项目网站。
</details></li>
</ul>
<hr>
<h2 id="Augment-the-Pairs-Semantics-Preserving-Image-Caption-Pair-Augmentation-for-Grounding-Based-Vision-and-Language-Models"><a href="#Augment-the-Pairs-Semantics-Preserving-Image-Caption-Pair-Augmentation-for-Grounding-Based-Vision-and-Language-Models" class="headerlink" title="Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation for Grounding-Based Vision and Language Models"></a>Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation for Grounding-Based Vision and Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02536">http://arxiv.org/abs/2311.02536</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amzn/augment-the-pairs-wacv2024">https://github.com/amzn/augment-the-pairs-wacv2024</a></li>
<li>paper_authors: Jingru Yi, Burak Uzkent, Oana Ignat, Zili Li, Amanmeet Garg, Xiang Yu, Linda Liu</li>
<li>for: 提高视觉语言模型的表现，具体来说是在准确地定位文本描述中提到的物体。</li>
<li>methods: 使用文本决定和无文本决定的数据增强策略，包括文本背景颜色噪声和水平旋转，以保持图像和文本之间的Semantic consistency。另外，我们还提出了基于受限的信号重建的新的数据增强策略，即像素级别的遮盲。</li>
<li>results: 通过对Flickr30k、referring expressions和GQA三个常用的数据集进行广泛的实验，我们的方法表现出了与现有状态艺术的高水平的表现，并且与CLIP大规模图像和语言数据集预训练的图像Encoder结合使用可以进一步提高表现。<details>
<summary>Abstract</summary>
Grounding-based vision and language models have been successfully applied to low-level vision tasks, aiming to precisely locate objects referred in captions. The effectiveness of grounding representation learning heavily relies on the scale of the training dataset. Despite being a useful data enrichment strategy, data augmentation has received minimal attention in existing vision and language tasks as augmentation for image-caption pairs is non-trivial. In this study, we propose a robust phrase grounding model trained with text-conditioned and text-unconditioned data augmentations. Specifically, we apply text-conditioned color jittering and horizontal flipping to ensure semantic consistency between images and captions. To guarantee image-caption correspondence in the training samples, we modify the captions according to pre-defined keywords when applying horizontal flipping. Additionally, inspired by recent masked signal reconstruction, we propose to use pixel-level masking as a novel form of data augmentation. While we demonstrate our data augmentation method with MDETR framework, the proposed approach is applicable to common grounding-based vision and language tasks with other frameworks. Finally, we show that image encoder pretrained on large-scale image and language datasets (such as CLIP) can further improve the results. Through extensive experiments on three commonly applied datasets: Flickr30k, referring expressions and GQA, our method demonstrates advanced performance over the state-of-the-arts with various metrics. Code can be found in https://github.com/amzn/augment-the-pairs-wacv2024.
</details>
<details>
<summary>摘要</summary>
围绕基于grounding的视觉语言模型的研究，我们提出了一种可靠的图像描述对应模型，使用文本条件和无条件数据增强来学习表示学习。具体来说，我们使用文本条件的颜色扰动和水平翻转来保证图像和描述的semantic consistency。为保证训练样本中的图像描述对应，我们在应用水平翻转时对描述进行修改。此外，我们受到最近的masked signal reconstruction的启发，提出了一种新的数据增强方法：像素级别的遮盲。我们通过对MDETR框架进行修改来示出我们的数据增强方法的可应用性。最后，我们表明通过使用大规模的图像和语言数据集（如CLIP）进行预训练，可以进一步提高结果。通过对Flickr30k、referring expressions和GQA等三个常用的数据集进行广泛的实验，我们的方法达到了与先前最佳的多种纪录。代码可以在https://github.com/amzn/augment-the-pairs-wacv2024中找到。
</details></li>
</ul>
<hr>
<h2 id="TokenMotion-Motion-Guided-Vision-Transformer-for-Video-Camouflaged-Object-Detection-Via-Learnable-Token-Selection"><a href="#TokenMotion-Motion-Guided-Vision-Transformer-for-Video-Camouflaged-Object-Detection-Via-Learnable-Token-Selection" class="headerlink" title="TokenMotion: Motion-Guided Vision Transformer for Video Camouflaged Object Detection Via Learnable Token Selection"></a>TokenMotion: Motion-Guided Vision Transformer for Video Camouflaged Object Detection Via Learnable Token Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02535">http://arxiv.org/abs/2311.02535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zifan Yu, Erfan Bank Tavakoli, Meida Chen, Suya You, Raghuveer Rao, Sanjeev Agarwal, Fengbo Ren</li>
<li>for: 提高视频掩体物体检测（VCOD）的性能，解决Texture相似性和Camera运动引起的难题。</li>
<li>methods: 使用 transformer 模型提取运动指导特征，通过学习 tokens 选择来提高 VCOD 性能。</li>
<li>results: 在 MoCA-Mask 数据集上评估，TMNet 实现了 VCOD 领域的状态可比性，相比 existed 状态可比性方法，提高了12.8%的Weighted F-度、8.4%的S-度和10.7%的Mean IoU。<details>
<summary>Abstract</summary>
The area of Video Camouflaged Object Detection (VCOD) presents unique challenges in the field of computer vision due to texture similarities between target objects and their surroundings, as well as irregular motion patterns caused by both objects and camera movement. In this paper, we introduce TokenMotion (TMNet), which employs a transformer-based model to enhance VCOD by extracting motion-guided features using a learnable token selection. Evaluated on the challenging MoCA-Mask dataset, TMNet achieves state-of-the-art performance in VCOD. It outperforms the existing state-of-the-art method by a 12.8% improvement in weighted F-measure, an 8.4% enhancement in S-measure, and a 10.7% boost in mean IoU. The results demonstrate the benefits of utilizing motion-guided features via learnable token selection within a transformer-based framework to tackle the intricate task of VCOD.
</details>
<details>
<summary>摘要</summary>
“视频掩体物体检测（VCOD）领域存在特殊挑战，主要是因为目标对象和周围环境的文本相似性，以及对象和摄像头运动导致的不规则运动模式。本文提出了TokenMotion（TMNet），利用 transformer 模型提取运动导向特征，通过学习式Token选择进行增强。在复杂的 MoCA-Mask 数据集上测试，TMNet  achieve 状态机器人-measure 的最佳性能，比既有状态机器人-measure 方法提高 12.8%，S-measure 提高 8.4%， mean IoU 提高 10.7%。结果表明，通过在 transformer 框架中使用学习式Token选择来捕捉运动导向特征，可以有效地解决 VCOD 领域中的复杂问题。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.CV_2023_11_05/" data-id="clpahu74b00mo3h88chib5u90" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.AI_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T12:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/cs.AI_2023_11_05/">cs.AI - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Modelling-Cellular-Perturbations-with-the-Sparse-Additive-Mechanism-Shift-Variational-Autoencoder"><a href="#Modelling-Cellular-Perturbations-with-the-Sparse-Additive-Mechanism-Shift-Variational-Autoencoder" class="headerlink" title="Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder"></a>Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02794">http://arxiv.org/abs/2311.02794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/insitro/sams-vae">https://github.com/insitro/sams-vae</a></li>
<li>paper_authors: Michael Bereket, Theofanis Karaletsos</li>
<li>For: This paper proposes a new method called SAMS-VAE for modeling the effects of diverse interventions on cells in order to characterize unknown biological mechanisms of action in drug discovery.* Methods: SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects, and sparsifies these global latent variables for individual perturbations to identify disentangled, perturbation-specific latent subspaces that are flexibly composable.* Results: SAMS-VAE outperforms comparable models in terms of generalization across in-distribution and out-of-distribution tasks, including a combinatorial reasoning task under resource paucity, and yields interpretable latent structures which correlate strongly to known biological mechanisms.Here is the same information in Simplified Chinese text:* For: 这篇论文提出了一种新的方法called SAMS-VAE，用于模型不同干预对细胞的影响，以Characterize unknown biological mechanisms of action in drug discovery。* Methods: SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects，并将这些全球隐变量简化为具体的干预特定隐变空间，以便可以flexibly composable。* Results: SAMS-VAE比相关的模型在不同的任务上表现出色，包括资源缺乏下的combined reasoning任务，并且生成了可解释的隐变结构，与知道的生物机制强相关。<details>
<summary>Abstract</summary>
Generative models of observations under interventions have been a vibrant topic of interest across machine learning and the sciences in recent years. For example, in drug discovery, there is a need to model the effects of diverse interventions on cells in order to characterize unknown biological mechanisms of action. We propose the Sparse Additive Mechanism Shift Variational Autoencoder, SAMS-VAE, to combine compositionality, disentanglement, and interpretability for perturbation models. SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects. Crucially, SAMS-VAE sparsifies these global latent variables for individual perturbations to identify disentangled, perturbation-specific latent subspaces that are flexibly composable. We evaluate SAMS-VAE both quantitatively and qualitatively on a range of tasks using two popular single cell sequencing datasets. In order to measure perturbation-specific model-properties, we also introduce a framework for evaluation of perturbation models based on average treatment effects with links to posterior predictive checks. SAMS-VAE outperforms comparable models in terms of generalization across in-distribution and out-of-distribution tasks, including a combinatorial reasoning task under resource paucity, and yields interpretable latent structures which correlate strongly to known biological mechanisms. Our results suggest SAMS-VAE is an interesting addition to the modeling toolkit for machine learning-driven scientific discovery.
</details>
<details>
<summary>摘要</summary>
“生成干预测数据的模型在机器学习和科学领域中具有很大的兴趣，例如药物探索中需要模型不同类型的干预效应以描述未知生物机制。我们提出了对compose, disentangle和可解释性具有优势的SAMS-VAE模型，用于干预模型。SAMS-VAE将批处数据的latent state视为受到干预的sample专有的本地 latent variable和稀有的全球 latent variable，并将这些全球 latent variable压缩以归一化干预效应。我们通过两个受欢迎的单细胞测量数据集进行评估，并提出了基于对干预模型的平均治疗效应的评估框架，以及与后 posterior predictive checks 的连结。SAMS-VAE在不同任务中表现出色，包括资源缺乏下的构成逻辑任务，并具有可解释的latent结构，与生物机制具有强相关。我们的结果显示SAMS-VAE是机器学习驱动科学探索的有趣添加。”
</details></li>
</ul>
<hr>
<h2 id="CausalCite-A-Causal-Formulation-of-Paper-Citations"><a href="#CausalCite-A-Causal-Formulation-of-Paper-Citations" class="headerlink" title="CausalCite: A Causal Formulation of Paper Citations"></a>CausalCite: A Causal Formulation of Paper Citations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02790">http://arxiv.org/abs/2311.02790</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/causalnlp/causal-cite">https://github.com/causalnlp/causal-cite</a></li>
<li>paper_authors: Ishan Kumar, Zhijing Jin, Ehsan Mokhtarian, Siyuan Guo, Yuen Chen, Negar Kiyavash, Mrinmaya Sachan, Bernhard Schoelkopf</li>
<li>for: 这 paper 的目的是提出一种 causal inference 方法，用于评估科学论文的影响力。</li>
<li>methods: 该方法基于高维文本嵌入，使用 LLMs 对每篇论文进行编码，然后通过cosine similarity提取相似样本，并使用这些样本的权重平均值 Synthesize 一个 counterfactual 样本。</li>
<li>results: 该方法可以准确地评估论文的影响力，并且具有高相关性和稳定性。 authors 还提供了一些建议，用于未来的研究人员可以更好地使用该 metric。 code 和数据可以在 <a target="_blank" rel="noopener" href="https://github.com/causalNLP/causal-cite">https://github.com/causalNLP/causal-cite</a> 上获取。<details>
<summary>Abstract</summary>
Evaluating the significance of a paper is pivotal yet challenging for the scientific community. While the citation count is the most commonly used proxy for this purpose, they are widely criticized for failing to accurately reflect a paper's true impact. In this work, we propose a causal inference method, TextMatch, which adapts the traditional matching framework to high-dimensional text embeddings. Specifically, we encode each paper using the text embeddings by large language models (LLMs), extract similar samples by cosine similarity, and synthesize a counterfactual sample by the weighted average of similar papers according to their similarity values. We apply the resulting metric, called CausalCite, as a causal formulation of paper citations. We show its effectiveness on various criteria, such as high correlation with paper impact as reported by scientific experts on a previous dataset of 1K papers, (test-of-time) awards for past papers, and its stability across various sub-fields of AI. We also provide a set of findings that can serve as suggested ways for future researchers to use our metric for a better understanding of a paper's quality. Our code and data are at https://github.com/causalNLP/causal-cite.
</details>
<details>
<summary>摘要</summary>
评估一篇论文的重要性是科学社区中的一项核心任务，但是也是一项具有挑战性的任务。虽然引用数是最常用的代理，但它们被广泛批评因为不能准确反映论文的真实影响。在这种情况下，我们提出了一种 causal inference 方法，即 TextMatch，该方法将传统的匹配框架应用到高维文本嵌入。具体来说，我们使用大型自然语言模型（LLM）生成的文本嵌入来编码每篇论文，然后通过cosinus相似性来提取相似的样本，并使用这些样本的相似性值来权重混合这些相似的论文。我们称这种度量为 CausalCite，它是一种用于评估论文引用的 causal 形式。我们在不同的评估标准下显示了 CausalCite 的有效性，包括高相关性与论文影响力（由科学专家在过去的数据集上提供的）、奖励、以及在不同的人工智能子领域中的稳定性。我们还提供了一些发现，可以帮助未来的研究人员通过我们的度量来更好地理解一篇论文的质量。我们的代码和数据可以在 GitHub 上找到：https://github.com/causalNLP/causal-cite。
</details></li>
</ul>
<hr>
<h2 id="Make-a-Donut-Language-Guided-Hierarchical-EMD-Space-Planning-for-Zero-shot-Deformable-Object-Manipulation"><a href="#Make-a-Donut-Language-Guided-Hierarchical-EMD-Space-Planning-for-Zero-shot-Deformable-Object-Manipulation" class="headerlink" title="Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation"></a>Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02787">http://arxiv.org/abs/2311.02787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang You, Bokui Shen, Congyue Deng, Haoran Geng, He Wang, Leonidas Guibas</li>
<li>for: 这个论文的目的是解决机器人 manipulate 弹性对象的问题，这是机器人学中最吸引人又最困难的问题。</li>
<li>methods: 这个论文使用了大语言模型（LLM）来提出一个没有示范的层次规划方法，可以解决复杂的长期任务。每个阶段都有工具和子目标，使用了DiffPhysics-P2P损失函数和地球运动距离（EMD）空间来优化预测控制策略。</li>
<li>results: 实验结果表明，这种方法在糖体 manipulate 任务中表现出色，包括短期和长期任务。它还能够Robustly 扩展到未经示范的复杂任务。<details>
<summary>Abstract</summary>
Deformable object manipulation stands as one of the most captivating yet formidable challenges in robotics. While previous techniques have predominantly relied on learning latent dynamics through demonstrations, typically represented as either particles or images, there exists a pertinent limitation: acquiring suitable demonstrations, especially for long-horizon tasks, can be elusive. Moreover, basing learning entirely on demonstrations can hamper the model's ability to generalize beyond the demonstrated tasks. In this work, we introduce a demonstration-free hierarchical planning approach capable of tackling intricate long-horizon tasks without necessitating any training. We employ large language models (LLMs) to articulate a high-level, stage-by-stage plan corresponding to a specified task. For every individual stage, the LLM provides both the tool's name and the Python code to craft intermediate subgoal point clouds. With the tool and subgoal for a particular stage at our disposal, we present a granular closed-loop model predictive control strategy. This leverages Differentiable Physics with Point-to-Point correspondence (DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied iteratively. Experimental findings affirm that our technique surpasses multiple benchmarks in dough manipulation, spanning both short and long horizons. Remarkably, our model demonstrates robust generalization capabilities to novel and previously unencountered complex tasks without any preliminary demonstrations. We further substantiate our approach with experimental trials on real-world robotic platforms.
</details>
<details>
<summary>摘要</summary>
manipulate 非常复杂的物体stood as one of the most captivating yet formidable challenges in robotics. While previous techniques have predominantly relied on learning latent dynamics through demonstrations, typically represented as either particles or images, there exists a pertinent limitation: acquiring suitable demonstrations, especially for long-horizon tasks, can be elusive. Moreover, basing learning entirely on demonstrations can hamper the model's ability to generalize beyond the demonstrated tasks. In this work, we introduce a demonstration-free hierarchical planning approach capable of tackling intricate long-horizon tasks without necessitating any training. We employ large language models (LLMs) to articulate a high-level, stage-by-stage plan corresponding to a specified task. For every individual stage, the LLM provides both the tool's name and the Python code to craft intermediate subgoal point clouds. With the tool and subgoal for a particular stage at our disposal, we present a granular closed-loop model predictive control strategy. This leverages Differentiable Physics with Point-to-Point correspondence (DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied iteratively. Experimental findings affirm that our technique surpasses multiple benchmarks in dough manipulation, spanning both short and long horizons. Remarkably, our model demonstrates robust generalization capabilities to novel and previously unencountered complex tasks without any preliminary demonstrations. We further substantiate our approach with experimental trials on real-world robotic platforms.
</details></li>
</ul>
<hr>
<h2 id="Towards-Generic-Anomaly-Detection-and-Understanding-Large-scale-Visual-linguistic-Model-GPT-4V-Takes-the-Lead"><a href="#Towards-Generic-Anomaly-Detection-and-Understanding-Large-scale-Visual-linguistic-Model-GPT-4V-Takes-the-Lead" class="headerlink" title="Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes the Lead"></a>Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes the Lead</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02782">http://arxiv.org/abs/2311.02782</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/caoyunkang/GPT4V-for-Generic-Anomaly-Detection">https://github.com/caoyunkang/GPT4V-for-Generic-Anomaly-Detection</a></li>
<li>paper_authors: Yunkang Cao, Xiaohao Xu, Chen Sun, Xiaonan Huang, Weiming Shen</li>
<li>for: 这个研究旨在应用GPT-4V（视力语言模型）来进行一般化的偏常探测任务。</li>
<li>methods: 这个研究使用GPT-4V模型进行多modal, multi-domain偏常探测任务，包括图像、影片、点 cloud和时间序列数据，并涵盖了不同的应用领域，如工业、医疗、逻辑、影片、3D偏常探测和位置任务。</li>
<li>results: GPT-4V在zero&#x2F;one-shot偏常探测中显示出了高效的探测和解释全球和细部 semantic 模式，实现了精准地区别 normal 和偏常的分别。<details>
<summary>Abstract</summary>
Anomaly detection is a crucial task across different domains and data types. However, existing anomaly detection models are often designed for specific domains and modalities. This study explores the use of GPT-4V(ision), a powerful visual-linguistic model, to address anomaly detection tasks in a generic manner. We investigate the application of GPT-4V in multi-modality, multi-domain anomaly detection tasks, including image, video, point cloud, and time series data, across multiple application areas, such as industrial, medical, logical, video, 3D anomaly detection, and localization tasks. To enhance GPT-4V's performance, we incorporate different kinds of additional cues such as class information, human expertise, and reference images as prompts.Based on our experiments, GPT-4V proves to be highly effective in detecting and explaining global and fine-grained semantic patterns in zero/one-shot anomaly detection. This enables accurate differentiation between normal and abnormal instances. Although we conducted extensive evaluations in this study, there is still room for future evaluation to further exploit GPT-4V's generic anomaly detection capacity from different aspects. These include exploring quantitative metrics, expanding evaluation benchmarks, incorporating multi-round interactions, and incorporating human feedback loops. Nevertheless, GPT-4V exhibits promising performance in generic anomaly detection and understanding, thus opening up a new avenue for anomaly detection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>> anomaly detection 是一项重要的任务 across 不同的领域和数据类型。然而，现有的异常检测模型通常是为特定的领域和Modalities 设计的。本研究探索使用 GPT-4V（视力语言模型）来Address 异常检测任务的通用方式。我们 investigate GPT-4V 在多modal, multi-domain 异常检测任务中的应用，包括图像、视频、点云和时间序列数据，以及多个应用领域，如工业、医疗、逻辑、视频、3D 异常检测和位置定位任务。为了提高 GPT-4V 的表现，我们 incorporate 不同类型的额外提示，如类信息、人工智能和参考图像。根据我们的实验，GPT-4V 在检测和解释 Zero/one-shot 异常检测中表现出色，可以准确地分辨正常和异常实例。虽然我们进行了广泛的评估，但还有更多的可能性来自 GPT-4V 的通用异常检测能力。这些包括探索量化指标、扩展评估标准、 incorporating 多 Round Interactions 和 incorporating 人类反馈循环。然而，GPT-4V 在通用异常检测和理解方面表现出色，因此开启了一个新的途径 для异常检测。
</details></li>
</ul>
<hr>
<h2 id="ChaTA-Towards-an-Intelligent-Question-Answer-Teaching-Assistant-using-Open-Source-LLMs"><a href="#ChaTA-Towards-an-Intelligent-Question-Answer-Teaching-Assistant-using-Open-Source-LLMs" class="headerlink" title="ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs"></a>ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02775">http://arxiv.org/abs/2311.02775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yann Hicke, Anmol Agarwal, Qianou Ma, Paul Denny</li>
<li>for: 这篇论文目的是为了解决知识检索和智能问答（QA）中的扩展和智能化问题。</li>
<li>methods: 这篇论文使用了开源的大语言模型（LLM），以保持数据隐私。它使用了LLaMA-2家族模型，并应用了改进技术，包括检索增强生成（RAG）、监督微调（SFT）和人类反馈学习的替代方法（RLHF）。</li>
<li>results: 在一个 Piazza 数据集上，这篇论文通过人工评估和自动 LLlM 评估，发现了改进技术的共同作用，提高了答案质量约33%，并发现了RAG 是一个有力的添加。这项工作将为开发智能 QA 助手Customizable for 课程而铺平道路。<details>
<summary>Abstract</summary>
To address the challenges of scalable and intelligent question-answering (QA), we introduce an innovative solution that leverages open-source Large Language Models (LLMs) to ensure data privacy. We use models from the LLaMA-2 family and augmentations including retrieval augmented generation (RAG), supervised fine-tuning (SFT), and an alternative to reinforcement learning with human feedback (RLHF). We perform our experiments on a Piazza dataset from an introductory CS course with 10k QA pairs and 1.5k pairs of preferences data and conduct both human evaluations and automatic LLM evaluations on a small subset. We find preliminary evidence that modeling techniques collectively enhance the quality of answers by 33%, and RAG is an impactful addition. This work paves the way for the development of ChaTA, an intelligent QA assistant customizable for courses with an online QA platform.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Communication-Efficient-and-Privacy-Preserving-Federated-Learning-Based-on-Evolution-Strategies"><a href="#Communication-Efficient-and-Privacy-Preserving-Federated-Learning-Based-on-Evolution-Strategies" class="headerlink" title="Communication Efficient and Privacy-Preserving Federated Learning Based on Evolution Strategies"></a>Communication Efficient and Privacy-Preserving Federated Learning Based on Evolution Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03405">http://arxiv.org/abs/2311.03405</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Eric-Lan0/FedES">https://github.com/Eric-Lan0/FedES</a></li>
<li>paper_authors: Guangchen Lan</li>
<li>for: 这个研究旨在提出一种基于演化策略的联合学习算法（Federated Evolution Strategies，FedES），以便在分布式的深度神经网络（DNNs）训练中实现低通信负载和数据隐私。</li>
<li>methods: 这个研究使用了演化策略（Evolution Strategies）来实现联合学习，而不是传输模型参数。因此，它具有非常低的通信负载。此外，这个方法还可以保护数据隐私，因为第三方无法估算梯度 без knowing 预先共享的种子。</li>
<li>results: 实验结果显示，FedES 可以实现低通信负载和数据隐私，同时保持与反射方法相同的参数整合性。<details>
<summary>Abstract</summary>
Federated learning (FL) is an emerging paradigm for training deep neural networks (DNNs) in distributed manners. Current FL approaches all suffer from high communication overhead and information leakage. In this work, we present a federated learning algorithm based on evolution strategies (FedES), a zeroth-order training method. Instead of transmitting model parameters, FedES only communicates loss values, and thus has very low communication overhead. Moreover, a third party is unable to estimate gradients without knowing the pre-shared seed, which protects data privacy. Experimental results demonstrate FedES can achieve the above benefits while keeping convergence performance the same as that with back propagation methods.
</details>
<details>
<summary>摘要</summary>
Federated learning（FL）是一种新趋势的深度神经网络（DNNs）训练方法，现有的FL方法都受到高度通信开销和信息泄露的限制。在这项工作中，我们提出了基于进化策略（FedES）的 federated learning算法，而不是传输模型参数，FedES只在交换损失值，因此通信开销非常低。此外，第三方无法估计梯度，不知道预先分享的种子，因此保护了数据隐私。实验结果表明，FedES可以实现这些优点，同时保持与反向传播方法相同的凝结性能。Note: The translation is done using Google Translate and may not be perfect. Please let me know if you need further assistance or if you would like me to use a different translation tool.
</details></li>
</ul>
<hr>
<h2 id="Rule-Learning-as-Machine-Translation-using-the-Atomic-Knowledge-Bank"><a href="#Rule-Learning-as-Machine-Translation-using-the-Atomic-Knowledge-Bank" class="headerlink" title="Rule Learning as Machine Translation using the Atomic Knowledge Bank"></a>Rule Learning as Machine Translation using the Atomic Knowledge Bank</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02765">http://arxiv.org/abs/2311.02765</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krisaesoey/atomictranslation">https://github.com/krisaesoey/atomictranslation</a></li>
<li>paper_authors: Kristoffer Æsøy, Ana Ozaki</li>
<li>for: 本研究旨在探讨使用机器学习模型进行逻辑推理是否可靠和可控的问题。</li>
<li>methods: 本研究使用 transformers 将自然语言中表达的规则翻译成逻辑规则，并使用逻辑推理工具进行逻辑推理。</li>
<li>results: 研究发现，使用 transformers 翻译自然语言中表达的规则可以生成可靠和可控的逻辑规则，并且可以用于逻辑推理。<details>
<summary>Abstract</summary>
Machine learning models, and in particular language models, are being applied to various tasks that require reasoning. While such models are good at capturing patterns their ability to reason in a trustable and controlled manner is frequently questioned. On the other hand, logic-based rule systems allow for controlled inspection and already established verification methods. However it is well-known that creating such systems manually is time-consuming and prone to errors. We explore the capability of transformers to translate sentences expressing rules in natural language into logical rules. We see reasoners as the most reliable tools for performing logical reasoning and focus on translating language into the format expected by such tools. We perform experiments using the DKET dataset from the literature and create a dataset for language to logic translation based on the Atomic knowledge bank.
</details>
<details>
<summary>摘要</summary>
机器学习模型，尤其是语言模型，在各种需要逻辑 reasoning 任务中应用。虽然这些模型能够捕捉模式，但其逻辑 reasoning 能力受到一定的质疑。然而，逻辑基础的规则系统具有可控的检查和已知的验证方法。然而，手动创建这些系统可能需要很长时间，并且容易出错。我们 investigate transformer 能力将自然语言中的句子翻译成逻辑规则。我们认为逻辑工具是逻辑 reasoning 最可靠的工具，因此我们将着眼于将语言翻译成这些工具所期望的格式。我们使用文献中的 DKET 数据集进行实验，并创建了基于 Atomic knowledge bank 的语言到逻辑翻译数据集。
</details></li>
</ul>
<hr>
<h2 id="Causal-Question-Answering-with-Reinforcement-Learning"><a href="#Causal-Question-Answering-with-Reinforcement-Learning" class="headerlink" title="Causal Question Answering with Reinforcement Learning"></a>Causal Question Answering with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02760">http://arxiv.org/abs/2311.02760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Lukas Blübaum, Stefan Heindorf</li>
<li>for: 本研究的目的是回答 causal  вопро题，即寻找 causal 关系和其背景数据。</li>
<li>methods: 本文使用 reinforcement learning 方法，具体来说是 actor-critic 算法，来搜索 causal 关系和解释问题。</li>
<li>results: 本文的实验结果表明，使用 reinforcement learning 方法可以成功地回答 causal 问题，并且可以快速地搜索到解释问题的路径。<details>
<summary>Abstract</summary>
Causal questions inquire about causal relationships between different events or phenomena. Specifically, they often aim to determine whether there is a relationship between two phenomena, or to identify all causes/effects of a phenomenon. Causal questions are important for a variety of use cases, including virtual assistants and search engines. However, many current approaches to causal question answering cannot provide explanations or evidence for their answers. Hence, in this paper, we aim to answer causal questions with CauseNet, a large-scale dataset of causal relations and their provenance data. Inspired by recent, successful applications of reinforcement learning to knowledge graph tasks, such as link prediction and fact-checking, we explore the application of reinforcement learning on CauseNet for causal question answering. We introduce an Actor-Critic based agent which learns to search through the graph to answer causal questions. We bootstrap the agent with a supervised learning procedure to deal with large action spaces and sparse rewards. Our evaluation shows that the agent successfully prunes the search space to answer binary causal questions by visiting less than 30 nodes per question compared to over 3,000 nodes by a naive breadth-first search. Our ablation study indicates that our supervised learning strategy provides a strong foundation upon which our reinforcement learning agent improves. The paths returned by our agent explain the mechanisms by which a cause produces an effect. Moreover, for each edge on a path, CauseNet stores its original source on the web allowing for easy verification of paths.
</details>
<details>
<summary>摘要</summary>
causal 问题查询的关系是两个或多个事件或现象之间的关系。特别是，它们通常想要确定两个现象之间是否存在关系，或者找出一个现象的所有原因。 causal 问题是各种用例中重要的，包括虚拟助手和搜索引擎。然而，许多当前的 causal 问题回答方法无法提供解释或证据。因此，在这篇论文中，我们使用 CauseNet，一个大规模的 causal 关系和其来源数据集，回答 causal 问题。以 reciprocal learning 的 inspiration，我们在 CauseNet 上应用 reciprocal learning 来回答 causal 问题。我们 introduce 一个 actor-critic 基于的搜索者，该搜索者可以在图上搜索以回答 causal 问题。我们使用一种监督学习过程来处理大的动作空间和罕见奖励。我们的评估显示，我们的搜索者可以成功地减少搜索空间，以回答 binary 的 causal 问题，每个问题只需访问 fewer than 30 个节点，而不是 naive 的广度优先搜索所需的 more than 3,000 个节点。我们的剥离研究表明，我们的监督学习策略提供了一个强大的基础，于而我们的 reciprocal learning 代理进行改进。 path 返回的 by our agent 解释了一个原因如何产生一个效果。此外，每个边在路径上，CauseNet 都将其原始来源保存在网上，以便轻松验证路径。
</details></li>
</ul>
<hr>
<h2 id="Learning-Independently-from-Causality-in-Multi-Agent-Environments"><a href="#Learning-Independently-from-Causality-in-Multi-Agent-Environments" class="headerlink" title="Learning Independently from Causality in Multi-Agent Environments"></a>Learning Independently from Causality in Multi-Agent Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02741">http://arxiv.org/abs/2311.02741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Pina, Varuna De Silva, Corentin Artaud</li>
<li>for: 这个论文旨在研究多智能 Reinforcement Learning（MARL）领域中的懒散代理问题，并从 causality 的视角来 investigate 这个问题。</li>
<li>methods: 该论文使用了 fully decentralized MARL  setup，并使用了 causality 来链接个体观察和团队奖励。</li>
<li>results: 实验结果表明，通过使用 causality 来链接个体观察和团队奖励，可以提高独立代理的智能行为，并且帮助团队实现更好的性能。<details>
<summary>Abstract</summary>
Multi-Agent Reinforcement Learning (MARL) comprises an area of growing interest in the field of machine learning. Despite notable advances, there are still problems that require investigation. The lazy agent pathology is a famous problem in MARL that denotes the event when some of the agents in a MARL team do not contribute to the common goal, letting the teammates do all the work. In this work, we aim to investigate this problem from a causality-based perspective. We intend to create the bridge between the fields of MARL and causality and argue about the usefulness of this link. We study a fully decentralised MARL setup where agents need to learn cooperation strategies and show that there is a causal relation between individual observations and the team reward. The experiments carried show how this relation can be used to improve independent agents in MARL, resulting not only on better performances as a team but also on the rise of more intelligent behaviours on individual agents.
</details>
<details>
<summary>摘要</summary>
多智能机器学习（MARL）是一个快速发展的领域之一，尚未解决的问题仍然存在。懒散代理症是MARL领域中著名的问题，表示一些代理在MARL团队中不做贡献，让团队其他成员完成所有工作。在这种情况下，我们希望从 causality 的视角来调查这个问题。我们想要建立 MARL 和 causality 之间的桥梁，并讨论这种链接的有用性。我们研究了一个完全分散式的 MARL 设置，其中代理需要学习合作策略，并证明了个体观察与团队奖励之间存在 causal 关系。实验表明，这种关系可以用来改进独立的代理在 MARL 中的表现，不仅提高团队的性能，还使得代理的行为更加聪明。
</details></li>
</ul>
<hr>
<h2 id="AV-Lip-Sync-Leveraging-AV-HuBERT-to-Exploit-Multimodal-Inconsistency-for-Video-Deepfake-Detection"><a href="#AV-Lip-Sync-Leveraging-AV-HuBERT-to-Exploit-Multimodal-Inconsistency-for-Video-Deepfake-Detection" class="headerlink" title="AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Video Deepfake Detection"></a>AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency for Video Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02733">http://arxiv.org/abs/2311.02733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahibzada Adil Shahzad, Ammarah Hashmi, Yan-Tsung Peng, Yu Tsao, Hsin-Min Wang</li>
<li>for: 防止伪造 multimedia 内容的传播，尤其是 fake news 和 false propaganda。</li>
<li>methods: 使用 multi-modal self-supervised learning (SSL) 特征提取器，捕捉视频和音频模式之间的不一致，进而实现多模式识别。</li>
<li>results: 比较所有现有模型，取得新的 state-of-the-art 性能在 FakeAVCeleb 和 DeepfakeTIMIT 数据集上。<details>
<summary>Abstract</summary>
Multimodal manipulations (also known as audio-visual deepfakes) make it difficult for unimodal deepfake detectors to detect forgeries in multimedia content. To avoid the spread of false propaganda and fake news, timely detection is crucial. The damage to either modality (i.e., visual or audio) can only be discovered through multi-modal models that can exploit both pieces of information simultaneously. Previous methods mainly adopt uni-modal video forensics and use supervised pre-training for forgery detection. This study proposes a new method based on a multi-modal self-supervised-learning (SSL) feature extractor to exploit inconsistency between audio and visual modalities for multi-modal video forgery detection. We use the transformer-based SSL pre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic feature extractor and a multi-scale temporal convolutional neural network to capture the temporal correlation between the audio and visual modalities. Since AV-HuBERT only extracts visual features from the lip region, we also adopt another transformer-based video model to exploit facial features and capture spatial and temporal artifacts caused during the deepfake generation process. Experimental results show that our model outperforms all existing models and achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT datasets.
</details>
<details>
<summary>摘要</summary>
多模态操作（也称为音频视频深伪）使得单模态深伪检测器很难检测多媒体内容中的伪造。为避免假新闻和假 пропаганда 的传播，实时检测是关键。过去的方法主要采用单模态视频科学和监测预训练来检测伪造。本研究提出了一种基于多模态自适应学（SSL）特征提取器来利用视频和音频模态之间的不一致来检测多模态视频伪造。我们使用基于 transformer 的 SSL 预训练 Audio-Visual HuBERT（AV-HuBERT）模型作为视觉和听音特征提取器，并使用多尺度时间卷积神经网络来捕捉音频和视觉模态之间的时间相关性。由于 AV-HuBERT 只提取视觉特征自唇部分，我们还采用另一种基于 transformer 的视频模型来利用脸部特征和捕捉深伪生成过程中的空间和时间偏差。实验结果表明，我们的模型在 FakeAVCeleb 和 DeepfakeTIMIT 数据集上的性能比所有现有模型高，实现了新的状态纪录水平。
</details></li>
</ul>
<hr>
<h2 id="Extraction-of-Atypical-Aspects-from-Customer-Reviews-Datasets-and-Experiments-with-Language-Models"><a href="#Extraction-of-Atypical-Aspects-from-Customer-Reviews-Datasets-and-Experiments-with-Language-Models" class="headerlink" title="Extraction of Atypical Aspects from Customer Reviews: Datasets and Experiments with Language Models"></a>Extraction of Atypical Aspects from Customer Reviews: Datasets and Experiments with Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02702">http://arxiv.org/abs/2311.02702</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smitanannaware/xtrata">https://github.com/smitanannaware/xtrata</a></li>
<li>paper_authors: Smita Nannaware, Erfan Al-Hossami, Razvan Bunescu</li>
<li>for: 本研究的目的是检测顾客评论中的非常规方面，以便提高用户满意度。</li>
<li>methods: 本研究使用了人工批注 benchmark 数据集，以评估不同语言模型的性能。</li>
<li>results: 研究发现，使用 Flan-T5 进行 fine-tuning 和 GPT-3.5 的零shot 和几 shot 提示可以准确检测顾客评论中的非常规方面。<details>
<summary>Abstract</summary>
A restaurant dinner may become a memorable experience due to an unexpected aspect enjoyed by the customer, such as an origami-making station in the waiting area. If aspects that are atypical for a restaurant experience were known in advance, they could be leveraged to make recommendations that have the potential to engender serendipitous experiences, further increasing user satisfaction. Although relatively rare, whenever encountered, atypical aspects often end up being mentioned in reviews due to their memorable quality. Correspondingly, in this paper we introduce the task of detecting atypical aspects in customer reviews. To facilitate the development of extraction models, we manually annotate benchmark datasets of reviews in three domains - restaurants, hotels, and hair salons, which we use to evaluate a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and few-shot prompting of GPT-3.5.
</details>
<details>
<summary>摘要</summary>
餐厅晚餐可能变成一个深刻的记忆，因为顾客在等待区域内感受到了一个意外的元素，如 Origami 制作站。如果在餐厅经验中不寻常的方面知道在先，可以利用这些方面来提供建议，以便在用户满意度方面产生巧合体验。虽然这些不寻常的方面相对罕见，但当遇到时，它们通常会被评论中提及，因为它们具有深刻的特点。在这篇论文中，我们介绍了检测顾客评论中不寻常的方面的任务。为了促进EXTRACTION 模型的开发，我们手动标注了多个领域的客评论 benchmark 数据集 - 餐厅、酒店和美发店，并使用这些数据集来评估多种语言模型，从 fine-tuning Flan-T5 到零shot 和几shot 的 GPT-3.5 的Prompting。
</details></li>
</ul>
<hr>
<h2 id="Architecture-Matters-Uncovering-Implicit-Mechanisms-in-Graph-Contrastive-Learning"><a href="#Architecture-Matters-Uncovering-Implicit-Mechanisms-in-Graph-Contrastive-Learning" class="headerlink" title="Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning"></a>Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02687">http://arxiv.org/abs/2311.02687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaojun Guo, Yifei Wang, Zeming Wei, Yisen Wang</li>
<li>for: 研究 graph contrastive learning (GCL) 方法的系统性特点，包括Positive samples 不是必须的、negative samples 不需要 для图类别或节点类别，以及数据增强对 GCL 的影响较小。</li>
<li>methods: 研究如何通过理解 GNN 的隐式概念偏好来解释 GCL 方法的特点。</li>
<li>results: 发现 GCL 方法的特点与传统的 visual contrastive learning (VCL) 方法有很大差异，包括Positive samples 不是必须的、negative samples 不需要 для图类别或节点类别，以及数据增强对 GCL 的影响较小。<details>
<summary>Abstract</summary>
With the prosperity of contrastive learning for visual representation learning (VCL), it is also adapted to the graph domain and yields promising performance. However, through a systematic study of various graph contrastive learning (GCL) methods, we observe that some common phenomena among existing GCL methods that are quite different from the original VCL methods, including 1) positive samples are not a must for GCL; 2) negative samples are not necessary for graph classification, neither for node classification when adopting specific normalization modules; 3) data augmentations have much less influence on GCL, as simple domain-agnostic augmentations (e.g., Gaussian noise) can also attain fairly good performance. By uncovering how the implicit inductive bias of GNNs works in contrastive learning, we theoretically provide insights into the above intriguing properties of GCL. Rather than directly porting existing VCL methods to GCL, we advocate for more attention toward the unique architecture of graph learning and consider its implicit influence when designing GCL methods. Code is available at https: //github.com/PKU-ML/ArchitectureMattersGCL.
</details>
<details>
<summary>摘要</summary>
With the prosperity of contrastive learning for visual representation learning (VCL), it has also been adapted to the graph domain and has shown promising performance. However, through a systematic study of various graph contrastive learning (GCL) methods, we observe that some common phenomena exist among existing GCL methods that are quite different from the original VCL methods, including:1. Positive samples are not a must for GCL.2. Negative samples are not necessary for graph classification, nor for node classification when using specific normalization modules.3. Data augmentations have much less influence on GCL, as simple domain-agnostic augmentations (e.g., Gaussian noise) can also achieve fairly good performance.By uncovering how the implicit inductive bias of GNNs works in contrastive learning, we provide theoretical insights into the above intriguing properties of GCL. Rather than directly porting existing VCL methods to GCL, we advocate for more attention to be paid to the unique architecture of graph learning and consider its implicit influence when designing GCL methods. Code is available at: <https://github.com/PKU-ML/ArchitectureMattersGCL>.
</details></li>
</ul>
<hr>
<h2 id="Compute-at-Scale-–-A-Broad-Investigation-into-the-Data-Center-Industry"><a href="#Compute-at-Scale-–-A-Broad-Investigation-into-the-Data-Center-Industry" class="headerlink" title="Compute at Scale – A Broad Investigation into the Data Center Industry"></a>Compute at Scale – A Broad Investigation into the Data Center Industry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02651">http://arxiv.org/abs/2311.02651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konstantin Pilz, Lennart Heim</li>
<li>for: 这份报告描述了数据中心行业的现状和其对人工智能发展的重要性。</li>
<li>methods: 报告使用了大量的计算资源和网络连接来描述数据中心的特点和业务模式。</li>
<li>results: 根据报告，全球数据中心市场的价值约为2500亿美元，预计在下一个七年内将双倍增长。同时，全球大约有500个大型数据中心（每个MW电压），美国、欧洲和中国是最重要的市场。<details>
<summary>Abstract</summary>
This report characterizes the data center industry and its importance for AI development. Data centers are industrial facilities that efficiently provide compute at scale and thus constitute the engine rooms of today's digital economy. As large-scale AI training and inference become increasingly computationally expensive, they are dominantly executed from this designated infrastructure. Key features of data centers include large-scale compute clusters that require extensive cooling and consume large amounts of power, the need for fast connectivity both within the data center and to the internet, and an emphasis on security and reliability. The global industry is valued at approximately $250B and is expected to double over the next seven years. There are likely about 500 large (above 10 MW) data centers globally, with the US, Europe, and China constituting the most important markets. The report further covers important actors, business models, main inputs, and typical locations of data centers.
</details>
<details>
<summary>摘要</summary>
这份报告描述了数据中心业和其对人工智能发展的重要性。数据中心是大规模计算的工业设施，它们提供大规模计算能力，并因此成为当今数字经济的发动机。随着大规模人工智能训练和推断变得越来越计算昂贵，它们主要在这些指定的基础设施上进行执行。数据中心的主要特点包括大规模计算集群，需要广泛的冷却和大量的电力，快速的内部连接和互联网连接，以及安全性和可靠性的强调。全球业态估价约2500亿美元，预计在下一个七年内将 doubles。全球可能有约500个大于10MW的数据中心，美国、欧洲和中国是最重要的市场。报告还涵盖了重要的actor、业务模式、主要输入和典型的数据中心所在地。
</details></li>
</ul>
<hr>
<h2 id="New-Approach-for-an-Affective-Computing-Driven-Quality-of-Experience-QoE-Prediction"><a href="#New-Approach-for-an-Affective-Computing-Driven-Quality-of-Experience-QoE-Prediction" class="headerlink" title="New Approach for an Affective Computing-Driven Quality of Experience (QoE) Prediction"></a>New Approach for an Affective Computing-Driven Quality of Experience (QoE) Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02647">http://arxiv.org/abs/2311.02647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Bègue, Mohamed Aymen Labiod, Abdelhamid Melloulk<br>for:这篇论文旨在提出一种基于情感计算的 качество经验（QoE）预测模型，以便在多媒体QoE评估场景下提高体验质量。methods:这篇论文使用了计算多核电enzephalogram（EEG）信息，并使用了差异 entropy和功率 спектル密度来特征提取。然后，使用深度学习模型来研究是否可以通过这些特征来预测QoE。results:这篇论文使用了一个公共可用的数据集，并使用了多个深度学习模型来研究QoE预测的可能性。结果显示，使用LSTM模型可以获得最好的结果，其中F1分数在68%到78%之间。此外，分析表明，Delta频率带是最不必要的，两个电极具有更高的重要性，而两个电极具有很低的影响。<details>
<summary>Abstract</summary>
In human interactions, emotion recognition is crucial. For this reason, the topic of computer-vision approaches for automatic emotion recognition is currently being extensively researched. Processing multi-channel electroencephalogram (EEG) information is one of the most researched methods for automatic emotion recognition. This paper presents a new model for an affective computing-driven Quality of Experience (QoE) prediction. In order to validate the proposed model, a publicly available dataset is used. The dataset contains EEG, ECG, and respiratory data and is focused on a multimedia QoE assessment context. The EEG data are retained on which the differential entropy and the power spectral density are calculated with an observation window of three seconds. These two features were extracted to train several deep-learning models to investigate the possibility of predicting QoE with five different factors. The performance of these models is compared, and the best model is optimized to improve the results. The best results were obtained with an LSTM-based model, presenting an F1-score from 68% to 78%. An analysis of the model and its features shows that the Delta frequency band is the least necessary, that two electrodes have a higher importance, and that two other electrodes have a very low impact on the model's performances.
</details>
<details>
<summary>摘要</summary>
人际交互中，情感认知是非常重要的。因此，计算机视觉方法自动情感认知的研究在当前已经非常广泛。处理多通道电enzephalogram（EEG）信息是最广泛研究的方法。这篇论文提出了一种新的情感计算驱动的品质经验（QoE）预测模型。为验证提议的模型，使用了一个公共可用的数据集。该数据集包括EEG、ECG和呼吸数据，并且是关于多媒体QoE评估上下文。EEG数据上计算了差异积分和功率spectral density，使用观察窗口为3秒。这两个特征用于训练多个深度学习模型，以 investigate可能通过五个因素预测QoE。模型的性能相比，LSTM模型显示最佳结果，其F1得分在68%到78%之间。分析模型和其特征显示，Delta频率带是最不必要的，两个电极有更高的重要性，两个电极具有很低的影响。
</details></li>
</ul>
<hr>
<h2 id="PotholeGuard-A-Pothole-Detection-Approach-by-Point-Cloud-Semantic-Segmentation"><a href="#PotholeGuard-A-Pothole-Detection-Approach-by-Point-Cloud-Semantic-Segmentation" class="headerlink" title="PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic Segmentation"></a>PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02641">http://arxiv.org/abs/2311.02641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahil Nawale, Dhruv Khut, Daksh Dave, Gauransh Sawhney, Pushkar Aggrawal, Dr. Kailas Devadakar</li>
<li>for: 本研究旨在提供一种robust和准确的3D破洞 segmentation方法，用于道路安全维护。</li>
<li>methods: 该方法使用点云图像 segmentation，并提供了一种新的点云缺失缓解机制，以及一种本地关系学习模块，以提高本地特征表示。</li>
<li>results: 对三个公共数据集进行了广泛的实验，并证明了PotholeGuard方法在现有方法中的超越性。<details>
<summary>Abstract</summary>
Pothole detection is crucial for road safety and maintenance, traditionally relying on 2D image segmentation. However, existing 3D Semantic Pothole Segmentation research often overlooks point cloud sparsity, leading to suboptimal local feature capture and segmentation accuracy. Our research presents an innovative point cloud-based pothole segmentation architecture. Our model efficiently identifies hidden features and uses a feedback mechanism to enhance local characteristics, improving feature presentation. We introduce a local relationship learning module to understand local shape relationships, enhancing structural insights. Additionally, we propose a lightweight adaptive structure for refining local point features using the K nearest neighbor algorithm, addressing point cloud density differences and domain selection. Shared MLP Pooling is integrated to learn deep aggregation features, facilitating semantic data exploration and segmentation guidance. Extensive experiments on three public datasets confirm PotholeGuard's superior performance over state-of-the-art methods. Our approach offers a promising solution for robust and accurate 3D pothole segmentation, with applications in road maintenance and safety.
</details>
<details>
<summary>摘要</summary>
《破洞检测是公路安全和维护中非常重要的一环，传统上靠的是2D图像分割。然而，现有的3D语义破洞分割研究经常忽略点云稀疏性，导致本地特征捕捉和分割精度受到限制。我们的研究提出了一种创新的点云基于的破洞分割建筑。我们的模型能够高效发现隐藏的特征，并使用反馈机制来增强本地特征，提高特征表现。我们引入了地方关系学习模块，以更好地理解地方形态关系，提高结构性能。此外，我们提议了一种轻量级适应结构，通过K最近邻近算法来调整本地点特征，解决点云密度差异和领域选择问题。我们将 Shared MLP Pooling 集成到整个模型中，以学习深度聚合特征，促进 semantic 数据探索和分割引导。我们的方法在三个公共数据集上进行了广泛的实验，并证明了 PotholeGuard 的超过状态艺术方法的性能。我们的方法可以为公路维护和安全带来一个可靠和准确的3D破洞分割解决方案。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-Promise-and-Pitfalls-of-ChatGPT-for-Automated-Code-Generation"><a href="#Assessing-the-Promise-and-Pitfalls-of-ChatGPT-for-Automated-Code-Generation" class="headerlink" title="Assessing the Promise and Pitfalls of ChatGPT for Automated Code Generation"></a>Assessing the Promise and Pitfalls of ChatGPT for Automated Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02640">http://arxiv.org/abs/2311.02640</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dsaatusu/chatgpt-promises-and-pitfalls">https://github.com/dsaatusu/chatgpt-promises-and-pitfalls</a></li>
<li>paper_authors: Muhammad Fawad Akbar Khan, Max Ramsdell, Erik Falor, Hamid Karimi</li>
<li>for: 评估 chatGPT 大语言模型在代码生成方面的能力，并与人工程师的代码相比。</li>
<li>methods: 使用了一个新的代码生成数据集，并对 chatGPT 和人工程师的代码进行了比较性评估，以评估 chatGPT 的代码生成能力。</li>
<li>results: 显示了 chatGPT 在数据分析任务中的强大能力（准确率为 93.1%），但在视觉graphical挑战中存在局限性。 chatGPT 的代码具有较高的含义性和安全性，且倾向于使用模块化设计和更好的错误处理。 机器学习模型也能够准确地分辨出 chatGPT 的代码和人工程师的代码之间的差异。<details>
<summary>Abstract</summary>
This paper presents a comprehensive evaluation of the code generation capabilities of ChatGPT, a prominent large language model, compared to human programmers. A novel dataset of 131 code-generation prompts across 5 categories was curated to enable robust analysis. Code solutions were generated by both ChatGPT and humans for all prompts, resulting in 262 code samples. A meticulous manual assessment methodology prioritized evaluating correctness, comprehensibility, and security using 14 established code quality metrics. The key findings reveal ChatGPT's strengths in crafting concise, efficient code with advanced constructs, showcasing strengths in data analysis tasks (93.1% accuracy) but limitations in visual-graphical challenges. Comparative analysis with human code highlights ChatGPT's inclination towards modular design and superior error handling. Additionally, machine learning models effectively distinguished ChatGPT from human code with up to 88% accuracy, suggesting detectable coding style disparities. By providing profound insights into ChatGPT's code generation capabilities and limitations through quantitative metrics and qualitative analysis, this study makes valuable contributions toward advancing AI-based programming assistants. The curated dataset and methodology offer a robust foundation for future research in this nascent domain. All data and codes are available on https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls.
</details>
<details>
<summary>摘要</summary>
The key findings show that ChatGPT excels in crafting concise and efficient code with advanced constructs, particularly in data analysis tasks (93.1% accuracy). However, it struggles with visual-graphical challenges. Comparative analysis with human code reveals that ChatGPT tends towards modular design and superior error handling. Additionally, machine learning models can accurately distinguish ChatGPT code from human code (up to 88% accuracy), indicating detectable differences in coding style.This study provides valuable insights into ChatGPT's code generation capabilities and limitations through quantitative metrics and qualitative analysis. The curated dataset and methodology serve as a robust foundation for future research in this emerging field. All data and codes are available on GitHub (https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls).
</details></li>
</ul>
<hr>
<h2 id="A-Critical-Perceptual-Pre-trained-Model-for-Complex-Trajectory-Recovery"><a href="#A-Critical-Perceptual-Pre-trained-Model-for-Complex-Trajectory-Recovery" class="headerlink" title="A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery"></a>A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02631">http://arxiv.org/abs/2311.02631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dedong Li, Ziyue Li, Zhishuai Li, Lei Bai, Qingyuan Gong, Lijun Sun, Wolfgang Ketter, Rui Zhao</li>
<li>For: 提高复杂路径轨迹恢复的精度， especialmente 处理跨度远 road segment 和多个拐弯的情况。* Methods: 使用顺序语言模型在预训练 manner 学习道路段表示 вектор，并提出了多视图图文件和复杂度意识Transformer（MGCAT）模型，可以在轨迹预训练中 adaptively 聚合多视图图文件特征，以及增强关键节点的注意力。* Results: 对大规模数据集进行了广泛的实验，结果表明，我们的方法可以更好地学习轨迹恢复的表示，全体 F1 分数提高 5.22%，特别是复杂轨迹 F1 分数提高 8.16%。<details>
<summary>Abstract</summary>
The trajectory on the road traffic is commonly collected at a low sampling rate, and trajectory recovery aims to recover a complete and continuous trajectory from the sparse and discrete inputs. Recently, sequential language models have been innovatively adopted for trajectory recovery in a pre-trained manner: it learns road segment representation vectors, which will be used in the downstream tasks. However, existing methods are incapable of handling complex trajectories: when the trajectory crosses remote road segments or makes several turns, which we call critical nodes, the quality of learned representations deteriorates, and the recovered trajectories skip the critical nodes. This work is dedicated to offering a more robust trajectory recovery for complex trajectories. Firstly, we define the trajectory complexity based on the detour score and entropy score and construct the complexity-aware semantic graphs correspondingly. Then, we propose a Multi-view Graph and Complexity Aware Transformer (MGCAT) model to encode these semantics in trajectory pre-training from two aspects: 1) adaptively aggregate the multi-view graph features considering trajectory pattern, and 2) higher attention to critical nodes in a complex trajectory. Such that, our MGCAT is perceptual when handling the critical scenario of complex trajectories. Extensive experiments are conducted on large-scale datasets. The results prove that our method learns better representations for trajectory recovery, with 5.22% higher F1-score overall and 8.16% higher F1-score for complex trajectories particularly. The code is available at https://github.com/bonaldli/ComplexTraj.
</details>
<details>
<summary>摘要</summary>
trajectory 在路况资料收集时通常采集得非常低， trajectory 恢复目标是恢复完整、连续的 trajectory 从稀疏、离散输入中。 最近，序列语言模型在预训练方式下被创新地应用于 trajectory 恢复中，它学习了路段表示 вектор，这些 вектор 将在下游任务中使用。然而，现有方法无法处理复杂的 trajectory：当 trajectory 过 remote 路段或多次转弯时，学习的表示质量会下降， recovered  trajectory 会跳过关键节点。这项工作旨在提供更加稳定的 trajectory 恢复方法，能够处理复杂的 trajectory。我们首先定义 trajectory 的复杂性基于拐弯分数和 entropy 分数，并构建了相应的复杂性意识图。然后，我们提出了多视图图和复杂性意识图 transformer（MGCAT）模型，用于在 trajectory 预训练中编码这些semantics。MGCAT 模型通过以下两种方式来编码这些semantics：1）适应性地集合多视图图特征，考虑 trajectory 模式；2）在复杂的 trajectory 中高优先级关注关键节点。这样，我们的 MGCAT 在处理复杂的 trajectory 时具有较高的感知性。我们在大规模数据集上进行了广泛的实验，结果表明我们的方法可以更好地学习 trajectory 恢复的表示，全局 F1 分数提高 5.22%，而复杂 trajectory 的 F1 分数提高 8.16%。代码可以在 <https://github.com/bonaldli/ComplexTraj> 上获取。
</details></li>
</ul>
<hr>
<h2 id="The-New-Frontier-of-Cybersecurity-Emerging-Threats-and-Innovations"><a href="#The-New-Frontier-of-Cybersecurity-Emerging-Threats-and-Innovations" class="headerlink" title="The New Frontier of Cybersecurity: Emerging Threats and Innovations"></a>The New Frontier of Cybersecurity: Emerging Threats and Innovations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02630">http://arxiv.org/abs/2311.02630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daksh Dave, Gauransh Sawhney, Pushkar Aggarwal, Nitish Silswal, Dhruv Khut</li>
<li>for: 这项研究旨在全面检讨Cybersecurity领域的多种威胁，包括Malware攻击、社会工程攻击、网络漏洞和数据泄露等四类威胁。</li>
<li>methods: 本研究采用资深研究方法，检讨了这些威胁对个人、组织和社会的影响。</li>
<li>results: 研究发现了一系列新兴Cybersecurity威胁，包括高级 persistente攻击、劫持攻击、物联网（IoT）漏洞和社会工程攻击等。这些威胁对组织和个人都构成了严重的风险。因此，需要采取多层防御措施，包括强大的安全措施、全面的员工培训和定期的安全审核。<details>
<summary>Abstract</summary>
In today's digitally interconnected world, cybersecurity threats have reached unprecedented levels, presenting a pressing concern for individuals, organizations, and governments. This study employs a qualitative research approach to comprehensively examine the diverse threats of cybersecurity and their impacts across various sectors. Four primary categories of threats are identified and analyzed, encompassing malware attacks, social engineering attacks, network vulnerabilities, and data breaches. The research delves into the consequences of these threats on individuals, organizations, and society at large. The findings reveal a range of key emerging threats in cybersecurity, including advanced persistent threats, ransomware attacks, Internet of Things (IoT) vulnerabilities, and social engineering exploits. Consequently, it is evident that emerging cybersecurity threats pose substantial risks to both organizations and individuals. The sophistication and diversity of these emerging threats necessitate a multi-layered approach to cybersecurity. This approach should include robust security measures, comprehensive employee training, and regular security audits. The implications of these emerging threats are extensive, with potential consequences such as financial loss, reputational damage, and compromised personal information. This study emphasizes the importance of implementing effective measures to mitigate these threats. It highlights the significance of using strong passwords, encryption methods, and regularly updating software to bolster cyber defenses.
</details>
<details>
<summary>摘要</summary>
The research reveals a range of key emerging threats in cybersecurity, including advanced persistent threats, ransomware attacks, Internet of Things (IoT) vulnerabilities, and social engineering exploits. These emerging threats pose substantial risks to both organizations and individuals, with potential consequences such as financial loss, reputational damage, and compromised personal information.To mitigate these threats, this study emphasizes the importance of implementing effective measures, such as robust security measures, comprehensive employee training, and regular security audits. Additionally, using strong passwords, encryption methods, and regularly updating software can help bolster cyber defenses. The sophistication and diversity of emerging threats necessitate a multi-layered approach to cybersecurity.The findings of this study have far-reaching implications, highlighting the significance of taking proactive measures to protect against cyber threats. With the increasing dependence on digital technologies, it is essential to stay vigilant and adapt to the evolving landscape of cyber threats. By prioritizing cybersecurity, individuals and organizations can minimize the risks of financial loss, reputational damage, and compromised personal information.
</details></li>
</ul>
<hr>
<h2 id="AIOps-Driven-Enhancement-of-Log-Anomaly-Detection-in-Unsupervised-Scenarios"><a href="#AIOps-Driven-Enhancement-of-Log-Anomaly-Detection-in-Unsupervised-Scenarios" class="headerlink" title="AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised Scenarios"></a>AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02621">http://arxiv.org/abs/2311.02621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daksh Dave, Gauransh Sawhney, Dhruv Khut, Sahil Nawale, Pushkar Aggrawal, Prasenjit Bhavathankar</li>
<li>for: 本研究旨在提高AIOps平台中的日志异常检测效果，填补现有研究空白。</li>
<li>methods: 本研究提出了一种新型的混合方法，结合了不监督学习策略，包括原始数据处理和人工神经网络。</li>
<li>results: 实验结果表明，提出的方法可以减少 Pseudo-positive 的数量，并且可以处理日志在原始、未处理的形式下进行分析。<details>
<summary>Abstract</summary>
Artificial intelligence operations (AIOps) play a pivotal role in identifying, mitigating, and analyzing anomalous system behaviors and alerts. However, the research landscape in this field remains limited, leaving significant gaps unexplored. This study introduces a novel hybrid framework through an innovative algorithm that incorporates an unsupervised strategy. This strategy integrates Principal Component Analysis (PCA) and Artificial Neural Networks (ANNs) and uses a custom loss function to substantially enhance the effectiveness of log anomaly detection. The proposed approach encompasses the utilization of both simulated and real-world datasets, including logs from SockShop and Hadoop Distributed File System (HDFS). The experimental results are highly promising, demonstrating significant reductions in pseudo-positives. Moreover, this strategy offers notable advantages, such as the ability to process logs in their raw, unprocessed form, and the potential for further enhancements. The successful implementation of this approach showcases a remarkable reduction in anomalous logs, thus unequivocally establishing the efficacy of the proposed methodology. Ultimately, this study makes a substantial contribution to the advancement of log anomaly detection within AIOps platforms, addressing the critical need for effective and efficient log analysis in modern and complex systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Get-the-Ball-Rolling-Alerting-Autonomous-Robots-When-to-Help-to-Close-the-Healthcare-Loop"><a href="#Get-the-Ball-Rolling-Alerting-Autonomous-Robots-When-to-Help-to-Close-the-Healthcare-Loop" class="headerlink" title="Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close the Healthcare Loop"></a>Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close the Healthcare Loop</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02602">http://arxiv.org/abs/2311.02602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxin Shen, Yanyao Liu, Ziming Wang, Ziyuan Jiao, Yufeng Chen, Wenjuan Han</li>
<li>for: 推动健康Robot研究 без人类干预或指令，提出自主帮助挑战和大规模人均数据采集。</li>
<li>methods: 提出健康Robot拥有自动确定帮助需要、生成有用子任务、通过物理机器执行计划、接受环境反馈以生成新任务的能力。</li>
<li>results: 解决开放场景中自主任务生成、现场与静止常识之间的漏洞、语言指令与实际世界之间的漏洞等挑战，并提出Helpy方法尝试填补健康循环学习无需人类干预的情况。<details>
<summary>Abstract</summary>
To facilitate the advancement of research in healthcare robots without human intervention or commands, we introduce the Autonomous Helping Challenge, along with a crowd-sourcing large-scale dataset. The goal is to create healthcare robots that possess the ability to determine when assistance is necessary, generate useful sub-tasks to aid in planning, carry out these plans through a physical robot, and receive feedback from the environment in order to generate new tasks and continue the process. Besides the general challenge in open-ended scenarios, Autonomous Helping focuses on three specific challenges: autonomous task generation, the gap between the current scene and static commonsense, and the gap between language instruction and the real world. Additionally, we propose Helpy, a potential approach to close the healthcare loop in the learning-free setting.
</details>
<details>
<summary>摘要</summary>
为了推动医疗机器人自主研究的发展，我们提出了无人指导的帮助挑战，同时发布了大规模的人类参与评估数据集。我们的目标是创造一种具有自动确定帮助需求、生成有用子任务、执行 física robot 计划、并接受环境反馈以生成新任务的医疗机器人。除了开放场景中的总体挑战外，Autonomous Helping 特点在于三个特定挑战：自动任务生成、现场与静态常识之间的差距、以及语言指令与实际世界之间的差距。此外，我们提出了一种可能的方法来在无学习设定下关闭医疗循环——Helpy。
</details></li>
</ul>
<hr>
<h2 id="Automated-Camera-Calibration-via-Homography-Estimation-with-GNNs"><a href="#Automated-Camera-Calibration-via-Homography-Estimation-with-GNNs" class="headerlink" title="Automated Camera Calibration via Homography Estimation with GNNs"></a>Automated Camera Calibration via Homography Estimation with GNNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02598">http://arxiv.org/abs/2311.02598</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giacomo D’Amicantonio, Egor Bondarev, Peter H. N. De With</li>
<li>for: 这篇论文是为了提高交通监测系统中相机的准确性和自动化调整而提出的一种新方法。</li>
<li>methods: 该方法基于图граaph neural networks，使用 bird’s-eye-view 图像生成交叉口视角图像集合，并使用这些图像集合学习拓扑结构，从而估算出Homography矩阵。</li>
<li>results: 该方法在实验中表现出色，在真实世界相机上取得了最高精度的准确性和自动化调整。<details>
<summary>Abstract</summary>
Over the past few decades, a significant rise of camera-based applications for traffic monitoring has occurred. Governments and local administrations are increasingly relying on the data collected from these cameras to enhance road safety and optimize traffic conditions. However, for effective data utilization, it is imperative to ensure accurate and automated calibration of the involved cameras. This paper proposes a novel approach to address this challenge by leveraging the topological structure of intersections. We propose a framework involving the generation of a set of synthetic intersection viewpoint images from a bird's-eye-view image, framed as a graph of virtual cameras to model these images. Using the capabilities of Graph Neural Networks, we effectively learn the relationships within this graph, thereby facilitating the estimation of a homography matrix. This estimation leverages the neighbourhood representation for any real-world camera and is enhanced by exploiting multiple images instead of a single match. In turn, the homography matrix allows the retrieval of extrinsic calibration parameters. As a result, the proposed framework demonstrates superior performance on both synthetic datasets and real-world cameras, setting a new state-of-the-art benchmark.
</details>
<details>
<summary>摘要</summary>
We propose a framework that involves generating a set of synthetic intersection viewpoint images from a bird's-eye-view image, framed as a graph of virtual cameras to model these images. Using the capabilities of Graph Neural Networks, we effectively learn the relationships within this graph, thereby facilitating the estimation of a homography matrix. This estimation leverages the neighborhood representation for any real-world camera and is enhanced by exploiting multiple images instead of a single match. In turn, the homography matrix allows the retrieval of extrinsic calibration parameters.As a result, the proposed framework demonstrates superior performance on both synthetic datasets and real-world cameras, setting a new state-of-the-art benchmark.
</details></li>
</ul>
<hr>
<h2 id="FloodBrain-Flood-Disaster-Reporting-by-Web-based-Retrieval-Augmented-Generation-with-an-LLM"><a href="#FloodBrain-Flood-Disaster-Reporting-by-Web-based-Retrieval-Augmented-Generation-with-an-LLM" class="headerlink" title="FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented Generation with an LLM"></a>FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented Generation with an LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02597">http://arxiv.org/abs/2311.02597</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grace Colverd, Paul Darm, Leonard Silverberg, Noah Kasmanoff</li>
<li>for: 急需快速灾害影响报告，以便规划人道援助。</li>
<li>methods: 利用大量语言模型（LLMs）实现文本生成和问题解答等功能，并将资讯EXTRACT AND CURATE FROM THE WEB以生成灾害影响报告。</li>
<li>results: 比较不同的大量语言模型（LLMs）的生成报告和人工撰写的报告，发现与人工评分相似的相关性。另外，透过组件分析，发现单一管道元件的重要性。以增进大量语言模型的应用，减少灾害发生后的协调时间。<details>
<summary>Abstract</summary>
Fast disaster impact reporting is crucial in planning humanitarian assistance. Large Language Models (LLMs) are well known for their ability to write coherent text and fulfill a variety of tasks relevant to impact reporting, such as question answering or text summarization. However, LLMs are constrained by the knowledge within their training data and are prone to generating inaccurate, or "hallucinated", information. To address this, we introduce a sophisticated pipeline embodied in our tool FloodBrain (floodbrain.com), specialized in generating flood disaster impact reports by extracting and curating information from the web. Our pipeline assimilates information from web search results to produce detailed and accurate reports on flood events. We test different LLMs as backbones in our tool and compare their generated reports to human-written reports on different metrics. Similar to other studies, we find a notable correlation between the scores assigned by GPT-4 and the scores given by human evaluators when comparing our generated reports to human-authored ones. Additionally, we conduct an ablation study to test our single pipeline components and their relevancy for the final reports. With our tool, we aim to advance the use of LLMs for disaster impact reporting and reduce the time for coordination of humanitarian efforts in the wake of flood disasters.
</details>
<details>
<summary>摘要</summary>
快速灾害影响报告是紧急 situations 规划人道援助的关键。大型自然语言模型（LLM）因其可以生成协调的文本和完成多种与影响报告相关的任务，如问答或文本摘要。然而，LLM 受训数据中知识的限制，容易生成错误或 "幻见" 信息。为解决这问题，我们提出了一个复杂的管道，并在我们的工具 FloodBrain (floodbrain.com) 中实现了生成洪水灾害影响报告。我们的管道从网络搜索结果中提取和筛选信息，生成详细和准确的洪水事件报告。我们测试了不同的 LLM 作为管道的脑库，并与人类评估器的评分相比较。与其他研究相似，我们发现了 GPT-4 的评分和人类评估器的评分之间存在显著的相关性。此外，我们还进行了减少学Component 的研究，以评估它们在最终报告中的重要性。我们的工具 aim 是使用 LLM 进行灾害影响报告，提高人道援助协调的效率，并减少洪水灾害后的协调时间。
</details></li>
</ul>
<hr>
<h2 id="scBeacon-single-cell-biomarker-extraction-via-identifying-paired-cell-clusters-across-biological-conditions-with-contrastive-siamese-networks"><a href="#scBeacon-single-cell-biomarker-extraction-via-identifying-paired-cell-clusters-across-biological-conditions-with-contrastive-siamese-networks" class="headerlink" title="scBeacon: single-cell biomarker extraction via identifying paired cell clusters across biological conditions with contrastive siamese networks"></a>scBeacon: single-cell biomarker extraction via identifying paired cell clusters across biological conditions with contrastive siamese networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02594">http://arxiv.org/abs/2311.02594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyu Liu, Kweon Yong Jin, Jun Ding</li>
<li>for: 这篇论文旨在提高单细胞水平的标识分析，尤其是在疾病和健康状态之间的交互作用下。</li>
<li>methods: 这篇论文提出了一个名为 scBeacon 的新的框架，这是一个基于深度对称 siamese 网络的无监控方法，可以对单细胞水平的标识进行分组，并且可以对不同状态下的单细胞进行匹配。</li>
<li>results: 根据评估结果，scBeacon 在各种数据集上表现出色，较 existing 的单细胞标识分析工具有更高的精度和灵活性。<details>
<summary>Abstract</summary>
Despite the breakthroughs in biomarker discovery facilitated by differential gene analysis, challenges remain, particularly at the single-cell level. Traditional methodologies heavily rely on user-supplied cell annotations, focusing on individually expressed data, often neglecting the critical interactions between biological conditions, such as healthy versus diseased states. In response, here we introduce scBeacon, an innovative framework built upon a deep contrastive siamese network. scBeacon pioneers an unsupervised approach, adeptly identifying matched cell populations across varied conditions, enabling a refined differential gene analysis. By utilizing a VQ-VAE framework, a contrastive siamese network, and a greedy iterative strategy, scBeacon effectively pinpoints differential genes that hold potential as key biomarkers. Comprehensive evaluations on a diverse array of datasets validate scBeacon's superiority over existing single-cell differential gene analysis tools. Its precision and adaptability underscore its significant role in enhancing diagnostic accuracy in biomarker discovery. With the emphasis on the importance of biomarkers in diagnosis, scBeacon is positioned to be a pivotal asset in the evolution of personalized medicine and targeted treatments.
</details>
<details>
<summary>摘要</summary>
尽管生物标志物发现方面已经做出了重大突破，但是在单个细胞水平还存在一些挑战。传统的方法ologies依赖用户提供的细胞注释，宁静关注个别表达数据，经常忽略生物条件之间的关键互动，如健康与疾病状态之间的对比。为此，我们在这里引入scBeacon，一种创新的框架，基于深度对比性同构网络。scBeacon采用无监督方法，能够准确地匹配不同状态下的细胞人口，从而提高了差异基因分析的精度。通过VQ-VAE框架、对比性同构网络和迅速迭代策略，scBeacon可以有效地找到具有潜在作用的差异基因，这些基因可能成为重要的生物标志物。对于一系列多样化的数据集进行了全面的评估，scBeacon的精度和适应性得到了证明，与现有的单个细胞差异基因分析工具相比，具有显著的优势。鉴于生物标志物在诊断中的重要性，scBeacon将成为个人化医学和Targeted therapy的核心资产。
</details></li>
</ul>
<hr>
<h2 id="Differentially-Private-Pre-Trained-Model-Fusion-using-Decentralized-Federated-Graph-Matching"><a href="#Differentially-Private-Pre-Trained-Model-Fusion-using-Decentralized-Federated-Graph-Matching" class="headerlink" title="Differentially Private Pre-Trained Model Fusion using Decentralized Federated Graph Matching"></a>Differentially Private Pre-Trained Model Fusion using Decentralized Federated Graph Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03396">http://arxiv.org/abs/2311.03396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qian Chen, Yiqiang Chen, Xinlong Jiang, Teng Zhang, Weiwei Dai, Wuliang Huang, Zhen Yan, Bo Ye</li>
<li>for: 本研究旨在提供一种保持隐私的模型融合方法，以便在模型作为服务的场景中实现高质量的模型服务传递。</li>
<li>methods: 本研究使用了图structured architecture，并采用了本地差分隐私机制和分布式联合图匹配来保证模型融合过程中的隐私。</li>
<li>results: 实验结果表明，PrivFusion可以保持模型性能的同时保障隐私，并且在实际的医疗应用中得到了较好的效果。<details>
<summary>Abstract</summary>
Model fusion is becoming a crucial component in the context of model-as-a-service scenarios, enabling the delivery of high-quality model services to local users. However, this approach introduces privacy risks and imposes certain limitations on its applications. Ensuring secure model exchange and knowledge fusion among users becomes a significant challenge in this setting. To tackle this issue, we propose PrivFusion, a novel architecture that preserves privacy while facilitating model fusion under the constraints of local differential privacy. PrivFusion leverages a graph-based structure, enabling the fusion of models from multiple parties without necessitating retraining. By employing randomized mechanisms, PrivFusion ensures privacy guarantees throughout the fusion process. To enhance model privacy, our approach incorporates a hybrid local differentially private mechanism and decentralized federated graph matching, effectively protecting both activation values and weights. Additionally, we introduce a perturbation filter adapter to alleviate the impact of randomized noise, thereby preserving the utility of the fused model. Through extensive experiments conducted on diverse image datasets and real-world healthcare applications, we provide empirical evidence showcasing the effectiveness of PrivFusion in maintaining model performance while preserving privacy. Our contributions offer valuable insights and practical solutions for secure and collaborative data analysis within the domain of privacy-preserving model fusion.
</details>
<details>
<summary>摘要</summary>
<<SYS>>模型融合在服务模式下成为关键组件，使得本地用户获得高质量模型服务。然而，这种方法带来隐私风险并带来一些应用限制。保持安全的模型交换和用户知识融合成为这种设置中的主要挑战。为解决这个问题，我们提出了 PrivFusion，一种新的架构，可以在保持隐私的情况下进行模型融合。PrivFusion利用图structured，可以在多方参与者的情况下进行模型融合，不需要重新训练。通过随机机制，PrivFusion保证了隐私保障 throughout the fusion process。为增强模型隐私，我们的方法包括了hybrid本地分布式隐私机制和分布式图匹配，以保护模型的活动值和权重。此外，我们还提出了抑制随机噪声的滤波器适配器，以降低随机噪声的影响，保持融合模型的用用性。通过对多个图像数据集和实际医疗应用进行了广泛的实验，我们提供了Empirical evidence，证明PrivFusion可以保持模型性能的同时保护隐私。我们的贡献提供了有价值的实践解决方案和技术方法，用于在隐私保护下进行安全的数据分析。
</details></li>
</ul>
<hr>
<h2 id="Newvision-application-for-helping-blind-people-using-deep-learning"><a href="#Newvision-application-for-helping-blind-people-using-deep-learning" class="headerlink" title="Newvision: application for helping blind people using deep learning"></a>Newvision: application for helping blind people using deep learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03395">http://arxiv.org/abs/2311.03395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumar Srinivas Bobba, Kartheeban K, Vamsi Krishna Sai Boddu, Vijaya Mani Surendra Bolla, Dinesh Bugga</li>
<li>for: 帮助视障人群在日常生活中独立行动，提高生活质量。</li>
<li>methods: 使用计算机视觉、距离估算附加于超声波传感器、语音识别和语音助手，为用户提供实时环境信息。</li>
<li>results: 可以帮助视障人群在环境中导航、识别物体和人员、阅读文本、避免障碍。<details>
<summary>Abstract</summary>
As able-bodied people, we often take our vision for granted. For people who are visually impaired, however, their disability can have a significant impact on their daily lives. We are developing proprietary headgear that will help visually impaired people navigate their surroundings, identify objects and people, read text, and avoid obstacles. The headgear will use a combination of computer vision, distance estimation with ultrasonic sensors, voice recognition, and voice assistants to provide users with real-time information about their environment. Users will be able to interact with the headgear through voice commands, such as ''What is that?'' to identify an object or ''Navigate to the front door'' to find their way around. The headgear will then provide the user with a verbal description of the object or spoken navigation instructions. We believe that this headgear has the potential to make a significant difference in the lives of visually impaired people, allowing them to live more independently and participate more fully in society.
</details>
<details>
<summary>摘要</summary>
As 能够的人们，我们经常忽略我们的视力。但对于有视力障碍的人们，他们的障碍可能会对他们的日常生活产生深远的影响。我们正在开发专有的头盔，帮助有视力障碍的人们在环境中导航、识别物体和人员、阅读文本，并避免障碍。这个头盔使用计算机视觉、ultrasonic探测、语音识别和语音助手等技术，为用户提供实时环境信息。用户可以通过声音命令，如 ''什么是那？'' 识别物体，或 ''导航到门口'' 查找方向。头盔然后为用户提供物体的声音描述或导航说明。我们认为这个头盔有可能对有视力障碍人员的生活产生深远的影响，让他们更独立地生活，更全面地参与社会。
</details></li>
</ul>
<hr>
<h2 id="KITS-Inductive-Spatio-Temporal-Kriging-with-Increment-Training-Strategy"><a href="#KITS-Inductive-Spatio-Temporal-Kriging-with-Increment-Training-Strategy" class="headerlink" title="KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy"></a>KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02565">http://arxiv.org/abs/2311.02565</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qianxiong Xu, Cheng Long, Ziyue Li, Sijie Ruan, Rui Zhao, Zhishuai Li</li>
<li>For: This paper proposes a new method called KITS (Kriging with Increment Training Strategy) to address the issue of graph gap in inductive spatio-temporal kriging methods based on graph neural networks.* Methods: The KITS method adds virtual nodes to the training graph to mitigate the graph gap issue, and pairs each virtual node with its most similar observed node to fuse their features together. The method also constructs reliable pseudo labels for virtual nodes to enhance the supervision signal.* Results: The KITS method consistently outperforms existing kriging methods by large margins, with an improvement over MAE score of up to 18.33%.<details>
<summary>Abstract</summary>
Sensors are commonly deployed to perceive the environment. However, due to the high cost, sensors are usually sparsely deployed. Kriging is the tailored task to infer the unobserved nodes (without sensors) using the observed source nodes (with sensors). The essence of kriging task is transferability. Recently, several inductive spatio-temporal kriging methods have been proposed based on graph neural networks, being trained based on a graph built on top of observed nodes via pretext tasks such as masking nodes out and reconstructing them. However, the graph in training is inevitably much sparser than the graph in inference that includes all the observed and unobserved nodes. The learned pattern cannot be well generalized for inference, denoted as graph gap. To address this issue, we first present a novel Increment training strategy: instead of masking nodes (and reconstructing them), we add virtual nodes into the training graph so as to mitigate the graph gap issue naturally. Nevertheless, the empty-shell virtual nodes without labels could have bad-learned features and lack supervision signals. To solve these issues, we pair each virtual node with its most similar observed node and fuse their features together; to enhance the supervision signal, we construct reliable pseudo labels for virtual nodes. As a result, the learned pattern of virtual nodes could be safely transferred to real unobserved nodes for reliable kriging. We name our new Kriging model with Increment Training Strategy as KITS. Extensive experiments demonstrate that KITS consistently outperforms existing kriging methods by large margins, e.g., the improvement over MAE score could be as high as 18.33%.
</details>
<details>
<summary>摘要</summary>
感知器通常用于感知环境。然而，由于成本高昂，感知器通常会受到稀畴部署。基于树状网络的 krilling 任务可以用来推断没有感知器的节点（无感知节点）。 krilling 任务的核心思想是传播性。现在，基于图ael 神经网络的一些 inductive spatio-temporal krilling 方法已经被提出，这些方法通过在观察节点基础上建立图来进行训练，然后通过预测任务来学习。然而，训练图和推断图都包含所有观察和无感知节点，这会导致学习的模式难以在推断中 generalized。这种问题被称为图 gap。为解决这个问题，我们首先提出了一种新的增量训练策略：而不是将节点屏蔽（并重建它们），我们会将虚拟节点添加到训练图中，以mitigate the graph gap issue naturally。然而，空 shell 的虚拟节点没有标签可能会有坏学习特征和缺乏监督信号。为解决这些问题，我们将每个虚拟节点与其最相似的观察节点进行对应，并将它们的特征特性相加。此外，为增强监督信号，我们将虚拟节点的 pseudo label 建立起来。因此，学习的虚拟节点模式可以安全地传输到实际的无感知节点，以确保可靠的 krilling。我们称之为 KITS。我们的实验表明，KITS 可以大幅超过现有的 krilling 方法，例如 MAE 分数的改进率可以高达 18.33%。
</details></li>
</ul>
<hr>
<h2 id="Time-Series-Synthesis-Using-the-Matrix-Profile-for-Anonymization"><a href="#Time-Series-Synthesis-Using-the-Matrix-Profile-for-Anonymization" class="headerlink" title="Time Series Synthesis Using the Matrix Profile for Anonymization"></a>Time Series Synthesis Using the Matrix Profile for Anonymization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02563">http://arxiv.org/abs/2311.02563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Audrey Der, Chin-Chia Michael Yeh, Yan Zheng, Junpeng Wang, Huiyuan Chen, Zhongfang Zhuang, Liang Wang, Wei Zhang, Eamonn Keogh</li>
<li>for: 提供一种方法 Synthesize time series data，以便在保持数据相似性的情况下，避免遵循 privacy regulations 或 commercial confidentiality 的限制。</li>
<li>methods: 提出了 Time Series Synthesis Using Matrix Profile (TSSUMP) 方法，该方法可以在保持数据相似性的情况下，将时间序列数据synthesized，以便在数据分析 tasks 中使用。</li>
<li>results: 通过实际案例研究，表明 TSSUMP 方法可以减少时间序列数据的相关性，同时保持数据的相似性，使得数据分析工具可以在synthesized时间序列上达到 near-identical 性能。<details>
<summary>Abstract</summary>
Publishing and sharing data is crucial for the data mining community, allowing collaboration and driving open innovation. However, many researchers cannot release their data due to privacy regulations or fear of leaking confidential business information. To alleviate such issues, we propose the Time Series Synthesis Using the Matrix Profile (TSSUMP) method, where synthesized time series can be released in lieu of the original data. The TSSUMP method synthesizes time series by preserving similarity join information (i.e., Matrix Profile) while reducing the correlation between the synthesized and the original time series. As a result, neither the values for the individual time steps nor the local patterns (or shapes) from the original data can be recovered, yet the resulting data can be used for downstream tasks that data analysts are interested in. We concentrate on similarity joins because they are one of the most widely applied time series data mining routines across different data mining tasks. We test our method on a case study of ECG and gender masking prediction. In this case study, the gender information is not only removed from the synthesized time series, but the synthesized time series also preserves enough information from the original time series. As a result, unmodified data mining tools can obtain near-identical performance on the synthesized time series as on the original time series.
</details>
<details>
<summary>摘要</summary>
发布和分享数据对数据挖掘社区至关重要，它帮助研究人员合作和推动开放创新。然而，许多研究人员无法发布自己的数据，因为隐私法规或担心泄露商业机密信息。为解决这些问题，我们提出了时间序列合成使用矩阵Profile（TSSUMP）方法，其中合成的时间序列可以代替原始数据。TSSUMP方法将时间序列合成，保持相似性Join信息（即矩阵Profile），同时减少合成时间序列和原始时间序列之间的相关性。因此，不能回归原始数据中的值，也不能回归本地特征（或形状）。然而，合成的数据仍然可以用于下游任务，数据分析师感兴趣的任务。我们专注于相似Join，因为它们是时间序列数据挖掘任务中最常用的 Routine。我们在ECG和性别遮盾预测case study中测试了我们的方法。在这个case study中， gender信息不仅从合成的时间序列中被除了，还保留了原始时间序列中的足够信息。因此，未修改的数据挖掘工具可以在合成的时间序列上获得近似于原始时间序列的性能。
</details></li>
</ul>
<hr>
<h2 id="Ego-Network-Transformer-for-Subsequence-Classification-in-Time-Series-Data"><a href="#Ego-Network-Transformer-for-Subsequence-Classification-in-Time-Series-Data" class="headerlink" title="Ego-Network Transformer for Subsequence Classification in Time Series Data"></a>Ego-Network Transformer for Subsequence Classification in Time Series Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02561">http://arxiv.org/abs/2311.02561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chin-Chia Michael Yeh, Huiyuan Chen, Yujie Fan, Xin Dai, Yan Zheng, Vivian Lai, Junpeng Wang, Zhongfang Zhuang, Liang Wang, Wei Zhang, Eamonn Keogh</li>
<li>for: 这篇论文旨在解决实际时间序列数据中的背景序列与前景序列混合类别问题。</li>
<li>methods: 本论文提出了一个新的时间序列子序列分类方法，将每个子序列表示为一个自我网络，具有重要最近邻信息。</li>
<li>results: 根据128个单变量和30个多变量时间序列数据集进行实验，结果显示本方法比据点方法表现出色，在104个数据集中表现更好。<details>
<summary>Abstract</summary>
Time series classification is a widely studied problem in the field of time series data mining. Previous research has predominantly focused on scenarios where relevant or foreground subsequences have already been extracted, with each subsequence corresponding to a single label. However, real-world time series data often contain foreground subsequences that are intertwined with background subsequences. Successfully classifying these relevant subsequences requires not only distinguishing between different classes but also accurately identifying the foreground subsequences amidst the background. To address this challenge, we propose a novel subsequence classification method that represents each subsequence as an ego-network, providing crucial nearest neighbor information to the model. The ego-networks of all subsequences collectively form a time series subsequence graph, and we introduce an algorithm to efficiently construct this graph. Furthermore, we have demonstrated the significance of enforcing temporal consistency in the prediction of adjacent subsequences for the subsequence classification problem. To evaluate the effectiveness of our approach, we conducted experiments using 128 univariate and 30 multivariate time series datasets. The experimental results demonstrate the superior performance of our method compared to alternative approaches. Specifically, our method outperforms the baseline on 104 out of 158 datasets.
</details>
<details>
<summary>摘要</summary>
时间序列分类是时间序列数据挖掘领域广泛研究的问题。先前的研究主要集中在已经提取了相关或前景 subsequences 的情况下进行研究，每个 subsequences 都对应一个单独的标签。然而，实际世界中的时间序列数据经常包含相关的前景 subsequences，需要不仅分辨不同的类型，还需要准确地识别前景 subsequences 中的相关部分。为解决这个挑战，我们提出了一种新的 subsequences 分类方法，即将每个 subsequences 表示为一个自我网络，提供了关键的最近邻居信息给模型。所有 subsequences 的ego-networks 共同形成了时间序列 subsequences 图，我们介绍了一种有效地构建这个图的算法。此外，我们还证明了在预测相邻 subsequences 时应该保持时间一致性的重要性。为评估我们的方法的有效性，我们对 128 个单variate 和 30 个多variate 时间序列数据集进行了实验。实验结果表明，我们的方法与其他方法相比，在 104 个数据集上表现出了更高的性能。具体来说，我们的方法在 158 个数据集中超过了基准值。
</details></li>
</ul>
<hr>
<h2 id="Sketching-Multidimensional-Time-Series-for-Fast-Discord-Mining"><a href="#Sketching-Multidimensional-Time-Series-for-Fast-Discord-Mining" class="headerlink" title="Sketching Multidimensional Time Series for Fast Discord Mining"></a>Sketching Multidimensional Time Series for Fast Discord Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03393">http://arxiv.org/abs/2311.03393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chin-Chia Michael Yeh, Yan Zheng, Menghai Pan, Huiyuan Chen, Zhongfang Zhuang, Junpeng Wang, Liang Wang, Wei Zhang, Jeff M. Phillips, Eamonn Keogh</li>
<li>for: 本研究旨在提高多维时间序列异常检测中维度缩放的效率，并提供一种可靠地检测多维时间序列异常的方法。</li>
<li>methods: 本研究使用缩放矩阵 Profile 来捕捉时间序列异常，并提出一种基于缩放矩阵的快速异常检测算法。</li>
<li>results: 实验结果表明，提出的算法可以在多个实际世界应用中提高吞吐量，并且只具有 minimal impact on the quality of the approximated solution。此外，该算法还可以处理动态添加或删除维度的情况，允许数据分析师在实时进行 “what-if” 分析。<details>
<summary>Abstract</summary>
Time series discords are a useful primitive for time series anomaly detection, and the matrix profile is capable of capturing discord effectively. There exist many research efforts to improve the scalability of discord discovery with respect to the length of time series. However, there is surprisingly little work focused on reducing the time complexity of matrix profile computation associated with dimensionality of a multidimensional time series. In this work, we propose a sketch for discord mining among multi-dimensional time series. After an initial pre-processing of the sketch as fast as reading the data, the discord mining has runtime independent of the dimensionality of the original data. On several real world examples from water treatment and transportation, the proposed algorithm improves the throughput by at least an order of magnitude (50X) and only has minimal impact on the quality of the approximated solution. Additionally, the proposed method can handle the dynamic addition or deletion of dimensions inconsequential overhead. This allows a data analyst to consider "what-if" scenarios in real time while exploring the data.
</details>
<details>
<summary>摘要</summary>
时序列冲突是一种有用的原始 primitives  для时序列异常检测，matrix profile 可以有效地捕捉冲突。有很多研究努力以提高时序列冲突发现的可扩展性，但是奇怪的是，有 surprisingly little work focused on reducing the time complexity of matrix profile computation associated with the dimensionality of a multidimensional time series.在这种工作中，我们提议一种笔记 для多维时序列冲突挖掘。经过初始快速预处理的笔记，冲突挖掘的运行时间与原始数据的维度无关。在几个实际世界示例中（水处理和交通），我们提出的算法可以提高通过put throughput 至少一个数量级（50X），并且只有 minimal impact on the quality of the approximated solution。此外，我们的方法还可以处理动态添加或删除维度的无关 overhead。这意味着数据分析师可以在实时中考虑 "what-if" 场景，在探索数据时进行实时探索。
</details></li>
</ul>
<hr>
<h2 id="Nonlinear-Multi-objective-Reinforcement-Learning-with-Provable-Guarantees"><a href="#Nonlinear-Multi-objective-Reinforcement-Learning-with-Provable-Guarantees" class="headerlink" title="Nonlinear Multi-objective Reinforcement Learning with Provable Guarantees"></a>Nonlinear Multi-objective Reinforcement Learning with Provable Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02544">http://arxiv.org/abs/2311.02544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nianli Peng, Brandon Fain</li>
<li>for: 解决单或多目标Markov决策过程（MDP）中 maximize 期望值的非线性函数。</li>
<li>methods: 使用证明可靠的保证来解决这些问题，扩展了经典的E3算法，并提出了一种基于奖励意识的值迭代过程，以及一种同时学习环境模型的算法。</li>
<li>results: 该算法可以在很短的时间内获得一个约等于优化的策略，时间复杂度为MDP大小、欲达到的拟合度和非线性函数的平滑程度的高阶幂。<details>
<summary>Abstract</summary>
We describe RA-E3 (Reward-Aware Explicit Explore or Exploit), an algorithm with provable guarantees for solving a single or multi-objective Markov Decision Process (MDP) where we want to maximize the expected value of a nonlinear function over accumulated rewards. This allows us to model fairness-aware welfare optimization for multi-objective reinforcement learning as well as risk-aware reinforcement learning with nonlinear Von Neumann-Morgenstern utility functions in the single objective setting. RA-E3 extends the classic E3 algorithm that solves MDPs with scalar rewards and linear preferences. We first state a distinct reward-aware version of value iteration that calculates a non-stationary policy that is approximately optimal for a given model of the environment. This sub-procedure is based on an extended form of Bellman optimality for nonlinear optimization that explicitly considers time and current accumulated reward. We then describe how to use this optimization procedure in a larger algorithm that must simultaneously learn a model of the environment. The algorithm learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.
</details>
<details>
<summary>摘要</summary>
我们描述RA-E3（奖励意识的明确探索或利用算法），这是一个具有证明保证的算法，用于解决单或多个目标Markov决策过程（MDP），以 Maximize the expected value of a nonlinear function over accumulated rewards. 这Permit us to model fairness-aware welfare optimization for multi-objective reinforcement learning as well as risk-aware reinforcement learning with nonlinear Von Neumann-Morgenstern utility functions in the single objective setting. RA-E3 extends the classic E3 algorithm that solves MDPs with scalar rewards and linear preferences. We first state a distinct reward-aware version of value iteration that calculates a non-stationary policy that is approximately optimal for a given model of the environment. This sub-procedure is based on an extended form of Bellman optimality for nonlinear optimization that explicitly considers time and current accumulated reward. We then describe how to use this optimization procedure in a larger algorithm that must simultaneously learn a model of the environment. The algorithm learns an approximately optimal policy in time that depends polynomially on the MDP size, desired approximation, and smoothness of the nonlinear function, and exponentially on the number of objectives.
</details></li>
</ul>
<hr>
<h2 id="Dense-Video-Captioning-A-Survey-of-Techniques-Datasets-and-Evaluation-Protocols"><a href="#Dense-Video-Captioning-A-Survey-of-Techniques-Datasets-and-Evaluation-Protocols" class="headerlink" title="Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation Protocols"></a>Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation Protocols</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02538">http://arxiv.org/abs/2311.02538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iqra Qasim, Alexander Horsch, Dilip K. Prasad</li>
<li>for: 本研究旨在描述视频中的各种事件和互动，以提高视频的自然语言描述能力。</li>
<li>methods: 本研究使用了 dense video captioning (DVC) 技术，包括视频特征提取 (VFE)、时间事件Localization (TEL) 和高密度caption生成 (DCG) 三个子任务。</li>
<li>results: 研究人员通过实现DVC技术来描述视频中的各种事件和互动，并获得了较好的结果。<details>
<summary>Abstract</summary>
Untrimmed videos have interrelated events, dependencies, context, overlapping events, object-object interactions, domain specificity, and other semantics that are worth highlighting while describing a video in natural language. Owing to such a vast diversity, a single sentence can only correctly describe a portion of the video. Dense Video Captioning (DVC) aims at detecting and describing different events in a given video. The term DVC originated in the 2017 ActivityNet challenge, after which considerable effort has been made to address the challenge. Dense Video Captioning is divided into three sub-tasks: (1) Video Feature Extraction (VFE), (2) Temporal Event Localization (TEL), and (3) Dense Caption Generation (DCG). This review aims to discuss all the studies that claim to perform DVC along with its sub-tasks and summarize their results. We also discuss all the datasets that have been used for DVC. Lastly, we highlight some emerging challenges and future trends in the field.
</details>
<details>
<summary>摘要</summary>
<<SYS>> simulti-translation:en-cn原文：Untrimmed videos have interrelated events, dependencies, context, overlapping events, object-object interactions, domain specificity, and other semantics that are worth highlighting while describing a video in natural language. Owing to such a vast diversity, a single sentence can only correctly describe a portion of the video. Dense Video Captioning (DVC) aims at detecting and describing different events in a given video. The term DVC originated in the 2017 ActivityNet challenge, after which considerable effort has been made to address the challenge. Dense Video Captioning is divided into three sub-tasks: (1) Video Feature Extraction (VFE), (2) Temporal Event Localization (TEL), and (3) Dense Caption Generation (DCG). This review aims to discuss all the studies that claim to perform DVC along with its sub-tasks and summarize their results. We also discuss all the datasets that have been used for DVC. Lastly, we highlight some emerging challenges and future trends in the field.翻译：视频中有关联的事件、依赖关系、上下文、重叠事件、对象之间交互、域特定性和其他semantics，这些都值得在描述视频的自然语言中提到。由于这种广泛的多样性，单个句子只能正确描述视频的一部分。dense video captioning（DVC）目标在检测和描述视频中的不同事件。DVC的概念在2017年的ActivityNet挑战之后得到了广泛的努力，以解决这个挑战。DVC分为三个子任务：（1）视频特征提取（VFE），（2）时间事件地理位置（TEL），和（3）密集caption生成（DCG）。本文尝试讨论所有宣称实现DVC的研究，以及它们的结果。我们还讨论了所有用于DVC的数据集。最后，我们提出了一些emerging挑战和未来趋势。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.AI_2023_11_05/" data-id="clpahu6z6006l3h88do7x1t34" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.CL_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T11:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/cs.CL_2023_11_05/">cs.CL - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Robust-Generalization-Strategies-for-Morpheme-Glossing-in-an-Endangered-Language-Documentation-Context"><a href="#Robust-Generalization-Strategies-for-Morpheme-Glossing-in-an-Endangered-Language-Documentation-Context" class="headerlink" title="Robust Generalization Strategies for Morpheme Glossing in an Endangered Language Documentation Context"></a>Robust Generalization Strategies for Morpheme Glossing in an Endangered Language Documentation Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02777">http://arxiv.org/abs/2311.02777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Ginn, Alexis Palmer</li>
<li>for: 这篇论文旨在 investigate the ability of morpheme labeling models to generalize, especially in resource-constrained settings.</li>
<li>methods: 这篇论文使用 weight decay optimization, output denoising, and iterative pseudo-labeling 方法来减少模型在不同类型文本上的差异性。</li>
<li>results:  experiments 表明，通过使用这些方法，模型的性能在未经见过的类型文本上提高了2%。<details>
<summary>Abstract</summary>
Generalization is of particular importance in resource-constrained settings, where the available training data may represent only a small fraction of the distribution of possible texts. We investigate the ability of morpheme labeling models to generalize by evaluating their performance on unseen genres of text, and we experiment with strategies for closing the gap between performance on in-distribution and out-of-distribution data. Specifically, we use weight decay optimization, output denoising, and iterative pseudo-labeling, and achieve a 2% improvement on a test set containing texts from unseen genres. All experiments are performed using texts written in the Mayan language Uspanteko.
</details>
<details>
<summary>摘要</summary>
通用化在有限资源的情况下 particualrly important, where the available training data may only represent a small fraction of the distribution of possible texts. We investigate the ability of morpheme labeling models to generalize by evaluating their performance on unseen genres of text, and we experiment with strategies for closing the gap between performance on in-distribution and out-of-distribution data. Specifically, we use weight decay optimization, output denoising, and iterative pseudo-labeling, and achieve a 2% improvement on a test set containing texts from unseen genres. All experiments are performed using texts written in the Mayan language Uspanteko.Here's the text with Traditional Chinese characters:通用化在有限资源的情况下 particualrly important, where the available training data may only represent a small fraction of the distribution of possible texts. We investigate the ability of morpheme labeling models to generalize by evaluating their performance on unseen genres of text, and we experiment with strategies for closing the gap between performance on in-distribution and out-of-distribution data. Specifically, we use weight decay optimization, output denoising, and iterative pseudo-labeling, and achieve a 2% improvement on a test set containing texts from unseen genres. All experiments are performed using texts written in the Mayan language Uspanteko.
</details></li>
</ul>
<hr>
<h2 id="Attention-or-Convolution-Transformer-Encoders-in-Audio-Language-Models-for-Inference-Efficiency"><a href="#Attention-or-Convolution-Transformer-Encoders-in-Audio-Language-Models-for-Inference-Efficiency" class="headerlink" title="Attention or Convolution: Transformer Encoders in Audio Language Models for Inference Efficiency"></a>Attention or Convolution: Transformer Encoders in Audio Language Models for Inference Efficiency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02772">http://arxiv.org/abs/2311.02772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungho Jeon, Ching-Feng Yeh, Hakan Inan, Wei-Ning Hsu, Rashi Rungta, Yashar Mehdad, Daniel Bikel</li>
<li>for: 这个论文目的是提出一种简单自编程的音频模型，可以达到与更复杂的预训练模型相同的推理效率。</li>
<li>methods: 这个论文使用了混合卷积模块和自注意模块的speech transformerEncoder，实现了ASR的state-of-the-art性和高效性。</li>
<li>results: 研究表明，使用这种speech transformerEncoder可以大幅提高预训练音频模型的效率，但是我们还可以通过使用高级自注意来实现相同的效率。此外，我们发现使用低位数字量化技术可以进一步提高效率。<details>
<summary>Abstract</summary>
In this paper, we show that a simple self-supervised pre-trained audio model can achieve comparable inference efficiency to more complicated pre-trained models with speech transformer encoders. These speech transformers rely on mixing convolutional modules with self-attention modules. They achieve state-of-the-art performance on ASR with top efficiency. We first show that employing these speech transformers as an encoder significantly improves the efficiency of pre-trained audio models as well. However, our study shows that we can achieve comparable efficiency with advanced self-attention solely. We demonstrate that this simpler approach is particularly beneficial with a low-bit weight quantization technique of a neural network to improve efficiency. We hypothesize that it prevents propagating the errors between different quantized modules compared to recent speech transformers mixing quantized convolution and the quantized self-attention modules.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们显示了一种简单的自我超vised预训练音频模型可以达到与更复杂的预训练模型（具有speech transformer Encoder）相当的推理效率。这些speech transformer Encoder通过混合径向模块与自我注意模块来实现了ASR中的状态环境。我们首先显示了使用这些speech transformer Encoder作为encoder可以显著提高预训练音频模型的效率。然而，我们的研究表明，我们可以通过高级自我注意来实现相同的效率。我们示出了这种更简单的方法在使用低位数量量化神经网络时 particualrly有利。我们假设这种方法可以避免在不同量化模块之间传递错误，相比之下，当前的speech transformers混合量化径向模块和量化自我注意模块。
</details></li>
</ul>
<hr>
<h2 id="Pyclipse-a-library-for-deidentification-of-free-text-clinical-notes"><a href="#Pyclipse-a-library-for-deidentification-of-free-text-clinical-notes" class="headerlink" title="Pyclipse, a library for deidentification of free-text clinical notes"></a>Pyclipse, a library for deidentification of free-text clinical notes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02748">http://arxiv.org/abs/2311.02748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Callandra Moore, Jonathan Ranisau, Walter Nelson, Jeremy Petch, Alistair Johnson</li>
<li>for:  Automated deidentification of clinical text data is crucial due to the high cost of manual deidentification, which has been a barrier to sharing clinical text and the advancement of clinical natural language processing.</li>
<li>methods:  The pyclipse framework is proposed to address the challenges of creating effective automated deidentification tools, including issues in reproducibility due to differences in text processing, evaluation methods, and a lack of consistency across clinical domains and institutions.</li>
<li>results:  The pyclipse framework is demonstrated to be a unified and configurable evaluation procedure that can streamline the comparison of deidentification algorithms, and it is found that algorithm performance consistently falls short of the results reported in the original papers, even when evaluated on the same benchmark dataset.<details>
<summary>Abstract</summary>
Automated deidentification of clinical text data is crucial due to the high cost of manual deidentification, which has been a barrier to sharing clinical text and the advancement of clinical natural language processing. However, creating effective automated deidentification tools faces several challenges, including issues in reproducibility due to differences in text processing, evaluation methods, and a lack of consistency across clinical domains and institutions. To address these challenges, we propose the pyclipse framework, a unified and configurable evaluation procedure to streamline the comparison of deidentification algorithms. Pyclipse serves as a single interface for running open-source deidentification algorithms on local clinical data, allowing for context-specific evaluation. To demonstrate the utility of pyclipse, we compare six deidentification algorithms across four public and two private clinical text datasets. We find that algorithm performance consistently falls short of the results reported in the original papers, even when evaluated on the same benchmark dataset. These discrepancies highlight the complexity of accurately assessing and comparing deidentification algorithms, emphasizing the need for a reproducible, adjustable, and extensible framework like pyclipse. Our framework lays the foundation for a unified approach to evaluate and improve deidentification tools, ultimately enhancing patient protection in clinical natural language processing.
</details>
<details>
<summary>摘要</summary>
自动化识别临床文本数据的重要性在于手动识别的高成本，这成为了临床自然语言处理的发展的一个障碍。然而，创建有效的自动化识别工具面临着许多挑战，包括评估方法的不同和临床领域和机构之间的不一致性。为解决这些挑战，我们提出了pyclipse框架，一个可配置的评估过程框架，可以帮助Streamline识别算法的比较。pyclipse提供了一个单一的界面，可以在本地临床数据上运行开源识别算法，并为每个临床领域和机构提供上下文特定的评估。为了证明pyclipse的有用性，我们将比较六种识别算法在四个公共和两个私人临床文本数据集上的表现。我们发现，算法的表现 consistently short of the results reported in the original papers, even when evaluated on the same benchmark dataset.这些差异 highlights the complexity of accurately assessing and comparing deidentification algorithms, emphasizing the need for a reproducible, adjustable, and extensible framework like pyclipse.我们的框架为识别工具的评估和改进提供了一个统一的方法，从而推动了患者保护在临床自然语言处理中。
</details></li>
</ul>
<hr>
<h2 id="Nepali-Video-Captioning-using-CNN-RNN-Architecture"><a href="#Nepali-Video-Captioning-using-CNN-RNN-Architecture" class="headerlink" title="Nepali Video Captioning using CNN-RNN Architecture"></a>Nepali Video Captioning using CNN-RNN Architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02699">http://arxiv.org/abs/2311.02699</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bipesh Subedi, Saugat Singh, Bal Krishna Bal</li>
<li>for: 这个研究旨在开发一个基于深度神经网络的尼泊尔视频描述系统，以提供精准和contextually relevant的视频描述 для尼泊尔视频。</li>
<li>methods: 该研究使用了预训练的CNN和RNN，并通过数据采集、数据处理、模型实现和评估来实现目标。研究使用了Google翻译将MSVD数据集扩展到尼泊尔语描述，然后训练了不同的CNN-RNN架构。</li>
<li>results: 研究发现，使用EfficientNetB0和BiLSTM结构的模型在BLEU和METEOR metric上达到了17和46的分数。此外，研究还描述了在尼泊尔语视频描述方面遇到的挑战和未来研究的方向。<details>
<summary>Abstract</summary>
This article presents a study on Nepali video captioning using deep neural networks. Through the integration of pre-trained CNNs and RNNs, the research focuses on generating precise and contextually relevant captions for Nepali videos. The approach involves dataset collection, data preprocessing, model implementation, and evaluation. By enriching the MSVD dataset with Nepali captions via Google Translate, the study trains various CNN-RNN architectures. The research explores the effectiveness of CNNs (e.g., EfficientNetB0, ResNet101, VGG16) paired with different RNN decoders like LSTM, GRU, and BiLSTM. Evaluation involves BLEU and METEOR metrics, with the best model being EfficientNetB0 + BiLSTM with 1024 hidden dimensions, achieving a BLEU-4 score of 17 and METEOR score of 46. The article also outlines challenges and future directions for advancing Nepali video captioning, offering a crucial resource for further research in this area.
</details>
<details>
<summary>摘要</summary>
The study involves several steps, including dataset collection, data preprocessing, model implementation, and evaluation. To enrich the MSVD dataset with Nepali captions, the researchers use Google Translate to add captions to the videos. They then train various CNN-RNN architectures, including EfficientNetB0, ResNet101, and VGG16, paired with different RNN decoders such as LSTM, GRU, and BiLSTM.The evaluation metrics used in the study are BLEU and METEOR, and the best model is found to be EfficientNetB0 + BiLSTM with 1024 hidden dimensions, achieving a BLEU-4 score of 17 and METEOR score of 46. The article also discusses challenges and future directions for advancing Nepali video captioning, providing a valuable resource for further research in this area.
</details></li>
</ul>
<hr>
<h2 id="LLM-enhanced-Self-training-for-Cross-domain-Constituency-Parsing"><a href="#LLM-enhanced-Self-training-for-Cross-domain-Constituency-Parsing" class="headerlink" title="LLM-enhanced Self-training for Cross-domain Constituency Parsing"></a>LLM-enhanced Self-training for Cross-domain Constituency Parsing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02660">http://arxiv.org/abs/2311.02660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianling Li, Meishan Zhang, Peiming Guo, Min Zhang, Yue Zhang</li>
<li>for: 本研究探讨了自动训练在跨领域任务中的应用，特别是在跨领域成分分析中。</li>
<li>methods: 本研究提出了利用大语言模型（LLM）生成领域特定的raw corpora，并通过 grammar rules和假实例选择 criterion来引导LLM生成raw corpora。</li>
<li>results: 实验结果表明，自动训练 для成分分析，启用LLM，可以超越传统方法，无论LLM的性能如何。此外，结合grammar rules和假实例选择 criterion可以实现最高的跨领域成分分析性能。<details>
<summary>Abstract</summary>
Self-training has proven to be an effective approach for cross-domain tasks, and in this study, we explore its application to cross-domain constituency parsing. Traditional self-training methods rely on limited and potentially low-quality raw corpora. To overcome this limitation, we propose enhancing self-training with the large language model (LLM) to generate domain-specific raw corpora iteratively. For the constituency parsing, we introduce grammar rules that guide the LLM in generating raw corpora and establish criteria for selecting pseudo instances. Our experimental results demonstrate that self-training for constituency parsing, equipped with an LLM, outperforms traditional methods regardless of the LLM's performance. Moreover, the combination of grammar rules and confidence criteria for pseudo-data selection yields the highest performance in the cross-domain constituency parsing.
</details>
<details>
<summary>摘要</summary>
自我训练已经证明是跨领域任务的有效方法，在这种研究中，我们探索了它的应用于跨领域成分分析。传统的自我训练方法取得有限和可能是低质量的Raw corpora。为了超越这些限制，我们提议通过大型语言模型（LLM）生成领域特定的Raw corpora，并在每一轮生成Raw corpora时遵循语法规则。对于成分分析，我们引入语法规则来导引LLM生成Raw corpora，并设置pseudo实例选择的标准。我们的实验结果表明，将自我训练与LLM结合使用，可以超越传统方法，无论LLM的性能如何。此外，结合语法规则和pseudo实例选择的信心标准，可以在跨领域成分分析中获得最高性能。
</details></li>
</ul>
<hr>
<h2 id="Divide-Conquer-for-Entailment-aware-Multi-hop-Evidence-Retrieval"><a href="#Divide-Conquer-for-Entailment-aware-Multi-hop-Evidence-Retrieval" class="headerlink" title="Divide &amp; Conquer for Entailment-aware Multi-hop Evidence Retrieval"></a>Divide &amp; Conquer for Entailment-aware Multi-hop Evidence Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02616">http://arxiv.org/abs/2311.02616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Luo, Mihai Surdeanu</li>
<li>for: Answering multi-hop questions by retrieving evidences that are semantically equivalent or entailed by the question.</li>
<li>methods: Divide the task into two sub-tasks: semantic textual similarity retrieval and inference similarity retrieval, and use two ensemble models (EAR and EARnest) to jointly re-rank sentences with consideration of diverse relevance signals.</li>
<li>results: Significantly outperform all single retrieval models and two ensemble baseline models on HotpotQA, and more effective in retrieving relevant evidences for multi-hop questions.<details>
<summary>Abstract</summary>
Lexical and semantic matches are commonly used as relevance measurements for information retrieval. Together they estimate the semantic equivalence between the query and the candidates. However, semantic equivalence is not the only relevance signal that needs to be considered when retrieving evidences for multi-hop questions. In this work, we demonstrate that textual entailment relation is another important relevance dimension that should be considered. To retrieve evidences that are either semantically equivalent to or entailed by the question simultaneously, we divide the task of evidence retrieval for multi-hop question answering (QA) into two sub-tasks, i.e., semantic textual similarity and inference similarity retrieval. We propose two ensemble models, EAR and EARnest, which tackle each of the sub-tasks separately and then jointly re-rank sentences with the consideration of the diverse relevance signals. Experimental results on HotpotQA verify that our models not only significantly outperform all the single retrieval models it is based on, but is also more effective than two intuitive ensemble baseline models.
</details>
<details>
<summary>摘要</summary>
lexical和semantic匹配通常用于信息检索中的相关性评估。它们共同估计查询和候选答案之间的semanticEquivalence。但semanticEquivalence并不是多步问题检索证据的唯一相关性信号。在这种情况下，我们表明文本涵义关系是另一个重要的相关性维度。为了同时检索具有查询和问题相似或涵义涵盖的证据，我们将多步问题answering（QA）证据检索任务分为两个子任务：semantic textual similarity retrieval和inference similarity retrieval。我们提出了两种ensemble模型，EAR和EARnest，它们分别处理每个子任务，然后对结果进行jointly重新排序，考虑多种相关性信号的多样性。实验结果表明，我们的模型不仅在HotpotQA上显著超越所有基于它的单个检索模型，还比两个INTUITIVE ensemble基eline模型更有效。
</details></li>
</ul>
<hr>
<h2 id="mahaNLP-A-Marathi-Natural-Language-Processing-Library"><a href="#mahaNLP-A-Marathi-Natural-Language-Processing-Library" class="headerlink" title="mahaNLP: A Marathi Natural Language Processing Library"></a>mahaNLP: A Marathi Natural Language Processing Library</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02579">http://arxiv.org/abs/2311.02579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/l3cube-pune/MarathiNLP">https://github.com/l3cube-pune/MarathiNLP</a></li>
<li>paper_authors: Vidula Magdum, Omkar Dhekane, Sharayu Hiwarkhedkar, Saloni Mittal, Raviraj Joshi</li>
<li>for: 这个研究是为了提供一个开源的自然语言处理（NLP）库，专门针对印度语言Marathi进行支持。</li>
<li>methods: 这个研究使用了现代的MahaBERT基于trasnformer模型，并提供了一个易于使用、可扩展、对应的Marathi文本分析工具组。</li>
<li>results: 这个研究提供了一个全面的NLP任务集，包括基本的预处理任务和进阶的NLP任务，例如情感分析、命名实体识别、讨厌话检测和句子完成。<details>
<summary>Abstract</summary>
We present mahaNLP, an open-source natural language processing (NLP) library specifically built for the Marathi language. It aims to enhance the support for the low-resource Indian language Marathi in the field of NLP. It is an easy-to-use, extensible, and modular toolkit for Marathi text analysis built on state-of-the-art MahaBERT-based transformer models. Our work holds significant importance as other existing Indic NLP libraries provide basic Marathi processing support and rely on older models with restricted performance. Our toolkit stands out by offering a comprehensive array of NLP tasks, encompassing both fundamental preprocessing tasks and advanced NLP tasks like sentiment analysis, NER, hate speech detection, and sentence completion. This paper focuses on an overview of the mahaNLP framework, its features, and its usage. This work is a part of the L3Cube MahaNLP initiative, more information about it can be found at https://github.com/l3cube-pune/MarathiNLP .
</details>
<details>
<summary>摘要</summary>
我们介绍mahaNLP，一个开源的自然语言处理（NLP）库，专门为旁遮普语言提供支持。它的目标是在NLP领域提高旁遮普语言的支持。这是一个易于使用、可扩展、具有模块性的旁遮普文本分析工具库，建立于现代的MahaBERT基于转移模型。我们的工作具有重要的意义，因为现有的印度语言NLP库只提供了基本的旁遮普处理支持，并且使用older模型，性能有限。我们的工具库包括了许多NLP任务，包括基本的预处理任务以及高级NLP任务，如情感分析、命名实体识别、仇恨言语检测和句子完成。本文将对mahaNLP框架、特点和使用进行概述。这是L3Cube MahaNLP项目的一部分，更多信息可以在https://github.com/l3cube-pune/MarathiNLP查看。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Sequencing-of-Documents"><a href="#Temporal-Sequencing-of-Documents" class="headerlink" title="Temporal Sequencing of Documents"></a>Temporal Sequencing of Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02578">http://arxiv.org/abs/2311.02578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Gervers, Gelila Tilahun</li>
<li>for: 这篇论文是为了排序历史文档的时间顺序而写的。</li>
<li>methods: 这种方法使用非 Parametric 泛函模型（Fan, Heckman, 和 Wand, 1995）来捕捉文字使用的慢滑度变化。</li>
<li>results: 这种方法可以有效地对历史文档进行排序，并且在对 medieval English 财产转让文档和美国国情报告 addresses 进行比较时，都有显著的改善。<details>
<summary>Abstract</summary>
We outline an unsupervised method for temporal rank ordering of sets of historical documents, namely American State of the Union Addresses and DEEDS, a corpus of medieval English property transfer documents. Our method relies upon effectively capturing the gradual change in word usage via a bandwidth estimate for the non-parametric Generalized Linear Models (Fan, Heckman, and Wand, 1995). The number of possible rank orders needed to search through possible cost functions related to the bandwidth can be quite large, even for a small set of documents. We tackle this problem of combinatorial optimization using the Simulated Annealing algorithm, which allows us to obtain the optimal document temporal orders. Our rank ordering method significantly improved the temporal sequencing of both corpora compared to a randomly sequenced baseline. This unsupervised approach should enable the temporal ordering of undated document sets.
</details>
<details>
<summary>摘要</summary>
我们提出了一种无监督的方法，用于排序历史文档集合，包括美国州联合宪言和中世纪英格兰财产转让文档集。我们的方法基于有效地捕捉文本中慢慢变化的词汇使用情况，通过非参数化的泛化线性模型（Fan, Heckman, 和 Wand，1995）来估算带宽。由于搜索可能的排序方案的数量可能很大，即使是一小组文档也可能会出现这个问题。我们使用模拟熔化算法来解决这个问题，从而获得最佳的文档排序顺序。我们的排序方法在对两个 corpora 进行比较时具有显著改善，相比随机排序基线。这种无监督的方法应该能够应用于无日期文档集。
</details></li>
</ul>
<hr>
<h2 id="BanMANI-A-Dataset-to-Identify-Manipulated-Social-Media-News-in-Bangla"><a href="#BanMANI-A-Dataset-to-Identify-Manipulated-Social-Media-News-in-Bangla" class="headerlink" title="BanMANI: A Dataset to Identify Manipulated Social Media News in Bangla"></a>BanMANI: A Dataset to Identify Manipulated Social Media News in Bangla</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02570">http://arxiv.org/abs/2311.02570</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kamruzzaman15/banmani">https://github.com/kamruzzaman15/banmani</a></li>
<li>paper_authors: Mahammed Kamruzzaman, Md. Minul Islam Shovon, Gene Louis Kim</li>
<li>for: 本研究旨在识别社交媒体新闻中 false 地操纵相关新闻文章的具体说法。</li>
<li>methods: 本研究使用了一种数据集采集方法，以 circumvent 当前可用的 NLP 工具在 Bangla 语言上的限制。</li>
<li>results: 研究发现，当 Zero-shot 和微调设定下，现有的 LLM 都难以满足这个任务的要求。<details>
<summary>Abstract</summary>
Initial work has been done to address fake news detection and misrepresentation of news in the Bengali language. However, no work in Bengali yet addresses the identification of specific claims in social media news that falsely manipulates a related news article. At this point, this problem has been tackled in English and a few other languages, but not in the Bengali language. In this paper, we curate a dataset of social media content labeled with information manipulation relative to reference articles, called BanMANI. The dataset collection method we describe works around the limitations of the available NLP tools in Bangla. We expect these techniques will carry over to building similar datasets in other low-resource languages. BanMANI forms the basis both for evaluating the capabilities of existing NLP systems and for training or fine-tuning new models specifically on this task. In our analysis, we find that this task challenges current LLMs both under zero-shot and fine-tuned settings.
</details>
<details>
<summary>摘要</summary>
初步工作已经对假新闻检测和新闻歪曲的问题进行了准备。然而，目前没有任何工作在孟加拉语中对社交媒体新闻中谎言性的具体CLAIM进行识别。在这篇论文中，我们为这个问题收集了一个社交媒体内容的标注数据集，称为BanMANI。我们的数据集采集方法会讲述在可用的NLP工具 limitation下如何实现。我们期望这些技术可以扩展到其他低资源语言。BanMANI将成为评估现有NLP系统的能力以及训练或精度调整新模型的基础。在我们的分析中，我们发现这个任务对当前LLMs都是一个挑战，无论在零情况下或者精度调整后。
</details></li>
</ul>
<hr>
<h2 id="Topic-model-based-on-co-occurrence-word-networks-for-unbalanced-short-text-datasets"><a href="#Topic-model-based-on-co-occurrence-word-networks-for-unbalanced-short-text-datasets" class="headerlink" title="Topic model based on co-occurrence word networks for unbalanced short text datasets"></a>Topic model based on co-occurrence word networks for unbalanced short text datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02566">http://arxiv.org/abs/2311.02566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjie Ma, Junping Du, Meiyu Liang, Zeli Guan</li>
<li>for: 检测罕见话题在短文本 datasets 中的检测 (Detecting scarce topics in unbalanced short text datasets)</li>
<li>methods: 基于 co-occurrence word networks 的话题模型 (Topic model based on co-occurrence word networks)</li>
<li>results: 在不平衡短文本 datasets 中提供了一种可靠的话题检测方法 (Provides a reliable method for detecting topics in unbalanced short text datasets)<details>
<summary>Abstract</summary>
We propose a straightforward solution for detecting scarce topics in unbalanced short-text datasets. Our approach, named CWUTM (Topic model based on co-occurrence word networks for unbalanced short text datasets), Our approach addresses the challenge of sparse and unbalanced short text topics by mitigating the effects of incidental word co-occurrence. This allows our model to prioritize the identification of scarce topics (Low-frequency topics). Unlike previous methods, CWUTM leverages co-occurrence word networks to capture the topic distribution of each word, and we enhanced the sensitivity in identifying scarce topics by redefining the calculation of node activity and normalizing the representation of both scarce and abundant topics to some extent. Moreover, CWUTM adopts Gibbs sampling, similar to LDA, making it easily adaptable to various application scenarios. Our extensive experimental validation on unbalanced short-text datasets demonstrates the superiority of CWUTM compared to baseline approaches in discovering scarce topics. According to the experimental results the proposed model is effective in early and accurate detection of emerging topics or unexpected events on social platforms.
</details>
<details>
<summary>摘要</summary>
我们提出了一种直观的解决方案，用于探测罕见话题在不均衡短文本数据集中。我们的方法，名为CWUTM（基于协occurrence词网络的短文本数据集中罕见话题模型），解决了短文本话题的罕见性和不均衡性的挑战。我们的模型可以增强对罕见话题的识别，并且可以在不同应用场景中轻松地适应。我们对不均衡短文本数据集进行了广泛的实验 validate，结果表明，相比基eline方法，CWUTM在发现罕见话题方面表现出了明显的优势。根据实验结果，我们的模型可以在社交平台上早期发现emerging话题或意外事件。Note: "短文本数据集" (short-text dataset) in Chinese is typically translated as "短文本集" (short-text collection), and "罕见话题" (scarce topic) is translated as "罕见话题" (rare topic) or "罕见话题" (underrepresented topic).
</details></li>
</ul>
<hr>
<h2 id="Relation-Extraction-Model-Based-on-Semantic-Enhancement-Mechanism"><a href="#Relation-Extraction-Model-Based-on-Semantic-Enhancement-Mechanism" class="headerlink" title="Relation Extraction Model Based on Semantic Enhancement Mechanism"></a>Relation Extraction Model Based on Semantic Enhancement Mechanism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02564">http://arxiv.org/abs/2311.02564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiyu Liu, Junping Du, Yingxia Shao, Zeli Guan</li>
<li>for: 提高信息抽取中关系EXTRACTION的效果，解决 triple overlap 问题</li>
<li>methods: 基于CasRel框架和semantic enhancement mechanism，提出了CasAug模型，通过对可能主语进行semantic coding，采用含义增强机制，对可能主语进行权重调整，提高关系EXTRACTION的精度</li>
<li>results: 比基eline模型提高了关系EXTRACTION的效果，可以更好地处理 triple overlap 问题，提高了对多个关系的EXTRACTION能力<details>
<summary>Abstract</summary>
Relational extraction is one of the basic tasks related to information extraction in the field of natural language processing, and is an important link and core task in the fields of information extraction, natural language understanding, and information retrieval. None of the existing relation extraction methods can effectively solve the problem of triple overlap. The CasAug model proposed in this paper based on the CasRel framework combined with the semantic enhancement mechanism can solve this problem to a certain extent. The CasAug model enhances the semantics of the identified possible subjects by adding a semantic enhancement mechanism, First, based on the semantic coding of possible subjects, pre-classify the possible subjects, and then combine the subject lexicon to calculate the semantic similarity to obtain the similar vocabulary of possible subjects. According to the similar vocabulary obtained, each word in different relations is calculated through the attention mechanism. For the contribution of the possible subject, finally combine the relationship pre-classification results to weight the enhanced semantics of each relationship to find the enhanced semantics of the possible subject, and send the enhanced semantics combined with the possible subject to the object and relationship extraction module. Complete the final relation triplet extraction. The experimental results show that, compared with the baseline model, the CasAug model proposed in this paper has improved the effect of relation extraction, and CasAug's ability to deal with overlapping problems and extract multiple relations is also better than the baseline model, indicating that the semantic enhancement mechanism proposed in this paper It can further reduce the judgment of redundant relations and alleviate the problem of triple overlap.
</details>
<details>
<summary>摘要</summary>
基于自然语言处理的信息EXTRACTION中，关系提取是一项基础任务和核心任务，与信息提取、自然语言理解和信息检索 closely related。现有的关系提取方法无法有效解决 triple overlap 问题。本文提出的 CasAug 模型，基于 CasRel 框架和semantic enhancement mechanism，可以减少重复的关系判断和 triple overlap 问题。CasAug 模型首先使用可能主语的semantic coding进行预类型，然后使用主语词典计算 Possible subjects 的semantic similarity，以获得每个关系中的相似词汇。通过注意机制，对每个关系中的每个词语进行计算。最后，根据关系预类型的结果，对各种关系中的semantics进行权重计算，并将权重计算结果与可能主语进行组合。最终，通过对象和关系提取模块进行完善，完成最终的关系 triplet 提取。实验结果表明，相比基eline模型，提出的 CasAug 模型在关系提取方面有所提高，并且 CasAug 模型在 triple overlap 问题上的处理能力也比基eline模型更好，这表明该paper中提出的 semantic enhancement mechanism 可以进一步减少重复的关系判断和 triple overlap 问题。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.CL_2023_11_05/" data-id="clpahu71l00ej3h88fimw4emj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/cs.LG_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T10:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/cs.LG_2023_11_05/">cs.LG - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="From-molecules-to-scaffolds-to-functional-groups-building-context-dependent-molecular-representation-via-multi-channel-learning"><a href="#From-molecules-to-scaffolds-to-functional-groups-building-context-dependent-molecular-representation-via-multi-channel-learning" class="headerlink" title="From molecules to scaffolds to functional groups: building context-dependent molecular representation via multi-channel learning"></a>From molecules to scaffolds to functional groups: building context-dependent molecular representation via multi-channel learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02798">http://arxiv.org/abs/2311.02798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Wan, Jialu Wu, Tingjun Hou, Chang-Yu Hsieh, Xiaowei Jia</li>
<li>for: 这篇论文主要应用在化学物质的物理化学和生物学性质预测中，例如药物发现。</li>
<li>methods: 这篇论文使用了自类学习（SSL）方法，利用大规模、未标注的化学物质数据来学习化学空间的基础表现，并将这些表现与特定应用场景相结合。</li>
<li>results: 这篇论文的结果显示了与其他基eline比较之下，在多个分子属性评估标准中表现出色，并在特定但普遍的挑战 scenarios 中具有更高的稳定性和应用性。<details>
<summary>Abstract</summary>
Reliable molecular property prediction is essential for various scientific endeavors and industrial applications, such as drug discovery. However, the scarcity of data, combined with the highly non-linear causal relationships between physicochemical and biological properties and conventional molecular featurization schemes, complicates the development of robust molecular machine learning models. Self-supervised learning (SSL) has emerged as a popular solution, utilizing large-scale, unannotated molecular data to learn a foundational representation of chemical space that might be advantageous for downstream tasks. Yet, existing molecular SSL methods largely overlook domain-specific knowledge, such as molecular similarity and scaffold importance, as well as the context of the target application when operating over the large chemical space. This paper introduces a novel learning framework that leverages the knowledge of structural hierarchies within molecular structures, embeds them through separate pre-training tasks over distinct channels, and employs a task-specific channel selection to compose a context-dependent representation. Our approach demonstrates competitive performance across various molecular property benchmarks and establishes some state-of-the-art results. It further offers unprecedented advantages in particularly challenging yet ubiquitous scenarios like activity cliffs with enhanced robustness and generalizability compared to other baselines.
</details>
<details>
<summary>摘要</summary>
可靠的分子性质预测是科学研究和工业应用中的关键，如药物搜索。然而，数据稀缺和物理化和生物性质之间非线性关系，以及传统的分子特征化方案，使分子机器学习模型的开发变得复杂。自我超视学习（SSL）已成为一种流行的解决方案，利用大规模、无注释的分子数据来学习分子空间的基础表示，这可能对下游任务有利。然而，现有的分子SSL方法忽视了域专门知识，如分子相似性和架构重要性，以及目标应用场景的 контекст。本文介绍一种新的学习框架，利用分子结构中的结构层次结构，通过不同的预训练任务来嵌入这些结构，并使用任务特定的通道选择来组合上下文依赖的表示。我们的方法在多种分子性质benchmark上显示竞争性的性能，并在一些特殊 yet ubiquitous的enario中提供了前所未有的优势，比如活性峰值中的提高了Robustness和普遍性。
</details></li>
</ul>
<hr>
<h2 id="Riemannian-Laplace-Approximation-with-the-Fisher-Metric"><a href="#Riemannian-Laplace-Approximation-with-the-Fisher-Metric" class="headerlink" title="Riemannian Laplace Approximation with the Fisher Metric"></a>Riemannian Laplace Approximation with the Fisher Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02766">http://arxiv.org/abs/2311.02766</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ksnxr/rlaf">https://github.com/ksnxr/rlaf</a></li>
<li>paper_authors: Hanlin Yu, Marcelo Hartmann, Bernardo Williams, Mark Girolami, Arto Klami</li>
<li>for: 用于 Bayesian inference 的数据拟合</li>
<li>methods: 使用 Laplace 方法和 Riemannian geometry 拟合 Gaussian 分布</li>
<li>results: 提供了两种修改后的变体，并在几个实验中证明了其实际上的改进<details>
<summary>Abstract</summary>
The Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties heavily depend on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the method, and demonstrating practical improvements in a range of experiments.
</details>
<details>
<summary>摘要</summary>
拉普拉斯方法用 Gaussian 分布近似目标概率分布， computationally efficient 和 asymptotically exact  для Bayesian inference  due to the Bernstein-von Mises theorem，但对复杂目标和 finite-data posterior 通常太粗糙。一种 recient generalization of the Laplace Approximation 使用 chosen Riemannian geometry 提供一个更加丰富的近似家族，仍然保持 computation efficiency，但选择的 метри可能会导致近似过于窄而且偏向的问题。我们在这里修正这个缺陷，发展了两个替代方案，并对方法的理论分析进行了扩展，在一系列实验中也表现了实践上的改进。
</details></li>
</ul>
<hr>
<h2 id="Log-Concavity-of-Multinomial-Likelihood-Functions-Under-Interval-Censoring-Constraints-on-Frequencies-or-Their-Partial-Sums"><a href="#Log-Concavity-of-Multinomial-Likelihood-Functions-Under-Interval-Censoring-Constraints-on-Frequencies-or-Their-Partial-Sums" class="headerlink" title="Log-Concavity of Multinomial Likelihood Functions Under Interval Censoring Constraints on Frequencies or Their Partial Sums"></a>Log-Concavity of Multinomial Likelihood Functions Under Interval Censoring Constraints on Frequencies or Their Partial Sums</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02763">http://arxiv.org/abs/2311.02763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bruce Levin, Erik Learned-Miller</li>
<li>for: 本文为了描述 multinomial vector 在 interval censoring 约束下的概率函数是完全log-concave。</li>
<li>methods: 本文使用 M-convex subset 的概念和 constrained sample spaces 的概念来证明概率函数的完全log-concavity。</li>
<li>results: 本文证明了 multinomial vector 在 interval censoring 约束下的概率函数是完全log-concave。<details>
<summary>Abstract</summary>
We show that the likelihood function for a multinomial vector observed under arbitrary interval censoring constraints on the frequencies or their partial sums is completely log-concave by proving that the constrained sample spaces comprise M-convex subsets of the discrete simplex.
</details>
<details>
<summary>摘要</summary>
我们显示了Multinomial vector在arbitrary interval censored的情况下观察到的概率函数是完全log-concave，通过证明受限样本空间包含M-convex的简单体的子集。
</details></li>
</ul>
<hr>
<h2 id="One-Shot-Strategic-Classification-Under-Unknown-Costs"><a href="#One-Shot-Strategic-Classification-Under-Unknown-Costs" class="headerlink" title="One-Shot Strategic Classification Under Unknown Costs"></a>One-Shot Strategic Classification Under Unknown Costs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02761">http://arxiv.org/abs/2311.02761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elan Rosenfeld, Nir Rosenfeld</li>
<li>for: 本研究旨在学习具有抗扰乱性的决策规则，以适应不确定的用户回应。</li>
<li>methods: 本研究使用一shot设定，通过commit一个核心分类器来解决不确定的用户回应问题。</li>
<li>results: 研究发现， même avec small mis-estimation of the true cost, the accuracy of the classifier can be arbitrarily low in the worst case. 我们提出了一种 minimax 问题来解决这个问题，并提供了efficient algorithms for both full-batch and stochastic settings, which converge to the minimax optimal solution at the dimension-independent rate of $\tilde{\mathcal{O}(T^{-\frac{1}{2})$.<details>
<summary>Abstract</summary>
A primary goal in strategic classification is to learn decision rules which are robust to strategic input manipulation. Earlier works assume that strategic responses are known; while some recent works address the important challenge of unknown responses, they exclusively study sequential settings which allow multiple model deployments over time. But there are many domains$\unicode{x2014}$particularly in public policy, a common motivating use-case$\unicode{x2014}$where multiple deployments are unrealistic, or where even a single bad round is undesirable. To address this gap, we initiate the study of strategic classification under unknown responses in the one-shot setting, which requires committing to a single classifier once. Focusing on the users' cost function as the source of uncertainty, we begin by proving that for a broad class of costs, even a small mis-estimation of the true cost can entail arbitrarily low accuracy in the worst case. In light of this, we frame the one-shot task as a minimax problem, with the goal of identifying the classifier with the smallest worst-case risk over an uncertainty set of possible costs. Our main contribution is efficient algorithms for both the full-batch and stochastic settings, which we prove converge (offline) to the minimax optimal solution at the dimension-independent rate of $\tilde{\mathcal{O}(T^{-\frac{1}{2})$. Our analysis reveals important structure stemming from the strategic nature of user responses, particularly the importance of dual norm regularization with respect to the cost function.
</details>
<details>
<summary>摘要</summary>
primary goal in strategic classification 是学习强制性不受输入操纵的决策规则。earlier works 假设战略回应是已知的；而一些最近的工作 Address 了重要的挑战，但 exclusively 研究了顺序设置，允许多个模型的多次部署在时间上。但是，在公共政策领域等很多领域，多个部署是不现实的，或者 Even a single bad round 是不 desirable。为了解决这个差距，我们开始研究不知道回应的战略分类在一枚 Setting 中，需要在一次性地选择一个分类器。我们从用户的成本函数中的不确定性开始，我们证明了，even a small mis-estimation of the true cost 可以导致最差情况下的准确率为零。在这种情况下，我们将一枚 Setting 定义为一个 minimax 问题，目标是找到可以在不确定性集中的可能成本中最小最差情况的决策器。我们的主要贡献是对批处理和随机设置中的精炼算法，我们证明它们在线上 converges 到 minimax 优化的解决方案，具有约等于 $T^{- \frac{1}{2}$ 的缩放率。我们的分析表明了由战略性的用户回应带来的重要结构，特别是对于成本函数的双重范数规范。
</details></li>
</ul>
<hr>
<h2 id="ELEGANT-Certified-Defense-on-the-Fairness-of-Graph-Neural-Networks"><a href="#ELEGANT-Certified-Defense-on-the-Fairness-of-Graph-Neural-Networks" class="headerlink" title="ELEGANT: Certified Defense on the Fairness of Graph Neural Networks"></a>ELEGANT: Certified Defense on the Fairness of Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02757">http://arxiv.org/abs/2311.02757</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yushundong/elegant">https://github.com/yushundong/elegant</a></li>
<li>paper_authors: Yushun Dong, Binchi Zhang, Hanghang Tong, Jundong Li</li>
<li>for: 防止Graph Neural Networks（GNNs）的偏见和不公平性攻击</li>
<li>methods: 提出了一个名为ELEGANT的原则性框架，并进行了详细的理论证明，以保证GNNs的公平性</li>
<li>results: 在实际实验中，ELEGANT被证明可以有效地防止攻击者通过添加偏见来让GNNs的预测结果偏离公平性，并且可以用于GNNs偏移修复Here is the translation in English:</li>
<li>for: Protecting Graph Neural Networks (GNNs) from bias and unfair attacks</li>
<li>methods: Proposed a principled framework called ELEGANT and provided a detailed theoretical certification analysis to ensure the fairness of GNNs</li>
<li>results: In practical experiments, ELEGANT was proven to be effective in preventing attackers from corrupting the fairness level of GNNs’ predictions by adding perturbations, and it can also be used for GNN debiasing.<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have emerged as a prominent graph learning model in various graph-based tasks over the years. Nevertheless, due to the vulnerabilities of GNNs, it has been empirically proved that malicious attackers could easily corrupt the fairness level of their predictions by adding perturbations to the input graph data. In this paper, we take crucial steps to study a novel problem of certifiable defense on the fairness level of GNNs. Specifically, we propose a principled framework named ELEGANT and present a detailed theoretical certification analysis for the fairness of GNNs. ELEGANT takes any GNNs as its backbone, and the fairness level of such a backbone is theoretically impossible to be corrupted under certain perturbation budgets for attackers. Notably, ELEGANT does not have any assumption over the GNN structure or parameters, and does not require re-training the GNNs to realize certification. Hence it can serve as a plug-and-play framework for any optimized GNNs ready to be deployed. We verify the satisfactory effectiveness of ELEGANT in practice through extensive experiments on real-world datasets across different backbones of GNNs, where ELEGANT is also demonstrated to be beneficial for GNN debiasing. Open-source code can be found at https://github.com/yushundong/ELEGANT.
</details>
<details>
<summary>摘要</summary>
格网神经网络（GNNs）在各种基于图的任务中显示出了突出的表现。然而，由于GNNS的漏洞，实际证明了恶意攻击者可以轻松地腐蚀GNNS的预测公平性水平。在这篇论文中，我们研究了一个新的问题——GNNS公平性水平的证明防御。 Specifically, we propose a principled framework named ELEGANT and present a detailed theoretical certification analysis for the fairness of GNNs. ELEGANT takes any GNNs as its backbone, and the fairness level of such a backbone is theoretically impossible to be corrupted under certain perturbation budgets for attackers. Notably, ELEGANT does not make any assumptions about the GNN structure or parameters, and does not require re-training the GNNs to realize certification. Therefore, it can serve as a plug-and-play framework for any optimized GNNs ready to be deployed. We verify the satisfactory effectiveness of ELEGANT in practice through extensive experiments on real-world datasets across different backbones of GNNs, where ELEGANT is also demonstrated to be beneficial for GNN debiasing. 开源代码可以在https://github.com/yushundong/ELEGANT找到。
</details></li>
</ul>
<hr>
<h2 id="Staged-Reinforcement-Learning-for-Complex-Tasks-through-Decomposed-Environments"><a href="#Staged-Reinforcement-Learning-for-Complex-Tasks-through-Decomposed-Environments" class="headerlink" title="Staged Reinforcement Learning for Complex Tasks through Decomposed Environments"></a>Staged Reinforcement Learning for Complex Tasks through Decomposed Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02746">http://arxiv.org/abs/2311.02746</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Pina, Corentin Artaud, Xiaolan Liu, Varuna De Silva</li>
<li>for: 这个论文是关于智能控制领域内的强化学习（RL）的应用，尤其是在智能汽车控制方面。</li>
<li>methods: 论文提出了两种方法来 aproximate RL 问题到实际问题上，包括分解复杂任务为多个子任务，以及使用中央训练分布执行（CTDE） paradigma。</li>
<li>results: 实验结果表明，提posed方法可以提高智能代理人在交通十字路相关的复杂任务中的表现，并最小化可能发生的安全问题。<details>
<summary>Abstract</summary>
Reinforcement Learning (RL) is an area of growing interest in the field of artificial intelligence due to its many notable applications in diverse fields. Particularly within the context of intelligent vehicle control, RL has made impressive progress. However, currently it is still in simulated controlled environments where RL can achieve its full super-human potential. Although how to apply simulation experience in real scenarios has been studied, how to approximate simulated problems to the real dynamic problems is still a challenge. In this paper, we discuss two methods that approximate RL problems to real problems. In the context of traffic junction simulations, we demonstrate that, if we can decompose a complex task into multiple sub-tasks, solving these tasks first can be advantageous to help minimising possible occurrences of catastrophic events in the complex task. From a multi-agent perspective, we introduce a training structuring mechanism that exploits the use of experience learned under the popular paradigm called Centralised Training Decentralised Execution (CTDE). This experience can then be leveraged in fully decentralised settings that are conceptually closer to real settings, where agents often do not have access to a central oracle and must be treated as isolated independent units. The results show that the proposed approaches improve agents performance in complex tasks related to traffic junctions, minimising potential safety-critical problems that might happen in these scenarios. Although still in simulation, the investigated situations are conceptually closer to real scenarios and thus, with these results, we intend to motivate further research in the subject.
</details>
<details>
<summary>摘要</summary>
强化学习（RL）是人工智能领域的一个快速发展领域，具有各种应用场景的优势。特别是在智能控制领域，RL已经做出了卓越的进展。然而，目前RL仍然在模拟控制环境中达到了最高的超人类水平。虽然有研究如何将模拟经验应用于实际场景，但是如何近似模拟问题到实际动态问题仍然是一个挑战。在这篇论文中，我们讨论了两种方法可以将RL问题近似到实际问题。在交通立交点模拟中，我们示出了如果将复杂任务分解成多个子任务，解决这些子任务可以帮助避免在复杂任务中可能发生的潜在灾难事件。从多智能代理的视角来看，我们介绍了一种使用中央训练分布执行（CTDE）的训练结构机制，利用这种机制可以在完全分布式的设置中使用经验学习。这些经验可以在实际场景中使用，agent们在实际场景中通常不具备中央报告机制，因此这些经验可以在完全分布式的设置中帮助agent们提高完成复杂任务的能力。结果显示，提出的方法可以在交通立交点任务中提高agent的性能，避免可能发生的安全关键问题。虽然仍在模拟环境中， investigate的情况概念上更近于实际场景，因此我们希望通过这些结果激励更多的研究在这个领域。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Correlated-Auxiliary-Feedback-in-Parameterized-Bandits"><a href="#Exploiting-Correlated-Auxiliary-Feedback-in-Parameterized-Bandits" class="headerlink" title="Exploiting Correlated Auxiliary Feedback in Parameterized Bandits"></a>Exploiting Correlated Auxiliary Feedback in Parameterized Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02715">http://arxiv.org/abs/2311.02715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arun Verma, Zhongxiang Dai, Yao Shu, Bryan Kian Hsiang Low</li>
<li>for: 这个论文研究了一种新的参数化带宽问题变体，在这个问题中，学习者可以观察附加的协助反馈，这些反馈与观察到的奖励相关。</li>
<li>methods: 这个论文首先开发了一种利用协助反馈建立奖励估计器，并提供了准确的信息 bounds，从而减少了 regret。</li>
<li>results: 实验结果在不同的设定中证明了我们提出的方法可以减少 regret，并且可以在不同的协助反馈下达到更好的性能。<details>
<summary>Abstract</summary>
We study a novel variant of the parameterized bandits problem in which the learner can observe additional auxiliary feedback that is correlated with the observed reward. The auxiliary feedback is readily available in many real-life applications, e.g., an online platform that wants to recommend the best-rated services to its users can observe the user's rating of service (rewards) and collect additional information like service delivery time (auxiliary feedback). In this paper, we first develop a method that exploits auxiliary feedback to build a reward estimator with tight confidence bounds, leading to a smaller regret. We then characterize the regret reduction in terms of the correlation coefficient between reward and its auxiliary feedback. Experimental results in different settings also verify the performance gain achieved by our proposed method.
</details>
<details>
<summary>摘要</summary>
我们研究一种新的参数化强制投票问题变体，在该问题中学习者可以观察附加的auxiliary反馈，这些反馈与观察到的奖励相关。这些附加反馈在实际应用中很普遍，例如一个在线平台想要推荐用户最佳评分服务可以观察用户对服务的评分（奖励）并收集附加信息如服务交付时间（auxiliary反馈）。我们首先开发了一种利用附加反馈建立奖励估计器，并提供紧张的信息 bounds，从而减少了 regret。然后，我们Characterize了 regret reduction的相对评价差，并通过不同的设置的实验结果来验证我们的提posed方法的性能提升。
</details></li>
</ul>
<hr>
<h2 id="A-Goal-Driven-Approach-to-Systems-Neuroscience"><a href="#A-Goal-Driven-Approach-to-Systems-Neuroscience" class="headerlink" title="A Goal-Driven Approach to Systems Neuroscience"></a>A Goal-Driven Approach to Systems Neuroscience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02704">http://arxiv.org/abs/2311.02704</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuroailab/Neural-Alignment">https://github.com/neuroailab/Neural-Alignment</a></li>
<li>paper_authors: Aran Nayebi</li>
<li>for: 这篇论文的目的是提出一种新的解释神经元和神经细胞之间的交互方式，以解决现有的描述问题。</li>
<li>methods: 这篇论文使用了实验 neuroscience 技术，记录并 manipulate 动物表现Complex behaviors 的时候，神经元的活动。</li>
<li>results: 这篇论文提出了一种新的解释神经元和神经细胞之间的交互方式，并在多种脑区和物种中进行了应用，以研究智能行为的起源。<details>
<summary>Abstract</summary>
Humans and animals exhibit a range of interesting behaviors in dynamic environments, and it is unclear how our brains actively reformat this dense sensory information to enable these behaviors. Experimental neuroscience is undergoing a revolution in its ability to record and manipulate hundreds to thousands of neurons while an animal is performing a complex behavior. As these paradigms enable unprecedented access to the brain, a natural question that arises is how to distill these data into interpretable insights about how neural circuits give rise to intelligent behaviors. The classical approach in systems neuroscience has been to ascribe well-defined operations to individual neurons and provide a description of how these operations combine to produce a circuit-level theory of neural computations. While this approach has had some success for small-scale recordings with simple stimuli, designed to probe a particular circuit computation, often times these ultimately lead to disparate descriptions of the same system across stimuli. Perhaps more strikingly, many response profiles of neurons are difficult to succinctly describe in words, suggesting that new approaches are needed in light of these experimental observations. In this thesis, we offer a different definition of interpretability that we show has promise in yielding unified structural and functional models of neural circuits, and describes the evolutionary constraints that give rise to the response properties of the neural population, including those that have previously been difficult to describe individually. We demonstrate the utility of this framework across multiple brain areas and species to study the roles of recurrent processing in the primate ventral visual pathway; mouse visual processing; heterogeneity in rodent medial entorhinal cortex; and facilitating biological learning.
</details>
<details>
<summary>摘要</summary>
人类和动物在动态环境中展现出各种 interessante 行为，但是我们的大脑如何活动地重新格式化这些紧密的感知信息以启用这些行为仍然不清楚。现代神经科学实验受到了记录和修改百到千个神经元的技术的革命，这些方法使得我们可以在动物表现复杂行为时获取至前无之有的脑部数据。随着这些方法的发展，一个自然的问题出现了：如何将这些数据转化成可解释的洞察。传统的系统神经科学方法是将各个神经元归功于特定的操作，并提供一种描述如何这些操作相互作用以生成神经计算的综合理论。虽然这种方法在小规模记录下有一定的成功，但是它在面对复杂的刺激时经常导致不同的描述，这些描述在不同的刺激下都是不一致的。事实上，许多神经元响应 profiles 很难以用字符串来描述，这表明需要新的方法。在这个论文中，我们提出了一种不同的可解释性定义，并证明该定义在生成神经Circuit 级别的结构和功能模型方面具有承诺。我们还证明了这种定义在多个脑区和种类中的应用，以研究恒定处理的角色，包括人类脑镜下部Visual 路径; 鼠类视觉处理; 鼠类中脑核心受体区域的多样性; 和促进生物学学习。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-AI-Research-Paper-Analysis-Methodology-Component-Extraction-using-Factored-Transformer-based-Sequence-Modeling-Approach"><a href="#Enhancing-AI-Research-Paper-Analysis-Methodology-Component-Extraction-using-Factored-Transformer-based-Sequence-Modeling-Approach" class="headerlink" title="Enhancing AI Research Paper Analysis: Methodology Component Extraction using Factored Transformer-based Sequence Modeling Approach"></a>Enhancing AI Research Paper Analysis: Methodology Component Extraction using Factored Transformer-based Sequence Modeling Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03401">http://arxiv.org/abs/2311.03401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Madhusudan Ghosh, Debasis Ganguly, Partha Basuchowdhuri, Sudip Kumar Naskar</li>
<li>for: 本研究旨在自动抽取科学方法名称，提高科学文献中方法组成部分的抽取精度。</li>
<li>methods: 本研究提议使用分解方法，利用方法域的广泛类别信息，如 NLP、RL 等，以提高方法组成部分的抽取精度。</li>
<li>results: 实验结果显示，分解方法在尝试setup中表现出色，与基eline相比，提高了9.257%的精度。<details>
<summary>Abstract</summary>
Research in scientific disciplines evolves, often rapidly, over time with the emergence of novel methodologies and their associated terminologies. While methodologies themselves being conceptual in nature and rather difficult to automatically extract and characterise, in this paper, we seek to develop supervised models for automatic extraction of the names of the various constituents of a methodology, e.g., `R-CNN', `ELMo' etc. The main research challenge for this task is effectively modeling the contexts around these methodology component names in a few-shot or even a zero-shot setting. The main contributions of this paper towards effectively identifying new evolving scientific methodology names are as follows: i) we propose a factored approach to sequence modeling, which leverages a broad-level category information of methodology domains, e.g., `NLP', `RL' etc.; ii) to demonstrate the feasibility of our proposed approach of identifying methodology component names under a practical setting of fast evolving AI literature, we conduct experiments following a simulated chronological setup (newer methodologies not seen during the training process); iii) our experiments demonstrate that the factored approach outperforms state-of-the-art baselines by margins of up to 9.257\% for the methodology extraction task with the few-shot setup.
</details>
<details>
<summary>摘要</summary>
科学研究领域中的研究方法不断发展，经常快速地出现新的方法和其相关的术语。在这篇论文中，我们想要开发有监督模型来自动提取方法学Component的名称，例如“R-CNN”、“ELMo”等。我们的研究挑战是在几个或者 zeroshot设置下，有效地模型这些方法组件名称的上下文。我们的主要贡献如下：1. 我们提出了一种分解方法来模型序列，借鉴了方法学领域的大致类别信息，例如“NLP”、“RL”等。2. 为证明我们提出的方法在实际情况下可行，我们在快速演化的AI文献中进行了实验，采用了模拟时间序列的设置（ newer methodologies not seen during the training process）。3. 我们的实验表明，我们的分解方法可以在几个或者 zeroshot设置下，与现有的基eline相比，提高了方法提取任务的效果，提高了9.257%。
</details></li>
</ul>
<hr>
<h2 id="Identifying-Linearly-Mixed-Causal-Representations-from-Multi-Node-Interventions"><a href="#Identifying-Linearly-Mixed-Causal-Representations-from-Multi-Node-Interventions" class="headerlink" title="Identifying Linearly-Mixed Causal Representations from Multi-Node Interventions"></a>Identifying Linearly-Mixed Causal Representations from Multi-Node Interventions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02695">http://arxiv.org/abs/2311.02695</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Bing, Urmi Ninad, Jonas Wahl, Jakob Runge</li>
<li>for: 本研究旨在 Addressing the underconstrained problem of causal representation learning, particularly in the presence of multiple variables intervened upon within one environment.</li>
<li>methods: 我们的方法基于一个通用的假设，即在不同环境中的干预覆盖和多变量干预。我们采用了一种新的规范，即在不同环境中的干预Trace，并通过对这些跟踪进行规范和精炼来学习 causal representation。</li>
<li>results: 我们的实验结果表明，我们的方法可以在多变量干预下学习有效的 causal representation，并且可以避免一些先前的假设，如单变量干预和独立干预。<details>
<summary>Abstract</summary>
The task of inferring high-level causal variables from low-level observations, commonly referred to as causal representation learning, is fundamentally underconstrained. As such, recent works to address this problem focus on various assumptions that lead to identifiability of the underlying latent causal variables. A large corpus of these preceding approaches consider multi-environment data collected under different interventions on the causal model. What is common to virtually all of these works is the restrictive assumption that in each environment, only a single variable is intervened on. In this work, we relax this assumption and provide the first identifiability result for causal representation learning that allows for multiple variables to be targeted by an intervention within one environment. Our approach hinges on a general assumption on the coverage and diversity of interventions across environments, which also includes the shared assumption of single-node interventions of previous works. The main idea behind our approach is to exploit the trace that interventions leave on the variance of the ground truth causal variables and regularizing for a specific notion of sparsity with respect to this trace. In addition to and inspired by our theoretical contributions, we present a practical algorithm to learn causal representations from multi-node interventional data and provide empirical evidence that validates our identifiability results.
</details>
<details>
<summary>摘要</summary>
task of inferring high-level causal variables from low-level observations, commonly referred to as causal representation learning, is fundamentally underconstrained. As such, recent works to address this problem focus on various assumptions that lead to identifiability of the underlying latent causal variables. A large corpus of these preceding approaches consider multi-environment data collected under different interventions on the causal model. What is common to virtually all of these works is the restrictive assumption that in each environment, only a single variable is intervened on. In this work, we relax this assumption and provide the first identifiability result for causal representation learning that allows for multiple variables to be targeted by an intervention within one environment. Our approach hinges on a general assumption on the coverage and diversity of interventions across environments, which also includes the shared assumption of single-node interventions of previous works. The main idea behind our approach is to exploit the trace that interventions leave on the variance of the ground truth causal variables and regularizing for a specific notion of sparsity with respect to this trace. In addition to and inspired by our theoretical contributions, we present a practical algorithm to learn causal representations from multi-node interventional data and provide empirical evidence that validates our identifiability results.
</details></li>
</ul>
<hr>
<h2 id="Regret-Analysis-of-Learning-Based-Linear-Quadratic-Gaussian-Control-with-Additive-Exploration"><a href="#Regret-Analysis-of-Learning-Based-Linear-Quadratic-Gaussian-Control-with-Additive-Exploration" class="headerlink" title="Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with Additive Exploration"></a>Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with Additive Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02679">http://arxiv.org/abs/2311.02679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Archith Athrey, Othmane Mazhar, Meichen Guo, Bart De Schutter, Shengling Shi</li>
<li>for: 本文研究一种 computationally efficient 探索策略，即naive exploration，用于控制未知部分可观测系统 within Linear Quadratic Gaussian (LQG) 框架。</li>
<li>methods: 本文提出了一种 two-phase 控制算法 called LQG-NAIVE，包括一个初始阶段输入 Gaussian 信号以获得系统模型，然后在一个 episodic 的方式中与 naive exploration 和控制进行交互。</li>
<li>results: 我们证明了 LQG-NAIVE 可以实现 regret 增长率为 $\tilde{\mathcal{O}(\sqrt{T})$，即 $\mathcal{O}(\sqrt{T})$ 以上下标 Logarithmic factors 之后 $T$ 步骤。此外，我们还提出了 LQG-IF2E，它在探索信号中包括 Fisher Information Matrix (FIM)，并提供了 LQG-IF2E 的竞争性性能比 LQG-NAIVE 更好的数据分析证明。<details>
<summary>Abstract</summary>
In this paper, we analyze the regret incurred by a computationally efficient exploration strategy, known as naive exploration, for controlling unknown partially observable systems within the Linear Quadratic Gaussian (LQG) framework. We introduce a two-phase control algorithm called LQG-NAIVE, which involves an initial phase of injecting Gaussian input signals to obtain a system model, followed by a second phase of an interplay between naive exploration and control in an episodic fashion. We show that LQG-NAIVE achieves a regret growth rate of $\tilde{\mathcal{O}(\sqrt{T})$, i.e., $\mathcal{O}(\sqrt{T})$ up to logarithmic factors after $T$ time steps, and we validate its performance through numerical simulations. Additionally, we propose LQG-IF2E, which extends the exploration signal to a `closed-loop' setting by incorporating the Fisher Information Matrix (FIM). We provide compelling numerical evidence of the competitive performance of LQG-IF2E compared to LQG-NAIVE.
</details>
<details>
<summary>摘要</summary>
在本文中，我们分析了computationally efficient exploration strategy（naive exploration）在Linear Quadratic Gaussian（LQG）框架下控制未知部分可观测系统中的 regret。我们提出了一种两相控制算法，即LQG-NAIVE，其包括一个初始阶段插入 Gaussian 输入信号以获得系统模型，然后是一个 episodic 的第二阶段，在这个阶段中，naive exploration 和控制之间进行了协调。我们证明了LQG-NAIVE 的 regret增长率为 $\tilde{\mathcal{O}(\sqrt{T})$，即在 $T$ 步时间后， regret 增长率为 $\mathcal{O}(\sqrt{T})$ 以上 logarithmic 因素。此外，我们还提出了LQG-IF2E，它在探索信号中包含了 Fisher Information Matrix（FIM）。我们通过数值实验证明了LQG-IF2E 的竞争性性比 LQG-NAIVE 更高。
</details></li>
</ul>
<hr>
<h2 id="Drone-Enabled-Load-Management-for-Solar-Small-Cell-Networks-in-Next-Gen-Communications-Optimization-for-Solar-Small-Cells"><a href="#Drone-Enabled-Load-Management-for-Solar-Small-Cell-Networks-in-Next-Gen-Communications-Optimization-for-Solar-Small-Cells" class="headerlink" title="Drone-Enabled Load Management for Solar Small Cell Networks in Next-Gen Communications Optimization for Solar Small Cells"></a>Drone-Enabled Load Management for Solar Small Cell Networks in Next-Gen Communications Optimization for Solar Small Cells</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02648">http://arxiv.org/abs/2311.02648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daksh Dave, Dhruv Khut, Sahil Nawale, Pushkar Aggrawal, Disha Rastogi, Kailas Devadkar</li>
<li>for: 支持5G及以后移动通信网络的绿色微网络能源管理</li>
<li>methods: 使用无人机携带的空中基站 Load Transfer 技术实现稳定可靠的能源重新分配</li>
<li>results: 提高了基站的可靠性和灵活性，降低了基站的能源损失和无人机交换次数<details>
<summary>Abstract</summary>
In recent years, the cellular industry has witnessed a major evolution in communication technologies. It is evident that the Next Generation of cellular networks(NGN) will play a pivotal role in the acceptance of emerging IoT applications supporting high data rates, better Quality of Service(QoS), and reduced latency. However, the deployment of NGN will introduce a power overhead on the communication infrastructure. Addressing the critical energy constraints in 5G and beyond, this study introduces an innovative load transfer method using drone-carried airborne base stations (BSs) for stable and secure power reallocation within a green micro-grid network. This method effectively manages energy deficit by transferring aerial BSs from high to low-energy cells, depending on user density and the availability of aerial BSs, optimizing power distribution in advanced cellular networks. The complexity of the proposed system is significantly lower as compared to existing power cable transmission systems currently employed in powering the BSs. Furthermore, our proposed algorithm has been shown to reduce BS power outages while requiring a minimum number of drone exchanges. We have conducted a thorough review on real-world dataset to prove the efficacy of our proposed approach to support BS during high load demand times
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Pointer-Networks-with-Q-Learning-for-OP-Combinatorial-Optimization"><a href="#Pointer-Networks-with-Q-Learning-for-OP-Combinatorial-Optimization" class="headerlink" title="Pointer Networks with Q-Learning for OP Combinatorial Optimization"></a>Pointer Networks with Q-Learning for OP Combinatorial Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02629">http://arxiv.org/abs/2311.02629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Barro</li>
<li>for:  solves the Orienteering Problem (OP)</li>
<li>methods:  combines Pointer Networks (Ptr-Nets) and Q-learning</li>
<li>results:  superior capability in managing OP situationsHere are the three key points in Traditional Chinese:</li>
<li>for: 解决 Orienteering Problem (OP)</li>
<li>methods: 结合 Pointer Networks (Ptr-Nets) 和 Q-learning</li>
<li>results: 在 OP 中的优秀表现<details>
<summary>Abstract</summary>
The Orienteering Problem (OP) presents a unique challenge in combinatorial optimization, emphasized by its widespread use in logistics, delivery, and transportation planning. Given the NP-hard nature of OP, obtaining optimal solutions is inherently complex. While Pointer Networks (Ptr-Nets) have exhibited prowess in various combinatorial tasks, their performance in the context of OP leaves room for improvement. Recognizing the potency of Q-learning, especially when paired with deep neural structures, this research unveils the Pointer Q-Network (PQN). This innovative method combines Ptr-Nets and Q-learning, effectively addressing the specific challenges presented by OP. We deeply explore the architecture and efficiency of PQN, showcasing its superior capability in managing OP situations.
</details>
<details>
<summary>摘要</summary>
Orienteering Problem（OP）呈现了 combinatorial optimization 领域的独特挑战，它在物流、交通规划等领域广泛应用。由于 OP 的NP-硬性，获得优化解决方案是自然复杂的。然而，Pointer Networks（Ptr-Nets）在其他 combinatorial 任务中表现出色，但在 OP 中的表现仍有空间提升。本研究认识到 Q-学习的能力，特别是在与深度神经结构结合时，因此提出了 Pointer Q-Network（PQN）。这种创新方法结合了 Ptr-Nets 和 Q-学习，有效地解决了 OP 中的特定挑战。我们深入探讨 PQN 的architecture和效率，展示其在 OP 中的superior 能力。
</details></li>
</ul>
<hr>
<h2 id="An-adaptive-standardisation-model-for-Day-Ahead-electricity-price-forecasting"><a href="#An-adaptive-standardisation-model-for-Day-Ahead-electricity-price-forecasting" class="headerlink" title="An adaptive standardisation model for Day-Ahead electricity price forecasting"></a>An adaptive standardisation model for Day-Ahead electricity price forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02610">http://arxiv.org/abs/2311.02610</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ccaribe9/adaptstdepf">https://github.com/ccaribe9/adaptstdepf</a></li>
<li>paper_authors: Carlos Sebastián, Carlos E. González-Guillén, Jesús Juan</li>
<li>for:  Electricity market day-ahead price forecasting</li>
<li>methods:  Introducing adaptive standardization to mitigate dataset shifts and improve forecasting performance</li>
<li>results:  Significant improvement in forecasting accuracy across four markets, including two novel datasets, using less complex and widely accepted learning algorithms.<details>
<summary>Abstract</summary>
The study of Day-Ahead prices in the electricity market is one of the most popular problems in time series forecasting. Previous research has focused on employing increasingly complex learning algorithms to capture the sophisticated dynamics of the market. However, there is a threshold where increased complexity fails to yield substantial improvements. In this work, we propose an alternative approach by introducing an adaptive standardisation to mitigate the effects of dataset shifts that commonly occur in the market. By doing so, learning algorithms can prioritize uncovering the true relationship between the target variable and the explanatory variables. We investigate four distinct markets, including two novel datasets, previously unexplored in the literature. These datasets provide a more realistic representation of the current market context, that conventional datasets do not show. The results demonstrate a significant improvement across all four markets, using learning algorithms that are less complex yet widely accepted in the literature. This significant advancement unveils opens up new lines of research in this field, highlighting the potential of adaptive transformations in enhancing the performance of forecasting models.
</details>
<details>
<summary>摘要</summary>
研究一天前价格在电力市场是时间序列预测中最受欢迎的问题。先前的研究强调使用越来越复杂的学习算法来捕捉市场的复杂动态。然而，有一个阈值，其中增加复杂性不会带来显著改善。在这种情况下，我们提议一种不同的方法，即引入适应标准化，以mitigate dataset shifts常见于市场中。这样做可以使学习算法更加注重捕捉target变量和解释变量之间的真实关系。我们对四个市场进行了研究，包括两个新的数据集，之前从未出现在文献中。这些数据集提供了更加现实的市场背景，与 conventient datasets不同。结果显示在所有四个市场中有显著改善，使用在文献中广泛accepted的学习算法。这一显著进步揭示了适应转换在预测模型性能提高方面的潜在力量，开启了新的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Steady-State-Analysis-of-Queues-with-Hawkes-Arrival-and-Its-Application-to-Online-Learning-for-Hawkes-Queues"><a href="#Steady-State-Analysis-of-Queues-with-Hawkes-Arrival-and-Its-Application-to-Online-Learning-for-Hawkes-Queues" class="headerlink" title="Steady-State Analysis of Queues with Hawkes Arrival and Its Application to Online Learning for Hawkes Queues"></a>Steady-State Analysis of Queues with Hawkes Arrival and Its Application to Online Learning for Hawkes Queues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02577">http://arxiv.org/abs/2311.02577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyun Chen, Guiyu Hong</li>
<li>for: 这个论文 investigate了单服务器队列中 Hawkes 到达和一般服务分布的长期行为，以及相关的优化问题。</li>
<li>methods: 该论文使用了新的 coupling 技术来确定工作负荷和忙期过程的 finite moment bounds，并证明这些队列过程在恒定状态下对数快速 converges。</li>
<li>results: 根据这些理论结论，该论文开发了一种高效的数据驱动的 numerial 算法来解决 Hawkes 队列中的优化工作人员问题，并发现在高峰期 régime, Hawkes 队列的工作人员划算与 класси GI&#x2F;GI&#x2F;1 模型存在显著差异。<details>
<summary>Abstract</summary>
We investigate the long-run behavior of single-server queues with Hawkes arrivals and general service distributions and related optimization problems. In detail, utilizing novel coupling techniques, we establish finite moment bounds for the stationary distribution of the workload and busy period processes. In addition, we are able to show that, those queueing processes converge exponentially fast to their stationary distribution. Based on these theoretic results, we develop an efficient numerical algorithm to solve the optimal staffing problem for the Hawkes queues in a data-driven manner. Numerical results indicate a sharp difference in staffing for Hawkes queues, compared to the classic GI/GI/1 model, especially in the heavy-traffic regime.
</details>
<details>
<summary>摘要</summary>
我们研究单服务器队列中的长期行为，包括途径 Hawkes 的到达和一般服务分布，以及相关的优化问题。在详细的探讨中，我们利用新的 Coupling 技术，确定了工作负荷和忙期过程的finite moment bound。此外，我们还证明了这些队列过程在 exponentially fast 速度下关于其站点分布的整体准确性。基于这些理论结果，我们开发了一种高效的数据驱动的数字算法，解决 Hawkes 队列的优化人员问题。 numerically 的结果表明，在高负荷情况下，Hawkes 队列的人员配置和 класси GI/GI/1 模型之间存在很大的差异。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Treasure-Hunt-Content-based-Time-Series-Retrieval-System-for-Discovering-Insights"><a href="#Temporal-Treasure-Hunt-Content-based-Time-Series-Retrieval-System-for-Discovering-Insights" class="headerlink" title="Temporal Treasure Hunt: Content-based Time Series Retrieval System for Discovering Insights"></a>Temporal Treasure Hunt: Content-based Time Series Retrieval System for Discovering Insights</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02560">http://arxiv.org/abs/2311.02560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chin-Chia Michael Yeh, Huiyuan Chen, Xin Dai, Yan Zheng, Yujie Fan, Vivian Lai, Junpeng Wang, Audrey Der, Zhongfang Zhuang, Liang Wang, Wei Zhang</li>
<li>for: 本研究旨在解决多个领域时序数据库中的时序数据检索问题。</li>
<li>methods: 本研究使用了多种流行的时序数据模型化和检索方法，并提出了一种新的距离学习模型来解决这个问题。</li>
<li>results: 对于多个领域时序数据库中的时序数据检索问题，新的距离学习模型表现出色，超过了现有的方法。<details>
<summary>Abstract</summary>
Time series data is ubiquitous across various domains such as finance, healthcare, and manufacturing, but their properties can vary significantly depending on the domain they originate from. The ability to perform Content-based Time Series Retrieval (CTSR) is crucial for identifying unknown time series examples. However, existing CTSR works typically focus on retrieving time series from a single domain database, which can be inadequate if the user does not know the source of the query time series. This limitation motivates us to investigate the CTSR problem in a scenario where the database contains time series from multiple domains. To facilitate this investigation, we introduce a CTSR benchmark dataset that comprises time series data from a variety of domains, such as motion, power demand, and traffic. This dataset is sourced from a publicly available time series classification dataset archive, making it easily accessible to researchers in the field. We compare several popular methods for modeling and retrieving time series data using this benchmark dataset. Additionally, we propose a novel distance learning model that outperforms the existing methods. Overall, our study highlights the importance of addressing the CTSR problem across multiple domains and provides a useful benchmark dataset for future research.
</details>
<details>
<summary>摘要</summary>
时序数据在不同领域 everywhere，如金融、医疗和制造等，但它们的属性可以很大不同。能够实现基于内容的时序数据检索（CTSR）是识别未知时序例子的重要能力。然而，现有的CTSR工作通常将注意力集中在单一领域数据库上，这可能不够用于用户不知道查询时序序列的来源。这种限制使我们感到需要调查多个领域数据库中的CTSR问题。为了实现这一目的，我们提出了一个CTSRBenchmark dataset，该dataset包含多个领域的时序数据，如运动、电力需求和交通。这些数据来自公共可用时序分类数据集存档，因此可以让研究人员在领域中轻松地访问。我们比较了多种流行的时序数据模型化和检索方法，并提出了一种新的距离学习模型，该模型在CTSRBenchmark dataset上表现出色。总之，我们的研究强调了跨多个领域的CTSR问题的重要性，并提供了一个有用的CTSRBenchmark dataset，为未来的研究提供了便利。
</details></li>
</ul>
<hr>
<h2 id="Fast-Minimization-of-Expected-Logarithmic-Loss-via-Stochastic-Dual-Averaging"><a href="#Fast-Minimization-of-Expected-Logarithmic-Loss-via-Stochastic-Dual-Averaging" class="headerlink" title="Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging"></a>Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02557">http://arxiv.org/abs/2311.02557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chung-En Tsai, Hao-Chung Cheng, Yen-Huan Li</li>
<li>for: 这个论文目的是将预期对数损失最小化，并且考虑了概率简单体和量子激发函数的问题。</li>
<li>methods: 这个论文使用了 Stochastic First-Order Algorithm with Logarithmic Barrier， named $B$-sample stochastic dual averaging。</li>
<li>results: 这个算法可以在 $\tilde{O} (d^2&#x2F;\varepsilon^2)$ 时间内获得 $\varepsilon$-优解，与现有的概率方法减少了 $d^{2\omega-2}$ 的时间复杂度，超过了批处理方法的时间复杂度 $d^2$。<details>
<summary>Abstract</summary>
Consider the problem of minimizing an expected logarithmic loss over either the probability simplex or the set of quantum density matrices. This problem encompasses tasks such as solving the Poisson inverse problem, computing the maximum-likelihood estimate for quantum state tomography, and approximating positive semi-definite matrix permanents with the currently tightest approximation ratio. Although the optimization problem is convex, standard iteration complexity guarantees for first-order methods do not directly apply due to the absence of Lipschitz continuity and smoothness in the loss function.   In this work, we propose a stochastic first-order algorithm named $B$-sample stochastic dual averaging with the logarithmic barrier. For the Poisson inverse problem, our algorithm attains an $\varepsilon$-optimal solution in $\tilde{O} (d^2/\varepsilon^2)$ time, matching the state of the art. When computing the maximum-likelihood estimate for quantum state tomography, our algorithm yields an $\varepsilon$-optimal solution in $\tilde{O} (d^3/\varepsilon^2)$ time, where $d$ denotes the dimension. This improves on the time complexities of existing stochastic first-order methods by a factor of $d^{\omega-2}$ and those of batch methods by a factor of $d^2$, where $\omega$ denotes the matrix multiplication exponent. Numerical experiments demonstrate that empirically, our algorithm outperforms existing methods with explicit complexity guarantees.
</details>
<details>
<summary>摘要</summary>
问题是最小化预期的含阶函数损失的问题，这个问题包括解决波索因 inverse 问题、计算量子状态探测的最大可能性估计、以及使用当前最紧的比率来近似正semidefinite 矩阵的 permanents。尽管优化问题是凸的，但标准的第一阶方法的证明不直接适用，因为损失函数没有 lipschitz 连续和光滑性。在这篇文章中，我们提出了一种 Stochastic first-order 算法，名为 $B$-sample stochastic dual averaging with logarithmic barrier。对于波索因 inverse 问题，我们的算法可以在 $\tilde{O} (d^2/\varepsilon^2)$ 时间内获得 $\varepsilon$-优的解，与当前状态之冲突。当计算量子状态探测的最大可能性估计时，我们的算法可以在 $\tilde{O} (d^3/\varepsilon^2)$ 时间内获得 $\varepsilon$-优的解，其中 $d$ 是维度。这比现有的随机第一阶方法的时间复杂度增加 $d^{\omega}-2}$，并且比批处理方法增加 $d^2$，其中 $\omega$ 是矩阵乘法 exponent。实验表明，我们的算法在实际中比现有的方法 WITH 显式复杂度保证更好。
</details></li>
</ul>
<hr>
<h2 id="High-dimensional-Bid-Learning-for-Energy-Storage-Bidding-in-Energy-Markets"><a href="#High-dimensional-Bid-Learning-for-Energy-Storage-Bidding-in-Energy-Markets" class="headerlink" title="High-dimensional Bid Learning for Energy Storage Bidding in Energy Markets"></a>High-dimensional Bid Learning for Energy Storage Bidding in Energy Markets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02551">http://arxiv.org/abs/2311.02551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinyu Liu, Hongye Guo, Qinghu Tang, En Lu, Qiuna Cai, Qixin Chen</li>
<li>for:  optimize the profitability of Energy Storage Systems (ESSs) in electricity markets with high volatility</li>
<li>methods:  modify the common reinforcement learning (RL) process with a new bid representation method called Neural Network Embedded Bids (NNEBs), which represents market bids as monotonic neural networks with discrete outputs</li>
<li>results:  achieve 18% higher profit than the baseline and up to 78% profit of the optimal market bidder through experiments on real-world market datasets<details>
<summary>Abstract</summary>
With the growing penetration of renewable energy resource, electricity market prices have exhibited greater volatility. Therefore, it is important for Energy Storage Systems(ESSs) to leverage the multidimensional nature of energy market bids to maximize profitability. However, current learning methods cannot fully utilize the high-dimensional price-quantity bids in the energy markets. To address this challenge, we modify the common reinforcement learning(RL) process by proposing a new bid representation method called Neural Network Embedded Bids (NNEBs). NNEBs refer to market bids that are represented by monotonic neural networks with discrete outputs. To achieve effective learning of NNEBs, we first learn a neural network as a strategic mapping from the market price to ESS power output with RL. Then, we re-train the network with two training modifications to make the network output monotonic and discrete. Finally, the neural network is equivalently converted into a high-dimensional bid for bidding. We conducted experiments over real-world market datasets. Our studies show that the proposed method achieves 18% higher profit than the baseline and up to 78% profit of the optimal market bidder.
</details>
<details>
<summary>摘要</summary>
NNEBs refer to market bids that are represented by monotonic neural networks with discrete outputs. To effectively learn NNEBs, we first learn a neural network as a strategic mapping from the market price to ESS power output with RL. Then, we re-train the network with two training modifications to make the network output monotonic and discrete. Finally, the neural network is equivalently converted into a high-dimensional bid for bidding.We conducted experiments over real-world market datasets. Our studies show that the proposed method achieves 18% higher profit than the baseline and up to 78% profit of the optimal market bidder.
</details></li>
</ul>
<hr>
<h2 id="Preliminary-Analysis-on-Second-Order-Convergence-for-Biased-Policy-Gradient-Methods"><a href="#Preliminary-Analysis-on-Second-Order-Convergence-for-Biased-Policy-Gradient-Methods" class="headerlink" title="Preliminary Analysis on Second-Order Convergence for Biased Policy Gradient Methods"></a>Preliminary Analysis on Second-Order Convergence for Biased Policy Gradient Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02546">http://arxiv.org/abs/2311.02546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siqiao Mu, Diego Klabjan</li>
<li>for: 研究 policy gradient 算法在非凸函数空间中的 globally optimal 性和稳定性。</li>
<li>methods: 使用非凸函数结构的 regularity  assumptions, 以及 second-order  guarantee 技巧，从而实现更好的 convergence 性。</li>
<li>results: 提供了 biased policy gradient 算法的 preliminary 结果，并且采用 nonconvex 优化 技巧进行证明。  future work 将是提供actor-critic 算法的 finite-time second-order convergence 分析。<details>
<summary>Abstract</summary>
Although the convergence of policy gradient algorithms to first-order stationary points is well-established, the objective functions of reinforcement learning problems are typically highly nonconvex. Therefore, recent work has focused on two extensions: ``global" convergence guarantees under regularity assumptions on the function structure, and second-order guarantees for escaping saddle points and convergence to true local minima. Our work expands on the latter approach, avoiding the restrictive assumptions of the former that may not apply to general objective functions. Existing results on vanilla policy gradient only consider an unbiased gradient estimator, but practical implementations under the infinite-horizon discounted setting, including both Monte-Carlo methods and actor-critic methods, involve gradient descent updates with a biased gradient estimator. We present preliminary results on the convergence of biased policy gradient algorithms to second-order stationary points, leveraging proof techniques from nonconvex optimization. In our next steps we aim to provide the first finite-time second-order convergence analysis for actor-critic algorithms.
</details>
<details>
<summary>摘要</summary>
although the convergence of policy gradient algorithms to first-order stationary points is well-established, the objective functions of reinforcement learning problems are typically highly nonconvex. therefore, recent work has focused on two extensions: "global" convergence guarantees under regularity assumptions on the function structure, and second-order guarantees for escaping saddle points and convergence to true local minima. our work expands on the latter approach, avoiding the restrictive assumptions of the former that may not apply to general objective functions. existing results on vanilla policy gradient only consider an unbiased gradient estimator, but practical implementations under the infinite-horizon discounted setting, including both monte-carlo methods and actor-critic methods, involve gradient descent updates with a biased gradient estimator. we present preliminary results on the convergence of biased policy gradient algorithms to second-order stationary points, leveraging proof techniques from nonconvex optimization. in our next steps, we aim to provide the first finite-time second-order convergence analysis for actor-critic algorithms.Here's the translation in Traditional Chinese:although the convergence of policy gradient algorithms to first-order stationary points is well-established, the objective functions of reinforcement learning problems are typically highly nonconvex. therefore, recent work has focused on two extensions: "global" convergence guarantees under regularity assumptions on the function structure, and second-order guarantees for escaping saddle points and convergence to true local minima. our work expands on the latter approach, avoiding the restrictive assumptions of the former that may not apply to general objective functions. existing results on vanilla policy gradient only consider an unbiased gradient estimator, but practical implementations under the infinite-horizon discounted setting, including both monte-carlo methods and actor-critic methods, involve gradient descent updates with a biased gradient estimator. we present preliminary results on the convergence of biased policy gradient algorithms to second-order stationary points, leveraging proof techniques from nonconvex optimization. in our next steps, we aim to provide the first finite-time second-order convergence analysis for actor-critic algorithms.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/cs.LG_2023_11_05/" data-id="clpahu76y00uf3h88ebedb10j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/eess.IV_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T09:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/eess.IV_2023_11_05/">eess.IV - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Flexible-uniform-sampling-foveated-Fourier-single-pixel-imaging"><a href="#Flexible-uniform-sampling-foveated-Fourier-single-pixel-imaging" class="headerlink" title="Flexible uniform-sampling foveated Fourier single-pixel imaging"></a>Flexible uniform-sampling foveated Fourier single-pixel imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02646">http://arxiv.org/abs/2311.02646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huan Cui, Jie Cao, Qun Hao, Haoyu Zhang, Chang Zhou</li>
<li>for: The paper aims to achieve high-quality single-pixel imaging (SPI) using fewer measurements, which is essential for real-time SPI applications.</li>
<li>methods: The proposed method, called uniform-sampling foveated FSI (UFFSI), utilizes three features: uniform sampling, effective sampling, and flexible fovea. These features reduce data redundancy, transform non-uniform sampling into uniform sampling, and achieve under-sampling high-efficiency and high-quality SPI.</li>
<li>results: Experimental results show that UFFSI with 255<em>341 cells and 89% reduction in data redundancy can achieve significantly better imaging quality than traditional high-resolution FSI with 1024</em>768 pixels, while reducing the number of measurements required. This breakthrough may pave the way for future real-time SPI applications.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这个论文目的是实现 fewer measurements 的高质量单像素成像 (SPI)，这对实时 SPI 应用非常重要。</li>
<li>methods: 提议的方法是 uniform-sampling foveated FSI (UFFSI)，它利用了三个特点：uniform sampling、effective sampling 和 flexible fovea。这些特点可以减少数据纠缠、将非uniform sampling 转换为 uniform sampling，并实现 under-sampling 高效率高质量 SPI。</li>
<li>results: 实验结果表明，UFFSI  WITH 255*341 cells 和 89% 的数据纠缠减少，可以在大规模场景中实现高质量 SPI，而不需要如传统高分辨 FSI 的多个数据。这种突破可能会对未来实时 SPI 应用产生深见。<details>
<summary>Abstract</summary>
Fourier single-pixel imaging (FSI) is a data-efficient single-pixel imaging (SPI). However, there is still a serious challenge to obtain higher imaging quality using fewer measurements, which limits the development of real-time SPI. In this work, a uniform-sampling foveated FSI (UFFSI) is proposed with three features, uniform sampling, effective sampling and flexible fovea, to achieve under-sampling high-efficiency and high-quality SPI, even in a large-scale scene. First, by flexibly using the three proposed foveated pattern structures, data redundancy is reduced significantly to only require high resolution (HR) on regions of interest (ROIs), which radically reduces the need of total data number. Next, by the non-uniform weight distribution processing, non-uniform spatial sampling is transformed into uniform sampling, then the fast Fourier transform is used accurately and directly to obtain under-sampling high imaging quality with further reduced measurements. At a sampling ratio of 0.0084 referring to HR FSI with 1024*768 pixels, experimentally, by UFFSI with 255*341 cells of 89% reduction in data redundancy, the ROI has a significantly better imaging quality to meet imaging needs. We hope this work can provide a breakthrough for future real-time SPI.
</details>
<details>
<summary>摘要</summary>
富含单个像素成像（FSI）是一种数据效率高的单个像素成像（SPI）。然而，在使用更少测量时，获得更高质量成像仍然是一个严重挑战，这限制了实时SPI的发展。在这种工作中，我们提出了一种固定样式的均匀抽象抽象（UFFSI），具有三个特点：均匀采样、有效采样和灵活覆盖。通过使用这三种提议的覆盖模式，减少了数据繁殖，只需要在关键区域（ROI）中高分辨率（HR），从而减少了总数据量。然后，通过非均匀权重分布处理，将非均匀的空间采样转换为均匀采样，然后使用快速傅立叶变换，直接获得减少测量的高质量成像。在0.0084的抽象比例（HR FSI）下，实验证明，使用UFFSI的255*341个细胞，可以减少数据繁殖的89%，ROI中的成像质量得到明显改善。我们希望这种工作可以为未来实时SPI提供一个突破。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/eess.IV_2023_11_05/" data-id="clpahu7el01d53h88b8ji45fh" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/05/eess.SP_2023_11_05/" class="article-date">
  <time datetime="2023-11-05T08:00:00.000Z" itemprop="datePublished">2023-11-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/05/eess.SP_2023_11_05/">eess.SP - 2023-11-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Age-of-Information-Analysis-for-CR-NOMA-Aided-Uplink-Systems-with-Randomly-Arrived-Packets"><a href="#Age-of-Information-Analysis-for-CR-NOMA-Aided-Uplink-Systems-with-Randomly-Arrived-Packets" class="headerlink" title="Age of Information Analysis for CR-NOMA Aided Uplink Systems with Randomly Arrived Packets"></a>Age of Information Analysis for CR-NOMA Aided Uplink Systems with Randomly Arrived Packets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02691">http://arxiv.org/abs/2311.02691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanshi Sun, Yanglin Ye, Zhiguo Ding, Momiao Zhou, Lei Liu<br>for: 这种研究旨在应用 cognitive radio 引导的非对称访问技术来降低 uplink 传输中的年龄信息 (AoI)。methods: 这种研究使用了时分多access (TDMA) 的传统网络作为研究对象，每个用户都被分配了一个专用的时间槽来传输其状态更新信息。 研究采用了 cognitive radio 技术，让每个用户在其他用户的时间槽中发送信息，从而提高发送机会数。 研究人员还开发了一个精确的分析框架，以确定 CR-NOMA 和无重传的 AoI 表达式，并考虑了状态更新生成过程中的随机性。results: 研究结果表明，通过应用 CR-NOMA，AoI 可以显著降低，特别是当状态到达率低时。 此外，使用重传也能够减少 AoI，特别是当状态到达率低时。<details>
<summary>Abstract</summary>
This paper studies the application of cognitive radio inspired non-orthogonal multiple access (CR-NOMA) to reduce age of information (AoI) for uplink transmission. In particular, a time division multiple access (TDMA) based legacy network is considered, where each user is allocated with a dedicated time slot to transmit its status update information. The CR-NOMA is implemented as an add-on to the TDMA legacy network, which enables each user to have more opportunities to transmit by sharing other user's time slots. A rigorous analytical framework is developed to obtain the expressions for AoIs achieved by CR-NOMA with and without re-transmission, by taking the randomness of the status update generating process into consideration. Numerical results are presented to verify the accuracy of the developed analysis. It is shown that the AoI can be significantly reduced by applying CR-NOMA compared to TDMA. Moreover, the use of re-transmission is helpful to reduce AoI, especially when the status arrival rate is low.
</details>
<details>
<summary>摘要</summary>
To analyze the performance of CR-NOMA, a rigorous analytical framework is developed, taking into account the randomness of the status update generating process. The expressions for AoIs achieved by CR-NOMA with and without re-transmission are derived, and numerical results are presented to verify the accuracy of the analysis.The results show that CR-NOMA can significantly reduce AoI compared to TDMA, and the use of re-transmission is particularly beneficial when the status arrival rate is low. This suggests that CR-NOMA can be an effective technique for improving the efficiency of uplink transmission in legacy networks.
</details></li>
</ul>
<hr>
<h2 id="An-Open-Dataset-Storage-Standard-for-6G-Testbeds"><a href="#An-Open-Dataset-Storage-Standard-for-6G-Testbeds" class="headerlink" title="An Open Dataset Storage Standard for 6G Testbeds"></a>An Open Dataset Storage Standard for 6G Testbeds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02662">http://arxiv.org/abs/2311.02662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gilles Callebaut, Michiel Sandra, Christian Nelson, Thomas Wilding, Daan Delabie, Benjamin J. B. Deutschmann, William Tärneberg, Emma Fitzgerald, Anders J. Johansson, Liesbet Van der Perre</li>
<li>for: 提高6G测试床的数据可访性和可重用性，以便增进研究社区中数据的共享和合作。</li>
<li>methods: 提出了数据存储标准（DSS），用于实验和仿真数据的交换和处理，并支持多种测试床和数据类型。</li>
<li>results: DSS可以提高研究者们对数据的访问和 reuse，满足FAIR原则（找到、访问、交换、重用），并且不限于RF数据存储。<details>
<summary>Abstract</summary>
The emergence of sixth-generation (6G) networks has spurred the development of novel testbeds, including sub-THz networks, cell-free systems, and 6G simulators. To maximize the benefits of these systems, it is crucial to make the generated data publicly available and easily reusable by others. Although data sharing has become a common practice, a lack of standardization hinders data accessibility and interoperability. In this study, we propose the Dataset Storage Standard (DSS) to address these challenges by facilitating data exchange and enabling convenient processing script creation in a testbed-agnostic manner. DSS supports both experimental and simulated data, allowing researchers to employ the same processing scripts and tools across different datasets. Unlike existing standardization efforts such as SigMF and NI RF Data Recording API, DSS provides a broader scope by accommodating a common definition file for testbeds and is not limited to RF data storage. The dataset format utilizes a hierarchical structure, with a tensor representation for specific experiment scenarios. In summary, DSS offers a comprehensive and flexible framework for enhancing the FAIR principles (Findability, Accessibility, Interoperability, and Reusability) in 6G testbeds, promoting open and efficient data sharing in the research community.
</details>
<details>
<summary>摘要</summary>
“六代网络（6G）的出现促进了新的测试平台的发展，包括Sub-THz网络、无终端系统和6G模拟器。为了最大化这些系统的利器，它是非常重要的让生成的数据公开可用，并且可以轻松地重用其他人。虽然数据分享已经成为常见的做法，但是数据访问和兼容性受到标准化的限制。在这项研究中，我们提议使用数据存储标准（DSS）来解决这些挑战，使得数据交换和处理脚本的创建变得更加简单和通用。DSS支持实验和模拟数据，允许研究人员使用相同的处理脚本和工具来处理不同的数据集。与现有的标准化尝试如SigMF和NI RF数据记录API不同，DSS具有更广泛的范围，可以涵盖各种测试平台的公定定义文件。数据格式采用层次结构，使用tensor表示法来描述特定的实验场景。总之，DSS提供了一个全面和灵活的框架，以便在6G测试平台中提高FAIR原则（找到、访问、兼容性和重用），推动开放和高效的数据分享在研究 сообществе。”
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Hybrid-Terrestrial-LEO-Satellite-Systems-for-Rural-Connectivity"><a href="#Exploiting-Hybrid-Terrestrial-LEO-Satellite-Systems-for-Rural-Connectivity" class="headerlink" title="Exploiting Hybrid Terrestrial&#x2F;LEO Satellite Systems for Rural Connectivity"></a>Exploiting Hybrid Terrestrial&#x2F;LEO Satellite Systems for Rural Connectivity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02591">http://arxiv.org/abs/2311.02591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Houcem Ben Salem, Nour Kouzayha, Ammar EL Falou, Mohamed-Slim Alouini, Tareq Y. Al-Naffouri</li>
<li>for: 本文目的是评估hybrid terrestrial&#x2F;satellite网络在农村地区提供连接性能的性能。</li>
<li>methods: 本文使用束ochastic geometry工具来 derivatetractable表达式，用于评估hybrid网络中用户与基站或卫星连接的coverage概率和平均数据速率。</li>
<li>results: 经过Monte Carlo仿真 validate the accuracy of the derived expressions, the obtained results show that the satellite constellation size, terrestrial base station density, and MIMO configuration parameters all have a significant impact on the performance of hybrid networks in providing rural connectivity.<details>
<summary>Abstract</summary>
Satellite networks are playing an important role in realizing global seamless connectivity in beyond 5G and 6G wireless networks. In this paper, we develop a comprehensive analytical framework to assess the performance of hybrid terrestrial/satellite networks in providing rural connectivity. We assume that the terrestrial base stations are equipped with multiple-input-multiple-output (MIMO) technologies and that the user has the option to associate with a base station or a satellite to be served. Using tools from stochastic geometry, we derive tractable expressions for the coverage probability and average data rate and prove the accuracy of the derived expressions through Monte Carlo simulations. The obtained results capture the impact of the satellite constellation size, the terrestrial base station density, and the MIMO configuration parameters.
</details>
<details>
<summary>摘要</summary>
卫星网络在超5G和6G无线网络中实现全球无缝连接具有重要作用。本文，我们开发了一个完整的分析框架，以评估卫星/地面网络在偏远地区connectivity提供的性能。我们假设地面基站装备了多输入多出力（MIMO）技术，用户可以选择与基站或卫星连接。使用Stochastic Geometry工具，我们 derivates tractable表达式，表示覆盖率和平均数据速率，并通过Monte Carlo仿真实验 validate the accuracy of the derived expressions。获得的结果反映了卫星星座大小、地面基站密度和MIMO配置参数的影响。
</details></li>
</ul>
<hr>
<h2 id="Pilot-Based-Key-Distribution-and-Encryption-for-Secure-Coherent-Passive-Optical-Networks"><a href="#Pilot-Based-Key-Distribution-and-Encryption-for-Secure-Coherent-Passive-Optical-Networks" class="headerlink" title="Pilot-Based Key Distribution and Encryption for Secure Coherent Passive Optical Networks"></a>Pilot-Based Key Distribution and Encryption for Secure Coherent Passive Optical Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02554">http://arxiv.org/abs/2311.02554</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haide Wang, Ji Zhou, Qingxin Lu, Jianrui Zeng, Yongqing Liao, Weiping Liu, Changyuan Yu, Zhaohui Li<br>for: 提高了物理层安全性，增强了光学网络的安全性。methods: 使用 Advanced Encryption Standard（AES）算法和四级振荡形式（GCS-PAM4）的导航干扰器基础设定密钥分布。results: 实验结果表明，使用GCS-PAM4导航干扰器可以实现无错误的上行传输，并且防止下行传输中的侦测。此外，使用GCS-PAM4导航干扰器对CPR的影响相对较小。<details>
<summary>Abstract</summary>
The security issues of passive optical networks (PONs) have always been a concern due to broadcast transmission. Physical-layer security enhancement for the coherent PON should be as significant as improving transmission performance. In this paper, we propose the advanced encryption standard (AES) algorithm and geometric constellation shaping four-level pulse amplitude modulation (GCS-PAM4) pilot-based key distribution for secure coherent PON. The first bit of the GCS-PAM4 pilot is used for the hardware-efficient carrier phase recovery (CPR), while the second bit is utilized for key distribution without occupying the additional overhead. The key bits are encoded by the polar code to ensure error-free distribution. Frequent key updates are permitted for every codeword to improve the security of coherent PON. The experimental results of the 200-Gbps secure coherent PON using digital subcarrier multiplexing show that the GCS-PAM4 pilot-based key distribution could be error-free at upstream transmission without occupying the additional overhead and the eavesdropping would be prevented by AES algorithm at downstream transmission. Moreover, there is almost no performance penalty on the CPR using the GCS-PAM4 pilot compared to the binary phase shift keying pilot.
</details>
<details>
<summary>摘要</summary>
PASSIVE OPTICAL NETWORKS (PONs) 的安全问题一直以来都是一大问题，因为它们使用广播传输。为了提高干扰性的 Physical-layer 安全性，在本文中我们提出了高级加密标准 (AES) 算法和四个水平杂化干扰 (GCS-PAM4) 导航器基于钥匙分布。GCS-PAM4 导航器的第一个比特用于硬件高效的 carriers 逻辑征 recovery (CPR)，而第二个比特用于钥匙分布，不占用额外开销。钥匙位数用波尔代码确保错误自动分配。在每个代码字符串中允许频繁更新钥匙，以提高干扰性的 PON 安全性。实验结果表明，使用数字子帧多路分 multiplexing 的 200 Gbps 安全干扰 PON 中 GCS-PAM4 导航器基于钥匙分布可以在上行传输中实现无错误，并且在下行传输中防止侦测。此外，使用 GCS-PAM4 导航器与使用 binary phase shift keying 导航器相比，CPR 的性能几乎无损。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/05/eess.SP_2023_11_05/" data-id="clpahu7ge01hl3h88g9eq18jk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/04/cs.SD_2023_11_04/" class="article-date">
  <time datetime="2023-11-04T15:00:00.000Z" itemprop="datePublished">2023-11-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/04/cs.SD_2023_11_04/">cs.SD - 2023-11-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="OverHear-Headphone-based-Multi-sensor-Keystroke-Inference"><a href="#OverHear-Headphone-based-Multi-sensor-Keystroke-Inference" class="headerlink" title="OverHear: Headphone based Multi-sensor Keystroke Inference"></a>OverHear: Headphone based Multi-sensor Keystroke Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02288">http://arxiv.org/abs/2311.02288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Raveen Wijewickrama, Maryam Abbasihafshejani, Anindya Maiti, Murtuza Jadliwala</li>
<li>for: 这篇论文旨在检测和分析Headphones中的键盘输入嗅探攻击。</li>
<li>methods: 该论文使用了OverHear框架，该框架利用了Headphones中的高级度麦克风和加速度计数据来进行键盘输入预测。</li>
<li>results: 实验结果表明，该方法可以在不同环境下达到键盘输入预测精度达80%以上，而 word prediction 精度超过70%。<details>
<summary>Abstract</summary>
Headphones, traditionally limited to audio playback, have evolved to integrate sensors like high-definition microphones and accelerometers. While these advancements enhance user experience, they also introduce potential eavesdropping vulnerabilities, with keystroke inference being our concern in this work. To validate this threat, we developed OverHear, a keystroke inference framework that leverages both acoustic and accelerometer data from headphones. The accelerometer data, while not sufficiently detailed for individual keystroke identification, aids in clustering key presses by hand position. Concurrently, the acoustic data undergoes analysis to extract Mel Frequency Cepstral Coefficients (MFCC), aiding in distinguishing between different keystrokes. These features feed into machine learning models for keystroke prediction, with results further refined via dictionary-based word prediction methods. In our experimental setup, we tested various keyboard types under different environmental conditions. We were able to achieve top-5 key prediction accuracy of around 80% for mechanical keyboards and around 60% for membrane keyboards with top-100 word prediction accuracies over 70% for all keyboard types. The results highlight the effectiveness and limitations of our approach in the context of real-world scenarios.
</details>
<details>
<summary>摘要</summary>
headphones, 原本只是专门用于音频播放的设备, 已经演化到添加了高级 Microphone 和加速度计数器等感应器。这些进步可以增强用户体验, 但也会带来 potential eavesdropping 问题, 我们在这个工作中关注的是键盘输入推测的问题。为了验证这个问题, 我们开发了 OverHear 框架, 这个框架利用 headphones 上的 acoustic 和加速度数据来进行键盘输入推测。加速度数据,  although not detailed enough for individual key press identification, 可以帮助分组键盘输入。同时, acoustic 数据会进行分析, 以提取 Mel Frequency Cepstral Coefficients (MFCC)，帮助区分不同的键盘输入。这些特征会被 feed 到机器学习模型中, 以进行键盘预测, 结果会透过字库基于词汇预测方法进一步精确化。在我们的实验设置中, 我们对不同环境下的不同键盘进行了试验, 我们能够 achieve top-5 key prediction accuracy 约 80% 以上, 以及 top-100 word prediction accuracy 约 70% 以上, 这些结果显示了我们的方法在实际应用中的有效性和局限性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/04/cs.SD_2023_11_04/" data-id="clpahu79p01243h885kxf1pty" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/11/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/13/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
