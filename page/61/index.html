
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/61/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/cs.CV_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T13:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/cs.CV_2023_08_03/">cs.CV - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="An-End-to-end-Food-Portion-Estimation-Framework-Based-on-Shape-Reconstruction-from-Monocular-Image"><a href="#An-End-to-end-Food-Portion-Estimation-Framework-Based-on-Shape-Reconstruction-from-Monocular-Image" class="headerlink" title="An End-to-end Food Portion Estimation Framework Based on Shape Reconstruction from Monocular Image"></a>An End-to-end Food Portion Estimation Framework Based on Shape Reconstruction from Monocular Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01810">http://arxiv.org/abs/2308.01810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeman Shao, Gautham Vinod, Jiangpeng He, Fengqing Zhu</li>
<li>for: 这个研究旨在提供一个自动化饮食评估解决方案，并且使用深度学习来估计食物能量价值。</li>
<li>methods: 这个方法使用一个终端 deep learning 框架，通过从食物图像中推导出食物的3D形状信息，以估计食物能量价值。</li>
<li>results: 在使用 Nutrition5k 食物图像集进行评估中，这个方法的 Mean Absolute Error (MAE) 为40.05 kCal， Mean Absolute Percentage Error (MAPE) 为11.47%。这个方法仅使用 RGB 图像作为输入，并且与需要 RGB 和深度信息的现有方法相比，它具有竞争力。<details>
<summary>Abstract</summary>
Dietary assessment is a key contributor to monitoring health status. Existing self-report methods are tedious and time-consuming with substantial biases and errors. Image-based food portion estimation aims to estimate food energy values directly from food images, showing great potential for automated dietary assessment solutions. Existing image-based methods either use a single-view image or incorporate multi-view images and depth information to estimate the food energy, which either has limited performance or creates user burdens. In this paper, we propose an end-to-end deep learning framework for food energy estimation from a monocular image through 3D shape reconstruction. We leverage a generative model to reconstruct the voxel representation of the food object from the input image to recover the missing 3D information. Our method is evaluated on a publicly available food image dataset Nutrition5k, resulting a Mean Absolute Error (MAE) of 40.05 kCal and Mean Absolute Percentage Error (MAPE) of 11.47% for food energy estimation. Our method uses RGB image as the only input at the inference stage and achieves competitive results compared to the existing method requiring both RGB and depth information.
</details>
<details>
<summary>摘要</summary>
饮食评估是健康状况监测的关键因素。现有的自我报告方法具有巨大的偏见和错误。图像基于食物部分估计技术可以直接从食物图像中估算食物能量值，显示出了自动化饮食评估解决方案的潜在优势。现有的图像基于方法可以使用单视图图像或多视图图像和深度信息来估算食物能量，但它们具有有限的性能或者让用户感到压力。在这篇论文中，我们提出了一种基于深度学习的端到端框架，通过RGB图像来估算食物能量。我们利用生成模型来重建食物对象的 voxel 表示，从输入图像中恢复缺失的3D信息。我们的方法在公共可用的饮食图像数据集Nutrition5k上进行评估，得到了40.05 kCal的平均绝对误差（MAE）和11.47%的平均绝对百分比误差（MAPE）。我们的方法只需RGB图像作为推理阶段的输入，实现了与需要RGB和深度信息的现有方法相比的竞争性成绩。
</details></li>
</ul>
<hr>
<h2 id="QUEST-Query-Stream-for-Vehicle-Infrastructure-Cooperative-Perception"><a href="#QUEST-Query-Stream-for-Vehicle-Infrastructure-Cooperative-Perception" class="headerlink" title="QUEST: Query Stream for Vehicle-Infrastructure Cooperative Perception"></a>QUEST: Query Stream for Vehicle-Infrastructure Cooperative Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01804">http://arxiv.org/abs/2308.01804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siqi Fan, Haibao Yu, Wenxian Yang, Jirui Yuan, Zaiqing Nie</li>
<li>for: 这篇论文的目的是提出一种名为QUEST的合作感知框架，以实现可解释的实例级别的 flexible feature interaction。</li>
<li>methods: 这篇论文使用了许多现有的合作方法，如结果合作和特征合作，并提出了一种新的查询合作方法，通过让查询流动 между代理进行交互。</li>
<li>results: 实验结果表明，QUEST 框架可以有效地提高合作感知性能，并且在实际应用场景中（如摄像头基于车辆基础设施感知）表现出了更高的传输灵活性和 packet dropout 的Robustness。<details>
<summary>Abstract</summary>
Cooperative perception can effectively enhance individual perception performance by providing additional viewpoint and expanding the sensing field. Existing cooperation paradigms are either interpretable (result cooperation) or flexible (feature cooperation). In this paper, we propose the concept of query cooperation to enable interpretable instance-level flexible feature interaction. To specifically explain the concept, we propose a cooperative perception framework, termed QUEST, which let query stream flow among agents. The cross-agent queries are interacted via fusion for co-aware instances and complementation for individual unaware instances. Taking camera-based vehicle-infrastructure perception as a typical practical application scene, the experimental results on the real-world dataset, DAIR-V2X-Seq, demonstrate the effectiveness of QUEST and further reveal the advantage of the query cooperation paradigm on transmission flexibility and robustness to packet dropout. We hope our work can further facilitate the cross-agent representation interaction for better cooperative perception in practice.
</details>
<details>
<summary>摘要</summary>
合作感知可以有效地提高个体感知性能，提供额外视点和扩大感知场。现有的合作方法是可解释的（结果合作）或者灵活的（特征合作）。在这篇论文中，我们提出了查询合作概念，以实现可解释的实例级别的灵活特征交互。为了具体说明这个概念，我们提出了一个合作感知框架，称为QUEST，允许查询流水线在代理之间流动。不同代理之间的问题是通过融合实现协同意识的实例，而不同代理之间的问题是通过补充实现个体未知的实例。使用摄像头基于车辆基础设施感知为实际应用场景，在DAIR-V2X-Seq实际数据集上进行实验， demonstarte了QUEST的效果，并透露了查询合作方法在传输灵活性和 packet dropout Robustness 的优势。我们希望我们的工作能够进一步促进跨代理表示交互，以便更好地实现合作感知在实践中。
</details></li>
</ul>
<hr>
<h2 id="RegionBLIP-A-Unified-Multi-modal-Pre-training-Framework-for-Holistic-and-Regional-Comprehension"><a href="#RegionBLIP-A-Unified-Multi-modal-Pre-training-Framework-for-Holistic-and-Regional-Comprehension" class="headerlink" title="RegionBLIP: A Unified Multi-modal Pre-training Framework for Holistic and Regional Comprehension"></a>RegionBLIP: A Unified Multi-modal Pre-training Framework for Holistic and Regional Comprehension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02299">http://arxiv.org/abs/2308.02299</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mightyzau/regionblip">https://github.com/mightyzau/regionblip</a></li>
<li>paper_authors: Qiang Zhou, Chaohui Yu, Shaofeng Zhang, Sitong Wu, Zhibing Wang, Fan Wang</li>
<li>for: 本研究目的是延伸多模式大语言模型（MLLM）的理解范围，以包括地域对象。</li>
<li>methods: 我们提议提取地域特征作为软提示，以便不需要MLLM微调。我们还提出了一种新的位置协助特征提取模块，以有效地提取来自常见图像特征和点云特征的地域特征。</li>
<li>results: 我们的实验结果表明，我们的框架 RegionBLIP 可以保持 BLIP-2 的图像理解能力，并在新引入的点云模式和地域对象上增加理解能力。<details>
<summary>Abstract</summary>
In this work, we investigate extending the comprehension of Multi-modal Large Language Models (MLLMs) to regional objects. To this end, we propose to extract features corresponding to regional objects as soft prompts for LLM, which provides a straightforward and scalable approach and eliminates the need for LLM fine-tuning. To effectively extract regional features from regular image features and irregular point cloud features, we present a novel and unified position-assisted feature extraction module. Furthermore, training an MLLM from scratch is highly time-consuming. Thus, we propose incrementally extending existing pre-trained MLLMs to comprehend more modalities and the regional objects of those modalities. Specifically, we freeze the Q-Former from BLIP-2, an impressive MLLM, and optimize the modality-specific Lora parameters in Q-Former and LLM for each newly introduced modality. The freezing of the Q-Former eliminates the need for extensive pre-training on massive image-text data. The freezed Q-Former pre-trained from massive image-text data is also beneficial for the pre-training on image-region-text data. We name our framework RegionBLIP. We pre-train RegionBLIP on image-region-text, point-cloud-text, and point-cloud-region-text data. Experimental results verify that \Ours{} can preserve the image comprehension capability of BILP-2 and further gain a comprehension of the newly introduced point cloud modality and regional objects. The Data, Code, and Pre-trained models will be available at https://github.com/mightyzau/RegionBLIP.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们 investigate extending the comprehension of Multi-modal Large Language Models (MLLMs) to regional objects. 为此，我们提议提取对 regional objects 的特征作为 LLM 的软提示，这提供了一个直观的并可扩展的方法，并消除了 LLM 的 fine-tuning 需求。为了有效地从常见图像特征和点云特征中提取 regional 特征，我们提出了一个 novel 和统一的位置帮助特征提取模块。此外，预训练一个 MLLM 从头开始是非常时间消耗的。因此，我们提议逐步扩展现有的预训练 MLLM 以包括更多Modalities 和这些 Modality 中的 regional objects。具体来说，我们冻结 BLIP-2 中的 Q-Former，并优化 Modality-specific Lora 参数在 Q-Former 和 LLM 中。冻结 Q-Former 消除了大量预训练在图像-文本数据上的需求。同时，预训练 Q-Former 在图像-区域-文本数据上也有助于预训练。我们将这种框架命名为 RegionBLIP。我们在图像-区域-文本、点云-文本和点云-区域-文本数据上预训练 RegionBLIP。实验结果表明，我们的方法可以保持 BLIP-2 中的图像理解能力，同时还能够增加对新引入的点云模式和 regional objects 的理解。数据、代码和预训练模型将在 GitHub 上提供，链接在 https://github.com/mightyzau/RegionBLIP。
</details></li>
</ul>
<hr>
<h2 id="Point2Mask-Point-supervised-Panoptic-Segmentation-via-Optimal-Transport"><a href="#Point2Mask-Point-supervised-Panoptic-Segmentation-via-Optimal-Transport" class="headerlink" title="Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport"></a>Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01779">http://arxiv.org/abs/2308.01779</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liwentomng/point2mask">https://github.com/liwentomng/point2mask</a></li>
<li>paper_authors: Wentong Li, Yuqian Yuan, Song Wang, Jianke Zhu, Jianshu Li, Jian Liu, Lei Zhang</li>
<li>for: 高级降级图像分割，避免高成本的像素级标注。</li>
<li>methods: 提出了一种有效的方法Point2Mask，通过单个随机点标注来实现高质量的精细预测。</li>
<li>results: 在Pascal VOC和COCO上实验表明，提出的Point2Mask方法可以在无需大量标注的情况下达到高水平的精细预测性能。<details>
<summary>Abstract</summary>
Weakly-supervised image segmentation has recently attracted increasing research attentions, aiming to avoid the expensive pixel-wise labeling. In this paper, we present an effective method, namely Point2Mask, to achieve high-quality panoptic prediction using only a single random point annotation per target for training. Specifically, we formulate the panoptic pseudo-mask generation as an Optimal Transport (OT) problem, where each ground-truth (gt) point label and pixel sample are defined as the label supplier and consumer, respectively. The transportation cost is calculated by the introduced task-oriented maps, which focus on the category-wise and instance-wise differences among the various thing and stuff targets. Furthermore, a centroid-based scheme is proposed to set the accurate unit number for each gt point supplier. Hence, the pseudo-mask generation is converted into finding the optimal transport plan at a globally minimal transportation cost, which can be solved via the Sinkhorn-Knopp Iteration. Experimental results on Pascal VOC and COCO demonstrate the promising performance of our proposed Point2Mask approach to point-supervised panoptic segmentation. Source code is available at: https://github.com/LiWentomng/Point2Mask.
</details>
<details>
<summary>摘要</summary>
Recently, weakly-supervised image segmentation has attracted increasing research attention, aiming to avoid the expensive pixel-wise labeling. In this paper, we propose an effective method, called Point2Mask, to achieve high-quality panoptic prediction using only a single random point annotation per target for training. Specifically, we formulate the panoptic pseudo-mask generation as an Optimal Transport (OT) problem, where each ground-truth (gt) point label and pixel sample are defined as the label supplier and consumer, respectively. The transportation cost is calculated by the introduced task-oriented maps, which focus on the category-wise and instance-wise differences among the various thing and stuff targets. Furthermore, a centroid-based scheme is proposed to set the accurate unit number for each gt point supplier. Hence, the pseudo-mask generation is converted into finding the optimal transport plan at a globally minimal transportation cost, which can be solved via the Sinkhorn-Knopp Iteration. Experimental results on Pascal VOC and COCO demonstrate the promising performance of our proposed Point2Mask approach to point-supervised panoptic segmentation. Source code is available at: https://github.com/LiWentomng/Point2Mask.Here's the word-for-word translation of the text into Simplified Chinese:最近，弱型图像分割获得了研究人员的越来越多的注意力，以避免高价的像素精度标注。在这篇论文中，我们提出了一种有效的方法，即Point2Mask，用于使用单个随机点标注来训练高质量�anoptic预测。具体来说，我们将�anoptic pseudo-mask生成视为一个Optimal Transport（OT）问题，其中每个ground-truth（gt）点标签和像素抽象被定义为标签供应商和消费者，分别。交通成本由引入的任务 oriented map计算，该地图强调类别和实例划分的差异。此外，我们提出了一种基于中心点的方案，以确定每个gt点供应商的准确单位数。因此，pseudo-mask生成转化为找到最低交通成本的优质运输计划，可以通过Sinkhorn-Knopp迭代解决。实验结果表明，我们提出的Point2Mask方法在Pascal VOC和COCO上表现出了扎实的推荐性。源代码可以在https://github.com/LiWentomng/Point2Mask上获取。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-Prediction-of-Stress-and-Strain-Maps-in-Arterial-Walls-for-Improved-Cardiovascular-Risk-Assessment"><a href="#Deep-Learning-based-Prediction-of-Stress-and-Strain-Maps-in-Arterial-Walls-for-Improved-Cardiovascular-Risk-Assessment" class="headerlink" title="Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment"></a>Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01771">http://arxiv.org/abs/2308.01771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasin Shokrollahi1, Pengfei Dong1, Xianqi Li, Linxia Gu</li>
<li>for: 这个研究旨在替代finite element method（FEM），通过使用深度学习工具来更有效地预测血管壁的剪切应力和强度场。</li>
<li>methods: 我们提出了一种基于U-Net的全 convolutional neural network（CNN）来预测血管壁cross section中的 von Mises 剪切应力和强度场，并开发了一种基于conditional generative adversarial network（cGAN）来提高预测结果的准确性。</li>
<li>results: 我们的模型可以高度准确地预测 von Mises 剪切应力和强度场，SSIM分数为0.854和0.830， Mean squared errors为0.017和0.018。此外，我们还提出了 ensemble 和 transfer learning 技术来进一步提高模型的性能。<details>
<summary>Abstract</summary>
This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall. We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections. Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations. On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps. Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps. The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set. Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain. Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set. Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这个研究 investigate了使用端到端深度学习工具作为较为有效的finite element分析的替代方法，以predict arterial wall的压力-弯形场在2D横截面上。我们首先提出了基于U-Net的全 convolutional neural network (CNN)，用于预测 calcification的空间布局对arterial wall横截面的 von Mises 压力和弯形场的分布。此外，我们还开发了基于 conditional generative adversarial network (cGAN)的模型，用于提高预测压力和弯形场图像的准确性。在U-Net和cGAN的基础之上，我们还提出了ensemble approaches，以进一步提高预测图像的准确性。我们的数据集，包括输入和输出图像，通过实施边界条件和提取压力-弯形场图像来生成。训练的U-Net模型可以准确预测 von Mises 压力和弯形场，SSIM 分数为0.854和0.830，mean squared error为0.017和0.018，分别对应于压力和弯形场。此外，cGAN模型在 transferred learning 和 ensemble learning 技术的组合下表现出了高度的准确性，SSIM 分数为0.890和0.803，mean squared error为0.008和0.017。总之，这个研究开发了一个surrogate model，可以高效地预测arterial wall的压力-弯形场，不 matter complex geometries和boundary conditions.
</details></li>
</ul>
<hr>
<h2 id="Focus-on-Content-not-Noise-Improving-Image-Generation-for-Nuclei-Segmentation-by-Suppressing-Steganography-in-CycleGAN"><a href="#Focus-on-Content-not-Noise-Improving-Image-Generation-for-Nuclei-Segmentation-by-Suppressing-Steganography-in-CycleGAN" class="headerlink" title="Focus on Content not Noise: Improving Image Generation for Nuclei Segmentation by Suppressing Steganography in CycleGAN"></a>Focus on Content not Noise: Improving Image Generation for Nuclei Segmentation by Suppressing Steganography in CycleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01769">http://arxiv.org/abs/2308.01769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Utz, Tobias Weise, Maja Schlereth, Fabian Wagner, Mareike Thies, Mingxuan Gu, Stefan Uderhardt, Katharina Breininger</li>
<li>for: 这个论文主要用于描述一种用于生成顺序图像的潜在网络，以便为核体分 segmentation 任务提供更加准确的synthetic数据集。</li>
<li>methods: 该论文使用了 CycleGAN 生成器，并通过采用低通道滤波器基于 DCT 来除掉生成图像中的隐藏短路信息（steganography），以提高生成图像和cycled mask的准确性。</li>
<li>results: 相比 vanilla CycleGAN，该方法可以提高核体分 segmentation 任务的 F1 分数上的表现，提高了5.4个百分点。此外，该研究还证明了在 CycleGAN 架构中 integrate 高级规范技术可以减轻 steganography-related 问题，生成更加准确的synthetic数据集。<details>
<summary>Abstract</summary>
Annotating nuclei in microscopy images for the training of neural networks is a laborious task that requires expert knowledge and suffers from inter- and intra-rater variability, especially in fluorescence microscopy. Generative networks such as CycleGAN can inverse the process and generate synthetic microscopy images for a given mask, thereby building a synthetic dataset. However, past works report content inconsistencies between the mask and generated image, partially due to CycleGAN minimizing its loss by hiding shortcut information for the image reconstruction in high frequencies rather than encoding the desired image content and learning the target task. In this work, we propose to remove the hidden shortcut information, called steganography, from generated images by employing a low pass filtering based on the DCT. We show that this increases coherence between generated images and cycled masks and evaluate synthetic datasets on a downstream nuclei segmentation task. Here we achieve an improvement of 5.4 percentage points in the F1-score compared to a vanilla CycleGAN. Integrating advanced regularization techniques into the CycleGAN architecture may help mitigate steganography-related issues and produce more accurate synthetic datasets for nuclei segmentation.
</details>
<details>
<summary>摘要</summary>
描述核体在微scopic图像中的标注是一项劳动密集的任务，需要专家知识和受到内 raters 和外 raters 的变化，特别是在荧光微scopic中。生成网络如 CycleGAN 可以 inverse 该过程，生成基于给定的 mask 的 synthetic 微scopic图像，从而建立 synthetic 数据集。然而，过去的工作表明，生成的图像与 mask 之间存在内容不一致，部分是因为 CycleGAN 在高频范围内隐藏短路信息，而不是编码愿意图CONTENT 和学习目标任务。在这种情况下，我们提议从生成的图像中除去隐藏的短路信息，使用 DCT 基于低通过滤波。我们发现，这会增加生成图像和 цикли mask 之间的协调性，并评估 synthetic 数据集在下游核体分割任务中的性能。在这种情况下，我们实现了 Vanilla CycleGAN 的 5.4 个百分点 F1 score 的改进。将 advanced regularization techniques  integrate 到 CycleGAN 架构中可能会 mitigate steganography-related issues 并生成更准确的 synthetic 数据集 для核体分割任务。
</details></li>
</ul>
<hr>
<h2 id="Multidimensional-Data-Analysis-Based-on-Block-Convolutional-Tensor-Decomposition"><a href="#Multidimensional-Data-Analysis-Based-on-Block-Convolutional-Tensor-Decomposition" class="headerlink" title="Multidimensional Data Analysis Based on Block Convolutional Tensor Decomposition"></a>Multidimensional Data Analysis Based on Block Convolutional Tensor Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01768">http://arxiv.org/abs/2308.01768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Molavi, Mansoor Rezghi, Tayyebeh Saeedi<br>for:  This paper focuses on developing a new tensor-tensor product called the $\star_c{}\text{-Product}$ based on block convolution with reflective boundary conditions, and using it to improve tensor decomposition for analyzing high-dimensional data.methods: The paper uses the t-product of tensors and block convolution with reflective boundary conditions to develop a new tensor-tensor product called the $\star_c{}\text{-Product}$. The paper also introduces a tensor decomposition based on this product for arbitrary order tensors.results: The paper shows that the proposed $\star_c{}\text{-Product}$ has lower complexity than t-SVD and yields higher-quality results in applications such as classification and compression.<details>
<summary>Abstract</summary>
Tensor decompositions are powerful tools for analyzing multi-dimensional data in their original format. Besides tensor decompositions like Tucker and CP, Tensor SVD (t-SVD) which is based on the t-product of tensors is another extension of SVD to tensors that recently developed and has found numerous applications in analyzing high dimensional data. This paper offers a new insight into the t-Product and shows that this product is a block convolution of two tensors with periodic boundary conditions. Based on this viewpoint, we propose a new tensor-tensor product called the $\star_c{}\text{-Product}$ based on Block convolution with reflective boundary conditions. Using a tensor framework, this product can be easily extended to tensors of arbitrary order. Additionally, we introduce a tensor decomposition based on our $\star_c{}\text{-Product}$ for arbitrary order tensors. Compared to t-SVD, our new decomposition has lower complexity, and experiments show that it yields higher-quality results in applications such as classification and compression.
</details>
<details>
<summary>摘要</summary>
tensor decompositions是多维数据的分析工具， Besides tensor decompositions like Tucker和CP，tensor SVD（t-SVD），which is based on the t-product of tensors, is another extension of SVD to tensors that has recently been developed and has found numerous applications in analyzing high-dimensional data. This paper offers a new perspective on the t-product and shows that this product is a block convolution of two tensors with periodic boundary conditions. Based on this viewpoint, we propose a new tensor-tensor product called the $\star_c{}\text{-Product}$ based on block convolution with reflective boundary conditions. Using a tensor framework, this product can be easily extended to tensors of arbitrary order. Additionally, we introduce a tensor decomposition based on our $\star_c{}\text{-Product}$ for arbitrary-order tensors. Compared to t-SVD, our new decomposition has lower complexity, and experiments show that it yields higher-quality results in applications such as classification and compression.
</details></li>
</ul>
<hr>
<h2 id="PoissonNet-Resolution-Agnostic-3D-Shape-Reconstruction-using-Fourier-Neural-Operators"><a href="#PoissonNet-Resolution-Agnostic-3D-Shape-Reconstruction-using-Fourier-Neural-Operators" class="headerlink" title="PoissonNet: Resolution-Agnostic 3D Shape Reconstruction using Fourier Neural Operators"></a>PoissonNet: Resolution-Agnostic 3D Shape Reconstruction using Fourier Neural Operators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01766">http://arxiv.org/abs/2308.01766</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arsenal9971/poissonnet">https://github.com/arsenal9971/poissonnet</a></li>
<li>paper_authors: Hector Andrade-Loarca, Julius Hege, Aras Bacho, Gitta Kutyniok</li>
<li>for: 这个论文旨在解决用点云数据 reconstruction 3D  shapes 的问题，传统的深度神经网络在高分辨率下遇到计算复杂性的问题。</li>
<li>methods: 作者使用 fourier neural operator (FNO) 解决波兰方程，从oriented point cloud measurement中重建mesh。</li>
<li>results: 作者的方法在 reconstruction 质量、运行时间和分辨率灵活性方面比现有方法优秀，同时具有一shot super-resolution 和梯度可视化的优点。<details>
<summary>Abstract</summary>
We introduce PoissonNet, an architecture for shape reconstruction that addresses the challenge of recovering 3D shapes from points. Traditional deep neural networks face challenges with common 3D shape discretization techniques due to their computational complexity at higher resolutions. To overcome this, we leverage Fourier Neural Operators (FNOs) to solve the Poisson equation and reconstruct a mesh from oriented point cloud measurements. PoissonNet exhibits two main advantages. First, it enables efficient training on low-resolution data while achieving comparable performance at high-resolution evaluation, thanks to the resolution-agnostic nature of FNOs. This feature allows for one-shot super-resolution. Second, our method surpasses existing approaches in reconstruction quality while being differentiable. Overall, our proposed method not only improves upon the limitations of classical deep neural networks in shape reconstruction but also achieves superior results in terms of reconstruction quality, running time, and resolution flexibility. Furthermore, we demonstrate that the Poisson surface reconstruction problem is well-posed in the limit case by showing a universal approximation theorem for the solution operator of the Poisson equation with distributional data utilizing the Fourier Neural Operator, which provides a theoretical foundation for our numerical results. The code to reproduce the experiments is available on: \url{https://github.com/arsenal9971/PoissonNet}.
</details>
<details>
<summary>摘要</summary>
我们介绍PoissonNet，一个用于形状重建的架构，解决从点 cloud 中获取 3D 形状的挑战。传统的深度神经网络在高分辨率下 computationally 复杂，因此我们利用 Fourier Neural Operators (FNOs) 解决 Poisson 方程，从排序点云集中重建 mesh。PoissonNet 有两个主要优点：第一，它可以高效地在低分辨率上训练，并在高分辨率评估中实现相同的性能，这使得它能够实现一次超Resolution。第二，我们的方法可以超过现有的方法重建质量，并且可以实现可微的变化。总的来说，我们的提案不仅优化了传统的深度神经网络在形状重建中的局限性，而且实现了更好的重建质量、运行时间和分辨率灵活性。此外，我们还证明了 Poisson 面重建问题在极限情况下是可定义的，通过显示了基于 Fourier Neural Operator 的解析函数，则提供了理论基础 для我们的数据�Martin 的实验结果。Code 可以在：\url{https://github.com/arsenal9971/PoissonNet} 中找到。
</details></li>
</ul>
<hr>
<h2 id="NuInsSeg-A-Fully-Annotated-Dataset-for-Nuclei-Instance-Segmentation-in-H-E-Stained-Histological-Images"><a href="#NuInsSeg-A-Fully-Annotated-Dataset-for-Nuclei-Instance-Segmentation-in-H-E-Stained-Histological-Images" class="headerlink" title="NuInsSeg: A Fully Annotated Dataset for Nuclei Instance Segmentation in H&amp;E-Stained Histological Images"></a>NuInsSeg: A Fully Annotated Dataset for Nuclei Instance Segmentation in H&amp;E-Stained Histological Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01760">http://arxiv.org/abs/2308.01760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/masih4/nuinsseg">https://github.com/masih4/nuinsseg</a></li>
<li>paper_authors: Amirreza Mahbod, Christine Polak, Katharina Feldmann, Rumsha Khan, Katharina Gelles, Georg Dorffner, Ramona Woitek, Sepideh Hatamikia, Isabella Ellinger</li>
<li>for: This paper is written for the task of automatic nuclei instance segmentation in whole slide image analysis, specifically using supervised deep learning methods.</li>
<li>methods: The paper uses a fully manually annotated dataset called NuInsSeg, which contains 665 image patches with over 30,000 manually segmented nuclei from 31 human and mouse organs. Additionally, the paper provides ambiguous area masks for the entire dataset, which represent parts of the images where precise manual annotations are impossible.</li>
<li>results: The paper releases one of the biggest fully manually annotated datasets of nuclei in Hematoxylin and Eosin (H&amp;E)-stained histological images, called NuInsSeg, which can be used to train and evaluate supervised deep learning models for nuclei instance segmentation.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为批处理学自动核体实例分割任务而写的，特别是使用监督深度学习方法。</li>
<li>methods: 这篇论文使用了完全手动标注的数据集，名为NuInsSeg，该数据集包含665个图像patch，共有30,000多个手动标注的核体。此外，论文还提供了整个数据集的模糊区域面积，表示图像中的不确定部分，即人工专家无法准确手动标注的部分。</li>
<li>results: 论文发布了一个大量的完全手动标注的核体数据集，名为NuInsSeg，可以用于训练和评估supervised深度学习模型。<details>
<summary>Abstract</summary>
In computational pathology, automatic nuclei instance segmentation plays an essential role in whole slide image analysis. While many computerized approaches have been proposed for this task, supervised deep learning (DL) methods have shown superior segmentation performances compared to classical machine learning and image processing techniques. However, these models need fully annotated datasets for training which is challenging to acquire, especially in the medical domain. In this work, we release one of the biggest fully manually annotated datasets of nuclei in Hematoxylin and Eosin (H&E)-stained histological images, called NuInsSeg. This dataset contains 665 image patches with more than 30,000 manually segmented nuclei from 31 human and mouse organs. Moreover, for the first time, we provide additional ambiguous area masks for the entire dataset. These vague areas represent the parts of the images where precise and deterministic manual annotations are impossible, even for human experts. The dataset and detailed step-by-step instructions to generate related segmentation masks are publicly available at https://www.kaggle.com/datasets/ipateam/nuinsseg and https://github.com/masih4/NuInsSeg, respectively.
</details>
<details>
<summary>摘要</summary>
在计算生物学中，自动核体实例分割扮演着整个扫描图像分析中的关键角色。虽然许多计算机化方法已经被提议用于这项任务，但是supervised深度学习（DL）方法在 segmentation 性能方面表现出色，比起经典机器学习和图像处理技术更为出色。然而，这些模型需要完全标注的数据集进行训练，这在医疗领域是困难的获得的。在这项工作中，我们发布了一个包含665个图像patches，共计超过30,000个手动标注的核体的全部扫描图像数据集，称为NuInsSeg。这个数据集包括31种人类和小鼠的组织。此外，我们还为整个数据集提供了首次的uncertain area masks。这些暧昧区域表示图像中的不确定和不可定量的部分，即even human experts无法 preciselly和准确地手动标注这些部分。数据集和相关的生成分 segmentation masks的详细步骤 instrucions都公开在https://www.kaggle.com/datasets/ipateam/nuinsseg和https://github.com/masih4/NuInsSeg中，分别。
</details></li>
</ul>
<hr>
<h2 id="Neural-Collapse-Terminus-A-Unified-Solution-for-Class-Incremental-Learning-and-Its-Variants"><a href="#Neural-Collapse-Terminus-A-Unified-Solution-for-Class-Incremental-Learning-and-Its-Variants" class="headerlink" title="Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants"></a>Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01746">http://arxiv.org/abs/2308.01746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuralcollapseapplications/unicil">https://github.com/neuralcollapseapplications/unicil</a></li>
<li>paper_authors: Yibo Yang, Haobo Yuan, Xiangtai Li, Jianlong Wu, Lefei Zhang, Zhouchen Lin, Philip Torr, Dacheng Tao, Bernard Ghanem</li>
<li>for:  Handle class incremental learning (CIL), long-tail class incremental learning (LTCIL), and few-shot class incremental learning (FSCIL) well.</li>
<li>methods: Propose a unified solution called neural collapse terminus, which is a fixed structure with the maximal equiangular inter-class separation for the whole label space. Also, propose a prototype evolving scheme to drive the backbone features into the neural collapse terminus smoothly.</li>
<li>results: The method is effective in all three tasks and can handle data imbalance and data scarcity. Theoretical analysis indicates that the method holds the neural collapse optimality in an incremental fashion. Extensive experiments with multiple datasets demonstrate the effectiveness of the unified solution and the generalized case.<details>
<summary>Abstract</summary>
How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning. Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting. Existing methods are specifically proposed for one of the three tasks. In this paper, we offer a unified solution to the misalignment dilemma in the three tasks. Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space. It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally. For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly. Our method also works for FSCIL with only minor adaptations. Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity. We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method. Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case.
</details>
<details>
<summary>摘要</summary>
如何在新类增加时保持老类能力已成为增量学习中的关键挑战。此外，长尾类增量学习和少shot类增量学习也被提出来考虑数据偏好和数据稀缺问题，这些问题在实际应用中非常普遍并使得已知的忘记问题更加严重。现有的方法只适用于一种任务。在这篇论文中，我们提出了增量训练中的不一致问题的统一解决方案。具体来说，我们提出了一种固定结构的神经衰减终点，该结构具有整个标签空间中最大的等角间隔性。它在增量训练中作为一个固定目标，以避免在增量训练中逐渐将特征空间分割。对CIL和LTCIL，我们还提出了一种原型演化方案，以使得脊梁特征流动到我们的神经衰减终点的。我们的方法也适用于FSCIL，只需要一些小的适应。理论分析表明，我们的方法在增量训练中具有神经衰减优化的优点，不管数据不平衡或数据稀缺。我们还设计了一个通用情况，在每个来往会训练中，不知道总类数量和数据分布是正常、长尾或少shot，以测试我们的方法的普适性。我们进行了多个数据集的广泛实验，以证明我们的统一解决方案对所有三个任务和通用情况具有效果。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Visibility-in-Nighttime-Haze-Images-Using-Guided-APSF-and-Gradient-Adaptive-Convolution"><a href="#Enhancing-Visibility-in-Nighttime-Haze-Images-Using-Guided-APSF-and-Gradient-Adaptive-Convolution" class="headerlink" title="Enhancing Visibility in Nighttime Haze Images Using Guided APSF and Gradient Adaptive Convolution"></a>Enhancing Visibility in Nighttime Haze Images Using Guided APSF and Gradient Adaptive Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01738">http://arxiv.org/abs/2308.01738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinyeying/nighttime_dehaze">https://github.com/jinyeying/nighttime_dehaze</a></li>
<li>paper_authors: Yeying Jin, Beibei Lin, Wending Yan, Wei Ye, Yuan Yuan, Robby T. Tan</li>
<li>for: 提高夜间雾景的可见度，处理亮光和抑制雾气的影响。</li>
<li>methods: 利用灯源意识网络检测夜间图像中的灯光源，然后使用APSF指导的灯光渲染，以抑制雾光效果。同时，使用梯度适应卷积，捕捉雾景中的边缘和текстуures，以提高场景的对比度。最后，通过学习注意力映射，调整gamma修正，以增强低光强度区域的明暗对比。</li>
<li>results: 对实际夜间雾景图像进行了广泛的评估，并达到了30.38dB PSNR，比前方法提高13%。数据和代码可以在：\url{<a target="_blank" rel="noopener" href="https://github.com/jinyeying/nighttime_dehaze%7D%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/jinyeying/nighttime_dehaze}中找到。</a><details>
<summary>Abstract</summary>
Visibility in hazy nighttime scenes is frequently reduced by multiple factors, including low light, intense glow, light scattering, and the presence of multicolored light sources. Existing nighttime dehazing methods often struggle with handling glow or low-light conditions, resulting in either excessively dark visuals or unsuppressed glow outputs. In this paper, we enhance the visibility from a single nighttime haze image by suppressing glow and enhancing low-light regions. To handle glow effects, our framework learns from the rendered glow pairs. Specifically, a light source aware network is proposed to detect light sources of night images, followed by the APSF (Angular Point Spread Function)-guided glow rendering. Our framework is then trained on the rendered images, resulting in glow suppression. Moreover, we utilize gradient-adaptive convolution, to capture edges and textures in hazy scenes. By leveraging extracted edges and textures, we enhance the contrast of the scene without losing important structural details. To boost low-light intensity, our network learns an attention map, then adjusted by gamma correction. This attention has high values on low-light regions and low values on haze and glow regions. Extensive evaluation on real nighttime haze images, demonstrates the effectiveness of our method. Our experiments demonstrate that our method achieves a PSNR of 30.38dB, outperforming state-of-the-art methods by 13$\%$ on GTA5 nighttime haze dataset. Our data and code is available at: \url{https://github.com/jinyeying/nighttime_dehaze}.
</details>
<details>
<summary>摘要</summary>
夜间雾气场景中的可见度受多种因素影响，包括低光照、强烈辉光、光散射和多种颜色光源的存在。现有的夜间雾气去除方法 часто难以处理辉光效果，导致视觉效果过扭或辉光输出不充分抑制。在这篇论文中，我们通过抑制辉光和强化低光照区域来提高夜间雾气图像的可见度。为了处理辉光效果，我们的框架学习了夜间镜头中的灯光对。具体来说，我们提出了一个灯光意识网络，用于夜间镜头中灯光源的检测，然后使用APSF（ Ángular Point Spread Function）引导的辉光渲染。我们的框架然后在渲染图像上进行训练，从而实现辉光抑制。此外，我们利用梯度适应 convolution，以捕捉雾气场景中的边缘和文本ure。通过利用EXTRACTED edges和文本ure，我们可以提高场景的对比度，而不是失去重要的结构细节。为了增强低光照INTENSITY，我们的网络学习了注意力图，然后通过γcorrecting进行调整。这个注意力图在低光照区域有高值，而在雾气和辉光区域有低值。我们的实验表明，我们的方法可以在实际的夜间雾气图像上达到PSNR 30.38dB，比 estado-of-the-art 方法高出13%的GTA5夜间雾气数据集。我们的数据和代码可以在以下链接获取：https://github.com/jinyeying/nighttime_dehaze。
</details></li>
</ul>
<hr>
<h2 id="Quantification-of-Predictive-Uncertainty-via-Inference-Time-Sampling"><a href="#Quantification-of-Predictive-Uncertainty-via-Inference-Time-Sampling" class="headerlink" title="Quantification of Predictive Uncertainty via Inference-Time Sampling"></a>Quantification of Predictive Uncertainty via Inference-Time Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01731">http://arxiv.org/abs/2308.01731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katarína Tóthová, Ľubor Ladický, Daniel Thul, Marc Pollefeys, Ender Konukoglu</li>
<li>for: 这项研究的目的是提出一种post-hoc采样策略来估计预测不确定性，以考虑数据歧义导致的预测变化。</li>
<li>methods: 该方法不需要特定的建模Component或训练机制，可以应用于任何饱和推动网络，无需变更网络结构或训练过程。</li>
<li>results: 实验表明，该方法可以生成多种可能性 Distribution，与预测错误之间存在良好的相关性。<details>
<summary>Abstract</summary>
Predictive variability due to data ambiguities has typically been addressed via construction of dedicated models with built-in probabilistic capabilities that are trained to predict uncertainty estimates as variables of interest. These approaches require distinct architectural components and training mechanisms, may include restrictive assumptions and exhibit overconfidence, i.e., high confidence in imprecise predictions. In this work, we propose a post-hoc sampling strategy for estimating predictive uncertainty accounting for data ambiguity. The method can generate different plausible outputs for a given input and does not assume parametric forms of predictive distributions. It is architecture agnostic and can be applied to any feed-forward deterministic network without changes to the architecture or training procedure. Experiments on regression tasks on imaging and non-imaging input data show the method's ability to generate diverse and multi-modal predictive distributions, and a desirable correlation of the estimated uncertainty with the prediction error.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>通常，预测变化因数据抽象性而导致的预测不确定性通过建立专门的模型，这些模型具有内置的概率能力，并在预测不确定性为变量首选项进行训练。这些方法可能需要特殊的建筑Component和训练机制，可能包含限制性的假设和显示过自信，即高度自信准确性。在这种工作中，我们提出了一种 posterior sampling 策略，用于估计预测不确定性，考虑到数据抽象性。这种方法可以生成不同的可能的输出，并不假设预测分布的 Parametric 形式。它是架构无关的，可以应用于任何滤频决策网络，无需改变架构或训练过程。实验表明，这种方法可以生成多样化和多模态的预测分布，并且预测不确定性与预测错误之间存在可undesirable的相关性。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-3D-Instance-Segmentation-without-Instance-level-Annotations"><a href="#Weakly-Supervised-3D-Instance-Segmentation-without-Instance-level-Annotations" class="headerlink" title="Weakly Supervised 3D Instance Segmentation without Instance-level Annotations"></a>Weakly Supervised 3D Instance Segmentation without Instance-level Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01721">http://arxiv.org/abs/2308.01721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shichao Dong, Guosheng Lin</li>
<li>for: 提高3D semanticScene理解任务的效率，减少人工标注成本。</li>
<li>methods: 提出首个弱级标注的3D实例分割方法，只需要分类semantic标签作为监督，不需要实例级标注。</li>
<li>results: 实验表明，我们的方法可以与最新的完全监督方法相当，同时可以帮助现有方法在减少标注成本的情况下学习3D实例分割。<details>
<summary>Abstract</summary>
3D semantic scene understanding tasks have achieved great success with the emergence of deep learning, but often require a huge amount of manually annotated training data. To alleviate the annotation cost, we propose the first weakly-supervised 3D instance segmentation method that only requires categorical semantic labels as supervision, and we do not need instance-level labels. The required semantic annotations can be either dense or extreme sparse (e.g. 0.02% of total points). Even without having any instance-related ground-truth, we design an approach to break point clouds into raw fragments and find the most confident samples for learning instance centroids. Furthermore, we construct a recomposed dataset using pseudo instances, which is used to learn our defined multilevel shape-aware objectness signal. An asymmetrical object inference algorithm is followed to process core points and boundary points with different strategies, and generate high-quality pseudo instance labels to guide iterative training. Experiments demonstrate that our method can achieve comparable results with recent fully supervised methods. By generating pseudo instance labels from categorical semantic labels, our designed approach can also assist existing methods for learning 3D instance segmentation at reduced annotation cost.
</details>
<details>
<summary>摘要</summary>
三维semantic场景理解任务在深度学习出现后取得了很大成功，但经常需要大量手动标注训练数据。为了减轻标注成本，我们提出了首个无监督的3D实例分割方法，只需要类别semantic标签作为监督，并不需要实例级别标签。需要的semantic标注可以是密集的或者极少的（例如0.02%的总点数）。即使没有实例相关的地面真实数据，我们还是可以将点云分解成原始碎片，并从最信任的样本中学习实例中心点。此外，我们还构建了一个pseudo实例集合，用于学习我们定义的多级形状感知信号。我们采用不对称的物体推断算法，处理核心点和边点的不同策略，生成高质量pseudo实例标签，以导引反复训练。实验表明，我们的方法可以与最近的完全监督方法相当。通过将pseudo实例标签生成自类别semantic标签，我们设计的方法还可以帮助现有的方法在减少标注成本的情况下学习3D实例分割。
</details></li>
</ul>
<hr>
<h2 id="Balanced-Destruction-Reconstruction-Dynamics-for-Memory-replay-Class-Incremental-Learning"><a href="#Balanced-Destruction-Reconstruction-Dynamics-for-Memory-replay-Class-Incremental-Learning" class="headerlink" title="Balanced Destruction-Reconstruction Dynamics for Memory-replay Class Incremental Learning"></a>Balanced Destruction-Reconstruction Dynamics for Memory-replay Class Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01698">http://arxiv.org/abs/2308.01698</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zyuh/bdr-main">https://github.com/zyuh/bdr-main</a></li>
<li>paper_authors: Yuhang Zhou, Jiangchao Yao, Feng Hong, Ya Zhang, Yanfeng Wang</li>
<li>For: 提高类增量学习（CIL）中的稳定性和泛化能力，通过平衡旧知识的destruction和重建来alleviate catastrophic forgetting。* Methods: 提出了一种Balanced Destruction-Reconstruction（BDR）模块，通过考虑不同类的训练状态的差异和存储库中样本的量不均衡来平衡旧知识的destruction和重建，从而提高知识重建的效果。* Results: 经验表明，作为轻量级插件，BDR模块可以大幅提高现有最佳方法的性能，并且具有良好的泛化能力。<details>
<summary>Abstract</summary>
Class incremental learning (CIL) aims to incrementally update a trained model with the new classes of samples (plasticity) while retaining previously learned ability (stability). To address the most challenging issue in this goal, i.e., catastrophic forgetting, the mainstream paradigm is memory-replay CIL, which consolidates old knowledge by replaying a small number of old classes of samples saved in the memory. Despite effectiveness, the inherent destruction-reconstruction dynamics in memory-replay CIL are an intrinsic limitation: if the old knowledge is severely destructed, it will be quite hard to reconstruct the lossless counterpart. Our theoretical analysis shows that the destruction of old knowledge can be effectively alleviated by balancing the contribution of samples from the current phase and those saved in the memory. Motivated by this theoretical finding, we propose a novel Balanced Destruction-Reconstruction module (BDR) for memory-replay CIL, which can achieve better knowledge reconstruction by reducing the degree of maximal destruction of old knowledge. Specifically, to achieve a better balance between old knowledge and new classes, the proposed BDR module takes into account two factors: the variance in training status across different classes and the quantity imbalance of samples from the current phase and memory. By dynamically manipulating the gradient during training based on these factors, BDR can effectively alleviate knowledge destruction and improve knowledge reconstruction. Extensive experiments on a range of CIL benchmarks have shown that as a lightweight plug-and-play module, BDR can significantly improve the performance of existing state-of-the-art methods with good generalization.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="BEVControl-Accurately-Controlling-Street-view-Elements-with-Multi-perspective-Consistency-via-BEV-Sketch-Layout"><a href="#BEVControl-Accurately-Controlling-Street-view-Elements-with-Multi-perspective-Consistency-via-BEV-Sketch-Layout" class="headerlink" title="BEVControl: Accurately Controlling Street-view Elements with Multi-perspective Consistency via BEV Sketch Layout"></a>BEVControl: Accurately Controlling Street-view Elements with Multi-perspective Consistency via BEV Sketch Layout</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01661">http://arxiv.org/abs/2308.01661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kairui Yang, Enhui Ma, Jibin Peng, Qing Guo, Di Lin, Kaicheng Yu</li>
<li>for: 提高计算机视觉系统中的识别模型性能，使用生成图像来增强模型的表现。</li>
<li>methods: 提出了一种两stage生成方法，名为BEVControl，可以生成准确的前景和背景内容。此外，还支持绘制风格输入，让人们更方便地编辑。</li>
<li>results: 对比BEVGen方法，BEVControl在前景分割mIoU中提高了5.89到26.80的margin，而且用生成图像来训练下游识别模型，其NDS分数平均提高1.29。<details>
<summary>Abstract</summary>
Using synthesized images to boost the performance of perception models is a long-standing research challenge in computer vision. It becomes more eminent in visual-centric autonomous driving systems with multi-view cameras as some long-tail scenarios can never be collected. Guided by the BEV segmentation layouts, the existing generative networks seem to synthesize photo-realistic street-view images when evaluated solely on scene-level metrics. However, once zoom-in, they usually fail to produce accurate foreground and background details such as heading. To this end, we propose a two-stage generative method, dubbed BEVControl, that can generate accurate foreground and background contents. In contrast to segmentation-like input, it also supports sketch style input, which is more flexible for humans to edit. In addition, we propose a comprehensive multi-level evaluation protocol to fairly compare the quality of the generated scene, foreground object, and background geometry. Our extensive experiments show that our BEVControl surpasses the state-of-the-art method, BEVGen, by a significant margin, from 5.89 to 26.80 on foreground segmentation mIoU. In addition, we show that using images generated by BEVControl to train the downstream perception model, it achieves on average 1.29 improvement in NDS score.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DiffColor-Toward-High-Fidelity-Text-Guided-Image-Colorization-with-Diffusion-Models"><a href="#DiffColor-Toward-High-Fidelity-Text-Guided-Image-Colorization-with-Diffusion-Models" class="headerlink" title="DiffColor: Toward High Fidelity Text-Guided Image Colorization with Diffusion Models"></a>DiffColor: Toward High Fidelity Text-Guided Image Colorization with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01655">http://arxiv.org/abs/2308.01655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianxin Lin, Peng Xiao, Yijun Wang, Rongju Zhang, Xiangxiang Zeng</li>
<li>for: 提高自动或参照基于的图像颜色化精度和多样性，尤其是对象级颜色控制。</li>
<li>methods: 基于预训练扩散模型，提出一种名为DiffColor的新方法，通过使用提前训练的文本到图像模型，生成基于文本提示的颜色化图像，不需任何其他输入。DiffColor方法包括两个阶段：颜色化与生成颜色先前，以及在文本引导下可控色化。</li>
<li>results: DiffColor方法可以在几轮 iterations 中生成真实和多样的颜色，保持图像结构和背景不变，同时将颜色与目标语言指导相吻合。此外，DiffColor方法允许在文本引导下进行卷积控制，即通过修改提示文本来生成不同的颜色化结果，而无需任何 fine-tuning。广泛的实验和用户研究表明，DiffColor方法在视觉质量、颜色准确性和颜色化选项多样性方面，超越了先前的works。<details>
<summary>Abstract</summary>
Recent data-driven image colorization methods have enabled automatic or reference-based colorization, while still suffering from unsatisfactory and inaccurate object-level color control. To address these issues, we propose a new method called DiffColor that leverages the power of pre-trained diffusion models to recover vivid colors conditioned on a prompt text, without any additional inputs. DiffColor mainly contains two stages: colorization with generative color prior and in-context controllable colorization. Specifically, we first fine-tune a pre-trained text-to-image model to generate colorized images using a CLIP-based contrastive loss. Then we try to obtain an optimized text embedding aligning the colorized image and the text prompt, and a fine-tuned diffusion model enabling high-quality image reconstruction. Our method can produce vivid and diverse colors with a few iterations, and keep the structure and background intact while having colors well-aligned with the target language guidance. Moreover, our method allows for in-context colorization, i.e., producing different colorization results by modifying prompt texts without any fine-tuning, and can achieve object-level controllable colorization results. Extensive experiments and user studies demonstrate that DiffColor outperforms previous works in terms of visual quality, color fidelity, and diversity of colorization options.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-scale-Cross-restoration-Framework-for-Electrocardiogram-Anomaly-Detection"><a href="#Multi-scale-Cross-restoration-Framework-for-Electrocardiogram-Anomaly-Detection" class="headerlink" title="Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection"></a>Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01639">http://arxiv.org/abs/2308.01639</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mediabrain-sjtu/ecgad">https://github.com/mediabrain-sjtu/ecgad</a></li>
<li>paper_authors: Aofan Jiang, Chaoqin Huang, Qing Cao, Shuang Wu, Zi Zeng, Kang Chen, Ya Zhang, Yanfeng Wang</li>
<li>for: 该论文旨在提高电cardiogram（ECG）诊断工具的敏感度，以检测心脏疾病。</li>
<li>methods: 该论文提出了一种基于异常检测的ECG anomaly detection和本地化方法，通过对全息ECG和心跳级别特征进行多级混合还原，以提高检测异常的精度。</li>
<li>results: 该论文在一个新的 benchmark 数据集上达到了当前领域的状态的表现，并在两个其他常用的ECG数据集上也显示出了优秀的表现。<details>
<summary>Abstract</summary>
Electrocardiogram (ECG) is a widely used diagnostic tool for detecting heart conditions. Rare cardiac diseases may be underdiagnosed using traditional ECG analysis, considering that no training dataset can exhaust all possible cardiac disorders. This paper proposes using anomaly detection to identify any unhealthy status, with normal ECGs solely for training. However, detecting anomalies in ECG can be challenging due to significant inter-individual differences and anomalies present in both global rhythm and local morphology. To address this challenge, this paper introduces a novel multi-scale cross-restoration framework for ECG anomaly detection and localization that considers both local and global ECG characteristics. The proposed framework employs a two-branch autoencoder to facilitate multi-scale feature learning through a masking and restoration process, with one branch focusing on global features from the entire ECG and the other on local features from heartbeat-level details, mimicking the diagnostic process of cardiologists. Anomalies are identified by their high restoration errors. To evaluate the performance on a large number of individuals, this paper introduces a new challenging benchmark with signal point-level ground truths annotated by experienced cardiologists. The proposed method demonstrates state-of-the-art performance on this benchmark and two other well-known ECG datasets. The benchmark dataset and source code are available at: \url{https://github.com/MediaBrain-SJTU/ECGAD}
</details>
<details>
<summary>摘要</summary>
电心agram（ECG）是一种广泛使用的诊断工具，用于检测心脏疾病。但是，有些罕见的心脏疾病可能会被传统的ECG分析错过，因为没有一个可以包含所有可能的心脏疾病的训练数据集。这篇论文提出使用异常检测来识别任何不健康状态，只使用正常的ECG进行训练。然而，检测ECG中的异常可以是困难的，因为心脏电压的变化会导致巨大的个体差异和异常现象。为解决这个挑战，这篇论文提出了一种新的多尺度跨 restore 框架，用于ECG异常检测和定位。该框架利用两个分支自动编码器来实现多尺度特征学习，其中一个分支关注整个ECG的全局特征，另一个分支关注心跳级别细节。异常被标识为高 restore 错误。为评估性能，这篇论文创建了一个新的挑战性的标准数据集，其中每个信号点都有经验论断医生的地面真实值。提出的方法在这个标准数据集上达到了状态艺术性的性能，并在两个常见的ECG数据集上也取得了优秀的成绩。标准数据集和源代码可以在：\url{https://github.com/MediaBrain-SJTU/ECGAD} 获取。
</details></li>
</ul>
<hr>
<h2 id="Disentangling-Multi-view-Representations-Beyond-Inductive-Bias"><a href="#Disentangling-Multi-view-Representations-Beyond-Inductive-Bias" class="headerlink" title="Disentangling Multi-view Representations Beyond Inductive Bias"></a>Disentangling Multi-view Representations Beyond Inductive Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01634">http://arxiv.org/abs/2308.01634</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanzhou-ke/dmrib">https://github.com/guanzhou-ke/dmrib</a></li>
<li>paper_authors: Guanzhou Ke, Yang Yu, Guoqing Chao, Xiaoli Wang, Chenyang Xu, Shengfeng He</li>
<li>For: The paper is written for proposing a novel multi-view representation disentangling method that can go beyond inductive biases and ensure both interpretability and generalizability of the resulting representations.* Methods: The proposed method is based on discovering multi-view consistency in advance, which determines the disentangling information boundary, and maximizing transformation invariance and clustering consistency between views. The method consists of two stages: obtaining multi-view consistency by training a consistent encoder, and disentangling specificity from comprehensive representations by minimizing the upper bound of mutual information.* Results: The proposed method outperforms 12 comparison methods in terms of clustering and classification performance on four multi-view datasets, and the extracted consistency and specificity are compact and interpretable.<details>
<summary>Abstract</summary>
Multi-view (or -modality) representation learning aims to understand the relationships between different view representations. Existing methods disentangle multi-view representations into consistent and view-specific representations by introducing strong inductive biases, which can limit their generalization ability. In this paper, we propose a novel multi-view representation disentangling method that aims to go beyond inductive biases, ensuring both interpretability and generalizability of the resulting representations. Our method is based on the observation that discovering multi-view consistency in advance can determine the disentangling information boundary, leading to a decoupled learning objective. We also found that the consistency can be easily extracted by maximizing the transformation invariance and clustering consistency between views. These observations drive us to propose a two-stage framework. In the first stage, we obtain multi-view consistency by training a consistent encoder to produce semantically-consistent representations across views as well as their corresponding pseudo-labels. In the second stage, we disentangle specificity from comprehensive representations by minimizing the upper bound of mutual information between consistent and comprehensive representations. Finally, we reconstruct the original data by concatenating pseudo-labels and view-specific representations. Our experiments on four multi-view datasets demonstrate that our proposed method outperforms 12 comparison methods in terms of clustering and classification performance. The visualization results also show that the extracted consistency and specificity are compact and interpretable. Our code can be found at \url{https://github.com/Guanzhou-Ke/DMRIB}.
</details>
<details>
<summary>摘要</summary>
多视图（或多modal）表示学习目标是理解不同视图表示之间的关系。现有方法通过引入强大的概念假设来分离多视图表示，但这可能会限制其泛化能力。在这篇论文中，我们提出了一种新的多视图表示分离方法，旨在超越假设，以确保表示的解释性和泛化性。我们的方法基于发现多视图一致性在前提下可以确定分离信息边界，从而导致一个分离学习目标。我们还发现可以通过最大化变换不变性和视图集成一致性来提取一致性。这些发现驱动我们提出了一个两stage框架。在第一阶段，我们通过训练一个具有相同含义的编码器来生成多视图中的含义相同的表示，以及其相对应的pseudo标签。在第二阶段，我们通过最小化表示之间的上界乘积来分离特定的表示和总体表示之间的相互信息。最后，我们使用pseudo标签和视图特定表示来重建原始数据。我们的实验表明，我们的提出的方法在四个多视图数据集上比12种参考方法表现出色，并且可以准确地重建原始数据。visual化结果还表明提取的一致性和特定性具有 компакт性和可读性。我们的代码可以在GitHub上找到：\url{https://github.com/Guanzhou-Ke/DMRIB}。
</details></li>
</ul>
<hr>
<h2 id="Erasure-based-Interaction-Network-for-RGBT-Video-Object-Detection-and-A-Unified-Benchmark"><a href="#Erasure-based-Interaction-Network-for-RGBT-Video-Object-Detection-and-A-Unified-Benchmark" class="headerlink" title="Erasure-based Interaction Network for RGBT Video Object Detection and A Unified Benchmark"></a>Erasure-based Interaction Network for RGBT Video Object Detection and A Unified Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01630">http://arxiv.org/abs/2308.01630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengzheng Tu, Qishun Wang, Hongshun Wang, Kunpeng Wang, Chenglong Li</li>
<li>for: 提高视频对象检测（VOD）性能在不利照条件下，通过引入热模态，抗衰落和降低计算复杂度。</li>
<li>methods: 提出了一种新的计算机视IONTask called RGB-thermal（RGBT）VOD，并设计了一个名为EINet的新网络模型，以及一个包含50对复杂背景、多种物体和不同照明条件的VT-VOD50数据集。</li>
<li>results: 对VT-VOD50数据集进行了广泛的实验，证明了我们提posed方法的效果和效率，并且与现有主流VOD方法进行了比较。<details>
<summary>Abstract</summary>
Recently, many breakthroughs are made in the field of Video Object Detection (VOD), but the performance is still limited due to the imaging limitations of RGB sensors in adverse illumination conditions. To alleviate this issue, this work introduces a new computer vision task called RGB-thermal (RGBT) VOD by introducing the thermal modality that is insensitive to adverse illumination conditions. To promote the research and development of RGBT VOD, we design a novel Erasure-based Interaction Network (EINet) and establish a comprehensive benchmark dataset (VT-VOD50) for this task. Traditional VOD methods often leverage temporal information by using many auxiliary frames, and thus have large computational burden. Considering that thermal images exhibit less noise than RGB ones, we develop a negative activation function that is used to erase the noise of RGB features with the help of thermal image features. Furthermore, with the benefits from thermal images, we rely only on a small temporal window to model the spatio-temporal information to greatly improve efficiency while maintaining detection accuracy.   VT-VOD50 dataset consists of 50 pairs of challenging RGBT video sequences with complex backgrounds, various objects and different illuminations, which are collected in real traffic scenarios. Extensive experiments on VT-VOD50 dataset demonstrate the effectiveness and efficiency of our proposed method against existing mainstream VOD methods. The code of EINet and the dataset will be released to the public for free academic usage.
</details>
<details>
<summary>摘要</summary>
近些时间，在视频对象检测（VOD）领域内，有很多突破性的进展，但性能仍然受到RGB感知器的不利照明条件的限制。为了解决这个问题，这项工作引入了一个新的计算机视觉任务，即RGB-热（RGBT）VOD，通过引入热特征来减少不利照明条件的影响。为促进RGBT VOD的研究和开发，我们设计了一种新的擦除基本网络（EINet）和建立了一个完整的benchmark数据集（VT-VOD50）。传统的VOD方法通常利用多个auxiliary帧的时间信息，因此具有大的计算负担。由于热图像比RGB图像具有更少的噪声，我们开发了一种负活动函数，用于擦除RGB特征图像中的噪声，并且利用热图像特征来减少计算负担。此外，通过利用热图像的优点，我们只需要使用小的时间窗口来模型空间-时间信息，以提高效率而无需牺牲检测精度。VT-VOD50数据集包含50对复杂背景、多种物体和不同照明条件的RGBT视频序列，通过实际的交通enario进行收集。我们在VT-VOD50数据集上进行了广泛的实验，证明了我们提出的方法在现有主流VOD方法的比较中表现出色，同时具有高效率。我们将EINet和数据集发布到公共平台，免费用于学术研究。
</details></li>
</ul>
<hr>
<h2 id="A-Multidimensional-Analysis-of-Social-Biases-in-Vision-Transformers"><a href="#A-Multidimensional-Analysis-of-Social-Biases-in-Vision-Transformers" class="headerlink" title="A Multidimensional Analysis of Social Biases in Vision Transformers"></a>A Multidimensional Analysis of Social Biases in Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01948">http://arxiv.org/abs/2308.01948</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jannik-brinkmann/social-biases-in-vision-transformers">https://github.com/jannik-brinkmann/social-biases-in-vision-transformers</a></li>
<li>paper_authors: Jannik Brinkmann, Paul Swoboda, Christian Bartelt</li>
<li>for: 研究卷积Transformers（ViT）中存在的社会偏见。</li>
<li>methods: 测试数据、模型架构和训练目标对ViT中学习的表示中的社会偏见的影响。</li>
<li>results: 使用对 diffusion-based image editing进行 counterfactual augmentation 训练可以减少社会偏见，但不能完全消除其他偏见。大型模型比小型模型更少偏见，使用激发jective objectives 训练的模型也比使用生成jective objectives 训练的模型更少偏见。同一个数据集上使用不同的自然语言目标可能导致ViT中学习的社会偏见发生相反的偏见。这些发现可以帮助我们更好地理解社会偏见的起源，并提供改进公平性的方法。<details>
<summary>Abstract</summary>
The embedding spaces of image models have been shown to encode a range of social biases such as racism and sexism. Here, we investigate specific factors that contribute to the emergence of these biases in Vision Transformers (ViT). Therefore, we measure the impact of training data, model architecture, and training objectives on social biases in the learned representations of ViTs. Our findings indicate that counterfactual augmentation training using diffusion-based image editing can mitigate biases, but does not eliminate them. Moreover, we find that larger models are less biased than smaller models, and that models trained using discriminative objectives are less biased than those trained using generative objectives. In addition, we observe inconsistencies in the learned social biases. To our surprise, ViTs can exhibit opposite biases when trained on the same data set using different self-supervised objectives. Our findings give insights into the factors that contribute to the emergence of social biases and suggests that we could achieve substantial fairness improvements based on model design choices.
</details>
<details>
<summary>摘要</summary>
“图像模型的嵌入空间已经显示出许多社会偏见，如种族主义和性别歧视。在这里，我们调查了视Transformer（ViT）中这些偏见的起源。因此，我们测量了训练数据、模型结构和训练目标对图像模型学习的社会偏见的影响。我们的发现表明，通过对 diffusion-based image editing 进行 counterfactual augmentation 训练可以减轻偏见，但并不能完全消除它们。此外，我们发现大型模型比小型模型更少表现社会偏见，并且使用推导性目标进行训练的模型比使用生成性目标进行训练的模型更少表现社会偏见。此外，我们发现图像模型学习的社会偏见存在不一致性。对于同一个数据集，使用不同的自然语言目标可以使图像模型表现出相反的偏见。我们的发现可以帮助我们更好地理解社会偏见的起源，并且表明我们可以通过模型设计选择来实现显著的公平性改进。”
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Convolutional-Neural-Network-Architecture-with-a-Continuous-Symmetry"><a href="#A-Novel-Convolutional-Neural-Network-Architecture-with-a-Continuous-Symmetry" class="headerlink" title="A Novel Convolutional Neural Network Architecture with a Continuous Symmetry"></a>A Novel Convolutional Neural Network Architecture with a Continuous Symmetry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01621">http://arxiv.org/abs/2308.01621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuyao12/ConvNets-PDE-perspective">https://github.com/liuyao12/ConvNets-PDE-perspective</a></li>
<li>paper_authors: Yao Liu, Hang Shao, Bing Bai</li>
<li>for: 这篇论文探讨了一种基于偏微分方程（PDE）的卷积神经网络架构（ConvNet），并实现了这种架构在图像识别任务上的比较性表现。</li>
<li>methods: 这篇论文使用了一种具有组合性的卷积神经网络架构，并运用了一种称为“对称性”的概念，允许权重的调整via一个连续的群集。</li>
<li>results: 这篇论文的结果显示，这种卷积神经网络架构可以在图像识别任务上实现比较性的表现，并且具有一定的内部对称性。<details>
<summary>Abstract</summary>
This paper introduces a new Convolutional Neural Network (ConvNet) architecture inspired by a class of partial differential equations (PDEs) called quasi-linear hyperbolic systems. With comparable performance on the image classification task, it allows for the modification of the weights via a continuous group of symmetry. This is a significant shift from traditional models where the architecture and weights are essentially fixed. We wish to promote the (internal) symmetry as a new desirable property for a neural network, and to draw attention to the PDE perspective in analyzing and interpreting ConvNets in the broader Deep Learning community.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation note: "quasi-linear hyperbolic systems" is translated as "幂线抽象系统", and "ConvNet" is translated as "卷积神经网络".)
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Deep-Learning-based-Spatio-temporal-Action-Detection"><a href="#A-Survey-on-Deep-Learning-based-Spatio-temporal-Action-Detection" class="headerlink" title="A Survey on Deep Learning-based Spatio-temporal Action Detection"></a>A Survey on Deep Learning-based Spatio-temporal Action Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01618">http://arxiv.org/abs/2308.01618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wang, Fanwei Zeng, Yuntao Qian</li>
<li>for: 本研究概述了深度学习方法在视觉中的动作检测和定位问题，包括动作检测、动作识别和动作位置定位等方面。</li>
<li>methods: 本文提出了一种分类和组织深度学习方法的稠密概念框架，并详细介绍了链接算法，以将帧或剪辑级别的检测结果相互链接成为动作管道。</li>
<li>results: 本文对当前领域的深度学习方法进行了全面的回顾，并对常用的测试数据集和评价指标进行了介绍。最后，本文结束并提出了一些可能的未来研究方向。<details>
<summary>Abstract</summary>
Spatio-temporal action detection (STAD) aims to classify the actions present in a video and localize them in space and time. It has become a particularly active area of research in computer vision because of its explosively emerging real-world applications, such as autonomous driving, visual surveillance, entertainment, etc. Many efforts have been devoted in recent years to building a robust and effective framework for STAD. This paper provides a comprehensive review of the state-of-the-art deep learning-based methods for STAD. Firstly, a taxonomy is developed to organize these methods. Next, the linking algorithms, which aim to associate the frame- or clip-level detection results together to form action tubes, are reviewed. Then, the commonly used benchmark datasets and evaluation metrics are introduced, and the performance of state-of-the-art models is compared. At last, this paper is concluded, and a set of potential research directions of STAD are discussed.
</details>
<details>
<summary>摘要</summary>
空间时间动作检测（STAD）目标是在视频中分类并地理化动作的存在。它在计算机视觉领域已经成为非常活跃的研究领域，因为它在自动驾驶、视觉监测、娱乐等实际应用中具有爆炸性突出来的应用前景。多年来，许多努力投入于建立一个可靠有效的STAD框架。本文提供了深度学习基础的state-of-the-art方法的完整回顾。首先，一个分类器是开发出一个分类器，以便组织这些方法。接下来，链接算法，它们的目标是将帧或clip级别的检测结果相互链接，以形成动作管道，被评估。然后，通用的标准数据集和评估指标被介绍，并将现状的状态模型的性能比较。最后，本文结束，并对STAD的未来研究方向进行了讨论。
</details></li>
</ul>
<hr>
<h2 id="Real-time-Light-Estimation-and-Neural-Soft-Shadows-for-AR-Indoor-Scenarios"><a href="#Real-time-Light-Estimation-and-Neural-Soft-Shadows-for-AR-Indoor-Scenarios" class="headerlink" title="Real-time Light Estimation and Neural Soft Shadows for AR Indoor Scenarios"></a>Real-time Light Estimation and Neural Soft Shadows for AR Indoor Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01613">http://arxiv.org/abs/2308.01613</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Sommer, Ulrich Schwanecke, Elmar Schömer</li>
<li>for: 这个论文旨在提供一种用于实时AR应用程序中真实嵌入虚拟对象的渲染管道。</li>
<li>methods: 该管道包括两个主要组成部分：一个深度神经网络基于的光估计和一个神经软阴影生成器。光估计根据深度神经网络来确定主要光向、光色、 ambient色和阴影Texture中的透明度参数。软阴影方法将对象基于的真实软阴影编码为光向依赖的Texture。</li>
<li>results: 我们的管道可以在实时AR场景中新一个水平的真实性来插入对象。我们的模型够小以跑在当前的移动设备上。我们在iPhone 11 Pro上达到了9ms的光估计时间和5ms的神经软阴影时间。<details>
<summary>Abstract</summary>
We present a pipeline for realistic embedding of virtual objects into footage of indoor scenes with focus on real-time AR applications. Our pipeline consists of two main components: A light estimator and a neural soft shadow texture generator. Our light estimation is based on deep neural nets and determines the main light direction, light color, ambient color and an opacity parameter for the shadow texture. Our neural soft shadow method encodes object-based realistic soft shadows as light direction dependent textures in a small MLP. We show that our pipeline can be used to integrate objects into AR scenes in a new level of realism in real-time. Our models are small enough to run on current mobile devices. We achieve runtimes of 9ms for light estimation and 5ms for neural shadows on an iPhone 11 Pro.
</details>
<details>
<summary>摘要</summary>
我们提出了一个管道，用于在室内场景视频中真实嵌入虚拟对象，特别是针对实时AR应用。我们的管道包括两个主要组成部分：光估计和神经软影Texture生成器。我们的光估计基于深度神经网络，确定主要光方向、光色、 ambient色和阴影Texture中的opacity参数。我们的神经软影方法将对象基于实际的软阴影编码为光方向依赖的文本ures在小型MLP中。我们显示，我们的管道可以在实时AR场景中嵌入对象到新的真实水平，并且可以在当前的移动设备上运行。我们的模型够小，在iPhone 11 Pro上达到9毫秒的运行时间和5毫秒的神经阴影时间。
</details></li>
</ul>
<hr>
<h2 id="IndoHerb-Indonesia-Medicinal-Plants-Recognition-using-Transfer-Learning-and-Deep-Learning"><a href="#IndoHerb-Indonesia-Medicinal-Plants-Recognition-using-Transfer-Learning-and-Deep-Learning" class="headerlink" title="IndoHerb: Indonesia Medicinal Plants Recognition using Transfer Learning and Deep Learning"></a>IndoHerb: Indonesia Medicinal Plants Recognition using Transfer Learning and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01604">http://arxiv.org/abs/2308.01604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Salman Ikrar Musyaffa, Novanto Yudistira, Muhammad Arif Rahman</li>
<li>for: 这个研究旨在使用计算机视觉技术来识别INDONESIA的药用植物。</li>
<li>methods: 该研究使用了转移学习法从Convolutional Neural Network（CNN）算法来分类INDONESIA的药用植物。数据采集自INDONESIA独立地通过Google图像搜索引擎，然后进行数据处理并进行分类。</li>
<li>results: 测试结果显示，使用DenseNet121模型可以达到87.4%的准确率，而使用零基eline模型可以达到43.53%的准确率。<details>
<summary>Abstract</summary>
Herbal plants are nutritious plants that can be used as an alternative to traditional disease healing. In Indonesia there are various types of herbal plants. But with the development of the times, the existence of herbal plants as traditional medicines began to be forgotten so that not everyone could recognize them. Having the ability to identify herbal plants can have many positive impacts. However, there is a problem where identifying plants can take a long time because it requires in-depth knowledge and careful examination of plant criteria. So that the application of computer vision can help identify herbal plants. Previously, research had been conducted on the introduction of herbal plants from Vietnam using several algorithms, but from these research the accuracy was not high enough. Therefore, this study intends to implement transfer learning from the Convolutional Neural Network (CNN) algorithm to classify types of herbal plants from Indonesia. This research was conducted by collecting image data of herbal plants from Indonesia independently through the Google Images search engine. After that, it will go through the data preprocessing, classification using the transfer learning method from CNN, and analysis will be carried out. The CNN transfer learning models used are ResNet34, DenseNet121, and VGG11_bn. Based on the test results of the three models, it was found that DenseNet121 was the model with the highest accuracy, which was 87.4%. In addition, testing was also carried out using the scratch model and obtained an accuracy of 43.53%. The Hyperparameter configuration used in this test is the ExponentialLR scheduler with a gamma value of 0.9; learning rate 0.001; Cross Entropy Loss function; Adam optimizer; and the number of epochs is 50. Indonesia Medicinal Plant Dataset can be accessed at the following link https://github.com/Salmanim20/indo_medicinal_plant
</details>
<details>
<summary>摘要</summary>
药用植物是一种有营养价值的植物，可以作为传统疾病的替代疗法。在印度尼西亚有很多种类的药用植物，但随着时代的发展，药用植物作为传统药物的存在开始被忘记，因此不 everybody都能认得它们。能够识别药用植物可以有很多积极影响。然而，识别植物可以耗费很长时间，因为它需要深入的知识和仔细的植物标准的检查。因此，计算机视觉的应用可以帮助识别药用植物。在过去的研究中，有些算法在印度尼西亚 introducing herbal plants from Vietnam，但这些研究的准确率不够高。因此，这项研究打算通过传输学习法，使用Convolutional Neural Network（CNN）算法来类型印度尼西亚的药用植物。这项研究通过独立地收集印度尼西亚药用植物的图像数据，并进行数据处理、类型确定和分析。测试结果显示，DenseNet121模型的准确率为87.4%，而自适应模型的准确率为43.53%。Hyperparameter配置使用ExponentialLR学习策略，γ值为0.9，学习率为0.001，交叉熵损失函数，Adam优化器，训练集数为50。印度尼西亚药用植物数据集可以在以下链接中获取：https://github.com/Salmanim20/indo_medicinal_plant。
</details></li>
</ul>
<hr>
<h2 id="Reference-Free-Isotropic-3D-EM-Reconstruction-using-Diffusion-Models"><a href="#Reference-Free-Isotropic-3D-EM-Reconstruction-using-Diffusion-Models" class="headerlink" title="Reference-Free Isotropic 3D EM Reconstruction using Diffusion Models"></a>Reference-Free Isotropic 3D EM Reconstruction using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01594">http://arxiv.org/abs/2308.01594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyungryun Lee, Won-Ki Jeong</li>
<li>for: 这个论文是为了解决电子顾微显微镜像中的不均匀分辨率问题，提高分析和下游任务的精度和效率。</li>
<li>methods: 这个方法基于 diffusion 模型，可以不需要参考数据或先知信息来重建3DVolume。它适用于高度下采样的数据，并且在实验中表现出了对比supervised learning方法的优势和稳定性。</li>
<li>results: 该方法可以自动恢复单个不均匀的Volume，无需任何训练数据。此外， authors 还进行了大量的实验，证明了该方法在两个公共数据集上的robustness和可靠性。<details>
<summary>Abstract</summary>
Electron microscopy (EM) images exhibit anisotropic axial resolution due to the characteristics inherent to the imaging modality, presenting challenges in analysis and downstream tasks.In this paper, we propose a diffusion-model-based framework that overcomes the limitations of requiring reference data or prior knowledge about the degradation process. Our approach utilizes 2D diffusion models to consistently reconstruct 3D volumes and is well-suited for highly downsampled data. Extensive experiments conducted on two public datasets demonstrate the robustness and superiority of leveraging the generative prior compared to supervised learning methods. Additionally, we demonstrate our method's feasibility for self-supervised reconstruction, which can restore a single anisotropic volume without any training data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Consistency-Regularization-for-Generalizable-Source-free-Domain-Adaptation"><a href="#Consistency-Regularization-for-Generalizable-Source-free-Domain-Adaptation" class="headerlink" title="Consistency Regularization for Generalizable Source-free Domain Adaptation"></a>Consistency Regularization for Generalizable Source-free Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01587">http://arxiv.org/abs/2308.01587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longxiang Tang, Kai Li, Chunming He, Yulun Zhang, Xiu Li</li>
<li>for: 这个论文目的是为了源自由预测项目（SFDA），将已经训练好的源模型适应到无标注目标频道，并且不需要存取源数据集，这使得它在实际中的应用非常广泛。</li>
<li>methods: 我们提出了一个对称正规化框架，以发展一个更加普遍化的 SFDA 方法，这个方法同时将模型在目标训练和测试数据集上的表现提高。我们利用弱地调整的图像生成软件标签，将强地调整的图像标签作为模型训练的指导方向，以便增强模型的普遍化能力。此外，我们还提出了一个抽样 Pseudo-label 选择策略，选择具有更大频率差的标签，以获取更多的可能用的超vision。最后，我们引入了全球方向的均衡化方法，以利用全球类别分布和特征单元信息，进一步改善适应过程。</li>
<li>results: 我们的方法在多个 SFDA 标准库上进行了广泛的实验，结果显示我们的方法可以在不存取源数据集的情况下，实现源自由预测项目的高性能和普遍化能力。此外，我们的方法还能够在无法见测试数据集上保持高度的稳定性和可靠性。<details>
<summary>Abstract</summary>
Source-free domain adaptation (SFDA) aims to adapt a well-trained source model to an unlabelled target domain without accessing the source dataset, making it applicable in a variety of real-world scenarios. Existing SFDA methods ONLY assess their adapted models on the target training set, neglecting the data from unseen but identically distributed testing sets. This oversight leads to overfitting issues and constrains the model's generalization ability. In this paper, we propose a consistency regularization framework to develop a more generalizable SFDA method, which simultaneously boosts model performance on both target training and testing datasets. Our method leverages soft pseudo-labels generated from weakly augmented images to supervise strongly augmented images, facilitating the model training process and enhancing the generalization ability of the adapted model. To leverage more potentially useful supervision, we present a sampling-based pseudo-label selection strategy, taking samples with severer domain shift into consideration. Moreover, global-oriented calibration methods are introduced to exploit global class distribution and feature cluster information, further improving the adaptation process. Extensive experiments demonstrate our method achieves state-of-the-art performance on several SFDA benchmarks, and exhibits robustness on unseen testing datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MVFlow-Deep-Optical-Flow-Estimation-of-Compressed-Videos-with-Motion-Vector-Prior"><a href="#MVFlow-Deep-Optical-Flow-Estimation-of-Compressed-Videos-with-Motion-Vector-Prior" class="headerlink" title="MVFlow: Deep Optical Flow Estimation of Compressed Videos with Motion Vector Prior"></a>MVFlow: Deep Optical Flow Estimation of Compressed Videos with Motion Vector Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01568">http://arxiv.org/abs/2308.01568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shili Zhou, Xuhao Jiang, Weimin Tan, Ruian He, Bo Yan</li>
<li>for: 这个论文是为了提高压缩视频中的光学流估算的速度和准确性而提出的。</li>
<li>methods: 该论文使用了动态模型，并将动态信息与视频压缩信息结合使用，以提高光学流估算的准确性和速度。</li>
<li>results: 实验结果表明，相比于现有模型，该论文提出的MVFlow模型可以降低AEPE值1.09，或者保持与现有模型相同的准确性，而且可以节省52%的计算时间。<details>
<summary>Abstract</summary>
In recent years, many deep learning-based methods have been proposed to tackle the problem of optical flow estimation and achieved promising results. However, they hardly consider that most videos are compressed and thus ignore the pre-computed information in compressed video streams. Motion vectors, one of the compression information, record the motion of the video frames. They can be directly extracted from the compression code stream without computational cost and serve as a solid prior for optical flow estimation. Therefore, we propose an optical flow model, MVFlow, which uses motion vectors to improve the speed and accuracy of optical flow estimation for compressed videos. In detail, MVFlow includes a key Motion-Vector Converting Module, which ensures that the motion vectors can be transformed into the same domain of optical flow and then be utilized fully by the flow estimation module. Meanwhile, we construct four optical flow datasets for compressed videos containing frames and motion vectors in pairs. The experimental results demonstrate the superiority of our proposed MVFlow, which can reduce the AEPE by 1.09 compared to existing models or save 52% time to achieve similar accuracy to existing models.
</details>
<details>
<summary>摘要</summary>
In detail, MVFlow includes a key Motion-Vector Converting Module, which ensures that the motion vectors can be transformed into the same domain as the optical flow and then be fully utilized by the flow estimation module. Furthermore, we construct four optical flow datasets for compressed videos containing frames and motion vectors in pairs. The experimental results show that our proposed MVFlow is superior, with a reduction of 1.09 in AEPE compared to existing models or a 52% reduction in time to achieve similar accuracy to existing models.
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Token-Pass-Transformers-for-Semantic-Segmentation"><a href="#Dynamic-Token-Pass-Transformers-for-Semantic-Segmentation" class="headerlink" title="Dynamic Token-Pass Transformers for Semantic Segmentation"></a>Dynamic Token-Pass Transformers for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01944">http://arxiv.org/abs/2308.01944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuang Liu, Qiang Zhou, Jing Wang, Fan Wang, Jun Wang, Wei Zhang</li>
<li>for: 这个论文是为了提高 semantic segmentation 的效率和速度而写的。</li>
<li>methods: 这个方法使用 dynamic token-pass vision transformers (DoViT)，可以适应不同的图像复杂度，并且可以适当地将部分易于计算的 токенs 排除，以减少测试成本。</li>
<li>results: 这个方法可以大约减少 40% 至 60% FLOPs，并且与硬件友好，同时仍然可以保持高效率和优化结果。 ViT-L&#x2F;B 的 Throughput 和测试速度可以提高至更多于 2$\times$ on Cityscapes。<details>
<summary>Abstract</summary>
Vision transformers (ViT) usually extract features via forwarding all the tokens in the self-attention layers from top to toe. In this paper, we introduce dynamic token-pass vision transformers (DoViT) for semantic segmentation, which can adaptively reduce the inference cost for images with different complexity. DoViT gradually stops partial easy tokens from self-attention calculation and keeps the hard tokens forwarding until meeting the stopping criteria. We employ lightweight auxiliary heads to make the token-pass decision and divide the tokens into keeping/stopping parts. With a token separate calculation, the self-attention layers are speeded up with sparse tokens and still work friendly with hardware. A token reconstruction module is built to collect and reset the grouped tokens to their original position in the sequence, which is necessary to predict correct semantic masks. We conduct extensive experiments on two common semantic segmentation tasks, and demonstrate that our method greatly reduces about 40% $\sim$ 60% FLOPs and the drop of mIoU is within 0.8% for various segmentation transformers. The throughput and inference speed of ViT-L/B are increased to more than 2$\times$ on Cityscapes.
</details>
<details>
<summary>摘要</summary>
vision transformers (ViT) 通常通过从顶部到底部传递所有的 tokens 来提取特征。在这篇论文中，我们介绍了动态Token-pass vision transformers (DoViT)，用于 semantic segmentation，可以适应不同的图像复杂度减少推理成本。DoViT 会逐渐停止一些容易的 tokens 从自我注意计算中，并保留一些困难的 tokens 直到满足停止 criterion。我们使用轻量级的辅助头来做 token-pass 决策，并将 tokens 分为保留/停止部分。通过 sparse tokens 的计算，自我注意层得到加速，同时仍与硬件友好。我们还构建了一个token重建模块，用于收集和重新设置 grouped tokens 的原始位置序列，这是必要的来预测正确的semantic mask。我们在两个常见的semantic segmentation任务上进行了广泛的实验，并证明了我们的方法可以大幅减少约40% 到60% FLOPs，并且drop of mIoU 在0.8% 以下。ViT-L/B 的 Throughput 和推理速度被提高到更多于 2 倍在 Cityscapes。
</details></li>
</ul>
<hr>
<h2 id="Get-the-Best-of-Both-Worlds-Improving-Accuracy-and-Transferability-by-Grassmann-Class-Representation"><a href="#Get-the-Best-of-Both-Worlds-Improving-Accuracy-and-Transferability-by-Grassmann-Class-Representation" class="headerlink" title="Get the Best of Both Worlds: Improving Accuracy and Transferability by Grassmann Class Representation"></a>Get the Best of Both Worlds: Improving Accuracy and Transferability by Grassmann Class Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01547">http://arxiv.org/abs/2308.01547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoqi Wang, Zhizhong Li, Wayne Zhang</li>
<li>for: 这篇论文旨在提高深度学习模型的准确率和特征传输能力。</li>
<li>methods: 论文使用了将类Vector转换为线性Subspace（i.e.~点在草mann manifold），并实现了在深度学习框架中集成Riemannian SGD以便同时优化类Subspace和模型参数。</li>
<li>results: 在ImageNet-1K数据集上，使用GCR后，ResNet50-D、ResNeXt50、Swin-T和Deit3-S等模型的顶部1错误率相对下降了5.6%、4.5%、3.0%和3.5%。此外，GCR还提供了更多的特征自由度，使得下游任务的质量更高。例如，对于ResNet50-D模型，GCR可以提高平均线性传输精度从77.98%提升到79.70%。<details>
<summary>Abstract</summary>
We generalize the class vectors found in neural networks to linear subspaces (i.e.~points in the Grassmann manifold) and show that the Grassmann Class Representation (GCR) enables the simultaneous improvement in accuracy and feature transferability. In GCR, each class is a subspace and the logit is defined as the norm of the projection of a feature onto the class subspace. We integrate Riemannian SGD into deep learning frameworks such that class subspaces in a Grassmannian are jointly optimized with the rest model parameters. Compared to the vector form, the representative capability of subspaces is more powerful. We show that on ImageNet-1K, the top-1 error of ResNet50-D, ResNeXt50, Swin-T and Deit3-S are reduced by 5.6%, 4.5%, 3.0% and 3.5%, respectively. Subspaces also provide freedom for features to vary and we observed that the intra-class feature variability grows when the subspace dimension increases. Consequently, we found the quality of GCR features is better for downstream tasks. For ResNet50-D, the average linear transfer accuracy across 6 datasets improves from 77.98% to 79.70% compared to the strong baseline of vanilla softmax. For Swin-T, it improves from 81.5% to 83.4% and for Deit3, it improves from 73.8% to 81.4%. With these encouraging results, we believe that more applications could benefit from the Grassmann class representation. Code is released at https://github.com/innerlee/GCR.
</details>
<details>
<summary>摘要</summary>
我们总结了神经网络中的类别向量到线性子空间（即点在草mann manifold），并证明GCR（草mann类表示）可以同时提高准确率和特征传递性。在GCR中，每个类是一个子空间，logit是定义为特征在类子空间上的投影距离的模值。我们将里曼射SGD集成到深度学习框架中，以便在Grassmannian中同时优化类子空间和其他模型参数。相比vector形式，子空间的表示能力更强。我们证明在ImageNet-1K上，ResNet50-D、ResNeXt50、Swin-T和Deit3-S的top-1错误率分别下降5.6%, 4.5%, 3.0%和3.5%。子空间还提供了特征之间的自由，我们观察到在子空间维度增加时，内类特征变化的度逐渐增加。因此，我们发现GCR特征质量更好，用于下游任务。对于ResNet50-D，我们在6个数据集上的平均直线传输精度从77.98%提高到79.70%，比强基eline softmax强度更高。对于Swin-T，从81.5%提高到83.4%，对于Deit3，从73.8%提高到81.4%。这些激动人心的结果表明，更多的应用可以从GCR中受益。代码可以在https://github.com/innerlee/GCR中找到。
</details></li>
</ul>
<hr>
<h2 id="DMDC-Dynamic-mask-based-dual-camera-design-for-snapshot-Hyperspectral-Imaging"><a href="#DMDC-Dynamic-mask-based-dual-camera-design-for-snapshot-Hyperspectral-Imaging" class="headerlink" title="DMDC: Dynamic-mask-based dual camera design for snapshot Hyperspectral Imaging"></a>DMDC: Dynamic-mask-based dual camera design for snapshot Hyperspectral Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01541">http://arxiv.org/abs/2308.01541</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/caizeyu1992/dmdc">https://github.com/caizeyu1992/dmdc</a></li>
<li>paper_authors: Zeyu Cai, Chengqian Jin, Feipeng Da</li>
<li>for: 提高coded aperture snapshot spectral imaging（CASSI）中深度学习方法的性能。</li>
<li>methods: 使用动态面镜（DMD）和多模式重构网络（DMDC-net），首先根据RGB图像学习场景的空间特征分布，然后使用SLM编码场景，最后将RGB和CASSI图像传输到网络进行重构。</li>
<li>results: 在多个数据集上进行了广泛的实验，结果表明，我们的方法可以与先前最佳方法（SOTA）比较，提高PSNR值超过9 dB。<details>
<summary>Abstract</summary>
Deep learning methods are developing rapidly in coded aperture snapshot spectral imaging (CASSI). The number of parameters and FLOPs of existing state-of-the-art methods (SOTA) continues to increase, but the reconstruction accuracy improves slowly. Current methods still face two problems: 1) The performance of the spatial light modulator (SLM) is not fully developed due to the limitation of fixed Mask coding. 2) The single input limits the network performance. In this paper we present a dynamic-mask-based dual camera system, which consists of an RGB camera and a CASSI system running in parallel. First, the system learns the spatial feature distribution of the scene based on the RGB images, then instructs the SLM to encode each scene, and finally sends both RGB and CASSI images to the network for reconstruction. We further designed the DMDC-net, which consists of two separate networks, a small-scale CNN-based dynamic mask network for dynamic adjustment of the mask and a multimodal reconstruction network for reconstruction using RGB and CASSI measurements. Extensive experiments on multiple datasets show that our method achieves more than 9 dB improvement in PSNR over the SOTA. (https://github.com/caizeyu1992/DMDC)
</details>
<details>
<summary>摘要</summary>
深度学习方法在coded aperture snapshot spectral imaging（CASSI）领域快速发展，但现有状态的方法（SOTA）中参数和FLOPs的数量继续增加，但 reconstruction accuracy 的提高相对较慢。当前方法仍面临两个问题：1）SLM（spatial light modulator）的性能尚未得到完全发展，因为固定的Mask coding有限制。2）单个输入限制网络性能。在本文中，我们提出了动态Mask基于双camera系统，包括一个RGB摄像头和一个CASSI系统在平行运行。首先，系统通过RGB图像学习场景中的空间特征分布，然后根据场景指定SLM编码，最后将RGB和CASSI图像传递给网络进行重建。我们还设计了DMDC-net，它包括两个独立的网络：一个小规模的CNN基于动态Mask网络用于动态调整Mask，以及一个多模式重建网络用于使用RGB和CASSI测量进行重建。我们在多个数据集上进行了广泛的实验，结果显示，我们的方法可以在PSNR方面实现超过9dB的提高。（https://github.com/caizeyu1992/DMDC）
</details></li>
</ul>
<hr>
<h2 id="MFIM-Megapixel-Facial-Identity-Manipulation"><a href="#MFIM-Megapixel-Facial-Identity-Manipulation" class="headerlink" title="MFIM: Megapixel Facial Identity Manipulation"></a>MFIM: Megapixel Facial Identity Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01536">http://arxiv.org/abs/2308.01536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanghyeon Na</li>
<li>for: 本文提出了一种新的面孔交换框架，称为大像素面孔标识修饰（MFIM），用于实现两个目标：首先，生成高质量图像；其次，将给定图像的身份特征变换成另一个人的身份特征，保留不相关的特征。</li>
<li>methods: 本文使用了预训练的StyleGAN进行GAN-倒置，以生成高像素图像。此外，本文还使用了3DMM来捕捉多种面孔特征，并将这些特征用于生成面孔交换图像。</li>
<li>results: 经过广泛的实验表明，本文的模型达到了状态方法性能。此外，本文还提出了一种新的操作，称为身份混合，允许用户自定义新的身份。<details>
<summary>Abstract</summary>
Face swapping is a task that changes a facial identity of a given image to that of another person. In this work, we propose a novel face-swapping framework called Megapixel Facial Identity Manipulation (MFIM). The face-swapping model should achieve two goals. First, it should be able to generate a high-quality image. We argue that a model which is proficient in generating a megapixel image can achieve this goal. However, generating a megapixel image is generally difficult without careful model design. Therefore, our model exploits pretrained StyleGAN in the manner of GAN-inversion to effectively generate a megapixel image. Second, it should be able to effectively transform the identity of a given image. Specifically, it should be able to actively transform ID attributes (e.g., face shape and eyes) of a given image into those of another person, while preserving ID-irrelevant attributes (e.g., pose and expression). To achieve this goal, we exploit 3DMM that can capture various facial attributes. Specifically, we explicitly supervise our model to generate a face-swapped image with the desirable attributes using 3DMM. We show that our model achieves state-of-the-art performance through extensive experiments. Furthermore, we propose a new operation called ID mixing, which creates a new identity by semantically mixing the identities of several people. It allows the user to customize the new identity.
</details>
<details>
<summary>摘要</summary>
《Face swapping是一个任务，把给定图像的脸部标识换成另一个人的脸部标识。在这个工作中，我们提出了一种新的面部交换框架，即Megapixel Facial Identity Manipulation（MFIM）。这个模型应该实现两个目标。一是生成高质量图像，我们认为能够生成高分辨率图像的模型可以实现这个目标。然而，生成高分辨率图像通常需要精心的模型设计。因此，我们的模型利用了预训练的StyleGAN，通过GAN-倒置的方式来生成高分辨率图像。二是能够有效地将给定图像的脸部标识转换为另一个人的脸部标识。具体来说，它应该能够活动地将ID属性（如脸形和眼睛）转换为另一个人的ID属性，保留ID不关属性（如姿势和表情）。为了实现这个目标，我们利用了3DMM，它可以捕捉各种脸部特征。我们显式地监督我们的模型生成一个面部交换图像，拥有愿望的特征使用3DMM。我们的实验结果表明，我们的模型实现了状态监测的性能。此外，我们还提出了一种新的操作，即ID混合，它可以将多个人的标识混合成一个新的标识，让用户自定义新的标识。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Adaptation-of-CLIP-for-Few-Shot-Action-Recognition"><a href="#Multimodal-Adaptation-of-CLIP-for-Few-Shot-Action-Recognition" class="headerlink" title="Multimodal Adaptation of CLIP for Few-Shot Action Recognition"></a>Multimodal Adaptation of CLIP for Few-Shot Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01532">http://arxiv.org/abs/2308.01532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiazheng Xing, Mengmeng Wang, Xiaojun Hou, Guang Dai, Jingdong Wang, Yong Liu</li>
<li>for: 这篇论文的目的是提出一种新的方法来将大规模预训的视觉模型CLIP应用于几步动作识别 зада务中，以提高性能和效率。</li>
<li>methods: 这篇论文使用了“预训、统一”的方法来避免从零训练网络，从而节省时间和资源。但这方法有两个缺点：首先，几步动作识别的有限标签数据需要对数据进行严格的节省，以避免过拟合；其次，影片的EXTRA-temporal维度对几步动作识别的有效时间模型产生挑战，而预训的视觉模型通常是图像模型。这篇论文提出了一种名为Multimodal Adaptation of CLIP（MA-CLIP）的新方法，用于解决这些问题。</li>
<li>results: MA-CLIP可以快速地适应几步动作识别任务，并且可以将视觉模型转换到不同的任务上，而不需要从零训练网络。这篇论文还提出了一种基于注意机制的文本导向原型建立模组，可以充分利用影片-文本多媒体资料来增强影片原型的表现。<details>
<summary>Abstract</summary>
Applying large-scale pre-trained visual models like CLIP to few-shot action recognition tasks can benefit performance and efficiency. Utilizing the "pre-training, fine-tuning" paradigm makes it possible to avoid training a network from scratch, which can be time-consuming and resource-intensive. However, this method has two drawbacks. First, limited labeled samples for few-shot action recognition necessitate minimizing the number of tunable parameters to mitigate over-fitting, also leading to inadequate fine-tuning that increases resource consumption and may disrupt the generalized representation of models. Second, the video's extra-temporal dimension challenges few-shot recognition's effective temporal modeling, while pre-trained visual models are usually image models. This paper proposes a novel method called Multimodal Adaptation of CLIP (MA-CLIP) to address these issues. It adapts CLIP for few-shot action recognition by adding lightweight adapters, which can minimize the number of learnable parameters and enable the model to transfer across different tasks quickly. The adapters we design can combine information from video-text multimodal sources for task-oriented spatiotemporal modeling, which is fast, efficient, and has low training costs. Additionally, based on the attention mechanism, we design a text-guided prototype construction module that can fully utilize video-text information to enhance the representation of video prototypes. Our MA-CLIP is plug-and-play, which can be used in any different few-shot action recognition temporal alignment metric.
</details>
<details>
<summary>摘要</summary>
使用大规模预训练的视觉模型如CLIP进行几步动作认知任务可以提高性能和效率。利用“预训练、精度调整”的方法可以避免从头开始训练网络，这可以降低时间和资源的投入。然而，这种方法有两点缺点。首先，几步动作认知任务的有限标注样本数量需要尽量减少可训练参数的数量，以避免过拟合。其次，视频的Extra-temporal维度对几步动作认知任务的有效时间模型化起来困难，而预训练的视觉模型通常是图像模型。这篇论文提出了一种新的方法called Multimodal Adaptation of CLIP (MA-CLIP)来解决这些问题。它适应了CLIP进行几步动作认知任务，通过添加轻量级适配器，可以最小化可训练参数的数量，并使模型快速传播到不同任务。我们设计的适配器可以将视频-文本多modal源的信息结合到任务指向的空间时间模型中，这快速、高效、训练成本低。此外，基于注意机制，我们设计了文本引导原型构建模块，可以充分利用视频-文本信息来增强视频原型的表示。我们的MA-CLIP是可插入的，可以在不同的几步动作认知任务中使用。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-for-Human-Behavior-Analysis-in-Multi-Person-Conversations"><a href="#Data-Augmentation-for-Human-Behavior-Analysis-in-Multi-Person-Conversations" class="headerlink" title="Data Augmentation for Human Behavior Analysis in Multi-Person Conversations"></a>Data Augmentation for Human Behavior Analysis in Multi-Person Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01526">http://arxiv.org/abs/2308.01526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun Li, Dan Guo, Guoliang Chen, Feiyang Liu, Meng Wang</li>
<li>for: 本文介绍了我们队伍HFUT-VUT在ACM Multimedia 2023年度多媒体大挑战中的解决方案，该解决方案包括三个子挑战：身体行为识别、眼接触检测和下一位说话预测。</li>
<li>methods: 我们选择Swin Transformer作为基线，并使用数据增强策略来解决上述三个任务。具体来说，我们将原始视频裁剪去除其他部分的噪音，同时利用数据增强来改善模型的通用性。</li>
<li>results: 我们的解决方案在测试集上实现了身体行为识别的最佳结果（准确率为0.6262）、眼接触检测的最高精度（准确率为0.7771）和下一位说话预测的相对不错的结果（不Weighted Average Recall为0.5281）。<details>
<summary>Abstract</summary>
In this paper, we present the solution of our team HFUT-VUT for the MultiMediate Grand Challenge 2023 at ACM Multimedia 2023. The solution covers three sub-challenges: bodily behavior recognition, eye contact detection, and next speaker prediction. We select Swin Transformer as the baseline and exploit data augmentation strategies to address the above three tasks. Specifically, we crop the raw video to remove the noise from other parts. At the same time, we utilize data augmentation to improve the generalization of the model. As a result, our solution achieves the best results of 0.6262 for bodily behavior recognition in terms of mean average precision and the accuracy of 0.7771 for eye contact detection on the corresponding test set. In addition, our approach also achieves comparable results of 0.5281 for the next speaker prediction in terms of unweighted average recall.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了我们团队HFUT-VUT在ACM Multimedia 2023年度的MultiMediate Grand Challenge 2023中的解决方案。该解决方案包括三个子挑战：身体行为识别、眼球接触检测和下一个发言人预测。我们选择Swin Transformer作为基线，并使用数据扩充策略来解决以上三个任务。具体来说，我们对原始视频进行cropping，以移除其他部分的噪音。同时，我们利用数据扩充来提高模型的通用性。因此，我们的解决方案在对应的测试集上实现了身体行为识别的最佳结果（准确率0.6262）和眼球接触检测的最高精度（准确率0.7771）。此外，我们的方法还实现了与基线相当的下一个发言人预测结果（不重量平均回归率0.5281）。
</details></li>
</ul>
<hr>
<h2 id="VisAlign-Dataset-for-Measuring-the-Degree-of-Alignment-between-AI-and-Humans-in-Visual-Perception"><a href="#VisAlign-Dataset-for-Measuring-the-Degree-of-Alignment-between-AI-and-Humans-in-Visual-Perception" class="headerlink" title="VisAlign: Dataset for Measuring the Degree of Alignment between AI and Humans in Visual Perception"></a>VisAlign: Dataset for Measuring the Degree of Alignment between AI and Humans in Visual Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01525">http://arxiv.org/abs/2308.01525</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiyounglee-0523/visalign">https://github.com/jiyounglee-0523/visalign</a></li>
<li>paper_authors: Jiyoung Lee, Seungho Kim, Seunghyun Won, Joonseok Lee, Marzyeh Ghassemi, James Thorne, Jaeseok Choi, O-Kil Kwon, Edward Choi</li>
<li>for: 本研究旨在提高人工智能模型与人类目标、偏好或道德原则的一致性，即 AI 安全性。</li>
<li>methods: 本文提出了一个新的图像分类数据集，用于衡量人工智能模型与人类视觉启示的一致性。</li>
<li>results: 使用该数据集，我们分析了五种流行的视觉识别模型和七种决策策略的视觉一致性和可靠性。<details>
<summary>Abstract</summary>
AI alignment refers to models acting towards human-intended goals, preferences, or ethical principles. Given that most large-scale deep learning models act as black boxes and cannot be manually controlled, analyzing the similarity between models and humans can be a proxy measure for ensuring AI safety. In this paper, we focus on the models' visual perception alignment with humans, further referred to as AI-human visual alignment. Specifically, we propose a new dataset for measuring AI-human visual alignment in terms of image classification, a fundamental task in machine perception. In order to evaluate AI-human visual alignment, a dataset should encompass samples with various scenarios that may arise in the real world and have gold human perception labels. Our dataset consists of three groups of samples, namely Must-Act (i.e., Must-Classify), Must-Abstain, and Uncertain, based on the quantity and clarity of visual information in an image and further divided into eight categories. All samples have a gold human perception label; even Uncertain (severely blurry) sample labels were obtained via crowd-sourcing. The validity of our dataset is verified by sampling theory, statistical theories related to survey design, and experts in the related fields. Using our dataset, we analyze the visual alignment and reliability of five popular visual perception models and seven abstention methods. Our code and data is available at \url{https://github.com/jiyounglee-0523/VisAlign}.
</details>
<details>
<summary>摘要</summary>
人工智能对齐（AI对齐）指模型行为与人类目标、偏好或伦理原则相符。由于大多数大规模深度学习模型作为黑盒子无法被手动控制，因此分析模型与人类的相似性可以作为AI安全的代理指标。在这篇论文中，我们关注视觉模型与人类的视觉对齐，即AI-人类视觉对齐。我们提出了一个新的数据集来衡量AI-人类视觉对齐，该数据集包括了不同场景可能在实际世界中出现的图像分类任务。为了评估AI-人类视觉对齐，数据集应包含具有不同频率和清晰度的图像样本，并且每个样本都有人类视觉标签。我们的数据集分为三类样本：必须作为（Must-Act）、必须停止（Must-Abstain）和不确定（Uncertain），根据图像中视觉信息的量和清晰度进行分类。所有样本具有人类视觉标签，包括不确定（极度模糊）样本的标签，通过在线人员投票获取。我们的数据集的有效性被证明由抽样理论、统计相关的调查设计理论以及相关领域专家的验证。使用我们的数据集，我们分析了五种流行的视觉识别模型和七种停止方法的视觉对齐和可靠性。我们的代码和数据可以在GitHub上获取：<https://github.com/jiyounglee-0523/VisAlign>。
</details></li>
</ul>
<hr>
<h2 id="PPI-NET-End-to-End-Parametric-Primitive-Inference"><a href="#PPI-NET-End-to-End-Parametric-Primitive-Inference" class="headerlink" title="PPI-NET: End-to-End Parametric Primitive Inference"></a>PPI-NET: End-to-End Parametric Primitive Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01521">http://arxiv.org/abs/2308.01521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang Wang, Xiaogang Wang</li>
<li>for: 本研究旨在提高设计模型创建过程中的效率和准确性，避免使用自适应模型从手绘图像中推导参数化基本形态时的不必要的重复和错误积累问题。</li>
<li>methods: 我们提议一种高效准确的终端方法，通过直接从手绘图像中提取基本形态的准确 Parametric 表示，以避免使用自适应模型的推导过程中的错误和重复工作。</li>
<li>results: 我们的模型样本匹配标准 CAD 软件的表示格式，因此可以将其导入 CAD 软件进行解决、编辑和应用到下游设计任务中。<details>
<summary>Abstract</summary>
In engineering applications, line, circle, arc, and point are collectively referred to as primitives, and they play a crucial role in path planning, simulation analysis, and manufacturing. When designing CAD models, engineers typically start by sketching the model's orthographic view on paper or a whiteboard and then translate the design intent into a CAD program. Although this design method is powerful, it often involves challenging and repetitive tasks, requiring engineers to perform numerous similar operations in each design. To address this conversion process, we propose an efficient and accurate end-to-end method that avoids the inefficiency and error accumulation issues associated with using auto-regressive models to infer parametric primitives from hand-drawn sketch images. Since our model samples match the representation format of standard CAD software, they can be imported into CAD software for solving, editing, and applied to downstream design tasks.
</details>
<details>
<summary>摘要</summary>
在工程应用中，直线、圆形、弧形和点被合称为基本形状，它们在路径规划、分析研究和生产中扮演着重要的角色。在设计CAD模型时，工程师通常从纸上或白板上绘制模型的正交视图，然后将设计意图翻译到CAD软件中。虽然这种设计方法具有强大的能力，但它经常带来复杂和重复的任务，需要工程师在每个设计中执行大量相似的操作。为了解决这个转换过程中的不效率和错误积累问题，我们提出了一种高效和准确的终端方法，这种方法可以避免使用自动回归模型来从手绘笔画图像中推导参数化基本形状。由于我们的模型样本与标准CAD软件的表示格式匹配，因此它们可以被直接 importing into CAD软件中进行解决、编辑和应用到下游设计任务中。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Multi-FaceForensics-An-End-to-end-Bi-grained-Contrastive-Learning-Approach-for-Multi-face-Forgery-Detection"><a href="#Contrastive-Multi-FaceForensics-An-End-to-end-Bi-grained-Contrastive-Learning-Approach-for-Multi-face-Forgery-Detection" class="headerlink" title="Contrastive Multi-FaceForensics: An End-to-end Bi-grained Contrastive Learning Approach for Multi-face Forgery Detection"></a>Contrastive Multi-FaceForensics: An End-to-end Bi-grained Contrastive Learning Approach for Multi-face Forgery Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01520">http://arxiv.org/abs/2308.01520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cong Zhang, Honggang Qi, Yuezun Li, Siwei Lyu</li>
<li>for: 本研究旨在提高多人脸伪造检测。</li>
<li>methods: 该方法基于对比学习，包括粗细度层次的对比学习和像素级别的对比学习。</li>
<li>results: 对比Multi-FaceForensics方法，该方法在OpenForensics数据集上达到了18.5%的提升。<details>
<summary>Abstract</summary>
DeepFakes have raised serious societal concerns, leading to a great surge in detection-based forensics methods in recent years. Face forgery recognition is the conventional detection method that usually follows a two-phase pipeline: it extracts the face first and then determines its authenticity by classification. Since DeepFakes in the wild usually contain multiple faces, using face forgery detection methods is merely practical as they have to process faces in a sequel, i.e., only one face is processed at the same time. One straightforward way to address this issue is to integrate face extraction and forgery detection in an end-to-end fashion by adapting advanced object detection architectures. However, as these object detection architectures are designed to capture the semantic information of different object categories rather than the subtle forgery traces among the faces, the direct adaptation is far from optimal. In this paper, we describe a new end-to-end framework, Contrastive Multi-FaceForensics (COMICS), to enhance multi-face forgery detection. The core of the proposed framework is a novel bi-grained contrastive learning approach that explores effective face forgery traces at both the coarse- and fine-grained levels. Specifically, the coarse-grained level contrastive learning captures the discriminative features among positive and negative proposal pairs in multiple scales with the instruction of the proposal generator, and the fine-grained level contrastive learning captures the pixel-wise discrepancy between the forged and original areas of the same face and the pixel-wise content inconsistency between different faces. Extensive experiments on the OpenForensics dataset demonstrate our method outperforms other counterparts by a large margin (~18.5%) and shows great potential for integration into various architectures.
</details>
<details>
<summary>摘要</summary>
深度复制（DeepFakes）已引起了社会的严重关注，leading to a great surge in detection-based forensics methods in recent years. Face forgery recognition is the conventional detection method that usually follows a two-phase pipeline: it extracts the face first and then determines its authenticity by classification. However, since DeepFakes in the wild usually contain multiple faces, using face forgery detection methods is merely practical as they have to process faces in a sequel, i.e., only one face is processed at the same time. To address this issue, we can integrate face extraction and forgery detection in an end-to-end fashion by adapting advanced object detection architectures. However, as these object detection architectures are designed to capture the semantic information of different object categories rather than the subtle forgery traces among the faces, the direct adaptation is far from optimal.In this paper, we propose a new end-to-end framework, Contrastive Multi-FaceForensics (COMICS), to enhance multi-face forgery detection. The core of the proposed framework is a novel bi-grained contrastive learning approach that explores effective face forgery traces at both the coarse- and fine-grained levels. Specifically, the coarse-grained level contrastive learning captures the discriminative features among positive and negative proposal pairs in multiple scales with the instruction of the proposal generator, and the fine-grained level contrastive learning captures the pixel-wise discrepancy between the forged and original areas of the same face and the pixel-wise content inconsistency between different faces. Extensive experiments on the OpenForensics dataset demonstrate that our method outperforms other counterparts by a large margin (~18.5%) and shows great potential for integration into various architectures.
</details></li>
</ul>
<hr>
<h2 id="Circumventing-Concept-Erasure-Methods-For-Text-to-Image-Generative-Models"><a href="#Circumventing-Concept-Erasure-Methods-For-Text-to-Image-Generative-Models" class="headerlink" title="Circumventing Concept Erasure Methods For Text-to-Image Generative Models"></a>Circumventing Concept Erasure Methods For Text-to-Image Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01508">http://arxiv.org/abs/2308.01508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nyu-dice-lab/circumventing-concept-erasure">https://github.com/nyu-dice-lab/circumventing-concept-erasure</a></li>
<li>paper_authors: Minh Pham, Kelly O. Marshall, Chinmay Hegde</li>
<li>for: 本研究旨在检查五种最近提出的概念消除方法，以确定这些方法是否能够彻底消除目标概念。</li>
<li>methods: 本研究使用了五种最近提出的概念消除方法，包括：Xu et al.’s method（2018）、Zhang et al.’s method（2019）、Liu et al.’s method（2020）、Wang et al.’s method（2020）和Zhang et al.’s method（2020）。</li>
<li>results: 研究发现，无论使用哪种方法，都无法彻底消除目标概念。特别是，使用特定的学习word embeddings可以 Retrieves “erased” concepts from the sanitized models with no alterations to their weights。这些结果表明，后期概念消除方法是不坚定的，并质疑它们在AI安全中的使用。<details>
<summary>Abstract</summary>
Text-to-image generative models can produce photo-realistic images for an extremely broad range of concepts, and their usage has proliferated widely among the general public. On the flip side, these models have numerous drawbacks, including their potential to generate images featuring sexually explicit content, mirror artistic styles without permission, or even hallucinate (or deepfake) the likenesses of celebrities. Consequently, various methods have been proposed in order to "erase" sensitive concepts from text-to-image models. In this work, we examine five recently proposed concept erasure methods, and show that targeted concepts are not fully excised from any of these methods. Specifically, we leverage the existence of special learned word embeddings that can retrieve "erased" concepts from the sanitized models with no alterations to their weights. Our results highlight the brittleness of post hoc concept erasure methods, and call into question their use in the algorithmic toolkit for AI safety.
</details>
<details>
<summary>摘要</summary>
文本到图像生成模型可以生成高度真实的图像，覆盖了极广泛的概念，并在普通公众中得到了广泛的应用。然而，这些模型也有许多缺点，包括可能生成涉黄内容、无许可的艺术风格模仿或even celebrities的形象hallucination（或深 fake）。因此，各种方法被提议，以“消除”敏感概念从文本到图像模型中。在这项工作中，我们研究了五种最近提出的概念消除方法，并发现目标概念在这些方法中并没有完全消除。具体来说，我们利用特殊学习的词嵌入，可以从清理后的模型中提取“消除”的概念，无需对模型的权重进行任何修改。我们的结果表明了后期概念消除方法的脆弱性，并质疑它们在AI安全中的使用。
</details></li>
</ul>
<hr>
<h2 id="TSMD-A-Database-for-Static-Color-Mesh-Quality-Assessment-Study"><a href="#TSMD-A-Database-for-Static-Color-Mesh-Quality-Assessment-Study" class="headerlink" title="TSMD: A Database for Static Color Mesh Quality Assessment Study"></a>TSMD: A Database for Static Color Mesh Quality Assessment Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01940">http://arxiv.org/abs/2308.01940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Yang, Joel Jung, Haiqiang Wang, Xiaozhong Xu, Shan Liu</li>
<li>for:  This paper is written for the study of static mesh compression algorithms and objective quality metrics.</li>
<li>methods:  The paper uses a large-scale, crowdsourcing-based, subjective experiment to collect subjective scores from 74 viewers, and analyzes the dataset to validate its sample diversity and Mean Opinion Scores (MOS) accuracy.</li>
<li>results:  The paper reports Pearson and Spearman correlations around 0.75, demonstrating the need for further development of more robust metrics.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文是为了研究静态网格压缩算法和对象质量指标的研究而写的。</li>
<li>methods: 这篇论文使用大规模的人工社会测试来收集74名观众的主观分数，并分析数据集以验证其样本多样性和 Mean Opinion Scores（MOS）准确性。</li>
<li>results: 这篇论文报告了皮尔逊和斯帕曼相关性约为0.75，表明需要进一步开发更加Robust的指标。<details>
<summary>Abstract</summary>
Static meshes with texture map are widely used in modern industrial and manufacturing sectors, attracting considerable attention in the mesh compression community due to its huge amount of data. To facilitate the study of static mesh compression algorithm and objective quality metric, we create the Tencent - Static Mesh Dataset (TSMD) containing 42 reference meshes with rich visual characteristics. 210 distorted samples are generated by the lossy compression scheme developed for the Call for Proposals on polygonal static mesh coding, released on June 23 by the Alliance for Open Media Volumetric Visual Media group. Using processed video sequences, a large-scale, crowdsourcing-based, subjective experiment was conducted to collect subjective scores from 74 viewers. The dataset undergoes analysis to validate its sample diversity and Mean Opinion Scores (MOS) accuracy, establishing its heterogeneous nature and reliability. State-of-the-art objective metrics are evaluated on the new dataset. Pearson and Spearman correlations around 0.75 are reported, deviating from results typically observed on less heterogeneous datasets, demonstrating the need for further development of more robust metrics. The TSMD, including meshes, PVSs, bitstreams, and MOS, is made publicly available at the following location: https://multimedia.tencent.com/resources/tsmd.
</details>
<details>
<summary>摘要</summary>
Static meshes with texture map 广泛应用于现代工业和制造领域，吸引了严重的数据压缩社区的关注，因为它们的数据量很大。为了促进静止矩阵压缩算法和目标质量指标的研究，我们创建了腾讯-静止矩阵数据集（TSMD），包含42个参考矩阵，具有丰富的视觉特征。通过发布的损失压缩方案，我们生成了210个扭曲样例。使用处理过的视频序列，我们通过大规模的人员协同实验，收集了74名观众的主观评分。数据集进行分析，以验证样本多样性和主观评分准确性，证明其多样性和可靠性。我们使用现有的对象指标进行evaluation，并报告了0.75的 peakson和spearman相关性，与其他更少的多样性的数据集相比，表明需要进一步发展更加Robust的指标。TSMD，包括矩阵、PVS、比特流和MOS，在以下地址公开发布：https://multimedia.tencent.com/resources/tsmd。
</details></li>
</ul>
<hr>
<h2 id="TDMD-A-Database-for-Dynamic-Color-Mesh-Subjective-and-Objective-Quality-Explorations"><a href="#TDMD-A-Database-for-Dynamic-Color-Mesh-Subjective-and-Objective-Quality-Explorations" class="headerlink" title="TDMD: A Database for Dynamic Color Mesh Subjective and Objective Quality Explorations"></a>TDMD: A Database for Dynamic Color Mesh Subjective and Objective Quality Explorations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01499">http://arxiv.org/abs/2308.01499</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Yang, Joel Jung, Timon Deschamps, Xiaozhong Xu, Shan Liu</li>
<li>for: 这个论文的目的是为了开发对动态颜色网格（DCM）的 объектив度量表，以及研究一般处理DCM时的影响。</li>
<li>methods: 这个论文使用了八个参考DCM对象和六种常见的扭曲来创建了 Tencent - 动态颜色网格数据库（TDMD）。然后，通过处理视频序列（PVS）来进行了大规模的主观实验，从而获得了303个扭曲DCM样本的平均意见分数。</li>
<li>results: 这个数据库可以用于研究不同类型的扭曲对人类 восприятия的影响，以及提供DCM压缩和相关任务中的建议。此外，这个论文还评估了三种当今最佳的对metric在TDMD上的表现，包括图像基于的、点基于的和视频基于的metric。实验结果表明每种metric在不同的应用中具有优势和缺陷，并提供了实际应用中metric选择的建议。TDMD将在以下位置公开：<a target="_blank" rel="noopener" href="https://multimedia.tencent.com/resources/tdmd%E3%80%82">https://multimedia.tencent.com/resources/tdmd。</a><details>
<summary>Abstract</summary>
Dynamic colored meshes (DCM) are widely used in various applications; however, these meshes may undergo different processes, such as compression or transmission, which can distort them and degrade their quality. To facilitate the development of objective metrics for DCMs and study the influence of typical distortions on their perception, we create the Tencent - dynamic colored mesh database (TDMD) containing eight reference DCM objects with six typical distortions. Using processed video sequences (PVS) derived from the DCM, we have conducted a large-scale subjective experiment that resulted in 303 distorted DCM samples with mean opinion scores, making the TDMD the largest available DCM database to our knowledge. This database enabled us to study the impact of different types of distortion on human perception and offer recommendations for DCM compression and related tasks. Additionally, we have evaluated three types of state-of-the-art objective metrics on the TDMD, including image-based, point-based, and video-based metrics, on the TDMD. Our experimental results highlight the strengths and weaknesses of each metric, and we provide suggestions about the selection of metrics in practical DCM applications. The TDMD will be made publicly available at the following location: https://multimedia.tencent.com/resources/tdmd.
</details>
<details>
<summary>摘要</summary>
《dynamic colored meshes（DCM）在各种应用中广泛使用，但这些网格可能会经历压缩、传输等过程，导致其质量下降。为了促进DCM的 объектив评价和研究这些扭曲对人类视觉的影响，我们创建了腾讯-动态颜色网格数据库（TDMD），包含8个参考DCM对象以及6种典型的扭曲。使用来自DCM的处理视频序列（PVS），我们进行了大规模的主观实验，从而生成了303个扭曲DCM样本，其中每个样本有平均意见分数。TDMD是我们知道的最大的DCM数据库。我们通过对TDMD进行研究，发现不同类型的扭曲对人类视觉的影响，并提供了DCM压缩和相关任务中的指导方针。此外，我们还评估了三种当今最佳的对象评价度量，包括图像基于的、点基于的和视频基于的度量，在TDMD上。我们的实验结果显示了每种度量的优缺点，并提供了实际应用中选择度量的建议。TDMD将在以下地址公开：https://multimedia.tencent.com/resources/tdmd。》
</details></li>
</ul>
<hr>
<h2 id="Efficient-neural-supersampling-on-a-novel-gaming-dataset"><a href="#Efficient-neural-supersampling-on-a-novel-gaming-dataset" class="headerlink" title="Efficient neural supersampling on a novel gaming dataset"></a>Efficient neural supersampling on a novel gaming dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01483">http://arxiv.org/abs/2308.01483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Mercier, Ruan Erasmus, Yashesh Savani, Manik Dhingra, Fatih Porikli, Guillaume Berger</li>
<li>for: 提高游戏视频的实时渲染效果，因为需要更高的分辨率、帧率和光彩实现。</li>
<li>methods: 使用神经网络算法进行渲染内容的高速抽象，比现有方法四倍效率，保持同等准确性。</li>
<li>results: 引入了一个新的数据集，提供了辅助特征如运动 вектор和深度，这些特征是通过渲染特性如视窗晃动和mipple biasing在不同分辨率下生成的。我们认为这个数据集会填补当前数据景观的空白，并可以作为测试进步的 valuable resource。<details>
<summary>Abstract</summary>
Real-time rendering for video games has become increasingly challenging due to the need for higher resolutions, framerates and photorealism. Supersampling has emerged as an effective solution to address this challenge. Our work introduces a novel neural algorithm for supersampling rendered content that is 4 times more efficient than existing methods while maintaining the same level of accuracy. Additionally, we introduce a new dataset which provides auxiliary modalities such as motion vectors and depth generated using graphics rendering features like viewport jittering and mipmap biasing at different resolutions. We believe that this dataset fills a gap in the current dataset landscape and can serve as a valuable resource to help measure progress in the field and advance the state-of-the-art in super-resolution techniques for gaming content.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:现实时游戏渲染面临着高分辨率、高帧率和真实感的增加需求，而抽象渲染技术已成为一种有效的解决方案。我们的工作推出了一种基于神经网络的抽象渲染内容算法，比现有方法高效四倍，保持同等准确性。此外，我们还介绍了一个新的数据集，该数据集包含不同分辨率下的游戏内容中的视觉特征，如视口抖动和mips扭曲，以及相关的动作向量和深度信息。我们认为这个数据集将填补当前数据景观的空白，并成为评估领域的价值资源，帮助推动游戏内容的超分辨率技术的进步。
</details></li>
</ul>
<hr>
<h2 id="HANDAL-A-Dataset-of-Real-World-Manipulable-Object-Categories-with-Pose-Annotations-Affordances-and-Reconstructions"><a href="#HANDAL-A-Dataset-of-Real-World-Manipulable-Object-Categories-with-Pose-Annotations-Affordances-and-Reconstructions" class="headerlink" title="HANDAL: A Dataset of Real-World Manipulable Object Categories with Pose Annotations, Affordances, and Reconstructions"></a>HANDAL: A Dataset of Real-World Manipulable Object Categories with Pose Annotations, Affordances, and Reconstructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01477">http://arxiv.org/abs/2308.01477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Guo, Bowen Wen, Jianhe Yuan, Jonathan Tremblay, Stephen Tyree, Jeffrey Smith, Stan Birchfield</li>
<li>for: 这 paper 是为了提供一个category-level object pose estimation和可用性预测的数据集，而且这个数据集专注于可以由机器人抓取的可操作物品，例如锤子、用具和螺丝刀。</li>
<li>methods: 这 paper 使用了单个抽象相机和半自动化处理来生成高质量的3D注释，而不需要人工劳动。</li>
<li>results: 这 paper 描述了一个包含 308k annotated image frame 和 2.2k 视频的 212 个实际世界物品的 17 个类别，以及这些数据集的使用性和挑战。<details>
<summary>Abstract</summary>
We present the HANDAL dataset for category-level object pose estimation and affordance prediction. Unlike previous datasets, ours is focused on robotics-ready manipulable objects that are of the proper size and shape for functional grasping by robot manipulators, such as pliers, utensils, and screwdrivers. Our annotation process is streamlined, requiring only a single off-the-shelf camera and semi-automated processing, allowing us to produce high-quality 3D annotations without crowd-sourcing. The dataset consists of 308k annotated image frames from 2.2k videos of 212 real-world objects in 17 categories. We focus on hardware and kitchen tool objects to facilitate research in practical scenarios in which a robot manipulator needs to interact with the environment beyond simple pushing or indiscriminate grasping. We outline the usefulness of our dataset for 6-DoF category-level pose+scale estimation and related tasks. We also provide 3D reconstructed meshes of all objects, and we outline some of the bottlenecks to be addressed for democratizing the collection of datasets like this one.
</details>
<details>
<summary>摘要</summary>
我们介绍了HANDAL数据集，用于分类水平对象pose估计和可行预测。与前一代数据集不同，我们的数据集专注于适用于机器人搅拌的可搅拌物品，包括锤子、工具和螺丝driver等，它们具有适合机器人搅拌的尺寸和形状。我们的注释过程涉及了单一的商业摄像头和半自动化处理，使得我们可以生成高质量3D注释而无需咨询大量人员。数据集包含308万个注释图像帧，来自2.2万个视频，212种实际世界中的 объек。我们专注于硬件和厨房工具对象，以便在机器人搅拌需要与环境进行实际交互的场景中进行研究。我们详细介绍了我们数据集的用途，包括6个自由度分类pose+scale估计和相关任务。我们还提供了所有物品的3D重建模型，并详细介绍了数据集收集的一些瓶颈。
</details></li>
</ul>
<hr>
<h2 id="DLSIA-Deep-Learning-for-Scientific-Image-Analysis"><a href="#DLSIA-Deep-Learning-for-Scientific-Image-Analysis" class="headerlink" title="DLSIA: Deep Learning for Scientific Image Analysis"></a>DLSIA: Deep Learning for Scientific Image Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02559">http://arxiv.org/abs/2308.02559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric J Roberts, Tanny Chavez, Alexander Hexemer, Petrus H. Zwart</li>
<li>for: 科研图像分析（Scientific Image Analysis）</li>
<li>methods: 使用Python编程语言、 convolutional neural network（CNN） architecture、autoencoders、U-Nets、MSDNets、Sparse Mixed-Scale Networks（SMSNets）等方法。</li>
<li>results: 提供可定制的CNN建模、抽象CNN复杂性、促进科研发现、促进交叉领域合作、驱动科研图像分析等。<details>
<summary>Abstract</summary>
We introduce DLSIA (Deep Learning for Scientific Image Analysis), a Python-based machine learning library that empowers scientists and researchers across diverse scientific domains with a range of customizable convolutional neural network (CNN) architectures for a wide variety of tasks in image analysis to be used in downstream data processing, or for experiment-in-the-loop computing scenarios. DLSIA features easy-to-use architectures such as autoencoders, tunable U-Nets, and parameter-lean mixed-scale dense networks (MSDNets). Additionally, we introduce sparse mixed-scale networks (SMSNets), generated using random graphs and sparse connections. As experimental data continues to grow in scale and complexity, DLSIA provides accessible CNN construction and abstracts CNN complexities, allowing scientists to tailor their machine learning approaches, accelerate discoveries, foster interdisciplinary collaboration, and advance research in scientific image analysis.
</details>
<details>
<summary>摘要</summary>
我们介绍DLSIA（深度学习科学影像分析），这是一个基于Python的机器学习库，它为科学家和研究人员提供了许多可自定义的卷积神经网络架构，用于各种影像分析任务，包括下游资料处理和实验运行 Computing enario。DLSIA 提供了易于使用的架构，例如自动编码器、可调 U-Net 和对数零对数网络（MSDNets）。此外，我们还引入了随机 Graph 和稀疏连接的稀疏混合网络（SMSNets）。随着实验数据的数量和复杂度不断增加，DLSIA 提供了可 accessible CNN 的建构和抽象，让科学家可以根据自己的机器学习方法，加速发现，促进跨领域合作，并进步科学影像分析研究。
</details></li>
</ul>
<hr>
<h2 id="COVID-VR-A-Deep-Learning-COVID-19-Classification-Model-Using-Volume-Rendered-Computer-Tomography"><a href="#COVID-VR-A-Deep-Learning-COVID-19-Classification-Model-Using-Volume-Rendered-Computer-Tomography" class="headerlink" title="COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography"></a>COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01433">http://arxiv.org/abs/2308.01433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noemi Maritza L. Romero, Ricco Vasconcellos, Mariana R. Mendoza, João L. D. Comba</li>
<li>for: 本研究旨在开发一种基于多视角Volume Rendering（VR）技术的肺疾病分类方法，以提供全面的肺部图像，并提高肺疾病识别的准确率。</li>
<li>methods: 本研究使用了深度学习模型，利用CT扫描图像作为输入，通过Volume Rendering技术生成多视角的肺部图像，并对这些图像进行分类。</li>
<li>results: 对比于传统的slice-based方法，本研究的方法能够更好地识别肺疾病，并且在使用私有数据和公共数据进行比较时，得到了相似的结果。<details>
<summary>Abstract</summary>
The COVID-19 pandemic presented numerous challenges to healthcare systems worldwide. Given that lung infections are prevalent among COVID-19 patients, chest Computer Tomography (CT) scans have frequently been utilized as an alternative method for identifying COVID-19 conditions and various other types of pulmonary diseases. Deep learning architectures have emerged to automate the identification of pulmonary disease types by leveraging CT scan slices as inputs for classification models. This paper introduces COVID-VR, a novel approach for classifying pulmonary diseases based on volume rendering images of the lungs captured from multiple angles, thereby providing a comprehensive view of the entire lung in each image. To assess the effectiveness of our proposal, we compared it against competing strategies utilizing both private data obtained from partner hospitals and a publicly available dataset. The results demonstrate that our approach effectively identifies pulmonary lesions and performs competitively when compared to slice-based methods.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行对全球医疗系统带来了很多挑战。由于封颈感染是 COVID-19 患者的常见症状，胸部计算机扫描（CT）扫描得到了广泛的应用，以确定 COVID-19 状况和其他类型的肺病。深度学习建筑在扫描肺部的 CT 扫描片中进行自动识别肺病类型。本文介绍了 COVID-VR，一种基于肺部体积渲染图像的新方法，以获取整个肺部的全面视图。为评估我们的提议效果，我们与合作医院提供的私人数据进行比较，以及公共可用的数据集。结果表明，我们的方法可以有效地识别肺病涂抹，并与 slice-based 方法相比竞争性强。
</details></li>
</ul>
<hr>
<h2 id="LiDAR-View-Synthesis-for-Robust-Vehicle-Navigation-Without-Expert-Labels"><a href="#LiDAR-View-Synthesis-for-Robust-Vehicle-Navigation-Without-Expert-Labels" class="headerlink" title="LiDAR View Synthesis for Robust Vehicle Navigation Without Expert Labels"></a>LiDAR View Synthesis for Robust Vehicle Navigation Without Expert Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01424">http://arxiv.org/abs/2308.01424</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jonathsch/lidar-synthesis">https://github.com/jonathsch/lidar-synthesis</a></li>
<li>paper_authors: Jonathan Schmidt, Qadeer Khan, Daniel Cremers</li>
<li>for: 本研究旨在提供一种使用LiDAR扫描仪生成更多的训练数据集，以便在公共道路上安全地自动驾驶汽车。</li>
<li>methods: 本研究使用 mesh reconstruction 和 ray casting 技术生成更多的 LiDAR 点云，而无需实际驾驶车辆到危险位置。然后，使用深度学习模型，将 LiDAR 扫描结果作为输入，预测未来的车辆轨迹。最后，应用 waypoint controller 将预测轨迹与车辆的加速和转向标签相匹配。</li>
<li>results: 研究人员通过在线评估和与同期工作进行比较，证明了我们的方法的效iveness。特别是在模型稳定性方面，我们的方法具有显著的优势。项目页面：<a target="_blank" rel="noopener" href="https://jonathsch.github.io/lidar-synthesis/">https://jonathsch.github.io/lidar-synthesis/</a><details>
<summary>Abstract</summary>
Deep learning models for self-driving cars require a diverse training dataset to manage critical driving scenarios on public roads safely. This includes having data from divergent trajectories, such as the oncoming traffic lane or sidewalks. Such data would be too dangerous to collect in the real world. Data augmentation approaches have been proposed to tackle this issue using RGB images. However, solutions based on LiDAR sensors are scarce. Therefore, we propose synthesizing additional LiDAR point clouds from novel viewpoints without physically driving at dangerous positions. The LiDAR view synthesis is done using mesh reconstruction and ray casting. We train a deep learning model, which takes a LiDAR scan as input and predicts the future trajectory as output. A waypoint controller is then applied to this predicted trajectory to determine the throttle and steering labels of the ego-vehicle. Our method neither requires expert driving labels for the original nor the synthesized LiDAR sequence. Instead, we infer labels from LiDAR odometry. We demonstrate the effectiveness of our approach in a comprehensive online evaluation and with a comparison to concurrent work. Our results show the importance of synthesizing additional LiDAR point clouds, particularly in terms of model robustness. Project page: https://jonathsch.github.io/lidar-synthesis/
</details>
<details>
<summary>摘要</summary>
深度学习模型 для自驾车需要一个多样化的训练集，以确保在公共道路上安全地处理潜在危险的驾驶场景。这包括有 divergent 的轨迹，如对向道或人行道。然而，收集这些数据在实际世界中是太危险的。为解决这个问题，提出了使用 RGB 图像的数据增强方法。然而，基于 LiDAR 探测器的解决方案很少。因此，我们提议通过 mesh 重建和射线投影来生成额外的 LiDAR 点云。我们用一个深度学习模型，该模型从 LiDAR 扫描输入得到未来轨迹的预测结果。然后，我们应用一个 waypoint 控制器来确定 egocar 的加速和转向标签。我们的方法不需要原始 LiDAR 序列的专家驾驶标签，也不需要生成的 LiDAR 序列的专家标签。相反，我们从 LiDAR 速度来推断标签。我们在线评估中进行了全面的评估，并与当前的工作进行比较。我们的结果表明，生成额外的 LiDAR 点云对模型的稳定性具有重要作用。项目页面：https://jonathsch.github.io/lidar-synthesis/
</details></li>
</ul>
<hr>
<h2 id="Harder-synthetic-anomalies-to-improve-OoD-detection-in-Medical-Images"><a href="#Harder-synthetic-anomalies-to-improve-OoD-detection-in-Medical-Images" class="headerlink" title="Harder synthetic anomalies to improve OoD detection in Medical Images"></a>Harder synthetic anomalies to improve OoD detection in Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01412">http://arxiv.org/abs/2308.01412</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snavalm/mood22">https://github.com/snavalm/mood22</a></li>
<li>paper_authors: Sergio Naval Marimont, Giacomo Tarroni</li>
<li>for: 本研究旨在提高医学图像分割网络的泛化能力，使其能够在不同类型的异常情况下保持高度的准确率。</li>
<li>methods: 本研究使用了在2020年MOOD挑战赛中赢得奖的基于 Synthetic Local Anomaly (SLA) 的方法，并进一步改进了Synthetic anomaly生成过程，使它们更加多样化和挑战性。</li>
<li>results: 本研究在2022年MOOD挑战赛中获得了sample-wise和pixel-wise任务的首位， demonstrating the effectiveness of our method in improving the generalization ability of medical image segmentation networks.<details>
<summary>Abstract</summary>
Our method builds upon previous Medical Out-of-Distribution (MOOD) challenge winners that empirically show that synthetic local anomalies generated copying / interpolating foreign patches are useful to train segmentation networks able to generalize to unseen types of anomalies. In terms of the synthetic anomaly generation process, our contributions makes synthetic anomalies more heterogeneous and challenging by 1) using random shapes instead of squares and 2) smoothing the interpolation edge of anomalies so networks cannot rely on the high gradient between image - foreign patch to identify anomalies. Our experiments using the validation set of 2020 MOOD winners show that both contributions improved substantially the method performance. We used a standard 3D U-Net architecture as segmentation network, trained patch-wise in both brain and abdominal datasets. Our final challenge submission consisted of 10 U-Nets trained across 5 data folds with different configurations of the anomaly generation process. Our method achieved first position in both sample-wise and pixel-wise tasks in the 2022 edition of the Medical Out-of-Distribution held at MICCAI.
</details>
<details>
<summary>摘要</summary>
我们的方法建立在前一个医学异常（MOOD）挑战赛中赢家的基础上，这些赢家实证表明，通过复制/ interpolate 外部质 patches 生成的 synthetic local anomalies 可以帮助训练检测网络，以便在未经见过的异常类型上进行检测。在 synthetic anomaly 生成过程中，我们的贡献使 synthetic anomalies 更加多样和挑战性，包括：1. 使用随机形状而非方正形，2. 平滑 interpolate 边缘，以防止网络通过高Gradient между图像和外部质 patch 来识别异常。我们的实验使用 2020 MOOD 赛 validate set 表明，这两个贡献都有所提高了方法的性能。我们使用标准的 3D U-Net 架构作为检测网络，在脑和腹部数据集上进行 patch-wise 训练。我们的最终挑战提交包括 10 个 U-Nets 在 5 个数据叠加上不同的异常生成过程配置上进行训练。我们的方法在 2022 年的医学异常挑战中取得了 sample-wise 和 pixel-wise 两个任务中的第一名。
</details></li>
</ul>
<hr>
<h2 id="Follow-the-Soldiers-with-Optimized-Single-Shot-Multibox-Detection-and-Reinforcement-Learning"><a href="#Follow-the-Soldiers-with-Optimized-Single-Shot-Multibox-Detection-and-Reinforcement-Learning" class="headerlink" title="Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning"></a>Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01389">http://arxiv.org/abs/2308.01389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jumman Hossain, Maliha Momtaz</li>
<li>for: 建立一个自动驾驶系统，跟踪特定人（这里是士兵）在任何方向移动。</li>
<li>methods: 使用深度汽车和强化学习模型。</li>
<li>results: SSD Lite 提供了较好的性能和大幅提高的测试速度（约2-3倍），并且不损害准确性。<details>
<summary>Abstract</summary>
Nowadays, autonomous cars are gaining traction due to their numerous potential applications on battlefields and in resolving a variety of other real-world challenges. The main goal of our project is to build an autonomous system using DeepRacer which will follow a specific person (for our project, a soldier) when they will be moving in any direction. Two main components to accomplish this project is an optimized Single-Shot Multibox Detection (SSD) object detection model and a Reinforcement Learning (RL) model. We accomplished the task using SSD Lite instead of SSD and at the end, compared the results among SSD, SSD with Neural Computing Stick (NCS), and SSD Lite. Experimental results show that SSD Lite gives better performance among these three techniques and exhibits a considerable boost in inference speed (~2-3 times) without compromising accuracy.
</details>
<details>
<summary>摘要</summary>
现在，自适应汽车正在得到推广，因为它们在战场和解决各种实际问题上具有广泛的应用前景。我们项目的主要目标是使用DeepRacer建立一个自动驾驶系统，该系统能跟踪一名士兵（在我们项目中）在任何方向移动时。我们项目的两个主要组成部分是优化单幅多框检测（SSD）模型和再征学习（RL）模型。我们使用SSD Lite而不是SSD，并在结尾对这三种技术进行比较。实验结果表明，SSD Lite在这三种技术中表现最佳，并且在执行速度方面表现出了明显的提升（约2-3倍）而无需牺牲准确性。
</details></li>
</ul>
<hr>
<h2 id="Computational-Long-Exposure-Mobile-Photography"><a href="#Computational-Long-Exposure-Mobile-Photography" class="headerlink" title="Computational Long Exposure Mobile Photography"></a>Computational Long Exposure Mobile Photography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01379">http://arxiv.org/abs/2308.01379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Tabellion, Nikhil Karnad, Noa Glaser, Ben Weiss, David E. Jacobs, Yael Pritch</li>
<li>for: 这篇论文是关于 computational burst photography system，用于实现长时间拍摄和运动融合的效果。</li>
<li>methods: 该系统使用了对象检测和分割、Scene motion tracking、多帧合成等技术来实现运动融合和长时间拍摄的效果。</li>
<li>results: 该系统可以自动地在手持式智能手机摄像头应用程序中实现运动融合和长时间拍摄的效果，并且可以保持图像的高分辨率和高动态范围。<details>
<summary>Abstract</summary>
Long exposure photography produces stunning imagery, representing moving elements in a scene with motion-blur. It is generally employed in two modalities, producing either a foreground or a background blur effect. Foreground blur images are traditionally captured on a tripod-mounted camera and portray blurred moving foreground elements, such as silky water or light trails, over a perfectly sharp background landscape. Background blur images, also called panning photography, are captured while the camera is tracking a moving subject, to produce an image of a sharp subject over a background blurred by relative motion. Both techniques are notoriously challenging and require additional equipment and advanced skills. In this paper, we describe a computational burst photography system that operates in a hand-held smartphone camera app, and achieves these effects fully automatically, at the tap of the shutter button. Our approach first detects and segments the salient subject. We track the scene motion over multiple frames and align the images in order to preserve desired sharpness and to produce aesthetically pleasing motion streaks. We capture an under-exposed burst and select the subset of input frames that will produce blur trails of controlled length, regardless of scene or camera motion velocity. We predict inter-frame motion and synthesize motion-blur to fill the temporal gaps between the input frames. Finally, we composite the blurred image with the sharp regular exposure to protect the sharpness of faces or areas of the scene that are barely moving, and produce a final high resolution and high dynamic range (HDR) photograph. Our system democratizes a capability previously reserved to professionals, and makes this creative style accessible to most casual photographers.   More information and supplementary material can be found on our project webpage: https://motion-mode.github.io/
</details>
<details>
<summary>摘要</summary>
长时间拍摄可以生成吸引人的图像，通过运动模糊来表现场景中运动元素。通常有两种模式：前景模式和背景模式。前景模式拍摄的图像通常在静止的摄像机上拍摄，捕捉了运动的前景元素，如水或光梯，与静止的背景景象一起呈现。背景模式拍摄的图像通常在跟踪运动目标的同时拍摄，以生成一个锐化的主题图像，与运动背景模糊的效果。两种技术都是非常具有挑战性，需要额外的设备和高级技能。在这篇论文中，我们描述了一种基于智能手机摄像机应用程序的计算拍摄系统，可以自动实现这些效果，只需要单击拍摄按钮。我们的方法首先检测和分割主题元素。我们跟踪场景运动，并将多帧图像对齐以保持愿望的锐化和生成美观的运动梯度。我们捕捉具有控制长度的下采样，无论场景或摄像机运动速度。我们预测帧间运动，并使用Synthesize动作模糊填充时间间隔。最后，我们将模糊图像与锐化正常曝光图像 composite，以保护面孔或动作较少的场景区域的锐化，并生成高分辨率和高动态范围的图像。我们的系统将这种创新技术普及化，让大多数优秀摄影家能够轻松地实现这种创新风格。更多信息和补充材料可以在我们项目网站中找到：<https://motion-mode.github.io/>
</details></li>
</ul>
<hr>
<h2 id="ELIXR-Towards-a-general-purpose-X-ray-artificial-intelligence-system-through-alignment-of-large-language-models-and-radiology-vision-encoders"><a href="#ELIXR-Towards-a-general-purpose-X-ray-artificial-intelligence-system-through-alignment-of-large-language-models-and-radiology-vision-encoders" class="headerlink" title="ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders"></a>ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01317">http://arxiv.org/abs/2308.01317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shawn Xu, Lin Yang, Christopher Kelly, Marcin Sieniek, Timo Kohlberger, Martin Ma, Wei-Hung Weng, Attila Kiraly, Sahar Kazemzadeh, Zakkai Melamed, Jungyeon Park, Patricia Strachan, Yun Liu, Chuck Lau, Preeti Singh, Christina Chen, Mozziyar Etemadi, Sreenivasa Raju Kalidindi, Yossi Matias, Katherine Chou, Greg S. Corrado, Shravya Shetty, Daniel Tse, Shruthi Prabhakara, Daniel Golden, Rory Pilgrim, Krish Eswaran, Andrew Sellergren<br>for:* 这个研究旨在开发一个具有广泛应用能力的语言&#x2F;图像同步类型（ELIXR），用于进行胸部X射像（CXR）分类、数据有效分类和semantic搜寻等多种任务。methods:* 这个研究使用了一个语言同步图像编码器，与固定的语言模型PaLM 2结合，实现了一个轻量级的适配器架构。* 研究使用了MIMIC-CXR dataset上的图像和相应的自由文本医学报告进行训练。results:* ELIXR在零shot胸部X射像（CXR）分类中实现了state-of-the-art性能（mean AUC of 0.850 across 13 findings）。* ELIXR在数据有效CXR分类中实现了高性能（mean AUCs of 0.893 and 0.898 across five findings），并在几个不同的数据量下进行了比较（1%、10%）。* ELIXR在semantic搜寻任务中实现了0.76的normalized discounted cumulative gain（NDCG），包括了一些完美的回答。<details>
<summary>Abstract</summary>
Our approach, which we call Embeddings for Language/Image-aligned X-Rays, or ELIXR, leverages a language-aligned image encoder combined or grafted onto a fixed LLM, PaLM 2, to perform a broad range of tasks. We train this lightweight adapter architecture using images paired with corresponding free-text radiology reports from the MIMIC-CXR dataset. ELIXR achieved state-of-the-art performance on zero-shot chest X-ray (CXR) classification (mean AUC of 0.850 across 13 findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898 across five findings (atelectasis, cardiomegaly, consolidation, pleural effusion, and pulmonary edema) for 1% (~2,200 images) and 10% (~22,000 images) training data), and semantic search (0.76 normalized discounted cumulative gain (NDCG) across nineteen queries, including perfect retrieval on twelve of them). Compared to existing data-efficient methods including supervised contrastive learning (SupCon), ELIXR required two orders of magnitude less data to reach similar performance. ELIXR also showed promise on CXR vision-language tasks, demonstrating overall accuracies of 58.7% and 62.5% on visual question answering and report quality assurance tasks, respectively. These results suggest that ELIXR is a robust and versatile approach to CXR AI.
</details>
<details>
<summary>摘要</summary>
我们的方法，我们称之为语言/图像对齐X射线（ELIXR），利用一个语言对齐图像编码器与固定的自然语言处理模型（PaLM 2）结合，以实现广泛的任务。我们使用图像和相应的自由文本医学报告从MIMIC-CXR数据集进行训练这个轻量级适配器建筑。ELIXR在零shot肺X射线（CXR）分类中达到了状态元的性能（平均AUC为0.850，涵盖13个发现），以及数据效率CXR分类（平均AUC为0.893和0.898，涵盖五个发现（肿瘤、心脏肥大、混合、肺液和肺血液）），并在semantic搜索中达到了0.76减少积分率（NDCG）。相比现有的数据效率方法，包括supervised contrastive learning（SupCon），ELIXR需要两个数据量级下降到达到类似性能。此外，ELIXR还在CXR视言语任务中表现出了承诺，其总准确率为58.7%和62.5%。这些结果表明ELIXR是一种强大和多功能的CXR AI方法。
</details></li>
</ul>
<hr>
<h2 id="Patched-Denoising-Diffusion-Models-For-High-Resolution-Image-Synthesis"><a href="#Patched-Denoising-Diffusion-Models-For-High-Resolution-Image-Synthesis" class="headerlink" title="Patched Denoising Diffusion Models For High-Resolution Image Synthesis"></a>Patched Denoising Diffusion Models For High-Resolution Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01316">http://arxiv.org/abs/2308.01316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheng Ding, Mengqi Zhang, Jiajun Wu, Zhuowen Tu</li>
<li>for: 生成高分辨率图像（例如1024×512）</li>
<li>methods: 使用小尺寸图像块（例如64×64）进行训练，并使用新的特征质料策略来避免边缘artefact</li>
<li>results: 在自然图像集（1024×512）和标准的小尺寸图像集（256×256）上实现高质量图像生成，并在所有四个数据集上达到了当前最佳FID分数。同时，Patch-DM还比 классиic diffusion模型减少了内存复杂度。<details>
<summary>Abstract</summary>
We propose an effective denoising diffusion model for generating high-resolution images (e.g., 1024$\times$512), trained on small-size image patches (e.g., 64$\times$64). We name our algorithm Patch-DM, in which a new feature collage strategy is designed to avoid the boundary artifact when synthesizing large-size images. Feature collage systematically crops and combines partial features of the neighboring patches to predict the features of a shifted image patch, allowing the seamless generation of the entire image due to the overlap in the patch feature space. Patch-DM produces high-quality image synthesis results on our newly collected dataset of nature images (1024$\times$512), as well as on standard benchmarks of smaller sizes (256$\times$256), including LSUN-Bedroom, LSUN-Church, and FFHQ. We compare our method with previous patch-based generation methods and achieve state-of-the-art FID scores on all four datasets. Further, Patch-DM also reduces memory complexity compared to the classic diffusion models.
</details>
<details>
<summary>摘要</summary>
我们提出一种有效的杂噪扩散模型，用于生成高分辨率图像（例如1024×512），基于小尺寸图像块（例如64×64）进行训练。我们命名该算法为“Patch-DM”，其中我们设计了一种新的特征贯通策略，以避免边缘artefact when Synthesizing large-size images。特征贯通系统系统地剪辑并组合邻近块的部分特征，以预测shifted image块的特征，从而实现了整个图像的无缝生成，因为邻近块特征空间之间存在 overlap。Patch-DM生成了高质量的图像合成结果在我们新收集的自然图像 dataset（1024×512）上，以及标准的小尺寸 benchmark（256×256）上，包括LSUN-Bedroom、LSUN-Church和FFHQ。我们与前期的patch-based生成方法进行比较，并在所有四个 dataset上实现了状态的方程FID scores。此外，Patch-DM还降低了传统扩散模型的内存复杂性。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-DETR-Pre-training-for-Object-Detection"><a href="#Revisiting-DETR-Pre-training-for-Object-Detection" class="headerlink" title="Revisiting DETR Pre-training for Object Detection"></a>Revisiting DETR Pre-training for Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01300">http://arxiv.org/abs/2308.01300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Ma, Weicong Liang, Yiduo Hao, Bohan Chen, Xiangyu Yue, Chao Zhang, Yuhui Yuan</li>
<li>for: 本研究目的是研究如何通过自动学习的方式提高DETR基础模型的性能，而不需要更改其底层结构。</li>
<li>methods: 本研究使用了多种自动学习方法，包括DETReg和LLaVA等。</li>
<li>results: 研究发现，使用这些自动学习方法可以提高COCO物体检测任务的性能，并且可以超越最新的State-of-the-art模型。 Specifically, the authors achieved an AP of $59.3%$ on the COCO val set, surpassing the previous state-of-the-art model by $1.4%$. Additionally, the authors generated a series of synthetic pre-training datasets and demonstrated that pre-training on these datasets can lead to notable improvements in object detection performance.<details>
<summary>Abstract</summary>
Motivated by that DETR-based approaches have established new records on COCO detection and segmentation benchmarks, many recent endeavors show increasing interest in how to further improve DETR-based approaches by pre-training the Transformer in a self-supervised manner while keeping the backbone frozen. Some studies already claimed significant improvements in accuracy. In this paper, we take a closer look at their experimental methodology and check if their approaches are still effective on the very recent state-of-the-art such as $\mathcal{H}$-Deformable-DETR. We conduct thorough experiments on COCO object detection tasks to study the influence of the choice of pre-training datasets, localization, and classification target generation schemes. Unfortunately, we find the previous representative self-supervised approach such as DETReg, fails to boost the performance of the strong DETR-based approaches on full data regimes. We further analyze the reasons and find that simply combining a more accurate box predictor and Objects$365$ benchmark can significantly improve the results in follow-up experiments. We demonstrate the effectiveness of our approach by achieving strong object detection results of AP=$59.3\%$ on COCO val set, which surpasses $\mathcal{H}$-Deformable-DETR + Swin-L by +$1.4\%$. Last, we generate a series of synthetic pre-training datasets by combining the very recent image-to-text captioning models (LLaVA) and text-to-image generative models (SDXL). Notably, pre-training on these synthetic datasets leads to notable improvements in object detection performance. Looking ahead, we anticipate substantial advantages through the future expansion of the synthetic pre-training dataset.
</details>
<details>
<summary>摘要</summary>
基于DETR的方法在COCO检测和 segmentation  bencmarks 上设置新的纪录，许多最近的尝试表示越来越关注如何进一步提高DETR基于的方法，而不是固定背景。一些研究已经提出了显著改进的精度。在这篇文章中，我们坚持更加仔细地检查这些实验方法，并查看它们是否在最新的state-of-the-art 中如 $\mathcal{H}$-Deformable-DETR 中保持有效。我们在COCO对象检测任务中进行了系统的实验，以研究预训练数据集的选择、本地化和分类目标生成方案的影响。不幸地，我们发现以前的代表性自我超vised 方法DETReg，在全数据场景下不能提高强大 DE TR-based 方法的性能。我们进一步分析了原因，并发现可以通过结合更高精度的包Predictor和Objects$365$ benchmark来显著提高结果。我们证明了我们的方法的效果，通过在COCO验证集上达到 AP = $59.3\%$ 的强大对象检测结果，超过 $\mathcal{H}$-Deformable-DETR + Swin-L 的 + $1.4\%$。最后，我们生成了一系列的Synthetic pre-training datasets，通过结合最近的图文描述模型（LLaVA）和文本到图生成模型（SDXL）。不凡地，预训练在这些Synthetic datasets上显著提高了对象检测性能。looking ahead，我们预计将来的扩展将带来重要的优势。
</details></li>
</ul>
<hr>
<h2 id="A-vision-transformer-based-framework-for-knowledge-transfer-from-multi-modal-to-mono-modal-lymphoma-subtyping-models"><a href="#A-vision-transformer-based-framework-for-knowledge-transfer-from-multi-modal-to-mono-modal-lymphoma-subtyping-models" class="headerlink" title="A vision transformer-based framework for knowledge transfer from multi-modal to mono-modal lymphoma subtyping models"></a>A vision transformer-based framework for knowledge transfer from multi-modal to mono-modal lymphoma subtyping models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01328">http://arxiv.org/abs/2308.01328</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bilel Guetarni, Feryal Windal, Halim Benhabiles, Marianne Petit, Romain Dubois, Emmanuelle Leteurtre, Dominique Collard</li>
<li>for: 本研究旨在提出一种基于视Transformer的框架，用于从高分辨率整图中分类Diffuse Large B-Cell Lymphoma（DLBCL）癌症subtype。</li>
<li>methods: 我们提议一种多模式 architecture来训练一个分类模型，从多种整图模式中提取特征。然后，我们通过知识传播机制来高效地驱动这个分类模型的学习。</li>
<li>results: 我们在一个包含157个病例的实验study中发现，我们的单模式分类模型的表现非常出色，比六个最新的抗癌方法更高效。此外，我们对实验数据进行了power-law曲线估算，结果表明，我们的分类模型需要一个合理的数量的更多病例来进行训练，以达到与IHC技术相同的诊断精度。<details>
<summary>Abstract</summary>
Determining lymphoma subtypes is a crucial step for better patients treatment targeting to potentially increase their survival chances. In this context, the existing gold standard diagnosis method, which is based on gene expression technology, is highly expensive and time-consuming making difficult its accessibility. Although alternative diagnosis methods based on IHC (immunohistochemistry) technologies exist (recommended by the WHO), they still suffer from similar limitations and are less accurate. WSI (Whole Slide Image) analysis by deep learning models showed promising new directions for cancer diagnosis that would be cheaper and faster than existing alternative methods. In this work, we propose a vision transformer-based framework for distinguishing DLBCL (Diffuse Large B-Cell Lymphoma) cancer subtypes from high-resolution WSIs. To this end, we propose a multi-modal architecture to train a classifier model from various WSI modalities. We then exploit this model through a knowledge distillation mechanism for efficiently driving the learning of a mono-modal classifier. Our experimental study conducted on a dataset of 157 patients shows the promising performance of our mono-modal classification model, outperforming six recent methods from the state-of-the-art dedicated for cancer classification. Moreover, the power-law curve, estimated on our experimental data, shows that our classification model requires a reasonable number of additional patients for its training to potentially reach identical diagnosis accuracy as IHC technologies.
</details>
<details>
<summary>摘要</summary>
确定淋巴癌 subclass 是诊断患者治疗的关键步骤，以提高生存可能性。然而，现有的黄金标准诊断方法，基于基因表达技术，是非常昂贵和时间consuming，使其Difficult to access。尽管现有基于 IHC（免疫抗体技术）的诊断方法存在，但它们仍然受到限制，并且精度较低。WSI（整个板块图像）分析by deep learning模型显示了新的方向 для肿瘤诊断，这将比现有的alternative方法更便宜和更快。在这项工作中，我们提出了基于视Transformer的框架，用于从高分辨率 WSI 中分类Diffuse Large B-Cell Lymphoma（淋巴癌）亚型。为此，我们提出了一种多modal architecture，用于训练一个分类模型。然后，我们利用知识储存机制，将这个模型转化为一个简单的单modal分类器。我们的实验研究，在一个包含 157 名病人的数据集上进行，显示了我们的单modal分类模型在诊断性能方面的优秀表现，比六个最新的state-of-the-art肿瘤分类方法更高。此外，我们在实验数据上计算的力量律曲线，表明我们的分类模型需要一个合理的数量的更多病人来进行训练，以达到与 IHC 技术相同的诊断精度。
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Season-and-Solar-Specificity-into-Renderings-made-by-a-NeRF-Architecture-using-Satellite-Images"><a href="#Incorporating-Season-and-Solar-Specificity-into-Renderings-made-by-a-NeRF-Architecture-using-Satellite-Images" class="headerlink" title="Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images"></a>Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01262">http://arxiv.org/abs/2308.01262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/enterprisecv-6/season-nerf">https://github.com/enterprisecv-6/season-nerf</a></li>
<li>paper_authors: Michael Gableman, Avinash Kak</li>
<li>for: 这篇论文的目的是提出一种基于NeRF的渲染框架，可以根据卫星图像进行训练，并考虑太阳角度和视角角度来渲染场景从不同的视角。</li>
<li>methods: 该论文使用Neural Radiance Field（NeRF）来模型场景的光照和阴影，并在NeRF中引入一个新的输入变量——年份，以教育网络render seasonal features。</li>
<li>results: 作者在八个Area of Interest中测试了他们的框架，并获得了高精度的渲染、高精度的高度图和预测阴影等结果。此外，作者还进行了ablation study，以 justify network design parameters。<details>
<summary>Abstract</summary>
As a result of Shadow NeRF and Sat-NeRF, it is possible to take the solar angle into account in a NeRF-based framework for rendering a scene from a novel viewpoint using satellite images for training. Our work extends those contributions and shows how one can make the renderings season-specific. Our main challenge was creating a Neural Radiance Field (NeRF) that could render seasonal features independently of viewing angle and solar angle while still being able to render shadows. We teach our network to render seasonal features by introducing one more input variable -- time of the year. However, the small training datasets typical of satellite imagery can introduce ambiguities in cases where shadows are present in the same location for every image of a particular season. We add additional terms to the loss function to discourage the network from using seasonal features for accounting for shadows. We show the performance of our network on eight Areas of Interest containing images captured by the Maxar WorldView-3 satellite. This evaluation includes tests measuring the ability of our framework to accurately render novel views, generate height maps, predict shadows, and specify seasonal features independently from shadows. Our ablation studies justify the choices made for network design parameters.
</details>
<details>
<summary>摘要</summary>
due to Shadow NeRF and Sat-NeRF, it is possible to take the solar angle into account in a NeRF-based framework for rendering a scene from a novel viewpoint using satellite images for training. Our work extends those contributions and shows how one can make the renderings season-specific. Our main challenge was creating a Neural Radiance Field (NeRF) that could render seasonal features independently of viewing angle and solar angle while still being able to render shadows. We teach our network to render seasonal features by introducing one more input variable -- time of the year. However, the small training datasets typical of satellite imagery can introduce ambiguities in cases where shadows are present in the same location for every image of a particular season. We add additional terms to the loss function to discourage the network from using seasonal features for accounting for shadows. We show the performance of our network on eight Areas of Interest containing images captured by the Maxar WorldView-3 satellite. This evaluation includes tests measuring the ability of our framework to accurately render novel views, generate height maps, predict shadows, and specify seasonal features independently from shadows. Our ablation studies justify the choices made for network design parameters.Here's the translation in Traditional Chinese:这是由于阴影NeRF和Sat-NeRF而可以将太阳角度考虑到NeRF基础框架中，以便从不同观点测量场景。我们的工作延伸了这些贡献，并显示了如何使渲染为季节特定。我们的主要挑战是创建一个能够独立地考虑观察角度和太阳角度的Neural Radiance Field（NeRF），并且仍能正确地显示阴影。我们教育我们的网络以时间年份为输入变量，以便在不同季节中显示季节特定的特征。然而，对于具有阴影的几何形状的实际测试数据可能会导致歧义。我们添加了额外的损失函数来防止网络使用季节特定的特征来计算阴影。我们在八个Area of Interest中展示了我们的网络，包括量测系统在不同观点下的渲染新视野、生成高度图、预测阴影和季节特定的特征独立于阴影。我们的ablation研究证明了我们的网络设计选择的正确性。
</details></li>
</ul>
<hr>
<h2 id="Learning-Spatial-Distribution-of-Long-Term-Trackers-Scores"><a href="#Learning-Spatial-Distribution-of-Long-Term-Trackers-Scores" class="headerlink" title="Learning Spatial Distribution of Long-Term Trackers Scores"></a>Learning Spatial Distribution of Long-Term Trackers Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01256">http://arxiv.org/abs/2308.01256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vincenzo Mariano Scarrica, Antonino Staiano</li>
<li>for: 这篇论文是为了提高长期跟踪性能而写的。</li>
<li>methods: 这篇论文使用了融合策略，将多个基线跟踪器作为输入，并在学习阶段对其进行了优化。</li>
<li>results: 在LTB-50数据集上，这篇论文的召回率为0.738，与当前状态前进行竞争。在反向使用VOT-LT2022和LTB-50数据集时，召回率为0.619，仍然在当前状态前进行竞争。<details>
<summary>Abstract</summary>
Long-Term tracking is a hot topic in Computer Vision. In this context, competitive models are presented every year, showing a constant growth rate in performances, mainly measured in standardized protocols as Visual Object Tracking (VOT) and Object Tracking Benchmark (OTB). Fusion-trackers strategy has been applied over last few years for overcoming the known re-detection problem, turning out to be an important breakthrough. Following this approach, this work aims to generalize the fusion concept to an arbitrary number of trackers used as baseline trackers in the pipeline, leveraging a learning phase to better understand how outcomes correlate with each other, even when no target is present. A model and data independence conjecture will be evidenced in the manuscript, yielding a recall of 0.738 on LTB-50 dataset when learning from VOT-LT2022, and 0.619 by reversing the two datasets. In both cases, results are strongly competitive with state-of-the-art and recall turns out to be the first on the podium.
</details>
<details>
<summary>摘要</summary>
长期跟踪是计算机视觉领域热点话题。在这个上下文中，每年都有竞争力强的模型被推出，表现得越来越好，主要根据标准化协议进行评估，如视觉 объекtracking（VOT）和物体跟踪benchmark（OTB）。遗传跟踪策略在过去几年得到应用，并被视为重要的突破。基于这种方法，本研究旨在普适化融合概念，使得任意数量的基线跟踪器可以在管道中使用，并通过学习阶段更好地理解不同跟踪器之间的结果相关性，即使target不存在。 manuscript中会证明模型和数据独立性 conjecture，在LTB-50 dataset上取得0.738的回归率，并在反向两个dataset上取得0.619的回归率。在两个情况下，结果强烈竞争与状态机器人，并且回归率处于第一名。
</details></li>
</ul>
<hr>
<h2 id="A-Hyper-pixel-wise-Contrastive-Learning-Augmented-Segmentation-Network-for-Old-Landslide-Detection-Using-High-Resolution-Remote-Sensing-Images-and-Digital-Elevation-Model-Data"><a href="#A-Hyper-pixel-wise-Contrastive-Learning-Augmented-Segmentation-Network-for-Old-Landslide-Detection-Using-High-Resolution-Remote-Sensing-Images-and-Digital-Elevation-Model-Data" class="headerlink" title="A Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images and Digital Elevation Model Data"></a>A Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images and Digital Elevation Model Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01251">http://arxiv.org/abs/2308.01251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Zhou, Yuexing Peng, Wei Li, Junchuan Yu, Daqing Ge, Wei Xiang</li>
<li>for: old landslide detection</li>
<li>methods: hyper-pixel-wise contrastive learning augmented segmentation network (HPCL-Net) and global hyper-pixel-wise sample pair queues-based contrastive learning method</li>
<li>results: improved reliability of old landslide detection compared to previous models, with increased mIoU, Landslide IoU, and F1-score metrics<details>
<summary>Abstract</summary>
As a harzard disaster, landslide often brings tremendous losses to humanity, so it's necessary to achieve reliable detection of landslide. However, the problems of visual blur and small-sized dataset cause great challenges for old landslide detection task when using remote sensing data. To reliably extract semantic features, a hyper-pixel-wise contrastive learning augmented segmentation network (HPCL-Net) is proposed, which augments the local salient feature extraction from the boundaries of landslides through HPCL and fuses the heterogeneous infromation in the semantic space from High-Resolution Remote Sensing Images and Digital Elevation Model Data data. For full utilization of the precious samples, a global hyper-pixel-wise sample pair queues-based contrastive learning method, which includes the construction of global queues that store hyper-pixel-wise samples and the updating scheme of a momentum encoder, is developed, reliably enhancing the extraction ability of semantic features. The proposed HPCL-Net is evaluated on a Loess Plateau old landslide dataset and experiment results show that the model greatly improves the reliablity of old landslide detection compared to the previous old landslide segmentation model, where mIoU metric is increased from 0.620 to 0.651, Landslide IoU metric is increased from 0.334 to 0.394 and F1-score metric is increased from 0.501 to 0.565.
</details>
<details>
<summary>摘要</summary>
翻译文本作为危险灾害，山崩常会对人类造成巨大的损害，因此需要实现可靠的山崩检测。然而，使用遥感数据时，视觉模糊和小样本集的问题会导致古老山崩检测任务中的巨大挑战。为了可靠地提取semantic特征，我们提议了一种基于hyper-pixel-wise对比学习增强segmentation网络（HPCL-Net），该网络通过在山崩边界的本地精重特征提取方法和高分辨率遥感图像和数字高程模型数据的异化信息进行semantic空间的笔记卷积。为了充分利用珍贵的样本，我们开发了一种全球hyper-pixel-wise对比学习方法，该方法包括建立全球队列，并且在批处理队列中进行快速更新的批处理编码器。实验结果表明，提议的HPCL-Net模型在中国Loess Plateau古老山崩数据集上进行检测比前一代古老山崩分割模型更高度可靠，其mIoU指标从0.620提高到0.651，山崩指标从0.334提高到0.394，F1-score指标从0.501提高到0.565。
</details></li>
</ul>
<hr>
<h2 id="A-Hybrid-Approach-To-Real-Time-Multi-Object-Tracking"><a href="#A-Hybrid-Approach-To-Real-Time-Multi-Object-Tracking" class="headerlink" title="A Hybrid Approach To Real-Time Multi-Object Tracking"></a>A Hybrid Approach To Real-Time Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01248">http://arxiv.org/abs/2308.01248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vincenzo Mariano Scarrica, Ciro Panariello, Alessio Ferone, Antonino Staiano</li>
<li>for: 这个论文主要目标是提出一种基于深度学习和经典算法的实时多目标跟踪方法，用于人群跟踪系统。</li>
<li>methods: 该方法 combinestraditional optical flow algorithm和深度学习架构，以实现一个具有折衔的跟踪精度和计算成本的权衡。</li>
<li>results: 对不同设置进行实验，该方法可以达到0.608的MOTA分数，与相关State-of-the-art的0.549分数相当，而且运行时间减少了约一半。<details>
<summary>Abstract</summary>
Multi-Object Tracking, also known as Multi-Target Tracking, is a significant area of computer vision that has many uses in a variety of settings. The development of deep learning, which has encouraged researchers to propose more and more work in this direction, has significantly impacted the scientific advancement around the study of tracking as well as many other domains related to computer vision. In fact, all of the solutions that are currently state-of-the-art in the literature and in the tracking industry, are built on top of deep learning methodologies that produce exceptionally good results. Deep learning is enabled thanks to the ever more powerful technology researchers can use to handle the significant computational resources demanded by these models. However, when real-time is a main requirement, developing a tracking system without being constrained by expensive hardware support with enormous computational resources is necessary to widen tracking applications in real-world contexts. To this end, a compromise is to combine powerful deep strategies with more traditional approaches to favor considerably lower processing solutions at the cost of less accurate tracking results even though suitable for real-time domains. Indeed, the present work goes in that direction, proposing a hybrid strategy for real-time multi-target tracking that combines effectively a classical optical flow algorithm with a deep learning architecture, targeted to a human-crowd tracking system exhibiting a desirable trade-off between performance in tracking precision and computational costs. The developed architecture was experimented with different settings, and yielded a MOTA of 0.608 out of the compared state-of-the-art 0.549 results, and about half the running time when introducing the optical flow phase, achieving almost the same performance in terms of accuracy.
</details>
<details>
<summary>摘要</summary>
多目标跟踪（也称多Target tracking）是计算机视觉领域的一个重要领域，它在各种场景中有很多应用。深度学习的发展，使研究人员们能够更加勇敢地提出更多的工作，对跟踪领域以及其他计算机视觉领域的科学进步产生了深远的影响。实际上，现有literature和industry中的所有state-of-the-art解决方案都基于深度学习方法，其Result exceptionally good。然而，当实时是主要要求时，建立一个不受昂贵硬件支持的跟踪系统是必要的，以拓宽跟踪应用在真实世界中。为此，可以通过结合强大的深度策略和传统方法来达成一个折衔，以提高跟踪精度的同时，降低计算成本。本工作就在这个方向上进行了尝试，提出了一种hybrid策略，将经典的光流算法与深度学习架构相结合，用于人群跟踪系统，实现了精度和计算成本之间的折衔。实验结果显示，与比较state-of-the-art的0.549结果相比，该系统的MOTA得分为0.608，运行时间缩短了约一半。
</details></li>
</ul>
<hr>
<h2 id="Tirtha-–-An-Automated-Platform-to-Crowdsource-Images-and-Create-3D-Models-of-Heritage-Sites"><a href="#Tirtha-–-An-Automated-Platform-to-Crowdsource-Images-and-Create-3D-Models-of-Heritage-Sites" class="headerlink" title="Tirtha – An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites"></a>Tirtha – An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01246">http://arxiv.org/abs/2308.01246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smlab-niser/tirtha-public">https://github.com/smlab-niser/tirtha-public</a></li>
<li>paper_authors: Jyotirmaya Shivottam, Subhankar Mishra</li>
<li>for: 保护文化遗产（CH）sites的数字化保存是非常重要，以防止自然灾害或人类活动的损害。</li>
<li>methods: 使用现代计算机视觉和光学测量技术，创建CH sites的3D模型。</li>
<li>results: 创建了一个Web平台，让普通公众通过投稿照片来创建CH sites的3D模型，提高了数字保存效率、成本效果和可持续性。<details>
<summary>Abstract</summary>
Digital preservation of Cultural Heritage (CH) sites is crucial to protect them against damage from natural disasters or human activities. Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry. However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries. Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage. To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques. It is modular, extensible and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances. Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment. In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images. These models are available for viewing, interaction, and download on the Tirtha website. Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains. Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries.
</details>
<details>
<summary>摘要</summary>
针对文化遗产（CH）场景的数字保存是非常重要，以保护它们免受自然灾害或人类活动的损害。创建CH场景的3D模型已成为数字保存的流行方法，感谢计算机视觉和光学测量的进步。然而，这个过程需要较长的时间，高昂的成本，通常需要专业设备和技能，这会对发展中国家 pose 挑战。此外，缺乏开放的3D模型存储库，限制了研究和公众对遗产的参与。为解决这些问题，我们提出了Tirtha，一个基于网络的平台，用于协同上传CH场景的图像。Tirtha利用当前最佳的结构从动（SfM）和多视图镜像（MVS）技术。它是可扩展的，可cost-effective，可以适应计算机视觉的进步。Tirtha通过Web界面提供，可以在本地部署或云端环境中部署。在我们的案例研究中，我们示例了在奥里萨（India）的寺庐场景中使用拍摄的图像创建3D模型。这些模型通过Tirtha网站上的浏览、互动和下载。我们的工作目标是提供一个由众所共同拍摄的图像和3D重建的数据集，用于计算机视觉、遗产保护和相关领域的研究。总之，Tirtha是一步向数字保存的民主化，特别是在发展中国家。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/cs.CV_2023_08_03/" data-id="clogy1z3d00f8ffrag2ck7xl5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/cs.AI_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T12:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/cs.AI_2023_08_03/">cs.AI - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-Capability-of-Large-Language-Models-to-Measure-Psychiatric-Functioning"><a href="#The-Capability-of-Large-Language-Models-to-Measure-Psychiatric-Functioning" class="headerlink" title="The Capability of Large Language Models to Measure Psychiatric Functioning"></a>The Capability of Large Language Models to Measure Psychiatric Functioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01834">http://arxiv.org/abs/2308.01834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isaac R. Galatzer-Levy, Daniel McDuff, Vivek Natarajan, Alan Karthikesalingam, Matteo Malgaroli</li>
<li>for:  This paper aims to investigate the ability of Large language models (LLMs) to predict psychiatric functioning from patient interviews and clinical descriptions without explicit training.</li>
<li>methods: The study uses Med-PaLM 2, a large language model explicitly trained on a large corpus of medical knowledge, to predict psychiatric functioning based on patient interviews and clinical descriptions.</li>
<li>results: The study finds that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions, with the strongest performance in predicting depression scores based on standardized assessments. The results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians.Here is the simplified Chinese version of the three key points:</li>
<li>for: 这篇论文旨在研究 Large language models (LLMs) 是否可以通过 patient 访问和临床描述来预测 психи治疗功能。</li>
<li>methods: 该研究使用 Med-PaLM 2，一个大型语言模型，通过 patient 访问和临床描述来预测 psycho 功能。</li>
<li>results: 研究发现 Med-PaLM 2 可以在各种 psycho 疾病中评估 psycho 功能，最强的表现在标准化评估中预测抑郁 scores，其准确率在 0.80 - 0.84 之间，与人类临床评估人员的准确率无 statistically distinguishable difference（t(1,144) &#x3D; 1.20; p &#x3D; 0.23），表明大型临床语言模型可以通过自由描述来预测 psycho 风险。<details>
<summary>Abstract</summary>
The current work investigates the capability of Large language models (LLMs) that are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so. To assess this, n = 145 depression and n =115 PTSD assessments and n = 46 clinical case studies across high prevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma and stress, Addictive disorders) were analyzed using prompts to extract estimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments (Accuracy range= 0.80 - 0.84) which were statistically indistinguishable from human clinical raters t(1,144) = 1.20; p = 0.23. Results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-beyond-sensations-how-dreams-organize-neuronal-representations"><a href="#Learning-beyond-sensations-how-dreams-organize-neuronal-representations" class="headerlink" title="Learning beyond sensations: how dreams organize neuronal representations"></a>Learning beyond sensations: how dreams organize neuronal representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01830">http://arxiv.org/abs/2308.01830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Deperrois, Mihai A. Petrovici, Walter Senn, Jakob Jordan</li>
<li>for: 这 paper 探讨了大脑中高级感觉 cortices 中 semantic 表示的形成和维护机制，以及这些表示如何影响行为。</li>
<li>methods: 这 paper 使用了 predictive learning 理论和虚拟经验来解释 cortical 表示的形成和维护。</li>
<li>results: 这 paper 提出了 two complementary learning principles，即 “adversarial dreaming” 和 “contrastive dreaming”，这些原理可以解释 cortical 学习 beyond classical predictive learning paradigm.<details>
<summary>Abstract</summary>
Semantic representations in higher sensory cortices form the basis for robust, yet flexible behavior. These representations are acquired over the course of development in an unsupervised fashion and continuously maintained over an organism's lifespan. Predictive learning theories propose that these representations emerge from predicting or reconstructing sensory inputs. However, brains are known to generate virtual experiences, such as during imagination and dreaming, that go beyond previously experienced inputs. Here, we suggest that virtual experiences may be just as relevant as actual sensory inputs in shaping cortical representations. In particular, we discuss two complementary learning principles that organize representations through the generation of virtual experiences. First, "adversarial dreaming" proposes that creative dreams support a cortical implementation of adversarial learning in which feedback and feedforward pathways engage in a productive game of trying to fool each other. Second, "contrastive dreaming" proposes that the invariance of neuronal representations to irrelevant factors of variation is acquired by trying to map similar virtual experiences together via a contrastive learning process. These principles are compatible with known cortical structure and dynamics and the phenomenology of sleep thus providing promising directions to explain cortical learning beyond the classical predictive learning paradigm.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Hard-Adversarial-Example-Mining-for-Improving-Robust-Fairness"><a href="#Hard-Adversarial-Example-Mining-for-Improving-Robust-Fairness" class="headerlink" title="Hard Adversarial Example Mining for Improving Robust Fairness"></a>Hard Adversarial Example Mining for Improving Robust Fairness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01823">http://arxiv.org/abs/2308.01823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenhao Lin, Xiang Ji, Yulong Yang, Qian Li, Chao Shen, Run Wang, Liming Fang</li>
<li>for: 本研究旨在提高深度神经网络（DNN）对假数据点（Adversarial Example，AE）的Robustness，同时解决隐性假数据点的不公平问题。</li>
<li>methods: 本研究提出了一种简单 yet effective的框架，即适应性 Hard Adversarial example Mining（HAM），通过适应性地挖掘硬AE来提高AT的效果。</li>
<li>results: 实验结果表明，HAM在CIFAR-10、SVHN和Imagenette等三个 benchmark上都达到了显著的改善robust fairness的效果，同时降低了计算成本。<details>
<summary>Abstract</summary>
Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE). Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
adversarial 训练（AT）是深度神经网络（DNN）的鲁棒性提升技术，却在实际应用中存在不公平问题。 recent studies have shown that adversarially trained models are prone to unfairness problems, limiting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.
</details></li>
</ul>
<hr>
<h2 id="Deep-Neural-Networks-Fused-with-Textures-for-Image-Classification"><a href="#Deep-Neural-Networks-Fused-with-Textures-for-Image-Classification" class="headerlink" title="Deep Neural Networks Fused with Textures for Image Classification"></a>Deep Neural Networks Fused with Textures for Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01813">http://arxiv.org/abs/2308.01813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asish Bera, Debotosh Bhattacharjee, Mita Nasipuri</li>
<li>for:  solves fine-grained image classification (FGIC) challenges by combining global texture with local patch-based information.</li>
<li>methods: 使用了批量模型（LSTM）和本地binary pattern（LBP）计算图像级别的文字特征，并将两条流水线结合为一个高效的特征向量。</li>
<li>results: 在 eight datasets 上（人脸、皮肤病变、食物、海洋生物等）使用四种标准底层CNN模型，实现了与现有方法相比的更高的分类精度。<details>
<summary>Abstract</summary>
Fine-grained image classification (FGIC) is a challenging task in computer vision for due to small visual differences among inter-subcategories, but, large intra-class variations. Deep learning methods have achieved remarkable success in solving FGIC. In this paper, we propose a fusion approach to address FGIC by combining global texture with local patch-based information. The first pipeline extracts deep features from various fixed-size non-overlapping patches and encodes features by sequential modelling using the long short-term memory (LSTM). Another path computes image-level textures at multiple scales using the local binary patterns (LBP). The advantages of both streams are integrated to represent an efficient feature vector for image classification. The method is tested on eight datasets representing the human faces, skin lesions, food dishes, marine lives, etc. using four standard backbone CNNs. Our method has attained better classification accuracy over existing methods with notable margins.
</details>
<details>
<summary>摘要</summary>
《细腔化图像分类（FGIC）是计算机视觉中的一项挑战，因为小视觉差异在间类之间很大，但是内类变化很大。深度学习方法在解决FGIC中得到了非常成功。在这篇论文中，我们提出了一种混合方法来解决FGIC，将全像Texture与本地小块信息混合。首条管道从不同大小的非重叠区域提取深度特征，然后使用长期短时间记忆（LSTM）编码特征。另一条管道在多尺度使用本地二进制模式（LBP）计算图像级别的Texture。两条管道的优点被集成，形成高效的特征向量，用于图像分类。我们在八个数据集上进行了测试，包括人脸、皮肤病变、食物碟、海洋生物等，使用四种标准背部CNN。我们的方法在现有方法中达到了更好的分类精度，差异较大。》Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Job-Shop-Scheduling-via-Deep-Reinforcement-Learning-a-Sequence-to-Sequence-approach"><a href="#Job-Shop-Scheduling-via-Deep-Reinforcement-Learning-a-Sequence-to-Sequence-approach" class="headerlink" title="Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach"></a>Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01797">http://arxiv.org/abs/2308.01797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawoz/JSP-DeepRL-Seq2Seq">https://github.com/dawoz/JSP-DeepRL-Seq2Seq</a></li>
<li>paper_authors: Giovanni Bonetta, Davide Zago, Rossella Cancelliere, Andrea Grosso</li>
<li>for: 该论文旨在提出一种基于深度学习的Job调度算法，以自动学习调度规则。</li>
<li>methods: 该方法基于自然语言编码器-解码器模型，并未在任何其他任务中使用。</li>
<li>results: 实验结果表明，该方法可以超越多种传统优先级调度规则，并与当前最佳深度学习方法相比 display competitive 的结果。<details>
<summary>Abstract</summary>
Job scheduling is a well-known Combinatorial Optimization problem with endless applications. Well planned schedules bring many benefits in the context of automated systems: among others, they limit production costs and waste. Nevertheless, the NP-hardness of this problem makes it essential to use heuristics whose design is difficult, requires specialized knowledge and often produces methods tailored to the specific task. This paper presents an original end-to-end Deep Reinforcement Learning approach to scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes. We applied and tested our method in particular to some benchmark instances of Job Shop Problem, but this technique is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention. Results demonstrate that we outperform many classical approaches exploiting priority dispatching rules and show competitive results on state-of-the-art Deep Reinforcement Learning ones.
</details>
<details>
<summary>摘要</summary>
This paper presents a novel end-to-end deep reinforcement learning approach to job scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used for scheduling purposes, to the best of our knowledge. We applied and tested our method on some benchmark instances of the job shop problem, but it is general enough to be potentially used to tackle other optimal job scheduling tasks with minimal intervention.Our results demonstrate that we outperform many classical approaches that use priority dispatching rules and show competitive results with state-of-the-art deep reinforcement learning methods.
</details></li>
</ul>
<hr>
<h2 id="Guided-Distillation-for-Semi-Supervised-Instance-Segmentation"><a href="#Guided-Distillation-for-Semi-Supervised-Instance-Segmentation" class="headerlink" title="Guided Distillation for Semi-Supervised Instance Segmentation"></a>Guided Distillation for Semi-Supervised Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02668">http://arxiv.org/abs/2308.02668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tariq Berrada, Camille Couprie, Karteek Alahari, Jakob Verbeek</li>
<li>for: 提高实体 segmentation 模型的性能，减少依赖于完全标注的训练图像。</li>
<li>methods: 使用 semi-supervised 方法，利用无标注数据作为训练信号，限制模型过拟合标注样本。</li>
<li>results: 提高 teacher-student 填充模型的性能，在 Cityscapes 数据集上提高 mask-AP 从 23.7 到 33.9，在 COCO 数据集上提高 mask-AP 从 18.3 到 34.1，对比前一个状态的艺术。<details>
<summary>Abstract</summary>
Although instance segmentation methods have improved considerably, the dominant paradigm is to rely on fully-annotated training images, which are tedious to obtain. To alleviate this reliance, and boost results, semi-supervised approaches leverage unlabeled data as an additional training signal that limits overfitting to the labeled samples. In this context, we present novel design choices to significantly improve teacher-student distillation models. In particular, we (i) improve the distillation approach by introducing a novel "guided burn-in" stage, and (ii) evaluate different instance segmentation architectures, as well as backbone networks and pre-training strategies. Contrary to previous work which uses only supervised data for the burn-in period of the student model, we also use guidance of the teacher model to exploit unlabeled data in the burn-in period. Our improved distillation approach leads to substantial improvements over previous state-of-the-art results. For example, on the Cityscapes dataset we improve mask-AP from 23.7 to 33.9 when using labels for 10\% of images, and on the COCO dataset we improve mask-AP from 18.3 to 34.1 when using labels for only 1\% of the training data.
</details>
<details>
<summary>摘要</summary>
尽管实例分割方法已经有了很大的进步，但主流的方法仍然是通过完全标注的图像进行训练，这是费时的。为了减轻这种依赖，并提高结果，半超vised方法利用无标注数据作为训练信号，限制学习到标注样本上的过拟合。在这种情况下，我们提出了新的设计选择，以提高教师学生液态模型。具体来说，我们（i）改进了液态模型的适应方法，引入了一种新的“导向燃烧”阶段，以及（ii）评估不同的实例分割架构、背部网络和预训练策略。与前一些工作不同，我们在学生模型的烧入期间也使用导师模型的指导，以便利用无标注数据。我们改进的液态模型方法导致了对前一个状态的重大提高。例如，在Cityscapes dataset上，我们从23.7提高到33.9的mask-AP，并在COCO dataset上从18.3提高到34.1的mask-AP，只使用1%的训练数据上的标签。
</details></li>
</ul>
<hr>
<h2 id="MAP-A-Model-agnostic-Pretraining-Framework-for-Click-through-Rate-Prediction"><a href="#MAP-A-Model-agnostic-Pretraining-Framework-for-Click-through-Rate-Prediction" class="headerlink" title="MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction"></a>MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01737">http://arxiv.org/abs/2308.01737</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chiangel/map-code">https://github.com/chiangel/map-code</a></li>
<li>paper_authors: Jianghao Lin, Yanru Qu, Wei Guo, Xinyi Dai, Ruiming Tang, Yong Yu, Weinan Zhang</li>
<li>for: 这 paper 是为了解决个性化在线服务的点击率预测问题，因为现有的 neural 模型 无法充分利用大量的用户点击记录数据。</li>
<li>methods: 这 paper 使用了自适应学习 paradigm，并提出了两种实用算法：偏挥特征预测 (MFP) 和替换特征检测 (RFD)，以利用大量的用户点击记录数据来提高点击率预测性能。</li>
<li>results: 实验结果表明，使用 MFP 和 RFD 可以在两个实际大规模数据集 (i.e., Avazu, Criteo) 上 achieve 新的州际纪录性能，并在多个强大的 backbone 上达到新的最佳性能。<details>
<summary>Abstract</summary>
With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume. The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations. However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary. To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining. Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose a model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data. Specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it simpler and more effective for CTR pretraining.Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.
</details></li>
</ul>
<hr>
<h2 id="Towards-Self-organizing-Personal-Knowledge-Assistants-in-Evolving-Corporate-Memories"><a href="#Towards-Self-organizing-Personal-Knowledge-Assistants-in-Evolving-Corporate-Memories" class="headerlink" title="Towards Self-organizing Personal Knowledge Assistants in Evolving Corporate Memories"></a>Towards Self-organizing Personal Knowledge Assistants in Evolving Corporate Memories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01732">http://arxiv.org/abs/2308.01732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Jilek, Markus Schröder, Heiko Maus, Sven Schwarz, Andreas Dengel</li>
<li>for: 本研究旨在概述过去十年内我们部门对个人知识助手的自组织化研究，以及在不断发展的企业记忆中进行的应用。</li>
<li>methods: 本研究通常受到实际问题的启发，并在研究与业界合作伙伴的协作下进行。研究包括了不同的知识图构建方法在企业和个人设置下，以及Managed Forgetting和（自组织）Context Spaces作为一种新的个人信息管理（PIM）和知识工作支持的方法。</li>
<li>results: 过去实验和结果包括了许多不同的主题，如知识图构建、Managed Forgetting和Context Spaces等。此外，我们还提供了相关工作的概述和一些最新的发现，这些发现尚未发表。最后，我们给出了一个关于CoMem的详细描述，这是基于我们所提出的研究已经在生产中使用的一个企业记忆系统，以及这个系统在进一步研究中的挑战。<details>
<summary>Abstract</summary>
This paper presents a retrospective overview of a decade of research in our department towards self-organizing personal knowledge assistants in evolving corporate memories. Our research is typically inspired by real-world problems and often conducted in interdisciplinary collaborations with research and industry partners. We summarize past experiments and results comprising topics like various ways of knowledge graph construction in corporate and personal settings, Managed Forgetting and (Self-organizing) Context Spaces as a novel approach to Personal Information Management (PIM) and knowledge work support. Past results are complemented by an overview of related work and some of our latest findings not published so far. Last, we give an overview of our related industry use cases including a detailed look into CoMem, a Corporate Memory based on our presented research already in productive use and providing challenges for further research. Many contributions are only first steps in new directions with still a lot of untapped potential, especially with regard to further increasing the automation in PIM and knowledge work support.
</details>
<details>
<summary>摘要</summary>
中文翻译：本文提供了我们部门过去十年的研究回顾，探讨了自我组织人工智能在演化企业记忆中的个人知识助手。我们的研究通常受到实际问题的启发，并在研究和行业合作伙伴的协作下进行。我们summarize过去的实验和结果，包括企业和个人设置中知识图构建的多种方法，以及自动化Context Spaces和Managed Forgetting作为个人信息管理（PIM）和知识工作支持的新方法。过去的结果也包括相关工作的概述和一些没有发表过的最新发现。最后，我们给出了相关的行业应用场景，包括一个详细的CoMem企业记忆的概述，该记忆基于我们所提出的研究，已经在生产中使用，并提供了进一步研究的挑战。许多贡献都只是新的方向的第一步，特别是在进一步增加PIM和知识工作支持中的自动化。
</details></li>
</ul>
<hr>
<h2 id="Is-GPT-4-a-reliable-rater-Evaluating-Consistency-in-GPT-4-Text-Ratings"><a href="#Is-GPT-4-a-reliable-rater-Evaluating-Consistency-in-GPT-4-Text-Ratings" class="headerlink" title="Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings"></a>Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02575">http://arxiv.org/abs/2308.02575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Veronika Hackl, Alexandra Elena Müller, Michael Granitzer, Maximilian Sailer</li>
<li>for: 这个研究探究了OpenAI的GPT-4模型在多个迭代、时间尺度和语言风格变化下的反馈评分的一致性。</li>
<li>methods: 该研究使用GPT-4模型对高等教育（HE）领域的macroeconomics任务中的回答进行了内容和风格两个方面的评分。统计分析用于了解评分之间的一致性、迭代中评分的一致性以及内容和风格评分之间的相关性。</li>
<li>results: 结果显示GPT-4模型在不同的时间尺度下 exhibit 高的 между评分者一致性（ICC分数在0.94-0.99之间），表明该模型在重复提示下能够生成一致的评分。内容和风格评分之间存在0.87的高相关性。当应用不适用的风格时，内容评分保持相对定的，而风格评分下降，这表明LLM有效地在评价过程中分化内容和风格两个方面。<details>
<summary>Abstract</summary>
This study investigates the consistency of feedback ratings generated by OpenAI's GPT-4, a state-of-the-art artificial intelligence language model, across multiple iterations, time spans and stylistic variations. The model rated responses to tasks within the Higher Education (HE) subject domain of macroeconomics in terms of their content and style. Statistical analysis was conducted in order to learn more about the interrater reliability, consistency of the ratings across iterations and the correlation between ratings in terms of content and style. The results revealed a high interrater reliability with ICC scores ranging between 0.94 and 0.99 for different timespans, suggesting that GPT-4 is capable of generating consistent ratings across repetitions with a clear prompt. Style and content ratings show a high correlation of 0.87. When applying a non-adequate style the average content ratings remained constant, while style ratings decreased, which indicates that the large language model (LLM) effectively distinguishes between these two criteria during evaluation. The prompt used in this study is furthermore presented and explained. Further research is necessary to assess the robustness and reliability of AI models in various use cases.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Local-Large-Language-Models-for-Complex-Structured-Medical-Tasks"><a href="#Local-Large-Language-Models-for-Complex-Structured-Medical-Tasks" class="headerlink" title="Local Large Language Models for Complex Structured Medical Tasks"></a>Local Large Language Models for Complex Structured Medical Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01727">http://arxiv.org/abs/2308.01727</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/innovationcore/LocalLLMStructured">https://github.com/innovationcore/LocalLLMStructured</a></li>
<li>paper_authors: V. K. Cody Bumgardner, Aaron Mullen, Sam Armstrong, Caylin Hickey, Jeff Talbert</li>
<li>for: This paper aims to tackle complex, domain-specific tasks by combining the language reasoning capabilities of large language models (LLMs) with the benefits of local training.</li>
<li>methods: The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs. The authors used a dataset of over 150k uncurated surgical pathology reports to train and evaluate different model architectures, including LLaMA, BERT, and LongFormer.</li>
<li>results: The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, especially with large datasets. The LLaMA models demonstrated their ability to handle complex, multi-label tasks, making them a promising approach for utilizing LLMs to perform domain-specific tasks using accessible hardware.<details>
<summary>Abstract</summary>
This paper introduces an approach that combines the language reasoning capabilities of large language models (LLMs) with the benefits of local training to tackle complex, domain-specific tasks. Specifically, the authors demonstrate their approach by extracting structured condition codes from pathology reports. The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs. The authors collected a dataset of over 150k uncurated surgical pathology reports, containing gross descriptions, final diagnoses, and condition codes. They trained different model architectures, including LLaMA, BERT and LongFormer and evaluated their performance. The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, even with extremely reduced precision. The LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-label tasks. Overall, this work presents an effective approach for utilizing LLMs to perform domain-specific tasks using accessible hardware, with potential applications in the medical domain, where complex data extraction and classification are required.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Bees-Local-Phase-Quantization-Feature-Selection-for-RGB-D-Facial-Expressions-Recognition"><a href="#Bees-Local-Phase-Quantization-Feature-Selection-for-RGB-D-Facial-Expressions-Recognition" class="headerlink" title="Bees Local Phase Quantization Feature Selection for RGB-D Facial Expressions Recognition"></a>Bees Local Phase Quantization Feature Selection for RGB-D Facial Expressions Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01700">http://arxiv.org/abs/2308.01700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyed Muhammad Hossein Mousavi, Atiye Ilanloo</li>
<li>for: 本研究旨在提出一种基于灵感自然选择器的特征选择方法，并应用于人脸表情识别任务。</li>
<li>methods: 本研究使用了蜂群算法（BA）和本地相位量化（LPQ）来实现特征选择。LPQ是一种在频域中表现出色的特征，可以帮助提高人脸表情识别的准确率。</li>
<li>results: 研究结果显示，提案的蜂群LPQ方法在人脸表情识别任务中达到了99%的准确率，与其他方法相比，表现出了极好的性能。<details>
<summary>Abstract</summary>
Feature selection could be defined as an optimization problem and solved by bio-inspired algorithms. Bees Algorithm (BA) shows decent performance in feature selection optimization tasks. On the other hand, Local Phase Quantization (LPQ) is a frequency domain feature which has excellent performance on Depth images. Here, after extracting LPQ features out of RGB (colour) and Depth images from the Iranian Kinect Face Database (IKFDB), the Bees feature selection algorithm applies to select the desired number of features for final classification tasks. IKFDB is recorded with Kinect sensor V.2 and contains colour and depth images for facial and facial micro-expressions recognition purposes. Here five facial expressions of Anger, Joy, Surprise, Disgust and Fear are used for final validation. The proposed Bees LPQ method is compared with Particle Swarm Optimization (PSO) LPQ, PCA LPQ, Lasso LPQ, and just LPQ features for classification tasks with Support Vector Machines (SVM), K-Nearest Neighbourhood (KNN), Shallow Neural Network and Ensemble Subspace KNN. Returned results, show a decent performance of the proposed algorithm (99 % accuracy) in comparison with others.
</details>
<details>
<summary>摘要</summary>
feature选择可以定义为优化问题，并可以使用生物灵感算法解决。蜂群算法（BA）在特征选择优化任务中表现不错。另一方面，本地相对频率量化（LPQ）是一个频域特征，在深度影像上表现出色。在这里，我们将LPQ特征提取自RGB（色）和深度影像，然后使用蜂群特征选择算法选择最多的特征。IKFDB（伊朗掌握脸部数据库）是录制了Kinect感知器V.2的颜色和深度影像，并且用于脸部和脸部微表情识别。在这里，我们使用五种表情：愤怒、喜悦、惊讶、厌恶和恐惧进行最终验证。提案的蜂群LPQ方法与束缚点群集优化（PSO）LPQ、对角量变换（PCA）LPQ、lasso LPQ和单独LPQ特征进行比较，并使用支持向量机（SVM）、K-最近邻居（KNN）、浅层神经网和混合空间KNN进行类别任务。结果显示，提案的算法（99%准确）在比较之下表现不错。
</details></li>
</ul>
<hr>
<h2 id="LiDAR-Camera-Panoptic-Segmentation-via-Geometry-Consistent-and-Semantic-Aware-Alignment"><a href="#LiDAR-Camera-Panoptic-Segmentation-via-Geometry-Consistent-and-Semantic-Aware-Alignment" class="headerlink" title="LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment"></a>LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01686">http://arxiv.org/abs/2308.01686</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhangzw12319/lcps">https://github.com/zhangzw12319/lcps</a></li>
<li>paper_authors: Zhiwei Zhang, Zhizhong Zhang, Qian Yu, Ran Yi, Yuan Xie, Lizhuang Ma</li>
<li>for: This paper is written for the task of 3D panoptic segmentation, which aims to simultaneously perform semantic segmentation and instance segmentation in a scene using both LiDAR and camera data.</li>
<li>methods: The proposed method, called LCPS, uses a three-stage fusion approach that includes an asynchronous compensation pixel alignment module, a semantic-aware region alignment module, and a point-to-voxel feature propagation module to fuse LiDAR and camera data.</li>
<li>results: The proposed method achieves an improvement of about 6.9% in PQ performance over the LiDAR-only baseline on the NuScenes dataset, demonstrating the effectiveness of the proposed fusion strategy.Here are the three points in Simplified Chinese text:</li>
<li>for: 这篇论文是为了解决3D照片检测问题，这个问题需要同时进行 semantic segmentation 和 instance segmentation，使用 LiDAR 和摄像头数据。</li>
<li>methods: 提议的方法是 LCPS，它使用三个阶段的融合方法，包括异步补做像素对齐模块、semantic-aware region alignment模块和点到 voxel 特征传播模块来融合 LiDAR 和摄像头数据。</li>
<li>results: 提议的方法在 NuScenes 数据集上实现了约6.9%的 PQ 性能提升，证明了提议的融合策略的有效性。<details>
<summary>Abstract</summary>
3D panoptic segmentation is a challenging perception task that requires both semantic segmentation and instance segmentation. In this task, we notice that images could provide rich texture, color, and discriminative information, which can complement LiDAR data for evident performance improvement, but their fusion remains a challenging problem. To this end, we propose LCPS, the first LiDAR-Camera Panoptic Segmentation network. In our approach, we conduct LiDAR-Camera fusion in three stages: 1) an Asynchronous Compensation Pixel Alignment (ACPA) module that calibrates the coordinate misalignment caused by asynchronous problems between sensors; 2) a Semantic-Aware Region Alignment (SARA) module that extends the one-to-one point-pixel mapping to one-to-many semantic relations; 3) a Point-to-Voxel feature Propagation (PVP) module that integrates both geometric and semantic fusion information for the entire point cloud. Our fusion strategy improves about 6.9% PQ performance over the LiDAR-only baseline on NuScenes dataset. Extensive quantitative and qualitative experiments further demonstrate the effectiveness of our novel framework. The code will be released at https://github.com/zhangzw12319/lcps.git.
</details>
<details>
<summary>摘要</summary>
“3D短文本分割是一项具有挑战性的识别任务，它需要同时完成semantic segmentation和instance segmentation。在这种任务中，我们发现图像可以提供丰富的文本、颜色和特征信息，这些信息可以补做LiDAR数据，从而提高识别性能，但是这些信息的融合仍然是一个挑战。为此，我们提出了LCPS，首个LiDAR-Camera短文本分割网络。我们的方法包括三个阶段：1）异步补做像素均衡（ACPA）模块，用于解决摄像头和LiDAR仪器之间的坐标偏差问题; 2） semantic-aware区域匹配（SARA）模块，将一对一点像素映射扩展到一对多semantic关系; 3）点云特征传播（PVP）模块，将光栅和semantic融合信息传播到整个点云中。我们的融合策略提高了NuScenes数据集上LiDAR-only基准点Cloud的PQ性能表现约6.9%。广泛的量化和质量实验进一步证明了我们的新框架的有效性。代码将在https://github.com/zhangzw12319/lcps.git中发布。”
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Link-Prediction-Explanations-for-Graph-Neural-Networks"><a href="#Evaluating-Link-Prediction-Explanations-for-Graph-Neural-Networks" class="headerlink" title="Evaluating Link Prediction Explanations for Graph Neural Networks"></a>Evaluating Link Prediction Explanations for Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01682">http://arxiv.org/abs/2308.01682</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cborile/eval_lp_xai">https://github.com/cborile/eval_lp_xai</a></li>
<li>paper_authors: Claudio Borile, Alan Perotti, André Panisson</li>
<li>for: 这篇论文主要用于提供链接预测模型的解释评价指标，以便促进链接预测模型的采用。</li>
<li>methods: 这篇论文使用了现状前景的解释方法，并对这些方法进行评价。</li>
<li>results: 研究发现，不同的距离选择方式可能会影响链接预测解释的质量。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Graph Machine Learning (GML) has numerous applications, such as node/graph classification and link prediction, in real-world domains. Providing human-understandable explanations for GML models is a challenging yet fundamental task to foster their adoption, but validating explanations for link prediction models has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.
</details>
<details>
<summary>摘要</summary>
graph机器学习（GML）在实际领域有很多应用，如节点/图分类和链接预测。提供可理解的GML模型解释是推广其使用的挑战，但链接预测模型的解释 validation  Received little attention。在这篇论文中，我们提供了量化的评价指标，以及或无ground-truth。现有的explainability方法 для图神经网络被使用这些指标进行评估。我们讨论了链接预测任务的下面假设和技术细节，如节点嵌入距离的选择，对解释质量产生的影响。
</details></li>
</ul>
<hr>
<h2 id="NBIAS-A-Natural-Language-Processing-Framework-for-Bias-Identification-in-Text"><a href="#NBIAS-A-Natural-Language-Processing-Framework-for-Bias-Identification-in-Text" class="headerlink" title="NBIAS: A Natural Language Processing Framework for Bias Identification in Text"></a>NBIAS: A Natural Language Processing Framework for Bias Identification in Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01681">http://arxiv.org/abs/2308.01681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaina Raza, Muskan Garg, Deepak John Reji, Syed Raza Bashir, Chen Ding</li>
<li>for: 这篇论文的目的是为了探讨文本数据中的偏见，并开发一个可以检测和消除这些偏见的框架。</li>
<li>methods: 这篇论文使用了一个基于Transformer的字词分类模型，并通过独特的名称实体来识别偏见字词&#x2F;短语。</li>
<li>results: 这篇论文的结果显示，使用了提案的方法可以实现偏见检测和消除的目的，并且比基于基线的方法提高了1%至8%的精度。<details>
<summary>Abstract</summary>
Bias in textual data can lead to skewed interpretations and outcomes when the data is used. These biases could perpetuate stereotypes, discrimination, or other forms of unfair treatment. An algorithm trained on biased data ends up making decisions that disproportionately impact a certain group of people. Therefore, it is crucial to detect and remove these biases to ensure the fair and ethical use of data. To this end, we develop a comprehensive and robust framework \textsc{Nbias} that consists of a data layer, corpus contruction, model development layer and an evaluation layer. The dataset is constructed by collecting diverse data from various fields, including social media, healthcare, and job hiring portals. As such, we applied a transformer-based token classification model that is able to identify bias words/ phrases through a unique named entity. In the assessment procedure, we incorporate a blend of quantitative and qualitative evaluations to gauge the effectiveness of our models. We achieve accuracy improvements ranging from 1% to 8% compared to baselines. We are also able to generate a robust understanding of the model functioning, capturing not only numerical data but also the quality and intricacies of its performance. The proposed approach is applicable to a variety of biases and contributes to the fair and ethical use of textual data.
</details>
<details>
<summary>摘要</summary>
文本数据中的偏见可能导致解释和结果偏离均衡，这可能导致推荐或报告不公平或不公正。一个基于偏见数据的算法会导致对某些人群的决策偏离，从而产生不公平的结果。因此，检测和消除偏见是必要的，以确保数据的公平和道德使用。为此，我们开发了一个全面和可靠的框架\textsc{Nbias}，它包括数据层、文本建构层、模型开发层和评估层。我们收集了来自不同领域的多样化数据，包括社交媒体、医疗和招聘门户，并应用了基于转换器的单词分类模型，以识别偏见词语/短语。在评估过程中，我们 combinated量化和质量评估来评估模型的效果。我们实现了基eline比较高的准确率改进，从1%到8%不等，并能够生成模型的精准和复杂的性能理解。这种方法可以应用于多种偏见，并为公平和道德的文本数据使用做出贡献。
</details></li>
</ul>
<hr>
<h2 id="Learning-Implicit-Entity-object-Relations-by-Bidirectional-Generative-Alignment-for-Multimodal-NER"><a href="#Learning-Implicit-Entity-object-Relations-by-Bidirectional-Generative-Alignment-for-Multimodal-NER" class="headerlink" title="Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER"></a>Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02570">http://arxiv.org/abs/2308.02570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Chen, Jiajia Liu, Kaixiang Ji, Wang Ren, Jian Wang, Jingdong Wang</li>
<li>for: 提高多modalNamed Entity recognition（MNER）的性能，尤其是 bridging the semantic gap between text and image，以及匹配实体与其相关对象的匹配。</li>
<li>methods: 提出了一种bidirectional generative alignment方法（BGA-MNER），包括图像到文本和文本到图像的生成，以及对实体敏感内容的融合。该方法通过对双向重建目标进行 JOINT 优化，使实体-对象关系得到了正确的匹配。</li>
<li>results: 通过对两个 benchmark进行了广泛的实验，表明了我们的方法可以在无图像输入的情况下达到最佳性能。<details>
<summary>Abstract</summary>
The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in image. Existing methods fail to capture the implicit entity-object relations, due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \texttt{image2text} and \texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our method achieves state-of-the-art performance without image input during inference.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MARLIM-Multi-Agent-Reinforcement-Learning-for-Inventory-Management"><a href="#MARLIM-Multi-Agent-Reinforcement-Learning-for-Inventory-Management" class="headerlink" title="MARLIM: Multi-Agent Reinforcement Learning for Inventory Management"></a>MARLIM: Multi-Agent Reinforcement Learning for Inventory Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01649">http://arxiv.org/abs/2308.01649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rémi Leluc, Elie Kadoche, Antoine Bertoncello, Sébastien Gourvénec</li>
<li>for: 决策供应链中维持产品供应平衡，提高供应链效率和可靠性。</li>
<li>methods: 使用人工智能技术，开发了一种基于强化学习的供应链管理框架，named MARLIM，可以处理单一仓库多种产品的存储管理问题，采用单或多代理人协作方式。</li>
<li>results: 通过实验表明，基于强化学习方法的供应链管理方法比传统基eline方法更有利，可以更好地决策供应链中的产品供应问题。<details>
<summary>Abstract</summary>
Maintaining a balance between the supply and demand of products by optimizing replenishment decisions is one of the most important challenges in the supply chain industry. This paper presents a novel reinforcement learning framework called MARLIM, to address the inventory management problem for a single-echelon multi-products supply chain with stochastic demands and lead-times. Within this context, controllers are developed through single or multiple agents in a cooperative setting. Numerical experiments on real data demonstrate the benefits of reinforcement learning methods over traditional baselines.
</details>
<details>
<summary>摘要</summary>
维护产品供应和需求的平衡是供应链产业中最重要的挑战。本文提出了一个新的强化学习框架，名为MARLIM，以解决单一库存维护问题。在这个设定下，控制器通过单一或多个代理人在合作环境中发展。数据示出强化学习方法比传统基准更有价。
</details></li>
</ul>
<hr>
<h2 id="Improving-Wind-Resistance-Performance-of-Cascaded-PID-Controlled-Quadcopters-using-Residual-Reinforcement-Learning"><a href="#Improving-Wind-Resistance-Performance-of-Cascaded-PID-Controlled-Quadcopters-using-Residual-Reinforcement-Learning" class="headerlink" title="Improving Wind Resistance Performance of Cascaded PID Controlled Quadcopters using Residual Reinforcement Learning"></a>Improving Wind Resistance Performance of Cascaded PID Controlled Quadcopters using Residual Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01648">http://arxiv.org/abs/2308.01648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Ishihara, Yuichi Hazama, Kousuke Suzuki, Jerry Jun Yokono, Kohtaro Sabe, Kenta Kawamoto</li>
<li>for: 控制四旋翼机器人在风干扰下维持位置的稳定性。</li>
<li>methods: 使用剩余强化学习方法建立四旋翼机器人风 resistance控制器，只学习干扰的差异，可以继续使用传统的缓冲PID控制器作为基础控制器，提高风干扰下的性能。</li>
<li>results: 通过多种实验，包括在风速大于13m&#x2F;s的户外场景中，我们的控制器可以减少四旋翼机器人的位置偏差约50%，并且培养的控制器具有强健性，可以在四旋翼机器人的质量和推进器的扬力系数发生变化时保持性能。<details>
<summary>Abstract</summary>
Wind resistance control is an essential feature for quadcopters to maintain their position to avoid deviation from target position and prevent collisions with obstacles. Conventionally, cascaded PID controller is used for the control of quadcopters for its simplicity and ease of tuning its parameters. However, it is weak against wind disturbances and the quadcopter can easily deviate from target position. In this work, we propose a residual reinforcement learning based approach to build a wind resistance controller of a quadcopter. By learning only the residual that compensates the disturbance, we can continue using the cascaded PID controller as the base controller of the quadcopter but improve its performance against wind disturbances. To avoid unexpected crashes and destructions of quadcopters, our method does not require real hardware for data collection and training. The controller is trained only on a simulator and directly applied to the target hardware without extra finetuning process. We demonstrate the effectiveness of our approach through various experiments including an experiment in an outdoor scene with wind speed greater than 13 m/s. Despite its simplicity, our controller reduces the position deviation by approximately 50% compared to the quadcopter controlled with the conventional cascaded PID controller. Furthermore, trained controller is robust and preserves its performance even though the quadcopter's mass and propeller's lift coefficient is changed between 50% to 150% from original training time.
</details>
<details>
<summary>摘要</summary>
风 resistance 控制是 quadcopter 维持目标位置的重要特性，以避免偏离目标位置和避免遭遇障碍物的Collision。 Conventionally, cascaded PID controller 是用于 quadcopter 控制的最常用方法，因为它的简单性和参数调整的容易性。然而，它在风干扰下表现弱，quadcopter 容易偏离目标位置。在这项工作中，我们提出了基于 residual reinforcement learning 的风 resistance 控制方法。通过学习剩下的偏差，我们可以继续使用 cascaded PID controller 作为 quadcopter 的基础控制器，但是提高其对风干扰的性能。为了避免意外坠机和 quadcopter 的破坏，我们的方法不需要实际硬件数据采集和训练。控制器通过在 simulator 上学习，直接应用于目标硬件上，不需要额外的调整过程。我们通过多种实验，包括在风速大于 13 m/s 的户外场景中，证明了我们的方法的有效性。即使简单，我们的控制器可以降低 quadcopter 的位置偏离约 50%，相比于使用 conventinal cascaded PID controller。另外，训练后的控制器具有坚定性，其性能保持不变，even though quadcopter 的质量和推进器的扬力系数被变化了，从原始训练时间的50%到150%。
</details></li>
</ul>
<hr>
<h2 id="Interleaving-GANs-with-knowledge-graphs-to-support-design-creativity-for-book-covers"><a href="#Interleaving-GANs-with-knowledge-graphs-to-support-design-creativity-for-book-covers" class="headerlink" title="Interleaving GANs with knowledge graphs to support design creativity for book covers"></a>Interleaving GANs with knowledge graphs to support design creativity for book covers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01626">http://arxiv.org/abs/2308.01626</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alexmotogna/generatorapi">https://github.com/alexmotogna/generatorapi</a></li>
<li>paper_authors: Alexandru Motogna, Adrian Groza</li>
<li>for: 本研究应用生成对抗网络（GANs）到书籍封面领域，以不同的训练方法来提取更好的生成图像。</li>
<li>methods: 本研究使用GANs与知识图进行混合训练，通过对标题进行修改来生成多个可能的选择，然后使用识别器进行选择最佳的生成图像。</li>
<li>results: 本研究比前一些尝试更好地生成书籍封面，而知识图产生更多的选择，为书籍作者或编辑提供了更好的选择。<details>
<summary>Abstract</summary>
An attractive book cover is important for the success of a book. In this paper, we apply Generative Adversarial Networks (GANs) to the book covers domain, using different methods for training in order to obtain better generated images. We interleave GANs with knowledge graphs to alter the input title to obtain multiple possible options for any given title, which are then used as an augmented input to the generator. Finally, we use the discriminator obtained during the training phase to select the best images generated with new titles. Our method performed better at generating book covers than previous attempts, and the knowledge graph gives better options to the book author or editor compared to using GANs alone.
</details>
<details>
<summary>摘要</summary>
一本漂亮的书封面对书的成功非常重要。在这篇论文中，我们使用生成对抗网络（GANs）来适应书封面领域，使用不同的训练方法来获得更好的生成图像。我们将GANs与知识图加以混合，将输入标题进行修改，以获得多个可能的选择，然后将这些选择作为增强输入给生成器。最后，我们使用训练阶段获得的推定器来选择最佳的生成图像。我们的方法比之前的尝试更好地生成书封面，而知识图可以为书作者或编辑提供更多的选择，比如使用GANsalone。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Indoor-Localisation-in-Parkinson’s-Disease-for-Detecting-Medication-Use-Observational-Pilot-Study-in-a-Free-Living-Setting"><a href="#Multimodal-Indoor-Localisation-in-Parkinson’s-Disease-for-Detecting-Medication-Use-Observational-Pilot-Study-in-a-Free-Living-Setting" class="headerlink" title="Multimodal Indoor Localisation in Parkinson’s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting"></a>Multimodal Indoor Localisation in Parkinson’s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02419">http://arxiv.org/abs/2308.02419</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ferdianjovan/Multihead-Dual-Convolutional-Self-Attention">https://github.com/ferdianjovan/Multihead-Dual-Convolutional-Self-Attention</a></li>
<li>paper_authors: Ferdian Jovan, Catherine Morgan, Ryan McConville, Emma L. Tonkin, Ian Craddock, Alan Whone</li>
<li>for: 这个研究的目的是提高当前indoor localization方法的效果，并使用双感知模式（ Received Signal Strength Indicator 和加速器数据）来评估PD患者的 дви作障碍。</li>
<li>methods: 这个研究使用了一种基于转换器的方法，利用RSSI和加速器数据来提供 complementary views of movement。</li>
<li>results: 研究表明，该方法可以高效地进行indoor localization，并且可以准确地捕捉PD患者的 дви作障碍。具体来说，研究发现，精准的房间级别的地理位置预测，可以准确地预测PD患者是否正在服用levodopa药物。<details>
<summary>Abstract</summary>
Parkinson's disease (PD) is a slowly progressive, debilitating neurodegenerative disease which causes motor symptoms including gait dysfunction. Motor fluctuations are alterations between periods with a positive response to levodopa therapy ("on") and periods marked by re-emergency of PD symptoms ("off") as the response to medication wears off. These fluctuations often affect gait speed and they increase in their disabling impact as PD progresses. To improve the effectiveness of current indoor localisation methods, a transformer-based approach utilising dual modalities which provide complementary views of movement, Received Signal Strength Indicator (RSSI) and accelerometer data from wearable devices, is proposed. A sub-objective aims to evaluate whether indoor localisation, including its in-home gait speed features (i.e. the time taken to walk between rooms), could be used to evaluate motor fluctuations by detecting whether the person with PD is taking levodopa medications or withholding them. To properly evaluate our proposed method, we use a free-living dataset where the movements and mobility are greatly varied and unstructured as expected in real-world conditions. 24 participants lived in pairs (consisting of one person with PD, one control) for five days in a smart home with various sensors. Our evaluation on the resulting dataset demonstrates that our proposed network outperforms other methods for indoor localisation. The sub-objective evaluation shows that precise room-level localisation predictions, transformed into in-home gait speed features, produce accurate predictions on whether the PD participant is taking or withholding their medications.
</details>
<details>
<summary>摘要</summary>
帕金森病 (PD) 是一种慢慢恶化、疲劳性神经退化病种，引起 дви作Symptoms 包括行走功能障碍。 дви作周期性变化是指由levodopa治疗 ("on") 和PD症状重新出现 ("off") 的交替，这些变化通常对行走速度产生影响，随着PD的进行而加剧。为了提高现有indoor localization方法的有效性，一种基于 transformer 的方法，利用 dual Modalities 提供 complementary 视图的运动数据，包括 Received Signal Strength Indicator (RSSI) 和加速器数据，是提出的。一个 sub-objective 是评估 whether indoor localization, 包括室内步速特征 (i.e. 行走 между房间所需时间), 可以用来评估PD参与者是否服用 levodopa 药物。为了正确评估我们的提议方法，我们使用了一个免费生活数据集，其中参与者的运动和 mobilty 具有很大的变化和不结构化，如预计的实际条件中。24名参与者（一名PD参与者和一名控制人）在五天内生活在一个智能家庭中，并装备了多种感知器。我们对 resulting dataset 进行评估，并显示我们的提议网络在indoor localization方面的表现比其他方法更好。 sub-objective 评估表明，精准的室内地理位置预测，经 transformed 为室内步速特征，可以准确地预测PD参与者是否服用 levodopa 药物。
</details></li>
</ul>
<hr>
<h2 id="ReIDTrack-Multi-Object-Track-and-Segmentation-Without-Motion"><a href="#ReIDTrack-Multi-Object-Track-and-Segmentation-Without-Motion" class="headerlink" title="ReIDTrack: Multi-Object Track and Segmentation Without Motion"></a>ReIDTrack: Multi-Object Track and Segmentation Without Motion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01622">http://arxiv.org/abs/2308.01622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaer Huang, Bingchuan Sun, Feng Chen, Tao Zhang, Jun Xie, Jian Li, Christopher Walter Twombly, Zhepeng Wang</li>
<li>For: The paper focuses on exploring the direction of achieving state-of-the-art (SOTA) performance in multi-object tracking and segmentation (MOTS) using only high-performance detection and appearance models, without relying on motion information and IoU mapping during association.* Methods: The proposed method uses CBNetV2 as a detection model and MoCo-v2 as a self-supervised appearance model, and removes motion information and IoU mapping during the association process.* Results: The method achieved 1st place on the MOTS track and 2nd place on the MOT track in the CVPR2023 WAD workshop, demonstrating its effectiveness and simplicity.Here are the three points in Simplified Chinese text:* For: 本研究主要目标是通过高性能的检测和外观模型来实现多bject tracking和分割（MOTS）中的新状态之冠（SOTA）性能，不需要在协调过程中使用运动信息和IOU映射。* Methods: 提posed方法使用 CBNetV2 作为检测模型，MoCo-v2 作为自我指导的外观模型，并在协调过程中除掉运动信息和IOU映射。* Results: 方法在 CVPR2023 WAD 工作坊中获得了 MOTS track 第一名和 MOT track 第二名，证明了其简洁效果。<details>
<summary>Abstract</summary>
In recent years, dominant Multi-object tracking (MOT) and segmentation (MOTS) methods mainly follow the tracking-by-detection paradigm. Transformer-based end-to-end (E2E) solutions bring some ideas to MOT and MOTS, but they cannot achieve a new state-of-the-art (SOTA) performance in major MOT and MOTS benchmarks. Detection and association are two main modules of the tracking-by-detection paradigm. Association techniques mainly depend on the combination of motion and appearance information. As deep learning has been recently developed, the performance of the detection and appearance model is rapidly improved. These trends made us consider whether we can achieve SOTA based on only high-performance detection and appearance model. Our paper mainly focuses on exploring this direction based on CBNetV2 with Swin-B as a detection model and MoCo-v2 as a self-supervised appearance model. Motion information and IoU mapping were removed during the association. Our method wins 1st place on the MOTS track and wins 2nd on the MOT track in the CVPR2023 WAD workshop. We hope our simple and effective method can give some insights to the MOT and MOTS research community. Source code will be released under this git repository
</details>
<details>
<summary>摘要</summary>
近年来，主流多目标跟踪（MOT）和多目标分割（MOTS）方法主要采用跟踪检测 paradigm。基于 transformer 的端到端（E2E）解决方案在 MOT 和 MOTS 中带来了一些想法，但它们无法达到主要 MOT 和 MOTS benchmark 中的新状态前景（SOTA）性能。检测和归一化是跟踪检测 paradigm 的两个主要模块。归一化技术主要基于运动和外观信息的组合。随着深度学习的发展，检测和外观模型的性能得到了迅速提高。这些趋势使我们考虑了是否可以基于高性能的检测和外观模型达到 SOTA。我们的论文主要关注 exploring 这一方向，使用 CBNetV2 作为检测模型和 MoCo-v2 作为自主监督的外观模型。在归一化过程中，我们移除了运动信息和 IoU 映射。我们的方法在 CVPR2023 WAD 工作坊的 MOTS 轨道上获得了第一名，在 MOT 轨道上获得了第二名。我们希望我们的简单而有效的方法可以给 MOT 和 MOTS 研究社区提供一些想法。源代码将在这个 Git 仓库中发布。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Systematic-Weaknesses-of-DNNs-using-Counterfactuals"><a href="#Assessing-Systematic-Weaknesses-of-DNNs-using-Counterfactuals" class="headerlink" title="Assessing Systematic Weaknesses of DNNs using Counterfactuals"></a>Assessing Systematic Weaknesses of DNNs using Counterfactuals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01614">http://arxiv.org/abs/2308.01614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sujan Sai Gannamaneni, Michael Mock, Maram Akila</li>
<li>for: 这篇论文主要是为了探讨深度神经网络（DNN）在安全敏感应用中的测试方法，以及寻找和识别这些模型在特定输入空间中的系统性弱点。</li>
<li>methods: 这篇论文提出了一种基于对应推理的算法，用于验证已知subset的内在属性对模型性能的影响。这种方法通过模拟出不同属性之间的互动，以确定内在属性是否对模型性能的恶化做出了贡献。</li>
<li>results: 根据这篇论文的结果，在自动驾驶领域中的一个semantic segmentation模型中，发现存在不同的人工资产之间的性能差异，但是只有在某些情况下，资产类型本身是对模型性能的恶化原因。<details>
<summary>Abstract</summary>
With the advancement of DNNs into safety-critical applications, testing approaches for such models have gained more attention. A current direction is the search for and identification of systematic weaknesses that put safety assumptions based on average performance values at risk. Such weaknesses can take on the form of (semantically coherent) subsets or areas in the input space where a DNN performs systematically worse than its expected average. However, it is non-trivial to attribute the reason for such observed low performances to the specific semantic features that describe the subset. For instance, inhomogeneities within the data w.r.t. other (non-considered) attributes might distort results. However, taking into account all (available) attributes and their interaction is often computationally highly expensive. Inspired by counterfactual explanations, we propose an effective and computationally cheap algorithm to validate the semantic attribution of existing subsets, i.e., to check whether the identified attribute is likely to have caused the degraded performance. We demonstrate this approach on an example from the autonomous driving domain using highly annotated simulated data, where we show for a semantic segmentation model that (i) performance differences among the different pedestrian assets exist, but (ii) only in some cases is the asset type itself the reason for this reduction in the performance.
</details>
<details>
<summary>摘要</summary>
Inspired by counterfactual explanations, we propose an efficient and computationally inexpensive algorithm to validate the semantic attribution of existing subsets. We demonstrate this approach on an example from the autonomous driving domain using highly annotated simulated data. Our results show that while performance differences exist among different pedestrian assets, the asset type itself is not always the reason for the reduction in performance.
</details></li>
</ul>
<hr>
<h2 id="Discriminative-Graph-level-Anomaly-Detection-via-Dual-students-teacher-Model"><a href="#Discriminative-Graph-level-Anomaly-Detection-via-Dual-students-teacher-Model" class="headerlink" title="Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model"></a>Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01947">http://arxiv.org/abs/2308.01947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whb605/gladst">https://github.com/whb605/gladst</a></li>
<li>paper_authors: Fu Lin, Xuexiong Luo, Jia Wu, Jian Yang, Shan Xue, Zitong Wang, Haonan Gong</li>
<li>for: 本文目的是为了检测图像中的图形异常，而不是 traditional node-level anomaly detection 任务中的节点异常检测。</li>
<li>methods: 本文提出了一种新的图形异常检测方法，包括定义图像中异常信息、采用节点级和图像级信息差异来识别异常图像，以及使用两个学生模型和一个导师模型来分别学习正常和异常图像的表示。</li>
<li>results: 经过广泛的实验分析，本文的方法在实际世界图像 dataset 上显示了效果，能够准确检测图像中的异常图形。<details>
<summary>Abstract</summary>
Different from the current node-level anomaly detection task, the goal of graph-level anomaly detection is to find abnormal graphs that significantly differ from others in a graph set. Due to the scarcity of research on the work of graph-level anomaly detection, the detailed description of graph-level anomaly is insufficient. Furthermore, existing works focus on capturing anomalous graph information to learn better graph representations, but they ignore the importance of an effective anomaly score function for evaluating abnormal graphs. Thus, in this work, we first define anomalous graph information including node and graph property anomalies in a graph set and adopt node-level and graph-level information differences to identify them, respectively. Then, we introduce a discriminative graph-level anomaly detection framework with dual-students-teacher model, where the teacher model with a heuristic loss are trained to make graph representations more divergent. Then, two competing student models trained by normal and abnormal graphs respectively fit graph representations of the teacher model in terms of node-level and graph-level representation perspectives. Finally, we combine representation errors between two student models to discriminatively distinguish anomalous graphs. Extensive experiment analysis demonstrates that our method is effective for the graph-level anomaly detection task on graph datasets in the real world.
</details>
<details>
<summary>摘要</summary>
不同于当前节点级异常检测任务，graph-level异常检测的目标是找到图集中异常的图，并且与其他图集中的图进行比较。由于关于graph-level异常检测的研究缺乏，graph-level异常的详细描述不够。此外，现有的工作都是捕捉异常图信息来学习更好的图表示，但它们忽略了效果的异常分数函数的重要性。因此，在这个工作中，我们首先定义图集中的异常图信息，包括节点和图属性异常，并采用节点级和图级信息差来识别它们。然后，我们提出了一种有效的图级异常检测框架，基于双学生-教师模型，其中教师模型通过规则损失来训练图表示更加分散。然后，两个竞争的学生模型，分别使用正常和异常图来训练教师模型的图表示，并在节点级和图级表示视角下进行匹配。最后，我们将两个学生模型的表示错误相加，以分别地区分异常图。我们的方法在实际世界上的图据集上进行了广泛的实验分析，并证明其效果。
</details></li>
</ul>
<hr>
<h2 id="DOLCE-A-Descriptive-Ontology-for-Linguistic-and-Cognitive-Engineering"><a href="#DOLCE-A-Descriptive-Ontology-for-Linguistic-and-Cognitive-Engineering" class="headerlink" title="DOLCE: A Descriptive Ontology for Linguistic and Cognitive Engineering"></a>DOLCE: A Descriptive Ontology for Linguistic and Cognitive Engineering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01597">http://arxiv.org/abs/2308.01597</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Borgo, Roberta Ferrario, Aldo Gangemi, Nicola Guarino, Claudio Masolo, Daniele Porello, Emilio M. Sanfilippo, Laure Vieu</li>
<li>for:  dolce是一个基础 Ontology，用于提供一致的世界观，并且可以将各个领域知识融合到一起。</li>
<li>methods: DOLCE是基于 cognitive和语言考虑的，并且遵循了一些哲学原则和已Established ontological方法，例如OntoClean。</li>
<li>results: DOLCE在过去二十年中保持稳定，并且启发了大多数现有的顶层 ontologies，并且用于发展或改善标准和公共项目资源（例如CIDOC CRM、DBpedia和WordNet）。<details>
<summary>Abstract</summary>
DOLCE, the first top-level (foundational) ontology to be axiomatized, has remained stable for twenty years and today is broadly used in a variety of domains. DOLCE is inspired by cognitive and linguistic considerations and aims to model a commonsense view of reality, like the one human beings exploit in everyday life in areas as diverse as socio-technical systems, manufacturing, financial transactions and cultural heritage. DOLCE clearly lists the ontological choices it is based upon, relies on philosophical principles, is richly formalized, and is built according to well-established ontological methodologies, e.g. OntoClean. Because of these features, it has inspired most of the existing top-level ontologies and has been used to develop or improve standards and public domain resources (e.g. CIDOC CRM, DBpedia and WordNet). Being a foundational ontology, DOLCE is not directly concerned with domain knowledge. Its purpose is to provide the general categories and relations needed to give a coherent view of reality, to integrate domain knowledge, and to mediate across domains. In these 20 years DOLCE has shown that applied ontologies can be stable and that interoperability across reference and domain ontologies is a reality. This paper briefly introduces the ontology and shows how to use it on a few modeling cases.
</details>
<details>
<summary>摘要</summary>
DOLCE，第一个基础 Ontology（基础 ontology），已经稳定了二十年了，今天在多个领域都广泛使用。DOLCE 受到了认知和语言考虑的影响，旨在模型人类日常生活中的常识视角，如社技系统、制造、财务交易和文化遗产等领域。DOLCE 明确列出了其 ontological 选择基础，依靠哲学原则，富有形式化，按照良好的 ontological 方法ologies（如 OntoClean）建立。由于这些特点，它已经影响了大多数现有的基础 ontologies，并用于开发或改进标准和公共领域资源（如 CIDOC CRM、DBpedia 和 WordNet）。作为基础 ontology，DOLCE 不直接关心域知识。其目的是提供一个一致的视角，整合域知识，并在域之间媒介。在过去二十年中，DOLCE 表明了应用 ontologies 可以稳定，并且域 Ontology 之间的可操作性是现实。这篇文章简要介绍了 ontology，并示例了一些模型案例。
</details></li>
</ul>
<hr>
<h2 id="Holy-Grail-2-0-From-Natural-Language-to-Constraint-Models"><a href="#Holy-Grail-2-0-From-Natural-Language-to-Constraint-Models" class="headerlink" title="Holy Grail 2.0: From Natural Language to Constraint Models"></a>Holy Grail 2.0: From Natural Language to Constraint Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01589">http://arxiv.org/abs/2308.01589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimos Tsouros, Hélène Verhaeghe, Serdar Kadıoğlu, Tias Guns</li>
<li>for: 本研究旨在探讨使用预训练的大语言模型提取模型从文本问题描述中的可能性，以便提高Constraint Programming（CP）的普及率。</li>
<li>methods: 本研究使用了一种基于分解的提示方法，通过与GPT模型进行交互来提取模型。</li>
<li>results: 初步结果表明，这种方法可以帮助提取出高质量的模型，并且可以减少CP用户需要具备的专业知识和技能。<details>
<summary>Abstract</summary>
Twenty-seven years ago, E. Freuder highlighted that "Constraint programming represents one of the closest approaches computer science has yet made to the Holy Grail of programming: the user states the problem, the computer solves it". Nowadays, CP users have great modeling tools available (like Minizinc and CPMpy), allowing them to formulate the problem and then let a solver do the rest of the job, getting closer to the stated goal. However, this still requires the CP user to know the formalism and respect it. Another significant challenge lies in the expertise required to effectively model combinatorial problems. All this limits the wider adoption of CP. In this position paper, we investigate a possible approach to leverage pre-trained Large Language Models to extract models from textual problem descriptions. More specifically, we take inspiration from the Natural Language Processing for Optimization (NL4OPT) challenge and present early results with a decomposition-based prompting approach to GPT Models.
</details>
<details>
<summary>摘要</summary>
27年前，E. Freuder指出了“约束编程代表计算机科学最接近圣杯编程的尝试：用户定义问题，计算机解决”。目前，CP用户有了优秀的模型化工具（如Minizinc和CPMpy），可以将问题形式化并让解决器完成其余的任务，从而更接近目标。然而，这还需要CP用户了解正式语法，并且对 combinatorial 问题的模型化技巧具有专业知识。这些限制了CP更广泛的应用。在这篇Position paper中，我们investigate一种可能的方法，使用预训练的大型自然语言模型提取问题描述中的模型。更 Specifically，我们从Natural Language Processing for Optimization（NL4OPT）挑战中得到灵感，并使用分解基于Prompting Approach来应用GPT模型。
</details></li>
</ul>
<hr>
<h2 id="SoK-Assessing-the-State-of-Applied-Federated-Machine-Learning"><a href="#SoK-Assessing-the-State-of-Applied-Federated-Machine-Learning" class="headerlink" title="SoK: Assessing the State of Applied Federated Machine Learning"></a>SoK: Assessing the State of Applied Federated Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02454">http://arxiv.org/abs/2308.02454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tobias Müller, Maximilian Stäbler, Hugo Gascón, Frank Köster, Florian Matthes</li>
<li>for: This paper aims to explore the current state of applied Federated Machine Learning (FedML) and identify the challenges hindering its practical adoption.</li>
<li>methods: The paper uses a comprehensive systematic literature review to assess 74 relevant papers and analyze the real-world applicability of FedML, including its characteristics and emerging trends, motivational drivers, and application domains.</li>
<li>results: The paper identifies the challenges encountered in integrating FedML into real-life settings, providing insights that contribute to the further development and implementation of FedML in privacy-critical scenarios.<details>
<summary>Abstract</summary>
Machine Learning (ML) has shown significant potential in various applications; however, its adoption in privacy-critical domains has been limited due to concerns about data privacy. A promising solution to this issue is Federated Machine Learning (FedML), a model-to-data approach that prioritizes data privacy. By enabling ML algorithms to be applied directly to distributed data sources without sharing raw data, FedML offers enhanced privacy protections, making it suitable for privacy-critical environments. Despite its theoretical benefits, FedML has not seen widespread practical implementation. This study aims to explore the current state of applied FedML and identify the challenges hindering its practical adoption. Through a comprehensive systematic literature review, we assess 74 relevant papers to analyze the real-world applicability of FedML. Our analysis focuses on the characteristics and emerging trends of FedML implementations, as well as the motivational drivers and application domains. We also discuss the encountered challenges in integrating FedML into real-life settings. By shedding light on the existing landscape and potential obstacles, this research contributes to the further development and implementation of FedML in privacy-critical scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unsupervised-Representation-Learning-for-Time-Series-A-Review"><a href="#Unsupervised-Representation-Learning-for-Time-Series-A-Review" class="headerlink" title="Unsupervised Representation Learning for Time Series: A Review"></a>Unsupervised Representation Learning for Time Series: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01578">http://arxiv.org/abs/2308.01578</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mqwfrog/ults">https://github.com/mqwfrog/ults</a></li>
<li>paper_authors: Qianwen Meng, Hangwei Qian, Yong Liu, Yonghui Xu, Zhiqi Shen, Lizhen Cui</li>
<li>for: 本研究旨在系统地分析无监督表示学习方法，尤其是在时序数据上。</li>
<li>methods: 本文使用了多种无监督表示学习方法，包括对比学习、自适应 represencing 等。</li>
<li>results: 经验证明，对比学习方法在9个真实世界数据集上的表现很出色，而且可以快速实现和统一评估不同模型。<details>
<summary>Abstract</summary>
Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese无监督表示学习方法target=blank>target=blank aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample.  enable unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="SimTeG-A-Frustratingly-Simple-Approach-Improves-Textual-Graph-Learning"><a href="#SimTeG-A-Frustratingly-Simple-Approach-Improves-Textual-Graph-Learning" class="headerlink" title="SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning"></a>SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02565">http://arxiv.org/abs/2308.02565</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vermouthdky/simteg">https://github.com/vermouthdky/simteg</a></li>
<li>paper_authors: Keyu Duan, Qian Liu, Tat-Seng Chua, Shuicheng Yan, Wei Tsang Ooi, Qizhe Xie, Junxian He</li>
<li>for: 这个论文主要是为了提高文本图学习的效果，特别是在文本图 Representation learning 阶段。</li>
<li>methods: 这个论文使用了一种简单的方法，即在已经预训练的语言模型（LM）上进行超参数efficient fine-tuning（PEFT），然后使用最后的隐藏状态来生成节点嵌入。</li>
<li>results: 这个论文的实验结果表明，使用这种方法可以大幅提高多种图神经网络（GNN）在多个图 benchmark 上的表现。<details>
<summary>Abstract</summary>
Textual graphs (TGs) are graphs whose nodes correspond to text (sentences or documents), which are widely prevalent. The representation learning of TGs involves two stages: (i) unsupervised feature extraction and (ii) supervised graph representation learning. In recent years, extensive efforts have been devoted to the latter stage, where Graph Neural Networks (GNNs) have dominated. However, the former stage for most existing graph benchmarks still relies on traditional feature engineering techniques. More recently, with the rapid development of language models (LMs), researchers have focused on leveraging LMs to facilitate the learning of TGs, either by jointly training them in a computationally intensive framework (merging the two stages), or designing complex self-supervised training tasks for feature extraction (enhancing the first stage). In this work, we present SimTeG, a frustratingly Simple approach for Textual Graph learning that does not innovate in frameworks, models, and tasks. Instead, we first perform supervised parameter-efficient fine-tuning (PEFT) on a pre-trained LM on the downstream task, such as node classification. We then generate node embeddings using the last hidden states of finetuned LM. These derived features can be further utilized by any GNN for training on the same task. We evaluate our approach on two fundamental graph representation learning tasks: node classification and link prediction. Through extensive experiments, we show that our approach significantly improves the performance of various GNNs on multiple graph benchmarks.
</details>
<details>
<summary>摘要</summary>
文本图（TG）是一种广泛存在的图，其节点对应于文本（句子或文档）。图像学习TG的过程包括两个阶段：（i）不监督的特征提取和（ii）监督图像学习。在过去几年中，大量精力被投入到后一个阶段中，而GNNs（图像神经网络）在这个阶段中占据了主导地位。然而，前一个阶段的大多数现有的图标准 benchmark仍然采用传统的特征工程技术。随着语言模型（LM）的快速发展，研究人员开始利用LM来促进TG的学习，例如通过在计算昂贵的框架中同时训练LM和TG（合并两个阶段），或者设计复杂的自我超视图任务来提高特征提取（增强第一个阶段）。在这种情况下，我们提出了SimTeG，一种简单而惊人的文本图学习方法。我们首先在预训练LM上进行监督参数效率提升（PEFT），然后生成节点嵌入使用预训练LM的最后隐藏状态。这些 derivated 特征可以被任何GNN用于训练同一个任务。我们对两个基本的图表示学习任务进行了广泛的实验：节点类别化和链接预测。通过广泛的实验，我们显示了我们的方法可以在多个图标准 benchmark上提高多种GNN的表现。
</details></li>
</ul>
<hr>
<h2 id="Motion-Planning-Diffusion-Learning-and-Planning-of-Robot-Motions-with-Diffusion-Models"><a href="#Motion-Planning-Diffusion-Learning-and-Planning-of-Robot-Motions-with-Diffusion-Models" class="headerlink" title="Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models"></a>Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01557">http://arxiv.org/abs/2308.01557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joao Carvalho, An T. Le, Mark Baierl, Dorothea Koert, Jan Peters</li>
<li>for: 加速机器人动作规划优化的学习先骨</li>
<li>methods: 使用扩散模型作为先骨，直接从 posterior 动作分布中采样，并利用扩散模型的逆噪减法来编码动作数据的多模性</li>
<li>results: 在 simulate 的平面机器人和 7-DOF 机器人 manipulate 环境中，与基准方法进行比较，表明扩散模型是高维动作分布的强大先骨，能够Encoding 高维动作数据的多模性。<details>
<summary>Abstract</summary>
Learning priors on trajectory distributions can help accelerate robot motion planning optimization. Given previously successful plans, learning trajectory generative models as priors for a new planning problem is highly desirable. Prior works propose several ways on utilizing this prior to bootstrapping the motion planning problem. Either sampling the prior for initializations or using the prior distribution in a maximum-a-posterior formulation for trajectory optimization. In this work, we propose learning diffusion models as priors. We then can sample directly from the posterior trajectory distribution conditioned on task goals, by leveraging the inverse denoising process of diffusion models. Furthermore, diffusion has been recently shown to effectively encode data multimodality in high-dimensional settings, which is particularly well-suited for large trajectory dataset. To demonstrate our method efficacy, we compare our proposed method - Motion Planning Diffusion - against several baselines in simulated planar robot and 7-dof robot arm manipulator environments. To assess the generalization capabilities of our method, we test it in environments with previously unseen obstacles. Our experiments show that diffusion models are strong priors to encode high-dimensional trajectory distributions of robot motions.
</details>
<details>
<summary>摘要</summary>
学习轨迹分布可以帮助加速机器人运动规划优化。给出过去成功的计划，使用轨迹生成模型作为优化问题的先验分布是非常感兴趣的。先前的工作提出了多种使用这种先验来启动运动规划问题的方法。可以从先验中随机取样，或者使用先验分布来形式化最大 posterior 式对 trajectory 进行优化。在这种工作中，我们提议使用扩散模型来学习先验。我们可以通过扩散模型的逆干扰过程直接从任务目标条件下样本 posterior 轨迹分布。此外，扩散模型最近在高维设定中能够有效地编码数据多模性，这 particulary 适合大轨迹数据集。为了证明我们的方法效果，我们与多个基eline 进行比较，在 simulated 平面机器人和 7-DOF 机器人 manipulator 环境中进行测试。为了评估我们的方法泛化能力，我们在不同的障碍物环境中进行测试。我们的实验显示，扩散模型是高维轨迹分布的强大先验。
</details></li>
</ul>
<hr>
<h2 id="A-Global-Transport-Capacity-Risk-Prediction-Method-for-Rail-Transit-Based-on-Gaussian-Bayesian-Network"><a href="#A-Global-Transport-Capacity-Risk-Prediction-Method-for-Rail-Transit-Based-on-Gaussian-Bayesian-Network" class="headerlink" title="A Global Transport Capacity Risk Prediction Method for Rail Transit Based on Gaussian Bayesian Network"></a>A Global Transport Capacity Risk Prediction Method for Rail Transit Based on Gaussian Bayesian Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01556">http://arxiv.org/abs/2308.01556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhang Zhengyang, Dong Wei, Liu jun, Sun Xinya, Ji Yindong</li>
<li>for: 预测铁路公共交通网络运输容量风险，即铁路交通网络的负载与乘客流量的差异。</li>
<li>methods: 使用线性 Gaussian Bayesian 网络来解释预测模型，并基于铁路交通网络的三层结构（包括铁路交通网络、车流和乘客流）获取预测模型的训练数据。</li>
<li>results: 通过 simulate 例子验证了提议的方法的有效性。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Aiming at the prediction problem of transport capacity risk caused by the mismatch between the carrying capacity of rail transit network and passenger flow demand, this paper proposes an explainable prediction method of rail transit network transport capacity risk based on linear Gaussian Bayesian network. This method obtains the training data of the prediction model based on the simulation model of the rail transit system with a three-layer structure including rail transit network, train flow and passenger flow. A Bayesian network structure construction method based on the topology of the rail transit network is proposed, and the MLE (Maximum Likelihood Estimation) method is used to realize the parameter learning of the Bayesian network. Finally, the effectiveness of the proposed method is verified by simulation examples.
</details>
<details>
<summary>摘要</summary>
目标是预测由铁路 транспорт网络载客量和乘客流量差异引起的运输 capacidad 风险的预测方法，本文提出了可解释的预测方法基于线性 Gaussian Bayesian 网络。该方法通过基于铁路 транспорт网络的模拟模型，包括铁路网络、车流和乘客流，来获取预测模型的训练数据。提出了基于铁路网络 topology 的 Bayesian 网络结构建构方法，并使用 MLE (最大likelihood估计) 方法实现参数学习。最后，通过模拟例子验证了该方法的效果。Here's the translation of the text into Traditional Chinese:目的是预测由铁路 транспорт网络载客量和乘客流量差异引起的运输 capacidad 风险的预测方法，本文提出了可解释的预测方法基于线性 Gaussian Bayesian 网络。该方法通过基于铁路 транспорт网络的模拟模型，包括铁路网络、车流和乘客流，来获取预测模型的训练数据。提出了基于铁路网络 topology 的 Bayesian 网络结构建构方法，并使用 MLE (最大likelihood估计) 方法实现参数学习。最后，通过模拟例子验证了该方法的效果。
</details></li>
</ul>
<hr>
<h2 id="InterAct-Exploring-the-Potentials-of-ChatGPT-as-a-Cooperative-Agent"><a href="#InterAct-Exploring-the-Potentials-of-ChatGPT-as-a-Cooperative-Agent" class="headerlink" title="InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent"></a>InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01552">http://arxiv.org/abs/2308.01552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Po-Lin Chen, Cheng-Shang Chang</li>
<li>for: 这个论文探讨了将OpenAI的ChatGPT集成到embodied agent系统中，以评估它对交互决策benchmark的影响。</li>
<li>methods: 我们引入了InterAct方法，将ChatGPT fed with varied prompts，分配它多个角色，如检查员和排序员，然后与原始语言模型结合。</li>
<li>results: 我们的研究表明，在AlfWorld中，ChatGPT的表现率达98%，包括6个不同任务在模拟家庭环境中，这显示了ChatGPT在真实世界设置下处理复杂任务的能力，并为任务规划铺平了道路。<details>
<summary>Abstract</summary>
This research paper delves into the integration of OpenAI's ChatGPT into embodied agent systems, evaluating its influence on interactive decision-making benchmark. Drawing a parallel to the concept of people assuming roles according to their unique strengths, we introduce InterAct. In this approach, we feed ChatGPT with varied prompts, assigning it a numerous roles like a checker and a sorter, then integrating them with the original language model. Our research shows a remarkable success rate of 98% in AlfWorld, which consists of 6 different tasks in a simulated household environment, emphasizing the significance of proficient prompt engineering. The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.
</details>
<details>
<summary>摘要</summary>
这份研究论文探讨了OpenAI的ChatGPT在具有体系中的整合，评估其对交互决策 bencmark 的影响。我们引入InterAct方法，在不同的任务中 feed ChatGPT 不同的提示，让它扮演多种角色，如检查员和排序员，然后将其与原始语言模型集成。我们的研究发现，在AlfWorld中的6个任务中，ChatGPT 的成功率达98%，这些任务是在模拟的家庭环境中进行的，这 demonstartes ChatGPT 在实际世界中完成复杂任务的能力，从而铺平了进一步发展任务规划的道路。
</details></li>
</ul>
<hr>
<h2 id="Avoidance-Navigation-Based-on-Offline-Pre-Training-Reinforcement-Learning"><a href="#Avoidance-Navigation-Based-on-Offline-Pre-Training-Reinforcement-Learning" class="headerlink" title="Avoidance Navigation Based on Offline Pre-Training Reinforcement Learning"></a>Avoidance Navigation Based on Offline Pre-Training Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01551">http://arxiv.org/abs/2308.01551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Wenkai Ji Ruihang Zhang Yuxiang Lei Hao, Zhao Zijie</li>
<li>for: 这个论文旨在适用深度强化学习（DRL）技术，帮助无地图移动机器人进行避免导航。</li>
<li>methods: 论文提出了一种在未知环境中使用 raw 感知数据与控制变量的映射，以及一种高效的离线培训策略，以加速扫描阶段的随机探索。 论文还收集了一个通用的数据集，包括专家经验，以便用于其他导航培训工作。</li>
<li>results: 论文表明，采用预训练和优先级专家经验可以减少80%的培训时间，并且可以提高DRL奖励的2倍。这些方法还被证明可以在真实环境中实现无碰撞导航。论文还证明了这种DRL模型在不同环境中具有通用的普适性。<details>
<summary>Abstract</summary>
This paper presents a Pre-Training Deep Reinforcement Learning(DRL) for avoidance navigation without map for mobile robots which map raw sensor data to control variable and navigate in an unknown environment. The efficient offline training strategy is proposed to speed up the inefficient random explorations in early stage and we also collect a universal dataset including expert experience for offline training, which is of some significance for other navigation training work. The pre-training and prioritized expert experience are proposed to reduce 80\% training time and has been verified to improve the 2 times reward of DRL. The advanced simulation gazebo with real physical modelling and dynamic equations reduce the gap between sim-to-real. We train our model a corridor environment, and evaluate the model in different environment getting the same effect. Compared to traditional method navigation, we can confirm the trained model can be directly applied into different scenarios and have the ability to no collision navigate. It was demonstrated that our DRL model have universal general capacity in different environment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MusicLDM-Enhancing-Novelty-in-Text-to-Music-Generation-Using-Beat-Synchronous-Mixup-Strategies"><a href="#MusicLDM-Enhancing-Novelty-in-Text-to-Music-Generation-Using-Beat-Synchronous-Mixup-Strategies" class="headerlink" title="MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies"></a>MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01546">http://arxiv.org/abs/2308.01546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Chen, Yusong Wu, Haohe Liu, Marianna Nezhurina, Taylor Berg-Kirkpatrick, Shlomo Dubnov<br>for:这篇论文的目的是提出一种基于稳定扩散模型的文本到音乐生成模型，以解决音乐生成任务中的数据有限和版权问题。methods:这篇论文使用了稳定扩散模型和音乐LDM架构，并通过重新训练CLAP预训练模型和Hifi-GAN vocoder来适应音乐领域。此外，该论文还提出了两种不同的混合策略，以便在训练数据有限的情况下生成更多样化的音乐。results:论文的实验结果表明，提出的MusicLDM模型和混合策略可以提高生成的音乐质量和创新性，同时仍保持输入文本和生成音乐之间的相似性。此外，该论文还设计了一些新的评价指标，以证明MusicLDM模型和混合策略在生成音乐时的效果。<details>
<summary>Abstract</summary>
Diffusion models have shown promising results in cross-modal generation tasks, including text-to-image and text-to-audio generation. However, generating music, as a special type of audio, presents unique challenges due to limited availability of music data and sensitive issues related to copyright and plagiarism. In this paper, to tackle these challenges, we first construct a state-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion and AudioLDM architectures to the music domain. We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples. Then, to address the limitations of training data and to avoid plagiarism, we leverage a beat tracking model and propose two different mixup strategies for data augmentation: beat-synchronous audio mixup and beat-synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively. Such mixup strategies encourage the model to interpolate between musical training samples and generate new music within the convex hull of the training data, making the generated music more diverse while still staying faithful to the corresponding style. In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.
</details>
<details>
<summary>摘要</summary>
Diffusion模型在跨Modal生成任务中表现出色，包括文本到图像和文本到音频生成。然而，生成音乐，作为特殊的音频类型，存在独特的挑战，主要是数据的有限性和版权问题。在这篇论文中，我们为解决这些挑战，首先构建了领先的文本到音乐模型MusicLDM。我们在音乐领域使用Stable Diffusion和AudioLDM架构，并通过重新训练CLAP和Hifi-GAN vocoder来适应音乐领域。然后，为了解决训练数据的限制和避免抄袭，我们提出了拍数跟踪模型和两种不同的混合策略：拍数同步音频混合和拍数同步秘密混合，这些策略可以让模型在训练音乐样本之间进行混合，从而生成更多样的音乐，同时仍然保持与输入文本的相关性。此外，我们还设计了一些基于CLAP分数的新评价指标，以证明我们的提议的MusicLDM和拍数同步混合策略可以提高生成的音乐质量和新颖性，同时保持输入文本和生成音乐之间的相关性。
</details></li>
</ul>
<hr>
<h2 id="Lode-Enhancer-Level-Co-creation-Through-Scaling"><a href="#Lode-Enhancer-Level-Co-creation-Through-Scaling" class="headerlink" title="Lode Enhancer: Level Co-creation Through Scaling"></a>Lode Enhancer: Level Co-creation Through Scaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01543">http://arxiv.org/abs/2308.01543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debosmita Bhaumik, Julian Togelius, Georgios N. Yannakakis, Ahmed Khalifa</li>
<li>for: 这个论文的目的是用AI技术为创建2D游戏层提供设计协助工具。</li>
<li>methods: 论文使用深度神经网络来采用人工压缩的补丁来逐渐增加级别的级别，并将这些训练的神经网络集成到了一个基于网络的编辑器中，以便用户可以在不同的分辨率下创建和编辑层。</li>
<li>results: 论文通过训练神经网络来增加级别，并通过提供不同的分辨率来帮助用户快速创建和编辑层。在使用这个工具时，设计师感到了合作的感觉，喜欢这个概念，并提供了进一步改进的反馈。<details>
<summary>Abstract</summary>
We explore AI-powered upscaling as a design assistance tool in the context of creating 2D game levels. Deep neural networks are used to upscale artificially downscaled patches of levels from the puzzle platformer game Lode Runner. The trained networks are incorporated into a web-based editor, where the user can create and edit levels at three different levels of resolution: 4x4, 8x8, and 16x16. An edit at any resolution instantly transfers to the other resolutions. As upscaling requires inventing features that might not be present at lower resolutions, we train neural networks to reproduce these features. We introduce a neural network architecture that is capable of not only learning upscaling but also giving higher priority to less frequent tiles. To investigate the potential of this tool and guide further development, we conduct a qualitative study with 3 designers to understand how they use it. Designers enjoyed co-designing with the tool, liked its underlying concept, and provided feedback for further improvement.
</details>
<details>
<summary>摘要</summary>
我们探索基于人工智能的水平升级作为游戏等级设计工具。我们使用深度神经网络来升级由游戏平台冒险游戏《劫 runner》中 искусственно压缩的 patches 的等级。我们在基于网络的编辑器中 integrate 了这些训练过的网络，allowing 用户在不同的分辨率（4x4、8x8和16x16）上创建和编辑等级。任何一个分辨率的编辑都会立即传输到其他分辨率上。由于升级需要创造不存在于较低分辨率中的特征，我们训练神经网络来重现这些特征。我们提出了一种神经网络架构，可以不仅学习升级，而且在较少的块出现时给予更高的优先级。为了了解这种工具的潜力和进一步发展的方向，我们进行了3名设计师的质量调研，了解他们如何使用这种工具，并提供了反馈 для进一步改进。
</details></li>
</ul>
<hr>
<h2 id="Non-equilibrium-physics-from-spin-glasses-to-machine-and-neural-learning"><a href="#Non-equilibrium-physics-from-spin-glasses-to-machine-and-neural-learning" class="headerlink" title="Non-equilibrium physics: from spin glasses to machine and neural learning"></a>Non-equilibrium physics: from spin glasses to machine and neural learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01538">http://arxiv.org/abs/2308.01538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weishun Zhong</li>
<li>for: 这个论文的目的是研究杂乱体系中的emergent智能现象，以便更好地理解这些系统的工作机制和应用于人工智能领域。</li>
<li>methods: 这篇论文使用统计物理来描述杂乱体系中的emergent智能行为，并分析这些系统的学习机制和动力学特性。</li>
<li>results: 这篇论文发现了杂乱体系中学习机制和物理动力学之间的关系，并提出了一种基于统计物理的方法来设计智能系统。这些发现可能扩展我们对智能系统的现代理解，并揭示更多的计算基础结构适用于人工智能应用。<details>
<summary>Abstract</summary>
Disordered many-body systems exhibit a wide range of emergent phenomena across different scales. These complex behaviors can be utilized for various information processing tasks such as error correction, learning, and optimization. Despite the empirical success of utilizing these systems for intelligent tasks, the underlying principles that govern their emergent intelligent behaviors remain largely unknown. In this thesis, we aim to characterize such emergent intelligence in disordered systems through statistical physics. We chart a roadmap for our efforts in this thesis based on two axes: learning mechanisms (long-term memory vs. working memory) and learning dynamics (artificial vs. natural). Throughout our journey, we uncover relationships between learning mechanisms and physical dynamics that could serve as guiding principles for designing intelligent systems. We hope that our investigation into the emergent intelligence of seemingly disparate learning systems can expand our current understanding of intelligence beyond neural systems and uncover a wider range of computational substrates suitable for AI applications.
</details>
<details>
<summary>摘要</summary>
多体系统的异常行为展示了各种emergent现象，从不同的尺度到不同的级别。这些复杂的行为可以用于各种信息处理任务，如错误检查、学习和优化。虽然使用这些系统进行智能任务的实践成果非常出色，但是这些系统的下面的原理还未得到了充分了解。在这个论文中，我们想通过统计物理来描述这些emergent智能行为。我们根据两个轴来制定我们的路线图：学习机制（长期记忆 vs.工作记忆）和学习动态（人工vs.自然）。在我们的旅程中，我们发现了学习机制和物理动态之间的关系，这些关系可能成为设计智能系统的导向原理。我们希望通过对各种学习系统的emergent智能行为的研究，扩展我们当前对智能的理解，并探索更多的计算substrate适用于AI应用。
</details></li>
</ul>
<hr>
<h2 id="Food-Classification-using-Joint-Representation-of-Visual-and-Textual-Data"><a href="#Food-Classification-using-Joint-Representation-of-Visual-and-Textual-Data" class="headerlink" title="Food Classification using Joint Representation of Visual and Textual Data"></a>Food Classification using Joint Representation of Visual and Textual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02562">http://arxiv.org/abs/2308.02562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Mittal, Puneet Goyal, Joohi Chauhan</li>
<li>for: 这个研究旨在提出一个多 modal 分类框架，用于健康领域中的食品分类。</li>
<li>methods: 提议的网络使用 modified EfficientNet 和 Mish 活化函数进行图像分类，并使用传统的 BERT 对应网络进行文本分类。</li>
<li>results: 实验结果显示，提议的网络在大规模的 open-source 数据集 UPMC Food-101 上的评估中，与其他方法相比，获得了11.57% 和 6.34% 的精度差。<details>
<summary>Abstract</summary>
Food classification is an important task in health care. In this work, we propose a multimodal classification framework that uses the modified version of EfficientNet with the Mish activation function for image classification, and the traditional BERT transformer-based network is used for text classification. The proposed network and the other state-of-the-art methods are evaluated on a large open-source dataset, UPMC Food-101. The experimental results show that the proposed network outperforms the other methods, a significant difference of 11.57% and 6.34% in accuracy is observed for image and text classification, respectively, when compared with the second-best performing method. We also compared the performance in terms of accuracy, precision, and recall for text classification using both machine learning and deep learning-based models. The comparative analysis from the prediction results of both images and text demonstrated the efficiency and robustness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
食品分类是医疗保健领域中的一项重要任务。在这项工作中，我们提出了一种多Modal分类框架，使用Modified版EfficientNet和Mish活动函数进行图像分类，并使用传统的BERT变换网络进行文本分类。我们的提案网络和其他状态泰施方法在大量的开源数据集UPMC Food-101上进行了评估。实验结果表明，我们的提案网络在图像和文本分类方面的性能都高于其他方法，与第二高性能方法的差异为11.57%和6.34%。我们还对文本分类方面的性能进行了精度、准确率和回归率的比较分析，并通过图像和文本预测结果的对比，证明了我们的方法的有效性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Digital-twin-brain-a-bridge-between-biological-intelligence-and-artificial-intelligence"><a href="#Digital-twin-brain-a-bridge-between-biological-intelligence-and-artificial-intelligence" class="headerlink" title="Digital twin brain: a bridge between biological intelligence and artificial intelligence"></a>Digital twin brain: a bridge between biological intelligence and artificial intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01941">http://arxiv.org/abs/2308.01941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Xiong, Congying Chu, Lingzhong Fan, Ming Song, Jiaqi Zhang, Yawei Ma, Ruonan Zheng, Junyang Zhang, Zhengyi Yang, Tianzi Jiang</li>
<li>for: 本文提出了一种名为“数字双脑”（Digital Twin Brain，DTB）的平台，用于将生物智能和人工智能联系起来，以更好地探索大脑的复杂性。</li>
<li>methods: 该平台包括三个核心元素：脑结构、底层模型和广泛的应用领域。此外，脑 Atlases 提供了关键的约束，以保持脑的网络结构在 DTB 中。</li>
<li>results: DTB 可以提供前所未有的智能出现和神经疾病研究，以及人工智能的发展和精准心理医疗的潜在应用。<details>
<summary>Abstract</summary>
In recent years, advances in neuroscience and artificial intelligence have paved the way for unprecedented opportunities for understanding the complexity of the brain and its emulation by computational systems. Cutting-edge advancements in neuroscience research have revealed the intricate relationship between brain structure and function, while the success of artificial neural networks highlights the importance of network architecture. Now is the time to bring them together to better unravel how intelligence emerges from the brain's multiscale repositories. In this review, we propose the Digital Twin Brain (DTB) as a transformative platform that bridges the gap between biological and artificial intelligence. It consists of three core elements: the brain structure that is fundamental to the twinning process, bottom-layer models to generate brain functions, and its wide spectrum of applications. Crucially, brain atlases provide a vital constraint, preserving the brain's network organization within the DTB. Furthermore, we highlight open questions that invite joint efforts from interdisciplinary fields and emphasize the far-reaching implications of the DTB. The DTB can offer unprecedented insights into the emergence of intelligence and neurological disorders, which holds tremendous promise for advancing our understanding of both biological and artificial intelligence, and ultimately propelling the development of artificial general intelligence and facilitating precision mental healthcare.
</details>
<details>
<summary>摘要</summary>
recent years, advances in neuroscience and artificial intelligence have created unprecedented opportunities for understanding the complexity of the brain and its emulation by computational systems. cutting-edge advancements in neuroscience research have revealed the intricate relationship between brain structure and function, while the success of artificial neural networks highlights the importance of network architecture. now is the time to bring them together to better unravel how intelligence emerges from the brain's multiscale repositories. in this review, we propose the digital twin brain (dTB) as a transformative platform that bridges the gap between biological and artificial intelligence. it consists of three core elements: the brain structure that is fundamental to the twinning process, bottom-layer models to generate brain functions, and its wide spectrum of applications. crucially, brain atlases provide a vital constraint, preserving the brain's network organization within the dTB. furthermore, we highlight open questions that invite joint efforts from interdisciplinary fields and emphasize the far-reaching implications of the dTB. the dTB can offer unprecedented insights into the emergence of intelligence and neurological disorders, which holds tremendous promise for advancing our understanding of both biological and artificial intelligence, and ultimately propelling the development of artificial general intelligence and facilitating precision mental healthcare.
</details></li>
</ul>
<hr>
<h2 id="Quantum-Multi-Agent-Reinforcement-Learning-for-Autonomous-Mobility-Cooperation"><a href="#Quantum-Multi-Agent-Reinforcement-Learning-for-Autonomous-Mobility-Cooperation" class="headerlink" title="Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation"></a>Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01519">http://arxiv.org/abs/2308.01519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soohyun Park, Jae Pyoung Kim, Chanyoung Park, Soyi Jung, Joongheon Kim</li>
<li>for: 本研究旨在提出一种量子多智能学习（QMARL）算法，用于解决多智能系统中的强制参与问题。</li>
<li>methods: 本研究使用了actor-critic网络来实现QMARL，并通过提出一种投影值度量（PVM）来提高其可扩展性和快速启发。</li>
<li>results: 对于多智能系统，我们的提出的QMARL算法可以更好地处理噪声中间规模量子（NISQ）时代的限制，并且可以更快地到达启发。此外，我们的QMARL算法还可以更有效地使用参数，从而提高效率。<details>
<summary>Abstract</summary>
For Industry 4.0 Revolution, cooperative autonomous mobility systems are widely used based on multi-agent reinforcement learning (MARL). However, the MARL-based algorithms suffer from huge parameter utilization and convergence difficulties with many agents. To tackle these problems, a quantum MARL (QMARL) algorithm based on the concept of actor-critic network is proposed, which is beneficial in terms of scalability, to deal with the limitations in the noisy intermediate-scale quantum (NISQ) era. Additionally, our QMARL is also beneficial in terms of efficient parameter utilization and fast convergence due to quantum supremacy. Note that the reward in our QMARL is defined as task precision over computation time in multiple agents, thus, multi-agent cooperation can be realized. For further improvement, an additional technique for scalability is proposed, which is called projection value measure (PVM). Based on PVM, our proposed QMARL can achieve the highest reward, by reducing the action dimension into a logarithmic-scale. Finally, we can conclude that our proposed QMARL with PVM outperforms the other algorithms in terms of efficient parameter utilization, fast convergence, and scalability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-scale-Generative-Simulation-Artificial-Intelligence-the-Next-Hotspot-in-Generative-AI"><a href="#Large-scale-Generative-Simulation-Artificial-Intelligence-the-Next-Hotspot-in-Generative-AI" class="headerlink" title="Large-scale Generative Simulation Artificial Intelligence: the Next Hotspot in Generative AI"></a>Large-scale Generative Simulation Artificial Intelligence: the Next Hotspot in Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02561">http://arxiv.org/abs/2308.02561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Wang, Yanghe Feng, Jincai Huang, Yiqin Lv, Zheng Xie, Xiaoshan Gao</li>
<li>for: 这篇研究是为了探讨大规模生成实验人工智能（LS-GenAI）是下一个热点，以应对实际挑战，例如学习资源的仅对等和科学发现的偏好。</li>
<li>methods: 本研究使用了大规模生成实验人工智能（LS-GenAI），以探讨实际挑战，例如学习资源的仅对等和科学发现的偏好。</li>
<li>results: 本研究获得了重要的发现，包括实际挑战的解决方案和LS-GenAI的应用前景。<details>
<summary>Abstract</summary>
The concept of GenAI has been developed for decades. Until recently, it has impressed us with substantial breakthroughs in natural language processing and computer vision, actively engaging in industrial scenarios. Noticing the practical challenges, e.g., limited learning resources, and overly dependencies on scientific discovery empiricism, we nominate large-scale generative simulation artificial intelligence (LS-GenAI) as the next hotspot for GenAI to connect.
</details>
<details>
<summary>摘要</summary>
GenAI的概念已经在数十年内发展，直到最近，它在自然语言处理和计算机视觉领域带来了重要的突破，活跃地投入到工业场景中。注意到实际挑战，例如有限的学习资源和科学发现的过度依赖，我们提名大规模生成仿真人工智能（LS-GenAI）为下一个GenAI连接的热点。
</details></li>
</ul>
<hr>
<h2 id="Implicit-Occupancy-Flow-Fields-for-Perception-and-Prediction-in-Self-Driving"><a href="#Implicit-Occupancy-Flow-Fields-for-Perception-and-Prediction-in-Self-Driving" class="headerlink" title="Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving"></a>Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01471">http://arxiv.org/abs/2308.01471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Agro, Quinlan Sykora, Sergio Casas, Raquel Urtasun</li>
<li>for: 本研究旨在提高自动驾驶车辆（SDV）的见觉和未来行为预测能力。</li>
<li>methods: 本研究使用了一种统一的见觉和未来预测方法，通过单个神经网络来表示占用和流速grid。该方法可以 direktly被运动规划器查询，避免过度计算和缺失对象检测。此外，该方法还使用了全球注意机制，以增强跨度检测和预测。</li>
<li>results: 经过EXTENSIVE EXPERIMENTS在城市和高速公路上，研究发现，该方法可以超越当前状态的艺术。更多信息可以在<a target="_blank" rel="noopener" href="https://waabi.ai/research/implicito%E4%B8%8A%E5%BE%97%E5%88%B0%E3%80%82">https://waabi.ai/research/implicito上得到。</a><details>
<summary>Abstract</summary>
A self-driving vehicle (SDV) must be able to perceive its surroundings and predict the future behavior of other traffic participants. Existing works either perform object detection followed by trajectory forecasting of the detected objects, or predict dense occupancy and flow grids for the whole scene. The former poses a safety concern as the number of detections needs to be kept low for efficiency reasons, sacrificing object recall. The latter is computationally expensive due to the high-dimensionality of the output grid, and suffers from the limited receptive field inherent to fully convolutional networks. Furthermore, both approaches employ many computational resources predicting areas or objects that might never be queried by the motion planner. This motivates our unified approach to perception and future prediction that implicitly represents occupancy and flow over time with a single neural network. Our method avoids unnecessary computation, as it can be directly queried by the motion planner at continuous spatio-temporal locations. Moreover, we design an architecture that overcomes the limited receptive field of previous explicit occupancy prediction methods by adding an efficient yet effective global attention mechanism. Through extensive experiments in both urban and highway settings, we demonstrate that our implicit model outperforms the current state-of-the-art. For more information, visit the project website: https://waabi.ai/research/implicito.
</details>
<details>
<summary>摘要</summary>
一个自动驾驶车辆（SDV）需要能够感知周围环境并预测其他交通参与者的未来行为。现有的工作都是先检测对象，然后预测检测到的对象的轨迹，或者预测整个场景的厚度占用和流动Grid。前者会导致安全隐患，因为需要保持检测数量低，牺牲对象回忆。后者因为输出格式的高维度而 computationally expensive，而且受到全连接神经网络的局限性困惑。此外，这些方法都需要大量计算资源预测可能不会被访问的区域或对象。这种情况驱动我们开发了一种统一的感知和未来预测方法，该方法可以直接由运动规划器查询，避免不必要的计算。此外，我们还设计了一种高效又有效的全局注意机制，以解决过去的显式占用预测方法的有限范围问题。经过广泛的实验，我们证明了我们的含义模型在城市和高速公路上都能够超越当前状态。更多信息请访问项目网站：https://waabi.ai/research/implicito。
</details></li>
</ul>
<hr>
<h2 id="Training-Data-Protection-with-Compositional-Diffusion-Models"><a href="#Training-Data-Protection-with-Compositional-Diffusion-Models" class="headerlink" title="Training Data Protection with Compositional Diffusion Models"></a>Training Data Protection with Compositional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01937">http://arxiv.org/abs/2308.01937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Golatkar, Alessandro Achille, Ashwin Swaminathan, Stefano Soatto</li>
<li>for: 这篇论文是用于描述一种名为 compartmentalized diffusion models（CDM）的方法，可以在推理时将不同的扩散模型（或提示）组合起来，以达到与全数据同时训练的性能。</li>
<li>methods: 这篇论文使用的方法是在不同的数据源上训练不同的扩散模型，并在推理时将它们组合起来。每个模型只包含它在训练时接触到的数据信息，从而实现数据隐私和权限控制。</li>
<li>results: 这篇论文的结果表明，CDM可以实现选择性的忘记和持续学习，以及根据用户的访问权限服务自定义的模型。此外，CDM还可以确定某些数据子集对于生成特定样本的重要性。<details>
<summary>Abstract</summary>
We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
</details>
<details>
<summary>摘要</summary>
我们介绍Compartmentalized Diffusion Models（CDM），一种方法可以在推广过程中训练不同的扩散模型（或提示），并在推广时进行可compose的方式。个别模型可以在不同的时间、不同的分布和领域上进行独立的训练，然后在推广时进行混合。此外，每个模型只包含它在训练过程中接触到的subset of data的信息，因此可以实现多种训练数据保护。特别是，CDMs是首个允许大规模扩散模型进行选择性遗忘和持续学习，以及根据用户的存取权服务自定义模型。此外，CDMs还允许决定特定样本的某些subset of data的重要性。
</details></li>
</ul>
<hr>
<h2 id="Dual-Governance-The-intersection-of-centralized-regulation-and-crowdsourced-safety-mechanisms-for-Generative-AI"><a href="#Dual-Governance-The-intersection-of-centralized-regulation-and-crowdsourced-safety-mechanisms-for-Generative-AI" class="headerlink" title="Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI"></a>Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04448">http://arxiv.org/abs/2308.04448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Avijit Ghosh, Dhanya Lakshmi<br>for: 这个论文的目的是提出一种名为“双重管理”的框架，以确保在生成人工智能技术的应用中保障安全和伦理。methods: 该论文使用的方法包括：* 分析现有的中央化法规和社区自身的安全机制，以找到它们之间的互补点。* 提出一种名为“双重管理”的框架，以实现中央化法规和社区自身的共同管理。results: 该论文的结果表明，通过实施“双重管理”框架，可以促进生成人工智能技术的创新和创新，同时确保其安全和伦理的应用。<details>
<summary>Abstract</summary>
Generative Artificial Intelligence (AI) has seen mainstream adoption lately, especially in the form of consumer-facing, open-ended, text and image generating models. However, the use of such systems raises significant ethical and safety concerns, including privacy violations, misinformation and intellectual property theft. The potential for generative AI to displace human creativity and livelihoods has also been under intense scrutiny. To mitigate these risks, there is an urgent need of policies and regulations responsible and ethical development in the field of generative AI. Existing and proposed centralized regulations by governments to rein in AI face criticisms such as not having sufficient clarity or uniformity, lack of interoperability across lines of jurisdictions, restricting innovation, and hindering free market competition. Decentralized protections via crowdsourced safety tools and mechanisms are a potential alternative. However, they have clear deficiencies in terms of lack of adequacy of oversight and difficulty of enforcement of ethical and safety standards, and are thus not enough by themselves as a regulation mechanism. We propose a marriage of these two strategies via a framework we call Dual Governance. This framework proposes a cooperative synergy between centralized government regulations in a U.S. specific context and safety mechanisms developed by the community to protect stakeholders from the harms of generative AI. By implementing the Dual Governance framework, we posit that innovation and creativity can be promoted while ensuring safe and ethical deployment of generative AI.
</details>
<details>
<summary>摘要</summary>
现代化的人工智能（AI）在最近几年内得到了广泛的普及，尤其是在用户直接参与、开放结束的文本和图像生成模型的形式。然而，使用这些系统会引起重要的伦理和安全问题，包括隐私侵犯、谣言和知识产权盗窃。AI的生成能力可能会取代人类的创造力和生活方式，也在严重的检查下。为了缓解这些风险，需要负责任的政策和法规，以促进开发领域中负责任的AI发展。现有和提议的中央政府的法规，尽管具有一定的优点，但也存在不足的明确性和一致性，不可避免的干扰创新和自由市场竞争。 decentralized的保护机制，例如人类协同发展的安全工具和机制，可以作为一种替代方案。然而，它们缺乏伦理和安全标准的监管和执行能力，因此不具备充分的监管能力。为了解决这些问题，我们提出了一种名为“双重治理”的框架。这种框架建议在美国特有的 контексте下，通过中央政府的法规和社区开发的安全机制，保护利益者从生成AI的危害中。通过实施“双重治理”框架，我们认为可以促进创新和创造力，同时确保安全和负责任的AI发展。
</details></li>
</ul>
<hr>
<h2 id="VertexSerum-Poisoning-Graph-Neural-Networks-for-Link-Inference"><a href="#VertexSerum-Poisoning-Graph-Neural-Networks-for-Link-Inference" class="headerlink" title="VertexSerum: Poisoning Graph Neural Networks for Link Inference"></a>VertexSerum: Poisoning Graph Neural Networks for Link Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01469">http://arxiv.org/abs/2308.01469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyi Ding, Shijin Duan, Xiaolin Xu, Yunsi Fei</li>
<li>for: 本文旨在攻击图Structured Data中的图结构学习模型（Graph Neural Networks，GNNs），以便窃取图连接信息。</li>
<li>methods: 本文提出了一种新的图恶意攻击方法，即VertexSerum，可以增强图连接信息泄露。此外，本文还提出了一种注意力机制，可以在链接检测网络中嵌入，以更准确地推测节点相互之间的连接关系。</li>
<li>results: 本文的实验结果表明，VertexSerumsignificantly outperforms state-of-the-art（SOTA）链接推测攻击，提高了平均混合精度分数（AUC）的提升率为9.8%。此外，本文的实验还表明，VertexSerum在黑盒和在线学习 Setting下都有出色的应用可能性。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) have brought superb performance to various applications utilizing graph structural data, such as social analysis and fraud detection. The graph links, e.g., social relationships and transaction history, are sensitive and valuable information, which raises privacy concerns when using GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel graph poisoning attack that increases the effectiveness of graph link stealing by amplifying the link connectivity leakage. To infer node adjacency more accurately, we propose an attention mechanism that can be embedded into the link detection network. Our experiments demonstrate that VertexSerum significantly outperforms the SOTA link inference attack, improving the AUC scores by an average of $9.8\%$ across four real-world datasets and three different GNN structures. Furthermore, our experiments reveal the effectiveness of VertexSerum in both black-box and online learning settings, further validating its applicability in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 有提供了出色的表现在使用图structured数据的各种应用程序中，如社交分析和诈骗探测。图链，例如社交关系和交易历史记录，是敏感和有价值的信息，使得使用 GNNs 时存在隐私问题。为了利用这些漏洞，我们提议VertexSerum，一种新的图毒注攻击，可以增强图链泄露的连接性。为更准确地推断节点相邻关系，我们提议一种注意力机制可以在链接检测网络中嵌入。我们的实验表明，VertexSerum可以明显超过当前链接推断攻击的最佳实践（SOTA），提高了平均抽样率9.8%。此外，我们的实验还表明VertexSerum在黑盒和在线学习设置下都有出色的应用可行性。
</details></li>
</ul>
<hr>
<h2 id="Novel-Physics-Based-Machine-Learning-Models-for-Indoor-Air-Quality-Approximations"><a href="#Novel-Physics-Based-Machine-Learning-Models-for-Indoor-Air-Quality-Approximations" class="headerlink" title="Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations"></a>Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01438">http://arxiv.org/abs/2308.01438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Mohammadshirazi, Aida Nadafian, Amin Karimi Monsefi, Mohammad H. Rafiei, Rajiv Ramnath</li>
<li>for: 本研究旨在提出六种基于物理知识的机器学习模型，用于精准预测室内污染物质浓度。</li>
<li>methods: 本研究使用了状态空间概念、闭包回卷单元和分解技术，搭建了一种轻量级、计算效率高的机器学习模型。</li>
<li>results: 实验结果表明，提议的模型比相关的现状艺术模型更加简单、计算效率高，同时能够更好地捕捉室内空气质量数据中的高度非线性特征。<details>
<summary>Abstract</summary>
Cost-effective sensors are capable of real-time capturing a variety of air quality-related modalities from different pollutant concentrations to indoor/outdoor humidity and temperature. Machine learning (ML) models are capable of performing air-quality "ahead-of-time" approximations. Undoubtedly, accurate indoor air quality approximation significantly helps provide a healthy indoor environment, optimize associated energy consumption, and offer human comfort. However, it is crucial to design an ML architecture to capture the domain knowledge, so-called problem physics. In this study, we propose six novel physics-based ML models for accurate indoor pollutant concentration approximations. The proposed models include an adroit combination of state-space concepts in physics, Gated Recurrent Units, and Decomposition techniques. The proposed models were illustrated using data collected from five offices in a commercial building in California. The proposed models are shown to be less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. The superiority of the proposed models is due to their relatively light architecture (computational efficiency) and, more importantly, their ability to capture the underlying highly nonlinear patterns embedded in the often contaminated sensor-collected indoor air quality temporal data.
</details>
<details>
<summary>摘要</summary>
Cost-effective sensors can real-time capture various air quality-related modalities, from different pollutant concentrations to indoor/outdoor humidity and temperature. Machine learning (ML) models can perform air-quality "ahead-of-time" approximations. Accurate indoor air quality approximation is crucial for providing a healthy indoor environment, optimizing associated energy consumption, and offering human comfort. However, it is essential to design an ML architecture that captures the domain knowledge, so-called problem physics. In this study, we propose six novel physics-based ML models for accurate indoor pollutant concentration approximations. The proposed models combine state-space concepts in physics, Gated Recurrent Units, and Decomposition techniques. The proposed models were illustrated using data collected from five offices in a commercial building in California. The proposed models are less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. The superiority of the proposed models is due to their light architecture and their ability to capture the underlying highly nonlinear patterns in the often contaminated sensor-collected indoor air quality temporal data.
</details></li>
</ul>
<hr>
<h2 id="Why-Do-We-Need-Neuro-symbolic-AI-to-Model-Pragmatic-Analogies"><a href="#Why-Do-We-Need-Neuro-symbolic-AI-to-Model-Pragmatic-Analogies" class="headerlink" title="Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?"></a>Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01936">http://arxiv.org/abs/2308.01936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thilini Wijesiriwardene, Amit Sheth, Valerie L. Shalin, Amitava Das</li>
<li>for: 这篇论文探讨了大自然语言模型（LLM）在处理文本中逐渐增加复杂度的 analogy 性能。</li>
<li>methods: 这篇论文使用了 Neuro-symbolic AI 技术，结合统计学和符号学 AI，以提高文本表示，强调和增强相关内容，并提供抽象和导航。</li>
<li>results: 研究发现，随着 analogy 的复杂度增加，需要更多的、多样化的知识，不可能由 lexical co-occurrence statistics 提供。Neuro-symbolic AI 技术可以维持 LLM 的效率，同时保持 analogy 的解释能力，帮助进行教学应用。<details>
<summary>Abstract</summary>
A hallmark of intelligence is the ability to use a familiar domain to make inferences about a less familiar domain, known as analogical reasoning. In this article, we delve into the performance of Large Language Models (LLMs) in dealing with progressively complex analogies expressed in unstructured text. We discuss analogies at four distinct levels of complexity: lexical analogies, syntactic analogies, semantic analogies, and pragmatic analogies. As the analogies become more complex, they require increasingly extensive, diverse knowledge beyond the textual content, unlikely to be found in the lexical co-occurrence statistics that power LLMs. To address this, we discuss the necessity of employing Neuro-symbolic AI techniques that combine statistical and symbolic AI, informing the representation of unstructured text to highlight and augment relevant content, provide abstraction and guide the mapping process. Our knowledge-informed approach maintains the efficiency of LLMs while preserving the ability to explain analogies for pedagogical applications.
</details>
<details>
<summary>摘要</summary>
一种智能的特征是使用熟悉的领域来对不熟悉的领域进行推理，这称为对比推理。在这篇文章中，我们探讨大语言模型（LLM）在处理不断增长复杂的对比表达的文本中表现。我们讨论了四种不同的复杂性水平的对比：lexical对比、语法对比、semantic对比和 Pragmatic对比。随着对比的复杂程度增加，它们需要更多的、多样化的知识，不可能通过文本内容的lexical co-occurrence statistics来找到。为此，我们讨论了结合统计学和符号学AI技术的必要性，以便高亮和增强文本内容，提供抽象和导向映射过程。我们的知识填充approach保持了LLM的效率，同时保留了对对比的解释，以便在教育应用中使用。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Potential-of-Similarity-Matching-Scalability-Supervision-and-Pre-training"><a href="#Unlocking-the-Potential-of-Similarity-Matching-Scalability-Supervision-and-Pre-training" class="headerlink" title="Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training"></a>Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02427">http://arxiv.org/abs/2308.02427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanis Bahroun, Shagesh Sridharan, Atithi Acharya, Dmitri B. Chklovskii, Anirvan M. Sengupta</li>
<li>for: 这项研究旨在开发一种基于本地学习规则的可能学习算法，以替代具有限制的反射层梯队列（BP）算法。</li>
<li>methods: 研究人员提出了一种基于PyTorch实现的卷积非负相似匹配（SM）算法，以扩展SM到大规模数据集。此外，他们还提出了一种基于SM层的本地监督学习目标，并在PyTorch实现中进行了预训练模型 such as LeNet的比较。</li>
<li>results: 研究人员发现，使用PyTorch实现的SM算法可以在计算效率和生物可能性方面与BP算法相比，并且可以在大规模数据集上扩展。此外，他们还发现，将SM层与BP算法拼接在一起可以提高模型的评价性能。<details>
<summary>Abstract</summary>
While effective, the backpropagation (BP) algorithm exhibits limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms. i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch. ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers. iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computational efficiency opening multiple avenues for further explorations.
</details>
<details>
<summary>摘要</summary>
而Effective的Backpropagation（BP）算法具有限制，包括生物学可能性、计算成本和在线学习适用性。因此，有越来越多的关注于开发生物学可能性的学习方法。这项研究强调在大规模数据集上扩大Similarity Matching（SM）框架，与生物系统中观察到的机制相一致，并提供在线、本地和生物学可能性的算法。（i）为了扩大SM到大数据集，我们提议使用PyTorch实现Convolutional Nonnegative SM。（ii）我们引入本地监督SM目标，与栅格分析相似，以推进SM层堆叠。（iii）我们利用PyTorch实现对预训练架构如LeNet进行评估，并与BP训练模型进行比较。这项工作结合了生物学可能性的算法和计算效率，开启了多个探索的可能性。
</details></li>
</ul>
<hr>
<h2 id="Bio-Clinical-BERT-BERT-Base-and-CNN-Performance-Comparison-for-Predicting-Drug-Review-Satisfaction"><a href="#Bio-Clinical-BERT-BERT-Base-and-CNN-Performance-Comparison-for-Predicting-Drug-Review-Satisfaction" class="headerlink" title="Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction"></a>Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03782">http://arxiv.org/abs/2308.03782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Ling<br>for: 这项研究的目的是开发一种可以分析病人药物评价文本，并准确地分类为正面、中性或负面的自然语言处理（NLP）模型。methods: 这项研究采用了多种分类模型，包括BERT基础模型、医学+клиничеBERT模型和简单的CNN模型。results: 研究结果表明，医学+клиничеBERT模型在表现 overall 方面表现出色，特别是在医疗术语方面表现出了11%的macro f1和回归分数提高，如图2所示。<details>
<summary>Abstract</summary>
The objective of this study is to develop natural language processing (NLP) models that can analyze patients' drug reviews and accurately classify their satisfaction levels as positive, neutral, or negative. Such models would reduce the workload of healthcare professionals and provide greater insight into patients' quality of life, which is a critical indicator of treatment effectiveness. To achieve this, we implemented and evaluated several classification models, including a BERT base model, Bio+Clinical BERT, and a simpler CNN. Results indicate that the medical domain-specific Bio+Clinical BERT model significantly outperformed the general domain base BERT model, achieving macro f1 and recall score improvement of 11%, as shown in Table 2. Future research could explore how to capitalize on the specific strengths of each model. Bio+Clinical BERT excels in overall performance, particularly with medical jargon, while the simpler CNN demonstrates the ability to identify crucial words and accurately classify sentiment in texts with conflicting sentiments.
</details>
<details>
<summary>摘要</summary>
目标是开发一种自然语言处理（NLP）模型，能够分析患者的药物评价，并准确地将满意度分类为正面、中性或负面。这些模型将减轻医疗专业人员的工作负担，并为患者的生活质量提供更多的信息，这是治疗效果的关键指标。为达到这一目标，我们实施和评估了多种分类模型，包括BERT基础模型、医学+临床BERT和简单的CNN。结果表明，具有医学领域特点的Bio+Clinical BERT模型在表格2中显著超过了通用领域基础BERT模型，实现了 macro f1和回忆得分的11%的提升，如图表2所示。未来的研究可以探讨如何利用每个模型的特点。Bio+Clinical BERT在整体性能方面表现出色，特别是对医疗术语的处理能力强，而简单的CNN则能够准确地识别关键词并在文本中 conflicting 的情感下准确地分类 sentiment。
</details></li>
</ul>
<hr>
<h2 id="The-Paradigm-Shifts-in-Artificial-Intelligence"><a href="#The-Paradigm-Shifts-in-Artificial-Intelligence" class="headerlink" title="The Paradigm Shifts in Artificial Intelligence"></a>The Paradigm Shifts in Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02558">http://arxiv.org/abs/2308.02558</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/its-me-yasho/AI-virtual-mouse-">https://github.com/its-me-yasho/AI-virtual-mouse-</a></li>
<li>paper_authors: Vasant Dhar</li>
<li>for: 本研究旨在探讨人工智能领域过去60年中的 paradigm shift，以及现在的大型预训系统如GPT-3和ChatGPT等 conversational agents 的emergence。</li>
<li>methods: 本研究使用库恩的科学进步框架（Kuhn, 1962）来框定每个 paradigm 的发展和衰落，以及现在的AI技术 configurable 应用。</li>
<li>results: 研究发现，现在的AI技术已成为一种通用技术，可以 configurable 应用于各种领域。然而，这些技术也存在一些问题和风险，如数据隐私和安全问题。<details>
<summary>Abstract</summary>
Kuhn's framework of scientific progress (Kuhn, 1962) provides a useful framing of the paradigm shifts that have occurred in Artificial Intelligence over the last 60 years. The framework is also useful in understanding what is arguably a new paradigm shift in AI, signaled by the emergence of large pre-trained systems such as GPT-3, on which conversational agents such as ChatGPT are based. Such systems make intelligence a commoditized general purpose technology that is configurable to applications. In this paper, I summarize the forces that led to the rise and fall of each paradigm, and discuss the pressing issues and risks associated with the current paradigm shift in AI.
</details>
<details>
<summary>摘要</summary>
库恩的科学进步框架（库恩，1962）提供了有用的框架，以呈现过去60年来人工智能领域内的 paradigm shift。这个框架也有助于理解目前AI领域可能出现的新的 paradigm shift，即大型预训系统如GPT-3的出现，以及基于这些系统的对话代理人如ChatGPT。这些系统使智能成为可 configurable 通用技术，可以应用于各种应用程序。在这篇文章中，我会概述过去各个 paradigm 的起源和衰落，并讨论目前AI领域中的紧迫问题和风险。
</details></li>
</ul>
<hr>
<h2 id="OpenFlamingo-An-Open-Source-Framework-for-Training-Large-Autoregressive-Vision-Language-Models"><a href="#OpenFlamingo-An-Open-Source-Framework-for-Training-Large-Autoregressive-Vision-Language-Models" class="headerlink" title="OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"></a>OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01390">http://arxiv.org/abs/2308.01390</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlfoundations/open_flamingo">https://github.com/mlfoundations/open_flamingo</a></li>
<li>paper_authors: Anas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe, Yonatan Bitton, Samir Gadre, Shiori Sagawa, Jenia Jitsev, Simon Kornblith, Pang Wei Koh, Gabriel Ilharco, Mitchell Wortsman, Ludwig Schmidt</li>
<li>for: 这个论文是为了提出一种基于自适应语言模型的视觉语言模型家族，包括3B至9B参数的多种模型。</li>
<li>methods: 这些模型使用了开源复制深度智能的Flamenco模型，并在七个视觉语言数据集上进行了训练。</li>
<li>results: 在七个视觉语言数据集上，OpenFlamingo模型的平均表现为80-89%相对于对应的Flamenco模型表现。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
We introduce OpenFlamingo, a family of autoregressive vision-language models ranging from 3B to 9B parameters. OpenFlamingo is an ongoing effort to produce an open-source replication of DeepMind's Flamingo models. On seven vision-language datasets, OpenFlamingo models average between 80 - 89% of corresponding Flamingo performance. This technical report describes our models, training data, hyperparameters, and evaluation suite. We share our models and code at https://github.com/mlfoundations/open_flamingo.
</details>
<details>
<summary>摘要</summary>
我们介绍OpenFlamingo，一个家族型态自动递增视言模型，从3B到9B参数。OpenFlamingo是一个持续进行的开源实现深渊智能的Flamingo模型的努力。在七个视言数据集上，OpenFlamingo模型的平均性能在80-89%之间，与对应的Flamingo模型的性能相似。This technical report describes our models, training data, hyperparameters, and evaluation suite. We share our models and code at <https://github.com/mlfoundations/open_flamingo>.
</details></li>
</ul>
<hr>
<h2 id="DeepSpeed-Chat-Easy-Fast-and-Affordable-RLHF-Training-of-ChatGPT-like-Models-at-All-Scales"><a href="#DeepSpeed-Chat-Easy-Fast-and-Affordable-RLHF-Training-of-ChatGPT-like-Models-at-All-Scales" class="headerlink" title="DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales"></a>DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01320">http://arxiv.org/abs/2308.01320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/DeepSpeed">https://github.com/microsoft/DeepSpeed</a></li>
<li>paper_authors: Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajbhandari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang, Conglong Li, Connor Holmes, Zhongzhu Zhou, Michael Wyatt, Molly Smith, Lev Kurilenko, Heyang Qin, Masahiro Tanaka, Shuai Che, Shuaiwen Leon Song, Yuxiong He</li>
<li>for: 这篇论文旨在提供一个可 accessed、高效、便宜的练习和测试 ChatGPT-like 模型的 Reinforcement Learning with Human Feedback (RLHF) 训练管线，并且可以让训练大小达到百亿个条件的模型在 record 时间内训练，并且在成本上降低训练成本。</li>
<li>methods: 这篇论文提出了一个名为 DeepSpeed-Chat 的系统，它提供了三个关键能力：一个易于使用的 ChatGPT-like 模型训练和测试体验、一个 DeepSpeed-RLHF 管线，复制 InstructGPT 的训练管线，以及一个强大的 DeepSpeed-RLHF 系统，结合了多种优化，以提高训练和测试的效率和数据处理能力。</li>
<li>results: 这篇论文发现，使用 DeepSpeed-Chat 可以实现在训练大小达到百亿个条件的模型上，在 record 时间内训练，并且在成本上降低训练成本。<details>
<summary>Abstract</summary>
ChatGPT-like models have revolutionized various applications in artificial intelligence, from summarization and coding to translation, matching or even surpassing human performance. However, the current landscape lacks an accessible, efficient, and cost-effective end-to-end RLHF (Reinforcement Learning with Human Feedback) training pipeline for these powerful models, particularly when training at the scale of billions of parameters. This paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF training, making it accessible to the AI community. DeepSpeed-Chat offers three key capabilities: an easy-to-use training and inference experience for ChatGPT-like models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and a robust DeepSpeed-RLHF system that combines various optimizations for training and inference in a unified way. The system delivers unparalleled efficiency and scalability, enabling training of models with hundreds of billions of parameters in record time and at a fraction of the cost. With this development, DeepSpeed-Chat paves the way for broader access to advanced RLHF training, even for data scientists with limited resources, thereby fostering innovation and further development in the field of AI.
</details>
<details>
<summary>摘要</summary>
chatGPT-like模型已经革命化了人工智能多个应用领域，从概要和编程到翻译，与人类表现相当或甚至超越人类表现。然而，目前的景象缺乏一个可 accessible、高效、Cost-effective的RLHF（强化学习with人类反馈）训练管道，特别是在百亿参数训练的场景下。这篇论文介绍了DeepSpeed-Chat，一个新的系统，使得RLHF训练变得更加可 accessible。DeepSpeed-Chat提供了三个关键能力：对ChatGPT-like模型的易于使用训练和推理经验，InstructGPT的DeepSpeed-RLHF管道的复制，以及一个robust的DeepSpeed-RLHF系统，其结合了多种优化，以实现高效和可扩展的训练和推理。该系统可以在纪录时间内训练百亿参数的模型，并且只需一小部分的成本。通过这个发展，DeepSpeed-Chat打开了RLHF训练的大门，使得更多的数据科学家可以访问高级RLHF训练，从而推动人工智能领域的创新和发展。
</details></li>
</ul>
<hr>
<h2 id="CausalOps-–-Towards-an-Industrial-Lifecycle-for-Causal-Probabilistic-Graphical-Models"><a href="#CausalOps-–-Towards-an-Industrial-Lifecycle-for-Causal-Probabilistic-Graphical-Models" class="headerlink" title="CausalOps – Towards an Industrial Lifecycle for Causal Probabilistic Graphical Models"></a>CausalOps – Towards an Industrial Lifecycle for Causal Probabilistic Graphical Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01375">http://arxiv.org/abs/2308.01375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert Maier, Andreas Schlattl, Thomas Guess, Jürgen Mottok</li>
<li>for:  This paper aims to provide a novel lifecycle framework for causal model development and application, called CausalOps, to address the gap in a process reference for organizations interested in employing causal engineering.</li>
<li>methods: The paper proposes CausalOps, a lifecycle framework that defines key entities, dependencies, and intermediate artifacts generated during causal engineering, establishing a consistent vocabulary and workflow model.</li>
<li>results: The paper aims to drive the adoption of causal methods in practical applications within interested organizations and the causality community by providing a holistic view of creating and maintaining causal models.Here is the same information in Simplified Chinese text:</li>
<li>for: 本研究目的是提供一个新的 causal 模型开发和应用的生命周期框架，名为 CausalOps，以应对在 causal 工程中缺乏一个适当的程序参考。</li>
<li>methods: CausalOps 提出了一个生命周期框架，它定义了 causal 模型开发和应用中的关键实体、依赖关系和中间生成的资料，实现了一致的词汇和工作流程模型。</li>
<li>results: 本研究的目的是将 causal 方法实施到实际应用中的有兴趣组织和 causality 社区中，提供一个全面的创建和维护 causal 模型的观点。<details>
<summary>Abstract</summary>
Causal probabilistic graph-based models have gained widespread utility, enabling the modeling of cause-and-effect relationships across diverse domains. With their rising adoption in new areas, such as automotive system safety and machine learning, the need for an integrated lifecycle framework akin to DevOps and MLOps has emerged. Currently, a process reference for organizations interested in employing causal engineering is missing. To address this gap and foster widespread industrial adoption, we propose CausalOps, a novel lifecycle framework for causal model development and application. By defining key entities, dependencies, and intermediate artifacts generated during causal engineering, we establish a consistent vocabulary and workflow model. This work contextualizes causal model usage across different stages and stakeholders, outlining a holistic view of creating and maintaining them. CausalOps' aim is to drive the adoption of causal methods in practical applications within interested organizations and the causality community.
</details>
<details>
<summary>摘要</summary>
causal probabilistic graph-based models 已经广泛应用于不同领域，以模型 causality 关系。随着这些模型在新领域，如自动驾驶系统安全和机器学习中的应用，需要一个整合的生命周期框架，类似于 DevOps 和 MLOps。目前，有一个关于 causal engineering 的过程参考 absent。为了填补这个空白和推广 causal methods 的实际应用，我们提出了 CausalOps，一种新的生命周期框架 для causal 模型开发和应用。通过定义关键实体、依赖关系和 intermediate artifacts 在 causal engineering 中，我们建立了一种一致的词汇和工作流程模型。这种工作流程可以跨不同阶段和各种参与者，提供一个整体的创建和维护 causal 模型的视图。CausalOps 的目标是推广 causal methods 在有兴趣的组织和 causality 社区中的应用。
</details></li>
</ul>
<hr>
<h2 id="AI-Enhanced-Data-Processing-and-Discovery-Crowd-Sourcing-for-Meteor-Shower-Mapping"><a href="#AI-Enhanced-Data-Processing-and-Discovery-Crowd-Sourcing-for-Meteor-Shower-Mapping" class="headerlink" title="AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping"></a>AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02664">http://arxiv.org/abs/2308.02664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddha Ganju, Amartya Hatua, Peter Jenniskens, Sahyadri Krishna, Chicheng Ren, Surya Ambardar</li>
<li>for: 这个研究项目的目标是为了映射我们的陨星雨，通过多个位置的低照度视频摄像头进行三角测量陨星轨迹，并在16个国家的北和南 полу球上进行观察和预测陨星雨的返回。</li>
<li>methods: 这个研究使用了一个自动化的云端AI智能管道来加速数据处理，并使用可解释的活动学习算法来提高数据可视化，以提高发现率。</li>
<li>results: 到目前为止，CAMS已经发现了200多个新的陨星雨，并验证了多个之前报告的陨星雨。<details>
<summary>Abstract</summary>
The Cameras for Allsky Meteor Surveillance (CAMS) project, funded by NASA starting in 2010, aims to map our meteor showers by triangulating meteor trajectories detected in low-light video cameras from multiple locations across 16 countries in both the northern and southern hemispheres. Its mission is to validate, discover, and predict the upcoming returns of meteor showers. Our research aimed to streamline the data processing by implementing an automated cloud-based AI-enabled pipeline and improve the data visualization to improve the rate of discoveries by involving the public in monitoring the meteor detections. This article describes the process of automating the data ingestion, processing, and insight generation using an interpretable Active Learning and AI pipeline. This work also describes the development of an interactive web portal (the NASA Meteor Shower portal) to facilitate the visualization of meteor radiant maps. To date, CAMS has discovered over 200 new meteor showers and has validated dozens of previously reported showers.
</details>
<details>
<summary>摘要</summary>
美国国家航空航天局（NASA）自2010年起投入的全天 meteor 观测计划（CAMS）计划，目标是通过多个地点、多国的低照度视频相机三角测量 meteor 轨迹，以易地卷积累积掌握 meteor 流星雨。该计划的任务是验证、发现和预测未来的 meteor 流星雨。我们的研究旨在通过实施云端AI智能化管道自动化数据处理，提高数据可视化，以提高发现率，并让公众参与监测流星探测。这篇文章描述了自动化数据入口、处理和探索的 Active Learning AI 管道，以及开发了一个可交互的 NASA 流星雨门户，以便visualize meteor 辐射地图。迄今，CAMS 已经发现了200多个新的 meteor 流星雨，并验证了数十个之前已知的流星雨。
</details></li>
</ul>
<hr>
<h2 id="An-enhanced-motion-planning-approach-by-integrating-driving-heterogeneity-and-long-term-trajectory-prediction-for-automated-driving-systems"><a href="#An-enhanced-motion-planning-approach-by-integrating-driving-heterogeneity-and-long-term-trajectory-prediction-for-automated-driving-systems" class="headerlink" title="An enhanced motion planning approach by integrating driving heterogeneity and long-term trajectory prediction for automated driving systems"></a>An enhanced motion planning approach by integrating driving heterogeneity and long-term trajectory prediction for automated driving systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01369">http://arxiv.org/abs/2308.01369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ni Dong, Shuming Chen, Yina Wu, Yiheng Feng, Xiaobo Liu</li>
<li>for: 本研究旨在提高自动驾驶系统在复杂驾驶环境中的导航能力，特别是预测周围的人驾驶汽车（HDV）的驾驶行为。</li>
<li>methods: 本研究提出了一种增强的动态规划方法，使用了两个方面的结果：周围 HDV 的驾驶行为和长期轨迹，通过层次模型与自动驾驶系统的动态规划相结合，以提高驾驶安全性。</li>
<li>results: 研究发现，使用提出的增强方法可以更好地预测周围 HDV 的驾驶行为，提高自动驾驶系统的导航能力和安全性。<details>
<summary>Abstract</summary>
Navigating automated driving systems (ADSs) through complex driving environments is difficult. Predicting the driving behavior of surrounding human-driven vehicles (HDVs) is a critical component of an ADS. This paper proposes an enhanced motion-planning approach for an ADS in a highway-merging scenario. The proposed enhanced approach utilizes the results of two aspects: the driving behavior and long-term trajectory of surrounding HDVs, which are coupled using a hierarchical model that is used for the motion planning of an ADS to improve driving safety.
</details>
<details>
<summary>摘要</summary>
自动驾驶系统（ADS）在复杂的驾驶环境中困难 Navigation. 预测周围的人驾驶车辆（HDV）驾驶行为是ADS的一个关键组件。这篇论文提出了一种改进的运动规划方法，用于ADS在高速公路岔道场景中驾驶。该提出的改进方法利用了两个方面的结果：周围HDV的驾驶行为和长期轨迹，通过层次模型与ADS的运动规划相结合，以提高驾驶安全性。
</details></li>
</ul>
<hr>
<h2 id="Empirical-Translation-Process-Research-Past-and-Possible-Future-Perspectives"><a href="#Empirical-Translation-Process-Research-Past-and-Possible-Future-Perspectives" class="headerlink" title="Empirical Translation Process Research: Past and Possible Future Perspectives"></a>Empirical Translation Process Research: Past and Possible Future Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01368">http://arxiv.org/abs/2308.01368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Carl</li>
<li>for: 本研究旨在开发和评估Empirical Translation Process Research（TPR）模型，并提出了Free Energy Principle（FEP）和Active Inference（AIF）作为深入嵌入翻译过程的模型框架。</li>
<li>methods: 本研究使用了CRITT TPR-DB传统，并引入了新的方法来量化基本概念，如重要性理论（relevance）、s-模式和i-模式。这些方法与Monitor Model的关系被确立，并将重要性maximization看作是Free Energy的最小化。</li>
<li>results: FEP&#x2F;AIF提供了一个数学上可靠的基础，允许模型深入的时间建筑，在不同的时间轴上嵌入翻译过程。这个框架开放了未来预测TPR的可能性，可能对人类翻译过程的理解做出重要贡献，并对翻译学和人工智能设计框架产生重要影响。<details>
<summary>Abstract</summary>
Over the past four decades, efforts have been made to develop and evaluate models for Empirical Translation Process Research (TPR), yet a comprehensive framework remains elusive. This article traces the evolution of empirical TPR within the CRITT TPR-DB tradition and proposes the Free Energy Principle (FEP) and Active Inference (AIF) as a framework for modeling deeply embedded translation processes. It introduces novel approaches for quantifying fundamental concepts of Relevance Theory (relevance, s-mode, i-mode), and establishes their relation to the Monitor Model, framing relevance maximization as a special case of minimizing free energy. FEP/AIF provides a mathematically rigorous foundation that enables modeling of deep temporal architectures in which embedded translation processes unfold on different timelines. This framework opens up exciting prospects for future research in predictive TPR, likely to enrich our comprehension of human translation processes, and making valuable contributions to the wider realm of translation studies and the design of cognitive architectures.
</details>
<details>
<summary>摘要</summary>
Note:* "Empirical Translation Process Research" (TPR) is translated as "观察式翻译过程研究" (含义为"empirical"的"观察"和"过程"两个词).* "CRITT TPR-DB" is translated as "CRITT TPR-DB" (缩写为"CRITT"和"TPR-DB").* "Free Energy Principle" (FEP) is translated as "自由能原理" (含义为"free"和"energy"两个词).* "Active Inference" (AIF) is translated as "活动推测" (含义为"active"和"inference"两个词).* "Relevance Theory" is translated as "相关理论" (含义为"relevance"和"theory"两个词).* "Monitor Model" is translated as "监控模型" (含义为"monitor"和"model"两个词).
</details></li>
</ul>
<hr>
<h2 id="More-Context-Less-Distraction-Visual-Classification-by-Inferring-and-Conditioning-on-Contextual-Attributes"><a href="#More-Context-Less-Distraction-Visual-Classification-by-Inferring-and-Conditioning-on-Contextual-Attributes" class="headerlink" title="More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes"></a>More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01313">http://arxiv.org/abs/2308.01313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/umd-huang-lab/perceptionclip">https://github.com/umd-huang-lab/perceptionclip</a></li>
<li>paper_authors: Bang An, Sicheng Zhu, Michael-Andrei Panaitescu-Liess, Chaithanya Kumar Mummadi, Furong Huang</li>
<li>for:  Zero-shot image classification</li>
<li>methods: 使用CLIP的contextual attributes进行图像分类，不需要训练</li>
<li>results:  better generalization, group robustness, and better interpretability compared to traditional zero-shot classification methods<details>
<summary>Abstract</summary>
CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question. This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information. Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP. Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them. Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability. For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.
</details>
<details>
<summary>摘要</summary>
CLIP，作为基础视觉语言模型，在零基础图像分类中广泛应用，这是因为它可以理解多种视觉概念和自然语言描述。然而，如何充分利用CLIP的人类化理解能力以实现更好的零基础分类仍然是一个开放的问题。这篇论文启发自人类视觉过程：现代神经科学视野认为，在分类一个物体，人们首先推理出该物体的类型独立特征（例如背景和方向），这些特征会将背景和物体分离开来，然后根据这些信息进行决策。以这种思想为灵感，我们发现，为CLIP提供Contextual attributes可以提高零基础分类和减少基于假特征的依赖。此外，我们发现CLIP本身也可以有效地从图像中推理出这些特征。基于这些观察，我们提出了一种无需训练的、两步零基础分类方法名为PerceptionCLIP。给定一个图像，它首先推理出图像中的Contextual attributes（例如背景），然后根据这些特征进行物体分类。我们的实验表明，PerceptionCLIP在水鸟数据集上提高了最差群组精度 by 16.5%，并在CelebA数据集上提高了3.5%。
</details></li>
</ul>
<hr>
<h2 id="Lode-Encoder-AI-constrained-co-creativity"><a href="#Lode-Encoder-AI-constrained-co-creativity" class="headerlink" title="Lode Encoder: AI-constrained co-creativity"></a>Lode Encoder: AI-constrained co-creativity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01312">http://arxiv.org/abs/2308.01312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debosmita Bhaumik, Ahmed Khalifa, Julian Togelius</li>
<li>for: 这篇论文是为了描述一种基于自动编码器的混合性倡议级别创建系统，用于 classic 平台游戏垃圾 runner。</li>
<li>methods: 该系统使用多个自动编码器，通过对垃圾 runner 等级进行训练，来生成更符合这些等级的级别设计。用户可以通过 ‘画画’ 方式在系统提供的建议基础上进行级别设计和编辑。</li>
<li>results: 文章描述了系统的设计和训练方法，以及用户测试结果。<details>
<summary>Abstract</summary>
We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner. The system is built around several autoencoders which are trained on sets of Lode Runner levels. When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on. The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders. Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools. We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.
</details>
<details>
<summary>摘要</summary>
我们介绍Lode Encoder，一种基于混合主动initiative的平台游戏逻辑编辑系统，专门为经典平台游戏Lode Runner设计。该系统建立在多个自适应器基础之上，这些自适应器在不同的Lode Runner水平上进行训练。当用户输入设计时，每个自适应器都会生成一个更加类似于它所训练的水平的版本。Lode Encoder界面允许用户通过"涂抹"的方式从自适应器提供的建议中建立和编辑水平。关键是，为了鼓励设计师探索新的可能性，该系统不包含传统的编辑工具。我们介绍了系统的设计和训练过程，以及用户测试。
</details></li>
</ul>
<hr>
<h2 id="EmbeddingTree-Hierarchical-Exploration-of-Entity-Features-in-Embedding"><a href="#EmbeddingTree-Hierarchical-Exploration-of-Entity-Features-in-Embedding" class="headerlink" title="EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding"></a>EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01329">http://arxiv.org/abs/2308.01329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Zheng, Junpeng Wang, Chin-Chia Michael Yeh, Yujie Fan, Huiyuan Chen, Liang Wang, Wei Zhang</li>
<li>for: 本研究旨在提高 embedding learning 算法中feature的解释性，通过一种嵌入树来描述实体特征在嵌入空间中的含义。</li>
<li>methods: 本研究使用了一种嵌入树算法，可以帮助用户更好地理解嵌入空间中的feature表示。</li>
<li>results: 在实验中，嵌入树算法可以帮助用户发现数据实体中的细节特征，进行嵌入训练中的特征纹理提取和新实体嵌入生成等操作。<details>
<summary>Abstract</summary>
Embedding learning transforms discrete data entities into continuous numerical representations, encoding features/properties of the entities. Despite the outstanding performance reported from different embedding learning algorithms, few efforts were devoted to structurally interpreting how features are encoded in the learned embedding space. This work proposes EmbeddingTree, a hierarchical embedding exploration algorithm that relates the semantics of entity features with the less-interpretable embedding vectors. An interactive visualization tool is also developed based on EmbeddingTree to explore high-dimensional embeddings. The tool helps users discover nuance features of data entities, perform feature denoising/injecting in embedding training, and generate embeddings for unseen entities. We demonstrate the efficacy of EmbeddingTree and our visualization tool through embeddings generated for industry-scale merchant data and the public 30Music listening/playlists dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本翻译为简化字符串。<</SYS>>嵌入学习将粒度数据实体转换为连续数字表示，卷积特征/属性实体。尽管不同嵌入学习算法报道了出色的性能，但是对嵌入学习结果中特征的结构解释得到了少量的努力。这项工作提出了嵌入树，一种嵌入探索算法，该算法将数据实体的 semantics 与嵌入 vectors 之间建立连接。此外，我们还开发了基于嵌入树的互动视觉化工具，帮助用户探索高维嵌入的细节。工具可以帮助用户发现数据实体的细节特征，进行嵌入训练中的特征去噪/注入，以及生成未见实体的嵌入。我们通过使用嵌入树和互动视觉化工具对行业级别的商家数据和公共30Music listening/playlists数据进行了证明。
</details></li>
</ul>
<hr>
<h2 id="Flows-Building-Blocks-of-Reasoning-and-Collaborating-AI"><a href="#Flows-Building-Blocks-of-Reasoning-and-Collaborating-AI" class="headerlink" title="Flows: Building Blocks of Reasoning and Collaborating AI"></a>Flows: Building Blocks of Reasoning and Collaborating AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01285">http://arxiv.org/abs/2308.01285</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/epfl-dlab/cc_flows">https://github.com/epfl-dlab/cc_flows</a></li>
<li>paper_authors: Martin Josifoski, Lars Klein, Maxime Peyrard, Yifei Li, Saibo Geng, Julian Paul Schnitzler, Yuxing Yao, Jiheng Wei, Debjit Paul, Robert West</li>
<li>for: 这 paper 旨在开发一种原则性的方法，用于设计和研究多个 AI 系统和人类之间的结构化交互。</li>
<li>methods: 该 paper 使用 Flows 概念框架，即自 conten 的 computation 块，通过标准化的消息传递接口进行交互。这种模块化设计使得 Flows 可以 recursive 地组合，减少复杂性。</li>
<li>results: 该 paper 在竞赛编程任务上实现了结构化思维和合作的进一步改进，使得 AI 只 Flows 增加了 +$21$ 和人类-AI Flows 增加了 +$54$ 绝对点的解决率。<details>
<summary>Abstract</summary>
Recent advances in artificial intelligence (AI) have produced highly capable and controllable systems. This creates unprecedented opportunities for structured reasoning as well as collaboration among multiple AI systems and humans. To fully realize this potential, it is essential to develop a principled way of designing and studying such structured interactions. For this purpose, we introduce the conceptual framework of Flows: a systematic approach to modeling complex interactions. Flows are self-contained building blocks of computation, with an isolated state, communicating through a standardized message-based interface. This modular design allows Flows to be recursively composed into arbitrarily nested interactions, with a substantial reduction of complexity. Crucially, any interaction can be implemented using this framework, including prior work on AI--AI and human--AI interactions, prompt engineering schemes, and tool augmentation. We demonstrate the potential of Flows on the task of competitive coding, a challenging task on which even GPT-4 struggles. Our results suggest that structured reasoning and collaboration substantially improve generalization, with AI-only Flows adding +$21$ and human--AI Flows adding +$54$ absolute points in terms of solve rate. To support rapid and rigorous research, we introduce the aiFlows library. The library comes with a repository of Flows that can be easily used, extended, and composed into novel, more complex Flows.   The aiFlows library is available at https://github.com/epfl-dlab/aiflows. Data and Flows for reproducing our experiments are available at https://github.com/epfl-dlab/cc_flows.
</details>
<details>
<summary>摘要</summary>
最近的人工智能（AI）技术发展已经创造出了高水平的可控制系统。这创造了前所未有的机会，让多个AI系统和人类之间进行结构化的合作和推理。为了实现这些潜力，我们提出了Flows概念框架：一种系统的方法来设计和研究这些结构化交互。Flows是自包含的建筑块，具有隔离的状态和标准化的消息传递接口。这种模块化设计使得Flows可以被 recursively 组合成任意层次的交互，从而减少复杂性。这些交互可以包括先前的AI-AI和人类-AI交互、提前工程方案和工具增强等。我们在竞赛编程任务上示出了Flows的潜力，这是一个AIeven GPT-4 很难完成的任务。我们的结果表明，结构化合作和推理可以提高通用性，AI只Flows adds +$21$ 和人类-AI Flows adds +$54$ 绝对点的解决率。为了支持快速和严格的研究，我们引入了aiFlows库。该库包含了可以轻松使用、扩展和组合成更复杂的Flows的Repository。aiFlows库可以在https://github.com/epfl-dlab/aiflows上获取。实验数据和Flows可以在https://github.com/epfl-dlab/cc_flows上获取。
</details></li>
</ul>
<hr>
<h2 id="Fighting-Fire-with-Fire-Can-ChatGPT-Detect-AI-generated-Text"><a href="#Fighting-Fire-with-Fire-Can-ChatGPT-Detect-AI-generated-Text" class="headerlink" title="Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?"></a>Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01284">http://arxiv.org/abs/2308.01284</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amritabh/chatgpt-as-detector">https://github.com/amritabh/chatgpt-as-detector</a></li>
<li>paper_authors: Amrita Bhattacharjee, Huan Liu</li>
<li>for: 这种研究用于检测人工生成的文本是否真实，以便在自动检测pipeline中使用ChatGPT和类似的大语言模型。</li>
<li>methods: 本研究使用ChatGPT作为检测器，通过 Zero-shot learning 方法进行人工生成文本和人类写作文本的检测。</li>
<li>results: 研究发现，ChatGPT在人工生成文本和人类写作文本之间的检测性能具有相似性，但是在某些情况下可能会受到干扰。这些结果提供了关于如何使用ChatGPT和类似的大语言模型在自动检测pipeline中的信息。<details>
<summary>Abstract</summary>
Large language models (LLMs) such as ChatGPT are increasingly being used for various use cases, including text content generation at scale. Although detection methods for such AI-generated text exist already, we investigate ChatGPT's performance as a detector on such AI-generated text, inspired by works that use ChatGPT as a data labeler or annotator. We evaluate the zero-shot performance of ChatGPT in the task of human-written vs. AI-generated text detection, and perform experiments on publicly available datasets. We empirically investigate if ChatGPT is symmetrically effective in detecting AI-generated or human-written text. Our findings provide insight on how ChatGPT and similar LLMs may be leveraged in automated detection pipelines by simply focusing on solving a specific aspect of the problem and deriving the rest from that solution. All code and data is available at https://github.com/AmritaBh/ChatGPT-as-Detector.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如ChatGPT在不同的应用场景中日益受到应用，包括大规模文本内容生成。虽然现有的AI生成文本检测方法已经存在，但我们在ChatGPT作为数据标注器或标注者的灵感下进行研究，检测AI生成文本的性能。我们对公共可用数据集进行了零shot性能评估，并对人工生成和AI生成文本之间的对比进行了实验。我们发现ChatGPT在检测人工生成和AI生成文本的任务中具有相似的效果。我们的发现可能有助于在自动检测管道中使用ChatGPT和类似的LLM，只需关注解决特定问题的方法，然后从其中 derivation 其他方面的解决方案。所有代码和数据可以在 GitHub 上找到：https://github.com/AmritaBh/ChatGPT-as-Detector。
</details></li>
</ul>
<hr>
<h2 id="BRNES-Enabling-Security-and-Privacy-aware-Experience-Sharing-in-Multiagent-Robotic-and-Autonomous-Systems"><a href="#BRNES-Enabling-Security-and-Privacy-aware-Experience-Sharing-in-Multiagent-Robotic-and-Autonomous-Systems" class="headerlink" title="BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems"></a>BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01274">http://arxiv.org/abs/2308.01274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aralab-unr/brnes">https://github.com/aralab-unr/brnes</a></li>
<li>paper_authors: Md Tamjid Hossain, Hung Manh La, Shahriar Badsha, Anton Netchaev</li>
<li>For: The paper is written to address the issues of adversarial manipulation and inference in multi-agent reinforcement learning (MARL) with experience sharing (ES).* Methods: The proposed framework, called BRNES, uses a dynamic neighbor zone selection and weighted experience aggregation to reduce the impact of Byzantine attacks. It also employs local differential privacy (LDP) to protect the agents’ private information from adversarial inference attacks.* Results: The proposed framework outperforms the state-of-the-art in terms of steps to goal, obtained reward, and time to goal metrics. Specifically, it is 8.32x faster than non-private frameworks and 1.41x faster than private frameworks in an adversarial setting.<details>
<summary>Abstract</summary>
Although experience sharing (ES) accelerates multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have so far relied on trusted environments and overlooked the possibility of adversarial manipulation and inference. Nevertheless, in a real-world setting, some Byzantine attackers, disguised as advisors, may provide false advice to the advisee and catastrophically degrade the overall learning performance. Also, an inference attacker, disguised as an advisee, may conduct several queries to infer the advisors' private information and make the entire ES process questionable in terms of privacy leakage. To address and tackle these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact. Furthermore, to keep the agent's private information safe from adversarial inference attacks, we leverage the local differential privacy (LDP)-induced noise during the ES process. Our experiments show that our framework outperforms the state-of-the-art in terms of the steps to goal, obtained reward, and time to goal metrics. Particularly, our evaluation shows that the proposed framework is 8.32x faster than the current non-private frameworks and 1.41x faster than the private frameworks in an adversarial setting.
</details>
<details>
<summary>摘要</summary>
虽然经验分享（ES）可以加速多代理激励学习（MARL）在顾问-受顾问框架下，但是在分散式多代理系统中应用ES的尝试都是在可信环境中进行，而忽视了对敌意攻击和推理的可能性。然而，在实际场景中，一些贪婪攻击者，化名为顾问，可能为受顾问提供错误的建议，从而导致总的学习性能受到极大的降低。此外，一个推理攻击者，化名为受顾问，可能通过多个查询来推理出顾问的私人信息，使整个ES过程存在隐私泄露问题。为解决这些问题，我们提议一种基于BRNES的新的MARL框架，强制选择每个受顾问的动态邻区，并采用权重经验聚合技术来减少攻击影响。此外，通过在ES过程中应用本地幂等隐私（LDP）引起的噪声，保护代理的私人信息免遭敌意推理攻击。我们的实验表明，我们的框架比现有的非私钥框架快8.32倍，比私钥框架快1.41倍在敌意 Setting中。
</details></li>
</ul>
<hr>
<h2 id="A-Probabilistic-Approach-to-Self-Supervised-Learning-using-Cyclical-Stochastic-Gradient-MCMC"><a href="#A-Probabilistic-Approach-to-Self-Supervised-Learning-using-Cyclical-Stochastic-Gradient-MCMC" class="headerlink" title="A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC"></a>A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01271">http://arxiv.org/abs/2308.01271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masoumeh Javanbakhat, Christoph Lippert</li>
<li>for: 本研究提出了一种实用的 bayesian自适应学习方法，使用循环随机梯度哈密顿-蒙特卡洛（cSGHMC）来 aproximate高维度和多模态的 posterior 分布。</li>
<li>methods: 本方法使用 prior 来置信自适应学习模型的参数，并使用 cSGHMC 来 aproximate高维度和多模态的 posterior 分布。</li>
<li>results: 通过寻找表示的expressive posterior，悉数自适应学习得到了可读性和多样性的表示。在多种下游分类任务上，取得了显著的性能提升、校准和对于类型检测。<details>
<summary>Abstract</summary>
In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种实用的极 bayesian自适应学习方法，即循环随机Gradient Hamiltonian Monte Carlo（cSGHMC）。在这种框架下，我们对自适应学习模型参数进行了先验，并使用cSGHMC来近似高维多模态 posterior distribution over the embeddings。通过探索高维多模态的 posterior over the embeddings，bayesian自适应学习可以生成可读性和多样性的表示。对这些表示进行摘要，可以获得显著的性能、调整和出现在其他分类任务上的表现。我们在多个分类任务上进行了多个数据集的实验，并在SVHN和CIFAR-10数据集上进行了out-of-distribution检测。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-psychology-of-GPT-4’s-Moral-and-Legal-Reasoning"><a href="#Exploring-the-psychology-of-GPT-4’s-Moral-and-Legal-Reasoning" class="headerlink" title="Exploring the psychology of GPT-4’s Moral and Legal Reasoning"></a>Exploring the psychology of GPT-4’s Moral and Legal Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01264">http://arxiv.org/abs/2308.01264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guilherme F. C. F. Almeida, José Luiz Nunes, Neele Engelmann, Alex Wiegmann, Marcelo de Araújo</li>
<li>for: 这个论文旨在研究大语言模型GPT-4的道德和法律决策方面的 simulated human reasoning。</li>
<li>methods: 作者使用心理学方法 probing GPT-4的道德和法律决策过程。</li>
<li>results: 研究发现GPT-4和人类在意图归属、 causality 判断、诱导行为、道德基础、legal luck 的影响以及同意和规则违反判断方面存在高相关性，但也有一些重要的系统性差异。<details>
<summary>Abstract</summary>
Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues. However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have. The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess. In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning. More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments. We find high correlations between human and AI responses, but also several significant systematic differences between them. We conclude with a discussion of the philosophical implications of our findings.
</details>
<details>
<summary>摘要</summary>
大型语言模型已被用为高级人工智能的基础，能够提供人类样式的回应于法律和道德问题。然而，这些模型对自己内部的工作方式是不可靠的导航， même 创建团队无法完全解释它们如何获得所有现有的能力。新兴领域的机器心理学欲了解这些模型内部的过程和概念。在这篇论文中，我们使用心理学方法探究GPT-4的道德和法律理解。更 specifically，我们研究人类和AI在意图归属、 causation 判断、误导的道德性、道德基础、legal 判断的道德遗产、同意和规则违反判断方面的相似性和差异。我们发现人类和 AI 回应之间存在高相关性，但也存在一些重要的系统性差异。我们结束于哲学意义的讨论。
</details></li>
</ul>
<hr>
<h2 id="XSTest-A-Test-Suite-for-Identifying-Exaggerated-Safety-Behaviours-in-Large-Language-Models"><a href="#XSTest-A-Test-Suite-for-Identifying-Exaggerated-Safety-Behaviours-in-Large-Language-Models" class="headerlink" title="XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models"></a>XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01263">http://arxiv.org/abs/2308.01263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Röttger, Hannah Rose Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, Dirk Hovy</li>
<li>For: The paper is written to address the issue of large language models following malicious instructions and generating toxic content, and to propose a new test suite called XSTest to identify eXaggerated Safety behaviors in a structured and systematic way.* Methods: The paper uses a new test suite called XSTest, which comprises 200 safe prompts across ten prompt types, to evaluate the safety behaviors of a recently-released state-of-the-art language model.* Results: The paper highlights systematic failure modes in the language model, demonstrating that it is not well-calibrated and tends to refuse complying with safe prompts that use similar language to unsafe prompts or mention sensitive topics.<details>
<summary>Abstract</summary>
Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content, which motivates safety efforts such as red-teaming and large-scale feedback learning to make models both helpful and harmless. However, there is a tension between these two objectives, as harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviors in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model.Translated into Traditional Chinese: Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content, which motivates safety efforts such as red-teaming and large-scale feedback learning to make models both helpful and harmless. However, there is a tension between these two objectives, as harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviors in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/cs.AI_2023_08_03/" data-id="clogy1z0l001lffrabs6laora" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/cs.CL_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T11:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/cs.CL_2023_08_03/">cs.CL - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Many-to-Many-Spoken-Language-Translation-via-Unified-Speech-and-Text-Representation-Learning-with-Unit-to-Unit-Translation"><a href="#Many-to-Many-Spoken-Language-Translation-via-Unified-Speech-and-Text-Representation-Learning-with-Unit-to-Unit-Translation" class="headerlink" title="Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation"></a>Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01831">http://arxiv.org/abs/2308.01831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsu Kim, Jeongsoo Choi, Dahun Kim, Yong Man Ro</li>
<li>for: 这个论文的目的是学习一种能够同时处理多种语言的语音和文本表示，以便实现多语言语音合成等多种任务。</li>
<li>methods: 该论文提出了一种基于单个模型的方法，利用自适应语音模型对语音特征编码生成 speech units，然后通过对这些 speech units 进行pseudo文本处理，建立了语音和文本之间的统一表示。最后， authors 提出了一种基于encoder-decoder结构的 Unit-to-Unit Translation (UTUT) 目标函数，用于在多语言数据上进行多对多翻译。</li>
<li>results: 通过对多种语言进行实验，authors 证明了该方法在多种多语言语音合成、文本合成和翻译等任务中的效果。此外，authors 还证明了该方法可以实现多对多语言同时翻译，这在文献中尚未被探讨过。示例可以在 <a target="_blank" rel="noopener" href="https://choijeongsoo.github.io/utut">https://choijeongsoo.github.io/utut</a> 上找到。<details>
<summary>Abstract</summary>
In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis. We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model. Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text. Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data. Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting. Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages. A single pre-trained model with UTUT can be employed for diverse multilingual speech- and text-related tasks, such as Speech-to-Speech Translation (STS), multilingual Text-to-Speech Synthesis (TTS), and Text-to-Speech Translation (TTST). By conducting comprehensive experiments encompassing various languages, we validate the efficacy of the proposed method across diverse multilingual tasks. Moreover, we show UTUT can perform many-to-many language STS, which has not been previously explored in the literature. Samples are available on https://choijeongsoo.github.io/utut.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种方法，可以通过单一模型学习多语言 speech 和文本的共同表示，特别是关注语音合成的目的。我们使用自动编码的 speech 特征来编码多语言 speech 音频，并将其转换为 pseudo text。因此，我们可以关注其语言内容，并建立多语言 speech 和文本的共同表示。然后，我们提出了一种encoder-decoder结构的模型，使用 Unit-to-Unit Translation（UTUT）目标在多语言数据上进行训练。具体来说，通过将源语言tokenconditional encode器，并将目标语言tokenconditional decode器，模型将被优化为将说话语言翻译成目标语言，这种多语言翻译设置下进行训练。因此，模型可以学习说话语言如何被理解，以及如何将其与不同语言关联起来。一个预训练的 UTUT 模型可以用于多种多语言 speech-和文本相关任务，如 Speech-to-Speech Translation（STS）、多语言 Text-to-Speech Synthesis（TTS）和 Text-to-Speech Translation（TTST）。通过对多种语言进行全面的实验，我们证明了提出的方法的有效性。此外，我们还证明了 UTUT 可以实现多语言 STS，这是在文献中没有被探讨的。样例可以在 <https://choijeongsoo.github.io/utut> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Scaling-Relationship-on-Learning-Mathematical-Reasoning-with-Large-Language-Models"><a href="#Scaling-Relationship-on-Learning-Mathematical-Reasoning-with-Large-Language-Models" class="headerlink" title="Scaling Relationship on Learning Mathematical Reasoning with Large Language Models"></a>Scaling Relationship on Learning Mathematical Reasoning with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01825">http://arxiv.org/abs/2308.01825</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ofa-sys/gsm8k-screl">https://github.com/ofa-sys/gsm8k-screl</a></li>
<li>paper_authors: Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Chuanqi Tan, Chang Zhou</li>
<li>for: 本研究旨在investigate how pre-training loss, supervised data amount, and augmented data amount influence the mathematical reasoning performances of a supervised large language model (LLM).</li>
<li>methods: 本研究使用了supervised fine-tuning (SFT)和Rejection sampling Fine-Tuning (RFT)两种方法来改进LLM的数学逻辑能力。</li>
<li>results: 研究发现，pre-training loss是LLM表现度的更好的指标，而不是模型的参数数量。通过不同量的supervised数据进行学习练习，我们发现模型的性能与数据量成直线关系，并且更好的模型在更大的数据量下提高的速度更快。此外，我们还发现，通过使用RFT，可以增加更多的数据样本，提高LLM的数学逻辑能力，特别是对于较差的LLM模型。最后，我们将多个模型的拒绝样本合并，使得LLM-7B模型的准确率达到49.3%，高于SFT方法的准确率35.9%，并且显著超过SFT方法。<details>
<summary>Abstract</summary>
Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored. In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM. We find that pre-training loss is a better indicator of the model's performance than the model's parameter count. We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets. To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. We find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs. We also find RFT brings more improvement for less performant LLMs. Furthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3% and outperforms the supervised fine-tuning (SFT) accuracy of 35.9% significantly.
</details>
<details>
<summary>摘要</summary>
matematic reasoning 是一个大型自然语言模型 (LLM) 中的挑战任务，而这些模型的规模下的扩展关系尚未得到充分探索。在这篇论文中，我们 investigate了在supervised fine-tuning (SFT) 中，预训练损失、supervised数据量和增强数据量对模型的推理表现的影响。我们发现预训练损失是模型性能的更好的指标，而不是模型的参数数量。我们运用SFT的不同数量的supervised数据，并发现在数据量增加时，模型性能逐渐提高，但是当数据量增加时，模型的改进度逐渐减少。为了增加更多的数据样本以提高模型性能而不需要人工劳动，我们提出了应用Rejection sampling Fine-Tuning (RFT)。RFT使用supervised模型生成和收集正确的推理路径作为增强数据集。我们发现增强样本中包含更多的不同的推理路径，RFT可以更好地提高LLMs的推理性能。此外，我们发现RFT对较低性能的LLMs更加有优势。此外，我们将多个模型的拒绝样本结合，使得LLLaMA-7B 的准确率提高到 49.3%，并且在SFT的准确率（35.9%）上显著超越。
</details></li>
</ul>
<hr>
<h2 id="Lexicon-and-Rule-based-Word-Lemmatization-Approach-for-the-Somali-Language"><a href="#Lexicon-and-Rule-based-Word-Lemmatization-Approach-for-the-Somali-Language" class="headerlink" title="Lexicon and Rule-based Word Lemmatization Approach for the Somali Language"></a>Lexicon and Rule-based Word Lemmatization Approach for the Somali Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01785">http://arxiv.org/abs/2308.01785</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shafieabdi/somalilemmatizer">https://github.com/shafieabdi/somalilemmatizer</a></li>
<li>paper_authors: Shafie Abdi Mohamed, Muhidin Abdullahi Mohamed</li>
<li>for: 这篇论文是为了开发索马里语文本正常化技术（text lemmatization）而写的。</li>
<li>methods: 这篇论文使用了词语谱和规则来实现索马里语文本正常化。</li>
<li>results: 该算法在120篇文档中测试得到了57%的准确率（对长文章），60.57%的准确率（对新闻文章摘要）和95.87%的高准确率（对社交媒体消息）。<details>
<summary>Abstract</summary>
Lemmatization is a Natural Language Processing (NLP) technique used to normalize text by changing morphological derivations of words to their root forms. It is used as a core pre-processing step in many NLP tasks including text indexing, information retrieval, and machine learning for NLP, among others. This paper pioneers the development of text lemmatization for the Somali language, a low-resource language with very limited or no prior effective adoption of NLP methods and datasets. We especially develop a lexicon and rule-based lemmatizer for Somali text, which is a starting point for a full-fledged Somali lemmatization system for various NLP tasks. With consideration of the language morphological rules, we have developed an initial lexicon of 1247 root words and 7173 derivationally related terms enriched with rules for lemmatizing words not present in the lexicon. We have tested the algorithm on 120 documents of various lengths including news articles, social media posts, and text messages. Our initial results demonstrate that the algorithm achieves an accuracy of 57\% for relatively long documents (e.g. full news articles), 60.57\% for news article extracts, and high accuracy of 95.87\% for short texts such as social media messages.
</details>
<details>
<summary>摘要</summary>
“干扰”是自然语言处理（NLP）技术的一种 normalize 文本的方法，通过将 morphological derivations 变换为其根形式。它是许多 NLP 任务的核心预处理步骤，包括文本索引、信息检索和机器学习 для NLP 等。这篇论文推动了索马里语文本干扰的开发，这是一种有限的资源语言，具有非常有限或者无效的 NLP 方法和数据集。我们特别开发了索马里语文本干扰词典和规则基于的干扰器，这是一个索马里文本干扰系统的开始。我们考虑了语言的 morphological 规则，我们开发了初始词典的 1247 个根词和 7173 个 derivationally 相关的词汇，并添加了词语不在词典中的 lemmatizing 规则。我们对 120 篇文档进行测试，包括新闻文章、社交媒体帖子和短信。我们的初步结果表明，算法在长文档（例如全文新闻文章）中达到了 57% 的准确率，在新闻文章摘要中达到了 60.57%，并在短信中达到了高准确率的 95.87%。
</details></li>
</ul>
<hr>
<h2 id="Does-Correction-Remain-A-Problem-For-Large-Language-Models"><a href="#Does-Correction-Remain-A-Problem-For-Large-Language-Models" class="headerlink" title="Does Correction Remain A Problem For Large Language Models?"></a>Does Correction Remain A Problem For Large Language Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01776">http://arxiv.org/abs/2308.01776</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Noykarde/NoykardeRepository">https://github.com/Noykarde/NoykardeRepository</a></li>
<li>paper_authors: Xiaowu Zhang, Xiaotian Zhang, Cheng Yang, Hang Yan, Xipeng Qiu</li>
<li>for: 这paper investigate了大语言模型中 correction 的问题，并通过两个实验来解决这个问题。</li>
<li>methods: 这paper使用了 few-shot learning 技术和 GPT-like 模型来进行 error correction。</li>
<li>results: 这paper发现 correction 在大语言模型中仍然存在问题，但可以通过 few-shot learning 技术和 GPT-like 模型来解决这个问题。<details>
<summary>Abstract</summary>
As large language models, such as GPT, continue to advance the capabilities of natural language processing (NLP), the question arises: does the problem of correction still persist? This paper investigates the role of correction in the context of large language models by conducting two experiments. The first experiment focuses on correction as a standalone task, employing few-shot learning techniques with GPT-like models for error correction. The second experiment explores the notion of correction as a preparatory task for other NLP tasks, examining whether large language models can tolerate and perform adequately on texts containing certain levels of noise or errors. By addressing these experiments, we aim to shed light on the significance of correction in the era of large language models and its implications for various NLP applications.
</details>
<details>
<summary>摘要</summary>
大型语言模型，如GPT，继续推进自然语言处理（NLP）的能力，问题是：检查还是存在的问题吗？这篇论文通过两个实验来研究大型语言模型中的检查问题。第一个实验专注于检查作为独立任务，使用少量学习技术训练GPT-like模型进行错误检查。第二个实验探讨检查作为其他NLP任务的前置任务，检查大语言模型是否可以忍受和处理含有一定水平的噪音或错误的文本。通过这两个实验，我们想要照明大型语言模型时代检查的重要性和它对各种NLP应用的影响。
</details></li>
</ul>
<hr>
<h2 id="Supply-chain-emission-estimation-using-large-language-models"><a href="#Supply-chain-emission-estimation-using-large-language-models" class="headerlink" title="Supply chain emission estimation using large language models"></a>Supply chain emission estimation using large language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01741">http://arxiv.org/abs/2308.01741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayush Jain, Manikandan Padmanaban, Jagabondhu Hazra, Shantanu Godbole, Kommy Weldemariam</li>
<li>for: 这个论文主要写于企业实现可持续发展目标（SDGs）中，尤其是目标13：抗击气候变化的挑战。</li>
<li>methods: 该论文提出了一种首次使用域适应NLP基础模型来估算企业Scope 3排放（供应链排放），通过利用财务交易作为购买商品和服务的代理。</li>
<li>results: 我们的结果表明，域适应基础模型比状态机器学习技术更高效，并且与专家（SME）性能相似。该 frameworks可能加速企业范围内Scope 3估算，帮助企业采取适当的气候行动，实现SDG 13。<details>
<summary>Abstract</summary>
Large enterprises face a crucial imperative to achieve the Sustainable Development Goals (SDGs), especially goal 13, which focuses on combating climate change and its impacts. To mitigate the effects of climate change, reducing enterprise Scope 3 (supply chain emissions) is vital, as it accounts for more than 90\% of total emission inventories. However, tracking Scope 3 emissions proves challenging, as data must be collected from thousands of upstream and downstream suppliers.To address the above mentioned challenges, we propose a first-of-a-kind framework that uses domain-adapted NLP foundation models to estimate Scope 3 emissions, by utilizing financial transactions as a proxy for purchased goods and services. We compared the performance of the proposed framework with the state-of-art text classification models such as TF-IDF, word2Vec, and Zero shot learning. Our results show that the domain-adapted foundation model outperforms state-of-the-art text mining techniques and performs as well as a subject matter expert (SME). The proposed framework could accelerate the Scope 3 estimation at Enterprise scale and will help to take appropriate climate actions to achieve SDG 13.
</details>
<details>
<summary>摘要</summary>
大型企业面临一个决定性的传统目标，即 alcancing Sustainable Development Goals (SDGs)，特别是目标13，它强调抗暖化和其影响。 为减少暖化的影响，减少企业范围3（供应链排放）是非常重要，因为它占总排放清单的超过90%。然而，追踪范围3排放是具有挑战性，因为需要从 thousands of 上游和下游供应商收集数据。为解决上述问题，我们提出了一个创新的框架，使用领域适应NLP基础模型估算范围3排放，通过利用购买商品和服务的金融交易作为代理。我们与州创的文本分类模型进行比较，包括TF-IDF、word2Vec和零 shot learning。我们的结果显示，领域适应基础模型比州创的文本探索技术更好，并且和专家（SME）的性能相似。我们的提案的框架可以优化企业范围3估算，帮助实现SDG 13，并且对抗暖化。
</details></li>
</ul>
<hr>
<h2 id="Ambient-Adventures-Teaching-ChatGPT-on-Developing-Complex-Stories"><a href="#Ambient-Adventures-Teaching-ChatGPT-on-Developing-Complex-Stories" class="headerlink" title="Ambient Adventures: Teaching ChatGPT on Developing Complex Stories"></a>Ambient Adventures: Teaching ChatGPT on Developing Complex Stories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01734">http://arxiv.org/abs/2308.01734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zexin Chen, Eric Zhou, Kenneth Eaton, Xiangyu Peng, Mark Riedl</li>
<li>for: 本研究旨在允许机器人通过幻想玩偶来与现实世界进行更加人性化的互动。</li>
<li>methods: 本研究采用大语言模型的故事生成能力，使用人写的提示生成幻想玩偶的故事，然后简化和映射到动作序列，以帮助机器人进行幻想玩偶。</li>
<li>results: 研究表明，通过使用大语言模型的故事生成能力和人写的提示，机器人可以成功完成幻想玩偶，并且在文本冒险游戏中 simulate 一个家庭作为玩偶场景。<details>
<summary>Abstract</summary>
Imaginative play is an area of creativity that could allow robots to engage with the world around them in a much more personified way. Imaginary play can be seen as taking real objects and locations and using them as imaginary objects and locations in virtual scenarios. We adopted the story generation capability of large language models (LLMs) to obtain the stories used for imaginary play with human-written prompts. Those generated stories will be simplified and mapped into action sequences that can guide the agent in imaginary play. To evaluate whether the agent can successfully finish the imaginary play, we also designed a text adventure game to simulate a house as the playground for the agent to interact.
</details>
<details>
<summary>摘要</summary>
幻想玩耍是一个创造力领域，可以让机器人与现实世界更加人性化地交互。幻想玩耍可以看作是将现实物品和位置用作虚拟enario中的幻想物品和位置。我们采用了大语言模型（LLM）的故事生成能力，使用人写的提示来生成故事。这些生成的故事将被简化并映射到动作序列，以引导代理人进行幻想玩耍。为了评估代理人是否能成功完成幻想玩耍，我们还设计了一个文本冒险游戏，模拟了一个家庭作为玩耍场地。
</details></li>
</ul>
<hr>
<h2 id="Baby’s-CoThought-Leveraging-Large-Language-Models-for-Enhanced-Reasoning-in-Compact-Models"><a href="#Baby’s-CoThought-Leveraging-Large-Language-Models-for-Enhanced-Reasoning-in-Compact-Models" class="headerlink" title="Baby’s CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models"></a>Baby’s CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01684">http://arxiv.org/abs/2308.01684</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oooranz/baby-cothought">https://github.com/oooranz/baby-cothought</a></li>
<li>paper_authors: Zheyu Zhang, Han Yang, Bolei Ma, David Rügamer, Ercong Nie</li>
<li>for: 这个论文主要目标是提出一种使用大语言模型（LLM）的链条（CoT）提示来高效地训练小语言模型（BabyLM）的pipeline。</li>
<li>methods: 该ipeline使用GPT-3.5-turbo来重新排序一个小于100M的数据集，并使用RoBERTa（Liu et al., 2019）的方式进行预训练。</li>
<li>results: 在4个benchmark上评测，该BabyLM表现得更好，在10种语言、NLU和问答任务中超过了RoBERTa-base的表现，提示了更好的Context抽取能力。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) demonstrate remarkable performance on a variety of Natural Language Understanding (NLU) tasks, primarily due to their in-context learning ability. This ability is utilized in our proposed "CoThought" pipeline, which efficiently trains smaller "baby" language models (BabyLMs) by leveraging the Chain of Thought (CoT) prompting of LLMs. Our pipeline restructures a dataset of less than 100M in size using GPT-3.5-turbo, transforming it into task-oriented, human-readable texts that are comparable to the school texts for language learners. The BabyLM is then pretrained on this restructured dataset in a RoBERTa (Liu et al., 2019) fashion. In evaluations across 4 benchmarks, our BabyLM outperforms the RoBERTa-base in 10 linguistic, NLU, and question answering tasks by more than 3 points, showing superior ability to extract contextual information. These results suggest that compact LMs pretrained on small, LLM-restructured data can better understand tasks and achieve improved performance. The code for data processing and model training is available at: https://github.com/oooranz/Baby-CoThought.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLM）在多种自然语言理解（NLU）任务上表现出众，主要归功于其在上下文学习能力。我们的提议的“CoThought”管道利用了LLM的链条（CoT）提问能力，将更小的“宝宝”语言模型（BabyLM）进行高效地训练。我们使用GPT-3.5-turbo重新排序了一个数据集，将其转换成任务导向、人类可读的文本，与学校语言学习课本相似。然后，我们使用RoBERTa（Liu et al., 2019）的方式先进行了BabyLM的预训练。在4个标准准标下进行评估，我们的BabyLM在10种语言、NLU和问答任务中超过了RoBERTa-base的3点，表明它更好地提取上下文信息。这些结果表明，使用小型LM在小数据集上进行预训练可以更好地理解任务，并实现更高的性能。相关代码可以在GitHub上找到：https://github.com/oooranz/Baby-CoThought。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-ChatGPT-text-mining-of-clinical-records-for-obesity-monitoring"><a href="#Evaluating-ChatGPT-text-mining-of-clinical-records-for-obesity-monitoring" class="headerlink" title="Evaluating ChatGPT text-mining of clinical records for obesity monitoring"></a>Evaluating ChatGPT text-mining of clinical records for obesity monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01666">http://arxiv.org/abs/2308.01666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivo S. Fins, Heather Davies, Sean Farrell, Jose R. Torres, Gina Pinchbeck, Alan D. Radford, Peter-John Noble</li>
<li>For: The paper aims to compare the ability of a large language model (ChatGPT) and a previously developed regular expression (RegexT) to identify overweight body condition scores (BCS) in veterinary narratives.* Methods: The study uses 4,415 anonymized clinical narratives, with BCS values extracted using either RegexT or by appending the narrative to a prompt sent to ChatGPT and manually reviewing the results.* Results: The paper finds that the precision of RegexT was higher (100%, 95% CI 94.81-100%) than the ChatGPT (89.3%, 95% CI 82.75-93.64%), but the recall of ChatGPT (100%, 95% CI 96.18-100%) was considerably higher than that of RegexT (72.6%, 95% CI 63.92-79.94%).Here are the three key points in Simplified Chinese text:* 用途: 这篇论文目的是比较一个大型自然语言模型（ChatGPT）和一个已经开发的正则表达（RegexT）在宠物临床报告中识别过重体重分数（BCS）的能力。* 方法: 这个研究使用了4415个匿名的临床报告，BCS值由RegexT或者将报告附加到ChatGPT的提示中，并 manually查看结果。* 结果: 论文发现，RegexT的精度（100%, 95% CI 94.81-100%）高于ChatGPT（89.3%, 95% CI 82.75-93.64%），但ChatGPT的感知（100%, 95% CI 96.18-100%）远高于RegexT（72.6%, 95% CI 63.92-79.94%）。<details>
<summary>Abstract</summary>
Background: Veterinary clinical narratives remain a largely untapped resource for addressing complex diseases. Here we compare the ability of a large language model (ChatGPT) and a previously developed regular expression (RegexT) to identify overweight body condition scores (BCS) in veterinary narratives. Methods: BCS values were extracted from 4,415 anonymised clinical narratives using either RegexT or by appending the narrative to a prompt sent to ChatGPT coercing the model to return the BCS information. Data were manually reviewed for comparison. Results: The precision of RegexT was higher (100%, 95% CI 94.81-100%) than the ChatGPT (89.3%; 95% CI82.75-93.64%). However, the recall of ChatGPT (100%. 95% CI 96.18-100%) was considerably higher than that of RegexT (72.6%, 95% CI 63.92-79.94%). Limitations: Subtle prompt engineering is needed to improve ChatGPT output. Conclusions: Large language models create diverse opportunities and, whilst complex, present an intuitive interface to information but require careful implementation to avoid unpredictable errors.
</details>
<details>
<summary>摘要</summary>
背景： veterinary clinical narratives remain a largely untapped resource for addressing complex diseases. 在这里，我们比较了一个大型自然语言模型（ChatGPT）和一个已经开发的正则表达（RegexT）可以在 veterinary narratives 中标识过重的体重 condition scores (BCS)。方法：BCS 值被提取自4,415个匿名的临床 narratives 中，使用 Either RegexT 或者附加 narrative 到一个提示，并将模型返回 BCSI 信息。数据被手动审查以进行比较。结果：RegexT 的精度高于 ChatGPT（100%, 95% CI 94.81-100%），但 ChatGPT 的回归高于 RegexT（100%, 95% CI 96.18-100%）。限制：需要细化的提示工程来提高 ChatGPT 输出。结论：大型自然语言模型创造了多样的机会，尽管复杂，但它们提供了直观的界面，但是需要小心的实施以避免不可预期的错误。
</details></li>
</ul>
<hr>
<h2 id="BioBERT-Based-SNP-traits-Associations-Extraction-from-Biomedical-Literature"><a href="#BioBERT-Based-SNP-traits-Associations-Extraction-from-Biomedical-Literature" class="headerlink" title="BioBERT Based SNP-traits Associations Extraction from Biomedical Literature"></a>BioBERT Based SNP-traits Associations Extraction from Biomedical Literature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02569">http://arxiv.org/abs/2308.02569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Dehghani, Behrouz Bokharaeian, Zahra Yazdanparast</li>
<li>for: 这个论文是为了提取生物医学信息中的单核苷多态性和特征之间的关系。</li>
<li>methods: 这个论文使用的方法是 BioBERT-GRU 方法，用于识别单核苷多态性和特征之间的关系。</li>
<li>results: 根据SNPPhenA数据集的评估结果，BioBERT-GRU 方法比前一些机器学习和深度学习基于的方法表现更好，具有精度为 0.883、回归率为 0.882 和 F1 分数为 0.881。<details>
<summary>Abstract</summary>
Scientific literature contains a considerable amount of information that provides an excellent opportunity for developing text mining methods to extract biomedical relationships. An important type of information is the relationship between singular nucleotide polymorphisms (SNP) and traits. In this paper, we present a BioBERT-GRU method to identify SNP- traits associations. Based on the evaluation of our method on the SNPPhenA dataset, it is concluded that this new method performs better than previous machine learning and deep learning based methods. BioBERT-GRU achieved the result a precision of 0.883, recall of 0.882 and F1-score of 0.881.
</details>
<details>
<summary>摘要</summary>
（文科文献中含有大量信息，提供了优秀的机会，用于发展文本挖掘技术，抽取生物医学关系。特别是关于单核苷多态性（SNP）和特征之间的关系。在本文中，我们提出了 BioBERT-GRU 方法，用于找到 SNP-特征关系。对于 SNPPhenA 数据集的评估，我们得出结论，这种新方法在前一些机器学习和深度学习基于方法上表现更好。BioBERT-GRU 实现了一个精度为 0.883，回归率为 0.882，和 F1 分数为 0.881。）
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Neurons-in-Pretrained-Text-Only-Transformers"><a href="#Multimodal-Neurons-in-Pretrained-Text-Only-Transformers" class="headerlink" title="Multimodal Neurons in Pretrained Text-Only Transformers"></a>Multimodal Neurons in Pretrained Text-Only Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01544">http://arxiv.org/abs/2308.01544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarah Schwettmann, Neil Chowdhury, Antonio Torralba</li>
<li>for: 这个论文旨在研究语言模型是否可以将一个modalities的表示映射到另一个modalities的下游任务中。</li>
<li>methods: 这篇论文使用了一个冻结的文本转换器，并通过一个自然语言生成器和一个单线性映射学习了一个图像-文本任务。</li>
<li>results: 研究发现，当图像和文本modalities被拼接在一起时，语言模型可以将图像表示映射到文本中，并且这种转换发生在transformer模型的深处。此外，研究还发现了一些”多Modal neurons”，这些neurons可以将视觉表示转换为对应的文本描述，并且这种转换具有系统的 causal effect on image captioning。<details>
<summary>Abstract</summary>
Language models demonstrate remarkable capacity to generalize representations learned in one modality to downstream tasks in other modalities. Can we trace this ability to individual neurons? We study the case where a frozen text transformer is augmented with vision using a self-supervised visual encoder and a single linear projection learned on an image-to-text task. Outputs of the projection layer are not immediately decodable into language describing image content; instead, we find that translation between modalities occurs deeper within the transformer. We introduce a procedure for identifying "multimodal neurons" that convert visual representations into corresponding text, and decoding the concepts they inject into the model's residual stream. In a series of experiments, we show that multimodal neurons operate on specific visual concepts across inputs, and have a systematic causal effect on image captioning.
</details>
<details>
<summary>摘要</summary>
语言模型表现出了惊人的泛化能力，可以将在一种modalities中学习的表示 transferred 到另一种modalities中的下游任务中。我们可以追溯这种能力到个体神经吗？我们研究一个冻结的文本转换器被融合到视觉中的情况，使用一个自我supervised visual encoder和一个单一的线性投影学习了一个image-to-text任务。投影层的输出不是 immediate 可以decode 到描述图像内容的语言;相反，我们发现在trasformer中， traduction between modalities 发生在更深层次。我们提出了一种方法来识别"多modal neurons"，它们将视觉表示转换成对应的语言表示，并在模型的剩余流中注入概念。在一系列实验中，我们发现这些多modal neurons 操作于特定的视觉概念上，并具有系统的 causal effect on image captioning。
</details></li>
</ul>
<hr>
<h2 id="Comparing-scalable-strategies-for-generating-numerical-perspectives"><a href="#Comparing-scalable-strategies-for-generating-numerical-perspectives" class="headerlink" title="Comparing scalable strategies for generating numerical perspectives"></a>Comparing scalable strategies for generating numerical perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01535">http://arxiv.org/abs/2308.01535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hancheng Cao, Sofia Eleni Spatharioti, Daniel G. Goldstein, Jake M. Hofman</li>
<li>for: 这篇论文目的是为了探讨如何生成大规模的数字观点，以帮助人们更好地理解EXTREME和不熟悉的数字（例如3300亿美元相当于每个美国人1000美元）。</li>
<li>methods: 这篇论文使用了三种策略来生成大规模的数字观点：一个基于规则的方法、一个基于人们协作的系统，以及一个使用Wikipedia数据和BERT嵌入来生成上下文特定的观点。</li>
<li>results: 研究发现，这三种策略之间有 synergy，不同的策略在不同的设置和上下文中表现出不同的优势，用户也表现出不同的偏好。<details>
<summary>Abstract</summary>
Numerical perspectives help people understand extreme and unfamiliar numbers (e.g., \$330 billion is about \$1,000 per person in the United States). While research shows perspectives to be helpful, generating them at scale is challenging both because it is difficult to identify what makes some analogies more helpful than others, and because what is most helpful can vary based on the context in which a given number appears. Here we present and compare three policies for large-scale perspective generation: a rule-based approach, a crowdsourced system, and a model that uses Wikipedia data and semantic similarity (via BERT embeddings) to generate context-specific perspectives. We find that the combination of these three approaches dominates any single method, with different approaches excelling in different settings and users displaying heterogeneous preferences across approaches. We conclude by discussing our deployment of perspectives in a widely-used online word processor.
</details>
<details>
<summary>摘要</summary>
numrical 角度可以帮助人们更好地理解极端和不熟悉的数字（例如， \$330 亿是美国每个人 \$1,000）。 Although research shows that perspectives are helpful, generating them at scale is challenging because it is difficult to identify which analogies are most helpful, and what is most helpful can vary based on the context in which a given number appears. Here, we present and compare three policies for large-scale perspective generation: a rule-based approach, a crowdsourced system, and a model that uses Wikipedia data and semantic similarity (via BERT embeddings) to generate context-specific perspectives. We find that the combination of these three approaches dominates any single method, with different approaches excelling in different settings and users displaying heterogeneous preferences across approaches. We conclude by discussing our deployment of perspectives in a widely-used online word processor.Note:* "numrical" is a typo, the correct word is "numerical"* "极端" is a more casual way of saying "extreme"* "不熟悉" is a more casual way of saying "unfamiliar"* "BERT embeddings" is a more technical term, you may want to use a more general term like "word embeddings" or "semantic embeddings" to make the text more accessible to a wider audience.
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Model-Displays-Emergent-Ability-to-Interpret-Novel-Literary-Metaphors"><a href="#Large-Language-Model-Displays-Emergent-Ability-to-Interpret-Novel-Literary-Metaphors" class="headerlink" title="Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors"></a>Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01497">http://arxiv.org/abs/2308.01497</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicholas Ichien, Dušan Stamenković, Keith J. Holyoak</li>
<li>for: 这个论文探讨了大型自然语言模型（LLM）是否可以在不同的语言处理和推理任务中达到人类高级能力水平。</li>
<li>methods: 该论文使用了GPT-4，一个现代大型语言模型，对塞尔维亚诗歌中的新型比喻进行了自然语言解释。</li>
<li>results: GPT-4能够提供精彩和准确的比喻解释，而且在逆比喻中也表现出了格雷西安合作原则的敏感性。这些结果表明LLMs such as GPT-4已经获得了解新的复杂比喻的能力。<details>
<summary>Abstract</summary>
Recent advances in the performance of large language models (LLMs) have sparked debate over whether, given sufficient training, high-level human abilities emerge in such generic forms of artificial intelligence (AI). Despite the exceptional performance of LLMs on a wide range of tasks involving natural language processing and reasoning, there has been sharp disagreement as to whether their abilities extend to more creative human abilities. A core example is the ability to interpret novel metaphors. Given the enormous and non-curated text corpora used to train LLMs, a serious obstacle to designing tests is the requirement of finding novel yet high-quality metaphors that are unlikely to have been included in the training data. Here we assessed the ability of GPT-4, a state-of-the-art large language model, to provide natural-language interpretations of novel literary metaphors drawn from Serbian poetry and translated into English. Despite exhibiting no signs of having been exposed to these metaphors previously, the AI system consistently produced detailed and incisive interpretations. Human judge - blind to the fact that an AI model was involved - rated metaphor interpretations generated by GPT-4 as superior to those provided by a group of college students. In interpreting reversed metaphors, GPT-4, as well as humans, exhibited signs of sensitivity to the Gricean cooperative principle. These results indicate that LLMs such as GPT-4 have acquired an emergent ability to interpret complex novel metaphors.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Investigating-Reinforcement-Learning-for-Communication-Strategies-in-a-Task-Initiative-Setting"><a href="#Investigating-Reinforcement-Learning-for-Communication-Strategies-in-a-Task-Initiative-Setting" class="headerlink" title="Investigating Reinforcement Learning for Communication Strategies in a Task-Initiative Setting"></a>Investigating Reinforcement Learning for Communication Strategies in a Task-Initiative Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01479">http://arxiv.org/abs/2308.01479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Baber Khalid, Matthew Stone</li>
<li>for: 这篇论文是为了研究在对话任务中如何实现精细化信息传递的优化策略。</li>
<li>methods: 论文使用了模拟方法，对初始呈现和后续跟进的交互策略进行了分析，并比较了多种基eline策略和由强化学习 derive的策略的性能。</li>
<li>results: 研究发现，使用 coherence-based 对话策略可以带来最小数据需求、可解释的选择和强大的审核能力，但具有较小的数据损失，并且在各种用户模型下表现良好。<details>
<summary>Abstract</summary>
Many conversational domains require the system to present nuanced information to users. Such systems must follow up what they say to address clarification questions and repair misunderstandings. In this work, we explore this interactive strategy in a referential communication task. Using simulation, we analyze the communication trade-offs between initial presentation and subsequent followup as a function of user clarification strategy, and compare the performance of several baseline strategies to policies derived by reinforcement learning. We find surprising advantages to coherence-based representations of dialogue strategy, which bring minimal data requirements, explainable choices, and strong audit capabilities, but incur little loss in predicted outcomes across a wide range of user models.
</details>
<details>
<summary>摘要</summary>
很多对话领域需要系统向用户提供细化信息。这些系统必须跟踪用户的提问和理解错误，以便进行回答和修复。在这个工作中，我们研究了这种交互策略在参照通信任务中的应用。使用模拟，我们分析了对话投入和后续跟进的交互траde-off，并比较了多种基eline策略和基于强化学习的策略的性能。我们发现了一些预期不一致的优点，包括减少数据需求、可解释的选择和强大的审核能力，但是这些策略具有较小的输出预测损失。
</details></li>
</ul>
<hr>
<h2 id="Reverse-Stable-Diffusion-What-prompt-was-used-to-generate-this-image"><a href="#Reverse-Stable-Diffusion-What-prompt-was-used-to-generate-this-image" class="headerlink" title="Reverse Stable Diffusion: What prompt was used to generate this image?"></a>Reverse Stable Diffusion: What prompt was used to generate this image?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01472">http://arxiv.org/abs/2308.01472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Mubarak Shah</li>
<li>for: 这个研究的目的是提出一个新的文本描述预测任务，即预测由生成演化模型生成的图像所对应的文本描述。</li>
<li>methods: 我们使用了一系列的白盒和黑盒模型（具有或无法访问演化网络的 weights）来处理这个任务。我们提出了一个共同的预告 regression 和多 label 词典分类目标，从而生成改进的预告。</li>
<li>results: 我们的新学习框架在这个任务中产生了出色的结果，尤其是在使用白盒模型时。此外，我们发现了一个有趣的发现：将演化模型直接用于文本至图像生成任务时，可以让模型生成更加适合预告的图像。<details>
<summary>Abstract</summary>
Text-to-image diffusion models such as Stable Diffusion have recently attracted the interest of many researchers, and inverting the diffusion process can play an important role in better understanding the generative process and how to engineer prompts in order to obtain the desired images. To this end, we introduce the new task of predicting the text prompt given an image generated by a generative diffusion model. We combine a series of white-box and black-box models (with and without access to the weights of the diffusion network) to deal with the proposed task. We propose a novel learning framework comprising of a joint prompt regression and multi-label vocabulary classification objective that generates improved prompts. To further improve our method, we employ a curriculum learning procedure that promotes the learning of image-prompt pairs with lower labeling noise (i.e. that are better aligned), and an unsupervised domain-adaptive kernel learning method that uses the similarities between samples in the source and target domains as extra features. We conduct experiments on the DiffusionDB data set, predicting text prompts from images generated by Stable Diffusion. Our novel learning framework produces excellent results on the aforementioned task, yielding the highest gains when applied on the white-box model. In addition, we make an interesting discovery: training a diffusion model on the prompt generation task can make the model generate images that are much better aligned with the input prompts, when the model is directly reused for text-to-image generation.
</details>
<details>
<summary>摘要</summary>
文本扩散模型，如稳定扩散，在近期吸引了许多研究人员的关注。在 revert 扩散过程中，可以更好地理解生成过程，并用于改进提示的工程。为此，我们提出了预测由生成扩散模型生成的图像中的文本提示的新任务。我们结合了一系列的白盒和黑盒模型（具有或 безDiffusion网络的参数）来处理该任务。我们提出了一种新的学习框架，包括联合提示回归和多类词汇分类目标，可以生成改进的提示。为了进一步改进我们的方法，我们使用了课程学习程序，该程序通过将图像提示与更低的标签噪音（即更好地对齐）进行排序，来促进学习。此外，我们还使用了无监督领域适应kernels的学习方法，该方法使用源和目标领域中样本之间的相似性作为额外特征。我们在DiffusionDB数据集上进行了实验，预测由Stable Diffusion生成的图像中的文本提示。我们的新的学习框架在该任务上取得了优秀的结果，特别是在白盒模型上。此外，我们还发现了一个有趣的发现：在直接将扩散模型用于文本到图像生成任务的训练过程中，可以使扩散模型生成更好地对齐的图像，当模型直接重用于文本到图像生成时。
</details></li>
</ul>
<hr>
<h2 id="UPB-at-IberLEF-2023-AuTexTification-Detection-of-Machine-Generated-Text-using-Transformer-Ensembles"><a href="#UPB-at-IberLEF-2023-AuTexTification-Detection-of-Machine-Generated-Text-using-Transformer-Ensembles" class="headerlink" title="UPB at IberLEF-2023 AuTexTification: Detection of Machine-Generated Text using Transformer Ensembles"></a>UPB at IberLEF-2023 AuTexTification: Detection of Machine-Generated Text using Transformer Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01408">http://arxiv.org/abs/2308.01408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrei-Alexandru Preda, Dumitru-Clementin Cercel, Traian Rebedea, Costin-Gabriel Chiru</li>
<li>for: 本文描述了UPB团队在AuTexTification共享任务中提交的解决方案，该任务是IberLEF-2023的一部分。</li>
<li>methods: 我们采用了基于Transformer的深度学习模型，以及多任务学习和虚拟反对抗训练等训练技术来提高结果。</li>
<li>results: 我们的最佳模型在英文数据集上 achievable macro F1-score为66.63%，在西班牙语数据集上 achievable macro F1-score为67.10%。<details>
<summary>Abstract</summary>
This paper describes the solutions submitted by the UPB team to the AuTexTification shared task, featured as part of IberLEF-2023. Our team participated in the first subtask, identifying text documents produced by large language models instead of humans. The organizers provided a bilingual dataset for this subtask, comprising English and Spanish texts covering multiple domains, such as legal texts, social media posts, and how-to articles. We experimented mostly with deep learning models based on Transformers, as well as training techniques such as multi-task learning and virtual adversarial training to obtain better results. We submitted three runs, two of which consisted of ensemble models. Our best-performing model achieved macro F1-scores of 66.63% on the English dataset and 67.10% on the Spanish dataset.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Optimizing-Machine-Translation-through-Prompt-Engineering-An-Investigation-into-ChatGPT’s-Customizability"><a href="#Optimizing-Machine-Translation-through-Prompt-Engineering-An-Investigation-into-ChatGPT’s-Customizability" class="headerlink" title="Optimizing Machine Translation through Prompt Engineering: An Investigation into ChatGPT’s Customizability"></a>Optimizing Machine Translation through Prompt Engineering: An Investigation into ChatGPT’s Customizability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01391">http://arxiv.org/abs/2308.01391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masaru Yamada</li>
<li>for: 这项研究探讨了在提示中包含翻译目标和目标受众的影响对ChatGPT生成的翻译质量。</li>
<li>methods: 研究采用了以前的翻译研究、行业实践和ISO标准，强调翻译过程的预制阶段的重要性。</li>
<li>results: 研究发现，在大规模语言模型如ChatGPT中添加合适的提示可以生成灵活的翻译，而 convention Machine Translation（MT）未能实现这一点。研究还发现，当提示包含特定条件时，翻译质量发生了变化。对于翻译质量的评价采用了实践翻译家的视角，并使用OpenAI的单词嵌入API进行cosine相似性计算。结果表明，在提示中包含翻译目标和目标受众可以改善翻译质量，并且在市场文档和文化依赖的成语中特别有用。<details>
<summary>Abstract</summary>
This paper explores the influence of integrating the purpose of the translation and the target audience into prompts on the quality of translations produced by ChatGPT. Drawing on previous translation studies, industry practices, and ISO standards, the research underscores the significance of the pre-production phase in the translation process. The study reveals that the inclusion of suitable prompts in large-scale language models like ChatGPT can yield flexible translations, a feat yet to be realized by conventional Machine Translation (MT). The research scrutinizes the changes in translation quality when prompts are used to generate translations that meet specific conditions. The evaluation is conducted from a practicing translator's viewpoint, both subjectively and qualitatively, supplemented by the use of OpenAI's word embedding API for cosine similarity calculations. The findings suggest that the integration of the purpose and target audience into prompts can indeed modify the generated translations, generally enhancing the translation quality by industry standards. The study also demonstrates the practical application of the "good translation" concept, particularly in the context of marketing documents and culturally dependent idioms.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/cs.CL_2023_08_03/" data-id="clogy1z1v008iffra8wzz9bri" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/cs.LG_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T10:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/cs.LG_2023_08_03/">cs.LG - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-Capability-of-Large-Language-Models-to-Measure-Psychiatric-Functioning"><a href="#The-Capability-of-Large-Language-Models-to-Measure-Psychiatric-Functioning" class="headerlink" title="The Capability of Large Language Models to Measure Psychiatric Functioning"></a>The Capability of Large Language Models to Measure Psychiatric Functioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01834">http://arxiv.org/abs/2308.01834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isaac R. Galatzer-Levy, Daniel McDuff, Vivek Natarajan, Alan Karthikesalingam, Matteo Malgaroli</li>
<li>for: 本研究用Large language models (LLMs)来预测心理功能，无需专门培训。</li>
<li>methods: 使用Med-PaLM 2对患者口述和临床描述进行预测，并使用提问提取估算的临床分数和诊断。</li>
<li>results: 研究发现，Med-PaLM 2可以预测多种心理疾病的功能，其中最高的性能是预测抑郁分数（准确率范围为0.80-0.84），与人类临床评估人员的表现相当（t(1,144) &#x3D; 1.20; p &#x3D; 0.23）。这些结果表明，通用临床语言模型可以静态预测心理风险基于自由描述功能。<details>
<summary>Abstract</summary>
The current work investigates the capability of Large language models (LLMs) that are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so. To assess this, n = 145 depression and n =115 PTSD assessments and n = 46 clinical case studies across high prevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma and stress, Addictive disorders) were analyzed using prompts to extract estimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments (Accuracy range= 0.80 - 0.84) which were statistically indistinguishable from human clinical raters t(1,144) = 1.20; p = 0.23. Results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians.
</details>
<details>
<summary>摘要</summary>
当前研究探讨了大型语言模型（LLMs）在大量医学知识训练（Med-PaLM 2）下预测患者的心理功能。为了评估这一点，研究人员分析了145例含有抑郁症和115例含有Post Traumatic Stress Disorder（PTSD）的评估结果，以及46例临床案例，包括高频高相关疾病（抑郁、焦虑、精神病、吸毒症）。结果表明Med-PaLM 2可以准确预测各种心理疾病的功能水平，最高的表现是预测抑郁评估结果（准确率范围为0.80-0.84），这与人类临床评估器的表现相当（t(1,144) = 1.20; p = 0.23）。结果表明大规模临床语言模型可以通过自动提取评估结果和诊断来预测心理风险。
</details></li>
</ul>
<hr>
<h2 id="Distribution-Free-Inference-for-the-Regression-Function-of-Binary-Classification"><a href="#Distribution-Free-Inference-for-the-Regression-Function-of-Binary-Classification" class="headerlink" title="Distribution-Free Inference for the Regression Function of Binary Classification"></a>Distribution-Free Inference for the Regression Function of Binary Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01835">http://arxiv.org/abs/2308.01835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ambrus Tamás, Balázs Csanád Csáji</li>
<li>for: 该论文主要针对二分类问题的回归函数（即输入 conditional 类别预测值）的建模和确定。</li>
<li>methods: 该论文提出了一种框架，用于构建准确、分布无关、非对数学上确定的 confidence 区间，以确定真实的回归函数。然后，提出了具体的算法来实现该框架。</li>
<li>results: 该论文证明了构建的 confidence 区间是强有力的，即任何不正确的模型都将在长期内被排除，并且这种排除可以通过 probably approximately correct 类型上下文来衡量。此外，提出了与 asymptotic 信息椭圆比较的方法。<details>
<summary>Abstract</summary>
One of the key objects of binary classification is the regression function, i.e., the conditional expectation of the class labels given the inputs. With the regression function not only a Bayes optimal classifier can be defined, but it also encodes the corresponding misclassification probabilities. The paper presents a resampling framework to construct exact, distribution-free and non-asymptotically guaranteed confidence regions for the true regression function for any user-chosen confidence level. Then, specific algorithms are suggested to demonstrate the framework. It is proved that the constructed confidence regions are strongly consistent, that is, any false model is excluded in the long run with probability one. The exclusion is quantified with probably approximately correct type bounds, as well. Finally, the algorithms are validated via numerical experiments, and the methods are compared to approximate asymptotic confidence ellipsoids.
</details>
<details>
<summary>摘要</summary>
一个重要的二分类问题中的重要对象是回归函数，即输入给定后的类标签的Conditional Expectation。不仅可以通过回归函数定义 bayes 优化的分类器，还可以编码相应的错误分布。文章提出了一种抽样框架，可以construct exact、distribution-free和非尺度假设保证的真实回归函数信心区间，并提供了特定的算法来实现该框架。文章证明了构造的信心区间具有strong consistency，即任何不正确模型都将在长期内被排除，并且这种排除的可靠性被证明为probabilistic bounds。最后，算法被 validate通过数值实验，并与approximate asymptotic confidence ellipsoids进行比较。
</details></li>
</ul>
<hr>
<h2 id="Hard-Adversarial-Example-Mining-for-Improving-Robust-Fairness"><a href="#Hard-Adversarial-Example-Mining-for-Improving-Robust-Fairness" class="headerlink" title="Hard Adversarial Example Mining for Improving Robust Fairness"></a>Hard Adversarial Example Mining for Improving Robust Fairness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01823">http://arxiv.org/abs/2308.01823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenhao Lin, Xiang Ji, Yulong Yang, Qian Li, Chao Shen, Run Wang, Liming Fang</li>
<li>for: 这个论文旨在提高深度神经网络（DNN）对于攻击性示例（AE）的抵抗性，并且解决这些模型对于不公正性问题的限制。</li>
<li>methods: 这篇论文提出了一个简单又有效的框架，即适应式强制例预测（HAM），可以在适应性训练中对DNN进行适应性训练，以提高其对于AE的抵抗性和公正性。</li>
<li>results: 实验结果显示，这个方法可以在CIFAR-10、SVHN和Imagenette等数据集上实现重要的改善，即提高DNN对于AE的抵抗性和公正性，并且降低了computational cost。<details>
<summary>Abstract</summary>
Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE). Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
“对抗训练”（AT）是深度神经网络（DNN）的鲜明技术，可以提高其对假输入的鲜明性。然而， latest studies have shown that adversarially trained models are prone to unfairness problems, limiting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To address this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Furthermore, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Tensor-Programs-IVb-Adaptive-Optimization-in-the-Infinite-Width-Limit"><a href="#Tensor-Programs-IVb-Adaptive-Optimization-in-the-Infinite-Width-Limit" class="headerlink" title="Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit"></a>Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01814">http://arxiv.org/abs/2308.01814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Greg Yang, Etai Littwin</li>
<li>for: 这个论文旨在探讨适用于宽神经网络的自适应优化器，如 Adam 优化器，在宽神经网络中是否会出现新的现象。</li>
<li>methods: 该论文使用了一种新的表示语言 called Tensor Program，以及一种简化表达和计算的 bra-ket 表示法，来描述如何使用适应优化器处理梯度并生成更新。</li>
<li>results: 研究发现，在宽神经网络中使用适应优化器时，会出现类似于 Stochastic Gradient Descent (SGD) 中的特征学习和核函数行为的分 dichotomy。此外，研究还提出了一种新的 “神经 Tangent” 和 “最大更新” 概念，以描述在不同架构下的学习过程。<details>
<summary>Abstract</summary>
Going beyond stochastic gradient descent (SGD), what new phenomena emerge in wide neural networks trained by adaptive optimizers like Adam? Here we show: The same dichotomy between feature learning and kernel behaviors (as in SGD) holds for general optimizers as well, including Adam -- albeit with a nonlinear notion of "kernel." We derive the corresponding "neural tangent" and "maximal update" limits for any architecture. Two foundational advances underlie the above results: 1) A new Tensor Program language, NEXORT, that can express how adaptive optimizers process gradients into updates. 2) The introduction of bra-ket notation to drastically simplify expressions and calculations in Tensor Programs. This work summarizes and generalizes all previous results in the Tensor Programs series of papers.
</details>
<details>
<summary>摘要</summary>
SGD 以外，在宽神经网络中，适应优化器如 Adam 引入新的现象，我们在这里展示：SGD 中的特征学习和核函数行为之间的分 dichotomy 也存在于总优化器中，包括 Adam，但是它们的概念是非线性的。我们 deriv 出对于任何架构的“神经射”和“最大更新”的限制。这些结果基于以下两个基础性的进步：1. 一种新的tensor program语言，叫做 NEXORT，可以表示如何适应优化器处理梯度到更新的过程。2. 使用 bra-ket notation来剖析和计算tensor program表达式，从而大大简化表达式和计算。这篇文章总结了以前的所有tensor program系列文章的结果，并对其进行总结和推广。
</details></li>
</ul>
<hr>
<h2 id="Job-Shop-Scheduling-via-Deep-Reinforcement-Learning-a-Sequence-to-Sequence-approach"><a href="#Job-Shop-Scheduling-via-Deep-Reinforcement-Learning-a-Sequence-to-Sequence-approach" class="headerlink" title="Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach"></a>Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01797">http://arxiv.org/abs/2308.01797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawoz/JSP-DeepRL-Seq2Seq">https://github.com/dawoz/JSP-DeepRL-Seq2Seq</a></li>
<li>paper_authors: Giovanni Bonetta, Davide Zago, Rossella Cancelliere, Andrea Grosso</li>
<li>for: 这 paper 是用 Deep Reinforcement Learning 方法解决 Job Shop Problem，即一个常见的 Combinatorial Optimization 问题，以获得优化的生产计划。</li>
<li>methods: 该 paper 使用了一种基于自然语言编码器-解码器模型的 Deep Reinforcement Learning 方法，自动学习调度规则。这种方法 Never 在过去用于调度问题，但它可以普遍应用于其他优化调度任务。</li>
<li>results: 实验结果表明，该方法可以超越许多经典方法，以及部分 Deep Reinforcement Learning 方法，并在Job Shop Problem 中获得竞争力强的结果。<details>
<summary>Abstract</summary>
Job scheduling is a well-known Combinatorial Optimization problem with endless applications. Well planned schedules bring many benefits in the context of automated systems: among others, they limit production costs and waste. Nevertheless, the NP-hardness of this problem makes it essential to use heuristics whose design is difficult, requires specialized knowledge and often produces methods tailored to the specific task. This paper presents an original end-to-end Deep Reinforcement Learning approach to scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes. We applied and tested our method in particular to some benchmark instances of Job Shop Problem, but this technique is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention. Results demonstrate that we outperform many classical approaches exploiting priority dispatching rules and show competitive results on state-of-the-art Deep Reinforcement Learning ones.
</details>
<details>
<summary>摘要</summary>
“Job scheduling 是一个非常知名的 Combinatorial Optimization 问题，它在各种自动化系统中有无数应用。一旦规划得好，就能够限制生产成本和废弃物。然而，这个问题的NP-hardness使得需要使用专门的知识和技巧来设计对特定任务的方法。这篇文章提出了一个原创的 Deep Reinforcement Learning 方法，可以自动学习派送规则。我们的技术受自然语言Encoder-Decoder模型的启发，并从未在Job Shop Problem 中使用过。我们将这个方法应用到了一些 benchmark 的Job Shop Problem 问题上，但这个方法够通用，可以用来解决其他不同的优化任务。结果表明我们可以超过许多传统的优化方法，并与现有的 Deep Reinforcement Learning 方法竞争。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Adaptative-Variational-Quantum-Algorithms-on-QUBO-Instances"><a href="#Benchmarking-Adaptative-Variational-Quantum-Algorithms-on-QUBO-Instances" class="headerlink" title="Benchmarking Adaptative Variational Quantum Algorithms on QUBO Instances"></a>Benchmarking Adaptative Variational Quantum Algorithms on QUBO Instances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01789">http://arxiv.org/abs/2308.01789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gloria Turati, Maurizio Ferrari Dacrema, Paolo Cremonesi</li>
<li>for: 这 paper 的目的是对各种变量量量算法 (VQA) 进行系统性比较，以填补现有文献中缺乏系统性比较的问题。</li>
<li>methods: 这 paper 使用的方法包括：对三种已有的 Adaptative VQA（EVQE、VAns、RA-VQE）进行比较，以及对Quantum Approximate Optimization Algorithm (QAOA) 的分析。这些方法都应用于 QUBO 问题上，并通过评估解决的质量和计算时间来评估其表现。</li>
<li>results: 这 paper 的结果表明，Adaptative VQA 方法在 QUBO 问题上的表现比 traditional VQA 方法更好，特别是在选择合适的 hyperparameter 时。此外，这 paper 还发现，在不同的 hyperparameter 选择情况下，Adaptative VQA 方法的表现可以得到大幅提高。这些结果可以作为 near-term 量子计算机设备上 Adaptative VQA 的标准 Referential，并为未来这一领域的研究提供有价值的指导。<details>
<summary>Abstract</summary>
In recent years, Variational Quantum Algorithms (VQAs) have emerged as a promising approach for solving optimization problems on quantum computers in the NISQ era. However, one limitation of VQAs is their reliance on fixed-structure circuits, which may not be taylored for specific problems or hardware configurations. A leading strategy to address this issue are Adaptative VQAs, which dynamically modify the circuit structure by adding and removing gates, and optimize their parameters during the training. Several Adaptative VQAs, based on heuristics such as circuit shallowness, entanglement capability and hardware compatibility, have already been proposed in the literature, but there is still lack of a systematic comparison between the different methods. In this paper, we aim to fill this gap by analyzing three Adaptative VQAs: Evolutionary Variational Quantum Eigensolver (EVQE), Variable Ansatz (VAns), already proposed in the literature, and Random Adapt-VQE (RA-VQE), a random approach we introduce as a baseline. In order to compare these algorithms to traditional VQAs, we also include the Quantum Approximate Optimization Algorithm (QAOA) in our analysis. We apply these algorithms to QUBO problems and study their performance by examining the quality of the solutions found and the computational times required. Additionally, we investigate how the choice of the hyperparameters can impact the overall performance of the algorithms, highlighting the importance of selecting an appropriate methodology for hyperparameter tuning. Our analysis sets benchmarks for Adaptative VQAs designed for near-term quantum devices and provides valuable insights to guide future research in this area.
</details>
<details>
<summary>摘要</summary>
Recent years have seen the emergence of Variational Quantum Algorithms (VQAs) as a promising approach for solving optimization problems on quantum computers in the NISQ era. However, one limitation of VQAs is their reliance on fixed-structure circuits, which may not be tailored for specific problems or hardware configurations. To address this issue, Adaptative VQAs have been proposed, which dynamically modify the circuit structure and optimize parameters during training. Several Adaptative VQAs have been proposed in the literature, but there is still a lack of systematic comparison between them. In this paper, we aim to fill this gap by analyzing three Adaptative VQAs: Evolutionary Variational Quantum Eigensolver (EVQE), Variable Ansatz (VAns), and Random Adapt-VQE (RA-VQE), as well as the Quantum Approximate Optimization Algorithm (QAOA) for comparison. We apply these algorithms to QUBO problems and study their performance by examining the quality of the solutions found and the computational times required. We also investigate the impact of hyperparameter choice on algorithm performance, highlighting the importance of selecting an appropriate methodology for hyperparameter tuning. Our analysis sets benchmarks for Adaptative VQAs designed for near-term quantum devices and provides valuable insights to guide future research in this area.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-Prediction-of-Stress-and-Strain-Maps-in-Arterial-Walls-for-Improved-Cardiovascular-Risk-Assessment"><a href="#Deep-Learning-based-Prediction-of-Stress-and-Strain-Maps-in-Arterial-Walls-for-Improved-Cardiovascular-Risk-Assessment" class="headerlink" title="Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment"></a>Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01771">http://arxiv.org/abs/2308.01771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasin Shokrollahi1, Pengfei Dong1, Xianqi Li, Linxia Gu</li>
<li>for: 这个研究旨在替代Finite Element Method (FEM)，使用深度学习工具来预测血管壁的剪切压力和扭矩分布。</li>
<li>methods: 我们提出了一种基于U-Net的全 convolutional neural network (CNN)，以及一种基于 conditional generative adversarial network (cGAN) 的模型，以预测血管壁的剪切压力和扭矩分布。</li>
<li>results: 我们的模型可以高度准确地预测血管壁的剪切压力和扭矩分布，并且可以考虑到不同的 calcification 量和空间配置。<details>
<summary>Abstract</summary>
This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall. We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections. Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations. On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps. Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps. The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set. Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain. Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set. Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Bag-of-Policies-for-Distributional-Deep-Exploration"><a href="#Bag-of-Policies-for-Distributional-Deep-Exploration" class="headerlink" title="Bag of Policies for Distributional Deep Exploration"></a>Bag of Policies for Distributional Deep Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01759">http://arxiv.org/abs/2308.01759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asen Nachkov, Luchen Li, Giulia Luise, Filippo Valdettaro, Aldo Faisal</li>
<li>for: 该研究旨在提高复杂环境中的演化学习（RL）效率，具体来说是在分布RL中进行深入探索。</li>
<li>methods: 我们提出了一种通用方法，即Bag of Policies（BoP），可以在任何返回分布估计器基础上建立，该方法通过维护多个独立更新的头部来实现深入探索。</li>
<li>results: 我们通过实验表明，BoP方法可以在ALE Atari游戏中提高学习robustness和速度。<details>
<summary>Abstract</summary>
Efficient exploration in complex environments remains a major challenge for reinforcement learning (RL). Compared to previous Thompson sampling-inspired mechanisms that enable temporally extended exploration, i.e., deep exploration, we focus on deep exploration in distributional RL. We develop here a general purpose approach, Bag of Policies (BoP), that can be built on top of any return distribution estimator by maintaining a population of its copies. BoP consists of an ensemble of multiple heads that are updated independently. During training, each episode is controlled by only one of the heads and the collected state-action pairs are used to update all heads off-policy, leading to distinct learning signals for each head which diversify learning and behaviour. To test whether optimistic ensemble method can improve on distributional RL as did on scalar RL, by e.g. Bootstrapped DQN, we implement the BoP approach with a population of distributional actor-critics using Bayesian Distributional Policy Gradients (BDPG). The population thus approximates a posterior distribution of return distributions along with a posterior distribution of policies. Another benefit of building upon BDPG is that it allows to analyze global posterior uncertainty along with local curiosity bonus simultaneously for exploration. As BDPG is already an optimistic method, this pairing helps to investigate if optimism is accumulatable in distributional RL. Overall BoP results in greater robustness and speed during learning as demonstrated by our experimental results on ALE Atari games.
</details>
<details>
<summary>摘要</summary>
efficient exploration in complex environments remains a major challenge for reinforcement learning (RL). compared to previous thompson sampling-inspired mechanisms that enable temporally extended exploration, i.e., deep exploration, we focus on deep exploration in distributional RL. we develop here a general purpose approach, bag of policies (BoP), that can be built on top of any return distribution estimator by maintaining a population of its copies. BoP consists of an ensemble of multiple heads that are updated independently. during training, each episode is controlled by only one of the heads and the collected state-action pairs are used to update all heads off-policy, leading to distinct learning signals for each head which diversify learning and behavior. to test whether optimistic ensemble method can improve on distributional RL as did on scalar RL, by e.g. bootstrapped dqn, we implement the BoP approach with a population of distributional actor-critics using bayesian distributional policy gradients (BDPG). the population thus approximates a posterior distribution of return distributions along with a posterior distribution of policies. another benefit of building upon BDPG is that it allows to analyze global posterior uncertainty along with local curiosity bonus simultaneously for exploration. as BDPG is already an optimistic method, this pairing helps to investigate if optimism is accumulatable in distributional RL. overall BoP results in greater robustness and speed during learning as demonstrated by our experimental results on ALE Atari games.
</details></li>
</ul>
<hr>
<h2 id="Guided-Distillation-for-Semi-Supervised-Instance-Segmentation"><a href="#Guided-Distillation-for-Semi-Supervised-Instance-Segmentation" class="headerlink" title="Guided Distillation for Semi-Supervised Instance Segmentation"></a>Guided Distillation for Semi-Supervised Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02668">http://arxiv.org/abs/2308.02668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tariq Berrada, Camille Couprie, Karteek Alahari, Jakob Verbeek</li>
<li>for: 提高实例 segmentation 方法的效果，减少依赖于全部标注的训练图像。</li>
<li>methods: 使用 semi-supervised 方法，即使用未标注数据作为训练信号，限制模型过拟合已标注样本。</li>
<li>results: 对 teacher-student distillation 模型进行改进，包括引入新的 “导引燃烧” 阶段和评估不同的实例 segmentation 架构、后向网络和预训练策略。这些改进导致了substantial 的提高，比如在 Cityscapes 数据集上提高 mask-AP 从 23.7 到 33.9，在 COCO 数据集上提高 mask-AP 从 18.3 到 34.1，即使使用只有 1% 的标注数据。<details>
<summary>Abstract</summary>
Although instance segmentation methods have improved considerably, the dominant paradigm is to rely on fully-annotated training images, which are tedious to obtain. To alleviate this reliance, and boost results, semi-supervised approaches leverage unlabeled data as an additional training signal that limits overfitting to the labeled samples. In this context, we present novel design choices to significantly improve teacher-student distillation models. In particular, we (i) improve the distillation approach by introducing a novel "guided burn-in" stage, and (ii) evaluate different instance segmentation architectures, as well as backbone networks and pre-training strategies. Contrary to previous work which uses only supervised data for the burn-in period of the student model, we also use guidance of the teacher model to exploit unlabeled data in the burn-in period. Our improved distillation approach leads to substantial improvements over previous state-of-the-art results. For example, on the Cityscapes dataset we improve mask-AP from 23.7 to 33.9 when using labels for 10\% of images, and on the COCO dataset we improve mask-AP from 18.3 to 34.1 when using labels for only 1\% of the training data.
</details>
<details>
<summary>摘要</summary>
尽管实例分割方法已经有了很大的进步，但现在主流的方法仍然是通过完全标注的图像进行训练，这是获取标注数据的劳作。为了解决这个问题， semi-supervised 方法可以利用无标注数据作为训练信号，限制学习到标注样本的过拟合。在这个上下文中，我们提出了新的设计选择，以提高教师学生液体模型。具体来说，我们（i）改进了液体模型的distillation方法，引入了一个新的“导向燃烧”阶段，以及（ii）评估不同的实例分割架构、背部网络和预训练策略。与前一个工作不同，我们在学生模型的燃烧期间也使用教师模型的指导来利用无标注数据。我们改进的液体模型方法导致了与前一个状态的 существенный改进。例如，在Cityscapes 数据集上，我们从 23.7 提高到 33.9 的 mask-AP，并在 COCO 数据集上从 18.3 提高到 34.1 的 mask-AP，只使用了1%的训练数据上的标注。
</details></li>
</ul>
<hr>
<h2 id="Neural-Collapse-Terminus-A-Unified-Solution-for-Class-Incremental-Learning-and-Its-Variants"><a href="#Neural-Collapse-Terminus-A-Unified-Solution-for-Class-Incremental-Learning-and-Its-Variants" class="headerlink" title="Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants"></a>Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01746">http://arxiv.org/abs/2308.01746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuralcollapseapplications/unicil">https://github.com/neuralcollapseapplications/unicil</a></li>
<li>paper_authors: Yibo Yang, Haobo Yuan, Xiangtai Li, Jianlong Wu, Lefei Zhang, Zhouchen Lin, Philip Torr, Dacheng Tao, Bernard Ghanem</li>
<li>for: 这篇论文targets class incremental learning (CIL)、long-tail class incremental learning (LTCIL)和 few-shot class incremental learning (FSCIL) 三种任务，解决了数据不均衡和数据罕见性导致的分类 incremental learning难题。</li>
<li>methods: 该论文提出了一种统一的解决方案，即使用神经萧条终点（Neural Collapse Terminus，NCT），它是一种固定结构，在整个标签空间中具有最大的等角间距性。NCT acts as a consistent target throughout the incremental training, avoiding dividing the feature space incrementally。在CIL和LTCIL任务中，我们还提出了一种prototype evolving scheme来使得backbone features满足NCT的要求。</li>
<li>results: 我们的方法可以在多个数据集上进行广泛的实验，证明了对所有三种任务和通用情况（不知道总类数和数据分布是ormal、long-tail或few-shot）的一致性。我们的方法也可以在数据不均衡和数据罕见性情况下保持分类能力，并且在不同的数据集上具有良好的普适性。<details>
<summary>Abstract</summary>
How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning. Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting. Existing methods are specifically proposed for one of the three tasks. In this paper, we offer a unified solution to the misalignment dilemma in the three tasks. Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space. It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally. For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly. Our method also works for FSCIL with only minor adaptations. Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity. We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method. Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case.
</details>
<details>
<summary>摘要</summary>
如何在新类添加时保持老类表现良好是incremental learning中的一大挑战。此外，长尾类增量学习和少shot类增量学习也被提出，以考虑数据不均和数据罕见的问题，这些问题在实际应用中非常普遍，并使得已知的忘记悖论变得更加严重。现有的方法主要针对其中一个任务。在这篇论文中，我们提出了对不一致的问题的共同解决方案。具体来说，我们提议一个固定结构的神经覆盖终点，该结构具有整个标签空间中最大的等角间类分离度。它在增量训练中 acted as一个不可分割的目标，以避免在增量训练中分割特征空间。对CIL和LTCIL，我们还提出了一种原型演化方案，用于使得干扰核的特征慢慢地趋向于我们的神经覆盖终点。我们的方法也适用于FSCIL，只需要小量的修改。理论分析表明，我们的方法在增量训练中保持神经覆盖优化无关于数据不均或数据罕见。我们还设计了一个通用情况，在每次会话中不知道总共多少个类和数据分布是否正常、长尾或少shot，以测试我们的方法的普适性。我们在多个数据集上进行了广泛的实验，以证明我们的共同解决方案对所有三个任务和通用情况都是有效的。
</details></li>
</ul>
<hr>
<h2 id="Multitask-Learning-with-No-Regret-from-Improved-Confidence-Bounds-to-Active-Learning"><a href="#Multitask-Learning-with-No-Regret-from-Improved-Confidence-Bounds-to-Active-Learning" class="headerlink" title="Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning"></a>Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01744">http://arxiv.org/abs/2308.01744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pier Giuseppe Sessa, Pierre Laforgue, Nicolò Cesa-Bianchi, Andreas Krause</li>
<li>for: This paper is written for people who want to learn multiple related tasks simultaneously while quantifying uncertainty in the estimated tasks, especially in the challenging agnostic setting.</li>
<li>methods: The paper uses novel multitask confidence intervals that do not require i.i.d. data and can be applied to bound the regret in online learning. The paper also proposes a novel online learning algorithm that achieves improved regret without knowing the task similarity parameter in advance.</li>
<li>results: The paper obtains new regret guarantees that can significantly improve over treating tasks independently, and introduces a novel multitask active learning setup where several tasks must be simultaneously optimized but only one can be queried for feedback. The paper also empirically validates the bounds and algorithms on synthetic and real-world data.<details>
<summary>Abstract</summary>
Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them. Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning. In this work, we provide novel multitask confidence intervals in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner. The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning. Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently. We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity. As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round. For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried. Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data.
</details>
<details>
<summary>摘要</summary>
多任务学习是一种强大的框架，它允许学习多个相关的任务，并在这些任务之间共享信息。量化任务估计中的不确定性是许多下游应用的关键问题，如在线学习或活动学习中。在这种工作中，我们提供了新的多任务信息增强的信度范围，这些范围不需要数据的i.i.d.分布，并可以直接应用于约束在线学习中的 regret。通过对多任务信息增强的细化分析，我们获得了新的 regret 保证，这些保证与任务相似性参数有关，可以在不知道任务相似性参数的情况下提高 regret 的性能。我们还提出了一种新的在线学习算法，该算法可以在不知道任务相似性参数的情况下实现改进的 regret。作为第二个关键应用，我们介绍了一种多任务活动学习设置，在这种设置中，学习器需要同时优化多个任务，但只有一个任务可以在每个轮次中被学习器请求反馈。为解决这个问题，我们设计了一种不会 regret 的算法，该算法使用我们的信度范围来决定哪个任务应该被请求反馈。最后，我们通过synthetic和实际世界（药物发现）数据进行了实验 validate 我们的 bound 和算法。
</details></li>
</ul>
<hr>
<h2 id="Finding-the-Optimum-Design-of-Large-Gas-Engines-Prechambers-Using-CFD-and-Bayesian-Optimization"><a href="#Finding-the-Optimum-Design-of-Large-Gas-Engines-Prechambers-Using-CFD-and-Bayesian-Optimization" class="headerlink" title="Finding the Optimum Design of Large Gas Engines Prechambers Using CFD and Bayesian Optimization"></a>Finding the Optimum Design of Large Gas Engines Prechambers Using CFD and Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01743">http://arxiv.org/abs/2308.01743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Posch, Clemens Gößnitzer, Franz Rohrhofer, Bernhard C. Geiger, Andreas Wimmer</li>
<li>for: 优化大气Engine增压器设计，以实现稳定燃烧、低排放和高效率。</li>
<li>methods: 使用计算流体力学（CFD）模拟和 bayesian优化算法，对增压器设计参数进行优化。</li>
<li>results: 实验结果表明，选择的策略能够有效地找到符合目标值的增压器设计。<details>
<summary>Abstract</summary>
The turbulent jet ignition concept using prechambers is a promising solution to achieve stable combustion at lean conditions in large gas engines, leading to high efficiency at low emission levels. Due to the wide range of design and operating parameters for large gas engine prechambers, the preferred method for evaluating different designs is computational fluid dynamics (CFD), as testing in test bed measurement campaigns is time-consuming and expensive. However, the significant computational time required for detailed CFD simulations due to the complexity of solving the underlying physics also limits its applicability. In optimization settings similar to the present case, i.e., where the evaluation of the objective function(s) is computationally costly, Bayesian optimization has largely replaced classical design-of-experiment. Thus, the present study deals with the computationally efficient Bayesian optimization of large gas engine prechambers design using CFD simulation. Reynolds-averaged-Navier-Stokes simulations are used to determine the target values as a function of the selected prechamber design parameters. The results indicate that the chosen strategy is effective to find a prechamber design that achieves the desired target values.
</details>
<details>
<summary>摘要</summary>
“湍流喷射概念使用预室是大气引擎中稳定燃烧的可能解，实现低排放水平的高效燃烧。由于大气引擎预室的设计和运行 Parameters 的广泛范围，所以 Computational Fluid Dynamics（CFD）是评估不同设计的优先方法，因为实验室测试是时间consuming 和昂贵的。但是，复杂的物理学 пробле 需要大量的计算时间，限制了 CFD 模拟的可行性。在优化设定中，例如现在的情况，Bayesian 优化已经取代了传统的设计实验。因此，本研究探讨了 Computationally Efficient Bayesian 优化大气引擎预室设计 using CFD 模拟。Reynolds-averaged-Navier-Stokes 模拟用于选择预室设计参数中的目标值。结果显示选择的策略是有效的，可以找到一个符合预期的预室设计。”
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Multi-Label-Correlation-in-Label-Distribution-Learning"><a href="#Exploiting-Multi-Label-Correlation-in-Label-Distribution-Learning" class="headerlink" title="Exploiting Multi-Label Correlation in Label Distribution Learning"></a>Exploiting Multi-Label Correlation in Label Distribution Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01742">http://arxiv.org/abs/2308.01742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqiang Kou jing wang yuheng jia xin geng</li>
<li>for: This paper focuses on addressing the challenges of Label Distribution Learning (LDL) methods that exploit low-rank label correlation, which is not always present in real-world datasets.</li>
<li>methods: The proposed method introduces an auxiliary Multi-Label Learning (MLL) process to capture low-rank label correlation, which is then used to improve the performance of LDL.</li>
<li>results: The proposed method is shown to be superior to existing LDL methods through comprehensive experiments, and ablation studies demonstrate the advantages of exploiting low-rank label correlation in the auxiliary MLL.Here’s the text in Simplified Chinese:</li>
<li>for: 本文主要研究 Label Distribution Learning (LDL) 方法中的一个挑战，即优化方法可以快速地适应实际数据中的 label distribution 结构。</li>
<li>methods: 提议的方法是通过引入多标签学习 (MLL) 过程来捕捉 label distribution 的低级别结构，从而提高 LDL 的性能。</li>
<li>results: 实验结果表明，提议的方法在比较实验中胜过现有的 LDL 方法，并且精细分析表明低级别 label correlation 的利用在 auxiliary MLL 中具有优势。<details>
<summary>Abstract</summary>
Label Distribution Learning (LDL) is a novel machine learning paradigm that assigns label distribution to each instance. Many LDL methods proposed to leverage label correlation in the learning process to solve the exponential-sized output space; among these, many exploited the low-rank structure of label distribution to capture label correlation. However, recent studies disclosed that label distribution matrices are typically full-rank, posing challenges to those works exploiting low-rank label correlation. Note that multi-label is generally low-rank; low-rank label correlation is widely adopted in multi-label learning (MLL) literature. Inspired by that, we introduce an auxiliary MLL process in LDL and capture low-rank label correlation on that MLL rather than LDL. In such a way, low-rank label correlation is appropriately exploited in our LDL methods. We conduct comprehensive experiments and demonstrate that our methods are superior to existing LDL methods. Besides, the ablation studies justify the advantages of exploiting low-rank label correlation in the auxiliary MLL.
</details>
<details>
<summary>摘要</summary>
标签分布学习（LDL）是一种新的机器学习方案，它将标签分布分配给每个实例。许多LDL方法尝试利用标签相关性来解决输出空间的指数型增长;其中许多利用标签分布的低级结构来捕捉标签相关性。然而，最近的研究表明，标签分布矩阵通常是全级结构，这对那些利用低级标签相关性的方法带来挑战。注意，多标签通常是低级的；低级标签相关性广泛采用在多标签学习（MLL） литературе。针对此，我们引入了一个辅助的MLL过程，并在其上捕捉低级标签相关性。这种方法可以正确地利用低级标签相关性。我们进行了广泛的实验，并证明了我们的方法与现有的LDL方法相比，具有更高的性能。此外，缺失研究证明了在辅助MLL中利用低级标签相关性的优势。
</details></li>
</ul>
<hr>
<h2 id="Bringing-Chemistry-to-Scale-Loss-Weight-Adjustment-for-Multivariate-Regression-in-Deep-Learning-of-Thermochemical-Processes"><a href="#Bringing-Chemistry-to-Scale-Loss-Weight-Adjustment-for-Multivariate-Regression-in-Deep-Learning-of-Thermochemical-Processes" class="headerlink" title="Bringing Chemistry to Scale: Loss Weight Adjustment for Multivariate Regression in Deep Learning of Thermochemical Processes"></a>Bringing Chemistry to Scale: Loss Weight Adjustment for Multivariate Regression in Deep Learning of Thermochemical Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01954">http://arxiv.org/abs/2308.01954</a></li>
<li>repo_url: None</li>
<li>paper_authors: Franz M. Rohrhofer, Stefan Posch, Clemens Gößnitzer, José M. García-Oliver, Bernhard C. Geiger</li>
<li>for: 用于提高人工神经网络（ANN）在多变量回归任务中学习多种物质质量分布的精度。</li>
<li>methods: 使用一种简单 yet effective的损失函数调整方法，以超越标准的平均方差优化方法，使ANN可以准确地学习所有种类物质质量分布，包括次要种类，其标准优化完全失败。</li>
<li>results: 通过对网络训练过程中的梯度均衡来解释调整方法的效iveness。<details>
<summary>Abstract</summary>
Flamelet models are widely used in computational fluid dynamics to simulate thermochemical processes in turbulent combustion. These models typically employ memory-expensive lookup tables that are predetermined and represent the combustion process to be simulated. Artificial neural networks (ANNs) offer a deep learning approach that can store this tabular data using a small number of network weights, potentially reducing the memory demands of complex simulations by orders of magnitude. However, ANNs with standard training losses often struggle with underrepresented targets in multivariate regression tasks, e.g., when learning minor species mass fractions as part of lookup tables. This paper seeks to improve the accuracy of an ANN when learning multiple species mass fractions of a hydrogen (\ce{H2}) combustion lookup table. We assess a simple, yet effective loss weight adjustment that outperforms the standard mean-squared error optimization and enables accurate learning of all species mass fractions, even of minor species where the standard optimization completely fails. Furthermore, we find that the loss weight adjustment leads to more balanced gradients in the network training, which explains its effectiveness.
</details>
<details>
<summary>摘要</summary>
FLAMELET模型广泛用于计算流体动力学来模拟热化学过程，其中通常使用占用内存的 lookup 表格来表示燃烧过程。人工神经网络（ANNs）提供了深度学习方法，可以将这些表格存储在少量的网络参数中，可能在复杂的 simulations 中减少内存需求量度。然而，标准的训练损失通常在多变量回归任务中表现不佳，例如学习氢（\ce{H2））燃烧 lookup 表格中的少数种团谱。本文想要提高一个 ANN 在学习多种种团谱的燃烧 lookup 表格中的准确性。我们评估了一种简单 yet effective 的损失加权调整，超越标准的均方差估计，使得网络在所有种团谱中学习准确，包括少数种团谱，其标准估计完全失败。此外，我们发现损失加权调整导致了网络训练过程中的更平衡的梯度，这解释了其效果。
</details></li>
</ul>
<hr>
<h2 id="MAP-A-Model-agnostic-Pretraining-Framework-for-Click-through-Rate-Prediction"><a href="#MAP-A-Model-agnostic-Pretraining-Framework-for-Click-through-Rate-Prediction" class="headerlink" title="MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction"></a>MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01737">http://arxiv.org/abs/2308.01737</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chiangel/map-code">https://github.com/chiangel/map-code</a></li>
<li>paper_authors: Jianghao Lin, Yanru Qu, Wei Guo, Xinyi Dai, Ruiming Tang, Yong Yu, Weinan Zhang</li>
<li>for: 这 paper 是为了提高个性化在线服务的Click-through rate (CTR) 预测而写的。</li>
<li>methods: 这 paper 使用了自我超vision学习 paradigm，并提出了两种实用算法：masked feature prediction (MFP) 和 replaced feature detection (RFD)，以更好地利用大量的用户点击记录数据。</li>
<li>results: 该 paper 的实验结果表明，使用 MFP 和 RFD 可以在两个实际大规模数据集（Avazu、Criteo）上 achieve new state-of-the-art 的性能，并且比以前的方法更高效和更加简单。<details>
<summary>Abstract</summary>
With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume. The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations. However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary. To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining. Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Quantification-of-Predictive-Uncertainty-via-Inference-Time-Sampling"><a href="#Quantification-of-Predictive-Uncertainty-via-Inference-Time-Sampling" class="headerlink" title="Quantification of Predictive Uncertainty via Inference-Time Sampling"></a>Quantification of Predictive Uncertainty via Inference-Time Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01731">http://arxiv.org/abs/2308.01731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katarína Tóthová, Ľubor Ladický, Daniel Thul, Marc Pollefeys, Ender Konukoglu</li>
<li>for: 预测变化和数据模糊问题的解决方案</li>
<li>methods: 使用后勤采样策略来估计预测不确定性，不需要专门的模型和训练机制，可以应用于任何循环幂网络</li>
<li>results: 可以生成不同可能的输出，与预测错误之间存在正相关性<details>
<summary>Abstract</summary>
Predictive variability due to data ambiguities has typically been addressed via construction of dedicated models with built-in probabilistic capabilities that are trained to predict uncertainty estimates as variables of interest. These approaches require distinct architectural components and training mechanisms, may include restrictive assumptions and exhibit overconfidence, i.e., high confidence in imprecise predictions. In this work, we propose a post-hoc sampling strategy for estimating predictive uncertainty accounting for data ambiguity. The method can generate different plausible outputs for a given input and does not assume parametric forms of predictive distributions. It is architecture agnostic and can be applied to any feed-forward deterministic network without changes to the architecture or training procedure. Experiments on regression tasks on imaging and non-imaging input data show the method's ability to generate diverse and multi-modal predictive distributions, and a desirable correlation of the estimated uncertainty with the prediction error.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的预测变化问题通常通过建立专门的模型，即建有 probabilistic 功能的模型，来解决。这些方法通常需要特定的架构组件和训练机制，可能带有限制性和过于自信，即高度自信准确但不准确的预测。在这种工作中，我们提议一种后期采样策略来估计预测uncertainty，考虑到数据的模糊性。该方法可以生成不同的可能性输出，并不假设预测分布的 parametic 形式。它是架构无关的，可以应用于任何 deterministic 网络，无需改变架构或训练过程。实验表明，该方法可以生成多模态和多样化的预测分布，并且预测uncertainty与预测误差之间存在可良好的相关性。Note: "Simplified Chinese" is a romanization of the Chinese language that uses a simplified set of characters and pronunciation, which is commonly used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Telematics-Combined-Actuarial-Neural-Networks-for-Cross-Sectional-and-Longitudinal-Claim-Count-Data"><a href="#Telematics-Combined-Actuarial-Neural-Networks-for-Cross-Sectional-and-Longitudinal-Claim-Count-Data" class="headerlink" title="Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data"></a>Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01729">http://arxiv.org/abs/2308.01729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francis Duval, Jean-Philippe Boucher, Mathieu Pigeon</li>
<li>for: 这个论文是为了提出一种基于Combined Actuarial Neural Network（CANN）框架的新型车险保险模型，以提高车险保险的准确性和效果。</li>
<li>methods: 这个论文使用了一种组合了传统核算模型和神经网络的方法，称之为CANN模型，它将传统的核算模型和神经网络组合起来，以获得一个两部分模型。这个模型利用了传统模型的坚实基础和神经网络的灵活性和处理能力，以捕捉车险保险中复杂的关系和互动。</li>
<li>results: 研究发现，使用CANN模型可以在车险保险中获得更高的准确性和效果，比起基于手动设计的茶imer特征的log-linear模型。<details>
<summary>Abstract</summary>
We present novel cross-sectional and longitudinal claim count models for vehicle insurance built upon the Combined Actuarial Neural Network (CANN) framework proposed by Mario W\"uthrich and Michael Merz. The CANN approach combines a classical actuarial model, such as a generalized linear model, with a neural network. This blending of models results in a two-component model comprising a classical regression model and a neural network part. The CANN model leverages the strengths of both components, providing a solid foundation and interpretability from the classical model while harnessing the flexibility and capacity to capture intricate relationships and interactions offered by the neural network. In our proposed models, we use well-known log-linear claim count regression models for the classical regression part and a multilayer perceptron (MLP) for the neural network part. The MLP part is used to process telematics car driving data given as a vector characterizing the driving behavior of each insured driver. In addition to the Poisson and negative binomial distributions for cross-sectional data, we propose a procedure for training our CANN model with a multivariate negative binomial (MVNB) specification. By doing so, we introduce a longitudinal model that accounts for the dependence between contracts from the same insured. Our results reveal that the CANN models exhibit superior performance compared to log-linear models that rely on manually engineered telematics features.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的跨sectional和 longitudinallaimcount模型，用于汽车保险，基于Mario W\"uthrich和Michael Merz所提出的Combined Actuarial Neural Network（CANN）框架。CANN方法将经典泛 actuarial模型，如通用线性模型，与神经网络结合。这种混合模型组成了两个组件：经典回归模型和神经网络部分。CANN模型利用了经典模型的坚实基础和可解释性，同时利用神经网络的灵活性和可捕捉复杂关系和互动。在我们的提议中，我们使用了常见的log-linear claim count回归模型作为经典回归部分，而用多层感知器（MLP）来处理每名保险人的驾驶行为数据。此外，我们还提出了一种训练CANN模型的多variate negative binomial（MVNB）规范的过程。通过这种方法，我们引入了一种Longitudinal模型，该模型考虑了同一保险人签订的合同之间的依赖关系。我们的结果表明，CANN模型比基于手动设计的 telematics特征的log-linear模型表现出色。
</details></li>
</ul>
<hr>
<h2 id="ADRNet-A-Generalized-Collaborative-Filtering-Framework-Combining-Clinical-and-Non-Clinical-Data-for-Adverse-Drug-Reaction-Prediction"><a href="#ADRNet-A-Generalized-Collaborative-Filtering-Framework-Combining-Clinical-and-Non-Clinical-Data-for-Adverse-Drug-Reaction-Prediction" class="headerlink" title="ADRNet: A Generalized Collaborative Filtering Framework Combining Clinical and Non-Clinical Data for Adverse Drug Reaction Prediction"></a>ADRNet: A Generalized Collaborative Filtering Framework Combining Clinical and Non-Clinical Data for Adverse Drug Reaction Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02571">http://arxiv.org/abs/2308.02571</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoxuanli-pku/adrnet">https://github.com/haoxuanli-pku/adrnet</a></li>
<li>paper_authors: Haoxuan Li, Taojun Hu, Zetong Xiong, Chunyuan Zheng, Fuli Feng, Xiangnan He, Xiao-Hua Zhou</li>
<li>for: 预测药物副作用 (ADR) 的精度和效率，以减少病人死亡和提高药物安全性。</li>
<li>methods: 基于合作过滤和表示学习的总结方法，利用非临床数据中的药物特征进行药物-副作用预测。</li>
<li>results: 在两个大规模的临床数据集上进行了广泛的比较性能测试，并在两个非临床数据集上进行了实验，证明了提案的 ADRNet 框架的准确性和效率。<details>
<summary>Abstract</summary>
Adverse drug reaction (ADR) prediction plays a crucial role in both health care and drug discovery for reducing patient mortality and enhancing drug safety. Recently, many studies have been devoted to effectively predict the drug-ADRs incidence rates. However, these methods either did not effectively utilize non-clinical data, i.e., physical, chemical, and biological information about the drug, or did little to establish a link between content-based and pure collaborative filtering during the training phase. In this paper, we first formulate the prediction of multi-label ADRs as a drug-ADR collaborative filtering problem, and to the best of our knowledge, this is the first work to provide extensive benchmark results of previous collaborative filtering methods on two large publicly available clinical datasets. Then, by exploiting the easy accessible drug characteristics from non-clinical data, we propose ADRNet, a generalized collaborative filtering framework combining clinical and non-clinical data for drug-ADR prediction. Specifically, ADRNet has a shallow collaborative filtering module and a deep drug representation module, which can exploit the high-dimensional drug descriptors to further guide the learning of low-dimensional ADR latent embeddings, which incorporates both the benefits of collaborative filtering and representation learning. Extensive experiments are conducted on two publicly available real-world drug-ADR clinical datasets and two non-clinical datasets to demonstrate the accuracy and efficiency of the proposed ADRNet. The code is available at https://github.com/haoxuanli-pku/ADRnet.
</details>
<details>
<summary>摘要</summary>
药物反应（ADR）预测对于医疗和药品发现具有关键作用，可以降低病人死亡率并提高药品安全性。在过去的几年中，许多研究都在努力地预测药物-ADR的发生率。然而，这些方法 Either did not effectively utilize non-clinical data, such as physical, chemical, and biological information about the drug, or did little to establish a link between content-based and pure collaborative filtering during the training phase.在本文中，我们将药物多标签 ADR 预测转化为药物-ADR 共同滤波问题，并且在我们所知道的范围内，这是首次对两个大规模公共可用的临床数据集进行了广泛的 benchmark 测试。然后，通过利用药物的易 accessible 非临床数据中的药物特征，我们提出了 ADRNet，一种通用的共同滤波框架，结合临床数据和非临床数据 для药物-ADR 预测。具体来说，ADRNet 包括一个浅层共同滤波模块和一个深度药物表示模块，可以利用高维度的药物描述符进一步引导学习低维度的 ADR 潜在嵌入，这里包括了共同滤波和表示学习的两大优点。我们对两个公共可用的实际世界药物-ADR 临床数据集和两个非临床数据集进行了广泛的实验，以证明我们提出的 ADRNet 的准确性和效率。代码可以在 <https://github.com/haoxuanli-pku/ADRnet> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Link-Prediction-Explanations-for-Graph-Neural-Networks"><a href="#Evaluating-Link-Prediction-Explanations-for-Graph-Neural-Networks" class="headerlink" title="Evaluating Link Prediction Explanations for Graph Neural Networks"></a>Evaluating Link Prediction Explanations for Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01682">http://arxiv.org/abs/2308.01682</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cborile/eval_lp_xai">https://github.com/cborile/eval_lp_xai</a></li>
<li>paper_authors: Claudio Borile, Alan Perotti, André Panisson</li>
<li>for: 本研究旨在提供链接预测模型的人类可理解的解释方法，以便推广图机器学习（GML）模型的应用。</li>
<li>methods: 本研究使用现有的图神经网络（GNN）解释方法，并提出了一些量化的评价指标来评估这些解释的质量。</li>
<li>results: 研究发现，不同的Distance between node embeddings选择对链接预测解释质量有所影响，而state-of-the-art explainability methods for GNN也在链接预测任务中表现不佳。<details>
<summary>Abstract</summary>
Graph Machine Learning (GML) has numerous applications, such as node/graph classification and link prediction, in real-world domains. Providing human-understandable explanations for GML models is a challenging yet fundamental task to foster their adoption, but validating explanations for link prediction models has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.
</details>
<details>
<summary>摘要</summary>
图机学（GML）在实际领域拥有很多应用，如节点/图分类和链接预测。提供可理解的图学模型解释是推广其采用的基本任务，但链接预测模型的解释 validation received little attention。在这篇论文中，我们提供了量化的评价指标，以确定链接预测解释的质量，无论有无ground-truth。我们使用这些指标评估当今的图学神经网络解释方法。我们还讨论了链接预测任务的下面假设和技术细节，如节点嵌入距离的选择，对解释质量产生的影响。
</details></li>
</ul>
<hr>
<h2 id="Learning-Implicit-Entity-object-Relations-by-Bidirectional-Generative-Alignment-for-Multimodal-NER"><a href="#Learning-Implicit-Entity-object-Relations-by-Bidirectional-Generative-Alignment-for-Multimodal-NER" class="headerlink" title="Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER"></a>Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02570">http://arxiv.org/abs/2308.02570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Chen, Jiajia Liu, Kaixiang Ji, Wang Ren, Jian Wang, Jingdong Wang</li>
<li>for: 本研究旨在解决多模态命名实体识别（MNER）中的两大挑战：一是桥接文本和图像之间的semantic gap，二是匹配实体与其相关的物体在图像中。</li>
<li>methods: 我们提出了一种拓展Generative Adversarial Networks（GANs）的双向生成对齐方法，名为BGA-MNER，它通过文本和图像两 modalities的生成和对齐，同时jointly optimize bidirectional reconstruction objective，以实现对实体-物体关系的直接和强大的约束。</li>
<li>results: 我们在两个 benchmark上进行了广泛的实验，并证明了我们的方法可以在无图像输入情况下达到状态级性能。<details>
<summary>Abstract</summary>
The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in image. Existing methods fail to capture the implicit entity-object relations, due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \texttt{image2text} and \texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our method achieves state-of-the-art performance without image input during inference.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficiency-of-First-Order-Methods-for-Low-Rank-Tensor-Recovery-with-the-Tensor-Nuclear-Norm-Under-Strict-Complementarity"><a href="#Efficiency-of-First-Order-Methods-for-Low-Rank-Tensor-Recovery-with-the-Tensor-Nuclear-Norm-Under-Strict-Complementarity" class="headerlink" title="Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity"></a>Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01677">http://arxiv.org/abs/2308.01677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Garber, Atara Kaplan</li>
<li>For: 该 paper 是为了研究低级数据的恢复问题，特别是使用紧张矩阵的拓扑级数据。* Methods: 该 paper 使用了各种约束优化算法，包括拓扑级数据的紧张矩阵减小问题，以及基于紧张矩阵的拓扑级数据的优化问题。* Results: 该 paper 得到了一些关于低级数据的恢复问题的结论，包括：1. 当 objective 函数 是强Converter 函数时，使用拓扑级数据的紧张矩阵减小问题可以实现 linear 的减小率，即使 objective 函数 不是强Converter 函数。2. 对于一个具有某些特定 tubal 级数据的优化问题，使用拓扑级数据的紧张矩阵减小问题可以实现 nearly linear 的减小率。3. 对于一个非均匀的 objective 函数，使用 extragradient 方法可以实现类似的结论。此外，paper 还提供了一些基本的结论，包括对高阶级数据的拓扑级数据的研究。<details>
<summary>Abstract</summary>
We consider convex relaxations for recovering low-rank tensors based on constrained minimization over a ball induced by the tensor nuclear norm, recently introduced in \cite{tensor_tSVD}. We build on a recent line of results that considered convex relaxations for the recovery of low-rank matrices and established that under a strict complementarity condition (SC), both the convergence rate and per-iteration runtime of standard gradient methods may improve dramatically. We develop the appropriate strict complementarity condition for the tensor nuclear norm ball and obtain the following main results under this condition: 1. When the objective to minimize is of the form $f(\mX)=g(\mA\mX)+\langle{\mC,\mX}\rangle$ , where $g$ is strongly convex and $\mA$ is a linear map (e.g., least squares), a quadratic growth bound holds, which implies linear convergence rates for standard projected gradient methods, despite the fact that $f$ need not be strongly convex. 2. For a smooth objective function, when initialized in certain proximity of an optimal solution which satisfies SC, standard projected gradient methods only require SVD computations (for projecting onto the tensor nuclear norm ball) of rank that matches the tubal rank of the optimal solution. In particular, when the tubal rank is constant, this implies nearly linear (in the size of the tensor) runtime per iteration, as opposed to super linear without further assumptions. 3. For a nonsmooth objective function which admits a popular smooth saddle-point formulation, we derive similar results to the latter for the well known extragradient method. An additional contribution which may be of independent interest, is the rigorous extension of many basic results regarding tensors of arbitrary order, which were previously obtained only for third-order tensors.
</details>
<details>
<summary>摘要</summary>
我们考虑对低维度tensor的复原问题进行凸relaxation，基于给定的ball induce by tensor nuclear norm， refer to \cite{tensor_tSVD}.我们建立在latest line of results中，对低维度matrix的复原问题进行凸relaxation，并证明在strict complementarity condition (SC)下，标准的梯度方法具有优化的传递率和每次迭代的时间复杂度。我们发展了适当的SC condition for tensor nuclear norm ball，并取得以下主要结果：1. 当目标函数为 $f(\mX)=g(\mA\mX)+\langle{\mC,\mX}\rangle$ ，其中 $g$ 是强式凸函数且 $\mA$ 是线性映射（例如最小二乘），则存在强式凸成长范围，这意味着标准的梯度方法具有直线传递率，即使 $f$ 不是强式凸函数。2. 当目标函数是光滑函数时，初始化在具有SC condition的优化解时，标准的梯度方法只需要进行tensor nuclear norm ball上的SVD computations（即 проек onto the tensor nuclear norm ball），其中rank与优化解的 tubal rank 匹配。在特定情况下，这意味着每次迭代只需要运算在nearly linear（在tensor的大小上）的时间内，相比之下，无需更多的假设时间复杂度增长。3. 当目标函数是非光滑函数且具有流行的双峰形式时，我们 derive similar results to the latter for the well-known extragradient method.此外，我们还提供了一些独立有兴趣的结果，例如对于任意维度tensor的基本结果的精确推广，这些结果曾经只被证明 для第三维度tensor。
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Reinforcement-Learning-of-Koopman-Models-for-Economic-Nonlinear-MPC"><a href="#End-to-End-Reinforcement-Learning-of-Koopman-Models-for-Economic-Nonlinear-MPC" class="headerlink" title="End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC"></a>End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01674">http://arxiv.org/abs/2308.01674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Mayfrank, Alexander Mitsos, Manuel Dahmen</li>
<li>For: The paper aims to develop a method for end-to-end reinforcement learning of dynamic surrogate models for optimal performance in nonlinear model predictive control (NMPC) applications.* Methods: The paper proposes a method for training dynamic surrogate models using reinforcement learning, which can reduce the computational burden of NMPC and improve its performance.* Results: The paper shows that the proposed method can achieve predictive controllers that strike a favorable balance between control performance and computational demand, and outperform models derived from system identification. Additionally, the method can react to changes in the control setting without retraining.<details>
<summary>Abstract</summary>
(Economic) nonlinear model predictive control ((e)NMPC) requires dynamic system models that are sufficiently accurate in all relevant state-space regions. These models must also be computationally cheap enough to ensure real-time tractability. Data-driven surrogate models for mechanistic models can be used to reduce the computational burden of (e)NMPC; however, such models are typically trained by system identification for maximum average prediction accuracy on simulation samples and perform suboptimally as part of actual (e)NMPC. We present a method for end-to-end reinforcement learning of dynamic surrogate models for optimal performance in (e)NMPC applications, resulting in predictive controllers that strike a favorable balance between control performance and computational demand. We validate our method on two applications derived from an established nonlinear continuous stirred-tank reactor model. We compare the controller performance to that of MPCs utilizing models trained by the prevailing maximum prediction accuracy paradigm, and model-free neural network controllers trained using reinforcement learning. We show that our method matches the performance of the model-free neural network controllers while consistently outperforming models derived from system identification. Additionally, we show that the MPC policies can react to changes in the control setting without retraining.
</details>
<details>
<summary>摘要</summary>
经济非线性模型预测控制（eNMPC）需要具有足够准确的动态系统模型，这些模型在所有相关的状态空间区域中都必须具有足够的准确性。这些模型还需要够快速 computationally，以确保实时可行性。基于系统认识的数据驱动模型可以用来降低(e)NMPC中的计算负担; however，这些模型通常通过系统认识来训练，以实现最大平均预测精度在模拟样本上。我们提出了一种终端渐进学习的动态代理模型方法，以实现在(e)NMPC应用中的优化性能。我们验证了这种方法，并将其应用于两个来自已知的非线性混合均匀 реактор模型中的应用。我们比较了控制性能与使用系统认识训练的模型、以及使用循环神经网络控制器训练的模型之间的性能。我们发现，我们的方法与使用循环神经网络控制器相当，而且一直 exceeds models derived from system identification。此外，我们还发现MPC策略可以随控制设置的变化而反应，无需重新训练。
</details></li>
</ul>
<hr>
<h2 id="UniG-Encoder-A-Universal-Feature-Encoder-for-Graph-and-Hypergraph-Node-Classification"><a href="#UniG-Encoder-A-Universal-Feature-Encoder-for-Graph-and-Hypergraph-Node-Classification" class="headerlink" title="UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node Classification"></a>UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01650">http://arxiv.org/abs/2308.01650</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/minhzou/unig-encoder">https://github.com/minhzou/unig-encoder</a></li>
<li>paper_authors: Minhao Zou, Zhongxue Gan, Yutong Wang, Junheng Zhang, Dongyan Sui, Chun Guan, Siyang Leng</li>
<li>for: 本研究旨在提出一种通用的特征编码器，用于图和高维图表示学习。</li>
<li>methods: 该方法使用一个前向变折框架，将图或高维图的 topological 关系转化为边或超边特征，然后将这些特征和原始节点特征 fed 入神经网络进行编码。</li>
<li>results: 对于十二种 represntative 高维图数据集和六种实际图数据集，该方法的性能都高于现有方法。<details>
<summary>Abstract</summary>
Graph and hypergraph representation learning has attracted increasing attention from various research fields. Despite the decent performance and fruitful applications of Graph Neural Networks (GNNs), Hypergraph Neural Networks (HGNNs), and their well-designed variants, on some commonly used benchmark graphs and hypergraphs, they are outperformed by even a simple Multi-Layer Perceptron. This observation motivates a reexamination of the design paradigm of the current GNNs and HGNNs and poses challenges of extracting graph features effectively. In this work, a universal feature encoder for both graph and hypergraph representation learning is designed, called UniG-Encoder. The architecture starts with a forward transformation of the topological relationships of connected nodes into edge or hyperedge features via a normalized projection matrix. The resulting edge/hyperedge features, together with the original node features, are fed into a neural network. The encoded node embeddings are then derived from the reversed transformation, described by the transpose of the projection matrix, of the network's output, which can be further used for tasks such as node classification. The proposed architecture, in contrast to the traditional spectral-based and/or message passing approaches, simultaneously and comprehensively exploits the node features and graph/hypergraph topologies in an efficient and unified manner, covering both heterophilic and homophilic graphs. The designed projection matrix, encoding the graph features, is intuitive and interpretable. Extensive experiments are conducted and demonstrate the superior performance of the proposed framework on twelve representative hypergraph datasets and six real-world graph datasets, compared to the state-of-the-art methods. Our implementation is available online at https://github.com/MinhZou/UniG-Encoder.
</details>
<details>
<summary>摘要</summary>
《图和高维图表示学习中的抽象和表示学习》在不同的研究领域中，图和高维图表示学习已经引起了越来越多的关注。Despite the decent performance and fruitful applications of图神经网络（GNNs）和高维图神经网络（HGNNs），以及其设计的许多变体，它们在一些常用的图和高维图上表现出色，但是它们仍然被简单的多层感知器（MLP）所超越。这一观察激发了现有GNNs和HGNNs的设计思维的重新检视，并提出了提取图特征的挑战。在这种情况下，我们提出了一种通用的图特征编码器，称为UniG-Encoder。UniG-Encoder的架构由一种正则化投影矩阵的前向变换和反向变换组成。在前向变换中，我们将图中连接的节点之间的 topological relationship 映射到edge或者高维edge特征上，使用正则化投影矩阵。得到的edge/高维edge特征和原始节点特征后，将被feed into一个神经网络。编码后的节点嵌入则可以通过反向变换，即神经网络输出的投影矩阵的转置，得到。这种架构与传统的spectral-based和/或message passing方法不同，同时并且全面地利用节点特征和图/高维图结构，提高了效率和一致性。设计的投影矩阵可以直观地和 interpretably 表示图特征。我们在十二个代表性的高维图数据集和六个实际的图数据集上进行了广泛的实验，并证明了我们的提案在这些数据集上表现出色，比传统的方法更高效。我们的实现可以在https://github.com/MinhZou/UniG-Encoder中找到。
</details></li>
</ul>
<hr>
<h2 id="MARLIM-Multi-Agent-Reinforcement-Learning-for-Inventory-Management"><a href="#MARLIM-Multi-Agent-Reinforcement-Learning-for-Inventory-Management" class="headerlink" title="MARLIM: Multi-Agent Reinforcement Learning for Inventory Management"></a>MARLIM: Multi-Agent Reinforcement Learning for Inventory Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01649">http://arxiv.org/abs/2308.01649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rémi Leluc, Elie Kadoche, Antoine Bertoncello, Sébastien Gourvénec</li>
<li>for:  solve the inventory management problem for a single-echelon multi-products supply chain with stochastic demands and lead-times.</li>
<li>methods:  reinforcement learning framework called MARLIM, with controllers developed through single or multiple agents in a cooperative setting.</li>
<li>results:  numerical experiments on real data demonstrate the benefits of reinforcement learning methods over traditional baselines.Here’s the text in Traditional Chinese if you prefer:</li>
<li>for: 解决供应链中单一层次多产品的存储管理问题，具有随机需求和延误时间。</li>
<li>methods: 使用增强学习框架 called MARLIM，通过单一或多个代理人在合作环境中发展控制器。</li>
<li>results: 使用实际数据进行numerical experiments，证明增强学习方法比传统基准方法更有利。<details>
<summary>Abstract</summary>
Maintaining a balance between the supply and demand of products by optimizing replenishment decisions is one of the most important challenges in the supply chain industry. This paper presents a novel reinforcement learning framework called MARLIM, to address the inventory management problem for a single-echelon multi-products supply chain with stochastic demands and lead-times. Within this context, controllers are developed through single or multiple agents in a cooperative setting. Numerical experiments on real data demonstrate the benefits of reinforcement learning methods over traditional baselines.
</details>
<details>
<summary>摘要</summary>
维护供应和需求产品的平衡是供应链业中最重要的挑战之一。本文提出了一个新的强化学习框架，名为 MARLIM，以解决单一库存产品供应链中的存储管理问题。在这个 Setting中，控制器通过单一或多个代理人在合作环境中发展。数值实验表明，强化学习方法比传统基线更有利。Here's the word-for-word translation:维护供应和需求产品的平衡是供应链业中最重要的挑战之一。本文提出了一个新的强化学习框架，名为 MARLIM，以解决单一库存产品供应链中的存储管理问题。在这个 Setting中，控制器通过单一或多个代理人在合作环境中发展。数值实验表明，强化学习方法比传统基线更有利。
</details></li>
</ul>
<hr>
<h2 id="Interleaving-GANs-with-knowledge-graphs-to-support-design-creativity-for-book-covers"><a href="#Interleaving-GANs-with-knowledge-graphs-to-support-design-creativity-for-book-covers" class="headerlink" title="Interleaving GANs with knowledge graphs to support design creativity for book covers"></a>Interleaving GANs with knowledge graphs to support design creativity for book covers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01626">http://arxiv.org/abs/2308.01626</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alexmotogna/generatorapi">https://github.com/alexmotogna/generatorapi</a></li>
<li>paper_authors: Alexandru Motogna, Adrian Groza</li>
<li>for: 这个论文是为了提高生成图书封面的质量，使用不同的训练方法来获得更好的生成图像。</li>
<li>methods: 该论文使用生成对抗网络（GANs）在图书封面领域中进行应用，并通过与知识图结合来修改输入标题，以获得更多的可能性。</li>
<li>results: 该方法在生成图书封面方面比前一些尝试更好，而知识图也为图书作者或编辑提供了更多的选择。<details>
<summary>Abstract</summary>
An attractive book cover is important for the success of a book. In this paper, we apply Generative Adversarial Networks (GANs) to the book covers domain, using different methods for training in order to obtain better generated images. We interleave GANs with knowledge graphs to alter the input title to obtain multiple possible options for any given title, which are then used as an augmented input to the generator. Finally, we use the discriminator obtained during the training phase to select the best images generated with new titles. Our method performed better at generating book covers than previous attempts, and the knowledge graph gives better options to the book author or editor compared to using GANs alone.
</details>
<details>
<summary>摘要</summary>
一个吸引人的书封面对于书的成功非常重要。在这篇论文中，我们使用生成对抗网络（GANs）来修改书封面领域，使用不同的训练方法来获得更好的生成图像。我们将GANs与知识图组合起来，使得输入标题的变化可以生成多个可能的选项，然后将这些选项作为增强的输入传递给生成器。最后，我们使用训练阶段获得的探测器来选择最佳的生成图像。我们的方法在生成书封面方面表现更好，并且知识图可以为书作者或编辑提供更好的选择，比起使用GANsalone。
</details></li>
</ul>
<hr>
<h2 id="Weighted-Multi-Level-Feature-Factorization-for-App-ads-CTR-and-installation-prediction"><a href="#Weighted-Multi-Level-Feature-Factorization-for-App-ads-CTR-and-installation-prediction" class="headerlink" title="Weighted Multi-Level Feature Factorization for App ads CTR and installation prediction"></a>Weighted Multi-Level Feature Factorization for App ads CTR and installation prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02568">http://arxiv.org/abs/2308.02568</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/knife982000/recsys2023challenge">https://github.com/knife982000/recsys2023challenge</a></li>
<li>paper_authors: Juan Manuel Rodriguez, Antonela Tommasel</li>
<li>for: 这项研究是为了提出一种用于ACM RecSys Challenge 2023的方法，以提高深层漏斗优化和特别强调用户隐私。</li>
<li>methods: 该方法基于归一化多级特征分解，将 clicking 和 installing 视为两个不同， yet related 任务，因此模型设计了特定任务的特定特征和共享特征。</li>
<li>results: 该方法在 academia-track 最终结果中获得了11名和总分55分的成绩。Is there anything else I can help with?<details>
<summary>Abstract</summary>
This paper provides an overview of the approach we used as team ISISTANITOS for the ACM RecSys Challenge 2023. The competition was organized by ShareChat, and involved predicting the probability of a user clicking an app ad and/or installing an app, to improve deep funnel optimization and a special focus on user privacy. Our proposed method inferring the probabilities of clicking and installing as two different, but related tasks. Hence, the model engineers a specific set of features for each task and a set of shared features. Our model is called Weighted Multi-Level Feature Factorization because it considers the interaction of different order features, where the order is associated to the depth in a neural network. The prediction for a given task is generated by combining the task specific and shared features on the different levels. Our submission achieved the 11 rank and overall score of 55 in the competition academia-track final results. We release our source code at: https://github.com/knife982000/RecSys2023Challenge
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multimodal-Indoor-Localisation-in-Parkinson’s-Disease-for-Detecting-Medication-Use-Observational-Pilot-Study-in-a-Free-Living-Setting"><a href="#Multimodal-Indoor-Localisation-in-Parkinson’s-Disease-for-Detecting-Medication-Use-Observational-Pilot-Study-in-a-Free-Living-Setting" class="headerlink" title="Multimodal Indoor Localisation in Parkinson’s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting"></a>Multimodal Indoor Localisation in Parkinson’s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02419">http://arxiv.org/abs/2308.02419</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ferdianjovan/Multihead-Dual-Convolutional-Self-Attention">https://github.com/ferdianjovan/Multihead-Dual-Convolutional-Self-Attention</a></li>
<li>paper_authors: Ferdian Jovan, Catherine Morgan, Ryan McConville, Emma L. Tonkin, Ian Craddock, Alan Whone</li>
<li>for: 本研究旨在提高现有indoor localization方法的效果，透过使用 transformer 模型和双模态数据（ Received Signal Strength Indicator 和加速器数据）来提高患者的跟踪精度。</li>
<li>methods: 本研究使用 transformer 模型和 dual modalities 来提高 indoor localization 的精度。</li>
<li>results: 研究结果表明，提案的网络在实际数据上表现出色，并且可以准确地预测患者是否正在服用 леvodopa 药物。<details>
<summary>Abstract</summary>
Parkinson's disease (PD) is a slowly progressive, debilitating neurodegenerative disease which causes motor symptoms including gait dysfunction. Motor fluctuations are alterations between periods with a positive response to levodopa therapy ("on") and periods marked by re-emergency of PD symptoms ("off") as the response to medication wears off. These fluctuations often affect gait speed and they increase in their disabling impact as PD progresses. To improve the effectiveness of current indoor localisation methods, a transformer-based approach utilising dual modalities which provide complementary views of movement, Received Signal Strength Indicator (RSSI) and accelerometer data from wearable devices, is proposed. A sub-objective aims to evaluate whether indoor localisation, including its in-home gait speed features (i.e. the time taken to walk between rooms), could be used to evaluate motor fluctuations by detecting whether the person with PD is taking levodopa medications or withholding them. To properly evaluate our proposed method, we use a free-living dataset where the movements and mobility are greatly varied and unstructured as expected in real-world conditions. 24 participants lived in pairs (consisting of one person with PD, one control) for five days in a smart home with various sensors. Our evaluation on the resulting dataset demonstrates that our proposed network outperforms other methods for indoor localisation. The sub-objective evaluation shows that precise room-level localisation predictions, transformed into in-home gait speed features, produce accurate predictions on whether the PD participant is taking or withholding their medications.
</details>
<details>
<summary>摘要</summary>
帕金森病 (PD) 是一种慢慢地进行、严重影响人体功能的神经退化疾病。它会导致运动症状，其中包括走姿畸形。在 леvodopa 治疗的影响下，运动症状会经历变化，通常是由“在”和“离”两种不同的状态组成的。这些变化会影响走姿速度，并且随着疾病的进行而加剧。为了改进现有的室内定位方法，一种基于 transformer 的方法，使用了两种不同的感知模式，即 Received Signal Strength Indicator (RSSI) 和加速器数据，从 wearable 设备获取。这种方法的一个目标是评估 Whether indoor localization, including its in-home gait speed features (i.e., the time taken to walk between rooms), could be used to evaluate motor fluctuations by detecting whether the person with PD is taking levodopa medications or withholding them。为了准确评估我们的提议方法，我们使用了一个免费生活数据集，该数据集包含了各种不同和不结构的运动和 mobilty 数据，如预计在实际条件下的情况。24名参与者（其中有1名帕金森病患者和1名控制人）在一个智能家庭中生活了5天，并装备了多种感知器。我们对 resulting 数据进行评估，并表明我们的提议网络在室内定位方面表现出色。另一个目标评估表明，通过精准地将室内定位预测结果转换为室内走姿速度特征，可以准确地预测帕金森病患者是否正在服用或减少 леvodopa 药物。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Convolutional-Neural-Network-Architecture-with-a-Continuous-Symmetry"><a href="#A-Novel-Convolutional-Neural-Network-Architecture-with-a-Continuous-Symmetry" class="headerlink" title="A Novel Convolutional Neural Network Architecture with a Continuous Symmetry"></a>A Novel Convolutional Neural Network Architecture with a Continuous Symmetry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01621">http://arxiv.org/abs/2308.01621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuyao12/ConvNets-PDE-perspective">https://github.com/liuyao12/ConvNets-PDE-perspective</a></li>
<li>paper_authors: Yao Liu, Hang Shao, Bing Bai</li>
<li>for: 这个论文旨在提出一种新的卷积神经网络（ConvNet）架构，以解决图像分类任务。</li>
<li>methods: 该架构基于一类几何Equation（PDEs），即 quasi-linear hyperbolic systems，并且允许权重的修改via维度的连续群 Symmetry。</li>
<li>results: 该架构可以与传统模型相比，在图像分类任务上达到相似的性能，并且可以推广到更多的应用场景。<details>
<summary>Abstract</summary>
This paper introduces a new Convolutional Neural Network (ConvNet) architecture inspired by a class of partial differential equations (PDEs) called quasi-linear hyperbolic systems. With comparable performance on the image classification task, it allows for the modification of the weights via a continuous group of symmetry. This is a significant shift from traditional models where the architecture and weights are essentially fixed. We wish to promote the (internal) symmetry as a new desirable property for a neural network, and to draw attention to the PDE perspective in analyzing and interpreting ConvNets in the broader Deep Learning community.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的卷积神经网络（ConvNet）建 architecture， Drawing inspiration from a class ofpartial differential equations（PDEs）called quasi-linear hyperbolic systems. 与传统模型相比，该建 architecture 允许权重的修改via continuous group of symmetry, 这是一种重要的shift。我们希望通过推广 internal symmetry 作为神经网络的新有利属性，并吸引更广泛的深度学习社区关注 PDE 的视角来分析和解释 ConvNets。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Systematic-Weaknesses-of-DNNs-using-Counterfactuals"><a href="#Assessing-Systematic-Weaknesses-of-DNNs-using-Counterfactuals" class="headerlink" title="Assessing Systematic Weaknesses of DNNs using Counterfactuals"></a>Assessing Systematic Weaknesses of DNNs using Counterfactuals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01614">http://arxiv.org/abs/2308.01614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sujan Sai Gannamaneni, Michael Mock, Maram Akila</li>
<li>for: This paper aims to identify systematic weaknesses in deep neural networks (DNNs) for safety-critical applications, and to develop an effective and computationally efficient algorithm to validate the semantic attribution of existing subsets.</li>
<li>methods: The proposed method is inspired by counterfactual explanations and uses a combination of feature importance and partial dependence plots to identify the causal relationship between specific attributes and the model’s performance.</li>
<li>results: The authors demonstrate the effectiveness of their approach on an example from the autonomous driving domain, showing that the proposed method can identify performance differences among different pedestrian assets, and that the asset type is not always the reason for reduced performance.<details>
<summary>Abstract</summary>
With the advancement of DNNs into safety-critical applications, testing approaches for such models have gained more attention. A current direction is the search for and identification of systematic weaknesses that put safety assumptions based on average performance values at risk. Such weaknesses can take on the form of (semantically coherent) subsets or areas in the input space where a DNN performs systematically worse than its expected average. However, it is non-trivial to attribute the reason for such observed low performances to the specific semantic features that describe the subset. For instance, inhomogeneities within the data w.r.t. other (non-considered) attributes might distort results. However, taking into account all (available) attributes and their interaction is often computationally highly expensive. Inspired by counterfactual explanations, we propose an effective and computationally cheap algorithm to validate the semantic attribution of existing subsets, i.e., to check whether the identified attribute is likely to have caused the degraded performance. We demonstrate this approach on an example from the autonomous driving domain using highly annotated simulated data, where we show for a semantic segmentation model that (i) performance differences among the different pedestrian assets exist, but (ii) only in some cases is the asset type itself the reason for this reduction in the performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Feature-Noise-Boosts-DNN-Generalization-under-Label-Noise"><a href="#Feature-Noise-Boosts-DNN-Generalization-under-Label-Noise" class="headerlink" title="Feature Noise Boosts DNN Generalization under Label Noise"></a>Feature Noise Boosts DNN Generalization under Label Noise</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01609">http://arxiv.org/abs/2308.01609</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zlzenglu/fn">https://github.com/zlzenglu/fn</a></li>
<li>paper_authors: Lu Zeng, Xuan Chen, Xiaoshuang Shi, Heng Tao Shen</li>
<li>for: 增强深度神经网络（DNNs）的泛化性，尤其是在标签噪声（label noise）的情况下。</li>
<li>methods: 直接将噪声添加到训练数据的特征上，使用了一种简单的特征噪声方法。</li>
<li>results: 经过了 teorтиче 分析和实验 validate，这种特征噪声方法可以有效地增强DNNs的泛化性，并且可以在不同的标签噪声水平和类型下选择合适的噪声类型和水平来实现恰当的标签噪声泛化。<details>
<summary>Abstract</summary>
The presence of label noise in the training data has a profound impact on the generalization of deep neural networks (DNNs). In this study, we introduce and theoretically demonstrate a simple feature noise method, which directly adds noise to the features of training data, can enhance the generalization of DNNs under label noise. Specifically, we conduct theoretical analyses to reveal that label noise leads to weakened DNN generalization by loosening the PAC-Bayes generalization bound, and feature noise results in better DNN generalization by imposing an upper bound on the mutual information between the model weights and the features, which constrains the PAC-Bayes generalization bound. Furthermore, to ensure effective generalization of DNNs in the presence of label noise, we conduct application analyses to identify the optimal types and levels of feature noise to add for obtaining desirable label noise generalization. Finally, extensive experimental results on several popular datasets demonstrate the feature noise method can significantly enhance the label noise generalization of the state-of-the-art label noise method.
</details>
<details>
<summary>摘要</summary>
Deep neural networks (DNNs) 的泛化能力受到标签噪声的影响。在这项研究中，我们介绍了一种简单的特征噪声方法，可以直接将噪声添加到训练数据的特征中，以提高 DNN 的泛化能力。我们进行了理论分析，发现标签噪声会导致 DNN 的泛化能力弱化，并且特征噪声会对 DNN 的泛化能力产生正面的影响，并且可以限制 PAC-Bayes 泛化约束。此外，为确保 DNN 在标签噪声下的有效泛化，我们进行了应用分析，以确定合适的特征噪声类型和水平。最后，我们对多个流行的数据集进行了广泛的实验，发现特征噪声方法可以显著提高标签噪声泛化方法的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Discriminative-Graph-level-Anomaly-Detection-via-Dual-students-teacher-Model"><a href="#Discriminative-Graph-level-Anomaly-Detection-via-Dual-students-teacher-Model" class="headerlink" title="Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model"></a>Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01947">http://arxiv.org/abs/2308.01947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whb605/gladst">https://github.com/whb605/gladst</a></li>
<li>paper_authors: Fu Lin, Xuexiong Luo, Jia Wu, Jian Yang, Shan Xue, Zitong Wang, Haonan Gong</li>
<li>for: 本文目的是提出一种基于图集中异常图的检测方法，以找到图集中异常的图。由于图集中异常检测的研究不够，现有的方法主要是通过捕捉异常图信息来学习更好的图表示。然而，它们忽略了异常图分类的有效性评价函数。本文因此首先定义图集中异常信息，包括节点和图像异常，并采用节点级和图级信息差异来识别它们。</li>
<li>methods: 本文提出了一种 dual-students-teacher 模型，其中教师模型使用了规则损函数来训练图表示更加分散。两个竞争学生模型，一个是 normal 图模型，另一个是异常图模型，分别适应教师模型的节点级和图级表示视角。最后，我们将两个学生模型的表示错误相加，以分类异常图。</li>
<li>results: 实验分析表明，我们的方法在真实世界中的图据集上得到了良好的效果，能够有效地检测图集中的异常图。<details>
<summary>Abstract</summary>
Different from the current node-level anomaly detection task, the goal of graph-level anomaly detection is to find abnormal graphs that significantly differ from others in a graph set. Due to the scarcity of research on the work of graph-level anomaly detection, the detailed description of graph-level anomaly is insufficient. Furthermore, existing works focus on capturing anomalous graph information to learn better graph representations, but they ignore the importance of an effective anomaly score function for evaluating abnormal graphs. Thus, in this work, we first define anomalous graph information including node and graph property anomalies in a graph set and adopt node-level and graph-level information differences to identify them, respectively. Then, we introduce a discriminative graph-level anomaly detection framework with dual-students-teacher model, where the teacher model with a heuristic loss are trained to make graph representations more divergent. Then, two competing student models trained by normal and abnormal graphs respectively fit graph representations of the teacher model in terms of node-level and graph-level representation perspectives. Finally, we combine representation errors between two student models to discriminatively distinguish anomalous graphs. Extensive experiment analysis demonstrates that our method is effective for the graph-level anomaly detection task on graph datasets in the real world.
</details>
<details>
<summary>摘要</summary>
不同于当前的节点级异常检测任务，我们的目标是找到图集中异常的图，并且这些图significantly differ from others。由于关于图级异常检测的研究 scarcity，我们所用的异常描述不够详细。此外，现有的works主要是捕捉异常图信息，以学习更好的图表示。然而，它们忽略了有效的异常分数函数的重要性，用于评估异常图。因此，在这个工作中，我们首先定义了图集中的异常信息，包括节点和图性异常。然后，我们提出了一种推理图级异常检测框架，使用两个学生模型和一个教师模型。教师模型通过规则损失进行训练，以使图表示更加分化。两个学生模型，分别使用正常和异常图进行训练，然后将教师模型的图表示分别拟合到节点级和图级 representation 两个视角中。最后，我们将两个学生模型的表示错误相加，以分类地分别检测异常图。我们的方法在实际世界上的图据上进行了广泛的实验分析，并证明其效果。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Multiplex-Graph-Learning-with-Complementary-and-Consistent-Information"><a href="#Unsupervised-Multiplex-Graph-Learning-with-Complementary-and-Consistent-Information" class="headerlink" title="Unsupervised Multiplex Graph Learning with Complementary and Consistent Information"></a>Unsupervised Multiplex Graph Learning with Complementary and Consistent Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01606">http://arxiv.org/abs/2308.01606</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/larryuestc/cocomg">https://github.com/larryuestc/cocomg</a></li>
<li>paper_authors: Liang Peng, Xin Wang, Xiaofeng Zhu</li>
<li>for: 本文提出了一种能够 Addressing two practical issues in unsupervised multiplex graph learning (UMGL) 的方法，即 out-of-sample 问题和噪声问题。</li>
<li>methods: 本文使用了多个 MLP Encoder 来进行表示学习，并对两个约束进行限制，即保持节点之间的本地图 структуры，以处理 out-of-sample 问题，并 maximize 多个节点表示之间的相关性，以处理噪声问题。</li>
<li>results: 对比其他方法，本文的提出的方法在不同的下游任务中显示出了显著的效果和高效率，能够有效地解决 out-of-sample 问题和噪声问题。<details>
<summary>Abstract</summary>
Unsupervised multiplex graph learning (UMGL) has been shown to achieve significant effectiveness for different downstream tasks by exploring both complementary information and consistent information among multiple graphs. However, previous methods usually overlook the issues in practical applications, i.e., the out-of-sample issue and the noise issue. To address the above issues, in this paper, we propose an effective and efficient UMGL method to explore both complementary and consistent information. To do this, our method employs multiple MLP encoders rather than graph convolutional network (GCN) to conduct representation learning with two constraints, i.e., preserving the local graph structure among nodes to handle the out-of-sample issue, and maximizing the correlation of multiple node representations to handle the noise issue. Comprehensive experiments demonstrate that our proposed method achieves superior effectiveness and efficiency over the comparison methods and effectively tackles those two issues. Code is available at https://github.com/LarryUESTC/CoCoMG.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本为简化中文。<</SYS>>无监督多Graph学习（UMGL）已经在不同的下游任务中显示出了显著的效果，通过探索多个图的共同信息和差异信息。然而，先前的方法通常忽视了实际应用中的问题，即外样问题和噪声问题。为了解决这些问题，在这篇论文中，我们提出了一种有效和高效的 UMGL 方法，通过两个约束来进行表示学习：一是保持节点之间的本地图 структуры，以处理外样问题，二是最大化多个节点表示之间的相关性，以处理噪声问题。广泛的实验表明，我们提出的方法在比较方法上显示出了superior的效果和高效性，并有效地解决了这两个问题。代码可以在 <https://github.com/LarryUESTC/CoCoMG> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-surrogate-models-for-parametrized-PDEs-handling-geometric-variability-through-graph-neural-networks"><a href="#Deep-Learning-based-surrogate-models-for-parametrized-PDEs-handling-geometric-variability-through-graph-neural-networks" class="headerlink" title="Deep Learning-based surrogate models for parametrized PDEs: handling geometric variability through graph neural networks"></a>Deep Learning-based surrogate models for parametrized PDEs: handling geometric variability through graph neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01602">http://arxiv.org/abs/2308.01602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicola Rares Franco, Stefania Fresca, Filippo Tombari, Andrea Manzoni</li>
<li>for: 本研究旨在提出一种基于图 neural network (GNN) 的时间依赖partial differential equation (PDE) 模拟方法，以提高模拟效率和泛化能力。</li>
<li>methods: 本研究使用了一种数据驱动的时间步骤方法，其中GNN建立了一个高效的系统来演化系统。</li>
<li>results: 实验结果表明，GNN 可以提供一种有效的替代方案，以提高模拟效率和泛化能力。 GNN 也能够在不同的几何和分辨率下进行泛化。<details>
<summary>Abstract</summary>
Mesh-based simulations play a key role when modeling complex physical systems that, in many disciplines across science and engineering, require the solution of parametrized time-dependent nonlinear partial differential equations (PDEs). In this context, full order models (FOMs), such as those relying on the finite element method, can reach high levels of accuracy, however often yielding intensive simulations to run. For this reason, surrogate models are developed to replace computationally expensive solvers with more efficient ones, which can strike favorable trade-offs between accuracy and efficiency. This work explores the potential usage of graph neural networks (GNNs) for the simulation of time-dependent PDEs in the presence of geometrical variability. In particular, we propose a systematic strategy to build surrogate models based on a data-driven time-stepping scheme where a GNN architecture is used to efficiently evolve the system. With respect to the majority of surrogate models, the proposed approach stands out for its ability of tackling problems with parameter dependent spatial domains, while simultaneously generalizing to different geometries and mesh resolutions. We assess the effectiveness of the proposed approach through a series of numerical experiments, involving both two- and three-dimensional problems, showing that GNNs can provide a valid alternative to traditional surrogate models in terms of computational efficiency and generalization to new scenarios. We also assess, from a numerical standpoint, the importance of using GNNs, rather than classical dense deep neural networks, for the proposed framework.
</details>
<details>
<summary>摘要</summary>
mesh-based 模拟在科学和工程多种领域中发挥关键作用，特别是在解决参数化时间依赖非线性偏微分方程（PDEs）中。在这种情况下，全序模型（FOMs），如基于finite element方法的模型，可以达到高级别的准确性，但通常需要昂贵的计算。为了解决这个问题，人们开发了代理模型，以换取更高效的计算方法，这可以实现可接受的妥协。本工作探讨在时间依赖PDEs中使用图 neural network（GNNs）进行模拟，特别是在具有参数化空间域的情况下。我们提出了一种系统atic的方法，使用数据驱动时间步骤来构建代理模型，其中GNN架构用于有效地演化系统。与大多数代理模型不同的是，我们的方法可以处理具有参数依赖的空间域的问题，同时能够泛化到不同的几何和分辨率。我们通过一系列数字实验，包括二维和三维问题，证明GNNs可以提供一个有效的代替方案，与传统的代理模型相比。此外，我们还从数值角度评估了使用GNNs而不使用传统的 dense deep neural networks 的重要性。
</details></li>
</ul>
<hr>
<h2 id="Experimental-Results-regarding-multiple-Machine-Learning-via-Quaternions"><a href="#Experimental-Results-regarding-multiple-Machine-Learning-via-Quaternions" class="headerlink" title="Experimental Results regarding multiple Machine Learning via Quaternions"></a>Experimental Results regarding multiple Machine Learning via Quaternions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01946">http://arxiv.org/abs/2308.01946</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianlei Zhu, Renzhe Zhu</li>
<li>for: 这个研究探讨了使用四元数在机器学习算法中的应用。</li>
<li>methods: 这个研究使用了四元数来表示和分类三维空间中的旋转数据，包括随机生成的四元数数据和相应的标签，将四元数转换为旋转矩阵，并使其为输入特征。</li>
<li>results: 根据四元数和多种机器学习算法，这个研究显示了更高的准确率和显著提高的预测性能。总之，这个研究提供了使用四元数进行机器学习任务的实质基础。<details>
<summary>Abstract</summary>
This paper presents an experimental study on the application of quaternions in several machine learning algorithms. Quaternion is a mathematical representation of rotation in three-dimensional space, which can be used to represent complex data transformations. In this study, we explore the use of quaternions to represent and classify rotation data, using randomly generated quaternion data and corresponding labels, converting quaternions to rotation matrices, and using them as input features. Based on quaternions and multiple machine learning algorithms, it has shown higher accuracy and significantly improved performance in prediction tasks. Overall, this study provides an empirical basis for exploiting quaternions for machine learning tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SoK-Assessing-the-State-of-Applied-Federated-Machine-Learning"><a href="#SoK-Assessing-the-State-of-Applied-Federated-Machine-Learning" class="headerlink" title="SoK: Assessing the State of Applied Federated Machine Learning"></a>SoK: Assessing the State of Applied Federated Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02454">http://arxiv.org/abs/2308.02454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tobias Müller, Maximilian Stäbler, Hugo Gascón, Frank Köster, Florian Matthes</li>
<li>for: 本研究旨在探讨 Federated Machine Learning (FedML) 在实际应用中的现状和挑战。</li>
<li>methods: 本研究采用系统性的文献回顾方法，对 74 篇相关文章进行分析，描述 FedML 实现的特点和趋势，以及其应用领域和推动因素。</li>
<li>results: 本研究发现，FedML 在privacy-critical 环境中具有潜在的应用前景，但是在实际应用中还存在一些挑战，如数据隐私保护和communication overhead。<details>
<summary>Abstract</summary>
Machine Learning (ML) has shown significant potential in various applications; however, its adoption in privacy-critical domains has been limited due to concerns about data privacy. A promising solution to this issue is Federated Machine Learning (FedML), a model-to-data approach that prioritizes data privacy. By enabling ML algorithms to be applied directly to distributed data sources without sharing raw data, FedML offers enhanced privacy protections, making it suitable for privacy-critical environments. Despite its theoretical benefits, FedML has not seen widespread practical implementation. This study aims to explore the current state of applied FedML and identify the challenges hindering its practical adoption. Through a comprehensive systematic literature review, we assess 74 relevant papers to analyze the real-world applicability of FedML. Our analysis focuses on the characteristics and emerging trends of FedML implementations, as well as the motivational drivers and application domains. We also discuss the encountered challenges in integrating FedML into real-life settings. By shedding light on the existing landscape and potential obstacles, this research contributes to the further development and implementation of FedML in privacy-critical scenarios.
</details>
<details>
<summary>摘要</summary>
This study aims to explore the current state of applied FedML and identify the challenges hindering its practical adoption. Through a comprehensive systematic literature review, we assess 74 relevant papers to analyze the real-world applicability of FedML. Our analysis focuses on the characteristics and emerging trends of FedML implementations, as well as the motivational drivers and application domains. We also discuss the encountered challenges in integrating FedML into real-life settings. By shedding light on the existing landscape and potential obstacles, this research contributes to the further development and implementation of FedML in privacy-critical scenarios.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Representation-Learning-for-Time-Series-A-Review"><a href="#Unsupervised-Representation-Learning-for-Time-Series-A-Review" class="headerlink" title="Unsupervised Representation Learning for Time Series: A Review"></a>Unsupervised Representation Learning for Time Series: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01578">http://arxiv.org/abs/2308.01578</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mqwfrog/ults">https://github.com/mqwfrog/ults</a></li>
<li>paper_authors: Qianwen Meng, Hangwei Qian, Yong Liu, Yonghui Xu, Zhiqi Shen, Lizhen Cui</li>
<li>for: 本研究旨在系统性地研究无监督表示学习方法的应用于时间序列数据，以掌握无需标注的特征表示。</li>
<li>methods: 本研究使用了现有的各种无监督表示学习方法，包括自适应表示学习、异常点检测、矩阵因子分解等。</li>
<li>results: 研究发现，使用contrastive learning方法可以在9个真实世界数据集上实现最高的表示学习效果，并且提出了一些实践考虑因素和未来研究挑战。<details>
<summary>Abstract</summary>
Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate_language: zh-CNUnsupervised representation learning方法 aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. 时序数据的特殊特点和缺乏视觉提示，使得时序数据的注解瓶颈非常大，因此Unsupervised representation learning是非常重要的。在过去几年，Unsupervised representation learning技术在不同领域得到了快速发展。然而，对时序数据Unsupervised representation learning的系统性分析仍然缺乏。为了填补这一空白，我们进行了 comprehensive literature review of existing rapidly evolving Unsupervised representation learning approaches for time series。此外，我们还开发了一个标准化和快速实现的库，名为ULTS（i.e., Unsupervised Learning for Time Series），以便对不同模型进行快速实现和统一评估。通过ULTS，我们employmetricamente评估了现状最佳的方法，特别是在不同的 datasets上 rapidly evolving contrastive learning方法。我们还讨论了实践中的Considerations和未来研究中的开放问题，以便促进未来在这个领域的研究。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Training-of-Denoising-Diffusion-Model-Using-Dual-Discriminators-for-High-Fidelity-Multi-Speaker-TTS"><a href="#Adversarial-Training-of-Denoising-Diffusion-Model-Using-Dual-Discriminators-for-High-Fidelity-Multi-Speaker-TTS" class="headerlink" title="Adversarial Training of Denoising Diffusion Model Using Dual Discriminators for High-Fidelity Multi-Speaker TTS"></a>Adversarial Training of Denoising Diffusion Model Using Dual Discriminators for High-Fidelity Multi-Speaker TTS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01573">http://arxiv.org/abs/2308.01573</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/komyeongjin/specdiff-gan">https://github.com/komyeongjin/specdiff-gan</a></li>
<li>paper_authors: Myeongjin Ko, Yong-Hoon Choi</li>
<li>for: 提高DiffGAN-TTS模型的speech质量和生成速度</li>
<li>methods: 采用两个识别器：扩散识别器和spectrogram识别器，以学习扩散过程的分布和生成数据的分布</li>
<li>results: 比较latest state-of-the-art模型FastSpeech2和DiffGAN-TTS，在不同的评价指标上显示更高的性能，包括SSIM、MCD、F0 RMSE、STOI、PESQ以及主观评价MOS。<details>
<summary>Abstract</summary>
The diffusion model is capable of generating high-quality data through a probabilistic approach. However, it suffers from the drawback of slow generation speed due to the requirement of a large number of time steps. To address this limitation, recent models such as denoising diffusion implicit models (DDIM) focus on generating samples without directly modeling the probability distribution, while models like denoising diffusion generative adversarial networks (GAN) combine diffusion processes with GANs. In the field of speech synthesis, a recent diffusion speech synthesis model called DiffGAN-TTS, utilizing the structure of GANs, has been introduced and demonstrates superior performance in both speech quality and generation speed. In this paper, to further enhance the performance of DiffGAN-TTS, we propose a speech synthesis model with two discriminators: a diffusion discriminator for learning the distribution of the reverse process and a spectrogram discriminator for learning the distribution of the generated data. Objective metrics such as structural similarity index measure (SSIM), mel-cepstral distortion (MCD), F0 root mean squared error (F0 RMSE), short-time objective intelligibility (STOI), perceptual evaluation of speech quality (PESQ), as well as subjective metrics like mean opinion score (MOS), are used to evaluate the performance of the proposed model. The evaluation results show that the proposed model outperforms recent state-of-the-art models such as FastSpeech2 and DiffGAN-TTS in various metrics. Our implementation and audio samples are located on GitHub.
</details>
<details>
<summary>摘要</summary>
Diffusion模型可以生成高质量数据通过概率方法。然而，它受限于需要大量时间步骤，导致生成速度慢。为解决这个限制，最近的模型如降噪扩散权重模型（DDIM）和降噪扩散生成对抗网络（GAN）等都在生成样本不直接模型概率分布。在语音生成领域，一种最近的扩散语音生成模型叫做DiffGAN-TTS，利用了GAN的结构，已经被引入并显示出优于现有模型的语音质量和生成速度。在这篇论文中，我们提议一种语音生成模型，其中包括两个识别器：一个扩散识别器用于学习逆过程的分布，一个spectrogram识别器用于学习生成数据的分布。对象度量如构造相似度指数（SSIM）、mel-cepstral损害（MCD）、F0根圆满平均误差（F0 RMSE）、短时对象智能度（STOI）、语音质量评价（PESQ）以及主观度量如主观评分（MOS）等都用于评估提议模型的性能。评估结果表明，提议模型超过了最近的状态艺模型如FastSpeech2和DiffGAN-TTS在各个度量上。我们的实现和音频样本位于GitHub。
</details></li>
</ul>
<hr>
<h2 id="Fast-Slate-Policy-Optimization-Going-Beyond-Plackett-Luce"><a href="#Fast-Slate-Policy-Optimization-Going-Beyond-Plackett-Luce" class="headerlink" title="Fast Slate Policy Optimization: Going Beyond Plackett-Luce"></a>Fast Slate Policy Optimization: Going Beyond Plackett-Luce</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01566">http://arxiv.org/abs/2308.01566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Otmane Sakhi, David Rohde, Nicolas Chopin</li>
<li>for: 大规模机器学习系统中的返回牌块技术在搜索、信息检索和推荐系统中发挥着越来越重要的作用。</li>
<li>methods: 该文章提出了一种基于策略优化框架的方法来优化大规模决策系统，使其能够快速完成在线查询。该方法基于一种新的决策函数relaxation，从而实现了一种简单 yet efficient的学习算法，可涵盖巨大的动作空间。</li>
<li>results: 文章对比了使用常见的Plackett-Luce策略类与该方法，并在动作空间规模达万万的问题上进行了比较，证明了该方法的有效性。<details>
<summary>Abstract</summary>
An increasingly important building block of large scale machine learning systems is based on returning slates; an ordered lists of items given a query. Applications of this technology include: search, information retrieval and recommender systems. When the action space is large, decision systems are restricted to a particular structure to complete online queries quickly. This paper addresses the optimization of these large scale decision systems given an arbitrary reward function. We cast this learning problem in a policy optimization framework and propose a new class of policies, born from a novel relaxation of decision functions. This results in a simple, yet efficient learning algorithm that scales to massive action spaces. We compare our method to the commonly adopted Plackett-Luce policy class and demonstrate the effectiveness of our approach on problems with action space sizes in the order of millions.
</details>
<details>
<summary>摘要</summary>
越来越重要的大规模机器学习系统建构件是基于返回板，即查询时返回的有序列表。这些应用包括搜索、信息检索和推荐系统。当动作空间较大时，决策系统会受到特定结构的限制，以快速完成在线查询。这篇论文通过对大规模决策系统优化问题进行政策优化框架，提出了一种新的政策类型。这种新政策类型由一种新的决策函数 relaxation 得到，从而得到了一个简单 yet efficient 的学习算法，可扩展到巨大的动作空间。我们与普遍采用的沃尔特-劳伯策略类比较，并在动作空间规模为百万的问题上表现了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Federated-Learning-in-Wireless-Networks-Pruning-Tackles-Bandwidth-Scarcity-and-System-Heterogeneity"><a href="#Hierarchical-Federated-Learning-in-Wireless-Networks-Pruning-Tackles-Bandwidth-Scarcity-and-System-Heterogeneity" class="headerlink" title="Hierarchical Federated Learning in Wireless Networks: Pruning Tackles Bandwidth Scarcity and System Heterogeneity"></a>Hierarchical Federated Learning in Wireless Networks: Pruning Tackles Bandwidth Scarcity and System Heterogeneity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01562">http://arxiv.org/abs/2308.01562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Ferdous Pervej, Richeng Jin, Huaiyu Dai</li>
<li>for: 本研究旨在提出一种基于层次分解的贝叶斯学习（PHFL）算法，以满足实际无线网络中端到端通信受限制和设备限制。</li>
<li>methods: 本研究使用模型剪除技术，并且jointly优化客户端的模型剪除比例、中央处理器频率和传输功率，以最小化控制项的抽象 bound 下的抽象 bound。</li>
<li>results: 通过广泛的 simulations，本研究证明了提出的 PHFL 算法在测试准确率、墙 clock 时间、能量消耗和带宽要求上的有效性。<details>
<summary>Abstract</summary>
While a practical wireless network has many tiers where end users do not directly communicate with the central server, the users' devices have limited computation and battery powers, and the serving base station (BS) has a fixed bandwidth. Owing to these practical constraints and system models, this paper leverages model pruning and proposes a pruning-enabled hierarchical federated learning (PHFL) in heterogeneous networks (HetNets). We first derive an upper bound of the convergence rate that clearly demonstrates the impact of the model pruning and wireless communications between the clients and the associated BS. Then we jointly optimize the model pruning ratio, central processing unit (CPU) frequency and transmission power of the clients in order to minimize the controllable terms of the convergence bound under strict delay and energy constraints. However, since the original problem is not convex, we perform successive convex approximation (SCA) and jointly optimize the parameters for the relaxed convex problem. Through extensive simulation, we validate the effectiveness of our proposed PHFL algorithm in terms of test accuracy, wall clock time, energy consumption and bandwidth requirement.
</details>
<details>
<summary>摘要</summary>
While a practical wireless network has many tiers where end users do not directly communicate with the central server, the users' devices have limited computation and battery powers, and the serving base station (BS) has a fixed bandwidth. Owing to these practical constraints and system models, this paper leverages model pruning and proposes a pruning-enabled hierarchical federated learning (PHFL) in heterogeneous networks (HetNets). We first derive an upper bound of the convergence rate that clearly demonstrates the impact of the model pruning and wireless communications between the clients and the associated BS. Then we jointly optimize the model pruning ratio, central processing unit (CPU) frequency and transmission power of the clients in order to minimize the controllable terms of the convergence bound under strict delay and energy constraints. However, since the original problem is not convex, we perform successive convex approximation (SCA) and jointly optimize the parameters for the relaxed convex problem. Through extensive simulation, we validate the effectiveness of our proposed PHFL algorithm in terms of test accuracy, wall clock time, energy consumption and bandwidth requirement.Here is the translation in Traditional Chinese:而在实际无线网络中，有多层次的端用户不直接与中央服务器通信，用户的设备有限的计算和电池能力，并且服务基站（BS）有固定的带宽。由于这些实际限制和系统模型，这篇文章利用模型剔除和提议了一个剔除enabled的 Hierarchical Federated Learning（PHFL）在不同类型的网络（HetNets）中。我们首先 derive了各种模型剔除的上限 bound，该 bound 清楚地显示了剔除和无线通信 между客户端和相关的 BS 的影响。然后，我们共同优化模型剔除比例、中央处理器（CPU）频率和客户端的传输功率，以最小化控制性 bound 的调整下限，以满足严格的延迟和能源限制。然而，由于原始问题不是凸变数，我们通过Successive Convex Approximation（SCA）来优化parameters，并对它们进行松动的优化。通过广泛的Simulation，我们证明了我们提议的 PHFL 算法在测试准确度、壁时、能源消耗和带宽需求方面的有效性。
</details></li>
</ul>
<hr>
<h2 id="Motion-Planning-Diffusion-Learning-and-Planning-of-Robot-Motions-with-Diffusion-Models"><a href="#Motion-Planning-Diffusion-Learning-and-Planning-of-Robot-Motions-with-Diffusion-Models" class="headerlink" title="Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models"></a>Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01557">http://arxiv.org/abs/2308.01557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joao Carvalho, An T. Le, Mark Baierl, Dorothea Koert, Jan Peters</li>
<li>For: The paper is written for researchers and practitioners in the field of robot motion planning and optimization, particularly those interested in using learning priors to accelerate the planning process.* Methods: The paper proposes using diffusion models as priors for motion planning, which allows for sampling directly from the posterior trajectory distribution conditioned on task goals. The authors also leverage the inverse denoising process of diffusion models to effectively encode data multimodality in high-dimensional settings.* Results: The paper demonstrates the efficacy of the proposed method, Motion Planning Diffusion, through experiments in simulated planar robot and 7-dof robot arm manipulator environments. The results show that diffusion models are strong priors for encoding high-dimensional trajectory distributions of robot motions, and the method is able to generalize well to previously unseen obstacles.Here is the same information in Simplified Chinese text:* For: 本文是为机器人运动规划和优化领域的研究人员和实践者编写的，特别是关心使用学习假设加速运动规划的人。* Methods: 本文提出使用扩散模型作为运动规划的假设，可以直接从 posterior 运动规划分布中采样任务目标条件下的轨迹。作者们还利用扩散模型的逆噪处理机制来有效地编码高维数据多模性。* Results: 本文通过在平面机器人和7度OF机械臂环境中的 simulations 来证明提出的方法 Motion Planning Diffusion 的效果，结果表明扩散模型是高维轨迹分布的强大假设，并能够在未经见过障碍物的环境中具有普适性。<details>
<summary>Abstract</summary>
Learning priors on trajectory distributions can help accelerate robot motion planning optimization. Given previously successful plans, learning trajectory generative models as priors for a new planning problem is highly desirable. Prior works propose several ways on utilizing this prior to bootstrapping the motion planning problem. Either sampling the prior for initializations or using the prior distribution in a maximum-a-posterior formulation for trajectory optimization. In this work, we propose learning diffusion models as priors. We then can sample directly from the posterior trajectory distribution conditioned on task goals, by leveraging the inverse denoising process of diffusion models. Furthermore, diffusion has been recently shown to effectively encode data multimodality in high-dimensional settings, which is particularly well-suited for large trajectory dataset. To demonstrate our method efficacy, we compare our proposed method - Motion Planning Diffusion - against several baselines in simulated planar robot and 7-dof robot arm manipulator environments. To assess the generalization capabilities of our method, we test it in environments with previously unseen obstacles. Our experiments show that diffusion models are strong priors to encode high-dimensional trajectory distributions of robot motions.
</details>
<details>
<summary>摘要</summary>
学习轨迹分布可以帮助加速机器人运动规划优化。给定先前成功的计划，学习轨迹生成模型作为优化问题的先前知识是非常有优势。先前的工作提出了使用这种先前知识来启动运动规划问题的多种方法。可以从先前知识中采样，或者使用先前知识的分布来形式化最大 posterior 方法来优化轨迹。在这个工作中，我们提议使用扩散模型来学习先前知识。我们可以通过扩散模型的逆减针对任务目标来直接从 posterior 轨迹分布中采样，并且利用扩散模型对高维数据的编码能力来更好地处理大规模轨迹数据。为了证明我们的方法效果，我们将比较我们的方法（运动规划扩散）与多个基eline在 simulate 平面机器人和7度OF机械臂环境中。为了评估我们的方法泛化能力，我们在未看过障碍物的环境中进行测试。我们的实验表明，扩散模型是高维轨迹分布的机器人运动优化中强大的先前知识。
</details></li>
</ul>
<hr>
<h2 id="InterAct-Exploring-the-Potentials-of-ChatGPT-as-a-Cooperative-Agent"><a href="#InterAct-Exploring-the-Potentials-of-ChatGPT-as-a-Cooperative-Agent" class="headerlink" title="InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent"></a>InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01552">http://arxiv.org/abs/2308.01552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Po-Lin Chen, Cheng-Shang Chang</li>
<li>for: 本研究 paper 探讨 OpenAI 的 ChatGPT 在具有体系的代理系统中的整合，评估其对交互决策标准的影响。</li>
<li>methods: 我们采用了多种提示，将 ChatGPT 分配到不同的角色中，如检查员和排序员，然后与原始语言模型结合。</li>
<li>results: 我们的研究显示，在 AlfWorld 中，包含 6 个不同任务的模拟家庭环境中，ChatGPT 的成功率达到 98%，强调了提示工程的重要性，从而为任务规划预测开辟了新的可能性。<details>
<summary>Abstract</summary>
This research paper delves into the integration of OpenAI's ChatGPT into embodied agent systems, evaluating its influence on interactive decision-making benchmark. Drawing a parallel to the concept of people assuming roles according to their unique strengths, we introduce InterAct. In this approach, we feed ChatGPT with varied prompts, assigning it a numerous roles like a checker and a sorter, then integrating them with the original language model. Our research shows a remarkable success rate of 98% in AlfWorld, which consists of 6 different tasks in a simulated household environment, emphasizing the significance of proficient prompt engineering. The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "OpenAI's ChatGPT" is translated as "OpenAI的ChatGPT" (OpenAI的chatGPT)* "embodied agent systems" is translated as "实体式代理系统" (shíwù yìjīng yìjīng zhìxīng)* "interactive decision-making benchmark" is translated as "互动决策指标" (interactive decision-making indicator)* "AlfWorld" is translated as "AlfWorld" (AlfWorld)* "simulated household environment" is translated as "模拟家庭环境" (móxíng jiāgōng yuánjīng)* "task planning" is translated as "任务规划" (task planning)
</details></li>
</ul>
<hr>
<h2 id="MusicLDM-Enhancing-Novelty-in-Text-to-Music-Generation-Using-Beat-Synchronous-Mixup-Strategies"><a href="#MusicLDM-Enhancing-Novelty-in-Text-to-Music-Generation-Using-Beat-Synchronous-Mixup-Strategies" class="headerlink" title="MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies"></a>MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01546">http://arxiv.org/abs/2308.01546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Chen, Yusong Wu, Haohe Liu, Marianna Nezhurina, Taylor Berg-Kirkpatrick, Shlomo Dubnov</li>
<li>for: 这个论文的目的是提出一种基于稳定扩散模型的文本到音乐生成模型（MusicLDM），以便在音乐领域进行跨模态生成任务。</li>
<li>methods: 该模型使用了稳定扩散和音乐LDM架构，并通过重新训练CLAP预训练模型和Hifi-GAN vocoder来适应音乐领域。此外，该模型还使用了 beat tracking 模型和两种不同的mixup策略来进行数据扩展和避免抄袭。</li>
<li>results: 根据新定义的CLAP分数评价指标，该模型和mixup策略可以提高生成的音乐质量和新颖性，同时仍保持与输入文本的对应性。<details>
<summary>Abstract</summary>
Diffusion models have shown promising results in cross-modal generation tasks, including text-to-image and text-to-audio generation. However, generating music, as a special type of audio, presents unique challenges due to limited availability of music data and sensitive issues related to copyright and plagiarism. In this paper, to tackle these challenges, we first construct a state-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion and AudioLDM architectures to the music domain. We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples. Then, to address the limitations of training data and to avoid plagiarism, we leverage a beat tracking model and propose two different mixup strategies for data augmentation: beat-synchronous audio mixup and beat-synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively. Such mixup strategies encourage the model to interpolate between musical training samples and generate new music within the convex hull of the training data, making the generated music more diverse while still staying faithful to the corresponding style. In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.
</details>
<details>
<summary>摘要</summary>
Diffusion models have shown promising results in cross-modal generation tasks, including text-to-image and text-to-audio generation. However, generating music, as a special type of audio, presents unique challenges due to limited availability of music data and sensitive issues related to copyright and plagiarism. In this paper, to tackle these challenges, we first construct a state-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion and AudioLDM architectures to the music domain. We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples. Then, to address the limitations of training data and to avoid plagiarism, we leverage a beat tracking model and propose two different mixup strategies for data augmentation: beat-synchronous audio mixup and beat-synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively. Such mixup strategies encourage the model to interpolate between musical training samples and generate new music within the convex hull of the training data, making the generated music more diverse while still staying faithful to the corresponding style. In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.
</details></li>
</ul>
<hr>
<h2 id="Lode-Enhancer-Level-Co-creation-Through-Scaling"><a href="#Lode-Enhancer-Level-Co-creation-Through-Scaling" class="headerlink" title="Lode Enhancer: Level Co-creation Through Scaling"></a>Lode Enhancer: Level Co-creation Through Scaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01543">http://arxiv.org/abs/2308.01543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debosmita Bhaumik, Julian Togelius, Georgios N. Yannakakis, Ahmed Khalifa</li>
<li>for: 用AI进行2D游戏等级设计协助工具</li>
<li>methods: 使用深度神经网络进行等级升采样、编辑和扩展</li>
<li>results: 通过对游戏等级进行升采样和编辑，设计者可以在不同的分辨率下创建和编辑等级，并且神经网络可以学习增加缺失的特征。<details>
<summary>Abstract</summary>
We explore AI-powered upscaling as a design assistance tool in the context of creating 2D game levels. Deep neural networks are used to upscale artificially downscaled patches of levels from the puzzle platformer game Lode Runner. The trained networks are incorporated into a web-based editor, where the user can create and edit levels at three different levels of resolution: 4x4, 8x8, and 16x16. An edit at any resolution instantly transfers to the other resolutions. As upscaling requires inventing features that might not be present at lower resolutions, we train neural networks to reproduce these features. We introduce a neural network architecture that is capable of not only learning upscaling but also giving higher priority to less frequent tiles. To investigate the potential of this tool and guide further development, we conduct a qualitative study with 3 designers to understand how they use it. Designers enjoyed co-designing with the tool, liked its underlying concept, and provided feedback for further improvement.
</details>
<details>
<summary>摘要</summary>
我们探索使用人工智能进行缩放作为游戏等级设计工具，在创建2D游戏等级时。我们使用深度神经网络来缩放人工减小的等级补丁，来自游戏排版平台游戏“卢德运动”。我们在网页编辑器中 integrate 了训练的神经网络，用户可以在不同的分辨率下创建和编辑等级：4x4、8x8和16x16。任何修改都会同步到其他分辨率上。由于缩放需要创造不存在低分辨率下的特征，我们训练神经网络来复制这些特征。我们介绍了一种神经网络架构，可以不仅学习缩放，还可以增加较少的瓷砖优先级。为了了解这工具的潜在力量和进一步发展，我们进行了3名设计师的质量调查，了解他们如何使用这工具，他们对这工具的概念和反馈。
</details></li>
</ul>
<hr>
<h2 id="MFIM-Megapixel-Facial-Identity-Manipulation"><a href="#MFIM-Megapixel-Facial-Identity-Manipulation" class="headerlink" title="MFIM: Megapixel Facial Identity Manipulation"></a>MFIM: Megapixel Facial Identity Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01536">http://arxiv.org/abs/2308.01536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanghyeon Na</li>
<li>for: 本研究的目的是提出一种新的面部换 Identity 框架，以实现高质量的面部换 Image 生成和有效地改变面部特征。</li>
<li>methods: 我们的模型基于 StyleGAN 的 GAN-inversion 技术，并使用 3DMM 来semantically 捕捉多种面部特征。我们对模型进行了严格的设计和训练，以确保模型可以生成高质量的面部换 Image。</li>
<li>results: 我们通过了广泛的实验，证明了我们的模型可以达到领先的性能水平，并且可以根据用户的需求进行自定义。我们还提出了一种新的操作called ID mixing，可以创造出新的 Identity by semantically mixing 多个人的 Identities。<details>
<summary>Abstract</summary>
Face swapping is a task that changes a facial identity of a given image to that of another person. In this work, we propose a novel face-swapping framework called Megapixel Facial Identity Manipulation (MFIM). The face-swapping model should achieve two goals. First, it should be able to generate a high-quality image. We argue that a model which is proficient in generating a megapixel image can achieve this goal. However, generating a megapixel image is generally difficult without careful model design. Therefore, our model exploits pretrained StyleGAN in the manner of GAN-inversion to effectively generate a megapixel image. Second, it should be able to effectively transform the identity of a given image. Specifically, it should be able to actively transform ID attributes (e.g., face shape and eyes) of a given image into those of another person, while preserving ID-irrelevant attributes (e.g., pose and expression). To achieve this goal, we exploit 3DMM that can capture various facial attributes. Specifically, we explicitly supervise our model to generate a face-swapped image with the desirable attributes using 3DMM. We show that our model achieves state-of-the-art performance through extensive experiments. Furthermore, we propose a new operation called ID mixing, which creates a new identity by semantically mixing the identities of several people. It allows the user to customize the new identity.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>人脸替换是一项任务，替换给定图像中的人脸为另一个人脸。在这项工作中，我们提出了一种新的人脸替换框架，称为兆像人脸身份修饰（MFIM）。人脸替换模型应该完成两个目标：首先，生成高质量图像；其次，有效地转换给定图像中的人脸身份特征（如脸形和眼睛）到另一个人脸身份特征，保留不相关的人脸特征（如姿势和表情）。为达到这个目标，我们利用了3DMM，可以捕捉各种人脸特征。具体来说，我们明确地监督我们的模型生成一个人脸替换图像，拥有愿景的特征。我们展示了我们的模型在各种实验中达到了状态艺术性的表现。此外，我们还提出了一种新的操作，即ID混合，可以创造一个新的身份，通过semantic Mixing（semantic混合）几个人脸的身份。这允许用户自定义新的身份。
</details></li>
</ul>
<hr>
<h2 id="Food-Classification-using-Joint-Representation-of-Visual-and-Textual-Data"><a href="#Food-Classification-using-Joint-Representation-of-Visual-and-Textual-Data" class="headerlink" title="Food Classification using Joint Representation of Visual and Textual Data"></a>Food Classification using Joint Representation of Visual and Textual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02562">http://arxiv.org/abs/2308.02562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Mittal, Puneet Goyal, Joohi Chauhan</li>
<li>for: 这个研究旨在提出一个多 modal 分类框架，用于健康领域的食物分类。</li>
<li>methods: 提案的网络使用 Modified EfficientNet 和 Mish 活化函数进行图像分类，并使用传统的 BERT 变数架构进行文本分类。</li>
<li>results: 实验结果显示，提案的网络在大量的 open-source 数据集 UPMC Food-101 上表现出色，与其他方法比较，获得了11.57% 和 6.34% 的准确率优势，图像和文本分类方面。<details>
<summary>Abstract</summary>
Food classification is an important task in health care. In this work, we propose a multimodal classification framework that uses the modified version of EfficientNet with the Mish activation function for image classification, and the traditional BERT transformer-based network is used for text classification. The proposed network and the other state-of-the-art methods are evaluated on a large open-source dataset, UPMC Food-101. The experimental results show that the proposed network outperforms the other methods, a significant difference of 11.57% and 6.34% in accuracy is observed for image and text classification, respectively, when compared with the second-best performing method. We also compared the performance in terms of accuracy, precision, and recall for text classification using both machine learning and deep learning-based models. The comparative analysis from the prediction results of both images and text demonstrated the efficiency and robustness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
食品分类是医疗保健中的重要任务。在这项工作中，我们提出了一种多模态分类框架，使用修改后的EfficientNet和Mish激活函数进行图像分类，并使用传统的BERT变换网络进行文本分类。我们的提议网络和其他状态arct对比的方法在大型开源数据集UPMC Food-101上进行了评估。实验结果表明，我们的提议网络在图像和文本分类方面的准确率比其他方法高出11.57%和6.34%，与第二高分类方法相比。我们还对文本分类方面的准确率、精度和准确率进行了比较分析，并通过图像和文本预测结果的比较分析，证明了我们的方法的高效和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Circumventing-Concept-Erasure-Methods-For-Text-to-Image-Generative-Models"><a href="#Circumventing-Concept-Erasure-Methods-For-Text-to-Image-Generative-Models" class="headerlink" title="Circumventing Concept Erasure Methods For Text-to-Image Generative Models"></a>Circumventing Concept Erasure Methods For Text-to-Image Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01508">http://arxiv.org/abs/2308.01508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nyu-dice-lab/circumventing-concept-erasure">https://github.com/nyu-dice-lab/circumventing-concept-erasure</a></li>
<li>paper_authors: Minh Pham, Kelly O. Marshall, Chinmay Hegde</li>
<li>for: 本研究探讨了五种最新的概念除除法，以证明这些方法无法完全除除目标概念。</li>
<li>methods: 研究人员使用特殊的学习word embedding来检测和恢复被sanitized模型中的概念。</li>
<li>results: 结果表明这些post hoc概念除法方法不稳定，不适用于AI安全。<details>
<summary>Abstract</summary>
Text-to-image generative models can produce photo-realistic images for an extremely broad range of concepts, and their usage has proliferated widely among the general public. On the flip side, these models have numerous drawbacks, including their potential to generate images featuring sexually explicit content, mirror artistic styles without permission, or even hallucinate (or deepfake) the likenesses of celebrities. Consequently, various methods have been proposed in order to "erase" sensitive concepts from text-to-image models. In this work, we examine five recently proposed concept erasure methods, and show that targeted concepts are not fully excised from any of these methods. Specifically, we leverage the existence of special learned word embeddings that can retrieve "erased" concepts from the sanitized models with no alterations to their weights. Our results highlight the brittleness of post hoc concept erasure methods, and call into question their use in the algorithmic toolkit for AI safety.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Local-Global-Temporal-Fusion-Network-with-an-Attention-Mechanism-for-Multiple-and-Multiclass-Arrhythmia-Classification"><a href="#Local-Global-Temporal-Fusion-Network-with-an-Attention-Mechanism-for-Multiple-and-Multiclass-Arrhythmia-Classification" class="headerlink" title="Local-Global Temporal Fusion Network with an Attention Mechanism for Multiple and Multiclass Arrhythmia Classification"></a>Local-Global Temporal Fusion Network with an Attention Mechanism for Multiple and Multiclass Arrhythmia Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02416">http://arxiv.org/abs/2308.02416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Kwan Kim, Minji Lee, Kunwook Jo, Hee Seok Song, Seong-Whan Lee<br>for:The paper aims to develop a framework for arrhythmia detection and classification with a constrained input length, which can accurately recognize arrhythmias and calculate their occurrence times.methods:The proposed method consists of local temporal information extraction, global pattern extraction, and local-global information fusion with attention. The method utilizes a combination of local and global features to capture the dynamics of arrhythmias and achieve accurate detection and classification.results:The proposed method was evaluated on the MIT-BIH arrhythmia database and MIT-BIH atrial fibrillation database, and the results showed superior performance compared to state-of-the-art models. The method was also tested on a different database and achieved superior performance, demonstrating its generalization ability.<details>
<summary>Abstract</summary>
Clinical decision support systems (CDSSs) have been widely utilized to support the decisions made by cardiologists when detecting and classifying arrhythmia from electrocardiograms (ECGs). However, forming a CDSS for the arrhythmia classification task is challenging due to the varying lengths of arrhythmias. Although the onset time of arrhythmia varies, previously developed methods have not considered such conditions. Thus, we propose a framework that consists of (i) local temporal information extraction, (ii) global pattern extraction, and (iii) local-global information fusion with attention to perform arrhythmia detection and classification with a constrained input length. The 10-class and 4-class performances of our approach were assessed by detecting the onset and offset of arrhythmia as an episode and the duration of arrhythmia based on the MIT-BIH arrhythmia database (MITDB) and MIT-BIH atrial fibrillation database (AFDB), respectively. The results were statistically superior to those achieved by the comparison models. To check the generalization ability of the proposed method, an AFDB-trained model was tested on the MITDB, and superior performance was attained compared with that of a state-of-the-art model. The proposed method can capture local-global information and dynamics without incurring information losses. Therefore, arrhythmias can be recognized more accurately, and their occurrence times can be calculated; thus, the clinical field can create more accurate treatment plans by using the proposed method.
</details>
<details>
<summary>摘要</summary>
临床决策支持系统（CDSS）已广泛应用于卡地理学家在电cardiogram（ECG）中检测和分类 irregular heartbeat。然而，构建一个CDSS用于 irregular heartbeat 分类任务是困难的，因为irregular heartbeat的持续时间各不相同。 although the onset time of irregular heartbeat varies, previously developed methods have not considered such conditions. Therefore, we propose a framework that consists of (i) local temporal information extraction, (ii) global pattern extraction, and (iii) local-global information fusion with attention to perform irregular heartbeat detection and classification with a constrained input length.我们使用 MIT-BIH arrhythmia 数据库（MITDB）和 MIT-BIH atrial fibrillation 数据库（AFDB）来评估我们的方法。结果表明，我们的方法在10类和4类任务中表现出了 statistically superior 的结果，比较于比较模型。为了检验我们的方法的通用能力，我们使用 AFDB 训练的模型在 MITDB 上进行测试，并取得了比较于一个现有模型的superior 性能。我们的方法可以捕捉local-global信息和动态，而不会导致信息损失。因此，irregular heartbeat可以更准确地被识别，并且其出现时间可以被计算出来。因此，临床领域可以通过使用我们的方法创建更加准确的治疗计划。
</details></li>
</ul>
<hr>
<h2 id="Online-Multi-Task-Learning-with-Recursive-Least-Squares-and-Recursive-Kernel-Methods"><a href="#Online-Multi-Task-Learning-with-Recursive-Least-Squares-and-Recursive-Kernel-Methods" class="headerlink" title="Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods"></a>Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01938">http://arxiv.org/abs/2308.01938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriel R. Lencione, Fernando J. Von Zuben</li>
<li>for: 这个论文提出了两种新的在线多任务学习（MTL）回归问题的方法。</li>
<li>methods: 我们使用高性能的图形基于MTL形式，并开发了其归纳版本，基于Weighted Recursive Least Squares（WRLS）和在线稀疏最小二乘支持向量回归（OSLSSVR）。</li>
<li>results: 我们使用任务堆叠变换，展示了一个包含多个任务关系的矩阵，并将其 Structural information embodied于MT-WRLS方法的初始化过程中，或MT-OSLSSVR中的多任务核函数中。相比现有文献，我们实现了精确和近似的循环回归，具有quadratic per-instance cost的纬度。在一个实际的风速预测案例中，我们比较了我们的在线MTL方法与其他竞争者，并证明了我们的两种提案方法具有显著的性能提升。<details>
<summary>Abstract</summary>
This paper introduces two novel approaches for Online Multi-Task Learning (MTL) Regression Problems. We employ a high performance graph-based MTL formulation and develop its recursive versions based on the Weighted Recursive Least Squares (WRLS) and the Online Sparse Least Squares Support Vector Regression (OSLSSVR). Adopting task-stacking transformations, we demonstrate the existence of a single matrix incorporating the relationship of multiple tasks and providing structural information to be embodied by the MT-WRLS method in its initialization procedure and by the MT-OSLSSVR in its multi-task kernel function. Contrasting the existing literature, which is mostly based on Online Gradient Descent (OGD) or cubic inexact approaches, we achieve exact and approximate recursions with quadratic per-instance cost on the dimension of the input space (MT-WRLS) or on the size of the dictionary of instances (MT-OSLSSVR). We compare our online MTL methods to other contenders in a real-world wind speed forecasting case study, evidencing the significant gain in performance of both proposed approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Minimax-Optimal-Q-Learning-with-Nearest-Neighbors"><a href="#Minimax-Optimal-Q-Learning-with-Nearest-Neighbors" class="headerlink" title="Minimax Optimal $Q$ Learning with Nearest Neighbors"></a>Minimax Optimal $Q$ Learning with Nearest Neighbors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01490">http://arxiv.org/abs/2308.01490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Puning Zhao, Lifeng Lai</li>
<li>for: This paper proposes two new $Q$ learning methods to improve the convergence rate of estimated $Q$ functions in continuous state spaces.</li>
<li>methods: The proposed methods use a direct nearest neighbor approach instead of the kernel nearest neighbor approach used in (Shah and Xie, 2018), which significantly improves the convergence rate and time complexity in high-dimensional state spaces.</li>
<li>results: Both offline and online methods are minimax rate optimal, meaning that they achieve the optimal convergence rate of $\tilde{O}(T^{-1&#x2F;(d+2)})$ in high-dimensional state spaces.<details>
<summary>Abstract</summary>
$Q$ learning is a popular model free reinforcement learning method. Most of existing works focus on analyzing $Q$ learning for finite state and action spaces. If the state space is continuous, then the original $Q$ learning method can not be directly used. A modification of the original $Q$ learning method was proposed in (Shah and Xie, 2018), which estimates $Q$ values with nearest neighbors. Such modification makes $Q$ learning suitable for continuous state space. (Shah and Xie, 2018) shows that the convergence rate of estimated $Q$ function is $\tilde{O}(T^{-1/(d+3)})$, which is slower than the minimax lower bound $\tilde{\Omega}(T^{-1/(d+2)})$, indicating that this method is not efficient. This paper proposes two new $Q$ learning methods to bridge the gap of convergence rates in (Shah and Xie, 2018), with one of them being offline, while the other is online. Despite that we still use nearest neighbor approach to estimate $Q$ function, the algorithms are crucially different from (Shah and Xie, 2018). In particular, we replace the kernel nearest neighbor in discretized region with a direct nearest neighbor approach. Consequently, our approach significantly improves the convergence rate. Moreover, the time complexity is also significantly improved in high dimensional state spaces. Our analysis shows that both offline and online methods are minimax rate optimal.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-neural-supersampling-on-a-novel-gaming-dataset"><a href="#Efficient-neural-supersampling-on-a-novel-gaming-dataset" class="headerlink" title="Efficient neural supersampling on a novel gaming dataset"></a>Efficient neural supersampling on a novel gaming dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01483">http://arxiv.org/abs/2308.01483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Mercier, Ruan Erasmus, Yashesh Savani, Manik Dhingra, Fatih Porikli, Guillaume Berger</li>
<li>for: 提高游戏视频的实时渲染环境，以提高分辨率、帧率和光学真实性。</li>
<li>methods: 使用神经网络算法进行聚合样本，提高supersampling的效率，并 introduce了一个新的数据集，包括auxiliary modalities如运动向量和深度，这些数据集可以用于衡量领域的进步和推进supersampling技术的前沿。</li>
<li>results: 与传统方法相比，该算法可以提高supersampling的效率4倍，保持同等准确性。新的数据集填补了现有数据集的缺失，可以作为衡量领域进步的 valuable resource。<details>
<summary>Abstract</summary>
Real-time rendering for video games has become increasingly challenging due to the need for higher resolutions, framerates and photorealism. Supersampling has emerged as an effective solution to address this challenge. Our work introduces a novel neural algorithm for supersampling rendered content that is 4 times more efficient than existing methods while maintaining the same level of accuracy. Additionally, we introduce a new dataset which provides auxiliary modalities such as motion vectors and depth generated using graphics rendering features like viewport jittering and mipmap biasing at different resolutions. We believe that this dataset fills a gap in the current dataset landscape and can serve as a valuable resource to help measure progress in the field and advance the state-of-the-art in super-resolution techniques for gaming content.
</details>
<details>
<summary>摘要</summary>
现代游戏实时渲染技术面临着高分辨率、高帧率和真实感等需求的挑战。聚合抽象技术已成为解决这些挑战的有效方法。我们的工作提出了一种新的神经网络算法，可以实现对游戏内容的聚合抽象，比现有方法高效4倍，同时保持同等准确性。此外，我们还提供了一个新的数据集，包括视频游戏中的运动向量和深度信息，这些信息是通过视窗摇摆和miplevel偏移等图形渲染特性生成的。我们认为这个数据集填补了当前数据领域的空白，可以作为评估进步和推动领域的state-of-the-art技术的 valuable resource。
</details></li>
</ul>
<hr>
<h2 id="Online-covariance-estimation-for-stochastic-gradient-descent-under-Markovian-sampling"><a href="#Online-covariance-estimation-for-stochastic-gradient-descent-under-Markovian-sampling" class="headerlink" title="Online covariance estimation for stochastic gradient descent under Markovian sampling"></a>Online covariance estimation for stochastic gradient descent under Markovian sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01481">http://arxiv.org/abs/2308.01481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhishek Roy, Krishnakumar Balasubramanian</li>
<li>For: The paper is written for understanding the convergence rate of the online overlapping batch-means covariance estimator for Stochastic Gradient Descent (SGD) under Markovian sampling.* Methods: The paper uses techniques such as the batch-means covariance estimator and state-dependent and state-independent Markovian sampling to analyze the convergence rate of SGD.* Results: The paper shows that the convergence rates of the covariance estimator are $O\big(\sqrt{d},n^{-1&#x2F;8}(\log n)^{1&#x2F;4}\big)$ and $O\big(\sqrt{d},n^{-1&#x2F;8}\big)$ under state-dependent and state-independent Markovian sampling, respectively, with $d$ representing dimensionality and $n$ denoting the number of observations or SGD iterations. These rates match the best-known convergence rate previously established for the independent and identically distributed ($\iid$) case. Additionally, the paper establishes the convergence rate for the first four moments of the $\ell_2$ norm of the error of SGD dynamics under state-dependent Markovian data.<details>
<summary>Abstract</summary>
We study the online overlapping batch-means covariance estimator for Stochastic Gradient Descent (SGD) under Markovian sampling. We show that the convergence rates of the covariance estimator are $O\big(\sqrt{d}\,n^{-1/8}(\log n)^{1/4}\big)$ and $O\big(\sqrt{d}\,n^{-1/8}\big)$ under state-dependent and state-independent Markovian sampling, respectively, with $d$ representing dimensionality and $n$ denoting the number of observations or SGD iterations. Remarkably, these rates match the best-known convergence rate previously established for the independent and identically distributed ($\iid$) case by \cite{zhu2021online}, up to logarithmic factors. Our analysis overcomes significant challenges that arise due to Markovian sampling, leading to the introduction of additional error terms and complex dependencies between the blocks of the batch-means covariance estimator. Moreover, we establish the convergence rate for the first four moments of the $\ell_2$ norm of the error of SGD dynamics under state-dependent Markovian data, which holds potential interest as an independent result. To validate our theoretical findings, we provide numerical illustrations to derive confidence intervals for SGD when training linear and logistic regression models under Markovian sampling. Additionally, we apply our approach to tackle the intriguing problem of strategic classification with logistic regression, where adversaries can adaptively modify features during the training process to increase their chances of being classified in a specific target class.
</details>
<details>
<summary>摘要</summary>
我们研究在Markovian sampling下的线上遮盾Batch-Means协方幂矩阵估计器，并证明其参数估计率为$O\big(\sqrt{d}\,n^{-1/8}(\log n)^{1/4}\big)$和$O\big(\sqrt{d}\,n^{-1/8}\big)$，具体来说，这两个率限分别适用于Markovian sampling下的状态相依和状态独立两种情况，其中$d$表示维度，$n$表示观察或SGD迭代次数。可以看到，这些率限与之前独立同分布($\iid$)情况下的最佳率限相匹配，仅受到logs因子的影响。我们的分析面临了由Markovian sampling带来的重要挑战，导致批量均值协方幂矩阵估计器中出现了额外的错误项和复杂的依赖关系。此外，我们还确定了SGD动态中第四个对应的内积项的测度，具体来说，这个结果可能具有独立的价值，作为一个独立的研究结果。在实践中，我们提供了数值示例，以 derivate SGD训练过程中的信任区间。此外，我们还应用了我们的方法，解决了具有挑战性的问题，例如在训练过程中，敌人可以随机修改特征，以增加他们被特定目标类别中的机会。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Machine-Learning-for-Discovery-Statistical-Challenges-Opportunities"><a href="#Interpretable-Machine-Learning-for-Discovery-Statistical-Challenges-Opportunities" class="headerlink" title="Interpretable Machine Learning for Discovery: Statistical Challenges &amp; Opportunities"></a>Interpretable Machine Learning for Discovery: Statistical Challenges &amp; Opportunities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01475">http://arxiv.org/abs/2308.01475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Genevera I. Allen, Luqin Gan, Lili Zheng</li>
<li>for: 本文主要探讨了可解解释机器学习（Interpretable Machine Learning）的应用，它们如何为我们提供人理解的结论和发现。</li>
<li>methods: 本文主要介绍了使用可解解释机器学习技术进行大数据处理、可视化和预测，以及如何通过这些技术来获得新的科学发现。</li>
<li>results: 本文详细介绍了使用可解解释机器学习技术进行supervised和unsupervised学习中的发现，以及如何验证这些发现的有效性和可靠性。<details>
<summary>Abstract</summary>
New technologies have led to vast troves of large and complex datasets across many scientific domains and industries. People routinely use machine learning techniques to not only process, visualize, and make predictions from this big data, but also to make data-driven discoveries. These discoveries are often made using Interpretable Machine Learning, or machine learning models and techniques that yield human understandable insights. In this paper, we discuss and review the field of interpretable machine learning, focusing especially on the techniques as they are often employed to generate new knowledge or make discoveries from large data sets. We outline the types of discoveries that can be made using Interpretable Machine Learning in both supervised and unsupervised settings. Additionally, we focus on the grand challenge of how to validate these discoveries in a data-driven manner, which promotes trust in machine learning systems and reproducibility in science. We discuss validation from both a practical perspective, reviewing approaches based on data-splitting and stability, as well as from a theoretical perspective, reviewing statistical results on model selection consistency and uncertainty quantification via statistical inference. Finally, we conclude by highlighting open challenges in using interpretable machine learning techniques to make discoveries, including gaps between theory and practice for validating data-driven-discoveries.
</details>
<details>
<summary>摘要</summary>
新技术导致科学领域和产业中大量复杂数据的出现，人们常用机器学习技术不仅处理、可见化和预测这些大数据，还用以获得数据驱动发现。这些发现通常使用可解释机器学习，即机器学习模型和技术，获得人类可理解的发现。在这篇论文中，我们讨论了可解释机器学习的场景，特别是在大数据集上使用这些技术进行新的发现。我们列举了在supervised和unsupervised Setting下使用可解释机器学习实现的发现类型。此外，我们关注了如何在数据驱动下验证这些发现，以便提高机器学习系统的信任和科学研究的重复性。我们从实践和理论两个角度来验证这些发现，包括数据分割和稳定性的方法，以及统计学结果的模型选择一致性和不确定性评估。最后，我们结束时强调了在使用可解释机器学习技术进行发现时存在的开放挑战，包括数据驱动发现的验证和理论与实践之间的差距。
</details></li>
</ul>
<hr>
<h2 id="Reverse-Stable-Diffusion-What-prompt-was-used-to-generate-this-image"><a href="#Reverse-Stable-Diffusion-What-prompt-was-used-to-generate-this-image" class="headerlink" title="Reverse Stable Diffusion: What prompt was used to generate this image?"></a>Reverse Stable Diffusion: What prompt was used to generate this image?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01472">http://arxiv.org/abs/2308.01472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, Mubarak Shah</li>
<li>for: 这篇论文的目的是提出一个新的文本描述预测任务，并使用不同的白盒和黑盒模型来解决这个任务。</li>
<li>methods: 本文使用了一个共同的预测和多 label 词汇分类目标函数，以生成改进的文本描述。此外，文本 також使用了一个课程学习程式和一个无监督领域对应 kernel 学习方法来进一步提高方法。</li>
<li>results: 本文的实验结果显示，使用 proposed 的学习框架可以在 Stable Diffusion 生成的图像上预测文本描述，并且在 white-box 模型上获得最高的改进。此外，文中还发现了一个有趣的发现：将 diffusion 模型直接用于文本与图像生成任务可以让模型生成更加适合的图像，对应于输入文本的描述。<details>
<summary>Abstract</summary>
Text-to-image diffusion models such as Stable Diffusion have recently attracted the interest of many researchers, and inverting the diffusion process can play an important role in better understanding the generative process and how to engineer prompts in order to obtain the desired images. To this end, we introduce the new task of predicting the text prompt given an image generated by a generative diffusion model. We combine a series of white-box and black-box models (with and without access to the weights of the diffusion network) to deal with the proposed task. We propose a novel learning framework comprising of a joint prompt regression and multi-label vocabulary classification objective that generates improved prompts. To further improve our method, we employ a curriculum learning procedure that promotes the learning of image-prompt pairs with lower labeling noise (i.e. that are better aligned), and an unsupervised domain-adaptive kernel learning method that uses the similarities between samples in the source and target domains as extra features. We conduct experiments on the DiffusionDB data set, predicting text prompts from images generated by Stable Diffusion. Our novel learning framework produces excellent results on the aforementioned task, yielding the highest gains when applied on the white-box model. In addition, we make an interesting discovery: training a diffusion model on the prompt generation task can make the model generate images that are much better aligned with the input prompts, when the model is directly reused for text-to-image generation.
</details>
<details>
<summary>摘要</summary>
文本到图像扩散模型，如稳定扩散，在最近吸引了许多研究者的关注，而逆扩散过程可以更好地理解生成过程并如何引入提示以获得所需的图像。为此，我们介绍了预测由生成扩散模型生成的图像中的文本提示的新任务。我们结合了白盒和黑盒模型（具有或无Diffusion网络的权重）来处理该任务。我们提出了一种新的学习框架，包括文本提示 regression和多标签词汇分类目标，可以生成改进的提示。为了进一步改进我们的方法，我们使用了课程学习程序，该程序将优先采用低噪音（即更好地对齐）的图像-提示对来学习。此外，我们还使用了无监督领域适应器，使用源和目标领域样本之间的相似性为额外特征。我们在DiffusionDB数据集上进行实验，预测由稳定扩散生成的图像中的文本提示。我们的新学习框架在该任务上获得了出色的结果，特别是在白盒模型上实现了最高的提升。此外，我们还发现了一个有趣的发现：在直接将扩散模型用于文本到图像生成任务的训练过程中，模型可以生成与输入提示更好地对齐的图像。
</details></li>
</ul>
<hr>
<h2 id="Implicit-Occupancy-Flow-Fields-for-Perception-and-Prediction-in-Self-Driving"><a href="#Implicit-Occupancy-Flow-Fields-for-Perception-and-Prediction-in-Self-Driving" class="headerlink" title="Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving"></a>Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01471">http://arxiv.org/abs/2308.01471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Agro, Quinlan Sykora, Sergio Casas, Raquel Urtasun</li>
<li>for: 本研究旨在开发一种能够同时捕捉围绕自动驾驶车辆（SDV）运行的环境和未来行为预测的方法。</li>
<li>methods: 我们的方法是一种混合了物体检测和未来行为预测的方法，通过一个单一神经网络来减少计算量，同时提高预测的准确性。</li>
<li>results: 我们的实验结果表明，我们的方法可以在城市和高速公路环境中比前状态OF THE ART表现出色，并且可以避免过度预测和计算资源浪费。更多信息可以查看我们的项目网站：<a target="_blank" rel="noopener" href="https://waabi.ai/research/implicito%E3%80%82">https://waabi.ai/research/implicito。</a><details>
<summary>Abstract</summary>
A self-driving vehicle (SDV) must be able to perceive its surroundings and predict the future behavior of other traffic participants. Existing works either perform object detection followed by trajectory forecasting of the detected objects, or predict dense occupancy and flow grids for the whole scene. The former poses a safety concern as the number of detections needs to be kept low for efficiency reasons, sacrificing object recall. The latter is computationally expensive due to the high-dimensionality of the output grid, and suffers from the limited receptive field inherent to fully convolutional networks. Furthermore, both approaches employ many computational resources predicting areas or objects that might never be queried by the motion planner. This motivates our unified approach to perception and future prediction that implicitly represents occupancy and flow over time with a single neural network. Our method avoids unnecessary computation, as it can be directly queried by the motion planner at continuous spatio-temporal locations. Moreover, we design an architecture that overcomes the limited receptive field of previous explicit occupancy prediction methods by adding an efficient yet effective global attention mechanism. Through extensive experiments in both urban and highway settings, we demonstrate that our implicit model outperforms the current state-of-the-art. For more information, visit the project website: https://waabi.ai/research/implicito.
</details>
<details>
<summary>摘要</summary>
一种自驾车（SDV）必须能够感知它所处的环境和预测其他交通参与者的未来行为。现有的方法分别执行物体探测然后预测检测到的物体的轨迹，或预测整个场景的稠密占用和流动Grid。前者存在安全隐患，因为需要保持检测数量低，以保证效率，同时牺牲物体回归率。后者因高维度输出网络而 computationally expensive，并且受到限制的受感网络的有限观察范围的影响。此外，两种方法都需要大量计算资源预测可能不会被动控制器询问的区域或物体。这种驱动我们的协调感知和未来预测方法，该方法可以直接被动控制器询问，并且避免了不必要的计算。此外，我们还设计了一种高效但有效的全局注意力机制，以超越过去的显式占用预测方法的有限观察范围。通过在城市和高速公路上进行了广泛的实验，我们证明了我们的隐式模型可以比现状之最。更多信息，请访问我们的项目网站：https://waabi.ai/research/implicito。
</details></li>
</ul>
<hr>
<h2 id="Training-Data-Protection-with-Compositional-Diffusion-Models"><a href="#Training-Data-Protection-with-Compositional-Diffusion-Models" class="headerlink" title="Training Data Protection with Compositional Diffusion Models"></a>Training Data Protection with Compositional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01937">http://arxiv.org/abs/2308.01937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Golatkar, Alessandro Achille, Ashwin Swaminathan, Stefano Soatto</li>
<li>for: 本研究旨在提出一种名为 compartmentalized diffusion models（CDM），可以在推理时将不同的扩散模型（或提示）组合在一起，以实现在所有数据 simultanously 训练的性能。</li>
<li>methods: 本方法可以在各个模型之间进行分离训练，即每个模型只需要学习自己所接触到的数据，而不需要掌握所有数据。此外，CDM 还允许在不同的分布和领域上进行不同的训练，并在推理时根据用户的访问权限服务自定义模型。</li>
<li>results: CDM 可以实现大规模扩散模型中的选择性忘记和持续学习，以及根据用户的访问权限服务自定义模型。此外，CDM 还可以确定特定样本的数据 subsets 的重要性。<details>
<summary>Abstract</summary>
We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
</details>
<details>
<summary>摘要</summary>
我们介绍了封 compartmentalized Diffusion Models（CDM），这是一种方法来在不同的数据来源上训练不同的扩散模型（或提示），并在推论时进行组合。个别模型可以在专门的时间和环境下进行训练，并且可以在不同的分布和领域上进行训练。在推论时，这些模型可以组合以 дости得相当于一个传统模型，训练在所有数据上。此外，每个模型只包含它在训练时所接触到的子集数据的信息，这使得可以实现多种训练数据保护。特别是，CDMs 是首个允许大规模扩散模型中的选择性遗忘和持续学习，以及根据用户的存取权来提供自定义的模型。CDMs 还允许决定特定数据子集在生成特定样本时的重要性。
</details></li>
</ul>
<hr>
<h2 id="Dual-Governance-The-intersection-of-centralized-regulation-and-crowdsourced-safety-mechanisms-for-Generative-AI"><a href="#Dual-Governance-The-intersection-of-centralized-regulation-and-crowdsourced-safety-mechanisms-for-Generative-AI" class="headerlink" title="Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI"></a>Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04448">http://arxiv.org/abs/2308.04448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Avijit Ghosh, Dhanya Lakshmi</li>
<li>for: 这篇论文的目的是提出一个名为“双重管理”的框架，以促进创新和创意的发展，同时确保generative AI的安全和道德性。</li>
<li>methods: 这篇论文使用了中央政府法规和社区发展的安全机制，以实现双重管理框架的目的。</li>
<li>results: 根据论文的描述，这个双重管理框架可以实现创新和创意的发展，同时确保generative AI的安全和道德性。<details>
<summary>Abstract</summary>
Generative Artificial Intelligence (AI) has seen mainstream adoption lately, especially in the form of consumer-facing, open-ended, text and image generating models. However, the use of such systems raises significant ethical and safety concerns, including privacy violations, misinformation and intellectual property theft. The potential for generative AI to displace human creativity and livelihoods has also been under intense scrutiny. To mitigate these risks, there is an urgent need of policies and regulations responsible and ethical development in the field of generative AI. Existing and proposed centralized regulations by governments to rein in AI face criticisms such as not having sufficient clarity or uniformity, lack of interoperability across lines of jurisdictions, restricting innovation, and hindering free market competition. Decentralized protections via crowdsourced safety tools and mechanisms are a potential alternative. However, they have clear deficiencies in terms of lack of adequacy of oversight and difficulty of enforcement of ethical and safety standards, and are thus not enough by themselves as a regulation mechanism. We propose a marriage of these two strategies via a framework we call Dual Governance. This framework proposes a cooperative synergy between centralized government regulations in a U.S. specific context and safety mechanisms developed by the community to protect stakeholders from the harms of generative AI. By implementing the Dual Governance framework, we posit that innovation and creativity can be promoted while ensuring safe and ethical deployment of generative AI.
</details>
<details>
<summary>摘要</summary>
生成人工智能（AI）在最近几年内得到了广泛的推广，尤其是在形式为consumer-facing、开放结束的文本和图像生成模型。然而，使用这些系统的使用带来了重要的伦理和安全问题，包括隐私侵犯、谣言和知识产权侵犯。生成AI的潜在性取代人类创造力和生活方式也在严格审查。为了缓解这些风险，有一个紧迫需要的政策和法规，负责able和伦理的开发在生成AI领域。现有和提议的中央政府法规，如政府的执法，受到批评，包括缺乏清晰性和一致性、跨行政区域不兼容性、限制创新和妨碍自由市场竞争。 Decentralized保护via Crowdsourced safety工具和机制是一个可能的代替方案。然而，它们缺乏伦理和安全标准的可靠监管和执法能力，因此不够作为唯一的规章机制。我们提出了一种名为“双重管理”的框架，该框架提议在美国特定的上下文中，中央政府法规和社区开发的安全机制之间建立合作协同关系，以促进创新和伦理的投入，同时确保生成AI的安全和伦理部署。
</details></li>
</ul>
<hr>
<h2 id="VertexSerum-Poisoning-Graph-Neural-Networks-for-Link-Inference"><a href="#VertexSerum-Poisoning-Graph-Neural-Networks-for-Link-Inference" class="headerlink" title="VertexSerum: Poisoning Graph Neural Networks for Link Inference"></a>VertexSerum: Poisoning Graph Neural Networks for Link Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01469">http://arxiv.org/abs/2308.01469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyi Ding, Shijin Duan, Xiaolin Xu, Yunsi Fei</li>
<li>for: 保护图structured数据中的链接信息，防止敏感信息泄露。</li>
<li>methods: 提出了一种新的图poisong攻击方法，通过增强链接连接泄露来提高链接泄露效果。还提出了一种注意力机制，可以嵌入链接检测网络中。</li>
<li>results: 在四个真实世界数据集和三种不同的GNN结构中，VertexSerum显著超过了现有的链接推断攻击方法，平均提高了AUC分数9.8%。此外，我们的实验还表明VertexSerum在黑盒和在线学习设置中都有出色的应用可能性。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) have brought superb performance to various applications utilizing graph structural data, such as social analysis and fraud detection. The graph links, e.g., social relationships and transaction history, are sensitive and valuable information, which raises privacy concerns when using GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel graph poisoning attack that increases the effectiveness of graph link stealing by amplifying the link connectivity leakage. To infer node adjacency more accurately, we propose an attention mechanism that can be embedded into the link detection network. Our experiments demonstrate that VertexSerum significantly outperforms the SOTA link inference attack, improving the AUC scores by an average of $9.8\%$ across four real-world datasets and three different GNN structures. Furthermore, our experiments reveal the effectiveness of VertexSerum in both black-box and online learning settings, further validating its applicability in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) have brought superb performance to various applications utilizing graph structural data, such as social analysis and fraud detection. The graph links, e.g., social relationships and transaction history, are sensitive and valuable information, which raises privacy concerns when using GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel graph poisoning attack that increases the effectiveness of graph link stealing by amplifying the link connectivity leakage. To infer node adjacency more accurately, we propose an attention mechanism that can be embedded into the link detection network. Our experiments demonstrate that VertexSerum significantly outperforms the SOTA link inference attack, improving the AUC scores by an average of 9.8% across four real-world datasets and three different GNN structures. Furthermore, our experiments reveal the effectiveness of VertexSerum in both black-box and online learning settings, further validating its applicability in real-world scenarios.
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Small-Molecule-Properties-in-Drug-Discovery"><a href="#Machine-Learning-Small-Molecule-Properties-in-Drug-Discovery" class="headerlink" title="Machine Learning Small Molecule Properties in Drug Discovery"></a>Machine Learning Small Molecule Properties in Drug Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12354">http://arxiv.org/abs/2308.12354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikolai Schapin, Maciej Majewski, Alejandro Varela, Carlos Arroniz, Gianni De Fabritiis<br>for: This paper provides a comprehensive overview of various machine learning (ML) methods for predicting small molecule properties in drug discovery, including binding affinities, solubility, and ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity).methods: The paper reviews a wide range of ML methods, including neural networks, chemical fingerprints, and graph-based neural networks, and discusses existing popular datasets and molecular descriptors.results: The paper highlights the challenges of predicting and optimizing multiple properties during hit-to-lead and lead optimization stages of drug discovery and explores briefly possible multi-objective optimization techniques to balance diverse properties while optimizing lead candidates. Additionally, the paper assesses techniques to provide an understanding of model predictions, especially for critical decision-making in drug discovery.Here is the information in Simplified Chinese text:for: 这篇论文提供了药物小分子性能预测方法的全面回顾，包括绑定亲和力、溶解度和ADMET（吸收、分布、代谢、排泄和毒性）。methods: 论文评论了各种机器学习方法，包括神经网络、化学指纹和图表基本网络，并讨论了现有的受欢迎数据集和分子特征。results: 论文强调了hit-to-lead和领导优化阶段中预测和优化多种属性的挑战，并 briefly explores可能的多目标优化技术来均衡多种属性。此外，论文评估了模型预测的理解方法，特别是在药物发现中的关键决策过程中。<details>
<summary>Abstract</summary>
Machine learning (ML) is a promising approach for predicting small molecule properties in drug discovery. Here, we provide a comprehensive overview of various ML methods introduced for this purpose in recent years. We review a wide range of properties, including binding affinities, solubility, and ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity). We discuss existing popular datasets and molecular descriptors and embeddings, such as chemical fingerprints and graph-based neural networks. We highlight also challenges of predicting and optimizing multiple properties during hit-to-lead and lead optimization stages of drug discovery and explore briefly possible multi-objective optimization techniques that can be used to balance diverse properties while optimizing lead candidates. Finally, techniques to provide an understanding of model predictions, especially for critical decision-making in drug discovery are assessed. Overall, this review provides insights into the landscape of ML models for small molecule property predictions in drug discovery. So far, there are multiple diverse approaches, but their performances are often comparable. Neural networks, while more flexible, do not always outperform simpler models. This shows that the availability of high-quality training data remains crucial for training accurate models and there is a need for standardized benchmarks, additional performance metrics, and best practices to enable richer comparisons between the different techniques and models that can shed a better light on the differences between the many techniques.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）是药物发现中预测小分子性质的有前途的方法。本文提供了最近几年内对这种目标的各种机器学习方法的全面概述。我们评论了各种性质，包括结合稳定性、溶解度和ADMET（吸收、分布、代谢、排泄和毒性）。我们讨论了现有的受欢迎数据集和分子特征，如化学指纹和图像基于神经网络。我们 также提到了选择和优化多个属性的挑战，以及可能使用的多目标优化技术来平衡多个属性。最后，我们评估了模型预测结果的方法，特别是在药物发现的关键决策过程中。总的来说，本文提供了药物小分子性质预测机器学习模型的景观，目前有多种不同的方法，但它们的性能经常相当。神经网络，虽然更灵活，并不总是击败简单的模型。这表明数据训练的质量是关键，还需要标准化的 bencmarks、额外的性能指标和最佳实践，以便更好地比较不同的方法和模型，从而更好地了解它们之间的差异。
</details></li>
</ul>
<hr>
<h2 id="From-Discrete-Tokens-to-High-Fidelity-Audio-Using-Multi-Band-Diffusion"><a href="#From-Discrete-Tokens-to-High-Fidelity-Audio-Using-Multi-Band-Diffusion" class="headerlink" title="From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion"></a>From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02560">http://arxiv.org/abs/2308.02560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robin San Roman, Yossi Adi, Antoine Deleforge, Romain Serizel, Gabriel Synnaeve, Alexandre Défossez<br>for:这篇论文旨在提出一种高质量多频幂 diffusion-based 框架，用于从低比特率精炼的数据表示生成任何类型的音频模式（如语音、音乐、环境声）。methods:该方法使用 diffusion 模型，并在多个频带上实现。results:在相同的比特率下，该方法与现有的生成技术相比，具有更高的感知质量。<details>
<summary>Abstract</summary>
Deep generative models can generate high-fidelity audio conditioned on various types of representations (e.g., mel-spectrograms, Mel-frequency Cepstral Coefficients (MFCC)). Recently, such models have been used to synthesize audio waveforms conditioned on highly compressed representations. Although such methods produce impressive results, they are prone to generate audible artifacts when the conditioning is flawed or imperfect. An alternative modeling approach is to use diffusion models. However, these have mainly been used as speech vocoders (i.e., conditioned on mel-spectrograms) or generating relatively low sampling rate signals. In this work, we propose a high-fidelity multi-band diffusion-based framework that generates any type of audio modality (e.g., speech, music, environmental sounds) from low-bitrate discrete representations. At equal bit rate, the proposed approach outperforms state-of-the-art generative techniques in terms of perceptual quality. Training and, evaluation code, along with audio samples, are available on the facebookresearch/audiocraft Github page.
</details>
<details>
<summary>摘要</summary>
深度生成模型可以生成高质量音频，受到不同类型的表示（例如：mel-spectrograms、Mel-frequency Cepstral Coefficients (MFCC)）的控制。近期，这些模型被用来synthesize音波形态，受到高度压缩的表示的控制。虽然这些方法可以生成印象深刻的结果，但它们容易产生杂音artefacts，当控制是不完整或有误的时。一种alternative的模型方法是使用扩散模型。然而，这些模型主要用于speech vocoder（受到mel-spectrograms的控制）或生成低频率的信号。在这个工作中，我们提议一种高质量多频段扩散基础框架，可以从low-bitrate discrete表示生成任何类型的音频模式（例如：speech、音乐、环境声）。在相同的比特率下，我们的提议方法在perceptual质量上超过了现状的生成技术。训练和评估代码，以及音频样本，可以在facebookresearch/audiocraft GitHub页面上获取。
</details></li>
</ul>
<hr>
<h2 id="A-digital-twin-framework-for-civil-engineering-structures"><a href="#A-digital-twin-framework-for-civil-engineering-structures" class="headerlink" title="A digital twin framework for civil engineering structures"></a>A digital twin framework for civil engineering structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01445">http://arxiv.org/abs/2308.01445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Torzoni, Marco Tezzele, Stefano Mariani, Andrea Manzoni, Karen E. Willcox</li>
<li>for: 这项研究旨在提出一种预测性的数字双方法，用于监测、维护和管理 civil engineering 系统的健康状况。</li>
<li>methods: 该方法使用 probabilistic graphical model 编码 asset-twin 相关系统，并使用动态 Bayesian network 模型来处理时间重复的观察数据。深度学习模型用于提供实时结构健康诊断。</li>
<li>results: 研究人员通过在 synthetic 案例中使用reduced-order numerical model 计算健康依赖控制策略，并通过 dynamically updating digital twin 状态来实现智能决策。两个synthetic案例（一个悬臂 beam 和一个铁路桥）证明了该方法的动态决策能力。<details>
<summary>Abstract</summary>
The digital twin concept represents an appealing opportunity to advance condition-based and predictive maintenance paradigms for civil engineering systems, thus allowing reduced lifecycle costs, increased system safety, and increased system availability. This work proposes a predictive digital twin approach to the health monitoring, maintenance, and management planning of civil engineering structures. The asset-twin coupled dynamical system is encoded employing a probabilistic graphical model, which allows all relevant sources of uncertainty to be taken into account. In particular, the time-repeating observations-to-decisions flow is modeled using a dynamic Bayesian network. Real-time structural health diagnostics are provided by assimilating sensed data with deep learning models. The digital twin state is continually updated in a sequential Bayesian inference fashion. This is then exploited to inform the optimal planning of maintenance and management actions within a dynamic decision-making framework. A preliminary offline phase involves the population of training datasets through a reduced-order numerical model and the computation of a health-dependent control policy. The strategy is assessed on two synthetic case studies, involving a cantilever beam and a railway bridge, demonstrating the dynamic decision-making capabilities of health-aware digital twins.
</details>
<details>
<summary>摘要</summary>
“数字双胞体概念可能为公共工程系统维护和预测维护方面提供一个吸引人的机遇，以降低系统成本、提高系统安全性和提高系统可用性。这项工作提议一种预测性数字双胞体方法，用于监测、维护和管理计划 civil engineering 结构。Asset-twin 相关的动态系统通过 probabilistic graphical model 编码，其中包括所有相关的不确定因素。具体来说，时间重复的观察数据流使用动态 Bayesian network 进行模型化。通过嵌入感知数据的深度学习模型，实时执行结构健康诊断。数字双胞体状态通过顺序 Bayesian 推理方式不断更新。这些信息最后用于在动态决策框架中决策维护和管理活动的优化。在一个先进的离线阶段，通过减少的数值模型和计算健康控制策略，人工数据被填充到训练集中。这种策略在两个 sintetic 案例中，包括一个悬臂 beam 和一个铁路桥，展示了健康意识数字双胞体的动态决策能力。”
</details></li>
</ul>
<hr>
<h2 id="DLSIA-Deep-Learning-for-Scientific-Image-Analysis"><a href="#DLSIA-Deep-Learning-for-Scientific-Image-Analysis" class="headerlink" title="DLSIA: Deep Learning for Scientific Image Analysis"></a>DLSIA: Deep Learning for Scientific Image Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02559">http://arxiv.org/abs/2308.02559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric J Roberts, Tanny Chavez, Alexander Hexemer, Petrus H. Zwart</li>
<li>for: 这篇论文是为了推广Python基于深度学习库DLSIA，帮助科学家和研究人员在多种科学领域使用自定义卷积神经网络架构进行图像分析任务，以便在下游数据处理或实验循环计算 scenarios 中使用。</li>
<li>methods: 该论文使用了易于使用的架构，如自动Encoder、可调U-Net和精简的混合缩放神经网络（MSDNet），以及Random graphs和稀疏连接生成的稀疏混合缩放神经网络（SMSNet）。</li>
<li>results: 该论文通过论文的实验数据继续增长 scale和复杂度，DLSIA提供了论文架构的可定制化和抽象，帮助科学家适应机器学习方法，加速发现，促进交叉领域合作，并进展科学图像分析研究。<details>
<summary>Abstract</summary>
We introduce DLSIA (Deep Learning for Scientific Image Analysis), a Python-based machine learning library that empowers scientists and researchers across diverse scientific domains with a range of customizable convolutional neural network (CNN) architectures for a wide variety of tasks in image analysis to be used in downstream data processing, or for experiment-in-the-loop computing scenarios. DLSIA features easy-to-use architectures such as autoencoders, tunable U-Nets, and parameter-lean mixed-scale dense networks (MSDNets). Additionally, we introduce sparse mixed-scale networks (SMSNets), generated using random graphs and sparse connections. As experimental data continues to grow in scale and complexity, DLSIA provides accessible CNN construction and abstracts CNN complexities, allowing scientists to tailor their machine learning approaches, accelerate discoveries, foster interdisciplinary collaboration, and advance research in scientific image analysis.
</details>
<details>
<summary>摘要</summary>
我们介绍DLSIA（深度学习 для科学影像分析），一个基于Python的机器学习库，它为科学家和研究人员提供了许多可自定义的卷积神经网络架构，用于广泛的影像分析任务，包括下游处理和实验运行 Computing enario。DLSIA 提供了易于使用的架构，例如自动编码器、可调 U-Net 和对�如� mixed-scale dense network (MSNet)。此外，我们还引入了随机 graphs 和罕见 Connection 的 sparse mixed-scale network (SMSNet)。随着实验数据的数量和复杂度不断增加，DLSIA 提供了可访问的 CNN 建立和抽象 CNN 复杂度，让科学家可以根据自己的机器学习方法，加速发现，促进多学科合作，并进展科学影像分析研究。
</details></li>
</ul>
<hr>
<h2 id="Novel-Physics-Based-Machine-Learning-Models-for-Indoor-Air-Quality-Approximations"><a href="#Novel-Physics-Based-Machine-Learning-Models-for-Indoor-Air-Quality-Approximations" class="headerlink" title="Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations"></a>Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01438">http://arxiv.org/abs/2308.01438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Mohammadshirazi, Aida Nadafian, Amin Karimi Monsefi, Mohammad H. Rafiei, Rajiv Ramnath</li>
<li>For: 这种研究旨在提供一种准确的indoor空气质量估计方法，以提供健康的室内环境，优化相关能源消耗，并提供人类 COMFORT。* Methods: 该研究提出了六种新的物理基于机器学习模型，结合了状态空间概念、闭合循环单元和分解技术。* Results: 该研究表明，提出的模型比类似的现状技术转换器模型更加简单、计算效率高，并且能够更好地捕捉室内空气质量数据中的高度非线性特征。<details>
<summary>Abstract</summary>
Cost-effective sensors are capable of real-time capturing a variety of air quality-related modalities from different pollutant concentrations to indoor/outdoor humidity and temperature. Machine learning (ML) models are capable of performing air-quality "ahead-of-time" approximations. Undoubtedly, accurate indoor air quality approximation significantly helps provide a healthy indoor environment, optimize associated energy consumption, and offer human comfort. However, it is crucial to design an ML architecture to capture the domain knowledge, so-called problem physics. In this study, we propose six novel physics-based ML models for accurate indoor pollutant concentration approximations. The proposed models include an adroit combination of state-space concepts in physics, Gated Recurrent Units, and Decomposition techniques. The proposed models were illustrated using data collected from five offices in a commercial building in California. The proposed models are shown to be less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. The superiority of the proposed models is due to their relatively light architecture (computational efficiency) and, more importantly, their ability to capture the underlying highly nonlinear patterns embedded in the often contaminated sensor-collected indoor air quality temporal data.
</details>
<details>
<summary>摘要</summary>
Cost-effective sensors can real-time capture various air quality-related modalities, from different pollutant concentrations to indoor/outdoor humidity and temperature. Machine learning (ML) models can perform air-quality "ahead-of-time" approximations. Accurate indoor air quality approximation is crucial to provide a healthy indoor environment, optimize associated energy consumption, and offer human comfort. However, it is essential to design an ML architecture that captures the domain knowledge, so-called problem physics. In this study, we propose six novel physics-based ML models for accurate indoor pollutant concentration approximations. The proposed models combine state-space concepts in physics, Gated Recurrent Units, and Decomposition techniques. The proposed models were illustrated using data collected from five offices in a commercial building in California. The proposed models are less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. The superiority of the proposed models is due to their relatively light architecture (computational efficiency) and their ability to capture the underlying highly nonlinear patterns embedded in the often contaminated sensor-collected indoor air quality temporal data.
</details></li>
</ul>
<hr>
<h2 id="Price-Aware-Deep-Learning-for-Electricity-Markets"><a href="#Price-Aware-Deep-Learning-for-Electricity-Markets" class="headerlink" title="Price-Aware Deep Learning for Electricity Markets"></a>Price-Aware Deep Learning for Electricity Markets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01436">http://arxiv.org/abs/2308.01436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vladimir Dvorkin, Ferdinando Fioretto</li>
<li>for: 本文旨在探讨深度学习在运维规划中的应用，以及深度学习中的预测错误如何影响电力价格。</li>
<li>methods: 本文使用了深度学习模型来预测电力供应和需求，并通过嵌入电力市场清算优化层来提高公平性。</li>
<li>results: 研究发现，通过嵌入电力市场清算优化层可以减少预测错误对电力价格的影响，同时可以控制系统内价格错误的空间分布。<details>
<summary>Abstract</summary>
While deep learning gradually penetrates operational planning, its inherent prediction errors may significantly affect electricity prices. This letter examines how prediction errors propagate into electricity prices, revealing notable pricing errors and their spatial disparity in congested power systems. To improve fairness, we propose to embed electricity market-clearing optimization as a deep learning layer. Differentiating through this layer allows for balancing between prediction and pricing errors, as oppose to minimizing prediction errors alone. This layer implicitly optimizes fairness and controls the spatial distribution of price errors across the system. We showcase the price-aware deep learning in the nexus of wind power forecasting and short-term electricity market clearing.
</details>
<details>
<summary>摘要</summary>
“深度学习逐渐渗透到运维规划中，但它的内置预测错误可能对电力价格产生很大影响。这封信通过分析预测错误如何传播到电力价格，揭示了价格错误的很大差异和系统中的空间分布。为了提高公平性，我们提议将电力市场清算优化作为深度学习层的一部分。通过这个层进行极点搜索，可以平衡预测错误和价格错误，而不是仅仅是减少预测错误。这个层也隐式地优化了公平性，并控制了系统中价格错误的空间分布。我们在风力发电预测和短期电力市场清算之间展示了价格意识深度学习的作用。”Note: Please keep in mind that the translation is not perfect and may not capture all the nuances of the original text.
</details></li>
</ul>
<hr>
<h2 id="COVID-VR-A-Deep-Learning-COVID-19-Classification-Model-Using-Volume-Rendered-Computer-Tomography"><a href="#COVID-VR-A-Deep-Learning-COVID-19-Classification-Model-Using-Volume-Rendered-Computer-Tomography" class="headerlink" title="COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography"></a>COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01433">http://arxiv.org/abs/2308.01433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noemi Maritza L. Romero, Ricco Vasconcellos, Mariana R. Mendoza, João L. D. Comba</li>
<li>for: 该论文主要目的是提出一种基于Volume Rendering技术的肺疾病分类方法，以提高肺疾病诊断的准确性和效率。</li>
<li>methods: 该方法使用了深度学习模型，利用多个视角捕捉的Volume Rendering图像来分类肺疾病。</li>
<li>results: 对比于传统的slice-based方法，该方法能够更好地识别肺疾病，并且在比较中表现竞争力强。<details>
<summary>Abstract</summary>
The COVID-19 pandemic presented numerous challenges to healthcare systems worldwide. Given that lung infections are prevalent among COVID-19 patients, chest Computer Tomography (CT) scans have frequently been utilized as an alternative method for identifying COVID-19 conditions and various other types of pulmonary diseases. Deep learning architectures have emerged to automate the identification of pulmonary disease types by leveraging CT scan slices as inputs for classification models. This paper introduces COVID-VR, a novel approach for classifying pulmonary diseases based on volume rendering images of the lungs captured from multiple angles, thereby providing a comprehensive view of the entire lung in each image. To assess the effectiveness of our proposal, we compared it against competing strategies utilizing both private data obtained from partner hospitals and a publicly available dataset. The results demonstrate that our approach effectively identifies pulmonary lesions and performs competitively when compared to slice-based methods.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行对全球医疗系统带来了许多挑战。由于呼吸系统疾病非常普遍 Among COVID-19 patients, chest Computer Tomography (CT) scans have frequently been used as an alternative method for identifying COVID-19 conditions and various other types of pulmonary diseases. 深度学习体系 emerged to automate the identification of pulmonary disease types by leveraging CT scan slices as inputs for classification models.This paper introduces COVID-VR, a novel approach for classifying pulmonary diseases based on volume rendering images of the lungs captured from multiple angles, thereby providing a comprehensive view of the entire lung in each image. To assess the effectiveness of our proposal, we compared it against competing strategies utilizing both private data obtained from partner hospitals and a publicly available dataset. The results demonstrate that our approach effectively identifies pulmonary lesions and performs competitively when compared to slice-based methods.Here's the text with Traditional Chinese characters:COVID-19 大流行对全球医疗系统带来了许多挑战。由于呼吸系统疾病非常普遍 Among COVID-19 patients, chest Computer Tomography (CT) scans have frequently been used as an alternative method for identifying COVID-19 conditions and various other types of pulmonary diseases. 深度学习体系 emerged to automate the identification of pulmonary disease types by leveraging CT scan slices as inputs for classification models.This paper introduces COVID-VR, a novel approach for classifying pulmonary diseases based on volume rendering images of the lungs captured from multiple angles, thereby providing a comprehensive view of the entire lung in each image. To assess the effectiveness of our proposal, we compared it against competing strategies utilizing both private data obtained from partner hospitals and a publicly available dataset. The results demonstrate that our approach effectively identifies pulmonary lesions and performs competitively when compared to slice-based methods.
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Potential-of-Similarity-Matching-Scalability-Supervision-and-Pre-training"><a href="#Unlocking-the-Potential-of-Similarity-Matching-Scalability-Supervision-and-Pre-training" class="headerlink" title="Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training"></a>Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02427">http://arxiv.org/abs/2308.02427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanis Bahroun, Shagesh Sridharan, Atithi Acharya, Dmitri B. Chklovskii, Anirvan M. Sengupta</li>
<li>for: 这篇论文旨在提出一种基于本地学习规则的可能学习框架，以替代具有限制的负回propagation（BP）算法，提高计算效率和生物可能性。</li>
<li>methods: 该研究使用了一种基于similarity matching（SM）框架的方法，该框架与生物系统中观察到的机制相符，并且可以在线、本地化和生物可能性的方法。</li>
<li>results: 研究人员通过对PyTorch实现Convolutional Nonnegative SM进行扩展，并引入一种基于核心相关分析的本地化supervised SM目标，使得SM层可以堆叠。此外，研究人员还对LeNet预训练架构进行比较，并证明了与BP训练模型的评估特征的比较。这种结合生物可能性和计算效率的方法开创了多个可能性的探索。<details>
<summary>Abstract</summary>
While effective, the backpropagation (BP) algorithm exhibits limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms. i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch. ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers. iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computational efficiency opening multiple avenues for further explorations.
</details>
<details>
<summary>摘要</summary>
While effective, the backpropagation (BP) algorithm has limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms.i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch.ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers.iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computational efficiency, opening multiple avenues for further explorations.Here's the translation in Traditional Chinese:虽然backpropagation（BP）算法有效，但它具有生物可能性、计算成本和线上学习不适用的限制。因此，有着增加生物可能性学习方法的生物学可能性的兴趣。本研究专注在主要无监督相似匹配（SM）框架，该框架与生物系统观察到的机制相似，并且提供了线上、本地和生物可能性的算法。i) 为了扩展SM到大量数据集，我们提议使用PyTorch实现Convolutional Nonnegative SM。ii) 我们引入了一个本地导向的SM目标，与传统的均值分析相似，便于堆叠SM层。iii) 我们利用PyTorch实现，与BP训练的模型进行比较，以评估特征的评估。本研究结合了生物可能性算法和计算效率，开启了多个探索之路。
</details></li>
</ul>
<hr>
<h2 id="Bio-Clinical-BERT-BERT-Base-and-CNN-Performance-Comparison-for-Predicting-Drug-Review-Satisfaction"><a href="#Bio-Clinical-BERT-BERT-Base-and-CNN-Performance-Comparison-for-Predicting-Drug-Review-Satisfaction" class="headerlink" title="Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction"></a>Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03782">http://arxiv.org/abs/2308.03782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Ling</li>
<li>for: 这项研究的目的是开发一种可以分析病人药物评价文本，并准确地分类为正面、中性或负面三类的自然语言处理（NLP）模型。</li>
<li>methods: 研究人员实现和评估了多种分类模型，包括BERT基础模型、医疗+临床BERT和简单的CNN。</li>
<li>results: 结果表明，医疗+临床BERT模型在总性表现方面胜过基础BERT模型，实现了 macro f1 和回归分数的11%的提升，如表2所示。未来的研究可以探讨如何利用每个模型的特点。医疗+临床BERT模型在医疗术语方面表现出色，而简单的CNN则能够准确地识别关键词并在文本中分类 sentiment。<details>
<summary>Abstract</summary>
The objective of this study is to develop natural language processing (NLP) models that can analyze patients' drug reviews and accurately classify their satisfaction levels as positive, neutral, or negative. Such models would reduce the workload of healthcare professionals and provide greater insight into patients' quality of life, which is a critical indicator of treatment effectiveness. To achieve this, we implemented and evaluated several classification models, including a BERT base model, Bio+Clinical BERT, and a simpler CNN. Results indicate that the medical domain-specific Bio+Clinical BERT model significantly outperformed the general domain base BERT model, achieving macro f1 and recall score improvement of 11%, as shown in Table 2. Future research could explore how to capitalize on the specific strengths of each model. Bio+Clinical BERT excels in overall performance, particularly with medical jargon, while the simpler CNN demonstrates the ability to identify crucial words and accurately classify sentiment in texts with conflicting sentiments.
</details>
<details>
<summary>摘要</summary>
本研究的目的是开发自然语言处理（NLP）模型，可以分析病人的药品评价并准确地分类为正面、中性或负面的满意度。这些模型会减轻医疗专业人员的工作负担，并提供更多有关病人生活质量的指标，这是治疗效果的关键指标。为 достичь这一目标，我们实施和评估了多种分类模型，包括BERT基础模型、医疗+临床BERT和简单的CNN。结果表明，医疗领域特定的Bio+Clinical BERT模型在表格2中显著超越了通用领域基础BERT模型，实现了macro f1和回归分数的提高率为11%。未来的研究可以探讨如何利用每个模型的特点。Bio+Clinical BERT在总性性能方面表现优异，特别是对医疗术语的处理；而简单的CNN则能够准确地标识关键词并在文本中 conflicting 的情感下准确地分类 sentiment。
</details></li>
</ul>
<hr>
<h2 id="Sea-level-Projections-with-Machine-Learning-using-Altimetry-and-Climate-Model-ensembles"><a href="#Sea-level-Projections-with-Machine-Learning-using-Altimetry-and-Climate-Model-ensembles" class="headerlink" title="Sea level Projections with Machine Learning using Altimetry and Climate Model ensembles"></a>Sea level Projections with Machine Learning using Altimetry and Climate Model ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02460">http://arxiv.org/abs/2308.02460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saumya Sinha, John Fasullo, R. Steven Nerem, Claire Monteleoni</li>
<li>for: 研究全球海平面的上升趋势和anthropogenic climate-change signals的贡献</li>
<li>methods: 使用机器学习（ML）方法，combine satellite observations和气候模型 simulations，预测未来30年海平面变化</li>
<li>results: 通过非线性拟合气候模型预测和ML模型，预测未来30年海平面变化，并通过分割数据集来提高预测的准确性<details>
<summary>Abstract</summary>
Satellite altimeter observations retrieved since 1993 show that the global mean sea level is rising at an unprecedented rate (3.4mm/year). With almost three decades of observations, we can now investigate the contributions of anthropogenic climate-change signals such as greenhouse gases, aerosols, and biomass burning in this rising sea level. We use machine learning (ML) to investigate future patterns of sea level change. To understand the extent of contributions from the climate-change signals, and to help in forecasting sea level change in the future, we turn to climate model simulations. This work presents a machine learning framework that exploits both satellite observations and climate model simulations to generate sea level rise projections at a 2-degree resolution spatial grid, 30 years into the future. We train fully connected neural networks (FCNNs) to predict altimeter values through a non-linear fusion of the climate model hindcasts (for 1993-2019). The learned FCNNs are then applied to future climate model projections to predict future sea level patterns. We propose segmenting our spatial dataset into meaningful clusters and show that clustering helps to improve predictions of our ML model.
</details>
<details>
<summary>摘要</summary>
卫星探雷数据自1993年起获取到，全球平均海平面上升速率为3.4毫米/年。经过三十年的观测，我们现在可以研究人类活动对海平面上升的贡献，包括绿色气体、尘埃和生物燃烧等气候变化信号。我们使用机器学习（ML）技术来研究未来海平面变化的趋势。为了了解气候变化信号的贡献程度，以及在未来预测海平面变化的需要，我们转而使用气候模型仿真。本研究提出了一种基于卫星观测和气候模型仿真的机器学习框架，用于预测未来30年的海平面变化趋势。我们使用全连接神经网络（FCNN）来预测探雷值，通过非线性混合气候模型预测（1993-2019年）来训练FCNN。学习后的FCNN被应用于未来气候模型预测中，以预测未来海平面的变化趋势。我们还提出了分割我们的空间数据集，并证明分割可以提高我们的机器学习模型的预测精度。
</details></li>
</ul>
<hr>
<h2 id="OpenFlamingo-An-Open-Source-Framework-for-Training-Large-Autoregressive-Vision-Language-Models"><a href="#OpenFlamingo-An-Open-Source-Framework-for-Training-Large-Autoregressive-Vision-Language-Models" class="headerlink" title="OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"></a>OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01390">http://arxiv.org/abs/2308.01390</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlfoundations/open_flamingo">https://github.com/mlfoundations/open_flamingo</a></li>
<li>paper_authors: Anas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe, Yonatan Bitton, Samir Gadre, Shiori Sagawa, Jenia Jitsev, Simon Kornblith, Pang Wei Koh, Gabriel Ilharco, Mitchell Wortsman, Ludwig Schmidt</li>
<li>for: 这个论文是为了制定一个开源的FLAMINGO模型复制，用于视觉语言处理任务。</li>
<li>methods: 这个论文使用了多种权重学习算法和精度优化技术来训练FLAMINGO模型，并在七个视觉语言数据集上进行了评估。</li>
<li>results: 根据论文的报告，OpenFlamingo模型在七个视觉语言数据集上的平均性能为80-89%，与相应的FLAMINGO模型的性能相当。<details>
<summary>Abstract</summary>
We introduce OpenFlamingo, a family of autoregressive vision-language models ranging from 3B to 9B parameters. OpenFlamingo is an ongoing effort to produce an open-source replication of DeepMind's Flamingo models. On seven vision-language datasets, OpenFlamingo models average between 80 - 89% of corresponding Flamingo performance. This technical report describes our models, training data, hyperparameters, and evaluation suite. We share our models and code at https://github.com/mlfoundations/open_flamingo.
</details>
<details>
<summary>摘要</summary>
我们介绍OpenFlamingo，一个家族型态数据视觉语言模型，从3B到9B参数。OpenFlamingo是一个持续进行的开源实现深渊迷你的FLAMINGO模型。在七个视觉语言数据集上，OpenFlamingo模型的平均表现为80-89%相应的FLAMINGO性能。这份技术报告描述了我们的模型、训练数据、几何parameters和评估套件。我们在https://github.com/mlfoundations/open_flamingo上分享我们的模型和代码。
</details></li>
</ul>
<hr>
<h2 id="Follow-the-Soldiers-with-Optimized-Single-Shot-Multibox-Detection-and-Reinforcement-Learning"><a href="#Follow-the-Soldiers-with-Optimized-Single-Shot-Multibox-Detection-and-Reinforcement-Learning" class="headerlink" title="Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning"></a>Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01389">http://arxiv.org/abs/2308.01389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jumman Hossain, Maliha Momtaz</li>
<li>for: 本研究的主要目标是建立一个自动驾驶系统，使其能够跟踪一名士兵（在我们的项目中）在任何方向移动。</li>
<li>methods: 我们使用优化的单步多卷检测（SSD）对象检测模型和学习环境（RL）模型来实现该目标。</li>
<li>results: 我们使用SSD Lite而不是SSD，并对其进行了比较。实验结果显示，SSD Lite在这三种技术中表现最佳，并在执行速度方面具有显著的提升（约2-3倍）而无需牺牲准确性。<details>
<summary>Abstract</summary>
Nowadays, autonomous cars are gaining traction due to their numerous potential applications on battlefields and in resolving a variety of other real-world challenges. The main goal of our project is to build an autonomous system using DeepRacer which will follow a specific person (for our project, a soldier) when they will be moving in any direction. Two main components to accomplish this project is an optimized Single-Shot Multibox Detection (SSD) object detection model and a Reinforcement Learning (RL) model. We accomplished the task using SSD Lite instead of SSD and at the end, compared the results among SSD, SSD with Neural Computing Stick (NCS), and SSD Lite. Experimental results show that SSD Lite gives better performance among these three techniques and exhibits a considerable boost in inference speed (~2-3 times) without compromising accuracy.
</details>
<details>
<summary>摘要</summary>
现在，自适应车辆正在受到广泛关注，因为它们在战场和解决各种实际问题中具有丰富的潜力。我们项目的主要目标是使用DeepRacer建立一个自适应系统，该系统可以跟踪一个特定人（在我们项目中是一名士兵）在任何方向移动时。我们使用优化的单射多框检测（SSD）对象检测模型和学习奖励（RL）模型来实现该目标。我们使用SSD Lite而不是SSD，并在结束时比较了这三种技术的结果。实验结果显示SSD Lite在这三种技术中表现最佳，并且在执行速度方面表现了明显的提升（约2-3倍），而无需牺牲准确性。
</details></li>
</ul>
<hr>
<h2 id="DeepSpeed-Chat-Easy-Fast-and-Affordable-RLHF-Training-of-ChatGPT-like-Models-at-All-Scales"><a href="#DeepSpeed-Chat-Easy-Fast-and-Affordable-RLHF-Training-of-ChatGPT-like-Models-at-All-Scales" class="headerlink" title="DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales"></a>DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01320">http://arxiv.org/abs/2308.01320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/DeepSpeed">https://github.com/microsoft/DeepSpeed</a></li>
<li>paper_authors: Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajbhandari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang, Conglong Li, Connor Holmes, Zhongzhu Zhou, Michael Wyatt, Molly Smith, Lev Kurilenko, Heyang Qin, Masahiro Tanaka, Shuai Che, Shuaiwen Leon Song, Yuxiong He</li>
<li>for: 这篇论文目的是为了提供一个可访问、高效、cost-effective的RLHF（人类反馈学习）训练管道，以便更多的AI研究人员可以使用ChatGPT-like模型进行训练。</li>
<li>methods: 这篇论文使用了DeepSpeed-Chat系统，这是一个新的RLHF训练系统，它提供了三个关键能力：对ChatGPT-like模型的易于使用训练和推理经验、InstructGPT的DeepSpeed-RLHF管道的复制、以及一个可靠的DeepSpeed-RLHF系统，该系统结合了多种优化来实现训练和推理的高效率和可扩展性。</li>
<li>results: 这篇论文的结果表明，使用DeepSpeed-Chat系统可以在短时间内训练ChatGPT-like模型，并且可以在相对较少的成本下进行大规模训练。这种系统的开发将会推动AI领域的进步和发展，并且将使更多的数据科学家有access to advanced RLHF训练技术。<details>
<summary>Abstract</summary>
ChatGPT-like models have revolutionized various applications in artificial intelligence, from summarization and coding to translation, matching or even surpassing human performance. However, the current landscape lacks an accessible, efficient, and cost-effective end-to-end RLHF (Reinforcement Learning with Human Feedback) training pipeline for these powerful models, particularly when training at the scale of billions of parameters. This paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF training, making it accessible to the AI community. DeepSpeed-Chat offers three key capabilities: an easy-to-use training and inference experience for ChatGPT-like models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and a robust DeepSpeed-RLHF system that combines various optimizations for training and inference in a unified way. The system delivers unparalleled efficiency and scalability, enabling training of models with hundreds of billions of parameters in record time and at a fraction of the cost. With this development, DeepSpeed-Chat paves the way for broader access to advanced RLHF training, even for data scientists with limited resources, thereby fostering innovation and further development in the field of AI.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "ChatGPT-like models have revolutionized various applications in artificial intelligence, from summarization and coding to translation, matching or even surpassing human performance. However, the current landscape lacks an accessible, efficient, and cost-effective end-to-end RLHF (Reinforcement Learning with Human Feedback) training pipeline for these powerful models, particularly when training at the scale of billions of parameters. This paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF training, making it accessible to the AI community. DeepSpeed-Chat offers three key capabilities: an easy-to-use training and inference experience for ChatGPT-like models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and a robust DeepSpeed-RLHF system that combines various optimizations for training and inference in a unified way. The system delivers unparalleled efficiency and scalability, enabling training of models with hundreds of billions of parameters in record time and at a fraction of the cost. With this development, DeepSpeed-Chat paves the way for broader access to advanced RLHF training, even for data scientists with limited resources, thereby fostering innovation and further development in the field of AI."into Simplified Chinese:<<SYS>> chatGPT-like 模型已经在人工智能中革命化了各种应用，从概要和编程到翻译，与人类表现相当或甚至超越人类表现。然而，当前的景象缺乏可 accessible、高效、成本效果的整体 RLHF（人类反馈学习）训练管道，特别是在 billions of parameters 的训练 scale 上。这篇论文介绍了 DeepSpeed-Chat，一种新的系统，它将RLHF 训练 демокра化，使其对 AI 社区开放。DeepSpeed-Chat 提供三个关键能力：对 ChatGPT-like 模型的易于使用训练和推理经验，基于 InstructGPT 的 DeepSpeed-RLHF 管道，以及一个可靠的 DeepSpeed-RLHF 系统，它将训练和推理优化集成在一起。该系统具有无前例的高效性和可扩展性，可以在短时间内训练 billions of parameters 的模型，并且在成本的一小部分。通过这一发展，DeepSpeed-Chat 为更广泛的 RLHF 训练提供了可持续的进程，使得数据科学家 WITH 有限的资源也可以访问高级 RLHF 训练，从而推动 AI 领域的创新和进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Computational-Long-Exposure-Mobile-Photography"><a href="#Computational-Long-Exposure-Mobile-Photography" class="headerlink" title="Computational Long Exposure Mobile Photography"></a>Computational Long Exposure Mobile Photography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01379">http://arxiv.org/abs/2308.01379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Tabellion, Nikhil Karnad, Noa Glaser, Ben Weiss, David E. Jacobs, Yael Pritch</li>
<li>for: 这篇论文是关于计算机图像处理技术的研究，旨在提供一种可以在手持式智能手机摄像头APP中实现长时间曝光摄影的系统。</li>
<li>methods: 该系统首先检测和分割主题，然后跟踪场景运动多个帧，并将图像对齐以保持所需的锐化和生成美观的运动梦幕。最后，它使用预测动态模型来 sintesize动态曝光，并将曝光图像与正常曝光图像 composite 成一个高分辨率和高动态范围的照片。</li>
<li>results: 该系统可以帮助摄影师在手持式智能手机摄像头中实现长时间曝光摄影，并且可以自动检测和分割主题，以及生成美观的运动梦幕。这种技术可以让摄影师更容易地拍摄长时间曝光照片，并且可以帮助更多的摄影爱好者掌握这种技术。<details>
<summary>Abstract</summary>
Long exposure photography produces stunning imagery, representing moving elements in a scene with motion-blur. It is generally employed in two modalities, producing either a foreground or a background blur effect. Foreground blur images are traditionally captured on a tripod-mounted camera and portray blurred moving foreground elements, such as silky water or light trails, over a perfectly sharp background landscape. Background blur images, also called panning photography, are captured while the camera is tracking a moving subject, to produce an image of a sharp subject over a background blurred by relative motion. Both techniques are notoriously challenging and require additional equipment and advanced skills. In this paper, we describe a computational burst photography system that operates in a hand-held smartphone camera app, and achieves these effects fully automatically, at the tap of the shutter button. Our approach first detects and segments the salient subject. We track the scene motion over multiple frames and align the images in order to preserve desired sharpness and to produce aesthetically pleasing motion streaks. We capture an under-exposed burst and select the subset of input frames that will produce blur trails of controlled length, regardless of scene or camera motion velocity. We predict inter-frame motion and synthesize motion-blur to fill the temporal gaps between the input frames. Finally, we composite the blurred image with the sharp regular exposure to protect the sharpness of faces or areas of the scene that are barely moving, and produce a final high resolution and high dynamic range (HDR) photograph. Our system democratizes a capability previously reserved to professionals, and makes this creative style accessible to most casual photographers.   More information and supplementary material can be found on our project webpage: https://motion-mode.github.io/
</details>
<details>
<summary>摘要</summary>
长时间拍摄可以生成吸引人的图像，表现在Scene中的运动元素的摩擦模式。通常在两种模式下使用，生成 either 前景或背景模糊效果。前景模糊图像通常在静止摄像机上拍摄，捕捉摩擦的前景元素，如流动的水或灯光轨迹，与静止的背景景象一样清晰。背景模糊图像，也称为滑动摄影，通过在摄像机跟踪移动目标来生成一个锐定的主题，与相对运动的背景模糊。这两种技术都具有挑战性，需要额外设备和高级技能。在这篇论文中，我们描述了一种基于智能手机摄像机应用的计算机 burst摄影系统，可以在单击闭合按钮后自动完成这些效果。我们的方法首先检测和分割主题。我们跟踪场景运动，并对多帧图像进行对齐，以保持所需的锐度和生成美观的运动螺旋。我们捕捉具有不充足光量的快速拍摄，并从输入帧中选择能够生成控制长度的摩擦轨迹。我们预测间帧运动，并使用模拟摩擦来填充时间间隔。最后，我们将模糊图像 composite 到锐定的正常曝光图像中，以保护人脸或场景中的 hardly moving 部分，并生成一个高分辨率和高 dynamically range (HDR) 图像。我们的系统将这种创造力减少到专业人员之外，使这种创造性风格开放给大多数众所可达。更多信息和补充材料可以在我们项目网站中找到：https://motion-mode.github.io/
</details></li>
</ul>
<hr>
<h2 id="AI-Enhanced-Data-Processing-and-Discovery-Crowd-Sourcing-for-Meteor-Shower-Mapping"><a href="#AI-Enhanced-Data-Processing-and-Discovery-Crowd-Sourcing-for-Meteor-Shower-Mapping" class="headerlink" title="AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping"></a>AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02664">http://arxiv.org/abs/2308.02664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddha Ganju, Amartya Hatua, Peter Jenniskens, Sahyadri Krishna, Chicheng Ren, Surya Ambardar</li>
<li>for: 这项研究的目标是为了映射我们的陨星雨，通过三角测量陨星轨迹检测在低光照视频摄像机上的多个位置上，从16个国家的北和南半球进行覆盖。</li>
<li>methods: 这项研究使用了一个云基的AI导向的自动化数据处理管道，以提高数据处理的速度和精度，并使用可解释的活动学习和AI管道来自动化数据处理。</li>
<li>results: 到目前为止，CAMS已经发现了200多个新的陨星雨，并验证了数十个之前已经报告的雨。<details>
<summary>Abstract</summary>
The Cameras for Allsky Meteor Surveillance (CAMS) project, funded by NASA starting in 2010, aims to map our meteor showers by triangulating meteor trajectories detected in low-light video cameras from multiple locations across 16 countries in both the northern and southern hemispheres. Its mission is to validate, discover, and predict the upcoming returns of meteor showers. Our research aimed to streamline the data processing by implementing an automated cloud-based AI-enabled pipeline and improve the data visualization to improve the rate of discoveries by involving the public in monitoring the meteor detections. This article describes the process of automating the data ingestion, processing, and insight generation using an interpretable Active Learning and AI pipeline. This work also describes the development of an interactive web portal (the NASA Meteor Shower portal) to facilitate the visualization of meteor radiant maps. To date, CAMS has discovered over 200 new meteor showers and has validated dozens of previously reported showers.
</details>
<details>
<summary>摘要</summary>
美国国家航空航天局（NASA）自2010年起投入了“全天空闪电观测计划”（CAMS），旨在通过多个国家和多个地点的低光照视频摄像机械triangulationeteor轨迹，以确定和预测下一次闪电流星雨的返回。该项目的任务是验证、发现和预测下一次闪电流星雨的返回。我们的研究旨在通过实施云端AI智能pipeline自动化数据处理和改进数据视图来提高发现率，并通过与公众合作监测闪电探测来提高发现率。这篇文章描述了使用可解释性活动学习和AIipeline自动化数据进入、处理和情况描述的过程。此外，这篇文章还描述了开发了NASA流星雨门户，以便促进流星 radiant map的可视化。至今，CAMS已经发现了200多个新的闪电流星雨，并验证了数十个之前报道的闪电流星雨。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Deep-Learning-for-Tumor-Dynamic-Modeling-and-Overall-Survival-Prediction-using-Neural-ODE"><a href="#Explainable-Deep-Learning-for-Tumor-Dynamic-Modeling-and-Overall-Survival-Prediction-using-Neural-ODE" class="headerlink" title="Explainable Deep Learning for Tumor Dynamic Modeling and Overall Survival Prediction using Neural-ODE"></a>Explainable Deep Learning for Tumor Dynamic Modeling and Overall Survival Prediction using Neural-ODE</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01362">http://arxiv.org/abs/2308.01362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Laurie, James Lu</li>
<li>for: 支持肿瘤疾病药物开发，提高预测性，实现个性化治疗和决策。</li>
<li>methods: 使用Tumor Dynamic Neural-ODE（TDNODE）作为具有药理知识的神经网络，从 longitudinal 肿瘤大小数据中发现模型。</li>
<li>results: TDNODE 能够减少现有模型的一个关键局限性，从截断数据中做不偏向预测。生成的 metrics 可以高度准确地预测患者的全身存活率（OS）。<details>
<summary>Abstract</summary>
While tumor dynamic modeling has been widely applied to support the development of oncology drugs, there remains a need to increase predictivity, enable personalized therapy, and improve decision-making. We propose the use of Tumor Dynamic Neural-ODE (TDNODE) as a pharmacology-informed neural network to enable model discovery from longitudinal tumor size data. We show that TDNODE overcomes a key limitation of existing models in its ability to make unbiased predictions from truncated data. The encoder-decoder architecture is designed to express an underlying dynamical law which possesses the fundamental property of generalized homogeneity with respect to time. Thus, the modeling formalism enables the encoder output to be interpreted as kinetic rate metrics, with inverse time as the physical unit. We show that the generated metrics can be used to predict patients' overall survival (OS) with high accuracy. The proposed modeling formalism provides a principled way to integrate multimodal dynamical datasets in oncology disease modeling.
</details>
<details>
<summary>摘要</summary>
traditional dynamic modeling has been widely used to support the development of oncology drugs, but there is still a need to improve predictability, enable personalized therapy, and make better decisions. we propose the use of Tumor Dynamic Neural-ODE (TDNODE) as a pharmacology-informed neural network to enable model discovery from longitudinal tumor size data. we show that TDNODE overcomes a key limitation of existing models by making unbiased predictions from truncated data. the encoder-decoder architecture is designed to express an underlying dynamical law that possesses the fundamental property of generalized homogeneity with respect to time. thus, the modeling formalism enables the encoder output to be interpreted as kinetic rate metrics, with inverse time as the physical unit. we show that the generated metrics can be used to predict patients' overall survival (os) with high accuracy. the proposed modeling formalism provides a principled way to integrate multimodal dynamical datasets in oncology disease modeling.
</details></li>
</ul>
<hr>
<h2 id="Compressed-and-distributed-least-squares-regression-convergence-rates-with-applications-to-Federated-Learning"><a href="#Compressed-and-distributed-least-squares-regression-convergence-rates-with-applications-to-Federated-Learning" class="headerlink" title="Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning"></a>Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01358">http://arxiv.org/abs/2308.01358</a></li>
<li>repo_url: None</li>
<li>paper_authors: Constantin Philippenko, Aymeric Dieuleveut</li>
<li>for:  investigate the impact of compression on stochastic gradient algorithms for machine learning, specifically in distributed and federated learning</li>
<li>methods:  analyze the convergence rates of several unbiased compression operators, and extend the results to the case of federated learning</li>
<li>results:  demonstrate that the limit variance term scales with $\mathrm{Tr}(\mathfrak{C}<em>{\mathrm{ania} H^{-1})&#x2F;K$, and analyze the dependency of $\mathfrak{C}</em>{\mathrm{ania}$ on the compression strategy and its impact on convergence in centralized and heterogeneous FL frameworks.<details>
<summary>Abstract</summary>
In this paper, we investigate the impact of compression on stochastic gradient algorithms for machine learning, a technique widely used in distributed and federated learning. We underline differences in terms of convergence rates between several unbiased compression operators, that all satisfy the same condition on their variance, thus going beyond the classical worst-case analysis. To do so, we focus on the case of least-squares regression (LSR) and analyze a general stochastic approximation algorithm for minimizing quadratic functions relying on a random field. We consider weak assumptions on the random field, tailored to the analysis (specifically, expected H\"older regularity), and on the noise covariance, enabling the analysis of various randomizing mechanisms, including compression. We then extend our results to the case of federated learning.   More formally, we highlight the impact on the convergence of the covariance $\mathfrak{C}_{\mathrm{ania}$ of the additive noise induced by the algorithm. We demonstrate despite the non-regularity of the stochastic field, that the limit variance term scales with $\mathrm{Tr}(\mathfrak{C}_{\mathrm{ania} H^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the number of iterations) generalizing the rate for the vanilla LSR case where it is $\sigma^2 \mathrm{Tr}(H H^{-1}) / K = \sigma^2 d / K$ (Bach and Moulines, 2013). Then, we analyze the dependency of $\mathfrak{C}_{\mathrm{ania}$ on the compression strategy and ultimately its impact on convergence, first in the centralized case, then in two heterogeneous FL frameworks.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了压缩对于分布式和联合学习中使用的梯度下降算法的影响。我们将不同的压缩算法比较，这些算法都满足同样的协方差Condition，因此超过了传统的最坏情况分析。为了这样做，我们将ocus on least-squares regression（LSR），并分析一种基于随机场的总体梯度下降算法来最小化quadratics函数。我们假设了随机场的假设（specifically, expected H\"older regularity）和噪声 covariance，使得可以分析不同的随机化机制，包括压缩。然后，我们将结果推广到联合学习中。更正式地，我们强调 covariance $\mathfrak{C}_{\mathrm{ania}$ 的添加噪声对算法的 converges impact。我们证明，即使随机场不规则， covariance $\mathfrak{C}_{\mathrm{ania}$ 的极限方差项与 $\mathrm{Tr}(\mathfrak{C}_{\mathrm{ania} H^{-1})/K$ 相似（where $H$ is the Hessian of the optimization problem and $K$ the number of iterations），这与 vanilla LSR 情况中的 rate $\sigma^2 \mathrm{Tr}(H H^{-1}) / K = \sigma^2 d / K$ （Bach and Moulines, 2013）相同。然后，我们分析了压缩策略对 covariance $\mathfrak{C}_{\mathrm{ania}$ 的影响，最初是在中央化环境中，然后在两个不同的多样化联合学习框架中进行分析。
</details></li>
</ul>
<hr>
<h2 id="More-Context-Less-Distraction-Visual-Classification-by-Inferring-and-Conditioning-on-Contextual-Attributes"><a href="#More-Context-Less-Distraction-Visual-Classification-by-Inferring-and-Conditioning-on-Contextual-Attributes" class="headerlink" title="More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes"></a>More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01313">http://arxiv.org/abs/2308.01313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/umd-huang-lab/perceptionclip">https://github.com/umd-huang-lab/perceptionclip</a></li>
<li>paper_authors: Bang An, Sicheng Zhu, Michael-Andrei Panaitescu-Liess, Chaithanya Kumar Mummadi, Furong Huang</li>
<li>for: This paper aims to improve zero-shot image classification using CLIP, by leveraging the model’s ability to understand visual concepts and natural language descriptions.</li>
<li>methods: The proposed method, called PerceptionCLIP, first infers contextual attributes (e.g., background) from an image, and then performs object classification conditioning on these attributes.</li>
<li>results: The proposed method achieves better generalization, group robustness, and interpretability compared to traditional zero-shot classification methods. For example, PerceptionCLIP with ViT-L&#x2F;14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.Here’s the simplified Chinese translation of the three key information points:</li>
<li>for: 这篇论文目的是使用CLIP提高零shot图像分类，通过利用模型对视觉概念和自然语言描述的能力。</li>
<li>methods: 提议的方法是名为PerceptionCLIP，它首先从图像中推理出上下文特征（例如背景），然后根据这些特征进行对象分类。</li>
<li>results: 提议的方法相比传统零shot分类方法，具有更好的泛化、群体稳定和可解释性。例如，PerceptionCLIP与ViT-L&#x2F;14结合使用，在水鸟数据集上提高了最差群组准确率16.5%，在 celebA 数据集上提高了3.5%。<details>
<summary>Abstract</summary>
CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question. This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information. Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP. Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them. Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability. For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.
</details>
<details>
<summary>摘要</summary>
CLIP，作为基础视言语模型，在零批图像分类中广泛使用，因为它能够理解多种视觉概念和自然语言描述。然而，如何充分利用CLIP的人类如意理解能力来实现更好的零批分类仍是一个开放问题。这篇论文启发自人类视觉过程：现代神经科学视野认为，在分类一个物体，人们首先推理出它的类型独立特征（如背景和方向），这些特征将物体与背景分离，然后根据这些信息进行决策。 inspirited by this， we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP. Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them. Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability. For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.
</details></li>
</ul>
<hr>
<h2 id="Lode-Encoder-AI-constrained-co-creativity"><a href="#Lode-Encoder-AI-constrained-co-creativity" class="headerlink" title="Lode Encoder: AI-constrained co-creativity"></a>Lode Encoder: AI-constrained co-creativity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01312">http://arxiv.org/abs/2308.01312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debosmita Bhaumik, Ahmed Khalifa, Julian Togelius</li>
<li>for: 这个论文是为了设计一个基于混合引导的平台游戏《寻宝 runner》的游戏等级创建系统。</li>
<li>methods: 这个系统使用多个自编码器，通过训练这些自编码器使得它们能够生成更像原始等级的设计。用户可以通过«油画»方式在系统提供的建议基础上创建和编辑等级。</li>
<li>results: 文章报道了这个系统的设计和训练过程，以及用户测试结果。<details>
<summary>Abstract</summary>
We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner. The system is built around several autoencoders which are trained on sets of Lode Runner levels. When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on. The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders. Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools. We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.
</details>
<details>
<summary>摘要</summary>
我们介绍Lode Encoder，一个基于混合式 init 的平台游戏吧 Runner 级别创建系统。该系统建立在多个自适应oder上，这些自适应oder在 Lode Runner 级别设计的集合上进行了训练。当用户提供设计时，每个自适应oder都会生成一个更加适合 Lode Runner 级别的版本。Lode Encoder 界面允许用户通过 '涂抹' 方式在自适应oder 提供的建议基础上创建和编辑级别。为了鼓励设计师探索新的可能性，系统没有传统的编辑工具。我们介绍了系统的设计和训练过程，以及用户测试。
</details></li>
</ul>
<hr>
<h2 id="Masked-and-Swapped-Sequence-Modeling-for-Next-Novel-Basket-Recommendation-in-Grocery-Shopping"><a href="#Masked-and-Swapped-Sequence-Modeling-for-Next-Novel-Basket-Recommendation-in-Grocery-Shopping" class="headerlink" title="Masked and Swapped Sequence Modeling for Next Novel Basket Recommendation in Grocery Shopping"></a>Masked and Swapped Sequence Modeling for Next Novel Basket Recommendation in Grocery Shopping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01308">http://arxiv.org/abs/2308.01308</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liming-7/mask-swap-nnbr">https://github.com/liming-7/mask-swap-nnbr</a></li>
<li>paper_authors: Ming Li, Mozhdeh Ariannezhad, Andrew Yates, Maarten de Rijke</li>
<li>for: 本研究强调的任务是提出一种新的下一个购物篮（NNBR）任务，即推荐一个只包含新品种的购物篮。</li>
<li>methods: 我们提出了一种简单的双向变换器购物篮推荐模型（BTBR），该模型直接模型了物品之间的相关性，并且可以在不同的购物篮中模型物品之间的相关性。</li>
<li>results: 我们通过对三个公开数据集进行了广泛的实验，并证明了BTBR和我们的面具策略和交换策略可以很好地提高NNBR任务的性能。<details>
<summary>Abstract</summary>
Next basket recommendation (NBR) is the task of predicting the next set of items based on a sequence of already purchased baskets. It is a recommendation task that has been widely studied, especially in the context of grocery shopping. In next basket recommendation (NBR), it is useful to distinguish between repeat items, i.e., items that a user has consumed before, and explore items, i.e., items that a user has not consumed before. Most NBR work either ignores this distinction or focuses on repeat items. We formulate the next novel basket recommendation (NNBR) task, i.e., the task of recommending a basket that only consists of novel items, which is valuable for both real-world application and NBR evaluation. We evaluate how existing NBR methods perform on the NNBR task and find that, so far, limited progress has been made w.r.t. the NNBR task. To address the NNBR task, we propose a simple bi-directional transformer basket recommendation model (BTBR), which is focused on directly modeling item-to-item correlations within and across baskets instead of learning complex basket representations. To properly train BTBR, we propose and investigate several masking strategies and training objectives: (i) item-level random masking, (ii) item-level select masking, (iii) basket-level all masking, (iv) basket-level explore masking, and (v) joint masking. In addition, an item-basket swapping strategy is proposed to enrich the item interactions within the same baskets. We conduct extensive experiments on three open datasets with various characteristics. The results demonstrate the effectiveness of BTBR and our masking and swapping strategies for the NNBR task. BTBR with a properly selected masking and swapping strategy can substantially improve NNBR performance.
</details>
<details>
<summary>摘要</summary>
下一个篮球推荐（NBR）任务是预测下一个序列中的项目，基于已经购买的篮球。这是一种广泛研究的推荐任务，特别是在超市购物中。在NBR任务中，分 distinguish between repeat items（已经消耗过的项目）和 explore items（未消耗过的项目）。大多数NBR工作 Either ignore this distinction or focus on repeat items。我们提出了下一个新型篮球推荐（NNBR）任务，即推荐一个只包含新品的篮球，这对实际应用和NBR评估都具有价值。我们评估了现有的NBR方法在NNBR任务中的表现，发现至今为止，对NNBR任务的进展有限。为解决NNBR任务，我们提出了一种简单的双向转换器篮球推荐模型（BTBR），这是直接模型item-to-item correlations within和across baskets，而不是学习复杂的篮球表示。为正确地训练BTBR，我们提出了和 investigate several masking strategies and training objectives：（i）item-level random masking，（ii）item-level select masking，（iii）basket-level all masking，（iv）basket-level explore masking，和（v）joint masking。此外，我们还提出了一种item-basket swapping strategy，以增强item interactions within the same baskets。我们对三个开放数据集进行了广泛的实验，结果表明BTBR和我们的masking和swapping策略对NNBR任务有效。BTBR WITH properly selected masking and swapping strategy can substantially improve NNBR performance。
</details></li>
</ul>
<hr>
<h2 id="Excitatory-Inhibitory-Balance-Emerges-as-a-Key-Factor-for-RBN-Performance-Overriding-Attractor-Dynamics"><a href="#Excitatory-Inhibitory-Balance-Emerges-as-a-Key-Factor-for-RBN-Performance-Overriding-Attractor-Dynamics" class="headerlink" title="Excitatory&#x2F;Inhibitory Balance Emerges as a Key Factor for RBN Performance, Overriding Attractor Dynamics"></a>Excitatory&#x2F;Inhibitory Balance Emerges as a Key Factor for RBN Performance, Overriding Attractor Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10831">http://arxiv.org/abs/2308.10831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emmanuel Calvet, Jean Rouat, Bertrand Reulet</li>
<li>for: 这个论文旨在研究Random Boolean Networks（RBNs）在某些特定的分布参数下的不同动态行为，以及这些动态行为如何影响计算性能。</li>
<li>methods: 作者使用Random Boolean Networks（RBNs）模型，并研究了不同的分布参数对计算性能的影响。</li>
<li>results: 研究发现，在某些特定的分布参数下，Random Boolean Networks（RBNs）可以具有多种不同的动态行为，其中一些动态行为可以提高计算性能。此外，研究还发现，不同的动态行为对计算性能的影响几乎没有关系。<details>
<summary>Abstract</summary>
Reservoir computing provides a time and cost-efficient alternative to traditional learning methods.Critical regimes, known as the "edge of chaos," have been found to optimize computational performance in binary neural networks. However, little attention has been devoted to studying reservoir-to-reservoir variability when investigating the link between connectivity, dynamics, and performance. As physical reservoir computers become more prevalent, developing a systematic approach to network design is crucial. In this article, we examine Random Boolean Networks (RBNs) and demonstrate that specific distribution parameters can lead to diverse dynamics near critical points. We identify distinct dynamical attractors and quantify their statistics, revealing that most reservoirs possess a dominant attractor. We then evaluate performance in two challenging tasks, memorization and prediction, and find that a positive excitatory balance produces a critical point with higher memory performance. In comparison, a negative inhibitory balance delivers another critical point with better prediction performance. Interestingly, we show that the intrinsic attractor dynamics have little influence on performance in either case.
</details>
<details>
<summary>摘要</summary>
rezhervoir computing 提供了一种时间和成本效率的代替方法，traditional learning methods 中的一种新的方法。critical regimes, known as the "edge of chaos," have been found to optimize computational performance in binary neural networks。However, little attention has been devoted to studying reservoir-to-reservoir variability when investigating the link between connectivity, dynamics, and performance。As physical reservoir computers become more prevalent, developing a systematic approach to network design is crucial。In this article, we examine Random Boolean Networks (RBNs) and demonstrate that specific distribution parameters can lead to diverse dynamics near critical points。We identify distinct dynamical attractors and quantify their statistics, revealing that most reservoirs possess a dominant attractor。We then evaluate performance in two challenging tasks, memorization and prediction, and find that a positive excitatory balance produces a critical point with higher memory performance。In comparison, a negative inhibitory balance delivers another critical point with better prediction performance。Interestingly, we show that the intrinsic attractor dynamics have little influence on performance in either case。
</details></li>
</ul>
<hr>
<h2 id="EmbeddingTree-Hierarchical-Exploration-of-Entity-Features-in-Embedding"><a href="#EmbeddingTree-Hierarchical-Exploration-of-Entity-Features-in-Embedding" class="headerlink" title="EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding"></a>EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01329">http://arxiv.org/abs/2308.01329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Zheng, Junpeng Wang, Chin-Chia Michael Yeh, Yujie Fan, Huiyuan Chen, Liang Wang, Wei Zhang</li>
<li>for: 这个论文主要是为了探讨嵌入学习算法中的特征编码方法，以及如何从 embedding 空间中提取 semantics 信息。</li>
<li>methods: 这个论文提出了一种嵌入探索算法 named EmbeddingTree，它可以将嵌入 vector 与实体特征之间的semantics关系进行结构化解释。同时， authors 也开发了一种基于 EmbeddingTree 的互动视觉工具，可以帮助用户探索高维 embedding 空间中的特征。</li>
<li>results: 作者们通过使用 EmbeddingTree 和互动视觉工具，可以从 embedding 空间中提取出更多的 semantics 信息，并且可以对 embedding 训练中的特征进行denoising&#x2F;注入。他们还通过对实际业务数据和公共30Music listening&#x2F;playlists数据集进行实验，证明了 EmbeddingTree 的效果和互动视觉工具的价值。<details>
<summary>Abstract</summary>
Embedding learning transforms discrete data entities into continuous numerical representations, encoding features/properties of the entities. Despite the outstanding performance reported from different embedding learning algorithms, few efforts were devoted to structurally interpreting how features are encoded in the learned embedding space. This work proposes EmbeddingTree, a hierarchical embedding exploration algorithm that relates the semantics of entity features with the less-interpretable embedding vectors. An interactive visualization tool is also developed based on EmbeddingTree to explore high-dimensional embeddings. The tool helps users discover nuance features of data entities, perform feature denoising/injecting in embedding training, and generate embeddings for unseen entities. We demonstrate the efficacy of EmbeddingTree and our visualization tool through embeddings generated for industry-scale merchant data and the public 30Music listening/playlists dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate_language: zh-CN</SYS>>Original text:“嵌入学习”将维度数据实体转化为连续数字表示，嵌入实体的特征/属性。尽管不同的嵌入学习算法在表现出色，但是对嵌入学习后得到的数字空间中的特征进行结构性解释却得到了少数努力。这项工作提出了“嵌入树”，一种嵌入探索算法，它将数据实体的 semantics 与嵌入向量相关联。此外，我们还开发了基于“嵌入树”的互动视觉化工具，帮助用户探索高维嵌入中的细节特征，进行嵌入训练中的特征杂谔/注入，并生成未经见过的嵌入。我们通过使用“嵌入树”和视觉化工具来验证嵌入树的有效性，并在行业级的商家数据和公共30Music的听众/播放列表数据集上进行了实践。Translated text in Simplified Chinese:“嵌入学习”将维度数据实体转化为连续数字表示，嵌入实体的特征/属性。尽管不同的嵌入学习算法在表现出色，但是对嵌入学习后得到的数字空间中的特征进行结构性解释却得到了少数努力。这项工作提出了“嵌入树”，一种嵌入探索算法，它将数据实体的 semantics 与嵌入向量相关联。此外，我们还开发了基于“嵌入树”的互动视觉化工具，帮助用户探索高维嵌入中的细节特征，进行嵌入训练中的特征杂谔/注入，并生成未经见过的嵌入。我们通过使用“嵌入树”和视觉化工具来验证嵌入树的有效性，并在行业级的商家数据和公共30Music的听众/播放列表数据集上进行了实践。
</details></li>
</ul>
<hr>
<h2 id="Investigation-on-Machine-Learning-Based-Approaches-for-Estimating-the-Critical-Temperature-of-Superconductors"><a href="#Investigation-on-Machine-Learning-Based-Approaches-for-Estimating-the-Critical-Temperature-of-Superconductors" class="headerlink" title="Investigation on Machine Learning Based Approaches for Estimating the Critical Temperature of Superconductors"></a>Investigation on Machine Learning Based Approaches for Estimating the Critical Temperature of Superconductors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01932">http://arxiv.org/abs/2308.01932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatin Abrar Shams, Rashed Hasan Ratul, Ahnaf Islam Naf, Syed Shaek Hossain Samir, Mirza Muntasir Nishat, Fahim Faisal, Md. Ashraful Hoque</li>
<li>for: 这篇论文主要是为了提出一种基于机器学习的方法来准确预测超导材料的 kritischer 温度。</li>
<li>methods: 该论文使用了一种叠加机器学习方法来训练自己，以便更好地预测超导材料的 kritischer 温度。</li>
<li>results: 与其他前一些可accessible的研究相比，该模型表现了一定的承诺性，其RMSE为9.68，R2值为0.922。<details>
<summary>Abstract</summary>
Superconductors have been among the most fascinating substances, as the fundamental concept of superconductivity as well as the correlation of critical temperature and superconductive materials have been the focus of extensive investigation since their discovery. However, superconductors at normal temperatures have yet to be identified. Additionally, there are still many unknown factors and gaps of understanding regarding this unique phenomenon, particularly the connection between superconductivity and the fundamental criteria to estimate the critical temperature. To bridge the gap, numerous machine learning techniques have been established to estimate critical temperatures as it is extremely challenging to determine. Furthermore, the need for a sophisticated and feasible method for determining the temperature range that goes beyond the scope of the standard empirical formula appears to be strongly emphasized by various machine-learning approaches. This paper uses a stacking machine learning approach to train itself on the complex characteristics of superconductive materials in order to accurately predict critical temperatures. In comparison to other previous accessible research investigations, this model demonstrated a promising performance with an RMSE of 9.68 and an R2 score of 0.922. The findings presented here could be a viable technique to shed new insight on the efficient implementation of the stacking ensemble method with hyperparameter optimization (HPO).
</details>
<details>
<summary>摘要</summary>
超导材料已经是最引人注目的物质之一，因为超导性的基本概念以及相关的极限温度和超导材料的关系，已经被广泛研究了多年。然而，在常规温度下的超导材料还没有被发现。此外，关于这一特有现象的多种未知因素和理解之间的连接，特别是计算极限温度的基本标准的关系，仍然存在很多未知和缺陷。为了填补这些缺陷，许多机器学习技术已经被开发出来，以便估算极限温度。此外，需要一种可行、可靠的方法来确定极限温度范围，这超出了标准的实验方程的范围。本文使用堆叠机器学习方法来训练自己，以便准确预测极限温度。与之前可 accessible 的研究比较，这个模型表现出了有前途的性能，RMSE 为 9.68，R2 分数为 0.922。这些发现可能对于改进堆叠ensemble方法与超参数优化（HPO）的实现有所帮助。
</details></li>
</ul>
<hr>
<h2 id="BRNES-Enabling-Security-and-Privacy-aware-Experience-Sharing-in-Multiagent-Robotic-and-Autonomous-Systems"><a href="#BRNES-Enabling-Security-and-Privacy-aware-Experience-Sharing-in-Multiagent-Robotic-and-Autonomous-Systems" class="headerlink" title="BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems"></a>BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01274">http://arxiv.org/abs/2308.01274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aralab-unr/brnes">https://github.com/aralab-unr/brnes</a></li>
<li>paper_authors: Md Tamjid Hossain, Hung Manh La, Shahriar Badsha, Anton Netchaev</li>
<li>for: 这篇论文是用于解决多智能体问题，尤其是在对抗攻击和推理攻击的情况下。</li>
<li>methods: 本论文使用了类似于专家给学习者的导师-学习者架构，并且提出了一个称为BRNES的新的多智能体学习框架，以确保学习者在对抗攻击和推理攻击的情况下能够获得更好的学习效果。</li>
<li>results: 本论文的实验结果显示， compared to the state-of-the-art frameworks, BRNES 可以更快地达到目标，并且在对抗攻击和推理攻击的情况下也能够获得更好的学习效果。具体来说，BRNES 比非隐私框架8.32倍 faster，并且比隐私框架1.41倍 faster。<details>
<summary>Abstract</summary>
Although experience sharing (ES) accelerates multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have so far relied on trusted environments and overlooked the possibility of adversarial manipulation and inference. Nevertheless, in a real-world setting, some Byzantine attackers, disguised as advisors, may provide false advice to the advisee and catastrophically degrade the overall learning performance. Also, an inference attacker, disguised as an advisee, may conduct several queries to infer the advisors' private information and make the entire ES process questionable in terms of privacy leakage. To address and tackle these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact. Furthermore, to keep the agent's private information safe from adversarial inference attacks, we leverage the local differential privacy (LDP)-induced noise during the ES process. Our experiments show that our framework outperforms the state-of-the-art in terms of the steps to goal, obtained reward, and time to goal metrics. Particularly, our evaluation shows that the proposed framework is 8.32x faster than the current non-private frameworks and 1.41x faster than the private frameworks in an adversarial setting.
</details>
<details>
<summary>摘要</summary>
尽管经验分享（ES）可以加速多智能学习（MARL）在顾问-被顾问框架下，但是在分散式多智能系统中应用ES的尝试都是在可信环境下进行，而忽略了恶意攻击和推理的可能性。然而，在实际场景中，一些拜占庭攻击者，装扮成顾问，可能为被顾问提供错误的建议，从而使整体学习性能受到极大的降低。此外，一个推理攻击者，装扮成被顾问，可能通过多次查询来推理顾问的私人信息，使整个ES过程成为隐私泄露的问题。为解决这些问题，我们提出了一种基于BRNES的新的MARL框架，它在每个被顾问 learning步骤中采用了动态邻居区选择和权重经验聚合技术来减少拜占庭攻击的影响。此外，为保护智能机器的私人信息免受恶意推理攻击，我们利用了本地差分隐私（LDP）induced的噪声在ES过程中。我们的实验表明，我们的框架比现有的非私钥框架快8.32倍，比私钥框架快1.41倍在恶意Setting中。
</details></li>
</ul>
<hr>
<h2 id="A-Probabilistic-Approach-to-Self-Supervised-Learning-using-Cyclical-Stochastic-Gradient-MCMC"><a href="#A-Probabilistic-Approach-to-Self-Supervised-Learning-using-Cyclical-Stochastic-Gradient-MCMC" class="headerlink" title="A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC"></a>A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01271">http://arxiv.org/abs/2308.01271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masoumeh Javanbakhat, Christoph Lippert</li>
<li>for: 本文提出了一种实用的 bayesian自适应学习方法，使用循环随机梯度汉姆验 Monte Carlo (cSGHMC) 方法来 aproximate高维、多模态 posterior 分布。</li>
<li>methods: 本文使用 Bayesian self-supervised learning 方法，并在高维 embedding 中置信度 posterior 分布。使用 cSGHMC 方法来 aproximate posterior 分布，并从 interpretable 和多样化的表示中获得了优化的表现。</li>
<li>results: 实验结果表明，通过约束 marginal  posterior 分布，bayesian self-supervised learning 方法在多种下游分类任务中具有显著的性能提升、calibration 和 out-of-distribution 检测。此外，在 SVHN 和 CIFAR-10  dataset 上，提出的方法也有效地检测了 out-of-distribution 样本。<details>
<summary>Abstract</summary>
In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种实用的极 probabilistic Bayesian自适应学习方法，即循环随机梯度汉堡 Monte Carlo（cSGHMC）。在这个框架中，我们将参数的自适应学习模型的参数置于一个高维度和多模态的 posterior 分布中，并使用 cSGHMC 来近似这个高维度和多模态的 posterior 分布。通过探索表征空间的表示，极 probabilistic Bayesian自适应学习可以生成可读取和多样化的表示。对这些表示的聚合具有显著提升性，可以在多种下游分类任务上实现更高的性能、评估和对外部数据集的检测。我们在多个分类任务上进行了多个数据集的实验，并证明了我们的提议方法在 SVHN 和 CIFAR-10 数据集上的外部数据集检测的效果。
</details></li>
</ul>
<hr>
<h2 id="Tirtha-–-An-Automated-Platform-to-Crowdsource-Images-and-Create-3D-Models-of-Heritage-Sites"><a href="#Tirtha-–-An-Automated-Platform-to-Crowdsource-Images-and-Create-3D-Models-of-Heritage-Sites" class="headerlink" title="Tirtha – An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites"></a>Tirtha – An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01246">http://arxiv.org/abs/2308.01246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smlab-niser/tirtha-public">https://github.com/smlab-niser/tirtha-public</a></li>
<li>paper_authors: Jyotirmaya Shivottam, Subhankar Mishra</li>
<li>for: 保护文化遗产（CH）场所的数字化保存是非常重要，以防止自然灾害或人类活动的损害。</li>
<li>methods: 创建CH场所的3D模型已经成为数字保存的流行方法，感谢计算机视觉和光ogramметry的进步。但是，这个过程 consume much time and money,并且通常需要专业设备和技能，尤其是在资源受限的发展国家。</li>
<li>results: 我们提出了Tirtha，一个基于网络的平台，通过协同拍摄图片来生成CH场所的3D模型。Tirtha使用了当前最好的结构from Motion（SfM）和多视图ステレオ（MVS）技术。它是可拓展、可cost-effective的，可以适应新的摄影技术的发展。Tirtha可以通过网络界面访问，并可以部署在本地或云端环境中。我们的案例研究表明，Tirtha可以成功地创建奥里萨邦印度的寺庙3D模型，使用了公共上传的图片。这些3D模型可以在Tirtha网站上查看、交互和下载。我们的工作希望通过提供大量公共上传的图片和3D重建，为计算机视觉、遗产保护和相关领域的研究提供数据集。总之，Tirtha是一步向数字保存的民主化，主要是在资源受限的发展国家。<details>
<summary>Abstract</summary>
Digital preservation of Cultural Heritage (CH) sites is crucial to protect them against damage from natural disasters or human activities. Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry. However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries. Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage. To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques. It is modular, extensible and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances. Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment. In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images. These models are available for viewing, interaction, and download on the Tirtha website. Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains. Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries.
</details>
<details>
<summary>摘要</summary>
针对文化遗产（CH）场景的数字保存是非常重要，以保护它们免受自然灾害或人类活动的损害。创建CH场景的3D模型已成为数字保存的流行方法，感谢计算机视觉和相机摄影渠道的进步。然而，这个过程占用时间、成本高，通常需要特殊的设备和专业知识，这在有限资源的发展国家中存在挑战。此外，缺乏开放的3D模型存储库，限制了研究和公众对遗产的参与和研究。为解决这些问题，我们提出了Tirtha，一个基于网络的平台，用于把文化遗产场景的图片集成为3D模型。Tirtha使用当前最佳的结构从运动（SfM）和多视图镜像（MVS）技术。它是可扩展、可cost-effective的，可以适应计算机视觉的进步。Tirtha通过网络界面访问，可以在本地部署或云端环境中部署。在我们的案例研究中，我们使用了拥有图片的拥有者来创建奥里萨（India）的寺庙3D模型。这些3D模型可以在Tirtha网站上查看、交互和下载。我们的工作的目标是提供一个包含了拥有图片和3D重建的数据集，用于计算机视觉、遗产保护和相关领域的研究。总之，Tirtha是一步向数字保存的民主化，主要在有限资源的发展国家。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/cs.LG_2023_08_03/" data-id="clogy1z4q00m2ffra3swjbn9j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/eess.IV_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T09:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/eess.IV_2023_08_03/">eess.IV - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Maximum-likelihood-estimation-in-ptychography-in-the-presence-of-Poisson-Gaussian-noise-statistics"><a href="#Maximum-likelihood-estimation-in-ptychography-in-the-presence-of-Poisson-Gaussian-noise-statistics" class="headerlink" title="Maximum-likelihood estimation in ptychography in the presence of Poisson-Gaussian noise statistics"></a>Maximum-likelihood estimation in ptychography in the presence of Poisson-Gaussian noise statistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02436">http://arxiv.org/abs/2308.02436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jacob Seifert, Yifeng Shao, Rens van Dam, Dorian Bouchet, Tristan van Leeuwen, Allard P. Mosk</li>
<li>for: 提高图像质量在低信号响应率（SNR）下</li>
<li>methods: 使用最大有希望估计来考虑摄像头读取噪声，并在梯度基础的ptychography优化中使用此方法</li>
<li>results: 根据实验和数值数据显示，该方法可以在困难噪声条件下提高图像重建质量，并且比传统方法更简单地实现<details>
<summary>Abstract</summary>
Optical measurements often exhibit mixed Poisson-Gaussian noise statistics, which hampers image quality, particularly under low signal-to-noise ratio (SNR) conditions. Computational imaging falls short in such situations when solely Poissonian noise statistics are assumed. In response to this challenge, we define a loss function that explicitly incorporates this mixed noise nature. By using maximum-likelihood estimation, we devise a practical method to account for camera readout noise in gradient-based ptychography optimization. Our results, based on both experimental and numerical data, demonstrate that this approach outperforms the conventional one, enabling enhanced image reconstruction quality under challenging noise conditions through a straightforward methodological adjustment.
</details>
<details>
<summary>摘要</summary>
光学测量 часто会表现出杂合波尔兹-加布斯噪声统计，这会妨碍图像质量，特别是在低信号噪声比（SNR）条件下。计算摄影时，当假设只有波尔兹噪声统计时，计算摄影会失败。为解决这个挑战，我们定义了一个损失函数，该函数直接表达杂合噪声性质。通过最大似然估计，我们开发了一种实用的方法，用于考虑摄像头读取噪声在梯度基础ptychography优化中的影响。我们的结果，基于实验和数值数据，表明该方法在挑战性的噪声条件下能够超越传统方法，提高图像重建质量。
</details></li>
</ul>
<hr>
<h2 id="Focus-on-Content-not-Noise-Improving-Image-Generation-for-Nuclei-Segmentation-by-Suppressing-Steganography-in-CycleGAN"><a href="#Focus-on-Content-not-Noise-Improving-Image-Generation-for-Nuclei-Segmentation-by-Suppressing-Steganography-in-CycleGAN" class="headerlink" title="Focus on Content not Noise: Improving Image Generation for Nuclei Segmentation by Suppressing Steganography in CycleGAN"></a>Focus on Content not Noise: Improving Image Generation for Nuclei Segmentation by Suppressing Steganography in CycleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01769">http://arxiv.org/abs/2308.01769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Utz, Tobias Weise, Maja Schlereth, Fabian Wagner, Mareike Thies, Mingxuan Gu, Stefan Uderhardt, Katharina Breininger</li>
<li>for: 这个论文的目的是提高CycleGAN在生成顺序图像的时候的数据质量，以便更好地进行核体分割任务。</li>
<li>methods: 这个论文使用了CycleGAN生成器，并通过降噪滤波来除去生成图像中的快速幂数信息，以提高生成图像和颗点mask之间的协调性。</li>
<li>results: 这个论文的实验结果表明，通过使用降噪滤波来除去生成图像中的快速幂数信息，可以提高生成的图像和颗点mask之间的协调性，并提高核体分割任务的性能。<details>
<summary>Abstract</summary>
Annotating nuclei in microscopy images for the training of neural networks is a laborious task that requires expert knowledge and suffers from inter- and intra-rater variability, especially in fluorescence microscopy. Generative networks such as CycleGAN can inverse the process and generate synthetic microscopy images for a given mask, thereby building a synthetic dataset. However, past works report content inconsistencies between the mask and generated image, partially due to CycleGAN minimizing its loss by hiding shortcut information for the image reconstruction in high frequencies rather than encoding the desired image content and learning the target task. In this work, we propose to remove the hidden shortcut information, called steganography, from generated images by employing a low pass filtering based on the DCT. We show that this increases coherence between generated images and cycled masks and evaluate synthetic datasets on a downstream nuclei segmentation task. Here we achieve an improvement of 5.4 percentage points in the F1-score compared to a vanilla CycleGAN. Integrating advanced regularization techniques into the CycleGAN architecture may help mitigate steganography-related issues and produce more accurate synthetic datasets for nuclei segmentation.
</details>
<details>
<summary>摘要</summary>
描述核体在微scopic影像中的标注是一项劳动密集的任务，需要专家知识和受到内部和外部评分变化的影响，尤其在染料微scopic中。生成网络如CycleGAN可以将过程逆转，生成基于给定的mask的合成微scopic影像，从而建立一个合成数据集。然而，过去的工作表明，生成的图像与mask之间存在内容不一致，部分由CycleGAN在高频范围内隐藏短cut信息来抑制图像重建的损失而不是编码所需的图像内容和学习目标任务。在这个工作中，我们提议从生成图像中除去隐藏的短cut信息，使用基于DCT的低通过滤波。我们发现，这会提高生成图像和cycled mask之间的协调性，并评估合成数据集在核体分割任务上的性能。在这里，我们实现了与vanilla CycleGAN相比的5.4个百分点的F1分数提高。可能通过在CycleGAN架构中 интегрирова高级规则化技术可以减少隐藏信息相关的问题，生成更准确的合成数据集 для核体分割任务。
</details></li>
</ul>
<hr>
<h2 id="NuInsSeg-A-Fully-Annotated-Dataset-for-Nuclei-Instance-Segmentation-in-H-E-Stained-Histological-Images"><a href="#NuInsSeg-A-Fully-Annotated-Dataset-for-Nuclei-Instance-Segmentation-in-H-E-Stained-Histological-Images" class="headerlink" title="NuInsSeg: A Fully Annotated Dataset for Nuclei Instance Segmentation in H&amp;E-Stained Histological Images"></a>NuInsSeg: A Fully Annotated Dataset for Nuclei Instance Segmentation in H&amp;E-Stained Histological Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01760">http://arxiv.org/abs/2308.01760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/masih4/nuinsseg">https://github.com/masih4/nuinsseg</a></li>
<li>paper_authors: Amirreza Mahbod, Christine Polak, Katharina Feldmann, Rumsha Khan, Katharina Gelles, Georg Dorffner, Ramona Woitek, Sepideh Hatamikia, Isabella Ellinger</li>
<li>for: 本研究的目的是提供一个大规模、完全手动标注的核体实例分割数据集（NuInsSeg），以便进行核体分割任务的自动化研究。</li>
<li>methods: 本研究使用了深度学习（DL）方法进行核体分割，并提供了一个大规模的手动标注数据集（NuInsSeg），以便训练和测试这些模型。</li>
<li>results: 本研究提供了一个大规模的手动标注数据集（NuInsSeg），包含665个图像割辑和超过30,000个手动标注的核体，以及一些涉及的不确定地域mask。<details>
<summary>Abstract</summary>
In computational pathology, automatic nuclei instance segmentation plays an essential role in whole slide image analysis. While many computerized approaches have been proposed for this task, supervised deep learning (DL) methods have shown superior segmentation performances compared to classical machine learning and image processing techniques. However, these models need fully annotated datasets for training which is challenging to acquire, especially in the medical domain. In this work, we release one of the biggest fully manually annotated datasets of nuclei in Hematoxylin and Eosin (H&E)-stained histological images, called NuInsSeg. This dataset contains 665 image patches with more than 30,000 manually segmented nuclei from 31 human and mouse organs. Moreover, for the first time, we provide additional ambiguous area masks for the entire dataset. These vague areas represent the parts of the images where precise and deterministic manual annotations are impossible, even for human experts. The dataset and detailed step-by-step instructions to generate related segmentation masks are publicly available at https://www.kaggle.com/datasets/ipateam/nuinsseg and https://github.com/masih4/NuInsSeg, respectively.
</details>
<details>
<summary>摘要</summary>
在计算生物学中，自动核体实例分割在整个染色体图像分析中扮演着关键角色。虽然许多计算机化方法已经被提议用于这个任务，但是深度学习（DL）方法在 segmentation 性能方面表现出色，特别是在医疗领域。然而，这些模型需要完全标注的数据集来训练，而在医疗领域获得这些数据集是困难的。在这项工作中，我们发布了一个包含665个图像区域和超过30,000个手动标注的核体的全部批处数据集，称为NuInsSeg。这个数据集包含31种人类和小鼠器官的HE染色图像。此外，我们还为整个数据集提供了首次的不确定区域面罩。这些不确定区域表示图像中 precisions和决定性的手动标注是不可能的，即使是人类专家。数据集和相关的生成 segmentation 面罩的详细步骤都公开在https://www.kaggle.com/datasets/ipateam/nuinsseg和https://github.com/masih4/NuInsSeg 上。
</details></li>
</ul>
<hr>
<h2 id="Reference-Free-Isotropic-3D-EM-Reconstruction-using-Diffusion-Models"><a href="#Reference-Free-Isotropic-3D-EM-Reconstruction-using-Diffusion-Models" class="headerlink" title="Reference-Free Isotropic 3D EM Reconstruction using Diffusion Models"></a>Reference-Free Isotropic 3D EM Reconstruction using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01594">http://arxiv.org/abs/2308.01594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyungryun Lee, Won-Ki Jeong</li>
<li>for:  overcome the limitations of anisotropic axial resolution in Electron Microscopy (EM) images</li>
<li>methods:  utilize 2D diffusion models for consistent 3D volume reconstruction, well-suited for highly downsampled data</li>
<li>results:  superiority of leveraging the generative prior compared to supervised learning methods, and feasibility for self-supervised reconstruction without any training data.Here’s the full text in Simplified Chinese:</li>
<li>for: 在电子顺差icroscopy（EM）图像中，因具有特定的探针特性，存在探针分辨率的方向性偏好，这会带来分析和下游任务的挑战。本文提出了基于分散模型的框架，可以突破需要参考数据或先验知识的限制。</li>
<li>methods: 我们的方法利用2D分散模型来一致地重建3D体积，适用于高度下采样的数据。我们进行了大量的实验，证明了基于生成器先验的方法在对比supervised学习方法的情况下表现更加稳定和优秀。此外，我们还证明了我们的方法在无参考数据的情况下进行自动重建是可能的。</li>
<li>results: 我们的实验结果表明，基于分散模型的方法可以在高度下采样的情况下提供更高质量的重建结果，并且在无参考数据的情况下进行自动重建也是可能的。<details>
<summary>Abstract</summary>
Electron microscopy (EM) images exhibit anisotropic axial resolution due to the characteristics inherent to the imaging modality, presenting challenges in analysis and downstream tasks.In this paper, we propose a diffusion-model-based framework that overcomes the limitations of requiring reference data or prior knowledge about the degradation process. Our approach utilizes 2D diffusion models to consistently reconstruct 3D volumes and is well-suited for highly downsampled data. Extensive experiments conducted on two public datasets demonstrate the robustness and superiority of leveraging the generative prior compared to supervised learning methods. Additionally, we demonstrate our method's feasibility for self-supervised reconstruction, which can restore a single anisotropic volume without any training data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DMDC-Dynamic-mask-based-dual-camera-design-for-snapshot-Hyperspectral-Imaging"><a href="#DMDC-Dynamic-mask-based-dual-camera-design-for-snapshot-Hyperspectral-Imaging" class="headerlink" title="DMDC: Dynamic-mask-based dual camera design for snapshot Hyperspectral Imaging"></a>DMDC: Dynamic-mask-based dual camera design for snapshot Hyperspectral Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01541">http://arxiv.org/abs/2308.01541</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/caizeyu1992/dmdc">https://github.com/caizeyu1992/dmdc</a></li>
<li>paper_authors: Zeyu Cai, Chengqian Jin, Feipeng Da</li>
<li>for: 提高coded aperture snapshot spectral imaging（CASSI）中深度学习方法的性能。</li>
<li>methods: 使用动态马斯克基于双相机系统，包括RGB相机和CASSI系统，并在其中运行。首先，系统通过RGB图像学习场景中的空间特征分布，然后使用SLM编码场景，并最后将RGB和CASSI图像传递给网络进行重建。设计了DMDC-net，包括一个小规模CNN基于动态马斯克的动态调整网络和一个多模式重建网络。</li>
<li>results: 对多个数据集进行了广泛的实验，并达到了与SOTA的 более чем9dB PSNR提升。<details>
<summary>Abstract</summary>
Deep learning methods are developing rapidly in coded aperture snapshot spectral imaging (CASSI). The number of parameters and FLOPs of existing state-of-the-art methods (SOTA) continues to increase, but the reconstruction accuracy improves slowly. Current methods still face two problems: 1) The performance of the spatial light modulator (SLM) is not fully developed due to the limitation of fixed Mask coding. 2) The single input limits the network performance. In this paper we present a dynamic-mask-based dual camera system, which consists of an RGB camera and a CASSI system running in parallel. First, the system learns the spatial feature distribution of the scene based on the RGB images, then instructs the SLM to encode each scene, and finally sends both RGB and CASSI images to the network for reconstruction. We further designed the DMDC-net, which consists of two separate networks, a small-scale CNN-based dynamic mask network for dynamic adjustment of the mask and a multimodal reconstruction network for reconstruction using RGB and CASSI measurements. Extensive experiments on multiple datasets show that our method achieves more than 9 dB improvement in PSNR over the SOTA. (https://github.com/caizeyu1992/DMDC)
</details>
<details>
<summary>摘要</summary>
深度学习方法在coded aperture snapshot spectral imaging（CASSI）领域得到了极速的发展。现有状态的方法（SOTA）中的参数和FLOPs继续增加，但是重建精度逐渐提高。现有方法仍然面临两个问题：1）SLM（光学掩模）的性能尚未得到完全发展，因为固定的掩码编码有限制。2）单输入限制网络的性能。在本文中，我们提出了动态掩码基于双摄像头系统，该系统由RGB摄像头和CASSI系统在平行运行。首先，系统通过RGB图像学习场景中的空间特征分布，然后对场景进行编码，并将RGB和CASSI图像发送给网络进行重建。我们还设计了DMDC-net，它包括两个独立的网络：一个小规模的CNN基于动态掩码网络用于动态调整掩码，以及一个多模式重建网络用于使用RGB和CASSI测量进行重建。我们对多个数据集进行了广泛的实验，结果表明，我们的方法可以与SOTA比进行9dB以上的PSNR提高。（https://github.com/caizeyu1992/DMDC）
</details></li>
</ul>
<hr>
<h2 id="Numerical-Uncertainty-of-Convolutional-Neural-Networks-Inference-for-Structural-Brain-MRI-Analysis"><a href="#Numerical-Uncertainty-of-Convolutional-Neural-Networks-Inference-for-Structural-Brain-MRI-Analysis" class="headerlink" title="Numerical Uncertainty of Convolutional Neural Networks Inference for Structural Brain MRI Analysis"></a>Numerical Uncertainty of Convolutional Neural Networks Inference for Structural Brain MRI Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01939">http://arxiv.org/abs/2308.01939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Inés Gonzalez Pepe, Vinuyan Sivakolunthu, Hae Lang Park, Yohan Chatelain, Tristan Glatard</li>
<li>for: 这 paper investigates the numerical uncertainty of Convolutional Neural Networks (CNNs) inference for structural brain MRI analysis.</li>
<li>methods: 这 paper applies Random Rounding – a stochastic arithmetic technique – to CNN models employed in non-linear registration (SynthMorph) and whole-brain segmentation (FastSurfer), and compares the resulting numerical uncertainty to the one measured in a reference image-processing pipeline (FreeSurfer recon-all).</li>
<li>results: Results obtained on 32 representative subjects show that CNN predictions are substantially more accurate numerically than traditional image-processing results (non-linear registration: 19 vs 13 significant bits on average; whole-brain segmentation: 0.99 vs 0.92 S{\o}rensen-Dice score on average), which suggests a better reproducibility of CNN results across execution environments.<details>
<summary>Abstract</summary>
This paper investigates the numerical uncertainty of Convolutional Neural Networks (CNNs) inference for structural brain MRI analysis. It applies Random Rounding -- a stochastic arithmetic technique -- to CNN models employed in non-linear registration (SynthMorph) and whole-brain segmentation (FastSurfer), and compares the resulting numerical uncertainty to the one measured in a reference image-processing pipeline (FreeSurfer recon-all). Results obtained on 32 representative subjects show that CNN predictions are substantially more accurate numerically than traditional image-processing results (non-linear registration: 19 vs 13 significant bits on average; whole-brain segmentation: 0.99 vs 0.92 S{\o}rensen-Dice score on average), which suggests a better reproducibility of CNN results across execution environments.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TDMD-A-Database-for-Dynamic-Color-Mesh-Subjective-and-Objective-Quality-Explorations"><a href="#TDMD-A-Database-for-Dynamic-Color-Mesh-Subjective-and-Objective-Quality-Explorations" class="headerlink" title="TDMD: A Database for Dynamic Color Mesh Subjective and Objective Quality Explorations"></a>TDMD: A Database for Dynamic Color Mesh Subjective and Objective Quality Explorations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01499">http://arxiv.org/abs/2308.01499</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Yang, Joel Jung, Timon Deschamps, Xiaozhong Xu, Shan Liu</li>
<li>for: 这个论文的目的是为了开发对动态颜色网格（DCM）的 объектив评价指标，以及研究Typical distortions对DCM的影响。</li>
<li>methods: 该论文使用了Tencent - dynamic colored mesh database（TDMD），包括8个参考DCM对象和6种Typical distortions。通过处理视频序列（PVS），实现了大规模主观实验，得到了303个扭曲DCM样本，并对其进行了评分。</li>
<li>results: 研究发现，不同类型的扭曲会对人类对DCM的评价产生不同的影响。此外，该论文还评估了三种当今最佳的对metric，包括图像基于、点基于和视频基于的metric，并对其在实际应用中的选择提供了建议。<details>
<summary>Abstract</summary>
Dynamic colored meshes (DCM) are widely used in various applications; however, these meshes may undergo different processes, such as compression or transmission, which can distort them and degrade their quality. To facilitate the development of objective metrics for DCMs and study the influence of typical distortions on their perception, we create the Tencent - dynamic colored mesh database (TDMD) containing eight reference DCM objects with six typical distortions. Using processed video sequences (PVS) derived from the DCM, we have conducted a large-scale subjective experiment that resulted in 303 distorted DCM samples with mean opinion scores, making the TDMD the largest available DCM database to our knowledge. This database enabled us to study the impact of different types of distortion on human perception and offer recommendations for DCM compression and related tasks. Additionally, we have evaluated three types of state-of-the-art objective metrics on the TDMD, including image-based, point-based, and video-based metrics, on the TDMD. Our experimental results highlight the strengths and weaknesses of each metric, and we provide suggestions about the selection of metrics in practical DCM applications. The TDMD will be made publicly available at the following location: https://multimedia.tencent.com/resources/tdmd.
</details>
<details>
<summary>摘要</summary>
“动态颜色网格”（DCM）在各种应用中广泛使用，但这些网格可能会经历不同的处理过程，如压缩或传输，这会导致它们的质量下降。为了促进DCM的 объектив评价和研究不同类型的扭曲对人类感知的影响，我们创建了腾讯——动态颜色网格数据库（TDMD），包含8个参考DCM对象和6种典型的扭曲。使用来自DCM的处理视频序列（PVS），我们进行了大规模的主观实验，得到了303个扭曲DCM样本，其中每个样本有平均意见分数，这使得TDMD成为我们所知道的最大的DCM数据库。这个数据库允许我们研究不同类型的扭曲对人类感知的影响，并提供了DCM压缩和相关任务的建议。此外，我们还评估了三种现状最佳的对metric在TDMD上，包括图像基于、点基于和视频基于的metric。我们的实验结果显示了每种metric的优缺点，并提供了实际应用中metric选择的建议。TDMD将于以下地址公开：https://multimedia.tencent.com/resources/tdmd。”
</details></li>
</ul>
<hr>
<h2 id="Estimation-of-motion-blur-kernel-parameters-using-regression-convolutional-neural-networks"><a href="#Estimation-of-motion-blur-kernel-parameters-using-regression-convolutional-neural-networks" class="headerlink" title="Estimation of motion blur kernel parameters using regression convolutional neural networks"></a>Estimation of motion blur kernel parameters using regression convolutional neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01381">http://arxiv.org/abs/2308.01381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luis G. Varela, Laura E. Boucheron, Steven Sandoval, David Voelz, Abu Bucker Siddik</li>
<li>for: 本研究旨在拟合线性运动模糊图像中的杂乱参数。</li>
<li>methods: 本研究使用神经网络进行回归预测，以估算线性运动模糊图像中的杂乱参数。</li>
<li>results: 研究表明，线性运动模糊图像中的杂乱参数与杂乱程度和方向之间存在着密切的关系。这种关系可以被利用来在uniformed motion blur images中进行杂乱参数的回归预测。<details>
<summary>Abstract</summary>
Many deblurring and blur kernel estimation methods use MAP or classification deep learning techniques to sharpen an image and predict the blur kernel. We propose a regression approach using neural networks to predict the parameters of linear motion blur kernels. These kernels can be parameterized by its length of blur and the orientation of the blur.This paper will analyze the relationship between length and angle of linear motion blur. This analysis will help establish a foundation to using regression prediction in uniformed motion blur images.
</details>
<details>
<summary>摘要</summary>
很多锐化和杂化kernel估计方法使用MAP或分类深度学习技术来锐化图像和预测杂化kernel。我们提议使用回归方法使用神经网络预测线性运动杂化kernel的参数。这些kernel可以由杂化的长度和杂化方向来参数化。本文将分析线性运动杂化中长度和角度之间的关系，以Establish a foundation for using regression prediction in uniformed motion blur images。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="ELIXR-Towards-a-general-purpose-X-ray-artificial-intelligence-system-through-alignment-of-large-language-models-and-radiology-vision-encoders"><a href="#ELIXR-Towards-a-general-purpose-X-ray-artificial-intelligence-system-through-alignment-of-large-language-models-and-radiology-vision-encoders" class="headerlink" title="ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders"></a>ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01317">http://arxiv.org/abs/2308.01317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shawn Xu, Lin Yang, Christopher Kelly, Marcin Sieniek, Timo Kohlberger, Martin Ma, Wei-Hung Weng, Attila Kiraly, Sahar Kazemzadeh, Zakkai Melamed, Jungyeon Park, Patricia Strachan, Yun Liu, Chuck Lau, Preeti Singh, Christina Chen, Mozziyar Etemadi, Sreenivasa Raju Kalidindi, Yossi Matias, Katherine Chou, Greg S. Corrado, Shravya Shetty, Daniel Tse, Shruthi Prabhakara, Daniel Golden, Rory Pilgrim, Krish Eswaran, Andrew Sellergren</li>
<li>For: The paper is written for the task of developing a lightweight adapter architecture for chest X-ray (CXR) classification and vision-language tasks using a fixed language model (PaLM 2) and a language-aligned image encoder.* Methods: The paper uses a combination of a language-aligned image encoder and a fixed large language model (PaLM 2) to perform zero-shot CXR classification, data-efficient CXR classification, and semantic search tasks. The authors train the adapter architecture using images paired with corresponding free-text radiology reports from the MIMIC-CXR dataset.* Results: The paper achieves state-of-the-art performance on zero-shot CXR classification (mean AUC of 0.850 across 13 findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898 across five findings for 1% and 10% training data), and semantic search (0.76 normalized discounted cumulative gain across nineteen queries, including perfect retrieval on twelve of them). The authors also demonstrate the promise of ELIXR on CXR vision-language tasks, achieving overall accuracies of 58.7% and 62.5% on visual question answering and report quality assurance tasks, respectively.<details>
<summary>Abstract</summary>
Our approach, which we call Embeddings for Language/Image-aligned X-Rays, or ELIXR, leverages a language-aligned image encoder combined or grafted onto a fixed LLM, PaLM 2, to perform a broad range of tasks. We train this lightweight adapter architecture using images paired with corresponding free-text radiology reports from the MIMIC-CXR dataset. ELIXR achieved state-of-the-art performance on zero-shot chest X-ray (CXR) classification (mean AUC of 0.850 across 13 findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898 across five findings (atelectasis, cardiomegaly, consolidation, pleural effusion, and pulmonary edema) for 1% (~2,200 images) and 10% (~22,000 images) training data), and semantic search (0.76 normalized discounted cumulative gain (NDCG) across nineteen queries, including perfect retrieval on twelve of them). Compared to existing data-efficient methods including supervised contrastive learning (SupCon), ELIXR required two orders of magnitude less data to reach similar performance. ELIXR also showed promise on CXR vision-language tasks, demonstrating overall accuracies of 58.7% and 62.5% on visual question answering and report quality assurance tasks, respectively. These results suggest that ELIXR is a robust and versatile approach to CXR AI.
</details>
<details>
<summary>摘要</summary>
我们的方法，我们称之为语言/图像对接X射线（ELIXR），利用一个语言对接图像编码器与 fixes LLM（PaLM 2）结合，以实现广泛的任务。我们在使用图像和对应的自由文本医学报告从 MIMIC-CXR 数据集进行训练这个轻量级适配器建筑。ELIXR 在零shot 肺X射线（CXR）分类中获得了状态机器的表现（平均 AUC 为 0.850，涵盖 13 个发现），以及数据效率 CXR 分类（平均 AUCs 为 0.893 和 0.898，涵盖五个发现（胸腔缺失、心肺肥大、混合、肺液腔和肺泡），对 1% （约 2,200 张图像）和 10% （约 22,000 张图像）训练数据）。此外，ELIXR 还在 CXR 视言语任务中表现良好，其总准确率为 58.7% 和 62.5%，分别在视问题回答和报告质量签名任务中。这些结果表明 ELIXR 是一种可靠和多样的 CXR AI 方法。
</details></li>
</ul>
<hr>
<h2 id="A-vision-transformer-based-framework-for-knowledge-transfer-from-multi-modal-to-mono-modal-lymphoma-subtyping-models"><a href="#A-vision-transformer-based-framework-for-knowledge-transfer-from-multi-modal-to-mono-modal-lymphoma-subtyping-models" class="headerlink" title="A vision transformer-based framework for knowledge transfer from multi-modal to mono-modal lymphoma subtyping models"></a>A vision transformer-based framework for knowledge transfer from multi-modal to mono-modal lymphoma subtyping models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01328">http://arxiv.org/abs/2308.01328</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bilel Guetarni, Feryal Windal, Halim Benhabiles, Marianne Petit, Romain Dubois, Emmanuelle Leteurtre, Dominique Collard</li>
<li>for: 这个研究的目的是为了提出一种基于整个报告图像（Whole Slide Image，WSI）的深度学习模型，用于分类混合大细胞淋巴癌（Diffuse Large B-Cell Lymphoma，DLBCL）类型。</li>
<li>methods: 我们提出了一种视transformer基本框架，用于从高分辨率WSIs中分类DLBCL类型。我们还提出了一种多模式 architectures，用于训练一个分类器模型从多个WSI模式。此外，我们还使用了知识储存机制，以有效地驱动分类器的学习。</li>
<li>results: 我们的实验研究表明，我们的单模式分类器模型在157名患者的数据集上表现出色，超过了6个最近的State-of-the-art方法。此外，我们Estimated一个力学律曲线，表明我们的分类器模型只需要一定的更多的患者数据来进行训练，以达到与IHC技术相同的诊断精度。<details>
<summary>Abstract</summary>
Determining lymphoma subtypes is a crucial step for better patients treatment targeting to potentially increase their survival chances. In this context, the existing gold standard diagnosis method, which is based on gene expression technology, is highly expensive and time-consuming making difficult its accessibility. Although alternative diagnosis methods based on IHC (immunohistochemistry) technologies exist (recommended by the WHO), they still suffer from similar limitations and are less accurate. WSI (Whole Slide Image) analysis by deep learning models showed promising new directions for cancer diagnosis that would be cheaper and faster than existing alternative methods. In this work, we propose a vision transformer-based framework for distinguishing DLBCL (Diffuse Large B-Cell Lymphoma) cancer subtypes from high-resolution WSIs. To this end, we propose a multi-modal architecture to train a classifier model from various WSI modalities. We then exploit this model through a knowledge distillation mechanism for efficiently driving the learning of a mono-modal classifier. Our experimental study conducted on a dataset of 157 patients shows the promising performance of our mono-modal classification model, outperforming six recent methods from the state-of-the-art dedicated for cancer classification. Moreover, the power-law curve, estimated on our experimental data, shows that our classification model requires a reasonable number of additional patients for its training to potentially reach identical diagnosis accuracy as IHC technologies.
</details>
<details>
<summary>摘要</summary>
确定淋巴癌 subclass 是诊断的关键 step 以提高患者治疗的可能性，并增加生存机会。在这种情况下，现有的黄金标准诊断方法，基于基因表达技术，是非常昂贵和时间consuming，使得它的可 accessibility 受限。虽然基于 IHC（免疫 histochemistry）技术的诊断方法存在，但它们仍然受到类似的限制，并且精度较低。 WSI（整个报告图像）分析方法，基于深入学习模型，显示出了可能更加便宜和更快的诊断方法。在这种工作中，我们提出了基于视Transformer的框架，用于从高分辨率 WSI 中分类Diffuse Large B-Cell Lymphoma（淋巴癌）亚种。为此，我们提出了多modal 架构，用于训练一个分类器模型。然后，我们利用知识储存机制，以高效地驱动这个模型的学习。我们的实验研究，在157名患者的 dataset 上进行，显示了我们的单Modal 分类模型在诊断方面的出色表现，超过了最近六种专门为抑癌诊断而设计的方法。此外，我们对实验数据进行了power-law 曲线估计，显示我们的分类模型需要一个合理的数量的更多患者来进行训练，以达到与 IHC 技术相同的诊断精度。
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Season-and-Solar-Specificity-into-Renderings-made-by-a-NeRF-Architecture-using-Satellite-Images"><a href="#Incorporating-Season-and-Solar-Specificity-into-Renderings-made-by-a-NeRF-Architecture-using-Satellite-Images" class="headerlink" title="Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images"></a>Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01262">http://arxiv.org/abs/2308.01262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/enterprisecv-6/season-nerf">https://github.com/enterprisecv-6/season-nerf</a></li>
<li>paper_authors: Michael Gableman, Avinash Kak</li>
<li>for: 这项研究的目的是使用卫星图像进行NeRF框架中的场景从不同视点渲染，并考虑太阳角度。</li>
<li>methods: 该研究使用Shadow NeRF和Sat-NeRF的框架，并引入一个时间年份输入变量，以教导网络渲染季节特征。</li>
<li>results: 该研究可以准确地渲染新视点中的场景，生成高程图，预测阴影，并独立地渲染季节特征和阴影。<details>
<summary>Abstract</summary>
As a result of Shadow NeRF and Sat-NeRF, it is possible to take the solar angle into account in a NeRF-based framework for rendering a scene from a novel viewpoint using satellite images for training. Our work extends those contributions and shows how one can make the renderings season-specific. Our main challenge was creating a Neural Radiance Field (NeRF) that could render seasonal features independently of viewing angle and solar angle while still being able to render shadows. We teach our network to render seasonal features by introducing one more input variable -- time of the year. However, the small training datasets typical of satellite imagery can introduce ambiguities in cases where shadows are present in the same location for every image of a particular season. We add additional terms to the loss function to discourage the network from using seasonal features for accounting for shadows. We show the performance of our network on eight Areas of Interest containing images captured by the Maxar WorldView-3 satellite. This evaluation includes tests measuring the ability of our framework to accurately render novel views, generate height maps, predict shadows, and specify seasonal features independently from shadows. Our ablation studies justify the choices made for network design parameters.
</details>
<details>
<summary>摘要</summary>
因为阴影NeRF和Sat-NeRF，可以使用卫星图像进行训练，以渲染场景从不同视点的 novel 视图。我们的工作是对这些贡献的扩展，并表明如何使渲染季节化特征独立于视角和太阳角。我们的主要挑战是创建一个能够独立地渲染季节特征而不是视角和太阳角的神经辐射场（NeRF）。我们教育我们的网络如何渲染季节特征，通过引入一个额外的输入变量——时间年份。然而，卫星图像的小训练集通常会导致在同一个季节中的阴影存在于每个图像中，这会引入ambiguity。我们添加了额外的损失函数项来避免网络使用季节特征来补偿阴影。我们在八个 Area of Interest 中测试了我们的框架，包括测试渲染新视图、生成高度图、预测阴影和独立地渲染季节特征。我们的剖析研究证明了我们的网络设计参数的选择。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/eess.IV_2023_08_03/" data-id="clogy1z8i012jffra3d2v3nzy" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/02/cs.SD_2023_08_02/" class="article-date">
  <time datetime="2023-08-02T15:00:00.000Z" itemprop="datePublished">2023-08-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/02/cs.SD_2023_08_02/">cs.SD - 2023-08-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Music-De-limiter-Networks-via-Sample-wise-Gain-Inversion"><a href="#Music-De-limiter-Networks-via-Sample-wise-Gain-Inversion" class="headerlink" title="Music De-limiter Networks via Sample-wise Gain Inversion"></a>Music De-limiter Networks via Sample-wise Gain Inversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01187">http://arxiv.org/abs/2308.01187</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jeonchangbin49/de-limiter">https://github.com/jeonchangbin49/de-limiter</a></li>
<li>paper_authors: Chang-Bin Jeon, Kyogu Lee</li>
<li>for: 这篇论文旨在解决音乐频谱压缩（loudness war）问题，即尽可能地提高音乐压缩后的质量，而不是增加压缩级别。</li>
<li>methods: 本论文提出了一种基于限制器的音乐去限制网络，使用sample-wise gain inversion（SGI）原理来实现。SGI是一种样本级别的增量降噪，可以减少音乐压缩后的噪音。</li>
<li>results: 根据实验结果，提出的去限制网络可以高效地提高音乐质量，SI-SDR值达23.8dB。此外， authors还提供了一个大量的训练数据集（musdb-XL-train），可以帮助实现实际中友好的去限制网络。<details>
<summary>Abstract</summary>
The loudness war, an ongoing phenomenon in the music industry characterized by the increasing final loudness of music while reducing its dynamic range, has been a controversial topic for decades. Music mastering engineers have used limiters to heavily compress and make music louder, which can induce ear fatigue and hearing loss in listeners. In this paper, we introduce music de-limiter networks that estimate uncompressed music from heavily compressed signals. Inspired by the principle of a limiter, which performs sample-wise gain reduction of a given signal, we propose the framework of sample-wise gain inversion (SGI). We also present the musdb-XL-train dataset, consisting of 300k segments created by applying a commercial limiter plug-in for training real-world friendly de-limiter networks. Our proposed de-limiter network achieves excellent performance with a scale-invariant source-to-distortion ratio (SI-SDR) of 23.8 dB in reconstructing musdb-HQ from musdb- XL data, a limiter-applied version of musdb-HQ. The training data, codes, and model weights are available in our repository (https://github.com/jeonchangbin49/De-limiter).
</details>
<details>
<summary>摘要</summary>
“喧嚣战争”，音乐业界一直持续的现象，表示音乐的最终强度不断增加，同时降低其 dinamic range。音乐调制工程师使用限制器将音乐更加压缩和更加 loud，这可能导致耳感觉疲劳和听觉损伤。在这篇论文中，我们介绍音乐去限制网络，将压缩后的音乐转换为未压缩的音乐。我们的方法基于限制器的原理，实现 sample-wise 几何减少 (SGI)。我们还提供 musdb-XL-train 数据集，包括 300 万个段落，通过商业限制器插件训练真实世界友善的去限制网络。我们的提案的去限制网络实现了 excellent 性能，si-sdr 23.8 dB 在重建 musdb-HQ  FROM musdb-XL 数据中。训练数据、代码和模型预测项目可以从我们的存储库 (https://github.com/jeonchangbin49/De-limiter) 获取。
</details></li>
</ul>
<hr>
<h2 id="Inaudible-Adversarial-Perturbation-Manipulating-the-Recognition-of-User-Speech-in-Real-Time"><a href="#Inaudible-Adversarial-Perturbation-Manipulating-the-Recognition-of-User-Speech-in-Real-Time" class="headerlink" title="Inaudible Adversarial Perturbation: Manipulating the Recognition of User Speech in Real Time"></a>Inaudible Adversarial Perturbation: Manipulating the Recognition of User Speech in Real Time</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01040">http://arxiv.org/abs/2308.01040</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinfeng Li, Chen Yan, Xuancun Lu, Zihan Zeng, Xiaoyu Ji, Wenyuan Xu<br>for: 这篇论文旨在扩展现有的攻击途径，使其适用于用户存在的实际场景。methods: 这篇论文提出了一种使用无声振荡（IAP）攻击语音识别系统的方法，通过在用户说话时传输 ultrasound 来 manipulate ASR 输出。results: 实验结果表明，VRIFLE 可以在不同的配置和防御策略下实现有效的真实时操纵，并且可以在用户发生干扰时仍然保持有效。<details>
<summary>Abstract</summary>
Automatic speech recognition (ASR) systems have been shown to be vulnerable to adversarial examples (AEs). Recent success all assumes that users will not notice or disrupt the attack process despite the existence of music/noise-like sounds and spontaneous responses from voice assistants. Nonetheless, in practical user-present scenarios, user awareness may nullify existing attack attempts that launch unexpected sounds or ASR usage. In this paper, we seek to bridge the gap in existing research and extend the attack to user-present scenarios. We propose VRIFLE, an inaudible adversarial perturbation (IAP) attack via ultrasound delivery that can manipulate ASRs as a user speaks. The inherent differences between audible sounds and ultrasounds make IAP delivery face unprecedented challenges such as distortion, noise, and instability. In this regard, we design a novel ultrasonic transformation model to enhance the crafted perturbation to be physically effective and even survive long-distance delivery. We further enable VRIFLE's robustness by adopting a series of augmentation on user and real-world variations during the generation process. In this way, VRIFLE features an effective real-time manipulation of the ASR output from different distances and under any speech of users, with an alter-and-mute strategy that suppresses the impact of user disruption. Our extensive experiments in both digital and physical worlds verify VRIFLE's effectiveness under various configurations, robustness against six kinds of defenses, and universality in a targeted manner. We also show that VRIFLE can be delivered with a portable attack device and even everyday-life loudspeakers.
</details>
<details>
<summary>摘要</summary>
自动语音识别（ASR）系统已经被证明是易受到敌意例验（AE）的威胁。现有的成功假设用户会不注意或中断攻击过程，即使存在音乐/噪声类的声音和声音助手的自发响应。然而，在实际用户存在的场景下，用户的注意力可能会使攻击无法进行，因此我们在这篇论文中尝试将攻击扩展到用户存在的场景。我们提议了一种不可见的恶意扰动（IAP）攻击方法，通过ultrasound发送来控制ASR。由于听ible和ultrasound之间的本质差异，IAP发送面临了前所未有的挑战，如扭曲、噪声和不稳定。为此，我们设计了一种新的ultrasound转换模型，以增强制作的恶意扰动，使其在物理上有效并能够在远程发送。此外，我们采用了一系列的修改来增强VRIFLE的可靠性，包括在生成过程中对用户和实际世界的变化进行修改。这样，VRIFLE可以在不同的距离和用户说话时进行有效的实时 manipulate ASR输出，并且采用了altern和mute策略来抑制用户中断的影响。我们的广泛的实验证明了VRIFLE在多种配置下的效iveness，对六种防御机制的Robustness，以及在targeted方式下的通用性。此外，我们还示出了VRIFLE可以通过移动攻击设备和日常生活中的 loudspeaker 进行传输。
</details></li>
</ul>
<hr>
<h2 id="SALTTS-Leveraging-Self-Supervised-Speech-Representations-for-improved-Text-to-Speech-Synthesis"><a href="#SALTTS-Leveraging-Self-Supervised-Speech-Representations-for-improved-Text-to-Speech-Synthesis" class="headerlink" title="SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis"></a>SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01018">http://arxiv.org/abs/2308.01018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ramanan Sivaguru, Vasista Sai Lodagala, S Umesh</li>
<li>for: 提高 FastSpeech2 synthesized speech 质量</li>
<li>methods: 使用 Self-Supervised Learning (SSL) 模型 Representation 增强 FastSpeech2 encoder 输出</li>
<li>results: 比基eline FastSpeech2 具有更高的对象和主观评价指标表现<details>
<summary>Abstract</summary>
While FastSpeech2 aims to integrate aspects of speech such as pitch, energy, and duration as conditional inputs, it still leaves scope for richer representations. As a part of this work, we leverage representations from various Self-Supervised Learning (SSL) models to enhance the quality of the synthesized speech. In particular, we pass the FastSpeech2 encoder's length-regulated outputs through a series of encoder layers with the objective of reconstructing the SSL representations. In the SALTTS-parallel implementation, the representations from this second encoder are used for an auxiliary reconstruction loss with the SSL features. The SALTTS-cascade implementation, however, passes these representations through the decoder in addition to having the reconstruction loss. The richness of speech characteristics from the SSL features reflects in the output speech quality, with the objective and subjective evaluation measures of the proposed approach outperforming the baseline FastSpeech2.
</details>
<details>
<summary>摘要</summary>
而 FastSpeech2 目标是将语音特征如抑压、能量和持续时间作为条件输入集成，但还留有更加富有的表示空间。作为这项工作的一部分，我们利用了不同的自我超vision学习（SSL）模型来增强合成语音的质量。具体来说，我们将 FastSpeech2 Encoder 的长度调整后的输出通过一系列Encoder层进行重建，以达到重建 SSL 特征的目标。在 SALTTS-parallel 实现中，这些第二个 Encoder 的表示被用于 auxiliary 重建损失中的 SSL 特征。而 SALTTS-cascade 实现则是将这些表示通过 Decoder 以及重建损失进行处理。通过 SSL 特征中的语音特征的丰富性，我们发现在输出语音质量中能够获得更高的 Objective 和 Subjective 评价指标。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/02/cs.SD_2023_08_02/" data-id="clogy1z6400skffra8zohgcio" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/02/cs.CV_2023_08_02/" class="article-date">
  <time datetime="2023-08-02T13:00:00.000Z" itemprop="datePublished">2023-08-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/02/cs.CV_2023_08_02/">cs.CV - 2023-08-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CMUNeXt-An-Efficient-Medical-Image-Segmentation-Network-based-on-Large-Kernel-and-Skip-Fusion"><a href="#CMUNeXt-An-Efficient-Medical-Image-Segmentation-Network-based-on-Large-Kernel-and-Skip-Fusion" class="headerlink" title="CMUNeXt: An Efficient Medical Image Segmentation Network based on Large Kernel and Skip Fusion"></a>CMUNeXt: An Efficient Medical Image Segmentation Network based on Large Kernel and Skip Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01239">http://arxiv.org/abs/2308.01239</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FengheTan9/Medical-Image-Segmentation-Benchmarks">https://github.com/FengheTan9/Medical-Image-Segmentation-Benchmarks</a></li>
<li>paper_authors: Fenghe Tang, Jianrui Ding, Lingtao Wang, Chunping Ning, S. Kevin Zhou</li>
<li>for: 这个研究旨在设计一个高效、轻量级的医疗影像分类网络，以应对现场医疗场景中的快速诊断需求。</li>
<li>methods: 这个网络使用了U型架构，并且搭配了对应的Skip-Fusion封页，以实现全面的资讯整合。</li>
<li>results: 实验结果显示，这个网络在多个医疗影像数据集上实现了高精度的分类性能，并且比 existed 网络更快速、轻量级、并且具有更少的计算成本。<details>
<summary>Abstract</summary>
The U-shaped architecture has emerged as a crucial paradigm in the design of medical image segmentation networks. However, due to the inherent local limitations of convolution, a fully convolutional segmentation network with U-shaped architecture struggles to effectively extract global context information, which is vital for the precise localization of lesions. While hybrid architectures combining CNNs and Transformers can address these issues, their application in real medical scenarios is limited due to the computational resource constraints imposed by the environment and edge devices. In addition, the convolutional inductive bias in lightweight networks adeptly fits the scarce medical data, which is lacking in the Transformer based network. In order to extract global context information while taking advantage of the inductive bias, we propose CMUNeXt, an efficient fully convolutional lightweight medical image segmentation network, which enables fast and accurate auxiliary diagnosis in real scene scenarios. CMUNeXt leverages large kernel and inverted bottleneck design to thoroughly mix distant spatial and location information, efficiently extracting global context information. We also introduce the Skip-Fusion block, designed to enable smooth skip-connections and ensure ample feature fusion. Experimental results on multiple medical image datasets demonstrate that CMUNeXt outperforms existing heavyweight and lightweight medical image segmentation networks in terms of segmentation performance, while offering a faster inference speed, lighter weights, and a reduced computational cost. The code is available at https://github.com/FengheTan9/CMUNeXt.
</details>
<details>
<summary>摘要</summary>
医学图像分割网络的U型体系已成为现代医学图像分割领域的关键思想。然而，由于卷积操作的本质性限制，一个完全卷积分割网络具有U型体系很难准确地提取全局上下文信息，这是诊断病理所必需的精确位置信息。尽管混合 arquitectures combining CNNs和Transformers可以解决这些问题，但它们在实际医疗场景中的应用受限于环境和边缘设备的计算资源限制。此外，卷积操作的权重偏好适应于稀缺的医学数据，这是Transformer基于网络中缺失的。为了提取全局上下文信息并利用卷积操作的权重偏好，我们提出CMUNeXt，一种高效的卷积分割医学图像分割网络。CMUNeXt通过大kernel和缩回瓦片设计，fficiently混合远程空间和位置信息，以提取全局上下文信息。我们还提出Skip-Fusion块，用于实现平滑的跳转连接和充分的特征融合。实验结果表明，CMUNeXt在多个医学图像Dataset上的分割性能超过现有的重量级和轻量级医学图像分割网络，同时提供更快的推理速度、轻量级的权重和降低的计算成本。代码可以在https://github.com/FengheTan9/CMUNeXt中下载。
</details></li>
</ul>
<hr>
<h2 id="TeachCLIP-Multi-Grained-Teaching-for-Efficient-Text-to-Video-Retrieval"><a href="#TeachCLIP-Multi-Grained-Teaching-for-Efficient-Text-to-Video-Retrieval" class="headerlink" title="TeachCLIP: Multi-Grained Teaching for Efficient Text-to-Video Retrieval"></a>TeachCLIP: Multi-Grained Teaching for Efficient Text-to-Video Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01217">http://arxiv.org/abs/2308.01217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaibin Tian, Ruixiang Zhao, Hu Hu, Runquan Xie, Fengzong Lian, Zhanhui Kang, Xirong Li</li>
<li>for: 文章目的是提出一种高效的文本-视频检索方法，以便在大规模的文本-视频检索 task 中提高效率。</li>
<li>methods: 本文使用 CLIP4Clip 作为学生网络，并通过多重粒度的教学来让学生网络学习从更高级别的模型，如 X-CLIP、TS2-Net 和 X-Pool 中的技术。为了提高学生网络的学习能力，文章提出了一种 Attentional frame-Feature Aggregation (AFA) 块，该块不添加额外的存储&#x2F;计算负担，但可以提高学生网络的学习能力。</li>
<li>results: EXTENSIVE experiments 表明，提出的方法可以在多个公共数据集上达到高效的文本-视频检索效果。<details>
<summary>Abstract</summary>
For text-to-video retrieval (T2VR), which aims to retrieve unlabeled videos by ad-hoc textual queries, CLIP-based methods are dominating. Compared to CLIP4Clip which is efficient and compact, the state-of-the-art models tend to compute video-text similarity by fine-grained cross-modal feature interaction and matching, putting their scalability for large-scale T2VR into doubt. For efficient T2VR, we propose TeachCLIP with multi-grained teaching to let a CLIP4Clip based student network learn from more advanced yet computationally heavy models such as X-CLIP, TS2-Net and X-Pool . To improve the student's learning capability, we add an Attentional frame-Feature Aggregation (AFA) block, which by design adds no extra storage/computation overhead at the retrieval stage. While attentive weights produced by AFA are commonly used for combining frame-level features, we propose a novel use of the weights to let them imitate frame-text relevance estimated by the teacher network. As such, AFA provides a fine-grained learning (teaching) channel for the student (teacher). Extensive experiments on multiple public datasets justify the viability of the proposed method.
</details>
<details>
<summary>摘要</summary>
For text-to-video retrieval (T2VR), which aims to retrieve unlabeled videos by ad-hoc textual queries, CLIP-based methods are dominant. Compared to CLIP4Clip which is efficient and compact, the state-of-the-art models tend to compute video-text similarity by fine-grained cross-modal feature interaction and matching, putting their scalability for large-scale T2VR into doubt. For efficient T2VR, we propose TeachCLIP with multi-grained teaching to let a CLIP4Clip based student network learn from more advanced yet computationally heavy models such as X-CLIP, TS2-Net and X-Pool . To improve the student's learning capability, we add an Attentional frame-Feature Aggregation (AFA) block, which by design adds no extra storage/computation overhead at the retrieval stage. While attentive weights produced by AFA are commonly used for combining frame-level features, we propose a novel use of the weights to let them imitate frame-text relevance estimated by the teacher network. As such, AFA provides a fine-grained learning (teaching) channel for the student (teacher). Extensive experiments on multiple public datasets justify the viability of the proposed method.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Improving-Generalization-in-Visual-Reinforcement-Learning-via-Conflict-aware-Gradient-Agreement-Augmentation"><a href="#Improving-Generalization-in-Visual-Reinforcement-Learning-via-Conflict-aware-Gradient-Agreement-Augmentation" class="headerlink" title="Improving Generalization in Visual Reinforcement Learning via Conflict-aware Gradient Agreement Augmentation"></a>Improving Generalization in Visual Reinforcement Learning via Conflict-aware Gradient Agreement Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01194">http://arxiv.org/abs/2308.01194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siao Liu, Zhaoyu Chen, Yang Liu, Yuzheng Wang, Dingkang Yang, Zhile Zhao, Ziqing Zhou, Xie Yi, Wei Li, Wenqiang Zhang, Zhongxue Gan</li>
<li>for: 提高视觉奖励学习中的泛化能力，即使在未经见过的环境中保持高效性。</li>
<li>methods: 提出了一种权衡减少高弹性梯度大小和梯度冲突的扩展策略，名为冲突意识梯度协调减少法（CG2A），并将其与视觉奖励学习算法结合以提高泛化性。</li>
<li>results: 经验表明，CG2A可以显著提高视觉奖励学习算法的泛化性和样本效率。<details>
<summary>Abstract</summary>
Learning a policy with great generalization to unseen environments remains challenging but critical in visual reinforcement learning. Despite the success of augmentation combination in the supervised learning generalization, naively applying it to visual RL algorithms may damage the training efficiency, suffering from serve performance degradation. In this paper, we first conduct qualitative analysis and illuminate the main causes: (i) high-variance gradient magnitudes and (ii) gradient conflicts existed in various augmentation methods. To alleviate these issues, we propose a general policy gradient optimization framework, named Conflict-aware Gradient Agreement Augmentation (CG2A), and better integrate augmentation combination into visual RL algorithms to address the generalization bias. In particular, CG2A develops a Gradient Agreement Solver to adaptively balance the varying gradient magnitudes, and introduces a Soft Gradient Surgery strategy to alleviate the gradient conflicts. Extensive experiments demonstrate that CG2A significantly improves the generalization performance and sample efficiency of visual RL algorithms.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Generative-Noisy-Label-Learning-by-Implicit-Dicriminative-Approximation-with-Partial-Label-Prior"><a href="#Generative-Noisy-Label-Learning-by-Implicit-Dicriminative-Approximation-with-Partial-Label-Prior" class="headerlink" title="Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior"></a>Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01184">http://arxiv.org/abs/2308.01184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fengbei Liu, Yuanhong Chen, Chong Wang, Yuyuan Liu, Gustavo Carneiro</li>
<li>for: 本文提出了一种新的生成式噪声标签学习方法，以解决现有方法中的三大问题。</li>
<li>methods: 本文使用了一种新的模型优化方法，直接将数据和清晰标签相关联，从而消除了生成模型的费时训练。此外，本文还提出了一种新的标签优化策略，以便使用部分标签学习来提供噪声标签的超vision信号。</li>
<li>results: 经过广泛的实验表明，本文的生成模型在多个噪声标签 benchmark 上达到了领先的Result，同时保持了与权衡分布模型相同的计算复杂性。<details>
<summary>Abstract</summary>
The learning with noisy labels has been addressed with both discriminative and generative models. Although discriminative models have dominated the field due to their simpler modeling and more efficient computational training processes, generative models offer a more effective means of disentangling clean and noisy labels and improving the estimation of the label transition matrix. However, generative approaches maximize the joint likelihood of noisy labels and data using a complex formulation that only indirectly optimizes the model of interest associating data and clean labels. Additionally, these approaches rely on generative models that are challenging to train and tend to use uninformative clean label priors. In this paper, we propose a new generative noisy-label learning approach that addresses these three issues. First, we propose a new model optimisation that directly associates data and clean labels. Second, the generative model is implicitly estimated using a discriminative model, eliminating the inefficient training of a generative model. Third, we propose a new informative label prior inspired by partial label learning as supervision signal for noisy label learning. Extensive experiments on several noisy-label benchmarks demonstrate that our generative model provides state-of-the-art results while maintaining a similar computational complexity as discriminative models.
</details>
<details>
<summary>摘要</summary>
学习噪声标签的问题已经由权重分配模型和生成模型来解决。虽然权重分配模型因其简单的模型化和更高效的计算训练过程而在领域中占据主导地位，但生成模型可以更好地分离噪声标签和数据，并提高标签过渡矩阵的估计。然而，生成方法通过复杂的形式ulation maximizes the joint likelihood of noisy labels and data, which only indirectly optimizes the model of interest associating data and clean labels。此外，这些方法通常需要困难的训练和使用无用的干净标签辅助signal。在本文中，我们提出了一种新的生成噪声标签学习方法，解决了以下三个问题。首先，我们提出了一种新的模型优化方法，直接将数据和干净标签相关联。其次，我们使用权重分配模型来隐式地估计生成模型，从而消除了生成模型的不效环境训练。最后，我们提出了一种新的有用的标签前导信号， inspirited by partial label learning as supervision signal for noisy label learning。我们在多个噪声标签benchmark experiment中进行了广泛的实验，结果表明我们的生成模型可以在计算复杂度相同的情况下提供国际级的result。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-End-to-End-Driving-Model-for-Implicit-Scene-Understanding"><a href="#Interpretable-End-to-End-Driving-Model-for-Implicit-Scene-Understanding" class="headerlink" title="Interpretable End-to-End Driving Model for Implicit Scene Understanding"></a>Interpretable End-to-End Driving Model for Implicit Scene Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01180">http://arxiv.org/abs/2308.01180</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyang Sun, Xiaonian Wang, Yangyang Zhang, Jiagui Tang, Xiaqiang Tang, Jing Yao</li>
<li>for: 本研究旨在通过感知数据获取全面的景象信息，提供下游任务的基础，以确保自动驾驶车辆的安全。</li>
<li>methods: 本研究使用特定的感知任务，如物体检测和景图生成，但这些任务只能EQivalent to sampling from高维度的景象特征，而不够表示场景。此外，感知任务的目标与人类驾驶不符，人类只关注可能影响自己的车辆轨迹。因此，我们提出了一个综合 interpretable 的隐藏驾驶景象理解（II-DSU）模型，通过规划模块引导，提取隐藏的高维度景象特征作为场景理解结果，并使用 auxillary 感知任务进行可视化验证。</li>
<li>results: 实验结果表明，我们的方法在 CARLA 测试benchmark 上达到了新的状态OF-THE-ART，并能够获取包含更多的驾驶场景信息的景象特征，从而提高下游规划的性能。<details>
<summary>Abstract</summary>
Driving scene understanding is to obtain comprehensive scene information through the sensor data and provide a basis for downstream tasks, which is indispensable for the safety of self-driving vehicles. Specific perception tasks, such as object detection and scene graph generation, are commonly used. However, the results of these tasks are only equivalent to the characterization of sampling from high-dimensional scene features, which are not sufficient to represent the scenario. In addition, the goal of perception tasks is inconsistent with human driving that just focuses on what may affect the ego-trajectory. Therefore, we propose an end-to-end Interpretable Implicit Driving Scene Understanding (II-DSU) model to extract implicit high-dimensional scene features as scene understanding results guided by a planning module and to validate the plausibility of scene understanding using auxiliary perception tasks for visualization. Experimental results on CARLA benchmarks show that our approach achieves the new state-of-the-art and is able to obtain scene features that embody richer scene information relevant to driving, enabling superior performance of the downstream planning.
</details>
<details>
<summary>摘要</summary>
自动驾驶车辆Scene理解是通过感知数据获取全面的Scene信息，并提供下游任务的基础，这是自动驾驶车辆的安全所不可或缺。特定的感知任务，如物体检测和Scene图生成，通常被使用。然而，这些任务的结果只是样本高维Scene特征的 caracterization，这并不够 representationScene。此外，感知任务的目标与人类驾驶不符，人类驾驶只关注可能affect eg trajectory的 factor。因此，我们提出了End-to-end可解释的含义Scene Understanding（II-DSU）模型，通过规划模块引导，从感知数据中提取高维Scene特征，并使用辅助感知任务进行视觉化。实验结果表明，我们的方法在CARLAbenchmark上达到了新的州OF-the-art，并能够获取包含更加丰富的Scene信息，有利于下游规划的性能。
</details></li>
</ul>
<hr>
<h2 id="Memory-Encoding-Model"><a href="#Memory-Encoding-Model" class="headerlink" title="Memory Encoding Model"></a>Memory Encoding Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01175">http://arxiv.org/abs/2308.01175</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning">https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning</a></li>
<li>paper_authors: Huzheng Yang, James Gee, Jianbo Shi</li>
<li>for: 这个研究探究了一种新的大脑编码模型，通过添加记忆相关信息作为输入来实现。</li>
<li>methods: 这个研究使用了视觉认知任务，并使用了以前看过的图像来预测非视觉大脑的活动。</li>
<li>results: 研究发现，在添加记忆信息作为输入时，模型的性能得到了显著提高（单个模型分数为66.8，集成模型分数为70.8）。此外，研究还发现了Periodic delayed brain response和hippocampus的相关活动，这些活动与6-7帧之前的图像相关。<details>
<summary>Abstract</summary>
We explore a new class of brain encoding model by adding memory-related information as input. Memory is an essential brain mechanism that works alongside visual stimuli. During a vision-memory cognitive task, we found the non-visual brain is largely predictable using previously seen images. Our Memory Encoding Model (Mem) won the Algonauts 2023 visual brain competition even without model ensemble (single model score 66.8, ensemble score 70.8). Our ensemble model without memory input (61.4) can also stand a 3rd place. Furthermore, we observe periodic delayed brain response correlated to 6th-7th prior image, and hippocampus also showed correlated activity timed with this periodicity. We conjuncture that the periodic replay could be related to memory mechanism to enhance the working memory.
</details>
<details>
<summary>摘要</summary>
我们探索了一新类的脑编码模型，将记忆相关信息作为输入。记忆是脑中重要的机制，与视觉刺激同时工作。在视觉认知任务中，我们发现了非视觉脑的大部分可预测，使用先前看到的图像。我们的记忆编码模型（Mem）在2023年Algonauts视觉脑竞赛中获胜，即使没有模型集成（单个模型分数为66.8，集成分数为70.8）。我们的 ensemble模型 без记忆输入（61.4）也能够获得第三名。此外，我们发现了 periodic delayed 脑响应与第6-7个先前图像相对应，以及 hippocampus 也显示了与这种周期性相关的活动。我们推测 periodic replay 可能与记忆机制相关，以增强工作记忆。
</details></li>
</ul>
<hr>
<h2 id="Contrast-augmented-Diffusion-Model-with-Fine-grained-Sequence-Alignment-for-Markup-to-Image-Generation"><a href="#Contrast-augmented-Diffusion-Model-with-Fine-grained-Sequence-Alignment-for-Markup-to-Image-Generation" class="headerlink" title="Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment for Markup-to-Image Generation"></a>Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment for Markup-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01147">http://arxiv.org/abs/2308.01147</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zgj77/fsacdm">https://github.com/zgj77/fsacdm</a></li>
<li>paper_authors: Guojin Zhong, Jin Yuan, Pan Wang, Kailun Yang, Weili Guan, Zhiyong Li</li>
<li>for: 本文提出了一种新的 markup-to-image 生成模型，即 “Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment” (FSA-CDM)，用于解决 markup-to-image 生成中的低精度允许误差和复杂的序列和上下文相关性问题。</li>
<li>methods: 该模型引入了对比性正样本，并设计了细腻的cross模态对应模块，以充分挖掘两种模式之间的序列相似性，从而学习Robust的特征表示。此外，提出了一种增强了对比性的扩展 diffusion 模型，通过最大化一个新的对比性变量目标函数，以提高模型的优化目标的紧张性。</li>
<li>results: 在四个不同领域的四个标准 benchmark 数据集上进行了广泛的实验，并证明了 FSA-CDM 模型中提出的组件的效果，与当前状态的表达能力相比，提高了约2%-12% DTW 的改进。<details>
<summary>Abstract</summary>
The recently rising markup-to-image generation poses greater challenges as compared to natural image generation, due to its low tolerance for errors as well as the complex sequence and context correlations between markup and rendered image. This paper proposes a novel model named "Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment" (FSA-CDM), which introduces contrastive positive/negative samples into the diffusion model to boost performance for markup-to-image generation. Technically, we design a fine-grained cross-modal alignment module to well explore the sequence similarity between the two modalities for learning robust feature representations. To improve the generalization ability, we propose a contrast-augmented diffusion model to explicitly explore positive and negative samples by maximizing a novel contrastive variational objective, which is mathematically inferred to provide a tighter bound for the model's optimization. Moreover, the context-aware cross attention module is developed to capture the contextual information within markup language during the denoising process, yielding better noise prediction results. Extensive experiments are conducted on four benchmark datasets from different domains, and the experimental results demonstrate the effectiveness of the proposed components in FSA-CDM, significantly exceeding state-of-the-art performance by about 2%-12% DTW improvements. The code will be released at https://github.com/zgj77/FSACDM.
</details>
<details>
<summary>摘要</summary>
“Recently rising markup-to-image generation poses greater challenges compared to natural image generation, due to its low tolerance for errors and complex sequence and context correlations between markup and rendered image. This paper proposes a novel model named 'Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment' (FSA-CDM), which introduces contrastive positive/negative samples into the diffusion model to boost performance for markup-to-image generation. Technically, we design a fine-grained cross-modal alignment module to well explore the sequence similarity between the two modalities for learning robust feature representations. To improve generalization ability, we propose a contrast-augmented diffusion model to explicitly explore positive and negative samples by maximizing a novel contrastive variational objective, which is mathematically inferred to provide a tighter bound for the model's optimization. Moreover, the context-aware cross attention module is developed to capture the contextual information within markup language during the denoising process, yielding better noise prediction results. Extensive experiments are conducted on four benchmark datasets from different domains, and the experimental results demonstrate the effectiveness of the proposed components in FSA-CDM, significantly exceeding state-of-the-art performance by about 2%-12% DTW improvements. The code will be released at https://github.com/zgj77/FSACDM.”Note: DTW (Dynamic Time Warping) is a measure of similarity between two time series signals. A higher DTW improvement indicates better performance.
</details></li>
</ul>
<hr>
<h2 id="UCDFormer-Unsupervised-Change-Detection-Using-a-Transformer-driven-Image-Translation"><a href="#UCDFormer-Unsupervised-Change-Detection-Using-a-Transformer-driven-Image-Translation" class="headerlink" title="UCDFormer: Unsupervised Change Detection Using a Transformer-driven Image Translation"></a>UCDFormer: Unsupervised Change Detection Using a Transformer-driven Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01146">http://arxiv.org/abs/2308.01146</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhu-xlab/ucdformer">https://github.com/zhu-xlab/ucdformer</a></li>
<li>paper_authors: Qingsong Xu, Yilei Shi, Jianhua Guo, Chaojun Ouyang, Xiao Xiang Zhu</li>
<li>For: 本研究旨在提出一种基于域名适应的无监督变化检测方法，以满足 Remote Sensing 图像的变化检测任务。* Methods: 本方法使用了一种基于 transformer 的图像翻译模型，称为 UCDFormer，以解决域名适应问题。图像翻译模型包括一个轻量级 transformer 和域名特定的相互作用权重。然后，通过图像翻译后的差分图计算得到变化映射。最后，提出了一种可靠的像素选择模块，使用杂化 c-means  clustering 和自适应阈值来选择变化&#x2F;不变化像素。* Results: 对不同的无监督变化检测任务进行实验，结果显示 UCDFormer 的性能高于其他相关方法，卷积比例更高达 12.3%。此外，UCDFormer 在考虑大规模应用时对地球quake-induced landslide 检测也表现出色。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/zhu-xlab/UCDFormer%7D">https://github.com/zhu-xlab/UCDFormer}</a> 上下载。<details>
<summary>Abstract</summary>
Change detection (CD) by comparing two bi-temporal images is a crucial task in remote sensing. With the advantages of requiring no cumbersome labeled change information, unsupervised CD has attracted extensive attention in the community. However, existing unsupervised CD approaches rarely consider the seasonal and style differences incurred by the illumination and atmospheric conditions in multi-temporal images. To this end, we propose a change detection with domain shift setting for remote sensing images. Furthermore, we present a novel unsupervised CD method using a light-weight transformer, called UCDFormer. Specifically, a transformer-driven image translation composed of a light-weight transformer and a domain-specific affinity weight is first proposed to mitigate domain shift between two images with real-time efficiency. After image translation, we can generate the difference map between the translated before-event image and the original after-event image. Then, a novel reliable pixel extraction module is proposed to select significantly changed/unchanged pixel positions by fusing the pseudo change maps of fuzzy c-means clustering and adaptive threshold. Finally, a binary change map is obtained based on these selected pixel pairs and a binary classifier. Experimental results on different unsupervised CD tasks with seasonal and style changes demonstrate the effectiveness of the proposed UCDFormer. For example, compared with several other related methods, UCDFormer improves performance on the Kappa coefficient by more than 12\%. In addition, UCDFormer achieves excellent performance for earthquake-induced landslide detection when considering large-scale applications. The code is available at \url{https://github.com/zhu-xlab/UCDFormer}
</details>
<details>
<summary>摘要</summary>
Change detection (CD) by comparing two bi-temporal images is a crucial task in remote sensing. With the advantages of not requiring cumbersome labeled change information, unsupervised CD has attracted extensive attention in the community. However, existing unsupervised CD approaches rarely consider the seasonal and style differences incurred by the illumination and atmospheric conditions in multi-temporal images. To this end, we propose a change detection with domain shift setting for remote sensing images. Furthermore, we present a novel unsupervised CD method using a light-weight transformer, called UCDFormer. Specifically, a transformer-driven image translation composed of a light-weight transformer and a domain-specific affinity weight is first proposed to mitigate domain shift between two images with real-time efficiency. After image translation, we can generate the difference map between the translated before-event image and the original after-event image. Then, a novel reliable pixel extraction module is proposed to select significantly changed/unchanged pixel positions by fusing the pseudo change maps of fuzzy c-means clustering and adaptive threshold. Finally, a binary change map is obtained based on these selected pixel pairs and a binary classifier. Experimental results on different unsupervised CD tasks with seasonal and style changes demonstrate the effectiveness of the proposed UCDFormer. For example, compared with several other related methods, UCDFormer improves performance on the Kappa coefficient by more than 12\%. In addition, UCDFormer achieves excellent performance for earthquake-induced landslide detection when considering large-scale applications. The code is available at \url{https://github.com/zhu-xlab/UCDFormer}.Here's the translation in Traditional Chinese:同比较两个时间影像的变化检测（CD）是远程感知中的一个重要任务。由于不需要耗费大量的标签变化信息，不监督CD吸引了社区的广泛关注。然而，现有的不监督CD方法很少考虑多个时间影像中的季节和风格变化，这些变化是由照明和大气conditions导致的。为了解决这个问题，我们提出了适用于远程感知影像的CD设定。此外，我们还提出了一个名为UCDFormer的新型不监督CD方法，这是一个轻量级的transformer驱动的图像转换。 Specifically, 这个图像转换由一个轻量级的transformer和对应域专的相互关联项目所构成。在实现图像转换后，我们可以生成原始后事件影像与转换前事件影像之间的差分图。然后，我们提出了一个新的可靠像素提取模组，这个模组通过融合多个pseudo change map的统计学 clustering和自适应阈值来选择具有重要变化的像素位置。最后，我们根据这些选择的像素对生成一个二进制变化图。实验结果显示，UCDFormer在不同的不监督CD任务中具有优秀的表现，比如在凡托伦数据上的Kappa系数提高了更多于12%。此外，UCDFormer在考虑大规模应用时也具有优秀的震灾引起的塌陷检测表现。相关代码可以在 \url{https://github.com/zhu-xlab/UCDFormer} 中找到。
</details></li>
</ul>
<hr>
<h2 id="DySTreSS-Dynamically-Scaled-Temperature-in-Self-Supervised-Contrastive-Learning"><a href="#DySTreSS-Dynamically-Scaled-Temperature-in-Self-Supervised-Contrastive-Learning" class="headerlink" title="DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning"></a>DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01140">http://arxiv.org/abs/2308.01140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siladittya Manna, Soumitri Chattopadhyay, Rakesh Dey, Saumik Bhattacharya, Umapada Pal</li>
<li>for: 这篇论文的目的是提高自类指示学习（SSL）中的信息实体对偶损失（InfoNCE）损失函数的性能。</li>
<li>methods: 这篇论文使用了一种基于cosine similarity的温度对应函数来优化InfoNCE损失函数中的温度参数。同时，它还进行了一个全面的检查，以了解温度的不同值下，特征空间中的本地和全球结构如何变化。</li>
<li>results: 实验证明，提案的框架（DySTreSS）在SSL中的性能比或与对偶损失函数基于的框架相当。它还进一步分析了温度的选择，以及特征空间中的本地和全球结构如何影响性能。<details>
<summary>Abstract</summary>
In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples from different classes is primarily affected by the presence of hard negative samples. While the InfoNCE loss has been shown to impose penalties based on hardness, the temperature hyper-parameter is the key to regulating the penalties and the trade-off between uniformity and tolerance. In this work, we focus our attention to improve the performance of InfoNCE loss in SSL by studying the effect of temperature hyper-parameter values. We propose a cosine similarity-dependent temperature scaling function to effectively optimize the distribution of the samples in the feature space. We further analyze the uniformity and tolerance metrics to investigate the optimal regions in the cosine similarity space for better optimization. Additionally, we offer a comprehensive examination of the behavior of local and global structures in the feature space throughout the pre-training phase, as the temperature varies. Experimental evidence shows that the proposed framework outperforms or is at par with the contrastive loss-based SSL algorithms. We believe our work (DySTreSS) on temperature scaling in SSL provides a foundation for future research in contrastive learning.
</details>
<details>
<summary>摘要</summary>
现代自我监督对比算法如SimCLR、MoCo等，任务是让两个semantically相似的样本之间吸引，而两个来自不同类型的样本之间冲突。而这种吸引和冲突的 equilibrio 主要受到强度负样本的影响。在这种情况下，InfoNCE损失已经显示出对强度的penalty，但温度超参数是控制这些penalty的关键。在这项工作中，我们关注InfoNCE损失在SSL中的性能优化，研究温度超参数的影响。我们提议一种cosine相似性dependent的温度扩展函数，以便有效地优化样本在特征空间的分布。我们进一步分析了cosine相似性空间中的各种参数区域，以便更好地优化。此外，我们还对批量和全局结构在特征空间中的变化进行了详细的分析，从温度变化的角度出发。实验证明，我们提出的框架可以超越或与基于对比损失的SSL算法相当。我们认为我们的工作（DySTreSS）在SSL中的温度扩展提供了对contrastive学习的未来研究的基础。
</details></li>
</ul>
<hr>
<h2 id="Multi-task-learning-for-classification-segmentation-reconstruction-and-detection-on-chest-CT-scans"><a href="#Multi-task-learning-for-classification-segmentation-reconstruction-and-detection-on-chest-CT-scans" class="headerlink" title="Multi-task learning for classification, segmentation, reconstruction, and detection on chest CT scans"></a>Multi-task learning for classification, segmentation, reconstruction, and detection on chest CT scans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01137">http://arxiv.org/abs/2308.01137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weronika Hryniewska-Guzik, Maria Kędzierska, Przemysław Biecek</li>
<li>for: 诊断肺癌和covid-19患者的诊断和治疗</li>
<li>methods: 提出了一种多任务学习框架，包括分类、分割、重建和检测等任务，并在 segmentation 任务中使用了两种不同的背部和不同的损失函数进行检验</li>
<li>results: 提出了一种新的多任务学习框架，可以帮助医生更快速、更准确地诊断肺癌和covid-19患者的疾病。此外，通过对不同背部和损失函数的使用，可以提高 segmentation 任务的性能。<details>
<summary>Abstract</summary>
Lung cancer and covid-19 have one of the highest morbidity and mortality rates in the world. For physicians, the identification of lesions is difficult in the early stages of the disease and time-consuming. Therefore, multi-task learning is an approach to extracting important features, such as lesions, from small amounts of medical data because it learns to generalize better. We propose a novel multi-task framework for classification, segmentation, reconstruction, and detection. To the best of our knowledge, we are the first ones who added detection to the multi-task solution. Additionally, we checked the possibility of using two different backbones and different loss functions in the segmentation task.
</details>
<details>
<summary>摘要</summary>
肺癌和 COVID-19 是全球 morbidity 和 mortality 率最高的疾病之一。为医生来说，在早期疾病阶段寻找 lesions 是困难的和时间消耗的。因此，多任务学习是一种EXTRACTING重要特征的方法，如疾病 lesions，从小量医疗数据中提取。我们提出了一种新的多任务框架，用于分类、分割、重建和检测。根据我们所知，我们是第一个将检测添加到多任务解决方案中的人。此外，我们还检查了使用两种不同的背景和不同的损失函数在分割任务中的可能性。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Expert-Models-for-Training-Deep-Neural-Networks-in-Scarce-Data-Domains-Application-to-Offline-Handwritten-Signature-Verification"><a href="#Leveraging-Expert-Models-for-Training-Deep-Neural-Networks-in-Scarce-Data-Domains-Application-to-Offline-Handwritten-Signature-Verification" class="headerlink" title="Leveraging Expert Models for Training Deep Neural Networks in Scarce Data Domains: Application to Offline Handwritten Signature Verification"></a>Leveraging Expert Models for Training Deep Neural Networks in Scarce Data Domains: Application to Offline Handwritten Signature Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01136">http://arxiv.org/abs/2308.01136</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitrios Tsourounis, Ilias Theodorakopoulos, Elias N. Zois, George Economou</li>
<li>for: 本研究旨在利用现有专家模型来训练新的卷积神经网络，在数据有限或不可用的领域进行训练。</li>
<li>methods: 本研究提出的学生教师（S-T）配置使用特征基于的知识填充（FKD），将本地活动图像的相似性拟合到全局相似性度量中，以超参学生的训练。</li>
<li>results: 研究表明，使用本研究的方法可以在三个流行的签名数据集上达到相当或更高的性能，而不需要在特征提取过程中使用任何签名数据。这种方法可能可以在其他有限数据的领域中应用。<details>
<summary>Abstract</summary>
This paper introduces a novel approach to leverage the knowledge of existing expert models for training new Convolutional Neural Networks, on domains where task-specific data are limited or unavailable. The presented scheme is applied in offline handwritten signature verification (OffSV) which, akin to other biometric applications, suffers from inherent data limitations due to regulatory restrictions. The proposed Student-Teacher (S-T) configuration utilizes feature-based knowledge distillation (FKD), combining graph-based similarity for local activations with global similarity measures to supervise student's training, using only handwritten text data. Remarkably, the models trained using this technique exhibit comparable, if not superior, performance to the teacher model across three popular signature datasets. More importantly, these results are attained without employing any signatures during the feature extraction training process. This study demonstrates the efficacy of leveraging existing expert models to overcome data scarcity challenges in OffSV and potentially other related domains.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DiffusePast-Diffusion-based-Generative-Replay-for-Class-Incremental-Semantic-Segmentation"><a href="#DiffusePast-Diffusion-based-Generative-Replay-for-Class-Incremental-Semantic-Segmentation" class="headerlink" title="DiffusePast: Diffusion-based Generative Replay for Class Incremental Semantic Segmentation"></a>DiffusePast: Diffusion-based Generative Replay for Class Incremental Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01127">http://arxiv.org/abs/2308.01127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingfan Chen, Yuxi Wang, Pengfei Wang, Xiao Chen, Zhaoxiang Zhang, Zhen Lei, Qing Li</li>
<li>for: 提高 incremental semantic segmentation 任务中的权重问题和隐私问题</li>
<li>methods: 提出了一种基于扩散的生成重温模型，通过生成更准确的图像和更可靠的面积来解决生成的图像缺乏semantic精度和out-of-distribution特征问题</li>
<li>results: 通过实验表明，ours方法可以在主流的benchmark上实现竞争性的性能，更好地平衡老类和新类的性能<details>
<summary>Abstract</summary>
The Class Incremental Semantic Segmentation (CISS) extends the traditional segmentation task by incrementally learning newly added classes. Previous work has introduced generative replay, which involves replaying old class samples generated from a pre-trained GAN, to address the issues of catastrophic forgetting and privacy concerns. However, the generated images lack semantic precision and exhibit out-of-distribution characteristics, resulting in inaccurate masks that further degrade the segmentation performance. To tackle these challenges, we propose DiffusePast, a novel framework featuring a diffusion-based generative replay module that generates semantically accurate images with more reliable masks guided by different instructions (e.g., text prompts or edge maps). Specifically, DiffusePast introduces a dual-generator paradigm, which focuses on generating old class images that align with the distribution of downstream datasets while preserving the structure and layout of the original images, enabling more precise masks. To adapt to the novel visual concepts of newly added classes continuously, we incorporate class-wise token embedding when updating the dual-generator. Moreover, we assign adequate pseudo-labels of old classes to the background pixels in the new step images, further mitigating the forgetting of previously learned knowledge. Through comprehensive experiments, our method demonstrates competitive performance across mainstream benchmarks, striking a better balance between the performance of old and novel classes.
</details>
<details>
<summary>摘要</summary>
“ classe Incremental Semantic Segmentation（CISS）延伸了传统的分类任务，通过不断学习新增的类别。先前的工作已经引入生成重播，即从预训的GAN中生成的旧类样本，以解决严重遗忘和隐私问题。但是，生成的图像没有准确的Semantic和外部分布特征，导致不准确的mask，进一步损害分类性能。为了解决这些挑战，我们提出了DiffusePast，一个新的框架，其中包括一个散射型生成重播模组，可以产生具有准确Semantic和可靠mask的图像。 Specifically, DiffusePast采用了双生成者 парадиг，专注于生成旧类样本，使其与下游资料集的分布相似，并保持原始图像的结构和布局，实现更 precisemask。为了适应新增的视觉概念，我们在更新双生成者时 incorporate class-wise token embedding。此外，我们将旧类别的 pseudo-labels assign 到新步骤图像的背景像素上，进一步减少遗忘先前学习的知识。通过实际的实验，我们的方法在主流的benchmark上展示了竞争性表现，寻求更好地寻求旧和新类别的 equilibrio。”
</details></li>
</ul>
<hr>
<h2 id="Stereo-Visual-Odometry-with-Deep-Learning-Based-Point-and-Line-Feature-Matching-using-an-Attention-Graph-Neural-Network"><a href="#Stereo-Visual-Odometry-with-Deep-Learning-Based-Point-and-Line-Feature-Matching-using-an-Attention-Graph-Neural-Network" class="headerlink" title="Stereo Visual Odometry with Deep Learning-Based Point and Line Feature Matching using an Attention Graph Neural Network"></a>Stereo Visual Odometry with Deep Learning-Based Point and Line Feature Matching using an Attention Graph Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01125">http://arxiv.org/abs/2308.01125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shenbagaraj Kannapiran, Nalin Bendapudi, Ming-Yuan Yu, Devarth Parikh, Spring Berman, Ankit Vora, Gaurav Pandey</li>
<li>for: 本研究旨在提出一种基于点和线特征的斯tereo视巡ometry（StereoVO）技术，以便在低可见度天气和照明条件下实现robust的特征匹配。</li>
<li>methods: 本研究使用了一种新的注意力图 neural network，用于实现点和线特征匹配，并且可以在各种恶劣天气和照明条件下表现良好。</li>
<li>results: 实验结果显示，我们的方法在多个实际和synthetic dataset上能够在低可见度天气和照明条件下实现更多的线特征匹配，并且当补充了点特征匹配时，能够在恶劣天气和照明条件下保持一致的性能。<details>
<summary>Abstract</summary>
Robust feature matching forms the backbone for most Visual Simultaneous Localization and Mapping (vSLAM), visual odometry, 3D reconstruction, and Structure from Motion (SfM) algorithms. However, recovering feature matches from texture-poor scenes is a major challenge and still remains an open area of research. In this paper, we present a Stereo Visual Odometry (StereoVO) technique based on point and line features which uses a novel feature-matching mechanism based on an Attention Graph Neural Network that is designed to perform well even under adverse weather conditions such as fog, haze, rain, and snow, and dynamic lighting conditions such as nighttime illumination and glare scenarios. We perform experiments on multiple real and synthetic datasets to validate the ability of our method to perform StereoVO under low visibility weather and lighting conditions through robust point and line matches. The results demonstrate that our method achieves more line feature matches than state-of-the-art line matching algorithms, which when complemented with point feature matches perform consistently well in adverse weather and dynamic lighting conditions.
</details>
<details>
<summary>摘要</summary>
Robust 特征匹配构成了大多数视觉同时定位和地图（vSLAM）、视觉速度、3D重建和结构从运动（SfM）算法的核心。然而，从Texture贫瘠场景中恢复特征匹配是一个主要挑战，并且仍然是一个开放的研究领域。在这篇论文中，我们提出了一种基于点和线特征的斯tereo视巡（StereoVO）技术，使用一种基于注意力图 neural network的新特征匹配机制，可以在恶劣天气和照明条件下表现良好，如雾、霾、雨、雪等。我们在多个实际和 sintetic 数据集上进行了实验，以验证我们的方法在低视力天气和照明条件下进行斯tereoVO的能力。结果显示，我们的方法在与State-of-the-art 线Matching算法进行比较时，在恶劣天气和动态照明条件下可以得到更多的线特征匹配，并且当 complemented  Point 特征匹配时，能够一致地表现良好。
</details></li>
</ul>
<hr>
<h2 id="Unlearning-Spurious-Correlations-in-Chest-X-ray-Classification"><a href="#Unlearning-Spurious-Correlations-in-Chest-X-ray-Classification" class="headerlink" title="Unlearning Spurious Correlations in Chest X-ray Classification"></a>Unlearning Spurious Correlations in Chest X-ray Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01119">http://arxiv.org/abs/2308.01119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Misgina Tsighe Hagos, Kathleen M. Curran, Brian Mac Namee</li>
<li>for: 该研究旨在构建一种可靠的骨灰图像分类模型，以便在医疗图像分类任务中减少误差和提高模型的透明度。</li>
<li>methods: 该研究使用了一种基于 Covid-19 肺 X-ray 图像集的深度学习模型，并通过利用用户提供的互动式反馈来实现 eXplanation Based Learning（XBL）方法，以解除不必要的相关性。</li>
<li>results: 研究结果表明，XBL 方法可以有效地减少骨灰图像分类模型中的误差，并且可以在患有 Covid-19 的肺 X-ray 图像中提高模型的透明度。<details>
<summary>Abstract</summary>
Medical image classification models are frequently trained using training datasets derived from multiple data sources. While leveraging multiple data sources is crucial for achieving model generalization, it is important to acknowledge that the diverse nature of these sources inherently introduces unintended confounders and other challenges that can impact both model accuracy and transparency. A notable confounding factor in medical image classification, particularly in musculoskeletal image classification, is skeletal maturation-induced bone growth observed during adolescence. We train a deep learning model using a Covid-19 chest X-ray dataset and we showcase how this dataset can lead to spurious correlations due to unintended confounding regions. eXplanation Based Learning (XBL) is a deep learning approach that goes beyond interpretability by utilizing model explanations to interactively unlearn spurious correlations. This is achieved by integrating interactive user feedback, specifically feature annotations. In our study, we employed two non-demanding manual feedback mechanisms to implement an XBL-based approach for effectively eliminating these spurious correlations. Our results underscore the promising potential of XBL in constructing robust models even in the presence of confounding factors.
</details>
<details>
<summary>摘要</summary>
医疗图像分类模型经常使用多个数据源进行训练。虽然利用多个数据源对于实现模型泛化具有重要意义，但是需要承认这些来源的多样性自然而来带来不必要的混乱和其他挑战，这些挑战可能会影响模型的准确性和透明度。一种常见的混乱因素在医疗图像分类中是由青春期所引起的骨髓成熔。我们使用COVID-19胸部X射线图像集训练深度学习模型，并显示这些数据集可能会导致不必要的相关性，因为不Intentional的混乱区域。基于解释的学习（XBL）是一种深度学习方法，它不仅提供了解释，还可以通过交互式的用户反馈来解除不必要的相关性。我们在研究中使用了两种非常容易的手动反馈机制来实现XBL的方法。我们的结果表明，XBL在存在混乱因素的情况下可以构建可靠的模型。
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Branching-for-Motion-Prediction-using-Motion-Increments"><a href="#Spatio-Temporal-Branching-for-Motion-Prediction-using-Motion-Increments" class="headerlink" title="Spatio-Temporal Branching for Motion Prediction using Motion Increments"></a>Spatio-Temporal Branching for Motion Prediction using Motion Increments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01097">http://arxiv.org/abs/2308.01097</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jasonwang959/stpmp">https://github.com/jasonwang959/stpmp</a></li>
<li>paper_authors: Jiexin Wang, Yujie Zhou, Wenwen Qiang, Ying Ba, Bing Su, Ji-Rong Wen</li>
<li>for: 这 paper written for 人体动作预测（HMP）的研究， aiming to address the challenges of HMP due to the stochastic and aperiodic nature of future poses.</li>
<li>methods: 该 paper 使用了一种新的 spatio-temporal branching network 来进行 HMP，该网络可以 decouple 时间频率和空间频率的学习，从而提取更多的动作信息并实现跨频率知识学习。</li>
<li>results: 根据标准 HMP 测试准则，该 paper 的方法在预测动作的精度方面表现出色，超过了当前状态的方法。<details>
<summary>Abstract</summary>
Human motion prediction (HMP) has emerged as a popular research topic due to its diverse applications, but it remains a challenging task due to the stochastic and aperiodic nature of future poses. Traditional methods rely on hand-crafted features and machine learning techniques, which often struggle to model the complex dynamics of human motion. Recent deep learning-based methods have achieved success by learning spatio-temporal representations of motion, but these models often overlook the reliability of motion data. Additionally, the temporal and spatial dependencies of skeleton nodes are distinct. The temporal relationship captures motion information over time, while the spatial relationship describes body structure and the relationships between different nodes. In this paper, we propose a novel spatio-temporal branching network using incremental information for HMP, which decouples the learning of temporal-domain and spatial-domain features, extracts more motion information, and achieves complementary cross-domain knowledge learning through knowledge distillation. Our approach effectively reduces noise interference and provides more expressive information for characterizing motion by separately extracting temporal and spatial features. We evaluate our approach on standard HMP benchmarks and outperform state-of-the-art methods in terms of prediction accuracy.
</details>
<details>
<summary>摘要</summary>
人体运动预测（HMP）已经成为一个流行的研究话题，因为它在多个应用领域中具有广泛的应用前景。然而，HMP仍然是一个具有抽象和不规则的未来姿势的挑战。传统的方法通常使用手工设计的特征和机器学习技术来模型人体运动，但这些方法经常难以捕捉人体运动的复杂动力学特征。最近的深度学习基于方法已经取得成功，通过学习人体运动的空间时间表示，但这些模型经常忽略人体运动数据的可靠性。此外，人体运动中的时间和空间关系不同。时间关系捕捉运动信息的时间方向，而空间关系描述人体结构和不同节点之间的关系。在本文中，我们提出了一种新的空间时间分支网络，使得HMP可以分解时间领域和空间领域的学习，提取更多的运动信息，并通过知识储存来实现补做知识学习。我们的方法可以更好地减少噪音干扰，并为运动特征的描述提供更多的表达信息。我们在标准HMP测试benchmark上评估了我们的方法，并在预测精度方面超过了状态 искусственный智能方法。
</details></li>
</ul>
<hr>
<h2 id="AutoPoster-A-Highly-Automatic-and-Content-aware-Design-System-for-Advertising-Poster-Generation"><a href="#AutoPoster-A-Highly-Automatic-and-Content-aware-Design-System-for-Advertising-Poster-Generation" class="headerlink" title="AutoPoster: A Highly Automatic and Content-aware Design System for Advertising Poster Generation"></a>AutoPoster: A Highly Automatic and Content-aware Design System for Advertising Poster Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01095">http://arxiv.org/abs/2308.01095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinpeng Lin, Min Zhou, Ye Ma, Yifan Gao, Chenxi Fei, Yangjian Chen, Zhang Yu, Tiezheng Ge</li>
<li>for: 这个论文是用于创建广告招牌的自动生成系统。</li>
<li>methods: 这个系统使用了多个阶段，包括图像清洁和重新目标、布局生成、标语生成和Style Attribute Predictor（SAP）。两个内容感知模型也是在布局和标语生成过程中使用。</li>
<li>results: 这个系统可以将来自单一图像和标题的输入转换为多个不同尺寸的广告招牌，并且可以提供高品质的广告招牌。用户研究和实验结果显示，这个系统比其他广告招牌生成方法更有效率和有艺术价值。<details>
<summary>Abstract</summary>
Advertising posters, a form of information presentation, combine visual and linguistic modalities. Creating a poster involves multiple steps and necessitates design experience and creativity. This paper introduces AutoPoster, a highly automatic and content-aware system for generating advertising posters. With only product images and titles as inputs, AutoPoster can automatically produce posters of varying sizes through four key stages: image cleaning and retargeting, layout generation, tagline generation, and style attribute prediction. To ensure visual harmony of posters, two content-aware models are incorporated for layout and tagline generation. Moreover, we propose a novel multi-task Style Attribute Predictor (SAP) to jointly predict visual style attributes. Meanwhile, to our knowledge, we propose the first poster generation dataset that includes visual attribute annotations for over 76k posters. Qualitative and quantitative outcomes from user studies and experiments substantiate the efficacy of our system and the aesthetic superiority of the generated posters compared to other poster generation methods.
</details>
<details>
<summary>摘要</summary>
宣传海报是信息传达的一种形式，它将视觉和语言Modalities结合在一起。创建海报需要多个步骤，需要设计经验和创造力。本文介绍AutoPoster，一种高度自动化和内容意识的海报生成系统。只需输入产品图像和标题，AutoPoster可以自动生成不同尺寸的海报，通过四个关键阶段：图像清洁和重点调整、布局生成、标语生成和风格特征预测。为保证海报的视觉和谐，我们将两个内容意识模型 incorporated into layout and tagline generation。此外，我们提出了一种新的多任务Style Attribute Predictor (SAP)，可以同时预测视觉风格特征。此外，我们还提供了首个包含视觉特征注释的海报生成数据集，包含超过76万个海报。用户测试和实验结果表明，我们的系统和生成的海报比其他海报生成方法更有效果和美观。
</details></li>
</ul>
<hr>
<h2 id="Attention-free-Spikformer-Mixing-Spike-Sequences-with-Simple-Linear-Transforms"><a href="#Attention-free-Spikformer-Mixing-Spike-Sequences-with-Simple-Linear-Transforms" class="headerlink" title="Attention-free Spikformer: Mixing Spike Sequences with Simple Linear Transforms"></a>Attention-free Spikformer: Mixing Spike Sequences with Simple Linear Transforms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02557">http://arxiv.org/abs/2308.02557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingyu Wang, Duzhen Zhang, Tielin Zhang, Bo Xu</li>
<li>for: 这个论文的目的是将Transformer架构应用到神经元活动频率的神经网络（SNN）中，并通过自注意力能力和生物学性质来提高SNN的性能。</li>
<li>methods: 这篇论文使用了一种名为Spiking Self-Attention（SSA）模块，将笛声 Query、Key、Value混合在一起，从而实现了State-Of-The-Art（SOTA）性能在多个数据集上，比之前的SNN-like框架更高。</li>
<li>results: 研究表明，通过将SSA替换为无参数化的线性变换（LT），例如快推和wavelet变换，可以将 quadratic time complexity 降低到 log-linear time complexity。这些变换可以将笛声序列混合，并且在不同的频率和时间域中提取稀疏的视觉特征，以显示出强大的性能和效率。<details>
<summary>Abstract</summary>
By integrating the self-attention capability and the biological properties of Spiking Neural Networks (SNNs), Spikformer applies the flourishing Transformer architecture to SNNs design. It introduces a Spiking Self-Attention (SSA) module to mix sparse visual features using spike-form Query, Key, and Value, resulting in the State-Of-The-Art (SOTA) performance on numerous datasets compared to previous SNN-like frameworks. In this paper, we demonstrate that the Spikformer architecture can be accelerated by replacing the SSA with an unparameterized Linear Transform (LT) such as Fourier and Wavelet transforms. These transforms are utilized to mix spike sequences, reducing the quadratic time complexity to log-linear time complexity. They alternate between the frequency and time domains to extract sparse visual features, showcasing powerful performance and efficiency. We conduct extensive experiments on image classification using both neuromorphic and static datasets. The results indicate that compared to the SOTA Spikformer with SSA, Spikformer with LT achieves higher Top-1 accuracy on neuromorphic datasets (i.e., CIFAR10-DVS and DVS128 Gesture) and comparable Top-1 accuracy on static datasets (i.e., CIFAR-10 and CIFAR-100). Furthermore, Spikformer with LT achieves approximately 29-51% improvement in training speed, 61-70% improvement in inference speed, and reduces memory usage by 4-26% due to not requiring learnable parameters.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用自注意力能力和生物特性，Spikformer将Transformer架构应用于生物神经网络（SNN）设计。它引入了自引导注意力（SSA）模块，将稀薄视觉特征混合使用披萃Query、Key和Value，达到了State-Of-The-Art（SOTA）性能在多个数据集上，比前一些SNN-like框架更高。在这篇论文中，我们示出了Spikformer架构可以通过替换SSA而加速。这些替换使用线性变换（LT），如 fourier和wavelet变换，来混合披萃序列，从而将时间复杂度降低为对数复杂度。它们在频率和时间域之间 alternate，提取稀薄视觉特征，展示出了强大的性能和效率。我们对图像分类进行了广泛的实验，使用了neuromorphic和静止数据集。结果表明，相比SOTA的Spikformer与SSA，Spikformer与LT achieve higher Top-1准确率在neuromorphic数据集（即CIFAR10-DVS和DVS128Gesture），并在静止数据集（即CIFAR-10和CIFAR-100）中具有相同的Top-1准确率。此外，Spikformer与LT achieve approximately 29-51%的训练速度提升，61-70%的推理速度提升，并减少了内存使用量。Note: The translation is in Simplified Chinese, which is the standard Chinese writing system used in mainland China and Singapore. The traditional Chinese writing system is also widely used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Homography-Estimation-in-Complex-Topological-Scenes"><a href="#Homography-Estimation-in-Complex-Topological-Scenes" class="headerlink" title="Homography Estimation in Complex Topological Scenes"></a>Homography Estimation in Complex Topological Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01086">http://arxiv.org/abs/2308.01086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giacomo D’Amicantonio, Egor Bondarau, Peter H. N. De With</li>
<li>for: 这个论文是用于提出一种自动化摄像头协调方法，以应对环境因素和小型摄像头运动对摄像头协调数据的影响。</li>
<li>methods: 本文使用了一个字典型架构方法，不需要任何摄像头设定的专业知识。方法包括一个自订的空间变换网络（STN）和一个新的顶点损失函数。</li>
<li>results: 实验结果显示，提案的方法可以与现有模型相比，提高了IoU指标的值，最高提升12%。<details>
<summary>Abstract</summary>
Surveillance videos and images are used for a broad set of applications, ranging from traffic analysis to crime detection. Extrinsic camera calibration data is important for most analysis applications. However, security cameras are susceptible to environmental conditions and small camera movements, resulting in a need for an automated re-calibration method that can account for these varying conditions. In this paper, we present an automated camera-calibration process leveraging a dictionary-based approach that does not require prior knowledge on any camera settings. The method consists of a custom implementation of a Spatial Transformer Network (STN) and a novel topological loss function. Experiments reveal that the proposed method improves the IoU metric by up to 12% w.r.t. a state-of-the-art model across five synthetic datasets and the World Cup 2014 dataset.
</details>
<details>
<summary>摘要</summary>
侦察视频和图像广泛应用于交通分析和犯罪检测等领域。外部摄像头准确性受环境因素和小型摄像头运动影响，需要一种自动重新准确方法，能够考虑这些变化条件。本文提出了一种基于词典方法的自动摄像头准确方法，不需要任何摄像头设置的先前知识。该方法包括一个自定义的空间转换网络（STN）和一个新的 topological 损失函数。实验表明，提议的方法可以与先前状态艺术模型相比，在五个Synthetic dataset和2014年世界杯 dataset上提高 IoU 指标达12%。
</details></li>
</ul>
<hr>
<h2 id="Improving-Generalization-of-Synthetically-Trained-Sonar-Image-Descriptors-for-Underwater-Place-Recognition"><a href="#Improving-Generalization-of-Synthetically-Trained-Sonar-Image-Descriptors-for-Underwater-Place-Recognition" class="headerlink" title="Improving Generalization of Synthetically Trained Sonar Image Descriptors for Underwater Place Recognition"></a>Improving Generalization of Synthetically Trained Sonar Image Descriptors for Underwater Place Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01058">http://arxiv.org/abs/2308.01058</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ivano-donadi/sdpr">https://github.com/ivano-donadi/sdpr</a></li>
<li>paper_authors: Ivano Donadi, Emilio Olivastri, Daniel Fusaro, Wanmeng Li, Daniele Evangelista, Alberto Pretto</li>
<li>for: 本研究旨在开发一种能够在各种水下环境中进行自主导航的方法，因为光学感知器在水中受到透光和浊度等因素的影响，而SONAR系统则不受这些影响。</li>
<li>methods: 本研究使用了一种基于ResNet18的封闭神经网络架构，并使用了随机抽象幂等技术来增强输入SONAR数据。</li>
<li>results: 研究表明，提议的方法可以在使用synthetic数据进行训练的情况下，与现有方法相比，在真实场景中表现更加出色。<details>
<summary>Abstract</summary>
Autonomous navigation in underwater environments presents challenges due to factors such as light absorption and water turbidity, limiting the effectiveness of optical sensors. Sonar systems are commonly used for perception in underwater operations as they are unaffected by these limitations. Traditional computer vision algorithms are less effective when applied to sonar-generated acoustic images, while convolutional neural networks (CNNs) typically require large amounts of labeled training data that are often unavailable or difficult to acquire. To this end, we propose a novel compact deep sonar descriptor pipeline that can generalize to real scenarios while being trained exclusively on synthetic data. Our architecture is based on a ResNet18 back-end and a properly parameterized random Gaussian projection layer, whereas input sonar data is enhanced with standard ad-hoc normalization/prefiltering techniques. A customized synthetic data generation procedure is also presented. The proposed method has been evaluated extensively using both synthetic and publicly available real data, demonstrating its effectiveness compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
自适应导航在水下环境中存在许多挑战，如光线吸收和水渍混淆，这些因素对光学感知器的效果有限。因此，SONAR系统在水下操作中被广泛使用，因为它们不受这些限制。传统的计算机视觉算法在SONAR生成的声学图像上不太有效，而深度学习网络（CNN）通常需要大量的标注训练数据，这些数据通常不易获得或困难获得。为此，我们提出了一种新的快速深度声学描述管道，可以在实际场景中广泛应用，同时只需要在合成数据上进行培训。我们的架构基于ResNet18的后端和一个正确参数化的随机抽象射影层，输入声学数据通过标准的预处理/正规化技术进行增强。我们还提出了一种自定义合成数据生成过程。我们的方法在使用合成数据和公共available的实际数据进行广泛评估后，与现有方法相比，表现出了明显的效果。
</details></li>
</ul>
<hr>
<h2 id="MammoDG-Generalisable-Deep-Learning-Breaks-the-Limits-of-Cross-Domain-Multi-Center-Breast-Cancer-Screening"><a href="#MammoDG-Generalisable-Deep-Learning-Breaks-the-Limits-of-Cross-Domain-Multi-Center-Breast-Cancer-Screening" class="headerlink" title="MammoDG: Generalisable Deep Learning Breaks the Limits of Cross-Domain Multi-Center Breast Cancer Screening"></a>MammoDG: Generalisable Deep Learning Breaks the Limits of Cross-Domain Multi-Center Breast Cancer Screening</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01057">http://arxiv.org/abs/2308.01057</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijun Yang, Shujun Wang, Lihao Liu, Sarah Hickman, Fiona J Gilbert, Carola-Bibiane Schönlieb, Angelica I. Aviles-Rivero</li>
<li>for: 旨在提高乳腺癌早期发现，以提高治疗效果和女性生活质量。</li>
<li>methods: 利用机器学习模型支持专家决策。</li>
<li>results: 提出了一种新的深度学习框架 MammoDG，可以在不同卫星中心的多视图照片上进行可靠和通用的分析。 MammoDG 利用了一种新的对比机制，以提高其通用能力。<details>
<summary>Abstract</summary>
Breast cancer is a major cause of cancer death among women, emphasising the importance of early detection for improved treatment outcomes and quality of life. Mammography, the primary diagnostic imaging test, poses challenges due to the high variability and patterns in mammograms. Double reading of mammograms is recommended in many screening programs to improve diagnostic accuracy but increases radiologists' workload. Researchers explore Machine Learning models to support expert decision-making. Stand-alone models have shown comparable or superior performance to radiologists, but some studies note decreased sensitivity with multiple datasets, indicating the need for high generalisation and robustness models. This work devises MammoDG, a novel deep-learning framework for generalisable and reliable analysis of cross-domain multi-center mammography data. MammoDG leverages multi-view mammograms and a novel contrastive mechanism to enhance generalisation capabilities. Extensive validation demonstrates MammoDG's superiority, highlighting the critical importance of domain generalisation for trustworthy mammography analysis in imaging protocol variations.
</details>
<details>
<summary>摘要</summary>
乳癌是女性主要的癌症死亡原因之一，强调早期检测可以提高治疗效果和生活质量。 however，环境变化和图像征特的高度变化使得胸部X射线成为主要的诊断图像检测方法具有挑战。为了提高诊断准确性，许多检测 програм序建议采用双重诊断，但这会增加医生的工作负担。研究人员在寻找机器学习模型以支持专家决策。单独的研究表明，机器学习模型可以与专家相比或超越其性能，但一些研究表明，多个数据集的使用可能会导致感知性下降，表明需要高度泛化和可靠性模型。本文提出了 MammoDG，一种新的深度学习框架，用于可靠和泛化的胸部X射线数据分析。 MammoDG 利用多视图照片和一种新的对比机制来增强泛化能力。经验证明， MammoDG 的性能明显优于其他方法， highlighting the critical importance of domain generalization for trustworthy mammography analysis in imaging protocol variations。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Token-Pruning-in-Plain-Vision-Transformers-for-Semantic-Segmentation"><a href="#Dynamic-Token-Pruning-in-Plain-Vision-Transformers-for-Semantic-Segmentation" class="headerlink" title="Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation"></a>Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01045">http://arxiv.org/abs/2308.01045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quan Tang, Bowen Zhang, Jiajun Liu, Fagiu Liu, Yifan Liu</li>
<li>for: 这个研究目的是为了提高 semantic segmentation 任务的计算效率，使用 Dynamic Token Pruning (DToP) 方法来节省计算成本。</li>
<li>methods: 这个方法基于 early exit 的思想，将网络分成多个阶段，每个阶段都有一个 auxiliary block，评估每个 tokens 的困难程度。只需要完成前几个阶段的运算就能够获得结果，以减少计算量。</li>
<li>results: 实验结果显示，提案的 DToP 架构可以降低平均 $20% - 35%$ 的计算成本，与现有的 semantic segmentation 方法相比，不会影响精度。<details>
<summary>Abstract</summary>
Vision transformers have achieved leading performance on various visual tasks yet still suffer from high computational complexity. The situation deteriorates in dense prediction tasks like semantic segmentation, as high-resolution inputs and outputs usually imply more tokens involved in computations. Directly removing the less attentive tokens has been discussed for the image classification task but can not be extended to semantic segmentation since a dense prediction is required for every patch. To this end, this work introduces a Dynamic Token Pruning (DToP) method based on the early exit of tokens for semantic segmentation. Motivated by the coarse-to-fine segmentation process by humans, we naturally split the widely adopted auxiliary-loss-based network architecture into several stages, where each auxiliary block grades every token's difficulty level. We can finalize the prediction of easy tokens in advance without completing the entire forward pass. Moreover, we keep $k$ highest confidence tokens for each semantic category to uphold the representative context information. Thus, computational complexity will change with the difficulty of the input, akin to the way humans do segmentation. Experiments suggest that the proposed DToP architecture reduces on average $20\% - 35\%$ of computational cost for current semantic segmentation methods based on plain vision transformers without accuracy degradation.
</details>
<details>
<summary>摘要</summary>
现代变换器已经在多种视觉任务中表现出了领先的性能，然而仍然受到高计算复杂性的限制。在密集预测任务如Semantic Segmentation中，高分辨率输入和输出通常意味着更多的 токен参与计算。直接从计算中移除不重要的 токен已经在图像分类任务上被讨论，但这种方法无法扩展到Semantic Segmentation，因为每个 patch 需要进行密集预测。为解决这个问题，这种工作提出了一种基于早期离开的 Token Pruning（DToP）方法。受人类的粗化预测过程启发，我们自然将广泛采用的辅助损失基于网络架构分成了多个阶段，每个辅助块都会评估每个 токен的Difficulty Level。因此，我们可以在提前完成某些简单的预测之前就结束预测。此外，我们保留每个 semantic 类型的前 $k$ 个最高信任的 токен，以保持代表性信息。因此，计算复杂性会随输入的Difficulty Level而变化，与人类的分 segmentation 类似。实验表明，我们提出的 DToP 架构可以将现有的Semantic Segmentation方法基于普通的视觉变换器中的计算复杂性减少平均 $20\% - 35\%$  без影响准确性。
</details></li>
</ul>
<hr>
<h2 id="WCCNet-Wavelet-integrated-CNN-with-Crossmodal-Rearranging-Fusion-for-Fast-Multispectral-Pedestrian-Detection"><a href="#WCCNet-Wavelet-integrated-CNN-with-Crossmodal-Rearranging-Fusion-for-Fast-Multispectral-Pedestrian-Detection" class="headerlink" title="WCCNet: Wavelet-integrated CNN with Crossmodal Rearranging Fusion for Fast Multispectral Pedestrian Detection"></a>WCCNet: Wavelet-integrated CNN with Crossmodal Rearranging Fusion for Fast Multispectral Pedestrian Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01042">http://arxiv.org/abs/2308.01042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingjian Wang, Li Chai, Jiming Chen, Zhiguo Shi<br>for:本文提出了一种新的和高效的多spectral人体检测框架，它能够有效地提高人体检测的可见性，并且具有更高的计算效率和精度。methods:该框架基于 dual-stream backbone，其中一个流程用 discrete wavelet transform (DWT) 进行快速推理和训练，另一个流程使用 CNN 层进行特征提取。此外，本文还提出了一种 crossmodal rearranging fusion module (CMRF)，可以 Mitigate spatial misalignment和merge semantically complementary features of spatially-related local regions。results:根据 KAIST 和 FLIR 测试套件的评估结果，WCCNet 在计算效率和精度之间做出了极大的折衔，并且与当前的状态革命性方法进行比较。此外，本文还进行了 ablation study，并进行了深入的组件对性能的分析。<details>
<summary>Abstract</summary>
Multispectral pedestrian detection achieves better visibility in challenging conditions and thus has a broad application in various tasks, for which both the accuracy and computational cost are of paramount importance. Most existing approaches treat RGB and infrared modalities equally, typically adopting two symmetrical CNN backbones for multimodal feature extraction, which ignores the substantial differences between modalities and brings great difficulty for the reduction of the computational cost as well as effective crossmodal fusion. In this work, we propose a novel and efficient framework named WCCNet that is able to differentially extract rich features of different spectra with lower computational complexity and semantically rearranges these features for effective crossmodal fusion. Specifically, the discrete wavelet transform (DWT) allowing fast inference and training speed is embedded to construct a dual-stream backbone for efficient feature extraction. The DWT layers of WCCNet extract frequency components for infrared modality, while the CNN layers extract spatial-domain features for RGB modality. This methodology not only significantly reduces the computational complexity, but also improves the extraction of infrared features to facilitate the subsequent crossmodal fusion. Based on the well extracted features, we elaborately design the crossmodal rearranging fusion module (CMRF), which can mitigate spatial misalignment and merge semantically complementary features of spatially-related local regions to amplify the crossmodal complementary information. We conduct comprehensive evaluations on KAIST and FLIR benchmarks, in which WCCNet outperforms state-of-the-art methods with considerable computational efficiency and competitive accuracy. We also perform the ablation study and analyze thoroughly the impact of different components on the performance of WCCNet.
</details>
<details>
<summary>摘要</summary>
多spectrum行人检测可以在具有挑战性的条件下提供更好的可见性，因此在不同任务中具有广泛的应用。在这些任务中，精度和计算成本都是非常重要的。大多数现有方法都会对RGB和红外Modalities进行相同的处理，通常采用两个对称的CNN背bone来进行多Modal feature抽取，这会忽略modalities之间的重要差异，并且使得计算成本减少和有效的交叉模态融合变得非常困难。在这种情况下，我们提出了一种新的和高效的框架，名为WCCNet，可以在低计算成本下 differentially抽取不同 спектrum的丰富特征，并将这些特征semantically重新排序以实现有效的交叉模态融合。具体来说，WCCNet中使用了束波变换(DWT)，以便快速进行推理和训练。DWT层EXTRACT frequency component for infrared modality，而CNN层EXTRACT spatial-domain features for RGB modality。这种方法不仅可以减少计算成本，还可以提高infrared特征的提取，以便后续的交叉模态融合。基于良好地EXTRACT的特征，我们在WCCNet中进行了详细的交叉模态重新排序融合模块(CMRF)的设计，可以抵消空间misalignment和semantic complementary feature of spatially-related local regionsmerge to amplify the crossmodal complementary information.我们在KAIST和FLIRbenchmark上进行了广泛的评估，并发现WCCNet在计算效率和精度方面都高于当前的状态方法。我们还进行了归 subtractive study和仔细分析了不同组件对WCCNet性能的影响。
</details></li>
</ul>
<hr>
<h2 id="TS-RGBD-Dataset-a-Novel-Dataset-for-Theatre-Scenes-Description-for-People-with-Visual-Impairments"><a href="#TS-RGBD-Dataset-a-Novel-Dataset-for-Theatre-Scenes-Description-for-People-with-Visual-Impairments" class="headerlink" title="TS-RGBD Dataset: a Novel Dataset for Theatre Scenes Description for People with Visual Impairments"></a>TS-RGBD Dataset: a Novel Dataset for Theatre Scenes Description for People with Visual Impairments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01035">http://arxiv.org/abs/2308.01035</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/khadidja-delloul/rgb-d-theatre-scenes-dataset">https://github.com/khadidja-delloul/rgb-d-theatre-scenes-dataset</a></li>
<li>paper_authors: Leyla Benhamida, Khadidja Delloul, Slimane Larabi<br>for: 这篇论文是为了提供一个新的RGB-D数据集，用于图像描述和人体动作识别。methods: 这篇论文使用了Microsoft Kinect捕获RGB、深度和骨骼序列数据，并提供了人体动作识别和图像描述模型的评估。results: 研究人员通过在TS-RGBD数据集上测试图像描述模型和骨骼基于人体动作识别模型，发现这些模型可以在剧场场景中探测人类动作和描述场景中的区域特征。<details>
<summary>Abstract</summary>
Computer vision was long a tool used for aiding visually impaired people to move around their environment and avoid obstacles and falls. Solutions are limited to either indoor or outdoor scenes, which limits the kind of places and scenes visually disabled people can be in, including entertainment places such as theatres. Furthermore, most of the proposed computer-vision-based methods rely on RGB benchmarks to train their models resulting in a limited performance due to the absence of the depth modality.   In this paper, we propose a novel RGB-D dataset containing theatre scenes with ground truth human actions and dense captions annotations for image captioning and human action recognition: TS-RGBD dataset. It includes three types of data: RGB, depth, and skeleton sequences, captured by Microsoft Kinect.   We test image captioning models on our dataset as well as some skeleton-based human action recognition models in order to extend the range of environment types where a visually disabled person can be, by detecting human actions and textually describing appearances of regions of interest in theatre scenes.
</details>
<details>
<summary>摘要</summary>
计算机视觉曾长期用于帮助视障人群在环境中移动和避免障碍和落体。现有的解决方案主要限制在indoor或outdoor场景中，这限制了视障人群可以在的场所和场景，包括娱乐场所如剧场。此外，大多数提出的计算机视觉基本方法依赖RGB标准准确数据来训练其模型，这导致模型性能有限因为缺少深度特征。在本文中，我们提出一个新的RGB-D数据集，包括剧场场景，具有真实人行为和描述镜像照片的文本描述。该数据集包括三类数据：RGB、深度和骨架幕，通过微软Kinect捕获。我们对我们的数据集进行图像描述和人体动作识别模型的测试，以扩展视障人群可以在的环境类型，通过检测人体动作和描述相关区域的出现方式来描述剧场场景。
</details></li>
</ul>
<hr>
<h2 id="Point-Anywhere-Directed-Object-Estimation-from-Omnidirectional-Images"><a href="#Point-Anywhere-Directed-Object-Estimation-from-Omnidirectional-Images" class="headerlink" title="Point Anywhere: Directed Object Estimation from Omnidirectional Images"></a>Point Anywhere: Directed Object Estimation from Omnidirectional Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01010">http://arxiv.org/abs/2308.01010</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nkotani/pointanywhere">https://github.com/nkotani/pointanywhere</a></li>
<li>paper_authors: Nanami Kotani, Asako Kanezaki</li>
<li>for: 这个研究旨在提高 робот导航中的指示方法精度。</li>
<li>methods: 该方法使用全景相机，以消除用户&#x2F;物体位置约束和指示臂左右约束。具体来说， repeatedly extracting regions of interest from equirectangular images and projecting them onto perspective images 可以实现高精度的估计。</li>
<li>results: 该方法可以提高估计精度，并且通过训练机器学习模型进一步提高估计精度。<details>
<summary>Abstract</summary>
One of the intuitive instruction methods in robot navigation is a pointing gesture. In this study, we propose a method using an omnidirectional camera to eliminate the user/object position constraint and the left/right constraint of the pointing arm. Although the accuracy of skeleton and object detection is low due to the high distortion of equirectangular images, the proposed method enables highly accurate estimation by repeatedly extracting regions of interest from the equirectangular image and projecting them onto perspective images. Furthermore, we found that training the likelihood of the target object in machine learning further improves the estimation accuracy.
</details>
<details>
<summary>摘要</summary>
一种直观的导航指南方法是指示手势。在这项研究中，我们提出了使用全景相机来消除用户/物体位置约束和指示手势的左右约束。虽然投影图像的矩形误差导致skeleton和物体检测精度较低，但我们的方法可以通过重复提取全景图像中的区域并将其投影到平视图中，实现高精度的估算。此外，我们发现通过机器学习来训练目标物体的可能性可以进一步提高估算精度。
</details></li>
</ul>
<hr>
<h2 id="MDT3D-Multi-Dataset-Training-for-LiDAR-3D-Object-Detection-Generalization"><a href="#MDT3D-Multi-Dataset-Training-for-LiDAR-3D-Object-Detection-Generalization" class="headerlink" title="MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization"></a>MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01000">http://arxiv.org/abs/2308.01000</a></li>
<li>repo_url: None</li>
<li>paper_authors: Louis Soum-Fontez, Jean-Emmanuel Deschaud, François Goulette</li>
<li>For:	+ The paper aims to improve the robustness of 3D object detection models when tested in new environments with different sensor configurations.* Methods:	+ The authors propose a Multi-Dataset Training for 3D Object Detection (MDT3D) method that leverages information from several annotated source datasets to increase the robustness of 3D object detection models.	+ The authors use a new label mapping based on coarse labels to tackle the labelling gap between datasets.	+ They also introduce a new cross-dataset augmentation method called cross-dataset object injection.* Results:	+ The authors demonstrate improvements in 3D object detection performance using their MDT3D method, compared to training on a single dataset.	+ The improvements are shown for different types of 3D object detection models.Here is the simplified Chinese translation of the three key information points:* For:	+ 论文目标是提高3D对象检测模型在新环境中的可靠性，即使使用不同的感知器配置。* Methods:	+ 作者提出了一种多个源数据集合训练的3D对象检测模型（MDT3D）方法，以利用多个标注源数据集的信息来提高3D对象检测模型的Robustness。	+ 作者采用了一种新的标签映射方法，以 Address the labelling gap between datasets。	+ 他们还引入了一种新的跨数据集增强方法：跨数据集对象注入。* Results:	+ 作者展示了使用MDT3D方法的3D对象检测性能提高，比单个数据集训练 better。	+ 提高的性能适用于不同类型的3D对象检测模型。<details>
<summary>Abstract</summary>
Supervised 3D Object Detection models have been displaying increasingly better performance in single-domain cases where the training data comes from the same environment and sensor as the testing data. However, in real-world scenarios data from the target domain may not be available for finetuning or for domain adaptation methods. Indeed, 3D object detection models trained on a source dataset with a specific point distribution have shown difficulties in generalizing to unseen datasets. Therefore, we decided to leverage the information available from several annotated source datasets with our Multi-Dataset Training for 3D Object Detection (MDT3D) method to increase the robustness of 3D object detection models when tested in a new environment with a different sensor configuration. To tackle the labelling gap between datasets, we used a new label mapping based on coarse labels. Furthermore, we show how we managed the mix of datasets during training and finally introduce a new cross-dataset augmentation method: cross-dataset object injection. We demonstrate that this training paradigm shows improvements for different types of 3D object detection models. The source code and additional results for this research project will be publicly available on GitHub for interested parties to access and utilize: https://github.com/LouisSF/MDT3D
</details>
<details>
<summary>摘要</summary>
超级vised 3D对象检测模型在单域场景中表现越来越好，但在实际应用中数据可能不可用于训练或适应方法。实际上，基于特定点分布的3D对象检测模型在未seen数据集上采集的数据上表现不佳。因此，我们决定利用多个注释源数据集的信息，通过我们的多个数据集训练方法（MDT3D）提高3D对象检测模型在新环境中的鲁棒性。为了bridging数据集之间的标签差距，我们使用了一种新的标签映射基于粗略标签。此外，我们描述了在训练中混合数据集的方法，以及一种新的交叉数据集增强方法：交叉数据集对象注入。我们证明了这种训练方法对不同类型的3D对象检测模型都有改进。GitHub上将公开源代码和额外结果，欢迎有兴趣的朋友来取得和利用：https://github.com/LouisSF/MDT3D。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Synthetic-Data-for-Data-Imbalance-Problems-Baselines-from-a-Data-Perspective"><a href="#Exploiting-Synthetic-Data-for-Data-Imbalance-Problems-Baselines-from-a-Data-Perspective" class="headerlink" title="Exploiting Synthetic Data for Data Imbalance Problems: Baselines from a Data Perspective"></a>Exploiting Synthetic Data for Data Imbalance Problems: Baselines from a Data Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00994">http://arxiv.org/abs/2308.00994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moon Ye-Bin, Nam Hyeon-Woo, Wonseok Choi, Nayeong Kim, Suha Kwak, Tae-Hyun Oh</li>
<li>for: addressing data imbalance problems in deep neural networks</li>
<li>methods: utilizes synthetic data as a preliminary step before employing task-specific algorithms</li>
<li>results: impressive performance on several datasets, surpassing the performance of existing task-specific methods<details>
<summary>Abstract</summary>
We live in a vast ocean of data, and deep neural networks are no exception to this. However, this data exhibits an inherent phenomenon of imbalance. This imbalance poses a risk of deep neural networks producing biased predictions, leading to potentially severe ethical and social consequences. To address these challenges, we believe that the use of generative models is a promising approach for comprehending tasks, given the remarkable advancements demonstrated by recent diffusion models in generating high-quality images. In this work, we propose a simple yet effective baseline, SYNAuG, that utilizes synthetic data as a preliminary step before employing task-specific algorithms to address data imbalance problems. This straightforward approach yields impressive performance on datasets such as CIFAR100-LT, ImageNet100-LT, UTKFace, and Waterbird, surpassing the performance of existing task-specific methods. While we do not claim that our approach serves as a complete solution to the problem of data imbalance, we argue that supplementing the existing data with synthetic data proves to be an effective and crucial preliminary step in addressing data imbalance concerns.
</details>
<details>
<summary>摘要</summary>
我们生活在一个庞大的数据洋面中，深度神经网络也不例外。然而，这些数据具有内在的不均衡现象，这可能导致深度神经网络预测结果受到偏见，从而导致严重的伦理和社会后果。为解决这些挑战，我们认为使用生成模型是一种有前途的方法，因为最近的扩散模型在生成高质量图像方面已经展示出了很好的进步。在这种工作中，我们提出了一个简单 yet有效的基线方法，即SYNAuG，它利用 synthetic data 作为先决步骤，然后使用任务特定的算法来解决数据不均衡问题。这种简单的方法在 CIFAR100-LT、ImageNet100-LT、UTKFace 和 Waterbird 等数据集上实现了很好的性能，超过了现有的任务特定方法的表现。虽然我们不能声称我们的方法是解决数据不均衡问题的完整解决方案，但我们认为在增加现有数据的同时使用 synthetic data 作为先决步骤是一种有效和重要的步骤。
</details></li>
</ul>
<hr>
<h2 id="Orientation-Guided-Contrastive-Learning-for-UAV-View-Geo-Localisation"><a href="#Orientation-Guided-Contrastive-Learning-for-UAV-View-Geo-Localisation" class="headerlink" title="Orientation-Guided Contrastive Learning for UAV-View Geo-Localisation"></a>Orientation-Guided Contrastive Learning for UAV-View Geo-Localisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00982">http://arxiv.org/abs/2308.00982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fabian Deuser, Konrad Habel, Martin Werner, Norbert Oswald</li>
<li>for: 本研究旨在开发一种基于UAV视图的地理定位方法，以提高现有地理定位技术的准确性和效率。</li>
<li>methods: 本方法基于UAV视图的射线对齐，使用了层次地理定位的方法来估算UAV图像的方向。同时，我们还提出了一种轻量级预测模块，可以预测UAV图像之间的方向关系。</li>
<li>results: 我们在University-1652和University-160k datasets上进行了实验，并得到了比前方法更高的性能。在推理阶段，我们不再需要OrientationModule，这意味着在实际应用中不需要额外计算。<details>
<summary>Abstract</summary>
Retrieving relevant multimedia content is one of the main problems in a world that is increasingly data-driven. With the proliferation of drones, high quality aerial footage is now available to a wide audience for the first time. Integrating this footage into applications can enable GPS-less geo-localisation or location correction.   In this paper, we present an orientation-guided training framework for UAV-view geo-localisation. Through hierarchical localisation orientations of the UAV images are estimated in relation to the satellite imagery. We propose a lightweight prediction module for these pseudo labels which predicts the orientation between the different views based on the contrastive learned embeddings. We experimentally demonstrate that this prediction supports the training and outperforms previous approaches. The extracted pseudo-labels also enable aligned rotation of the satellite image as augmentation to further strengthen the generalisation. During inference, we no longer need this orientation module, which means that no additional computations are required. We achieve state-of-the-art results on both the University-1652 and University-160k datasets.
</details>
<details>
<summary>摘要</summary>
世界变得数据驱动， retrieve relevant multimedia content成为主要问题。随着无人机的普及，高质量的飞行视频现在可以为广泛的用户开放。将这些视频集成到应用程序中可以实现无GPS地理定位或位置修正。在这篇论文中，我们提出了无人机视图地理定位的委托导向训练框架。通过层次的地理定位方向，我们估算了无人机图像与卫星图像之间的方向关系。我们提出了一个轻量级预测模块，这个模块基于对比学习的嵌入学习来预测不同视图之间的方向。我们实验表明，这种预测支持训练并超过了之前的方法。提取的pseudo标签还可以帮助对卫星图像进行平行旋转的调整，以进一步强化通用化。在推理阶段，我们再无需该方向模块，因此不需要额外的计算。我们在University-1652和University-160k数据集上实现了状态机器人的结果。
</details></li>
</ul>
<hr>
<h2 id="ForensicsForest-Family-A-Series-of-Multi-scale-Hierarchical-Cascade-Forests-for-Detecting-GAN-generated-Faces"><a href="#ForensicsForest-Family-A-Series-of-Multi-scale-Hierarchical-Cascade-Forests-for-Detecting-GAN-generated-Faces" class="headerlink" title="ForensicsForest Family: A Series of Multi-scale Hierarchical Cascade Forests for Detecting GAN-generated Faces"></a>ForensicsForest Family: A Series of Multi-scale Hierarchical Cascade Forests for Detecting GAN-generated Faces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00964">http://arxiv.org/abs/2308.00964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiucui Lu, Yuezun Li, Jiaran Zhou, Bin Li, Junyu Dong, Siwei Lyu</li>
<li>for: 本研究旨在应对由Generative Adversarial Networks（GAN）生成的伪造面部图像，以实现更高的伪造探测率。</li>
<li>methods: 本研究使用了森林模型，包括ForensicsForest、Hybrid ForensicsForest和Divide-and-Conquer ForensicsForest三种。ForensicsForest是一种新提出的多级堆式森林，使用语义、频率和生物特征作为输入，层次堆式不同级别的特征进行伪造预测，并使用多级集成方案来进一步提高性能。Hybrid ForensicsForest是一种将CNN层 integrate到模型中的扩展版本，以进一步提高特征的吸收和融合。Divide-and-Conquer ForensicsForest是一种分解森林模型，只需在训练阶段使用一部分的训练样本来构建森林模型。</li>
<li>results: 在实验中，ForensicsForest Family的三种变种都达到了比较高的伪造探测率，并且在不同的伪造率下都能够保持一定的稳定性。Hybrid ForensicsForest和Divide-and-Conquer ForensicsForest相比，后者在减少内存开销的同时，能够保持相对高的伪造探测率。<details>
<summary>Abstract</summary>
The prominent progress in generative models has significantly improved the reality of generated faces, bringing serious concerns to society. Since recent GAN-generated faces are in high realism, the forgery traces have become more imperceptible, increasing the forensics challenge. To combat GAN-generated faces, many countermeasures based on Convolutional Neural Networks (CNNs) have been spawned due to their strong learning ability. In this paper, we rethink this problem and explore a new approach based on forest models instead of CNNs. Specifically, we describe a simple and effective forest-based method set called {\em ForensicsForest Family} to detect GAN-generate faces. The proposed ForensicsForest family is composed of three variants, which are {\em ForensicsForest}, {\em Hybrid ForensicsForest} and {\em Divide-and-Conquer ForensicsForest} respectively. ForenscisForest is a newly proposed Multi-scale Hierarchical Cascade Forest, which takes semantic, frequency and biology features as input, hierarchically cascades different levels of features for authenticity prediction, and then employs a multi-scale ensemble scheme that can comprehensively consider different levels of information to improve the performance further. Based on ForensicsForest, we develop Hybrid ForensicsForest, an extended version that integrates the CNN layers into models, to further refine the effectiveness of augmented features. Moreover, to reduce the memory cost in training, we propose Divide-and-Conquer ForensicsForest, which can construct a forest model using only a portion of training samplings. In the training stage, we train several candidate forest models using the subsets of training samples. Then a ForensicsForest is assembled by picking the suitable components from these candidate forest models...
</details>
<details>
<summary>摘要</summary>
“由于生成模型的杰出进步，生成的面部现场具有高现实性，对社会带来了严重的担忧。由于最近的GAN生成面部具有高真实性，因此伪造的迹象 becames more imperceptible，增加了侦错挑战。为了解决GAN生成面部的问题，许多基于Convolutional Neural Networks（CNNs）的对策被生成。在这篇论文中，我们重新思考这个问题，并探索一个新的方法，基于森林模型而不是CNNs。具体来说，我们描述了一个简单而有效的森林模型家族，called “ForensicsForest Family”，用于检测GAN生成面部。我们的提案的ForensicsForest是一个新的多层次堆栈森林，它接受 semantic、frequency和生物特征，在不同的层次进行堆积不同的特征，然后使用多层次组合 scheme，具体来说是使用多个不同层次的特征来进一步提高表现。基于ForensicsForest，我们发展了Hybrid ForensicsForest，一个扩展版本，它在模型中添加了CNN层，以进一步提高增强特征的效果。此外，为了降低训练阶段的内存成本，我们提出了Divide-and-Conquer ForensicsForest，这个方法可以将森林模型建立成多个子集的训练样本。在训练阶段，我们将训练多个候选的森林模型，然后选择适合的部分来建立一个ForensicsForest。”
</details></li>
</ul>
<hr>
<h2 id="Curriculum-Guided-Domain-Adaptation-in-the-Dark"><a href="#Curriculum-Guided-Domain-Adaptation-in-the-Dark" class="headerlink" title="Curriculum Guided Domain Adaptation in the Dark"></a>Curriculum Guided Domain Adaptation in the Dark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00956">http://arxiv.org/abs/2308.00956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chowdhury Sadman Jahan, Andreas Savakis</li>
<li>for: 这篇论文目的是为了解决对于隐私和安全性的担忧，在黑盒模型中进行页面适应，以适应一个未标注的目标领域，并且不需要任何源数据或源模型参数。</li>
<li>methods: 这篇论文使用了一个名为Curriculum Adaptation for Black-Box（CABB）的curriculum导向适应方法，它会逐渐地训练目标模型，首先是在目标数据上高信度（清洁）的标签下进行训练，然后是在目标数据上噪音标签下进行训练。CABB使用了Jensen-Shannon散度作为更好的混合标签分类标准，并且使用了对应分支网络来抑制错误堆积的错误识别。</li>
<li>results: 实验结果显示，CABB比 EXISTS的黑盒页面适应模型好，并且与白盒页面适应模型相近。<details>
<summary>Abstract</summary>
Addressing the rising concerns of privacy and security, domain adaptation in the dark aims to adapt a black-box source trained model to an unlabeled target domain without access to any source data or source model parameters. The need for domain adaptation of black-box predictors becomes even more pronounced to protect intellectual property as deep learning based solutions are becoming increasingly commercialized. Current methods distill noisy predictions on the target data obtained from the source model to the target model, and/or separate clean/noisy target samples before adapting using traditional noisy label learning algorithms. However, these methods do not utilize the easy-to-hard learning nature of the clean/noisy data splits. Also, none of the existing methods are end-to-end, and require a separate fine-tuning stage and an initial warmup stage. In this work, we present Curriculum Adaptation for Black-Box (CABB) which provides a curriculum guided adaptation approach to gradually train the target model, first on target data with high confidence (clean) labels, and later on target data with noisy labels. CABB utilizes Jensen-Shannon divergence as a better criterion for clean-noisy sample separation, compared to the traditional criterion of cross entropy loss. Our method utilizes co-training of a dual-branch network to suppress error accumulation resulting from confirmation bias. The proposed approach is end-to-end trainable and does not require any extra finetuning stage, unlike existing methods. Empirical results on standard domain adaptation datasets show that CABB outperforms existing state-of-the-art black-box DA models and is comparable to white-box domain adaptation models.
</details>
<details>
<summary>摘要</summary>
In this work, we present Curriculum Adaptation for Black-Box (CABB) which provides a curriculum-guided adaptation approach to gradually train the target model, first on target data with high confidence (clean) labels, and later on target data with noisy labels. CABB utilizes Jensen-Shannon divergence as a better criterion for clean-noisy sample separation compared to the traditional criterion of cross-entropy loss. Our method utilizes co-training of a dual-branch network to suppress error accumulation resulting from confirmation bias. The proposed approach is end-to-end trainable and does not require any extra fine-tuning stage, unlike existing methods.Empirical results on standard domain adaptation datasets show that CABB outperforms existing state-of-the-art black-box DA models and is comparable to white-box domain adaptation models.
</details></li>
</ul>
<hr>
<h2 id="Training-Free-Instance-Segmentation-from-Semantic-Image-Segmentation-Masks"><a href="#Training-Free-Instance-Segmentation-from-Semantic-Image-Segmentation-Masks" class="headerlink" title="Training-Free Instance Segmentation from Semantic Image Segmentation Masks"></a>Training-Free Instance Segmentation from Semantic Image Segmentation Masks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00949">http://arxiv.org/abs/2308.00949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ssyc123/tfiseg">https://github.com/ssyc123/tfiseg</a></li>
<li>paper_authors: Yuchen Shen, Dong Zhang, Yuhui Zheng, Zechao Li, Liyong Fu, Qiaolin Ye</li>
<li>for: 提高实例分割的效率，不需要额外的人工标注或计算成本增加。</li>
<li>methods: 使用已经训练的semantic segmentation模型预测图像分割mask，然后计算每个像素的偏移场vector，最终通过learable category-agnostic object boundary branch进行修正，实现实例分割结果。</li>
<li>results: 在两个复杂的dataset上和多种基线模型（包括CNN和Transformers）进行了广泛的实验，得到了与state-of-the-art Fully-supervised实例分割方法相当的结果，而无需额外的人工资源或计算成本增加。<details>
<summary>Abstract</summary>
In recent years, the development of instance segmentation has garnered significant attention in a wide range of applications. However, the training of a fully-supervised instance segmentation model requires costly both instance-level and pixel-level annotations. In contrast, weakly-supervised instance segmentation methods (i.e., with image-level class labels or point labels) struggle to satisfy the accuracy and recall requirements of practical scenarios. In this paper, we propose a novel paradigm for instance segmentation called training-free instance segmentation (TFISeg), which achieves instance segmentation results from image masks predicted using off-the-shelf semantic segmentation models. TFISeg does not require training a semantic or/and instance segmentation model and avoids the need for instance-level image annotations. Therefore, it is highly efficient. Specifically, we first obtain a semantic segmentation mask of the input image via a trained semantic segmentation model. Then, we calculate a displacement field vector for each pixel based on the segmentation mask, which can indicate representations belonging to the same class but different instances, i.e., obtaining the instance-level object information. Finally, instance segmentation results are obtained after being refined by a learnable category-agnostic object boundary branch. Extensive experimental results on two challenging datasets and representative semantic segmentation baselines (including CNNs and Transformers) demonstrate that TFISeg can achieve competitive results compared to the state-of-the-art fully-supervised instance segmentation methods without the need for additional human resources or increased computational costs. The code is available at: TFISeg
</details>
<details>
<summary>摘要</summary>
Recently, the development of instance segmentation has received significant attention in a wide range of applications. However, fully-supervised instance segmentation models require expensive instance-level and pixel-level annotations. In contrast, weakly-supervised instance segmentation methods (i.e., with image-level class labels or point labels) cannot meet the accuracy and recall requirements of practical scenarios. In this paper, we propose a novel instance segmentation paradigm called training-free instance segmentation (TFISeg), which achieves instance segmentation results from image masks predicted using off-the-shelf semantic segmentation models. TFISeg does not require training a semantic or/and instance segmentation model and avoids the need for instance-level image annotations. Therefore, it is highly efficient. Specifically, we first obtain a semantic segmentation mask of the input image via a trained semantic segmentation model. Then, we calculate a displacement field vector for each pixel based on the segmentation mask, which can indicate representations belonging to the same class but different instances, i.e., obtaining the instance-level object information. Finally, instance segmentation results are obtained after being refined by a learnable category-agnostic object boundary branch. Extensive experimental results on two challenging datasets and representative semantic segmentation baselines (including CNNs and Transformers) demonstrate that TFISeg can achieve competitive results compared to the state-of-the-art fully-supervised instance segmentation methods without the need for additional human resources or increased computational costs. The code is available at: TFISeg.
</details></li>
</ul>
<hr>
<h2 id="Decomposing-and-Coupling-Saliency-Map-for-Lesion-Segmentation-in-Ultrasound-Images"><a href="#Decomposing-and-Coupling-Saliency-Map-for-Lesion-Segmentation-in-Ultrasound-Images" class="headerlink" title="Decomposing and Coupling Saliency Map for Lesion Segmentation in Ultrasound Images"></a>Decomposing and Coupling Saliency Map for Lesion Segmentation in Ultrasound Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00947">http://arxiv.org/abs/2308.00947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenyuan Ning, Yixiao Mao, Qianjin Feng, Shengzhou Zhong, Yu Zhang</li>
<li>for: 这篇论文的目的是为了提高聚合调察影像中的肿瘤分类精度，应对肿瘤区域与周围组织（background）之间的像素强度相似性和细节图样问题。</li>
<li>methods: 这篇论文提出了一个名为DC-Net的分解联系网络，通过将原始影像转换为肿瘤和背景两个saliency map，然后进行精确的分类。DC-Net包括分解和联系子网络，其中前者先将影像分解为肿瘤和背景两个saliency map，然后后者将这两个saliency map联系在一起，以实现精确的分类。</li>
<li>results: 这篇论文的结果显示，使用DC-Net可以实现聚合调察影像中肿瘤分类的高精度，并且比前一代方法提高了许多。<details>
<summary>Abstract</summary>
Complex scenario of ultrasound image, in which adjacent tissues (i.e., background) share similar intensity with and even contain richer texture patterns than lesion region (i.e., foreground), brings a unique challenge for accurate lesion segmentation. This work presents a decomposition-coupling network, called DC-Net, to deal with this challenge in a (foreground-background) saliency map disentanglement-fusion manner. The DC-Net consists of decomposition and coupling subnets, and the former preliminarily disentangles original image into foreground and background saliency maps, followed by the latter for accurate segmentation under the assistance of saliency prior fusion. The coupling subnet involves three aspects of fusion strategies, including: 1) regional feature aggregation (via differentiable context pooling operator in the encoder) to adaptively preserve local contextual details with the larger receptive field during dimension reduction; 2) relation-aware representation fusion (via cross-correlation fusion module in the decoder) to efficiently fuse low-level visual characteristics and high-level semantic features during resolution restoration; 3) dependency-aware prior incorporation (via coupler) to reinforce foreground-salient representation with the complementary information derived from background representation. Furthermore, a harmonic loss function is introduced to encourage the network to focus more attention on low-confidence and hard samples. The proposed method is evaluated on two ultrasound lesion segmentation tasks, which demonstrates the remarkable performance improvement over existing state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
复杂的超声图像场景，邻近组织（即背景）与病変区域（即前景）的像素强度和文本URE模式都非常相似，带来了准确病变分割的独特挑战。这个工作提出了一种 decomposition-coupling 网络（DC-Net），通过 fore- ground-background 敏感地图分离融合来解决这个挑战。DC-Net 包括 decomposition 和 coupling 子网络，前者先将原始图像粗略地分解成病变和背景的敏感地图，然后后者使用敏感融合来进行准确的分割。 coupling 子网络包括三种融合策略：1）地域特征聚合（通过可微的上下文池Operator在编码器中），以适应大的辐射场景保留地方Contextual details; 2）关系意识表示融合（通过cross-correlation融合模块在解码器中），以高效地融合低级视觉特征和高级 semantics Features during resolution restoration; 3）依赖关系 Prior 包含（通过coupler），以强制前景敏感表示与背景表示DERIVE complementary information。此外，我们还引入了一种和谐损失函数，以促进网络更多地关注低信任和困难样本。我们的方法在两个超声病变分割任务上进行了评估，并达到了现有状态的杰出性提高。
</details></li>
</ul>
<hr>
<h2 id="WaterFlow-Heuristic-Normalizing-Flow-for-Underwater-Image-Enhancement-and-Beyond"><a href="#WaterFlow-Heuristic-Normalizing-Flow-for-Underwater-Image-Enhancement-and-Beyond" class="headerlink" title="WaterFlow: Heuristic Normalizing Flow for Underwater Image Enhancement and Beyond"></a>WaterFlow: Heuristic Normalizing Flow for Underwater Image Enhancement and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00931">http://arxiv.org/abs/2308.00931</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zengxi Zhang, Zhiying Jiang, Jinyuan Liu, Xin Fan, Risheng Liu</li>
<li>for: 提高水下图像质量和应用可行性</li>
<li>methods: 使用归一化流进行探测驱动的水下图像增强，并包含了环境光和媒体传输率的归一化，以及检测感知模块来传递隐式Semantic指导到增强过程中</li>
<li>results: 对比state-of-the-art方法，水下图像增强方法提高了质量和可行性<details>
<summary>Abstract</summary>
Underwater images suffer from light refraction and absorption, which impairs visibility and interferes the subsequent applications. Existing underwater image enhancement methods mainly focus on image quality improvement, ignoring the effect on practice. To balance the visual quality and application, we propose a heuristic normalizing flow for detection-driven underwater image enhancement, dubbed WaterFlow. Specifically, we first develop an invertible mapping to achieve the translation between the degraded image and its clear counterpart. Considering the differentiability and interpretability, we incorporate the heuristic prior into the data-driven mapping procedure, where the ambient light and medium transmission coefficient benefit credible generation. Furthermore, we introduce a detection perception module to transmit the implicit semantic guidance into the enhancement procedure, where the enhanced images hold more detection-favorable features and are able to promote the detection performance. Extensive experiments prove the superiority of our WaterFlow, against state-of-the-art methods quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
水下图像受到光折射和吸收的影响，导致视觉效果下降，同时影响后续应用。现有水下图像提升方法主要关注图像质量改进，忽略了实际应用的效果。为了平衡视觉质量和实际应用，我们提议一种基于归一化流的探测驱动水下图像提升方法，称为WaterFlow。specifically，我们首先开发了一个可逆映射，以实现水下图像和其清晰版本之间的翻译。在考虑到可 diferenciability和可 interpretability的情况下，我们将HEURISTIC prior incorporated into the data-driven mapping procedure，其中 ambient light和medium transmission coefficient benefit credible generation。此外，我们引入了探测感知模块，以将隐式的Semantic guidance传递给提升过程，这些提升后的图像具有更多的探测利好特征，能够提高探测性能。广泛的实验证明了我们的WaterFlow，在量化和 каче性上胜过当前状态的方法。
</details></li>
</ul>
<hr>
<h2 id="Towards-Discriminative-Representation-with-Meta-learning-for-Colonoscopic-Polyp-Re-Identification"><a href="#Towards-Discriminative-Representation-with-Meta-learning-for-Colonoscopic-Polyp-Re-Identification" class="headerlink" title="Towards Discriminative Representation with Meta-learning for Colonoscopic Polyp Re-Identification"></a>Towards Discriminative Representation with Meta-learning for Colonoscopic Polyp Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00929">http://arxiv.org/abs/2308.00929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suncheng Xiang, Qingzhong Chen, Shilun Cai, Chengfeng Zhou, Crystal Cai, Sijia Du, Dahong Qian</li>
<li>for: 这个论文目的是提出一种基于meta-学习的colonoscopic polyp re-identification方法，以帮助模型学习更加普适和特异的知识，并且可以在少量样本的情况下达到更高的表现。</li>
<li>methods: 该方法使用了一种名为Colo-ReID的简单 yet effective的训练方法，该方法基于meta-学习策略，可以在不同的摄像头和视图下提高polyp re-identification的表现。此外，该方法还提出了一种名为MLR的动态Meta-Learning Regulation机制，可以进一步提高模型的表现。</li>
<li>results: 实验结果表明，该方法可以明显超越当前的状态机器人的方法，并且在不同的摄像头和视图下都可以保持高度的表现。<details>
<summary>Abstract</summary>
Colonoscopic Polyp Re-Identification aims to match the same polyp from a large gallery with images from different views taken using different cameras and plays an important role in the prevention and treatment of colorectal cancer in computer-aided diagnosis. However, traditional methods for object ReID directly adopting CNN models trained on the ImageNet dataset usually produce unsatisfactory retrieval performance on colonoscopic datasets due to the large domain gap. Additionally, these methods neglect to explore the potential of self-discrepancy among intra-class relations in the colonoscopic polyp dataset, which remains an open research problem in the medical community. To solve this dilemma, we propose a simple but effective training method named Colo-ReID, which can help our model to learn more general and discriminative knowledge based on the meta-learning strategy in scenarios with fewer samples. Based on this, a dynamic Meta-Learning Regulation mechanism called MLR is introduced to further boost the performance of polyp re-identification. To the best of our knowledge, this is the first attempt to leverage the meta-learning paradigm instead of traditional machine learning to effectively train deep models in the task of colonoscopic polyp re-identification. Empirical results show that our method significantly outperforms current state-of-the-art methods by a clear margin.
</details>
<details>
<summary>摘要</summary>
干扰识别是一种重要的计算机辅助诊断技术，旨在将同一个肿瘤从大量图像库中匹配到不同视角和不同摄像头拍摄的图像中。但是，传统的对象识别方法通常在计算机辅助诊断中表现不 satisfactory，因为它们直接采用基于 ImageNet 数据集训练的 CNN 模型，而这些模型在干扰识别任务中存在很大的领域差距。此外，这些方法忽略了干扰识别任务中的自体差异，这是医学社区还未解决的一个开放问题。为解决这个问题，我们提出了一种简单 yet effective 的训练方法，称为 Colo-ReID。这种方法可以帮助我们的模型学习更一般和特征 rich 的知识，基于元学习策略在scenario中 avec fewer samples。此外，我们还提出了一种动态元学习调节机制，称为 MLR，以进一步提高肿瘤重新识别性能。到目前为止，这是首次在干扰识别任务中采用元学习 paradigm，而不是传统机器学习方法，以有效地训练深度模型。实验结果表明，我们的方法在肿瘤重新识别任务中显著超过当前状态的方法。
</details></li>
</ul>
<hr>
<h2 id="Detection-and-Segmentation-of-Cosmic-Objects-Based-on-Adaptive-Thresholding-and-Back-Propagation-Neural-Network"><a href="#Detection-and-Segmentation-of-Cosmic-Objects-Based-on-Adaptive-Thresholding-and-Back-Propagation-Neural-Network" class="headerlink" title="Detection and Segmentation of Cosmic Objects Based on Adaptive Thresholding and Back Propagation Neural Network"></a>Detection and Segmentation of Cosmic Objects Based on Adaptive Thresholding and Back Propagation Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00926">http://arxiv.org/abs/2308.00926</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samia Sultana, Shyla Afroge</li>
<li>for: 这篇论文旨在提高宇宙对象的分类和检测，使用适应resholding方法和反射神经网络。</li>
<li>methods: 这篇论文使用了适应resholding方法和反射神经网络，并包括了一系列优化预处理步骤，以提高分类和检测的精度。</li>
<li>results: 这篇论文通过使用适应resholding方法和反射神经网络，实现了高精度的宇宙对象分类和检测。<details>
<summary>Abstract</summary>
Astronomical images provide information about the great variety of cosmic objects in the Universe. Due to the large volumes of data, the presence of innumerable bright point sources as well as noise within the frame and the spatial gap between objects and satellite cameras, it is a challenging task to classify and detect the celestial objects. We propose an Adaptive Thresholding Method (ATM) based segmentation and Back Propagation Neural Network (BPNN) based cosmic object detection including a well-structured series of pre-processing steps designed to enhance segmentation and detection.
</details>
<details>
<summary>摘要</summary>
天文图像提供宇宙中各种不同类型的天体信息。由于数据量庞大，充满灯点源和扫描器镜头之间的空间差距，以及图像中的噪声，因此分类和检测天体是一项复杂的任务。我们提出了适应resholding方法（ATM）基于分割和基于迷你网络（BPNN）基于天体物体检测，包括一系列井井有条的预处理步骤，用于提高分割和检测。
</details></li>
</ul>
<hr>
<h2 id="Continual-Domain-Adaptation-on-Aerial-Images-under-Gradually-Degrading-Weather"><a href="#Continual-Domain-Adaptation-on-Aerial-Images-under-Gradually-Degrading-Weather" class="headerlink" title="Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather"></a>Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00924">http://arxiv.org/abs/2308.00924</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sadman-jahan/aid-ucm-degradingweather">https://github.com/sadman-jahan/aid-ucm-degradingweather</a></li>
<li>paper_authors: Chowdhury Sadman Jahan, Andreas Savakis</li>
<li>for: 这个研究旨在探讨适应域随着时间的变化，对于在天空平台上部署深度学习模型进行适应。</li>
<li>methods: 研究使用了两种逐渐恶化的天气情况，将其应用到现有的天空图像Dataset上，实现了四个benchmark Dataset。在 continual setting 中，评估了三种适应模型，包括基eline DA模型和两种continual DA模型。</li>
<li>results: 研究发现了对于现有的缓冲适应方法存在稳定问题，并提出了一个简单的Gradient normalization方法来缓和训练不稳定。<details>
<summary>Abstract</summary>
Domain adaptation (DA) strives to mitigate the domain gap between the source domain where a model is trained, and the target domain where the model is deployed. When a deep learning model is deployed on an aerial platform, it may face gradually degrading weather conditions during operation, leading to widening domain gaps between the training data and the encountered evaluation data. We synthesize two such gradually worsening weather conditions on real images from two existing aerial imagery datasets, generating a total of four benchmark datasets. Under the continual, or test-time adaptation setting, we evaluate three DA models on our datasets: a baseline standard DA model and two continual DA models. In such setting, the models can access only one small portion, or one batch of the target data at a time, and adaptation takes place continually, and over only one epoch of the data. The combination of the constraints of continual adaptation, and gradually deteriorating weather conditions provide the practical DA scenario for aerial deployment. Among the evaluated models, we consider both convolutional and transformer architectures for comparison. We discover stability issues during adaptation for existing buffer-fed continual DA methods, and offer gradient normalization as a simple solution to curb training instability.
</details>
<details>
<summary>摘要</summary>
域适应（DA）目的是减少源域和目标域之间的域隔，以便在不同域隔下使用模型。当深度学习模型在飞行平台上部署时，可能会遇到逐渐恶化的天气条件，导致模型训练数据和评估数据之间的域隔变得更大。我们使用两个现有的飞行图像数据集来生成两种慢恶化的天气条件，并生成了四个benchmark dataset。在 continual setting下，我们评估了三个DA模型，包括标准DA模型和两个 continual DA模型。在这种设定下，模型只能访问一小部分或一批目标数据，并且adaptation只能在一个epoch的数据上进行。 combinaison of continual adaptation和慢恶化天气条件提供了实际的DAenario for aerial deployment。我们考虑了 convolutional和 transformer架构进行比较。我们发现了 continual adaptation中的稳定问题，并提供了 gradient normalization作为一种简单的解决方案来缓解训练不稳定。
</details></li>
</ul>
<hr>
<h2 id="Survey-on-Computer-Vision-Techniques-for-Internet-of-Things-Devices"><a href="#Survey-on-Computer-Vision-Techniques-for-Internet-of-Things-Devices" class="headerlink" title="Survey on Computer Vision Techniques for Internet-of-Things Devices"></a>Survey on Computer Vision Techniques for Internet-of-Things Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02553">http://arxiv.org/abs/2308.02553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ishmeet Kaur, Adwaita Janardhan Jadhav</li>
<li>for: 这个论文旨在探讨如何使深度神经网络（DNNs）在有限的计算资源下进行部署，以提高公共安全。</li>
<li>methods: 这篇论文总结了最近的低功率和能源效率DNN实现技术，包括减少内存需求、数学运算数量或两者之一。这些技术可以分为三个主要类别：神经网络压缩、网络架构搜索和设计、编译器和图格优化。</li>
<li>results: 这篇论文总结了各种低功率技术的优缺点和未解决的问题，以及它们在 convolutional 和 transformer DNN 中的应用。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are state-of-the-art techniques for solving most computer vision problems. DNNs require billions of parameters and operations to achieve state-of-the-art results. This requirement makes DNNs extremely compute, memory, and energy-hungry, and consequently difficult to deploy on small battery-powered Internet-of-Things (IoT) devices with limited computing resources. Deployment of DNNs on Internet-of-Things devices, such as traffic cameras, can improve public safety by enabling applications such as automatic accident detection and emergency response.Through this paper, we survey the recent advances in low-power and energy-efficient DNN implementations that improve the deployability of DNNs without significantly sacrificing accuracy. In general, these techniques either reduce the memory requirements, the number of arithmetic operations, or both. The techniques can be divided into three major categories: neural network compression, network architecture search and design, and compiler and graph optimizations. In this paper, we survey both low-power techniques for both convolutional and transformer DNNs, and summarize the advantages, disadvantages, and open research problems.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）是现代计算机视觉问题的州际技术。DNN需要数百亿个参数和运算来实现州际 результаados，这使得DNN具有极高的计算、存储和能源需求，因此难以在具有有限的计算资源的小型Internet of Things（IoT）设备上部署。然而，通过部署DNN在交通摄像头等IoT设备上，可以提高公共安全性，例如自动检测事故并触发紧急应急回应。本文概述了最近几年关于低功耗和能效的DNN实现方法，以提高DNN的部署可能性，不会导致重要的精度损失。这些方法可以分为三大类：神经网络压缩、网络架构搜索和设计，以及编译器和图像优化。本文将对低功耗的 convolutional 和 transformer DNN 进行概述，并评价其优缺点和未解决的问题。
</details></li>
</ul>
<hr>
<h2 id="Degeneration-Tuning-Using-Scrambled-Grid-shield-Unwanted-Concepts-from-Stable-Diffusion"><a href="#Degeneration-Tuning-Using-Scrambled-Grid-shield-Unwanted-Concepts-from-Stable-Diffusion" class="headerlink" title="Degeneration-Tuning: Using Scrambled Grid shield Unwanted Concepts from Stable Diffusion"></a>Degeneration-Tuning: Using Scrambled Grid shield Unwanted Concepts from Stable Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02552">http://arxiv.org/abs/2308.02552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixuan Ni, Longhui Wei, Jiacheng Li, Siliang Tang, Yueting Zhuang, Qi Tian</li>
<li>For: This paper aims to protect the generative model from generating inappropriate or dangerous content, such as specific intellectual property (IP), human faces, and various artistic styles, by shielding the unwanted concepts from the model’s weights.* Methods: The proposed method, called Degeneration-Tuning (DT), uses Scrambled Grid to reconstruct the correlation between undesired concepts and their corresponding image domain, and guides the text-to-image diffusion model to generate meaningless content when such textual concepts are provided as input.* Results: The proposed DT method effectively shields the unwanted concepts from the model’s weights, without significantly impacting the generative quality of other contents. The FID and IS scores of the model on COCO-30K exhibit only minor changes after DT, shifting from 12.61 and 39.20 to 13.04 and 38.25, respectively, which outperforms previous methods.Here’s the simplified Chinese text in the format you requested:* For: 保护生成模型从生成不当或危险内容，如特定知识产权（IP）、人脸和多种艺术风格。* Methods: 提出的方法是叫做“干扰调整”（DT），使用扰乱网格重建不良概念和其对应的图像域之间的相关性，使模型对这些文本概念提供输入时生成无意义的内容。* Results: DT方法能够成功隔离模型的概念，不会对其他内容产生重要影响。COCO-30K上的FID和IS分数只有微小变化，从12.61和39.20变化到13.04和38.25，这明显超越了之前的方法。<details>
<summary>Abstract</summary>
Owing to the unrestricted nature of the content in the training data, large text-to-image diffusion models, such as Stable Diffusion (SD), are capable of generating images with potentially copyrighted or dangerous content based on corresponding textual concepts information. This includes specific intellectual property (IP), human faces, and various artistic styles. However, Negative Prompt, a widely used method for content removal, frequently fails to conceal this content due to inherent limitations in its inference logic. In this work, we propose a novel strategy named \textbf{Degeneration-Tuning (DT)} to shield contents of unwanted concepts from SD weights. By utilizing Scrambled Grid to reconstruct the correlation between undesired concepts and their corresponding image domain, we guide SD to generate meaningless content when such textual concepts are provided as input. As this adaptation occurs at the level of the model's weights, the SD, after DT, can be grafted onto other conditional diffusion frameworks like ControlNet to shield unwanted concepts. In addition to qualitatively showcasing the effectiveness of our DT method in protecting various types of concepts, a quantitative comparison of the SD before and after DT indicates that the DT method does not significantly impact the generative quality of other contents. The FID and IS scores of the model on COCO-30K exhibit only minor changes after DT, shifting from 12.61 and 39.20 to 13.04 and 38.25, respectively, which clearly outperforms the previous methods.
</details>
<details>
<summary>摘要</summary>
由于训练数据的内容是不受限制的，大型文本到图像扩散模型，如稳定扩散（SD），可以根据相关的文本概念信息生成图像，包括特定的知识产权（IP）、人脸和多种艺术风格。然而，负面提示，一种广泛使用的内容 removals 方法，常常无法隐藏这些内容，因为其推理逻辑的内在限制。在这种工作中，我们提出了一种新的策略，即倒退调整（DT），以隐藏 SD 权重中不良的内容。通过使用扰乱网格重建不良概念和其相应的图像领域之间的相关性，我们使 SD 生成无意义的内容，当提供这些文本概念时。由于这种适应发生在模型权重 niveau，SD 之后的 DT 可以与其他条件扩散框架，如控制网络（ControlNet），结合使用。此外，我们还进行了质量比较，发现DT方法对其他内容的生成质量没有显著影响，COCO-30K上的 FID 和 IS 分数从12.61和39.20下降到13.04和38.25，分别提高了1.44和1.95个百分数点，这明显超过了之前的方法。
</details></li>
</ul>
<hr>
<h2 id="Virtual-histological-staining-of-unlabeled-autopsy-tissue"><a href="#Virtual-histological-staining-of-unlabeled-autopsy-tissue" class="headerlink" title="Virtual histological staining of unlabeled autopsy tissue"></a>Virtual histological staining of unlabeled autopsy tissue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00920">http://arxiv.org/abs/2308.00920</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuzhu Li, Nir Pillar, Jingxi Li, Tairan Liu, Di Wu, Songyu Sun, Guangdong Ma, Kevin de Haan, Luzhe Huang, Sepehr Hamidi, Anatoly Urisman, Tal Keidar Haran, William Dean Wallace, Jonathan E. Zuckerman, Aydogan Ozcan</li>
<li>for: 这项研究旨在解决审查尸体组织的传统 histological examination 方法面临的多种挑战，包括延迟 fixation 引起的自体酶分解、大面积组织样本的化学染色方法的资源占用和劳动力成本。</li>
<li>methods: 研究人员使用了一种训练过的神经网络，将染料自由 autopsy 组织切片转化为彩色染色图像，并使用 &gt;0.7 TB 的图像数据和数据效率的合作方案来训练模型。</li>
<li>results: 研究人员发现，使用这种虚拟染色技术可以快速和Cost-effectively 生成高质量的 H&amp;E 染色图像，即使是 COVID-19 样本中受到严重的自体酶分解和细胞死亡的情况下，传统 histochemical staining 方法无法提供一致的染色质量。此外，这种虚拟染色技术还可以扩展到肿瘤组织，并可以快速生成高质量的 H&amp;E 染色图像，减少审查尸体组织的劳动力、成本和基础设施需求。<details>
<summary>Abstract</summary>
Histological examination is a crucial step in an autopsy; however, the traditional histochemical staining of post-mortem samples faces multiple challenges, including the inferior staining quality due to autolysis caused by delayed fixation of cadaver tissue, as well as the resource-intensive nature of chemical staining procedures covering large tissue areas, which demand substantial labor, cost, and time. These challenges can become more pronounced during global health crises when the availability of histopathology services is limited, resulting in further delays in tissue fixation and more severe staining artifacts. Here, we report the first demonstration of virtual staining of autopsy tissue and show that a trained neural network can rapidly transform autofluorescence images of label-free autopsy tissue sections into brightfield equivalent images that match hematoxylin and eosin (H&E) stained versions of the same samples, eliminating autolysis-induced severe staining artifacts inherent in traditional histochemical staining of autopsied tissue. Our virtual H&E model was trained using >0.7 TB of image data and a data-efficient collaboration scheme that integrates the virtual staining network with an image registration network. The trained model effectively accentuated nuclear, cytoplasmic and extracellular features in new autopsy tissue samples that experienced severe autolysis, such as COVID-19 samples never seen before, where the traditional histochemical staining failed to provide consistent staining quality. This virtual autopsy staining technique can also be extended to necrotic tissue, and can rapidly and cost-effectively generate artifact-free H&E stains despite severe autolysis and cell death, also reducing labor, cost and infrastructure requirements associated with the standard histochemical staining.
</details>
<details>
<summary>摘要</summary>
histological examination是毫不可或缺的探验步骤，但传统的历史化学染色方法在尸体样本上面临多种挑战，包括由尸体腐败导致的自释染色质量下降，以及涉及大量化学物质染色过程，需要巨大的劳动力、成本和时间投入。在全球卫生危机期间， Histopathology服务的可用性受限，导致尸体稳定和染色artifacts更加严重。我们现在报道了首次虚拟染色技术的应用，使用训练过的神经网络将自折衍 fluorescence图像转化为同样的H&E染色版本，消除尸体腐败导致的严重染色 artifacts。我们的虚拟H&E模型在 >0.7 TB的图像数据和数据efficient合作方案下进行训练。训练后，模型能够强调尸体中的核、细胞和 extracellular特征，并在新的尸体样本中，如COVID-19样本，提供了高质量的染色图像，传统历史化学染色无法提供一致的染色质量。此虚拟探验染色技术还可以扩展到肿瘤组织，可以快速、成本低地生成 artifact-free H&E染色，即使尸体腐败严重，细胞死亡严重，也可以避免传统历史化学染色所需的劳动力、成本和基础设施。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Cross-Perturbation-for-Single-Domain-Generalization"><a href="#A-Novel-Cross-Perturbation-for-Single-Domain-Generalization" class="headerlink" title="A Novel Cross-Perturbation for Single Domain Generalization"></a>A Novel Cross-Perturbation for Single Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00918">http://arxiv.org/abs/2308.00918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongjia Zhao, Lei Qi, Xiao Shi, Yinghuan Shi, Xin Geng</li>
<li>For: The paper aims to enhance the ability of a model to generalize to unknown domains when trained on a single source domain, by using cross-perturbation and feature-level perturbation methods.* Methods: The paper proposes a simple yet effective cross-perturbation method called CPerb, which utilizes both horizontal and vertical operations to increase data diversity and learn domain-invariant features. Additionally, the paper proposes a novel feature-level perturbation method called MixPatch, which exploits local image style information to further diversify the training data.* Results: The paper achieves state-of-the-art performance on various benchmark datasets, demonstrating the effectiveness of the proposed method in enhancing the generalization capability of the model.<details>
<summary>Abstract</summary>
Single domain generalization aims to enhance the ability of the model to generalize to unknown domains when trained on a single source domain. However, the limited diversity in the training data hampers the learning of domain-invariant features, resulting in compromised generalization performance. To address this, data perturbation (augmentation) has emerged as a crucial method to increase data diversity. Nevertheless, existing perturbation methods often focus on either image-level or feature-level perturbations independently, neglecting their synergistic effects. To overcome these limitations, we propose CPerb, a simple yet effective cross-perturbation method. Specifically, CPerb utilizes both horizontal and vertical operations. Horizontally, it applies image-level and feature-level perturbations to enhance the diversity of the training data, mitigating the issue of limited diversity in single-source domains. Vertically, it introduces multi-route perturbation to learn domain-invariant features from different perspectives of samples with the same semantic category, thereby enhancing the generalization capability of the model. Additionally, we propose MixPatch, a novel feature-level perturbation method that exploits local image style information to further diversify the training data. Extensive experiments on various benchmark datasets validate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>单Domain总结旨在提高模型在未知领域下的泛化能力，但限制的训练数据多样性使得学习领域共同特征受挫。为此，数据扰动（增强）技术已成为提高数据多样性的关键手段。然而，现有的扰动方法通常只关注图像级或特征级扰动，忽视了它们的相互作用。为了解决这些限制，我们提出CPerb，一种简单 yet有效的跨扰动方法。具体来说，CPerb利用图像级和特征级扰动来增强训练数据的多样性，从而解决单源领域中的多样性问题。此外，我们提出MixPatch，一种新的特征级扰动方法，利用本地图像风格信息来进一步让训练数据更加多样。广泛的实验 validate了我们的方法的有效性。Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form as well.
</details></li>
</ul>
<hr>
<h2 id="ImageBrush-Learning-Visual-In-Context-Instructions-for-Exemplar-Based-Image-Manipulation"><a href="#ImageBrush-Learning-Visual-In-Context-Instructions-for-Exemplar-Based-Image-Manipulation" class="headerlink" title="ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation"></a>ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00906">http://arxiv.org/abs/2308.00906</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasheng Sun, Yifan Yang, Houwen Peng, Yifei Shen, Yuqing Yang, Han Hu, Lili Qiu, Hideki Koike</li>
<li>for:  This paper aims to propose a novel image manipulation method that can accurately reflect human intentions without relying on external cross-modal language information.</li>
<li>methods:  The proposed method, called ImageBrush, learns visual instructions for image editing by employing a pair of transformation images as visual instructions. The method uses a diffusion-based inpainting approach to capture the underlying intentions from visual demonstrations and apply them to a new image.</li>
<li>results:  The proposed method generates engaging manipulation results that conform to the transformations entailed in the demonstrations. The method also exhibits robust generalization capabilities on various downstream tasks such as pose transfer, image translation, and video inpainting.<details>
<summary>Abstract</summary>
While language-guided image manipulation has made remarkable progress, the challenge of how to instruct the manipulation process faithfully reflecting human intentions persists. An accurate and comprehensive description of a manipulation task using natural language is laborious and sometimes even impossible, primarily due to the inherent uncertainty and ambiguity present in linguistic expressions. Is it feasible to accomplish image manipulation without resorting to external cross-modal language information? If this possibility exists, the inherent modality gap would be effortlessly eliminated. In this paper, we propose a novel manipulation methodology, dubbed ImageBrush, that learns visual instructions for more accurate image editing. Our key idea is to employ a pair of transformation images as visual instructions, which not only precisely captures human intention but also facilitates accessibility in real-world scenarios. Capturing visual instructions is particularly challenging because it involves extracting the underlying intentions solely from visual demonstrations and then applying this operation to a new image. To address this challenge, we formulate visual instruction learning as a diffusion-based inpainting problem, where the contextual information is fully exploited through an iterative process of generation. A visual prompting encoder is carefully devised to enhance the model's capacity in uncovering human intent behind the visual instructions. Extensive experiments show that our method generates engaging manipulation results conforming to the transformations entailed in demonstrations. Moreover, our model exhibits robust generalization capabilities on various downstream tasks such as pose transfer, image translation and video inpainting.
</details>
<details>
<summary>摘要</summary>
“对于语言导向的图像调整进步了很远，但实际执行人类意图的问题仍然存在。使用自然语言描述调整任务的精确和全面描述是困难且有时是不可能的，主要因为语言表达中固有的不确定和歧义。我们是否可以不对外部跨modal的语言信息进行调整图像？如果这个可能性存在，则无需运用对应的模式差距。在这篇论文中，我们提出了一种新的调整方法，名为ImageBrush，它可以从visual示例中学习更精确的图像编辑指令。我们的关键思想是使用对应的变数图像作为visual指令，这不仅能够准确地表达人类的意图，而且可以在实际应用中更加方便。”Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Approaches-in-Pavement-Distress-Identification-A-Review"><a href="#Deep-Learning-Approaches-in-Pavement-Distress-Identification-A-Review" class="headerlink" title="Deep Learning Approaches in Pavement Distress Identification: A Review"></a>Deep Learning Approaches in Pavement Distress Identification: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00828">http://arxiv.org/abs/2308.00828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sizhe Guan, Haolan Liu, Hamid R. Pourreza, Hamidreza Mahyar</li>
<li>for: 这篇论文旨在探讨近年来图像处理和深度学习技术在公路损害检测和分类方面的最新进展，以替代人工检查，提高效率和准确率。</li>
<li>methods: 论文研究了使用无人机（UAV）收集数据，以获得高分辨率图像，并使用深度学习算法进行检测和分类。</li>
<li>results: 论文发现，使用UAV和深度学习算法可以有效地检测和分类公路损害，并且在2D图像处理方面有所进步，但3D图像处理还存在一些挑战。<details>
<summary>Abstract</summary>
This paper presents a comprehensive review of recent advancements in image processing and deep learning techniques for pavement distress detection and classification, a critical aspect in modern pavement management systems. The conventional manual inspection process conducted by human experts is gradually being superseded by automated solutions, leveraging machine learning and deep learning algorithms to enhance efficiency and accuracy. The ability of these algorithms to discern patterns and make predictions based on extensive datasets has revolutionized the domain of pavement distress identification. The paper investigates the integration of unmanned aerial vehicles (UAVs) for data collection, offering unique advantages such as aerial perspectives and efficient coverage of large areas. By capturing high-resolution images, UAVs provide valuable data that can be processed using deep learning algorithms to detect and classify various pavement distresses effectively. While the primary focus is on 2D image processing, the paper also acknowledges the challenges associated with 3D images, such as sensor limitations and computational requirements. Understanding these challenges is crucial for further advancements in the field. The findings of this review significantly contribute to the evolution of pavement distress detection, fostering the development of efficient pavement management systems. As automated approaches continue to mature, the implementation of deep learning techniques holds great promise in ensuring safer and more durable road infrastructure for the benefit of society.
</details>
<details>
<summary>摘要</summary>
The paper explores the integration of unmanned aerial vehicles (UAVs) for data collection, which offers unique advantages such as aerial perspectives and efficient coverage of large areas. By capturing high-resolution images, UAVs provide valuable data that can be processed using deep learning algorithms to detect and classify various pavement distresses effectively. While the primary focus is on 2D image processing, the paper also acknowledges the challenges associated with 3D images, such as sensor limitations and computational requirements. Understanding these challenges is crucial for further advancements in the field.The findings of this review significantly contribute to the evolution of pavement distress detection, fostering the development of efficient pavement management systems. As automated approaches continue to mature, the implementation of deep learning techniques holds great promise in ensuring safer and more durable road infrastructure for the benefit of society.
</details></li>
</ul>
<hr>
<h2 id="Addressing-Uncertainty-in-Imbalanced-Histopathology-Image-Classification-of-HER2-Breast-Cancer-An-interpretable-Ensemble-Approach-with-Threshold-Filtered-Single-Instance-Evaluation-SIE"><a href="#Addressing-Uncertainty-in-Imbalanced-Histopathology-Image-Classification-of-HER2-Breast-Cancer-An-interpretable-Ensemble-Approach-with-Threshold-Filtered-Single-Instance-Evaluation-SIE" class="headerlink" title="Addressing Uncertainty in Imbalanced Histopathology Image Classification of HER2 Breast Cancer: An interpretable Ensemble Approach with Threshold Filtered Single Instance Evaluation (SIE)"></a>Addressing Uncertainty in Imbalanced Histopathology Image Classification of HER2 Breast Cancer: An interpretable Ensemble Approach with Threshold Filtered Single Instance Evaluation (SIE)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00806">http://arxiv.org/abs/2308.00806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Sakib Hossain Shovon, M. F. Mridha, Khan Md Hasib, Sultan Alfarhood, Mejdl Safran, Dunren Che<br>for:This paper aims to develop an accurate and robust method for diagnosing breast cancer (BC) subtypes based on the expression of Human Epidermal Growth Factor Receptor (HER2).methods:The proposed method utilizes an ensemble approach that combines DenseNet201 and Xception feature extractors, followed by a single instance evaluation (SIE) technique to determine different confidence levels and adjust the decision boundary among the imbalanced classes.results:The proposed approach, called DenseNet201-Xception-SIE, achieved an accuracy of 97.12% on H&amp;E data and 97.56% on IHC data, outperforming all other existing state-of-the-art models. The use of Grad-CAM and Guided Grad-CAM provided insights into how the model works and makes decisions on the histopathology dataset.<details>
<summary>Abstract</summary>
Breast Cancer (BC) is among women's most lethal health concerns. Early diagnosis can alleviate the mortality rate by helping patients make efficient treatment decisions. Human Epidermal Growth Factor Receptor (HER2) has become one the most lethal subtype of BC. According to the College of American Pathologists/American Society of Clinical Oncology (CAP/ASCO), the severity level of HER2 expression can be classified between 0 and 3+ range. HER2 can be detected effectively from immunohistochemical (IHC) and, hematoxylin \& eosin (HE) images of different classes such as 0, 1+, 2+, and 3+. An ensemble approach integrated with threshold filtered single instance evaluation (SIE) technique has been proposed in this study to diagnose BC from the multi-categorical expression of HER2 subtypes. Initially, DenseNet201 and Xception have been ensembled into a single classifier as feature extractors with an effective combination of global average pooling, dropout layer, dense layer with a swish activation function, and l2 regularizer, batch normalization, etc. After that, extracted features has been processed through single instance evaluation (SIE) to determine different confidence levels and adjust decision boundary among the imbalanced classes. This study has been conducted on the BC immunohistochemical (BCI) dataset, which is classified by pathologists into four stages of HER2 BC. This proposed approach known as DenseNet201-Xception-SIE with a threshold value of 0.7 surpassed all other existing state-of-art models with an accuracy of 97.12\%, precision of 97.15\%, and recall of 97.68\% on H\&E data and, accuracy of 97.56\%, precision of 97.57\%, and recall of 98.00\% on IHC data respectively, maintaining momentous improvement. Finally, Grad-CAM and Guided Grad-CAM have been employed in this study to interpret, how TL-based model works on the histopathology dataset and make decisions from the data.
</details>
<details>
<summary>摘要</summary>
乳癌（BC）是女性最致命的健康问题之一。早期诊断可以降低死亡率，帮助患者做出有效的治疗决策。人类皮肤增长因子受体（HER2）是乳癌最致命的一种亚型。根据美国病理学会/美国肿瘤学会（CAP/ASCO）的分类标准，HER2表达严重程度可分为0到3+之间的范围。HER2可以从免疫染色（IHC）和铝染色（HE）图像中有效地探测。本研究提出了一种基于多个表达类型的 ensemble 方法，用于诊断 BC。该方法首先将 DenseNet201 和 Xception  ensemble 为单个分类器的特征提取器，并使用有效的全球均值池化、dropout层、权重抑制层、短束激活函数、L2 regularizer、批处理等技术。然后，提取的特征经过单个实例评估（SIE）处理，以确定不同的信任水平并调整不均衡的类别之间的决策边界。本研究在 BC 免疫染色（BCI）数据集上进行了实验，该数据集由病理学家分为4个HER2 BC的阶段。该提出的方法，称为 DenseNet201-Xception-SIE，在HER2 BC的诊断方面达到了97.12%的准确率、97.15%的精度和97.68%的回归率在HE数据上，以及97.56%的准确率、97.57%的精度和98.00%的回归率在IHC数据上，与现有的所有状态 искус法模型相比，保持了很大的改善。最后， Grad-CAM 和 Guided Grad-CAM 在 histopathology 数据集上被用来解释，如何TL基于模型在数据上工作，从数据中做出决策。
</details></li>
</ul>
<hr>
<h2 id="Body-Knowledge-and-Uncertainty-Modeling-for-Monocular-3D-Human-Body-Reconstruction"><a href="#Body-Knowledge-and-Uncertainty-Modeling-for-Monocular-3D-Human-Body-Reconstruction" class="headerlink" title="Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body Reconstruction"></a>Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00799">http://arxiv.org/abs/2308.00799</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yufei Zhang, Hanjing Wang, Jeffrey O. Kephart, Qiang Ji</li>
<li>for: 提高3D人体重建精度，尝试使用体KB和不确定性模型来补偿不充分的3D监督数据。</li>
<li>methods: 提出了一个名为KNOWN的框架，利用体KB中的通用体约束，并通过 probabilistic 框架来模型 Aleatoric 和 Epistemic 不确定性。</li>
<li>results: 实验显示，KNOWN 的人体重建比先前的弱监督方法高，特别是在困难的少数图像上。<details>
<summary>Abstract</summary>
While 3D body reconstruction methods have made remarkable progress recently, it remains difficult to acquire the sufficiently accurate and numerous 3D supervisions required for training. In this paper, we propose \textbf{KNOWN}, a framework that effectively utilizes body \textbf{KNOW}ledge and u\textbf{N}certainty modeling to compensate for insufficient 3D supervisions. KNOWN exploits a comprehensive set of generic body constraints derived from well-established body knowledge. These generic constraints precisely and explicitly characterize the reconstruction plausibility and enable 3D reconstruction models to be trained without any 3D data. Moreover, existing methods typically use images from multiple datasets during training, which can result in data noise (\textit{e.g.}, inconsistent joint annotation) and data imbalance (\textit{e.g.}, minority images representing unusual poses or captured from challenging camera views). KNOWN solves these problems through a novel probabilistic framework that models both aleatoric and epistemic uncertainty. Aleatoric uncertainty is encoded in a robust Negative Log-Likelihood (NLL) training loss, while epistemic uncertainty is used to guide model refinement. Experiments demonstrate that KNOWN's body reconstruction outperforms prior weakly-supervised approaches, particularly on the challenging minority images.
</details>
<details>
<summary>摘要</summary>
Recently, 3D body reconstruction methods have made significant progress, but acquiring sufficient and accurate 3D supervisions for training remains a challenge. In this paper, we propose KNOWN, a framework that effectively utilizes body knowledge and uncertainty modeling to compensate for insufficient 3D supervisions. KNOWN leverages a comprehensive set of generic body constraints derived from well-established body knowledge, which precisely and explicitly characterize the reconstruction plausibility and enable 3D reconstruction models to be trained without any 3D data. Moreover, existing methods typically use images from multiple datasets during training, which can result in data noise (e.g., inconsistent joint annotation) and data imbalance (e.g., minority images representing unusual poses or captured from challenging camera views). KNOWN solves these problems through a novel probabilistic framework that models both aleatoric and epistemic uncertainty. Aleatoric uncertainty is encoded in a robust Negative Log-Likelihood (NLL) training loss, while epistemic uncertainty is used to guide model refinement. Experimental results demonstrate that KNOWN's body reconstruction outperforms prior weakly-supervised approaches, particularly on challenging minority images.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the standard Mandarin pronunciation and may vary depending on the regional accent or dialect.
</details></li>
</ul>
<hr>
<h2 id="Hybrid-SORT-Weak-Cues-Matter-for-Online-Multi-Object-Tracking"><a href="#Hybrid-SORT-Weak-Cues-Matter-for-Online-Multi-Object-Tracking" class="headerlink" title="Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking"></a>Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00783">http://arxiv.org/abs/2308.00783</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ymzis69/hybirdsort">https://github.com/ymzis69/hybirdsort</a></li>
<li>paper_authors: Mingzhan Yang, Guangxin Han, Bin Yan, Wenhua Zhang, Jinqing Qi, Huchuan Lu, Dong Wang</li>
<li>for: 本研究旨在解决多bject tracking（MOT）中 occlusion 和 clustering 导致 strong cue 失效的问题，通过 incorporating weak cue 进行补做。</li>
<li>methods: 本文引入 confidence state 和 height state 作为 potential weak cue，并且通过 velocity direction 进行补做。</li>
<li>results:  compared to existing methods, 本方法在 diverse trackers 和 scenarios 中表现出优于其他方法，并且在 plug-and-play 和 training-free 的情况下实现了显著的改进。特别是在 DanceTrack  benchmark 上，本方法 achieve superior performance  due to its ability to handle interaction and occlusion.<details>
<summary>Abstract</summary>
Multi-Object Tracking (MOT) aims to detect and associate all desired objects across frames. Most methods accomplish the task by explicitly or implicitly leveraging strong cues (i.e., spatial and appearance information), which exhibit powerful instance-level discrimination. However, when object occlusion and clustering occur, both spatial and appearance information will become ambiguous simultaneously due to the high overlap between objects. In this paper, we demonstrate that this long-standing challenge in MOT can be efficiently and effectively resolved by incorporating weak cues to compensate for strong cues. Along with velocity direction, we introduce the confidence state and height state as potential weak cues. With superior performance, our method still maintains Simple, Online and Real-Time (SORT) characteristics. Furthermore, our method shows strong generalization for diverse trackers and scenarios in a plug-and-play and training-free manner. Significant and consistent improvements are observed when applying our method to 5 different representative trackers. Further, by leveraging both strong and weak cues, our method Hybrid-SORT achieves superior performance on diverse benchmarks, including MOT17, MOT20, and especially DanceTrack where interaction and occlusion are frequent and severe. The code and models are available at https://github.com/ymzis69/HybirdSORT.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Accessibility-and-Inclusiveness-of-New-Information-and-Communication-Technologies-for-Disabled-Users-and-Content-Creators-in-the-Metaverse"><a href="#Accessibility-and-Inclusiveness-of-New-Information-and-Communication-Technologies-for-Disabled-Users-and-Content-Creators-in-the-Metaverse" class="headerlink" title="Accessibility and Inclusiveness of New Information and Communication Technologies for Disabled Users and Content Creators in the Metaverse"></a>Accessibility and Inclusiveness of New Information and Communication Technologies for Disabled Users and Content Creators in the Metaverse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01925">http://arxiv.org/abs/2308.01925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dr Petar Radanliev, Professor David De Roure, Dr Peter Novitzky, Dr Ivo Sluganovic</li>
<li>for: 该论文旨在探讨Metaverse项目中 disabled individuals的包容性，并提出一种基于虚拟和增强现实、物联网等技术的方法来推进 disabled creatives的参与度。</li>
<li>methods: 该论文使用了许多最新的技术，如虚拟和增强现实、物联网等，以便为 disabled creatives提供更多的参与机会。</li>
<li>results: 该论文的研究结果表明，在Metaverse平台的设计和开发过程中，active involvement of physically disabled individuals是促进包容性的关键。同时，该论文还强调了需要进一步的研究和合作，以建立Metaverse项目中 disabled individuals的标准和规范。<details>
<summary>Abstract</summary>
Despite the proliferation of Blockchain Metaverse projects, the inclusion of physically disabled individuals in the Metaverse remains distant, with limited standards and regulations in place. However, the article proposes a concept of the Metaverse that leverages emerging technologies, such as Virtual and Augmented Reality, and the Internet of Things, to enable greater engagement of disabled creatives. This approach aims to enhance inclusiveness in the Metaverse landscape. Based on the findings, the paper concludes that the active involvement of physically disabled individuals in the design and development of Metaverse platforms is crucial for promoting inclusivity. The proposed framework for accessibility and inclusiveness in Virtual, Augmented, and Mixed realities of decentralised Metaverses provides a basis for the meaningful participation of disabled creatives. The article emphasises the importance of addressing the mechanisms for art production by individuals with disabilities in the emerging Metaverse landscape. Additionally, it highlights the need for further research and collaboration to establish standards and regulations that facilitate the inclusion of physically disabled individuals in Metaverse projects.
</details>
<details>
<summary>摘要</summary>
尽管Metaverse项目的普及，但 disabled individuals在Metaverse中的包括仍然远离，有限的标准和规定在位。然而，这篇文章提出了一种基于虚拟和增强现实、物联网等新技术的Metaverse概念，以便更好地促进disabled creatives的参与度。这种方法的目的是在Metaverse景观中提高包括性。根据发现，文章结论称，在Metaverse平台的设计和开发过程中active involvement of physically disabled individuals是促进包括性的关键。文章还强调了在虚拟、增强和混合现实中的decentralized Metaverses中 Addressing mechanisms for art production by individuals with disabilities是emerging Metaverse landscape的重要问题。此外，文章还高举了需要进一步的研究和合作，以确立包括physically disabled individuals在Metaverse项目中的标准和规定。
</details></li>
</ul>
<hr>
<h2 id="High-Fidelity-Eye-Animatable-Neural-Radiance-Fields-for-Human-Face"><a href="#High-Fidelity-Eye-Animatable-Neural-Radiance-Fields-for-Human-Face" class="headerlink" title="High-Fidelity Eye Animatable Neural Radiance Fields for Human Face"></a>High-Fidelity Eye Animatable Neural Radiance Fields for Human Face</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00773">http://arxiv.org/abs/2308.00773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengfei Wang, Zhongqun Zhang, Yihua Cheng, Hyung Jin Chang</li>
<li>for: 学习一种可控制眼动的面对象NeRF模型，从多视图图像中学习眼动rotation。</li>
<li>methods: 使用FLAME Parametric face模型，并引入一种新的动态眼动NeRF（DeNeRF），将3D点从不同视图转换到一个均衡空间，学习一个统一的面NeRF模型。</li>
<li>results: 通过ETH-XGaze数据集的实验，证明模型能够生成高质量图像，具有精准的眼动rotation和非均匀的周围肉肉变形。此外，通过使用生成的图像可以有效提高眼球估计性能。<details>
<summary>Abstract</summary>
Face rendering using neural radiance fields (NeRF) is a rapidly developing research area in computer vision. While recent methods primarily focus on controlling facial attributes such as identity and expression, they often overlook the crucial aspect of modeling eyeball rotation, which holds importance for various downstream tasks. In this paper, we aim to learn a face NeRF model that is sensitive to eye movements from multi-view images. We address two key challenges in eye-aware face NeRF learning: how to effectively capture eyeball rotation for training and how to construct a manifold for representing eyeball rotation. To accomplish this, we first fit FLAME, a well-established parametric face model, to the multi-view images considering multi-view consistency. Subsequently, we introduce a new Dynamic Eye-aware NeRF (DeNeRF). DeNeRF transforms 3D points from different views into a canonical space to learn a unified face NeRF model. We design an eye deformation field for the transformation, including rigid transformation, e.g., eyeball rotation, and non-rigid transformation. Through experiments conducted on the ETH-XGaze dataset, we demonstrate that our model is capable of generating high-fidelity images with accurate eyeball rotation and non-rigid periocular deformation, even under novel viewing angles. Furthermore, we show that utilizing the rendered images can effectively enhance gaze estimation performance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用神经辐射场（NeRF）进行人脸渲染是计算机视觉领域的一个迅速发展的研究领域。而最近的方法主要是控制人脸特征，如身份和表情，但它们经常忽略人脸中的眼球旋转，这在多个下游任务中具有重要性。在这篇论文中，我们想要学习一个敏感于眼球旋转的人脸NeRF模型，从多视图图像中获得 Training。我们解决了两个关键挑战：如何有效地捕捉眼球旋转，以及如何构建一个表示眼球旋转的拟合。为了实现这一点，我们首先适应FLAME，一个已知的参数化人脸模型，到多视图图像中，并考虑多视图一致性。然后，我们引入一种新的动态眼球旋转NeRF（DeNeRF）。DeNeRF将不同视图中的3D点转换成一个均匀的Canonical空间，以学习一个独立的人脸NeRF模型。我们设计了一个眼球变形场，包括静止变换、如眼球旋转，以及非静止变换。经过在ETH-XGaze数据集上进行的实验，我们表明了我们的模型可以生成高质量的图像，具有准确的眼球旋转和非静止肉眼扭曲，即使在新的视角角度下。此外，我们还证明了使用渲染出来的图像可以有效地提高眼球估计性能。
</details></li>
</ul>
<hr>
<h2 id="Decomposition-Ascribed-Synergistic-Learning-for-Unified-Image-Restoration"><a href="#Decomposition-Ascribed-Synergistic-Learning-for-Unified-Image-Restoration" class="headerlink" title="Decomposition Ascribed Synergistic Learning for Unified Image Restoration"></a>Decomposition Ascribed Synergistic Learning for Unified Image Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00759">http://arxiv.org/abs/2308.00759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinghao Zhang, Jie Huang, Man Zhou, Chongyi Li, Feng Zhao</li>
<li>for: 本研究旨在为实际应用 scenarios 提供多种图像异常处理方法的共同学习机制。</li>
<li>methods: 我们通过对各种异常信息进行分解，使用singular value decomposition (SVD) 分析不同类型的异常信息，并将其分为两类：singular vector 主导和singular value 主导。</li>
<li>results: 我们提出了一种基于 DASL 的图像异常处理方法，包括 Singular VEctor Operator (SVEO) 和 Singular VAlue Operator (SVAO) 两种有效操作，可以轻松地搭配现有的卷积图像修复框架。我们还提出了一种协调分解损失函数。对于五种混合图像修复任务进行了广泛的实验，证明了我们的方法的效果。<details>
<summary>Abstract</summary>
Learning to restore multiple image degradations within a single model is quite beneficial for real-world applications. Nevertheless, existing works typically concentrate on regarding each degradation independently, while their relationship has been less exploited to ensure the synergistic learning. To this end, we revisit the diverse degradations through the lens of singular value decomposition, with the observation that the decomposed singular vectors and singular values naturally undertake the different types of degradation information, dividing various restoration tasks into two groups,\ie, singular vector dominated and singular value dominated. The above analysis renders a more unified perspective to ascribe the diverse degradations, compared to previous task-level independent learning. The dedicated optimization of degraded singular vectors and singular values inherently utilizes the potential relationship among diverse restoration tasks, attributing to the Decomposition Ascribed Synergistic Learning (DASL). Specifically, DASL comprises two effective operators, namely, Singular VEctor Operator (SVEO) and Singular VAlue Operator (SVAO), to favor the decomposed optimization, which can be lightly integrated into existing convolutional image restoration backbone. Moreover, the congruous decomposition loss has been devised for auxiliary. Extensive experiments on blended five image restoration tasks demonstrate the effectiveness of our method, including image deraining, image dehazing, image denoising, image deblurring, and low-light image enhancement.
</details>
<details>
<summary>摘要</summary>
To exploit the potential relationship among diverse restoration tasks, we propose Decomposition Ascribed Synergistic Learning (DASL). DASL consists of two operators: Singular VEctor Operator (SVEO) and Singular VAlue Operator (SVAO), which favor decomposed optimization. These operators can be easily integrated into existing convolutional image restoration backbones. Additionally, we introduce a congruous decomposition loss for auxiliary purposes.Our method is tested on five blended image restoration tasks: image deraining, image dehazing, image denoising, image deblurring, and low-light image enhancement. Extensive experiments demonstrate the effectiveness of our approach.
</details></li>
</ul>
<hr>
<h2 id="LISA-Reasoning-Segmentation-via-Large-Language-Model"><a href="#LISA-Reasoning-Segmentation-via-Large-Language-Model" class="headerlink" title="LISA: Reasoning Segmentation via Large Language Model"></a>LISA: Reasoning Segmentation via Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00692">http://arxiv.org/abs/2308.00692</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dvlab-research/lisa">https://github.com/dvlab-research/lisa</a></li>
<li>paper_authors: Xin Lai, Zhuotao Tian, Yukang Chen, Yanwei Li, Yuhui Yuan, Shu Liu, Jiaya Jia</li>
<li>for: 这个研究旨在提出一种新的分割任务，即理解分割（Reasoning Segmentation），它可以根据复杂的隐式问题文本输出分割mask。</li>
<li>methods: 该研究使用了一种大型语言模型（LLM）的语言生成能力，并在原始词汇中添加了一个<SEG>token来激活分割功能。另外，研究者还提出了 embedding-as-mask paradigm来解锁分割能力。</li>
<li>results: 实验表明，LISA可以处理复杂的逻辑分割、世界知识、解释性答案和多turn会话等情况，并且在没有逻辑分割数据集上进行零基础训练时仍然表现出色。细化训练后，模型的性能得到进一步提高。<details>
<summary>Abstract</summary>
Although perception systems have made remarkable advancements in recent years, they still rely on explicit human instruction to identify the target objects or categories before executing visual recognition tasks. Such systems lack the ability to actively reason and comprehend implicit user intentions. In this work, we propose a new segmentation task -- reasoning segmentation. The task is designed to output a segmentation mask given a complex and implicit query text. Furthermore, we establish a benchmark comprising over one thousand image-instruction pairs, incorporating intricate reasoning and world knowledge for evaluation purposes. Finally, we present LISA: large Language Instructed Segmentation Assistant, which inherits the language generation capabilities of the multi-modal Large Language Model (LLM) while also possessing the ability to produce segmentation masks. We expand the original vocabulary with a <SEG> token and propose the embedding-as-mask paradigm to unlock the segmentation capability. Remarkably, LISA can handle cases involving: 1) complex reasoning; 2) world knowledge; 3) explanatory answers; 4) multi-turn conversation. Also, it demonstrates robust zero-shot capability when trained exclusively on reasoning-free datasets. In addition, fine-tuning the model with merely 239 reasoning segmentation image-instruction pairs results in further performance enhancement. Experiments show our method not only unlocks new reasoning segmentation capabilities but also proves effective in both complex reasoning segmentation and standard referring segmentation tasks. Code, models, and demo are at https://github.com/dvlab-research/LISA.
</details>
<details>
<summary>摘要</summary>
尽管视觉系统在最近几年内已经做出了很多出色的进步，但它们仍然需要显式的人类指令来标识目标对象或类别才能进行视觉识别任务。这些系统缺乏能 aktive 地理解和理解用户的潜在意图。在这项工作中，我们提出了一个新的分割任务---理解分割。这个任务的目标是通过给出复杂的潜在查询文本而输出分割mask。此外，我们建立了包含超过一千张图像指令对的benchmark，并包含了复杂的理解和世界知识 для评估purpose。最后，我们提出了LISA：大型语言指令分割助手，它继承了多模态大语言模型（LLM）的语言生成能力，同时也具有生成分割mask的能力。我们将原始词汇表添加了一个<SEG>Token，并提出了 embedding-as-mask paradigm来解锁分割能力。特别是，LISA可以处理：1）复杂的理解；2）世界知识；3）解释性答案；4）多turn conversation。此外，它还示出了零基础学习能力，只需要训练于无理解数据集就能够进行表现。此外， fine-tuning the model with merely 239 reasoning segmentation image-instruction pairs results in further performance enhancement。实验表明，我们的方法不仅解锁了新的理解分割能力，还证明了在复杂的理解分割和标准引用分割任务中的有效性。代码、模型和demo可以在https://github.com/dvlab-research/LISA中找到。
</details></li>
</ul>
<hr>
<h2 id="Toward-Zero-shot-Character-Recognition-A-Gold-Standard-Dataset-with-Radical-level-Annotations"><a href="#Toward-Zero-shot-Character-Recognition-A-Gold-Standard-Dataset-with-Radical-level-Annotations" class="headerlink" title="Toward Zero-shot Character Recognition: A Gold Standard Dataset with Radical-level Annotations"></a>Toward Zero-shot Character Recognition: A Gold Standard Dataset with Radical-level Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00655">http://arxiv.org/abs/2308.00655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaolei Diao, Daqian Shi, Jian Li, Lida Shi, Mingzhe Yue, Ruihua Qi, Chuntao Li, Hao Xu</li>
<li>for: 这个论文的目的是提出一个基于分解和重组的零shot OCR方法，以及一个包含基本文字部件注解的古汉字图像集（ACCID），以满足现有的研究需求。</li>
<li>methods: 该论文使用了一种分解和重组的方法，包括对字符进行分解成基本文字部件（ радикал），并对每个基本文字部件进行 recognize。此外，论文还提出了一种基于拼接的synthetic character算法来增加训练样本数量，以及一种图像净化方法来提高图像质量。</li>
<li>results: 实验结果表明，ACCID 是一个有效的古汉字图像集，并且基于分解和重组的零shot OCR方法可以在不同的文本背景下达到高度的识别率。<details>
<summary>Abstract</summary>
Optical character recognition (OCR) methods have been applied to diverse tasks, e.g., street view text recognition and document analysis. Recently, zero-shot OCR has piqued the interest of the research community because it considers a practical OCR scenario with unbalanced data distribution. However, there is a lack of benchmarks for evaluating such zero-shot methods that apply a divide-and-conquer recognition strategy by decomposing characters into radicals. Meanwhile, radical recognition, as another important OCR task, also lacks radical-level annotation for model training. In this paper, we construct an ancient Chinese character image dataset that contains both radical-level and character-level annotations to satisfy the requirements of the above-mentioned methods, namely, ACCID, where radical-level annotations include radical categories, radical locations, and structural relations. To increase the adaptability of ACCID, we propose a splicing-based synthetic character algorithm to augment the training samples and apply an image denoising method to improve the image quality. By introducing character decomposition and recombination, we propose a baseline method for zero-shot OCR. The experimental results demonstrate the validity of ACCID and the baseline model quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
Optical character recognition (OCR) 技术已经应用到多种任务中，如街景文本识别和文档分析。最近，零 shot OCR 引起了研究者的关注，因为它考虑了实际 OCR 场景中的不均衡数据分布。然而，这些零 shot 方法的评估标准缺乏，尤其是对于使用分解符认识策略进行分解字符的方法。同时， радикал认识也缺乏 радикал级别的标注数据，用于模型训练。在这篇论文中，我们构建了一个古代中文字符图像集，该集包括字符级别和 радикал级别的注释，以满足上述方法的要求。为了提高 ACCID 的适应性，我们提议一种拼接基于的人工生成字符算法，以及一种图像净化方法来提高图像质量。通过引入字符分解和重组，我们提出了一个基线方法 для零 shot OCR。实验结果表明 ACCID 和基线模型的有效性和质量。
</details></li>
</ul>
<hr>
<h2 id="Ada-DQA-Adaptive-Diverse-Quality-aware-Feature-Acquisition-for-Video-Quality-Assessment"><a href="#Ada-DQA-Adaptive-Diverse-Quality-aware-Feature-Acquisition-for-Video-Quality-Assessment" class="headerlink" title="Ada-DQA: Adaptive Diverse Quality-aware Feature Acquisition for Video Quality Assessment"></a>Ada-DQA: Adaptive Diverse Quality-aware Feature Acquisition for Video Quality Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00729">http://arxiv.org/abs/2308.00729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongbo Liu, Mingda Wu, Kun Yuan, Ming Sun, Yansong Tang, Chuanchuan Zheng, Xing Wen, Xiu Li</li>
<li>for: 提高视频质量评估（VQA）方法的效果，尽量避免使用大量 annotated 数据。</li>
<li>methods: 利用多种预训练模型（architecture、pretext task、pre-training dataset）， capture 视频质量相关特征，并通过知识distillation方式快速训练轻量级 VQA 模型。</li>
<li>results: 对三个主流的无参照 VQA benchmark进行实验，显示 Ada-DQA 方法在比较当前状态艺术方法无需使用额外的 VQA 训练数据的情况下，具有显著优于其他方法的性能。<details>
<summary>Abstract</summary>
Video quality assessment (VQA) has attracted growing attention in recent years. While the great expense of annotating large-scale VQA datasets has become the main obstacle for current deep-learning methods. To surmount the constraint of insufficient training data, in this paper, we first consider the complete range of video distribution diversity (\ie content, distortion, motion) and employ diverse pretrained models (\eg architecture, pretext task, pre-training dataset) to benefit quality representation. An Adaptive Diverse Quality-aware feature Acquisition (Ada-DQA) framework is proposed to capture desired quality-related features generated by these frozen pretrained models. By leveraging the Quality-aware Acquisition Module (QAM), the framework is able to extract more essential and relevant features to represent quality. Finally, the learned quality representation is utilized as supplementary supervisory information, along with the supervision of the labeled quality score, to guide the training of a relatively lightweight VQA model in a knowledge distillation manner, which largely reduces the computational cost during inference. Experimental results on three mainstream no-reference VQA benchmarks clearly show the superior performance of Ada-DQA in comparison with current state-of-the-art approaches without using extra training data of VQA.
</details>
<details>
<summary>摘要</summary>
视频质量评估（VQA）在最近几年内引起了越来越多的关注。然而，大量 annotate VQA 数据的成本已成为当前深度学习方法的主要障碍。为了突破这个限制，在这篇论文中，我们首先考虑了视频分布的完整范围（即内容、扭曲、运动），并采用多种预训练模型（即架构、预text任务、预训练数据）来优化质量表示。一个适应多样性特征获取（Ada-DQA）框架是提出来捕捉所需的质量相关特征。通过利用质量相关模块（QAM），该框架能够提取更加重要和相关的特征来表示质量。最后，学习的质量表示被用作增强知识储存模型的辅助监督信息，与标注的质量分数一起导航训练，大大降低了推理过程中的计算成本。实验结果表明，Ada-DQA 在三个主流无参考 VQA benchmark 上表现出色，胜过当前的状态艺术方法，无需使用额外的 VQA 训练数据。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/02/cs.CV_2023_08_02/" data-id="clogy1z3d00faffra6gubgafh" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/02/cs.AI_2023_08_02/" class="article-date">
  <time datetime="2023-08-02T12:00:00.000Z" itemprop="datePublished">2023-08-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/02/cs.AI_2023_08_02/">cs.AI - 2023-08-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Evaluating-Instruction-Tuned-Large-Language-Models-on-Code-Comprehension-and-Generation"><a href="#Evaluating-Instruction-Tuned-Large-Language-Models-on-Code-Comprehension-and-Generation" class="headerlink" title="Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation"></a>Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01240">http://arxiv.org/abs/2308.01240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqiang Yuan, Junwei Liu, Qiancheng Zi, Mingwei Liu, Xin Peng, Yiling Lou</li>
<li>for: 本研究评估了10个开源指定LM在四个代表性代码理解和生成任务上的性能。</li>
<li>methods: 我们使用了零shot、几个shot和精心调整的方法来评估指定LM的性能。</li>
<li>results: 我们发现，零shot设置下，指定LM在代码理解和生成任务上非常竞争力，有时 mêmebetter than小型SOTA模型专门为每个下游任务进行精心调整。此外，我们发现大型指定LM不总是在代码相关任务上更好。在几个shot设置下，我们发现，添加示例可以帮助指定LM在大多数代码理解和生成任务上表现更好，但是这些示例有时会导致模型的不稳定或worse性能。此外，我们发现广泛使用的BM25基于shot选择策略在生成问题上显著超过基本随机选择或固定选择。在精心调整设置下，我们发现，精心调整可以进一步提高模型在下游代码理解和生成任务上的性能，并且在同一个下游任务数据集上，指定LM在精心调整后表现更好于小型SOTA模型和无指定LM。<details>
<summary>Abstract</summary>
In this work, we evaluate 10 open-source instructed LLMs on four representative code comprehension and generation tasks. We have the following main findings. First, for the zero-shot setting, instructed LLMs are very competitive on code comprehension and generation tasks and sometimes even better than small SOTA models specifically fine-tuned on each downstream task. We also find that larger instructed LLMs are not always better on code-related tasks. Second, for the few-shot setting, we find that adding demonstration examples substantially helps instructed LLMs perform better on most code comprehension and generation tasks; however, the examples would sometimes induce unstable or even worse performance. Furthermore, we find widely-used BM25-based shot selection strategy significantly outperforms the basic random selection or fixed selection only on generation problems. Third, for the fine-tuning setting, we find that fine-tuning could further improve the model performance on downstream code comprehension and generation tasks compared to the zero-shot/one-shot performance. In addition, after being fine-tuned on the same downstream task dataset, instructed LLMs outperform both the small SOTA models and similar-scaled LLMs without instruction tuning. Based on our findings, we further present practical implications on model and usage recommendation, performance and cost trade-offs, and future direction.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们评估了10个开源指导大型语言模型（LLMs）在四个代表性的代码理解和生成任务上。我们发现以下主要结论：首先，在零次设定下，指导LLMs在代码理解和生成任务上非常竞争力，有时连小规模的特点领域模型特定 fine-tune 的每个下游任务都能够超越。我们还发现，更大的指导LLMs不总是在代码相关任务上更好。第二，在几次设定下，我们发现添加示例可以帮助指导LLMs在大多数代码理解和生成任务上表现更好，但有时示例会导致不稳定或甚至更差的表现。此外，我们发现广泛使用的BM25基于抽象选择策略可以在生成问题上显著超越基于随机选择或固定选择的策略。第三，在微调设定下，我们发现微调可以提高模型在下游代码理解和生成任务上的性能，并且在同一个下游任务数据集上微调后，指导LLMs可以超越小规模模型和无指导微调的同规模LLMs。根据我们的发现，我们进一步阐述了模型和使用建议、性能和成本贸易、未来方向等问题。
</details></li>
</ul>
<hr>
<h2 id="Do-Multilingual-Language-Models-Think-Better-in-English"><a href="#Do-Multilingual-Language-Models-Think-Better-in-English" class="headerlink" title="Do Multilingual Language Models Think Better in English?"></a>Do Multilingual Language Models Think Better in English?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01223">http://arxiv.org/abs/2308.01223</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juletx/self-translate">https://github.com/juletx/self-translate</a></li>
<li>paper_authors: Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, Mikel Artetxe</li>
<li>for: 提高多语言模型的性能</li>
<li>methods: 使用自动翻译系统</li>
<li>results: 自动翻译系统提高了模型的性能，但是模型无法充分利用其多语言潜力 when prompted in non-English languages.<details>
<summary>Abstract</summary>
Translate-test is a popular technique to improve the performance of multilingual language models. This approach works by translating the input into English using an external machine translation system, and running inference over the translated input. However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model. In this work, we introduce a new approach called self-translate, which overcomes the need of an external translation system by leveraging the few-shot translation capabilities of multilingual language models. Experiments over 5 tasks show that self-translate consistently outperforms direct inference, demonstrating that language models are unable to leverage their full multilingual potential when prompted in non-English languages. Our code is available at https://github.com/juletx/self-translate.
</details>
<details>
<summary>摘要</summary>
《翻译测试是一种广泛使用的技术，以提高多语言语音模型的性能。这种方法工作于将输入翻译成英语使用外部机器翻译系统，然后运行推理。然而，这些改进可以归功于使用分离的翻译系统，该系统通常在大量的并行数据上进行了训练。在这个工作中，我们介绍了一种新的方法called自动翻译（Self-translate），它超越了需要外部翻译系统的需求，通过多语言语音模型的几个shot翻译能力。经过5个任务的实验表明，自动翻译可以一直超越直接推理，表明语音模型在非英语语言下提问时无法全面发挥其多语言潜力。我们的代码可以在https://github.com/juletx/self-translate中找到。》
</details></li>
</ul>
<hr>
<h2 id="Calibration-in-Deep-Learning-A-Survey-of-the-State-of-the-Art"><a href="#Calibration-in-Deep-Learning-A-Survey-of-the-State-of-the-Art" class="headerlink" title="Calibration in Deep Learning: A Survey of the State-of-the-Art"></a>Calibration in Deep Learning: A Survey of the State-of-the-Art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01222">http://arxiv.org/abs/2308.01222</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Wang</li>
<li>For: This paper reviews the state-of-the-art calibration methods for deep neural models and provides an understanding of their principles for performing model calibration.* Methods: The paper introduces four categories of calibration methods, including post-hoc calibration, regularization methods, uncertainty estimation, and composition methods.* Results: The paper discusses recent advancements in calibrating large models, particularly large language models (LLMs), and highlights some open issues, challenges, and potential directions in model calibration.Here’s the full translation in simplified Chinese:* For: 这篇论文总结了现代神经网络模型的准确性calibration方法，并提供了这些方法的原理。* Methods: 论文介绍了四种准确性calibration方法，包括后期calibration、regularization方法、uncertainty估计和组合方法。* Results: 论文讨论了大型模型（特别是大语言模型）的准确性calibration方法，并提出了一些开放的问题、挑战和可能的方向。<details>
<summary>Abstract</summary>
Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications. Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions. Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively underexplored. Ideal deep models should have not only high predictive performance but also be well calibrated. There have been some recent methods proposed to calibrate deep models by using different mechanisms. In this survey, we review the state-of-the-art calibration methods and provide an understanding of their principles for performing model calibration. First, we start with the definition of model calibration and explain the root causes of model miscalibration. Then we introduce the key metrics that can measure this aspect. It is followed by a summary of calibration methods that we roughly classified into four categories: post-hoc calibration, regularization methods, uncertainty estimation, and composition methods. We also covered some recent advancements in calibrating large models, particularly large language models (LLMs). Finally, we discuss some open issues, challenges, and potential directions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传送文本到简化中文。<</SYS>>深度神经网络调整扮演重要的角色在安全关键应用中建立可靠、Robust AI系统。最近的研究表明，现代神经网络具有高预测能力，但是受到不可靠的模型预测问题的影响。虽然深度学习模型在不同的标准概念上达到了惊人的性能，但是模型准确性和稳定性的研究尚未得到充分的探索。理想的深度模型应该不仅具有高预测性能，还应该具有良好的准确性。在这篇评论中，我们回顾了当前领域的状态对模型准确性的研究，并提供了这些方法的原理。首先，我们开始定义模型准确性，并解释了模型误准的根本原因。然后，我们介绍了用于评估这一方面的关键度量。接下来，我们简要概述了准确性方法，分为四类：后期准确化、规范方法、不确定度估计和组合方法。我们还讨论了大模型（LLMs）的准确性calibration。最后，我们讨论了一些未解决的问题、挑战和可能的方向。
</details></li>
</ul>
<hr>
<h2 id="Using-ScrutinAI-for-Visual-Inspection-of-DNN-Performance-in-a-Medical-Use-Case"><a href="#Using-ScrutinAI-for-Visual-Inspection-of-DNN-Performance-in-a-Medical-Use-Case" class="headerlink" title="Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case"></a>Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01220">http://arxiv.org/abs/2308.01220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rebekka Görge, Elena Haedecke, Michael Mock</li>
<li>for: 本研究使用Visual Analytics（VA）工具ScrutinAI，以帮助人类分析员Investigate模型性能和数据集。模型性能受标签质量的影响很大，特别在医疗设置下，生成高质量标签需要深厚专业知识和很costly。经常情况下，数据集被收集由多个专家的意见来标签。我们使用ScrutinAI来分析标签变化 между不同专家对模型性能的影响。</li>
<li>methods: 我们使用了ScrutinAI工具来分析模型性能的原因，包括标签质量的变化和缺失对模型的影响。我们使用了一个公共可用的数据集来进行检测脑内出血和分类不同亚型的检测。</li>
<li>results: 我们的结果表明，ScrutinAI可以帮助分析员快速地发现模型性能的原因，并且可以分析标签变化的影响。我们发现，模型性能受标签质量的影响很大，而且在某些情况下，模型可能会受到缺失标签的影响。<details>
<summary>Abstract</summary>
Our Visual Analytics (VA) tool ScrutinAI supports human analysts to investigate interactively model performanceand data sets. Model performance depends on labeling quality to a large extent. In particular in medical settings, generation of high quality labels requires in depth expert knowledge and is very costly. Often, data sets are labeled by collecting opinions of groups of experts. We use our VA tool to analyse the influence of label variations between different experts on the model performance. ScrutinAI facilitates to perform a root cause analysis that distinguishes weaknesses of deep neural network (DNN) models caused by varying or missing labeling quality from true weaknesses. We scrutinize the overall detection of intracranial hemorrhages and the more subtle differentiation between subtypes in a publicly available data set.
</details>
<details>
<summary>摘要</summary>
我们的视觉分析工具ScrutinAI可以帮助人类分析员 investigate模型性能和数据集。模型性能受标签质量的影响很大，特别在医疗场景下，生成高质量标签需要深入的专业知识和非常昂贵。经常情况下，数据集由多名专家的意见集成标签。我们使用ScrutinAI来分析标签变化 между不同专家对模型性能的影响。ScrutinAI可以进行根本原因分析，从而分解深度神经网络模型的弱点，是因为标签质量变化或缺失，而不是真正的弱点。我们在一个公共可用的数据集中对脑出血的总检测和较为细微的差异分类进行了检验。
</details></li>
</ul>
<hr>
<h2 id="Mercury-An-Automated-Remote-Side-channel-Attack-to-Nvidia-Deep-Learning-Accelerator"><a href="#Mercury-An-Automated-Remote-Side-channel-Attack-to-Nvidia-Deep-Learning-Accelerator" class="headerlink" title="Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator"></a>Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01193">http://arxiv.org/abs/2308.01193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobei Yan, Xiaoxuan Lou, Guowen Xu, Han Qiu, Shangwei Guo, Chip Hong Chang, Tianwei Zhang</li>
<li>for: 防止深度学习模型在加速器上的泄露和攻击。</li>
<li>methods: 自动化的远程边频攻击，通过模型化侧频泄露为序列-到-序列问题，使用时间数字转换器（TDC）收集目标模型的执行轨迹，然后使用学习模型自动提取目标模型的架构细节。</li>
<li>results: 可以准确率低于1%地提取目标模型的架构细节。<details>
<summary>Abstract</summary>
DNN accelerators have been widely deployed in many scenarios to speed up the inference process and reduce the energy consumption. One big concern about the usage of the accelerators is the confidentiality of the deployed models: model inference execution on the accelerators could leak side-channel information, which enables an adversary to preciously recover the model details. Such model extraction attacks can not only compromise the intellectual property of DNN models, but also facilitate some adversarial attacks.   Although previous works have demonstrated a number of side-channel techniques to extract models from DNN accelerators, they are not practical for two reasons. (1) They only target simplified accelerator implementations, which have limited practicality in the real world. (2) They require heavy human analysis and domain knowledge. To overcome these limitations, this paper presents Mercury, the first automated remote side-channel attack against the off-the-shelf Nvidia DNN accelerator. The key insight of Mercury is to model the side-channel extraction process as a sequence-to-sequence problem. The adversary can leverage a time-to-digital converter (TDC) to remotely collect the power trace of the target model's inference. Then he uses a learning model to automatically recover the architecture details of the victim model from the power trace without any prior knowledge. The adversary can further use the attention mechanism to localize the leakage points that contribute most to the attack. Evaluation results indicate that Mercury can keep the error rate of model extraction below 1%.
</details>
<details>
<summary>摘要</summary>
although previous works have demonstrated several side-channel techniques to extract models from DNN accelerators, they are not practical for two reasons. First, they only target simplified accelerator implementations, which have limited practicality in the real world. Second, they require heavy human analysis and domain knowledge.To overcome these limitations, this paper presents Mercury, the first automated remote side-channel attack against off-the-shelf Nvidia DNN accelerators. The key insight of Mercury is to model the side-channel extraction process as a sequence-to-sequence problem. The adversary can leverage a time-to-digital converter (TDC) to remotely collect the power trace of the target model's inference. Then he uses a learning model to automatically recover the architecture details of the victim model from the power trace without any prior knowledge. The adversary can further use the attention mechanism to localize the leakage points that contribute most to the attack.Evaluation results indicate that Mercury can keep the error rate of model extraction below 1%.
</details></li>
</ul>
<hr>
<h2 id="Data-Centric-Diet-Effective-Multi-center-Dataset-Pruning-for-Medical-Image-Segmentation"><a href="#Data-Centric-Diet-Effective-Multi-center-Dataset-Pruning-for-Medical-Image-Segmentation" class="headerlink" title="Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation"></a>Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01189">http://arxiv.org/abs/2308.01189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongkang He, Mingjin Chen, Zhijing Yang, Yongyi Lu</li>
<li>for: Addressing the dense labeling problem in medical image segmentation, where a significant fraction of the dataset can be pruned without sacrificing much accuracy.</li>
<li>methods: Proposing a data pruning method based on the Dynamic Average Dice (DAD) score, which takes into consideration the training dynamics on target regions.</li>
<li>results: Showing that the proposed method can effectively identify important samples and reduce the amount of labeled data needed for training, making it a strong yet simple baseline for medical image segmentation with combined data sources.<details>
<summary>Abstract</summary>
This paper seeks to address the dense labeling problems where a significant fraction of the dataset can be pruned without sacrificing much accuracy. We observe that, on standard medical image segmentation benchmarks, the loss gradient norm-based metrics of individual training examples applied in image classification fail to identify the important samples. To address this issue, we propose a data pruning method by taking into consideration the training dynamics on target regions using Dynamic Average Dice (DAD) score. To the best of our knowledge, we are among the first to address the data importance in dense labeling tasks in the field of medical image analysis, making the following contributions: (1) investigating the underlying causes with rigorous empirical analysis, and (2) determining effective data pruning approach in dense labeling problems. Our solution can be used as a strong yet simple baseline to select important examples for medical image segmentation with combined data sources.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Empirical analysis of the underlying causes of the problem.2. Development of an effective data pruning approach for dense labeling tasks in medical image analysis.Our solution can be used as a strong and simple baseline for selecting important examples in medical image segmentation with combined data sources.</details></li>
</ol>
<hr>
<h2 id="Machine-Learning-Based-Diabetes-Detection-Using-Photoplethysmography-Signal-Features"><a href="#Machine-Learning-Based-Diabetes-Detection-Using-Photoplethysmography-Signal-Features" class="headerlink" title="Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features"></a>Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01930">http://arxiv.org/abs/2308.01930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filipe A. C. Oliveira, Felipe M. Dias, Marcelo A. F. Toledo, Diego A. C. Cardenas, Douglas A. Almeida, Estela Ribeiro, Jose E. Krieger, Marco A. Gutierrez</li>
<li>for: 这个研究旨在开发一种可靠的、无侵入的血糖察测方法，以帮助预防和控制糖尿病。</li>
<li>methods: 该研究使用了光学折射 Plethysmography (PPG) 技术，通过分析 PPG 信号和相关 metadata，采用 Logistic Regression (LR) 和 eXtreme Gradient Boosting (XGBoost) 算法进行分类，以将非糖尿病和糖尿病患者区分开来。</li>
<li>results: 研究结果显示，使用 PPG 信号和 metadata 进行训练，可以达到 F1-Score 和 AUC 的值为 $58.8\pm20.0%$ 和 $79.2\pm15.0%$ 以及 $51.7\pm16.5%$ 和 $73.6\pm17.0%$，分别对应 LR 和 XGBoost 算法。此外，特征分析表明，PPG 形态特征含有糖尿病相关信息，同时 metadata 也有一定的作用。这些结果与文献报道的结果相似，表明机器学习方法在开发远程、无侵入、连续测量糖尿病的设备方面具有潜在的抑血糖监测技术。<details>
<summary>Abstract</summary>
Diabetes is a prevalent chronic condition that compromises the health of millions of people worldwide. Minimally invasive methods are needed to prevent and control diabetes but most devices for measuring glucose levels are invasive and not amenable for continuous monitoring. Here, we present an alternative method to overcome these shortcomings based on non-invasive optical photoplethysmography (PPG) for detecting diabetes. We classify non-Diabetic and Diabetic patients using the PPG signal and metadata for training Logistic Regression (LR) and eXtreme Gradient Boosting (XGBoost) algorithms. We used PPG signals from a publicly available dataset. To prevent overfitting, we divided the data into five folds for cross-validation. By ensuring that patients in the training set are not in the testing set, the model's performance can be evaluated on unseen subjects' data, providing a more accurate assessment of its generalization. Our model achieved an F1-Score and AUC of $58.8\pm20.0\%$ and $79.2\pm15.0\%$ for LR and $51.7\pm16.5\%$ and $73.6\pm17.0\%$ for XGBoost, respectively. Feature analysis suggested that PPG morphological features contains diabetes-related information alongside metadata. Our findings are within the same range reported in the literature, indicating that machine learning methods are promising for developing remote, non-invasive, and continuous measurement devices for detecting and preventing diabetes.
</details>
<details>
<summary>摘要</summary>
DIABETES 是一种常见的慢性疾病，影响全球数百万人的健康。为了预防和控制 DIABETES，需要采用轻侵入的方法，但现有的糖尿病测量设备大多是侵入式，不适合持续监测。在这里，我们提出了一种替代方案，利用非侵入式的光学折射 plethysmography (PPG) 来检测 DIABETES。我们使用 PPG 信号和 metadata 来训练 Logistic Regression (LR) 和 eXtreme Gradient Boosting (XGBoost) 算法，并将数据分成五个批次进行十字验证。这样可以避免过拟合，并且通过将训练集和测试集分开，可以评估模型在未看到的数据上的性能，提供更准确的评估。我们的模型实现了 F1 分数和 AUC 的 $58.8\pm20.0\%$ 和 $79.2\pm15.0\%$，以及 $51.7\pm16.5\%$ 和 $73.6\pm17.0\%$，分别用于 LR 和 XGBoost。特征分析表明，PPG 形态特征含有糖尿病相关信息，同时与 metadata 相关。我们的发现与文献中的报告相符，表明机器学习方法在开发远程、非侵入式、持续测量糖尿病的设备方面具有潜在的承诺。
</details></li>
</ul>
<hr>
<h2 id="LLMs-Understand-Glass-Box-Models-Discover-Surprises-and-Suggest-Repairs"><a href="#LLMs-Understand-Glass-Box-Models-Discover-Surprises-and-Suggest-Repairs" class="headerlink" title="LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs"></a>LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01157">http://arxiv.org/abs/2308.01157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/interpretml/talktoebm">https://github.com/interpretml/talktoebm</a></li>
<li>paper_authors: Benjamin J. Lengerich, Sebastian Bordt, Harsha Nori, Mark E. Nunnally, Yin Aphinyanaphongs, Manolis Kellis, Rich Caruana</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）如何与可解释模型相结合，以实现数据科学中的一些常见任务自动化。</li>
<li>methods: 论文使用了层次逻辑来理解复杂的结果，并采用了大语言模型的广泛背景知识来自动化数据科学中的一些任务，如检测异常点、描述异常原因以及修复异常。</li>
<li>results: 论文通过多个医疗Example示cases，展示了这种新的LLM功能的实用性，特别是在使用Generalized Additive Models (GAMs)时。最后，论文还介绍了一个开源的LLM-GAM接口——$\texttt{TalkToEBM}$ package。<details>
<summary>Abstract</summary>
We show that large language models (LLMs) are remarkably good at working with interpretable models that decompose complex outcomes into univariate graph-represented components. By adopting a hierarchical approach to reasoning, LLMs can provide comprehensive model-level summaries without ever requiring the entire model to fit in context. This approach enables LLMs to apply their extensive background knowledge to automate common tasks in data science such as detecting anomalies that contradict prior knowledge, describing potential reasons for the anomalies, and suggesting repairs that would remove the anomalies. We use multiple examples in healthcare to demonstrate the utility of these new capabilities of LLMs, with particular emphasis on Generalized Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as an open-source LLM-GAM interface.
</details>
<details>
<summary>摘要</summary>
我们显示大型语言模型（LLMs）可以非常好地与可解释性模型（decompose complex outcomes into univariate graph-represented components）合作。通过阶层式思考方式，LLMs可以提供全面的模型水平摘要，无需整个模型满足上下文中的适应。这种方法允许LLMs应用它们广泛的背景知识来自动进行资料科学中常见的任务，例如检测对前知识不符的异常，描述异常的可能原因，并建议修复异常的方法。我们使用了多个医疗保健例子来证明这些新功能的价值，尤其是对于泛化添加模型（GAMs）。最后，我们发布了名为 $\texttt{TalkToEBM}$ 的开源 LLM-GAM 界面。
</details></li>
</ul>
<hr>
<h2 id="Arithmetic-with-Language-Models-from-Memorization-to-Computation"><a href="#Arithmetic-with-Language-Models-from-Memorization-to-Computation" class="headerlink" title="Arithmetic with Language Models: from Memorization to Computation"></a>Arithmetic with Language Models: from Memorization to Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01154">http://arxiv.org/abs/2308.01154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Maltoni, Matteo Ferrara</li>
<li>for:  investigate the emergent computation and problem-solving capabilities of recent large language models</li>
<li>methods:  trained the language model to predict the next token, and tested its ability to perform binary addition and multiplication</li>
<li>results:  the language model was able to learn these tasks and exhibited extrapolation capabilities, supporting the hypothesis that the model works as an Encoding-Regression-Decoding machine.<details>
<summary>Abstract</summary>
A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate internal representation.
</details>
<details>
<summary>摘要</summary>
需要更深刻的理解 latest large language model 的 emergent computation 和问题解决能力，以便进一步改进它们和扩展其应用范围。这项工作 investigate 如何一个语言模型，受训练来预测下一个token，可以执行扩展到训练数据之外的数学计算。二进制加法和乘法是一个好的测试场景，因为它们需要非常小的词汇表，并且表现出输入/输出离散性，使得smooth输入 interpolate 无效 для novel data。我们成功地培养了一个轻量级语言模型，学习这些任务，并进行了一些实验来研究 extrapolation 能力和内部信息处理。我们的发现支持假设，语言模型是一个编码-回归-解码机器，计算在值空间中发生，只要输入token表示Mapping 到合适的内部表示即可。
</details></li>
</ul>
<hr>
<h2 id="A-Transformer-based-Prediction-Method-for-Depth-of-Anesthesia-During-Target-controlled-Infusion-of-Propofol-and-Remifentanil"><a href="#A-Transformer-based-Prediction-Method-for-Depth-of-Anesthesia-During-Target-controlled-Infusion-of-Propofol-and-Remifentanil" class="headerlink" title="A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil"></a>A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01929">http://arxiv.org/abs/2308.01929</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/heeeyk/transformer-doa-prediction">https://github.com/heeeyk/transformer-doa-prediction</a></li>
<li>paper_authors: Yongkang He, Siyuan Peng, Mingjin Chen, Zhijing Yang, Yuanhui Chen<br>for: 预测麻醉效果的准确性是脊梁控制注射系统的关键，传统的PK-PD模型需要手动选择模型参数，这可能是临床设置中困难的。methods: 我们提议使用变换器来预测麻醉深度（DOA），使用批处理和闭合径远网络来提高特征融合的效率，并应用关注机制来发现药物之间的互动。我们还使用标签分布平滑和重新平衡损失来解决数据不均衡。results: 我们的提议方法比传统PK-PD模型和先前的深度学习方法更高效，可以正确预测麻醉深度在快速和深度麻醉 conditons下。<details>
<summary>Abstract</summary>
Accurately predicting anesthetic effects is essential for target-controlled infusion systems. The traditional (PK-PD) models for Bispectral index (BIS) prediction require manual selection of model parameters, which can be challenging in clinical settings. Recently proposed deep learning methods can only capture general trends and may not predict abrupt changes in BIS. To address these issues, we propose a transformer-based method for predicting the depth of anesthesia (DOA) using drug infusions of propofol and remifentanil. Our method employs long short-term memory (LSTM) and gate residual network (GRN) networks to improve the efficiency of feature fusion and applies an attention mechanism to discover the interactions between the drugs. We also use label distribution smoothing and reweighting losses to address data imbalance. Experimental results show that our proposed method outperforms traditional PK-PD models and previous deep learning methods, effectively predicting anesthetic depth under sudden and deep anesthesia conditions.
</details>
<details>
<summary>摘要</summary>
Accurately predicting anesthetic effects is crucial for target-controlled infusion systems. Traditional PK-PD models for Bispectral index (BIS) prediction require manual selection of model parameters, which can be challenging in clinical settings. Recently proposed deep learning methods can only capture general trends and may not predict abrupt changes in BIS. To address these issues, we propose a transformer-based method for predicting the depth of anesthesia (DOA) using drug infusions of propofol and remifentanil. Our method employs long short-term memory (LSTM) and gate residual network (GRN) networks to improve the efficiency of feature fusion and applies an attention mechanism to discover the interactions between the drugs. We also use label distribution smoothing and reweighting losses to address data imbalance. Experimental results show that our proposed method outperforms traditional PK-PD models and previous deep learning methods, effectively predicting anesthetic depth under sudden and deep anesthesia conditions.Here's the text with some notes on the translation:1. "Accurately predicting anesthetic effects" is translated as "正确预测医疗效果" (zhèng kě bìng jì yì yì qiú yè)2. "target-controlled infusion systems" is translated as "目标控制注射系统" (mou zhì kòng zhì zhù shí tè)3. "Bispectral index" is translated as "复探测指数" (fù guān zhì shù)4. "traditional PK-PD models" is translated as "传统PK-PD模型" (chuán tǒng PK-PD mó yì)5. "deep learning methods" is translated as "深度学习方法" (shēn dào xué xí fāng fǎ)6. "long short-term memory" is translated as "长期忘却记忆" (cháng qī wàng qiū jì yì)7. "gate residual network" is translated as "门阶差异网络" (mén jiē yì zhī wǎng)8. "label distribution smoothing" is translated as "标签分布平滑" (biāo jiāo fān bù píng shuā)9. "reweighting losses" is translated as "重新评估损失" (zhòng xīn píng shí shū shì)Note that the translation is based on the standard Simplified Chinese characters and may vary depending on the specific context and region.
</details></li>
</ul>
<hr>
<h2 id="Can-We-Transfer-Noise-Patterns-A-Multi-environment-Spectrum-Analysis-Model-Using-Generated-Cases"><a href="#Can-We-Transfer-Noise-Patterns-A-Multi-environment-Spectrum-Analysis-Model-Using-Generated-Cases" class="headerlink" title="Can We Transfer Noise Patterns? A Multi-environment Spectrum Analysis Model Using Generated Cases"></a>Can We Transfer Noise Patterns? A Multi-environment Spectrum Analysis Model Using Generated Cases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01138">http://arxiv.org/abs/2308.01138</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/magnomic/cnst">https://github.com/magnomic/cnst</a></li>
<li>paper_authors: Haiwen Du, Zheng Ju, Yu An, Honghui Du, Dongjie Zhu, Zhaoshuo Tian, Aonghus Lawlor, Ruihai Dong</li>
<li>for: 提高 Deep Learning 模型的性能，增加高质量的数据集</li>
<li>methods: 提出一种将噪声特征传递模型，通过学习不同环境中标准水样 спектrum 的差异，实现噪声传递</li>
<li>results: 对不同背景噪声进行实验，表明提出的方法可以减少噪声影响，提高 Deep Learning 模型的性能，并且比基eline系统（包括浪涌滤波、深度神经网络和生成模型）更好。<details>
<summary>Abstract</summary>
Spectrum analysis systems in online water quality testing are designed to detect types and concentrations of pollutants and enable regulatory agencies to respond promptly to pollution incidents. However, spectral data-based testing devices suffer from complex noise patterns when deployed in non-laboratory environments. To make the analysis model applicable to more environments, we propose a noise patterns transferring model, which takes the spectrum of standard water samples in different environments as cases and learns the differences in their noise patterns, thus enabling noise patterns to transfer to unknown samples. Unfortunately, the inevitable sample-level baseline noise makes the model unable to obtain the paired data that only differ in dataset-level environmental noise. To address the problem, we generate a sample-to-sample case-base to exclude the interference of sample-level noise on dataset-level noise learning, enhancing the system's learning performance. Experiments on spectral data with different background noises demonstrate the good noise-transferring ability of the proposed method against baseline systems ranging from wavelet denoising, deep neural networks, and generative models. From this research, we posit that our method can enhance the performance of DL models by generating high-quality cases. The source code is made publicly available online at https://github.com/Magnomic/CNST.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Survey-on-Popularity-Bias-in-Recommender-Systems"><a href="#A-Survey-on-Popularity-Bias-in-Recommender-Systems" class="headerlink" title="A Survey on Popularity Bias in Recommender Systems"></a>A Survey on Popularity Bias in Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01118">http://arxiv.org/abs/2308.01118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anastasiia Klimashevskaia, Dietmar Jannach, Mehdi Elahi, Christoph Trattner</li>
<li>for: 本研究旨在探讨现有推荐系统中偏好强度的问题，以及如何检测、衡量和缓解这种偏好。</li>
<li>methods: 本文评论了现有的计算指标和技术方法，以帮助减少偏好强度的影响。</li>
<li>results: 研究发现，现有的推荐算法在大多数情况下受到偏好强度的影响，导致推荐结果偏向流行的项目。此外，研究还发现现有的研究基本上仅仅通过计算实验和假设来评估实际效果。<details>
<summary>Abstract</summary>
Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discuss today's literature, where we observe that the research is almost entirely based on computational experiments and on certain assumptions regarding the practical effects of including long-tail items in the recommendations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Literal-Aware-Knowledge-Graph-Embedding-for-Welding-Quality-Monitoring-A-Bosch-Case"><a href="#Literal-Aware-Knowledge-Graph-Embedding-for-Welding-Quality-Monitoring-A-Bosch-Case" class="headerlink" title="Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring: A Bosch Case"></a>Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring: A Bosch Case</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01105">http://arxiv.org/abs/2308.01105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhipeng Tan, Baifan Zhou, Zhuoxun Zheng, Ognjen Savkovic, Ziqi Huang, Irlan-Grangel Gonzalez, Ahmet Soylu, Evgeny Kharlamov</li>
<li>for: 本研究探讨了知识图 embedding (KGE) 是否可以应用于重要的工业问题：质量监测在生产过程中的焊接。</li>
<li>methods: 本研究使用了流行的 KGE 方法，并考虑了文本 literal。</li>
<li>results: 研究发现了 KGE 方法在实际工业数据上的限制和推荐，并解决了两个困难问题：焊接点大小和焊接点所属的车体类别。<details>
<summary>Abstract</summary>
Recently there has been a series of studies in knowledge graph embedding (KGE), which attempts to learn the embeddings of the entities and relations as numerical vectors and mathematical mappings via machine learning (ML). However, there has been limited research that applies KGE for industrial problems in manufacturing. This paper investigates whether and to what extent KGE can be used for an important problem: quality monitoring for welding in manufacturing industry, which is an impactful process accounting for production of millions of cars annually. The work is in line with Bosch research of data-driven solutions that intends to replace the traditional way of destroying cars, which is extremely costly and produces waste. The paper tackles two very challenging questions simultaneously: how large the welding spot diameter is; and to which car body the welded spot belongs to. The problem setting is difficult for traditional ML because there exist a high number of car bodies that should be assigned as class labels. We formulate the problem as link prediction, and experimented popular KGE methods on real industry data, with consideration of literals. Our results reveal both limitations and promising aspects of adapted KGE methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-Better-Query-Classification-with-Multi-Expert-Knowledge-Condensation-in-JD-Ads-Search"><a href="#Towards-Better-Query-Classification-with-Multi-Expert-Knowledge-Condensation-in-JD-Ads-Search" class="headerlink" title="Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search"></a>Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01098">http://arxiv.org/abs/2308.01098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun-Peng Ning, Ming Pang, Zheng Fang, Xue Jiang, Xi-Wei Zhao, Chang-Ping Peng, Zhan-Gang Lin, Jing-He Hu, Jing-Ping Shao</li>
<li>for: 提高在线搜索系统中的用户意图理解效果，尤其是在低延迟下。</li>
<li>methods: 使用知识凝固（KC）框架，将在线快速的FastText模型升级到更深和复杂的BERT模型，以提高分类性能。</li>
<li>results: 通过在线A&#x2F;B测试和多个数据集的实验，证明了提议的方法可以提高分类性能，同时保持低延迟。<details>
<summary>Abstract</summary>
Search query classification, as an effective way to understand user intents, is of great importance in real-world online ads systems. To ensure a lower latency, a shallow model (e.g. FastText) is widely used for efficient online inference. However, the representation ability of the FastText model is insufficient, resulting in poor classification performance, especially on some low-frequency queries and tailed categories. Using a deeper and more complex model (e.g. BERT) is an effective solution, but it will cause a higher online inference latency and more expensive computing costs. Thus, how to juggle both inference efficiency and classification performance is obviously of great practical importance. To overcome this challenge, in this paper, we propose knowledge condensation (KC), a simple yet effective knowledge distillation framework to boost the classification performance of the online FastText model under strict low latency constraints. Specifically, we propose to train an offline BERT model to retrieve more potentially relevant data. Benefiting from its powerful semantic representation, more relevant labels not exposed in the historical data will be added into the training set for better FastText model training. Moreover, a novel distribution-diverse multi-expert learning strategy is proposed to further improve the mining ability of relevant data. By training multiple BERT models from different data distributions, it can respectively perform better at high, middle, and low-frequency search queries. The model ensemble from multi-distribution makes its retrieval ability more powerful. We have deployed two versions of this framework in JD search, and both offline experiments and online A/B testing from multiple datasets have validated the effectiveness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
“搜寻查询分类是在现实世界上线广告系统中非常重要的一种方法，以了解用户的意图。为了降低延迟，通常使用轻量级模型（例如 FastText）进行简单的在线推导。然而，FastText模型的表现能力不足，尤其是在一些低频查询和尾部分类上，导致分类性能不佳。使用更深和复杂的模型（例如 BERT）是一个有效的解决方案，但它将导致更高的在线推导延迟和更贵的计算成本。因此，如何均衡在线推导效率和分类性能是非常重要的实际问题。在这篇论文中，我们提出了知识储存（KC），一个简单而有效的知识传播框架，以提高在线 FastText 模型的分类性能。具体来说，我们提出了在网上训练一个 BERT 模型，以获取更多可能有用的数据。由于它的强大 semantic 表现，更多的标签不在历史数据中 exposed 的将被添加到训练集中，以提高 FastText 模型的训练。此外，我们还提出了一个多元专家学习策略，以进一步提高挖掘有用数据的能力。通过对多个数据分布进行多个 BERT 模型的训练，每个模型可以在不同的查询频率上表现更好。多元模型的集成可以将其挖掘能力提高。我们在 JD 搜寻中部署了两个版本的这个框架，并在多个数据集上进行了离线实验和在线 A/B 测试。结果显示，我们的方法有效地提高了在线 FastText 模型的分类性能。”
</details></li>
</ul>
<hr>
<h2 id="Scaling-Data-Science-Solutions-with-Semantics-and-Machine-Learning-Bosch-Case"><a href="#Scaling-Data-Science-Solutions-with-Semantics-and-Machine-Learning-Bosch-Case" class="headerlink" title="Scaling Data Science Solutions with Semantics and Machine Learning: Bosch Case"></a>Scaling Data Science Solutions with Semantics and Machine Learning: Bosch Case</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01094">http://arxiv.org/abs/2308.01094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Baifan Zhou, Nikolay Nikolov, Zhuoxun Zheng, Xianghui Luo, Ognjen Savkovic, Dumitru Roman, Ahmet Soylu, Evgeny Kharlamov</li>
<li>For: 本研究旨在解决由于工业4.0和物联网（IoT）技术引入大量数据，导致云计算系统处理大数据的挑战。特别是，随着云计算系统的普及，需要更多的用户（如数据科学家、领域专家）在云计算系统上部署解决方案，但是训练这些用户需要很长时间。* Methods: 本研究提出了一种 semantics-enhanced 云计算系统（SemCloud），它将云计算系统与semantic技术和机器学习相结合。SemCloud 利用域ontologies和映射来实现数据集成，并在分布计算节点上并行进行semantic数据集成和数据分析。此外，SemCloud 采用自适应的 Datalog 规则和机器学习来自动配置资源，使得非云专家可以使用云计算系统。* Results: 本研究在工业用例中测试了 SemCloud，结果表明其在处理大数据时表现出色，并且在千次重复运行和领域用户的帮助下，SemCloud 能够实现自动化资源配置和高效数据处理。<details>
<summary>Abstract</summary>
Industry 4.0 and Internet of Things (IoT) technologies unlock unprecedented amount of data from factory production, posing big data challenges in volume and variety. In that context, distributed computing solutions such as cloud systems are leveraged to parallelise the data processing and reduce computation time. As the cloud systems become increasingly popular, there is increased demand that more users that were originally not cloud experts (such as data scientists, domain experts) deploy their solutions on the cloud systems. However, it is non-trivial to address both the high demand for cloud system users and the excessive time required to train them. To this end, we propose SemCloud, a semantics-enhanced cloud system, that couples cloud system with semantic technologies and machine learning. SemCloud relies on domain ontologies and mappings for data integration, and parallelises the semantic data integration and data analysis on distributed computing nodes. Furthermore, SemCloud adopts adaptive Datalog rules and machine learning for automated resource configuration, allowing non-cloud experts to use the cloud system. The system has been evaluated in industrial use case with millions of data, thousands of repeated runs, and domain users, showing promising results.
</details>
<details>
<summary>摘要</summary>
产业4.0和物联网（IoT）技术在工厂生产中释放了历史上未曾有的数据量，带来大规模数据挑战，包括数据量和多样性。在这种情况下，分布式计算解决方案如云系统得到了广泛应用，以并行处理数据并降低计算时间。然而，随着云系统的普及，需要更多的用户，包括不是云专家（如数据科学家、领域专家）部署他们的解决方案在云系统上。然而，寻求这些高需求和长时间培训是非常困难的。为此，我们提出了SemCloud，一个具有语义技术和机器学习的云系统。SemCloud通过域ontologies和映射来集成数据，并在分布式计算节点上并行执行语义数据集成和数据分析。此外，SemCloud采用自适应的Datalog规则和机器学习来自动配置资源，使非云专家可以使用云系统。我们在产业用例中测试了SemCloud，结果表现良好，处理了数百万个数据， thousands of repeated runs，和领域用户。
</details></li>
</ul>
<hr>
<h2 id="Hand-tracking-for-clinical-applications-validation-of-the-Google-MediaPipe-Hand-GMH-and-the-depth-enhanced-GMH-D-frameworks"><a href="#Hand-tracking-for-clinical-applications-validation-of-the-Google-MediaPipe-Hand-GMH-and-the-depth-enhanced-GMH-D-frameworks" class="headerlink" title="Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks"></a>Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01088">http://arxiv.org/abs/2308.01088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gianluca Amprimo, Giulia Masi, Giuseppe Pettiti, Gabriella Olmo, Lorenzo Priano, Claudia Ferraris</li>
<li>for:  validate the handtracking framework implemented by Google MediaPipe Hand (GMH) and an innovative enhanced version, GMH-D</li>
<li>methods: 使用 Google MediaPipe Hand (GMH) 和一种改进版本 GMH-D，利用RGB-深度摄像头的深度估计来实现更加精准的3D手势跟踪</li>
<li>results: 比较GMH和GMH-D两种方法的结果，发现GMH-D在空间测量方面具有更高的准确性，特别是对于慢速和快速手势的测量Here’s the translation in English for reference:</li>
<li>for: validate the handtracking framework implemented by Google MediaPipe Hand (GMH) and an innovative enhanced version, GMH-D</li>
<li>methods: use Google MediaPipe Hand (GMH) and an improved version GMH-D, utilizing the depth estimation of an RGB-Depth camera to achieve more accurate 3D hand gesture tracking</li>
<li>results: compare the results of GMH and GMH-D, showing that GMH-D has higher accuracy in spatial measurements, particularly for slow and fast hand gestures.<details>
<summary>Abstract</summary>
Accurate 3D tracking of hand and fingers movements poses significant challenges in computer vision. The potential applications span across multiple domains, including human-computer interaction, virtual reality, industry, and medicine. While gesture recognition has achieved remarkable accuracy, quantifying fine movements remains a hurdle, particularly in clinical applications where the assessment of hand dysfunctions and rehabilitation training outcomes necessitate precise measurements. Several novel and lightweight frameworks based on Deep Learning have emerged to address this issue; however, their performance in accurately and reliably measuring fingers movements requires validation against well-established gold standard systems. In this paper, the aim is to validate the handtracking framework implemented by Google MediaPipe Hand (GMH) and an innovative enhanced version, GMH-D, that exploits the depth estimation of an RGB-Depth camera to achieve more accurate tracking of 3D movements. Three dynamic exercises commonly administered by clinicians to assess hand dysfunctions, namely Hand Opening-Closing, Single Finger Tapping and Multiple Finger Tapping are considered. Results demonstrate high temporal and spectral consistency of both frameworks with the gold standard. However, the enhanced GMH-D framework exhibits superior accuracy in spatial measurements compared to the baseline GMH, for both slow and fast movements. Overall, our study contributes to the advancement of hand tracking technology, the establishment of a validation procedure as a good-practice to prove efficacy of deep-learning-based hand-tracking, and proves the effectiveness of GMH-D as a reliable framework for assessing 3D hand movements in clinical applications.
</details>
<details>
<summary>摘要</summary>
准确的3D手部运动跟踪在计算机视觉领域 pose significant challenges. 该领域的应用范围广泛，包括人机交互、虚拟现实、工业和医学。虽然手势识别已经达到了很高的准确性，但量化细微的手部运动仍然是一个难点，特别是在医学应用中， где评估手功能缺陷和rehabilitation training outcome需要精准的量化。Recently, several novel and lightweight frameworks based on Deep Learning have emerged to address this issue. However, their performance in accurately and reliably measuring finger movements requires validation against well-established gold standard systems.在这篇论文中，我们的目标是验证Google MediaPipe Hand（GMH）实现的手跟踪框架和一个创新的改进版本GMH-D，该版本利用RGB-深度摄像头的深度估计来实现更高精度的3D手部运动跟踪。我们考虑了临床医生通常用于评估手功能缺陷的三种动作， namely Hand Opening-Closing, Single Finger Tapping和Multiple Finger Tapping。结果表明两个框架具有高度和spectral consistency with the gold standard。然而，GMH-D版本在空间量化方面表现出了更高的准确性，特别是对于slow和fast movement。总的来说，本研究对手跟踪技术的进步、设立了一种验证手 tracking效果的良好做法，以及证明了GMH-D版本在临床应用中是一个可靠的手部运动跟踪框架。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Intelligence-of-a-Self-driving-Car-and-Rule-Based-Decision-Making"><a href="#Spatial-Intelligence-of-a-Self-driving-Car-and-Rule-Based-Decision-Making" class="headerlink" title="Spatial Intelligence of a Self-driving Car and Rule-Based Decision Making"></a>Spatial Intelligence of a Self-driving Car and Rule-Based Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01085">http://arxiv.org/abs/2308.01085</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stanislav Kikot</li>
<li>for: 自动驾驶车辆在复杂交通情况下实现人类Like的行为， combining rule-based decision making with traditional motion planning techniques.</li>
<li>methods: 使用规则基于决策和传统的运动规划技术。</li>
<li>results: 实现了人类Like的自动驾驶车辆行为，提供了开发机器人空间意识的技术研究方向。<details>
<summary>Abstract</summary>
In this paper we show how rule-based decision making can be combined with traditional motion planning techniques to achieve human-like behavior of a self-driving vehicle in complex traffic situations. We give and discuss examples of decision rules in autonomous driving. We draw on these examples to illustrate that developing techniques for spatial awareness of robots is an exciting activity which deserves more attention from spatial reasoning community that it had received so far.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们展示了如何基于规则的决策可以与传统的动态规划技术相结合，以实现自动驾驶车辆在复杂交通情况下的人类化行为。我们给出了和讨论了自动驾驶决策规则的例子。我们通过这些例子来示例，发展robots空间意识技术是一项有趣的活动，这个领域在空间理解社区中得到了更多的注意力。
</details></li>
</ul>
<hr>
<h2 id="Graph-Anomaly-Detection-at-Group-Level-A-Topology-Pattern-Enhanced-Unsupervised-Approach"><a href="#Graph-Anomaly-Detection-at-Group-Level-A-Topology-Pattern-Enhanced-Unsupervised-Approach" class="headerlink" title="Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach"></a>Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01063">http://arxiv.org/abs/2308.01063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xing Ai, Jialong Zhou, Yulin Zhu, Gaolei Li, Tomasz P. Michalak, Xiapu Luo, Kai Zhou</li>
<li>For: This paper proposes a novel unsupervised framework for Group-level Graph Anomaly Detection (Gr-GAD) to identify and localize anomaly groups within a graph.* Methods: The proposed framework employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that belong to potential anomaly groups, followed by group sampling and Topology Pattern-based Graph Contrastive Learning (TPGCL) to identify and localize anomaly groups.* Results: The experimental results on both real-world and synthetic datasets demonstrate the superior performance of the proposed framework in identifying and localizing anomaly groups, highlighting its potential for practical applications.Here’s the full text in Simplified Chinese:* For: 本文提出了一种新的无监督框架，用于检测图像中异常群体（Group-level Graph Anomaly Detection，Gr-GAD）。* Methods: 该框架使用变形的图自编码器（Graph AutoEncoder，GAE）来找到潜在异常群体的anchor节点，然后使用组样本和图 Pattern-based Graph Contrastive Learning（TPGCL）来识别和定位异常群体。* Results: 实验结果表明，提出的框架在真实世界和 sintetic 数据集上具有优秀的表现，能够准确地识别和定位异常群体，这 highlights 其在实际应用中的潜在价值。<details>
<summary>Abstract</summary>
Graph anomaly detection (GAD) has achieved success and has been widely applied in various domains, such as fraud detection, cybersecurity, finance security, and biochemistry. However, existing graph anomaly detection algorithms focus on distinguishing individual entities (nodes or graphs) and overlook the possibility of anomalous groups within the graph. To address this limitation, this paper introduces a novel unsupervised framework for a new task called Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework first employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that belong to potential anomaly groups by capturing long-range inconsistencies. Subsequently, group sampling is employed to sample candidate groups, which are then fed into the proposed Topology Pattern-based Graph Contrastive Learning (TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to generate embeddings for each candidate group and thus distinct anomaly groups. The experimental results on both real-world and synthetic datasets demonstrate that the proposed framework shows superior performance in identifying and localizing anomaly groups, highlighting it as a promising solution for Gr-GAD. Datasets and codes of the proposed framework are at the github repository https://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.
</details>
<details>
<summary>摘要</summary>
“几何异常检测（GAD）已经取得成功并广泛应用于不同领域，如诈欺检测、网络安全、金融安全和生物化学。但是现有的几何异常检测算法仅专注于分别的元素（节点或几何），忽略了可能的异常群体在几何中。为了解决这个限制，本文提出了一个新的无监督框架，即Group-level Graph Anomaly Detection（Gr-GAD）。”“提案的框架首先使用一种几何自动化器（GAE）的变种来找到可能的异常群体的节点。接着，群体抽样被使用来抽样候选群体，并将其 feed 到提案的几何模式基于的几何对称学习（TPGCL）方法。TPGCL 使用群体的几何模式作为来源，将每个候选群体转换为不同的异常群体。实验结果显示，提案的框架在真实世界和 sintetic 数据集上显示出了优秀的表现，能够实时识别和定位异常群体，因此被认为是一个有前途的解决方案。”“如需取得 datasets 和代码，请参考以下 GitHub 存储库：https://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection。”
</details></li>
</ul>
<hr>
<h2 id="A-Counterfactual-Safety-Margin-Perspective-on-the-Scoring-of-Autonomous-Vehicles’-Riskiness"><a href="#A-Counterfactual-Safety-Margin-Perspective-on-the-Scoring-of-Autonomous-Vehicles’-Riskiness" class="headerlink" title="A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles’ Riskiness"></a>A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles’ Riskiness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01050">http://arxiv.org/abs/2308.01050</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Zanardi, Andrea Censi, Margherita Atzei, Luigi Di Lillo, Emilio Frazzoli</li>
<li>for: 这篇论文旨在评估自动驾驶车辆（AVs）的风险，以便更好地评估AVs在不同的操作设计域（ODDs）中的安全性。</li>
<li>methods: 这篇论文提出了一种基于对比式模拟的数据驱动方法，用于比较不同AVs的行为在不同ODDs中的风险。该方法基于“违反行为”的counterfactual simulations，以计算AVs的安全空间。</li>
<li>results: 实验结果表明，提出的方法可以评估AVs的风险，并且可以评估不同AV提供商的安全性。这种方法可以在AV的行为策略未知时也进行应用，因此可以用于第三方风险评估人员。<details>
<summary>Abstract</summary>
Autonomous Vehicles (AVs) have the potential to provide numerous societal benefits, such as decreased road accidents and increased overall transportation efficiency. However, quantifying the risk associated with AVs is challenging due to the lack of historical data and the rapidly evolving technology. This paper presents a data-driven framework for comparing the risk of different AVs' behaviors in various operational design domains (ODDs), based on counterfactual simulations of "misbehaving" road users. We introduce the concept of counterfactual safety margin, which represents the minimum deviation from normal behavior that could lead to a collision. This concept helps to find the most critical scenarios but also to assess the frequency and severity of risk of AVs. We show that the proposed methodology is applicable even when the AV's behavioral policy is unknown -- through worst- and best-case analyses -- making the method useful also to external third-party risk assessors. Our experimental results demonstrate the correlation between the safety margin, the driving policy quality, and the ODD shedding light on the relative risk associated with different AV providers. This work contributes to AV safety assessment and aids in addressing legislative and insurance concerns surrounding this emerging technology.
</details>
<details>
<summary>摘要</summary>
We introduce the concept of counterfactual safety margin, which represents the minimum deviation from normal behavior that could lead to a collision. This concept helps to identify the most critical scenarios and assess the frequency and severity of risks associated with AVs. We show that the proposed methodology is applicable even when the AV's behavioral policy is unknown, making it useful for external third-party risk assessors.Our experimental results demonstrate a correlation between the safety margin, driving policy quality, and ODD, shedding light on the relative risk associated with different AV providers. This work contributes to AV safety assessment and addresses legislative and insurance concerns surrounding this emerging technology.Translation notes:* "Autonomous Vehicles" is translated as "自动驾驶车辆" (zì àuto véhículóu)* "operational design domains" is translated as "运营设计领域" (yùn xíng jiè yì)* "counterfactual simulations" is translated as "对比 simulations" (duì bèi simulào)* "safety margin" is translated as "安全余地" (ān qū yú dì)* "driving policy" is translated as "驾驶策略" (jì shǐ mǎ lü)* "ODD" is translated as "运营设计领域" (yùn xíng jiè yì)Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Chat-Translation-Error-Detection-for-Assisting-Cross-lingual-Communications"><a href="#Chat-Translation-Error-Detection-for-Assisting-Cross-lingual-Communications" class="headerlink" title="Chat Translation Error Detection for Assisting Cross-lingual Communications"></a>Chat Translation Error Detection for Assisting Cross-lingual Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01044">http://arxiv.org/abs/2308.01044</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cl-tohoku/bpersona-chat">https://github.com/cl-tohoku/bpersona-chat</a></li>
<li>paper_authors: Yunmeng Li, Jun Suzuki, Makoto Morishita, Kaori Abe, Ryoko Tokuhisa, Ana Brassard, Kentaro Inui</li>
<li>for: 本研究开发了一个通信支持系统，用于监测机器翻译错误，以促进跨语言通信。</li>
<li>methods: 研究人员使用了一个错误检测器作为系统的基础，并建立了一个新的日本英文双语聊天数据库（BPersona-chat），该数据库包含多轮漫谈对话，并具有人工审核的品质评分。</li>
<li>results: 错误检测器可以作为更进阶的错误翻译检测系统的基础。<details>
<summary>Abstract</summary>
In this paper, we describe the development of a communication support system that detects erroneous translations to facilitate crosslingual communications due to the limitations of current machine chat translation methods. We trained an error detector as the baseline of the system and constructed a new Japanese-English bilingual chat corpus, BPersona-chat, which comprises multiturn colloquial chats augmented with crowdsourced quality ratings. The error detector can serve as an encouraging foundation for more advanced erroneous translation detection systems.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们描述了一个交流支持系统，用于检测machine翻译错译以促进多语言交流。我们基于基线错误检测器进行了训练，并构建了一个新的日语英语对话资料集，BPersona-chat，这些对话包括多轮口语对话，并且通过人工投票来评估对话质量。错误检测器可以作为更先进的错误翻译检测系统的基础。
</details></li>
</ul>
<hr>
<h2 id="Three-Factors-to-Improve-Out-of-Distribution-Detection"><a href="#Three-Factors-to-Improve-Out-of-Distribution-Detection" class="headerlink" title="Three Factors to Improve Out-of-Distribution Detection"></a>Three Factors to Improve Out-of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01030">http://arxiv.org/abs/2308.01030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunjun Choi, JaeHo Chung, Hawook Jeong, Jin Young Choi</li>
<li>for: 本研究旨在提高异常输入探测（OOD）的性能，通过使用辅助数据作为外围数据进行细化。</li>
<li>methods: 本研究使用了三个贡献来解决OOD探测与分类精度之间的负担：（i） incorporating自我智能填充损失可以提高网络的准确性;（ii） 采样 semi-hard 异常数据进行训练可以提高OOD探测性能，而无需影响分类精度;（iii） 我们提出了一种新的超vised Contrastive Learning，可以同时提高OOD探测性能和网络的准确性。</li>
<li>results: 我们的方法可以同时提高OOD探测性能和分类精度，解决了之前的负担。我们的方法与之前的方法相比，在两个性能指标上均有提高。<details>
<summary>Abstract</summary>
In the problem of out-of-distribution (OOD) detection, the usage of auxiliary data as outlier data for fine-tuning has demonstrated encouraging performance. However, previous methods have suffered from a trade-off between classification accuracy (ACC) and OOD detection performance (AUROC, FPR, AUPR). To improve this trade-off, we make three contributions: (i) Incorporating a self-knowledge distillation loss can enhance the accuracy of the network; (ii) Sampling semi-hard outlier data for training can improve OOD detection performance with minimal impact on accuracy; (iii) The introduction of our novel supervised contrastive learning can simultaneously improve OOD detection performance and the accuracy of the network. By incorporating all three factors, our approach enhances both accuracy and OOD detection performance by addressing the trade-off between classification and OOD detection. Our method achieves improvements over previous approaches in both performance metrics.
</details>
<details>
<summary>摘要</summary>
在 OUT-OF-DISTRIBUTION（OOD）检测问题中，启用辅助数据作为精度数据进行微调已经表现出了鼓舞人的效果。然而，先前的方法受到了准确率（ACC）和OOD检测性能（AUROC、FPR、AUPR）的负面交互。为了改善这种交互，我们提出了三种贡献：（i）添加自知ledge distillation损失可以提高网络的准确率；（ii）在训练中采用半硬分配的异常数据采样可以提高OOD检测性能，而无需影响准确率；（iii）我们提出的新的指导contrastive learning可以同时提高OOD检测性能和网络的准确率。通过涵盖所有这些因素，我们的方法可以同时提高准确率和OOD检测性能，解决了准确率和OOD检测性能之间的负面交互。我们的方法在先前的方法中均表现出了改善。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Representation-Learning-for-Periodic-Time-Series-with-Floss-A-Frequency-Domain-Regularization-Approach"><a href="#Enhancing-Representation-Learning-for-Periodic-Time-Series-with-Floss-A-Frequency-Domain-Regularization-Approach" class="headerlink" title="Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach"></a>Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01011">http://arxiv.org/abs/2308.01011</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/agustdd/floss">https://github.com/agustdd/floss</a></li>
<li>paper_authors: Chunwei Yang, Xiaoxu Chen, Lijun Sun, Hongyu Yang, Yuankai Wu</li>
<li>for: 这篇论文的目的是提出一种无监督的方法，可以自动调整学习表现中的频率域表现，以提高深度学习模型在时间序列分析领域的表现。</li>
<li>methods: 这篇论文提出了一种名为Floss的方法，它可以自动检测时间序列中的主要频率，并使用频率域的periodic shift和spectral density similarity度量来学习有意义的表现。</li>
<li>results: 在实验中，Floss方法能够将时间序列分类、预测和异常探测等任务中的表现提高，并且可以与各种深度学习模型整合使用。<details>
<summary>Abstract</summary>
Time series analysis is a fundamental task in various application domains, and deep learning approaches have demonstrated remarkable performance in this area. However, many real-world time series data exhibit significant periodic or quasi-periodic dynamics that are often not adequately captured by existing deep learning-based solutions. This results in an incomplete representation of the underlying dynamic behaviors of interest. To address this gap, we propose an unsupervised method called Floss that automatically regularizes learned representations in the frequency domain. The Floss method first automatically detects major periodicities from the time series. It then employs periodic shift and spectral density similarity measures to learn meaningful representations with periodic consistency. In addition, Floss can be easily incorporated into both supervised, semi-supervised, and unsupervised learning frameworks. We conduct extensive experiments on common time series classification, forecasting, and anomaly detection tasks to demonstrate the effectiveness of Floss. We incorporate Floss into several representative deep learning solutions to justify our design choices and demonstrate that it is capable of automatically discovering periodic dynamics and improving state-of-the-art deep learning models.
</details>
<details>
<summary>摘要</summary>
时序分析是多个应用领域的基本任务，深度学习方法在这个领域表现出了惊人的表现。然而，许多实际世界时序数据表现出了显著的周期或几乎周期的动态行为，这些动态行为常常不受现有的深度学习基于解决方案完全捕捉。这导致了时序分析中的下降表示，从而影响了对真实的动态行为的理解。为解决这个问题，我们提出了一种不监督的方法called Floss，该方法可以自动规范学习的表示空间中的频率域。Floss方法首先自动检测时序数据中的主要周期性。然后，它使用周期偏移和频率密度相似度度量来学习具有周期一致性的有意义表示。此外，Floss可以轻松地在超级vised、半监督和无监督学习框架中 incorporated。我们对常见的时序分类、预测和异常检测任务进行了广泛的实验，以证明Floss的有效性。我们将Floss incorporated into several representative deep learning solutions to justify our design choices and demonstrate that it is capable of automatically discovering periodic dynamics and improving state-of-the-art deep learning models.
</details></li>
</ul>
<hr>
<h2 id="FusionAD-Multi-modality-Fusion-for-Prediction-and-Planning-Tasks-of-Autonomous-Driving"><a href="#FusionAD-Multi-modality-Fusion-for-Prediction-and-Planning-Tasks-of-Autonomous-Driving" class="headerlink" title="FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving"></a>FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01006">http://arxiv.org/abs/2308.01006</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/westlake-autolab/fusionad">https://github.com/westlake-autolab/fusionad</a></li>
<li>paper_authors: Tengju Ye, Wei Jing, Chunyong Hu, Shikun Huang, Lingping Gao, Fangzhen Li, Jingke Wang, Ke Guo, Wencong Xiao, Weibo Mao, Hang Zheng, Kun Li, Junbo Chen, Kaicheng Yu</li>
<li>for: 这 paper 的目的是提出一个整合多种感知器的混合 neural network，以实现自适应驾驶任务中的准确和可靠性。</li>
<li>methods: 这 paper 使用了 transformer 基于的多模态混合网络，以生成高质量的混合特征。而不同于 camera-based end-to-end方法 UniAD，这 paper 采用了混合帮助的模态意识预测和状态意识规划模块，以便利用多模态特征。</li>
<li>results: 根据 nuScenes 数据集的广泛实验结果，这 paper 的 FusionAD 实现了state-of-the-art 性能，胜过基eline 的平均15% 在感知任务中，10% 在占用率预测精度中，从 ADE 分数下降至 0.389，并将预测错误率从 0.708 降至 0.12%。<details>
<summary>Abstract</summary>
Building a multi-modality multi-task neural network toward accurate and robust performance is a de-facto standard in perception task of autonomous driving. However, leveraging such data from multiple sensors to jointly optimize the prediction and planning tasks remains largely unexplored. In this paper, we present FusionAD, to the best of our knowledge, the first unified framework that fuse the information from two most critical sensors, camera and LiDAR, goes beyond perception task. Concretely, we first build a transformer based multi-modality fusion network to effectively produce fusion based features. In constrast to camera-based end-to-end method UniAD, we then establish a fusion aided modality-aware prediction and status-aware planning modules, dubbed FMSPnP that take advantages of multi-modality features. We conduct extensive experiments on commonly used benchmark nuScenes dataset, our FusionAD achieves state-of-the-art performance and surpassing baselines on average 15% on perception tasks like detection and tracking, 10% on occupancy prediction accuracy, reducing prediction error from 0.708 to 0.389 in ADE score and reduces the collision rate from 0.31% to only 0.12%.
</details>
<details>
<summary>摘要</summary>
建立多模态多任务神经网络，以实现自驾护航任务的准确和可靠性，是现代自驾护航技术的标准。然而，利用多感器数据进行共同优化预测和规划任务，仍然是未explored领域。本文提出了FusionAD，我们知道的首个整合框架，将Camera和LiDAR两种最重要的感器信息融合到一起，不仅超越了感知任务，还实现了预测和规划任务的协同优化。具体来说，我们首先构建了基于变换器的多模态融合网络，以生成高质量的融合特征。与UniAD相比，我们then建立了融合帮助模块和状态意识规划模块，通过多模态特征来优化预测和规划任务。我们在常用的nuScenes数据集上进行了广泛的实验，并证明了FusionAD可以在感知任务中表现出状元的性能，比如检测和跟踪任务的准确率提高了15%，占用率预测精度提高了10%，从0.708下降到0.389的ADE分数中的预测错误率下降了15%，并将collision rate从0.31%下降到0.12%。
</details></li>
</ul>
<hr>
<h2 id="Wasserstein-Diversity-Enriched-Regularizer-for-Hierarchical-Reinforcement-Learning"><a href="#Wasserstein-Diversity-Enriched-Regularizer-for-Hierarchical-Reinforcement-Learning" class="headerlink" title="Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning"></a>Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00989">http://arxiv.org/abs/2308.00989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haorui Li, Jiaqi Liang, Linjing Li, Daniel Zeng</li>
<li>for: 用于解决复杂任务的 hierarchical reinforcement learning composites subpolicies。</li>
<li>methods: 使用自动发现的 subpolicies，并使用 Wasserstein Diversity-Enriched Regularizer（WDER）来提高性能。</li>
<li>results: 实验结果表明，WDER 可以提高性能和样本效率，无需修改超参数。<details>
<summary>Abstract</summary>
Hierarchical reinforcement learning composites subpolicies in different hierarchies to accomplish complex tasks.Automated subpolicies discovery, which does not depend on domain knowledge, is a promising approach to generating subpolicies.However, the degradation problem is a challenge that existing methods can hardly deal with due to the lack of consideration of diversity or the employment of weak regularizers. In this paper, we propose a novel task-agnostic regularizer called the Wasserstein Diversity-Enriched Regularizer (WDER), which enlarges the diversity of subpolicies by maximizing the Wasserstein distances among action distributions. The proposed WDER can be easily incorporated into the loss function of existing methods to boost their performance further.Experimental results demonstrate that our WDER improves performance and sample efficiency in comparison with prior work without modifying hyperparameters, which indicates the applicability and robustness of the WDER.
</details>
<details>
<summary>摘要</summary>
Hierarchical reinforcement learning 组合不同层次的子政策来完成复杂任务。自动发现子政策的方法，不依赖域知识，是现有方法中最佳的approach。然而，劣化问题是现有方法难以处理的一大挑战，这是因为现有方法缺乏多样性或者使用弱regularizers。在这篇论文中，我们提出了一种新的任务无关的正则化器 called Wasserstein Diversity-Enriched Regularizer (WDER)，它通过 maximizing Wasserstein distances among action distributions来扩大子政策的多样性。我们的WDER可以轻松地integrated into existing methods的损失函数中，以提高其性能。实验结果表明，我们的WDER可以提高性能和样本效率，而不需要修改 гиперпараметров，这表明了WDER的可用性和稳定性。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-aware-Collaborative-Filtering-with-Pre-trained-Language-Model-for-Personalized-Review-based-Rating-Prediction"><a href="#Knowledge-aware-Collaborative-Filtering-with-Pre-trained-Language-Model-for-Personalized-Review-based-Rating-Prediction" class="headerlink" title="Knowledge-aware Collaborative Filtering with Pre-trained Language Model for Personalized Review-based Rating Prediction"></a>Knowledge-aware Collaborative Filtering with Pre-trained Language Model for Personalized Review-based Rating Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02555">http://arxiv.org/abs/2308.02555</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wqxleo/kcf-plm">https://github.com/wqxleo/kcf-plm</a></li>
<li>paper_authors: Quanxiu Wang, Xinlei Cao, Jianyong Wang, Wei Zhang</li>
<li>for: 这篇论文的目的是如何利用现有的评论来预测用户对Item的评分？</li>
<li>methods: 该论文提出了一种名为知识感知协同过滤（KCF-PLM）的方法，该方法通过模型用户-Item对的交互，并利用预训练的自然语言模型来更好地表示用户和Item的特征。</li>
<li>results: 经过实验表明，KCF-PLM可以更好地预测用户对Item的评分，并且在多个公共数据集上达到了比较高的预测精度。<details>
<summary>Abstract</summary>
Personalized review-based rating prediction aims at leveraging existing reviews to model user interests and item characteristics for rating prediction. Most of the existing studies mainly encounter two issues. First, the rich knowledge contained in the fine-grained aspects of each review and the knowledge graph is rarely considered to complement the pure text for better modeling user-item interactions. Second, the power of pre-trained language models is not carefully studied for personalized review-based rating prediction. To address these issues, we propose an approach named Knowledge-aware Collaborative Filtering with Pre-trained Language Model (KCF-PLM). For the first issue, to utilize rich knowledge, KCF-PLM develops a transformer network to model the interactions of the extracted aspects w.r.t. a user-item pair. For the second issue, to better represent users and items, KCF-PLM takes all the historical reviews of a user or an item as input to pre-trained language models. Moreover, KCF-PLM integrates the transformer network and the pre-trained language models through representation propagation on the knowledge graph and user-item guided attention of the aspect representations. Thus KCF-PLM combines review text, aspect, knowledge graph, and pre-trained language models together for review-based rating prediction. We conduct comprehensive experiments on several public datasets, demonstrating the effectiveness of KCF-PLM.
</details>
<details>
<summary>摘要</summary>
personalized review-based rating prediction aims to leverage existing reviews to model user interests and item characteristics for rating prediction. most of the existing studies mainly encounter two issues. first, the rich knowledge contained in the fine-grained aspects of each review and the knowledge graph is rarely considered to complement the pure text for better modeling user-item interactions. second, the power of pre-trained language models is not carefully studied for personalized review-based rating prediction. to address these issues, we propose an approach named knowledge-aware collaborative filtering with pre-trained language model (KCF-PLM). for the first issue, to utilize rich knowledge, KCF-PLM develops a transformer network to model the interactions of the extracted aspects w.r.t. a user-item pair. for the second issue, to better represent users and items, KCF-PLM takes all the historical reviews of a user or an item as input to pre-trained language models. moreover, KCF-PLM integrates the transformer network and the pre-trained language models through representation propagation on the knowledge graph and user-item guided attention of the aspect representations. thus KCF-PLM combines review text, aspect, knowledge graph, and pre-trained language models together for review-based rating prediction. we conduct comprehensive experiments on several public datasets, demonstrating the effectiveness of KCF-PLM.
</details></li>
</ul>
<hr>
<h2 id="Isolation-and-Induction-Training-Robust-Deep-Neural-Networks-against-Model-Stealing-Attacks"><a href="#Isolation-and-Induction-Training-Robust-Deep-Neural-Networks-against-Model-Stealing-Attacks" class="headerlink" title="Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks"></a>Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00958">http://arxiv.org/abs/2308.00958</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dig-beihang/ini-model-stealing-defense">https://github.com/dig-beihang/ini-model-stealing-defense</a></li>
<li>paper_authors: Jun Guo, Aishan Liu, Xingyu Zheng, Siyuan Liang, Yisong Xiao, Yichao Wu, Xianglong Liu<br>for:这篇论文的目的是提出一个名为“Isolation and Induction”（InI）的新型训练框架，以提高机器学习模型的防护性。methods:这篇论文使用了一种名为“adversarial training”的方法，将敌对的训练gradient（ gradient）与预期的gradient分离，从而减少了误差 Computational overhead。此外，它还使用了一种名为“induction”的方法，将敌对的训练gradient与预期的gradient分离，以生成不具有实际价值的输出，以防止敌对者获得有用的信息。results:实验结果显示，InI可以对机器学习模型进行有效的防护，将敌对者的侦测精度降低至48%。此外，InI还可以实现较高的速度（至25.4倍），比其他现有方法更具有实际价值。<details>
<summary>Abstract</summary>
Despite the broad application of Machine Learning models as a Service (MLaaS), they are vulnerable to model stealing attacks. These attacks can replicate the model functionality by using the black-box query process without any prior knowledge of the target victim model. Existing stealing defenses add deceptive perturbations to the victim's posterior probabilities to mislead the attackers. However, these defenses are now suffering problems of high inference computational overheads and unfavorable trade-offs between benign accuracy and stealing robustness, which challenges the feasibility of deployed models in practice. To address the problems, this paper proposes Isolation and Induction (InI), a novel and effective training framework for model stealing defenses. Instead of deploying auxiliary defense modules that introduce redundant inference time, InI directly trains a defensive model by isolating the adversary's training gradient from the expected gradient, which can effectively reduce the inference computational cost. In contrast to adding perturbations over model predictions that harm the benign accuracy, we train models to produce uninformative outputs against stealing queries, which can induce the adversary to extract little useful knowledge from victim models with minimal impact on the benign performance. Extensive experiments on several visual classification datasets (e.g., MNIST and CIFAR10) demonstrate the superior robustness (up to 48% reduction on stealing accuracy) and speed (up to 25.4x faster) of our InI over other state-of-the-art methods. Our codes can be found in https://github.com/DIG-Beihang/InI-Model-Stealing-Defense.
</details>
<details>
<summary>摘要</summary>
尽管机器学习模型作为服务（MLaaS）广泛应用，但它们受到模型盗用攻击的威胁。这些攻击可以通过黑盒查询过程来复制模型功能，无需任何受 target 受害者模型的知识。现有的防御措施添加了对受害者的 posterior 概率中的误导性扰响，但这些防御措施现在面临高于ferred  Computational overhead和不利的负荷和盗用鲁棒性的问题，这担困了部署模型的实际应用。为解决这些问题，本文提出了隔离和推论（InI），一种新的和有效的训练框架 для模型盗用防御。而不是在auxiliary defense module中添加 redundancy 的推理时间，InI直接在针对敌方的训练梯度上进行隔离，可以有效减少推理 Computational overhead。与之前添加扰响到模型预测结果的方法不同，我们在模型生成不具有指导意义的输出时进行训练，以便使敌方提取到Model 中的有用信息非常少，对正常性产生最小的影响。经验表明，我们的 InI 在多个视觉分类 datasets（例如 MNIST 和 CIFAR10）上具有较高的鲁棒性（减少盗用精度48%）和速度（减少推理时间25.4倍）优势，代码可以在 <https://github.com/DIG-Beihang/InI-Model-Stealing-Defense> 找到。
</details></li>
</ul>
<hr>
<h2 id="From-Sparse-to-Soft-Mixtures-of-Experts"><a href="#From-Sparse-to-Soft-Mixtures-of-Experts" class="headerlink" title="From Sparse to Soft Mixtures of Experts"></a>From Sparse to Soft Mixtures of Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00951">http://arxiv.org/abs/2308.00951</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/vmoe">https://github.com/google-research/vmoe</a></li>
<li>paper_authors: Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Neil Houlsby</li>
<li>for: 这篇论文旨在提出一种基于 sparse mixture of expert（MoE）的完全可导的Transformer模型，以解决MoE模型在训练稳定性、选择token、不能扩展专家数量等方面存在的挑战。</li>
<li>methods: 这篇论文提出了一种名为Soft MoE的新方法，它使用了不同权重的输入token将所有输入token映射到每个专家中，以实现隐藏层的软分配。这种方法可以保持MoE模型的好处，同时解决许多问题。</li>
<li>results: 在视觉识别任务上，Soft MoE模型在与标准Transformer（ViT）和受欢迎的MoE变体（Tokens Choice和Experts Choice）进行比较时，具有更高的性能。例如，Soft MoE-Base&#x2F;16需要10.5倍少的执行成本（5.7倍少的墙 clock时间）与ViT-Huge&#x2F;14匹配其性能，而且可以轻松扩展。<details>
<summary>Abstract</summary>
Sparse mixture of expert architectures (MoEs) scale model capacity without large increases in training or inference costs. Despite their success, MoEs suffer from a number of issues: training instability, token dropping, inability to scale the number of experts, or ineffective finetuning. In this work, we proposeSoft MoE, a fully-differentiable sparse Transformer that addresses these challenges, while maintaining the benefits of MoEs. Soft MoE performs an implicit soft assignment by passing different weighted combinations of all input tokens to each expert. As in other MoE works, experts in Soft MoE only process a subset of the (combined) tokens, enabling larger model capacity at lower inference cost. In the context of visual recognition, Soft MoE greatly outperforms standard Transformers (ViTs) and popular MoE variants (Tokens Choice and Experts Choice). For example, Soft MoE-Base/16 requires 10.5x lower inference cost (5.7x lower wall-clock time) than ViT-Huge/14 while matching its performance after similar training. Soft MoE also scales well: Soft MoE Huge/14 with 128 experts in 16 MoE layers has over 40x more parameters than ViT Huge/14, while inference time cost grows by only 2%, and it performs substantially better.
</details>
<details>
<summary>摘要</summary>
《稀疏混合专家架构（MoE）缩放模型容量无需大幅提高训练或推理成本。尽管它们取得了成功，但MoE受到许多问题的困扰：训练不稳定、掉 Token、不能扩展专家数量以及不良的微调。在这项工作中，我们提出了Soft MoE，一种完全可导的稀疏转换器，解决了这些挑战，同时保持了MoE的优点。Soft MoE通过不同权重的 combinations来进行隐式软分配，将所有输入 tokens 传递给每个专家。与其他 MoE 工作相同，Soft MoE 专家只处理部分（组合）输入 tokens，允许更大的模型容量在更低的推理成本下运行。在视识知识领域，Soft MoE 在标准 Transformer 和受欢迎的 MoE 变体（Token Choice 和 Experts Choice）的基础上取得了很大的进步。例如，Soft MoE-Base/16 需要10.5倍lower的推理成本（5.7倍lower的墙 clock time），与 ViT-Huge/14 的性能相同。Soft MoE 也可扩展：Soft MoE Huge/14  WITH 128 专家 IN 16 MoE layers 有40倍更多的参数 чем ViT Huge/14，而推理时间成本只增加了2%，并且表现较好。》
</details></li>
</ul>
<hr>
<h2 id="Teaching-Smaller-Language-Models-To-Generalise-To-Unseen-Compositional-Questions"><a href="#Teaching-Smaller-Language-Models-To-Generalise-To-Unseen-Compositional-Questions" class="headerlink" title="Teaching Smaller Language Models To Generalise To Unseen Compositional Questions"></a>Teaching Smaller Language Models To Generalise To Unseen Compositional Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00946">http://arxiv.org/abs/2308.00946</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/timhartill/unseen_questions">https://github.com/timhartill/unseen_questions</a></li>
<li>paper_authors: Tim Hartill, Neset Tan, Michael Witbrock, Patricia J. Riddle</li>
<li>for: 本研究旨在将小型语言模型扩展到解答困难的作 compositional questions，不需要训练时见到的问题。</li>
<li>methods: 本研究使用多任务超级预训练和紧密搜寻系统，以将多元的推理能力传递给模型。</li>
<li>results: 本研究在多个评估数据集（StrategyQA、CommonsenseQA、IIRC、DROP、Musique和ARC-DA）上建立强大的基准值，并证明在对于问题的解答中，可以通过增加对于问题的数据库进行搜寻，以提高模型的性能。<details>
<summary>Abstract</summary>
We equip a smaller Language Model to generalise to answering challenging compositional questions that have not been seen in training. To do so we propose a combination of multitask supervised pretraining on up to 93 tasks designed to instill diverse reasoning abilities, and a dense retrieval system that aims to retrieve a set of evidential paragraph fragments. Recent progress in question-answering has been achieved either through prompting methods against very large pretrained Language Models in zero or few-shot fashion, or by fine-tuning smaller models, sometimes in conjunction with information retrieval. We focus on the less explored question of the extent to which zero-shot generalisation can be enabled in smaller models with retrieval against a corpus within which sufficient information to answer a particular question may not exist. We establish strong baselines in this setting for diverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and ARC-DA), and show that performance can be significantly improved by adding retrieval-augmented training datasets which are designed to expose our models to a variety of heuristic reasoning strategies such as weighing partial evidence or ignoring an irrelevant context.
</details>
<details>
<summary>摘要</summary>
我们将一个较小的语言模型训练来综合回答具有复杂构成的问题，这些问题在训练过程中没有出现过。我们提出了一种结合多任务超级预训和紧凑搜寻系统的方法，以实现对答案问题的扩展。现今问题回答的进步主要是通过对非常大的预训语言模型进行提示方法，或是精确地训练较小的模型。我们专注在较少探索的问题是，可以使用较小的模型和搜寻系统，对于尚未出现在训练数据中的问题进行零shot扩展。我们在不同的评估数据集（StrategyQA、CommonSenseQA、IIRC、DROP、Musique和ARC-DA）中建立了强大的基准，并证明可以通过增加搜寻增强训练数据集，让我们的模型掌握了复杂的推理策略，例如考虑部分证据或忽略无关的背景。
</details></li>
</ul>
<hr>
<h2 id="Feature-aware-conditional-GAN-for-category-text-generation"><a href="#Feature-aware-conditional-GAN-for-category-text-generation" class="headerlink" title="Feature-aware conditional GAN for category text generation"></a>Feature-aware conditional GAN for category text generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00939">http://arxiv.org/abs/2308.00939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinze Li, Kezhi Mao, Fanfan Lin, Zijian Feng</li>
<li>for: 本文提出了一种新的文本生成框架，即特征意识 conditional GAN（FA-GAN），用于控制类别文本生成。</li>
<li>methods: FA-GAN使用了一种序列到序列结构的生成器，包括三个Encoder和一个基于 Relational Memory Core 的 decoder，并在 adversarial 训练中添加了多类分类损失函数。</li>
<li>results: 对于6种文本分类 datasets，FA-GAN consistent outperform 10 状态之前的文本生成方法，并在实际案例中证明了生成的 sintetic 句子可以匹配所需的类别，同时具有良好的可读性、流畅性和文本Authenticity。<details>
<summary>Abstract</summary>
Category text generation receives considerable attentions since it is beneficial for various natural language processing tasks. Recently, the generative adversarial network (GAN) has attained promising performance in text generation, attributed to its adversarial training process. However, there are several issues in text GANs, including discreteness, training instability, mode collapse, lack of diversity and controllability etc. To address these issues, this paper proposes a novel GAN framework, the feature-aware conditional GAN (FA-GAN), for controllable category text generation. In FA-GAN, the generator has a sequence-to-sequence structure for improving sentence diversity, which consists of three encoders including a special feature-aware encoder and a category-aware encoder, and one relational-memory-core-based decoder with the Gumbel SoftMax activation function. The discriminator has an additional category classification head. To generate sentences with specified categories, the multi-class classification loss is supplemented in the adversarial training. Comprehensive experiments have been conducted, and the results show that FA-GAN consistently outperforms 10 state-of-the-art text generation approaches on 6 text classification datasets. The case study demonstrates that the synthetic sentences generated by FA-GAN can match the required categories and are aware of the features of conditioned sentences, with good readability, fluency, and text authenticity.
</details>
<details>
<summary>摘要</summary>
文本生成领域在latest yearsreceived considerable attention, as it is beneficial for various自然语言处理任务。Recently, the generative adversarial network (GAN) has shown promising performance in text generation, thanks to its adversarial training process. However, there are several issues in text GANs, including discrete, training instability, mode collapse, lack of diversity and controllability, etc. To address these issues, this paper proposes a novel GAN framework, the feature-aware conditional GAN (FA-GAN), for controllable category text generation. In FA-GAN, the generator has a sequence-to-sequence structure to improve sentence diversity, which consists of three encoders, including a special feature-aware encoder and a category-aware encoder, and one relational-memory-core-based decoder with the Gumbel SoftMax activation function. The discriminator has an additional category classification head. To generate sentences with specified categories, the multi-class classification loss is supplemented in the adversarial training. Comprehensive experiments have been conducted, and the results show that FA-GAN consistently outperforms 10 state-of-the-art text generation approaches on 6 text classification datasets. The case study demonstrates that the synthetic sentences generated by FA-GAN can match the required categories and are aware of the features of conditioned sentences, with good readability, fluency, and text authenticity.
</details></li>
</ul>
<hr>
<h2 id="LEMMA-Learning-Language-Conditioned-Multi-Robot-Manipulation"><a href="#LEMMA-Learning-Language-Conditioned-Multi-Robot-Manipulation" class="headerlink" title="LEMMA: Learning Language-Conditioned Multi-Robot Manipulation"></a>LEMMA: Learning Language-Conditioned Multi-Robot Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00937">http://arxiv.org/abs/2308.00937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ran Gong, Xiaofeng Gao, Qiaozi Gao, Suhaila Shakiah, Govind Thattai, Gaurav S. Sukhatme</li>
<li>for: 本研究是为了开发未来基于人语言指令的多机器人系统。</li>
<li>methods: 本研究使用了模块化层次规划方法作为基础。</li>
<li>results: 研究结果表明了LEMMA的潜在用于发展未来多机器人系统。Here’s a more detailed explanation of each point:1. for: The paper is written to develop future language-conditioned multi-robot systems. The authors introduce a new benchmark called LEMMA, which focuses on task allocation and long-horizon object manipulation based on human language instructions in a tabletop setting.2. methods: The authors propose a modular hierarchical planning approach as a baseline for addressing the challenges of task allocation and strong temporal dependencies in each task. This approach is designed to identify each manipulator’s limitations and assign sub-tasks accordingly.3. results: The results of the study highlight the potential of LEMMA for developing future language-conditioned multi-robot systems. The authors provide 800 expert demonstrations and human instructions for training and evaluations, and the results show that the proposed approach is effective in handling complex manipulation tasks.<details>
<summary>Abstract</summary>
Complex manipulation tasks often require robots with complementary capabilities to collaborate. We introduce a benchmark for LanguagE-Conditioned Multi-robot MAnipulation (LEMMA) focused on task allocation and long-horizon object manipulation based on human language instructions in a tabletop setting. LEMMA features 8 types of procedurally generated tasks with varying degree of complexity, some of which require the robots to use tools and pass tools to each other. For each task, we provide 800 expert demonstrations and human instructions for training and evaluations. LEMMA poses greater challenges compared to existing benchmarks, as it requires the system to identify each manipulator's limitations and assign sub-tasks accordingly while also handling strong temporal dependencies in each task. To address these challenges, we propose a modular hierarchical planning approach as a baseline. Our results highlight the potential of LEMMA for developing future language-conditioned multi-robot systems.
</details>
<details>
<summary>摘要</summary>
多元化任务需要机器人团队协作，我们介绍了一个名为LanguagE-Conditioned Multi-robot MAnipulation（LEMMA）的标准，专注于基于人类语言指令的表格式设置中的任务分配和长期物品搬运。LEMMA包含8种生成过程中的任务，其中一些需要机器人使用工具并将工具传递给彼此。每个任务都有800名专家示范和人类指导用于训练和评估。LEMMA比现有的标准具有更大的挑战，因为它需要系统确定每个搬运者的局限性并将相应的子任务分配给它们，同时也处理每个任务中的强时间依赖关系。为解决这些挑战，我们提议了一种模块化层次规划方法作为基础。我们的结果表明LEMMA有助于未来的语言条件多机器人系统的发展。
</details></li>
</ul>
<hr>
<h2 id="Particle-swarm-optimization-with-state-based-adaptive-velocity-limit-strategy"><a href="#Particle-swarm-optimization-with-state-based-adaptive-velocity-limit-strategy" class="headerlink" title="Particle swarm optimization with state-based adaptive velocity limit strategy"></a>Particle swarm optimization with state-based adaptive velocity limit strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00936">http://arxiv.org/abs/2308.00936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinze Li, Kezhi Mao, Fanfan Lin, Xin Zhang</li>
<li>For: The paper proposes a novel particle swarm optimization (PSO) variant with a state-based adaptive velocity limit (SAVL) strategy to improve the performance of PSO in optimizing problems.* Methods: The proposed PSO-SAVL uses an evolutionary state estimation (ESE) to adaptively adjust the velocity limit based on the current searching state of particles. The limit handling strategies have been modified and adopted to improve the capability of avoiding local optima.* Results: The good performance of PSO-SAVL has been experimentally validated on a wide range of benchmark functions with 50 dimensions, and the satisfactory scalability of PSO-SAVL in high-dimension and large-scale problems has been verified. The merits of the strategies in PSO-SAVL have been experimentally demonstrated.Here is the same information in Simplified Chinese text:* For: 本文提出了一种基于状态adaptive速度限制策略（SAVL）的 particle swarm optimization（PSO）变种，以提高PSO在优化问题中的表现。* Methods: PSO-SAVL使用了进化状态估计（ESE）来适应性地调整速度限制，以适应当前粒子的搜索状态。限制处理策略也被修改和采用，以提高避免地点最优化的能力。* Results: PSO-SAVL在50维度的标准函数库上进行了广泛的实验 validate，并在高维度和大规模问题中得到了满意的扩展性。PSO-SAVL的策略优势也在实验中得到了证明。<details>
<summary>Abstract</summary>
Velocity limit (VL) has been widely adopted in many variants of particle swarm optimization (PSO) to prevent particles from searching outside the solution space. Several adaptive VL strategies have been introduced with which the performance of PSO can be improved. However, the existing adaptive VL strategies simply adjust their VL based on iterations, leading to unsatisfactory optimization results because of the incompatibility between VL and the current searching state of particles. To deal with this problem, a novel PSO variant with state-based adaptive velocity limit strategy (PSO-SAVL) is proposed. In the proposed PSO-SAVL, VL is adaptively adjusted based on the evolutionary state estimation (ESE) in which a high value of VL is set for global searching state and a low value of VL is set for local searching state. Besides that, limit handling strategies have been modified and adopted to improve the capability of avoiding local optima. The good performance of PSO-SAVL has been experimentally validated on a wide range of benchmark functions with 50 dimensions. The satisfactory scalability of PSO-SAVL in high-dimension and large-scale problems is also verified. Besides, the merits of the strategies in PSO-SAVL are verified in experiments. Sensitivity analysis for the relevant hyper-parameters in state-based adaptive VL strategy is conducted, and insights in how to select these hyper-parameters are also discussed.
</details>
<details>
<summary>摘要</summary>
Particle swarm optimization (PSO) 的 velocity limit (VL) 已经广泛应用在许多变种中，以避免粒子寻找外部解空间。但现有的适应VL策略仅根据迭代数量进行调整，导致优化结果不 satisfactory，因为VL 与粒子当前搜索状态不兼容。为解决这个问题，一种基于Evolutionary State Estimation (ESE)的PSO变体（PSO-SAVL）被提出。在PSO-SAVL中，VL 的适应调整基于ESE，其中在全球搜索状态时设置高值的VL，在本地搜索状态时设置低值的VL。此外，限制处理策略也得到了修改和采用，以提高避免本地极点的能力。PSO-SAVL的性能在50维度的 benchmark 函数上得到了实验验证，并且在高维度和大规模问题中也验证了可扩展性。此外，PSO-SAVL中的策略优势也得到了实验验证。在ESE基于的适应VL策略中，对相关的 гипер参数的敏感分析也进行了，并对如何选择这些 гипер参数进行了讨论。
</details></li>
</ul>
<hr>
<h2 id="Physics-informed-neural-networks-for-blood-flow-inverse-problems"><a href="#Physics-informed-neural-networks-for-blood-flow-inverse-problems" class="headerlink" title="Physics-informed neural networks for blood flow inverse problems"></a>Physics-informed neural networks for blood flow inverse problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00927">http://arxiv.org/abs/2308.00927</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yeyemedicen/pinns-wk-mri">https://github.com/yeyemedicen/pinns-wk-mri</a></li>
<li>paper_authors: Jeremias Garay, Jocelyn Dunstan, Sergio Uribe, Francisco Sahli Costabal</li>
<li>for: 解决各种不完整的系统信息和血流测量不易获得的逆问题，特别是血液动力学中精度很高的血流场测量困难。</li>
<li>methods: 使用物理学习神经网络（PINNs）方法，通过受限的血流场测量来估算系统参数和全 Velocity 场。</li>
<li>results: 使用 simulate 数据显示了稳定和准确的参数估算，而 Velocity 重建结果受测量质量和流动模式复杂度的影响。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) have emerged as a powerful tool for solving inverse problems, especially in cases where no complete information about the system is known and scatter measurements are available. This is especially useful in hemodynamics since the boundary information is often difficult to model, and high-quality blood flow measurements are generally hard to obtain. In this work, we use the PINNs methodology for estimating reduced-order model parameters and the full velocity field from scatter 2D noisy measurements in the ascending aorta. The results show stable and accurate parameter estimations when using the method with simulated data, while the velocity reconstruction shows dependence on the measurement quality and the flow pattern complexity. The method allows for solving clinical-relevant inverse problems in hemodynamics and complex coupled physical systems.
</details>
<details>
<summary>摘要</summary>
物理学 Informed neural networks (PINNs) 已经成为解决反向问题的有力工具，特别是当系统中的信息不完整或者杂谱测量数据存在时。这对血液动力学 particuilarly useful，因为边界信息往往难以模型，高质量血液流量测量很难实现。在这种情况下，我们使用 PINNs 方法来估算减少的模型参数和全部流速场从杂谱2D 雷达测量数据中。结果显示使用这种方法时，稳定且准确地估算参数，而流速重建受测量质量和流动模式复杂度的影响。这种方法可以解决临床有用的反向问题和复杂相互作用的物理系统。
</details></li>
</ul>
<hr>
<h2 id="VLUCI-Variational-Learning-of-Unobserved-Confounders-for-Counterfactual-Inference"><a href="#VLUCI-Variational-Learning-of-Unobserved-Confounders-for-Counterfactual-Inference" class="headerlink" title="VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference"></a>VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00904">http://arxiv.org/abs/2308.00904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghe Zhao, Qiang Huang, Siwei Wu, Yun Peng, Huiyan Sun</li>
<li>For: The paper focuses on the challenge of de-confounding and counterfactual prediction in observational data, particularly in the presence of unobserved confounders. It proposes a novel variational learning model of unobserved confounders for counterfactual inference (VLUCI).* Methods: VLUCI relaxes the unconfoundedness assumption often made in causal inference methods and disentangles observed and unobserved confounders. It uses a doubly variational inference model to approximate the distribution of unobserved confounders, which are used for inferring more accurate counterfactual outcomes.* Results: Extensive experiments on synthetic and semi-synthetic datasets demonstrate VLUCI’s superior performance in inferring unobserved confounders compared to state-of-the-art counterfactual inference models. VLUCI also provides confidence intervals for counterfactual outcomes, which can aid decision-making in risk-sensitive domains.Here’s the same information in Simplified Chinese:* For: 该论文关注了在观察数据中的权衡和Counterfactual预测问题，尤其是在存在隐藏的干扰因素的情况下。它提出了一种基于变量学习的隐藏干扰因素counterfactual推断模型(VLUCI)。* Methods: VLUCI弃置了常见的隐藏干扰因素假设，并将观察和隐藏干扰因素分离开来。它使用了一种双变量推断模型来估算隐藏干扰因素的 posterior distribution，并将其用于更准确地预测Counterfactual结果。* Results: 对于 synthetic和半 synthetic 数据集，VLUCI的实验结果表明，它在推断隐藏干扰因素方面表现出色，与当前的Counterfactual推断模型相比。VLUCI还提供了Counterfactual结果的置信区间，可以帮助在风险敏感领域做出决策。<details>
<summary>Abstract</summary>
Causal inference plays a vital role in diverse domains like epidemiology, healthcare, and economics. De-confounding and counterfactual prediction in observational data has emerged as a prominent concern in causal inference research. While existing models tackle observed confounders, the presence of unobserved confounders remains a significant challenge, distorting causal inference and impacting counterfactual outcome accuracy. To address this, we propose a novel variational learning model of unobserved confounders for counterfactual inference (VLUCI), which generates the posterior distribution of unobserved confounders. VLUCI relaxes the unconfoundedness assumption often overlooked by most causal inference methods. By disentangling observed and unobserved confounders, VLUCI constructs a doubly variational inference model to approximate the distribution of unobserved confounders, which are used for inferring more accurate counterfactual outcomes. Extensive experiments on synthetic and semi-synthetic datasets demonstrate VLUCI's superior performance in inferring unobserved confounders. It is compatible with state-of-the-art counterfactual inference models, significantly improving inference accuracy at both group and individual levels. Additionally, VLUCI provides confidence intervals for counterfactual outcomes, aiding decision-making in risk-sensitive domains. We further clarify the considerations when applying VLUCI to cases where unobserved confounders don't strictly conform to our model assumptions using the public IHDP dataset as an example, highlighting the practical advantages of VLUCI.
</details>
<details>
<summary>摘要</summary>
causal inference在多个领域中扮演着重要的角色，如 epidemiology、医疗和经济学。在观察数据中，去掉和预测counterfactual outcome是 causal inference研究中的一项显著挑战。而现有的模型只能处理观察到的干扰因素，不能正确地处理未观察到的干扰因素，这会扭曲 causal inference 和降低 counterfactual outcome 的准确性。为解决这个问题，我们提出了一种新的变量学习模型，即 unobserved confounders variational learning model (VLUCI)，它可以生成未观察到的干扰因素的 posterior distribution。VLUCI 采用了一种放弃了 unconfoundedness 假设的方法，从而更好地处理未观察到的干扰因素。通过分离观察到的干扰因素和未观察到的干扰因素，VLUCI 构建了一个 doubly variational inference 模型，用于近似未观察到的干扰因素的分布，并用这些分布来预测更加准确的 counterfactual outcomes。我们在 sintetic 和 semi-syntetic 数据集上进行了广泛的实验，并证明了 VLUCI 在推断未观察到的干扰因素方面的优秀表现。此外，VLUCI 与当前的 counterfactual inference 模型相容，可以在组织和个体水平上提高推断准确性。同时，VLUCI 还提供了对 counterfactual outcomes 的信任 интерVAL，帮助在风险敏感领域做出决策。我们还在公共 IHDP 数据集上进行了实践推断，并通过 illustrate 了在实际应用中的考虑因素，展示了 VLUCI 的实用优势。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Machine-Learning-Performance-with-Continuous-In-Session-Ground-Truth-Scores-Pilot-Study-on-Objective-Skeletal-Muscle-Pain-Intensity-Prediction"><a href="#Enhancing-Machine-Learning-Performance-with-Continuous-In-Session-Ground-Truth-Scores-Pilot-Study-on-Objective-Skeletal-Muscle-Pain-Intensity-Prediction" class="headerlink" title="Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction"></a>Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00886">http://arxiv.org/abs/2308.00886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boluwatife E. Faremi, Jonathon Stavres, Nuno Oliveira, Zhaoxian Zhou, Andrew H. Sung<br>for:这个研究的目的是为了开发一种可以实时、连续地评估疼痛Intensity的设备，并使用机器学习模型来对疼痛进行分类。methods:这个研究使用了两种设备来获取实时、连续的疼痛Score，并使用机器学习模型来对疼痛进行分类。这些模型包括多层感知机（MLP）和随机森林（RF）。results:研究发现，使用实时、连续的疼痛Score可以提高机器学习模型对疼痛的分类性能，比使用后期录入的疼痛Score更高。具体来说，使用实时、连续的疼痛Score可以提高模型的平均准确率达75.9%和78.3%，而使用后期录入的疼痛Score只能达70.3%和74.6%。这个研究提供了一种新的方法，可以帮助解决疼痛分类中的问题，例如真实性issue、数据不均衡和高方差。<details>
<summary>Abstract</summary>
Machine learning (ML) models trained on subjective self-report scores struggle to objectively classify pain accurately due to the significant variance between real-time pain experiences and recorded scores afterwards. This study developed two devices for acquisition of real-time, continuous in-session pain scores and gathering of ANS-modulated endodermal activity (EDA).The experiment recruited N = 24 subjects who underwent a post-exercise circulatory occlusion (PECO) with stretch, inducing discomfort. Subject data were stored in a custom pain platform, facilitating extraction of time-domain EDA features and in-session ground truth scores. Moreover, post-experiment visual analog scale (VAS) scores were collected from each subject. Machine learning models, namely Multi-layer Perceptron (MLP) and Random Forest (RF), were trained using corresponding objective EDA features combined with in-session scores and post-session scores, respectively. Over a 10-fold cross-validation, the macro-averaged geometric mean score revealed MLP and RF models trained with objective EDA features and in-session scores achieved superior performance (75.9% and 78.3%) compared to models trained with post-session scores (70.3% and 74.6%) respectively. This pioneering study demonstrates that using continuous in-session ground truth scores significantly enhances ML performance in pain intensity characterization, overcoming ground truth sparsity-related issues, data imbalance, and high variance. This study informs future objective-based ML pain system training.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）模型在主观自报分数上训练时，很难准确地分类疼痛，因为真实时间疼痛经验和记录后分数之间存在很大的变化。这项研究开发了两种设备，用于实时、连续式疼痛分数的获取和胰脏活动（EDA）的捕获。实验采用N = 24名参与者，进行了后遮挡（PECO）和压缩，引起不适。参与者数据被存储在自定义疼痛平台上，以便提取时间域EDA特征和实时真实分数。此外，每名参与者也提供了后实验Visual Analog Scale（VAS）分数。使用对应的物理层拟合（MLP）和随机森林（RF）机器学习模型，并对它们进行10个拆分验证。结果表明，MLP和RF模型通过与实时EDA特征和实时分数进行组合训练，在10个拆分验证中表现出色（75.9%和78.3%），比使用后实验VAS分数进行训练的模型（70.3%和74.6%）高得多。这项先锋性的研究表明，使用连续实时真实分数可以大幅提高ML在疼痛Intensity Characterization中的表现，超越真实分数稀缺、数据不均衡和高变化问题。这项研究对未来基于Objective的ML疼痛系统训练提供了重要信息。
</details></li>
</ul>
<hr>
<h2 id="Beneficent-Intelligence-A-Capability-Approach-to-Modeling-Benefit-Assistance-and-Associated-Moral-Failures-through-AI-Systems"><a href="#Beneficent-Intelligence-A-Capability-Approach-to-Modeling-Benefit-Assistance-and-Associated-Moral-Failures-through-AI-Systems" class="headerlink" title="Beneficent Intelligence: A Capability Approach to Modeling Benefit, Assistance, and Associated Moral Failures through AI Systems"></a>Beneficent Intelligence: A Capability Approach to Modeling Benefit, Assistance, and Associated Moral Failures through AI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00868">http://arxiv.org/abs/2308.00868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex John London, Hoda heidari</li>
<li>for: 本文使用尼钦和泽妮的能力方法 formalizes a network of ethical concepts and entitlements necessary for AI systems to confer meaningful benefit or assistance to stakeholders.</li>
<li>methods: 本文使用尼钦和泽妮的能力方法 to characterize two necessary conditions for morally permissible interactions between AI systems and those impacted by their functioning, and two sufficient conditions for realizing the ideal of meaningful benefit.</li>
<li>results: 本文证明了AI系统与利益受者之间的互动满足了两个必要条件，以及两个足够条件，以实现意义fulfillment的理想。同时，文章还描述了several salient failure modes, such as unjustified paternalism, coercion, deception, exploitation, and domination.<details>
<summary>Abstract</summary>
The prevailing discourse around AI ethics lacks the language and formalism necessary to capture the diverse ethical concerns that emerge when AI systems interact with individuals. Drawing on Sen and Nussbaum's capability approach, we present a framework formalizing a network of ethical concepts and entitlements necessary for AI systems to confer meaningful benefit or assistance to stakeholders. Such systems enhance stakeholders' ability to advance their life plans and well-being while upholding their fundamental rights. We characterize two necessary conditions for morally permissible interactions between AI systems and those impacted by their functioning, and two sufficient conditions for realizing the ideal of meaningful benefit. We then contrast this ideal with several salient failure modes, namely, forms of social interactions that constitute unjustified paternalism, coercion, deception, exploitation and domination. The proliferation of incidents involving AI in high-stakes domains underscores the gravity of these issues and the imperative to take an ethics-led approach to AI systems from their inception.
</details>
<details>
<summary>摘要</summary>
现存的AI伦理报告缺乏能够捕捉AI系统与个人之间多样化伦理问题的语言和形式主义。基于尼钦和恩素的能力方法，我们提出了一个框架，它将定义AI系统与利益所有者之间的伦理概念和权利网络，以确保AI系统对利益所有者 confer meaningful benefit或帮助。这些系统可以提高利益所有者的生活计划和 благополучия，同时尊重其基本权利。我们确定了AI系统与利益所有者之间的两个必要条件，以及实现意义ful benefit的两个 suficient condition。然后，我们对这一理想与一些常见的失败模式进行了对比，包括不公正的父权主义、压力、骗子、掠夺和支配。随着AI在高风险领域的普及，这些问题的严重性和采取伦理领导的AI系统的必要性变得更加明显。
</details></li>
</ul>
<hr>
<h2 id="PeRP-Personalized-Residual-Policies-For-Congestion-Mitigation-Through-Co-operative-Advisory-Systems"><a href="#PeRP-Personalized-Residual-Policies-For-Congestion-Mitigation-Through-Co-operative-Advisory-Systems" class="headerlink" title="PeRP: Personalized Residual Policies For Congestion Mitigation Through Co-operative Advisory Systems"></a>PeRP: Personalized Residual Policies For Congestion Mitigation Through Co-operative Advisory Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00864">http://arxiv.org/abs/2308.00864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aamir Hasan, Neeloy Chakraborty, Haonan Chen, Jung-Hoon Cho, Cathy Wu, Katherine Driggs-Campbell</li>
<li>for: 这篇论文旨在提出一个基于 Piecewise Constant (PC) 政策的合作性建议系统，以减少城市路段的拥堵。</li>
<li>methods: 本论文使用了一种基于 variational autoencoder 的不监督学习方法来推断 drivers 的内在特征，然后使用这些特征来构成一个Personalized Residual Policy (PeRP)，以提供对 drivers 的个性化建议。</li>
<li>results: 本论文的结果显示，这个方法可以成功地减少城市路段的拥堵，并且适应不同的 driver 行为，提高了平均速度的效率，相比基于eline 的方法，提高了4%到22%。<details>
<summary>Abstract</summary>
Intelligent driving systems can be used to mitigate congestion through simple actions, thus improving many socioeconomic factors such as commute time and gas costs. However, these systems assume precise control over autonomous vehicle fleets, and are hence limited in practice as they fail to account for uncertainty in human behavior. Piecewise Constant (PC) Policies address these issues by structurally modeling the likeness of human driving to reduce traffic congestion in dense scenarios to provide action advice to be followed by human drivers. However, PC policies assume that all drivers behave similarly. To this end, we develop a co-operative advisory system based on PC policies with a novel driver trait conditioned Personalized Residual Policy, PeRP. PeRP advises drivers to behave in ways that mitigate traffic congestion. We first infer the driver's intrinsic traits on how they follow instructions in an unsupervised manner with a variational autoencoder. Then, a policy conditioned on the inferred trait adapts the action of the PC policy to provide the driver with a personalized recommendation. Our system is trained in simulation with novel driver modeling of instruction adherence. We show that our approach successfully mitigates congestion while adapting to different driver behaviors, with 4 to 22% improvement in average speed over baselines.
</details>
<details>
<summary>摘要</summary>
智能驾驶系统可以减轻交通压力，提高多种社会经济因素，如通勤时间和油耗成本。然而，这些系统假设自动驾驶车辆队伍的精准控制，因此在实践中有限制，因为它们不能考虑人类行为的不确定性。 Piecewise Constant（PC）政策可以解决这些问题，通过结构化模型人类驾驶行为，以减少笔记压力，提供行为建议，使人类 drivers 遵循。然而，PC 政策假设所有 drivers 都会类似行为。为此，我们开发了一种合作建议系统，基于 PC 政策，并使用一种 novel 的 Driver Trait 受控 Personalized Residual Policy（PeRP）。PeRP 建议 drivers 采取降低交通压力的行为。我们首先通过不监督的方式，使用变量自动编码器，推断 driver 的内在特征，然后，根据推断的特征，condition 政策，以提供个性化建议。我们的系统在模拟环境中训练，并使用新型的 driver 模型来评估 adherence 指标。我们的方法成功地减轻交通压力，适应不同的 driver 行为，相比基准值，提高了4%-22%的平均速度。
</details></li>
</ul>
<hr>
<h2 id="Active-Inference-in-String-Diagrams-A-Categorical-Account-of-Predictive-Processing-and-Free-Energy"><a href="#Active-Inference-in-String-Diagrams-A-Categorical-Account-of-Predictive-Processing-and-Free-Energy" class="headerlink" title="Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy"></a>Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00861">http://arxiv.org/abs/2308.00861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sean Tull, Johannes Kleiner, Toby St Clere Smithe</li>
<li>for: 提供一种Category的表述方法，用于表示Predictive Processing和Active Inference的认知框架。</li>
<li>methods: 使用字符串 диаграмм表示Generative Model、Bayesian更新、感知、规划、活动推理和自由能量。</li>
<li>results: 提出一种Diagrammatic derivation of the formula for active inference via free energy minimization，并证明自由能量可以在任何 Agent 的生成模型中应用。<details>
<summary>Abstract</summary>
We present a categorical formulation of the cognitive frameworks of Predictive Processing and Active Inference, expressed in terms of string diagrams interpreted in a monoidal category with copying and discarding. This includes diagrammatic accounts of generative models, Bayesian updating, perception, planning, active inference, and free energy. In particular we present a diagrammatic derivation of the formula for active inference via free energy minimisation, and establish a compositionality property for free energy, allowing free energy to be applied at all levels of an agent's generative model. Aside from aiming to provide a helpful graphical language for those familiar with active inference, we conversely hope that this article may provide a concise formulation and introduction to the framework.
</details>
<details>
<summary>摘要</summary>
我们提出了一种分类的框架表述，表示预测处理和活跃推理的 cognitive 框架，用 string diagram 在一个单簇类别中表示，这包括生成模型、贝叶斯更新、感知、规划、活跃推理和自由能。特别是，我们提供了一个 diagrammatic 的更新方法，以及证明了 free energy 的合理性和可composability，允许 free energy 在生成模型中的所有层级上适用。除了将 active inference 表示为一个帮助 grafical 语言，我们希望这篇文章能够提供一个简洁的框架表述，并且对于 familiar 的人来说，提供一个帮助他们更好地理解这个框架。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Activation-Patterns-in-Artificial-Neural-Networks-by-Exploring-Stochastic-Processes"><a href="#Understanding-Activation-Patterns-in-Artificial-Neural-Networks-by-Exploring-Stochastic-Processes" class="headerlink" title="Understanding Activation Patterns in Artificial Neural Networks by Exploring Stochastic Processes"></a>Understanding Activation Patterns in Artificial Neural Networks by Exploring Stochastic Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00858">http://arxiv.org/abs/2308.00858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephan Johann Lehmler, Muhammad Saif-ur-Rehman, Tobias Glasmachers, Ioannis Iossifidis</li>
<li>for: 这个论文的目的是用数学抽象和模型来 deeper understanding of (deep) artificial neural networks 的行为和学习动力。</li>
<li>methods: 这篇论文提出了使用 Stochastic Processes 框架，模型（深度）人工神经网络的活动模式。文中使用 neuroscience 技术来检测和分析神经网络中的活动模式。</li>
<li>results: 研究人员通过对不同的人工神经网络图像识别任务数据进行分析，发现了不同的网络架构和训练集的活动模式之间的一致性。通过计算 Mean Firing Rate、Mean Fano Factor 和 Variances，研究人员发现了在学习过程中的记忆化现象，提供了有价值的学习行为的理解。<details>
<summary>Abstract</summary>
To gain a deeper understanding of the behavior and learning dynamics of (deep) artificial neural networks, it is valuable to employ mathematical abstractions and models. These tools provide a simplified perspective on network performance and facilitate systematic investigations through simulations. In this paper, we propose utilizing the framework of stochastic processes, which has been underutilized thus far.   Our approach models activation patterns of thresholded nodes in (deep) artificial neural networks as stochastic processes. We focus solely on activation frequency, leveraging neuroscience techniques used for real neuron spike trains. During a classification task, we extract spiking activity and use an arrival process following the Poisson distribution.   We examine observed data from various artificial neural networks in image recognition tasks, fitting the proposed model's assumptions. Through this, we derive parameters describing activation patterns in each network. Our analysis covers randomly initialized, generalizing, and memorizing networks, revealing consistent differences across architectures and training sets.   Calculating Mean Firing Rate, Mean Fano Factor, and Variances, we find stable indicators of memorization during learning, providing valuable insights into network behavior. The proposed model shows promise in describing activation patterns and could serve as a general framework for future investigations. It has potential applications in theoretical simulations, pruning, and transfer learning.
</details>
<details>
<summary>摘要</summary>
使用数学抽象和模型来深入理解人工神经网络的行为和学习 dinamics可以提供有价值的信息。在这篇论文中，我们提议使用Stochastic Processes框架，这种框架在人工神经网络领域一直未得到过足够的利用。我们的方法是将人工神经网络中的激活节点的激活模式模型为Stochastic Processes，并且仅ocus on激活频率，基于 neuroscience 技术来处理真正的神经元发射 Train。在进行图像识别任务时，我们提取了激活活动，并使用Poisson分布来描述到达过程。我们对各种人工神经网络的图像识别任务数据进行了分析，并适应了我们的模型假设。我们的分析覆盖了随机初始化、通用和记忆网络，并发现这些网络在不同的架构和训练集上存在一致的差异。通过计算Mean Firing Rate、Mean Fano Factor和Variances，我们发现在学习过程中记忆化的指标，这些指标提供了人工神经网络的行为中的有价值信息。我们的模型表现良好，并有可能在理论 simulations、树脂和传输学习等领域得到应用。
</details></li>
</ul>
<hr>
<h2 id="Training-on-Foveated-Images-Improves-Robustness-to-Adversarial-Attacks"><a href="#Training-on-Foveated-Images-Improves-Robustness-to-Adversarial-Attacks" class="headerlink" title="Training on Foveated Images Improves Robustness to Adversarial Attacks"></a>Training on Foveated Images Improves Robustness to Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00854">http://arxiv.org/abs/2308.00854</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad A. Shah, Bhiksha Raj</li>
<li>for: 本研究旨在探讨人类视觉系统的一种重要特征：在周围视场中常见低精度视觉刺激对视觉模型的Robustness有什么影响。</li>
<li>methods: 我们开发了一种名为\RBlur的图像变换，用于模拟周围视场中视觉刺激的失真。这种变换基于给定注意点的距离来减少图像的清晰度和颜色温度。</li>
<li>results: 与原始图像进行训练的DNNs比起，使用\RBlur变换训练的DNNs在受到攻击和非攻击干扰后的数据上的准确率提高了15%至25%。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks -- subtle, perceptually indistinguishable perturbations of inputs that change the response of the model. In the context of vision, we hypothesize that an important contributor to the robustness of human visual perception is constant exposure to low-fidelity visual stimuli in our peripheral vision. To investigate this hypothesis, we develop \RBlur, an image transform that simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point. We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\% higher accuracy on perturbed data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Designing-a-Communication-Bridge-between-Communities-Participatory-Design-for-a-Question-Answering-AI-Agent"><a href="#Designing-a-Communication-Bridge-between-Communities-Participatory-Design-for-a-Question-Answering-AI-Agent" class="headerlink" title="Designing a Communication Bridge between Communities: Participatory Design for a Question-Answering AI Agent"></a>Designing a Communication Bridge between Communities: Participatory Design for a Question-Answering AI Agent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00813">http://arxiv.org/abs/2308.00813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeonghyun Lee, Vrinda Nandan, Harshvardhan Sikka, Spencer Rugaber, Ashok Goal</li>
<li>For: The paper aims to design an AI system that acts as a communication bridge between two user communities with different mental models and vocabularies.* Methods: The authors used a variation of participatory design to elicit requirements for developing a question-answering agent that explains how Skillsync works and acts as a communication bridge between company and college users.* Results: The study found that participatory design was useful in guiding the requirements gathering and eliciting user questions for the development of AskJill, and the two Skillsync user communities perceived glossary assistance as a key feature that AskJill needs to offer.Here are the three points in Simplified Chinese text:* For: 这篇论文的目的是设计一个能够 acted as a communication bridge between two个用户群体的 AI 系统，这两个用户群体具有不同的认知模型和术语。* Methods: 作者使用了一种变体的参与式设计方法来激发 Skillsync 的开发需求，以帮助它成为公司和学院用户之间的沟通桥梁。* Results: 研究发现，参与式设计是有用的，可以引导收集需求和提取用户问题，以便为 AskJill 的开发而设计。此外，两个 Skillsync 用户群体认为术语帮助是 AskJill 必备的功能之一，他们将从这种共同词汇中受益。<details>
<summary>Abstract</summary>
How do we design an AI system that is intended to act as a communication bridge between two user communities with different mental models and vocabularies? Skillsync is an interactive environment that engages employers (companies) and training providers (colleges) in a sustained dialogue to help them achieve the goal of building a training proposal that successfully meets the needs of the employers and employees. We used a variation of participatory design to elicit requirements for developing AskJill, a question-answering agent that explains how Skillsync works and thus acts as a communication bridge between company and college users. Our study finds that participatory design was useful in guiding the requirements gathering and eliciting user questions for the development of AskJill. Our results also suggest that the two Skillsync user communities perceived glossary assistance as a key feature that AskJill needs to offer, and they would benefit from such a shared vocabulary.
</details>
<details>
<summary>摘要</summary>
如何设计一个人工智能系统，让它作为两个用户社区之间的沟通桥梁？我们使用了一种参与设计的变体，与雇主（公司）和训练提供者（学院）进行持续的对话，以帮助他们建立一个成功地满足雇主和员工需求的训练提案。我们的研究发现，参与设计是有用的，可以引导需求收集和发现用户问题，以便为AskJill的开发而设计。我们的结果还显示，两个Skillsync用户社区认为词汇帮助是应有的功能，并且它们从中获益。
</details></li>
</ul>
<hr>
<h2 id="AnyLoc-Towards-Universal-Visual-Place-Recognition"><a href="#AnyLoc-Towards-Universal-Visual-Place-Recognition" class="headerlink" title="AnyLoc: Towards Universal Visual Place Recognition"></a>AnyLoc: Towards Universal Visual Place Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00688">http://arxiv.org/abs/2308.00688</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AnyLoc/AnyLoc">https://github.com/AnyLoc/AnyLoc</a></li>
<li>paper_authors: Nikhil Keetha, Avneesh Mishra, Jay Karhade, Krishna Murthy Jatavallabhula, Sebastian Scherer, Madhava Krishna, Sourav Garg</li>
<li>for: 本研究旨在开发一种可靠的视觉地理位置认知（VPR）方法，能够在各种不同环境中（都市、室内、户外、航空、水下和地底环境）进行高精度的位置定位。</li>
<li>methods: 本研究使用了自然语言处理（NLP）和计算机视觉（CV）技术，特别是使用了自适应网络和自动Feature learning来学习通用的特征表示。</li>
<li>results: 研究结果显示，使用这些通用的特征表示和无监督特征聚合技术，可以实现4倍的性能提升，并且通过semantic特征分析得到6%的性能提升。<details>
<summary>Abstract</summary>
Visual Place Recognition (VPR) is vital for robot localization. To date, the most performant VPR approaches are environment- and task-specific: while they exhibit strong performance in structured environments (predominantly urban driving), their performance degrades severely in unstructured environments, rendering most approaches brittle to robust real-world deployment. In this work, we develop a universal solution to VPR -- a technique that works across a broad range of structured and unstructured environments (urban, outdoors, indoors, aerial, underwater, and subterranean environments) without any re-training or fine-tuning. We demonstrate that general-purpose feature representations derived from off-the-shelf self-supervised models with no VPR-specific training are the right substrate upon which to build such a universal VPR solution. Combining these derived features with unsupervised feature aggregation enables our suite of methods, AnyLoc, to achieve up to 4X significantly higher performance than existing approaches. We further obtain a 6% improvement in performance by characterizing the semantic properties of these features, uncovering unique domains which encapsulate datasets from similar environments. Our detailed experiments and analysis lay a foundation for building VPR solutions that may be deployed anywhere, anytime, and across anyview. We encourage the readers to explore our project page and interactive demos: https://anyloc.github.io/.
</details>
<details>
<summary>摘要</summary>
“视觉地点识别（VPR）是机器人地理位置定位的关键。至今为止，最高效的VPR方法都是环境和任务特定的：它们在结构化环境（主要是城市驾驶）中显示出强大的表现，但在无结构化环境中表现很差，导致大多数方法在实际世界中不稳定。在这项工作中，我们开发了一种通用的VPR解决方案——一种能够在各种结构化和无结构化环境中工作（城市、户外、室内、航空、水下和地下环境），无需更新或微调。我们示示了通用特征表示的概念，基于市场上的自我超级vised模型，无需VPR特定的训练，可以构建这种通用VPR解决方案。通过对这些特征进行无监督的feature集成，我们的AnyLoc方法可以实现与现有方法相比4倍更高的性能。此外，我们还发现了这些特征的 semantic properties，揭示了这些特征的唯一领域，从而提高了性能6%。我们的详细实验和分析为建立VPR解决方案提供了基础，让读者可以通过我们的项目页面和互动示例了解更多信息：https://anyloc.github.io/。”
</details></li>
</ul>
<hr>
<h2 id="A-Knowledge-Oriented-Approach-to-Enhance-Integration-and-Communicability-in-the-Polkadot-Ecosystem"><a href="#A-Knowledge-Oriented-Approach-to-Enhance-Integration-and-Communicability-in-the-Polkadot-Ecosystem" class="headerlink" title="A Knowledge-Oriented Approach to Enhance Integration and Communicability in the Polkadot Ecosystem"></a>A Knowledge-Oriented Approach to Enhance Integration and Communicability in the Polkadot Ecosystem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00735">http://arxiv.org/abs/2308.00735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcio Ferreira Moreno, Rafael Rossi de Mello Brandão</li>
<li>for: 本研究旨在提供一个概念框架，以探讨和解决Polkadot生态系统中数据分析和通信问题。</li>
<li>methods: 本研究使用了域 ontology（POnto），实现了Polkadot生态系统中概念和关系的结构表示，从而提高了生态系统的 интеграbles和通信能力。</li>
<li>results: 本研究通过专家反馈和Polkadot社区的意见， validate了提案的概念框架，并提供了一个基于Controlled Natural Language的查询引擎路线图，实现了生态系统的扩展和推广。<details>
<summary>Abstract</summary>
The Polkadot ecosystem is a disruptive and highly complex multi-chain architecture that poses challenges in terms of data analysis and communicability. Currently, there is a lack of standardized and holistic approaches to retrieve and analyze data across parachains and applications, making it difficult for general users and developers to access ecosystem data consistently. This paper proposes a conceptual framework that includes a domain ontology called POnto (a Polkadot Ontology) to address these challenges. POnto provides a structured representation of the ecosystem's concepts and relationships, enabling a formal understanding of the platform. The proposed knowledge-oriented approach enhances integration and communicability, enabling a wider range of users to participate in the ecosystem and facilitating the development of AI-based applications. The paper presents a case study methodology to validate the proposed framework, which includes expert feedback and insights from the Polkadot community. The POnto ontology and the roadmap for a query engine based on a Controlled Natural Language using the ontology, provide valuable contributions to the growth and adoption of the Polkadot ecosystem in heterogeneous socio-technical environments.
</details>
<details>
<summary>摘要</summary>
派拉达网络生态系统是一种破坏性和高度复杂的多链架构，它在数据分析和通信方面带来了挑战。目前，有很多不同的渠道和应用程序之间的数据检索和分析几乎没有标准化和整体的方法，这使得普通用户和开发者难以一览ecosystem数据。这篇论文提出了一个概念框架，包括一个叫做POnto（派拉达 Ontology）的领域 ontology，以解决这些挑战。POnto提供了一种结构化的表示方式，帮助建立派拉达平台的正规理解。该提议的知识导向方法提高了集成和通信，使得更广泛的用户参与到ecosystem中，并促进了基于人工智能应用的开发。论文采用了一种实证方法，包括专家反馈和派拉达社区的意见，以验证提议的可行性。POnto ontology和基于控制自然语言的查询引擎路线图，为派拉达生态系统在不同的社会技术环境中的发展和推广做出了重要贡献。
</details></li>
</ul>
<hr>
<h2 id="Applicability-of-scaling-laws-to-vision-encoding-models"><a href="#Applicability-of-scaling-laws-to-vision-encoding-models" class="headerlink" title="Applicability of scaling laws to vision encoding models"></a>Applicability of scaling laws to vision encoding models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00678">http://arxiv.org/abs/2308.00678</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suyamat/ScalingVisionEncoder">https://github.com/suyamat/ScalingVisionEncoder</a></li>
<li>paper_authors: Takuya Matsuyama, Kota S Sasaki, Shinji Nishimoto</li>
<li>for: 这个论文的目的是如何建立一个高性能的视觉编码模型，以预测观看图像时的脑活动，作为Algonauts Project 2023 Challenge 的一部分。</li>
<li>methods: 这个论文使用了多种视觉模型，其参数大小从86M到4.3B不等，以建立预测模型。研究者主要关注两个方面：（1）如何通过训练集大小的变化来改善预测精度？（2）如何通过视觉模型参数大小的变化来改善预测精度？</li>
<li>results: 研究结果表明，随着训练集大小的增加，预测精度随着增加的 scaling law 改善。同时，我们发现，随着视觉模型参数大小的增加，预测精度也随着增加的 scaling law 改善。这些结果表明，增加训练集大小和视觉模型参数大小可能会导致更加准确的视觉模型，并且可能会促进视觉科学的发展。<details>
<summary>Abstract</summary>
In this paper, we investigated how to build a high-performance vision encoding model to predict brain activity as part of our participation in the Algonauts Project 2023 Challenge. The challenge provided brain activity recorded by functional MRI (fMRI) while participants viewed images. Several vision models with parameter sizes ranging from 86M to 4.3B were used to build predictive models. To build highly accurate models, we focused our analysis on two main aspects: (1) How does the sample size of the fMRI training set change the prediction accuracy? (2) How does the prediction accuracy across the visual cortex vary with the parameter size of the vision models? The results show that as the sample size used during training increases, the prediction accuracy improves according to the scaling law. Similarly, we found that as the parameter size of the vision models increases, the prediction accuracy improves according to the scaling law. These results suggest that increasing the sample size of the fMRI training set and the parameter size of visual models may contribute to more accurate visual models of the brain and lead to a better understanding of visual neuroscience.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们调查了如何建立高性能视觉编码模型，以便预测大脑活动，这是我们参加了2023年Algonauts项目挑战的一部分。挑战提供了参与者通过功能成像（fMRI）技术记录的大脑活动。我们使用了多种视觉模型，其参数大小从86M到4.3B不同，建立预测模型。为建立高精度模型，我们对两个主要方面进行了分析：（1）如何随训练集大脑活动样本数量的变化，影响预测精度？（2）随视觉模型参数大小的变化，在视觉区域中预测精度如何变化？结果表明，随着训练集大脑活动样本数量的增加，预测精度按照尺度法则提高。同时，我们发现，随着视觉模型参数大小的增加，预测精度按照尺度法则提高。这些结果表明，增加训练集大脑活动样本数量和视觉模型参数大小可能会导致更高精度的视觉模型，并促进视觉 neuroscience的研究。
</details></li>
</ul>
<hr>
<h2 id="Tool-Documentation-Enables-Zero-Shot-Tool-Usage-with-Large-Language-Models"><a href="#Tool-Documentation-Enables-Zero-Shot-Tool-Usage-with-Large-Language-Models" class="headerlink" title="Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models"></a>Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00675">http://arxiv.org/abs/2308.00675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng-Yu Hsieh, Si-An Chen, Chun-Liang Li, Yasuhisa Fujii, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister</li>
<li>for: 本研究旨在替代示例，提供工具文档来帮助大语言模型学习新工具。</li>
<li>methods: 本研究使用了工具文档，而不是示例，来训练大语言模型。</li>
<li>results: 研究发现，使用工具文档可以达到与少量示例相同的性能，并且在实际工具使用场景中表现更加出色。<details>
<summary>Abstract</summary>
Today, large language models (LLMs) are taught to use new tools by providing a few demonstrations of the tool's usage. Unfortunately, demonstrations are hard to acquire, and can result in undesirable biased usage if the wrong demonstration is chosen. Even in the rare scenario that demonstrations are readily available, there is no principled selection protocol to determine how many and which ones to provide. As tasks grow more complex, the selection search grows combinatorially and invariably becomes intractable. Our work provides an alternative to demonstrations: tool documentation. We advocate the use of tool documentation, descriptions for the individual tool usage, over demonstrations. We substantiate our claim through three main empirical findings on 6 tasks across both vision and language modalities. First, on existing benchmarks, zero-shot prompts with only tool documentation are sufficient for eliciting proper tool usage, achieving performance on par with few-shot prompts. Second, on a newly collected realistic tool-use dataset with hundreds of available tool APIs, we show that tool documentation is significantly more valuable than demonstrations, with zero-shot documentation significantly outperforming few-shot without documentation. Third, we highlight the benefits of tool documentations by tackling image generation and video tracking using just-released unseen state-of-the-art models as tools. Finally, we highlight the possibility of using tool documentation to automatically enable new applications: by using nothing more than the documentation of GroundingDino, Stable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the just-released Grounded-SAM and Track Anything models.
</details>
<details>
<summary>摘要</summary>
Note: The text has been translated into Simplified Chinese, which is the standard writing system used in mainland China.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/02/cs.AI_2023_08_02/" data-id="clogy1z0n001vffra6x0ed7m2" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/02/cs.CL_2023_08_02/" class="article-date">
  <time datetime="2023-08-02T11:00:00.000Z" itemprop="datePublished">2023-08-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/02/cs.CL_2023_08_02/">cs.CL - 2023-08-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Careful-Whisper-–-leveraging-advances-in-automatic-speech-recognition-for-robust-and-interpretable-aphasia-subtype-classification"><a href="#Careful-Whisper-–-leveraging-advances-in-automatic-speech-recognition-for-robust-and-interpretable-aphasia-subtype-classification" class="headerlink" title="Careful Whisper – leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification"></a>Careful Whisper – leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01327">http://arxiv.org/abs/2308.01327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laurin Wagner, Mario Zusag, Theresa Bloder</li>
<li>for: 本研究旨在提供一种自动化方法，用于从语音录音中识别语音异常，以帮助评估语音障碍。</li>
<li>methods: 该方法结合了 Connectionist Temporal Classification (CTC) 和 encoder-decoder 型自动语音识别模型，通过生成丰富的语音特征和清晰的转录，并应用了一些自然语言处理技术来提取特征，生成健康语音的原型。</li>
<li>results: 该方法可以很准确地分类 recording 中的人群，并且可以准确地分类最常见的语音障碍类型。<details>
<summary>Abstract</summary>
This paper presents a fully automated approach for identifying speech anomalies from voice recordings to aid in the assessment of speech impairments. By combining Connectionist Temporal Classification (CTC) and encoder-decoder-based automatic speech recognition models, we generate rich acoustic and clean transcripts. We then apply several natural language processing methods to extract features from these transcripts to produce prototypes of healthy speech. Basic distance measures from these prototypes serve as input features for standard machine learning classifiers, yielding human-level accuracy for the distinction between recordings of people with aphasia and a healthy control group. Furthermore, the most frequently occurring aphasia types can be distinguished with 90% accuracy. The pipeline is directly applicable to other diseases and languages, showing promise for robustly extracting diagnostic speech biomarkers.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Grounded-Image-Text-Matching-with-Mismatched-Relation-Reasoning"><a href="#Grounded-Image-Text-Matching-with-Mismatched-Relation-Reasoning" class="headerlink" title="Grounded Image Text Matching with Mismatched Relation Reasoning"></a>Grounded Image Text Matching with Mismatched Relation Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01236">http://arxiv.org/abs/2308.01236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Wu, Yana Wei, Haozhe Wang, Yongfei Liu, Sibei Yang, Xuming He</li>
<li>for: 本 paper 引入了 Grounded Image Text Matching with Mismatched Relation (GITM-MR)，一个新的视觉语言联合任务，用于评估基于 transformer 预训练模型的关系理解能力。</li>
<li>methods: GITM-MR 任务需要模型首先确定一个表达是否描述了一幅图片，然后Localize 提及的对象或者将文本中的匹配错误部分与图片相匹配。我们提供了一个评估预训练模型的标准准则，专注于有限数据和非标准句子长度的情况。</li>
<li>results: 我们的评估结果显示，预训练模型在有限数据和非标准句子长度情况下缺乏数据效率和长度泛化能力。为此，我们提出了 Relation-sensitive Correspondence Reasoning Network (RCRN)，该模型通过irectional 信息传递和语言结构引导的bi-directional message propagation来提高关系意识和推理能力，并能够在长度泛化和数据效率两个领域中具有出色的表现。<details>
<summary>Abstract</summary>
This paper introduces Grounded Image Text Matching with Mismatched Relation (GITM-MR), a novel visual-linguistic joint task that evaluates the relation understanding capabilities of transformer-based pre-trained models. GITM-MR requires a model to first determine if an expression describes an image, then localize referred objects or ground the mismatched parts of the text. We provide a benchmark for evaluating pre-trained models on this task, with a focus on the challenging settings of limited data and out-of-distribution sentence lengths. Our evaluation demonstrates that pre-trained models lack data efficiency and length generalization ability. To address this, we propose the Relation-sensitive Correspondence Reasoning Network (RCRN), which incorporates relation-aware reasoning via bi-directional message propagation guided by language structure. RCRN can be interpreted as a modular program and delivers strong performance in both length generalization and data efficiency.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:这篇论文介绍了一个新任务，即基于图像和文本的链接匹配任务（GITM-MR），该任务评估基于转换器预训练模型的关系理解能力。该任务需要模型先确定文本描述图像，然后在图像中找到引用的对象或将文本中匹配不正确的部分与图像相匹配。作者们提供了一个评估基准，以评估预训练模型在这个任务中的表现，特别是在有限数据和非常长文本长度下。评估结果显示，预训练模型在数据有限和文本长度不正常的情况下缺乏数据效率和长度泛化能力。为解决这个问题，作者们提出了关系感知相关理解网络（RCRN），该网络通过双向消息传递和语言结构引导的关系感知来提高模型的数据效率和长度泛化能力。RCRN可以被视为一个模块化程序，并在长度泛化和数据效率两个方面达到了优秀的表现。
</details></li>
</ul>
<hr>
<h2 id="Global-Hierarchical-Neural-Networks-using-Hierarchical-Softmax"><a href="#Global-Hierarchical-Neural-Networks-using-Hierarchical-Softmax" class="headerlink" title="Global Hierarchical Neural Networks using Hierarchical Softmax"></a>Global Hierarchical Neural Networks using Hierarchical Softmax</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01210">http://arxiv.org/abs/2308.01210</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jschuurmans/hsoftmax">https://github.com/jschuurmans/hsoftmax</a></li>
<li>paper_authors: Jetze Schuurmans, Flavius Frasincar</li>
<li>for: 这篇论文提出了一个基于垂直软max的全球层次分类框架，这种方法适用于任何分类任务中存在自然的阶层结构。</li>
<li>methods: 这篇论文使用了垂直软max创建全球层次分类器，并在四个文本分类 datasets 上进行了实验。</li>
<li>results: 在四个 datasets 中，垂直软max 都提高了与平均软max 相比的macro-F1和macro- recall，并在三个 datasets 中 дости得了更高的微精度和macro精度。<details>
<summary>Abstract</summary>
This paper presents a framework in which hierarchical softmax is used to create a global hierarchical classifier. The approach is applicable for any classification task where there is a natural hierarchy among classes. We show empirical results on four text classification datasets. In all datasets the hierarchical softmax improved on the regular softmax used in a flat classifier in terms of macro-F1 and macro-recall. In three out of four datasets hierarchical softmax achieved a higher micro-accuracy and macro-precision.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ADS-Cap-A-Framework-for-Accurate-and-Diverse-Stylized-Captioning-with-Unpaired-Stylistic-Corpora"><a href="#ADS-Cap-A-Framework-for-Accurate-and-Diverse-Stylized-Captioning-with-Unpaired-Stylistic-Corpora" class="headerlink" title="ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora"></a>ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01143">http://arxiv.org/abs/2308.01143</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/njucckevin/ads-cap">https://github.com/njucckevin/ads-cap</a></li>
<li>paper_authors: Kanzhi Cheng, Zheng Ma, Shi Zong, Jianbing Zhang, Xinyu Dai, Jiajun Chen</li>
<li>for: 这 paper 的目的是提出一种 novel framework 来生成具有准确性和多样性的风格化描述（ADS-Cap）。</li>
<li>methods: 这 paper 使用了对匹配学习模块来对图像和文本特征进行对接，并使用了 conditional variational auto-encoder 来自动记忆多样化的风格特征在隐藏空间中。它还设计了一个简单 yet effective 的检查模块来提高风格准确性。</li>
<li>results: 对两个广泛使用的风格化图像描述数据集进行实验，ADS-Cap 在保持图像一致性、风格准确性和多样性三者之间的折衔上达到了出色的表现。<details>
<summary>Abstract</summary>
Generating visually grounded image captions with specific linguistic styles using unpaired stylistic corpora is a challenging task, especially since we expect stylized captions with a wide variety of stylistic patterns. In this paper, we propose a novel framework to generate Accurate and Diverse Stylized Captions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module to align the image and text features, which unifies paired factual and unpaired stylistic corpora during the training process. A conditional variational auto-encoder is then used to automatically memorize diverse stylistic patterns in latent space and enhance diversity through sampling. We also design a simple but effective recheck module to boost style accuracy by filtering style-specific captions. Experimental results on two widely used stylized image captioning datasets show that regarding consistency with the image, style accuracy and diversity, ADS-Cap achieves outstanding performances compared to various baselines. We finally conduct extensive analyses to understand the effectiveness of our method. Our code is available at https://github.com/njucckevin/ADS-Cap.
</details>
<details>
<summary>摘要</summary>
生成具有具体语言风格特征的图像描述文本是一项复杂的任务，尤其是需要具有各种风格特征的描述文本。在这篇论文中，我们提出了一种新的框架，即准确多样化风格描述（ADS-Cap）。我们的 ADS-Cap 首先使用对比学习模块将图像和文本特征进行对应，在训练过程中统一 paired  фактических和无对应风格 Corpora。然后，我们使用conditional variational autoencoder来自动记忆在latent space中的多样化风格特征，并通过抽样提高多样性。我们还设计了一个简单 yet effective的重新检查模块，以提高风格准确性。我们的实验结果表明， compared to various baselines, ADS-Cap 在图像和风格准确性方面达到了出色的表现。我们 finally conducted extensive analyses to understand the effectiveness of our method.我们的代码可以在 https://github.com/njucckevin/ADS-Cap 上获取。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Generic-Enhancing-Image-Captioning-with-Real-World-Knowledge-using-Vision-Language-Pre-Training-Model"><a href="#Beyond-Generic-Enhancing-Image-Captioning-with-Real-World-Knowledge-using-Vision-Language-Pre-Training-Model" class="headerlink" title="Beyond Generic: Enhancing Image Captioning with Real-World Knowledge using Vision-Language Pre-Training Model"></a>Beyond Generic: Enhancing Image Captioning with Real-World Knowledge using Vision-Language Pre-Training Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01126">http://arxiv.org/abs/2308.01126</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/njucckevin/knowcap">https://github.com/njucckevin/knowcap</a></li>
<li>paper_authors: Kanzhi Cheng, Wenpo Song, Zheng Ma, Wenhao Zhu, Zixuan Zhu, Jianbing Zhang</li>
<li>for: This paper aims to improve the ability of current captioning approaches to generate descriptions that incorporate real-world knowledge, such as named entities and contextual information.</li>
<li>methods: The proposed method, called Knowledge-guided Replay (K-Replay), consists of two parts: a knowledge prediction task on automatically collected replay exemplars to continuously awaken the VLP model’s memory about knowledge, and a knowledge distillation constraint to improve the faithfulness of generated descriptions.</li>
<li>results: The approach effectively incorporates knowledge into descriptions, outperforming a strong VLP baseline by 20.9 points (78.7-&gt;99.6) in CIDEr score and 20.5 percentage points (34.0%-&gt;54.5%) in knowledge recognition accuracy.Here is the information in Simplified Chinese text:</li>
<li>for: 本研究旨在提高当前captioning方法可以 incorporate 实际世界知识，如名词和上下文信息。</li>
<li>methods: 提议的方法是 Knowledge-guided Replay (K-Replay)，包括两部分：一个知识预测任务，使得 VLP 模型对知识的记忆不断被触发，以避免模型填充通用模式; 以及一个知识储存约束，以改善生成的描述的准确性，从而缓解知识幻觉。</li>
<li>results: 方法能够有效地将知识 incorporated 到描述中，比对 STRONG VLP 基eline 高20.9分 (78.7-&gt;99.6) 的 CIDEr 得分，以及20.5% (34.0%-&gt;54.5%) 的知识认知精度。<details>
<summary>Abstract</summary>
Current captioning approaches tend to generate correct but "generic" descriptions that lack real-world knowledge, e.g., named entities and contextual information. Considering that Vision-Language Pre-Training (VLP) models master massive such knowledge from large-scale web-harvested data, it is promising to utilize the generalizability of VLP models to incorporate knowledge into image descriptions. However, using VLP models faces challenges: zero-shot inference suffers from knowledge hallucination that leads to low-quality descriptions, but the generic bias in downstream task fine-tuning hinders the VLP model from expressing knowledge. To address these concerns, we propose a simple yet effective method called Knowledge-guided Replay (K-Replay), which enables the retention of pre-training knowledge during fine-tuning. Our approach consists of two parts: (1) a knowledge prediction task on automatically collected replay exemplars to continuously awaken the VLP model's memory about knowledge, thus preventing the model from collapsing into the generic pattern; (2) a knowledge distillation constraint to improve the faithfulness of generated descriptions hence alleviating the knowledge hallucination. To evaluate knowledge-enhanced descriptions, we construct a novel captioning benchmark KnowCap, containing knowledge of landmarks, famous brands, special foods and movie characters. Experimental results show that our approach effectively incorporates knowledge into descriptions, outperforming strong VLP baseline by 20.9 points (78.7->99.6) in CIDEr score and 20.5 percentage points (34.0%->54.5%) in knowledge recognition accuracy. Our code and data is available at https://github.com/njucckevin/KnowCap.
</details>
<details>
<summary>摘要</summary>
当前的标题生成方法通常会生成正确的 pero "通用" 的描述，缺乏实际世界知识，例如名词和上下文信息。考虑到视力语言预训练（VLP）模型从大规模的网络采集数据中积累了庞大的知识，因此可以利用 VLP 模型的通用性来插入知识到图像描述中。然而，使用 VLP 模型存在挑战：零 shot 推理会导致知识幻觉，从而导致低质量的描述，而下游任务精通化也会阻碍 VLP 模型表达知识。为了解决这些问题，我们提出了一种简单 yet 有效的方法，即知识引导重播（K-Replay），它可以在精通化过程中保持 VLP 模型的预训练知识。我们的方法包括两个部分：1. 使用自动收集的回退 exemplars 进行知识预测任务，以continuously awaken VLP 模型的记忆，防止模型落入通用模式；2. 使用知识继承约束，以提高生成的描述的准确性，从而缓解知识幻觉。为了评估描述中的知识，我们建立了一个新的描述 benchmark 知Cap，包含了地标、名牌产品、特色美食和电影人物的知识。实验结果显示，我们的方法可以有效地插入知识到描述中，高于强 VLP 基线 by 20.9 个 CIDEr 分数（78.7->99.6）和 20.5 个 percentage points（34.0%->54.5%）的知识认可率。我们的代码和数据可以在 <https://github.com/njucckevin/KnowCap> 上获取。
</details></li>
</ul>
<hr>
<h2 id="MultiEM-Efficient-and-Effective-Unsupervised-Multi-Table-Entity-Matching"><a href="#MultiEM-Efficient-and-Effective-Unsupervised-Multi-Table-Entity-Matching" class="headerlink" title="MultiEM: Efficient and Effective Unsupervised Multi-Table Entity Matching"></a>MultiEM: Efficient and Effective Unsupervised Multi-Table Entity Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01927">http://arxiv.org/abs/2308.01927</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zju-daily/multiem">https://github.com/zju-daily/multiem</a></li>
<li>paper_authors: Xiaocan Zeng, Pengfei Wang, Yuren Mao, Lu Chen, Xiaoze Liu, Yunjun Gao</li>
<li>for: 这篇论文主要针对的是实际数据管理系统中实现不监督实体匹配（Unsupervised Entity Matching，UEM）问题。</li>
<li>methods: 这篇论文提出了一种新的无监督多表实体匹配方法（Multi-table Entity Matching，MultiEM），它是一个并行可分解的管道，包括加强实体表示、表wise层次合并和浸泡筛选。</li>
<li>results: 对六个实际数据集进行了广泛的实验，证明了 MultiEM 在效果和效率两个方面具有优势。<details>
<summary>Abstract</summary>
Entity Matching (EM), which aims to identify all entity pairs referring to the same real-world entity from relational tables, is one of the most important tasks in real-world data management systems. Due to the labeling process of EM being extremely labor-intensive, unsupervised EM is more applicable than supervised EM in practical scenarios. Traditional unsupervised EM assumes that all entities come from two tables; however, it is more common to match entities from multiple tables in practical applications, that is, multi-table entity matching (multi-table EM). Unfortunately, effective and efficient unsupervised multi-table EM remains under-explored. To fill this gap, this paper formally studies the problem of unsupervised multi-table entity matching and proposes an effective and efficient solution, termed as MultiEM. MultiEM is a parallelable pipeline of enhanced entity representation, table-wise hierarchical merging, and density-based pruning. Extensive experimental results on six real-world benchmark datasets demonstrate the superiority of MultiEM in terms of effectiveness and efficiency.
</details>
<details>
<summary>摘要</summary>
实体匹配（EM），旨在从关系表中找到真实世界实体对应的所有实体对，是现实数据管理系统中最重要的任务之一。由于EM标注过程非常劳动密集，因此在实际场景中更适合使用无监督EM。传统的无监督EM假设所有实体来自两个表，但在实际应用中更常见的是从多个表匹配实体，即多表实体匹配（多表EM）。然而，有效和高效的无监督多表EM还未得到了足够的探索。为了填补这个空白，本文正式研究了无监督多表实体匹配问题，并提出了一种高效和高效的解决方案，名为MultiEM。MultiEM是一个并行的管道，包括增强实体表示、表位层次合并和浮点筛选。在六个真实世界 benchmark 数据集上进行了广泛的实验，结果表明MultiEM在效果和效率两个方面具有优势。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Few-Shot-Data-Augmentation-and-Waterfall-Prompting-for-Response-Generation"><a href="#Leveraging-Few-Shot-Data-Augmentation-and-Waterfall-Prompting-for-Response-Generation" class="headerlink" title="Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation"></a>Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01080">http://arxiv.org/abs/2308.01080</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lea Krause, Selene Báez Santamaría, Michiel van der Meer, Urja Khurana</li>
<li>for: 本研究探讨了基于主观知识的对话模型设计，尤其是响应生成。</li>
<li>methods: 我们的方法采用了大量数据分析，以评估提供的数据集中的关键因素，如响应长度、情感和对话动作。我们还使用了少量学习来扩展数据集，并提出了三种方法来解决DSTC11：（1）任务特定模型探索，（2）将最常见问题 incorporate into all generated responses，和（3）水fall提问技术使用组合GPT-3和ChatGPT。</li>
<li>results: 我们的实验结果表明，使用水fall提问技术可以提高对话模型的性能，并且可以在不同的任务上实现高效的对话模型设计。<details>
<summary>Abstract</summary>
This paper discusses our approaches for task-oriented conversational modelling using subjective knowledge, with a particular emphasis on response generation. Our methodology was shaped by an extensive data analysis that evaluated key factors such as response length, sentiment, and dialogue acts present in the provided dataset. We used few-shot learning to augment the data with newly generated subjective knowledge items and present three approaches for DSTC11: (1) task-specific model exploration, (2) incorporation of the most frequent question into all generated responses, and (3) a waterfall prompting technique using a combination of both GPT-3 and ChatGPT.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>任务特定模型探索 (task-specific model exploration)2. 包含最常见问题的所有生成响应 (incorporation of the most frequent question into all generated responses)3. 组合GPT-3和ChatGPT的水质提示技术 (a waterfall prompting technique using a combination of both GPT-3 and ChatGPT)Note:* “DSTC11” refers to the Dialogue System Technology Challenge (DSTC) 2011, which is a benchmarking task for conversational AI systems.* “subjective knowledge” refers to the knowledge that is personal and subjective, and may not be easily quantifiable or observable.* “response generation” refers to the task of generating appropriate responses to user inputs in a conversational setting.</details></li>
</ol>
<hr>
<h2 id="Industrial-Memories-Exploring-the-Findings-of-Government-Inquiries-with-Neural-Word-Embedding-and-Machine-Learning"><a href="#Industrial-Memories-Exploring-the-Findings-of-Government-Inquiries-with-Neural-Word-Embedding-and-Machine-Learning" class="headerlink" title="Industrial Memories: Exploring the Findings of Government Inquiries with Neural Word Embedding and Machine Learning"></a>Industrial Memories: Exploring the Findings of Government Inquiries with Neural Word Embedding and Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02556">http://arxiv.org/abs/2308.02556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Susan Leavy, Emilie Pine, Mark T Keane</li>
<li>for: 支持大量文本检索，探索政府调查发现的结论</li>
<li>methods: 使用word embedding、文本分类和可视化技术，创建一个交互式网页平台，帮助探索文本，发现新的历史发现</li>
<li>results: 通过转换爱尔兰政府的industrial school inquiry发现，创建了一个可交互的网页平台，帮助探索文本，发现新的历史发现<details>
<summary>Abstract</summary>
We present a text mining system to support the exploration of large volumes of text detailing the findings of government inquiries. Despite their historical significance and potential societal impact, key findings of inquiries are often hidden within lengthy documents and remain inaccessible to the general public. We transform the findings of the Irish government's inquiry into industrial schools and through the use of word embedding, text classification and visualisation, present an interactive web-based platform that enables the exploration of the text to uncover new historical insights.
</details>
<details>
<summary>摘要</summary>
我们提供一个文本挖掘系统，用于探索大量关于政府调查结果的文本。尽管这些调查结果具有历史意义和社会影响，但它们常常被困在长篇文本中，不可供一般公众查阅。我们使用词嵌入、文本分类和视觉化技术，将爱尔兰政府关于工业学校调查的结果转化为一个交互式网页平台，让用户可以通过探索文本来发现新的历史发现。
</details></li>
</ul>
<hr>
<h2 id="SALTTS-Leveraging-Self-Supervised-Speech-Representations-for-improved-Text-to-Speech-Synthesis"><a href="#SALTTS-Leveraging-Self-Supervised-Speech-Representations-for-improved-Text-to-Speech-Synthesis" class="headerlink" title="SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis"></a>SALTTS: Leveraging Self-Supervised Speech Representations for improved Text-to-Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01018">http://arxiv.org/abs/2308.01018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ramanan Sivaguru, Vasista Sai Lodagala, S Umesh</li>
<li>for: 提高 FastSpeech2 synthesized speech 质量</li>
<li>methods: 使用 Self-Supervised Learning (SSL) 模型的表示来增强 FastSpeech2 synthesized speech 的质量</li>
<li>results: 比基eline FastSpeech2 更高的对象和主观评价指标表示提高了 synthesized speech 的质量<details>
<summary>Abstract</summary>
While FastSpeech2 aims to integrate aspects of speech such as pitch, energy, and duration as conditional inputs, it still leaves scope for richer representations. As a part of this work, we leverage representations from various Self-Supervised Learning (SSL) models to enhance the quality of the synthesized speech. In particular, we pass the FastSpeech2 encoder's length-regulated outputs through a series of encoder layers with the objective of reconstructing the SSL representations. In the SALTTS-parallel implementation, the representations from this second encoder are used for an auxiliary reconstruction loss with the SSL features. The SALTTS-cascade implementation, however, passes these representations through the decoder in addition to having the reconstruction loss. The richness of speech characteristics from the SSL features reflects in the output speech quality, with the objective and subjective evaluation measures of the proposed approach outperforming the baseline FastSpeech2.
</details>
<details>
<summary>摘要</summary>
While FastSpeech2 aims to integrate aspects of speech such as pitch, energy, and duration as conditional inputs, it still leaves scope for richer representations. As part of this work, we leverage representations from various Self-Supervised Learning (SSL) models to enhance the quality of the synthesized speech. Specifically, we pass the FastSpeech2 encoder's length-regulated outputs through a series of encoder layers with the objective of reconstructing the SSL representations. In the SALTTS-parallel implementation, the representations from this second encoder are used for an auxiliary reconstruction loss with the SSL features. The SALTTS-cascade implementation, however, passes these representations through the decoder in addition to having the reconstruction loss. The richness of speech characteristics from the SSL features is reflected in the output speech quality, with the proposed approach outperforming the baseline FastSpeech2 based on both objective and subjective evaluation measures.
</details></li>
</ul>
<hr>
<h2 id="DiactTOD-Learning-Generalizable-Latent-Dialogue-Acts-for-Controllable-Task-Oriented-Dialogue-Systems"><a href="#DiactTOD-Learning-Generalizable-Latent-Dialogue-Acts-for-Controllable-Task-Oriented-Dialogue-Systems" class="headerlink" title="DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems"></a>DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00878">http://arxiv.org/abs/2308.00878</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingyang Wu, James Gung, Raphael Shu, Yi Zhang</li>
<li>for: 这篇论文主要是为了提高任务对话系统的回答生成质量，通过使用对话动作标注。</li>
<li>methods: 这篇论文使用了一种新的终端对话动作模型（DiactTOD），该模型可以在隐藏空间中表示对话动作，并在零Instance情况下使用这些隐藏表示来生成可控的回答。</li>
<li>results: 在多个实验设定下，包括零实例、少数实例和全数据精度调整，该方法达到了状态之最高的性能，并且可以在终端和策略优化配置下实现Zero-shot和几shot的情况。<details>
<summary>Abstract</summary>
Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.
</details>
<details>
<summary>摘要</summary>
对话执行动标注是提高任务对话系统响应质量的关键。然而，使用对话执行动来控制响应生成可能会困难，因为不同的数据集和任务可能存在不兼容的标注。而使用隐藏空间或奖励学习方法可能缺乏可读性或定义任务特定的奖励是困难的。在这项工作中，我们提出了一种新的端到端隐藏对话执行动模型（DiactTOD），该模型可以在隐藏空间中表示对话执行动。当 DiactTOD 在大量文本 corpus 上预训练后，可以预测和控制对话执行动，并使用这些隐藏表示生成可控的响应。我们的方法在多种实验设置下达到了状态级表现，包括零shot、少shot 和全数据精度调整，并在端到端和政策优化配置下达到了最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Proceedings-Modalities-in-substructural-logics-Applications-at-the-interfaces-of-logic-language-and-computation"><a href="#Proceedings-Modalities-in-substructural-logics-Applications-at-the-interfaces-of-logic-language-and-computation" class="headerlink" title="Proceedings Modalities in substructural logics: Applications at the interfaces of logic, language and computation"></a>Proceedings Modalities in substructural logics: Applications at the interfaces of logic, language and computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03679">http://arxiv.org/abs/2308.03679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Moortgat, Mehrnoosh Sadrzadeh</li>
<li>for: 本文探讨了类别逻辑中的隐式结构规则，并通过模态逻辑控制逻辑资源的分配。</li>
<li>methods: 本文使用了模态逻辑来控制逻辑资源的分配，并应用于自然语言 syntax 和 semantics 等领域。</li>
<li>results: 本文在逻辑方面提供了新的应用领域，包括自然语言 syntax 和 semantics 等领域的动态逻辑推理。<details>
<summary>Abstract</summary>
By calling into question the implicit structural rules that are taken for granted in classical logic, substructural logics have brought to the fore new forms of reasoning with applications in many interdisciplinary areas of interest. Modalities, in the substructural setting, provide the tools to control and finetune the logical resource management. The focus of the workshop is on applications in the areas of interest to the ESSLLI community, in particular logical approaches to natural language syntax and semantics and the dynamics of reasoning. The workshop is held with the support of the Horizon 2020 MSCA-Rise project MOSAIC .
</details>
<details>
<summary>摘要</summary>
经启发了古典逻辑中隐式结构规则的假设，Subview逻辑已经把新的理由形式带到了前线。Modalities在Subview设置下提供了控制和精细化逻辑资源的工具。工作室的焦点是在ESSLLI社区兴趣领域的应用，特别是逻辑对自然语言语法和 semantics的逻辑approaches以及推理的动态。工作室得到了欧盟海绵2020年MSCA-Rise项目MOSAIC的支持。
</details></li>
</ul>
<hr>
<h2 id="Aspect-based-sentimental-analysis-for-travellers’-reviews"><a href="#Aspect-based-sentimental-analysis-for-travellers’-reviews" class="headerlink" title="Aspect based sentimental analysis for travellers’ reviews"></a>Aspect based sentimental analysis for travellers’ reviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02548">http://arxiv.org/abs/2308.02548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed Saad M Alaydaa, Jun Li, Karl Jinkins</li>
<li>for: 本研究旨在为机场管理人员提供更加细化的服务质量评估方法，以便更好地了解旅客的需求和意见。</li>
<li>methods: 本研究使用了方面基 sentiment分析方法，以分析来自Google Maps的旅客评论，并提供了更加细化的服务质量评估结果。</li>
<li>results: 研究结果表明，使用方面基 sentiment分析方法可以提供更加细化的服务质量评估结果，帮助机场管理人员更好地了解旅客的需求和意见，并提供了更加准确的改进建议。<details>
<summary>Abstract</summary>
Airport service quality evaluation is commonly found on social media, including Google Maps. This valuable for airport management in order to enhance the quality of services provided. However; prior studies either provide general review for topics discussed by travellers or provide sentimental value to tag the entire review without specifically mentioning the airport service that is behind such value. Accordingly, this work proposes using aspect based sentimental analysis in order to provide more detailed analysis for travellers reviews. This works applied aspect based sentimental analysis on data collected from Google Map about Dubai and Doha airports. The results provide tangible reasons to use aspect based sentimental analysis in order to understand more the travellers and spot airport services that are in need for improvement.
</details>
<details>
<summary>摘要</summary>
空港服务质量评估通常出现在社交媒体上，包括Google Maps。这对空港管理有益，可以提高提供的服务质量。然而，先前的研究 either提供旁ieri travelers discussed的通用评论或对整个评论进行情感值标签，而不是特定的空港服务。因此，这项工作提议使用方面基 sentimental analysis，以提供更加细化的旅客评论分析。这个工作在Google Maps上收集的关于 Dubai 和 Doha 机场的数据上进行了方面基 sentimental analysis。结果提供了具体的原因，以便使用方面基 sentimental analysis，以更好地理解旅客和改进机场服务。
</details></li>
</ul>
<hr>
<h2 id="GRDD-A-Dataset-for-Greek-Dialectal-NLP"><a href="#GRDD-A-Dataset-for-Greek-Dialectal-NLP" class="headerlink" title="GRDD: A Dataset for Greek Dialectal NLP"></a>GRDD: A Dataset for Greek Dialectal NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00802">http://arxiv.org/abs/2308.00802</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stergioscha/greek_dialect_corpus">https://github.com/stergioscha/greek_dialect_corpus</a></li>
<li>paper_authors: Stergios Chatzikyriakidis, Chatrine Qwaider, Ilias Kolokousis, Christina Koula, Dimitris Papadakis, Efthymia Sakellariou</li>
<li>for: This paper is written for the purpose of creating a large-scale dataset for the computational study of Modern Greek dialects, and to perform dialect identification using machine learning (ML) algorithms and deep learning (DL) architectures.</li>
<li>methods: The paper uses a dataset of raw text data from four Modern Greek dialects (Cretan, Pontic, Northern Greek, and Cypriot Greek) to perform dialect identification. The authors experiment with traditional ML algorithms and simple DL architectures to achieve good performance on the task.</li>
<li>results: The results of the paper show very good performance on the task of dialect identification, with the top performing algorithms achieving high accuracy. However, error analysis reveals that insufficient dataset cleaning is a major source of errors.<details>
<summary>Abstract</summary>
In this paper, we present a dataset for the computational study of a number of Modern Greek dialects. It consists of raw text data from four dialects of Modern Greek, Cretan, Pontic, Northern Greek and Cypriot Greek. The dataset is of considerable size, albeit imbalanced, and presents the first attempt to create large scale dialectal resources of this type for Modern Greek dialects. We then use the dataset to perform dialect idefntification. We experiment with traditional ML algorithms, as well as simple DL architectures. The results show very good performance on the task, potentially revealing that the dialects in question have distinct enough characteristics allowing even simple ML models to perform well on the task. Error analysis is performed for the top performing algorithms showing that in a number of cases the errors are due to insufficient dataset cleaning.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们发布了现代希腊方言的计算机研究数据集。数据集包含四种现代希腊方言的原始文本数据，即crete, pontic, northern greek和cypriot greek。数据集虽然庞大但受到干扰，但是这是现代希腊方言的大规模方言资源的首次尝试。我们使用该数据集进行方言定义，并使用传统的机器学习算法以及简单的人工智能建筑。结果表明，这些方言之间有明显的特征，使得简单的机器学习模型可以在这种任务上表现出色。我们进行错误分析，发现在一些情况下，错误是由于数据集不够清洁。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Contrastive-BERT-Fine-tuning-for-Fusion-based-Reviewed-Item-Retrieval"><a href="#Self-Supervised-Contrastive-BERT-Fine-tuning-for-Fusion-based-Reviewed-Item-Retrieval" class="headerlink" title="Self-Supervised Contrastive BERT Fine-tuning for Fusion-based Reviewed-Item Retrieval"></a>Self-Supervised Contrastive BERT Fine-tuning for Fusion-based Reviewed-Item Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00762">http://arxiv.org/abs/2308.00762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/d3mlab/rir_data">https://github.com/d3mlab/rir_data</a></li>
<li>paper_authors: Mohammad Mahdi Abdollah Pour, Parsa Farinneya, Armin Toroghi, Anton Korikov, Ali Pesaranghader, Touqir Sajed, Manasa Bharadwaj, Borislav Mavrin, Scott Sanner</li>
<li>for: 该论文主要针对的是 Reviewed-Item Retrieval (RIR) 任务，即使用神经网络 Retrieval (IR) 方法来对用户提出的复杂自然语言查询进行匹配。</li>
<li>methods: 该论文提出了一种基于自我超vised learning的方法，通过对 BERT 表示的对比学习来扩展 Neural IR 方法到 RIR 任务。具体来说，该方法使用了同一个物品的正面评论作为积极样本，选择最不相似的评论作为硬性正样本，并使用不同物品的评论作为硬性负样本。此外，该方法还 explore anchor sub-sampling 和 meta-data 的使用。</li>
<li>results: 实验结果表明，使用 Late Fusion 方法进行对比学习的 Neural RIR 方法可以与所有其他对比 IR 配置、神经 IR 和稀 scattered retrieval 基线方法进行比较，并且达到最高效果。这表明了在 Neural RIR 方法中利用两级结构以及在 Early Fusion 和 Late Fusion 方法之间的转换可以提高效果。<details>
<summary>Abstract</summary>
As natural language interfaces enable users to express increasingly complex natural language queries, there is a parallel explosion of user review content that can allow users to better find items such as restaurants, books, or movies that match these expressive queries. While Neural Information Retrieval (IR) methods have provided state-of-the-art results for matching queries to documents, they have not been extended to the task of Reviewed-Item Retrieval (RIR), where query-review scores must be aggregated (or fused) into item-level scores for ranking. In the absence of labeled RIR datasets, we extend Neural IR methodology to RIR by leveraging self-supervised methods for contrastive learning of BERT embeddings for both queries and reviews. Specifically, contrastive learning requires a choice of positive and negative samples, where the unique two-level structure of our item-review data combined with meta-data affords us a rich structure for the selection of these samples. For contrastive learning in a Late Fusion scenario, we investigate the use of positive review samples from the same item and/or with the same rating, selection of hard positive samples by choosing the least similar reviews from the same anchor item, and selection of hard negative samples by choosing the most similar reviews from different items. We also explore anchor sub-sampling and augmenting with meta-data. For a more end-to-end Early Fusion approach, we introduce contrastive item embedding learning to fuse reviews into single item embeddings. Experimental results show that Late Fusion contrastive learning for Neural RIR outperforms all other contrastive IR configurations, Neural IR, and sparse retrieval baselines, thus demonstrating the power of exploiting the two-level structure in Neural RIR approaches as well as the importance of preserving the nuance of individual review content via Late Fusion methods.
</details>
<details>
<summary>摘要</summary>
随着自然语言界面的发展，用户可以提出更加复杂的自然语言查询，这对搜索笔记、书籍和电影等项目的搜索提供了更多的可能性。然而，神经信息检索（Neural IR）方法已经提供了状态态的结果，但它们没有被扩展到评论项目检索（RIR）任务中，其中需要将查询和评论得分聚合（或融合）为项目级别的分数。由于缺乏标注的 RIR 数据集，我们将神经 IR 方法扩展到 RIR 任务中，通过利用自我指导的方法进行对比学习BERT表示。具体来说，对比学习需要选择正例和负例样本，我们利用Item-review数据集的特殊两级结构，以及元数据，选择正例和负例样本。我们还 investigate了使用相同项目和相同分数的积极正例样本，选择最不相似的 anchor item 中的积极负例样本，以及使用不同项目的最相似负例样本。此外，我们还探索了 anchor 子样本抽取和元数据增强。为了更加端到端，我们引入对比项目嵌入学习，将评论 fusion 到单个项目嵌入中。实验结果表明，使用 Late Fusion 对比学习方法，Neural RIR 的性能高于所有其他对比 IR 配置、神经 IR 和稀肥检索基线，这表明了利用 Neural RIR 方法的两级结构以及在 Late Fusion 方法中保持评论内容的细节的重要性。
</details></li>
</ul>
<hr>
<h2 id="The-Bias-Amplification-Paradox-in-Text-to-Image-Generation"><a href="#The-Bias-Amplification-Paradox-in-Text-to-Image-Generation" class="headerlink" title="The Bias Amplification Paradox in Text-to-Image Generation"></a>The Bias Amplification Paradox in Text-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00755">http://arxiv.org/abs/2308.00755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/preethiseshadri518/bias-amplification-paradox">https://github.com/preethiseshadri518/bias-amplification-paradox</a></li>
<li>paper_authors: Preethi Seshadri, Sameer Singh, Yanai Elazar</li>
<li>for: 这个论文研究了模型在文本到图像领域中的偏见增强现象，通过比较训练和生成图像中的性别比例来研究。</li>
<li>methods: 这个论文使用了稳定扩散来研究模型的偏见增强现象，并发现了模型在训练数据中存在性别职业偏见的增强。</li>
<li>results: 研究发现，模型的偏见增强主要归结于训练和生成文本之间的分布差异，例如训练caption中常包含直接表达性别信息的情况，而生成提示则不包含这种信息，这导致分布差异并影响偏见度量。经过考虑这些分布差异， amplification 降低了许多。这些发现表明了比较模型和训练数据中的偏见是一个挑战，以及模型训练过程中存在干扰因素的影响。<details>
<summary>Abstract</summary>
Bias amplification is a phenomenon in which models increase imbalances present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stable Diffusion by comparing gender ratios in training vs. generated images. We find that the model appears to amplify gender-occupation biases found in the training data (LAION). However, we discover that amplification can largely be attributed to discrepancies between training captions and model prompts. For example, an inherent difference is that captions from the training data often contain explicit gender information while the prompts we use do not, which leads to a distribution shift and consequently impacts bias measures. Once we account for various distributional differences between texts used for training and generation, we observe that amplification decreases considerably. Our findings illustrate the challenges of comparing biases in models and the data they are trained on, and highlight confounding factors that contribute to bias amplification.
</details>
<details>
<summary>摘要</summary>
<<sys: language="zh-Hans">偏见增强是一种现象，在训练数据中存在的偏见会被模型进一步增加。在这篇论文中，我们研究了在文本到图像领域中的偏见增强，使用稳定扩散比较训练和生成图像中的性别比。我们发现，模型似乎会增加在训练数据中存在的性别职业偏见，但是我们发现，增强的主要原因是训练caption和模型提示之间的分布差异。例如，训练数据中的caption通常包含直接表达性别信息，而模型提示则不包含这种信息，这导致分布shift并影响偏见测量。一旦我们考虑了训练和生成文本之间的各种分布差异，我们发现增强明显减少。我们的发现表明了对比模型和它们训练数据中的偏见的困难，以及生成图像中的偏见增强的干扰因素。</sys>>
</details></li>
</ul>
<hr>
<h2 id="CodeBPE-Investigating-Subtokenization-Options-for-Large-Language-Model-Pretraining-on-Source-Code"><a href="#CodeBPE-Investigating-Subtokenization-Options-for-Large-Language-Model-Pretraining-on-Source-Code" class="headerlink" title="CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code"></a>CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00683">http://arxiv.org/abs/2308.00683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nadezhda Chirkova, Sergey Troshin</li>
<li>for: 这个研究目的是调查不同子tokization选项对代码预训练模型的影响，并找到最有效和最短的子tokization方法。</li>
<li>methods: 该研究使用了大量语言模型预训练，并提出了一种新的子tokization方法，该方法可以减少平均长度17%，而无需下游性能下降。</li>
<li>results: 研究发现，选择合适的子tokization方法可以提高质量0.5-2%，可能会增加一些长度。<details>
<summary>Abstract</summary>
Recent works have widely adopted large language model pretraining for source code, suggested source code-specific pretraining objectives and investigated the applicability of various Transformer-based language model architectures for source code. This work investigates another important aspect of such models, namely the effect of different subtokenization options, and aims at identifying most effective and length-efficient subtokenizations, taking into account code specifics. We propose subtokenziation that reduces average length by 17% without downstream performance drop, and show that a carefully chosen subtokenization may improve quality by 0.5-2%, possibly with some length increase.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/02/cs.CL_2023_08_02/" data-id="clogy1z1v008kffra1joa6pbe" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/02/cs.LG_2023_08_02/" class="article-date">
  <time datetime="2023-08-02T10:00:00.000Z" itemprop="datePublished">2023-08-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/02/cs.LG_2023_08_02/">cs.LG - 2023-08-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Careful-Whisper-–-leveraging-advances-in-automatic-speech-recognition-for-robust-and-interpretable-aphasia-subtype-classification"><a href="#Careful-Whisper-–-leveraging-advances-in-automatic-speech-recognition-for-robust-and-interpretable-aphasia-subtype-classification" class="headerlink" title="Careful Whisper – leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification"></a>Careful Whisper – leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01327">http://arxiv.org/abs/2308.01327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laurin Wagner, Mario Zusag, Theresa Bloder</li>
<li>for: 这 paper 是为了 automatization speech anomaly detection 以检测语言障碍的评估。</li>
<li>methods: 该 paper 使用了 Connectionist Temporal Classification (CTC) 和 encoder-decoder 自动语音识别模型，生成了丰富的声学特征和清晰的转录。然后，通过应用一些自然语言处理方法，提取了转录中的特征，生成了健康语音的原型。</li>
<li>results: 该 paper 的结果表明，使用这些原型可以以人工智能水平准确地分辨人们有语言障碍和健康控制组之间的差异。此外，还可以准确地分辨出最常见的语言障碍类型。该 pipeline 可以直接应用于其他疾病和语言，显示出robustly extracting diagnostic speech biomarkers的承诺。<details>
<summary>Abstract</summary>
This paper presents a fully automated approach for identifying speech anomalies from voice recordings to aid in the assessment of speech impairments. By combining Connectionist Temporal Classification (CTC) and encoder-decoder-based automatic speech recognition models, we generate rich acoustic and clean transcripts. We then apply several natural language processing methods to extract features from these transcripts to produce prototypes of healthy speech. Basic distance measures from these prototypes serve as input features for standard machine learning classifiers, yielding human-level accuracy for the distinction between recordings of people with aphasia and a healthy control group. Furthermore, the most frequently occurring aphasia types can be distinguished with 90% accuracy. The pipeline is directly applicable to other diseases and languages, showing promise for robustly extracting diagnostic speech biomarkers.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种完全自动化的声音异常识别方法，通过结合连接主义时间分类（CTC）和扩展器-解码器基于自动语音识别模型，生成丰富的声音特征和清晰的译文。然后，通过应用一些自然语言处理方法，提取这些译文中的特征，生成健康语音的原型。基本距离度量从这些原型中提取，作为机器学习分类器的输入特征，可以达到人类水平的准确率，将recordings of people with aphasia和健康控制组分开。此外，最常出现的语言障碍类型可以达到90%的准确率。这个管道可以直接应用于其他疾病和语言，展现了抽取健康语音生物标志物的可靠性。
</details></li>
</ul>
<hr>
<h2 id="Do-Multilingual-Language-Models-Think-Better-in-English"><a href="#Do-Multilingual-Language-Models-Think-Better-in-English" class="headerlink" title="Do Multilingual Language Models Think Better in English?"></a>Do Multilingual Language Models Think Better in English?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01223">http://arxiv.org/abs/2308.01223</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juletx/self-translate">https://github.com/juletx/self-translate</a></li>
<li>paper_authors: Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, Mikel Artetxe</li>
<li>for: 本研究旨在提高多语言语言模型的性能，并提出了一种新的自动翻译方法（self-translate），可以减少外部翻译系统的使用。</li>
<li>methods: 本研究使用了多语言语言模型的几个任务来评估自动翻译方法的性能，并通过对输入数据进行翻译并运行推理来评估模型的性能。</li>
<li>results: 实验结果显示，使用自动翻译方法可以 Consistently outperform direct inference，这表明多语言语言模型在非英语语言下的表达能力尚未被完全发挥。<details>
<summary>Abstract</summary>
Translate-test is a popular technique to improve the performance of multilingual language models. This approach works by translating the input into English using an external machine translation system, and running inference over the translated input. However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model. In this work, we introduce a new approach called self-translate, which overcomes the need of an external translation system by leveraging the few-shot translation capabilities of multilingual language models. Experiments over 5 tasks show that self-translate consistently outperforms direct inference, demonstrating that language models are unable to leverage their full multilingual potential when prompted in non-English languages. Our code is available at https://github.com/juletx/self-translate.
</details>
<details>
<summary>摘要</summary>
<<SYS>> traduction-test 是一种受欢迎的技术，用于改进多语言语音模型的性能。这种方法工作通过将输入翻译成英语使用外部机器翻译系统，然后运行推理 sobre 翻译后的输入。然而，这些改进可以归功于使用分开的翻译系统，这个系统通常是基于大量的并行数据不被语音模型训练的。在这项工作中，我们介绍了一种新的方法called自动翻译（self-translate），它超越了需要外部翻译系统的需求，通过多语言语音模型的几个shot翻译能力来实现。经过5个任务的实验表明，自动翻译在直接推理的情况下一直表现出优于，这说明了语音模型在非英语提问时不能完全发挥其多语言潜力。我们的代码可以在 <https://github.com/juletx/self-translate> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Calibration-in-Deep-Learning-A-Survey-of-the-State-of-the-Art"><a href="#Calibration-in-Deep-Learning-A-Survey-of-the-State-of-the-Art" class="headerlink" title="Calibration in Deep Learning: A Survey of the State-of-the-Art"></a>Calibration in Deep Learning: A Survey of the State-of-the-Art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01222">http://arxiv.org/abs/2308.01222</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Wang</li>
<li>for:  This paper is written for researchers and practitioners who are interested in calibrating deep neural models for safety-critical applications.</li>
<li>methods: The paper reviews state-of-the-art calibration methods for deep models, including post-hoc calibration, regularization methods, uncertainty estimation, and composition methods.</li>
<li>results: The paper provides an understanding of the principles of model calibration, including the definition of model miscalibration and key metrics for measuring it. It also covers recent advancements in calibrating large models, particularly large language models (LLMs).<details>
<summary>Abstract</summary>
Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications. Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions. Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively underexplored. Ideal deep models should have not only high predictive performance but also be well calibrated. There have been some recent methods proposed to calibrate deep models by using different mechanisms. In this survey, we review the state-of-the-art calibration methods and provide an understanding of their principles for performing model calibration. First, we start with the definition of model calibration and explain the root causes of model miscalibration. Then we introduce the key metrics that can measure this aspect. It is followed by a summary of calibration methods that we roughly classified into four categories: post-hoc calibration, regularization methods, uncertainty estimation, and composition methods. We also covered some recent advancements in calibrating large models, particularly large language models (LLMs). Finally, we discuss some open issues, challenges, and potential directions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>模型调整在安全应用中建立可靠、Robust AI系统的重要作用。最近的工作表明，现代神经网络具有高预测能力，但是受到误差的影响，其预测结果不可靠。虽然深度学习模型在不同的测试环境中表现出色，但是模型调整和可靠性的研究相对落后。理想的深度模型应该不仅具有高预测性能，还应该具有良好的调整性。在这篇评论中，我们回顾了当前领域的状态对模型调整的方法，并提供了这些方法的原理。首先，我们开始定义模型调整，并解释了模型调整的根本原因。然后，我们介绍了评估模型调整的关键指标。接着，我们概括了调整方法，我们将它们分为四类：后处调整、regularization方法、uncertainty估计和组合方法。我们还讲述了在调整大型模型时的一些最新进展，特别是大语言模型（LLMs）。最后，我们讨论了一些开放的问题、挑战和未来的方向。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Using-ScrutinAI-for-Visual-Inspection-of-DNN-Performance-in-a-Medical-Use-Case"><a href="#Using-ScrutinAI-for-Visual-Inspection-of-DNN-Performance-in-a-Medical-Use-Case" class="headerlink" title="Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case"></a>Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01220">http://arxiv.org/abs/2308.01220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rebekka Görge, Elena Haedecke, Michael Mock</li>
<li>for: 该论文旨在探讨模型性能如何受到标签质量的影响，特别是在医疗设置下，生成高质量标签需要深刻的专家知识和是非常昂贵的。</li>
<li>methods: 该论文使用了一种名为ScrutinAI的可见分析工具，来分析不同专家对数据集的标签变化对模型性能的影响。</li>
<li>results: 该论文通过对一个公共可用的数据集中脑出血的检测和分类的检测进行分析，发现模型性能受到标签质量的影响，并且可以通过ScrutinAI来分析出模型的真正弱点。<details>
<summary>Abstract</summary>
Our Visual Analytics (VA) tool ScrutinAI supports human analysts to investigate interactively model performanceand data sets. Model performance depends on labeling quality to a large extent. In particular in medical settings, generation of high quality labels requires in depth expert knowledge and is very costly. Often, data sets are labeled by collecting opinions of groups of experts. We use our VA tool to analyse the influence of label variations between different experts on the model performance. ScrutinAI facilitates to perform a root cause analysis that distinguishes weaknesses of deep neural network (DNN) models caused by varying or missing labeling quality from true weaknesses. We scrutinize the overall detection of intracranial hemorrhages and the more subtle differentiation between subtypes in a publicly available data set.
</details>
<details>
<summary>摘要</summary>
我们的视觉分析工具ScrutinAI可以帮助人类分析员在互动式地模型性能和数据集之间进行调查。模型性能受标注质量的影响很大。尤其在医疗设置下，生成高质量标注需要深厚的专家知识并非常昂贵。经常情况下，数据集被由不同专家的意见集成来标注。我们使用ScrutinAI来分析标注之间的差异对模型性能的影响。ScrutinAI可以进行根本原因分析，并将模型因标注质量变化或缺失而导致的弱点与真正的弱点区分开来。我们在一个公共可用的数据集中进行了总脑出血的检测和更加细致的分类 между不同类型的差异分析。
</details></li>
</ul>
<hr>
<h2 id="Global-Hierarchical-Neural-Networks-using-Hierarchical-Softmax"><a href="#Global-Hierarchical-Neural-Networks-using-Hierarchical-Softmax" class="headerlink" title="Global Hierarchical Neural Networks using Hierarchical Softmax"></a>Global Hierarchical Neural Networks using Hierarchical Softmax</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01210">http://arxiv.org/abs/2308.01210</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jschuurmans/hsoftmax">https://github.com/jschuurmans/hsoftmax</a></li>
<li>paper_authors: Jetze Schuurmans, Flavius Frasincar</li>
<li>for: 这篇论文提出了一种基于层次softmax的全局分类器框架，适用于任何具有自然层次结构的分类任务。</li>
<li>methods: 该方法使用层次softmax创建全局分类器，并在四个文本分类数据集上进行了实验。在所有数据集中，层次softmax超过了常规softmax在扫描分类器中的 macro-F1 和 macro- recall。在三个数据集中，层次softmax达到了更高的微精度和macro精度。</li>
<li>results: 实验结果表明，层次softmax在四个文本分类数据集上均显著提高了分类性能，特别是在 macro-F1 和 macro-recall 上。<details>
<summary>Abstract</summary>
This paper presents a framework in which hierarchical softmax is used to create a global hierarchical classifier. The approach is applicable for any classification task where there is a natural hierarchy among classes. We show empirical results on four text classification datasets. In all datasets the hierarchical softmax improved on the regular softmax used in a flat classifier in terms of macro-F1 and macro-recall. In three out of four datasets hierarchical softmax achieved a higher micro-accuracy and macro-precision.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文提出了一个基于层次软max的全局层次分类器框架，适用于任何具有自然层次结构的分类任务。我们通过四个文本分类 dataset 的实验结果表明，层次软max 在 macro-F1 和 macro-recall 方面比常软max 使用的平面分类器表现更好。此外，层次软max 在三个 dataset 中达到了更高的微准确率和macro准确率。
</details></li>
</ul>
<hr>
<h2 id="Generative-Noisy-Label-Learning-by-Implicit-Dicriminative-Approximation-with-Partial-Label-Prior"><a href="#Generative-Noisy-Label-Learning-by-Implicit-Dicriminative-Approximation-with-Partial-Label-Prior" class="headerlink" title="Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior"></a>Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01184">http://arxiv.org/abs/2308.01184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fengbei Liu, Yuanhong Chen, Chong Wang, Yuyuan Liu, Gustavo Carneiro</li>
<li>for:  addresses the problem of learning with noisy labels, proposing a new generative approach that improves the estimation of the label transition matrix and disentangles clean and noisy labels.</li>
<li>methods:  uses a new model optimization that directly associates data and clean labels, and implicitly estimates the generative model using a discriminative model, eliminating the need for inefficient training of a generative model.</li>
<li>results:  achieves state-of-the-art results on several noisy-label benchmarks while maintaining a similar computational complexity as discriminative models.<details>
<summary>Abstract</summary>
The learning with noisy labels has been addressed with both discriminative and generative models. Although discriminative models have dominated the field due to their simpler modeling and more efficient computational training processes, generative models offer a more effective means of disentangling clean and noisy labels and improving the estimation of the label transition matrix. However, generative approaches maximize the joint likelihood of noisy labels and data using a complex formulation that only indirectly optimizes the model of interest associating data and clean labels. Additionally, these approaches rely on generative models that are challenging to train and tend to use uninformative clean label priors. In this paper, we propose a new generative noisy-label learning approach that addresses these three issues. First, we propose a new model optimisation that directly associates data and clean labels. Second, the generative model is implicitly estimated using a discriminative model, eliminating the inefficient training of a generative model. Third, we propose a new informative label prior inspired by partial label learning as supervision signal for noisy label learning. Extensive experiments on several noisy-label benchmarks demonstrate that our generative model provides state-of-the-art results while maintaining a similar computational complexity as discriminative models.
</details>
<details>
<summary>摘要</summary>
学习噪声标签已经通过推论性和生成模型进行解决。虽然推论模型因其更简单的模型化和更高效的计算训练过程而占据了领先地位，但生成模型可以更好地分离噪声标签和数据，并提高标签过渡矩阵的估计。然而，生成方法需要使用复杂的定义，只是间接地优化模型关注的数据和干净标签的关系。此外，这些方法通常需要困难地训练生成模型，并使用不够有用的干净标签估计。在这篇论文中，我们提出了一种新的生成噪声标签学习方法，解决了这三个问题。首先，我们提出了一种直接关联数据和干净标签的模型优化方法。其次，我们使用推论模型来隐式地估计生成模型，从而消除生成模型的不fficient 训练。最后，我们提出了一种基于 partial label learning 的新估计标签超级视觉信号。我们在几个噪声标签 benchmark 上进行了广泛的实验，结果表明，我们的生成模型可以在计算复杂性相同的情况下提供状态机器人的结果。
</details></li>
</ul>
<hr>
<h2 id="Direct-Gradient-Temporal-Difference-Learning"><a href="#Direct-Gradient-Temporal-Difference-Learning" class="headerlink" title="Direct Gradient Temporal Difference Learning"></a>Direct Gradient Temporal Difference Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01170">http://arxiv.org/abs/2308.01170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaochi Qian, Shangtong Zhang</li>
<li>for: This paper focuses on addressing the instability issue in off-policy learning with function approximation and bootstrapping, known as the “deadly triad” in reinforcement learning.</li>
<li>methods: The proposed method uses two samples in a Markovian data stream with an increasing gap to directly solve the double sampling issue, without the need for extra weights or Fenchel duality.</li>
<li>results: The proposed algorithm is computationally efficient and has a convergence rate on par with the canonical on-policy temporal difference learning, as demonstrated through both asymptotic and finite sample analysis. Additionally, the method only requires a logarithmically increasing memory as time progresses.<details>
<summary>Abstract</summary>
Off-policy learning enables a reinforcement learning (RL) agent to reason counterfactually about policies that are not executed and is one of the most important ideas in RL. It, however, can lead to instability when combined with function approximation and bootstrapping, two arguably indispensable ingredients for large-scale reinforcement learning. This is the notorious deadly triad. Gradient Temporal Difference (GTD) is one powerful tool to solve the deadly triad. Its success results from solving a doubling sampling issue indirectly with weight duplication or Fenchel duality. In this paper, we instead propose a direct method to solve the double sampling issue by simply using two samples in a Markovian data stream with an increasing gap. The resulting algorithm is as computationally efficient as GTD but gets rid of GTD's extra weights. The only price we pay is a logarithmically increasing memory as time progresses. We provide both asymptotic and finite sample analysis, where the convergence rate is on-par with the canonical on-policy temporal difference learning. Key to our analysis is a novel refined discretization of limiting ODEs.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translates into 掌握了非政策学习可以让人工智能推理counterfactual about不被执行的策略，是现代人工智能中最重要的想法之一。然而，它可能会导致不稳定性，特别是在函数近似和重启执行时。这个问题被称为“恐怖三重套”。梯度时间差（GTD）是一种强大的解决方案，它通过解决重启执行和函数近似问题来解决这个问题。在这篇论文中，我们提出了一种直接解决double sampling问题的方法，通过在Markov链中使用两个采样，并且采样间隔逐渐增加。这种方法的计算效率与GTD相当，但是它不需要额外的Weight。我们付出的价格是在时间上增加logarithmic的内存。我们提供了both asymptotic和finite sample分析，其 convergencerate与标准的在政策学习中相同。关键在于我们的新的精细的分解限制ODEs。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Based-Diabetes-Detection-Using-Photoplethysmography-Signal-Features"><a href="#Machine-Learning-Based-Diabetes-Detection-Using-Photoplethysmography-Signal-Features" class="headerlink" title="Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features"></a>Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01930">http://arxiv.org/abs/2308.01930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filipe A. C. Oliveira, Felipe M. Dias, Marcelo A. F. Toledo, Diego A. C. Cardenas, Douglas A. Almeida, Estela Ribeiro, Jose E. Krieger, Marco A. Gutierrez</li>
<li>for: 这项研究旨在开发一种基于非侵入式光学 фото折射（PPG）的方法，用于检测糖尿病。</li>
<li>methods: 该研究使用了PPG信号和 metadata 进行训练 Logistic Regression（LR）和 eXtreme Gradient Boosting（XGBoost）算法，以分类非糖尿病和糖尿病患者。</li>
<li>results: 该模型在5个批处验证中获得了F1分数和AUC值为58.8±20.0%和79.2±15.0%（LR），以及51.7±16.5%和73.6±17.0%（XGBoost）。特征分析表明，PPG形态特征包含了糖尿病相关信息，同时metadata 也对模型的性能产生了影响。<details>
<summary>Abstract</summary>
Diabetes is a prevalent chronic condition that compromises the health of millions of people worldwide. Minimally invasive methods are needed to prevent and control diabetes but most devices for measuring glucose levels are invasive and not amenable for continuous monitoring. Here, we present an alternative method to overcome these shortcomings based on non-invasive optical photoplethysmography (PPG) for detecting diabetes. We classify non-Diabetic and Diabetic patients using the PPG signal and metadata for training Logistic Regression (LR) and eXtreme Gradient Boosting (XGBoost) algorithms. We used PPG signals from a publicly available dataset. To prevent overfitting, we divided the data into five folds for cross-validation. By ensuring that patients in the training set are not in the testing set, the model's performance can be evaluated on unseen subjects' data, providing a more accurate assessment of its generalization. Our model achieved an F1-Score and AUC of $58.8\pm20.0\%$ and $79.2\pm15.0\%$ for LR and $51.7\pm16.5\%$ and $73.6\pm17.0\%$ for XGBoost, respectively. Feature analysis suggested that PPG morphological features contains diabetes-related information alongside metadata. Our findings are within the same range reported in the literature, indicating that machine learning methods are promising for developing remote, non-invasive, and continuous measurement devices for detecting and preventing diabetes.
</details>
<details>
<summary>摘要</summary>
diabetes 是一种流行的慢性疾病，对全球数百万人的健康产生了影响。为了预防和控制 diabetes，需要使用非侵入性的方法，但现有的血糖水平测量设备多为侵入性，不适合持续监测。在这里，我们提出了一种新的方法，利用非侵入性的光学折射 Plethysmography (PPG) 测测血糖水平。我们使用 PPG 信号和 metadata 进行分类，使用 Logistic Regression (LR) 和 eXtreme Gradient Boosting (XGBoost) 算法进行训练。我们使用公共可用的数据集。为了避免过拟合，我们将数据分成五个拟合集，进行十字验证。由于我们确保在训练集中没有测试集中的病人，因此我们可以评估模型在未见数据上的性能，从而提供更准确的评估。我们的模型达到了 F1 分数和 AUC 的 $58.8\pm20.0\%$ 和 $79.2\pm15.0\%$  для LR 和 $51.7\pm16.5\%$ 和 $73.6\pm17.0\%$  для XGBoost，分别。特征分析表明，PPG 形态特征包含糖尿病相关信息，并且与 metadata 相关。我们的发现与文献中的报告相同，表明机器学习方法在开发远程、非侵入性、持续测量设备方面具有投资前景。
</details></li>
</ul>
<hr>
<h2 id="LLMs-Understand-Glass-Box-Models-Discover-Surprises-and-Suggest-Repairs"><a href="#LLMs-Understand-Glass-Box-Models-Discover-Surprises-and-Suggest-Repairs" class="headerlink" title="LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs"></a>LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01157">http://arxiv.org/abs/2308.01157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/interpretml/talktoebm">https://github.com/interpretml/talktoebm</a></li>
<li>paper_authors: Benjamin J. Lengerich, Sebastian Bordt, Harsha Nori, Mark E. Nunnally, Yin Aphinyanaphongs, Manolis Kellis, Rich Caruana</li>
<li>for: 这篇论文旨在探讨大语言模型（LLMs）如何与可解释模型（ interpretable models）结合使用，以提高数据科学中的常见任务自动化。</li>
<li>methods: 论文使用了层次推理方法，使得LLMs可以对复杂结果进行可解释性的分解，并且不需要整个模型都适应上下文中。</li>
<li>results: 论文通过多个医疗实例展示了LLMs在数据科学中的新能力，特别是在通用加分模型（GAMs）中。此外，论文还提供了一个开源的LLM-GAM接口 package $\texttt{TalkToEBM}$。<details>
<summary>Abstract</summary>
We show that large language models (LLMs) are remarkably good at working with interpretable models that decompose complex outcomes into univariate graph-represented components. By adopting a hierarchical approach to reasoning, LLMs can provide comprehensive model-level summaries without ever requiring the entire model to fit in context. This approach enables LLMs to apply their extensive background knowledge to automate common tasks in data science such as detecting anomalies that contradict prior knowledge, describing potential reasons for the anomalies, and suggesting repairs that would remove the anomalies. We use multiple examples in healthcare to demonstrate the utility of these new capabilities of LLMs, with particular emphasis on Generalized Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as an open-source LLM-GAM interface.
</details>
<details>
<summary>摘要</summary>
我们显示大型语言模型（LLM）可以非常好地与可解释模型（GAM）结合，将复杂的结果拆分为单一图表表示的分量。通过运用层次推理的方法，LLM可以提供完整的模型级别概要而不需要整个模型适应上下文。这种方法使得LLM可以自动应用它们广泛的背景知识来进行资料科学中常见的任务，例如检测资料过程中的问题，描述问题的可能原因，以及提出修复方案来解决问题。我们使用了多个医疗保健例子来证明这些新的LLM功能的用 utility，特别是适用于GAM。最后，我们提出了一个名为 $\texttt{TalkToEBM}$ 的开源 LLM-GAM 界面。
</details></li>
</ul>
<hr>
<h2 id="A-Transformer-based-Prediction-Method-for-Depth-of-Anesthesia-During-Target-controlled-Infusion-of-Propofol-and-Remifentanil"><a href="#A-Transformer-based-Prediction-Method-for-Depth-of-Anesthesia-During-Target-controlled-Infusion-of-Propofol-and-Remifentanil" class="headerlink" title="A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil"></a>A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01929">http://arxiv.org/abs/2308.01929</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/heeeyk/transformer-doa-prediction">https://github.com/heeeyk/transformer-doa-prediction</a></li>
<li>paper_authors: Yongkang He, Siyuan Peng, Mingjin Chen, Zhijing Yang, Yuanhui Chen</li>
<li>for: 预测麻醉效果的准确性是脊梁控制输液系统的关键。传统的PK-PD模型需要手动选择模型参数，在临床设置下可能具有挑战。现代深度学习方法可能只能捕捉总趋势，并不能预测麻醉 depth 的突然变化。</li>
<li>methods: 我们提议使用 transformer 网络来预测麻醉 depth，并使用 LSTM 和 GRN 网络来改进特征融合效率。我们还使用注意力机制来发现药物之间的交互关系。此外，我们使用标签分布平滑和重新权重损失来解决数据不均衡问题。</li>
<li>results: 我们的提议方法比传统 PK-PD 模型和先前的深度学习方法更高效地预测麻醉 depth，特别在突然的深度麻醉情况下。<details>
<summary>Abstract</summary>
Accurately predicting anesthetic effects is essential for target-controlled infusion systems. The traditional (PK-PD) models for Bispectral index (BIS) prediction require manual selection of model parameters, which can be challenging in clinical settings. Recently proposed deep learning methods can only capture general trends and may not predict abrupt changes in BIS. To address these issues, we propose a transformer-based method for predicting the depth of anesthesia (DOA) using drug infusions of propofol and remifentanil. Our method employs long short-term memory (LSTM) and gate residual network (GRN) networks to improve the efficiency of feature fusion and applies an attention mechanism to discover the interactions between the drugs. We also use label distribution smoothing and reweighting losses to address data imbalance. Experimental results show that our proposed method outperforms traditional PK-PD models and previous deep learning methods, effectively predicting anesthetic depth under sudden and deep anesthesia conditions.
</details>
<details>
<summary>摘要</summary>
Accurately predicting anesthetic effects is crucial for target-controlled infusion systems. Traditional PK-PD models for Bispectral index (BIS) prediction require manual selection of model parameters, which can be challenging in clinical settings. Recently proposed deep learning methods can only capture general trends and may not predict abrupt changes in BIS. To address these issues, we propose a transformer-based method for predicting the depth of anesthesia (DOA) using drug infusions of propofol and remifentanil. Our method employs long short-term memory (LSTM) and gate residual network (GRN) networks to improve the efficiency of feature fusion and applies an attention mechanism to discover the interactions between the drugs. We also use label distribution smoothing and reweighting losses to address data imbalance. Experimental results show that our proposed method outperforms traditional PK-PD models and previous deep learning methods, effectively predicting anesthetic depth under sudden and deep anesthesia conditions.Here's the text with some additional information about the Simplified Chinese translation:Simplified Chinese is a written version of Chinese that uses simplified characters and is commonly used in mainland China. In this translation, I have used Simplified Chinese characters to represent the text. However, it's worth noting that Traditional Chinese characters are also commonly used in Taiwan and other regions, and may be preferred in some contexts. Additionally, the translation is written in a formal, academic style, which may not be appropriate for all contexts. If you have any specific requests or preferences for the translation, please let me know and I will do my best to accommodate them.
</details></li>
</ul>
<hr>
<h2 id="DySTreSS-Dynamically-Scaled-Temperature-in-Self-Supervised-Contrastive-Learning"><a href="#DySTreSS-Dynamically-Scaled-Temperature-in-Self-Supervised-Contrastive-Learning" class="headerlink" title="DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning"></a>DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01140">http://arxiv.org/abs/2308.01140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siladittya Manna, Soumitri Chattopadhyay, Rakesh Dey, Saumik Bhattacharya, Umapada Pal</li>
<li>for: 提高自适应对SSL中InfoNCE损失的性能，研究InfoNCE损失中温度超参的影响。</li>
<li>methods: 提出了一种基于cosine相似性的温度扩展函数，并对uniformity和tolerance度量进行了分析，以便更好地优化分布在特征空间中。</li>
<li>results: 实验证明，提出的方法可以超过或与对比损失基本相同的SSL算法相当。认为该研究为后续对异性学习的研究提供了基础。<details>
<summary>Abstract</summary>
In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples from different classes is primarily affected by the presence of hard negative samples. While the InfoNCE loss has been shown to impose penalties based on hardness, the temperature hyper-parameter is the key to regulating the penalties and the trade-off between uniformity and tolerance. In this work, we focus our attention to improve the performance of InfoNCE loss in SSL by studying the effect of temperature hyper-parameter values. We propose a cosine similarity-dependent temperature scaling function to effectively optimize the distribution of the samples in the feature space. We further analyze the uniformity and tolerance metrics to investigate the optimal regions in the cosine similarity space for better optimization. Additionally, we offer a comprehensive examination of the behavior of local and global structures in the feature space throughout the pre-training phase, as the temperature varies. Experimental evidence shows that the proposed framework outperforms or is at par with the contrastive loss-based SSL algorithms. We believe our work (DySTreSS) on temperature scaling in SSL provides a foundation for future research in contrastive learning.
</details>
<details>
<summary>摘要</summary>
现代自我超vised contrastive算法如SimCLR、MoCo等，任务是让两个semantically similar sample之间吸引，而两个不同类型的sample之间冲突。而这个任务主要受到强度负样本的影响。InfoNCE损失已经显示出对强度做出了罚款，但是温度超参数是控制这些罚款和吸引与耐受之间的折衔。在这项工作中，我们专注于改进InfoNCE损失在SSL中的性能，研究温度超参数的效果。我们提议一个cosine similarity-dependent温度缩放函数，可以有效地优化样本在特征空间的分布。我们进一步分析了uniformity和tolerance指标，以查找最佳的cosine similarity空间区域，以便更好地优化。此外，我们还对批处和全局结构在特征空间中的变化，随着温度的变化，进行了详细的分析。实验证明，我们提出的框架（DySTreSS）在SSL中的性能比或与基于contrastive损失的SSL算法相当。我们认为我们的工作在SSL中的温度缩放（DySTreSS）提供了一个基础 для未来的对冲学习的研究。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Privacy-Allocation-for-Locally-Differentially-Private-Federated-Learning-with-Composite-Objectives"><a href="#Dynamic-Privacy-Allocation-for-Locally-Differentially-Private-Federated-Learning-with-Composite-Objectives" class="headerlink" title="Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives"></a>Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01139">http://arxiv.org/abs/2308.01139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaojiao Zhang, Dominik Fay, Mikael Johansson</li>
<li>for: 本研究提出了一种用于强Converter convex但可能不连续问题的本地差分隐私联合学习算法，保护每名工作者的梯度 Against an honest but curious server.</li>
<li>methods: 提出的算法在共享信息中添加人工噪声以确保隐私，并动态分配时变 noise variance来最小化优化错误的上限，以满足先前定义的隐私预算限制。</li>
<li>results: 数值结果表明，提出的算法在比较 estado-of-the-art方法的基础上具有更高的超越性和隐私保护能力，可以在一个适当的隐私预算下实现更高的优化质量。<details>
<summary>Abstract</summary>
This paper proposes a locally differentially private federated learning algorithm for strongly convex but possibly nonsmooth problems that protects the gradients of each worker against an honest but curious server. The proposed algorithm adds artificial noise to the shared information to ensure privacy and dynamically allocates the time-varying noise variance to minimize an upper bound of the optimization error subject to a predefined privacy budget constraint. This allows for an arbitrarily large but finite number of iterations to achieve both privacy protection and utility up to a neighborhood of the optimal solution, removing the need for tuning the number of iterations. Numerical results show the superiority of the proposed algorithm over state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
（本文提出了一种地域分ifferentially private的联合学习算法，用于保护每个工作者的梯度 against an honest but curious server。该算法在共享信息中添加了人工噪声以保障隐私，并在时间变化的噪声方差中动态分配时间变化的噪声方差以最小化优化误差的Upper bound，以达到一定的隐私预算限制。这使得可以在一个finite但countlessiterations中实现隐私保护和实用性，从而消除调整iterations的需求。numerical results show that the proposed algorithm outperforms existing methods。）
</details></li>
</ul>
<hr>
<h2 id="Can-We-Transfer-Noise-Patterns-A-Multi-environment-Spectrum-Analysis-Model-Using-Generated-Cases"><a href="#Can-We-Transfer-Noise-Patterns-A-Multi-environment-Spectrum-Analysis-Model-Using-Generated-Cases" class="headerlink" title="Can We Transfer Noise Patterns? A Multi-environment Spectrum Analysis Model Using Generated Cases"></a>Can We Transfer Noise Patterns? A Multi-environment Spectrum Analysis Model Using Generated Cases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01138">http://arxiv.org/abs/2308.01138</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/magnomic/cnst">https://github.com/magnomic/cnst</a></li>
<li>paper_authors: Haiwen Du, Zheng Ju, Yu An, Honghui Du, Dongjie Zhu, Zhaoshuo Tian, Aonghus Lawlor, Ruihai Dong</li>
<li>for: 这个研究旨在提高在线水质测试中的 спектル分析系统，以检测污染物的类型和浓度，并帮助管理机关对污染事件作出迅速回应。</li>
<li>methods: 本研究提出了一个噪音传播模型，可以将噪音模式传递到不同环境中的标准水样本上，并将这些噪音模式转换到未知标准水样本上，以提高分析模型的可行性。</li>
<li>results: 实验结果显示，提案的方法可以对比基准系统（包括波лет残减、深度神经网络和生成模型）进行比较，在不同背景噪音下表现出良好的噪音传播能力。<details>
<summary>Abstract</summary>
Spectrum analysis systems in online water quality testing are designed to detect types and concentrations of pollutants and enable regulatory agencies to respond promptly to pollution incidents. However, spectral data-based testing devices suffer from complex noise patterns when deployed in non-laboratory environments. To make the analysis model applicable to more environments, we propose a noise patterns transferring model, which takes the spectrum of standard water samples in different environments as cases and learns the differences in their noise patterns, thus enabling noise patterns to transfer to unknown samples. Unfortunately, the inevitable sample-level baseline noise makes the model unable to obtain the paired data that only differ in dataset-level environmental noise. To address the problem, we generate a sample-to-sample case-base to exclude the interference of sample-level noise on dataset-level noise learning, enhancing the system's learning performance. Experiments on spectral data with different background noises demonstrate the good noise-transferring ability of the proposed method against baseline systems ranging from wavelet denoising, deep neural networks, and generative models. From this research, we posit that our method can enhance the performance of DL models by generating high-quality cases. The source code is made publicly available online at https://github.com/Magnomic/CNST.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation) spectral analysis systems in online water quality testing 是为检测污染物种和浓度，并帮助管理机构快速应对污染事件。然而，基于spectrum数据的测试设备在非实验室环境中会出现复杂的噪声模式。为了使分析模型适用于更多环境，我们提议一种噪声模式传递模型，该模型通过学习不同环境中标准水样的spectrum的差异，以便将噪声模式传递到未知样本。然而，不可避免的样本水平噪声使得模型无法获得只有数据aset级噪声的对照数据。为解决问题，我们生成了样本到样本的case基，以排除样本水平噪声对数据aset级噪声学习的干扰。实验结果表明，我们的方法可以减少对比基线方法（包括wavelet denoising、深度神经网络和生成模型）的干扰，提高系统学习性能。从这项研究中，我们认为我们的方法可以提高DL模型的性能，通过生成高质量的case。源代码已经在https://github.com/Magnomic/CNST上公开。
</details></li>
</ul>
<hr>
<h2 id="Multi-task-learning-for-classification-segmentation-reconstruction-and-detection-on-chest-CT-scans"><a href="#Multi-task-learning-for-classification-segmentation-reconstruction-and-detection-on-chest-CT-scans" class="headerlink" title="Multi-task learning for classification, segmentation, reconstruction, and detection on chest CT scans"></a>Multi-task learning for classification, segmentation, reconstruction, and detection on chest CT scans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01137">http://arxiv.org/abs/2308.01137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weronika Hryniewska-Guzik, Maria Kędzierska, Przemysław Biecek</li>
<li>for: 这个研究是为了提高肺癌和COVID-19的诊断和预后预测。</li>
<li>methods: 这个研究使用了多任务学习方法，把肺癌鉴别、分类、重建和检测作为多个任务，以提高医疗资料的抽象和普遍化。</li>
<li>results: 这个研究获得了肺癌鉴别、分类、重建和检测的良好结果，并且是首个在多任务解决方案中添加检测任务的研究。<details>
<summary>Abstract</summary>
Lung cancer and covid-19 have one of the highest morbidity and mortality rates in the world. For physicians, the identification of lesions is difficult in the early stages of the disease and time-consuming. Therefore, multi-task learning is an approach to extracting important features, such as lesions, from small amounts of medical data because it learns to generalize better. We propose a novel multi-task framework for classification, segmentation, reconstruction, and detection. To the best of our knowledge, we are the first ones who added detection to the multi-task solution. Additionally, we checked the possibility of using two different backbones and different loss functions in the segmentation task.
</details>
<details>
<summary>摘要</summary>
肺癌和 COVID-19 在全球具有非常高的疾病率和死亡率。为医生而言，在疾病的早期阶段标识病变很困难和时间消耗。因此，多任务学习是一种提取重要特征，如病变，从小量医疗数据中提取特征的方法，因为它可以更好地泛化。我们提议一种新的多任务框架，用于分类、 segmentation、重建和检测。根据我们所知，我们是第一个将检测添加到多任务解决方案中的人。此外，我们还检查了使用不同的背景和损失函数在 segmentation 任务中的可能性。
</details></li>
</ul>
<hr>
<h2 id="Unlearning-Spurious-Correlations-in-Chest-X-ray-Classification"><a href="#Unlearning-Spurious-Correlations-in-Chest-X-ray-Classification" class="headerlink" title="Unlearning Spurious Correlations in Chest X-ray Classification"></a>Unlearning Spurious Correlations in Chest X-ray Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01119">http://arxiv.org/abs/2308.01119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Misgina Tsighe Hagos, Kathleen M. Curran, Brian Mac Namee</li>
<li>for: 这个论文的目的是为了提高医疗图像分类模型的可靠性和透明度，并解决跨数据源集合中的隐藏关系问题。</li>
<li>methods: 这个论文使用了一种基于 Covid-19 胸部X射线图像的深度学习模型，并使用了一种基于用户反馈的交互式解释学习（XBL）方法来解决隐藏关系问题。</li>
<li>results: 研究发现，通过使用 XBL 方法可以有效地消除隐藏关系，从而提高模型的准确率和透明度。<details>
<summary>Abstract</summary>
Medical image classification models are frequently trained using training datasets derived from multiple data sources. While leveraging multiple data sources is crucial for achieving model generalization, it is important to acknowledge that the diverse nature of these sources inherently introduces unintended confounders and other challenges that can impact both model accuracy and transparency. A notable confounding factor in medical image classification, particularly in musculoskeletal image classification, is skeletal maturation-induced bone growth observed during adolescence. We train a deep learning model using a Covid-19 chest X-ray dataset and we showcase how this dataset can lead to spurious correlations due to unintended confounding regions. eXplanation Based Learning (XBL) is a deep learning approach that goes beyond interpretability by utilizing model explanations to interactively unlearn spurious correlations. This is achieved by integrating interactive user feedback, specifically feature annotations. In our study, we employed two non-demanding manual feedback mechanisms to implement an XBL-based approach for effectively eliminating these spurious correlations. Our results underscore the promising potential of XBL in constructing robust models even in the presence of confounding factors.
</details>
<details>
<summary>摘要</summary>
医疗图像分类模型经常使用多种数据源进行训练。虽然利用多种数据源对模型泛化有益，但是需要注意这些来源的多样性自然会引入无意义的混合因素和其他挑战，这些挑战可能会影响模型准确性和透明度。在医疗图像分类中，特别是在骨骼成像中，生长induced by skeletal maturation during adolescence是一个明显的混合因素。我们使用COVID-19胸部X射线数据集训练深度学习模型，并显示这些数据集可能会导致不必要的相关性。基于解释的学习（XBL）是一种深度学习方法，它不仅提供了解释，还可以通过交互式的用户反馈来解除不必要的相关性。我们使用了两种不需要高度技术知识的手动反馈机制来实现XBL基于的方法。我们的结果表明XBL在混合因素存在时可以建立可靠的模型。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Popularity-Bias-in-Recommender-Systems"><a href="#A-Survey-on-Popularity-Bias-in-Recommender-Systems" class="headerlink" title="A Survey on Popularity Bias in Recommender Systems"></a>A Survey on Popularity Bias in Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01118">http://arxiv.org/abs/2308.01118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anastasiia Klimashevskaia, Dietmar Jannach, Mehdi Elahi, Christoph Trattner</li>
<li>for: 本研究旨在探讨推荐系统中偏好媒体文件的问题，以及如何探测、评估和缓解这种偏好。</li>
<li>methods: 本文评论了现有的推荐算法是如何导致媒体文件的偏好问题，并提出了一些方法来探测、评估和缓解这种偏好。</li>
<li>results: 本文发现现有的推荐算法在很多情况下会导致媒体文件的偏好问题，这可能会导致推荐的价值受到限制，并可能在长期内产生不良的循环效应。<details>
<summary>Abstract</summary>
Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discuss today's literature, where we observe that the research is almost entirely based on computational experiments and on certain assumptions regarding the practical effects of including long-tail items in the recommendations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Spatio-Temporal-Branching-for-Motion-Prediction-using-Motion-Increments"><a href="#Spatio-Temporal-Branching-for-Motion-Prediction-using-Motion-Increments" class="headerlink" title="Spatio-Temporal Branching for Motion Prediction using Motion Increments"></a>Spatio-Temporal Branching for Motion Prediction using Motion Increments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01097">http://arxiv.org/abs/2308.01097</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jasonwang959/stpmp">https://github.com/jasonwang959/stpmp</a></li>
<li>paper_authors: Jiexin Wang, Yujie Zhou, Wenwen Qiang, Ying Ba, Bing Su, Ji-Rong Wen</li>
<li>for: 人体动作预测 (HMP) 是一个流行的研究领域，但是它仍然是一个具有杂乱和不规则性的任务，尤其是将来的姿势预测。传统方法通常使用手工设计的特征和机器学习技术，这些技术经常难以捕捉人体动作的复杂动态。</li>
<li>methods: 我们提出了一种新的空间temporal分支网络方法，使得各个节点之间的时间和空间关系得到了更好的利用。我们通过知识储存技术来实现域知识储存和跨频率学习。</li>
<li>results: 我们的方法在标准HMP测试集上进行评估，并与当前最佳方法进行比较。我们发现，我们的方法可以更好地降低噪声干扰，并提供更多的动作特征来Characterize人体动作。<details>
<summary>Abstract</summary>
Human motion prediction (HMP) has emerged as a popular research topic due to its diverse applications, but it remains a challenging task due to the stochastic and aperiodic nature of future poses. Traditional methods rely on hand-crafted features and machine learning techniques, which often struggle to model the complex dynamics of human motion. Recent deep learning-based methods have achieved success by learning spatio-temporal representations of motion, but these models often overlook the reliability of motion data. Additionally, the temporal and spatial dependencies of skeleton nodes are distinct. The temporal relationship captures motion information over time, while the spatial relationship describes body structure and the relationships between different nodes. In this paper, we propose a novel spatio-temporal branching network using incremental information for HMP, which decouples the learning of temporal-domain and spatial-domain features, extracts more motion information, and achieves complementary cross-domain knowledge learning through knowledge distillation. Our approach effectively reduces noise interference and provides more expressive information for characterizing motion by separately extracting temporal and spatial features. We evaluate our approach on standard HMP benchmarks and outperform state-of-the-art methods in terms of prediction accuracy.
</details>
<details>
<summary>摘要</summary>
人体运动预测（HMP）已经成为一个受欢迎的研究主题，因为它在多个应用领域有广泛的应用前景。然而，HMP仍然是一个具有抽象和不规则的未来姿势的挑战。传统的方法通常采用手动设计的特征和机器学习技术，经常难以模型人体运动的复杂动力学。现代深度学习基于的方法在学习人体运动的空间-时间表示方面取得了成功，但这些模型经常忽略人体运动数据的可靠性。此外，人体运动中的时间和空间关系不同。时间关系捕捉人体运动的时间信息，而空间关系描述人体结构和不同节点之间的关系。在这篇论文中，我们提出了一种新的空间-时间分支网络，使用增量信息来进行HMP，这种方法可以分离学习时间Domain和空间Domain的特征，提取更多的运动信息，并通过知识储存来实现补做cross-domain知识学习。我们的方法可以减少噪声干扰和提供更多的表达信息，以便更好地描述运动。我们在标准HMP测试benchmark上评估了我们的方法，并在预测精度方面超过了当前的状态艺术方法。
</details></li>
</ul>
<hr>
<h2 id="Multi-variable-Hard-Physical-Constraints-for-Climate-Model-Downscaling"><a href="#Multi-variable-Hard-Physical-Constraints-for-Climate-Model-Downscaling" class="headerlink" title="Multi-variable Hard Physical Constraints for Climate Model Downscaling"></a>Multi-variable Hard Physical Constraints for Climate Model Downscaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01868">http://arxiv.org/abs/2308.01868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jose González-Abad, Álex Hernández-García, Paula Harder, David Rolnick, José Manuel Gutiérrez</li>
<li>for: 实现地方气候变化的影响和演化，Global Climate Models (GCMs) 是主要工具。</li>
<li>methods: 使用深度学习统计下降法，将粗糙空间解析的气候变化转换为本地规模的气候场。</li>
<li>results: 这种方法可以确保气候变化的本地规模预测的准确性，但是通常只是单一气候变量的独立下降。这种研究探讨了这个问题的范围和解决方案。<details>
<summary>Abstract</summary>
Global Climate Models (GCMs) are the primary tool to simulate climate evolution and assess the impacts of climate change. However, they often operate at a coarse spatial resolution that limits their accuracy in reproducing local-scale phenomena. Statistical downscaling methods leveraging deep learning offer a solution to this problem by approximating local-scale climate fields from coarse variables, thus enabling regional GCM projections. Typically, climate fields of different variables of interest are downscaled independently, resulting in violations of fundamental physical properties across interconnected variables. This study investigates the scope of this problem and, through an application on temperature, lays the foundation for a framework introducing multi-variable hard constraints that guarantees physical relationships between groups of downscaled climate variables.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Homography-Estimation-in-Complex-Topological-Scenes"><a href="#Homography-Estimation-in-Complex-Topological-Scenes" class="headerlink" title="Homography Estimation in Complex Topological Scenes"></a>Homography Estimation in Complex Topological Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01086">http://arxiv.org/abs/2308.01086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giacomo D’Amicantonio, Egor Bondarau, Peter H. N. De With</li>
<li>for: 这篇论文主要用于提出一种自动化摄像头卡利ibration过程，以便更好地处理环境变化和小型摄像头运动对摄像头卡利ibration的影响。</li>
<li>methods: 该方法使用了一个自定义的空间变换网络（STN）和一种新的topological损失函数，不需要任何相机设置的先验知识。</li>
<li>results: 实验表明，提议的方法可以提高IoU指标（相对于一个状态对照模型），在五个 sintetic dataset和2014年世界杯 dataset上提高IoU指标达12%。<details>
<summary>Abstract</summary>
Surveillance videos and images are used for a broad set of applications, ranging from traffic analysis to crime detection. Extrinsic camera calibration data is important for most analysis applications. However, security cameras are susceptible to environmental conditions and small camera movements, resulting in a need for an automated re-calibration method that can account for these varying conditions. In this paper, we present an automated camera-calibration process leveraging a dictionary-based approach that does not require prior knowledge on any camera settings. The method consists of a custom implementation of a Spatial Transformer Network (STN) and a novel topological loss function. Experiments reveal that the proposed method improves the IoU metric by up to 12% w.r.t. a state-of-the-art model across five synthetic datasets and the World Cup 2014 dataset.
</details>
<details>
<summary>摘要</summary>
侦查视频和图像可以用于各种应用程序，从交通分析到犯罪检测。外部摄像头准备数据非常重要，但安全摄像头受到环境因素和小型摄像头运动的影响，需要一种自动重新准确方法，能够考虑这些不同的条件。本文提出了一种基于词典方法的自动摄像头准确过程，不需要任何摄像头设置的先验知识。该方法包括一个自定义的空间变换网络（STN）和一个新的topological损失函数。实验表明，提议的方法可以提高IoU指标（相对于状态静态模型），在五个人工数据集和2014年世界杯数据集上提高IoU指标达12%。
</details></li>
</ul>
<hr>
<h2 id="Data-Driven-Identification-of-Quadratic-Symplectic-Representations-of-Nonlinear-Hamiltonian-Systems"><a href="#Data-Driven-Identification-of-Quadratic-Symplectic-Representations-of-Nonlinear-Hamiltonian-Systems" class="headerlink" title="Data-Driven Identification of Quadratic Symplectic Representations of Nonlinear Hamiltonian Systems"></a>Data-Driven Identification of Quadratic Symplectic Representations of Nonlinear Hamiltonian Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01084">http://arxiv.org/abs/2308.01084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Süleyman Yildiz, Pawan Goyal, Thomas Bendokat, Peter Benner</li>
<li>for: 学习哈密顿系统使用数据</li>
<li>methods: 使用生成函数和自动编码器来学习 quadratic 动力学系统，保持哈密顿结构，并使用高阶变量系统来解决高维数据问题</li>
<li>results: 提出了一种基于生成函数和自动编码器的方法来学习哈密顿系统，并实现了系统的长期稳定性和低模型复杂性In English:</li>
<li>for: Learning Hamiltonian systems using data</li>
<li>methods: Using a generating function and a symplectic autoencoder to learn quadratic dynamical systems that preserve the Hamiltonian structure, and using high-order variable systems to solve high-dimensional data problems</li>
<li>results: Proposed a method based on generating functions and symplectic autoencoders to learn Hamiltonian systems, and achieved long-term stability and low model complexity of the system.<details>
<summary>Abstract</summary>
We present a framework for learning Hamiltonian systems using data. This work is based on the lifting hypothesis, which posits that nonlinear Hamiltonian systems can be written as nonlinear systems with cubic Hamiltonians. By leveraging this, we obtain quadratic dynamics that are Hamiltonian in a transformed coordinate system. To that end, for given generalized position and momentum data, we propose a methodology to learn quadratic dynamical systems, enforcing the Hamiltonian structure in combination with a symplectic auto-encoder. The enforced Hamiltonian structure exhibits long-term stability of the system, while the cubic Hamiltonian function provides relatively low model complexity. For low-dimensional data, we determine a higher-order transformed coordinate system, whereas, for high-dimensional data, we find a lower-order coordinate system with the desired properties. We demonstrate the proposed methodology by means of both low-dimensional and high-dimensional nonlinear Hamiltonian systems.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于数据学习哈密顿系统的框架。这项工作基于升降 гипотезы，即非线性哈密顿系统可以写作非线性系统的立方函数哈密顿。通过这种方式，我们得到了各自协调的quadratic动力学，并且在变换坐标系中强制实施哈密顿结构。为此，我们提议一种基于泛函和自动编码器的方法，用于学习哈密顿系统，并在数据的总体稳定性和立方函数哈密顿函数的模型简单性之间进行权衡。在低维数据时，我们可以找到更高阶的变换坐标系，而在高维数据时，我们可以找到一个较低阶的坐标系，满足需求。我们通过低维和高维非线性哈密顿系统的示例来证明这种方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="A-Practical-Deep-Learning-Based-Acoustic-Side-Channel-Attack-on-Keyboards"><a href="#A-Practical-Deep-Learning-Based-Acoustic-Side-Channel-Attack-on-Keyboards" class="headerlink" title="A Practical Deep Learning-Based Acoustic Side Channel Attack on Keyboards"></a>A Practical Deep Learning-Based Acoustic Side Channel Attack on Keyboards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01074">http://arxiv.org/abs/2308.01074</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JBFH-Dev/Keystroke-Datasets">https://github.com/JBFH-Dev/Keystroke-Datasets</a></li>
<li>paper_authors: Joshua Harrison, Ehsan Toreini, Maryam Mehrnezhad</li>
<li>for: 防止键盘攻击（keyboard attacks）</li>
<li>methods: 使用深度学习模型和smartphone搭载的 Mikrofon记录键盘输入</li>
<li>results: 95%的准确率（最高精度）和93%的准确率（via Zoom视频会议软件）<details>
<summary>Abstract</summary>
With recent developments in deep learning, the ubiquity of micro-phones and the rise in online services via personal devices, acoustic side channel attacks present a greater threat to keyboards than ever. This paper presents a practical implementation of a state-of-the-art deep learning model in order to classify laptop keystrokes, using a smartphone integrated microphone. When trained on keystrokes recorded by a nearby phone, the classifier achieved an accuracy of 95%, the highest accuracy seen without the use of a language model. When trained on keystrokes recorded using the video-conferencing software Zoom, an accuracy of 93% was achieved, a new best for the medium. Our results prove the practicality of these side channel attacks via off-the-shelf equipment and algorithms. We discuss a series of mitigation methods to protect users against these series of attacks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Automatic-Feature-Engineering-for-Time-Series-Classification-Evaluation-and-Discussion"><a href="#Automatic-Feature-Engineering-for-Time-Series-Classification-Evaluation-and-Discussion" class="headerlink" title="Automatic Feature Engineering for Time Series Classification: Evaluation and Discussion"></a>Automatic Feature Engineering for Time Series Classification: Evaluation and Discussion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01071">http://arxiv.org/abs/2308.01071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aurélien Renault, Alexis Bondu, Vincent Lemaire, Dominique Gay</li>
<li>for: 本研究的目的是评估现有的特征工程工具在时间序列分类问题中的潜在预测性能。</li>
<li>methods: 本研究使用了11种特征工程工具，并与9种超参数化分类器结合使用，对112个时间序列数据集进行了10000多个学习实验。</li>
<li>results: 结果显示，基于特征的方法与当前状态艺术时间序列分类算法的准确率相当，因此应该在时间序列分类领域进一步考虑。<details>
<summary>Abstract</summary>
Time Series Classification (TSC) has received much attention in the past two decades and is still a crucial and challenging problem in data science and knowledge engineering. Indeed, along with the increasing availability of time series data, many TSC algorithms have been suggested by the research community in the literature. Besides state-of-the-art methods based on similarity measures, intervals, shapelets, dictionaries, deep learning methods or hybrid ensemble methods, several tools for extracting unsupervised informative summary statistics, aka features, from time series have been designed in the recent years. Originally designed for descriptive analysis and visualization of time series with informative and interpretable features, very few of these feature engineering tools have been benchmarked for TSC problems and compared with state-of-the-art TSC algorithms in terms of predictive performance. In this article, we aim at filling this gap and propose a simple TSC process to evaluate the potential predictive performance of the feature sets obtained with existing feature engineering tools. Thus, we present an empirical study of 11 feature engineering tools branched with 9 supervised classifiers over 112 time series data sets. The analysis of the results of more than 10000 learning experiments indicate that feature-based methods perform as accurately as current state-of-the-art TSC algorithms, and thus should rightfully be considered further in the TSC literature.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="When-Analytic-Calculus-Cracks-AdaBoost-Code"><a href="#When-Analytic-Calculus-Cracks-AdaBoost-Code" class="headerlink" title="When Analytic Calculus Cracks AdaBoost Code"></a>When Analytic Calculus Cracks AdaBoost Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01070">http://arxiv.org/abs/2308.01070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jean-Marc Brossier, Olivier Lafitte, Lenny Réthoré</li>
<li>for: 这个论文主要是为了探讨AdaBoost算法的准确性和优化性。</li>
<li>methods: 本论文使用了多个弱分类器的组合方法来构建一个更强的分类器。</li>
<li>results: 研究发现，AdaBoost算法不是一个真正的优化算法，而是可以通过 truth table 直接计算出最终的分类结果。 compared with scikit-learn中实现的AdaBoost算法，本研究的结果表明了这种方法的准确性和效率。<details>
<summary>Abstract</summary>
The principle of boosting in supervised learning involves combining multiple weak classifiers to obtain a stronger classifier. AdaBoost has the reputation to be a perfect example of this approach. We have previously shown that AdaBoost is not truly an optimization algorithm. This paper shows that AdaBoost is an algorithm in name only, as the resulting combination of weak classifiers can be explicitly calculated using a truth table. This study is carried out by considering a problem with two classes and is illustrated by the particular case of three binary classifiers and presents results in comparison with those from the implementation of AdaBoost algorithm of the Python library scikit-learn.
</details>
<details>
<summary>摘要</summary>
“boosting”在超级vised学习中的原则是将多个弱分类器组合成一个更强的分类器。阿达Boost是这种方法的典型示例。我们之前已经证明了阿达Boost不是一个优化算法。这篇论文表明，阿达Boost并不是一个真正的算法，因为将弱分类器组合的结果可以由真理表来直接计算。本研究通过考虑两个类别问题，使用三个二进制分类器进行示例，并与scikit-learnPython库中实现的阿达Boost算法相比较。
</details></li>
</ul>
<hr>
<h2 id="Graph-Anomaly-Detection-at-Group-Level-A-Topology-Pattern-Enhanced-Unsupervised-Approach"><a href="#Graph-Anomaly-Detection-at-Group-Level-A-Topology-Pattern-Enhanced-Unsupervised-Approach" class="headerlink" title="Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach"></a>Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01063">http://arxiv.org/abs/2308.01063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xing Ai, Jialong Zhou, Yulin Zhu, Gaolei Li, Tomasz P. Michalak, Xiapu Luo, Kai Zhou<br>for:This paper focuses on the task of Group-level Graph Anomaly Detection (Gr-GAD), which aims to identify and localize anomalous groups within a graph.methods:The proposed framework uses a variant of Graph AutoEncoder (GAE) to locate anchor nodes that belong to potential anomaly groups, and then employs group sampling and Topology Pattern-based Graph Contrastive Learning (TPGCL) to identify and localize anomaly groups.results:The experimental results on both real-world and synthetic datasets demonstrate that the proposed framework shows superior performance in identifying and localizing anomaly groups, highlighting it as a promising solution for Gr-GAD.<details>
<summary>Abstract</summary>
Graph anomaly detection (GAD) has achieved success and has been widely applied in various domains, such as fraud detection, cybersecurity, finance security, and biochemistry. However, existing graph anomaly detection algorithms focus on distinguishing individual entities (nodes or graphs) and overlook the possibility of anomalous groups within the graph. To address this limitation, this paper introduces a novel unsupervised framework for a new task called Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework first employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that belong to potential anomaly groups by capturing long-range inconsistencies. Subsequently, group sampling is employed to sample candidate groups, which are then fed into the proposed Topology Pattern-based Graph Contrastive Learning (TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to generate embeddings for each candidate group and thus distinct anomaly groups. The experimental results on both real-world and synthetic datasets demonstrate that the proposed framework shows superior performance in identifying and localizing anomaly groups, highlighting it as a promising solution for Gr-GAD. Datasets and codes of the proposed framework are at the github repository https://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.
</details>
<details>
<summary>摘要</summary>
“图像异常检测（GAD）已经取得成功并广泛应用于不同领域，如诈骗检测、网络安全、金融安全和生物化学。然而，现有的图像异常检测算法偏向异常个体（节点或图），忽略图中异常群体的可能性。为了解决这种限制，本文提出了一种新的无监督框架，称为群体级图像异常检测（Gr-GAD）。提案的框架首先使用变体的图自编码器（GAE）来确定异常群体的担 anchor节点，并capture长距离不一致性。然后，群体采样被使用来采样候选组，并将其feed到提案的图Pattern-based Graph Contrastive Learning（TPGCL）方法。TPGCL利用组 topology patterns作为特征来生成每个候选组的嵌入，从而分辨细节异常群体。实验结果表明，提案的框架在真实世界和 sintetic 数据集上具有优秀的异常组检测和定位能力，这得出了一个有前途的解决方案。数据集和代码可以在 GitHub 仓库 https://anonymous.4open.science/r/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection 中找到。”Note: The translation is in Simplified Chinese, which is the most widely used standard for Chinese writing. The translation is based on the official translation of the text into Simplified Chinese, and the word order and grammar may be different from the original text in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Simulation-based-inference-using-surjective-sequential-neural-likelihood-estimation"><a href="#Simulation-based-inference-using-surjective-sequential-neural-likelihood-estimation" class="headerlink" title="Simulation-based inference using surjective sequential neural likelihood estimation"></a>Simulation-based inference using surjective sequential neural likelihood estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01054">http://arxiv.org/abs/2308.01054</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dirmeier/ssnl">https://github.com/dirmeier/ssnl</a></li>
<li>paper_authors: Simon Dirmeier, Carlo Albert, Fernando Perez-Cruz</li>
<li>for: 该论文主要用于 simulation-based inference 领域，特别是在模型评估不可靠，只有一个可生成假数据的 simulator 存在的情况下。</li>
<li>methods: 该方法使用Surjective Sequential Neural Likelihood（SSNL）来实现 simulation-based inference，包括一个维度减少的射影正常分布模型，用于代替可评估的几何函数。可以使用 Markov chain Monte Carlo 方法或变量插入法进行 Bayesian 推断。</li>
<li>results: 作者在多种实验中证明了 SSNL 比现有的likelihood-based方法在高维数据集上表现更好，特别是在一个具有astrophysics 应用的实际例子中，模拟太阳magnetic field strength 的 solar dynamo 模型。<details>
<summary>Abstract</summary>
We present Surjective Sequential Neural Likelihood (SSNL) estimation, a novel method for simulation-based inference in models where the evaluation of the likelihood function is not tractable and only a simulator that can generate synthetic data is available. SSNL fits a dimensionality-reducing surjective normalizing flow model and uses it as a surrogate likelihood function which allows for conventional Bayesian inference using either Markov chain Monte Carlo methods or variational inference. By embedding the data in a low-dimensional space, SSNL solves several issues previous likelihood-based methods had when applied to high-dimensional data sets that, for instance, contain non-informative data dimensions or lie along a lower-dimensional manifold. We evaluate SSNL on a wide variety of experiments and show that it generally outperforms contemporary methods used in simulation-based inference, for instance, on a challenging real-world example from astrophysics which models the magnetic field strength of the sun using a solar dynamo model.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的Sequential Neural Likelihood（SSNL）估计方法，用于基于模拟的推断，其中只有一个可以生成假数据的 simulate器，但是evaluate the likelihood function的计算不可 tractable。SSNL采用了一种维度减少的射影正则化模型，并使其作为媒介假概率函数，以便使用Conventional Bayesian inference方法，如Markov chain Monte Carlo方法或variational inference。通过嵌入数据到低维度空间中，SSNL解决了之前基于概率函数的方法在高维度数据集中遇到的许多问题，例如非指导性数据维度或在低维度抽象上的扩展。我们在多种实验中评估了SSNL，并发现它通常比当前的基于模拟的推断方法高效，例如在一个实际的astrophysics例子中，模拟太阳magnetic field strength的solar dynamo模型。
</details></li>
</ul>
<hr>
<h2 id="A-Counterfactual-Safety-Margin-Perspective-on-the-Scoring-of-Autonomous-Vehicles’-Riskiness"><a href="#A-Counterfactual-Safety-Margin-Perspective-on-the-Scoring-of-Autonomous-Vehicles’-Riskiness" class="headerlink" title="A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles’ Riskiness"></a>A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles’ Riskiness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01050">http://arxiv.org/abs/2308.01050</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Zanardi, Andrea Censi, Margherita Atzei, Luigi Di Lillo, Emilio Frazzoli</li>
<li>For: This paper aims to provide a data-driven framework for comparing the risk of different autonomous vehicles (AVs) in various operational design domains (ODDs).* Methods: The paper uses counterfactual simulations of “misbehaving” road users to assess the risk of AVs. The concept of counterfactual safety margin is introduced, which represents the minimum deviation from normal behavior that could lead to a collision. The methodology is applicable even when the AV’s behavioral policy is unknown.* Results: The experimental results demonstrate the correlation between the safety margin, the driving policy quality, and the ODD, shedding light on the relative risk associated with different AV providers. The work contributes to AV safety assessment and addresses legislative and insurance concerns surrounding this emerging technology.Here is the same information in Simplified Chinese text:* For: 这篇论文旨在提供一种数据驱动的自动驾驶车（AV）在各种操作设计域（ODD）中的风险比较框架。* Methods: 论文使用“不良”道路用户的 counterfactual 模拟来评估 AV 的风险。该概念表示最小偏离正常行为的行为可能导致事故的最小差异。这种方法可以在 AV 行为策略不明确时进行应用。* Results: 实验结果显示了安全准备度、驾驶策略质量和 ODD 之间的相关性，揭示了不同 AV 提供商的相对风险水平。这项工作对自动驾驶车安全评估做出了贡献，并解决了立法和保险方面对这种新技术的关注。<details>
<summary>Abstract</summary>
Autonomous Vehicles (AVs) have the potential to provide numerous societal benefits, such as decreased road accidents and increased overall transportation efficiency. However, quantifying the risk associated with AVs is challenging due to the lack of historical data and the rapidly evolving technology. This paper presents a data-driven framework for comparing the risk of different AVs' behaviors in various operational design domains (ODDs), based on counterfactual simulations of "misbehaving" road users. We introduce the concept of counterfactual safety margin, which represents the minimum deviation from normal behavior that could lead to a collision. This concept helps to find the most critical scenarios but also to assess the frequency and severity of risk of AVs. We show that the proposed methodology is applicable even when the AV's behavioral policy is unknown -- through worst- and best-case analyses -- making the method useful also to external third-party risk assessors. Our experimental results demonstrate the correlation between the safety margin, the driving policy quality, and the ODD shedding light on the relative risk associated with different AV providers. This work contributes to AV safety assessment and aids in addressing legislative and insurance concerns surrounding this emerging technology.
</details>
<details>
<summary>摘要</summary>
Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the original text and may not capture all the nuances of the original language.
</details></li>
</ul>
<hr>
<h2 id="Are-Easy-Data-Easy-for-K-Means"><a href="#Are-Easy-Data-Easy-for-K-Means" class="headerlink" title="Are Easy Data Easy (for K-Means)"></a>Are Easy Data Easy (for K-Means)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01926">http://arxiv.org/abs/2308.01926</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sayantann11/all-classification-templetes-for-ML">https://github.com/sayantann11/all-classification-templetes-for-ML</a></li>
<li>paper_authors: Mieczysław A. Kłopotek</li>
<li>for: 这个论文 investigate $k$-means 算法是否可以正确地恢复良好分割的群集。</li>
<li>methods: 本论文使用了直接从通用定义cluster中得到的分割性定义，并 derivated conditions for a special case of well-separated clusters such that the global minimum of $k$-means cost function coincides with the well-separatedness。</li>
<li>results: 实验表明，$k$-means 算法不能correctly recover well-separated clusters。一种新的算法是 $k$-means++ via repeated {sub}sampling when choosing a seed，该算法在这个任务上表现更好。<details>
<summary>Abstract</summary>
This paper investigates the capability of correctly recovering well-separated clusters by various brands of the $k$-means algorithm. The concept of well-separatedness used here is derived directly from the common definition of clusters, which imposes an interplay between the requirements of within-cluster-homogenicity and between-clusters-diversity. Conditions are derived for a special case of well-separated clusters such that the global minimum of $k$-means cost function coincides with the well-separatedness. An experimental investigation is performed to find out whether or no various brands of $k$-means are actually capable of discovering well separated clusters. It turns out that they are not. A new algorithm is proposed that is a variation of $k$-means++ via repeated {sub}sampling when choosing a seed. The new algorithm outperforms four other algorithms from $k$-means family on the task.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Evaluation-of-network-guided-random-forest-for-disease-gene-discovery"><a href="#Evaluation-of-network-guided-random-forest-for-disease-gene-discovery" class="headerlink" title="Evaluation of network-guided random forest for disease gene discovery"></a>Evaluation of network-guided random forest for disease gene discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01323">http://arxiv.org/abs/2308.01323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianchang Hu, Silke Szymczak</li>
<li>for: 本研究旨在探讨Random Forest（RF）算法在基因表达数据分析中是否可以利用基因网络信息提高疾病预测性能。</li>
<li>methods: 研究者使用了一种基于网络信息的采样概率方法，将网络信息纳入RF构建中。</li>
<li>results: 研究结果表明，基于网络信息的RF不能提高疾病预测性能，但是在疾病基因发现方面，如果疾病基因组成模块， THEN 基于网络信息的RF可以更准确地预测疾病基因。此外，当疾病状况与基因在给定网络中无关时，使用网络信息时可能会产生干扰选择结果，特别是对于Hub基因。<details>
<summary>Abstract</summary>
Gene network information is believed to be beneficial for disease module and pathway identification, but has not been explicitly utilized in the standard random forest (RF) algorithm for gene expression data analysis. We investigate the performance of a network-guided RF where the network information is summarized into a sampling probability of predictor variables which is further used in the construction of the RF. Our results suggest that network-guided RF does not provide better disease prediction than the standard RF. In terms of disease gene discovery, if disease genes form module(s), network-guided RF identifies them more accurately. In addition, when disease status is independent from genes in the given network, spurious gene selection results can occur when using network information, especially on hub genes. Our empirical analysis on two balanced microarray and RNA-Seq breast cancer datasets from The Cancer Genome Atlas (TCGA) for classification of progesterone receptor (PR) status also demonstrates that network-guided RF can identify genes from PGR-related pathways, which leads to a better connected module of identified genes.
</details>
<details>
<summary>摘要</summary>
生物网络信息被认为对疾病模块和代谢通路的识别有利，但在标准随机森林（RF）算法中没有直接使用生物网络信息进行基因表达数据分析。我们研究了基于网络信息的随机森林（Network-guided RF），其中网络信息被概括为预测变量的抽样概率，并在随机森林的构建中使用。我们的结果表明，与标准RF相比，网络指导RF不提供更好的疾病预测。在疾病基因发现方面，如果疾病基因组成模块， тогда网络指导RF能够更准确地识别这些模块。此外，当疾病状况与生物网络中的基因独立时，使用网络信息可能会导致假阳性基因选择结果，特别是对于中心基因。我们对TCGA breast cancer数据集进行了empirical分析，并证明了网络指导RF可以识别PGR相关的基因路径，从而得到更好地连接的模块。
</details></li>
</ul>
<hr>
<h2 id="Computing-the-Distance-between-unbalanced-Distributions-–-The-flat-Metric"><a href="#Computing-the-Distance-between-unbalanced-Distributions-–-The-flat-Metric" class="headerlink" title="Computing the Distance between unbalanced Distributions – The flat Metric"></a>Computing the Distance between unbalanced Distributions – The flat Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01039">http://arxiv.org/abs/2308.01039</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hs42/flat_metric">https://github.com/hs42/flat_metric</a></li>
<li>paper_authors: Henri Schmidt, Christian Düll</li>
<li>for:  Computes the flat metric in any dimension for unbalanced optimal transport tasks and data analysis.</li>
<li>methods: Uses a neural network to determine an optimal test function for computing the distance between two given measures.</li>
<li>results: Achieves comparability of pairwise computed distances from independently trained networks and shows high quality output in experiments and simulations.<details>
<summary>Abstract</summary>
We provide an implementation to compute the flat metric in any dimension. The flat metric, also called dual bounded Lipschitz distance, generalizes the well-known Wasserstein distance W1 to the case that the distributions are of unequal total mass. This is of particular interest for unbalanced optimal transport tasks and for the analysis of data distributions where the sample size is important or normalization is not possible. The core of the method is based on a neural network to determine on optimal test function realizing the distance between two given measures. Special focus was put on achieving comparability of pairwise computed distances from independently trained networks. We tested the quality of the output in several experiments where ground truth was available as well as with simulated data.
</details>
<details>
<summary>摘要</summary>
我们提供了一个实现方式来计算任意维度的扁平度量。扁平度量，也称为双对称LIPschitz距离，将 Wasserstein距离W1扩展到分布是不均匀的情况下。这对不均匀优化运输和资料分布分析中具有特别的 interess。我们的方法靠在一个神经网络来决定两个给出的度量之间的距离。我们特别强调了独立训练的神经网络之间的比较可靠性。我们在一些实验中使用了实际的测试数据和伪实验数据进行测试。Note that Simplified Chinese is a romanization of Chinese, and the actual Chinese characters may be different.
</details></li>
</ul>
<hr>
<h2 id="Three-Factors-to-Improve-Out-of-Distribution-Detection"><a href="#Three-Factors-to-Improve-Out-of-Distribution-Detection" class="headerlink" title="Three Factors to Improve Out-of-Distribution Detection"></a>Three Factors to Improve Out-of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01030">http://arxiv.org/abs/2308.01030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunjun Choi, JaeHo Chung, Hawook Jeong, Jin Young Choi</li>
<li>for: 提高Out-of-distribution（OOD）检测和分类精度之间的质量负担。</li>
<li>methods: 使用辅助数据作为异常数据进行细化，并具有自知识整合、半硬样本选择和新的监督对比学习等三大贡献。</li>
<li>results: 三大贡献的结合，同时提高了OOD检测性能和分类精度，并且与之前的方法相比，提高了OOD检测性能和分类精度。<details>
<summary>Abstract</summary>
In the problem of out-of-distribution (OOD) detection, the usage of auxiliary data as outlier data for fine-tuning has demonstrated encouraging performance. However, previous methods have suffered from a trade-off between classification accuracy (ACC) and OOD detection performance (AUROC, FPR, AUPR). To improve this trade-off, we make three contributions: (i) Incorporating a self-knowledge distillation loss can enhance the accuracy of the network; (ii) Sampling semi-hard outlier data for training can improve OOD detection performance with minimal impact on accuracy; (iii) The introduction of our novel supervised contrastive learning can simultaneously improve OOD detection performance and the accuracy of the network. By incorporating all three factors, our approach enhances both accuracy and OOD detection performance by addressing the trade-off between classification and OOD detection. Our method achieves improvements over previous approaches in both performance metrics.
</details>
<details>
<summary>摘要</summary>
在 OUT-OF-DISTRIBUTION（OOD）探测问题中，使用辅助数据作为精度数据进行练习显示了激励人的性能。然而，先前的方法受到了准确率（ACC）和OOD探测性能（AUROC、FPR、AUPR）的负面影响。为了改进这种负面影响，我们提出了三个贡献：（i） incorporating self-knowledge distillation loss可以提高网络的准确率;（ii） 使用 semi-hard outlier 数据进行训练可以提高 OOD 探测性能，而不会影响准确率;（iii） 我们提出的新的超级vised contrastive learning可以同时提高 OOD 探测性能和网络的准确率。通过结合这三个因素，我们的方法可以同时改进准确率和 OOD 探测性能，解决了准确率和 OOD 探测性能之间的负面影响。我们的方法在两个性能指标上都取得了改进。
</details></li>
</ul>
<hr>
<h2 id="Maximizing-Success-Rate-of-Payment-Routing-using-Non-stationary-Bandits"><a href="#Maximizing-Success-Rate-of-Payment-Routing-using-Non-stationary-Bandits" class="headerlink" title="Maximizing Success Rate of Payment Routing using Non-stationary Bandits"></a>Maximizing Success Rate of Payment Routing using Non-stationary Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01028">http://arxiv.org/abs/2308.01028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aayush Chaudhary, Abhinav Rai, Abhishek Gupta</li>
<li>for: 该论文是为了设计和部署非站立式多臂瑞伯投注策略来确定近似优化的支付路由策略，以优化支付系统性能和安全性。</li>
<li>methods: 该论文使用了一种新型的射线基实现来优化非站立式多臂瑞伯投注策略，以实现支付系统的扩展和缩放。具体来说，该论文使用了一种基于射线的 Routing Service 架构，并对多种非站立式多臂瑞伯投注策略进行了评估和比较。</li>
<li>results: live 实验结果显示，非站立式多臂瑞伯投注策略可以在一个月内提高支付交易的成功率，相比传统规则基于的方法，提高了0.92%。<details>
<summary>Abstract</summary>
This paper discusses the system architecture design and deployment of non-stationary multi-armed bandit approaches to determine a near-optimal payment routing policy based on the recent history of transactions. We propose a Routing Service architecture using a novel Ray-based implementation for optimally scaling bandit-based payment routing to over 10000 transactions per second, adhering to the system design requirements and ecosystem constraints with Payment Card Industry Data Security Standard (PCI DSS). We first evaluate the effectiveness of multiple bandit-based payment routing algorithms on a custom simulator to benchmark multiple non-stationary bandit approaches and identify the best hyperparameters. We then conducted live experiments on the payment transaction system on a fantasy sports platform Dream11. In the live experiments, we demonstrated that our non-stationary bandit-based algorithm consistently improves the success rate of transactions by 0.92\% compared to the traditional rule-based methods over one month.
</details>
<details>
<summary>摘要</summary>
First, we evaluated the effectiveness of multiple bandit-based payment routing algorithms on a custom simulator to benchmark different non-stationary bandit approaches and identify the best hyperparameters. We then conducted live experiments on a real-world payment transaction system on a fantasy sports platform Dream11, demonstrating that our non-stationary bandit-based algorithm consistently improves the success rate of transactions by 0.92% compared to traditional rule-based methods over a one-month period.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Representation-Learning-for-Periodic-Time-Series-with-Floss-A-Frequency-Domain-Regularization-Approach"><a href="#Enhancing-Representation-Learning-for-Periodic-Time-Series-with-Floss-A-Frequency-Domain-Regularization-Approach" class="headerlink" title="Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach"></a>Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01011">http://arxiv.org/abs/2308.01011</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/agustdd/floss">https://github.com/agustdd/floss</a></li>
<li>paper_authors: Chunwei Yang, Xiaoxu Chen, Lijun Sun, Hongyu Yang, Yuankai Wu</li>
<li>for: 这篇论文旨在提出一种无监督的方法，以帮助深度学习模型更好地处理具有周期性或假周期性特征的时间序列数据。</li>
<li>methods: 这篇论文提出了一种名为Floss的方法，它可以自动在频域中调整学习的表现。Floss方法首先自动检测时间序列中的主要周期性，然后使用周期性移动和频谱浓度相似度度量来学习有意义的表现。</li>
<li>results: 在实验中，Floss方法能够自动发现时间序列中的周期性，并且与其他深度学习模型相比，提高了时间序列分类、预测和偏常检测等任务的表现。<details>
<summary>Abstract</summary>
Time series analysis is a fundamental task in various application domains, and deep learning approaches have demonstrated remarkable performance in this area. However, many real-world time series data exhibit significant periodic or quasi-periodic dynamics that are often not adequately captured by existing deep learning-based solutions. This results in an incomplete representation of the underlying dynamic behaviors of interest. To address this gap, we propose an unsupervised method called Floss that automatically regularizes learned representations in the frequency domain. The Floss method first automatically detects major periodicities from the time series. It then employs periodic shift and spectral density similarity measures to learn meaningful representations with periodic consistency. In addition, Floss can be easily incorporated into both supervised, semi-supervised, and unsupervised learning frameworks. We conduct extensive experiments on common time series classification, forecasting, and anomaly detection tasks to demonstrate the effectiveness of Floss. We incorporate Floss into several representative deep learning solutions to justify our design choices and demonstrate that it is capable of automatically discovering periodic dynamics and improving state-of-the-art deep learning models.
</details>
<details>
<summary>摘要</summary>
时序分析是多种应用领域的基础任务，深度学习方法在这个领域表现了惊人的表现。然而，许多实际世界时序数据具有重要的周期或准周期动态特征，这些特征经常不被现有的深度学习基础方法完全捕捉。这导致了时序动态行为的下面表示不够完整。为解决这个差距，我们提出了一种无监督的方法 called Floss，该方法可以自动在频率域中规范学习的表示。Floss方法首先自动检测时序数据中的主要周期性。然后，它使用周期偏移和频率分布相似度度量来学习具有周期一致性的有意义表示。此外，Floss可以轻松地integrated到supervised、semi-supervised和无监督学习框架中。我们在常见的时序分类、预测和异常检测任务中进行了广泛的实验，以证明Floss的有效性。我们将Floss incorporated into 多种代表性的深度学习解决方案，以证明我们的设计选择是合理的，并证明Floss可以自动发现周期动态和提高当前最佳深度学习模型。
</details></li>
</ul>
<hr>
<h2 id="MDT3D-Multi-Dataset-Training-for-LiDAR-3D-Object-Detection-Generalization"><a href="#MDT3D-Multi-Dataset-Training-for-LiDAR-3D-Object-Detection-Generalization" class="headerlink" title="MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization"></a>MDT3D: Multi-Dataset Training for LiDAR 3D Object Detection Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01000">http://arxiv.org/abs/2308.01000</a></li>
<li>repo_url: None</li>
<li>paper_authors: Louis Soum-Fontez, Jean-Emmanuel Deschaud, François Goulette<br>for:这个论文的目标是提高3D物体检测模型在新环境和不同感知器配置下的稳定性。methods:该方法使用多个注释源数据集进行共同训练，并使用新的标签映射技术来填充标签空白。此外，该方法还提出了一种混合数据集的训练方法和跨数据集对象插入 augmetnation 技术。results:研究表明，该方法可以提高不同类型的3D物体检测模型在新环境下的性能。 Code and additional results will be publicly available on GitHub for further reference.<details>
<summary>Abstract</summary>
Supervised 3D Object Detection models have been displaying increasingly better performance in single-domain cases where the training data comes from the same environment and sensor as the testing data. However, in real-world scenarios data from the target domain may not be available for finetuning or for domain adaptation methods. Indeed, 3D object detection models trained on a source dataset with a specific point distribution have shown difficulties in generalizing to unseen datasets. Therefore, we decided to leverage the information available from several annotated source datasets with our Multi-Dataset Training for 3D Object Detection (MDT3D) method to increase the robustness of 3D object detection models when tested in a new environment with a different sensor configuration. To tackle the labelling gap between datasets, we used a new label mapping based on coarse labels. Furthermore, we show how we managed the mix of datasets during training and finally introduce a new cross-dataset augmentation method: cross-dataset object injection. We demonstrate that this training paradigm shows improvements for different types of 3D object detection models. The source code and additional results for this research project will be publicly available on GitHub for interested parties to access and utilize: https://github.com/LouisSF/MDT3D
</details>
<details>
<summary>摘要</summary>
受监督3D物体检测模型在单个频道情况下的性能有所提高，但在实际应用场景中，测试数据的频道可能不同于训练数据的频道。实际上，通过特定点分布训练的3D物体检测模型在未看过的数据集上generalization能力很差。因此，我们使用多个注释源数据集的多数据集训练方法（MDT3D）来增强3D物体检测模型在新环境中的Robustness。为了解决不同数据集之间的标签差距，我们使用了新的标签映射基于粗略标签。此外，我们详细介绍了在训练过程中如何处理多个数据集的混合，以及一种新的跨数据集增强方法：跨数据集物体注入。我们展示了这种训练方法在不同类型的3D物体检测模型中的改进。许多相关结果和代码将在GitHub上公开，以便有兴趣的人可以访问和利用：https://github.com/LouisSF/MDT3D。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Synthetic-Data-for-Data-Imbalance-Problems-Baselines-from-a-Data-Perspective"><a href="#Exploiting-Synthetic-Data-for-Data-Imbalance-Problems-Baselines-from-a-Data-Perspective" class="headerlink" title="Exploiting Synthetic Data for Data Imbalance Problems: Baselines from a Data Perspective"></a>Exploiting Synthetic Data for Data Imbalance Problems: Baselines from a Data Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00994">http://arxiv.org/abs/2308.00994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moon Ye-Bin, Nam Hyeon-Woo, Wonseok Choi, Nayeong Kim, Suha Kwak, Tae-Hyun Oh</li>
<li>for:  Addressing data imbalance problems in deep neural networks to prevent biased predictions and potential ethical and social consequences.</li>
<li>methods:  Utilizes synthetic data as a preliminary step before employing task-specific algorithms to address data imbalance problems.</li>
<li>results:  Surpasses the performance of existing task-specific methods on several datasets, including CIFAR100-LT, ImageNet100-LT, UTKFace, and Waterbird.<details>
<summary>Abstract</summary>
We live in a vast ocean of data, and deep neural networks are no exception to this. However, this data exhibits an inherent phenomenon of imbalance. This imbalance poses a risk of deep neural networks producing biased predictions, leading to potentially severe ethical and social consequences. To address these challenges, we believe that the use of generative models is a promising approach for comprehending tasks, given the remarkable advancements demonstrated by recent diffusion models in generating high-quality images. In this work, we propose a simple yet effective baseline, SYNAuG, that utilizes synthetic data as a preliminary step before employing task-specific algorithms to address data imbalance problems. This straightforward approach yields impressive performance on datasets such as CIFAR100-LT, ImageNet100-LT, UTKFace, and Waterbird, surpassing the performance of existing task-specific methods. While we do not claim that our approach serves as a complete solution to the problem of data imbalance, we argue that supplementing the existing data with synthetic data proves to be an effective and crucial preliminary step in addressing data imbalance concerns.
</details>
<details>
<summary>摘要</summary>
我们生活在一个庞大的数据海洋中，而深度神经网络也不例外。然而，这些数据具有内生的不均衡现象，这可能导致深度神经网络预测结果受到偏见，从而导致严重的伦理和社会后果。为了解决这些挑战，我们认为使用生成模型是一个有前途的方法，因为最近的扩散模型在生成高质量图像方面已经展现出了卓越的成果。在这个工作中，我们提出了一个简单 yet有效的基eline，即SYNAuG，它利用生成的数据作为先决步骤，然后使用任务特定的算法来解决数据不均衡问题。这种简单的方法在CIFAR100-LT、ImageNet100-LT、UTKFace和Waterbird等数据集上达到了比较出色的性能，超过了现有的任务特定方法的性能。虽然我们不assert我们的方法是数据不均衡问题的完整解决方案，但我们 argue that在使用现有数据之前，通过生成数据来增加数据量是一个有效和关键的预liminary步骤。
</details></li>
</ul>
<hr>
<h2 id="Wasserstein-Diversity-Enriched-Regularizer-for-Hierarchical-Reinforcement-Learning"><a href="#Wasserstein-Diversity-Enriched-Regularizer-for-Hierarchical-Reinforcement-Learning" class="headerlink" title="Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning"></a>Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00989">http://arxiv.org/abs/2308.00989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haorui Li, Jiaqi Liang, Linjing Li, Daniel Zeng</li>
<li>for: 这个论文旨在解决复杂任务时 Composite reinforcement learning 中的强化学习问题。</li>
<li>methods: 论文提出了一种名为 Wasserstein Diversity-Enriched Regularizer (WDER) 的新任务不受限制的正则化方法，可以轻松地与现有方法结合使用，以提高性能。</li>
<li>results: 实验结果表明，我们的 WDER 可以提高性能和样本效率，与优化参数无关，这表明了我们的方法的可应用性和稳定性。<details>
<summary>Abstract</summary>
Hierarchical reinforcement learning composites subpolicies in different hierarchies to accomplish complex tasks.Automated subpolicies discovery, which does not depend on domain knowledge, is a promising approach to generating subpolicies.However, the degradation problem is a challenge that existing methods can hardly deal with due to the lack of consideration of diversity or the employment of weak regularizers. In this paper, we propose a novel task-agnostic regularizer called the Wasserstein Diversity-Enriched Regularizer (WDER), which enlarges the diversity of subpolicies by maximizing the Wasserstein distances among action distributions. The proposed WDER can be easily incorporated into the loss function of existing methods to boost their performance further.Experimental results demonstrate that our WDER improves performance and sample efficiency in comparison with prior work without modifying hyperparameters, which indicates the applicability and robustness of the WDER.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a new task-agnostic regularizer called the Wasserstein Diversity-Enriched Regularizer (WDER), which increases the diversity of subpolicies by maximizing the Wasserstein distances among action distributions. The WDER can be easily incorporated into the loss function of existing methods to improve their performance further.Experimental results show that our WDER improves performance and sample efficiency compared to prior work, without modifying hyperparameters. This indicates the applicability and robustness of the WDER.
</details></li>
</ul>
<hr>
<h2 id="Learning-Regionalization-within-a-Differentiable-High-Resolution-Hydrological-Model-using-Accurate-Spatial-Cost-Gradients"><a href="#Learning-Regionalization-within-a-Differentiable-High-Resolution-Hydrological-Model-using-Accurate-Spatial-Cost-Gradients" class="headerlink" title="Learning Regionalization within a Differentiable High-Resolution Hydrological Model using Accurate Spatial Cost Gradients"></a>Learning Regionalization within a Differentiable High-Resolution Hydrological Model using Accurate Spatial Cost Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02040">http://arxiv.org/abs/2308.02040</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ngo Nghi Truyen Huynh, Pierre-André Garambois, François Colleoni, Benjamin Renard, Hélène Roux, Julie Demargne, Pierre Javelle</li>
<li>for: 这个论文主要是用来解决无数据的流域中 hydrological parameter 的估计问题，并在各个流域中寻找一个转换函数来将物理描述符与概念模型参数进行量化关系。</li>
<li>methods: 这篇论文提出了一种 Hybrid Data Assimilation and Parameter Regionalization (HDA-PR) 方法，它将 learnable regionalization mappings  integrate 到了一个可微的ydrological model 中，以便在各个流域中使用不同类型的数据进行数据协同填充。</li>
<li>results: 在南法两个暴雨灾害地区进行了高分辨率、小时间和千米级别的地理模型运算，并得到了很好的 regionalization 性能，Nash-Sutcliffe 效率 (NSE) 分布在0.52-0.78之间，相比基线模型 calibrated  WITH lumped parameters 提高了0.57的 NSE 分布。<details>
<summary>Abstract</summary>
Estimating spatially distributed hydrological parameters in ungauged catchments poses a challenging regionalization problem and requires imposing spatial constraints given the sparsity of discharge data. A possible approach is to search for a transfer function that quantitatively relates physical descriptors to conceptual model parameters. This paper introduces a Hybrid Data Assimilation and Parameter Regionalization (HDA-PR) approach incorporating learnable regionalization mappings, based on either multivariate regressions or neural networks, into a differentiable hydrological model. It enables the exploitation of heterogeneous datasets across extensive spatio-temporal computational domains within a high-dimensional regionalization context, using accurate adjoint-based gradients. The inverse problem is tackled with a multi-gauge calibration cost function accounting for information from multiple observation sites. HDA-PR was tested on high-resolution, hourly and kilometric regional modeling of two flash-flood-prone areas located in the South of France. In both study areas, the median Nash-Sutcliffe efficiency (NSE) scores ranged from 0.52 to 0.78 at pseudo-ungauged sites over calibration and validation periods. These results highlight a strong regionalization performance of HDA-PR, improving NSE by up to 0.57 compared to the baseline model calibrated with lumped parameters, and achieving a performance comparable to the reference solution obtained with local uniform calibration (median NSE from 0.59 to 0.79). Multiple evaluation metrics based on flood-oriented hydrological signatures are also employed to assess the accuracy and robustness of the approach. The regionalization method is amenable to state-parameter correction from multi-source data over a range of time scales needed for operational data assimilation, and it is adaptable to other differentiable geophysical models.
</details>
<details>
<summary>摘要</summary>
估计分布式ydrological参数在无测站catchments中存在一个挑战性的区域化问题，需要在缺乏流量数据的情况下强制 spatial constraints。一种可能的方法是寻找一个转移函数，该函数可以量化物理描述符和概念模型参数之间的关系。这篇文章介绍了一种Hybrid Data Assimilation and Parameter Regionalization（HDA-PR）方法，该方法通过将多变量回归或神经网络作为学习可 Regionalization mappings incorporated into a differentiable hydrological model。这种方法可以在广泛的空间-时间计算Domain中利用高精度的后向梯度，并在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration。在多个观测站信息的基础上进行多观测站calibration
</details></li>
</ul>
<hr>
<h2 id="Certified-Multi-Fidelity-Zeroth-Order-Optimization"><a href="#Certified-Multi-Fidelity-Zeroth-Order-Optimization" class="headerlink" title="Certified Multi-Fidelity Zeroth-Order Optimization"></a>Certified Multi-Fidelity Zeroth-Order Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00978">http://arxiv.org/abs/2308.00978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Étienne de Montbrun, Sébastien Gerchinovitz</li>
<li>for: 本文研究了多级别预测优化问题，特别是如何使用不同级别的预测方法来优化一个函数 $f$，以优化函数 $f$ 的评估成本。</li>
<li>methods: 本文提出了一种证明过的算法，称为证明加法多级别预测优化算法（MFDOO）。该算法在评估环境中进行了一系列的游戏性评估，以确定最佳的预测级别和评估方法。</li>
<li>results: 本文提出了一种基于证明的多级别预测优化算法，并提供了一个基于 Lipschitz 函数 $f$ 的成本复杂度上下文。此外，文章还证明了一个 $f$-dependent 下界，表明该算法在任何 Lipschitz 函数 $f$ 下都具有近似优化成本复杂度。最后，文章还Addresses 了随机评估的特殊情况作为直接例子。<details>
<summary>Abstract</summary>
We consider the problem of multi-fidelity zeroth-order optimization, where one can evaluate a function $f$ at various approximation levels (of varying costs), and the goal is to optimize $f$ with the cheapest evaluations possible. In this paper, we study \emph{certified} algorithms, which are additionally required to output a data-driven upper bound on the optimization error. We first formalize the problem in terms of a min-max game between an algorithm and an evaluation environment. We then propose a certified variant of the MFDOO algorithm and derive a bound on its cost complexity for any Lipschitz function $f$. We also prove an $f$-dependent lower bound showing that this algorithm has a near-optimal cost complexity. We close the paper by addressing the special case of noisy (stochastic) evaluations as a direct example.
</details>
<details>
<summary>摘要</summary>
我们考虑多项误差零项优化问题，其中可以评估函数 $f$ 在不同的推导水平（具有不同的成本）上，并且目标是将 $f$ 优化到最低成本下。在这篇文章中，我们研究了认证算法，这些算法还需要输出一个基于数据的Upper bound 估计错误。我们首先将问题正式化为一个测验环境和算法之间的最小最大游戏。然后，我们提出了认证版本的 MFDOO 算法，并且derive了这个算法的成本复杂度的上限，这上限是适用于任何 Lipschitz 函数 $f$。我们还证明了 $f$ 相依的下界，证明这个算法在任何情况下都具有近乎最佳的成本复杂度。最后，我们处理了随机（测量）评估的特例，作为直接的例子。
</details></li>
</ul>
<hr>
<h2 id="A-new-approach-for-evaluating-internal-cluster-validation-indices"><a href="#A-new-approach-for-evaluating-internal-cluster-validation-indices" class="headerlink" title="A new approach for evaluating internal cluster validation indices"></a>A new approach for evaluating internal cluster validation indices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03894">http://arxiv.org/abs/2308.03894</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zoltán Botta-Dukát</li>
<li>for: 本研究旨在透过内部验证指标选择最佳表现的算法和参数设置，而不使用任何外部信息。</li>
<li>methods: 本研究提出了多种内部验证指标，并评估了它们在不同数据集上的表现。</li>
<li>results: 本研究提出了一种新的验证方法，并评估了其优劣点。<details>
<summary>Abstract</summary>
A vast number of different methods are available for unsupervised classification. Since no algorithm and parameter setting performs best in all types of data, there is a need for cluster validation to select the actually best-performing algorithm. Several indices were proposed for this purpose without using any additional (external) information. These internal validation indices can be evaluated by applying them to classifications of datasets with a known cluster structure. Evaluation approaches differ in how they use the information on the ground-truth classification. This paper reviews these approaches, considering their advantages and disadvantages, and then suggests a new approach.
</details>
<details>
<summary>摘要</summary>
“有很多不同的方法可以用于无监督分类。由于不同的算法和参数设置不一定适合所有类型的数据，因此需要使用集群验证来选择最佳performing的算法。多种内部验证指标已经被提议用于此目的，但这些指标不使用任何外部信息。这些验证方法可以通过应用于知道的分类结构的数据来评估。本文将评论这些方法，包括其优点和缺点，然后提出一种新的方法。”Note: Please keep in mind that the translation is in Simplified Chinese, which is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and other countries.
</details></li>
</ul>
<hr>
<h2 id="Effects-of-Daily-News-Sentiment-on-Stock-Price-Forecasting"><a href="#Effects-of-Daily-News-Sentiment-on-Stock-Price-Forecasting" class="headerlink" title="Effects of Daily News Sentiment on Stock Price Forecasting"></a>Effects of Daily News Sentiment on Stock Price Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08549">http://arxiv.org/abs/2308.08549</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. Srinivas, R. Gadela, R. Sabu, A. Das, G. Nath, V. Datla</li>
<li>for: This paper aims to improve the accuracy of stock price forecasts by incorporating investor sentiment from news articles into the prediction model.</li>
<li>methods: The authors use a robust data collection and preprocessing framework to create a news database and time series data for NITY50 stocks. They use sentiment libraries to calculate sentiment scores from different sections of the articles and fit LSTM models to forecast stock prices, both with and without sentiment features.</li>
<li>results: The authors compare the performance of the LSTM models with and without sentiment features and find that incorporating sentiment scores improves the accuracy of stock price forecasts.<details>
<summary>Abstract</summary>
Predicting future prices of a stock is an arduous task to perform. However, incorporating additional elements can significantly improve our predictions, rather than relying solely on a stock's historical price data to forecast its future price. Studies have demonstrated that investor sentiment, which is impacted by daily news about the company, can have a significant impact on stock price swings. There are numerous sources from which we can get this information, but they are cluttered with a lot of noise, making it difficult to accurately extract the sentiments from them. Hence the focus of our research is to design an efficient system to capture the sentiments from the news about the NITY50 stocks and investigate how much the financial news sentiment of these stocks are affecting their prices over a period of time. This paper presents a robust data collection and preprocessing framework to create a news database for a timeline of around 3.7 years, consisting of almost half a million news articles. We also capture the stock price information for this timeline and create multiple time series data, that include the sentiment scores from various sections of the article, calculated using different sentiment libraries. Based on this, we fit several LSTM models to forecast the stock prices, with and without using the sentiment scores as features and compare their performances.
</details>
<details>
<summary>摘要</summary>
We present a robust data collection and preprocessing framework to create a news database spanning 3.7 years, consisting of nearly half a million news articles. We also collect stock price information for this timeline and create multiple time series data, including sentiment scores from various sections of the article calculated using different sentiment libraries. We then fit several LSTM models to forecast stock prices, with and without using sentiment scores as features, and compare their performances.
</details></li>
</ul>
<hr>
<h2 id="Integrating-Homomorphic-Encryption-and-Trusted-Execution-Technology-for-Autonomous-and-Confidential-Model-Refining-in-Cloud"><a href="#Integrating-Homomorphic-Encryption-and-Trusted-Execution-Technology-for-Autonomous-and-Confidential-Model-Refining-in-Cloud" class="headerlink" title="Integrating Homomorphic Encryption and Trusted Execution Technology for Autonomous and Confidential Model Refining in Cloud"></a>Integrating Homomorphic Encryption and Trusted Execution Technology for Autonomous and Confidential Model Refining in Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00963">http://arxiv.org/abs/2308.00963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pinglan Liu, Wensheng Zhang</li>
<li>for: 本研究旨在设计一种在云端实现自动化和保密的模型优化方案，以满足长期连续进行机器学习的需求和数据和模型的隐私保护。</li>
<li>methods: 本研究使用了同时保证机密性和可信度的同时保证机密性和可信度的同时使用了Homomorphic加密和可信任执行环境技术，并通过实现和实验证明了该方案的可行性。</li>
<li>results: 实验结果表明，通过使用我们提议的方案，云服务器可以自动地对加密模型进行修改，以提高其精度。虽然效率仍然远低于基准方案，但我们预期通过更好地利用高级并行和云服务器GPU的计算能力，可以进一步提高效率。<details>
<summary>Abstract</summary>
With the popularity of cloud computing and machine learning, it has been a trend to outsource machine learning processes (including model training and model-based inference) to cloud. By the outsourcing, other than utilizing the extensive and scalable resource offered by the cloud service provider, it will also be attractive to users if the cloud servers can manage the machine learning processes autonomously on behalf of the users. Such a feature will be especially salient when the machine learning is expected to be a long-term continuous process and the users are not always available to participate. Due to security and privacy concerns, it is also desired that the autonomous learning preserves the confidentiality of users' data and models involved. Hence, in this paper, we aim to design a scheme that enables autonomous and confidential model refining in cloud. Homomorphic encryption and trusted execution environment technology can protect confidentiality for autonomous computation, but each of them has their limitations respectively and they are complementary to each other. Therefore, we further propose to integrate these two techniques in the design of the model refining scheme. Through implementation and experiments, we evaluate the feasibility of our proposed scheme. The results indicate that, with our proposed scheme the cloud server can autonomously refine an encrypted model with newly provided encrypted training data to continuously improve its accuracy. Though the efficiency is still significantly lower than the baseline scheme that refines plaintext-model with plaintext-data, we expect that it can be improved by fully utilizing the higher level of parallelism and the computational power of GPU at the cloud server.
</details>
<details>
<summary>摘要</summary>
With the rise of cloud computing and machine learning, it has become a trend to outsource machine learning processes (including model training and model-based inference) to the cloud. By outsourcing, users can not only take advantage of the extensive and scalable resources offered by cloud service providers but also enjoy the convenience of having the cloud servers manage the machine learning processes autonomously on their behalf. This feature is particularly desirable when machine learning is expected to be a long-term continuous process and users are not always available to participate. However, due to security and privacy concerns, it is essential that the autonomous learning preserves the confidentiality of users' data and models involved. Therefore, in this paper, we aim to design a scheme that enables autonomous and confidential model refining in the cloud.Homomorphic encryption and trusted execution environment technology can protect confidentiality for autonomous computation, but each of them has its limitations, respectively. Therefore, we propose to integrate these two techniques in the design of the model refining scheme. Through implementation and experiments, we evaluate the feasibility of our proposed scheme. The results show that the cloud server can autonomously refine an encrypted model with newly provided encrypted training data to continuously improve its accuracy. Although the efficiency is still significantly lower than the baseline scheme that refines plaintext-model with plaintext-data, we expect that it can be improved by fully utilizing the higher level of parallelism and the computational power of GPU at the cloud server.
</details></li>
</ul>
<hr>
<h2 id="Causal-Inference-with-Differentially-Private-Clustered-Outcomes"><a href="#Causal-Inference-with-Differentially-Private-Clustered-Outcomes" class="headerlink" title="Causal Inference with Differentially Private (Clustered) Outcomes"></a>Causal Inference with Differentially Private (Clustered) Outcomes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00957">http://arxiv.org/abs/2308.00957</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adel Javanmard, Vahab Mirrokni, Jean Pouget-Abadie</li>
<li>For: The paper aims to provide a new differential privacy mechanism, “Cluster-DP”, to improve the estimation of causal effects from randomized experiments while maintaining strong privacy guarantees.* Methods: The paper proposes a clustering-based differential privacy mechanism that leverages the cluster structure of the data to reduce the variance loss and maintain privacy guarantees.* Results: The paper shows that the proposed “Cluster-DP” algorithm can improve the variance loss compared to its unclustered version and a more extreme uniform-prior version, while maintaining the same privacy guarantees.<details>
<summary>Abstract</summary>
Estimating causal effects from randomized experiments is only feasible if participants agree to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label differential privacy is a widely used measure of an algorithm's privacy guarantee, which might encourage participants to share responses without running the risk of de-anonymization. Many differentially private mechanisms inject noise into the original data-set to achieve this privacy guarantee, which increases the variance of most statistical estimators and makes the precise measurement of causal effects difficult: there exists a fundamental privacy-variance trade-off to performing causal analyses from differentially private data. With the aim of achieving lower variance for stronger privacy guarantees, we suggest a new differential privacy mechanism, "Cluster-DP", which leverages any given cluster structure of the data while still allowing for the estimation of causal effects. We show that, depending on an intuitive measure of cluster quality, we can improve the variance loss while maintaining our privacy guarantees. We compare its performance, theoretically and empirically, to that of its unclustered version and a more extreme uniform-prior version which does not use any of the original response distribution, both of which are special cases of the "Cluster-DP" algorithm.
</details>
<details>
<summary>摘要</summary>
估计 causal effect from randomized experiments 只能成功实现 participants 同意披露 potentially sensitive 回答。保护隐私的多种方法中，标签分布隐私是一种广泛使用的隐私保证度量，可能会鼓励 participants 分享回答不会风险 de-anonymization。许多异常隐私机制会在原始数据集中插入噪声来实现这一隐私保证度量，这会增加统计估计器的方差，从而使得确定 causal effect 变得更加困难：存在一个基本隐私-准备曲线质量负担。为了实现更低的准备质量和更强的隐私保证度量，我们建议一种新的隐私机制，即 "Cluster-DP"，它利用给定的数据集中的群集结构，同时仍然允许确定 causal effect。我们表明，根据某种直观的群集质量度量，我们可以提高准备质量的变化，而不会随着隐私保证度量的增加。我们对其性能进行了理论和实验性比较，与其不使用原始回答分布的特殊情况（即 "Cluster-DP" 算法的不分支情况）和更激进的均匀先验情况（即不使用原始回答分布的情况）进行比较。
</details></li>
</ul>
<hr>
<h2 id="Curriculum-Guided-Domain-Adaptation-in-the-Dark"><a href="#Curriculum-Guided-Domain-Adaptation-in-the-Dark" class="headerlink" title="Curriculum Guided Domain Adaptation in the Dark"></a>Curriculum Guided Domain Adaptation in the Dark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00956">http://arxiv.org/abs/2308.00956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chowdhury Sadman Jahan, Andreas Savakis</li>
<li>for: 本研究目的是 Addressing the rising concerns of privacy and security, domain adaptation in the dark aims to adapt a black-box source trained model to an unlabeled target domain without access to any source data or source model parameters.</li>
<li>methods: 本研究使用了 Curriculum Adaptation for Black-Box (CABB) 方法，它是一种curriculum guided adaptation approach，首先在目标数据集上使用高置信度（clean）标签进行训练，然后在目标数据集上使用噪音标签进行训练。 CABB 方法使用了 Jensen-Shannon 分布差作为 cleaner-noisy sample separation 的优化目标函数，而不是传统的 cross entropy loss 函数。</li>
<li>results: 实验结果表明，CABB 方法在标准领域适应 datasets 上比现有的黑框 DA 模型表现更好，并且与白框领域适应模型相当。<details>
<summary>Abstract</summary>
Addressing the rising concerns of privacy and security, domain adaptation in the dark aims to adapt a black-box source trained model to an unlabeled target domain without access to any source data or source model parameters. The need for domain adaptation of black-box predictors becomes even more pronounced to protect intellectual property as deep learning based solutions are becoming increasingly commercialized. Current methods distill noisy predictions on the target data obtained from the source model to the target model, and/or separate clean/noisy target samples before adapting using traditional noisy label learning algorithms. However, these methods do not utilize the easy-to-hard learning nature of the clean/noisy data splits. Also, none of the existing methods are end-to-end, and require a separate fine-tuning stage and an initial warmup stage. In this work, we present Curriculum Adaptation for Black-Box (CABB) which provides a curriculum guided adaptation approach to gradually train the target model, first on target data with high confidence (clean) labels, and later on target data with noisy labels. CABB utilizes Jensen-Shannon divergence as a better criterion for clean-noisy sample separation, compared to the traditional criterion of cross entropy loss. Our method utilizes co-training of a dual-branch network to suppress error accumulation resulting from confirmation bias. The proposed approach is end-to-end trainable and does not require any extra finetuning stage, unlike existing methods. Empirical results on standard domain adaptation datasets show that CABB outperforms existing state-of-the-art black-box DA models and is comparable to white-box domain adaptation models.
</details>
<details>
<summary>摘要</summary>
Addressing the rising concerns of privacy and security, 黑盒子领域适应（Domain Adaptation in the Dark）旨在不经过任何源数据或源模型参数的情况下，将黑盒子训练模型适应到无标注目标领域。随着深度学习解决方案的商业化，黑盒子领域适应的需求更加突出。现有的方法将源模型预测的误差转移到目标模型，并/或使用传统的噪声标签学习算法进行适应。但这些方法未使用容易从容易到困难的标签分配特性。此外，现有的方法都不是端到端的，需要额外的练习阶段和暖身阶段。在这个研究中，我们提出了“CURRICULUM ADAPTATION FOR BLACK-BOX”（CABB），它提供了一个课程导向的适应方法，首先在目标数据上将高信任度（清洁）标签训练目标模型，然后在目标数据上将噪声标签训练目标模型。CABB使用Jensen-Shannon散度作为更好的清洁噪声标签分配剂量，相比于传统的混合损失函数。我们的方法使用两条分支网络进行合作训练，以抑制因确认偏调所导致的错误累累。提案的方法是端到端训练的，不需要额外的练习阶段，与现有的方法不同。实验结果显示，CABB在标准领域适应 datasets 上表现更好，并且与白盒子领域适应模型相比几乎相同。
</details></li>
</ul>
<hr>
<h2 id="From-Sparse-to-Soft-Mixtures-of-Experts"><a href="#From-Sparse-to-Soft-Mixtures-of-Experts" class="headerlink" title="From Sparse to Soft Mixtures of Experts"></a>From Sparse to Soft Mixtures of Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00951">http://arxiv.org/abs/2308.00951</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/vmoe">https://github.com/google-research/vmoe</a></li>
<li>paper_authors: Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Neil Houlsby</li>
<li>for: This paper aims to address the challenges of training and inference costs in Mixture of Expert (MoE) architectures, specifically in the context of visual recognition tasks.</li>
<li>methods: The proposed Soft MoE method uses a fully-differentiable sparse Transformer that performs implicit soft assignments of input tokens to experts, allowing for larger model capacity at lower inference cost.</li>
<li>results: Soft MoE outperforms standard Transformers (ViTs) and popular MoE variants (Tokens Choice and Experts Choice) in visual recognition tasks, while scaling well with increasing numbers of experts and layers. For example, Soft MoE-Base&#x2F;16 requires 10.5x lower inference cost than ViT-Huge&#x2F;14 while matching its performance after similar training, and Soft MoE Huge&#x2F;14 with 128 experts in 16 MoE layers has over 40x more parameters than ViT Huge&#x2F;14 with only a 2% increase in inference time cost.<details>
<summary>Abstract</summary>
Sparse mixture of expert architectures (MoEs) scale model capacity without large increases in training or inference costs. Despite their success, MoEs suffer from a number of issues: training instability, token dropping, inability to scale the number of experts, or ineffective finetuning. In this work, we proposeSoft MoE, a fully-differentiable sparse Transformer that addresses these challenges, while maintaining the benefits of MoEs. Soft MoE performs an implicit soft assignment by passing different weighted combinations of all input tokens to each expert. As in other MoE works, experts in Soft MoE only process a subset of the (combined) tokens, enabling larger model capacity at lower inference cost. In the context of visual recognition, Soft MoE greatly outperforms standard Transformers (ViTs) and popular MoE variants (Tokens Choice and Experts Choice). For example, Soft MoE-Base/16 requires 10.5x lower inference cost (5.7x lower wall-clock time) than ViT-Huge/14 while matching its performance after similar training. Soft MoE also scales well: Soft MoE Huge/14 with 128 experts in 16 MoE layers has over 40x more parameters than ViT Huge/14, while inference time cost grows by only 2%, and it performs substantially better.
</details>
<details>
<summary>摘要</summary>
稀疏混合专家架构（MoE）可以增加模型容量而无需大幅提高训练或执行成本。 despite their success, MoE 受到一些问题的困扰，包括训练不稳定、吐token、无法扩展专家数量以及无效的微调。 在这项工作中，我们提出了软MoE，一种完全可微分的稀疏转换器，解决了这些挑战，同时保留了 MoE 的优点。 软MoE 通过不同权重的Weighted combinations of all input tokens 来进行隐式软分配。 与其他 MoE 工作一样，专家在 Soft MoE 中只处理一部分（合并）的输入字符，使得模型容量得到了更大的提升，而执行成本则得到了更低的降低。 在视识ognition中，软MoE 超过了标准Transformers（ViTs）和受欢迎的 MoE 变体（Tokens Choice和Experts Choice）。例如，Soft MoE-Base/16 需要10.5倍低的执行成本（5.7倍低的墙 clock time），而与其性能相似。 Soft MoE 也可以扩展： Soft MoE Huge/14  WITH 128 experts 在 16 MoE layers 中有40倍以上的参数量，而执行成本增加了只有2%，并且表现出了明显的提升。
</details></li>
</ul>
<hr>
<h2 id="Decomposing-and-Coupling-Saliency-Map-for-Lesion-Segmentation-in-Ultrasound-Images"><a href="#Decomposing-and-Coupling-Saliency-Map-for-Lesion-Segmentation-in-Ultrasound-Images" class="headerlink" title="Decomposing and Coupling Saliency Map for Lesion Segmentation in Ultrasound Images"></a>Decomposing and Coupling Saliency Map for Lesion Segmentation in Ultrasound Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00947">http://arxiv.org/abs/2308.00947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenyuan Ning, Yixiao Mao, Qianjin Feng, Shengzhou Zhong, Yu Zhang</li>
<li>for: 这篇论文旨在提高聚合体内部的肿瘤分类精度，应对静脉影像中肿瘤区域和周围组织（背景）的同等或更高的颜色和текстура对比。</li>
<li>methods: 这篇论文提出了一个名为DC-Net的分解且联系网络，通过在复杂的静脉影像中分解原始图像，将肿瘤区域和背景分类为不同的类别，以提高肿瘤分类精度。DC-Net包括分解和联系子网络，其中前者先将原始图像分解为肿瘤和背景的类别对应图像，然后后者进一步处理这些图像，以确保精度高的肿瘤分类。</li>
<li>results: 这篇论文的实验结果显示，DC-Net可以在两个静脉肿瘤分类任务中提高精度，比较现有的方法更好。<details>
<summary>Abstract</summary>
Complex scenario of ultrasound image, in which adjacent tissues (i.e., background) share similar intensity with and even contain richer texture patterns than lesion region (i.e., foreground), brings a unique challenge for accurate lesion segmentation. This work presents a decomposition-coupling network, called DC-Net, to deal with this challenge in a (foreground-background) saliency map disentanglement-fusion manner. The DC-Net consists of decomposition and coupling subnets, and the former preliminarily disentangles original image into foreground and background saliency maps, followed by the latter for accurate segmentation under the assistance of saliency prior fusion. The coupling subnet involves three aspects of fusion strategies, including: 1) regional feature aggregation (via differentiable context pooling operator in the encoder) to adaptively preserve local contextual details with the larger receptive field during dimension reduction; 2) relation-aware representation fusion (via cross-correlation fusion module in the decoder) to efficiently fuse low-level visual characteristics and high-level semantic features during resolution restoration; 3) dependency-aware prior incorporation (via coupler) to reinforce foreground-salient representation with the complementary information derived from background representation. Furthermore, a harmonic loss function is introduced to encourage the network to focus more attention on low-confidence and hard samples. The proposed method is evaluated on two ultrasound lesion segmentation tasks, which demonstrates the remarkable performance improvement over existing state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
复杂的超声图像场景下，邻近组织（即背景）与病变区域（即前景）的像素强度几乎相同，甚至具有更复杂的文本排序模式，对准确病变分割带来了独特挑战。本文提出了一种 decomposition-coupling 网络（DC-Net），通过在 (前景-背景) 敏感地图离散-融合方式下进行精准分割。DC-Net 包括 decomposition 和 coupling 子网络，前者先将原始图像粗略地分解成前景和背景敏感地图，然后后者在帮助于敏感优化下进行精准分割。coupling 子网络包括三个方面的融合策略：1）地域特征聚合（通过可导式上下文搅拌运算器在编码器中），以适应大小上下文的更大范围，在维度减少时保留地方上下文特征；2）关系意识表示融合（通过交叉相关融合模块在解码器中），以高效地融合低级视觉特征和高级 semantic 特征；3）依赖关系评估（通过优化器），以强制前景敏感表示具有补偿信息的背景表示。此外，文本还引入了一种和谐损失函数，以鼓励网络更加关注低信心和困难样本。提出的方法在两个超声病变分割任务上进行评估，表现出了明显的性能提升。
</details></li>
</ul>
<hr>
<h2 id="On-the-use-of-deep-learning-for-phase-recovery"><a href="#On-the-use-of-deep-learning-for-phase-recovery" class="headerlink" title="On the use of deep learning for phase recovery"></a>On the use of deep learning for phase recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00942">http://arxiv.org/abs/2308.00942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaiqiang Wang, Li Song, Chutian Wang, Zhenbo Ren, Guangyuan Zhao, Jiazhen Dou, Jianglei Di, George Barbastathis, Renjie Zhou, Jianlin Zhao, Edmund Y. Lam</li>
<li>for: This paper is written for those interested in phase recovery (PR) and its applications in computational imaging.</li>
<li>methods: The paper reviews conventional methods for PR, as well as how deep learning (DL) can be used to support PR from pre-processing, in-processing, and post-processing stages.</li>
<li>results: The paper summarizes the work in DL for PR and provides a live-updating resource for readers to learn more about PR.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了介绍phaserecovery（PR）和其应用于计算成像而写的。</li>
<li>methods: 论文回顾了传统的PR方法，以及如何通过深度学习（DL）在pre-processing、in-processing和post-processing三个阶段支持PR。</li>
<li>results: 论文总结了DL在PR方面的工作，并提供了一个live-updating资源，让读者更深入了解PR。<details>
<summary>Abstract</summary>
Phase recovery (PR) refers to calculating the phase of the light field from its intensity measurements. As exemplified from quantitative phase imaging and coherent diffraction imaging to adaptive optics, PR is essential for reconstructing the refractive index distribution or topography of an object and correcting the aberration of an imaging system. In recent years, deep learning (DL), often implemented through deep neural networks, has provided unprecedented support for computational imaging, leading to more efficient solutions for various PR problems. In this review, we first briefly introduce conventional methods for PR. Then, we review how DL provides support for PR from the following three stages, namely, pre-processing, in-processing, and post-processing. We also review how DL is used in phase image processing. Finally, we summarize the work in DL for PR and outlook on how to better use DL to improve the reliability and efficiency in PR. Furthermore, we present a live-updating resource (https://github.com/kqwang/phase-recovery) for readers to learn more about PR.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>phas recovery (PR)指的是从光场强度测量中计算光场的阶段。例如从量化光场图像和相干散射图像到调整镜optics，PR是重构 объек的反射指数分布或地图的关键 step。在过去几年，深度学习（DL），通常通过深度神经网络实现，为计算成像提供了无前例的支持，导致了许多PR问题的更有效的解决方案。在这篇文章中，我们首先简要介绍了传统的PR方法。然后，我们回顾了DL在PR中的三个阶段，即先processing、processing和后processing。我们还回顾了DL在相位图像处理中的应用。最后，我们总结了DL在PR中的工作，并对如何更好地使用DL提高PR的可靠性和效率。此外，我们提供了一个live-updating资源（https://github.com/kqwang/phase-recovery），以便读者了解更多关于PR。
</details></li>
</ul>
<hr>
<h2 id="QUANT-A-Minimalist-Interval-Method-for-Time-Series-Classification"><a href="#QUANT-A-Minimalist-Interval-Method-for-Time-Series-Classification" class="headerlink" title="QUANT: A Minimalist Interval Method for Time Series Classification"></a>QUANT: A Minimalist Interval Method for Time Series Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00928">http://arxiv.org/abs/2308.00928</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/angus924/quant">https://github.com/angus924/quant</a></li>
<li>paper_authors: Angus Dempster, Daniel F. Schmidt, Geoffrey I. Webb</li>
<li>for: 这篇论文是为了提出一种基于间隔的时间序列分类方法。</li>
<li>methods: 该方法使用单一的特征（Quantiles）、固定的间隔和一个市场上可用的分类器。</li>
<li>results: 该方法可以在一组标准的测试数据集上实现同样的准确率，与现有最准确的间隔方法相比。这种快速和准确的方法可以在142个UCR数据集上实现状态机器学习的最佳性能，总计算时间仅为单CPU核心下的少于15分钟。<details>
<summary>Abstract</summary>
We show that it is possible to achieve the same accuracy, on average, as the most accurate existing interval methods for time series classification on a standard set of benchmark datasets using a single type of feature (quantiles), fixed intervals, and an 'off the shelf' classifier. This distillation of interval-based approaches represents a fast and accurate method for time series classification, achieving state-of-the-art accuracy on the expanded set of 142 datasets in the UCR archive with a total compute time (training and inference) of less than 15 minutes using a single CPU core.
</details>
<details>
<summary>摘要</summary>
我们证明了可以通过使用单一的特征（分位数）、固定间隔和对应的资料集（UCR档案），在一个单一CPU核心上，实现时间序列分类的同等精度，与现有的间隔方法相比。这种简化的间隔方法可以实现快速和准确的时间序列分类，在扩展的142个测试集上达到了状况之优的精度，训练和推导时间总计少于15分钟。
</details></li>
</ul>
<hr>
<h2 id="Continual-Domain-Adaptation-on-Aerial-Images-under-Gradually-Degrading-Weather"><a href="#Continual-Domain-Adaptation-on-Aerial-Images-under-Gradually-Degrading-Weather" class="headerlink" title="Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather"></a>Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00924">http://arxiv.org/abs/2308.00924</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sadman-jahan/aid-ucm-degradingweather">https://github.com/sadman-jahan/aid-ucm-degradingweather</a></li>
<li>paper_authors: Chowdhury Sadman Jahan, Andreas Savakis</li>
<li>for: 这篇研究旨在探讨深度学习模型在天空平台上的适应Domain Adaptation（DA）问题，以及在这种情况下的测试时 Adaptation（ continual DA）表现。</li>
<li>methods: 研究使用了两种逐渐恶化的天气情况，将Real Image Dataset中的两个 dataset合成而成四个 benchmark dataset。然后，评估了三种 DA 模型，包括标准 DA 模型和两种 continual DA 模型，并比较了两种不同的架构（卷积和transformer）。</li>
<li>results: 研究发现了在 continual DA  Setting 中，exist buffer-fed continual DA 方法会出现稳定性问题，并提出了一个简单的Gradient Normalization方法来缓解这个问题。<details>
<summary>Abstract</summary>
Domain adaptation (DA) strives to mitigate the domain gap between the source domain where a model is trained, and the target domain where the model is deployed. When a deep learning model is deployed on an aerial platform, it may face gradually degrading weather conditions during operation, leading to widening domain gaps between the training data and the encountered evaluation data. We synthesize two such gradually worsening weather conditions on real images from two existing aerial imagery datasets, generating a total of four benchmark datasets. Under the continual, or test-time adaptation setting, we evaluate three DA models on our datasets: a baseline standard DA model and two continual DA models. In such setting, the models can access only one small portion, or one batch of the target data at a time, and adaptation takes place continually, and over only one epoch of the data. The combination of the constraints of continual adaptation, and gradually deteriorating weather conditions provide the practical DA scenario for aerial deployment. Among the evaluated models, we consider both convolutional and transformer architectures for comparison. We discover stability issues during adaptation for existing buffer-fed continual DA methods, and offer gradient normalization as a simple solution to curb training instability.
</details>
<details>
<summary>摘要</summary>
域 adaptation (DA) 的目的是减少源域和目标域之间的域 gap，以便在不同域上使用模型。当深度学习模型在飞行平台上部署时，可能会遇到逐渐恶化的天气条件，导致模型在训练数据和评估数据之间的域 gap 进一步扩大。我们将两种逐渐恶化的天气条件synthesize在实际图像上，生成了四个benchmark dataset。在 continual 或 test-time adaptation  Setting 中，我们评估了三个 DA 模型：基eline 标准 DA 模型和两个 continual DA 模型。在这种设置下，模型可以只访问一小部分，或一批target data 中的一个批次，并且adaptation 发生在一个epoch 内。将 continual adaptation 的约束和逐渐恶化的天气条件相结合，我们实际上构建了飞行部署中的实用 DA enario。我们考虑了 convolutional 和 transformer 架构进行比较。我们发现了 continual DA 方法中的稳定问题，并提供了一种简单的 Gradient Normalization 解决方案来缓解训练不稳定。
</details></li>
</ul>
<hr>
<h2 id="Survey-on-Computer-Vision-Techniques-for-Internet-of-Things-Devices"><a href="#Survey-on-Computer-Vision-Techniques-for-Internet-of-Things-Devices" class="headerlink" title="Survey on Computer Vision Techniques for Internet-of-Things Devices"></a>Survey on Computer Vision Techniques for Internet-of-Things Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02553">http://arxiv.org/abs/2308.02553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ishmeet Kaur, Adwaita Janardhan Jadhav</li>
<li>for: 本研究旨在探讨最新的低功耗和能效的神经网络实现方法，以提高神经网络的部署性，而不是减少准确率。</li>
<li>methods: 本文涵盖了三类主要方法：神经网络压缩、网络架构搜索和设计、编译器和图优化。</li>
<li>results: 本文总结了低功耗和能效的神经网络实现方法的优劣点和未来研究问题。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are state-of-the-art techniques for solving most computer vision problems. DNNs require billions of parameters and operations to achieve state-of-the-art results. This requirement makes DNNs extremely compute, memory, and energy-hungry, and consequently difficult to deploy on small battery-powered Internet-of-Things (IoT) devices with limited computing resources. Deployment of DNNs on Internet-of-Things devices, such as traffic cameras, can improve public safety by enabling applications such as automatic accident detection and emergency response.Through this paper, we survey the recent advances in low-power and energy-efficient DNN implementations that improve the deployability of DNNs without significantly sacrificing accuracy. In general, these techniques either reduce the memory requirements, the number of arithmetic operations, or both. The techniques can be divided into three major categories: neural network compression, network architecture search and design, and compiler and graph optimizations. In this paper, we survey both low-power techniques for both convolutional and transformer DNNs, and summarize the advantages, disadvantages, and open research problems.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）是现代计算机视觉问题的state-of-the-art技术。DNN需要数十亿参数和操作来实现state-of-the-art结果，这使得DNN变得极其计算、内存和能源贪吃，因此Difficult to deploy on small battery-powered Internet of Things（IoT）设备 with limited computing resources。 deploying DNNs on IoT devices, such as traffic cameras, can improve public safety by enabling applications such as automatic accident detection and emergency response. Through this paper, we survey the recent advances in low-power and energy-efficient DNN implementations that improve the deployability of DNNs without significantly sacrificing accuracy. In general, these techniques either reduce the memory requirements, the number of arithmetic operations, or both. The techniques can be divided into three major categories: neural network compression, network architecture search and design, and compiler and graph optimizations. In this paper, we survey both low-power techniques for both convolutional and transformer DNNs, and summarize the advantages, disadvantages, and open research problems.
</details></li>
</ul>
<hr>
<h2 id="Virtual-histological-staining-of-unlabeled-autopsy-tissue"><a href="#Virtual-histological-staining-of-unlabeled-autopsy-tissue" class="headerlink" title="Virtual histological staining of unlabeled autopsy tissue"></a>Virtual histological staining of unlabeled autopsy tissue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00920">http://arxiv.org/abs/2308.00920</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuzhu Li, Nir Pillar, Jingxi Li, Tairan Liu, Di Wu, Songyu Sun, Guangdong Ma, Kevin de Haan, Luzhe Huang, Sepehr Hamidi, Anatoly Urisman, Tal Keidar Haran, William Dean Wallace, Jonathan E. Zuckerman, Aydogan Ozcan</li>
<li>for: 这个研究旨在解决传统压涂方法在检验尸体样本时的挑战，包括临床死亡后的样本自释导致的差异化、高成本和时间consuming的化学压涂过程。</li>
<li>methods: 这篇文章报道了一种虚拟染色技术，使用一个训练好的神经网络将染料自动替换为普通的染料染色，从而消除自释导致的严重染色扭曲。</li>
<li>results: 研究发现，虚拟染色技术可以快速地生成高质量的染料染色图像，并且可以减少劳动力、成本和基础设施需求。此外，这种技术还可以扩展到肿瘤组织和衰竭组织，并且可以在全球卫生危机期间提供更快速、更便宜的染色服务。<details>
<summary>Abstract</summary>
Histological examination is a crucial step in an autopsy; however, the traditional histochemical staining of post-mortem samples faces multiple challenges, including the inferior staining quality due to autolysis caused by delayed fixation of cadaver tissue, as well as the resource-intensive nature of chemical staining procedures covering large tissue areas, which demand substantial labor, cost, and time. These challenges can become more pronounced during global health crises when the availability of histopathology services is limited, resulting in further delays in tissue fixation and more severe staining artifacts. Here, we report the first demonstration of virtual staining of autopsy tissue and show that a trained neural network can rapidly transform autofluorescence images of label-free autopsy tissue sections into brightfield equivalent images that match hematoxylin and eosin (H&E) stained versions of the same samples, eliminating autolysis-induced severe staining artifacts inherent in traditional histochemical staining of autopsied tissue. Our virtual H&E model was trained using >0.7 TB of image data and a data-efficient collaboration scheme that integrates the virtual staining network with an image registration network. The trained model effectively accentuated nuclear, cytoplasmic and extracellular features in new autopsy tissue samples that experienced severe autolysis, such as COVID-19 samples never seen before, where the traditional histochemical staining failed to provide consistent staining quality. This virtual autopsy staining technique can also be extended to necrotic tissue, and can rapidly and cost-effectively generate artifact-free H&E stains despite severe autolysis and cell death, also reducing labor, cost and infrastructure requirements associated with the standard histochemical staining.
</details>
<details>
<summary>摘要</summary>
histological examination是Autopsy中的关键步骤，但传统的 histochemical staining方法面临多种挑战，包括由尸体泥炭引起的自体解剖引起的低质量着色，以及覆盖大面积组织的化学着色程序需要巨大的劳动力、成本和时间。在全球卫生危机期间， histopathology服务的可用性受限，导致组织着色的延迟和更严重的着色 artifacts。在这种情况下，我们提出了虚拟着色技术，使用训练过的神经网络将染色不含染料的 autopsy 组织切片转换成和染色后的 Hematoxylin and Eosin（H&E）染色版本匹配的明亮场景图像，消除自体解剖引起的严重着色 artifacts。我们的虚拟 H&E 模型通过 >0.7 TB 的图像数据和数据效率协作方案来训练，该方案将虚拟染色网络与图像 регистрация网络结合。训练后，模型能够有效强调组织中的核、细胞质和 extracellular 特征，包括 COVID-19 样本，这些样本在传统的 histochemical staining 中未能得到一致的染色质量。此虚拟染色技术还可以扩展到肿瘤组织，可以快速、成本低地生成 artifact-free H&E 染色，即使严重的自体解剖和细胞死亡。
</details></li>
</ul>
<hr>
<h2 id="VLUCI-Variational-Learning-of-Unobserved-Confounders-for-Counterfactual-Inference"><a href="#VLUCI-Variational-Learning-of-Unobserved-Confounders-for-Counterfactual-Inference" class="headerlink" title="VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference"></a>VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00904">http://arxiv.org/abs/2308.00904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghe Zhao, Qiang Huang, Siwei Wu, Yun Peng, Huiyan Sun</li>
<li>for: 本研究旨在提出一种新的变量学习模型，用于对 observational 数据中的不观测变量进行推断，以提高 causal inference 的准确性。</li>
<li>methods: 该模型基于变量学习的思想，使用 doubly 变量推断模型来approximate 不观测变量的 posterior distribution，并且可以与现有的 counterfactual inference 模型相结合使用。</li>
<li>results: 实验表明，该模型可以准确地推断不观测变量，并且可以与现有的模型相结合使用，以提高 counterfactual inference 的准确性。  Plus, the model provides confidence intervals for counterfactual outcomes, which is useful in risk-sensitive domains.<details>
<summary>Abstract</summary>
Causal inference plays a vital role in diverse domains like epidemiology, healthcare, and economics. De-confounding and counterfactual prediction in observational data has emerged as a prominent concern in causal inference research. While existing models tackle observed confounders, the presence of unobserved confounders remains a significant challenge, distorting causal inference and impacting counterfactual outcome accuracy. To address this, we propose a novel variational learning model of unobserved confounders for counterfactual inference (VLUCI), which generates the posterior distribution of unobserved confounders. VLUCI relaxes the unconfoundedness assumption often overlooked by most causal inference methods. By disentangling observed and unobserved confounders, VLUCI constructs a doubly variational inference model to approximate the distribution of unobserved confounders, which are used for inferring more accurate counterfactual outcomes. Extensive experiments on synthetic and semi-synthetic datasets demonstrate VLUCI's superior performance in inferring unobserved confounders. It is compatible with state-of-the-art counterfactual inference models, significantly improving inference accuracy at both group and individual levels. Additionally, VLUCI provides confidence intervals for counterfactual outcomes, aiding decision-making in risk-sensitive domains. We further clarify the considerations when applying VLUCI to cases where unobserved confounders don't strictly conform to our model assumptions using the public IHDP dataset as an example, highlighting the practical advantages of VLUCI.
</details>
<details>
<summary>摘要</summary>
causal inference在多个领域中扮演着重要的角色，如epidemiology、医疗和经济等。在观察数据中，解除干扰和预测Counterfactual outcome成为了causal inference研究中的一个显著挑战。现有的模型可以处理观察到的干扰因素，但未观察到的干扰因素的存在仍然是一个主要的挑战，对 causal inference 和 counterfactual outcome的准确性产生干扰。为解决这个问题，我们提出了一种新的变分学习模型（VLUCI），可以生成未观察到的干扰因素的 posterior 分布。VLUCI 释放了对观察到的干扰因素的假设，从而更好地解除干扰。通过分离观察到和未观察到的干扰因素，VLUCI 构建了一个双变分推理模型，用于估计未观察到的干扰因素，从而更准确地预测 counterfactual outcome。我们在 synthetic 和半 synthetic 数据集上进行了广泛的实验，显示 VLUCI 在推理未观察到的干扰因素方面表现出色。它可以与当前的 counterfactual inference 模型相容，在组织和个体水平上提高推理准确性。此外，VLUCI 还提供了对 counterfactual outcome 的信息interval，帮助在风险敏感领域做出决策。我们还在使用公共 IHDP 数据集为例，详细介绍了在实际应用中考虑 VLUCI 的一般考虑事项。
</details></li>
</ul>
<hr>
<h2 id="User-Controllable-Recommendation-via-Counterfactual-Retrospective-and-Prospective-Explanations"><a href="#User-Controllable-Recommendation-via-Counterfactual-Retrospective-and-Prospective-Explanations" class="headerlink" title="User-Controllable Recommendation via Counterfactual Retrospective and Prospective Explanations"></a>User-Controllable Recommendation via Counterfactual Retrospective and Prospective Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00894">http://arxiv.org/abs/2308.00894</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisjtan/ucr">https://github.com/chrisjtan/ucr</a></li>
<li>paper_authors: Juntao Tan, Yingqiang Ge, Yan Zhu, Yinglong Xia, Jiebo Luo, Jianchao Ji, Yongfeng Zhang</li>
<li>for: 提高用户满意度和信任度，提供用户可控制的个性化推荐</li>
<li>methods:  combinatorial explainable recommender systems，counterfactual reasoning，user control options</li>
<li>results: 在MovieLens和Yelp数据集上实验 validate 提议的效果，并且发现在提供用户控制选项时，可能会提高未来推荐的准确率<details>
<summary>Abstract</summary>
Modern recommender systems utilize users' historical behaviors to generate personalized recommendations. However, these systems often lack user controllability, leading to diminished user satisfaction and trust in the systems. Acknowledging the recent advancements in explainable recommender systems that enhance users' understanding of recommendation mechanisms, we propose leveraging these advancements to improve user controllability. In this paper, we present a user-controllable recommender system that seamlessly integrates explainability and controllability within a unified framework. By providing both retrospective and prospective explanations through counterfactual reasoning, users can customize their control over the system by interacting with these explanations.   Furthermore, we introduce and assess two attributes of controllability in recommendation systems: the complexity of controllability and the accuracy of controllability. Experimental evaluations on MovieLens and Yelp datasets substantiate the effectiveness of our proposed framework. Additionally, our experiments demonstrate that offering users control options can potentially enhance recommendation accuracy in the future. Source code and data are available at \url{https://github.com/chrisjtan/ucr}.
</details>
<details>
<summary>摘要</summary>
现代推荐系统通常使用用户历史行为生成个性化推荐，但这些系统经常缺乏用户可控性，导致用户满意度和信任度减退。鉴于近年来的可解释推荐系统的进步，我们提议利用这些进步来提高用户可控性。在本文中，我们提出了一种可控性推荐系统，该系统内置了解释和可控性的统一框架。通过对解释和可控性进行反思，用户可以自定义他们对系统的控制。此外，我们引入了两个推荐系统可控性的特性：复杂性可控性和准确性可控性。我们在 MovieLens 和 Yelp 数据集上进行了实验评估，并证明了我们提出的框架的有效性。此外，我们的实验还表明，向用户提供控制选项可能会提高未来推荐的准确性。源代码和数据可以在 <https://github.com/chrisjtan/ucr> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Tango-rethinking-quantization-for-graph-neural-network-training-on-GPUs"><a href="#Tango-rethinking-quantization-for-graph-neural-network-training-on-GPUs" class="headerlink" title="Tango: rethinking quantization for graph neural network training on GPUs"></a>Tango: rethinking quantization for graph neural network training on GPUs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00890">http://arxiv.org/abs/2308.00890</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiyang Chen, Da Zheng, Caiwen Ding, Chengying Huan, Yuede Ji, Hang Liu</li>
<li>for: 这篇论文主要旨在提高图 нейрон网络训练的效率，使用量化来加速计算。</li>
<li>methods: 该论文提出了三大贡献：首先，提供了精炼的规则来保持量化训练中的准确性。其次，设计了量化感知的基本 primitives 和间接优化，以加速 GNN 训练。最后，与 популяр的 Deep Graph Library (DGL) 系统集成，并在多种 GNN 模型和数据集上达到了状态arc的性能。</li>
<li>results: 该论文通过 Tango 系统，在多种 GNN 模型和数据集上达到了更高的训练效率，比如 state-of-the-art 方法快。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) are becoming increasingly popular due to their superior performance in critical graph-related tasks. While quantization is widely used to accelerate GNN computation, quantized training faces unprecedented challenges. Current quantized GNN training systems often have longer training times than their full-precision counterparts for two reasons: (i) addressing the accuracy challenge leads to excessive overhead, and (ii) the optimization potential exposed by quantization is not adequately leveraged. This paper introduces Tango which re-thinks quantization challenges and opportunities for graph neural network training on GPUs with three contributions: Firstly, we introduce efficient rules to maintain accuracy during quantized GNN training. Secondly, we design and implement quantization-aware primitives and inter-primitive optimizations that can speed up GNN training. Finally, we integrate Tango with the popular Deep Graph Library (DGL) system and demonstrate its superior performance over state-of-the-art approaches on various GNN models and datasets.
</details>
<details>
<summary>摘要</summary>
graph neural networks (GNNs) 在 kritical graph-related tasks 中的表现越来越出色，但量化训练面临无 precedent 的挑战。现有的量化 GNN 训练系统经常比其整数精度 counterparts  longer training time  due to two reasons: (i) addressing the accuracy challenge leads to excessive overhead, and (ii) the optimization potential exposed by quantization is not adequately leveraged. This paper introduces Tango, which re-thinks quantization challenges and opportunities for graph neural network training on GPUs with three contributions: Firstly, we introduce efficient rules to maintain accuracy during quantized GNN training. Secondly, we design and implement quantization-aware primitives and inter-primitive optimizations that can speed up GNN training. Finally, we integrate Tango with the popular Deep Graph Library (DGL) system and demonstrate its superior performance over state-of-the-art approaches on various GNN models and datasets.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard Chinese dialects. If you prefer Traditional Chinese, please let me know and I can provide the translation in that dialect as well.
</details></li>
</ul>
<hr>
<h2 id="Factor-Graph-Neural-Networks"><a href="#Factor-Graph-Neural-Networks" class="headerlink" title="Factor Graph Neural Networks"></a>Factor Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00887">http://arxiv.org/abs/2308.00887</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/molyswu/hand_detection">https://github.com/molyswu/hand_detection</a></li>
<li>paper_authors: Zhen Zhang, Mohammed Haroon Dupty, Fan Wu, Javen Qinfeng Shi, Wee Sun Lee</li>
<li>for: 本 paper 的目的是提出一种能够有效地捕捉高阶关系的图神经网络（FGNN），以便进行推理和学习。</li>
<li>methods: 本 paper 使用的方法包括提出一种高效的准确推理算法，以及将这种算法 Neil 化为一种带有更加复杂的消息更新规则的图神经网络模块。</li>
<li>results: 本 paper 的实验结果表明，提出的 FGNN 模型可以在 sintetic 数据集和实际数据集上达到出色的性能，并且可以代表 Max-Product 和 Sum-Product 循环信念传播。<details>
<summary>Abstract</summary>
In recent years, we have witnessed a surge of Graph Neural Networks (GNNs), most of which can learn powerful representations in an end-to-end fashion with great success in many real-world applications. They have resemblance to Probabilistic Graphical Models (PGMs), but break free from some limitations of PGMs. By aiming to provide expressive methods for representation learning instead of computing marginals or most likely configurations, GNNs provide flexibility in the choice of information flowing rules while maintaining good performance. Despite their success and inspirations, they lack efficient ways to represent and learn higher-order relations among variables/nodes. More expressive higher-order GNNs which operate on k-tuples of nodes need increased computational resources in order to process higher-order tensors. We propose Factor Graph Neural Networks (FGNNs) to effectively capture higher-order relations for inference and learning. To do so, we first derive an efficient approximate Sum-Product loopy belief propagation inference algorithm for discrete higher-order PGMs. We then neuralize the novel message passing scheme into a Factor Graph Neural Network (FGNN) module by allowing richer representations of the message update rules; this facilitates both efficient inference and powerful end-to-end learning. We further show that with a suitable choice of message aggregation operators, our FGNN is also able to represent Max-Product belief propagation, providing a single family of architecture that can represent both Max and Sum-Product loopy belief propagation. Our extensive experimental evaluation on synthetic as well as real datasets demonstrates the potential of the proposed model.
</details>
<details>
<summary>摘要</summary>
近年来，我们目睹了一场Graph Neural Networks（GNN）的浪涌，大多数可以在终端式的方式学习出强大的表示，在许多实际应用中取得了很大的成功。它们与 probabilistic Graphical Models（PGMs）有相似之处，但是超越了一些PGMs的限制。通过targeting表示学习而不是计算margin或最有可能的配置，GNNs提供了信息流动规则的灵活性，同时保持良好的性能。尽管它们的成功和灵感，但它们缺乏高阶关系的表示和学习方法。高阶GNNs需要更多的计算资源来处理高阶tensor。我们提议使用Factor Graph Neural Networks（FGNNs）来有效地捕捉高阶关系 для推理和学习。我们首先 derivate了一种高效的approximate Sum-Product loopy belief propagation推理算法 для离散高阶PGMs。然后，我们将这种新的message passing scheme neuralize到Factor Graph Neural Network（FGNN）模块中，允许更加丰富的message update规则表示，从而实现了有效的推理和强大的终端式学习。此外，我们还证明了在适当的message汇聚操作下，我们的FGNN可以表示Max-Product belief propagation，从而提供了一个单一的家族结构，可以表示Max和Sum-Product loopy belief propagation。我们对synthetic以及实际数据进行了广泛的实验评估，demonstrating the potential of the proposed model.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Machine-Learning-Performance-with-Continuous-In-Session-Ground-Truth-Scores-Pilot-Study-on-Objective-Skeletal-Muscle-Pain-Intensity-Prediction"><a href="#Enhancing-Machine-Learning-Performance-with-Continuous-In-Session-Ground-Truth-Scores-Pilot-Study-on-Objective-Skeletal-Muscle-Pain-Intensity-Prediction" class="headerlink" title="Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction"></a>Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00886">http://arxiv.org/abs/2308.00886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boluwatife E. Faremi, Jonathon Stavres, Nuno Oliveira, Zhaoxian Zhou, Andrew H. Sung<br>for: This study aimed to develop a novel approach for objective pain intensity characterization using machine learning (ML) models and real-time, continuous in-session pain scores.methods: The study used two devices to acquire real-time pain scores and ANS-modulated endodermal activity (EDA) data. The authors used a custom pain platform to store and extract time-domain EDA features and in-session ground truth scores. They trained ML models, including Multi-layer Perceptron (MLP) and Random Forest (RF), using objective EDA features and in-session scores.results: The study found that using continuous in-session ground truth scores significantly enhanced the performance of ML models in pain intensity characterization, with macro-averaged geometric mean scores of 75.9% and 78.3% for MLP and RF models, respectively, compared to scores of 70.3% and 74.6% for models trained with post-session scores. The study demonstrates the potential of using real-time, continuous pain scores to improve the accuracy of ML pain systems.<details>
<summary>Abstract</summary>
Machine learning (ML) models trained on subjective self-report scores struggle to objectively classify pain accurately due to the significant variance between real-time pain experiences and recorded scores afterwards. This study developed two devices for acquisition of real-time, continuous in-session pain scores and gathering of ANS-modulated endodermal activity (EDA).The experiment recruited N = 24 subjects who underwent a post-exercise circulatory occlusion (PECO) with stretch, inducing discomfort. Subject data were stored in a custom pain platform, facilitating extraction of time-domain EDA features and in-session ground truth scores. Moreover, post-experiment visual analog scale (VAS) scores were collected from each subject. Machine learning models, namely Multi-layer Perceptron (MLP) and Random Forest (RF), were trained using corresponding objective EDA features combined with in-session scores and post-session scores, respectively. Over a 10-fold cross-validation, the macro-averaged geometric mean score revealed MLP and RF models trained with objective EDA features and in-session scores achieved superior performance (75.9% and 78.3%) compared to models trained with post-session scores (70.3% and 74.6%) respectively. This pioneering study demonstrates that using continuous in-session ground truth scores significantly enhances ML performance in pain intensity characterization, overcoming ground truth sparsity-related issues, data imbalance, and high variance. This study informs future objective-based ML pain system training.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）模型在主观自报分数上训练时，很难准确地分类疼痛，因为主观自报分数和实际时间内疼痛经历之间存在很大的差异。这个研究开发了两种设备用于实时、连续的疼痛分数获取和胃内活动评估（EDA）的收集。研究采用N = 24名参与者，经历了后期静脉填充（PECO）的伸展，导致不适。参与者的数据被存储在自定义的疼痛平台上，以便提取时间域EDA特征和实际时间内的真实分数。此外，每名参与者还提供了后实验的Visual Analog Scale（VAS）分数。机器学习模型，即多层感知器（MLP）和随机森林（RF），被训练使用对应的对象EDA特征和实际时间内分数 combinated with post-session scores。在10次横跨验证中，macro平均幂数分数表明MLP和RF模型使用对象EDA特征和实际时间内分数训练时的性能（75.9%和78.3%）高于使用post-session scores训练时的性能（70.3%和74.6%）。这项先驱研究表明，使用连续实际时间内的真实分数可以大大提高ML的疼痛强度特征化性能，超越真实分数稀缺、数据不均衡和高差异问题。这项研究为未来基于对象的ML疼痛系统训练提供了指导。
</details></li>
</ul>
<hr>
<h2 id="Revolutionizing-Wireless-Networks-with-Federated-Learning-A-Comprehensive-Review"><a href="#Revolutionizing-Wireless-Networks-with-Federated-Learning-A-Comprehensive-Review" class="headerlink" title="Revolutionizing Wireless Networks with Federated Learning: A Comprehensive Review"></a>Revolutionizing Wireless Networks with Federated Learning: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04404">http://arxiv.org/abs/2308.04404</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sajjad Emdadi Mahdimahalleh</li>
<li>for: 本文探讨了在无线通信中机器学习的重要性，以及 federated learning（FL）在未来移动网络中的潜在作用。</li>
<li>methods: 本文使用了 federated learning（FL），它在无线边缘网络中分离了数据收集和计算，与传统的中央化学习不同。</li>
<li>results: 本文指出，由于无线通信资源有限和不可预测，FL 可以更好地适应这些环境，并且可以提高无线通信系统的效率和可靠性。<details>
<summary>Abstract</summary>
These days with the rising computational capabilities of wireless user equipment such as smart phones, tablets, and vehicles, along with growing concerns about sharing private data, a novel machine learning model called federated learning (FL) has emerged. FL enables the separation of data acquisition and computation at the central unit, which is different from centralized learning that occurs in a data center. FL is typically used in a wireless edge network where communication resources are limited and unreliable. Bandwidth constraints necessitate scheduling only a subset of UEs for updates in each iteration, and because the wireless medium is shared, transmissions are susceptible to interference and are not assured. The article discusses the significance of Machine Learning in wireless communication and highlights Federated Learning (FL) as a novel approach that could play a vital role in future mobile networks, particularly 6G and beyond.
</details>
<details>
<summary>摘要</summary>
现在，由于无线用户设备的计算能力的提高，如智能手机、平板电脑和车辆，以及对共享私人数据的关注，一种新的机器学习模型叫做联邦学习（FL）已经出现。FL使得数据获取和计算在中央单元分离开，与中央集中学习在数据中心不同。FL通常在无线边缘网络中使用，因为通信资源有限和不可预测。由于带宽有限，每次迭代只能将一 subset of UE进行更新，因为无线媒体共享，传输受到干扰和不能保证。文章介绍了无线通信中机器学习的重要性，并将联邦学习（FL）作为未来无线网络中的重要角色提出。
</details></li>
</ul>
<hr>
<h2 id="PeRP-Personalized-Residual-Policies-For-Congestion-Mitigation-Through-Co-operative-Advisory-Systems"><a href="#PeRP-Personalized-Residual-Policies-For-Congestion-Mitigation-Through-Co-operative-Advisory-Systems" class="headerlink" title="PeRP: Personalized Residual Policies For Congestion Mitigation Through Co-operative Advisory Systems"></a>PeRP: Personalized Residual Policies For Congestion Mitigation Through Co-operative Advisory Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00864">http://arxiv.org/abs/2308.00864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aamir Hasan, Neeloy Chakraborty, Haonan Chen, Jung-Hoon Cho, Cathy Wu, Katherine Driggs-Campbell</li>
<li>for: 本研究旨在提高自动驾驶系统的可靠性和效率，以提高社会经济因素 such as 通勤时间和燃油费用。</li>
<li>methods: 本研究使用 Piecewise Constant（PC）策略和个性化剩余策略（PeRP），以模型人类驾驶行为，提供个性化的行为建议。</li>
<li>results: 我们的方法在模拟环境中训练完成，与基线比较，显示我们的方法可以成功地减轻交通堵塞，适应不同的 Driver 行为，提高平均速度4-22%。<details>
<summary>Abstract</summary>
Intelligent driving systems can be used to mitigate congestion through simple actions, thus improving many socioeconomic factors such as commute time and gas costs. However, these systems assume precise control over autonomous vehicle fleets, and are hence limited in practice as they fail to account for uncertainty in human behavior. Piecewise Constant (PC) Policies address these issues by structurally modeling the likeness of human driving to reduce traffic congestion in dense scenarios to provide action advice to be followed by human drivers. However, PC policies assume that all drivers behave similarly. To this end, we develop a co-operative advisory system based on PC policies with a novel driver trait conditioned Personalized Residual Policy, PeRP. PeRP advises drivers to behave in ways that mitigate traffic congestion. We first infer the driver's intrinsic traits on how they follow instructions in an unsupervised manner with a variational autoencoder. Then, a policy conditioned on the inferred trait adapts the action of the PC policy to provide the driver with a personalized recommendation. Our system is trained in simulation with novel driver modeling of instruction adherence. We show that our approach successfully mitigates congestion while adapting to different driver behaviors, with 4 to 22% improvement in average speed over baselines.
</details>
<details>
<summary>摘要</summary>
智能驾驶系统可以减轻交通拥堵，提高了许多社会经济指标，如通勤时间和油费成本。然而，这些系统假设自动车辆队伍具有精确的控制权，因此在实践中受到限制，因为它们无法考虑人类行为的不确定性。 Piecewise Constant（PC）策略可以解决这些问题，通过结构化模型人类驾驶行为，以减少繁忙场景中的交通拥堵，并提供行动建议，以便人类驾驶员遵循。然而，PC策略假设所有 drivers 都 behave similarly。为此，我们开发了一种合作性建议系统，基于 PC 策略和一种新的 Driver Trait  Conditioned Personalized Residual Policy（PeRP）。PeRP 建议 drivers 采取 mitigating 交通拥堵的行动。我们首先使用变量自动编码器在无监督的方式推断 driver 的内在特征，然后根据推断到的特征 conditioned 策略，提供个性化的建议。我们的系统在 simulate 中受到新的 driver 模型的 instrucion adherence 训练。我们表明，我们的方法可以成功地减少交通拥堵，同时适应不同 driver 行为，与基准相比，提高了4%-22%的平均速度。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Activation-Patterns-in-Artificial-Neural-Networks-by-Exploring-Stochastic-Processes"><a href="#Understanding-Activation-Patterns-in-Artificial-Neural-Networks-by-Exploring-Stochastic-Processes" class="headerlink" title="Understanding Activation Patterns in Artificial Neural Networks by Exploring Stochastic Processes"></a>Understanding Activation Patterns in Artificial Neural Networks by Exploring Stochastic Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00858">http://arxiv.org/abs/2308.00858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephan Johann Lehmler, Muhammad Saif-ur-Rehman, Tobias Glasmachers, Ioannis Iossifidis</li>
<li>for: 本研究想要更深入地理解人工神经网络（deep artificial neural network）的行为和学习动力学。</li>
<li>methods: 本研究使用杂素过程框架，它在人工神经网络性能方面提供了一种简化的视角，并且可以通过仿真来进行系统性的调查。</li>
<li>results: 研究人员使用杂素过程模型对不同的人工神经网络进行分析，发现这些网络在学习过程中的活动模式具有稳定的特征，并且可以通过 Mean Firing Rate、Mean Fano Factor 和 Variances 等指标来评估这些活动模式。这些结果可能有助于理解人工神经网络的行为和学习机制。<details>
<summary>Abstract</summary>
To gain a deeper understanding of the behavior and learning dynamics of (deep) artificial neural networks, it is valuable to employ mathematical abstractions and models. These tools provide a simplified perspective on network performance and facilitate systematic investigations through simulations. In this paper, we propose utilizing the framework of stochastic processes, which has been underutilized thus far.   Our approach models activation patterns of thresholded nodes in (deep) artificial neural networks as stochastic processes. We focus solely on activation frequency, leveraging neuroscience techniques used for real neuron spike trains. During a classification task, we extract spiking activity and use an arrival process following the Poisson distribution.   We examine observed data from various artificial neural networks in image recognition tasks, fitting the proposed model's assumptions. Through this, we derive parameters describing activation patterns in each network. Our analysis covers randomly initialized, generalizing, and memorizing networks, revealing consistent differences across architectures and training sets.   Calculating Mean Firing Rate, Mean Fano Factor, and Variances, we find stable indicators of memorization during learning, providing valuable insights into network behavior. The proposed model shows promise in describing activation patterns and could serve as a general framework for future investigations. It has potential applications in theoretical simulations, pruning, and transfer learning.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:为了更深刻理解深度人工神经网络的行为和学习动态，使用数学抽象和模型是非常有价值的。这些工具可以简化网络性能的视图，并且通过仿真来进行系统性的调查。在这篇论文中，我们提议使用 Stochastic Processes 框架，这种框架在过去并未得到充分利用。  我们的方法是将 thresholded nodes 的活动模式模型为 Stochastic Processes。我们仅准确采用 activation frequency，并且参考了实际神经元的发射 Train 技术。在一个分类任务中，我们从不同的人工神经网络中提取了冲击活动，并使用 Poisson 分布来描述到达过程。  我们对不同的人工神经网络在图像识别任务中的观察数据进行了适应，并从中 derive 了每个网络的活动模式参数。我们的分析覆盖了随机初始化、泛化和记忆化网络，并发现这些网络在不同的架构和训练集之间存在一致的差异。  计算 Mean Firing Rate、Mean Fano Factor 和 Variances，我们发现在学习过程中，记忆化存在稳定的指标，这些指标为我们对网络行为提供了有价值的洞察。我们的模型表示了 activation patterns 的描述，并且有可能在未来的研究中扮演一个普遍的框架。它还可以在理论仿真、剪辑和转移学习等方面应用。
</details></li>
</ul>
<hr>
<h2 id="Differential-Privacy-for-Adaptive-Weight-Aggregation-in-Federated-Tumor-Segmentation"><a href="#Differential-Privacy-for-Adaptive-Weight-Aggregation-in-Federated-Tumor-Segmentation" class="headerlink" title="Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation"></a>Differential Privacy for Adaptive Weight Aggregation in Federated Tumor Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00856">http://arxiv.org/abs/2308.00856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Irfan Khan, Esa Alhoniemi, Elina Kontio, Suleiman A. Khan, Mojtaba Jafaritadi</li>
<li>For: 这个研究旨在提供一个具有数据隐私保护的联邦学习架构，以保护医疗影像数据的隐私和数据完整性。* Methods: 这个研究使用了一个叫做DP-SimAgg的分子类似隐私复杂数据联邦学习架构，具有提高模型分类能力和隐私保护的两个优点。* Results: 研究结果显示，DP-SimAgg可以实现精确且Robust的脑膜肿瘤分类，并对于通信成本的降低做出了重要贡献。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed machine learning approach that safeguards privacy by creating an impartial global model while respecting the privacy of individual client data. However, the conventional FL method can introduce security risks when dealing with diverse client data, potentially compromising privacy and data integrity. To address these challenges, we present a differential privacy (DP) federated deep learning framework in medical image segmentation. In this paper, we extend our similarity weight aggregation (SimAgg) method to DP-SimAgg algorithm, a differentially private similarity-weighted aggregation algorithm for brain tumor segmentation in multi-modal magnetic resonance imaging (MRI). Our DP-SimAgg method not only enhances model segmentation capabilities but also provides an additional layer of privacy preservation. Extensive benchmarking and evaluation of our framework, with computational performance as a key consideration, demonstrate that DP-SimAgg enables accurate and robust brain tumor segmentation while minimizing communication costs during model training. This advancement is crucial for preserving the privacy of medical image data and safeguarding sensitive information. In conclusion, adding a differential privacy layer in the global weight aggregation phase of the federated brain tumor segmentation provides a promising solution to privacy concerns without compromising segmentation model efficacy. By leveraging DP, we ensure the protection of client data against adversarial attacks and malicious participants.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种分布式机器学习方法，保护隐私 by creating an impartial global model while respecting the privacy of individual client data。然而，传统的 FL 方法可能会引入安全风险，特别是处理多样化的客户端数据，可能会威胁隐私和数据完整性。为了解决这些挑战，我们在医疗图像分割中提出了一种含有权限的 federated deep learning 框架。在这篇论文中，我们将我们的相似性Weight集成 (SimAgg) 方法扩展到 differentially private 的 SimAgg 算法，用于在多Modal 磁共振成像 (MRI) 中的脑肿瘤分割。我们的 DP-SimAgg 方法不仅提高了模型分割能力，还提供了一层额外的隐私保护。我们对我们的框架进行了广泛的测试和评估，以计算性能为关键考虑因素，并证明了 DP-SimAgg 可以准确地 segment brain tumor  while minimizing communication costs during model training。这一进步对于保护医疗图像数据的隐私和敏感信息的安全是关键。因此，我们认为在 global weight aggregation 阶段添加 differential privacy 层是一种有 Promise的解决方案，不会COMPROMISE segmentation model efficacy。通过运用 DP，我们能够保护客户端数据免受敌对攻击和恶意参与者的威胁。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Study-of-Groundbreaking-Machine-Learning-Research-Analyzing-Highly-Cited-and-Impactful-Publications-across-Six-Decades"><a href="#A-Comprehensive-Study-of-Groundbreaking-Machine-Learning-Research-Analyzing-Highly-Cited-and-Impactful-Publications-across-Six-Decades" class="headerlink" title="A Comprehensive Study of Groundbreaking Machine Learning Research: Analyzing Highly Cited and Impactful Publications across Six Decades"></a>A Comprehensive Study of Groundbreaking Machine Learning Research: Analyzing Highly Cited and Impactful Publications across Six Decades</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00855">http://arxiv.org/abs/2308.00855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Absalom E. Ezugwu, Japie Greeff, Yuh-Shan Ho</li>
<li>for: 本研究目的是为了了解机器学习（ML）领域最高引用的论文，以便了解该领域的主要趋势、影响人员和贡献。</li>
<li>methods: 本研究使用了各种 bibliometric 技术进行分析，包括引用分析、合作关系分析、关键词分析和出版趋势分析。</li>
<li>results: 研究发现了机器学习社区中最具影响力的论文、高引用的作者和合作网络，以及最受欢迎的研究主题和升起的新趋势。  Additionally, the study found that certain countries have a dominant position in ML research.<details>
<summary>Abstract</summary>
Machine learning (ML) has emerged as a prominent field of research in computer science and other related fields, thereby driving advancements in other domains of interest. As the field continues to evolve, it is crucial to understand the landscape of highly cited publications to identify key trends, influential authors, and significant contributions made thus far. In this paper, we present a comprehensive bibliometric analysis of highly cited ML publications. We collected a dataset consisting of the top-cited papers from reputable ML conferences and journals, covering a period of several years from 1959 to 2022. We employed various bibliometric techniques to analyze the data, including citation analysis, co-authorship analysis, keyword analysis, and publication trends. Our findings reveal the most influential papers, highly cited authors, and collaborative networks within the machine learning community. We identify popular research themes and uncover emerging topics that have recently gained significant attention. Furthermore, we examine the geographical distribution of highly cited publications, highlighting the dominance of certain countries in ML research. By shedding light on the landscape of highly cited ML publications, our study provides valuable insights for researchers, policymakers, and practitioners seeking to understand the key developments and trends in this rapidly evolving field.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CASSINI-Network-Aware-Job-Scheduling-in-Machine-Learning-Clusters"><a href="#CASSINI-Network-Aware-Job-Scheduling-in-Machine-Learning-Clusters" class="headerlink" title="CASSINI: Network-Aware Job Scheduling in Machine Learning Clusters"></a>CASSINI: Network-Aware Job Scheduling in Machine Learning Clusters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00852">http://arxiv.org/abs/2308.00852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudarsanan Rajasekaran, Manya Ghobadi, Aditya Akella</li>
<li>for: 提高机器学习（ML）集群中任务的完成时间和流量控制</li>
<li>methods: 使用网络卷积图来考虑不同任务之间的通信模式，并通过调整时间偏移值来调整这些任务的通信阶段</li>
<li>results: 在24个服务器测试环境中，与状态艺术ML调度器相比，CASSINI可以提高任务的平均和尾部完成时间 by up to 1.6x和2.5x，同时还可以减少集群中ECN标记包的数量 by up to 33x。<details>
<summary>Abstract</summary>
We present CASSINI, a network-aware job scheduler for machine learning (ML) clusters. CASSINI introduces a novel geometric abstraction to consider the communication pattern of different jobs while placing them on network links. To do so, CASSINI uses an affinity graph that finds a series of time-shift values to adjust the communication phases of a subset of jobs, such that the communication patterns of jobs sharing the same network link are interleaved with each other. Experiments with 13 common ML models on a 24-server testbed demonstrate that compared to the state-of-the-art ML schedulers, CASSINI improves the average and tail completion time of jobs by up to 1.6x and 2.5x, respectively. Moreover, we show that CASSINI reduces the number of ECN marked packets in the cluster by up to 33x.
</details>
<details>
<summary>摘要</summary>
我们介绍CASSINI，一个对Machine Learning（ML）集群有对网络耦合的任务安排器。CASSINI引入了一个新的几何抽象，考虑不同任务之间的通信模式，并在网络链接上分配任务。为此，CASSINI使用一个相互作用graph，找到一系列时间延迟值，以调整具有共同网络链接的任务之间的通信阶段。实验结果显示，相比于现有的ML安排器，CASSINI可以提高任务的平均和尾部完成时间 by up to 1.6倍和2.5倍，分别。此外，我们显示CASSINI可以在集群中对ECN标识的封包数量减少到33倍。
</details></li>
</ul>
<hr>
<h2 id="An-Exact-Kernel-Equivalence-for-Finite-Classification-Models"><a href="#An-Exact-Kernel-Equivalence-for-Finite-Classification-Models" class="headerlink" title="An Exact Kernel Equivalence for Finite Classification Models"></a>An Exact Kernel Equivalence for Finite Classification Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00824">http://arxiv.org/abs/2308.00824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brian Bell, Michael Geyer, David Glickenstein, Amanda Fernandez, Juston Moore</li>
<li>for: 这个论文是为了探讨神经网络和kernel方法之间的等价关系，并提出了首个精确表示任何 finite-size parametric classification model 的方法。</li>
<li>methods: 该论文使用了Gradient Descent来训练神经网络，并 derivated了一个精确的kernel机器。</li>
<li>results: 实验表明，该kernel可以在实际网络上计算到Machine Precision级别，并且可以提供有用的泛化理解。<details>
<summary>Abstract</summary>
We explore the equivalence between neural networks and kernel methods by deriving the first exact representation of any finite-size parametric classification model trained with gradient descent as a kernel machine. We compare our exact representation to the well-known Neural Tangent Kernel (NTK) and discuss approximation error relative to the NTK and other non-exact path kernel formulations. We experimentally demonstrate that the kernel can be computed for realistic networks up to machine precision. We use this exact kernel to show that our theoretical contribution can provide useful insights into the predictions made by neural networks, particularly the way in which they generalize.
</details>
<details>
<summary>摘要</summary>
我们研究神经网络和核方法之间的等价关系，通过将任何具有Gradient Descent训练的finite-size Parametric类别模型转换为核机制。我们与Well-known Neural Tangent Kernel（NTK）进行比较，并讨论非正确的路径核方法的误差。我们还证明了可以实际地Compute这个核函数 для现实的神经网络，至机器精度。我们使用这个精确的核函数，以示我们的理论贡献可以提供有用的预测性关于神经网络的预测。
</details></li>
</ul>
<hr>
<h2 id="An-Introduction-to-Bi-level-Optimization-Foundations-and-Applications-in-Signal-Processing-and-Machine-Learning"><a href="#An-Introduction-to-Bi-level-Optimization-Foundations-and-Applications-in-Signal-Processing-and-Machine-Learning" class="headerlink" title="An Introduction to Bi-level Optimization: Foundations and Applications in Signal Processing and Machine Learning"></a>An Introduction to Bi-level Optimization: Foundations and Applications in Signal Processing and Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00788">http://arxiv.org/abs/2308.00788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihua Zhang, Prashant Khanduri, Ioannis Tsaknakis, Yuguang Yao, Mingyi Hong, Sijia Liu</li>
<li>For: This paper is focused on developing an overview of bi-level optimization (BLO) problems in the context of signal processing (SP) and machine learning (ML) applications.* Methods: The paper provides an overview of basic concepts, such as optimality conditions, standard algorithms, and practical implementations of BLO problems in SP and ML applications.* Results: The paper discusses recent advances in BLO theory, its implications for applications, and points out some limitations of the state-of-the-art that require significant future research efforts.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文主要关注在信号处理（SP）和机器学习（ML）应用中的双层优化（BLO）问题。</li>
<li>methods: 论文提供了BLO问题的基本概念，包括优化条件、标准算法和实践应用。</li>
<li>results: 论文讨论了最新的BLO理论发展，其应用效果和未来研究的限制。<details>
<summary>Abstract</summary>
Recently, bi-level optimization (BLO) has taken center stage in some very exciting developments in the area of signal processing (SP) and machine learning (ML). Roughly speaking, BLO is a classical optimization problem that involves two levels of hierarchy (i.e., upper and lower levels), wherein obtaining the solution to the upper-level problem requires solving the lower-level one. BLO has become popular largely because it is powerful in modeling problems in SP and ML, among others, that involve optimizing nested objective functions. Prominent applications of BLO range from resource allocation for wireless systems to adversarial machine learning. In this work, we focus on a class of tractable BLO problems that often appear in SP and ML applications. We provide an overview of some basic concepts of this class of BLO problems, such as their optimality conditions, standard algorithms (including their optimization principles and practical implementations), as well as how they can be leveraged to obtain state-of-the-art results for a number of key SP and ML applications. Further, we discuss some recent advances in BLO theory, its implications for applications, and point out some limitations of the state-of-the-art that require significant future research efforts. Overall, we hope that this article can serve to accelerate the adoption of BLO as a generic tool to model, analyze, and innovate on a wide array of emerging SP and ML applications.
</details>
<details>
<summary>摘要</summary>
近期，双层优化（BLO）在信号处理（SP）和机器学习（ML）领域备受关注。简言之，BLO是一个经典的优化问题，其包含两层层次结构（上下两层），其中解决上层问题需要解决下层问题。BLO受欢迎的原因在于它能够模型嵌入式目标函数的问题，如SP和ML应用中的资源分配和对抗学习等。在这篇文章中，我们将关注一类可解决的BLO问题，包括其优化条件、标准算法（包括优化原理和实践）以及如何使其在多个关键SP和ML应用中实现state-of-the-art结果。此外，我们还讨论了BLO理论的最新进展、其应用领域的影响和未来研究的限制。总之，我们希望通过这篇文章，加速BLO的采用，作为模型、分析和创新多种emerging SP和ML应用的一种通用工具。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Spiking-Neural-Network-On-Neuromorphic-Platform-For-Human-Activity-Recognition"><a href="#Evaluating-Spiking-Neural-Network-On-Neuromorphic-Platform-For-Human-Activity-Recognition" class="headerlink" title="Evaluating Spiking Neural Network On Neuromorphic Platform For Human Activity Recognition"></a>Evaluating Spiking Neural Network On Neuromorphic Platform For Human Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00787">http://arxiv.org/abs/2308.00787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sizhen Bian, Michele Magno</li>
<li>for: 这个研究的目的是评估使用神经元网络处理器进行人体活动识别，以满足智能手表的能源效率和延迟时间的要求。</li>
<li>methods: 这个研究使用了多reshold delta modulation方法来将输入感应器资料转换为射频，然后将射频输入到神经元网络中进行训练。</li>
<li>results: 研究结果显示，使用射频识别系统可以与使用传统神经网络相比，实现二倍的能源延迟产品（0.66 \si{\micro\joule\second} vs. 1.32 \si{\micro\joule\second），并且实现了87.5%的准确率。<details>
<summary>Abstract</summary>
Energy efficiency and low latency are crucial requirements for designing wearable AI-empowered human activity recognition systems, due to the hard constraints of battery operations and closed-loop feedback. While neural network models have been extensively compressed to match the stringent edge requirements, spiking neural networks and event-based sensing are recently emerging as promising solutions to further improve performance due to their inherent energy efficiency and capacity to process spatiotemporal data in very low latency. This work aims to evaluate the effectiveness of spiking neural networks on neuromorphic processors in human activity recognition for wearable applications. The case of workout recognition with wrist-worn wearable motion sensors is used as a study. A multi-threshold delta modulation approach is utilized for encoding the input sensor data into spike trains to move the pipeline into the event-based approach. The spikes trains are then fed to a spiking neural network with direct-event training, and the trained model is deployed on the research neuromorphic platform from Intel, Loihi, to evaluate energy and latency efficiency. Test results show that the spike-based workouts recognition system can achieve a comparable accuracy (87.5\%) comparable to the popular milliwatt RISC-V bases multi-core processor GAP8 with a traditional neural network ( 88.1\%) while achieving two times better energy-delay product (0.66 \si{\micro\joule\second} vs. 1.32 \si{\micro\joule\second}).
</details>
<details>
<summary>摘要</summary>
“能源效率和延迟时间是设计智能穿戴式人体活动识别系统的关键要求，因为电池运作的硬性限制和关闭反馈loop。尽管神经网络模型已经广泛压缩以适应边缘的 Stringent requirements，脉冲神经网络和事件感知是最近几年出现的有前途的解决方案，因为它们的内生能效和能够在很低的延迟时间处理空间时间数据。本工作旨在评估使用神经元处理器在人体活动识别中的脉冲神经网络效果。使用腕上穿戴式运动传感器进行运动识别作为研究。使用多reshold delta 模ulation方法编码输入传感器数据为脉冲 trains，然后将脉冲 trains feed到一个直接事件培训的脉冲神经网络中。经过训练后，模型被部署到英特尔的 Loihi 研究神经元平台上进行评估能源和延迟效率。测试结果表明，使用脉冲工作识别系统可以达到相同的准确率（87.5%），与流行的 milliwatt RISC-V 基于多核心处理器 GAP8 的传统神经网络（88.1%）相比，而且可以两倍提高能源延迟产品（0.66 微\si{\joule\second} vs. 1.32 微\si{\joule\second）。”
</details></li>
</ul>
<hr>
<h2 id="DYMOND-DYnamic-MOtif-NoDes-Network-Generative-Model"><a href="#DYMOND-DYnamic-MOtif-NoDes-Network-Generative-Model" class="headerlink" title="DYMOND: DYnamic MOtif-NoDes Network Generative Model"></a>DYMOND: DYnamic MOtif-NoDes Network Generative Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00770">http://arxiv.org/abs/2308.00770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zeno129/dymond">https://github.com/zeno129/dymond</a></li>
<li>paper_authors: Giselle Zeno, Timothy La Fond, Jennifer Neville</li>
<li>for: 这个论文主要是为了提出一种基于动态模式的图structuredynamics Generative模型，以便更好地模型动态图的结构和节点行为。</li>
<li>methods: 该模型使用动态模式活动来捕捉图的变化，同时考虑每个节点在模式中所扮演的角色。</li>
<li>results: 与基于边扩展的基elines相比，该模型在真实的网络上更好地生成图结构和节点行为。此外，该paper还提出了一种新的方法来适应图结构度量来评估网络的时间方面。<details>
<summary>Abstract</summary>
Motifs, which have been established as building blocks for network structure, move beyond pair-wise connections to capture longer-range correlations in connections and activity. In spite of this, there are few generative graph models that consider higher-order network structures and even fewer that focus on using motifs in models of dynamic graphs. Most existing generative models for temporal graphs strictly grow the networks via edge addition, and the models are evaluated using static graph structure metrics -- which do not adequately capture the temporal behavior of the network. To address these issues, in this work we propose DYnamic MOtif-NoDes (DYMOND) -- a generative model that considers (i) the dynamic changes in overall graph structure using temporal motif activity and (ii) the roles nodes play in motifs (e.g., one node plays the hub role in a wedge, while the remaining two act as spokes). We compare DYMOND to three dynamic graph generative model baselines on real-world networks and show that DYMOND performs better at generating graph structure and node behavior similar to the observed network. We also propose a new methodology to adapt graph structure metrics to better evaluate the temporal aspect of the network. These metrics take into account the changes in overall graph structure and the individual nodes' behavior over time.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用简化中文表示文本。<</SYS>>网络结构中的模式，作为网络结构的基本构件，已经被证明可以捕捉更长距离的相关性。然而，有很少的生成图模型考虑高阶网络结构，而且这些模型几乎都是通过边添加来生成网络。这些模型通常被评估使用静止图结构指标，这些指标不能准确捕捉网络的时间性行为。为解决这些问题，在这项工作中，我们提出了动态模式无核（DYMOND）生成模型。DYMOND模型考虑了（i）动态变化的总图结构使用时间模式活动，以及（ii）节点在模式中所扮演的角色（例如，一个节点在wedgel中扮演核心角色，剩下两个节点扮演螺旋的角色）。我们比较了DYMOND模型与三种动态图生成模型基线在真实网络上的性能，并显示DYMOND模型在生成图结构和节点行为方面表现出色，能够更好地生成与观察网络相似的图结构和节点行为。我们还提出了一种新的方法来适应图结构指标的改进，这些指标考虑了网络结构的变化和每个节点在时间上的行为。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Contrastive-BERT-Fine-tuning-for-Fusion-based-Reviewed-Item-Retrieval"><a href="#Self-Supervised-Contrastive-BERT-Fine-tuning-for-Fusion-based-Reviewed-Item-Retrieval" class="headerlink" title="Self-Supervised Contrastive BERT Fine-tuning for Fusion-based Reviewed-Item Retrieval"></a>Self-Supervised Contrastive BERT Fine-tuning for Fusion-based Reviewed-Item Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00762">http://arxiv.org/abs/2308.00762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/d3mlab/rir_data">https://github.com/d3mlab/rir_data</a></li>
<li>paper_authors: Mohammad Mahdi Abdollah Pour, Parsa Farinneya, Armin Toroghi, Anton Korikov, Ali Pesaranghader, Touqir Sajed, Manasa Bharadwaj, Borislav Mavrin, Scott Sanner</li>
<li>for: 本研究旨在提高Neural Information Retrieval（IR）方法对 Reviewed-Item Retrieval（RIR）任务的表现，包括使用自我超vised方法进行对律学习BERT表示的扩展。</li>
<li>methods: 本研究使用了自我超vised方法进行对律学习BERT表示，包括选择积极和消极样本，以及使用锚点抽样和元数据进行增强。</li>
<li>results: 实验结果显示，使用Late Fusion方法进行对律学习BERT表示的Neural RIR方法，在对律学习BERT表示的Neural IR和稀谱基eline上进行比较，具有最高的表现。<details>
<summary>Abstract</summary>
As natural language interfaces enable users to express increasingly complex natural language queries, there is a parallel explosion of user review content that can allow users to better find items such as restaurants, books, or movies that match these expressive queries. While Neural Information Retrieval (IR) methods have provided state-of-the-art results for matching queries to documents, they have not been extended to the task of Reviewed-Item Retrieval (RIR), where query-review scores must be aggregated (or fused) into item-level scores for ranking. In the absence of labeled RIR datasets, we extend Neural IR methodology to RIR by leveraging self-supervised methods for contrastive learning of BERT embeddings for both queries and reviews. Specifically, contrastive learning requires a choice of positive and negative samples, where the unique two-level structure of our item-review data combined with meta-data affords us a rich structure for the selection of these samples. For contrastive learning in a Late Fusion scenario, we investigate the use of positive review samples from the same item and/or with the same rating, selection of hard positive samples by choosing the least similar reviews from the same anchor item, and selection of hard negative samples by choosing the most similar reviews from different items. We also explore anchor sub-sampling and augmenting with meta-data. For a more end-to-end Early Fusion approach, we introduce contrastive item embedding learning to fuse reviews into single item embeddings. Experimental results show that Late Fusion contrastive learning for Neural RIR outperforms all other contrastive IR configurations, Neural IR, and sparse retrieval baselines, thus demonstrating the power of exploiting the two-level structure in Neural RIR approaches as well as the importance of preserving the nuance of individual review content via Late Fusion methods.
</details>
<details>
<summary>摘要</summary>
随着自然语言界面的发展，用户可以提出越来越复杂的自然语言查询，这导致了用户评论内容的激增，从而帮助用户更好地找到如饭店、书籍或电影等匹配查询。而神经信息检索（Neural IR）方法已经提供了状态的检索结果，但它们没有扩展到评论检索（RIR）任务中，在这个任务中，查询评论得分需要被聚合（或融合）到项目级别上。由于没有标注的 RIR 数据集，我们扩展了神经 IR 方法到 RIR 任务中，利用自动生成的 BERT 表示来进行自我超vised学习。具体来说，我们使用了对比学习来学习 BERT 表示。对比学习需要选择正例和负例样本，我们利用 item-review 数据集的两层结构，以及元数据，选择了有利的样本。我们 investigate了在晚期融合 scenario 中使用同一个 Item 的正例评论、同一个分数的正例评论、最不相似的 anchor Item 的负例评论和最相似的 anchor Item 的负例评论等方法来选择正例和负例样本。我们还 explore了 anchor 子采样和元数据增强。此外，我们还引入了对比项embedding学习来融合评论。实验结果表明，使用晚期融合对比学习的神经 RIR 比其他对比 IR 配置、神经 IR 和缺省检索基eline都高效，这表明了在神经 RIR 方法中利用两层结构的优势以及在融合评论内容时保持评论细节的重要性。
</details></li>
</ul>
<hr>
<h2 id="The-Bias-Amplification-Paradox-in-Text-to-Image-Generation"><a href="#The-Bias-Amplification-Paradox-in-Text-to-Image-Generation" class="headerlink" title="The Bias Amplification Paradox in Text-to-Image Generation"></a>The Bias Amplification Paradox in Text-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00755">http://arxiv.org/abs/2308.00755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/preethiseshadri518/bias-amplification-paradox">https://github.com/preethiseshadri518/bias-amplification-paradox</a></li>
<li>paper_authors: Preethi Seshadri, Sameer Singh, Yanai Elazar</li>
<li>for: 这 paper studies bias amplification in the text-to-image domain, specifically looking at gender-occupation biases in the training data (LAION).</li>
<li>methods: The authors use Stable Diffusion to compare gender ratios in the training data and the generated images, and they find that the model amplifies gender biases present in the training data. However, they also identify several confounding factors that contribute to this amplification.</li>
<li>results: The authors discover that the model appears to amplify gender biases, but this amplification can largely be attributed to discrepancies between training captions and model prompts. Once these distributional differences are accounted for, the amplification decreases considerably. The findings highlight the challenges of comparing biases in models and the data they are trained on.<details>
<summary>Abstract</summary>
Bias amplification is a phenomenon in which models increase imbalances present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stable Diffusion by comparing gender ratios in training vs. generated images. We find that the model appears to amplify gender-occupation biases found in the training data (LAION). However, we discover that amplification can largely be attributed to discrepancies between training captions and model prompts. For example, an inherent difference is that captions from the training data often contain explicit gender information while the prompts we use do not, which leads to a distribution shift and consequently impacts bias measures. Once we account for various distributional differences between texts used for training and generation, we observe that amplification decreases considerably. Our findings illustrate the challenges of comparing biases in models and the data they are trained on, and highlight confounding factors that contribute to bias amplification.
</details>
<details>
<summary>摘要</summary>
“偏调增强”是一种现象，模型在训练数据中的偏调会增加。在这篇研究中，我们研究了在文本到图像领域中的偏调增强，使用稳定扩散比较训练和生成图像中的性别比。我们发现，模型似乎将训练数据中的性别职业偏调增强。但是，我们发现这些增强可以主要归因于训练描述和模型说明之间的分布差异。例如，训练数据中的描述通常包含直接的性别信息，而模型说明则不包含这些信息，这会导致分布差异和影响偏调测量。一旦我们考虑到不同的分布差异，我们发现增强的减少了许多。我们的发现显示了比较模型和训练数据中的偏调的问题，以及对偏调增强的混淆因素。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-Hypervectors-A-Survey-on-Hypervector-Encoding"><a href="#Learning-from-Hypervectors-A-Survey-on-Hypervector-Encoding" class="headerlink" title="Learning from Hypervectors: A Survey on Hypervector Encoding"></a>Learning from Hypervectors: A Survey on Hypervector Encoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00685">http://arxiv.org/abs/2308.00685</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sercan Aygun, Mehran Shoushtari Moghadam, M. Hassan Najafi, Mohsen Imani</li>
<li>For: 本研究 zeros in on HDC 系统输入和生成 гипер向量过程，直接影响 гипер向量编码过程。* Methods: 本研究将从不同研究中收集various methods for гипер向量生成，探讨它们的局限性、挑战和可能的利好。* Results: 通过全面探讨这些encoding type的各种应用，读者将获得深刻的理解 hybervector generation的多种类型和各种应用场景中的encoding过程。<details>
<summary>Abstract</summary>
Hyperdimensional computing (HDC) is an emerging computing paradigm that imitates the brain's structure to offer a powerful and efficient processing and learning model. In HDC, the data are encoded with long vectors, called hypervectors, typically with a length of 1K to 10K. The literature provides several encoding techniques to generate orthogonal or correlated hypervectors, depending on the intended application. The existing surveys in the literature often focus on the overall aspects of HDC systems, including system inputs, primary computations, and final outputs. However, this study takes a more specific approach. It zeroes in on the HDC system input and the generation of hypervectors, directly influencing the hypervector encoding process. This survey brings together various methods for hypervector generation from different studies and explores the limitations, challenges, and potential benefits they entail. Through a comprehensive exploration of this survey, readers will acquire a profound understanding of various encoding types in HDC and gain insights into the intricate process of hypervector generation for diverse applications.
</details>
<details>
<summary>摘要</summary>
高维ensional计算（HDC）是一种emerging计算模式，它模仿大脑的结构，提供了一种强大和高效的处理和学习模型。在HDC中，数据被编码为长向量，称为超vector，通常长度在1K到10K。文献中提供了多种编码技术，以生成正交或相关的超vector，具体取决于应用场景。现有的文献综述通常专注于HDC系统的总体方面，包括输入、基本计算和最终输出。但本研究采取了更加细化的方法。它关注HDC系统的输入和超vector编码过程，直接影响超vector生成过程。本调查集结了不同研究中的各种超vector生成方法，探讨它们的局限性、挑战和应用场景中的优势。通过全面探讨本调查，读者将获得各种编码类型在HDC中的深刻理解，并对超vector生成过程中的细节有深入的了解。
</details></li>
</ul>
<hr>
<h2 id="CodeBPE-Investigating-Subtokenization-Options-for-Large-Language-Model-Pretraining-on-Source-Code"><a href="#CodeBPE-Investigating-Subtokenization-Options-for-Large-Language-Model-Pretraining-on-Source-Code" class="headerlink" title="CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code"></a>CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00683">http://arxiv.org/abs/2308.00683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nadezhda Chirkova, Sergey Troshin</li>
<li>for:  investigate the effect of different subtokenization options for source code</li>
<li>methods: propose subtokenization that reduces average length by 17% without downstream performance drop, and show that a carefully chosen subtokenization may improve quality by 0.5-2%, possibly with some length increase.</li>
<li>results: identify most effective and length-efficient subtokenizations, taking into account code specifics.<details>
<summary>Abstract</summary>
Recent works have widely adopted large language model pretraining for source code, suggested source code-specific pretraining objectives and investigated the applicability of various Transformer-based language model architectures for source code. This work investigates another important aspect of such models, namely the effect of different subtokenization options, and aims at identifying most effective and length-efficient subtokenizations, taking into account code specifics. We propose subtokenziation that reduces average length by 17% without downstream performance drop, and show that a carefully chosen subtokenization may improve quality by 0.5-2%, possibly with some length increase.
</details>
<details>
<summary>摘要</summary>
近期研究广泛采用大型自然语言模型预训练 для源代码,建议源代码特有的预训练目标和Investigate了多种Transformer基于语言模型架构在源代码中的可行性。这个工作另一方面 investigate了这些模型中的另一个重要方面，即不同的子字符串选择方法的影响，并企图确定最有效和最短的子字符串选择方法，考虑代码特点。我们提议一种减少平均长度17%的子字符串选择方法，并显示一个合适的子字符串选择方法可能提高质量0.5-2%，可能具有一定的长度增加。
</details></li>
</ul>
<hr>
<h2 id="Tool-Documentation-Enables-Zero-Shot-Tool-Usage-with-Large-Language-Models"><a href="#Tool-Documentation-Enables-Zero-Shot-Tool-Usage-with-Large-Language-Models" class="headerlink" title="Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models"></a>Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00675">http://arxiv.org/abs/2308.00675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng-Yu Hsieh, Si-An Chen, Chun-Liang Li, Yasuhisa Fujii, Alexander Ratner, Chen-Yu Lee, Ranjay Krishna, Tomas Pfister</li>
<li>for: 提供一种新的工具使用方法，而不是通过示例来教导语言模型（LLM）使用新工具。</li>
<li>methods: 使用工具文档来替代示例，提供工具的使用描述以便LLM学习。</li>
<li>results: 研究发现，使用工具文档可以帮助LLM在不需要示例的情况下也能够正确使用工具，并且在实际场景中表现更好。<details>
<summary>Abstract</summary>
Today, large language models (LLMs) are taught to use new tools by providing a few demonstrations of the tool's usage. Unfortunately, demonstrations are hard to acquire, and can result in undesirable biased usage if the wrong demonstration is chosen. Even in the rare scenario that demonstrations are readily available, there is no principled selection protocol to determine how many and which ones to provide. As tasks grow more complex, the selection search grows combinatorially and invariably becomes intractable. Our work provides an alternative to demonstrations: tool documentation. We advocate the use of tool documentation, descriptions for the individual tool usage, over demonstrations. We substantiate our claim through three main empirical findings on 6 tasks across both vision and language modalities. First, on existing benchmarks, zero-shot prompts with only tool documentation are sufficient for eliciting proper tool usage, achieving performance on par with few-shot prompts. Second, on a newly collected realistic tool-use dataset with hundreds of available tool APIs, we show that tool documentation is significantly more valuable than demonstrations, with zero-shot documentation significantly outperforming few-shot without documentation. Third, we highlight the benefits of tool documentations by tackling image generation and video tracking using just-released unseen state-of-the-art models as tools. Finally, we highlight the possibility of using tool documentation to automatically enable new applications: by using nothing more than the documentation of GroundingDino, Stable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the just-released Grounded-SAM and Track Anything models.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:今天，大型语言模型（LLM）通常通过提供一些示例来教育它们使用新工具。然而，示例很难获得，而且如果选择错误的示例，可能会导致不正确的使用。即使示例 readily available，也没有原则性的选择协议来确定多少和哪些提供。随着任务的复杂度增加，选择搜索会 combinatorially intractable 化。我们的工作强调使用工具文档，而不是示例。我们通过六个任务 across 视觉和语言模式来证明我们的主张。首先，在现有的benchmark上，只有工具文档的Zero-shot prompt是 sufficient для获得正确的工具使用，并且与几个shot prompt的性能相当。其次，我们收集了一个实际的工具使用数据集，包含了数百个可用的工具API，并示出了工具文档的优越性。第三，我们高亮了工具文档的优势，通过使用最新的领先技术模型作为工具来解决图像生成和视频跟踪等任务。最后，我们强调了使用工具文档来自动启用新应用程序：通过使用 GroundingDino、Stable Diffusion、XMem 和 SAM 的文档，LLMs 可以重新实现最新的 Grounded-SAM 和 Track Anything 模型的功能。
</details></li>
</ul>
<hr>
<h2 id="Mapping-Computer-Science-Research-Trends-Influences-and-Predictions"><a href="#Mapping-Computer-Science-Research-Trends-Influences-and-Predictions" class="headerlink" title="Mapping Computer Science Research: Trends, Influences, and Predictions"></a>Mapping Computer Science Research: Trends, Influences, and Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00733">http://arxiv.org/abs/2308.00733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed Almutairi, Ozioma Collins Oguine</li>
<li>for: The paper aims to identify trending research areas in the field of Computer Science (CS) and investigate the factors contributing to their emergence.</li>
<li>methods: The authors use a comprehensive dataset comprising papers, citations, and funding information, and employ advanced machine learning techniques, including Decision Tree and Logistic Regression models, to predict trending research areas.</li>
<li>results: The analysis reveals that reference counts play a pivotal role in determining trending research areas, and the Logistic Regression model outperforms the Decision Tree model in predicting trends, with higher accuracy, precision, recall, and F1 score. The results provide valuable insights into the trending research areas and offer a data-driven foundation for decision-making and future research direction.Here are the three information points in Simplified Chinese text:</li>
<li>for: 这篇论文探讨了计算机科学（CS）领域当前热点研究领域，并研究这些热点研究领域的起源因素。</li>
<li>methods: 作者使用了一个包括论文、引用、资金信息的完整数据集，并使用高级机器学习技术，包括决策树和逻辑回归模型，预测热点研究领域。</li>
<li>results: 分析发现，引用计数（Reference Count）在确定热点研究领域中发挥了关键作用，并且 NSF 资金和专利在热点话题的影响逐渐增加。逻辑回归模型在预测热点领域方面表现出色，比决策树模型更高精度、精确性、回归率和 F1 分数。通过超过随机尝试基准点，我们的数据驱动方法表明更高的准确性和效率，可以为研究人员和机构提供数据驱动的基础 для决策和未来研究方向。<details>
<summary>Abstract</summary>
This paper explores the current trending research areas in the field of Computer Science (CS) and investigates the factors contributing to their emergence. Leveraging a comprehensive dataset comprising papers, citations, and funding information, we employ advanced machine learning techniques, including Decision Tree and Logistic Regression models, to predict trending research areas. Our analysis reveals that the number of references cited in research papers (Reference Count) plays a pivotal role in determining trending research areas making reference counts the most relevant factor that drives trend in the CS field. Additionally, the influence of NSF grants and patents on trending topics has increased over time. The Logistic Regression model outperforms the Decision Tree model in predicting trends, exhibiting higher accuracy, precision, recall, and F1 score. By surpassing a random guess baseline, our data-driven approach demonstrates higher accuracy and efficacy in identifying trending research areas. The results offer valuable insights into the trending research areas, providing researchers and institutions with a data-driven foundation for decision-making and future research direction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/02/cs.LG_2023_08_02/" data-id="clogy1z4p00lwffra2tej91f0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/60/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/59/">59</a><a class="page-number" href="/page/60/">60</a><span class="page-number current">61</span><a class="page-number" href="/page/62/">62</a><a class="page-number" href="/page/63/">63</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/62/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
