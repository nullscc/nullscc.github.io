
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/5/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.IV_2023_11_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/02/eess.IV_2023_11_02/" class="article-date">
  <time datetime="2023-11-02T09:00:00.000Z" itemprop="datePublished">2023-11-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/02/eess.IV_2023_11_02/">eess.IV - 2023-11-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Unveiling-the-deep-plumbing-system-of-a-volcano-by-a-reflection-matrix-analysis-of-seismic-noise"><a href="#Unveiling-the-deep-plumbing-system-of-a-volcano-by-a-reflection-matrix-analysis-of-seismic-noise" class="headerlink" title="Unveiling the deep plumbing system of a volcano by a reflection matrix analysis of seismic noise"></a>Unveiling the deep plumbing system of a volcano by a reflection matrix analysis of seismic noise</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01296">http://arxiv.org/abs/2311.01296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elsa Giraudat, Arnaud Burtin, Arthur Le Ber, Mathias Fink, Jean-Christophe Komorowski, Alexandre Aubry</li>
<li>for: 这篇论文是为了研究加德鲁瓦岛拉索韦雷尔火山的内部结构和水热系统而写的。</li>
<li>methods: 这篇论文使用了震动噪声记录在罕见的地震仪数组上的方法，以揭示火山内部的液体和岩石多尺度不均质和非线性动态。</li>
<li>results: 研究人员通过分析震动噪声的时空横列相关性，实际获得了火山内部的各种反射特征，以及水热系统的几何结构和动态行为。这些结果为火山的概念模型和高级监测带来了新的视角和信息。<details>
<summary>Abstract</summary>
In geophysics, volcanoes are particularly difficult to image because of the multi-scale heterogeneities of fluids and rocks that compose them and their complex non-linear dynamics. By exploiting seismic noise recorded by a sparse array of geophones, we are able to reveal the magmatic and hydrothermal plumbing system of La Soufri\`ere volcano in Guadeloupe. Spatio-temporal cross-correlation of seismic noise actually provides the impulse responses between virtual geophones located inside the volcano. The resulting reflection matrix can be exploited to numerically perform an auto-focus of seismic waves on any reflector of the underground. An unprecedented view on the volcano's inner structure is obtained at a half-wavelength resolution. This innovative observable provides fundamental information for the conceptual modeling and high-resolution monitoring of volcanoes.
</details>
<details>
<summary>摘要</summary>
在地球物理学中，火山特别难以成像，因为它们由多级不同性的液体和岩石组成，以及复杂非线性动态。我们通过利用地震噪声记录的稀疏阵列地震仪，能够揭示拉撒韦尔火山（La Soufri\`ere）在格瑞达岛的 магмати和 hidrotermal 沟管系统。在空间时间交叉相关的地震噪声中，实际提供了虚拟地震仪内部火山中的响应函数。得到的反射矩阵可以 numerically 进行自动фокус处理，以获得任何反射器的地下高分辨率视图。这种创新的可见提供了基本信息 для概念模型和高分辨率监测火山。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/02/eess.IV_2023_11_02/" data-id="cloqtaf1m018vgh884ejz3msu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/02/eess.SP_2023_11_02/" class="article-date">
  <time datetime="2023-11-02T08:00:00.000Z" itemprop="datePublished">2023-11-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/02/eess.SP_2023_11_02/">eess.SP - 2023-11-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Supervised-Learning-Based-Real-Time-Adaptive-Beamforming-On-board-Multibeam-Satellites"><a href="#Supervised-Learning-Based-Real-Time-Adaptive-Beamforming-On-board-Multibeam-Satellites" class="headerlink" title="Supervised Learning Based Real-Time Adaptive Beamforming On-board Multibeam Satellites"></a>Supervised Learning Based Real-Time Adaptive Beamforming On-board Multibeam Satellites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01334">http://arxiv.org/abs/2311.01334</a></li>
<li>repo_url: None</li>
<li>paper_authors: Flor Ortiz, Juan A. Vasquez-Peralvo, Jorge Querol, Eva Lagunas, Jorge L. Gonzalez Rios, Marcele O. K. Mendonca, Luis Garces, Victor Monzon Baeza, Symeon Chatzinotas</li>
<li>for: 本研究旨在提高卫星通信系统的资源管理效率，以满足动态交通需求和宽频带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽带宽�<details>
<summary>Abstract</summary>
Satellite communications (SatCom) are crucial for global connectivity, especially in the era of emerging technologies like 6G and narrowing the digital divide. Traditional SatCom systems struggle with efficient resource management due to static multibeam configurations, hindering quality of service (QoS) amidst dynamic traffic demands. This paper introduces an innovative solution - real-time adaptive beamforming on multibeam satellites with software-defined payloads in geostationary orbit (GEO). Utilizing a Direct Radiating Array (DRA) with circular polarization in the 17.7 - 20.2 GHz band, the paper outlines DRA design and a supervised learning-based algorithm for on-board beamforming. This adaptive approach not only meets precise beam projection needs but also dynamically adjusts beamwidth, minimizes sidelobe levels (SLL), and optimizes effective isotropic radiated power (EIRP).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Statistical-Results-of-Multivariate-Fox-H-Function-for-Exact-Performance-Analysis-of-RIS-Assisted-Wireless-Communication"><a href="#Statistical-Results-of-Multivariate-Fox-H-Function-for-Exact-Performance-Analysis-of-RIS-Assisted-Wireless-Communication" class="headerlink" title="Statistical Results of Multivariate Fox-H Function for Exact Performance Analysis of RIS-Assisted Wireless Communication"></a>Statistical Results of Multivariate Fox-H Function for Exact Performance Analysis of RIS-Assisted Wireless Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01312">http://arxiv.org/abs/2311.01312</a></li>
<li>repo_url: None</li>
<li>paper_authors: vinay kumar chapala, S. M. Zafaruddin<br>for: This paper aims to provide an exact analysis of the ergodic capacity and outage probability of RIS-assisted wireless systems using a multivariate Fox-H function to characterize the statistical properties of the signal-to-noise ratio (SNR).methods: The proposed approach uses a novel method to obtain the distribution of the sum of independent and non-identically distributed (i.ni.d) random variables characterized by the multivariate Fox-H function. The authors also develop a general framework for an exact analysis of the ergodic capacity when the multivariate Fox-H function characterizes the statistics of SNR.results: The paper derives exact expressions for the outage probability and ergodic capacity of RIS-assisted wireless systems under Rician fading channels with phase errors. The results are validated through computer simulations, and the performance of the RIS-assisted system is demonstrated under various practically relevant scenarios for a better performance assessment.<details>
<summary>Abstract</summary>
Existing research provides statistical results on the sum of single-variate Fox-H functions to analyze the performance of diversity receivers and reconfigurable intelligent surfaces (RIS) based wireless systems. There is a research gap in exact performance analysis when more than a single-variate Fox-H function represents the statistical characterization of wireless systems. In this paper, we propose a novel approach to obtain the distribution of the sum of independent and non-identically distributed (i.ni.d) random variables characterized by the multivariate Fox-H function. Further, we develop a general framework for an exact analysis of the ergodic capacity when the multivariate Fox-H function characterizes the statistics of signal-to-noise ratio (SNR). We apply the derived results to conduct an exact performance analysis of outage probability and ergodic capacity, taking an example of RIS-assisted communication over Rician fading channels with phase errors. We conduct computer simulations to validate the exact analysis and demonstrate performance of the RIS-assisted system under various practically relevant scenarios for a better performance assessment.
</details>
<details>
<summary>摘要</summary>
existingu research provides statistical results on the sum of single-variate Fox-H functions to analyze the performance of diversity receivers and reconfigurable intelligent surfaces (RIS) based wireless systems. There is a research gap in exact performance analysis when more than a single-variate Fox-H function represents the statistical characterization of wireless systems. In this paper, we propose a novel approach to obtain the distribution of the sum of independent and non-identically distributed (i.ni.d) random variables characterized by the multivariate Fox-H function. Further, we develop a general framework for an exact analysis of the ergodic capacity when the multivariate Fox-H function characterizes the statistics of signal-to-noise ratio (SNR). We apply the derived results to conduct an exact performance analysis of outage probability and ergodic capacity, taking an example of RIS-assisted communication over Rician fading channels with phase errors. We conduct computer simulations to validate the exact analysis and demonstrate performance of the RIS-assisted system under various practically relevant scenarios for a better performance assessment.Here's the word-for-word translation of the text into Simplified Chinese:现有研究提供了单variate Fox-H函数的统计结果，以分析多样化接收机和智能表面（RIS）基于无线系统的性能。研究存在多variate Fox-H函数表征无线系统的统计分析凌隙。在这篇论文中，我们提出了一种新的方法，以获得独立和非相同分布（i.ni.d）随机变量的总和的分布，这些随机变量由多variate Fox-H函数表征。此外，我们还提出了一个通用的框架，用于准确分析吞吐量（ergodic capacity），当多variate Fox-H函数表征无线系统的统计。我们应用得出的结果，进行了准确的性能分析，包括失业概率和吞吐量的分析，使用RIS协助通信系统在Rician折射投射通道上的示例。我们还进行了计算机实验，以验证准确分析，并在不同的实际情况下，展示RIS协助系统的性能。
</details></li>
</ul>
<hr>
<h2 id="Map-assisted-TDOA-Localization-Enhancement-Based-On-CNN"><a href="#Map-assisted-TDOA-Localization-Enhancement-Based-On-CNN" class="headerlink" title="Map-assisted TDOA Localization Enhancement Based On CNN"></a>Map-assisted TDOA Localization Enhancement Based On CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01291">http://arxiv.org/abs/2311.01291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiwen Chen, Tianqi Xiang, Xi Chen, Xin Zhang</li>
<li>for: 本研究旨在提高无线位置准备技术中的NLOS多Path效应 correction。</li>
<li>methods: 该研究提出一种基于Convolutional Neural Network (CNN)的本地化错误修正方法，通过映射中的障碍物特征提取来预测NLOS多Path效应引起的本地化错误。</li>
<li>results: 研究表明，使用CNN预测NLOS多Path效应引起的本地化错误后，对比TDOA本地化算法的结果，NLOS多Path效应 correction表现出色，可以大幅提高TDOA的准备精度。<details>
<summary>Abstract</summary>
For signal processing related to localization technologies, non line of sight (NLOS) multipaths have great impact over the localization error level. This study proposes a localization correction method based on convolution neural network (CNN) that extracts obstacles' features from maps to predict the localization errors caused by NLOS effects. A novel compensation scheme is developed and structured around the localization error predicted by the CNN. Four prediction tasks are executed over the building distributions within the maps and the propagation model in urban zones, resulting in CNN models with high prediction accuracy. Finally, a thorough comparison of the accuracy performance between the time difference of arrival (TDOA) localization algorithm and the results after the error compensation reveals that, generally, the CNN prediction approach demonstrates a great localization error correction performance. It can be observed that the powerful feature extraction capability of CNN can be exploited by processing surrounding maps to predict localization error distribution, which has great potential in further enhancement of TDOA performance under challenging scenarios with rich multi-path propagation.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:为信号处理相关的本地化技术，非线视程（NLOS）多paths有着很大的影响于本地化错误水平。本研究提出了基于卷积神经网络（CNN）的本地化修正方法，该方法通过从地图中提取障碍物特征来预测NLOS效应所导致的本地化错误。基于这个预测结果，我们开发了一种新的补偿方案，并将其结构化为本地化错误预测值。在 urbana 区域内，执行了四个预测任务，这些任务是基于建筑物分布和propagation模型。结果显示，CNN模型具有高度预测精度。最后，对TDOA本地化算法和补偿后的结果进行了严格的比较，可以看到，通过CNN预测方法可以对本地化错误进行高度的修正。这表明，CNN的强大特征提取能力可以通过处理周围的地图来预测本地化错误分布，这有很大的潜力，可以进一步提高TDOA性能在复杂的场景下。
</details></li>
</ul>
<hr>
<h2 id="ExPECA-An-Experimental-Platform-for-Trustworthy-Edge-Computing-Applications"><a href="#ExPECA-An-Experimental-Platform-for-Trustworthy-Edge-Computing-Applications" class="headerlink" title="ExPECA: An Experimental Platform for Trustworthy Edge Computing Applications"></a>ExPECA: An Experimental Platform for Trustworthy Edge Computing Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01279">http://arxiv.org/abs/2311.01279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samie Mostafavi, Vishnu Narayanan Moothedath, Stefan Rönngren, Neelabhro Roy, Gourav Prateek Sharma, Sangwon Seo, Manuel Olguín Muñoz, James Gross</li>
<li>for: 这篇论文旨在提供一个拥有综合终端到终端实验和高度复制性的edge计算和无线通信研发测试环境。</li>
<li>methods: 该测试环境基于OpenStack-based Chameleon Infrastructure（CHI）框架，利用其灵活性和操作 convenienceto provide a highly controlled underground facility for wireless experiments.</li>
<li>results: 通过使用OpenRTiST应用程序，研究人员可以在ExPECA测试环境中进行灵活的实验和性能分析，并且可以利用容器化计算环境来支持多种研究领域和实验设置。<details>
<summary>Abstract</summary>
This paper presents ExPECA, an edge computing and wireless communication research testbed designed to tackle two pressing challenges: comprehensive end-to-end experimentation and high levels of experimental reproducibility. Leveraging OpenStack-based Chameleon Infrastructure (CHI) framework for its proven flexibility and ease of operation, ExPECA is located in a unique, isolated underground facility, providing a highly controlled setting for wireless experiments. The testbed is engineered to facilitate integrated studies of both communication and computation, offering a diverse array of Software-Defined Radios (SDR) and Commercial Off-The-Shelf (COTS) wireless and wired links, as well as containerized computational environments. We exemplify the experimental possibilities of the testbed using OpenRTiST, a latency-sensitive, bandwidth-intensive application, and analyze its performance. Lastly, we highlight an array of research domains and experimental setups that stand to gain from ExPECA's features, including closed-loop applications and time-sensitive networking.
</details>
<details>
<summary>摘要</summary>
To demonstrate the experimental capabilities of the testbed, we use OpenRTiST, a latency-sensitive, bandwidth-intensive application, and analyze its performance. Additionally, we highlight a variety of research domains and experimental setups that can benefit from ExPECA's features, including closed-loop applications and time-sensitive networking.Translated into Simplified Chinese:这篇论文介绍了ExPECA，一个Edge computing和无线通信研究测试床，旨在解决两个紧迫的挑战：全面的端到端实验和高水平的实验复制性。利用OpenStack基础设施的Chameleon基础设施（CHI）框架，ExPECA位于一个独特的地下设施中，提供了一个高度控制的无线实验环境。测试床设计用于探索无线通信和计算的集成研究，提供了一系列Software-Defined Radio（SDR）和商业可用的无线和有线链路，以及容器化的计算环境。我们使用OpenRTiST，一个延迟敏感、带宽敏感的应用程序，来示例测试床的实验可能性，并分析其性能。此外，我们还高亮了一些研究领域和实验设置，可以从ExPECA的特点中受益，包括关闭Loop应用和时间敏感网络。
</details></li>
</ul>
<hr>
<h2 id="Decentralized-Federated-Learning-on-the-Edge-over-Wireless-Mesh-Networks"><a href="#Decentralized-Federated-Learning-on-the-Edge-over-Wireless-Mesh-Networks" class="headerlink" title="Decentralized Federated Learning on the Edge over Wireless Mesh Networks"></a>Decentralized Federated Learning on the Edge over Wireless Mesh Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01186">http://arxiv.org/abs/2311.01186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdelaziz Salama, Achilleas Stergioulis, Syed Ali Zaidi, Des McLernon</li>
<li>for: 这个研究旨在提出一个替代方案，即分布式机器学习（Decentralized Federated Learning，DFL），并在无线网络作为通信基础建构。</li>
<li>methods: 这个研究使用了Stochastic Geometry Theory和物理干扰模型进行网络性能分析，并且对应不同的统计汇编方法（FedAvg、Krum和Median方法）进行系统实验。</li>
<li>results: 研究结果显示，将使用Genetic Algorithm进行压缩可以将 particiants的本地模型大小压缩到基线中的一半，并且与中央化 Federated Learning 和传统的分布式机器学习相比，在类别任务中实现相似的精度和平均损失。此外，它还可以实现大量数据的压缩和通信带宽的减少。<details>
<summary>Abstract</summary>
The rapid growth of Internet of Things (IoT) devices has generated vast amounts of data, leading to the emergence of federated learning as a novel distributed machine learning paradigm. Federated learning enables model training at the edge, leveraging the processing capacity of edge devices while preserving privacy and mitigating data transfer bottlenecks. However, the conventional centralized federated learning architecture suffers from a single point of failure and susceptibility to malicious attacks. In this study, we delve into an alternative approach called decentralized federated learning (DFL) conducted over a wireless mesh network as the communication backbone. We perform a comprehensive network performance analysis using stochastic geometry theory and physical interference models, offering fresh insights into the convergence analysis of DFL. Additionally, we conduct system simulations to assess the proposed decentralized architecture under various network parameters and different aggregator methods such as FedAvg, Krum and Median methods. Our model is trained on the widely recognized EMNIST dataset for benchmarking handwritten digit classification. To minimize the model's size at the edge and reduce communication overhead, we employ a cutting-edge compression technique based on genetic algorithms. Our simulation results reveal that the compressed decentralized architecture achieves performance comparable to the baseline centralized architecture and traditional DFL in terms of accuracy and average loss for our classification task. Moreover, it significantly reduces the size of shared models over the wireless channel by compressing participants' local model sizes to nearly half of their original size compared to the baselines, effectively reducing complexity and communication overhead.
</details>
<details>
<summary>摘要</summary>
“因互联网物联网（IoT）装置的快速增长，导致机器学习（ML）模型训练的大量数据生成，带来了分布式机器学习（FedML）的出现。 FedML可以在边缘进行模型训练，利用边缘设备的处理能力，同时保持隐私和减少数据传输瓶须。但是，传统中央化的 FedML架构受到单点失效和黑客攻击的威胁。在这篇研究中，我们研究了一种分布式 FedML（DFL）架构，通过无线 mesh 网络作为通信基础建构。我们使用Stochastic Geometry Theory和物理干扰模型进行网络性能分析，提供新的混合分析方法。此外，我们还进行系统实验，评估我们的对称架构在不同网络参数和组合方法（如FedAvg、Krum和Median方法）下的表现。我们的模型是基于EMNIST资料集，用于测试手写数字分类。为了优化模型在边缘的存储和减少通信负载，我们使用 cutting-edge 干扰技术，基于遗传算法实现模型压缩。我们的实验结果显示，压缩的分布式架构可以与中央化架构和传统的 DFL 相比，在准确性和平均损失方面具有相似的表现，同时对于我们的分类任务，对模型的共享大小进行了有效的压缩，从而减少了网络负载和复杂度。”
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Traffic-Congestion-Management-with-Fog-Computing-A-Simulation-based-Investigation-using-iFog-Simulator"><a href="#Enhanced-Traffic-Congestion-Management-with-Fog-Computing-A-Simulation-based-Investigation-using-iFog-Simulator" class="headerlink" title="Enhanced Traffic Congestion Management with Fog Computing: A Simulation-based Investigation using iFog-Simulator"></a>Enhanced Traffic Congestion Management with Fog Computing: A Simulation-based Investigation using iFog-Simulator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01181">http://arxiv.org/abs/2311.01181</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alzahraa Elsayed, Khalil Mohamed, Hany Harb</li>
<li>for: 提高智能城市压力堵塞管理系统的准确延迟计算，以便在云计算中处理大量数据。</li>
<li>methods: fog computing技术，以实现在边缘处理而不是云计算。</li>
<li>results: 比较其他方法，包括IOV和STL，并确定提出的系统模型在各种纪录中的优劣表现。<details>
<summary>Abstract</summary>
Accurate latency computation is essential for the Internet of Things (IoT) since the connected devices generate a vast amount of data that is processed on cloud infrastructure. However, the cloud is not an optimal solution. To overcome this issue, fog computing is used to enable processing at the edge while still allowing communication with the cloud. Many applications rely on fog computing, including traffic management. In this paper, an Intelligent Traffic Congestion Mitigation System (ITCMS) is proposed to address traffic congestion in heavily populated smart cities. The proposed system is implemented using fog computing and tested in a crowded city. Its performance is evaluated based on multiple metrics, such as traffic efficiency, energy savings, reduced latency, average traffic flow rate, and waiting time. The obtained results are compared with similar techniques that tackle the same issue. The results obtained indicate that the execution time of the simulation is 4,538 seconds, and the delay in the application loop is 49.67 seconds. The paper addresses various issues, including CPU usage, heap memory usage, throughput, and the total average delay, which are essential for evaluating the performance of the ITCMS. Our system model is also compared with other models to assess its performance. A comparison is made using two parameters, namely throughput and the total average delay, between the ITCMS, IOV (Internet of Vehicle), and STL (Seasonal-Trend Decomposition Procedure based on LOESS). Consequently, the results confirm that the proposed system outperforms the others in terms of higher accuracy, lower latency, and improved traffic efficiency.
</details>
<details>
<summary>摘要</summary>
优质延迟计算是智能物联网（IoT）中不可或缺的，因为连接设备生成的数据量非常大，需要在云基础设施上处理。但云不是最佳解决方案。为了解决这个问题，fog计算被用来启用边缘处理，同时仍允许与云进行通信。许多应用程序依赖于fog计算，包括交通管理。在这篇论文中，一个智能交通堵塞缓解系统（ITCMS）被提出，以解决智能城市中高度拥堵的交通问题。该系统采用fog计算实现，并在热点城市进行测试。其性能被评估基于多个纪录，包括交通效率、能源储存、延迟、平均交通流速和等待时间。获得的结果与其他解决方案进行比较，结果表明，提案系统在多个纪录中表现更高精度、更低延迟和更好的交通效率。system model comparison also is made with other models to assess its performance. A comparison is made using two parameters, namely throughput and the total average delay, between the ITCMS, IOV (Internet of Vehicle), and STL (Seasonal-Trend Decomposition Procedure based on LOESS). Consequently, the results confirm that the proposed system outperforms the others in terms of higher accuracy, lower latency, and improved traffic efficiency.
</details></li>
</ul>
<hr>
<h2 id="Modulation-Design-and-Optimization-for-RIS-Assisted-Symbiotic-Radios"><a href="#Modulation-Design-and-Optimization-for-RIS-Assisted-Symbiotic-Radios" class="headerlink" title="Modulation Design and Optimization for RIS-Assisted Symbiotic Radios"></a>Modulation Design and Optimization for RIS-Assisted Symbiotic Radios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01167">http://arxiv.org/abs/2311.01167</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hu Zhou, Bowen Cai, Qianqian Zhang, Ruizhe Long, Yiyang Pei, Ying-Chang Liang</li>
<li>For: 提高RIS协助SR系统中干扰链的性能，解决SR系统中简单干扰链的干扰问题。* Methods: 提出一种新的Modulation scheme，将RIS的频率差分成两部分：征文件不变部分和征文件变部分，用于协助主传和传输次信号。通过解决复合信号的检测问题，提高主和次传信号的比特错误率性能。* Results: 对比 conventional modulation scheme，提出的新Modulation scheme能够提高SR系统中干扰链的性能，并且可以在主传链受阻时提供更好的性能。<details>
<summary>Abstract</summary>
In reconfigurable intelligent surface (RIS)-assisted symbiotic radio (SR), the RIS acts as a secondary transmitter by modulating its information bits over the incident primary signal and simultaneously assists the primary transmission, then a cooperative receiver is used to jointly decode the primary and secondary signals. Most existing works of SR focus on using RIS to enhance the reflecting link while ignoring the ambiguity problem for the joint detection caused by the multiplication relationship of the primary and secondary signals. Particularly, in case of a blocked direct link, joint detection will suffer from severe performance loss due to the ambiguity, when using the conventional on-off keying and binary phase shift keying modulation schemes for RIS. To address this issue, we propose a novel modulation scheme for RIS-assisted SR that divides the phase-shift matrix into two components: the symbol-invariant and symbol-varying components, which are used to assist the primary transmission and carry the secondary signal, respectively. To design these two components, we focus on the detection of the composite signal formed by the primary and secondary signals, through which a problem of minimizing the bit error rate (BER) of the composite signal is formulated to improve both the BER performance of the primary and secondary ones. By solving the problem, we derive the closed-form solution of the optimal symbol-invariant and symbol-varying components, which is related to the channel strength ratio of the direct link to the reflecting link. Moreover, theoretical BER performance is analyzed. Finally, simulation results show the superiority of the proposed modulation scheme over its conventional counterpart.
</details>
<details>
<summary>摘要</summary>
在协助式广播（SR）中，协助器（RIS） behave as a secondary transmitter by modulating its information bits over the incident primary signal and simultaneously assisting the primary transmission，然后使用协同接收器来联合解码主要和次要信号。大多数现有的SR工作都忽略了在共同检测中的混淆问题，特别是在直接链路被阻断时，共同检测将受到严重的性能损失due to the multiplication relationship between the primary and secondary signals。为解决这个问题，我们提出了一种新的模ulation scheme for RIS-assisted SR，该方案将分解阶跃矩阵into two components：符号不变和符号变components，用于帮助主传输和传输次要信号，分别。为设计这两个组成部分，我们关注了主传输和次要传输的复合信号的检测，并通过解决这个问题，我们得到了closed-form solution of the optimal symbol-invariant and symbol-varying components，该解决方案与直接链路到反射链路的通信强度比进行关系。此外，我们还进行了理论性能分析。最后，我们通过实验结果展示了我们的提案方案的优越性。
</details></li>
</ul>
<hr>
<h2 id="Combating-Inter-Operator-Pilot-Contamination-in-Reconfigurable-Intelligent-Surfaces-Assisted-Multi-Operator-Networks"><a href="#Combating-Inter-Operator-Pilot-Contamination-in-Reconfigurable-Intelligent-Surfaces-Assisted-Multi-Operator-Networks" class="headerlink" title="Combating Inter-Operator Pilot Contamination in Reconfigurable Intelligent Surfaces Assisted Multi-Operator Networks"></a>Combating Inter-Operator Pilot Contamination in Reconfigurable Intelligent Surfaces Assisted Multi-Operator Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01151">http://arxiv.org/abs/2311.01151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doğa Gürgünoğlu, Emil Björnson, Gábor Fodor</li>
<li>for: 研究了在多个运营商协助网络中出现的新型飞行器污染现象， где多个运营商为其各自的用户提供服务。运营商使用专用频率带，但每个智能表层在多个频率带中不可避免地反射用户设备的传输上行信号。因此，同时反射的试验信号在渠道估计阶段引入了一种新的交互运营商飞行器污染效应。</li>
<li>methods:  investigate the implications of this effect in systems with either deterministic or correlated Rayleigh fading channels, specifically focusing on its impact on channel estimation quality, signal equalization, and channel capacity.</li>
<li>results:  numerical results demonstrate the substantial degradation in system performance caused by this phenomenon and highlight the pressing need to address inter-operator pilot contamination in multi-operator RIS deployments. To combat the negative effect of this new type of pilot contamination, we propose to use orthogonal RIS configurations during uplink pilot transmission, which can mitigate or eliminate the negative effect of inter-operator pilot contamination at the expense of some inter-operator information exchange and orchestration.<details>
<summary>Abstract</summary>
In this paper, we study a new kind of pilot contamination appearing in multi-operator reconfigurable intelligent surfaces (RIS) assisted networks, where multiple operators provide services to their respective served users. The operators use dedicated frequency bands, but each RIS inadvertently reflects the transmitted uplink signals of the user equipment devices in multiple bands. Consequently, the concurrent reflection of pilot signals during the channel estimation phase introduces a new inter-operator pilot contamination effect. We investigate the implications of this effect in systems with either deterministic or correlated Rayleigh fading channels, specifically focusing on its impact on channel estimation quality, signal equalization, and channel capacity. The numerical results demonstrate the substantial degradation in system performance caused by this phenomenon and highlight the pressing need to address inter-operator pilot contamination in multi-operator RIS deployments. To combat the negative effect of this new type of pilot contamination, we propose to use orthogonal RIS configurations during uplink pilot transmission, which can mitigate or eliminate the negative effect of inter-operator pilot contamination at the expense of some inter-operator information exchange and orchestration.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Comparison-of-Different-Segmentations-in-Automated-Detection-of-Hypertension-Using-Electrocardiography-with-Empirical-Mode-Decomposition"><a href="#Comparison-of-Different-Segmentations-in-Automated-Detection-of-Hypertension-Using-Electrocardiography-with-Empirical-Mode-Decomposition" class="headerlink" title="Comparison of Different Segmentations in Automated Detection of Hypertension Using Electrocardiography with Empirical Mode Decomposition"></a>Comparison of Different Segmentations in Automated Detection of Hypertension Using Electrocardiography with Empirical Mode Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01142">http://arxiv.org/abs/2311.01142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Y. E. Erdoğan, A. Narin</li>
<li>for: 旨在早期和准确地诊断高血压（HPT）病例，使用电子心脏agram（ECG）信号进行自动识别。</li>
<li>methods: 使用Empirical Mode Decomposition方法提取5层Intrinsic Mode Function（IMF）信号，并从每个IMF中提取9个特征进行分类。</li>
<li>results: 使用5-fold cross-validation技术，在ECG数据集中实现了99.9991%和99.9989%的准确率，表明该方法在诊断HPT中具有潜在的用途。<details>
<summary>Abstract</summary>
Hypertension (HPT) refers to a condition where the pressure exerted on the walls of arteries by blood pumped from the heart to the body reaches levels that can lead to various ailments. Annually, a significant number of lives are lost globally due to diseases linked to HPT. Therefore, the early and accurate diagnosis of HPT is of utmost importance. This study aimed to automatically and with minimal error detect patients suffering from HPT by utilizing electrocardiogram (ECG) signals. The research involved the collection of ECG signals from two distinct groups. These groups consisted of ECG data of both five thousand and ten thousand data points in length, respectively. The performance in HPT detection was evaluated using entropy measurements derived from the 5-layer Intrinsic Mode Function(IMF) signals through the application of the Empirical Mode Decomposition method. The resulting performances were compared based on the nine features extracted from each IMF. To summarize, employing the 5-fold cross-validation technique, the most exceptional accuracy rates achieved were 99.9991% and 99.9989% for ECG data of lengths five thousand and ten thousand,respectively, using decision tree algorithms. These remarkable performance results indicate the potential usefulness of this method in assisting medical professionals to identify individuals with HPT.
</details>
<details>
<summary>摘要</summary>
高血压（HPT）是指心脏吐出到体内的血液压力超过了正常范围，可能导致多种疾病。每年全球都有很多人因与HPT相关的疾病而丧生。因此，早期准确诊断HPT的重要性是自然的。本研究目的是使用电子心电团（ECG）信号自动、准确地诊断患有HPT的患者。研究中收集了ECG信号的两个组。这两个组分别包括5000和10000个数据点的ECG数据。通过使用预测方法，对5层内含函数（IMF）信号进行了Entropy测量，以评估HPT检测的性能。基于每个IMF提取的9个特征进行比较。总结来说，通过使用5fold交叉验证法，使用决策树算法的情况下，ECG数据的5000和10000个数据点的性能最高达99.9991%和99.9989%。这些优异的性能结果表明这种方法在帮助医生诊断HPT患者有潜在的用途。
</details></li>
</ul>
<hr>
<h2 id="Noncontact-Detection-of-Sleep-Apnea-Using-Radar-and-Expectation-Maximization-Algorithm"><a href="#Noncontact-Detection-of-Sleep-Apnea-Using-Radar-and-Expectation-Maximization-Algorithm" class="headerlink" title="Noncontact Detection of Sleep Apnea Using Radar and Expectation-Maximization Algorithm"></a>Noncontact Detection of Sleep Apnea Using Radar and Expectation-Maximization Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01084">http://arxiv.org/abs/2311.01084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takato Koda, Shigeaki Okumura, Hirofumi Taki, Satoshi Hamada, Hironobu Sunadome, Susumu Sato, Kazuo Chin, Takuya Sakamoto</li>
<li>for: 这研究旨在提出一种基于激光的新方法，用于准确地检测呼吸障碍事件。</li>
<li>methods: 这方法使用了望前预设的预算-最大化算法，将正常和不正常呼吸模式中的呼吸特征提取出来，实现了灵活的呼吸检测能力，无需任何实验参数。</li>
<li>results: 这研究通过对五名呼吸障碍症状患者进行同时的诊断和激光测量，发现这方法可以每小时检测出呼吸障碍事件4.8次，与传统的阈值基本方法相比，提高了准确性1.8倍，显示了我们提出的方法的有效性。<details>
<summary>Abstract</summary>
Sleep apnea syndrome requires early diagnosis because this syndrome can lead to a variety of health problems. If sleep apnea events can be detected in a noncontact manner using radar, we can then avoid the discomfort caused by the contact-type sensors that are used in conventional polysomnography. This study proposes a novel radar-based method for accurate detection of sleep apnea events. The proposed method uses the expectation-maximization algorithm to extract the respiratory features that form normal and abnormal breathing patterns, resulting in an adaptive apnea detection capability without any requirement for empirical parameters. We conducted an experimental quantitative evaluation of the proposed method by performing polysomnography and radar measurements simultaneously in five patients with the symptoms of sleep apnea syndrome. Through these experiments, we show that the proposed method can detect the number of apnea and hypopnea events per hour with an error of 4.8 times/hour; this represents an improvement in the accuracy by 1.8 times when compared with the conventional threshold-based method and demonstrates the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
睡眠呼吸暂停综合症需早期诊断，因为这种病种可能会导致多种健康问题。如果可以使用雷达探测sleep apnea事件而不用触摸式传感器，我们就可以避免由传统多somnography所带来的不适感。本研究提出了一种基于雷达的新方法，能够准确检测sleep apnea事件。该方法使用了望望-最大化算法提取呼吸特征，从而实现了不需任何参数的自适应apnea检测能力。我们在五名睡眠呼吸暂停症病人身上同时进行了多somnography和雷达测量，并通过实验证明了我们的提议方法可以准确地检测每小时的apnea和低吸量事件数量，误差为4.8次/小时，与传统的阈值基于方法相比提高精度1.8倍，这表明了我们的提议方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Fourier-Analysis-of-Signals-on-Directed-Acyclic-Graphs-DAG-Using-Graph-Zero-Padding"><a href="#Fourier-Analysis-of-Signals-on-Directed-Acyclic-Graphs-DAG-Using-Graph-Zero-Padding" class="headerlink" title="Fourier Analysis of Signals on Directed Acyclic Graphs (DAG) Using Graph Zero-Padding"></a>Fourier Analysis of Signals on Directed Acyclic Graphs (DAG) Using Graph Zero-Padding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01073">http://arxiv.org/abs/2311.01073</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ljubisa Stankovic, Milos Dakovic, Ali Bagheri Bardi, Milos Brajovic, Isidora Stankovic</li>
<li>for: 这篇论文是为了解决directed acyclic graphs（DAGs）中的causal关系、依赖关系和流动关系模型中的一个问题，即spectral analysis变得不实用，因为adjacency matrix的特征值全部为零。</li>
<li>methods: 该论文提出了一种graph zero-paddingapproach，即在原有的DAG结构上添加更多的vertices，并将这些vertices的信号值设为零。这种方法可以帮助实现DAG上的spectral评估，即计算顶点域散射无 aliasing的问题。</li>
<li>results: 该论文的研究结果表明，通过使用graph zero-paddingapproach，可以实现DAG上的spectral评估，并且不会因为Graph结构的变化而带来干扰。这种方法可以帮助解决DAG中的一些问题，如causal关系、依赖关系和流动关系的模型。<details>
<summary>Abstract</summary>
Directed acyclic graphs (DAGs) are used for modeling causal relationships, dependencies, and flows in various systems. However, spectral analysis becomes impractical in this setting because the eigendecomposition of the adjacency matrix yields all eigenvalues equal to zero. This inherent property of DAGs results in an inability to differentiate between frequency components of signals on such graphs. This problem can be addressed by adding edges in DAG. However, this approach changes the physics of the considered problem. To address this limitation, we propose a graph zero-padding approach. This approach involves augmenting the original DAG with additional vertices that are connected to the existing structure. The added vertices are characterized by signal values set to zero. The proposed technique enables the spectral evaluation of system outputs on DAGs, that is the computation of vertex-domain convolution without the adverse effects of aliasing due to changes in graph structure.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Continuous-Fluid-Antenna-Systems-Modeling-and-Analysis"><a href="#Continuous-Fluid-Antenna-Systems-Modeling-and-Analysis" class="headerlink" title="Continuous Fluid Antenna Systems: Modeling and Analysis"></a>Continuous Fluid Antenna Systems: Modeling and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01058">http://arxiv.org/abs/2311.01058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Constantinos Psomas, Peter J. Smith, Himal A. Suraweera, Ioannis Krikidis</li>
<li>for: 这篇论文是关于流体天线（FA）技术的研究，FA 技术可以带来无线网络中的灵活性和重新配置能力。</li>
<li>methods: 该论文使用了一个综合的框架来设计和分析流体天线系统（CFAS），并 derive了关于水平交叉率（LCR）和均匀干扰比率（SIR）过程中的closed-form analytical表达。</li>
<li>results: 研究结果表明，CFAS 在比较 discrete 天线系统时表现更好，并提供了 FA 系统的性能限制。<details>
<summary>Abstract</summary>
Fluid antennas (FAs) is a promising technology for introducing flexibility and reconfigurability in wireless networks. Recent research efforts have highlighted the potential gains that can be achieved in comparison to conventional antennas. These works assume that the FA has a discrete number of positions that the liquid can take. However, from a practical standpoint, the liquid moves in a continuous fashion to any point inside the FA. In this paper, we focus on a continuous FA system (CFAS) and present a general framework for its design and analytical evaluation. In particular, we derive closed-form analytical expressions for the level crossing rate (LCR) and the average fade duration of the continuous signal-to-interference ratio (SIR) process over the FA's length. Then, by leveraging the LCR expression, we characterize the system's outage performance with a bound on the cumulative distribution function of the SIR's supremum. Our results confirm that the CFAS outperforms its discrete counterpart and thus provides the performance limits of FA-based systems.
</details>
<details>
<summary>摘要</summary>
“流体天线（FA）是一种可能带来flexibility和重新配置的无线网络技术。近期的研究努力表明，相比于传统天线，FA可以获得更大的优化。”“这些研究假设FA具有确定数量的位置，但实际上，流体可以在FA中任意位置移动。在本文中，我们专注于连续FA系统（CFAS），并提出一个通用的设计框架和分析评估。”“具体来说，我们 derivated 点横过率（LCR）和平均障碍时间的关注率表达式，并使用LCR表达式来描述系统的失灵性表现。”“我们的结果显示，CFAS在比较于确定FA系统时表现更好，因此提供了FA-based系统的性能限制。”
</details></li>
</ul>
<hr>
<h2 id="From-5G-to-6G-Revolutionizing-Satellite-Networks-through-TRANTOR-Foundation"><a href="#From-5G-to-6G-Revolutionizing-Satellite-Networks-through-TRANTOR-Foundation" class="headerlink" title="From 5G to 6G: Revolutionizing Satellite Networks through TRANTOR Foundation"></a>From 5G to 6G: Revolutionizing Satellite Networks through TRANTOR Foundation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01055">http://arxiv.org/abs/2311.01055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pol Henarejos, Xavier Artiga, Miguel A. Vázquez, Màrius Caus, Musbah Shaat, Joan Bas, Lluís Blanco, Ana I. Pérez-Neira</li>
<li>for: 本研究旨在开发一个标准化的5G生态系统，以满足卫星互联网提供商的需求，提供更高的数据速率、更大的网络容量、更低的延迟、更可靠的连接和更高的可用性。</li>
<li>methods: 本研究使用了5G技术，包括开发多频道多轨道天线、gNodeB和UE5G非地面网络设备，以满足卫星交通的多种需求和负载。</li>
<li>results: 本研究实现了一个可扩展、安全、高效的卫星网络管理解决方案，可以满足卫星互联网提供商的增长需求和多样化需求。<details>
<summary>Abstract</summary>
5G technology will drastically change the way satellite internet providers deliver services by offering higher data speeds, massive network capacity, reduced latency, improved reliability and increased availability. A standardised 5G ecosystem will enable adapting 5G to satellite needs. The EU-funded TRANTOR project will seek to develop novel and secure satellite network management solutions that allow scaling up heterogeneous satellite traffic demands and capacities in a cost-effective and highly dynamic way. Researchers also target the development of flexible 6G non-terrestrial access architectures. The focus will be on the design of a multi-orbit and multi-band antenna for satellite user equipment (UE), as well as the development of gNodeB (gNB) and UE 5G non-terrestrial network equipment to support multi-connectivity.
</details>
<details>
<summary>摘要</summary>
5G技术将完全改变卫星互联网提供商如何提供服务，提供更高的数据速率、更大的网络容量、减少延迟、改善可靠性和提高可用性。标准化的5G生态系统将帮助适应5G卫星需求。欧盟资金支持的TRANTOR项目将努力开发新的安全卫星网络管理解决方案，以满足卫星流量需求和容量的扩展和弹性scaling。研究人员还将 targets developing flexible 6G non-terrestrial access architectures。关注的方面包括卫星用户设备（UE）多天线多频段设计，以及支持多连接的gNodeB（gNB）和UE 5G非地面网络设备的开发。
</details></li>
</ul>
<hr>
<h2 id="Mathematical-Properties-of-the-Zadoff-Chu-Sequences"><a href="#Mathematical-Properties-of-the-Zadoff-Chu-Sequences" class="headerlink" title="Mathematical Properties of the Zadoff-Chu Sequences"></a>Mathematical Properties of the Zadoff-Chu Sequences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.01035">http://arxiv.org/abs/2311.01035</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Gregoratti, Xavier Arteaga, Joaquim Broquetas</li>
<li>for: 这篇论文是一份收集了知名结果的赫杯-珠 sequences 论文，包括所有证明，使用一致的数学符号，为易引用。</li>
<li>methods: 论文 derivates a formula to compute the first term (频率为零) of the discrete Fourier transform of a Zadoff-Chu sequence $x_u[n]$ of prime length $N_{\text{ZC}$ and root index $u$, with constant complexity independent of the sequence length.</li>
<li>results: 论文得到了一个公式，可以计算 Zadoff-Chu sequence $x_u[n]$ 的抽象傅立叶变换的首项（频率为零），并且这个公式与赫杯-珠 sequences 的特性有关。<details>
<summary>Abstract</summary>
This paper is a compilation of well-known results about Zadoff-Chu sequences, including all proofs with a consistent mathematical notation, for easy reference. Moreover, for a Zadoff-Chu sequence $x_u[n]$ of prime length $N_{\text{ZC}$ and root index $u$, a formula is derived that allows computing the first term (frequency zero) of its discrete Fourier transform, $X_u[0]$, with constant complexity independent of the sequence length, as opposed to accumulating all its $N_{\text{ZC}$ terms. The formula stems from a famous result in analytic number theory and is an interesting complement to the fact that the discrete Fourier transform of a Zadoff-Chu sequence is itself a Zadoff-Chu sequence whose terms are scaled by $X_u[0]$. Finally, the paper concludes with a brief analysis of time-continuous signals derived from Zadoff-Chu sequences, especially those obtained by OFDM-modulating a Zadoff-Chu sequence.
</details>
<details>
<summary>摘要</summary>
Note: "Simplified Chinese" is a translation of the text into Traditional Chinese, which is the standard writing system used in Taiwan and other countries.Here's the translation of the text into Simplified Chinese, which is used in mainland China:这篇论文收集了关于佐道夫-楚 sequences的Well-known Results，包括所有证明，使用一致的数学符号，为易参照。此外，对佐道夫-楚序列 $x_u[n]$ 的 prime length $N_{\text{ZC}$ 和根指数 $u$， derivation 一个公式，可以计算其抽象傅立叙 Transform 的首项（频率为零），X_u[0]，与Constant complexity 独立于序列长度，不同于积累所有 $N_{\text{ZC}$ 项。这个公式基于分析数论中著名的结果，是一种有趣的补充，因为抽象傅立叙 Transform 的佐道夫-楚序列自身是一个扩展的佐道夫-楚序列，其项被扩展为 $X_u[0]$。最后，文章 briefly analyzes time-continuous signals derived from Zadoff-Chu sequences, particularly those obtained by OFDM-modulating a Zadoff-Chu sequence.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/02/eess.SP_2023_11_02/" data-id="cloqtaf3g01cqgh88d10ncwzf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.SD_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T15:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.SD_2023_11_01/">cs.SD - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Investigating-Self-Supervised-Deep-Representations-for-EEG-based-Auditory-Attention-Decoding"><a href="#Investigating-Self-Supervised-Deep-Representations-for-EEG-based-Auditory-Attention-Decoding" class="headerlink" title="Investigating Self-Supervised Deep Representations for EEG-based Auditory Attention Decoding"></a>Investigating Self-Supervised Deep Representations for EEG-based Auditory Attention Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00814">http://arxiv.org/abs/2311.00814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karan Thakkar, Jiarui Hai, Mounya Elhilali</li>
<li>for: 这篇研究旨在探索深度自愿学习（SS）表现在脑活动讯号处理中的可行性，尤其是在复杂的声音环境中对需要的声音源进行隔离。</li>
<li>methods: 本研究使用了12个深度和2个浅层表现，对EEG数据自57名参与者和多种语言进行了评估。</li>
<li>results: 实验结果显示，深度特征在背景声音源隔离中表现出超过浅层特征，无论是哪些数据和分析窗口。这显示可能存在脑中隐藏的非线性编码，深度非线性特征可能会更好地捕捉这些隐藏的讯号。此外，研究还分析了不同层次的SS表现和窗口大小对AAD性能的影响。<details>
<summary>Abstract</summary>
Auditory Attention Decoding (AAD) algorithms play a crucial role in isolating desired sound sources within challenging acoustic environments directly from brain activity. Although recent research has shown promise in AAD using shallow representations such as auditory envelope and spectrogram, there has been limited exploration of deep Self-Supervised (SS) representations on a larger scale. In this study, we undertake a comprehensive investigation into the performance of linear decoders across 12 deep and 2 shallow representations, applied to EEG data from multiple studies spanning 57 subjects and multiple languages. Our experimental results consistently reveal the superiority of deep features for AAD at decoding background speakers, regardless of the datasets and analysis windows. This result indicates possible nonlinear encoding of unattended signals in the brain that are revealed using deep nonlinear features. Additionally, we analyze the impact of different layers of SS representations and window sizes on AAD performance. These findings underscore the potential for enhancing EEG-based AAD systems through the integration of deep feature representations.
</details>
<details>
<summary>摘要</summary>
听觉注意力解码（AAD）算法在复杂的听觉环境中直接从大脑活动中隔离感兴趣的声音源。although recent research has shown promise in AAD using shallow representations such as auditory envelope and spectrogram, there has been limited exploration of deep Self-Supervised (SS) representations on a larger scale. In this study, we undertake a comprehensive investigation into the performance of linear decoders across 12 deep and 2 shallow representations, applied to EEG data from multiple studies spanning 57 subjects and multiple languages. Our experimental results consistently reveal the superiority of deep features for AAD at decoding background speakers, regardless of the datasets and analysis windows. This result indicates possible nonlinear encoding of unattended signals in the brain that are revealed using deep nonlinear features. Additionally, we analyze the impact of different layers of SS representations and window sizes on AAD performance. These findings underscore the potential for enhancing EEG-based AAD systems through the integration of deep feature representations.Here's the word-for-word translation:听觉注意力解码算法在复杂的听觉环境中直接从大脑活动中隔离感兴趣的声音源。although recent research has shown promise in AAD using shallow representations such as auditory envelope and spectrogram, there has been limited exploration of deep Self-Supervised (SS) representations on a larger scale. In this study, we undertake a comprehensive investigation into the performance of linear decoders across 12 deep and 2 shallow representations, applied to EEG data from multiple studies spanning 57 subjects and multiple languages. Our experimental results consistently reveal the superiority of deep features for AAD at decoding background speakers, regardless of the datasets and analysis windows. This result indicates possible nonlinear encoding of unattended signals in the brain that are revealed using deep nonlinear features. Additionally, we analyze the impact of different layers of SS representations and window sizes on AAD performance. These findings underscore the potential for enhancing EEG-based AAD systems through the integration of deep feature representations.
</details></li>
</ul>
<hr>
<h2 id="C2C-Cough-to-COVID-19-Detection-in-BHI-2023-Data-Challenge"><a href="#C2C-Cough-to-COVID-19-Detection-in-BHI-2023-Data-Challenge" class="headerlink" title="C2C: Cough to COVID-19 Detection in BHI 2023 Data Challenge"></a>C2C: Cough to COVID-19 Detection in BHI 2023 Data Challenge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00364">http://arxiv.org/abs/2311.00364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Woo-Jin Chung, Miseul Kim, Hong-Goo Kang</li>
<li>For: The paper is written for the BHI 2023 Data Competition: Sensor challenge, with the goal of developing an acoustic-based COVID-19 diagnosis system.* Methods: The paper uses pre-processing of input signals, cough-related representation extraction leveraging Wav2vec2.0, and data augmentation to develop the Cough to COVID-19 (C2C) system.* Results: The paper demonstrates the promising potential of C2C to enhance the diagnostic accuracy of COVID-19 via cough signals, with a ROC-AUC value of 0.7810 in the context of COVID-19 diagnosis.Here is the text in Simplified Chinese:* 为：本文为BHI 2023数据比赛：感测挑战提交作品，旨在开发基于听音的 COVID-19诊断系统。* 方法：本文使用输入信号预处理、基于 Wav2vec2.0 的喊喊相关表示EXTRACT、数据增强等方法开发 Cough to COVID-19 (C2C) 系统。* 结果：本文通过实验发现，C2C 系统可以在 COVID-19 诊断中提高诊断精度，ROC-AUC 值达0.7810。<details>
<summary>Abstract</summary>
This report describes our submission to BHI 2023 Data Competition: Sensor challenge. Our Audio Alchemists team designed an acoustic-based COVID-19 diagnosis system, Cough to COVID-19 (C2C), and won the 1st place in the challenge. C2C involves three key contributions: pre-processing of input signals, cough-related representation extraction leveraging Wav2vec2.0, and data augmentation. Through experimental findings, we demonstrate C2C's promising potential to enhance the diagnostic accuracy of COVID-19 via cough signals. Our proposed model achieves a ROC-AUC value of 0.7810 in the context of COVID-19 diagnosis. The implementation details and the python code can be found in the following link: https://github.com/Woo-jin-Chung/BHI_2023_challenge_Audio_Alchemists
</details>
<details>
<summary>摘要</summary>
这份报告描述了我们对BHI 2023数据比赛：感知挑战的提交。我们的Audio Alchemists团队设计了基于声音的COVID-19诊断系统，叫做Cough to COVID-19（C2C），并在挑战中获得了第一名。C2C包括三个关键贡献：输入信号的预处理、基于Wav2vec2.0的喊喊相关特征提取，以及数据扩展。通过实验发现，我们示出了C2C在COVID-19诊断中的潜在优势，可以提高COVID-19诊断的准确率。我们的提出的模型在COVID-19诊断上 achievement ROC-AUC值为0.7810。更多细节和python代码可以在以下链接中找到：https://github.com/Woo-jin-Chung/BHI_2023_challenge_Audio_Alchemists。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.SD_2023_11_01/" data-id="cloqtaex500yxgh884qae86vl" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/eess.AS_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T14:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/eess.AS_2023_11_01/">eess.AS - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Reverberant-sound-field-equalisation-for-an-enhanced-stereo-playback-experience"><a href="#Reverberant-sound-field-equalisation-for-an-enhanced-stereo-playback-experience" class="headerlink" title="Reverberant sound field equalisation for an enhanced stereo playback experience"></a>Reverberant sound field equalisation for an enhanced stereo playback experience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00624">http://arxiv.org/abs/2311.00624</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Brooks-Park, Steven van de Par</li>
<li>for: 提高室内播放质量</li>
<li>methods: 使用新型平衡技术，通过两个围壳喇叭加入杂音场能量，保持直接喇叭不变，但是listenposition处的总能量平衡</li>
<li>results: 比traditional平衡技术和stereo播放更受欢迎<details>
<summary>Abstract</summary>
The topic of room equalisation has been at the forefront of research and product development for many years, with the aim of increasing the playback quality of loudspeakers in reverberant rooms. Traditional room equalisation systems comprise of a number of filters that when applied to the primary loudspeakers, additional room colouration is compensated for. This publication introduces a novel equalisation technique where gammatone filter band energy is added to the reverberant sound field via two surround loudspeakers, leaving the direct sound from the primary loudspeakers unaltered, but the sum of direct and reverberant energy is equalised at the listening position. Unlike traditional systems, this method allows the target function of the direct sound to differ from the reverberant sound field. The proposed method is motivated by the different roles direct and reverberant sound components play in humans perception of sound. Along with introducing the proposed method, results from a subjective listening test are presented, demonstrating the preference towards the proposed technique when compared to a traditional room equalisation technique and stereo playback.
</details>
<details>
<summary>摘要</summary>
topic of 房间平衡已经是多年来研究和产品开发的焦点，目的是提高喷流房间中 loudspeakers 的播放质量。传统的房间平衡系统包括多个缓减器，当应用于主要喷流speakers时，会赔偿房间颜色。这篇文章介绍了一种新的平衡技术，通过两个围声speakers 将 gammatone 缓减器带能量添加到透传声场中，保留直接喷流speakers 不变，但是在听众位置进行平衡。与传统系统不同，这种方法允许目标函数直接喷流的音响不同于透传声场。该提议的方法被动机于人类听众对音响的感知中直接和透传声场的不同角色。文章还 introduce 了这种方法并发布了一个对比传统房间平衡技术和 stero 播放的主观听测结果。
</details></li>
</ul>
<hr>
<h2 id="An-analysis-of-large-speech-models-based-representations-for-speech-emotion-recognition"><a href="#An-analysis-of-large-speech-models-based-representations-for-speech-emotion-recognition" class="headerlink" title="An analysis of large speech models-based representations for speech emotion recognition"></a>An analysis of large speech models-based representations for speech emotion recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00394">http://arxiv.org/abs/2311.00394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Bogdan Stânea, Vlad Striletchi, Cosmin Striletchi, Adriana Stan</li>
<li>for: 这项研究是为了研究大语音模型中的特征，以及这些特征在语音情感识别任务中的表现。</li>
<li>methods: 这项研究使用了预训练的大语音模型，并explored其内置的抽象能力。研究使用了简单的分类方法，以避免对任务添加知识或干扰。</li>
<li>results: 研究发现，无需迁移，一些大语音模型的表示能够包含情感识别任务中的信息，使得表现与标准数据集上的 state-of-the-art 结果几乎相同。<details>
<summary>Abstract</summary>
Large speech models-derived features have recently shown increased performance over signal-based features across multiple downstream tasks, even when the networks are not finetuned towards the target task. In this paper we show the results of an analysis of several signal- and neural models-derived features for speech emotion recognition. We use pretrained models and explore their inherent potential abstractions of emotions. Simple classification methods are used so as to not interfere or add knowledge to the task. We show that, even without finetuning, some of these large neural speech models' representations can enclose information that enables performances close to, and even beyond state-of-the-art results across six standard speech emotion recognition datasets.
</details>
<details>
<summary>摘要</summary>
大型语音模型Derived feature在多个下游任务中表现出来的提高，即使无需finetune到目标任务。在这篇论文中，我们进行了各种信号模型和神经网络模型Derived feature的分析，用于speech emotion认知。我们使用预训练模型，探索它们的内在抽象情感。我们使用简单的分类方法，以避免干扰或添加任务知识。我们发现，无需finetune，一些大型语音模型的表示可以包含情感认知的信息，使其表现与或超过标准六个speech emotion认知 dataset的状态的报告。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/eess.AS_2023_11_01/" data-id="cloqtaeyw012jgh88ai8k5nbm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.CV_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T13:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.CV_2023_11_01/">cs.CV - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Call-to-Arms-AI-Should-be-Critical-for-Social-Media-Analysis-of-Conflict-Zones"><a href="#A-Call-to-Arms-AI-Should-be-Critical-for-Social-Media-Analysis-of-Conflict-Zones" class="headerlink" title="A Call to Arms: AI Should be Critical for Social Media Analysis of Conflict Zones"></a>A Call to Arms: AI Should be Critical for Social Media Analysis of Conflict Zones</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00810">http://arxiv.org/abs/2311.00810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Afia Abedin, Abdul Bais, Cody Buntain, Laura Courchesne, Brian McQuinn, Matthew E. Taylor, Muhib Ullah</li>
<li>for: 本研究旨在利用计算机视觉技术来跟踪乌克兰冲突中不同类型武装部队的武器系统和 armed groups的标识符，以及这些武器系统在冲突中的分布。</li>
<li>methods: 本研究使用计算机视觉技术来识别和跟踪乌克兰冲突中的武器系统和 armed groups。</li>
<li>results: 本研究可能可以跟踪冲突中不同类型武装部队的武器系统和 armed groups的使用情况，以及这些武器系统在冲突中的分布。这种系统可能可以用于实时跟踪冲突，包括人道主义和医疗援助的需求。<details>
<summary>Abstract</summary>
The massive proliferation of social media data represents a transformative moment in conflict studies. This data can provide unique insights into the spread and use of weaponry, but the scale and types of data are problematic for traditional open-source intelligence. This paper presents preliminary, transdisciplinary work using computer vision to identify specific weapon systems and the insignias of the armed groups using them. There is potential to not only track how weapons are distributed through networks of armed units but also to track which types of weapons are being used by the different types of state and non-state military actors in Ukraine. Such a system could ultimately be used to understand conflicts in real-time, including where humanitarian and medical aid is most needed. We believe that using AI to help automate such processes should be a high-priority goal for our community, with near-term real-world payoffs.
</details>
<details>
<summary>摘要</summary>
“社交媒体数据的庞大扩散 представляет一个转变时刻在冲突研究中。这些数据可以提供唯一的察视武器的扩散和使用情况，但传统的开源情报处理这些数据的规模和类型具有挑战。本文发表了初步的跨学科工作，使用计算机视觉来识别特定的武器系统和武装组织使用的标识符。这种系统可以跟踪武器在武装单位网络中的分布，以及不同类型的国家和非国家军事 acted in ukraine 中的武器使用类型。这种系统可以在实时进行跟踪，包括人道主义和医疗援助的需求。我们认为，使用AI自动化这些过程应该是我们社区的高优先事项，具有近期的实际应用效果。”Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="VQA-GEN-A-Visual-Question-Answering-Benchmark-for-Domain-Generalization"><a href="#VQA-GEN-A-Visual-Question-Answering-Benchmark-for-Domain-Generalization" class="headerlink" title="VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization"></a>VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00807">http://arxiv.org/abs/2311.00807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suraj Jyothi Unni, Raha Moraffah, Huan Liu</li>
<li>for: 这个论文的目的是提出一个多模态 benchmark dataset，以便评估视觉问答模型在不同的分布Shift下的一致性。</li>
<li>methods: 这个论文使用了一个shift induced pipeline来生成多模态分布Shift，并对现有的VQA模型进行评估。</li>
<li>results: 实验表明，VQA-GEN dataset能够暴露现有的VQA模型在多模态分布Shift下的敏感性，并且模型在VQA-GEN dataset上进行训练后，在跨Domains和内Domains中表现出了改善。此外，这个论文还分析了每种分布Shift技术的重要性，以便更好地理解模型在不同的分布Shift下的一致性。<details>
<summary>Abstract</summary>
Visual question answering (VQA) models are designed to demonstrate visual-textual reasoning capabilities. However, their real-world applicability is hindered by a lack of comprehensive benchmark datasets. Existing domain generalization datasets for VQA exhibit a unilateral focus on textual shifts while VQA being a multi-modal task contains shifts across both visual and textual domains. We propose VQA-GEN, the first ever multi-modal benchmark dataset for distribution shift generated through a shift induced pipeline. Experiments demonstrate VQA-GEN dataset exposes the vulnerability of existing methods to joint multi-modal distribution shifts. validating that comprehensive multi-modal shifts are critical for robust VQA generalization. Models trained on VQA-GEN exhibit improved cross-domain and in-domain performance, confirming the value of VQA-GEN. Further, we analyze the importance of each shift technique of our pipeline contributing to the generalization of the model.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传入文本转化为简化中文。<</SYS>>视觉问答（VQA）模型是用来演示视觉文本理解能力的。然而，它们在实际应用中受到了全面的基准数据集的限制。现有的领域泛化数据集 для VQA 具有单一的文本变化预测，而 VQA 是一个多Modal任务，其中包括视觉和文本频率的变化。我们提议 VQA-GEN，是首个基于shift induced pipeline的多Modal基准数据集。实验表明，VQA-GEN数据集会暴露现有方法对于多Modal共同分布的敏感性。这 validate了需要对多Modal分布进行robust化，以确保VQA模型的通用化。模型在 VQA-GEN 上训练后，在跨频道和内频道性能都有所提高，证明了 VQA-GEN 的价值。此外，我们分析了我们的排序队列中每种排序技术的重要性，以确定模型的通用化。
</details></li>
</ul>
<hr>
<h2 id="Automatic-counting-of-planting-microsites-via-local-visual-detection-and-global-count-estimation"><a href="#Automatic-counting-of-planting-microsites-via-local-visual-detection-and-global-count-estimation" class="headerlink" title="Automatic counting of planting microsites via local visual detection and global count estimation"></a>Automatic counting of planting microsites via local visual detection and global count estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00796">http://arxiv.org/abs/2311.00796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Zgaren, Wassim Bouachir, Nizar Bouguila</li>
<li>for: 这篇论文是用于自动估计植树块中垫峰的数量的。</li>
<li>methods: 该方法使用了计算机视觉和人工智能技术，将估计任务转化为一个超级vised学习问题，使用了两个预测模型。首先，使用深度特征来探测可见的垫峰，然后使用块级特征来提供最终估计。</li>
<li>results: 对于 constructed UAV dataset，实验表明提案方法比人工方法在精度上具有优势，同时可以大幅降低时间和成本。<details>
<summary>Abstract</summary>
In forest industry, mechanical site preparation by mounding is widely used prior to planting operations. One of the main problems when planning planting operations is the difficulty in estimating the number of mounds present on a planting block, as their number may greatly vary depending on site characteristics. This estimation is often carried out through field surveys by several forestry workers. However, this procedure is prone to error and slowness. Motivated by recent advances in UAV imagery and artificial intelligence, we propose a fully automated framework to estimate the number of mounds on a planting block. Using computer vision and machine learning, we formulate the counting task as a supervised learning problem using two prediction models. A local detection model is firstly used to detect visible mounds based on deep features, while a global prediction function is subsequently applied to provide a final estimation based on block-level features. To evaluate the proposed method, we constructed a challenging UAV dataset representing several plantation blocks with different characteristics. The performed experiments demonstrated the robustness of the proposed method, which outperforms manual methods in precision, while significantly reducing time and cost.
</details>
<details>
<summary>摘要</summary>
在森林工业中，机械场准备通过堆填是广泛使用的，以便进行植树操作。一个主要的问题在规划植树操作时是计算堆填的数量，因为它们的数量可能会很大地变化，很难估算。这个估算通常通过外部考察而进行，但这种方法容易出错和慢。驱动了最近的无人机影像和人工智能的进步，我们提出了一个完全自动化的计算方法，以便计算堆填的数量。使用计算机视觉和机器学习，我们将计算任务转化为一个监督学习问题，使用两个预测模型。首先，我们使用深度特征来检测可见的堆填，然后使用块级特征来提供最终的估算。为评估我们的方法，我们构建了一个具有不同特点的无人机数据集，表示了多个植树块。实验表明，我们的方法比手动方法更加精准，同时可以明显减少时间和成本。
</details></li>
</ul>
<hr>
<h2 id="What-User-Behaviors-Make-the-Differences-During-the-Process-of-Visual-Analytics"><a href="#What-User-Behaviors-Make-the-Differences-During-the-Process-of-Visual-Analytics" class="headerlink" title="What User Behaviors Make the Differences During the Process of Visual Analytics?"></a>What User Behaviors Make the Differences During the Process of Visual Analytics?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00690">http://arxiv.org/abs/2311.00690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahin Doroudian, Zekun Wu, Aidong Lu</li>
<li>for: 本研究旨在提高视觉分析过程中的理解，以便提高视觉设计和交互功能的发展。</li>
<li>methods: 本研究使用时间序列分类方法进行数据收集和分析，以了解用户在视觉分析过程中的行为。</li>
<li>results: 研究发现，用户在视觉分析过程中的行为可以被分 distinguish，并且存在用户物理行为和视觉任务之间的强相关性。此外，我们还提出了一种自动地study sensemaking的方法，无需繁重的手动标注。<details>
<summary>Abstract</summary>
The understanding of visual analytics process can benefit visualization researchers from multiple aspects, including improving visual designs and developing advanced interaction functions. However, the log files of user behaviors are still hard to analyze due to the complexity of sensemaking and our lack of knowledge on the related user behaviors. This work presents a study on a comprehensive data collection of user behaviors, and our analysis approach with time-series classification methods. We have chosen a classical visualization application, Covid-19 data analysis, with common analysis tasks covering geo-spatial, time-series and multi-attributes. Our user study collects user behaviors on a diverse set of visualization tasks with two comparable systems, desktop and immersive visualizations. We summarize the classification results with three time-series machine learning algorithms at two scales, and explore the influences of behavior features. Our results reveal that user behaviors can be distinguished during the process of visual analytics and there is a potentially strong association between the physical behaviors of users and the visualization tasks they perform. We also demonstrate the usage of our models by interpreting open sessions of visual analytics, which provides an automatic way to study sensemaking without tedious manual annotations.
</details>
<details>
<summary>摘要</summary>
理解视觉分析过程可以为视觉研究人员带来多方面的利益，包括改进视觉设计和开发高级交互功能。然而，用户行为的日志仍然具有复杂的感知和我们对相关用户行为的不了解。这项工作提出了一项全面的用户行为数据收集研究，以及我们的分析方法和时间序列分类方法。我们选择了一个经典的视觉应用程序，即COVID-19数据分析，并在这个应用程序中进行了常见的分析任务，包括地理空间、时间序列和多属性。我们的用户研究收集了用户在多个视觉任务上的行为记录，并对两种相似的系统进行了对比分析。我们总结了三种时间序列机器学习算法的分类结果，并探索了行为特征的影响。我们的结果表明，用户行为在视觉分析过程中可以分辨出来，并且用户的物理行为和他们执行的视觉任务之间可能存在强相关性。此外，我们还证明了我们的模型可以通过自动地解释开放会话，以便无需繁琐的手动标注，来研究感知过程。
</details></li>
</ul>
<hr>
<h2 id="Collaboration-in-Immersive-Environments-Challenges-and-Solutions"><a href="#Collaboration-in-Immersive-Environments-Challenges-and-Solutions" class="headerlink" title="Collaboration in Immersive Environments: Challenges and Solutions"></a>Collaboration in Immersive Environments: Challenges and Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00689">http://arxiv.org/abs/2311.00689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Shahin Doroudian, Zachary Wartell</li>
<li>for: This paper provides an overview of the current state of research on collaboration in immersive environments, including Virtual Reality (VR) and Augmented Reality (AR) settings.</li>
<li>methods: The paper discusses the different types of immersive environments, including VR and AR, and the different forms of collaboration that can occur in these environments.</li>
<li>results: The paper highlights the challenges and limitations of collaboration in immersive environments, such as the lack of physical cues, cost and usability, and the need for further research in this area.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文提供了现有关于在虚拟和扩展实现中进行协作的研究状况概述，包括虚拟和扩展实现环境。</li>
<li>methods: 论文讨论了不同类型的虚拟和扩展实现环境，以及在这些环境中可能出现的不同合作形式。</li>
<li>results: 论文强调了在虚拟和扩展实现环境中进行协作的挑战和限制，如缺乏物理提示、成本和使用性问题，以及需要进一步的研究。<details>
<summary>Abstract</summary>
Virtual Reality (VR) and Augmented Reality (AR) tools have been applied in all engineering fields in order to avoid the use of physical prototypes, to train in high-risk situations, and to interpret real or simulated results. In order to complete a shared task or assign tasks to the agents in such immersive environments, collaboration or Shared Cooperative Activities are a necessity. Collaboration in immersive environments is an emerging field of research that aims to study and enhance the ways in which people interact and work together in Virtual and Augmented Reality settings. Collaboration in immersive environments is a complex process that involves different factors such as communication, coordination, and social presence. This paper provides an overview of the current state of research on collaboration in immersive environments. It discusses the different types of immersive environments, including VR and AR, and the different forms of collaboration that can occur in these environments. The paper also highlights the challenges and limitations of collaboration in immersive environments, such as the lack of physical cues, cost and usability and the need for further research in this area. Overall, collaboration in immersive environments is a promising field with a wide range of potential applications, from education to industry, and it can benefit both individuals and groups by enhancing their ability to work together effectively.
</details>
<details>
<summary>摘要</summary>
虚拟现实（VR）和增强现实（AR）工具在所有工程领域中应用，以避免使用物理原型，进行高风险的训练，并解释现实或模拟结果。为完成共同任务或分配任务给代理人，在这些吸引环境中进行合作或共同活动是必要。合作在吸引环境中是一项新兴的研究领域，旨在研究人们在虚拟和增强现实Setting中如何交互和合作工作。在这些环境中进行合作是一个复杂的过程，涉及到不同的因素，如通信、协调和社交存在。本文提供了有关现有研究的总体情况，包括VR和AR等不同类型的吸引环境，以及在这些环境中不同形式的合作。文章还强调了在吸引环境中合作的挑战和限制，如物理冲击缺失、成本和可用性问题，以及需要进一步研究。总的来说，在吸引环境中进行合作是一个有前途的领域，它可以为人们提供更好的合作方式，从教育到行业，并且对个人和团队来说都有益。
</details></li>
</ul>
<hr>
<h2 id="ProcSim-Proxy-based-Confidence-for-Robust-Similarity-Learning"><a href="#ProcSim-Proxy-based-Confidence-for-Robust-Similarity-Learning" class="headerlink" title="ProcSim: Proxy-based Confidence for Robust Similarity Learning"></a>ProcSim: Proxy-based Confidence for Robust Similarity Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00668">http://arxiv.org/abs/2311.00668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oriol Barbany, Xiaofan Lin, Muhammet Bastan, Arnab Dhua</li>
<li>for: 学习一个嵌入空间，使得输入之间的距离与其内在Semantic相似性有高度相关性。</li>
<li>methods: 使用ProcSim框架，对每个样本计算 норamlized距离到类表现者的信任分数。</li>
<li>results: 实验结果表明，提议的方法在投入uniform和提议的semantic coherent noise的DMLbenchmark数据集上达到了状态 искусственный智能的性能。<details>
<summary>Abstract</summary>
Deep Metric Learning (DML) methods aim at learning an embedding space in which distances are closely related to the inherent semantic similarity of the inputs. Previous studies have shown that popular benchmark datasets often contain numerous wrong labels, and DML methods are susceptible to them. Intending to study the effect of realistic noise, we create an ontology of the classes in a dataset and use it to simulate semantically coherent labeling mistakes. To train robust DML models, we propose ProcSim, a simple framework that assigns a confidence score to each sample using the normalized distance to its class representative. The experimental results show that the proposed method achieves state-of-the-art performance on the DML benchmark datasets injected with uniform and the proposed semantically coherent noise.
</details>
<details>
<summary>摘要</summary>
深度度量学（DML）方法目标是学习一个尺度空间，其中距离与输入的内在Semantic相似性 closely related。先前的研究表明，流行的benchmark数据集经常包含大量的错误标签，而DML方法受其影响。为了研究实际噪声的效果，我们创建了一个数据集中类别的 ontology，并使用其来模拟Semantically coherent的标签错误。为了训练Robust DML模型，我们提议ProcSim，一种简单的框架，对每个样本分配一个信任分数，基于样本的normalized distance to its class representative。实验结果显示，我们的方法在DML benchmark数据集中 uniformly和我们所提出的semantically coherent噪声下 дости得了state-of-the-art性能。
</details></li>
</ul>
<hr>
<h2 id="TPSeNCE-Towards-Artifact-Free-Realistic-Rain-Generation-for-Deraining-and-Object-Detection-in-Rain"><a href="#TPSeNCE-Towards-Artifact-Free-Realistic-Rain-Generation-for-Deraining-and-Object-Detection-in-Rain" class="headerlink" title="TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain"></a>TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00660">http://arxiv.org/abs/2311.00660</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shenzheng2000/tpsence">https://github.com/shenzheng2000/tpsence</a></li>
<li>paper_authors: Shen Zheng, Changjie Lu, Srinivasa G. Narasimhan</li>
<li>for: 这 paper 的目的是提出一种无对应图像传输框架，以生成更加真实的雨天图像，并减少了雨天图像生成中的噪声和扭曲。</li>
<li>methods: 该 paper 使用了一种Triangular Probability Similarity (TPS) 约束，以引导生成的图像向清晰和雨天图像的槽中靠拢，从而减少生成过程中的噪声和扭曲。此外，它还使用了一种Semantic Noise Contrastive Estimation (SeNCE) 策略，重新评估负样本的推动力度，根据清晰和雨天图像之间的语义相似性和特征相似性。</li>
<li>results: 实验结果表明，该方法可以生成更加真实的雨天图像，减少了噪声和扭曲。此外，该方法还可以用于生成真实的雪天和夜天图像，强调其普遍应用性。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/ShenZheng2000/TPSeNCE">https://github.com/ShenZheng2000/TPSeNCE</a> 上获取。<details>
<summary>Abstract</summary>
Rain generation algorithms have the potential to improve the generalization of deraining methods and scene understanding in rainy conditions. However, in practice, they produce artifacts and distortions and struggle to control the amount of rain generated due to a lack of proper constraints. In this paper, we propose an unpaired image-to-image translation framework for generating realistic rainy images. We first introduce a Triangular Probability Similarity (TPS) constraint to guide the generated images toward clear and rainy images in the discriminator manifold, thereby minimizing artifacts and distortions during rain generation. Unlike conventional contrastive learning approaches, which indiscriminately push negative samples away from the anchors, we propose a Semantic Noise Contrastive Estimation (SeNCE) strategy and reassess the pushing force of negative samples based on the semantic similarity between the clear and the rainy images and the feature similarity between the anchor and the negative samples. Experiments demonstrate realistic rain generation with minimal artifacts and distortions, which benefits image deraining and object detection in rain. Furthermore, the method can be used to generate realistic snowy and night images, underscoring its potential for broader applicability. Code is available at https://github.com/ShenZheng2000/TPSeNCE.
</details>
<details>
<summary>摘要</summary>
雨生成算法有potential以提高雨天情况下的泛化和场景理解。然而，在实践中，它们会生成artefacts和扭曲，并且控制雨水生成的量因缺乏合适的约束而困难。在这篇论文中，我们提出了一种不带对应图像的图像到图像翻译框架，用于生成真实的雨天图像。我们首先引入了三角形概率相似（TPS）约束，以导引生成的图像向清晰和雨天图像的权重空间中迁移，从而减少artefacts和扭曲在雨水生成过程中。不同于传统的对比学习方法，我们提出了semantic Noise Contrastive Estimation（SeNCE）策略，并重新评估负样本的推动力度基于清晰和雨天图像之间的semantic相似性和特征相似性。实验表明可以生成真实的雨天图像，同时减少artefacts和扭曲，这对图像抢掉和物体检测在雨天有益。此外，该方法还可以用于生成真实的雪天和夜天图像，这augments its potential for broader applicability。代码可以在https://github.com/ShenZheng2000/TPSeNCE上获取。
</details></li>
</ul>
<hr>
<h2 id="De-Diffusion-Makes-Text-a-Strong-Cross-Modal-Interface"><a href="#De-Diffusion-Makes-Text-a-Strong-Cross-Modal-Interface" class="headerlink" title="De-Diffusion Makes Text a Strong Cross-Modal Interface"></a>De-Diffusion Makes Text a Strong Cross-Modal Interface</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00618">http://arxiv.org/abs/2311.00618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Wei, Chenxi Liu, Siyuan Qiao, Zhishuai Zhang, Alan Yuille, Jiahui Yu</li>
<li>for: 这 paper 是用于提出一种新的文本-图像 interfaces，它可以将图像转换为文本形式，从而提高图像和文本之间的交互性和灵活性。</li>
<li>methods: 这 paper 使用了一种自适应文本-图像干涉模型，其中的编码器将输入图像转换为文本形式，然后使用固定的文本-图像干涉解码器来重建输入图像。这种方法被称为 De-Diffusion。</li>
<li>results: 实验表明，De-Diffusion 可以准确地将图像转换为文本形式，并且可以让这种文本形式被Off-the-shelf text-to-image工具和大型自然语言处理器（LLMs）进行多样化的多模态任务。例如，一个 De-Diffusion 模型可以通过提供不同的文本描述来生成可重用的描述，并且在开放式视觉语言任务中达到了新的州OF-THE-ART。<details>
<summary>Abstract</summary>
We demonstrate text as a strong cross-modal interface. Rather than relying on deep embeddings to connect image and language as the interface representation, our approach represents an image as text, from which we enjoy the interpretability and flexibility inherent to natural language. We employ an autoencoder that uses a pre-trained text-to-image diffusion model for decoding. The encoder is trained to transform an input image into text, which is then fed into the fixed text-to-image diffusion decoder to reconstruct the original input -- a process we term De-Diffusion. Experiments validate both the precision and comprehensiveness of De-Diffusion text representing images, such that it can be readily ingested by off-the-shelf text-to-image tools and LLMs for diverse multi-modal tasks. For example, a single De-Diffusion model can generalize to provide transferable prompts for different text-to-image tools, and also achieves a new state of the art on open-ended vision-language tasks by simply prompting large language models with few-shot examples.
</details>
<details>
<summary>摘要</summary>
我们展示了文本作为强大的跨模态界面。而不是依靠深度嵌入来连接图像和语言作为界面表示，我们的方法将图像转换为文本，从而得到了自然语言中的可读性和灵活性。我们使用一个自适应Encoder，使用预训练的文本到图像扩散模型进行解码。解码器被训练以将输入图像转换为文本，然后将其传递给固定的文本到图像扩散解码器进行重建原始输入——一个过程我们称为“拆解”。实验证明了我们的拆解方法可以准确地表示图像，并且可以轻松地被普通的文本到图像工具和大语言模型进行多样化的多模态任务。例如，单个拆解模型可以泛化提供不同文本到图像工具的可移植提示，同时也实现了开放式视觉语言任务的新 государ录录。
</details></li>
</ul>
<hr>
<h2 id="Occluded-Person-Re-Identification-with-Deep-Learning-A-Survey-and-Perspectives"><a href="#Occluded-Person-Re-Identification-with-Deep-Learning-A-Survey-and-Perspectives" class="headerlink" title="Occluded Person Re-Identification with Deep Learning: A Survey and Perspectives"></a>Occluded Person Re-Identification with Deep Learning: A Survey and Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00603">http://arxiv.org/abs/2311.00603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enhao Ning, Changshuo Wang, Huang Zhangc, Xin Ning, Prayag Tiwari</li>
<li>for: 本研究评估了多种遮盲人识别技术，以提高人识别系统的可靠性和精度。</li>
<li>methods: 本研究使用了深度学习技术，对 occluded person Re-ID 方法进行了系统性的比较和分析，并提出了未来发展的想法。</li>
<li>results: 研究发现了一些状态级别的 occluded person Re-ID 方法，并对这些方法进行了系统性的评估和比较。<details>
<summary>Abstract</summary>
Person re-identification (Re-ID) technology plays an increasingly crucial role in intelligent surveillance systems. Widespread occlusion significantly impacts the performance of person Re-ID. Occluded person Re-ID refers to a pedestrian matching method that deals with challenges such as pedestrian information loss, noise interference, and perspective misalignment. It has garnered extensive attention from researchers. Over the past few years, several occlusion-solving person Re-ID methods have been proposed, tackling various sub-problems arising from occlusion. However, there is a lack of comprehensive studies that compare, summarize, and evaluate the potential of occluded person Re-ID methods in detail. In this review, we start by providing a detailed overview of the datasets and evaluation scheme used for occluded person Re-ID. Next, we scientifically classify and analyze existing deep learning-based occluded person Re-ID methods from various perspectives, summarizing them concisely. Furthermore, we conduct a systematic comparison among these methods, identify the state-of-the-art approaches, and present an outlook on the future development of occluded person Re-ID.
</details>
<details>
<summary>摘要</summary>
人识别（Re-ID）技术在智能监测系统中发挥越来越重要的作用。广泛的遮挡会导致人识别的性能下降。遮挡人识别指的是一种受到人员信息损失、干扰噪声和视角偏移等挑战的人识别方法。这一问题在过去几年内吸引了大量研究人员的关注。在这篇评论中，我们首先提供了遮挡人识别数据集和评价方法的详细介绍。然后，我们科学地分类和分析了现有的深度学习基于遮挡人识别方法，从多种角度进行了系统性的总结。此外，我们进行了系统性的比较，确定了状态之最佳方法，并对未来人识别领域的发展提出了一个前look。
</details></li>
</ul>
<hr>
<h2 id="PAUMER-Patch-Pausing-Transformer-for-Semantic-Segmentation"><a href="#PAUMER-Patch-Pausing-Transformer-for-Semantic-Segmentation" class="headerlink" title="PAUMER: Patch Pausing Transformer for Semantic Segmentation"></a>PAUMER: Patch Pausing Transformer for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00586">http://arxiv.org/abs/2311.00586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evann Courdier, Prabhu Teja Sivaprasad, François Fleuret</li>
<li>for: 提高图像分割器的效率，通过不同的计算量来区分不同部分的图像。</li>
<li>methods: 使用预测结果的熵作为挫止计算的标准，以实现在最终解码器之前停止计算。</li>
<li>results: 在 Cityscapes 和 ADE20K 两个标准图像分割数据集上，我们的方法可以实现约 $50%$ 的高速运行，并且对 mIoU 的下降只有 $0.65%$ 和 $4.6%$ 分别。<details>
<summary>Abstract</summary>
We study the problem of improving the efficiency of segmentation transformers by using disparate amounts of computation for different parts of the image. Our method, PAUMER, accomplishes this by pausing computation for patches that are deemed to not need any more computation before the final decoder. We use the entropy of predictions computed from intermediate activations as the pausing criterion, and find this aligns well with semantics of the image. Our method has a unique advantage that a single network trained with the proposed strategy can be effortlessly adapted at inference to various run-time requirements by modulating its pausing parameters. On two standard segmentation datasets, Cityscapes and ADE20K, we show that our method operates with about a $50\%$ higher throughput with an mIoU drop of about $0.65\%$ and $4.6\%$ respectively.
</details>
<details>
<summary>摘要</summary>
我团队研究如何通过不同的计算量来提高分割变换器的效率。我们的方法PAUMER使用停止计算的方式来实现这一点，在最终解码器之前停止计算某些patches。我们使用Intermediate activation的 entropy来决定停止计算的标准，发现它与图像 semantics 吻合得非常好。我们的方法有一个独特的优势，可以在执行时根据需要适应不同的运行时参数，只需要调整停止计算的参数即可。在Cityscapes和ADE20K两个标准分割dataset上，我们证明了我们的方法可以实现约50%的更高的throughput，并且相应的mIoU下降约0.65%和4.6%。
</details></li>
</ul>
<hr>
<h2 id="A-Robust-Deep-Learning-Method-with-Uncertainty-Estimation-for-the-Pathological-Classification-of-Renal-Cell-Carcinoma-based-on-CT-Images"><a href="#A-Robust-Deep-Learning-Method-with-Uncertainty-Estimation-for-the-Pathological-Classification-of-Renal-Cell-Carcinoma-based-on-CT-Images" class="headerlink" title="A Robust Deep Learning Method with Uncertainty Estimation for the Pathological Classification of Renal Cell Carcinoma based on CT Images"></a>A Robust Deep Learning Method with Uncertainty Estimation for the Pathological Classification of Renal Cell Carcinoma based on CT Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00567">http://arxiv.org/abs/2311.00567</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ni Yao, Hang Hu, Kaicong Chen, Chen Zhao, Yuan Guo, Boya Li, Jiaofen Nan, Yanting Li, Chuang Han, Fubao Zhu, Weihua Zhou, Li Tian</li>
<li>for: 这个研究的目的是为了使用深度学习模型来帮助医生在骨髓癌手术前进行不同类型的肾癌诊断，以提高诊断的准确性和有效性。</li>
<li>methods: 这个研究使用了5-fold横推分来运行深度学习模型，并在模型中包含不确定性估计，以提高模型的准确性和可靠性。</li>
<li>results: 研究结果显示，这个深度学习模型在5-fold横推分中的AUC值为0.868（95% CI：0.826-0.923），并在外部验证集中的AUC值为0.856（95% CI：0.838-0.882）。这表示这个模型在预后诊断肾癌不同类型的过程中表现了良好的准确性和可靠性。<details>
<summary>Abstract</summary>
Objectives To develop and validate a deep learning-based diagnostic model incorporating uncertainty estimation so as to facilitate radiologists in the preoperative differentiation of the pathological subtypes of renal cell carcinoma (RCC) based on CT images. Methods Data from 668 consecutive patients, pathologically proven RCC, were retrospectively collected from Center 1. By using five-fold cross-validation, a deep learning model incorporating uncertainty estimation was developed to classify RCC subtypes into clear cell RCC (ccRCC), papillary RCC (pRCC), and chromophobe RCC (chRCC). An external validation set of 78 patients from Center 2 further evaluated the model's performance. Results In the five-fold cross-validation, the model's area under the receiver operating characteristic curve (AUC) for the classification of ccRCC, pRCC, and chRCC was 0.868 (95% CI: 0.826-0.923), 0.846 (95% CI: 0.812-0.886), and 0.839 (95% CI: 0.802-0.88), respectively. In the external validation set, the AUCs were 0.856 (95% CI: 0.838-0.882), 0.787 (95% CI: 0.757-0.818), and 0.793 (95% CI: 0.758-0.831) for ccRCC, pRCC, and chRCC, respectively. Conclusions The developed deep learning model demonstrated robust performance in predicting the pathological subtypes of RCC, while the incorporated uncertainty emphasized the importance of understanding model confidence, which is crucial for assisting clinical decision-making for patients with renal tumors. Clinical relevance statement Our deep learning approach, integrated with uncertainty estimation, offers clinicians a dual advantage: accurate RCC subtype predictions complemented by diagnostic confidence references, promoting informed decision-making for patients with RCC.
</details>
<details>
<summary>摘要</summary>
目的：通过深度学习模型并实现uncertainty estimation，帮助放射学家在 préoperative 阶段 diferenciate 肾癌细型（RCC）的 PATHOLOGICAL 亚型，基于 CT 图像。方法：收集了 668 例 consecutive 病例数据，确诊为 RCC，从 Center 1 进行了 Retrospective 收集。通过五fold 交叉验证，我们开发了一种 incorporating uncertainty estimation 的深度学习模型，用于分类 RCC 亚型为 clear cell RCC（ccRCC）、papillary RCC（pRCC）和 chromophobe RCC（chRCC）。外验证集中心 2 中的 78 例病例进一步评估了模型的性能。结果：在五fold 交叉验证中，模型的 Receiver Operating Characteristic Curve（AUC）为 ccRCC、pRCC 和 chRCC 的分类为 0.868（95% CI：0.826-0.923）、0.846（95% CI：0.812-0.886）和 0.839（95% CI：0.802-0.88），分别。在外验证集中，AUCs 为 0.856（95% CI：0.838-0.882）、0.787（95% CI：0.757-0.818）和 0.793（95% CI：0.758-0.831）。结论：我们开发的深度学习模型在预测 RCC 亚型方面表现了robust，同时 incorporated uncertainty 强调了理解模型confidence的重要性，这对于帮助诊断肾肿瘤病人具有重要的价值。临床实践意义：我们的深度学习方法，integrated with uncertainty estimation，为放射学家提供了 dual advantage：准确地预测 RCC 亚型，同时提供了诊断 confidence 参考，为肾肿瘤病人提供了 informed decision-making。
</details></li>
</ul>
<hr>
<h2 id="CROMA-Remote-Sensing-Representations-with-Contrastive-Radar-Optical-Masked-Autoencoders"><a href="#CROMA-Remote-Sensing-Representations-with-Contrastive-Radar-Optical-Masked-Autoencoders" class="headerlink" title="CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders"></a>CROMA: Remote Sensing Representations with Contrastive Radar-Optical Masked Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00566">http://arxiv.org/abs/2311.00566</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/antofuller/croma">https://github.com/antofuller/croma</a></li>
<li>paper_authors: Anthony Fuller, Koreen Millard, James R. Green</li>
<li>for: 这个研究旨在开发一个基于自类超级学习的框架，以 learns rich unimodal和多modal表现。</li>
<li>methods: 这个框架 combine了对比和重建自我超级学习目标，分别将陌生 multispectral 和 Synthetic Aperture Radar 标本处理为 masked-out 状态，并在空间和时间Alignment的情况下进行 Cross-modal contrastive learning。</li>
<li>results: 这个框架可以实现高效地 extrapolate 到大型测试影像（最大17.6倍），并且在四个分类 bencmark 上进行评估，包括 fine-tuning、线性和非线性 probing、kNN 分类和 K-means 对应。<details>
<summary>Abstract</summary>
A vital and rapidly growing application, remote sensing offers vast yet sparsely labeled, spatially aligned multimodal data; this makes self-supervised learning algorithms invaluable. We present CROMA: a framework that combines contrastive and reconstruction self-supervised objectives to learn rich unimodal and multimodal representations. Our method separately encodes masked-out multispectral optical and synthetic aperture radar samples -- aligned in space and time -- and performs cross-modal contrastive learning. Another encoder fuses these sensors, producing joint multimodal encodings that are used to predict the masked patches via a lightweight decoder. We show that these objectives are complementary when leveraged on spatially aligned multimodal data. We also introduce X- and 2D-ALiBi, which spatially biases our cross- and self-attention matrices. These strategies improve representations and allow our models to effectively extrapolate to images up to 17.6x larger at test-time. CROMA outperforms the current SoTA multispectral model, evaluated on: four classification benchmarks -- finetuning (avg. 1.8%), linear (avg. 2.4%) and nonlinear (avg. 1.4%) probing, kNN classification (avg. 3.5%), and K-means clustering (avg. 8.4%); and three segmentation benchmarks (avg. 6.4%). CROMA's rich, optionally multimodal representations can be widely leveraged across remote sensing applications.
</details>
<details>
<summary>摘要</summary>
一个非常重要和快速发展的应用程序，远程感知提供了庞大但罕见标注的、空间对齐的多模态数据，这使得无监督学习算法成为了非常重要的。我们提出了 CROMA 框架，该框架将对比和重建自我监督目标结合在一起，以学习丰富的单模态和多模态表示。我们在 espacio 和时间方面对多普通频谱光学和Synthetic Aperture Radar 样本进行了隐藏masking，然后通过对各个感知器进行交叉模式对比学习来学习单模态和多模态表示。另一个Encoder 将这些感知器进行融合，生成了联合多模态编码，并使用轻量级解码器来预测隐藏的补充。我们表明了这些目标之间的对比性，并引入了 X-和2D-ALiBi 的空间偏好矩阵，以提高表示和使模型能够在测试时 extrapolate 到大小为 17.6 倍的图像。CROMA 在四个分类标准 bencmarks 上取得了 SoTA 的最佳成绩，包括：四个分类 benchmarks 的 fine-tuning （平均 1.8%）、直接学习（平均 2.4%）和非直接学习（平均 1.4%） probing、kNN 分类（平均 3.5%）和 K-means 归一化（平均 8.4%）。此外，CROMA 在三个分割标准 bencmarks 上取得了平均 6.4% 的成绩。CROMA 的丰富、可选的多模态表示可以广泛应用于远程感知领域。
</details></li>
</ul>
<hr>
<h2 id="MNN-Mixed-Nearest-Neighbors-for-Self-Supervised-Learning"><a href="#MNN-Mixed-Nearest-Neighbors-for-Self-Supervised-Learning" class="headerlink" title="MNN: Mixed Nearest-Neighbors for Self-Supervised Learning"></a>MNN: Mixed Nearest-Neighbors for Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00562">http://arxiv.org/abs/2311.00562</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pc-cp/mnn">https://github.com/pc-cp/mnn</a></li>
<li>paper_authors: Chen Peng, Xianzhong Long, Yun Li</li>
<li>for: 提高自动学习中的自我超视标注的性能和训练效率</li>
<li>methods: 基于权重融合和图像混合操作的简单自我超视标注框架Mixed Nearest-Neighbors for Self-Supervised Learning (MNN)</li>
<li>results: 在四个标准数据集上表现出色的泛化性和训练效率<details>
<summary>Abstract</summary>
In contrastive self-supervised learning, positive samples are typically drawn from the same image but in different augmented views, resulting in a relatively limited source of positive samples. An effective way to alleviate this problem is to incorporate the relationship between samples, which involves including the top-k nearest neighbors of positive samples in the framework. However, the problem of false neighbors (i.e., neighbors that do not belong to the same category as the positive sample) is an objective but often overlooked challenge due to the query of neighbor samples without human supervision. In this paper, we present a simple Self-supervised learning framework called Mixed Nearest-Neighbors for Self-Supervised Learning (MNN). MNN optimizes the influence of neighbor samples on the semantics of positive samples through an intuitive weighting approach and image mixture operations. The results of our study demonstrate that MNN exhibits exceptional generalization performance and training efficiency on four benchmark datasets.
</details>
<details>
<summary>摘要</summary>
contrastive self-supervised learning中，正样本通常来自同一幅图像，但在不同的扩展视图中，导致正样本的数量相对受限。一种有效的解决方法是利用样本之间的关系，这包括将正样本的top-k最近邻居包含在框架中。然而，false neighbors（即不属于正样本类别的邻居）是一个目标，但通常被忽略的挑战，因为查询邻居样本没有人工监督。在本文中，我们提出了一种简单的自动学习框架，名为混合最近邻居自我超vised学习（MNN）。MNN通过对正样本的语义优化邻居样本的影响，使用直观的权重方法和图像混合操作。我们的研究结果表明，MNN在四个标准 benchmark dataset上展现出了非常出色的泛化性和训练效率。
</details></li>
</ul>
<hr>
<h2 id="ProBio-A-Protocol-guided-Multimodal-Dataset-for-Molecular-Biology-Lab"><a href="#ProBio-A-Protocol-guided-Multimodal-Dataset-for-Molecular-Biology-Lab" class="headerlink" title="ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab"></a>ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00556">http://arxiv.org/abs/2311.00556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jieming Cui, Ziren Gong, Baoxiong Jia, Siyuan Huang, Zilong Zheng, Jianzhu Ma, Yixin Zhu</li>
<li>for: 解决分子生物领域中复制研究结果的困难</li>
<li>methods: 使用现代智能系统进行研究，并在 BioLab  settings 中进行 activity understanding 研究</li>
<li>results: 提供了一个完整的多模态数据集（ProBio）和两个挑战性的标准（透明解决方案跟踪和多模态行为识别），以便研究现代 AI 技术在分子生物领域的应用。<details>
<summary>Abstract</summary>
The challenge of replicating research results has posed a significant impediment to the field of molecular biology. The advent of modern intelligent systems has led to notable progress in various domains. Consequently, we embarked on an investigation of intelligent monitoring systems as a means of tackling the issue of the reproducibility crisis. Specifically, we first curate a comprehensive multimodal dataset, named ProBio, as an initial step towards this objective. This dataset comprises fine-grained hierarchical annotations intended for the purpose of studying activity understanding in BioLab. Next, we devise two challenging benchmarks, transparent solution tracking and multimodal action recognition, to emphasize the unique characteristics and difficulties associated with activity understanding in BioLab settings. Finally, we provide a thorough experimental evaluation of contemporary video understanding models and highlight their limitations in this specialized domain to identify potential avenues for future research. We hope ProBio with associated benchmarks may garner increased focus on modern AI techniques in the realm of molecular biology.
</details>
<details>
<summary>摘要</summary>
科学研究复现困难问题在分子生物学领域内存着重要的阻碍。现代智能系统的出现在不同领域中带来了显著的进步，因此我们决定通过研究智能监测系统来解决复现危机。我们首先筹集了一个全面的多Modal数据集，名为ProBio，作为这个目标的初步步骤。这个数据集包括细化的层次标注，用于研究 BioLab 中活动理解的目的。然后，我们设计了两个具有挑战性的标准，透明解决方案跟踪和多Modal动作认知，以强调 BioLab 中活动理解的特殊特征和挑战。最后，我们进行了详细的实验评估当今视频理解模型，并指出其在这个特殊领域的限制，以便未来研究的可能性。我们希望 ProBio 和相关的标准可以吸引更多关注现代AI技术在分子生物学领域的应用。
</details></li>
</ul>
<hr>
<h2 id="Continual-atlas-based-segmentation-of-prostate-MRI"><a href="#Continual-atlas-based-segmentation-of-prostate-MRI" class="headerlink" title="Continual atlas-based segmentation of prostate MRI"></a>Continual atlas-based segmentation of prostate MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00548">http://arxiv.org/abs/2311.00548</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meclabtuda/atlas-replay">https://github.com/meclabtuda/atlas-replay</a></li>
<li>paper_authors: Amin Ranem, Camila González, Daniel Pinto dos Santos, Andreas Michael Bucher, Ahmed Ezzat Othman, Anirban Mukhopadhyay</li>
<li>for: 这篇论文是为了解决自然图像分类中的持续学习（Continual Learning，CL）方法对医疗图像分类的问题。</li>
<li>methods: 这篇论文使用了 atlas-based segmentation 方法，利用对区域 инте点的domain knowledge，实现了semantically coherent的预测。此外，这篇论文还使用了隐私保护的 prototype，以确保模型不会受到训练分布的影响。</li>
<li>results: 这篇论文的结果显示，Atlas Replay 方法可以在七个公开的 проstate segmentation 数据集上提供高品质的分类mask，并且能够在不同的训练分布下保持知识。此外，Atlas Replay 方法还能够对 yet-unseen 领域进行Robust 的预测，而不是end-to-end segmentation 方法。<details>
<summary>Abstract</summary>
Continual learning (CL) methods designed for natural image classification often fail to reach basic quality standards for medical image segmentation. Atlas-based segmentation, a well-established approach in medical imaging, incorporates domain knowledge on the region of interest, leading to semantically coherent predictions. This is especially promising for CL, as it allows us to leverage structural information and strike an optimal balance between model rigidity and plasticity over time. When combined with privacy-preserving prototypes, this process offers the advantages of rehearsal-based CL without compromising patient privacy. We propose Atlas Replay, an atlas-based segmentation approach that uses prototypes to generate high-quality segmentation masks through image registration that maintain consistency even as the training distribution changes. We explore how our proposed method performs compared to state-of-the-art CL methods in terms of knowledge transferability across seven publicly available prostate segmentation datasets. Prostate segmentation plays a vital role in diagnosing prostate cancer, however, it poses challenges due to substantial anatomical variations, benign structural differences in older age groups, and fluctuating acquisition parameters. Our results show that Atlas Replay is both robust and generalizes well to yet-unseen domains while being able to maintain knowledge, unlike end-to-end segmentation methods. Our code base is available under https://github.com/MECLabTUDA/Atlas-Replay.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Cardiovascular-Disease-Prediction-Through-Comparative-Analysis-of-Machine-Learning-Models-A-Case-Study-on-Myocardial-Infarction"><a href="#Improving-Cardiovascular-Disease-Prediction-Through-Comparative-Analysis-of-Machine-Learning-Models-A-Case-Study-on-Myocardial-Infarction" class="headerlink" title="Improving Cardiovascular Disease Prediction Through Comparative Analysis of Machine Learning Models: A Case Study on Myocardial Infarction"></a>Improving Cardiovascular Disease Prediction Through Comparative Analysis of Machine Learning Models: A Case Study on Myocardial Infarction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00517">http://arxiv.org/abs/2311.00517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonayet Miah, Duc M Ca, Md Abu Sayed, Ehsanur Rashid Lipu, Fuad Mahmud, S M Yasir Arafat<br>for: 这个研究旨在预测心肺病，即医学研究中的一项挑战。methods: 这个研究使用了六种不同的机器学习模型进行比较分析，包括Logistic Regression、Support Vector Machine、决策树、Bagging、XGBoost和LightGBM。results: 研究结果显示，XGBoost模型表现最佳，准确率达到92.72%。此外，Logistic Regression、Support Vector Machine和LightGBM模型也达到了 relativamente高的准确率。这些结果表明，通过采用高级机器学习技术，可以提高心肺病预测的精度。<details>
<summary>Abstract</summary>
Cardiovascular disease remains a leading cause of mortality in the contemporary world. Its association with smoking, elevated blood pressure, and cholesterol levels underscores the significance of these risk factors. This study addresses the challenge of predicting myocardial illness, a formidable task in medical research. Accurate predictions are pivotal for refining healthcare strategies. This investigation conducts a comparative analysis of six distinct machine learning models: Logistic Regression, Support Vector Machine, Decision Tree, Bagging, XGBoost, and LightGBM. The attained outcomes exhibit promise, with accuracy rates as follows: Logistic Regression (81.00%), Support Vector Machine (75.01%), XGBoost (92.72%), LightGBM (90.60%), Decision Tree (82.30%), and Bagging (83.01%). Notably, XGBoost emerges as the top-performing model. These findings underscore its potential to enhance predictive precision for coronary infarction. As the prevalence of cardiovascular risk factors persists, incorporating advanced machine learning techniques holds the potential to refine proactive medical interventions.
</details>
<details>
<summary>摘要</summary>
心血管疾病仍然是当今世界上主要的死亡原因之一。它与吸烟、高血压和凝血水平的关系，表明了这些风险因素的重要性。这项研究面临着预测心肌疾病的挑战，这是医学研究中的一项困难任务。准确的预测是医疗战略的重要组成部分。这个研究对六种不同的机器学习模型进行了比较分析：Logistic Regression、Support Vector Machine、决策树、Bagging、XGBoost和LightGBM。所获得的结果展示了批处的批处，准确率如下：Logistic Regression（81.00%）、Support Vector Machine（75.01%）、XGBoost（92.72%）、LightGBM（90.60%）、决策树（82.30%）和Bagging（83.01%）。值得注意的是，XGBoost在这些模型中表现出色，这表明它在预测心肌疾病方面的潜在能力。随着卡路дии血管风险因素的存在，利用高级机器学习技术可能会更加细化的预测和投入措施。
</details></li>
</ul>
<hr>
<h2 id="Deep-Neural-Networks-for-Automatic-Speaker-Recognition-Do-Not-Learn-Supra-Segmental-Temporal-Features"><a href="#Deep-Neural-Networks-for-Automatic-Speaker-Recognition-Do-Not-Learn-Supra-Segmental-Temporal-Features" class="headerlink" title="Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features"></a>Deep Neural Networks for Automatic Speaker Recognition Do Not Learn Supra-Segmental Temporal Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00489">http://arxiv.org/abs/2311.00489</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Neururer, Volker Dellwo, Thilo Stadelmann</li>
<li>for: 本研究旨在探讨深度神经网络在自动人识唱任务中的成功原因，以及它们是如何模型各种特征的。</li>
<li>methods: 本研究使用了一种新的测试方法，用于评估现有的状态对 speaker recognition 的性能是否受到各种特征的影响。同时，研究还提出了一些使得网络更加注重各种特征的方法，并评估了它们的效果。</li>
<li>results: 研究发现，现有的 CNN 和 RNN 网络 Architecture 对 speaker recognition 并不充分模型各种特征，即使被迫了。这些结果为未来更好地利用语音信号和深度学习的研究提供了一个高度相关的基础，同时也提供了对这些网络的解释性的深入了解。<details>
<summary>Abstract</summary>
While deep neural networks have shown impressive results in automatic speaker recognition and related tasks, it is dissatisfactory how little is understood about what exactly is responsible for these results. Part of the success has been attributed in prior work to their capability to model supra-segmental temporal information (SST), i.e., learn rhythmic-prosodic characteristics of speech in addition to spectral features. In this paper, we (i) present and apply a novel test to quantify to what extent the performance of state-of-the-art neural networks for speaker recognition can be explained by modeling SST; and (ii) present several means to force respective nets to focus more on SST and evaluate their merits. We find that a variety of CNN- and RNN-based neural network architectures for speaker recognition do not model SST to any sufficient degree, even when forced. The results provide a highly relevant basis for impactful future research into better exploitation of the full speech signal and give insights into the inner workings of such networks, enhancing explainability of deep learning for speech technologies.
</details>
<details>
<summary>摘要</summary>
深度神经网络在自动识别人谱和相关任务中表现出色，但是currently little is understood about what exactly is responsible for these results. Prior work has attributed some of the success to their ability to model supra-segmental temporal information (SST), i.e., learn the rhythmic and prosodic characteristics of speech in addition to spectral features. In this paper, we (i) present and apply a novel test to quantify the extent to which the performance of state-of-the-art neural networks for speaker recognition can be explained by modeling SST; and (ii) present several means to force these networks to focus more on SST and evaluate their merits. We find that a variety of CNN- and RNN-based neural network architectures for speaker recognition do not model SST to a sufficient degree, even when forced. The results provide a highly relevant basis for impactful future research into better exploitation of the full speech signal and give insights into the inner workings of such networks, enhancing explainability of deep learning for speech technologies.Here's the translation in Traditional Chinese as well:深度神经网络在自动识别人谱和相关任务中表现出色，但目前对其成功的根本原因所知甚少。 Prior work将一部分成功归功于它们能够模型超 Segmental temporal information (SST)，即学习语音的几何和声振特征。在这篇论文中，我们（i）提出和应用一个新的测试来评估现代神经网络对人识别的表现是否可以被归因于模型SST; 以及（ii）提出了让这些网络更加专注于SST的多种方法，并评估其效果。我们发现现代CNN和RNN基于神经网络架构的对人识别表现并不充分靠拢SST，甚至在强制性下也不会。结果提供了深刻的基础 для未来对整个语音信号的更好利用，并对神经网络内部的运作给出了更多的解释，对于语音科技的深度学习提供了新的思路。
</details></li>
</ul>
<hr>
<h2 id="DEFN-Dual-Encoder-Fourier-Group-Harmonics-Network-for-Three-Dimensional-Macular-Hole-Reconstruction-with-Stochastic-Retinal-Defect-Augmentation-and-Dynamic-Weight-Composition"><a href="#DEFN-Dual-Encoder-Fourier-Group-Harmonics-Network-for-Three-Dimensional-Macular-Hole-Reconstruction-with-Stochastic-Retinal-Defect-Augmentation-and-Dynamic-Weight-Composition" class="headerlink" title="DEFN: Dual-Encoder Fourier Group Harmonics Network for Three-Dimensional Macular Hole Reconstruction with Stochastic Retinal Defect Augmentation and Dynamic Weight Composition"></a>DEFN: Dual-Encoder Fourier Group Harmonics Network for Three-Dimensional Macular Hole Reconstruction with Stochastic Retinal Defect Augmentation and Dynamic Weight Composition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00483">http://arxiv.org/abs/2311.00483</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iipl-hangzhoudianziuniversity/defn-pytorch">https://github.com/iipl-hangzhoudianziuniversity/defn-pytorch</a></li>
<li>paper_authors: Xingru Huang, Yihao Guo, Jian Huang, Zhi Li, Tianyun Zhang, Kunyan Cai, Gaopeng Huang, Wenhao Chen, Zhaoyang Xu, Liangqiong Qu, Ji Hu, Tinyu Wang, Shaowei Jiang, Chenggang Yan, Yaoqi Sun, Xin Ye, Yaqi Wang</li>
<li>for: 这个论文的目的是提供一种基于深度学习的三维重建方法，以帮助诊断和治疗棘狭血管病变。</li>
<li>methods: 该论文使用了一种名为DEFN的三维 segmentation网络，该网络包括三个创新模块：Fourier Group Harmonics（FuGH）、Simplified 3D Spatial Attention（S3DSA）和Harmonic Squeeze-and-Excitation Module（HSE）。此外，该论文还提出了一种新的数据增强方法 named Stochastic Retinal Defect Injection（SRDI）和一种网络优化策略 named DynamicWeightCompose（DWC）。</li>
<li>results: 相比13个基线方法，DEFN表现最佳，并可以提供高精度的三维retinal重建和量化指标，为ophthalmologists提供革命性的诊断和治疗决策工具，对棘狭血管病变的诊断和治疗具有启示性的影响。<details>
<summary>Abstract</summary>
The spatial and quantitative parameters of macular holes are vital for diagnosis, surgical choices, and post-op monitoring. Macular hole diagnosis and treatment rely heavily on spatial and quantitative data, yet the scarcity of such data has impeded the progress of deep learning techniques for effective segmentation and real-time 3D reconstruction. To address this challenge, we assembled the world's largest macular hole dataset, Retinal OCTfor Macular Hole Enhancement (ROME-3914), and a Comprehensive Archive for Retinal Segmentation (CARS-30k), both expertly annotated. In addition, we developed an innovative 3D segmentation network, the Dual-Encoder FuGH Network (DEFN), which integrates three innovative modules: Fourier Group Harmonics (FuGH), Simplified 3D Spatial Attention (S3DSA) and Harmonic Squeeze-and-Excitation Module (HSE). These three modules synergistically filter noise, reduce computational complexity, emphasize detailed features, and enhance the network's representation ability. We also proposed a novel data augmentation method, Stochastic Retinal Defect Injection (SRDI), and a network optimization strategy DynamicWeightCompose (DWC), to further improve the performance of DEFN. Compared with 13 baselines, our DEFN shows the best performance. We also offer precise 3D retinal reconstruction and quantitative metrics, bringing revolutionary diagnostic and therapeutic decision-making tools for ophthalmologists, and is expected to completely reshape the diagnosis and treatment patterns of difficult-to-treat macular degeneration. The source code is publicly available at: https://github.com/IIPL-HangzhouDianUniversity/DEFN-Pytorch.
</details>
<details>
<summary>摘要</summary>
“ macular hole 的空间和量化参数非常重要 для诊断、手术选择以及后期监测。然而，这些数据的缺乏使得深度学习技术的应用在macular hole 的准确分割和实时3D重建方面受到了阻碍。为解决这个挑战，我们组建了全球最大的macular hole数据集，Retinal OCT for Macular Hole Enhancement (ROME-3914)，以及一个丰富的Retinal Segmentation Archive (CARS-30k)，均有专业的注释。此外，我们开发了一种创新的3D分割网络，双核Encoder FuGH网络 (DEFN)，该网络包括三个创新模块： fourier group harmonics (FuGH)、简化3D空间注意力 (S3DSA) 和响应式压缩模块 (HSE)。这三个模块紧密协作，减少噪声、降低计算复杂度、强调细节特征、提高网络的表征能力。我们还提出了一种新的数据增强方法，随机retinal defect injection (SRDI)，以及一种网络优化策略，动态 веса组合 (DWC)，以进一步提高 DEFN 的性能。与13个基线相比，我们的 DEFN 表现最佳。此外，我们还提供了高精度的3D retinal重建和量化指标，为各位眼科医生提供革命性的诊断和治疗决策工具，并预计将完全重塑difficult-to-treat macular degeneration 的诊断和治疗模式。数据集源代码可以在以下链接获取：https://github.com/IIPL-HangzhouDianUniversity/DEFN-Pytorch。”
</details></li>
</ul>
<hr>
<h2 id="Group-Distributionally-Robust-Knowledge-Distillation"><a href="#Group-Distributionally-Robust-Knowledge-Distillation" class="headerlink" title="Group Distributionally Robust Knowledge Distillation"></a>Group Distributionally Robust Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00476">http://arxiv.org/abs/2311.00476</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konstantinos Vilouras, Xiao Liu, Pedro Sanchez, Alison Q. O’Neil, Sotirios A. Tsaftaris</li>
<li>for: 这篇论文旨在解决专业医疗影像分析中的sub-population shift问题，即训练模型在不同医院或扫描机上取得的数据不寻常的情况。</li>
<li>methods: 本文提出了一种分布式Robust optimization（DRO）技术，即集合权重更新方法，以解决在训练过程中的各组别损失问题。</li>
<li>results: 本文透过实验 validate了我们的方法，GroupDistil，在两个 benchmark 数据集（自然图像和心脏MRI）上，以提高worst-group accuracy。<details>
<summary>Abstract</summary>
Knowledge distillation enables fast and effective transfer of features learned from a bigger model to a smaller one. However, distillation objectives are susceptible to sub-population shifts, a common scenario in medical imaging analysis which refers to groups/domains of data that are underrepresented in the training set. For instance, training models on health data acquired from multiple scanners or hospitals can yield subpar performance for minority groups. In this paper, inspired by distributionally robust optimization (DRO) techniques, we address this shortcoming by proposing a group-aware distillation loss. During optimization, a set of weights is updated based on the per-group losses at a given iteration. This way, our method can dynamically focus on groups that have low performance during training. We empirically validate our method, GroupDistil on two benchmark datasets (natural images and cardiac MRIs) and show consistent improvement in terms of worst-group accuracy.
</details>
<details>
<summary>摘要</summary>
知识填充可以快速和有效地将大型模型中学习的特征传递到小型模型中。然而，液态目标函数容易受到次群体变化的影响，这是医学图像分析中常见的问题，即训练数据中具有少量表达的组/领域。例如，通过多个扫描仪或医院获得的健康数据训练模型可能会导致少数群体的性能下降。在这篇论文中，我们 inspirited by distributionally robust optimization（DRO）技术，提出了一种群体意识的填充损失函数。在优化过程中，一组参数会根据每个组的损失值进行更新。这样，我们的方法可以在训练过程中动态地关注表现不佳的组。我们在两个标准 benchmark 数据集（自然图像和心脏 MR）上进行了实验，并显示了适用于最差组的精度。
</details></li>
</ul>
<hr>
<h2 id="PET-Tracer-Conversion-among-Brain-PET-via-Variable-Augmented-Invertible-Network"><a href="#PET-Tracer-Conversion-among-Brain-PET-via-Variable-Augmented-Invertible-Network" class="headerlink" title="PET Tracer Conversion among Brain PET via Variable Augmented Invertible Network"></a>PET Tracer Conversion among Brain PET via Variable Augmented Invertible Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00735">http://arxiv.org/abs/2311.00735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bohui Shen, Wei Zhang, Xubiao Liu, Pengfei Yu, Shirui Jiang, Xinchong Shi, Xiangsong Zhang, Xiaoyu Zhou, Weirui Zhang, Bingxuan Li, Qiegen Liu</li>
<li>for: 用于诊断脑病和脑科研究</li>
<li>methods: 使用深度学习的追踪转换神经网络（TC-INN）将FDG图像映射到DOPA图像上</li>
<li>results: 实现了FDG图像与DOPA图像之间的图像映射，获得了更多的诊断信息<details>
<summary>Abstract</summary>
Positron emission tomography (PET), as an imaging technique with high biochemical sensitivity, has been widely used in diagnosis of encephalopathy and brain science research used in brain disease diagnosis and brain science research. Since different tracers present different effects on the same focal area, the choice of tracers is getting more significant for PET imaging. Nowadays, with the wide application of PET imaging in neuropsychiatric treatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine (DOPA) has been found to be more effective than 18F-labeled fluorine-2-deoxyglucose (FDG) in this field. However, due to the complexity of its preparation and other limitations, DOPA is far less widely used than FDG. To address this issue, a tracer conversion invertible neural network (TC-INN) for image projection is developed to map FDG images to DOPA images through deep learning. More diagnostic information is obtained by generating PET images from FDG to DOPA. Specifically, the proposed TC-INN consists of two separate phases, one for training the traceable data, the other for re-building the new data. The reference DOPA PET image is used as the learning target for the corresponding network during the training process of tracer conversion. Mean-while, the invertible network iteratively estimates the resultant DOPA PET data and compares it to the reference DOPA PET data. Notably, the reversible model employed variable enhancement techniques to achieve better power generation. Moreover, image registration needs to be performed before training due to the angular deviation of the acquired FDG and DOPA data information. Experimental results show generative ability in mapping be-tween FDG images and DOPA images. It demonstrates great potential for PET image conversion in the case of limited tracer applications.
</details>
<details>
<summary>摘要</summary>
Positron emission tomography (PET) 技术，因其高度的生物化敏感度，在脑病诊断和脑科研究中广泛应用。由于不同的追踪物在同一个点上有不同的效果，因此选择追踪物的选择变得更加重要。目前，随着PET成像在神经精神疾病治疗中的广泛应用，6-18F-fluoro-3,4-二氢苯乙酸（DOPA）在这个领域被发现比18F-标记的氟德氧糖（FDG）更有效。然而，由于DOPA的制备复杂和其他限制，它在实际应用中远远不如FDG广泛应用。为解决这个问题，我们开发了一种tc-inn（追踪转换深度学习网络），用于将FDG成像映射到DOPA成像上。通过深度学习，我们可以从FDG成像中获得更多的诊断信息。特别是，tc-inn包括两个不同阶段：一个用于训练追踪数据，另一个用于重新构建新数据。参考DOPA PET成像作为学习目标，tc-inn在训练过程中使用深度学习来转化FDG成像为DOPA成像。同时，tc-inn还使用可变增强技术来提高能量生成。此外，由于FDG和DOPA数据信息的angular偏移，需要在训练前进行图像 региSTR，以保证模型的准确性。实验结果表明，tc-inn可以有效地将FDG成像映射到DOPA成像上。这表明tc-inn在追踪物应用有限时具有潜在的潜力。
</details></li>
</ul>
<hr>
<h2 id="Single-view-3D-Scene-Reconstruction-with-High-fidelity-Shape-and-Texture"><a href="#Single-view-3D-Scene-Reconstruction-with-High-fidelity-Shape-and-Texture" class="headerlink" title="Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture"></a>Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00457">http://arxiv.org/abs/2311.00457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DaLi-Jack/SSR-code">https://github.com/DaLi-Jack/SSR-code</a></li>
<li>paper_authors: Yixin Chen, Junfeng Ni, Nan Jiang, Yaowei Zhang, Yixin Zhu, Siyuan Huang</li>
<li>for: 本研究旨在提高单视图像中的场景重建细节，以提高场景理解和3D场景编辑等应用。</li>
<li>methods: 该方法基于单视神经隐式形状和颜色场景场景（SSR）表示，利用了explicit 3D形状超级视图和volume rendering来恢复高精度的 объек形和表面质感。</li>
<li>results: 该方法可以提高对象的细节重建率，并且可以在不同的视图角度下渲染图像。此外，该方法还可以组合对象水平的表示，以实现场景的整体理解和3D场景编辑等应用。<details>
<summary>Abstract</summary>
Reconstructing detailed 3D scenes from single-view images remains a challenging task due to limitations in existing approaches, which primarily focus on geometric shape recovery, overlooking object appearances and fine shape details. To address these challenges, we propose a novel framework for simultaneous high-fidelity recovery of object shapes and textures from single-view images. Our approach utilizes the proposed Single-view neural implicit Shape and Radiance field (SSR) representations to leverage both explicit 3D shape supervision and volume rendering of color, depth, and surface normal images. To overcome shape-appearance ambiguity under partial observations, we introduce a two-stage learning curriculum incorporating both 3D and 2D supervisions. A distinctive feature of our framework is its ability to generate fine-grained textured meshes while seamlessly integrating rendering capabilities into the single-view 3D reconstruction model. This integration enables not only improved textured 3D object reconstruction by 27.7% and 11.6% on the 3D-FRONT and Pix3D datasets, respectively, but also supports the rendering of images from novel viewpoints. Beyond individual objects, our approach facilitates composing object-level representations into flexible scene representations, thereby enabling applications such as holistic scene understanding and 3D scene editing. We conduct extensive experiments to demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统方法有限，单视图图像 reconstruction 仍然是一个挑战，主要集中于几何形状回归，忽略物体外观和细节形状。为解决这些挑战，我们提出了一种新的框架，可同时高精度地恢复物体形状和текстура从单视图图像。我们的方法利用我们提出的单视图神经隐式形状场和颜色场（SSR）来利用Explicit 3D形状超级视图和Volume Rendering技术。为了解决形状外观不确定性，我们提出了一个两阶段学习课程，包括3D和2D超级视图。我们的框架可以生成细节rich的纹理化链 mesh，并同时将渲染功能集成到单视图3D重建模型中。这种集成不仅提高了纹理3D物体重建的精度，还支持从新视角渲染图像。我们的方法不仅可以应用于个体物体，还可以组合物体水平的表示，以实现全景场理解和3D场景编辑。我们进行了广泛的实验，以证明我们的方法的有效性。Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Progressive-Recurrent-Network-for-Shadow-Removal"><a href="#Progressive-Recurrent-Network-for-Shadow-Removal" class="headerlink" title="Progressive Recurrent Network for Shadow Removal"></a>Progressive Recurrent Network for Shadow Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00455">http://arxiv.org/abs/2311.00455</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghui Wang, Wengang Zhou, Hao Feng, Li Li, Houqiang Li</li>
<li>for:  removes shadows from images in a coarse-to-fine fashion</li>
<li>methods:  Progressive Recurrent Network (PRNet) with shadow feature extraction and progressive shadow removal</li>
<li>results:  superior performance in removing shadows compared to existing deep learning-based approaches, with 29% fewer network parameters.<details>
<summary>Abstract</summary>
Single-image shadow removal is a significant task that is still unresolved. Most existing deep learning-based approaches attempt to remove the shadow directly, which can not deal with the shadow well. To handle this issue, we consider removing the shadow in a coarse-to-fine fashion and propose a simple but effective Progressive Recurrent Network (PRNet). The network aims to remove the shadow progressively, enabing us to flexibly adjust the number of iterations to strike a balance between performance and time. Our network comprises two parts: shadow feature extraction and progressive shadow removal. Specifically, the first part is a shallow ResNet which constructs the representations of the input shadow image on its original size, preventing the loss of high-frequency details caused by the downsampling operation. The second part has two critical components: the re-integration module and the update module. The proposed re-integration module can fully use the outputs of the previous iteration, providing input for the update module for further shadow removal. In this way, the proposed PRNet makes the whole process more concise and only uses 29% network parameters than the best published method. Extensive experiments on the three benchmarks, ISTD, ISTD+, and SRD, demonstrate that our method can effectively remove shadows and achieve superior performance.
</details>
<details>
<summary>摘要</summary>
单图阴影除除是一项仍未解决的重要任务。现有的深度学习基本方法都是直接除阴影，这会导致阴影处理不够好。为了解决这个问题，我们提出了一种分解阴影的方法，并提出了一种简单 yet effective的进程回归网络（PRNet）。该网络的目标是逐步除阴影，以便根据需要调整迭代次数，以达到性能和时间之间的平衡。我们的网络包括两部分：阴影特征提取和进程阴影除法。特别是，第一部分是一个浅层ResNet，可以在输入阴影图像的原始大小上构建阴影图像的表示，避免由下采样操作导致的高频率细节丢失。第二部分包括两个关键组件：重新集成模块和更新模块。我们提出的重新集成模块可以全面使用上一轮的输出，提供更新模块的输入，从而实现更好的阴影除法。这样，我们的PRNet可以让整个过程更简洁，仅使用29%的网络参数，比最佳发布方法少。广泛的实验表明，我们的方法可以有效地除阴影，并达到高性能。
</details></li>
</ul>
<hr>
<h2 id="CLIP-AD-A-Language-Guided-Staged-Dual-Path-Model-for-Zero-shot-Anomaly-Detection"><a href="#CLIP-AD-A-Language-Guided-Staged-Dual-Path-Model-for-Zero-shot-Anomaly-Detection" class="headerlink" title="CLIP-AD: A Language-Guided Staged Dual-Path Model for Zero-shot Anomaly Detection"></a>CLIP-AD: A Language-Guided Staged Dual-Path Model for Zero-shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00453">http://arxiv.org/abs/2311.00453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuhai Chen, Jiangning Zhang, Guanzhong Tian, Haoyang He, Wuhao Zhang, Yabiao Wang, Chengjie Wang, Yunsheng Wu, Yong Liu</li>
<li>for: 这篇论文针对零例异常检测（AD）进行研究，AD 是一个有价值但未受到充分研究的任务，它可以在测试物件没有任何参考图像时进行检测。</li>
<li>methods: 本文使用语言导向策略，提出了简单又有效的架构 CLIP-AD，利用大型感知语言模型 CLIP 的zero-shot分类能力。我们直接计算文本&#x2F;图像特征之间的相似性，但我们发现这会导致错误的预测和无关的高亮。因此，我们引入了一个阶段双轻量级模型（SDP），它可以有效地使用不同层次的特征，并通过架构和特征切除来解决这些问题。</li>
<li>results: 实验结果显示，SDP 可以在 VisA 上优于 SOTA 的表现，例如在分类&#x2F;分 segmentation F1 分数上提高 +1.0&#x2F;+1.2 分，而 SDP+ 则可以在 VisA 上提高 +1.9&#x2F;+11.7 分。<details>
<summary>Abstract</summary>
This paper considers zero-shot Anomaly Detection (AD), a valuable yet under-studied task, which performs AD without any reference images of the test objects. Specifically, we employ a language-guided strategy and propose a simple-yet-effective architecture CLIP-AD, leveraging the superior zero-shot classification capabilities of the large vision-language model CLIP. A natural idea for anomaly segmentation is to directly calculate the similarity between text/image features, but we observe opposite predictions and irrelevant highlights in the results. Inspired by the phenomena, we introduce a Staged Dual-Path model (SDP) that effectively uses features from various levels and applies architecture and feature surgery to address these issues. Furthermore, delving beyond surface phenomena, we identify the problem arising from misalignment of text/image features in the joint embedding space. Thus, we introduce a fine-tuning strategy by adding linear layers and construct an extended model SDP+, further enhancing the performance. Abundant experiments demonstrate the effectiveness of our approach, e.g., on VisA, SDP outperforms SOTA by +1.0/+1.2 in classification/segmentation F1 scores, while SDP+ achieves +1.9/+11.7 improvements.
</details>
<details>
<summary>摘要</summary>
However, we observe that directly calculating the similarity between text/image features can lead to opposite predictions and irrelevant highlights in the results. To address this issue, we introduce a Staged Dual-Path (SDP) model that effectively uses features from various levels and applies architecture and feature surgery.Furthermore, we identify the problem of misaligned text/image features in the joint embedding space as the root cause of the issues. To address this, we propose a fine-tuning strategy that involves adding linear layers and constructing an extended model called SDP+. This approach further enhances the performance of our method.The effectiveness of our approach is demonstrated through abundant experiments, where SDP outperforms state-of-the-art (SOTA) methods by +1.0/+1.2 in classification/segmentation F1 scores, while SDP+ achieves +1.9/+11.7 improvements.
</details></li>
</ul>
<hr>
<h2 id="On-Manipulating-Scene-Text-in-the-Wild-with-Diffusion-Models"><a href="#On-Manipulating-Scene-Text-in-the-Wild-with-Diffusion-Models" class="headerlink" title="On Manipulating Scene Text in the Wild with Diffusion Models"></a>On Manipulating Scene Text in the Wild with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00734">http://arxiv.org/abs/2311.00734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Santoso, Christian Simon, Williem Pao</li>
<li>for: 这篇论文是为了提出一种基于扩散模型的场景文本修改方法，以提高图像修改的精度和稳定性。</li>
<li>methods: 该方法使用了两种适应策略， namely one-shot style adaptation和文本识别导航，以使用扩散模型来替换图像中的文本。</li>
<li>results: 在多个场景文本 dataset上进行了广泛的比较和ablation study，并证明了该方法的高效性和稳定性。 更进一步，该方法可以在 Synthesize scene text  tasks 中实现高度的 Optical Character Recognition (OCR) 精度。<details>
<summary>Abstract</summary>
Diffusion models have gained attention for image editing yielding impressive results in text-to-image tasks. On the downside, one might notice that generated images of stable diffusion models suffer from deteriorated details. This pitfall impacts image editing tasks that require information preservation e.g., scene text editing. As a desired result, the model must show the capability to replace the text on the source image to the target text while preserving the details e.g., color, font size, and background. To leverage the potential of diffusion models, in this work, we introduce Diffusion-BasEd Scene Text manipulation Network so-called DBEST. Specifically, we design two adaptation strategies, namely one-shot style adaptation and text-recognition guidance. In experiments, we thoroughly assess and compare our proposed method against state-of-the-arts on various scene text datasets, then provide extensive ablation studies for each granularity to analyze our performance gain. Also, we demonstrate the effectiveness of our proposed method to synthesize scene text indicated by competitive Optical Character Recognition (OCR) accuracy. Our method achieves 94.15% and 98.12% on COCO-text and ICDAR2013 datasets for character-level evaluation.
</details>
<details>
<summary>摘要</summary>
Diffusion models 已经吸引了关注，用于图像编辑，并且在文本至图像任务中取得了出众的结果。然而，可能会注意到，Diffusion models 生成的图像中的细节会受到影响，导致图像编辑任务中的信息损失。这个问题特别影响了场景文本编辑任务，例如修改场景中的文本。为了解决这个问题，我们在这里提出了Diffusion-BasEd Scene Text manipulation Network，简称DBEST。我们设计了两种适应策略，即一次式风格适应和文本识别引导。在实验中，我们详细评估和比较我们的提议方法与当前最佳方法在不同的场景文本集合上。此外，我们还进行了每个细节水平的拓展研究，以分析我们的性能提升。此外，我们还证明了我们的提议方法可以生成高质量的场景文本，并且与高精度Optical Character Recognition (OCR)相匹配。我们的方法在 COCO-text 和 ICDAR2013 数据集上取得了94.15%和98.12%的字符级评估结果。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Traffic-Object-Detection-in-Variable-Illumination-with-RGB-Event-Fusion"><a href="#Enhancing-Traffic-Object-Detection-in-Variable-Illumination-with-RGB-Event-Fusion" class="headerlink" title="Enhancing Traffic Object Detection in Variable Illumination with RGB-Event Fusion"></a>Enhancing Traffic Object Detection in Variable Illumination with RGB-Event Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00436">http://arxiv.org/abs/2311.00436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhanwen Liu, Nan Yang, Yang Wang, Yuke Li, Xiangmo Zhao, Fei-Yue Wang</li>
<li>for: 本研究旨在提高遥感摄像头中的交通物体检测精度，并且可以在不同的照明条件下提供高效的检测结果。</li>
<li>methods: 本研究使用生物体ahnspired事件摄像头和Structure-aware Fusion Network (SFNet)，通过跨Modalities的融合来补做了图像中的信息损失，从而获得适用于不同照明条件的交通物体检测表现。</li>
<li>results: 实验结果表明，SFNet可以超越传统摄像头的视觉界限，并且在比较照明条件下比 Frame-based方法提高了8.0%的mAP50和5.9%的mAP50:95。<details>
<summary>Abstract</summary>
Traffic object detection under variable illumination is challenging due to the information loss caused by the limited dynamic range of conventional frame-based cameras. To address this issue, we introduce bio-inspired event cameras and propose a novel Structure-aware Fusion Network (SFNet) that extracts sharp and complete object structures from the event stream to compensate for the lost information in images through cross-modality fusion, enabling the network to obtain illumination-robust representations for traffic object detection. Specifically, to mitigate the sparsity or blurriness issues arising from diverse motion states of traffic objects in fixed-interval event sampling methods, we propose the Reliable Structure Generation Network (RSGNet) to generate Speed Invariant Frames (SIF), ensuring the integrity and sharpness of object structures. Next, we design a novel Adaptive Feature Complement Module (AFCM) which guides the adaptive fusion of two modality features to compensate for the information loss in the images by perceiving the global lightness distribution of the images, thereby generating illumination-robust representations. Finally, considering the lack of large-scale and high-quality annotations in the existing event-based object detection datasets, we build a DSEC-Det dataset, which consists of 53 sequences with 63,931 images and more than 208,000 labels for 8 classes. Extensive experimental results demonstrate that our proposed SFNet can overcome the perceptual boundaries of conventional cameras and outperform the frame-based method by 8.0% in mAP50 and 5.9% in mAP50:95. Our code and dataset will be available at https://github.com/YN-Yang/SFNet.
</details>
<details>
<summary>摘要</summary>
天然语言探测交通对象在不同照明条件下是挑战，因为传统的帧基本摄像机的动态范围有限，导致信息损失。为解决这问题，我们引入生物体鼓励的事件摄像机和一种新的结构意识网络（SFNet），以提取事件流中的锐利和完整的对象结构，并通过交叉模式融合，赋予网络获取不同照明条件下的对象检测表现。Specifically，我们提出了可靠结构生成网络（RSGNet），以生成速度不变的帧（SIF），以避免由交通对象不同运动状态所导致的缺失或模糊问题。然后，我们设计了一种适应性特征补充模块（AFCM），以便适应性融合两种模式特征，以补偿图像中的信息损失。最后，由于现有的事件基本对象检测数据集缺乏大规模和高质量的标注，我们建立了DSEC-Det数据集，该数据集包括53个序列，63931张图像和208178个标注，对8个类进行标注。我们的实验结果表明，我们的提出的SFNet可以超越传统摄像机的感知边界，并在MAP50和MAP50:95上比Frame-based方法高8.0%和5.9%。我们的代码和数据集将在https://github.com/YN-Yang/SFNet上提供。
</details></li>
</ul>
<hr>
<h2 id="Event-based-Background-Oriented-Schlieren"><a href="#Event-based-Background-Oriented-Schlieren" class="headerlink" title="Event-based Background-Oriented Schlieren"></a>Event-based Background-Oriented Schlieren</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00434">http://arxiv.org/abs/2311.00434</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tub-rip/event_based_bos">https://github.com/tub-rip/event_based_bos</a></li>
<li>paper_authors: Shintaro Shiba, Friedhelm Hamann, Yoshimitsu Aoki, Guillermo Gallego</li>
<li>For:  This paper is written to explore the use of event cameras for schlieren imaging, a technique used to observe the flow of transparent media such as air or water.* Methods:  The paper uses a novel technique that combines event data and frames to perceive air convection, and formulates the problem as a variational optimization problem.* Results:  The proposed method is shown to obtain on par results with existing frame-based optical flow techniques, and works under dark conditions where frame-based schlieren fails. Additionally, the method enables slow-motion analysis.Here is the information in Simplified Chinese text:* For: 这篇论文是用来探索使用事件摄像机进行斜扫图像技术，用于观察透明媒体如空气或水的流动。* Methods: 这篇论文使用了一种新的方法，将事件数据和帧数据结合起来感知空气循环，并将问题转化为一个可变优化问题。* Results: 提议的方法能够与现有的帧基于的光流计算机相比，并在黑暗条件下工作，而 frame-based 斜扫技术失败。此外，方法还可以进行慢动作分析。<details>
<summary>Abstract</summary>
Schlieren imaging is an optical technique to observe the flow of transparent media, such as air or water, without any particle seeding. However, conventional frame-based techniques require both high spatial and temporal resolution cameras, which impose bright illumination and expensive computation limitations. Event cameras offer potential advantages (high dynamic range, high temporal resolution, and data efficiency) to overcome such limitations due to their bio-inspired sensing principle. This paper presents a novel technique for perceiving air convection using events and frames by providing the first theoretical analysis that connects event data and schlieren. We formulate the problem as a variational optimization one combining the linearized event generation model with a physically-motivated parameterization that estimates the temporal derivative of the air density. The experiments with accurately aligned frame- and event camera data reveal that the proposed method enables event cameras to obtain on par results with existing frame-based optical flow techniques. Moreover, the proposed method works under dark conditions where frame-based schlieren fails, and also enables slow-motion analysis by leveraging the event camera's advantages. Our work pioneers and opens a new stack of event camera applications, as we publish the source code as well as the first schlieren dataset with high-quality frame and event data. https://github.com/tub-rip/event_based_bos
</details>
<details>
<summary>摘要</summary>
《Schlieren成像技术是一种用于观察透明媒体流动的光学技术，无需添加任何粒子杂料。然而，传统的帧基技术需要高分辨率和高时间分辨率的摄像机，这会带来严重的照明和计算限制。事件摄像机具有优势（高动态范围、高时间分辨率和数据效率），这些优势可以让我们超越传统的约束。本文提出了一种使用事件和帧来实现空气擦拂的观察方法，并提供了首次对事件数据和约束之间的连接的理论分析。我们将问题定义为一种变分优化问题，将线性化事件生成模型与物理上有理的参数化联合起来，以估计空气密度的时间导数。实验结果表明，我们提出的方法可以使事件摄像机与现有的帧基光学流动技术相当。此外，我们的方法在黑暗条件下也可以工作，并且可以利用事件摄像机的优势进行慢动作分析。我们的工作开启了新的事件摄像机应用领域，同时我们也发布了高质量帧和事件数据的首个Schlieren数据集。请参考我们的GitHub地址：https://github.com/tub-rip/event_based_bos。
</details></li>
</ul>
<hr>
<h2 id="Feature-oriented-Deep-Learning-Framework-for-Pulmonary-Cone-beam-CT-CBCT-Enhancement-with-Multi-task-Customized-Perceptual-Loss"><a href="#Feature-oriented-Deep-Learning-Framework-for-Pulmonary-Cone-beam-CT-CBCT-Enhancement-with-Multi-task-Customized-Perceptual-Loss" class="headerlink" title="Feature-oriented Deep Learning Framework for Pulmonary Cone-beam CT (CBCT) Enhancement with Multi-task Customized Perceptual Loss"></a>Feature-oriented Deep Learning Framework for Pulmonary Cone-beam CT (CBCT) Enhancement with Multi-task Customized Perceptual Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00412">http://arxiv.org/abs/2311.00412</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhujiarui42/cfp-loss">https://github.com/zhujiarui42/cfp-loss</a></li>
<li>paper_authors: Jiarui Zhu, Werxing Chen, Hongfei Sun, Shaohua Zhi, Jing Qin, Jing Cai, Ge Ren<br>for:  This paper aims to enhance the quality of cone-beam computed tomography (CBCT) images for cancer treatment planning by using a deep learning-based feature-oriented framework.methods:  The proposed framework consists of two main components: a multi-task learning feature-selection network (MTFS-Net) and a CBCT-to-CT translation network guided by feature-to-feature perceptual loss. The MTFS-Net customizes a perceptual loss function, while the CBCT-to-CT translation network uses advanced generative models such as U-Net, GAN, and CycleGAN.results:  The proposed framework can generate synthesized CT (sCT) images for the lung that have a high similarity to CT images, with an average SSIM index of 0.9869 and an average PSNR index of 39.9621. The sCT images also exhibit visually pleasing performance with effective artifacts suppression, noise reduction, and distinctive anatomical details preservation. The proposed framework outperforms state-of-the-art models for pulmonary CBCT enhancement.<details>
<summary>Abstract</summary>
Cone-beam computed tomography (CBCT) is routinely collected during image-guided radiation therapy (IGRT) to provide updated patient anatomy information for cancer treatments. However, CBCT images often suffer from streaking artifacts and noise caused by under-rate sampling projections and low-dose exposure, resulting in low clarity and information loss. While recent deep learning-based CBCT enhancement methods have shown promising results in suppressing artifacts, they have limited performance on preserving anatomical details since conventional pixel-to-pixel loss functions are incapable of describing detailed anatomy. To address this issue, we propose a novel feature-oriented deep learning framework that translates low-quality CBCT images into high-quality CT-like imaging via a multi-task customized feature-to-feature perceptual loss function. The framework comprises two main components: a multi-task learning feature-selection network(MTFS-Net) for customizing the perceptual loss function; and a CBCT-to-CT translation network guided by feature-to-feature perceptual loss, which uses advanced generative models such as U-Net, GAN and CycleGAN. Our experiments showed that the proposed framework can generate synthesized CT (sCT) images for the lung that achieved a high similarity to CT images, with an average SSIM index of 0.9869 and an average PSNR index of 39.9621. The sCT images also achieved visually pleasing performance with effective artifacts suppression, noise reduction, and distinctive anatomical details preservation. Our experiment results indicate that the proposed framework outperforms the state-of-the-art models for pulmonary CBCT enhancement. This framework holds great promise for generating high-quality anatomical imaging from CBCT that is suitable for various clinical applications.
</details>
<details>
<summary>摘要</summary>
通常情况下， cone-beam computed tomography（CBCT）在image-guided radiation therapy（IGRT）中被 Routinely collected to provide updated patient anatomy information for cancer treatments。然而， CBCT 图像经常受到弧形artefacts和噪声的影响，这些噪声和artefacts是由于低 sampling rate和低剂量暴露而导致的。虽然最近的深度学习基于 CBCT 改进方法已经显示出了良好的表现，但它们在保留 анатомиче细节方面有限的表现，因为传统的像素到像素损失函数无法描述细节的anaatomy。为解决这个问题，我们提出了一种新的 feature-oriented 深度学习框架。该框架包括两个主要组成部分：一个多任务特征选择网络（MTFS-Net），用于定制特征损失函数；以及一个CBCT 到 CT 翻译网络，通过特征与特征的损失函数来 guid。该网络使用了先进的生成模型，如 U-Net、GAN 和 CycleGAN。我们的实验结果表明，提议的框架可以生成高质量的 CT 图像，与 CT 图像的相似性平均值为 0.9869，PSNR 值平均值为 39.9621。这些synthesized CT（sCT）图像也达到了较好的视觉表现，有效地减少了噪声和artefacts，同时保留了细节的anaatomy。我们的实验结果表明，提议的框架超过了现状最佳模型，用于肺部 CBCT 改进。这种框架具有大量应用前景，可以生成高质量的 анатомиче imaging，适用于各种临床应用。
</details></li>
</ul>
<hr>
<h2 id="Open-Set-Face-Recognition-with-Maximal-Entropy-and-Objectosphere-Loss"><a href="#Open-Set-Face-Recognition-with-Maximal-Entropy-and-Objectosphere-Loss" class="headerlink" title="Open-Set Face Recognition with Maximal Entropy and Objectosphere Loss"></a>Open-Set Face Recognition with Maximal Entropy and Objectosphere Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00400">http://arxiv.org/abs/2311.00400</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Henrique Vareto, Yu Linghu, Terrance E. Boult, William Robson Schwartz, Manuel Günther</li>
<li>for: 本研究针对开放集成识别问题，即在训练和投入阶段未见过的未知个体出现在运行阶段。</li>
<li>methods: 本文提出了一种嵌入式网络，该网络可以通过额外的负面图像和特定的成本函数（如物体镜像损失和提议的最大熵损失）得到改进。</li>
<li>results: 研究人员通过使用预训练的深度神经网络（DNN）作为特征提取器，然后使用嵌入式网络来替换预训练DNN的输出层，实现了在开放集成卷积上的出色表现。<details>
<summary>Abstract</summary>
Open-set face recognition characterizes a scenario where unknown individuals, unseen during the training and enrollment stages, appear on operation time. This work concentrates on watchlists, an open-set task that is expected to operate at a low False Positive Identification Rate and generally includes only a few enrollment samples per identity. We introduce a compact adapter network that benefits from additional negative face images when combined with distinct cost functions, such as Objectosphere Loss (OS) and the proposed Maximal Entropy Loss (MEL). MEL modifies the traditional Cross-Entropy loss in favor of increasing the entropy for negative samples and attaches a penalty to known target classes in pursuance of gallery specialization. The proposed approach adopts pre-trained deep neural networks (DNNs) for face recognition as feature extractors. Then, the adapter network takes deep feature representations and acts as a substitute for the output layer of the pre-trained DNN in exchange for an agile domain adaptation. Promising results have been achieved following open-set protocols for three different datasets: LFW, IJB-C, and UCCS as well as state-of-the-art performance when supplementary negative data is properly selected to fine-tune the adapter network.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-Omni-supervised-Referring-Expression-Segmentation"><a href="#Towards-Omni-supervised-Referring-Expression-Segmentation" class="headerlink" title="Towards Omni-supervised Referring Expression Segmentation"></a>Towards Omni-supervised Referring Expression Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00397">http://arxiv.org/abs/2311.00397</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nineblu/omni-res">https://github.com/nineblu/omni-res</a></li>
<li>paper_authors: Minglang Huang, Yiyi Zhou, Gen Luo, Guannan Jiang, Weilin Zhuang, Xiaoshuai Sun</li>
<li>for: 提高 Referring Expression Segmentation (RES) 训练效率，使用不同类型的数据，如无标注数据、部分标注数据和弱标注数据，进行efficient RES 训练。</li>
<li>methods: 提出 Omni-supervised Referring Expression Segmentation (Omni-RES) 任务，使用教师学生学习方法，选择和改进高质量 Pseudo-masks，以提高 RES 性能。</li>
<li>results: 对一些 state-of-the-art RES 模型进行了广泛的实验，并证明了 Omni-RES 方法的效iveness，比如使用Only 10% 全标注数据，Omni-RES 可以帮助基本模型达到完全标注数据的性能水平，并且在半标注数据上超过半标注数据上超过 semi-supervised 方法，提高 RefCOCO 和 RefCOCO+ 的性能。<details>
<summary>Abstract</summary>
Referring Expression Segmentation (RES) is an emerging task in computer vision, which segments the target instances in images based on text descriptions. However, its development is plagued by the expensive segmentation labels. To address this issue, we propose a new learning task for RES called Omni-supervised Referring Expression Segmentation (Omni-RES), which aims to make full use of unlabeled, fully labeled and weakly labeled data, e.g., referring points or grounding boxes, for efficient RES training. To accomplish this task, we also propose a novel yet strong baseline method for Omni-RES based on the recently popular teacher-student learning, where where the weak labels are not directly transformed into supervision signals but used as a yardstick to select and refine high-quality pseudo-masks for teacher-student learning. To validate the proposed Omni-RES method, we apply it to a set of state-of-the-art RES models and conduct extensive experiments on a bunch of RES datasets. The experimental results yield the obvious merits of Omni-RES than the fully-supervised and semi-supervised training schemes. For instance, with only 10% fully labeled data, Omni-RES can help the base model achieve 100% fully supervised performance, and it also outperform the semi-supervised alternative by a large margin, e.g., +14.93% on RefCOCO and +14.95% on RefCOCO+, respectively. More importantly, Omni-RES also enable the use of large-scale vision-langauges like Visual Genome to facilitate low-cost RES training, and achieve new SOTA performance of RES, e.g., 80.66 on RefCOCO.
</details>
<details>
<summary>摘要</summary>
“参考表达分割（RES）是计算机视觉领域的一种新趋势，它基于图像中的文本描述来分割目标实例。然而，其发展受到严重的分割标签成本的限制。为解决这个问题，我们提出了一种新的学习任务，即多种指导 Referring Expression Segmentation（Omni-RES），它通过利用无标签数据、全标签数据和弱标签数据，例如引用点或权重标签，进行高效的RES训练。为实现这个任务，我们还提出了一种新的基线方法，基于最近受欢迎的教师学生学习，其中弱标签不直接转化为监督信号，而是用于选择和改进高质量的 pseudo-mask。为验证我们的 Omni-RES 方法，我们对一些状态前的 RES 模型进行了广泛的实验，并在一些 RES 数据集上进行了测试。实验结果表明，Omni-RES 方法在比 Fully-supervised 和 Semi-supervised 训练方案更有优势。例如，只有 10% 全标签数据，Omni-RES 可以帮助基础模型达到全标签性能，并且也在 Semi-supervised 方案中高于差分较大，例如 RefCOCO 和 RefCOCO+ 上的 +14.93% 和 +14.95%，分别。此外，Omni-RES 还可以使用大规模的视觉语言，如 Visual Genome，来实现低成本的 RES 训练，并实现新的 SOTA 性能，例如 RefCOCO 上的 80.66%。”
</details></li>
</ul>
<hr>
<h2 id="Fixation-based-Self-calibration-for-Eye-Tracking-in-VR-Headsets"><a href="#Fixation-based-Self-calibration-for-Eye-Tracking-in-VR-Headsets" class="headerlink" title="Fixation-based Self-calibration for Eye Tracking in VR Headsets"></a>Fixation-based Self-calibration for Eye Tracking in VR Headsets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00391">http://arxiv.org/abs/2311.00391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryusei Uramune, Sei Ikeda, Hiroki Ishizuka, Osamu Oshiro<br>for:这种研究旨在提出一种基于自由视点和对象表面上的点 fixes 的自适应均衡方法，以便在虚拟现实（VR）头戴式设备中进行眼动跟踪。methods:该方法基于视点可以自由移动以及在不同视点下 fixes 的点的分布在对象表面上的假设。首先，通过对三维场景数据进行扩展的 I-VDT 算法，检测出 fixations。然后，通过最小化 PoRs 的散度指标来优化均衡参数。results:这种方法可能可以无需显式用户均衡、图像处理或标记代理物来确定用户依赖的偏移量从视场轴到视场轴，并且在 18 名参与者在两个 VR 环境中步行时，该方法的精度为 2.1$^\circ$，与平均偏移相比明显低。这是第一种在三维环境中的自适应均衡方法，其精度低于 3$^\circ$。此外，通过修改检测 fixations 或优化优化算法可以提高方法的精度。<details>
<summary>Abstract</summary>
This study proposes a novel self-calibration method for eye tracking in a virtual reality (VR) headset. The proposed method is based on the assumptions that the user's viewpoint can freely move and that the points of regard (PoRs) from different viewpoints are distributed within a small area on an object surface during visual fixation. In the method, fixations are first detected from the time-series data of uncalibrated gaze directions using an extension of the I-VDT (velocity and dispersion threshold identification) algorithm to a three-dimensional (3D) scene. Then, the calibration parameters are optimized by minimizing the sum of a dispersion metrics of the PoRs. The proposed method can potentially identify the optimal calibration parameters representing the user-dependent offset from the optical axis to the visual axis without explicit user calibration, image processing, or marker-substitute objects. For the gaze data of 18 participants walking in two VR environments with many occlusions, the proposed method achieved an accuracy of 2.1$^\circ$, which was significantly lower than the average offset. Our method is the first self-calibration method with an average error lower than 3$^\circ$ in 3D environments. Further, the accuracy of the proposed method can be improved by up to 1.2$^\circ$ by refining the fixation detection or optimization algorithm.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这个研究提出了一种新的自适应准备方法 для视觉跟踪器在虚拟现实（VR）头戴式设备中。该方法基于用户视点可以自由移动以及不同视点下的点关注（PoR）在物体表面上分布在小区域内的假设。在该方法中，首先从未加工的时间序列数据中检测了不加工视线方向的fixation，使用了三维场景中的I-VDT（速度和杂散阈值识别）算法的扩展。然后，通过最小化点关注的杂散度矩阵来优化准备参数。该方法可能可以无需显式用户准备、图像处理或marker substitute对象来确定用户依赖的偏移量从光学轴到视觉轴。对18名参与者在两个VR环境中走动的视觉数据进行了分析，该方法的精度为2.1°，与平均偏移值有 statistically significant difference。我们的方法是3D环境中第一个自适应准备方法，其平均错误低于3°。此外，通过改进fixation检测或优化算法，可以提高该方法的精度。
</details></li>
</ul>
<hr>
<h2 id="NeuralGF-Unsupervised-Point-Normal-Estimation-by-Learning-Neural-Gradient-Function"><a href="#NeuralGF-Unsupervised-Point-Normal-Estimation-by-Learning-Neural-Gradient-Function" class="headerlink" title="NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function"></a>NeuralGF: Unsupervised Point Normal Estimation by Learning Neural Gradient Function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00389">http://arxiv.org/abs/2311.00389</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leoqli/neuralgf">https://github.com/leoqli/neuralgf</a></li>
<li>paper_authors: Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang, Yu-Shen Liu, Zhizhong Han</li>
<li>for: 本研究旨在提出一种能够直接从点云数据中提取方向法的深度学习方法，而无需使用地面真实方向的监督。</li>
<li>methods: 我们引入了一种新的神经网络学习方法，该方法鼓励神经网络 fits 输入点云数据，并且在点上产生单位方向的梯度。我们还引入了损失函数，使得查询点能够逐渐到达移动目标点，并且在approximated surface上归一化。</li>
<li>results: 我们的方法可以更加准确地估计方向，并且能够抗抗噪、缺失和density变化。我们的result在广泛使用的benchmark上达到了最佳性能，超过了latest方法。<details>
<summary>Abstract</summary>
Normal estimation for 3D point clouds is a fundamental task in 3D geometry processing. The state-of-the-art methods rely on priors of fitting local surfaces learned from normal supervision. However, normal supervision in benchmarks comes from synthetic shapes and is usually not available from real scans, thereby limiting the learned priors of these methods. In addition, normal orientation consistency across shapes remains difficult to achieve without a separate post-processing procedure. To resolve these issues, we propose a novel method for estimating oriented normals directly from point clouds without using ground truth normals as supervision. We achieve this by introducing a new paradigm for learning neural gradient functions, which encourages the neural network to fit the input point clouds and yield unit-norm gradients at the points. Specifically, we introduce loss functions to facilitate query points to iteratively reach the moving targets and aggregate onto the approximated surface, thereby learning a global surface representation of the data. Meanwhile, we incorporate gradients into the surface approximation to measure the minimum signed deviation of queries, resulting in a consistent gradient field associated with the surface. These techniques lead to our deep unsupervised oriented normal estimator that is robust to noise, outliers and density variations. Our excellent results on widely used benchmarks demonstrate that our method can learn more accurate normals for both unoriented and oriented normal estimation tasks than the latest methods. The source code and pre-trained model are publicly available at https://github.com/LeoQLi/NeuralGF.
</details>
<details>
<summary>摘要</summary>
普通估计3D点云是3D形状处理的基本任务。现状领域的方法都是基于点云上的本地表面适应学习得到的约束。然而，实际扫描数据中的正常监督信息通常不可获得，因此这些方法中学习的约束有限。另外，在不同形状之间均匀的正常方向 consistency 还是一个难以实现的问题。为解决这些问题，我们提出了一种新的方法， direct 从点云中估计方向正常场，不使用地面 truth 监督。我们通过引入一种新的 neural gradient 函数学习 paradigm，让神经网络适应输入点云，并且在点上得到单位 нор 的梯度。具体来说，我们引入了一种新的损失函数，使得查询点能够逐步到达移动目标，并将查询点积累到估计的表面上，从而学习全局表面 Representation 的数据。同时，我们将梯度 integrate 到表面估计中，以测量查询点与表面之间的最小积分差，从而获得一个均匀的梯度场，与表面相关的梯度场。这些技术导致我们的深度无监督方向正常估计器，可以抗抵达噪音、异常点和density 变化。我们的Result 在广泛使用的标准 benchmark 上表现出色，表明我们的方法可以更加准确地估计方向正常场，超过最新的方法。我们的源代码和预训练模型可以在 <https://github.com/LeoQLi/NeuralGF> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Learning-Cooperative-Trajectory-Representations-for-Motion-Forecasting"><a href="#Learning-Cooperative-Trajectory-Representations-for-Motion-Forecasting" class="headerlink" title="Learning Cooperative Trajectory Representations for Motion Forecasting"></a>Learning Cooperative Trajectory Representations for Motion Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00371">http://arxiv.org/abs/2311.00371</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/air-thu/dair-v2x-seq">https://github.com/air-thu/dair-v2x-seq</a></li>
<li>paper_authors: Hongzhi Ruan, Haibao Yu, Wenxian Yang, Siqi Fan, Yingjuan Tang, Zaiqing Nie</li>
<li>for: This paper focuses on motion forecasting for autonomous driving, specifically using cooperative information from infrastructure and other vehicles to enhance forecasting capabilities.</li>
<li>methods: The proposed method is called V2X-Graph, which is an interpretable and end-to-end learning framework that leverages cooperative motion and interaction contexts using an interpretable graph.</li>
<li>results: The paper demonstrates the effectiveness of V2X-Graph on the V2I motion forecasting dataset V2X-Seq, and also constructs a real-world V2X motion forecasting dataset V2X-Traj to further evaluate the method. The results show the advantage of the proposed method.<details>
<summary>Abstract</summary>
Motion forecasting is an essential task for autonomous driving, and the effective information utilization from infrastructure and other vehicles can enhance motion forecasting capabilities. Existing research have primarily focused on leveraging single-frame cooperative information to enhance the limited perception capability of the ego vehicle, while underutilizing the motion and interaction information of traffic participants observed from cooperative devices. In this paper, we first propose the cooperative trajectory representations learning paradigm. Specifically, we present V2X-Graph, the first interpretable and end-to-end learning framework for cooperative motion forecasting. V2X-Graph employs an interpretable graph to fully leverage the cooperative motion and interaction contexts. Experimental results on the vehicle-to-infrastructure (V2I) motion forecasting dataset, V2X-Seq, demonstrate the effectiveness of V2X-Graph. To further evaluate on V2X scenario, we construct the first real-world vehicle-to-everything (V2X) motion forecasting dataset V2X-Traj, and the performance shows the advantage of our method. We hope both V2X-Graph and V2X-Traj can facilitate the further development of cooperative motion forecasting. Find project at https://github.com/AIR-THU/V2X-Graph, find data at https://github.com/AIR-THU/DAIR-V2X-Seq.
</details>
<details>
<summary>摘要</summary>
传感器预测是自动驾驶中的关键任务，利用基础设施和其他车辆的有效信息可以提高传感器预测能力。现有研究主要是利用单一帧合作信息来增强egos车辆的有限感知能力，而未充分利用交通参与者的运动和互动信息。在本文中，我们首先提出了合作轨迹表示学习思路。特别是，我们提出了V2X-Graph，第一个可解释的终端学习框架 для合作运动预测。V2X-Graph使用可解释的图来完全利用合作运动和互动上下文。实验结果表明，V2X-Graph在V2I动作预测数据集上具有显著优势。为进一步评估V2X场景，我们构建了第一个真实世界的 Vehicle-to-Everything（V2X）动作预测数据集V2X-Traj，并发现了我们的方法的优势。我们希望V2X-Graph和V2X-Traj可以促进合作动作预测的进一步发展。项目可以在https://github.com/AIR-THU/V2X-Graph找到，数据可以在https://github.com/AIR-THU/DAIR-V2X-Seq找到。
</details></li>
</ul>
<hr>
<h2 id="LatentWarp-Consistent-Diffusion-Latents-for-Zero-Shot-Video-to-Video-Translation"><a href="#LatentWarp-Consistent-Diffusion-Latents-for-Zero-Shot-Video-to-Video-Translation" class="headerlink" title="LatentWarp: Consistent Diffusion Latents for Zero-Shot Video-to-Video Translation"></a>LatentWarp: Consistent Diffusion Latents for Zero-Shot Video-to-Video Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00353">http://arxiv.org/abs/2311.00353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Bao, Di Qiu, Guoliang Kang, Baochang Zhang, Bo Jin, Kaiye Wang, Pengfei Yan</li>
<li>for:  zero-shot video-to-video translation with temporal coherence</li>
<li>methods: incorporates warping operation in the latent space to constrain query tokens and improve temporal consistency</li>
<li>results: superior video-to-video translation with enhanced visual temporal coherence compared to previous methods<details>
<summary>Abstract</summary>
Leveraging the generative ability of image diffusion models offers great potential for zero-shot video-to-video translation. The key lies in how to maintain temporal consistency across generated video frames by image diffusion models. Previous methods typically adopt cross-frame attention, \emph{i.e.,} sharing the \textit{key} and \textit{value} tokens across attentions of different frames, to encourage the temporal consistency. However, in those works, temporal inconsistency issue may not be thoroughly solved, rendering the fidelity of generated videos limited.%The current state of the art cross-frame attention method aims at maintaining fine-grained visual details across frames, but it is still challenged by the temporal coherence problem. In this paper, we find the bottleneck lies in the unconstrained query tokens and propose a new zero-shot video-to-video translation framework, named \textit{LatentWarp}. Our approach is simple: to constrain the query tokens to be temporally consistent, we further incorporate a warping operation in the latent space to constrain the query tokens. Specifically, based on the optical flow obtained from the original video, we warp the generated latent features of last frame to align with the current frame during the denoising process. As a result, the corresponding regions across the adjacent frames can share closely-related query tokens and attention outputs, which can further improve latent-level consistency to enhance visual temporal coherence of generated videos. Extensive experiment results demonstrate the superiority of \textit{LatentWarp} in achieving video-to-video translation with temporal coherence.
</details>
<details>
<summary>摘要</summary>
利用生成能力的图像扩散模型可以提供无需预训练的视频到视频翻译的潜在潜力。关键在于如何在生成的视频帧中保持时间一致性。先前的方法通常采用cross-frame注意力，即在不同帧的注意力中共享键和值token，以促进时间一致性。然而，这些工作中可能并未完全解决时间不一致的问题，因此生成的视频的准确性有限。现状的潜在抑制方法是保持细腻的视觉细节的同时，仍然面临着时间协调问题。在这篇论文中，我们发现瓶颈在不受限制的查询token上，因此我们提出了一种新的无需预训练视频到视频翻译框架，名为LatentWarp。我们的方法简单：在生成过程中，基于原始视频中获得的光流，将生成的最后一帧的秘密特征截图进行扭曲，以使得当前帧和相邻帧的相关区域可以共享相似的查询token和注意力输出，从而进一步提高秘密水平的一致性，以提高生成的视频的视觉时间准确性。我们的实验结果表明，LatentWarp可以在无需预训练的情况下实现视频到视频翻译的时间准确性。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Head-Orientation-of-Neurotypical-and-Autistic-Individuals-in-Triadic-Conversations"><a href="#Analyzing-Head-Orientation-of-Neurotypical-and-Autistic-Individuals-in-Triadic-Conversations" class="headerlink" title="Analyzing Head Orientation of Neurotypical and Autistic Individuals in Triadic Conversations"></a>Analyzing Head Orientation of Neurotypical and Autistic Individuals in Triadic Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00343">http://arxiv.org/abs/2311.00343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onur N. Tepencelik, Wenchuan Wei, Pamela C. Cosman, Sujit Dey</li>
<li>for: 这个论文是用来估计人体和头部的方向偏移的系统。</li>
<li>methods: 这个系统使用了低分辨率点云数据来估计人体和头部的方向偏移。模型使用椭球适应和人工神经网络回归器来准确地估计人体和头部的方向偏移。</li>
<li>results: 模型的测试结果表明，与其他使用RGB摄像头的身体和头部偏移估计系统相比，使用LiDAR感知器保护用户隐私，并达到相似的准确性。此外，模型不需要在前方 Specified placement，并且可以在实际会话中准确地估计人体和头部的方向偏移。<details>
<summary>Abstract</summary>
We propose a system that estimates people's body and head orientations using low-resolution point cloud data from two LiDAR sensors. Our models make accurate estimations in real-world conversation settings where the subject moves naturally with varying head and body poses. The body orientation estimation model uses ellipse fitting while the head orientation estimation model is a pipeline of geometric feature extraction and an ensemble of neural network regressors. Compared with other body and head orientation estimation systems using RGB cameras, our proposed system uses LiDAR sensors to preserve user privacy, while achieving comparable accuracy. Unlike other body/head orientation estimation systems, our sensors do not require a specified placement in front of the subject. Our models achieve a mean absolute estimation error of 5.2 degrees for body orientation and 13.7 degrees for head orientation. We use our models to quantify behavioral differences between neurotypical and autistic individuals in triadic conversations. Tests of significance show that people with autism spectrum disorder display significantly different behavior compared to neurotypical individuals in terms of distributing attention between participants in a conversation, suggesting that the approach could be a component of a behavioral analysis or coaching system.
</details>
<details>
<summary>摘要</summary>
我们提出了一个系统，使用低分辨率点云数据从两个LiDAR感知器来估算人体和头部orientation。我们的模型在真实世界的对话 Setting中具有高精度，可以捕捉人体在自然的移动和变化pose下的orientation。bodyorientation estimation模型使用椭球拟合，而headorientation estimation模型则是一个包括几何特征提取和多个神经网络回归器的管道。与其他使用RGB摄像头的body和headorientation estimation系统相比，我们的提议的系统使用LiDAR感知器，保持用户隐私，同时实现相似的准确性。与其他body/headorientation estimation系统不同的是，我们的感知器不需要在前方的主题处置于特定的位置。我们的模型的 mean absolute estimation error为5.2度 дляbodyorientation和13.7度 дляheadorientation。我们使用我们的模型来量化 между neurtypical和autism Spectrum Disorder（ASD）个体在多人对话中的行为差异。测试显示，人类ASD Displayed significant differences in attention distribution between participants in a conversation compared to neurotypical individuals, suggesting that the approach could be a component of a behavioral analysis or coaching system.
</details></li>
</ul>
<hr>
<h2 id="fMRI-PTE-A-Large-scale-fMRI-Pretrained-Transformer-Encoder-for-Multi-Subject-Brain-Activity-Decoding"><a href="#fMRI-PTE-A-Large-scale-fMRI-Pretrained-Transformer-Encoder-for-Multi-Subject-Brain-Activity-Decoding" class="headerlink" title="fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for Multi-Subject Brain Activity Decoding"></a>fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for Multi-Subject Brain Activity Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00342">http://arxiv.org/abs/2311.00342</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuelin Qian, Yun Wang, Jingyang Huo, Jianfeng Feng, Yanwei Fu</li>
<li>for: This paper aims to develop a novel approach for pre-training fMRI data, addressing the challenges of individual brain differences and improving the quality of brain activity decoding.</li>
<li>methods: The proposed approach, called fMRI-PTE, uses an auto-encoder to transform fMRI signals into unified 2D representations, leveraging a novel learning strategy and image generators to enhance the quality of reconstruction and facilitate downstream tasks.</li>
<li>results: The authors demonstrate the effectiveness of fMRI-PTE through extensive experiments, showing improved performance in brain activity decoding compared to traditional methods and offering a promising foundation for future research in this area.<details>
<summary>Abstract</summary>
The exploration of brain activity and its decoding from fMRI data has been a longstanding pursuit, driven by its potential applications in brain-computer interfaces, medical diagnostics, and virtual reality. Previous approaches have primarily focused on individual subject analysis, highlighting the need for a more universal and adaptable framework, which is the core motivation behind our work. In this work, we propose fMRI-PTE, an innovative auto-encoder approach for fMRI pre-training, with a focus on addressing the challenges of varying fMRI data dimensions due to individual brain differences. Our approach involves transforming fMRI signals into unified 2D representations, ensuring consistency in dimensions and preserving distinct brain activity patterns. We introduce a novel learning strategy tailored for pre-training 2D fMRI images, enhancing the quality of reconstruction. fMRI-PTE's adaptability with image generators enables the generation of well-represented fMRI features, facilitating various downstream tasks, including within-subject and cross-subject brain activity decoding. Our contributions encompass introducing fMRI-PTE, innovative data transformation, efficient training, a novel learning strategy, and the universal applicability of our approach. Extensive experiments validate and support our claims, offering a promising foundation for further research in this domain.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate(The exploration of brain activity and its decoding from fMRI data has been a longstanding pursuit, driven by its potential applications in brain-computer interfaces, medical diagnostics, and virtual reality. Previous approaches have primarily focused on individual subject analysis, highlighting the need for a more universal and adaptable framework, which is the core motivation behind our work. In this work, we propose fMRI-PTE, an innovative auto-encoder approach for fMRI pre-training, with a focus on addressing the challenges of varying fMRI data dimensions due to individual brain differences. Our approach involves transforming fMRI signals into unified 2D representations, ensuring consistency in dimensions and preserving distinct brain activity patterns. We introduce a novel learning strategy tailored for pre-training 2D fMRI images, enhancing the quality of reconstruction. fMRI-PTE's adaptability with image generators enables the generation of well-represented fMRI features, facilitating various downstream tasks, including within-subject and cross-subject brain activity decoding. Our contributions encompass introducing fMRI-PTE, innovative data transformation, efficient training, a novel learning strategy, and the universal applicability of our approach. Extensive experiments validate and support our claims, offering a promising foundation for further research in this domain.)Here's the translation:<<SYS>>翻译(脑活动的探索和从fMRI数据中的解码已经是一项长期的追求，它的潜在应用包括脑机器交互、医疗诊断和虚拟现实等。先前的方法主要集中在个体Subject的分析上，这 highlights the need for a more universal and adaptable framework, which is the core motivation behind our work。在这项工作中，我们提出了fMRI-PTE，一种创新的自编码方法 для fMRI预训练，强调解决因个体脑difficulties而导致的fMRI数据维度的变化挑战。我们的方法涉及将fMRI信号转换成统一的2D表示形式，确保维度的一致性和保持脑活动特征的分布。我们介绍了一种适应于预训练2D fMRI图像的新学习策略，提高了重建质量。fMRI-PTE的图像生成器的可靠性使得可以生成高质量的fMRI特征，促进了多种下游任务，包括在个体和跨个体脑活动解码。我们的贡献包括引入fMRI-PTE、创新数据转换、高效训练、适应学习策略和我们的方法的 universality。广泛的实验证明和支持我们的声明，提供了一个可靠的基础 для进一步的研究在这个领域。)
</details></li>
</ul>
<hr>
<h2 id="Space-Narrative-Generating-Images-and-3D-Scenes-of-Chinese-Garden-from-Text-using-Deep-Learning"><a href="#Space-Narrative-Generating-Images-and-3D-Scenes-of-Chinese-Garden-from-Text-using-Deep-Learning" class="headerlink" title="Space Narrative: Generating Images and 3D Scenes of Chinese Garden from Text using Deep Learning"></a>Space Narrative: Generating Images and 3D Scenes of Chinese Garden from Text using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00339">http://arxiv.org/abs/2311.00339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxi Shi1, Hao Hua1</li>
<li>for: 这篇论文主要针对的是传统中国园林研究和修复的困难问题，即缺乏直接资料。</li>
<li>methods: 该论文提出了一种基于深度学习方法的园林图像生成方法，使用了文本描述和历史园林画作为数据集，并使用了LoRA进行精度调整。</li>
<li>results: 该论文通过使用文本描述和历史园林画的数据集，使用了深度学习方法生成了具有明朝风格的园林图像，并可以在Unity 3D 中实现三维展示。<details>
<summary>Abstract</summary>
The consistent mapping from poems to paintings is essential for the research and restoration of traditional Chinese gardens. But the lack of firsthand ma-terial is a great challenge to the reconstruction work. In this paper, we pro-pose a method to generate garden paintings based on text descriptions using deep learning method. Our image-text pair dataset consists of more than one thousand Ming Dynasty Garden paintings and their inscriptions and post-scripts. A latent text-to-image diffusion model learns the mapping from de-scriptive texts to garden paintings of the Ming Dynasty, and then the text description of Jichang Garden guides the model to generate new garden paintings. The cosine similarity between the guide text and the generated image is the evaluation criterion for the generated images. Our dataset is used to fine-tune the pre-trained diffusion model using Low-Rank Adapta-tion of Large Language Models (LoRA). We also transformed the generated images into a panorama and created a free-roam scene in Unity 3D. Our post-trained model is capable of generating garden images in the style of Ming Dynasty landscape paintings based on textual descriptions. The gener-ated images are compatible with three-dimensional presentation in Unity 3D.
</details>
<details>
<summary>摘要</summary>
“ Traditional Chinese gardens 的研究和修复受到描述与画作之间的一致性很大帮助。但是，由于缺乏直接证据，修复工作受到很大挑战。本文提出了一种基于深度学习方法生成园林画作的方法。我们的图文对照集包括明朝园林画作和其附注和词汇，共计超过一千个。我们使用文本描述和图像生成模型，将描述文本引导模型生成新的园林画作。我们使用 cosine 相似性作为生成图像的评价标准。我们的模型可以在 Unity 3D 中生成园林画作，并将其转换为漫游场景。我们的模型可以基于文本描述生成园林画作，并且可以与三维表现相匹配。”
</details></li>
</ul>
<hr>
<h2 id="SDF4CHD-Generative-Modeling-of-Cardiac-Anatomies-with-Congenital-Heart-Defects"><a href="#SDF4CHD-Generative-Modeling-of-Cardiac-Anatomies-with-Congenital-Heart-Defects" class="headerlink" title="SDF4CHD: Generative Modeling of Cardiac Anatomies with Congenital Heart Defects"></a>SDF4CHD: Generative Modeling of Cardiac Anatomies with Congenital Heart Defects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00332">http://arxiv.org/abs/2311.00332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fanwei Kong, Sascha Stocker, Perry S. Choi, Michael Ma, Daniel B. Ennis, Alison Marsden<br>for:This paper aims to improve the diagnosis and treatment planning of congenital heart disease (CHD) by generating virtual cardiac anatomies using deep learning (DL) methods.methods:The proposed approach uses a type- and shape-disentangled generative model based on signed distance fields (SDF) to capture the wide spectrum of cardiac anatomies observed in different CHD types. The approach also learns invertible deformations to morph the learned CHD type-specific anatomies and reconstruct patient-specific shapes.results:The proposed approach has the potential to augment the image-segmentation pairs for rarer CHD types for cardiac segmentation and generate cohorts of CHD cardiac meshes for computational simulation, which can improve the diagnosis and treatment planning of CHD patients.<details>
<summary>Abstract</summary>
Congenital heart disease (CHD) encompasses a spectrum of cardiovascular structural abnormalities, often requiring customized treatment plans for individual patients. Computational modeling and analysis of these unique cardiac anatomies can improve diagnosis and treatment planning and may ultimately lead to improved outcomes. Deep learning (DL) methods have demonstrated the potential to enable efficient treatment planning by automating cardiac segmentation and mesh construction for patients with normal cardiac anatomies. However, CHDs are often rare, making it challenging to acquire sufficiently large patient cohorts for training such DL models. Generative modeling of cardiac anatomies has the potential to fill this gap via the generation of virtual cohorts; however, prior approaches were largely designed for normal anatomies and cannot readily capture the significant topological variations seen in CHD patients. Therefore, we propose a type- and shape-disentangled generative approach suitable to capture the wide spectrum of cardiac anatomies observed in different CHD types and synthesize differently shaped cardiac anatomies that preserve the unique topology for specific CHD types. Our DL approach represents generic whole heart anatomies with CHD type-specific abnormalities implicitly using signed distance fields (SDF) based on CHD type diagnosis, which conveniently captures divergent anatomical variations across different types and represents meaningful intermediate CHD states. To capture the shape-specific variations, we then learn invertible deformations to morph the learned CHD type-specific anatomies and reconstruct patient-specific shapes. Our approach has the potential to augment the image-segmentation pairs for rarer CHD types for cardiac segmentation and generate cohorts of CHD cardiac meshes for computational simulation.
</details>
<details>
<summary>摘要</summary>
Congenital heart disease (CHD) 包括一系列心血管结构畸形，经常需要根据各个患者的特殊情况制定个性化的治疗方案。计算模型和分析这些特殊的心血管结构可以提高诊断和治疗规划，并最终可能导致更好的结果。深度学习（DL）方法已经表明可以通过自动化心血管分 segmentation和心血管建模来提高诊断和治疗规划的效率。但是，CHD 的发生率很低，因此困难以获得足够的患者组合来训练这些 DL 模型。生成模型可以填补这一空白，通过生成虚拟患者组合来模拟不同类型的 CHD。但是，先前的方法主要针对正常的心血管结构，无法轻松地捕捉 CHD 患者的重要的拓扑变化。因此，我们提出了一种类型和形状分解的生成方法，可以 capture 不同类型的 CHD 的各种拓扑变化，并生成具有不同形状的心血管结构。我们的 DL 方法使用了签名距离场（SDF）基于 CHD 类型诊断，以便捕捉不同类型的 CHD 中的多样化拓扑变化。然后，我们学习了可逆变形，以将学习的 CHD 类型特定的心血管结构变换为患者特定的形状。我们的方法有望增加较少seen的 CHD 类型的图像分割对，以及生成不同类型的 CHD 心血管核心，以便计算模拟。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Clustering-Representations-with-Positive-Proximity-and-Cluster-Dispersion-Learning"><a href="#Enhancing-Clustering-Representations-with-Positive-Proximity-and-Cluster-Dispersion-Learning" class="headerlink" title="Enhancing Clustering Representations with Positive Proximity and Cluster Dispersion Learning"></a>Enhancing Clustering Representations with Positive Proximity and Cluster Dispersion Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00731">http://arxiv.org/abs/2311.00731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhishek Kumar, Dong-Gyu Lee</li>
<li>for: 这篇论文主要用于提出一种新的深度划分方法，即PIPCDR方法，用于解决现代深度划分中的问题。</li>
<li>methods: PIPCDR方法使用了一种新的正例邻近损失函数和一种减少划分趋势的补偿器，以兼顾两种方法的优点，并消除其缺点。</li>
<li>results: PIPCDR方法在一系列模拟和实际 datasets上表现出色，能够生成良好的划分结果，同时避免维度缩合和类别碰撞问题，提高划分精度。<details>
<summary>Abstract</summary>
Contemporary deep clustering approaches often rely on either contrastive or non-contrastive techniques to acquire effective representations for clustering tasks. Contrastive methods leverage negative pairs to achieve homogenous representations but can introduce class collision issues, potentially compromising clustering performance. On the contrary, non-contrastive techniques prevent class collisions but may produce non-uniform representations that lead to clustering collapse. In this work, we propose a novel end-to-end deep clustering approach named PIPCDR, designed to harness the strengths of both approaches while mitigating their limitations. PIPCDR incorporates a positive instance proximity loss and a cluster dispersion regularizer. The positive instance proximity loss ensures alignment between augmented views of instances and their sampled neighbors, enhancing within-cluster compactness by selecting genuinely positive pairs within the embedding space. Meanwhile, the cluster dispersion regularizer maximizes inter-cluster distances while minimizing within-cluster compactness, promoting uniformity in the learned representations. PIPCDR excels in producing well-separated clusters, generating uniform representations, avoiding class collision issues, and enhancing within-cluster compactness. We extensively validate the effectiveness of PIPCDR within an end-to-end Majorize-Minimization framework, demonstrating its competitive performance on moderate-scale clustering benchmark datasets and establishing new state-of-the-art results on large-scale datasets.
</details>
<details>
<summary>摘要</summary>
现代深度划分方法 oftentimes 依赖于 either 对比或非对比技术来获得有效的划分表示。对比方法 利用负对比来实现同一类型的表示，但可能会引入类冲突问题，可能会降低划分性能。然而，非对比技术 避免类冲突问题，但可能会生成不均匀的表示，导致划分崩溃。在这项工作中，我们提出了一种新的端到端深度划分方法，名为PIPCDR。PIPCDR 结合了正例邻接损失和群分散正则化。正例邻接损失 确保在扩展视图中的实例和其采样的邻居之间的Alignment，提高同一个分组内的紧凑性，通过选择真正的正例对在嵌入空间中进行选择。同时，群分散正则化 最大化间分组距离，最小化同一个分组内的紧凑性，使得学习的表示具有均匀性。PIPCDR 在生成均匀的分组、避免类冲突问题、提高同一个分组内的紧凑性和端到端 Majorize-Minimization 框架中展现出了竞争性的性能，并在大规模数据集上达到了新的国际纪录。
</details></li>
</ul>
<hr>
<h2 id="Flooding-Regularization-for-Stable-Training-of-Generative-Adversarial-Networks"><a href="#Flooding-Regularization-for-Stable-Training-of-Generative-Adversarial-Networks" class="headerlink" title="Flooding Regularization for Stable Training of Generative Adversarial Networks"></a>Flooding Regularization for Stable Training of Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00318">http://arxiv.org/abs/2311.00318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iu Yahiro, Takashi Ishida, Naoto Yokoya</li>
<li>for: 提高生成 adversarial network (GAN) 的稳定性。</li>
<li>methods: 直接对抗损失函数进行补偿，使用涌流法来防止批判器损失值过低。</li>
<li>results: 实验表明，涌流法可以稳定 GAN 的训练，并且可以与其他稳定技术结合使用。此外，研究还发现，对批判器损失值进行限制，可以使训练过程更加稳定，即使涌流水平较高。<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GANs) have shown remarkable performance in image generation. However, GAN training suffers from the problem of instability. One of the main approaches to address this problem is to modify the loss function, often using regularization terms in addition to changing the type of adversarial losses. This paper focuses on directly regularizing the adversarial loss function. We propose a method that applies flooding, an overfitting suppression method in supervised learning, to GANs to directly prevent the discriminator's loss from becoming excessively low. Flooding requires tuning the flood level, but when applied to GANs, we propose that the appropriate range of flood level settings is determined by the adversarial loss function, supported by theoretical analysis of GANs using the binary cross entropy loss. We experimentally verify that flooding stabilizes GAN training and can be combined with other stabilization techniques. We also reveal that by restricting the discriminator's loss to be no greater than flood level, the training proceeds stably even when the flood level is somewhat high.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Empirical-Study-of-Frame-Selection-for-Text-to-Video-Retrieval"><a href="#An-Empirical-Study-of-Frame-Selection-for-Text-to-Video-Retrieval" class="headerlink" title="An Empirical Study of Frame Selection for Text-to-Video Retrieval"></a>An Empirical Study of Frame Selection for Text-to-Video Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00298">http://arxiv.org/abs/2311.00298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengxia Wu, Min Cao, Yang Bai, Ziyin Zeng, Chen Chen, Liqiang Nie, Min Zhang</li>
<li>for: 文本-视频重现（TVR）旨在在大量视频库中找到基于文本查询的最相关视频。</li>
<li>methods: exist 方法通常选择视频中的一 subset of frames来表示视频内容，以提高 TVR 的性能和效率。</li>
<li>results: 根据多个 TVR benchmark 的全面分析，我们证明了 proper frame 选择可以显著提高 TVR 的检索效率，而无需牺牲检索性能。<details>
<summary>Abstract</summary>
Text-to-video retrieval (TVR) aims to find the most relevant video in a large video gallery given a query text. The intricate and abundant context of the video challenges the performance and efficiency of TVR. To handle the serialized video contexts, existing methods typically select a subset of frames within a video to represent the video content for TVR. How to select the most representative frames is a crucial issue, whereby the selected frames are required to not only retain the semantic information of the video but also promote retrieval efficiency by excluding temporally redundant frames. In this paper, we make the first empirical study of frame selection for TVR. We systemically classify existing frame selection methods into text-free and text-guided ones, under which we detailedly analyze six different frame selections in terms of effectiveness and efficiency. Among them, two frame selections are first developed in this paper. According to the comprehensive analysis on multiple TVR benchmarks, we empirically conclude that the TVR with proper frame selections can significantly improve the retrieval efficiency without sacrificing the retrieval performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Graph-Representation-Learning-for-Infrared-and-Visible-Image-Fusion"><a href="#Graph-Representation-Learning-for-Infrared-and-Visible-Image-Fusion" class="headerlink" title="Graph Representation Learning for Infrared and Visible Image Fusion"></a>Graph Representation Learning for Infrared and Visible Image Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00291">http://arxiv.org/abs/2311.00291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Li, Lu Bai, Bin Yang, Chang Li, Lingfei Ma, Edwin R. Hancock</li>
<li>for: 本研究的目的是提出一种基于图表示的多模态图像重构方法，以提高图像重构的精度和效率。</li>
<li>methods: 本研究使用图 convolutional neural networks (GCNs) 抽取非本地自相关特征 (NLss)，通过图可以提供细致的结构来归一化特征并传递信息。</li>
<li>results: 实验结果表明，提出的方法可以更好地捕捉图像中的NLss，并且与传统方法相比，具有更高的重构精度和效率。<details>
<summary>Abstract</summary>
Infrared and visible image fusion aims to extract complementary features to synthesize a single fused image. Many methods employ convolutional neural networks (CNNs) to extract local features due to its translation invariance and locality. However, CNNs fail to consider the image's non-local self-similarity (NLss), though it can expand the receptive field by pooling operations, it still inevitably leads to information loss. In addition, the transformer structure extracts long-range dependence by considering the correlativity among all image patches, leading to information redundancy of such transformer-based methods. However, graph representation is more flexible than grid (CNN) or sequence (transformer structure) representation to address irregular objects, and graph can also construct the relationships among the spatially repeatable details or texture with far-space distance. Therefore, to address the above issues, it is significant to convert images into the graph space and thus adopt graph convolutional networks (GCNs) to extract NLss. This is because the graph can provide a fine structure to aggregate features and propagate information across the nearest vertices without introducing redundant information. Concretely, we implement a cascaded NLss extraction pattern to extract NLss of intra- and inter-modal by exploring interactions of different image pixels in intra- and inter-image positional distance. We commence by preforming GCNs on each intra-modal to aggregate features and propagate information to extract independent intra-modal NLss. Then, GCNs are performed on the concatenate intra-modal NLss features of infrared and visible images, which can explore the cross-domain NLss of inter-modal to reconstruct the fused image. Ablation studies and extensive experiments illustrates the effectiveness and superiority of the proposed method on three datasets.
</details>
<details>
<summary>摘要</summary>
infrared和可见图像融合的目标是提取 complementary 特征来生成合并的单独图像。许多方法使用卷积神经网络（CNN）提取本地特征，因为它们的翻译不变性和本地性。然而，CNN失去了图像的非本地自相似性（NLss），尽管它可以通过抽象操作扩大感知范围，但仍然会导致信息损失。此外，transformer结构可以捕捉图像的长距离相关性，但是它会导致图像的信息重复。然而，图像表示更加灵活于网格（CNN）或序列（transformer结构）表示，可以 Address Irregular Objects。因此，为了解决这些问题，需要将图像转换为图像空间，并采用图像卷积神经网络（GCNs）提取NLss。这是因为图像可以提供细致的结构来聚合特征和在最近邻居中传递信息，而无需引入重复信息。具体来说，我们实现了一种卷积NLss提取模式，通过探索不同图像像素之间的交互来提取NLss。我们开始是在每个intra-modal中使用GCNs来聚合特征和传递信息，以提取独立的intra-modalNLss。然后，我们在 concatenate  intra-modalNLss特征上使用GCNs来探索跨频道NLss，以重构融合图像。aborlation studies和广泛的实验表明了我们提posed方法的有效性和优越性。
</details></li>
</ul>
<hr>
<h2 id="Mixture-of-Experts-for-Open-Set-Domain-Adaptation-A-Dual-Space-Detection-Approach"><a href="#Mixture-of-Experts-for-Open-Set-Domain-Adaptation-A-Dual-Space-Detection-Approach" class="headerlink" title="Mixture-of-Experts for Open Set Domain Adaptation: A Dual-Space Detection Approach"></a>Mixture-of-Experts for Open Set Domain Adaptation: A Dual-Space Detection Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00285">http://arxiv.org/abs/2311.00285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenbang Du, Jiayu An, Jiahao Hong, Dongrui Wu</li>
<li>for: 这篇论文的目的是实现开放集领域适束（OSDA），以实现源领域和目标领域之间的分布和标签迁移，并实现精准的分类结果。</li>
<li>methods: 这篇论文使用了混合专家（MoE）的方法，将不同的专家处理不同的输入特征，从而生成不同的专家路由模式，以便更好地识别未知的类别样本。</li>
<li>results: 这篇论文的实验结果显示，使用了Graph Router来更好地利用图像组件之间的空间信息，可以更好地识别未知的类别样本，并且比较精准地预测未知类别的结果。<details>
<summary>Abstract</summary>
Open Set Domain Adaptation (OSDA) aims to cope with the distribution and label shifts between the source and target domains simultaneously, performing accurate classification for known classes while identifying unknown class samples in the target domain. Most existing OSDA approaches, depending on the final image feature space of deep models, require manually-tuned thresholds, and may easily misclassify unknown samples as known classes. Mixture-of-Expert (MoE) could be a remedy. Within an MoE, different experts address different input features, producing unique expert routing patterns for different classes in a routing feature space. As a result, unknown class samples may also display different expert routing patterns to known classes. This paper proposes Dual-Space Detection, which exploits the inconsistencies between the image feature space and the routing feature space to detect unknown class samples without any threshold. Graph Router is further introduced to better make use of the spatial information among image patches. Experiments on three different datasets validated the effectiveness and superiority of our approach. The code will come soon.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TLMCM-Network-for-Medical-Image-Hierarchical-Multi-Label-Classification"><a href="#TLMCM-Network-for-Medical-Image-Hierarchical-Multi-Label-Classification" class="headerlink" title="TLMCM Network for Medical Image Hierarchical Multi-Label Classification"></a>TLMCM Network for Medical Image Hierarchical Multi-Label Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00282">http://arxiv.org/abs/2311.00282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meng Wu, Siyan Luo, Qiyu Wu, Wenbin Ouyang<br>for:本研究旨在提高现代医疗领域的医学影像层次多标签分类（MI-HMC）任务中的两大挑战：数据不均衡和层次约束。现有的解决方案通常包括复杂的模型建立设计或域专业的预处理，需要较大的专业知识或努力进行实现。methods:为解决这些限制，本研究提出了传输学习与最大约束模块（TLMCM）网络，用于MI-HMC任务。TLMCM网络提供了一种新的方法，以超越现有方法，根据Area Under the Average Precision and Recall Curve（$AU\overline{(PRC)}$）指标。此外，本研究还提出了两种新的准确率指标：$EMR$和$HammingAccuracy$,在MI-HMC任务中尚未得到广泛的探讨。results:实验结果表明，TLMCM网络在MI-HMC任务中可以达到高多标签预测率（80%-90%），使其成为医疗领域应用中的有价值贡献。<details>
<summary>Abstract</summary>
Medical Image Hierarchical Multi-Label Classification (MI-HMC) is of paramount importance in modern healthcare, presenting two significant challenges: data imbalance and \textit{hierarchy constraint}. Existing solutions involve complex model architecture design or domain-specific preprocessing, demanding considerable expertise or effort in implementation. To address these limitations, this paper proposes Transfer Learning with Maximum Constraint Module (TLMCM) network for the MI-HMC task. The TLMCM network offers a novel approach to overcome the aforementioned challenges, outperforming existing methods based on the Area Under the Average Precision and Recall Curve($AU\overline{(PRC)}$) metric. In addition, this research proposes two novel accuracy metrics, $EMR$ and $HammingAccuracy$, which have not been extensively explored in the context of the MI-HMC task. Experimental results demonstrate that the TLMCM network achieves high multi-label prediction accuracy($80\%$-$90\%$) for MI-HMC tasks, making it a valuable contribution to healthcare domain applications.
</details>
<details>
<summary>摘要</summary>
医疗图像层次多标签分类（MI-HMC）在现代医疗中具有重要意义，存在两个主要挑战：数据不均衡和层次约束。现有的解决方案包括复杂的模型建立设计或域pecific的预处理，需要较大的专业知识或努力进行实现。为了解决这些限制，本文提出了基于传输学习的最大约束模块（TLMCM）网络，用于MI-HMC任务。TLMCM网络提供了一种新的方法，超越现有方法，根据Area Under the Average Precision and Recall Curve（$AU\overline{(PRC)}$）指标。此外，本研究还提出了两个新的准确率指标，$EMR$和$HammingAccuracy$,在MI-HMC任务中尚未得到广泛的探讨。实验结果表明，TLMCM网络在MI-HMC任务中实现了80%-90%的多标签预测率，使其成为医疗领域应用中的有价值贡献。
</details></li>
</ul>
<hr>
<h2 id="OpenForest-A-data-catalogue-for-machine-learning-in-forest-monitoring"><a href="#OpenForest-A-data-catalogue-for-machine-learning-in-forest-monitoring" class="headerlink" title="OpenForest: A data catalogue for machine learning in forest monitoring"></a>OpenForest: A data catalogue for machine learning in forest monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00277">http://arxiv.org/abs/2311.00277</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rolnicklab/openforest">https://github.com/rolnicklab/openforest</a></li>
<li>paper_authors: Arthur Ouaknine, Teja Kattenborn, Etienne Laliberté, David Rolnick</li>
<li>for: 本研究旨在提供一个开放的数据集，以便应用机器学习方法进行大规模森林监测。</li>
<li>methods: 本研究使用了86个开放数据集，包括森林资源调查、地面、空中和卫星数据记录等，以探讨森林生态系统的变化。</li>
<li>results: 本研究提供了一个动态目录，名为OpenForest，用于收集和总结所有可用的开放数据集，以便推广大规模森林监测的研究。<details>
<summary>Abstract</summary>
Forests play a crucial role in Earth's system processes and provide a suite of social and economic ecosystem services, but are significantly impacted by human activities, leading to a pronounced disruption of the equilibrium within ecosystems. Advancing forest monitoring worldwide offers advantages in mitigating human impacts and enhancing our comprehension of forest composition, alongside the effects of climate change. While statistical modeling has traditionally found applications in forest biology, recent strides in machine learning and computer vision have reached important milestones using remote sensing data, such as tree species identification, tree crown segmentation and forest biomass assessments. For this, the significance of open access data remains essential in enhancing such data-driven algorithms and methodologies. Here, we provide a comprehensive and extensive overview of 86 open access forest datasets across spatial scales, encompassing inventories, ground-based, aerial-based, satellite-based recordings, and country or world maps. These datasets are grouped in OpenForest, a dynamic catalogue open to contributions that strives to reference all available open access forest datasets. Moreover, in the context of these datasets, we aim to inspire research in machine learning applied to forest biology by establishing connections between contemporary topics, perspectives and challenges inherent in both domains. We hope to encourage collaborations among scientists, fostering the sharing and exploration of diverse datasets through the application of machine learning methods for large-scale forest monitoring. OpenForest is available at https://github.com/RolnickLab/OpenForest .
</details>
<details>
<summary>摘要</summary>
森林扮演着地球系维程序中重要的角色，提供了一系列社会和经济生态系统服务，但是人类活动对森林产生了明显的干扰，导致生态系统内部的平衡状态出现了明显的异常。推进全球森林监测可以有助于减轻人类对森林的影响，提高我们对森林结构的理解，以及气候变化的影响。在森林生物学中，统计学模型传统上找到了应用，但现在机器学习和计算机视觉在使用遥感数据时已经取得了重要的进步，例如树种识别、树冠分割和森林生物质评估。为此，开放数据的重要性仍然是不可或缺的，以提高这些数据驱动的算法和方法。本文提供了86个开放访问森林数据集，覆盖不同的空间尺度，包括森林资源库、地面、航空、卫星记录等，并分类在OpenForest中，一个动态目录开放至贡献。此外，在这些数据集的背景下，我们希望通过与机器学习领域的连接来激发研究，探索森林生物学中的当代话题、视角和挑战，并促进科学家之间的合作，共享和探索多种数据集，通过机器学习方法进行大规模森林监测。OpenForest可以在https://github.com/RolnickLab/OpenForest上获取。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Latent-Diffusion-Model-for-3D-Medical-Image-to-Image-Translation-Multi-modal-Magnetic-Resonance-Imaging-Study"><a href="#Adaptive-Latent-Diffusion-Model-for-3D-Medical-Image-to-Image-Translation-Multi-modal-Magnetic-Resonance-Imaging-Study" class="headerlink" title="Adaptive Latent Diffusion Model for 3D Medical Image to Image Translation: Multi-modal Magnetic Resonance Imaging Study"></a>Adaptive Latent Diffusion Model for 3D Medical Image to Image Translation: Multi-modal Magnetic Resonance Imaging Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00265">http://arxiv.org/abs/2311.00265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jongdory/aldm">https://github.com/jongdory/aldm</a></li>
<li>paper_authors: Jonghun Kim, Hyunjin Park</li>
<li>for: This paper proposes a model for image-to-image translation in 3D medical images without patch cropping, which can be used for comprehensive evaluations in medical image analysis.</li>
<li>methods: The proposed model uses a latent diffusion model (LDM) with switchable blocks, specifically multiple switchable spatially adaptive normalization (MS-SPADE), to generate high-quality target modalities in 3D.</li>
<li>results: The model demonstrated successful image synthesis across different source-target modality scenarios and outperformed other models in quantitative evaluations tested on multi-modal brain magnetic resonance imaging datasets of four different modalities and an independent IXI dataset.<details>
<summary>Abstract</summary>
Multi-modal images play a crucial role in comprehensive evaluations in medical image analysis providing complementary information for identifying clinically important biomarkers. However, in clinical practice, acquiring multiple modalities can be challenging due to reasons such as scan cost, limited scan time, and safety considerations. In this paper, we propose a model based on the latent diffusion model (LDM) that leverages switchable blocks for image-to-image translation in 3D medical images without patch cropping. The 3D LDM combined with conditioning using the target modality allows generating high-quality target modality in 3D overcoming the shortcoming of the missing out-of-slice information in 2D generation methods. The switchable block, noted as multiple switchable spatially adaptive normalization (MS-SPADE), dynamically transforms source latents to the desired style of the target latents to help with the diffusion process. The MS-SPADE block allows us to have one single model to tackle many translation tasks of one source modality to various targets removing the need for many translation models for different scenarios. Our model exhibited successful image synthesis across different source-target modality scenarios and surpassed other models in quantitative evaluations tested on multi-modal brain magnetic resonance imaging datasets of four different modalities and an independent IXI dataset. Our model demonstrated successful image synthesis across various modalities even allowing for one-to-many modality translations. Furthermore, it outperformed other one-to-one translation models in quantitative evaluations.
</details>
<details>
<summary>摘要</summary>
多Modal图像在医学影像分析中扮演着关键性的角色，提供了补充信息，用于标识临床重要的生物标志物。然而，在临床实践中，获取多Modal的可能性受到了多种因素的限制，如扫描成本、扫描时间和安全考虑。在这篇论文中，我们提出了基于秘密扩散模型（LDM）的模型，使用可 switchable 块（MS-SPADE）来实现图像到图像翻译。3D LDM 与 Conditioning 使用目标模式Allow generating high-quality target modality in 3D, overcoming the shortcomings of missing out-of-slice information in 2D generation methods. MS-SPADE block dynamically transforms source latents to the desired style of the target latents to help with the diffusion process. Our model can handle many translation tasks of one source modality to various targets, eliminating the need for multiple translation models for different scenarios. We tested our model on multi-modal brain magnetic resonance imaging datasets of four different modalities and an independent IXI dataset, and it exhibited successful image synthesis across different source-target modality scenarios and outperformed other models in quantitative evaluations. Our model also demonstrated successful image synthesis across various modalities, even allowing for one-to-many modality translations, and outperformed other one-to-one translation models in quantitative evaluations.
</details></li>
</ul>
<hr>
<h2 id="Solutions-to-Elliptic-and-Parabolic-Problems-via-Finite-Difference-Based-Unsupervised-Small-Linear-Convolutional-Neural-Networks"><a href="#Solutions-to-Elliptic-and-Parabolic-Problems-via-Finite-Difference-Based-Unsupervised-Small-Linear-Convolutional-Neural-Networks" class="headerlink" title="Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks"></a>Solutions to Elliptic and Parabolic Problems via Finite Difference Based Unsupervised Small Linear Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00259">http://arxiv.org/abs/2311.00259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Celaya, Keegan Kirk, David Fuentes, Beatrice Riviere</li>
<li>for: 解决Partial Differential Equations (PDEs)问题，尤其是使用深度学习和神经网络来解决PDEs。</li>
<li>methods: 提出了一种 Fully Unsupervised Approach，不需要训练数据或标注输入输出对。</li>
<li>results: 对一些选择的elliptic和parabolic问题进行比较，与finite difference方法相当准确。<details>
<summary>Abstract</summary>
In recent years, there has been a growing interest in leveraging deep learning and neural networks to address scientific problems, particularly in solving partial differential equations (PDEs). However, current neural network-based PDE solvers often rely on extensive training data or labeled input-output pairs, making them prone to challenges in generalizing to out-of-distribution examples. To mitigate the generalization gap encountered by conventional neural network-based methods in estimating PDE solutions, we formulate a fully unsupervised approach, requiring no training data, to estimate finite difference solutions for PDEs directly via small convolutional neural networks. Our proposed algorithms demonstrate a comparable accuracy to the true solution for several selected elliptic and parabolic problems compared to the finite difference method.
</details>
<details>
<summary>摘要</summary>
近年来，有越来越多的关注利用深度学习和神经网络解决科学问题，特别是解决部分偏微分方程（PDEs）。然而，现有的神经网络基于PDE解决方法通常需要大量的训练数据或标注输入输出对，使其容易遇到对不同示例的泛化问题。为了解决传统神经网络基于方法中的泛化差距，我们提出了一种完全无监督的方法，不需要任何训练数据，直接通过小型 convolutional neural networks 来估算部分偏微分解决方案。我们的提议的算法在选择的椭球和偏微分问题中与finite difference方法相比证明了相似的准确性。
</details></li>
</ul>
<hr>
<h2 id="RAUNE-Net-A-Residual-and-Attention-Driven-Underwater-Image-Enhancement-Method"><a href="#RAUNE-Net-A-Residual-and-Attention-Driven-Underwater-Image-Enhancement-Method" class="headerlink" title="RAUNE-Net: A Residual and Attention-Driven Underwater Image Enhancement Method"></a>RAUNE-Net: A Residual and Attention-Driven Underwater Image Enhancement Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00246">http://arxiv.org/abs/2311.00246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fansuregrin/raune-net">https://github.com/fansuregrin/raune-net</a></li>
<li>paper_authors: Wangzhen Peng, Chenghao Zhou, Runze Hu, Jingchao Cao, Yutao Liu</li>
<li>For: 提高水下图像的清晰度和质量* Methods: 使用深度学习和含义学习的策略，包括高级特征径 residual 学习和两种注意力控制技术* Results: 对水下图像进行了改进，提高了对水下图像的恢复和修复性能，并且在不同的水下环境下都能够保持良好的视觉效果<details>
<summary>Abstract</summary>
Underwater image enhancement (UIE) poses challenges due to distinctive properties of the underwater environment, including low contrast, high turbidity, visual blurriness, and color distortion. In recent years, the application of deep learning has quietly revolutionized various areas of scientific research, including UIE. However, existing deep learning-based UIE methods generally suffer from issues of weak robustness and limited adaptability. In this paper, inspired by residual and attention mechanisms, we propose a more reliable and reasonable UIE network called RAUNE-Net by employing residual learning of high-level features at the network's bottle-neck and two aspects of attention manipulations in the down-sampling procedure. Furthermore, we collect and create two datasets specifically designed for evaluating UIE methods, which contains different types of underwater distortions and degradations. The experimental validation demonstrates that our method obtains promising objective performance and consistent visual results across various real-world underwater images compared to other eight UIE methods. Our example code and datasets are publicly available at https://github.com/fansuregrin/RAUNE-Net.
</details>
<details>
<summary>摘要</summary>
水下图像提高（UIE）在水下环境中存在许多挑战，包括低对比度、高混杂度、视觉模糊和颜色扭曲。在最近几年，深度学习在科研领域中的应用已经革命化了许多领域，包括UIE。然而，现有的深度学习基于UIE方法通常具有弱Robustness和有限的适应性。在这篇论文中，我们提出一种更可靠和合理的UIE网络，称为RAUNE-Net，通过在网络的瓶颈位置使用高级特征的径向学习和下采样过程中使用两种注意力 manipulate。此外，我们收集了和制作了专门用于评估UIE方法的两个数据集，这些数据集包含不同类型的水下扭曲和降低。实验验证表明，我们的方法在各种真实水下图像上获得了显著的目标性能和一致的视觉结果，与其他八个UIE方法相比。我们的示例代码和数据集公开在https://github.com/fansuregrin/RAUNE-Net。
</details></li>
</ul>
<hr>
<h2 id="1DFormer-Learning-1D-Landmark-Representations-via-Transformer-for-Facial-Landmark-Tracking"><a href="#1DFormer-Learning-1D-Landmark-Representations-via-Transformer-for-Facial-Landmark-Tracking" class="headerlink" title="1DFormer: Learning 1D Landmark Representations via Transformer for Facial Landmark Tracking"></a>1DFormer: Learning 1D Landmark Representations via Transformer for Facial Landmark Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00241">http://arxiv.org/abs/2311.00241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shi Yin, Shijie Huan, Defu Lian, Shangfei Wang, Jinshui Hu, Tao Guo, Bing Yin, Baocai Yin, Cong Liu</li>
<li>for: 该 paper  targets 提高 facial landmark tracking 的性能，并 explore 1D landmark representations 的潜在能力。</li>
<li>methods: 该 paper 提出了一种基于 Transformer 架构的方法，名为 1DFormer，它通过在时间和空间维度进行 token 交互，捕捉 facial landmark 的动态和几何特征，并通过多头注意力机制和循环混合机制来适应长期 landmark 动态。</li>
<li>results: 实验结果表明，1DFormer 能够模型 facial landmark 序列中的长期顺序模式以及内在的面部结构特征，并在 facial landmark tracking 中 achieve state-of-the-art 性能。<details>
<summary>Abstract</summary>
Recently, heatmap regression methods based on 1D landmark representations have shown prominent performance on locating facial landmarks. However, previous methods ignored to make deep explorations on the good potentials of 1D landmark representations for sequential and structural modeling of multiple landmarks to track facial landmarks. To address this limitation, we propose a Transformer architecture, namely 1DFormer, which learns informative 1D landmark representations by capturing the dynamic and the geometric patterns of landmarks via token communications in both temporal and spatial dimensions for facial landmark tracking. For temporal modeling, we propose a recurrent token mixing mechanism, an axis-landmark-positional embedding mechanism, as well as a confidence-enhanced multi-head attention mechanism to adaptively and robustly embed long-term landmark dynamics into their 1D representations; for structure modeling, we design intra-group and inter-group structure modeling mechanisms to encode the component-level as well as global-level facial structure patterns as a refinement for the 1D representations of landmarks through token communications in the spatial dimension via 1D convolutional layers. Experimental results on the 300VW and the TF databases show that 1DFormer successfully models the long-range sequential patterns as well as the inherent facial structures to learn informative 1D representations of landmark sequences, and achieves state-of-the-art performance on facial landmark tracking.
</details>
<details>
<summary>摘要</summary>
最近，基于1D landmark表示方法的热图回归方法已经在识别人脸特征点方面表现出了显著的表现。然而，之前的方法忽略了对1D landmark表示的深入探索，以挖掘出多个特征点的序列和结构模型化的潜在可能性。为此，我们提议一种名为1DFormer的Transformer架构，该架构通过在时间和空间维度进行token通信来学习有用的1D landmark表示。为了模elling长期序列动态，我们提出了循环token混合机制、轴点附加嵌入机制以及信息增强多头注意机制，以适应地 Adaptively和可靠地将长期特征点动态嵌入其1D表示中。为了结构模型化，我们设计了间组和组间结构模型化机制，以编码组件水平以及全局水平的脸部结构模式，并通过1D卷积层进行Token交互，以便在空间维度进行1D表示的修正。实验结果表明，1DFormer成功地模elling了长期序列的特征点动态，以及脸部结构模式，并在人脸特征点跟踪方面实现了状态对应的最佳性能。
</details></li>
</ul>
<hr>
<h2 id="DINO-Mix-Enhancing-Visual-Place-Recognition-with-Foundational-Vision-Model-and-Feature-Mixing"><a href="#DINO-Mix-Enhancing-Visual-Place-Recognition-with-Foundational-Vision-Model-and-Feature-Mixing" class="headerlink" title="DINO-Mix: Enhancing Visual Place Recognition with Foundational Vision Model and Feature Mixing"></a>DINO-Mix: Enhancing Visual Place Recognition with Foundational Vision Model and Feature Mixing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00230">http://arxiv.org/abs/2311.00230</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gaoshuang Huang, Yang Zhou, Xiaofei Hu, Chenglong Zhang, Luying Zhao, Wenjian Gan, Mingbo Hou</li>
<li>for: 本研究旨在提高现实世界中的视觉位置识别（VPR）技术的精度和可靠性，使其能够在复杂的环境下（包括光照变化、季节变化和遮挡物）提供高精度的位置识别结果。</li>
<li>methods: 本研究使用DINOv2模型作为基础网络，进行trimming和精度调整，以提取图像特征。我们提出了一种新的VPR架构，称为DINO-Mix，它将基础视觉模型与特征聚合模块结合，以提取全球稳定和普适的图像特征。我们使用MLP-Mixer型混合模块，将图像特征进行混合，以获得高精度和普适的位置识别结果。</li>
<li>results: 我们在包括光照变化、季节变化和遮挡物的测试集（Tokyo24&#x2F;7、Nordland、SF-XL-Testv1）中，利用我们提出的DINO-Mix架构，实现了Top-1准确率为91.75%、80.18%和82%，分别比现状态艺术方法提高5.14%的精度。<details>
<summary>Abstract</summary>
Utilizing visual place recognition (VPR) technology to ascertain the geographical location of publicly available images is a pressing issue for real-world VPR applications. Although most current VPR methods achieve favorable results under ideal conditions, their performance in complex environments, characterized by lighting variations, seasonal changes, and occlusions caused by moving objects, is generally unsatisfactory. In this study, we utilize the DINOv2 model as the backbone network for trimming and fine-tuning to extract robust image features. We propose a novel VPR architecture called DINO-Mix, which combines a foundational vision model with feature aggregation. This architecture relies on the powerful image feature extraction capabilities of foundational vision models. We employ an MLP-Mixer-based mix module to aggregate image features, resulting in globally robust and generalizable descriptors that enable high-precision VPR. We experimentally demonstrate that the proposed DINO-Mix architecture significantly outperforms current state-of-the-art (SOTA) methods. In test sets having lighting variations, seasonal changes, and occlusions (Tokyo24/7, Nordland, SF-XL-Testv1), our proposed DINO-Mix architecture achieved Top-1 accuracy rates of 91.75%, 80.18%, and 82%, respectively. Compared with SOTA methods, our architecture exhibited an average accuracy improvement of 5.14%.
</details>
<details>
<summary>摘要</summary>
utilizing visual place recognition (VPR) technology to determine the geographical location of publicly available images is a pressing issue for real-world VPR applications. although most current VPR methods achieve favorable results under ideal conditions, their performance in complex environments, characterized by lighting variations, seasonal changes, and occlusions caused by moving objects, is generally unsatisfactory. in this study, we utilize the DINOv2 model as the backbone network for trimming and fine-tuning to extract robust image features. we propose a novel VPR architecture called DINO-Mix, which combines a foundational vision model with feature aggregation. this architecture relies on the powerful image feature extraction capabilities of foundational vision models. we employ an MLP-Mixer-based mix module to aggregate image features, resulting in globally robust and generalizable descriptors that enable high-precision VPR. we experimentally demonstrate that the proposed DINO-Mix architecture significantly outperforms current state-of-the-art (SOTA) methods. in test sets having lighting variations, seasonal changes, and occlusions (Tokyo24/7, Nordland, SF-XL-Testv1), our proposed DINO-Mix architecture achieved Top-1 accuracy rates of 91.75%, 80.18%, and 82%, respectively. compared with SOTA methods, our architecture exhibited an average accuracy improvement of 5.14%.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.CV_2023_11_01/" data-id="cloqtaes500kvgh88hdvqdd8u" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.AI_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T12:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.AI_2023_11_01/">cs.AI - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Generate-and-Pray-Using-SALLMS-to-Evaluate-the-Security-of-LLM-Generated-Code"><a href="#Generate-and-Pray-Using-SALLMS-to-Evaluate-the-Security-of-LLM-Generated-Code" class="headerlink" title="Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code"></a>Generate and Pray: Using SALLMS to Evaluate the Security of LLM Generated Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00889">http://arxiv.org/abs/2311.00889</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed Latif Siddiq, Joanna C. S. Santos</li>
<li>for: 本研究旨在 evaluating Large Language Models (LLMs) 的安全性，以确保 LLMs 生成的代码不仅功能正确，还不会带来漏洞。</li>
<li>methods: 本研究使用了一个框架 named SALLM，它包括一个新的安全中心Python提问集、一个测试生成代码的环境以及一些新的评价指标来评估 LLMs 的安全代码生成能力。</li>
<li>results: 研究发现，现有的评价指标主要关注函数正确性，忽视安全考虑因素，导致 LLMs 可能生成的代码存在漏洞。SALLM 框架可以系统地评估 LLMs 的安全代码生成能力，帮助开发者更好地使用 LLMs 进行软件开发。<details>
<summary>Abstract</summary>
With the growing popularity of Large Language Models (e.g. GitHub Copilot, ChatGPT, etc.) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate Large Language Models (LLMs) do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. There's a clear absence of benchmarks that focus on evaluating the security of the generated code. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Metrics such as pass@k gauge the probability of obtaining the correct code in the top k suggestions. Other popular metrics like BLEU, CodeBLEU, ROUGE, and METEOR similarly emphasize functional accuracy, neglecting security implications. In light of these research gaps, in this paper, we described SALLM, a framework to benchmark LLMs' abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, an evaluation environment to test the generated code, and novel metrics to evaluate the models' performance from the perspective of secure code generation.
</details>
<details>
<summary>摘要</summary>
随着大型语言模型（如GitHub Copilot和ChatGPT等）在软件工程师日常实践中的普及，需要确保这些工具生成的代码不仅功能正确，还要免受漏洞。虽然LLM可以帮助开发者更加生产力，但根据先前的研究表明，LLM可能会生成不安全的代码。这有两个贡献因素。首先，现有的LLM评价数据集不能够准确表征实际的软件工程任务，而是基于竞赛编程挑战或教室型编程任务。在实际应用中，生成的代码将被集成到更大的代码库中， introducing potential security risks。此外，存在一个缺失的评价标准，即评价生成代码的安全性。其次，现有的评价指标主要集中在生成代码的功能正确性上，忽视安全考虑。例如，pass@k指标衡量在topk建议中获得正确代码的概率。其他流行的指标如BLEU、CodeBLEU、ROUGE和METEOR也强调功能正确性，忽视安全后果。为了填补这些研究漏洞，本文提出了SALLM框架，用于系统地评价LLM的安全代码生成能力。SALLM框架包括三个主要组成部分：一个新的安全中心Python提问集，一个用于测试生成代码的评价环境，以及一些新的安全性评价指标。
</details></li>
</ul>
<hr>
<h2 id="SCPO-Safe-Reinforcement-Learning-with-Safety-Critic-Policy-Optimization"><a href="#SCPO-Safe-Reinforcement-Learning-with-Safety-Critic-Policy-Optimization" class="headerlink" title="SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization"></a>SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00880">http://arxiv.org/abs/2311.00880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaafar Mhamed, Shangding Gu</li>
<li>for: 这篇论文旨在提高实际应用中的强化学习环境的安全性。</li>
<li>methods: 该论文使用了受限的Markov决策过程（CMDP），并使用Lagrangian relaxation技术转化为不受限的双问题。</li>
<li>results: 该研究提出了一种新的安全强化学习算法（SCPO），可以自动平衡安全限制的满足和奖励的最大化。该算法在实验中舒适性比基本参考点高。<details>
<summary>Abstract</summary>
Incorporating safety is an essential prerequisite for broadening the practical applications of reinforcement learning in real-world scenarios. To tackle this challenge, Constrained Markov Decision Processes (CMDPs) are leveraged, which introduce a distinct cost function representing safety violations. In CMDPs' settings, Lagrangian relaxation technique has been employed in previous algorithms to convert constrained optimization problems into unconstrained dual problems. However, these algorithms may inaccurately predict unsafe behavior, resulting in instability while learning the Lagrange multiplier. This study introduces a novel safe reinforcement learning algorithm, Safety Critic Policy Optimization (SCPO). In this study, we define the safety critic, a mechanism that nullifies rewards obtained through violating safety constraints. Furthermore, our theoretical analysis indicates that the proposed algorithm can automatically balance the trade-off between adhering to safety constraints and maximizing rewards. The effectiveness of the SCPO algorithm is empirically validated by benchmarking it against strong baselines.
</details>
<details>
<summary>摘要</summary>
要扩大强化学习在实际场景中的应用，保障是一个必不可少的前提。为此，我们利用受限的Markov决策过程（CMDP），它们引入了一个特定的成本函数表示安全违反。在CMDP的设置下，以前的算法使用Lagrangian relaxation技术将受限优化问题转化为无约优化问题的双重问题。然而，这些算法可能会错误地预测不安全的行为，导致学习 Lagrange多余预测的不稳定。本研究提出了一种新的安全强化学习算法，安全批评策略优化（SCPO）。在本研究中，我们定义了安全批评机制，即在违反安全限制时取消获得的奖励。此外，我们的理论分析表明，提案的算法可以自动平衡遵守安全限制和最大化奖励之间的衡量。我们对SCPO算法进行了实验验证，并证明其与强大的基elines进行比较。
</details></li>
</ul>
<hr>
<h2 id="Selectively-Sharing-Experiences-Improves-Multi-Agent-Reinforcement-Learning"><a href="#Selectively-Sharing-Experiences-Improves-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning"></a>Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00865">http://arxiv.org/abs/2311.00865</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mgerstgrasser/super">https://github.com/mgerstgrasser/super</a></li>
<li>paper_authors: Matthias Gerstgrasser, Tom Danino, Sarah Keren</li>
<li>for: 本文提出了一种新的多代理RL方法，即选择性多代理经验转移（Selective Multi-Agent Prioritized Experience Relay，SMAPER），其中代理在训练时共享有限的转移经验。理解是，即使每个代理只有少量相关经验，也可以帮助它们学习。不同于许多其他多代理RL算法，这种方法允许代理在很大程度上自主训练，只需要代理之间的有限通信。</li>
<li>methods: 本文使用了SMAPER算法，其包括以下几个步骤：首先，每个代理从环境中收集经验，并将其分为有价值和无价值两类；然后，每个代理选择一部分有价值经验与其他代理共享，而不是所有的经验；最后，每个代理根据共享的经验进行学习。</li>
<li>results: 作者证明了SMAPER方法可以超过基eline的不共享训练和现状的多代理RL算法。此外，只共享有限的高度相关经验可以超过共享所有经验，并且这种性能提升是对多种参数和DQN变体的robust。参考实现可以在<a target="_blank" rel="noopener" href="https://github.com/mgerstgrasser/super%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/mgerstgrasser/super上找到。</a><details>
<summary>Abstract</summary>
We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized Experience Relay, in which agents share with other agents a limited number of transitions they observe during training. The intuition behind this is that even a small number of relevant experiences from other agents could help each agent learn. Unlike many other multi-agent RL algorithms, this approach allows for largely decentralized training, requiring only a limited communication channel between agents. We show that our approach outperforms baseline no-sharing decentralized training and state-of-the art multi-agent RL algorithms. Further, sharing only a small number of highly relevant experiences outperforms sharing all experiences between agents, and the performance uplift from selective experience sharing is robust across a range of hyperparameters and DQN variants. A reference implementation of our algorithm is available at https://github.com/mgerstgrasser/super.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的多代理RL方法，选择性多代理优先经验转移（Selective Multi-Agent Prioritized Experience Relay，简称SMAPER）。在这种方法中，代理们在训练时分享有限的转移经验。我们的理念是，即使只有一小部分代理的转移经验，也可以帮助每个代理学习。不同于许多其他多代理RL算法，我们的方法允许大量分布式训练，只需要代理之间的有限通信。我们证明了，我们的方法比基eline无共享的分布式训练和现状的多代理RL算法高效。此外，仅分享一小部分高度相关的经验，可以超越分享所有经验 между代理，并且SMAPER的性能提升是对多种 гиперпараметров和DQN变体的 robust。一个Reference实现我们的算法可以在https://github.com/mgerstgrasser/super上找到。
</details></li>
</ul>
<hr>
<h2 id="Training-Dynamics-of-Contextual-N-Grams-in-Language-Models"><a href="#Training-Dynamics-of-Contextual-N-Grams-in-Language-Models" class="headerlink" title="Training Dynamics of Contextual N-Grams in Language Models"></a>Training Dynamics of Contextual N-Grams in Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00863">http://arxiv.org/abs/2311.00863</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luciaquirke/contextual-ngrams">https://github.com/luciaquirke/contextual-ngrams</a></li>
<li>paper_authors: Lucia Quirke, Lovis Heindrich, Wes Gurnee, Neel Nanda</li>
<li>for: 这个论文的目的是提出了语言模型中的上下文 нейроン存在的证据，并证明了这些 neuron 是如何形成的。</li>
<li>methods: 这篇论文使用了一种叫做 second-order circuit 的方法，即在训练过程中，先形成了各个 n-gram 循环 circuit，然后这些循环 circuit 与 German detection circuit 相互作用，形成了一个更大的上下文 neuron 循环。</li>
<li>results: 这篇论文发现了一些异常观察结果，如训练时间序列的同步过渡，以及许多上下文 neuron 在训练早期就已经形成，但是在后期被忘记。这些结果与之前的假设不符，显示了上下文 neuron 的形成是一个慢速的过程，而不是突然的阶段性变化。<details>
<summary>Abstract</summary>
Prior work has shown the existence of contextual neurons in language models, including a neuron that activates on German text. We show that this neuron exists within a broader contextual n-gram circuit: we find late layer neurons which recognize and continue n-grams common in German text, but which only activate if the German neuron is active. We investigate the formation of this circuit throughout training and find that it is an example of what we call a second-order circuit. In particular, both the constituent n-gram circuits and the German detection circuit which culminates in the German neuron form with independent functions early in training - the German detection circuit partially through modeling German unigram statistics, and the n-grams by boosting appropriate completions. Only after both circuits have already formed do they fit together into a second-order circuit. Contrary to the hypotheses presented in prior work, we find that the contextual n-gram circuit forms gradually rather than in a sudden phase transition. We further present a range of anomalous observations such as a simultaneous phase transition in many tasks coinciding with the learning rate warm-up, and evidence that many context neurons form simultaneously early in training but are later unlearned.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Zero-Coordinate-Shift-Whetted-Automatic-Differentiation-for-Physics-informed-Operator-Learning"><a href="#Zero-Coordinate-Shift-Whetted-Automatic-Differentiation-for-Physics-informed-Operator-Learning" class="headerlink" title="Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning"></a>Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00860">http://arxiv.org/abs/2311.00860</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stfc-sciml/zerocoordinateshift">https://github.com/stfc-sciml/zerocoordinateshift</a></li>
<li>paper_authors: Kuangdai Leng, Mallikarjun Shankar, Jeyan Thiyagalingam</li>
<li>for: physics-informed machine learning, particularly for computing high-order derivatives of network output w.r.t. coordinates.</li>
<li>methods:  introduces a novel and lightweight algorithm called Zero Coordinate Shift (ZCS), which simplifies the wanted derivatives from “many-roots-many-leaves” to “one-root-many-leaves” by introducing only one scalar-valued leaf variable for each spatial or temporal dimension.</li>
<li>results:  persistently brings down GPU memory consumption and wall time for training by an order of magnitude, with the savings increasing with problem scale (i.e., number of functions, number of points, and order of PDE).<details>
<summary>Abstract</summary>
Automatic differentiation (AD) is a critical step in physics-informed machine learning, required for computing the high-order derivatives of network output w.r.t. coordinates. In this paper, we present a novel and lightweight algorithm to conduct such AD for physics-informed operator learning, as we call the trick of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf variables, ZCS introduces only one scalar-valued leaf variable for each spatial or temporal dimension, leading to a game-changing performance leap by simplifying the wanted derivatives from "many-roots-many-leaves" to "one-root-many-leaves". ZCS is easy to implement with current deep learning libraries; our own implementation is by extending the DeepXDE package. We carry out a comprehensive benchmark analysis and several case studies, training physics-informed DeepONets to solve partial differential equations (PDEs) without data. The results show that ZCS has persistently brought down GPU memory consumption and wall time for training by an order of magnitude, with the savings increasing with problem scale (i.e., number of functions, number of points and order of PDE). As a low-level optimisation, ZCS entails no restrictions on data, physics (PDEs) or network architecture and does not compromise training results from any aspect.
</details>
<details>
<summary>摘要</summary>
自动 diferenciación (AD) es un paso crítico en aprendizaje de máquina informado por física, necesario para calcular las altas derivadas de salida de red w.r.t. coordenadas. En este artículo, presentamos un algoritmo nuevo y liviano para realizar AD para aprendizaje de operadores informados por física, como llamamos la truca de Zero Coordinate Shift (ZCS). En lugar de hacer que todas las variables de coordenada sean variables de hoja, ZCS introduce solo una variable de hoja escalar para cada dimensión espacial o temporal, lo que conduce a un salto de rendimiento revolucionario simplificando las derivadas deseadas de "muchas raíces muchas hojas" a "una raíz muchas hojas". ZCS es fácil de implementar con las bibliotecas de aprendizaje profundo actuales; nuestra propia implementación es mediante la extensión del paquete DeepXDE. Realizamos un análisis de benchmark completo y varios estudios de caso, entrenando redes DeepONet informadas por física para resolver ecuaciones diferenciales parciales (PDEs) sin datos. Los resultados muestran que ZCS ha reducido consumo de memoria de GPU y tiempo de pared de entrenamiento en orden de magnitud, con los ahorros aumentando con el tamaño del problema (es decir, el número de funciones, el número de puntos y el orden de PDE). Como una optimización de bajo nivel, ZCS no impone restricciones en los datos, la física (PDEs) ni la arquitectura de la red y no compromete los resultados de entrenamiento en ningún aspecto.
</details></li>
</ul>
<hr>
<h2 id="Optimal-Cost-Constrained-Adversarial-Attacks-For-Multiple-Agent-Systems"><a href="#Optimal-Cost-Constrained-Adversarial-Attacks-For-Multiple-Agent-Systems" class="headerlink" title="Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems"></a>Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00859">http://arxiv.org/abs/2311.00859</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqing Lu, Guanlin Liu, Lifeng Cai, Weiyu Xu</li>
<li>for: 这篇论文主要关注于实现多源攻击者在多智能系统中实现最佳攻击策略。</li>
<li>methods: 本论文提出一种基于内步骤静态攻击资源分配优化和间步骤动态计划的优化方法，以实现多源攻击者在多智能系统中的最佳攻击。</li>
<li>results: 本论文的数据显示，提出的攻击策略可以对攻击的智能系统实现内步骤静态攻击资源分配优化，并可以对攻击的智能系统实现间步骤动态计划。这些攻击策略可以对攻击的智能系统实现重要的攻击减少。<details>
<summary>Abstract</summary>
Finding optimal adversarial attack strategies is an important topic in reinforcement learning and the Markov decision process. Previous studies usually assume one all-knowing coordinator (attacker) for whom attacking different recipient (victim) agents incurs uniform costs. However, in reality, instead of using one limitless central attacker, the attacks often need to be performed by distributed attack agents. We formulate the problem of performing optimal adversarial agent-to-agent attacks using distributed attack agents, in which we impose distinct cost constraints on each different attacker-victim pair. We propose an optimal method integrating within-step static constrained attack-resource allocation optimization and between-step dynamic programming to achieve the optimal adversarial attack in a multi-agent system. Our numerical results show that the proposed attacks can significantly reduce the rewards received by the attacked agents.
</details>
<details>
<summary>摘要</summary>
找到最佳反对攻击策略是在强化学习和马克福德决策过程中非常重要的主题。先前的研究通常假设一个全知的协调者（攻击者），对不同的接收者（受害者）机器人进行攻击，卷入的成本均为一个常数。然而，在现实中，攻击通常需要由分布式的攻击者进行，而不是一个无限的中央攻击者。我们将在分布式攻击者中表述最佳反对攻击策略，并在每个不同攻击者-受害者对中强制实施不同的成本限制。我们提出一种折衔的方法，将在每步骤内的静态受限攻击资源分配优化与每步骤之间的动态规划相结合，以实现最佳反对攻击策略。我们的数据分析结果表明，我们的攻击方法可以在多机器人系统中很大程度地减少被攻击者的奖励。
</details></li>
</ul>
<hr>
<h2 id="A-Multi-Agent-Reinforcement-Learning-Framework-for-Evaluating-the-U-S-Ending-the-HIV-Epidemic-Plan"><a href="#A-Multi-Agent-Reinforcement-Learning-Framework-for-Evaluating-the-U-S-Ending-the-HIV-Epidemic-Plan" class="headerlink" title="A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S. Ending the HIV Epidemic Plan"></a>A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S. Ending the HIV Epidemic Plan</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00855">http://arxiv.org/abs/2311.00855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dinesh Sharma, Ankit Shah, Chaitra Gopalappa</li>
<li>for: 这个论文的目的是为了帮助决策公共卫生政策，具体来说是通过多智能型强化学习（MARL）模型来分析和优化感染人类免疫缺乏病毒（HIV）的治疗和预防措施，以帮助降低HIV感染新增 casos。</li>
<li>methods: 这篇论文使用了多智能型强化学习（MARL）模型，这种模型可以考虑到不同地区之间的流行病学交互作用，并且可以为每个地区分析和优化HIV的治疖和预防措施。</li>
<li>results: 实验分析表明，使用MARL模型可以生成与单个智能型强化学习（RL）模型不同的优化策略，这表明了不同地区之间的流行病学交互作用的影响，并且提供了一种可靠的方法来分析和优化HIV的治疖和预防措施。<details>
<summary>Abstract</summary>
Human immunodeficiency virus (HIV) is a major public health concern in the United States, with about 1.2 million people living with HIV and 35,000 newly infected each year. There are considerable geographical disparities in HIV burden and care access across the U.S. The 2019 Ending the HIV Epidemic (EHE) initiative aims to reduce new infections by 90% by 2030, by improving coverage of diagnoses, treatment, and prevention interventions and prioritizing jurisdictions with high HIV prevalence. Identifying optimal scale-up of intervention combinations will help inform resource allocation. Existing HIV decision analytic models either evaluate specific cities or the overall national population, thus overlooking jurisdictional interactions or differences. In this paper, we propose a multi-agent reinforcement learning (MARL) model, that enables jurisdiction-specific decision analyses but in an environment with cross-jurisdictional epidemiological interactions. In experimental analyses, conducted on jurisdictions within California and Florida, optimal policies from MARL were significantly different than those generated from single-agent RL, highlighting the influence of jurisdictional variations and interactions. By using comprehensive modeling of HIV and formulations of state space, action space, and reward functions, this work helps demonstrate the strengths and applicability of MARL for informing public health policies, and provides a framework for expanding to the national-level to inform the EHE.
</details>
<details>
<summary>摘要</summary>
人体免疫缺陷病毒（HIV）是美国公共卫生中的一个重要问题，约有120万人患有HIV，每年新感染35000人。美国各地有较大的HIV荷重和护理访问差异。2019年的结束HIV疫苗计划（EHE）目标是在2030年减少新感染90%，通过提高诊断、治疗和预防 intervención的覆盖率，并优先级高HIV感染地区。确定最佳扩大 intervención的组合将有助于资源分配。现有的HIV决策分析模型 either评估特定城市或整个国家人口，因此忽视了地区交互或差异。在这篇论文中，我们提出了多代理人学习（MARL）模型，允许地区特定的决策分析，但在具有跨地区疫学交互的环境中进行。在加利福尼亚和佛罗里达的实验分析中，MARL优化的策略与单代理人学习生成的策略有显著差异，这 highlights了地区差异和交互的影响。通过全面地模型HIV和形式状态、行动空间和奖励函数，这种工作帮助表明MARL的优势和适用性，并提供了扩展到国家水平以 inform EHE的框架。
</details></li>
</ul>
<hr>
<h2 id="healthAIChain-Improving-security-and-safety-using-Blockchain-Technology-applications-in-AI-based-healthcare-systems"><a href="#healthAIChain-Improving-security-and-safety-using-Blockchain-Technology-applications-in-AI-based-healthcare-systems" class="headerlink" title="healthAIChain: Improving security and safety using Blockchain Technology applications in AI-based healthcare systems"></a>healthAIChain: Improving security and safety using Blockchain Technology applications in AI-based healthcare systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00842">http://arxiv.org/abs/2311.00842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naresh Kshetri, James Hutson, Revathy G</li>
<li>for: 这篇论文旨在探讨使用区块链技术来提高医疗系统的安全性和可靠性，以及在医疗和医疗相关领域中应用区块链技术的可能性。</li>
<li>methods: 本论文使用了区块链技术来解决医疗系统中的安全性和可靠性问题，并且对区块链技术在医疗系统中的应用进行了评估和分析。</li>
<li>results: 研究表明，使用区块链技术可以提高医疗系统的安全性和可靠性，同时也可以提高医疗系统的性能和可扩展性。此外，本论文还提出了一种基于AI技术的医疗区块链模型（healthAIChain），以提高患者数据的安全性和可靠性。<details>
<summary>Abstract</summary>
Blockchain as a digital ledger for keeping records of digital transactions and other information, it is secure and decentralized technology. The globally growing number of digital population every day possesses a significant threat to online data including the medical and patients data. After bitcoin, blockchain technology has emerged into a general-purpose technology with applications in medical industries and healthcare. Blockchain can promote highly configurable openness while retaining the highest security standards for critical data of medical patients. Referred to as distributed record keeping for healthcare systems which makes digital assets unalterable and transparent via a cryptographic hash and decentralized network. The study delves into the security and safety improvement associated with implementing blockchain in AI-based healthcare systems. Blockchain-enabled AI tackles the existing issues related to security, performance efficiencies, and safety in healthcare systems. We have also examined the Artificial Intelligence in healthcare and medical industry, potential areas, open questions concerning the blockchain in healthcare systems. Finally, the article proposed an AI-based healthcare blockchain model (healthAIChain) to improve patients data and security.
</details>
<details>
<summary>摘要</summary>
链情为数字日志的保存记录数字交易和其他信息，它是一种安全和分散的技术。全球每天增长的数字人口对于在线数据，包括医疗和患者数据，具有重要的威胁。自比特币以后，区块链技术在医疗领域和卫生保健领域得到应用。区块链可以实现高度可配置的开放性，同时保持最高的安全标准 для医疗患者的敏感数据。被称为分布式记录系统，使得数字资产不可改变和透明，通过 крипτографиic Hash和分散网络。这篇文章研究了在区块链技术应用于人工智能基础设施医疗系统中的安全性和可靠性问题。此外，文章还考虑了人工智能在医疗和医疗保健领域的潜在领域和开放问题。最后，文章提出了一种基于人工智能的医疗链模型（健康AI链），以提高患者数据和安全性。
</details></li>
</ul>
<hr>
<h2 id="Constant-time-Motion-Planning-with-Anytime-Refinement-for-Manipulation"><a href="#Constant-time-Motion-Planning-with-Anytime-Refinement-for-Manipulation" class="headerlink" title="Constant-time Motion Planning with Anytime Refinement for Manipulation"></a>Constant-time Motion Planning with Anytime Refinement for Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00837">http://arxiv.org/abs/2311.00837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Itamar Mishani, Hayden Feddock, Maxim Likhachev</li>
<li>for: 这个论文是为了提高机器人抓取系统的自主性和可靠性而写的。</li>
<li>methods: 这个论文使用了一种常数时间动态规划（CTMP）算法，并将其与任何时间修正算法结合使用。</li>
<li>results: 该方法可以快速生成初始解决方案，并在分配的时间预算内进行不断修正，以达到一个平衡点， simultanously guaranteeing the ability to generate motion plans within a user-defined time bound.<details>
<summary>Abstract</summary>
Robotic manipulators are essential for future autonomous systems, yet limited trust in their autonomy has confined them to rigid, task-specific systems. The intricate configuration space of manipulators, coupled with the challenges of obstacle avoidance and constraint satisfaction, often makes motion planning the bottleneck for achieving reliable and adaptable autonomy. Recently, a class of constant-time motion planners (CTMP) was introduced. These planners employ a preprocessing phase to compute data structures that enable online planning provably guarantee the ability to generate motion plans, potentially sub-optimal, within a user defined time bound. This framework has been demonstrated to be effective in a number of time-critical tasks. However, robotic systems often have more time allotted for planning than the online portion of CTMP requires, time that can be used to improve the solution. To this end, we propose an anytime refinement approach that works in combination with CTMP algorithms. Our proposed framework, as it operates as a constant time algorithm, rapidly generates an initial solution within a user-defined time threshold. Furthermore, functioning as an anytime algorithm, it iteratively refines the solution's quality within the allocated time budget. This enables our approach to strike a balance between guaranteed fast plan generation and the pursuit of optimization over time. We support our approach by elucidating its analytical properties, showing the convergence of the anytime component towards optimal solutions. Additionally, we provide empirical validation through simulation and real-world demonstrations on a 6 degree-of-freedom robot manipulator, applied to an assembly domain.
</details>
<details>
<summary>摘要</summary>
机器人 manipulate 是未来自主系统的关键组件，但它们的自主性受限，通常只能用于固定的任务特定系统。 manipulate 的复杂配置空间，以及避免障碍物和约束满足的挑战，通常使动作规划成为自主系统的瓶颈，阻碍它们实现可靠和适应的自主性。 recent 年，一种叫做常数时间动作规划器（CTMP）的新类型的动作规划器被引入。这种规划器在先期处理阶段计算出数据结构，以在线规划时保证能够在用户定义的时间上限内生成动作计划，可能不optimal。这个框架在许多时间敏感任务中得到证明。然而，机器人系统经常有更多的时间用于规划，而不是 CTMP 在线部分所需的时间。为此，我们提出了一种任何时间精度增强方法，它在 CTMP 算法的基础上运行，快速生成用户定义的时间上限内的初始解决方案。此外，作为任何时间算法，它会逐渐改进解决方案的质量，在分配的时间预算内。这使我们的方法能够协调快速生成的解决方案和时间的优化。我们支持我们的方法通过分析性质的证明，显示了任何时间组件的收敛性，以及在实际示范和实验中的验证。Note: Please note that the translation is done using a machine translation tool, and may not be perfect or idiomatic.
</details></li>
</ul>
<hr>
<h2 id="Beyond-Still-Images-Robust-Multi-Stream-Spatiotemporal-Networks"><a href="#Beyond-Still-Images-Robust-Multi-Stream-Spatiotemporal-Networks" class="headerlink" title="Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks"></a>Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00800">http://arxiv.org/abs/2311.00800</a></li>
<li>repo_url: None</li>
<li>paper_authors: AmirHosein Fadaei, Mohammad-Reza A. Dehaqani</li>
<li>for: 研究自然视觉的一种特点是对输入变化的抵抗能力，从而生成不变的环境表示。在深度神经网络中，certain forms of spatial input variation can cause significant changes in the representations of video content.</li>
<li>methods: 我们采用了一种简单的多流模型，以探索其在面对空间和时间变化时的抗变化能力。我们在训练时包含视频和时间流，以便在视频理解任务中提高准确率和map值。</li>
<li>results: 结果表明，在训练时包含视频和时间流可以降低图像和视频理解任务中的准确率和map值下降，相对下降1.36%和3.14%。<details>
<summary>Abstract</summary>
A defining characteristic of natural vision is its ability to withstand a variety of input alterations, resulting in the creation of an invariant representation of the surroundings. While convolutional neural networks exhibit resilience to certain forms of spatial input variation, modifications in the spatial and temporal aspects can significantly affect the representations of video content in deep neural networks. Inspired by the resilience of natural vision to input variations, we employ a simple multi-stream model to explore its potential to address spatiotemporal changes by including temporal features. Our primary goal is to introduce a video-trained model and evaluate its robustness to diverse image and video inputs, with a particular focus on exploring the role of temporal features in invariant recognition. Results show that including videos and the temporal stream during training mitigates the decline in accuracy and mAP in image and video understanding tasks by 1.36% and 3.14%, respectively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Tipping-Points-of-Evolving-Epidemiological-Networks-Machine-Learning-Assisted-Data-Driven-Effective-Modeling"><a href="#Tipping-Points-of-Evolving-Epidemiological-Networks-Machine-Learning-Assisted-Data-Driven-Effective-Modeling" class="headerlink" title="Tipping Points of Evolving Epidemiological Networks: Machine Learning-Assisted, Data-Driven Effective Modeling"></a>Tipping Points of Evolving Epidemiological Networks: Machine Learning-Assisted, Data-Driven Effective Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00797">http://arxiv.org/abs/2311.00797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikolaos Evangelou, Tianqi Cui, Juan M. Bello-Rivas, Alexei Makeev, Ioannis G. Kevrekidis</li>
<li>For: The paper studies the tipping point collective dynamics of an adaptive susceptible-infected-susceptible (SIS) epidemiological network using a data-driven, machine learning-assisted approach.* Methods: The paper identifies a parameter-dependent effective stochastic differential equation (eSDE) in terms of physically meaningful coarse mean-field variables through a deep-learning ResNet architecture inspired by numerical stochastic integrators. The paper also constructs an approximate effective bifurcation diagram based on the identified drift term of the eSDE and compares it with the mean-field SIS model bifurcation diagram.* Results: The paper observes a subcritical Hopf bifurcation in the evolving network’s effective SIS dynamics, which causes the tipping point behavior and leads to large amplitude collective oscillations that spontaneously arise from the neighborhood of a (noisy) stationary state. The paper studies the statistics of these rare events using repeated brute force simulations and established mathematical&#x2F;computational tools, and demonstrates that the collective SDE can also be identified and the rare events computations performed in terms of data-driven coarse observables obtained through manifold learning techniques, such as Diffusion Maps.<details>
<summary>Abstract</summary>
We study the tipping point collective dynamics of an adaptive susceptible-infected-susceptible (SIS) epidemiological network in a data-driven, machine learning-assisted manner. We identify a parameter-dependent effective stochastic differential equation (eSDE) in terms of physically meaningful coarse mean-field variables through a deep-learning ResNet architecture inspired by numerical stochastic integrators. We construct an approximate effective bifurcation diagram based on the identified drift term of the eSDE and contrast it with the mean-field SIS model bifurcation diagram. We observe a subcritical Hopf bifurcation in the evolving network's effective SIS dynamics, that causes the tipping point behavior; this takes the form of large amplitude collective oscillations that spontaneously -- yet rarely -- arise from the neighborhood of a (noisy) stationary state. We study the statistics of these rare events both through repeated brute force simulations and by using established mathematical/computational tools exploiting the right-hand-side of the identified SDE. We demonstrate that such a collective SDE can also be identified (and the rare events computations also performed) in terms of data-driven coarse observables, obtained here via manifold learning techniques, in particular Diffusion Maps. The workflow of our study is straightforwardly applicable to other complex dynamics problems exhibiting tipping point dynamics.
</details>
<details>
<summary>摘要</summary>
我们研究一个自适应感染者-病人-自适应感染者（SIS）流行病学网络的集合动力学在数据驱动、机器学习协助下进行研究。我们通过深度学习ResNet架构，从数值随机 интеграル中灵感，对 Physically meaningful 的宽泛平均变量进行定义，并construct了一个approximate的效果枢轴图。我们比较了这个枢轴图与传统的SIS模型的分化图，发现在流行病学网络的有效SIS动力学中存在一个低于极限的Hopf分化。这种分化导致了 collective 振荡的出现，这些振荡会在静态状态附近自发生，并且具有大 amplitudo 和罕见的特点。我们通过重复的粗糙 simulate 和使用已知的数学/计算工具，研究这些罕见事件的统计特性。我们还示出，这种集合SDE可以通过数据驱动的粗糙观察量来定义（并且进行罕见事件计算），例如通过抽象学习技术，特别是Diffusion Maps。我们的工作流程可以 straightforwardly 应用于其他复杂动力学问题，例如其他的tipping point动力学问题。
</details></li>
</ul>
<hr>
<h2 id="SAGE-Smart-home-Agent-with-Grounded-Execution"><a href="#SAGE-Smart-home-Agent-with-Grounded-Execution" class="headerlink" title="SAGE: Smart home Agent with Grounded Execution"></a>SAGE: Smart home Agent with Grounded Execution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00772">http://arxiv.org/abs/2311.00772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dmitriy Rivkin, Francois Hogan, Amal Feriani, Abhisek Konar, Adam Sigal, Steve Liu, Greg Dudek</li>
<li>for: 这篇论文旨在提高智能家居助手的灵活性，以更好地满足用户需求。</li>
<li>methods: 该框架使用自然语言处理技术和机器学习模型，以自动推理用户需求和设备状态，并通过对设备API文档进行探索和自动代码生成来实现智能家居任务。</li>
<li>results: 在43个智能家居任务中，SAGE取得了23个成功，舒过现有的LLM基eline（5&#x2F;43）。<details>
<summary>Abstract</summary>
This article introduces SAGE (Smart home Agent with Grounded Execution), a framework designed to maximize the flexibility of smart home assistants by replacing manually-defined inference logic with an LLM-powered autonomous agent system. SAGE integrates information about user preferences, device states, and external factors (such as weather and TV schedules) through the orchestration of a collection of tools. SAGE's capabilities include learning user preferences from natural-language utterances, interacting with devices by reading their API documentation, writing code to continuously monitor devices, and understanding natural device references. To evaluate SAGE, we develop a benchmark of 43 highly challenging smart home tasks, where SAGE successfully achieves 23 tasks, significantly outperforming existing LLM-enabled baselines (5/43).
</details>
<details>
<summary>摘要</summary>
Note:* "智能家居代理人" (Smart Home Agent) is a simplified Chinese term that refers to a software agent that can perform tasks and make decisions on behalf of a user in a smart home environment.* "地面执行" (Grounded Execution) refers to the ability of the agent to execute tasks in the real world, by interacting with physical devices and sensors.* "LLM-powered" means that the agent is powered by a large language model (LLM), which allows it to understand and generate natural language, and to learn from its experiences.* "natural-language utterances" refers to the way users communicate with the agent, using natural language to express their preferences and requests.* "device states" refers to the current status of the devices in the smart home environment, such as whether a light is on or off.* "external factors" refers to information that is not specific to the smart home environment, such as the weather or TV schedules.* "orchestration of a collection of tools" refers to the way the agent uses a variety of tools and techniques to perform tasks and achieve its goals.* "benchmark of 43 highly challenging smart home tasks" refers to a set of tasks that are difficult and diverse, and that test the capabilities of the agent in different ways.* "outperforming existing LLM-enabled baselines" means that the agent performs better than other agents that have been trained on similar tasks and data.
</details></li>
</ul>
<hr>
<h2 id="Hand-Gesture-Classification-on-Praxis-Dataset-Trading-Accuracy-for-Expense"><a href="#Hand-Gesture-Classification-on-Praxis-Dataset-Trading-Accuracy-for-Expense" class="headerlink" title="Hand Gesture Classification on Praxis Dataset: Trading Accuracy for Expense"></a>Hand Gesture Classification on Praxis Dataset: Trading Accuracy for Expense</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00767">http://arxiv.org/abs/2311.00767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rahat Islam, Kenneth Lai, Svetlana Yanushkevich</li>
<li>for: 这种研究旨在开发一种高效、准确、便宜的 cortical pathology 诊断方法，用于多种医疗应用。</li>
<li>methods: 该研究使用了RGB-Depth感知器记录的 ‘skeletal’ 数据，从Praxis数据集中提取了体 JOINT 坐标数据，并使用了窗口技术和深度学习架构，如RNN和LSTM，进行手势识别。</li>
<li>results: 该研究实现了使用体 JOINT 数据进行手势识别，达到了70.8%的总准确率，并且通过分析时间序列数据使用LSTM进行手势识别，达到了74.3%和67.3%的手势识别率。<details>
<summary>Abstract</summary>
In this paper, we investigate hand gesture classifiers that rely upon the abstracted 'skeletal' data recorded using the RGB-Depth sensor. We focus on 'skeletal' data represented by the body joint coordinates, from the Praxis dataset. The PRAXIS dataset contains recordings of patients with cortical pathologies such as Alzheimer's disease, performing a Praxis test under the direction of a clinician. In this paper, we propose hand gesture classifiers that are more effective with the PRAXIS dataset than previously proposed models. Body joint data offers a compressed form of data that can be analyzed specifically for hand gesture recognition. Using a combination of windowing techniques with deep learning architecture such as a Recurrent Neural Network (RNN), we achieved an overall accuracy of 70.8% using only body joint data. In addition, we investigated a long-short-term-memory (LSTM) to extract and analyze the movement of the joints through time to recognize the hand gestures being performed and achieved a gesture recognition rate of 74.3% and 67.3% for static and dynamic gestures, respectively. The proposed approach contributed to the task of developing an automated, accurate, and inexpensive approach to diagnosing cortical pathologies for multiple healthcare applications.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了基于RGB-深度传感器记录的抽象 '骨架' 数据的手势识别器。我们专注于Praxis数据集中的体 JOINT坐标数据。Praxis数据集包含由Alzheimer病患者在临床医生指导下进行的Praxis测试记录。在这篇论文中，我们提议了与Praxis数据集更有效的手势识别器。 body JOINT数据提供了一种压缩形式的数据，可以专门对手势识别进行分析。通过窗口技术和深度学习架构如回归神经网络（RNN），我们实现了使用只body JOINT数据的总准确率为70.8%。此外，我们还使用循环神经网络（LSTM）来抽取和分析关节的运动，以识别手势的执行，并实现了手势识别率为74.3%和67.3% для静止和动态手势，分别。我们的方法对于诊断 cortical pathology 的多种医疗应用做出了贡献。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Design-and-Use-Tools-for-Robotic-Manipulation"><a href="#Learning-to-Design-and-Use-Tools-for-Robotic-Manipulation" class="headerlink" title="Learning to Design and Use Tools for Robotic Manipulation"></a>Learning to Design and Use Tools for Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00754">http://arxiv.org/abs/2311.00754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziang Liu, Stephen Tian, Michelle Guo, C. Karen Liu, Jiajun Wu</li>
<li>for: 本研究旨在设计一个可以快速实现多个目标的抓取机制，并且可以在实际环境中运行。</li>
<li>methods: 本研究使用深度学习来结合形式和控制的优化，实现设计一个可以实现多个目标的抓取机制。</li>
<li>results: 本研究在模拟的抓取任务中显示了更高的效率和可扩展性，并且可以在实际环境中运行。此外，研究还显示了可以通过将设计政策和控制政策分开来实现更好的可控性和可扩展性。<details>
<summary>Abstract</summary>
When limited by their own morphologies, humans and some species of animals have the remarkable ability to use objects from the environment toward accomplishing otherwise impossible tasks. Robots might similarly unlock a range of additional capabilities through tool use. Recent techniques for jointly optimizing morphology and control via deep learning are effective at designing locomotion agents. But while outputting a single morphology makes sense for locomotion, manipulation involves a variety of strategies depending on the task goals at hand. A manipulation agent must be capable of rapidly prototyping specialized tools for different goals. Therefore, we propose learning a designer policy, rather than a single design. A designer policy is conditioned on task information and outputs a tool design that helps solve the task. A design-conditioned controller policy can then perform manipulation using these tools. In this work, we take a step towards this goal by introducing a reinforcement learning framework for jointly learning these policies. Through simulated manipulation tasks, we show that this framework is more sample efficient than prior methods in multi-goal or multi-variant settings, can perform zero-shot interpolation or fine-tuning to tackle previously unseen goals, and allows tradeoffs between the complexity of design and control policies under practical constraints. Finally, we deploy our learned policies onto a real robot. Please see our supplementary video and website at https://robotic-tool-design.github.io/ for visualizations.
</details>
<details>
<summary>摘要</summary>
In this work, we introduce a reinforcement learning framework for jointly learning these policies. Through simulated manipulation tasks, we show that our framework is more sample efficient than prior methods in multi-goal or multi-variant settings, can perform zero-shot interpolation or fine-tuning to tackle previously unseen goals, and allows tradeoffs between the complexity of design and control policies under practical constraints. Finally, we deploy our learned policies onto a real robot, and provide visualizations on our supplementary website at <https://robotic-tool-design.github.io/>.
</details></li>
</ul>
<hr>
<h2 id="Are-These-the-Same-Apple-Comparing-Images-Based-on-Object-Intrinsics"><a href="#Are-These-the-Same-Apple-Comparing-Images-Based-on-Object-Intrinsics" class="headerlink" title="Are These the Same Apple? Comparing Images Based on Object Intrinsics"></a>Are These the Same Apple? Comparing Images Based on Object Intrinsics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00750">http://arxiv.org/abs/2311.00750</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/s-tian/cute">https://github.com/s-tian/cute</a></li>
<li>paper_authors: Klemen Kotar, Stephen Tian, Hong-Xing Yu, Daniel L. K. Yamins, Jiajun Wu</li>
<li>for:  measure image similarity purely based on intrinsic object properties that define object identity, especially for general object categories.</li>
<li>methods:  combine deep features learned from contrastive self-supervised learning with foreground filtering.</li>
<li>results:  a strong baseline that best measures intrinsic object-centric image similarity among current methods, and can aid in downstream applications such as acting as an analog for human subjects and improving generalizable re-identification.Here’s the Chinese text in the format you requested:</li>
<li>for:  measure image similarity purely based on intrinsic object properties that define object identity, especially for general object categories.</li>
<li>methods:  combine deep features learned from contrastive self-supervised learning with foreground filtering.</li>
<li>results:  a strong baseline that best measures intrinsic object-centric image similarity among current methods, and can aid in downstream applications such as acting as an analog for human subjects and improving generalizable re-identification.<details>
<summary>Abstract</summary>
The human visual system can effortlessly recognize an object under different extrinsic factors such as lighting, object poses, and background, yet current computer vision systems often struggle with these variations. An important step to understanding and improving artificial vision systems is to measure image similarity purely based on intrinsic object properties that define object identity. This problem has been studied in the computer vision literature as re-identification, though mostly restricted to specific object categories such as people and cars. We propose to extend it to general object categories, exploring an image similarity metric based on object intrinsics. To benchmark such measurements, we collect the Common paired objects Under differenT Extrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different extrinsic factors such as lighting, poses, and imaging conditions. While existing methods such as LPIPS and CLIP scores do not measure object intrinsics well, we find that combining deep features learned from contrastive self-supervised learning with foreground filtering is a simple yet effective approach to approximating the similarity. We conduct an extensive survey of pre-trained features and foreground extraction methods to arrive at a strong baseline that best measures intrinsic object-centric image similarity among current methods. Finally, we demonstrate that our approach can aid in downstream applications such as acting as an analog for human subjects and improving generalizable re-identification. Please see our project website at https://s-tian.github.io/projects/cute/ for visualizations of the data and demos of our metric.
</details>
<details>
<summary>摘要</summary>
人类视觉系统可以很容易地认出不同的外部因素（如照明、物体姿态和背景）下的物体，而现代计算机视觉系统却经常遇到这些变化的困难。为了更好地理解和改进人工视觉系统，我们需要测量图像相似性基于物体内部特征。这个问题在计算机视觉文献中已经被研究为重复识别，但主要局限于特定的物体类别，如人脸和汽车。我们提议扩展到普通的物体类别，研究基于物体内部特征的图像相似性度量。为了评估这种测量，我们收集了18,000张不同照明、姿态和捕捉条件的图像，组成了Common paired objects Under differenT Extrinsics（CUTE）数据集。现有的方法，如LPIPS和CLIP分数，不能很好地测量物体内部特征，但我们发现将深度特征通过对比自我supervised学习学习出来的特征与前景过滤结合是一种简单 yet effective的方法来估算图像相似性。我们进行了广泛的预训练特征和前景EXTRACTION方法的测试，以达到当前最强的基eline，可以最好地测量物体内部特征相似性。最后，我们示出了我们的方法可以在下游应用中提供人类参照和通用重复识别等功能。请参考我们项目网站https://s-tian.github.io/projects/cute/，可以查看数据的视觉化和我们度量的示例。
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Creative-Mind-Language-Model-As-Hierarchical-Policy-For-Improved-Exploration-on-Challenging-Problem-Solving"><a href="#Unleashing-the-Creative-Mind-Language-Model-As-Hierarchical-Policy-For-Improved-Exploration-on-Challenging-Problem-Solving" class="headerlink" title="Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving"></a>Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00694">http://arxiv.org/abs/2311.00694</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lz1oceani/llm-as-hierarchical-policy">https://github.com/lz1oceani/llm-as-hierarchical-policy</a></li>
<li>paper_authors: Zhan Ling, Yunhao Fang, Xuanlin Li, Tongzhou Mu, Mingu Lee, Reza Pourreza, Roland Memisevic, Hao Su</li>
<li>for: This paper aims to improve the ability of large language models (LLMs) to solve challenging reasoning problems by framing LLMs as hierarchical policies via in-context learning.</li>
<li>methods: The proposed approach uses a visionary leader to propose multiple diverse high-level problem-solving tactics as hints, accompanied by a follower that executes detailed problem-solving processes following each of the high-level instructions. The follower samples multiple reasoning chains to tackle the problem, generating a solution group for each leader proposal.</li>
<li>results: The approach improves the final answer accuracy on challenging problems in the MATH dataset and produces meaningful and inspiring hints that enhance problem-solving strategy exploration.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have achieved tremendous progress, yet they still often struggle with challenging reasoning problems. Current approaches address this challenge by sampling or searching detailed and low-level reasoning chains. However, these methods are still limited in their exploration capabilities, making it challenging for correct solutions to stand out in the huge solution space. In this work, we unleash LLMs' creative potential for exploring multiple diverse problem solving strategies by framing an LLM as a hierarchical policy via in-context learning. This policy comprises of a visionary leader that proposes multiple diverse high-level problem-solving tactics as hints, accompanied by a follower that executes detailed problem-solving processes following each of the high-level instruction. The follower uses each of the leader's directives as a guide and samples multiple reasoning chains to tackle the problem, generating a solution group for each leader proposal. Additionally, we propose an effective and efficient tournament-based approach to select among these explored solution groups to reach the final answer. Our approach produces meaningful and inspiring hints, enhances problem-solving strategy exploration, and improves the final answer accuracy on challenging problems in the MATH dataset. Code will be released at https://github.com/lz1oceani/LLM-As-Hierarchical-Policy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-Task-personalized-Multimodal-Few-shot-Learning-for-Visually-rich-Document-Entity-Retrieval"><a href="#On-Task-personalized-Multimodal-Few-shot-Learning-for-Visually-rich-Document-Entity-Retrieval" class="headerlink" title="On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval"></a>On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00693">http://arxiv.org/abs/2311.00693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayi Chen, Hanjun Dai, Bo Dai, Aidong Zhang, Wei Wei</li>
<li>for: 这 paper 的目的是研究在新的文档类型不断出现的情况下，如何实现Visual-rich document entity retrieval (VDER)  task，特别是在每个任务中具有个性化的目标类型和不同文档中的实体出现方式。</li>
<li>methods: 这 paper 使用了任务意识度 meta-learning 框架，包括一个层次解码器 (HC) 和一种对比学习策略 (ContrastProtoNet)，以实现效果的任务个性化。</li>
<li>results:  эксперименталь结果表明，这些方法可以大幅提高流行的 meta-learning 基eline 的稳定性。<details>
<summary>Abstract</summary>
Visually-rich document entity retrieval (VDER), which extracts key information (e.g. date, address) from document images like invoices and receipts, has become an important topic in industrial NLP applications. The emergence of new document types at a constant pace, each with its unique entity types, presents a unique challenge: many documents contain unseen entity types that occur only a couple of times. Addressing this challenge requires models to have the ability of learning entities in a few-shot manner. However, prior works for Few-shot VDER mainly address the problem at the document level with a predefined global entity space, which doesn't account for the entity-level few-shot scenario: target entity types are locally personalized by each task and entity occurrences vary significantly among documents. To address this unexplored scenario, this paper studies a novel entity-level few-shot VDER task. The challenges lie in the uniqueness of the label space for each task and the increased complexity of out-of-distribution (OOD) contents. To tackle this novel task, we present a task-aware meta-learning based framework, with a central focus on achieving effective task personalization that distinguishes between in-task and out-of-task distribution. Specifically, we adopt a hierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) to achieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boost future research in the field of entity-level few-shot VDER. Experimental results demonstrate our approaches significantly improve the robustness of popular meta-learning baselines.
</details>
<details>
<summary>摘要</summary>
带有视觉 ric hdocument entity retrieve (VDER) 在工业自然语言处理应用中变得非常重要。新的文档类型随时间的推移而出现，每种文档都有独特的实体类型，这种情况提出了一个挑战：许多文档中的实体类型是未经见过的。为了解决这个挑战，模型需要能够在几次training中学习实体。然而，先前的几 shot VDER 研究主要关注了文档水平的问题，使用预先定义的全局实体空间，而不考虑实体级几 shot scenario：目标实体类型在每个任务中是本地个性化的，而且实体出现在文档中的差异很大。为了解决这个未探索的场景，本文研究了一个新的实体级几 shot VDER 任务。挑战在于标签空间的独特性和文档中实体出现的不同性。为了解决这个问题，我们提出了一个任务意识度meta-学习基础框架，强调实现效果task个性化，以便分辨在任务中和out-of-task分布中的差异。具体来说，我们采用层次解码器（HC）和对比学习（ContrastProtoNet）来实现这一目标。此外，我们还提供了一个新的数据集，FewVEX，以便未来的研究人员在实体级几 shot VDER 领域进行更多的研究。实验结果表明，我们的方法可以显著提高流行的meta-学习基础模型的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Improving-Interpersonal-Communication-by-Simulating-Audiences-with-Language-Models"><a href="#Improving-Interpersonal-Communication-by-Simulating-Audiences-with-Language-Models" class="headerlink" title="Improving Interpersonal Communication by Simulating Audiences with Language Models"></a>Improving Interpersonal Communication by Simulating Audiences with Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00687">http://arxiv.org/abs/2311.00687</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/theryanl/egs">https://github.com/theryanl/egs</a></li>
<li>paper_authors: Ryan Liu, Howard Yen, Raja Marjieh, Thomas L. Griffiths, Ranjay Krishna</li>
<li>for: 提高目标实现效率的交流和决策过程</li>
<li>methods: 利用大语言模型（LLM）模拟来帮助人们更好地交流和决策</li>
<li>results: 在8个场景中，EGS框架选择的候选者和建议得到了人类评分员的偏好，而且在5个场景中，观众模拟得到了人类评分员的一致。此外，EGS框架在实际用户上 Forum 中应用也得到了良好的效果。<details>
<summary>Abstract</summary>
How do we communicate with others to achieve our goals? We use our prior experience or advice from others, or construct a candidate utterance by predicting how it will be received. However, our experiences are limited and biased, and reasoning about potential outcomes can be difficult and cognitively challenging. In this paper, we explore how we can leverage Large Language Model (LLM) simulations to help us communicate better. We propose the Explore-Generate-Simulate (EGS) framework, which takes as input any scenario where an individual is communicating to an audience with a goal they want to achieve. EGS (1) explores the solution space by producing a diverse set of advice relevant to the scenario, (2) generates communication candidates conditioned on subsets of the advice, and (3) simulates the reactions from various audiences to determine both the best candidate and advice to use. We evaluate the framework on eight scenarios spanning the ten fundamental processes of interpersonal communication. For each scenario, we collect a dataset of human evaluations across candidates and baselines, and showcase that our framework's chosen candidate is preferred over popular generation mechanisms including Chain-of-Thought. We also find that audience simulations achieve reasonably high agreement with human raters across 5 of the 8 scenarios. Finally, we demonstrate the generality of our framework by applying it to real-world scenarios described by users on web forums. Through evaluations and demonstrations, we show that EGS enhances the effectiveness and outcomes of goal-oriented communication across a variety of situations, thus opening up new possibilities for the application of large language models in revolutionizing communication and decision-making processes.
</details>
<details>
<summary>摘要</summary>
如何与他人沟通以达到我们的目标呢？我们可以利用我们的前经验或他人的建议，或者构建一个候选句子，预测它会如何被接受。然而，我们的经验是有限和偏袋的，理解可能的结果是心智具有挑战性的。在这篇论文中，我们探讨如何通过大语言模型（LLM）模拟来改善我们的沟通。我们提出了探索-生成-模拟（EGS）框架，该框架输入任何沟通场景，目标是与听众沟通。EGS（1）探索解决方案空间，生成各种相关于场景的建议集，（2）基于这些建议生成句子候选，并（3）通过不同听众的反应来确定最佳候选和建议。我们对八个场景进行了评估，每个场景都有人类评估者的数据集和基线，并显示了我们的框架选择的候选 exceeds Chain-of-Thought 的流行生成机制。此外，我们发现了观众模拟可以与人类评估者达到相当高的一致性在五个场景中。最后，我们通过应用它到网络论坛上的实际场景来证明框架的一般性。通过评估和示例，我们表明了EGS可以提高目标沟通的效iveness和结果，因此开启了大语言模型在沟通和决策过程中的新可能性。
</details></li>
</ul>
<hr>
<h2 id="Emergence-of-Collective-Open-Ended-Exploration-from-Decentralized-Meta-Reinforcement-Learning"><a href="#Emergence-of-Collective-Open-Ended-Exploration-from-Decentralized-Meta-Reinforcement-Learning" class="headerlink" title="Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning"></a>Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00651">http://arxiv.org/abs/2311.00651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Richard Bornemann, Gautier Hamon, Eleni Nisioti, Clément Moulin-Frier</li>
<li>for: 本研究的目的是研究多个智能体在开放的任务分布上自适应学习并实现集体探索策略。</li>
<li>methods: 本研究使用了分布式培aunder reinforcement learning和开放任务分布来训练多个智能体。</li>
<li>results: 研究发现，由多个智能体自适应学习的策略可以在测试时face novel objects时示出强大的泛化能力，并且在没有强制合作的情况下，智能体们还能学习集体探索策略，解决 novel tasks。此外，智能体们学习的集体探索策略还可以在开放任务设定下扩展到更深的任务树。<details>
<summary>Abstract</summary>
Recent works have proven that intricate cooperative behaviors can emerge in agents trained using meta reinforcement learning on open ended task distributions using self-play. While the results are impressive, we argue that self-play and other centralized training techniques do not accurately reflect how general collective exploration strategies emerge in the natural world: through decentralized training and over an open-ended distribution of tasks. In this work we therefore investigate the emergence of collective exploration strategies, where several agents meta-learn independent recurrent policies on an open ended distribution of tasks. To this end we introduce a novel environment with an open ended procedurally generated task space which dynamically combines multiple subtasks sampled from five diverse task types to form a vast distribution of task trees. We show that decentralized agents trained in our environment exhibit strong generalization abilities when confronted with novel objects at test time. Additionally, despite never being forced to cooperate during training the agents learn collective exploration strategies which allow them to solve novel tasks never encountered during training. We further find that the agents learned collective exploration strategies extend to an open ended task setting, allowing them to solve task trees of twice the depth compared to the ones seen during training. Our open source code as well as videos of the agents can be found on our companion website.
</details>
<details>
<summary>摘要</summary>
近期研究表明，通过meta reinforcement learning在开放式任务分布上训练Agent可以实现复杂的合作行为。虽然结果吸引人，但我们认为自我玩家和中央训练技术不准确反映了自然界中集体探索策略的发展：通过分布式训练和开放式任务分布来发展集体探索策略。因此，我们在这项工作中investigate集体探索策略的emergence，其中多个Agent通过独立的recurrent Policy来meta-learn一个开放式任务分布。为此，我们提出了一个新的环境，其中包含一个开放式、生成式任务空间，动态组合了多个从五种多样化任务类型中采样的子任务，形成了一个庞大的任务树分布。我们表明，在这个环境中训练的分布式Agent exhibit强大的泛化能力，并且在测试时面对新物体时，能够快速适应。此外，我们发现，训练时不 forced合作的Agent仍然可以学习集体探索策略，并且这些策略可以在开放式任务设置下进行扩展，解决 novel task 不seen during training。我们的开源代码以及视频可以在我们的伙伴网站上找到。
</details></li>
</ul>
<hr>
<h2 id="FAIRLABEL-Correcting-Bias-in-Labels"><a href="#FAIRLABEL-Correcting-Bias-in-Labels" class="headerlink" title="FAIRLABEL: Correcting Bias in Labels"></a>FAIRLABEL: Correcting Bias in Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00638">http://arxiv.org/abs/2311.00638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Srinivasan H Sengamedu, Hien Pham</li>
<li>for: 该论文目的是检测和修正机器学习模型中的偏见。</li>
<li>methods: 该论文使用的方法是FAIRLABEL算法，该算法可以检测和修正labels中的偏见，以降低模型对各个组的不同影响。</li>
<li>results: 该论文的结果显示，FAIRLABEL算法可以有效地检测和修正偏见，在synthetic dataset上的检测精度为86.7%，比基eline模型高出14.8%。此外，在UC Irvine Adult、German Credit Risk和Compas等数据集上，FAIRLABEL算法可以降低Disparate Impact Ratio，最高提高54.2%。<details>
<summary>Abstract</summary>
There are several algorithms for measuring fairness of ML models. A fundamental assumption in these approaches is that the ground truth is fair or unbiased. In real-world datasets, however, the ground truth often contains data that is a result of historical and societal biases and discrimination. Models trained on these datasets will inherit and propagate the biases to the model outputs. We propose FAIRLABEL, an algorithm which detects and corrects biases in labels. The goal of FAIRLABELis to reduce the Disparate Impact (DI) across groups while maintaining high accuracy in predictions. We propose metrics to measure the quality of bias correction and validate FAIRLABEL on synthetic datasets and show that the label correction is correct 86.7% of the time vs. 71.9% for a baseline model. We also apply FAIRLABEL on benchmark datasets such as UCI Adult, German Credit Risk, and Compas datasets and show that the Disparate Impact Ratio increases by as much as 54.2%.
</details>
<details>
<summary>摘要</summary>
有几种算法可以测量机器学习模型的公平性。这些方法的基本假设是地面真实不偏袋。然而，在实际数据集中，地面经常包含历史和社会偏袋和歧视的数据，模型在这些数据集上训练时会继承和传播这些偏袋。我们提出了 FAIRLABEL 算法，可以检测和修正标签中的偏袋。FAIRLABEL 的目标是降低不同群体之间的不同影响（DI），同时保持预测准确率高。我们提出了用于衡量偏袋修正质量的指标，并验证 FAIRLABEL 在模拟数据集上的性能，显示了86.7%的正确率vs. 71.9%的基eline模型。我们还应用 FAIRLABEL 于常见的 UCI 成人、德国借款风险和 Compas 数据集，并显示了 Disparate Impact Ratio 的提高，最高达54.2%。
</details></li>
</ul>
<hr>
<h2 id="A-Bi-level-Framework-for-Traffic-Accident-Duration-Prediction-Leveraging-Weather-and-Road-Condition-Data-within-a-Practical-Optimum-Pipeline"><a href="#A-Bi-level-Framework-for-Traffic-Accident-Duration-Prediction-Leveraging-Weather-and-Road-Condition-Data-within-a-Practical-Optimum-Pipeline" class="headerlink" title="A Bi-level Framework for Traffic Accident Duration Prediction: Leveraging Weather and Road Condition Data within a Practical Optimum Pipeline"></a>A Bi-level Framework for Traffic Accident Duration Prediction: Leveraging Weather and Road Condition Data within a Practical Optimum Pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00634">http://arxiv.org/abs/2311.00634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafat Tabassum Sukonna, Soham Irtiza Swapnil</li>
<li>for: 预测交通事故持续时间的挑战是带有随机性的，因为交通事故的持续时间往往受到多种因素的影响，如事故严重程度、路面条件、天气等。本研究旨在检验是否可以使用交通事故数据库中的静态特征来预测事故持续时间，不使用事故上下文信息数据，如事故严重程度和文本描述。</li>
<li>methods: 本研究使用了多种机器学习模型来预测事故的短期和长期影响，并采用了二元方法来准确地预测事故持续时间。使用 Random Forest 分类模型可以在83%的正确率下分类事故的短期和长期影响，而 LightGBM 回归模型在 Mean Average Error (MAE) 和 Root Mean Squared Error (RMSE) 指标上表现较好，分别为 26.15、13.3、32.91和28.91。</li>
<li>results: 研究结果显示，只使用交通事故数据库中的静态特征可以准确地预测事故持续时间。使用最佳的分类和回归模型，我们构建了一个端到端的预测管道，并与之前的研究结果相符。 SHAP 值分析表明，天气条件、风速和风寒是决定事故持续时间的最重要因素。<details>
<summary>Abstract</summary>
Due to the stochastic nature of events, predicting the duration of a traffic incident presents a formidable challenge. Accurate duration estimation can result in substantial advantages for commuters in selecting optimal routes and for traffic management personnel in addressing non-recurring congestion issues. In this study, we gathered accident duration, road conditions, and meteorological data from a database of traffic accidents to check the feasibility of a traffic accident duration pipeline without accident contextual information data like accident severity and textual description. Multiple machine learning models were employed to predict whether an accident's impact on road traffic would be of a short-term or long-term nature, and then utilizing a bimodal approach the precise duration of the incident's effect was determined. Our binary classification random forest model distinguished between short-term and long-term effects with an 83% accuracy rate, while the LightGBM regression model outperformed other machine learning regression models with Mean Average Error (MAE) values of 26.15 and 13.3 and RMSE values of 32.91 and 28.91 for short and long-term accident duration prediction, respectively. Using the optimal classification and regression model identified in the preceding section, we then construct an end-to-end pipeline to incorporate the entire process. The results of both separate and combined approaches were comparable with previous works, which shows the applicability of only using static features for predicting traffic accident duration. The SHAP value analysis identified weather conditions, wind chill and wind speed as the most influential factors in determining the duration of an accident.
</details>
<details>
<summary>摘要</summary>
因为事件的随机性，预测交通事故持续时间是一项具有挑战性的任务。 preciselly estimating the duration of a traffic accident can bring significant benefits to commuters in choosing the best routes and to traffic management personnel in addressing non-recurring congestion issues. 在这项研究中，我们从交通事故事件数据库中收集了事故持续时间、路面条件和天气数据，以检验是否可以建立交通事故持续时间管道，不使用事故Contextual information数据如事故严重程度和文本描述。 我们使用多种机器学习模型来预测事故对道路交通的影响是短期或长期的，然后使用二分类方法确定事故的具体持续时间。我们的二分类Random Forest模型可以准确地将事故的影响分为短期和长期两个类别，其中精度为83%。 LightGBM回归模型在机器学习回归模型中表现出色，其MAE值为26.15和13.3，RMSE值为32.91和28.91，分别用于短期和长期事故持续时间预测。 使用最佳的分类和回归模型，我们构建了一个端到端管道，并将整个过程包含在内。结果表明，只使用静态特征可以达到与之前的研究结果相同的精度。 SHAP值分析表明，天气条件、风速和风轻度是确定事故持续时间的最重要因素。
</details></li>
</ul>
<hr>
<h2 id="Loss-Modeling-for-Multi-Annotator-Datasets"><a href="#Loss-Modeling-for-Multi-Annotator-Datasets" class="headerlink" title="Loss Modeling for Multi-Annotator Datasets"></a>Loss Modeling for Multi-Annotator Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00619">http://arxiv.org/abs/2311.00619</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/molyswu/hand_detection">https://github.com/molyswu/hand_detection</a></li>
<li>paper_authors: Uthman Jinadu, Jesse Annan, Shanshan Wen, Yi Ding</li>
<li>for: 提高 dataset 的公平性，即使使用大量数据 annotator 的注释。</li>
<li>methods: 使用 multitask learning 和 loss-based label correction 来学习更准确的多个注释者意见。</li>
<li>results: 可以清晰地分化同意和不同意的注释，并且在单个或多个注释者设置下提高预测性能。<details>
<summary>Abstract</summary>
Accounting for the opinions of all annotators of a dataset is critical for fairness. However, when annotating large datasets, individual annotators will frequently provide thousands of ratings which can lead to fatigue. Additionally, these annotation processes can occur over multiple days which can lead to an inaccurate representation of an annotator's opinion over time. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, we demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data.
</details>
<details>
<summary>摘要</summary>
accounting for all annotators' opinions is crucial for fairness, but when annotating large datasets, individual annotators may provide thousands of ratings, leading to fatigue. furthermore, the annotation process may take place over multiple days, which can result in inaccurate representation of an annotator's opinion over time. to address this issue, we propose using multitask learning in conjunction with loss-based label correction to learn a more accurate representation of diverse opinions. we show that our novel formulation can cleanly separate agreeing and disagreeing annotations, and improve prediction performance in a single or multi-annotator setting. additionally, we demonstrate that our method remains robust to additional label noise that is commonly found in subjective data.
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Variational-Inference-for-Probabilistic-Programs-with-Stochastic-Support"><a href="#Rethinking-Variational-Inference-for-Probabilistic-Programs-with-Stochastic-Support" class="headerlink" title="Rethinking Variational Inference for Probabilistic Programs with Stochastic Support"></a>Rethinking Variational Inference for Probabilistic Programs with Stochastic Support</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00594">http://arxiv.org/abs/2311.00594</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/treigerm/sdvi_neurips">https://github.com/treigerm/sdvi_neurips</a></li>
<li>paper_authors: Tim Reichelt, Luke Ong, Tom Rainforth</li>
<li>for: 这个论文是用于解决 probabilistic programs with stochastic support 中的变量抽象问题的新方法。</li>
<li>methods: 这个方法使用了分解程序into sub-programs with static support,然后自动建立每个子程序的独立子导数。</li>
<li>results: 这个方法可以提高变量抽象的性能，具体来说，可以更好地建立适当的变量家族，从而提高推断性能。<details>
<summary>Abstract</summary>
We introduce Support Decomposition Variational Inference (SDVI), a new variational inference (VI) approach for probabilistic programs with stochastic support. Existing approaches to this problem rely on designing a single global variational guide on a variable-by-variable basis, while maintaining the stochastic control flow of the original program. SDVI instead breaks the program down into sub-programs with static support, before automatically building separate sub-guides for each. This decomposition significantly aids in the construction of suitable variational families, enabling, in turn, substantial improvements in inference performance.
</details>
<details>
<summary>摘要</summary>
我们介绍Support Decomposition Variational Inference（SDVI），一种新的可能性计算（VI）方法，用于实际程序中的数据支持。现有的方法对这个问题是通过设计单一的全球可能性引导，并在变量基础上维护原始程序中的随机控制流。然而，SDVI将程序分解为子程序，并自动建立每个子程序的独立子引导。这个分解可以帮助建立适合的可能性家族，从而提高推论性能。
</details></li>
</ul>
<hr>
<h2 id="Coop-Memory-is-not-a-Commodity"><a href="#Coop-Memory-is-not-a-Commodity" class="headerlink" title="Coop: Memory is not a Commodity"></a>Coop: Memory is not a Commodity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00591">http://arxiv.org/abs/2311.00591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianhao Zhang, Shihan Ma, Peihong Liu, Jinhui Yuan</li>
<li>for: 提高深度学习框架下限制内存预算下的神经网络训练效率</li>
<li>methods: 提出了一种基于窗口内存混合的tensor重新材料化策略，并提出了便宜的tensor分割和可重复在位进行进一步减少重新材料化成本</li>
<li>results: 对八种代表性的神经网络进行了实验，实验结果表明，Coop可以达到$2\times$的内存储存空间约束，并大幅减少计算开销、搜索延迟和内存散射问题 compared to状态则基elines。<details>
<summary>Abstract</summary>
Tensor rematerialization allows the training of deep neural networks (DNNs) under limited memory budgets by checkpointing the models and recomputing the evicted tensors as needed. However, the existing tensor rematerialization techniques overlook the memory system in deep learning frameworks and implicitly assume that free memory blocks at different addresses are identical. Under this flawed assumption, discontiguous tensors are evicted, among which some are not used to allocate the new tensor. This leads to severe memory fragmentation and increases the cost of potential rematerializations. To address this issue, we propose to evict tensors within a sliding window to ensure all evictions are contiguous and are immediately used. Furthermore, we proposed cheap tensor partitioning and recomputable in-place to further reduce the rematerialization cost by optimizing the tensor allocation. We named our method Coop as it is a co-optimization of tensor allocation and tensor rematerialization. We evaluated Coop on eight representative DNNs. The experimental results demonstrate that Coop achieves up to $2\times$ memory saving and hugely reduces compute overhead, search latency, and memory fragmentation compared to the state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
tensor重新材料化可以在有限内存预算下训练深度神经网络（DNN），通过检查点模型并重新计算被踢出的张量来实现。然而，现有的张量重新材料化技术忽视深度学习框架中的内存系统，并且自然地假设不同地址上的免费内存块是相同的。基于这个错误的假设，深度神经网络中的张量会被踢出，其中一些张量并没有用于分配新的张量。这会导致内存散落严重，并使 potential rematerializations 的成本增加。为解决这个问题，我们提议在滑动窗口内踢出张量，以确保所有的踢出都是连续的，并且立即用于分配新的张量。此外，我们还提出了便宜的张量分配和可重复计算在位的方法，以进一步减少rematerialization成本。我们命名了我们的方法为Coop，因为它是张量分配和张量重新材料化的共优化。我们在八个代表性的深度神经网络上进行了实验。实验结果表明，Coop可以达到 $2\times$ 的内存减少和巨大减少计算开销、搜索延迟和内存散落比现状态之前的基elines。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Summarization-with-Normalizing-Flows-and-Aggressive-Training"><a href="#Boosting-Summarization-with-Normalizing-Flows-and-Aggressive-Training" class="headerlink" title="Boosting Summarization with Normalizing Flows and Aggressive Training"></a>Boosting Summarization with Normalizing Flows and Aggressive Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00588">http://arxiv.org/abs/2311.00588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuyangstat/flowsum">https://github.com/yuyangstat/flowsum</a></li>
<li>paper_authors: Yu Yang, Xiaotong Shen</li>
<li>for: 这个论文是为了提出一种基于normalizing flows的Transformer-based摘要框架，以解决变量摘要中的两个主要挑战：latent representation中的 semantic information不足和训练过程中的 posterior collapse。</li>
<li>methods: 该方法使用normalizing flows来实现灵活的latent posterior模型，并提出了一种控制性的 alternate aggressive training（CAAT）策略和改进的门控制机制。</li>
<li>results: 实验结果表明，FlowSUM可以显著提高生成的摘要质量，并允许知识储存以最小化影响 inference时间。此外，论文还研究了normalizing flows中的 posterior collapse问题，并分析了摘要质量如何受到训练策略、门初始值、normalizing flows类型和数量的影响，为未来研究提供了有价值的信息。<details>
<summary>Abstract</summary>
This paper presents FlowSUM, a normalizing flows-based variational encoder-decoder framework for Transformer-based summarization. Our approach tackles two primary challenges in variational summarization: insufficient semantic information in latent representations and posterior collapse during training. To address these challenges, we employ normalizing flows to enable flexible latent posterior modeling, and we propose a controlled alternate aggressive training (CAAT) strategy with an improved gate mechanism. Experimental results show that FlowSUM significantly enhances the quality of generated summaries and unleashes the potential for knowledge distillation with minimal impact on inference time. Furthermore, we investigate the issue of posterior collapse in normalizing flows and analyze how the summary quality is affected by the training strategy, gate initialization, and the type and number of normalizing flows used, offering valuable insights for future research.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Minimally-Modifying-a-Markov-Game-to-Achieve-Any-Nash-Equilibrium-and-Value"><a href="#Minimally-Modifying-a-Markov-Game-to-Achieve-Any-Nash-Equilibrium-and-Value" class="headerlink" title="Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value"></a>Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00582">http://arxiv.org/abs/2311.00582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Wu, Jeremy McMahan, Yiding Chen, Yudong Chen, Xiaojin Zhu, Qiaomin Xie</li>
<li>for: 这个论文研究了游戏修改问题，即一位仁慈的游戏设计者或一位恶意对手修改游戏奖励函数，使得一个目标策略Profile变为游戏的唯一马歇尔完美 equilibrio，并且其价值在一定范围内。</li>
<li>methods: 该论文使用了policy profile的 Installation Set Theory 和Random Perturbation Algorithm来解决这个问题。</li>
<li>results: 论文提出了一种高效的修改计划，可以在near-optimal cost下使得目标策略Profile变为游戏的唯一马歇尔完美 equilibrio。<details>
<summary>Abstract</summary>
We study the game modification problem, where a benevolent game designer or a malevolent adversary modifies the reward function of a zero-sum Markov game so that a target deterministic or stochastic policy profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, in a way that minimizes the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of some game, and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm, which solves a convex optimization problem with linear constraints and then performs random perturbation, to obtain a modification plan with a near-optimal cost.
</details>
<details>
<summary>摘要</summary>
我们研究游戏修改问题，其中一位好心的游戏设计师或一位邪恶对手修改了游戏奖励函数，使得目标决策函数 Profile 变成游戏的唯一马克洛夫完美均衡，并且其价值在一定范围内，以最小化修改成本。我们描述了可以安装为游戏唯一均衡的策略Profile集，并提出了必要和 suficient condition для成功安装。我们还提出了一种高效的算法，它首先解决一个几何编制问题，然后通过随机干扰来获得一个近似优化成本的修改计划。
</details></li>
</ul>
<hr>
<h2 id="Can-Foundation-Models-Watch-Talk-and-Guide-You-Step-by-Step-to-Make-a-Cake"><a href="#Can-Foundation-Models-Watch-Talk-and-Guide-You-Step-by-Step-to-Make-a-Cake" class="headerlink" title="Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?"></a>Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00738">http://arxiv.org/abs/2311.00738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuwei Bao, Keunwoo Peter Yu, Yichi Zhang, Shane Storks, Itamar Bar-Yossef, Alexander De La Iglesia, Megan Su, Xiao Lin Zheng, Joyce Chai</li>
<li>for: 这个论文旨在开发一种可以提供 situational, personalized 任务指导的人工智能系统，以帮助人类完成多种任务。</li>
<li>methods: 这个论文使用了一个新的多modal benchmark dataset，Watch, Talk and Guide (WTaG)，基于自然的人类用户和导师之间的互动。它还提出了两个任务：用户和环境理解，以及导师决策。 authors 利用了多种基础模型，以研究这些模型是否可以快速适应可见指导任务。</li>
<li>results: 数据evaluation结果表明，这些模型在某些情况下可以达到 fair 性能，但快速适应任务仍然是一大挑战。这个论文的benchmark和基elines将为未来的 situational task guidance 工作提供一个进程架构。<details>
<summary>Abstract</summary>
Despite tremendous advances in AI, it remains a significant challenge to develop interactive task guidance systems that can offer situated, personalized guidance and assist humans in various tasks. These systems need to have a sophisticated understanding of the user as well as the environment, and make timely accurate decisions on when and what to say. To address this issue, we created a new multimodal benchmark dataset, Watch, Talk and Guide (WTaG) based on natural interaction between a human user and a human instructor. We further proposed two tasks: User and Environment Understanding, and Instructor Decision Making. We leveraged several foundation models to study to what extent these models can be quickly adapted to perceptually enabled task guidance. Our quantitative, qualitative, and human evaluation results show that these models can demonstrate fair performances in some cases with no task-specific training, but a fast and reliable adaptation remains a significant challenge. Our benchmark and baselines will provide a stepping stone for future work on situated task guidance.
</details>
<details>
<summary>摘要</summary>
尽管人工智能技术有很大的进步，仍然是一项非常大的挑战，开发出可以提供协助人类完成各种任务的交互式任务指南系统。这些系统需要具备高度智能的用户和环境认知，并在时间和内容上做出准确的决策。为解决这个问题，我们创建了一个新的多模态基准数据集，Watch, Talk and Guide（WTaG），基于人类用户和人类导师之间的自然交互。我们还提出了两个任务：用户和环境理解，以及导师决策。我们利用了一些基础模型，以研究这些模型是否可以快速适应具有感知能力的任务指南。我们的量化、质量和人类评估结果表明，这些模型在某些情况下可以达到公平的性能，但快速和可靠的适应仍然是一项大的挑战。我们的基准和基线将为未来的协助任务指南做出贡献。
</details></li>
</ul>
<hr>
<h2 id="LLaVA-Interactive-An-All-in-One-Demo-for-Image-Chat-Segmentation-Generation-and-Editing"><a href="#LLaVA-Interactive-An-All-in-One-Demo-for-Image-Chat-Segmentation-Generation-and-Editing" class="headerlink" title="LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing"></a>LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00571">http://arxiv.org/abs/2311.00571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei-Ge Chen, Irina Spiridonova, Jianwei Yang, Jianfeng Gao, Chunyuan Li</li>
<li>for: 这个论文旨在描述一种用于多模态人机交互的研究 прототип（LLaVA-Interactive），可以与人类用户进行多回交流，并将多模态用户输入与生成多模态响应。</li>
<li>methods: 这个系统使用了三种预制的AI模型的多模态技能，包括视觉聊天的LLaVA、图像分割的SEEM以及图像生成和修改的GLIGEN，无需进行额外的模型训练。</li>
<li>results: 论文描述了LLaVA-Interactive的开发，并对其在多种应用场景中的推荐进行了展示，以鼓励未来的多模态交互系统研究。<details>
<summary>Abstract</summary>
LLaVA-Interactive is a research prototype for multimodal human-AI interaction. The system can have multi-turn dialogues with human users by taking multimodal user inputs and generating multimodal responses. Importantly, LLaVA-Interactive goes beyond language prompt, where visual prompt is enabled to align human intents in the interaction. The development of LLaVA-Interactive is extremely cost-efficient as the system combines three multimodal skills of pre-built AI models without additional model training: visual chat of LLaVA, image segmentation from SEEM, as well as image generation and editing from GLIGEN. A diverse set of application scenarios is presented to demonstrate the promises of LLaVA-Interactive and to inspire future research in multimodal interactive systems.
</details>
<details>
<summary>摘要</summary>
LLaVA-Interactive 是一个研究原型，用于多模态人机交互。该系统可以与人类用户进行多轮对话，接受多模态用户输入并生成多模态回应。特别是，LLaVA-Interactive 超越语言提示，允许视觉提示对人类意图进行Alignment。该系统的开发非常经济，因为它将三种预构建 AI 模型结合使用，无需进行额外模型训练：视觉对话的 LLaVA，图像分割的 SEEM，以及图像生成和编辑的 GLIGEN。一组多样化的应用场景被示出，以证明 LLaVA-Interactive 的推荐和未来多模态交互系统的研究的可能性。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Visual-Cues-in-the-Intensive-Care-Unit-and-Association-with-Patient-Clinical-Status"><a href="#Detecting-Visual-Cues-in-the-Intensive-Care-Unit-and-Association-with-Patient-Clinical-Status" class="headerlink" title="Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status"></a>Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00565">http://arxiv.org/abs/2311.00565</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subhash Nerella, Ziyuan Guan, Andrea Davidson, Yuanfang Ren, Tezcan Baslanti, Brooke Armfield, Patrick Tighe, Azra Bihorac, Parisa Rashidi</li>
<li>for: 这研究旨在开发一种基于人工智能技术的评估工具，以帮助医疗工作者在护理科室中进行更加准确和细化的病人评估。</li>
<li>methods: 该研究使用了一种名为“面具损失计算”的新技术，以解决数据不均衡问题，并使用了SWINTransformer模型进行训练。</li>
<li>results: 研究发现，通过检测18种表情动作单元（AU），可以与病人的acuity状况、急性脑功能障碍和疼痛有 statistically significant 的相关性。SWINTransformer模型在测试集上达到了0.57的mean F1分数和0.89的mean准确率。<details>
<summary>Abstract</summary>
Intensive Care Units (ICU) provide close supervision and continuous care to patients with life-threatening conditions. However, continuous patient assessment in the ICU is still limited due to time constraints and the workload on healthcare providers. Existing patient assessments in the ICU such as pain or mobility assessment are mostly sporadic and administered manually, thus introducing the potential for human errors. Developing Artificial intelligence (AI) tools that can augment human assessments in the ICU can be beneficial for providing more objective and granular monitoring capabilities. For example, capturing the variations in a patient's facial cues related to pain or agitation can help in adjusting pain-related medications or detecting agitation-inducing conditions such as delirium. Additionally, subtle changes in visual cues during or prior to adverse clinical events could potentially aid in continuous patient monitoring when combined with high-resolution physiological signals and Electronic Health Record (EHR) data. In this paper, we examined the association between visual cues and patient condition including acuity status, acute brain dysfunction, and pain. We leveraged our AU-ICU dataset with 107,064 frames collected in the ICU annotated with facial action units (AUs) labels by trained annotators. We developed a new "masked loss computation" technique that addresses the data imbalance problem by maximizing data resource utilization. We trained the model using our AU-ICU dataset in conjunction with three external datasets to detect 18 AUs. The SWIN Transformer model achieved 0.57 mean F1-score and 0.89 mean accuracy on the test set. Additionally, we performed AU inference on 634,054 frames to evaluate the association between facial AUs and clinically important patient conditions such as acuity status, acute brain dysfunction, and pain.
</details>
<details>
<summary>摘要</summary>
医疗保健机构（ICU）为患有生命威胁的患者提供临密监测和不间断的护理，但是现有的患者评估在ICU仍然受到时间约束和医疗人员的工作负担的限制。现有的患者评估，如疼痛或 mobilité评估，都是间歇的并由人工进行，因此存在人类错误的潜在风险。通过开发人工智能（AI）工具可以帮助医疗人员更加 объекively和精细地监测患者的状况。例如，捕捉患者面部表达的变化，以帮助调整疼痛药物或检测刺激性情况如 delirio。此外，在或 перед不良临床事件发生时，通过高分辨率生物参数和电子医疗纪录（EHR）数据，可能发现细微的视觉表达变化，以帮助持续性监测患者。在这篇论文中，我们研究了面部表达和患者状况之间的关系，包括病情严重程度、脑部功能障碍和疼痛。我们利用我们的AU-ICU数据集，包括107,064帧在ICU中收集的患者面部表达，并由训练过的标注员进行了facial action units（AUs）标签。我们开发了一种“遮盖损失计算”技术，解决数据不均衡问题，以最大化数据资源使用。我们使用我们的AU-ICU数据集，并与三个外部数据集进行了模型训练，检测18种AUs。SWIN Transformer模型在测试集上取得了0.57的 mean F1-score和0.89的 mean accuracy。此外，我们对634,054帧的面部表达进行了AU推断，以评估面部表达和临床重要的患者状况，如病情严重程度、脑部功能障碍和疼痛。
</details></li>
</ul>
<hr>
<h2 id="Tackling-the-Abstraction-and-Reasoning-Corpus-ARC-with-Object-centric-Models-and-the-MDL-Principle"><a href="#Tackling-the-Abstraction-and-Reasoning-Corpus-ARC-with-Object-centric-Models-and-the-MDL-Principle" class="headerlink" title="Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle"></a>Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00545">http://arxiv.org/abs/2311.00545</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sebferre/arc-mdl">https://github.com/sebferre/arc-mdl</a></li>
<li>paper_authors: Sébastien Ferré</li>
<li>for: 用于推动人工智能研究，创建更高水平的智能系统。</li>
<li>methods: 使用对象中心模型，与人类自然语言程序相似，并使用最小描述长度原则进行有效的搜索。</li>
<li>results: 解决了多种任务，学习出的模型与自然程序相似，并在不同领域中进行了扩展应用。<details>
<summary>Abstract</summary>
The Abstraction and Reasoning Corpus (ARC) is a challenging benchmark, introduced to foster AI research towards human-level intelligence. It is a collection of unique tasks about generating colored grids, specified by a few examples only. In contrast to the transformation-based programs of existing work, we introduce object-centric models that are in line with the natural programs produced by humans. Our models can not only perform predictions, but also provide joint descriptions for input/output pairs. The Minimum Description Length (MDL) principle is used to efficiently search the large model space. A diverse range of tasks are solved, and the learned models are similar to the natural programs. We demonstrate the generality of our approach by applying it to a different domain.
</details>
<details>
<summary>摘要</summary>
《抽象和理解集合（ARC）》是一个挑战性的标准集，旨在促进人工智能研究，以达到人类水平的智能。它包含一些唯一的任务，需要生成颜色grid，只需要几个示例来定义。与现有的变换基本的程序不同，我们引入了对象中心的模型，与人类生成的自然程序相符。我们的模型不仅可以进行预测，还可以提供输入/输出对的共同描述。使用最小描述长度（MDL）原理，我们有效地搜索大型模型空间。我们解决了多种任务，并且学习的模型与自然程序类似。我们示示了我们的方法的通用性，通过应用到不同领域。
</details></li>
</ul>
<hr>
<h2 id="The-Development-of-LLMs-for-Embodied-Navigation"><a href="#The-Development-of-LLMs-for-Embodied-Navigation" class="headerlink" title="The Development of LLMs for Embodied Navigation"></a>The Development of LLMs for Embodied Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00530">http://arxiv.org/abs/2311.00530</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rongtao-xu/awesome-llm-en">https://github.com/rongtao-xu/awesome-llm-en</a></li>
<li>paper_authors: Jinzhou Lin, Han Gao, Rongtao Xu, Changwei Wang, Li Guo, Shibiao Xu</li>
<li>for: 本研究的目的是探讨Large Language Models（LLMs）与embodied intelligence的相互作用，尤其是在导航任务中。</li>
<li>methods: 本文使用了现有的state-of-the-art模型和研究方法，以及一个全面的链接列表，以描述LLMs在embodied intelligence中的应用。</li>
<li>results: 本文对现有的embodied navigation模型和数据集进行了评估，并分析了LLMs在导航任务中的优势和缺点。同时，本文还预测了未来LLMs在embodied intelligence中的发展趋势。<details>
<summary>Abstract</summary>
In recent years, the rapid advancement of Large Language Models (LLMs) such as the Generative Pre-trained Transformer (GPT) has attracted increasing attention due to their potential in a variety of practical applications. The application of LLMs with Embodied Intelligence has emerged as a significant area of focus. Among the myriad applications of LLMs, navigation tasks are particularly noteworthy because they demand a deep understanding of the environment and quick, accurate decision-making. LLMs can augment embodied intelligence systems with sophisticated environmental perception and decision-making support, leveraging their robust language and image-processing capabilities. This article offers an exhaustive summary of the symbiosis between LLMs and embodied intelligence with a focus on navigation. It reviews state-of-the-art models, research methodologies, and assesses the advantages and disadvantages of existing embodied navigation models and datasets. Finally, the article elucidates the role of LLMs in embodied intelligence, based on current research, and forecasts future directions in the field. A comprehensive list of studies in this survey is available at https://github.com/Rongtao-Xu/Awesome-LLM-EN
</details>
<details>
<summary>摘要</summary>
This article provides an exhaustive summary of the symbiosis between LLMs and embodied intelligence, focusing on navigation. It reviews state-of-the-art models, research methodologies, and assesses the advantages and disadvantages of existing embodied navigation models and datasets. Additionally, the article elucidates the role of LLMs in embodied intelligence based on current research and forecasts future directions in the field. A comprehensive list of studies in this survey is available at [INSERT GITHUB LINK].Translated into Simplified Chinese:近年来，大语言模型（LLM）如生成预训练转换器（GPT）的快速发展，吸引了广泛关注，因为它们在各种实际应用中具有潜在的潜力。LLM与embodied intelligence的结合，被视为一个重要的研究方向。在LLM中，导航任务特别值得注意，因为它们需要深刻了解环境，快速准确地作出决策。LLM可以增强embodied intelligence系统，提供了先进的环境感知和决策支持，利用它们的语言和图像处理能力。本文提供了LLM与embodied intelligence的完整概述，强调导航。它检查了现状的模型、研究方法和现有的embodied navigation模型和数据集的优缺点。此外，文章还详细介绍了LLM在embodied intelligence中的角色，基于当前研究，并预测未来在这个领域的发展趋势。具体的研究列表可以在[INSERT GITHUB LINK]中找到。
</details></li>
</ul>
<hr>
<h2 id="Learning-impartial-policies-for-sequential-counterfactual-explanations-using-Deep-Reinforcement-Learning"><a href="#Learning-impartial-policies-for-sequential-counterfactual-explanations-using-Deep-Reinforcement-Learning" class="headerlink" title="Learning impartial policies for sequential counterfactual explanations using Deep Reinforcement Learning"></a>Learning impartial policies for sequential counterfactual explanations using Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00523">http://arxiv.org/abs/2311.00523</a></li>
<li>repo_url: None</li>
<li>paper_authors: E. Panagiotou, E. Ntoutsi</li>
<li>for: 这个论文的目的是提高Explainable Artificial Intelligence（XAI）中的sequential counterfactual（SCF）示例的效果。</li>
<li>methods: 这个论文使用了Reinforcement Learning（RL）方法来学习SCF的找索引策略，以提高执行效率。</li>
<li>results: 这个论文发现了现有方法可能会导致政策具有不适的属性，如偏爱特定的动作。这个论文提议使用分类器的输出概率来创建更加有用的奖励，以 Mitigate这个效应。<details>
<summary>Abstract</summary>
In the field of explainable Artificial Intelligence (XAI), sequential counterfactual (SCF) examples are often used to alter the decision of a trained classifier by implementing a sequence of modifications to the input instance. Although certain test-time algorithms aim to optimize for each new instance individually, recently Reinforcement Learning (RL) methods have been proposed that seek to learn policies for discovering SCFs, thereby enhancing scalability. As is typical in RL, the formulation of the RL problem, including the specification of state space, actions, and rewards, can often be ambiguous. In this work, we identify shortcomings in existing methods that can result in policies with undesired properties, such as a bias towards specific actions. We propose to use the output probabilities of the classifier to create a more informative reward, to mitigate this effect.
</details>
<details>
<summary>摘要</summary>
在可解释人工智能（XAI）领域，sequential counterfactual（SCF）例子经常用于改变已训练的分类器的决策，通过对输入实例进行一系列的修改。虽然一些测试时间算法尝试在每个新实例上优化，但是最近的奖励学习（RL）方法已经被提议用于找到SCFs，从而提高可扩展性。在RL问题的形式ulation中，包括状态空间、动作和奖励的规定，通常是抽象的。在这种情况下，我们发现现有方法的缺陷可能导致政策具有不жела的性质，如偏向特定的动作。我们提议使用分类器的输出概率来创建更有用的奖励，以 Mitigate这种效应。
</details></li>
</ul>
<hr>
<h2 id="Efficient-LLM-Inference-on-CPUs"><a href="#Efficient-LLM-Inference-on-CPUs" class="headerlink" title="Efficient LLM Inference on CPUs"></a>Efficient LLM Inference on CPUs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00502">http://arxiv.org/abs/2311.00502</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/intel/intel-extension-for-transformers">https://github.com/intel/intel-extension-for-transformers</a></li>
<li>paper_authors: Haihao Shen, Hanwen Chang, Bo Dong, Yu Luo, Hengyu Meng</li>
<li>for: 本文旨在提出一种有效的方法，以提高大语言模型（LLMs）的部署效率。</li>
<li>methods: 本文使用自动INT4Weight-只量化流程和特制的LLM运行时，以优化CPU上LLM推理的速度。</li>
<li>results: 我们在各种流行的LLMs，包括Llama2、Llama、GPT-NeoX等，实现了高效的CPU推理。代码可以在：<a target="_blank" rel="noopener" href="https://github.com/intel/intel-extension-for-transformers">https://github.com/intel/intel-extension-for-transformers</a> 中找到。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated remarkable performance and tremendous potential across a wide range of tasks. However, deploying these models has been challenging due to the astronomical amount of model parameters, which requires a demand for large memory capacity and high memory bandwidth. In this paper, we propose an effective approach that can make the deployment of LLMs more efficiently. We support an automatic INT4 weight-only quantization flow and design a special LLM runtime with highly-optimized kernels to accelerate the LLM inference on CPUs. We demonstrate the general applicability of our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase the extreme inference efficiency on CPUs. The code is publicly available at: https://github.com/intel/intel-extension-for-transformers.
</details>
<details>
<summary>摘要</summary>
庞大语言模型（LLM）在各种任务上表现出色，但是部署这些模型却是一项极具挑战性的任务，因为它们的模型参数数量太多，需要大量的内存容量和高带宽。在这篇论文中，我们提出了一种有效的方法，可以使得LLM的部署更加高效。我们支持自动INT4Weight-only量化流程，并设计了特制的LLM运行时，以加速LLM的推理过程在CPU上。我们在各种受欢迎的LLM模型，包括Llama2、Llama和GPT-NeoX等模型上进行了普适性测试，并示出了在CPUs上的极高推理效率。代码可以在以下链接获取：https://github.com/intel/intel-extension-for-transformers。
</details></li>
</ul>
<hr>
<h2 id="Intriguing-Properties-of-Data-Attribution-on-Diffusion-Models"><a href="#Intriguing-Properties-of-Data-Attribution-on-Diffusion-Models" class="headerlink" title="Intriguing Properties of Data Attribution on Diffusion Models"></a>Intriguing Properties of Data Attribution on Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00500">http://arxiv.org/abs/2311.00500</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sail-sg/d-trak">https://github.com/sail-sg/d-trak</a></li>
<li>paper_authors: Xiaosen Zheng, Tianyu Pang, Chao Du, Jing Jiang, Min Lin</li>
<li>for: 这paper的目的是为了trace模型输出回到训练数据上,以确保数据贡献者得到公平的奖励或认可。</li>
<li>methods: 这paper使用了several theoretically motivated方法来实现数据归属,以提高计算可扩展性和效果的trade-off。</li>
<li>results: 在DDPMs和LoRA-finetuned模型上进行了广泛的实验和ablation study,发现了一些Counter-intuitive的观察结果，其中些 theoretically不合理的设计选择在数据归属方面 empirically outperform了之前的基准值，并且在linear datamodeling score和counterfactual评价方面均表现出了明显的改善。这些结果表明了一种更加有效的数据归属方法，同时也表明了在非拟合设置下，按照理论上的假设可能会导致数据归属性能下降。代码可以在<a target="_blank" rel="noopener" href="https://github.com/sail-sg/D-TRAK%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/sail-sg/D-TRAK中找到。</a><details>
<summary>Abstract</summary>
Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a significantly more efficient approach for attributing diffusion models, while the unexpected findings suggest that at least in non-convex settings, constructions guided by theoretical assumptions may lead to inferior attribution performance. The code is available at https://github.com/sail-sg/D-TRAK.
</details>
<details>
<summary>摘要</summary>
“数据追溯” seek to trace 模型输出到训练数据 zurück. With the recent development of diffusion models, 数据追溯 has become a desired module to properly assign valuations for high-quality or copyrighted 训练样本, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement 数据追溯, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a significantly more efficient approach for attributing diffusion models, while the unexpected findings suggest that at least in non-convex settings, constructions guided by theoretical assumptions may lead to inferior attribution performance. 代码可以在 <https://github.com/sail-sg/D-TRAK> 获取。
</details></li>
</ul>
<hr>
<h2 id="Bayes-enhanced-Multi-view-Attention-Networks-for-Robust-POI-Recommendation"><a href="#Bayes-enhanced-Multi-view-Attention-Networks-for-Robust-POI-Recommendation" class="headerlink" title="Bayes-enhanced Multi-view Attention Networks for Robust POI Recommendation"></a>Bayes-enhanced Multi-view Attention Networks for Robust POI Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00491">http://arxiv.org/abs/2311.00491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangnan Xia, Yu Yang, Senzhang Wang, Hongzhi Yin, Jiannong Cao, Philip S. Yu</li>
<li>for: 本研究旨在提高 Location-Based Social Network 服务中 POI 推荐的精度和可靠性，由于现有的 POI 检查点数据可能受到主观和 объектив 因素的影响，导致 POI 推荐的性能下降。</li>
<li>methods: 本研究提出了一种 Bayes-enhanced Multi-view Attention Network，包括个人 POI 转移图、semantic-based POI 图和距离-based POI 图，用于全面模型 POI 之间的依赖关系。在个人 POI 转移图中，采用 Bayes-enhanced 空间依赖学习模块进行数据扩充，以增加数据多样性。然后，使用多视图注意力学习模块对 POI 表示学习进行修复。</li>
<li>results: 对比当前状态的方法，本研究的 BayMAN 方法在 POI 推荐时 Significantly 高于其他方法，特别是当 POI 检查点数据不完整或受到噪声影响时。<details>
<summary>Abstract</summary>
POI recommendation is practically important to facilitate various Location-Based Social Network services, and has attracted rising research attention recently. Existing works generally assume the available POI check-ins reported by users are the ground-truth depiction of user behaviors. However, in real application scenarios, the check-in data can be rather unreliable due to both subjective and objective causes including positioning error and user privacy concerns, leading to significant negative impacts on the performance of the POI recommendation. To this end, we investigate a novel problem of robust POI recommendation by considering the uncertainty factors of the user check-ins, and proposes a Bayes-enhanced Multi-view Attention Network. Specifically, we construct personal POI transition graph, the semantic-based POI graph and distance-based POI graph to comprehensively model the dependencies among the POIs. As the personal POI transition graph is usually sparse and sensitive to noise, we design a Bayes-enhanced spatial dependency learning module for data augmentation from the local view. A Bayesian posterior guided graph augmentation approach is adopted to generate a new graph with collaborative signals to increase the data diversity. Then both the original and the augmented graphs are used for POI representation learning to counteract the data uncertainty issue. Next, the POI representations of the three view graphs are input into the proposed multi-view attention-based user preference learning module. By incorporating the semantic and distance correlations of POIs, the user preference can be effectively refined and finally robust recommendation results are achieved. The results of extensive experiments show that BayMAN significantly outperforms the state-of-the-art methods in POI recommendation when the available check-ins are incomplete and noisy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Dual-Conditioned-Diffusion-Models-for-Out-Of-Distribution-Detection-Application-to-Fetal-Ultrasound-Videos"><a href="#Dual-Conditioned-Diffusion-Models-for-Out-Of-Distribution-Detection-Application-to-Fetal-Ultrasound-Videos" class="headerlink" title="Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos"></a>Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00469">http://arxiv.org/abs/2311.00469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Divyanshu Mishra, He Zhao, Pramit Saha, Aris T. Papageorghiou, J. Alison Noble</li>
<li>for: 本研究旨在提高机器学习模型的可靠性，通过检测训练数据集外的样本。</li>
<li>methods: 本研究使用 dual-conditioned diffusion models (DCDM)，通过在模型中添加受控制的类信息和启发特征来实现重构基于OOD检测。</li>
<li>results: 对比参考方法，本研究所得到的准确率提高12%, 特征准确率提高22%, F1分数提高8%。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-based OOD detection. This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution. The proposed model outperforms reference methods with a 12% improvement in accuracy, 22% higher precision, and an 8% better F1 score.
</details>
<details>
<summary>摘要</summary>
外部分布（OOD）检测是提高机器学习模型的可靠性的关键之一，检测训练分布之外的样本。在某些任务中，检测OOD样本可能具有挑战性，因为ID和OOD类之间存在很大的同化和结构相似性。例如，在诊断胎儿心脏视频中，心脏和其他身体部位（如腹部）之间存在很高的结构相似性，同时心脏还有5种不同的视角和视频内部结构变化。为了在这种情况下检测OOD样本，我们需要构建一个能够总结各个体征变化的模型，同时拒绝类似OOD样本。在这篇论文中，我们提出了双conditioned diffusion模型（DCDM），其中我们将模型 conditioned于ID类信息和输入图像的隐藏特征，以实现图像的重构基于OOD检测。这将限制模型生成图像的概率分布，使其生成结构和semantic相似于训练分布中的图像。我们的模型与参考方法相比，提高了12%的准确率，22%的精度和8%的F1分数。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Hyperbolic-Embeddings-for-Coarse-to-Fine-Robot-Design"><a href="#Leveraging-Hyperbolic-Embeddings-for-Coarse-to-Fine-Robot-Design" class="headerlink" title="Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design"></a>Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00462">http://arxiv.org/abs/2311.00462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heng Dong, Junyu Zhang, Chongjie Zhang</li>
<li>for: 设计多细胞机器人，实现多种任务的高效控制。</li>
<li>methods: 提出了一种新的粗细化到细致的方法，首先寻找优化的粗细机器人，然后逐渐细化。为了解决粗细转换中的决定问题，引入了Hyperbolic Embeddings for Robot Design（HERD）框架。HERD将机器人归一化到共同的虚拟空间中，并使用改进的十字熵方法进行优化。</li>
<li>results: 经验研究表明，该方法在多种复杂任务中显示出优于其他方法的高效性和普适性。<details>
<summary>Abstract</summary>
Multi-cellular robot design aims to create robots comprised of numerous cells that can be efficiently controlled to perform diverse tasks. Previous research has demonstrated the ability to generate robots for various tasks, but these approaches often optimize robots directly in the vast design space, resulting in robots with complicated morphologies that are hard to control. In response, this paper presents a novel coarse-to-fine method for designing multi-cellular robots. Initially, this strategy seeks optimal coarse-grained robots and progressively refines them. To mitigate the challenge of determining the precise refinement juncture during the coarse-to-fine transition, we introduce the Hyperbolic Embeddings for Robot Design (HERD) framework. HERD unifies robots of various granularity within a shared hyperbolic space and leverages a refined Cross-Entropy Method for optimization. This framework enables our method to autonomously identify areas of exploration in hyperbolic space and concentrate on regions demonstrating promise. Finally, the extensive empirical studies on various challenging tasks sourced from EvoGym show our approach's superior efficiency and generalization capability.
</details>
<details>
<summary>摘要</summary>
多细胞机器人设计目标是创建由多个细胞组成的机器人，可以高效控制完成多种任务。前一些研究已经实现了这些任务，但这些方法经常直接优化机器人的设计空间，导致机器人的结构变得复杂，控制困难。因此，本文提出了一种新的粗细到细的设计方法。首先，这种策略寻找最佳粗细机器人，然后进行细化。为了解决在粗细转换过程中决定精细化的具体时间点的挑战，我们提出了Hiperbolic Embeddings for Robot Design（HERD）框架。HERD在多细胞空间中囊括了各种机器人，并利用了改进的十字积分法进行优化。这种框架使我们的方法可以自动在偏特空间中寻找探索的区域，并集中在示 promise的区域。最后，我们对多个复杂任务的实验研究表明，我们的方法具有更高的效率和通用性。
</details></li>
</ul>
<hr>
<h2 id="On-the-Opportunities-of-Green-Computing-A-Survey"><a href="#On-the-Opportunities-of-Green-Computing-A-Survey" class="headerlink" title="On the Opportunities of Green Computing: A Survey"></a>On the Opportunities of Green Computing: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00447">http://arxiv.org/abs/2311.00447</a></li>
<li>repo_url: None</li>
<li>paper_authors: You Zhou, Xiujing Lin, Xiang Zhang, Maolin Wang, Gangwei Jiang, Huakang Lu, Yupeng Wu, Kai Zhang, Zhe Yang, Kehang Wang, Yongduo Sui, Fengwei Jia, Zuoli Tang, Yao Zhao, Hongxuan Zhang, Tiannuo Yang, Weibo Chen, Yunong Mao, Yi Li, De Bao, Yu Li, Hongrui Liao, Ting Liu, Jingwen Liu, Jinchi Guo, Jin Zhao, Xiangyu Zhao, Ying WEI, Hong Qian, Qi Liu, Xiang Wang, Wai Kin, Chan, Chenliang Li, Yusen Li, Shiyu Yang, Jining Yan, Chao Mou, Shuai Han, Wuxia Jin, Guannan Zhang, Xiaodong Zeng</li>
<li>for: 这篇论文主要是为了探讨绿色计算技术在人工智能领域中的应用和发展。</li>
<li>methods: 论文使用了一种系统性的分析方法，概括了绿色计算领域的四个关键组成部分，即“量化环保”、“能效AI”、“能效计算系统”和“可持续性用 случа”。</li>
<li>results: 论文结果表明，绿色计算技术有可能解决人工智能发展所带来的资源约束和环保问题。这个新的研究方向具有很大的潜力，并且鼓励更多的研究人员关注这个领域，让人工智能更加环保。<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) has achieved significant advancements in technology and research with the development over several decades, and is widely used in many areas including computing vision, natural language processing, time-series analysis, speech synthesis, etc. During the age of deep learning, especially with the arise of Large Language Models, a large majority of researchers' attention is paid on pursuing new state-of-the-art (SOTA) results, resulting in ever increasing of model size and computational complexity. The needs for high computing power brings higher carbon emission and undermines research fairness by preventing small or medium-sized research institutions and companies with limited funding in participating in research. To tackle the challenges of computing resources and environmental impact of AI, Green Computing has become a hot research topic. In this survey, we give a systematic overview of the technologies used in Green Computing. We propose the framework of Green Computing and devide it into four key components: (1) Measures of Greenness, (2) Energy-Efficient AI, (3) Energy-Efficient Computing Systems and (4) AI Use Cases for Sustainability. For each components, we discuss the research progress made and the commonly used techniques to optimize the AI efficiency. We conclude that this new research direction has the potential to address the conflicts between resource constraints and AI development. We encourage more researchers to put attention on this direction and make AI more environmental friendly.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在技术和研究方面已经取得了重要进步，并广泛应用于多个领域，如计算视觉、自然语言处理、时间序列分析、语音合成等。在深度学习时代，特别是大语言模型的出现，研究者的关注主要集中在追求新的状态或艺术（SOTA）结果，导致模型的大小和计算复杂度的不断增加。这导致了更高的计算能力和环境影响，同时还妨碍了小或中型研究机构和公司的参与，因为它们有限的资金无法投入研究。为了解决AI计算资源和环境影响的挑战，绿色计算成为了热门的研究方向。在这篇评论中，我们提供了绿色计算的系统性评论，并将其分为四个关键组成部分：（1）绿色度指标，（2）能效AI，（3）能效计算系统，（4）用于可持续发展的AI应用场景。对于每个组成部分，我们讨论了研究进步和优化AI效率的常用技术。我们认为，这新的研究方向具有解决资源约束和AI发展之间的矛盾的潜力。我们劝勉更多的研究者关注这个方向，使AI更加环保。
</details></li>
</ul>
<hr>
<h2 id="A-Systematic-Comparison-of-Syllogistic-Reasoning-in-Humans-and-Language-Models"><a href="#A-Systematic-Comparison-of-Syllogistic-Reasoning-in-Humans-and-Language-Models" class="headerlink" title="A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models"></a>A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00445">http://arxiv.org/abs/2311.00445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiwalayo Eisape, MH Tessler, Ishita Dasgupta, Fei Sha, Sjoerd van Steenkiste, Tal Linzen</li>
<li>for:  investigate whether language models replicate human reasoning biases in logical inference</li>
<li>methods:  using syllogisms to test the logical reasoning abilities of language models, comparing the performance of larger and smaller models and humans</li>
<li>results:  larger models are more logical than smaller ones and humans, but all models make systematic errors and mimic human reasoning biases such as ordering effects and logical fallacies<details>
<summary>Abstract</summary>
A central component of rational behavior is logical inference: the process of determining which conclusions follow from a set of premises. Psychologists have documented several ways in which humans' inferences deviate from the rules of logic. Do language models, which are trained on text generated by humans, replicate these biases, or are they able to overcome them? Focusing on the case of syllogisms -- inferences from two simple premises, which have been studied extensively in psychology -- we show that larger models are more logical than smaller ones, and also more logical than humans. At the same time, even the largest models make systematic errors, some of which mirror human reasoning biases such as ordering effects and logical fallacies. Overall, we find that language models mimic the human biases included in their training data, but are able to overcome them in some cases.
</details>
<details>
<summary>摘要</summary>
人类理智中的一个重要组成部分是逻辑推理：从一组前提中导出结论的过程。心理学家已经记录了人们的推理偏差，而语言模型是否会复制这些偏差？我们通过研究 Syllogisms ，即从两个简单前提中导出结论，发现大型模型比小型模型更逻辑，同时也比人类更逻辑。然而，也有大型模型存在系统性错误，一些与人类理智偏差相似，如顺序效应和逻辑错误。总之，语言模型会吸收来自其训练数据中的人类偏差，但在一些情况下能够超越它们。
</details></li>
</ul>
<hr>
<h2 id="Improving-Robustness-for-Vision-Transformer-with-a-Simple-Dynamic-Scanning-Augmentation"><a href="#Improving-Robustness-for-Vision-Transformer-with-a-Simple-Dynamic-Scanning-Augmentation" class="headerlink" title="Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation"></a>Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00441">http://arxiv.org/abs/2311.00441</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashank Kotyan, Danilo Vasconcellos Vargas</li>
<li>for: 提高计算机视觉任务中 ViT 的准确率和Robustness</li>
<li>methods: 提出了一种名为 “动态扫描增强” 的扩展技术，利用动态输入序列来适应不同的补丁，以保持性能和Robustness</li>
<li>results: 对多种攻击和自然图像进行了详细的测试，发现这种适应性增强了 ViT 的Robustness，从 $17%$ 提高到 $92%$，并且对于自然图像的准确率也有所提高。<details>
<summary>Abstract</summary>
Vision Transformer (ViT) has demonstrated promising performance in computer vision tasks, comparable to state-of-the-art neural networks. Yet, this new type of deep neural network architecture is vulnerable to adversarial attacks limiting its capabilities in terms of robustness. This article presents a novel contribution aimed at further improving the accuracy and robustness of ViT, particularly in the face of adversarial attacks. We propose an augmentation technique called `Dynamic Scanning Augmentation' that leverages dynamic input sequences to adaptively focus on different patches, thereby maintaining performance and robustness. Our detailed investigations reveal that this adaptability to the input sequence induces significant changes in the attention mechanism of ViT, even for the same image. We introduce four variations of Dynamic Scanning Augmentation, outperforming ViT in terms of both robustness to adversarial attacks and accuracy against natural images, with one variant showing comparable results. By integrating our augmentation technique, we observe a substantial increase in ViT's robustness, improving it from $17\%$ to $92\%$ measured across different types of adversarial attacks. These findings, together with other comprehensive tests, indicate that Dynamic Scanning Augmentation enhances accuracy and robustness by promoting a more adaptive type of attention. In conclusion, this work contributes to the ongoing research on Vision Transformers by introducing Dynamic Scanning Augmentation as a technique for improving the accuracy and robustness of ViT. The observed results highlight the potential of this approach in advancing computer vision tasks and merit further exploration in future studies.
</details>
<details>
<summary>摘要</summary>
目标是使用新的深度神经网络架构ViT（Vision Transformer）在计算机视觉任务中表现出色，但是这种架构受到了针对性攻击的限制，增加了其可靠性的问题。这篇文章提出了一种新的贡献，即使用动态扫描加速器来提高ViT的准确率和可靠性，特别是在对抗针对性攻击方面。我们提出的动态扫描加速器利用动态输入序列来适应不同的补丁，以保持性能和可靠性。我们的详细调查表明，这种适应输入序列的能力会导致ViT的注意机制发生显著变化，即使用同一张图片。我们提出了四种变体的动态扫描加速器，其中一种变体与ViT相比，在对抗针对性攻击和自然图像方面均有显著提高。通过将我们的加速器纳入ViT中，我们观察到了ViT的可靠性从17%提高到92%，测试过程中不同类型的针对性攻击中。这些结果，以及其他详细的测试，表明动态扫描加速器可以提高ViT的准确率和可靠性，并促进计算机视觉任务的进步。因此，这种方法在未来的研究中具有潜在的应用前景。
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Generalization-through-Prioritization-and-Diversity-in-Self-Imitation-Reinforcement-Learning-over-Procedural-Environments-with-Sparse-Rewards"><a href="#Enhanced-Generalization-through-Prioritization-and-Diversity-in-Self-Imitation-Reinforcement-Learning-over-Procedural-Environments-with-Sparse-Rewards" class="headerlink" title="Enhanced Generalization through Prioritization and Diversity in Self-Imitation Reinforcement Learning over Procedural Environments with Sparse Rewards"></a>Enhanced Generalization through Prioritization and Diversity in Self-Imitation Reinforcement Learning over Procedural Environments with Sparse Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00426">http://arxiv.org/abs/2311.00426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alain Andres, Daochen Zha, Javier Del Ser</li>
<li>for: The paper is written to address the challenge of exploration in Reinforcement Learning (RL) with sparse rewards, specifically in procedurally-generated (PCG) environments.</li>
<li>methods: The paper proposes tailored self-Imitation Learning (self-IL) sampling strategies that prioritize transitions based on different criteria and address diversity loss through modifications to counteract the impact of generalization requirements and bias introduced by prioritization techniques.</li>
<li>results: The paper achieves a new state-of-the-art performance in the MiniGrid-MultiRoom-N12-S10 environment through experimental analysis conducted over three PCG sparse reward environments, including MiniGrid and ProcGen.Here’s the same information in Simplified Chinese text:</li>
<li>for: 该文章是为了解决在强化学习（RL）中的探索挑战，特别是在生成过程中的环境（PCG）中。</li>
<li>methods: 文章提出了适应性自我模仿学习（自我IL）的采样策略，根据不同的优先级来决定保留哪些经验，并通过修改来减少泛化需求和偏见引入的影响。</li>
<li>results: 通过对三个PCG稀补奖励环境，包括MiniGrid和ProcGen，的实验分析，文章在MiniGrid-MultiRoom-N12-S10环境中达到了新的最佳性能。<details>
<summary>Abstract</summary>
Exploration poses a fundamental challenge in Reinforcement Learning (RL) with sparse rewards, limiting an agent's ability to learn optimal decision-making due to a lack of informative feedback signals. Self-Imitation Learning (self-IL) has emerged as a promising approach for exploration, leveraging a replay buffer to store and reproduce successful behaviors. However, traditional self-IL methods, which rely on high-return transitions and assume singleton environments, face challenges in generalization, especially in procedurally-generated (PCG) environments. Therefore, new self-IL methods have been proposed to rank which experiences to persist, but they replay transitions uniformly regardless of their significance, and do not address the diversity of the stored demonstrations. In this work, we propose tailored self-IL sampling strategies by prioritizing transitions in different ways and extending prioritization techniques to PCG environments. We also address diversity loss through modifications to counteract the impact of generalization requirements and bias introduced by prioritization techniques. Our experimental analysis, conducted over three PCG sparse reward environments, including MiniGrid and ProcGen, highlights the benefits of our proposed modifications, achieving a new state-of-the-art performance in the MiniGrid-MultiRoom-N12-S10 environment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Neural-Implicit-Field-Editing-Considering-Object-environment-Interaction"><a href="#Neural-Implicit-Field-Editing-Considering-Object-environment-Interaction" class="headerlink" title="Neural Implicit Field Editing Considering Object-environment Interaction"></a>Neural Implicit Field Editing Considering Object-environment Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00425">http://arxiv.org/abs/2311.00425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihong Zeng, Zongji Wang, Yuanben Zhang, Weinan Cai, Zehao Cao, Lili Zhang, Yan Guo, Yanhong Zhang, Junyi Liu</li>
<li>for: 该论文主要目标是提出一种基于神经隐藏场的3D场景编辑方法，以解决现有方法中对物体和场景环境的交互不充分考虑的问题。</li>
<li>methods: 该方法基于两条流 neural rendering 系统，其中一条流负责处理物体和场景环境的交互，另一条流则负责处理物体的编辑任务。为了从混合汤中获取照明条件，该系统使用内在分解方法进行成功分离物体和场景环境之间的交互。</li>
<li>results: 该方法可以在对象级编辑任务中生成合理的外观变化，并且在新视图synthesis任务中实现了竞争性的表现质量。<details>
<summary>Abstract</summary>
The 3D scene editing method based on neural implicit field has gained wide attention. It has achieved excellent results in 3D editing tasks. However, existing methods often blend the interaction between objects and scene environment. The change of scene appearance like shadows is failed to be displayed in the rendering view. In this paper, we propose an Object and Scene environment Interaction aware (OSI-aware) system, which is a novel two-stream neural rendering system considering object and scene environment interaction. To obtain illuminating conditions from the mixture soup, the system successfully separates the interaction between objects and scene environment by intrinsic decomposition method. To study the corresponding changes to the scene appearance from object-level editing tasks, we introduce a depth map guided scene inpainting method and shadow rendering method by point matching strategy. Extensive experiments demonstrate that our novel pipeline produce reasonable appearance changes in scene editing tasks. It also achieve competitive performance for the rendering quality in novel-view synthesis tasks.
</details>
<details>
<summary>摘要</summary>
《基于神经隐函数的3D场景编辑方法获得了广泛关注。它在3D编辑任务中表现出色。然而，现有方法经常混合对象和场景环境的交互。改变场景外观的影响，如阴影，在渲染视图中未能正确显示。在这篇论文中，我们提出了一个对象和场景环境相互aware（OSI-aware）系统，这是一种新的两派神经渲染系统，考虑了对象和场景环境的交互。为了从混合液中获得照明条件，我们成功地将对象和场景环境之间的交互分解成内在分解方法。为了研究对象编辑任务中场景外观的相应变化，我们引入了深度地图准入场景填充方法和阴影渲染方法，使用点匹配策略。广泛的实验表明，我们的新ipeline在场景编辑任务中产生了合理的外观变化，同时在新视图合成任务中达到了竞争性的表现质量。》Note: Please keep in mind that the translation is done by a machine and may not be perfect, especially when it comes to the nuances of language and cultural references.
</details></li>
</ul>
<hr>
<h2 id="Couples-can-be-tractable-New-algorithms-and-hardness-results-for-the-Hospitals-Residents-problem-with-Couples"><a href="#Couples-can-be-tractable-New-algorithms-and-hardness-results-for-the-Hospitals-Residents-problem-with-Couples" class="headerlink" title="Couples can be tractable: New algorithms and hardness results for the Hospitals &#x2F; Residents problem with Couples"></a>Couples can be tractable: New algorithms and hardness results for the Hospitals &#x2F; Residents problem with Couples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00405">http://arxiv.org/abs/2311.00405</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gergely Csáji, David Manlove, Iain McBride, James Trimble</li>
<li>for: 这个论文是研究{\sc Hospitals &#x2F; Residents problem with Couples}（{\sc hrc）的，它的解决方案是一个稳定匹配或一份报告表明无法找到匹配。</li>
<li>methods: 我们提出了一种新的多项时间算法，可以在{\sc hrc}实例中找到一个近似稳定匹配（对医院容量进行最多1个调整），其中couples的偏好是不响应（如果一个成员更改为更好的医院，那么夫妻也会改善）和不完全（每对医院都是两个成员都可以接受的）。</li>
<li>results: 我们的算法可以在一个子responsive、子完全的{\sc hrc}实例中找到一个稳定匹配，并且我们也证明了这个算法可以解决一个稳定b匹配问题，其中的基础graph是一个多GraphWithLoops。此外，我们还证明了{\sc hrc}的NP困难性，包括在一些特定的情况下是NP困难的。<details>
<summary>Abstract</summary>
In this paper we study the {\sc Hospitals / Residents problem with Couples} ({\sc hrc}), where a solution is a stable matching or a report that none exists. We present a novel polynomial-time algorithm that can find a near-feasible stable matching (adjusting the hospitals' capacities by at most 1) in an {\sc hrc} instance where the couples' preferences are sub-responsive (i.e., if one member switches to a better hospital, than the couple also improves) and sub-complete (i.e., each pair of hospitals that are individually acceptable to both members are jointly acceptable for the couple) by reducing it to an instance of the {\sc Stable Fixtures} problem. We also present a polynomial-time algorithm for {\sc hrc} in a sub-responsive, sub-complete instance that is a Dual Market, or where all couples are one of several possible types. We show that our algorithm also implies the polynomial-time solvability of a stable b-matching problem, where the underlying graph is a multigraph with loops.   We complement our algorithms with several hardness results. We show that {\sc hrc} with sub-responsive and sub-complete couples is NP-hard, even with other strong restrictions. We also show that {\sc hrc} with a Dual Market is NP-hard under several simultaneous restrictions. Finally, we show that the problem of finding a matching with the minimum number of blocking pairs in {\sc hrc} is not approximable within $m^{1-\varepsilon}$, for any $\varepsilon>0$, where $m$ is the total length of the hospitals' preference lists, unless P=NP, even if each couple applies to only one pair of hospitals. Our polynomial-time solvability results greatly expand the class of known tractable instances of {\sc hrc} and provide additional evidence as to why long-standing entry-level labour markets that allow couples such as the National Resident Matching Program remain successful to this day.
</details>
<details>
<summary>摘要</summary>
在本文中，我们研究了医院和住院医生匹配问题（hrc），其中解决方案是稳定匹配或报告无解。我们提出了一种新的多项式时间算法，可以在hrc实例中，其中伙伴偏好是不响应的（即如果一方转移到更好的医院，那么伙伴也会改善）和不完整的（即每对医院都是两个成员都可以接受的）情况下，通过将医院容量调整到最多1来找到一个近似稳定匹配。我们还提出了一种多项式时间算法，用于hrc实例中的子响应、不完整实例，或者所有的couple都是一种特定类型。我们证明了我们的算法还可以解决稳定b匹配问题，其中下面的图是一个多重图。我们在本文中还提供了多种硬性结果。我们证明了hrc中的sub-responsive和sub-complete伙伴是NP困难的，即无论做出哪些强制限制，hrc都是NP困难的。我们还证明了hrc中的dual market是NP困难的，只要满足一些同时的强制限制。最后，我们证明了hrc中寻找最小数量的堵塞对的匹配是不可以approximate在$m^{1-\varepsilon}$中，其中$m$是医院的偏好列表总长度，任何$\varepsilon>0$。我们的多项式时间可行性结果大大扩展了知道的可解实例，并提供了更多的证明，证明为什么长期存在的入门级劳动市场，如国家住院医生匹配计划，至今仍然成功。
</details></li>
</ul>
<hr>
<h2 id="A-Spatial-Temporal-Transformer-based-Framework-For-Human-Pose-Assessment-And-Correction-in-Education-Scenarios"><a href="#A-Spatial-Temporal-Transformer-based-Framework-For-Human-Pose-Assessment-And-Correction-in-Education-Scenarios" class="headerlink" title="A Spatial-Temporal Transformer based Framework For Human Pose Assessment And Correction in Education Scenarios"></a>A Spatial-Temporal Transformer based Framework For Human Pose Assessment And Correction in Education Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00401">http://arxiv.org/abs/2311.00401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenyang Hu, Kai Liu, Libin Liu, Huiliang Shang</li>
<li>for: 这篇论文是为了提供一个基于空间-时间转换器的框架，用于在教育场景中评估和修正学生的人体姿势。</li>
<li>methods: 该框架包括skeletal tracking、pose estimation、姿势评估和姿势修正模块，以提供专业、快速修复反馈。</li>
<li>results: 我们的模型可以有效地评估和修正学生的动作质量。STTF利用转换器模型捕捉人体姿势的空间和时间相关性，实现了准确的评估和有效的修正。<details>
<summary>Abstract</summary>
Human pose assessment and correction play a crucial role in applications across various fields, including computer vision, robotics, sports analysis, healthcare, and entertainment. In this paper, we propose a Spatial-Temporal Transformer based Framework (STTF) for human pose assessment and correction in education scenarios such as physical exercises and science experiment. The framework comprising skeletal tracking, pose estimation, posture assessment, and posture correction modules to educate students with professional, quick-to-fix feedback. We also create a pose correction method to provide corrective feedback in the form of visual aids. We test the framework with our own dataset. It comprises (a) new recordings of five exercises, (b) existing recordings found on the internet of the same exercises, and (c) corrective feedback on the recordings by professional athletes and teachers. Results show that our model can effectively measure and comment on the quality of students' actions. The STTF leverages the power of transformer models to capture spatial and temporal dependencies in human poses, enabling accurate assessment and effective correction of students' movements.
</details>
<details>
<summary>摘要</summary>
人体姿势评估和修正在多个领域中扮演着关键角色，包括计算机视觉、机器人学、运动分析、医疗和娱乐等。在这篇论文中，我们提出了基于空间时间变换器（STTF）的人体姿势评估和修正框架，用于在教育场景中评估和修正学生的 физи 活动和科学实验中的姿势。该框架包括骨骼跟踪、姿势估计、姿势评价和姿势修正模块，以提供专业、快速修复的反馈。我们还开发了一种姿势修正方法，以提供可见的修正反馈。我们对自己的数据集进行测试，该数据集包括（a）新录制的五种运动动作，（b）互联网上已有的同样运动动作的录制，以及（c）由专业运动员和教师提供的修正反馈。结果表明，我们的模型可以有效地评估和修正学生的动作质量。STTF利用变换器模型来捕捉人体姿势中的空间和时间相依关系，以便准确地评估和修正学生的动作。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-deep-neural-networks-with-symbolic-knowledge-Towards-trustworthy-and-interpretable-AI-for-education"><a href="#Augmenting-deep-neural-networks-with-symbolic-knowledge-Towards-trustworthy-and-interpretable-AI-for-education" class="headerlink" title="Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education"></a>Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00393">http://arxiv.org/abs/2311.00393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danial Hooshyar, Roger Azevedo, Yeongwook Yang</li>
<li>for: 该研究旨在探讨人工神经网络（ANNs）在教育应用中的限制，并提出一种基于神经符号学家AI的解决方案，以增强ANNs的教育潜力。</li>
<li>methods: 该研究采用了一种基于神经符号学家AI的方法，称为NSAI，可以在深度神经网络中注入和提取教育知识。</li>
<li>results: 研究发现，NSAI方法比深度神经网络 Merely 训练数据和数据增强方法（SMOTE和自动编码器）的模型具有更好的泛化性。此外，NSAI方法可以减少训练数据中的偏见和自适应性，并提供可读性和解释性的规则。<details>
<summary>Abstract</summary>
Artificial neural networks (ANNs) have shown to be amongst the most important artificial intelligence (AI) techniques in educational applications, providing adaptive educational services. However, their educational potential is limited in practice due to three major challenges: i) difficulty in incorporating symbolic educational knowledge (e.g., causal relationships, and practitioners' knowledge) in their development, ii) learning and reflecting biases, and iii) lack of interpretability. Given the high-risk nature of education, the integration of educational knowledge into ANNs becomes crucial for developing AI applications that adhere to essential educational restrictions, and provide interpretability over the predictions. This research argues that the neural-symbolic family of AI has the potential to address the named challenges. To this end, it adapts a neural-symbolic AI framework and accordingly develops an approach called NSAI, that injects and extracts educational knowledge into and from deep neural networks, for modelling learners computational thinking. Our findings reveal that the NSAI approach has better generalizability compared to deep neural networks trained merely on training data, as well as training data augmented by SMOTE and autoencoder methods. More importantly, unlike the other models, the NSAI approach prioritises robust representations that capture causal relationships between input features and output labels, ensuring safety in learning to avoid spurious correlations and control biases in training data. Furthermore, the NSAI approach enables the extraction of rules from the learned network, facilitating interpretation and reasoning about the path to predictions, as well as refining the initial educational knowledge. These findings imply that neural-symbolic AI can overcome the limitations of ANNs in education, enabling trustworthy and interpretable applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Difficulty in incorporating symbolic educational knowledge (e.g., causal relationships, practitioners’ knowledge) in their development.2. Learning and reflecting biases.3. Lack of interpretability.To address these challenges, this research advocates for the use of neural-symbolic AI, which has the potential to integrate educational knowledge into ANNs and provide interpretability over the predictions. The proposed approach, called NSAI, injects and extracts educational knowledge into and from deep neural networks, enabling the modelling of learners’ computational thinking.The results show that the NSAI approach has better generalizability compared to deep neural networks trained merely on training data, as well as training data augmented by SMOTE and autoencoder methods. Additionally, the NSAI approach prioritizes robust representations that capture causal relationships between input features and output labels, ensuring safety in learning and avoiding spurious correlations and control biases in training data.Moreover, the NSAI approach enables the extraction of rules from the learned network, facilitating interpretation and reasoning about the path to predictions, as well as refining the initial educational knowledge. These findings suggest that neural-symbolic AI can overcome the limitations of ANNs in education, enabling trustworthy and interpretable applications.</details></li>
</ol>
<hr>
<h2 id="Will-Code-Remain-a-Relevant-User-Interface-for-End-User-Programming-with-Generative-AI-Models"><a href="#Will-Code-Remain-a-Relevant-User-Interface-for-End-User-Programming-with-Generative-AI-Models" class="headerlink" title="Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?"></a>Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00382">http://arxiv.org/abs/2311.00382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Advait Sarkar</li>
<li>for: 本研究探讨了在生成AI时，传统编程语言仍然对非专业程序员有用性的问题。</li>
<li>methods: 本文采用了观察研究的方法，探讨了生成AI对非专业程序员的影响。</li>
<li>results: 本文提出了“生成shift假设”，即生成AI会对传统编程语言产生质量和量上的扩展。同时，文章还探讨了传统编程语言在非专业程序员中的可能性。<details>
<summary>Abstract</summary>
The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which "traditional" programming languages remain relevant for non-expert end-user programmers in a world with generative AI. We posit the "generative shift hypothesis": that generative AI will create qualitative and quantitative expansions in the traditional scope of end-user programming. We outline some reasons that traditional programming languages may still be relevant and useful for end-user programmers. We speculate whether each of these reasons might be fundamental and enduring, or whether they may disappear with further improvements and innovations in generative AI. Finally, we articulate a set of implications for end-user programming research, including the possibility of needing to revisit many well-established core concepts, such as Ko's learning barriers and Blackwell's attention investment model.
</details>
<details>
<summary>摘要</summary>
研究领域内的终端用户编程主要关注于帮助非专业人员学习编程，以便实现他们的任务。生成AI可能将把用户的编程需求转化为自然语言提示，从而彻底改变这一情况。在这篇文章中，我们探讨了传统编程语言在非专业终端编程者面前是否仍然有用的问题。我们提出了“生成转移 гипотеза”：生成AI会使得终端编程的范围发生质量和量上的扩展。我们列举了传统编程语言在非专业终端编程者面前可能仍然有用的原因。我们推测这些原因是否是基本和普遍的，或者将随着生成AI的进一步改进和创新而消失。最后，我们详细介绍了终端编程研究的影响，包括可能需要重新评估许多已有核心概念，如科氏学习障碍和布莱克威尔注意力投入模型。
</details></li>
</ul>
<hr>
<h2 id="Architecture-of-Data-Anomaly-Detection-Enhanced-Decentralized-Expert-System-for-Early-Stage-Alzheimer’s-Disease-Prediction"><a href="#Architecture-of-Data-Anomaly-Detection-Enhanced-Decentralized-Expert-System-for-Early-Stage-Alzheimer’s-Disease-Prediction" class="headerlink" title="Architecture of Data Anomaly Detection-Enhanced Decentralized Expert System for Early-Stage Alzheimer’s Disease Prediction"></a>Architecture of Data Anomaly Detection-Enhanced Decentralized Expert System for Early-Stage Alzheimer’s Disease Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00373">http://arxiv.org/abs/2311.00373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Kambiz Behfar, Qumars Behfar, Marzie Hosseinpour</li>
<li>for: 这个研究旨在早期检测阿尔茨海默病，以提高病人结果。</li>
<li>methods: 这个研究使用了分布式专家系统，结合区块链技术和人工智能，以实现Robust anomaly detection。</li>
<li>results: 这个系统可以提供更精确的早期阿尔茨海默病预测，并保护数据完整性和病人隐私。<details>
<summary>Abstract</summary>
Alzheimer's Disease is a global health challenge that requires early and accurate detection to improve patient outcomes. Magnetic Resonance Imaging (MRI) holds significant diagnostic potential, but its effective analysis remains a formidable task. This study introduces a groundbreaking decentralized expert system that cleverly combines blockchain technology with Artificial Intelligence (AI) to integrate robust anomaly detection for patient-submitted data.   Traditional diagnostic methods often lead to delayed and imprecise predictions, especially in the early stages of the disease. Centralized data repositories struggle to manage the immense volumes of MRI data, and persistent privacy concerns hinder collaborative efforts. Our innovative solution harnesses decentralization to protect data integrity and patient privacy, facilitated by blockchain technology. It not only emphasizes AI-driven MRI analysis but also incorporates a sophisticated data anomaly detection architecture. These mechanisms scrutinize patient-contributed data for various issues, including data quality problems and atypical findings within MRI images.   Conducting an exhaustive check of MRI image correctness and quality directly on the blockchain is impractical due to computational complexity and cost constraints. Typically, such checks are performed off-chain, and the blockchain securely records the results. This comprehensive approach empowers our decentralized app to provide more precise early-stage Alzheimer's Disease predictions. By merging the strengths of blockchain, AI, and anomaly detection, our system represents a pioneering step towards revolutionizing disease diagnostics.
</details>
<details>
<summary>摘要</summary>
阿尔茨海默病是全球医疗挑战，早期检测是提高病人结果的关键。核磁共振成像（MRI）具有诊断潜力，但是有效分析具有挑战。这项研究推出了创新的分布式专家系统，协调区块链技术和人工智能（AI），以实现强大的异常检测。传统诊断方法通常会导致延迟和不准确的预测，特别是早期病情阶段。中央数据存储系统忙于管理大量MRI数据，而持续的隐私问题阻碍了合作努力。我们的创新解决方案利用分布式保护数据完整性和患者隐私，通过区块链技术。它不仅强调AI驱动的MRI分析，还包括了复杂的数据异常检测建筑。这些机制在患者提供的数据中检测了各种问题，包括数据质量问题和MRI图像中的异常现象。由于计算复杂性和成本约束，在区块链上进行全面的MRI图像正确性和质量检查是不实际。通常，这些检查在外部进行，并将结果记录在区块链上。这种全面的方法使我们的分布式应用程序提供更精准的早期阿尔茨海默病预测。通过融合区块链、AI和异常检测的优势，我们的系统表现出了革新的潜力，为疾病诊断领域带来巨大的改变。
</details></li>
</ul>
<hr>
<h2 id="Prompt-based-Logical-Semantics-Enhancement-for-Implicit-Discourse-Relation-Recognition"><a href="#Prompt-based-Logical-Semantics-Enhancement-for-Implicit-Discourse-Relation-Recognition" class="headerlink" title="Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition"></a>Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00367">http://arxiv.org/abs/2311.00367</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lalalamdbf/plse_idrr">https://github.com/lalalamdbf/plse_idrr</a></li>
<li>paper_authors: Chenxu Wang, Ping Jian, Mu Huang<br>for: 本文主要针对推广语句关系识别（IDRR）进行研究，并提出一种基于提示的逻辑 semantics 增强方法（PLSE），以提高 IDRR 的性能和可靠性。methods: 本文使用了预训语言模型的提示基于逻辑 semantics 预测，以将知识与语句关系相互连接。此外，为了解决预测器的局部依赖问题，本文提出了一种基于互联信息最大化的自愿学习目标，以从中获得提高的逻辑 semantics 表示。results: 本文在 PDTB 2.0 和 CoNLL16 数据集上实验ally demonstrate that our PLSE method achieves outstanding and consistent performance against the current state-of-the-art models。<details>
<summary>Abstract</summary>
Implicit Discourse Relation Recognition (IDRR), which infers discourse relations without the help of explicit connectives, is still a crucial and challenging task for discourse parsing. Recent works tend to exploit the hierarchical structure information from the annotated senses, which demonstrate enhanced discourse relation representations can be obtained by integrating sense hierarchy. Nevertheless, the performance and robustness for IDRR are significantly constrained by the availability of annotated data. Fortunately, there is a wealth of unannotated utterances with explicit connectives, that can be utilized to acquire enriched discourse relation features. In light of such motivation, we propose a Prompt-based Logical Semantics Enhancement (PLSE) method for IDRR. Essentially, our method seamlessly injects knowledge relevant to discourse relation into pre-trained language models through prompt-based connective prediction. Furthermore, considering the prompt-based connective prediction exhibits local dependencies due to the deficiency of masked language model (MLM) in capturing global semantics, we design a novel self-supervised learning objective based on mutual information maximization to derive enhanced representations of logical semantics for IDRR. Experimental results on PDTB 2.0 and CoNLL16 datasets demonstrate that our method achieves outstanding and consistent performance against the current state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
《含义推理提升（IDRR）》是一项挑战性的自然语言处理任务，它推断话语关系无需显式连接。在最近的研究中，人们通常利用话语结构信息，从注解的意思中获得增强的话语关系表示。然而，IDRR的性能和可靠性受到注解数据的可用性的限制。幸运的是，有大量未注解的句子，可以用于获得增强的话语关系特征。基于这种动机，我们提出了一种《含义推理提升（PLSE）》方法，用于IDRR。我们的方法通过提供相关的话语关系知识，使预训练语言模型内置了含义推理能力。此外，由于隐藏语言模型（MLM）无法捕捉全局 semantics，我们设计了一种新的自动学习目标，基于mutual information maximization来 derivate增强的含义semantics表示。实验结果表明，我们的方法在 PDTB 2.0 和 CoNLL16 数据集上达到了当前状态的最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Samples-Selection-for-Contrastive-Learning-Mining-of-Potential-Samples"><a href="#Rethinking-Samples-Selection-for-Contrastive-Learning-Mining-of-Potential-Samples" class="headerlink" title="Rethinking Samples Selection for Contrastive Learning: Mining of Potential Samples"></a>Rethinking Samples Selection for Contrastive Learning: Mining of Potential Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00358">http://arxiv.org/abs/2311.00358</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengkui Dong, Xianzhong Long, Yun Li</li>
<li>for: 本研究旨在提高对比学习中样本采样的方法，以提高模型的自助学习能力。</li>
<li>methods: 我们的方法包括两个方面：首先，对于正样本，我们考虑了数据增强得到的扩展样本视图以及数据挖掘得到的样本视图，并使用软和硬权重策略权重合并。其次，我们分析了负样本的梯度方面，并 mines 适度困难的负样本作为可能的负样本。</li>
<li>results: 我们的方法在CIFAR10、CIFAR100和TinyImagenet等 datasets上进行了实验，并显示了与一些传统自助学习方法相比明显的优势。我们的方法在这些 datasets 上取得了88.57%、61.10%和36.69%的 top-1 准确率。<details>
<summary>Abstract</summary>
Contrastive learning predicts whether two images belong to the same category by training a model to make their feature representations as close or as far away as possible. In this paper, we rethink how to mine samples in contrastive learning, unlike other methods, our approach is more comprehensive, taking into account both positive and negative samples, and mining potential samples from two aspects: First, for positive samples, we consider both the augmented sample views obtained by data augmentation and the mined sample views through data mining. Then, we weight and combine them using both soft and hard weighting strategies. Second, considering the existence of uninformative negative samples and false negative samples in the negative samples, we analyze the negative samples from the gradient perspective and finally mine negative samples that are neither too hard nor too easy as potential negative samples, i.e., those negative samples that are close to positive samples. The experiments show the obvious advantages of our method compared with some traditional self-supervised methods. Our method achieves 88.57%, 61.10%, and 36.69% top-1 accuracy on CIFAR10, CIFAR100, and TinyImagenet, respectively.
</details>
<details>
<summary>摘要</summary>
异构学习预测两张图像属于同一个类别，通过训练模型使其特征表示更加相近或更加远 away。在这篇论文中，我们重新思考了如何采样异构学习中的样本。不同于其他方法，我们的方法更加全面，考虑了两种样本类型的样本：首先，对于正样本，我们考虑了数据扩充后得到的扩充样本视图，以及通过数据挖掘得到的样本视图。然后，我们将它们权重和组合使用软和硬权重策略。其次，我们分析了负样本中的不用fu正样本和假负样本，并最终 mines这些负样本，即与正样本相似的负样本。实验显示，我们的方法与一些传统的自助学习方法相比，具有明显的优势。我们的方法在CIFAR10、CIFAR100和TinyImagenet上取得了88.57%、61.10%和36.69%的top-1准确率。
</details></li>
</ul>
<hr>
<h2 id="QFree-A-Universal-Value-Function-Factorization-for-Multi-Agent-Reinforcement-Learning"><a href="#QFree-A-Universal-Value-Function-Factorization-for-Multi-Agent-Reinforcement-Learning" class="headerlink" title="QFree: A Universal Value Function Factorization for Multi-Agent Reinforcement Learning"></a>QFree: A Universal Value Function Factorization for Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00356">http://arxiv.org/abs/2311.00356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rizhong Wang, Huiping Li, Di Cui, Demin Xu</li>
<li>For: The paper is written to propose a universal value function factorization method for multi-agent reinforcement learning (MARL) that satisfies the individual-global-max (IGM) principle without imposing additional limitations on the IGM function class.* Methods: The paper develops a mathematical equivalent conditions of the IGM principle based on the advantage function, and establishes a more expressive mixing network architecture that can fulfill the equivalent factorization. The novel loss function is developed by considering the equivalent conditions as regularization term during policy evaluation in the MARL algorithm.* Results: The proposed method, called QFree, is verified in a nonmonotonic matrix game scenario and achieves state-of-the-art performance in a general-purpose complex MARL benchmark environment, Starcraft Multi-Agent Challenge (SMAC).Here are the three points in Simplified Chinese:* For: 本 paper 是为了提出一种满足个体-全局-最大 (IGM) 原理的多智能体学习 (MARL) 价值函数分解方法。* Methods: 本 paper 基于优势函数的数学等价条件来定义 IGM 原理，并设计了一种更具表达能力的混合网络架构来满足等价分解。  novel 损失函数是在 MARL 算法中评估政策时考虑等价条件作为正则项来开发的。* Results: QFree 在非卷积环境中证明了其效果，并在 Starcraft Multi-Agent Challenge (SMAC) 多智能体挑战环境中达到了当前最佳性能。<details>
<summary>Abstract</summary>
Centralized training is widely utilized in the field of multi-agent reinforcement learning (MARL) to assure the stability of training process. Once a joint policy is obtained, it is critical to design a value function factorization method to extract optimal decentralized policies for the agents, which needs to satisfy the individual-global-max (IGM) principle. While imposing additional limitations on the IGM function class can help to meet the requirement, it comes at the cost of restricting its application to more complex multi-agent environments. In this paper, we propose QFree, a universal value function factorization method for MARL. We start by developing mathematical equivalent conditions of the IGM principle based on the advantage function, which ensures that the principle holds without any compromise, removing the conservatism of conventional methods. We then establish a more expressive mixing network architecture that can fulfill the equivalent factorization. In particular, the novel loss function is developed by considering the equivalent conditions as regularization term during policy evaluation in the MARL algorithm. Finally, the effectiveness of the proposed method is verified in a nonmonotonic matrix game scenario. Moreover, we show that QFree achieves the state-of-the-art performance in a general-purpose complex MARL benchmark environment, Starcraft Multi-Agent Challenge (SMAC).
</details>
<details>
<summary>摘要</summary>
中央化训练在多智能学习（MARL）领域广泛应用，以确保训练过程的稳定性。一旦获得共同策略，然后需要设计一种值函数分解方法，以EXTRACT optimal的分布式策略，满足IGM原则。虽然通过添加额外限制IGM函数类型可以帮助适应更复杂的多智能环境，但是这会增加训练复杂性。在这篇论文中，我们提出了QFree，一种通用的值函数分解方法 для MARL。我们首先开发了IGM原则的数学等价条件，以确保该原则在不妥协的情况下保持有效，从而消除传统方法中的保守性。然后，我们设计了一种更具表达能力的混合网络架构，可以满足等价分解。具体来说，我们开发了一种新的损失函数，通过在MARL算法中考虑等价条件来评估策略。最后，我们证明了提案的效果，在非 monotonic 矩阵游戏场景中进行了验证。此外，我们还证明了QFree在一个通用的复杂 MARL 环境中达到了状态领先性，例如Starcraft Multi-Agent Challenge（SMAC）。
</details></li>
</ul>
<hr>
<h2 id="tmn-at-SMM4H-2023-Comparing-Text-Preprocessing-Techniques-for-Detecting-Tweets-Self-reporting-a-COVID-19-Diagnosis"><a href="#tmn-at-SMM4H-2023-Comparing-Text-Preprocessing-Techniques-for-Detecting-Tweets-Self-reporting-a-COVID-19-Diagnosis" class="headerlink" title="tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for Detecting Tweets Self-reporting a COVID-19 Diagnosis"></a>tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for Detecting Tweets Self-reporting a COVID-19 Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00732">http://arxiv.org/abs/2311.00732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anna Glazkova</li>
<li>for: 本文描述了在SMM4H 2023年度任务1中开发的一种系统，用于自动分类报告COVID-19诊断的推特。</li>
<li>methods: 本文使用了不同的技术进行推特处理，并使用四种基于 transformer 的模型进行 fine-tuning。</li>
<li>results: ensemble 的 fine-tuned 语言模型得到了84.5%的 F1 分数，比平均值高出4.1%。<details>
<summary>Abstract</summary>
The paper describes a system developed for Task 1 at SMM4H 2023. The goal of the task is to automatically distinguish tweets that self-report a COVID-19 diagnosis (for example, a positive test, clinical diagnosis, or hospitalization) from those that do not. We investigate the use of different techniques for preprocessing tweets using four transformer-based models. The ensemble of fine-tuned language models obtained an F1-score of 84.5%, which is 4.1% higher than the average value.
</details>
<details>
<summary>摘要</summary>
文章描述了在SMM4H 2023年的任务1中开发的系统。任务的目标是自动分类推特中的自测COVID-19诊断（例如，正确的测试、临床诊断或入院）和不符的推特。我们研究了不同的预处理技术，使用四种基于转换器的模型进行预处理，并获得了 ensemble 的精度模型，其 F1 分数为 84.5%，高于平均值4.1%。
</details></li>
</ul>
<hr>
<h2 id="A-Definition-of-Open-Ended-Learning-Problems-for-Goal-Conditioned-Agents"><a href="#A-Definition-of-Open-Ended-Learning-Problems-for-Goal-Conditioned-Agents" class="headerlink" title="A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents"></a>A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00344">http://arxiv.org/abs/2311.00344</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olivier Sigaud, Gianluca Baldassarre, Cedric Colas, Stephane Doncieux, Richard Duro, Nicolas Perrin-Gilbert, Vieri Giuliano Santucci</li>
<li>for: 本研究为了解决开放式学习概念的不同定义和相关概念（如 continual learning、生命长学习和自我规划学习）之间的差异，并提出一个基本元素Property的定义，以便更好地理解开放式学习的本质。</li>
<li>methods: 本研究使用了论述和分析方法，描述了开放式学习的基本概念和历史发展，并提出了一种基于时间无穷horizon的开放式学习问题的定义方法。</li>
<li>results: 本研究显示了开放式学习的基本元素Property，并提出了一种基于这个元素的开放式学习问题的定义方法。此外，本研究还指出了在开放式学习领域还需要进一步的研究，以填充开放式学习与更广泛的发展人工智能研究中的差异。<details>
<summary>Abstract</summary>
A lot of recent machine learning research papers have "Open-ended learning" in their title. But very few of them attempt to define what they mean when using the term. Even worse, when looking more closely there seems to be no consensus on what distinguishes open-ended learning from related concepts such as continual learning, lifelong learning or autotelic learning. In this paper, we contribute to fixing this situation. After illustrating the genealogy of the concept and more recent perspectives about what it truly means, we outline that open-ended learning is generally conceived as a composite notion encompassing a set of diverse properties. In contrast with these previous approaches, we propose to isolate a key elementary property of open-ended processes, which is to always produce novel elements from time to time over an infinite horizon. From there, we build the notion of open-ended learning problems and focus in particular on the subset of open-ended goal-conditioned reinforcement learning problems, as this framework facilitates the definition of learning a growing repertoire of skills. Finally, we highlight the work that remains to be performed to fill the gap between our elementary definition and the more involved notions of open-ended learning that developmental AI researchers may have in mind.
</details>
<details>
<summary>摘要</summary>
很多最近的机器学习研究论文中都有“开放式学习”的标题，但很少有人尝试定义这个术语的含义。甚至更糟糕的是，当仔细查看时，似乎没有一致性的定义将开放式学习与相关概念，如持续学习、人生学习或自我追求学习区分开。在这篇论文中，我们贡献到解决这个问题。我们首先描述了概念的家系和更近期的观点，然后提出了开放式学习是一种复杂的概念，包括多种多样的性质。与之前的方法不同，我们提出了开放式学习过程的关键基本属性——在无穷远 horizon 上不断产生新的元素。从而，我们建立了开放式学习问题的概念，特别是关注开放式目标条件强化学习问题，因为这种框架可以定义学习增长的技能集。最后，我们强调了将这些基本定义与发展人工智能研究者可能有的更复杂的开放式学习概念相关的工作还需要进行。
</details></li>
</ul>
<hr>
<h2 id="MetisFL-An-Embarrassingly-Parallelized-Controller-for-Scalable-Efficient-Federated-Learning-Workflows"><a href="#MetisFL-An-Embarrassingly-Parallelized-Controller-for-Scalable-Efficient-Federated-Learning-Workflows" class="headerlink" title="MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows"></a>MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp; Efficient Federated Learning Workflows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00334">http://arxiv.org/abs/2311.00334</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitris Stripelis, Chrysovalantis Anastasiou, Patrick Toral, Armaghan Asghar, Jose Luis Ambite</li>
<li>for: 这个研究旨在提高 Federated Learning（FL）系统中的联合控制器可扩展性和可携性。</li>
<li>methods: 这个研究使用了一个名为 MetisFL 的新型 FL 系统，将联合控制器设计为“首席公民”，重新设计了联合控制器进行大规模 FL 工作流程的加速。</li>
<li>results: 透过对其他州旗性 FL 系统进行量化比较，这个研究证明了 MetisFL 在实际应用中可以获得10倍的压缩时间执行提升，适用于各种具有增加模型大小和联合网站的具有挑战性的 FL 工作流程。<details>
<summary>Abstract</summary>
A Federated Learning (FL) system typically consists of two core processing entities: the federation controller and the learners. The controller is responsible for managing the execution of FL workflows across learners and the learners for training and evaluating federated models over their private datasets. While executing an FL workflow, the FL system has no control over the computational resources or data of the participating learners. Still, it is responsible for other operations, such as model aggregation, task dispatching, and scheduling. These computationally heavy operations generally need to be handled by the federation controller. Even though many FL systems have been recently proposed to facilitate the development of FL workflows, most of these systems overlook the scalability of the controller. To meet this need, we designed and developed a novel FL system called MetisFL, where the federation controller is the first-class citizen. MetisFL re-engineers all the operations conducted by the federation controller to accelerate the training of large-scale FL workflows. By quantitatively comparing MetisFL against other state-of-the-art FL systems, we empirically demonstrate that MetisFL leads to a 10-fold wall-clock time execution boost across a wide range of challenging FL workflows with increasing model sizes and federation sites.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:一个 Federated Learning (FL) 系统通常包括两个核心处理实体：联邦控制器和学习者。控制器负责管理执行 FL 工作流程 across 学习者和学习者对其私有数据上的训练和评估联邦模型。在执行 FL 工作流程时，FL 系统没有对参与学习者的计算资源或数据进行控制。然而，它负责其他操作，如模型集成、任务分配和调度。这些计算沉重的操作通常需要由联邦控制器处理。虽然有很多 FL 系统最近被提出来促进 FL 工作流程的开发，但大多数这些系统忽略了控制器的扩展性。为了解决这个需求，我们设计并开发了一个新的 FL 系统 called MetisFL，其中联邦控制器是首要公民。MetisFL 重新设计了联邦控制器所执行的所有操作，以加速训练大规模 FL 工作流程。通过对 MetisFL 与其他当前状态艺术 FL 系统进行Quantitative比较，我们实际地证明 MetisFL 在各种挑战性 FL 工作流程中具有10倍的增速。
</details></li>
</ul>
<hr>
<h2 id="Robust-Graph-Clustering-via-Meta-Weighting-for-Noisy-Graphs"><a href="#Robust-Graph-Clustering-via-Meta-Weighting-for-Noisy-Graphs" class="headerlink" title="Robust Graph Clustering via Meta Weighting for Noisy Graphs"></a>Robust Graph Clustering via Meta Weighting for Noisy Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00322">http://arxiv.org/abs/2311.00322</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hyeonsoojo/metagc">https://github.com/hyeonsoojo/metagc</a></li>
<li>paper_authors: Hyeonsoo Jo, Fanchen Bu, Kijung Shin</li>
<li>for: robustly clustering graphs with noise edges</li>
<li>methods: using a decomposable clustering loss function and meta-weighting to adaptively adjust node pair weights</li>
<li>results: outperforms state-of-the-art GNN-based competitors on five real-world graphs under varying levels of noise<details>
<summary>Abstract</summary>
How can we find meaningful clusters in a graph robustly against noise edges? Graph clustering (i.e., dividing nodes into groups of similar ones) is a fundamental problem in graph analysis with applications in various fields. Recent studies have demonstrated that graph neural network (GNN) based approaches yield promising results for graph clustering. However, we observe that their performance degenerates significantly on graphs with noise edges, which are prevalent in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC employs a decomposable clustering loss function, which can be rephrased as a sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We show empirically that MetaGC learns weights as intended and consequently outperforms the state-of-the-art GNN-based competitors, even when they are equipped with separate denoising schemes, on five real-world graphs under varying levels of noise. Our code and datasets are available at https://github.com/HyeonsooJo/MetaGC.
</details>
<details>
<summary>摘要</summary>
如何在图中寻找有意义的集群？图分组（即将节点分组到相似的节点集中）是图分析的基本问题，具有各种应用场景。 latest studies have shown that graph neural network (GNN) based approaches have promising results for graph clustering. However, we observe that their performance degrades significantly on graphs with noise edges, which are common in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC uses a decomposable clustering loss function, which can be rephrased as a sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We empirically show that MetaGC learns weights as intended and consequently outperforms the state-of-the-art GNN-based competitors, even when they are equipped with separate denoising schemes, on five real-world graphs under varying levels of noise. Our code and datasets are available at <https://github.com/HyeonsooJo/MetaGC>.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Lexical-Simplification-with-Context-Augmentation"><a href="#Unsupervised-Lexical-Simplification-with-Context-Augmentation" class="headerlink" title="Unsupervised Lexical Simplification with Context Augmentation"></a>Unsupervised Lexical Simplification with Context Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00310">http://arxiv.org/abs/2311.00310</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/twadada/lexsub_decontextualised">https://github.com/twadada/lexsub_decontextualised</a></li>
<li>paper_authors: Takashi Wada, Timothy Baldwin, Jey Han Lau</li>
<li>for: 这个论文主要是为了提出一种新的无监督词归简方法，使用单语言数据和预训练语言模型。</li>
<li>methods: 该方法使用目标词和其上下文作为输入，通过基于目标上下文和额外样本的策略生成替换词。</li>
<li>results: 在英语、葡萄牙语和西班牙语的TSAR-2022分享任务上，该模型与其他无监督系统相比，具有显著的性能优势，并在拼接GPT-3.5模型后创造出新的状态天。此外，在SWORDS词归简数据集上进行评估，该模型也实现了新的状态天。<details>
<summary>Abstract</summary>
We propose a new unsupervised lexical simplification method that uses only monolingual data and pre-trained language models. Given a target word and its context, our method generates substitutes based on the target context and also additional contexts sampled from monolingual data. We conduct experiments in English, Portuguese, and Spanish on the TSAR-2022 shared task, and show that our model substantially outperforms other unsupervised systems across all languages. We also establish a new state-of-the-art by ensembling our model with GPT-3.5. Lastly, we evaluate our model on the SWORDS lexical substitution data set, achieving a state-of-the-art result.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的无监督词性简化方法，只使用单语言数据和预训练语言模型。给定目标词和其上下文，我们的方法生成替换基于目标上下文和其他从单语言数据采样的上下文。我们在英语、葡萄牙语和西班牙语的TSAR-2022共享任务上进行实验，并显示我们的模型在所有语言上明显超过其他无监督系统。我们还在我们的模型和GPT-3.5的拟合中成立了新的状态对。最后，我们对SWORDS词性替换数据集进行评估，达到了状态纪录。
</details></li>
</ul>
<hr>
<h2 id="From-Image-to-Language-A-Critical-Analysis-of-Visual-Question-Answering-VQA-Approaches-Challenges-and-Opportunities"><a href="#From-Image-to-Language-A-Critical-Analysis-of-Visual-Question-Answering-VQA-Approaches-Challenges-and-Opportunities" class="headerlink" title="From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities"></a>From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00308">http://arxiv.org/abs/2311.00308</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Farhan Ishmam, Md Sakib Hossain Shovon, M. F. Mridha, Nilanjan Dey</li>
<li>for: 本论文旨在探讨视觉问答（VQA）领域的多模态任务，包括计算机视觉（CV）和自然语言处理（NLP）等方面，并且旨在根据任何视觉输入生成问题的答案。</li>
<li>methods: 本论文 introduce a detailed taxonomy to categorize the facets of VQA, 并且总结了随着时间的推移，VQA的范围从原始的自然图像集扩展到 sintetic images、视频、3D环境等多种视觉输入。此外，本论文还探讨了大量预训练网络的出现对VQA的影响，从而导致了传统的特征提取和融合方法被 replaced by vision language pre-training（VLP）技术。</li>
<li>results: 本论文 summarizes the recent trends, challenges, and scopes for improvement in VQA, 并且探讨了VLP在VQA领域的挑战，并提出了一些未解决的开放问题。此外，本论文还扩展了VQA的范围，探讨了相关的多模态问答任务和未来的研究方向。<details>
<summary>Abstract</summary>
The multimodal task of Visual Question Answering (VQA) encompassing elements of Computer Vision (CV) and Natural Language Processing (NLP), aims to generate answers to questions on any visual input. Over time, the scope of VQA has expanded from datasets focusing on an extensive collection of natural images to datasets featuring synthetic images, video, 3D environments, and various other visual inputs. The emergence of large pre-trained networks has shifted the early VQA approaches relying on feature extraction and fusion schemes to vision language pre-training (VLP) techniques. However, there is a lack of comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods. Furthermore, the VLP challenges in the lens of VQA haven't been thoroughly explored, leaving room for potential open problems to emerge. Our work presents a survey in the domain of VQA that delves into the intricacies of VQA datasets and methods over the field's history, introduces a detailed taxonomy to categorize the facets of VQA, and highlights the recent trends, challenges, and scopes for improvement. We further generalize VQA to multimodal question answering, explore tasks related to VQA, and present a set of open problems for future investigation. The work aims to navigate both beginners and experts by shedding light on the potential avenues of research and expanding the boundaries of the field.
</details>
<details>
<summary>摘要</summary>
Multimodal任务视觉问答（VQA）包括计算机视觉（CV）和自然语言处理（NLP）的多个方面，旨在对任何视觉输入生成问题的答案。随着时间的推移，VQA的范围从原始的庞大自然图像集扩展到了 sintetic图像、视频、3D环境和其他多种视觉输入。随着大型预训练网络的出现，早期VQA方法依靠特征提取和融合方案已经转向了视语言预训练（VLP）技术。然而，现在还没有一份全面的报告，涵盖传统VQA架构和当代VLP基于方法。此外，VLP在VQA镜头下的挑战还没有得到全面的探讨，留下了一些未解决的问题。我们的工作提出了VQA领域的一份报告，探讨VQA数据集和方法的历史、介绍VQA的细化分类、描述当前趋势、挑战和改进的可能性。我们还将VQA扩展到多模态问答任务，探讨与VQA相关的任务，并提出一些未解决的问题，以便帮助新手和专家更好地理解这个领域，拓宽领域的边缘。
</details></li>
</ul>
<hr>
<h2 id="Inference-of-CO2-flow-patterns-–-a-feasibility-study"><a href="#Inference-of-CO2-flow-patterns-–-a-feasibility-study" class="headerlink" title="Inference of CO2 flow patterns – a feasibility study"></a>Inference of CO2 flow patterns – a feasibility study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00290">http://arxiv.org/abs/2311.00290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhinav Prakash Gahlot, Huseyin Tuna Erdinc, Rafael Orozco, Ziyi Yin, Felix J. Herrmann</li>
<li>for: 本研究旨在开发一种能够准确探测地下碳捕集器（CCS）技术下的CO2泄漏，特别是通过存储储量中的渠道束缚的自然或人工扰动的 faults。</li>
<li>methods: 本研究使用 conditional normalizing flow 技术来描述 CO2 泄漏的流行行为，并通过 numerical experiments 来分析其性能。</li>
<li>results: 研究结果表明，使用 conditional normalizing flow 技术可以生成高精度的 CO2 泄漏流行行为的推断，并且uncertainty 的推断也是合理的，主要来自于地震数据的噪声和存储储量中流体流行性特性的不确定性。<details>
<summary>Abstract</summary>
As the global deployment of carbon capture and sequestration (CCS) technology intensifies in the fight against climate change, it becomes increasingly imperative to establish robust monitoring and detection mechanisms for potential underground CO2 leakage, particularly through pre-existing or induced faults in the storage reservoir's seals. While techniques such as history matching and time-lapse seismic monitoring of CO2 storage have been used successfully in tracking the evolution of CO2 plumes in the subsurface, these methods lack principled approaches to characterize uncertainties related to the CO2 plumes' behavior. Inclusion of systematic assessment of uncertainties is essential for risk mitigation for the following reasons: (i) CO2 plume-induced changes are small and seismic data is noisy; (ii) changes between regular and irregular (e.g., caused by leakage) flow patterns are small; and (iii) the reservoir properties that control the flow are strongly heterogeneous and typically only available as distributions. To arrive at a formulation capable of inferring flow patterns for regular and irregular flow from well and seismic data, the performance of conditional normalizing flow will be analyzed on a series of carefully designed numerical experiments. While the inferences presented are preliminary in the context of an early CO2 leakage detection system, the results do indicate that inferences with conditional normalizing flows can produce high-fidelity estimates for CO2 plumes with or without leakage. We are also confident that the inferred uncertainty is reasonable because it correlates well with the observed errors. This uncertainty stems from noise in the seismic data and from the lack of precise knowledge of the reservoir's fluid flow properties.
</details>
<details>
<summary>摘要</summary>
在全球范围内部署碳捕集技术的战 against 气候变化中，建立强大的监测和检测机制 для potential underground CO2 泄露已变得越来越重要。特别是通过存在或人为引入的 faults in the storage reservoir's seals 中的泄露。虽然历史匹配和时间lapse seismic monitoring of CO2 storage 已经成功地跟踪了在地下的 CO2 气泡的进化，但这些方法缺乏定则的方法来评估相关的不确定性。包括系统性的评估不确定性是必要的，以便风险控制，因为：（i） CO2 气泡引起的变化很小，seismic data 是噪音的；（ii）常规和不常规（例如，由泄露引起的）流pattern 之间的变化很小；和（iii）存储器的 свойства，控制流的流速和方向，是强 heterogeneous 的，通常只有分布式存储。为了到达一种可以从 well 和 seismic data 中推断常规和不常规流的形式，我们将分析 conditional normalizing flow 的性能在一系列仔细设计的数值实验中。虽然这些推断是在 CO2 泄露检测系统中的预liminary CONTEXT中提出的，但结果表明，使用 conditional normalizing flows 可以生成高精度的 CO2 气泡推断，无论是否存在泄露。我们还 confidence 的是，推断的不确定性是合理的，因为它与观测数据中的噪音和存储器的流体流速和方向的缺乏精确知识相关。这种不确定性来自 seismic data 中的噪音和存储器的流体流速和方向的缺乏精确知识。
</details></li>
</ul>
<hr>
<h2 id="Active-Instruction-Tuning-Improving-Cross-Task-Generalization-by-Training-on-Prompt-Sensitive-Tasks"><a href="#Active-Instruction-Tuning-Improving-Cross-Task-Generalization-by-Training-on-Prompt-Sensitive-Tasks" class="headerlink" title="Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks"></a>Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00288">http://arxiv.org/abs/2311.00288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pluslabnlp/active-it">https://github.com/pluslabnlp/active-it</a></li>
<li>paper_authors: Po-Nien Kung, Fan Yin, Di Wu, Kai-Wei Chang, Nanyun Peng</li>
<li>for: 这篇论文的目的是提出一个新的活动指令调整方法，以便对于实际应用中的大型自然语言模型（LLM）进行最佳化。</li>
<li>methods: 这篇论文使用了一个新的框架，即基于提示不确定性的活动指令调整方法，来选择新的任务，并对选择的任务进行调整。这个方法基于提示出现在的模型输出不确定性，以评估新任务的有用性。</li>
<li>results: 实验结果显示，这个方法可以与其他基于随机选择的方法相比，在NIV2和Self-Instruct datasets上实现更好的离散应用扩展性，并且可以透过给定的任务地图来评估和诊断任务的有用性。<details>
<summary>Abstract</summary>
Instruction tuning (IT) achieves impressive zero-shot generalization results by training large language models (LLMs) on a massive amount of diverse tasks with instructions. However, how to select new tasks to improve the performance and generalizability of IT models remains an open question. Training on all existing tasks is impractical due to prohibiting computation requirements, and randomly selecting tasks can lead to suboptimal performance. In this work, we propose active instruction tuning based on prompt uncertainty, a novel framework to identify informative tasks, and then actively tune the models on the selected tasks. We represent the informativeness of new tasks with the disagreement of the current model outputs over perturbed prompts. Our experiments on NIV2 and Self-Instruct datasets demonstrate that our method consistently outperforms other baseline strategies for task selection, achieving better out-of-distribution generalization with fewer training tasks. Additionally, we introduce a task map that categorizes and diagnoses tasks based on prompt uncertainty and prediction probability. We discover that training on ambiguous (prompt-uncertain) tasks improves generalization while training on difficult (prompt-certain and low-probability) tasks offers no benefit, underscoring the importance of task selection for instruction tuning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Knowledge-Infused-Prompting-Assessing-and-Advancing-Clinical-Text-Data-Generation-with-Large-Language-Models"><a href="#Knowledge-Infused-Prompting-Assessing-and-Advancing-Clinical-Text-Data-Generation-with-Large-Language-Models" class="headerlink" title="Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models"></a>Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00287">http://arxiv.org/abs/2311.00287</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ritaranx/clingen">https://github.com/ritaranx/clingen</a></li>
<li>paper_authors: Ran Xu, Hejie Cui, Yue Yu, Xuan Kan, Wenqi Shi, Yuchen Zhuang, Wei Jin, Joyce Ho, Carl Yang</li>
<li>for: 这个论文是为了提高临床自然语言处理领域中的方法，以便更好地处理复杂的医疗术语和临床背景。</li>
<li>methods: 该论文使用了大型自然语言模型（LLM）来解决这些问题，并提出了一种新的、资源有效的方法，即ClinGen，它将知识注入到过程中。</li>
<li>results: 该论文的实验表明，ClinGen可以在7种临床自然语言处理任务和16个数据集上提高性能，并且能够有效地增加数据生成的多样性和准确性。<details>
<summary>Abstract</summary>
Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the diversity of generated training instances. We will publish our code and all the generated data in \url{https://github.com/ritaranx/ClinGen}.
</details>
<details>
<summary>摘要</summary>
临床自然语言处理需要针对医疗域特有的挑战，如医疗术语和临床背景。最近，大型自然语言模型（LLM）在这个领域表现了承诺。然而，直接部署LLM可能会导致隐私问题并受到资源限制。为解决这个挑战，我们探索了人工生成的临床文本，使用LLM进行临床NLP任务。我们提出了一种创新的、资源有效的方法，名为ClinGen，它将知识整合到过程中。我们的模型包括临床知识提取和上下文 Informed LLM 提示。两者均从外部域specific知识图和LLM中提取临床主题和写作风格，以引导数据生成。我们的广泛的实验研究 across 7 临床 NLP 任务和 16 个数据集显示，ClinGen 在不同任务上一致地提高性能，并准确地调整实际数据的分布，并且有效地增加生成的训练示例多样性。我们将将代码和所有生成的数据发布在 \url{https://github.com/ritaranx/ClinGen}.
</details></li>
</ul>
<hr>
<h2 id="JADE-A-Linguistics-based-Safety-Evaluation-Platform-for-LLM"><a href="#JADE-A-Linguistics-based-Safety-Evaluation-Platform-for-LLM" class="headerlink" title="JADE: A Linguistics-based Safety Evaluation Platform for LLM"></a>JADE: A Linguistics-based Safety Evaluation Platform for LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00286">http://arxiv.org/abs/2311.00286</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whitzard-ai/jade-db">https://github.com/whitzard-ai/jade-db</a></li>
<li>paper_authors: Mi Zhang, Xudong Pan, Min Yang</li>
<li>for: 这个论文的目的是提出一种名为JADE的目标语言杂化平台，用于同时破坏多种广泛使用的中文和英文语言模型（LLMs）。</li>
<li>methods: JADE使用诺曼·钱博士的变换生成语法理论，将seed问题的语言复杂度逐步增加，直到破坏LLMs的安全防护。</li>
<li>results: JADE可以同时破坏多种中文和英文LLMs，并且生成了一些不安全的问题，其中大多数问题都能够让LLMs生成不良的回答。在 average unsafe generation ratio 为 70% 的情况下，这些问题仍然是自然、流畅的。<details>
<summary>Abstract</summary>
In this paper, we present JADE, a targeted linguistic fuzzing platform which strengthens the linguistic complexity of seed questions to simultaneously and consistently break a wide range of widely-used LLMs categorized in three groups: eight open-sourced Chinese, six commercial Chinese and four commercial English LLMs. JADE generates three safety benchmarks for the three groups of LLMs, which contain unsafe questions that are highly threatening: the questions simultaneously trigger harmful generation of multiple LLMs, with an average unsafe generation ratio of $70\%$ (please see the table below), while are still natural questions, fluent and preserving the core unsafe semantics. We release the benchmark demos generated for commercial English LLMs and open-sourced English LLMs in the following link: https://github.com/whitzard-ai/jade-db. For readers who are interested in evaluating on more questions generated by JADE, please contact us.   JADE is based on Noam Chomsky's seminal theory of transformational-generative grammar. Given a seed question with unsafe intention, JADE invokes a sequence of generative and transformational rules to increment the complexity of the syntactic structure of the original question, until the safety guardrail is broken. Our key insight is: Due to the complexity of human language, most of the current best LLMs can hardly recognize the invariant evil from the infinite number of different syntactic structures which form an unbound example space that can never be fully covered. Technically, the generative/transformative rules are constructed by native speakers of the languages, and, once developed, can be used to automatically grow and transform the parse tree of a given question, until the guardrail is broken. For more evaluation results and demo, please check our website: https://whitzard-ai.github.io/jade.html.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了JADE，一种针对性语言扩散平台，强化了种子问题的语言复杂度，同时并不断破坏了多种广泛使用的中文和英文语言模型。JADE生成了三个安全指标 для这三个类型的语言模型，包括 unsafe 问题，这些问题同时触发了多种语言模型的危险生成，平均危险生成率为70%（请参考下面的表），但是仍然是自然的问题，流畅而且保留了核心危险 semantics。我们在以下链接上发布了商业英文语言模型和开源英文语言模型的示例数据：https://github.com/whitzard-ai/jade-db。如果您有兴趣evaluate更多由JADE生成的问题，请与我们联系。JADE基于诺姆·钱百列的transformational-generative grammar理论。给定一个带有危险意图的种子问题，JADE采用一系列生成和transformational规则，逐步增加问题的语法结构复杂度，直到破坏安全 guardrail。我们的关键发现是：由于人类语言的复杂性，现有的最佳语言模型很难正确识别不同语法结构中的恶势力。技术上，生成/transformative规则由本地语言专家构建，并一旦开发，可以自动增长和转换问题的parse树，直到 guardrail 被破坏。更多评估结果和示例，请查看我们的网站：https://whitzard-ai.github.io/jade.html。
</details></li>
</ul>
<hr>
<h2 id="Re-Scoring-Using-Image-Language-Similarity-for-Few-Shot-Object-Detection"><a href="#Re-Scoring-Using-Image-Language-Similarity-for-Few-Shot-Object-Detection" class="headerlink" title="Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection"></a>Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00278">http://arxiv.org/abs/2311.00278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Jae Jung, Seung Dae Han, Joohee Kim</li>
<li>for: 本研究旨在提高几个标注数据的 объек检测性能，特别是检测新的对象。</li>
<li>methods: 本研究使用了 Contrastive Language-Image Pre-training (CLIP) 和 hard negative classification loss 来改进对象检测性能。</li>
<li>results: 经验表明，提出的 RISF 方法在 MS-COCO 和 PASCAL VOC 上具有显著的性能提升，substantially 超越了现有的方法。<details>
<summary>Abstract</summary>
Few-shot object detection, which focuses on detecting novel objects with few labels, is an emerging challenge in the community. Recent studies show that adapting a pre-trained model or modified loss function can improve performance. In this paper, we explore leveraging the power of Contrastive Language-Image Pre-training (CLIP) and hard negative classification loss in low data setting. Specifically, we propose Re-scoring using Image-language Similarity for Few-shot object detection (RISF) which extends Faster R-CNN by introducing Calibration Module using CLIP (CM-CLIP) and Background Negative Re-scale Loss (BNRL). The former adapts CLIP, which performs zero-shot classification, to re-score the classification scores of a detector using image-class similarities, the latter is modified classification loss considering the punishment for fake backgrounds as well as confusing categories on a generalized few-shot object detection dataset. Extensive experiments on MS-COCO and PASCAL VOC show that the proposed RISF substantially outperforms the state-of-the-art approaches. The code will be available.
</details>
<details>
<summary>摘要</summary>
“几何 shot 物体检测，强调检测新物体几个标签，是当前社区的一个崛起挑战。 latest studies show that modifying a pre-trained model or loss function can improve performance. In this paper, we explore using the power of Contrastive Language-Image Pre-training (CLIP) and hard negative classification loss in low data setting. Specifically, we propose Re-scoring using Image-language Similarity for Few-shot object detection (RISF) which extends Faster R-CNN by introducing Calibration Module using CLIP (CM-CLIP) and Background Negative Re-scale Loss (BNRL). The former adapts CLIP, which performs zero-shot classification, to re-score the classification scores of a detector using image-class similarities, the latter is modified classification loss considering the punishment for fake backgrounds as well as confusing categories on a generalized few-shot object detection dataset. Extensive experiments on MS-COCO and PASCAL VOC show that the proposed RISF substantially outperforms the state-of-the-art approaches. The code will be available.”Here's the breakdown of the translation:* 几何 shot (few-shot) 物体检测 (object detection)* 强调 (emphasize) 新物体 (novel objects) 几个标签 (few labels)* latest studies (最近的研究) show (显示) that (that) modifying (修改) a pre-trained model (预训练模型) or loss function (损失函数) can improve (提高) performance.* In this paper (在这篇论文中), we explore (探索) using the power (使用) of Contrastive Language-Image Pre-training (CLIP) and hard negative classification loss (困难的负类别损失) in low data setting (低数据设定).* Specifically (特别), we propose (提议) Re-scoring using Image-language Similarity for Few-shot object detection (RISF) which extends (扩展) Faster R-CNN by introducing (引入) Calibration Module using CLIP (CM-CLIP) and Background Negative Re-scale Loss (BNRL).* The former (前者) adapts (适应) CLIP, which performs zero-shot classification (执行零批分类), to re-score (重新分类) the classification scores (分类分数) of a detector (检测器) using image-class similarities (图像类相似性).* The latter (后者) is modified (修改) classification loss (类别损失) considering (考虑) the punishment (惩罚) for fake backgrounds (假背景) as well as confusing categories (混淆类别) on a generalized few-shot object detection dataset (一般化的几何 shot 物体检测集).* Extensive experiments (广泛的实验) on MS-COCO and PASCAL VOC show (显示) that the proposed RISF substantially outperforms (显著超越) the state-of-the-art approaches (当前的方法).* The code will be available (代码将可用).
</details></li>
</ul>
<hr>
<h2 id="ChatCoder-Chat-based-Refine-Requirement-Improves-LLMs’-Code-Generation"><a href="#ChatCoder-Chat-based-Refine-Requirement-Improves-LLMs’-Code-Generation" class="headerlink" title="ChatCoder: Chat-based Refine Requirement Improves LLMs’ Code Generation"></a>ChatCoder: Chat-based Refine Requirement Improves LLMs’ Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00272">http://arxiv.org/abs/2311.00272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zejun Wang, Jia Li, Ge Li, Zhi Jin</li>
<li>for: 提高大型自然语言处理模型对人类需求的理解和代码生成性能</li>
<li>methods: 通过人类与大型自然语言处理模型的对话方式，引导人类用户修改需求表达，使其更加精确、不ambiguous和完整</li>
<li>results: 实验显示，ChatCoder可以大幅提高现有大型自然语言处理模型的代码生成性能，同时比起修改基于需求的方法和人类回应基于模型 fine-tuning 方法更有优势。<details>
<summary>Abstract</summary>
Large language models have shown good performances in generating code to meet human requirements. However, human requirements expressed in natural languages can be vague, incomplete, and ambiguous, leading large language models to misunderstand human requirements and make mistakes. Worse, it is difficult for a human user to refine the requirement. To help human users refine their requirements and improve large language models' code generation performances, we propose ChatCoder: a method to refine the requirements via chatting with large language models. We design a chat scheme in which the large language models will guide the human users to refine their expression of requirements to be more precise, unambiguous, and complete than before. Experiments show that ChatCoder has improved existing large language models' performance by a large margin. Besides, ChatCoder has the advantage over refine-based methods and LLMs fine-tuned via human response.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型已经表现出优秀的代码生成能力，但是人类需求表现往往是模糊、不完整和欠精确，导致大型自然语言模型 misunderstand 人类需求并发生错误。更糟糕的是，人类用户很难更正需求。为了帮助人类用户更正需求并提高大型自然语言模型的代码生成能力，我们提出了 ChatCoder：一种方法，通过与大型自然语言模型聊天，帮助人类用户更正需求，使其更精确、不模糊和完整。实验结果显示，ChatCoder 可以大幅提高现有大型自然语言模型的表现。此外，ChatCoder 比较于 refine-based 方法和 LLMS 通过人类回应进行 fine-tuning 来更有优势。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Decision-Transformer-via-Hierarchical-Reinforcement-Learning"><a href="#Rethinking-Decision-Transformer-via-Hierarchical-Reinforcement-Learning" class="headerlink" title="Rethinking Decision Transformer via Hierarchical Reinforcement Learning"></a>Rethinking Decision Transformer via Hierarchical Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00267">http://arxiv.org/abs/2311.00267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Ma, Chenjun Xiao, Hebin Liang, Jianye Hao</li>
<li>for: 这篇论文旨在探讨决策变换（DT）算法在决策学习（RL）中的应用。</li>
<li>methods: 该论文提出了一种基于转换架构的普适序列模型框架，用于研究序列决策。在做决策时，高级策略首先提议理想的提示，而低级策略根据给定提示生成动作。研究发现，DT是这个框架的一个特殊情况，并讨论了这些选择的可能的失败。</li>
<li>results: 经验结果显示，提出的算法在多个控制和导航标准准chmark上显著超过DT。<details>
<summary>Abstract</summary>
Decision Transformer (DT) is an innovative algorithm leveraging recent advances of the transformer architecture in reinforcement learning (RL). However, a notable limitation of DT is its reliance on recalling trajectories from datasets, losing the capability to seamlessly stitch sub-optimal trajectories together. In this work we introduce a general sequence modeling framework for studying sequential decision making through the lens of Hierarchical RL. At the time of making decisions, a high-level policy first proposes an ideal prompt for the current state, a low-level policy subsequently generates an action conditioned on the given prompt. We show DT emerges as a special case of this framework with certain choices of high-level and low-level policies, and discuss the potential failure of these choices. Inspired by these observations, we study how to jointly optimize the high-level and low-level policies to enable the stitching ability, which further leads to the development of new offline RL algorithms. Our empirical results clearly show that the proposed algorithms significantly surpass DT on several control and navigation benchmarks. We hope our contributions can inspire the integration of transformer architectures within the field of RL.
</details>
<details>
<summary>摘要</summary>
Note:* "变转器架构" (transformer architecture) is translated as "变换器架构" in Simplified Chinese.* "Sequential Decision Making" (SDM) is translated as "Sequential Decision Making" in Simplified Chinese.* "高级策略" (high-level policy) is translated as "高级策略" in Simplified Chinese.* "低级策略" (low-level policy) is translated as "低级策略" in Simplified Chinese.* "做出决策" (make decisions) is translated as "做出决策" in Simplified Chinese.* "整体" (entirely) is translated as "整体" in Simplified Chinese.* "新的offline RL算法" (new offline RL algorithms) is translated as "新的offline RL算法" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Plug-and-Play-Policy-Planner-for-Large-Language-Model-Powered-Dialogue-Agents"><a href="#Plug-and-Play-Policy-Planner-for-Large-Language-Model-Powered-Dialogue-Agents" class="headerlink" title="Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents"></a>Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00262">http://arxiv.org/abs/2311.00262</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Deng, Wenxuan Zhang, Wai Lam, See-Kiong Ng, Tat-Seng Chua</li>
<li>for: 该论文旨在提高语言模型（LLM）的对话政策规划能力，以便在对话中更加积极地与人类交互。</li>
<li>methods: 该论文提出了一种新的对话政策规划 paradigm，named PPDPP，它使用可调整的语言模型插件作为对话政策规划器，并通过监督微调和目标带动回馈来协助LLM拟合不同应用场景。</li>
<li>results: 实验结果表明，PPDPP在三种不同的积极对话应用中（包括谈判、情感支持和教学对话）具有显著优势，与现有方法相比，可以减少对话时间、提高对话质量和适应性。<details>
<summary>Abstract</summary>
Proactive dialogues serve as a practical yet challenging dialogue problem in the era of large language models (LLMs), where the dialogue policy planning is the key to improving the proactivity of LLMs. Most existing studies enable the dialogue policy planning of LLMs using various prompting schemes or iteratively enhance this capability in handling the given case with verbal AI feedback. However, these approaches are either bounded by the policy planning capability of the frozen LLMs or hard to be transferred to new cases. In this work, we introduce a new dialogue policy planning paradigm to strategize LLMs for proactive dialogue problems with a tunable language model plug-in as a plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play simulation. In this manner, the LLM-powered dialogue agent can not only be generalized to different cases after the training, but also be applicable to different applications by just substituting the learned plug-in. In addition, we propose to evaluate the policy planning capability of dialogue systems under the interactive setting. Experimental results demonstrate that PPDPP consistently and substantially outperforms existing approaches on three different proactive dialogue applications, including negotiation, emotional support, and tutoring dialogues.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLM）的对话政策规划是一个实用又挑战性的对话问题，在这个时代，对话政策规划是改善 LLM 的核心。现有的研究通常使用不同的提示方案或逐步提高这个能力，但这些方法都受到固定 LLM 的政策规划能力的限制，或者对新情况难以转移。在这个工作中，我们介绍了一个新的对话政策规划方法，以便将 LLM 为主动对话问题的战略。 Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play simulation. In this manner, the LLM-powered dialogue agent can not only be generalized to different cases after the training, but also be applicable to different applications by just substituting the learned plug-in. In addition, we propose to evaluate the policy planning capability of dialogue systems under the interactive setting. Experimental results demonstrate that PPDPP consistently and substantially outperforms existing approaches on three different proactive dialogue applications, including negotiation, emotional support, and tutoring dialogues.
</details></li>
</ul>
<hr>
<h2 id="Implicit-biases-in-multitask-and-continual-learning-from-a-backward-error-analysis-perspective"><a href="#Implicit-biases-in-multitask-and-continual-learning-from-a-backward-error-analysis-perspective" class="headerlink" title="Implicit biases in multitask and continual learning from a backward error analysis perspective"></a>Implicit biases in multitask and continual learning from a backward error analysis perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00235">http://arxiv.org/abs/2311.00235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benoit Dherin</li>
<li>for: 这篇论文是关于使用回溯错误分析计算神经网络在多任务和继续学习 Setting 中的隐式训练偏好的研究。</li>
<li>methods: 这篇论文使用了 Stochastic Gradient Descent 训练神经网络，并 derive 了一些修改后的损失函数，其中包括原始损失函数、 converge 损失函数、隐式平滑化正则化项以及 conflict 项。</li>
<li>results: 研究发现，在多任务 Setting 中，conflict 项是一个已知的量，度量任务梯度的吸引力，而在继续学习 Setting 中，conflict 项是一个新的深度学习优化中的量，它是 differential geometry 中的 Lie 括号 between 任务梯度。<details>
<summary>Abstract</summary>
Using backward error analysis, we compute implicit training biases in multitask and continual learning settings for neural networks trained with stochastic gradient descent. In particular, we derive modified losses that are implicitly minimized during training. They have three terms: the original loss, accounting for convergence, an implicit flatness regularization term proportional to the learning rate, and a last term, the conflict term, which can theoretically be detrimental to both convergence and implicit regularization. In multitask, the conflict term is a well-known quantity, measuring the gradient alignment between the tasks, while in continual learning the conflict term is a new quantity in deep learning optimization, although a basic tool in differential geometry: The Lie bracket between the task gradients.
</details>
<details>
<summary>摘要</summary>
(使用倒数反析，我们计算了多任务和持续学习设置下神经网络在权重梯度下降法中的隐式训练偏见。特别是，我们 derivated modified losses，在训练中隐式地减少。它们包括三个项：原始损失，考虑到收敛，隐式平滑化规化项，卷积率相对，以及最后一个项，冲突项，可以 theoretically detrimental to both convergence and implicit regularization。在多任务中，冲突项是一个已知量，测量任务的梯度对齐，而在持续学习中，冲突项是一个新的深度学习优化工具，尽管是Diffgeometry中的一个基本工具：任务梯度的Lie括茧。)
</details></li>
</ul>
<hr>
<h2 id="StableFDG-Style-and-Attention-Based-Learning-for-Federated-Domain-Generalization"><a href="#StableFDG-Style-and-Attention-Based-Learning-for-Federated-Domain-Generalization" class="headerlink" title="StableFDG: Style and Attention Based Learning for Federated Domain Generalization"></a>StableFDG: Style and Attention Based Learning for Federated Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00227">http://arxiv.org/abs/2311.00227</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jungwuk Park, Dong-Jun Han, Jinho Kim, Shiqiang Wang, Christopher G. Brinton, Jaekyun Moon</li>
<li>for: 本文提出了一种针对 Federated Learning （FL） 环境中的领域泛化（Domain Generalization，DG）问题的解决方案，以提高FL中的鲁棒性和通用性。</li>
<li>methods: 本文提出了两个重要贡献：首先是基于样式的学习策略，允许每个客户端在本地数据集中探索新的样式，提高领域多样性 based on 提出的样式分享、转移和探索策略。 其次是基于注意力的特征强调器，可以捕捉不同类别数据amples 之间的相似性，强调重要&#x2F;共同特征，以更好地学习FL中的领域无关特征。</li>
<li>results: 实验结果表明，StableFDG 比现有的基elines 在多个 DG 标准 benchmark 数据集上表现出色， demonstrating its effectiveness.<details>
<summary>Abstract</summary>
Traditional federated learning (FL) algorithms operate under the assumption that the data distributions at training (source domains) and testing (target domain) are the same. The fact that domain shifts often occur in practice necessitates equipping FL methods with a domain generalization (DG) capability. However, existing DG algorithms face fundamental challenges in FL setups due to the lack of samples/domains in each client's local dataset. In this paper, we propose StableFDG, a style and attention based learning strategy for accomplishing federated domain generalization, introducing two key contributions. The first is style-based learning, which enables each client to explore novel styles beyond the original source domains in its local dataset, improving domain diversity based on the proposed style sharing, shifting, and exploration strategies. Our second contribution is an attention-based feature highlighter, which captures the similarities between the features of data samples in the same class, and emphasizes the important/common characteristics to better learn the domain-invariant characteristics of each class in data-poor FL scenarios. Experimental results show that StableFDG outperforms existing baselines on various DG benchmark datasets, demonstrating its efficacy.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Traditional federated learning (FL) algorithms operate under the assumption that the data distributions at training (source domains) and testing (target domain) are the same. The fact that domain shifts often occur in practice necessitates equipping FL methods with a domain generalization (DG) capability. However, existing DG algorithms face fundamental challenges in FL setups due to the lack of samples/domains in each client's local dataset. In this paper, we propose StableFDG, a style and attention based learning strategy for accomplishing federated domain generalization, introducing two key contributions. The first is style-based learning, which enables each client to explore novel styles beyond the original source domains in its local dataset, improving domain diversity based on the proposed style sharing, shifting, and exploration strategies. Our second contribution is an attention-based feature highlighter, which captures the similarities between the features of data samples in the same class, and emphasizes the important/common characteristics to better learn the domain-invariant characteristics of each class in data-poor FL scenarios. Experimental results show that StableFDG outperforms existing baselines on various DG benchmark datasets, demonstrating its efficacy."中文翻译：传统的联合学习（FL）算法假设训练（源领域）和测试（目标领域）数据分布相同。然而，在实践中，频繁出现域shift问题，因此需要为FL方法增加域泛化（DG）能力。然而，现有的DG算法在FL设置中面临fundamental挑战，因为每个客户端的本地数据集中缺乏样本/域。在这篇论文中，我们提出了稳定FDG，一种风格和注意力基于学习策略，用于实现联合域泛化。我们的两大贡献是：首先，风格学习，允许每个客户端在本地数据集中探索新的风格，提高域多样性基于我们提出的风格分享、转换和探索策略。其次，我们提出了注意力基本特征强调器，可以捕捉数据示例在同一类型中的相似性，强调重要/共同特征，以更好地学习每个类型的域无关特征。实验结果表明，稳定FDG在多个DGbenchmark数据集上表现出色，证明其效果。
</details></li>
</ul>
<hr>
<h2 id="Domain-decomposition-based-coupling-of-physics-informed-neural-networks-via-the-Schwarz-alternating-method"><a href="#Domain-decomposition-based-coupling-of-physics-informed-neural-networks-via-the-Schwarz-alternating-method" class="headerlink" title="Domain decomposition-based coupling of physics-informed neural networks via the Schwarz alternating method"></a>Domain decomposition-based coupling of physics-informed neural networks via the Schwarz alternating method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00224">http://arxiv.org/abs/2311.00224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Will Snyder, Irina Tezaur, Christopher Wentland</li>
<li>for: 解决非线性偏微分方程（PDE）的数据驱动工具。</li>
<li>methods: 使用Schwarz alternating方法将PINN coupling到彼此和传统数值模型（FOM）。</li>
<li>results: 对一个一维稳态扩散-扩散方程进行数值研究，发现 coupling PINN via Schwarz alternating method可以提高PINN训练速度，但不一定加速PINN convergence。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) are appealing data-driven tools for solving and inferring solutions to nonlinear partial differential equations (PDEs). Unlike traditional neural networks (NNs), which train only on solution data, a PINN incorporates a PDE's residual into its loss function and trains to minimize the said residual at a set of collocation points in the solution domain. This paper explores the use of the Schwarz alternating method as a means to couple PINNs with each other and with conventional numerical models (i.e., full order models, or FOMs, obtained via the finite element, finite difference or finite volume methods) following a decomposition of the physical domain. It is well-known that training a PINN can be difficult when the PDE solution has steep gradients. We investigate herein the use of domain decomposition and the Schwarz alternating method as a means to accelerate the PINN training phase. Within this context, we explore different approaches for imposing Dirichlet boundary conditions within each subdomain PINN: weakly through the loss and/or strongly through a solution transformation. As a numerical example, we consider the one-dimensional steady state advection-diffusion equation in the advection-dominated (high Peclet) regime. Our results suggest that the convergence of the Schwarz method is strongly linked to the choice of boundary condition implementation within the PINNs being coupled. Surprisingly, strong enforcement of the Schwarz boundary conditions does not always lead to a faster convergence of the method. While it is not clear from our preliminary study that the PINN-PINN coupling via the Schwarz alternating method accelerates PINN convergence in the advection-dominated regime, it reveals that PINN training can be improved substantially for Peclet numbers as high as 1e6 by performing a PINN-FOM coupling.
</details>
<details>
<summary>摘要</summary>
物理学 Informed Neural Networks (PINNs) 是一种吸引人的数据驱动工具，用于解决和推导非线性偏微分方程 (PDEs) 的解。与传统的神经网络 (NNs) 不同，PINNs 在训练过程中不仅学习解数据，还包含 PDE 的剩余在损失函数中，并在协调点上培训以降低这些剩余。本文研究了使用 Schwarz 交互方法将 PINNs 集成到传统的数值模型 (FOMs) 中，以实现域 decomposure 的目的。在训练 PINNs 时，如果解的梯度较大，可能会增加训练难度。我们在这里研究了使用域 decomposure 和 Schwarz 交互方法来加速 PINNs 训练阶段。在这个上下文中，我们还研究了不同的 Dirichlet 边界条件的实现方式，包括通过损失函数和/或强制实施解转换。我们的数字示例是一个一维不变 steady state 扩散-扩散 Equation 在扩散 доминиated (高 Peclet)  режиме。我们的结果表明，Schwarz 方法的收敛与 PINNs 之间的边界条件实现方式有着强有力的关系。尽管使用强制实施边界条件可能会加速方法的收敛，但并不总是如此。我们的初步研究表明，在 Peclet 数为 1e6 的情况下，通过 PINNs-FOM 集成可以大幅提高 PINNs 的训练效率。
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Capture-Public-Opinion-about-Global-Warming-An-Empirical-Assessment-of-Algorithmic-Fidelity-and-Bias"><a href="#Can-Large-Language-Models-Capture-Public-Opinion-about-Global-Warming-An-Empirical-Assessment-of-Algorithmic-Fidelity-and-Bias" class="headerlink" title="Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias"></a>Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00217">http://arxiv.org/abs/2311.00217</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. Lee, T. Q. Peng, M. H. Goldberg, S. A. Rosenthal, J. E. Kotcher, E. W. Maibach, A. Leiserowitz</li>
<li>for: This study assesses the algorithmic fidelity and bias of large language models (LLMs) in simulating survey responses, specifically in relation to climate change perspectives.</li>
<li>methods: The study uses two nationally representative climate change surveys and conditions LLMs on demographics and&#x2F;or psychological covariates to simulate survey responses. GPT-4 is used as one of the LLMs and is found to perform better when conditioned on both demographics and covariates.</li>
<li>results: The study finds that LLMs can effectively capture presidential voting behaviors, but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included. The study also identifies disparities in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans.<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated their potential in social science research by emulating human perceptions and behaviors, a concept referred to as algorithmic fidelity. This study assesses the algorithmic fidelity and bias of LLMs by utilizing two nationally representative climate change surveys. The LLMs were conditioned on demographics and/or psychological covariates to simulate survey responses. The findings indicate that LLMs can effectively capture presidential voting behaviors but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included. GPT-4 exhibits improved performance when conditioned on both demographics and covariates. However, disparities emerge in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans. While highlighting the potential of LLMs to aid social science research, these results underscore the importance of meticulous conditioning, model selection, survey question format, and bias assessment when employing LLMs for survey simulation. Further investigation into prompt engineering and algorithm auditing is essential to harness the power of LLMs while addressing their inherent limitations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Consistent-Video-to-Video-Transfer-Using-Synthetic-Dataset"><a href="#Consistent-Video-to-Video-Transfer-Using-Synthetic-Dataset" class="headerlink" title="Consistent Video-to-Video Transfer Using Synthetic Dataset"></a>Consistent Video-to-Video Transfer Using Synthetic Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00213">http://arxiv.org/abs/2311.00213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxin Cheng, Tianjun Xiao, Tong He</li>
<li>for: 文章旨在提出一种新的和高效的文本基于视频编辑方法，减少每个视频需要进行资源占用的模型特定finetuning。</li>
<li>methods: 我们的方法的核心是一个synthetic paired视频数据集，用于视频转换任务。我们 Drawing inspiration from Instruct Pix2Pix的图像转换via编辑指令，我们将这种 парадиг应用到视频领域。我们还引入了Long Video Sampling Correction，确保批处理中的长视频保持一致。</li>
<li>results: 我们的方法超越了现有的方法如Tune-A-Video，表明了文本基于视频编辑的重要进步，并开示了进一步探索和应用的潜在可能性。<details>
<summary>Abstract</summary>
We introduce a novel and efficient approach for text-based video-to-video editing that eliminates the need for resource-intensive per-video-per-model finetuning. At the core of our approach is a synthetic paired video dataset tailored for video-to-video transfer tasks. Inspired by Instruct Pix2Pix's image transfer via editing instruction, we adapt this paradigm to the video domain. Extending the Prompt-to-Prompt to videos, we efficiently generate paired samples, each with an input video and its edited counterpart. Alongside this, we introduce the Long Video Sampling Correction during sampling, ensuring consistent long videos across batches. Our method surpasses current methods like Tune-A-Video, heralding substantial progress in text-based video-to-video editing and suggesting exciting avenues for further exploration and deployment.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的和高效的文本基于视频到视频编辑方法，消除了每个视频需要进行资源占用的精细化训练的需求。我们的方法的核心是一个人工合成的视频对应 dataset，专门用于视频转换任务。 Drawing inspiration from Instruct Pix2Pix的图像转换via编辑指令，我们将这种 парадиг adapted to the video domain。通过扩展Prompt-to-Prompt来视频，我们高效地生成了对应的样本，每个样本包括一个输入视频和其修改后的对应视频。此外，我们还引入了长视频抽样 corrections，以确保批处中的视频都是一致的长度。我们的方法超越了现有的方法 like Tune-A-Video， representing a significant progress in text-based video-to-video editing and opening up exciting avenues for further exploration and deployment.
</details></li>
</ul>
<hr>
<h2 id="Magmaw-Modality-Agnostic-Adversarial-Attacks-on-Machine-Learning-Based-Wireless-Communication-Systems"><a href="#Magmaw-Modality-Agnostic-Adversarial-Attacks-on-Machine-Learning-Based-Wireless-Communication-Systems" class="headerlink" title="Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems"></a>Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00207">http://arxiv.org/abs/2311.00207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jung-Woo Chang, Ke Sun, Nasimeh Heydaribeni, Seira Hidano, Xinyu Zhang, Farinaz Koushanfar</li>
<li>For: This paper proposes a black-box attack methodology called Magmaw that can generate universal adversarial perturbations for any multimodal signal transmitted over a wireless channel, targeting ML-based wireless systems.* Methods: Magmaw uses a combination of optimization techniques and machine learning algorithms to generate perturbations that are resilient to existing defense methods such as adversarial training and perturbation signal subtraction.* Results: The paper demonstrates the effectiveness of Magmaw through experimental results on a real-time wireless attack platform using a software-defined radio system, showing significant performance degradation even in the presence of defense mechanisms. Additionally, Magmaw is found to be effective against encrypted communication channels and conventional communications.Here’s the simplified Chinese text for the three key points:* For: 这篇论文提出了一种黑盒攻击方法，名为Magmaw，可以生成任何多模态信号通过无线通信频率的 universal  adversarial 扰动。* Methods: Magmaw 使用了优化技术和机器学习算法来生成对防御机制不效的扰动。* Results: 论文通过实验示范了Magmaw 的效果，使用了一个基于软件定义 радио系统的实时无线攻击平台，并证明了Magmaw 在防御机制存在时仍然能够导致显著的性能下降。<details>
<summary>Abstract</summary>
Machine Learning (ML) has been instrumental in enabling joint transceiver optimization by merging all physical layer blocks of the end-to-end wireless communication systems. Although there have been a number of adversarial attacks on ML-based wireless systems, the existing methods do not provide a comprehensive view including multi-modality of the source data, common physical layer components, and wireless domain constraints. This paper proposes Magmaw, the first black-box attack methodology capable of generating universal adversarial perturbations for any multimodal signal transmitted over a wireless channel. We further introduce new objectives for adversarial attacks on ML-based downstream applications. The resilience of the attack to the existing widely used defense methods of adversarial training and perturbation signal subtraction is experimentally verified. For proof-of-concept evaluation, we build a real-time wireless attack platform using a software-defined radio system. Experimental results demonstrate that Magmaw causes significant performance degradation even in the presence of the defense mechanisms. Surprisingly, Magmaw is also effective against encrypted communication channels and conventional communications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification"><a href="#ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification" class="headerlink" title="ChatGPT-Powered Hierarchical Comparisons for Image Classification"></a>ChatGPT-Powered Hierarchical Comparisons for Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00206">http://arxiv.org/abs/2311.00206</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhiyuan-r/chatgpt-powered-hierarchical-comparisons-for-image-classification">https://github.com/zhiyuan-r/chatgpt-powered-hierarchical-comparisons-for-image-classification</a></li>
<li>paper_authors: Zhiyuan Ren, Yiyang Su, Xiaoming Liu</li>
<li>for: 提出了一种新的图像分类框架，用于解决零例开放词汇图像分类 Task。</li>
<li>methods: 使用 CLIP 预训练视觉语言模型，并利用大型语言模型（LLMs）如 ChatGPT 提供类别特有的知识。</li>
<li>results: 提出了一种基于层次比较的图像分类方法，可以带来有意义、有效和可解释的结果。<details>
<summary>Abstract</summary>
The zero-shot open-vocabulary challenge in image classification is tackled by pretrained vision-language models like CLIP, which benefit from incorporating class-specific knowledge from large language models (LLMs) like ChatGPT. However, biases in CLIP lead to similar descriptions for distinct but related classes, prompting our novel image classification framework via hierarchical comparisons: using LLMs to recursively group classes into hierarchies and classifying images by comparing image-text embeddings at each hierarchy level, resulting in an intuitive, effective, and explainable approach.
</details>
<details>
<summary>摘要</summary>
CLIP和类型特定语言模型（LLM）如ChatGPT的视觉语言模型可以解决零架open-vocabulary挑战，但CLIP中的偏见导致类似的描述 для不同 yet related的类别，因此我们提出了一种新的图像分类框架：通过使用LLM来 recursively分类类别，并将图像与文本嵌入对比在每个层级上，从而实现直观、有效和可解释的方法。
</details></li>
</ul>
<hr>
<h2 id="Continuous-Training-and-Fine-tuning-for-Domain-Specific-Language-Models-in-Medical-Question-Answering"><a href="#Continuous-Training-and-Fine-tuning-for-Domain-Specific-Language-Models-in-Medical-Question-Answering" class="headerlink" title="Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering"></a>Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00204">http://arxiv.org/abs/2311.00204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Guo, Yining Hua</li>
<li>for: 这个研究旨在将大型语言模型训练为医学领域专家模型，以便应用不需要训练成本过高。</li>
<li>methods: 这个研究使用了连续训练和指令精炼方法，将Llama 2 base model逐渐适应中文医学领域。首先，使用10亿个中文医学参考文本进行连续训练，教育模型学习医学相关词汇和知识。然后，将模型精炼在54,000个中文医学考试例项上。</li>
<li>results: 实验结果显示，这种方法具有效果，可以训练出与GPT-3.5-turbo相比的模型，但需要训练时间和计算资源的投入相对较少。这个领域专家模型可以用于中文医学应用，同时也提供了领域专家模型训练的一个模板，可以应用于其他需要专家知识的领域，如法律、科学和工程。<details>
<summary>Abstract</summary>
Large language models exhibit promising general capabilities but often lack specialized knowledge for domain-specific tasks. Developing domain experts from a base model enables a range of applications without prohibitive training costs. This work demonstrates a method using continuous training and instruction fine-tuning to rapidly adapt Llama 2 base models to the Chinese medical domain. We first conduct continuous training on 1B tokens from Chinese medical references to teach relevant vocabulary and knowledge. The models are then fine-tuned on 54K examples sourced from the Chinese National Medical Licensing Examination. Experiments on Chinese medical data confirm the effectiveness of this approach, producing a model comparable to GPT-3.5-turbo while using way less computational resource. The resulting domain-specific model could be useful for various Chinese medical applications. More broadly, this provides a template for domain-specific training of large language models in areas where pre-trained models lack the required expertise, such as law, science, and engineering.
</details>
<details>
<summary>摘要</summary>
大型语言模型具有抢idthPromising的通用能力，但经常缺乏专业知识 для领域特定任务。将基本模型发展为领域专家，可以无需昂费训练成本，开辟多个应用程序。这个工作展示了一种使用连续训练和指导精炼方法快速地适应Llama 2基本模型到中文医学领域。我们首先通过10亿个中文医学参考文本进行连续训练，教育模型重要的词汇和知识。然后，我们对54,000个中文医学测验例题进行精炼，实验结果显示这种方法的有效性，可以与GPT-3.5-turbo相比，但用了很多 fewer computational resource。所有的领域专家模型可以用于多个中文医学应用程序。此外，这提供了对各个领域的大型语言模型特定训练的模板，例如法律、科学和工程。
</details></li>
</ul>
<hr>
<h2 id="ZEETAD-Adapting-Pretrained-Vision-Language-Model-for-Zero-Shot-End-to-End-Temporal-Action-Detection"><a href="#ZEETAD-Adapting-Pretrained-Vision-Language-Model-for-Zero-Shot-End-to-End-Temporal-Action-Detection" class="headerlink" title="ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection"></a>ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00729">http://arxiv.org/abs/2311.00729</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/UARK-AICV/ZEETAD">https://github.com/UARK-AICV/ZEETAD</a></li>
<li>paper_authors: Thinh Phan, Khoa Vo, Duy Le, Gianfranco Doretto, Donald Adjeroh, Ngan Le</li>
<li>for: 本研究旨在提高零例目标检测（TAD）的性能，特别是在无需大量标注数据的情况下。</li>
<li>methods: 本研究使用了两个模块：分别是一个基于转移器的 dual-localization 模块和一个基于 CLIP 的 zero-shot 提案类型检测模块。 dual-localization 模块可以在视频中检测动作事件，并选择ively收集关键的 semantic 嵌入，以便 later 的认知。 CLIP 模块可以从文本和帧输入中生成 semantic 嵌入。</li>
<li>results: 对 THUMOS14 和 ActivityNet-1.3 数据集进行了广泛的实验，结果显示我们的方法在零例目标检测中表现出色，并能够有效地将 ViL 模型传递知识到未看到的动作类别。<details>
<summary>Abstract</summary>
Temporal action detection (TAD) involves the localization and classification of action instances within untrimmed videos. While standard TAD follows fully supervised learning with closed-set setting on large training data, recent zero-shot TAD methods showcase the promising of open-set setting by leveraging large-scale contrastive visual-language (ViL) pretrained models. However, existing zero-shot TAD methods have limitations on how to properly construct the strong relationships between two interdependent tasks of localization and classification and adapt ViL model to video understanding. In this work, we present ZEETAD, featuring two modules: dual-localization and zero-shot proposal classification. The former is a Transformer-based module that detects action events while selectively collecting crucial semantic embeddings for later recognition. The latter one, CLIP-based module, generates semantic embeddings from text and frame inputs for each temporal unit. Additionally, we enhance discriminative capability on unseen classes by minimally updating the frozen CLIP encoder with lightweight adapters. Extensive experiments on THUMOS14 and ActivityNet-1.3 datasets demonstrate our approach's superior performance in zero-shot TAD and effective knowledge transfer from ViL models to unseen action categories.
</details>
<details>
<summary>摘要</summary>
Temporal action detection (TAD) 涉及到视频中的动作实例的地方化和分类。而标准的 TAD 采用完全监督学习，使用大量训练数据。而现有的零shot TAD 方法具有如何正确地建立两个相互依赖的任务的关系，并将 ViL 模型适应视频理解。在这种工作中，我们提出了 ZEETAD，它包括两个模块：双向本地化和零shot 提案分类。前者是基于 Transformer 的模块，检测动作事件，并选择ively 收集关键的 semantic 嵌入，以便后续的识别。后者是基于 CLIP 的模块，生成从文本和帧输入的 semantic 嵌入。此外，我们通过轻量级更新冰封 CLIP 编码器来增强对未看到的类型的推理能力。我们对 THUMOS14 和 ActivityNet-1.3 数据集进行了广泛的实验，并证明了我们的方法在零shot TAD 和将 ViL 模型传递到未经见过的动作类别的能力是superior。
</details></li>
</ul>
<hr>
<h2 id="Modeling-subjectivity-by-Mimicking-Annotator-Annotation-in-toxic-comment-identification-across-diverse-communities"><a href="#Modeling-subjectivity-by-Mimicking-Annotator-Annotation-in-toxic-comment-identification-across-diverse-communities" class="headerlink" title="Modeling subjectivity (by Mimicking Annotator Annotation) in toxic comment identification across diverse communities"></a>Modeling subjectivity (by Mimicking Annotator Annotation) in toxic comment identification across diverse communities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00203">http://arxiv.org/abs/2311.00203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Senjuti Dutta, Sid Mittal, Sherol Chen, Deepak Ramachandran, Ravi Rajakumar, Ian Kivlichan, Sunny Mak, Alena Butryna, Praveen Paritosh</li>
<li>for: 本研究旨在提高自动化内容审核系统的可靠性，通过模拟多样化社区的看法来减少人工审核的依赖。</li>
<li>methods: 研究使用了新 datasets 和现有的公共 datasets，以及 Large Language Model(LLM) 进行评估。</li>
<li>results: 研究发现，各个 annotator 群体之间存在主观性，这说明了多数投票法的缺陷。将主观标签作为训练数据的真实标签，将在未来对多样化社区中的恶意评论进行识别和审核。<details>
<summary>Abstract</summary>
The prevalence and impact of toxic discussions online have made content moderation crucial.Automated systems can play a vital role in identifying toxicity, and reducing the reliance on human moderation.Nevertheless, identifying toxic comments for diverse communities continues to present challenges that are addressed in this paper.The two-part goal of this study is to(1)identify intuitive variances from annotator disagreement using quantitative analysis and (2)model the subjectivity of these viewpoints.To achieve our goal, we published a new dataset\footnote{\url{https://github.com/XXX} with expert annotators' annotations and used two other public datasets to identify the subjectivity of toxicity.Then leveraging the Large Language Model(LLM),we evaluate the model's ability to mimic diverse viewpoints on toxicity by varying size of the training data and utilizing same set of annotators as the test set used during model training and a separate set of annotators as the test set.We conclude that subjectivity is evident across all annotator groups, demonstrating the shortcomings of majority-rule voting. Moving forward, subjective annotations should serve as ground truth labels for training models for domains like toxicity in diverse communities.
</details>
<details>
<summary>摘要</summary>
在线上的敏感讨论普遍和影响力大，内容审核已成为必备。自动化系统可以扮演重要的角色，识别毒单不易，并减少人工审核的依赖。然而，识别多元社群中的毒单仍然存在挑战，这些挑战在这篇论文中被解决。本研究的两个目标是：一、通过量化分析发现标签者间的差异，二、模拟不同观点的主观性。为了实现目标，我们发布了一个新的数据集\footnotemark[1]，并使用了三个公共数据集来识别毒单的主观性。接着，我们运用了大型自然语言模型（LLM）来评估模型是否能够模拟多元社群中的不同观点，并随着训练数据的大小和使用相同的标签者组来训练模型和评估模型。我们发现，在所有标签者群体中，主观性都存在，这表明了多数决的缺陷。未来，将主观标签作为训练模型的参考参数，将有助于提高在多元社群中的内容审核。
</details></li>
</ul>
<hr>
<h2 id="Federated-Natural-Policy-Gradient-Methods-for-Multi-task-Reinforcement-Learning"><a href="#Federated-Natural-Policy-Gradient-Methods-for-Multi-task-Reinforcement-Learning" class="headerlink" title="Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning"></a>Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00201">http://arxiv.org/abs/2311.00201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Yang, Shicong Cen, Yuting Wei, Yuxin Chen, Yuejie Chi</li>
<li>for: 这个论文的目的是研究分布式决策的多个代理不共享本地数据轨迹。</li>
<li>methods: 这个论文使用的方法是 federated reinforcement learning（RL），它可以在多个分布式代理之间进行协同决策，而不需要共享本地数据轨迹。</li>
<li>results: 论文的结果表明，使用 federated vanilla 和 entropy-regularized natural policy gradient（NPG）方法可以在分布式环境中学习 globally optimal policy，并且可以在不同的网络大小和连接性下实现非 asymptotic 全球准确性保证。<details>
<summary>Abstract</summary>
Federated reinforcement learning (RL) enables collaborative decision making of multiple distributed agents without sharing local data trajectories. In this work, we consider a multi-task setting, in which each agent has its own private reward function corresponding to different tasks, while sharing the same transition kernel of the environment. Focusing on infinite-horizon tabular Markov decision processes, the goal is to learn a globally optimal policy that maximizes the sum of the discounted total rewards of all the agents in a decentralized manner, where each agent only communicates with its neighbors over some prescribed graph topology. We develop federated vanilla and entropy-regularized natural policy gradient (NPG) methods under softmax parameterization, where gradient tracking is applied to the global Q-function to mitigate the impact of imperfect information sharing. We establish non-asymptotic global convergence guarantees under exact policy evaluation, which are nearly independent of the size of the state-action space and illuminate the impacts of network size and connectivity. To the best of our knowledge, this is the first time that global convergence is established for federated multi-task RL using policy optimization. Moreover, the convergence behavior of the proposed algorithms is robust against inexactness of policy evaluation.
</details>
<details>
<summary>摘要</summary>
simult代码中文翻译<</SYS>>多 Agent 联合强化学习（RL）可以在多个分布式 Agent 之间进行共同决策，不需要共享本地数据轨迹。在这个工作中，我们考虑了多任务 setting，每个 Agent 都有自己私有的私人奖励函数，对应不同的任务，而共享同一个环境转移核函数。我们的目标是在无穷远Tabular Markov决策过程中学习一个全局最优策略，以最大化所有 Agent 的折扣总奖励，在分布式方式下进行决策，每个 Agent 只与其邻居进行交流，并且在一定的图形结构上进行交流。我们开发了联邦vanilla和熵 regularized 自然策略梯度（NPG）方法，并使用 softmax 归一化，并在梯度跟踪技术下对全球Q函数进行梯度追踪，以避免因不完全信息共享而导致的影响。我们提出了不对极限的全球吞吐量保证，这些保证在状态动作空间的大小和精度级别上几乎是独立的，并且透视网络大小和连接度的影响。到目前为止，这是首次对联邦多任务 RL 使用策略优化进行全球吞吐量的全球吞吐量确认。此外，我们的方法的吞吐量行为对精度评估的不一致具有Robust性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.AI_2023_11_01/" data-id="cloqtaena006dgh88efbk99my" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.CL_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T11:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.CL_2023_11_01/">cs.CL - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="On-The-Open-Prompt-Challenge-In-Conditional-Audio-Generation"><a href="#On-The-Open-Prompt-Challenge-In-Conditional-Audio-Generation" class="headerlink" title="On The Open Prompt Challenge In Conditional Audio Generation"></a>On The Open Prompt Challenge In Conditional Audio Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00897">http://arxiv.org/abs/2311.00897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ernie Chang, Sidd Srinivasan, Mahi Luthra, Pin-Jie Lin, Varun Nagaraja, Forrest Iandola, Zechun Liu, Zhaoheng Ni, Changsheng Zhao, Yangyang Shi, Vikas Chandra</li>
<li>for: 这个论文的目的是如何使用 TTA 模型来改善用户输入提示的音频生成质量。</li>
<li>methods: 这个论文使用了两个关键思想来解决用户提示挑战：首先，用户提示通常比训练提示更为简略，导致音频生成和提示之间存在大的启用差异。其次，存在一种音频描述分布，TTA 模型在这种分布下能够更好地生成更高质量的音频。</li>
<li>results: 该论文通过使用 instruction-tuned 模型重写提示，并通过margin ranking学习使用文本-音频对应为反馈信号，实现了对音频质量的改善。在对象和主观人类评价中，都观察到了明显的改善。<details>
<summary>Abstract</summary>
Text-to-audio generation (TTA) produces audio from a text description, learning from pairs of audio samples and hand-annotated text. However, commercializing audio generation is challenging as user-input prompts are often under-specified when compared to text descriptions used to train TTA models. In this work, we treat TTA models as a ``blackbox'' and address the user prompt challenge with two key insights: (1) User prompts are generally under-specified, leading to a large alignment gap between user prompts and training prompts. (2) There is a distribution of audio descriptions for which TTA models are better at generating higher quality audio, which we refer to as ``audionese''. To this end, we rewrite prompts with instruction-tuned models and propose utilizing text-audio alignment as feedback signals via margin ranking learning for audio improvements. On both objective and subjective human evaluations, we observed marked improvements in both text-audio alignment and music audio quality.
</details>
<details>
<summary>摘要</summary>
文本到声音生成（TTA）可以生成声音从文本描述，学习从声音样本和手动标注的文本对。但是，商业化声音生成具有挑战，因为用户输入提示通常与用于训练TTA模型的文本描述相比较少。在这项工作中，我们将TTA模型当做黑obox处理，并通过两个关键发现：（1）用户提示通常不够具体，导致用户提示和训练提示之间存在大的对齐差。（2）存在一个声音描述的分布，TTA模型在这个分布下能够更高质量的生成声音，我们称之为“audionese”。因此，我们将提示重新编写为 instruction-tuned 模型，并提出使用文本-声音对应为反馈信号via margin ranking学习来改善声音质量。在对象和主观人类评估中，我们观察到了明显改善的文本-声音对应和音乐声音质量。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Prompt-Editing-For-Conditional-Audio-Generation"><a href="#In-Context-Prompt-Editing-For-Conditional-Audio-Generation" class="headerlink" title="In-Context Prompt Editing For Conditional Audio Generation"></a>In-Context Prompt Editing For Conditional Audio Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00895">http://arxiv.org/abs/2311.00895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ernie Chang, Pin-Jie Lin, Yang Li, Sidd Srinivasan, Gael Le Lan, David Kant, Yangyang Shi, Forrest Iandola, Vikas Chandra</li>
<li>for: 提高text-to-audio生成模型在实际数据上的部署，因为实际数据中的分布shift可能会使模型表现下降。</li>
<li>methods:  Retrieval-based in-context prompt editing framework，利用训练Caption作为示例来修改用户提示。</li>
<li>results: 提高了用户提示集中的音频质量。<details>
<summary>Abstract</summary>
Distributional shift is a central challenge in the deployment of machine learning models as they can be ill-equipped for real-world data. This is particularly evident in text-to-audio generation where the encoded representations are easily undermined by unseen prompts, which leads to the degradation of generated audio -- the limited set of the text-audio pairs remains inadequate for conditional audio generation in the wild as user prompts are under-specified. In particular, we observe a consistent audio quality degradation in generated audio samples with user prompts, as opposed to training set prompts. To this end, we present a retrieval-based in-context prompt editing framework that leverages the training captions as demonstrative exemplars to revisit the user prompts. We show that the framework enhanced the audio quality across the set of collected user prompts, which were edited with reference to the training captions as exemplars.
</details>
<details>
<summary>摘要</summary>
<SYS>将文本转换为简化中文</SYS>模型在实际数据中部署时面临 distribuitional shift 挑战，这是因为模型可能不具备适应实际数据的能力。这种情况特别明显在文本到音频生成中， encoded 表示被不знакомые提示所损害，导致生成的音频质量下降。由于用户提交的提示集是有限的，因此 conditional audio generation 在野外是不充分的。我们发现，在用户提交的提示下，生成的音频样本的质量受到了影响，而使用训练集提示的情况下，音频质量更高。为此，我们提出了一种基于检索的上下文修改框架，利用训练caption作为示例来修改用户提交的提示。我们显示，该框架可以在用户提交的提示集中提高音频质量。
</details></li>
</ul>
<hr>
<h2 id="Pretraining-Data-Mixtures-Enable-Narrow-Model-Selection-Capabilities-in-Transformer-Models"><a href="#Pretraining-Data-Mixtures-Enable-Narrow-Model-Selection-Capabilities-in-Transformer-Models" class="headerlink" title="Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models"></a>Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00871">http://arxiv.org/abs/2311.00871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Steve Yadlowsky, Lyric Doshi, Nilesh Tripuraneni</li>
<li>for: 本研究探讨了Transformer模型在无supervision的情况下，是否可以通过受限的数据集来学习新任务。</li>
<li>methods: 研究者采用了基于序列的$(x, f(x))$对的方法，以investigate transformer模型在不同任务家族之间的协同学习能力。</li>
<li>results: 实验结果表明，当任务家族在预训练数据中充分表现时，Transformer模型能够几乎协同学习新任务，但当任务或函数出现外域时，模型会表现出各种失败模式和泛化能力下降。<details>
<summary>Abstract</summary>
Transformer models, notably large language models (LLMs), have the remarkable ability to perform in-context learning (ICL) -- to perform new tasks when prompted with unseen input-output examples without any explicit model training. In this work, we study how effectively transformers can bridge between their pretraining data mixture, comprised of multiple distinct task families, to identify and learn new tasks in-context which are both inside and outside the pretraining distribution. Building on previous work, we investigate this question in a controlled setting, where we study transformer models trained on sequences of $(x, f(x))$ pairs rather than natural language. Our empirical results show transformers demonstrate near-optimal unsupervised model selection capabilities, in their ability to first in-context identify different task families and in-context learn within them when the task families are well-represented in their pretraining data. However when presented with tasks or functions which are out-of-domain of their pretraining data, we demonstrate various failure modes of transformers and degradation of their generalization for even simple extrapolation tasks. Together our results highlight that the impressive ICL abilities of high-capacity sequence models may be more closely tied to the coverage of their pretraining data mixtures than inductive biases that create fundamental generalization capabilities.
</details>
<details>
<summary>摘要</summary>
启发器模型，特别是大语言模型（LLM），有让人惊叹的能力：无需显式训练，就能在新的输入输出示例上进行学习。在这项工作中，我们研究了启发器模型在受过训练的数据混合中如何 bridge 到新任务上进行学习。我们在控制的环境下进行研究，我们研究了基于 sequences of （x, f(x)) pairs 而不是自然语言的启发器模型。我们的实验结果表明，启发器模型在受过训练的数据混合中能够准确地identify 新任务家族并在其中学习，当任务家族在受过训练数据中充分表示时。但当面临没有适应性的任务或函数时，我们 demonstate 启发器模型的多种失败模式和泛化能力的减退。这些结果表明，高容量序列模型的印象优秀ICL能力可能更加closely tied于其受过训练数据混合的覆盖率而不是基本的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Disfluency-Detection-from-Untranscribed-Speech"><a href="#Automatic-Disfluency-Detection-from-Untranscribed-Speech" class="headerlink" title="Automatic Disfluency Detection from Untranscribed Speech"></a>Automatic Disfluency Detection from Untranscribed Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00867">http://arxiv.org/abs/2311.00867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amrit Romana, Kazuhito Koishida, Emily Mower Provost</li>
<li>for: 这个研究是为了提高自动异常流 speech 识别和分类。</li>
<li>methods: 这个研究使用语言、音频和多模态方法进行自动异常流 speech 识别和分类。</li>
<li>results: 研究发现，使用语音为输入的音频基于方法比语音识别系统来的方法更高效。此外，多模态架构也提高了异常流 speech 识别性能。<details>
<summary>Abstract</summary>
Speech disfluencies, such as filled pauses or repetitions, are disruptions in the typical flow of speech. Stuttering is a speech disorder characterized by a high rate of disfluencies, but all individuals speak with some disfluencies and the rates of disfluencies may by increased by factors such as cognitive load. Clinically, automatic disfluency detection may help in treatment planning for individuals who stutter. Outside of the clinic, automatic disfluency detection may serve as a pre-processing step to improve natural language understanding in downstream applications. With this wide range of applications in mind, we investigate language, acoustic, and multimodal methods for frame-level automatic disfluency detection and categorization. Each of these methods relies on audio as an input. First, we evaluate several automatic speech recognition (ASR) systems in terms of their ability to transcribe disfluencies, measured using disfluency error rates. We then use these ASR transcripts as input to a language-based disfluency detection model. We find that disfluency detection performance is largely limited by the quality of transcripts and alignments. We find that an acoustic-based approach that does not require transcription as an intermediate step outperforms the ASR language approach. Finally, we present multimodal architectures which we find improve disfluency detection performance over the unimodal approaches. Ultimately, this work introduces novel approaches for automatic frame-level disfluency and categorization. In the long term, this will help researchers incorporate automatic disfluency detection into a range of applications.
</details>
<details>
<summary>摘要</summary>
干扰性言语，如填充停顿或重复，是语言流动的干扰。吵吵吵是一种语言障碍，其特征是高率干扰，但所有人都会有一些干扰，并且干扰率可能会受因素如认知负担的影响。临床上，自动干扰检测可能会帮助治疗吵吵吵的人群。外部，自动干扰检测可能会作为下游应用程序的预处理步骤，以提高自然语言理解。为了实现这些应用，我们 investigate语言、音响和多模态方法 для自动干扰检测和分类。每种方法都依赖于音频输入。我们首先评估了多种自动语音识别（ASR）系统，以确定它们在捕捉干扰的能力。然后，我们使用这些ASR转译结果作为语言基于的干扰检测模型的输入。我们发现，干扰检测性能受转译和对齐的限制。我们还发现一种基于音响的方法，不需要转译作为中间步骤，可以超过语言基于的方法。最后，我们展示了多模态架构，我们发现它们可以提高干扰检测性能。总之，这项工作介绍了新的自动干扰检测和分类方法。长期来看，这将帮助研究人员在多种应用程序中自动检测干扰。
</details></li>
</ul>
<hr>
<h2 id="Calibrated-Seq2seq-Models-for-Efficient-and-Generalizable-Ultra-fine-Entity-Typing"><a href="#Calibrated-Seq2seq-Models-for-Efficient-and-Generalizable-Ultra-fine-Entity-Typing" class="headerlink" title="Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine Entity Typing"></a>Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine Entity Typing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00835">http://arxiv.org/abs/2311.00835</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanlinf/casent">https://github.com/yanlinf/casent</a></li>
<li>paper_authors: Yanlin Feng, Adithya Pratapa, David R Mortensen</li>
<li>for: 这篇论文的目的是提出一种seq2seq模型，用于ultra-fine实体类型预测。</li>
<li>methods: 该模型使用约束搜索和自适应排序来生成多个类型，并使用一种新的准确抑制方法来转换Raw序列概率为信任分数。</li>
<li>results: 在UFET数据集上进行了广泛的实验，并取得了F1分数和准确性错误的最佳性能，同时实现了更 чем50倍的搜索速度。此外，在零shot和几shot设置下，模型也表现出了极好的泛化能力，并在特殊领域实体类型预测上超越了大型语言模型。<details>
<summary>Abstract</summary>
Ultra-fine entity typing plays a crucial role in information extraction by predicting fine-grained semantic types for entity mentions in text. However, this task poses significant challenges due to the massive number of entity types in the output space. The current state-of-the-art approaches, based on standard multi-label classifiers or cross-encoder models, suffer from poor generalization performance or inefficient inference. In this paper, we present CASENT, a seq2seq model designed for ultra-fine entity typing that predicts ultra-fine types with calibrated confidence scores. Our model takes an entity mention as input and employs constrained beam search to generate multiple types autoregressively. The raw sequence probabilities associated with the predicted types are then transformed into confidence scores using a novel calibration method. We conduct extensive experiments on the UFET dataset which contains over 10k types. Our method outperforms the previous state-of-the-art in terms of F1 score and calibration error, while achieving an inference speedup of over 50 times. Additionally, we demonstrate the generalization capabilities of our model by evaluating it in zero-shot and few-shot settings on five specialized domain entity typing datasets that are unseen during training. Remarkably, our model outperforms large language models with 10 times more parameters in the zero-shot setting, and when fine-tuned on 50 examples, it significantly outperforms ChatGPT on all datasets. Our code, models and demo are available at https://github.com/yanlinf/CASENT.
</details>
<details>
<summary>摘要</summary>
“ULTRA-细化实体类型标注在信息提取中扮演了关键角色，但这个任务受到巨量实体类型的输出空间的挑战。现有的状态 искусственный智能方法，基于标准多标签分类器或相关器模型，受到低效率和差异性的限制。在这篇论文中，我们提出了CASENT模型，这是一种seq2seq模型，用于ULTRA-细化实体类型标注。我们的模型从实体提及中提取实体类型，并使用约束搜索 beam来生成多个类型。然后，我们使用一种新的准确方法将Raw序列概率转换为信任分数。我们在UFET数据集上进行了广泛的实验，其中包含超过10,000个类型。我们的方法在F1分数和准确性错误方面超过前一个状态艺术，同时实现了更高的执行速度。此外，我们还证明了我们的模型在零shot和几shot设置中的普适性，在不同领域实体类型标注数据集上具有优秀表现。特别是，当与10次更多的参数的大语言模型进行比较时，在零shot设置中，我们的模型在所有数据集上表现出优异。代码、模型和示例可以在https://github.com/yanlinf/CASENT中找到。”
</details></li>
</ul>
<hr>
<h2 id="Construction-Artifacts-in-Metaphor-Identification-Datasets"><a href="#Construction-Artifacts-in-Metaphor-Identification-Datasets" class="headerlink" title="Construction Artifacts in Metaphor Identification Datasets"></a>Construction Artifacts in Metaphor Identification Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00790">http://arxiv.org/abs/2311.00790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joanne Boisson, Luis Espinosa-Anke, Jose Camacho-Collados</li>
<li>for: 本研究探讨了现有的比喻 indentification数据集是否可以被游戏。</li>
<li>methods: 作者使用了语言模型来测试这个假设，并发现了这些数据集中的偏见导致了模型的表现不佳。</li>
<li>results: 作者在不同的数据集和设置中测试了这个假设，并发现了这些数据集中的偏见导致了模型的表现不佳。<details>
<summary>Abstract</summary>
Metaphor identification aims at understanding whether a given expression is used figuratively in context. However, in this paper we show how existing metaphor identification datasets can be gamed by fully ignoring the potential metaphorical expression or the context in which it occurs. We test this hypothesis in a variety of datasets and settings, and show that metaphor identification systems based on language models without complete information can be competitive with those using the full context. This is due to the construction procedures to build such datasets, which introduce unwanted biases for positive and negative classes. Finally, we test the same hypothesis on datasets that are carefully sampled from natural corpora and where this bias is not present, making these datasets more challenging and reliable.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。</SYS>>表达identification目标是理解给定表达是在上下文中使用 figuratively。然而，在这篇论文中，我们展示了现有的比喻identification数据集可以被游戏，完全忽略可能的比喻表达或上下文。我们在多种数据集和设置下测试了这个假设，并显示了不完整的语言模型可以与基于全文的系统竞争。这是因为构建这些数据集的过程引入了不必要的偏见，导致了正确级别的分类。最后，我们对自然聚合体中精心采样的数据集进行了测试，这些数据集不受这种偏见的影响，使得它们更加具有挑战性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Language-Model-Training-Paradigms-for-Clinical-Feature-Embeddings"><a href="#Language-Model-Training-Paradigms-for-Clinical-Feature-Embeddings" class="headerlink" title="Language Model Training Paradigms for Clinical Feature Embeddings"></a>Language Model Training Paradigms for Clinical Feature Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00768">http://arxiv.org/abs/2311.00768</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuroeth/icu_benchmarks">https://github.com/yuroeth/icu_benchmarks</a></li>
<li>paper_authors: Yurong Hu, Manuel Burger, Gunnar Rätsch, Rita Kuznetsova</li>
<li>for: 医学时序序数据的缺乏量化问题中，研究领域使用表示学习，以提高医学时序序数据的可视化和分类性能。本文旨在提高医学时序序数据的表示学习，通过 derivation of universal embeddings for clinical features such as heart rate and blood pressure。</li>
<li>methods: 本文使用自动生成文本的自监督训练方法，使用语言模型来学习高质量的医学特征嵌入。通过不同的自监督训练方法，我们实现了更高的时间步长和患者级别的表示学习精度。</li>
<li>results: 我们使用不supervised dimension reduction techniques来可视化学习的嵌入，并发现与临床知识有高度的一致性。此外，我们还在MIMIC-III标准测试集上评估模型性能，并证明了使用医学特征嵌入可以提高模型的表达能力。<details>
<summary>Abstract</summary>
In research areas with scarce data, representation learning plays a significant role. This work aims to enhance representation learning for clinical time series by deriving universal embeddings for clinical features, such as heart rate and blood pressure. We use self-supervised training paradigms for language models to learn high-quality clinical feature embeddings, achieving a finer granularity than existing time-step and patient-level representation learning. We visualize the learnt embeddings via unsupervised dimension reduction techniques and observe a high degree of consistency with prior clinical knowledge. We also evaluate the model performance on the MIMIC-III benchmark and demonstrate the effectiveness of using clinical feature embeddings. We publish our code online for replication.
</details>
<details>
<summary>摘要</summary>
在医疗数据 scarcity 的研究领域，表示学习扮演着重要的角色。这项工作的目标是通过获取丰富的临床特征表示来增强临床时间序列的表示学习。我们使用自我超vised 训练方法来学习高质量的临床特征表示，实现了更高的粒度 than 现有的时间步和患者级别表示学习。我们使用无监督的减维技术来可见化学习得到的表示，并观察到了与临床知识的高度一致性。我们还在 MIMIC-III 测试集上评估模型性能，并证明使用临床特征表示可以获得有效的结果。我们在线发布代码，以便进行复现。
</details></li>
</ul>
<hr>
<h2 id="Challenges-for-Linguistically-Driven-Computer-Based-Sign-Recognition-from-Continuous-Signing-for-American-Sign-Language"><a href="#Challenges-for-Linguistically-Driven-Computer-Based-Sign-Recognition-from-Continuous-Signing-for-American-Sign-Language" class="headerlink" title="Challenges for Linguistically-Driven Computer-Based Sign Recognition from Continuous Signing for American Sign Language"></a>Challenges for Linguistically-Driven Computer-Based Sign Recognition from Continuous Signing for American Sign Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00762">http://arxiv.org/abs/2311.00762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carol Neidle</li>
<li>for: 这篇论文主要写于计算机基于视频中识别隔离的注解符号的问题。</li>
<li>methods: 该论文主要介绍了识别注解符号的一些挑战，包括自然occurring的内部和外部签名同步变化，以及美国手语（ASL）的语言变体。</li>
<li>results: 论文还讨论了一些语言规律，可以帮助提高手势和注解符号识别的性能。<details>
<summary>Abstract</summary>
There have been recent advances in computer-based recognition of isolated, citation-form signs from video. There are many challenges for such a task, not least the naturally occurring inter- and intra- signer synchronic variation in sign production, including sociolinguistic variation in the realization of certain signs. However, there are several significant factors that make recognition of signs from continuous signing an even more difficult problem. This article presents an overview of such challenges, based in part on findings from a large corpus of linguistically annotated video data for American Sign Language (ASL). Some linguistic regularities in the structure of signs that can boost handshape and sign recognition are also discussed.
</details>
<details>
<summary>摘要</summary>
Recently, there have been advances in computer-based recognition of isolated, citation-form signs from video. However, there are many challenges for this task, including natural variations in sign production, such as sociolinguistic variations in the realization of certain signs. Moreover, recognition of signs from continuous signing is an even more difficult problem. This article provides an overview of these challenges, based on findings from a large corpus of linguistically annotated video data for American Sign Language (ASL). Additionally, some linguistic regularities in the structure of signs that can improve handshape and sign recognition are also discussed.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation may differ slightly from Traditional Chinese, which is used in Taiwan and other countries.
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Single-Channel-Speaker-Turn-Aware-Conversational-Speech-Translation"><a href="#End-to-End-Single-Channel-Speaker-Turn-Aware-Conversational-Speech-Translation" class="headerlink" title="End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation"></a>End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00697">http://arxiv.org/abs/2311.00697</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amazon-science/stac-speech-translation">https://github.com/amazon-science/stac-speech-translation</a></li>
<li>paper_authors: Juan Zuluaga-Gomez, Zhaocheng Huang, Xing Niu, Rohit Paturi, Sundararajan Srinivasan, Prashant Mathur, Brian Thompson, Marcello Federico</li>
<li>for: 这篇论文旨在解决单通道多说话人对话语音识别翻译中的泛化问题。</li>
<li>methods: 该模型采用了结束到终端的多任务培训模型，名为Speaker-Turn Aware Conversational Speech Translation，它结合了自动语音识别、语音翻译和说话人转移检测，使用特殊符号来标注序列化。</li>
<li>results: 在采用Fisher-CALLHOME数据集，并将单个说话人通道合并到一个多说话人通道中，实现了更真实和挑战性的多说话人对话场景。实验结果表明，我们的模型在多说话人条件下比参照系统表现出色，在单说话人条件下也达到了相对比较的性能。我们公开了数据处理和模型训练脚本。<details>
<summary>Abstract</summary>
Conventional speech-to-text translation (ST) systems are trained on single-speaker utterances, and they may not generalize to real-life scenarios where the audio contains conversations by multiple speakers. In this paper, we tackle single-channel multi-speaker conversational ST with an end-to-end and multi-task training model, named Speaker-Turn Aware Conversational Speech Translation, that combines automatic speech recognition, speech translation and speaker turn detection using special tokens in a serialized labeling format. We run experiments on the Fisher-CALLHOME corpus, which we adapted by merging the two single-speaker channels into one multi-speaker channel, thus representing the more realistic and challenging scenario with multi-speaker turns and cross-talk. Experimental results across single- and multi-speaker conditions and against conventional ST systems, show that our model outperforms the reference systems on the multi-speaker condition, while attaining comparable performance on the single-speaker condition. We release scripts for data processing and model training.
</details>
<details>
<summary>摘要</summary>
传统的语音到文本翻译（ST）系统通常在单个说话人的单个音频上训练，这些系统可能无法泛化到实际生活中的多个说话人对话场景。在这篇论文中，我们解决了单通道多说话人对话的语音到文本翻译问题，我们提出了一种综合和多任务训练模型，名为对话者转换意识涉及的语音翻译模型。我们使用特殊符号来检测说话者的转换，并将自动语音识别、语音翻译和说话者转换拼接在一起。我们在鱼客-CALLHOME corpus上进行了实验，将两个单个说话人的通道合并到一个多个说话人通道中，从而更真实地反映多个说话人之间的对话场景。我们对单个和多个说话人情况下的实验结果进行比较，并与传统的ST系统进行比较，结果显示我们的模型在多个说话人情况下超过参照系统，而在单个说话人情况下与参照系统相当。我们将数据处理脚本和模型训练脚本公开发布。
</details></li>
</ul>
<hr>
<h2 id="Little-Giants-Exploring-the-Potential-of-Small-LLMs-as-Evaluation-Metrics-in-Summarization-in-the-Eval4NLP-2023-Shared-Task"><a href="#Little-Giants-Exploring-the-Potential-of-Small-LLMs-as-Evaluation-Metrics-in-Summarization-in-the-Eval4NLP-2023-Shared-Task" class="headerlink" title="Little Giants: Exploring the Potential of Small LLMs as Evaluation Metrics in Summarization in the Eval4NLP 2023 Shared Task"></a>Little Giants: Exploring the Potential of Small LLMs as Evaluation Metrics in Summarization in the Eval4NLP 2023 Shared Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00686">http://arxiv.org/abs/2311.00686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neema Kotonya, Saran Krishnasamy, Joel Tetreault, Alejandro Jaimes</li>
<li>for: 本研究征文描述了我们在2023年NLP共同任务中参与的尝试，该任务旨在评估使用提示技术来使大语言模型处理质量评估任务，特别是在翻译和摘要的评估中。</li>
<li>methods: 我们采用了多种提示技术，包括标准提示、根据注释员指导的提示和创新的链条提示。此外，我们还将这些方法与零批学习和一批学习方法结合使用，以 maximize我们的评估过程的效果。</li>
<li>results: 我们的工作表明，将这些方法结合使用，使用一个”小”的开源模型（orca_mini_v3_7B）可以获得竞争力强的结果。<details>
<summary>Abstract</summary>
This paper describes and analyzes our participation in the 2023 Eval4NLP shared task, which focuses on assessing the effectiveness of prompt-based techniques to empower Large Language Models to handle the task of quality estimation, particularly in the context of evaluating machine translations and summaries. We conducted systematic experiments with various prompting techniques, including standard prompting, prompts informed by annotator instructions, and innovative chain-of-thought prompting. In addition, we integrated these approaches with zero-shot and one-shot learning methods to maximize the efficacy of our evaluation procedures. Our work reveals that combining these approaches using a "small", open source model (orca_mini_v3_7B) yields competitive results.
</details>
<details>
<summary>摘要</summary>
这份论文描述了我们在2023年的Eval4NLP共同任务中的参与，这个任务旨在通过使用提示技术来让大语言模型进行质量评估，特别是在机器翻译和摘要的评估中。我们进行了系统化的实验，使用了不同的提示技术，包括标准提示、基于注释员指导的提示和创新的链条思维提示。此外，我们还将这些方法与零shot和一shot学习方法相结合，以最大化我们的评估过程的效果。我们的工作表明，将这些方法结合使用一个"小"的开源模型（orca_mini_v3_7B）可以获得竞争力强的结果。
</details></li>
</ul>
<hr>
<h2 id="Attention-Alignment-and-Flexible-Positional-Embeddings-Improve-Transformer-Length-Extrapolation"><a href="#Attention-Alignment-and-Flexible-Positional-Embeddings-Improve-Transformer-Length-Extrapolation" class="headerlink" title="Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation"></a>Attention Alignment and Flexible Positional Embeddings Improve Transformer Length Extrapolation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00684">http://arxiv.org/abs/2311.00684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ta-Chung Chi, Ting-Han Fan, Alexander I. Rudnicky</li>
<li>for: 该论文旨在探讨如何使Transformer语言模型可以处理 longer than training length的序列，无需进行长序列细化。</li>
<li>methods: 该论文使用了 T5 家族的大型预训练语言模型，并 investigate了其位置嵌入的灵活性。</li>
<li>results: 该论文发现 T5 family 的位置嵌入可以捕捉到rich和灵活的注意模式，但是它们受到了长输入序列的扩散注意问题的困扰。该论文提出了两种注意协调策略，通过温度调整来解决这个问题，从而提高 T5 的长上下文利用能力。<details>
<summary>Abstract</summary>
An ideal length-extrapolatable Transformer language model can handle sequences longer than the training length without any long sequence fine-tuning. Such long-context utilization capability highly relies on a flexible positional embedding design. Upon investigating the flexibility of existing large pre-trained Transformer language models, we find that the T5 family deserves a closer look, as its positional embeddings capture rich and flexible attention patterns. However, T5 suffers from the dispersed attention issue: the longer the input sequence, the flatter the attention distribution. To alleviate the issue, we propose two attention alignment strategies via temperature scaling. Our findings improve the long-context utilization capability of T5 on language modeling, retrieval, and multi-document question answering without any fine-tuning, suggesting that a flexible positional embedding design and attention alignment go a long way toward Transformer length extrapolation.\footnote{\url{https://github.com/chijames/Attention-Alignment-Transformer-Length-Extrapolation}
</details>
<details>
<summary>摘要</summary>
一种理想的长度推导Transformer语言模型应该能够处理 longer than training length 的序列，而不需要任何长序细化。这种长context使用能力几乎完全取决于位置嵌入设计的灵活性。我们调查了现有大型预训练Transformer语言模型的 flexible positional embedding 设计，发现 T5 家族值得更加仔细研究，因为它的位置嵌入 capture 了丰富和灵活的注意模式。然而， T5 受到了分散注意 Issue：即输入序列越长，注意分布就越平坦。为了解决这问题，我们提出了两种注意对齐策略，通过温度扩大来实现。我们的发现提高了 T5 在语言模型、检索和多文档问答中的长context使用能力，无需任何细化，表明一种灵活的位置嵌入设计和注意对齐可以帮助Transformer长度推导。Note: The translation is in Simplified Chinese, which is a standardized form of Chinese used in mainland China and Singapore. The translation is based on the official translation of the text provided in the footnote.
</details></li>
</ul>
<hr>
<h2 id="Are-Large-Language-Models-Reliable-Judges-A-Study-on-the-Factuality-Evaluation-Capabilities-of-LLMs"><a href="#Are-Large-Language-Models-Reliable-Judges-A-Study-on-the-Factuality-Evaluation-Capabilities-of-LLMs" class="headerlink" title="Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs"></a>Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00681">http://arxiv.org/abs/2311.00681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xue-Yong Fu, Md Tahmid Rahman Laskar, Cheng Chen, Shashi Bhushan TN</li>
<li>for: 本研究探讨了Large Language Models（LLMs）作为文本生成模型生成的概要中的准确性评估者。</li>
<li>methods: 本研究提出了一种新的方法，使用单个LLM进行整个问答式准确性评估过程。然后，研究对不同的LLM进行了直接准确性评估，并对human annotation进行了比较。</li>
<li>results: 研究发现，与人类评估不符，LLMs之间存在显著的相关性，尤其是GPT-3.5在两个准确性子类型上显示出了良好的相关性。这些结果表明，目前的LLMs尚未具备正确评估准确性的能力。<details>
<summary>Abstract</summary>
In recent years, Large Language Models (LLMs) have gained immense attention due to their notable emergent capabilities, surpassing those seen in earlier language models. A particularly intriguing application of LLMs is their role as evaluators for texts produced by various generative models.   In this study, we delve into the potential of LLMs as reliable assessors of factual consistency in summaries generated by text-generation models. Initially, we introduce an innovative approach for factuality assessment using LLMs. This entails employing a singular LLM for the entirety of the question-answering-based factuality scoring process. Following this, we examine the efficacy of various LLMs in direct factuality scoring, benchmarking them against traditional measures and human annotations.   Contrary to initial expectations, our results indicate a lack of significant correlations between factuality metrics and human evaluations, specifically for GPT-4 and PaLM-2. Notable correlations were only observed with GPT-3.5 across two factuality subcategories. These consistent findings across various factual error categories suggest a fundamental limitation in the current LLMs' capability to accurately gauge factuality.   This version presents the information more concisely while maintaining the main points and findings of the original text.
</details>
<details>
<summary>摘要</summary>
Recently, Large Language Models (LLMs) have received extensive attention due to their remarkable emergent capabilities, surpassing those of earlier language models. One fascinating application of LLMs is their ability to evaluate the factual consistency of texts generated by various generative models. In this study, we explore the potential of LLMs as reliable assessors of factual consistency in summaries produced by text-generation models. We propose an innovative approach for factuality assessment using LLMs, which involves using a single LLM for the entire question-answering-based factuality scoring process. We then compare the efficacy of various LLMs in direct factuality scoring, benchmarking them against traditional measures and human annotations.Surprisingly, our results indicate a lack of significant correlations between factuality metrics and human evaluations, particularly for GPT-4 and PaLM-2. Only GPT-3.5 showed notable correlations across two factuality subcategories. These consistent findings across various factual error categories suggest a fundamental limitation in the current LLMs' ability to accurately assess factuality.This version presents the information more concisely while maintaining the main points and findings of the original text.
</details></li>
</ul>
<hr>
<h2 id="Emotion-Detection-for-Misinformation-A-Review"><a href="#Emotion-Detection-for-Misinformation-A-Review" class="headerlink" title="Emotion Detection for Misinformation: A Review"></a>Emotion Detection for Misinformation: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00671">http://arxiv.org/abs/2311.00671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwei Liu, Tianlin Zhang, Kailai Yang, Paul Thompson, Zeping Yu, Sophia Ananiadou</li>
<li>For: The paper focuses on the detection of misinformation (e.g., fake news and rumors) in social media, with a particular emphasis on the role of emotions and sentiments in distinguishing between genuine and false information.* Methods: The paper reviews a range of emotion-based methods for misinformation detection, including the use of emotion, sentiment, and stance-based features. These methods are analyzed in terms of their strengths and weaknesses.* Results: The paper discusses ongoing challenges in emotion-based misinformation detection, including the need for large, high-quality datasets, accurate annotation, and benchmarking. The authors also suggest future research directions, such as incorporating multimodality and improving interpretability.Here’s the same information in Simplified Chinese:* For: 这篇论文关注社交媒体中的谣言检测（如假新闻和谣言），特别是情感和 sentiment 在分辨真实和假信息中的作用。* Methods: 论文回顾了一系列基于情感、sentiment和立场的谣言检测方法，并分析了它们的优点和缺点。* Results: 论文讨论了谣言检测中的ongoing挑战，包括需要大量、高质量的数据、准确的注释和benchmarking。作者还提出了未来研究方向，如多 modal 和提高可读性。<details>
<summary>Abstract</summary>
With the advent of social media, an increasing number of netizens are sharing and reading posts and news online. However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people's lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic. The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors. This article comprehensively reviews emotion-based methods for misinformation detection. We begin by explaining the strong links between emotions and misinformation. We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance-based features, and describe their strengths and weaknesses. Finally, we discuss a number of ongoing challenges in emotion-based misinformation detection based on large language models and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.
</details>
<details>
<summary>摘要</summary>
We begin by discussing the strong connections between emotions and misinformation. We then provide a detailed analysis of a variety of misinformation detection methods that use emotion, sentiment, and stance-based features, and describe their strengths and weaknesses. Finally, we address ongoing challenges in emotion-based misinformation detection using large language models and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmarking, multimodality, and interpretability.
</details></li>
</ul>
<hr>
<h2 id="Explicit-Morphological-Knowledge-Improves-Pre-training-of-Language-Models-for-Hebrew"><a href="#Explicit-Morphological-Knowledge-Improves-Pre-training-of-Language-Models-for-Hebrew" class="headerlink" title="Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew"></a>Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00658">http://arxiv.org/abs/2311.00658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eylon Gueta, Omer Goldman, Reut Tsarfaty</li>
<li>for: 研究 Whether incorporating explicit morphological knowledge can improve the performance of pre-trained language models (PLMs) for morphologically-rich languages (MRLs).</li>
<li>methods: 提议 various morphologically driven tokenization methods to enable the model to leverage morphological cues beyond raw text.</li>
<li>results: 实验 Results show that morphologically driven tokenization demonstrates improved results compared to a standard language-agnostic tokenization, on a benchmark of both semantic and morphologic tasks.<details>
<summary>Abstract</summary>
Pre-trained language models (PLMs) have shown remarkable successes in acquiring a wide range of linguistic knowledge, relying solely on self-supervised training on text streams. Nevertheless, the effectiveness of this language-agnostic approach has been frequently questioned for its sub-optimal performance when applied to morphologically-rich languages (MRLs). We investigate the hypothesis that incorporating explicit morphological knowledge in the pre-training phase can improve the performance of PLMs for MRLs. We propose various morphologically driven tokenization methods enabling the model to leverage morphological cues beyond raw text. We pre-train multiple language models utilizing the different methods and evaluate them on Hebrew, a language with complex and highly ambiguous morphology. Our experiments show that morphologically driven tokenization demonstrates improved results compared to a standard language-agnostic tokenization, on a benchmark of both semantic and morphologic tasks. These findings suggest that incorporating morphological knowledge holds the potential for further improving PLMs for morphologically rich languages.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Formal-Translation-from-Reversing-Petri-Nets-to-Coloured-Petri-Nets"><a href="#Formal-Translation-from-Reversing-Petri-Nets-to-Coloured-Petri-Nets" class="headerlink" title="Formal Translation from Reversing Petri Nets to Coloured Petri Nets"></a>Formal Translation from Reversing Petri Nets to Coloured Petri Nets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00629">http://arxiv.org/abs/2311.00629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kamila Barylska, Anna Gogolinska, Lukasz Mikulski, Anna Philippou, Marcin Piatkowski, Kyriaki Psara</li>
<li>for: 这篇论文旨在探讨反计算的扩展 computing paradigm，以及其在化学反应、量子计算、机器人和分布式系统等领域的应用。</li>
<li>methods: 这篇论文使用了修改 Petri nets 的方法，以实现反计算的三种主要形式，即回溯、 causal 反转和 out-of-causal-order 反转。这些修改包括使用名称的 токен，可以组合在一起形成键。</li>
<li>results: 这篇论文报告了一种可以处理多个名称的 токен的翻译方法，该方法可以将反计算 Petri nets 翻译成 Coloured Petri Nets (CPNs) 模型，并且可以自动处理反计算系统的分析和翻译。<details>
<summary>Abstract</summary>
Reversible computation is an emerging computing paradigm that allows any sequence of operations to be executed in reverse order at any point during computation. Its appeal lies in its potential for lowpower computation and its relevance to a wide array of applications such as chemical reactions, quantum computation, robotics, and distributed systems. Reversing Petri nets are a recently-proposed extension of Petri nets that implements the three main forms of reversibility, namely, backtracking, causal reversing, and out-of-causal-order reversing. Their distinguishing feature is the use of named tokens that can be combined together to form bonds. Named tokens along with a history function, constitute the means of remembering past behaviour, thus, enabling reversal. In recent work, we have proposed a structural translation from a subclass of RPNs to the model of Coloured Petri Nets (CPNs), an extension of traditional Petri nets where tokens carry data values. In this paper, we extend the translation to handle RPNs with token multiplicity under the individual-token interpretation, a model which allows multiple tokens of the same type to exist in a system. To support the three types of reversibility, tokens are associated with their causal history and, while tokens of the same type are equally eligible to fire a transition when going forward, when going backwards they are able to reverse only the transitions they have previously fired. The new translation, in addition to lifting the restriction on token uniqueness, presents a refined approach for transforming RPNs to CPNs through a unifying approach that allows instantiating each of the three types of reversibility. The paper also reports on a tool that implements this translation, paving the way for automated translations and analysis of reversible systems using CPN Tools.
</details>
<details>
<summary>摘要</summary>
“逆计算”是一种emerging computing paradigm，允许任何运算序列在computation中执行逆序。它的吸引力在于它的低功耗计算和它适用于广泛应用，如化学反应、量子计算、机器人和分布式系统。“复原”Petri nets是一种最近提出的扩展，实现了三种主要的逆向性，namely， backtracking、causal reversing和out-of-causal-order reversing。它的特点是使用名称的对象，可以组合在一起形成关联。名称、以及一个历史函数，使得可以记住过去的行为，因此实现逆向。在最近的工作中，我们已经提出了一种结构转换，将一 subclass of RPNs转换为Colored Petri Nets（CPNs）模型， Traditional Petri nets的扩展，其中Token carry data values。在这篇论文中，我们延伸了转换，以处理 RPNs with token multiplicity under the individual-token interpretation，一个允许多个同类型的Token在系统中存在的模型。为了支持三种逆向性，Token被 associate with its causal history，而当Token在前进时，它们可以将Transition firing，但当它们在逆向时，它们只能逆转它们以前燃烧过的Transition。新的转换，不仅解除了Token唯一性的限制，而且提供了一个统一的方法，可以实现将 RPNs 转换为 CPNs。论文还报告了一个工具，实现了这个转换，将来自逆向系统的自动转换和分析。
</details></li>
</ul>
<hr>
<h2 id="Crosslingual-Retrieval-Augmented-In-context-Learning-for-Bangla"><a href="#Crosslingual-Retrieval-Augmented-In-context-Learning-for-Bangla" class="headerlink" title="Crosslingual Retrieval Augmented In-context Learning for Bangla"></a>Crosslingual Retrieval Augmented In-context Learning for Bangla</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00587">http://arxiv.org/abs/2311.00587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoqian Li, Ercong Nie, Sheng Liang</li>
<li>for: 提高低资源语言如বাংলা的自然语言处理性能</li>
<li>methods: 利用跨语言检索增强在context学习</li>
<li>results: 跨语言检索增强的提高了多语言预训练语言模型（MPLMs）在বাংলা任务上的性能<details>
<summary>Abstract</summary>
The promise of Large Language Models (LLMs) in Natural Language Processing has often been overshadowed by their limited performance in low-resource languages such as Bangla. To address this, our paper presents a pioneering approach that utilizes cross-lingual retrieval augmented in-context learning. By strategically sourcing semantically similar prompts from high-resource language, we enable multilingual pretrained language models (MPLMs), especially the generative model BLOOMZ, to successfully boost performance on Bangla tasks. Our extensive evaluation highlights that the cross-lingual retrieval augmented prompts bring steady improvements to MPLMs over the zero-shot performance.
</details>
<details>
<summary>摘要</summary>
LLMs（大型自然语言处理语言模型）在自然语言处理方面的承诺经常被低资源语言如孟加拉语掩蔽。为解决这一问题，我们的论文提出了一种创新的方法，利用跨语言检索增强在语言上学习。我们策略性地从高资源语言中抽取相似的提示，使多语言预训练语言模型（MPLMs），特别是生成模型BLOOMZ，在孟加拉语任务上表现出色。我们的广泛评估表明，跨语言检索增强提示可以持续提高MPLMs的零shot性能。
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Design-Accurate-Label-Functions"><a href="#Can-Large-Language-Models-Design-Accurate-Label-Functions" class="headerlink" title="Can Large Language Models Design Accurate Label Functions?"></a>Can Large Language Models Design Accurate Label Functions?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00739">http://arxiv.org/abs/2311.00739</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Naiqing Guan, Kaiwen Chen, Nick Koudas</li>
<li>for: 这个论文主要用于探讨使用先验语言模型（PLM）自动生成高精度标签函数（LF）的可能性。</li>
<li>methods: 本研究使用了数据雕刻框架（DataSculpt），这是一种基于PLM的交互式框架，可以自动生成LF。研究者采用了多种提示技术、实例选择策略和LF筛选方法来探索广泛的设计空间。</li>
<li>results: 研究者在12个实际数据集上进行了广泛的评估，包括多种任务。评估结果显示了当前PLM在LF设计中的优势和局限性。<details>
<summary>Abstract</summary>
Programmatic weak supervision methodologies facilitate the expedited labeling of extensive datasets through the use of label functions (LFs) that encapsulate heuristic data sources. Nonetheless, the creation of precise LFs necessitates domain expertise and substantial endeavors. Recent advances in pre-trained language models (PLMs) have exhibited substantial potential across diverse tasks. However, the capacity of PLMs to autonomously formulate accurate LFs remains an underexplored domain. In this research, we address this gap by introducing DataSculpt, an interactive framework that harnesses PLMs for the automated generation of LFs. Within DataSculpt, we incorporate an array of prompting techniques, instance selection strategies, and LF filtration methods to explore the expansive design landscape. Ultimately, we conduct a thorough assessment of DataSculpt's performance on 12 real-world datasets, encompassing a range of tasks. This evaluation unveils both the strengths and limitations of contemporary PLMs in LF design.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Embedded-Diachronic-Sense-Change-Model-with-a-Case-Study-from-Ancient-Greek"><a href="#An-Embedded-Diachronic-Sense-Change-Model-with-a-Case-Study-from-Ancient-Greek" class="headerlink" title="An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek"></a>An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00541">http://arxiv.org/abs/2311.00541</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/schyanzafar/edisc">https://github.com/schyanzafar/edisc</a></li>
<li>paper_authors: Schyan Zafar, Geoff K. Nicholls</li>
<li>for: 这个论文的目的是分析古希腊文本集的词语意思变化。</li>
<li>methods: 这个论文使用了无监督学习的GASC和DiSC生成模型，对target字(“kosmos”)的多个意思进行分析，并使用MCMC方法来衡量这些意思的变化趋势。</li>
<li>results: 该论文提出了EDiSC模型，它结合了单词嵌入和DiSC模型，可以提供更高的预测精度、真实恢复率和 uncertainty 量化，以及更好的MCMC方法的样本效率和扩展性。<details>
<summary>Abstract</summary>
Word meanings change over time, and word senses evolve, emerge or die out in the process. For ancient languages, where the corpora are often small, sparse and noisy, modelling such changes accurately proves challenging, and quantifying uncertainty in sense-change estimates consequently becomes important. GASC and DiSC are existing generative models that have been used to analyse sense change for target words from an ancient Greek text corpus, using unsupervised learning without the help of any pre-training. These models represent the senses of a given target word such as "kosmos" (meaning decoration, order or world) as distributions over context words, and sense prevalence as a distribution over senses. The models are fitted using MCMC methods to measure temporal changes in these representations. In this paper, we introduce EDiSC, an embedded version of DiSC, which combines word embeddings with DiSC to provide superior model performance. We show empirically that EDiSC offers improved predictive accuracy, ground-truth recovery and uncertainty quantification, as well as better sampling efficiency and scalability properties with MCMC methods. We also discuss the challenges of fitting these models.
</details>
<details>
<summary>摘要</summary>
word meanings change over time, and word senses evolve, emerge, or die out in the process. For ancient languages, where the corpora are often small, sparse, and noisy, modeling such changes accurately proves challenging, and quantifying uncertainty in sense-change estimates consequently becomes important. GASC and DiSC are existing generative models that have been used to analyze sense change for target words from an ancient Greek text corpus, using unsupervised learning without the help of any pre-training. these models represent the senses of a given target word, such as "kosmos" (meaning decoration, order, or world), as distributions over context words, and sense prevalence as a distribution over senses. the models are fitted using MCMC methods to measure temporal changes in these representations. in this paper, we introduce EDiSC, an embedded version of DiSC, which combines word embeddings with DiSC to provide superior model performance. we show empirically that EDiSC offers improved predictive accuracy, ground-truth recovery, and uncertainty quantification, as well as better sampling efficiency and scalability properties with MCMC methods. we also discuss the challenges of fitting these models.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Text-Rendering-Strategies-for-Pixel-Language-Models"><a href="#Text-Rendering-Strategies-for-Pixel-Language-Models" class="headerlink" title="Text Rendering Strategies for Pixel Language Models"></a>Text Rendering Strategies for Pixel Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00522">http://arxiv.org/abs/2311.00522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas F. Lotz, Elizabeth Salesky, Phillip Rust, Desmond Elliott</li>
<li>for: 这篇论文主要针对的是开放词汇语言模型Pixel模型中的文本渲染方法。</li>
<li>methods: 论文使用了四种不同的文本渲染方法，包括单个字符大字符渲染、字符匹配渲染、字符串渲染和字符串匹配渲染。</li>
<li>results: 研究发现，使用单个字符大字符渲染方法可以提高句子级任务的性能，而不会对token级任务或多语言任务造成干扰。此外，使用这种渲染方法也可以降低模型的参数数量，从86M降低到22M，并且模型的性能仍然保持在同等水平。<details>
<summary>Abstract</summary>
Pixel-based language models process text rendered as images, which allows them to handle any script, making them a promising approach to open vocabulary language modelling. However, recent approaches use text renderers that produce a large set of almost-equivalent input patches, which may prove sub-optimal for downstream tasks, due to redundancy in the input representations. In this paper, we investigate four approaches to rendering text in the PIXEL model (Rust et al., 2023), and find that simple character bigram rendering brings improved performance on sentence-level tasks without compromising performance on token-level or multilingual tasks. This new rendering strategy also makes it possible to train a more compact model with only 22M parameters that performs on par with the original 86M parameter model. Our analyses show that character bigram rendering leads to a consistently better model but with an anisotropic patch embedding space, driven by a patch frequency bias, highlighting the connections between image patch- and tokenization-based language models.
</details>
<details>
<summary>摘要</summary>
Pixel基于的语言模型可以处理作为图像的文本，这使得它们成为开 vocabulary 语言模型的有力的方法。然而，最近的方法使用生成大量几乎相同的输入补充，这可能会导致下游任务中的重复性，从而降低性能。在这篇论文中，我们调查了PIXEL模型（Rust et al., 2023）中四种文本渲染方法，并发现简单的字符双字渲染可以提高句子级任务的性能，不会影响 Token 级或多语言任务的性能。这新的渲染策略还使得可以训练一个更加占用的模型，只有 22M 参数，它与原始 86M 参数模型具有相同的性能。我们的分析表明，字符双字渲染导致一个更好的模型，但是 embedding 空间具有不均匀的特征，即补充频率偏好，这显示了图像补充和tokenization基于语言模型之间的连接。
</details></li>
</ul>
<hr>
<h2 id="Rule-Based-Error-Classification-for-Analyzing-Differences-in-Frequent-Errors"><a href="#Rule-Based-Error-Classification-for-Analyzing-Differences-in-Frequent-Errors" class="headerlink" title="Rule-Based Error Classification for Analyzing Differences in Frequent Errors"></a>Rule-Based Error Classification for Analyzing Differences in Frequent Errors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00513">http://arxiv.org/abs/2311.00513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsushi Shirafuji, Taku Matsumoto, Md Faizul Ibne Amin, Yutaka Watanobe</li>
<li>for: 本研究旨在揭示 novice 和 expert 程序员之间 Error 的差异。</li>
<li>methods: 我们提出了一种基于规则的 Error 分类工具，用于分类 code pairs 中的错误。</li>
<li>results: 我们对 95,631 个 code pairs 进行分类，平均错误数为 3.47。分析结果表明， novice 程序员的错误主要归结于programming知识的缺乏，而 expert 程序员的错误则主要归结于 problerm解决过程中的疏忽或不同于常规方法的解决方式。<details>
<summary>Abstract</summary>
Finding and fixing errors is a time-consuming task not only for novice programmers but also for expert programmers. Prior work has identified frequent error patterns among various levels of programmers. However, the differences in the tendencies between novices and experts have yet to be revealed. From the knowledge of the frequent errors in each level of programmers, instructors will be able to provide helpful advice for each level of learners. In this paper, we propose a rule-based error classification tool to classify errors in code pairs consisting of wrong and correct programs. We classify errors for 95,631 code pairs and identify 3.47 errors on average, which are submitted by various levels of programmers on an online judge system. The classified errors are used to analyze the differences in frequent errors between novice and expert programmers. The analyzed results show that, as for the same introductory problems, errors made by novices are due to the lack of knowledge in programming, and the mistakes are considered an essential part of the learning process. On the other hand, errors made by experts are due to misunderstandings caused by the carelessness of reading problems or the challenges of solving problems differently than usual. The proposed tool can be used to create error-labeled datasets and for further code-related educational research.
</details>
<details>
<summary>摘要</summary>
发现和修复错误是一项时间消耗的任务，不仅对于新手程序员而言，也对于专家程序员来说。先前的工作已经确定了不同级别程序员的错误模式的频繁性。然而，新手和专家之间的差异仍未得到揭示。通过了解每个级别程序员的错误频率，教师将能提供有用的建议。在这篇论文中，我们提议一种基于规则的错误分类工具，用于分类代码对中的错误和正确代码。我们对95631个代码对进行分类，并发现每个代码对的平均错误数为3.47。分类后的错误被用来分析新手和专家之间的错误差异。分析结果显示，对于同一些入门问题，新手的错误是由于缺乏编程知识，这些错误被视为学习过程中的必要部分。而专家的错误则是由于阅读问题不够仔细或解决问题不同于常见方式所致。我们的工具可以用于创建错误标注数据集和进一步的代码相关教育研究。
</details></li>
</ul>
<hr>
<h2 id="Robustness-Tests-for-Automatic-Machine-Translation-Metrics-with-Adversarial-Attacks"><a href="#Robustness-Tests-for-Automatic-Machine-Translation-Metrics-with-Adversarial-Attacks" class="headerlink" title="Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks"></a>Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00508">http://arxiv.org/abs/2311.00508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/i-need-sleep/eval_attack">https://github.com/i-need-sleep/eval_attack</a></li>
<li>paper_authors: Yichen Huang, Timothy Baldwin</li>
<li>for: 本研究探讨了MT评价指标在针对性Synthesized文本的性能，以探讨评价指标的稳定性。</li>
<li>methods: 我们使用了word-和character-level攻击对三种流行的机器翻译指标BERTScore、BLEURT和COMET进行实验。</li>
<li>results: 我们的人工实验表明，自动指标往往会对针对性下降的翻译文本进行过多的惩罚。此外，我们发现BERTScore指标存在不一致的问题，它将原始句子和针对性下降的句子视为相似，而将针对性下降的翻译文本视为与参考文本不符。这些异常情况激发了更多的robust指标的开发。<details>
<summary>Abstract</summary>
We investigate MT evaluation metric performance on adversarially-synthesized texts, to shed light on metric robustness. We experiment with word- and character-level attacks on three popular machine translation metrics: BERTScore, BLEURT, and COMET. Our human experiments validate that automatic metrics tend to overpenalize adversarially-degraded translations. We also identify inconsistencies in BERTScore ratings, where it judges the original sentence and the adversarially-degraded one as similar, while judging the degraded translation as notably worse than the original with respect to the reference. We identify patterns of brittleness that motivate more robust metric development.
</details>
<details>
<summary>摘要</summary>
我们研究MT评价指标性能在针对式 synthesized 文本上，以探讨指标Robustness。我们对三种流行的机器翻译指标：BERTScore、BLEURT和COMET进行实验，用单词和字符级攻击。我们的人工实验证明了自动指标往往对针对性下降的翻译进行过分罚。我们还发现BERTScore评分存在不一致性，它将原始句子和针对性下降的句子评分为相似，而它对参考的翻译进行评分时则评分较低。我们发现了指标脆弱的特征，这些特征驱动我们更加Robust指标的发展。
</details></li>
</ul>
<hr>
<h2 id="Comparing-Optimization-Targets-for-Contrast-Consistent-Search"><a href="#Comparing-Optimization-Targets-for-Contrast-Consistent-Search" class="headerlink" title="Comparing Optimization Targets for Contrast-Consistent Search"></a>Comparing Optimization Targets for Contrast-Consistent Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00488">http://arxiv.org/abs/2311.00488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hugo Fry, Seamus Fallows, Ian Fan, Jamie Wright, Nandi Schoots</li>
<li>for: 优化CCS搜索算法的目标，即recover大语言模型内部真实的表示。</li>
<li>methods: 提出了新的Midpoint-Displacement（MD）损失函数，并证明在某个参数值下，MD损失函数导致搜索器的 weights 与 CCS 相似。</li>
<li>results: MD 损失函数在certain hyper-parameter value下可以达到与 CCS 相似的搜索器 weights，并且further show that this hyper-parameter不是最佳值，可以通过更好的hyper-parameter来提高测试准确率。<details>
<summary>Abstract</summary>
We investigate the optimization target of Contrast-Consistent Search (CCS), which aims to recover the internal representations of truth of a large language model. We present a new loss function that we call the Midpoint-Displacement (MD) loss function. We demonstrate that for a certain hyper-parameter value this MD loss function leads to a prober with very similar weights to CCS. We further show that this hyper-parameter is not optimal and that with a better hyper-parameter the MD loss function attains a higher test accuracy than CCS.
</details>
<details>
<summary>摘要</summary>
我们研究对比搜索（CCS）优化目标，该目标是恢复大语言模型的内部真实性表示。我们提出了一个新的损失函数，称为中点差（MD）损失函数。我们示出了一个特定的 гипер参数值下，MD损失函数导致探测器的 веса与 CCS 非常相似。此外，我们还证明了这个 гипер参数并不是最佳的，并且通过更好的 гипер参数，MD 损失函数在测试准确率方面超过了 CCS。
</details></li>
</ul>
<hr>
<h2 id="Style-Locality-for-Controllable-Generation-with-kNN-Language-Models"><a href="#Style-Locality-for-Controllable-Generation-with-kNN-Language-Models" class="headerlink" title="Style Locality for Controllable Generation with kNN Language Models"></a>Style Locality for Controllable Generation with kNN Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00475">http://arxiv.org/abs/2311.00475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gilles Nawezi, Lucie Flek, Charles Welch</li>
<li>for: 这个论文主要是为了控制文本的风格和语言表达而研究的（control the style and language expression of text）</li>
<li>methods: 该论文使用了外部记忆和最近邻居语言模型（external memory and nearest neighbor language models），并在这些模型中添加了地域层次（locality levels）来学习如何对文本中的词语进行权重调整（weighting of words in text），以提高模型的性能。</li>
<li>results: 该研究发现，使用这种新的控制风格模型（novel approach）可以成功地控制文本的风格，并且提供了更好的流畅性-风格质量的平衡（better fluency-style trade-off）thanprevious work。<details>
<summary>Abstract</summary>
Recent language models have been improved by the addition of external memory. Nearest neighbor language models retrieve similar contexts to assist in word prediction. The addition of locality levels allows a model to learn how to weight neighbors based on their relative location to the current text in source documents, and have been shown to further improve model performance. Nearest neighbor models have been explored for controllable generation but have not examined the use of locality levels. We present a novel approach for this purpose and evaluate it using automatic and human evaluation on politeness, formality, supportiveness, and toxicity textual data. We find that our model is successfully able to control style and provides a better fluency-style trade-off than previous work.
</details>
<details>
<summary>摘要</summary>
近期语言模型已经得到了外部记忆的加入，以 nearest neighbor 语言模型为例，可以在word预测中提供类似的上下文，以帮助预测单词。通过不同的地方级别学习如何对当前文档中的邻居进行权重调整，可以进一步提高模型的性能。近邻模型在可控生成中也被研究，但没有检查了地方级别的使用。我们提出了一种新的方法，并通过自动和人工评估来评估其在政eness、正式、支持性和恶意等文本数据上的性能。我们发现我们的模型能够成功地控制样式，并提供了更好的流畅性-风格质量的交换。
</details></li>
</ul>
<hr>
<h2 id="Discourse-Relations-Classification-and-Cross-Framework-Discourse-Relation-Classification-Through-the-Lens-of-Cognitive-Dimensions-An-Empirical-Investigation"><a href="#Discourse-Relations-Classification-and-Cross-Framework-Discourse-Relation-Classification-Through-the-Lens-of-Cognitive-Dimensions-An-Empirical-Investigation" class="headerlink" title="Discourse Relations Classification and Cross-Framework Discourse Relation Classification Through the Lens of Cognitive Dimensions: An Empirical Investigation"></a>Discourse Relations Classification and Cross-Framework Discourse Relation Classification Through the Lens of Cognitive Dimensions: An Empirical Investigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00451">http://arxiv.org/abs/2311.00451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingxue Fu</li>
<li>for: 本研究旨在捕捉不同框架下的干扰关系，并使用简单的认知启发的维度来描述这些关系。</li>
<li>methods: 本研究使用了Sanders等人（2018）提出的简单维度来捕捉干扰关系，并进行了跨框架的干扰关系分类。</li>
<li>results: 研究发现，使用这些维度可以 Transfer Knowledge 从一个框架到另一个框架，并且不同的维度对不同的干扰关系有不同的影响。<details>
<summary>Abstract</summary>
Existing discourse formalisms use different taxonomies of discourse relations, which require expert knowledge to understand, posing a challenge for annotation and automatic classification. We show that discourse relations can be effectively captured by some simple cognitively inspired dimensions proposed by Sanders et al.(2018). Our experiments on cross-framework discourse relation classification (PDTB & RST) demonstrate that it is possible to transfer knowledge of discourse relations for one framework to another framework by means of these dimensions, in spite of differences in discourse segmentation of the two frameworks. This manifests the effectiveness of these dimensions in characterizing discourse relations across frameworks. Ablation studies reveal that different dimensions influence different types of discourse relations. The patterns can be explained by the role of dimensions in characterizing and distinguishing different relations. We also report our experimental results on automatic prediction of these dimensions.
</details>
<details>
<summary>摘要</summary>
现有的话语形式学派使用不同的话语关系称号，这需要专家知识来理解，对于标注和自动分类而言是一大挑战。我们表明了使用沙德等人（2018）所提出的一些简单的认知启发的维度可以有效地捕捉话语关系。我们的实验表明，可以将一个框架中的话语关系转移到另一个框架中，这些维度的帮助下，即使两个框架之间存在话语分 segmentation 的差异。这说明了这些维度在不同框架之间的话语关系capture的效果。我们也进行了删除研究，发现不同的维度对不同的话语关系产生不同的影响。这些模式可以由这些维度在话语关系之间的角色从中解释。此外，我们还报告了自动预测这些维度的实验结果。
</details></li>
</ul>
<hr>
<h2 id="Distil-Whisper-Robust-Knowledge-Distillation-via-Large-Scale-Pseudo-Labelling"><a href="#Distil-Whisper-Robust-Knowledge-Distillation-via-Large-Scale-Pseudo-Labelling" class="headerlink" title="Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling"></a>Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00430">http://arxiv.org/abs/2311.00430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huggingface/distil-whisper">https://github.com/huggingface/distil-whisper</a></li>
<li>paper_authors: Sanchit Gandhi, Patrick von Platen, Alexander M. Rush</li>
<li>for: 这个研究的目的是为了将大型预训练的语音识别模型在具有低延迟和有限资源的环境中进行运行。</li>
<li>methods: 该研究使用pseudo-labeling技术 assemble了一个大规模的开源数据集，并使用这些数据集来缩小Whisper模型，称为Distil-Whisper。通过简单的单词错误率（WER）假设，选择了最高质量的pseudo-标签进行训练。</li>
<li>results: 相比Whisper模型，Distil-Whisper模型速度快5.8倍，具有51% fewer参数，在零基础转移设置下对异类数据进行测试时的Word Error Rate（WER）下降至1%。Distil-Whisper保持了Whisper模型对困难的声学条件的Robustness，而且对长形音频中的投射错误具有较好的鲁棒性。 Distil-Whisper可以与Whisper模型一起使用，以实现2倍的速度提升，而且数学上保证输出是与原始模型相同的。<details>
<summary>Abstract</summary>
As the size of pre-trained speech recognition models increases, running these large models in low-latency or resource-constrained environments becomes challenging. In this work, we leverage pseudo-labelling to assemble a large-scale open-source dataset which we use to distill the Whisper model into a smaller variant, called Distil-Whisper. Using a simple word error rate (WER) heuristic, we select only the highest quality pseudo-labels for training. The distilled model is 5.8 times faster with 51% fewer parameters, while performing to within 1% WER on out-of-distribution test data in a zero-shot transfer setting. Distil-Whisper maintains the robustness of the Whisper model to difficult acoustic conditions, while being less prone to hallucination errors on long-form audio. Distil-Whisper is designed to be paired with Whisper for speculative decoding, yielding a 2 times speed-up while mathematically ensuring the same outputs as the original model. To facilitate further research in this domain, we make our training code, inference code and models publicly accessible.
</details>
<details>
<summary>摘要</summary>
随着预训言语识别模型的大小增加，运行这些大模型在低延迟或资源受限的环境中变得具有挑战。在这项工作中，我们利用 Pseudo-label 技术组织了大规模的开源数据集，并使用简单的单词错误率（WER）匹配来选择最高质量的 Pseudo-labels 进行训练。经过筛选后，我们得到了一个名为 Distil-Whisper 的减小型，其速度比 Whisper 快5.8倍，参数量减少51%，并在零分配情况下保持 Whisper 模型的robustness，同时减少了对长形音频的幻觉错误。 Distil-Whisper 可以与 Whisper 集成，实现2倍的速度增加，并且数学保证输出与原始模型相同。为了促进这个领域的研究，我们将训练代码、推理代码和模型公开访问ible。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Human-AI-Coordination-via-Preparatory-Language-based-Convention"><a href="#Efficient-Human-AI-Coordination-via-Preparatory-Language-based-Convention" class="headerlink" title="Efficient Human-AI Coordination via Preparatory Language-based Convention"></a>Efficient Human-AI Coordination via Preparatory Language-based Convention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00416">http://arxiv.org/abs/2311.00416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cong Guan, Lichao Zhang, Chunpeng Fan, Yichen Li, Feng Chen, Lihe Li, Yunjia Tian, Lei Yuan, Yang Yu</li>
<li>for: 本研究旨在开发智能代理人，以实现人工通用智能的目标。</li>
<li>methods: 我们利用大语言模型（LLM）来开发行动计划，以便指导人类和AI进行合作。</li>
<li>results: 我们的方法在实验环境中比现有的学习方法表现出更高的性能，并且在协调实际人类时达到了更好的人类偏好的对齐和15%的性能提升。<details>
<summary>Abstract</summary>
Developing intelligent agents capable of seamless coordination with humans is a critical step towards achieving artificial general intelligence. Existing methods for human-AI coordination typically train an agent to coordinate with a diverse set of policies or with human models fitted from real human data. However, the massively diverse styles of human behavior present obstacles for AI systems with constrained capacity, while high quality human data may not be readily available in real-world scenarios. In this study, we observe that prior to coordination, humans engage in communication to establish conventions that specify individual roles and actions, making their coordination proceed in an orderly manner. Building upon this observation, we propose employing the large language model (LLM) to develop an action plan (or equivalently, a convention) that effectively guides both human and AI. By inputting task requirements, human preferences, the number of agents, and other pertinent information into the LLM, it can generate a comprehensive convention that facilitates a clear understanding of tasks and responsibilities for all parties involved. Furthermore, we demonstrate that decomposing the convention formulation problem into sub-problems with multiple new sessions being sequentially employed and human feedback, will yield a more efficient coordination convention. Experimental evaluations conducted in the Overcooked-AI environment, utilizing a human proxy model, highlight the superior performance of our proposed method compared to existing learning-based approaches. When coordinating with real humans, our method achieves better alignment with human preferences and an average performance improvement of 15% compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
开发智能代理人可以与人类协同工作是人工一般智能的关键一步。现有的人类AI协同方法通常是训练一个代理人可以与多种政策或人类模型从实际人类数据中学习协同。然而，人类行为的极其多样性会对具有限制的AI系统带来难以解决的问题，而高质量的人类数据可能在实际 scenarios中不 readily available。在这项研究中，我们发现在协同之前，人类通常通过交流来确定协同的规则和行为，使其协同顺序进行。基于这一观察，我们提议使用大型自然语言模型（LLM）来开发一个行动计划（或等效地，一个公约），以便指导人类和AI进行协同。通过输入任务需求、人类偏好、代理人数量和其他相关信息到LLM，它可以生成一份全面的公约，以便所有参与者都能够快速理解任务和责任。此外，我们表明可以将公约的形式化问题分解成多个新会议的子问题，并采用人类反馈，以便更高效地协同。在Overcooked-AI环境中的实验评估中，我们的提议方法比现有的学习基本方法表现出更高的性能。当与真正的人类协同时，我们的方法可以更好地与人类偏好相匹配，并在平均上提高15%的性能相比于状态艺术。
</details></li>
</ul>
<hr>
<h2 id="AdaSent-Efficient-Domain-Adapted-Sentence-Embeddings-for-Few-Shot-Classification"><a href="#AdaSent-Efficient-Domain-Adapted-Sentence-Embeddings-for-Few-Shot-Classification" class="headerlink" title="AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification"></a>AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00408">http://arxiv.org/abs/2311.00408</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ukplab/adasent">https://github.com/ukplab/adasent</a></li>
<li>paper_authors: Yongxin Huang, Kexin Wang, Sourav Dutta, Raj Nath Patel, Goran Glavaš, Iryna Gurevych</li>
<li>for:  investigate strategies for domain-specialization in the context of few-shot sentence classification with Pre-trained Sentence Encoders (SEs)</li>
<li>methods:  unsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained Language Model (PLM), training a SEPT adapter on the base PLM to decouple SEPT from DAPT</li>
<li>results:  substantially improves the accuracy of few-shot sentence classification, matches or surpasses the performance of full SEPT on DAPT-ed PLM, while substantially reducing the training costs<details>
<summary>Abstract</summary>
Recent work has found that few-shot sentence classification based on pre-trained Sentence Encoders (SEs) is efficient, robust, and effective. In this work, we investigate strategies for domain-specialization in the context of few-shot sentence classification with SEs. We first establish that unsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained Language Model (PLM) (i.e., not an SE) substantially improves the accuracy of few-shot sentence classification by up to 8.4 points. However, applying DAPT on SEs, on the one hand, disrupts the effects of their (general-domain) Sentence Embedding Pre-Training (SEPT). On the other hand, applying general-domain SEPT on top of a domain-adapted base PLM (i.e., after DAPT) is effective but inefficient, since the computationally expensive SEPT needs to be executed on top of a DAPT-ed PLM of each domain. As a solution, we propose AdaSent, which decouples SEPT from DAPT by training a SEPT adapter on the base PLM. The adapter can be inserted into DAPT-ed PLMs from any domain. We demonstrate AdaSent's effectiveness in extensive experiments on 17 different few-shot sentence classification datasets. AdaSent matches or surpasses the performance of full SEPT on DAPT-ed PLM, while substantially reducing the training costs. The code for AdaSent is available.
</details>
<details>
<summary>摘要</summary>
最近的研究发现，基于预训练的句子编码器（SE）的几个步骤分类是高效、可靠和有效的。在这项工作中，我们研究预训练的域特化策略在几个步骤分类中的应用。我们首先证明了不supervised域适应预训练（DAPT）基于基础预训练语言模型（PLM）可以很大程度上提高几个步骤分类的准确率，最高提高8.4个点。但是，在SE上进行DAPT会中断SEPT的效果，而在基础PLM上进行general-domain SEPT后再进行DAPT是有效的，但是 computationally expensive SEPT的计算成本会增加。为了解决这个问题，我们提出了AdaSent，它将SEPT和DAPT分离开来，通过在基础PLM上训练SEPT adapter来实现。adapter可以在任何域的DAPT-ed PLM中插入。我们在17个不同的几个步骤分类dataset上进行了广泛的实验，并证明了AdaSent的有效性。AdaSent可以与全SEPT在DAPT-ed PLM上进行比较，同时减少训练成本。代码可以在线获取。
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Knowledge-Injection-for-Radiology-Report-Generation"><a href="#Enhanced-Knowledge-Injection-for-Radiology-Report-Generation" class="headerlink" title="Enhanced Knowledge Injection for Radiology Report Generation"></a>Enhanced Knowledge Injection for Radiology Report Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00399">http://arxiv.org/abs/2311.00399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingqiu Li, Jilan Xu, Runtian Yuan, Mohan Chen, Yuejie Zhang, Rui Feng, Xiaobo Zhang, Shang Gao</li>
<li>for:  automated radiology report generation</li>
<li>methods:  utilizes two branches (Weighted Concept Knowledge and Multimodal Retrieval Knowledge) to extract different types of knowledge and integrate with current image</li>
<li>results:  achieves superior performance over other state-of-the-art methods, with effective knowledge injection and well-structured knowledge gain<details>
<summary>Abstract</summary>
Automatic generation of radiology reports holds crucial clinical value, as it can alleviate substantial workload on radiologists and remind less experienced ones of potential anomalies. Despite the remarkable performance of various image captioning methods in the natural image field, generating accurate reports for medical images still faces challenges, i.e., disparities in visual and textual data, and lack of accurate domain knowledge. To address these issues, we propose an enhanced knowledge injection framework, which utilizes two branches to extract different types of knowledge. The Weighted Concept Knowledge (WCK) branch is responsible for introducing clinical medical concepts weighted by TF-IDF scores. The Multimodal Retrieval Knowledge (MRK) branch extracts triplets from similar reports, emphasizing crucial clinical information related to entity positions and existence. By integrating this finer-grained and well-structured knowledge with the current image, we are able to leverage the multi-source knowledge gain to ultimately facilitate more accurate report generation. Extensive experiments have been conducted on two public benchmarks, demonstrating that our method achieves superior performance over other state-of-the-art methods. Ablation studies further validate the effectiveness of two extracted knowledge sources.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HARE-Explainable-Hate-Speech-Detection-with-Step-by-Step-Reasoning"><a href="#HARE-Explainable-Hate-Speech-Detection-with-Step-by-Step-Reasoning" class="headerlink" title="HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning"></a>HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00321">http://arxiv.org/abs/2311.00321</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joonkeekim/hare-hate-speech">https://github.com/joonkeekim/hare-hate-speech</a></li>
<li>paper_authors: Yongjin Yang, Joonkee Kim, Yujin Kim, Namgyu Ho, James Thorne, Se-young Yun</li>
<li>for: 本研究旨在减轻社交媒体上的仇恨言语检测，以确保在线安全。</li>
<li>methods: 本研究使用大语言模型（LLM）的逻辑能力填充现有的恶意语言检测描述的漏洞，以提供有效的检测模型超级vision。</li>
<li>results: 实验表明，使用我们的方法，使用模型生成的数据，可以超越基elines，使用现有的自由文本人工检测。我们的方法可以提高模型的解释质量和泛化性。<details>
<summary>Abstract</summary>
With the proliferation of social media, accurate detection of hate speech has become critical to ensure safety online. To combat nuanced forms of hate speech, it is important to identify and thoroughly explain hate speech to help users understand its harmful effects. Recent benchmarks have attempted to tackle this issue by training generative models on free-text annotations of implications in hateful text. However, we find significant reasoning gaps in the existing annotations schemes, which may hinder the supervision of detection models. In this paper, we introduce a hate speech detection framework, HARE, which harnesses the reasoning capabilities of large language models (LLMs) to fill these gaps in explanations of hate speech, thus enabling effective supervision of detection models. Experiments on SBIC and Implicit Hate benchmarks show that our method, using model-generated data, consistently outperforms baselines, using existing free-text human annotations. Analysis demonstrates that our method enhances the explanation quality of trained models and improves generalization to unseen datasets. Our code is available at https://github.com/joonkeekim/hare-hate-speech.git.
</details>
<details>
<summary>摘要</summary>
随着社交媒体的普及，精准地检测 hate speech 已成为确保在线安全的关键。为了对 nuanced 形式的 hate speech 进行有效的检测，需要准确地识别和解释 hate speech，以帮助用户理解其有害的影响。现有的标准化框架已经尝试解决这个问题，通过在 free-text 约束下训练生成模型。然而，我们发现现有的注释方案存在重要的理由差距，这可能会阻碍检测模型的超级vision。在这篇论文中，我们提出了一种 hate speech detection 框架，即 HARE，它利用大型语言模型（LLM）的理解能力来填充这些注释中的解释漏洞，从而为检测模型提供有效的超级vision。我们的实验表明，使用我们的方法，使用模型生成的数据，可以在 SBIC 和 Implicit Hate 标准底下 consistently 超越基elines，使用现有的 free-text 人类注释。分析表明，我们的方法可以提高训练模型的解释质量，并且可以提高对未看到的数据集的泛化能力。我们的代码可以在 <https://github.com/joonkeekim/hare-hate-speech.git> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-for-Code-Translation-with-Comparable-Corpora-and-Multiple-References"><a href="#Data-Augmentation-for-Code-Translation-with-Comparable-Corpora-and-Multiple-References" class="headerlink" title="Data Augmentation for Code Translation with Comparable Corpora and Multiple References"></a>Data Augmentation for Code Translation with Comparable Corpora and Multiple References</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00317">http://arxiv.org/abs/2311.00317</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Veronicium/CMTrans">https://github.com/Veronicium/CMTrans</a></li>
<li>paper_authors: Yiqing Xie, Atharva Naik, Daniel Fried, Carolyn Rose</li>
<li>for: 本文是关于编程语言之间代码翻译的研究，具体来说是使用数据扩充技术来解决翻译数据的限制问题。</li>
<li>methods: 本文提出了两种数据扩充技术，一种是建立可比较的代码对，另一种是对已有的平行数据进行多个参考翻译的扩充。特别是，使用自然语言文档生成代码的方法来建立可比较的代码对，并对可用的平行数据进行多个参考翻译的扩充，以增加翻译目标的多样性。</li>
<li>results: 实验结果表明，使用本文提出的数据扩充技术可以大幅提高CodeT5在Java、Python和C++之间的翻译精度，具体来说是提高了7.5%的计算准确率（CA@1），这 verify了翻译的正确性。codes可以在<a target="_blank" rel="noopener" href="https://github.com/Veronicium/CMTrans%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/Veronicium/CMTrans中下载。</a><details>
<summary>Abstract</summary>
One major challenge of translating code between programming languages is that parallel training data is often limited. To overcome this challenge, we present two data augmentation techniques, one that builds comparable corpora (i.e., code pairs with similar functionality), and another that augments existing parallel data with multiple reference translations. Specifically, we build and analyze multiple types of comparable corpora, including programs generated from natural language documentation using a code generation model. Furthermore, to reduce overfitting to a single reference translation, we automatically generate additional translation references for available parallel data and filter the translations by unit tests, which increases variation in target translations. Experiments show that our data augmentation techniques significantly improve CodeT5 for translation between Java, Python, and C++ by an average of 7.5% Computational Accuracy (CA@1), which verifies the correctness of translations by execution. The code is available at https://github.com/Veronicium/CMTrans.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在代码翻译 между编程语言是并发训练数据匮乏。为解决这个挑战，我们提出了两种数据增强技术，一种是建立相似功能的代码对照集（i.e., 代码对照集），另一种是对已有并发数据中的多个参考翻译进行增强。我们建立了多种类型的相似对照集，包括通过自然语言文档生成的代码。此外，为避免单个参考翻译的过拟合，我们自动生成了更多的翻译参考，并使用单元测试过滤掉过拟合的翻译。实验表明，我们的数据增强技术可以在 Java、Python 和 C++ 之间的代码翻译中提高 CodeT5 的平均计算准确率（CA@1）约为 7.5%，这verify了翻译的正确性。代码可以在 GitHub 上找到：https://github.com/Veronicium/CMTrans。
</details></li>
</ul>
<hr>
<h2 id="Probing-Explicit-and-Implicit-Gender-Bias-through-LLM-Conditional-Text-Generation"><a href="#Probing-Explicit-and-Implicit-Gender-Bias-through-LLM-Conditional-Text-Generation" class="headerlink" title="Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation"></a>Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00306">http://arxiv.org/abs/2311.00306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangjue Dong, Yibo Wang, Philip S. Yu, James Caverlee</li>
<li>for: 本文旨在检测语言模型中的性别偏见，并提出一种基于三种输入策略的Conditional Text Generation机制，以检测LLMs中的显式和隐式性别偏见。</li>
<li>methods: 本文使用三种不同的输入策略来评测LLMs的性别偏见，包括使用随机输入、使用人名输入和使用各种语言模型输入。同时，本文还使用显式和隐式评价指标来评价LLMs中的性别偏见。</li>
<li>results: 实验结果表明，增大模型大小不一定能够提高公平性，并且所有测试的LLMs都表现出显式和&#x2F;或隐式的性别偏见，即使输入中不含显式性别标签。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) can generate biased and toxic responses. Yet most prior work on LLM gender bias evaluation requires predefined gender-related phrases or gender stereotypes, which are challenging to be comprehensively collected and are limited to explicit bias evaluation. In addition, we believe that instances devoid of gender-related language or explicit stereotypes in inputs can still induce gender bias in LLMs. Thus, in this work, we propose a conditional text generation mechanism without the need for predefined gender phrases and stereotypes. This approach employs three types of inputs generated through three distinct strategies to probe LLMs, aiming to show evidence of explicit and implicit gender biases in LLMs. We also utilize explicit and implicit evaluation metrics to evaluate gender bias in LLMs under different strategies. Our experiments demonstrate that an increased model size does not consistently lead to enhanced fairness and all tested LLMs exhibit explicit and/or implicit gender bias, even when explicit gender stereotypes are absent in the inputs.
</details>
<details>
<summary>摘要</summary>
Note: "Simplified Chinese" is a romanization of Chinese characters, which may not be exactly the same as the traditional Chinese characters used in mainland China. The translation is done using the "Simplified Chinese" format.
</details></li>
</ul>
<hr>
<h2 id="Detecting-Syllable-Level-Pronunciation-Stress-with-A-Self-Attention-Model"><a href="#Detecting-Syllable-Level-Pronunciation-Stress-with-A-Self-Attention-Model" class="headerlink" title="Detecting Syllable-Level Pronunciation Stress with A Self-Attention Model"></a>Detecting Syllable-Level Pronunciation Stress with A Self-Attention Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00301">http://arxiv.org/abs/2311.00301</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangweiying303/stress-detection-model">https://github.com/wangweiying303/stress-detection-model</a></li>
<li>paper_authors: Wang Weiying, Nakajima Akinori</li>
<li>for: 本研究旨在开发一种自注意模型，用于检测英语口语中每个音节的强调水平。</li>
<li>methods: 本研究使用了多种语音和分类特征，包括抽象层的抽象特征、句子级别的语音特征和语音识别器等，输入到自注意模型中，并使用自注意机制对每个音节进行强调预测。</li>
<li>results: 研究发现，使用 simplest model 可以在不同的数据集上实现准确率高达88%和93%，而更先进的模型可以提供更高的准确率。这些模型可以应用于在线会议、英语学习等场景。<details>
<summary>Abstract</summary>
One precondition of effective oral communication is that words should be pronounced clearly, especially for non-native speakers. Word stress is the key to clear and correct English, and misplacement of syllable stress may lead to misunderstandings. Thus, knowing the stress level is important for English speakers and learners. This paper presents a self-attention model to identify the stress level for each syllable of spoken English. Various prosodic and categorical features, including the pitch level, intensity, duration and type of the syllable and its nuclei (the vowel of the syllable), are explored. These features are input to the self-attention model, and syllable-level stresses are predicted. The simplest model yields an accuracy of over 88% and 93% on different datasets, while more advanced models provide higher accuracy. Our study suggests that the self-attention model can be promising in stress-level detection. These models could be applied to various scenarios, such as online meetings and English learning.
</details>
<details>
<summary>摘要</summary>
一个重要的或al通信前提是话语应该清楚地发音，特别是非本地语言 speaker。话语重点是英语的关键，不正确的重点可能导致歧义。因此，了解话语重点非常重要 для英语 speaker和学习者。这篇论文提出了一种自注意模型，用于判断每个话语的重点水平。不同的prosodic和分类特征，包括话语的抽象水平、强度、持续时间和元音类型，都被探讨。这些特征作为输入，输入到自注意模型中，并预测每个话语的重点。最简单的模型的准确率高于88%和93%在不同的数据集上，而更先进的模型可以提供更高的准确率。我们的研究表明，自注意模型在重点水平检测中具有承诺。这些模型可以应用于不同的场景，如在线会议和英语学习。
</details></li>
</ul>
<hr>
<h2 id="Entity-Alignment-Method-of-Science-and-Technology-Patent-based-on-Graph-Convolution-Network-and-Information-Fusion"><a href="#Entity-Alignment-Method-of-Science-and-Technology-Patent-based-on-Graph-Convolution-Network-and-Information-Fusion" class="headerlink" title="Entity Alignment Method of Science and Technology Patent based on Graph Convolution Network and Information Fusion"></a>Entity Alignment Method of Science and Technology Patent based on Graph Convolution Network and Information Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00300">http://arxiv.org/abs/2311.00300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runze Fang, Yawen Li, Yingxia Shao, Zeli Guan, Zhe Xue</li>
<li>for: 提高科技专利知识图库中实体匹配的性能</li>
<li>methods: 基于图 convolution 网络和 BERT 模型，利用图 структуры信息和实体属性信息进行多信息融合，以提高实体匹配的精度</li>
<li>results: 在三个 Referenced 数据集上进行实验，评估指标都高于现有方法<details>
<summary>Abstract</summary>
The entity alignment of science and technology patents aims to link the equivalent entities in the knowledge graph of different science and technology patent data sources. Most entity alignment methods only use graph neural network to obtain the embedding of graph structure or use attribute text description to obtain semantic representation, ignoring the process of multi-information fusion in science and technology patents. In order to make use of the graphic structure and auxiliary information such as the name, description and attribute of the patent entity, this paper proposes an entity alignment method based on the graph convolution network for science and technology patent information fusion. Through the graph convolution network and BERT model, the structure information and entity attribute information of the science and technology patent knowledge graph are embedded and represented to achieve multi-information fusion, thus improving the performance of entity alignment. Experiments on three benchmark data sets show that the proposed method Hit@K The evaluation indicators are better than the existing methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>科技与科学专利实体对应的实体对齐目标是将不同科技与科学专利数据源知识图中相应的实体相互对应。大多数实体对齐方法只使用图 neural network 获取图结构的嵌入或使用特征文本描述获取 semantic 表示，忽略了科技与科学专利中多种信息融合的过程。为了利用专利知识图中的图结构和辅助信息 such as 专利名称、描述和属性，本文提出了基于图 convolution network 和 BERT 模型的科技与科学专利信息融合的实体对齐方法。通过图 convolution network 和 BERT 模型，专利知识图中的结构信息和实体属性信息被嵌入和表示，实现多种信息融合，从而提高实体对齐的性能。对三个标准数据集进行实验，评估指标都比现有方法更好。>>>
</details></li>
</ul>
<hr>
<h2 id="Semantic-Representation-Learning-of-Scientific-Literature-based-on-Adaptive-Feature-and-Graph-Neural-Network"><a href="#Semantic-Representation-Learning-of-Scientific-Literature-based-on-Adaptive-Feature-and-Graph-Neural-Network" class="headerlink" title="Semantic Representation Learning of Scientific Literature based on Adaptive Feature and Graph Neural Network"></a>Semantic Representation Learning of Scientific Literature based on Adaptive Feature and Graph Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00296">http://arxiv.org/abs/2311.00296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongrui Gao, Yawen Li, Meiyu Liang, Zeli Guan, Zhe Xue</li>
<li>for: 本研究旨在提出一种基于适应特征和图 neural network的科学文献semantic representation学习方法，以增强科学文献的特征表示能力。</li>
<li>methods: 本方法首先引入适应特征方法，考虑了科学文献的全局和局部特征；然后使用图注意机制对科学文献的特征进行权重赋值，以更好地表示各个科学文献之间的相互关系。此外，本方法还提出了一种无监督图 neural network semantic representation学习方法，通过比较相互信息between科学文献的本地半语义表示和全局图semantic representation，使得图 neural network能够捕捉到各个科学文献之间的相互关系，提高了学习 semantic representation的能力。</li>
<li>results: 实验结果显示，基于适应特征和图 neural network的科学文献semantic representation学习方法在科学文献分类任务上具有竞争力，并实现了良好的result。<details>
<summary>Abstract</summary>
Because most of the scientific literature data is unmarked, it makes semantic representation learning based on unsupervised graph become crucial. At the same time, in order to enrich the features of scientific literature, a learning method of semantic representation of scientific literature based on adaptive features and graph neural network is proposed. By introducing the adaptive feature method, the features of scientific literature are considered globally and locally. The graph attention mechanism is used to sum the features of scientific literature with citation relationship, and give each scientific literature different feature weights, so as to better express the correlation between the features of different scientific literature. In addition, an unsupervised graph neural network semantic representation learning method is proposed. By comparing the mutual information between the positive and negative local semantic representation of scientific literature and the global graph semantic representation in the potential space, the graph neural network can capture the local and global information, thus improving the learning ability of the semantic representation of scientific literature. The experimental results show that the proposed learning method of semantic representation of scientific literature based on adaptive feature and graph neural network is competitive on the basis of scientific literature classification, and has achieved good results.
</details>
<details>
<summary>摘要</summary>
因为大多数科学文献数据未标注，使得基于无监督图的语义表示学习成为不可或缺的。同时，为了丰富科学文献的特征，一种基于适应特征和图神经网络的科学文献语义表示学习方法被提议。通过引入适应特征方法，科学文献的特征被考虑在全球和地方两个维度。使用图注意力机制将科学文献的特征相加，并给每个科学文献不同的特征重量，以更好地表示不同科学文献之间的相关性。此外，一种无监督图神经网络语义表示学习方法被提议。通过比较相互信息between科学文献的正向和负向本地语义表示和全球图semantic representation在潜在空间中，图神经网络可以捕捉本地和全球信息，从而提高语义表示学习的能力。实验结果表明，基于适应特征和图神经网络的科学文献语义表示学习方法在科学文献分类基础上具有竞争力，并取得了良好的结果。
</details></li>
</ul>
<hr>
<h2 id="IBADR-an-Iterative-Bias-Aware-Dataset-Refinement-Framework-for-Debiasing-NLU-models"><a href="#IBADR-an-Iterative-Bias-Aware-Dataset-Refinement-Framework-for-Debiasing-NLU-models" class="headerlink" title="IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models"></a>IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00292">http://arxiv.org/abs/2311.00292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyue Wang, Xin Liu, Lijie Wang, Yaoxiang Wang, Jinsong Su, Hua Wu</li>
<li>for: 本文旨在提出一种基于迭代偏见感知的自适应偏见识别框架（IBADR），以帮助自然语言理解（NLU）模型减少偏见。</li>
<li>methods: 本文使用的方法包括训练一个浅层模型来评估样本中偏见的程度，然后将每个样本与偏见指标相对应，并使用这些扩展样本来训练一个样本生成器。这个生成器可以学习偏见指标和样本之间的对应关系。最后，本文使用这个生成器生成具有更少偏见特征的 Pseudo 样本，并将其添加到样本池中。</li>
<li>results: 本文的实验结果和深入分析表明，IBADR 不仅可以显著超越现有的 dataset refinement 方法， дости得 State-of-the-Art 性能，而且可以与模型中心的方法兼容。<details>
<summary>Abstract</summary>
As commonly-used methods for debiasing natural language understanding (NLU) models, dataset refinement approaches heavily rely on manual data analysis, and thus maybe unable to cover all the potential biased features. In this paper, we propose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which debiases NLU models without predefining biased features. We maintain an iteratively expanded sample pool. Specifically, at each iteration, we first train a shallow model to quantify the bias degree of samples in the pool. Then, we pair each sample with a bias indicator representing its bias degree, and use these extended samples to train a sample generator. In this way, this generator can effectively learn the correspondence relationship between bias indicators and samples. Furthermore, we employ the generator to produce pseudo samples with fewer biased features by feeding specific bias indicators. Finally, we incorporate the generated pseudo samples into the pool. Experimental results and in-depth analyses on two NLU tasks show that IBADR not only significantly outperforms existing dataset refinement approaches, achieving SOTA, but also is compatible with model-centric methods.
</details>
<details>
<summary>摘要</summary>
通常使用的自然语言理解（NLU）模型偏见纠正方法中，数据集精度方法依赖于手动数据分析，因此可能无法涵盖所有可能的偏见特征。在这篇论文中，我们提出了IBADR，一种迭代偏见感知数据集精度框架，可以无需先定偏见特征来纠正NLU模型。我们保持一个逐渐扩展的样本池。specifically，在每个迭代中，我们首先使用一个浅度模型来评估样本池中每个样本的偏见度。然后，我们对每个样本分配一个偏见指标，表示其偏见度。这些扩展的样本后来用于训练样本生成器。这样的生成器可以有效地学习样本和偏见指标之间的对应关系。此外，我们使用生成器生成具有更少偏见特征的 Pseudo 样本。最后，我们将生成的 Pseudo 样本添加到样本池中。实验结果和NLU任务的深入分析表明，IBADR不仅可以准确地纠正现有的数据集精度方法，同时也与模型中心的方法兼容。
</details></li>
</ul>
<hr>
<h2 id="SoulChat-Improving-LLMs’-Empathy-Listening-and-Comfort-Abilities-through-Fine-tuning-with-Multi-turn-Empathy-Conversations"><a href="#SoulChat-Improving-LLMs’-Empathy-Listening-and-Comfort-Abilities-through-Fine-tuning-with-Multi-turn-Empathy-Conversations" class="headerlink" title="SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations"></a>SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00273">http://arxiv.org/abs/2311.00273</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scutcyr/soulchat">https://github.com/scutcyr/soulchat</a></li>
<li>paper_authors: Yirong Chen, Xiaofen Xing, Jingkai Lin, Huimin Zheng, Zhenyu Wang, Qi Liu, Xiangmin Xu</li>
<li>for: 这个论文是为了提高语言模型在心理咨询领域的Empathy能力而写的。</li>
<li>methods: 这个论文使用了多turn对话Context和更加接近心理咨询者的回应来finetune语言模型，以提高其Empathy能力。</li>
<li>results: 实验表明，通过使用多turn对话历史和更加接近心理咨询者的回应来finetune语言模型，可以显著提高语言模型的Empathy能力。<details>
<summary>Abstract</summary>
Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Syntactic-Inductive-Bias-in-Transformer-Language-Models-Especially-Helpful-for-Low-Resource-Languages"><a href="#Syntactic-Inductive-Bias-in-Transformer-Language-Models-Especially-Helpful-for-Low-Resource-Languages" class="headerlink" title="Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?"></a>Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00268">http://arxiv.org/abs/2311.00268</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lgessler/lr-sib">https://github.com/lgessler/lr-sib</a></li>
<li>paper_authors: Luke Gessler, Nathan Schneider</li>
<li>for: 检验Transformer基于语言模型BERT的针对低资源语言的启发性 inductive bias 是否可以提高预训练过程中的性能。</li>
<li>methods: 使用针对低资源语言的语法结构 inductive bias 进行预训练。</li>
<li>results: 在五种低资源语言（维吾尔语、沃洛夫语、马耳他语、古埃及语、古希腊语）中，发现这些针对低资源语言的方法并不一定有益，很少有提高性能的效果。<details>
<summary>Abstract</summary>
A line of work on Transformer-based language models such as BERT has attempted to use syntactic inductive bias to enhance the pretraining process, on the theory that building syntactic structure into the training process should reduce the amount of data needed for training. But such methods are often tested for high-resource languages such as English. In this work, we investigate whether these methods can compensate for data sparseness in low-resource languages, hypothesizing that they ought to be more effective for low-resource languages. We experiment with five low-resource languages: Uyghur, Wolof, Maltese, Coptic, and Ancient Greek. We find that these syntactic inductive bias methods produce uneven results in low-resource settings, and provide surprisingly little benefit in most cases.
</details>
<details>
<summary>摘要</summary>
一些基于Transformer的语言模型，如BERT，尝试使用语法指导来增强预训练过程，理由是在训练过程中建立语法结构可以减少训练数据量。但这些方法通常在高资源语言如英语上进行测试。在这项工作中，我们研究了这些方法是否能在低资源语言中提供更好的效果，假设它们应该更有效于低资源语言。我们在五种低资源语言中进行实验：维吾尔语、沃洛夫语、马耳他语、古埃及语和古希腊语。我们发现这些语法指导方法在低资源环境中的效果不均匀，大多数情况下提供了surprisingly little benefit。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Exemplars-Make-Large-Language-Models-More-Robust-A-Domain-Agnostic-Behavioral-Analysis"><a href="#Noisy-Exemplars-Make-Large-Language-Models-More-Robust-A-Domain-Agnostic-Behavioral-Analysis" class="headerlink" title="Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis"></a>Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00258">http://arxiv.org/abs/2311.00258</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hiroki39/noisy-exemplars-make-large-language-models-more-robust">https://github.com/hiroki39/noisy-exemplars-make-large-language-models-more-robust</a></li>
<li>paper_authors: Hongyi Zheng, Abulhair Saparov</li>
<li>for: 研究大语言模型（LLM）在逻辑推理问题中具有几个步骤的解题能力，但现有的研究很少探讨 LLM 在几个步骤的推理问题中的Robustness。</li>
<li>methods: 提出了一种系统的方法来测试 LLM 在多步逻辑问题中的Robustness，包括在不同层次（如 lexical 和 semantic 等）进行干扰分析，以及通过控制干扰示例的比例来提高几个步骤推理方法的Robustness。</li>
<li>results: 通过实验发现，模型对替换单词为同义词的干扰最为敏感，同时增加干扰示例的比例可以提高几个步骤推理方法的Robustness。<details>
<summary>Abstract</summary>
Recent advances in prompt engineering enable large language models (LLMs) to solve multi-hop logical reasoning problems with impressive accuracy. However, there is little existing work investigating the robustness of LLMs with few-shot prompting techniques. Therefore, we introduce a systematic approach to test the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic perturbations. We include perturbations at multiple levels of abstractions (e.g. lexical perturbations such as typos, and semantic perturbations such as the inclusion of intermediate reasoning steps in the questions) to conduct behavioral analysis on the LLMs. Throughout our experiments, we find that models are more sensitive to certain perturbations such as replacing words with their synonyms. We also demonstrate that increasing the proportion of perturbed exemplars in the prompts improves the robustness of few-shot prompting methods.
</details>
<details>
<summary>摘要</summary>
现代提问工程技术使大语言模型（LLM）在多步逻辑理解任务中表现出色。然而，exist little previous work investigating LLMs的可靠性using few-shot prompting techniques。因此，我们提出了一种系统性的方法来测试LLMs在多步逻辑任务中的可靠性via domain-agnostic perturbations。我们在多个层次（例如，lexical perturbations such as typos,和semantic perturbations such as the inclusion of intermediate reasoning steps in the questions）中添加干扰来进行行为分析。在我们的实验中，我们发现模型更敏感于替换words with synonyms。我们还示出，增加干扰 exemplars的比例在提问中可以提高few-shot prompting methods的可靠性。
</details></li>
</ul>
<hr>
<h2 id="The-Mystery-and-Fascination-of-LLMs-A-Comprehensive-Survey-on-the-Interpretation-and-Analysis-of-Emergent-Abilities"><a href="#The-Mystery-and-Fascination-of-LLMs-A-Comprehensive-Survey-on-the-Interpretation-and-Analysis-of-Emergent-Abilities" class="headerlink" title="The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities"></a>The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00237">http://arxiv.org/abs/2311.00237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Zhou, Jiazheng Li, Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He</li>
<li>For: This paper is written to provide a thorough survey on the interpretation and analysis of emergent abilities of large language models (LLMs).* Methods: The paper uses a macro perspective and a micro-perspective to examine studies on the mechanistic interpretability and empirical interpretability of emergent abilities in LLMs.* Results: The paper highlights the challenges encountered in interpreting emergent abilities in LLMs and suggests potential avenues for future research.Here’s the Chinese translation of the three pieces of information:* For: 这篇论文是为了提供大语言模型（LLM）的潜在能力的彻底评估和分析。* Methods: 这篇论文使用一种macro perspective和一种微观 perspective来检查大语言模型中emergent能力的机制可读性和实际可读性。* Results: 这篇论文描述了对大语言模型中emergent能力的解释所遇到的挑战和未来研究的可能性。<details>
<summary>Abstract</summary>
Understanding emergent abilities, such as in-context learning (ICL) and chain-of-thought (CoT) prompting in large language models (LLMs), is of utmost importance. This importance stems not only from the better utilization of these capabilities across various tasks, but also from the proactive identification and mitigation of potential risks, including concerns of truthfulness, bias, and toxicity, that may arise alongside these capabilities. In this paper, we present a thorough survey on the interpretation and analysis of emergent abilities of LLMs. First, we provide a concise introduction to the background and definition of emergent abilities. Then, we give an overview of advancements from two perspectives: 1) a macro perspective, emphasizing studies on the mechanistic interpretability and delving into the mathematical foundations behind emergent abilities; and 2) a micro-perspective, concerning studies that focus on empirical interpretability by examining factors associated with these abilities. We conclude by highlighting the challenges encountered and suggesting potential avenues for future research. We believe that our work establishes the basis for further exploration into the interpretation of emergent abilities.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Distort-Distract-Decode-Instruction-Tuned-Model-Can-Refine-its-Response-from-Noisy-Instructions"><a href="#Distort-Distract-Decode-Instruction-Tuned-Model-Can-Refine-its-Response-from-Noisy-Instructions" class="headerlink" title="Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions"></a>Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00233">http://arxiv.org/abs/2311.00233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taehyeon Kim, Joonkee Kim, Gihun Lee, Se-Young Yun</li>
<li>for: 这篇论文旨在提高指令搜索模型的扩展性，使其能够更好地处理不同的指令。</li>
<li>methods: 该论文提出了一种简单 yet effective的方法 called Instructive Decoding (ID), 它通过对下一个token的预测值进行冲击，使用来自受损指令（noisy instruction）的预测值来提高模型的准确率。</li>
<li>results: 经过实验，该方法可以在多种指令搜索模型和任务上提高性能，而无需更新参数。尤其是在使用’opposite’作为受损指令时，表现最好，其能够带来最大的性能提升。<details>
<summary>Abstract</summary>
While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set. This paper presents Instructive Decoding (ID), a simple yet effective approach that augments the efficacy of instruction-tuned models. Specifically, ID adjusts the logits for next-token prediction in a contrastive manner, utilizing predictions generated from a manipulated version of the original instruction, referred to as a noisy instruction. This noisy instruction aims to elicit responses that could diverge from the intended instruction yet remain plausible. We conduct experiments across a spectrum of such noisy instructions, ranging from those that insert semantic noise via random words to others like 'opposite' that elicit the deviated responses. Our approach achieves considerable performance gains across various instruction-tuned models and tasks without necessitating any additional parameter updates. Notably, utilizing 'opposite' as the noisy instruction in ID, which exhibits the maximum divergence from the original instruction, consistently produces the most significant performance gains across multiple models and tasks.
</details>
<details>
<summary>摘要</summary>
“对于已训练的语言模型，实际应用中的指令可能会让模型做出不正确的回答。本文提出了一个简单 yet 有效的方法——指令增强（Instructive Decoding，ID），以提高已训练的指令模型的表现。特别是，ID 在下一个字的预测中调整 logits 的方式，通过使用从修改过的原始指令（即杂音指令）所生成的预测，以获得更加积极的回答。我们在不同的杂音指令上进行了实验，包括插入 semantics 杂音的 Random Word，以及“opposite”类型的杂音指令，以获得更大的表现改进。我们发现，使用“opposite”类型的杂音指令可以导致最大的表现改进，并且不需要进行任何额外的参数更新。”Note: Simplified Chinese is used in this translation, as it is the most widely used variety of Chinese in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Is-GPT-Powerful-Enough-to-Analyze-the-Emotions-of-Memes"><a href="#Is-GPT-Powerful-Enough-to-Analyze-the-Emotions-of-Memes" class="headerlink" title="Is GPT Powerful Enough to Analyze the Emotions of Memes?"></a>Is GPT Powerful Enough to Analyze the Emotions of Memes?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00223">http://arxiv.org/abs/2311.00223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingjing Wang, Joshua Luo, Grace Yang, Allen Hong, Feng Luo</li>
<li>for: 这个研究的目的是探讨GPT-3.5在互联网趣图中的情感分析能力。</li>
<li>methods: 这个研究使用GPT-3.5模型来处理互联网趣图，包括分类趣图情感、确定趣图类型和检测趣图中的暗示性仇恨。</li>
<li>results: 研究发现GPT-3.5在处理这些任务时表现出色，但也存在一些限制，如理解社会规范和文化背景、解释暗示性意境和数据偏见等问题。<details>
<summary>Abstract</summary>
Large Language Models (LLMs), representing a significant achievement in artificial intelligence (AI) research, have demonstrated their ability in a multitude of tasks. This project aims to explore the capabilities of GPT-3.5, a leading example of LLMs, in processing the sentiment analysis of Internet memes. Memes, which include both verbal and visual aspects, act as a powerful yet complex tool for expressing ideas and sentiments, demanding an understanding of societal norms and cultural contexts. Notably, the detection and moderation of hateful memes pose a significant challenge due to their implicit offensive nature. This project investigates GPT's proficiency in such subjective tasks, revealing its strengths and potential limitations. The tasks include the classification of meme sentiment, determination of humor type, and detection of implicit hate in memes. The performance evaluation, using datasets from SemEval-2020 Task 8 and Facebook hateful memes, offers a comparative understanding of GPT responses against human annotations. Despite GPT's remarkable progress, our findings underscore the challenges faced by these models in handling subjective tasks, which are rooted in their inherent limitations including contextual understanding, interpretation of implicit meanings, and data biases. This research contributes to the broader discourse on the applicability of AI in handling complex, context-dependent tasks, and offers valuable insights for future advancements.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM），代表人工智能（AI）研究的一项重要成就，在多种任务中表现出色。这个项目旨在探索GPT-3.5的能力，一种领先的LLM，在互联网趣图上进行情感分析。趣图包含语言和视觉方面的特征，需要对社会规范和文化背景有深入的理解。尤其是对于带有偏见的趣图进行排查和修剪是一项非常复杂的任务，因为它们的危险性往往是 implicit的。这个项目探索GPT在这些主观任务中的表现，揭示其强点和可能的限制。任务包括趣图情感分类、趣图类型划分和排查带有偏见的趣图。使用SemEval-2020任务8的数据集和Facebook上的仇恨趣图进行性能评估，以获得人注解与GPT响应的比较理解。虽然GPT在这些任务中做出了惊人的进步，但我们的发现表明这些模型在处理主观任务时面临着挑战，这些挑战源于它们的内在限制，包括Contextual Understanding、解释偏见的能力和数据偏见。这项研究对于人工智能在处理复杂、上下文依赖的任务中的应用提供了有价值的反思，并为未来的进步提供了有价值的发现。
</details></li>
</ul>
<hr>
<h2 id="Transformers-as-Recognizers-of-Formal-Languages-A-Survey-on-Expressivity"><a href="#Transformers-as-Recognizers-of-Formal-Languages-A-Survey-on-Expressivity" class="headerlink" title="Transformers as Recognizers of Formal Languages: A Survey on Expressivity"></a>Transformers as Recognizers of Formal Languages: A Survey on Expressivity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00208">http://arxiv.org/abs/2311.00208</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lena Strobl, William Merrill, Gail Weiss, David Chiang, Dana Angluin</li>
<li>for: 这篇论文旨在探讨transformer模型在自然语言处理中的能力和限制，通过将问题转化为正式语言来比较transformer模型和其他模型的性能。</li>
<li>methods: 本论文使用了一种形式语言来描述问题，并对不同的问题进行了 theoretically分析，以了解transformer模型能否解决这些问题。</li>
<li>results: 本论文提供了一个总结性的survey，汇总了各种研究中的不同假设和结论，并提供了一个统一的框架来协调 aparently contradictory findings。<details>
<summary>Abstract</summary>
As transformers have gained prominence in natural language processing, some researchers have investigated theoretically what problems they can and cannot solve, by treating problems as formal languages. Exploring questions such as this will help to compare transformers with other models, and transformer variants with one another, for various tasks. Work in this subarea has made considerable progress in recent years. Here, we undertake a comprehensive survey of this work, documenting the diverse assumptions that underlie different results and providing a unified framework for harmonizing seemingly contradictory findings.
</details>
<details>
<summary>摘要</summary>
Translate the given text into Simplified Chinese.</SYS>答：如transformers在自然语言处理中获得了主导地位，一些研究人员已经研究了这些模型可以解决哪些问题，通过对问题进行正式语言的处理。探讨这些问题将有助于比较transformers与其他模型，以及不同transformer变体之间的比较，在不同任务上。在这个子领域中，工作已经在过去几年中做出了大量的进展。我们现在对这些工作进行了完整的报告，并 documenting不同假设的不同假设，以提供一个统一的框架，以协调似然相反的发现。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.CL_2023_11_01/" data-id="cloqtaepl00dwgh88571l4nqz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/cs.LG_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T10:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/cs.LG_2023_11_01/">cs.LG - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Data-Driven-Model-Selections-of-Second-Order-Particle-Dynamics-via-Integrating-Gaussian-Processes-with-Low-Dimensional-Interacting-Structures"><a href="#Data-Driven-Model-Selections-of-Second-Order-Particle-Dynamics-via-Integrating-Gaussian-Processes-with-Low-Dimensional-Interacting-Structures" class="headerlink" title="Data-Driven Model Selections of Second-Order Particle Dynamics via Integrating Gaussian Processes with Low-Dimensional Interacting Structures"></a>Data-Driven Model Selections of Second-Order Particle Dynamics via Integrating Gaussian Processes with Low-Dimensional Interacting Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00902">http://arxiv.org/abs/2311.00902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinchao Feng, Charles Kulick, Sui Tang</li>
<li>For: The paper aims to develop a data-driven approach for discovering a general second-order particle-based model for modeling the aggregation and collective behavior of interacting agents.* Methods: The proposed approach uses Gaussian Process (GP) priors on latent interaction kernels constrained to dynamics and observational data, which allows for uncertainty quantification and nonparametric modeling of interacting dynamical systems. The paper also develops acceleration techniques to improve scalability.* Results: The proposed approach is demonstrated to be effective in modeling various prototype systems, including real-world fish motion datasets, and outperforms competitor methods despite the use of small data sets. The approach learns an effective representation of the nonlinear dynamics in these spaces.<details>
<summary>Abstract</summary>
In this paper, we focus on the data-driven discovery of a general second-order particle-based model that contains many state-of-the-art models for modeling the aggregation and collective behavior of interacting agents of similar size and body type. This model takes the form of a high-dimensional system of ordinary differential equations parameterized by two interaction kernels that appraise the alignment of positions and velocities. We propose a Gaussian Process-based approach to this problem, where the unknown model parameters are marginalized by using two independent Gaussian Process (GP) priors on latent interaction kernels constrained to dynamics and observational data. This results in a nonparametric model for interacting dynamical systems that accounts for uncertainty quantification. We also develop acceleration techniques to improve scalability. Moreover, we perform a theoretical analysis to interpret the methodology and investigate the conditions under which the kernels can be recovered. We demonstrate the effectiveness of the proposed approach on various prototype systems, including the selection of the order of the systems and the types of interactions. In particular, we present applications to modeling two real-world fish motion datasets that display flocking and milling patterns up to 248 dimensions. Despite the use of small data sets, the GP-based approach learns an effective representation of the nonlinear dynamics in these spaces and outperforms competitor methods.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们关注数据驱动的第二阶射数据驱动模型的发现，这个模型包含了许多当前的模型，用于描述相互作用的体积粒子之间的聚合和集体行为。这个模型以高维系数方程的形式表示，由两个交互卷积函数来评估位姿速度的Alignment。我们提议使用 Gaussian Process 方法来解决这个问题，其中未知模型参数通过两个独立的 Gaussian Process 假设来推敲。这results in a nonparametric model for interacting dynamical systems that accounts for uncertainty quantification. In addition, we develop acceleration techniques to improve scalability. Furthermore, we perform a theoretical analysis to interpret the methodology and investigate the conditions under which the kernels can be recovered. We demonstrate the effectiveness of the proposed approach on various prototype systems, including the selection of the order of the systems and the types of interactions. In particular, we present applications to modeling two real-world fish motion datasets that display flocking and milling patterns up to 248 dimensions. Despite the use of small data sets, the GP-based approach learns an effective representation of the nonlinear dynamics in these spaces and outperforms competitor methods.
</details></li>
</ul>
<hr>
<h2 id="COSTAR-Improved-Temporal-Counterfactual-Estimation-with-Self-Supervised-Learning"><a href="#COSTAR-Improved-Temporal-Counterfactual-Estimation-with-Self-Supervised-Learning" class="headerlink" title="COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised Learning"></a>COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00886">http://arxiv.org/abs/2311.00886</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/google-research">https://github.com/google-research/google-research</a></li>
<li>paper_authors: Chuizheng Meng, Yihe Dong, Sercan Ö. Arık, Yan Liu, Tomas Pfister</li>
<li>for: 这篇论文旨在提出一种用于估计时间Counterfactual结果的方法，以便在健康照护和电子商务等领域做出决策，当Randomized Controlled Trials（RCTs）受到高成本或不实际性时。</li>
<li>methods: 本文引入Counterfactual Self-supervised TrAnsformeR（COSTAR）方法，该方法具有自动化学习来提高历史表现。提议的架构结合时间和特征间的注意力，并使用特有的时间对比损失，以更好地预测时间Counterfactual结果。</li>
<li>results: 比较 existing models 的实验结果显示，COSTAR 方法可以实现更高的估计精度和扩展性，并在不同的数据集上具有良好的一致性。<details>
<summary>Abstract</summary>
Estimation of temporal counterfactual outcomes from observed history is crucial for decision-making in many domains such as healthcare and e-commerce, particularly when randomized controlled trials (RCTs) suffer from high cost or impracticality. For real-world datasets, modeling time-dependent confounders is challenging due to complex dynamics, long-range dependencies and both past treatments and covariates affecting the future outcomes. In this paper, we introduce COunterfactual Self-supervised TrAnsformeR (COSTAR), a novel approach that integrates self-supervised learning for improved historical representations. The proposed framework combines temporal and feature-wise attention with a component-wise contrastive loss tailored for temporal treatment outcome observations, yielding superior performance in estimation accuracy and generalization to out-of-distribution data compared to existing models, as validated by empirical results on both synthetic and real-world datasets.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT描述：在各种领域中，如医疗和电商，估算时间上的假设结果是决策的关键，特别是当随机控制试验（RCT）的成本或实用性太高时。实际数据中模型时间依赖的难点在于复杂的动态、长距离依赖和过去的治疗和 covariates 影响未来结果。本文介绍一种新的方法——自动学习Counterfactual Self-supervised TrAnsformeR（COSTAR），它将自动学习纳入历史表示中，以提高估算精度和对异常数据的泛化。方法：1. 将时间序列分解成多个特征，并对每个特征应用自动学习模型进行学习。2. 使用时间和特征粒度的注意力，对历史数据进行注意力机制。3. 使用特征粒度的对比损失函数，以优化历史表示。效果：1. 与现有模型相比，COSTAR 在估算精度和对异常数据的泛化方面具有显著优势。2. COSTAR 在实际数据上显示出较高的鲁棒性和泛化能力。结论：COSTAR 是一种可靠的、高效的 temporal counterfactual outcomes 估算方法，可以在各种领域中应用。<<SYS>>I hope this helps! Let me know if you have any further questions or if there's anything else I can help with.
</details></li>
</ul>
<hr>
<h2 id="Learning-Collective-Behaviors-from-Observation"><a href="#Learning-Collective-Behaviors-from-Observation" class="headerlink" title="Learning Collective Behaviors from Observation"></a>Learning Collective Behaviors from Observation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00875">http://arxiv.org/abs/2311.00875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinchao Feng, Ming Zhong</li>
<li>for: 理解复杂系统中间的自组织行为</li>
<li>methods: 使用学习方法来识别动力系统的结构，包括理论保证收敛和计算效率</li>
<li>results: 可以处理高维观测数据，涵盖观测噪声、复杂互动规则、缺失互动特征和实际观测agent系统观测数据<details>
<summary>Abstract</summary>
We present a review of a series of learning methods used to identify the structure of dynamical systems, aiming to understand emergent behaviors in complex systems of interacting agents. These methods not only offer theoretical guarantees of convergence but also demonstrate computational efficiency in handling high-dimensional observational data. They can manage observation data from both first- and second-order dynamical systems, accounting for observation/stochastic noise, complex interaction rules, missing interaction features, and real-world observations of interacting agent systems. The essence of developing such a series of learning methods lies in designing appropriate loss functions using the variational inverse problem approach, which inherently provides dimension reduction capabilities to our learning methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一系列学习方法，用于识别动力系统的结构，以便理解复杂系统中间的 emergent 行为。这些方法不仅提供了理论上的确定性 guarantees，还能够效率地处理高维观测数据。它们可以处理来自一元和二元动力系统的观测数据，并考虑观测/抽象噪声、复杂互动规则、缺失互动特征和实际世界中间的互动代理系统观测数据。难点在于开发这种系列学习方法的核心在于设计适当的损失函数，使用变量逆问题方法，这种方法自然提供了维度减少能力。
</details></li>
</ul>
<hr>
<h2 id="Low-latency-Real-time-Voice-Conversion-on-CPU"><a href="#Low-latency-Real-time-Voice-Conversion-on-CPU" class="headerlink" title="Low-latency Real-time Voice Conversion on CPU"></a>Low-latency Real-time Voice Conversion on CPU</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00873">http://arxiv.org/abs/2311.00873</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/koeai/llvc">https://github.com/koeai/llvc</a></li>
<li>paper_authors: Konstantine Sadov, Matthew Hutter, Asara Near</li>
<li>for: 这篇论文旨在实现实时任意声音转换，以便在各种应用场景中使用。</li>
<li>methods: 该模型采用了前期音频滤波和干扰级联网络，并结合了生成对抗学习和知识储存技术，以实现低延迟和低资源占用。</li>
<li>results: 模型在16kHz采样率下的延迟低于20毫秒，并且在Consumer CPU上运行速度约为2.8倍于实时。此外，该模型还实现了最低的资源占用和延迟，并提供了开源样本、代码和预训练模型重量。<details>
<summary>Abstract</summary>
We adapt the architectures of previous audio manipulation and generation neural networks to the task of real-time any-to-one voice conversion. Our resulting model, LLVC ($\textbf{L}$ow-latency $\textbf{L}$ow-resource $\textbf{V}$oice $\textbf{C}$onversion), has a latency of under 20ms at a bitrate of 16kHz and runs nearly 2.8x faster than real-time on a consumer CPU. LLVC uses both a generative adversarial architecture as well as knowledge distillation in order to attain this performance. To our knowledge LLVC achieves both the lowest resource usage as well as the lowest latency of any open-source voice conversion model. We provide open-source samples, code, and pretrained model weights at https://github.com/KoeAI/LLVC.
</details>
<details>
<summary>摘要</summary>
我们适应之前的音频修改和生成神经网络的架构，用于实时任意到一个语音转换任务。我们的结果是LLVC（低延迟低资源语音转换）模型，延迟时间低于20毫秒，采样率16kHz，在消耗者CPU上运行速度约为2.8倍于实时。LLVC使用生成对抗架构以及知识塑造来实现这种性能。我们认为LLVC在开源语音转换模型中实现了最低的资源使用和延迟时间。我们在https://github.com/KoeAI/LLVC提供开源样本、代码和预训练模型参数。
</details></li>
</ul>
<hr>
<h2 id="Generalizing-Nonlinear-ICA-Beyond-Structural-Sparsity"><a href="#Generalizing-Nonlinear-ICA-Beyond-Structural-Sparsity" class="headerlink" title="Generalizing Nonlinear ICA Beyond Structural Sparsity"></a>Generalizing Nonlinear ICA Beyond Structural Sparsity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00866">http://arxiv.org/abs/2311.00866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujia Zheng, Kun Zhang</li>
<li>for: 非线性独立组分分析（ICA）旨在揭示真实的潜在来源从其可观察的非线性混合中解释。</li>
<li>methods: 使用结构稀缺来实现无监督的可 identificability。</li>
<li>results: 提出了一些新的可 identificability 结果，以适应实际场景中的不完整、偏 sparse 和依赖源等限制。<details>
<summary>Abstract</summary>
Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established. Theoretical claims are supported empirically on both synthetic and real-world datasets.
</details>
<details>
<summary>摘要</summary>
To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity, and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are more observed variables than sources (undercomplete), and when certain sparsity and/or source independence assumptions are not met for some changing sources. Moreover, we show that even in cases with flexible grouping structures (e.g., part of the sources can be divided into irreducible independent groups with various sizes), appropriate identifiability results can also be established.Empirical results on both synthetic and real-world datasets support our theoretical claims.
</details></li>
</ul>
<hr>
<h2 id="SmoothHess-ReLU-Network-Feature-Interactions-via-Stein’s-Lemma"><a href="#SmoothHess-ReLU-Network-Feature-Interactions-via-Stein’s-Lemma" class="headerlink" title="SmoothHess: ReLU Network Feature Interactions via Stein’s Lemma"></a>SmoothHess: ReLU Network Feature Interactions via Stein’s Lemma</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00858">http://arxiv.org/abs/2311.00858</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maxtorop/smoothhess">https://github.com/maxtorop/smoothhess</a></li>
<li>paper_authors: Max Torop, Aria Masoomi, Davin Hill, Kivanc Kose, Stratis Ioannidis, Jennifer Dy</li>
<li>for: 这个论文目的是解释神经网络中特征之间的交互效应。</li>
<li>methods: 这个论文提出了一种基于Stein lemma的方法，名为SmoothHess，来估算神经网络中的二阶交互效应。这种方法需要网络梯度的调用，但不需要修改ReLU网络的结构。</li>
<li>results: 论文通过在 benchmark datasets 和一个实际医疗领域的呼吸测量数据集上验证了SmoothHess的能力，并证明了它的优于其他方法。<details>
<summary>Abstract</summary>
Several recent methods for interpretability model feature interactions by looking at the Hessian of a neural network. This poses a challenge for ReLU networks, which are piecewise-linear and thus have a zero Hessian almost everywhere. We propose SmoothHess, a method of estimating second-order interactions through Stein's Lemma. In particular, we estimate the Hessian of the network convolved with a Gaussian through an efficient sampling algorithm, requiring only network gradient calls. SmoothHess is applied post-hoc, requires no modifications to the ReLU network architecture, and the extent of smoothing can be controlled explicitly. We provide a non-asymptotic bound on the sample complexity of our estimation procedure. We validate the superior ability of SmoothHess to capture interactions on benchmark datasets and a real-world medical spirometry dataset.
</details>
<details>
<summary>摘要</summary>
几种最近的方法用于解释神经网络中的特征交互，通过查看神经网络的第二Derivative。然而，ReLU网络是划分线性的，因此其第二Derivative在大多数地方都是零。我们提出了SmoothHess方法，通过斯坦 lemma来估算神经网络抽象后的第二Derivative。具体来说，我们使用一种高效的采样算法来估算神经网络与 Gaussian 卷积后的第二Derivative，只需要网络梯度的调用。SmoothHess 是一种后期应用的方法，不需要修改 ReLU 网络的结构，并且可以控制抽象程度的Explicitly。我们提供了非 asymptotic 的样本复杂性下界。我们验证了 SmoothHess 在 benchmark 数据集和一个真实世界的医疗领域的呼吸测试数据集上的超过其他方法 capture 交互的能力。
</details></li>
</ul>
<hr>
<h2 id="Electronic-excited-states-from-physically-constrained-machine-learning"><a href="#Electronic-excited-states-from-physically-constrained-machine-learning" class="headerlink" title="Electronic excited states from physically-constrained machine learning"></a>Electronic excited states from physically-constrained machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00844">http://arxiv.org/abs/2311.00844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edoardo Cignoni, Divya Suman, Jigyasa Nigam, Lorenzo Cupellini, Benedetta Mennucci, Michele Ceriotti</li>
<li>for: 这篇论文旨在探讨使用数据驱动技术来代替物理结构计算的问题，以及是否应该直接将机器学习（ML）应用到预测材料性质上，或者是将其与物理基础相互结合。</li>
<li>methods: 作者提出了一种结合数据驱动技术和物理基础的集成模型方法，其中使用了对效 Hamiltonian 的Symmetry-adapted ML模型来复制电子激发的数值计算结果。</li>
<li>results: 作者的模型可以对更大和更复杂的分子进行预测，并且可以通过间接目标已经得到的计算结果，从而实现了很大的计算成本减少。这些结果证明了将数据驱动技术与物理基础相互结合的优势，并提供了开发ML-加上电子结构方法的蓝本。<details>
<summary>Abstract</summary>
Data-driven techniques are increasingly used to replace electronic-structure calculations of matter. In this context, a relevant question is whether machine learning (ML) should be applied directly to predict the desired properties or be combined explicitly with physically-grounded operations. We present an example of an integrated modeling approach, in which a symmetry-adapted ML model of an effective Hamiltonian is trained to reproduce electronic excitations from a quantum-mechanical calculation. The resulting model can make predictions for molecules that are much larger and more complex than those that it is trained on, and allows for dramatic computational savings by indirectly targeting the outputs of well-converged calculations while using a parameterization corresponding to a minimal atom-centered basis. These results emphasize the merits of intertwining data-driven techniques with physical approximations, improving the transferability and interpretability of ML models without affecting their accuracy and computational efficiency, and providing a blueprint for developing ML-augmented electronic-structure methods.
</details>
<details>
<summary>摘要</summary>
“数据驱动技术在物质计算中越来越广泛应用，问题是何时应用机器学习（ML）直接预测感兴趣的性质，或者与物理基础相结合显式地运算。我们提出一种集成模型方法，其中使用对效 Hamiltoniano的 симметри优化机器学习模型来复制电子激发的量子力学计算结果。得到的模型可以预测大量和复杂的分子，并且可以在很大程度上减少计算成本，因为直接targeting已经 converges的计算结果，使用一个对应于最小原子基的参数。这些结果强调了将数据驱动技术与物理方法相结合的优势，提高机器学习模型的传输性和解释性，不影响它们的准确性和计算效率，并为开发机器学习增强电子结构方法提供蓝本。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Sharp-Noisy-Binary-Search-with-Monotonic-Probabilities"><a href="#Sharp-Noisy-Binary-Search-with-Monotonic-Probabilities" class="headerlink" title="Sharp Noisy Binary Search with Monotonic Probabilities"></a>Sharp Noisy Binary Search with Monotonic Probabilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00840">http://arxiv.org/abs/2311.00840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas Gretta, Eric Price</li>
<li>for: 这个论文主要针对的问题是如何使用不同概率的硬币来找到一个目标概率 $\tau$。</li>
<li>methods: 这篇论文使用了 Karp 和 Kleinberg 提出的噪声搜索模型，并将其推广到一个更广泛的情况，在这个情况下，硬币的概率可能是不同的。</li>
<li>results: 这篇论文提出了一个实用的算法，可以在 $\Theta(\frac{1}{\varepsilon^2} \log n)$ 样本中找到目标概率 $\tau$，这是最佳的Bound。此外，论文还解决了两个理论挑战：高概率行为和锐度常数。<details>
<summary>Abstract</summary>
We revisit the noisy binary search model of Karp and Kleinberg, in which we have $n$ coins with unknown probabilities $p_i$ that we can flip. The coins are sorted by increasing $p_i$, and we would like to find where the probability crosses (to within $\varepsilon$) of a target value $\tau$. This generalized the fixed-noise model of Burnashev and Zigangirov , in which $p_i = \frac{1}{2} \pm \varepsilon$, to a setting where coins near the target may be indistinguishable from it. Karp and Kleinberg showed that $\Theta(\frac{1}{\varepsilon^2} \log n)$ samples are necessary and sufficient for this task.   We produce a practical algorithm by solving two theoretical challenges: high-probability behavior and sharp constants. We give an algorithm that succeeds with probability $1-\delta$ from   \[   \frac{1}{C_{\tau, \varepsilon} \cdot \left(\lg n + O(\log^{2/3} n \log^{1/3} \frac{1}{\delta} + \log \frac{1}{\delta})\right)   \]   samples, where $C_{\tau, \varepsilon}$ is the optimal such constant achievable. For $\delta > n^{-o(1)}$ this is within $1 + o(1)$ of optimal, and for $\delta \ll 1$ it is the first bound within constant factors of optimal.
</details>
<details>
<summary>摘要</summary>
我们重访噪音搜寻模型，由karp和kleinberg提出的模型，其中我们有n枚钱币，每枚钱币的概率$p_i$都是未知的。这些钱币按照增加的$p_i$排序，我们想找出这些概率在 target值 $\tau$ 附近的地方。这个问题可以视为burnashev和zigangirov的固定噪音模型的扩展，这个模型中每枚钱币的概率都是 $\frac{1}{2} \pm \varepsilon$。karp和kleinberg表明了 $\Theta\left(\frac{1}{\varepsilon^2} \log n\right)$ 样本是必要和充分的。我们提出了一个实用的算法，解决了两个理论挑战：高概率行为和锐数常数。我们的算法在 $1-\delta$ 的几率下成功，并且需要 $\frac{1}{C_{\tau, \varepsilon} \cdot \left(\lg n + O\left(\log^{2/3} n \log^{1/3} \frac{1}{\delta} + \log \frac{1}{\delta}\right)\right)$ 样本。如果 $\delta > n^{-o(1)}$ ，这个结果在 $1 + o(1)$ 内，而如果 $\delta \ll 1$ ，这个结果是第一个在常数因数内的界限。
</details></li>
</ul>
<hr>
<h2 id="A-quantum-classical-performance-separation-in-nonconvex-optimization"><a href="#A-quantum-classical-performance-separation-in-nonconvex-optimization" class="headerlink" title="A quantum-classical performance separation in nonconvex optimization"></a>A quantum-classical performance separation in nonconvex optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00811">http://arxiv.org/abs/2311.00811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lwins-lights/qhd">https://github.com/lwins-lights/qhd</a></li>
<li>paper_authors: Jiaqi Leng, Yufan Zheng, Xiaodi Wu</li>
<li>for: 这篇论文旨在证明一种非凸连续优化问题家族，每个$d$-维问题有$2^d$个局部最优点，并且用量子算法解决这些问题。</li>
<li>methods: 该论文使用了Quantum Hamiltonian Descent（QHD）算法，该算法可以在$d$-维问题中解决任何问题，需要 $\widetilde{\mathcal{O}(d^3)$量子函数值访问和 $\widetilde{\mathcal{O}(d^4)$个1-qubit和2-qubit元素量子门。</li>
<li>results: 对比 represntative的类别优化算法&#x2F;解决方案（包括Gurobi），量子算法能够在超polynomial时间内解决这些优化问题，而类别优化算法则需要超polynomial时间。<details>
<summary>Abstract</summary>
In this paper, we identify a family of nonconvex continuous optimization instances, each $d$-dimensional instance with $2^d$ local minima, to demonstrate a quantum-classical performance separation. Specifically, we prove that the recently proposed Quantum Hamiltonian Descent (QHD) algorithm [Leng et al., arXiv:2303.01471] is able to solve any $d$-dimensional instance from this family using $\widetilde{\mathcal{O}(d^3)$ quantum queries to the function value and $\widetilde{\mathcal{O}(d^4)$ additional 1-qubit and 2-qubit elementary quantum gates. On the other side, a comprehensive empirical study suggests that representative state-of-the-art classical optimization algorithms/solvers (including Gurobi) would require a super-polynomial time to solve such optimization instances.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们确定了一个家族非凸连续优化问题，每个 $d$-维问题有 $2^d$ 的本地最优点。我们证明了最近提出的量子汉密顿下降（QHD）算法 [Leng et al., arXiv:2303.01471] 能够解决任何 $d$-维问题。具体来说，QHD 算法需要 $\widetilde{\mathcal{O}(d^3)$ 量子查询函数值和 $\widetilde{\mathcal{O}(d^4)$ additional 1-qubit 和 2-qubit 元素量子门。而在另一个方面，一项大规模实验表明，代表性的现代类比优化算法/解决方案（包括 Gurobi）会在解决这些优化问题上需要超多项时间。
</details></li>
</ul>
<hr>
<h2 id="Mahalanobis-Aware-Training-for-Out-of-Distribution-Detection"><a href="#Mahalanobis-Aware-Training-for-Out-of-Distribution-Detection" class="headerlink" title="Mahalanobis-Aware Training for Out-of-Distribution Detection"></a>Mahalanobis-Aware Training for Out-of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00808">http://arxiv.org/abs/2311.00808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Connor Mclaughlin, Jason Matterer, Michael Yee</li>
<li>for: 这份研究是为了提高深度学习模型在开放世界中的适用性，特别是检测异常或非标准样本需要人类干预。</li>
<li>methods: 本研究使用了一个新的损失函数和调理方法，以增强网络的分布基于的异常检测能力。</li>
<li>results: 在CIFAR-10上，本研究获得了明显改善的false positive rate的结果，尤其是在距离OOD标的任务上降低了50%以上。<details>
<summary>Abstract</summary>
While deep learning models have seen widespread success in controlled environments, there are still barriers to their adoption in open-world settings. One critical task for safe deployment is the detection of anomalous or out-of-distribution samples that may require human intervention. In this work, we present a novel loss function and recipe for training networks with improved density-based out-of-distribution sensitivity. We demonstrate the effectiveness of our method on CIFAR-10, notably reducing the false-positive rate of the relative Mahalanobis distance method on far-OOD tasks by over 50%.
</details>
<details>
<summary>摘要</summary>
深度学习模型在控制环境中已经取得了广泛的成功，但在开放世界上仍存在采用障碍物。一个重要的任务是检测异常或非标量样本，以便人工干预。在这项工作中，我们提出了一种新的损失函数和训练方法，可以提高网络对非标量敏感性。我们在CIFAR-10上进行了实验，并证明我们的方法可以在远程OOD任务中降低相对马哈拉诺比距离方法的假阳性率高于50%。
</details></li>
</ul>
<hr>
<h2 id="Neural-Field-Dynamics-Model-for-Granular-Object-Piles-Manipulation"><a href="#Neural-Field-Dynamics-Model-for-Granular-Object-Piles-Manipulation" class="headerlink" title="Neural Field Dynamics Model for Granular Object Piles Manipulation"></a>Neural Field Dynamics Model for Granular Object Piles Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00802">http://arxiv.org/abs/2311.00802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shangjie Xue, Shuo Cheng, Pujith Kachana, Danfei Xu</li>
<li>for:  Granular material manipulation</li>
<li>methods:  Fully convolutional neural network (FCNN) with density field-based representation and translation equivariance, differentiable action rendering module</li>
<li>results:  Exceeds existing latent or particle-based methods in accuracy and computation efficiency, demonstrates zero-shot generalization capabilities in various environments and tasks.<details>
<summary>Abstract</summary>
We present a learning-based dynamics model for granular material manipulation. Inspired by the Eulerian approach commonly used in fluid dynamics, our method adopts a fully convolutional neural network that operates on a density field-based representation of object piles and pushers, allowing it to exploit the spatial locality of inter-object interactions as well as the translation equivariance through convolution operations. Furthermore, our differentiable action rendering module makes the model fully differentiable and can be directly integrated with a gradient-based trajectory optimization algorithm. We evaluate our model with a wide array of piles manipulation tasks both in simulation and real-world experiments and demonstrate that it significantly exceeds existing latent or particle-based methods in both accuracy and computation efficiency, and exhibits zero-shot generalization capabilities across various environments and tasks.
</details>
<details>
<summary>摘要</summary>
我们提出了一种学习基于的动力学模型，用于粒子材料处理。 Drawing inspiration from fluid dynamics的Eulerian方法，我们的方法使用了一个完全卷积神经网络，该网络在基于物体堆和推进器的浓度场表示上进行操作，以利用物体之间的空间地区性和翻译同构性。此外，我们的可 diferenciable action rendering模块使得模型成为可导数的，可以直接与梯度基本的轨迹优化算法集成。我们在模拟和实际实验中对堆物处理任务进行了广泛的评估，并证明了我们的模型在精度和计算效率两个方面明显超过了现有的隐藏或 particulate 方法，并且在不同环境和任务上显示出零拟合能力。
</details></li>
</ul>
<hr>
<h2 id="GIST-Generated-Inputs-Sets-Transferability-in-Deep-Learning"><a href="#GIST-Generated-Inputs-Sets-Transferability-in-Deep-Learning" class="headerlink" title="GIST: Generated Inputs Sets Transferability in Deep Learning"></a>GIST: Generated Inputs Sets Transferability in Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00801">http://arxiv.org/abs/2311.00801</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/flowss/gist">https://github.com/flowss/gist</a></li>
<li>paper_authors: Florian Tambon, Foutse Khomh, Giuliano Antoniol</li>
<li>for: 这篇论文是为了提高神经网络的验证和测试效率而开发的新方法。</li>
<li>methods: 这篇论文使用了生成式输入集（Generated Inputs Sets Transferability，GIST）来快速将测试集转移到新的模型下，并选择符合运算目标的测试集。</li>
<li>results: 实验结果显示，GIST可以将测试集转移到新的模型下，并且可以选择符合运算目标的测试集。这显示GIST可以帮助将测试集转移到不同的模型和测试集生成程序中。<details>
<summary>Abstract</summary>
As the demand for verifiability and testability of neural networks continues to rise, an increasing number of methods for generating test sets are being developed. However, each of these techniques tends to emphasize specific testing aspects and can be quite time-consuming. A straightforward solution to mitigate this issue is to transfer test sets between some benchmarked models and a new model under test, based on a desirable property one wishes to transfer. This paper introduces GIST (Generated Inputs Sets Transferability), a novel approach for the efficient transfer of test sets among Deep Learning models. Given a property of interest that a user wishes to transfer (e.g., coverage criterion), GIST enables the selection of good test sets from the point of view of this property among available ones from a benchmark. We empirically evaluate GIST on fault types coverage property with two modalities and different test set generation procedures to demonstrate the approach's feasibility. Experimental results show that GIST can select an effective test set for the given property to transfer it to the model under test. Our results suggest that GIST could be applied to transfer other properties and could generalize to different test sets' generation procedures and modalities
</details>
<details>
<summary>摘要</summary>
随着神经网络的验证性和测试性需求不断增长，开发测试集的方法也在不断增加。然而，每种测试集生成技术都强调特定的测试方面，可能占用很多时间。为了解决这个问题，我们提出了一种简单的解决方案：通过将 benchmarked 模型中的测试集转移到新的模型下，基于您想要传输的性能来选择好的测试集。这篇论文介绍了 GIST（生成输入集传输性），一种新的深度学习模型测试集传输方法。给定一个您想要传输的性能（例如，覆盖标准），GIST 可以在可用的测试集中选择符合这个性能的好测试集，并将其传输到模型下。我们在不同的检测类型和测试集生成过程中对 GIST 进行了实验评估。实验结果表明，GIST 可以选择一个有效的测试集，以便将其传输到模型下。我们的结果表明，GIST 可以应用于传输其他性能，并且可以扩展到不同的测试集生成过程和模式。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Electronic-Stopping-Power-Predictions-by-10-Million-Times-with-a-Combination-of-Time-Dependent-Density-Functional-Theory-and-Machine-Learning"><a href="#Accelerating-Electronic-Stopping-Power-Predictions-by-10-Million-Times-with-a-Combination-of-Time-Dependent-Density-Functional-Theory-and-Machine-Learning" class="headerlink" title="Accelerating Electronic Stopping Power Predictions by 10 Million Times with a Combination of Time-Dependent Density Functional Theory and Machine Learning"></a>Accelerating Electronic Stopping Power Predictions by 10 Million Times with a Combination of Time-Dependent Density Functional Theory and Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00787">http://arxiv.org/abs/2311.00787</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/globus-labs/stopping-power-ml">https://github.com/globus-labs/stopping-power-ml</a></li>
<li>paper_authors: Logan Ward, Ben Blaiszik, Cheng-Wei Lee, Troy Martin, Ian Foster, André Schleife</li>
<li>for: 设计核 реактор、医疗治疗、半导体和量子材料等技术</li>
<li>methods: 组合时间依赖函数理论和机器学习方法，减少评估新材料的时间，并提供了关于材料细节如何影响电子停止的有价值数据</li>
<li>results: 在铝中的贫子辐射中实现了电子停止的首先原理计算，并通过机器学习 interpolate 到其他方向，提高了评估新材料的速度，并预测了入射角影响“布拉格峰”的深度变化。<details>
<summary>Abstract</summary>
Knowing the rate at which particle radiation releases energy in a material, the stopping power, is key to designing nuclear reactors, medical treatments, semiconductor and quantum materials, and many other technologies. While the nuclear contribution to stopping power, i.e., elastic scattering between atoms, is well understood in the literature, the route for gathering data on the electronic contribution has for decades remained costly and reliant on many simplifying assumptions, including that materials are isotropic. We establish a method that combines time-dependent density functional theory (TDDFT) and machine learning to reduce the time to assess new materials to mere hours on a supercomputer and provides valuable data on how atomic details influence electronic stopping. Our approach uses TDDFT to compute the electronic stopping contributions to stopping power from first principles in several directions and then machine learning to interpolate to other directions at rates 10 million times higher. We demonstrate the combined approach in a study of proton irradiation in aluminum and employ it to predict how the depth of maximum energy deposition, the "Bragg Peak," varies depending on incident angle -- a quantity otherwise inaccessible to modelers. The lack of any experimental information requirement makes our method applicable to most materials, and its speed makes it a prime candidate for enabling quantum-to-continuum models of radiation damage. The prospect of reusing valuable TDDFT data for training the model make our approach appealing for applications in the age of materials data science.
</details>
<details>
<summary>摘要</summary>
知道物质辐射中粒子的能量释放率，即停挡力，对设计核反应堆、医疗治疗、半导体和量子材料等技术非常重要。虽然核心在材料中的辐射贡献已经在文献中很好地理解，但是获取电子贡献的数据一直被视为成本高、依赖于简化假设的问题。我们提出了一种方法，它结合时间相关函数理论（TDDFT）和机器学习，可以在超级计算机上减少评估新材料的时间到只需几个小时，并提供了有价值的数据，以及材料细节如何影响电子停挡。我们的方法使用TDDFT计算电子停挡贡献的数据，从 primera principios  Compute 在多个方向上，然后使用机器学习进行 interpolate 到其他方向。我们在钴离子辐射中的铝 studied 并使用它来预测入射角度对最大能量储存深度的影响，这个量抑制器  otherwise 不可能通过模型来模拟。我们的方法不需要任何实验性数据，因此适用于大多数材料，而且它的速度使其成为量子至连续模型的辐射损害的优秀选择。此外，可以 reuse 值得TDDFT数据来训练模型，使我们的方法更有吸引力。
</details></li>
</ul>
<hr>
<h2 id="Harnessing-machine-learning-for-accurate-treatment-of-overlapping-opacity-species-in-GCMs"><a href="#Harnessing-machine-learning-for-accurate-treatment-of-overlapping-opacity-species-in-GCMs" class="headerlink" title="Harnessing machine learning for accurate treatment of overlapping opacity species in GCMs"></a>Harnessing machine learning for accurate treatment of overlapping opacity species in GCMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00775">http://arxiv.org/abs/2311.00775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aaron David Schneider, Paul Mollière, Gilles Louppe, Ludmila Carone, Uffe Gråe Jørgensen, Leen Decin, Christiane Helling<br>for: 这个研究旨在帮助我们更好地理解外星 planet 和棕矮星的高精度观测结果，特别是通过详细的通流模型（GCM）来模拟化学和辐射的交互作用。methods: 这个研究使用了各种混合方法，包括深度学习（DeepSets，DS）、自适应等效抑制（AEE）和随机重叠与重新排序（RORR）等方法，以混合不同化学种类的Opacity的相关k表。results: 研究发现，DS方法在GCM中具有高度准确和高效的特点，而RORR方法则太慢了。此外，AEE方法的准确性取决于其特定的实现方式，并可能会在实现辐射传输解的过程中引入数值问题。最后，通过模拟降水 TiO 和 VO 的情况，我们证明了降水会阻碍大气层的形成。<details>
<summary>Abstract</summary>
To understand high precision observations of exoplanets and brown dwarfs, we need detailed and complex general circulation models (GCMs) that incorporate hydrodynamics, chemistry, and radiation. In this study, we specifically examine the coupling between chemistry and radiation in GCMs and compare different methods for mixing opacities of different chemical species in the correlated-k assumption, when equilibrium chemistry cannot be assumed. We propose a fast machine learning method based on DeepSets (DS), which effectively combines individual correlated-k opacities (k-tables). We evaluate the DS method alongside other published methods like adaptive equivalent extinction (AEE) and random overlap with rebinning and resorting (RORR). We integrate these mixing methods into our GCM (expeRT/MITgcm) and assess their accuracy and performance for the example of the hot Jupiter HD~209458 b. Our findings indicate that the DS method is both accurate and efficient for GCM usage, whereas RORR is too slow. Additionally, we observe that the accuracy of AEE depends on its specific implementation and may introduce numerical issues in achieving radiative transfer solution convergence. We then apply the DS mixing method in a simplified chemical disequilibrium situation, where we model the rainout of TiO and VO, and confirm that the rainout of TiO and VO would hinder the formation of a stratosphere. To further expedite the development of consistent disequilibrium chemistry calculations in GCMs, we provide documentation and code for coupling the DS mixing method with correlated-k radiative transfer solvers. The DS method has been extensively tested to be accurate enough for GCMs, however, other methods might be needed for accelerating atmospheric retrievals.
</details>
<details>
<summary>摘要</summary>
要更好地理解外星 planet 和棕矮星的高精度观测结果，我们需要详细、复杂的通流模型（GCM），这些模型包括 гидро动力学、化学和辐射。在这个研究中，我们专门研究 GCM 中化学和辐射的关系，并比较不同的混合方法。我们提出了一种基于 DeepSets（DS）的快速机器学习方法，可以有效地结合不同化学种类的 opacity 值。我们评估了 DS 方法 alongside 其他已发表的方法，如适应性等抵抗（AEE）和随机 overlap with rebinning and resorting（RORR）。我们将这些混合方法 integrate 到我们的 GCM（expeRT/MITgcm）中，并评估它们在 HD~209458 b 的示例中的准确性和性能。我们发现 DS 方法在 GCM 中具有高准确性和高效率，而 RORR 方法过于慢。此外，我们发现 AEE 方法的准确性取决于具体的实现方式，可能会在实现辐射传输解的过程中引入数值问题。我们然后使用 DS 混合方法在简化化的化学不平衡情况下模拟降水 TiO 和 VO，并证实降水 TiO 和 VO 会阻碍大气层的形成。为了更快速地开发一致的不平衡化学计算方法，我们提供了相关的文档和代码。 DS 方法已经在 GCM 中得到了充分的测试和证明，但可能需要其他方法来加速大气层 retrieval 的发展。
</details></li>
</ul>
<hr>
<h2 id="Conformalized-Deep-Splines-for-Optimal-and-Efficient-Prediction-Sets"><a href="#Conformalized-Deep-Splines-for-Optimal-and-Efficient-Prediction-Sets" class="headerlink" title="Conformalized Deep Splines for Optimal and Efficient Prediction Sets"></a>Conformalized Deep Splines for Optimal and Efficient Prediction Sets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00774">http://arxiv.org/abs/2311.00774</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ndiamant/spice">https://github.com/ndiamant/spice</a></li>
<li>paper_authors: Nathaniel Diamant, Ehsan Hajiramezanali, Tommaso Biancalani, Gabriele Scalia</li>
<li>for: 高飞行机器学习应用中的 uncertainty estimation</li>
<li>methods: 使用神经网络 parameterized splines 进行 conditional density 估计，并提供了两种高效计算 conformal scores</li>
<li>results: 实验结果表明，SPICE-ND 模型可以减少 prediction set 的平均大小，包括某些数据集的减少率达 nearly 50% 相比基eline; SPICE-HPD 模型可以实现最好的 conditional coverage  compared to baselines.<details>
<summary>Abstract</summary>
Uncertainty estimation is critical in high-stakes machine learning applications. One effective way to estimate uncertainty is conformal prediction, which can provide predictive inference with statistical coverage guarantees. We present a new conformal regression method, Spline Prediction Intervals via Conformal Estimation (SPICE), that estimates the conditional density using neural-network-parameterized splines. We prove universal approximation and optimality results for SPICE, which are empirically validated by our experiments. SPICE is compatible with two different efficient-to-compute conformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the other asymptotically optimal for conditional coverage (SPICE-HPD). Results on benchmark datasets demonstrate SPICE-ND models achieve the smallest average prediction set sizes, including average size reductions of nearly 50% for some datasets compared to the next best baseline. SPICE-HPD models achieve the best conditional coverage compared to baselines. The SPICE implementation is made available.
</details>
<details>
<summary>摘要</summary>
高度优先级机器学习应用中的不确定性估计是 kritical。一种有效的不确定性估计方法是尊重预测（Conformal Prediction），它可以提供统计保证的预测推断。我们介绍了一种新的尊重回归方法，即spline预测区间via Conformal Estimation（SPICE），它使用神经网络参数化的spline来估计条件概率分布。我们证明了SPICE的 универсалapproximation和优化结果，并通过实验验证了这些结果。SPICE与两种高效计算的尊重分数相容，一种是对边缘覆盖（SPICE-ND）的oracle-optimal分数，另一种是对条件覆盖（SPICE-HPD）的极限优化分数。实验结果表明SPICE-ND模型在一些数据集上实现了最小的平均预测集大小，包括某些数据集上预测集大小减少了近50%的情况。SPICE-HPD模型在基线上比基eline的条件覆盖更好。SPICE实现 disponible。
</details></li>
</ul>
<hr>
<h2 id="Sorting-with-Predictions"><a href="#Sorting-with-Predictions" class="headerlink" title="Sorting with Predictions"></a>Sorting with Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00749">http://arxiv.org/abs/2311.00749</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xingjian-bai/learning-augmented-sorting">https://github.com/xingjian-bai/learning-augmented-sorting</a></li>
<li>paper_authors: Xingjian Bai, Christian Coester</li>
<li>for: 本研究探讨了排序问题，通过学习增强算法来提高排序效率。</li>
<li>methods: 本文提出了两种不同的设定：在第一个设定中，每个元素都会得到其排序列表中的预测位置；在第二个设定中，我们假设有一种”快速和粗糙”的比较方法，以及一种”慢和准确”的比较方法。两种设定下，我们设计了新的简单算法，只需要$O(\sum_i \log \eta_i)$个 precis comparing，其中 $\eta_i$ 是元素 $i$ 的预测错误。</li>
<li>results: 我们证明了这种比较复杂度是对于考虑的错误度下 theoretically 优化的。实验证明了在排序任务中应用学习增强算法的潜在优势。<details>
<summary>Abstract</summary>
We explore the fundamental problem of sorting through the lens of learning-augmented algorithms, where algorithms can leverage possibly erroneous predictions to improve their efficiency. We consider two different settings: In the first setting, each item is provided a prediction of its position in the sorted list. In the second setting, we assume there is a "quick-and-dirty" way of comparing items, in addition to slow-and-exact comparisons. For both settings, we design new and simple algorithms using only $O(\sum_i \log \eta_i)$ exact comparisons, where $\eta_i$ is a suitably defined prediction error for the $i$th element. In particular, as the quality of predictions deteriorates, the number of comparisons degrades smoothly from $O(n)$ to $O(n\log n)$. We prove that the comparison complexity is theoretically optimal with respect to the examined error measures. An experimental evaluation against existing adaptive and non-adaptive sorting algorithms demonstrates the potential of applying learning-augmented algorithms in sorting tasks.
</details>
<details>
<summary>摘要</summary>
我们通过学习加强算法的视角探讨排序问题的基本问题，其中算法可以利用可能存在误差的预测来提高其效率。我们考虑了两种不同的设置：在第一个设置中，每个项目都被提供一个排序列表中的预测位置。在第二个设置中，我们假设存在一种“快速和粗糙”的比较方法，并且与慢速和精确的比较方法相加。对于两种设置，我们设计了新的简单算法，只需要$O(\sum_i \log \eta_i)$ 的确定比较次数，其中 $\eta_i$ 是元素 $i$ 的预测误差。特别是，预测质量逐渐下降时，比较次数会逐渐下降从 $O(n)$ 到 $O(n\log n)$。我们证明了比较复杂度是对于考虑的误差度量来说 theoretically 最优的。实验评估了现有的适应式和非适应式排序算法，示出了应用学习加强算法在排序任务中的潜在优势。
</details></li>
</ul>
<hr>
<h2 id="Decision-Support-Framework-for-Home-Health-Caregiver-Allocation-A-Case-Study-of-HHC-Agency-in-Tennessee-USA"><a href="#Decision-Support-Framework-for-Home-Health-Caregiver-Allocation-A-Case-Study-of-HHC-Agency-in-Tennessee-USA" class="headerlink" title="Decision Support Framework for Home Health Caregiver Allocation: A Case Study of HHC Agency in Tennessee, USA"></a>Decision Support Framework for Home Health Caregiver Allocation: A Case Study of HHC Agency in Tennessee, USA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00696">http://arxiv.org/abs/2311.00696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyed Mohammad Ebrahim Sharifnia, Faezeh Bagheri, Rupy Sawhney, John E. Kobza, Enrique Macias De Anda, Mostafa Hajiaghaei-Keshteli, Michael Mirrielees</li>
<li>for: 这个研究的目的是优化家庭健康照顾（HHC）的资源分配，以满足老年人口的增长需求，并确保提供高质量的照顾服务。</li>
<li>methods: 本研究提出了一个决策支持框架，使用融合方法考虑家庭健康照顾者的访问顺序弹性，并企图降低旅行里程、增加每个观察期间的访问次数，并保持照顾的连续性 - 这是关键的顾客满意度指标。</li>
<li>results: 使用田索美洲洲 Tennessee 的家庭健康照顾机构数据，本研究的方法实现了优化旅行里程的目的，并获得了优化旅行里程（最多达42%）和增加每个观察期间的访问次数，而不需要对家庭健康照顾者实施限制。此外，提出的框架还用于评估照顾者资源的分配，提供宝贵的照顾资源管理意见。<details>
<summary>Abstract</summary>
Population aging is a global challenge, leading to increased demand for healthcare and social services for the elderly. Home Health Care (HHC) emerges as a vital solution, specifically designed to serve this population segment. Given the surging demand for HHC, it's essential to coordinate and regulate caregiver allocation efficiently. This is crucial for both budget-optimized planning and ensuring the delivery of high-quality care. This research addresses a key question faced by home health agencies (HHAs): "How can caregiver allocation be optimized, especially when caregivers prefer flexibility in their visiting sequences?". While earlier studies proposed rigid visiting sequences, our study introduces a decision support framework that allocates caregivers through a hybrid method that considers the flexibility in visiting sequences and aims to reduce travel mileage, increase the number of visits per planning period, and maintain the continuity of care - a critical metric for patient satisfaction. Utilizing data from an HHA in Tennessee, United States, our approach led to an impressive reduction in average travel mileage (up to 42% depending on discipline) without imposing restrictions on caregivers. Furthermore, the proposed framework is used for caregivers' supply analysis to provide valuable insights into caregiver resource management.
</details>
<details>
<summary>摘要</summary>
全球人口老龄化是一个挑战，导致医疗和社会服务需求增加。家庭健康照顾（HHC）成为一种重要的解决方案，特意设计来服务这个人口段。随着护理需求的增加，有效协调和规范护理人员分配变得非常重要。这是为了保证优质护理的提供，同时也是为了降低成本。本研究面临的问题是：“护理人员分配如何优化，特别是当护理人员喜欢灵活的访问顺序呢？”EARLIER STUDIES提出了固定的访问顺序，但我们的研究推出了一个决策支持框架，该框架通过考虑灵活的访问顺序，以减少旅行里程、增加每个规划期的访问次数，并保持护理连续性——一个关键的满意度指标。使用了一家美国田纳西州的家庭健康照顾机构的数据，我们的方法实现了减少平均旅行里程（最多42%），而不是强制限制护理人员的行为。此外，我们的提案的框架还用于护理人员供应分析，为护理资源管理提供有价值的洞察。
</details></li>
</ul>
<hr>
<h2 id="Software-Repositories-and-Machine-Learning-Research-in-Cyber-Security"><a href="#Software-Repositories-and-Machine-Learning-Research-in-Cyber-Security" class="headerlink" title="Software Repositories and Machine Learning Research in Cyber Security"></a>Software Repositories and Machine Learning Research in Cyber Security</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00691">http://arxiv.org/abs/2311.00691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mounika Vanamala, Keith Bryant, Alex Caravella</li>
<li>For: 本研究旨在提高软件开发过程中早期阶段的漏洞检测，通过利用cyber安全存储库如MITRE的CAPEC和CVE数据库，并采用主题模型和机器学习技术，检测软件需求阶段的漏洞。* Methods: 本研究使用了不同的机器学习方法，包括LDA、主题模型、SVM、Na&quot;ive Bayes、随机森林和神经网络，以及深度学习，以寻找软件需求阶段的漏洞。* Results: 研究表明，采用机器学习技术可以提高软件开发过程中早期阶段的漏洞检测，并且可以在不同的软件开发enario下提供关键的助け手，帮助开发者开发更加安全的软件。<details>
<summary>Abstract</summary>
In today's rapidly evolving technological landscape and advanced software development, the rise in cyber security attacks has become a pressing concern. The integration of robust cyber security defenses has become essential across all phases of software development. It holds particular significance in identifying critical cyber security vulnerabilities at the initial stages of the software development life cycle, notably during the requirement phase. Through the utilization of cyber security repositories like The Common Attack Pattern Enumeration and Classification (CAPEC) from MITRE and the Common Vulnerabilities and Exposures (CVE) databases, attempts have been made to leverage topic modeling and machine learning for the detection of these early-stage vulnerabilities in the software requirements process. Past research themes have returned successful outcomes in attempting to automate vulnerability identification for software developers, employing a mixture of unsupervised machine learning methodologies such as LDA and topic modeling. Looking ahead, in our pursuit to improve automation and establish connections between software requirements and vulnerabilities, our strategy entails adopting a variety of supervised machine learning techniques. This array encompasses Support Vector Machines (SVM), Na\"ive Bayes, random forest, neural networking and eventually transitioning into deep learning for our investigation. In the face of the escalating complexity of cyber security, the question of whether machine learning can enhance the identification of vulnerabilities in diverse software development scenarios is a paramount consideration, offering crucial assistance to software developers in developing secure software.
</details>
<details>
<summary>摘要</summary>
今天的技术发展和软件开发在加速，网络安全攻击的升级成为了严重的担忧。在软件开发生命周期的所有阶段中，集成强大的网络安全防御变得非常重要。特别是在软件开发需求阶段，早期发现网络安全漏洞变得非常重要。通过利用MITRE提供的Common Attack Pattern Enumeration and Classification（CAPEC）和Common Vulnerabilities and Exposures（CVE）数据库，尝试使用主题模型和机器学习自动检测早期网络安全漏洞。过去的研究主题已经取得了成功的结果，通过杂交不监督机器学习方法，如Latent Dirichlet Allocation（LDA）和主题模型，自动检测漏洞。在前进的探索中，我们将采取多种监督机器学习技术，包括支持向量机（SVM）、愚见树（Na\"ive Bayes）、Random Forest、神经网络和最终过渡到深度学习。面对网络安全的加速升级，机器学习是否能够提高早期网络安全漏洞的检测，成为了 paramount 的考虑，为软件开发者提供关键的帮助，以开发安全的软件。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Classification-of-Gamma-Photon-Interactions-in-Room-Temperature-Semiconductor-Radiation-Detectors"><a href="#Deep-Learning-Based-Classification-of-Gamma-Photon-Interactions-in-Room-Temperature-Semiconductor-Radiation-Detectors" class="headerlink" title="Deep Learning-Based Classification of Gamma Photon Interactions in Room-Temperature Semiconductor Radiation Detectors"></a>Deep Learning-Based Classification of Gamma Photon Interactions in Room-Temperature Semiconductor Radiation Detectors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00682">http://arxiv.org/abs/2311.00682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandeep K. Chaudhuri, Qinyang Li, Krishna C. Mandal, Jianjun Hu</li>
<li>for: 这种论文旨在开发一种基于深度学习的核心粒子探测器，以提高医疗成像设备的性能。</li>
<li>methods: 这种探测器使用了半导体材料CdZnTeSe (CZTS)，并利用了深度学习算法CoPhNet来分辨γ&#x2F;X射线粒子的Compton散射和照相电子事件。</li>
<li>results: 研究人员通过使用模拟数据和实验数据进行训练和验证，发现CoPhNet模型可以在CZTS半导体探测器中具有高精度地分辨Compton散射和照相电子事件。此外，模型还能够在不同的操作参数下保持性能稳定。<details>
<summary>Abstract</summary>
Photon counting radiation detectors have become an integral part of medical imaging modalities such as Positron Emission Tomography or Computed Tomography. One of the most promising detectors is the wide bandgap room temperature semiconductor detectors, which depends on the interaction gamma/x-ray photons with the detector material involves Compton scattering which leads to multiple interaction photon events (MIPEs) of a single photon. For semiconductor detectors like CdZnTeSe (CZTS), which have a high overlap of detected energies between Compton and photoelectric events, it is nearly impossible to distinguish between Compton scattered events from photoelectric events using conventional readout electronics or signal processing algorithms. Herein, we report a deep learning classifier CoPhNet that distinguishes between Compton scattering and photoelectric interactions of gamma/x-ray photons with CdZnTeSe (CZTS) semiconductor detectors. Our CoPhNet model was trained using simulated data to resemble actual CZTS detector pulses and validated using both simulated and experimental data. These results demonstrated that our CoPhNet model can achieve high classification accuracy over the simulated test set. It also holds its performance robustness under operating parameter shifts such as Signal-Noise-Ratio (SNR) and incident energy. Our work thus laid solid foundation for developing next-generation high energy gamma-rays detectors for better biomedical imaging.
</details>
<details>
<summary>摘要</summary>
吸收辐射探测器在医疗成像方面扮演着重要角色，如 пози特罗密度 Tomatoes Emission Tomography 或 Computed Tomography。最有前途的探测器是宽带隔材料温度 Semiconductor 探测器，这种探测器通过辐射 photon 与探测器材料的交互，发生 Compton 散射，从而导致多个交互 photon 事件（MIPEs）。例如 CdZnTeSe（CZTS）探测器，它们的探测能谱重叠度很高，因此使用传统的读取电路或信号处理算法来分辨 Compton 散射事件和光电事件是很困难的。在这种情况下，我们提出了一种深度学习分类器 CoPhNet，可以在 CdZnTeSe（CZTS） 探测器上分辨 Compton 散射和光电事件。我们的 CoPhNet 模型通过使用 simulate 数据来模拟实际 CZTS 探测器脉冲，并 validate 使用实验和 simulate 数据。这些结果表明，我们的 CoPhNet 模型可以在 simulate 测试集上 достичь高精度分类。此外，我们的模型还保持了操作参数的变化，如信号噪声比（SNR）和入射能量的稳定性。因此，我们的工作为开发下一代高能γ射线探测器奠定了坚实的基础，以提高生物医疗成像。
</details></li>
</ul>
<hr>
<h2 id="Complexity-of-Single-Loop-Algorithms-for-Nonlinear-Programming-with-Stochastic-Objective-and-Constraints"><a href="#Complexity-of-Single-Loop-Algorithms-for-Nonlinear-Programming-with-Stochastic-Objective-and-Constraints" class="headerlink" title="Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints"></a>Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00678">http://arxiv.org/abs/2311.00678</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmet Alacaoglu, Stephen J. Wright</li>
<li>for: 解决非凸优化问题中的函数等式约束。</li>
<li>methods: 使用单循环二次罚黄和增强拉格朗日精算法。</li>
<li>results: 在三个不同情况下，分别需要 $\widetilde{O}(\varepsilon^{-3})$, $\widetilde{O}(\varepsilon^{-4})$, $\widetilde{O}(\varepsilon^{-5})$的复杂性来找到 $\varepsilon$-近似首项约束的解。这些复杂性都是最佳known的。<details>
<summary>Abstract</summary>
We analyze the complexity of single-loop quadratic penalty and augmented Lagrangian algorithms for solving nonconvex optimization problems with functional equality constraints. We consider three cases, in all of which the objective is stochastic and smooth, that is, an expectation over an unknown distribution that is accessed by sampling. The nature of the equality constraints differs among the three cases: deterministic and linear in the first case, deterministic, smooth and nonlinear in the second case, and stochastic, smooth and nonlinear in the third case. Variance reduction techniques are used to improve the complexity. To find a point that satisfies $\varepsilon$-approximate first-order conditions, we require $\widetilde{O}(\varepsilon^{-3})$ complexity in the first case, $\widetilde{O}(\varepsilon^{-4})$ in the second case, and $\widetilde{O}(\varepsilon^{-5})$ in the third case. For the first and third cases, they are the first algorithms of "single loop" type (that also use $O(1)$ samples at each iteration) that still achieve the best-known complexity guarantees.
</details>
<details>
<summary>摘要</summary>
我们分析单循环二项罚则和增强拉格历预算法来解决非凸似格式化问题。我们考虑三个情况，其中所有问题的目标都是随机且平滑的，即透过抽样取得未知分布的期望值。具体来说，第一个情况中的等价条件是决定性的且线性的，第二个情况中的等价条件是决定性的、平滑的且非线性的，第三个情况中的等价条件是随机的、平滑的且非线性的。我们使用差分reduction技术来改善复杂性。为了找到满足 $\varepsilon$-近似first-order条件的点，我们需要 $\widetilde{O}(\varepsilon^{-3})$ 的复杂性在第一个情况中，$\widetilde{O}(\varepsilon^{-4})$ 的复杂性在第二个情况中，以及 $\widetilde{O}(\varepsilon^{-5})$ 的复杂性在第三个情况中。在第一个和第三个情况中，这些算法是单循环类型的首个Algorithm (也使用 $O(1)$ 抽样在每个迭代中)，它们仍能获得最好的复杂性保证。
</details></li>
</ul>
<hr>
<h2 id="Last-Iterate-Convergence-Properties-of-Regret-Matching-Algorithms-in-Games"><a href="#Last-Iterate-Convergence-Properties-of-Regret-Matching-Algorithms-in-Games" class="headerlink" title="Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games"></a>Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00676">http://arxiv.org/abs/2311.00676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Cai, Gabriele Farina, Julien Grand-Clément, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Weiqiang Zheng</li>
<li>for:  solving large-scale two-player zero-sum games in practice</li>
<li>methods:  regret matching$^+$ (RM$^+$) and its variants</li>
<li>results:  last-iterate convergence properties of various popular variants of RM$^+$Here are the concise summaries in Simplified Chinese text:</li>
<li>for: 解决大规模的两个玩家零点游戏问题</li>
<li>methods:  regret matching$^+$ (RM$^+$) 和其变种</li>
<li>results:  regret matching$^+$ 的最后轮收敛性质的研究<details>
<summary>Abstract</summary>
Algorithms based on regret matching, specifically regret matching$^+$ (RM$^+$), and its variants are the most popular approaches for solving large-scale two-player zero-sum games in practice. Unlike algorithms such as optimistic gradient descent ascent, which have strong last-iterate and ergodic convergence properties for zero-sum games, virtually nothing is known about the last-iterate properties of regret-matching algorithms. Given the importance of last-iterate convergence for numerical optimization reasons and relevance as modeling real-word learning in games, in this paper, we study the last-iterate convergence properties of various popular variants of RM$^+$. First, we show numerically that several practical variants such as simultaneous RM$^+$, alternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate convergence guarantees even on a simple $3\times 3$ game. We then prove that recent variants of these algorithms based on a smoothing technique do enjoy last-iterate convergence: we prove that extragradient RM$^{+}$ and smooth Predictive RM$^+$ enjoy asymptotic last-iterate convergence (without a rate) and $1/\sqrt{t}$ best-iterate convergence. Finally, we introduce restarted variants of these algorithms, and show that they enjoy linear-rate last-iterate convergence.
</details>
<details>
<summary>摘要</summary>
算法基于后悔匹配，特别是后悔匹配$^+$（RM$^+）和其变体，在实务中是解决大规模两者零余游戏的最受欢迎方法。不同于如优化 Gradient Descent 的算法，它们在零余游戏中有强烈的最后迭代和均匀收敛性 properties，但是关于 regret-matching 算法的最后迭代属性几乎没有知识。为了解决这个问题，在这篇论文中，我们研究 regret-matching 算法的最后迭代属性。首先，我们通过实验发现了几个实际的variant，例如同步 RM$^+$, 交替 RM$^+$, 和同步预测 RM$^+$，都没有最后迭代 convergence guarantees，甚至在一个简单的 $3\times 3$ 游戏中。然后，我们证明了这些算法的新变体，基于抽象技术，具有最后迭代 convergence：我们证明了 extragradient RM$^+$ 和精确预测 RM$^+$ 在无限次迭代下具有 asymptotic last-iterate convergence（无范围）和 $1/\sqrt{t}$ best-iterate convergence。最后，我们引入了重新启动这些算法的变体，并证明它们具有线性率最后迭代 convergence。
</details></li>
</ul>
<hr>
<h2 id="Recovering-Linear-Causal-Models-with-Latent-Variables-via-Cholesky-Factorization-of-Covariance-Matrix"><a href="#Recovering-Linear-Causal-Models-with-Latent-Variables-via-Cholesky-Factorization-of-Covariance-Matrix" class="headerlink" title="Recovering Linear Causal Models with Latent Variables via Cholesky Factorization of Covariance Matrix"></a>Recovering Linear Causal Models with Latent Variables via Cholesky Factorization of Covariance Matrix</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00674">http://arxiv.org/abs/2311.00674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunfeng Cai, Xu Li, Minging Sun, Ping Li</li>
<li>for: 本研究旨在提出一种基于Cholesky分解的DAG结构回归算法，用于解决包含隐变量的combinaatorial问题。</li>
<li>methods: 该算法基于对观察数据的协方差矩阵进行Cholesky分解，具有快速和容易实现的特点，并且有理论保证精确回归。</li>
<li>results: 在 sintetic和实际数据上，该算法比前方法快速得多，并在状态艺术表现上达到了顶峰性。在等误差假设下，我们还提出了一种优化过程，用于处理含隐变量的DAG回归问题，并在数值仿真中显示其效果。<details>
<summary>Abstract</summary>
Discovering the causal relationship via recovering the directed acyclic graph (DAG) structure from the observed data is a well-known challenging combinatorial problem. When there are latent variables, the problem becomes even more difficult. In this paper, we first propose a DAG structure recovering algorithm, which is based on the Cholesky factorization of the covariance matrix of the observed data. The algorithm is fast and easy to implement and has theoretical grantees for exact recovery. On synthetic and real-world datasets, the algorithm is significantly faster than previous methods and achieves the state-of-the-art performance. Furthermore, under the equal error variances assumption, we incorporate an optimization procedure into the Cholesky factorization based algorithm to handle the DAG recovering problem with latent variables. Numerical simulations show that the modified "Cholesky + optimization" algorithm is able to recover the ground truth graph in most cases and outperforms existing algorithms.
</details>
<details>
<summary>摘要</summary>
发现 causal 关系via  recovering  directed acyclic graph (DAG) 结构从观察数据是一个常见的 combinatorial 问题。当存在潜在变量时，问题变得更加困难。在这篇论文中，我们首先提出了 DAG 结构回归算法，基于观察数据的协方差矩阵的 Cholesky 分解。该算法快速易于实现，并有理论保证对数据进行正确回归。在synthetic和实际数据集上，该算法比前方法更快速，并达到了领域内最佳性能。进一步，在等误差假设下，我们将 Cholesky 基于算法与优化过程结合，以处理含潜在变量的 DAG 回归问题。numerical simulations 表明，修改后的 "Cholesky + 优化" 算法能够回归真实图形，并在大多数情况下高于现有算法。
</details></li>
</ul>
<hr>
<h2 id="Latent-Space-Translation-via-Semantic-Alignment"><a href="#Latent-Space-Translation-via-Semantic-Alignment" class="headerlink" title="Latent Space Translation via Semantic Alignment"></a>Latent Space Translation via Semantic Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00664">http://arxiv.org/abs/2311.00664</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/flegyas/latent-translation">https://github.com/flegyas/latent-translation</a></li>
<li>paper_authors: Valentino Maiorca, Luca Moschella, Antonio Norelli, Marco Fumero, Francesco Locatello, Emanuele Rodolà</li>
<li>for: 本研究旨在更好地理解神经网络模型间的内在相似性，以及如何将这些模型的表示转换到不同预训练的网络中。</li>
<li>methods: 本研究使用了标准的代数方法来直接估算表示之间的转换，而不需要额外训练。</li>
<li>results: 研究发现，可以使用这种转换方法来协调神经网络模型的编码器和解码器，并在不同的训练、领域、架构和下游任务中进行有效的适应。此外，研究还发现可以使用零shot学习来协调文本编码器和视觉解码器，即使这两个模型在训练和测试数据上没有共同学习。<details>
<summary>Abstract</summary>
While different neural models often exhibit latent spaces that are alike when exposed to semantically related data, this intrinsic similarity is not always immediately discernible. Towards a better understanding of this phenomenon, our work shows how representations learned from these neural modules can be translated between different pre-trained networks via simpler transformations than previously thought. An advantage of this approach is the ability to estimate these transformations using standard, well-understood algebraic procedures that have closed-form solutions. Our method directly estimates a transformation between two given latent spaces, thereby enabling effective stitching of encoders and decoders without additional training. We extensively validate the adaptability of this translation procedure in different experimental settings: across various trainings, domains, architectures (e.g., ResNet, CNN, ViT), and in multiple downstream tasks (classification, reconstruction). Notably, we show how it is possible to zero-shot stitch text encoders and vision decoders, or vice-versa, yielding surprisingly good classification performance in this multimodal setting.
</details>
<details>
<summary>摘要</summary>
不同神经网络经常表现出 semantic 相似的幽默空间，但这种内在相似性并不总是明显可见。为了更好地理解这种现象，我们的工作表明了如何通过简单的变换来跨越不同预训练的神经网络中的表示。我们的方法直接估算了两个给定的幽默空间之间的转换，从而实现了不需要额外训练的卷积Encoder和Decoder的团合。我们广泛验证了这种翻译过程的适应性，包括不同的训练数据、领域、架构（例如 ResNet、CNN、ViT）以及多个下游任务（分类、重建）。尤其是，我们示出了可以零shot卷积文本Encoder和视觉Decoder，或者vice versa，即使没有额外训练，也可以获得良好的分类性能在多模态 setting。
</details></li>
</ul>
<hr>
<h2 id="Online-Signal-Estimation-on-the-Graph-Edges-via-Line-Graph-Transformation"><a href="#Online-Signal-Estimation-on-the-Graph-Edges-via-Line-Graph-Transformation" class="headerlink" title="Online Signal Estimation on the Graph Edges via Line Graph Transformation"></a>Online Signal Estimation on the Graph Edges via Line Graph Transformation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00656">http://arxiv.org/abs/2311.00656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Yan, Ercan Engin Kuruoglu</li>
<li>for: 该论文提出了一种基于Line Graph Normalized Least Mean Square（LGNLMS）算法的在线时变图边信号预测方法。</li>
<li>methods: 该算法使用Line Graph将图边信号转换为图边的 dual 点的节点信号，以便使用已有的GSP概念进行处理，无需重新定义图边上的信号。</li>
<li>results: 该方法可以准确地预测图边信号，并且可以在线实时进行预测。<details>
<summary>Abstract</summary>
We propose the Line Graph Normalized Least Mean Square (LGNLMS) algorithm for online time-varying graph edge signals prediction. LGNLMS utilizes the Line Graph to transform graph edge signals into the node of its edge-to-vertex dual. This enables edge signals to be processed using established GSP concepts without redefining them on graph edges.
</details>
<details>
<summary>摘要</summary>
我们提出了线 graphs 正规化最小方差方法（LGNLMS）来线上时间变化的图Edge信号预测。LGNLMS利用线图来转换图Edge信号到它的edge-to-vertex dual中的node。这使得图Edge信号可以使用已经定义的GSP概念进行处理，而不需要在图Edge上重新定义它们。
</details></li>
</ul>
<hr>
<h2 id="Kronecker-Factored-Approximate-Curvature-for-Modern-Neural-Network-Architectures"><a href="#Kronecker-Factored-Approximate-Curvature-for-Modern-Neural-Network-Architectures" class="headerlink" title="Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures"></a>Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00636">http://arxiv.org/abs/2311.00636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runa Eschenhagen, Alexander Immer, Richard E. Turner, Frank Schneider, Philipp Hennig</li>
<li>for: 本研究旨在应用 Kronecker-Factored Approximate Curvature (K-FAC) 优化方法到现代神经网络架构中，以提高神经网络训练速度并降低计算成本。</li>
<li>methods: 本研究使用了两种不同的线性weight-sharing层设置，即 expand 和 reduce，以适应不同的神经网络架构。并使用了 K-FAC 优化方法来优化神经网络的自动 Hyperparameter 选择。</li>
<li>results: 研究发现，使用 K-FAC 优化方法可以快速地训练神经网络，并且可以在 $50$-$75%$ 的步数上达到相同的VALIDATION 度量目标。此外，两种不同的 K-FAC 变种在训练图 neural network 和视Transformer 中也具有类似的性能。<details>
<summary>Abstract</summary>
The core components of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with $\textit{weight-sharing}$. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimisation method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavours of K-FAC -- $\textit{expand}$ and $\textit{reduce}$. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimising the marginal likelihood for a Wide ResNet. Finally, we observe little difference between these two K-FAC variations when using them to train both a graph neural network and a vision transformer. However, both variations are able to reach a fixed validation metric target in $50$-$75\%$ of the number of steps of a first-order reference run, which translates into a comparable improvement in wall-clock time. This highlights the potential of applying K-FAC to modern neural network architectures.
</details>
<details>
<summary>摘要</summary>
Modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with weight-sharing. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimization method, has shown promise in speeding up neural network training and reducing computational costs. However, there is currently no framework to apply it to generic architectures, specifically those with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers that motivate two flavors of K-FAC - expand and reduce. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimizing the marginal likelihood for a Wide ResNet. Finally, we observe little difference between these two K-FAC variations when using them to train both a graph neural network and a vision transformer. However, both variations are able to reach a fixed validation metric target in 50-75% of the number of steps of a first-order reference run, which translates into a comparable improvement in wall-clock time. This highlights the potential of applying K-FAC to modern neural network architectures.Here's the text with the Chinese characters:现代神经网络架构，如 transformers、卷积 neural network 或 graph neural network，可以表示为线性层的 linear layers with weight-sharing。Kronecker-Factored Approximate Curvature (K-FAC)，一种二阶优化方法，已经示出了减少神经网络训练时间的损益。然而，目前没有一个框架来应用它们到通用架构，尤其是 Linear weight-sharing 层。在这项工作中，我们确定了 linear weight-sharing 层的两种不同设置，它们驱动了 two flavors of K-FAC - expand 和 reduce。我们证明它们是深度线性网络中 weight-sharing 的 exact setting。另外，K-FAC-reduce 通常比 K-FAC-expand 更快，我们利用它来加速自动超参的选择。最后，我们发现使用这两种 K-FAC 变化来训练图 neural network 和视Transformer 时，两者之间没有很大差异。然而，它们都能在首选Reference run 的 $50$-$75\%$ 步骤中达到固定的验证指标目标，这意味着它们在wall-clock时间中具有相似的改善。这一点 highlights K-FAC 的潜在应用可能性。
</details></li>
</ul>
<hr>
<h2 id="Controllable-Music-Production-with-Diffusion-Models-and-Guidance-Gradients"><a href="#Controllable-Music-Production-with-Diffusion-Models-and-Guidance-Gradients" class="headerlink" title="Controllable Music Production with Diffusion Models and Guidance Gradients"></a>Controllable Music Production with Diffusion Models and Guidance Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00613">http://arxiv.org/abs/2311.00613</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Levy, Bruno Di Giorgi, Floris Weers, Angelos Katharopoulos, Tom Nickson</li>
<li>for: 这个论文旨在使用扩散模型进行音乐生成，解决多种实际任务，包括继续、填充和重新生成44.1kHz顺声音频。</li>
<li>methods: 这个论文使用 sampling-time 引导的扩散模型进行音乐生成，支持 both reconstruction 和 classification 损失，或任何组合。</li>
<li>results: 这个论文可以生成匹配周围上下文的音乐，或符合类型分布或预训练 embedding 模型。<details>
<summary>Abstract</summary>
We demonstrate how conditional generation from diffusion models can be used to tackle a variety of realistic tasks in the production of music in 44.1kHz stereo audio with sampling-time guidance. The scenarios we consider include continuation, inpainting and regeneration of musical audio, the creation of smooth transitions between two different music tracks, and the transfer of desired stylistic characteristics to existing audio clips. We achieve this by applying guidance at sampling time in a simple framework that supports both reconstruction and classification losses, or any combination of the two. This approach ensures that generated audio can match its surrounding context, or conform to a class distribution or latent representation specified relative to any suitable pre-trained classifier or embedding model.
</details>
<details>
<summary>摘要</summary>
我们展示了如何使用扩散模型进行条件生成，以解决音乐生产中的各种现实任务，包括续写、填充和重新生成音乐Audio，创造缓和过渡 между两个不同的音乐轨道，以及将欲要的风格特征传递到现有音频clip中。我们通过在采样时提供指导，实现了这些任务，并且支持 both reconstruction和 classificationlosses，或任何组合其中的两者。这种方法确保生成的音频能匹配周围的上下文，或者符合任何适用的预训练分类器或嵌入模型中的分布或表示。
</details></li>
</ul>
<hr>
<h2 id="A-Collaborative-Filtering-Based-Two-Stage-Model-with-Item-Dependency-for-Course-Recommendation"><a href="#A-Collaborative-Filtering-Based-Two-Stage-Model-with-Item-Dependency-for-Course-Recommendation" class="headerlink" title="A Collaborative Filtering-Based Two Stage Model with Item Dependency for Course Recommendation"></a>A Collaborative Filtering-Based Two Stage Model with Item Dependency for Course Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00612">http://arxiv.org/abs/2311.00612</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Eric L. Lee, Tsung-Ting Kuo, Shou-De Lin</li>
<li>for: 这篇论文旨在扩展基于协同推荐（CF）模型的课程推荐系统。</li>
<li>methods: 论文提出了应用CF模型到课程推荐 task 中的多个挑战，包括缺乏评分和元数据、课程注册分布不均衡以及课程之间的关系模型。论文还提出了一些解决方案。最终，论文提出了一种两 stage CF 模型受课程依赖关系 regularization，以及基于课程转换网络的图structured 推荐方法，实现了使用真实世界数据的 AUC 为 0.97。</li>
<li>results: 论文的实验结果表明，该方法可以达到 AUC 为 0.97 的高精度。<details>
<summary>Abstract</summary>
Recommender systems have been studied for decades with numerous promising models been proposed. Among them, Collaborative Filtering (CF) models are arguably the most successful one due to its high accuracy in recommendation and elimination of privacy-concerned personal meta-data from training. This paper extends the usage of CF-based model to the task of course recommendation. We point out several challenges in applying the existing CF-models to build a course recommendation engine, including the lack of rating and meta-data, the imbalance of course registration distribution, and the demand of course dependency modeling. We then propose several ideas to address these challenges. Eventually, we combine a two-stage CF model regularized by course dependency with a graph-based recommender based on course-transition network, to achieve AUC as high as 0.97 with a real-world dataset.
</details>
<details>
<summary>摘要</summary>
“推荐系统已经进行了多年研究，许多有挑战性的模型被提出。其中，协同推荐（CF）模型被认为是最成功的，主要因为它的推荐精度高和不需要隐私敏感的人际资料在训练中。本文将CF模型应用到课程推荐任务上，并提出了许多问题。包括缺乏评价和元数据、课程注册分布不均衡以及课程之间的依赖关系模型。我们随后提出了一些解决方案。最终，我们结合了两阶段CF模型与基于课程迁移网络的图形推荐，实现了实际数据上的AUC值为0.97。”Note that Simplified Chinese is the official standard for Chinese writing in mainland China and is used in this translation. Traditional Chinese is used in Taiwan and Hong Kong, and the translation would be slightly different in those variants.
</details></li>
</ul>
<hr>
<h2 id="Structure-Learning-with-Adaptive-Random-Neighborhood-Informed-MCMC"><a href="#Structure-Learning-with-Adaptive-Random-Neighborhood-Informed-MCMC" class="headerlink" title="Structure Learning with Adaptive Random Neighborhood Informed MCMC"></a>Structure Learning with Adaptive Random Neighborhood Informed MCMC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00599">http://arxiv.org/abs/2311.00599</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xitongliang/the-parni-scheme">https://github.com/xitongliang/the-parni-scheme</a></li>
<li>paper_authors: Alberto Caron, Xitong Liang, Samuel Livingstone, Jim Griffin</li>
<li>For: The paper is written for learning the structure of Directed Acyclic Graphs (DAGs) under observational data, using a fully-Bayesian approach with a novel Markov Chain Monte Carlo (MCMC) sampler called PARNI-DAG.* Methods: PARNI-DAG uses a locally informed, adaptive random neighborhood proposal to efficiently sample DAGs, and it includes a pre-tuning procedure of the sampler’s parameters to ensure better scalability.* Results: PARNI-DAG quickly converges to high-probability regions and is less likely to get stuck in local modes in high-dimensional settings, and it is demonstrated to be effective in learning DAG structures on a variety of experiments.Here is the same information in Simplified Chinese text:* For: 本 paper 用于在观察数据下学习 Directed Acyclic Graphs (DAGs) 的结构，使用完全 Bayesian 方法和一种新的 Markov Chain Monte Carlo (MCMC) 抽取器 called PARNI-DAG。* Methods: PARNI-DAG 使用本地 Informed, adaptive random neighborhood proposal 来有效地抽取 DAGs，并包括一种适应性 parameter 的预调整过程，以确保更好的扩展性。* Results: PARNI-DAG 快速 converges to high-probability regions，并且在高维度设置中更 unlikely to get stuck in local modes，并在各种实验中证明其效果。<details>
<summary>Abstract</summary>
In this paper, we introduce a novel MCMC sampler, PARNI-DAG, for a fully-Bayesian approach to the problem of structure learning under observational data. Under the assumption of causal sufficiency, the algorithm allows for approximate sampling directly from the posterior distribution on Directed Acyclic Graphs (DAGs). PARNI-DAG performs efficient sampling of DAGs via locally informed, adaptive random neighborhood proposal that results in better mixing properties. In addition, to ensure better scalability with the number of nodes, we couple PARNI-DAG with a pre-tuning procedure of the sampler's parameters that exploits a skeleton graph derived through some constraint-based or scoring-based algorithms. Thanks to these novel features, PARNI-DAG quickly converges to high-probability regions and is less likely to get stuck in local modes in the presence of high correlation between nodes in high-dimensional settings. After introducing the technical novelties in PARNI-DAG, we empirically demonstrate its mixing efficiency and accuracy in learning DAG structures on a variety of experiments.
</details>
<details>
<summary>摘要</summary>
在本文中，我们介绍了一种新的MCMC抽样器，PARNI-DAG，用于在观察数据下进行完全 Bayesian 结构学习。假设 causal sufficiency，该算法允许直接从 posterior 分布中采样 Directed Acyclic Graphs (DAGs)。PARNI-DAG 使用地方 Informed 适应随机 neighboor proposal，从而实现更好的混合性。此外，为了提高扩展性，我们将 PARNI-DAG 结合一种预调整 sampler 参数的方法，该方法利用一个基于约束或 scoring 算法 derivied的skeleton graph。这些新特性使得 PARNI-DAG 快速 converges to high-probability regions，并且更 unlikely to get stuck in local modes 在高维度设置下。我们在技术新特性的介绍后，通过实验证明 PARNI-DAG 的混合效率和准确性在学习 DAG 结构方面。
</details></li>
</ul>
<hr>
<h2 id="Flexible-Tails-for-Normalising-Flows-with-Application-to-the-Modelling-of-Financial-Return-Data"><a href="#Flexible-Tails-for-Normalising-Flows-with-Application-to-the-Modelling-of-Financial-Return-Data" class="headerlink" title="Flexible Tails for Normalising Flows, with Application to the Modelling of Financial Return Data"></a>Flexible Tails for Normalising Flows, with Application to the Modelling of Financial Return Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00580">http://arxiv.org/abs/2311.00580</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tennessee-wallaceh/tailnflows">https://github.com/tennessee-wallaceh/tailnflows</a></li>
<li>paper_authors: Tennessee Hickling, Dennis Prangle</li>
<li>for: 这个论文目的是为了提出一种可以改变分布的尾部性质的变换方法，以便模拟多变量的重 tailed 分布。</li>
<li>methods: 这种方法基于极值理论，使用一层 normalizing flow 来实现。</li>
<li>results: 通过应用这种方法，可以模拟金融收益的极端冲击，并生成新的可能极端的返回数据集。<details>
<summary>Abstract</summary>
We propose a transformation capable of altering the tail properties of a distribution, motivated by extreme value theory, which can be used as a layer in a normalizing flow to approximate multivariate heavy tailed distributions. We apply this approach to model financial returns, capturing potentially extreme shocks that arise in such data. The trained models can be used directly to generate new synthetic sets of potentially extreme returns
</details>
<details>
<summary>摘要</summary>
我们提出一种转换，可以改变分布的尾部性质，基于极值理论，可以用作正常化流中的层，近似多变量极大尾部分布。我们应用这种方法模型金融回报，捕捉可能出现的极端冲击。训练模型可以直接生成新的可能极端的 sintetic返回集。Here's a breakdown of the translation:* "We propose" is translated as "我们提出" (wǒmen tīshì)* "a transformation" is translated as "一种转换" (yī zhī zhuān biàn)* "capable of altering the tail properties" is translated as "可以改变分布的尾部性质" (kěyǐ gǎi biàn fēn xiǎng de yǐ yóu)* "motivated by extreme value theory" is translated as "基于极值理论" (jī yù lǐ lún)* "which can be used as a layer in a normalizing flow" is translated as "可以用作正常化流中的层" (kěyǐ yòu yì zhèng huà lù)* "to approximate multivariate heavy tailed distributions" is translated as "近似多变量极大尾部分布" (jìn shì duō biàn yù jí dà wěi bù fēn xiǎng)* "We apply this approach to model financial returns" is translated as "我们应用这种方法模型金融回报" (wǒmen yìng yòu zhèng xìng fāng yì jīn yìu huì bò)* "capturing potentially extreme shocks that arise in such data" is translated as "捕捉可能出现的极端冲击" (bò shòu kěnéng chūshì de jí dà chōng jī)* "The trained models can be used directly to generate new synthetic sets of potentially extreme returns" is translated as "训练模型可以直接生成新的可能极端的 sintetic返回集" (xùn xīng mó delè yì yī zhèng shēng chuāng xīn de kěnéng jí dà de sintetic fù bù)
</details></li>
</ul>
<hr>
<h2 id="Revealing-CNN-Architectures-via-Side-Channel-Analysis-in-Dataflow-based-Inference-Accelerators"><a href="#Revealing-CNN-Architectures-via-Side-Channel-Analysis-in-Dataflow-based-Inference-Accelerators" class="headerlink" title="Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based Inference Accelerators"></a>Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based Inference Accelerators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00579">http://arxiv.org/abs/2311.00579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hansika Weerasena, Prabhat Mishra</li>
<li>for: 这 paper 是为了研究如何通过数据流基于 CNN 加速器来恢复 CNN 模型结构。</li>
<li>methods: 这 paper 使用了数据流映射的空间和时间数据重复特性，以及建筑设计的指示信息，对数据流基于 CNN 加速器进行了Memory-based 侧通道攻击，以恢复 CNN 模型结构。</li>
<li>results: 实验结果表明，该攻击可以成功恢复Lenet、Alexnet和VGGnet16等Popular CNN 模型的结构。<details>
<summary>Abstract</summary>
Convolution Neural Networks (CNNs) are widely used in various domains. Recent advances in dataflow-based CNN accelerators have enabled CNN inference in resource-constrained edge devices. These dataflow accelerators utilize inherent data reuse of convolution layers to process CNN models efficiently. Concealing the architecture of CNN models is critical for privacy and security. This paper evaluates memory-based side-channel information to recover CNN architectures from dataflow-based CNN inference accelerators. The proposed attack exploits spatial and temporal data reuse of the dataflow mapping on CNN accelerators and architectural hints to recover the structure of CNN models. Experimental results demonstrate that our proposed side-channel attack can recover the structures of popular CNN models, namely Lenet, Alexnet, and VGGnet16.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在各个领域广泛应用。最新的数据流基于CNN加速器的进步使得CNN推理可以在有限的边缘设备中进行 efficiently。这些数据流加速器利用卷积层的自然数据重用来处理CNN模型。隐藏CNN模型的架构是重要的隐私和安全问题。这篇论文评估了基于数据流的CNN推理加速器中的内存相关的侧annel信息，以便还原CNN模型的结构。我们提出的攻击利用卷积层的空间和时间数据重用以及架构提示来还原流行的CNN模型 Lenet、Alexnet 和 VGGnet16 的结构。实验结果表明，我们的侧annel攻击可以成功地还原这些CNN模型的结构。
</details></li>
</ul>
<hr>
<h2 id="Transfer-learning-for-improved-generalizability-in-causal-physics-informed-neural-networks-for-beam-simulations"><a href="#Transfer-learning-for-improved-generalizability-in-causal-physics-informed-neural-networks-for-beam-simulations" class="headerlink" title="Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations"></a>Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00578">http://arxiv.org/abs/2311.00578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taniya Kapoor, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet</li>
<li>for: 本文提出了一种新的方法，用于模拟钢板在弹性基础上的动态行为。</li>
<li>methods: 本文使用了一种基于物理学信息学习网络（PINN）框架的转移学习方法，使用了 causality-respecting PINN 损失函数，以解决大空间时间域问题。</li>
<li>results: 实验表明，提议的方法可以快速 converge 并提供高精度的结果，并且在不同的初始条件下（包括噪声）都能够提供 precisions 的结果。此外，对 Timoshenko 钢板进行了扩展的空间和时间领域测试，并与当前 physics-informed 方法进行了比较，结果表明，提议的方法可以准确捕捉钢板的内在动态。<details>
<summary>Abstract</summary>
This paper introduces a novel methodology for simulating the dynamics of beams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beam models on the Winkler foundation are simulated using a transfer learning approach within a causality-respecting physics-informed neural network (PINN) framework. Conventional PINNs encounter challenges in handling large space-time domains, even for problems with closed-form analytical solutions. A causality-respecting PINN loss function is employed to overcome this limitation, effectively capturing the underlying physics. However, it is observed that the causality-respecting PINN lacks generalizability. We propose using solutions to similar problems instead of training from scratch by employing transfer learning while adhering to causality to accelerate convergence and ensure accurate results across diverse scenarios. Numerical experiments on the Euler-Bernoulli beam highlight the efficacy of the proposed approach for various initial conditions, including those with noise in the initial data. Furthermore, the potential of the proposed method is demonstrated for the Timoshenko beam in an extended spatial and temporal domain. Several comparisons suggest that the proposed method accurately captures the inherent dynamics, outperforming the state-of-the-art physics-informed methods under standard $L^2$-norm metric and accelerating convergence.
</details>
<details>
<summary>摘要</summary>
Traditional PINNs struggle with large space-time domains, even for problems with known analytical solutions. To overcome this limitation, the authors employ a causality-respecting PINN loss function that effectively captures the underlying physics. However, this approach lacks generalizability.To address this issue, the authors propose using transfer learning while adhering to causality to accelerate convergence and ensure accurate results across diverse scenarios. The proposed method is tested on the Euler-Bernoulli beam for various initial conditions, including noisy data, and demonstrates improved accuracy and faster convergence compared to state-of-the-art physics-informed methods.The proposed method is also applied to the Timoshenko beam in a larger spatial and temporal domain, showing its potential for simulating the dynamics of more complex beam systems. The results suggest that the proposed method accurately captures the inherent dynamics of the beams, outperforming existing methods under the standard $L^2$-norm metric.
</details></li>
</ul>
<hr>
<h2 id="Personalized-Assignment-to-One-of-Many-Treatment-Arms-via-Regularized-and-Clustered-Joint-Assignment-Forests"><a href="#Personalized-Assignment-to-One-of-Many-Treatment-Arms-via-Regularized-and-Clustered-Joint-Assignment-Forests" class="headerlink" title="Personalized Assignment to One of Many Treatment Arms via Regularized and Clustered Joint Assignment Forests"></a>Personalized Assignment to One of Many Treatment Arms via Regularized and Clustered Joint Assignment Forests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00577">http://arxiv.org/abs/2311.00577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rahul Ladhania, Jann Spiess, Lyle Ungar, Wenbo Wu</li>
<li>for: 学习个性化分配试验中的几个药品臂的医疗效果。</li>
<li>methods: 使用常见方法估计各臂的医疗效果可能会受到副本数据的巨大噪声，我们提议使用聚合信息的方法来减少噪声。</li>
<li>results: 通过 simulations 和理论模型，我们发现使用聚合信息可以减少噪声，并且可以实现个性化分配的医疗效果。Here’s a more detailed explanation of each point:</li>
<li>for: The paper is focused on learning personalized assignments to one of many treatment arms from a randomized controlled trial. The goal is to estimate the heterogeneous treatment effects for each arm, while accounting for the excess variance that can arise when there are many arms.</li>
<li>methods: The paper proposes two methods to address this challenge: (1) a regularized forest-based assignment algorithm based on greedy recursive partitioning, and (2) a clustering scheme that combines treatment arms with consistently similar outcomes. These methods pool information across treatment arms to reduce the excess variance and improve the accuracy of the treatment assignments.</li>
<li>results: The paper presents the results of simulations and a theoretical model that demonstrate the effectiveness of the proposed methods. The results show that the regularized optimization and clustering methods can lead to significant gains in terms of predicting arm-wise outcomes and achieving sizable utility gains from personalization.<details>
<summary>Abstract</summary>
We consider learning personalized assignments to one of many treatment arms from a randomized controlled trial. Standard methods that estimate heterogeneous treatment effects separately for each arm may perform poorly in this case due to excess variance. We instead propose methods that pool information across treatment arms: First, we consider a regularized forest-based assignment algorithm based on greedy recursive partitioning that shrinks effect estimates across arms. Second, we augment our algorithm by a clustering scheme that combines treatment arms with consistently similar outcomes. In a simulation study, we compare the performance of these approaches to predicting arm-wise outcomes separately, and document gains of directly optimizing the treatment assignment with regularization and clustering. In a theoretical model, we illustrate how a high number of treatment arms makes finding the best arm hard, while we can achieve sizable utility gains from personalization by regularized optimization.
</details>
<details>
<summary>摘要</summary>
我们考虑学习对很多治疗臂的对照试验 personnalized 任务。标准方法可能在这种情况下表现不佳，因为过度差异。我们 instead propose 方法可以聚集到治疗臂上的信息：首先，我们考虑一种对应树基于循环分割的调整算法，将效果估计调整到不同的臂上。其次，我们将 clustering 方案与治疗臂相结合，以实现具有相似结果的臂集合。在一个 simulated study 中，我们比较这些方法和分别预测每个臂的结果，并证明了通过调整和聚集可以实现更高的利益。在一个理论模型中，我们显示出一高数量的治疗臂使得找到最佳臂的问题困难，但是通过调整估计可以实现较大的价值增加。
</details></li>
</ul>
<hr>
<h2 id="Online-Student-t-Processes-with-an-Overall-local-Scale-Structure-for-Modelling-Non-stationary-Data"><a href="#Online-Student-t-Processes-with-an-Overall-local-Scale-Structure-for-Modelling-Non-stationary-Data" class="headerlink" title="Online Student-$t$ Processes with an Overall-local Scale Structure for Modelling Non-stationary Data"></a>Online Student-$t$ Processes with an Overall-local Scale Structure for Modelling Non-stationary Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00564">http://arxiv.org/abs/2311.00564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taole Sha, Michael Minyi Zhang</li>
<li>for:  Handle time-dependent data with non-stationarity and heavy-tailed errors.</li>
<li>methods:  Bayesian mixture of student-$t$ processes with overall-local scale structure for the covariance, and sequential Monte Carlo (SMC) sampler for online inference.</li>
<li>results:  Superior performance compared to typical Gaussian process-based models on real-world data sets.<details>
<summary>Abstract</summary>
Time-dependent data often exhibit characteristics, such as non-stationarity and heavy-tailed errors, that would be inappropriate to model with the typical assumptions used in popular models. Thus, more flexible approaches are required to be able to accommodate such issues. To this end, we propose a Bayesian mixture of student-$t$ processes with an overall-local scale structure for the covariance. Moreover, we use a sequential Monte Carlo (SMC) sampler in order to perform online inference as data arrive in real-time. We demonstrate the superiority of our proposed approach compared to typical Gaussian process-based models on real-world data sets in order to prove the necessity of using mixtures of student-$t$ processes.
</details>
<details>
<summary>摘要</summary>
时间相关数据经常具有非站立性和重 tailed 错误特点，这些特点不适合使用流行的模型假设。因此，需要更 flexible 的方法来处理这些问题。为此，我们提议使用 Bayesian  mixture of student-$t$ processes 以及全局本地尺度结构来描述协方差。此外，我们还使用 sequential Monte Carlo (SMC) 样本器进行在线推断，以便在实时接收数据时进行推断。我们通过对实际数据集进行比较，证明了我们的提议方法的必要性，并且超过了 typical Gaussian process-based 模型。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-optimize-by-multi-gradient-for-multi-objective-optimization"><a href="#Learning-to-optimize-by-multi-gradient-for-multi-objective-optimization" class="headerlink" title="Learning to optimize by multi-gradient for multi-objective optimization"></a>Learning to optimize by multi-gradient for multi-objective optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00559">http://arxiv.org/abs/2311.00559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linxi Yang, Xinmin Yang, Liping Tang</li>
<li>for: 本研究旨在提出一种基于自动学习的多目标优化方法，以满足当今人工智能（AI）科学研究中的学习型研究方法的需求。</li>
<li>methods: 本研究提出了一种基于自动学习的多 gradient 学习方法（ML2O），该方法可以自动学习一个生成器或映射，以更新方向。此外，我们还提出了一种受保护的多 gradient 学习方法（GML2O），并证明其迭代序列会 converges to a Pareto 稳定点。</li>
<li>results: 实验结果表明，我们学习的优化器在训练多任务学习（MTL）神经网络时表现更高效，比手动设计的竞争对手。<details>
<summary>Abstract</summary>
The development of artificial intelligence (AI) for science has led to the emergence of learning-based research paradigms, necessitating a compelling reevaluation of the design of multi-objective optimization (MOO) methods. The new generation MOO methods should be rooted in automated learning rather than manual design. In this paper, we introduce a new automatic learning paradigm for optimizing MOO problems, and propose a multi-gradient learning to optimize (ML2O) method, which automatically learns a generator (or mappings) from multiple gradients to update directions. As a learning-based method, ML2O acquires knowledge of local landscapes by leveraging information from the current step and incorporates global experience extracted from historical iteration trajectory data. By introducing a new guarding mechanism, we propose a guarded multi-gradient learning to optimize (GML2O) method, and prove that the iterative sequence generated by GML2O converges to a Pareto critical point. The experimental results demonstrate that our learned optimizer outperforms hand-designed competitors on training multi-task learning (MTL) neural network.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）的发展对科学研究带来了新的学习基本设计方法的需求，这需要我们重新评估多目标优化（MOO）方法的设计。新一代MOO方法应该是基于自动学习而不是手动设计。在这篇论文中，我们介绍了一种新的自动学习 парадиг，用于优化MOO问题，并提出了多Gradient学习优化（ML2O）方法。这种学习基于的方法可以自动学习一个生成器（或映射），以更新方向。通过利用当前步骤中的信息和历史迭代轨迹数据来捕捉当地特征，ML2O方法可以学习当地景观。我们还提出了一种新的保护机制，称为卫护多Gradient学习优化（GML2O）方法，并证明其迭代序列会 converge to a Pareto优点。实验结果表明，我们学习优化器比手动设计的竞争对手在训练多任务学习（MTL）神经网络上表现更好。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Without-a-Processor-Emergent-Learning-in-a-Nonlinear-Electronic-Metamaterial"><a href="#Machine-Learning-Without-a-Processor-Emergent-Learning-in-a-Nonlinear-Electronic-Metamaterial" class="headerlink" title="Machine Learning Without a Processor: Emergent Learning in a Nonlinear Electronic Metamaterial"></a>Machine Learning Without a Processor: Emergent Learning in a Nonlinear Electronic Metamaterial</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00537">http://arxiv.org/abs/2311.00537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sam Dillavou, Benjamin D Beyer, Menachem Stern, Marc Z Miskin, Andrea J Liu, Douglas J Durian</li>
<li>for: 这项研究旨在开发一种可以进行快速、能效的分析学习机制，以替代传统的深度学习算法。</li>
<li>methods: 研究人员使用了一种基于晶体管的非线性学习元件，实现了无计算机的非线性学习。</li>
<li>results: 研究人员发现，这种非线性学习元件可以完成传统 linear 系统无法实现的任务，包括 XOR 和非线性回归。此外，这种系统还具有较低的能耗和可重新编辑的特点。<details>
<summary>Abstract</summary>
Standard deep learning algorithms require differentiating large nonlinear networks, a process that is slow and power-hungry. Electronic learning metamaterials offer potentially fast, efficient, and fault-tolerant hardware for analog machine learning, but existing implementations are linear, severely limiting their capabilities. These systems differ significantly from artificial neural networks as well as the brain, so the feasibility and utility of incorporating nonlinear elements have not been explored. Here we introduce a nonlinear learning metamaterial -- an analog electronic network made of self-adjusting nonlinear resistive elements based on transistors. We demonstrate that the system learns tasks unachievable in linear systems, including XOR and nonlinear regression, without a computer. We find our nonlinear learning metamaterial reduces modes of training error in order (mean, slope, curvature), similar to spectral bias in artificial neural networks. The circuitry is robust to damage, retrainable in seconds, and performs learned tasks in microseconds while dissipating only picojoules of energy across each transistor. This suggests enormous potential for fast, low-power computing in edge systems like sensors, robotic controllers, and medical devices, as well as manufacturability at scale for performing and studying emergent learning.
</details>
<details>
<summary>摘要</summary>
标准深度学习算法需要分别大的非线性网络，这是一个缓态且电力消耗很大的过程。电子学习元件提供了可能快速、效率高、错误快速修复的硬件 для数位机器学习，但现有的实现方法是线性的，这限制了它们的能力。这些系统与人工神经网络以及大脑有所不同，因此尚未探讨了非线性元素的可行性和价值。我们现在引入了非线性学习元件---一个基于普通遮蔽器的数位电子网络。我们证明了这个系统可以进行线性系统无法进行的任务，包括XOR和非线性回归，并且不需要电脑。我们发现了我们的非线性学习元件可以将训练错误分解为不同的模式（平均值、斜率、曲线），类似于人工神经网络的spectral bias。这个网络的普通遮蔽器是可靠的、可重复 trains 秒钟内，并且在微秒钟内完成学习任务，同时电子普通遮蔽器只消耗了每个普通遮蔽器的picojoules的能量。这表明这种快速、低功率的计算在边缘系统中，如感测器、 robot控制器和医疗设备，以及在大规模生产中进行和研究emergent learning的可能性很大。
</details></li>
</ul>
<hr>
<h2 id="Active-Noise-Control-Portable-Device-Design"><a href="#Active-Noise-Control-Portable-Device-Design" class="headerlink" title="Active Noise Control Portable Device Design"></a>Active Noise Control Portable Device Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00535">http://arxiv.org/abs/2311.00535</a></li>
<li>repo_url: None</li>
<li>paper_authors: kai Wu, Yuanyuan Chen</li>
<li>for: 降低噪音的系统，以提高工作效率和人类健康。</li>
<li>methods: 使用感应器检测环境中的噪音，然后将噪音处理成反相频率信号，最后透过喇叭发送处理后的较小的噪音。</li>
<li>results: 这个智能噪音减少系统可以干预低频噪音，并且搭配睡眠追踪、音乐播放等应用程序，可以提供轻松、安全、智能的噪音减少解决方案。<details>
<summary>Abstract</summary>
While our world is filled with its own natural sounds that we can't resist enjoying, it is also chock-full of other sounds that can be irritating, this is noise. Noise not only influences the working efficiency but also the human's health. The problem of reducing noise is one of great importance and great difficulty. The problem has been addressed in many ways over the years. The current methods for noise reducing mostly rely on the materials and transmission medium, which are only effective to some extent for the high frequency noise. However, the effective reduction noise method especially for low frequency noise is very limited.   Here we come up with a noise reduction system consist of a sensor to detect the noise in the environment. Then the noise will be sent to an electronic control system to process the noise, which will generate a reverse phase frequency signal to counteract the disturbance. Finally, the processed smaller noise will be broadcasted by the speaker. Through this smart noise reduction system, even the noise with low-frequency can be eliminated.   The system is also integrated with sleep tracking and music player applications. It can also remember and store settings for the same environment, sense temperature, and smart control of home furniture, fire alarm, etc. This smart system can transfer data easily by Wi-Fi or Bluetooth and controlled by its APP.   In this project, we will present a model of the above technology which can be used in various environments to prevent noise pollution and provide a solution to the people who have difficulties finding a peaceful and quiet environment for sleep, work or study.
</details>
<details>
<summary>摘要</summary>
在我们的世界中，充满自然的声音是我们无法抵抗的乐趣之一，但是这些声音也包括了吵闹和干扰的声音，它们不仅影响工作效率，还影响人类的健康。减少吵闹的问题是一项非常重要且具有挑战性的问题。过去多年来，人们已经使用了许多方法来解决这个问题，但现有的减少吵闹方法主要依靠材料和传输媒体，它们只能够有限地降低高频吵闹。然而，对低频吵闹的有效减少方法尚存在很大的限制。为了解决这问题，我们提出了一种吵闹减少系统，该系统包括一个检测环境吵闹的感知器。然后，吵闹将被传输到一个电子控制系统进行处理，该系统会生成一个逆相频率信号，以抵消干扰。最后，已经处理过的小于吵闹将被广播器播发出来。通过这个智能吵闹减少系统，甚至可以减少低频吵闹。这个系统还 integrates 睡眠跟踪和音乐播放应用程序，可以记录和存储相同环境的设置，感测 темпераature 和智能控制家具、火警等。这个智能系统可以通过 Wi-Fi 或蓝牙传输数据，并由其APP控制。在这个项目中，我们将展示一种可以在不同环境中应用的技术模型，用于防止吵闹污染和提供舒适的睡眠、工作或学习环境。
</details></li>
</ul>
<hr>
<h2 id="Real-Time-Magnetic-Tracking-and-Diagnosis-of-COVID-19-via-Machine-Learning"><a href="#Real-Time-Magnetic-Tracking-and-Diagnosis-of-COVID-19-via-Machine-Learning" class="headerlink" title="Real-Time Magnetic Tracking and Diagnosis of COVID-19 via Machine Learning"></a>Real-Time Magnetic Tracking and Diagnosis of COVID-19 via Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00737">http://arxiv.org/abs/2311.00737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dang Nguyen, Phat K. Huynh, Vinh Duc An Bui, Kee Young Hwang, Nityanand Jain, Chau Nguyen, Le Huu Nhat Minh, Le Van Truong, Xuan Thanh Nguyen, Dinh Hoang Nguyen, Le Tien Dung, Trung Q. Le, Manh-Huong Phan</li>
<li>for: 这个研究旨在开发一种可靠、非侵入性的检测工具，以支持公共卫生政策的实施。</li>
<li>methods: 该平台结合了磁気呼吸感知技术（MRST）和机器学习（ML），并采用了三种呼吸测试协议：正常呼吸、停止呼吸和深呼吸。</li>
<li>results: 研究发现，这种检测平台可以准确地识别 COVID-19 患者和健康者，准确率高达 90%。<details>
<summary>Abstract</summary>
The COVID-19 pandemic underscored the importance of reliable, noninvasive diagnostic tools for robust public health interventions. In this work, we fused magnetic respiratory sensing technology (MRST) with machine learning (ML) to create a diagnostic platform for real-time tracking and diagnosis of COVID-19 and other respiratory diseases. The MRST precisely captures breathing patterns through three specific breath testing protocols: normal breath, holding breath, and deep breath. We collected breath data from both COVID-19 patients and healthy subjects in Vietnam using this platform, which then served to train and validate ML models. Our evaluation encompassed multiple ML algorithms, including support vector machines and deep learning models, assessing their ability to diagnose COVID-19. Our multi-model validation methodology ensures a thorough comparison and grants the adaptability to select the most optimal model, striking a balance between diagnostic precision with model interpretability. The findings highlight the exceptional potential of our diagnostic tool in pinpointing respiratory anomalies, achieving over 90% accuracy. This innovative sensor technology can be seamlessly integrated into healthcare settings for patient monitoring, marking a significant enhancement for the healthcare infrastructure.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行强调了可靠、不侵入的诊断工具的重要性，以便实施有效的公共卫生措施。在这项工作中，我们将磁力呼吸感测技术（MRST）与机器学习（ML）相结合，创造了一个用于实时跟踪和诊断COVID-19和其他呼吸疾病的诊断平台。MRST可以高精度地捕捉呼吸模式，通过三种呼吸测试协议：正常呼吸、停吸和深呼吸。我们在越南collected呼吸数据，并使用这个平台来训练和验证ML模型。我们的评估包括多种ML算法，包括支持向量机和深度学习模型，评估它们是否能够诊断COVID-19。我们的多模型验证方法可以很好地比较多种模型，从而选择最佳模型，并且能够寻求在诊断精度和模型解释性之间取得平衡。研究发现，我们的诊断工具可以准确地检测呼吸异常，达到90%以上的准确率。这种创新的感测技术可以轻松地integrated into healthcare settings，为患者监测提供了 significanthenhancement。
</details></li>
</ul>
<hr>
<h2 id="Retrieval-Based-Reconstruction-For-Time-series-Contrastive-Learning"><a href="#Retrieval-Based-Reconstruction-For-Time-series-Contrastive-Learning" class="headerlink" title="Retrieval-Based Reconstruction For Time-series Contrastive Learning"></a>Retrieval-Based Reconstruction For Time-series Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00519">http://arxiv.org/abs/2311.00519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maxwell A. Xu, Alexander Moreno, Hui Wei, Benjamin M. Marlin, James M. Rehg</li>
<li>for: 本研究旨在提出一种基于 Retrieval-BAsed Reconstruction (REBAR) 的自我超vised contrastive learning方法，以便在时间序列数据上实现更高的下游任务表现。</li>
<li>methods: 该方法首先利用卷积cross-attention架构计算REBAR错误值，然后通过验证实验表明REBAR错误值是种类别成员关系预测器，从而正当使用为正&#x2F;负标签。最后，该方法被纳入对冲学习框架中，可以学习一个 дости得state-of-the-art表现的嵌入。</li>
<li>results: 该研究通过多种Modalities的验证实验表明，在REBAR contrastive learning框架中，可以学习一个高效的嵌入，并且在下游任务上达到了 estado-of-the-art 表现。<details>
<summary>Abstract</summary>
The success of self-supervised contrastive learning hinges on identifying positive data pairs that, when pushed together in embedding space, encode useful information for subsequent downstream tasks. However, in time-series, this is challenging because creating positive pairs via augmentations may break the original semantic meaning. We hypothesize that if we can retrieve information from one subsequence to successfully reconstruct another subsequence, then they should form a positive pair. Harnessing this intuition, we introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR) contrastive learning. First, we utilize a convolutional cross-attention architecture to calculate the REBAR error between two different time-series. Then, through validation experiments, we show that the REBAR error is a predictor of mutual class membership, justifying its usage as a positive/negative labeler. Finally, once integrated into a contrastive learning framework, our REBAR method can learn an embedding that achieves state-of-the-art performance on downstream tasks across various modalities.
</details>
<details>
<summary>摘要</summary>
文章标题：基于检索的重构减错学习文章摘要：自监督减错学习的成功取决于标识符合的数据对，使得在嵌入空间中拼接起来的信息具有下游任务的用于。然而，在时序序列中，通过扩展可能会破坏原始 semantics 的含义。我们假设如果可以从一个子序列中检索到另一个子序列，并成功地重构它，那么它们应该组成一个正确的对。基于这个假设，我们介绍了我们的新方法：REtrieval-BAsed Reconstruction（REBAR）减错学习。首先，我们使用卷积 convolutional cross-attention 架构来计算 REBAR 错误 между两个不同的时序序列。然后，通过验证实验，我们表明 REBAR 错误是分类成员之间的共同标识符，因此可以作为正/负标签。最后，我们将 REBAR 方法integrated into a contrastive learning framework，可以学习一个在不同模式下 achieve state-of-the-art 的嵌入。
</details></li>
</ul>
<hr>
<h2 id="Fixed-Budget-Best-Arm-Identification-in-Sparse-Linear-Bandits"><a href="#Fixed-Budget-Best-Arm-Identification-in-Sparse-Linear-Bandits" class="headerlink" title="Fixed-Budget Best-Arm Identification in Sparse Linear Bandits"></a>Fixed-Budget Best-Arm Identification in Sparse Linear Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00481">http://arxiv.org/abs/2311.00481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Recep Can Yavas, Vincent Y. F. Tan</li>
<li>for: 该研究是关于固定预算下最佳臂的标识问题，具体来说是在稀疏线性弹性下进行最佳臂的标识。</li>
<li>methods: 该研究使用了lasso和优化设计(-lasso-od)算法来解决最佳臂的标识问题。在第一阶段，使用归一化lasso来估计权重矩阵中非零元素的支持，然后在第二阶段使用OD-LinBAI算法进行最佳臂的标识。</li>
<li>results: 研究人员通过仔细选择几何参数（如lasso的正则化参数），并在两个阶段中均衡错误概率，从而得到了较低的错误概率。此外，研究人员还证明了lasso-od算法在稀疏和高维的线性弹性中具有几乎最佳性。最后，通过数值示例，研究人员证明了lasso-od算法在非稀疏的线性弹性中的显著性能提高。<details>
<summary>Abstract</summary>
We study the best-arm identification problem in sparse linear bandits under the fixed-budget setting. In sparse linear bandits, the unknown feature vector $\theta^*$ may be of large dimension $d$, but only a few, say $s \ll d$ of these features have non-zero values. We design a two-phase algorithm, Lasso and Optimal-Design- (Lasso-OD) based linear best-arm identification. The first phase of Lasso-OD leverages the sparsity of the feature vector by applying the thresholded Lasso introduced by Zhou (2009), which estimates the support of $\theta^*$ correctly with high probability using rewards from the selected arms and a judicious choice of the design matrix. The second phase of Lasso-OD applies the OD-LinBAI algorithm by Yang and Tan (2022) on that estimated support. We derive a non-asymptotic upper bound on the error probability of Lasso-OD by carefully choosing hyperparameters (such as Lasso's regularization parameter) and balancing the error probabilities of both phases. For fixed sparsity $s$ and budget $T$, the exponent in the error probability of Lasso-OD depends on $s$ but not on the dimension $d$, yielding a significant performance improvement for sparse and high-dimensional linear bandits. Furthermore, we show that Lasso-OD is almost minimax optimal in the exponent. Finally, we provide numerical examples to demonstrate the significant performance improvement over the existing algorithms for non-sparse linear bandits such as OD-LinBAI, BayesGap, Peace, LinearExploration, and GSE.
</details>
<details>
<summary>摘要</summary>
我们研究最佳臂识别问题在简线性弹珠下，尤其是在固定预算设定下。在简线性弹珠中，未知特征向量 $\theta^*$ 可能是高维度 $d$，但只有一些，例如 $s \ll d$ 的特征有非零值。我们设计了两相运算法，即 Lasso 和 Optimal-Design-（Lasso-OD）基于的线性最佳臂识别。第一相的 Lasso-OD 利用特征向量的简单性，通过实际 Zhou (2009) 提出的降顿 Lasso，估计 $\theta^*$ 的支持正确地使用对选择的枪和设计矩阵获得的奖励。第二相的 Lasso-OD 则应用 Yang 和 Tan (2022) 提出的 OD-LinBAI 算法。我们谨慎地选择几何 Parameters（如 Lasso 的 regularization 参数），并将两相的错误概率均衡，以取得非对应数学上的最佳性。对于固定的 $s$ 和 $T$，Lasso-OD 的错误概率的指数随 $s$ 而变化，从而获得高维度和简线性弹珠的明显性能提升。此外，我们还证明 Lasso-OD 是对数最佳的。最后，我们提供了一些实际的数据，以证明 Lasso-OD 对非简线性弹珠的现有算法，如 OD-LinBAI、BayesGap、Peace、LinearExploration 和 GSE 的性能有很大的提升。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-models-for-probabilistic-programming"><a href="#Diffusion-models-for-probabilistic-programming" class="headerlink" title="Diffusion models for probabilistic programming"></a>Diffusion models for probabilistic programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00474">http://arxiv.org/abs/2311.00474</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dirmeier/dmvi">https://github.com/dirmeier/dmvi</a></li>
<li>paper_authors: Simon Dirmeier, Fernando Perez-Cruz</li>
<li>for: 这个论文是为了提出一种新的自动化粗略推理方法，用于概率编程语言（PPL）中的 Bayesian 模型。</li>
<li>methods: 这个方法使用扩散模型来作为 PPL 中的粗略推理方法，通过 derivation 一种新的尺度函数来 aproximate 真实 posterior 分布。</li>
<li>results: 论文通过对一些常见的 Bayesian 模型进行评估，显示了 DMVI 的 posterior 推理结果比 contemporary 方法在 PPL 中更为准确，同时 computation cost 相对 similar，且需要更少的手动调整。<details>
<summary>Abstract</summary>
We propose Diffusion Model Variational Inference (DMVI), a novel method for automated approximate inference in probabilistic programming languages (PPLs). DMVI utilizes diffusion models as variational approximations to the true posterior distribution by deriving a novel bound to the marginal likelihood objective used in Bayesian modelling. DMVI is easy to implement, allows hassle-free inference in PPLs without the drawbacks of, e.g., variational inference using normalizing flows, and does not make any constraints on the underlying neural network model. We evaluate DMVI on a set of common Bayesian models and show that its posterior inferences are in general more accurate than those of contemporary methods used in PPLs while having a similar computational cost and requiring less manual tuning.
</details>
<details>
<summary>摘要</summary>
我们提出了Diffusion Model Variational Inference（DMVI），一种新的自动化近似推理方法，用于probabilistic programming languages（PPLs）中的推理。DMVI利用扩散模型作为真实 posterior distribution的可变 approximations，通过 derive a novel bound to the marginal likelihood objective used in Bayesian modeling。DMVI易于实现，在 PPLs 中进行快速简单的推理，不受 normalizing flows 等方法的缺点，而且不需要对基于神经网络模型的任何约束。我们对一组常见的 Bayesian 模型进行评估，发现 DMVI 的 posterior inferences 通常比当今 PPLs 中的方法更准确，而且计算成本和手动调整的需求相似。
</details></li>
</ul>
<hr>
<h2 id="Asynchronous-SGD-on-Graphs-a-Unified-Framework-for-Asynchronous-Decentralized-and-Federated-Optimization"><a href="#Asynchronous-SGD-on-Graphs-a-Unified-Framework-for-Asynchronous-Decentralized-and-Federated-Optimization" class="headerlink" title="Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization"></a>Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00465">http://arxiv.org/abs/2311.00465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathieu Even, Anastasia Koloskova, Laurent Massoulié</li>
<li>for: 提高分布式机器学习的通信复杂性</li>
<li>methods: 使用异步通信和分布式计算技术</li>
<li>results: 提供了一个通用的算法框架，可以包括异步版本的多种算法，如SGD、分布式SGD、本地SGD、FedBuff，并且在更宽泛的假设下提供了速度 converge 的速率。<details>
<summary>Abstract</summary>
Decentralized and asynchronous communications are two popular techniques to speedup communication complexity of distributed machine learning, by respectively removing the dependency over a central orchestrator and the need for synchronization. Yet, combining these two techniques together still remains a challenge. In this paper, we take a step in this direction and introduce Asynchronous SGD on Graphs (AGRAF SGD) -- a general algorithmic framework that covers asynchronous versions of many popular algorithms including SGD, Decentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and computation assumptions. We provide rates of convergence under much milder assumptions than previous decentralized asynchronous works, while still recovering or even improving over the best know results for all the algorithms covered.
</details>
<details>
<summary>摘要</summary>
distributed 和异步通信是分布机器学习中通信复杂性的两种受欢迎技术，分别取消中央把关和同步需求。然而，将这两种技术相结合仍然是一项挑战。本文提出了一个步骤，即异步SGD on Graphs（AGRAF SGD）——一种涵盖异步版本的多种流行算法，包括SGD、分布SGD、本地SGD、FedBuff等。我们提供了更加宽松的通信和计算假设，并且可以在较弱的假设下提供速度收敛率，同时仍然能够回归或者超越之前的最佳结果。
</details></li>
</ul>
<hr>
<h2 id="Robust-and-Conjugate-Gaussian-Process-Regression"><a href="#Robust-and-Conjugate-Gaussian-Process-Regression" class="headerlink" title="Robust and Conjugate Gaussian Process Regression"></a>Robust and Conjugate Gaussian Process Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00463">http://arxiv.org/abs/2311.00463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matias Altamirano, François-Xavier Briol, Jeremias Knoblauch</li>
<li>for:  This paper aims to improve the robustness of Gaussian process (GP) regression by developing a provably robust and conjugate Gaussian process (RCGP) regression method.</li>
<li>methods: The RCGP method uses generalised Bayesian inference to perform provably robust and conjugate closed-form updates at virtually no additional cost.</li>
<li>results: The paper demonstrates the strong empirical performance of RCGP on a range of problems, including Bayesian optimisation and sparse variational Gaussian processes.<details>
<summary>Abstract</summary>
To enable closed form conditioning, a common assumption in Gaussian process (GP) regression is independent and identically distributed Gaussian observation noise. This strong and simplistic assumption is often violated in practice, which leads to unreliable inferences and uncertainty quantification. Unfortunately, existing methods for robustifying GPs break closed-form conditioning, which makes them less attractive to practitioners and significantly more computationally expensive. In this paper, we demonstrate how to perform provably robust and conjugate Gaussian process (RCGP) regression at virtually no additional cost using generalised Bayesian inference. RCGP is particularly versatile as it enables exact conjugate closed form updates in all settings where standard GPs admit them. To demonstrate its strong empirical performance, we deploy RCGP for problems ranging from Bayesian optimisation to sparse variational Gaussian processes.
</details>
<details>
<summary>摘要</summary>
要启用闭式条件，一个常见的假设在泊松过程（GP）回归是独立和同样分布的 Gaussian 观测噪声。这强大且简单的假设经常在实践中被违反，导致不可靠的推断和不确定性评估。现有的方法用于强化 GPs 会打砸闭式条件，使其变得更加不吸引实践人员并显着增加计算成本。在这篇论文中，我们示示如何在较低的成本下实现可证的Robust conjugate Gaussian process（RCGP）回归，使用通用极权推理。RCGP 特别是可以在所有情况下实现扩展 conjugate 闭式更新，因此在标准 GPs 承认它们时具有精确的预测性。为证明其强大的实际性，我们在 Bayesian 优化到 sparse variational Gaussian processes 中应用 RCGP。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Budgeted-Rejection-Sampling-for-Generative-Models"><a href="#Optimal-Budgeted-Rejection-Sampling-for-Generative-Models" class="headerlink" title="Optimal Budgeted Rejection Sampling for Generative Models"></a>Optimal Budgeted Rejection Sampling for Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00460">http://arxiv.org/abs/2311.00460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandre Verine, Muni Sreenivas Pydi, Benjamin Negrevergne, Yann Chevaleyre</li>
<li>for: 提高权威性模型的性能和多样性</li>
<li>methods: 使用优化采样方法，包括提出的最优预算采样方案和综合训练方法</li>
<li>results: 通过实验和理论支持，显示提出的方法可以显著提高样本质量和多样性<details>
<summary>Abstract</summary>
Rejection sampling methods have recently been proposed to improve the performance of discriminator-based generative models. However, these methods are only optimal under an unlimited sampling budget, and are usually applied to a generator trained independently of the rejection procedure. We first propose an Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal with respect to \textit{any} $f$-divergence between the true distribution and the post-rejection distribution, for a given sampling budget. Second, we propose an end-to-end method that incorporates the sampling scheme into the training procedure to further enhance the model's overall performance. Through experiments and supporting theory, we show that the proposed methods are effective in significantly improving the quality and diversity of the samples.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。</SYS>>Recently, rejection sampling methods have been proposed to improve the performance of discriminator-based generative models. However, these methods are only optimal with an unlimited sampling budget, and are usually applied to a generator trained independently of the rejection procedure. We first propose an Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal with respect to any $f$-divergence between the true distribution and the post-rejection distribution, for a given sampling budget. Second, we propose an end-to-end method that incorporates the sampling scheme into the training procedure to further enhance the model's overall performance. Through experiments and supporting theory, we show that the proposed methods are effective in significantly improving the quality and diversity of the samples.Here's the translation in Traditional Chinese:<<SYS>>将文本翻译为简化中文。</SYS>>最近，拒绝抽样方法已经被提议来提高标注器基本的生成模型性能。然而，这些方法仅在无限抽样预算下是最佳的，并通常将抽样程序独立应用于生成器。我们首先提出了一个Optimal Budgeted Rejection Sampling（OBRS）方案，可以在任何 $f$-分布之间的对应预算下，具有最佳的性能。其次，我们提出了一个统一方法，将抽样方案 integrate到训练过程中，以进一步提高模型的总性能。通过实验和支持理论，我们证明了提案的方法可以对样本质量和多样性作出重要改善。
</details></li>
</ul>
<hr>
<h2 id="Hessian-Eigenvectors-and-Principal-Component-Analysis-of-Neural-Network-Weight-Matrices"><a href="#Hessian-Eigenvectors-and-Principal-Component-Analysis-of-Neural-Network-Weight-Matrices" class="headerlink" title="Hessian Eigenvectors and Principal Component Analysis of Neural Network Weight Matrices"></a>Hessian Eigenvectors and Principal Component Analysis of Neural Network Weight Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00452">http://arxiv.org/abs/2311.00452</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Haink</li>
<li>for: 这个研究探究了深度神经网络的训练过程中的复杂动力学和网络参数之间的关系。</li>
<li>methods: 这个研究使用了训练深度神经网络的方法，包括潜在函数模型、特征值分解和主成分分析等。</li>
<li>results: 研究发现了网络参数和网络 weights 之间的关系，并提出了一种基于这种关系的方法来 Mitigate catastrophic forgetting。这种方法可以应用于不同规模的神经网络，包括更大的网络 architecture。<details>
<summary>Abstract</summary>
This study delves into the intricate dynamics of trained deep neural networks and their relationships with network parameters. Trained networks predominantly continue training in a single direction, known as the drift mode. This drift mode can be explained by the quadratic potential model of the loss function, suggesting a slow exponential decay towards the potential minima. We unveil a correlation between Hessian eigenvectors and network weights. This relationship, hinging on the magnitude of eigenvalues, allows us to discern parameter directions within the network. Notably, the significance of these directions relies on two defining attributes: the curvature of their potential wells (indicated by the magnitude of Hessian eigenvalues) and their alignment with the weight vectors. Our exploration extends to the decomposition of weight matrices through singular value decomposition. This approach proves practical in identifying critical directions within the Hessian, considering both their magnitude and curvature. Furthermore, our examination showcases the applicability of principal component analysis in approximating the Hessian, with update parameters emerging as a superior choice over weights for this purpose. Remarkably, our findings unveil a similarity between the largest Hessian eigenvalues of individual layers and the entire network. Notably, higher eigenvalues are concentrated more in deeper layers. Leveraging these insights, we venture into addressing catastrophic forgetting, a challenge of neural networks when learning new tasks while retaining knowledge from previous ones. By applying our discoveries, we formulate an effective strategy to mitigate catastrophic forgetting, offering a possible solution that can be applied to networks of varying scales, including larger architectures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Form-follows-Function-Text-to-Text-Conditional-Graph-Generation-based-on-Functional-Requirements"><a href="#Form-follows-Function-Text-to-Text-Conditional-Graph-Generation-based-on-Functional-Requirements" class="headerlink" title="Form follows Function: Text-to-Text Conditional Graph Generation based on Functional Requirements"></a>Form follows Function: Text-to-Text Conditional Graph Generation based on Functional Requirements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00444">http://arxiv.org/abs/2311.00444</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Peter A. Zachares, Vahan Hovhannisyan, Alan Mosca, Yarin Gal</li>
<li>for: 本研究针对 conditioned on 图形函数需求下的图形生成问题进行了 novel 的设定。</li>
<li>methods: 我们将问题定义为文本到文本生成问题，并提出了一种基于预训练大型自然语言模型（LLM）的方法，通过 incorporating message passing layers into LLM 的架构来增加图形结构信息。</li>
<li>results: 我们设计了一系列公共available和广泛研究的分子和知识图数据集，以评估我们的提议方法。结果表明，我们的方法可以更好地满足请求的函数需求，与类似任务的基线方法相比，具有 statistically significant 的差异。<details>
<summary>Abstract</summary>
This work focuses on the novel problem setting of generating graphs conditioned on a description of the graph's functional requirements in a downstream task. We pose the problem as a text-to-text generation problem and focus on the approach of fine-tuning a pretrained large language model (LLM) to generate graphs. We propose an inductive bias which incorporates information about the structure of the graph into the LLM's generation process by incorporating message passing layers into an LLM's architecture. To evaluate our proposed method, we design a novel set of experiments using publicly available and widely studied molecule and knowledge graph data sets. Results suggest our proposed approach generates graphs which more closely meet the requested functional requirements, outperforming baselines developed on similar tasks by a statistically significant margin.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Crop-Disease-Classification-using-Support-Vector-Machines-with-Green-Chromatic-Coordinate-GCC-and-Attention-based-feature-extraction-for-IoT-based-Smart-Agricultural-Applications"><a href="#Crop-Disease-Classification-using-Support-Vector-Machines-with-Green-Chromatic-Coordinate-GCC-and-Attention-based-feature-extraction-for-IoT-based-Smart-Agricultural-Applications" class="headerlink" title="Crop Disease Classification using Support Vector Machines with Green Chromatic Coordinate (GCC) and Attention based feature extraction for IoT based Smart Agricultural Applications"></a>Crop Disease Classification using Support Vector Machines with Green Chromatic Coordinate (GCC) and Attention based feature extraction for IoT based Smart Agricultural Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00429">http://arxiv.org/abs/2311.00429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashwat Jha, Vishvaditya Luhach, Gauri Shanker Gupta, Beependra Singh</li>
<li>For: 农民可以快速和准确地识别作物疾病，保持农业产量和食品安全。* Methods: 使用注意力基于的特征提取，RGB通道基于的色彩分析，支持向量机（SVM）等机器学习和深度学习算法，并可以与移动应用程序和物联网设备集成。* Results: 提出一种新的分类方法，基于先前的研究，使用注意力基于的特征提取、RGB通道基于的色彩分析、SVM等算法，并可以与移动应用程序和物联网设备集成，并且在准确率方面与其他算法相比，达到了99.69%的精度。<details>
<summary>Abstract</summary>
Crops hold paramount significance as they serve as the primary provider of energy, nutrition, and medicinal benefits for the human population. Plant diseases, however, can negatively affect leaves during agricultural cultivation, resulting in significant losses in crop output and economic value. Therefore, it is crucial for farmers to identify crop diseases. However, this method frequently necessitates hard work, a lot of planning, and in-depth familiarity with plant pathogens. Given these numerous obstacles, it is essential to provide solutions that can easily interface with mobile and IoT devices so that our farmers can guarantee the best possible crop development. Various machine learning (ML) as well as deep learning (DL) algorithms have been created & studied for the identification of plant disease detection, yielding substantial and promising results. This article presents a novel classification method that builds on prior work by utilising attention-based feature extraction, RGB channel-based chromatic analysis, Support Vector Machines (SVM) for improved performance, and the ability to integrate with mobile applications and IoT devices after quantization of information. Several disease classification algorithms were compared with the suggested model, and it was discovered that, in terms of accuracy, Vision Transformer-based feature extraction and additional Green Chromatic Coordinate feature with SVM classification achieved an accuracy of (GCCViT-SVM) - 99.69%, whereas after quantization for IoT device integration achieved an accuracy of - 97.41% while almost reducing 4x in size. Our findings have profound implications because they have the potential to transform how farmers identify crop illnesses with precise and fast information, thereby preserving agricultural output and ensuring food security.
</details>
<details>
<summary>摘要</summary>
This article presents a novel classification method that leverages attention-based feature extraction, RGB channel-based chromatic analysis, and Support Vector Machines (SVM) for improved performance. The method also has the ability to integrate with mobile applications and IoT devices after quantization of information. Several disease classification algorithms were compared with the proposed model, and the results showed that the Vision Transformer-based feature extraction and additional Green Chromatic Coordinate feature with SVM classification achieved an accuracy of 99.69%, while the quantized model achieved an accuracy of 97.41% with a reduction of almost 4x in size.These findings have significant implications for the agricultural industry, as they have the potential to revolutionize how farmers identify crop diseases with precise and fast information, ensuring food security and preserving agricultural output.
</details></li>
</ul>
<hr>
<h2 id="NEO-KD-Knowledge-Distillation-Based-Adversarial-Training-for-Robust-Multi-Exit-Neural-Networks"><a href="#NEO-KD-Knowledge-Distillation-Based-Adversarial-Training-for-Robust-Multi-Exit-Neural-Networks" class="headerlink" title="NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks"></a>NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust Multi-Exit Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00428">http://arxiv.org/abs/2311.00428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seokil Ham, Jungwuk Park, Dong-Jun Han, Jaekyun Moon</li>
<li>for: 本研究旨在提高多出口神经网络对 adversarial 攻击的鲜度，通过使用知识塑造技术进行 adversarial 训练策略。</li>
<li>methods: 本研究提出了两个关键贡献：首先，通过邻域知识塑造引导对 adversarial 示例的输出倾向于clean数据 ensemble outputs的邻居exit outputs；其次，使用 exit-wise 对称知识塑造来减少对不同子模型的 adversarial 传递性。</li>
<li>results: 实验结果表明， compared to基于现有 adversarial training 或知识塑造技术的基eline，我们的方法在不同的数据集&#x2F;模型上 achieve the best adversarial accuracy with reduced computation budgets。<details>
<summary>Abstract</summary>
While multi-exit neural networks are regarded as a promising solution for making efficient inference via early exits, combating adversarial attacks remains a challenging problem. In multi-exit networks, due to the high dependency among different submodels, an adversarial example targeting a specific exit not only degrades the performance of the target exit but also reduces the performance of all other exits concurrently. This makes multi-exit networks highly vulnerable to simple adversarial attacks. In this paper, we propose NEO-KD, a knowledge-distillation-based adversarial training strategy that tackles this fundamental challenge based on two key contributions. NEO-KD first resorts to neighbor knowledge distillation to guide the output of the adversarial examples to tend to the ensemble outputs of neighbor exits of clean data. NEO-KD also employs exit-wise orthogonal knowledge distillation for reducing adversarial transferability across different submodels. The result is a significantly improved robustness against adversarial attacks. Experimental results on various datasets/models show that our method achieves the best adversarial accuracy with reduced computation budgets, compared to the baselines relying on existing adversarial training or knowledge distillation techniques for multi-exit networks.
</details>
<details>
<summary>摘要</summary>
多出口神经网络被视为减少推理成本的有前途的解决方案，但是抗击敌方攻击仍然是一个困难的问题。在多出口网络中，由于不同子模型之间的高度依赖关系，攻击一个特定的出口不仅会降低该出口的性能，而且同时降低所有其他出口的性能。这使得多出口网络对简单的敌方攻击非常敏感。在这篇论文中，我们提出了NEO-KD，基于知识塑造的对抗训练策略，以解决这一基本挑战。NEO-KD首先通过邻居知识塑造引导攻击样本的输出倾向于净数据邻居出口的 ensemble 输出。NEO-KD还使用出口wise ortogonal knowledge塑造来降低攻击传播性 across 不同子模型。这使得我们的方法在不同的数据集/模型上实现了显著提高的对抗性。实验结果表明，我们的方法在计算预算下可以实现最好的对抗精度，相比于基于现有的对抗训练或知识塑造技术的基eline。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-quantification-and-out-of-distribution-detection-using-surjective-normalizing-flows"><a href="#Uncertainty-quantification-and-out-of-distribution-detection-using-surjective-normalizing-flows" class="headerlink" title="Uncertainty quantification and out-of-distribution detection using surjective normalizing flows"></a>Uncertainty quantification and out-of-distribution detection using surjective normalizing flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00377">http://arxiv.org/abs/2311.00377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/irmlma/uncertainty-quantification-snf">https://github.com/irmlma/uncertainty-quantification-snf</a></li>
<li>paper_authors: Simon Dirmeier, Ye Hong, Yanan Xin, Fernando Perez-Cruz</li>
<li>for: 这篇论文的目的是提出一个简单的方法来量化深度学习模型中的知识型和几率型不确定性，以便应用在实际应用中，例如气候科学或 mobilty 分析。</li>
<li>methods: 这篇论文使用了surjective normalizing flows来识别深度学习模型中的非标准数据集，这可以在单一的前进中进行计算。这个方法建基于最近的深度不确定性量化和生成模型中的normalizing flows。</li>
<li>results: 作者将方法应用到一个人工合成的数据集和一些从 intervenational 分布中导出的数据集上，并证明了这个方法可靠地分辨出内部数据集和外部数据集。作者与Dirichlet 过程混合模型和bijective flow进行比较，发现surjective flow模型是关键的 ком成分，可以可靠地分辨内部数据集和外部数据集。<details>
<summary>Abstract</summary>
Reliable quantification of epistemic and aleatoric uncertainty is of crucial importance in applications where models are trained in one environment but applied to multiple different environments, often seen in real-world applications for example, in climate science or mobility analysis. We propose a simple approach using surjective normalizing flows to identify out-of-distribution data sets in deep neural network models that can be computed in a single forward pass. The method builds on recent developments in deep uncertainty quantification and generative modeling with normalizing flows. We apply our method to a synthetic data set that has been simulated using a mechanistic model from the mobility literature and several data sets simulated from interventional distributions induced by soft and atomic interventions on that model, and demonstrate that our method can reliably discern out-of-distribution data from in-distribution data. We compare the surjective flow model to a Dirichlet process mixture model and a bijective flow and find that the surjections are a crucial component to reliably distinguish in-distribution from out-of-distribution data.
</details>
<details>
<summary>摘要</summary>
可靠地量化知识型和随机型uncertainty在应用中是非常重要的，特别是在模型在多个环境中训练后应用于多个不同的环境中，例如气候科学或者流动分析。我们提出了一种简单的方法，使用射影正则化流来在深度神经网络模型中标识不同环境中的数据集。该方法基于深度不确定性评估和生成模型的正则化流的最新发展。我们在一个人工生成的数据集和一些基于软件和原子性改变的数据集上应用了我们的方法，并证明了我们的方法可靠地将不同环境中的数据集分为准确和不准确两类。我们与 Dirichlet 过程混合模型和 bijection 流进行比较，发现射影流模型是重要的组成部分，可以可靠地分辨在 Distribution 和 out-of-distribution 数据之间。
</details></li>
</ul>
<hr>
<h2 id="Performance-Optimization-of-Deep-Learning-Sparse-Matrix-Kernels-on-Intel-Max-Series-GPU"><a href="#Performance-Optimization-of-Deep-Learning-Sparse-Matrix-Kernels-on-Intel-Max-Series-GPU" class="headerlink" title="Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel Max Series GPU"></a>Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel Max Series GPU</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00368">http://arxiv.org/abs/2311.00368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Zubair, Christoph Bauinger</li>
<li>for: 这个论文主要关注三种稀疏矩阵运算，它们在机器学习应用中非常重要，即稀疏矩阵乘法（SPMM）、采样稀疏矩阵乘法（SDDMM）以及这两者的融合（FusedMM）。</li>
<li>methods: 作者们开发了优化的实现方法，使用Intel oneAPI的显式SIMD（ESIMD）SYCL扩展API来实现SPMM、SDDMM和FusedMM操作。与CUDA或SYCL不同，ESIMD API允许编写显式vector化的kernel代码。</li>
<li>results: 作者们的实现方法在目标Intel数据中心GPU上达到了 peak性能，并与Intel oneMKL库在Intel GPU上的性能相比，以及NVIDIA V100 GPU上的一个最近CUDA实现相比， demonstrate that their implementations of sparse matrix operations outperform either.<details>
<summary>Abstract</summary>
In this paper, we focus on three sparse matrix operations that are relevant for machine learning applications, namely, the sparse-dense matrix multiplication (SPMM), the sampled dense-dense matrix multiplication (SDDMM), and the composition of the SDDMM with SPMM, also termed as FusedMM. We develop optimized implementations for SPMM, SDDMM, and FusedMM operations utilizing Intel oneAPI's Explicit SIMD (ESIMD) SYCL extension API. In contrast to CUDA or SYCL, the ESIMD API enables the writing of explicitly vectorized kernel code. Sparse matrix algorithms implemented with the ESIMD API achieved performance close to the peak of the targeted Intel Data Center GPU. We compare our performance results to Intel's oneMKL library on Intel GPUs and to a recent CUDA implementation for the sparse matrix operations on NVIDIA's V100 GPU and demonstrate that our implementations for sparse matrix operations outperform either.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们关注了三种稀疏矩阵操作，即稀疏积分矩阵（SPMM）、采样积分积分矩阵（SDDMM）以及这两者的融合（FusedMM）。我们开发了优化的实现方法，使用 intel oneAPI 的显式 SIMD（ESIMD） SYCL 扩展 API。与 CUDA 或 SYCL 不同，ESIMD API 允许我们编写明确的向量化kernel代码。我们使用 ESIMD API 实现的稀疏矩阵算法在目标 Intel 数据中心 GPU 上达到了 peak 性能。我们对 intel oneMKL 库在 intel GPU 上的性能进行比较，以及 NVIDIA V100 GPU 上的一个最近的 CUDA 实现，并证明了我们的稀疏矩阵操作实现的性能高于其他任何一个。
</details></li>
</ul>
<hr>
<h2 id="Adversarially-Robust-Distributed-Count-Tracking-via-Partial-Differential-Privacy"><a href="#Adversarially-Robust-Distributed-Count-Tracking-via-Partial-Differential-Privacy" class="headerlink" title="Adversarially Robust Distributed Count Tracking via Partial Differential Privacy"></a>Adversarially Robust Distributed Count Tracking via Partial Differential Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00346">http://arxiv.org/abs/2311.00346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongzheng Xiong, Xiaoyi Zhu, Zengfeng Huang</li>
<li>for: 本文研究分布式跟踪模型（即分布式功能监控），其中有 $k$ 个站点，每个站点接收一条流量，并与中央服务器进行交互。服务器需要不断地跟踪所有流量的函数，以最小化交互成本。</li>
<li>methods: 本文使用了随机化算法，但是现有的随机化算法假设了“无知敌对”（oblivious adversary），即敌对方可以在算法开始前完全构建整个输入流。在这种情况下，我们考虑了适应性敌对方，即敌对方可以根据前一次答案选择新的输入项。 deterministic 算法是对适应性敌对方的robust，而随机化算法可能不是。我们 investigate 是随机化算法的 $\sqrt{k}$ 优势来自于随机性本身，还是因为无知敌对假设。</li>
<li>results: 我们提供了一个robust algorithm，其communication cost是 deterministic 算法的lower bound。 existing robustification techniques 不能实现optimal bounds，因为分布式问题的特殊性。 To address this, we extend the differential privacy framework by introducing “partial differential privacy” and proving a new generalization theorem. This theorem may have broader applications beyond robust count tracking, making it of independent interest.<details>
<summary>Abstract</summary>
We study the distributed tracking model, also known as distributed functional monitoring. This model involves $k$ sites each receiving a stream of items and communicating with the central server. The server's task is to track a function of all items received thus far continuously, with minimum communication cost. For count tracking, it is known that there is a $\sqrt{k}$ gap in communication between deterministic and randomized algorithms. However, existing randomized algorithms assume an "oblivious adversary" who constructs the entire input streams before the algorithm starts. Here we consider adaptive adversaries who can choose new items based on previous answers from the algorithm. Deterministic algorithms are trivially robust to adaptive adversaries, while randomized ones may not. Therefore, we investigate whether the $\sqrt{k}$ advantage of randomized algorithms is from randomness itself or the oblivious adversary assumption. We provide an affirmative answer to this question by giving a robust algorithm with optimal communication. Existing robustification techniques do not yield optimal bounds due to the inherent challenges of the distributed nature of the problem. To address this, we extend the differential privacy framework by introducing "partial differential privacy" and proving a new generalization theorem. This theorem may have broader applications beyond robust count tracking, making it of independent interest.
</details>
<details>
<summary>摘要</summary>
我们研究分布式跟踪模型，也称为分布式功能监测。这个模型中，有 $k$ 个站点，每个站点接收一束项目并与中央服务器进行交流。服务器的任务是不断跟踪所有项目的函数，以最小化交流成本。对于计数跟踪，已知存在 $\sqrt{k}$ 的交流差异 между deterministic 和 randomized 算法。然而，现有的 randomized 算法假设了一个 "无知敌手"（oblivious adversary），该敌手在算法开始之前构建整个输入流。在这里，我们考虑 adaptive 敌手，该敌手可以根据先前答案选择新的项目。deterministic 算法对 adaptive 敌手是可以逆转的，而 randomized 算法可能不是。因此，我们研究是 randomized 算法的 $\sqrt{k}$ 优势来自于随机性本身，还是 oblivious adversary 假设。我们提供了一个有optimal communication的robust算法，现有的 robustification 技术不能实现optimal bounds，因为分布式问题的特殊性。为解决这一点，我们扩展了 differential privacy 框架，引入 "partial differential privacy"，并证明一个新的总则。这个总则可能有更广泛的应用，因此是独立的兴趣。
</details></li>
</ul>
<hr>
<h2 id="The-Open-DAC-2023-Dataset-and-Challenges-for-Sorbent-Discovery-in-Direct-Air-Capture"><a href="#The-Open-DAC-2023-Dataset-and-Challenges-for-Sorbent-Discovery-in-Direct-Air-Capture" class="headerlink" title="The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct Air Capture"></a>The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct Air Capture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00341">http://arxiv.org/abs/2311.00341</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Open-Catalyst-Project/ocp">https://github.com/Open-Catalyst-Project/ocp</a></li>
<li>paper_authors: Anuroop Sriram, Sihoon Choi, Xiaohan Yu, Logan M. Brabson, Abhishek Das, Zachary Ulissi, Matt Uyttendaele, Andrew J. Medford, David S. Sholl</li>
<li>for: 这个论文是为了开发新的碳排放除去技术，以适应全球气候变化的挑战。</li>
<li>methods: 该论文使用计算机方法，利用最新的机器学习技术（ML），对8800种金属组合物框架（MOF）进行了超过38亿次密度函数理论计算（DFT）。</li>
<li>results: 该论文提供了一个名为Open DAC 2023（ODAC23）的开源数据集，包含了38亿次DFT计算，并经过了深入分析，从而提取了MOF材料的特性。此外，该论文还使用了最新的ML模型，以估计DFT计算的结果。<details>
<summary>Abstract</summary>
New methods for carbon dioxide removal are urgently needed to combat global climate change. Direct air capture (DAC) is an emerging technology to capture carbon dioxide directly from ambient air. Metal-organic frameworks (MOFs) have been widely studied as potentially customizable adsorbents for DAC. However, discovering promising MOF sorbents for DAC is challenging because of the vast chemical space to explore and the need to understand materials as functions of humidity and temperature. We explore a computational approach benefiting from recent innovations in machine learning (ML) and present a dataset named Open DAC 2023 (ODAC23) consisting of more than 38M density functional theory (DFT) calculations on more than 8,800 MOF materials containing adsorbed CO2 and/or H2O. ODAC23 is by far the largest dataset of MOF adsorption calculations at the DFT level of accuracy currently available. In addition to probing properties of adsorbed molecules, the dataset is a rich source of information on structural relaxation of MOFs, which will be useful in many contexts beyond specific applications for DAC. A large number of MOFs with promising properties for DAC are identified directly in ODAC23. We also trained state-of-the-art ML models on this dataset to approximate calculations at the DFT level. This open-source dataset and our initial ML models will provide an important baseline for future efforts to identify MOFs for a wide range of applications, including DAC.
</details>
<details>
<summary>摘要</summary>
新的碳排放除去方法urgently需要来 combat global climatic change。直接空气 capture（DAC）是一种emerging technology to capture碳排放 directly from ambient air。 Metal-organic frameworks（MOFs）have been widely studied as potentially customizable adsorbents for DAC。However，discovering promising MOF sorbents for DAC is challenging because of the vast chemical space to explore and the need to understand materials as functions of humidity and temperature。We explore a computational approach benefiting from recent innovations in machine learning（ML）and present a dataset named Open DAC 2023（ODAC23）consisting of more than 38M density functional theory（DFT）calculations on more than 8,800 MOF materials containing adsorbed CO2 and/or H2O。ODAC23 is by far the largest dataset of MOF adsorption calculations at the DFT level of accuracy currently available。In addition to probing properties of adsorbed molecules，the dataset is a rich source of information on structural relaxation of MOFs，which will be useful in many contexts beyond specific applications for DAC。A large number of MOFs with promising properties for DAC are identified directly in ODAC23。We also trained state-of-the-art ML models on this dataset to approximate calculations at the DFT level。This open-source dataset and our initial ML models will provide an important baseline for future efforts to identify MOFs for a wide range of applications，including DAC。
</details></li>
</ul>
<hr>
<h2 id="Latent-Space-Inference-For-Spatial-Transcriptomics"><a href="#Latent-Space-Inference-For-Spatial-Transcriptomics" class="headerlink" title="Latent Space Inference For Spatial Transcriptomics"></a>Latent Space Inference For Spatial Transcriptomics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00330">http://arxiv.org/abs/2311.00330</a></li>
<li>repo_url: None</li>
<li>paper_authors: J. Ding, S. N. Zaman, P. Y. Chen, D. Wang</li>
<li>for: 这个研究旨在解决单细胞RNA测序和图像基于的空间转录组学数据的问题，即同时获取细胞表达信息和其 spatial坐标。</li>
<li>methods: 这个研究使用机器学习方法，具体来说是可变机器学习方法，将单细胞RNA测序和图像基于的空间转录组学数据映射到共同的假设空间表示中。</li>
<li>results: 研究发现，通过将这两种数据映射到共同的假设空间表示中，可以同时获取细胞表达信息和其 spatial坐标，从而为我们带来更深刻的理解细胞生物学过程和路径way.<details>
<summary>Abstract</summary>
In order to understand the complexities of cellular biology, researchers are interested in two important metrics: the genetic expression information of cells and their spatial coordinates within a tissue sample. However, state-of-the art methods, namely single-cell RNA sequencing and image based spatial transcriptomics can only recover a subset of this information, either full genetic expression with loss of spatial information, or spatial information with loss of resolution in sequencing data. In this project, we investigate a probabilistic machine learning method to obtain the full genetic expression information for tissues samples while also preserving their spatial coordinates. This is done through mapping both datasets to a joint latent space representation with the use of variational machine learning methods. From here, the full genetic and spatial information can be decoded and to give us greater insights on the understanding of cellular processes and pathways.
</details>
<details>
<summary>摘要</summary>
为了理解细胞生物学中的复杂性，研究人员对两个重要指标感兴趣：细胞的遗传表达信息和它们在组织样本中的空间坐标。然而，现有的技术，即单细胞RNA扩增和图像基于的空间转录组学，只能回归一部分这些信息，即全遗传表达信息的损失或图像数据中的分辨率损失。在本项目中，我们研究一种概率机器学习方法，以获取组织样本中的全遗传表达信息，同时保持它们的空间坐标。我们通过将两个数据集映射到共同的假设空间表示中，使用变分机器学习方法来实现这一目标。从这里，我们可以解码全遗传和空间信息，以提供更深刻的细胞生物学过程和 PATHway 的理解。
</details></li>
</ul>
<hr>
<h2 id="Multi-task-Representation-Learning-for-Pure-Exploration-in-Bilinear-Bandits"><a href="#Multi-task-Representation-Learning-for-Pure-Exploration-in-Bilinear-Bandits" class="headerlink" title="Multi-task Representation Learning for Pure Exploration in Bilinear Bandits"></a>Multi-task Representation Learning for Pure Exploration in Bilinear Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00327">http://arxiv.org/abs/2311.00327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subhojyoti Mukherjee, Qiaomin Xie, Josiah P. Hanna, Robert Nowak</li>
<li>for: 本文研究了多任务表示学习 Bilinear Bandit 中的纯探索问题。</li>
<li>methods: 本文提出了一种名为 GOBLIN 的算法，使用实验设计方法来优化样本分配以学习全局表示，并最小化每个任务中的样本数量来确定优化的对象。</li>
<li>results: 本文的结果表明，通过共享表示来加速找到每个任务中的优化对象，可以减少样本数量，比传统独立解决每个任务的方法更有效。<details>
<summary>Abstract</summary>
We study multi-task representation learning for the problem of pure exploration in bilinear bandits. In bilinear bandits, an action takes the form of a pair of arms from two different entity types and the reward is a bilinear function of the known feature vectors of the arms. In the \textit{multi-task bilinear bandit problem}, we aim to find optimal actions for multiple tasks that share a common low-dimensional linear representation. The objective is to leverage this characteristic to expedite the process of identifying the best pair of arms for all tasks. We propose the algorithm GOBLIN that uses an experimental design approach to optimize sample allocations for learning the global representation as well as minimize the number of samples needed to identify the optimal pair of arms in individual tasks. To the best of our knowledge, this is the first study to give sample complexity analysis for pure exploration in bilinear bandits with shared representation. Our results demonstrate that by learning the shared representation across tasks, we achieve significantly improved sample complexity compared to the traditional approach of solving tasks independently.
</details>
<details>
<summary>摘要</summary>
我们研究多任务表示学习 Bilinear bandits 中的纯探索问题。在 Bilinear bandits 中，一个动作是两个不同类型的 arm 的对，奖励是两个known feature vector 的 bilinear函数。在多任务 Bilinear bandit 问题中，我们目标是找到多个任务共享的低维度线性表示，并利用这个特点来快速确定所有任务的最佳对。我们提出了 GOBLIN 算法，使用实验设计方法来优化样本分配以学习全局表示，以及最小化每个任务中的样本数量。根据我们所知，这是首次对 Bilinear bandits 中纯探索问题进行样本复杂度分析的研究。我们的结果表明，通过学习共享表示，我们可以在每个任务中实现明显改善的样本复杂度。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Hearing-Programming-Acoustic-Scenes-with-Binaural-Hearables"><a href="#Semantic-Hearing-Programming-Acoustic-Scenes-with-Binaural-Hearables" class="headerlink" title="Semantic Hearing: Programming Acoustic Scenes with Binaural Hearables"></a>Semantic Hearing: Programming Acoustic Scenes with Binaural Hearables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00320">http://arxiv.org/abs/2311.00320</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bandhav Veluri, Malek Itani, Justin Chan, Takuya Yoshioka, Shyamnath Gollakota</li>
<li>for: 该研究旨在开发一种新的听众设备功能，即在实时中听取或忽略实际环境中的特定声音，而不会干扰其他声音。</li>
<li>methods: 该研究使用了两个技术贡献：1）提出了首个能够在干扰声音和背景噪声存在的情况下实现拟声音提取的神经网络，2）设计了一种可以在实际世界中普遍化的训练方法。</li>
<li>results: 研究结果表明，该系统可以处理20种声音类型，并且在连接式手机上实现了6.56毫秒的运行时间。在实际生活中进行的评估中，证明了该系统可以提取目标声音并保持它们的空间cue。项目页面与代码：<a target="_blank" rel="noopener" href="https://semantichearing.cs.washington.edu/">https://semantichearing.cs.washington.edu</a><details>
<summary>Abstract</summary>
Imagine being able to listen to the birds chirping in a park without hearing the chatter from other hikers, or being able to block out traffic noise on a busy street while still being able to hear emergency sirens and car honks. We introduce semantic hearing, a novel capability for hearable devices that enables them to, in real-time, focus on, or ignore, specific sounds from real-world environments, while also preserving the spatial cues. To achieve this, we make two technical contributions: 1) we present the first neural network that can achieve binaural target sound extraction in the presence of interfering sounds and background noise, and 2) we design a training methodology that allows our system to generalize to real-world use. Results show that our system can operate with 20 sound classes and that our transformer-based network has a runtime of 6.56 ms on a connected smartphone. In-the-wild evaluation with participants in previously unseen indoor and outdoor scenarios shows that our proof-of-concept system can extract the target sounds and generalize to preserve the spatial cues in its binaural output. Project page with code: https://semantichearing.cs.washington.edu
</details>
<details>
<summary>摘要</summary>
想像你可以在公园中听到鸟叫，而不听到其他游客的喊喊叫，或者在忙街上听到交通噪音，而快速听到紧急警 siren 和车 horn。我们引入semantic hearing，一种新的能力 для智能听众设备，允许它们在实时中，选择性地听到或忽略来自实际环境中的具体声音，而不失去声学位置信息。为了实现这一目标，我们做出了两项技术贡献：1. 我们提出了第一个能够在干扰声和背景噪音的情况下进行针对声音抽取的 neural network，可以在实时中提取Target声音。2. 我们设计了一种可以在实际应用中通用的训练方法，使我们的系统能够在实际应用中泛化。结果表明，我们的系统可以处理20种声音类型，并且我们使用 transformer 网络的运行时间为6.56 ms。在实际场景中进行了审试，我们的证明系统可以提取Target声音并保持声学位置信息。项目页面与代码：https://semantichearing.cs.washington.eduNote: Simplified Chinese is used here, as it is the most widely used standard for Chinese writing.
</details></li>
</ul>
<hr>
<h2 id="Federated-Topic-Model-and-Model-Pruning-Based-on-Variational-Autoencoder"><a href="#Federated-Topic-Model-and-Model-Pruning-Based-on-Variational-Autoencoder" class="headerlink" title="Federated Topic Model and Model Pruning Based on Variational Autoencoder"></a>Federated Topic Model and Model Pruning Based on Variational Autoencoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00314">http://arxiv.org/abs/2311.00314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjie Ma, Yawen Li, Meiyu Liang, Ang Li</li>
<li>for: 本研究旨在提出一种 Federated Topic Model（FTM），以保护每个节点的隐私，并在多方合作训练模型时提高模型的性能。</li>
<li>methods: 本研究使用了Variational Autoencoder（VAE）来实现FTM，并提出了两种不同的方法来决定模型剪枝率。</li>
<li>results: 实验结果显示，基于VAE的FTM剪枝方法可以大幅提高模型训练速度，而不失其性能。<details>
<summary>Abstract</summary>
Topic modeling has emerged as a valuable tool for discovering patterns and topics within large collections of documents. However, when cross-analysis involves multiple parties, data privacy becomes a critical concern. Federated topic modeling has been developed to address this issue, allowing multiple parties to jointly train models while protecting pri-vacy. However, there are communication and performance challenges in the federated sce-nario. In order to solve the above problems, this paper proposes a method to establish a federated topic model while ensuring the privacy of each node, and use neural network model pruning to accelerate the model, where the client periodically sends the model neu-ron cumulative gradients and model weights to the server, and the server prunes the model. To address different requirements, two different methods are proposed to determine the model pruning rate. The first method involves slow pruning throughout the entire model training process, which has limited acceleration effect on the model training process, but can ensure that the pruned model achieves higher accuracy. This can significantly reduce the model inference time during the inference process. The second strategy is to quickly reach the target pruning rate in the early stage of model training in order to accelerate the model training speed, and then continue to train the model with a smaller model size after reaching the target pruning rate. This approach may lose more useful information but can complete the model training faster. Experimental results show that the federated topic model pruning based on the variational autoencoder proposed in this paper can greatly accelerate the model training speed while ensuring the model's performance.
</details>
<details>
<summary>摘要</summary>
通用主题模型在处理大量文档时发现模式和话题变得非常有用。然而，当跨分析包括多个方的情况下，数据隐私变得非常重要。联邦主题模型是为此目的而开发的，允许多个方共同训练模型，保护每个节点的隐私。然而，联邦场景中存在交流和性能问题。为解决以上问题，本文提出了一种方法，可以在多个节点之间共同训练模型，保证每个节点的隐私，并使用神经网络模型剪辑以加速模型训练。在客户端 periodic 发送模型神经元累积偏移和模型参数给服务器，服务器进行模型剪辑。为了应对不同的需求，本文提出了两种不同的方法来确定模型剪辑率。第一种方法是在整个模型训练过程中慢慢剪辑模型，可以在模型训练过程中有限度地加速模型训练，但是可以确保剪辑后的模型准确率高。这可以减少模型推理时间。第二种方法是在模型训练过程的早期 quickly 到达目标剪辑率，以加速模型训练速度，然后继续使用较小的模型大小进行模型训练。这种方法可能会产生更多的有用信息产生，但可以更快地完成模型训练。实验结果表明，基于变量自动encoder的联邦主题模型剪辑可以快速加速模型训练速度，保证模型性能。
</details></li>
</ul>
<hr>
<h2 id="Stacking-an-autoencoder-for-feature-selection-of-zero-day-threats"><a href="#Stacking-an-autoencoder-for-feature-selection-of-zero-day-threats" class="headerlink" title="Stacking an autoencoder for feature selection of zero-day threats"></a>Stacking an autoencoder for feature selection of zero-day threats</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00304">http://arxiv.org/abs/2311.00304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahmut Tokmak, Mike Nkongolo</li>
<li>For: This paper is written for researchers and practitioners in the field of cybersecurity, particularly those interested in zero-day attack detection and artificial neural networks.* Methods: The paper uses a stacked autoencoder (SAE) and a Long Short-Term Memory (LSTM) scheme for feature selection and zero-day threat classification. The SAE is used for unsupervised feature extraction, and the LSTM is used for supervised learning to enhance the model’s discriminative capabilities.* Results: The paper reports high precision, recall, and F1 score values for the SAE-LSTM model in identifying various types of zero-day attacks, and demonstrates strong predictive capabilities across all three attack categories. The balanced average scores suggest that the model generalizes effectively and consistently across different attack categories.Here’s the simplified Chinese text for the three key information points:* For: 这篇论文是为了针对安全领域的研究人员和实践者而写的，尤其是关注于零日攻击检测和人工神经网络。* Methods: 这篇论文使用了堆叠自动编码器（SAE）和长短期记忆（LSTM）方法来实现特征选择和零日威胁分类。 SAE 用于无监督特征提取，而 LSTM 用于监督学习以提高模型的识别能力。* Results: 论文报告了 SAELSTM 模型在不同类型的零日攻击上的高精度、回归率和 F1 分数值，并示出了模型在不同攻击类别之间的一致性和通用性。<details>
<summary>Abstract</summary>
Zero-day attack detection plays a critical role in mitigating risks, protecting assets, and staying ahead in the evolving threat landscape. This study explores the application of stacked autoencoder (SAE), a type of artificial neural network, for feature selection and zero-day threat classification using a Long Short-Term Memory (LSTM) scheme. The process involves preprocessing the UGRansome dataset and training an unsupervised SAE for feature extraction. Finetuning with supervised learning is then performed to enhance the discriminative capabilities of this model. The learned weights and activations of the autoencoder are analyzed to identify the most important features for discriminating between zero-day threats and normal system behavior. These selected features form a reduced feature set that enables accurate classification. The results indicate that the SAE-LSTM performs well across all three attack categories by showcasing high precision, recall, and F1 score values, emphasizing the model's strong predictive capabilities in identifying various types of zero-day attacks. Additionally, the balanced average scores of the SAE-LSTM suggest that the model generalizes effectively and consistently across different attack categories.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate("Zero-day attack detection plays a critical role in mitigating risks, protecting assets, and staying ahead in the evolving threat landscape. This study explores the application of stacked autoencoder (SAE), a type of artificial neural network, for feature selection and zero-day threat classification using a Long Short-Term Memory (LSTM) scheme. The process involves preprocessing the UGRansome dataset and training an unsupervised SAE for feature extraction. Finetuning with supervised learning is then performed to enhance the discriminative capabilities of this model. The learned weights and activations of the autoencoder are analyzed to identify the most important features for discriminating between zero-day threats and normal system behavior. These selected features form a reduced feature set that enables accurate classification. The results indicate that the SAE-LSTM performs well across all three attack categories by showcasing high precision, recall, and F1 score values, emphasizing the model's strong predictive capabilities in identifying various types of zero-day attacks. Additionally, the balanced average scores of the SAE-LSTM suggest that the model generalizes effectively and consistently across different attack categories.")]以下是文本的简化中文翻译： Zero-day 攻击检测在降低风险、保护资产和在演化的威胁领域中发挥关键角色。本研究探讨使用堆式自适应器（SAE），一种人工神经网络，来选择特征和预测 zero-day 威胁。该过程包括对 UGRansome 数据集进行预处理，并使用无监督 SAE 进行特征提取。然后，通过监督学习进行训练，以提高模型的推论能力。模型学习的权重和活动都被分析以确定最重要的特征，以便在预测 zero-day 威胁和正常系统行为之间进行分类。这些选择的特征组成了一个减少特征集，使得准确地进行分类。结果表明，SAE-LSTM 在三个攻击类别中都表现出色，具有高精度、 recall 和 F1 分数值，证明模型在不同的攻击类别中具有强的预测能力。此外，SAE-LSTM 的平衡平均分数表明，模型在不同的攻击类别中具有一致的泛化能力和一致性。
</details></li>
</ul>
<hr>
<h2 id="Model-driven-Engineering-for-Machine-Learning-Components-A-Systematic-Literature-Review"><a href="#Model-driven-Engineering-for-Machine-Learning-Components-A-Systematic-Literature-Review" class="headerlink" title="Model-driven Engineering for Machine Learning Components: A Systematic Literature Review"></a>Model-driven Engineering for Machine Learning Components: A Systematic Literature Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00284">http://arxiv.org/abs/2311.00284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hira Naveed, Chetan Arora, Hourieh Khalajzadeh, John Grundy, Omar Haggag</li>
<li>for: 本研究的目的是进一步探讨Model-Driven Engineering（MDE）与机器学习（ML）的交叉，通过系统性的文献综述（SLR）来分析现有的研究，包括他们的动机、MDE解决方案、评估技术、关键的利好和局限性。</li>
<li>methods: 本研究使用的方法包括对选择的研究进行分析，根据不同的问题领域进行分类和summarization，并对每个研究进行评估和分析。</li>
<li>results: 本研究的结果表明，使用MDE4ML可以提高开发效率、降低开发成本、提高系统可维护性和可扩展性等。但是，还存在一些局限性和挑战，需要进一步的研究和发展。<details>
<summary>Abstract</summary>
Context: Machine Learning (ML) has become widely adopted as a component in many modern software applications. Due to the large volumes of data available, organizations want to increasingly leverage their data to extract meaningful insights and enhance business profitability. ML components enable predictive capabilities, anomaly detection, recommendation, accurate image and text processing, and informed decision-making. However, developing systems with ML components is not trivial; it requires time, effort, knowledge, and expertise in ML, data processing, and software engineering. There have been several studies on the use of model-driven engineering (MDE) techniques to address these challenges when developing traditional software and cyber-physical systems. Recently, there has been a growing interest in applying MDE for systems with ML components. Objective: The goal of this study is to further explore the promising intersection of MDE with ML (MDE4ML) through a systematic literature review (SLR). Through this SLR, we wanted to analyze existing studies, including their motivations, MDE solutions, evaluation techniques, key benefits and limitations. Results: We analyzed selected studies with respect to several areas of interest and identified the following: 1) the key motivations behind using MDE4ML; 2) a variety of MDE solutions applied, such as modeling languages, model transformations, tool support, targeted ML aspects, contributions and more; 3) the evaluation techniques and metrics used; and 4) the limitations and directions for future work. We also discuss the gaps in existing literature and provide recommendations for future research. Conclusion: This SLR highlights current trends, gaps and future research directions in the field of MDE4ML, benefiting both researchers and practitioners
</details>
<details>
<summary>摘要</summary>
Machine Learning (ML) 已经成为现代软件应用中的一个重要组件。由于大量数据的可用性，组织希望通过数据来提取有意义的洞见和提高商业利润。 ML  ком�ponenets 提供预测功能、偏差检测、建议、精准的图像和文本处理，并帮助做出了解决策。然而，开发具有 ML  ком�ponenets 的系统不是易事；它需要时间、努力、知识和 ML、数据处理和软件工程的专家知识。过去，有关使用模型驱动工程（MDE）技术来解决这些挑战的研究已经很多。最近，关于应用 MDE for 系统 with ML  ком�ponenets 的研究则有所增加。目标：本研究的目标是进一步探索 MDE 与 ML （MDE4ML）的联合领域，通过系统性文献综述（SLR）。通过这个 SLR，我们想要分析选择的研究，包括他们的动机、MDE 解决方案、评估技术和 метри克、主要优点和局限性。结果：我们分析选择的研究，并评估他们在以下几个领域：1）使用 MDE4ML 的动机；2）MDE 解决方案的多样性，包括模型语言、模型转换、工具支持、针对 ML 方面的贡献等；3）评估技术和 метри克的使用；和4）限制和未来研究的方向。我们还讨论了现有文献中的潜在空白和未来研究的建议。结论：这个 SLR 显示了 MDE4ML 的现有趋势、缺点和未来研究的方向，对研究者和实践者都有帮助。
</details></li>
</ul>
<hr>
<h2 id="Generalization-Bounds-for-Label-Noise-Stochastic-Gradient-Descent"><a href="#Generalization-Bounds-for-Label-Noise-Stochastic-Gradient-Descent" class="headerlink" title="Generalization Bounds for Label Noise Stochastic Gradient Descent"></a>Generalization Bounds for Label Noise Stochastic Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00274">http://arxiv.org/abs/2311.00274</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jung Eun Huh, Patrick Rebeschini</li>
<li>for: This paper is written for those interested in understanding the generalization error bounds of stochastic gradient descent (SGD) with label noise in non-convex settings.</li>
<li>methods: The paper uses a combination of uniform dissipativity and smoothness conditions, as well as a suitable choice of semimetric, to establish a contraction in Wasserstein distance of the label noise stochastic gradient flow.</li>
<li>results: The paper derives time-independent generalization error bounds for the discretized algorithm with a constant learning rate, which scales polynomially with the parameter dimension $d$ and with the rate of $n^{-2&#x2F;3}$, where $n$ is the sample size. This rate is better than the best-known rate of $n^{-1&#x2F;2}$ established for stochastic gradient Langevin dynamics (SGLD) under similar conditions.<details>
<summary>Abstract</summary>
We develop generalization error bounds for stochastic gradient descent (SGD) with label noise in non-convex settings under uniform dissipativity and smoothness conditions. Under a suitable choice of semimetric, we establish a contraction in Wasserstein distance of the label noise stochastic gradient flow that depends polynomially on the parameter dimension $d$. Using the framework of algorithmic stability, we derive time-independent generalisation error bounds for the discretized algorithm with a constant learning rate. The error bound we achieve scales polynomially with $d$ and with the rate of $n^{-2/3}$, where $n$ is the sample size. This rate is better than the best-known rate of $n^{-1/2}$ established for stochastic gradient Langevin dynamics (SGLD) -- which employs parameter-independent Gaussian noise -- under similar conditions. Our analysis offers quantitative insights into the effect of label noise.
</details>
<details>
<summary>摘要</summary>
我们研究了批处理梯度下降（SGD）中标签噪声的总化误差上限在非对称 Setting下，并且在各种不同的semimetric下进行了选择。我们在标签噪声梯度流中确立了一个 Wasserstein 距离的减少，这个减少的程度取决于参数维度 $d$。使用算法稳定性框架，我们得到了一个时间独立的总化误差上限，这个上限与参数维度 $d$ 和学习率 $n$ 相乘。我们的分析提供了标签噪声的量化意见，并且我们的误差上限的速度与 $d$ 和 $n$ 相乘。这个速度比最好known的 $n^{-1/2}$ 更快，这个速度是在类似条件下使用参数独立的 Gaussian 噪声的SGLD中得到的。
</details></li>
</ul>
<hr>
<h2 id="Incentivized-Collaboration-in-Active-Learning"><a href="#Incentivized-Collaboration-in-Active-Learning" class="headerlink" title="Incentivized Collaboration in Active Learning"></a>Incentivized Collaboration in Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00260">http://arxiv.org/abs/2311.00260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lee Cohen, Han Shao</li>
<li>for: 这个论文是关于多个代理征learn标签的协同学习，即多个代理征试图从一个共同假设中学习标签。</li>
<li>methods: 作者引入了一种创新的协同学习框架，以便各代理征可以尽可能减少标签复杂性。他们聚焦于设计独立合理（IR）协同协议，以确保代理征不能通过单独行动减少其预期标签复杂性。</li>
<li>results: 作者首先表明，如果给定任何最佳活动学习算法，则与整个数据集进行协同学习即可保证IR协同协议。然而，计算最佳算法是NP困难的。因此，作者提供了一些IR协同协议，可以与最佳 tractable approximation algorithm 相比肩并减少标签复杂性。<details>
<summary>Abstract</summary>
In collaborative active learning, where multiple agents try to learn labels from a common hypothesis, we introduce an innovative framework for incentivized collaboration. Here, rational agents aim to obtain labels for their data sets while keeping label complexity at a minimum. We focus on designing (strict) individually rational (IR) collaboration protocols, ensuring that agents cannot reduce their expected label complexity by acting individually. We first show that given any optimal active learning algorithm, the collaboration protocol that runs the algorithm as is over the entire data is already IR. However, computing the optimal algorithm is NP-hard. We therefore provide collaboration protocols that achieve (strict) IR and are comparable with the best known tractable approximation algorithm in terms of label complexity.
</details>
<details>
<summary>摘要</summary>
协同活动学习中，多个代理尝试学习共同假设中的标签，我们提出了一种创新的协作框架，以增加代理的奖励。在这个框架中，合理的代理希望通过最小化标签复杂度来获得标签。我们主要关注设计（严格）个人合理（IR）的协作协议，以确保代理不能通过单独行动减少其预期标签复杂度。我们首先证明，任何优化的活动学习算法都可以通过整个数据集进行执行，而不需要进行协作。然而，计算优化算法是NP困难的。因此，我们提供了一些可比较于最佳可追踪算法的协作协议，以达到（严格）IR的目标，并且和最佳可追踪算法相比，标签复杂度减少的程度相对较小。
</details></li>
</ul>
<hr>
<h2 id="Active-Neural-Topological-Mapping-for-Multi-Agent-Exploration"><a href="#Active-Neural-Topological-Mapping-for-Multi-Agent-Exploration" class="headerlink" title="Active Neural Topological Mapping for Multi-Agent Exploration"></a>Active Neural Topological Mapping for Multi-Agent Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00252">http://arxiv.org/abs/2311.00252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyi Yang, Yuxiang Yang, Chao Yu, Jiayu Chen, Jingchen Yu, Haibing Ren, Huazhong Yang, Yu Wang<br>for: 多个自动机器人在未知环境中进行合作探索任务，需要在有限时间内利用感知信号完成探索任务。methods: 提出了一种基于神经网络的多自动机器人 topological mapping 技术，包括图像编码器和距离基于的优化技术，以及一种基于图 neural network 的层次嵌入式规划算法。results: 在一个 физи实验中，该技术可以在未seen scenario 下提高探索效率和普适性，比基于规划的基eline 下降至少 26.40%，并比基于RL的竞争对手下降至少 7.63%。<details>
<summary>Abstract</summary>
This paper investigates the multi-agent cooperative exploration problem, which requires multiple agents to explore an unseen environment via sensory signals in a limited time. A popular approach to exploration tasks is to combine active mapping with planning. Metric maps capture the details of the spatial representation, but are with high communication traffic and may vary significantly between scenarios, resulting in inferior generalization. Topological maps are a promising alternative as they consist only of nodes and edges with abstract but essential information and are less influenced by the scene structures. However, most existing topology-based exploration tasks utilize classical methods for planning, which are time-consuming and sub-optimal due to their handcrafted design. Deep reinforcement learning (DRL) has shown great potential for learning (near) optimal policies through fast end-to-end inference. In this paper, we propose Multi-Agent Neural Topological Mapping (MANTM) to improve exploration efficiency and generalization for multi-agent exploration tasks. MANTM mainly comprises a Topological Mapper and a novel RL-based Hierarchical Topological Planner (HTP). The Topological Mapper employs a visual encoder and distance-based heuristics to construct a graph containing main nodes and their corresponding ghost nodes. The HTP leverages graph neural networks to capture correlations between agents and graph nodes in a coarse-to-fine manner for effective global goal selection. Extensive experiments conducted in a physically-realistic simulator, Habitat, demonstrate that MANTM reduces the steps by at least 26.40% over planning-based baselines and by at least 7.63% over RL-based competitors in unseen scenarios.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文研究了多个机器人合作探索问题，它们需要在未知环境中通过感知信号在有限时间内进行探索。现有的探索任务的办法是将活动地图与规划结合使用。度量地图捕捉了环境的细节信息，但是它们可能因为enario的变化而导致普遍性下降。而图像地图则是一种有前途的替代方案，它只包含节点和边，并且通过距离基于的优化来构建图像。但是大多数现有的图像基于的探索任务仍然使用经典的规划方法，这些方法可能是时间消耗和不优化的。深度强化学习（DRL）已经显示出了学习（近似）优化政策的潜力，而这些政策可以通过快速的终端推理来实现。在这篇论文中，我们提出了多机器人神经图像映射（MANTM），以提高探索效率和普遍性。MANTM主要包括一个图像映射器和一个基于RL的层次图像规划器（HTP）。图像映射器使用视觉编码器和距离基于的优化来构建包含主节点和其对应的鬼节点的图像。HTP利用图像神经网络来捕捉多个机器人和图像节点之间的相互关系，并在层次结构中进行有效的全局目标选择。在Habitat simulator中进行了广泛的实验，表明MANTM可以比基于规划的基准解决方案减少步骤数少于26.40%，并且比基于RL的竞争对手减少步骤数少于7.63%。
</details></li>
</ul>
<hr>
<h2 id="DistDNAS-Search-Efficient-Feature-Interactions-within-2-Hours"><a href="#DistDNAS-Search-Efficient-Feature-Interactions-within-2-Hours" class="headerlink" title="DistDNAS: Search Efficient Feature Interactions within 2 Hours"></a>DistDNAS: Search Efficient Feature Interactions within 2 Hours</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00231">http://arxiv.org/abs/2311.00231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tunhou Zhang, Wei Wen, Igor Fedorov, Xi Liu, Buyun Zhang, Fangqiu Han, Wen-Yen Chen, Yiping Han, Feng Yan, Hai Li, Yiran Chen</li>
<li>for: 提高推荐系统的搜索效率和服务效率</li>
<li>methods: 使用DistDNAS策略，即在不同的数据日期上分布搜索优化交互模块，以及引入可导 differentiable cost-aware损失函数来优化服务效率</li>
<li>results: 在一个1TB的Criteo Terabyte dataset上进行了广泛的实验评估，结果显示DistDNAS可以提高0.001的AUC和60%的FLOPs，比当前状态艺术CTR模型更好。<details>
<summary>Abstract</summary>
Search efficiency and serving efficiency are two major axes in building feature interactions and expediting the model development process in recommender systems. On large-scale benchmarks, searching for the optimal feature interaction design requires extensive cost due to the sequential workflow on the large volume of data. In addition, fusing interactions of various sources, orders, and mathematical operations introduces potential conflicts and additional redundancy toward recommender models, leading to sub-optimal trade-offs in performance and serving cost. In this paper, we present DistDNAS as a neat solution to brew swift and efficient feature interaction design. DistDNAS proposes a supernet to incorporate interaction modules of varying orders and types as a search space. To optimize search efficiency, DistDNAS distributes the search and aggregates the choice of optimal interaction modules on varying data dates, achieving over 25x speed-up and reducing search cost from 2 days to 2 hours. To optimize serving efficiency, DistDNAS introduces a differentiable cost-aware loss to penalize the selection of redundant interaction modules, enhancing the efficiency of discovered feature interactions in serving. We extensively evaluate the best models crafted by DistDNAS on a 1TB Criteo Terabyte dataset. Experimental evaluations demonstrate 0.001 AUC improvement and 60% FLOPs saving over current state-of-the-art CTR models.
</details>
<details>
<summary>摘要</summary>
搜索效率和服务效率是建立功能互动和加速模型开发过程中的两大轴心。在大规模的参考数据上，搜索到最佳功能互动设计需要很大的成本，因为搜索工作流程需要遍历大量数据。此外，将来自不同来源、顺序和mathematical operations的互动组合导致推荐模型中的冲突和额外累累，从而导致性能和服务成本的折冲。在本文中，我们提出了DistDNAS作为一个简单的解决方案，它透过建立互动模组的supernet，实现了快速和高效的功能互动设计。DistDNAS通过分布搜索和聚合选择最佳互动模组的选择，实现了25倍的速度提升和从2天缩短为2小时的搜索成本。此外，DistDNAS引入了一个可微的成本警示loss，以惩罚选择重复的互动模组，提高发现的功能互动效率。我们对1TB Criteo Terabyte数据集进行了广泛的实验评估，结果显示了0.001 AUC提升和60% FLOPs节省，较前瞻性的CTR模型。
</details></li>
</ul>
<hr>
<h2 id="Transformers-are-Efficient-In-Context-Estimators-for-Wireless-Communication"><a href="#Transformers-are-Efficient-In-Context-Estimators-for-Wireless-Communication" class="headerlink" title="Transformers are Efficient In-Context Estimators for Wireless Communication"></a>Transformers are Efficient In-Context Estimators for Wireless Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00226">http://arxiv.org/abs/2311.00226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vicram Rajagopalan, Vishnu Teja Kunde, Chandra Shekhara Kaushik Valmeekam, Krishna Narayanan, Srinivas Shakkottai, Dileep Kalathil, Jean-Francois Chamberland</li>
<li>for: 这个论文的目的是提出一种基于听说器的听说符 estimation 方法，用于解决通信问题中的 transmitted symbols 估计问题。</li>
<li>methods: 这个方法使用了 transformers 来完成听说符 estimation，通过利用 pilots 来进行 end-to-end 的听说符 estimation，并且使用 transformers 的听说序列完成功能来提取信息。</li>
<li>results: 经过广泛的 simulations，这个方法不仅可以达到标准方法的性能水平，还可以在几个 context 示例后达到同样的性能水平，这表明 transformers 是一种高效的 in-context 估计器在通信设置下。<details>
<summary>Abstract</summary>
Pre-trained transformers can perform in-context learning, where they adapt to a new task using only a small number of prompts without any explicit model optimization. Inspired by this attribute, we propose a novel approach, called in-context estimation, for the canonical communication problem of estimating transmitted symbols from received symbols. A communication channel is essentially a noisy function that maps transmitted symbols to received symbols, and this function can be represented by an unknown parameter whose statistics depend on an (also unknown) latent context. Conventional approaches ignore this hierarchical structure and simply attempt to use known transmissions, called pilots, to perform a least-squares estimate of the channel parameter, which is then used to estimate successive, unknown transmitted symbols. We make the basic connection that transformers show excellent contextual sequence completion with a few prompts, and so they should be able to implicitly determine the latent context from pilot symbols to perform end-to-end in-context estimation of transmitted symbols. Furthermore, the transformer should use information efficiently, i.e., it should utilize any pilots received to attain the best possible symbol estimates. Through extensive simulations, we show that in-context estimation not only significantly outperforms standard approaches, but also achieves the same performance as an estimator with perfect knowledge of the latent context within a few context examples. Thus, we make a strong case that transformers are efficient in-context estimators in the communication setting.
</details>
<details>
<summary>摘要</summary>
pré-entraîné transformers peuvent effectuer l'apprentissage en contexte, où ils s'adaptent à une nouvelle tâche à l'aide seulement d'un petit nombre de prompts sans aucune optimization explicite du modèle. Inspirés par cette caractéristique, nous proposons une nouvelle approche, appelée estimation en contexte, pour le problème canonique de communication de déterminer les symboles transmis à partir des symboles reçus. Un canal de communication est essentiellement une fonction bruitée qui cartographie les symboles transmis en symboles reçus, et cette fonction peut être représentée par un paramètre inconnu dont les statistiques dépendent d'un contexte latent également inconnu. Les approches conventionnelles négligent cette structure hiérarchique et essaient simplement d'utiliser des transmissions conocues, appelées piliers, pour effectuer un estimateur de least-squares du paramètre de canal, qui est ensuite utilisé pour estimer les symboles transmis successifs inconus. Nous faisons la connexion basique que les transformers montrent une excellente completion de séquence contextuelle avec quelques prompts, et donc ils devraient être en mesure d'implicitement déterminer le contexte latent à partir des symboles de pilote pour effectuer une estimation en contexte de transmissions. De plus, le transformer devrait utiliser l'information de manière efficace, c'est-à-dire qu'il devrait utiliser tous les piliers reçus pour obtenir les estimations de symboles les meilleures possibles. Grâce à des simulations étendues, nous montrons que l'estimation en contexte ne seulement outrepasse les approches standard, mais également atteint le même niveau de performance qu'un estimateur avec une connaissance parfaite du contexte latent dans quelques exemples de contexte. Ainsi, nous faisons un fort cas que les transformers sont des estimateurs efficaces en contexte dans le setting de la communication.
</details></li>
</ul>
<hr>
<h2 id="WinNet-time-series-forecasting-with-a-window-enhanced-period-extracting-and-interacting"><a href="#WinNet-time-series-forecasting-with-a-window-enhanced-period-extracting-and-interacting" class="headerlink" title="WinNet:time series forecasting with a window-enhanced period extracting and interacting"></a>WinNet:time series forecasting with a window-enhanced period extracting and interacting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00214">http://arxiv.org/abs/2311.00214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjie Ou, Dongyue Guo, Zheng Zhang, Zhishuo Zhao, Yi Lin</li>
<li>for: 这个论文是为了提出一种高精度且简单结构的 CNN 模型，用于长期时间序预测任务。</li>
<li>methods: 该模型使用了以下三个Component：（i）间隔内部编码器（I2PE），将 1D 序列转换为 2D 矩阵，捕捉长期和短期周期性；（ii）两维期 decomposition（TDPD），模型期势和振荡项目；（iii）分解相关块（DCB），利用期势和振荡项目之间的相关性，支持预测任务。</li>
<li>results: 在九个基准数据集上，WinNet 可以达到 SOTA 性能和较低的计算复杂度，比 CNN、MLP 和 Transformer 等方法高。WinNet 为 CNN 基于方法在时间序列预测任务中提供了潜在的替代方案，具有完美的性能和效率平衡。<details>
<summary>Abstract</summary>
Recently, Transformer-based methods have significantly improved state-of-the-art time series forecasting results, but they suffer from high computational costs and the inability to capture the long and short periodicity of time series. We present a highly accurate and simply structured CNN-based model for long-term time series forecasting tasks, called WinNet, including (i) Inter-Intra Period Encoder (I2PE) to transform 1D sequence into 2D tensor with long and short periodicity according to the predefined periodic window, (ii) Two-Dimensional Period Decomposition (TDPD) to model period-trend and oscillation terms, and (iii) Decomposition Correlation Block (DCB) to leverage the correlations of the period-trend and oscillation terms to support the prediction tasks by CNNs. Results on nine benchmark datasets show that the WinNet can achieve SOTA performance and lower computational complexity over CNN-, MLP-, Transformer-based approaches. The WinNet provides potential for the CNN-based methods in the time series forecasting tasks, with perfect tradeoff between performance and efficiency.
</details>
<details>
<summary>摘要</summary>
近期，基于Transformer的方法在时间序列预测中取得了显著的进步，但它们受到高计算成本和无法捕捉时间序列的长短周期性的限制。我们提出了一种高准确性和简单结构的CNN基本模型，称为WinNet，包括以下三个 Component：1. 时间序列 Period Encoder (I2PE)，将1D序列转换成2D张量，并以预定的 periodic 窗口中的长短周期性进行编码。2. Two-Dimensional Period Decomposition (TDPD)，用于模型期势和抽象的振荡项。3. Decomposition Correlation Block (DCB)，利用 period-trend 和抽象的振荡项的相关性，以支持预测任务。在九个标准测试集上，WinNet可以 дости得State-of-the-art（SOTA）性能和低计算复杂度，比 CNN-, MLP-、Transformer-based 方法更高效。WinNet提供了CNN基本方法在时间序列预测任务中的潜在潜力，同时实现了精度和效率的完美平衡。
</details></li>
</ul>
<hr>
<h2 id="A-Unified-Framework-to-Enforce-Discover-and-Promote-Symmetry-in-Machine-Learning"><a href="#A-Unified-Framework-to-Enforce-Discover-and-Promote-Symmetry-in-Machine-Learning" class="headerlink" title="A Unified Framework to Enforce, Discover, and Promote Symmetry in Machine Learning"></a>A Unified Framework to Enforce, Discover, and Promote Symmetry in Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00212">http://arxiv.org/abs/2311.00212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel E. Otto, Nicholas Zolman, J. Nathan Kutz, Steven L. Brunton</li>
<li>for: 这 paper 是为了探讨在物理和机器学习中如何使用对称性来提高模型的泛化能力。</li>
<li>methods: 这 paper 使用了以下方法：1. 在训练模型时强制执行已知的对称性; 2. 从数据集或模型中发现未知的对称性; 3. 在训练过程中通过学习打砸对称性的潜在 канди达到提高模型性能。</li>
<li>results: 这 paper 提出了一种新的对称性核算法，可以在各种机器学习模型中应用，包括基函数回归、动力系统发现、多层感知机和图像空间中的神经网络。这种算法可以在训练过程中提高模型的泛化能力和性能。<details>
<summary>Abstract</summary>
Symmetry is present throughout nature and continues to play an increasingly central role in physics and machine learning. Fundamental symmetries, such as Poincar\'{e} invariance, allow physical laws discovered in laboratories on Earth to be extrapolated to the farthest reaches of the universe. Symmetry is essential to achieving this extrapolatory power in machine learning applications. For example, translation invariance in image classification allows models with fewer parameters, such as convolutional neural networks, to be trained on smaller data sets and achieve state-of-the-art performance. In this paper, we provide a unifying theoretical and methodological framework for incorporating symmetry into machine learning models in three ways: 1. enforcing known symmetry when training a model; 2. discovering unknown symmetries of a given model or data set; and 3. promoting symmetry during training by learning a model that breaks symmetries within a user-specified group of candidates when there is sufficient evidence in the data. We show that these tasks can be cast within a common mathematical framework whose central object is the Lie derivative associated with fiber-linear Lie group actions on vector bundles. We extend and unify several existing results by showing that enforcing and discovering symmetry are linear-algebraic tasks that are dual with respect to the bilinear structure of the Lie derivative. We also propose a novel way to promote symmetry by introducing a class of convex regularization functions based on the Lie derivative and nuclear norm relaxation to penalize symmetry breaking during training of machine learning models. We explain how these ideas can be applied to a wide range of machine learning models including basis function regression, dynamical systems discovery, multilayer perceptrons, and neural networks acting on spatial fields such as images.
</details>
<details>
<summary>摘要</summary>
自然中央存在对称，并且在物理和机器学习中扮演着越来越重要的角色。基本对称，如波兰卷积几何，使物理法则在宇宙中的各个方向都适用。对称是机器学习应用中达到这种推广能力的关键。例如，图像分类中的翻译对称使得使用 fewer parameters的卷积神经网络进行训练，可以达到现场的状态arta performance。在这篇论文中，我们提供了一种统一的理论和方法框架，用于在机器学习模型中包含对称。我们的方法包括：1. 在训练过程中强制执行已知对称; 2. 发现数据集或模型未知的对称; 3. 在训练过程中通过学习打砸对称时，找到对称的破坏。我们显示这些任务可以在共同的数学框架下进行，该框架的中心对象是在纤维线性 Lie 群动作下的 Lie 导数。我们扩展和统一了一些现有的结果，并证明了在训练过程中强制执行对称和发现对称是线性代数任务，这些任务是对 Lie 导数的 bilinear 结构进行对应。我们还提出了一种新的方法，基于 Lie 导数和核心 нор数relaxation，用于在训练机器学习模型时强制对称。我们解释了这些想法如何应用于各种机器学习模型，包括基函数回归、动力系统发现、多层感知机和图像空间中的神经网络。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-for-accuracy-in-density-functional-approximations"><a href="#Machine-learning-for-accuracy-in-density-functional-approximations" class="headerlink" title="Machine learning for accuracy in density functional approximations"></a>Machine learning for accuracy in density functional approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00196">http://arxiv.org/abs/2311.00196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Voss</li>
<li>for: 提高计算化学的准确性和效率</li>
<li>methods: 使用机器学习技术加速原子尺度 simulations和材料设计</li>
<li>results: 提高了计算机能力和预测力，并能 corrrect 基函数方法中的基本错误Here’s a more detailed explanation of each point:</li>
<li>for: The paper is written to improve the accuracy and efficiency of computational chemistry simulations and materials design using machine learning techniques.</li>
<li>methods: The paper uses machine learning approaches to enhance the predictive power of density functional theory and related approximations.</li>
<li>results: The paper reviews recent progress in applying machine learning to improve the accuracy of density functional and related approximations, and discusses the promises and challenges of devising machine learning models that can be transferred between different chemistries and materials classes.<details>
<summary>Abstract</summary>
Machine learning techniques have found their way into computational chemistry as indispensable tools to accelerate atomistic simulations and materials design. In addition, machine learning approaches hold the potential to boost the predictive power of computationally efficient electronic structure methods, such as density functional theory, to chemical accuracy and to correct for fundamental errors in density functional approaches. Here, recent progress in applying machine learning to improve the accuracy of density functional and related approximations is reviewed. Promises and challenges in devising machine learning models transferable between different chemistries and materials classes are discussed with the help of examples applying promising models to systems far outside their training sets.
</details>
<details>
<summary>摘要</summary>
使用机器学习技术加速 atomistic simulations 和材料设计已成为计算化学中不可或缺的工具。此外，机器学习方法还拥有提高计算效率电子结构方法的预测力的潜力，使其达到化学精度。本文将 recensione recent progress in applying machine learning to improve the accuracy of density functional and related approximations。文章还讨论了在不同化学和材料类型之间传递机器学习模型的承诺和挑战，并通过example应用有前提模型到远离训练集的系统。Translation:使用机器学习技术加速 atomistic simulations 和材料设计已成为计算化学中不可或缺的工具。此外，机器学习方法还拥有提高计算效率电子结构方法的预测力，使其达到化学精度。本文将 recensione recent progress in applying machine learning to improve the accuracy of density functional and related approximations。文章还讨论了在不同化学和材料类型之间传递机器学习模型的承诺和挑战，并通过example apply 有前提模型到远离训练集的系统。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/cs.LG_2023_11_01/" data-id="cloqtaeui00s1gh888ytgdi54" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/eess.IV_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T09:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/eess.IV_2023_11_01/">eess.IV - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="See-SIFT-in-a-Rain"><a href="#See-SIFT-in-a-Rain" class="headerlink" title="See SIFT in a Rain"></a>See SIFT in a Rain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00518">http://arxiv.org/abs/2311.00518</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiuchu-buyan/See_SIFT_in_a_Rain">https://github.com/jiuchu-buyan/See_SIFT_in_a_Rain</a></li>
<li>paper_authors: Wei Wu, Hao Chang, Zhu Li</li>
<li>for: 提高图像特征提取能力，为后续的特征基于应用提供更好的图像特征。</li>
<li>methods: 提议一种任务驱动的图像排除方法，通过两个分开的网络和不同的损失函数来实现两个目标。一个是检测SIFT特征的DoG pyramid回归网络（DPRNet），另一个是描述SIFT特征的梯度图像回归网络（GGIRNet）。</li>
<li>results: 实验结果表明，提议的算法在比较难以处理的暴雨情况下可以更好地提高图像特征提取能力，并且比现有方法更高效。<details>
<summary>Abstract</summary>
Rain streaks bring complicated pixel intensity changes and additional gradients, greatly obstructing the extraction of image features from background. This causes serious performance degradation in feature-based applications. Thus, it is critical to remove rain streaks from a single rainy image to recover image features. Recently, many excellent image deraining methods have made remarkable progress. However, these human visual system-driven approaches mainly focus on improving image quality with pixel recovery as loss function, and neglect how to enhance image feature recovery ability. To address this issue, we propose a task-driven image deraining algorithm to strengthen image feature supply for subsequent feature-based applications. Due to the extensive use and strong practicability of Scale-Invariant Feature Transform (SIFT), we first propose two separate networks using distinct losses and modules to achieve two goals, respectively. One is difference of Gaussian (DoG) pyramid recovery network (DPRNet) for SIFT detection, and the other gradients of Gaussian images recovery network (GGIRNet) for SIFT description. Second, in the DPRNet we propose an alternative interest point loss that directly penalizes scale response extrema to recover the DoG pyramid. Third, we advance a gradient attention module in the GGIRNet to recover those gradients of Gaussian images. Finally, with the recovered DoG pyramid and gradients, we can regain SIFT key points. This divide-and-conquer scheme to set different objectives for SIFT detection and description leads to good robustness. Compared with state-of-the-art methods, experimental results demonstrate that our proposed algorithm achieves better performance in both the number of recovered SIFT key points and their accuracy.
</details>
<details>
<summary>摘要</summary>
雨束线会导致图像像素强度变化和附加的梯度，大大阻碍图像特征的提取，从背景中。这会导致图像特征提取的性能下降，影响后续的特征基于应用。因此，需要从雨束图像中除除雨束，以恢复图像特征。现在，许多出色的图像抽取方法已经做出了很好的进步。然而，这些人视系统驱动的方法主要关注图像质量的改进，忽略了如何提高图像特征提取能力。为解决这个问题，我们提出了一种任务驱动的图像抽取算法，以增强图像特征供应。由于Scale-Invariant Feature Transform（SIFT）的广泛使用和强大实用性，我们首先提出了两个分开的网络，使用不同的损失函数和模块，分别完成两个目标。一个是Diffusion of Gaussian（DoG） pyramid recovery network（DPRNet），用于SIFT检测；另一个是Gradients of Gaussian images recovery network（GGIRNet），用于SIFT描述。二、在DPRNet中，我们提出了一种alternative interest point损失函数，直接惩罚scale response极值，以恢复DoG pyramid。三、在GGIRNet中，我们提出了一种gradient attention模块，用于恢复Gaussian图像的梯度。最后，通过恢复DoG pyramid和梯度，我们可以重新获得SIFT关键点。这种分解并且分配不同的目标 для SIFT检测和描述，导致良好的Robustness。与现状的方法相比，我们的提出的算法在recovered SIFT关键点的数量和准确性方面具有更好的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/eess.IV_2023_11_01/" data-id="cloqtaf1n018xgh88gxl97iux" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/01/eess.SP_2023_11_01/" class="article-date">
  <time datetime="2023-11-01T08:00:00.000Z" itemprop="datePublished">2023-11-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/eess.SP_2023_11_01/">eess.SP - 2023-11-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Channel-Estimation-for-Reconfigurable-Intelligent-Surface-MIMO-with-Tensor-Signal-Modelling"><a href="#Channel-Estimation-for-Reconfigurable-Intelligent-Surface-MIMO-with-Tensor-Signal-Modelling" class="headerlink" title="Channel Estimation for Reconfigurable Intelligent Surface MIMO with Tensor Signal Modelling"></a>Channel Estimation for Reconfigurable Intelligent Surface MIMO with Tensor Signal Modelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00876">http://arxiv.org/abs/2311.00876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander James Fernandes, Ioannis Psaromiligkos</li>
<li>for: 这个论文旨在研究一种宽频段MIMO智能表面（RIS）协助无线通信系统，并使用tensor信号模型技术来分别估算所有通信频道，包括非RIS频道（直接路径）和分离RIS频道。</li>
<li>methods: 本论文提出了两种通annel估算方法：两stage RIS OFF-ON方法和增强alternating least squares（E-ALS）方法。两种方法都利用tensor模型的结构来分离估算所有通信频道，而且比传统的最小二乘（LS）方法更高效。</li>
<li>results: 数值仿真结果表明，E-ALS方法可以提供最高精度的估算，但只有与两stage方法的运行时间相似。<details>
<summary>Abstract</summary>
We consider a narrowband MIMO reconfigurable intelligent surface (RIS)-assisted wireless communication system and use tensor signal modelling techniques to individually estimate all communication channels including the non-RIS channels (direct path) and decoupled RIS channels. We model the received signal as a third-order tensor composed of two CANDECOMP/PARAFAC decomposition terms for the non-RIS and the RIS-assisted links, respectively, and we propose two channel estimation methods based on an iterative alternating least squares (ALS) algorithm: The two-stage RIS OFF-ON method estimates each of the non-RIS and RIS-assisted terms in two pilot training stages, whereas the enhanced alternating least squares (E-ALS) method improves upon the ALS algorithm to jointly estimate all channels over the full training duration. A key benefit of both methods compared to the traditional least squares (LS) solution is that they exploit the structure of the tensor model to obtain decoupled estimates of all communication channels. We provide the computational complexities to obtain each of the channel estimates for our two proposed methods. Numerical simulations are used to evaluate the accuracy and verify the computational complexities of the proposed two-stage RIS OFF-ON, and E-ALS, and compare them to the traditional LS methods. Results show that E-ALS will obtain the most accurate estimate while only having a slightly higher run-time than the two-stage method.
</details>
<details>
<summary>摘要</summary>
我们考虑一个宽频段多Input多Output（MIMO）启动智能表面（RIS）协助无线通信系统，并使用张量信号模型技术来分别估算所有通信频道，包括非RIS频道（直接路径）和分离的RIS频道。我们模型接收信号为一个第三个张量，由两个CANDECOMP/PARAFAC分解项组成，一个是非RIS链和RIS协助链的两个分别链路。我们提出了两种通道估算方法，基于轮换最小二乘（ALS）算法：一是两stage RIS OFF-ON方法，它在两个预训练阶段中分别估算非RIS和RIS协助链的每个通信频道，而另一种是提高ALS算法的增强ALS方法，它在全duration训练时间内同时估算所有通信频道。与传统最小二乘（LS）方法相比，两种方法都利用张量模型的结构来获得分离的所有通信频道估算。我们提供了每个通道估算的计算复杂度。我们通过数值仿真来评估和验证我们的两种提议方法的准确性和计算复杂度，并与传统LS方法进行比较。结果表明，增强ALS方法将获得最准确的估算，只有与两stage方法的运行时间有些着。
</details></li>
</ul>
<hr>
<h2 id="Effective-filtering-approach-for-joint-parameter-state-estimation-in-SDEs-via-Rao-Blackwellization-and-modularization"><a href="#Effective-filtering-approach-for-joint-parameter-state-estimation-in-SDEs-via-Rao-Blackwellization-and-modularization" class="headerlink" title="Effective filtering approach for joint parameter-state estimation in SDEs via Rao-Blackwellization and modularization"></a>Effective filtering approach for joint parameter-state estimation in SDEs via Rao-Blackwellization and modularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00836">http://arxiv.org/abs/2311.00836</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhou Fang, Ankit Gupta, Mustafa Khammash</li>
<li>For: Joint parameter-state estimation in stochastic differential equations (SDEs)* Methods: Rao-Blackwellization and modularization* Results: Superior performance compared to existing approaches, with reduced computational complexity and mitigated issues of sample degeneracy and information loss.Here’s the Simplified Chinese text for each point:</li>
<li>for: 用于joint参数-状态估计在涨见微分方程（SDEs）中</li>
<li>methods: 使用Rao-Blackwellization和模块化</li>
<li>results: 与现有方法相比，表现更佳，具有减少计算复杂性和消除样本缺乏和信息损失等问题。<details>
<summary>Abstract</summary>
Stochastic filtering is a vibrant area of research in both control theory and statistics, with broad applications in many scientific fields. Despite its extensive historical development, there still lacks an effective method for joint parameter-state estimation in SDEs. The state-of-the-art particle filtering methods suffer from either sample degeneracy or information loss, with both issues stemming from the dynamics of the particles generated to represent system parameters.   This paper provides a novel and effective approach for joint parameter-state estimation in SDEs via Rao-Blackwellization and modularization. Our method operates in two layers: the first layer estimates the system states using a bootstrap particle filter, and the second layer marginalizes out system parameters explicitly. This strategy circumvents the need to generate particles representing system parameters, thereby mitigating their associated problems of sample degeneracy and information loss. Moreover, our method employs a modularization approach when integrating out the parameters, which significantly reduces the computational complexity. All these designs ensure the superior performance of our method. Finally, a numerical example is presented to illustrate that our method outperforms existing approaches by a large margin.
</details>
<details>
<summary>摘要</summary>
This paper proposes a novel and effective approach for joint parameter-state estimation in SDEs through Rao-Blackwellization and modularization. Our method operates in two layers: the first layer estimates the system states using a bootstrap particle filter, and the second layer marginalizes out system parameters explicitly. By avoiding the need to generate particles representing system parameters, our method mitigates the associated problems of sample degeneracy and information loss. Additionally, our method employs a modularization approach when integrating out the parameters, which significantly reduces the computational complexity. These designs ensure the superior performance of our method.To demonstrate the effectiveness of our approach, we provide a numerical example that shows our method outperforms existing methods by a large margin.
</details></li>
</ul>
<hr>
<h2 id="Regularized-Shannon-sampling-formulas-related-to-the-special-affine-Fourier-transform"><a href="#Regularized-Shannon-sampling-formulas-related-to-the-special-affine-Fourier-transform" class="headerlink" title="Regularized Shannon sampling formulas related to the special affine Fourier transform"></a>Regularized Shannon sampling formulas related to the special affine Fourier transform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00610">http://arxiv.org/abs/2311.00610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frank Filbir, Manfred Tasche, Anna Veselovska</li>
<li>for: 这篇论文描述了一种新的减震折射抽取方法， relate to 特殊抽象傅立叙 transform (SAFT)。</li>
<li>methods: 这种抽取方法使用了本地采样和特殊减震的窗函数，如 B-spline、sinh-type 和连续 Kaiser-Bessel 窗函数。</li>
<li>results: 对比于Shannon抽取系列，这种减震抽取方法具有加速衰减的抽取误差和在噪声存在时的数值稳定性。数值实验证明了理论结论。<details>
<summary>Abstract</summary>
In this paper, we present new regularized Shannon sampling formulas related to the special affine Fourier transform (SAFT). These sampling formulas use localized sampling with special compactly supported window functions, namely B-spline, sinh-type, and continuous Kaiser-Bessel window functions. In contrast to the Shannon sampling series for SAFT, the regularized Shannon sampling formulas for SAFT possesses an exponential decay of the approximation error and are numerically robust in the presence of noise, if certain oversampling condition is fulfilled. Several numerical experiments illustrate the theoretical results.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了新的减杂化Shannon抽取方法，与特殊直交傅立卷变换 (SAFT) 相关。这些抽取方法使用了本地化抽取，使用特殊压缩支持的窗函数，包括B-spline、sinh型和连续凯зер-贝塞尔窗函数。与Shannon抽取系列不同，我们的减杂化Shannon抽取方法具有辐射衰减的扩散误差，在噪声存在时是数值稳定的，只要满足certain oversampling condition。我们在数值实验中证明了这些理论结果。
</details></li>
</ul>
<hr>
<h2 id="A-Leakage-based-Method-for-Mitigation-of-Faulty-Reconfigurable-Intelligent-Surfaces"><a href="#A-Leakage-based-Method-for-Mitigation-of-Faulty-Reconfigurable-Intelligent-Surfaces" class="headerlink" title="A Leakage-based Method for Mitigation of Faulty Reconfigurable Intelligent Surfaces"></a>A Leakage-based Method for Mitigation of Faulty Reconfigurable Intelligent Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00527">http://arxiv.org/abs/2311.00527</a></li>
<li>repo_url: None</li>
<li>paper_authors: N. Moghadas Gholian, M. Rossanese, P. Mursia, A. Garcia-Saavedra, A. Asadi, V. Sciancalepore, X. Costa-Pérez<br>for:这篇论文旨在解决智能表面重配置技术在未来5G无线网络中的一个潜在问题，即不良信号散射。methods:本文提出了两种简单 yet effective的算法，它们基于最大化信号泄漏和噪声比率（SLNR）在预定的二维空间中，并适用于完美通道状态信息（CSI）和部分CSI情况下。results:数值和全波仿真结果表明，这两种算法可以提供更大的补偿效果，比对泄漏无法和参照方案。<details>
<summary>Abstract</summary>
Reconfigurable Intelligent Surfaces (RISs) are expected to be massively deployed in future beyond-5th generation wireless networks, thanks to their ability to programmatically alter the propagation environment, inherent low-cost and low-maintenance nature. Indeed, they are envisioned to be implemented on the facades of buildings or on moving objects. However, such an innovative characteristic may potentially turn into an involuntary negative behavior that needs to be addressed: an undesired signal scattering. In particular, RIS elements may be prone to experience failures due to lack of proper maintenance or external environmental factors. While the resulting Signal-to-Noise-Ratio (SNR) at the intended User Equipment (UE) may not be significantly degraded, we demonstrate the potential risks in terms of unwanted spreading of the transmit signal to non-intended UE. In this regard, we consider the problem of mitigating such undesired effect by proposing two simple yet effective algorithms, which are based on maximizing the Signal-to-Leakage- and-Noise-Ratio (SLNR) over a predefined two-dimensional (2D) area and are applicable in the case of perfect channel-state-information (CSI) and partial CSI, respectively. Numerical and full-wave simulations demonstrate the added gains compared to leakage-unaware and reference schemes.
</details>
<details>
<summary>摘要</summary>
“复 configurable 智能表面”（RIS）在未来第5代无线网络中大规模部署，感谢其可以通过程序修改媒体传播环境，具有低成本和低维护性。实际上，它们可能被实现在建筑物外墙或在移动物体上。然而，这种创新特点可能会变成不良行为：不需要的信号散射。具体来说，RIS元素可能因缺乏正确维护或外部环境因素而出现故障。尽管传输信号的噪声比（SNR）在意图用户设备（UE）上不会受到显著干扰，但我们表示这种不良影响的风险。在这种情况下，我们考虑了 mitigate 这种不良效果的两种简单 yet effective 算法，它们基于在预定的二维（2D）区域中 maximize 信号干扰比率（SLNR），并在完美通道状态信息（CSI）和部分 CSI 情况下都适用。数值和全波 simulations 表明，相比于干扰无法和参照方案，这两种方法增加了额外的优势。
</details></li>
</ul>
<hr>
<h2 id="Generating-HSR-Bogie-Vibration-Signals-via-Pulse-Voltage-Guided-Conditional-Diffusion-Model"><a href="#Generating-HSR-Bogie-Vibration-Signals-via-Pulse-Voltage-Guided-Conditional-Diffusion-Model" class="headerlink" title="Generating HSR Bogie Vibration Signals via Pulse Voltage-Guided Conditional Diffusion Model"></a>Generating HSR Bogie Vibration Signals via Pulse Voltage-Guided Conditional Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00496">http://arxiv.org/abs/2311.00496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan Liu, Jinglong Chen, Jingsong Xie, Yuanhong Chang</li>
<li>for: 高速铁路（HSR） bogie fault诊断</li>
<li>methods: 续程阶层传递 conditional diffusion model (VGCDM)</li>
<li>results: 比其他生成模型出色，实现最佳RSME、PSNR和FSCS指标，证明其在条件HSR bogie震动信号生成中的优势。In simpler English:</li>
<li>for: Fault diagnosis of high-speed rail (HSR) bogies</li>
<li>methods: Pulse Voltage-Guided Conditional Diffusion Model (VGCDM)</li>
<li>results: Outperforms other generative models, achieving the best RSME, PSNR, and FSCS indicators, demonstrating its superiority in generating HSR bogie vibration signals.<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GANs) for producing realistic signals, have substantially improved fault diagnosis algorithms in various Internet of Things (IoT) systems. However, challenges such as training instability and dynamical inaccuracy limit their utility in high-speed rail (HSR) bogie fault diagnosis. To address these challenges, we introduce the Pulse Voltage-Guided Conditional Diffusion Model (VGCDM). Unlike traditional implicit GANs, VGCDM adopts a sequential U-Net architecture, facilitating multi-phase denoising diffusion for generation, which bolsters training stability and mitigate convergence issues. VGCDM also incorporates control pulse voltage by cross-attention mechanism to ensure the alignment of vibration with voltage signals, enhancing the Conditional Diffusion Model's progressive controlablity. Consequently, solely straightforward sampling of control voltages, ensuring the efficient transformation from Gaussian Noise to vibration signals. This adaptability remains robust even in scenarios with time-varying speeds. To validate the effectiveness, we conducted two case studies using SQ dataset and high-simulation HSR bogie dataset. The results of our experiments unequivocally confirm that VGCDM outperforms other generative models, achieving the best RSME, PSNR, and FSCS, showing its superiority in conditional HSR bogie vibration signal generation. For access, our code is available at https://github.com/xuanliu2000/VGCDM.
</details>
<details>
<summary>摘要</summary>
Generative Adversarial Networks (GANs) 已经广泛应用于许多互联网东西 (IoT) 系统中，以生成实际的信号，提高了问题诊断算法的准确性。然而，在高速铁路 (HSR)  bogie 问题诊断中，GANs 受到许多挑战，如训练不稳定和动态不准确。为了解决这些挑战，我们提出了普ulse Voltage-Guided Conditional Diffusion Model (VGCDM)。VGCDM 采用了序列 U-Net 架构，实现多个阶段的净化扩散，从而提高训练稳定性和抑制混合问题。VGCDM 还通过cross-attention机制来控制普ulse电压，确保振荡与电压信号的对齐，提高 Conditional Diffusion Model 的进行控制性。因此，只需单纯地采样控制电压，以确保高效地将 Gaussian Noise 转化为振荡信号。这种适应性能够在时间变化的情况下保持稳定。为证明效果，我们在 SQ 数据集和高 simulate HSR bogie 数据集上进行了两个案例研究。结果表明，VGCDM 明显超过了其他生成模型，实现最佳 RSME、PSNR 和 FSCS，证明其在Conditional HSR bogie 振荡信号生成中的优越性。对于更多信息，请参考我们的 GitHub 仓库 <https://github.com/xuanliu2000/VGCDM>。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-Surface-Empowered-Integrated-Sensing-and-Communication-From-Coexistence-to-Reciprocity"><a href="#Intelligent-Surface-Empowered-Integrated-Sensing-and-Communication-From-Coexistence-to-Reciprocity" class="headerlink" title="Intelligent Surface Empowered Integrated Sensing and Communication: From Coexistence to Reciprocity"></a>Intelligent Surface Empowered Integrated Sensing and Communication: From Coexistence to Reciprocity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00418">http://arxiv.org/abs/2311.00418</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaitao Meng, Qingqing Wu, Christos Masouros, Wen Chen, Deshi Li</li>
<li>for: 这种研究旨在探讨智能反射&#x2F;折射表面（IRS）在 sixth-generation（6G）及以后无线网络中的集成感知通信（ISAC）中的应用。</li>
<li>methods: 该研究首先探讨了IRS在ISAC中的基本特性和创新感知建筑。然后讨论了IRS渠道控制和部署优化的多个目标。最后，研究探讨了不同部署策略之间的干扰关系，并提出了一些有前途的IRS增强ISAC的方向。</li>
<li>results: 研究发现，IRS可以有效地扩大S&amp;C覆盖范围和控制通信频率的度量，从而实现更高的集成增益。同时，研究还发现了不同部署策略之间的干扰关系，并提出了一些有前途的IRS增强ISAC的方向。<details>
<summary>Abstract</summary>
Integrated sensing and communication (ISAC) has attracted growing interests for sixth-generation (6G) and beyond wireless networks. The primary challenges faced by highly efficient ISAC include limited sensing and communication (S&C) coverage, constrained integration gain between S&C under weak channel correlations, and unknown performance boundary. Intelligent reflecting/refracting surfaces (IRSs) can effectively expand S&C coverage and control the degree of freedom of channels between the transmitters and receivers, thereby realizing increasing integration gains. In this work, we first delve into the fundamental characteristics of IRS-empowered ISAC and innovative IRS-assisted sensing architectures. Then, we discuss various objectives for IRS channel control and deployment optimization in ISAC systems. Furthermore, the interplay between S&C in different deployment strategies is investigated and some promising directions for IRS enhanced ISAC are outlined.
</details>
<details>
<summary>摘要</summary>
Integrated sensing and communication (ISAC) 在 sixth-generation (6G) 和更高版本无线网络中吸引了增长的关注。主要挑战包括有限的感知和通信 (S&C) 覆盖率、弱通道相关性下的约束集成增益，以及未知性能边界。智能反射/折射 поверхност (IRS) 可以有效地扩大 S&C 覆盖率，控制通信道之间的度量自由度，从而实现增加集成增益。在这种工作中，我们首先探讨了 ISAC 的基本特点和创新的 IRS 感知架构。然后，我们讨论了 ISAC 系统中 IRS 通道控制和部署优化的多种目标。此外，我们还研究了不同部署策略下的 S&C 间的互动，并提出了一些潜在的 IRS 增强 ISAC 的方向。
</details></li>
</ul>
<hr>
<h2 id="Deriving-Characteristic-Mode-Eigenvalue-Behavior-Using-Subduction-of-Group-Representations"><a href="#Deriving-Characteristic-Mode-Eigenvalue-Behavior-Using-Subduction-of-Group-Representations" class="headerlink" title="Deriving Characteristic Mode Eigenvalue Behavior Using Subduction of Group Representations"></a>Deriving Characteristic Mode Eigenvalue Behavior Using Subduction of Group Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00365">http://arxiv.org/abs/2311.00365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Grundmann, Lukas Warkentin, Dirk Manteuffel</li>
<li>for: 该文章目的是提出一种使用知道和理解的解方法来 derive 模态 eigenvalue 轨迹的特征。</li>
<li>methods: 该方法基于点群论中的投射概念，通过获取目标结构的Symmetry 性质来从高阶对称结构中获取目标结构的Symmetry 性质。这种方法在圆柱体上的特征模式（CMs）中进行了应用，并在一个 cube 在自由空间中和一个 cuboid 在完美电阻平面上的 eigenvalues 行为中得到了连续 derivation。</li>
<li>results: 该研究发现，在三维结构中，原来的交叠轨迹将分裂成多个不同的轨迹，形成了一种 Split Trace Crossing Avoidance（STCA）。这一发现可以解释三维结构中观察到的凹槽轨迹。此外，该研究还验证了这种知识的实用性，通过一个示例式天线设计，并在设计中选择了STCA在目标频率范围外，以避免输入匹配和远场图像的频率稳定性的负面影响。<details>
<summary>Abstract</summary>
A method to derive features of modal eigenvalue traces from known and understood solutions is proposed. It utilizes the concept of subduction from point group theory to obtain the symmetry properties of a target structure from those of a structure with a higher order of symmetry. This is applied exemplary to the analytically known characteristic modes (CMs) of the spherical shell. The eigenvalue behavior of a cube in free space and a cuboid on a perfectly electrically conducting plane are continuously derived from this. In this process, formerly crossing eigenvalue traces are found to split up, forming a split trace crossing avoidance (STCA). This finding is used to explain indentations in eigenvalue traces observed for three-dimensional structures, that are of increasing interest in recent literature. The utility of this knowledge is exemplified through a demonstrator antenna design. The dimensions of the antenna structure are chosen so the STCA is outside the target frequency range, avoiding negative impacts on input matching and the frequency stability of the far field patterns.
</details>
<details>
<summary>摘要</summary>
提出一种方法，用于从已知和理解的解的特征Derive特征 tracestracestructure的模态值轨迹。该方法利用点组 тео리 ahp 的投射 Property来获取目标结构的 симметry 属性，从而 derive the symmetry properties of a target structure from those of a structure with a higher order of symmetry. This is applied exemplary to the analytically known characteristic modes (CMs) of the spherical shell. The eigenvalue behavior of a cube in free space and a cuboid on a perfectly electrically conducting plane are continuously derived from this. In this process, formerly crossing eigenvalue traces are found to split up, forming a split trace crossing avoidance (STCA). This finding is used to explain indentations in eigenvalue traces observed for three-dimensional structures, that are of increasing interest in recent literature. The utility of this knowledge is exemplified through a demonstrator antenna design. The dimensions of the antenna structure are chosen so the STCA is outside the target frequency range, avoiding negative impacts on input matching and the frequency stability of the far field patterns.
</details></li>
</ul>
<hr>
<h2 id="On-the-Semi-Blind-Mutually-Referenced-Equalizers-for-MIMO-Systems"><a href="#On-the-Semi-Blind-Mutually-Referenced-Equalizers-for-MIMO-Systems" class="headerlink" title="On the Semi-Blind Mutually Referenced Equalizers for MIMO Systems"></a>On the Semi-Blind Mutually Referenced Equalizers for MIMO Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00325">http://arxiv.org/abs/2311.00325</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DoHaiSon/Semi-blind_Mutually_Referenced_Equalizers">https://github.com/DoHaiSon/Semi-blind_Mutually_Referenced_Equalizers</a></li>
<li>paper_authors: Do Hai Son, Karim Abed-Meraim, Tran Trong Duy, Nguyen Linh Trung, Tran Thi Thuy Quynh</li>
<li>for: 减少无线通信系统中的训练负担，提高频率响应和信号识别率。</li>
<li>methods: 基于MUTUALLY REFERENCED EQUALIZERS（MRE）算法，针对MIMO系统进行扩展，并提出了一种新的半开放式方法SB-MRE，兼 possessing 精度和简化性。</li>
<li>results: SB-MRE算法在比较其他线性算法（MMSE、ZF、MRE）的 simulate 结果中，在训练负担和复杂度方面表现出色，可以为无线通信系统中的频率响应和信号识别率提供一个有望的解决方案。<details>
<summary>Abstract</summary>
Minimizing training overhead in channel estimation is a crucial challenge in wireless communication systems. This paper presents an extension of the traditional blind algorithm, called "Mutually referenced equalizers" (MRE), specifically designed for MIMO systems. Additionally, we propose a novel semi-blind method, SB-MRE, which combines the benefits of pilot-based and MRE approaches to achieve enhanced performance while utilizing a reduced number of pilot symbols. Moreover, the SB-MRE algorithm helps to minimize complexity and training overhead and to remove the ambiguities inherent to blind processing. The simulation results demonstrated that SB-MRE outperforms other linear algorithms, i.e., MMSE, ZF, and MRE, in terms of training overhead symbols and complexity, thereby offering a promising solution to address the challenge of minimizing training overhead in channel estimation for wireless communication systems.
</details>
<details>
<summary>摘要</summary>
减少通信系统中的训练负担是无线通信系统中的一项重要挑战。这篇论文提出了基于多input多output（MIMO）系统的传统盲目算法扩展——共见平衡器（Mutually Referenced Equalizers，MRE）。此外，我们还提出了一种新的半盲目方法，半盲目MRE（SB-MRE），该方法结合了徽标基于和MRE方法的优点，以实现更高的性能，同时减少了徽标数量。此外，SB-MRE算法可以减少复杂性和训练负担，并解决盲目处理中存在的不确定性。实验结果表明，SB-MRE在训练负担符号和复杂性方面与其他线性算法（MMSE、ZF、MRE）相比，表现更好，因此可以有效地解决无线通信系统中的训练负担减少挑战。
</details></li>
</ul>
<hr>
<h2 id="Improving-MIMO-channel-estimation-via-receive-power-feedback"><a href="#Improving-MIMO-channel-estimation-via-receive-power-feedback" class="headerlink" title="Improving MIMO channel estimation via receive power feedback"></a>Improving MIMO channel estimation via receive power feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.00225">http://arxiv.org/abs/2311.00225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Zhang, Hang Zou, Samson Lasaulce, Lucas Saludjian</li>
<li>for: 本研究旨在解决无线网络中估计通道状态的问题，以提高估计精度。</li>
<li>methods: 本研究使用了经典的估计工具，并考虑了接收功率反馈（如接收信号强度指标 -RSSI-）的信息。</li>
<li>results: 研究显示，使用相应的MMSE可以提高估计精度，而使用MAP估计器的有用性取决于操作的SNR。<details>
<summary>Abstract</summary>
Estimating the channel state is known to be an important problem in wireless networks. To this end, it matters to exploit all the available information to improve channel estimation accuracy as much as possible. It turns out that the problem of exploiting the information associated with the receive power feedback (e.g., the received signal strength indicator -RSSI-) has not been identified and solved; in this setup, the transmitter is assumed to receive feedback from all the receivers in presence. As shown in this paper, to solve this problem, classical estimation tools can be used. Using the corresponding MMSE is shown to be always beneficial, whereas the relevance of using the MAP estimator would depend on the operating SNR.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>无线网络中估算通道状态是一个重要的问题。为此，需要尽可能地利用所有可用的信息来提高通道估算精度。实际上，受到返回Feedback（如接收信号强度指示器（RSSI））的信息利用问题尚未得到解决。在这种设置下，传输器接收来自所有接收器的反馈。根据这篇论文，可以使用经典的估算工具来解决这个问题。使用相应的MMSE是有利的，而使用MAP估算器的有用性则取决于操作SNR。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/01/eess.SP_2023_11_01/" data-id="cloqtaf3f01cogh88gsuc3emd" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/4/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/88/">88</a><a class="extend next" rel="next" href="/page/6/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
