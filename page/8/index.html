
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/8/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.SP_2023_10_29" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/29/eess.SP_2023_10_29/" class="article-date">
  <time datetime="2023-10-29T08:00:00.000Z" itemprop="datePublished">2023-10-29</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/29/eess.SP_2023_10_29/">eess.SP - 2023-10-29</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Optical-STAR-RIS-Aided-VLC-Systems-RSMA-Versus-NOMA"><a href="#Optical-STAR-RIS-Aided-VLC-Systems-RSMA-Versus-NOMA" class="headerlink" title="Optical STAR-RIS-Aided VLC Systems: RSMA Versus NOMA"></a>Optical STAR-RIS-Aided VLC Systems: RSMA Versus NOMA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.19141">http://arxiv.org/abs/2310.19141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omar Maraqa, Sylvester Aboagye, Telex M. N. Ngatched<br>for: This paper aims to study the performance of optical simultaneous transmission and reflection reconfigurable intelligent surface (OSTAR-RIS) in a multi-user indoor visible light communication (VLC) system.methods: The proposed system uses a novel multi-user indoor VLC system assisted by OSTAR-RIS, which employs both power-domain non-orthogonal multiple access (NOMA) and rate splitting multiple access (RSMA) to improve the sum rate performance. The roll and yaw angles of the reflector elements, as well as the refractive index of the refractor elements in OSTAR-RIS, are jointly optimized using a sum rate maximization problem.results: The simulation results show that the proposed OSTAR-RIS RSMA-aided VLC system outperforms the OSTAR-RIS NOMA-based VLC system in terms of both the sum rate and the sum energy efficiency.<details>
<summary>Abstract</summary>
A critical concern within the realm of visible light communications (VLC) pertains to enhancing system data rate, particularly in scenarios where the direct line-of-sight (LoS) connection is obstructed by obstacles. The deployment of meta-surface-based simultaneous transmission and reflection reconfigurable intelligent surface (STAR-RIS) has emerged to combat challenging LoS blockage scenarios and to provide 360 coverage in radio-frequency wireless systems. Recently, the concept of optical simultaneous transmission and reflection reconfigurable intelligent surface (OSTAR-RIS) has been promoted for VLC systems. This work is dedicated to studying the performance of OSTAR-RIS in detail and unveiling the VLC system performance gain under such technology. Specifically, we propose a novel multi-user indoor VLC system that is assisted by OSTAR-RIS. To improve the sum rate performance of the proposed system, both power-domain non-orthogonal multiple access (NOMA) and rate splitting multiple access (RSMA) are investigated in this work. To realize this, a sum rate maximization problem that jointly optimizes the roll and yaw angles of the reflector elements as well as the refractive index of the refractor elements in OSTAR-RIS is formulated, solved, and evaluated. The maximization problem takes into account practical considerations, such as the presence of non-users (i.e., blockers) and the orientation of the recipient's device. The sine-cosine meta-heuristic algorithm is employed to get the optimal solution of the formulated non-convex optimization problem. Moreover, the study delves into the sum energy efficiency optimization of the proposed system. Simulation results indicate that the proposed OSTAR-RIS RSMA-aided VLC system outperforms the OSTAR-RIS NOMA-based VLC system in terms of both the sum rate and the sum energy efficiency.
</details>
<details>
<summary>摘要</summary>
Visible light communication (VLC) 的一个关键问题是提高系统数据率，特别是在直线视线 (LoS) 连接被障碍物阻挡时。Meta-surface-based simultaneous transmission and reflection reconfigurable intelligent surface (STAR-RIS) 的部署已经在这些场景中提供了一种解决方案，并提供了360度的覆盖。在这些系统中，optical simultaneous transmission and reflection reconfigurable intelligent surface (OSTAR-RIS) 的概念也在提出。本研究的目的是研究OSTAR-RIS的性能，探讨VLC系统在这种技术下的性能提升。我们提出了一种基于OSTAR-RIS的多用户indoor VLC系统，并使用了power-domain non-orthogonal multiple access (NOMA) 和 rate splitting multiple access (RSMA) 来提高系统的总率性能。为此，我们提出了一个总率最大化问题，该问题jointly优化了OSTAR-RIS中 reflector元素的扭积角和折射率，以及recipient的设备方向。该问题考虑了实际因素，例如阻挡物 (i.e., 堵塞) 和recipient的设备方向。我们使用了sine-cosine meta-heuristic algorithm来获得优化问题的解。此外，我们还研究了系统的总能效率优化。实验结果表明，我们的OSTAR-RIS RSMA-aided VLC系统在总率和总能效率方面都超过了OSTAR-RIS NOMA-based VLC系统。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/29/eess.SP_2023_10_29/" data-id="cloq1wlh001cj7o88fpsnhx9j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/cs.CV_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T13:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/cs.CV_2023_10_28/">cs.CV - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Deep-Learning-based-Compressed-Domain-Multimedia-for-Man-and-Machine-A-Taxonomy-and-Application-to-Point-Cloud-Classification"><a href="#Deep-Learning-based-Compressed-Domain-Multimedia-for-Man-and-Machine-A-Taxonomy-and-Application-to-Point-Cloud-Classification" class="headerlink" title="Deep Learning-based Compressed Domain Multimedia for Man and Machine: A Taxonomy and Application to Point Cloud Classification"></a>Deep Learning-based Compressed Domain Multimedia for Man and Machine: A Taxonomy and Application to Point Cloud Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18849">http://arxiv.org/abs/2310.18849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdelrahman Seleem, André F. R. Guarda, Nuno M. M. Rodrigues, Fernando Pereira</li>
<li>for: 本研究旨在提出一种基于深度学习的图像和视频处理技术，以提高计算机视觉任务的性能和减少计算复杂度。</li>
<li>methods: 该研究使用了深度学习来提取图像和视频数据中的特征，并使用了一种新的稳定性分析方法来评估不同的图像和视频处理算法。</li>
<li>results: 研究结果显示，使用了基于深度学习的图像和视频处理算法可以大幅提高计算机视觉任务的性能，同时减少计算复杂度。此外，研究还发现了一些新的图像和视频处理算法，可以在不同的应用场景中得到优秀的效果。<details>
<summary>Abstract</summary>
In the current golden age of multimedia, human visualization is no longer the single main target, with the final consumer often being a machine which performs some processing or computer vision tasks. In both cases, deep learning plays a undamental role in extracting features from the multimedia representation data, usually producing a compressed representation referred to as latent representation. The increasing development and adoption of deep learning-based solutions in a wide area of multimedia applications have opened an exciting new vision where a common compressed multimedia representation is used for both man and machine. The main benefits of this vision are two-fold: i) improved performance for the computer vision tasks, since the effects of coding artifacts are mitigated; and ii) reduced computational complexity, since prior decoding is not required. This paper proposes the first taxonomy for designing compressed domain computer vision solutions driven by the architecture and weights compatibility with an available spatio-temporal computer vision processor. The potential of the proposed taxonomy is demonstrated for the specific case of point cloud classification by designing novel compressed domain processors using the JPEG Pleno Point Cloud Coding standard under development and adaptations of the PointGrid classifier. Experimental results show that the designed compressed domain point cloud classification solutions can significantly outperform the spatial-temporal domain classification benchmarks when applied to the decompressed data, containing coding artifacts, and even surpass their performance when applied to the original uncompressed data.
</details>
<details>
<summary>摘要</summary>
在当今的金色 Multimedia 时代，人类视觉不再是唯一的主要目标，最终consumer  часто是一个机器，执行一些处理或计算机视觉任务。在这两种情况下，深度学习在抽取 Multimedia 表示数据中的特征方面发挥了关键作用，通常生成一个压缩表示 referred to as 封顶表示。随着深度学习基于解决方案在各种 Multimedia 应用领域的开发和采用，开启了一个新的视野，在这个视野中，一个通用的压缩 Multimedia 表示被用于人类和机器。这个视野的主要优点有两个方面：一是提高计算机视觉任务的性能，因为编码artifacts的影响被减少; 二是降低计算复杂性，因为不需要先 decode。这篇文章提出了首个设计压缩领域计算机视觉解决方案的taxonomy，该taxonomy基于可用的空间temporal计算机视觉处理器的建立和重量相容性。特点的实验结果表明，通过设计 novel 压缩领域处理器，使用 JPEG Pleno Point Cloud Coding 标准在开发中和PointGrid分类器的改进，可以在压缩领域实现显著的点云分类性能提升，并在应用到解码后的数据中 even surpass 其性能。
</details></li>
</ul>
<hr>
<h2 id="INCODE-Implicit-Neural-Conditioning-with-Prior-Knowledge-Embeddings"><a href="#INCODE-Implicit-Neural-Conditioning-with-Prior-Knowledge-Embeddings" class="headerlink" title="INCODE: Implicit Neural Conditioning with Prior Knowledge Embeddings"></a>INCODE: Implicit Neural Conditioning with Prior Knowledge Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18846">http://arxiv.org/abs/2310.18846</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xmindflow/INCODE">https://github.com/xmindflow/INCODE</a></li>
<li>paper_authors: Amirhossein Kazerouni, Reza Azad, Alireza Hosseini, Dorit Merhof, Ulas Bagci</li>
<li>for: 提高信号表示的精度和灵活性，解决现有INR的细节捕捉和鲁棒性问题</li>
<li>methods: 利用深度先验知识调整抽象函数的参数，并通过任务特定预训练模型进行任务特定参数调整，以优化表示过程</li>
<li>results: 在多种信号表示任务上具有更高的精度、质量、灵活性和速度，并能够解决复杂的音频、图像、3D形状重建、NeRFs、反问题等任务，并且在各种难题上具有优于现有INR的表现<details>
<summary>Abstract</summary>
Implicit Neural Representations (INRs) have revolutionized signal representation by leveraging neural networks to provide continuous and smooth representations of complex data. However, existing INRs face limitations in capturing fine-grained details, handling noise, and adapting to diverse signal types. To address these challenges, we introduce INCODE, a novel approach that enhances the control of the sinusoidal-based activation function in INRs using deep prior knowledge. INCODE comprises a harmonizer network and a composer network, where the harmonizer network dynamically adjusts key parameters of the activation function. Through a task-specific pre-trained model, INCODE adapts the task-specific parameters to optimize the representation process. Our approach not only excels in representation, but also extends its prowess to tackle complex tasks such as audio, image, and 3D shape reconstructions, as well as intricate challenges such as neural radiance fields (NeRFs), and inverse problems, including denoising, super-resolution, inpainting, and CT reconstruction. Through comprehensive experiments, INCODE demonstrates its superiority in terms of robustness, accuracy, quality, and convergence rate, broadening the scope of signal representation. Please visit the project's website for details on the proposed method and access to the code.
</details>
<details>
<summary>摘要</summary>
归一神经表示（INR）已经革命化了信号表示方法，通过利用神经网络提供连续和平滑的数据表示方式。然而，现有INR受到细节capturing、鲁棒性和多样化信号类型的限制。为解决这些挑战，我们介绍了INCODE，一种新的方法，它使用深度先验知识来强化神经征函数的控制。INCODE包括一个和 composer网络，其中和网络动态调整 activation 函数的关键参数。通过一个任务特定的预训练模型，INCODE可以将任务特定的参数适应优化表示过程。我们的方法不仅在表示方面卓越，还能够扩展到复杂的任务，如音频、图像、三维形状重建、神经辐射场（NeRF）、反问题（包括噪声、超分解、缺失、CT重建）等。通过全面的实验，INCODE在稳定性、准确性、质量和收敛率方面表现出优异，扩大信号表示的范围。请参考项目网站了解提出的方法和获取代码。
</details></li>
</ul>
<hr>
<h2 id="Customizing-360-Degree-Panoramas-through-Text-to-Image-Diffusion-Models"><a href="#Customizing-360-Degree-Panoramas-through-Text-to-Image-Diffusion-Models" class="headerlink" title="Customizing 360-Degree Panoramas through Text-to-Image Diffusion Models"></a>Customizing 360-Degree Panoramas through Text-to-Image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18840">http://arxiv.org/abs/2310.18840</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/littlewhitesea/stitchdiffusion">https://github.com/littlewhitesea/stitchdiffusion</a></li>
<li>paper_authors: Hai Wang, Xiaoyu Xiang, Yuchen Fan, Jing-Hao Xue</li>
<li>for: 本研究旨在提出一种基于diffusion模型的个性化文本到图像（T2I）合成方法，用于自适应地生成360度全景图像。</li>
<li>methods: 我们首先为这项任务提前抽象了一个预训练的T2I扩散模型，然后使用LoRA进行精度调整。然而，这些调整并不能保证左右两侧图像的连续性，这是360度全景图像的重要特征。因此，我们提出了StitchDiffusion方法，包括在拼接块中进行预除噪音处理，以及应用全局剪辑来生成无缝360度全景图像。</li>
<li>results: 我们的自定义模型，加上我们提出的StitchDiffusion方法，可以生成高质量的360度全景图像。此外，我们的自定义模型在生成未在训练数据集中看到的场景时表现出了异常的泛化能力。<details>
<summary>Abstract</summary>
Personalized text-to-image (T2I) synthesis based on diffusion models has attracted significant attention in recent research. However, existing methods primarily concentrate on customizing subjects or styles, neglecting the exploration of global geometry. In this study, we propose an approach that focuses on the customization of 360-degree panoramas, which inherently possess global geometric properties, using a T2I diffusion model. To achieve this, we curate a paired image-text dataset specifically designed for the task and subsequently employ it to fine-tune a pre-trained T2I diffusion model with LoRA. Nevertheless, the fine-tuned model alone does not ensure the continuity between the leftmost and rightmost sides of the synthesized images, a crucial characteristic of 360-degree panoramas. To address this issue, we propose a method called StitchDiffusion. Specifically, we perform pre-denoising operations twice at each time step of the denoising process on the stitch block consisting of the leftmost and rightmost image regions. Furthermore, a global cropping is adopted to synthesize seamless 360-degree panoramas. Experimental results demonstrate the effectiveness of our customized model combined with the proposed StitchDiffusion in generating high-quality 360-degree panoramic images. Moreover, our customized model exhibits exceptional generalization ability in producing scenes unseen in the fine-tuning dataset. Code is available at https://github.com/littlewhitesea/StitchDiffusion.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。<</SYS>>研究中的个性化文本到图像（T2I）合成技术受到了非常重视。然而，现有的方法主要集中在主题或风格方面，忽略了全球几何特性的探索。在这种研究中，我们提出了一种方法，该方法是通过T2I扩散模型进行个性化360度全景图像的合成。为此，我们制作了特定于任务的图像文本对集，然后使用它来练化一个预训练的T2I扩散模型。然而，练化后的模型本身不能保证左侧和右侧图像的连续性，这是360度全景图像的关键特征。为解决这个问题，我们提出了一种方法called StitchDiffusion。具体来说，我们在每个时间步中对固定块进行预处理操作两次，并采用全球裁剪来合成无缝360度全景图像。实验结果表明，我们的定制模型与StitchDiffusion结合可以生成高质量的360度全景图像。此外，我们的定制模型还表现出了非常好的泛化能力，可以生成未在练化数据集中出现的场景。代码可以在https://github.com/littlewhitesea/StitchDiffusion上找到。
</details></li>
</ul>
<hr>
<h2 id="UniCat-Crafting-a-Stronger-Fusion-Baseline-for-Multimodal-Re-Identification"><a href="#UniCat-Crafting-a-Stronger-Fusion-Baseline-for-Multimodal-Re-Identification" class="headerlink" title="UniCat: Crafting a Stronger Fusion Baseline for Multimodal Re-Identification"></a>UniCat: Crafting a Stronger Fusion Baseline for Multimodal Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18812">http://arxiv.org/abs/2310.18812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jennifer Crawford, Haoli Yin, Luke McDermott, Daniel Cummings</li>
<li>for: 这个论文目标是为了解决多模态重识别任务中的批量化问题，提高对多种数据流的重识别能力。</li>
<li>methods: 该论文使用了多种方法，包括单模态和多模态方法，以及各种拼接和融合策略。</li>
<li>results: 研究发现，使用单模态方法可以获得更好的表示，而不是使用多模态方法。此外，使用不同的拼接和融合策略也可以提高表示的质量。<details>
<summary>Abstract</summary>
Multimodal Re-Identification (ReID) is a popular retrieval task that aims to re-identify objects across diverse data streams, prompting many researchers to integrate multiple modalities into a unified representation. While such fusion promises a holistic view, our investigations shed light on potential pitfalls. We uncover that prevailing late-fusion techniques often produce suboptimal latent representations when compared to methods that train modalities in isolation. We argue that this effect is largely due to the inadvertent relaxation of the training objectives on individual modalities when using fusion, what others have termed modality laziness. We present a nuanced point-of-view that this relaxation can lead to certain modalities failing to fully harness available task-relevant information, and yet, offers a protective veil to noisy modalities, preventing them from overfitting to task-irrelevant data. Our findings also show that unimodal concatenation (UniCat) and other late-fusion ensembling of unimodal backbones, when paired with best-known training techniques, exceed the current state-of-the-art performance across several multimodal ReID benchmarks. By unveiling the double-edged sword of "modality laziness", we motivate future research in balancing local modality strengths with global representations.
</details>
<details>
<summary>摘要</summary>
多模态重识别（ReID）是一个广泛应用的检索任务，旨在透过多种数据流处理对象的重识别，引起了许多研究人员将多种模式融合到一个统一表示中。然而，我们的调查发现，使用合并技术时常会产生优化后的下降，相比于单独训练模式时的表示。我们认为这是由于将多个模式融合时，不小心放弃各个模式的训练目标，导致模式懒散（modality laziness）的问题。我们提出一种复杂的观点，认为这种放弃可以使某些模式在任务相关的信息上充分发挥作用，同时防止不相关的数据泛染。我们的发现还表明，将单模式 concatenation（UniCat）和其他融合技术与最佳训练技术结合，可以在多模态ReIDbenchmark上超越当前状态的表现。我们的研究揭示了“模式懒散”的双重剑，激励未来的研究人员在地方模式强大性和全球表示之间寻求平衡。
</details></li>
</ul>
<hr>
<h2 id="A-Review-on-the-Applications-of-Machine-Learning-for-Tinnitus-Diagnosis-Using-EEG-Signals"><a href="#A-Review-on-the-Applications-of-Machine-Learning-for-Tinnitus-Diagnosis-Using-EEG-Signals" class="headerlink" title="A Review on the Applications of Machine Learning for Tinnitus Diagnosis Using EEG Signals"></a>A Review on the Applications of Machine Learning for Tinnitus Diagnosis Using EEG Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18795">http://arxiv.org/abs/2310.18795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farzaneh Ramezani, Hamidreza Bolhasani</li>
<li>for: 这个研究的目的是使用机器学习技术来识别或预测听力障碍患者，以便早期诊断和治疗。</li>
<li>methods: 这些研究使用了多种数据模式和机器学习技术来识别和分类听力障碍患者。</li>
<li>results: 这些研究的结果表明，使用EEG信号作为输入数据，可以准确地识别和预测听力障碍患者。但是，研究结果存在差异和矛盾，需要进一步的研究以更好地理解听力障碍的特征和预测方法。<details>
<summary>Abstract</summary>
Tinnitus is a prevalent hearing disorder that can be caused by various factors such as age, hearing loss, exposure to loud noises, ear infections or tumors, certain medications, head or neck injuries, and psychological conditions like anxiety and depression. While not every patient requires medical attention, about 20% of sufferers seek clinical intervention. Early diagnosis is crucial for effective treatment. New developments have been made in tinnitus detection to aid in early detection of this illness. Over the past few years, there has been a notable growth in the usage of electroencephalography (EEG) to study variations in oscillatory brain activity related to tinnitus. However, the results obtained from numerous studies vary greatly, leading to conflicting conclusions. Currently, clinicians rely solely on their expertise to identify individuals with tinnitus. Researchers in this field have incorporated various data modalities and machine-learning techniques to aid clinicians in identifying tinnitus characteristics and classifying people with tinnitus. The purpose of writing this article is to review articles that focus on using machine learning (ML) to identify or predict tinnitus patients using EEG signals as input data. We have evaluated 11 articles published between 2016 and 2023 using a systematic literature review (SLR) method. This article arranges perfect summaries of all the research reviewed and compares the significant aspects of each. Additionally, we performed statistical analyses to gain a deeper comprehension of the most recent research in this area. Almost all of the reviewed articles followed a five-step procedure to achieve the goal of tinnitus. Disclosure. Finally, we discuss the open affairs and challenges in this method of tinnitus recognition or prediction and suggest future directions for research.
</details>
<details>
<summary>摘要</summary>
听力障碍（tinnitus）是一种非常普遍的听力疾病，可以由年龄、听力损伤、高音响应、耳感染或肿瘤、某些药物、头或Neck伤等多种因素引起。虽然不是所有患者需要医疗干预，但约20%的患者会寻求临床 intervención。早期诊断非常重要，以便有效的治疗。在过去几年中，对听力障碍检测方法的新发展带来了一定的进步。通过使用电enzephalography（EEG）研究听力障碍相关的脑动力学特征，已经有了一定的进步。然而，这些研究的结果很多样化，导致了不一致的结论。目前，临床医生仅仅靠自己的专业知识来诊断听力障碍。研究人员在这一领域已经结合了不同的数据模式和机器学习技术，以帮助临床医生识别听力障碍特征并将患者分类。本文的目的是对使用机器学习（ML）识别或预测听力障碍患者的研究进行系统性的文献综述。我们对2016年至2023年间发表的11篇文章进行了系统性的文献综述，并对每篇文章进行了精确的摘要。此外，我们还进行了统计分析，以更深入地了解最近的研究发展。大多数复习的文章遵循了五步程序来实现听力障碍识别或预测的目标。最后，我们讨论了这一方法的开放问题和挑战，并建议未来的研究方向。
</details></li>
</ul>
<hr>
<h2 id="PrObeD-Proactive-Object-Detection-Wrapper"><a href="#PrObeD-Proactive-Object-Detection-Wrapper" class="headerlink" title="PrObeD: Proactive Object Detection Wrapper"></a>PrObeD: Proactive Object Detection Wrapper</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18788">http://arxiv.org/abs/2310.18788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vishal Asnani, Abhinav Kumar, Suya You, Xiaoming Liu</li>
<li>For: 提高$2D$物体检测的性能，使其能够更好地检测普通和掩蔽的图像中的物体。* Methods: 基于 wrapper 的扩展方法 PrObeD，包括一个编码器-解码器架构，通过生成图像依赖的信号（模板）来加密输入图像，并通过解码器从Encrypted images中提取这个模板。* Results: 对 MS-COCO、CAMO、COD$10$K 和 NC$4$K 数据集进行了实验，并在不同的检测器上显示了提高的检测性能。<details>
<summary>Abstract</summary>
Previous research in $2D$ object detection focuses on various tasks, including detecting objects in generic and camouflaged images. These works are regarded as passive works for object detection as they take the input image as is. However, convergence to global minima is not guaranteed to be optimal in neural networks; therefore, we argue that the trained weights in the object detector are not optimal. To rectify this problem, we propose a wrapper based on proactive schemes, PrObeD, which enhances the performance of these object detectors by learning a signal. PrObeD consists of an encoder-decoder architecture, where the encoder network generates an image-dependent signal termed templates to encrypt the input images, and the decoder recovers this template from the encrypted images. We propose that learning the optimum template results in an object detector with an improved detection performance. The template acts as a mask to the input images to highlight semantics useful for the object detector. Finetuning the object detector with these encrypted images enhances the detection performance for both generic and camouflaged. Our experiments on MS-COCO, CAMO, COD$10$K, and NC$4$K datasets show improvement over different detectors after applying PrObeD. Our models/codes are available at https://github.com/vishal3477/Proactive-Object-Detection.
</details>
<details>
<summary>摘要</summary>
PrObeD consists of an encoder-decoder architecture, where the encoder network generates an image-dependent signal called templates to encrypt the input images, and the decoder recovers this template from the encrypted images. We believe that learning the optimum template results in an object detector with improved detection performance. The template acts as a mask to the input images, highlighting semantics that are useful for the object detector. Finetuning the object detector with these encrypted images improves the detection performance for both generic and camouflaged objects.Our experiments on the MS-COCO, CAMO, COD$10$K, and NC$4$K datasets show that PrObeD improves the detection performance of different object detectors. Our models and codes are available at https://github.com/vishal3477/Proactive-Object-Detection.Simplified Chinese translation:前一些研究主要关注在二维对象检测中的不同任务，包括检测通用和涂抹图像中的对象。这些工作被视为通过对输入图像进行修改来实现对象检测的被动方法。然而，神经网络中的学习结果可能并不是最优的，因此我们认为这些学习结果可能并不是最优的。为了解决这个问题，我们提出了一种基于主动方法的包装器，称为PrObeD，它可以提高对象检测器的性能。PrObeD包括一个编码器-解码器架构，其中编码器网络生成一个图像具有依赖关系的信号，称为模板，并将这个模板用于对输入图像进行加密。解码器则可以从加密后的图像中提取出这个模板。我们认为，学习最优的模板可以提高对象检测器的检测性能。模板可以视为对输入图像进行修饰，使对象检测器更容易察见用于检测的 semantics。通过在这些加密图像上进行训练，可以提高对象检测器的检测性能，包括通用和涂抹图像中的对象。我们在 MS-COCO、CAMO、COD$10$K 和 NC$4$K 数据集上进行了实验，结果显示 PrObeD 可以提高不同的对象检测器的检测性能。我们的模型和代码可以在 https://github.com/vishal3477/Proactive-Object-Detection 上获取。
</details></li>
</ul>
<hr>
<h2 id="CityRefer-Geography-aware-3D-Visual-Grounding-Dataset-on-City-scale-Point-Cloud-Data"><a href="#CityRefer-Geography-aware-3D-Visual-Grounding-Dataset-on-City-scale-Point-Cloud-Data" class="headerlink" title="CityRefer: Geography-aware 3D Visual Grounding Dataset on City-scale Point Cloud Data"></a>CityRefer: Geography-aware 3D Visual Grounding Dataset on City-scale Point Cloud Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18773">http://arxiv.org/abs/2310.18773</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/atr-dbi/cityrefer">https://github.com/atr-dbi/cityrefer</a></li>
<li>paper_authors: Taiki Miyanishi, Fumiya Kitamori, Shuhei Kurita, Jungdae Lee, Motoaki Kawanabe, Nakamasa Inoue</li>
<li>for: 城市级3D点云数据是用于表示细节和复杂的户外结构的有前途的方式，可以用于吸引人的应用，如自适应导航和无人机。</li>
<li>methods: 我们引入了CityRefer数据集，其包含35k个自然语言描述和5k个地标标签，以及与OpenStreetMap的同步。我们还开发了基线系统，可以学习编码语言描述、3D物体实例和城市的地标信息，以实现视Grounding。</li>
<li>results: 据我们知道，CityRefer数据集是当前最大的城市级视Grounding数据集，用于本地化特定3D对象。<details>
<summary>Abstract</summary>
City-scale 3D point cloud is a promising way to express detailed and complicated outdoor structures. It encompasses both the appearance and geometry features of segmented city components, including cars, streets, and buildings, that can be utilized for attractive applications such as user-interactive navigation of autonomous vehicles and drones. However, compared to the extensive text annotations available for images and indoor scenes, the scarcity of text annotations for outdoor scenes poses a significant challenge for achieving these applications. To tackle this problem, we introduce the CityRefer dataset for city-level visual grounding. The dataset consists of 35k natural language descriptions of 3D objects appearing in SensatUrban city scenes and 5k landmarks labels synchronizing with OpenStreetMap. To ensure the quality and accuracy of the dataset, all descriptions and labels in the CityRefer dataset are manually verified. We also have developed a baseline system that can learn encoded language descriptions, 3D object instances, and geographical information about the city's landmarks to perform visual grounding on the CityRefer dataset. To the best of our knowledge, the CityRefer dataset is the largest city-level visual grounding dataset for localizing specific 3D objects.
</details>
<details>
<summary>摘要</summary>
城市级3D点云是一种有前途的方式表达细节和复杂的户外结构。它包括城市组成部分的外观和几何特征，包括汽车、街道和建筑物，可以用于有吸引力的应用，如用户交互导航自动汽车和无人机。然而，相比于图像和室内场景的广泛文本注释，户外场景的文本注释的缺乏对市场具有显著的挑战，以实现这些应用。为解决这个问题，我们介绍了城市参照数据集（CityRefer），该数据集包含35000个自然语言描述3D объек在敏捷城市场景中出现的场景和5000个地标标签，与OpenStreetMap相匹配。为保证数据集的质量和准确性，所有的描述和标签在CityRefer数据集中都是手动验证的。我们还开发了一个基eline系统，可以学习编码的自然语言描述、3D объек实例和城市的地标信息，以在CityRefer数据集上进行视觉定位。据我们所知，CityRefer数据集是当前最大的城市级视觉定位数据集，用于特定3D对象的本地化。
</details></li>
</ul>
<hr>
<h2 id="Online-Multi-view-Anomaly-Detection-with-Disentangled-Product-of-Experts-Modeling"><a href="#Online-Multi-view-Anomaly-Detection-with-Disentangled-Product-of-Experts-Modeling" class="headerlink" title="Online Multi-view Anomaly Detection with Disentangled Product-of-Experts Modeling"></a>Online Multi-view Anomaly Detection with Disentangled Product-of-Experts Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18728">http://arxiv.org/abs/2310.18728</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cshaowang/dPoE">https://github.com/cshaowang/dPoE</a></li>
<li>paper_authors: Hao Wang, Zhi-Qi Cheng, Jingdong Sun, Xin Yang, Xiao Wu, Hongyang Chen, Yan Yang</li>
<li>for: 本研究的目的是提出一种能够处理多视图数据的异常检测方法，以解决现有方法中的一些缺陷，如只适用于两个视图或特定类型异常等。</li>
<li>methods: 本研究使用了多视图学习、分解表示学习和生成模型等方法，其中包括一个Product-of-Experts（PoE）层、一个Total Correction（TC）推定器和一个联合损失函数等。</li>
<li>results: 经过广泛的实验测试，提出的dPoE模型在六个真实世界数据集上表现出色，舒过基elines明显。<details>
<summary>Abstract</summary>
Multi-view or even multi-modal data is appealing yet challenging for real-world applications. Detecting anomalies in multi-view data is a prominent recent research topic. However, most of the existing methods 1) are only suitable for two views or type-specific anomalies, 2) suffer from the issue of fusion disentanglement, and 3) do not support online detection after model deployment. To address these challenges, our main ideas in this paper are three-fold: multi-view learning, disentangled representation learning, and generative model. To this end, we propose dPoE, a novel multi-view variational autoencoder model that involves (1) a Product-of-Experts (PoE) layer in tackling multi-view data, (2) a Total Correction (TC) discriminator in disentangling view-common and view-specific representations, and (3) a joint loss function in wrapping up all components. In addition, we devise theoretical information bounds to control both view-common and view-specific representations. Extensive experiments on six real-world datasets demonstrate that the proposed dPoE outperforms baselines markedly.
</details>
<details>
<summary>摘要</summary>
多视图或多模式数据吸引了现实应用的研究者，但是检测多视图数据中异常现象是一个挑战。现有的大多数方法1）只适用于两个视图或类型特定异常，2）受混合解决问题的影响，3）无法在模型部署后进行在线检测。为解决这些挑战，我们的主要想法是三重：多视图学习、分解表示学习和生成模型。为此，我们提出了dPoE，一种新的多视图变量自适应器模型，它包括（1）一个Product-of-Experts（PoE）层来处理多视图数据，（2）一个总正确（TC）推分器来分解视图共同和视图特定表示，以及（3）一个联合损失函数来包装所有组件。此外，我们设计了理论信息约束来控制视图共同和视图特定表示。广泛的实验证明了我们提出的dPoE明显超过基eline。
</details></li>
</ul>
<hr>
<h2 id="Audio-Visual-Instance-Segmentation"><a href="#Audio-Visual-Instance-Segmentation" class="headerlink" title="Audio-Visual Instance Segmentation"></a>Audio-Visual Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18709">http://arxiv.org/abs/2310.18709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruohao Guo, Yaru Chen, Yanyu Qi, Wenzhen Yue, Dantong Niu, Xianghua Ying</li>
<li>for: 这个论文目标是提出一种新的多模态任务，即音频视频实例分割（AVIS），目的是同时在可见视频中识别、分割和跟踪各种声音实例。</li>
<li>methods: 该论文使用了一种简单的基础模型，其中添加了一个音频分支和一个跨模态融合模块，以使用Mask2Former来找到所有声音实例。</li>
<li>results: 该论文使用两种脊梁进行评估，并得到了在AVISeg上的较好的性能。作者认为，AVIS将激励社区尝试更加全面的多模态理解。<details>
<summary>Abstract</summary>
In this paper, we propose a new multi-modal task, namely audio-visual instance segmentation (AVIS), in which the goal is to identify, segment, and track individual sounding object instances in audible videos, simultaneously. To our knowledge, it is the first time that instance segmentation has been extended into the audio-visual domain. To better facilitate this research, we construct the first audio-visual instance segmentation benchmark (AVISeg). Specifically, AVISeg consists of 1,258 videos with an average duration of 62.6 seconds from YouTube and public audio-visual datasets, where 117 videos have been annotated by using an interactive semi-automatic labeling tool based on the Segment Anything Model (SAM). In addition, we present a simple baseline model for the AVIS task. Our new model introduces an audio branch and a cross-modal fusion module to Mask2Former to locate all sounding objects. Finally, we evaluate the proposed method using two backbones on AVISeg. We believe that AVIS will inspire the community towards a more comprehensive multi-modal understanding.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一个新的多模态任务，即听视频实例分割（AVIS），目的是同时在听sible的视频中识别、分割和跟踪具有声音的对象实例。我们认为这是多模态理解的一个新的突破口。为了更好地推进这项研究，我们建立了首个听视频实例分割benchmark（AVISeg）。具体来说，AVISeg包括YouTube和公共听视频数据集的1,258个视频，视频的平均时长为62.6秒，其中117个视频通过使用基于Segment Anything Model（SAM）的交互式半自动标注工具进行了标注。此外，我们提出了一个简单的基线模型 дляAVIS任务。我们的新模型在Mask2Former模型中添加了一个声音支持和一个跨模态融合模块，以便在听sible的视频中找到所有的声音对象。最后，我们使用两个背景网络测试了我们的提议方法。我们认为AVIS将鼓励社区更加全面地理解多模态。
</details></li>
</ul>
<hr>
<h2 id="Triplet-Attention-Transformer-for-Spatiotemporal-Predictive-Learning"><a href="#Triplet-Attention-Transformer-for-Spatiotemporal-Predictive-Learning" class="headerlink" title="Triplet Attention Transformer for Spatiotemporal Predictive Learning"></a>Triplet Attention Transformer for Spatiotemporal Predictive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18698">http://arxiv.org/abs/2310.18698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuesong Nie, Xi Chen, Haoyuan Jin, Zhihang Zhu, Yunfeng Yan, Donglian Qi</li>
<li>for: 预测未来序列 based on 历史序列，提高预测质量 while maintaining 计算效率</li>
<li>methods: 使用 triplet attention transformer，包括 Triplet Attention Module (TAM)，替代传统的 recurrent units， capture both inter-frame dynamics 和 intra-frame static features</li>
<li>results: 在多种场景下，包括移动对象轨迹预测、交通流预测、驾驶场景预测和人体动作捕捉，实现了 state-of-the-art 性能，超过了现有的 recurrent-based 和 recurrent-free 方法<details>
<summary>Abstract</summary>
Spatiotemporal predictive learning offers a self-supervised learning paradigm that enables models to learn both spatial and temporal patterns by predicting future sequences based on historical sequences. Mainstream methods are dominated by recurrent units, yet they are limited by their lack of parallelization and often underperform in real-world scenarios. To improve prediction quality while maintaining computational efficiency, we propose an innovative triplet attention transformer designed to capture both inter-frame dynamics and intra-frame static features. Specifically, the model incorporates the Triplet Attention Module (TAM), which replaces traditional recurrent units by exploring self-attention mechanisms in temporal, spatial, and channel dimensions. In this configuration: (i) temporal tokens contain abstract representations of inter-frame, facilitating the capture of inherent temporal dependencies; (ii) spatial and channel attention combine to refine the intra-frame representation by performing fine-grained interactions across spatial and channel dimensions. Alternating temporal, spatial, and channel-level attention allows our approach to learn more complex short- and long-range spatiotemporal dependencies. Extensive experiments demonstrate performance surpassing existing recurrent-based and recurrent-free methods, achieving state-of-the-art under multi-scenario examination including moving object trajectory prediction, traffic flow prediction, driving scene prediction, and human motion capture.
</details>
<details>
<summary>摘要</summary>
《空时空间预测学习》提供了一种自主学习 paradigma，允许模型通过预测未来序列基于历史序列来学习空间和时间模式。主流方法受限于缺乏并行化和实际场景下的表现不佳，我们提议一种创新的 triplet attention transformer，用于捕捉空间、时间和通道维度的自我注意力机制。在这种配置下：（i）时间ток包含了抽象的间隔frame的表示，以便捕捉自然的时间依赖关系；（ii）空间和通道注意力结合以进一步细化内帧表示，通过在空间和通道维度进行细化的交互来增强模型对于短距离和长距离空间时间关系的学习能力。 alternate temporal、空间和通道级别的注意力允许我们的方法学习更复杂的短距离和长距离空间时间关系。广泛的实验证明了我们的方法在多种场景下，包括人体动作跟踪、交通流量预测、驾驶场景预测和人体动作捕捉等，性能超过了现有的循环单元和循环自由方法，实现了状态当前的水平。
</details></li>
</ul>
<hr>
<h2 id="Foundational-Models-in-Medical-Imaging-A-Comprehensive-Survey-and-Future-Vision"><a href="#Foundational-Models-in-Medical-Imaging-A-Comprehensive-Survey-and-Future-Vision" class="headerlink" title="Foundational Models in Medical Imaging: A Comprehensive Survey and Future Vision"></a>Foundational Models in Medical Imaging: A Comprehensive Survey and Future Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18689">http://arxiv.org/abs/2310.18689</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bobby Azad, Reza Azad, Sania Eskandari, Afshin Bozorgpour, Amirhossein Kazerouni, Islem Rekik, Dorit Merhof</li>
<li>For: This paper provides a comprehensive overview of foundation models in the domain of medical imaging, with a focus on their applications, opportunities, and future directions.* Methods: The paper classifies foundation models within the medical domain based on training strategies, imaging modalities, specific organs of interest, and algorithms integral to these models.* Results: The paper discusses the practical use cases of some selected approaches and addresses the challenges and research pathways associated with foundational models in medical imaging, including interpretability, data management, computational requirements, and contextual comprehension.<details>
<summary>Abstract</summary>
Foundation models, large-scale, pre-trained deep-learning models adapted to a wide range of downstream tasks have gained significant interest lately in various deep-learning problems undergoing a paradigm shift with the rise of these models. Trained on large-scale dataset to bridge the gap between different modalities, foundation models facilitate contextual reasoning, generalization, and prompt capabilities at test time. The predictions of these models can be adjusted for new tasks by augmenting the model input with task-specific hints called prompts without requiring extensive labeled data and retraining. Capitalizing on the advances in computer vision, medical imaging has also marked a growing interest in these models. To assist researchers in navigating this direction, this survey intends to provide a comprehensive overview of foundation models in the domain of medical imaging. Specifically, we initiate our exploration by providing an exposition of the fundamental concepts forming the basis of foundation models. Subsequently, we offer a methodical taxonomy of foundation models within the medical domain, proposing a classification system primarily structured around training strategies, while also incorporating additional facets such as application domains, imaging modalities, specific organs of interest, and the algorithms integral to these models. Furthermore, we emphasize the practical use case of some selected approaches and then discuss the opportunities, applications, and future directions of these large-scale pre-trained models, for analyzing medical images. In the same vein, we address the prevailing challenges and research pathways associated with foundational models in medical imaging. These encompass the areas of interpretability, data management, computational requirements, and the nuanced issue of contextual comprehension.
</details>
<details>
<summary>摘要</summary>
大量训练的深度学习模型（foundation models）在不同领域的深度学习问题中受到了非常大的关注。这些模型可以在各种模式之间进行Contextual reasoning，通过加入任务特定的提示（prompts）来调整模型的预测，无需大量的标注数据和重新训练。随着计算机视觉领域的进步，医学影像领域也开始关注这些模型。本文旨在为医学影像领域的研究人员提供一份全面的评论，以帮助他们在这个方向中探索。 Specifically, we begin by providing an overview of the fundamental concepts that underlie foundation models. We then offer a systematic taxonomy of foundation models within the medical domain, classifying them based on their training strategies, application domains, imaging modalities, specific organs of interest, and the algorithms used in these models. We also highlight the practical use cases of some selected approaches and discuss the opportunities, applications, and future directions of these large-scale pre-trained models for analyzing medical images. Furthermore, we address the challenges and research pathways associated with foundational models in medical imaging, including interpretability, data management, computational requirements, and the nuanced issue of contextual comprehension.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Object-Detection-in-Optical-Remote-Sensing-Imagery-via-Attention-based-Feature-Distillation"><a href="#Efficient-Object-Detection-in-Optical-Remote-Sensing-Imagery-via-Attention-based-Feature-Distillation" class="headerlink" title="Efficient Object Detection in Optical Remote Sensing Imagery via Attention-based Feature Distillation"></a>Efficient Object Detection in Optical Remote Sensing Imagery via Attention-based Feature Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18676">http://arxiv.org/abs/2310.18676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pourya Shamsolmoali, Jocelyn Chanussot, Huiyu Zhou, Yue Lu</li>
<li>for: 这篇论文主要针对的是实时观测中的有效物体检测方法，并且使用知识传播（KD）技术来实现轻量级模型，同时保持精度。</li>
<li>methods: 本文提出了一个新的知识传播方法，即注意力基本Distillation（AFD），这个方法可以将教师模型中的本地和全球资讯都传播到学生模型中，以提高学生模型的检测精度。此外，本文还引入了一个多例对劲机制，以分辨背景和前景元素，并将其传播到学生模型中。</li>
<li>results: 本文的实验结果显示，这个AFD方法可以在两个公共的航空图像benchmark上实现和其他状态顶对称模型相同的检测性能，同时具有轻量级的特点。<details>
<summary>Abstract</summary>
Efficient object detection methods have recently received great attention in remote sensing. Although deep convolutional networks often have excellent detection accuracy, their deployment on resource-limited edge devices is difficult. Knowledge distillation (KD) is a strategy for addressing this issue since it makes models lightweight while maintaining accuracy. However, existing KD methods for object detection have encountered two constraints. First, they discard potentially important background information and only distill nearby foreground regions. Second, they only rely on the global context, which limits the student detector's ability to acquire local information from the teacher detector. To address the aforementioned challenges, we propose Attention-based Feature Distillation (AFD), a new KD approach that distills both local and global information from the teacher detector. To enhance local distillation, we introduce a multi-instance attention mechanism that effectively distinguishes between background and foreground elements. This approach prompts the student detector to focus on the pertinent channels and pixels, as identified by the teacher detector. Local distillation lacks global information, thus attention global distillation is proposed to reconstruct the relationship between various pixels and pass it from teacher to student detector. The performance of AFD is evaluated on two public aerial image benchmarks, and the evaluation results demonstrate that AFD in object detection can attain the performance of other state-of-the-art models while being efficient.
</details>
<details>
<summary>摘要</summary>
Recently, efficient object detection methods have received significant attention in remote sensing. Although deep convolutional networks often have excellent detection accuracy, deploying them on resource-limited edge devices is challenging. Knowledge distillation (KD) is a strategy that can address this issue by making models lightweight while maintaining accuracy. However, existing KD methods for object detection have two limitations. First, they discard potentially important background information and only distill nearby foreground regions. Second, they only rely on global context, which limits the student detector's ability to acquire local information from the teacher detector.To address these challenges, we propose Attention-based Feature Distillation (AFD), a new KD approach that distills both local and global information from the teacher detector. To enhance local distillation, we introduce a multi-instance attention mechanism that effectively distinguishes between background and foreground elements. This approach prompts the student detector to focus on the pertinent channels and pixels, as identified by the teacher detector. Local distillation lacks global information, so we propose attention global distillation to reconstruct the relationship between various pixels and pass it from teacher to student detector.We evaluate the performance of AFD on two public aerial image benchmarks, and the results show that AFD can achieve the performance of other state-of-the-art models while being efficient.
</details></li>
</ul>
<hr>
<h2 id="Foundation-Models-for-Generalist-Geospatial-Artificial-Intelligence"><a href="#Foundation-Models-for-Generalist-Geospatial-Artificial-Intelligence" class="headerlink" title="Foundation Models for Generalist Geospatial Artificial Intelligence"></a>Foundation Models for Generalist Geospatial Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18660">http://arxiv.org/abs/2310.18660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Jakubik, Sujit Roy, C. E. Phillips, Paolo Fraccaro, Denys Godwin, Bianca Zadrozny, Daniela Szwarcman, Carlos Gomes, Gabby Nyirjesy, Blair Edwards, Daiki Kimura, Naomi Simumba, Linsong Chu, S. Karthik Mukkavilli, Devyani Lambhate, Kamal Das, Ranjini Bangalore, Dario Oliveira, Michal Muszynski, Kumar Ankur, Muthukumaran Ramasubramanian, Iksha Gurung, Sam Khallaghi, Hanxi, Li, Michael Cecil, Maryam Ahmadi, Fatemeh Kordi, Hamed Alemohammad, Manil Maskey, Raghu Ganti, Kommy Weldemariam, Rahul Ramachandran<br>for:* 这篇论文的目的是为了提出一个高度可调整且可重用的人工智能（AI）模型的开发，以便在地球科学和遥测中具有重要影响。methods:* 这篇论文使用了自我指导的方法来预训foundational models，然后使用小量标签数据进行精确化。results:* 这篇论文的研究显示了一个首次的框架可以有效地将foundational models预训和精确化，并在多个地球观测任务上表现出色，例如多 Spectral satellite imagery 的测试。<details>
<summary>Abstract</summary>
Significant progress in the development of highly adaptable and reusable Artificial Intelligence (AI) models is expected to have a significant impact on Earth science and remote sensing. Foundation models are pre-trained on large unlabeled datasets through self-supervision, and then fine-tuned for various downstream tasks with small labeled datasets. This paper introduces a first-of-a-kind framework for the efficient pre-training and fine-tuning of foundational models on extensive geospatial data. We have utilized this framework to create Prithvi, a transformer-based geospatial foundational model pre-trained on more than 1TB of multispectral satellite imagery from the Harmonized Landsat-Sentinel 2 (HLS) dataset. Our study demonstrates the efficacy of our framework in successfully fine-tuning Prithvi to a range of Earth observation tasks that have not been tackled by previous work on foundation models involving multi-temporal cloud gap imputation, flood mapping, wildfire scar segmentation, and multi-temporal crop segmentation. Our experiments show that the pre-trained model accelerates the fine-tuning process compared to leveraging randomly initialized weights. In addition, pre-trained Prithvi compares well against the state-of-the-art, e.g., outperforming a conditional GAN model in multi-temporal cloud imputation by up to 5pp (or 5.7%) in the structural similarity index. Finally, due to the limited availability of labeled data in the field of Earth observation, we gradually reduce the quantity of available labeled data for refining the model to evaluate data efficiency and demonstrate that data can be decreased significantly without affecting the model's accuracy. The pre-trained 100 million parameter model and corresponding fine-tuning workflows have been released publicly as open source contributions to the global Earth sciences community through Hugging Face.
</details>
<details>
<summary>摘要</summary>
“预计在人工智能（AI）模型的开发中，有 significante进步，这将对地球科学和远程感知产生重要影响。基础模型通过自我超vision，在大量无标签数据上自我预训练，然后使用小量标签数据进行精度调整。这篇论文介绍了一种新的框架，用于高效地预训练和精度调整基础模型，并在extensive geospatial数据上进行了实践。我们使用了这个框架，创造了一个基于转换器的地ospatial基础模型，名为Prithvi，并在 более чем 1TB的多spectral卫星图像上进行了预训练。我们的研究表明，我们的框架可以成功地将Prithvi fine-tune到多种地观测任务中，包括多temporal云阴掩模型、洪水地图、野火痕分割和多temporal作物分割。我们的实验显示，预训练后的模型可以加速 fine-tuning 过程，并且与随机初始化的权重相比，具有更高的准确率。此外，我们的Prithvi模型在多temporal云阴掩模型中与状态艺术模型进行比较，在结构相似指数中提高了5pp（或5.7%）。最后，由于地球观测领域内标注数据的有限性，我们逐渐减少可用标注数据的量来评估数据效率，并证明可以大幅减少数据量而无需影响模型的准确率。预训练10000万参数模型和相应的精度调整工作流已经公开发布在Hugging Face上，作为对全球地球科学社区的开源贡献。”
</details></li>
</ul>
<hr>
<h2 id="Med-DANet-V2-A-Flexible-Dynamic-Architecture-for-Efficient-Medical-Volumetric-Segmentation"><a href="#Med-DANet-V2-A-Flexible-Dynamic-Architecture-for-Efficient-Medical-Volumetric-Segmentation" class="headerlink" title="Med-DANet V2: A Flexible Dynamic Architecture for Efficient Medical Volumetric Segmentation"></a>Med-DANet V2: A Flexible Dynamic Architecture for Efficient Medical Volumetric Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18656">http://arxiv.org/abs/2310.18656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoran Shen, Yifu Zhang, Wenxuan Wang, Chen Chen, Jing Liu, Shanshan Song, Jiangyun Li</li>
<li>for: 这个论文的目的是提高医疗影像三维分类的计算效率。</li>
<li>methods: 这个方法使用了动态推论基于层次复杂度，并 dynamically选择适合不同层次的2D候选模型。</li>
<li>results: 该方法在BraTS 2019和2020的实验中实现了与前一代方法相似或更好的性能，并且具有许多少的模型复杂度。相比Med-DANet和TransBTS，我们的框架可以提高模型效率，并且具有相似的分类结果。<details>
<summary>Abstract</summary>
Recent works have shown that the computational efficiency of 3D medical image (e.g. CT and MRI) segmentation can be impressively improved by dynamic inference based on slice-wise complexity. As a pioneering work, a dynamic architecture network for medical volumetric segmentation (i.e. Med-DANet) has achieved a favorable accuracy and efficiency trade-off by dynamically selecting a suitable 2D candidate model from the pre-defined model bank for different slices. However, the issues of incomplete data analysis, high training costs, and the two-stage pipeline in Med-DANet require further improvement. To this end, this paper further explores a unified formulation of the dynamic inference framework from the perspective of both the data itself and the model structure. For each slice of the input volume, our proposed method dynamically selects an important foreground region for segmentation based on the policy generated by our Decision Network and Crop Position Network. Besides, we propose to insert a stage-wise quantization selector to the employed segmentation model (e.g. U-Net) for dynamic architecture adapting. Extensive experiments on BraTS 2019 and 2020 show that our method achieves comparable or better performance than previous state-of-the-art methods with much less model complexity. Compared with previous methods Med-DANet and TransBTS with dynamic and static architecture respectively, our framework improves the model efficiency by up to nearly 4.1 and 17.3 times with comparable segmentation results on BraTS 2019.
</details>
<details>
<summary>摘要</summary>
To address these issues, this paper proposes a unified formulation of the dynamic inference framework from both the data and model perspectives. For each slice of the input volume, our method dynamically selects an important foreground region for segmentation based on the policy generated by our Decision Network and Crop Position Network. Additionally, we propose inserting a stage-wise quantization selector into the employed segmentation model (such as U-Net) for dynamic architecture adapting.Experiments on the BraTS 2019 and 2020 datasets show that our method achieves performance comparable to or better than previous state-of-the-art methods with much less model complexity. Compared with previous methods Med-DANet and TransBTS with dynamic and static architecture, respectively, our framework improves model efficiency by up to nearly 4.1 and 17.3 times with comparable segmentation results on BraTS 2019.
</details></li>
</ul>
<hr>
<h2 id="Feature-Guided-Masked-Autoencoder-for-Self-supervised-Learning-in-Remote-Sensing"><a href="#Feature-Guided-Masked-Autoencoder-for-Self-supervised-Learning-in-Remote-Sensing" class="headerlink" title="Feature Guided Masked Autoencoder for Self-supervised Learning in Remote Sensing"></a>Feature Guided Masked Autoencoder for Self-supervised Learning in Remote Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18653">http://arxiv.org/abs/2310.18653</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhu-xlab/fgmae">https://github.com/zhu-xlab/fgmae</a></li>
<li>paper_authors: Yi Wang, Hugo Hernández Hernández, Conrad M Albrecht, Xiao Xiang Zhu</li>
<li>for: 这篇论文旨在探讨自我监督学习帮助vised transformer在远程感知中进行预训。</li>
<li>methods: 本论文使用Masked AutoEncoder（MAE）作为预训模型，并将spectral和spatial remote sensing图像特征作为改进MAE重建目标。</li>
<li>results: 实验结果显示Feature Guided Masked Autoencoder（FG-MAE）可以提高多spectral图像和SAR图像的semantic理解，并且具有很好的扩展性。<details>
<summary>Abstract</summary>
Self-supervised learning guided by masked image modelling, such as Masked AutoEncoder (MAE), has attracted wide attention for pretraining vision transformers in remote sensing. However, MAE tends to excessively focus on pixel details, thereby limiting the model's capacity for semantic understanding, in particular for noisy SAR images. In this paper, we explore spectral and spatial remote sensing image features as improved MAE-reconstruction targets. We first conduct a study on reconstructing various image features, all performing comparably well or better than raw pixels. Based on such observations, we propose Feature Guided Masked Autoencoder (FG-MAE): reconstructing a combination of Histograms of Oriented Graidents (HOG) and Normalized Difference Indices (NDI) for multispectral images, and reconstructing HOG for SAR images. Experimental results on three downstream tasks illustrate the effectiveness of FG-MAE with a particular boost for SAR imagery. Furthermore, we demonstrate the well-inherited scalability of FG-MAE and release a first series of pretrained vision transformers for medium resolution SAR and multispectral images.
</details>
<details>
<summary>摘要</summary>
自领导学习，如遮盲自动编码（MAE），在远程感知领域内吸引了广泛的关注，用于预训练视Transformer。然而，MAE往往过分关注像素细节，因此限制模型对Semantic理解的能力，特别是对噪音SAR图像。在这篇论文中，我们探索谱spectral和空间Remote sensing图像特征作为改进MAE重建目标。我们首先进行了不同图像特征的重建研究，并发现所有特征都可以相对或更好地than raw pixels。基于这些观察，我们提出了特征引导遮盲自动编码（FG-MAE）：对多spectral图像重建 histogram of oriented gradients（HOG）和normalized difference indices（NDI）的组合，对SAR图像重建HOG。我们的实验结果表明FG-MAE在三个下游任务上表现出了效果，特别是对SAR图像。此外，我们还证明了FG-MAE具有良好的扩展性，并发布了首个媒体分辨率SAR和多spectral图像预训练的视Transformer。
</details></li>
</ul>
<hr>
<h2 id="Local-Global-Self-Supervised-Visual-Representation-Learning"><a href="#Local-Global-Self-Supervised-Visual-Representation-Learning" class="headerlink" title="Local-Global Self-Supervised Visual Representation Learning"></a>Local-Global Self-Supervised Visual Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18651">http://arxiv.org/abs/2310.18651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alijavidani/local_global_representation_learning">https://github.com/alijavidani/local_global_representation_learning</a></li>
<li>paper_authors: Ali Javidani, Mohammad Amin Sadeghi, Babak Nadjar Araabi</li>
<li>for: 本研究旨在探讨将patch-level特征学习纳入现有自动学习批处理方法中，以提高学习得到的视觉表示的质量。</li>
<li>methods: 我们提出了一种简单 yet effective的patch-matching算法，可以在扩展视图下找到图像中匹配的补丁。然后，我们使用基于Vision Transformer（ViT）的自动学习框架，将扩展视图和补丁进行自我超vised学习。这种方法可以同时生成图像级别和补丁级别的表示。</li>
<li>results: 我们在小、中、大规模数据集上预训练了我们的方法，并证明了我们的方法可以在图像分类和下游任务中超越当前状态艺技。<details>
<summary>Abstract</summary>
Self-supervised representation learning methods mainly focus on image-level instance discrimination. This study explores the potential benefits of incorporating patch-level discrimination into existing methods to enhance the quality of learned representations by simultaneously looking at local and global visual features. Towards this idea, we present a straightforward yet effective patch-matching algorithm that can find the corresponding patches across the augmented views of an image. The augmented views are subsequently fed into a self-supervised learning framework employing Vision Transformer (ViT) as its backbone. The result is the generation of both image-level and patch-level representations. Leveraging the proposed patch-matching algorithm, the model minimizes the representation distance between not only the CLS tokens but also the corresponding patches. As a result, the model gains a more comprehensive understanding of both the entirety of the image as well as its finer details. We pretrain the proposed method on small, medium, and large-scale datasets. It is shown that our approach could outperform state-of-the-art image-level representation learning methods on both image classification and downstream tasks. Keywords: Self-Supervised Learning; Visual Representations; Local-Global Representation Learning; Patch-Wise Representation Learning; Vision Transformer (ViT)
</details>
<details>
<summary>摘要</summary>
自我监督学习方法主要关注图像级别的实例识别。本研究探讨可以将图像级别的识别与patch级别的识别结合到现有方法中，以提高学习的表示质量。为了实现这一目标，我们提出了一种简单又有效的补丁匹配算法，可以在扩展视图中找到图像中的相对应补丁。这些扩展视图然后被 feed into一个自我监督学习框架，使用 Vision Transformer（ViT）作为 backing。通过这种方法，我们可以同时生成图像级别的表示和patch级别的表示。通过补丁匹配算法，模型可以将 CLS Token 的表示距离和相应的补丁之间的表示距离减小。因此，模型可以更好地理解图像的整体特征和细节特征。我们在小、中、大样本大小上进行预训练，并显示了我们的方法可以在图像级别表示学习中超越状态艺术的图像级别表示学习方法。关键词：自我监督学习;视觉表示;本地-全局表示学习;补丁级别表示学习; Vision Transformer（ViT）
</details></li>
</ul>
<hr>
<h2 id="Switching-Temporary-Teachers-for-Semi-Supervised-Semantic-Segmentation"><a href="#Switching-Temporary-Teachers-for-Semi-Supervised-Semantic-Segmentation" class="headerlink" title="Switching Temporary Teachers for Semi-Supervised Semantic Segmentation"></a>Switching Temporary Teachers for Semi-Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18640">http://arxiv.org/abs/2310.18640</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naver-ai/dual-teacher">https://github.com/naver-ai/dual-teacher</a></li>
<li>paper_authors: Jaemin Na, Jung-Woo Ha, Hyung Jin Chang, Dongyoon Han, Wonjun Hwang</li>
<li>for: 这篇研究旨在提高 semi-supervised  semantic segmentation 的效果，并且解决 teacher 和学生模型之间的问题。</li>
<li>methods: 这篇研究使用了 dual temporary teacher 方法，将 teacher 和学生模型分为两个短期教师，以降低学生模型与教师模型之间的 Coupling 问题。</li>
<li>results: 这篇研究在 PASCAL VOC、Cityscapes 和 ADE20K 测试 benchmark 上达到了竞争性的表现，并且训练时间比 state-of-the-art 方法短得多。此外，这篇研究还证明了其方法是模型不敏感的，可以与 CNN 和 Transformer 等不同类型的模型搭配使用。<details>
<summary>Abstract</summary>
The teacher-student framework, prevalent in semi-supervised semantic segmentation, mainly employs the exponential moving average (EMA) to update a single teacher's weights based on the student's. However, EMA updates raise a problem in that the weights of the teacher and student are getting coupled, causing a potential performance bottleneck. Furthermore, this problem may become more severe when training with more complicated labels such as segmentation masks but with few annotated data. This paper introduces Dual Teacher, a simple yet effective approach that employs dual temporary teachers aiming to alleviate the coupling problem for the student. The temporary teachers work in shifts and are progressively improved, so consistently prevent the teacher and student from becoming excessively close. Specifically, the temporary teachers periodically take turns generating pseudo-labels to train a student model and maintain the distinct characteristics of the student model for each epoch. Consequently, Dual Teacher achieves competitive performance on the PASCAL VOC, Cityscapes, and ADE20K benchmarks with remarkably shorter training times than state-of-the-art methods. Moreover, we demonstrate that our approach is model-agnostic and compatible with both CNN- and Transformer-based models. Code is available at \url{https://github.com/naver-ai/dual-teacher}.
</details>
<details>
<summary>摘要</summary>
教师-学生框架，广泛存在 semi-supervised 语义分割中，主要采用积分移动平均（EMA）来更新单个教师的参数基于学生的。然而，EMA 更新可能会导致教师和学生的参数相互关联，从而引起性能瓶颈。此外，这种问题可能会在具有更复杂的标签，如分割mask，但具有少量标注数据的情况下变得更加严重。本文介绍了 Dual Teacher，一种简单 yet effective 的方法，它采用了双临时教师来解决学生模型与教师模型之间的关联问题。这两个临时教师会在交替的时间间隔内为学生模型生成 pseudo-标签，以便在每个轮次中维护学生模型的独特特征。因此， Dual Teacher 在 PASCAL VOC、Cityscapes 和 ADE20K 测试集上 achieve 竞争性性能，并且训练时间较短于当前state-of-the-art 方法。此外，我们还证明了我们的方法是模型无关的，可以与 CNN 和 Transformer 等模型结合使用。代码可以在 \url{https://github.com/naver-ai/dual-teacher} 上找到。
</details></li>
</ul>
<hr>
<h2 id="Towards-Plastic-and-Stable-Exemplar-Free-Incremental-Learning-A-Dual-Learner-Framework-with-Cumulative-Parameter-Averaging"><a href="#Towards-Plastic-and-Stable-Exemplar-Free-Incremental-Learning-A-Dual-Learner-Framework-with-Cumulative-Parameter-Averaging" class="headerlink" title="Towards Plastic and Stable Exemplar-Free Incremental Learning: A Dual-Learner Framework with Cumulative Parameter Averaging"></a>Towards Plastic and Stable Exemplar-Free Incremental Learning: A Dual-Learner Framework with Cumulative Parameter Averaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18639">http://arxiv.org/abs/2310.18639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenju Sun, Qingyong Li, Wen Wang, Yangli-ao Geng</li>
<li>for: 这个研究是为了解决增量学习中的困难，特别是在例项自由情况下，当学习新任务时不能访问旧任务的样本。</li>
<li>methods: 这个方法使用了单任务学习（STL）和平均参数积存（CPA）技术，具有单任务学习和综合学习两种模式。</li>
<li>results: 实验结果显示，这个方法在CIFAR-100和Tiny-ImageNet上比过几个状态顶对的增量学习基eline表现出色，尤其在任务增量学习和类别增量学习情况下。<details>
<summary>Abstract</summary>
The dilemma between plasticity and stability presents a significant challenge in Incremental Learning (IL), especially in the exemplar-free scenario where accessing old-task samples is strictly prohibited during the learning of a new task. A straightforward solution to this issue is learning and storing an independent model for each task, known as Single Task Learning (STL). Despite the linear growth in model storage with the number of tasks in STL, we empirically discover that averaging these model parameters can potentially preserve knowledge across all tasks. Inspired by this observation, we propose a Dual-Learner framework with Cumulative Parameter Averaging (DLCPA). DLCPA employs a dual-learner design: a plastic learner focused on acquiring new-task knowledge and a stable learner responsible for accumulating all learned knowledge. The knowledge from the plastic learner is transferred to the stable learner via cumulative parameter averaging. Additionally, several task-specific classifiers work in cooperation with the stable learner to yield the final prediction. Specifically, when learning a new task, these modules are updated in a cyclic manner: i) the plastic learner is initially optimized using a self-supervised loss besides the supervised loss to enhance the feature extraction robustness; ii) the stable learner is then updated with respect to the plastic learner in a cumulative parameter averaging manner to maintain its task-wise generalization; iii) the task-specific classifier is accordingly optimized to align with the stable learner. Experimental results on CIFAR-100 and Tiny-ImageNet show that DLCPA outperforms several state-of-the-art exemplar-free baselines in both Task-IL and Class-IL settings.
</details>
<details>
<summary>摘要</summary>
increments 学习（IL）中的困境在选择between plasticity and stability 上是一个 significannot challenge, especially in the exemplar-free scenario where accessing old-task samples is strictly prohibited during the learning of a new task. A straightforward solution to this issue is learning and storing an independent model for each task, known as Single Task Learning (STL). Despite the linear growth in model storage with the number of tasks in STL, we empirically discover that averaging these model parameters can potentially preserve knowledge across all tasks. Inspired by this observation, we propose a Dual-Learner framework with Cumulative Parameter Averaging (DLCPA). DLCPA employs a dual-learner design: a plastic learner focused on acquiring new-task knowledge and a stable learner responsible for accumulating all learned knowledge. The knowledge from the plastic learner is transferred to the stable learner via cumulative parameter averaging. Additionally, several task-specific classifiers work in cooperation with the stable learner to yield the final prediction. Specifically, when learning a new task, these modules are updated in a cyclic manner: i) the plastic learner is initially optimized using a self-supervised loss besides the supervised loss to enhance the feature extraction robustness; ii) the stable learner is then updated with respect to the plastic learner in a cumulative parameter averaging manner to maintain its task-wise generalization; iii) the task-specific classifier is accordingly optimized to align with the stable learner. Experimental results on CIFAR-100 and Tiny-ImageNet show that DLCPA outperforms several state-of-the-art exemplar-free baselines in both Task-IL and Class-IL settings.
</details></li>
</ul>
<hr>
<h2 id="ODM3D-Alleviating-Foreground-Sparsity-for-Enhanced-Semi-Supervised-Monocular-3D-Object-Detection"><a href="#ODM3D-Alleviating-Foreground-Sparsity-for-Enhanced-Semi-Supervised-Monocular-3D-Object-Detection" class="headerlink" title="ODM3D: Alleviating Foreground Sparsity for Enhanced Semi-Supervised Monocular 3D Object Detection"></a>ODM3D: Alleviating Foreground Sparsity for Enhanced Semi-Supervised Monocular 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18620">http://arxiv.org/abs/2310.18620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijia Zhang, Dongnan Liu, Chao Ma, Weidong Cai</li>
<li>for: 提高单光图像3D物体检测（M3OD）的性能，使其能够更好地检测自动驾驶中的3D物体。</li>
<li>methods: 使用semi-supervised learning，将LiDAR频谱知识注入到单光图像检测器中，并通过提取前景稀缺性来进行更加有效的知识传递。</li>
<li>results: 在KITTI验证和测试环境中，其方法 ranked 1st，在BEV和3D检测纪录中都有显著的提升，舒过所有现有的单光方法，包括直接监督和半监督方法。<details>
<summary>Abstract</summary>
Monocular 3D object detection (M3OD) is a significant yet inherently challenging task in autonomous driving due to absence of implicit depth cues in a single RGB image. In this paper, we strive to boost currently underperforming monocular 3D object detectors by leveraging an abundance of unlabelled data via semi-supervised learning. Our proposed ODM3D framework entails cross-modal knowledge distillation at various levels to inject LiDAR-domain knowledge into a monocular detector during training. By identifying foreground sparsity as the main culprit behind existing methods' suboptimal training, we exploit the precise localisation information embedded in LiDAR points to enable more foreground-attentive and efficient distillation via the proposed BEV occupancy guidance mask, leading to notably improved knowledge transfer and M3OD performance. Besides, motivated by insights into why existing cross-modal GT-sampling techniques fail on our task at hand, we further design a novel cross-modal object-wise data augmentation strategy for effective RGB-LiDAR joint learning. Our method ranks 1st in both KITTI validation and test benchmarks, significantly surpassing all existing monocular methods, supervised or semi-supervised, on both BEV and 3D detection metrics.
</details>
<details>
<summary>摘要</summary>
《单目三维物体检测（M3OD）是自主驾驶中的一项重要 yet inherently 挑战性任务，因为单个 RGB 图像中缺乏隐式深度提示。在这篇文章中，我们努力提高目前的单目三维物体检测器，通过利用大量未标注数据进行 semi-supervised 学习。我们提出的 ODM3D 框架在不同层次进行交叉模态知识填充，以在训练中注入 LiDAR 频谱知识到单目检测器。通过发现前景稀畴是现有方法训练不佳的主要原因，我们利用 LiDAR 点的精确地址信息来实现更加前景注意和高效的填充，从而提高知识传递和 M3OD 性能。此外，鉴于现有交叉模态 GT 采样技术在我们任务上失效的原因，我们还设计了一种新的交叉模态对象增强数据采样策略，以便有效地在 RGB 和 LiDAR  JOINT 学习中进行对象增强。我们的方法在 KITTI 验证和测试benchmark上rank 1st，明显超过了所有现有的单目方法，包括直接监督和 semi-supervised 方法，在 BEV 和 3D 检测 метриках上。
</details></li>
</ul>
<hr>
<h2 id="Domain-Generalisation-via-Risk-Distribution-Matching"><a href="#Domain-Generalisation-via-Risk-Distribution-Matching" class="headerlink" title="Domain Generalisation via Risk Distribution Matching"></a>Domain Generalisation via Risk Distribution Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18598">http://arxiv.org/abs/2310.18598</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nktoan/risk-distribution-matching">https://github.com/nktoan/risk-distribution-matching</a></li>
<li>paper_authors: Toan Nguyen, Kien Do, Bao Duong, Thin Nguyen</li>
<li>for: 这篇论文旨在解决域对应（Domain Generalization，DG）中的问题，提出一个新的方法，利用风险分布来描述域，以 достиieving 域之对称。</li>
<li>methods: 这篇论文使用的方法是基于风险分布的，即使用最大mean距离（MMD）距离来测量风险分布之间的差异，并将其用于域之对称。</li>
<li>results: 实验结果显示，这篇论文提出的方法（Risk Distribution Matching，RDM）在标准的benchmark数据集上具有较高的域对称能力，并且比其他state-of-the-art DG方法更有效率。<details>
<summary>Abstract</summary>
We propose a novel approach for domain generalisation (DG) leveraging risk distributions to characterise domains, thereby achieving domain invariance. In our findings, risk distributions effectively highlight differences between training domains and reveal their inherent complexities. In testing, we may observe similar, or potentially intensifying in magnitude, divergences between risk distributions. Hence, we propose a compelling proposition: Minimising the divergences between risk distributions across training domains leads to robust invariance for DG. The key rationale behind this concept is that a model, trained on domain-invariant or stable features, may consistently produce similar risk distributions across various domains. Building upon this idea, we propose Risk Distribution Matching (RDM). Using the maximum mean discrepancy (MMD) distance, RDM aims to minimise the variance of risk distributions across training domains. However, when the number of domains increases, the direct optimisation of variance leads to linear growth in MMD computations, resulting in inefficiency. Instead, we propose an approximation that requires only one MMD computation, by aligning just two distributions: that of the worst-case domain and the aggregated distribution from all domains. Notably, this method empirically outperforms optimising distributional variance while being computationally more efficient. Unlike conventional DG matching algorithms, RDM stands out for its enhanced efficacy by concentrating on scalar risk distributions, sidestepping the pitfalls of high-dimensional challenges seen in feature or gradient matching. Our extensive experiments on standard benchmark datasets demonstrate that RDM shows superior generalisation capability over state-of-the-art DG methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的领域通用化（DG）方法，利用风险分布来特征化领域，从而实现领域不变性。我们发现，风险分布能够有效地披露训练领域之间的差异和内在复杂性。在测试中，我们可能会观察到类似或者可能加剧的差异between风险分布。因此，我们提出了一个有力的提议：将领域之间风险分布的差异降到最小化，以实现Robust Invariance for DG。这个概念的关键思想是，通过训练领域不变或稳定的特征，我们可以在不同领域上通过风险分布的匹配来实现模型的稳定性。基于这个想法，我们提出了风险分布匹配（RDM）。使用最大平均差（MMD）距离，RDM aimsto minimize the variance of risk distributions across training domains。然而，当领域数量增加时，直接优化差异会导致线性增长的MMD计算，从而变得不效率。因此，我们提出了一种简化方法，只需要一次MMD计算，通过对最坏领域的分布和所有领域的分布进行对应。与传统的DG匹配算法不同，RDM更加有效地做到了通过scalar风险分布来快速匹配，而不需要高维度的特征或梯度匹配。我们对标准 benchmark 数据集进行了广泛的实验，发现RDM在state-of-the-art DG方法中显示出了更好的总体化能力。
</details></li>
</ul>
<hr>
<h2 id="This-Looks-Like-Those-Illuminating-Prototypical-Concepts-Using-Multiple-Visualizations"><a href="#This-Looks-Like-Those-Illuminating-Prototypical-Concepts-Using-Multiple-Visualizations" class="headerlink" title="This Looks Like Those: Illuminating Prototypical Concepts Using Multiple Visualizations"></a>This Looks Like Those: Illuminating Prototypical Concepts Using Multiple Visualizations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18589">http://arxiv.org/abs/2310.18589</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/henrymachiyu/this-looks-like-those_protoconcepts">https://github.com/henrymachiyu/this-looks-like-those_protoconcepts</a></li>
<li>paper_authors: Chiyu Ma, Brandon Zhao, Chaofan Chen, Cynthia Rudin</li>
<li>for: 这个论文的目的是提出一种可解释的图像分类方法，结合深度学习和案例基础理解。</li>
<li>methods: 这个方法使用多个图像 patches 来学习概念，并使用这些概念进行可解释的图像分类。</li>
<li>results: 实验结果表明，这种方法可以应用于各种现有的prototype-based图像分类网络中，并在标准数据集上实现相同的准确率。<details>
<summary>Abstract</summary>
We present ProtoConcepts, a method for interpretable image classification combining deep learning and case-based reasoning using prototypical parts. Existing work in prototype-based image classification uses a ``this looks like that'' reasoning process, which dissects a test image by finding prototypical parts and combining evidence from these prototypes to make a final classification. However, all of the existing prototypical part-based image classifiers provide only one-to-one comparisons, where a single training image patch serves as a prototype to compare with a part of our test image. With these single-image comparisons, it can often be difficult to identify the underlying concept being compared (e.g., ``is it comparing the color or the shape?''). Our proposed method modifies the architecture of prototype-based networks to instead learn prototypical concepts which are visualized using multiple image patches. Having multiple visualizations of the same prototype allows us to more easily identify the concept captured by that prototype (e.g., ``the test image and the related training patches are all the same shade of blue''), and allows our model to create richer, more interpretable visual explanations. Our experiments show that our ``this looks like those'' reasoning process can be applied as a modification to a wide range of existing prototypical image classification networks while achieving comparable accuracy on benchmark datasets.
</details>
<details>
<summary>摘要</summary>
我们提出了ProtoConcepts，一种可读性高的图像分类方法，结合深度学习和倡议式推理，使用 protoypical parts。现有的图像分类方法中，使用“这看起来像那”的思维过程，将试验图像分解为 protoypical parts，并从这些 protoypical parts 中获取证据，以进行最终的分类。然而，所有的单一图像比较方法都仅提供一对一的比较，即一个训练图像区块作为一个 prototype，与试验图像中的一部分进行比较。这种单一图像比较可能很难理解到被比较的基本概念（例如，“是对颜色或形状的比较？”）。我们的提案方法改变 prototype-based 网络的架构，以学习 protoypical concepts，这些概念可以通过多个图像区块进行可读性更高的visual化。有多个可读性更高的 visual explanation，我们的模型可以更好地识别基本概念，并创建更加可读性更高的图像解释。我们的实验显示，我们的“这看起来像那”的思维过程可以与现有的 prototype-based 图像分类网络结合，在benchmark dataset上实现相似的准确性。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Multi-Modality-Learning-for-Multi-Label-Skin-Lesion-Classification"><a href="#Self-Supervised-Multi-Modality-Learning-for-Multi-Label-Skin-Lesion-Classification" class="headerlink" title="Self-Supervised Multi-Modality Learning for Multi-Label Skin Lesion Classification"></a>Self-Supervised Multi-Modality Learning for Multi-Label Skin Lesion Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18583">http://arxiv.org/abs/2310.18583</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dylan-h-wang/skin-sm3">https://github.com/dylan-h-wang/skin-sm3</a></li>
<li>paper_authors: Hao Wang, Euijoon Ahn, Lei Bi, Jinman Kim</li>
<li>for: 该研究旨在提高多Modal Skin Lesion 诊断精度，使用自助学习算法和多modal 特征。</li>
<li>methods: 该算法使用了对匹配的dermoscopic和临床图像进行最大化的相似性 Maximization，以及基于归一化的Clustering分析生成Surrogate pseudo-multi-labels。</li>
<li>results: 研究结果表明，该算法在 Seven-point Skin Lesion 数据集上表现更好于其他状态对照算法，并且能够准确地识别多种皮肤病变。<details>
<summary>Abstract</summary>
The clinical diagnosis of skin lesion involves the analysis of dermoscopic and clinical modalities. Dermoscopic images provide a detailed view of the surface structures whereas clinical images offer a complementary macroscopic information. The visual diagnosis of melanoma is also based on seven-point checklist which involves identifying different visual attributes. Recently, supervised learning approaches such as convolutional neural networks (CNNs) have shown great performances using both dermoscopic and clinical modalities (Multi-modality). The seven different visual attributes in the checklist are also used to further improve the the diagnosis. The performances of these approaches, however, are still reliant on the availability of large-scaled labeled data. The acquisition of annotated dataset is an expensive and time-consuming task, more so with annotating multi-attributes. To overcome this limitation, we propose a self-supervised learning (SSL) algorithm for multi-modality skin lesion classification. Our algorithm enables the multi-modality learning by maximizing the similarities between paired dermoscopic and clinical images from different views. In addition, we generate surrogate pseudo-multi-labels that represent seven attributes via clustering analysis. We also propose a label-relation-aware module to refine each pseudo-label embedding and capture the interrelationships between pseudo-multi-labels. We validated the effectiveness of our algorithm using well-benchmarked seven-point skin lesion dataset. Our results show that our algorithm achieved better performances than other state-of-the-art SSL counterparts.
</details>
<details>
<summary>摘要</summary>
诊断皮肤损伤的临床 диагностика involves 分析 dermoscopic 和临床特征。 dermoscopic 图像提供表面结构的详细视图，而临床图像提供较大规模的信息。诊断 меланомой 还是基于七点检查表，包括不同的视觉特征。最近，supervised learning 方法 such as convolutional neural networks (CNNs) 在多Modalities 上表现出色，使用dermoscopic 和临床特征。七个不同的视觉特征也用于进一步改进诊断。然而，这些方法的表现仍然受到大规模标注数据的可用性的限制。获取标注数据集是一项expensive 和时间consuming的任务，更是与标注多属性。为了突破这些限制，我们提出了一种自助学习（SSL）算法 для多Modalities 皮肤损伤分类。我们的算法使得多Modalities 学习，通过最大化不同视角dermoscopic 和临床图像之间的相似性。此外，我们生成了surrogate pseudo-multi-labels，通过分类分析代表七个属性。我们还提出了一种标签关系意识模块，用于修复每个 pseudo-label embedding 并捕捉 pseudo-multi-labels 之间的关系。我们 validated 我们的算法使用 well-benchmarked 七点皮肤损伤数据集。我们的结果显示，我们的算法在与其他状态时的SSL 对手中表现出色。
</details></li>
</ul>
<hr>
<h2 id="MultiScale-Spectral-Spatial-Convolutional-Transformer-for-Hyperspectral-Image-Classification"><a href="#MultiScale-Spectral-Spatial-Convolutional-Transformer-for-Hyperspectral-Image-Classification" class="headerlink" title="MultiScale Spectral-Spatial Convolutional Transformer for Hyperspectral Image Classification"></a>MultiScale Spectral-Spatial Convolutional Transformer for Hyperspectral Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18550">http://arxiv.org/abs/2310.18550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqiang Gong, Xian Zhou, Wen Yao</li>
<li>For: The paper is written for hyperspectral image classification, and it proposes a new architecture called MultiscaleFormer that captures both spectral and spatial information.* Methods: The proposed method uses multiscale spatial patches as tokens to formulate the spatial Transformer, and generates multiscale spectral-spatial representation of each pixel. It also uses a modified spectral-spatial CAF module to fuse cross-layer spectral and spatial information.* Results: The proposed method outperforms other architectures for hyperspectral image classification on commonly used real-world datasets.Here’s the simplified Chinese text for the three key points:* For: 这篇论文是为了干涉谱图像分类而写的，并提出了一种新的架构方案 called MultiscaleFormer，它能够捕捉谱图像的 spectral 和 spatial 信息。* Methods: 该方法使用多个级别的空间块作为 токен，以形成空间 transformer，并生成每个像素的多级 spectral-spatial 表示。它还使用一种修改后的 spectral-spatial CAF 模块来融合层次 spectral 和 spatial 信息。* Results: 该方法在常用的实际 dataset 上进行了实验，并与其他架构进行了比较，结果显示了该方法的优越性。<details>
<summary>Abstract</summary>
Due to the powerful ability in capturing the global information, Transformer has become an alternative architecture of CNNs for hyperspectral image classification. However, general Transformer mainly considers the global spectral information while ignores the multiscale spatial information of the hyperspectral image. In this paper, we propose a multiscale spectral-spatial convolutional Transformer (MultiscaleFormer) for hyperspectral image classification. First, the developed method utilizes multiscale spatial patches as tokens to formulate the spatial Transformer and generates multiscale spatial representation of each band in each pixel. Second, the spatial representation of all the bands in a given pixel are utilized as tokens to formulate the spectral Transformer and generate the multiscale spectral-spatial representation of each pixel. Besides, a modified spectral-spatial CAF module is constructed in the MultiFormer to fuse cross-layer spectral and spatial information. Therefore, the proposed MultiFormer can capture the multiscale spectral-spatial information and provide better performance than most of other architectures for hyperspectral image classification. Experiments are conducted over commonly used real-world datasets and the comparison results show the superiority of the proposed method.
</details>
<details>
<summary>摘要</summary>
由于Transformer的强大能力 capture global information，因此成为了干扰器的替代架构for hyperspectral image classification。然而，通常的Transformer主要考虑全球 spectral information，而忽略了多尺度空间信息的干扰器图像。在本文中，我们提出了一种多尺度 spectral-spatial convolutional Transformer（MultiscaleFormer）for hyperspectral image classification。首先，我们开发的方法使用多尺度空间块作为токен，并生成每个像素的多尺度空间表示。其次，所有帧在每个像素中的 spectral representation被作为 tokens，并生成每个像素的多尺度 spectral-spatial表示。此外，我们修改了 spectral-spatial CAF模块，以融合层次 spectral和空间信息。因此，我们提出的 MultiFormer 可以捕捉多尺度 spectral-spatial信息，并提供更好的性能 than most other architectures for hyperspectral image classification。我们对常用的实际 dataset进行了实验，并 compare 结果表明了我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="MEDAVET-Traffic-Vehicle-Anomaly-Detection-Mechanism-based-on-spatial-and-temporal-structures-in-vehicle-traffic"><a href="#MEDAVET-Traffic-Vehicle-Anomaly-Detection-Mechanism-based-on-spatial-and-temporal-structures-in-vehicle-traffic" class="headerlink" title="MEDAVET: Traffic Vehicle Anomaly Detection Mechanism based on spatial and temporal structures in vehicle traffic"></a>MEDAVET: Traffic Vehicle Anomaly Detection Mechanism based on spatial and temporal structures in vehicle traffic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18548">http://arxiv.org/abs/2310.18548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ana Rosalía Huamán Reyna, Alex Josué Flórez Farfán, Geraldo Pereira Rocha Filho, Sandra Sampaio, Robson de Grande, Luis Hideo, Vasconcelos Nakamura, Rodolfo Ipolito Meneguette</li>
<li>for: 这篇论文是为了模型交通异常检测而写的。</li>
<li>methods: 该论文使用计算机视觉技术进行车辆跟踪，并使用бипаolar图和Convex Hull算法定义运动区域。异常检测使用QuadTree和靠近 occluded 的数据结构。</li>
<li>results: 实验结果显示，该方法在 Track4 测试集上得到了85.7% 的 F1 分数和25.432 的平方差。<details>
<summary>Abstract</summary>
Currently, there are computer vision systems that help us with tasks that would be dull for humans, such as surveillance and vehicle tracking. An important part of this analysis is to identify traffic anomalies. An anomaly tells us that something unusual has happened, in this case on the highway. This paper aims to model vehicle tracking using computer vision to detect traffic anomalies on a highway. We develop the steps of detection, tracking, and analysis of traffic: the detection of vehicles from video of urban traffic, the tracking of vehicles using a bipartite graph and the Convex Hull algorithm to delimit moving areas. Finally for anomaly detection we use two data structures to detect the beginning and end of the anomaly. The first is the QuadTree that groups vehicles that are stopped for a long time on the road and the second that approaches vehicles that are occluded. Experimental results show that our method is acceptable on the Track4 test set, with an F1 score of 85.7% and a mean squared error of 25.432.
</details>
<details>
<summary>摘要</summary>
现在，计算机视觉系统可以帮助我们完成一些人类厌热的任务，如Surveillance和车辆跟踪。这个分析的一个重要组成部分是检测交通异常。异常告诉我们 чтоomething不寻常发生在公路上。这篇论文旨在通过计算机视觉来模型车辆跟踪，检测公路上的交通异常。我们开发了检测、跟踪和分析交通的步骤：从城市交通视频中检测车辆，使用二分图和Convex Hull算法来定义移动区域，并用两种数据结构来检测异常的开始和结束。实验结果表明，我们的方法在Track4测试集上得到了可接受的结果，F1分数为85.7%，平均方差为25.432。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/cs.CV_2023_10_28/" data-id="cloq1wl5z00kl7o888nodevrw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/cs.AI_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T12:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/cs.AI_2023_10_28/">cs.AI - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AI-for-Open-Science-A-Multi-Agent-Perspective-for-Ethically-Translating-Data-to-Knowledge"><a href="#AI-for-Open-Science-A-Multi-Agent-Perspective-for-Ethically-Translating-Data-to-Knowledge" class="headerlink" title="AI for Open Science: A Multi-Agent Perspective for Ethically Translating Data to Knowledge"></a>AI for Open Science: A Multi-Agent Perspective for Ethically Translating Data to Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18852">http://arxiv.org/abs/2310.18852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chase Yakaboski, Gregory Hyde, Clement Nyanhongo, Eugene Santos Jr</li>
<li>for: 本文提出了一种名为“AI for Open Science”（AI4OS）的概念，以便在科学实验室中提高开放性，并且将科学发现的开放化视为核心原则。</li>
<li>methods: 本文使用了知识发现和数据挖掘（KDD）的原则来正式化AI4OS的语言。并详细介绍了AI4OS系统中知识翻译的三个关键阶段，以及在这些阶段中应用开放性的具体方法。</li>
<li>results: 本文提出了一种用于评估AI4OS的理论指标，并阐述了这种指标的伦理意义。作者希望通过强调AI4OS，使AI4科学的自动化实验室不仅对开发者而言是有利，而且对社会也是有益。<details>
<summary>Abstract</summary>
AI for Science (AI4Science), particularly in the form of self-driving labs, has the potential to sideline human involvement and hinder scientific discovery within the broader community. While prior research has focused on ensuring the responsible deployment of AI applications, enhancing security, and ensuring interpretability, we also propose that promoting openness in AI4Science discoveries should be carefully considered. In this paper, we introduce the concept of AI for Open Science (AI4OS) as a multi-agent extension of AI4Science with the core principle of maximizing open knowledge translation throughout the scientific enterprise rather than a single organizational unit. We use the established principles of Knowledge Discovery and Data Mining (KDD) to formalize a language around AI4OS. We then discuss three principle stages of knowledge translation embedded in AI4Science systems and detail specific points where openness can be applied to yield an AI4OS alternative. Lastly, we formulate a theoretical metric to assess AI4OS with a supporting ethical argument highlighting its importance. Our goal is that by drawing attention to AI4OS we can ensure the natural consequence of AI4Science (e.g., self-driving labs) is a benefit not only for its developers but for society as a whole.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在科学领域（AI4Science），特别是自动驾驶室，有可能削弱人类参与度和阻碍科学发现。而且，现有研究主要集中在负责AI应用部署、加强安全性和保持可解释性等方面。我们还建议在AI4Science发现中保持开放性应该仔细考虑。在本文中，我们提出了AI для开放科学（AI4OS）的概念，它是AI4Science的多代理扩展，核心原则是在科学产业中最大化开放知识翻译。我们使用已有的知识发现和数据挖掘（KDD）原则来正式化AI4OS的语言。然后，我们讨论了AI4Science系统中知识翻译的三个基本阶段，并详细介绍了在每个阶段中开放性可以如何应用，以生成一种AI4OS的替代方案。最后，我们提出了一个理论指标来评估AI4OS，并附加了一个伦理论据，强调其重要性。我们的目标是通过吸引关注AI4OS，使AI4Science的自然后果（例如自动驾驶室）对发展者和社会都带来好处。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Data-Augmentations-on-Self-Semi-Fully-Supervised-Pre-trained-Models"><a href="#Exploring-Data-Augmentations-on-Self-Semi-Fully-Supervised-Pre-trained-Models" class="headerlink" title="Exploring Data Augmentations on Self-&#x2F;Semi-&#x2F;Fully- Supervised Pre-trained Models"></a>Exploring Data Augmentations on Self-&#x2F;Semi-&#x2F;Fully- Supervised Pre-trained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18850">http://arxiv.org/abs/2310.18850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shentong Mo, Zhun Sun, Chao Li</li>
<li>for:  investigate the effectiveness of data augmentation techniques in vision pre-trained models</li>
<li>methods:  apply 4 types of data augmentations (Random Erasing, CutOut, CutMix, and MixUp) to self-&#x2F;semi-&#x2F;fully-supervised pre-trained models</li>
<li>results:  observe that masking regions of images decreases invariance but increases diversity, while MixUp approach improves diversity with minimal decrease in invariance.Here’s the full text in Simplified Chinese:</li>
<li>for: 研究视觉预训模型中数据增强技术的效果</li>
<li>methods: 对自助&#x2F;半助&#x2F;全助预训模型应用4种数据增强方法（随机覆盖、剪辑、混合和混合）</li>
<li>results: 发现，对图像masking区域可以降低学习的不变性，但提供更大的多样性；而混合方法可以提高多样性，只是有一定的减少不变性。<details>
<summary>Abstract</summary>
Data augmentation has become a standard component of vision pre-trained models to capture the invariance between augmented views. In practice, augmentation techniques that mask regions of a sample with zero/mean values or patches from other samples are commonly employed in pre-trained models with self-/semi-/fully-supervised contrastive losses. However, the underlying mechanism behind the effectiveness of these augmentation techniques remains poorly explored. To investigate the problems, we conduct an empirical study to quantify how data augmentation affects performance. Concretely, we apply 4 types of data augmentations termed with Random Erasing, CutOut, CutMix and MixUp to a series of self-/semi-/fully- supervised pre-trained models. We report their performance on vision tasks such as image classification, object detection, instance segmentation, and semantic segmentation. We then explicitly evaluate the invariance and diversity of the feature embedding. We observe that: 1) Masking regions of the images decreases the invariance of the learned feature embedding while providing a more considerable diversity. 2) Manual annotations do not change the invariance or diversity of the learned feature embedding. 3) The MixUp approach improves the diversity significantly, with only a marginal decrease in terms of the invariance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>预训练模型中的数据扩充已成为标准组件，以捕捉不同扩充视图之间的不变性。在实践中，通常使用随机将区域Masking为零或平均值的技术来实现预训练模型，并使用自我/半自动/全自动对比损失。然而，这些扩充技术的下面机制仍然不够了解。为了调查问题，我们进行了一项实验来衡量数据扩充对性能的影响。具体来说，我们将4种数据扩充方法称为随机擦除、CutOut、CutMix和MixUp应用于一系列自我/半自动/全自动预训练模型。我们则Report它们在视觉任务中的性能，包括图像分类、物体检测、实例分割和semantic segmentation。然后，我们显式评估扩充后feature embedding的不变性和多样性。我们发现：1. 将图像中的区域Masking为零或平均值会降低学习的feature embedding不变性，同时提供更大的多样性。2. 手动标注没有改变学习的feature embedding不变性或多样性。3. MixUp方法可以提高多样性，只有小量地降低不变性。
</details></li>
</ul>
<hr>
<h2 id="BanditPAM-Faster-k-medoids-Clustering"><a href="#BanditPAM-Faster-k-medoids-Clustering" class="headerlink" title="BanditPAM++: Faster $k$-medoids Clustering"></a>BanditPAM++: Faster $k$-medoids Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18844">http://arxiv.org/abs/2310.18844</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thrungroup/banditpam_plusplus_experiments">https://github.com/thrungroup/banditpam_plusplus_experiments</a></li>
<li>paper_authors: Mo Tiwari, Ryan Kang, Donghyun Lee, Sebastian Thrun, Chris Piech, Ilan Shomorony, Martin Jinye Zhang</li>
<li>for: 这个论文主要关注于提高$k$-medoids clustering算法的效率和准确性。</li>
<li>methods: 该论文提出了两种算法优化方法，即在每个迭代中重用归一化信息，以及在不同迭代之间重用信息。</li>
<li>results: 实验结果表明，使用提出的 BanditPAM++ 算法可以在 CIFAR10 数据集上返回同样的 clustering 解决方案，但是运行速度比 BanditPAM 快得多，例如在 CIFAR10 数据集上，BanditPAM++ 运行时间是 BanditPAM 的10倍以上。<details>
<summary>Abstract</summary>
Clustering is a fundamental task in data science with wide-ranging applications. In $k$-medoids clustering, cluster centers must be actual datapoints and arbitrary distance metrics may be used; these features allow for greater interpretability of the cluster centers and the clustering of exotic objects in $k$-medoids clustering, respectively. $k$-medoids clustering has recently grown in popularity due to the discovery of more efficient $k$-medoids algorithms. In particular, recent research has proposed BanditPAM, a randomized $k$-medoids algorithm with state-of-the-art complexity and clustering accuracy. In this paper, we present BanditPAM++, which accelerates BanditPAM via two algorithmic improvements, and is $O(k)$ faster than BanditPAM in complexity and substantially faster than BanditPAM in wall-clock runtime. First, we demonstrate that BanditPAM has a special structure that allows the reuse of clustering information $\textit{within}$ each iteration. Second, we demonstrate that BanditPAM has additional structure that permits the reuse of information $\textit{across}$ different iterations. These observations inspire our proposed algorithm, BanditPAM++, which returns the same clustering solutions as BanditPAM but often several times faster. For example, on the CIFAR10 dataset, BanditPAM++ returns the same results as BanditPAM but runs over 10$\times$ faster. Finally, we provide a high-performance C++ implementation of BanditPAM++, callable from Python and R, that may be of interest to practitioners at https://github.com/motiwari/BanditPAM. Auxiliary code to reproduce all of our experiments via a one-line script is available at https://github.com/ThrunGroup/BanditPAM_plusplus_experiments.
</details>
<details>
<summary>摘要</summary>
“集群是数据科学中的基本任务，具有广泛的应用。在$k$-medians集群中，集群中心必须是实际数据点，并且可以使用任意距离度量；这些特点使得$k$-medians集群更有可读性，并且可以更好地集 clusters 的特殊对象。随着更高效的$k$-medians算法的发现，$k$-medians集群在最近几年内 Popularity 增长。本文提出了 BanditPAM++，它是一种随机化的 $k$-medians算法，通过两个算法优化，与 BanditPAM 相比， complexity 为 $O(k)$ 和增加了很多的 wall-clock 时间。首先，我们证明 BanditPAM 具有特殊的结构，可以在每个迭代中重用 clustering 信息。其次，我们证明 BanditPAM 具有额外的结构，允许在不同的迭代中重用信息。这些观察点激发我们提出 BanditPAM++，它返回与 BanditPAM 相同的 clustering 解决方案，但通常很多 slower。例如，在 CIFAR10 数据集上，BanditPAM++ 与 BanditPAM 返回相同的结果，但运行速度比 BanditPAM 快了大约 10 倍。最后，我们提供了高性能的 C++ 实现，可以在 Python 和 R 中调用，并可能对实践者有利。详细的实验代码可以在 https://github.com/motiwari/BanditPAM 和 https://github.com/ThrunGroup/BanditPAM_plusplus_experiments 上找到。”
</details></li>
</ul>
<hr>
<h2 id="Automating-the-Correctness-Assessment-of-AI-generated-Code-for-Security-Contexts"><a href="#Automating-the-Correctness-Assessment-of-AI-generated-Code-for-Security-Contexts" class="headerlink" title="Automating the Correctness Assessment of AI-generated Code for Security Contexts"></a>Automating the Correctness Assessment of AI-generated Code for Security Contexts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18834">http://arxiv.org/abs/2310.18834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Domenico Cotroneo, Alessio Foggia, Cristina Improta, Pietro Liguori, Roberto Natella</li>
<li>for: This paper aims to evaluate the correctness of AI-generated code for security purposes using a fully automated method.</li>
<li>methods: The proposed method, named ACCA, uses symbolic execution to assess whether the AI-generated code behaves as a reference implementation.</li>
<li>results: The proposed method outperforms baseline solutions and shows a strong correlation with human evaluation, with an average time of ~0.17s per code snippet, much faster than manual inspection.<details>
<summary>Abstract</summary>
In this paper, we propose a fully automated method, named ACCA, to evaluate the correctness of AI-generated code for security purposes. The method uses symbolic execution to assess whether the AI-generated code behaves as a reference implementation. We use ACCA to assess four state-of-the-art models trained to generate security-oriented assembly code and compare the results of the evaluation with different baseline solutions, including output similarity metrics, widely used in the field, and the well-known ChatGPT, the AI-powered language model developed by OpenAI. Our experiments show that our method outperforms the baseline solutions and assesses the correctness of the AI-generated code similar to the human-based evaluation, which is considered the ground truth for the assessment in the field. Moreover, ACCA has a very strong correlation with human evaluation (Pearson's correlation coefficient r=0.84 on average). Finally, since it is a fully automated solution that does not require any human intervention, the proposed method performs the assessment of every code snippet in ~0.17s on average, which is definitely lower than the average time required by human analysts to manually inspect the code, based on our experience.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种完全自动化的方法，名为ACCA，用于评估人工智能生成的代码的正确性，以便用于安全目的。该方法利用symbolic执行来评估AI生成的代码是否与参考实现一致。我们使用ACCA评估了四种现状最佳的模型，用于生成安全听力的assembly代码，并与不同的基准解决方案进行比较，包括输出相似度指标，在领域内广泛使用的，以及由OpenAI开发的知名的ChatGPT人工智能语言模型。我们的实验表明，我们的方法超越了基准解决方案，并与人类评估类似，被视为领域中的地面真实值。此外，ACCA与人类评估之间存在强相关性（平均Pearson相关系数r=0.84）。最后，由于它是完全自动化的，不需要任何人类参与，我们的方法可以快速地评估每个代码副本，平均需时约0.17秒，明显低于由人工分析员手动检查代码所需的时间，根据我们的经验。
</details></li>
</ul>
<hr>
<h2 id="Responsible-AI-RAI-Games-and-Ensembles"><a href="#Responsible-AI-RAI-Games-and-Ensembles" class="headerlink" title="Responsible AI (RAI) Games and Ensembles"></a>Responsible AI (RAI) Games and Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18832">http://arxiv.org/abs/2310.18832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yashgupta-7/rai-games">https://github.com/yashgupta-7/rai-games</a></li>
<li>paper_authors: Yash Gupta, Runtian Zhai, Arun Suggala, Pradeep Ravikumar</li>
<li>for: 这个研究旨在解决人工智能（AI）在社会中的影响，包括公平性、可靠性和安全性等问题。</li>
<li>methods: 这个研究使用了一种普遍的框架，称为责任AI（RAI）游戏，来研究这些问题。两种算法来解决这些游戏：一种是基于在线学习和游戏理论的游戏玩家算法，另一种是基于经典统计文献中的提升和回归算法。</li>
<li>results: 研究证明了这些方法在解决一些RAI问题，特别是在子人口变化时的性能竞争力。<details>
<summary>Abstract</summary>
Several recent works have studied the societal effects of AI; these include issues such as fairness, robustness, and safety. In many of these objectives, a learner seeks to minimize its worst-case loss over a set of predefined distributions (known as uncertainty sets), with usual examples being perturbed versions of the empirical distribution. In other words, aforementioned problems can be written as min-max problems over these uncertainty sets. In this work, we provide a general framework for studying these problems, which we refer to as Responsible AI (RAI) games. We provide two classes of algorithms for solving these games: (a) game-play based algorithms, and (b) greedy stagewise estimation algorithms. The former class is motivated by online learning and game theory, whereas the latter class is motivated by the classical statistical literature on boosting, and regression. We empirically demonstrate the applicability and competitive performance of our techniques for solving several RAI problems, particularly around subpopulation shift.
</details>
<details>
<summary>摘要</summary>
Recent research has focused on the social impact of AI, including issues such as fairness, robustness, and safety. In many cases, the goal is to minimize the worst-case loss over a set of predefined distribution (known as uncertainty sets), such as perturbed versions of the empirical distribution. These problems can be formulated as min-max problems over the uncertainty sets. In this study, we propose a general framework for addressing these issues, which we refer to as Responsible AI (RAI) games. We present two classes of algorithms for solving these games: (a) game-play based algorithms, and (b) greedy stagewise estimation algorithms. The former class is inspired by online learning and game theory, while the latter class is based on the classical statistical literature on boosting and regression. We empirically demonstrate the applicability and competitive performance of our techniques for solving several RAI problems, particularly in the context of subpopulation shift.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="All-Things-Considered-Detecting-Partisan-Events-from-News-Media-with-Cross-Article-Comparison"><a href="#All-Things-Considered-Detecting-Partisan-Events-from-News-Media-with-Cross-Article-Comparison" class="headerlink" title="All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison"></a>All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18827">http://arxiv.org/abs/2310.18827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujian Liu, Xinliang Frederick Zhang, Kaijian Zou, Ruihong Huang, Nick Beauchamp, Lu Wang</li>
<li>for: 本研究旨在探讨新闻媒体如何影响公众意见，以及媒体如何通过透明或不透明的方式 shape opinion。</li>
<li>methods: 本研究使用了一种基于潜在变量的框架，通过比较相同故事的多篇文章来预测文章的政治倾向。</li>
<li>results: 实验表明，媒体可以通过不公平地选择报道事件来形成公众意见，而且这种偏见存在于主流媒体中，即使媒体具有强的 объекivity 和非政治化准则。<details>
<summary>Abstract</summary>
Public opinion is shaped by the information news media provide, and that information in turn may be shaped by the ideological preferences of media outlets. But while much attention has been devoted to media bias via overt ideological language or topic selection, a more unobtrusive way in which the media shape opinion is via the strategic inclusion or omission of partisan events that may support one side or the other. We develop a latent variable-based framework to predict the ideology of news articles by comparing multiple articles on the same story and identifying partisan events whose inclusion or omission reveals ideology. Our experiments first validate the existence of partisan event selection, and then show that article alignment and cross-document comparison detect partisan events and article ideology better than competitive baselines. Our results reveal the high-level form of media bias, which is present even among mainstream media with strong norms of objectivity and nonpartisanship. Our codebase and dataset are available at https://github.com/launchnlp/ATC.
</details>
<details>
<summary>摘要</summary>
社会舆论是由新闻媒体提供的信息所形成的，而这些信息可能受媒体机构的意识形态偏好所影响。然而，许多注意力集中在媒体偏见的明显表达或话题选择上，而媒体 shape 意见的更加不显式的方式却很少得到关注。我们提出了一种基于隐藏变量的框架，用于预测新闻文章的意识性。我们通过比较同一个故事的多篇文章来确定包含或排除某些政治事件的媒体偏见。我们的实验首先证明了事件选择的存在，然后展示了文章对齐和跨文档比较的能力更好地探测文章意识性和媒体偏见。我们的结果表明，媒体偏见存在于主流媒体中，即使媒体有强大的objectivity和非政治化的准则。我们的代码库和数据集可以在 <https://github.com/launchnlp/ATC> 上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Fuzzy-Time-Series-Based-Model-Using-Particle-Swarm-Optimization-and-Weighted-Rules"><a href="#A-Fuzzy-Time-Series-Based-Model-Using-Particle-Swarm-Optimization-and-Weighted-Rules" class="headerlink" title="A Fuzzy Time Series-Based Model Using Particle Swarm Optimization and Weighted Rules"></a>A Fuzzy Time Series-Based Model Using Particle Swarm Optimization and Weighted Rules</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18825">http://arxiv.org/abs/2310.18825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Ortiz-Arroyo</li>
<li>for: 提高高阶不确定时间序列模型的精度和可靠性。</li>
<li>methods:  combining particle swarm optimization (PSO) and weighted summation to address the limitations of high-order fuzzy time series models.</li>
<li>results: 比前方法更高精度地模型时间序列。<details>
<summary>Abstract</summary>
During the last decades, a myriad of fuzzy time series models have been proposed in scientific literature. Among the most accurate models found in fuzzy time series, the high-order ones are the most accurate. The research described in this paper tackles three potential limitations associated with the application of high-order fuzzy time series models. To begin with, the adequacy of forecast rules lacks consistency. Secondly, as the model's order increases, data utilization diminishes. Thirdly, the uniformity of forecast rules proves to be highly contingent on the chosen interval partitions. To address these likely drawbacks, we introduce a novel model based on fuzzy time series that amalgamates the principles of particle swarm optimization (PSO) and weighted summation. Our results show that our approach models accurately the time series in comparison with previous methods.
</details>
<details>
<summary>摘要</summary>
在过去几十年中，数字时间序列模型的研究得到了广泛的发展和应用。高阶的含糊时间序列模型在科学文献中被认为是最为准确的。本研究考虑了高阶含糊时间序列模型的三个可能的限制：首先，预测规则的适用稳定性不充分；第二，随着模型的阶数增加，数据利用率逐渐减少；第三，预测规则的均匀性高度取决于选择的时间分割。为解决这些可能的缺点，我们提出了一种基于含糊时间序列的新模型，具有融合了粒子群组合优化（PSO）和Weighted Summary的原则。我们的结果表明，我们的方法可以准确地模型时间序列，与前期方法相比。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Semi-Supervised-Federated-Learning-How-to-co-train-fully-labeled-and-fully-unlabeled-client-imaging-data"><a href="#Rethinking-Semi-Supervised-Federated-Learning-How-to-co-train-fully-labeled-and-fully-unlabeled-client-imaging-data" class="headerlink" title="Rethinking Semi-Supervised Federated Learning: How to co-train fully-labeled and fully-unlabeled client imaging data"></a>Rethinking Semi-Supervised Federated Learning: How to co-train fully-labeled and fully-unlabeled client imaging data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18815">http://arxiv.org/abs/2310.18815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pramit Saha, Divyanshu Mishra, J. Alison Noble</li>
<li>for: 本研究旨在解决 semi-supervised federated learning (SSFL) 中 client 之间具有半标注数据的问题，特别是在医疗设置下，合作伙伴（通常是医院）可能拥有图像，但没有注释。</li>
<li>methods: 我们提出了一种新的学习方案，即 Isolated Federated Learning (IsoFed)，以避免简单的平均方法。我们的训练方法包括两个部分：（a）孤立的客户端模型归一化，以及（b）所有客户端的本地自我超vised pre-training。</li>
<li>results: 我们在四种不同的医疗影像数据集上进行了实验，包括 MedMNIST 的医疗影像 benchmark。我们还在不同的实验设置下变换了比例的标注客户端和多样性，以示出我们的方法在不同的情况下的效果。<details>
<summary>Abstract</summary>
The most challenging, yet practical, setting of semi-supervised federated learning (SSFL) is where a few clients have fully labeled data whereas the other clients have fully unlabeled data. This is particularly common in healthcare settings where collaborating partners (typically hospitals) may have images but not annotations. The bottleneck in this setting is the joint training of labeled and unlabeled clients as the objective function for each client varies based on the availability of labels. This paper investigates an alternative way for effective training with labeled and unlabeled clients in a federated setting. We propose a novel learning scheme specifically designed for SSFL which we call Isolated Federated Learning (IsoFed) that circumvents the problem by avoiding simple averaging of supervised and semi-supervised models together. In particular, our training approach consists of two parts - (a) isolated aggregation of labeled and unlabeled client models, and (b) local self-supervised pretraining of isolated global models in all clients. We evaluate our model performance on medical image datasets of four different modalities publicly available within the biomedical image classification benchmark MedMNIST. We further vary the proportion of labeled clients and the degree of heterogeneity to demonstrate the effectiveness of the proposed method under varied experimental settings.
</details>
<details>
<summary>摘要</summary>
最大挑战的、但实际可行的 semi-supervised federated learning（SSFL）设置是，一些客户端有完全标注数据，而另一些客户端有完全无标注数据。这种情况 particullary 在医疗设置中常见，合作伙伴（通常是医院）可能拥有图像，但并没有标注。瓶颈在这种设置下是 joint 训练标注和无标注客户端的目标函数，因为每个客户端的目标函数因标注的可用性而变化。这篇论文investigates an alternative way for effective training with labeled and unlabeled clients in a federated setting. We propose a novel learning scheme specifically designed for SSFL, which we call Isolated Federated Learning (IsoFed), to circumvent this problem by avoiding simple averaging of supervised and semi-supervised models together. In particular, our training approach consists of two parts: (a) isolated aggregation of labeled and unlabeled client models, and (b) local self-supervised pretraining of isolated global models in all clients. We evaluate our model performance on medical image datasets of four different modalities publicly available within the biomedical image classification benchmark MedMNIST. We further vary the proportion of labeled clients and the degree of heterogeneity to demonstrate the effectiveness of the proposed method under varied experimental settings.
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Framework-for-Interpretable-and-Probabilistic-Model-Based-Safe-Reinforcement-Learning"><a href="#Hierarchical-Framework-for-Interpretable-and-Probabilistic-Model-Based-Safe-Reinforcement-Learning" class="headerlink" title="Hierarchical Framework for Interpretable and Probabilistic Model-Based Safe Reinforcement Learning"></a>Hierarchical Framework for Interpretable and Probabilistic Model-Based Safe Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18811">http://arxiv.org/abs/2310.18811</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ammar N. Abbas, Georgios C. Chasparis, John D. Kelleher</li>
<li>for: 这篇论文的目的是提出一种基于深度强化学习的安全关键系统解决方案，以便在安全关键系统中使用深度强化学习，并且提供解释性的执行。</li>
<li>methods: 这篇论文使用了深度强化学习，并与传统决策策略相合作，以提高安全关键系统的可靠性和可控性。它还使用了潜在模型和强化学习的融合，以提高解释性和可靠性。</li>
<li>results: 这篇论文的实验结果显示，BC-SRLA在维护领域中的维护维护过程中表现出色，比传统方法和其他基于RL的基eline更好。<details>
<summary>Abstract</summary>
The difficulty of identifying the physical model of complex systems has led to exploring methods that do not rely on such complex modeling of the systems. Deep reinforcement learning has been the pioneer for solving this problem without the need for relying on the physical model of complex systems by just interacting with it. However, it uses a black-box learning approach that makes it difficult to be applied within real-world and safety-critical systems without providing explanations of the actions derived by the model. Furthermore, an open research question in deep reinforcement learning is how to focus the policy learning of critical decisions within a sparse domain. This paper proposes a novel approach for the use of deep reinforcement learning in safety-critical systems. It combines the advantages of probabilistic modeling and reinforcement learning with the added benefits of interpretability and works in collaboration and synchronization with conventional decision-making strategies. The BC-SRLA is activated in specific situations which are identified autonomously through the fused information of probabilistic model and reinforcement learning, such as abnormal conditions or when the system is near-to-failure. Further, it is initialized with a baseline policy using policy cloning to allow minimum interactions with the environment to address the challenges associated with using RL in safety-critical industries. The effectiveness of the BC-SRLA is demonstrated through a case study in maintenance applied to turbofan engines, where it shows superior performance to the prior art and other baselines.
</details>
<details>
<summary>摘要</summary>
因为识别复杂系统的物理模型具有挑战，因此探索不需要基于这些复杂模型的方法。深度强化学习曾经是解决这个问题的先驱，它不需要基于系统的物理模型来解决问题，只需通过与系统交互来解决问题。然而，它使用黑盒学习方法，这使得其在实际世界和安全关键系统中应用非常困难，而且无法提供行为的解释。此外，深度强化学习中的一个开放研究问题是如何将策略学习集中在稀疏领域中。本文提出了一种基于深度强化学习的新方法，用于安全关键系统中。它结合了概率模型和强化学习的优点，同时增加了可解性。此外，它与传统决策策略协作和同步，在特定情况下自动识别并且通过混合信息来识别，例如异常情况或系统垂直危机。此外，它使用策略做副本来初始化，以最小化与环境的交互，解决了使用强化学习在安全关键行业中的挑战。本文通过一个维护案例研究展示了BC-SRLA的有效性，其在维护领域的表现较优于先前艺术和其他基线。
</details></li>
</ul>
<hr>
<h2 id="OC-NMN-Object-centric-Compositional-Neural-Module-Network-for-Generative-Visual-Analogical-Reasoning"><a href="#OC-NMN-Object-centric-Compositional-Neural-Module-Network-for-Generative-Visual-Analogical-Reasoning" class="headerlink" title="OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning"></a>OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18807">http://arxiv.org/abs/2310.18807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rim Assouel, Pau Rodriguez, Perouz Taslakian, David Vazquez, Yoshua Bengio</li>
<li>for: This paper aims to improve the ability of machine learning systems to imagine and compose learned concepts in novel ways, specifically in the context of visual reasoning.</li>
<li>methods: The paper proposes a modular data augmentation framework called Object-centric Compositional Neural Module Network (OC-NMN), which decomposes visual generative reasoning tasks into a series of primitives applied to objects.</li>
<li>results: The paper shows that the proposed modular architectural choices can be used to generate new training tasks that lead to better out-of-distribution generalization, and compares the model to existing and new baselines in a proposed visual reasoning benchmark.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是提高机器学习系统的想象和组合学习能力，特别是在视觉理解中。</li>
<li>methods: 该论文提出了一种模块化数据增强框架，称为Object-centric Compositional Neural Module Network (OC-NMN)，它将视觉生成逻辑任务 decomposes 成一系列对象上的基本操作。</li>
<li>results: 论文显示，提出的模块性建筑设计可以生成新的训练任务，导致更好的 OUT-OF-distribution 通用化。并与现有和新的基准值进行比较，在提posed的视觉理解 bencmark 中。<details>
<summary>Abstract</summary>
A key aspect of human intelligence is the ability to imagine -- composing learned concepts in novel ways -- to make sense of new scenarios. Such capacity is not yet attained for machine learning systems. In this work, in the context of visual reasoning, we show how modularity can be leveraged to derive a compositional data augmentation framework inspired by imagination. Our method, denoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes visual generative reasoning tasks into a series of primitives applied to objects without using a domain-specific language. We show that our modular architectural choices can be used to generate new training tasks that lead to better out-of-distribution generalization. We compare our model to existing and new baselines in proposed visual reasoning benchmark that consists of applying arithmetic operations to MNIST digits.
</details>
<details>
<summary>摘要</summary>
人类智能的一个重要方面是具备想象能力---把已学习的概念组合在新的方式下来---以便理解新的场景。这种能力目前尚未被机器学习系统具备。在这项工作中，我们在视觉逻辑上利用了模块性，以 derive一种基于想象的数据增强框架。我们的方法，称为物体中心的compositional Neural Module Network（OC-NMN），将视觉生成逻辑任务分解成一系列对象上的基本Primitive。我们显示了我们的建筑方式可以生成新的训练任务，导致更好的对外值 generale。我们与现有和新的基准值进行比较，并在我们提出的视觉理解benchmark中进行测试，该benchmark包括对MNIST数字应用数学运算。
</details></li>
</ul>
<hr>
<h2 id="Open-Visual-Knowledge-Extraction-via-Relation-Oriented-Multimodality-Model-Prompting"><a href="#Open-Visual-Knowledge-Extraction-via-Relation-Oriented-Multimodality-Model-Prompting" class="headerlink" title="Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting"></a>Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18804">http://arxiv.org/abs/2310.18804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hejie Cui, Xinyu Fang, Zihan Zhang, Ran Xu, Xuan Kan, Xin Liu, Yue Yu, Manling Li, Yangqiu Song, Carl Yang</li>
<li>for: 这篇论文旨在探讨开放视觉知识EXTRACTION的新方法，以提高机器理解世界的能力。</li>
<li>methods: 该方法使用开放关系区域检测器和大型多模态模型，从图像中提取无格式的视觉知识。</li>
<li>results: 实验表明，OpenVik可以生成具有准确性和独特性的开放视觉知识，并在多种视觉理解应用中提供了显著的改进。<details>
<summary>Abstract</summary>
Images contain rich relational knowledge that can help machines understand the world. Existing methods on visual knowledge extraction often rely on the pre-defined format (e.g., sub-verb-obj tuples) or vocabulary (e.g., relation types), restricting the expressiveness of the extracted knowledge. In this work, we take a first exploration to a new paradigm of open visual knowledge extraction. To achieve this, we present OpenVik which consists of an open relational region detector to detect regions potentially containing relational knowledge and a visual knowledge generator that generates format-free knowledge by prompting the large multimodality model with the detected region of interest. We also explore two data enhancement techniques for diversifying the generated format-free visual knowledge. Extensive knowledge quality evaluations highlight the correctness and uniqueness of the extracted open visual knowledge by OpenVik. Moreover, integrating our extracted knowledge across various visual reasoning applications shows consistent improvements, indicating the real-world applicability of OpenVik.
</details>
<details>
<summary>摘要</summary>
图像含有丰富的关系知识，可以帮助机器理解世界。现有的视觉知识EXTRACTION方法 oft rely on先defined format (e.g., sub-verb-obj tuples) or vocabulary (e.g., relation types), restricting the expressiveness of the extracted knowledge。在这项工作中，我们开始了一种新的开放视觉知识EXTRACTION paradigm。为达到这个目标，我们提出了 OpenVik，它包括一个开放关系区域检测器，用于检测可能包含关系知识的区域，以及一个可视知识生成器，通过在检测到区域特点的提示下，生成无格式的知识。我们还探讨了两种数据增强技术，用于让生成的无格式视觉知识更加多样化。广泛的知识质量评估表明OpenVik提取的开放视觉知识具有正确性和独特性。此外，我们在不同的视觉理解应用中集成我们提取的知识，显示了一致的改进， indicating the real-world applicability of OpenVik。
</details></li>
</ul>
<hr>
<h2 id="Sequence-Level-Certainty-Reduces-Hallucination-In-Knowledge-Grounded-Dialogue-Generation"><a href="#Sequence-Level-Certainty-Reduces-Hallucination-In-Knowledge-Grounded-Dialogue-Generation" class="headerlink" title="Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation"></a>Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18794">http://arxiv.org/abs/2310.18794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixin Wan, Fanyou Wu, Weijie Xu, Srinivasan H. Sengamedu</li>
<li>for: 本研究的目的是探讨模型幻化现象在自然语言生成（NLG）中的作用，并提出基于确定性的回答排名方法来减少模型幻化。</li>
<li>methods: 本研究使用了序列级确定性的两个方面：概率确定性和含义确定性，并通过对知识推理对话生成（KGDG）任务的实验发现，两者均与模型回答中幻化水平有显著相关性。</li>
<li>results: 研究发现，在模型回答中含义确定性水平较高时，幻化水平较低，而概率确定性水平较高时，幻化水平较高。此外，研究还提供了理论分析和证明，证明含义确定性可以作为概率确定性的一种代替方案，并在黑obox场景中具有可行性。基于这些发现，本研究提出了确定性基本回答排名（CRR）方法，以减少NLG中模型幻化现象。CRR分为两种类型：概率CRR（P-CRR）和含义CRR（S-CRR）。P-CRR使用模型回答整个序列的平均Log probability来排名样本。S-CRR根据模型回答的含义相似度来排名一些模型回答的候选者，并使用含义相似度来估计模型回答的确定性水平。通过对3个KGDG数据集、3种排序方法和4个模型进行了广泛的实验， validate了我们提出的2种CRR方法的效果。<details>
<summary>Abstract</summary>
Model hallucination has been a crucial interest of research in Natural Language Generation (NLG). In this work, we propose sequence-level certainty as a common theme over hallucination in NLG, and explore the correlation between sequence-level certainty and the level of hallucination in model responses. We categorize sequence-level certainty into two aspects: probabilistic certainty and semantic certainty, and reveal through experiments on Knowledge-Grounded Dialogue Generation (KGDG) task that both a higher level of probabilistic certainty and a higher level of semantic certainty in model responses are significantly correlated with a lower level of hallucination. What's more, we provide theoretical proof and analysis to show that semantic certainty is a good estimator of probabilistic certainty, and therefore has the potential as an alternative to probability-based certainty estimation in black-box scenarios. Based on the observation on the relationship between certainty and hallucination, we further propose Certainty-based Response Ranking (CRR), a decoding-time method for mitigating hallucination in NLG. Based on our categorization of sequence-level certainty, we propose 2 types of CRR approach: Probabilistic CRR (P-CRR) and Semantic CRR (S-CRR). P-CRR ranks individually sampled model responses using their arithmetic mean log-probability of the entire sequence. S-CRR approaches certainty estimation from meaning-space, and ranks a number of model response candidates based on their semantic certainty level, which is estimated by the entailment-based Agreement Score (AS). Through extensive experiments across 3 KGDG datasets, 3 decoding methods, and on 4 different models, we validate the effectiveness of our 2 proposed CRR methods to reduce model hallucination.
</details>
<details>
<summary>摘要</summary>
modelo de generación de lenguaje natural (NLG) ha sido un tema crucial de investigación en la comunidad científica. En este trabajo, propusimos la certidumbre de secuencia como un tema común en la generación de lenguaje natural, y exploramos la relación entre la certidumbre de secuencia y el nivel de halucinación en las respuestas del modelo. Distinguiendo la certidumbre de secuencia en dos aspectos: la certidumbre probabilística y la certidumbre semántica, revelamos a través de experimentos en la tarea de generación de diálogo basado en conocimientos (KGDG) que ambos tienen un nivel significativamente correlacionado con un nivel bajo de halucinación. Además, proveímos pruebas teóricas y análisis para demostrar que la certidumbre semántica es un buen estimador de la certidumbre probabilística, y por lo tanto tiene el potencial de servir como una alternativa a la estimación de certidumbre basada en probabilidades en escenarios de "black-box". Basándonos en la observación de la relación entre la certidumbre y la halucinación, propusimos el Metodo de Ranking de Respuestas basado en la Certidumbre (CRR), un método de decodificación en tiempo real para mitigar la halucinación en NLG. Basándonos en nuestra categorización de la certidumbre de secuencia, propusimos dos enfoques de CRR: el enfoque de Certidumbre Probabilística (P-CRR) y el enfoque de Certidumbre Semántica (S-CRR). El enfoque P-CRR clasifica las respuestas individualmente seleccionadas del modelo utilizando su probabilidad aritmética promedio de toda la secuencia. El enfoque S-CRR se basa en la certidumbre semántica, y clasifica un número de candidatos de respuestas del modelo según su nivel de certidumbre semántica, que se estima utilizando el índice de Entendimiento (AS). A través de extensivos experimentos en tres conjuntos de datos de KGDG, tres métodos de decodificación y cuatro modelos diferentes, validamos la eficacia de nuestros dos métodos de CRR para reducir la halucinación del modelo.
</details></li>
</ul>
<hr>
<h2 id="“Do-it-my-way-”-Impact-of-Customizations-on-Trust-perceptions-in-Human-Robot-Collaboration"><a href="#“Do-it-my-way-”-Impact-of-Customizations-on-Trust-perceptions-in-Human-Robot-Collaboration" class="headerlink" title="“Do it my way!”: Impact of Customizations on Trust perceptions in Human-Robot Collaboration"></a>“Do it my way!”: Impact of Customizations on Trust perceptions in Human-Robot Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18791">http://arxiv.org/abs/2310.18791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parv Kapoor, Simon Chu, Angela Chen</li>
<li>for: 这个研究旨在探讨个性化助手机器人的影响，以及个性化程度对人类使用者的体验和信任感的影响。</li>
<li>methods: 研究采用了在人类使用者身上进行的内置研究（N&#x3D;17），并对不同水平的自定义可能性进行了比较。</li>
<li>results: 研究发现，增加个性化程度会导致更高的信任和舒适感。这些发现可以帮助设计师设计更信任worthy和个性化的助手机器人。<details>
<summary>Abstract</summary>
Trust has been shown to be a key factor in effective human-robot collaboration. In the context of assistive robotics, the effect of trust factors on human experience is further pronounced. Personalization of assistive robots is an orthogonal factor positively correlated with robot adoption and user perceptions. In this work, we investigate the relationship between these factors through a within-subjects study (N=17). We provide different levels of customization possibilities over baseline autonomous robot behavior and investigate its impact on trust. Our findings indicate that increased levels of customization was associated with higher trust and comfort perceptions. The assistive robot design process can benefit significantly from our insights for designing trustworthy and customized robots.
</details>
<details>
<summary>摘要</summary>
信任被证明为人机合作中关键因素。在帮助型机器人领域，信任因素对人类体验的影响更加明显。个性化机器人设计是一个 orthogonal 因素，与机器人采用和用户对机器人的评价显著相关。本研究通过在subjects（N=17）中进行内部研究，研究自适应机器人行为的不同水平的个性化可能性对信任的影响。我们发现，逐渐提高个性化水平与信任、舒适感的增加有显著相关性。这些发现可以帮助设计信任worthy和个性化的机器人设计过程。
</details></li>
</ul>
<hr>
<h2 id="Laughing-Hyena-Distillery-Extracting-Compact-Recurrences-From-Convolutions"><a href="#Laughing-Hyena-Distillery-Extracting-Compact-Recurrences-From-Convolutions" class="headerlink" title="Laughing Hyena Distillery: Extracting Compact Recurrences From Convolutions"></a>Laughing Hyena Distillery: Extracting Compact Recurrences From Convolutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18780">http://arxiv.org/abs/2310.18780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Massaroli, Michael Poli, Daniel Y. Fu, Hermann Kumbong, Rom N. Parnichkun, Aman Timalsina, David W. Romero, Quinn McIntyre, Beidi Chen, Atri Rudra, Ce Zhang, Christopher Re, Stefano Ermon, Yoshua Bengio</li>
<li>for: 降低memory footprint和提高throughput during generation</li>
<li>methods: 使用 rational interpolation和model-order reduction techniques，以及Weight-tying filters across channels into heads</li>
<li>results: 实现了10倍于Transformers的throughput和1.5倍于Hyena的throughput，而且无损质量 послеdistillation<details>
<summary>Abstract</summary>
Recent advances in attention-free sequence models rely on convolutions as alternatives to the attention operator at the core of Transformers. In particular, long convolution sequence models have achieved state-of-the-art performance in many domains, but incur a significant cost during auto-regressive inference workloads -- naively requiring a full pass (or caching of activations) over the input sequence for each generated token -- similarly to attention-based models. In this paper, we seek to enable $\mathcal O(1)$ compute and memory cost per token in any pre-trained long convolution architecture to reduce memory footprint and increase throughput during generation. Concretely, our methods consist in extracting low-dimensional linear state-space models from each convolution layer, building upon rational interpolation and model-order reduction techniques. We further introduce architectural improvements to convolution-based layers such as Hyena: by weight-tying the filters across channels into heads, we achieve higher pre-training quality and reduce the number of filters to be distilled. The resulting model achieves 10x higher throughput than Transformers and 1.5x higher than Hyena at 1.3B parameters, without any loss in quality after distillation.
</details>
<details>
<summary>摘要</summary>
最近的进展在无注意力序列模型中使用核函数作为Transformer核心中的注意力运算符的替代方案。具体而言，长核函数序列模型在多个领域中 achieved state-of-the-art performance，但是在自动生成推干负载中具有重要的成本 - 需要遍历输入序列的全部通过或缓存活动的结果。在这篇论文中，我们寻求实现$\mathcal O(1)$的 compute和memory成本每个 токен，以降低快取面积和增加生成速度。具体来说，我们的方法是从每个核函数层提取低维度的线性状态空间模型，建立在理性插值和模型阶层技术之上。我们还引入了对于核函数层的建筑改进，例如Hyena：将核函数跨通道联结成头部，以提高预训品质和降低缩减策略中的缩减策略。实验结果显示，我们的模型可以与Transformer和Hyena相比，在1.3B个参数下实现10倍的生成速度，不会对品质造成损害。
</details></li>
</ul>
<hr>
<h2 id="Improving-Compositional-Generalization-Using-Iterated-Learning-and-Simplicial-Embeddings"><a href="#Improving-Compositional-Generalization-Using-Iterated-Learning-and-Simplicial-Embeddings" class="headerlink" title="Improving Compositional Generalization Using Iterated Learning and Simplicial Embeddings"></a>Improving Compositional Generalization Using Iterated Learning and Simplicial Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18777">http://arxiv.org/abs/2310.18777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Ren, Samuel Lavoie, Mikhail Galkin, Danica J. Sutherland, Aaron Courville</li>
<li>for: The paper aims to improve the compositional generalization of deep neural networks, which is the ability to generalize to unseen combinations of latent factors.</li>
<li>methods: The paper proposes using iterated learning on models with simplicial embeddings to improve compositional generalization. This approach is motivated by an analysis of compositionality based on Kolmogorov complexity.</li>
<li>results: The paper demonstrates improvements in compositional generalization over other approaches, using both vision tasks with well-understood latent factors and real molecular graph prediction tasks where the latent structure is unknown.<details>
<summary>Abstract</summary>
Compositional generalization, the ability of an agent to generalize to unseen combinations of latent factors, is easy for humans but hard for deep neural networks. A line of research in cognitive science has hypothesized a process, ``iterated learning,'' to help explain how human language developed this ability; the theory rests on simultaneous pressures towards compressibility (when an ignorant agent learns from an informed one) and expressivity (when it uses the representation for downstream tasks). Inspired by this process, we propose to improve the compositional generalization of deep networks by using iterated learning on models with simplicial embeddings, which can approximately discretize representations. This approach is further motivated by an analysis of compositionality based on Kolmogorov complexity. We show that this combination of changes improves compositional generalization over other approaches, demonstrating these improvements both on vision tasks with well-understood latent factors and on real molecular graph prediction tasks where the latent structure is unknown.
</details>
<details>
<summary>摘要</summary>
人类的 Compositional generalization，即对未经过视图的组合因素进行泛化，容易 для人类，但困难 для深度神经网络。认知科学中的一条研究提出了一个过程，即“迭代学习”，以解释人类语言的发展能力;该理论基于同时应对压缩性（ikor ignorant agent 从 informed one 学习）和表达性（ikor it 使用表示进行下游任务）的同时压力。 inspirited by this process, we propose to improve the compositional generalization of deep networks by using iterated learning on models with simplicial embeddings, which can approximately discretize representations. This approach is further motivated by an analysis of compositionality based on Kolmogorov complexity. We show that this combination of changes improves compositional generalization over other approaches, demonstrating these improvements both on vision tasks with well-understood latent factors and on real molecular graph prediction tasks where the latent structure is unknown.Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau. The translation is written in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Linear-Mode-Connectivity-in-Sparse-Neural-Networks"><a href="#Linear-Mode-Connectivity-in-Sparse-Neural-Networks" class="headerlink" title="Linear Mode Connectivity in Sparse Neural Networks"></a>Linear Mode Connectivity in Sparse Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18769">http://arxiv.org/abs/2310.18769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke McDermott, Daniel Cummings</li>
<li>for: 这个论文研究了使用生成的数据进行神经网络减少，并研究了这些减少后的神经网络在真实数据上的训练特性。</li>
<li>methods: 该论文使用了迭代幅度减少（IMP）法，并使用了一种称为“液体减少”的方法来生成数据。</li>
<li>results: 研究发现，使用生成的数据和IMP法可以创建一类稀疏神经网络，这些神经网络在真实数据上训练时更加稳定，并且可以与传统IMP法相比，使用更少的训练点（最多150倍）达到相同的性能。<details>
<summary>Abstract</summary>
With the rise in interest of sparse neural networks, we study how neural network pruning with synthetic data leads to sparse networks with unique training properties. We find that distilled data, a synthetic summarization of the real data, paired with Iterative Magnitude Pruning (IMP) unveils a new class of sparse networks that are more stable to SGD noise on the real data, than either the dense model, or subnetworks found with real data in IMP. That is, synthetically chosen subnetworks often train to the same minima, or exhibit linear mode connectivity. We study this through linear interpolation, loss landscape visualizations, and measuring the diagonal of the hessian. While dataset distillation as a field is still young, we find that these properties lead to synthetic subnetworks matching the performance of traditional IMP with up to 150x less training points in settings where distilled data applies.
</details>
<details>
<summary>摘要</summary>
“因为神经网络束缚的兴趣增长，我们研究了使用 sintetic data 进行神经网络剪除的影响。我们发现，通过对真实数据进行概要汇总，并使用迭代大小剪除（IMP），可以找到一类特有的稀疏网络，它们在真实数据上更加稳定，SGD 噪音的影响下。即使使用真实数据进行 IMP，也不能达到这类网络的性能。我们通过线性 interpolate，损失地图可见化和对偏导数矩阵的评估来研究这一点。虽然数据概要为一个 relativity 新的领域，但我们发现这些特性使得使用 sintetic data 可以达到与传统 IMP 相同的性能，即使是使用 150 倍少的训练点。”
</details></li>
</ul>
<hr>
<h2 id="Reboost-Large-Language-Model-based-Text-to-SQL-Text-to-Python-and-Text-to-Function-–-with-Real-Applications-in-Traffic-Domain"><a href="#Reboost-Large-Language-Model-based-Text-to-SQL-Text-to-Python-and-Text-to-Function-–-with-Real-Applications-in-Traffic-Domain" class="headerlink" title="Reboost Large Language Model-based Text-to-SQL, Text-to-Python, and Text-to-Function – with Real Applications in Traffic Domain"></a>Reboost Large Language Model-based Text-to-SQL, Text-to-Python, and Text-to-Function – with Real Applications in Traffic Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18752">http://arxiv.org/abs/2310.18752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanghu Sui, Zhishuai Li, Ziyue Li, Sun Yang, Jingqing Ruan, Hangyu Mao, Rui Zhao</li>
<li>for: 提高文本到SQL执行精度</li>
<li>methods: 改进提问方法，包括查询重写和SQL增强</li>
<li>results: 实现了显著提高执行精度，使用较弱的预训练语言模型也达到了21.05%的最高精度Here’s the full translation of the abstract in Simplified Chinese:本文提出了一种更适应和更通用的提问方法，用于提高文本到SQL执行精度。我们发现了对于商业 dataset 的执行精度的显著下降，并且分析了 dataset 的复杂性和问题意图的不同所带来的影响。为了减少信息漏斗，我们将comments、值类型和值示例包含在数据库描述中。我们的实验表明，使用大型自然语言模型（LLMs）可以实现显著的性能提高。相比之下，state-of-the-art 方法在商业 dataset 上的执行精度为21.05%，而我们的方法在同一 dataset 上达到了65.79%。此外，我们还探讨了文本到Python和文本到函数等选项，并对其间的优缺点进行了深入分析，为社区提供了有价值的意见。<details>
<summary>Abstract</summary>
The previous state-of-the-art (SOTA) method achieved a remarkable execution accuracy on the Spider dataset, which is one of the largest and most diverse datasets in the Text-to-SQL domain. However, during our reproduction of the business dataset, we observed a significant drop in performance. We examined the differences in dataset complexity, as well as the clarity of questions' intentions, and assessed how those differences could impact the performance of prompting methods. Subsequently, We develop a more adaptable and more general prompting method, involving mainly query rewriting and SQL boosting, which respectively transform vague information into exact and precise information and enhance the SQL itself by incorporating execution feedback and the query results from the database content. In order to prevent information gaps, we include the comments, value types, and value samples for columns as part of the database description in the prompt. Our experiments with Large Language Models (LLMs) illustrate the significant performance improvement on the business dataset and prove the substantial potential of our method. In terms of execution accuracy on the business dataset, the SOTA method scored 21.05, while our approach scored 65.79. As a result, our approach achieved a notable performance improvement even when using a less capable pre-trained language model. Last but not least, we also explore the Text-to-Python and Text-to-Function options, and we deeply analyze the pros and cons among them, offering valuable insights to the community.
</details>
<details>
<summary>摘要</summary>
previous state-of-the-art (SOTA) 方法在 Spider 数据集上达到了杰出的执行精度，这是文本到 SQL 领域中最大和最多样的数据集之一。然而，在我们重现商业数据集时，我们注意到了显著的性能下降。我们分析了数据集的复杂性以及问题意图的清晰度，并评估了这些差异如何影响提示方法的性能。因此，我们开发了更适应和更通用的提示方法，包括主要的查询重写和 SQL 加强，将混淆信息转化为准确和精确信息，并通过 incorporating 执行反馈和数据库内容的查询结果来增强 SQL 本身。为了避免信息异常，我们将数据库描述中的注释、值类型和值示例包含在提示中。我们的实验表明，使用大型自然语言模型 (LLMs) 可以在商业数据集上实现显著性能提升，并证明了我们的方法的巨大潜力。在商业数据集上的执行精度方面，SOTA 方法得分 21.05，而我们的方法得分 65.79。因此，我们的方法在使用较弱预训练语言模型时 still 实现了显著的性能提升。最后，我们还探索了 Text-to-Python 和 Text-to-Function 选项，并进行了深入分析，提供了价值的发现。
</details></li>
</ul>
<hr>
<h2 id="On-Training-Implicit-Meta-Learning-With-Applications-to-Inductive-Weighing-in-Consistency-Regularization"><a href="#On-Training-Implicit-Meta-Learning-With-Applications-to-Inductive-Weighing-in-Consistency-Regularization" class="headerlink" title="On Training Implicit Meta-Learning With Applications to Inductive Weighing in Consistency Regularization"></a>On Training Implicit Meta-Learning With Applications to Inductive Weighing in Consistency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18741">http://arxiv.org/abs/2310.18741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fady Rezk</li>
<li>for: 这个论文的目的是比较不同的缺省方法在隐式微调学习中的计算成本、稳定性、泛化性和估计准确性。</li>
<li>methods: 这个论文使用了多种缺省方法，包括矩阵估计、均值场估计和积分估计等，并对它们进行了系统比较。</li>
<li>results: 研究发现，矩阵估计和均值场估计在缺省学习中具有较高的计算成本和稳定性，而积分估计具有较高的泛化性和估计准确性。此外，研究还提出了一种新的半监督学习算法，可以透过增强具有适应性的域特异特征来增强鲁棒性。该算法的实验结果超过了基eline FixMatch性能。<details>
<summary>Abstract</summary>
Meta-learning that uses implicit gradient have provided an exciting alternative to standard techniques which depend on the trajectory of the inner loop training. Implicit meta-learning (IML), however, require computing $2^{nd}$ order gradients, particularly the Hessian which is impractical to compute for modern deep learning models. Various approximations for the Hessian were proposed but a systematic comparison of their compute cost, stability, generalization of solution found and estimation accuracy were largely overlooked. In this study, we start by conducting a systematic comparative analysis of the various approximation methods and their effect when incorporated into IML training routines. We establish situations where catastrophic forgetting is exhibited in IML and explain their cause in terms of the inability of the approximations to estimate the curvature at convergence points. Sources of IML training instability are demonstrated and remedied. A detailed analysis of the effeciency of various inverse Hessian-vector product approximation methods is also provided. Subsequently, we use the insights gained to propose and evaluate a novel semi-supervised learning algorithm that learns to inductively weigh consistency regularization losses. We show how training a "Confidence Network" to extract domain specific features can learn to up-weigh useful images and down-weigh out-of-distribution samples. Results outperform the baseline FixMatch performance.
</details>
<details>
<summary>摘要</summary>
Meta-学习使用隐式梯度提供了一种有趣的代替标准技术，这些技术取决于内部循环训练的轨迹。然而，隐式 meta-学习（IML）需要计算第二个梯度，特别是希尔比格，这是现代深度学习模型中计算的不实际。Various approximations for the Hessian were proposed, but a systematic comparison of their compute cost, stability, generalization of solution found and estimation accuracy were largely overlooked.在这项研究中，我们开始了一个系统性的比较分析，检验不同的近似方法在IML训练流程中的效果。我们证明了IML训练中出现的 катастрофи忘记现象，并解释了其原因为近似方法无法在 converges 点 estimating 曲线的 curvature。我们还示出了IML训练的不稳定性的来源，并提供了修复方法。另外，我们还提供了一个细节的 inverse Hessian-vector product approximation 方法的效率分析。然后，我们使用获得的理解，提出和评估一种新的半监督学习算法，该算法可以学习 inductively 权重一致减少损失。我们表明了在训练 "信任网络" 来提取域pecific特征时，可以学习到升重用户图像和降低非标范图像。结果超出了基eline FixMatch性能。
</details></li>
</ul>
<hr>
<h2 id="Pre-training-with-Random-Orthogonal-Projection-Image-Modeling"><a href="#Pre-training-with-Random-Orthogonal-Projection-Image-Modeling" class="headerlink" title="Pre-training with Random Orthogonal Projection Image Modeling"></a>Pre-training with Random Orthogonal Projection Image Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18737">http://arxiv.org/abs/2310.18737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maryam Haghighat, Peyman Moghadam, Shaheer Mohamed, Piotr Koniusz</li>
<li>for: The paper is written for proposing a new self-supervised learning framework called Random Orthogonal Projection Image Modeling (ROPIM) that can be used for visual pre-training without the need for labels.</li>
<li>methods: The paper uses a random orthogonal projection method to randomly mask entire spatial image areas with locally varying masking degrees, which encourages the network to capture and learn structural information about objects and scenes.</li>
<li>results: The paper shows that using random orthogonal projection leads to superior performance compared to crop-based masking, and demonstrates state-of-the-art results on several popular benchmarks.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了介绍一种新的自我超视learning框架，即Random Orthogonal Projection Image Modeling（ROPIM），用于无标签的视觉预训练。</li>
<li>methods: 这篇论文使用随机正交投影方法，随机将整个图像空间掩码，实现了地方性Masking的效果，从而让网络学习对象和场景的结构信息。</li>
<li>results: 这篇论文表明，使用随机正交投影比crop-based masking更高效，并在多个流行的标准测试集上达到了领先的性能。<details>
<summary>Abstract</summary>
Masked Image Modeling (MIM) is a powerful self-supervised strategy for visual pre-training without the use of labels. MIM applies random crops to input images, processes them with an encoder, and then recovers the masked inputs with a decoder, which encourages the network to capture and learn structural information about objects and scenes. The intermediate feature representations obtained from MIM are suitable for fine-tuning on downstream tasks. In this paper, we propose an Image Modeling framework based on random orthogonal projection instead of binary masking as in MIM. Our proposed Random Orthogonal Projection Image Modeling (ROPIM) reduces spatially-wise token information under guaranteed bound on the noise variance and can be considered as masking entire spatial image area under locally varying masking degrees. Since ROPIM uses a random subspace for the projection that realizes the masking step, the readily available complement of the subspace can be used during unmasking to promote recovery of removed information. In this paper, we show that using random orthogonal projection leads to superior performance compared to crop-based masking. We demonstrate state-of-the-art results on several popular benchmarks.
</details>
<details>
<summary>摘要</summary>
自适应学习 ohne 标签的视觉预训练策略：面罩图像模型（MIM）。MIM 使用随机剪辑对输入图像进行处理，然后使用解码器恢复受随机剪辑影响的输入图像，这使得网络学习和捕捉图像中的结构信息。MIM 生成的中间特征表示可以进行下游任务的细化。在这篇论文中，我们提出了基于随机正交投影的图像模型框架（ROPIM）。ROPIM 在空间上减少了Token信息，并且可以保证随机投影的噪声方差的下界。由于 ROPIM 使用随机子空间进行投影，因此可以使用该子空间的可用资源进行解压缩，以便恢复被移除的信息。在这篇论文中，我们证明了使用随机正交投影可以比随机剪辑更高效。我们在多个流行的 benchmark 上达到了状态机器的表现。
</details></li>
</ul>
<hr>
<h2 id="Using-Large-Language-Models-to-Support-Thematic-Analysis-in-Empirical-Legal-Studies"><a href="#Using-Large-Language-Models-to-Support-Thematic-Analysis-in-Empirical-Legal-Studies" class="headerlink" title="Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies"></a>Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18729">http://arxiv.org/abs/2310.18729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jakub Drápal, Hannes Westermann, Jaromir Savelka</li>
<li>for: 本研究旨在探讨如何使用大语言模型（LLM）和法律专家合作进行逻辑分析，以便提高逻辑分析的效率和质量。</li>
<li>methods: 本研究使用了一种新的框架，即将LLM与法律专家合作进行逻辑分析的初始编码（阶段2）、主题搜索（阶段3）和数据分类（阶段4）。</li>
<li>results: 研究发现，使用LLM可以生成合理的初始编码，并且可以根据专家反馈进行改进。此外，模型还能够透过零例学习来将描述事实分类到主题类别中。最后，由LLM自动发现的主题与法律专家所找到的主题之间存在一定的相似性。这些发现可以帮助法律研究人员在启用LLM时作出更 Informed Decisions。<details>
<summary>Abstract</summary>
Thematic analysis and other variants of inductive coding are widely used qualitative analytic methods within empirical legal studies (ELS). We propose a novel framework facilitating effective collaboration of a legal expert with a large language model (LLM) for generating initial codes (phase 2 of thematic analysis), searching for themes (phase 3), and classifying the data in terms of the themes (to kick-start phase 4). We employed the framework for an analysis of a dataset (n=785) of facts descriptions from criminal court opinions regarding thefts. The goal of the analysis was to discover classes of typical thefts. Our results show that the LLM, namely OpenAI's GPT-4, generated reasonable initial codes, and it was capable of improving the quality of the codes based on expert feedback. They also suggest that the model performed well in zero-shot classification of facts descriptions in terms of the themes. Finally, the themes autonomously discovered by the LLM appear to map fairly well to the themes arrived at by legal experts. These findings can be leveraged by legal researchers to guide their decisions in integrating LLMs into their thematic analyses, as well as other inductive coding projects.
</details>
<details>
<summary>摘要</summary>
empirical legal studies (ELS)  widely used qualitative analytic methods, including thematic analysis and its variants. We propose a novel framework for effective collaboration between a legal expert and a large language model (LLM) in thematic analysis, including generating initial codes (phase 2), searching for themes (phase 3), and classifying the data in terms of themes (to kick-start phase 4). We applied the framework to a dataset (n=785) of fact descriptions from criminal court opinions on thefts, aiming to discover typical theft classes. Our results show that OpenAI's GPT-4, the LLM, generated reasonable initial codes and improved code quality based on expert feedback. Additionally, the model performed well in zero-shot classification of fact descriptions in terms of themes. The themes autonomously discovered by the LLM align well with the themes identified by legal experts, providing valuable insights for legal researchers integrating LLMs into their thematic analyses and other inductive coding projects.
</details></li>
</ul>
<hr>
<h2 id="The-Evolution-of-the-Interplay-Between-Input-Distributions-and-Linear-Regions-in-Networks"><a href="#The-Evolution-of-the-Interplay-Between-Input-Distributions-and-Linear-Regions-in-Networks" class="headerlink" title="The Evolution of the Interplay Between Input Distributions and Linear Regions in Networks"></a>The Evolution of the Interplay Between Input Distributions and Linear Regions in Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18725">http://arxiv.org/abs/2310.18725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan Qi, Yi Wei</li>
<li>for: 本研究旨在探讨深度神经网络的表达能力，具体来说是通过ReLU activation function来评估神经网络的表达能力。</li>
<li>methods: 本研究使用了 counted number of linear convex regions 来评估神经网络的表达能力。我们也提供了一种基于ReLU activation function的训练过程的分析。</li>
<li>results: 我们的研究发现，对于任意一个一维输入，存在一个最小阈值的神经元数量可以表达它。此外，我们还发现在训练过程中，ReLU网络的决策边界会经历反复细化过程。我们的研究希望能够激发网络优化的研究，并为深度神经网络的探索和分析提供启示。<details>
<summary>Abstract</summary>
It is commonly recognized that the expressiveness of deep neural networks is contingent upon a range of factors, encompassing their depth, width, and other relevant considerations. Currently, the practical performance of the majority of deep neural networks remains uncertain. For ReLU (Rectified Linear Unit) networks with piecewise linear activations, the number of linear convex regions serves as a natural metric to gauge the network's expressivity. In this paper, we count the number of linear convex regions in deep neural networks based on ReLU. In particular, we prove that for any one-dimensional input, there exists a minimum threshold for the number of neurons required to express it. We also empirically observe that for the same network, intricate inputs hinder its capacity to express linear regions. Furthermore, we unveil the iterative refinement process of decision boundaries in ReLU networks during training. We aspire for our research to serve as an inspiration for network optimization endeavors and aids in the exploration and analysis of the behaviors exhibited by deep networks.
</details>
<details>
<summary>摘要</summary>
通常认为深度神经网络的表达能力取决于各种因素，包括它们的深度、宽度和其他相关因素。目前，大多数深度神经网络的实际表现仍然不清楚。为ReLU（矩阵线性单元）网络，数量的凸 convex 区域作为一个自然的度量来衡量网络的表达能力。在这篇论文中，我们计算了深度神经网络中ReLU activation function的凸 convex 区域数量。特别是，我们证明了任何一维输入都存在一个最小阈值的神经元数量，可以表达它。此外，我们还观察到了在同一个网络中，复杂的输入会降低其表达线性区域的能力。此外，我们还揭示了ReLU网络在训练过程中的迭代精细化过程。我们希望通过这项研究，能够激发网络优化的努力，并且对深度网络的行为进行探索和分析。
</details></li>
</ul>
<hr>
<h2 id="WCLD-Curated-Large-Dataset-of-Criminal-Cases-from-Wisconsin-Circuit-Courts"><a href="#WCLD-Curated-Large-Dataset-of-Criminal-Cases-from-Wisconsin-Circuit-Courts" class="headerlink" title="WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit Courts"></a>WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit Courts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18724">http://arxiv.org/abs/2310.18724</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elliott Ash, Naman Goel, Nianyun Li, Claudia Marangon, Peiyao Sun</li>
<li>for: This paper provides a large dataset of criminal cases to support research on machine learning decision-support tools in criminal justice systems, with a focus on fairness and systemic issues.</li>
<li>methods: The dataset is constructed using reliable public data from 1970 to 2020, including information on prior criminal counts, recidivism outcomes, and various other attributes such as neighborhood characteristics, charge severity, and case decisions.</li>
<li>results: The dataset contains a large number of samples from five racial groups and provides researchers with a more comprehensive and rigorous platform for studying algorithmic fairness in the context of criminal justice.<details>
<summary>Abstract</summary>
Machine learning based decision-support tools in criminal justice systems are subjects of intense discussions and academic research. There are important open questions about the utility and fairness of such tools. Academic researchers often rely on a few small datasets that are not sufficient to empirically study various real-world aspects of these questions. In this paper, we contribute WCLD, a curated large dataset of 1.5 million criminal cases from circuit courts in the U.S. state of Wisconsin. We used reliable public data from 1970 to 2020 to curate attributes like prior criminal counts and recidivism outcomes. The dataset contains large number of samples from five racial groups, in addition to information like sex and age (at judgment and first offense). Other attributes in this dataset include neighborhood characteristics obtained from census data, detailed types of offense, charge severity, case decisions, sentence lengths, year of filing etc. We also provide pseudo-identifiers for judge, county and zipcode. The dataset will not only enable researchers to more rigorously study algorithmic fairness in the context of criminal justice, but also relate algorithmic challenges with various systemic issues. We also discuss in detail the process of constructing the dataset and provide a datasheet. The WCLD dataset is available at \url{https://clezdata.github.io/wcld/}.
</details>
<details>
<summary>摘要</summary>
机器学习基于决策支持工具在刑事司法系统中是激烈的讨论和学术研究的主题。有重要的开放问题，例如这些工具的有用性和公平性。学术研究人员 часто依靠一些小的数据集来实际研究各种现实世界方面的问题。在这篇论文中，我们贡献了WCLD，一个 curaated大型数据集，包含150万个刑事案件从美国威斯康星州的环境法院。我们使用可靠的公共数据从1970年到2020年来Curate属性，如前科犯罪记录和重犯率结果。这个数据集包含多个种族组，以及性别和年龄（审判时和首次犯罪时）的信息。其他属性包括从人口普查数据获取的社区特征、细致的犯罪类型、罪名严重程度、审判结果、刑罚长度、提交年份等。我们还提供了判官、郡和邮政编码的 Pseudo-标识符。这个数据集不仅允许研究人员更加严谨地研究刑事司法中的算法公平性，还可以将算法挑战与多种系统问题相关联。我们还在详细介绍了数据集构建过程，并提供了数据表单。WCLD数据集可以在 \url{https://clezdata.github.io/wcld/} 上下载。
</details></li>
</ul>
<hr>
<h2 id="Robust-Offline-Policy-Evaluation-and-Optimization-with-Heavy-Tailed-Rewards"><a href="#Robust-Offline-Policy-Evaluation-and-Optimization-with-Heavy-Tailed-Rewards" class="headerlink" title="Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards"></a>Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18715">http://arxiv.org/abs/2310.18715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jin Zhu, Runzhe Wan, Zhengling Qi, Shikai Luo, Chengchun Shi</li>
<li>for: 增强线上强化学习（RL）在重 tailed 奖励下的Robustness，这种情况在实际应用中很普遍。</li>
<li>methods: 我们提出了两种算法框架，ROAM和ROOM，用于稳定的 Off-policy Evaluation（OPE）和 Offline Policy Optimization（OPO）。我们的框架通过精心将 median-of-means 方法与线上RL结合，以便直观地估计值函数估计器的uncertainty。这不仅遵循 OPO 的原则，而且 также有效地处理重 tailed 奖励。</li>
<li>results: 我们的两种框架在对 logged 数据集展示 heavy-tailed 奖励分布时表现出色，与现有方法相比，有较高的性能。<details>
<summary>Abstract</summary>
This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Investigation-of-Darwiche-and-Pearl’s-Postulates-for-Iterated-Belief-Update"><a href="#An-Investigation-of-Darwiche-and-Pearl’s-Postulates-for-Iterated-Belief-Update" class="headerlink" title="An Investigation of Darwiche and Pearl’s Postulates for Iterated Belief Update"></a>An Investigation of Darwiche and Pearl’s Postulates for Iterated Belief Update</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18714">http://arxiv.org/abs/2310.18714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quanlong Guan, Tong Zhu, Liangda Fang, Junming Qiu, Zhao-Rong Lai, Weiqi Luo</li>
<li>For: This paper focuses on belief revision and update, two types of belief change, and how an agent can modify her beliefs in the presence of new information.* Methods: The paper uses the AGM and KM postulates to capture rational belief revision and update, respectively, but notes that these postulates are too permissive and can lead to unreasonable changes in the iteration.* Results: The paper presents a modification of the original KM postulates based on belief states, and migrates several well-known postulates for iterated belief revision to iterated belief update. The paper also provides exact semantic characterizations based on partial preorders for each of the proposed postulates, and analyzes the compatibility between the iterated postulates and the KM postulates for belief update.<details>
<summary>Abstract</summary>
Belief revision and update, two significant types of belief change, both focus on how an agent modify her beliefs in presence of new information. The most striking difference between them is that the former studies the change of beliefs in a static world while the latter concentrates on a dynamically-changing world. The famous AGM and KM postulates were proposed to capture rational belief revision and update, respectively. However, both of them are too permissive to exclude some unreasonable changes in the iteration. In response to this weakness, the DP postulates and its extensions for iterated belief revision were presented. Furthermore, Rodrigues integrated these postulates in belief update. Unfortunately, his approach does not meet the basic requirement of iterated belief update. This paper is intended to solve this problem of Rodrigues's approach. Firstly, we present a modification of the original KM postulates based on belief states. Subsequently, we migrate several well-known postulates for iterated belief revision to iterated belief update. Moreover, we provide the exact semantic characterizations based on partial preorders for each of the proposed postulates. Finally, we analyze the compatibility between the above iterated postulates and the KM postulates for belief update.
</details>
<details>
<summary>摘要</summary>
belief revision和更新两种重要的信念变化都关注于一个代理人在新信息存在下如何修改她的信念。两者最明显的差异在于前者研究在静止世界中的信念变化，而后者专注于动态变化的世界。著名的AGM和KM假设被提出来捕捉合理的信念修改和更新。然而，两者都过于允许一些不合理的修改在迭代中。为了解决这个弱点，DP假设和其扩展被提出来。此外，Rodrigues将这些假设 integrate到信念更新中。然而，他的方法并不满足基本的迭代信念更新要求。这篇论文的目的是解决Rodrigues的方法中的这个问题。首先，我们提出修改了原始KM假设的基于信念状态的修改。然后，我们将许多已知的迭代信念修改假设迁移到迭代信念更新中。此外，我们提供了每个提案的准确的语义特征化，基于partial orden для每个提案。最后，我们分析了以上迭代假设与KM假设之间的兼容性。
</details></li>
</ul>
<hr>
<h2 id="Probing-LLMs-for-Joint-Encoding-of-Linguistic-Categories"><a href="#Probing-LLMs-for-Joint-Encoding-of-Linguistic-Categories" class="headerlink" title="Probing LLMs for Joint Encoding of Linguistic Categories"></a>Probing LLMs for Joint Encoding of Linguistic Categories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18696">http://arxiv.org/abs/2310.18696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thesofakillers/infoshare">https://github.com/thesofakillers/infoshare</a></li>
<li>paper_authors: Giulio Starace, Konstantinos Papakostas, Rochelle Choenni, Apostolos Panagiotopoulos, Matteo Rosati, Alina Leidinger, Ekaterina Shutova</li>
<li>for: 这个论文旨在探讨大语言模型（LLM）中不同语言现象之间的编码方式，以及这些编码方式如何交互影响模型的表示。</li>
<li>methods: 作者提出了一种测试框架，用于检查 LLM 中不同语言现象之间的编码方式。他们在 syntax 领域进行了实验，并发现了在同一级别（相关的 parts-of-speech 类）和不同级别（parts-of-speech 类和相关的语法依赖关系）之间存在共同编码的证据。</li>
<li>results: 实验显示，在多语言 LLM 中，同样的 patterns 存在于不同语言中。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) exhibit impressive performance on a range of NLP tasks, due to the general-purpose linguistic knowledge acquired during pretraining. Existing model interpretability research (Tenney et al., 2019) suggests that a linguistic hierarchy emerges in the LLM layers, with lower layers better suited to solving syntactic tasks and higher layers employed for semantic processing. Yet, little is known about how encodings of different linguistic phenomena interact within the models and to what extent processing of linguistically-related categories relies on the same, shared model representations. In this paper, we propose a framework for testing the joint encoding of linguistic categories in LLMs. Focusing on syntax, we find evidence of joint encoding both at the same (related part-of-speech (POS) classes) and different (POS classes and related syntactic dependency relations) levels of linguistic hierarchy. Our cross-lingual experiments show that the same patterns hold across languages in multilingual LLMs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在多种自然语言处理任务上表现出众，这是因为预训练期间获得的通用语言知识。现有的模型解释研究（Tenney等，2019）表明，LLM层次结构中的下层更适合解决语法任务，而上层则用于 semantics处理。然而，我们对 LLM 中不同语言现象编码的交互并不甚了解，以及这些编码如何在模型中互相协作。在这篇论文中，我们提出了测试 LLM 中语言类别之间的共同编码框架。我们将注重语法，发现在同一级别（相关的部分词类）和不同级别（部分词类和相关的语法关系）之间都有共同编码证据。我们的跨语言实验表明，这些模式在多语言 LLM 中也存在。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Behavior-Extraction-via-Random-Intent-Priors"><a href="#Unsupervised-Behavior-Extraction-via-Random-Intent-Priors" class="headerlink" title="Unsupervised Behavior Extraction via Random Intent Priors"></a>Unsupervised Behavior Extraction via Random Intent Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18687">http://arxiv.org/abs/2310.18687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Hu, Yiqin Yang, Jianing Ye, Ziqing Mai, Chongjie Zhang</li>
<li>for: 提高offline reinforcement learning（RL）算法的效率和实用性，使其能够更好地利用奖励自由数据中的人类行为知识。</li>
<li>methods: 提出了一种无监督的方法UBER，通过不同的假奖分配给不同的代理人来提取多样化的行为集，并将其 reuse 为新任务学习的候选策略。</li>
<li>results: 经验和理论证明表明，使用随机神经网络生成的奖励函数可以提取多样化和有用的行为，一些甚至与专家相似。实验结果表明，UBER可以在多个 benchmark 上学习有效和多样的行为集，超过现有的基elines。<details>
<summary>Abstract</summary>
Reward-free data is abundant and contains rich prior knowledge of human behaviors, but it is not well exploited by offline reinforcement learning (RL) algorithms. In this paper, we propose UBER, an unsupervised approach to extract useful behaviors from offline reward-free datasets via diversified rewards. UBER assigns different pseudo-rewards sampled from a given prior distribution to different agents to extract a diverse set of behaviors, and reuse them as candidate policies to facilitate the learning of new tasks. Perhaps surprisingly, we show that rewards generated from random neural networks are sufficient to extract diverse and useful behaviors, some even close to expert ones. We provide both empirical and theoretical evidence to justify the use of random priors for the reward function. Experiments on multiple benchmarks showcase UBER's ability to learn effective and diverse behavior sets that enhance sample efficiency for online RL, outperforming existing baselines. By reducing reliance on human supervision, UBER broadens the applicability of RL to real-world scenarios with abundant reward-free data.
</details>
<details>
<summary>摘要</summary>
reward-free 数据够丰富，含有人类行为的丰富先验知识，但是现在的Offline reinforcement learning（RL）算法未能充分利用这些数据。在这篇论文中，我们提出了UBER，一种不带supervision的方法，通过多样化的奖励来提取用于新任务学习的有用行为集。我们尝试 assigning different pseudo-奖励，从给定的先验分布中随机生成的奖励，给不同的代理人，以提取多样化的行为集，并将其 reuse 作为新任务学习的候选策略。我们发现，由随机神经网络生成的奖励可以提取出高质量的多样化行为集，其中一些甚至可以与专家级别相比。我们提供了 both empirical 和理论证据，证明使用随机先验来奖励函数是有理由的。我们在多个 bench mark 上进行了实验，证明 UBER 能够学习有效和多样化的行为集，提高在线RL的样本效率，超过现有的基eline。通过减少人类监督，UBER 扩展了RL的应用范围，使其可以在实际情况下应用。
</details></li>
</ul>
<hr>
<h2 id="N-Critics-Self-Refinement-of-Large-Language-Models-with-Ensemble-of-Critics"><a href="#N-Critics-Self-Refinement-of-Large-Language-Models-with-Ensemble-of-Critics" class="headerlink" title="N-Critics: Self-Refinement of Large Language Models with Ensemble of Critics"></a>N-Critics: Self-Refinement of Large Language Models with Ensemble of Critics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18679">http://arxiv.org/abs/2310.18679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sajad Mousavi, Ricardo Luna Gutiérrez, Desik Rengarajan, Vineet Gundecha, Ashwin Ramesh Babu, Avisek Naug, Antonio Guillen, Soumyendu Sarkar</li>
<li>for: 提高 LLM 的可靠性和准确性， Mitigate 偏见和谎言</li>
<li>methods: 使用一个 ensemble of critics 和模型自身的反馈来修正模型输出， drawing inspiration from human self-reflection and input seeking behavior</li>
<li>results:  observe consistent performance improvements in reducing toxicity and correcting factual errors<details>
<summary>Abstract</summary>
We propose a self-correction mechanism for Large Language Models (LLMs) to mitigate issues such as toxicity and fact hallucination. This method involves refining model outputs through an ensemble of critics and the model's own feedback. Drawing inspiration from human behavior, we explore whether LLMs can emulate the self-correction process observed in humans who often engage in self-reflection and seek input from others to refine their understanding of complex topics. Our approach is model-agnostic and can be applied across various domains to enhance trustworthiness by addressing fairness, bias, and robustness concerns. We consistently observe performance improvements in LLMs for reducing toxicity and correcting factual errors.
</details>
<details>
<summary>摘要</summary>
我们提出了一种自修复机制，用于 mitigate Large Language Models（LLMs）中的问题，如恶意和谬误投入。这种方法通过一个ensemble of critics和模型自身的反馈来纠正模型输出。我们从人类行为中获得灵感，探讨 LLMS 是否可以模仿人类自我反思的自修复过程。我们的方法是无关模型的，可以在不同领域中应用，以提高可靠性，解决公平、偏见和Robustness 等问题。我们一致地观察到 LLMS 的性能提高，用于减少恶意和 corrected 错误。
</details></li>
</ul>
<hr>
<h2 id="GalliformeSpectra-A-Hen-Breed-Dataset"><a href="#GalliformeSpectra-A-Hen-Breed-Dataset" class="headerlink" title="GalliformeSpectra: A Hen Breed Dataset"></a>GalliformeSpectra: A Hen Breed Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.19830">http://arxiv.org/abs/2310.19830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Galib Muhammad Shahriar Himel, Md Masudul Islam</li>
<li>for: 这个论文旨在提供一份包含十种不同鸡种的完整数据集，以捕捉每种鸡种的独特特征和特征。</li>
<li>methods: 该论文使用了一种多样化的数据收集方法，收集了1010个原始JPG图像，展示了各种鸡种的身体特征、毛皮模式和特有的特征。这些图像后来被标准化、缩放和转换为PNG格式以保持数据集的一致性。</li>
<li>results: 该数据集提供了一个多样化的资源，可以用于鸡类科学、遗传学和农业研究。这个数据集的潜在价值在于它可以帮助研究人员探索不同鸡种之间的一致性和遗传特征，从而支持鸡类种养、遗传研究和生物技术发展。<details>
<summary>Abstract</summary>
This article presents a comprehensive dataset featuring ten distinct hen breeds, sourced from various regions, capturing the unique characteristics and traits of each breed. The dataset encompasses Bielefeld, Blackorpington, Brahma, Buckeye, Fayoumi, Leghorn, Newhampshire, Plymouthrock, Sussex, and Turken breeds, offering a diverse representation of poultry commonly bred worldwide. A total of 1010 original JPG images were meticulously collected, showcasing the physical attributes, feather patterns, and distinctive features of each hen breed. These images were subsequently standardized, resized, and converted to PNG format for consistency within the dataset. The compilation, although unevenly distributed across the breeds, provides a rich resource, serving as a foundation for research and applications in poultry science, genetics, and agricultural studies. This dataset holds significant potential to contribute to various fields by enabling the exploration and analysis of unique characteristics and genetic traits across different hen breeds, thereby supporting advancements in poultry breeding, farming, and genetic research.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FinBTech-Blockchain-Based-Video-and-Voice-Authentication-System-for-Enhanced-Security-in-Financial-Transactions-Utilizing-FaceNet512-and-Gaussian-Mixture-Models"><a href="#FinBTech-Blockchain-Based-Video-and-Voice-Authentication-System-for-Enhanced-Security-in-Financial-Transactions-Utilizing-FaceNet512-and-Gaussian-Mixture-Models" class="headerlink" title="FinBTech: Blockchain-Based Video and Voice Authentication System for Enhanced Security in Financial Transactions Utilizing FaceNet512 and Gaussian Mixture Models"></a>FinBTech: Blockchain-Based Video and Voice Authentication System for Enhanced Security in Financial Transactions Utilizing FaceNet512 and Gaussian Mixture Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18668">http://arxiv.org/abs/2310.18668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prof N. Jeenath Laila, Dr G. Tamilpavai</li>
<li>for: 为了提高金融交易的安全性和可靠性</li>
<li>methods: 使用智能合约、区块链技术、FaceNet512 face recognition和GMM语音认证，实现视频和音频验证</li>
<li>results: 提供了一个无 precedent 的多因素生物 metric 验证系统，提高安全性至新高度<details>
<summary>Abstract</summary>
In the digital age, it is crucial to make sure that financial transactions are as secure and reliable as possible. This abstract offers a ground-breaking method that combines smart contracts, blockchain technology, FaceNet512 for improved face recognition, and Gaussian Mixture Models (GMM) for speech authentication to create a system for video and audio verification that is unmatched. Smart contracts and the immutable ledger of the blockchain are combined to offer a safe and open environment for financial transactions. FaceNet512 and GMM offer multi-factor biometric authentication simultaneously, enhancing security to new heights. By combining cutting-edge technology, this system offers a strong defense against identity theft and illegal access, establishing a new benchmark for safe financial transactions.
</details>
<details>
<summary>摘要</summary>
在数字时代，确保金融交易的安全和可靠性非常重要。这个报道提供了一种创新的方法， combinig智能合同、区块链技术、FaceNet512 для提高人脸识别和混合 Gaussian Mixture Models (GMM)  для语音验证，以创建一个无与伦比的视频和音频验证系统。智能合同和区块链的坚实记录结合，提供了一个安全和开放的金融交易环境。FaceNet512 和 GMM 同时提供多因素生物 metric 验证，提高安全性至新的高度。通过结合前沿技术，这个系统提供了一个强大的防止身份盗用和未经授权访问的防御，设立了新的安全金融交易标准。
</details></li>
</ul>
<hr>
<h2 id="From-Indeterminacy-to-Determinacy-Augmenting-Logical-Reasoning-Capabilities-with-Large-Language-Models"><a href="#From-Indeterminacy-to-Determinacy-Augmenting-Logical-Reasoning-Capabilities-with-Large-Language-Models" class="headerlink" title="From Indeterminacy to Determinacy: Augmenting Logical Reasoning Capabilities with Large Language Models"></a>From Indeterminacy to Determinacy: Augmenting Logical Reasoning Capabilities with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18659">http://arxiv.org/abs/2310.18659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongda Sun, Weikai Xu, Wei Liu, Jian Luan, Bin Wang, Shuo Shang, Ji-Rong Wen, Rui Yan</li>
<li>for: 提高LLM的逻辑推理能力，以便更好地模仿人类逻辑思维。</li>
<li>methods: 提出了一种新的逻辑推理框架，即DetermLR，该框架将逻辑推理过程定义为一种从不确定前提开始，逐步增加确定前提，使结论变得更加明确的过程。DetermLR包括三个重要组成部分：1）前提识别：将前提分为两类：确定和不确定。这使LLM可以根据特定任务的复杂度选择适当的逻辑结构。2）前提优化和探索：利用量化度量评估每个前提的相关性，以便更好地决定探索哪些前提可能会带来新的发现。3）迭代过程和逻辑记忆：引入逻辑记忆模块，自动记录和提取可用的前提和逻辑路径，以保持历史逻辑细节，从而更好地优化前提优化和逻辑推理过程。</li>
<li>results: 对四个复杂的逻辑推理任务LogiQA、ProofWriter、FOLIO和LogicalDeduction进行了广泛的实验，结果表明，DetermLR与所有基线相比，在逻辑推理任务中表现出色，可以更好地完成逻辑推理任务，同时需要更少的访问状态。<details>
<summary>Abstract</summary>
Recent advances in LLMs have revolutionized the landscape of reasoning tasks. To enhance the capabilities of LLMs to emulate human reasoning, prior works focus on modeling reasoning steps using specific thought structures like chains, trees, or graphs. However, LLM-based reasoning continues to encounter three challenges: 1) Selecting appropriate reasoning structures for various tasks; 2) Exploiting known conditions sufficiently and efficiently to deduce new insights; 3) Considering the impact of historical reasoning experience. To address these challenges, we propose DetermLR, a novel reasoning framework that formulates the reasoning process as a transformational journey from indeterminate premises to determinate ones. This process is marked by the incremental accumulation of determinate premises, making the conclusion progressively closer to clarity. DetermLR includes three essential components: 1) Premise identification: We categorize premises into two distinct types: determinate and indeterminate. This empowers LLMs to customize reasoning structures to match the specific task complexities. 2) Premise prioritization and exploration: We leverage quantitative measurements to assess the relevance of each premise to the target, prioritizing more relevant premises for exploring new insights. 3) Iterative process with reasoning memory: We introduce a reasoning memory module to automate storage and extraction of available premises and reasoning paths, preserving historical reasoning details for more accurate premise prioritization. Comprehensive experimental results show that DetermLR outperforms all baselines on four challenging logical reasoning tasks: LogiQA, ProofWriter, FOLIO, and LogicalDeduction. DetermLR can achieve better reasoning performance while requiring fewer visited states, highlighting its superior efficiency and effectiveness in tackling logical reasoning tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Selecting appropriate reasoning structures for various tasks2. Exploiting known conditions sufficiently and efficiently to deduce new insights3. Considering the impact of historical reasoning experience.To address these challenges, we propose DetermLR, a novel reasoning framework that formulates the reasoning process as a transformational journey from indeterminate premises to determinate ones. This process is marked by the incremental accumulation of determinate premises, making the conclusion progressively closer to clarity. DetermLR includes three essential components: 1. Premise identification: We categorize premises into two distinct types: determinate and indeterminate. This empowers LLMs to customize reasoning structures to match the specific task complexities. 2. Premise prioritization and exploration: We leverage quantitative measurements to assess the relevance of each premise to the target, prioritizing more relevant premises for exploring new insights. 3. Iterative process with reasoning memory: We introduce a reasoning memory module to automate storage and extraction of available premises and reasoning paths, preserving historical reasoning details for more accurate premise prioritization.Comprehensive experimental results show that DetermLR outperforms all baselines on four challenging logical reasoning tasks: LogiQA, ProofWriter, FOLIO, and LogicalDeduction. DetermLR can achieve better reasoning performance while requiring fewer visited states, highlighting its superior efficiency and effectiveness in tackling logical reasoning tasks.</details></li>
</ol>
<hr>
<h2 id="EHRXQA-A-Multi-Modal-Question-Answering-Dataset-for-Electronic-Health-Records-with-Chest-X-ray-Images"><a href="#EHRXQA-A-Multi-Modal-Question-Answering-Dataset-for-Electronic-Health-Records-with-Chest-X-ray-Images" class="headerlink" title="EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images"></a>EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18652">http://arxiv.org/abs/2310.18652</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/baeseongsu/ehrxqa">https://github.com/baeseongsu/ehrxqa</a></li>
<li>paper_authors: Seongsu Bae, Daeun Kyung, Jaehee Ryu, Eunbyeol Cho, Gyubok Lee, Sunjun Kweon, Jungwoo Oh, Lei Ji, Eric I-Chao Chang, Tackeun Kim, Edward Choi</li>
<li>For: 这个论文旨在开发一个基于电子医疗记录（EHR）的多模态问答集（EHRXQA），以推动现有EHR问答系统中多模态合理的推理。* Methods: 该论文使用了两个uni-modal资源：1）MIMIC-CXR-VQA数据集，我们新创建的医疗图像问答标准 benchmark，以增强imaging模式在EHR问答中的参与度；2）EHRSQL（MIMIC-IV），一个重新设计的表格基于EHR问答dataset。通过将这两个uni-modal资源集成，我们成功构建了一个多模态EHR问答集。* Results: 该论文提出了一种基于NeuralSQL的策略，其中包括一个外部VQA API，以解决多模态EHR问题中的独特挑战。这项创新的尝试可以提高对多模态EHR源的参与度，我们认为这个dataset可以促进现实世界的医疗应用，如临床决策和研究。<details>
<summary>Abstract</summary>
Electronic Health Records (EHRs), which contain patients' medical histories in various multi-modal formats, often overlook the potential for joint reasoning across imaging and table modalities underexplored in current EHR Question Answering (QA) systems. In this paper, we introduce EHRXQA, a novel multi-modal question answering dataset combining structured EHRs and chest X-ray images. To develop our dataset, we first construct two uni-modal resources: 1) The MIMIC- CXR-VQA dataset, our newly created medical visual question answering (VQA) benchmark, specifically designed to augment the imaging modality in EHR QA, and 2) EHRSQL (MIMIC-IV), a refashioned version of a previously established table-based EHR QA dataset. By integrating these two uni-modal resources, we successfully construct a multi-modal EHR QA dataset that necessitates both uni-modal and cross-modal reasoning. To address the unique challenges of multi-modal questions within EHRs, we propose a NeuralSQL-based strategy equipped with an external VQA API. This pioneering endeavor enhances engagement with multi-modal EHR sources and we believe that our dataset can catalyze advances in real-world medical scenarios such as clinical decision-making and research. EHRXQA is available at https://github.com/baeseongsu/ehrxqa.
</details>
<details>
<summary>摘要</summary>
电子健康记录（EHR），它们包含了患者的医疗历史记录在不同的多模态格式中，经常忽视了现有EHR问答系统中的跨模态合理化潜力。在这篇论文中，我们引入了EHRXQA，一个新的多模态问答数据集，结合了结构化的EHR和胸部X射影像。为了开发我们的数据集，我们首先构建了两个单模态资源：1）我们新创建的医疗图像问答数据集（MIMIC-CXR-VQA），用于增强EHR中的图像模态，并2）EHRSQL（MIMIC-IV），一个重新设计的表格基于EHR问答数据集。通过将这两个单模态资源集成起来，我们成功地构建了一个多模态EHR问答数据集，需要同时进行单模态和跨模态合理化。为了解决EHR中多模态问题中的特殊挑战，我们提出了基于NeuralSQL的策略，并配备了外部VQA API。我们认为这一努力可以提高对多模态EHR源的参与度，并且我们相信EHRXQA数据集可以促进实际医疗场景中的决策和研究。EHRXQA数据集可以在https://github.com/baeseongsu/ehrxqa上下载。
</details></li>
</ul>
<hr>
<h2 id="Sleep-Deprivation-in-the-Forward-Forward-Algorithm"><a href="#Sleep-Deprivation-in-the-Forward-Forward-Algorithm" class="headerlink" title="Sleep Deprivation in the Forward-Forward Algorithm"></a>Sleep Deprivation in the Forward-Forward Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18647">http://arxiv.org/abs/2310.18647</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mirceatlx/ff">https://github.com/mirceatlx/ff</a></li>
<li>paper_authors: Mircea-Tudor Lică, David Dinucu-Jianu</li>
<li>for: 本研究探讨了在睡眠Context中Forward-Forward算法的两个前向通道分离方法的生物学意义。</li>
<li>methods: 本研究使用了Forward-Forward算法进行学习，并通过调整睡眠和醒目阶段之间的差距来调整算法的学习能力。</li>
<li>results: 研究发现，睡眠阶段的差距影响了算法的学习能力，而负数据的存在可以减轻睡眠不足的影响。<details>
<summary>Abstract</summary>
This paper aims to explore the separation of the two forward passes in the Forward-Forward algorithm from a biological perspective in the context of sleep. We show the size of the gap between the sleep and awake phase influences the learning capabilities of the algorithm and highlight the importance of negative data in diminishing the devastating effects of sleep deprivation.
</details>
<details>
<summary>摘要</summary>
Note: "Forward-Forward algorithm" is not a real algorithm, it's a fictional one used for illustration purposes only.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Agricultural-Commodities-Prices-with-Machine-Learning-A-Review-of-Current-Research"><a href="#Predicting-Agricultural-Commodities-Prices-with-Machine-Learning-A-Review-of-Current-Research" class="headerlink" title="Predicting Agricultural Commodities Prices with Machine Learning: A Review of Current Research"></a>Predicting Agricultural Commodities Prices with Machine Learning: A Review of Current Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18646">http://arxiv.org/abs/2310.18646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nhat-Quang Tran, Anna Felipe, Thanh Nguyen Ngoc, Tom Huynh, Quang Tran, Arthur Tang, Thuy Nguyen</li>
<li>For: 这篇论文是关于机器学习算法在农业价格预测中的一种评论。* Methods: 论文详细介绍了各种机器学习算法在农业价格预测中的应用，包括支持向量机器、决策树、彩虹分解等。* Results: 论文认为，机器学习算法可以提高农业价格预测的准确性和实时性，同时可以适应不同的农业市场和环境。但是，论文也指出了这些算法的限制和挑战，例如数据质量和可用性的问题。<details>
<summary>Abstract</summary>
Agricultural price prediction is crucial for farmers, policymakers, and other stakeholders in the agricultural sector. However, it is a challenging task due to the complex and dynamic nature of agricultural markets. Machine learning algorithms have the potential to revolutionize agricultural price prediction by improving accuracy, real-time prediction, customization, and integration. This paper reviews recent research on machine learning algorithms for agricultural price prediction. We discuss the importance of agriculture in developing countries and the problems associated with crop price falls. We then identify the challenges of predicting agricultural prices and highlight how machine learning algorithms can support better prediction. Next, we present a comprehensive analysis of recent research, discussing the strengths and weaknesses of various machine learning techniques. We conclude that machine learning has the potential to revolutionize agricultural price prediction, but further research is essential to address the limitations and challenges associated with this approach.
</details>
<details>
<summary>摘要</summary>
农业价格预测对农民、政策制定者和农业领acker有着重要的意义。然而，由于农业市场的复杂和动态特点，这是一项具有挑战性的任务。机器学习算法有可能为农业价格预测带来革命性的改善，包括准确性、实时预测、定制化和 интеграción。本文 recensreview了最近的研究，探讨了机器学习算法在农业价格预测中的应用。我们讨论了发展国家农业的重要性以及作物价格下跌的问题，然后详细介绍了各种机器学习技术的挑战和局限性。我们 conclude that 机器学习有可能为农业价格预测带来革命性的改善，但进一步的研究是必要的，以解决这种方法的限制和挑战。
</details></li>
</ul>
<hr>
<h2 id="One-shot-Localization-and-Segmentation-of-Medical-Images-with-Foundation-Models"><a href="#One-shot-Localization-and-Segmentation-of-Medical-Images-with-Foundation-Models" class="headerlink" title="One-shot Localization and Segmentation of Medical Images with Foundation Models"></a>One-shot Localization and Segmentation of Medical Images with Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18642">http://arxiv.org/abs/2310.18642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepa Anand, Gurunath Reddy M, Vanika Singhal, Dattesh D. Shanbhag, Shriram KS, Uday Patil, Chitresh Bhushan, Kavitha Manickam, Dawei Gui, Rakesh Mullick, Avinash Gopal, Parminder Bhatia, Taha Kass-Hout</li>
<li>for: 本研究使用自然图像预训练的视Transformers（ViT）和稳定扩散（SD）模型来解决医学图像对应问题。</li>
<li>methods: 研究使用多种预训练的ViT（DINO、DINOv2、SAM、CLIP）和SD模型，对医学图像进行解决对应问题。</li>
<li>results: 研究表明，使用自然图像预训练的ViT和SD模型可以在不同的医学图像模式（CT、MR、ultrasound）、多个解剖区域（脑、胸、 Abdomen、Extremities）和多种任务上达到良好的性能。此外，通过与模板图像进行对应，我们使用SAM模型进行单击分割，达到了单击分割的 dice range 62%-90%。我们的单击方法也超过了 reciently proposed few-shot segmentation方法 - UniverSeg（Dice range 47%-80%) 在大多数医学图像模式中的多个semantic segmentation任务中表现出色。<details>
<summary>Abstract</summary>
Recent advances in Vision Transformers (ViT) and Stable Diffusion (SD) models with their ability to capture rich semantic features of the image have been used for image correspondence tasks on natural images. In this paper, we examine the ability of a variety of pre-trained ViT (DINO, DINOv2, SAM, CLIP) and SD models, trained exclusively on natural images, for solving the correspondence problems on medical images. While many works have made a case for in-domain training, we show that the models trained on natural images can offer good performance on medical images across different modalities (CT,MR,Ultrasound) sourced from various manufacturers, over multiple anatomical regions (brain, thorax, abdomen, extremities), and on wide variety of tasks. Further, we leverage the correspondence with respect to a template image to prompt a Segment Anything (SAM) model to arrive at single shot segmentation, achieving dice range of 62%-90% across tasks, using just one image as reference. We also show that our single-shot method outperforms the recently proposed few-shot segmentation method - UniverSeg (Dice range 47%-80%) on most of the semantic segmentation tasks(six out of seven) across medical imaging modalities.
</details>
<details>
<summary>摘要</summary>
近期，人工智能领域内的视觉转换器（ViT）和稳定扩散（SD）模型在自然图像上表现出了捕捉图像 semantics的能力，这些模型在图像匹配任务中表现出色。在这篇论文中，我们研究了不同预训练的 ViT（DINO、DINOv2、SAM、CLIP）和 SD 模型，这些模型均在自然图像上进行封闭式训练，是否能够在医疗图像上解决匹配问题。虽然许多研究认为域内训练是关键，但我们发现这些模型在医疗图像上表现良好，包括不同的modalities（CT、MR、ultrasound），来自不同的制造商，以及多个解剖区域（大脑、胸部、腹部、四肢）。此外，我们利用模板图像的对应关系，使用 SAM 模型进行一步分割，实现了单步分割的 dice 范围为 62%-90%，使用只有一张图像作为参考。此外，我们的单步方法在多种医疗影像模式中的多个semantic segmentation任务中表现出色，超过了最近提出的几个shot segmentation方法（UniverSeg）的 dice 范围（47%-80%）。
</details></li>
</ul>
<hr>
<h2 id="Electrical-Impedance-Tomography-A-Fair-Comparative-Study-on-Deep-Learning-and-Analytic-based-Approaches"><a href="#Electrical-Impedance-Tomography-A-Fair-Comparative-Study-on-Deep-Learning-and-Analytic-based-Approaches" class="headerlink" title="Electrical Impedance Tomography: A Fair Comparative Study on Deep Learning and Analytic-based Approaches"></a>Electrical Impedance Tomography: A Fair Comparative Study on Deep Learning and Analytic-based Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18636">http://arxiv.org/abs/2310.18636</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dericknganyu/eit_dataset_generation">https://github.com/dericknganyu/eit_dataset_generation</a></li>
<li>paper_authors: Derick Nganyu Tanyu, Jianfeng Ning, Andreas Hauptmann, Bangti Jin, Peter Maass</li>
<li>For: This paper focuses on the Electrical Impedance Tomography (EIT) inverse problem, which is the challenge of inferring the internal conductivity distribution of an object from measurements taken on its boundary. The paper explores techniques for solving this problem, particularly the interplay between deep learning-based strategies and classical analytic-based methods.* Methods: The paper examines four state-of-the-art deep learning algorithms for solving the EIT inverse problem, including their representational capabilities and strengths. In addition, two analytic-based methods are dissected for their limitations and strengths. The paper also employs various numerical experiments to evaluate the efficacy of these methods.* Results: The paper provides a nuanced understanding of the methods’ ability to capture essential features and delineate complex conductivity patterns. The incorporation of variable conductivity scenarios allows for exploring the robustness and adaptability of each method. The results demonstrate the potential of deep learning-based methods for solving the EIT inverse problem, particularly in the presence of complex conductivity patterns.<details>
<summary>Abstract</summary>
Electrical Impedance Tomography (EIT) is a powerful imaging technique with diverse applications, e.g., medical diagnosis, industrial monitoring, and environmental studies. The EIT inverse problem is about inferring the internal conductivity distribution of an object from measurements taken on its boundary. It is severely ill-posed, necessitating advanced computational methods for accurate image reconstructions. Recent years have witnessed significant progress, driven by innovations in analytic-based approaches and deep learning. This review explores techniques for solving the EIT inverse problem, focusing on the interplay between contemporary deep learning-based strategies and classical analytic-based methods. Four state-of-the-art deep learning algorithms are rigorously examined, harnessing the representational capabilities of deep neural networks to reconstruct intricate conductivity distributions. In parallel, two analytic-based methods, rooted in mathematical formulations and regularisation techniques, are dissected for their strengths and limitations. These methodologies are evaluated through various numerical experiments, encompassing diverse scenarios that reflect real-world complexities. A suite of performance metrics is employed to assess the efficacy of these methods. These metrics collectively provide a nuanced understanding of the methods' ability to capture essential features and delineate complex conductivity patterns. One novel feature of the study is the incorporation of variable conductivity scenarios, introducing a level of heterogeneity that mimics textured inclusions. This departure from uniform conductivity assumptions mimics realistic scenarios where tissues or materials exhibit spatially varying electrical properties. Exploring how each method responds to such variable conductivity scenarios opens avenues for understanding their robustness and adaptability.
</details>
<details>
<summary>摘要</summary>
电气阻抗成像技术（EIT）是一种 poderosa 的成像技术，广泛应用于医学诊断、工业监测和环境研究等领域。EIT逆问题是关于从物体边缘测量获得内部电导分布的问题，它是非常不稳定的，需要高级计算方法以实现准确的成像重建。过去几年，驱动了由创新的数学基础和深度学习的技术进步，这种技术的研究受到了广泛关注。本文探讨了解决EIT逆问题的方法，特别是将现代深度学习基础与传统的数学基础相结合的方法。本文选择了四种现代深度学习算法进行严格的分析和评估，利用深度神经网络的表达能力来重建复杂的电导分布。同时，本文还介绍了两种传统的数学基础方法，包括基于数学形式和正则化技术的方法，并评估了它们的优缺点。这些方法在多种数字实验中被评估，涵盖了实际中的复杂场景。为评估这些方法的效果，本文采用了多种效果指标，这些指标共同提供了对方法的准确性和复杂电导分布的能力的全面了解。本文的一个新特点是对不同电导性场景进行变量电导分布的研究，这种假设与实际中的细胞或材料表现相符。通过对每种方法的响应来评估它们的Robustness和适应性。
</details></li>
</ul>
<hr>
<h2 id="Setting-the-Trap-Capturing-and-Defeating-Backdoors-in-Pretrained-Language-Models-through-Honeypots"><a href="#Setting-the-Trap-Capturing-and-Defeating-Backdoors-in-Pretrained-Language-Models-through-Honeypots" class="headerlink" title="Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots"></a>Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18633">http://arxiv.org/abs/2310.18633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruixiang Tang, Jiayi Yuan, Yiming Li, Zirui Liu, Rui Chen, Xia Hu</li>
<li>for: 防止语言模型中的后门攻击</li>
<li>methods:  integrate a honeypot module into the original PLM, impose penalties on the information acquired by the honeypot module</li>
<li>results: 减少了10%~40%的攻击成功率，比前一代方法更有效和可靠<details>
<summary>Abstract</summary>
In the field of natural language processing, the prevalent approach involves fine-tuning pretrained language models (PLMs) using local samples. Recent research has exposed the susceptibility of PLMs to backdoor attacks, wherein the adversaries can embed malicious prediction behaviors by manipulating a few training samples. In this study, our objective is to develop a backdoor-resistant tuning procedure that yields a backdoor-free model, no matter whether the fine-tuning dataset contains poisoned samples. To this end, we propose and integrate a honeypot module into the original PLM, specifically designed to absorb backdoor information exclusively. Our design is motivated by the observation that lower-layer representations in PLMs carry sufficient backdoor features while carrying minimal information about the original tasks. Consequently, we can impose penalties on the information acquired by the honeypot module to inhibit backdoor creation during the fine-tuning process of the stem network. Comprehensive experiments conducted on benchmark datasets substantiate the effectiveness and robustness of our defensive strategy. Notably, these results indicate a substantial reduction in the attack success rate ranging from 10\% to 40\% when compared to prior state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
在自然语言处理领域，普遍的方法是细化预训练语言模型（PLM）使用本地样本。 recent research has exposed the vulnerability of PLMs to backdoor attacks, where adversaries can embed malicious prediction behaviors by manipulating a few training samples. In this study, our objective is to develop a backdoor-resistant tuning procedure that yields a backdoor-free model, regardless of whether the fine-tuning dataset contains poisoned samples. To this end, we propose and integrate a honeypot module into the original PLM, specifically designed to absorb backdoor information exclusively. Our design is motivated by the observation that lower-layer representations in PLMs carry sufficient backdoor features while carrying minimal information about the original tasks. Therefore, we can impose penalties on the information acquired by the honeypot module to inhibit backdoor creation during the fine-tuning process of the stem network. Comprehensive experiments conducted on benchmark datasets substantiate the effectiveness and robustness of our defensive strategy. Notably, these results indicate a substantial reduction in the attack success rate ranging from 10% to 40% when compared to prior state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Benchmark-Generation-Framework-with-Customizable-Distortions-for-Image-Classifier-Robustness"><a href="#Benchmark-Generation-Framework-with-Customizable-Distortions-for-Image-Classifier-Robustness" class="headerlink" title="Benchmark Generation Framework with Customizable Distortions for Image Classifier Robustness"></a>Benchmark Generation Framework with Customizable Distortions for Image Classifier Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18626">http://arxiv.org/abs/2310.18626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Zachariah Carmichael, Vineet Gundecha, Sahand Ghorbanpour, Ricardo Luna, Gutierrez Antonio Guillen, Avisek Naug</li>
<li>for: 这个 paper 是为了提供一种生成攻击测试集的框架，以评估图像分类模型的可靠性。</li>
<li>methods: 这个框架使用了一种基于模型学习的强化学习算法，可以根据用户的需求选择合适的扰动种类，并生成多种扰动水平的测试集，以评估不同的图像分类模型的可靠性。</li>
<li>results: 这个框架可以生成高效和可转移的攻击样本，可以让不同的图像分类模型失败，包括 ResNet-50、Inception-V3 和 VGG-16 等模型。这些攻击样本可以在不受束缚的情况下生成，而不需要引入不自然的artifacts或颜色泄漏。<details>
<summary>Abstract</summary>
We present a novel framework for generating adversarial benchmarks to evaluate the robustness of image classification models. Our framework allows users to customize the types of distortions to be optimally applied to images, which helps address the specific distortions relevant to their deployment. The benchmark can generate datasets at various distortion levels to assess the robustness of different image classifiers. Our results show that the adversarial samples generated by our framework with any of the image classification models, like ResNet-50, Inception-V3, and VGG-16, are effective and transferable to other models causing them to fail. These failures happen even when these models are adversarially retrained using state-of-the-art techniques, demonstrating the generalizability of our adversarial samples. We achieve competitive performance in terms of net $L_2$ distortion compared to state-of-the-art benchmark techniques on CIFAR-10 and ImageNet; however, we demonstrate our framework achieves such results with simple distortions like Gaussian noise without introducing unnatural artifacts or color bleeds. This is made possible by a model-based reinforcement learning (RL) agent and a technique that reduces a deep tree search of the image for model sensitivity to perturbations, to a one-level analysis and action. The flexibility of choosing distortions and setting classification probability thresholds for multiple classes makes our framework suitable for algorithmic audits.
</details>
<details>
<summary>摘要</summary>
我团队提出了一种新的框架，用于生成对图像分类模型的Robustness进行评估。我们的框架允许用户自定义图像上应用的最佳噪声类型，以适应其特定的部署环境。这个框架可以生成各种噪声水平的数据集，以评估不同的图像分类器的Robustness。我们的结果显示，我们的框架生成的对图像分类模型的攻击样本，包括ResNet-50、Inception-V3和VGG-16等模型，都是有效的和可传递的。这些攻击样本会让这些模型失败，即使这些模型通过了最先进的防御技术进行适应。我们的框架在CIFAR-10和ImageNet上达到了与state-of-the-art的$L_2$损失相同的竞争性，但是我们的框架可以使用简单的噪声（如 Gaussian 噪声）而不需要引入不自然的artifacts或颜色泄漏。这是由一个基于模型的强化学习（RL） Agent和一种减少图像深度搜索的技术来实现的。我们的框架可以根据用户选择的噪声类型和多个类别的分类概率来进行自定义。这使得我们的框架适用于算法审核。
</details></li>
</ul>
<hr>
<h2 id="Arbitrarily-Scalable-Environment-Generators-via-Neural-Cellular-Automata"><a href="#Arbitrarily-Scalable-Environment-Generators-via-Neural-Cellular-Automata" class="headerlink" title="Arbitrarily Scalable Environment Generators via Neural Cellular Automata"></a>Arbitrarily Scalable Environment Generators via Neural Cellular Automata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18622">http://arxiv.org/abs/2310.18622</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lunjohnzhang/warehouse_env_gen_nca_public">https://github.com/lunjohnzhang/warehouse_env_gen_nca_public</a></li>
<li>paper_authors: Yulun Zhang, Matthew C. Fontaine, Varun Bhatt, Stefanos Nikolaidis, Jiaoyang Li</li>
<li>for: 提高多机器人系统的吞吐量（improve the throughput of multi-robot systems）</li>
<li>methods: 使用质量多样性（Quality Diversity）算法优化环境生成器（Neural Cellular Automata environment generators）</li>
<li>results: 可以生成无限大的环境，并且维持环境中的准备规划（consistent, regularized patterns），提高多机器人系统的可扩展性和可靠性（improve the scalability and reliability of multi-robot systems）<details>
<summary>Abstract</summary>
We study the problem of generating arbitrarily large environments to improve the throughput of multi-robot systems. Prior work proposes Quality Diversity (QD) algorithms as an effective method for optimizing the environments of automated warehouses. However, these approaches optimize only relatively small environments, falling short when it comes to replicating real-world warehouse sizes. The challenge arises from the exponential increase in the search space as the environment size increases. Additionally, the previous methods have only been tested with up to 350 robots in simulations, while practical warehouses could host thousands of robots. In this paper, instead of optimizing environments, we propose to optimize Neural Cellular Automata (NCA) environment generators via QD algorithms. We train a collection of NCA generators with QD algorithms in small environments and then generate arbitrarily large environments from the generators at test time. We show that NCA environment generators maintain consistent, regularized patterns regardless of environment size, significantly enhancing the scalability of multi-robot systems in two different domains with up to 2,350 robots. Additionally, we demonstrate that our method scales a single-agent reinforcement learning policy to arbitrarily large environments with similar patterns. We include the source code at \url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public}.
</details>
<details>
<summary>摘要</summary>
我们研究多机器人系统中的环境生成问题，以提高其吞吐量。先前的方法提出了质量多样性（QD）算法来优化自动化仓储的环境，但这些方法仅能优化较小的环境，无法模拟现实世界仓储的规模。这问题的挑战在于搜索空间的对数增长，以及先前的方法仅在350台机器人的 simulations 中进行过测试。在这篇文章中，我们不是直接优化环境，而是透过 QD 算法来优化神经细胞自动机（NCA）环境生成器。我们在小型环境中训练了一个 NCA 环境生成器，然后在测试时使用这个生成器来生成任意大的环境。我们证明了 NCA 环境生成器在不同领域中能够维持一致的、规律的模式，很大地提高了多机器人系统的扩展性，并且还能将单机器人学习策略扩展到任意大的环境中。我们在这篇文章中还提供了源代码，可以在 \url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public} 中获取。
</details></li>
</ul>
<hr>
<h2 id="Dense-Retrieval-as-Indirect-Supervision-for-Large-space-Decision-Making"><a href="#Dense-Retrieval-as-Indirect-Supervision-for-Large-space-Decision-Making" class="headerlink" title="Dense Retrieval as Indirect Supervision for Large-space Decision Making"></a>Dense Retrieval as Indirect Supervision for Large-space Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18619">http://arxiv.org/abs/2310.18619</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luka-group/ddr">https://github.com/luka-group/ddr</a></li>
<li>paper_authors: Nan Xu, Fei Wang, Mingtao Dong, Muhao Chen</li>
<li>for: 提高大量分类任务的准确率和泛化能力。</li>
<li>methods: 使用 dense retrieval 方法，将大量分类任务 reformulate 为学习 retrieve 任务，并使用 dual-encoder 架构来学习预测。</li>
<li>results: 在多个极端多类分类任务和少量数据情况下，DDR 可以大幅提高预测精度和泛化能力，至少比基eline 27.54%，F1 分数提高 1.17%，并在三个少量意图分类任务中平均提高了1.26%的准确率。<details>
<summary>Abstract</summary>
Many discriminative natural language understanding (NLU) tasks have large label spaces. Learning such a process of large-space decision making is particularly challenging due to the lack of training instances per label and the difficulty of selection among many fine-grained labels. Inspired by dense retrieval methods for passage finding in open-domain QA, we propose a reformulation of large-space discriminative NLU tasks as a learning-to-retrieve task, leading to a novel solution named Dense Decision Retrieval (DDR ). Instead of predicting fine-grained decisions as logits, DDR adopts a dual-encoder architecture that learns to predict by retrieving from a decision thesaurus. This approach not only leverages rich indirect supervision signals from easy-to-consume learning resources for dense retrieval, it also leads to enhanced prediction generalizability with a semantically meaningful representation of the large decision space. When evaluated on tasks with decision spaces ranging from hundreds to hundred-thousand scales, DDR outperforms strong baselines greatly by 27.54% in P@1 on two extreme multi-label classification tasks, 1.17% in F1 score ultra-fine entity typing, and 1.26% in accuracy on three few-shot intent classification tasks on average. Code and resources are available at https://github.com/luka-group/DDR
</details>
<details>
<summary>摘要</summary>
很多推理性自然语言理解（NLU）任务有很大的标签空间。学习这种大空间决策的过程特别是有很多标签的选择和训练实例的缺乏。 inspirited by dense retrieval方法用于在开放领域Question Answering中找到段落，我们提出了对大空间推理性NLU任务的重新表述，导致一种新的解决方案 называ为粘性决策检索（DDR）。而不是预测细化的决策，DDR采用了双核生成器体系，学习通过检索决策词典来预测。这种方法不仅利用了易于采用的学习资源的丰富间接监督信号，还导致了增强的预测泛化性和semantically meaningful的决策空间表示。当评估在标签空间范围从百到千千的任务上，DDR大幅超越了强基eline的表现，平均提高了27.54%的P@1、1.17%的F1分数和1.26%的准确率。代码和资源可以在https://github.com/luka-group/DDR上找到。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Mutual-Information-Analysis-Towards-Multi-view-Clustering-in-The-Wild"><a href="#Hierarchical-Mutual-Information-Analysis-Towards-Multi-view-Clustering-in-The-Wild" class="headerlink" title="Hierarchical Mutual Information Analysis: Towards Multi-view Clustering in The Wild"></a>Hierarchical Mutual Information Analysis: Towards Multi-view Clustering in The Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18614">http://arxiv.org/abs/2310.18614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiatai Wang, Zhiwei Xu, Xuewen Yang, Xin Wang</li>
<li>for: This paper focuses on addressing the challenges of missing and unaligned data in multi-view clustering, which is a common problem in practical computer vision applications.</li>
<li>methods: The proposed method uses a deep framework that combines data recovery and alignment in a hierarchically consistent way, leveraging dual prediction and contrastive reconstruction to achieve instance-level and class-level alignment.</li>
<li>results: The proposed method significantly outperforms state-of-the-art methods on multi-view clustering even in the cases of view missing and unalignment, as demonstrated by extensive experiments on public datasets.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文针对多视图 clustering 中缺失和不一致的数据问题进行解决，这是实际计算机视觉应用中的常见问题。</li>
<li>methods: 提议的方法使用深度框架，将数据恢复和对齐 fusion 在层次结构上进行一致性验证，通过 dual prediction 和对比重建来实现实例级别和类别级别的对齐。</li>
<li>results: 提议的方法在实际公共数据集上进行了广泛的实验，与现有方法进行比较，得到了显著的性能提升，即使在缺失和不一致的情况下也能够达到显著的效果。<details>
<summary>Abstract</summary>
Multi-view clustering (MVC) can explore common semantics from unsupervised views generated by different sources, and thus has been extensively used in applications of practical computer vision. Due to the spatio-temporal asynchronism, multi-view data often suffer from view missing and are unaligned in real-world applications, which makes it difficult to learn consistent representations. To address the above issues, this work proposes a deep MVC framework where data recovery and alignment are fused in a hierarchically consistent way to maximize the mutual information among different views and ensure the consistency of their latent spaces. More specifically, we first leverage dual prediction to fill in missing views while achieving the instance-level alignment, and then take the contrastive reconstruction to achieve the class-level alignment. To the best of our knowledge, this could be the first successful attempt to handle the missing and unaligned data problem separately with different learning paradigms. Extensive experiments on public datasets demonstrate that our method significantly outperforms state-of-the-art methods on multi-view clustering even in the cases of view missing and unalignment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Embedding-in-Recommender-Systems-A-Survey"><a href="#Embedding-in-Recommender-Systems-A-Survey" class="headerlink" title="Embedding in Recommender Systems: A Survey"></a>Embedding in Recommender Systems: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18608">http://arxiv.org/abs/2310.18608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyu Zhao, Maolin Wang, Xinjian Zhao, Jiansheng Li, Shucheng Zhou, Dawei Yin, Qing Li, Jiliang Tang, Ruocheng Guo</li>
<li>for: 本文提供了一个概述近期 embedding 技术在推荐系统中的研究进展的survey。</li>
<li>methods: 本文覆盖了多种 embedding 方法，包括 collaborative filtering、自监学习和图基于的技术。</li>
<li>results: 本文提出了一些创新的方法来提高推荐系统的性能和计算复杂性，包括 AutoML、哈希技术和量化技术。<details>
<summary>Abstract</summary>
Recommender systems have become an essential component of many online platforms, providing personalized recommendations to users. A crucial aspect is embedding techniques that coverts the high-dimensional discrete features, such as user and item IDs, into low-dimensional continuous vectors and can enhance the recommendation performance. Applying embedding techniques captures complex entity relationships and has spurred substantial research. In this survey, we provide an overview of the recent literature on embedding techniques in recommender systems. This survey covers embedding methods like collaborative filtering, self-supervised learning, and graph-based techniques. Collaborative filtering generates embeddings capturing user-item preferences, excelling in sparse data. Self-supervised methods leverage contrastive or generative learning for various tasks. Graph-based techniques like node2vec exploit complex relationships in network-rich environments. Addressing the scalability challenges inherent to embedding methods, our survey delves into innovative directions within the field of recommendation systems. These directions aim to enhance performance and reduce computational complexity, paving the way for improved recommender systems. Among these innovative approaches, we will introduce Auto Machine Learning (AutoML), hash techniques, and quantization techniques in this survey. We discuss various architectures and techniques and highlight the challenges and future directions in these aspects. This survey aims to provide a comprehensive overview of the state-of-the-art in this rapidly evolving field and serve as a useful resource for researchers and practitioners working in the area of recommender systems.
</details>
<details>
<summary>摘要</summary>
现在许多在线平台上都有推荐系统，为用户提供个性化的推荐。一个重要的方面是嵌入技术，将用户和 Item ID 等高维离散特征转换成低维连续向量，以提高推荐性能。采用嵌入技术可以捕捉复杂的实体关系，并促进了大量研究。在这篇报告中，我们提供了现代推荐系统中嵌入技术的最新Literature综述。这篇报告覆盖了协同练习、自然学习和图像基本技术等嵌入方法。协同练习生成 embeddings，捕捉用户和 Item 的偏好，在缺乏数据时表现出色。自然学习使用对比或生成学习来实现多种任务。图像基本技术如 node2vec 利用网络中的复杂关系。为了解决嵌入方法中的扩展性问题，我们在推荐系统领域内进行了创新的方向，以提高性能并降低计算复杂性，为未来的推荐系统铺平道路。这些创新方向包括自动机器学习（AutoML）、哈希技术和量化技术。我们讨论了不同的架构和技术，并高亮了这些方面中的挑战和未来方向。该报告的目的是为研究人员和实践者提供一份现代化的推荐系统领域的 estado-da-arte 资源，以便他们在这一领域进行更好的研究和实践。
</details></li>
</ul>
<hr>
<h2 id="MILDSum-A-Novel-Benchmark-Dataset-for-Multilingual-Summarization-of-Indian-Legal-Case-Judgments"><a href="#MILDSum-A-Novel-Benchmark-Dataset-for-Multilingual-Summarization-of-Indian-Legal-Case-Judgments" class="headerlink" title="MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments"></a>MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18600">http://arxiv.org/abs/2310.18600</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/law-ai/mildsum">https://github.com/law-ai/mildsum</a></li>
<li>paper_authors: Debtanu Datta, Shubham Soni, Rajdeep Mukherjee, Saptarshi Ghosh</li>
<li>for: 本研究旨在提供英文法律文件的跨语言概要，以便在印度的法律系统中提供更加公平的 justice。</li>
<li>methods: 该研究使用了多种多样的概要方法，以评估其在法律领域的性能。</li>
<li>results: 研究发现，跨语言概要在法律领域的应用仍然需要进一步的研究，以提高概要的准确性和可读性。<details>
<summary>Abstract</summary>
Automatic summarization of legal case judgments is a practically important problem that has attracted substantial research efforts in many countries. In the context of the Indian judiciary, there is an additional complexity -- Indian legal case judgments are mostly written in complex English, but a significant portion of India's population lacks command of the English language. Hence, it is crucial to summarize the legal documents in Indian languages to ensure equitable access to justice. While prior research primarily focuses on summarizing legal case judgments in their source languages, this study presents a pioneering effort toward cross-lingual summarization of English legal documents into Hindi, the most frequently spoken Indian language. We construct the first high-quality legal corpus comprising of 3,122 case judgments from prominent Indian courts in English, along with their summaries in both English and Hindi, drafted by legal practitioners. We benchmark the performance of several diverse summarization approaches on our corpus and demonstrate the need for further research in cross-lingual summarization in the legal domain.
</details>
<details>
<summary>摘要</summary>
自动摘要法律案例判决是一个实际重要的问题，在多个国家的研究中都获得了substantial的投入。在印度法院的背景下，有一个额外的复杂性---印度的法律案例判决大多是用复杂的英语写成，但印度大部分人口不会英语。因此，实际需要摘要法律文件的印地语言，以确保公平的法律服务。在先前的研究中，主要对源语言进行摘要，但这项研究则对英文法律文件进行标准化，并将其摘要为印地语言。我们建立了首个高品质的法律档案，包括3,122个案例判决由印度主要法院提供，以及其摘要在英语和印地语言中，由法律专业人员撰写。我们在我们的档案上评估了多种多元摘要方法的表现，并证明了在法律领域中的标准化摘要仍然需要进一步的研究。
</details></li>
</ul>
<hr>
<h2 id="Using-Early-Readouts-to-Mediate-Featural-Bias-in-Distillation"><a href="#Using-Early-Readouts-to-Mediate-Featural-Bias-in-Distillation" class="headerlink" title="Using Early Readouts to Mediate Featural Bias in Distillation"></a>Using Early Readouts to Mediate Featural Bias in Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18590">http://arxiv.org/abs/2310.18590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Tiwari, Durga Sivasubramanian, Anmol Mekala, Ganesh Ramakrishnan, Pradeep Shenoy</li>
<li>for: 本研究旨在改进在真实世界的超级vised学习任务中深度网络学习的潜在损害，特别是在托管学习中，学生模型可能比对应教师模型更具有较低的表达能力。</li>
<li>methods: 我们提出了一种新的早期读取机制，通过使用早期网络层的表示来预测标签。我们发现这些早期读outs自动地标识了问题实例或组，具体来说是具有高度信任但 incorrect 预测的情况。</li>
<li>results: 我们显示了这种早期读outs可以自动地为实例层次提供较好的预测信号，可以用于修改分配损害loss的学习过程中。我们在多个benchmark数据集上显示了提高group fairness度量和学生模型的总准确率。此外，我们还提供了次要分析，以帮助理解超级vised学习中特征学习的角色。<details>
<summary>Abstract</summary>
Deep networks tend to learn spurious feature-label correlations in real-world supervised learning tasks. This vulnerability is aggravated in distillation, where a student model may have lesser representational capacity than the corresponding teacher model. Often, knowledge of specific spurious correlations is used to reweight instances & rebalance the learning process. We propose a novel early readout mechanism whereby we attempt to predict the label using representations from earlier network layers. We show that these early readouts automatically identify problem instances or groups in the form of confident, incorrect predictions. Leveraging these signals to modulate the distillation loss on an instance level allows us to substantially improve not only group fairness measures across benchmark datasets, but also overall accuracy of the student model. We also provide secondary analyses that bring insight into the role of feature learning in supervision and distillation.
</details>
<details>
<summary>摘要</summary>
深度网络通常在实际supervised learning任务中学习假的特征-标签相关性。这种漏洞在精神投射中更加加剧，因为学生模型可能比对应的教师模型有更差的表达能力。经常使用特定假相关性的知识来重新权衡实例和重新调整学习过程。我们提出了一种新的早期读取机制，尝试使用早期网络层的表示来预测标签。我们发现这些早期读outs自然地标识问题实例或组，即高信息准确预测。利用这些信号来修改分配损失的实例级别可以大幅提高 benchmark数据集上的组准则性和学生模型的总准确率。我们还提供了次要分析，探讨特征学习在监督和精神投射中的角色。
</details></li>
</ul>
<hr>
<h2 id="Visual-Explanations-via-Iterated-Integrated-Attributions"><a href="#Visual-Explanations-via-Iterated-Integrated-Attributions" class="headerlink" title="Visual Explanations via Iterated Integrated Attributions"></a>Visual Explanations via Iterated Integrated Attributions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18585">http://arxiv.org/abs/2310.18585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oren Barkan, Yehonatan Elisha, Yuval Asher, Amit Eshel, Noam Koenigstein</li>
<li>for: 这篇论文用于解释视觉模型的预测结果。</li>
<li>methods: 该论文使用迭代 интеGRATED ATTRIBUTES（IIA）方法，通过迭代 интеGRATE 输入图像、模型内部表示和导数，生成准确和专注的解释地图。</li>
<li>results: 论文的实验结果表明，IIA方法可以准确地解释视觉模型的预测结果，并且在不同任务、数据集和网络架构上表现出色，超过了其他当前领先的解释技术。<details>
<summary>Abstract</summary>
We introduce Iterated Integrated Attributions (IIA) - a generic method for explaining the predictions of vision models. IIA employs iterative integration across the input image, the internal representations generated by the model, and their gradients, yielding precise and focused explanation maps. We demonstrate the effectiveness of IIA through comprehensive evaluations across various tasks, datasets, and network architectures. Our results showcase that IIA produces accurate explanation maps, outperforming other state-of-the-art explanation techniques.
</details>
<details>
<summary>摘要</summary>
我们介绍Iterated Integrated Attributions（IIA），一种通用的视觉模型预测解释方法。IIA通过迭代 интеграpection 输入图像、模型内部表示和其导数，生成精细和专注的解释地图。我们通过多种任务、数据集和网络架构的全面评估，证明IIA可以生成准确的解释地图，超越其他当前领域的解释技术。
</details></li>
</ul>
<hr>
<h2 id="Breaking-the-Trilemma-of-Privacy-Utility-Efficiency-via-Controllable-Machine-Unlearning"><a href="#Breaking-the-Trilemma-of-Privacy-Utility-Efficiency-via-Controllable-Machine-Unlearning" class="headerlink" title="Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable Machine Unlearning"></a>Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable Machine Unlearning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18574">http://arxiv.org/abs/2310.18574</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guangyaodou/conmu">https://github.com/guangyaodou/conmu</a></li>
<li>paper_authors: Zheyuan Liu, Guangyao Dou, Yijun Tian, Chunhui Zhang, Eli Chien, Ziwei Zhu</li>
<li>for: 这篇论文的主要目标是解决机器学习模型中的数据隐私问题，具体来说是通过控制 Privacy-Utility-Efficiency 三方面的质量来实现机器学习模型的卸载。</li>
<li>methods: 这篇论文提出了一种名为 Controllable Machine Unlearning（ConMU）的新框架，该框架包括三个基本模块：重要数据选择模块、进程 Gaussian 机制模块和卸载代理模块。这些模块协同实现了控制 Privacy-Utility-Efficiency 三方面的质量。</li>
<li>results: 对于各种标准数据集的实验表明，ConMU 控制机制具有优于现有卸载方法的灵活性和可控性，并且可以充分考虑不同的实际隐私法规。<details>
<summary>Abstract</summary>
Machine Unlearning (MU) algorithms have become increasingly critical due to the imperative adherence to data privacy regulations. The primary objective of MU is to erase the influence of specific data samples on a given model without the need to retrain it from scratch. Accordingly, existing methods focus on maximizing user privacy protection. However, there are different degrees of privacy regulations for each real-world web-based application. Exploring the full spectrum of trade-offs between privacy, model utility, and runtime efficiency is critical for practical unlearning scenarios. Furthermore, designing the MU algorithm with simple control of the aforementioned trade-off is desirable but challenging due to the inherent complex interaction. To address the challenges, we present Controllable Machine Unlearning (ConMU), a novel framework designed to facilitate the calibration of MU. The ConMU framework contains three integral modules: an important data selection module that reconciles the runtime efficiency and model generalization, a progressive Gaussian mechanism module that balances privacy and model generalization, and an unlearning proxy that controls the trade-offs between privacy and runtime efficiency. Comprehensive experiments on various benchmark datasets have demonstrated the robust adaptability of our control mechanism and its superiority over established unlearning methods. ConMU explores the full spectrum of the Privacy-Utility-Efficiency trade-off and allows practitioners to account for different real-world regulations. Source code available at: https://github.com/guangyaodou/ConMU.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-General-Framework-for-Robust-G-Invariance-in-G-Equivariant-Networks"><a href="#A-General-Framework-for-Robust-G-Invariance-in-G-Equivariant-Networks" class="headerlink" title="A General Framework for Robust G-Invariance in G-Equivariant Networks"></a>A General Framework for Robust G-Invariance in G-Equivariant Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18564">http://arxiv.org/abs/2310.18564</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gtc-invariance/gtc-invariance">https://github.com/gtc-invariance/gtc-invariance</a></li>
<li>paper_authors: Sophia Sanborn, Nina Miolane</li>
<li>For: The paper proposes a method for achieving robust group-invariance in group-equivariant convolutional neural networks (G-CNNs) called the G-triple-correlation (G-TC) layer.* Methods: The G-TC layer leverages the theory of the triple-correlation on groups, which is a unique, lowest-degree polynomial invariant map that is also complete.* Results: The G-TC layer yields measurable improvements in classification accuracy over standard Max G-Pooling in G-CNN architectures, and is resistant to invariance-based adversarial attacks. The method is demonstrated on several groups acting on both $\mathbb{R}^2$ and $\mathbb{R}^3$ on the G-MNIST and G-ModelNet10 datasets.Here is the same information in Simplified Chinese text:* For: 本文提出了一种方法来实现robust group-invariance在群equivariant convolutional neural networks（G-CNNs）中，称为G-triple-correlation（G-TC）层。* Methods: G-TC层利用群中的 triple-correlation理论，这是一个唯一的、最低度的多项式恒等函数，同时也是完整的。* Results: G-TC层在G-CNN架构中提供了较好的分类精度，并且对 invariant-based adversarial attacks具有强大的Robustness。此方法在几个群中对 $\mathbb{R}^2$ 和 $\mathbb{R}^3$ 上的 G-MNIST 和 G-ModelNet10 数据集进行了证明。<details>
<summary>Abstract</summary>
We introduce a general method for achieving robust group-invariance in group-equivariant convolutional neural networks ($G$-CNNs), which we call the $G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the triple-correlation on groups, which is the unique, lowest-degree polynomial invariant map that is also complete. Many commonly used invariant maps - such as the max - are incomplete: they remove both group and signal structure. A complete invariant, by contrast, removes only the variation due to the actions of the group, while preserving all information about the structure of the signal. The completeness of the triple correlation endows the $G$-TC layer with strong robustness, which can be observed in its resistance to invariance-based adversarial attacks. In addition, we observe that it yields measurable improvements in classification accuracy over standard Max $G$-Pooling in $G$-CNN architectures. We provide a general and efficient implementation of the method for any discretized group, which requires only a table defining the group's product structure. We demonstrate the benefits of this method for $G$-CNNs defined on both commutative and non-commutative groups - $SO(2)$, $O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$, chiral octahedral $O$ and full octahedral $O_h$ groups) - acting on $\mathbb{R}^2$ and $\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10 datasets.
</details>
<details>
<summary>摘要</summary>
我们介绍了一个通用的方法，可以在群equivariant convolutional neural networks（$G$-CNNs）中实现强健的群对称性，我们称之为$G$-三重相关（$G$-TC）层。这种方法利用群论中的三重相関，这是唯一的、最低阶的多项式群对称函数，同时也是完备的。许多常用的对称函数，如最大值，都是不完备的：它们会消除群和信号结构中的一部分。一个完备的对称函数，则会消除群的行动所导致的变化，保留信号的结构信息。三重相关的完备性使得$G$-TC层具有强大的免疫力，可以通过观察它对抗对称基于的攻击而证明。此外，我们发现这种方法可以提高$G$-CNN的分类精度，比标准的最大值$G$-Pooling更好。我们提供了一个通用且有效的实现方法，这需要一个表格定义了群的产生结构。我们在$G$-CNNs中使用了不同的域群，包括$SO(2)$, $O(2)$, $SO(3)$,和$O(3)$（为数为顺序$C8$, $D16$, $O$和$O_h$群），并在$\mathbb{R}^2$和$\mathbb{R}^3$上进行了$G$-MNIST和$G$-ModelNet10数据集上的实验。
</details></li>
</ul>
<hr>
<h2 id="Optimization-Free-Test-Time-Adaptation-for-Cross-Person-Activity-Recognition"><a href="#Optimization-Free-Test-Time-Adaptation-for-Cross-Person-Activity-Recognition" class="headerlink" title="Optimization-Free Test-Time Adaptation for Cross-Person Activity Recognition"></a>Optimization-Free Test-Time Adaptation for Cross-Person Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18562">http://arxiv.org/abs/2310.18562</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Claydon-Wang/OFTTA">https://github.com/Claydon-Wang/OFTTA</a></li>
<li>paper_authors: Shuoyuan Wang, Jindong Wang, HuaJun Xi, Bob Zhang, Lei Zhang, Hongxin Wei</li>
<li>for: 这个论文主要针对的是人体动作识别（HAR）模型在实际应用中的性能降低问题，以及如何通过测试流式进行时间适应（TTA）来解决这个问题。</li>
<li>methods: 这篇论文提出了一种不需要优化的测试时适应（OFTTA）框架，用于抗预测域变化和实时适应。OFTTA使用了快速的测试时批处理（EDTN）来取代批处理（CBN）层，并对分类器进行了距离计算和支持集维护。</li>
<li>results: 对于三个公共的人体动作识别（HAR）数据集和两种不同的TTA设置，实验结果表明，OFTTA可以与现有的TTA方法进行比较，在分类性能和计算效率两个方面均有优异表现。此外，我们还验证了OFTTA在边缘设备上的可行性，表明可能的部署在实际应用中。<details>
<summary>Abstract</summary>
Human Activity Recognition (HAR) models often suffer from performance degradation in real-world applications due to distribution shifts in activity patterns across individuals. Test-Time Adaptation (TTA) is an emerging learning paradigm that aims to utilize the test stream to adjust predictions in real-time inference, which has not been explored in HAR before. However, the high computational cost of optimization-based TTA algorithms makes it intractable to run on resource-constrained edge devices. In this paper, we propose an Optimization-Free Test-Time Adaptation (OFTTA) framework for sensor-based HAR. OFTTA adjusts the feature extractor and linear classifier simultaneously in an optimization-free manner. For the feature extractor, we propose Exponential DecayTest-time Normalization (EDTN) to replace the conventional batch normalization (CBN) layers. EDTN combines CBN and Test-time batch Normalization (TBN) to extract reliable features against domain shifts with TBN's influence decreasing exponentially in deeper layers. For the classifier, we adjust the prediction by computing the distance between the feature and the prototype, which is calculated by a maintained support set. In addition, the update of the support set is based on the pseudo label, which can benefit from reliable features extracted by EDTN. Extensive experiments on three public cross-person HAR datasets and two different TTA settings demonstrate that OFTTA outperforms the state-of-the-art TTA approaches in both classification performance and computational efficiency. Finally, we verify the superiority of our proposed OFTTA on edge devices, indicating possible deployment in real applications. Our code is available at \href{https://github.com/Claydon-Wang/OFTTA}{this https URL}.
</details>
<details>
<summary>摘要</summary>
人体活动识别（HAR）模型经常在实际应用中受到分布偏移的影响，导致性能下降。测试时适应（TTA）是一种新趋势的学习方法，它在实时推断中使用测试流来调整预测，在HAR中尚未得到探索。然而，优化基本的TTA算法的计算成本过高，使其无法在有限的边缘设备上进行实时推断。在这篇论文中，我们提出了一种不需要优化的测试时适应（OFTTA）框架，用于感知器基本HAR。OFTTA同时调整特征提取器和线性分类器。特征提取器方面，我们提出了对域偏移的 exponential decay test-time normalization（EDTN），以取代传统的批量normalization（CBN）层。EDTN将CBN和测试时批量normalization（TBN）相结合，以提取可靠的特征对域偏移。分类器方面，我们通过计算特征和拟标的距离，来更新支持集和pseudo标签。此外，更新支持集的方法基于pseudo标签，可以利用EDTN提取的可靠特征。我们对三个公共跨人HAR数据集和两种不同的TTA设置进行了广泛的实验，结果表明OFTTA在分类性能和计算效率两个方面都超过了当前TTA方法。最后，我们验证了我们提出的OFTTA在边缘设备上的可部署性， indicating possible deployment in real applications.我们的代码可以在\href{https://github.com/Claydon-Wang/OFTTA}{这个https URL}上找到。
</details></li>
</ul>
<hr>
<h2 id="Deep-Intrinsic-Decomposition-with-Adversarial-Learning-for-Hyperspectral-Image-Classification"><a href="#Deep-Intrinsic-Decomposition-with-Adversarial-Learning-for-Hyperspectral-Image-Classification" class="headerlink" title="Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral Image Classification"></a>Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18549">http://arxiv.org/abs/2310.18549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqiang Gong, Xian Zhou, Wen Yao</li>
<li>for: 提高干扰因素影响的高spectral图像分类性能</li>
<li>methods: 利用深度学习的强化学习方法，提取环境因素相关的特征和分类特征，并在激烈学习环境下进行对环境和分类的共同学习</li>
<li>results: 对三个常用的实际数据集进行了实验，并与其他比较方法进行了比较，结果表明提出的方法可以提高高spectral图像分类性能。<details>
<summary>Abstract</summary>
Convolutional neural networks (CNNs) have been demonstrated their powerful ability to extract discriminative features for hyperspectral image classification. However, general deep learning methods for CNNs ignore the influence of complex environmental factor which enlarges the intra-class variance and decreases the inter-class variance. This multiplies the difficulty to extract discriminative features. To overcome this problem, this work develops a novel deep intrinsic decomposition with adversarial learning, namely AdverDecom, for hyperspectral image classification to mitigate the negative impact of environmental factors on classification performance. First, we develop a generative network for hyperspectral image (HyperNet) to extract the environmental-related feature and category-related feature from the image. Then, a discriminative network is constructed to distinguish different environmental categories. Finally, a environmental and category joint learning loss is developed for adversarial learning to make the deep model learn discriminative features. Experiments are conducted over three commonly used real-world datasets and the comparison results show the superiority of the proposed method. The implementation of the proposed method and other compared methods could be accessed at https://github.com/shendu-sw/Adversarial Learning Intrinsic Decomposition for the sake of reproducibility.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在多spectral影像分类中表现出了强大的特征提取能力。然而，通用深度学习方法忽略了环境因素的复杂影响，这会增加内类差异和降低对类差异，从而困难提取特征。为解决这个问题，本文提出了一种新的深度内在分解与对抗学习方法，称为AdverDecom，用于多spectral影像分类。首先，我们开发了一个生成网络（HyperNet），用于提取影像中的环境相关特征和类别相关特征。然后，我们构建了一个分类网络，用于分辨不同的环境类别。最后，我们开发了一个环境和类别联合学习损失函数，用于对抗学习，以使深度模型学习特征。我们在三个常用的实际数据集上进行了实验，并比较了我们的方法和其他比较方法的结果，显示了我们的方法的优越性。实现方法和其他比较方法的实现可以通过https://github.com/shendu-sw/Adversarial Learning Intrinsic Decomposition访问，以便重现。
</details></li>
</ul>
<hr>
<h2 id="ReConTab-Regularized-Contrastive-Representation-Learning-for-Tabular-Data"><a href="#ReConTab-Regularized-Contrastive-Representation-Learning-for-Tabular-Data" class="headerlink" title="ReConTab: Regularized Contrastive Representation Learning for Tabular Data"></a>ReConTab: Regularized Contrastive Representation Learning for Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18541">http://arxiv.org/abs/2310.18541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suiyao Chen, Jing Wu, Naira Hovakimyan, Handong Yao</li>
<li>for: 本研究旨在提出一种深度自动表示学习框架，以提高tabular数据中的特征工程和选择过程。</li>
<li>methods: 该框架基于同 Raw Features 的非对称 autoencoder，并采用了正则化技术进行 Raw Feature 选择。同时，框架还应用了对比学习来维护最关键的信息。</li>
<li>results: 实验结果表明，该框架可以在各种实际数据集上提供显著的性能提升，并且可以轻松地与传统方法相结合，如 XGBoost 和 Random Forest。<details>
<summary>Abstract</summary>
Representation learning stands as one of the critical machine learning techniques across various domains. Through the acquisition of high-quality features, pre-trained embeddings significantly reduce input space redundancy, benefiting downstream pattern recognition tasks such as classification, regression, or detection. Nonetheless, in the domain of tabular data, feature engineering and selection still heavily rely on manual intervention, leading to time-consuming processes and necessitating domain expertise. In response to this challenge, we introduce ReConTab, a deep automatic representation learning framework with regularized contrastive learning. Agnostic to any type of modeling task, ReConTab constructs an asymmetric autoencoder based on the same raw features from model inputs, producing low-dimensional representative embeddings. Specifically, regularization techniques are applied for raw feature selection. Meanwhile, ReConTab leverages contrastive learning to distill the most pertinent information for downstream tasks. Experiments conducted on extensive real-world datasets substantiate the framework's capacity to yield substantial and robust performance improvements. Furthermore, we empirically demonstrate that pre-trained embeddings can seamlessly integrate as easily adaptable features, enhancing the performance of various traditional methods such as XGBoost and Random Forest.
</details>
<details>
<summary>摘要</summary>
<<SYS>>机器学习中的表示学习技术在不同领域具有重要的地位。通过获得高质量的特征，预训练的嵌入significantly reducent输入空间的重复性，从而为下游的模式识别任务，如分类、回归或检测提供了明显的性能提升。然而，在标量数据领域，功能工程和选择仍然高度依赖于人工干预，导致时间消耗大、需要域专业知识。为解决这个挑战，我们介绍ReConTab，一种深度自动表示学习框架，通过带有正则化的对比学习来实现。不论任务模型的类型，ReConTab使用同 Raw Features 的同构自动encoder来生成低维表示嵌入。特别是，对 Raw Features 进行正则化处理。同时，ReConTab通过对比学习来筛选最关键的信息，以便下游任务。经验表明，ReConTab在广泛的实际数据集上实现了显著和可靠的性能提升。此外，我们也证明了预训练嵌入可以轻松地适应为多种传统方法，如 XGBoost 和 Random Forest 提高性能。<</SYS>>
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/cs.AI_2023_10_28/" data-id="cloq1wl1c006b7o88gii00lab" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/cs.CL_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T11:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/cs.CL_2023_10_28/">cs.CL - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Translating-away-Translationese-without-Parallel-Data"><a href="#Translating-away-Translationese-without-Parallel-Data" class="headerlink" title="Translating away Translationese without Parallel Data"></a>Translating away Translationese without Parallel Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18830">http://arxiv.org/abs/2310.18830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rricha Jalota, Koel Dutta Chowdhury, Cristina España-Bonet, Josef van Genabith</li>
<li>for: 本研究旨在减少翻译语言的影响，以提高跨语言自然语言处理任务的准确性。</li>
<li>methods: 本研究使用了一种新的翻译风格传递方法，利用了自监督学习方法，并结合了原始语言模型损失和 semantics相似性损失。</li>
<li>results: 研究结果表明，本方法能够减少翻译语言的影响，保持内容完整性和目标风格流畅性。<details>
<summary>Abstract</summary>
Translated texts exhibit systematic linguistic differences compared to original texts in the same language, and these differences are referred to as translationese. Translationese has effects on various cross-lingual natural language processing tasks, potentially leading to biased results. In this paper, we explore a novel approach to reduce translationese in translated texts: translation-based style transfer. As there are no parallel human-translated and original data in the same language, we use a self-supervised approach that can learn from comparable (rather than parallel) mono-lingual original and translated data. However, even this self-supervised approach requires some parallel data for validation. We show how we can eliminate the need for parallel validation data by combining the self-supervised loss with an unsupervised loss. This unsupervised loss leverages the original language model loss over the style-transferred output and a semantic similarity loss between the input and style-transferred output. We evaluate our approach in terms of original vs. translationese binary classification in addition to measuring content preservation and target-style fluency. The results show that our approach is able to reduce translationese classifier accuracy to a level of a random classifier after style transfer while adequately preserving the content and fluency in the target original style.
</details>
<details>
<summary>摘要</summary>
文本翻译后会显示系统性的语言差异，这些差异称为翻译语言（translationese）。这些语言差异会影响跨语言自然语言处理任务的结果，可能导致偏向结果。在这篇论文中，我们探索了一种新的方法来减少翻译语言：翻译样式传递。由于没有同语言的人工翻译和原始数据，我们使用了一种自动学习的方法，可以从相似的原始和翻译数据中学习。然而， même 这种自动学习方法需要一些平行数据来验证。我们可以消除平行验证数据的需求 by combining the self-supervised loss with an unsupervised loss。这种无supervised loss 利用了原始语言模型的损失 sobre la output de estilo transferido y una pérdida de similitud semántica entre la entrada y la output de estilo transferido。我们按照原始vs. 翻译语言二分类、内容保持和目标风格流畅来评估我们的方法。结果表明，我们的方法可以在style transfer后减少翻译语言分类器的准确率到随机分类器的水平，同时保持内容和目标风格的流畅。
</details></li>
</ul>
<hr>
<h2 id="Are-NLP-Models-Good-at-Tracing-Thoughts-An-Overview-of-Narrative-Understanding"><a href="#Are-NLP-Models-Good-at-Tracing-Thoughts-An-Overview-of-Narrative-Understanding" class="headerlink" title="Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding"></a>Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18783">http://arxiv.org/abs/2310.18783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lixing Zhu, Runcong Zhao, Lin Gui, Yulan He</li>
<li>for: 本研究旨在探讨narative理解的应用和挑战，以提高大语言模型（LLM）的 narative comprehension 能力。</li>
<li>methods: 本研究使用了 comprehensive survey 方法，对 narrative understanding 任务进行了全面的检查和分类，并详细介绍了关键特征、定义、分类、相关数据集、训练目标和评价指标。</li>
<li>results: 本研究发现，通过扩展 modularized LLM 的能力，可以解决一些新的 narative understanding 任务。此外，通过将 narative understanding 定义为捕捉作者的想象创作灵感的问题，本研究提出了一新的视角，以增强 narative comprehension 能力。<details>
<summary>Abstract</summary>
Narrative understanding involves capturing the author's cognitive processes, providing insights into their knowledge, intentions, beliefs, and desires. Although large language models (LLMs) excel in generating grammatically coherent text, their ability to comprehend the author's thoughts remains uncertain. This limitation hinders the practical applications of narrative understanding. In this paper, we conduct a comprehensive survey of narrative understanding tasks, thoroughly examining their key features, definitions, taxonomy, associated datasets, training objectives, evaluation metrics, and limitations. Furthermore, we explore the potential of expanding the capabilities of modularized LLMs to address novel narrative understanding tasks. By framing narrative understanding as the retrieval of the author's imaginative cues that outline the narrative structure, our study introduces a fresh perspective on enhancing narrative comprehension.
</details>
<details>
<summary>摘要</summary>
narrative understanding 涉及捕捉作者的认知过程，提供作者的知识、意图、信仰、愿望等信息的启示。虽然大语言模型（LLM）在生成 grammatically coherent text 方面表现出色，但它们对作者的思想真实理解仍存在uncertainty。这种限制阻碍了 narraitve understanding 的实际应用。在这篇论文中，我们进行了全面的 narrative understanding 任务调查，详细检查了这些任务的关键特征、定义、分类、相关数据集、训练目标、评价指标以及局限性。此外，我们还探讨了扩展 modularized LLM 的能力，以解决新的 narrative understanding 任务。我们通过将 narrative understanding 定义为捕捉作者的想象力cue 的抽象，从新的角度增强了 narrative comprehension。
</details></li>
</ul>
<hr>
<h2 id="ProMap-Effective-Bilingual-Lexicon-Induction-via-Language-Model-Prompting"><a href="#ProMap-Effective-Bilingual-Lexicon-Induction-via-Language-Model-Prompting" class="headerlink" title="ProMap: Effective Bilingual Lexicon Induction via Language Model Prompting"></a>ProMap: Effective Bilingual Lexicon Induction via Language Model Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18778">http://arxiv.org/abs/2310.18778</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/4mekki4/promap">https://github.com/4mekki4/promap</a></li>
<li>paper_authors: Abdellah El Mekki, Muhammad Abdul-Mageed, ElMoatez Billah Nagoudi, Ismail Berrada, Ahmed Khoumsi</li>
<li>for: 本研究的目的是提出一种基于多语言多方言语言模型的提示方法，以解决基于静态单词表示的单词翻译 task 中的挑战。</li>
<li>methods: 该方法基于提前训练的多语言多方言语言模型，并使用有效的补充提示来改进单词翻译性能。</li>
<li>results: 在评估多种单词翻译方法，包括静态单词表示的方法，ProMap  consistently  achieve 状态的 лучResults ，并且在少数例示enario 下（ fewer than 10 个训练示例）也能够达到良好的性能。<details>
<summary>Abstract</summary>
Bilingual Lexicon Induction (BLI), where words are translated between two languages, is an important NLP task. While noticeable progress on BLI in rich resource languages using static word embeddings has been achieved. The word translation performance can be further improved by incorporating information from contextualized word embeddings. In this paper, we introduce ProMap, a novel approach for BLI that leverages the power of prompting pretrained multilingual and multidialectal language models to address these challenges. To overcome the employment of subword tokens in these models, ProMap relies on an effective padded prompting of language models with a seed dictionary that achieves good performance when used independently. We also demonstrate the effectiveness of ProMap in re-ranking results from other BLI methods such as with aligned static word embeddings. When evaluated on both rich-resource and low-resource languages, ProMap consistently achieves state-of-the-art results. Furthermore, ProMap enables strong performance in few-shot scenarios (even with less than 10 training examples), making it a valuable tool for low-resource language translation. Overall, we believe our method offers both exciting and promising direction for BLI in general and low-resource languages in particular. ProMap code and data are available at \url{https://github.com/4mekki4/promap}.
</details>
<details>
<summary>摘要</summary>
百度 Lexicon 推理 (BLI), 将词语翻译 между两种语言，是 NLP 任务中的一项重要任务。虽然在使用静态词嵌入的情况下，在丰富资源语言中已经取得了可注目的进步，但词语翻译性能可以通过使用语言模型的上下文化词嵌入进一步改进。在这篇论文中，我们介绍了 ProMap，一种新的 BLI 方法，利用预训练的多语言多方言语言模型的力量，解决这些挑战。为了超越使用子词 токен，ProMap 利用有效的补充提示语言模型的方法，并使用种子词典 achieve 好的性能。我们还 demonstarte ProMap 可以在其他 BLI 方法的结果中进行排名，如采用静态词嵌入的方法。当评估在丰富资源语言和低资源语言上时，ProMap  consistently 取得了状态的艺术结果。此外，ProMap 可以在少量示例下进行几极enario （即使使用 less than 10 个训练示例），这使其成为低资源语言翻译中的有价值工具。总之，我们认为我们的方法对 BLI 和低资源语言来说是一种激动人心的和有前途的方向。ProMap 代码和数据可以在 \url{https://github.com/4mekki4/promap} 上找到。
</details></li>
</ul>
<hr>
<h2 id="Crossing-the-Aisle-Unveiling-Partisan-and-Counter-Partisan-Events-in-News-Reporting"><a href="#Crossing-the-Aisle-Unveiling-Partisan-and-Counter-Partisan-Events-in-News-Reporting" class="headerlink" title="Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting"></a>Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18768">http://arxiv.org/abs/2310.18768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaijian Zou, Xinliang Frederick Zhang, Winston Wu, Nick Beauchamp, Lu Wang</li>
<li>for: 这篇论文研究了新闻媒体是如何通过事件包容或排除来影响公众意见的。</li>
<li>methods: 作者首先引入了检测党派和反党派事件的任务，并对这些事件进行了标注。然后，他们使用了高质量的数据集PAC，包含304篇来自不同政治立场的新闻文章，并对其进行了分析。</li>
<li>results: 研究发现，新闻媒体通过事件包容或排除来影响公众意见，并且这种影响可以通过语言模型更好地理解事件在更广泛的上下文中。同时，研究也发现了新闻媒体的选择性报道可能会影响公众意见的方向性。<details>
<summary>Abstract</summary>
News media is expected to uphold unbiased reporting. Yet they may still affect public opinion by selectively including or omitting events that support or contradict their ideological positions. Prior work in NLP has only studied media bias via linguistic style and word usage. In this paper, we study to which degree media balances news reporting and affects consumers through event inclusion or omission. We first introduce the task of detecting both partisan and counter-partisan events: events that support or oppose the author's political ideology. To conduct our study, we annotate a high-quality dataset, PAC, containing 8,511 (counter-)partisan event annotations in 304 news articles from ideologically diverse media outlets. We benchmark PAC to highlight the challenges of this task. Our findings highlight both the ways in which the news subtly shapes opinion and the need for large language models that better understand events within a broader context. Our dataset can be found at https://github.com/launchnlp/Partisan-Event-Dataset.
</details>
<details>
<summary>摘要</summary>
新闻媒体应该保持不倚于任何政治立场的报道，但它们可能仍然影响公众意见通过选择性地包括或排除支持或反对其政治立场的事件。在这篇论文中，我们研究了新闻报道是如何帮助或妨碍公众意见的。我们首先介绍了检测政治立场事件的任务，包括支持和反对作者政治立场的事件。为了进行这项研究，我们在304篇来自不同政治立场的新闻媒体发布的文章中标注了8511个（Counter-)政治立场事件。我们使用PAC数据集进行测试，以高亮这个任务的挑战。我们的发现表明新闻可以在不显着的方式下形成公众意见，同时也表明需要更好地理解事件在更广泛的上下文中。我们的数据集可以在GitHub上找到：https://github.com/launchnlp/Partisan-Event-Dataset。
</details></li>
</ul>
<hr>
<h2 id="TLM-Token-Level-Masking-for-Transformers"><a href="#TLM-Token-Level-Masking-for-Transformers" class="headerlink" title="TLM: Token-Level Masking for Transformers"></a>TLM: Token-Level Masking for Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18738">http://arxiv.org/abs/2310.18738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Young1993/tlm">https://github.com/Young1993/tlm</a></li>
<li>paper_authors: Yangjun Wu, Kebin Fang, Dongxiang Zhang, Han Wang, Hao Zhang, Gang Chen</li>
<li>for: 本研究旨在提高Transformer模型的鲁棒性和一致性，通过对自注意力连接进行质量控制。</li>
<li>methods: 本研究提出了一种基于Token Level Masking（TLM）的新训练策略，包括两种有效和容易实现的遮盾技术。</li>
<li>results: 实验表明，TLM可以在4种不同的自然语言处理任务上提高性能，比如GLUE、ChineseGLUE、中文语法错误修复和数据到文本生成等，并且可以超越DropHead和注意力遮盾。例如，使用BERT-large模型，TLM在GLUE上提高了0.5点相对于DropHead。此外，TLM在Rotowire上达到了18.93 BLEU的新纪录。<details>
<summary>Abstract</summary>
Structured dropout approaches, such as attention dropout and DropHead, have been investigated to regularize the multi-head attention mechanism in Transformers. In this paper, we propose a new regularization scheme based on token-level rather than structure-level to reduce overfitting. Specifically, we devise a novel Token-Level Masking (TLM) training strategy for Transformers to regularize the connections of self-attention, which consists of two masking techniques that are effective and easy to implement. The underlying idea is to manipulate the connections between tokens in the multi-head attention via masking, where the networks are forced to exploit partial neighbors' information to produce a meaningful representation. The generality and effectiveness of TLM are thoroughly evaluated via extensive experiments on 4 diversified NLP tasks across 18 datasets, including natural language understanding benchmark GLUE, ChineseGLUE, Chinese Grammatical Error Correction, and data-to-text generation. The results indicate that TLM can consistently outperform attention dropout and DropHead, e.g., it increases by 0.5 points relative to DropHead with BERT-large on GLUE. Moreover, TLM can establish a new record on the data-to-text benchmark Rotowire (18.93 BLEU). Our code will be publicly available at https://github.com/Young1993/tlm.
</details>
<details>
<summary>摘要</summary>
“structured dropout方法，如注意力Dropout和DropHead，已经用来规化Transformer中的多头注意力机制。在这篇论文中，我们提出了一新的规化方案，基于Token Level而不是结构 Level，以减少过拟合。 Specifically, we develop a novel Token-Level Masking（TLM）训练策略 дляTransformer，以规化自我注意力的连接，这包括两种遮盾技术，它们是有效且易于实现。 The underlying idea is to manipulate the connections between tokens in the multi-head attention via masking, where the networks are forced to exploit partial neighbors' information to produce a meaningful representation。”“我们透过广泛的实验评估TLM的通用性和效果，包括18个不同的自然语言处理任务和4个测试集。结果显示，TLM可以较DropHead和注意力Dropout表现出色，例如，与BERT-large在GLUE上的结果提高0.5分。此外，TLM可以创下Rotowire（18.93 BLEU）中的新纪录。我们将代码公开在https://github.com/Young1993/tlm。”
</details></li>
</ul>
<hr>
<h2 id="When-Reviewers-Lock-Horn-Finding-Disagreement-in-Scientific-Peer-Reviews"><a href="#When-Reviewers-Lock-Horn-Finding-Disagreement-in-Scientific-Peer-Reviews" class="headerlink" title="When Reviewers Lock Horn: Finding Disagreement in Scientific Peer Reviews"></a>When Reviewers Lock Horn: Finding Disagreement in Scientific Peer Reviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18685">http://arxiv.org/abs/2310.18685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sandeep82945/contradiction-in-peer-review">https://github.com/sandeep82945/contradiction-in-peer-review</a></li>
<li>paper_authors: Sandeep Kumar, Tirthankar Ghosal, Asif Ekbal</li>
<li>for: 本研究旨在Automatically identifying contradictions among reviewers on a given article.</li>
<li>methods: 我们提出了一种基本模型，可以从open review-based ICLR和NeurIPS会议的 around 8.5k paper中检测出对 противоречи的评论。</li>
<li>results: 我们创建了一个包含around 28k review pair中nearly 50k review pair comment的comprehensive review-pair contradiction数据集，并提出了一种基本模型可以自动检测评论中的对 противоречи。<details>
<summary>Abstract</summary>
To this date, the efficacy of the scientific publishing enterprise fundamentally rests on the strength of the peer review process. The journal editor or the conference chair primarily relies on the expert reviewers' assessment, identify points of agreement and disagreement and try to reach a consensus to make a fair and informed decision on whether to accept or reject a paper. However, with the escalating number of submissions requiring review, especially in top-tier Artificial Intelligence (AI) conferences, the editor/chair, among many other works, invests a significant, sometimes stressful effort to mitigate reviewer disagreements. Here in this work, we introduce a novel task of automatically identifying contradictions among reviewers on a given article. To this end, we introduce ContraSciView, a comprehensive review-pair contradiction dataset on around 8.5k papers (with around 28k review pairs containing nearly 50k review pair comments) from the open review-based ICLR and NeurIPS conferences. We further propose a baseline model that detects contradictory statements from the review pairs. To the best of our knowledge, we make the first attempt to identify disagreements among peer reviewers automatically. We make our dataset and code public for further investigations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ASTormer-An-AST-Structure-aware-Transformer-Decoder-for-Text-to-SQL"><a href="#ASTormer-An-AST-Structure-aware-Transformer-Decoder-for-Text-to-SQL" class="headerlink" title="ASTormer: An AST Structure-aware Transformer Decoder for Text-to-SQL"></a>ASTormer: An AST Structure-aware Transformer Decoder for Text-to-SQL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18662">http://arxiv.org/abs/2310.18662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruisheng Cao, Hanchong Zhang, Hongshen Xu, Jieyu Li, Da Ma, Lu Chen, Kai Yu</li>
<li>for: 文章目的是提出一种基于Transformer decoder的文本到SQL转换方法，以生成可执行的SQL程序，并确保输出SQL的有效性。</li>
<li>methods: 该方法使用AST结构具有STRUCTURE-aware Transformer decoder（ASTormer），在decoder中嵌入了结构知识，例如节点类型和位置，并通过绝对和相对位置嵌入来强化结构信息。</li>
<li>results: 对五个文本到SQL benchmark进行了广泛的实验，并证明了ASTormer比基于RNN的竞争对手更有效和高效。<details>
<summary>Abstract</summary>
Text-to-SQL aims to generate an executable SQL program given the user utterance and the corresponding database schema. To ensure the well-formedness of output SQLs, one prominent approach adopts a grammar-based recurrent decoder to produce the equivalent SQL abstract syntax tree (AST). However, previous methods mainly utilize an RNN-series decoder, which 1) is time-consuming and inefficient and 2) introduces very few structure priors. In this work, we propose an AST structure-aware Transformer decoder (ASTormer) to replace traditional RNN cells. The structural knowledge, such as node types and positions in the tree, is seamlessly incorporated into the decoder via both absolute and relative position embeddings. Besides, the proposed framework is compatible with different traversing orders even considering adaptive node selection. Extensive experiments on five text-to-SQL benchmarks demonstrate the effectiveness and efficiency of our structured decoder compared to competitive baselines.
</details>
<details>
<summary>摘要</summary>
文本到SQL的目标是生成基于用户语音和相应的数据库架构的可执行SQL程序。为保证输出SQL的正确性，一种广泛采用的方法是使用 grammar-based 回归decoder生成相应的SQL抽象语法树（AST）。然而，前一代方法主要采用 RNN 序列decoder，这些方法有以下两点缺陷：1）时间consuming 和不效率，2）不提供多少结构偏好。在这项工作中，我们提议一种AST结构意识的Transformer decoder（ASTormer）来取代传统的RNN细胞。在decoder中，结构知识，如树中节点类型和位置，通过绝对和相对位置嵌入被灵活地嵌入。此外，我们提出的框架可以与不同的搜索顺序一起使用，包括自适应节点选择。我们对五个文本到SQLbenchmark进行了广泛的实验，并证明了我们的结构化decoder与其他基准值比较有效和高效。
</details></li>
</ul>
<hr>
<h2 id="Personalised-Distillation-Empowering-Open-Sourced-LLMs-with-Adaptive-Learning-for-Code-Generation"><a href="#Personalised-Distillation-Empowering-Open-Sourced-LLMs-with-Adaptive-Learning-for-Code-Generation" class="headerlink" title="Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation"></a>Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18628">http://arxiv.org/abs/2310.18628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hailin Chen, Amrita Saha, Steven Hoi, Shafiq Joty</li>
<li>for: 本研究旨在提高小型开源模型的能力，通过将大型关闭源模型（如ChatGPT、GPT-4）的能力储存到小型开源模型中。</li>
<li>methods: 该研究提出了一种个性化储存方法，其中学生模型首先尝试解决任务，然后教师模型提供适应性更新，以便学生模型可以通过自己的错误来进行改进。这种个性化储存方法与传统的预先Feed的方法不同，因为它只有学生模型在进行学习时才会学习，而不是从教师模型那里获得知识。</li>
<li>results: 研究表明，个性化储存方法在代码生成任务中表现出色，可以在只有一 third的数据量下达到传统方法的水平。在HumanEval中，通过使用2.5-3K个性化示例，可以提高CodeGen-mono-16B的表现，从33.6%提高到36.4%，并提高StarCoder的表现，从39.5%提高到45.8%。<details>
<summary>Abstract</summary>
With the rise of powerful closed-sourced LLMs (ChatGPT, GPT-4), there are increasing interests in distilling the capabilies of close-sourced LLMs to smaller open-sourced LLMs. Previous distillation methods usually prompt ChatGPT to generate a set of instructions and answers, for the student model to learn. However, such standard distillation approach neglects the merits and conditions of the student model. Inspired by modern teaching principles, we design a personalised distillation process, in which the student attempts to solve a task first, then the teacher provides an adaptive refinement for the student to improve. Instead of feeding the student with teacher's prior, personalised distillation enables personalised learning for the student model, as it only learns on examples it makes mistakes upon and learns to improve its own solution. On code generation, personalised distillation consistently outperforms standard distillation with only one third of the data. With only 2.5-3K personalised examples that incur a data-collection cost of 4-6$, we boost CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to achieve 45.8% pass@1 on HumanEval.
</details>
<details>
<summary>摘要</summary>
Inspired by modern teaching principles, we designed a personalized distillation process in which the student attempts to solve a task first, and then the teacher provides an adaptive refinement for the student to improve. Instead of feeding the student with the teacher's prior knowledge, personalized distillation enables personalized learning for the student model, as it only learns from examples it makes mistakes on and learns to improve its own solutions.On code generation, personalized distillation consistently outperforms standard distillation with only one-third of the data. With only 2,500 to 3,000 personalized examples that incur a data-collection cost of $4 to $6, we boosted CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to achieve 45.8% pass@1 on HumanEval.
</details></li>
</ul>
<hr>
<h2 id="Anaphor-Assisted-Document-Level-Relation-Extraction"><a href="#Anaphor-Assisted-Document-Level-Relation-Extraction" class="headerlink" title="Anaphor Assisted Document-Level Relation Extraction"></a>Anaphor Assisted Document-Level Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18604">http://arxiv.org/abs/2310.18604</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/burgerburgerburger/aa">https://github.com/burgerburgerburger/aa</a></li>
<li>paper_authors: Chonggang Lu, Richong Zhang, Kai Sun, Jaein Kim, Cunwang Zhang, Yongyi Mao</li>
<li>for:  DocRE document-level relation extraction</li>
<li>methods:  Anaphor-Assisted (AA) framework</li>
<li>results:  new state-of-the-art performance<details>
<summary>Abstract</summary>
Document-level relation extraction (DocRE) involves identifying relations between entities distributed in multiple sentences within a document. Existing methods focus on building a heterogeneous document graph to model the internal structure of an entity and the external interaction between entities. However, there are two drawbacks in existing methods. On one hand, anaphor plays an important role in reasoning to identify relations between entities but is ignored by these methods. On the other hand, these methods achieve cross-sentence entity interactions implicitly by utilizing a document or sentences as intermediate nodes. Such an approach has difficulties in learning fine-grained interactions between entities across different sentences, resulting in sub-optimal performance. To address these issues, we propose an Anaphor-Assisted (AA) framework for DocRE tasks. Experimental results on the widely-used datasets demonstrate that our model achieves a new state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
文档级关系EXTRACTION（DocRE）涉及到在文档中多个句子中Identifying关系 между实体。现有方法是建立不同类型的文档图来模型实体的内部结构和实体之间的外部互动。然而，现有方法存在两点缺陷。一方面，Anaphora在理解关系 identification 中发挥重要作用，但这些方法忽略了它。另一方面，这些方法通过使用文档或句子作为中间节点来实现跨句sentenceEntity interaction，这会增加学习细化实体之间的交互问题，导致性能下降。为了解决这些问题，我们提出了Anaphor-Assisted（AA）框架来Address DocRE任务。实验结果表明，我们的模型在广泛使用的数据集上达到了新的状态的艺术性能。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-LLM-Inference-by-Enabling-Intermediate-Layer-Decoding"><a href="#Accelerating-LLM-Inference-by-Enabling-Intermediate-Layer-Decoding" class="headerlink" title="Accelerating LLM Inference by Enabling Intermediate Layer Decoding"></a>Accelerating LLM Inference by Enabling Intermediate Layer Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18581">http://arxiv.org/abs/2310.18581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neeraj Varshney, Agneet Chatterjee, Mihir Parmar, Chitta Baral</li>
<li>for: 提高LLMs的执行效率，使其适用于资源受限的实际应用中。</li>
<li>methods: 通过增加中间层的LITE损失，使中间层学习生成文本的能力，而不会影响最终层的生成质量。并通过“动态信任早退”的技术，在token层面实现更高效的推理，保持生成质量。</li>
<li>results: 在Alpaca数据集上进行了广泛的实验，并对四个不同的人工指令测试集进行了总体评估：Vicuna、WizardLM、Koala和Self-Instruct。结果表明，“动态早退”可以实现37.86%的平均成本改进，保持生成质量。进一步的分析结果表明，输出的语义相似性和生成的数量均有改进。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have achieved remarkable performance across a wide variety of natural language tasks; however, their large size makes their inference slow and computationally expensive which poses a practical challenge for resource constrained real-world applications. Focusing on this problem, we propose to instruction tune LLMs in a way that enables intermediate layer decoding for efficiently generating text, but importantly without compromising the quality of the generation. Specifically, we instruction tune LLMs with additional explicit Losses from the InTermediate layErs (LITE) and show that it enables these layers to acquire 'good' generation ability without affecting the generation ability of the final layer. We perform 'dynamic confidence-based early exiting' at token level from the intermediate layers which improves the efficiency of inference while maintaining the generation quality. We conduct comprehensive experiments by instruction tuning LLaMA-2 models on the widely used Alpaca dataset and holistically evaluate on four different human-instruction test sets: Vicuna, WizardLM, Koala, and Self-Instruct. We show that 'dynamic early exiting' achieves consistent and considerable cost improvements (37.86% on average) while maintaining the generation quality of the responses. We further conduct a thorough analysis of the results over several important aspects, such as comparing the semantic similarity of the outputs and dissecting the efficiency improvements by comparing the number of tokens generated in the output. In summary, our work contributes to improving the efficiency of LLM inference while maintaining the generation quality, a crucial step en route to enabling their widespread adoption.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）在各种自然语言任务上达到了很高的表现水平，但是它们的大小使得其推理慢且计算成本高，这成为了实际应用中的实际挑战。在这个问题上，我们提出了在LLM中 instrucion 优化，以实现中间层解码，以便高效地生成文本，而不会影响最终层的生成质量。我们在LLM中添加了额外的明确损失（LITE），使中间层学习“好”的生成能力，而不会影响最终层的生成能力。我们在中间层进行“动态信息确定早退”，从而提高推理效率，保持生成质量。我们对 LLamA-2 模型进行了广泛的实验，并对四个不同的人工指令测试集进行了总体评估：Vicuna、WizardLM、Koala 和 Self-Instruct。我们发现，“动态早退”可以具有重要的成本改善（37.86% 的平均提高），同时保持生成质量。我们进一步进行了详细的分析结果，包括比较输出的semantic相似性和生成量的比较分析。总之，我们的工作为LLM推理效率的提高，并保持生成质量，是实际应用中的关键一步。
</details></li>
</ul>
<hr>
<h2 id="Identifying-Conspiracy-Theories-News-based-on-Event-Relation-Graph"><a href="#Identifying-Conspiracy-Theories-News-based-on-Event-Relation-Graph" class="headerlink" title="Identifying Conspiracy Theories News based on Event Relation Graph"></a>Identifying Conspiracy Theories News based on Event Relation Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18545">http://arxiv.org/abs/2310.18545</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuanyuanlei-nlp/conspiracy_theories_emnlp_2023">https://github.com/yuanyuanlei-nlp/conspiracy_theories_emnlp_2023</a></li>
<li>paper_authors: Yuanyuan Lei, Ruihong Huang</li>
<li>for: 本研究旨在检测新闻文章中是否存在阴谋理论。</li>
<li>methods: 本文提出了一种基于事件关系图的阴谋理论检测方法，包括开发了一个事件意识语言模型以提高基础语言模型的事件和事件关系知识，以及使用一种多型图注意力网络来 derive 一个图像 embedding。</li>
<li>results: 实验结果表明，基于事件关系图的方法可以提高阴谋理论检测的准确率和受检测率，并且能够在新的媒体源上进行检测。<details>
<summary>Abstract</summary>
Conspiracy theories, as a type of misinformation, are narratives that explains an event or situation in an irrational or malicious manner. While most previous work examined conspiracy theory in social media short texts, limited attention was put on such misinformation in long news documents. In this paper, we aim to identify whether a news article contains conspiracy theories. We observe that a conspiracy story can be made up by mixing uncorrelated events together, or by presenting an unusual distribution of relations between events. Achieving a contextualized understanding of events in a story is essential for detecting conspiracy theories. Thus, we propose to incorporate an event relation graph for each article, in which events are nodes, and four common types of event relations, coreference, temporal, causal, and subevent relations, are considered as edges. Then, we integrate the event relation graph into conspiracy theory identification in two ways: an event-aware language model is developed to augment the basic language model with the knowledge of events and event relations via soft labels; further, a heterogeneous graph attention network is designed to derive a graph embedding based on hard labels. Experiments on a large benchmark dataset show that our approach based on event relation graph improves both precision and recall of conspiracy theory identification, and generalizes well for new unseen media sources.
</details>
<details>
<summary>摘要</summary>
《刺激论题》是一种不合理或恶意的含义，用于解释事件或情况。而大多数前期工作都是通过社交媒体短文来研究刺激论题，却受到了长文报道的限制。在这篇论文中，我们想要判断一篇新闻文章是否包含刺激论题。我们发现，刺激故事可以通过将不相关的事件混合起来，或者通过事件之间的不寻常的关系分布来构成。为了检测刺激论题，我们需要了解事件的上下文知识。因此，我们提议使用事件关系图来识刺刺激论题。每篇文章都有一个事件关系图，其中事件是节点，而四种常见的事件关系，核心引用、时间关系、 causal 关系和 subsequential 关系，被视为边。然后，我们将事件关系图 интеグриinto刺激论题标识中两种方式：首先，我们开发了一个事件意识语言模型，以提高基本语言模型的知识水平，并通过软标签将事件和事件关系传递给模型；其次，我们设计了一个多类Graph注意力网络，以生成基于硬标签的图 embedding。实验表明，我们基于事件关系图的方法可以提高刺激论题标识的精度和准确率，并在新的媒体来源上具有良好的泛化性。
</details></li>
</ul>
<hr>
<h2 id="Discourse-Structures-Guided-Fine-grained-Propaganda-Identification"><a href="#Discourse-Structures-Guided-Fine-grained-Propaganda-Identification" class="headerlink" title="Discourse Structures Guided Fine-grained Propaganda Identification"></a>Discourse Structures Guided Fine-grained Propaganda Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18544">http://arxiv.org/abs/2310.18544</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuanyuanlei-nlp/propaganda_emnlp_2023">https://github.com/yuanyuanlei-nlp/propaganda_emnlp_2023</a></li>
<li>paper_authors: Yuanyuan Lei, Ruihong Huang</li>
<li>for: 本研究旨在识别政治新闻中的宣传内容，以 sentence-level 和 token-level 两级精细度进行识别。</li>
<li>methods: 本研究提出了两种教师模型，一是基于 PDTB 风格的 discourse relations 来识别宣传内容，二是基于本文中的 sentence 和 token 的 discourse structures 来提高宣传内容识别精度。</li>
<li>results: 实验结果表明，通过利用教师预测概率或知识储存框架来汇集 discourse structures 可以显著提高宣传内容识别的精度。<details>
<summary>Abstract</summary>
Propaganda is a form of deceptive narratives that instigate or mislead the public, usually with a political purpose. In this paper, we aim to identify propaganda in political news at two fine-grained levels: sentence-level and token-level. We observe that propaganda content is more likely to be embedded in sentences that attribute causality or assert contrast to nearby sentences, as well as seen in opinionated evaluation, speculation and discussions of future expectation. Hence, we propose to incorporate both local and global discourse structures for propaganda discovery and construct two teacher models for identifying PDTB-style discourse relations between nearby sentences and common discourse roles of sentences in a news article respectively. We further devise two methods to incorporate the two types of discourse structures for propaganda identification by either using teacher predicted probabilities as additional features or soliciting guidance in a knowledge distillation framework. Experiments on the benchmark dataset demonstrate that leveraging guidance from discourse structures can significantly improve both precision and recall of propaganda content identification.
</details>
<details>
<summary>摘要</summary>
宣传是一种欺骗性的叙述，通常有政治目的。在这篇论文中，我们目标是在新闻文本中发现宣传。我们发现宣传内容更容易在归因或者评价附近的句子中出现，以及在评价、推测和未来预测中出现。因此，我们建议使用本地和全局文本结构来发现宣传。我们设计了两种教师模型，一个用于确定邻近句子之间的 PDTB 风格的语言关系，另一个用于确定新闻文本中句子的常见语言角色。此外，我们还提出了两种方法来结合这两种文本结构来发现宣传内容，一种是使用教师预测概率作为额外特征，另一种是在知识填充框架中寻求指导。实验表明，通过使用文本结构的指导，可以大幅提高宣传内容发现的精度和准确性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/cs.CL_2023_10_28/" data-id="cloq1wl3q00de7o88475f1zk7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/cs.LG_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T10:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/cs.LG_2023_10_28/">cs.LG - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="World-Model-Based-Sim2Real-Transfer-for-Visual-Navigation"><a href="#World-Model-Based-Sim2Real-Transfer-for-Visual-Navigation" class="headerlink" title="World Model Based Sim2Real Transfer for Visual Navigation"></a>World Model Based Sim2Real Transfer for Visual Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18847">http://arxiv.org/abs/2310.18847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Liu, Kiran Lekkala, Laurent Itti</li>
<li>For: 本研究目的是开发一个可以从便宜的 simulator 转移到实际世界的 robot  Navigation 系统。* Methods: 本研究使用了一个组合了传统的 World Model  комponents的系统，并将其整合成一个可以在 simulator 上全部训练的 Robust 系统。为了促进转移，我们使用了基于 Bird’s Eye View (BEV) 的中间表示，并将它与 First-Person View (FPV) 的 RGB 图像进行翻译。* Results: 我们使用了 CARLA  simulator 收集的数据进行训练，并显示了模型的效能。最后，我们发布了一个完整的代码库、数据和模型，供大众使用。<details>
<summary>Abstract</summary>
Sim2Real transfer has gained popularity because it helps transfer from inexpensive simulators to real world. This paper presents a novel system that fuses components in a traditional \textit{World Model} into a robust system, trained entirely within a simulator, that \textit{Zero-Shot} transfers to the real world. To facilitate transfer, we use an intermediary representation that are based on \textit{Bird's Eye View (BEV)} images. Thus, our robot learns to navigate in a simulator by first learning to translate from complex \textit{First-Person View (FPV)} based RGB images to BEV representations, then learning to navigate using those representations. Later, when tested in the real world, the robot uses the perception model that translates FPV-based RGB images to embeddings that are used by the downstream policy. The incorporation of state-checking modules using \textit{Anchor images} and \textit{Mixture Density LSTM} not only interpolates uncertain and missing observations but also enhances the robustness of the model when exposed to the real-world environment. We trained the model using data collected using a \textit{Differential drive} robot in the CARLA simulator. Our methodology's effectiveness is shown through the deployment of trained models onto a \textit{Real world Differential drive} robot. Lastly we release a comprehensive codebase, dataset and models for training and deployment that are available to the public.
</details>
<details>
<summary>摘要</summary>
实际转移（Sim2Real）已经受到普遍采用，因为它帮助将来自便宜的模拟器转移到真实世界。这篇论文提出了一个新的系统，将模拟器中的元件融合成一个可靠的系统，由真实世界训练，并且透过运算获得零损转移。为了促进转移，我们使用了中心投影（Bird's Eye View，BEV）图像作为中介表示。因此，我们的机器人在模拟器中学习将复杂的首人视角（First-Person View，FPV）基于RGB图像转换为BEV表示，然后学习使用这些表示进行navigation。当它在真实世界中进行测试时，机器人使用视觉模型将FPV基于RGB图像转换为嵌入，这些嵌入被用于下游策略。另外，我们还使用了状态检查模组使用 anchor image和mixture density LSTM interpolate uncertain和缺失观察，这不仅让模型在真实世界环境中更加稳定，而且也增强了模型的可靠性。我们使用了通过CARLA模拟器收集的数据进行训练。我们的方法的有效性被显示在真实世界中部署训练好的模型。最后，我们发布了一个完整的代码库、数据集和模型，供大众使用。
</details></li>
</ul>
<hr>
<h2 id="A-randomized-algorithm-for-nonconvex-minimization-with-inexact-evaluations-and-complexity-guarantees"><a href="#A-randomized-algorithm-for-nonconvex-minimization-with-inexact-evaluations-and-complexity-guarantees" class="headerlink" title="A randomized algorithm for nonconvex minimization with inexact evaluations and complexity guarantees"></a>A randomized algorithm for nonconvex minimization with inexact evaluations and complexity guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18841">http://arxiv.org/abs/2310.18841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuyao Li, Stephen J. Wright</li>
<li>for: Minimizing a smooth nonconvex function with inexact oracle access to gradient and Hessian.</li>
<li>methods: Using a novel method that chooses the step direction with equal probability of positive or negative sense, and using relative inexactness measures on gradient and Hessian.</li>
<li>results: Achieving ($\epsilon_{g}, \epsilon_{H}$)-approximate second-order optimality with convergence analysis based on martingale analysis and concentration inequalities.Here’s the full summary in Simplified Chinese:</li>
<li>for: 本文目的是使用不精准渐近 oracle 访问梯度和对角线，来实现 ($ \epsilon_{g}, \epsilon_{H} $)-精度二阶优化。</li>
<li>methods: 我们使用一种新的方法，其中在步长选择时，选择的方向的方向是正负两种有 Equal probability。此外，我们使用梯度和对角线的相对不精准度度量，并松弛了梯度和对角线的第一阶和第二阶误差之间的关联。</li>
<li>results: 我们可以通过 martingale 分析和集中不等式来证明我们的算法可以实现 ($\epsilon_{g}, \epsilon_{H}$)-精度二阶优化，并且可以应用到empirical risk minimization问题中。<details>
<summary>Abstract</summary>
We consider minimization of a smooth nonconvex function with inexact oracle access to gradient and Hessian (but not the function value) to achieve $(\epsilon_{g}, \epsilon_{H})$-approximate second-order optimality. A novel feature of our method is that if an approximate direction of negative curvature is chosen as the step, we choose its sense to be positive or negative with equal probability. We also use relative inexactness measures on gradient and Hessian and relax the coupling between the first- and second-order tolerances $\epsilon_{g}$ and $\epsilon_{H}$. Our convergence analysis includes both an expectation bound based on martingale analysis and a high-probability bound based on concentration inequalities. We apply our algorithm to empirical risk minimization problems and obtain gradient sample complexity.
</details>
<details>
<summary>摘要</summary>
我们考虑使用非конvex函数的最小化，但是只有不准确的梯度和偏微分（而不是函数值）的偏 oracle 访问来实现($\epsilon_{g}, \epsilon_{H}$)-次极性。我们的新特点在于，如果选择一个近似的负曲率方向作为步骤，我们会选择其方向为正或负的概率为50%。我们还使用relative不准确度度量在梯度和偏微分上，并松弛了梯度和偏微分的 Coupling。我们的收敛分析包括基于Martingale分析的预期 bound和基于集中不等式的高概率 bound。我们将我们的算法应用到empirical risk minimization问题，并获得梯度样本复杂度。
</details></li>
</ul>
<hr>
<h2 id="Intrinsic-Gaussian-Vector-Fields-on-Manifolds"><a href="#Intrinsic-Gaussian-Vector-Fields-on-Manifolds" class="headerlink" title="Intrinsic Gaussian Vector Fields on Manifolds"></a>Intrinsic Gaussian Vector Fields on Manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18824">http://arxiv.org/abs/2310.18824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Robert-Nicoud, Andreas Krause, Viacheslav Borovitskiy</li>
<li>for: 本文主要针对的是模型非欧几何空间上的向量值信号，尤其是在不确定性评估中。</li>
<li>methods: 本文提出了一种新的泊松过程模型，即 HODE-MATÉRN 泊松场，用于模型非欧几何空间上的向量值信号。</li>
<li>results: 本文的实验结果表明，HODE-MATÉRN 泊松场可以在二维球面和高维托里上提供更精细的 inductive bias，并且可以在不同的批处理上进行扩展。<details>
<summary>Abstract</summary>
Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat\'ern Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and "ideal" manifolds like hyperspheres, Lie groups, and homogeneous spaces. Finally, we show that our Gaussian vector fields constitute considerably more refined inductive biases than the extrinsic fields proposed before.
</details>
<details>
<summary>摘要</summary>
各种应用，从机器人学到气候科学，需要在非欧几何空间上模型信号，例如球面。在拓扑上， Gaussian process 模型在拓扑上最近得到了提议，特别是当需要uncertainty量化时。在拓扑设置中，向量值信号可能会与scalar值信号有很大差异，而前者在许多应用中非常重要，例如模型风速或未知动力系统的力场。在这篇论文中，我们提出了新的 Gaussian process 模型，用于vector值信号在拓扑上的模型，这些模型具有内在定义的拓扑geometry。我们还提供了在两个维度的球面和杂质上运行这些Hodge-Matérn Gaussian vector fields的计算基础。此外，我们还提出了两个扩展方向：离散二维网格和"理想"拓扑，如高维球面、 Lie group 和同态空间。最后，我们表明了我们的 Gaussian vector fields 比之前提出的外在场更加细致，即更加精细的 inductive bias。
</details></li>
</ul>
<hr>
<h2 id="Successfully-Applying-Lottery-Ticket-Hypothesis-to-Diffusion-Model"><a href="#Successfully-Applying-Lottery-Ticket-Hypothesis-to-Diffusion-Model" class="headerlink" title="Successfully Applying Lottery Ticket Hypothesis to Diffusion Model"></a>Successfully Applying Lottery Ticket Hypothesis to Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18823">http://arxiv.org/abs/2310.18823</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osier0524/lottery-ticket-to-ddpm">https://github.com/osier0524/lottery-ticket-to-ddpm</a></li>
<li>paper_authors: Chao Jiang, Bo Hui, Bohan Liu, Da Yan</li>
<li>for: 这个论文是为了应用抽签票假设（Lottery Ticket Hypothesis，LTH）到扩散模型而写的。</li>
<li>methods: 这个论文使用了LTH来找到一个扩散模型中的精炼版网络，并通过对这个精炼版网络进行简化来减少计算量。</li>
<li>results: 实验结果表明，这个方法可以找到一个具有更高精度且具有更少计算量的扩散模型。 codes可以在<a target="_blank" rel="noopener" href="https://github.com/osier0524/Lottery-Ticket-to-DDPM%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/osier0524/Lottery-Ticket-to-DDPM中找到。</a><details>
<summary>Abstract</summary>
Despite the success of diffusion models, the training and inference of diffusion models are notoriously expensive due to the long chain of the reverse process. In parallel, the Lottery Ticket Hypothesis (LTH) claims that there exists winning tickets (i.e., aproperly pruned sub-network together with original weight initialization) that can achieve performance competitive to the original dense neural network when trained in isolation. In this work, we for the first time apply LTH to diffusion models. We empirically find subnetworks at sparsity 90%-99% without compromising performance for denoising diffusion probabilistic models on benchmarks (CIFAR-10, CIFAR-100, MNIST). Moreover, existing LTH works identify the subnetworks with a unified sparsity along different layers. We observe that the similarity between two winning tickets of a model varies from block to block. Specifically, the upstream layers from two winning tickets for a model tend to be more similar than the downstream layers. Therefore, we propose to find the winning ticket with varying sparsity along different layers in the model. Experimental results demonstrate that our method can find sparser sub-models that require less memory for storage and reduce the necessary number of FLOPs. Codes are available at https://github.com/osier0524/Lottery-Ticket-to-DDPM.
</details>
<details>
<summary>摘要</summary>
尽管扩散模型取得成功，但它们的训练和推理过程却很昂贵，主要因为扩散过程中的链式结构。同时， Lottery Ticket Hypothesis（LTH）假设存在赢家票（即适当剪辑后的子网络以及原始权重初始化），可以在孤立训练中与普通 dense neural network 具有竞争性的性能。在这个工作中，我们首次应用 LTH 到扩散模型。我们实验发现，在 CIFAR-10、CIFAR-100 和 MNIST 等标准图像预测任务上，可以在 diffusion probabilistic models 中找到 90%-99% 的杂度率下的优秀子网络，而不会影响性能。此外，现有的 LTH 工作通常会找到具有不同层次杂度的子网络。我们发现，两个赢家票之间的相似性从层次上不同。具体来说，模型的上游层从两个赢家票之间更加相似，而下游层则更加不同。因此，我们提议在不同层次上找到具有变化杂度的赢家票。实验结果表明，我们的方法可以找到更加简洁的子网络，减少存储的内存需求和计算所需的 FLOPs。代码可以在 <https://github.com/osier0524/Lottery-Ticket-to-DDPM> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Test-Time-Personalization-for-Federated-Learning"><a href="#Adaptive-Test-Time-Personalization-for-Federated-Learning" class="headerlink" title="Adaptive Test-Time Personalization for Federated Learning"></a>Adaptive Test-Time Personalization for Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18816">http://arxiv.org/abs/2310.18816</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/baowenxuan/atp">https://github.com/baowenxuan/atp</a></li>
<li>paper_authors: Wenxuan Bao, Tianxin Wei, Haohan Wang, Jingrui He</li>
<li>for: 本研究旨在提出一种在测试时进行个性化 Federated Learning (FL) 的方法，以适应不同来源客户端的分布差异。</li>
<li>methods: 我们提出了一种名为 ATP 的自适应学习算法，可以在不含标注数据的情况下，在测试时地方式地适应模型。</li>
<li>results: 我们的 ATP 算法在面对多种分布差异，包括标签差异、图像损害和频率差异等，能够超越现有的 TTA 方法，并且可以在多个数据集和模型架构上实现优秀的表现。<details>
<summary>Abstract</summary>
Personalized federated learning algorithms have shown promising results in adapting models to various distribution shifts. However, most of these methods require labeled data on testing clients for personalization, which is usually unavailable in real-world scenarios. In this paper, we introduce a novel setting called test-time personalized federated learning (TTPFL), where clients locally adapt a global model in an unsupervised way without relying on any labeled data during test-time. While traditional test-time adaptation (TTA) can be used in this scenario, most of them inherently assume training data come from a single domain, while they come from multiple clients (source domains) with different distributions. Overlooking these domain interrelationships can result in suboptimal generalization. Moreover, most TTA algorithms are designed for a specific kind of distribution shift and lack the flexibility to handle multiple kinds of distribution shifts in FL. In this paper, we find that this lack of flexibility partially results from their pre-defining which modules to adapt in the model. To tackle this challenge, we propose a novel algorithm called ATP to adaptively learns the adaptation rates for each module in the model from distribution shifts among source domains. Theoretical analysis proves the strong generalization of ATP. Extensive experiments demonstrate its superiority in handling various distribution shifts including label shift, image corruptions, and domain shift, outperforming existing TTA methods across multiple datasets and model architectures. Our code is available at https://github.com/baowenxuan/ATP .
</details>
<details>
<summary>摘要</summary>
个人化联合学习算法已经在不同分布偏移中适应模型表现出色。然而，大多数这些方法需要测试客户端上有标注数据进行个人化，而在实际场景中这些数据通常不可获得。在这篇论文中，我们介绍了一种新的设定，即测试时个人化联合学习（TTPFL），Client可以在无标注数据的情况下，在本地适应全球模型，而不需要任何标注数据。尽管传统的测试时适应（TTA）可以在这种场景中使用，但大多数它们假设训练数据来自单一领域，而实际上来自多个客户端（源领域）的分布不同。忽略这些领域关系可能会导致低效泛化。此外，大多数TTA算法是为某种特定的分布偏移设计的，缺乏在多种分布偏移中的灵活性。为解决这个挑战，我们提议了一种新的算法，即ATP，可以自动学习模型中每个模块的适应率从分布偏移中。理论分析表明ATP具有强大的泛化性。广泛的实验表明ATP在处理多种分布偏移，包括标签偏移、图像损害和频率偏移，在多个数据集和模型架构上超越了现有的TTA方法，并且其代码可以在https://github.com/baowenxuan/ATP上获取。
</details></li>
</ul>
<hr>
<h2 id="Stability-of-Random-Forests-and-Coverage-of-Random-Forest-Prediction-Intervals"><a href="#Stability-of-Random-Forests-and-Coverage-of-Random-Forest-Prediction-Intervals" class="headerlink" title="Stability of Random Forests and Coverage of Random-Forest Prediction Intervals"></a>Stability of Random Forests and Coverage of Random-Forest Prediction Intervals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18814">http://arxiv.org/abs/2310.18814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Wang, Huaiqing Wu, Dan Nettleton</li>
<li>for: 这个论文主要是为了研究随机森林的稳定性，并且提供了一个稳定性的定义，以及一种基于这个定义的预测 интерVALL的建立方法。</li>
<li>methods: 这个论文使用了随机森林的实际实现，以及一些数理Statistics的工具来研究随机森林的稳定性。</li>
<li>results: 这个论文的结果表明，随机森林在一定条件下具有稳定性，并且可以提供正确的预测点和预测 интерVALL，而且这些预测 interval 的覆盖率可以保证在一定范围内。<details>
<summary>Abstract</summary>
We establish stability of random forests under the mild condition that the squared response ($Y^2$) does not have a heavy tail. In particular, our analysis holds for the practical version of random forests that is implemented in popular packages like \texttt{randomForest} in \texttt{R}. Empirical results show that stability may persist even beyond our assumption and hold for heavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic lower bound for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests. With another mild condition that is typically satisfied when $Y$ is continuous, we also establish a complementary upper bound, which can be similarly established for the jackknife prediction interval constructed from an arbitrary stable algorithm. We also discuss the asymptotic coverage probability under assumptions weaker than those considered in previous literature. Our work implies that random forests, with its stability property, is an effective machine learning method that can provide not only satisfactory point prediction but also justified interval prediction at almost no extra computational cost.
</details>
<details>
<summary>摘要</summary>
我们证明随机森林的稳定性，具体来说是当响应值($Y^2$) 不具有极大的尾部时。我们的分析适用于实际的随机森林实现，如\texttt{randomForest} 在 \texttt{R} 中的实现。实际结果表明，稳定性可能会 persist 超过我们的假设，并且适用于重 tailed $Y^2$。使用稳定性质量，我们证明了预测间隔 constructed from 随机森林的 out-of-bag 错误的下界。另外，对于 continuous $Y$ 的情况，我们还设立了一个轻量级的条件，并证明了这个下界。我们还讨论了先前文献中考虑的假设下的极限覆盖率。我们的工作 imply 随机森林，具有稳定性质量，是一种有效的机器学习方法，可以不仅提供满意的点预测，还可以提供正确的间预测，而且只需要一些较少的计算成本。
</details></li>
</ul>
<hr>
<h2 id="The-Synergy-of-Speculative-Decoding-and-Batching-in-Serving-Large-Language-Models"><a href="#The-Synergy-of-Speculative-Decoding-and-Batching-in-Serving-Large-Language-Models" class="headerlink" title="The Synergy of Speculative Decoding and Batching in Serving Large Language Models"></a>The Synergy of Speculative Decoding and Batching in Serving Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18813">http://arxiv.org/abs/2310.18813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qidong Su, Christina Giannoula, Gennady Pekhimenko</li>
<li>for: 这篇论文的目的是研究大语言模型（LLM）的批处理和预测解oding技术，以提高LLM的硬件利用率。</li>
<li>methods: 这篇论文使用了批处理和预测解oding两种技术来提高LLM的硬件利用率。</li>
<li>results: 论文的实验结果表明，适当的预测 lengths 与批处理大小有关，而且提出了一种适应性的预测解oding策略，可以与现有的最佳化策略相比。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) like GPT are state-of-the-art text generation models that provide significant assistance in daily routines. However, LLM execution is inherently sequential, since they only produce one token at a time, thus incurring low hardware utilization on modern GPUs. Batching and speculative decoding are two techniques to improve GPU hardware utilization in LLM inference. To study their synergy, we implement a prototype implementation and perform an extensive characterization analysis on various LLM models and GPU architectures. We observe that the optimal speculation length depends on the batch size used. We analyze the key observation and build a quantitative model to explain it. Based on our analysis, we propose a new adaptive speculative decoding strategy that chooses the optimal speculation length for different batch sizes. Our evaluations show that our proposed method can achieve equal or better performance than the state-of-the-art speculation decoding schemes with fixed speculation length.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如GPT是现在的文本生成模型，它们在日常 Routine 中提供了重要的帮助。然而，LLM 执行是Sequential 的，它们只生成一个 Token 在一次，从而导致现代 GPU 的硬件利用率低。批处和推测解码是两种技术来提高 LLM 执行的 GPU 硬件利用率。为了研究这两种技术的相互作用，我们实现了一个原型实现，并对不同的 LLM 模型和 GPU 架构进行了广泛的分析。我们发现，使用不同的批处大小时，最佳的推测长度会有所不同。我们分析了这一关键观察结果，并建立了一个量化的模型来解释它。根据我们的分析，我们提出了一种新的自适应推测解码策略，可以根据不同的批处大小选择最佳的推测长度。我们的评估表明，我们的提议方法可以与现有的最佳推测解码方法相当或更好的性能。
</details></li>
</ul>
<hr>
<h2 id="Inverse-distance-weighting-attention"><a href="#Inverse-distance-weighting-attention" class="headerlink" title="Inverse distance weighting attention"></a>Inverse distance weighting attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18805">http://arxiv.org/abs/2310.18805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/calvinmccarter/idw-attention">https://github.com/calvinmccarter/idw-attention</a></li>
<li>paper_authors: Calvin McCarter</li>
<li>for: 这篇论文研究了取代透彩积 dot-product 注意力的negative-log of Euclidean distance 的效果。</li>
<li>methods: 这种注意力方式简化为 inverse distance weighting interpolation，并在简单的一层隐藏层网络和vanilla cross-entropy loss中进行训练，用于文本分类问题。</li>
<li>results: 研究发现，使用这种注意力方式可以生成一个包含原型的键矩阵和相应的 logits 的解释网络，并可以通过手动构建的特殊情况 прототипы进行低影响的特殊情况处理。<details>
<summary>Abstract</summary>
We report the effects of replacing the scaled dot-product (within softmax) attention with the negative-log of Euclidean distance. This form of attention simplifies to inverse distance weighting interpolation. Used in simple one hidden layer networks and trained with vanilla cross-entropy loss on classification problems, it tends to produce a key matrix containing prototypes and a value matrix with corresponding logits. We also show that the resulting interpretable networks can be augmented with manually-constructed prototypes to perform low-impact handling of special cases.
</details>
<details>
<summary>摘要</summary>
我们报告了在扩展点积（在满意函数中）中使用负欧几丁度的效果。这种注意力的形式简化为对距离权重 interpolating。在简单的一个隐藏层网络中使用，并使用普通的极值损失函数进行训练，它通常会生成一个包含原型的键矩阵和相应的 logits 矩阵。我们还示出了使用手动构造的特殊情况扩展的可行性，以便实现低影响的特殊情况处理。Note: "扩展点积" in Chinese is "扩展点积" (kuòzhè dòngshí), and "负欧几丁度" is "负欧几丁度" (fùōujìtiànduō).
</details></li>
</ul>
<hr>
<h2 id="Weakly-Coupled-Deep-Q-Networks"><a href="#Weakly-Coupled-Deep-Q-Networks" class="headerlink" title="Weakly Coupled Deep Q-Networks"></a>Weakly Coupled Deep Q-Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18803">http://arxiv.org/abs/2310.18803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibrahim El Shar, Daniel R. Jiang</li>
<li>for: 增强深度强化学习算法的性能在受约非常小的 Markov决策过程（WCMDP）中。</li>
<li>methods: 使用单一网络训练多个独立的 DQN “子代理”，每个子代理专门处理一个子问题，然后将其解决结果组合成最佳动作值的上界，以引导主 DQN 代理向优化尝试。</li>
<li>results: 在有多达 10 个子问题、3^10 个总动作和连续状态空间的设置下，与 DQN 和相关技术相比，WCDQN 在数值实验中显示更快的收敛速度。<details>
<summary>Abstract</summary>
We propose weakly coupled deep Q-networks (WCDQN), a novel deep reinforcement learning algorithm that enhances performance in a class of structured problems called weakly coupled Markov decision processes (WCMDP). WCMDPs consist of multiple independent subproblems connected by an action space constraint, which is a structural property that frequently emerges in practice. Despite this appealing structure, WCMDPs quickly become intractable as the number of subproblems grows. WCDQN employs a single network to train multiple DQN "subagents", one for each subproblem, and then combine their solutions to establish an upper bound on the optimal action value. This guides the main DQN agent towards optimality. We show that the tabular version, weakly coupled Q-learning (WCQL), converges almost surely to the optimal action value. Numerical experiments show faster convergence compared to DQN and related techniques in settings with as many as 10 subproblems, $3^{10}$ total actions, and a continuous state space.
</details>
<details>
<summary>摘要</summary>
我们提出了弱连结深度Q网络（WCDQN），一种新的深度训练学习算法，它在受限构造问题（WCMDP）中提高表现。WCMDP包含多个独立的子问题，连接在动作空间约束上，这是实际中常见的结构性特征。然而，随着子问题的数量增加，WCMDP很快就会变得无法应对。WCDQN使用单一网络来训练多个DQN“子代”，每个子代针对每个子问题进行训练，然后结合其解决方案以建立最佳动作值的Upper bound。这导引主DQN代向最佳解决方案。我们证明了这个 Tabular 版本，弱连结Q学习（WCQL），会逐渐趋向最佳动作值，并且在包含多达10个子问题、3^{10}个总动作和连续状态空间的numerical实验中比DQN和相关技术更快地趋向最佳解决方案。
</details></li>
</ul>
<hr>
<h2 id="A-Competitive-Algorithm-for-Agnostic-Active-Learning"><a href="#A-Competitive-Algorithm-for-Agnostic-Active-Learning" class="headerlink" title="A Competitive Algorithm for Agnostic Active Learning"></a>A Competitive Algorithm for Agnostic Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18786">http://arxiv.org/abs/2310.18786</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Price, Yihan Zhou</li>
<li>for: 这种纸是用于研究agnostic active learning的最佳算法，具体来说是用于任何二分类假设集$H$和分布$D_X$ over $X$中的输入。</li>
<li>methods: 我们采用了一种不同于现有的方法的approach，即使用splitting-based方法，以实现在$O(m^* \log |H|)$ queries中达到$O(\eta)$ error的目标。</li>
<li>results: 我们的算法可以与最佳算法匹配，即使在某些输入上有NP困难，我们的算法可以在$O(\log |H|)$ overhead下达到$O(\eta)$ error。<details>
<summary>Abstract</summary>
For some hypothesis classes and input distributions, active agnostic learning needs exponentially fewer samples than passive learning; for other classes and distributions, it offers little to no improvement. The most popular algorithms for agnostic active learning express their performance in terms of a parameter called the disagreement coefficient, but it is known that these algorithms are inefficient on some inputs.   We take a different approach to agnostic active learning, getting an algorithm that is competitive with the optimal algorithm for any binary hypothesis class $H$ and distribution $D_X$ over $X$. In particular, if any algorithm can use $m^*$ queries to get $O(\eta)$ error, then our algorithm uses $O(m^* \log |H|)$ queries to get $O(\eta)$ error. Our algorithm lies in the vein of the splitting-based approach of Dasgupta [2004], which gets a similar result for the realizable ($\eta = 0$) setting.   We also show that it is NP-hard to do better than our algorithm's $O(\log |H|)$ overhead in general.
</details>
<details>
<summary>摘要</summary>
For some hypothesis classes and input distributions, active agnostic learning needs exponentially fewer samples than passive learning; for other classes and distributions, it offers little to no improvement. The most popular algorithms for agnostic active learning express their performance in terms of a parameter called the disagreement coefficient, but it is known that these algorithms are inefficient on some inputs.  We take a different approach to agnostic active learning, getting an algorithm that is competitive with the optimal algorithm for any binary hypothesis class $H$ and distribution $D_X$ over $X$. In particular, if any algorithm can use $m^*$ queries to get $O(\eta)$ error, then our algorithm uses $O(m^* \log |H|)$ queries to get $O(\eta)$ error. Our algorithm is in the same vein as the splitting-based approach of Dasgupta [2004], which gets a similar result for the realizable ($\eta = 0$) setting.   We also prove that it is NP-hard to do better than our algorithm's $O(\log |H|)$ overhead in general.Note: The text has been translated using Simplified Chinese characters.
</details></li>
</ul>
<hr>
<h2 id="High-probability-Convergence-Bounds-for-Nonlinear-Stochastic-Gradient-Descent-Under-Heavy-tailed-Noise"><a href="#High-probability-Convergence-Bounds-for-Nonlinear-Stochastic-Gradient-Descent-Under-Heavy-tailed-Noise" class="headerlink" title="High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise"></a>High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18784">http://arxiv.org/abs/2310.18784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aleksandar Armacki, Pranay Sharma, Gauri Joshi, Dragana Bajovic, Dusan Jakovetic, Soummya Kar</li>
<li>for: 本文研究了一种广泛的非线性SGD方法的收敛性。</li>
<li>methods: 本文使用了高probability下的收敛性 bounds，并且可以涵盖大多数现有的非线性SGD方法，如clipping、normalization和quantization。</li>
<li>results: 对具有 lipschitz continuous 的梯度的强转换函数，本文证明了logarithmic的依赖于失败概率，而且可以在heavy-tailed noise下工作。此外，本文的结果比现有的结果更加广泛，可以涵盖更多的非线性SGD方法和不同的噪声分布。<details>
<summary>Abstract</summary>
Several recent works have studied the convergence \textit{in high probability} of stochastic gradient descent (SGD) and its clipped variant. Compared to vanilla SGD, clipped SGD is practically more stable and has the additional theoretical benefit of logarithmic dependence on the failure probability. However, the convergence of other practical nonlinear variants of SGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved communication efficiency or accelerated convergence is much less understood. In this work, we study the convergence bounds \textit{in high probability} of a broad class of nonlinear SGD methods. For strongly convex loss functions with Lipschitz continuous gradients, we prove a logarithmic dependence on the failure probability, even when the noise is heavy-tailed. Strictly more general than the results for clipped SGD, our results hold for any nonlinearity with bounded (component-wise or joint) outputs, such as clipping, normalization, and quantization. Further, existing results with heavy-tailed noise assume bounded $\eta$-th central moments, with $\eta \in (1,2]$. In contrast, our refined analysis works even for $\eta=1$, strictly relaxing the noise moment assumptions in the literature.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Data-driven-Recommendation-Framework-for-Optimal-Walker-Designs"><a href="#A-Data-driven-Recommendation-Framework-for-Optimal-Walker-Designs" class="headerlink" title="A Data-driven Recommendation Framework for Optimal Walker Designs"></a>A Data-driven Recommendation Framework for Optimal Walker Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18772">http://arxiv.org/abs/2310.18772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Advaith Narayanan</li>
<li>for: 这篇论文旨在优化医疗步行器，以提高临床恢复和生理治疗下肢体的功能。</li>
<li>methods: 该论文使用自动化机器学习模型和栅Stacked-Ensemble方法，以优化医疗步行器的设计。同时，该论文还提供了大量的 Parametric walker 设计数据，以便训练预测模型。</li>
<li>results: 该论文的结果表明，通过使用自动化机器学习模型和多目标优化算法，可以实现高性能的医疗步行器设计。论文还提供了一些可能的医疗步行器设计，其中一些设计可以减轻重量达30%，同时提高结构稳定性和完整性。<details>
<summary>Abstract</summary>
The rapidly advancing fields of statistical modeling and machine learning have significantly enhanced data-driven design and optimization. This paper focuses on leveraging these design algorithms to optimize a medical walker, an integral part of gait rehabilitation and physiological therapy of the lower extremities. To achieve the desirable qualities of a walker, we train a predictive machine-learning model to identify trade-offs between performance objectives, thus enabling the use of efficient optimization algorithms. To do this, we use an Automated Machine Learning model utilizing a stacked-ensemble approach shown to outperform traditional ML models. However, training a predictive model requires vast amounts of data for accuracy. Due to limited publicly available walker designs, this paper presents a dataset of more than 5,000 parametric walker designs with performance values to assess mass, structural integrity, and stability. These performance values include displacement vectors for the given load case, stress coefficients, mass, and other physical properties. We also introduce a novel method of systematically calculating the stability index of a walker. We use MultiObjective Counterfactuals for Design (MCD), a novel genetic-based optimization algorithm, to explore the diverse 16-dimensional design space and search for high-performing designs based on numerous objectives. This paper presents potential walker designs that demonstrate up to a 30% mass reduction while increasing structural stability and integrity. This work takes a step toward the improved development of assistive mobility devices.
</details>
<details>
<summary>摘要</summary>
“随着统计模型和机器学习的快速进步，数据驱动设计和优化技术已经得到了很大的提高。本文将focus on 使用这些设计算法来优化医疗杆子，它是距离股体重abilitation和物理治疗的重要部分。为了实现杆子的欲望性能，我们将使用预测机器学习模型，以识别表现目标之间的贸易，并启用高效的优化算法。我们使用了自动化机器学习模型，使用堆叠合 ensemble 方法，已经被证明可以超越传统机器学习模型。然而，训练预测模型需要巨量的数据，以确保准确性。由于有限的公开可用的杆子设计，本文提供了超过5,000个 Parametric 杆子设计，并且包含表现值，以评估杆子的质量、结构完整性和稳定性。我们还引入了一新的稳定指数计算方法。我们使用多目标Counterfactuals for Design (MCD) ，一种新的基因型数据分析方法，来探索16个维度的设计空间，寻找高性能的设计。本文显示了可能的杆子设计，证明了可以降低30%的质量，同时增加结构的稳定性和完整性。这个工作为伤健移动设备的改进做出了一步。”
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Semi-Supervised-Imbalanced-Node-Classification-from-Bias-Variance-Decomposition"><a href="#Rethinking-Semi-Supervised-Imbalanced-Node-Classification-from-Bias-Variance-Decomposition" class="headerlink" title="Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition"></a>Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18765">http://arxiv.org/abs/2310.18765</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanliang3612/revar">https://github.com/yanliang3612/revar</a></li>
<li>paper_authors: Divin Yan, Gengchen Wei, Chen Yang, Shengzhong Zhang, Zengfeng Huang</li>
<li>for:  Addressing the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data.</li>
<li>methods:  Integrates imbalanced node classification and Bias-Variance Decomposition, leverages graph augmentation technique to estimate the variance, and designs a regularization term to alleviate the impact of imbalance.</li>
<li>results:  Outperforms state-of-the-art methods in various imbalanced scenarios, providing a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs.<details>
<summary>Abstract</summary>
This paper introduces a new approach to address the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data. Our approach integrates imbalanced node classification and Bias-Variance Decomposition, establishing a theoretical framework that closely relates data imbalance to model variance. We also leverage graph augmentation technique to estimate the variance, and design a regularization term to alleviate the impact of imbalance. Exhaustive tests are conducted on multiple benchmarks, including naturally imbalanced datasets and public-split class-imbalanced datasets, demonstrating that our approach outperforms state-of-the-art methods in various imbalanced scenarios. This work provides a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "GNNs" is translated as "图 нейрон网络" (graph neural networks)* "class imbalance" is translated as "类别不均衡" (class imbalance)* "Bias-Variance Decomposition" is translated as "偏差-差异分解" (Bias-Variance Decomposition)* "graph augmentation" is translated as "图补充" (graph augmentation)* "regularization term" is translated as "正则化项" (regularization term)Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form as well.
</details></li>
</ul>
<hr>
<h2 id="Purify-Improving-Diffusion-Purification-with-Advanced-Diffusion-Models-and-Control-of-Randomness"><a href="#Purify-Improving-Diffusion-Purification-with-Advanced-Diffusion-Models-and-Control-of-Randomness" class="headerlink" title="Purify++: Improving Diffusion-Purification with Advanced Diffusion Models and Control of Randomness"></a>Purify++: Improving Diffusion-Purification with Advanced Diffusion Models and Control of Randomness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18762">http://arxiv.org/abs/2310.18762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boya Zhang, Weijian Luo, Zhihua Zhang</li>
<li>for: 防止神经网络分类器受到攻击的安全性研究</li>
<li>methods:  diffusion purification 方法</li>
<li>results: Purify++ 算法提高了对多种攻击方法的防御能力<details>
<summary>Abstract</summary>
Adversarial attacks can mislead neural network classifiers. The defense against adversarial attacks is important for AI safety. Adversarial purification is a family of approaches that defend adversarial attacks with suitable pre-processing. Diffusion models have been shown to be effective for adversarial purification. Despite their success, many aspects of diffusion purification still remain unexplored. In this paper, we investigate and improve upon three limiting designs of diffusion purification: the use of an improved diffusion model, advanced numerical simulation techniques, and optimal control of randomness. Based on our findings, we propose Purify++, a new diffusion purification algorithm that is now the state-of-the-art purification method against several adversarial attacks. Our work presents a systematic exploration of the limits of diffusion purification methods.
</details>
<details>
<summary>摘要</summary>
Adversarial attacks can mislead neural network classifiers. The defense against adversarial attacks is important for AI safety. Adversarial purification is a family of approaches that defend against adversarial attacks with suitable pre-processing. Diffusion models have been shown to be effective for adversarial purification. Despite their success, many aspects of diffusion purification still remain unexplored. In this paper, we investigate and improve upon three limiting designs of diffusion purification: the use of an improved diffusion model, advanced numerical simulation techniques, and optimal control of randomness. Based on our findings, we propose Purify++, a new diffusion purification algorithm that is now the state-of-the-art purification method against several adversarial attacks. Our work presents a systematic exploration of the limits of diffusion purification methods.Here's the translation in Simplified Chinese characters: adversarial attacks 可以诱导 нейрон网络分类器错误。防止 adversarial attacks 是 AI 安全的重要任务。adversarial purification 是一家 approachedefend against adversarial attacks with suitable pre-processing。diffusion models 已经被证明是有效的 adversarial purification 方法。despite their success, many aspects of diffusion purification still remain unexplored。在这篇 paper中，我们investigate 和改进 diffusion purification 的三个限制设计：使用改进的 diffusion model，进阶的数值 simulations 技术，和优化的随机性控制。基于我们的发现，我们提出 Purify++, 一个新的 diffusion purification 算法，现在是 severaldiffusion purification 方法的州际标准。our work 展示了 diffusion purification 方法的系统性探索。
</details></li>
</ul>
<hr>
<h2 id="Optimization-of-utility-based-shortfall-risk-A-non-asymptotic-viewpoint"><a href="#Optimization-of-utility-based-shortfall-risk-A-non-asymptotic-viewpoint" class="headerlink" title="Optimization of utility-based shortfall risk: A non-asymptotic viewpoint"></a>Optimization of utility-based shortfall risk: A non-asymptotic viewpoint</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18743">http://arxiv.org/abs/2310.18743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumedh Gupte, Prashanth L. A., Sanjay P. Bhat</li>
<li>for: 本文研究了金融领域中流量风险的评估和优化问题，具体来说是Utility-based shortfall risk（UBSR）的估计和优化问题。</li>
<li>methods: 本文使用了类型样本平均approximation（SAA）来估计UBSR，并 derive了非尺度性质 bound 的均方差误差。在UBSR优化问题中，本文 derive了UBSR导数的表达式，该表达式是一个期望比率，两个期望都 involve UBSR。使用SAA来 aproximate numerator和denominator中的UBSR，得到一个偏导数估计器。</li>
<li>results: 本文 derive non-尺度性质 bound 表示该偏导数估计器是 asymptotically unbiased。此外，本文还 derive non-尺度性质 bound 表示SG算法的速度减少率。<details>
<summary>Abstract</summary>
We consider the problems of estimation and optimization of utility-based shortfall risk (UBSR), which is a popular risk measure in finance. In the context of UBSR estimation, we derive a non-asymptotic bound on the mean-squared error of the classical sample average approximation (SAA) of UBSR. Next, in the context of UBSR optimization, we derive an expression for the UBSR gradient under a smooth parameterization. This expression is a ratio of expectations, both of which involve the UBSR. We use SAA for the numerator as well as denominator in the UBSR gradient expression to arrive at a biased gradient estimator. We derive non-asymptotic bounds on the estimation error, which show that our gradient estimator is asymptotically unbiased. We incorporate the aforementioned gradient estimator into a stochastic gradient (SG) algorithm for UBSR optimization. Finally, we derive non-asymptotic bounds that quantify the rate of convergence of our SG algorithm for UBSR optimization.
</details>
<details>
<summary>摘要</summary>
我们考虑了金融中流行的价值基础隐没隐危 (UBSR) 的估计和优化问题。在 UBSR 估计上，我们 derivated 一个非对数减少的 bound 为 classical sample average approximation (SAA) 的均方误差。在 UBSR 优化上，我们 derivated 一个表达式，用于 UBSR 的梯度，这个表达式是两个期望的比率，其中一个是 UBSR 的期望值。我们使用 SAA 来计算 numerator 和 denominator 两个部分，从而得到一个偏导数 estimator。我们 derivated 非对数减少的 bounds ，证明了我们的梯度 estimator 是 asymptotically unbiased。最后，我们 incorporated 这个梯度 estimator 到一个随机梯度 (SG) 算法中，并 derivated 非对数减少的 bounds 来评估这个算法的速度传递率。
</details></li>
</ul>
<hr>
<h2 id="Curriculum-Learning-for-Graph-Neural-Networks-Which-Edges-Should-We-Learn-First"><a href="#Curriculum-Learning-for-Graph-Neural-Networks-Which-Edges-Should-We-Learn-First" class="headerlink" title="Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First"></a>Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18735">http://arxiv.org/abs/2310.18735</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rollingstonezz/curriculum_learning_for_gnns">https://github.com/rollingstonezz/curriculum_learning_for_gnns</a></li>
<li>paper_authors: Zheng Zhang, Junxiang Wang, Liang Zhao</li>
<li>For: 本文提出了一种新的课程学习策略，用于逐渐将图数据中的边 integrate 到训练中，以提高图 neural network 的泛化能力和Robustness。* Methods: 本文提出了一种基于课程学习的策略，使用了度量学习策略来衡量边的难度，并逐渐将边添加到训练中，以便学习更好的表示。* Results: 经过EXTENSIVE experiments on nine synthetic datasets and nine real-world datasets, 本文 Demonstrated the strength of the proposed method in improving the generalization ability and robustness of learned representations.<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have achieved great success in representing data with dependencies by recursively propagating and aggregating messages along the edges. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing GNNs may lead to suboptimal learned representations because they usually treat every edge in the graph equally. On the other hand, Curriculum Learning (CL), which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability and robustness of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, existing CL strategies are designed for independent data samples and cannot trivially generalize to handle data dependencies. To address these issues, we propose a novel CL strategy to gradually incorporate more edges into training according to their difficulty from easy to hard, where the degree of difficulty is measured by how well the edges are expected given the model training status. We demonstrate the strength of our proposed method in improving the generalization ability and robustness of learned representations through extensive experiments on nine synthetic datasets and nine real-world datasets. The code for our proposed method is available at https://github.com/rollingstonezz/Curriculum_learning_for_GNNs.
</details>
<details>
<summary>摘要</summary>
graph neural networks (GNNs) 图神网络已经取得了很大的成功，通过 recursively propagating 和 aggregating 消息来表示具有依赖关系的数据。然而，实际世界中的图 often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks.因此，现有的 GNN 可能会导致学习的表示不佳，因为它们通常对每个图边进行平等的处理。在另一个面向，curriculum learning (CL)，模仿人类学习的原理，可以在训练过程中逐渐从易到更加复杂的样本中学习，从而提高学习的普适性和鲁棒性。然而，现有的 CL 策略是为独立的数据样本设计的，无法直接扩展到处理数据依赖关系。为解决这些问题，我们提出了一种新的 CL 策略，通过度量图边的难度从易到更加困难地慢慢地包含更多的图边到训练中，其中图边的难度通过模型训练状态来评估。我们通过对九个Synthetic数据集和九个实际世界数据集进行了广泛的实验，证明了我们的提议的方法能够提高学习的普适性和鲁棒性。code  для我们的提议方法可以在 https://github.com/rollingstonezz/Curriculum_learning_for_GNNs 找到。
</details></li>
</ul>
<hr>
<h2 id="Latent-class-analysis-by-regularized-spectral-clustering"><a href="#Latent-class-analysis-by-regularized-spectral-clustering" class="headerlink" title="Latent class analysis by regularized spectral clustering"></a>Latent class analysis by regularized spectral clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18727">http://arxiv.org/abs/2310.18727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huan Qing</li>
<li>for: 这篇论文的目的是提出两种新的算法来估计 categorical 数据中的潜在类型模型。</li>
<li>methods: 这两种算法都基于一个新定义的规范化拉普拉斯矩阵，计算从响应矩阵中获得的。作者提供了这些算法的理论收敛速率，并证明了它们在某些轻度的条件下稳定地生成了一致的潜在类型分析。</li>
<li>results: 作者通过了广泛的 simulations 实验来证明算法的效率和准确性，并在实际的 categorical 数据上应用了这些算法，获得了有前途的结果。<details>
<summary>Abstract</summary>
The latent class model is a powerful tool for identifying latent classes within populations that share common characteristics for categorical data in social, psychological, and behavioral sciences. In this article, we propose two new algorithms to estimate a latent class model for categorical data. Our algorithms are developed by using a newly defined regularized Laplacian matrix calculated from the response matrix. We provide theoretical convergence rates of our algorithms by considering a sparsity parameter and show that our algorithms stably yield consistent latent class analysis under mild conditions. Additionally, we propose a metric to capture the strength of latent class analysis and several procedures designed based on this metric to infer how many latent classes one should use for real-world categorical data. The efficiency and accuracy of our algorithms are verified by extensive simulated experiments, and we further apply our algorithms to real-world categorical data with promising results.
</details>
<details>
<summary>摘要</summary>
“拉丁类模型是一种强大的工具，用于在人口中找到共同特征的分类数据的社会、心理和行为科学中。在这篇文章中，我们提出了两种新的算法，用于估计拉丁类模型。我们的算法基于响应矩阵中定义的新的规范化拉普拉斯矩阵。我们提供了对我们的算法的理论收敛率，并证明我们的算法在轻度条件下稳定地生成了一致的拉丁类分析。此外，我们还提出了一个用于捕捉拉丁类分析的强度的度量，以及基于这个度量的几种过程，用于在实际中的分类数据中决定拉丁类的数量。我们的算法的效率和准确性通过了广泛的模拟实验，并在实际中应用到了分类数据的成功。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="On-the-Accuracy-of-Hotelling-Type-Asymmetric-Tensor-Deflation-A-Random-Tensor-Analysis"><a href="#On-the-Accuracy-of-Hotelling-Type-Asymmetric-Tensor-Deflation-A-Random-Tensor-Analysis" class="headerlink" title="On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random Tensor Analysis"></a>On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random Tensor Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18717">http://arxiv.org/abs/2310.18717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed El Amine Seddik, Maxime Guillaud, Alexis Decurninge, José Henrique de Morais Goulart</li>
<li>For: This paper studies the asymptotic behavior of Hotelling-type tensor deflation in the presence of noise, specifically in the regime of large tensor dimensions.* Methods: The paper uses recent advances in random tensor theory to analytically characterize the estimated singular values and the alignment of estimated and true singular vectors at each step of the deflation procedure.* Results: The paper shows that the estimated singular values and the alignments between the estimated and true rank-1 signal components can be used to construct estimators of the signal-to-noise ratios and the alignments between the estimated and true rank-1 signal components.<details>
<summary>Abstract</summary>
This work introduces an asymptotic study of Hotelling-type tensor deflation in the presence of noise, in the regime of large tensor dimensions. Specifically, we consider a low-rank asymmetric tensor model of the form $\sum_{i=1}^r \beta_i{\mathcal{A}_i + {\mathcal{W}$ where $\beta_i\geq 0$ and the ${\mathcal{A}_i$'s are unit-norm rank-one tensors such that $\left| \langle {\mathcal{A}_i, {\mathcal{A}_j \rangle \right| \in [0, 1]$ for $i\neq j$ and ${\mathcal{W}$ is an additive noise term. Assuming that the dominant components are successively estimated from the noisy observation and subsequently subtracted, we leverage recent advances in random tensor theory in the regime of asymptotically large tensor dimensions to analytically characterize the estimated singular values and the alignment of estimated and true singular vectors at each step of the deflation procedure. Furthermore, this result can be used to construct estimators of the signal-to-noise ratios $\beta_i$ and the alignments between the estimated and true rank-1 signal components.
</details>
<details>
<summary>摘要</summary>
The proposed method involves successively estimating the dominant components of the tensor and subtracting them from the noisy observation. By leveraging recent advances in random tensor theory, the paper analytically characterizes the estimated singular values and the alignment of estimated and true singular vectors at each step of the deflation procedure.Furthermore, the results can be used to construct estimators of the signal-to-noise ratios $\beta_i$ and the alignments between the estimated and true rank-1 signal components. This study provides a comprehensive understanding of the behavior of Hotelling-type tensor deflation in the presence of noise and its applications in signal processing and machine learning.In Simplified Chinese, the text can be translated as:这个研究介绍了一种幂等式抑制方法在噪声存在的情况下进行研究，具体来说是在大tensor维度下进行研究。这个模型是一个低维偏 asymmetric tensor的形式，具体来说是 $\sum_{i=1}^r \beta_i{\mathcal{A}_i + {\mathcal{W}$，其中 $\beta_i\geq 0$ 和 $\left| \langle {\mathcal{A}_i, {\mathcal{A}_j \rangle \right| \in [0, 1]$  для $i\neq j$。噪声是一个加itive的。该方法假设在噪声观测下，逐步估计主要组分，并将其从噪声观测中 subtract。通过利用最近的幂等式理论，这篇论文分析了在噪声存在下的逐步估计方法的特性。此外，这些结果还可以用于构建噪声比例和真实维度方向的估计器。这种方法的应用包括信号处理和机器学习等领域。通过这篇论文，我们可以更好地理解幂等式抑制方法在噪声存在下的行为，以及其在实际应用中的可行性和有效性。
</details></li>
</ul>
<hr>
<h2 id="Laplacian-Canonization-A-Minimalist-Approach-to-Sign-and-Basis-Invariant-Spectral-Embedding"><a href="#Laplacian-Canonization-A-Minimalist-Approach-to-Sign-and-Basis-Invariant-Spectral-Embedding" class="headerlink" title="Laplacian Canonization: A Minimalist Approach to Sign and Basis Invariant Spectral Embedding"></a>Laplacian Canonization: A Minimalist Approach to Sign and Basis Invariant Spectral Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18716">http://arxiv.org/abs/2310.18716</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pku-ml/laplaciancanonization">https://github.com/pku-ml/laplaciancanonization</a></li>
<li>paper_authors: Jiangyan Ma, Yifei Wang, Yisen Wang</li>
<li>for: 提高 Graph Transformers 的效果，解决spectral embedding在理论上的缺陷</li>
<li>methods: 直接找到 Laplacian Canonization（LC），一种轻量级的预处理方法，可以应用于任何现有的 GNN</li>
<li>results: MAP 算法可以成功 canonize 超过 90% 的 eigenvectors，并在实验中表现出色，与现有方法相比带来较少的计算开销。<details>
<summary>Abstract</summary>
Spectral embedding is a powerful graph embedding technique that has received a lot of attention recently due to its effectiveness on Graph Transformers. However, from a theoretical perspective, the universal expressive power of spectral embedding comes at the price of losing two important invariance properties of graphs, sign and basis invariance, which also limits its effectiveness on graph data. To remedy this issue, many previous methods developed costly approaches to learn new invariants and suffer from high computation complexity. In this work, we explore a minimal approach that resolves the ambiguity issues by directly finding canonical directions for the eigenvectors, named Laplacian Canonization (LC). As a pure pre-processing method, LC is light-weighted and can be applied to any existing GNNs. We provide a thorough investigation, from theory to algorithm, on this approach, and discover an efficient algorithm named Maximal Axis Projection (MAP) that works for both sign and basis invariance and successfully canonizes more than 90% of all eigenvectors. Experiments on real-world benchmark datasets like ZINC, MOLTOX21, and MOLPCBA show that MAP consistently outperforms existing methods while bringing minimal computation overhead. Code is available at https://github.com/PKU-ML/LaplacianCanonization.
</details>
<details>
<summary>摘要</summary>
干扰 embedding 是一种强大的图 embedding 技术，在图transformer 中得到了很多关注，但从理论角度来看，它的通用表达力来到了两个重要的对称性问题的价格，即标志对称性和基准对称性，这也限制了它在图数据上的效果。为了解决这个问题，许多前一代的方法开发了昂贵的方法来学习新的对称性，并且受到高计算复杂度的困扰。在这种情况下，我们 explore 一种最小的方法，即laplacian canonization (LC)，它可以直接找到图laplacian 的可 canonical 方向。作为一种纯粹的预处理方法，LC 轻量级，可以应用于任何现有的 GNNs。我们提供了一份 thorought 的调查，从理论到算法，对这种方法，并发现了一种高效的算法 named Maximal Axis Projection (MAP)，它可以实现标志对称性和基准对称性，并成功 canonize 超过 90% 的所有 eigenvectors。实验结果表明，MAP 在实际 benchmark 数据上（如 ZINC、MOLTOX21 和 MOLPCBA） consistently 超过现有方法，同时带来最小的计算开销。代码可以在 https://github.com/PKU-ML/LaplacianCanonization 上找到。
</details></li>
</ul>
<hr>
<h2 id="Episodic-Multi-Task-Learning-with-Heterogeneous-Neural-Processes"><a href="#Episodic-Multi-Task-Learning-with-Heterogeneous-Neural-Processes" class="headerlink" title="Episodic Multi-Task Learning with Heterogeneous Neural Processes"></a>Episodic Multi-Task Learning with Heterogeneous Neural Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18713">http://arxiv.org/abs/2310.18713</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/autumn9999/hnps">https://github.com/autumn9999/hnps</a></li>
<li>paper_authors: Jiayi Shen, Xiantong Zhen, Qi, Wang, Marcel Worring</li>
<li>for: 本研究旨在解决多任务学习中的数据不足问题，具体来说是在 episodic 训练设置下利用任务之间的不同信息和 episoden 中的元知识，以有效地处理每个任务。</li>
<li>methods: 我们开发了异 heterogeneous Neural Processes (HNPs) 来解决这个问题，它们在层次 Bayes 框架中有效地利用先前经验作为元知识，捕捉任务之间的相互关系，从而 mitigate 数据不足。 transformer 结构的推理模块也是为了快速地进行元知识和任务相关性的推理。</li>
<li>results: 实验结果表明我们的提案的 HNPs 在比较基eline的情况下表现出色，并且对减少数据不足的影响进行了证明。 简化 Studios 中的结果也验证了我们设计的推理模块的有效性。<details>
<summary>Abstract</summary>
This paper focuses on the data-insufficiency problem in multi-task learning within an episodic training setup. Specifically, we explore the potential of heterogeneous information across tasks and meta-knowledge among episodes to effectively tackle each task with limited data. Existing meta-learning methods often fail to take advantage of crucial heterogeneous information in a single episode, while multi-task learning models neglect reusing experience from earlier episodes. To address the problem of insufficient data, we develop Heterogeneous Neural Processes (HNPs) for the episodic multi-task setup. Within the framework of hierarchical Bayes, HNPs effectively capitalize on prior experiences as meta-knowledge and capture task-relatedness among heterogeneous tasks, mitigating data-insufficiency. Meanwhile, transformer-structured inference modules are designed to enable efficient inferences toward meta-knowledge and task-relatedness. In this way, HNPs can learn more powerful functional priors for adapting to novel heterogeneous tasks in each meta-test episode. Experimental results show the superior performance of the proposed HNPs over typical baselines, and ablation studies verify the effectiveness of the designed inference modules.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ALERTA-Net-A-Temporal-Distance-Aware-Recurrent-Networks-for-Stock-Movement-and-Volatility-Prediction"><a href="#ALERTA-Net-A-Temporal-Distance-Aware-Recurrent-Networks-for-Stock-Movement-and-Volatility-Prediction" class="headerlink" title="ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock Movement and Volatility Prediction"></a>ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock Movement and Volatility Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18706">http://arxiv.org/abs/2310.18706</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hao1zhao/alerta-net">https://github.com/hao1zhao/alerta-net</a></li>
<li>paper_authors: Shengkun Wang, YangXiao Bai, Kaiqun Fu, Linhan Wang, Chang-Tien Lu, Taoran Ji</li>
<li>for: 预测股市运动和不稳定性	+ 投资者和 policymakers 都需要准确预测股市，作为经济健康指标</li>
<li>methods:  integrate sentiment analysis, macroeconomic indicators, search engine data, and historical prices within a multi-attention deep learning model	+ 利用社交媒体数据，具有丰富的公众情感信息，以增强股市预测的准确性</li>
<li>results: state-of-the-art performance using a dataset specifically curated for predicting stock market movements and volatility	+ 我们的提议模型在使用自定义的数据集后，实现了股市运动和不稳定性预测的状态oke-of-the-art表现<details>
<summary>Abstract</summary>
For both investors and policymakers, forecasting the stock market is essential as it serves as an indicator of economic well-being. To this end, we harness the power of social media data, a rich source of public sentiment, to enhance the accuracy of stock market predictions. Diverging from conventional methods, we pioneer an approach that integrates sentiment analysis, macroeconomic indicators, search engine data, and historical prices within a multi-attention deep learning model, masterfully decoding the complex patterns inherent in the data. We showcase the state-of-the-art performance of our proposed model using a dataset, specifically curated by us, for predicting stock market movements and volatility.
</details>
<details>
<summary>摘要</summary>
für both investors und policymakers ist die prognose des aktienmarktes essenziell, da er als indicator für die wirtschaftliche well-being dient. um diese herausforderung zu meistern, nutzen wir die kraft von sozialen medien-daten, ein reiches quell von öffentlicher meinung, um die genauigkeit der aktienmarkt-vorhersagen zu verbessern. im Gegensatz zu conventional methods, entwickeln wir eine ansprechung, die sentiment-analyse, makroökonomische indicatoren, suchmaschine-daten und historische preise in einem multi-attention-tiefen lernmodell integriert, das die komplexen muster im data meisterlich decodiert. wir zeigen die state-of-the-art-leistung unseres vorgeschlagenen modells anhand einer datenbasis, die von uns speziell für die vorhersage von aktienmarkt-bewegungen und -volatilität sammeln.
</details></li>
</ul>
<hr>
<h2 id="Explaining-by-Imitating-Understanding-Decisions-by-Interpretable-Policy-Learning"><a href="#Explaining-by-Imitating-Understanding-Decisions-by-Interpretable-Policy-Learning" class="headerlink" title="Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning"></a>Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.19831">http://arxiv.org/abs/2310.19831</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alihanhyk/interpole">https://github.com/alihanhyk/interpole</a></li>
<li>paper_authors: Alihan Hüyük, Daniel Jarrett, Mihaela van der Schaar</li>
<li>for: 这个论文是为了理解人类决策行为的概念模型，以便提高决策过程的透明度和负责任性。</li>
<li>methods: 这个论文提出了一种基于 bayesian 方法的可解释政策学习方法（Interpole），可以同时估计决策者的（可能偏袋）信念更新过程和决策策略。</li>
<li>results: 通过在模拟和真实世界数据上进行实验，论文示出了该方法的可能作为决策过程的调查、评估和理解的潜在价值。<details>
<summary>Abstract</summary>
Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker's policy is challenging -- with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision-making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning ("Interpole") that jointly estimates an agent's (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer's disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, quantifying, and understanding human decision-making behavior.
</details>
<details>
<summary>摘要</summary>
理解人类行为从观察数据中是决策过程中的关键，以确保决策过程中的透明度和负责任。在实际场景中，如医疗行业，模型决策者的政策非常困难，因为无法访问基础状态、环境动力学不明确、无法进行实际实验。我们希望通过学习数据驱动的方法学习决策行为，以满足以下三个关键需求：1. 具有透明度设计，以便理解决策过程中的决策因素。2. 可以处理部分可见性，以适应决策过程中的不同情况。3. 完全没有线上运行，以便在决策过程中进行实时调整。为了满足这些需求，我们提出了一种新的模型基于概率方法，即“Interpole”，可以同时估算决策者的（可能偏见的）信念更新过程和（可能不优的）信念行为映射。通过在模拟和实际数据上进行实验，我们证明了我们的方法可以作为决策过程的调查、评估和理解人类决策行为的调查工具。
</details></li>
</ul>
<hr>
<h2 id="Towards-Combinatorial-Generalization-for-Catalysts-A-Kohn-Sham-Charge-Density-Approach"><a href="#Towards-Combinatorial-Generalization-for-Catalysts-A-Kohn-Sham-Charge-Density-Approach" class="headerlink" title="Towards Combinatorial Generalization for Catalysts: A Kohn-Sham Charge-Density Approach"></a>Towards Combinatorial Generalization for Catalysts: A Kohn-Sham Charge-Density Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18702">http://arxiv.org/abs/2310.18702</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ppope/rho-learn">https://github.com/ppope/rho-learn</a></li>
<li>paper_authors: Phillip Pope, David Jacobs</li>
<li>for: 本研究旨在探讨一种基于点wise学习的Kohn-Sham充电密度模型，以实现对新材料的预测和设计。</li>
<li>methods: 本研究使用了点wise学习方法，学习了 bulk catalysts 的充电密度，并在新的材料结构中进行了探索和预测。</li>
<li>results: 研究发现，使用点wise学习方法可以实现对新材料的预测和设计，并且可以在多种元素组合下实现 combinatorial 泛化。测试结果显示，超过 80% 的二元和三元测试样本在使用点wise学习方法下可以更快地达到稳定状态，相比标准基线下降减13%的迭代次数，这可能是独立的兴趣点。<details>
<summary>Abstract</summary>
The Kohn-Sham equations underlie many important applications such as the discovery of new catalysts. Recent machine learning work on catalyst modeling has focused on prediction of the energy, but has so far not yet demonstrated significant out-of-distribution generalization. Here we investigate another approach based on the pointwise learning of the Kohn-Sham charge-density. On a new dataset of bulk catalysts with charge densities, we show density models can generalize to new structures with combinations of elements not seen at train time, a form of combinatorial generalization. We show that over 80% of binary and ternary test cases achieve faster convergence than standard baselines in Density Functional Theory, amounting to an average reduction of 13% in the number of iterations required to reach convergence, which may be of independent interest. Our results suggest that density learning is a viable alternative, trading greater inference costs for a step towards combinatorial generalization, a key property for applications.
</details>
<details>
<summary>摘要</summary>
金ohn-Sham方程在许多重要应用中发挥重要作用，如新 catalyst 的发现。现代机器学习方法在 catalyst 模型化中的 Prediction of energy 方面已经受到了重点研究，但是迄今为止并没有显示出significant out-of-distribution generalization。我们在这里 investigate 一种基于点wise learning of Kohn-Sham charge-density 的方法。使用新的 bulk catalysts with charge densities 数据集，我们显示了 density models 可以generalize 到新的结构，包括元素的组合不同于训练时间，这种 combinatorial generalization。我们表明了超过 80% 的 binary 和 ternary test cases 在 Density Functional Theory 中比标准基elines 更快 converges，平均降低了13%的迭代次数，这可能是独立的 interesseting。我们的结果表明了 density learning 是一种可行的alternative，通过更大的推理成本换取了 combinatorial generalization，一种重要的应用特性。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Algorithms-for-Generalized-Linear-Bandits-with-Heavy-tailed-Rewards"><a href="#Efficient-Algorithms-for-Generalized-Linear-Bandits-with-Heavy-tailed-Rewards" class="headerlink" title="Efficient Algorithms for Generalized Linear Bandits with Heavy-tailed Rewards"></a>Efficient Algorithms for Generalized Linear Bandits with Heavy-tailed Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18701">http://arxiv.org/abs/2310.18701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Xue, Yimu Wang, Yuanyu Wan, Jinfeng Yi, Lijun Zhang</li>
<li>For:  investigate the problem of generalized linear bandits with heavy-tailed rewards, and propose two novel algorithms based on truncation and mean of medians to address this issue.* Methods:  propose two algorithms, one based on truncation and the other based on mean of medians, to achieve an almost optimal regret bound of $\widetilde{O}(dT^{\frac{1}{1+\epsilon})$ with online learning support and lower computational complexity.* Results:  improve the regret bounds by a logarithmic factor compared to existing algorithms when $\epsilon&#x3D;1$, and confirm the merits of the proposed algorithms through numerical experimental results.<details>
<summary>Abstract</summary>
This paper investigates the problem of generalized linear bandits with heavy-tailed rewards, whose $(1+\epsilon)$-th moment is bounded for some $\epsilon\in (0,1]$. Although there exist methods for generalized linear bandits, most of them focus on bounded or sub-Gaussian rewards and are not well-suited for many real-world scenarios, such as financial markets and web-advertising. To address this issue, we propose two novel algorithms based on truncation and mean of medians. These algorithms achieve an almost optimal regret bound of $\widetilde{O}(dT^{\frac{1}{1+\epsilon})$, where $d$ is the dimension of contextual information and $T$ is the time horizon. Our truncation-based algorithm supports online learning, distinguishing it from existing truncation-based approaches. Additionally, our mean-of-medians-based algorithm requires only $O(\log T)$ rewards and one estimator per epoch, making it more practical. Moreover, our algorithms improve the regret bounds by a logarithmic factor compared to existing algorithms when $\epsilon=1$. Numerical experimental results confirm the merits of our algorithms.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Clairvoyance-A-Pipeline-Toolkit-for-Medical-Time-Series"><a href="#Clairvoyance-A-Pipeline-Toolkit-for-Medical-Time-Series" class="headerlink" title="Clairvoyance: A Pipeline Toolkit for Medical Time Series"></a>Clairvoyance: A Pipeline Toolkit for Medical Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18688">http://arxiv.org/abs/2310.18688</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vanderschaarlab/clairvoyance">https://github.com/vanderschaarlab/clairvoyance</a></li>
<li>paper_authors: Daniel Jarrett, Jinsung Yoon, Ioana Bica, Zhaozhi Qian, Ari Ercole, Mihaela van der Schaar</li>
<li>for: 这个研究旨在提供一个统一的、端到端的、自动机器学习（AutoML）友好的数据驱动医疗决策支持系统，以便在实际医疗过程中与患者互动，提供适应性强的预测和决策支持。</li>
<li>methods: 这个系统使用了许多Machine Learning（ML）技术，包括数据预processing、缺失数据填充、特征选择、预测和不确定性估计等。</li>
<li>results: 这个系统可以在实际医疗应用中实现高度自动化的数据驱动医疗决策支持，并且可以在不同的医疗设置中进行适应性强的预测和决策支持。<details>
<summary>Abstract</summary>
Time-series learning is the bread and butter of data-driven *clinical decision support*, and the recent explosion in ML research has demonstrated great potential in various healthcare settings. At the same time, medical time-series problems in the wild are challenging due to their highly *composite* nature: They entail design choices and interactions among components that preprocess data, impute missing values, select features, issue predictions, estimate uncertainty, and interpret models. Despite exponential growth in electronic patient data, there is a remarkable gap between the potential and realized utilization of ML for clinical research and decision support. In particular, orchestrating a real-world project lifecycle poses challenges in engineering (i.e. hard to build), evaluation (i.e. hard to assess), and efficiency (i.e. hard to optimize). Designed to address these issues simultaneously, Clairvoyance proposes a unified, end-to-end, autoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical standard, and (iii) interface for optimization. Our ultimate goal lies in facilitating transparent and reproducible experimentation with complex inference workflows, providing integrated pathways for (1) personalized prediction, (2) treatment-effect estimation, and (3) information acquisition. Through illustrative examples on real-world data in outpatient, general wards, and intensive-care settings, we illustrate the applicability of the pipeline paradigm on core tasks in the healthcare journey. To the best of our knowledge, Clairvoyance is the first to demonstrate viability of a comprehensive and automatable pipeline for clinical time-series ML.
</details>
<details>
<summary>摘要</summary>
时间序列学习是医疗数据驱动的严重症状支持的基础，最近几年的机器学习研究表明了各种医疗设置中的潜力。然而，医疗时间序列问题在实际应用中具有复杂的特性：它们包括数据预处理、缺失值填充、特征选择、预测 issuing、 uncertainty 估计和模型解释等多个组件的交互。尽管电子病人数据的增长呈指数型增长，但是在临床研究和决策支持中实现的潜力与可能性之间还存在巨大的差距。特别是在实际项目生命周期中，工程（即困难于建立）、评估（即困难于评估）和效率（即困难于优化）等问题具有挑战性。为了解决这些问题，Clairvoyance 提出了一个统一、端到端、自动化 ML 友好的管道，作为（i）软件工具包、（ii）实验标准和（iii）优化接口。我们的最终目标是使得医疗时间序列 ML 实际实践中的透明度和可重现性得到改善。通过使用实际数据来 illustrate 管道的应用，我们示例了医疗旅程中的核心任务，如个性化预测、治疗效果估计和信息获取。根据我们所知，Clairvoyance 是首个实现了Complex Inference Workflows 的综合和自动化管道的医疗时间序列 ML 项目。
</details></li>
</ul>
<hr>
<h2 id="DySurv-Dynamic-Deep-Learning-Model-for-Survival-Prediction-in-the-ICU"><a href="#DySurv-Dynamic-Deep-Learning-Model-for-Survival-Prediction-in-the-ICU" class="headerlink" title="DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU"></a>DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18681">http://arxiv.org/abs/2310.18681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Munib Mesinovic, Peter Watkinson, Tingting Zhu</li>
<li>for: 这篇论文旨在提出一种基于深度学习的预测生存时间方法，以便在ICU中进行动态死亡风险预测。</li>
<li>methods: 这篇论文使用了一种名为 DySurv 的新型 conditional variational autoencoder-based 方法，使用了病人电子医疗纪录中的静态和时间序列数据来估计死亡风险。</li>
<li>results: 这篇论文的实验结果显示，DySurv 方法可以在标准库中对比其他方法表现出色，并且在实际患者数据库中进行了验证。 survival 估计的内在一致性和不同数据集中的稳定性都支持了这种动态深度学习模型在预测生存时间方法中的可靠性。<details>
<summary>Abstract</summary>
Survival analysis helps approximate underlying distributions of time-to-events which in the case of critical care like in the ICU can be a powerful tool for dynamic mortality risk prediction. Extending beyond the classical Cox model, deep learning techniques have been leveraged over the last years relaxing the many constraints of their counterparts from statistical methods. In this work, we propose a novel conditional variational autoencoder-based method called DySurv which uses a combination of static and time-series measurements from patient electronic health records in estimating risk of death dynamically in the ICU. DySurv has been tested on standard benchmarks where it outperforms most existing methods including other deep learning methods and we evaluate it on a real-world patient database from MIMIC-IV. The predictive capacity of DySurv is consistent and the survival estimates remain disentangled across different datasets supporting the idea that dynamic deep learning models based on conditional variational inference in multi-task cases can be robust models for survival analysis.
</details>
<details>
<summary>摘要</summary>
生存分析可以 aproximate 时间事件的下面分布，在 ICU 中可以是一种强大的动态死亡风险预测工具。在过去几年中，深度学习技术被应用于生存分析，超越了统计方法的多种限制。在这种工作中，我们提出了一种名为 DySurv 的新方法，使用患者电子医疗记录中的静态和时间序列测量来 dynamically 估算 ICU 中死亡风险。DySurv 已经在标准Benchmark上测试，与其他深度学习方法相比，它在大多数情况下表现出色，并在实际患者数据库中进行了评估。survival 预测的可靠性和预测值在不同数据集中保持分离，支持我们的想法，即基于 conditional variational inference 的动态深度学习模型在多任务情况下可以是Robust模型 для survival analysis。
</details></li>
</ul>
<hr>
<h2 id="Energy-Based-Models-for-Anomaly-Detection-A-Manifold-Diffusion-Recovery-Approach"><a href="#Energy-Based-Models-for-Anomaly-Detection-A-Manifold-Diffusion-Recovery-Approach" class="headerlink" title="Energy-Based Models for Anomaly Detection: A Manifold Diffusion Recovery Approach"></a>Energy-Based Models for Anomaly Detection: A Manifold Diffusion Recovery Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18677">http://arxiv.org/abs/2310.18677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sangwoong Yoon, Young-Uk Jin, Yung-Kyun Noh, Frank C. Park</li>
<li>for: 这篇论文是用于侦测异常（Anomaly Detection）的新方法。</li>
<li>methods: 这篇论文使用的方法是把资料点推广到低维度构造中，然后使用EBM进行侦测。</li>
<li>results: 实验结果显示，这篇论文的方法可以在不同的资料类型和侦测任务中具有优秀的表现。<details>
<summary>Abstract</summary>
We present a new method of training energy-based models (EBMs) for anomaly detection that leverages low-dimensional structures within data. The proposed algorithm, Manifold Projection-Diffusion Recovery (MPDR), first perturbs a data point along a low-dimensional manifold that approximates the training dataset. Then, EBM is trained to maximize the probability of recovering the original data. The training involves the generation of negative samples via MCMC, as in conventional EBM training, but from a different distribution concentrated near the manifold. The resulting near-manifold negative samples are highly informative, reflecting relevant modes of variation in data. An energy function of MPDR effectively learns accurate boundaries of the training data distribution and excels at detecting out-of-distribution samples. Experimental results show that MPDR exhibits strong performance across various anomaly detection tasks involving diverse data types, such as images, vectors, and acoustic signals.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的能量基模型（EBM）训练方法，该方法利用数据中的低维结构。我们的算法，抽象扩散恢复（MPDR），首先将数据点扰动到一个低维抽象 manifold 上，然后通过 MCMC 生成负样本，与 convential EBM 训练中的负样本生成方式类似。但是，MPDR 使用的是一个集中在抽象 manifold 上的分布，从而生成了具有低维结构的负样本。这些近抽象 manifold 上的负样本具有高度信息richness，反映了数据中重要的变换模式。 MPDR 的能量函数可以准确地学习训练数据分布的边界，并且能够准确检测数据集外的异常样本。我们的实验结果显示，MPDR 在多种异常检测任务中表现出色，包括图像、向量和声音信号等数据类型。
</details></li>
</ul>
<hr>
<h2 id="Maximum-Independent-Set-Self-Training-through-Dynamic-Programming"><a href="#Maximum-Independent-Set-Self-Training-through-Dynamic-Programming" class="headerlink" title="Maximum Independent Set: Self-Training through Dynamic Programming"></a>Maximum Independent Set: Self-Training through Dynamic Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18672">http://arxiv.org/abs/2310.18672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Brusca, Lars C. P. M. Quaedvlieg, Stratis Skoulakis, Grigorios G Chrysos, Volkan Cevher</li>
<li>for: 本文提出了一种基于图神经网络（GNN）的最大独立集（MIS）问题解决方案， drawing inspiration from dynamic programming（DP）。</li>
<li>methods: specifically, the authors propose a DP-like recursive algorithm based on GNNs that first constructs two smaller sub-graphs, predicts the one with the larger MIS, and then uses it in the next recursive call.</li>
<li>results: the authors provide numerical evidence showing the superiority of their method compared to prior methods in multiple synthetic and real-world datasets.<details>
<summary>Abstract</summary>
This work presents a graph neural network (GNN) framework for solving the maximum independent set (MIS) problem, inspired by dynamic programming (DP). Specifically, given a graph, we propose a DP-like recursive algorithm based on GNNs that firstly constructs two smaller sub-graphs, predicts the one with the larger MIS, and then uses it in the next recursive call. To train our algorithm, we require annotated comparisons of different graphs concerning their MIS size. Annotating the comparisons with the output of our algorithm leads to a self-training process that results in more accurate self-annotation of the comparisons and vice versa. We provide numerical evidence showing the superiority of our method vs prior methods in multiple synthetic and real-world datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Causal-discovery-in-a-complex-industrial-system-A-time-series-benchmark"><a href="#Causal-discovery-in-a-complex-industrial-system-A-time-series-benchmark" class="headerlink" title="Causal discovery in a complex industrial system: A time series benchmark"></a>Causal discovery in a complex industrial system: A time series benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18654">http://arxiv.org/abs/2310.18654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Søren Wengel Mogensen, Karin Rathsman, Per Nilsson</li>
<li>for: 这篇论文是用来描述如何从观测数据中推断 causal structure的。</li>
<li>methods: 这篇论文使用了一种时间序列数据的 causal discovery 方法，并对真实的工业系统进行了测试。</li>
<li>results: 论文提供了一个industrial subsystem的 causal graph，并通过专家知识来构建了这个图。这个测试环境可以帮助开发 causal discovery 方法。<details>
<summary>Abstract</summary>
Causal discovery outputs a causal structure, represented by a graph, from observed data. For time series data, there is a variety of methods, however, it is difficult to evaluate these on real data as realistic use cases very rarely come with a known causal graph to which output can be compared. In this paper, we present a dataset from an industrial subsystem at the European Spallation Source along with its causal graph which has been constructed from expert knowledge. This provides a testbed for causal discovery from time series observations of complex systems, and we believe this can help inform the development of causal discovery methodology.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SSL-Framework-for-Causal-Inconsistency-between-Structures-and-Representations"><a href="#SSL-Framework-for-Causal-Inconsistency-between-Structures-and-Representations" class="headerlink" title="SSL Framework for Causal Inconsistency between Structures and Representations"></a>SSL Framework for Causal Inconsistency between Structures and Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18634">http://arxiv.org/abs/2310.18634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hang Chen, Xinyu Yang, Keqing Du</li>
<li>for: 这篇论文旨在探讨深度学习和 causal discovery 之间的交叉束合，以揭示无法统计数据中的 causal 关系。</li>
<li>methods: 本文提出了一种针对无法统计数据的 intervention 策略和 causal consistency condition (CCC) 的理论发展，并设计了一个自然语言模型 (LLMs) 和一个监督特殊化模型 (SSMs) 的自动学习框架。</li>
<li>results: 该文通过大量实验证明了其方法的有效性，并在三个下游任务中进行了评估。<details>
<summary>Abstract</summary>
The cross-pollination of deep learning and causal discovery has catalyzed a burgeoning field of research seeking to elucidate causal relationships within non-statistical data forms like images, videos, and text. Such data, often being named `indefinite data', exhibit unique challenges-inconsistency between causal structure and representation, which are not common in conventional data forms. To tackle this issue, we theoretically develop intervention strategies suitable for indefinite data and derive causal consistency condition (CCC). Moreover, we design a self-supervised learning (SSL) framework that considers interventions as `views' and CCC as a `philosophy' with two implement examples on Supervised Specialized Models (SSMs) and Large Language Models (LLMs), respectively. To evaluate pure inconsistency manifestations, we have prepared the first high-quality causal dialogue dataset-Causalogue. Evaluations are also performed on three other downstream tasks. Extensive experimentation has substantiated the efficacy of our methodology, illuminating how CCC could potentially play an influential role in various fields.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将深度学习和 causal discovery 融合，激发了一个蓬勃的研究，旨在揭示非统计数据中的 causal 关系。这类数据，常被称为 "未定数据"，具有独特的挑战 -  causal 结构和表示之间的不一致。为解决这个问题，我们提出了适应于未定数据的干预策略和 causal 一致性条件（CCC）的理论发展。此外，我们还设计了一个基于自我监督学习（SSL）框架，在该框架中，干预被视为 "视图"，CCC 被视为 "哲学"，并在 Supervised Specialized Models (SSMs) 和 Large Language Models (LLMs) 中进行了两个实现例子。为了评估纯净的不一致现象，我们准备了首个高质量 causal 对话集 - Causalogue。此外，我们还在三个下游任务上进行了评估。广泛的实验证明了我们的方法的有效性，揭示了 CCC 在不同领域的可能发挥作用。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Modeling-for-Wind-Power-Forecasting-A-Glass-Box-Approach-with-Exceptional-Accuracy"><a href="#Explainable-Modeling-for-Wind-Power-Forecasting-A-Glass-Box-Approach-with-Exceptional-Accuracy" class="headerlink" title="Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach with Exceptional Accuracy"></a>Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach with Exceptional Accuracy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18629">http://arxiv.org/abs/2310.18629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Liao, Fernando Porté-Agel, Jiannong Fang, Birgitte Bak-Jensen, Guangchun Ruan, Zhe Yang</li>
<li>for: 这篇论文旨在提出一个可读性高的风力预测模型，并且可以实现高精度的风力预测。</li>
<li>methods: 本论文使用了进步的人工智能技术（例如Gradient Boosting），创造了shape函数在预测模型中。这些函数可以将风力输出和输入特征之间的复杂非线性关系实现有效地映射。此外，预测模型还包括互动项，以实现输入特征之间的互动和联合作用。</li>
<li>results: 根据实验结果显示，提案的玻璃箱方法可以实现风力预测的可读性和高精度。对于全球和个别 perspective，这种方法都能够实现高精度的预测。此外，与大多数参考模型相比，玻璃箱方法表现更好，并且和最佳性能的神经网络相比，表现相当。因此，这种玻璃箱方法在可靠的风力预测中具有吸引力。<details>
<summary>Abstract</summary>
Machine learning models (e.g., neural networks) achieve high accuracy in wind power forecasting, but they are usually regarded as black boxes that lack interpretability. To address this issue, the paper proposes a glass-box approach that combines exceptional accuracy with transparency for wind power forecasting. Specifically, advanced artificial intelligence methods (e.g., gradient boosting) are innovatively employed to create shape functions within the forecasting model. These functions effectively map the intricate non-linear relationships between wind power output and input features. Furthermore, the forecasting model is enriched by incorporating interaction terms that adeptly capture interdependencies and synergies among the input features. Simulation results show that the proposed glass-box approach effectively interprets the results of wind power forecasting from both global and instance perspectives. Besides, it outperforms most benchmark models and exhibits comparable performance to the best-performing neural networks. This dual strength of transparency and high accuracy positions the proposed glass-box approach as a compelling choice for reliable wind power forecasting.
</details>
<details>
<summary>摘要</summary>
机器学习模型（如神经网络）可以实现高精度风力预测，但它们通常被视为黑盒模型，缺乏可读性。为解决这个问题，文章提出了一种玻璃盒方法，该方法结合了高精度和可读性来进行风力预测。具体来说，文章使用了进步的人工智能技术（如梯度提升）来创建shape函数在预测模型中。这些函数有效地映射了风力输出和输入特征之间的复杂非线性关系。此外，预测模型还被补充了交互项，以便精准地捕捉输入特征之间的互动和协同作用。 simulation结果显示，提议的玻璃盒方法可以从全局和实例两个角度进行可读性的风力预测，并且在大多数参考模型之上出performances，与最佳性能的神经网络相当。这种两种优点的玻璃盒方法因此成为可靠的风力预测的可靠选择。
</details></li>
</ul>
<hr>
<h2 id="Pessimistic-Off-Policy-Multi-Objective-Optimization"><a href="#Pessimistic-Off-Policy-Multi-Objective-Optimization" class="headerlink" title="Pessimistic Off-Policy Multi-Objective Optimization"></a>Pessimistic Off-Policy Multi-Objective Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18617">http://arxiv.org/abs/2310.18617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shima Alizadeh, Aniruddha Bhargava, Karthick Gopalswamy, Lalit Jain, Branislav Kveton, Ge Liu</li>
<li>for: 这篇论文主要研究了多目标优化问题中，如何从现有策略收集的数据中提取多目标策略优化。</li>
<li>methods: 该论文提出了一种偏负估 estimator，基于对抗性折衣分数（IPS），用于估算多目标策略价值。这种估计器在理论和实验中都提高了对于naive IPS估计器。</li>
<li>results: 该论文的分析是通用的，可以应用于不同的IPS估计器和优化方法。偏负估 estimator可以通过policy gradient来优化，在所有实验中表现良好。<details>
<summary>Abstract</summary>
Multi-objective optimization is a type of decision making problems where multiple conflicting objectives are optimized. We study offline optimization of multi-objective policies from data collected by an existing policy. We propose a pessimistic estimator for the multi-objective policy values that can be easily plugged into existing formulas for hypervolume computation and optimized. The estimator is based on inverse propensity scores (IPS), and improves upon a naive IPS estimator in both theory and experiments. Our analysis is general, and applies beyond our IPS estimators and methods for optimizing them. The pessimistic estimator can be optimized by policy gradients and performs well in all of our experiments.
</details>
<details>
<summary>摘要</summary>
多目标优化是决策问题的一种，其中有多个矛盾的目标被优化。我们研究基于现有策略所采集的数据进行离线优化的多目标策略。我们提出了一种消极估计器，用于估计多目标策略的价值，这种估计器基于反抗概率分布（IPS），并在理论和实验中都有所改进。我们的分析涵盖了更广泛的领域，并不仅限于我们的IPS估计器和优化方法。这种消极估计器可以通过政策Gradient优化，在所有实验中表现良好。
</details></li>
</ul>
<hr>
<h2 id="Temporally-Disentangled-Representation-Learning-under-Unknown-Nonstationarity"><a href="#Temporally-Disentangled-Representation-Learning-under-Unknown-Nonstationarity" class="headerlink" title="Temporally Disentangled Representation Learning under Unknown Nonstationarity"></a>Temporally Disentangled Representation Learning under Unknown Nonstationarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18615">http://arxiv.org/abs/2310.18615</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiangchensong/nctrl">https://github.com/xiangchensong/nctrl</a></li>
<li>paper_authors: Xiangchen Song, Weiran Yao, Yewen Fan, Xinshuai Dong, Guangyi Chen, Juan Carlos Niebles, Eric Xing, Kun Zhang</li>
<li>for: 研究者们是想解决非站点的时序数据中 causal  represencing 问题，即在不具备辅助变量（如类别标签和&#x2F;或领域标识符）的情况下，可以准确分离 causally 相关的 latent 变量。</li>
<li>methods: 研究者们在这篇论文中提出了一种名为 NCTRL 的原则性估计框架，可以在非站点设置下，基于测量序列数据，重建时延 causal 变量并分离其关系。</li>
<li>results: 实验证明，NCTRL 方法可以可靠地分离时延 causal 变量，并且在不具备辅助变量的情况下，表现出明显的优势，超过了现有的基准值。<details>
<summary>Abstract</summary>
In unsupervised causal representation learning for sequential data with time-delayed latent causal influences, strong identifiability results for the disentanglement of causally-related latent variables have been established in stationary settings by leveraging temporal structure. However, in nonstationary setting, existing work only partially addressed the problem by either utilizing observed auxiliary variables (e.g., class labels and/or domain indexes) as side information or assuming simplified latent causal dynamics. Both constrain the method to a limited range of scenarios. In this study, we further explored the Markov Assumption under time-delayed causally related process in nonstationary setting and showed that under mild conditions, the independent latent components can be recovered from their nonlinear mixture up to a permutation and a component-wise transformation, without the observation of auxiliary variables. We then introduce NCTRL, a principled estimation framework, to reconstruct time-delayed latent causal variables and identify their relations from measured sequential data only. Empirical evaluations demonstrated the reliable identification of time-delayed latent causal influences, with our methodology substantially outperforming existing baselines that fail to exploit the nonstationarity adequately and then, consequently, cannot distinguish distribution shifts.
</details>
<details>
<summary>摘要</summary>
在不监督 causal 表示学习中，对时间延迟的 latent causal 影响进行了强大的可Identifiability 结果，在静止设置下，通过利用时间结构来恰当地识别 causally 相关的 latent 变量。然而，在不稳定设置下，现有的工作只是部分地解决了问题，可以通过利用观测的auxiliary变量（例如类别标签和/或domain标识符）作为副信息，或者假设简单的 latent causal 动力学。两者都限制方法只能在有限的情况下运行。在这项研究中，我们进一步探讨了在时间延迟 causally 相关的 Markov 假设在不稳定设置下，并证明了在某些轻度条件下，独立的 latent 分量可以从其非线性混合中重建，而无需观测 auxilary 变量。然后，我们引入 NCTRL，一种原则性的估计框架，来重建时间延迟的 latent causal 变量，并identify它们之间的关系，从测量的时间序列数据中。实验证明了我们的方法可靠地识别时间延迟的 latent causal 影响，并且substantially 超越了不充分利用不稳定性的现有基准值。
</details></li>
</ul>
<hr>
<h2 id="Efficient-kernel-surrogates-for-neural-network-based-regression"><a href="#Efficient-kernel-surrogates-for-neural-network-based-regression" class="headerlink" title="Efficient kernel surrogates for neural network-based regression"></a>Efficient kernel surrogates for neural network-based regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18612">http://arxiv.org/abs/2310.18612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saad Qadeer, Andrew Engel, Adam Tsou, Max Vargas, Panos Stinis, Tony Chiang<br>for: 这篇论文的目的是为了解释深度神经网络（DNN）的效果和局限性，并提供一种低成本的估计方法。methods: 这篇论文使用了Randomly initialized DNNs和Conjugate Kernel（CK）来研究DNN的性能。results: 论文表明，CK可以作为NTK的低成本估计方法，并且在某些情况下可以超越NTK的性能。此外，论文还提供了一种改进DNN准确率的简单方法。<details>
<summary>Abstract</summary>
Despite their immense promise in performing a variety of learning tasks, a theoretical understanding of the effectiveness and limitations of Deep Neural Networks (DNNs) has so far eluded practitioners. This is partly due to the inability to determine the closed forms of the learned functions, making it harder to assess their precise dependence on the training data and to study their generalization properties on unseen datasets. Recent work has shown that randomly initialized DNNs in the infinite width limit converge to kernel machines relying on a Neural Tangent Kernel (NTK) with known closed form. These results suggest, and experimental evidence corroborates, that empirical kernel machines can also act as surrogates for finite width DNNs. The high computational cost of assembling the full NTK, however, makes this approach infeasible in practice, motivating the need for low-cost approximations. In the current work, we study the performance of the Conjugate Kernel (CK), an efficient approximation to the NTK that has been observed to yield fairly similar results. For the regression problem of smooth functions and classification using logistic regression, we show that the CK performance is only marginally worse than that of the NTK and, in certain cases, is shown to be superior. In particular, we establish bounds for the relative test losses, verify them with numerical tests, and identify the regularity of the kernel as the key determinant of performance. In addition to providing a theoretical grounding for using CKs instead of NTKs, our framework provides insights into understanding the robustness of the various approximants and suggests a recipe for improving DNN accuracy inexpensively. We present a demonstration of this on the foundation model GPT-2 by comparing its performance on a classification task using a conventional approach and our prescription.
</details>
<details>
<summary>摘要</summary>
尽管深度神经网络（DNN）在许多学习任务上表现出了极大的承诺，但是理论上的效iveness和局限性仍然无法被实践者们完全理解。这是因为不能确定closed form的学习函数，使得训练数据的依赖关系和未经训练数据集的泛化性 harder to assess。近期的研究表明，在无限宽限制下，Randomly initialized DNNs会 converges to kernel machines，这些机器可以通过known closed form的Neural Tangent Kernel（NTK）来描述。这些结果表明，和实验证据支持，empirical kernel machines可以作为finite width DNNs的surrogate。然而，assembling the full NTK的计算成本太高，这使得这种方法在实践中不可行，因此需要低成本的近似。在当前的工作中，我们研究了Conjugate Kernel（CK）的性能，CK是NTK的有效近似。对于抽象函数的回归问题和使用logistic regression进行分类，我们显示CK的性能只是NTK的一个小 margin worse，而且在某些情况下，CKeven outperform NTK。具体来说，我们给出了 bounds for the relative test losses，通过数值测试验证了这些 bound，并发现了核函数的 Regularity是性能的关键因素。此外，我们的框架还提供了使用CK instead of NTK的理论基础，以及如何提高DNN的准确性的recipe。我们在GPT-2基础模型上进行了一个示例，通过对一个分类任务使用我们的方法和传统方法进行比较。
</details></li>
</ul>
<hr>
<h2 id="Where-have-you-been-A-Study-of-Privacy-Risk-for-Point-of-Interest-Recommendation"><a href="#Where-have-you-been-A-Study-of-Privacy-Risk-for-Point-of-Interest-Recommendation" class="headerlink" title="Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation"></a>Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18606">http://arxiv.org/abs/2310.18606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunlin Cai, Jinghuai Zhang, Will Shand, Zhiqing Hong, Guang Wang, Desheng Zhang, Jianfeng Chi, Yuan Tian</li>
<li>For: This paper aims to evaluate the privacy risks of mobility data-based machine learning models, specifically point-of-interest recommendation models, by designing a privacy attack suite and conducting experimental evaluations.* Methods: The paper uses a privacy attack suite that includes data extraction and membership inference attacks to evaluate the privacy risks of POI recommendation models. The attacks assume different adversary knowledge and aim to extract different types of sensitive information from mobility data.* Results: The experimental evaluation using two real-world mobility datasets demonstrates that current POI recommendation models are vulnerable to the attacks in the privacy attack suite. The paper also presents unique findings on what types of mobility data are more susceptible to privacy attacks.<details>
<summary>Abstract</summary>
As location-based services (LBS) have grown in popularity, the collection of human mobility data has become increasingly extensive to build machine learning (ML) models offering enhanced convenience to LBS users. However, the convenience comes with the risk of privacy leakage since this type of data might contain sensitive information related to user identities, such as home/work locations. Prior work focuses on protecting mobility data privacy during transmission or prior to release, lacking the privacy risk evaluation of mobility data-based ML models. To better understand and quantify the privacy leakage in mobility data-based ML models, we design a privacy attack suite containing data extraction and membership inference attacks tailored for point-of-interest (POI) recommendation models, one of the most widely used mobility data-based ML models. These attacks in our attack suite assume different adversary knowledge and aim to extract different types of sensitive information from mobility data, providing a holistic privacy risk assessment for POI recommendation models. Our experimental evaluation using two real-world mobility datasets demonstrates that current POI recommendation models are vulnerable to our attacks. We also present unique findings to understand what types of mobility data are more susceptible to privacy attacks. Finally, we evaluate defenses against these attacks and highlight future directions and challenges.
</details>
<details>
<summary>摘要</summary>
为了应对 Location-based Services (LBS) 的普及，人类移动数据的收集已成为建立 Machine Learning (ML) 模型的重要步骤，以提供更高的用户便利。然而，这种便利也会带来隐私泄露的风险，因为这些数据可能包含用户标识信息，如家庭/办公室的位置。先前的工作主要关注于在传输或发布 mobility data 时保护隐私，而忽略了 mobility data 基于 ML 模型的隐私风险评估。为了更好地理解和评估 mobility data 基于 ML 模型的隐私泄露，我们设计了一个隐私攻击集，包括数据EXTRACTION和会员推理攻击，专门为点位服务（POI）推荐模型而设计。这些攻击在我们的攻击集中假设不同的反对手知识，目标是从移动数据中提取不同类型的敏感信息，为 POI 推荐模型的隐私风险进行总体评估。我们使用两个实际的移动数据集进行实验，表明现有 POI 推荐模型对我们的攻击非常感受。我们还发现了不同类型的移动数据是哪些隐私攻击最容易受到的，以及对这些攻击的防御措施和未来方向。
</details></li>
</ul>
<hr>
<h2 id="TorchDEQ-A-Library-for-Deep-Equilibrium-Models"><a href="#TorchDEQ-A-Library-for-Deep-Equilibrium-Models" class="headerlink" title="TorchDEQ: A Library for Deep Equilibrium Models"></a>TorchDEQ: A Library for Deep Equilibrium Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18605">http://arxiv.org/abs/2310.18605</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/locuslab/torchdeq">https://github.com/locuslab/torchdeq</a></li>
<li>paper_authors: Zhengyang Geng, J. Zico Kolter</li>
<li>for: This paper is written to provide a systematic and comprehensive framework for training and applying Deep Equilibrium (DEQ) models, which are a class of implicit models that map inputs to fixed points of neural networks.</li>
<li>methods: The paper presents TorchDEQ, an open-source PyTorch-based library that allows users to define, train, and infer using DEQs over multiple domains with minimal code and best practices.</li>
<li>results: The paper reports that by developing a joint framework that incorporates the best practices across all models, the performance, training stability, and efficiency of DEQs have been substantially improved on ten datasets across all six projects in the “DEQ Zoo”.<details>
<summary>Abstract</summary>
Deep Equilibrium (DEQ) Models, an emerging class of implicit models that maps inputs to fixed points of neural networks, are of growing interest in the deep learning community. However, training and applying DEQ models is currently done in an ad-hoc fashion, with various techniques spread across the literature. In this work, we systematically revisit DEQs and present TorchDEQ, an out-of-the-box PyTorch-based library that allows users to define, train, and infer using DEQs over multiple domains with minimal code and best practices. Using TorchDEQ, we build a ``DEQ Zoo'' that supports six published implicit models across different domains. By developing a joint framework that incorporates the best practices across all models, we have substantially improved the performance, training stability, and efficiency of DEQs on ten datasets across all six projects in the DEQ Zoo. TorchDEQ and DEQ Zoo are released as \href{https://github.com/locuslab/torchdeq}{open source}.
</details>
<details>
<summary>摘要</summary>
深度平衡（DEQ）模型，一种在深度学习社区中升起的新类刚果模型，可以将输入映射到神经网络中的固定点上。然而，在训练和应用DEQ模型时，目前仍然采用各种不同的技术，分散在文献中。在这项工作中，我们系统地回顾DEQs，并提出了一个名为TorchDEQ的基于PyTorch的库，允许用户定义、训练和推理使用DEQs，并在多个领域上进行最小代码和最佳实践。使用TorchDEQ，我们建立了一个名为“DEQ zoo”的 colección，支持了六种已发表的隐式模型，并在不同的领域中进行了六个项目的实验。通过开发一个集成所有模型最佳实践的共同框架，我们在十个数据集上提高了DEQs的性能、训练稳定性和效率。TorchDEQ和DEQ zoo都已经作为开源项目在GitHub上发布。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-Are-Better-Adversaries-Exploring-Generative-Clean-Label-Backdoor-Attacks-Against-Text-Classifiers"><a href="#Large-Language-Models-Are-Better-Adversaries-Exploring-Generative-Clean-Label-Backdoor-Attacks-Against-Text-Classifiers" class="headerlink" title="Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers"></a>Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18603">http://arxiv.org/abs/2310.18603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wencong You, Zayd Hammoudeh, Daniel Lowd</li>
<li>for: 这 paper 是为了攻击机器学习模型的弱点，使其预测结果被 manipulate 的。</li>
<li>methods: 这 paper 使用了语言模型来自动插入多种风格的触发器到文本中，以达到攻击目标。</li>
<li>results: 论文表明，使用 LLMBkd 攻击方法可以在各种风格下 achieve 高度的攻击成功率，只需要 little effort 和无需模型训练。<details>
<summary>Abstract</summary>
Backdoor attacks manipulate model predictions by inserting innocuous triggers into training and test data. We focus on more realistic and more challenging clean-label attacks where the adversarial training examples are correctly labeled. Our attack, LLMBkd, leverages language models to automatically insert diverse style-based triggers into texts. We also propose a poison selection technique to improve the effectiveness of both LLMBkd as well as existing textual backdoor attacks. Lastly, we describe REACT, a baseline defense to mitigate backdoor attacks via antidote training examples. Our evaluations demonstrate LLMBkd's effectiveness and efficiency, where we consistently achieve high attack success rates across a wide range of styles with little effort and no model training.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将给定文本翻译成简化中文。</SYS>>我们研究了一种新的后门攻击方法，称为LLMBkd。这种攻击方法利用语言模型自动插入文本中的多种风格化触发器。我们还提出了一种毒选择技术，以提高现有的文本后门攻击和LLMBkd的效果。此外，我们还描述了一种基eline防御方法，称为REACT，以 Mitigate backdoor attacks via antidote training examples。我们的评估结果表明，LLMBkd 具有高效率和多样化的触发器，可以轻松地在各种风格下实现高度成功率。
</details></li>
</ul>
<hr>
<h2 id="Online-Decision-Mediation"><a href="#Online-Decision-Mediation" class="headerlink" title="Online Decision Mediation"></a>Online Decision Mediation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18601">http://arxiv.org/abs/2310.18601</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uvhw/Bitcoin-Foundation">https://github.com/uvhw/Bitcoin-Foundation</a></li>
<li>paper_authors: Daniel Jarrett, Alihan Hüyük, Mihaela van der Schaar</li>
<li>For: The paper aims to serve as an intermediary between expert behavior and human behavior in decision-making, with the goal of striking a balance between purely prescriptive and purely descriptive approaches.* Methods: The paper proposes a solution that trades off immediate loss terms against future improvements in generalization error, and identifies why conventional bandit algorithms may fail.* Results: The paper demonstrates consistent gains over applicable benchmarks on performance measures with respect to the mediator policy, the learned model, and the decision-making system as a whole, through experiments and sensitivities on a variety of datasets.Here’s the simplified Chinese text for the three information points:* For: 这篇论文目标是在决策过程中作为中间人，以寻求 struck a balance between凡是指导的（purely prescriptive）和凡是描述的（purely descriptive）方法。* Methods: 论文提出了一种方法，该方法在评估损失和未来改进的泛化误差之间进行了交易，并解释了 conventional bandit 算法可能失败的原因。* Results: 论文通过对各种数据集的实验和敏感度分析，示出了与相关的参考模型、学习模型和决策系统总体性能的一致性。<details>
<summary>Abstract</summary>
Consider learning a decision support assistant to serve as an intermediary between (oracle) expert behavior and (imperfect) human behavior: At each time, the algorithm observes an action chosen by a fallible agent, and decides whether to *accept* that agent's decision, *intervene* with an alternative, or *request* the expert's opinion. For instance, in clinical diagnosis, fully-autonomous machine behavior is often beyond ethical affordances, thus real-world decision support is often limited to monitoring and forecasting. Instead, such an intermediary would strike a prudent balance between the former (purely prescriptive) and latter (purely descriptive) approaches, while providing an efficient interface between human mistakes and expert feedback. In this work, we first formalize the sequential problem of *online decision mediation* -- that is, of simultaneously learning and evaluating mediator policies from scratch with *abstentive feedback*: In each round, deferring to the oracle obviates the risk of error, but incurs an upfront penalty, and reveals the otherwise hidden expert action as a new training data point. Second, we motivate and propose a solution that seeks to trade off (immediate) loss terms against (future) improvements in generalization error; in doing so, we identify why conventional bandit algorithms may fail. Finally, through experiments and sensitivities on a variety of datasets, we illustrate consistent gains over applicable benchmarks on performance measures with respect to the mediator policy, the learned model, and the decision-making system as a whole.
</details>
<details>
<summary>摘要</summary>
考虑使用决策支持助手作为 oracle 专家行为和人类行为之间的中间人：在每次时刻，算法观察到一个不准确的代理人选择的行动，然后决定是否接受该代理人的决定， intervene with 一个替代方案，或者请求专家的意见。例如，在临床诊断中，完全自主的机器行为经常超出伦理范畴，因此现实世界决策支持通常受限于监测和预测。而这个中间人可以 strike 一个谨慎的平衡 между两者，同时提供一个有效的人类错误和专家反馈之间的交互。在这项工作中，我们首先正式化了在线决策媒介问题的sequential形式：在每个回合中，推迟到oracle会降低风险，但是会付出一个初始的罚款，并将 Otherwise 隐藏的专家行为作为一个新的训练数据点。其次，我们激励和提出一个解决方案，它在同时学习和评估媒介策略时，要求平衡 (immediate) 损失和 (future) 改进泛化误差的问题。在这个过程中，我们发现了 conventional bandit 算法可能失败的原因。最后，通过对多种数据集进行实验和敏感分析，我们证明了我们的方法在表现度量上与相关的benchmark相比具有一致性。
</details></li>
</ul>
<hr>
<h2 id="Fair-Streaming-Principal-Component-Analysis-Statistical-and-Algorithmic-Viewpoint"><a href="#Fair-Streaming-Principal-Component-Analysis-Statistical-and-Algorithmic-Viewpoint" class="headerlink" title="Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint"></a>Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18593">http://arxiv.org/abs/2310.18593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junghyun Lee, Hanseul Cho, Se-Young Yun, Chulhee Yun</li>
<li>for: 这个论文的目标是实现公平的主成分分析（PCA），使得投影后的分布匹配于敏感特征的分布。</li>
<li>methods: 这篇论文使用了一种新的定义called“可能相对公平优化”（PAFO）学习可能性，并在实际应用中提出了一种名为“公平流动PCA”的新设定，以及一种具有内存效率的算法“公平噪声方法”（FNPM）。</li>
<li>results: 这篇论文提供了这种算法的“统计”保证，这是公平PCA文献中的首次。此外，它还验证了这种算法的效果和内存效率在实际数据上。<details>
<summary>Abstract</summary>
Fair Principal Component Analysis (PCA) is a problem setting where we aim to perform PCA while making the resulting representation fair in that the projected distributions, conditional on the sensitive attributes, match one another. However, existing approaches to fair PCA have two main problems: theoretically, there has been no statistical foundation of fair PCA in terms of learnability; practically, limited memory prevents us from using existing approaches, as they explicitly rely on full access to the entire data. On the theoretical side, we rigorously formulate fair PCA using a new notion called \emph{probably approximately fair and optimal} (PAFO) learnability. On the practical side, motivated by recent advances in streaming algorithms for addressing memory limitation, we propose a new setting called \emph{fair streaming PCA} along with a memory-efficient algorithm, fair noisy power method (FNPM). We then provide its {\it statistical} guarantee in terms of PAFO-learnability, which is the first of its kind in fair PCA literature. Lastly, we verify the efficacy and memory efficiency of our algorithm on real-world datasets.
</details>
<details>
<summary>摘要</summary>
“ fair principal component analysis (PCA) 是一个问题设定，我们想要在 PCA 中进行不偏的表现，使得投影的分布，根据敏感特征，相互匹配。然而，现有的公平 PCA 方法有两个主要问题：一是理论上没有公平 PCA 的学习基础; two是实际上限制了我们使用现有方法，因为它们需要完整的数据存储。在理论上，我们严格定义公平 PCA 使用一个新的概念 called “可能接近公平且最佳”(PAFO) 可学习性。在实践上，运用最近的流动数据处理技术，我们提出一个新的设定 called “公平流动 PCA”，以及一个内存有效的算法，叫做公平杂音方法 (FNPM)。我们然后提供这个设定的“ Statistical ”保证，这是公平 PCA 文献中的第一个。最后，我们验证了我们的算法在实际数据上的有效性和内存效率。”
</details></li>
</ul>
<hr>
<h2 id="Inverse-Decision-Modeling-Learning-Interpretable-Representations-of-Behavior"><a href="#Inverse-Decision-Modeling-Learning-Interpretable-Representations-of-Behavior" class="headerlink" title="Inverse Decision Modeling: Learning Interpretable Representations of Behavior"></a>Inverse Decision Modeling: Learning Interpretable Representations of Behavior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18591">http://arxiv.org/abs/2310.18591</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danieljarrett/Inverse-Bounded-Rational-Control">https://github.com/danieljarrett/Inverse-Bounded-Rational-Control</a></li>
<li>paper_authors: Daniel Jarrett, Alihan Hüyük, Mihaela van der Schaar</li>
<li>for: 提高决策过程的模型化和改进</li>
<li>methods: 使用参数化表示Sequential Decision Behavior的框架，包括正则化控制行为和资料学习</li>
<li>results: 实现了学习（可读）表示 rationality，自然地捕捉了偏见行为、环境知识不准确和 bounded rationality 的概念<details>
<summary>Abstract</summary>
Decision analysis deals with modeling and enhancing decision processes. A principal challenge in improving behavior is in obtaining a transparent description of existing behavior in the first place. In this paper, we develop an expressive, unifying perspective on inverse decision modeling: a framework for learning parameterized representations of sequential decision behavior. First, we formalize the forward problem (as a normative standard), subsuming common classes of control behavior. Second, we use this to formalize the inverse problem (as a descriptive model), generalizing existing work on imitation/reward learning -- while opening up a much broader class of research problems in behavior representation. Finally, we instantiate this approach with an example (inverse bounded rational control), illustrating how this structure enables learning (interpretable) representations of (bounded) rationality -- while naturally capturing intuitive notions of suboptimal actions, biased beliefs, and imperfect knowledge of environments.
</details>
<details>
<summary>摘要</summary>
First, we define the forward problem, which includes common classes of control behavior. Then, we use this framework to formalize the inverse problem, which generalizes existing work on imitation and reward learning. This approach opens up a broader range of research problems in behavior representation.Finally, we provide an example of inverse bounded rational control, which demonstrates how this structure enables the learning of interpretable representations of rationality while naturally capturing suboptimal actions, biased beliefs, and imperfect knowledge of environments.
</details></li>
</ul>
<hr>
<h2 id="Optimal-Transport-for-Kernel-Gaussian-Mixture-Models"><a href="#Optimal-Transport-for-Kernel-Gaussian-Mixture-Models" class="headerlink" title="Optimal Transport for Kernel Gaussian Mixture Models"></a>Optimal Transport for Kernel Gaussian Mixture Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18586">http://arxiv.org/abs/2310.18586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jung Hun Oh, Rena Elkin, Anish Kumar Simhal, Jiening Zhu, Joseph O Deasy, Allen Tannenbaum</li>
<li>for: 本研究使用 Wasserstein 距离来衡量两个 Gaussian mixture 的距离，并利用 kernel trick 避免直接将输入数据映射到高维特征空间。</li>
<li>methods: 本研究使用 kernel Gaussian mixture models 来计算两个 Gaussian mixture 的 Wasserstein 距离。</li>
<li>results: 本研究提出了一种基于 RKHS 的 Wasserstein-type metric，可以帮助更好地模型复杂多模 density 的实际数据。<details>
<summary>Abstract</summary>
The Wasserstein distance from optimal mass transport (OMT) is a powerful mathematical tool with numerous applications that provides a natural measure of the distance between two probability distributions. Several methods to incorporate OMT into widely used probabilistic models, such as Gaussian or Gaussian mixture, have been developed to enhance the capability of modeling complex multimodal densities of real datasets. However, very few studies have explored the OMT problems in a reproducing kernel Hilbert space (RKHS), wherein the kernel trick is utilized to avoid the need to explicitly map input data into a high-dimensional feature space. In the current study, we propose a Wasserstein-type metric to compute the distance between two Gaussian mixtures in a RKHS via the kernel trick, i.e., kernel Gaussian mixture models.
</details>
<details>
<summary>摘要</summary>
水斯坦距离（OMT）是一个具有广泛应用的数学工具，它提供了两个概率分布之间的自然距离量。有几种方法可以将 OMT 整合到广泛使用的概率模型中，如 Gaussian 或 Gaussian 混合体，以增强模型处理复杂多模式数据的能力。然而，几乎没有研究探讨 OMT 问题在复复函数希尔贝特空间（RKHS）中，这里利用核函数传递器来避免直接将输入数据映射到高维的特征空间。在 presente 研究中，我们提出了一种 Wasserstein-type 度量来计算两个 Gaussian 混合体之间的距离，即核函数 Gaussian 混合模型。
</details></li>
</ul>
<hr>
<h2 id="Group-Robust-Classification-Without-Any-Group-Information"><a href="#Group-Robust-Classification-Without-Any-Group-Information" class="headerlink" title="Group Robust Classification Without Any Group Information"></a>Group Robust Classification Without Any Group Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18555">http://arxiv.org/abs/2310.18555</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tsirif/ula">https://github.com/tsirif/ula</a></li>
<li>paper_authors: Christos Tsirigotis, Joao Monteiro, Pau Rodriguez, David Vazquez, Aaron Courville</li>
<li>for: 这个研究旨在提高 Empirical Risk Minimization (ERM) 方法的高阶假设精度，并解决训练数据中的假设相互作用所导致的伪 correlations 问题，以便在高风险应用中部署系统。</li>
<li>methods: 这个研究提出了一种 entirely bias-unsupervised 的方法，使用预训练的自我supervised 模型来可靠地提取偏见信息，并与我们的验证标准数据集成logit adjustment 训练损失。</li>
<li>results: 我们的方法可以超过现有方法的性能，并在实际应用中提供了更好的伪相互作用精度，包括在 MPI3D dataset 上进行系统性的普遍化任务中，当混合对应 attribute value  absent 时，现有方法失败。<details>
<summary>Abstract</summary>
Empirical risk minimization (ERM) is sensitive to spurious correlations in the training data, which poses a significant risk when deploying systems trained under this paradigm in high-stake applications. While the existing literature focuses on maximizing group-balanced or worst-group accuracy, estimating these accuracies is hindered by costly bias annotations. This study contends that current bias-unsupervised approaches to group robustness continue to rely on group information to achieve optimal performance. Firstly, these methods implicitly assume that all group combinations are represented during training. To illustrate this, we introduce a systematic generalization task on the MPI3D dataset and discover that current algorithms fail to improve the ERM baseline when combinations of observed attribute values are missing. Secondly, bias labels are still crucial for effective model selection, restricting the practicality of these methods in real-world scenarios. To address these limitations, we propose a revised methodology for training and validating debiased models in an entirely bias-unsupervised manner. We achieve this by employing pretrained self-supervised models to reliably extract bias information, which enables the integration of a logit adjustment training loss with our validation criterion. Our empirical analysis on synthetic and real-world tasks provides evidence that our approach overcomes the identified challenges and consistently enhances robust accuracy, attaining performance which is competitive with or outperforms that of state-of-the-art methods, which, conversely, rely on bias labels for validation.
</details>
<details>
<summary>摘要</summary>
empirical risk minimization (ERM) sensitive to spurious correlations in the training data, posing significant risks when deploying systems trained under this paradigm in high-stakes applications. While the existing literature focuses on maximizing group-balanced or worst-group accuracy, estimating these accuracies is hindered by costly bias annotations. This study contends that current bias-unsupervised approaches to group robustness continue to rely on group information to achieve optimal performance. Firstly, these methods implicitly assume that all group combinations are represented during training. To illustrate this, we introduce a systematic generalization task on the MPI3D dataset and discover that current algorithms fail to improve the ERM baseline when combinations of observed attribute values are missing. Secondly, bias labels are still crucial for effective model selection, restricting the practicality of these methods in real-world scenarios. To address these limitations, we propose a revised methodology for training and validating debiased models in an entirely bias-unsupervised manner. We achieve this by employing pretrained self-supervised models to reliably extract bias information, which enables the integration of a logit adjustment training loss with our validation criterion. Our empirical analysis on synthetic and real-world tasks provides evidence that our approach overcomes the identified challenges and consistently enhances robust accuracy, attaining performance which is competitive with or outperforms that of state-of-the-art methods, which, conversely, rely on bias labels for validation.
</details></li>
</ul>
<hr>
<h2 id="Improved-Regret-Bounds-of-Multinomial-Logistic-Bandits-via-Regret-to-Confidence-Set-Conversion"><a href="#Improved-Regret-Bounds-of-Multinomial-Logistic-Bandits-via-Regret-to-Confidence-Set-Conversion" class="headerlink" title="Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion"></a>Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18554">http://arxiv.org/abs/2310.18554</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junghyun Lee, Se-Young Yun, Kwang-Sung Jun</li>
<li>for: 这个论文的目的是提高Logistic Bandit模型中的依赖关系，尤其是在大型数据集 ($S \geq d$) 时。</li>
<li>methods: 这个论文使用了一种新的方法 called “regret-to-confidence set conversion” (R2CS)，用于改进logistic bandit的 regret bound。</li>
<li>results: 通过使用R2CS方法，这个论文得到了一个优化的 regret bound，具有更好的依赖关系于$S$，同时保留计算可行性和其他因素($d$和$T$)的依赖关系。<details>
<summary>Abstract</summary>
Logistic bandit is a ubiquitous framework of modeling users' choices, e.g., click vs. no click for advertisement recommender system. We observe that the prior works overlook or neglect dependencies in $S \geq \lVert \theta_\star \rVert_2$, where $\theta_\star \in \mathbb{R}^d$ is the unknown parameter vector, which is particularly problematic when $S$ is large, e.g., $S \geq d$. In this work, we improve the dependency on $S$ via a novel approach called {\it regret-to-confidence set conversion (R2CS)}, which allows us to construct a convex confidence set based on only the \textit{existence} of an online learning algorithm with a regret guarantee. Using R2CS, we obtain a strict improvement in the regret bound w.r.t. $S$ in logistic bandits while retaining computational feasibility and the dependence on other factors such as $d$ and $T$. We apply our new confidence set to the regret analyses of logistic bandits with a new martingale concentration step that circumvents an additional factor of $S$. We then extend this analysis to multinomial logistic bandits and obtain similar improvements in the regret, showing the efficacy of R2CS. While we applied R2CS to the (multinomial) logistic model, R2CS is a generic approach for developing confidence sets that can be used for various models, which can be of independent interest.
</details>
<details>
<summary>摘要</summary>
“带有搜索问题的游戏”（Logistic Bandit）是一个普遍的框架，用于模型用户选择，例如广告追踪系统中的点击vs无点击。我们发现先前的研究往往忽略或忽略了$S \geq \lVert \theta_\star \rVert_2$中的相互依赖，尤其当$S$较大时（例如$S \geq d$）。在这个工作中，我们通过一种新的方法called“ regret-to-confidence set conversion”（R2CS），将可以建立基于仅存在线上学习算法的 regret guarantee的凸信心集。使用R2CS，我们得到了对$S$的 regret bound的严格改进，同时保持了 Computational Feasibility和其他因素（例如$d$和$T$）的依赖。我们将新的信心集应用到了带有新 martingale concentration step 的 regret分析中，从而缺少一个 $S$ 的额外因素。然后，我们将这些分析扩展到多ategorical logistic bandits，并获得了类似的改进。我们将R2CS应用到（多ategorical） logistic模型，但R2CS是一个更通用的方法，可以用于不同的模型，这可能是独立的兴趣。
</details></li>
</ul>
<hr>
<h2 id="The-Role-of-Reference-Points-in-Machine-Learned-Atomistic-Simulation-Models"><a href="#The-Role-of-Reference-Points-in-Machine-Learned-Atomistic-Simulation-Models" class="headerlink" title="The Role of Reference Points in Machine-Learned Atomistic Simulation Models"></a>The Role of Reference Points in Machine-Learned Atomistic Simulation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18552">http://arxiv.org/abs/2310.18552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyun Lei, Weike Ye, Joseph Montoya, Tim Mueller, Linda Hung, Jens Hummelshoej</li>
<li>for: 本研究提出了一种新的化学环境模型理论（CEMT），用于超越传统的基于原子 Machine Learning Force Field（MLFF）模型，广泛用于化学系统的分子动力学 simulations。</li>
<li>methods: 本研究使用了 Gaussian Multipole（GMP）函数来Feature化不同参考点集，包括finite difference grid-centered和bond-centered模型，以分析不同参考点集的能量预测精度、预测速度和学习效率。</li>
<li>results: 研究发现，使用非原子参考点可以提高力训练的灵活性和适应性，并且可以提高预测精度、预测速度和学习效率。此外，本研究还建立了 CEMT 与 real-space orbital-free finite element Density Functional Theory（FE-DFT）之间的联系，并表明了这种联系可以提高数据效率和稳定性。<details>
<summary>Abstract</summary>
This paper introduces the Chemical Environment Modeling Theory (CEMT), a novel, generalized framework designed to overcome the limitations inherent in traditional atom-centered Machine Learning Force Field (MLFF) models, widely used in atomistic simulations of chemical systems. CEMT demonstrated enhanced flexibility and adaptability by allowing reference points to exist anywhere within the modeled domain and thus, enabling the study of various model architectures. Utilizing Gaussian Multipole (GMP) featurization functions, several models with different reference point sets, including finite difference grid-centered and bond-centered models, were tested to analyze the variance in capabilities intrinsic to models built on distinct reference points. The results underscore the potential of non-atom-centered reference points in force training, revealing variations in prediction accuracy, inference speed and learning efficiency. Finally, a unique connection between CEMT and real-space orbital-free finite element Density Functional Theory (FE-DFT) is established, and the implications include the enhancement of data efficiency and robustness. It allows the leveraging of spatially-resolved energy densities and charge densities from FE-DFT calculations, as well as serving as a pivotal step towards integrating known quantum-mechanical laws into the architecture of ML models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Punica-Multi-Tenant-LoRA-Serving"><a href="#Punica-Multi-Tenant-LoRA-Serving" class="headerlink" title="Punica: Multi-Tenant LoRA Serving"></a>Punica: Multi-Tenant LoRA Serving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18547">http://arxiv.org/abs/2310.18547</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/punica-ai/punica">https://github.com/punica-ai/punica</a></li>
<li>paper_authors: Lequn Chen, Zihao Ye, Yongji Wu, Danyang Zhuo, Luis Ceze, Arvind Krishnamurthy</li>
<li>for: 这个论文是为了提出一个名为Punica的系统，用于在共享GPU集群中服务多个低阶适应（LoRA）模型。</li>
<li>methods: 这个系统使用了一个新的CUDA核心设计，允许不同LoRA模型的批处理操作在GPU上混合进行，这使得GPU只需要储存一个基础预训练模型，从而大幅提高GPU的内存和计算效率。</li>
<li>results: 根据评估结果，Punica在共享GPU集群中服务多个LoRA模型时，与现有的LLM服务系统相比，可以实现12倍的throughput提高，仅加2毫秒迟延性每个字。Punica的源代码可以在<a target="_blank" rel="noopener" href="https://github.com/punica-ai/punica%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/punica-ai/punica上获取。</a><details>
<summary>Abstract</summary>
Low-rank adaptation (LoRA) has become an important and popular method to adapt pre-trained models to specific domains. We present Punica, a system to serve multiple LoRA models in a shared GPU cluster. Punica contains a new CUDA kernel design that allows batching of GPU operations for different LoRA models. This allows a GPU to hold only a single copy of the underlying pre-trained model when serving multiple, different LoRA models, significantly enhancing GPU efficiency in terms of both memory and computation. Our scheduler consolidates multi-tenant LoRA serving workloads in a shared GPU cluster. With a fixed-sized GPU cluster, our evaluations show that Punica achieves 12x higher throughput in serving multiple LoRA models compared to state-of-the-art LLM serving systems while only adding 2ms latency per token. Punica is open source at https://github.com/punica-ai/punica .
</details>
<details>
<summary>摘要</summary>
低阶尝试（LoRA）已成为特定领域适应模型的重要和受欢迎方法。我们介绍了一个名为“Punica”的系统，用于在共享GPU集群中服务多个LoRA模型。Punica包含一个新的CUDA内核设计，允许不同LoRA模型的GPU操作批处理。这意味着GPU只需要存储一份基于预训练模型的底层模型，可以大幅提高GPU的内存和计算效率。我们的调度器将多家租户的LoRA服务工作负载在共享GPU集群中卷积。与现状的LLM服务系统相比，我们的Punica在服务多个LoRA模型时实现了12倍的throughput，同时只增加2毫秒的延迟每个字。Punica的源代码可以在<https://github.com/punica-ai/punica>上下载。
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Feature-Selection-Approach-for-Learning-Skinny-Trees"><a href="#End-to-end-Feature-Selection-Approach-for-Learning-Skinny-Trees" class="headerlink" title="End-to-end Feature Selection Approach for Learning Skinny Trees"></a>End-to-end Feature Selection Approach for Learning Skinny Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18542">http://arxiv.org/abs/2310.18542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shibal Ibrahim, Kayhan Behdin, Rahul Mazumder<br>for:这篇论文的目的是提出一种同时进行特征选择和树ensemble学习的工具包，以提高树ensemble模型的性能和可读性。methods:这篇论文使用了一种综合优化方法，包括特征选择和树ensemble学习，并且使用了分组L0-L2正则化来实现特征选择。results:这篇论文在15个 sintetic和实际世界数据集上实现了特征压缩率为1.5倍至620倍，并且在某些情况下可以达到10倍的推理速度提升，而无需失去性能。此外，这篇论文的特征选择方法也超过了许多现有的工具包，例如LightGBM和Random Forests，在特定的特征预算下（25%），Skinny Trees可以提高AUC性能，比LightGBM提高10.2%（最高达37.7%），比Random Forests提高3%（最高达12.5%）。<details>
<summary>Abstract</summary>
Joint feature selection and tree ensemble learning is a challenging task. Popular tree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests support feature selection post-training based on feature importances, which are known to be misleading, and can significantly hurt performance. We propose Skinny Trees: a toolkit for feature selection in tree ensembles, such that feature selection and tree ensemble learning occurs simultaneously. It is based on an end-to-end optimization approach that considers feature selection in differentiable trees with Group $\ell_0 - \ell_2$ regularization. We optimize with a first-order proximal method and present convergence guarantees for a non-convex and non-smooth objective. Interestingly, dense-to-sparse regularization scheduling can lead to more expressive and sparser tree ensembles than vanilla proximal method. On 15 synthetic and real-world datasets, Skinny Trees can achieve $1.5\times$ - $620\times$ feature compression rates, leading up to $10\times$ faster inference over dense trees, without any loss in performance. Skinny Trees lead to superior feature selection than many existing toolkits e.g., in terms of AUC performance for $25\%$ feature budget, Skinny Trees outperforms LightGBM by $10.2\%$ (up to $37.7\%$), and Random Forests by $3\%$ (up to $12.5\%$).
</details>
<details>
<summary>摘要</summary>
共同特征选择和树集合学习是一项具有挑战性的任务。常见的树集合工具包，例如梯度拟合树和随机森林，支持基于特征重要性的特征选择，这些特征选择是已知会导致性能下降的。我们提出了瘦树：一个特征选择在树集合学习中同时进行的工具包。它基于一个端到端优化方法，考虑特征选择在分子树中的分支权重 regularization。我们使用一种第一个贝叶幂方法并提供了对非对称和非均匀目标函数的收敛保证。有趣的是， dense-to-sparse 规则调度可以导致更具表达力和更稀疏的树集合，而不是原始的 proximal 方法。在 15 个 synthetic 和实际世界数据集上，瘦树可以实现 $1.5\times$ - $620\times$ 特征压缩率，导致 $10\times$ 更快的推理速度，而无损性能。瘦树在多个现有工具包中的特征选择表现更佳，例如在 $25\%$ 特征预算下，瘦树可以跟上 LightGBM 的 $10.2\%$ (最高 $37.7\%$)，并跟上 Random Forests 的 $3\%$ (最高 $12.5\%$)。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/cs.LG_2023_10_28/" data-id="cloq1wl8p00rz7o881rtja805" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/eess.IV_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T09:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/eess.IV_2023_10_28/">eess.IV - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Tracking-and-fast-imaging-of-a-translational-object-via-Fourier-modulation"><a href="#Tracking-and-fast-imaging-of-a-translational-object-via-Fourier-modulation" class="headerlink" title="Tracking and fast imaging of a translational object via Fourier modulation"></a>Tracking and fast imaging of a translational object via Fourier modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18732">http://arxiv.org/abs/2310.18732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijian Li, Xu-ri Yao, Wei Zhang, Yeliang Wang, Qing Zhao</li>
<li>for: 高速运动物体的追踪和图像化，具有各种应用领域的应用前景。</li>
<li>methods: 运用单ixel图像技术进行进程式捕捉高速运动物体，通过动作补偿以获得更好的图像质量。</li>
<li>results: 方法可以同时具有短的重建时间和高质量图像，并且可以实现对小物体的佳化追踪和边缘检测。<details>
<summary>Abstract</summary>
The tracking and imaging of high-speed moving objects hold significant promise for application in various fields. Single-pixel imaging enables the progressive capture of a fast-moving translational object through motion compensation. However, achieving a balance between a short reconstruction time and a good image quality is challenging. In this study, we present a approach that simultaneously incorporates position encoding and spatial information encoding through the Fourier patterns. The utilization of Fourier patterns with specific spatial frequencies ensures robust and accurate object localization. By exploiting the properties of the Fourier transform, our method achieves a remarkable reduction in time complexity and memory consumption while significantly enhancing image quality. Furthermore, we introduce an optimized sampling strategy specifically tailored for small moving objects, significantly reducing the required dwell time for imaging. The proposed method provides a practical solution for the real-time tracking, imaging and edge detection of translational objects, underscoring its considerable potential for diverse applications.
</details>
<details>
<summary>摘要</summary>
高速移动物体的跟踪和成像具有广泛的应用前景。单像素成像可以逐步捕捉fast-moving translational object，通过运动补偿来实现。但是，实现一个好的图像质量和重建时间短的 equilibrio却是挑战。在这种研究中，我们提出了一种方法，同时 incorporates position encoding和空间信息编码通过干扰Patterns。通过利用干扰transform的特性，我们的方法可以remarkably reduce时间复杂度和内存占用，同时显著提高图像质量。此外，我们还提出了专门为小 objetes introduce an optimized sampling strategy, significantly reducing the required dwell time for imaging.该方法提供了一个实用的解决方案，可以实时跟踪、成像和Edge detection of translational objects，强调其广泛的应用前景。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/eess.IV_2023_10_28/" data-id="cloq1wlfe018k7o887reqe9fd" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/eess.SP_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T08:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/eess.SP_2023_10_28/">eess.SP - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-Epileptic-Seizure-Detection-with-EEG-Feature-Embeddings"><a href="#Enhancing-Epileptic-Seizure-Detection-with-EEG-Feature-Embeddings" class="headerlink" title="Enhancing Epileptic Seizure Detection with EEG Feature Embeddings"></a>Enhancing Epileptic Seizure Detection with EEG Feature Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18767">http://arxiv.org/abs/2310.18767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arman Zarei, Bingzhao Zhu, Mahsa Shoaran</li>
<li>For: The paper aims to improve the performance of seizure detection systems using EEG signals by learning informative embeddings of the signals.* Methods: The proposed method converts raw EEG signals to appropriate embeddings, which are beneficial for various machine learning models.* Results: The proposed approach achieves significant improvements in sensitivity, specificity, and AUC score across multiple models, with a state-of-the-art classification performance of 100% sensitivity and 99% specificity.Here is the same information in Simplified Chinese text:* For: 这篇论文目的是使用EEG信号提高癫痫检测系统的性能。* Methods: 提议的方法是将原始EEG信号转换为有用的嵌入，这些嵌入对多种机器学习模型都是有利的。* Results: 提议的方法在多个模型上实现了显著提高的敏感性、特异性和AUC分数，并达到了新的顶峰性，即100%的敏感度和99%的特异度。<details>
<summary>Abstract</summary>
Epilepsy is one of the most prevalent brain disorders that disrupts the lives of millions worldwide. For patients with drug-resistant seizures, there exist implantable devices capable of monitoring neural activity, promptly triggering neurostimulation to regulate seizures, or alerting patients of potential episodes. Next-generation seizure detection systems heavily rely on high-accuracy machine learning-based classifiers to detect the seizure onset. Here, we propose to enhance the seizure detection performance by learning informative embeddings of the EEG signal. We empirically demonstrate, for the first time, that converting raw EEG signals to appropriate embeddings can significantly boost the performance of seizure detection algorithms. Importantly, we show that embedding features, which converts the raw EEG into an alternative representation, is beneficial for various machine learning models such as Logistic Regression, Multi-Layer Perceptron, Support Vector Machines, and Gradient Boosted Trees. The experiments were conducted on the CHB-MIT scalp EEG dataset. With the proposed EEG feature embeddings, we achieve significant improvements in sensitivity, specificity, and AUC score across multiple models. By employing this approach alongside an SVM classifier, we were able to attain state-of-the-art classification performance with a sensitivity of 100% and specificity of 99%, setting a new benchmark in the field.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:epsilepsy 是全球范围内最常见的脑部疾病之一，影响了数百万人。为了治疗这些药物抵抗性的癫痫病人，存在可以监测神经活动，迅速诱发神经刺激来调节癫痫的嵌入式设备。未来的癫痫检测系统几乎完全依赖于高精度机器学习模型来检测癫痫开始。在这里，我们提议通过学习有用的嵌入来增强癫痫检测性能。我们实际地示证，对于第一次癫痫检测，将raw EEG信号转换为合适的嵌入可以显著提高癫痫检测算法的性能。此外，我们还证明了嵌入特征可以为不同的机器学习模型，如Logistic Regression、Multi-Layer Perceptron、Support Vector Machines和Gradient Boosted Trees等提供有利。实验在CHB-MIT皮帽EEG数据集上进行。通过我们的EEG特征嵌入，我们在多个模型上实现了显著的改善，包括敏感性、特异性和AUC分数。通过与SVM分类器结合使用，我们实现了当前领域的最佳分类性能，敏感性为100%，特异性为99%。
</details></li>
</ul>
<hr>
<h2 id="Cluster-Based-Cell-Free-Massive-MIMO-Systems-A-Novel-Framework-to-Enhance-Spectral-Efficiency-with-Low-Complexity"><a href="#Cluster-Based-Cell-Free-Massive-MIMO-Systems-A-Novel-Framework-to-Enhance-Spectral-Efficiency-with-Low-Complexity" class="headerlink" title="Cluster-Based Cell-Free Massive MIMO Systems: A Novel Framework to Enhance Spectral Efficiency with Low Complexity"></a>Cluster-Based Cell-Free Massive MIMO Systems: A Novel Framework to Enhance Spectral Efficiency with Low Complexity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18734">http://arxiv.org/abs/2310.18734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Roshanghias, Reza Saadat<br>for: This paper aims to improve the spectral efficiency (SE) of distributed cell-free massive MIMO (CF-mMIMO) systems by proposing a novel cluster-based architecture.methods: The proposed cluster-based structure combines centralized and distributed configurations, with local precoders formed using collectively shared CSI within each cluster. The MMSE precoding technique is used to achieve optimal SE performance.results: The simulation results show that the proposed cluster-based framework achieves a significantly augmented SE compared to the distributed architecture, with the optimal SE attained using four clusters and the MMSE precoding technique. The computational complexity is reduced by over 85%. Additionally, the proposed approach outperforms the centralized structure in terms of SE.Here is the text in Simplified Chinese:for: 本文目的是提高分布式cell-free大MIMO系统的spectral efficiency（SE）。methods: 提议的集群结构 combinest中央化和分布式配置，通过每个集群内CSI的共享来形成本地预编码器。使用MMSE预编码技术来实现优化的SE性能。results: 仪表结果表明，提议的集群结构相比分布式结构，可以获得显著提高的SE性能，最佳SE性能在四个集群和MMSE预编码技术下实现，计算复杂度下降超过85%。此外，提议的方法还超越了中央结构的SE性能。<details>
<summary>Abstract</summary>
The issue of diminished spectral efficiency (SE) of the downlink (DL) transmission in distributed cell-free massive MIMO (CF-mMIMO) systems poses a significant challenge in terms of user equipment (UE) performance when compared to their centralized CF-mMIMO counterparts. The primary root cause of this issue can be attributed to the reduced efficacy of distributed precoders, which are devised using local channel state information (CSI) in distributed systems. This reduced efficacy becomes particularly pronounced in terms of interference mitigation when compared to centralized precoders. To address this issue, this paper proposes a novel architectural framework for CF-mMIMO systems, referred to herein as the "cluster-based structure." Within this innovative structure, a hybrid amalgamation of centralized and distributed configurations is employed, complemented by the introduction of a unique cluster arrangement for the access points (APs) within the network. In this design, the CSI of APs within each cluster is collectively shared within a local processor unit. Consequently, by harnessing this enhanced repository of local channel information, local precoders are formulated, which facilitate more effective interference mitigation with reduced computational complexity compared to the centralized approach. This approach ultimately results in a significantly augmented SE when contrasted with the distributed architecture. The simulation results unequivocally demonstrate that within the cluster-based framework, the optimal SE for the network is attained when utilizing four clusters in conjunction with the MMSE precoding technique, leading to a notable reduction in computational complexity exceeding 85%. Importantly, this approach surpasses the SE performance of the centralized structure.
</details>
<details>
<summary>摘要</summary>
分布式Cell-free巨观MIMO系统（CF-mMIMO）的下行传输（DL） Spectral Efficiency（SE）受到了明显的挑战，用户设备（UE）性能与中央CF-mMIMO对照之下显著下降。主要的根本原因在于分布式预编器的效果减退，这些预编器基于分布式系统中的本地频道状态信息（CSI）设计。在分布式系统中，这种减退的效果特别明显在干扰抑制方面，与中央预编器相比。为解决这一问题，本文提出了一种新的建筑框架，称为“分区结构”。在这种新的架构中， hybrid化中央和分布式配置是使用，并在网络中的APs之间创建了特有的帧排序。在这个设计中，APs在每个分区内的CSI是集中共享在本地处理单元中。通过利用这些增强的本地频道信息，本地预编器是计算更有效的干扰抑制，比中央方法更加简单。这种方法最终导致了分布式系统中的SE显著增加，与分布式架构相比，SE性能得到了显著提高。实验结果表明，在分区结构中，使用四个分区并与MMSE预编器技术相结合，可以获得网络的最佳SE，计算复杂度超过85%。这种方法还超越了中央结构的SE性能。
</details></li>
</ul>
<hr>
<h2 id="Two-stage-space-construction-for-real-time-modeling-of-distributed-parameter-systems-under-sparse-sensing"><a href="#Two-stage-space-construction-for-real-time-modeling-of-distributed-parameter-systems-under-sparse-sensing" class="headerlink" title="Two-stage space construction for real-time modeling of distributed parameter systems under sparse sensing"></a>Two-stage space construction for real-time modeling of distributed parameter systems under sparse sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18670">http://arxiv.org/abs/2310.18670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wei</li>
<li>for: This paper is written for real-time modeling of distributed parameter systems (DPSs) in cases of limited sensors.</li>
<li>methods: The paper introduces a two-stage spatial construction approach that uses a discrete space-completion method to recuperate spatiotemporal patterns of non-monitored locations, followed by the use of high-dimensional space construction methods to derive continuous spatial basis functions (SBFs). The nonlinear temporal model is identified and adjusted via long short-term memory (LSTM) neural networks.</li>
<li>results: The paper demonstrates the efficacy of the proposed modeling technique under sparse sensing using experimental tests conducted on a pouch-type Li-ion battery. The results show that the use of a cubic B-spline surface is an effective solution for optimizing space construction in the sense of least squares approximation.<details>
<summary>Abstract</summary>
Numerous industrial processes can be defined using distributed parameter systems (DPSs). This study introduces a two-stage spatial construction approach for real-time modeling of DPSs in cases of limited sensors. Initially, a discrete space-completion approach is created to recuperate the spatiotemporal patterns of non-monitored locations under sparse sensing. The high-dimensional space construction method is employed to derive continuous spatial basis functions (SBFs). The identification and adjustment of the nonlinear temporal model are carried out via the long short-term memory (LSTM) neural network. Eventually, the amalgamation of the derived SBFs and temporal model results in a spatially continuous model. The use of a cubic B-spline surface is validated as an effective solution for optimizing space construction in the sense of least squares approximation. Experimental tests conducted on a pouch-type Li-ion battery demonstrate the efficacy of the proposed modeling technique under sparse sensing. This work highlights the promise of sparse sensors in real-time full-space modeling for large-scale battery energy storage systems.
</details>
<details>
<summary>摘要</summary>
许多工业过程可以使用分布参数系统（DPS）进行定义。本研究提出了一种两Stage空间建构方法，用于实时模拟DPS，并且在有限感知的情况下进行模拟。首先，一种精简空间完成方法被创建，以恢复不监测区域的空间时间模式。然后，高维空间建构方法被应用，以 derivate连续空间基函数（SBF）。非线性时间模型的标识和调整由长Short-Term记忆神经网络（LSTM）完成。最后， derivate的 SBFs 和时间模型的结合，得到了一个连续空间模型。实验表明，使用立方BSpline面的方法可以有效地优化空间建构，从 least squares 的角度来看。这种方法在磁力牵引Li-ion电池的实验中得到了证明，并且表明了有限感知的感知器在实时全空间模型化方面的承诺。
</details></li>
</ul>
<hr>
<h2 id="Joint-Localization-and-Communication-Enhancement-in-Uplink-Integrated-Sensing-and-Communications-System-with-Clock-Asynchronism"><a href="#Joint-Localization-and-Communication-Enhancement-in-Uplink-Integrated-Sensing-and-Communications-System-with-Clock-Asynchronism" class="headerlink" title="Joint Localization and Communication Enhancement in Uplink Integrated Sensing and Communications System with Clock Asynchronism"></a>Joint Localization and Communication Enhancement in Uplink Integrated Sensing and Communications System with Clock Asynchronism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18630">http://arxiv.org/abs/2310.18630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Chen, XinXin He, Zhiyong Feng, Zhiqing Wei, Qixun Zhang, Xin Yuan, Ping Zhang</li>
<li>for: 提高单基站的射频定位和通信可靠性</li>
<li>methods: 利用多信号分类（MUSIC）基于抽象谱（AoA）估计，并在AoA估计中加入信号增强（CSI）估计，以消除额外复杂度。</li>
<li>results: 可以减少时钟偏移（TO）相关的频率变化引起的影响，并且可以实现单基站的射频定位。在实验中，提出的方案可以与最小二乘均方差（MMSE）CSI估计具有相同的比特错误率性能，并且可以提高射频定位的均方差Error（MSE）约8分质量单位。<details>
<summary>Abstract</summary>
In this paper, we propose a joint single-base localization and communication enhancement scheme for the uplink (UL) integrated sensing and communications (ISAC) system with asynchronism, which can achieve accurate single-base localization of user equipment (UE) and significantly improve the communication reliability despite the existence of timing offset (TO) due to the clock asynchronism between UE and base station (BS). Our proposed scheme integrates the CSI enhancement into the multiple signal classification (MUSIC)-based AoA estimation and thus imposes no extra complexity on the ISAC system. We further exploit a MUSIC-based range estimation method and prove that it can suppress the time-varying TO-related phase terms. Exploiting the AoA and range estimation of UE, we can estimate the location of UE. Finally, we propose a joint CSI and data signals-based localization scheme that can coherently exploit the data and the CSI signals to improve the AoA and range estimation, which further enhances the single-base localization of UE. The extensive simulation results show that the enhanced CSI can achieve equivalent bit error rate performance to the minimum mean square error (MMSE) CSI estimator. The proposed joint CSI and data signals-based localization scheme can achieve decimeter-level localization accuracy despite the existing clock asynchronism and improve the localization mean square error (MSE) by about 8 dB compared with the maximum likelihood (ML)-based benchmark method.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种同时进行单基地位置定位和通信增强方案，用于下降链（UL）结合感知通信（ISAC）系统中的异步问题，可以实现精确的单基地位置定位和提高通信可靠性，即使存在时钟偏移（TO）。我们的提议方案将增强因子（CSI）增强纳入多个信号分类（MUSIC）基于投射角（AoA）估计中，从而不增加ISAC系统的复杂性。我们进一步利用MUSIC基于距离估计方法，并证明它可以抑制时间变化的TO相关阶跃项。通过UE的AoA和距离估计，我们可以估计UE的位置。最后，我们提议一种同时使用CSI和数据信号的位置定位方案，可以具有协调利用数据和CSI信号来提高AoA和距离估计的优点，进而提高单基地位置定位精度。实验结果表明，提高CSI可以实现与最小平均方差（MMSE）CSI估计器相同的错误率性能。我们的联合CSI和数据信号基于位置定位方案可以在存在时钟偏移的情况下实现厘米级位置定位精度，并提高位置估计均方差（MSE）约8分贝比对最大likelihood（ML）参考方法。
</details></li>
</ul>
<hr>
<h2 id="A-Generalized-Statistical-Model-for-THz-wireless-Channel-with-Random-Atmospheric-Absorption"><a href="#A-Generalized-Statistical-Model-for-THz-wireless-Channel-with-Random-Atmospheric-Absorption" class="headerlink" title="A Generalized Statistical Model for THz wireless Channel with Random Atmospheric Absorption"></a>A Generalized Statistical Model for THz wireless Channel with Random Atmospheric Absorption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18616">http://arxiv.org/abs/2310.18616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranay Bhardwaj, S. M. Zafaruddin</li>
<li>for: 这个论文是为了研究和模型TERAHERTZ（THz）无线通信频率范围内的信号媒体特性和损害，以及这些损害对连接性和可靠性的影响。</li>
<li>methods: 这篇论文使用了γ分布来描述分子吸收率的Random Path-Loss，以及α-η-κ-μ分布来描述短期干扰。此外，论文还考虑了天线偏倾错误和接收机硬件缺陷。</li>
<li>results: 论文通过fox的H函数来描述信道障碍的共同统计效应，并分析了THz链路的失业概率，以证明提出的通用模型的分析可行性。 computer simulations也用于证明该模型在性能评估中的效果。<details>
<summary>Abstract</summary>
Current statistical channel models for Terahertz (THz) wireless communication primarily concentrate on the sub-THz band, mostly with $\alpha$-$\mu$ and Gaussian mixture fading distributions for short-term fading and deterministic modeling for atmospheric absorption. In this paper, we develop a generalized statistical model for signal propagation at THz frequencies considering random path-loss employing Gamma distribution for the molecular absorption coefficient, short-term fading characterized by the $\alpha$-$\eta$-$\kappa$-$\mu$ distribution, antenna misalignment errors, and transceiver hardware impairments. The proposed model can handle various propagation scenarios, including indoor and outdoor environments, backhaul/fronthaul situations, and complex urban settings. Using Fox's H-functions, we present the probability density function (PDF) and cumulative distribution function (CDF) that capture the combined statistical effects of channel impairments. We analyze the outage probability of a THz link to demonstrate the analytical tractability of the proposed generalized model. We present computer simulations to demonstrate the efficacy of the proposed model for performance assessment with the statistical effect of atmospheric absorption.
</details>
<details>
<summary>摘要</summary>
当前的天 Harrison（THz）无线通信频率模型主要集中在Sub-THz频段，通常使用α-μ和高斯混合折射分布来描述短期折射和大气吸收的 deterministic 模型。在本文中，我们开发了一种通用的天 Harrison（THz）信号卫星传播模型，考虑了随机路径损失，使用γ分布来描述分子吸收系数，短期折射由α-η-κ-μ分布 characterize，天线误差、发射机硬件不良等因素。该模型可以处理不同的传播enario，包括室内和室外环境，后向/前向 Situation，复杂的城市场景。使用Fox的H函数，我们提供了PDF和CDF，这些函数捕捉了天 Harrison（THz）通信频率的共同统计效应。我们分析了THz链接的失业概率，以示analytical tractability of the proposed generalized model。我们通过计算机实验证明了提案的模型在性能评估中的有效性，并且演示了天 Harrison（THz）通信频率的统计效应。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/eess.SP_2023_10_28/" data-id="cloq1wlgz01cf7o889ol4c161" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_10_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/27/cs.SD_2023_10_27/" class="article-date">
  <time datetime="2023-10-27T15:00:00.000Z" itemprop="datePublished">2023-10-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/27/cs.SD_2023_10_27/">cs.SD - 2023-10-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enabling-Acoustic-Audience-Feedback-in-Large-Virtual-Events"><a href="#Enabling-Acoustic-Audience-Feedback-in-Large-Virtual-Events" class="headerlink" title="Enabling Acoustic Audience Feedback in Large Virtual Events"></a>Enabling Acoustic Audience Feedback in Large Virtual Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18099">http://arxiv.org/abs/2310.18099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tamay Aykut, Markus Hofbauer, Christopher Kuhn, Eckehard Steinbach, Bernd Girod</li>
<li>for: 提供一个虚拟观众框架，实现虚拟会议中的现场氛围和观众反馈。</li>
<li>methods: 收集本地观众反馈，并将其提交虚拟观众服务器。将组合的虚拟观众反馈资讯传递给所有参加者，并将其转换为单一的音频反馈。</li>
<li>results: 提供一个可以实现现场氛围和观众反馈的虚拟观众框架，实现了虚拟会议中的现场氛围和观众反馈。<details>
<summary>Abstract</summary>
The COVID-19 pandemic shifted many events in our daily lives into the virtual domain. While virtual conference systems provide an alternative to physical meetings, larger events require a muted audience to avoid an accumulation of background noise and distorted audio. However, performing artists strongly rely on the feedback of their audience. We propose a concept for a virtual audience framework which supports all participants with the ambience of a real audience. Audience feedback is collected locally, allowing users to express enthusiasm or discontent by selecting means such as clapping, whistling, booing, and laughter. This feedback is sent as abstract information to a virtual audience server. We broadcast the combined virtual audience feedback information to all participants, which can be synthesized as a single acoustic feedback by the client. The synthesis can be done by turning the collective audience feedback into a prompt that is fed to state-of-the-art models such as AudioGen. This way, each user hears a single acoustic feedback sound of the entire virtual event, without requiring to unmute or risk hearing distorted, unsynchronized feedback.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行使得许多日常生活活动转移到虚拟领域。虚拟会议系统为物理会议提供了替代方案，但是大型活动需要干杂背景噪音和扭曲的音频避免。但是表演艺术家强调audience反馈的重要性。我们提出了一种虚拟听众框架，该框架支持所有参与者在虚拟环境中感受到真实听众的氛围。听众反馈被本地收集，用户可以通过选择方式如掌声、喊喊、嘘声和笑声表达积极或不满。这些反馈信息被发送到虚拟听众服务器，然后将所有参与者发送的反馈信息组合并 Broadcast。客户端可以将这些反馈信息 sinthez为单一的音频反馈，不需要静音或听到扭曲的反馈。
</details></li>
</ul>
<hr>
<h2 id="TorchAudio-2-1-Advancing-speech-recognition-self-supervised-learning-and-audio-processing-components-for-PyTorch"><a href="#TorchAudio-2-1-Advancing-speech-recognition-self-supervised-learning-and-audio-processing-components-for-PyTorch" class="headerlink" title="TorchAudio 2.1: Advancing speech recognition, self-supervised learning, and audio processing components for PyTorch"></a>TorchAudio 2.1: Advancing speech recognition, self-supervised learning, and audio processing components for PyTorch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17864">http://arxiv.org/abs/2310.17864</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pytorch/audio">https://github.com/pytorch/audio</a></li>
<li>paper_authors: Jeff Hwang, Moto Hira, Caroline Chen, Xiaohui Zhang, Zhaoheng Ni, Guangzhi Sun, Pingchuan Ma, Ruizhe Huang, Vineel Pratap, Yuekai Zhang, Anurag Kumar, Chin-Yun Yu, Chuang Zhu, Chunxi Liu, Jacob Kahn, Mirco Ravanelli, Peng Sun, Shinji Watanabe, Yangyang Shi, Yumeng Tao, Robin Scheibler, Samuele Cornell, Sean Kim, Stavros Petridis</li>
<li>for: 本文旨在探讨TorchAudio库的开发原则和内容，以及其最新版本（2.1）中包含的关键特性和功能。</li>
<li>methods: 本文使用自动学习预训练管道和高性能CTC解码器、语音识别模型和训练规则、高级媒体输入&#x2F;输出功能和多通道语音提升工具等方法。</li>
<li>results: 本文通过实证研究，证明了一些特性和功能的有效性，并达到了竞争性或者国际先进水平的表现。<details>
<summary>Abstract</summary>
TorchAudio is an open-source audio and speech processing library built for PyTorch. It aims to accelerate the research and development of audio and speech technologies by providing well-designed, easy-to-use, and performant PyTorch components. Its contributors routinely engage with users to understand their needs and fulfill them by developing impactful features. Here, we survey TorchAudio's development principles and contents and highlight key features we include in its latest version (2.1): self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment. For a selection of these features, through empirical studies, we demonstrate their efficacy and show that they achieve competitive or state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
torchAudio 是一个开源的音频和语音处理库，建立在 PyTorch 之上，旨在加速音频和语音技术的研究和开发。它的贡献者们routinely与用户交流，了解他们的需求，并通过开发有力量的功能来满足他们。在这篇文章中，我们将survey torchAudio 的开发原则和内容，并强调最新版本（2.1）中包含的关键功能。这些功能包括：自然语言处理预训练管道和训练规程，高性能的 CTC 解码器，语音识别模型和训练规程，高级媒体 I/O 能力，以及用于强制对应、多通道语音增强和无参考语音评估的工具。对这些功能的一些特点，我们通过实验研究证明了它们的有效性，并证明它们在比较或国际级的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/27/cs.SD_2023_10_27/" data-id="cloq1wlbi00za7o889xbaegel" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_10_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/27/eess.AS_2023_10_27/" class="article-date">
  <time datetime="2023-10-27T14:00:00.000Z" itemprop="datePublished">2023-10-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/27/eess.AS_2023_10_27/">eess.AS - 2023-10-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Improved-Lossless-Coding-for-Storage-and-Transmission-of-Multichannel-Immersive-Audio"><a href="#Improved-Lossless-Coding-for-Storage-and-Transmission-of-Multichannel-Immersive-Audio" class="headerlink" title="Improved Lossless Coding for Storage and Transmission of Multichannel Immersive Audio"></a>Improved Lossless Coding for Storage and Transmission of Multichannel Immersive Audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18461">http://arxiv.org/abs/2310.18461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Toni Hirvonen, Mahmoud Namazi</li>
<li>for: 提高多渠道无损编码的效率，用于听众体验技术</li>
<li>methods: 提议同时编码多个不同渠道的内容，使用过去样本和当前时间样本来预测混合音频，并使用一般线性解法优化模型参数，最后使用rice编码处理剩余信息</li>
<li>results: 相比基eline，提议方法能够提高听众体验技术的压缩率，包括存储和传输Here’s a breakdown of each point:</li>
<li>for: The paper is written for the purpose of improving the efficiency of multichannel lossless coding, which is used in audio compression technology.</li>
<li>methods: The proposed method uses a signal model that predicts the upmix based on both past samples of the upmix and current time samples of the downmix. The model parameters are optimized using a general linear solver, and the prediction residual is Rice coded. Additionally, the use of an SVD projection prior to residual coding is proposed.</li>
<li>results: The proposed method shows improved compression ratios compared to various baselines, including FLAC, for the storage and transmission of immersive audio.<details>
<summary>Abstract</summary>
In this paper, techniques for improving multichannel lossless coding are examined. A method is proposed for the simultaneous coding of two or more different renderings (mixes) of the same content. The signal model uses both past samples of the upmix, and the current time samples of downmix samples to predict the upmix. Model parameters are optimized via a general linear solver, and the prediction residual is Rice coded. Additionally, the use of an SVD projection prior to residual coding is proposed. A comparison is made against various baselines, including FLAC. The proposed methods show improved compression ratios for the storage and transmission of immersive audio.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了多通道无损编码技术的改进方法。我们提议同时编码两个或更多不同的渲染（混合）的同一个内容。信号模型使用过去时间amples的混合和当前时间amples的混合样本来预测混合。模型参数通过一般线性解决器优化，预测差异用Rice编码。此外，我们还提出了SVD проекции前置 residual编码的方法。与不同的基准值进行比较，我们的方法显示在具有幂扩增音频存储和传输中提供了更好的压缩比率。
</details></li>
</ul>
<hr>
<h2 id="MixRep-Hidden-Representation-Mixup-for-Low-Resource-Speech-Recognition"><a href="#MixRep-Hidden-Representation-Mixup-for-Low-Resource-Speech-Recognition" class="headerlink" title="MixRep: Hidden Representation Mixup for Low-Resource Speech Recognition"></a>MixRep: Hidden Representation Mixup for Low-Resource Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18450">http://arxiv.org/abs/2310.18450</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiamin1013/mixrep-espnet">https://github.com/jiamin1013/mixrep-espnet</a></li>
<li>paper_authors: Jiamin Xie, John H. L. Hansen</li>
<li>for: 本研究旨在提出一种简单有效的数据增强策略基于mixup，用于低资源ASR。</li>
<li>methods: 本文提出了 interpolating the feature dimensions of hidden representations in the neural network，可以应用于输入和每层输出的feature。此外，我们还提出了将mixup与时间轴的regulization相结合，并应用到ConformerEncoder上。</li>
<li>results: 实验结果表明，MixRep可以在低资源ASR中提供更高的性能，比其他增强方法更好。与SpecAugment强制比较，MixRep在eval92集和Callhome部分的eval’2000集上减少了相对WRER值6.5%和6.7%。<details>
<summary>Abstract</summary>
In this paper, we present MixRep, a simple and effective data augmentation strategy based on mixup for low-resource ASR. MixRep interpolates the feature dimensions of hidden representations in the neural network that can be applied to both the acoustic feature input and the output of each layer, which generalizes the previous MixSpeech method. Further, we propose to combine the mixup with a regularization along the time axis of the input, which is shown as complementary. We apply MixRep to a Conformer encoder of an E2E LAS architecture trained with a joint CTC loss. We experiment on the WSJ dataset and subsets of the SWB dataset, covering reading and telephony conversational speech. Experimental results show that MixRep consistently outperforms other regularization methods for low-resource ASR. Compared to a strong SpecAugment baseline, MixRep achieves a +6.5\% and a +6.7\% relative WER reduction on the eval92 set and the Callhome part of the eval'2000 set.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种基于mixup的简单有效数据扩大策略，称为MixRep，用于低资源ASR。MixRep interpolates the feature dimensions of hidden representations in the neural network, which can be applied to both the acoustic feature input and the output of each layer, thus generalizing the previous MixSpeech method。另外，我们提议将mixup与时间轴方向的准则相结合，以便增强其效果。我们在一个Conformer编码器上应用MixRep，并使用一个CTC损失函数进行训练。我们在WSJ dataset和SWB dataset的一些子集上进行实验，包括读取和电话交流的语音。实验结果表明，MixRep在低资源ASR中consistently outperform其他准则方法。相比于一个强大的SpecAugment基准，MixRep在eval92集和Callhome部分的eval'2000集上实现了+6.5%和+6.7%的相对WRER降低。
</details></li>
</ul>
<hr>
<h2 id="Relative-Transfer-Function-Vector-Estimation-for-Acoustic-Sensor-Networks-Exploiting-Covariance-Matrix-Structure"><a href="#Relative-Transfer-Function-Vector-Estimation-for-Acoustic-Sensor-Networks-Exploiting-Covariance-Matrix-Structure" class="headerlink" title="Relative Transfer Function Vector Estimation for Acoustic Sensor Networks Exploiting Covariance Matrix Structure"></a>Relative Transfer Function Vector Estimation for Acoustic Sensor Networks Exploiting Covariance Matrix Structure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18199">http://arxiv.org/abs/2310.18199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wiebke Middelberg, Henri Gode, Simon Doclo</li>
<li>for: 这篇论文主要针对的是听音环境中多个杂音源的噪声减少问题。</li>
<li>methods: 这篇论文提出了两种Relative Transfer Function（RTF）向量估计方法，其中一种是基于噪声covariance矩阵的whitening方法，另一种是基于噪声矩阵的off-diagonal块选择方法。</li>
<li>results: 在使用这两种方法后，对真实的频谱记录进行了 simulated 环境中的 reverberation 环境中的多个噪声源下的噪声减少测试，结果显示，modified CW方法与CW方法相比，有slightly better的SNR提升表现，而off-diagonal选择方法则超过了偏向RTF向量估计。<details>
<summary>Abstract</summary>
In many multi-microphone algorithms for noise reduction, an estimate of the relative transfer function (RTF) vector of the target speaker is required. The state-of-the-art covariance whitening (CW) method estimates the RTF vector as the principal eigenvector of the whitened noisy covariance matrix, where whitening is performed using an estimate of the noise covariance matrix. In this paper, we consider an acoustic sensor network consisting of multiple microphone nodes. Assuming uncorrelated noise between the nodes but not within the nodes, we propose two RTF vector estimation methods that leverage the block-diagonal structure of the noise covariance matrix. The first method modifies the CW method by considering only the diagonal blocks of the estimated noise covariance matrix. In contrast, the second method only considers the off-diagonal blocks of the noisy covariance matrix, but cannot be solved using a simple eigenvalue decomposition. When applying the estimated RTF vector in a minimum variance distortionless response beamformer, simulation results for real-world recordings in a reverberant environment with multiple noise sources show that the modified CW method performs slightly better than the CW method in terms of SNR improvement, while the off-diagonal selection method outperforms a biased RTF vector estimate obtained as the principal eigenvector of the noisy covariance matrix.
</details>
<details>
<summary>摘要</summary>
多频器算法中的Target speaker的相对传输函数（RTF）向量估计是多频器算法中非常重要的一个步骤。现在的State-of-the-art方法是covariance whitening（CW）方法，它估计RTF向量为白化后的噪声矩阵中的主要特征向量。在这篇论文中，我们考虑了一个包含多个麦克风节点的声学感知网络。假设 node之间的噪声是独立的，但不是内部独立的，我们提出了两种RTF向量估计方法，它们都利用噪声矩阵的块对称结构。第一种方法是修改CW方法，只考虑预估噪声矩阵的对角块。相比之下，第二种方法只考虑噪声矩阵的偏置块，但不可以使用简单的特征值分解来解决。当应用估计RTF向量在无损杂点抗噪声器中时，通过使用实际录制的真实环境中的多个噪声源，我们的simulation结果显示，修改CW方法与CW方法在SNR提高方面的性能略微不同，而偏置选择方法则超过偏置RTF向量估计。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/27/eess.AS_2023_10_27/" data-id="cloq1wlcy012e7o8809ag356x" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_10_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/27/cs.CV_2023_10_27/" class="article-date">
  <time datetime="2023-10-27T13:00:00.000Z" itemprop="datePublished">2023-10-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/27/cs.CV_2023_10_27/">cs.CV - 2023-10-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Using-convolutional-neural-networks-for-stereological-characterization-of-3D-hetero-aggregates-based-on-synthetic-STEM-data"><a href="#Using-convolutional-neural-networks-for-stereological-characterization-of-3D-hetero-aggregates-based-on-synthetic-STEM-data" class="headerlink" title="Using convolutional neural networks for stereological characterization of 3D hetero-aggregates based on synthetic STEM data"></a>Using convolutional neural networks for stereological characterization of 3D hetero-aggregates based on synthetic STEM data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18523">http://arxiv.org/abs/2310.18523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Fuchs, Tom Kirstein, Christoph Mahr, Orkun Furat, Valentin Baric, Andreas Rosenauer, Lutz Maedler, Volker Schmidt</li>
<li>for: 这个论文的目的是研究三维结构的异构聚合体，以derive process-structure或structure-property关系。</li>
<li>methods: 这个论文使用机器学习和空间随机模型的方法，通过生成Synthetic Training Data来 overcome 3D imaging技术的问题。</li>
<li>results: 这个论文提出了一种基于机器学习和空间随机模型的方法，可以从2D图像中预测3D结构。此外，论文还进行了错误分析，以评估这种预测方法的准确性。<details>
<summary>Abstract</summary>
The structural characterization of hetero-aggregates in 3D is of great interest, e.g., for deriving process-structure or structure-property relationships. However, since 3D imaging techniques are often difficult to perform as well as time and cost intensive, a characterization of hetero-aggregates based on 2D image data is desirable, but often non-trivial. To overcome the issues of characterizing 3D structures from 2D measurements, a method is presented that relies on machine learning combined with methods of spatial stochastic modeling, where the latter are utilized for the generation of synthetic training data. This kind of training data has the advantage that time-consuming experiments for the synthesis of differently structured materials followed by their 3D imaging can be avoided. More precisely, a parametric stochastic 3D model is presented, from which a wide spectrum of virtual hetero-aggregates can be generated. Additionally, the virtual structures are passed to a physics-based simulation tool in order to generate virtual scanning transmission electron microscopy (STEM) images. The preset parameters of the 3D model together with the simulated STEM images serve as a database for the training of convolutional neural networks, which can be used to determine the parameters of the underlying 3D model and, consequently, to predict 3D structures of hetero-aggregates from 2D STEM images. Furthermore, an error analysis is performed to evaluate the prediction power of the trained neural networks with respect to structural descriptors, e.g. the hetero-coordination number.
</details>
<details>
<summary>摘要</summary>
“三维结构Characterization的研究对于异化体组合物有很大的 интерес，例如 derivation of process-structure or structure-property relationships. However, since 3D imaging techniques are often difficult to perform and time-consuming, a characterization of hetero-aggregates based on 2D image data is desirable but challenging. To overcome the limitations of characterizing 3D structures from 2D measurements, a method is proposed that combines machine learning with spatial stochastic modeling. This approach utilizes synthetic training data generated by the latter method to avoid time-consuming experiments for the synthesis of differently structured materials and their 3D imaging. Specifically, a parametric stochastic 3D model is presented, from which a wide spectrum of virtual hetero-aggregates can be generated. The virtual structures are then passed to a physics-based simulation tool to generate virtual scanning transmission electron microscopy (STEM) images. The pre-set parameters of the 3D model and the simulated STEM images serve as a database for training convolutional neural networks, which can be used to determine the parameters of the underlying 3D model and predict 3D structures of hetero-aggregates from 2D STEM images. Additionally, an error analysis is performed to evaluate the prediction power of the trained neural networks with respect to structural descriptors, such as the hetero-coordination number.”Note that Simplified Chinese is used in this translation, which is a standardized form of Chinese that is easier to read and write than Traditional Chinese. However, if you prefer Traditional Chinese, I can also provide the translation in that format.
</details></li>
</ul>
<hr>
<h2 id="Learning-to-recognize-occluded-and-small-objects-with-partial-inputs"><a href="#Learning-to-recognize-occluded-and-small-objects-with-partial-inputs" class="headerlink" title="Learning to recognize occluded and small objects with partial inputs"></a>Learning to recognize occluded and small objects with partial inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18517">http://arxiv.org/abs/2310.18517</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hasibzunair/msl-recognition">https://github.com/hasibzunair/msl-recognition</a></li>
<li>paper_authors: Hasib Zunair, A. Ben Hamza</li>
<li>for: 多个图像中的多个对象识别，特别是当这些对象小时， occlusion 问题更加困难。</li>
<li>methods: 我们提出了Masked Supervised Learning（MSL），一种单stage，无需特定模型的学习方法，通过遮盲分支学习 context-based 表示，并通过标签一致性来模型标签的相互关系。</li>
<li>results: 实验结果表明，MSL 能够与之前的状态图像识别方法竞争，并且可以快速、简单地应用于多个标签图像识别任务。此外，我们还证明了MSL 对随机遮盲的稳定性和非遮盲对象的识别能力。代码和预训练模型可以在 GitHub 上获取。<details>
<summary>Abstract</summary>
Recognizing multiple objects in an image is challenging due to occlusions, and becomes even more so when the objects are small. While promising, existing multi-label image recognition models do not explicitly learn context-based representations, and hence struggle to correctly recognize small and occluded objects. Intuitively, recognizing occluded objects requires knowledge of partial input, and hence context. Motivated by this intuition, we propose Masked Supervised Learning (MSL), a single-stage, model-agnostic learning paradigm for multi-label image recognition. The key idea is to learn context-based representations using a masked branch and to model label co-occurrence using label consistency. Experimental results demonstrate the simplicity, applicability and more importantly the competitive performance of MSL against previous state-of-the-art methods on standard multi-label image recognition benchmarks. In addition, we show that MSL is robust to random masking and demonstrate its effectiveness in recognizing non-masked objects. Code and pretrained models are available on GitHub.
</details>
<details>
<summary>摘要</summary>
Recognizing multiple objects in an image is challenging due to occlusions, and becomes even more so when the objects are small. While existing multi-label image recognition models show promise, they do not explicitly learn context-based representations, and therefore struggle to correctly recognize small and occluded objects. Intuitively, recognizing occluded objects requires knowledge of partial input, and hence context. Motivated by this intuition, we propose Masked Supervised Learning (MSL), a single-stage, model-agnostic learning paradigm for multi-label image recognition. The key idea is to learn context-based representations using a masked branch and to model label co-occurrence using label consistency. Experimental results demonstrate the simplicity, applicability, and more importantly the competitive performance of MSL against previous state-of-the-art methods on standard multi-label image recognition benchmarks. In addition, we show that MSL is robust to random masking and demonstrate its effectiveness in recognizing non-masked objects. Code and pretrained models are available on GitHub.Here's the translation in Traditional Chinese:识别多个图像中的物体是困难的，尤其是当物体小时。现有的多 Label 图像识别模型虽然有推荐，但是它们不会直接学习上下文基于的表现，因此对于小和遮蔽的物体来说，其表现不佳。我们受到这个直觉的动机，提出了几个概念，包括：几个 Label 的共同出现，以及对于部分输入的知识。我们提出了一个单阶段、无法检测的学习方法，即掩盖Supervised Learning (MSL)，以学习上下文基于的表现。我们的关键思想是，通过掩盖分支来学习上下文基于的表现，并且使用标签的共同出现来模型标签的共同性。我们的实验结果显示，MSL 的简单性、应用性和更重要的是，与前一代方法相比，其表现非常竞争。此外，我们还证明了 MSL 在随机掩盖下是稳定的，并且在非掩盖的情况下表现良好。我们的代码和预训模型都可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="GPT-4-Vision-on-Medical-Image-Classification-–-A-Case-Study-on-COVID-19-Dataset"><a href="#GPT-4-Vision-on-Medical-Image-Classification-–-A-Case-Study-on-COVID-19-Dataset" class="headerlink" title="GPT-4 Vision on Medical Image Classification – A Case Study on COVID-19 Dataset"></a>GPT-4 Vision on Medical Image Classification – A Case Study on COVID-19 Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18498">http://arxiv.org/abs/2310.18498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruibo Chen, Tianyi Xiong, Yihan Wu, Guodong Liu, Zhengmian Hu, Lichang Chen, Yanshuo Chen, Chenxi Liu, Heng Huang</li>
<li>for: 这份技术报告探讨了 COVID-19 图像分类领域中 GPT-4 Vision (GPT-4V) 的应用，通过培养学习环境中的启发性来提高诊断过程。</li>
<li>methods: 该文使用 GPT-4V 在 COVID-19 图像中进行了启发性学习，以提高图像分类的准确率。</li>
<li>results: 研究发现，通过使用 GPT-4V，图像分类的准确率得到了显著提高，表明了 GPT-4V 在 COVID-19 图像分类中的潜在应用价值。<details>
<summary>Abstract</summary>
This technical report delves into the application of GPT-4 Vision (GPT-4V) in the nuanced realm of COVID-19 image classification, leveraging the transformative potential of in-context learning to enhance diagnostic processes.
</details>
<details>
<summary>摘要</summary>
这份技术报告探讨了 COVID-19 图像分类领域中 GPT-4 Vision（GPT-4V）的应用，利用 context learning 的潜在力量提高诊断过程。Note:* "GPT-4V" is translated as "GPT-4 Vision" (格PT-4视力)* "in-context learning" is translated as " context learning" (上下文学习)* "diagnostic processes" is translated as "诊断过程" (诊断过程)
</details></li>
</ul>
<hr>
<h2 id="Knowledge-based-in-silico-models-and-dataset-for-the-comparative-evaluation-of-mammography-AI-for-a-range-of-breast-characteristics-lesion-conspicuities-and-doses"><a href="#Knowledge-based-in-silico-models-and-dataset-for-the-comparative-evaluation-of-mammography-AI-for-a-range-of-breast-characteristics-lesion-conspicuities-and-doses" class="headerlink" title="Knowledge-based in silico models and dataset for the comparative evaluation of mammography AI for a range of breast characteristics, lesion conspicuities and doses"></a>Knowledge-based in silico models and dataset for the comparative evaluation of mammography AI for a range of breast characteristics, lesion conspicuities and doses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18494">http://arxiv.org/abs/2310.18494</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/didsr/msynth-release">https://github.com/didsr/msynth-release</a></li>
<li>paper_authors: Elena Sizikova, Niloufar Saharkhiz, Diksha Sharma, Miguel Lago, Berkman Sahiner, Jana G. Delfino, Aldo Badano</li>
<li>for: 评估人工智能（AI）医疗设备的安全性和效能，需要评估AI模型在不同的患者群体中表现。</li>
<li>methods: 我们提出一种基于计算机模拟的评估方法，使用干扰性的数字模型来模拟人体解剖结构，并使用数字复制成像系统来生成真实的synthetic图像集。</li>
<li>results: 我们释放了M-SYNTH数据集，包含四种乳腺纤维质分布的人群，通过Monte Carlo x射线计算模拟不同的暴露水平进行图像捕获。我们发现，随着乳腺纤维质的增加，AI模型的性能逐渐下降，而随着质量的增加，AI模型的性能则逐渐提高。随着暴露水平的减少，AI模型的性能下降，最高的性能出现在较低的暴露水平下。<details>
<summary>Abstract</summary>
To generate evidence regarding the safety and efficacy of artificial intelligence (AI) enabled medical devices, AI models need to be evaluated on a diverse population of patient cases, some of which may not be readily available. We propose an evaluation approach for testing medical imaging AI models that relies on in silico imaging pipelines in which stochastic digital models of human anatomy (in object space) with and without pathology are imaged using a digital replica imaging acquisition system to generate realistic synthetic image datasets. Here, we release M-SYNTH, a dataset of cohorts with four breast fibroglandular density distributions imaged at different exposure levels using Monte Carlo x-ray simulations with the publicly available Virtual Imaging Clinical Trial for Regulatory Evaluation (VICTRE) toolkit. We utilize the synthetic dataset to analyze AI model performance and find that model performance decreases with increasing breast density and increases with higher mass density, as expected. As exposure levels decrease, AI model performance drops with the highest performance achieved at exposure levels lower than the nominal recommended dose for the breast type.
</details>
<details>
<summary>摘要</summary>
<<SYS>>为了生成人工智能（AI）医疗设备的安全性和有效性的证据，我们需要对各种患者群体的病例进行评估。我们提出了一种使用数字医学ipeline进行医学影像AI模型的评估方法，其中使用了卫星模型来生成人工的影像数据集。在这种方法中，我们使用了VICTRE工具包来进行Monte Carlo x射线计算，生成了不同抑制物质分布的胸部病例数据集。我们通过分析这些数据来评估AI模型的性能，发现模型性能随着乳腺细胞分布的增加而下降，而模型在高质量细胞分布下的性能最高。随着曝光水平的下降，AI模型的性能下降，最佳性能在低于标准推荐剂量之下得到。>>>
</details></li>
</ul>
<hr>
<h2 id="Exploring-Shape-Embedding-for-Cloth-Changing-Person-Re-Identification-via-2D-3D-Correspondences"><a href="#Exploring-Shape-Embedding-for-Cloth-Changing-Person-Re-Identification-via-2D-3D-Correspondences" class="headerlink" title="Exploring Shape Embedding for Cloth-Changing Person Re-Identification via 2D-3D Correspondences"></a>Exploring Shape Embedding for Cloth-Changing Person Re-Identification via 2D-3D Correspondences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18438">http://arxiv.org/abs/2310.18438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubin Wang, Huimin Yu, Yuming Yan, Shuyi Song, Biyang Liu, Yichong Lu<br>for: 这篇论文旨在解决 cloth-changing ReID 问题，即人脸识别 task 中人物穿着不同服装时的问题。methods: 这篇论文提出了一种新的 shape embedding 方法，即 Continuous Surface Correspondence Learning (CSCL)，它通过Pixel-to-vertex classification来建立人像与3D人体模型之间的连续匹配，从而获取人像与3D模型之间的匹配点。results: 实验表明，CSCL 方法可以remarkably enhance the model’s global understanding of human body shape，并在 cloth-changing ReID 和 cloth-consistent ReID Benchmarks 上达到了出色的效果。<details>
<summary>Abstract</summary>
Cloth-Changing Person Re-Identification (CC-ReID) is a common and realistic problem since fashion constantly changes over time and people's aesthetic preferences are not set in stone. While most existing cloth-changing ReID methods focus on learning cloth-agnostic identity representations from coarse semantic cues (e.g. silhouettes and part segmentation maps), they neglect the continuous shape distributions at the pixel level. In this paper, we propose Continuous Surface Correspondence Learning (CSCL), a new shape embedding paradigm for cloth-changing ReID. CSCL establishes continuous correspondences between a 2D image plane and a canonical 3D body surface via pixel-to-vertex classification, which naturally aligns a person image to the surface of a 3D human model and simultaneously obtains pixel-wise surface embeddings. We further extract fine-grained shape features from the learned surface embeddings and then integrate them with global RGB features via a carefully designed cross-modality fusion module. The shape embedding paradigm based on 2D-3D correspondences remarkably enhances the model's global understanding of human body shape. To promote the study of ReID under clothing change, we construct 3D Dense Persons (DP3D), which is the first large-scale cloth-changing ReID dataset that provides densely annotated 2D-3D correspondences and a precise 3D mesh for each person image, while containing diverse cloth-changing cases over all four seasons. Experiments on both cloth-changing and cloth-consistent ReID benchmarks validate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
cloth-changing 人识别 (CC-ReID) 是一个常见并且现实存在的问题，因为时尚不断发展，人们的美学偏好也不是固定的。现有的 cloth-changing ReID 方法多数是通过学习粗略的 semantic cues（例如 silhouette 和 part segmentation map）来学习不同服装下的人脸特征，但是它们忽略了人体图像中精细的形状分布。在这篇文章中，我们提出了 Continuous Surface Correspondence Learning (CSCL)，一种新的形状嵌入方法，用于 cloth-changing ReID。CSCL 通过像素到顶点的分类来建立人体图像与Canonical 3D 人体模型之间的连续对应关系，从而自然地将人体图像与模型之间建立对应关系，同时获得像素级别的表面嵌入。我们还提取了高级别的形状特征从学习的表面嵌入，然后与全球 RGB 特征进行权重相乘。基于 2D-3D 对应关系的形状嵌入方法，可以强化模型对人体形状的全面理解。为了推动 cloth-changing ReID 的研究，我们构建了 3D Dense Persons (DP3D)，这是首个包含了不同的服装变化情况的 cloth-changing ReID 数据集，每个人像图像都有精 densely 注解的 2D-3D 对应关系和精确的 3D 网格。实验表明，我们的方法在 cloth-changing 和 cloth-consistent ReID Benchmark 上具有remarkable的效果。
</details></li>
</ul>
<hr>
<h2 id="Always-Clear-Days-Degradation-Type-and-Severity-Aware-All-In-One-Adverse-Weather-Removal"><a href="#Always-Clear-Days-Degradation-Type-and-Severity-Aware-All-In-One-Adverse-Weather-Removal" class="headerlink" title="Always Clear Days: Degradation Type and Severity Aware All-In-One Adverse Weather Removal"></a>Always Clear Days: Degradation Type and Severity Aware All-In-One Adverse Weather Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18293">http://arxiv.org/abs/2310.18293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Wei Chen, Soo-Chang Pei</li>
<li>for: 本研究旨在提出一种综合恢复多种恶势力影像的模型，以解决多种恶势力影像恢复中的两大挑战：第一，发现和处理多元领域的目标分布；第二，设计高效和有效的操作来处理不同类型的降低。</li>
<li>methods: 该模型基于inter&amp;intra-domain适应 literatura，并提出了一种新的Marginal Quality Ranking Loss（MQRL）和一种新的Contrastive Loss（CL）来引导气象情况的提取，以及一些新的技术如多头相关混合（MHCA）和本地-全局适应实例 нормализа（LG-AdaIN）来高效地恢复空间变化的气象降低。</li>
<li>results: 相比于现有的State-of-the-Art方法，该模型可以在不同的气象恢复任务中显著超越对手，并且具有较少的模型参数。此外，该模型还可以 Restore 未seen 领域的多种气象降低图像，并可以调整恢复水平。<details>
<summary>Abstract</summary>
All-in-one adverse weather removal is an emerging topic on image restoration, which aims to restore multiple weather degradation in an unified model, and the challenging are twofold. First, discovering and handling the property of multi-domain in target distribution formed by multiple weather conditions. Second, design efficient and effective operations for different degradation types. To address this problem, most prior works focus on the multi-domain caused by weather type. Inspired by inter\&intra-domain adaptation literature, we observed that not only weather type but also weather severity introduce multi-domain within each weather type domain, which is ignored by previous methods, and further limit their performance. To this end, we proposed a degradation type and severity aware model, called \textbf{UtilityIR}, for blind all-in-one bad weather image restoration. To extract weather information from single image, we proposed a novel Marginal Quality Ranking Loss (MQRL) and utilized Contrastive Loss (CL) to guide weather severity and type extraction, and leverage a bag of novel techniques such as Multi-Head Cross Attention (MHCA) and Local-Global Adaptive Instance Normalization (LG-AdaIN) to efficiently restore spatial varying weather degradation. The proposed method can significantly outperform the SOTA methods subjectively and objectively on different weather restoration tasks with a large margin, and enjoy less model parameters. Proposed method even can restore \textbf{unseen} domain combined multiple degradation images, and modulating restoration level. Implementation code will be available at {https://github.com/fordevoted/UtilityIR}{\textit{this repository}
</details>
<details>
<summary>摘要</summary>
全面天气环境去除是一个现代图像修复领域的热点问题，目标是通过一个统一模型来恢复多种天气下的图像异常情况，问题的两个级别是：首先，发现和处理目标分布中多个域的性质，其次，设计高效和有效的操作方法 для不同的退化类型。以前的大多数工作都是通过多种天气类型来处理多个域的问题，但是我们发现，不同的天气严重性也会在每个天气类型中引入多个域，这一点被以前的方法忽略了，从而限制了其性能。为了解决这个问题，我们提出了一种具有退化类型和严重性意识的模型，称为\textbf{UtilityIR}，用于盲目全面坏天气图像修复。为了从单个图像中提取天气信息，我们提出了一种新的环境质量排名损失函数（MQRL），并使用了对比损失函数（CL）来引导天气严重性和类型的提取，并利用了一系列新的技术，如多头交叉注意力（MHCA）和本地-全局适应实例均衡化（LG-AdaIN），以高效地恢复空间变化的天气退化。我们的方法可以Subjectively和Objectively在不同的天气修复任务上与state-of-the-art方法进行比较，并且具有较少的模型参数。我们的方法甚至可以恢复未经见过的多个退化图像，并可以调整修复水平。我们的实现代码将在[这个仓库](https://github.com/fordevoted/UtilityIR)上提供。
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-Federated-Learning-with-Group-Aware-Prompt-Tuning"><a href="#Heterogeneous-Federated-Learning-with-Group-Aware-Prompt-Tuning" class="headerlink" title="Heterogeneous Federated Learning with Group-Aware Prompt Tuning"></a>Heterogeneous Federated Learning with Group-Aware Prompt Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18285">http://arxiv.org/abs/2310.18285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Deng, Christos Thrampoulidis, Xiaoxiao Li</li>
<li>for: 这篇论文探讨了在联合学习（Federated Learning，FL）中使用转换器模型的应用，尤其是在具有多种本地数据的各种客户端上。</li>
<li>methods: 我们采用了预训练的转换器模型，并使用高效的提问调整策略。我们的策略是学习共享提问和组提问，以同时获得通用知识和组特定知识。此外，我们还设置了个性化组提问分配模块，以对每个输入分配个性化的组提问，使全球模型与每个客户端的数据分布相匹配。</li>
<li>results: 我们的方法可以让单个全球模型自动适应不同客户端的本地数据分布，不需要本地微调。与替换方法不同，我们的方法可以准确地跨越客户端之间的差异，从而实现联合学习中的全球和本地模型匹配。我们通过了广泛的实验和减少研究来证明方法的有效性。<details>
<summary>Abstract</summary>
Transformers have achieved remarkable success in various machine-learning tasks, prompting their widespread adoption. In this paper, we explore their application in the context of federated learning (FL), with a particular focus on heterogeneous scenarios where individual clients possess diverse local datasets. To meet the computational and communication demands of FL, we leverage pre-trained Transformers and use an efficient prompt-tuning strategy. Our strategy introduces the concept of learning both shared and group prompts, enabling the acquisition of universal knowledge and group-specific knowledge simultaneously. Additionally, a prompt selection module assigns personalized group prompts to each input, aligning the global model with the data distribution of each client. This approach allows us to train a single global model that can automatically adapt to various local client data distributions without requiring local fine-tuning. In this way, our proposed method effectively bridges the gap between global and personalized local models in Federated Learning and surpasses alternative approaches that lack the capability to adapt to previously unseen clients. The effectiveness of our approach is rigorously validated through extensive experimentation and ablation studies.
</details>
<details>
<summary>摘要</summary>
“对于联邦学习（Federated Learning，FL）的应用，trasnformers已经取得了杰出的成就，它们的广泛应用引起了广泛的关注。在本文中，我们探讨trasnformers在多种不同资料分布的联邦学习中的应用，特别是在客户端拥有多样化的本地数据时。为了解决联邦学习中的计算和通信需求，我们将pre-trained transformers和高效的提示调整策略应用于联邦学习。我们的策略是学习共享和分组提示，允许同时获取通用知识和分组特定知识。此外，提示选择模块将每个输入的个人化分组提示分配给每个客户端，使全球模型与每个客户端的数据分布保持一致。这种方法允许我们训练一个单一的全球模型，无需进行本地微调整，并且自动适应不同客户端的数据分布。因此，我们的提案可以有效地跨越全球和个人化的客户端模型之间的差异，超越缺乏适应不见前的客户端模型。我们的方法的有效性经过了广泛的实验和剥夺研究，以证明其可行性和优势。”
</details></li>
</ul>
<hr>
<h2 id="FOUND-Foot-Optimization-with-Uncertain-Normals-for-Surface-Deformation-Using-Synthetic-Data"><a href="#FOUND-Foot-Optimization-with-Uncertain-Normals-for-Surface-Deformation-Using-Synthetic-Data" class="headerlink" title="FOUND: Foot Optimization with Uncertain Normals for Surface Deformation Using Synthetic Data"></a>FOUND: Foot Optimization with Uncertain Normals for Surface Deformation Using Synthetic Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18279">http://arxiv.org/abs/2310.18279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oliver Boyne, Gwangbin Bae, James Charles, Roberto Cipolla</li>
<li>for: 这个论文的目的是为了实现几个视图图像中的表面重建 task，并且它特别关注人 Foot 的重建。</li>
<li>methods: 该论文使用了一种 uncertainty-aware 的表面法向量预测器，以及一种优化方案来适应一系列图像。</li>
<li>results: 论文表明其法向量预测器在实际图像上表现出色，而优化方案也在几个视图设置下比 estado del arte 光学测量管道表现更好。<details>
<summary>Abstract</summary>
Surface reconstruction from multi-view images is a challenging task, with solutions often requiring a large number of sampled images with high overlap. We seek to develop a method for few-view reconstruction, for the case of the human foot. To solve this task, we must extract rich geometric cues from RGB images, before carefully fusing them into a final 3D object. Our FOUND approach tackles this, with 4 main contributions: (i) SynFoot, a synthetic dataset of 50,000 photorealistic foot images, paired with ground truth surface normals and keypoints; (ii) an uncertainty-aware surface normal predictor trained on our synthetic dataset; (iii) an optimization scheme for fitting a generative foot model to a series of images; and (iv) a benchmark dataset of calibrated images and high resolution ground truth geometry. We show that our normal predictor outperforms all off-the-shelf equivalents significantly on real images, and our optimization scheme outperforms state-of-the-art photogrammetry pipelines, especially for a few-view setting. We release our synthetic dataset and baseline 3D scans to the research community.
</details>
<details>
<summary>摘要</summary>
表面重建从多视图图像是一项具有挑战性的任务，解决方案通常需要大量的采样图像和高重叠率。我们寻求开发一种几视图重建方法，专门针对人体脚部。为解决这个任务，我们需要从RGB图像中提取丰富的地理学特征，然后精心融合到最终的3D对象中。我们的FOUND方法从以下四个方面做出贡献：(i) SynFoot，一个包含50,000个真实风格的脚部图像，每个图像都有附加的表面法向量和关键点数据；(ii) 基于我们的 sintetic dataset 的不确定性感知表面法向量预测器；(iii) 用于把一系列图像适应到生成的脚部模型中的优化方案；(iv) 一个准备了卡лли布рован的图像和高分辨率的真实地理学几何结构的参考数据集。我们表明我们的normal预测器在真实图像上明显超过了所有准备的等价器，而我们的优化方案在几视图设置下明显超过了当前的摄影探测渠道。我们发布我们的 sintetic dataset 和基线3D扫描数据，以便研究人员进行更多的探索和应用。
</details></li>
</ul>
<hr>
<h2 id="LipSim-A-Provably-Robust-Perceptual-Similarity-Metric"><a href="#LipSim-A-Provably-Robust-Perceptual-Similarity-Metric" class="headerlink" title="LipSim: A Provably Robust Perceptual Similarity Metric"></a>LipSim: A Provably Robust Perceptual Similarity Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18274">http://arxiv.org/abs/2310.18274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/saraghazanfari/lipsim">https://github.com/saraghazanfari/lipsim</a></li>
<li>paper_authors: Sara Ghazanfari, Alexandre Araujo, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg</li>
<li>for: This paper is written for researchers and practitioners interested in developing and applying perceptual similarity metrics, particularly those concerned with the vulnerability of these metrics to adversarial attacks.</li>
<li>methods: The paper uses an ensemble of ViT-based feature extractors and proposes a framework for training a robust perceptual similarity metric called LipSim, which leverages 1-Lipschitz neural networks as the backbone and provides provable guarantees.</li>
<li>results: The paper demonstrates the vulnerability of state-of-the-art perceptual similarity metrics to adversarial attacks and presents a comprehensive set of experiments showing the performance of LipSim in terms of natural and certified scores, as well as on the image retrieval application.<details>
<summary>Abstract</summary>
Recent years have seen growing interest in developing and applying perceptual similarity metrics. Research has shown the superiority of perceptual metrics over pixel-wise metrics in aligning with human perception and serving as a proxy for the human visual system. On the other hand, as perceptual metrics rely on neural networks, there is a growing concern regarding their resilience, given the established vulnerability of neural networks to adversarial attacks. It is indeed logical to infer that perceptual metrics may inherit both the strengths and shortcomings of neural networks. In this work, we demonstrate the vulnerability of state-of-the-art perceptual similarity metrics based on an ensemble of ViT-based feature extractors to adversarial attacks. We then propose a framework to train a robust perceptual similarity metric called LipSim (Lipschitz Similarity Metric) with provable guarantees. By leveraging 1-Lipschitz neural networks as the backbone, LipSim provides guarded areas around each data point and certificates for all perturbations within an $\ell_2$ ball. Finally, a comprehensive set of experiments shows the performance of LipSim in terms of natural and certified scores and on the image retrieval application. The code is available at https://github.com/SaraGhazanfari/LipSim.
</details>
<details>
<summary>摘要</summary>
近年来，有越来越多的研究者关注开发和应用感知相似度度量。研究表明，感知度量比像素精度更能与人类感知相匹配，并作为人类视觉系统的代理。然而，由于感知度量基于神经网络，因此存在抗击攻击的担忧。这是合理的推理，因为神经网络具有抗击攻击的敏感性。在这种情况下，我们展示了现状顶尖感知相似度度量基于ViT基于特征提取器的集成系统对抗攻击的漏斗性。然后，我们提议一种训练可靠的感知相似度度量的框架，称为LipSim（Lipschitz相似度度量）。通过使用1-Lipschitz神经网络作为核心，LipSim提供了每个数据点的保护区和所有折射在$\ell_2$球体内的证明。最后，我们进行了详细的实验，以评估LipSim在自然和证明得分上的性能，以及图像检索应用中的表现。代码可以在https://github.com/SaraGhazanfari/LipSim中找到。
</details></li>
</ul>
<hr>
<h2 id="PlantPlotGAN-A-Physics-Informed-Generative-Adversarial-Network-for-Plant-Disease-Prediction"><a href="#PlantPlotGAN-A-Physics-Informed-Generative-Adversarial-Network-for-Plant-Disease-Prediction" class="headerlink" title="PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction"></a>PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18268">http://arxiv.org/abs/2310.18268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felipe A. Lopes, Vasit Sagan, Flavio Esposito</li>
<li>for: 园区监测是重要的农业管理和收获健康的关键，尤其是检测植物疾病。</li>
<li>methods: 我们使用无人飞行器（UAV）收集多spectral图像，以帮助园区监测。</li>
<li>results: 我们的 PlantPlotGAN 模型可以生成高品质的合成多spectral图像，并且可以提高检测植物疾病的预测模型精度。<details>
<summary>Abstract</summary>
Monitoring plantations is crucial for crop management and producing healthy harvests. Unmanned Aerial Vehicles (UAVs) have been used to collect multispectral images that aid in this monitoring. However, given the number of hectares to be monitored and the limitations of flight, plant disease signals become visually clear only in the later stages of plant growth and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the Fr\'echet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery.
</details>
<details>
<summary>摘要</summary>
监测植业是cro管理和生产健康卫生的关键。无人驾驶飞行器（UAV）已被用于收集多spectral图像，以帮助监测。然而， giventhe number of hectares to be monitored and the limitations of flight, plant disease signals only become visually clear in the later stages of plant growth, and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the Fréchet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery.Here's the word-for-word translation:监测植业是cro管理和生产健康卫生的关键。无人驾驶飞行器（UAV）已被用于收集多spectral图像，以帮助监测。然而， giventhe number of hectares to be monitored and the limitations of flight, plant disease signals only become visually clear in the later stages of plant growth, and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the Fréchet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery.
</details></li>
</ul>
<hr>
<h2 id="A-Self-Supervised-Approach-to-Land-Cover-Segmentation"><a href="#A-Self-Supervised-Approach-to-Land-Cover-Segmentation" class="headerlink" title="A Self-Supervised Approach to Land Cover Segmentation"></a>A Self-Supervised Approach to Land Cover Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18251">http://arxiv.org/abs/2310.18251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charles Moore, Dakota Hester</li>
<li>for: 这个论文旨在提供一种自动化高分辨率农业Remote sensing图像分类方法，不需要高质量的地面真实标签。</li>
<li>methods: 该方法使用一个冻结的预训练ViT背景，并在STEGO架构中进行微调。</li>
<li>results: 经过10个微调轮，实现了约52%的准确率在5个样本中，表明了自动化标注高分辨率农业Remote sensing图像的可能性。<details>
<summary>Abstract</summary>
Land use/land cover change (LULC) maps are integral resources in earth science and agricultural research. Due to the nature of such maps, the creation of LULC maps is often constrained by the time and human resources necessary to accurately annotate satellite imagery and remote sensing data. While computer vision models that perform semantic segmentation to create detailed labels from such data are not uncommon, litle research has been done on self-supervised and unsupervised approaches to labelling LULC maps without the use of ground-truth masks. Here, we demonstrate a self-supervised method of land cover segmentation that has no need for high-quality ground truth labels. The proposed deep learning employs a frozen pre-trained ViT backbone transferred from DINO in a STEGO architecture and is fine-tuned using a custom dataset consisting of very high resolution (VHR) sattelite imagery. After only 10 epochs of fine-tuning, an accuracy of roughly 52% was observed across 5 samples, signifying the feasibility of self-supervised models for the automated labelling of VHR LULC maps.
</details>
<details>
<summary>摘要</summary>
Land use/land cover change（LULC）地图是地球科学和农业研究中的重要资源。由于LULC地图的创建通常受到时间和人员资源的限制，因为需要精确地标注卫星图像和远程感知数据。虽然用计算机视觉模型进行semantic segmentation，从数据中生成细节标签并不是无前例的，但是对LULC地图的自动标注而无需高质量地面真实标签的研究不多。本文提出了一种没有需要高质量地面真实标签的自动标注方法。该深度学习模型使用冰结的预训练ViT背bone，并在STEGO架构中进行了精度调整。经过10个精度调整 epoch，模型在5个样本上达到了约52%的准确率，表明自动标注模型可以实施高分辨率LULC地图的自动标注。
</details></li>
</ul>
<hr>
<h2 id="Generative-AI-Model-for-Artistic-Style-Transfer-Using-Convolutional-Neural-Networks"><a href="#Generative-AI-Model-for-Artistic-Style-Transfer-Using-Convolutional-Neural-Networks" class="headerlink" title="Generative AI Model for Artistic Style Transfer Using Convolutional Neural Networks"></a>Generative AI Model for Artistic Style Transfer Using Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18237">http://arxiv.org/abs/2310.18237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonayet Miah, Duc M Cao, Md Abu Sayed, Md. Sabbirul Haque</li>
<li>for: 本文概述了一种基于卷积神经网络（CNN）的图像风格转移技术，用于将一个图像的内容和风格与另一个图像的风格相结合，创造独特的视觉作品。</li>
<li>methods: 本文使用了深度图像表示学习的 CNN 来分离和控制图像的内容和风格，并通过损失计算和优化来实现高质量的风格转移。</li>
<li>results: 本文通过实验结果显示了该方法的效果和多样性，包括不同风格和内容的图像合成。<details>
<summary>Abstract</summary>
Artistic style transfer, a captivating application of generative artificial intelligence, involves fusing the content of one image with the artistic style of another to create unique visual compositions. This paper presents a comprehensive overview of a novel technique for style transfer using Convolutional Neural Networks (CNNs). By leveraging deep image representations learned by CNNs, we demonstrate how to separate and manipulate image content and style, enabling the synthesis of high-quality images that combine content and style in a harmonious manner. We describe the methodology, including content and style representations, loss computation, and optimization, and showcase experimental results highlighting the effectiveness and versatility of the approach across different styles and content
</details>
<details>
<summary>摘要</summary>
美术风格传输，一种吸引人的生成人工智能应用，涉及将一幅图像的内容与另一幅图像的艺术风格相结合，以创造独特的视觉作品。本文提出了一种基于卷积神经网络（CNN）的新方法，用于实现风格传输。通过利用深度图像表示学习出来的CNN，我们示例了如何分离和处理图像内容和风格，以生成高质量的合成图像，其中内容和风格兼得协调。我们介绍了方法的具体实现，包括内容和风格表示、损失计算和优化，并通过实验结果表明该方法在不同的风格和内容上的效果和多样性。
</details></li>
</ul>
<hr>
<h2 id="How-Re-sampling-Helps-for-Long-Tail-Learning"><a href="#How-Re-sampling-Helps-for-Long-Tail-Learning" class="headerlink" title="How Re-sampling Helps for Long-Tail Learning?"></a>How Re-sampling Helps for Long-Tail Learning?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18236">http://arxiv.org/abs/2310.18236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shijxcs/csa">https://github.com/shijxcs/csa</a></li>
<li>paper_authors: Jiang-Xin Shi, Tong Wei, Yuke Xiang, Yu-Feng Li</li>
<li>for: investigate the effectiveness of re-sampling in modern long-tail learning tasks</li>
<li>methods: experiments on two homogeneous datasets, context shift augmentation module to generate diverse training images for the tail class</li>
<li>results: proposed module can boost generalization and outperform other approaches, including class-balanced re-sampling, decoupled classifier re-training, and data augmentation methods<details>
<summary>Abstract</summary>
Long-tail learning has received significant attention in recent years due to the challenge it poses with extremely imbalanced datasets. In these datasets, only a few classes (known as the head classes) have an adequate number of training samples, while the rest of the classes (known as the tail classes) are infrequent in the training data. Re-sampling is a classical and widely used approach for addressing class imbalance issues. Unfortunately, recent studies claim that re-sampling brings negligible performance improvements in modern long-tail learning tasks. This paper aims to investigate this phenomenon systematically. Our research shows that re-sampling can considerably improve generalization when the training images do not contain semantically irrelevant contexts. In other scenarios, however, it can learn unexpected spurious correlations between irrelevant contexts and target labels. We design experiments on two homogeneous datasets, one containing irrelevant context and the other not, to confirm our findings. To prevent the learning of spurious correlations, we propose a new context shift augmentation module that generates diverse training images for the tail class by maintaining a context bank extracted from the head-class images. Experiments demonstrate that our proposed module can boost the generalization and outperform other approaches, including class-balanced re-sampling, decoupled classifier re-training, and data augmentation methods. The source code is available at https://www.lamda.nju.edu.cn/code_CSA.ashx.
</details>
<details>
<summary>摘要</summary>
“长尾学习在最近几年内得到了广泛关注，因为它面临着极其不均衡的数据集的挑战。在这些数据集中，只有一些类（称为头类）有足够的训练样本，而另外的类（称为尾类）则是训练数据中罕见的。重新采样是经典的和广泛使用的方法来解决类均衡问题。然而，最新的研究表明，重新采样在现代长尾学习任务中并不能提供显著的性能提升。本文旨在系统地探讨这种现象。我们的研究表明，重新采样可以在训练图像不含 semantically irrelevant 上下文时大幅提高泛化。在其他情况下，它可能学习不相关的上下文和目标标签之间的意外相关性。我们设计了两个同质数据集的实验，一个包含 irrelevant context，另一个不包含，以确认我们的发现。为避免学习不相关的上下文，我们提议一种新的上下文shift augmentation模块，该模块可以生成 tail 类的多样化训练图像，保持 head 类图像中的上下文银行。实验表明，我们提议的模块可以提高泛化和其他方法相比，包括类均衡重新采样、解册分类器重新训练和数据扩展方法。代码可以在 <https://www.lamda.nju.edu.cn/code_CSA.ashx> 中获取。”
</details></li>
</ul>
<hr>
<h2 id="Edge-AI-Based-Vein-Detector-for-Efficient-Venipuncture-in-the-Antecubital-Fossa"><a href="#Edge-AI-Based-Vein-Detector-for-Efficient-Venipuncture-in-the-Antecubital-Fossa" class="headerlink" title="Edge AI-Based Vein Detector for Efficient Venipuncture in the Antecubital Fossa"></a>Edge AI-Based Vein Detector for Efficient Venipuncture in the Antecubital Fossa</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18234">http://arxiv.org/abs/2310.18234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edwin Salcedo, Patricia Peñaloza</li>
<li>for: 这个论文是为了提高 antecubital fossa 中的血管可见性而作的。</li>
<li>methods: 这个论文使用了 Near Infrared (NIR) 成像和深度学习 (DL) 技术来 segmentation 腕静脉。</li>
<li>results: 这个论文提出了一种新的 NIR 成像基于的腕静脉 segmentation 数据集，并提出了一种修改后的 U-Net 架构来特别地在 antecubital fossa 区域中找到血管。此外，这个论文还测试了四种常用的嵌入式微计算机和四种压缩模式，并选择了使用 Raspberry Pi 4B 卡来实现最佳的执行时间和准确性平衡。<details>
<summary>Abstract</summary>
Assessing the condition and visibility of veins is a crucial step before obtaining intravenous access in the antecubital fossa, which is a common procedure to draw blood or administer intravenous therapies (IV therapies). Even though medical practitioners are highly skilled at intravenous cannulation, they usually struggle to perform the procedure in patients with low visible veins due to fluid retention, age, overweight, dark skin tone, or diabetes. Recently, several investigations proposed combining Near Infrared (NIR) imaging and deep learning (DL) techniques for forearm vein segmentation. Although they have demonstrated compelling results, their use has been rather limited owing to the portability and precision requirements to perform venipuncture. In this paper, we aim to contribute to bridging this gap using three strategies. First, we introduce a new NIR-based forearm vein segmentation dataset of 2,016 labelled images collected from 1,008 subjects with low visible veins. Second, we propose a modified U-Net architecture that locates veins specifically in the antecubital fossa region of the examined patient. Finally, a compressed version of the proposed architecture was deployed inside a bespoke, portable vein finder device after testing four common embedded microcomputers and four common quantization modalities. Experimental results showed that the model compressed with Dynamic Range Quantization and deployed on a Raspberry Pi 4B card produced the best execution time and precision balance, with 5.14 FPS and 0.957 of latency and Intersection over Union (IoU), respectively. These results show promising performance inside a resource-restricted low-cost device.
</details>
<details>
<summary>摘要</summary>
医疗人员在 antecubital fossa 区域进行血液或 intravenous therapies (IV therapies) 的时候，需要评估血管的状况和可见度。尽管医疗人员具有高度的血液引导技能，但在有低可见度的血管的患者中，医疗人员通常会面临困难。近些年，一些研究提出了结合 Near Infrared (NIR) 成像和深度学习 (DL) 技术来 segment 胳膊血管的方法。尽管它们已经展示出了吸引人的结果，但它们的使用受到了可移植性和精度的限制，以便在进行 venipuncture 时进行血液引导。在这篇论文中，我们想要帮助bridging这个差距。我们的方法包括三个方面：1. 我们提供了一个新的 NIR-based 胳膊血管 segmentation 数据集，包含了 2,016 个标注的图像，来自 1,008 名患者，其中许多患者有低可见度的血管。2. 我们提出了一种修改后的 U-Net 架构，可以在特定的 antecubital fossa 区域内准确地定位血管。3. 我们在一个特制的、可携带的 vein finder 设备中部署了一个压缩版的提议架构，并测试了四种常见的嵌入式微计算机和四种常见的压缩模式。实验结果表明，使用 Dynamics Range Quantization 压缩并在 Raspberry Pi 4B 卡上部署的模型在执行时间和精度之间达到了良好的平衡，具体来说是 5.14 FPS 和 0.957 的延迟和 Intersection over Union (IoU)，分别是。这些结果表明在有限的资源和低成本设备中，我们的方法可以实现出色的性能。
</details></li>
</ul>
<hr>
<h2 id="TBDLNet-a-network-for-classifying-multidrug-resistant-and-drug-sensitive-tuberculosis"><a href="#TBDLNet-a-network-for-classifying-multidrug-resistant-and-drug-sensitive-tuberculosis" class="headerlink" title="TBDLNet: a network for classifying multidrug-resistant and drug-sensitive tuberculosis"></a>TBDLNet: a network for classifying multidrug-resistant and drug-sensitive tuberculosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18222">http://arxiv.org/abs/2310.18222</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziquan Zhu, Jing Tao, Shuihua Wang, Xin Zhang, Yudong Zhang</li>
<li>for: 本研究用一种新型深度学习模型TBDLNet来自动识别CT图像，以分类多药 resistant和敏感肺炎。</li>
<li>methods: 该模型采用预训练ResNet50提取特征，并使用三个随机神经网络来避免过拟合问题。 ensemble of three RNNs 是用来提高Robustness的。</li>
<li>results: 该模型在五种批处分划 validation中得到了0.9822的准确率、0.9815的特征率、0.9823的精度、0.9829的敏感率和0.9826的F1-score。TBDLNet适用于分类多药 resistant和敏感肺炎，可以早些地检测多药 resistant肺炎，帮助在时间内调整治疗方案，提高治疗效果。<details>
<summary>Abstract</summary>
This paper proposes applying a novel deep-learning model, TBDLNet, to recognize CT images to classify multidrug-resistant and drug-sensitive tuberculosis automatically. The pre-trained ResNet50 is selected to extract features. Three randomized neural networks are used to alleviate the overfitting problem. The ensemble of three RNNs is applied to boost the robustness via majority voting. The proposed model is evaluated by five-fold cross-validation. Five indexes are selected in this paper, which are accuracy, sensitivity, precision, F1-score, and specificity. The TBDLNet achieves 0.9822 accuracy, 0.9815 specificity, 0.9823 precision, 0.9829 sensitivity, and 0.9826 F1-score, respectively. The TBDLNet is suitable for classifying multidrug-resistant tuberculosis and drug-sensitive tuberculosis. It can detect multidrug-resistant pulmonary tuberculosis as early as possible, which helps to adjust the treatment plan in time and improve the treatment effect.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这篇论文提议使用一种新的深度学习模型TBDLNet，用于自动识别CT图像，并将其分为多药抗药性和敏感肺结核细菌两类。模型使用预训练的ResNet50提取特征，并使用三个随机的神经网络来避免过拟合问题。ensemble三个RNN使用多数投票法来提高鲁棒性。模型使用五fold交叉验证来评估，使用五个指标：准确率、敏感率、精度、F1分数和特征率。TBDLNet在这些指标中得分为0.9822、0.9815、0.9823、0.9829和0.9826，分别。TBDLNet适用于分类多药抗药性和敏感肺结核细菌，可以在时间上早 detection多药抗药性肺结核细菌，帮助在时间上适当地调整治疗方案，提高治疗效果。
</details></li>
</ul>
<hr>
<h2 id="Artifact-Robust-Graph-Based-Learning-in-Digital-Pathology"><a href="#Artifact-Robust-Graph-Based-Learning-in-Digital-Pathology" class="headerlink" title="Artifact-Robust Graph-Based Learning in Digital Pathology"></a>Artifact-Robust Graph-Based Learning in Digital Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18192">http://arxiv.org/abs/2310.18192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saba Heidari Gheshlaghi, Milan Aryal, Nasim Yahyasoltani, Masoud Ganji<br>for:This paper aims to develop a novel robust learning approach to account for perturbations in whole slide images (WSIs) for prostate cancer diagnosis.methods:The proposed approach uses graph convolutional networks (GCNs) to extract features from the graph representing WSI, followed by a denoiser and a transformer for classification.results:The proposed model shows significant improvement in cancer diagnosis compared to non-robust algorithms, with accuracy and kappa scores improved by the denoiser and the use of GCNs.<details>
<summary>Abstract</summary>
Whole slide images~(WSIs) are digitized images of tissues placed in glass slides using advanced scanners. The digital processing of WSIs is challenging as they are gigapixel images and stored in multi-resolution format. A common challenge with WSIs is that perturbations/artifacts are inevitable during storing the glass slides and digitizing them. These perturbations include motion, which often arises from slide movement during placement, and changes in hue and brightness due to variations in staining chemicals and the quality of digitizing scanners. In this work, a novel robust learning approach to account for these artifacts is presented. Due to the size and resolution of WSIs and to account for neighborhood information, graph-based methods are called for. We use graph convolutional network~(GCN) to extract features from the graph representing WSI. Through a denoiser {and pooling layer}, the effects of perturbations in WSIs are controlled and the output is followed by a transformer for the classification of different grades of prostate cancer. To compare the efficacy of the proposed approach, the model without denoiser is trained and tested with WSIs without any perturbation and then different perturbations are introduced in WSIs and passed through the network with the denoiser. The accuracy and kappa scores of the proposed model with prostate cancer dataset compared with non-robust algorithms show significant improvement in cancer diagnosis.
</details>
<details>
<summary>摘要</summary>
整幕图像（WSIs）是用高级扫描仪将组织胶囊中的组织样本扫描成数字图像。由于WSIs的数字处理具有高分辨率和多resolution format，因此处理WSIs是一项挑战。常见的WSIs问题是在存储玻璃板和扫描时产生的干扰和 artifacts。这些干扰包括摆动、着色和亮度变化，这些变化可能是化学品的质量和扫描仪的不同。在这项工作中，我们提出了一种新的Robust学习方法来处理这些干扰。由于WSIs的大小和分辨率，以及需要考虑 neighboring information，因此我们使用图gram卷积网络（GCN）来提取WSIs中的特征。通过杂化和池化层，我们控制了干扰的影响，然后使用变换器进行不同grade的肾癌诊断。为了比较提议方法的有效性，我们在不含干扰的WSIs上train和测试模型，然后在WSIs中引入不同的干扰，并将其传递 через网络。我们的方法与肾癌数据集的准确率和κ值 Score在非Robust算法的情况下显示了显著的改善。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Panoptic-Narrative-Grounding"><a href="#Semi-Supervised-Panoptic-Narrative-Grounding" class="headerlink" title="Semi-Supervised Panoptic Narrative Grounding"></a>Semi-Supervised Panoptic Narrative Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18142">http://arxiv.org/abs/2310.18142</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nini0919/sspng">https://github.com/nini0919/sspng</a></li>
<li>paper_authors: Danni Yang, Jiayi Ji, Xiaoshuai Sun, Haowei Wang, Yinan Li, Yiwei Ma, Rongrong Ji</li>
<li>for: 本研究旨在提高叙述幻像检测（PNG）任务的进步，使得它在有限的标注数据下进行训练。</li>
<li>methods: 我们提出了一种新的半有序PNG学习方案（SS-PNG），利用更少的标注图像对和更多的无标注对来实现竞争力的表现。在PNG任务中，每个像素可以属于多个开放的物体，因此现有的多类基于semi-supervised segmentation的框架无法直接应用于这个任务。我们开发了一种专门针对SS-PNG设置的SS-PNG网络（SS-PNG-NW），并进行了严格的 исследование和优化。</li>
<li>results: 我们的SS-PNG-NW+在PNG数据集上进行了广泛的实验，与完全有标注的模型相比，在所有数据比例下达到了相当的表现。特别是，我们的SS-PNG-NW+在只使用30%和50%的标注数据时表现出色，与完全有标注的模型相比，提高了0.8%和1.1%的表现。这表明我们的提出的SS-PNG-NW+在限制标注数据下提高PNG任务的实际性。<details>
<summary>Abstract</summary>
Despite considerable progress, the advancement of Panoptic Narrative Grounding (PNG) remains hindered by costly annotations. In this paper, we introduce a novel Semi-Supervised Panoptic Narrative Grounding (SS-PNG) learning scheme, capitalizing on a smaller set of labeled image-text pairs and a larger set of unlabeled pairs to achieve competitive performance. Unlike visual segmentation tasks, PNG involves one pixel belonging to multiple open-ended nouns. As a result, existing multi-class based semi-supervised segmentation frameworks cannot be directly applied to this task. To address this challenge, we first develop a novel SS-PNG Network (SS-PNG-NW) tailored to the SS-PNG setting. We thoroughly investigate strategies such as Burn-In and data augmentation to determine the optimal generic configuration for the SS-PNG-NW. Additionally, to tackle the issue of imbalanced pseudo-label quality, we propose a Quality-Based Loss Adjustment (QLA) approach to adjust the semi-supervised objective, resulting in an enhanced SS-PNG-NW+. Employing our proposed QLA, we improve BCE Loss and Dice loss at pixel and mask levels, respectively. We conduct extensive experiments on PNG datasets, with our SS-PNG-NW+ demonstrating promising results comparable to fully-supervised models across all data ratios. Remarkably, our SS-PNG-NW+ outperforms fully-supervised models with only 30% and 50% supervision data, exceeding their performance by 0.8% and 1.1% respectively. This highlights the effectiveness of our proposed SS-PNG-NW+ in overcoming the challenges posed by limited annotations and enhancing the applicability of PNG tasks. The source code is available at https://github.com/nini0919/SSPNG.
</details>
<details>
<summary>摘要</summary>
尽管已经做出了很大的进步，但是对于图像文本对应关系（PNG）的进一步发展仍然受到严重的标注成本限制。在这篇论文中，我们介绍了一种新的半超vised Panoptic Narrative Grounding（SS-PNG）学习方案，利用一个更小的标注图像文本对的集合和一个更大的无标注对来实现竞争性的性能。与视觉分割任务不同，PNG中一个像素可以属于多个开放式名称。因此，现有的多类基于 semi-supervised segmentation的框架无法直接应用于这个任务。为解决这个挑战，我们首先开发了一种适应 SS-PNG 的 SS-PNG 网络（SS-PNG-NW）。我们在这种 SS-PNG-NW 中进行了严格的调查和数据增强等策略，以确定最佳的通用配置。此外，为了解决假标注质量偏斜的问题，我们提出了一种 Quality-Based Loss Adjustment（QLA）方法，以调整 semi-supervised 目标函数，从而得到了一种提升的 SS-PNG-NW+。我们在 PNG 数据集上进行了广泛的实验，并证明了我们的 SS-PNG-NW+ 在所有数据比例下具有出色的表现，与完全超vised 模型相当。特别是，我们的 SS-PNG-NW+ 在仅使用 30% 和 50% 的超visisted数据时，超过了完全超vised 模型的性能，提高了其性能的 0.8% 和 1.1% 分别。这种表现说明了我们提出的 SS-PNG-NW+ 对于做到 PNG 任务的应用性能具有很高的效iveness。SS-PNG 网络的源代码可以在 GitHub 上找到：https://github.com/nini0919/SSPNG。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Representation-Learning-for-Diverse-Deformable-Shape-Collections"><a href="#Unsupervised-Representation-Learning-for-Diverse-Deformable-Shape-Collections" class="headerlink" title="Unsupervised Representation Learning for Diverse Deformable Shape Collections"></a>Unsupervised Representation Learning for Diverse Deformable Shape Collections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18141">http://arxiv.org/abs/2310.18141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Hahner, Souhaib Attaiki, Jochen Garcke, Maks Ovsjanikov</li>
<li>for: 本研究旨在开发一种基于学习的3D表面网格编码和处理方法，用于创建可解释的嵌入空间 для弹性形状集合。</li>
<li>methods: 我们的方法使用spectral pooling技术建立一个通用的隐藏空间，从 tradicional的mesh connectivity和形状类别中解脱出来。</li>
<li>results: 我们的方法可以实现优秀的重建和更加真实和平滑的 interpolations，并且超过基eline方法的性能。<details>
<summary>Abstract</summary>
We introduce a novel learning-based method for encoding and manipulating 3D surface meshes. Our method is specifically designed to create an interpretable embedding space for deformable shape collections. Unlike previous 3D mesh autoencoders that require meshes to be in a 1-to-1 correspondence, our approach is trained on diverse meshes in an unsupervised manner. Central to our method is a spectral pooling technique that establishes a universal latent space, breaking free from traditional constraints of mesh connectivity and shape categories. The entire process consists of two stages. In the first stage, we employ the functional map paradigm to extract point-to-point (p2p) maps between a collection of shapes in an unsupervised manner. These p2p maps are then utilized to construct a common latent space, which ensures straightforward interpretation and independence from mesh connectivity and shape category. Through extensive experiments, we demonstrate that our method achieves excellent reconstructions and produces more realistic and smoother interpolations than baseline approaches.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的学习基于方法用于编码和操作三维表面网格。我们的方法专门设计用于创建可解释的嵌入空间，用于不可归类的形状集合。与过去的3D笼自动编码器不同，我们的方法不需要笼子在1-1对应。我们的方法在无监督的情况下在多种笼子上进行训练。中心于我们的方法是一种spectral pooling技术，该技术建立了一个通用的嵌入空间，脱离了传统的笼子连接和形状类别的限制。整个过程分为两个阶段。在第一阶段，我们使用函数映射方法抽取点对点（p2p）地图 между一个集合的形状。这些p2p地图然后用于构建共同嵌入空间，这使得解释更直观，独立于笼子连接和形状类别。通过广泛的实验，我们证明了我们的方法可以实现出色的重建和更加真实和平滑的 interpolations than 基准方法。
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Video-Gaze-Estimation-via-Capturing-Head-face-eye-Spatial-temporal-Interaction-Context"><a href="#End-to-end-Video-Gaze-Estimation-via-Capturing-Head-face-eye-Spatial-temporal-Interaction-Context" class="headerlink" title="End-to-end Video Gaze Estimation via Capturing Head-face-eye Spatial-temporal Interaction Context"></a>End-to-end Video Gaze Estimation via Capturing Head-face-eye Spatial-temporal Interaction Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18131">http://arxiv.org/abs/2310.18131</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zgchen33/mcgaze">https://github.com/zgchen33/mcgaze</a></li>
<li>paper_authors: Yiran Guan, Zhuoguang Chen, Wenzheng Zeng, Zhiguo Cao, Yang Xiao</li>
<li>for: 提出了一种新的方法 Multi-Clue Gaze (MCGaze)，用于通过捕捉头、脸、眼的空间-时间交互context来进行视频跟踪眼动Estimation，这个问题之前没有得到充分关注。</li>
<li>methods: MCGaze方法可以同时解决头、脸、眼的指示位置定位问题，并在一步式的方式下进行优化，从而实现最佳性能。在这个过程中，头、脸、眼的上下文信息互相交换，从而在眼动推断中 simultanously capture global clue from head and face, and local clue from eye.</li>
<li>results: 实验结果表明，MCGaze方法在面临到复杂的 Gaze360 数据集的测试中表现出色，证明了我们的提议的优越性。<details>
<summary>Abstract</summary>
In this letter, we propose a new method, Multi-Clue Gaze (MCGaze), to facilitate video gaze estimation via capturing spatial-temporal interaction context among head, face, and eye in an end-to-end learning way, which has not been well concerned yet. The main advantage of MCGaze is that the tasks of clue localization of head, face, and eye can be solved jointly for gaze estimation in a one-step way, with joint optimization to seek optimal performance. During this, spatial-temporal context exchange happens among the clues on the head, face, and eye. Accordingly, the final gazes obtained by fusing features from various queries can be aware of global clues from heads and faces, and local clues from eyes simultaneously, which essentially leverages performance. Meanwhile, the one-step running way also ensures high running efficiency. Experiments on the challenging Gaze360 dataset verify the superiority of our proposition. The source code will be released at https://github.com/zgchen33/MCGaze.
</details>
<details>
<summary>摘要</summary>
在这封信中，我们提出了一种新的方法，即多 clue gaze（MCGaze），用于通过捕捉头、面和眼的空间-时间交互 context来进行视频眼动估计，这种方法尚未得到了充分关注。MCGaze 的主要优点是可以同时解决头、面和眼的 clue localization 问题，从而实现一步骤的眼动估计，并且在joint optimization中进行优化以求最佳性能。在这个过程中，头、面和眼之间的空间-时间上的Context Exchange 发生，从而使得最终的眼动结果可以同时充分利用全头和面上的全局 clue，以及眼上的本地 clue，这种方法可以提高性能。此外，MCGaze 的一步运行方式也保证了高效率。实验表明，在 Gaze360 数据集上，我们的提议超过了传统方法的性能。源代码将于 https://github.com/zgchen33/MCGaze 上发布。
</details></li>
</ul>
<hr>
<h2 id="Direct-Unsupervised-Denoising"><a href="#Direct-Unsupervised-Denoising" class="headerlink" title="Direct Unsupervised Denoising"></a>Direct Unsupervised Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18116">http://arxiv.org/abs/2310.18116</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krulllab/DirectDenoiser">https://github.com/krulllab/DirectDenoiser</a></li>
<li>paper_authors: Benjamin Salmon, Alexander Krull</li>
<li>for: 这个论文是为了提出一种新的干扰除法，以替代传统的监督学习方法。</li>
<li>methods: 这个论文使用了Variational AutoEncoders（VAEs）来实现无监督的干扰除法，而不需要对应的干扰数据。</li>
<li>results: 该方法可以在各种情况下提供高质量的干扰除结果，而且比传统的监督方法更快速，并且可以避免创造大量的样本抽象。<details>
<summary>Abstract</summary>
Traditional supervised denoisers are trained using pairs of noisy input and clean target images. They learn to predict a central tendency of the posterior distribution over possible clean images. When, e.g., trained with the popular quadratic loss function, the network's output will correspond to the minimum mean square error (MMSE) estimate. Unsupervised denoisers based on Variational AutoEncoders (VAEs) have succeeded in achieving state-of-the-art results while requiring only unpaired noisy data as training input. In contrast to the traditional supervised approach, unsupervised denoisers do not directly produce a single prediction, such as the MMSE estimate, but allow us to draw samples from the posterior distribution of clean solutions corresponding to the noisy input. To approximate the MMSE estimate during inference, unsupervised methods have to create and draw a large number of samples - a computationally expensive process - rendering the approach inapplicable in many situations. Here, we present an alternative approach that trains a deterministic network alongside the VAE to directly predict a central tendency. Our method achieves results that surpass the results achieved by the unsupervised method at a fraction of the computational cost.
</details>
<details>
<summary>摘要</summary>
传统的监督式降噪器通常通过对噪声输入和干净目标图像的对照对进行训练，学习预测噪声输入的后逻脑分布中的中位数。例如，使用流行的quadratic loss函数训练网络，网络的输出将对应于最小平均方差估计（MMSE）。不同于传统的监督式方法，无监督降噪器基于Variational AutoEncoders（VAEs）可以在不需要对应的干净数据的情况下实现状态的最佳结果。然而，在推理过程中，无监督降噪器不直接生成唯一的预测结果，而是允许我们从降噪器的 posterior distribution 中随机抽取干净解决方案对应的噪声输入。为了在推理过程中 aproximate MMSE 估计，无监督方法需要创建和抽取大量的样本，这是 computationally expensive 的过程，因此在许多情况下无法应用。在这篇文章中，我们提出了一种alternative方法，该方法通过同时训练 deterministic 网络和 VAE 来直接预测中位数。我们的方法可以在computational cost的一个 fraction 的情况下超越无监督方法的结果。
</details></li>
</ul>
<hr>
<h2 id="Classifier-head-Informed-Feature-Masking-and-Prototype-based-Logit-Smoothing-for-Out-of-Distribution-Detection"><a href="#Classifier-head-Informed-Feature-Masking-and-Prototype-based-Logit-Smoothing-for-Out-of-Distribution-Detection" class="headerlink" title="Classifier-head Informed Feature Masking and Prototype-based Logit Smoothing for Out-of-Distribution Detection"></a>Classifier-head Informed Feature Masking and Prototype-based Logit Smoothing for Out-of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18104">http://arxiv.org/abs/2310.18104</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuohao Sun, Yiqiao Qiu, Zhijun Tan, Weishi Zheng, Ruixuan Wang</li>
<li>for: 这篇研究旨在提出一种有效的后期Out-of-distribution（OOD）检测方法，以解决深度学习模型在实际应用中的错误预测问题。</li>
<li>methods: 本研究使用了一种新的特征遮盾策略和一种新的权重缓和策略，将特征遮盾定义为每个内部分类（ID）的重要特征，并将其他特征遮盾。此外，本研究还使用了一种cosine similarity的类似性计算来自适应温度因子，以缓和神经网络的过度自信预测。</li>
<li>results: 实验结果显示，本研究的方法可以将OOD检测精度提高，并且与现有方法相容。本研究新创出了State-of-the-art的性能。代码将会公开发布。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection is essential when deploying neural networks in the real world. One main challenge is that neural networks often make overconfident predictions on OOD data. In this study, we propose an effective post-hoc OOD detection method based on a new feature masking strategy and a novel logit smoothing strategy. Feature masking determines the important features at the penultimate layer for each in-distribution (ID) class based on the weights of the ID class in the classifier head and masks the rest features. Logit smoothing computes the cosine similarity between the feature vector of the test sample and the prototype of the predicted ID class at the penultimate layer and uses the similarity as an adaptive temperature factor on the logit to alleviate the network's overconfidence prediction for OOD data. With these strategies, we can reduce feature activation of OOD data and enlarge the gap in OOD score between ID and OOD data. Extensive experiments on multiple standard OOD detection benchmarks demonstrate the effectiveness of our method and its compatibility with existing methods, with new state-of-the-art performance achieved from our method. The source code will be released publicly.
</details>
<details>
<summary>摘要</summary>
OUT-OF-DISTRIBUTION (OOD) 检测是在真实世界中部署神经网络的关键。一个主要挑战是神经网络frequently 对OOD数据进行过自信的预测。在这项研究中，我们提出了一种有效的后置OOD检测方法，基于新的特征遮盾策略和一种新的logit平滑策略。特征遮盾在半最后层确定每个ID类型的重要特征，根据ID类型的分类器头的权重，并将其他特征遮盾。logit平滑计算测试样本的特征向量和预测ID类型的prototype在半最后层的cos仿射系数，并使用这个相似性作为适应温度因子来缓解神经网络对OOD数据的过自信预测。通过这些策略，我们可以降低OOD数据的特征活动和扩大ID和OOD数据之间的分布差。我们的方法与现有方法相容，并在多个标准OOD检测 benchmark上实现了新的 state-of-the-art 性能。我们将代码公开发布。
</details></li>
</ul>
<hr>
<h2 id="A-Chebyshev-Confidence-Guided-Source-Free-Domain-Adaptation-Framework-for-Medical-Image-Segmentation"><a href="#A-Chebyshev-Confidence-Guided-Source-Free-Domain-Adaptation-Framework-for-Medical-Image-Segmentation" class="headerlink" title="A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation"></a>A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18087">http://arxiv.org/abs/2310.18087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiesi Hu, Yanwu Yang, Xutao Guo, Jinghua Wang, Ting Ma<br>for:This paper focuses on addressing the accuracy deterioration issue of pseudo-labels (PLs) in source-free domain adaptation (SFDA) methods, which is a crucial problem in medical imaging scenarios due to privacy concerns.methods:The proposed framework consists of three main components: (1) Chebyshev confidence guided SFDA, (2) confidence-guided denoising methods (direct denoising and prototypical denoising), and (3) a novel teacher-student joint training scheme (TJTS) with a confidence weighting module.results:Extensive experiments in diverse domain scenarios demonstrate the effectiveness of the proposed framework, achieving superior performance compared to state-of-the-art SFDA methods. The proposed approach precisely estimates the reliability of PLs and generates high-quality PLs, leading to improved adaptation performance.<details>
<summary>Abstract</summary>
Source-free domain adaptation (SFDA) aims to adapt models trained on a labeled source domain to an unlabeled target domain without the access to source data. In medical imaging scenarios, the practical significance of SFDA methods has been emphasized due to privacy concerns. Recent State-of-the-art SFDA methods primarily rely on self-training based on pseudo-labels (PLs). Unfortunately, PLs suffer from accuracy deterioration caused by domain shift, and thus limit the effectiveness of the adaptation process. To address this issue, we propose a Chebyshev confidence guided SFDA framework to accurately assess the reliability of PLs and generate self-improving PLs for self-training. The Chebyshev confidence is estimated by calculating probability lower bound of the PL confidence, given the prediction and the corresponding uncertainty. Leveraging the Chebyshev confidence, we introduce two confidence-guided denoising methods: direct denoising and prototypical denoising. Additionally, we propose a novel teacher-student joint training scheme (TJTS) that incorporates a confidence weighting module to improve PLs iteratively. The TJTS, in collaboration with the denoising methods, effectively prevents the propagation of noise and enhances the accuracy of PLs. Extensive experiments in diverse domain scenarios validate the effectiveness of our proposed framework and establish its superiority over state-of-the-art SFDA methods. Our paper contributes to the field of SFDA by providing a novel approach for precisely estimating the reliability of pseudo-labels and a framework for obtaining high-quality PLs, resulting in improved adaptation performance.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose a Chebyshev confidence guided SFDA framework to accurately assess the reliability of PLs and generate self-improving PLs for self-training. The Chebyshev confidence is estimated by calculating the probability lower bound of the PL confidence, given the prediction and the corresponding uncertainty.Leveraging the Chebyshev confidence, we introduce two confidence-guided denoising methods: direct denoising and prototypical denoising. Additionally, we propose a novel teacher-student joint training scheme (TJTS) that incorporates a confidence weighting module to improve PLs iteratively. The TJTS, in collaboration with the denoising methods, effectively prevents the propagation of noise and enhances the accuracy of PLs.Extensive experiments in diverse domain scenarios validate the effectiveness of our proposed framework and establish its superiority over state-of-the-art SFDA methods. Our paper contributes to the field of SFDA by providing a novel approach for precisely estimating the reliability of pseudo-labels and a framework for obtaining high-quality PLs, resulting in improved adaptation performance.
</details></li>
</ul>
<hr>
<h2 id="Text-Augmented-Spatial-aware-Zero-shot-Referring-Image-Segmentation"><a href="#Text-Augmented-Spatial-aware-Zero-shot-Referring-Image-Segmentation" class="headerlink" title="Text Augmented Spatial-aware Zero-shot Referring Image Segmentation"></a>Text Augmented Spatial-aware Zero-shot Referring Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18049">http://arxiv.org/abs/2310.18049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yucheng Suo, Linchao Zhu, Yi Yang<br>for: 这种研究旨在解决零shot引用图像分割中的挑战，即基于引用表达而不需要训练的实例掩模分割。methods: 该方法基于Text Augmented Spatial-aware（TAS）框架，包括实例掩模提取网络、文本增强视觉对应分数以及空间修正器。results: 对RefCOCO、RefCOCO+和RefCOCOg等多个 dataset进行了广泛的实验，并表明该方法在零shot引用图像分割任务中具有明显的优势，超越了现有的状态计算方法。<details>
<summary>Abstract</summary>
In this paper, we study a challenging task of zero-shot referring image segmentation. This task aims to identify the instance mask that is most related to a referring expression without training on pixel-level annotations. Previous research takes advantage of pre-trained cross-modal models, e.g., CLIP, to align instance-level masks with referring expressions. %Yet, CLIP only considers image-text pair level alignment, which neglects fine-grained image region and complex sentence matching. Yet, CLIP only considers the global-level alignment of image-text pairs, neglecting fine-grained matching between the referring sentence and local image regions. To address this challenge, we introduce a Text Augmented Spatial-aware (TAS) zero-shot referring image segmentation framework that is training-free and robust to various visual encoders. TAS incorporates a mask proposal network for instance-level mask extraction, a text-augmented visual-text matching score for mining the image-text correlation, and a spatial rectifier for mask post-processing. Notably, the text-augmented visual-text matching score leverages a $P$ score and an $N$-score in addition to the typical visual-text matching score. The $P$-score is utilized to close the visual-text domain gap through a surrogate captioning model, where the score is computed between the surrogate model-generated texts and the referring expression. The $N$-score considers the fine-grained alignment of region-text pairs via negative phrase mining, encouraging the masked image to be repelled from the mined distracting phrases. Extensive experiments are conducted on various datasets, including RefCOCO, RefCOCO+, and RefCOCOg. The proposed method clearly outperforms state-of-the-art zero-shot referring image segmentation methods.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了零shot引用图像分割的挑战性任务。这个任务的目标是使用没有Pixel级别注释的情况下，从referring表达中确定最相关的实例Mask。先前的研究利用了预训练的交叉模态模型，如CLIP，来将实例级别的mask与referring表达相Alignment。然而，CLIP只考虑了图像文本对的全局匹配，忽略了图像区域细化和复杂的句子匹配。为解决这个挑战，我们提出了一个Text Augmented Spatial-aware（TAS）零shot引用图像分割框架。TAS包括一个Mask proposal网络 для实例级别的Mask提取，一个文本增强的视觉文本匹配分数 для挖掘图像文本的相关性，以及一个空间正则化器 дляMask后处理。值得注意的是，文本增强的视觉文本匹配分数利用了$P$ score和$N$-score，以及传统的视觉文本匹配分数。$P$-score通过一个surrogate captioning模型来闭合视觉文本域的差距，其中分数是计算surrogate模型生成的文本和引用表达之间的相似度。$N$-score考虑了图像文本对的细化对应，通过负phrase挖掘，使masked图像受到挖掘的负面抑制。我们对RefCOCO、RefCOCO+和RefCOCOg等多个dataset进行了广泛的实验，并证明了我们的方法在零shot引用图像分割任务中具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="ZeroNVS-Zero-Shot-360-Degree-View-Synthesis-from-a-Single-Real-Image"><a href="#ZeroNVS-Zero-Shot-360-Degree-View-Synthesis-from-a-Single-Real-Image" class="headerlink" title="ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image"></a>ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17994">http://arxiv.org/abs/2310.17994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyle Sargent, Zizhang Li, Tanmay Shah, Charles Herrmann, Hong-Xing Yu, Yunzhi Zhang, Eric Ryan Chan, Dmitry Lagun, Li Fei-Fei, Deqing Sun, Jiajun Wu</li>
<li>for: 这篇论文是设计来 Synthesize single-image novel view for in-the-wild scenes, 对于现有的方法而言，这些方法只适用于单一物体的场景中，这篇论文提出了新的技术来解决受到野外多个物体和复杂背景的挑战。</li>
<li>methods: 这篇论文使用了一个3D-aware散射模型，ZeroNVS，并将其训练在一个混合数据源上，这个数据源包括物体中心、室内和室外场景。为了解决数据混合所引入的问题，例如深度尺度歧义，这篇论文提出了一个新的摄像头参数化和均衡方案。</li>
<li>results: 这篇论文的模型在LPIPS中的 zero-shot 设定中设置了新的州OF-the-art 纪录，甚至超过了特别在DTU上训练的方法。此外，这篇论文还适用了Mip-NeRF 360 dataset作为单一图像新观点合成的新 bencmark，并在这个设定中展现了强大的性能。<details>
<summary>Abstract</summary>
We introduce a 3D-aware diffusion model, ZeroNVS, for single-image novel view synthesis for in-the-wild scenes. While existing methods are designed for single objects with masked backgrounds, we propose new techniques to address challenges introduced by in-the-wild multi-object scenes with complex backgrounds. Specifically, we train a generative prior on a mixture of data sources that capture object-centric, indoor, and outdoor scenes. To address issues from data mixture such as depth-scale ambiguity, we propose a novel camera conditioning parameterization and normalization scheme. Further, we observe that Score Distillation Sampling (SDS) tends to truncate the distribution of complex backgrounds during distillation of 360-degree scenes, and propose "SDS anchoring" to improve the diversity of synthesized novel views. Our model sets a new state-of-the-art result in LPIPS on the DTU dataset in the zero-shot setting, even outperforming methods specifically trained on DTU. We further adapt the challenging Mip-NeRF 360 dataset as a new benchmark for single-image novel view synthesis, and demonstrate strong performance in this setting. Our code and data are at http://kylesargent.github.io/zeronvs/
</details>
<details>
<summary>摘要</summary>
我们介绍了一种3D意识扩散模型，namely ZeroNVS，用于单图新视角合成Scene中的异常场景。而现有方法通常是为单个物体设置masked背景，我们提出了新的技术来解决在野外多对象场景中引入的挑战。具体来说，我们在混合数据源上训练了生成的先验，以捕捉object-centric、indoor和outdoor场景。为了解决数据混合引入的深度尺度歧义，我们提出了一种新的摄像头条件化和正规化方案。此外，我们发现Score Distillation Sampling (SDS)在混合360度场景中进行distillation时，容易对复杂背景进行短结，我们提出了"SDS anchoring"来提高合成的新视角的多样性。我们的模型在LPIPS上DTU数据集上达到了新的州OF-THE-ART记录，甚至超越了特地在DTU上训练的方法。此外，我们采用了Difficult Mip-NeRF 360数据集作为新的benchmark，并在这个设置下达到了出色的性能。我们的代码和数据可以在http://kylesargent.github.io/zeronvs/上找到。
</details></li>
</ul>
<hr>
<h2 id="FaultSeg-Swin-UNETR-Transformer-Based-Self-Supervised-Pretraining-Model-for-Fault-Recognition"><a href="#FaultSeg-Swin-UNETR-Transformer-Based-Self-Supervised-Pretraining-Model-for-Fault-Recognition" class="headerlink" title="FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model for Fault Recognition"></a>FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model for Fault Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17974">http://arxiv.org/abs/2310.17974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeren Zhang, Ran Chen, Jinwen Ma</li>
<li>for: 提高震动 fault 识别精度</li>
<li>methods: 自动学习 + Swintransformer + SimMIM 预训练 + 多尺度拟合 + edge detection</li>
<li>results: 在Thebe数据集上实现了领先的性能，OIS和ODS指标中评估为最佳Here’s a brief explanation of each point:1. for: The paper aims to improve the accuracy of seismic fault recognition by introducing a self-supervised learning approach using a large amount of unlabeled seismic data for pretraining.2. methods: The proposed method utilizes the Swin Transformer model as the core network and employs the SimMIM pretraining task to capture unique features related to discontinuities in seismic data. Additionally, the authors refine the structure of the Swin-UNETR model to enable multiscale decoding and fusion for more effective fault detection.3. results: The experimental results on the Thebe dataset demonstrate that the proposed method achieves state-of-the-art performance, as measured by the OIS and ODS metrics.<details>
<summary>Abstract</summary>
This paper introduces an approach to enhance seismic fault recognition through self-supervised pretraining. Seismic fault interpretation holds great significance in the fields of geophysics and geology. However, conventional methods for seismic fault recognition encounter various issues, including dependence on data quality and quantity, as well as susceptibility to interpreter subjectivity. Currently, automated fault recognition methods proposed based on small synthetic datasets experience performance degradation when applied to actual seismic data. To address these challenges, we have introduced the concept of self-supervised learning, utilizing a substantial amount of relatively easily obtainable unlabeled seismic data for pretraining. Specifically, we have employed the Swin Transformer model as the core network and employed the SimMIM pretraining task to capture unique features related to discontinuities in seismic data. During the fine-tuning phase, inspired by edge detection techniques, we have also refined the structure of the Swin-UNETR model, enabling multiscale decoding and fusion for more effective fault detection. Experimental results demonstrate that our proposed method attains state-of-the-art performance on the Thebe dataset, as measured by the OIS and ODS metrics.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multivessel-Coronary-Artery-Segmentation-and-Stenosis-Localisation-using-Ensemble-Learning"><a href="#Multivessel-Coronary-Artery-Segmentation-and-Stenosis-Localisation-using-Ensemble-Learning" class="headerlink" title="Multivessel Coronary Artery Segmentation and Stenosis Localisation using Ensemble Learning"></a>Multivessel Coronary Artery Segmentation and Stenosis Localisation using Ensemble Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17954">http://arxiv.org/abs/2310.17954</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Bilal, Dinis Martinho, Reiner Sim, Adnan Qayyum, Hunaid Vohra, Massimo Caputo, Taofeek Akinosho, Sofiat Abioye, Zaheer Khan, Waleed Niaz, Junaid Qadir<br>for: 这个研究旨在提供一个基于机器学习的自动化诊断方案，以帮助cardiologists诊断折叠动脉疾病（CAD）。methods: 该研究使用了一种结合多个基线模型的 ensemble 模型，通过逐渐提高性能的训练策略，包括多个阶段的预training、多血管分割和精度提高等。results: 该研究的结果显示，使用这种方法可以Double the predictive accuracy of the proposed solution，并且通过进一步纠正错误的blob来进行精度提高。最终得到的结果为 coronary artery segmentation 的 mean F1 score 为 37.69%，和 stenosis localization 的 mean F1 score 为 39.41%。<details>
<summary>Abstract</summary>
Coronary angiography analysis is a common clinical task performed by cardiologists to diagnose coronary artery disease (CAD) through an assessment of atherosclerotic plaque's accumulation. This study introduces an end-to-end machine learning solution developed as part of our solution for the MICCAI 2023 Automatic Region-based Coronary Artery Disease diagnostics using x-ray angiography imagEs (ARCADE) challenge, which aims to benchmark solutions for multivessel coronary artery segmentation and potential stenotic lesion localisation from X-ray coronary angiograms. We adopted a robust baseline model training strategy to progressively improve performance, comprising five successive stages of binary class pretraining, multivessel segmentation, fine-tuning using class frequency weighted dataloaders, fine-tuning using F1-based curriculum learning strategy (F1-CLS), and finally multi-target angiogram view classifier-based collective adaptation. Unlike many other medical imaging procedures, this task exhibits a notable degree of interobserver variability. %, making it particularly amenable to automated analysis. Our ensemble model combines the outputs from six baseline models using the weighted ensembling approach, which our analysis shows is found to double the predictive accuracy of the proposed solution. The final prediction was further refined, targeting the correction of misclassified blobs. Our solution achieved a mean F1 score of $37.69\%$ for coronary artery segmentation, and $39.41\%$ for stenosis localisation, positioning our team in the 5th position on both leaderboards. This work demonstrates the potential of automated tools to aid CAD diagnosis, guide interventions, and improve the accuracy of stent injections in clinical settings.
</details>
<details>
<summary>摘要</summary>
coronary angiography 分析是一种常见的临床任务，由医生用于诊断液体动脉疾病（CAD）的评估，包括atherosclerotic plaque的积累。这项研究介绍了一种基于我们的解决方案的自动化解决方案，用于MICCAI 2023 自动区域基础 coronary artery disease 诊断（ARCADE）挑战，以获得多个血管 segmentation 和可能的狭窄 lesion 的位置。我们采用了一种可靠的基线模型训练策略，包括五个顺序的 binary class pretraining、多血管 segmentation、精度调整使用类频率加载器、F1-based curriculum learning strategy（F1-CLS）和最后是多视图 coronary angiogram 类型的集成adaptation。与许多医疗影像过程不同，这个任务具有显著的Interobserver variability，使其更适合自动分析。我们的集成模型将六个基线模型的输出结合使用重量加权ensembleapproach，我们的分析显示可以double predictive accuracy of the proposed solution。最终预测还进行了进一步的纠正，以正确化错误的 blob。我们的解决方案在 coronary artery segmentation 方面 achievement mean F1 score of 37.69%，并在 localisation 方面 achievement mean F1 score of 39.41%，位于领先board 的第五名。这项工作 demonstarted the potential of automated tools to aid CAD diagnosis, guide interventions, and improve the accuracy of stent injections in clinical settings.
</details></li>
</ul>
<hr>
<h2 id="Shape-centered-Representation-Learning-for-Visible-Infrared-Person-Re-identification"><a href="#Shape-centered-Representation-Learning-for-Visible-Infrared-Person-Re-identification" class="headerlink" title="Shape-centered Representation Learning for Visible-Infrared Person Re-identification"></a>Shape-centered Representation Learning for Visible-Infrared Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17952">http://arxiv.org/abs/2310.17952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Li, Jiaxu Leng, Ji Gan, Mengjingcheng Mo, Xinbo Gao</li>
<li>for: 这个论文主要目标是提高人各个感知中的人脸识别率，尤其是在可见光和红外光之间的模式转换问题上。</li>
<li>methods: 该论文提出了一种基于形状特征学习的Shape-centered Representation Learning框架（ScRL），包括Shape Feature Propagation（SFP）和Infrared Shape Restitution（ISR）等技术，以提高人脸识别率。</li>
<li>results: 该论文的实验结果表明，ScRL可以在人脸识别任务中实现remarkable的性能，其中 Rank-1（mAP）精度达到76.1%, 71.2%, 92.4%（72.6%, 52.9%, 86.7%）在SYSU-MM01、HITSZ-VCM和RegDB数据集上。<details>
<summary>Abstract</summary>
Current Visible-Infrared Person Re-Identification (VI-ReID) methods prioritize extracting distinguishing appearance features, ignoring the natural resistance of body shape against modality changes. Initially, we gauged the discriminative potential of shapes by a straightforward concatenation of shape and appearance features. However, two unresolved issues persist in the utilization of shape features. One pertains to the dependence on auxiliary models for shape feature extraction in the inference phase, along with the errors in generated infrared shapes due to the intrinsic modality disparity. The other issue involves the inadequately explored correlation between shape and appearance features. To tackle the aforementioned challenges, we propose the Shape-centered Representation Learning framework (ScRL), which focuses on learning shape features and appearance features associated with shapes. Specifically, we devise the Shape Feature Propagation (SFP), facilitating direct extraction of shape features from original images with minimal complexity costs during inference. To restitute inaccuracies in infrared body shapes at the feature level, we present the Infrared Shape Restitution (ISR). Furthermore, to acquire appearance features related to shape, we design the Appearance Feature Enhancement (AFE), which accentuates identity-related features while suppressing identity-unrelated features guided by shape features. Extensive experiments are conducted to validate the effectiveness of the proposed ScRL. Achieving remarkable results, the Rank-1 (mAP) accuracy attains 76.1%, 71.2%, 92.4% (72.6%, 52.9%, 86.7%) on the SYSU-MM01, HITSZ-VCM, RegDB datasets respectively, outperforming existing state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
当前可见红外人重认（VI-ReID）方法强调抽出特征特征，忽视人体形态自然对模态变化的抵抗性。我们首先评估特征的推诉潜力，通过简单 concatenation  shape 和 appearance 特征。但是，在使用 shape 特征时，存在两个不解决的问题。其一是在推理阶段依赖 auxilary 模型来EXTRACT shape 特征，同时因内生模态差而产生的生成红外形态错误。另一个问题是 shape 和 appearance 特征之间的相关性未得到充分探索。为了解决这些挑战，我们提出了 Shape-centered Representation Learning 框架（ScRL），它注重学习 shape 特征和 appearance 特征相关的 shape。具体来说，我们设计了 Shape Feature Propagation （SFP），它可以在原始图像中直接EXTRACT shape 特征，降低推理复杂性。此外，我们还提出了 Infrared Shape Restitution （ISR），用于在特征层修复红外形态错误。此外，我们还设计了 Appearance Feature Enhancement （AFE），它可以强调身份相关的特征，同时避免身份不相关的特征，以shape特征为引导。我们进行了广泛的实验，以验证 ScRL 的效果。得到了惊人的结果，VI-ReID 方法的 Rank-1（mAP）精度达到 76.1%、71.2%、92.4%（72.6%、52.9%、86.7%），在 SYSU-MM01、HITSZ-VCM 和 RegDB 数据集上，分别高于当前状态的前iers。
</details></li>
</ul>
<hr>
<h2 id="Instance-Segmentation-under-Occlusions-via-Location-aware-Copy-Paste-Data-Augmentation"><a href="#Instance-Segmentation-under-Occlusions-via-Location-aware-Copy-Paste-Data-Augmentation" class="headerlink" title="Instance Segmentation under Occlusions via Location-aware Copy-Paste Data Augmentation"></a>Instance Segmentation under Occlusions via Location-aware Copy-Paste Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17949">http://arxiv.org/abs/2310.17949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nguyendinhson-kaist/mmsports23-seg-autoid">https://github.com/nguyendinhson-kaist/mmsports23-seg-autoid</a></li>
<li>paper_authors: Son Nguyen, Mikel Lainsa, Hung Dao, Daeyoung Kim, Giang Nguyen</li>
<li>for: 本研究主要针对计算机视觉中的 occlusion 问题进行解决，具体来说是在 instance segmentation 领域中。</li>
<li>methods: 本研究使用了一种新的数据增强技术，可以生成更多的训练样本，以及一种新的深度学习架构 Hybrid Task Cascade (HTC) 框架，以提高 segmentation 性能。</li>
<li>results: 本研究在 MMSports 2023 DeepSportRadar 比赛中取得了很好的结果，其中 occlusion 得分 (OM) 为 0.533，位于领导者板卡的第一名。<details>
<summary>Abstract</summary>
Occlusion is a long-standing problem in computer vision, particularly in instance segmentation. ACM MMSports 2023 DeepSportRadar has introduced a dataset that focuses on segmenting human subjects within a basketball context and a specialized evaluation metric for occlusion scenarios. Given the modest size of the dataset and the highly deformable nature of the objects to be segmented, this challenge demands the application of robust data augmentation techniques and wisely-chosen deep learning architectures. Our work (ranked 1st in the competition) first proposes a novel data augmentation technique, capable of generating more training samples with wider distribution. Then, we adopt a new architecture - Hybrid Task Cascade (HTC) framework with CBNetV2 as backbone and MaskIoU head to improve segmentation performance. Furthermore, we employ a Stochastic Weight Averaging (SWA) training strategy to improve the model's generalization. As a result, we achieve a remarkable occlusion score (OM) of 0.533 on the challenge dataset, securing the top-1 position on the leaderboard. Source code is available at this https://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID.
</details>
<details>
<summary>摘要</summary>
干扰是计算机视觉领域的长期问题，特别是在实例分割方面。ACM MMSports 2023 DeepSportRadar  datasets 已经引入了专门用于人体分割的篮球场景，以及特殊的评价指标 для干扰情况。由于数据集的规模较小和需要分割的对象具有高度变形的特点，这个挑战需要应用robust的数据扩展技术和合适的深度学习架构。我们的工作（在比赛中排名第一）首先提出了一种新的数据扩展技术，能够生成更多的训练样本，并且具有更广泛的分布。然后，我们采用了一个新的框架——Hybrid Task Cascade（HTC）框架，其中CBNetV2 作为 backing 和 MaskIoU 头部来提高分割性能。此外，我们还使用了一种Stochastic Weight Averaging（SWA） 训练策略，以提高模型的泛化性。因此，我们在挑战数据集上实现了干扰分数（OM）为 0.533，在 liderboard 上排名第一。源代码可以在以下链接中找到：https://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID。
</details></li>
</ul>
<hr>
<h2 id="Diversifying-Spatial-Temporal-Perception-for-Video-Domain-Generalization"><a href="#Diversifying-Spatial-Temporal-Perception-for-Video-Domain-Generalization" class="headerlink" title="Diversifying Spatial-Temporal Perception for Video Domain Generalization"></a>Diversifying Spatial-Temporal Perception for Video Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17942">http://arxiv.org/abs/2310.17942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kunyulin/stdn">https://github.com/kunyulin/stdn</a></li>
<li>paper_authors: Kun-Yu Lin, Jia-Run Du, Yipeng Gao, Jiaming Zhou, Wei-Shi Zheng</li>
<li>for: 学习通用视频分类模型，并在不同目标领域中进行泛化。</li>
<li>methods: 利用多种空间和时间维度的多cue学习，以找到可能的领域不受影响的cue。</li>
<li>results: 在三个不同类型的benchmark上进行了广泛的实验，证明了我们的方法的有效性和多样性。<details>
<summary>Abstract</summary>
Video domain generalization aims to learn generalizable video classification models for unseen target domains by training in a source domain. A critical challenge of video domain generalization is to defend against the heavy reliance on domain-specific cues extracted from the source domain when recognizing target videos. To this end, we propose to perceive diverse spatial-temporal cues in videos, aiming to discover potential domain-invariant cues in addition to domain-specific cues. We contribute a novel model named Spatial-Temporal Diversification Network (STDN), which improves the diversity from both space and time dimensions of video data. First, our STDN proposes to discover various types of spatial cues within individual frames by spatial grouping. Then, our STDN proposes to explicitly model spatial-temporal dependencies between video contents at multiple space-time scales by spatial-temporal relation modeling. Extensive experiments on three benchmarks of different types demonstrate the effectiveness and versatility of our approach.
</details>
<details>
<summary>摘要</summary>
视频领域通用化目标在培养源领域中学习通用的视频分类模型，以便在目标领域中进行推理。一个关键的挑战是防止在目标视频识别中过重依赖源领域特有的特征。为此，我们提议利用视频中的多样化空间-时间特征，找到可能的领域不受影响的特征。我们提出了一种新的模型，即空间-时间多样化网络（STDN），它在视频数据中提高多样化性。首先，我们的 STDN 提出了在个体帧中发现多种空间特征的方法，并进行空间组合。然后，我们的 STDN 利用多个空间-时间尺度的空间-时间关系模型，以模拟视频内容之间的空间-时间相互关系。我们在三个不同类型的 benchmark 上进行了广泛的实验，并证明了我们的方法的有效性和多样性。
</details></li>
</ul>
<hr>
<h2 id="DocStormer-Revitalizing-Multi-Degraded-Colored-Document-Images-to-Pristine-PDF"><a href="#DocStormer-Revitalizing-Multi-Degraded-Colored-Document-Images-to-Pristine-PDF" class="headerlink" title="DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF"></a>DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17910">http://arxiv.org/abs/2310.17910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaowei Liu, Jichun Li, Yihua Teng, Chaoqun Wang, Nuo Xu, Jihao Wu, Dandan Tu</li>
<li>for: 提高多层次陌生文档图像的Restoration至其潜在的PDF版本</li>
<li>methods: 基于”Perceive-then-Restore”模式的 transformer 块，加上 GAN 和优质PDF图像，以减少陌生度和提高视觉质量</li>
<li>results: 实验结果显示， DocStormer 可以有效地恢复多层次陌生文档图像，提供了一个新的 Restoration 方法，可以填补当前学术领域中的一个知识漏洞。<details>
<summary>Abstract</summary>
For capturing colored document images, e.g. posters and magazines, it is common that multiple degradations such as shadows, wrinkles, etc., are simultaneously introduced due to external factors. Restoring multi-degraded colored document images is a great challenge, yet overlooked, as most existing algorithms focus on enhancing color-ignored document images via binarization. Thus, we propose DocStormer, a novel algorithm designed to restore multi-degraded colored documents to their potential pristine PDF. The contributions are: firstly, we propose a "Perceive-then-Restore" paradigm with a reinforced transformer block, which more effectively encodes and utilizes the distribution of degradations. Secondly, we are the first to utilize GAN and pristine PDF magazine images to narrow the distribution gap between the enhanced results and PDF images, in pursuit of less degradation and better visual quality. Thirdly, we propose a non-parametric strategy, PFILI, which enables a smaller training scale and larger testing resolutions with acceptable detail trade-off, while saving memory and inference time. Fourthly, we are the first to propose a novel Multi-Degraded Colored Document image Enhancing dataset, named MD-CDE, for both training and evaluation. Experimental results show that the DocStormer exhibits superior performance, capable of revitalizing multi-degraded colored documents into their potential pristine digital versions, which fills the current academic gap from the perspective of method, data, and task.
</details>
<details>
<summary>摘要</summary>
For capturing 颜色文档图像，如 poster 和杂志， external factors 可能同时引入多种干扰， such as shadows 和折皮等。 Restoring 多干扰的颜色文档图像是一大挑战，尤其是被忽略的，因为大多数现有算法都专注于提高无色文档图像的明暗分割。 Therefore, we propose DocStormer, a novel algorithm designed to restore 多干扰的颜色文档图像 to its potential pristine PDF. The contributions are:Firstly, we propose a "Perceive-then-Restore" paradigm with a reinforced transformer block, which more effectively encodes and utilizes the distribution of degradations.Secondly, we are the first to utilize GAN and pristine PDF magazine images to narrow the distribution gap between the enhanced results and PDF images, in pursuit of less degradation and better visual quality.Thirdly, we propose a non-parametric strategy, PFILI, which enables a smaller training scale and larger testing resolutions with acceptable detail trade-off, while saving memory and inference time.Fourthly, we are the first to propose a novel Multi-Degraded Colored Document image Enhancing dataset, named MD-CDE, for both training and evaluation. Experimental results show that the DocStormer exhibits superior performance, capable of revitalizing 多干扰的颜色文档图像 into its potential pristine digital versions, which fills the current academic gap from the perspective of method, data, and task.
</details></li>
</ul>
<hr>
<h2 id="Impressions-Understanding-Visual-Semiotics-and-Aesthetic-Impact"><a href="#Impressions-Understanding-Visual-Semiotics-and-Aesthetic-Impact" class="headerlink" title="Impressions: Understanding Visual Semiotics and Aesthetic Impact"></a>Impressions: Understanding Visual Semiotics and Aesthetic Impact</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17887">http://arxiv.org/abs/2310.17887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Kruk, Caleb Ziems, Diyi Yang</li>
<li>for:  investigate the semiotics of images and how specific visual features and design choices can elicit specific emotions, thoughts, and beliefs.</li>
<li>methods:  design an annotation task heavily inspired by image analysis techniques in the Visual Arts to collect image-caption pairs and unique annotations exploring impact, pragmatic image description, impressions, and aesthetic design choices.</li>
<li>results:  existing multimodal image captioning and conditional generation models struggle to simulate plausible human responses to images, but this dataset significantly improves their ability to model impressions and aesthetic evaluations of images through fine-tuning and few-shot adaptation.Here is the full translation of the paper’s abstract in Simplified Chinese:</li>
<li>for: 这个研究旨在 investigate the semiotics of images, and how specific visual features and design choices can elicit specific emotions, thoughts, and beliefs.</li>
<li>methods: 这个研究使用了一个 heavily inspired by image analysis techniques in the Visual Arts 的 annotation task，收集了 1,440 个 image-caption pairs 和 4,320 个 unique annotations，探讨 impact, pragmatic image description, impressions, 和 aesthetic design choices.</li>
<li>results: 现有的 multimodal image captioning 和 conditional generation models 对 images 的 simulated human responses 表现不佳，但是这个 dataset 能够 significantly improve 这些模型的 ability to model impressions 和 aesthetic evaluations of images through fine-tuning 和 few-shot adaptation.<details>
<summary>Abstract</summary>
Is aesthetic impact different from beauty? Is visual salience a reflection of its capacity for effective communication? We present Impressions, a novel dataset through which to investigate the semiotics of images, and how specific visual features and design choices can elicit specific emotions, thoughts and beliefs. We posit that the impactfulness of an image extends beyond formal definitions of aesthetics, to its success as a communicative act, where style contributes as much to meaning formation as the subject matter. However, prior image captioning datasets are not designed to empower state-of-the-art architectures to model potential human impressions or interpretations of images. To fill this gap, we design an annotation task heavily inspired by image analysis techniques in the Visual Arts to collect 1,440 image-caption pairs and 4,320 unique annotations exploring impact, pragmatic image description, impressions, and aesthetic design choices. We show that existing multimodal image captioning and conditional generation models struggle to simulate plausible human responses to images. However, this dataset significantly improves their ability to model impressions and aesthetic evaluations of images through fine-tuning and few-shot adaptation.
</details>
<details>
<summary>摘要</summary>
是美学影响与美的区别？视觉吸引力是通信效果的反映吗？我们介绍Impressions，一个新的数据集，用于探讨图像的 semiotics，并如何specific visual features和设计选择可以引发specific emotions, thoughts和beliefs。我们认为图像的吸引力不仅限于传统的美学定义，还包括图像作为通信行为的成功度，style与subject matter共同形成意义。但是，先前的图像描述数据集不适用于激发人类的印象或解释。为了填补这个空白，我们设计了一个基于图像分析技术的image描述任务，收集了1,440个图像-描述对和4,320个特有的批注，探讨影响、实用描述、印象和美学设计选择。我们发现，现有的多modal图像描述和条件生成模型在模拟人类对图像的回应方面表现不佳。但是，这个数据集可以大幅提高这些模型对图像印象和美学评价的能力。
</details></li>
</ul>
<hr>
<h2 id="Reconstructive-Latent-Space-Neural-Radiance-Fields-for-Efficient-3D-Scene-Representations"><a href="#Reconstructive-Latent-Space-Neural-Radiance-Fields-for-Efficient-3D-Scene-Representations" class="headerlink" title="Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D Scene Representations"></a>Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D Scene Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17880">http://arxiv.org/abs/2310.17880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tristan Aumentado-Armstrong, Ashkan Mirzaei, Marcus A. Brubaker, Jonathan Kelly, Alex Levinshtein, Konstantinos G. Derpanis, Igor Gilitschenski</li>
<li>for: 这paper aimed to improve the efficiency of Neural Radiance Fields (NeRFs) for 3D scene representation, while maintaining high image quality.</li>
<li>methods: 该paper使用了一个 autoencoder (AE) 与 NeRF 结合，将 latent features 渲染并用 convolutional decoding 来生成新的视图。</li>
<li>results: 相比标准色域 NeRFs，latent-space NeRF 可以生成更高质量的新视图，并且可以在三倍的渲染速度下得到更好的效果。此外，通过缩小 AE 架构，可以控制效率和图像质量之间的交易，并达到更高的渲染速度。<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRFs) have proven to be powerful 3D representations, capable of high quality novel view synthesis of complex scenes. While NeRFs have been applied to graphics, vision, and robotics, problems with slow rendering speed and characteristic visual artifacts prevent adoption in many use cases. In this work, we investigate combining an autoencoder (AE) with a NeRF, in which latent features (instead of colours) are rendered and then convolutionally decoded. The resulting latent-space NeRF can produce novel views with higher quality than standard colour-space NeRFs, as the AE can correct certain visual artifacts, while rendering over three times faster. Our work is orthogonal to other techniques for improving NeRF efficiency. Further, we can control the tradeoff between efficiency and image quality by shrinking the AE architecture, achieving over 13 times faster rendering with only a small drop in performance. We hope that our approach can form the basis of an efficient, yet high-fidelity, 3D scene representation for downstream tasks, especially when retaining differentiability is useful, as in many robotics scenarios requiring continual learning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Siamese-DETR-for-Generic-Multi-Object-Tracking"><a href="#Siamese-DETR-for-Generic-Multi-Object-Tracking" class="headerlink" title="Siamese-DETR for Generic Multi-Object Tracking"></a>Siamese-DETR for Generic Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17875">http://arxiv.org/abs/2310.17875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiankun Liu, Yichen Li, Yuqi Jiang, Ying Fu<br>for: 本研究的目的是提出一种简单 yet effective的 Generic Multi-Object Tracking (GMOT) 方法，以便在不同场景中检测和跟踪动态对象。methods: 本研究使用了 Siamese-DETR 方法，其中利用了 detection 数据集 (e.g., COCO) 进行训练，并 introduce 了一种动态匹配训练策略以使用提供的筛选器。results: 实验结果显示，Siamese-DETR 在 GMOT-40 数据集上表现出色，至今为止比 EXISTS 的 MOT 方法更高。<details>
<summary>Abstract</summary>
The ability to detect and track the dynamic objects in different scenes is fundamental to real-world applications, e.g., autonomous driving and robot navigation. However, traditional Multi-Object Tracking (MOT) is limited to tracking objects belonging to the pre-defined closed-set categories. Recently, Open-Vocabulary MOT (OVMOT) and Generic MOT (GMOT) are proposed to track interested objects beyond pre-defined categories with the given text prompt and template image. However, the expensive well pre-trained (vision-)language model and fine-grained category annotations are required to train OVMOT models. In this paper, we focus on GMOT and propose a simple but effective method, Siamese-DETR, for GMOT. Only the commonly used detection datasets (e.g., COCO) are required for training. Different from existing GMOT methods, which train a Single Object Tracking (SOT) based detector to detect interested objects and then apply a data association based MOT tracker to get the trajectories, we leverage the inherent object queries in DETR variants. Specifically: 1) The multi-scale object queries are designed based on the given template image, which are effective for detecting different scales of objects with the same category as the template image; 2) A dynamic matching training strategy is introduced to train Siamese-DETR on commonly used detection datasets, which takes full advantage of provided annotations; 3) The online tracking pipeline is simplified through a tracking-by-query manner by incorporating the tracked boxes in previous frame as additional query boxes. The complex data association is replaced with the much simpler Non-Maximum Suppression (NMS). Extensive experimental results show that Siamese-DETR surpasses existing MOT methods on GMOT-40 dataset by a large margin.
</details>
<details>
<summary>摘要</summary>
能力检测和跟踪不同场景中的动态对象是实际应用中的基本要求，例如自动驾驶和机器人导航。然而，传统的多对象跟踪（MOT）仅能跟踪预定的关闭集类型的对象。最近，开放词汇MOT（OVMOT）和通用MOT（GMOT）被提出，以检测与给定模板图像中的对象相关的对象。然而，需要昂贵的高级见语言模型和细化类别标注来训练OVMOT模型。在本文中，我们将关注GMOT，并提出一种简单 yet effective的方法：Siamese-DETR。只需使用常用的检测数据集（例如COCO）进行训练。与现有GMOT方法不同，我们不会训练单个对象检测器来检测兴趣对象，而是利用DETR变体中的内置对象查询。具体来说，我们做了以下三个方法：1）基于给定模板图像的多尺度对象查询，可以有效地检测不同的对象大小与模板图像中的同一类型对象; 2）我们引入了动态匹配训练策略，以利用提供的注释来训练Siamese-DETR; 3）通过将跟踪框架简化为查询方式，并将已跟踪的框架作为额外的查询框架，替代复杂的数据关联。这里的数据关联被替换为非最大Suppression（NMS）。我们的实验结果表明，Siamese-DETR在GMOT-40数据集上大幅超越现有MOT方法。
</details></li>
</ul>
<hr>
<h2 id="SmooSeg-Smoothness-Prior-for-Unsupervised-Semantic-Segmentation"><a href="#SmooSeg-Smoothness-Prior-for-Unsupervised-Semantic-Segmentation" class="headerlink" title="SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation"></a>SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17874">http://arxiv.org/abs/2310.17874</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mc-lan/smooseg">https://github.com/mc-lan/smooseg</a></li>
<li>paper_authors: Mengcheng Lan, Xinjiang Wang, Yiping Ke, Jiaxing Xu, Litong Feng, Wayne Zhang</li>
<li>for: 这个论文主要针对不具有人工标注的图像分割 tasks，即将图像分割为Semantic groups而不需要人工标注。</li>
<li>methods: 我们提出了一个 novel 的方法，即 SmooSeg，它利用自我supervised learning 方法来模型对观测到的变化之间的关系，并将这些变化映射到Semantic groups中。我们还引入了一个新的平滑性损失函数，它可以在不同的Semantic groups之间实现平滑的变化，同时保留不同Semantic groups之间的关系。</li>
<li>results: 根据我们的实验结果，SmooSeg 可以对 COCOStuff、Cityscapes 和 Potsdam-3 等三个数据集进行高效的分割，并且与 STEGO 相比，SmooSeg 可以提高 pixel accuracy 的表现。具体来说，在 COCOStuff 数据集上，SmooSeg 可以提高 pixel accuracy 的表现+14.9%，在 Cityscapes 数据集上提高 +13.0%，在 Potsdam-3 数据集上提高 +5.7%。<details>
<summary>Abstract</summary>
Unsupervised semantic segmentation is a challenging task that segments images into semantic groups without manual annotation. Prior works have primarily focused on leveraging prior knowledge of semantic consistency or priori concepts from self-supervised learning methods, which often overlook the coherence property of image segments. In this paper, we demonstrate that the smoothness prior, asserting that close features in a metric space share the same semantics, can significantly simplify segmentation by casting unsupervised semantic segmentation as an energy minimization problem. Under this paradigm, we propose a novel approach called SmooSeg that harnesses self-supervised learning methods to model the closeness relationships among observations as smoothness signals. To effectively discover coherent semantic segments, we introduce a novel smoothness loss that promotes piecewise smoothness within segments while preserving discontinuities across different segments. Additionally, to further enhance segmentation quality, we design an asymmetric teacher-student style predictor that generates smoothly updated pseudo labels, facilitating an optimal fit between observations and labeling outputs. Thanks to the rich supervision cues of the smoothness prior, our SmooSeg significantly outperforms STEGO in terms of pixel accuracy on three datasets: COCOStuff (+14.9%), Cityscapes (+13.0%), and Potsdam-3 (+5.7%).
</details>
<details>
<summary>摘要</summary>
无监督semantic segmentation是一项复杂的任务，它的目标是将图像分割成semantic组without manual annotation. 先前的研究主要依靠自动学习方法来激活先前的semantic consistency或self-supervised learning方法，这些方法经常忽视图像分割的coherence性质. 在这篇论文中，我们表明了smoothness prior，即close features in a metric space share the same semantics，可以大大简化segmentation。 在这个思想下，我们提出了一种新的方法called SmooSeg，它利用self-supervised learning方法来表示observations的closeness关系作为smoothness信号。 为了有效发现coherent semantic segments，我们引入了一种新的smoothness loss，该损失函数激活piecewise smoothness within segments while preserving discontinuities across different segments。 此外，我们还设计了一种异形 teacher-student 预测器，该预测器可以生成smoothly updated pseudo labels，使得observations和labeling输出之间进行优化的适应。 由于smoothness prior提供了丰富的监督信号，我们的SmooSeg在COCOStuff (+14.9%), Cityscapes (+13.0%), and Potsdam-3 (+5.7%)三个数据集上都显著超过STEGO的像素准确率。
</details></li>
</ul>
<hr>
<h2 id="Grid-Jigsaw-Representation-with-CLIP-A-New-Perspective-on-Image-Clustering"><a href="#Grid-Jigsaw-Representation-with-CLIP-A-New-Perspective-on-Image-Clustering" class="headerlink" title="Grid Jigsaw Representation with CLIP: A New Perspective on Image Clustering"></a>Grid Jigsaw Representation with CLIP: A New Perspective on Image Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17869">http://arxiv.org/abs/2310.17869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijie Song, Zhenzhen Hu, Richang Hong</li>
<li>for: 这种图像归一化学习是计算机视觉领域中的一种不可或缺的基础技术，它可以帮助图像进行有效的分类和识别。</li>
<li>methods: 该文章提出了一种基于缝隙的图像归一化方法，即Grid Jigsaw Representation（GJR），该方法通过模拟人类缝隙图像的方式，来提高模型对图像的特征分解和分类能力。</li>
<li>results: 该文章通过对多个标准 benchmark 数据集进行测试，证明了GJR模块可以帮助图像归一化进行更好的分类和识别，并且在速度和精度两个方面具有优于传统方法的优势。此外，文章还提出了一种基于预训练的Grid Jigsaw Representation（pGJR）方法，该方法可以在快速的 converges 过程中提高图像归一化的效果。<details>
<summary>Abstract</summary>
Unsupervised representation learning for image clustering is essential in computer vision. Although the advancement of visual models has improved image clustering with efficient visual representations, challenges still remain. Firstly, these features often lack the ability to represent the internal structure of images, hindering the accurate clustering of visually similar images. Secondly, the existing features tend to lack finer-grained semantic labels, limiting the ability to capture nuanced differences and similarities between images.   In this paper, we first introduce Jigsaw based strategy method for image clustering called Grid Jigsaw Representation (GJR) with systematic exposition from pixel to feature in discrepancy against human and computer. We emphasize that this algorithm, which mimics human jigsaw puzzle, can effectively improve the model to distinguish the spatial feature between different samples and enhance the clustering ability. GJR modules are appended to a variety of deep convolutional networks and tested with significant improvements on a wide range of benchmark datasets including CIFAR-10, CIFAR-100/20, STL-10, ImageNet-10 and ImageNetDog-15.   On the other hand, convergence efficiency is always an important challenge for unsupervised image clustering. Recently, pretrained representation learning has made great progress and released models can extract mature visual representations. It is obvious that use the pretrained model as feature extractor can speed up the convergence of clustering where our aim is to provide new perspective in image clustering with reasonable resource application and provide new baseline. Further, we innovate pretrain-based Grid Jigsaw Representation (pGJR) with improvement by GJR. The experiment results show the effectiveness on the clustering task with respect to the ACC, NMI and ARI three metrics and super fast convergence speed.
</details>
<details>
<summary>摘要</summary>
自然无监督学习是计算机视觉中不可或缺的一部分。虽然视觉模型的进步使得图像归类得到了有效的视觉表示，但是还存在一些挑战。首先，这些特征通常缺乏表示图像内部结构的能力，使得准确归类类似图像 become more difficult.其次，现有的特征通常缺乏更细grained的Semantic Label，限制了捕捉图像之间细微差异和相似性的能力。在这篇论文中，我们首先介绍了基于Jigsaw策略的图像归类方法，即Grid Jigsaw Representation（GJR），并进行系统性的描述从像素到特征之间的差异。我们强调这种算法，类似于人类的缺失图形，可以有效地提高模型对图像之间的空间特征的分辨率，从而提高归类能力。GJR模块被附加到了多种深度卷积网络中，并在各种benchmark数据集上进行了广泛的测试，包括CIFAR-10、CIFAR-100/20、STL-10、ImageNet-10和ImageNetDog-15。然而，无监督图像归类中的收敛效率总是一个重要的挑战。最近，预训练的表征学习已经取得了很大的进步，释放出了许多高质量的视觉表示。可以看到，使用预训练模型作为特征提取器可以加速归类的收敛速度。我们的目标是提供一种新的视角，以及一种合理的资源应用，以提高图像归类的效果。此外，我们还创新了预训练基于Grid Jigsaw Representation（pGJR），通过改进GJR来提高归类效果。实验结果表明，pGJR在归类任务中对ACC、NMI和ARI三个 metric具有显著的效果，并且具有超快的收敛速度。
</details></li>
</ul>
<hr>
<h2 id="What-You-See-Is-What-You-Detect-Towards-better-Object-Densification-in-3D-detection"><a href="#What-You-See-Is-What-You-Detect-Towards-better-Object-Densification-in-3D-detection" class="headerlink" title="What You See Is What You Detect: Towards better Object Densification in 3D detection"></a>What You See Is What You Detect: Towards better Object Densification in 3D detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17842">http://arxiv.org/abs/2310.17842</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/orbis36/wysiwyd">https://github.com/orbis36/wysiwyd</a></li>
<li>paper_authors: Tianran Liu, Zeping Zhang Morteza Mousa Pasandi, Robert Laganiere</li>
<li>for: The paper is written for improving the accuracy of 3D object detection from Lidar signals, specifically addressing the issue of object completion in 3D perception.</li>
<li>methods: The paper proposes a visible part completion method that requires only a small number of prediction points, which is based on a mesh-deformation-based approach to augment the point set associated with visible foreground objects. The method consists of two parts: an Intra-Frustum Segmentation Transformer (IFST) and a Mesh Depth Completion Network(MDCNet).</li>
<li>results: The paper shows that the proposed method can provide up to 12.2% performance improvements over most of the public baseline models on the KITTI and NuScenes dataset, bringing the state-of-the-art to a new level.Here is the information in Simplified Chinese text:</li>
<li>for: 本文是为了提高三元素探测从激光信号中的准确性，特别是对三元素完成问题的解决。</li>
<li>methods: 本文提出了一种可见部分完成方法，只需要一小部分的预测点，基于 mesh 变形来增强可见前景对象的点集。该方法由两部分组成：内部 Frustum 分割 transformer (IFST) 和 mesh 深度完成网络 (MDCNet)。</li>
<li>results: 本文显示，提出的方法可以在 KITTI 和 NuScenes 数据集上提供最多 12.2% 的性能提升，将状态艺术带到新的水平。<details>
<summary>Abstract</summary>
Recent works have demonstrated the importance of object completion in 3D Perception from Lidar signal. Several methods have been proposed in which modules were used to densify the point clouds produced by laser scanners, leading to better recall and more accurate results. Pursuing in that direction, we present, in this work, a counter-intuitive perspective: the widely-used full-shape completion approach actually leads to a higher error-upper bound especially for far away objects and small objects like pedestrians. Based on this observation, we introduce a visible part completion method that requires only 11.3\% of the prediction points that previous methods generate. To recover the dense representation, we propose a mesh-deformation-based method to augment the point set associated with visible foreground objects. Considering that our approach focuses only on the visible part of the foreground objects to achieve accurate 3D detection, we named our method What You See Is What You Detect (WYSIWYD). Our proposed method is thus a detector-independent model that consists of 2 parts: an Intra-Frustum Segmentation Transformer (IFST) and a Mesh Depth Completion Network(MDCNet) that predicts the foreground depth from mesh deformation. This way, our model does not require the time-consuming full-depth completion task used by most pseudo-lidar-based methods. Our experimental evaluation shows that our approach can provide up to 12.2\% performance improvements over most of the public baseline models on the KITTI and NuScenes dataset bringing the state-of-the-art to a new level. The codes will be available at \textcolor[RGB]{0,0,255}{\url{https://github.com/Orbis36/WYSIWYD}
</details>
<details>
<summary>摘要</summary>
最近的研究表明3D感知从激光信号中的物体完成是非常重要的。许多方法已经被提出，其中包括使用模块来增强激光扫描仪生成的点云，从而提高精度和准确性。在这个方向下，我们在这项工作中提出了一个Counter-Intuitive Perspective：广泛使用的全形完成方法实际上会导致远距离物体和小物体（如人肉）的高错误上界。基于这一观察，我们引入可见部分完成方法，只需11.3%的预测点。为了恢复稠密表示，我们提议一种基于网格扭形的方法，用于补充可见前景物体的点集。由于我们的方法只关注可见前景物体来实现准确3D探测，因此我们将其命名为What You See Is What You Detect（WYSIWYD）。我们的提出的方法包括两部分：Intra-Frustum Segmentation Transformer（IFST）和Mesh Depth Completion Network（MDCNet），它们分别预测前景物体的深度和网格扭形。这样，我们的模型不需要时间consuming的全深度完成任务，与大多数 pseudo-lidar 基于的方法不同。我们的实验评估表明，我们的方法可以在 KITTI 和 NuScenes 数据集上提供Up to 12.2%的性能提升，将状态艺术引入到新的水平。代码将在 \textcolor[RGB]{0,0,255}{\url{https://github.com/Orbis36/WYSIWYD} 上提供。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/27/cs.CV_2023_10_27/" data-id="cloq1wl6000kp7o882fxl7zm5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/7/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/88/">88</a><a class="extend next" rel="next" href="/page/9/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
