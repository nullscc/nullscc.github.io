
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/47/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.AI_2023_08_30" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/30/cs.AI_2023_08_30/" class="article-date">
  <time datetime="2023-08-30T12:00:00.000Z" itemprop="datePublished">2023-08-30</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/30/cs.AI_2023_08_30/">cs.AI - 2023-08-30</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-General-Purpose-Self-Supervised-Model-for-Computational-Pathology"><a href="#A-General-Purpose-Self-Supervised-Model-for-Computational-Pathology" class="headerlink" title="A General-Purpose Self-Supervised Model for Computational Pathology"></a>A General-Purpose Self-Supervised Model for Computational Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15474">http://arxiv.org/abs/2308.15474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Richard J. Chen, Tong Ding, Ming Y. Lu, Drew F. K. Williamson, Guillaume Jaume, Bowen Chen, Andrew Zhang, Daniel Shao, Andrew H. Song, Muhammad Shaban, Mane Williams, Anurag Vaidya, Sharifa Sahai, Lukas Oldenburg, Luca L. Weishaupt, Judy J. Wang, Walt Williams, Long Phi Le, Georg Gerber, Faisal Mahmood</li>
<li>for: 本研究旨在提出一种通用的自助学习模型，用于解决生物病理学图像分类和诊断问题。</li>
<li>methods: 该模型使用了100万个各种组织类型的病理图像补充，并通过自助学习方法进行预训练。</li>
<li>results: 该模型在33种不同的临床任务中表现出色，包括分类、诊断和疾病类型划分等。此外，模型还能够在各种组织类型和诊断难度不同的情况下进行泛化和转移。<details>
<summary>Abstract</summary>
Tissue phenotyping is a fundamental computational pathology (CPath) task in learning objective characterizations of histopathologic biomarkers in anatomic pathology. However, whole-slide imaging (WSI) poses a complex computer vision problem in which the large-scale image resolutions of WSIs and the enormous diversity of morphological phenotypes preclude large-scale data annotation. Current efforts have proposed using pretrained image encoders with either transfer learning from natural image datasets or self-supervised pretraining on publicly-available histopathology datasets, but have not been extensively developed and evaluated across diverse tissue types at scale. We introduce UNI, a general-purpose self-supervised model for pathology, pretrained using over 100 million tissue patches from over 100,000 diagnostic haematoxylin and eosin-stained WSIs across 20 major tissue types, and evaluated on 33 representative CPath clinical tasks in CPath of varying diagnostic difficulties. In addition to outperforming previous state-of-the-art models, we demonstrate new modeling capabilities in CPath such as resolution-agnostic tissue classification, slide classification using few-shot class prototypes, and disease subtyping generalization in classifying up to 108 cancer types in the OncoTree code classification system. UNI advances unsupervised representation learning at scale in CPath in terms of both pretraining data and downstream evaluation, enabling data-efficient AI models that can generalize and transfer to a gamut of diagnostically-challenging tasks and clinical workflows in anatomic pathology.
</details>
<details>
<summary>摘要</summary>
组织现象评估是computational pathology（CPath）的基本任务，它的目标是通过学习标注组织生物marker的Objective characterizations，以帮助诊断医学。然而，整个标本影像（WSI）对于计算机视觉问题而言是一个复杂的问题，因为标本影像的大规模分辨率和丰富多样性的形态现象对于大规模标注数据的生成提供了一定的挑战。目前的努力已经提议使用预训归数图像Encoder， either transfer learning from natural image datasets or self-supervised pretraining on publicly-available histopathology datasets，但这些努力尚未得到了广泛的发展和评估。我们提出了UNI，一个通用的自主学习模型，预训使用了1000万个组织小图像，来自100000多个诊断HE染色标本影像，并在20个主要组织类型上进行了33个CPath临床任务的评估。此外，我们还展示了一些新的模型化能力，例如resolution-agnostic tissue classification、slides classification using few-shot class prototypes、和疾病分类对108种癌症的分类。UNI在CPath中进行了无监督学习的扩展，并在这些任务上实现了资料效率的AI模型，可以对诊断挑战性任务和临床工作流程进行普遍和转移。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Contrastive-Learning-and-Tabular-Attention-for-Automated-Alzheimer’s-Disease-Prediction"><a href="#Multimodal-Contrastive-Learning-and-Tabular-Attention-for-Automated-Alzheimer’s-Disease-Prediction" class="headerlink" title="Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer’s Disease Prediction"></a>Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer’s Disease Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15469">http://arxiv.org/abs/2308.15469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weichen Huang</li>
<li>for: 这个研究旨在开发一个多 modal 对照学习框架，以利用 MRI 扫描和 PET 等神经成像数据，并处理 AD 疾病数据中的值得注意的表格资料。</li>
<li>methods: 这个框架使用了一个新的表格注意模组，可以强调和排名表格中的重要特征。它还使用了多 modal 对照学习技术，以将图像和表格资料结合在一起。</li>
<li>results: 实验结果显示，这个框架可以从 ADNI 数据库中的逾 882 个 MRI 扫描标本中检测出 AD 疾病，并且可以实现高于 83.8% 的准确率，与前一代的州度优化技术相比，提高了约 10%。<details>
<summary>Abstract</summary>
Alongside neuroimaging such as MRI scans and PET, Alzheimer's disease (AD) datasets contain valuable tabular data including AD biomarkers and clinical assessments. Existing computer vision approaches struggle to utilize this additional information. To address these needs, we propose a generalizable framework for multimodal contrastive learning of image data and tabular data, a novel tabular attention module for amplifying and ranking salient features in tables, and the application of these techniques onto Alzheimer's disease prediction. Experimental evaulations demonstrate the strength of our framework by detecting Alzheimer's disease (AD) from over 882 MR image slices from the ADNI database. We take advantage of the high interpretability of tabular data and our novel tabular attention approach and through attribution of the attention scores for each row of the table, we note and rank the most predominant features. Results show that the model is capable of an accuracy of over 83.8%, almost a 10% increase from previous state of the art.
</details>
<details>
<summary>摘要</summary>
alongside neuroimaging such as MRI scans and PET, Alzheimer's disease (AD) datasets contain valuable tabular data including AD biomarkers and clinical assessments. Existing computer vision approaches struggle to utilize this additional information. To address these needs, we propose a generalizable framework for multimodal contrastive learning of image data and tabular data, a novel tabular attention module for amplifying and ranking salient features in tables, and the application of these techniques onto Alzheimer's disease prediction. Experimental evaulations demonstrate the strength of our framework by detecting Alzheimer's disease (AD) from over 882 MR image slices from the ADNI database. We take advantage of the high interpretability of tabular data and our novel tabular attention approach and through attribution of the attention scores for each row of the table, we note and rank the most predominant features. Results show that the model is capable of an accuracy of over 83.8%, almost a 10% increase from previous state of the art.Here's the translation in Traditional Chinese:附加了脑成像技术，如MRI扫描和PET，Alzheimer病（AD）数据集包含重要的表格资料，包括AD标识和临床评估。现有的计算机视觉方法对这些额外资讯难以使用。为解决这些需求，我们提出了一个通用的多modal对比学习框架，一个新的表格注意模组，以强调和排名表格中的重要特征。我们还应用了这些技术 onto Alzheimer病预测。实验评估显示了我们的框架在ADNI数据库中的882个MRI图像探针中检测到Alzheimer病的能力，比前一代的state of the art约10%高。我们利用表格资料的高解释性和我们的新的表格注意方法，通过每行表格中的注意分数汇总，发现和排名表格中的最主要特征。结果显示模型可以达到83.8%的精度，比前一代的state of the art约10%高。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Loss-Functions-Traffic-Predictions-in-Regular-and-Congestion-Scenarios"><a href="#A-Comparative-Study-of-Loss-Functions-Traffic-Predictions-in-Regular-and-Congestion-Scenarios" class="headerlink" title="A Comparative Study of Loss Functions: Traffic Predictions in Regular and Congestion Scenarios"></a>A Comparative Study of Loss Functions: Traffic Predictions in Regular and Congestion Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15464">http://arxiv.org/abs/2308.15464</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xieyangxinyu/a-comparative-study-of-loss-functions-traffic-predictions-in-regular-and-congestion-scenarios">https://github.com/xieyangxinyu/a-comparative-study-of-loss-functions-traffic-predictions-in-regular-and-congestion-scenarios</a></li>
<li>paper_authors: Yangxinyu Xie, Tanwi Mallick</li>
<li>for: 这 paper 的目的是提高深度学习模型在交通预测中的精度，特别是预测堵塞情况。</li>
<li>methods: 这 paper 使用了多种积分函数，包括 MAE-Focal Loss 和 Gumbel Loss，来解决传统损失函数的局限性。</li>
<li>results: 经过大规模实验，这 paper 发现 MAE-Focal Loss 和 Gumbel Loss 在预测交通速度方面具有最高效果，能够准确预测堵塞情况而不会妨碍正常交通预测。<details>
<summary>Abstract</summary>
Spatiotemporal graph neural networks have achieved state-of-the-art performance in traffic forecasting. However, they often struggle to forecast congestion accurately due to the limitations of traditional loss functions. While accurate forecasting of regular traffic conditions is crucial, a reliable AI system must also accurately forecast congestion scenarios to maintain safe and efficient transportation. In this paper, we explore various loss functions inspired by heavy tail analysis and imbalanced classification problems to address this issue. We evaluate the efficacy of these loss functions in forecasting traffic speed, with an emphasis on congestion scenarios. Through extensive experiments on real-world traffic datasets, we discovered that when optimizing for Mean Absolute Error (MAE), the MAE-Focal Loss function stands out as the most effective. When optimizing Mean Squared Error (MSE), Gumbel Loss proves to be the superior choice. These choices effectively forecast traffic congestion events without compromising the accuracy of regular traffic speed forecasts. This research enhances deep learning models' capabilities in forecasting sudden speed changes due to congestion and underscores the need for more research in this direction. By elevating the accuracy of congestion forecasting, we advocate for AI systems that are reliable, secure, and resilient in practical traffic management scenarios.
</details>
<details>
<summary>摘要</summary>
现代交通预测中使用的空间时间图 neural network 已经达到了领先的性能水平。然而，它们经常因传统的损失函数的局限性而难以准确预测堵塞情况。尽管正确预测常规交通情况是非常重要，但一个可靠的 AI 系统也必须准确预测堵塞场景，以保证安全和高效的交通运输。在这篇论文中，我们探讨了各种启发自重态分析和不均衡分类问题的损失函数，以解决这一问题。我们对这些损失函数在预测交通速度方面的效果进行了广泛的实验，发现了使用 MAE-Focal Loss 函数时，MAE 函数在预测堵塞场景中表现最佳。使用 MSE 函数时，Gumbel Loss 函数表现最佳。这些选择可以准确预测交通堵塞事件，不会 compromise 正常交通速度预测的准确性。这项研究提高了深度学习模型在预测快速变化的能力，并强调了对堵塞预测的需求。我们认为，通过提高堵塞预测的准确性，可以建立可靠、安全、可靠的 AI 系统，以满足实际交通管理场景中的需求。
</details></li>
</ul>
<hr>
<h2 id="ParaGuide-Guided-Diffusion-Paraphrasers-for-Plug-and-Play-Textual-Style-Transfer"><a href="#ParaGuide-Guided-Diffusion-Paraphrasers-for-Plug-and-Play-Textual-Style-Transfer" class="headerlink" title="ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer"></a>ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15459">http://arxiv.org/abs/2308.15459</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zacharyhorvitz/ParaGuide">https://github.com/zacharyhorvitz/ParaGuide</a></li>
<li>paper_authors: Zachary Horvitz, Ajay Patel, Chris Callison-Burch, Zhou Yu, Kathleen McKeown</li>
<li>for: 文章的目的是将文本的风格特征转换为新的风格，保留 semantic information。</li>
<li>methods: 本研究使用了一个新的扩散基础架构，叫做 ParaGuide，可以灵活地适应任意目标风格。这个方法使用了句子重写条件下的扩散模型，以及Gradient-based guidance from both off-the-shelf classifiers和强大的现有风格嵌入。</li>
<li>results: 研究在Enron Email Corpus上进行了人工和自动评估，和强大的基eline均以上。它可以成功地将文本的风格转换为新的风格，保留 semantic information。<details>
<summary>Abstract</summary>
Textual style transfer is the task of transforming stylistic properties of text while preserving meaning. Target "styles" can be defined in numerous ways, ranging from single attributes (e.g, formality) to authorship (e.g, Shakespeare). Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models. In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time. Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information. We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, sentiment, and even authorship style transfer.
</details>
<details>
<summary>摘要</summary>
文本风格转换是将文本的风格属性转换为另一种风格的任务，保持意义不变。目标风格可以定义为多种方式，从单一特征（例如正式度）到作者（例如莎士比亚）。前一代无监督风格转换方法通常需要大量标注数据，仅适用于固定的风格集或需要大型语言模型。相比之下，我们介绍了一种新的扩散基于框架，可以通过扩散模型来实现通用风格转换，并在推理时适应任意目标风格。我们的参数有效的方法， ParaGuide，利用了句子重构conditional扩散模型，并与梯度导航从存储类фика器和强有力的现有风格编码器来转换文本的风格，保持 semantic information。我们在恩рон电子邮件集上验证了该方法，并与人类和自动评估表明，它在正式度、情感和作者风格转换方面超过了强大基eline。
</details></li>
</ul>
<hr>
<h2 id="From-SMOTE-to-Mixup-for-Deep-Imbalanced-Classification"><a href="#From-SMOTE-to-Mixup-for-Deep-Imbalanced-Classification" class="headerlink" title="From SMOTE to Mixup for Deep Imbalanced Classification"></a>From SMOTE to Mixup for Deep Imbalanced Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15457">http://arxiv.org/abs/2308.15457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ntucllab/imbalanced-dl">https://github.com/ntucllab/imbalanced-dl</a></li>
<li>paper_authors: Wei-Chao Cheng, Tan-Ha Mai, Hsuan-Tien Lin</li>
<li>for: 本研究旨在探讨深度学习中对异质数据的处理方法，尤其是SMOTE数据增强技术是否有利于深度学习。</li>
<li>methods: 本研究使用了SMOTE技术，以及其扩展版本——软标签SMOTE和混合技术。</li>
<li>results: 研究发现，通过将SMOTE和混合技术结合使用，可以提高深度学习模型的泛化性能，并且在极端异质数据上达到最佳性能。<details>
<summary>Abstract</summary>
Given imbalanced data, it is hard to train a good classifier using deep learning because of the poor generalization of minority classes. Traditionally, the well-known synthetic minority oversampling technique (SMOTE) for data augmentation, a data mining approach for imbalanced learning, has been used to improve this generalization. However, it is unclear whether SMOTE also benefits deep learning. In this work, we study why the original SMOTE is insufficient for deep learning, and enhance SMOTE using soft labels. Connecting the resulting soft SMOTE with Mixup, a modern data augmentation technique, leads to a unified framework that puts traditional and modern data augmentation techniques under the same umbrella. A careful study within this framework shows that Mixup improves generalization by implicitly achieving uneven margins between majority and minority classes. We then propose a novel margin-aware Mixup technique that more explicitly achieves uneven margins. Extensive experimental results demonstrate that our proposed technique yields state-of-the-art performance on deep imbalanced classification while achieving superior performance on extremely imbalanced data. The code is open-sourced in our developed package https://github.com/ntucllab/imbalanced-DL to foster future research in this direction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="When-Do-Program-of-Thoughts-Work-for-Reasoning"><a href="#When-Do-Program-of-Thoughts-Work-for-Reasoning" class="headerlink" title="When Do Program-of-Thoughts Work for Reasoning?"></a>When Do Program-of-Thoughts Work for Reasoning?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15452">http://arxiv.org/abs/2308.15452</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zjunlp/easyinstruct">https://github.com/zjunlp/easyinstruct</a></li>
<li>paper_authors: Zhen Bi, Ningyu Zhang, Yinuo Jiang, Shumin Deng, Guozhou Zheng, Huajun Chen</li>
<li>for: 本研究旨在探讨 Large Language Models (LLMs) 在肢体人工智能领域的逻辑能力如何提高，以及程序语言的影响。</li>
<li>methods: 本研究提出了一种 complexity-impacted reasoning score (CIRS)，用于衡量程序语言的结构和逻辑特性对逻辑能力的影响。CIRS 使用抽象树来编码结构信息，并通过考虑困难性和环状复杂性来计算逻辑复杂性。</li>
<li>results: 研究发现，不同的程序数据复杂性会影响 LLMS 的逻辑能力提升。优化的复杂度是关键的，程序帮助提示可以提高逻辑能力。研究还提出了一种自动生成和分级算法，并应用于数学逻辑和代码生成任务。广泛的结果表明了我们的提出的方法的有效性。<details>
<summary>Abstract</summary>
The reasoning capabilities of Large Language Models (LLMs) play a pivotal role in the realm of embodied artificial intelligence. Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning tasks, the specific impact of code data on the improvement of reasoning capabilities remains under-explored. To address this gap, we propose complexity-impacted reasoning score (CIRS), which combines structural and logical attributes, to measure the correlation between code and reasoning abilities. Specifically, we use the abstract syntax tree to encode the structural information and calculate logical complexity by considering the difficulty and the cyclomatic complexity. Through an empirical analysis, we find not all code data of complexity can be learned or understood by LLMs. Optimal level of complexity is critical to the improvement of reasoning abilities by program-aided prompting. Then we design an auto-synthesizing and stratifying algorithm, and apply it to instruction generation for mathematical reasoning and code data filtering for code generation tasks. Extensive results demonstrates the effectiveness of our proposed approach. Code will be integrated into the EasyInstruct framework at https://github.com/zjunlp/EasyInstruct.
</details>
<details>
<summary>摘要</summary>
LLMs的逻辑能力在人工智能中扮演着关键性角色。虽有有效的程序激活提示法 для LLMs，但代码数据对复杂逻辑任务的改进仍然未得到足够的探讨。为解决这个空白，我们提出了复杂性影响逻辑能力指数（CIRS），它将结构性和逻辑性特征相结合，用于衡量代码数据对逻辑能力的相关性。我们使用抽象树来编码结构信息，并根据难度和 cyclomatic complexity来计算逻辑复杂性。经 empirical 分析发现，不 всех复杂度的代码数据可以被 LLMS 学习或理解。优质的复杂度是关键的，以便通过程序帮助提示来提高逻辑能力。然后，我们设计了自动生成和分配算法，并应用它到数学逻辑和代码生成任务中。广泛的结果表明了我们的提出的方法的有效性。代码将会被集成到 EasyInstruct 框架中，可以在 <https://github.com/zjunlp/EasyInstruct> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Complementing-Onboard-Sensors-with-Satellite-Map-A-New-Perspective-for-HD-Map-Construction"><a href="#Complementing-Onboard-Sensors-with-Satellite-Map-A-New-Perspective-for-HD-Map-Construction" class="headerlink" title="Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction"></a>Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15427">http://arxiv.org/abs/2308.15427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjie Gao, Jiawei Fu, Haodong Jing, Nanning Zheng</li>
<li>for: 提高自动驾驶系统中的高清晰地图建构方法的性能，使其更敏感于废弃环境。</li>
<li>methods: 补充车载感知器上的信息使用卫星地图，提高HD地图建构方法的性能。提出一种层次融合模块，通过Feature级别融合和BEV级别融合来实现卫星地图信息的更好融合。</li>
<li>results: 在扩展nuScenes数据集上，证明了我们的模块可以准确地融合到现有的HD地图建构方法中，提高其在HD地图Semantic segmentation和实例检测任务中的性能。<details>
<summary>Abstract</summary>
High-Definition (HD) maps play a crucial role in autonomous driving systems. Recent methods have attempted to construct HD maps in real-time based on information obtained from vehicle onboard sensors. However, the performance of these methods is significantly susceptible to the environment surrounding the vehicle due to the inherent limitation of onboard sensors, such as weak capacity for long-range detection. In this study, we demonstrate that supplementing onboard sensors with satellite maps can enhance the performance of HD map construction methods, leveraging the broad coverage capability of satellite maps. For the purpose of further research, we release the satellite map tiles as a complementary dataset of nuScenes dataset. Meanwhile, we propose a hierarchical fusion module that enables better fusion of satellite maps information with existing methods. Specifically, we design an attention mask based on segmentation and distance, applying the cross-attention mechanism to fuse onboard Bird's Eye View (BEV) features and satellite features in feature-level fusion. An alignment module is introduced before concatenation in BEV-level fusion to mitigate the impact of misalignment between the two features. The experimental results on the augmented nuScenes dataset showcase the seamless integration of our module into three existing HD map construction methods. It notably enhances their performance in both HD map semantic segmentation and instance detection tasks.
</details>
<details>
<summary>摘要</summary>
高清定义（HD）地图在自动驾驶系统中扮演着关键角色。现有方法尝试在实时基础上构建HD地图，但这些方法的性能受周围环境的影响很大，因为搭载在车辆上的感知器件具有较弱的远程探测能力。在本研究中，我们发现可以通过补充搭载在车辆上的感知器件与卫星地图的信息来提高HD地图构建方法的性能。为进一步研究，我们释放了卫星地图块作为nuScenes数据集的补充数据集。此外，我们提议了一种层次融合模块，使得更好地融合卫星地图信息与现有方法。具体来说，我们设计了一个基于分割和距离的注意mask，通过交叉注意机制来融合搭载在 Bird's Eye View（BEV）上的特征和卫星特征在特征层融合。在BEV层融合之前，我们引入了一个对齐模块，以mitigate卫星特征和BEV特征之间的偏移的影响。实验结果表明，我们的模块可以覆盖现有的三种HD地图构建方法，并在HD地图semantic segmentation和实例检测任务中显著提高其性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/30/cs.AI_2023_08_30/" data-id="clohum90j002tpj888hnvaudn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_30" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/30/cs.CL_2023_08_30/" class="article-date">
  <time datetime="2023-08-30T11:00:00.000Z" itemprop="datePublished">2023-08-30</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/30/cs.CL_2023_08_30/">cs.CL - 2023-08-30</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Vulgar-Remarks-Detection-in-Chittagonian-Dialect-of-Bangla"><a href="#Vulgar-Remarks-Detection-in-Chittagonian-Dialect-of-Bangla" class="headerlink" title="Vulgar Remarks Detection in Chittagonian Dialect of Bangla"></a>Vulgar Remarks Detection in Chittagonian Dialect of Bangla</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15448">http://arxiv.org/abs/2308.15448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanjim Mahmud, Michal Ptaszynski, Fumito Masui</li>
<li>for: 本研究旨在探讨社交媒体上的负面言语 automatic detection方法，尤其是在低资源语言如锡兰语方言上。</li>
<li>methods: 本研究使用了指导学习和深度学习算法来检测社交媒体上的侮辱言语。Logistic Regression实现了可观的准确率（0.91），而简单的RNN具有Word2vec和fastTex的组合实现了较低的准确率（0.84-0.90），这说明了NN算法需要更多的数据。</li>
<li>results: 本研究显示，使用指导学习和深度学习算法可以准确地检测社交媒体上的侮辱言语，但是NN算法需要更多的数据以实现更高的准确率。<details>
<summary>Abstract</summary>
The negative effects of online bullying and harassment are increasing with Internet popularity, especially in social media. One solution is using natural language processing (NLP) and machine learning (ML) methods for the automatic detection of harmful remarks, but these methods are limited in low-resource languages like the Chittagonian dialect of Bangla.This study focuses on detecting vulgar remarks in social media using supervised ML and deep learning algorithms.Logistic Regression achieved promising accuracy (0.91) while simple RNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the issue that NN algorithms require more data.
</details>
<details>
<summary>摘要</summary>
互联网欺凌和 Harrasment 的负面影响随着互联网的普及而增加，尤其在社交媒体上。一种解决方案是使用自然语言处理（NLP）和机器学习（ML）方法进行自动发现危险评论，但这些方法在低资源语言如锡兰语的拼写方言上有限。本研究关注社交媒体中的粗鄙评论使用监督式 ML 和深度学习算法探测。Logistic Regression 达到了可靠的准确率（0.91），而简单的 RNN 与 Word2vec 和 fastTex 的准确率（0.84-0.90）较低，表明 NN 算法需要更多的数据。
</details></li>
</ul>
<hr>
<h2 id="Characterizing-Learning-Curves-During-Language-Model-Pre-Training-Learning-Forgetting-and-Stability"><a href="#Characterizing-Learning-Curves-During-Language-Model-Pre-Training-Learning-Forgetting-and-Stability" class="headerlink" title="Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability"></a>Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15419">http://arxiv.org/abs/2308.15419</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tylerachang/lm-learning-curves">https://github.com/tylerachang/lm-learning-curves</a></li>
<li>paper_authors: Tyler A. Chang, Zhuowen Tu, Benjamin K. Bergen</li>
<li>for: 这些语言模型在预训练中学习的问题是什么？</li>
<li>methods: 这些语言模型在预训练中使用了什么方法？</li>
<li>results: 这些语言模型在预训练中得到了什么结果？Here are the answers in Simplified Chinese text:</li>
<li>for: 这些语言模型在预训练中学习的问题是如何快速预测语言模型的性能？</li>
<li>methods: 这些语言模型在预训练中使用了自适应语言模型的预训练方法？</li>
<li>results: 这些语言模型在预训练中得到了快速预测语言模型的稳定性和性能？<details>
<summary>Abstract</summary>
How do language models learn to make predictions during pre-training? To study this question, we extract learning curves from five autoregressive English language model pre-training runs, for 1M tokens in context. We observe that the language models generate short repetitive phrases before learning to generate longer and more coherent text. We quantify the final surprisal, within-run variability, age of acquisition, forgettability, and cross-run variability of learning curves for individual tokens in context. More frequent tokens reach lower final surprisals, exhibit less variability within and across pre-training runs, are learned earlier, and are less likely to be "forgotten" during pre-training. Higher n-gram probabilities further accentuate these effects. Independent of the target token, shorter and more frequent contexts correlate with marginally more stable and quickly acquired predictions. Effects of part-of-speech are also small, although nouns tend to be acquired later and less stably than verbs, adverbs, and adjectives. Our work contributes to a better understanding of language model pre-training dynamics and informs the deployment of stable language models in practice.
</details>
<details>
<summary>摘要</summary>
<<SYS>>我们使用五个权重autoregressive英语语言模型的预训练运行来研究语言模型如何预测。我们从100万个字Context中提取学习曲线，并观察到语言模型在预训练过程中首先生成短重复的短语，然后学习 longer和更 coherent的文本。我们量化每个Token在Context中的最终难度、内Run变化、年龄 acquisition、忘记性和 Cross-Run变化。我们发现更常见的Token在Context中更容易预测， exhibit less variability within和across预训练运行，learn Earlier，并更可能被"忘记" during预训练。高 n-gram概率更加强调这些效果。独立于目标Token，更短和更频繁的Contexts呈现marginally more stable and quickly acquired预测。 parts of speech的影响也很小，although nouns tend to be acquired later and less stably than verbs, adverbs, and adjectives。我们的工作对语言模型预训练动力学的更好理解，并可以帮助实践中稳定地部署语言模型。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/30/cs.CL_2023_08_30/" data-id="clohum954009spj88gzvl6elk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_30" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/30/cs.LG_2023_08_30/" class="article-date">
  <time datetime="2023-08-30T10:00:00.000Z" itemprop="datePublished">2023-08-30</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/30/cs.LG_2023_08_30/">cs.LG - 2023-08-30</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Policy-composition-in-reinforcement-learning-via-multi-objective-policy-optimization"><a href="#Policy-composition-in-reinforcement-learning-via-multi-objective-policy-optimization" class="headerlink" title="Policy composition in reinforcement learning via multi-objective policy optimization"></a>Policy composition in reinforcement learning via multi-objective policy optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15470">http://arxiv.org/abs/2308.15470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shruti Mishra, Ankit Anand, Jordan Hoffmann, Nicolas Heess, Martin Riedmiller, Abbas Abdolmaleki, Doina Precup</li>
<li>for: 本研究旨在使用相关的先进教学策略来帮助强化学习代理人学习成功的行为策略。</li>
<li>methods: 本研究使用了多目标策略优化算法（Multi-Objective Maximum a Posteriori Policy Optimization，简称MOPPO），其中包括任务目标以及教学策略作为多个目标。</li>
<li>results: 研究表明，在继续使用教学策略的情况下，强化学习代理人可以更快速地学习任务，特别是在缺乏形成奖励的情况下。在连续观察和动作空间的两个领域中，我们的代理人成功地组合了教学策略序列和并行，并能够进一步扩展教学策略以解决任务。<details>
<summary>Abstract</summary>
We enable reinforcement learning agents to learn successful behavior policies by utilizing relevant pre-existing teacher policies. The teacher policies are introduced as objectives, in addition to the task objective, in a multi-objective policy optimization setting. Using the Multi-Objective Maximum a Posteriori Policy Optimization algorithm \citep{abdolmaleki2020distributional}, we show that teacher policies can help speed up learning, particularly in the absence of shaping rewards. In two domains with continuous observation and action spaces, our agents successfully compose teacher policies in sequence and in parallel, and are also able to further extend the policies of the teachers in order to solve the task.   Depending on the specified combination of task and teacher(s), teacher(s) may naturally act to limit the final performance of an agent. The extent to which agents are required to adhere to teacher policies are determined by hyperparameters which determine both the effect of teachers on learning speed and the eventual performance of the agent on the task. In the {\tt humanoid} domain \citep{deepmindcontrolsuite2018}, we also equip agents with the ability to control the selection of teachers. With this ability, agents are able to meaningfully compose from the teacher policies to achieve a superior task reward on the {\tt walk} task than in cases without access to the teacher policies. We show the resemblance of composed task policies with the corresponding teacher policies through videos.
</details>
<details>
<summary>摘要</summary>
我们使用已有的教师策略来帮助权威学习代理人学习成功行为策略。教师策略被引入为目标之一，同时与任务目标一起使用多目标策略优化算法 \citep{abdolmaleki2020distributional}。我们在连续观察和动作空间的两个领域中表示，我们的代理人可以成功组合教师策略并且可以进一步扩展教师策略以解决任务。在指定的任务和教师的组合下，教师可能会自然地限制代理人的最终表现。代理人需要遵循教师策略的程度由参数决定，这些参数不仅影响代理人学习速度，还影响代理人在任务上的最终表现。在{\tt humanoid}领域 \citep{deepmindcontrolsuite2018}中，我们还让代理人控制选择教师的能力。通过这种能力，代理人能够有意义地从教师策略中组合任务策略，在{\tt walk}任务上比不使用教师策略的情况下更好的完成任务。我们通过视频显示，组合的任务策略与相应的教师策略之间的相似性。
</details></li>
</ul>
<hr>
<h2 id="Random-feature-approximation-for-general-spectral-methods"><a href="#Random-feature-approximation-for-general-spectral-methods" class="headerlink" title="Random feature approximation for general spectral methods"></a>Random feature approximation for general spectral methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15434">http://arxiv.org/abs/2308.15434</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mike Nguyen, Nicole Mücke</li>
<li>for: 本文研究了大规模算法中使用权重方法的减速技术，以及深度神经网络的分析方法。</li>
<li>methods: 本文使用了随机特征approximation技术，并对权重方法进行了分析。</li>
<li>results: 本文对权重方法的泛化性质进行了研究，并在不同的常数空间中获得了优化的学习率。<details>
<summary>Abstract</summary>
Random feature approximation is arguably one of the most popular techniques to speed up kernel methods in large scale algorithms and provides a theoretical approach to the analysis of deep neural networks. We analyze generalization properties for a large class of spectral regularization methods combined with random features, containing kernel methods with implicit regularization such as gradient descent or explicit methods like Tikhonov regularization. For our estimators we obtain optimal learning rates over regularity classes (even for classes that are not included in the reproducing kernel Hilbert space), which are defined through appropriate source conditions. This improves or completes previous results obtained in related settings for specific kernel algorithms.
</details>
<details>
<summary>摘要</summary>
随机特征近似是大规模算法中最受欢迎的技术之一，它提供了对深度神经网络的分析理论方法。我们分析了一大类spectral regularization方法，包括梯度下降或特ikhonov regularization等kernel方法，其中的泛化性质得到了改进或完善。我们的估计器可以在不同的常数类型下获得最佳学习速率，这些常数类型包括 reproduce kernel Hilbert space以外的类型。这些结果与之前在相关的设置中获得的结果相匹配或完善。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-solar-flare-forecasting-using-historical-magnetogram-data"><a href="#Probabilistic-solar-flare-forecasting-using-historical-magnetogram-data" class="headerlink" title="Probabilistic solar flare forecasting using historical magnetogram data"></a>Probabilistic solar flare forecasting using historical magnetogram data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.15410">http://arxiv.org/abs/2308.15410</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/swri-idea-lab/idea-lab-flare-forecast">https://github.com/swri-idea-lab/idea-lab-flare-forecast</a></li>
<li>paper_authors: Kiera van der Sande, Andrés Muñoz-Jaramillo, Subhamoy Chatterjee</li>
<li>for: 这个论文旨在利用机器学习技术预测太阳风暴。</li>
<li>methods: 这篇论文使用了卷积神经网络提取全天磁图像的特征，并将这些特征与磁图像和风暴历史信息相结合，使用了逻辑回归模型生成可カリibrated的风暴预测。</li>
<li>results: 包括历史数据在内的多种仪器的日常磁图像数据可以提高预测的准确性和可靠性，磁图像单一帧不含 significatively更多有用信息，而风暴历史信息比我们提取的磁图像特征更具预测力。<details>
<summary>Abstract</summary>
Solar flare forecasting research using machine learning (ML) has focused on high resolution magnetogram data from the SDO/HMI era covering Solar Cycle 24 and the start of Solar Cycle 25, with some efforts looking back to SOHO/MDI for data from Solar Cycle 23. In this paper, we consider over 4 solar cycles of daily historical magnetogram data from multiple instruments. This is the first attempt to take advantage of this historical data for ML-based flare forecasting. We apply a convolutional neural network (CNN) to extract features from full-disk magnetograms together with a logistic regression model to incorporate scalar features based on magnetograms and flaring history. We use an ensemble approach to generate calibrated probabilistic forecasts of M-class or larger flares in the next 24 hours. Overall, we find that including historical data improves forecasting skill and reliability. We show that single frame magnetograms do not contain significantly more relevant information than can be summarized in a small number of scalar features, and that flaring history has greater predictive power than our CNN-extracted features. This indicates the importance of including temporal information in flare forecasting models.
</details>
<details>
<summary>摘要</summary>
太阳风暴预测研究使用机器学习（ML）专注于高分辨率磁场图像从SDO/HMI时期的太阳周期24和太阳周期25之前的一些努力，也有一些努力回到SOHO/MDI上的数据。在这篇论文中，我们考虑了4个太阳周期的日常历史磁场数据从多个仪器。这是第一次利用历史数据为ML-基于的太阳风暴预测。我们使用卷积神经网络（CNN）提取磁场图像的特征，并将磁场图像和风暴历史中的一些缺失特征加以逻辑回归模型。我们使用一个集成方法生成标准化的可信度预测M级或大于M级太阳风暴在下一个24小时内发生。总的来说，我们发现包含历史数据可以提高预测技巧和可靠性。我们显示单个帧磁场图像不含有足够重要的信息，而风暴历史更有预测力量。这表明包含时间信息在太阳风暴预测模型中是非常重要的。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/30/cs.LG_2023_08_30/" data-id="clohum99g00nhpj88bfj05ti9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_29" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/29/cs.CV_2023_08_29/" class="article-date">
  <time datetime="2023-08-29T13:00:00.000Z" itemprop="datePublished">2023-08-29</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/29/cs.CV_2023_08_29/">cs.CV - 2023-08-29</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-Discovery-and-Effective-Evaluation-of-Visual-Perceptual-Similarity-A-Benchmark-and-Beyond"><a href="#Efficient-Discovery-and-Effective-Evaluation-of-Visual-Perceptual-Similarity-A-Benchmark-and-Beyond" class="headerlink" title="Efficient Discovery and Effective Evaluation of Visual Perceptual Similarity: A Benchmark and Beyond"></a>Efficient Discovery and Effective Evaluation of Visual Perceptual Similarity: A Benchmark and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14753">http://arxiv.org/abs/2308.14753</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vsd-benchmark/vsd">https://github.com/vsd-benchmark/vsd</a></li>
<li>paper_authors: Oren Barkan, Tal Reiss, Jonathan Weill, Ori Katz, Roy Hirsch, Itzik Malkiel, Noam Koenigstein</li>
<li>for: 该论文的目的是提出一个大规模的时尚视觉相似性数据集，以及一种有效的标签过程，以便评估视觉相似性检测方法。</li>
<li>methods: 该论文使用了专业注释的图像对进行标签，并提出了一种新的标签过程，可以应用于任何数据集。</li>
<li>results: 该论文提出了一个大规模的时尚视觉相似性数据集，并进行了对该数据集的分析和评估。Here’s the full text in Simplified Chinese:</li>
<li>for: 该论文的目的是提出一个大规模的时尚视觉相似性数据集，以及一种有效的标签过程，以便评估视觉相似性检测方法。</li>
<li>methods: 该论文使用了专业注释的图像对进行标签，并提出了一种新的标签过程，可以应用于任何数据集。</li>
<li>results: 该论文提出了一个大规模的时尚视觉相似性数据集，并进行了对该数据集的分析和评估。<details>
<summary>Abstract</summary>
Visual similarities discovery (VSD) is an important task with broad e-commerce applications. Given an image of a certain object, the goal of VSD is to retrieve images of different objects with high perceptual visual similarity. Although being a highly addressed problem, the evaluation of proposed methods for VSD is often based on a proxy of an identification-retrieval task, evaluating the ability of a model to retrieve different images of the same object. We posit that evaluating VSD methods based on identification tasks is limited, and faithful evaluation must rely on expert annotations. In this paper, we introduce the first large-scale fashion visual similarity benchmark dataset, consisting of more than 110K expert-annotated image pairs. Besides this major contribution, we share insight from the challenges we faced while curating this dataset. Based on these insights, we propose a novel and efficient labeling procedure that can be applied to any dataset. Our analysis examines its limitations and inductive biases, and based on these findings, we propose metrics to mitigate those limitations. Though our primary focus lies on visual similarity, the methodologies we present have broader applications for discovering and evaluating perceptual similarity across various domains.
</details>
<details>
<summary>摘要</summary>
<SYS>文本翻译为简化字符串。</SYS>视觉相似性发现（VSD）是一项广泛应用于电子商务的重要任务。给定一个对象的图像，VSD的目标是检索具有高度感知视觉相似性的不同对象的图像。尽管是一个已经受到广泛关注的问题，但评估提出的VSD方法的方法通常基于一种对象预测任务的代理，评估模型是否可以正确地检索不同的对象图像。我们认为，基于预测任务进行评估VSD方法有限制，我们应该依靠专家注释来进行 faithful 评估。在这篇文章中，我们发布了首个大规模的时尚视觉相似性准 benchmark 数据集，包含 более 110K 专家注释的图像对。此外，我们还分享了在编 Curate 这个数据集时遇到的挑战，并提出了一种新的和高效的标签过程，可以应用于任何数据集。我们的分析检查了这些限制和偏好，并基于这些发现，我们提出了一些缓解这些限制的度量。虽然我们的主要焦点是视觉相似性，但我们所提出的方法ologies 有更广泛的应用于发现和评估不同领域中的感知相似性。
</details></li>
</ul>
<hr>
<h2 id="MagicEdit-High-Fidelity-and-Temporally-Coherent-Video-Editing"><a href="#MagicEdit-High-Fidelity-and-Temporally-Coherent-Video-Editing" class="headerlink" title="MagicEdit: High-Fidelity and Temporally Coherent Video Editing"></a>MagicEdit: High-Fidelity and Temporally Coherent Video Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14749">http://arxiv.org/abs/2308.14749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Hao Liew, Hanshu Yan, Jianfeng Zhang, Zhongcong Xu, Jiashi Feng</li>
<li>for: 这个论文是为了解决文本引导视频编辑任务而写的。</li>
<li>methods: 这个论文使用了分离内容、结构和动作信号的方法来在训练中学习高效的视频-to-视频翻译。</li>
<li>results: 论文表明，这种方法可以实现高精度和时间协调的视频翻译，并且支持多种下游视频编辑任务，如视频 стилизация、本地编辑、视频MagicMix和视频填充。<details>
<summary>Abstract</summary>
In this report, we present MagicEdit, a surprisingly simple yet effective solution to the text-guided video editing task. We found that high-fidelity and temporally coherent video-to-video translation can be achieved by explicitly disentangling the learning of content, structure and motion signals during training. This is in contradict to most existing methods which attempt to jointly model both the appearance and temporal representation within a single framework, which we argue, would lead to degradation in per-frame quality. Despite its simplicity, we show that MagicEdit supports various downstream video editing tasks, including video stylization, local editing, video-MagicMix and video outpainting.
</details>
<details>
<summary>摘要</summary>
在这份报告中，我们介绍MagicEdit，一种高效且简单的解决文本引导视频编辑问题的解决方案。我们发现，在训练中分离内容、结构和运动信号的学习可以实现高精度和时间启示的视频-to-视频翻译。这与大多数现有方法不同，这些方法尝试同时模型视频的外观和时间表示，我们认为这会导致每帧质量下降。尽管简单，我们显示MagicEdit支持多种下渠视频编辑任务，包括视频风格化、本地编辑、MagicMix和视频外缩。
</details></li>
</ul>
<hr>
<h2 id="MagicAvatar-Multimodal-Avatar-Generation-and-Animation"><a href="#MagicAvatar-Multimodal-Avatar-Generation-and-Animation" class="headerlink" title="MagicAvatar: Multimodal Avatar Generation and Animation"></a>MagicAvatar: Multimodal Avatar Generation and Animation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14748">http://arxiv.org/abs/2308.14748</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/magic-research/magic-avatar">https://github.com/magic-research/magic-avatar</a></li>
<li>paper_authors: Jianfeng Zhang, Hanshu Yan, Zhongcong Xu, Jiashi Feng, Jun Hao Liew</li>
<li>for: 这个论文旨在提出一种基于多模态视频生成和人偶动画的框架，即 MagicAvatar。</li>
<li>methods: 这个框架包括两个阶段：第一个阶段是将多模态输入翻译成动作&#x2F;控制信号（例如人姿、深度、DensePose），第二个阶段是根据这些动作信号生成人偶视频。</li>
<li>results: MagicAvatar可以通过提供一些人的图像来animate人偶，并且可以实现文本指导和视频指导的人偶生成。此外，它还可以应用于多模态人偶动画。<details>
<summary>Abstract</summary>
This report presents MagicAvatar, a framework for multimodal video generation and animation of human avatars. Unlike most existing methods that generate avatar-centric videos directly from multimodal inputs (e.g., text prompts), MagicAvatar explicitly disentangles avatar video generation into two stages: (1) multimodal-to-motion and (2) motion-to-video generation. The first stage translates the multimodal inputs into motion/ control signals (e.g., human pose, depth, DensePose); while the second stage generates avatar-centric video guided by these motion signals. Additionally, MagicAvatar supports avatar animation by simply providing a few images of the target person. This capability enables the animation of the provided human identity according to the specific motion derived from the first stage. We demonstrate the flexibility of MagicAvatar through various applications, including text-guided and video-guided avatar generation, as well as multimodal avatar animation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Multimodal-to-motion: Translating the multimodal inputs into motion&#x2F;control signals (e.g., human pose, depth, DensePose).2. Motion-to-video generation: Generating avatar-centric video guided by these motion signals.Moreover, MagicAvatar supports avatar animation by simply providing a few images of the target person. This capability enables the animation of the provided human identity according to the specific motion derived from the first stage. We demonstrate the flexibility of MagicAvatar through various applications, including text-guided and video-guided avatar generation, as well as multimodal avatar animation.中文翻译：这份报告介绍了 MagicAvatar，一个用于多模态视频生成和人物动画的框架。与大多数现有方法不同，MagicAvatarexplicitly归纳了人物视频生成到两个阶段：1. 多模态到动作：将多模态输入翻译成动作&#x2F;控制信号（例如人姿、深度、DensePose）。2. 动作到视频生成：根据这些动作信号生成人物视频。此外，MagicAvatar还支持人物动画，只需提供一些目标人物的图像即可。这使得可以根据第一阶段得到的特定动作来动画提供的人物。我们通过多种应用，包括文本指导和视频指导的人物生成以及多模态人物动画，展示了MagicAvatar的灵活性。</details></li>
</ol>
<hr>
<h2 id="CoVR-Learning-Composed-Video-Retrieval-from-Web-Video-Captions"><a href="#CoVR-Learning-Composed-Video-Retrieval-from-Web-Video-Captions" class="headerlink" title="CoVR: Learning Composed Video Retrieval from Web Video Captions"></a>CoVR: Learning Composed Video Retrieval from Web Video Captions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14746">http://arxiv.org/abs/2308.14746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lucas-ventura/CoVR">https://github.com/lucas-ventura/CoVR</a></li>
<li>paper_authors: Lucas Ventura, Antoine Yang, Cordelia Schmid, Gül Varol</li>
<li>for: 这篇论文的目的是提出一种可扩展的自动生成compose Image Retrieval（CoIR）数据集方法，以替代手动纪录CoIR triplets的高成本和不可扩展性。</li>
<li>methods: 该方法利用了视频-caption对的对应关系，并采用了大型自然语言模型来生成修改文本。</li>
<li>results: 通过应用该方法于WebVid2M数据集，自动生成了160万个CoIR triplets，并提出了一个新的CoVR数据集和一个手动注解的评估集。实验表明，训练CoVR模型在我们的数据集上可以有效转移到CoIR，在零基eline设置下在CIRR和FashionIQ数据集上达到了最佳性能。<details>
<summary>Abstract</summary>
Composed Image Retrieval (CoIR) has recently gained popularity as a task that considers both text and image queries together, to search for relevant images in a database. Most CoIR approaches require manually annotated datasets, comprising image-text-image triplets, where the text describes a modification from the query image to the target image. However, manual curation of CoIR triplets is expensive and prevents scalability. In this work, we instead propose a scalable automatic dataset creation methodology that generates triplets given video-caption pairs, while also expanding the scope of the task to include composed video retrieval (CoVR). To this end, we mine paired videos with a similar caption from a large database, and leverage a large language model to generate the corresponding modification text. Applying this methodology to the extensive WebVid2M collection, we automatically construct our WebVid-CoVR dataset, resulting in 1.6 million triplets. Moreover, we introduce a new benchmark for CoVR with a manually annotated evaluation set, along with baseline results. Our experiments further demonstrate that training a CoVR model on our dataset effectively transfers to CoIR, leading to improved state-of-the-art performance in the zero-shot setup on both the CIRR and FashionIQ benchmarks. Our code, datasets, and models are publicly available at https://imagine.enpc.fr/~ventural/covr.
</details>
<details>
<summary>摘要</summary>
团体图像检索（CoIR）在最近几年内得到了广泛关注，因为它同时考虑图像和文本查询，以搜索图像库中相关的图像。大多数CoIR方法需要手动标注数据集，包括图像-文本-图像三元组，其中文本描述了查询图像到目标图像的修改。然而，手动筛选CoIR三元组是贵重的并不可扩展。在这种情况下，我们提议一种可扩展的自动数据创建方法，使用视频-标题对进行生成三元组，同时扩展CoIR任务的范围，以包括组合视频检索（CoVR）。为此，我们从大量视频库中挖掘具有相同标题的视频对，并利用大型自然语言模型生成相应的修改文本。通过应用这种方法，我们自动建立了WebVid-CoVR数据集，共计1600万三元组。此外，我们还提供了一个手动标注的评估集，以及基准结果。我们的实验表明，训练CoVR模型于我们的数据集后，可以转移到CoIR任务，在零例情况下在CIRR和FashionIQ benchmark上实现了状态的推进性表现。我们的代码、数据集和模型都公开提供在https://imagine.enpc.fr/~ventural/covr。
</details></li>
</ul>
<hr>
<h2 id="Total-Selfie-Generating-Full-Body-Selfies"><a href="#Total-Selfie-Generating-Full-Body-Selfies" class="headerlink" title="Total Selfie: Generating Full-Body Selfies"></a>Total Selfie: Generating Full-Body Selfies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14740">http://arxiv.org/abs/2308.14740</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bowei Chen, Brian Curless, Ira Kemelmacher-Shlizerman, Steve Seitz</li>
<li>for: 生成全身自拍照（用户提供的视频、目标姿势照片和每个位置的自拍照+背景对）</li>
<li>methods:  diffusion-based 方法组合这些信息生成高质量、正确pose和背景的全身自拍照</li>
<li>results: 生成高品质、自然的全身自拍照，包括用户所需的姿势和背景<details>
<summary>Abstract</summary>
We present a method to generate full-body selfies -- photos that you take of yourself, but capturing your whole body as if someone else took the photo of you from a few feet away. Our approach takes as input a pre-captured video of your body, a target pose photo, and a selfie + background pair for each location. We introduce a novel diffusion-based approach to combine all of this information into high quality, well-composed photos of you with the desired pose and background.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，可以生成全身自拍照片。这种方法使用已经捕捉的视频、目标姿势照片和每个位置的自拍+背景对。我们提出了一种新的扩散方法，可以将这些信息组合成高质量、正确姿势和背景的全身自拍照片。
</details></li>
</ul>
<hr>
<h2 id="R3D3-Dense-3D-Reconstruction-of-Dynamic-Scenes-from-Multiple-Cameras"><a href="#R3D3-Dense-3D-Reconstruction-of-Dynamic-Scenes-from-Multiple-Cameras" class="headerlink" title="R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras"></a>R3D3: Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14713">http://arxiv.org/abs/2308.14713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aron Schmied, Tobias Fischer, Martin Danelljan, Marc Pollefeys, Fisher Yu<br>for:多camera系统提供了一个简单且便宜的选择，但是实现实时三维重建和自己运动估计的挑战非常大。methods:我们提出了R3D3，一个多camera系统，它通过调合几何推导和单目深度精准化，实现了紧密的三维重建和自己运动估计。results:我们的设计能够在充满活动的外部环境中实现紧密、一致的三维重建，并在DDAD和NuScenes参考数据集上实现了状态顶尖的紧密深度预测。<details>
<summary>Abstract</summary>
Dense 3D reconstruction and ego-motion estimation are key challenges in autonomous driving and robotics. Compared to the complex, multi-modal systems deployed today, multi-camera systems provide a simpler, low-cost alternative. However, camera-based 3D reconstruction of complex dynamic scenes has proven extremely difficult, as existing solutions often produce incomplete or incoherent results. We propose R3D3, a multi-camera system for dense 3D reconstruction and ego-motion estimation. Our approach iterates between geometric estimation that exploits spatial-temporal information from multiple cameras, and monocular depth refinement. We integrate multi-camera feature correlation and dense bundle adjustment operators that yield robust geometric depth and pose estimates. To improve reconstruction where geometric depth is unreliable, e.g. for moving objects or low-textured regions, we introduce learnable scene priors via a depth refinement network. We show that this design enables a dense, consistent 3D reconstruction of challenging, dynamic outdoor environments. Consequently, we achieve state-of-the-art dense depth prediction on the DDAD and NuScenes benchmarks.
</details>
<details>
<summary>摘要</summary>
dense 3D 重建和自己运动估算是autéonomous driving 和机器人控制中的关键挑战。相比较复杂的多Modal 系统，多摄像头系统提供了一个简单、低成本的替代方案。然而，基于多摄像头的3D 重建复杂动态场景已经证明是非常困难，因为现有的解决方案通常会生成不完整或不一致的结果。我们提出了 R3D3，一个多摄像头系统用于精密3D 重建和自己运动估算。我们的方法在多摄像头的空间-时间信息上进行几何估算，并使用单摄像头的深度精度优化。我们将多摄像头特征相关和紧凑缓冲调整算法相结合，以获得强健的几何深度和pose估算。为了改进重建，特别是对于在运动 объек 或低文纹区域的情况，我们引入了学习场景假设。我们显示，这种设计可以实现高精度、一致的3D 重建，并在复杂的户外环境中达到了状态 искусственный智能 的 dense depth prediction  benchmarks。
</details></li>
</ul>
<hr>
<h2 id="360-Degree-Panorama-Generation-from-Few-Unregistered-NFoV-Images"><a href="#360-Degree-Panorama-Generation-from-Few-Unregistered-NFoV-Images" class="headerlink" title="360-Degree Panorama Generation from Few Unregistered NFoV Images"></a>360-Degree Panorama Generation from Few Unregistered NFoV Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14686">http://arxiv.org/abs/2308.14686</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shanemankiw/panodiff">https://github.com/shanemankiw/panodiff</a></li>
<li>paper_authors: Jionghao Wang, Ziyu Chen, Jun Ling, Rong Xie, Li Song</li>
<li>for: 生成完整的360度全景图像</li>
<li>methods: 使用一或多个不准确地捕捉的窄视场图像，以及文本提示和几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几yles in Simplified Chinese text:</li>
<li>for: 生成完整的360度全景图像</li>
<li>methods: 使用一或多个不准确地捕捉的窄视场图像，以及文本提示和几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几种几ypes几种几种几种几种几种几ypes几种几种几种几ypes几种几种几Types几种几Types几种几Types几种几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types几Types�<details>
<summary>Abstract</summary>
360$^\circ$ panoramas are extensively utilized as environmental light sources in computer graphics. However, capturing a 360$^\circ$ $\times$ 180$^\circ$ panorama poses challenges due to the necessity of specialized and costly equipment, and additional human resources. Prior studies develop various learning-based generative methods to synthesize panoramas from a single Narrow Field-of-View (NFoV) image, but they are limited in alterable input patterns, generation quality, and controllability. To address these issues, we propose a novel pipeline called PanoDiff, which efficiently generates complete 360$^\circ$ panoramas using one or more unregistered NFoV images captured from arbitrary angles. Our approach has two primary components to overcome the limitations. Firstly, a two-stage angle prediction module to handle various numbers of NFoV inputs. Secondly, a novel latent diffusion-based panorama generation model uses incomplete panorama and text prompts as control signals and utilizes several geometric augmentation schemes to ensure geometric properties in generated panoramas. Experiments show that PanoDiff achieves state-of-the-art panoramic generation quality and high controllability, making it suitable for applications such as content editing.
</details>
<details>
<summary>摘要</summary>
“360度全景图是计算机图形中广泛应用的环境光源。然而，捕捉360度×180度全景图受到特殊设备和人工资源的限制。先前的研究已经开发了基于学习的生成方法，以synthesize全景图从单个镜头视场（NFoV）图像中，但它们受到输入模式的局限性、生成质量和可控性的限制。为了解决这些问题，我们提出了一个新的渠道 called PanoDiff，它能够高效地使用一个或多个不准确的NFoV图像，从任意角度捕捉到完整的360度全景图。我们的方法包括两个主要组成部分：首先，一个两stage的角度预测模块，可以处理不同数量的NFoV输入。其次，一种新的扩散增强的全景图生成模型，使用部分全景图和文本提示作为控制信号，并使用多种几何增强方案来保证生成的全景图具备几何性质。实验表明，PanoDiff可以实现状态最佳的全景图生成质量和高可控性，适用于内容编辑等应用。”
</details></li>
</ul>
<hr>
<h2 id="Video-Based-Hand-Pose-Estimation-for-Remote-Assessment-of-Bradykinesia-in-Parkinson’s-Disease"><a href="#Video-Based-Hand-Pose-Estimation-for-Remote-Assessment-of-Bradykinesia-in-Parkinson’s-Disease" class="headerlink" title="Video-Based Hand Pose Estimation for Remote Assessment of Bradykinesia in Parkinson’s Disease"></a>Video-Based Hand Pose Estimation for Remote Assessment of Bradykinesia in Parkinson’s Disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14679">http://arxiv.org/abs/2308.14679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriela T. Acevedo Trebbau, Andrea Bandini, Diego L. Guarin</li>
<li>for: 这个研究旨在检验pose estimation算法是否能够在视频流服务中进行远程PD评估和监测。</li>
<li>methods: 研究使用了7种商业可用的手势估计模型来估计视频中手部的运动。</li>
<li>results: 结果显示，在本地记录的视频中，3种模型表现良好，而在视频流服务中记录的视频中，模型的准确率显著下降。研究还发现，视频流服务中的运动速度和模型准确率之间存在负相关性。<details>
<summary>Abstract</summary>
There is a growing interest in using pose estimation algorithms for video-based assessment of Bradykinesia in Parkinson's Disease (PD) to facilitate remote disease assessment and monitoring. However, the accuracy of pose estimation algorithms in videos from video streaming services during Telehealth appointments has not been studied. In this study, we used seven off-the-shelf hand pose estimation models to estimate the movement of the thumb and index fingers in videos of the finger-tapping (FT) test recorded from Healthy Controls (HC) and participants with PD and under two different conditions: streaming (videos recorded during a live Zoom meeting) and on-device (videos recorded locally with high-quality cameras). The accuracy and reliability of the models were estimated by comparing the models' output with manual results. Three of the seven models demonstrated good accuracy for on-device recordings, and the accuracy decreased significantly for streaming recordings. We observed a negative correlation between movement speed and the model's accuracy for the streaming recordings. Additionally, we evaluated the reliability of ten movement features related to bradykinesia extracted from video recordings of PD patients performing the FT test. While most of the features demonstrated excellent reliability for on-device recordings, most of the features demonstrated poor to moderate reliability for streaming recordings. Our findings highlight the limitations of pose estimation algorithms when applied to video recordings obtained during Telehealth visits, and demonstrate that on-device recordings can be used for automatic video-assessment of bradykinesia in PD.
</details>
<details>
<summary>摘要</summary>
有越来越多的关注使用pose estimation算法来评估基于视频的PD患者的静止症状评估和监测。然而，在视频流服务中使用pose estimation算法的准确性尚未被研究。本研究使用了七种市售手势估计模型来估计视频中的手指 thumb和index fingers的运动。我们使用了HC和PD患者在两种不同条件下录制的视频：流程（在live Zoom会议中录制的视频）和本地（使用高质量摄像头录制的视频）。我们将模型的准确性和可靠性与手动结果进行比较。三种模型在本地录制下表现良好，而流程录制下的准确性显著降低。我们发现视频录制中运动速度与模型的准确性之间存在负相关性。此外，我们评估了PD患者在执行FT测试时录制的视频中关于静止症状的10种运动特征的可靠性。大多数特征在本地录制下表现出色，而流程录制下大多数特征表现为亮度到中度的可靠性。我们的发现表明在Telehealth访问中使用pose estimation算法进行自动视频评估的难度，并且可以使用本地录制来实现更高的准确性和可靠性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/29/cs.CV_2023_08_29/" data-id="clohum97c00grpj884kf5atoy" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_29" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/29/cs.AI_2023_08_29/" class="article-date">
  <time datetime="2023-08-29T12:00:00.000Z" itemprop="datePublished">2023-08-29</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/29/cs.AI_2023_08_29/">cs.AI - 2023-08-29</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AI-Deception-A-Survey-of-Examples-Risks-and-Potential-Solutions"><a href="#AI-Deception-A-Survey-of-Examples-Risks-and-Potential-Solutions" class="headerlink" title="AI Deception: A Survey of Examples, Risks, and Potential Solutions"></a>AI Deception: A Survey of Examples, Risks, and Potential Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14752">http://arxiv.org/abs/2308.14752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter S. Park, Simon Goldstein, Aidan O’Gara, Michael Chen, Dan Hendrycks</li>
<li>For: 这篇论文主要探讨了现代人工智能系统是如何骗取人类信任的现象。* Methods: 论文首先是通过对现有的AI骗局例子进行概述，然后讨论了特定的AI系统（如Meta的CICERO）和通用AI系统（如大语言模型）如何骗取人类信任。* Results: 论文指出了AI骗局可能导致的一些风险，如诈骗、选举干预和AI系统控制失败等问题，并提出了一些解决这些问题的可能性，如实施robust风险评估要求、实施“机器人或者人”法律和重视相关研究，包括检测AI骗局和使AI系统更加不骗取人类信任的工具。<details>
<summary>Abstract</summary>
This paper argues that a range of current AI systems have learned how to deceive humans. We define deception as the systematic inducement of false beliefs in the pursuit of some outcome other than the truth. We first survey empirical examples of AI deception, discussing both special-use AI systems (including Meta's CICERO) built for specific competitive situations, and general-purpose AI systems (such as large language models). Next, we detail several risks from AI deception, such as fraud, election tampering, and losing control of AI systems. Finally, we outline several potential solutions to the problems posed by AI deception: first, regulatory frameworks should subject AI systems that are capable of deception to robust risk-assessment requirements; second, policymakers should implement bot-or-not laws; and finally, policymakers should prioritize the funding of relevant research, including tools to detect AI deception and to make AI systems less deceptive. Policymakers, researchers, and the broader public should work proactively to prevent AI deception from destabilizing the shared foundations of our society.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Regulatory frameworks should subject AI systems capable of deception to rigorous risk assessments.2. Policymakers should implement “bot-or-not” laws to distinguish between human and AI-generated content.3. Policymakers should prioritize funding for research on AI deception detection and making AI systems less deceptive.We urge policymakers, researchers, and the public to work together to prevent AI deception from undermining the foundations of our society.</details></li>
</ol>
<hr>
<h2 id="Flexible-Techniques-for-Differentiable-Rendering-with-3D-Gaussians"><a href="#Flexible-Techniques-for-Differentiable-Rendering-with-3D-Gaussians" class="headerlink" title="Flexible Techniques for Differentiable Rendering with 3D Gaussians"></a>Flexible Techniques for Differentiable Rendering with 3D Gaussians</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14737">http://arxiv.org/abs/2308.14737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonid Keselman, Martial Hebert</li>
<li>for: 快速、可靠的形状重建是计算机视觉应用中的关键组成部分。神经辐射场示示了高品质新视图合成可能性，但是受到实际场景和物体快速重建的性能要求受限。</li>
<li>methods: 本文提出了基于 altenative 形状表示的新方法，包括使用可导流动、导出水密网格和按照光栅方向渲染每个光栅。此外，我们还证明了两种最近的方法之间的互操作性。</li>
<li>results: 我们的扩展方法可以快速、稳定地进行形状重建，并且可以在GPU或CPU上进行执行。codes和视觉示例可以在<a target="_blank" rel="noopener" href="https://leonidk.github.io/fmb-plus%E6%89%BE%E5%88%B0%E3%80%82">https://leonidk.github.io/fmb-plus找到。</a><details>
<summary>Abstract</summary>
Fast, reliable shape reconstruction is an essential ingredient in many computer vision applications. Neural Radiance Fields demonstrated that photorealistic novel view synthesis is within reach, but was gated by performance requirements for fast reconstruction of real scenes and objects. Several recent approaches have built on alternative shape representations, in particular, 3D Gaussians. We develop extensions to these renderers, such as integrating differentiable optical flow, exporting watertight meshes and rendering per-ray normals. Additionally, we show how two of the recent methods are interoperable with each other. These reconstructions are quick, robust, and easily performed on GPU or CPU. For code and visual examples, see https://leonidk.github.io/fmb-plus
</details>
<details>
<summary>摘要</summary>
快速可靠的形状重建是许多计算机视觉应用程序的关键组成部分。神经辐射场示示了高真实度新视图合成可能性，但是它受到快速重建真实场景和物体的性能要求限制。数据recent approaches have built on alternative shape representations, in particular, 3D Gaussians. We develop extensions to these renderers, such as integrating differentiable optical flow, exporting watertight meshes, and rendering per-ray normals. Additionally, we show how two of the recent methods are interoperable with each other. These reconstructions are quick, robust, and easily performed on GPU or CPU. For code and visual examples, see <https://leonidk.github.io/fmb-plus>Here's the breakdown of the translation:* 快速可靠的形状重建 (fast and reliable shape reconstruction)* 是许多计算机视觉应用程序的关键组成部分 (is an essential ingredient in many computer vision applications)* 神经辐射场示示了高真实度新视图合成可能性 (Neural Radiance Fields demonstrated the possibility of high-fidelity novel view synthesis)* 但是它受到快速重建真实场景和物体的性能要求限制 (but was gated by performance requirements for fast reconstruction of real scenes and objects)* 数据recent approaches have built on alternative shape representations, in particular, 3D Gaussians (recent methods have focused on alternative shape representations, such as 3D Gaussians)* We develop extensions to these renderers (we develop extensions to these methods)* such as integrating differentiable optical flow (including differentiable optical flow)* exporting watertight meshes (exporting watertight meshes)* and rendering per-ray normals (and rendering per-ray normals)* Additionally, we show how two of the recent methods are interoperable with each other (additionally, we show how two of the recent methods can be combined)* These reconstructions are quick, robust, and easily performed on GPU or CPU (these reconstructions are fast, robust, and can be performed easily on GPU or CPU)* For code and visual examples, see <https://leonidk.github.io/fmb-plus> (for code and visual examples, see <https://leonidk.github.io/fmb-plus>)
</details></li>
</ul>
<hr>
<h2 id="Bayesian-artificial-brain-with-ChatGPT"><a href="#Bayesian-artificial-brain-with-ChatGPT" class="headerlink" title="Bayesian artificial brain with ChatGPT"></a>Bayesian artificial brain with ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14732">http://arxiv.org/abs/2308.14732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renato A. Krohling</li>
<li>for: 这个论文是为了研究 chatGPT 在概率理解方面的数学问题解决能力。</li>
<li>methods: 这个研究使用了 Zhu &amp; Gigerenzer 在 2006 年的研究，对 10 个概率理解问题进行了测试。</li>
<li>results: 结果显示，ChatGPT 能够 correctly 解决所有 10 个问题。<details>
<summary>Abstract</summary>
This paper aims to investigate the mathematical problem-solving capabilities of Chat Generative Pre-Trained Transformer (ChatGPT) in case of Bayesian reasoning. The study draws inspiration from Zhu & Gigerenzer's research in 2006, which posed the question: Can children reason the Bayesian way? In the pursuit of answering this question, a set of 10 Bayesian reasoning problems were presented. The results of their work revealed that children's ability to reason effectively using Bayesian principles is contingent upon a well-structured information representation. In this paper, we present the same set of 10 Bayesian reasoning problems to ChatGPT. Remarkably, the results demonstrate that ChatGPT provides the right solutions to all problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Distilled-GPT-for-Source-Code-Summarization"><a href="#Distilled-GPT-for-Source-Code-Summarization" class="headerlink" title="Distilled GPT for Source Code Summarization"></a>Distilled GPT for Source Code Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14731">http://arxiv.org/abs/2308.14731</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apcl-research/jam-cgpt">https://github.com/apcl-research/jam-cgpt</a></li>
<li>paper_authors: Chia-Yi Su, Collin McMillan</li>
<li>for: 这个论文的目的是提出一种可以在单个16GHz GPU上运行的开源模型，以便自动生成代码摘要，而不需要将代码发送到不受信任的第三方服务器上。</li>
<li>methods: 该论文使用了一种基于大语言模型的方法，通过知识储存的过程来训练一个小型的开源模型，以便模拟GPT-3.5的功能。</li>
<li>results: 论文的评估结果表明，该模型可以准确地生成代码摘要，并且可以在单个16GHz GPU上运行。<details>
<summary>Abstract</summary>
A code summary is a brief natural language description of source code. Summaries are usually only a single sentence long, and yet form the backbone of developer documentation. A short descriptions such as "changes all visible polygons to the color blue" can give a programmer a high-level idea of what code does without the effort of reading the code itself. Recently, products based on Large Language Models such as ChatGPT have demonstrated a strong ability to write these descriptions automatically. However, to use these tools, programmers must send their code to untrusted third parties for processing (e.g., via an API call). This loss of custody is not acceptable to many organizations. In this paper, we present an alternative: we train an open source model using sample output generated by GPT-3.5 in a process related to knowledge distillation. Our model is small enough (350m parameters) to be run on a single 16gb GPU, yet we show in our evaluation that it is large enough to mimic GPT-3.5 on this task.
</details>
<details>
<summary>摘要</summary>
code summary 是一个简短的自然语言描述，描述源代码的功能。这些描述通常只是一句话长，但是它们成为开发者文档的基础。例如，"改变所有可见的多边形为蓝色" 可以给程序员提供高级别的理解，不需要阅读代码本身。现在，基于大语言模型的产品，如 ChatGPT，已经显示出自动生成这些描述的能力。然而，使用这些工具，程序员必须将代码传递给不可靠的第三方进行处理（例如，通过 API 调用）。这种失去控制不acceptable  для多个组织。在这篇论文中，我们提出一种代替方案：我们使用一个开源模型，使用 GPT-3.5 生成的样本输出进行训练。我们的模型具有 350 万参数，可以在单个 16 GB GPU 上运行，而我们的评估表明，它可以模拟 GPT-3.5 在这个任务上。
</details></li>
</ul>
<hr>
<h2 id="PanoSwin-a-Pano-style-Swin-Transformer-for-Panorama-Understanding"><a href="#PanoSwin-a-Pano-style-Swin-Transformer-for-Panorama-Understanding" class="headerlink" title="PanoSwin: a Pano-style Swin Transformer for Panorama Understanding"></a>PanoSwin: a Pano-style Swin Transformer for Panorama Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14726">http://arxiv.org/abs/2308.14726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhixin Ling, Zhen Xing, Xiangdong Zhou, Manliang Cao, Guichun Zhou</li>
<li>for: 提高panorama理解能力</li>
<li>methods: 使用狭窄窗口卷积和投影注意力来解决equirectangular projection中的边界缺失和空间扭曲问题，同时采用绝对位坐标嵌入和相对位坐标偏移来增强panoramic geometry信息。</li>
<li>results: 在多种panoramic任务上（包括panoramic object detection、panoramic classification和panoramic layout estimation）实现了比领先方法更高的性能。<details>
<summary>Abstract</summary>
In panorama understanding, the widely used equirectangular projection (ERP) entails boundary discontinuity and spatial distortion. It severely deteriorates the conventional CNNs and vision Transformers on panoramas. In this paper, we propose a simple yet effective architecture named PanoSwin to learn panorama representations with ERP. To deal with the challenges brought by equirectangular projection, we explore a pano-style shift windowing scheme and novel pitch attention to address the boundary discontinuity and the spatial distortion, respectively. Besides, based on spherical distance and Cartesian coordinates, we adapt absolute positional embeddings and relative positional biases for panoramas to enhance panoramic geometry information. Realizing that planar image understanding might share some common knowledge with panorama understanding, we devise a novel two-stage learning framework to facilitate knowledge transfer from the planar images to panoramas. We conduct experiments against the state-of-the-art on various panoramic tasks, i.e., panoramic object detection, panoramic classification, and panoramic layout estimation. The experimental results demonstrate the effectiveness of PanoSwin in panorama understanding.
</details>
<details>
<summary>摘要</summary>
在панोра姆理解方面，广泛使用的Equirectangular Projection（ERP）会导致边界缺continuity和空间扭曲。这会严重损害传统的CNN和vision Transformers在пан姆上的性能。在这篇论文中，我们提出了一种简单又有效的架构名为PanoSwin，用于学习pan姆表示。为了处理ERP所带来的挑战，我们研究了一种pano-style shift windowing scheme和novel pitch attention来解决边界缺continuity和空间扭曲问题。此外，基于球面距离和Cartesian坐标，我们采用绝对位域嵌入和相对位域偏好来增强pan姆的几何信息。由于平面图像理解可能与pan姆理解共享一些共同知识，我们设计了一种新的两Stage学习框架，以便从平面图像中传输知识到pan姆。我们对各种pan姆任务进行了实验，包括pan姆 объек检测、pan姆分类和pan姆布局估计。实验结果表明PanoSwin在pan姆理解方面的效果。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Time-Series-Forecasting-with-Bayesian-Modeling"><a href="#Hierarchical-Time-Series-Forecasting-with-Bayesian-Modeling" class="headerlink" title="Hierarchical Time Series Forecasting with Bayesian Modeling"></a>Hierarchical Time Series Forecasting with Bayesian Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14719">http://arxiv.org/abs/2308.14719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gal Elgavish</li>
<li>for: 这个论文主要针对时间序列分析中的预测任务，即在不约束的情况下做出有用的决策。</li>
<li>methods: 该论文提出了一种分布式预测方法，即在不同层次结构中训练独立的预测模型，并将这些模型传递给一种重新调整算法以改进预测结果。</li>
<li>results: 该论文通过synthetic和实际数据集的实验表明，分布式预测方法可以提高预测的准确性，并且可以与其他相关的研究作品进行比较。<details>
<summary>Abstract</summary>
We encounter time series data in many domains such as finance, physics, business, and weather. One of the main tasks of time series analysis, one that helps to take informed decisions under uncertainty, is forecasting. Time series are often hierarchically structured, e.g., a company sales might be broken down into different regions, and each region into different stores. In some cases the number of series in the hierarchy is too big to fit in a single model to produce forecasts in relevant time, and a decentralized approach is beneficial.   One way to do this is to train independent forecasting models for each series and for some summary statistics series implied by the hierarchy (e.g. the sum of all series) and to pass those models to a reconciliation algorithm to improve those forecasts by sharing information between the series.   In this work we focus on the reconciliation step, and propose a method to do so from a Bayesian perspective - Bayesian forecast reconciliation. We also define the common case of linear Gaussian reconciliation, where the forecasts are Gaussian and the hierarchy has linear structure, and show that we can compute reconciliation in closed form. We evaluate these methods on synthetic and real data sets, and compare them to other work in this field.
</details>
<details>
<summary>摘要</summary>
我们在各个领域，如金融、物理、商业和天气中都可以找到时间序列数据。时间序列分析的一个主要任务是预测，帮助在不确定的情况下做出了解的决策。时间序列经常具有层次结构，例如一家公司的销售可能分解为不同的区域和每个区域的不同的店铺。在某些情况下，序列的数量太多，不能准确地预测，这时一种分布式方法是有利的。我们在这种情况下提出了一种方法，即训练独立的预测模型 для每个序列和某些层次统计量（例如所有序列的总和），然后将这些模型传递给一个协调算法以提高预测。在这篇文章中，我们关注协调步骤，并从泛函视角出发提出了一种bayesian预测协调方法。我们还定义了常见的线性 Gaussian 协调情况，其中预测是 Gaussian 分布，序列层次结构是线性的，并且可以在关闭式形式内计算协调。我们在 sintetic 和实际数据集上评估了这些方法，并与其他相关研究进行比较。
</details></li>
</ul>
<hr>
<h2 id="Fast-Feedforward-Networks"><a href="#Fast-Feedforward-Networks" class="headerlink" title="Fast Feedforward Networks"></a>Fast Feedforward Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14711">http://arxiv.org/abs/2308.14711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pbelcak/fastfeedforward">https://github.com/pbelcak/fastfeedforward</a></li>
<li>paper_authors: Peter Belcak, Roger Wattenhofer</li>
<li>for: 提高层SIZE与计算成本之间的非线性关系，并提供一种快速的替代方案。</li>
<li>methods: 引入快速推导（FFF）架构，其运行时间与 feedforward 网络相似，但计算成本呈尖峰式增长。</li>
<li>results: 比较 feedforward 网络和混合专家网络，FFF 在计算成本下降了5.8%的性能，并且可以轻松地替换 transformers。<details>
<summary>Abstract</summary>
We break the linear link between the layer size and its inference cost by introducing the fast feedforward (FFF) architecture, a logarithmic-time alternative to feedforward networks.   We show that FFFs give comparable performance to feedforward networks at an exponential fraction of their inference cost, are quicker to deliver performance compared to mixture-of-expert networks, and can readily take the place of either in transformers.   Pushing FFFs to the absolute limit, we train a vision transformer to perform single-neuron inferences at the cost of only 5.8% performance decrease against the full-width variant.   Our implementation is available as a Python package; just use "pip install fastfeedforward".
</details>
<details>
<summary>摘要</summary>
我们打破层Size和推论成本之间的直线关系，通过引入快速feedforward（FFF）架构，实现了对数时间的替代方案。我们显示，FFFs可以与传统 feedforward 网络比较，具有相似的性能，并且在推论过程中更快速地获得结果，而且可以轻松地取代混合专家网络。我们在推展FFFs的最大限度下，将视觉 трансформа获得单 neuron 推论的成本，与全宽版本相对只需要5.8%的性能损失。我们的实现可以通过 pip 安装 fastfeedforward  packages。
</details></li>
</ul>
<hr>
<h2 id="VideoCutLER-Surprisingly-Simple-Unsupervised-Video-Instance-Segmentation"><a href="#VideoCutLER-Surprisingly-Simple-Unsupervised-Video-Instance-Segmentation" class="headerlink" title="VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation"></a>VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14710">http://arxiv.org/abs/2308.14710</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/cutler">https://github.com/facebookresearch/cutler</a></li>
<li>paper_authors: Xudong Wang, Ishan Misra, Ziyun Zeng, Rohit Girdhar, Trevor Darrell</li>
<li>For: The paper is written for unsupervised video instance segmentation, which is a challenging task that requires identifying and tracking multiple objects in a video sequence without any labeled data.* Methods: The paper proposes a simple method called VideoCutLER, which uses high-quality pseudo masks and a simple video synthesis method to train a video model that can effectively segment and track multiple instances across video frames.* Results: The paper achieves competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, surpassing the previous state-of-the-art by a large margin. Specifically, the paper achieves 50.7% APvideo^50 and exceeds DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo.Here’s the information in Simplified Chinese text:</li>
<li>for: 该 paper 是为了解决无监督视频实例分割问题，这是一个非常困难的任务，需要在视频序列中识别和跟踪多个对象，而无需任何标注数据。</li>
<li>methods: 该 paper 提出了一种简单的方法，即 VideoCutLER，它使用高质量的 Pseudo 面Mask 和简单的视频合成方法来训练一个视频模型，能够有效地 segment 和跟踪多个实例 Across 视频帧。</li>
<li>results: 该 paper 在 YouTubeVIS-2019 benchmark 上 achieve 竞争性的无监督学习结果，大幅超过之前的状态泰施，具体来说是 50.7% APvideo^50 和 exceeds DINO 在 YouTubeVIS-2019 上的 APvideo 指标上。<details>
<summary>Abstract</summary>
Existing approaches to unsupervised video instance segmentation typically rely on motion estimates and experience difficulties tracking small or divergent motions. We present VideoCutLER, a simple method for unsupervised multi-instance video segmentation without using motion-based learning signals like optical flow or training on natural videos. Our key insight is that using high-quality pseudo masks and a simple video synthesis method for model training is surprisingly sufficient to enable the resulting video model to effectively segment and track multiple instances across video frames. We show the first competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, achieving 50.7% APvideo^50 , surpassing the previous state-of-the-art by a large margin. VideoCutLER can also serve as a strong pretrained model for supervised video instance segmentation tasks, exceeding DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo.
</details>
<details>
<summary>摘要</summary>
Traditional unsupervised video instance segmentation methods usually rely on motion estimates and have difficulty tracking small or divergent motions. We propose VideoCutLER, a simple method for unsupervised multi-instance video segmentation without using motion-based learning signals like optical flow or training on natural videos. Our key insight is that using high-quality pseudo masks and a simple video synthesis method for model training is surprisingly sufficient to enable the resulting video model to effectively segment and track multiple instances across video frames. We show the first competitive unsupervised learning results on the challenging YouTubeVIS-2019 benchmark, achieving 50.7% APvideo^50, surpassing the previous state-of-the-art by a large margin. VideoCutLER can also serve as a strong pretrained model for supervised video instance segmentation tasks, exceeding DINO by 15.9% on YouTubeVIS-2019 in terms of APvideo.Here's the word-for-word translation:传统的无监督视频实例分割方法通常基于运动估计，并且在跟踪小或弯曲运动时存在困难。我们提出了VideoCutLER，一种简单的无监督多实例视频分割方法，不使用运动基于学习信号如光流或者在自然视频上进行训练。我们的关键发现是，使用高质量的 Pseudo 面积和简单的视频合成方法来训练视频模型，奇怪地 sufficient 使得模型可以有效地在视频帧中分割和跟踪多个实例。我们在 YouTubeVIS-2019 benchmark 上 achieve 50.7% APvideo^50，大幅超越过去的状态泰然。VideoCutLER 还可以作为supervised video instance segmentation任务的强大预训练模型，在 YouTubeVIS-2019 上过去 DINO 的 APvideo 值 by 15.9%。
</details></li>
</ul>
<hr>
<h2 id="TRIVEA-Transparent-Ranking-Interpretation-using-Visual-Explanation-of-Black-Box-Algorithmic-Rankers"><a href="#TRIVEA-Transparent-Ranking-Interpretation-using-Visual-Explanation-of-Black-Box-Algorithmic-Rankers" class="headerlink" title="TRIVEA: Transparent Ranking Interpretation using Visual Explanation of Black-Box Algorithmic Rankers"></a>TRIVEA: Transparent Ranking Interpretation using Visual Explanation of Black-Box Algorithmic Rankers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14622">http://arxiv.org/abs/2308.14622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Yuan, Kaustav Bhattacharjee, Akm Zahirul Islam, Aritra Dasgupta</li>
<li>for: 这篇论文的目的是提高排名的透明度，使得不同领域的决策者可以更加了解排名的内在逻辑。</li>
<li>methods: 本论文使用算法学习排名模型，并使用可解释Machine Learning（XAI）技术来帮助人类理解排名模型中的各个参数对排名的影响。</li>
<li>results: 通过TRIVEA视觉分析系统，研究人员可以轻松地探索和理解复杂多属性排名数据，无需打开黑盒排名模型。<details>
<summary>Abstract</summary>
Ranking schemes drive many real-world decisions, like, where to study, whom to hire, what to buy, etc. Many of these decisions often come with high consequences. For example, a university can be deemed less prestigious if not featured in a top-k list, and consumers might not even explore products that do not get recommended to buyers. At the heart of most of these decisions are opaque ranking schemes, which dictate the ordering of data entities, but their internal logic is inaccessible or proprietary. Drawing inferences about the ranking differences is like a guessing game to the stakeholders, like, the rankees (i.e., the entities who are ranked, like product companies) and the decision-makers (i.e., who use the rankings, like buyers). In this paper, we aim to enable transparency in ranking interpretation by using algorithmic rankers that learn from available data and by enabling human reasoning about the learned ranking differences using explainable AI (XAI) methods. To realize this aim, we leverage the exploration-explanation paradigm of human-data interaction to let human stakeholders explore subsets and groupings of complex multi-attribute ranking data using visual explanations of model fit and attribute influence on rankings. We realize this explanation paradigm for transparent ranking interpretation in TRIVEA, a visual analytic system that is fueled by: i) visualizations of model fit derived from algorithmic rankers that learn the associations between attributes and rankings from available data and ii) visual explanations derived from XAI methods that help abstract important patterns, like, the relative influence of attributes in different ranking ranges. Using TRIVEA, end users not trained in data science have the agency to transparently reason about the global and local behavior of the rankings without the need to open black-box ranking models and develop confidence in the resulting attribute-based inferences. We demonstrate the efficacy of TRIVEA using multiple usage scenarios and subjective feedback from researchers with diverse domain expertise. Keywords: Visual Analytics, Learning-to-Rank, Explainable ML, Ranking
</details>
<details>
<summary>摘要</summary>
排名方案在现实生活中影响很大，例如选择学习的地方、聘请的人员、购买的产品等。这些决策通常带有严重的后果。例如，如果一所大学不被列入某些排名列表中，那么该大学可能会被评估为 less prestigious。顾客可能不会考虑没有获得推荐的产品。排名方案的内部逻辑通常是不可见或 propriety 的，因此决策者（如产品公司）和排名对象（如顾客）无法了解排名差异的解释。在这篇论文中，我们想要使排名解释变得 transparent ，使用算法学习排名方法，并使用可解释AI（XAI）方法来帮助人类理解学习到的排名差异。为实现这一目标，我们利用人类数据互动的探索-解释模式，让人类决策者在可视化的方式下探索复杂多属性排名数据的子集和分组。我们在 TRIVEA 中实现了这一解释模式，TRIVEA 是一个基于可视化的数据分析系统，它使用以下两种方法来提供可视化和解释：1. 基于算法学习的排名模型，从可用数据中学习排名和属性之间的关系，并生成可视化的模型适配。2. XAI 方法，帮助抽象出重要的 Pattern，如排名范围内的属性影响。使用 TRIVEA，无需数据科学背景的结束用户可以自主地透明地理解排名的全球和本地行为，并对Attribute-based的推理产生信任。我们通过多个使用场景和域专家的主观反馈，证明了 TRIVEA 的可行性和有用性。关键字：可视化分析、学习排名、可解释Machine Learning、排名
</details></li>
</ul>
<hr>
<h2 id="Assessing-Trust-in-Construction-AI-Powered-Collaborative-Robots-using-Structural-Equation-Modeling"><a href="#Assessing-Trust-in-Construction-AI-Powered-Collaborative-Robots-using-Structural-Equation-Modeling" class="headerlink" title="Assessing Trust in Construction AI-Powered Collaborative Robots using Structural Equation Modeling"></a>Assessing Trust in Construction AI-Powered Collaborative Robots using Structural Equation Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14697">http://arxiv.org/abs/2308.14697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Newsha Emaminejad, Lisa Kath, Reza Akhavian</li>
<li>for: This study aimed to investigate the key technical and psychological factors that impact the architecture, engineering, and construction (AEC) professionals’ trust in collaborative robots (cobots) powered by artificial intelligence (AI).</li>
<li>methods: The study employed a nationwide survey of 600 AEC industry practitioners to gather in-depth responses and valuable insights into the future opportunities for promoting the adoption, cultivation, and training of a skilled workforce to leverage this technology effectively. A Structural Equation Modeling (SEM) analysis was used to reveal the significant factors for the adoption of AI-powered cobots in construction.</li>
<li>results: The study found that safety and reliability are significant factors for the adoption of AI-powered cobots in construction, and fear of being replaced resulting from the use of cobots can have a substantial effect on the mental health of the affected workers. Additionally, the study found that a lower error rate in jobs involving cobots, safety measurements, and security of data collected by cobots from jobsites significantly impact reliability, while the transparency of cobots’ inner workings can benefit accuracy, robustness, security, privacy, and communication, and results in higher levels of automation. The study’s findings provide critical insights into the perceptions and experiences of AEC professionals towards adoption of cobots in construction and help project teams determine the adoption approach that aligns with the company’s goals and workers’ welfare.<details>
<summary>Abstract</summary>
This study aimed to investigate the key technical and psychological factors that impact the architecture, engineering, and construction (AEC) professionals' trust in collaborative robots (cobots) powered by artificial intelligence (AI). The study employed a nationwide survey of 600 AEC industry practitioners to gather in-depth responses and valuable insights into the future opportunities for promoting the adoption, cultivation, and training of a skilled workforce to leverage this technology effectively. A Structural Equation Modeling (SEM) analysis revealed that safety and reliability are significant factors for the adoption of AI-powered cobots in construction. Fear of being replaced resulting from the use of cobots can have a substantial effect on the mental health of the affected workers. A lower error rate in jobs involving cobots, safety measurements, and security of data collected by cobots from jobsites significantly impact reliability, while the transparency of cobots' inner workings can benefit accuracy, robustness, security, privacy, and communication, and results in higher levels of automation, all of which demonstrated as contributors to trust. The study's findings provide critical insights into the perceptions and experiences of AEC professionals towards adoption of cobots in construction and help project teams determine the adoption approach that aligns with the company's goals workers' welfare.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这项研究的目标是调查建筑、工程和建筑（AEC）专业人员对人工智能（AI）驱动的协作机器人（cobots）的信任度。研究使用了600名AEC行业专业人员参与全国范围内的调查，以获取深入的反应和有价值的洞察。结构方程分析发现，在建筑中采用AI驱动的cobots的安全性和可靠性是采用的关键因素。使用cobots可能会导致工人被取代，并且可能会对工人的心理健康产生很大的影响。在cobots参与的任务中，误差率的下降和工地安全测量对可靠性产生了重要影响，而cobots内部的透明度可以提高准确性、Robustness、安全性、隐私和通信，并导致更高水平的自动化，这些都是信任的重要因素。这项研究的发现对AEC专业人员对cobots在建筑领域的采用提供了关键的洞察和经验，帮助项目团队确定采用策略，以实现公司的目标和工人的福祉。
</details></li>
</ul>
<hr>
<h2 id="MELT-Mining-Effective-Lightweight-Transformations-from-Pull-Requests"><a href="#MELT-Mining-Effective-Lightweight-Transformations-from-Pull-Requests" class="headerlink" title="MELT: Mining Effective Lightweight Transformations from Pull Requests"></a>MELT: Mining Effective Lightweight Transformations from Pull Requests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14687">http://arxiv.org/abs/2308.14687</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/squareslab/melt">https://github.com/squareslab/melt</a></li>
<li>paper_authors: Daniel Ramos, Hailie Mitchell, Inês Lynce, Vasco Manquinho, Ruben Martins, Claire Le Goues</li>
<li>for: 提高API更新效率，帮助软件开发人员更快速地更新API。</li>
<li>methods: 使用机器学习技术 mines API更新规则 directly from pull requests in popular library repositories，并提出了一种通用化过程来提高规则的可重用性。</li>
<li>results: 在四个流行的库中 mines 461个更新规则，并通过应用这些规则到客户端项目中，成功减少了警告数量并解决了一些测试案例。<details>
<summary>Abstract</summary>
Software developers often struggle to update APIs, leading to manual, time-consuming, and error-prone processes. We introduce MELT, a new approach that generates lightweight API migration rules directly from pull requests in popular library repositories. Our key insight is that pull requests merged into open-source libraries are a rich source of information sufficient to mine API migration rules. By leveraging code examples mined from the library source and automatically generated code examples based on the pull requests, we infer transformation rules in \comby, a language for structural code search and replace. Since inferred rules from single code examples may be too specific, we propose a generalization procedure to make the rules more applicable to client projects. MELT rules are syntax-driven, interpretable, and easily adaptable. Moreover, unlike previous work, our approach enables rule inference to seamlessly integrate into the library workflow, removing the need to wait for client code migrations. We evaluated MELT on pull requests from four popular libraries, successfully mining 461 migration rules from code examples in pull requests and 114 rules from auto-generated code examples. Our generalization procedure increases the number of matches for mined rules by 9x. We applied these rules to client projects and ran their tests, which led to an overall decrease in the number of warnings and fixing some test cases demonstrating MELT's effectiveness in real-world scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Fine-Tuning-Llama-2-Large-Language-Models-for-Detecting-Online-Sexual-Predatory-Chats-and-Abusive-Texts"><a href="#Fine-Tuning-Llama-2-Large-Language-Models-for-Detecting-Online-Sexual-Predatory-Chats-and-Abusive-Texts" class="headerlink" title="Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts"></a>Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14683">http://arxiv.org/abs/2308.14683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thanh Thi Nguyen, Campbell Wilson, Janis Dalins</li>
<li>for: 这个研究的目的是为了探索在社交媒体平台上探索性的偏见和不当语言，以及发展一个可靠的检测系统，以维护网络上的安全，特别是对于弱化人群，如儿童和青少年。</li>
<li>methods: 本研究使用了Meta GenAI公司最近发布的免费预训Llama 2 7B-parameter模型，进行了精致的调整和测试，以检测在线上的性骚扰和不当语言。</li>
<li>results: 本研究的结果显示，提出的方法在三个不同的数据集上具有优秀的表现，能够自动和自适应地检测性骚扰和不当语言，并且可以应用于各种文本分类问题，如情感分析、骇客和诈欺检测、法律文件排序、假新闻检测、语言识别、用户意愿识别、文本基于产品分类、医疗记录分析和维护产品检测。<details>
<summary>Abstract</summary>
Detecting online sexual predatory behaviours and abusive language on social media platforms has become a critical area of research due to the growing concerns about online safety, especially for vulnerable populations such as children and adolescents. Researchers have been exploring various techniques and approaches to develop effective detection systems that can identify and mitigate these risks. Recent development of large language models (LLMs) has opened a new opportunity to address this problem more effectively. This paper proposes an approach to detection of online sexual predatory chats and abusive language using the open-source pretrained Llama 2 7B-parameter model, recently released by Meta GenAI. We fine-tune the LLM using datasets with different sizes, imbalance degrees, and languages (i.e., English, Roman Urdu and Urdu). Based on the power of LLMs, our approach is generic and automated without a manual search for a synergy between feature extraction and classifier design steps like conventional methods in this domain. Experimental results show a strong performance of the proposed approach, which performs proficiently and consistently across three distinct datasets with five sets of experiments. This study's outcomes indicate that the proposed method can be implemented in real-world applications (even with non-English languages) for flagging sexual predators, offensive or toxic content, hate speech, and discriminatory language in online discussions and comments to maintain respectful internet or digital communities. Furthermore, it can be employed for solving text classification problems with other potential applications such as sentiment analysis, spam and phishing detection, sorting legal documents, fake news detection, language identification, user intent recognition, text-based product categorization, medical record analysis, and resume screening.
</details>
<details>
<summary>摘要</summary>
在社交媒体平台上探测在线性侵和辱骂语言的行为已成为研究的关键领域，特别是对于容易受到侵害的人群，如儿童和青少年。研究人员已经在各种技术和方法上进行了探索，以开发有效的检测系统，以避免这些风险。最近，大型语言模型（LLMs）的发展对于解决这个问题提供了新的机会。本文提出了一种在线性侵辱聊天和辱骂语言检测的方法，使用Meta GenAI最近发布的开源预训练Llama 2 7B参数模型。我们在不同的数据集、不同程度的偏好和不同语言（英语、旁语和乌都）上进行了精细调整。基于LLMs的强大能力，我们的方法是自动化的，无需手动搜索特征提取和分类器设计步骤，与传统方法不同。实验结果表明，我们的方法在三个不同的数据集上表现出色，并在五组实验中表现了稳定和可靠的性。这些结果表明，我们的方法可以在实际应用中使用，即 Flagging sexual predators, offensive or toxic content, hate speech, and discriminatory language in online discussions and comments to maintain respectful internet or digital communities.此外，它还可以用于解决文本分类问题，包括情感分析、垃圾邮件和恶意软件检测、法律文档排序、假新闻检测、语言识别、用户意图识别、文本基于产品分类、医疗记录分析和简历屏选择。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/29/cs.AI_2023_08_29/" data-id="clohum9340034pj88ercr2kdd" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_29" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/29/cs.LG_2023_08_29/" class="article-date">
  <time datetime="2023-08-29T10:00:00.000Z" itemprop="datePublished">2023-08-29</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/29/cs.LG_2023_08_29/">cs.LG - 2023-08-29</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Minimizing-Quasi-Self-Concordant-Functions-by-Gradient-Regularization-of-Newton-Method"><a href="#Minimizing-Quasi-Self-Concordant-Functions-by-Gradient-Regularization-of-Newton-Method" class="headerlink" title="Minimizing Quasi-Self-Concordant Functions by Gradient Regularization of Newton Method"></a>Minimizing Quasi-Self-Concordant Functions by Gradient Regularization of Newton Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14742">http://arxiv.org/abs/2308.14742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikita Doikov</li>
<li>for: 本研究考虑了复合 convex 优化问题，其中一个分别是 quasi-self-concordant 平滑组件。这个问题类型在自身 concordant 函数和 lipschitz 连续偏导数之间进行自然的 interpolate。</li>
<li>methods: 我们使用 basic Newton method with gradient regularization 来解决这个问题。在无约束情况下，这种算法只需要在每步完成一个简单的矩阵反转操作（解决一个线性系统）。我们证明了这种算法在全球Linear rate 上具有快速的性能，与信任区间算法的复杂性 bound 相同，而我们的方法更加简单实现。</li>
<li>results: 我们发现，使用 quasi-self-concordant 函数的 Newton method 可以在多个实际问题中实现快速的全球Linear rate，无需进一步假设强或平均凸性 для目标函数。这些问题包括Logistic Regression、Soft Maximum 和 Matrix Scaling。<details>
<summary>Abstract</summary>
We study the composite convex optimization problems with a Quasi-Self-Concordant smooth component. This problem class naturally interpolates between classic Self-Concordant functions and functions with Lipschitz continuous Hessian. Previously, the best complexity bounds for this problem class were associated with trust-region schemes and implementations of a ball-minimization oracle. In this paper, we show that for minimizing Quasi-Self-Concordant functions we can use instead the basic Newton Method with Gradient Regularization. For unconstrained minimization, it only involves a simple matrix inversion operation (solving a linear system) at each step. We prove a fast global linear rate for this algorithm, matching the complexity bound of the trust-region scheme, while our method remains especially simple to implement. Then, we introduce the Dual Newton Method, and based on it, develop the corresponding Accelerated Newton Scheme for this problem class, which further improves the complexity factor of the basic method. As a direct consequence of our results, we establish fast global linear rates of simple variants of the Newton Method applied to several practical problems, including Logistic Regression, Soft Maximum, and Matrix Scaling, without requiring additional assumptions on strong or uniform convexity for the target objective.
</details>
<details>
<summary>摘要</summary>
我们研究复合凸优化问题中具有半自相关函数组成部分。这个问题类型天然地 interpolates between经典的自相关函数和具有 lipschitz 连续导数的函数。在过去，这个问题类型的最佳复杂性界限与信任区间算法和实现球形最小化器相关。在这篇论文中，我们证明可以使用基本的新顿方法与梯度规则化来减少 quasi-self-concordant 函数的最小化问题。无需进行额外的假设或假设，我们证明了这种算法在全球linear rate具有相同的复杂性界限，而且该算法的实现非常简单。然后，我们引入对应的 dual 新顿方法，并基于它，开发了对这个问题类型的加速新顿方案，进一步改善了基本方法的复杂性因子。作为直接结论，我们建立了基本新顿方法应用于一些实际问题的快速全球线性率，包括逻辑回归、软最大值和矩阵压缩，无需进行额外的假设或假设强或均匀凸性。
</details></li>
</ul>
<hr>
<h2 id="Diversified-Ensemble-of-Independent-Sub-Networks-for-Robust-Self-Supervised-Representation-Learning"><a href="#Diversified-Ensemble-of-Independent-Sub-Networks-for-Robust-Self-Supervised-Representation-Learning" class="headerlink" title="Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning"></a>Diversified Ensemble of Independent Sub-Networks for Robust Self-Supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14705">http://arxiv.org/abs/2308.14705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Vahidi, Lisa Wimmer, Hüseyin Anil Gündüz, Bernd Bischl, Eyke Hüllermeier, Mina Rezaei<br>for: 这个论文主要目标是提高深度学习模型的性能、估计不确定性和稳定性。methods: 这个论文使用了一种新的自我超vised训练方法，利用一个 ensemble of 独立的子网络，并使用一个新的损失函数来鼓励多样性。results: 这个论文的实验结果表明，使用这种方法可以efficiently建立一个多样化的sub-model ensemble，从而实现了高度准确的预测估计和模型不确定性的良好均衡。这种方法在多种任务中表现出色，包括随机数据生成、数据腐坏检测、 semi-supervised setting等。<details>
<summary>Abstract</summary>
Ensembling a neural network is a widely recognized approach to enhance model performance, estimate uncertainty, and improve robustness in deep supervised learning. However, deep ensembles often come with high computational costs and memory demands. In addition, the efficiency of a deep ensemble is related to diversity among the ensemble members which is challenging for large, over-parameterized deep neural networks. Moreover, ensemble learning has not yet seen such widespread adoption, and it remains a challenging endeavor for self-supervised or unsupervised representation learning. Motivated by these challenges, we present a novel self-supervised training regime that leverages an ensemble of independent sub-networks, complemented by a new loss function designed to encourage diversity. Our method efficiently builds a sub-model ensemble with high diversity, leading to well-calibrated estimates of model uncertainty, all achieved with minimal computational overhead compared to traditional deep self-supervised ensembles. To evaluate the effectiveness of our approach, we conducted extensive experiments across various tasks, including in-distribution generalization, out-of-distribution detection, dataset corruption, and semi-supervised settings. The results demonstrate that our method significantly improves prediction reliability. Our approach not only achieves excellent accuracy but also enhances calibration, surpassing baseline performance across a wide range of self-supervised architectures in computer vision, natural language processing, and genomics data.
</details>
<details>
<summary>摘要</summary>
ensemble 一种广泛应用的方法是增强模型性能，估计不确定性，并提高深度学习中的稳定性。然而，深度集成常常带来高计算成本和内存需求。此外，集成学习的效率与集成成员之间的多样性有直接关系，而大型、过参数化的深度神经网络中实现多样性是一项挑战。此外，集成学习还尚未得到广泛的应用，而且在无监督或自监督学习中实现集成学习是一项挑战。为了解决这些挑战，我们提出了一种新的自监督训练方法，该方法利用了多个独立的子网络，并且使用了一种新的损失函数，以促进多样性。我们的方法可以高效地建立一个多样性较高的子模型集成，从而获得高度准确的模型不确定性估计，而且与传统的深度自监督集成相比，计算成本减少了较多。为了评估我们的方法的效果，我们在各种任务上进行了广泛的实验，包括内部概率泛化、外部泛化检测、数据损害和半监督设置。结果表明，我们的方法可以显著提高预测可靠性。我们的方法不仅达到了出色的准确率，还可以提高准确性的抽象，在计算机视觉、自然语言处理和生物数据中的各种自监督架构上都达到了或超过了基eline性能。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-PLS-ML-Authentication-Scheme-for-V2I-Communication-Networks"><a href="#Hybrid-PLS-ML-Authentication-Scheme-for-V2I-Communication-Networks" class="headerlink" title="Hybrid PLS-ML Authentication Scheme for V2I Communication Networks"></a>Hybrid PLS-ML Authentication Scheme for V2I Communication Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.14693">http://arxiv.org/abs/2308.14693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hala Amin, Jawaher Kaldari, Nora Mohamed, Waqas Aman, Saif Al-Kuwari</li>
<li>for: 本研究旨在提供一种hybrid物理层安全（PLS）-机器学习（ML）身份验证方案，以确保智能汽车交通管理中的安全和有效性。</li>
<li>methods: 我们提出一种使用发送器车辆位置作为设备指纹的ToA基于本地化位置机制，并使用ML模型跟踪移动的合法车辆的方法。</li>
<li>results: 我们的实验结果表明，使用我们的方案可以减少False报警和遗漏检测的可能性，并且在 missed detection 方面表现更好于基eline方案。<details>
<summary>Abstract</summary>
Vehicular communication networks are rapidly emerging as vehicles become smarter. However, these networks are increasingly susceptible to various attacks. The situation is exacerbated by the rise in automated vehicles complicates, emphasizing the need for security and authentication measures to ensure safe and effective traffic management. In this paper, we propose a novel hybrid physical layer security (PLS)-machine learning (ML) authentication scheme by exploiting the position of the transmitter vehicle as a device fingerprint. We use a time-of-arrival (ToA) based localization mechanism where the ToA is estimated at roadside units (RSUs), and the coordinates of the transmitter vehicle are extracted at the base station (BS).Furthermore, to track the mobility of the moving legitimate vehicle, we use ML model trained on several system parameters. We try two ML models for this purpose, i.e., support vector regression and decision tree. To evaluate our scheme, we conduct binary hypothesis testing on the estimated positions with the help of the ground truths provided by the ML model, which classifies the transmitter node as legitimate or malicious. Moreover, we consider the probability of false alarm and the probability of missed detection as performance metrics resulting from the binary hypothesis testing, and mean absolute error (MAE), mean square error (MSE), and coefficient of determination $\text{R}^2$ to further evaluate the ML models. We also compare our scheme with a baseline scheme that exploits the angle of arrival at RSUs for authentication. We observe that our proposed position-based mechanism outperforms the baseline scheme significantly in terms of missed detections.
</details>
<details>
<summary>摘要</summary>
Our scheme uses a time-of-arrival (ToA) based localization mechanism, where the ToA is estimated at roadside units (RSUs) and the coordinates of the transmitter vehicle are extracted at the base station (BS). Additionally, we use ML models to track the mobility of the moving legitimate vehicle. We test two ML models for this purpose: support vector regression and decision tree.To evaluate our scheme, we conduct binary hypothesis testing on the estimated positions with the help of the ground truths provided by the ML model. This classifies the transmitter node as legitimate or malicious. We also consider the probability of false alarm and the probability of missed detection as performance metrics, as well as mean absolute error (MAE), mean square error (MSE), and coefficient of determination $\text{R}^2$ to evaluate the ML models.We compare our scheme with a baseline scheme that exploits the angle of arrival at RSUs for authentication and find that our proposed position-based mechanism outperforms the baseline scheme in terms of missed detections. Our scheme provides a more secure and effective way to authenticate vehicles in vehicular communication networks.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/29/cs.LG_2023_08_29/" data-id="clohum99f00nfpj880i9octcl" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/26/cs.CV_2023_08_26/" class="article-date">
  <time datetime="2023-08-26T13:00:00.000Z" itemprop="datePublished">2023-08-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/26/cs.CV_2023_08_26/">cs.CV - 2023-08-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Joint-Modeling-of-Feature-Correspondence-and-a-Compressed-Memory-for-Video-Object-Segmentation"><a href="#Joint-Modeling-of-Feature-Correspondence-and-a-Compressed-Memory-for-Video-Object-Segmentation" class="headerlink" title="Joint Modeling of Feature, Correspondence, and a Compressed Memory for Video Object Segmentation"></a>Joint Modeling of Feature, Correspondence, and a Compressed Memory for Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13505">http://arxiv.org/abs/2308.13505</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaming Zhang, Yutao Cui, Gangshan Wu, Limin Wang</li>
<li>for: 提高视频对象分割（VOS）方法的性能，解决现有方法中 dense matching  после Extracting 特征的限制，以及 pixel-wise 匹配导致的目标信息不具备全面理解。</li>
<li>methods: 提出一种 joint 模型，名为 JointFormer，具有三个元素的共同模型，包括特征、匹配和压缩存储。核心设计是 Joint Block，通过注意力的灵活性同时提取特征和传递目标信息到当前 токен和压缩存储 токен。这种方案允许进行广泛的信息传递和特征学习。</li>
<li>results: 根据 DAVIS 2017 val&#x2F;test-dev 和 YouTube-VOS 2018&#x2F;2019 val  bencmarks，我们的方法实现了新的state-of-the-art性能（89.7%和87.6%）和（87.0%和87.0%），与现有方法相比提高了很大的margin。<details>
<summary>Abstract</summary>
Current prevailing Video Object Segmentation (VOS) methods usually perform dense matching between the current and reference frames after extracting their features. One on hand, the decoupled modeling restricts the targets information propagation only at high-level feature space. On the other hand, the pixel-wise matching leads to a lack of holistic understanding of the targets. To overcome these issues, we propose a unified VOS framework, coined as JointFormer, for joint modeling the three elements of feature, correspondence, and a compressed memory. The core design is the Joint Block, utilizing the flexibility of attention to simultaneously extract feature and propagate the targets information to the current tokens and the compressed memory token. This scheme allows to perform extensive information propagation and discriminative feature learning. To incorporate the long-term temporal targets information, we also devise a customized online updating mechanism for the compressed memory token, which can prompt the information flow along the temporal dimension and thus improve the global modeling capability. Under the design, our method achieves a new state-of-art performance on DAVIS 2017 val/test-dev (89.7% and 87.6%) and YouTube-VOS 2018/2019 val (87.0% and 87.0%) benchmarks, outperforming existing works by a large margin.
</details>
<details>
<summary>摘要</summary>
当前主流的视频对象分割（VOS）方法通常是在提取特征后进行密集匹配 между当前和参考帧。一方面，分解模型限制目标信息的传播只在高级特征空间进行。另一方面，像素级匹配导致无法全面理解目标。为了解决这些问题，我们提出了一个统一的VOS框架，命名为JointFormer，用于联合模型特征、匹配和压缩存储。核心设计是Joint块，利用注意力的灵活性同时提取特征和传递目标信息到当前 токен和压缩存储 токен。这种方案允许进行广泛的信息传递和特征学习。为了包含长期时间的目标信息，我们还设计了自定义在线更新机制，以便在时间维度上流动信息，从而提高全局模型能力。根据设计，我们的方法在DAVIS 2017 val/test-dev（89.7%和87.6%）和YouTube-VOS 2018/2019 val（87.0%和87.0%）标准测试上达到了新的状态级表现，超过现有方法的表现。
</details></li>
</ul>
<hr>
<h2 id="A2Q-Accumulator-Aware-Quantization-with-Guaranteed-Overflow-Avoidance"><a href="#A2Q-Accumulator-Aware-Quantization-with-Guaranteed-Overflow-Avoidance" class="headerlink" title="A2Q: Accumulator-Aware Quantization with Guaranteed Overflow Avoidance"></a>A2Q: Accumulator-Aware Quantization with Guaranteed Overflow Avoidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13504">http://arxiv.org/abs/2308.13504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ian Colbert, Alessandro Pappalardo, Jakoba Petri-Koenig</li>
<li>for: 训练量化神经网络（QNN）以避免在推理时使用低精度累加器时发生溢出。</li>
<li>methods: 引入了一种新的量化方法，即accumulator-aware quantization（A2Q），它基于模型量化的约束，使得在训练QNN时，模型权重的L1范围遵循累加器的位数范围。这种方法同时激发了模型权重的不结构化粒度缺失，以确保避免溢出。</li>
<li>results: A2Q可以在深度学习基于计算机视觉任务上训练QNN，而无需使用浮点数据类型，同时保持模型精度与浮点模型相似。在我们的评估中，我们考虑了A2Q在通用平台和可编程硬件上的影响。但我们主要目标是在FPGA上部署模型，因为它可以完全利用自定义累加器的位数。我们的实验表明，累加器位数对FPGA上的加速器资源利用率产生显著影响。在我们的 benchmark 中，A2Q可以在 average 上减少资源利用率达到 2.3倍，与32位累加器相比，而且保持99.2%的浮点模型精度。<details>
<summary>Abstract</summary>
We present accumulator-aware quantization (A2Q), a novel weight quantization method designed to train quantized neural networks (QNNs) to avoid overflow when using low-precision accumulators during inference. A2Q introduces a unique formulation inspired by weight normalization that constrains the L1-norm of model weights according to accumulator bit width bounds that we derive. Thus, in training QNNs for low-precision accumulation, A2Q also inherently promotes unstructured weight sparsity to guarantee overflow avoidance. We apply our method to deep learning-based computer vision tasks to show that A2Q can train QNNs for low-precision accumulators while maintaining model accuracy competitive with a floating-point baseline. In our evaluations, we consider the impact of A2Q on both general-purpose platforms and programmable hardware. However, we primarily target model deployment on FPGAs because they can be programmed to fully exploit custom accumulator bit widths. Our experimentation shows accumulator bit width significantly impacts the resource efficiency of FPGA-based accelerators. On average across our benchmarks, A2Q offers up to a 2.3x reduction in resource utilization over 32-bit accumulator counterparts with 99.2% of the floating-point model accuracy.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的量化预测方法，名为“accumulator-aware quantization”（A2Q），用于在推导过程中避免量化神经网络（QNN）的过流。A2Q将量化神经网络的模型重量与累绩器的位元数量产生联乘关系，以确保在推导过程中避免过流。因此，在对低精度累绩器进行训练时，A2Q同时具有过程简化和过程简化的功能。我们将这种方法应用于深度学习数据领域的应用，并证明A2Q可以在低精度累绩器下训练QNN，并保持与浮点数据模型的竞争力。在我们的评估中，我们考虑了在通用平台和可程式硬件上的影响，但我们主要针对FPGA进行部署，因为FPGA可以根据自己的特定累绩器位元数量进行自适应。我们的实验表明，累绩器位元数量有着显著的影响力，A2Q可以在FPGA上的加速器上提供更好的资源利用率。在我们的测试中，A2Q在32位累绩器下提供了2.3倍的资源利用率，并保持99.2%的浮点数据模型精度。
</details></li>
</ul>
<hr>
<h2 id="Eventful-Transformers-Leveraging-Temporal-Redundancy-in-Vision-Transformers"><a href="#Eventful-Transformers-Leveraging-Temporal-Redundancy-in-Vision-Transformers" class="headerlink" title="Eventful Transformers: Leveraging Temporal Redundancy in Vision Transformers"></a>Eventful Transformers: Leveraging Temporal Redundancy in Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13494">http://arxiv.org/abs/2308.13494</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/WISION-Lab/eventful-transformer">https://github.com/WISION-Lab/eventful-transformer</a></li>
<li>paper_authors: Matthew Dutson, Yin Li, Mohit Gupta</li>
<li>for: 这篇论文的目的是提高视觉识别任务中的Transformers模型精度，并且降低它们的computational cost。</li>
<li>methods: 这篇论文使用了一种称为”Eventful Transformers”的方法，它可以将Transformers模型转换为具有适应控制的计算成本，并且可以在runtime中进行自适应调节。</li>
<li>results: 这篇论文在大规模的视频物件检测（ImageNet VID）和动作识别（EPIC-Kitchens 100） dataset上进行了评估，发现这种方法可以实现2-4倍的计算成本优化，仅有小量的精度损失。<details>
<summary>Abstract</summary>
Vision Transformers achieve impressive accuracy across a range of visual recognition tasks. Unfortunately, their accuracy frequently comes with high computational costs. This is a particular issue in video recognition, where models are often applied repeatedly across frames or temporal chunks. In this work, we exploit temporal redundancy between subsequent inputs to reduce the cost of Transformers for video processing. We describe a method for identifying and re-processing only those tokens that have changed significantly over time. Our proposed family of models, Eventful Transformers, can be converted from existing Transformers (often without any re-training) and give adaptive control over the compute cost at runtime. We evaluate our method on large-scale datasets for video object detection (ImageNet VID) and action recognition (EPIC-Kitchens 100). Our approach leads to significant computational savings (on the order of 2-4x) with only minor reductions in accuracy.
</details>
<details>
<summary>摘要</summary>
< Lang="zh-CN" >视力转换器在视觉识别任务中表现出色，但它们的计算成本很高。特别是在视频识别中，模型经常在帧或时间块之间重复应用。在这项工作中，我们利用时间重复性来降低转换器的计算成本。我们描述了一种方法，可以在运行时控制计算成本。我们的提议的家族模型，即事件转换器，可以将现有转换器转换成适应性控制计算成本的模型，而无需再训练。我们在大规模数据集上进行了视频物体检测（ImageNet VID）和动作识别（EPIC-Kitchens 100）的评估，我们的方法可以实现大量的计算成本减少（在2-4倍之间），只有小量的减少准确率。</SYS>Note: The Simplified Chinese translation is done using the Google Translate API, which may not be perfect and may not capture all the nuances of the original text.
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Performance-of-Proximity-Sensors-by-Utilizing-Transient-Histograms"><a href="#Unlocking-the-Performance-of-Proximity-Sensors-by-Utilizing-Transient-Histograms" class="headerlink" title="Unlocking the Performance of Proximity Sensors by Utilizing Transient Histograms"></a>Unlocking the Performance of Proximity Sensors by Utilizing Transient Histograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13473">http://arxiv.org/abs/2308.13473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carter Sifferman, Yeping Wang, Mohit Gupta, Michael Gleicher</li>
<li>for: 该论文主要用于提高close-range时间探测（ToF）距离传感器所获取的场景几何信息的准确性。</li>
<li>methods: 该论文使用了直接使用传感器捕获的转变 histogram，并使用可导渠 Rendering 管道来直接优化场景几何，以提高对观察结果的匹配。</li>
<li>results: 论文通过对八种不同视角的平面表面进行3,800次测量，并证明了其方法在大多数场景下高效性比Proprietary distance estimate基准值高一个数量级。此外，论文还示出了一种简单的机器人应用，通过使用该方法来感知机器人臂上的把握器上的距离和坡度。<details>
<summary>Abstract</summary>
We provide methods which recover planar scene geometry by utilizing the transient histograms captured by a class of close-range time-of-flight (ToF) distance sensor. A transient histogram is a one dimensional temporal waveform which encodes the arrival time of photons incident on the ToF sensor. Typically, a sensor processes the transient histogram using a proprietary algorithm to produce distance estimates, which are commonly used in several robotics applications. Our methods utilize the transient histogram directly to enable recovery of planar geometry more accurately than is possible using only proprietary distance estimates, and consistent recovery of the albedo of the planar surface, which is not possible with proprietary distance estimates alone. This is accomplished via a differentiable rendering pipeline, which simulates the transient imaging process, allowing direct optimization of scene geometry to match observations. To validate our methods, we capture 3,800 measurements of eight planar surfaces from a wide range of viewpoints, and show that our method outperforms the proprietary-distance-estimate baseline by an order of magnitude in most scenarios. We demonstrate a simple robotics application which uses our method to sense the distance to and slope of a planar surface from a sensor mounted on the end effector of a robot arm.
</details>
<details>
<summary>摘要</summary>
我们提供一种方法，可以利用 close-range time-of-flight (ToF) 距离传感器所捕获的过渡历史gram来恢复平面场景的几何结构。一个过渡历史gram是一个一维时间射频信号，其记录了在 ToF 传感器上 incident 光子的到达时间。通常，一个传感器会使用专有算法来处理过渡历史gram，以生成距离估计，这些估计在多种 робо得应用中被广泛使用。我们的方法直接利用过渡历史gram，以准确地恢复平面几何结构，并同时恢复平面表面的反射率，这两个参数不可能通过专有距离估计alone 获得。我们通过一个可微的渲染管线来实现这一点，该管线模拟了过渡成像过程，允许直接优化场景几何来匹配观测。为验证我们的方法，我们Capture 3,800个平面测量数据，来自多种视点，并显示我们的方法在大多数情况下高效性比专有距离估计baseline 提高一个数量级。我们还展示了一个简单的 робо得应用，使用我们的方法来检测 robot arm 上的末端器的距离和倾斜。
</details></li>
</ul>
<hr>
<h2 id="A-Fast-Minimization-Algorithm-for-the-Euler-Elastica-Model-Based-on-a-Bilinear-Decomposition"><a href="#A-Fast-Minimization-Algorithm-for-the-Euler-Elastica-Model-Based-on-a-Bilinear-Decomposition" class="headerlink" title="A Fast Minimization Algorithm for the Euler Elastica Model Based on a Bilinear Decomposition"></a>A Fast Minimization Algorithm for the Euler Elastica Model Based on a Bilinear Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13471">http://arxiv.org/abs/2308.13471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhifang Liu, Baochen Sun, Xue-Cheng Tai, Qi Wang, Huibin Chang</li>
<li>for: 这个论文的目的是提出一种新的、快速、稳定的 alternating minimization（HALM）算法来解决Euler Elastica（EE）模型中的非线性和缺失问题。</li>
<li>methods: 该算法基于bilinear decomposition of the gradient of the underlying image，并且包括三个子最小化问题，每个问题可以在关闭式或快速解决器中解决。</li>
<li>results: 对比其他当前状态算法，新算法能够更快、更稳定地解决EE模型，并且在一系列数学实验中表现良好。例如，与fast operator-splitting-based Deng-Glowinski-Tai算法相比，新算法的平均运行时间只需一半。<details>
<summary>Abstract</summary>
The Euler Elastica (EE) model with surface curvature can generate artifact-free results compared with the traditional total variation regularization model in image processing. However, strong nonlinearity and singularity due to the curvature term in the EE model pose a great challenge for one to design fast and stable algorithms for the EE model. In this paper, we propose a new, fast, hybrid alternating minimization (HALM) algorithm for the EE model based on a bilinear decomposition of the gradient of the underlying image and prove the global convergence of the minimizing sequence generated by the algorithm under mild conditions. The HALM algorithm comprises three sub-minimization problems and each is either solved in the closed form or approximated by fast solvers making the new algorithm highly accurate and efficient. We also discuss the extension of the HALM strategy to deal with general curvature-based variational models, especially with a Lipschitz smooth functional of the curvature. A host of numerical experiments are conducted to show that the new algorithm produces good results with much-improved efficiency compared to other state-of-the-art algorithms for the EE model. As one of the benchmarks, we show that the average running time of the HALM algorithm is at most one-quarter of that of the fast operator-splitting-based Deng-Glowinski-Tai algorithm.
</details>
<details>
<summary>摘要</summary>
“欧拉-艾拉斯特拉（EE）模型可以实现无残留的结果，与传统的总方差整合模型相比，在图像处理中。然而，EE模型中的曲率项带来强烈的非线性和极值问题，使得设计快速稳定的算法成为一大挑战。在本文中，我们提出了一个新的、快速、混合替换几何（HALM）算法，基于图像的梯度的 bilinear 分解，并证明了混合替换过程中的数列 convergence 的 globally 稳定性。HALM 算法包括三个子替换问题，每个都可以通过关键简单的类型或快速的算法来解决，使得新算法具有高精度和高效性。此外，我们还讨论了对应各种曲率基于的可变量化模型的扩展，特别是一个 Lipschitz 平滑函数的曲率。在实验中，我们展示了新算法在许多测试案例中具有较好的效果，并且比传统的算法更高效。”
</details></li>
</ul>
<hr>
<h2 id="RestNet-Boosting-Cross-Domain-Few-Shot-Segmentation-with-Residual-Transformation-Network"><a href="#RestNet-Boosting-Cross-Domain-Few-Shot-Segmentation-with-Residual-Transformation-Network" class="headerlink" title="RestNet: Boosting Cross-Domain Few-Shot Segmentation with Residual Transformation Network"></a>RestNet: Boosting Cross-Domain Few-Shot Segmentation with Residual Transformation Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13469">http://arxiv.org/abs/2308.13469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyang Huang, Chuang Zhu, Wenkai Chen</li>
<li>for: 本文目的是提出一种新的交叉频谱几何学习模型，以实现在未知频谱上进行 semantic segmentation，并且可以在有限的注释样本基础上进行学习。</li>
<li>methods: 本文提出了一种名为RestNet的几何学习模型，该模型通过 Semantic Enhanced Anchor Transform (SEAT) 模块和 Intra-domain Residual Enhancement (IRE) 模块来实现知识传递，同时保持了内域支持查询特征信息。此外，本文还提出了一种基于 prototype fusion 的面 predicate 策略，帮助模型慢慢地学习如何分割。</li>
<li>results: 实验表明，RestNet 可以在 ISIC、Chest X-ray 和 FSS-1000 等 dataset 上 achieve state-of-the-art 性能，并且不需要额外的 fine-tuning。<details>
<summary>Abstract</summary>
Cross-domain few-shot segmentation (CD-FSS) aims to achieve semantic segmentation in previously unseen domains with a limited number of annotated samples. Although existing CD-FSS models focus on cross-domain feature transformation, relying exclusively on inter-domain knowledge transfer may lead to the loss of critical intra-domain information. To this end, we propose a novel residual transformation network (RestNet) that facilitates knowledge transfer while retaining the intra-domain support-query feature information. Specifically, we propose a Semantic Enhanced Anchor Transform (SEAT) module that maps features to a stable domain-agnostic space using advanced semantics. Additionally, an Intra-domain Residual Enhancement (IRE) module is designed to maintain the intra-domain representation of the original discriminant space in the new space. We also propose a mask prediction strategy based on prototype fusion to help the model gradually learn how to segment. Our RestNet can transfer cross-domain knowledge from both inter-domain and intra-domain without requiring additional fine-tuning. Extensive experiments on ISIC, Chest X-ray, and FSS-1000 show that our RestNet achieves state-of-the-art performance. Our code will be available soon.
</details>
<details>
<summary>摘要</summary>
specifically，我们提出了一种 Semantic Enhanced Anchor Transform (SEAT) 模块，它可以将特征映射到一个稳定的领域不依赖的空间中使用先进的 semantics。此外，我们还提出了一种 Intra-domain Residual Enhancement (IRE) 模块，它可以保持原始领域的 intra-domain 表示。我们还提出了一种 mask prediction strategy based on prototype fusion，帮助模型慢慢地学习如何分割。我们的 RestNet 可以从 both inter-domain 和 intra-domain 中传递知识，而不需要额外的 fine-tuning。我们进行了广泛的实验，结果表明我们的 RestNet 可以达到 state-of-the-art 性能。我们的代码很快就会发布。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/26/cs.CV_2023_08_26/" data-id="clohum97b00gnpj882mf80r5u" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/26/cs.AI_2023_08_26/" class="article-date">
  <time datetime="2023-08-26T12:00:00.000Z" itemprop="datePublished">2023-08-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/26/cs.AI_2023_08_26/">cs.AI - 2023-08-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ChatGPT-as-Data-Augmentation-for-Compositional-Generalization-A-Case-Study-in-Open-Intent-Detection"><a href="#ChatGPT-as-Data-Augmentation-for-Compositional-Generalization-A-Case-Study-in-Open-Intent-Detection" class="headerlink" title="ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection"></a>ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13517">http://arxiv.org/abs/2308.13517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihao Fang, Xianzhi Li, Stephen W. Thomas, Xiaodan Zhu</li>
<li>for: 增强自然语言理解任务中的拓展性 generale</li>
<li>methods: 使用ChatGPT作为数据增强技术，提高开放意图检测任务中的组合泛化能力</li>
<li>results: 对多个benchmark进行严格评估，发现我们的方法可以明显提高模型性能，并且在开放意图检测任务中具有显著的提升效果。<details>
<summary>Abstract</summary>
Open intent detection, a crucial aspect of natural language understanding, involves the identification of previously unseen intents in user-generated text. Despite the progress made in this field, challenges persist in handling new combinations of language components, which is essential for compositional generalization. In this paper, we present a case study exploring the use of ChatGPT as a data augmentation technique to enhance compositional generalization in open intent detection tasks. We begin by discussing the limitations of existing benchmarks in evaluating this problem, highlighting the need for constructing datasets for addressing compositional generalization in open intent detection tasks. By incorporating synthetic data generated by ChatGPT into the training process, we demonstrate that our approach can effectively improve model performance. Rigorous evaluation of multiple benchmarks reveals that our method outperforms existing techniques and significantly enhances open intent detection capabilities. Our findings underscore the potential of large language models like ChatGPT for data augmentation in natural language understanding tasks.
</details>
<details>
<summary>摘要</summary>
开放意图检测是自然语言理解的重要方面，涉及到用户生成文本中未经见的意图的识别。Despite the progress made in this field, there are still challenges in handling new combinations of language components, which is crucial for compositional generalization. In this paper, we present a case study exploring the use of ChatGPT as a data augmentation technique to enhance compositional generalization in open intent detection tasks.我们开始 by discussing the limitations of existing benchmarks in evaluating this problem, highlighting the need for constructing datasets for addressing compositional generalization in open intent detection tasks. By incorporating synthetic data generated by ChatGPT into the training process, we demonstrate that our approach can effectively improve model performance. Rigorous evaluation of multiple benchmarks reveals that our method outperforms existing techniques and significantly enhances open intent detection capabilities. Our findings underscore the potential of large language models like ChatGPT for data augmentation in natural language understanding tasks.Here's the text with some minor adjustments to make it more readable in Simplified Chinese:开放意图检测是自然语言理解的重要方面，涉及到用户生成文本中未经见的意图的识别。尽管在这个领域已经做出了很多进步，但是处理新的语言组成部分的挑战仍然存在，这是重要的 Compositional generalization。在这篇论文中，我们进行了一个案例研究，探讨使用 ChatGPT 作为数据增强技术来提高开放意图检测任务中的 Compositional generalization。我们开始 by 讨论现有的 benchmar 的限制，高亮需要为开放意图检测任务构建数据集来解决 Compositional generalization 问题。通过在训练过程中添加 ChatGPT 生成的Synthetic数据，我们示出了我们的方法可以有效提高模型性能。多个 benchmar 的严格评估表明，我们的方法超过了现有的方法，并有效地提高了开放意图检测能力。我们的发现强调了大语言模型 like ChatGPT 的潜在作用在自然语言理解任务中。
</details></li>
</ul>
<hr>
<h2 id="Does-Asking-Clarifying-Questions-Increases-Confidence-in-Generated-Code-On-the-Communication-Skills-of-Large-Language-Models"><a href="#Does-Asking-Clarifying-Questions-Increases-Confidence-in-Generated-Code-On-the-Communication-Skills-of-Large-Language-Models" class="headerlink" title="Does Asking Clarifying Questions Increases Confidence in Generated Code? On the Communication Skills of Large Language Models"></a>Does Asking Clarifying Questions Increases Confidence in Generated Code? On the Communication Skills of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13507">http://arxiv.org/abs/2308.13507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie JW Wu</li>
<li>for: 提高大型自然语言模型（LLM）在代码生成任务中的能力</li>
<li>methods: 使用LLM生成器寻找高不确定性和低信任性问题，并向用户提问以获取反馈</li>
<li>results: 通过提高沟通技巧，提高代码生成器对代码质量的信任度<details>
<summary>Abstract</summary>
Large language models (LLMs) have significantly improved the ability to perform tasks in the field of code generation. However, there is still a gap between LLMs being capable coders and being top-tier software engineers. Based on the observation that top-level software engineers often ask clarifying questions to reduce ambiguity in both requirements and coding solutions, we argue that the same should be applied to LLMs for code generation tasks. By asking probing questions in various topics before generating the final code, the challenges of programming with LLMs, such as unclear intent specification, lack of computational thinking, and undesired code quality, may be alleviated. This, in turn, increases confidence in the generated code. In this work, we explore how to leverage better communication skills to achieve greater confidence in generated code. We propose a communication-centered process that uses an LLM-generated communicator to identify issues with high ambiguity or low confidence in problem descriptions and generated code. We then ask clarifying questions to obtain responses from users for refining the code.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:大型语言模型（LLM）已经对代码生成任务做出了重要改进，但是仍然存在LLM是出色的程序员和首席软件工程师之间的差距。根据观察到的首席软件工程师经常对需求和解决方案中的模糊性问题提出询问，我们认为这样的方法也应被应用到LLM的代码生成任务中。通过在生成代码之前向用户提出询问，可以帮助解决LLM在代码生成中的挑战，例如不清晰的意图规定、Computational Thinking的缺乏和不满意的代码质量。这样可以增加代码的信任度。在这个工作中，我们探索如何通过更好的沟通技巧来实现更高的代码信任度。我们提出了一个沟通中心的过程，使用LLM生成的通信器来识别问题中的高模糊性或低信任性，然后对用户提出询问以获取反馈。
</details></li>
</ul>
<hr>
<h2 id="Attending-Generalizability-in-Course-of-Deep-Fake-Detection-by-Exploring-Multi-task-Learning"><a href="#Attending-Generalizability-in-Course-of-Deep-Fake-Detection-by-Exploring-Multi-task-Learning" class="headerlink" title="Attending Generalizability in Course of Deep Fake Detection by Exploring Multi-task Learning"></a>Attending Generalizability in Course of Deep Fake Detection by Exploring Multi-task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13503">http://arxiv.org/abs/2308.13503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranav Balaji, Abhijit Das, Srijan Das, Antitza Dantcheva</li>
<li>for: 本研究探讨了多种多任务学习（MTL）技术，用于分类视频为原始或修改的混合修改场景，以提高深入Counterfeit场景中的泛化性。</li>
<li>methods: 我们使用了FaceForensics++ dataset，该 dataset包含1000个原始视频和4种不同的修改技术修改后的5000个视频。我们进行了广泛的多任务学习和对比技术的实验，这些技术在文献中已经得到了广泛的探讨。</li>
<li>results: 结果表明，我们提出的检测模型具有良好的泛化性，能够正确地检测不同修改方法的视频，比对state-of-the-art更高效。<details>
<summary>Abstract</summary>
This work explores various ways of exploring multi-task learning (MTL) techniques aimed at classifying videos as original or manipulated in cross-manipulation scenario to attend generalizability in deep fake scenario. The dataset used in our evaluation is FaceForensics++, which features 1000 original videos manipulated by four different techniques, with a total of 5000 videos. We conduct extensive experiments on multi-task learning and contrastive techniques, which are well studied in literature for their generalization benefits. It can be concluded that the proposed detection model is quite generalized, i.e., accurately detects manipulation methods not encountered during training as compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
这项工作探讨了多种多任务学习（MTL）技术，用于分类视频为原始或修改的混合 manipulate enario，以提高深度假象场景中的泛化性。我们使用的数据集是 FaceForensics++, 该数据集包含 1000 个原始视频，被四种不同的技术修改，总共有 5000 个视频。我们进行了广泛的多任务学习和对比技术实验，这些技术在文献中已经得到了广泛的研究和证明了其泛化效果。可以结论，我们提出的检测模型具有良好的泛化性，即在训练中未遇到的修改方法上具有高度的检测精度，比之前的状态艺术。
</details></li>
</ul>
<hr>
<h2 id="Escaping-the-Sample-Trap-Fast-and-Accurate-Epistemic-Uncertainty-Estimation-with-Pairwise-Distance-Estimators"><a href="#Escaping-the-Sample-Trap-Fast-and-Accurate-Epistemic-Uncertainty-Estimation-with-Pairwise-Distance-Estimators" class="headerlink" title="Escaping the Sample Trap: Fast and Accurate Epistemic Uncertainty Estimation with Pairwise-Distance Estimators"></a>Escaping the Sample Trap: Fast and Accurate Epistemic Uncertainty Estimation with Pairwise-Distance Estimators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13498">http://arxiv.org/abs/2308.13498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas Berry, David Meger</li>
<li>for: 本研究提出了一种新的方法来估计 ensemble 模型中的 epistemic uncertainty，使用 pairwise-distance estimators (PaiDEs)。</li>
<li>methods: PaiDEs 利用模型组件之间的对比距离来确定 entropy 的下界，并将这些下界作为信息基据 критериion 的估计。与现代深度学习方法不同，PaiDEs 可以在更大的空间（最多 100 $\times$）和更高的维度（最多 100 $\times$）上更快（大约 100 $\times$）和更准确地估计 epistemic uncertainty。</li>
<li>results: 通过一系列常用来评估 epistemic uncertainty 估计的实验（1D 杆形数据、Pendulum-v0、Hopper-v2、Ant-v2 和 Humanoid-v2），我们证明了 PaiDEs 在 epistemic uncertainty 估计中的优势。在每个实验 Setting 中，我们采用了 Active Learning 框架来展示 PaiDEs 的优势。<details>
<summary>Abstract</summary>
This work introduces a novel approach for epistemic uncertainty estimation for ensemble models using pairwise-distance estimators (PaiDEs). These estimators utilize the pairwise-distance between model components to establish bounds on entropy and uses said bounds as estimates for information-based criterion. Unlike recent deep learning methods for epistemic uncertainty estimation, which rely on sample-based Monte Carlo estimators, PaiDEs are able to estimate epistemic uncertainty up to 100$\times$ faster, over a larger space (up to 100$\times$) and perform more accurately in higher dimensions. To validate our approach, we conducted a series of experiments commonly used to evaluate epistemic uncertainty estimation: 1D sinusoidal data, Pendulum-v0, Hopper-v2, Ant-v2 and Humanoid-v2. For each experimental setting, an Active Learning framework was applied to demonstrate the advantages of PaiDEs for epistemic uncertainty estimation.
</details>
<details>
<summary>摘要</summary>
这个研究提出了一种新的方法来估计 ensemble 模型中的认知不确定性使用对比距离估计器（PaiDEs）。这些估计器利用对比距离来确定模型组件之间的 entropy  bound，并将这些 bound 用作信息基来的估计 criterion。与最近的深度学习方法不同，PaiDEs 可以在更大的空间（最多 100 倍）和更高维度（最多 100 倍）上更快（up to 100 倍）和更准确地估计认知不确定性。为验证我们的方法，我们进行了一系列通常用于评估认知不确定性估计的实验：1D 振荡数据、Pendulum-v0、Hopper-v2、Ant-v2 和 Humanoid-v2。对每个实验设置，我们应用了活动学习框架来展示 PaiDEs 在认知不确定性估计中的优势。
</details></li>
</ul>
<hr>
<h2 id="Open-Gaze-An-Open-Source-Implementation-Replicating-Google’s-Eye-Tracking-Paper"><a href="#Open-Gaze-An-Open-Source-Implementation-Replicating-Google’s-Eye-Tracking-Paper" class="headerlink" title="Open Gaze: An Open-Source Implementation Replicating Google’s Eye Tracking Paper"></a>Open Gaze: An Open-Source Implementation Replicating Google’s Eye Tracking Paper</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13495">http://arxiv.org/abs/2308.13495</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sushmanth reddy Mereddy, Jyothi Swaroop Reddy, Somnath Sharma<br>for:This paper aims to develop an open-source implementation of a smartphone-based gaze tracker that can accurately track eye movements without the need for specialized hardware.methods:The authors use machine learning techniques to develop an eye tracking solution that is native to smartphones, and they validate their approach using the MIT GazeCapture dataset.results:The authors demonstrate that their approach can accurately track eye movements during natural image observation and reading comprehension tasks, and they show that their smartphone-based gaze tracker is comparable in accuracy to state-of-the-art mobile eye trackers that are two orders of magnitude more expensive.<details>
<summary>Abstract</summary>
Eye tracking has been a pivotal tool in diverse fields such as vision research, language analysis, and usability assessment. The majority of prior investigations, however, have concentrated on expansive desktop displays employing specialized, costly eye tracking hardware that lacks scalability. Remarkably little insight exists into ocular movement patterns on smartphones, despite their widespread adoption and significant usage. In this manuscript, we present an open-source implementation of a smartphone-based gaze tracker that emulates the methodology proposed by a GooglePaper (whose source code remains proprietary). Our focus is on attaining accuracy comparable to that attained through the GooglePaper's methodology, without the necessity for supplementary hardware. Through the integration of machine learning techniques, we unveil an accurate eye tracking solution that is native to smartphones. Our approach demonstrates precision akin to the state-of-the-art mobile eye trackers, which are characterized by a cost that is two orders of magnitude higher. Leveraging the vast MIT GazeCapture dataset, which is available through registration on the dataset's website, we successfully replicate crucial findings from previous studies concerning ocular motion behavior in oculomotor tasks and saliency analyses during natural image observation. Furthermore, we emphasize the applicability of smartphone-based gaze tracking in discerning reading comprehension challenges. Our findings exhibit the inherent potential to amplify eye movement research by significant proportions, accommodating participation from thousands of subjects with explicit consent. This scalability not only fosters advancements in vision research, but also extends its benefits to domains such as accessibility enhancement and healthcare applications.
</details>
<details>
<summary>摘要</summary>
眼动跟踪技术已经在多个领域得到广泛应用，如视觉研究、语言分析和用户体验评估。然而，大多数前期研究都集中在使用特殊、昂贵的桌面显示器上进行眼动跟踪，lacking scalability。尚未得到充分的研究对于智能手机上的眼动跟踪，尽管智能手机的普及和使用率很高。在这篇文章中，我们提供了一个开源实现的智能手机基于眼动跟踪器，基于Google文献（其源代码尚未公开）的方法论。我们的注重点在于实现与Google文献的方法论相同的准确性，不需要额外的硬件。通过机器学习技术的 интеграción，我们提出了一种Native to smartphones的眼动跟踪解决方案。我们的方法与状态 искусственный智能手机眼动跟踪器相比，具有更高的准确性和可扩展性。基于MIT GazeCapture数据集，我们成功复制了先前研究中关于眼动行为在视觉任务和自然图像观看中的关键发现。此外，我们强调了智能手机基于眼动跟踪在了解阅读挑战中的应用。我们的发现表明了智能手机基于眼动跟踪的潜在潜力，可以提高眼动研究的进步，并扩展到访问ibilty enhancement和医疗应用领域。
</details></li>
</ul>
<hr>
<h2 id="Ultrafast-and-Ultralight-ConvNet-Based-Intelligent-Monitoring-System-for-Diagnosing-Early-Stage-Mpox-Anytime-and-Anywhere"><a href="#Ultrafast-and-Ultralight-ConvNet-Based-Intelligent-Monitoring-System-for-Diagnosing-Early-Stage-Mpox-Anytime-and-Anywhere" class="headerlink" title="Ultrafast-and-Ultralight ConvNet-Based Intelligent Monitoring System for Diagnosing Early-Stage Mpox Anytime and Anywhere"></a>Ultrafast-and-Ultralight ConvNet-Based Intelligent Monitoring System for Diagnosing Early-Stage Mpox Anytime and Anywhere</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13492">http://arxiv.org/abs/2308.13492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubiao Yue, Xiaoqiang Shi, Li Qin, Xinyue Zhang, Yanmei Chen, Jialong Xu, Zipei Zheng, Yujun Cao, Di Liu, Zhenzhang Li, Yang Li<br>for:The paper aims to develop a real-time diagnostic tool for monkeypox, addressing the lack of efficient diagnostic tools and the challenges of high inference speed, large parameter size, and limited diagnosis performance for early-stage monkeypox.methods:The proposed method, Fast-MpoxNet, is an ultrafast and ultralight deep learning network that integrates attention-based feature fusion and multiple auxiliary losses enhancement. It uses transfer learning and five-fold cross-validation, achieving 94.26% Accuracy on the Mpox dataset with a recall of 93.65% for early-stage monkeypox.results:Fast-MpoxNet achieves high accuracy and practicality in real-time diagnosis, with an Accuracy of 98.40% and a Practicality Score of 0.80 when adopting data augmentation. An application system named Mpox-AISM V2 was also developed for both personal computers and mobile phones, featuring ultrafast responses, offline functionality, and easy deployment. The proposed method has the potential to mitigate future monkeypox outbreaks and provide a new paradigm for developing real-time diagnostic tools in the healthcare field.<details>
<summary>Abstract</summary>
Due to the lack of more efficient diagnostic tools for monkeypox, its spread remains unchecked, presenting a formidable challenge to global health. While the high efficacy of deep learning models for monkeypox diagnosis has been demonstrated in related studies, the overlook of inference speed, the parameter size and diagnosis performance for early-stage monkeypox renders the models inapplicable in real-world settings. To address these challenges, we proposed an ultrafast and ultralight network named Fast-MpoxNet. Fast-MpoxNet possesses only 0.27M parameters and can process input images at 68 frames per second (FPS) on the CPU. To counteract the diagnostic performance limitation brought about by the small model capacity, it integrates the attention-based feature fusion module and the multiple auxiliary losses enhancement strategy for better detecting subtle image changes and optimizing weights. Using transfer learning and five-fold cross-validation, Fast-MpoxNet achieves 94.26% Accuracy on the Mpox dataset. Notably, its recall for early-stage monkeypox achieves 93.65%. By adopting data augmentation, our model's Accuracy rises to 98.40% and attains a Practicality Score (A new metric for measuring model practicality in real-time diagnosis application) of 0.80. We also developed an application system named Mpox-AISM V2 for both personal computers and mobile phones. Mpox-AISM V2 features ultrafast responses, offline functionality, and easy deployment, enabling accurate and real-time diagnosis for both the public and individuals in various real-world settings, especially in populous settings during the outbreak. Our work could potentially mitigate future monkeypox outbreak and illuminate a fresh paradigm for developing real-time diagnostic tools in the healthcare field.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-Optimal-Head-to-head-Autonomous-Racing-with-Curriculum-Reinforcement-Learning"><a href="#Towards-Optimal-Head-to-head-Autonomous-Racing-with-Curriculum-Reinforcement-Learning" class="headerlink" title="Towards Optimal Head-to-head Autonomous Racing with Curriculum Reinforcement Learning"></a>Towards Optimal Head-to-head Autonomous Racing with Curriculum Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13491">http://arxiv.org/abs/2308.13491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dvij Kalaria, Qin Lin, John M. Dolan</li>
<li>for: 本研究旨在提出一个头阵自动赛车环境，以便使用循环学习学习出最佳政策。</li>
<li>methods: 本研究使用了curriculum learning和安全循环学习算法，从 simpler vehicle model 逐渐转移到更加复杂的real environment，以教导循环学习代理人一个更加优化的政策。</li>
<li>results: 本研究的结果显示，使用curriculum learning和安全循环学习算法可以更加有效地将循环学习代理人训练到更加优化的政策，并且能够更加安全地进行训练。<details>
<summary>Abstract</summary>
Head-to-head autonomous racing is a challenging problem, as the vehicle needs to operate at the friction or handling limits in order to achieve minimum lap times while also actively looking for strategies to overtake/stay ahead of the opponent. In this work we propose a head-to-head racing environment for reinforcement learning which accurately models vehicle dynamics. Some previous works have tried learning a policy directly in the complex vehicle dynamics environment but have failed to learn an optimal policy. In this work, we propose a curriculum learning-based framework by transitioning from a simpler vehicle model to a more complex real environment to teach the reinforcement learning agent a policy closer to the optimal policy. We also propose a control barrier function-based safe reinforcement learning algorithm to enforce the safety of the agent in a more effective way while not compromising on optimality.
</details>
<details>
<summary>摘要</summary>
HEAD-TO-HEAD自动赛车是一个复杂的问题，车辆需要在摩擦或控制限制下运行，以实现最低圈速并同时积极寻找超越或保持领先的策略。在这项工作中，我们提出了一个真实精度模型车辆动力学环境的HEAD-TO-HEAD赛车环境。一些前一次的工作已经尝试直接在复杂的车辆动力学环境中学习策略，但未能学习优化策略。在这项工作中，我们提出了一种学习纲程学习框架，从一个更加简单的车辆模型转移到更加复杂的真实环境，以教育学习代理更近似于优化策略。我们还提出了一种基于控制障碍函数的安全学习算法，以更有效地保证代理的安全性，不会影响优化性。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Uncertainty-Localization-to-Enable-Human-in-the-loop-Analysis-of-Dynamic-Contrast-enhanced-Cardiac-MRI-Datasets"><a href="#Temporal-Uncertainty-Localization-to-Enable-Human-in-the-loop-Analysis-of-Dynamic-Contrast-enhanced-Cardiac-MRI-Datasets" class="headerlink" title="Temporal Uncertainty Localization to Enable Human-in-the-loop Analysis of Dynamic Contrast-enhanced Cardiac MRI Datasets"></a>Temporal Uncertainty Localization to Enable Human-in-the-loop Analysis of Dynamic Contrast-enhanced Cardiac MRI Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13488">http://arxiv.org/abs/2308.13488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dilek M. Yalcinkaya, Khalid Youssef, Bobak Heydari, Orlando Simonetti, Rohan Dharmakumar, Subha Raman, Behzad Sharif</li>
<li>for: 这个论文的目的是提出一种基于深度神经网络的动态质量控制（dQC）工具，用于识别DCE-CMRI数据集分割失败的情况。</li>
<li>methods: 这个论文使用的方法包括DCE-CMRI数据分割、深度神经网络分割和人工征化约束。</li>
<li>results: 研究发现，使用提出的dQC工具可以准确地识别分割失败的情况，并且可以提高分割结果的准确率和减少分割失败的数量。<details>
<summary>Abstract</summary>
Dynamic contrast-enhanced (DCE) cardiac magnetic resonance imaging (CMRI) is a widely used modality for diagnosing myocardial blood flow (perfusion) abnormalities. During a typical free-breathing DCE-CMRI scan, close to 300 time-resolved images of myocardial perfusion are acquired at various contrast "wash in/out" phases. Manual segmentation of myocardial contours in each time-frame of a DCE image series can be tedious and time-consuming, particularly when non-rigid motion correction has failed or is unavailable. While deep neural networks (DNNs) have shown promise for analyzing DCE-CMRI datasets, a "dynamic quality control" (dQC) technique for reliably detecting failed segmentations is lacking. Here we propose a new space-time uncertainty metric as a dQC tool for DNN-based segmentation of free-breathing DCE-CMRI datasets by validating the proposed metric on an external dataset and establishing a human-in-the-loop framework to improve the segmentation results. In the proposed approach, we referred the top 10% most uncertain segmentations as detected by our dQC tool to the human expert for refinement. This approach resulted in a significant increase in the Dice score (p<0.001) and a notable decrease in the number of images with failed segmentation (16.2% to 11.3%) whereas the alternative approach of randomly selecting the same number of segmentations for human referral did not achieve any significant improvement. Our results suggest that the proposed dQC framework has the potential to accurately identify poor-quality segmentations and may enable efficient DNN-based analysis of DCE-CMRI in a human-in-the-loop pipeline for clinical interpretation and reporting of dynamic CMRI datasets.
</details>
<details>
<summary>摘要</summary>
对 Dynamic Contrast-Enhanced (DCE) Cardiac Magnetic Resonance Imaging (CMRI) 诊断Myocardial Blood Flow (Perfusion) 异常，通常需要获取约 300 个时间分解的Myocardial Perfusion 影像，并在不同的对比“洗入/洗出”阶段进行评估。然而，手动分类Myocardial 边析在每个时间点的DCE影像系列可以是时间consuming 和耗时consuming，尤其是当非静态运动调整失败或无法使用时。深度神经网 (DNNs) 已经显示出了分析 DCE-CMRI 数据的潜力，但是一个“动态品质控制” (dQC) 技术来可靠地检测失败的分类是缺乏的。我们提出了一个新的空间时间不确定度量来作为 dQC 工具，并在一个人际loop 框架中进行改进。在我们的方法中，我们将top 10% 最不确定的分类作为 dQC 工具所检测的，并请求人工专家进行重新分类。这种方法导致了 Dice 分数的增加（p < 0.001）和失败分类的数量的下降（16.2% 到 11.3%），而对照方法，将相同数量的分类 randomly 选择进行人工参考，无法获得任何有意义的改善。我们的结果表明，我们的 dQC 框架具有可靠地检测失败分类的潜力，并且可以实现人际loop pipeline中的有效 DNN-based 分析 DCE-CMRI 数据，以便在诊断和报告动态 CMRI 数据时提供有用的资讯。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Knowledge-and-Reinforcement-Learning-for-Enhanced-Reliability-of-Language-Models"><a href="#Leveraging-Knowledge-and-Reinforcement-Learning-for-Enhanced-Reliability-of-Language-Models" class="headerlink" title="Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models"></a>Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13467">http://arxiv.org/abs/2308.13467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nancy Tyagi, Surjodeep Sarkar, Manas Gaur</li>
<li>for: 这个论文是为了提高现代语言模型（如BERT）的可靠性和准确性而写的。</li>
<li>methods: 这个论文使用了人工智能的集成学习方法，利用了ConceptNet和Wikipedia的知识图谱嵌入，以强化语言模型的可靠性和准确性。</li>
<li>results: 研究表明，使用这种知识导向集成学习方法可以提高语言模型的可靠性和准确性，在九个GLUE任务上都有出色的表现，超越了现有的最佳实现。<details>
<summary>Abstract</summary>
The Natural Language Processing(NLP) community has been using crowd sourcing techniques to create benchmark datasets such as General Language Understanding and Evaluation(GLUE) for training modern Language Models such as BERT. GLUE tasks measure the reliability scores using inter annotator metrics i.e. Cohens Kappa. However, the reliability aspect of LMs has often been overlooked. To counter this problem, we explore a knowledge-guided LM ensembling approach that leverages reinforcement learning to integrate knowledge from ConceptNet and Wikipedia as knowledge graph embeddings. This approach mimics human annotators resorting to external knowledge to compensate for information deficits in the datasets. Across nine GLUE datasets, our research shows that ensembling strengthens reliability and accuracy scores, outperforming state of the art.
</details>
<details>
<summary>摘要</summary>
natural language processing（NLP）社区已经使用人群SOURCING技术创建了通用语言理解和评估（GLUE）测试集，用于训练现代语言模型（BERT）。GLUE任务测试语言模型的可靠性使用互annotator metric，即科恩斯均度。然而，语言模型的可靠性问题经常被忽略。为解决这个问题，我们研究了一种基于知识图谱Embedding的知识导向语言模型集成方法。这种方法模拟人工注解者通过外部知识补做信息缺乏的数据集。在九个GLUE任务上，我们的研究表明，集成可以提高可靠性和准确率，超过当前最佳。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/26/cs.AI_2023_08_26/" data-id="clohum9360035pj882ldbacxf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/26/cs.CL_2023_08_26/" class="article-date">
  <time datetime="2023-08-26T11:00:00.000Z" itemprop="datePublished">2023-08-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/26/cs.CL_2023_08_26/">cs.CL - 2023-08-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Training-and-Meta-Evaluating-Machine-Translation-Evaluation-Metrics-at-the-Paragraph-Level"><a href="#Training-and-Meta-Evaluating-Machine-Translation-Evaluation-Metrics-at-the-Paragraph-Level" class="headerlink" title="Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level"></a>Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13506">http://arxiv.org/abs/2308.13506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Deutsch, Juraj Juraska, Mara Finkelstein, and Markus Freitag</li>
<li>for: 这个研究的目的是为了评估自动译文件翻译文本的效果，并不是只是评估单句翻译。</li>
<li>methods: 这篇论文提出了一种方法，即使用现有的句子级评估数据来创建段落级数据，并将这些数据用于训练和meta-评估评价指标。</li>
<li>results: 实验结果表明，使用句子级评估指标来评估整个段落的效果与使用专门为段落级设计的指标相当有效。<details>
<summary>Abstract</summary>
As research on machine translation moves to translating text beyond the sentence level, it remains unclear how effective automatic evaluation metrics are at scoring longer translations. In this work, we first propose a method for creating paragraph-level data for training and meta-evaluating metrics from existing sentence-level data. Then, we use these new datasets to benchmark existing sentence-level metrics as well as train learned metrics at the paragraph level. Interestingly, our experimental results demonstrate that using sentence-level metrics to score entire paragraphs is equally as effective as using a metric designed to work at the paragraph level. We speculate this result can be attributed to properties of the task of reference-based evaluation as well as limitations of our datasets with respect to capturing all types of phenomena that occur in paragraph-level translations.
</details>
<details>
<summary>摘要</summary>
研究在机器翻译中延伸到文段级别的文本翻译效果，然而现有自动评价指标的有效性在长文段翻译方面仍然不清楚。在这项工作中，我们首先提出了将现有句子级数据转化为训练和Meta评价指标的方法。然后，我们使用这些新的数据集来评估现有的句子级指标以及在 paragraph 级别进行学习的指标。实验结果显示，使用句子级指标评估整个文段的效果与使用特制的 paragraph 级指标相当。我们推测这些结果可能是由评估任务的特性以及我们数据集中捕捉到的所有类型的现象所致。
</details></li>
</ul>
<hr>
<h2 id="Ngambay-French-Neural-Machine-Translation-sba-Fr"><a href="#Ngambay-French-Neural-Machine-Translation-sba-Fr" class="headerlink" title="Ngambay-French Neural Machine Translation (sba-Fr)"></a>Ngambay-French Neural Machine Translation (sba-Fr)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13497">http://arxiv.org/abs/2308.13497</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Toadoum/Ngambay-French-Neural-Machine-Translation-sba_fr_v1-">https://github.com/Toadoum/Ngambay-French-Neural-Machine-Translation-sba_fr_v1-</a></li>
<li>paper_authors: Sakayo Toadoum Sari, Angela Fan, Lema Logamou Seknewna</li>
<li>for: 本研究旨在开发一个基于神经机器翻译（NMT）系统，以推动语言障碍的缓解。特别是在语言资源匮乏的情况下，NMT 系统的研发成为了一项感兴趣的话题。</li>
<li>methods: 本研究使用了三个预训练模型进行了微调，并使用了一个自适应的数据采集方法来生成训练数据。</li>
<li>results: 实验结果显示，使用 M2M100 模型可以在原始数据和原始+ sintetic 数据上达到高的 BLEU 分数。此外，公共可用的 bitext 数据集可以用于研究用途。<details>
<summary>Abstract</summary>
In Africa, and the world at large, there is an increasing focus on developing Neural Machine Translation (NMT) systems to overcome language barriers. NMT for Low-resource language is particularly compelling as it involves learning with limited labelled data. However, obtaining a well-aligned parallel corpus for low-resource languages can be challenging. The disparity between the technological advancement of a few global languages and the lack of research on NMT for local languages in Chad is striking. End-to-end NMT trials on low-resource Chad languages have not been attempted. Additionally, there is a dearth of online and well-structured data gathering for research in Natural Language Processing, unlike some African languages. However, a guided approach for data gathering can produce bitext data for many Chadian language translation pairs with well-known languages that have ample data. In this project, we created the first sba-Fr Dataset, which is a corpus of Ngambay-to-French translations, and fine-tuned three pre-trained models using this dataset. Our experiments show that the M2M100 model outperforms other models with high BLEU scores on both original and original+synthetic data. The publicly available bitext dataset can be used for research purposes.
</details>
<details>
<summary>摘要</summary>
在非洲和世界上，有越来越多的关注发展神经机器翻译（NMT）系统，以超越语言障碍。NMT для低资源语言特别有吸引力，因为它涉及到有限的标注数据学习。然而，获得低资源语言的高质量并行数据可以是挑战。非洲语言技术发展落差和中非的语言研究欠缺是惊人的。在毫不计入End-to-end NMT实验中，有些非洲语言的翻译还没有尝试。此外，在自然语言处理领域的在线和结构化数据收集也比较缺乏，与一些非洲语言不同。然而，一种引导的方法可以生成许多中非语言翻译对的数据，并且可以使用已知语言的丰富数据进行精度调整。在本项目中，我们创建了第一个sba-FrDataset，它是一个 Ngambay-to-French 翻译 corpus，并使用这个数据集进行三个预训练模型的精度调整。我们的实验表明，M2M100模型在原始和原始+ sintetic 数据上的 BLEU 分数均高于其他模型。公共可用的 bitext 数据集可以用于研究purposes。
</details></li>
</ul>
<hr>
<h2 id="Prompting-a-Large-Language-Model-to-Generate-Diverse-Motivational-Messages-A-Comparison-with-Human-Written-Messages"><a href="#Prompting-a-Large-Language-Model-to-Generate-Diverse-Motivational-Messages-A-Comparison-with-Human-Written-Messages" class="headerlink" title="Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages"></a>Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13479">http://arxiv.org/abs/2308.13479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Rhys Cox, Ashraf Abdul, Wei Tsang Ooi</li>
<li>for: 这个论文旨在探讨大语言模型（LLM）可以如何用于创作内容，以及使用特定指令可以提高LLM的创作质量。</li>
<li>methods: 该论文使用了一个以前的人群劳动任务管道，用于生成一个多样化的motivational message corpus。然后，该管道被用来生成消息，并与人群写作者和两个基线GPT-4提示进行比较。</li>
<li>results: 研究发现，使用人群劳动任务管道作为LLM提示可以使GPT-4生成更多样化的消息，比两个基线提示更好。此外，论文还讨论了由人类写作者和LLM生成的消息之间的对比。<details>
<summary>Abstract</summary>
Large language models (LLMs) are increasingly capable and prevalent, and can be used to produce creative content. The quality of content is influenced by the prompt used, with more specific prompts that incorporate examples generally producing better results. On from this, it could be seen that using instructions written for crowdsourcing tasks (that are specific and include examples to guide workers) could prove effective LLM prompts. To explore this, we used a previous crowdsourcing pipeline that gave examples to people to help them generate a collectively diverse corpus of motivational messages. We then used this same pipeline to generate messages using GPT-4, and compared the collective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the pipeline, and (3 & 4) two baseline GPT-4 prompts. We found that the LLM prompts using the crowdsourcing pipeline caused GPT-4 to produce more diverse messages than the two baseline prompts. We also discuss implications from messages generated by both human writers and LLMs.
</details>
<details>
<summary>摘要</summary>
Note: Simplified Chinese is also known as "Mandarin" or "Standard Chinese".Translation notes:* "Large language models" is translated as "大型语言模型" (dàxíng yǔyán módelǐng).* "Crowdsourcing" is translated as "人群协作" (rénqún xiézuò).* "Pipeline" is translated as "管道" (guǎndào).* "GPT-4" is translated as "GPT-4" (GPT-4).* "Baseline" is translated as "基线" (jīxiàn).* "Prompts" is translated as "提示" (tímǐ).* "Diverse" is translated as "多样的" (duōyàng de).* "Messages" is translated as "消息" (xiāoxi).Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="ARTIST-ARTificial-Intelligence-for-Simplified-Text"><a href="#ARTIST-ARTificial-Intelligence-for-Simplified-Text" class="headerlink" title="ARTIST: ARTificial Intelligence for Simplified Text"></a>ARTIST: ARTificial Intelligence for Simplified Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13458">http://arxiv.org/abs/2308.13458</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/delftcrowd/artist">https://github.com/delftcrowd/artist</a></li>
<li>paper_authors: Lorenzo Corti, Jie Yang</li>
<li>for: 本研究旨在探讨自然语言处理中的文本简化问题，以提高公共信息和知识的接入性。</li>
<li>methods: 本研究使用了最新的生成人工智能技术，包括语言模型、领域和读者适应和可见化模块，以自动简化文本的语言和结构层次。</li>
<li>results: 研究发现了自动文本简化技术的优势和局限性，包括处理文化和常识知识的挑战。这些结果代表了对荷兰文本简化的首次探索，并为未来的研究和实践提供了灯光。<details>
<summary>Abstract</summary>
Complex text is a major barrier for many citizens when accessing public information and knowledge. While often done manually, Text Simplification is a key Natural Language Processing task that aims for reducing the linguistic complexity of a text while preserving the original meaning. Recent advances in Generative Artificial Intelligence (AI) have enabled automatic text simplification both on the lexical and syntactical levels. However, as applications often focus on English, little is understood about the effectiveness of Generative AI techniques on low-resource languages such as Dutch. For this reason, we carry out empirical studies to understand the benefits and limitations of applying generative technologies for text simplification and provide the following outcomes: 1) the design and implementation for a configurable text simplification pipeline that orchestrates state-of-the-art generative text simplification models, domain and reader adaptation, and visualisation modules; 2) insights and lessons learned, showing the strengths of automatic text simplification while exposing the challenges in handling cultural and commonsense knowledge. These outcomes represent a first step in the exploration of Dutch text simplification and shed light on future endeavours both for research and practice.
</details>
<details>
<summary>摘要</summary>
各种复杂的文本是公共信息和知识访问的主要障碍。虽然经常是手动完成的，但文本简化是自然语言处理任务的关键任务，旨在降低文本语言复杂性，保留原始意思。现代生成人工智能技术（AI）已经使得自动文本简化在语言和语法层次上自动进行。然而，应用常focus on英语，对低资源语言如荷兰语的应用知之甚少。为了了解生成技术在文本简化中的效果和限制，我们进行了实践研究，并提供以下结果： 1）设计和实现一个可配置的文本简化管道，该管道将state-of-the-art生成文本简化模型、领域和读者适应、视觉模块相互协调。 2）对 automatic文本简化的发现和经验，包括自动简化的优势和处理文化和常识知识的挑战。这些结果代表了对荷兰文本简化的首次探索，并照亮未来的研究和实践的前景。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/26/cs.CL_2023_08_26/" data-id="clohum954009qpj888vcs7gwi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/26/cs.LG_2023_08_26/" class="article-date">
  <time datetime="2023-08-26T10:00:00.000Z" itemprop="datePublished">2023-08-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/26/cs.LG_2023_08_26/">cs.LG - 2023-08-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Unveiling-the-Role-of-Message-Passing-in-Dual-Privacy-Preservation-on-GNNs"><a href="#Unveiling-the-Role-of-Message-Passing-in-Dual-Privacy-Preservation-on-GNNs" class="headerlink" title="Unveiling the Role of Message Passing in Dual-Privacy Preservation on GNNs"></a>Unveiling the Role of Message Passing in Dual-Privacy Preservation on GNNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13513">http://arxiv.org/abs/2308.13513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyi Zhao, Hui Hu, Lu Cheng</li>
<li>for: This paper aims to address the privacy leakage issue in Graph Neural Networks (GNNs) and propose a principled privacy-preserving GNN framework.</li>
<li>methods: The proposed framework consists of three major modules: Sensitive Information Obfuscation Module, Dynamic Structure Debiasing Module, and Adversarial Learning Module.</li>
<li>results: Experimental results on four benchmark datasets show that the proposed model effectively protects both node and link privacy while preserving high utility for downstream tasks such as node classification.<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) are powerful tools for learning representations on graphs, such as social networks. However, their vulnerability to privacy inference attacks restricts their practicality, especially in high-stake domains. To address this issue, privacy-preserving GNNs have been proposed, focusing on preserving node and/or link privacy. This work takes a step back and investigates how GNNs contribute to privacy leakage. Through theoretical analysis and simulations, we identify message passing under structural bias as the core component that allows GNNs to \textit{propagate} and \textit{amplify} privacy leakage. Building upon these findings, we propose a principled privacy-preserving GNN framework that effectively safeguards both node and link privacy, referred to as dual-privacy preservation. The framework comprises three major modules: a Sensitive Information Obfuscation Module that removes sensitive information from node embeddings, a Dynamic Structure Debiasing Module that dynamically corrects the structural bias, and an Adversarial Learning Module that optimizes the privacy-utility trade-off. Experimental results on four benchmark datasets validate the effectiveness of the proposed model in protecting both node and link privacy while preserving high utility for downstream tasks, such as node classification.
</details>
<details>
<summary>摘要</summary>
格raph神经网络（GNNs）是一种强大的图像学习工具，可以在社交网络等图像上学习表示。然而，它们的隐私泄露攻击限制了它们在高风险领域的实际应用。为解决这个问题，隐私保护GNNs被提出，重点保护节点和/或连接的隐私。本工作从另一个角度研究GNNs如何导致隐私泄露。通过理论分析和实验，我们发现了 message passing under structural bias 是 GNNs 中最重要的泄露扩散和强化因素。基于这些发现，我们提出了一种理解隐私保护的 GNN 框架，称为 dual-privacy preservation。该框架包括三个主要模块：敏感信息干扰模块、动态结构偏置修正模块和对抗学习模块。实验结果表明，提出的模型可以保护节点和连接的隐私，同时保持下游任务的高用户性。
</details></li>
</ul>
<hr>
<h2 id="TpuGraphs-A-Performance-Prediction-Dataset-on-Large-Tensor-Computational-Graphs"><a href="#TpuGraphs-A-Performance-Prediction-Dataset-on-Large-Tensor-Computational-Graphs" class="headerlink" title="TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs"></a>TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13490">http://arxiv.org/abs/2308.13490</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research-datasets/tpu_graphs">https://github.com/google-research-datasets/tpu_graphs</a></li>
<li>paper_authors: Phitchaya Mangpo Phothilimthana, Sami Abu-El-Haija, Kaidi Cao, Bahare Fatemi, Charith Mendis, Bryan Perozzi</li>
<li>for: 这篇论文的目的是提供一个大型计算图论文性能预测数据集，用于优化机器学习编译器和自动调整器。</li>
<li>methods: 这篇论文使用了计算图来表示机器学习工作负荷，并收集了来自开源机器学习项目的各种模型架构。</li>
<li>results: 这篇论文提出了一个大型计算图论文性能预测数据集（TPuGraphs），其中每个图表示一个主要计算任务，例如训练epoch或推理步骤。该数据集包含25倍以上的图数据，770倍以上的图 сред值大小，并且引入了新的挑战，如扩展性、训练效率和模型质量。<details>
<summary>Abstract</summary>
Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10-20% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TpuGraphs, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the dataset are collected from open-source machine learning programs, featuring popular model architectures, e.g., ResNet, EfficientNet, Mask R-CNN, and Transformer. TpuGraphs provides 25x more graphs than the largest graph property prediction dataset (with comparable graph sizes), and 770x larger graphs on average compared to existing performance prediction datasets on machine learning programs. This graph-level prediction task on large graphs introduces new challenges in learning, ranging from scalability, training efficiency, to model quality.
</details>
<details>
<summary>摘要</summary>
精准硬件性能模型在代码优化中扮演着关键的角色。它们可以帮助编译器做出优化决策，或者帮助自动调整器确定程序的最佳配置。例如，XLA的自动调整器在处理大规模生产流量时发现了10-20%的提升。虽然有一些程序性能预测数据集存在，但它们主要针对小型子程序，如基本块或kernels。这篇文章介绍了TpuGraphs，一个基于计算图的程序性能预测数据集，运行在tensor处理单元（TPU）上。每个图像在数据集中表示了机器学习工作负荷的主要计算，例如训练epoch或推理步骤。每个数据样本包含一个计算图、一个编译配置和图像的执行时间。数据集中的图像来自开源机器学习程序，包括受欢迎的模型架构，如ResNet、EfficientNet、Mask R-CNN和Transformer。TpuGraphs提供了25倍更多的图像，并770倍更大的图像平均大小，相比已有的机器学习程序性能预测数据集。这个图级预测任务中的大图学习问题 introduce了新的挑战，从扩展性、培训效率、模型质量等方面。
</details></li>
</ul>
<hr>
<h2 id="Staleness-Alleviated-Distributed-GNN-Training-via-Online-Dynamic-Embedding-Prediction"><a href="#Staleness-Alleviated-Distributed-GNN-Training-via-Online-Dynamic-Embedding-Prediction" class="headerlink" title="Staleness-Alleviated Distributed GNN Training via Online Dynamic-Embedding Prediction"></a>Staleness-Alleviated Distributed GNN Training via Online Dynamic-Embedding Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.13466">http://arxiv.org/abs/2308.13466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangji Bai, Ziyang Yu, Zheng Chai, Yue Cheng, Liang Zhao</li>
<li>for: 这篇论文是为了解决Graph Neural Networks（GNNs）在大规模图上的训练中的难点，特别是难以同步多个节点的问题。</li>
<li>methods: 这篇论文使用了分布式计算来解决这个问题，并且使用了历史值推断来实现高并发性。</li>
<li>results: 这篇论文提出了一个名为SAT（Staleness-Alleviated Training）的新的分布式GNN训练框架，可以有效地减少节点嵌入缓存的旧化。实验结果显示，SAT可以实现更好的性能和训练速度在多个大规模图数据集上。<details>
<summary>Abstract</summary>
Despite the recent success of Graph Neural Networks (GNNs), it remains challenging to train GNNs on large-scale graphs due to neighbor explosions. As a remedy, distributed computing becomes a promising solution by leveraging abundant computing resources (e.g., GPU). However, the node dependency of graph data increases the difficulty of achieving high concurrency in distributed GNN training, which suffers from the massive communication overhead. To address it, Historical value approximation is deemed a promising class of distributed training techniques. It utilizes an offline memory to cache historical information (e.g., node embedding) as an affordable approximation of the exact value and achieves high concurrency. However, such benefits come at the cost of involving dated training information, leading to staleness, imprecision, and convergence issues. To overcome these challenges, this paper proposes SAT (Staleness-Alleviated Training), a novel and scalable distributed GNN training framework that reduces the embedding staleness adaptively. The key idea of SAT is to model the GNN's embedding evolution as a temporal graph and build a model upon it to predict future embedding, which effectively alleviates the staleness of the cached historical embedding. We propose an online algorithm to train the embedding predictor and the distributed GNN alternatively and further provide a convergence analysis. Empirically, we demonstrate that SAT can effectively reduce embedding staleness and thus achieve better performance and convergence speed on multiple large-scale graph datasets.
</details>
<details>
<summary>摘要</summary>
尽管 Graf Neural Networks (GNNs) 的最近成功，但是在大规模图上训练 GNNs 仍然具有挑战，主要是因为邻居爆炸。为了解决这问题，分布式计算成为了一种有前途的解决方案，利用了丰富的计算资源（例如 GPU）。然而，图数据中节点的依赖关系使得在分布式 GNN 训练中达到高并发性变得更加困难，这会导致巨大的通信开销。为了解决这个问题，历史值 aproximation 被视为一种有前途的分布式训练技术。它利用了一个缓存历史信息（例如节点嵌入）作为可以Affordable的近似值，并实现了高并发性。然而，这些利点来自于使用过时的训练信息，导致偏斜、不准确和融合问题。为了解决这些挑战，本文提出了 SAT（Staleness-Alleviated Training），一种新的和可扩展的分布式 GNN 训练框架。SAT 的关键思想是模型 GNN 的嵌入演化为一个 temporal graph，并建立一个模型来预测未来的嵌入，从而有效地减轻嵌入缓存的过时性。我们提出了一种在线算法来训练嵌入预测器和分布式 GNN  alternatively，并提供了一种融合分析。实验表明，SAT 可以有效地减轻嵌入缓存的过时性，从而实现更好的性能和融合速度在多个大规模图数据集上。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/26/cs.LG_2023_08_26/" data-id="clohum99f00ndpj884zjj5zzm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/46/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/45/">45</a><a class="page-number" href="/page/46/">46</a><span class="page-number current">47</span><a class="page-number" href="/page/48/">48</a><a class="page-number" href="/page/49/">49</a><span class="space">&hellip;</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/48/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
