
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/65/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_07_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/28/cs.CV_2023_07_28/" class="article-date">
  <time datetime="2023-07-28T13:00:00.000Z" itemprop="datePublished">2023-07-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/28/cs.CV_2023_07_28/">cs.CV - 2023-07-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="TriadNet-Sampling-free-predictive-intervals-for-lesional-volume-in-3D-brain-MR-images"><a href="#TriadNet-Sampling-free-predictive-intervals-for-lesional-volume-in-3D-brain-MR-images" class="headerlink" title="TriadNet: Sampling-free predictive intervals for lesional volume in 3D brain MR images"></a>TriadNet: Sampling-free predictive intervals for lesional volume in 3D brain MR images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15638">http://arxiv.org/abs/2307.15638</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/benolmbrt/TriadNet">https://github.com/benolmbrt/TriadNet</a></li>
<li>paper_authors: Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat</li>
<li>for: 评估脑肿瘤（如血栓或 tumor）的体积是诊断病人状况的重要指标，可以用来导引治疗策略。</li>
<li>methods: 利用深度卷积神经网络（CNN）进行分割，目前是状态体系的方法。</li>
<li>results: 提出了TriadNet方法，可同时提供肿瘤体积和相关预测 интерVAL simultanously，仅需一秒钟。在BraTS 2021大规模 MRI glioblastoma 图像数据库上，TriadNet方法显示出优势。<details>
<summary>Abstract</summary>
The volume of a brain lesion (e.g. infarct or tumor) is a powerful indicator of patient prognosis and can be used to guide the therapeutic strategy. Lesional volume estimation is usually performed by segmentation with deep convolutional neural networks (CNN), currently the state-of-the-art approach. However, to date, few work has been done to equip volume segmentation tools with adequate quantitative predictive intervals, which can hinder their usefulness and acceptation in clinical practice. In this work, we propose TriadNet, a segmentation approach relying on a multi-head CNN architecture, which provides both the lesion volumes and the associated predictive intervals simultaneously, in less than a second. We demonstrate its superiority over other solutions on BraTS 2021, a large-scale MRI glioblastoma image database.
</details>
<details>
<summary>摘要</summary>
病变Volume (例如血栓或肿瘤) 是一个重要的病人 прогностиic indicator，可以用于导引治疗策略。 lesional volume 估计通常使用深度卷积神经网络（CNN）进行，现在是状态的方法。然而，到目前为止，有很少的工作是在 volume segmentation 工具中添加适当的量化预测范围，这会限制它们在临床实践中的使用和接受度。在这种情况下，我们提出了 TriadNet，一种基于多头CNN架构的分割方法，可以同时提供lesion volume和相关的预测范围，并且在一秒钟内完成。我们在 BraTS 2021 大规模 MRI  glioblastoma 图像数据库上展示了它的优势。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Deep-Learning-in-Medical-Image-Registration-New-Technologies-Uncertainty-Evaluation-Metrics-and-Beyond"><a href="#A-Survey-on-Deep-Learning-in-Medical-Image-Registration-New-Technologies-Uncertainty-Evaluation-Metrics-and-Beyond" class="headerlink" title="A Survey on Deep Learning in Medical Image Registration: New Technologies, Uncertainty, Evaluation Metrics, and Beyond"></a>A Survey on Deep Learning in Medical Image Registration: New Technologies, Uncertainty, Evaluation Metrics, and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15615">http://arxiv.org/abs/2307.15615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyu Chen, Yihao Liu, Shuwen Wei, Zhangxing Bian, Shalini Subramanian, Aaron Carass, Jerry L. Prince, Yong Du</li>
<li>for: 本文提供了深度学习技术在医学图像registratin中的最新进展。</li>
<li>methods: 本文提出了多种新的网络架构、特异度函数和误差估计方法，以及适用于评估深度学习模型在registratin任务中的评价指标。</li>
<li>results: 本文对deep learning-based registratin的应用进行了实质性的探讨，包括多Atlas建构、多Atlas分割、运动估计和2D-3D registratin等。<details>
<summary>Abstract</summary>
Over the past decade, deep learning technologies have greatly advanced the field of medical image registration. The initial developments, such as ResNet-based and U-Net-based networks, laid the groundwork for deep learning-driven image registration. Subsequent progress has been made in various aspects of deep learning-based registration, including similarity measures, deformation regularizations, and uncertainty estimation. These advancements have not only enriched the field of deformable image registration but have also facilitated its application in a wide range of tasks, including atlas construction, multi-atlas segmentation, motion estimation, and 2D-3D registration. In this paper, we present a comprehensive overview of the most recent advancements in deep learning-based image registration. We begin with a concise introduction to the core concepts of deep learning-based image registration. Then, we delve into innovative network architectures, loss functions specific to registration, and methods for estimating registration uncertainty. Additionally, this paper explores appropriate evaluation metrics for assessing the performance of deep learning models in registration tasks. Finally, we highlight the practical applications of these novel techniques in medical imaging and discuss the future prospects of deep learning-based image registration.
</details>
<details>
<summary>摘要</summary>
In this paper, we present a comprehensive overview of the most recent advancements in deep learning-based image registration. We begin with a concise introduction to the core concepts of deep learning-based image registration. Then, we delve into innovative network architectures, loss functions specific to registration, and methods for estimating registration uncertainty. Additionally, this paper explores appropriate evaluation metrics for assessing the performance of deep learning models in registration tasks. Finally, we highlight the practical applications of these novel techniques in medical imaging and discuss the future prospects of deep learning-based image registration.Translated into Simplified Chinese:过去十年，深度学习技术在医疗图像注册领域已经做出了很大的进步。初期的发展，如ResNet基于和U-Net基于的网络，为深度学习驱动的图像注册奠定了基础。后续的进步包括相似度量、形变规范和注册不确定性的估计等方面。这些进步不仅涌现了图像注册领域的多样性，还促进了其应用于多种任务，如建立图像 атла斯、多个 атла斯分割、运动估计和2D-3D注册等。在这篇论文中，我们提供了深度学习基于图像注册的最新进展的全面概述。我们从核心概念的入门开始，然后探讨了新的网络架构、特定于注册的损失函数和注册不确定性的估计方法。此外，这篇论文还探讨了注册任务中深度学习模型的评价指标，以及这些新技术在医疗图像中的实际应用和未来前景。
</details></li>
</ul>
<hr>
<h2 id="Integrated-Digital-Reconstruction-of-Welded-Components-Supporting-Improved-Fatigue-Life-Prediction"><a href="#Integrated-Digital-Reconstruction-of-Welded-Components-Supporting-Improved-Fatigue-Life-Prediction" class="headerlink" title="Integrated Digital Reconstruction of Welded Components: Supporting Improved Fatigue Life Prediction"></a>Integrated Digital Reconstruction of Welded Components: Supporting Improved Fatigue Life Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15604">http://arxiv.org/abs/2307.15604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anders Faarbæk Mikkelstrup, Morten Kristiansen</li>
<li>for: 提高钢结构疲劳性能</li>
<li>methods: 使用自动化高频机械冲击处理，并利用数字重建技术来改进质量和生产效率</li>
<li>results: 实现了成本效果、可重用、灵活和快速的数字重建方法，以援助Component设计、全面质量监测和HFMI处理ocumentation<details>
<summary>Abstract</summary>
In the design of offshore jacket foundations, fatigue life is crucial. Post-weld treatment has been proposed to enhance the fatigue performance of welded joints, where particularly high-frequency mechanical impact (HFMI) treatment has been shown to improve fatigue performance significantly. Automated HFMI treatment has improved quality assurance and can lead to cost-effective design when combined with accurate fatigue life prediction. However, the finite element method (FEM), commonly used for predicting fatigue life in complex or multi-axial joints, relies on a basic CAD depiction of the weld, failing to consider the actual weld geometry and defects. Including the actual weld geometry in the FE model improves fatigue life prediction and possible crack location prediction but requires a digital reconstruction of the weld. Current digital reconstruction methods are time-consuming or require specialised scanning equipment and potential component relocation. The proposed framework instead uses an industrial manipulator combined with a line scanner to integrate digital reconstruction as part of the automated HFMI treatment setup. This approach applies standard image processing, simple filtering techniques, and non-linear optimisation for aligning and merging overlapping scans. A screened Poisson surface reconstruction finalises the 3D model to create a meshed surface. The outcome is a generic, cost-effective, flexible, and rapid method that enables generic digital reconstruction of welded parts, aiding in component design, overall quality assurance, and documentation of the HFMI treatment.
</details>
<details>
<summary>摘要</summary>
在海上钻井基础设计中，疲劳寿命是关键。POST-WELD处理已经被提议来提高焊接缝合的疲劳性能，其中高频机械冲击（HFMI）处理得到了显著提高疲劳性能的结果。自动化HFMI处理可以提高质量控制和可靠性，并可以通过精准的疲劳寿命预测来实现成本效益。但是，通用的Finite Element方法（FEM），常用于预测复杂或多轴缝合的疲劳寿命，基于焊接部的基本CAD描述，而不考虑实际焊接geometry和缺陷。包含实际焊接geometry在FEM模型中可以提高疲劳寿命预测和可能的裂解位置预测，但需要对焊接部进行数字重建。现有的数字重建方法有时间consuming或需要特殊的扫描设备，并且可能需要部件重新位置。提案的框架使用工业机械人与线扫描器结合来集成数字重建作为自动HFMI处理设置的一部分。这种方法使用标准的图像处理、简单的滤波技术和非线性优化来对 overlap的扫描进行协调和拼接。一个屏幕化的波峰表面重建最后生成3D模型，以创建一个可重用、成本效益、灵活的方法，以帮助 generic数字重建焊接部件，以便于组件设计、总质量控制和HFMI处理的文档。
</details></li>
</ul>
<hr>
<h2 id="OAFuser-Towards-Omni-Aperture-Fusion-for-Light-Field-Semantic-Segmentation-of-Road-Scenes"><a href="#OAFuser-Towards-Omni-Aperture-Fusion-for-Light-Field-Semantic-Segmentation-of-Road-Scenes" class="headerlink" title="OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic Segmentation of Road Scenes"></a>OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic Segmentation of Road Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15588">http://arxiv.org/abs/2307.15588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/feibryantkit/oafuser">https://github.com/feibryantkit/oafuser</a></li>
<li>paper_authors: Fei Teng, Jiaming Zhang, Kunyu Peng, Kailun Yang, Yaonan Wang, Rainer Stiefelhagen</li>
<li>for: 提高自动驾驶场景理解的图像semantic segmentation，利用光场相机提供的丰富的角度和空间信息。</li>
<li>methods: 提出Omni-Aperture Fusion模型（OAFuser），利用中心视图的dense Context和子镜头图像中的角度信息生成semantically-consistent的结果，并提出Sub-Aperture Fusion Module（SAFM）来嵌入子镜头图像到角度特征中，无需额外存储成本。</li>
<li>results: 在UrbanLF-Real和-Syn数据集上达到了当前最佳性能，mIoU达84.93%，与原始数据集上的最佳性能增加+4.53%。<details>
<summary>Abstract</summary>
Light field cameras can provide rich angular and spatial information to enhance image semantic segmentation for scene understanding in the field of autonomous driving. However, the extensive angular information of light field cameras contains a large amount of redundant data, which is overwhelming for the limited hardware resource of intelligent vehicles. Besides, inappropriate compression leads to information corruption and data loss. To excavate representative information, we propose an Omni-Aperture Fusion model (OAFuser), which leverages dense context from the central view and discovers the angular information from sub-aperture images to generate a semantically-consistent result. To avoid feature loss during network propagation and simultaneously streamline the redundant information from the light field camera, we present a simple yet very effective Sub-Aperture Fusion Module (SAFM) to embed sub-aperture images into angular features without any additional memory cost. Furthermore, to address the mismatched spatial information across viewpoints, we present Center Angular Rectification Module (CARM) realized feature resorting and prevent feature occlusion caused by asymmetric information. Our proposed OAFuser achieves state-of-the-art performance on the UrbanLF-Real and -Syn datasets and sets a new record of 84.93% in mIoU on the UrbanLF-Real Extended dataset, with a gain of +4.53%. The source code of OAFuser will be made publicly available at https://github.com/FeiBryantkit/OAFuser.
</details>
<details>
<summary>摘要</summary>
光场相机可以提供丰富的angular和空间信息，以提高自动驾驶场景理解。然而，广泛的angular信息光场相机包含大量的重复数据，对智能汽车硬件资源的限制是过载。此外，不当压缩会导致信息损害和数据损失。为了挖掘代表性信息，我们提出了 Omni-Aperture Fusion 模型（OAFuser），它利用中心视图的 dense context 和子镜像中的angular信息来生成具有semantic consistency的结果。为了避免网络传播过程中的特征损失并同时压缩红外相机中的重复信息，我们提出了一种简单 yet 高效的 Sub-Aperture Fusion Module（SAFM），可以在不添加额外存储成本下将子镜像 embed 到angular特征中。此外，为了 Address the mismatched spatial information across viewpoints，我们提出了 Center Angular Rectification Module（CARM），实现了Feature resorting 和避免了由不同视角信息干扰所致的特征遮挡。我们的提出的 OAFuser 在 UrbanLF-Real 和 UrbanLF-Syn 数据集上达到了状态机器人�왕的性能，并在 UrbanLF-Real Extended 数据集上 achieved 84.93% 的 mIoU 记录，与前一个记录 (+4.53%) 相比。我们将在 GitHub 上发布 OAFuser 的源代码，访问 https://github.com/FeiBryantkit/OAFuser。
</details></li>
</ul>
<hr>
<h2 id="Point-Clouds-Are-Specialized-Images-A-Knowledge-Transfer-Approach-for-3D-Understanding"><a href="#Point-Clouds-Are-Specialized-Images-A-Knowledge-Transfer-Approach-for-3D-Understanding" class="headerlink" title="Point Clouds Are Specialized Images: A Knowledge Transfer Approach for 3D Understanding"></a>Point Clouds Are Specialized Images: A Knowledge Transfer Approach for 3D Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15569">http://arxiv.org/abs/2307.15569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiachen Kang, Wenjing Jia, Xiangjian He, Kin Man Lam</li>
<li>for: 这篇论文是针对点云理解进行自我指导的 representation learning (SSRL) 问题，以 addressed 3D 数据缺乏和高notation costs 的挑战。</li>
<li>methods: 这篇论文提出了 PCExpert，一种新的 SSRL 方法，将点云视为 “特殊化的图像”，这个概念Shift 允许 PCExpert 可以更直接地和更深入地利用大规模的图像特征，通过在多种Transformer架构中共享参数。</li>
<li>results: PCExpert 可以在多种任务中表现出色，包括 ScanObjectNN 等，并且只需要训练少量的参数，而且其性能可以与全模型 fine-tuning 的结果相似（92.66%），这表明 PCExpert 具有强大和可靠的表示能力。<details>
<summary>Abstract</summary>
Self-supervised representation learning (SSRL) has gained increasing attention in point cloud understanding, in addressing the challenges posed by 3D data scarcity and high annotation costs. This paper presents PCExpert, a novel SSRL approach that reinterprets point clouds as "specialized images". This conceptual shift allows PCExpert to leverage knowledge derived from large-scale image modality in a more direct and deeper manner, via extensively sharing the parameters with a pre-trained image encoder in a multi-way Transformer architecture. The parameter sharing strategy, combined with a novel pretext task for pre-training, i.e., transformation estimation, empowers PCExpert to outperform the state of the arts in a variety of tasks, with a remarkable reduction in the number of trainable parameters. Notably, PCExpert's performance under LINEAR fine-tuning (e.g., yielding a 90.02% overall accuracy on ScanObjectNN) has already approached the results obtained with FULL model fine-tuning (92.66%), demonstrating its effective and robust representation capability.
</details>
<details>
<summary>摘要</summary>
自适应表示学习（SSRL）在点云理解方面受到越来越多的关注，总是面临3D数据罕见和高标注成本的挑战。本文提出PCExpert，一种新的SSRL方法，它将点云视为“专业化图像”，这种概念转换允许PCExpert在更直接和深入的方式利用大规模图像领域的知识，通过在多种Transformer架构中广泛共享参数和一种新的预测任务来进行预训练。这种参数共享策略，加之预训练中的变换估计任务，使得PCExpert能够超越当前状态的表现，并在多种任务中具有很好的灵活性和稳定性。值得一提的是，PCExpert在线性微调（例如在ScanObjectNN上达到90.02%的总准确率）的性能已经接近了全模型微调（92.66%）的结果，这显示PCExpert的表示能力是有效和可靠的。
</details></li>
</ul>
<hr>
<h2 id="Panoptic-Scene-Graph-Generation-with-Semantics-prototype-Learning"><a href="#Panoptic-Scene-Graph-Generation-with-Semantics-prototype-Learning" class="headerlink" title="Panoptic Scene Graph Generation with Semantics-prototype Learning"></a>Panoptic Scene Graph Generation with Semantics-prototype Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15567">http://arxiv.org/abs/2307.15567</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Li, Wei Ji, Yiming Wu, Mengze Li, You Qin, Lina Wei, Roger Zimmermann</li>
<li>for: 提高 PSG 模型在实际应用中的表现，解决固有偏见导致 PSG 模型在构建准确的决策平面上遇到困难。</li>
<li>methods: 提出了一种名为 ADTrans 的新框架，用于适应性地传输偏见 predicate 笔记到有用和统一的笔记。通过保证每个 predicate 类划 representation 的一致性和准确性，学习不偏 predicate 的聚类表示。同时，通过不断测量每个表现与其聚类表示之间的分布变化，不断屏选掉潜在的偏见数据。</li>
<li>results: 实验显示，ADTrans 可以显著提高 benchmark 模型的表现，实现新的州OF-the-art 性能，并在多个数据集上显示出极高的一致性和效果。<details>
<summary>Abstract</summary>
Panoptic Scene Graph Generation (PSG) parses objects and predicts their relationships (predicate) to connect human language and visual scenes. However, different language preferences of annotators and semantic overlaps between predicates lead to biased predicate annotations in the dataset, i.e. different predicates for same object pairs. Biased predicate annotations make PSG models struggle in constructing a clear decision plane among predicates, which greatly hinders the real application of PSG models. To address the intrinsic bias above, we propose a novel framework named ADTrans to adaptively transfer biased predicate annotations to informative and unified ones. To promise consistency and accuracy during the transfer process, we propose to measure the invariance of representations in each predicate class, and learn unbiased prototypes of predicates with different intensities. Meanwhile, we continuously measure the distribution changes between each presentation and its prototype, and constantly screen potential biased data. Finally, with the unbiased predicate-prototype representation embedding space, biased annotations are easily identified. Experiments show that ADTrans significantly improves the performance of benchmark models, achieving a new state-of-the-art performance, and shows great generalization and effectiveness on multiple datasets.
</details>
<details>
<summary>摘要</summary>
全面Scene图生成（PSG）解析物体并预测其关系（ predicate），将语言和视觉场景连接起来。然而，annotator的语言偏好和 predicate的semantic overlap导致数据集中的 predicate 注解受到偏见，例如对象对的不同 predicate。这种偏见使PSG模型在构建准确的决策平面上陷入困难，从而限制PSG模型的实际应用。为了解决上述内在偏见，我们提出了一种名为 ADTrans 的框架，用于自适应地传输偏见 predicate 注解到有用和统一的一个。为保证转移过程中的一致性和准确性，我们提议测量每个 predicate 类别中的表示不变性，并学习不偏 predicate 的 прототипы。同时，我们连续测量每个表现和其prototype之间的分布变化，并持续屏蔽潜在偏见数据。最终，通过不偏 predicate-prototype表示空间，偏见注解得到了轻松地识别。实验表明，ADTrans 可以显著提高 benchmark 模型的性能，达到新的状态对应性，并在多个数据集上显示出极大的一致性和效果。
</details></li>
</ul>
<hr>
<h2 id="Beating-Backdoor-Attack-at-Its-Own-Game"><a href="#Beating-Backdoor-Attack-at-Its-Own-Game" class="headerlink" title="Beating Backdoor Attack at Its Own Game"></a>Beating Backdoor Attack at Its Own Game</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15539">http://arxiv.org/abs/2307.15539</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/damianliumin/non-adversarial_backdoor">https://github.com/damianliumin/non-adversarial_backdoor</a></li>
<li>paper_authors: Min Liu, Alberto Sangiovanni-Vincentelli, Xiangyu Yue</li>
<li>for: 防御深度神经网络（DNNs）受到后门攻击，不会影响网络在干净数据上的性能，但会 manipulate 网络行为一旦添加触发模式。</li>
<li>methods: 我们提出了一种简单 yet highly effective 防御框架，通过在恶意样本上注入非对抗性后门来抑制攻击者的后门。</li>
<li>results: 我们在多个 benchmark 上进行了广泛的实验，结果显示我们的方法可以 достичь现状最佳的防御效果，同时具有最低的干净数据性能下降。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are vulnerable to backdoor attack, which does not affect the network's performance on clean data but would manipulate the network behavior once a trigger pattern is added. Existing defense methods have greatly reduced attack success rate, but their prediction accuracy on clean data still lags behind a clean model by a large margin. Inspired by the stealthiness and effectiveness of backdoor attack, we propose a simple but highly effective defense framework which injects non-adversarial backdoors targeting poisoned samples. Following the general steps in backdoor attack, we detect a small set of suspected samples and then apply a poisoning strategy to them. The non-adversarial backdoor, once triggered, suppresses the attacker's backdoor on poisoned data, but has limited influence on clean data. The defense can be carried out during data preprocessing, without any modification to the standard end-to-end training pipeline. We conduct extensive experiments on multiple benchmarks with different architectures and representative attacks. Results demonstrate that our method achieves state-of-the-art defense effectiveness with by far the lowest performance drop on clean data. Considering the surprising defense ability displayed by our framework, we call for more attention to utilizing backdoor for backdoor defense. Code is available at https://github.com/damianliumin/non-adversarial_backdoor.
</details>
<details>
<summary>摘要</summary>
Inspired by the stealthiness and effectiveness of backdoor attacks, we propose a simple but highly effective defense framework that injects non-adversarial backdoors targeting poisoned samples. Following the general steps in backdoor attacks, we detect a small set of suspected samples and then apply a poisoning strategy to them. The non-adversarial backdoor, once triggered, suppresses the attacker's backdoor on poisoned data, but has limited influence on clean data.The defense can be carried out during data preprocessing, without any modification to the standard end-to-end training pipeline. We conduct extensive experiments on multiple benchmarks with different architectures and representative attacks. Results demonstrate that our method achieves state-of-the-art defense effectiveness with by far the lowest performance drop on clean data.Considering the surprising defense ability displayed by our framework, we call for more attention to utilizing backdoors for backdoor defense. Code is available at https://github.com/damianliumin/non-adversarial_backdoor.
</details></li>
</ul>
<hr>
<h2 id="YOLOv8-for-Defect-Inspection-of-Hexagonal-Directed-Self-Assembly-Patterns-A-Data-Centric-Approach"><a href="#YOLOv8-for-Defect-Inspection-of-Hexagonal-Directed-Self-Assembly-Patterns-A-Data-Centric-Approach" class="headerlink" title="YOLOv8 for Defect Inspection of Hexagonal Directed Self-Assembly Patterns: A Data-Centric Approach"></a>YOLOv8 for Defect Inspection of Hexagonal Directed Self-Assembly Patterns: A Data-Centric Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15516">http://arxiv.org/abs/2307.15516</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enrique Dehaerne, Bappaditya Dey, Hossein Esfandiar, Lander Verstraete, Hyo Seon Suh, Sandip Halder, Stefan De Gendt</li>
<li>for: 本文旨在提出一种方法，以便在 Directed self-assembly (DSA)  Patterning 中获得高质量的报告标签，以便用于supervised Machine Learning 模型的准确性检测。</li>
<li>methods: 本文使用了一种基于 Machine Learning 的 SEM 图像分析方法，以便自动检测 DSA  Patterning 中的缺陷。</li>
<li>results: 本文的实验结果表明，使用 YOLOv8  neural network 可以在 DSA  Patterning 中达到精度更高于 0.9 mAP 的缺陷检测精度。<details>
<summary>Abstract</summary>
Shrinking pattern dimensions leads to an increased variety of defect types in semiconductor devices. This has spurred innovation in patterning approaches such as Directed self-assembly (DSA) for which no traditional, automatic defect inspection software exists. Machine Learning-based SEM image analysis has become an increasingly popular research topic for defect inspection with supervised ML models often showing the best performance. However, little research has been done on obtaining a dataset with high-quality labels for these supervised models. In this work, we propose a method for obtaining coherent and complete labels for a dataset of hexagonal contact hole DSA patterns while requiring minimal quality control effort from a DSA expert. We show that YOLOv8, a state-of-the-art neural network, achieves defect detection precisions of more than 0.9 mAP on our final dataset which best reflects DSA expert defect labeling expectations. We discuss the strengths and limitations of our proposed labeling approach and suggest directions for future work in data-centric ML-based defect inspection.
</details>
<details>
<summary>摘要</summary>
缩小模式维度会导致半导体设备中的缺陷类型多样化增加。这种情况推动了半导体 Patterning 的创新，如指导自assembly（DSA），但是传统的自动缺陷检测软件没有适用。机器学习基于 SEM 图像分析已成为半导体缺陷检测的流行研究话题，但是有少量研究关于获得高质量标签的方法。在这种工作中，我们提出一种方法，可以获得 coherent 和完整的标签集，用于半导体 DSA 模式的缺陷检测，而不需要 DSA 专家投入大量时间进行质量控制。我们显示，使用 YOLOv8  neural network，可以在我们的最终数据集上达到缺陷检测精度超过 0.9 mAP，这与 DSA 专家的标签预期相 closest 。我们讨论了我们的标签获取方法的优势和局限性，以及未来在数据驱动的 ML 基于缺陷检测方面的发展方向。
</details></li>
</ul>
<hr>
<h2 id="Improving-Image-Quality-of-Sparse-view-Lung-Cancer-CT-Images-with-a-Convolutional-Neural-Network"><a href="#Improving-Image-Quality-of-Sparse-view-Lung-Cancer-CT-Images-with-a-Convolutional-Neural-Network" class="headerlink" title="Improving Image Quality of Sparse-view Lung Cancer CT Images with a Convolutional Neural Network"></a>Improving Image Quality of Sparse-view Lung Cancer CT Images with a Convolutional Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15506">http://arxiv.org/abs/2307.15506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Annika Ries, Tina Dorosti, Johannes Thalhammer, Daniel Sasse, Andreas Sauter, Felix Meurer, Ashley Benne, Franz Pfeiffer, Daniela Pfeiffer</li>
<li>For: The paper aims to improve the image quality of sparse-view computed tomography (CT) images for lung cancer detection and to determine the best trade-off between number of views, image quality, and diagnostic confidence.* Methods: The paper uses a U-Net to improve the image quality of sparse-view CT images and evaluates the effectiveness of different levels of undersampling (16, 32, 64, 128, 256, and 512 views) on image quality and diagnostic confidence.* Results: The paper shows that 64-projection sparse-view images result in high image quality and diagnostic confidence, while fewer views lead to insufficient quality. Post-processing the sparse-view images with the U-Net further improves image quality and diagnostic confidence.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 该研究旨在提高 sparse-view CT 图像质量，以便更好地检测肺癌病变，并确定最佳投射视图数量、图像质量和诊断自信的平衡点。</li>
<li>methods: 该研究使用 U-Net 来提高 sparse-view CT 图像质量，并评估不同的投射视图数量（16, 32, 64, 128, 256, 512 个视图）对图像质量和诊断自信的影响。</li>
<li>results: 研究显示，64 投射 sparse-view CT 图像可以保持高质量和诊断自信，而更少的投射视图会导致图像质量下降。通过将 sparse-view CT 图像后处理 U-Net 模型，可以进一步提高图像质量和诊断自信。<details>
<summary>Abstract</summary>
Purpose: To improve the image quality of sparse-view computed tomography (CT) images with a U-Net for lung cancer detection and to determine the best trade-off between number of views, image quality, and diagnostic confidence.   Methods: CT images from 41 subjects (34 with lung cancer, seven healthy) were retrospectively selected (01.2016-12.2018) and forward projected onto 2048-view sinograms. Six corresponding sparse-view CT data subsets at varying levels of undersampling were reconstructed from sinograms using filtered backprojection with 16, 32, 64, 128, 256, and 512 views, respectively. A dual-frame U-Net was trained and evaluated for each subsampling level on 8,658 images from 22 diseased subjects. A representative image per scan was selected from 19 subjects (12 diseased, seven healthy) for a single-blinded reader study. The selected slices, for all levels of subsampling, with and without post-processing by the U-Net model, were presented to three readers. Image quality and diagnostic confidence were ranked using pre-defined scales. Subjective nodule segmentation was evaluated utilizing sensitivity (Se) and Dice Similarity Coefficient (DSC) with 95% confidence intervals (CI).   Results: The 64-projection sparse-view images resulted in Se = 0.89 and DSC = 0.81 [0.75,0.86] while their counterparts, post-processed with the U-Net, had improved metrics (Se = 0.94, DSC = 0.85 [0.82,0.87]). Fewer views lead to insufficient quality for diagnostic purposes. For increased views, no substantial discrepancies were noted between the sparse-view and post-processed images.   Conclusion: Projection views can be reduced from 2048 to 64 while maintaining image quality and the confidence of the radiologists on a satisfactory level.
</details>
<details>
<summary>摘要</summary>
Methods: 从 2016年1月至2018年12月收集到的41名病人（34名有肺癌，7名健康）的 CT 图像，并将它们前向投影到 2048 个视角的信号gram。将这些视角投影到稀畴视角 CT 数据集中，并使用缓冲后投影来重建图像。为每个抽象级别，使用 filtered backprojection 重建图像，并使用 dual-frame U-Net 训练和评估。在 8,658 张图像上进行了 22 名病人的评估。选择了每个扫描的一个代表图像，并在 19 名病人（12 名病人、7 名健康）中选择了一个代表图像。这些选择的slice被presented给三名读者。评估图像质量和诊断自信使用预定的级别。使用敏感度（Se）和 dice 相似度系数（DSC）来评估分割结果，并计算95% 的信任区间（CI）。Results: 64 个视角稀畴视角图像的 Se = 0.89 和 DSC = 0.81 [0.75,0.86]，而其对应的 U-Net 后处理图像的 metric 得到了改善（Se = 0.94, DSC = 0.85 [0.82,0.87]）。 fewer views 不够用于诊断purpose。随着视角数量的增加，没有显著的差异被注意到 между sparse-view 和 U-Net 后处理图像。Conclusion: 可以将 projection views 从 2048 缩减到 64，而不会影响图像质量和诊断人员对图像质量的自信。
</details></li>
</ul>
<hr>
<h2 id="Local-and-Global-Information-in-Obstacle-Detection-on-Railway-Tracks"><a href="#Local-and-Global-Information-in-Obstacle-Detection-on-Railway-Tracks" class="headerlink" title="Local and Global Information in Obstacle Detection on Railway Tracks"></a>Local and Global Information in Obstacle Detection on Railway Tracks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15478">http://arxiv.org/abs/2307.15478</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthias Brucker, Andrei Cramariuc, Cornelius von Einem, Roland Siegwart, Cesar Cadena</li>
<li>for: 避免铁路交通事故，提高列车安全性。</li>
<li>methods: 利用浅网络学习铁路分割，采用局部感知和控制global信息。</li>
<li>results: 比基eline方法高效，在自定义铁路图像集上评估。<details>
<summary>Abstract</summary>
Reliable obstacle detection on railways could help prevent collisions that result in injuries and potentially damage or derail the train. Unfortunately, generic object detectors do not have enough classes to account for all possible scenarios, and datasets featuring objects on railways are challenging to obtain. We propose utilizing a shallow network to learn railway segmentation from normal railway images. The limited receptive field of the network prevents overconfident predictions and allows the network to focus on the locally very distinct and repetitive patterns of the railway environment. Additionally, we explore the controlled inclusion of global information by learning to hallucinate obstacle-free images. We evaluate our method on a custom dataset featuring railway images with artificially augmented obstacles. Our proposed method outperforms other learning-based baseline methods.
</details>
<details>
<summary>摘要</summary>
可靠的铁路障碍检测可以帮助避免因collision而导致的伤害和可能地损坏或脱轨列车。然而，通用对象探测器并不具备足够的类型来覆盖所有可能的场景，而 dataset featuring objects on railways 也是具有挑战性的。我们提议利用一个浅网络学习铁路分割 FROM normal railway images。网络的有限接受区域防止过于自信的预测，allowing the network to focus on the locally very distinct and repetitive patterns of the railway environment。此外，我们还探索控制了包含全局信息的学习方法，通过学习生成障碍物free images。我们对自定义的 dataset featuring railway images with artificially augmented obstacles 进行评估，并证明了我们的提议方法在其他学习基础方法的比较中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Defocus-Blur-Synthesis-and-Deblurring-via-Interpolation-and-Extrapolation-in-Latent-Space"><a href="#Defocus-Blur-Synthesis-and-Deblurring-via-Interpolation-and-Extrapolation-in-Latent-Space" class="headerlink" title="Defocus Blur Synthesis and Deblurring via Interpolation and Extrapolation in Latent Space"></a>Defocus Blur Synthesis and Deblurring via Interpolation and Extrapolation in Latent Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15461">http://arxiv.org/abs/2307.15461</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nis-research/linear-latent-blur">https://github.com/nis-research/linear-latent-blur</a></li>
<li>paper_authors: Ioana Mazilu, Shunxin Wang, Sven Dummer, Raymond Veldhuis, Christoph Brune, Nicola Strisciuglio</li>
<li>for: 这篇论文的目的是提高微scopic图像的质量，以便进一步的处理和分析疾病。</li>
<li>methods: 该论文提出了一种方法，可以对图像进行恢复和合成不同程度的模糊效果。该方法使用自适应卷积神经网络，并采用了隐式和显式正则化技术来强制抽象关系在准确空间中的线性关系。</li>
<li>results: 该方法可以有效地模拟不同程度的模糊效果，从而提高数据的多样性，并提高微scopic图像的质量。这种方法可以作为数据增强技术，并且可以提高疾病的诊断和分析。<details>
<summary>Abstract</summary>
Though modern microscopes have an autofocusing system to ensure optimal focus, out-of-focus images can still occur when cells within the medium are not all in the same focal plane, affecting the image quality for medical diagnosis and analysis of diseases. We propose a method that can deblur images as well as synthesize defocus blur. We train autoencoders with implicit and explicit regularization techniques to enforce linearity relations among the representations of different blur levels in the latent space. This allows for the exploration of different blur levels of an object by linearly interpolating/extrapolating the latent representations of images taken at different focal planes. Compared to existing works, we use a simple architecture to synthesize images with flexible blur levels, leveraging the linear latent space. Our regularized autoencoders can effectively mimic blur and deblur, increasing data variety as a data augmentation technique and improving the quality of microscopic images, which would be beneficial for further processing and analysis.
</details>
<details>
<summary>摘要</summary>
现代微镜已经搭载了自动对焦系统，但是在细胞medium中不同的细胞不在同一个 фокус平面上，可能导致图像质量下降，影响医学诊断和疾病分析。我们提出了一种方法，可以恢复图像和生成杂推模灵。我们使用自动编码器，并通过显式和隐式正则化技术来强制抽象关系在 latent space 中的线性关系。这允许我们通过线性 interpolate/extrapolate latent representation来探索不同的杂推模灵水平。与现有方法相比，我们使用简单的架构来生成具有灵活杂推模灵的图像，利用 latent space 的线性性。我们的正则化自动编码器可以有效地模拟杂推模灵和恢复，增加数据的多样性，并提高微镜图像的质量，这将对进一步处理和分析产生有利影响。
</details></li>
</ul>
<hr>
<h2 id="ERCPMP-An-Endoscopic-Image-and-Video-Dataset-for-Colorectal-Polyps-Morphology-and-Pathology"><a href="#ERCPMP-An-Endoscopic-Image-and-Video-Dataset-for-Colorectal-Polyps-Morphology-and-Pathology" class="headerlink" title="ERCPMP: An Endoscopic Image and Video Dataset for Colorectal Polyps Morphology and Pathology"></a>ERCPMP: An Endoscopic Image and Video Dataset for Colorectal Polyps Morphology and Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15444">http://arxiv.org/abs/2307.15444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mojgan Forootan, Mohsen Rajabnia, Ahmad R Mafi, Hamed Azhdari Tehrani, Erfan Ghadirzadeh, Mahziar Setayeshfar, Zahra Ghaffari, Mohammad Tashakoripour, Mohammad Reza Zali, Hamidreza Bolhasani</li>
<li>For: The paper is written for developing accurate algorithms for medical prediction, detection, diagnosis, treatment, and prognosis, specifically for colorectal polyps.* Methods: The paper uses a dataset called ERCPMP, which contains demographic, morphological, and pathological data, endoscopic images, and videos of 191 patients with colorectal polyps. The dataset includes data on the diagnosis of the polyps, such as Tubular, Villous, Tubulovillous, Hyperplastic, Serrated, Inflammatory, and Adenocarcinoma with Dysplasia Grade &amp; Differentiation.* Results: The paper provides a dataset that can be used for developing accurate algorithms for medical prediction, detection, diagnosis, treatment, and prognosis of colorectal polyps. The dataset includes a wide range of data, including demographic, morphological, and pathological data, endoscopic images, and videos, which can be used to train and test machine learning and deep learning models.Here is the information in Simplified Chinese text:* 用途：这篇论文用于开发准确的医学预测、检测、诊断、治疗和预后预测算法，特别是对于肠Rectal 肿瘤。* 方法：论文使用一个名为ERCPMP的Endoscopic Image和Video Dataset，该Dataset包括191名患者的肠Rectal 肿瘤的人口统计、形态学数据、病理学数据、Endoscopic 图像和视频。该Dataset包括肿瘤的诊断，如管状、 villous、 tubulovillous、 hyperplastic、 serrated、 inflammatory 和adenocarcinoma with dysplasia grade &amp; differentiation。* 结果：论文提供了一个可以用于开发准确的医学预测、检测、诊断、治疗和预后预测算法的Dataset。该Dataset包括词语、形态学数据、病理学数据、Endoscopic 图像和视频，可以用于训练和测试机器学习和深度学习模型。<details>
<summary>Abstract</summary>
In the recent years, artificial intelligence (AI) and its leading subtypes, machine learning (ML) and deep learning (DL) and their applications are spreading very fast in various aspects such as medicine. Today the most important challenge of developing accurate algorithms for medical prediction, detection, diagnosis, treatment and prognosis is data. ERCPMP is an Endoscopic Image and Video Dataset for Recognition of Colorectal Polyps Morphology and Pathology. This dataset contains demographic, morphological and pathological data, endoscopic images and videos of 191 patients with colorectal polyps. Morphological data is included based on the latest international gastroenterology classification references such as Paris, Pit and JNET classification. Pathological data includes the diagnosis of the polyps including Tubular, Villous, Tubulovillous, Hyperplastic, Serrated, Inflammatory and Adenocarcinoma with Dysplasia Grade & Differentiation. The current version of this dataset is published and available on Elsevier Mendeley Dataverse and since it is under development, the latest version is accessible via: https://databiox.com.
</details>
<details>
<summary>摘要</summary>
recent 年们，人工智能（AI）和其主要子类型，机器学习（ML）和深度学习（DL）以及其应用在各个领域都在快速扩散，其中医学领域也是如此。 currently, the most important challenge of developing accurate algorithms for medical prediction, detection, diagnosis, treatment, and prognosis is data. ERCPMP 是一个 Endoscopic Image and Video Dataset for Recognition of Colorectal Polyps Morphology and Pathology。 This dataset contains demographic, morphological, and pathological data, endoscopic images and videos of 191 patients with colorectal polyps. Morphological data is based on the latest international gastroenterology classification references such as Paris, Pit, and JNET classification. Pathological data includes the diagnosis of the polyps, including Tubular, Villous, Tubulovillous, Hyperplastic, Serrated, Inflammatory, and Adenocarcinoma with Dysplasia Grade & Differentiation. The current version of this dataset is published and available on Elsevier Mendeley Dataverse, and the latest version can be accessed via: <https://databiox.com>.
</details></li>
</ul>
<hr>
<h2 id="Automated-Visual-Monitoring-of-Nocturnal-Insects-with-Light-based-Camera-Traps"><a href="#Automated-Visual-Monitoring-of-Nocturnal-Insects-with-Light-based-Camera-Traps" class="headerlink" title="Automated Visual Monitoring of Nocturnal Insects with Light-based Camera Traps"></a>Automated Visual Monitoring of Nocturnal Insects with Light-based Camera Traps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15433">http://arxiv.org/abs/2307.15433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitri Korsch, Paul Bodesheim, Gunnar Brehm, Joachim Denzler</li>
<li>for: 这个论文的目的是为了提供一个自动化的摄像头辅助的蜥蜉数量估计方法，以便更好地理解和对抗现在的蜥蜉减少趋势。</li>
<li>methods: 这个论文使用了一个两stage的检测和分类管道，使用了公民科学家手动捕捉的EU-Moths数据集，并对其进行了训练和评估。此外，它还介绍了一个自动化视觉监测系统的原型，并对其进行了评估。</li>
<li>results: 这个论文提供了这两个数据集的第一个检测和分类基线，并鼓励其他科学家使用这些公共可用的数据进行进一步的研究。<details>
<summary>Abstract</summary>
Automatic camera-assisted monitoring of insects for abundance estimations is crucial to understand and counteract ongoing insect decline. In this paper, we present two datasets of nocturnal insects, especially moths as a subset of Lepidoptera, photographed in Central Europe. One of the datasets, the EU-Moths dataset, was captured manually by citizen scientists and contains species annotations for 200 different species and bounding box annotations for those. We used this dataset to develop and evaluate a two-stage pipeline for insect detection and moth species classification in previous work. We further introduce a prototype for an automated visual monitoring system. This prototype produced the second dataset consisting of more than 27,000 images captured on 95 nights. For evaluation and bootstrapping purposes, we annotated a subset of the images with bounding boxes enframing nocturnal insects. Finally, we present first detection and classification baselines for these datasets and encourage other scientists to use this publicly available data.
</details>
<details>
<summary>摘要</summary>
自动摄像头助记 insect 数量的估计是理解和逆转正在进行的昆虫衰退的关键。在这篇论文中，我们介绍了中欧地区的两个昆虫数据集。其中一个数据集是由公民科学家手动捕捉的 EU-Moths 数据集，包含了 200 种不同物种的标注和 bounding box 标注。我们在过去的工作中使用了这个数据集来开发和评估一种昆虫检测和蛾类种类分类的两个阶段管道。我们还介绍了一种自动视觉监测系统的原型，这个原型在 95 个夜晚中拍摄了 более 27,000 张图像。为评估和启动目的，我们将一 subset 的图像标注为涵盖夜晚昆虫的 bounding box。最后，我们展示了这些数据集的第一个检测和分类基线，并邀请其他科学家使用这些公共可用的数据进行研究。
</details></li>
</ul>
<hr>
<h2 id="Implicit-neural-representation-for-change-detection"><a href="#Implicit-neural-representation-for-change-detection" class="headerlink" title="Implicit neural representation for change detection"></a>Implicit neural representation for change detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15428">http://arxiv.org/abs/2307.15428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Naylor, Diego Di Carlo, Arianna Traviglia, Makoto Yamada, Marco Fiorucci</li>
<li>for: 检测三维空间飞行LiDAR点云中发生的变化，特别是因为不匹配的空间支持和采集系统噪声。</li>
<li>methods: 我们提出了一种无监督方法，包括两个组成部分：神经场（NF） для连续形态重建和高斯混合模型 для分类变化。NF提供了不固定格式的表示方式，可以增加高频环境和减少噪声。</li>
<li>results: 我们在一个 benchmark 数据集上进行了测试，并证明了我们的方法可以与当前状态的艺术之前提高检测能力。此外，我们还应用了我们的方法于一个实际场景，并证明了它们与场景专家的发现相符。<details>
<summary>Abstract</summary>
Detecting changes that occurred in a pair of 3D airborne LiDAR point clouds, acquired at two different times over the same geographical area, is a challenging task because of unmatching spatial supports and acquisition system noise. Most recent attempts to detect changes on point clouds are based on supervised methods, which require large labelled data unavailable in real-world applications. To address these issues, we propose an unsupervised approach that comprises two components: Neural Field (NF) for continuous shape reconstruction and a Gaussian Mixture Model for categorising changes. NF offer a grid-agnostic representation to encode bi-temporal point clouds with unmatched spatial support that can be regularised to increase high-frequency details and reduce noise. The reconstructions at each timestamp are compared at arbitrary spatial scales, leading to a significant increase in detection capabilities. We apply our method to a benchmark dataset of simulated LiDAR point clouds for urban sprawling. The dataset offers different challenging scenarios with different resolutions, input modalities and noise levels, allowing a multi-scenario comparison of our method with the current state-of-the-art. We boast the previous methods on this dataset by a 10% margin in intersection over union metric. In addition, we apply our methods to a real-world scenario to identify illegal excavation (looting) of archaeological sites and confirm that they match findings from field experts.
</details>
<details>
<summary>摘要</summary>
检测两个3D空中探测点云之间的变化是一项具有挑战性的任务，因为这两个点云在不同的时间被获取，并且具有不匹配的空间支持和探测系统噪声。大多数最新的变化检测方法基于指导方法，需要大量的标注数据，这些数据在实际应用中很难获得。为了解决这些问题，我们提出了一种不supervised方法，它包括两个组成部分：神经场（NF）和高斯混合模型。NF提供了不受格子限制的表示方式，用于编码不匹配的时间点云，并可以通过增强高频率细节和减少噪声来增强高精度。在每个时间戳点上对重建的点云进行比较，可以在不同的空间缩放比例上进行比较，从而大幅提高检测能力。我们在一个 simulate LiDAR点云 benchmark dataset上应用了我们的方法，该dataset包括不同的具有不同分辨率、输入模式和噪声水平的场景。我们在这些场景中跟比现状态的方法，增加了10%的交叉部分精度。此外，我们还应用了我们的方法于一个实际场景，即考古遗产挖掘（looting），并证明与场地专家的发现相匹配。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Pipeline-for-Automated-Visual-Moth-Monitoring-Insect-Localization-and-Species-Classification"><a href="#Deep-Learning-Pipeline-for-Automated-Visual-Moth-Monitoring-Insect-Localization-and-Species-Classification" class="headerlink" title="Deep Learning Pipeline for Automated Visual Moth Monitoring: Insect Localization and Species Classification"></a>Deep Learning Pipeline for Automated Visual Moth Monitoring: Insect Localization and Species Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15427">http://arxiv.org/abs/2307.15427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitri Korsch, Paul Bodesheim, Joachim Denzler</li>
<li>for: 本研究旨在开发一个基于深度学习的苹果蛾自动识别系统，以帮助生物多样性监测。</li>
<li>methods: 本研究使用了一个基于蛾虫检测器和分类器的深度学习管线来分析蛾虫扫描仪上的图像。</li>
<li>results: 研究表明，将检测器和分类器结合使用可以提高蛾虫图像标识率从79.62%提高到88.05%。<details>
<summary>Abstract</summary>
Biodiversity monitoring is crucial for tracking and counteracting adverse trends in population fluctuations. However, automatic recognition systems are rarely applied so far, and experts evaluate the generated data masses manually. Especially the support of deep learning methods for visual monitoring is not yet established in biodiversity research, compared to other areas like advertising or entertainment. In this paper, we present a deep learning pipeline for analyzing images captured by a moth scanner, an automated visual monitoring system of moth species developed within the AMMOD project. We first localize individuals with a moth detector and afterward determine the species of detected insects with a classifier. Our detector achieves up to 99.01% mean average precision and our classifier distinguishes 200 moth species with an accuracy of 93.13% on image cutouts depicting single insects. Combining both in our pipeline improves the accuracy for species identification in images of the moth scanner from 79.62% to 88.05%.
</details>
<details>
<summary>摘要</summary>
生物多样性监测是追踪和抵消人口波动的关键。然而，自动识别系统 rarely 被应用，专家们仍然手动评估生成的数据量。特别是在生物多样性研究中，深度学习方法的视觉监测支持还没有得到广泛应用，相比其他领域如广告或娱乐业。本文提出了一个深度学习管道，用于分析由 moth scanner 捕捉的图像。我们首先使用 moth 检测器来 Localize 检测到的 insects，然后使用分类器来确定检测到的昆虫种类。我们的检测器可以达到 99.01% 的平均精度，分类器可以在单个昆虫图像中分类出 200 种昆虫，准确率为 93.13%。将两个模块结合在一起可以提高图像中的种类鉴定精度，从 79.62% 提高到 88.05%。
</details></li>
</ul>
<hr>
<h2 id="MLIC-Linear-Complexity-Multi-Reference-Entropy-Modeling-for-Learned-Image-Compression"><a href="#MLIC-Linear-Complexity-Multi-Reference-Entropy-Modeling-for-Learned-Image-Compression" class="headerlink" title="MLIC++: Linear Complexity Multi-Reference Entropy Modeling for Learned Image Compression"></a>MLIC++: Linear Complexity Multi-Reference Entropy Modeling for Learned Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15421">http://arxiv.org/abs/2307.15421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiangweibeta/mlic">https://github.com/jiangweibeta/mlic</a></li>
<li>paper_authors: Wei Jiang, Ronggang Wang</li>
<li>for: 这个论文是为了提出一种基于多参考 entropy 模型的学习型图像压缩方法，以提高图像压缩的效率和质量。</li>
<li>methods: 该方法使用 linear complexity 来捕捉全局相关性，而不是之前的 attention 方法，以降低复杂性。具体来说，它使用了 softmax  decomposion 来实现 linear complexity 的捕捉。</li>
<li>results:  compared to VTM-17.0，这种 MLIC$^{++}$ 方法可以提供12.44%的BD-rate 下降，并且在 PSNR 上具有较高的效率。Here’s the translation in English:</li>
<li>for: This paper proposes a learned image compression method based on multi-reference entropy modeling, to improve the efficiency and quality of image compression.</li>
<li>methods: The method uses linear complexity to capture global correlations, instead of the previous attention method, to reduce complexity. Specifically, it uses softmax decomposition to achieve linear complexity.</li>
<li>results: Compared to VTM-17.0, the proposed MLIC$^{++}$ method can provide a 12.44% reduction in BD-rate and higher efficiency in PSNR.<details>
<summary>Abstract</summary>
Recently, multi-reference entropy model has been proposed, which captures channel-wise, local spatial, and global spatial correlations. Previous works adopt attention for global correlation capturing, however, the quadratic cpmplexity limits the potential of high-resolution image coding. In this paper, we propose the linear complexity global correlations capturing, via the decomposition of softmax operation. Based on it, we propose the MLIC$^{++}$, a learned image compression with linear complexity for multi-reference entropy modeling. Our MLIC$^{++}$ is more efficient and it reduces BD-rate by 12.44% on the Kodak dataset compared to VTM-17.0 when measured in PSNR. Code will be available at https://github.com/JiangWeibeta/MLIC.
</details>
<details>
<summary>摘要</summary>
最近，多参照 entropy 模型已经被提出，它捕捉了通道 wise、本地空间和全局空间相关性。先前的工作采用了注意力来捕捉全局相关性，但 quadratic complexity 限制了高分辨率图像编码的潜力。在这篇文章中，我们提出了线性复杂度全局相关性捕捉，通过软MAX操作的分解。基于其，我们提出了 MLIC$^{++} $，一种学习图像压缩的线性复杂度多参照 entropy 模型。我们的 MLIC$^{++} $ 比 VTM-17.0 在 PSNR 下降12.44% 的 Kodak 数据集上更高效，代码将在 GitHub 上发布。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-aware-Unsupervised-Multi-Object-Tracking"><a href="#Uncertainty-aware-Unsupervised-Multi-Object-Tracking" class="headerlink" title="Uncertainty-aware Unsupervised Multi-Object Tracking"></a>Uncertainty-aware Unsupervised Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15409">http://arxiv.org/abs/2307.15409</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Liu, Sheng Jin, Zhihang Fu, Ze Chen, Rongxin Jiang, Jieping Ye</li>
<li>for: 提高无监督多 объек tracking的性能</li>
<li>methods: 采用自我监督技术，并开发了一个uncertainty-based metric来验证和修正危险关系</li>
<li>results: 实现了高性能的无监督多对象跟踪，并在MOT-Challenges和VisDrone-MOT benchmark上达到了最高级别的表现<details>
<summary>Abstract</summary>
Without manually annotated identities, unsupervised multi-object trackers are inferior to learning reliable feature embeddings. It causes the similarity-based inter-frame association stage also be error-prone, where an uncertainty problem arises. The frame-by-frame accumulated uncertainty prevents trackers from learning the consistent feature embedding against time variation. To avoid this uncertainty problem, recent self-supervised techniques are adopted, whereas they failed to capture temporal relations. The interframe uncertainty still exists. In fact, this paper argues that though the uncertainty problem is inevitable, it is possible to leverage the uncertainty itself to improve the learned consistency in turn. Specifically, an uncertainty-based metric is developed to verify and rectify the risky associations. The resulting accurate pseudo-tracklets boost learning the feature consistency. And accurate tracklets can incorporate temporal information into spatial transformation. This paper proposes a tracklet-guided augmentation strategy to simulate tracklets' motion, which adopts a hierarchical uncertainty-based sampling mechanism for hard sample mining. The ultimate unsupervised MOT framework, namely U2MOT, is proven effective on MOT-Challenges and VisDrone-MOT benchmark. U2MOT achieves a SOTA performance among the published supervised and unsupervised trackers.
</details>
<details>
<summary>摘要</summary>
Without manually annotated identities, unsupervised multi-object trackers are inferior to learning reliable feature embeddings. This causes the similarity-based inter-frame association stage to also be error-prone, resulting in an uncertainty problem. The frame-by-frame accumulated uncertainty prevents trackers from learning the consistent feature embedding against time variation. To avoid this uncertainty problem, recent self-supervised techniques are adopted, but they failed to capture temporal relations. The interframe uncertainty still exists. In fact, this paper argues that though the uncertainty problem is inevitable, it is possible to leverage the uncertainty itself to improve the learned consistency in turn. Specifically, an uncertainty-based metric is developed to verify and rectify the risky associations. The resulting accurate pseudo-tracklets boost learning the feature consistency. And accurate tracklets can incorporate temporal information into spatial transformation. This paper proposes a tracklet-guided augmentation strategy to simulate tracklets' motion, which adopts a hierarchical uncertainty-based sampling mechanism for hard sample mining. The ultimate unsupervised MOT framework, namely U2MOT, is proven effective on MOT-Challenges and VisDrone-MOT benchmark. U2MOT achieves a SOTA performance among the published supervised and unsupervised trackers.
</details></li>
</ul>
<hr>
<h2 id="Task-Oriented-Channel-Attention-for-Fine-Grained-Few-Shot-Classification"><a href="#Task-Oriented-Channel-Attention-for-Fine-Grained-Few-Shot-Classification" class="headerlink" title="Task-Oriented Channel Attention for Fine-Grained Few-Shot Classification"></a>Task-Oriented Channel Attention for Fine-Grained Few-Shot Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00093">http://arxiv.org/abs/2308.00093</a></li>
<li>repo_url: None</li>
<li>paper_authors: SuBeen Lee, WonJun Moon, Hyun Seok Seong, Jae-Pil Heo</li>
<li>for:  fine-grained image classification with limited training data</li>
<li>methods:  Task Discrepancy Maximization (TDM) with Support Attention Module (SAM) and Query Attention Module (QAM)</li>
<li>results:  accurate class-sensitive similarity measure and instance-wise highlighting of object-relevant channels<details>
<summary>Abstract</summary>
The difficulty of the fine-grained image classification mainly comes from a shared overall appearance across classes. Thus, recognizing discriminative details, such as eyes and beaks for birds, is a key in the task. However, this is particularly challenging when training data is limited. To address this, we propose Task Discrepancy Maximization (TDM), a task-oriented channel attention method tailored for fine-grained few-shot classification with two novel modules Support Attention Module (SAM) and Query Attention Module (QAM). SAM highlights channels encoding class-wise discriminative features, while QAM assigns higher weights to object-relevant channels of the query. Based on these submodules, TDM produces task-adaptive features by focusing on channels encoding class-discriminative details and possessed by the query at the same time, for accurate class-sensitive similarity measure between support and query instances. While TDM influences high-level feature maps by task-adaptive calibration of channel-wise importance, we further introduce Instance Attention Module (IAM) operating in intermediate layers of feature extractors to instance-wisely highlight object-relevant channels, by extending QAM. The merits of TDM and IAM and their complementary benefits are experimentally validated in fine-grained few-shot classification tasks. Moreover, IAM is also shown to be effective in coarse-grained and cross-domain few-shot classifications.
</details>
<details>
<summary>摘要</summary>
Fine-grained图像分类的困难主要来自于类别之间共同的整体外观。因此，认izable找到分类特征，如鸟类的眼睛和嘴，是关键。然而，当训练数据有限时，这变得非常困难。为 Addressing this challenge, we propose Task Discrepancy Maximization (TDM), a task-oriented channel attention method tailored for fine-grained few-shot classification with two novel modules Support Attention Module (SAM) and Query Attention Module (QAM). SAM highlights channels encoding class-wise discriminative features, while QAM assigns higher weights to object-relevant channels of the query. Based on these submodules, TDM produces task-adaptive features by focusing on channels encoding class-discriminative details and possessed by the query at the same time, for accurate class-sensitive similarity measure between support and query instances. While TDM influences high-level feature maps by task-adaptive calibration of channel-wise importance, we further introduce Instance Attention Module (IAM) operating in intermediate layers of feature extractors to instance-wisely highlight object-relevant channels, by extending QAM. The merits of TDM and IAM and their complementary benefits are experimentally validated in fine-grained few-shot classification tasks. Moreover, IAM is also shown to be effective in coarse-grained and cross-domain few-shot classifications.
</details></li>
</ul>
<hr>
<h2 id="AffineGlue-Joint-Matching-and-Robust-Estimation"><a href="#AffineGlue-Joint-Matching-and-Robust-Estimation" class="headerlink" title="AffineGlue: Joint Matching and Robust Estimation"></a>AffineGlue: Joint Matching and Robust Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15381">http://arxiv.org/abs/2307.15381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Barath, Dmytro Mishkin, Luca Cavalli, Paul-Edouard Sarlin, Petr Hruby, Marc Pollefeys</li>
<li>for: 本文提出了AffineGlue方法，用于 JOINT two-view 特征匹配和稳定估计，从而减少了问题的可能性级别。</li>
<li>methods: AffineGlue 使用单点最小解方法选择可能的匹配，并使用导航匹配来找到与模型相符的匹配。此外，我们还提出了一种新的 minimal solver for homography estimation，只需要一个 affine correspondence (AC) 和一个重力优先级。</li>
<li>results: AffineGlue 在实际 dataset 上表现优于 SOTA，即使假设重力方向下降。在 PhotoTourism 上，AUC@10° 分数提高了6.6个点 compared to SOTA。在 ScanNet 上，AffineGlue 使得 SuperPoint 和 SuperGlue 与无探测 LoFTR  achieve 类似的准确率。<details>
<summary>Abstract</summary>
We propose AffineGlue, a method for joint two-view feature matching and robust estimation that reduces the combinatorial complexity of the problem by employing single-point minimal solvers. AffineGlue selects potential matches from one-to-many correspondences to estimate minimal models. Guided matching is then used to find matches consistent with the model, suffering less from the ambiguities of one-to-one matches. Moreover, we derive a new minimal solver for homography estimation, requiring only a single affine correspondence (AC) and a gravity prior. Furthermore, we train a neural network to reject ACs that are unlikely to lead to a good model. AffineGlue is superior to the SOTA on real-world datasets, even when assuming that the gravity direction points downwards. On PhotoTourism, the AUC@10{\deg} score is improved by 6.6 points compared to the SOTA. On ScanNet, AffineGlue makes SuperPoint and SuperGlue achieve similar accuracy as the detector-free LoFTR.
</details>
<details>
<summary>摘要</summary>
我们提出了AffineGlue方法，它是一种能够同时实现二视图特征匹配和稳定估计的方法，通过单点最小解决方案来减少问题的 combinatorial 复杂性。AffineGlue选择一个可能的匹配点，并使用导向匹配来找到与模型一致的匹配。此外，我们还 derivated一种新的单 Affine 匹配（AC）的 homography 估计方法，只需要一个Affine对应性（AC）和重力 prior。此外，我们还训练了一个神经网络来拒绝不可能导致良好模型的AC。Compared to the state-of-the-art（SOTA），AffineGlue在实际数据集上表现更优异，即使gravity方向下降。在PhotoTourism上，AffineGlue在10度的AUC得分上提高了6.6分，比SOTA更高。在ScanNet上，AffineGlue使得SuperPoint和SuperGlue达到了无检测器LoFTR的同等准确率。
</details></li>
</ul>
<hr>
<h2 id="Prompt-Guided-Transformer-for-Multi-Task-Dense-Prediction"><a href="#Prompt-Guided-Transformer-for-Multi-Task-Dense-Prediction" class="headerlink" title="Prompt Guided Transformer for Multi-Task Dense Prediction"></a>Prompt Guided Transformer for Multi-Task Dense Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15362">http://arxiv.org/abs/2307.15362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Lu, Shalayiding Sirejiding, Yue Ding, Chunlin Wang, Hongtao Lu</li>
<li>for: 本文targets the problem of trading off performance and model parameters in task-conditional architecture, and proposes a simple and lightweight task-conditional model called Prompt Guided Transformer (PGT) to optimize this challenge.</li>
<li>methods: 本文提出了一种名为Prompt-conditioned Transformer block的新块，该块在自我注意机制中加入了任务特定的提示，以实现全球相互关系模型和参数效率的特征适应。此外，本文还提出了一种轻量级的解码器，以降低参数数量。</li>
<li>results: EXTENSIVE experiments on two multi-task dense prediction benchmarks, PASCAL-Context and NYUD-v2, show that our approach achieves state-of-the-art results among task-conditional methods while using fewer parameters, and maintains a significant balance between performance and parameter size.<details>
<summary>Abstract</summary>
Task-conditional architecture offers advantage in parameter efficiency but falls short in performance compared to state-of-the-art multi-decoder methods. How to trade off performance and model parameters is an important and difficult problem. In this paper, we introduce a simple and lightweight task-conditional model called Prompt Guided Transformer (PGT) to optimize this challenge. Our approach designs a Prompt-conditioned Transformer block, which incorporates task-specific prompts in the self-attention mechanism to achieve global dependency modeling and parameter-efficient feature adaptation across multiple tasks. This block is integrated into both the shared encoder and decoder, enhancing the capture of intra- and inter-task features. Moreover, we design a lightweight decoder to further reduce parameter usage, which accounts for only 2.7% of the total model parameters. Extensive experiments on two multi-task dense prediction benchmarks, PASCAL-Context and NYUD-v2, demonstrate that our approach achieves state-of-the-art results among task-conditional methods while using fewer parameters, and maintains a significant balance between performance and parameter size.
</details>
<details>
<summary>摘要</summary>
任务条件架构具有参数效率优势，但在性能方面与现有多decoder方法相比，表现略为下降。在这篇论文中，我们提出了一种简单且轻量级的任务条件模型，即提示导向 transformer（PGT），以优化这个挑战。我们的方法设计了一个任务特定提示块，将任务特定的提示 incorporated 在自我注意机制中，以实现全局依赖关系和参数效率的特征适应。这个块在共享encoder和decoder中都有所整合，从而提高了内部和外部任务特征的捕捉。此外，我们还设计了一个轻量级decoder，以进一步减少参数使用量，这个decoder占总模型参数的2.7%。我们在两个多任务稠密预测 benchmark，PASCAL-Context和NYUD-v2，进行了广泛的实验，结果表明，我们的方法在任务条件方法中实现了最佳的结果，同时具有更好的参数大小协调。
</details></li>
</ul>
<hr>
<h2 id="Supervised-Homography-Learning-with-Realistic-Dataset-Generation"><a href="#Supervised-Homography-Learning-with-Realistic-Dataset-Generation" class="headerlink" title="Supervised Homography Learning with Realistic Dataset Generation"></a>Supervised Homography Learning with Realistic Dataset Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15353">http://arxiv.org/abs/2307.15353</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jianghaiscu/realsh">https://github.com/jianghaiscu/realsh</a></li>
<li>paper_authors: Hai Jiang, Haipeng Li, Songchen Han, Haoqiang Fan, Bing Zeng, Shuaicheng Liu</li>
<li>For: 提出一种迭代框架，包括两个阶段：生成阶段和训练阶段，用于生成真实的训练数据并提取一个监督的投影网络。* Methods: 使用预估的主导平面屏障和投影对一个无标签图像对来生成一个新的标注过的训练对，并使用这些生成的数据进行训练监督投影网络。在训练阶段，使用内容一致模块和质量评估模块来进行数据的细化和评估。* Results: 实验结果表明，我们的方法可以达到现有最佳性能，并可以在生成的数据集上提高现有的监督方法的性能。代码和数据集可以在<a target="_blank" rel="noopener" href="https://github.com/JianghaiSCU/RealSH%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/JianghaiSCU/RealSH上下载。</a><details>
<summary>Abstract</summary>
In this paper, we propose an iterative framework, which consists of two phases: a generation phase and a training phase, to generate realistic training data and yield a supervised homography network. In the generation phase, given an unlabeled image pair, we utilize the pre-estimated dominant plane masks and homography of the pair, along with another sampled homography that serves as ground truth to generate a new labeled training pair with realistic motion. In the training phase, the generated data is used to train the supervised homography network, in which the training data is refined via a content consistency module and a quality assessment module. Once an iteration is finished, the trained network is used in the next data generation phase to update the pre-estimated homography. Through such an iterative strategy, the quality of the dataset and the performance of the network can be gradually and simultaneously improved. Experimental results show that our method achieves state-of-the-art performance and existing supervised methods can be also improved based on the generated dataset. Code and dataset are available at https://github.com/JianghaiSCU/RealSH.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种迭代框架，它包括两个阶段：生成阶段和训练阶段，用于生成真实的训练数据并生成一个监督式投影网络。在生成阶段，给定一个无标注的图像对，我们利用该对的先预计算的主要平面面积和投影，以及另一个随机选择的投影作为真实的参照，生成一个新的标注过的训练对。在训练阶段，生成的数据被用来训练监督式投影网络，其中生成的数据被修正 via 内容一致模块和质量评估模块。一旦一个迭代结束，训练完成后，用于下一次数据生成阶段的网络被更新。通过如此的迭代策略，数据集的质量和网络的性能可以逐渐提高。实验结果表明，我们的方法可以 дости得现状势最佳性能，并且可以根据生成的数据来改进现有的监督式方法。代码和数据可以在https://github.com/JianghaiSCU/RealSH中下载。
</details></li>
</ul>
<hr>
<h2 id="The-Radon-Signed-Cumulative-Distribution-Transform-and-its-applications-in-classification-of-Signed-Images"><a href="#The-Radon-Signed-Cumulative-Distribution-Transform-and-its-applications-in-classification-of-Signed-Images" class="headerlink" title="The Radon Signed Cumulative Distribution Transform and its applications in classification of Signed Images"></a>The Radon Signed Cumulative Distribution Transform and its applications in classification of Signed Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15339">http://arxiv.org/abs/2307.15339</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rohdelab/PyTransKit">https://github.com/rohdelab/PyTransKit</a></li>
<li>paper_authors: Le Gong, Shiying Li, Naqib Sad Pathan, Mohammad Shifat-E-Rabbi, Gustavo K. Rohde, Abu Hasnat Mohammad Rubaiyat, Sumati Thareja</li>
<li>for: 该研究提出了一种基于运输 mathematics 和最优运输的新图像表示技术。</li>
<li>methods: 该方法结合了Radon transform 和 Signed Cumulative Distribution Transform 两种已知的图像表示方法，并将其推广到任意函数（图像）上，因此可以用于更多应用场景。</li>
<li>results: 研究人员对实验和模拟数据进行了比较，发现新的 transform 能够更准确地表示签名图像中的信息内容，因此可以获得更高的分类精度。<details>
<summary>Abstract</summary>
Here we describe a new image representation technique based on the mathematics of transport and optimal transport. The method relies on the combination of the well-known Radon transform for images and a recent signal representation method called the Signed Cumulative Distribution Transform. The newly proposed method generalizes previous transport-related image representation methods to arbitrary functions (images), and thus can be used in more applications. We describe the new transform, and some of its mathematical properties and demonstrate its ability to partition image classes with real and simulated data. In comparison to existing transport transform methods, as well as deep learning-based classification methods, the new transform more accurately represents the information content of signed images, and thus can be used to obtain higher classification accuracies. The implementation of the proposed method in Python language is integrated as a part of the software package PyTransKit, available on Github.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的图像表示技术，基于运输学和最优运输学 mathematics。该方法通过结合已知的射频变换和最近的signal representation方法called Signed Cumulative Distribution Transform而组合。新提出的方法可以对任意函数（图像）进行扩展，因此可以在更多的应用中使用。我们描述了新的变换，以及一些其数学性质和示例数据。与现有的运输变换方法和深度学习基于分类方法相比，新的变换更好地表示签名图像中的信息内容，因此可以实现更高的分类精度。我们在Python语言中实现了该方法，并将其 integrate到PyTransKit软件包中，可以在Github上下载。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-PlenOctree-for-Adaptive-Sampling-Refinement-in-Explicit-NeRF"><a href="#Dynamic-PlenOctree-for-Adaptive-Sampling-Refinement-in-Explicit-NeRF" class="headerlink" title="Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF"></a>Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15333">http://arxiv.org/abs/2307.15333</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haotian Bai, Yiqi Lin, Yize Chen, Lin Wang</li>
<li>for: 这个研究是为了提高Explicit NeRF的训练和测试效率，以应对虚拟现实和游戏等领域。</li>
<li>methods: 这个研究使用的方法是Dynamic PlenOctree DOT，它是一个可靠的、高效的Octree表现，可以适应场景的变化。</li>
<li>results: 相比POT，DOT可以提高视觉质量，减少超过55.15%&#x2F;$68.84%$的参数，并提供1.7&#x2F;1.9倍的FPS дляNeRF-synthetic和Tanks $&amp;$ Temples。<details>
<summary>Abstract</summary>
The explicit neural radiance field (NeRF) has gained considerable interest for its efficient training and fast inference capabilities, making it a promising direction such as virtual reality and gaming. In particular, PlenOctree (POT)[1], an explicit hierarchical multi-scale octree representation, has emerged as a structural and influential framework. However, POT's fixed structure for direct optimization is sub-optimal as the scene complexity evolves continuously with updates to cached color and density, necessitating refining the sampling distribution to capture signal complexity accordingly. To address this issue, we propose the dynamic PlenOctree DOT, which adaptively refines the sample distribution to adjust to changing scene complexity. Specifically, DOT proposes a concise yet novel hierarchical feature fusion strategy during the iterative rendering process. Firstly, it identifies the regions of interest through training signals to ensure adaptive and efficient refinement. Next, rather than directly filtering out valueless nodes, DOT introduces the sampling and pruning operations for octrees to aggregate features, enabling rapid parameter learning. Compared with POT, our DOT outperforms it by enhancing visual quality, reducing over $55.15$/$68.84\%$ parameters, and providing 1.7/1.9 times FPS for NeRF-synthetic and Tanks $\&$ Temples, respectively. Project homepage:https://vlislab22.github.io/DOT.   [1] Yu, Alex, et al. "Plenoctrees for real-time rendering of neural radiance fields." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.
</details>
<details>
<summary>摘要</summary>
Explicit NeRF 技术在虚拟现实和游戏领域得到了广泛关注，因为它具有高效的训练和快速推断能力。特别是PlenOctree（POT）这种显式层次多规格树表示方法，在许多情况下成为了一种重要的框架。然而，POT 的固定结构导致了直接优化的问题，因为场景复杂度在缓存颜色和浓度更新的过程中不断变化，需要根据信号复杂度进行适应性的改进。为解决这个问题，我们提出了动态PlenOctree DOT，它可以动态调整样本分布，以适应场景复杂度的变化。具体来说，DOT提出了一种新的层次特征融合策略，在迭代渲染过程中对Region of Interest进行训练，以确保高效和适应的改进。而不是直接过滤无用的节点，DOT引入了采样和剪除操作，以协助快速学习参数。相比POT，我们的DOT在提高视觉质量、减少参数数量和提供更高的帧率方面表现出色，具体来说，DOT的视觉质量提高了55.15%/68.84%，参数减少了55.15%/68.84%，并且在NeRF-synthetic和Tanks $\&$ Temples等场景下提供了1.7/1.9倍的帧率。项目主页：https://vlislab22.github.io/DOT。[1] Yu, Alex, et al. "Plenoctrees for real-time rendering of neural radiance fields." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.
</details></li>
</ul>
<hr>
<h2 id="Staging-E-Commerce-Products-for-Online-Advertising-using-Retrieval-Assisted-Image-Generation"><a href="#Staging-E-Commerce-Products-for-Online-Advertising-using-Retrieval-Assisted-Image-Generation" class="headerlink" title="Staging E-Commerce Products for Online Advertising using Retrieval Assisted Image Generation"></a>Staging E-Commerce Products for Online Advertising using Retrieval Assisted Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15326">http://arxiv.org/abs/2307.15326</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yueh-Ning Ku, Mikhail Kuznetsov, Shaunak Mishra, Paloma de Juan</li>
<li>for: 这个论文是关于如何使用生成对抗网络（GAN）和检索助手GAN（Retrieval Assisted GAN，RAGAN）来增强电子商务平台上的动态产品广告（DPA）图像的。</li>
<li>methods: 这个论文提出了一种基于GAN和检索助手GAN的复制粘贴stagging方法，该方法首先从目录中检索与输入产品相似的已stagged产品，然后将其背景复制到输入图像中，并使用GAN基于填充模型来填充复制后的孔隙。</li>
<li>results: 论文通过在线度量和人工评估来证明了该复制粘贴stagging方法的效果，同时还展示了如何使用该方法生成产品动画。<details>
<summary>Abstract</summary>
Online ads showing e-commerce products typically rely on the product images in a catalog sent to the advertising platform by an e-commerce platform. In the broader ads industry such ads are called dynamic product ads (DPA). It is common for DPA catalogs to be in the scale of millions (corresponding to the scale of products which can be bought from the e-commerce platform). However, not all product images in the catalog may be appealing when directly re-purposed as an ad image, and this may lead to lower click-through rates (CTRs). In particular, products just placed against a solid background may not be as enticing and realistic as a product staged in a natural environment. To address such shortcomings of DPA images at scale, we propose a generative adversarial network (GAN) based approach to generate staged backgrounds for un-staged product images. Generating the entire staged background is a challenging task susceptible to hallucinations. To get around this, we introduce a simpler approach called copy-paste staging using retrieval assisted GANs. In copy paste staging, we first retrieve (from the catalog) staged products similar to the un-staged input product, and then copy-paste the background of the retrieved product in the input image. A GAN based in-painting model is used to fill the holes left after this copy-paste operation. We show the efficacy of our copy-paste staging method via offline metrics, and human evaluation. In addition, we show how our staging approach can enable animations of moving products leading to a video ad from a product image.
</details>
<details>
<summary>摘要</summary>
在线广告通常会使用电商平台提供的产品图片，这些图片通常会被称为动态产品广告（DPA）。DPA目录通常有数百万个图片，但不 все图片都能够直接复用为广告图片，这可能导致更低的键盘 clicks（CTR）。特别是，产品只有在固定背景下显示可能不那么吸引人和真实。为解决DPA图片的缺点，我们提出了基于生成对抗网络（GAN）的方法，生成产品在自然环境中的摄影。然而，整个生成整个场景是一项复杂的任务，易于生成幻觉。为此，我们提出了一种更简单的方法：复制粘贴配置。在复制粘贴配置中，我们首先从目录中检索与输入产品相似的已有的stage产品，然后将其中的背景复制到输入图片中。使用GAN基于的填充模型来填充复制后的孔隙。我们通过线上指标和人工评估表明了我们的配置方法的有效性。此外，我们还展示了如何使用我们的配置方法生成动画。
</details></li>
</ul>
<hr>
<h2 id="TaskExpert-Dynamically-Assembling-Multi-Task-Representations-with-Memorial-Mixture-of-Experts"><a href="#TaskExpert-Dynamically-Assembling-Multi-Task-Representations-with-Memorial-Mixture-of-Experts" class="headerlink" title="TaskExpert: Dynamically Assembling Multi-Task Representations with Memorial Mixture-of-Experts"></a>TaskExpert: Dynamically Assembling Multi-Task Representations with Memorial Mixture-of-Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15324">http://arxiv.org/abs/2307.15324</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prismformore/multi-task-transformer">https://github.com/prismformore/multi-task-transformer</a></li>
<li>paper_authors: Hanrong Ye, Dan Xu</li>
<li>for: 这个研究是为了解决多项任务学习中，同一个背景特征（例如从backbone层中的特征）中同时学习多个明确任务特有的特征的问题。</li>
<li>methods: 这个研究使用了一种名为TaskExpert的多项任务混合专家模型，它可以学习多个代表任务特有的特征空间，并在动态的方式下将任务特有的特征解析为多个专家网络。</li>
<li>results: 实验结果显示，TaskExpert在两个竞争性多项任务学习 benchmark（PASCAL-Context和NYUD-v2）上的9个指标中，均超越了前一代最佳方法。<details>
<summary>Abstract</summary>
Learning discriminative task-specific features simultaneously for multiple distinct tasks is a fundamental problem in multi-task learning. Recent state-of-the-art models consider directly decoding task-specific features from one shared task-generic feature (e.g., feature from a backbone layer), and utilize carefully designed decoders to produce multi-task features. However, as the input feature is fully shared and each task decoder also shares decoding parameters for different input samples, it leads to a static feature decoding process, producing less discriminative task-specific representations. To tackle this limitation, we propose TaskExpert, a novel multi-task mixture-of-experts model that enables learning multiple representative task-generic feature spaces and decoding task-specific features in a dynamic manner. Specifically, TaskExpert introduces a set of expert networks to decompose the backbone feature into several representative task-generic features. Then, the task-specific features are decoded by using dynamic task-specific gating networks operating on the decomposed task-generic features. Furthermore, to establish long-range modeling of the task-specific representations from different layers of TaskExpert, we design a multi-task feature memory that updates at each layer and acts as an additional feature expert for dynamic task-specific feature decoding. Extensive experiments demonstrate that our TaskExpert clearly outperforms previous best-performing methods on all 9 metrics of two competitive multi-task learning benchmarks for visual scene understanding (i.e., PASCAL-Context and NYUD-v2). Codes and models will be made publicly available at https://github.com/prismformore/Multi-Task-Transformer
</details>
<details>
<summary>摘要</summary>
学习多个不同任务的特征同时是多任务学习的基本问题。现今的状态提取模型直接从一个共享任务普适特征（例如，底层层次特征）中提取任务特征，并使用特别设计的解码器生成多任务特征。然而，由于输入特征完全共享，每个任务解码器也共享解码参数 для不同的输入样本，这会导致静态特征解码过程，生成更少的特征分解。为了解决这些限制，我们提出了TaskExpert，一种新的多任务混合专家模型，允许学习多个代表任务普适特征空间和动态解码任务特征。特别是，TaskExpert引入了一组专家网络将底层特征分解成多个代表任务普适特征。然后，每个任务特征被解码器使用动态任务特征闭合网络在不同的任务普适特征空间中解码。此外，为了在不同层次的TaskExpert中建立长距离模型化任务特征表示，我们设计了一个多任务特征记忆，在每层更新并作为多任务特征解码器的额外特征专家。广泛的实验证明了我们的TaskExpert明显超过了之前最佳表现的方法在图像Scene理解两个竞争性多任务学习 benchmark 上（即 PASCAL-Context 和 NYUD-v2）。代码和模型将在https://github.com/prismformore/Multi-Task-Transformer 上公开。
</details></li>
</ul>
<hr>
<h2 id="DocDeshadower-Frequency-aware-Transformer-for-Document-Shadow-Removal"><a href="#DocDeshadower-Frequency-aware-Transformer-for-Document-Shadow-Removal" class="headerlink" title="DocDeshadower: Frequency-aware Transformer for Document Shadow Removal"></a>DocDeshadower: Frequency-aware Transformer for Document Shadow Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15318">http://arxiv.org/abs/2307.15318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shenghong Luo, Ruifeng Xu, Xuhang Chen, Zinuo Li, Chi-Man Pun, Shuqiang Wang</li>
<li>for: 提高扫描文档中的阴影 removing 效果</li>
<li>methods: 使用多频Transformer模型、Attention-Aggregation Network和Gated Multi-scale Fusion Transformer来除阴影</li>
<li>results: 在质量和量化两个方面都超越现有的状态之最方法<details>
<summary>Abstract</summary>
The presence of shadows significantly impacts the visual quality of scanned documents. However, the existing traditional techniques and deep learning methods used for shadow removal have several limitations. These methods either rely heavily on heuristics, resulting in suboptimal performance, or require large datasets to learn shadow-related features. In this study, we propose the DocDeshadower, a multi-frequency Transformer-based model built on Laplacian Pyramid. DocDeshadower is designed to remove shadows at different frequencies in a coarse-to-fine manner. To achieve this, we decompose the shadow image into different frequency bands using Laplacian Pyramid. In addition, we introduce two novel components to this model: the Attention-Aggregation Network and the Gated Multi-scale Fusion Transformer. The Attention-Aggregation Network is designed to remove shadows in the low-frequency part of the image, whereas the Gated Multi-scale Fusion Transformer refines the entire image at a global scale with its large perceptive field. Our extensive experiments demonstrate that DocDeshadower outperforms the current state-of-the-art methods in both qualitative and quantitative terms.
</details>
<details>
<summary>摘要</summary>
文本中的阴影对可读性有着重要的影响，但现有的传统方法和深度学习方法used for shadow removal有一些局限性。这些方法可能会依赖于规则，导致性能下降，或者需要大量的数据来学习阴影相关的特征。在这项研究中，我们提出了DocDeshadower，一种多频Transformer基于Laplacian Pyramid的模型。DocDeshadower通过在不同频率带进行均衡处理来去除阴影。为此，我们使用Laplacian Pyramid将阴影图像分解成不同频率带。此外，我们还提出了两个新的组件：协调汇集网络和灵活多scale混合transformer。协调汇集网络用于在低频部分中去除阴影，而灵活多scale混合transformer则在全图上进行全局级别的细化处理，其大见范field允许它在不同频率带上进行细化处理。我们的广泛实验表明，DocDeshadower在可读性和量化上都超过了当前状态的方法。
</details></li>
</ul>
<hr>
<h2 id="Attentive-Multimodal-Fusion-for-Optical-and-Scene-Flow"><a href="#Attentive-Multimodal-Fusion-for-Optical-and-Scene-Flow" class="headerlink" title="Attentive Multimodal Fusion for Optical and Scene Flow"></a>Attentive Multimodal Fusion for Optical and Scene Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15301">http://arxiv.org/abs/2307.15301</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiesico/fusionraft">https://github.com/jiesico/fusionraft</a></li>
<li>paper_authors: Youjie Zhou, Guofeng Mei, Yiming Wang, Fabio Poiesi, Yi Wan</li>
<li>for: 这paper是为了解决RGB模式下的视觉和Scene flow估计问题，尤其是在噪声或低照度环境下。</li>
<li>methods: 这paper提出了一种基于深度学习的FusionRAFT方法，使得早期模式融合可以更好地利用两个感知模式（RGB和深度）的优势。该方法包括自我和交叉关注层，以建立有用的特征，以便更好地利用两个模式的优势。</li>
<li>results: 通过比较性试验，这paper表明FusionRAFT方法在Flyingthings3DSynthetic数据集和KITTI实际数据集上表现更好，并且在噪声和低照度条件下表现更加稳定和可靠。<details>
<summary>Abstract</summary>
This paper presents an investigation into the estimation of optical and scene flow using RGBD information in scenarios where the RGB modality is affected by noise or captured in dark environments. Existing methods typically rely solely on RGB images or fuse the modalities at later stages, which can result in lower accuracy when the RGB information is unreliable. To address this issue, we propose a novel deep neural network approach named FusionRAFT, which enables early-stage information fusion between sensor modalities (RGB and depth). Our approach incorporates self- and cross-attention layers at different network levels to construct informative features that leverage the strengths of both modalities. Through comparative experiments, we demonstrate that our approach outperforms recent methods in terms of performance on the synthetic dataset Flyingthings3D, as well as the generalization on the real-world dataset KITTI. We illustrate that our approach exhibits improved robustness in the presence of noise and low-lighting conditions that affect the RGB images. We release the code, models and dataset at https://github.com/jiesico/FusionRAFT.
</details>
<details>
<summary>摘要</summary>
中文翻译：本文研究了基于RGBD信息的光学和场景流计算，在RGB信息受到噪音或低光照影响的场景下。现有方法通常只采用RGB图像或在后续阶段进行模式融合，这可能会导致RGB信息不可靠时的性能下降。为解决这问题，我们提出了一种新的深度神经网络方法，即FusionRAFT，它在感知Modalities（RGB和深度）之间进行早期融合。我们的方法包括自身和交叉关注层，以不同的网络层次构建有用的特征，以利用两种模式之间的优势。通过比较实验，我们证明了我们的方法在Flyingthings3D sintetic dataset和KITTI实验室 dataset上的性能较高，并且在噪音和低光照条件下表现更加稳定。我们将代码、模型和数据集发布在https://github.com/jiesico/FusionRAFT上。
</details></li>
</ul>
<hr>
<h2 id="AC-Norm-Effective-Tuning-for-Medical-Image-Analysis-via-Affine-Collaborative-Normalization"><a href="#AC-Norm-Effective-Tuning-for-Medical-Image-Analysis-via-Affine-Collaborative-Normalization" class="headerlink" title="AC-Norm: Effective Tuning for Medical Image Analysis via Affine Collaborative Normalization"></a>AC-Norm: Effective Tuning for Medical Image Analysis via Affine Collaborative Normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15282">http://arxiv.org/abs/2307.15282</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/endoluminalsurgicalvision-imr/acnorm">https://github.com/endoluminalsurgicalvision-imr/acnorm</a></li>
<li>paper_authors: Chuyan Zhang, Yuncheng Yang, Hao Zheng, Yun Gu<br>for:  This paper focuses on enhancing the performance of clinical applications with limited annotations using self-supervised learning (SSL) and the “pretraining-then-finetuning” paradigm.methods:  The proposed method, Affine Collaborative Normalization (AC-Norm), utilizes the trainable affine parameters of batch normalization (BN) layers to dynamically recalibrate the channels in the target model according to the cross-domain channel-wise correlations, without adding extra parameters.results:  The proposed AC-Norm method outperformed the vanilla finetuning method by up to 4% improvement in various transfer learning tasks, including diabetic retinopathy grade classification, retinal vessel segmentation, CT lung nodule segmentation&#x2F;classification, CT liver-tumor segmentation, and MRI cardiac segmentation. Additionally, AC-Norm was found to be capable of fast transferability estimation.<details>
<summary>Abstract</summary>
Driven by the latest trend towards self-supervised learning (SSL), the paradigm of "pretraining-then-finetuning" has been extensively explored to enhance the performance of clinical applications with limited annotations. Previous literature on model finetuning has mainly focused on regularization terms and specific policy models, while the misalignment of channels between source and target models has not received sufficient attention. In this work, we revisited the dynamics of batch normalization (BN) layers and observed that the trainable affine parameters of BN serve as sensitive indicators of domain information. Therefore, Affine Collaborative Normalization (AC-Norm) is proposed for finetuning, which dynamically recalibrates the channels in the target model according to the cross-domain channel-wise correlations without adding extra parameters. Based on a single-step backpropagation, AC-Norm can also be utilized to measure the transferability of pretrained models. We evaluated AC-Norm against the vanilla finetuning and state-of-the-art fine-tuning methods on transferring diverse pretrained models to the diabetic retinopathy grade classification, retinal vessel segmentation, CT lung nodule segmentation/classification, CT liver-tumor segmentation and MRI cardiac segmentation tasks. Extensive experiments demonstrate that AC-Norm unanimously outperforms the vanilla finetuning by up to 4% improvement, even under significant domain shifts where the state-of-the-art methods bring no gains. We also prove the capability of AC-Norm in fast transferability estimation. Our code is available at https://github.com/EndoluminalSurgicalVision-IMR/ACNorm.
</details>
<details>
<summary>摘要</summary>
受最新的自动学习（SSL）趋势驱动，“预训练后finetuning”的方法在医疗应用中得到了广泛的探索，以提高limited annotations的性能。之前的模型finetuning研究主要集中在常规化项和特定策略模型上，而频道之间的偏移问题尚未得到了充分的注意。在这项工作中，我们重新探讨了批量 нормализа（BN）层的动力学，并发现了BN层的可调参数作为域信息的敏感指标。因此，我们提出了Affine Collaborative Normalization（AC-Norm），用于finetuning，可以在目标模型中动态重新准确channel，无需添加额外参数。基于单步反射，AC-Norm还可以用于评估预训练模型的传输性。我们对AC-Norm与常规finetuning和现有的精细调整方法进行了对比，在不同的频道偏移 task 上进行了广泛的实验。结果表明，AC-Norm在频道偏移情况下可以达到4%的提升，而在其他方法无法提供任何提升的情况下。我们还证明了AC-Norm的快速传输性能测试能力。代码可以在https://github.com/EndoluminalSurgicalVision-IMR/ACNorm上下载。
</details></li>
</ul>
<hr>
<h2 id="Recovering-high-quality-FODs-from-a-reduced-number-of-diffusion-weighted-images-using-a-model-driven-deep-learning-architecture"><a href="#Recovering-high-quality-FODs-from-a-reduced-number-of-diffusion-weighted-images-using-a-model-driven-deep-learning-architecture" class="headerlink" title="Recovering high-quality FODs from a reduced number of diffusion-weighted images using a model-driven deep learning architecture"></a>Recovering high-quality FODs from a reduced number of diffusion-weighted images using a model-driven deep learning architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15273">http://arxiv.org/abs/2307.15273</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jbartlett6/sdnet">https://github.com/jbartlett6/sdnet</a></li>
<li>paper_authors: J Bartlett, C E Davey, L A Johnston, J Duan</li>
<li>for: 该研究旨在提出一种基于深度学习的材料方向分布（FOD）重建方法，可以从少量的扩散束图像（DWI）中生成高精度的FOD。</li>
<li>methods: 该方法使用深度学习网络，使用扩散获取的Diffusion-weighted image（DWI）信号作为输入，并通过一种圆拟合网络来重建FOD。</li>
<li>results: 研究表明，该模型基于深度学习的FOD重建方法可以与现有的FOD超分辨率网络相比，并且可以通过调整约束来提高下游的fixel分类精度。代码可以在<a target="_blank" rel="noopener" href="https://github.com/Jbartlett6/SDNet%E4%B8%AD%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Jbartlett6/SDNet中获取。</a><details>
<summary>Abstract</summary>
Fibre orientation distribution (FOD) reconstruction using deep learning has the potential to produce accurate FODs from a reduced number of diffusion-weighted images (DWIs), decreasing total imaging time. Diffusion acquisition invariant representations of the DWI signals are typically used as input to these methods to ensure that they can be applied flexibly to data with different b-vectors and b-values; however, this means the network cannot condition its output directly on the DWI signal. In this work, we propose a spherical deconvolution network, a model-driven deep learning FOD reconstruction architecture, that ensures intermediate and output FODs produced by the network are consistent with the input DWI signals. Furthermore, we implement a fixel classification penalty within our loss function, encouraging the network to produce FODs that can subsequently be segmented into the correct number of fixels and improve downstream fixel-based analysis. Our results show that the model-based deep learning architecture achieves competitive performance compared to a state-of-the-art FOD super-resolution network, FOD-Net. Moreover, we show that the fixel classification penalty can be tuned to offer improved performance with respect to metrics that rely on accurately segmented of FODs. Our code is publicly available at https://github.com/Jbartlett6/SDNet .
</details>
<details>
<summary>摘要</summary>
《纤维方向分布（FOD）重建使用深度学习有可能生成准确的FOD，从一小量的扩散束图像（DWI）中减少总成像时间。通常使用扩散获取的不变表示来作为输入，以确保这些方法可以适应不同的b-向量和b值;然而，这意味着网络无法直接Conditional Output在DWI信号。在这种工作中，我们提议一种圆柱体抽象网络，一种驱动深度学习FOD重建架构，以确保输入DWI信号和输出FOD之间的一致。此外，我们实施了一种纤维分类罚金在我们的损失函数中，让网络生成FOD，可以随后被正确分割为纤维。我们的结果表明，模型驱动的深度学习架构与现状的FOD超分辨网络FOD-Net具有竞争性。此外，我们还证明了纤维分类罚金可以调整以提高基于纤维分割的下游分析的表现。我们的代码在https://github.com/Jbartlett6/SDNet上公开。》Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Anatomy-Aware-Lymph-Node-Detection-in-Chest-CT-using-Implicit-Station-Stratification"><a href="#Anatomy-Aware-Lymph-Node-Detection-in-Chest-CT-using-Implicit-Station-Stratification" class="headerlink" title="Anatomy-Aware Lymph Node Detection in Chest CT using Implicit Station Stratification"></a>Anatomy-Aware Lymph Node Detection in Chest CT using Implicit Station Stratification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15271">http://arxiv.org/abs/2307.15271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Yan, Dakai Jin, Dazhou Guo, Minfeng Xu, Na Shen, Xian-Sheng Hua, Xianghua Ye, Le Lu<br>for: 这个研究的目的是提高于医疗影像中发现异常淋巴节的自动检测性能。methods: 本研究提出了一个 novel 的终端框架，通过利用淋巴节的站信息来提高淋巴节检测性能。我们设计了多头检测器，并将每个头专注于区分淋巴节和非淋巴节结构的不同站信息。在训练过程中，我们使用了多任务学习，将淋巴节站信息作为多个类别的标签生成，因此在测试过程中不需要另外的Explicit LN站预测模型。results: 我们在82名肺癌患者和91名食道癌患者的CT影像检查中评估了我们的算法。结果显示，我们的方法可以从65.1%提高到71.4%和80.3%提高到85.5%，对于每个患者2个错误的淋巴节检测性能，均有明显的改善。相比于 existed 的多种基eline技术，如nnUNet、nnDetection和LENS，我们的方法具有更高的检测性能。<details>
<summary>Abstract</summary>
Finding abnormal lymph nodes in radiological images is highly important for various medical tasks such as cancer metastasis staging and radiotherapy planning. Lymph nodes (LNs) are small glands scattered throughout the body. They are grouped or defined to various LN stations according to their anatomical locations. The CT imaging appearance and context of LNs in different stations vary significantly, posing challenges for automated detection, especially for pathological LNs. Motivated by this observation, we propose a novel end-to-end framework to improve LN detection performance by leveraging their station information. We design a multi-head detector and make each head focus on differentiating the LN and non-LN structures of certain stations. Pseudo station labels are generated by an LN station classifier as a form of multi-task learning during training, so we do not need another explicit LN station prediction model during inference. Our algorithm is evaluated on 82 patients with lung cancer and 91 patients with esophageal cancer. The proposed implicit station stratification method improves the detection sensitivity of thoracic lymph nodes from 65.1% to 71.4% and from 80.3% to 85.5% at 2 false positives per patient on the two datasets, respectively, which significantly outperforms various existing state-of-the-art baseline techniques such as nnUNet, nnDetection and LENS.
</details>
<details>
<summary>摘要</summary>
找到不同常规图像中的异常淋巴节点是医疗领域中非常重要的各种任务中的一个，如癌细胞肿瘤stage和放疗规划。淋巴节点（LN）是身体中散布的小腺体，根据其生理位置分为不同的LN站。不同的LN站在CT图像的出现和背景下有很大的差异，这会提高自动检测的挑战，特别是对于病理LN。为了解决这个问题，我们提出了一种新的综合框架，利用LN站信息来提高淋巴节点检测性能。我们设计了多头检测器，每个头都专门用于区分LN和非LN结构。在训练时，我们使用LN站分类器生成pseudo站标签，以实现多任务学习，因此在推断时不需要另外的explicit LN站预测模型。我们的算法在82名肺癌患者和91名食道癌患者的数据集上进行了评估，并显示了提高了脊梗淋巴节点检测感度，从65.1%提高到71.4%和80.3%提高到85.5%，在2个false positive每个患者时，分别有显著的提高。与多种现有的基线技术相比，我们的方法显示出了显著的优势。
</details></li>
</ul>
<hr>
<h2 id="RSGPT-A-Remote-Sensing-Vision-Language-Model-and-Benchmark"><a href="#RSGPT-A-Remote-Sensing-Vision-Language-Model-and-Benchmark" class="headerlink" title="RSGPT: A Remote Sensing Vision Language Model and Benchmark"></a>RSGPT: A Remote Sensing Vision Language Model and Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15266">http://arxiv.org/abs/2307.15266</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Hu, Jianlong Yuan, Congcong Wen, Xiaonan Lu, Xiang Li<br>for: 本研究旨在开发特有的大视语言模型（VLM），用于数据分析领域中的远程感知（RS）应用。methods: 本研究使用了人工标注的卫星图像描述集（RSICap），以及卫星图像评估集（RSIEval），用于评估和训练大视语言模型。results: 研究发现，通过使用高质量的卫星图像描述集（RSICap）和卫星图像评估集（RSIEval），可以帮助开发大视语言模型（VLM），并且可以在RS应用中达到比较出色的性能。<details>
<summary>Abstract</summary>
The emergence of large-scale large language models, with GPT-4 as a prominent example, has significantly propelled the rapid advancement of artificial general intelligence and sparked the revolution of Artificial Intelligence 2.0. In the realm of remote sensing (RS), there is a growing interest in developing large vision language models (VLMs) specifically tailored for data analysis in this domain. However, current research predominantly revolves around visual recognition tasks, lacking comprehensive, large-scale image-text datasets that are aligned and suitable for training large VLMs, which poses significant challenges to effectively training such models for RS applications. In computer vision, recent research has demonstrated that fine-tuning large vision language models on small-scale, high-quality datasets can yield impressive performance in visual and language understanding. These results are comparable to state-of-the-art VLMs trained from scratch on massive amounts of data, such as GPT-4. Inspired by this captivating idea, in this work, we build a high-quality Remote Sensing Image Captioning dataset (RSICap) that facilitates the development of large VLMs in the RS field. Unlike previous RS datasets that either employ model-generated captions or short descriptions, RSICap comprises 2,585 human-annotated captions with rich and high-quality information. This dataset offers detailed descriptions for each image, encompassing scene descriptions (e.g., residential area, airport, or farmland) as well as object information (e.g., color, shape, quantity, absolute position, etc). To facilitate the evaluation of VLMs in the field of RS, we also provide a benchmark evaluation dataset called RSIEval. This dataset consists of human-annotated captions and visual question-answer pairs, allowing for a comprehensive assessment of VLMs in the context of RS.
</details>
<details>
<summary>摘要</summary>
大规模的大语言模型，如GPT-4，对人工通用智能的发展产生了巨大的推动，并促使了人工智能2.0的革命。在远程感知（RS）领域，有增加兴趣在开发特定于数据分析的大视语言模型（VLMs）。然而，当前的研究主要集中在视觉认知任务上，缺乏大规模、一致的图像文本数据集，这会对培育大VLMs的训练带来很大的挑战。在计算机视觉领域，最近的研究表明， fine-tuning大视语言模型在小规模、高质量数据集上可以获得出色的视觉和语言理解性能。这些结果与 state-of-the-art VLMs 训练自零开始大量数据，如GPT-4，相当。 inspirited by this captivating idea，在这项工作中，我们构建了高质量的远程感知图像描述集（RSICap），以便在RS领域开发大VLMs。与前期RS datasets不同，RSICap包含2,585个人注解的描述，其中包括Scene描述（例如：居民区、机场、农业等）以及物体信息（例如：颜色、形状、数量、绝对位置等）。为便于RS领域中VLMs的评估，我们还提供了一个名为RSIEval的基准评估集，该集包含人注解的描述和视觉问答对，以便对VLMs在RS领域进行全面的评估。
</details></li>
</ul>
<hr>
<h2 id="Learning-with-Constraint-Learning-New-Perspective-Solution-Strategy-and-Various-Applications"><a href="#Learning-with-Constraint-Learning-New-Perspective-Solution-Strategy-and-Various-Applications" class="headerlink" title="Learning with Constraint Learning: New Perspective, Solution Strategy and Various Applications"></a>Learning with Constraint Learning: New Perspective, Solution Strategy and Various Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15257">http://arxiv.org/abs/2307.15257</a></li>
<li>repo_url: None</li>
<li>paper_authors: Risheng Liu, Jiaxin Gao, Xuan Liu, Xin Fan</li>
<li>for: 解决复杂的机器学习和计算机视觉问题，包括生成对抗网络（GAN）和其变种、多任务和元学习、超参数学习以及各种实际应用。</li>
<li>methods: 提出了一种新的框架——学习干预学习（LwCL），可以一元化地探讨这些多样化的学习和视觉问题。LwCL 采用了一种高级别的层次优化模型，能够捕捉这些多样化的学习和视觉问题的本质。</li>
<li>results: 对于多种学习和视觉应用，LwCL 提供了一个广泛的解决方案，包括三类和九种问题类型。实验表明，LwCL 可以有效地解决各种复杂的机器学习和计算机视觉问题，并 bridge 理论和实践之间的差距。<details>
<summary>Abstract</summary>
The complexity of learning problems, such as Generative Adversarial Network (GAN) and its variants, multi-task and meta-learning, hyper-parameter learning, and a variety of real-world vision applications, demands a deeper understanding of their underlying coupling mechanisms. Existing approaches often address these problems in isolation, lacking a unified perspective that can reveal commonalities and enable effective solutions. Therefore, in this work, we proposed a new framework, named Learning with Constraint Learning (LwCL), that can holistically examine challenges and provide a unified methodology to tackle all the above-mentioned complex learning and vision problems. Specifically, LwCL is designed as a general hierarchical optimization model that captures the essence of these diverse learning and vision problems. Furthermore, we develop a gradient-response based fast solution strategy to overcome optimization challenges of the LwCL framework. Our proposed framework efficiently addresses a wide range of applications in learning and vision, encompassing three categories and nine different problem types. Extensive experiments on synthetic tasks and real-world applications verify the effectiveness of our approach. The LwCL framework offers a comprehensive solution for tackling complex machine learning and computer vision problems, bridging the gap between theory and practice.
</details>
<details>
<summary>摘要</summary>
“复杂的学习问题，如生成对抗网络（GAN）和其变种，多任务和元学习，参数学习，以及各种现实世界视觉应用，需要更深刻的理解它们的基础机制。现有方法通常对这些问题进行隔离处理，缺乏一个综合视角，这使得它们的解决方法受限。因此，在这项工作中，我们提出了一个新的框架，名为学习约束学（LwCL），可以总结这些多样化的学习和视觉问题。具体来说，LwCL是一种通用的层次优化模型，捕捉这些多样化的学习和视觉问题的核心。此外，我们开发了基于梯度响应的快速解决策略，以解决LwCL框架中的优化挑战。我们的提出的框架可以有效地解决各种学习和视觉问题，涵盖三个类别和九种不同的问题类型。广泛的实验证明了我们的方法的有效性，LwCL框架可以凝聚理论和实践之间的差距，为复杂的机器学习和计算机视觉问题提供一个普适的解决方案。”
</details></li>
</ul>
<hr>
<h2 id="A-Solution-to-Co-occurrence-Bias-Attributes-Disentanglement-via-Mutual-Information-Minimization-for-Pedestrian-Attribute-Recognition"><a href="#A-Solution-to-Co-occurrence-Bias-Attributes-Disentanglement-via-Mutual-Information-Minimization-for-Pedestrian-Attribute-Recognition" class="headerlink" title="A Solution to Co-occurrence Bias: Attributes Disentanglement via Mutual Information Minimization for Pedestrian Attribute Recognition"></a>A Solution to Co-occurrence Bias: Attributes Disentanglement via Mutual Information Minimization for Pedestrian Attribute Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15252">http://arxiv.org/abs/2307.15252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sdret/a-solution-to-co-occurence-bias-in-pedestrian-attribute-recognition">https://github.com/sdret/a-solution-to-co-occurence-bias-in-pedestrian-attribute-recognition</a></li>
<li>paper_authors: Yibo Zhou, Hai-Miao Hu, Jinzuo Yu, Zhenbo Xu, Weiqing Lu, Yuran Cao</li>
<li>for: 提高pedestrian attribute recognition的Robustness和Generalization能力</li>
<li>methods: 提出了一种Attributes-disentangled feature learning方法，通过mutual information minimization来解耦特征之间的相关性</li>
<li>results: 在实际场景中提高了baseline的性能，并在PETAzs和RAPzs等 dataset上实现了State-of-the-artresult<details>
<summary>Abstract</summary>
Recent studies on pedestrian attribute recognition progress with either explicit or implicit modeling of the co-occurrence among attributes. Considering that this known a prior is highly variable and unforeseeable regarding the specific scenarios, we show that current methods can actually suffer in generalizing such fitted attributes interdependencies onto scenes or identities off the dataset distribution, resulting in the underlined bias of attributes co-occurrence. To render models robust in realistic scenes, we propose the attributes-disentangled feature learning to ensure the recognition of an attribute not inferring on the existence of others, and which is sequentially formulated as a problem of mutual information minimization. Rooting from it, practical strategies are devised to efficiently decouple attributes, which substantially improve the baseline and establish state-of-the-art performance on realistic datasets like PETAzs and RAPzs. Code is released on https://github.com/SDret/A-Solution-to-Co-occurence-Bias-in-Pedestrian-Attribute-Recognition.
</details>
<details>
<summary>摘要</summary>
近期研究人员发现，人行AttributeRecognition的进步通常采用显式或隐式表示人行Attribute的相互关系。然而，这种已知的假设对特定场景的变化和不可预测，可能导致现有方法在不同场景下表现不佳，具有人行Attribute相互关系的偏见。为确保模型在真实场景中 robust，我们提议使用Attribute分离特征学习，以确保一个特征不受另一个特征的存在影响。这个问题可以看作是 mutual information minimization 问题。从而，我们提出了实用的策略来快速分离特征，并在实际数据集上达到了基eline和状态arp的表现。代码可以在 https://github.com/SDret/A-Solution-to-Co-occurence-Bias-in-Pedestrian-Attribute-Recognition 上找到。
</details></li>
</ul>
<hr>
<h2 id="D2S-Representing-local-descriptors-and-global-scene-coordinates-for-camera-relocalization"><a href="#D2S-Representing-local-descriptors-and-global-scene-coordinates-for-camera-relocalization" class="headerlink" title="D2S: Representing local descriptors and global scene coordinates for camera relocalization"></a>D2S: Representing local descriptors and global scene coordinates for camera relocalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15250">http://arxiv.org/abs/2307.15250</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bach-Thuan Bui, Dinh-Tuan Tran, Joo-Ho Lee</li>
<li>For: 本研究提出了一种基于直接学习的视地标记方法，用于解决现有的视地标记方法具有较高的计算成本和存储量的问题。* Methods: 本方法使用一个简单的神经网络 named D2S，用于表示本地描述符和场景坐标。 D2S 使用一种简单的损失函数和图注意机制，选择性地关注 robust 的描述符，而忽略某些不可靠的区域，如云、树和动态对象。* Results: 本方法在室内和室外环境中的场景坐标回归任务中表现出色，超过了现有的 CNN 基于方法。 它能够在不具备标注数据源的情况下，通过自然语言描述和自动分类来泛化到不同的场景中，包括从白天到黑夜的过渡和频率域转换。I hope that helps! Let me know if you have any further questions or if there’s anything else I can help with.<details>
<summary>Abstract</summary>
State-of-the-art visual localization methods mostly rely on complex procedures to match local descriptors and 3D point clouds. However, these procedures can incur significant cost in terms of inference, storage, and updates over time. In this study, we propose a direct learning-based approach that utilizes a simple network named D2S to represent local descriptors and their scene coordinates. Our method is characterized by its simplicity and cost-effectiveness. It solely leverages a single RGB image for localization during the testing phase and only requires a lightweight model to encode a complex sparse scene. The proposed D2S employs a combination of a simple loss function and graph attention to selectively focus on robust descriptors while disregarding areas such as clouds, trees, and several dynamic objects. This selective attention enables D2S to effectively perform a binary-semantic classification for sparse descriptors. Additionally, we propose a new outdoor dataset to evaluate the capabilities of visual localization methods in terms of scene generalization and self-updating from unlabeled observations. Our approach outperforms the state-of-the-art CNN-based methods in scene coordinate regression in indoor and outdoor environments. It demonstrates the ability to generalize beyond training data, including scenarios involving transitions from day to night and adapting to domain shifts, even in the absence of the labeled data sources. The source code, trained models, dataset, and demo videos are available at the following link: https://thpjp.github.io/d2s
</details>
<details>
<summary>摘要</summary>
现代视觉地标方法通常需要复杂的过程来匹配本地描述符和3D点云。然而，这些过程可能会带来较大的计算成本、存储成本和时间更新成本。在本研究中，我们提出了一种直接学习基于的方法，利用名为D2S的简单网络来表示本地描述符和其场景坐标。我们的方法具有简单性和成本效果。它仅在测试阶段使用单个RGB图像进行地标，并且仅需要一个轻量级模型来编码复杂的稀疏场景。提出的D2S使用一种简单的损失函数和图像注意力来选择ively关注可靠的描述符，而忽略云、树和一些动态对象。这种选择性注意力使得D2S可以有效地进行二分类Semantic地标。此外，我们还提出了一个新的户外数据集来评估视觉地标方法的场景总结和自动更新能力。我们的方法在室内和户外环境中超越了当前最佳CNN基于方法的场景坐标回归。它能够总结超出训练数据，包括从日到夜的过渡和适应频率变化，甚至在没有标注数据源的情况下。source code、训练模型、数据集和示例视频可以在以下链接获取：https://thpjp.github.io/d2s。
</details></li>
</ul>
<hr>
<h2 id="TROPHY-A-Topologically-Robust-Physics-Informed-Tracking-Framework-for-Tropical-Cyclones"><a href="#TROPHY-A-Topologically-Robust-Physics-Informed-Tracking-Framework-for-Tropical-Cyclones" class="headerlink" title="TROPHY: A Topologically Robust Physics-Informed Tracking Framework for Tropical Cyclones"></a>TROPHY: A Topologically Robust Physics-Informed Tracking Framework for Tropical Cyclones</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15243">http://arxiv.org/abs/2307.15243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Yan, Hanqi Guo, Thomas Peterka, Bei Wang, Jiali Wang</li>
<li>for: 本研究旨在提出一种基于物理知识的高效的TC跟踪方法，以提高大规模气象数据集中TC跟踪的计算效率。</li>
<li>methods: 本方法首先提出了一种基于物理知识的特征选择策略，以筛选出高稳定性和长期存在的TC kritical points。然后，在多层Robustness计算中，我们对TC kritical points进行了物理约束，以确保计算的TC跟踪结果具有物理意义。</li>
<li>results: 我们对30年的2D风场数据进行了实验，并通过对比观察轨迹和已有的TC跟踪算法，示出了TROPHY可以准确地跟踪TC的特征，并且有时even better than已有的TC跟踪算法。<details>
<summary>Abstract</summary>
Tropical cyclones (TCs) are among the most destructive weather systems. Realistically and efficiently detecting and tracking TCs are critical for assessing their impacts and risks. Recently, a multilevel robustness framework has been introduced to study the critical points of time-varying vector fields. The framework quantifies the robustness of critical points across varying neighborhoods. By relating the multilevel robustness with critical point tracking, the framework has demonstrated its potential in cyclone tracking. An advantage is that it identifies cyclonic features using only 2D wind vector fields, which is encouraging as most tracking algorithms require multiple dynamic and thermodynamic variables at different altitudes. A disadvantage is that the framework does not scale well computationally for datasets containing a large number of cyclones. This paper introduces a topologically robust physics-informed tracking framework (TROPHY) for TC tracking. The main idea is to integrate physical knowledge of TC to drastically improve the computational efficiency of multilevel robustness framework for large-scale climate datasets. First, during preprocessing, we propose a physics-informed feature selection strategy to filter 90% of critical points that are short-lived and have low stability, thus preserving good candidates for TC tracking. Second, during in-processing, we impose constraints during the multilevel robustness computation to focus only on physics-informed neighborhoods of TCs. We apply TROPHY to 30 years of 2D wind fields from reanalysis data in ERA5 and generate a number of TC tracks. In comparison with the observed tracks, we demonstrate that TROPHY can capture TC characteristics that are comparable to and sometimes even better than a well-validated TC tracking algorithm that requires multiple dynamic and thermodynamic scalar fields.
</details>
<details>
<summary>摘要</summary>
热带风暴（TC）是气候系统中最破坏性的天气系统之一。有效地探测和跟踪TC是评估其影响和风险的关键。最近，一种多级坚定性框架已经被提出来研究时变向量场中的关键点。这个框架可以量化不同级别的坚定性，并与多级坚定性相关的 kritical point tracking 进行比较。这个框架在风暴跟踪中表现出了潜力。它可以通过只使用2D风向场来识别风暴特征，这是有利的，因为大多数跟踪算法需要不同高度和层次的动力和 термодинамиче变量。然而，这个框架的计算效率不太好，特别是对大规模气候数据进行处理。这篇文章介绍了一种基于物理知识的逻辑坚定性物理协调跟踪框架（TROPHY），用于风暴跟踪。TROPHY的主要想法是通过将物理知识 integrate 到多级坚定性框架中，以提高计算效率。我们的方法包括：一、在预处理阶段，我们提出了物理学习Feature选择策略，以过滤90%的不稳定和短暂的关键点，保留适合风暴跟踪的好andidates。二、在进程阶段，我们在多级坚定性计算中强制实施物理学习的约束，只考虑物理学习所支持的TC约束。我们在ERA5的2D风向场数据上应用TROPHY，并生成了30年的风暴跟踪。与观测跟踪相比，我们示出TROPHY可以捕捉风暴特征，并且在一些情况下，甚至比一种已经证明有效的TC跟踪算法（需要多个动力和 термодинамичеscalar场）更好。
</details></li>
</ul>
<hr>
<h2 id="Fast-Dust-Sand-Image-Enhancement-Based-on-Color-Correction-and-New-Membership-Function"><a href="#Fast-Dust-Sand-Image-Enhancement-Based-on-Color-Correction-and-New-Membership-Function" class="headerlink" title="Fast Dust Sand Image Enhancement Based on Color Correction and New Membership Function"></a>Fast Dust Sand Image Enhancement Based on Color Correction and New Membership Function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15230">http://arxiv.org/abs/2307.15230</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Hakem Alsaeedi, Suha Mohammed Hadi, Yarub Alazzawi</li>
<li>for: 提高灰尘照片质量</li>
<li>methods: 使用色彩修正和新成员函数进行颜色偏移 correction，采用Adaptive Dark Channel Prior（A-DCP）进行雾化 removal，基于Contrast Limited Adaptive Histogram Equalization（CLAHE）进行对比度限制和图像亮度提高</li>
<li>results: 比现有研究更高效地除去红色和黄色投影，提供高质量和量灰尘照片<details>
<summary>Abstract</summary>
Images captured in dusty environments suffering from poor visibility and quality. Enhancement of these images such as sand dust images plays a critical role in various atmospheric optics applications. In this work, proposed a new model based on Color Correction and new membership function to enhance san dust images. The proposed model consists of three phases: correction of color shift, removal of haze, and enhancement of contrast and brightness. The color shift is corrected using a new membership function to adjust the values of U and V in the YUV color space. The Adaptive Dark Channel Prior (A-DCP) is used for haze removal. The stretching contrast and improving image brightness are based on Contrast Limited Adaptive Histogram Equalization (CLAHE). The proposed model tests and evaluates through many real sand dust images. The experimental results show that the proposed solution is outperformed the current studies in terms of effectively removing the red and yellow cast and provides high quality and quantity dust images.
</details>
<details>
<summary>摘要</summary>
图像捕捉在尘埃环境中，由于visibility和质量受到限制。尘埃图像加强在大气光学应用中扮演关键角色。本工作提出了一种基于颜色修正和新成员函数的图像加强模型。该模型包括三个阶段：色差修正、雾气除净和对比和亮度提高。色差修正使用新的成员函数调整YUV颜色空间中U和V值。使用适应黑道通道优先(A-DCP)进行雾气除净。对比和亮度提高基于对比限定适应 histogram平衡(CLAHE)。提出的模型在多个真实的沙尘图像上进行测试和评估。实验结果表明，提出的解决方案在效果上超越当前研究，可以有效地除掉红色和黄色投影，提供高质量和量的尘埃图像。
</details></li>
</ul>
<hr>
<h2 id="Sustainable-Transparency-in-Recommender-Systems-Bayesian-Ranking-of-Images-for-Explainability"><a href="#Sustainable-Transparency-in-Recommender-Systems-Bayesian-Ranking-of-Images-for-Explainability" class="headerlink" title="Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability"></a>Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01196">http://arxiv.org/abs/2308.01196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jorge Paz-Ruza, Amparo Alonso-Betanzos, Berta Guijarro-Berdiñas, Brais Cancela, Carlos Eiras-Franco</li>
<li>for: 提高推荐系统的透明度和用户信任度</li>
<li>methods: 使用用户创建的视觉内容生成个性化解释</li>
<li>results: 比前方法更高效，减少了75%的CO${_2}$排放和模型尺寸，在六个实际数据集上达到了一致性superior表现，而且具有remarkable efficiency和小型模型优势。<details>
<summary>Abstract</summary>
Recommender Systems have become crucial in the modern world, commonly guiding users towards relevant content or products, and having a large influence over the decisions of users and citizens. However, ensuring transparency and user trust in these systems remains a challenge; personalized explanations have emerged as a solution, offering justifications for recommendations. Among the existing approaches for generating personalized explanations, using visual content created by the users is one particularly promising option, showing a potential to maximize transparency and user trust. Existing models for explaining recommendations in this context face limitations: sustainability has been a critical concern, as they often require substantial computational resources, leading to significant carbon emissions comparable to the Recommender Systems where they would be integrated. Moreover, most models employ surrogate learning goals that do not align with the objective of ranking the most effective personalized explanations for a given recommendation, leading to a suboptimal learning process and larger model sizes. To address these limitations, we present BRIE, a novel model designed to tackle the existing challenges by adopting a more adequate learning goal based on Bayesian Pairwise Ranking, enabling it to achieve consistently superior performance than state-of-the-art models in six real-world datasets, while exhibiting remarkable efficiency, emitting up to 75% less CO${_2}$ during training and inference with a model up to 64 times smaller than previous approaches.
</details>
<details>
<summary>摘要</summary>
现有的解释推荐模型在这个上下文中存在限制：它们通常需要大量的计算资源，导致显著的碳排放和大型模型，与推荐系统集成时的碳排放相比。此外，大多数模型使用代理学习目标，这些目标与个性化解释排名的目标不一致，导致学习过程不优化和模型较大。为解决这些限制，我们提出了 BRIE，一种新的模型，通过采用更适合的学习目标基于 bayesian pairwise ranking，实现了与现状最佳的性能，在六个实际数据集上表现出了明显的优势，同时具有很好的效率和较小的模型大小。在训练和推理过程中，BRIE可以减少75%的碳排放，并且模型可以达到64倍小于现有方法。
</details></li>
</ul>
<hr>
<h2 id="Generative-AI-for-Medical-Imaging-extending-the-MONAI-Framework"><a href="#Generative-AI-for-Medical-Imaging-extending-the-MONAI-Framework" class="headerlink" title="Generative AI for Medical Imaging: extending the MONAI Framework"></a>Generative AI for Medical Imaging: extending the MONAI Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15208">http://arxiv.org/abs/2307.15208</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/project-monai/generativemodels">https://github.com/project-monai/generativemodels</a></li>
<li>paper_authors: Walter H. L. Pinaya, Mark S. Graham, Eric Kerfoot, Petru-Daniel Tudosiu, Jessica Dafflon, Virginia Fernandez, Pedro Sanchez, Julia Wolleb, Pedro F. da Costa, Ashay Patel, Hyungjin Chung, Can Zhao, Wei Peng, Zelong Liu, Xueyan Mei, Oeslle Lucena, Jong Chul Ye, Sotirios A. Tsaftaris, Prerna Dogra, Andrew Feng, Marc Modat, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardoso</li>
<li>for: 本研究旨在提供一个开源平台，专门用于训练、评估和部署生成模型和相关应用。</li>
<li>methods: 本研究使用了多种生成模型，包括扩散模型、自动推导 трансформа器和GANs，并在一个通用的方式下实现了这些模型。</li>
<li>results: 本研究可以将生成模型应用到不同的领域，包括医疗影像的问题检测、图像对图像翻译、干扰除和MRI重建。 results表明，这些模型可以在不同的领域中实现高效和精准的结果。<details>
<summary>Abstract</summary>
Recent advances in generative AI have brought incredible breakthroughs in several areas, including medical imaging. These generative models have tremendous potential not only to help safely share medical data via synthetic datasets but also to perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due to the complexity of these models, their implementation and reproducibility can be difficult. This complexity can hinder progress, act as a use barrier, and dissuade the comparison of new methods with existing works. In this study, we present MONAI Generative Models, a freely available open-source platform that allows researchers and developers to easily train, evaluate, and deploy generative models and related applications. Our platform reproduces state-of-art studies in a standardised way involving different architectures (such as diffusion models, autoregressive transformers, and GANs), and provides pre-trained models for the community. We have implemented these models in a generalisable fashion, illustrating that their results can be extended to 2D or 3D scenarios, including medical images with different modalities (like CT, MRI, and X-Ray data) and from different anatomical areas. Finally, we adopt a modular and extensible approach, ensuring long-term maintainability and the extension of current applications for future features.
</details>
<details>
<summary>摘要</summary>
In this study, we present MONAI Generative Models, a freely available open-source platform that allows researchers and developers to easily train, evaluate, and deploy generative models and related applications. Our platform reproduces state-of-the-art studies in a standardized way involving different architectures (such as diffusion models, autoregressive transformers, and GANs), and provides pre-trained models for the community. We have implemented these models in a generalizable fashion, illustrating that their results can be extended to 2D or 3D scenarios, including medical images with different modalities (such as CT, MRI, and X-ray data) and from different anatomical areas.Finally, we adopt a modular and extensible approach, ensuring long-term maintainability and the extension of current applications for future features.
</details></li>
</ul>
<hr>
<h2 id="Small-but-important-Traffic-light-proposals-for-detecting-small-traffic-lights-and-beyond"><a href="#Small-but-important-Traffic-light-proposals-for-detecting-small-traffic-lights-and-beyond" class="headerlink" title="Small, but important: Traffic light proposals for detecting small traffic lights and beyond"></a>Small, but important: Traffic light proposals for detecting small traffic lights and beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15191">http://arxiv.org/abs/2307.15191</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Sanitz, Christian Wilms, Simone Frintrop</li>
<li>for: 提高小型交通灯的检测精度</li>
<li>methods: 提出了一种新的交通灯检测系统，包括基于通用物体提案生成的新的交通灯提案生成器，以及细致多尺度特征和注意力机制，以提高检测效果。</li>
<li>results: 对三个公共可用的数据集进行评估，与六种方法进行比较，结果显示小型交通灯的检测精度提高至少12.6%，并在所有交通灯大小上表现优异。<details>
<summary>Abstract</summary>
Traffic light detection is a challenging problem in the context of self-driving cars and driver assistance systems. While most existing systems produce good results on large traffic lights, detecting small and tiny ones is often overlooked. A key problem here is the inherent downsampling in CNNs, leading to low-resolution features for detection. To mitigate this problem, we propose a new traffic light detection system, comprising a novel traffic light proposal generator that utilizes findings from general object proposal generation, fine-grained multi-scale features, and attention for efficient processing. Moreover, we design a new detection head for classifying and refining our proposals. We evaluate our system on three challenging, publicly available datasets and compare it against six methods. The results show substantial improvements of at least $12.6\%$ on small and tiny traffic lights, as well as strong results across all sizes of traffic lights.
</details>
<details>
<summary>摘要</summary>
干货灯检测是自驾车和驾驶助手系统中的一个挑战。大多数现有系统可以在大型干货灯上提供良好的结果，但检测小型和微型干货灯通常被忽略。这里的关键问题在于卷积神经网络中的自然下采样问题，导致检测特征的解析精度低下。为解决这个问题，我们提出了一个新的干货灯检测系统，包括一个新的干货灯提案生成器，该生成器利用通用物体提案生成的发现，以及细腻多尺度特征和注意力来实现高效处理。此外，我们还设计了一个新的检测头来分类和精细地修正我们的提案。我们在三个公共可用的数据集上评估了我们的系统，并与六种方法进行比较。结果显示，我们的系统在小型和微型干货灯上提供了至少12.6%的提升，并在所有干货灯大小上达到了强劲的结果。
</details></li>
</ul>
<hr>
<h2 id="EnSolver-Uncertainty-Aware-CAPTCHA-Solver-Using-Deep-Ensembles"><a href="#EnSolver-Uncertainty-Aware-CAPTCHA-Solver-Using-Deep-Ensembles" class="headerlink" title="EnSolver: Uncertainty-Aware CAPTCHA Solver Using Deep Ensembles"></a>EnSolver: Uncertainty-Aware CAPTCHA Solver Using Deep Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15180">http://arxiv.org/abs/2307.15180</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hoangcongduc/ensolver">https://github.com/hoangcongduc/ensolver</a></li>
<li>paper_authors: Duc C. Hoang, Cuong V. Nguyen, Amin Kharraz</li>
<li>for: 保护网站从自动化机器人的攻击中，通过使用文本基于的 CAPTCHA 安全机制。</li>
<li>methods: 使用深度学习技术建立 CAPTCHA 解决器，并使用深度ensemble不确定性估计来检测和跳过不符合预期的样本。</li>
<li>results: 使用对象检测模型和实验结果表明，EnSolver 可以在不同样本中具有高度的准确率和成功率，达到98.1% 和93% 分别。<details>
<summary>Abstract</summary>
The popularity of text-based CAPTCHA as a security mechanism to protect websites from automated bots has prompted researches in CAPTCHA solvers, with the aim of understanding its failure cases and subsequently making CAPTCHAs more secure. Recently proposed solvers, built on advances in deep learning, are able to crack even the very challenging CAPTCHAs with high accuracy. However, these solvers often perform poorly on out-of-distribution samples that contain visual features different from those in the training set. Furthermore, they lack the ability to detect and avoid such samples, making them susceptible to being locked out by defense systems after a certain number of failed attempts. In this paper, we propose EnSolver, a novel CAPTCHA solver that utilizes deep ensemble uncertainty estimation to detect and skip out-of-distribution CAPTCHAs, making it harder to be detected. We demonstrate the use of our solver with object detection models and show empirically that it performs well on both in-distribution and out-of-distribution data, achieving up to 98.1% accuracy when detecting out-of-distribution data and up to 93% success rate when solving in-distribution CAPTCHAs.
</details>
<details>
<summary>摘要</summary>
受欢迎的文本基于CAPTCHA作为网站自动化软件保护机制的流行性，使得研究人员努力开发CAPTCHA解决方案，以了解其失败情况，并使CAPTCHA更加安全。最近提出的解决方案基于深度学习技术，能够解决even the very challenging CAPTCHAs with high accuracy。然而，这些解决方案经常在不同于训练集的视觉特征的样本上表现不佳，并且缺乏检测和避免这些样本的能力，使其容易被防御系统锁定。在本文中，我们提出EnSolver，一种新的CAPTCHA解决方案，利用深度ensemble uncertainty estimation来检测和跳过不同于训练集的CAPTCHAs，使其更难被检测。我们使用对象检测模型来实现我们的解决方案，并证明了其在各种数据上的良好性，包括在分布型和不同分布型数据上的性能，达到了98.1%的检测精度和93%的成功率。
</details></li>
</ul>
<hr>
<h2 id="R-LPIPS-An-Adversarially-Robust-Perceptual-Similarity-Metric"><a href="#R-LPIPS-An-Adversarially-Robust-Perceptual-Similarity-Metric" class="headerlink" title="R-LPIPS: An Adversarially Robust Perceptual Similarity Metric"></a>R-LPIPS: An Adversarially Robust Perceptual Similarity Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15157">http://arxiv.org/abs/2307.15157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/saraghazanfari/r-lpips">https://github.com/saraghazanfari/r-lpips</a></li>
<li>paper_authors: Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, Alexandre Araujo</li>
<li>for: 本研究旨在提出一种robust learned perceptual image patch similarity（R-LPIPS）度量，以提高图像相似度评估中的安全性。</li>
<li>methods: 该度量使用了 adversarially trained deep features，并通过了一系列实验证明其比 классиical LPIPS 度量更加稳定和可靠。</li>
<li>results: 研究表明，R-LPIPS 度量能够更好地抗击 adversarial examples，并且在大规模应用中具有更高的安全性。<details>
<summary>Abstract</summary>
Similarity metrics have played a significant role in computer vision to capture the underlying semantics of images. In recent years, advanced similarity metrics, such as the Learned Perceptual Image Patch Similarity (LPIPS), have emerged. These metrics leverage deep features extracted from trained neural networks and have demonstrated a remarkable ability to closely align with human perception when evaluating relative image similarity. However, it is now well-known that neural networks are susceptible to adversarial examples, i.e., small perturbations invisible to humans crafted to deliberately mislead the model. Consequently, the LPIPS metric is also sensitive to such adversarial examples. This susceptibility introduces significant security concerns, especially considering the widespread adoption of LPIPS in large-scale applications. In this paper, we propose the Robust Learned Perceptual Image Patch Similarity (R-LPIPS) metric, a new metric that leverages adversarially trained deep features. Through a comprehensive set of experiments, we demonstrate the superiority of R-LPIPS compared to the classical LPIPS metric. The code is available at https://github.com/SaraGhazanfari/R-LPIPS.
</details>
<details>
<summary>摘要</summary>
Computer vision 中的相似度度量有着重要的作用，用于捕捉图像的含义。近年来，高级相似度度量，如学习的 Perceptual Image Patch Similarity（LPIPS），得到了广泛应用。这些度量利用训练过的神经网络提取的深度特征，并在评估图像相似性时表现出了人类视觉的惊人能力。然而，现在已经公认的是，神经网络受到攻击性例子的威胁，即通过小型的隐蔽的扰动量让模型做出错误的判断。这种敏感性引入了重要的安全问题，特别是在大规模应用中。在这篇论文中，我们提出了Robust Learned Perceptual Image Patch Similarity（R-LPIPS）度量，一种新的度量，利用攻击性训练的深度特征。通过全面的实验，我们证明了R-LPIPS在相似性评估中的优越性，相比于经典的LPIPS度量。代码可以在https://github.com/SaraGhazanfari/R-LPIPS中找到。
</details></li>
</ul>
<hr>
<h2 id="R-Block-Regularized-Block-of-Dropout-for-convolutional-networks"><a href="#R-Block-Regularized-Block-of-Dropout-for-convolutional-networks" class="headerlink" title="R-Block: Regularized Block of Dropout for convolutional networks"></a>R-Block: Regularized Block of Dropout for convolutional networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15150">http://arxiv.org/abs/2307.15150</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liqi Wang, Qiya Hu</li>
<li>for: 本研究旨在提出一种基于对比学习的卷积层正则化技术，以提高卷积神经网络的性能。</li>
<li>methods: 本研究使用了一种名为R-Block的对比学习训练策略，其目的是在卷积层中对两个不同采样的输出进行匹配。具体来说，R-Block将两个不同采样的卷积层输出的分布差用来最小化训练集的损失。我们还提出了两种构建子模型的方法。</li>
<li>results: 我们的实验结果显示，R-Block在比较其他结构化抛出变体时表现更好，而且我们的子模型构建方法也超过了其他方法。<details>
<summary>Abstract</summary>
Dropout as a regularization technique is widely used in fully connected layers while is less effective in convolutional layers. Therefore more structured forms of dropout have been proposed to regularize convolutional networks. The disadvantage of these methods is that the randomness introduced causes inconsistency between training and inference. In this paper, we apply a mutual learning training strategy for convolutional layer regularization, namely R-Block, which forces two outputs of the generated difference maximizing sub models to be consistent with each other. Concretely, R-Block minimizes the losses between the output distributions of two sub models with different drop regions for each sample in the training dataset. We design two approaches to construct such sub models. Our experiments demonstrate that R-Block achieves better performance than other existing structured dropout variants. We also demonstrate that our approaches to construct sub models outperforms others.
</details>
<details>
<summary>摘要</summary>
Dropout 作为一种常用的正则化技术，通常在全连接层中使用，而在卷积层中效果较差。因此，为了正则化卷积网络，更结构化的Dropout变体被提议。然而，这些方法的Randomness引入会导致训练和测试过程中的不一致。在这篇论文中，我们采用了相互学习训练策略，即R-Block，使得两个由生成的差分最大化子模型输出的结果彼此一致。具体来说，R-Block将每个训练集中的样本的输出分布between两个不同掉除区域的子模型Minimize the loss。我们设计了两种方法来构建子模型。我们的实验表明，R-Block在其他已有结构化Dropout变体的比较中表现更好。此外，我们的子模型构建方法也超过了其他方法。
</details></li>
</ul>
<hr>
<h2 id="Online-Clustered-Codebook"><a href="#Online-Clustered-Codebook" class="headerlink" title="Online Clustered Codebook"></a>Online Clustered Codebook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15139">http://arxiv.org/abs/2307.15139</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lyndonzheng/cvq-vae">https://github.com/lyndonzheng/cvq-vae</a></li>
<li>paper_authors: Chuanxia Zheng, Andrea Vedaldi</li>
<li>for: 这 paper 的目的是提出一种简单的在线代码库学习方法，以解决现有 VQ-VAE 中的代码Vector 归一化问题。</li>
<li>methods: 这 paper 使用 Clustering VQ-VAE (CVQ-VAE) 方法，选择编码特征作为更新“死亡”的代码Vector 的参考点，同时使用原始损失来优化代码库。</li>
<li>results: 该 paper 的 CVQ-VAE 方法可以广泛验证在不同的 dataset、任务（如重建和生成）和架构（如 VQ-VAE、VQGAN、LDM）上，并且可以轻松地与现有模型集成。<details>
<summary>Abstract</summary>
Vector Quantisation (VQ) is experiencing a comeback in machine learning, where it is increasingly used in representation learning. However, optimizing the codevectors in existing VQ-VAE is not entirely trivial. A problem is codebook collapse, where only a small subset of codevectors receive gradients useful for their optimisation, whereas a majority of them simply ``dies off'' and is never updated or used. This limits the effectiveness of VQ for learning larger codebooks in complex computer vision tasks that require high-capacity representations. In this paper, we present a simple alternative method for online codebook learning, Clustering VQ-VAE (CVQ-VAE). Our approach selects encoded features as anchors to update the ``dead'' codevectors, while optimising the codebooks which are alive via the original loss. This strategy brings unused codevectors closer in distribution to the encoded features, increasing the likelihood of being chosen and optimized. We extensively validate the generalization capability of our quantiser on various datasets, tasks (e.g. reconstruction and generation), and architectures (e.g. VQ-VAE, VQGAN, LDM). Our CVQ-VAE can be easily integrated into the existing models with just a few lines of code.
</details>
<details>
<summary>摘要</summary>
vector量化（VQ）在机器学习中经受着重新发现，现在越来越在表示学习中使用。然而，在现有的VQ-VAE中优化codevector并不是完全懒散的。一个问题是codebook塌缩，只有一小部分的codevector会收到有用的梯度更新，而大多数codevector会“死亡”并从未更新或使用。这限制了VQ在学习更大的codebook时的效iveness，特别是在复杂的计算机视觉任务中需要高容量表示。在这篇论文中，我们提出了一种简单的在线代码库学习方法，即Clustering VQ-VAE（CVQ-VAE）。我们的方法选择编码特征作为更新“死亡” codevector的锚点，同时通过原始损失来优化活跃的代码库。这种策略使得无用的codevector更近于编码特征的分布，提高了它们的选择和优化的可能性。我们广泛验证了我们的量化器在不同的数据集、任务（例如重建和生成）和结构（例如VQ-VAE、VQGAN、LDM）上的通用能力。我们的CVQ-VAE可以轻松地与现有模型集成，只需要几行代码。
</details></li>
</ul>
<hr>
<h2 id="Seal-3D-Interactive-Pixel-Level-Editing-for-Neural-Radiance-Fields"><a href="#Seal-3D-Interactive-Pixel-Level-Editing-for-Neural-Radiance-Fields" class="headerlink" title="Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields"></a>Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15131">http://arxiv.org/abs/2307.15131</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/windingwind/seal-3d">https://github.com/windingwind/seal-3d</a></li>
<li>paper_authors: Xiangyu Wang, Jingsen Zhu, Qi Ye, Yuchi Huo, Yunlong Ran, Zhihua Zhong, Jiming Chen</li>
<li>for: 这个论文旨在提供一种可交互地编辑神经表示的方法，以便在受限的编辑灵活性、质量和速度等方面提高NeRF编辑的效果。</li>
<li>methods: 该方法使用一种新的教师-学生训练策略和本地预训练和全球精度调整，将编辑指令映射到原始NeRF模型空间，以实现直接响应编辑指令并快速预览编辑效果。</li>
<li>results: 该方法可以实现各种编辑效果，并且可以在约1秒钟的交互速度下达到出色的编辑效果。<details>
<summary>Abstract</summary>
With the popularity of implicit neural representations, or neural radiance fields (NeRF), there is a pressing need for editing methods to interact with the implicit 3D models for tasks like post-processing reconstructed scenes and 3D content creation. While previous works have explored NeRF editing from various perspectives, they are restricted in editing flexibility, quality, and speed, failing to offer direct editing response and instant preview. The key challenge is to conceive a locally editable neural representation that can directly reflect the editing instructions and update instantly. To bridge the gap, we propose a new interactive editing method and system for implicit representations, called Seal-3D, which allows users to edit NeRF models in a pixel-level and free manner with a wide range of NeRF-like backbone and preview the editing effects instantly. To achieve the effects, the challenges are addressed by our proposed proxy function mapping the editing instructions to the original space of NeRF models and a teacher-student training strategy with local pretraining and global finetuning. A NeRF editing system is built to showcase various editing types. Our system can achieve compelling editing effects with an interactive speed of about 1 second.
</details>
<details>
<summary>摘要</summary>
《 neural radiance fields (NeRF) 的 популярность导致了对 implicit 3D 模型的编辑方法的强需求，以便在重建场景后处理和创建3D内容中进行交互式编辑。而过去的作品都已经在不同的角度探索了 NeRF 编辑，但它们的编辑灵活性、质量和速度受到了限制，无法提供直接的编辑回应和即时预览。关键挑战是总结一种可以直接反映编辑指令并快速更新的 neural representation。为了bridging这个差距，我们提出了一种新的交互式编辑方法和系统，叫做 Seal-3D，允许用户在像素级别和自由地编辑 NeRF 模型，并在即时预览编辑效果。以解决这些挑战，我们提出了一种代理函数，将编辑指令映射到原始 NeRF 模型的空间，以及一种教师学生训练策略，包括本地预训练和全球调整。我们建立了一个 NeRF 编辑系统，以示出多种编辑类型。我们的系统可以实现吸引人的编辑效果，编辑速度约为1秒。》
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Remote-Sensing-Change-Detection-of-Unregistered-Bi-temporal-Images-for-Natural-Disasters"><a href="#End-to-end-Remote-Sensing-Change-Detection-of-Unregistered-Bi-temporal-Images-for-Natural-Disasters" class="headerlink" title="End-to-end Remote Sensing Change Detection of Unregistered Bi-temporal Images for Natural Disasters"></a>End-to-end Remote Sensing Change Detection of Unregistered Bi-temporal Images for Natural Disasters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15128">http://arxiv.org/abs/2307.15128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guiqin Zhao, Lianlei Shan, Weiqiang Wang</li>
<li>for: 本研究旨在针对自然灾害区域内的建筑物损害检测，通过远程感知图像进行检测。</li>
<li>methods: 本研究使用了深度网络，并提出了一种无需注册的端到端变化检测网络（E2ECDNet），可以处理不匹配的双时间图像对。</li>
<li>results: 实验结果表明，E2ECDNet 能够在不匹配的双时间图像对上提供高精度的变化检测结果，并且与现有的注册变化检测方法相比，具有更高的精度和更快的运算速度。<details>
<summary>Abstract</summary>
Change detection based on remote sensing images has been a prominent area of interest in the field of remote sensing. Deep networks have demonstrated significant success in detecting changes in bi-temporal remote sensing images and have found applications in various fields. Given the degradation of natural environments and the frequent occurrence of natural disasters, accurately and swiftly identifying damaged buildings in disaster-stricken areas through remote sensing images holds immense significance. This paper aims to investigate change detection specifically for natural disasters. Considering that existing public datasets used in change detection research are registered, which does not align with the practical scenario where bi-temporal images are not matched, this paper introduces an unregistered end-to-end change detection synthetic dataset called xBD-E2ECD. Furthermore, we propose an end-to-end change detection network named E2ECDNet, which takes an unregistered bi-temporal image pair as input and simultaneously generates the flow field prediction result and the change detection prediction result. It is worth noting that our E2ECDNet also supports change detection for registered image pairs, as registration can be seen as a special case of non-registration. Additionally, this paper redefines the criteria for correctly predicting a positive case and introduces neighborhood-based change detection evaluation metrics. The experimental results have demonstrated significant improvements.
</details>
<details>
<summary>摘要</summary>
改变探测基于远程感知图像已经成为远程感知领域的一个主要领域。深度网络在比时图像之间进行改变探测中表现出了显著的成功，并在不同领域找到了应用。随着自然环境的衰退和自然灾害的频繁发生，通过远程感知图像快速和准确地确定灾难hit buildings是非常重要的。本文旨在研究自然灾害中的改变探测。由于现有的公共数据集在改变探测研究中使用的是注册的，这并不符合实际情况，在这种情况下，本文引入了一个无注册的综合改变探测数据集called xBD-E2ECD。此外，我们提议一种综合改变探测网络，称为E2ECDNet，该网络可以将无注册的双时图像对作为输入，并同时生成流场预测结果和改变探测预测结果。需要注意的是，我们的E2ECDNet还支持注册图像对的改变探测，因为注册可以看作特殊的非注册情况。此外，本文还重新定义了正确预测正例的标准，并引入了邻居基于改变探测评价指标。实验结果表明了显著的改进。
</details></li>
</ul>
<hr>
<h2 id="To-Adapt-or-Not-to-Adapt-Real-Time-Adaptation-for-Semantic-Segmentation"><a href="#To-Adapt-or-Not-to-Adapt-Real-Time-Adaptation-for-Semantic-Segmentation" class="headerlink" title="To Adapt or Not to Adapt? Real-Time Adaptation for Semantic Segmentation"></a>To Adapt or Not to Adapt? Real-Time Adaptation for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15063">http://arxiv.org/abs/2307.15063</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MarcBotet/hamlet">https://github.com/MarcBotet/hamlet</a></li>
<li>paper_authors: Marc Botet Colomer, Pier Luigi Dovesi, Theodoros Panagiotakopoulos, Joao Frederico Carvalho, Linus Härenstam-Nielsen, Hossein Azizpour, Hedvig Kjellström, Daniel Cremers, Matteo Poggi</li>
<li>for: 该论文旨在解决在部署时出现不可预期的领域变化，如突发天气事件，以实现 semantic segmentation 的在线领域适应。</li>
<li>methods: 该论文提出了一种基于硬件意识的模块最低成本训练框架（HAMLET），包括硬件意识反推协调器（HAMT）和特有的领域偏移探测器（LT），以实现实时领域适应。</li>
<li>results: 该论文的方法可以在单个consumer-grade GPU上达到更高于29帧&#x2F;秒的同时进行 semantic segmentation 和领域适应，并且在 OnDA 和 SHIFT 标准准则上实现了鼓舞人的准确率和速度质量平衡。<details>
<summary>Abstract</summary>
The goal of Online Domain Adaptation for semantic segmentation is to handle unforeseeable domain changes that occur during deployment, like sudden weather events. However, the high computational costs associated with brute-force adaptation make this paradigm unfeasible for real-world applications. In this paper we propose HAMLET, a Hardware-Aware Modular Least Expensive Training framework for real-time domain adaptation. Our approach includes a hardware-aware back-propagation orchestration agent (HAMT) and a dedicated domain-shift detector that enables active control over when and how the model is adapted (LT). Thanks to these advancements, our approach is capable of performing semantic segmentation while simultaneously adapting at more than 29FPS on a single consumer-grade GPU. Our framework's encouraging accuracy and speed trade-off is demonstrated on OnDA and SHIFT benchmarks through experimental results.
</details>
<details>
<summary>摘要</summary>
goal of Online Domain Adaptation for semantic segmentation is to handle unforeseeable domain changes that occur during deployment, like sudden weather events. However, the high computational costs associated with brute-force adaptation make this paradigm unfeasible for real-world applications. In this paper, we propose HAMLET, a Hardware-Aware Modular Least Expensive Training framework for real-time domain adaptation. Our approach includes a hardware-aware back-propagation orchestration agent (HAMT) and a dedicated domain-shift detector that enables active control over when and how the model is adapted (LT). Thanks to these advancements, our approach is capable of performing semantic segmentation while simultaneously adapting at more than 29FPS on a single consumer-grade GPU. Our framework's encouraging accuracy and speed trade-off is demonstrated on OnDA and SHIFT benchmarks through experimental results.Here's the translation in Traditional Chinese:goal of Online Domain Adaptation for semantic segmentation is to handle unforeseeable domain changes that occur during deployment, like sudden weather events. However, the high computational costs associated with brute-force adaptation make this paradigm unfeasible for real-world applications. In this paper, we propose HAMLET, a Hardware-Aware Modular Least Expensive Training framework for real-time domain adaptation. Our approach includes a hardware-aware back-propagation orchestration agent (HAMT) and a dedicated domain-shift detector that enables active control over when and how the model is adapted (LT). Thanks to these advancements, our approach is capable of performing semantic segmentation while simultaneously adapting at more than 29FPS on a single consumer-grade GPU. Our framework's encouraging accuracy and speed trade-off is demonstrated on OnDA and SHIFT benchmarks through experimental results.
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Visual-Acoustic-Matching"><a href="#Self-Supervised-Visual-Acoustic-Matching" class="headerlink" title="Self-Supervised Visual Acoustic Matching"></a>Self-Supervised Visual Acoustic Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15064">http://arxiv.org/abs/2307.15064</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arjun Somayazulu, Changan Chen, Kristen Grauman</li>
<li>for: 用于自然语言处理和媒体生成等应用场景，恢复和重新生成受到环境影响的音频clip。</li>
<li>methods: 提出一种自监督的方法，只使用目标场景图像和音频，不需要匹配的源音频作为参考。通过 Conditional GAN 框架和一种新的评价指标，学习抽象房间声学特征和重新生成音频。</li>
<li>results: 在多个挑战性的数据集上，与当前状态势最高，并在各种真实世界的音频和环境下表现出色。<details>
<summary>Abstract</summary>
Acoustic matching aims to re-synthesize an audio clip to sound as if it were recorded in a target acoustic environment. Existing methods assume access to paired training data, where the audio is observed in both source and target environments, but this limits the diversity of training data or requires the use of simulated data or heuristics to create paired samples. We propose a self-supervised approach to visual acoustic matching where training samples include only the target scene image and audio -- without acoustically mismatched source audio for reference. Our approach jointly learns to disentangle room acoustics and re-synthesize audio into the target environment, via a conditional GAN framework and a novel metric that quantifies the level of residual acoustic information in the de-biased audio. Training with either in-the-wild web data or simulated data, we demonstrate it outperforms the state-of-the-art on multiple challenging datasets and a wide variety of real-world audio and environments.
</details>
<details>
<summary>摘要</summary>
听音匹配目标是重新synthesize一个音频片段，使其在目标听音环境中 зву律。现有方法假设有对称的训练数据，其中包括源和目标环境中的音频，但这限制了训练数据的多样性或需要使用模拟数据或规则来生成对应的样本。我们提出了一种无监督的方法，通过jointly学习抽离房间听音和重新synthesize音频到目标环境中，使用条件GAAN框架和一个新的度量量化听音信息的减噪度。我们在使用实际网络数据或模拟数据进行训练后，示出其在多个挑战性 dataset 和真实世界的听音和环境中表现出色。
</details></li>
</ul>
<hr>
<h2 id="The-RoboDepth-Challenge-Methods-and-Advancements-Towards-Robust-Depth-Estimation"><a href="#The-RoboDepth-Challenge-Methods-and-Advancements-Towards-Robust-Depth-Estimation" class="headerlink" title="The RoboDepth Challenge: Methods and Advancements Towards Robust Depth Estimation"></a>The RoboDepth Challenge: Methods and Advancements Towards Robust Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15061">http://arxiv.org/abs/2307.15061</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ldkong1205/robodepth">https://github.com/ldkong1205/robodepth</a></li>
<li>paper_authors: Lingdong Kong, Yaru Niu, Shaoyuan Xie, Hanjiang Hu, Lai Xing Ng, Benoit R. Cottereau, Ding Zhao, Liangjun Zhang, Hesheng Wang, Wei Tsang Ooi, Ruijie Zhu, Ziyang Song, Li Liu, Tianzhu Zhang, Jun Yu, Mohan Jing, Pengwei Li, Xiaohua Qi, Cheng Jin, Yingfeng Chen, Jie Hou, Jie Zhang, Zhen Kan, Qiang Ling, Liang Peng, Minglei Li, Di Xu, Changpeng Yang, Yuanqi Yao, Gang Wu, Jian Kuai, Xianming Liu, Junjun Jiang, Jiamian Huang, Baojun Li, Jiale Chen, Shuang Zhang, Sun Ao, Zhenyu Li, Runze Chen, Haiyong Luo, Fang Zhao, Jingze Yu</li>
<li>for: 提高安全应用中深度估计的可靠性，如在不良天气、传感器故障和噪声污染等情况下提供可靠的深度预测。</li>
<li>methods: 使用自然语言处理、图像修复、超解析、对抗训练、扩散噪声消除、视觉语言预训练、学习模型ensemble和层次特征强化等方法来提高深度估计的 Robustness 和可靠性。</li>
<li>results: 通过RoboDepth Challenge的学术竞赛，发现了9种top-performing解决方案，包括空间-和频率域扩充、面罩模型、图像修复和超解析、对抗训练、扩散噪声消除、视觉语言预训练、学习模型ensemble和层次特征强化等方法，这些方法能够提高深度估计的可靠性和Robustness。<details>
<summary>Abstract</summary>
Accurate depth estimation under out-of-distribution (OoD) scenarios, such as adverse weather conditions, sensor failure, and noise contamination, is desirable for safety-critical applications. Existing depth estimation systems, however, suffer inevitably from real-world corruptions and perturbations and are struggled to provide reliable depth predictions under such cases. In this paper, we summarize the winning solutions from the RoboDepth Challenge -- an academic competition designed to facilitate and advance robust OoD depth estimation. This challenge was developed based on the newly established KITTI-C and NYUDepth2-C benchmarks. We hosted two stand-alone tracks, with an emphasis on robust self-supervised and robust fully-supervised depth estimation, respectively. Out of more than two hundred participants, nine unique and top-performing solutions have appeared, with novel designs ranging from the following aspects: spatial- and frequency-domain augmentations, masked image modeling, image restoration and super-resolution, adversarial training, diffusion-based noise suppression, vision-language pre-training, learned model ensembling, and hierarchical feature enhancement. Extensive experimental analyses along with insightful observations are drawn to better understand the rationale behind each design. We hope this challenge could lay a solid foundation for future research on robust and reliable depth estimation and beyond. The datasets, competition toolkit, workshop recordings, and source code from the winning teams are publicly available on the challenge website.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>实时深度估计在不同的应用场景中具有重要的意义，如恶劣天气、传感器故障和噪声污染等情况下，却存在现实世界中的干扰和损害，使得现有的深度估计系统很难提供可靠的深度预测。在这篇论文中，我们总结了RoboDepth Challenge中的胜利解决方案，这是一个学术竞赛，旨在促进和进步强健的应用场景外的深度估计。这个竞赛基于新建的KITTI-C和NYUDepth2-C标准准则。我们设置了两个独立的轨道，强调强健自我超vised和强健全supervised深度估计。共有超过200名参与者，9个独特和表现出色的解决方案出现在了，其中包括空间和频率域扩充、掩码图像模型、图像修复和超分辨率、对抗训练、扩散型噪声消除、视语预训练、学习集成和层次特征增强等方法。我们进行了广泛的实验分析和深入的观察，以更好地理解每种设计的原理。我们希望这次竞赛可以为未来的强健和可靠的深度估计奠定坚实的基础，并超出这个领域。竞赛网站上公开了数据集、竞赛工具箱、学术会录音和胜利团队的源代码。
</details></li>
</ul>
<hr>
<h2 id="MARS-An-Instance-aware-Modular-and-Realistic-Simulator-for-Autonomous-Driving"><a href="#MARS-An-Instance-aware-Modular-and-Realistic-Simulator-for-Autonomous-Driving" class="headerlink" title="MARS: An Instance-aware, Modular and Realistic Simulator for Autonomous Driving"></a>MARS: An Instance-aware, Modular and Realistic Simulator for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15058">http://arxiv.org/abs/2307.15058</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/open-air-sun/mars">https://github.com/open-air-sun/mars</a></li>
<li>paper_authors: Zirui Wu, Tianyu Liu, Liyi Luo, Zhide Zhong, Jianteng Chen, Hongmin Xiao, Chao Hou, Haozhe Lou, Yuantao Chen, Runyi Yang, Yuxin Huang, Xiaoyu Ye, Zike Yan, Yongliang Shi, Yiyi Liao, Hao Zhao</li>
<li>For: The paper proposes an autonomous driving simulator based on neural radiance fields (NeRFs) to solve remaining corner cases and improve realism in simulation.* Methods: The simulator models foreground instances and background environments separately with independent networks, allowing for flexible switching between different NeRF-related backbones, sampling strategies, input modalities, etc.* Results: The simulator achieves state-of-the-art photo-realism results and will be open-sourced, while most counterparts are not.Here’s the simplified Chinese text for the three key points:* For: 该论文提出了基于神经采样场（NeRF）的自动驾驶模拟器，以解决剩下的角落情况并提高模拟的真实性。* Methods: 该模拟器将前景实体和背景环境分别模型为独立的网络，允许自由地换换不同的NeRF相关脊梁、采样策略、输入模式等。* Results: 该模拟器实现了状态机器人化的图像真实性结果，并将被开源发布，而大多数对手不是。<details>
<summary>Abstract</summary>
Nowadays, autonomous cars can drive smoothly in ordinary cases, and it is widely recognized that realistic sensor simulation will play a critical role in solving remaining corner cases by simulating them. To this end, we propose an autonomous driving simulator based upon neural radiance fields (NeRFs). Compared with existing works, ours has three notable features: (1) Instance-aware. Our simulator models the foreground instances and background environments separately with independent networks so that the static (e.g., size and appearance) and dynamic (e.g., trajectory) properties of instances can be controlled separately. (2) Modular. Our simulator allows flexible switching between different modern NeRF-related backbones, sampling strategies, input modalities, etc. We expect this modular design to boost academic progress and industrial deployment of NeRF-based autonomous driving simulation. (3) Realistic. Our simulator set new state-of-the-art photo-realism results given the best module selection. Our simulator will be open-sourced while most of our counterparts are not. Project page: https://open-air-sun.github.io/mars/.
</details>
<details>
<summary>摘要</summary>
现在，自动驾驶车可以平稳驾驶在常见情况下，而实际感知器模拟将在解决剩下的角度情况中扮演关键角色。为此，我们提出了基于神经辐射场（NeRFs）的自动驾驶模拟器。与现有作品相比，我们的模拟器具有以下三个特点：1. 实例感知：我们的模拟器将背景环境和前景实例分别模型为独立的网络，以便分别控制实例的静态特性（如大小和外观）和动态特性（如轨迹）。2. 模块化：我们的模拟器允许自由地换换不同的现代NeRF相关脊梁、采样策略、输入Modalities等。我们期望这种模块化设计能促进学术进步和实业应用NeRF相关自动驾驶模拟。3. 实际：我们的模拟器在选择最佳模块时创造了新的state-of-the-art的 фото实实alomResults。我们的模拟器将被开源，而大多数对手不是。项目页面：<https://open-air-sun.github.io/mars/>。
</details></li>
</ul>
<hr>
<h2 id="PointOdyssey-A-Large-Scale-Synthetic-Dataset-for-Long-Term-Point-Tracking"><a href="#PointOdyssey-A-Large-Scale-Synthetic-Dataset-for-Long-Term-Point-Tracking" class="headerlink" title="PointOdyssey: A Large-Scale Synthetic Dataset for Long-Term Point Tracking"></a>PointOdyssey: A Large-Scale Synthetic Dataset for Long-Term Point Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15055">http://arxiv.org/abs/2307.15055</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/y-zheng18/point_odyssey">https://github.com/y-zheng18/point_odyssey</a></li>
<li>paper_authors: Yang Zheng, Adam W. Harley, Bokui Shen, Gordon Wetzstein, Leonidas J. Guibas</li>
<li>for: 本研究旨在提高长期细化跟踪算法的状态前方，强调自然化的运动。</li>
<li>methods: 该研究使用真实世界动作捕捉数据来动画可变形人物，建立3D场景，并使用结构从动视觉来渲染摄像头视点。其中，人物的外观、动作特征、物理、照明和大气效果都进行了随机化。</li>
<li>results: 研究人员通过对现有算法进行修改，使其在PointOdyssey数据集上表现更好，并在两个真实世界benchmark上表现出色。此外，研究人员还提出了一种改进PIPs点跟踪方法，使其在时间上具有更广泛的感知范围，并在PointOdyssey数据集和两个真实世界benchmark上提高了表现。<details>
<summary>Abstract</summary>
We introduce PointOdyssey, a large-scale synthetic dataset, and data generation framework, for the training and evaluation of long-term fine-grained tracking algorithms. Our goal is to advance the state-of-the-art by placing emphasis on long videos with naturalistic motion. Toward the goal of naturalism, we animate deformable characters using real-world motion capture data, we build 3D scenes to match the motion capture environments, and we render camera viewpoints using trajectories mined via structure-from-motion on real videos. We create combinatorial diversity by randomizing character appearance, motion profiles, materials, lighting, 3D assets, and atmospheric effects. Our dataset currently includes 104 videos, averaging 2,000 frames long, with orders of magnitude more correspondence annotations than prior work. We show that existing methods can be trained from scratch in our dataset and outperform the published variants. Finally, we introduce modifications to the PIPs point tracking method, greatly widening its temporal receptive field, which improves its performance on PointOdyssey as well as on two real-world benchmarks. Our data and code are publicly available at: https://pointodyssey.com
</details>
<details>
<summary>摘要</summary>
我们介绍PointOdyssey，一个大规模的人工数据集和数据生成框架，用于长期精细跟踪算法的训练和评估。我们的目标是提高状态的艺术性，因此我们使用了真实的动作捕捉数据来动画可变的人物，建立了基于动作捕捉环境的3D场景，并使用了从结构 FROM 运动中挖掘的轨迹来渲染摄像头视点。我们创造了多样性的组合，通过随机化人物的外观、动作特征、物理、照明、3D资产和大气效果来创造多样性。我们的数据集目前包含104个视频，每个视频平均2,000帧长，与先前的工作相比有几个数量级的更多的对应笔记注解。我们示出了在我们数据集中可以从头开始训练现有方法，并在PointOdyssey上以及两个真实的benchmark上表现出色。最后，我们对PIPs点跟踪方法进行修改，使其 temporal 感知场景得到了大幅提高，这也提高了它的表现在PointOdyssey上以及两个真实的benchmark上。我们的数据和代码在https://pointodyssey.com 上公开 available。
</details></li>
</ul>
<hr>
<h2 id="Learning-Depth-Estimation-for-Transparent-and-Mirror-Surfaces"><a href="#Learning-Depth-Estimation-for-Transparent-and-Mirror-Surfaces" class="headerlink" title="Learning Depth Estimation for Transparent and Mirror Surfaces"></a>Learning Depth Estimation for Transparent and Mirror Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15052">http://arxiv.org/abs/2307.15052</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Costanzino, Pierluigi Zama Ramirez, Matteo Poggi, Fabio Tosi, Stefano Mattoccia, Luigi Di Stefano</li>
<li>for: 估算透明或镜面（ToM）表面深度是一个困难的任务，需要感知器、算法或深度网络。</li>
<li>methods: 我们提出了一个简单的管道，使用神经网络来学习正确地估算ToM表面深度，无需任何真实标注。我们解释了如何获取可靠的 pseudo标签，通过在图像中填充ToM对象并使用单视深度估算模型来处理它们。这些标签可以用于练化现有的单视或双视网络，让它们学习如何处理ToM表面。</li>
<li>results: 在Booster数据集上进行实验，我们发现我们的简单提案具有很大的改进作用。<details>
<summary>Abstract</summary>
Inferring the depth of transparent or mirror (ToM) surfaces represents a hard challenge for either sensors, algorithms, or deep networks. We propose a simple pipeline for learning to estimate depth properly for such surfaces with neural networks, without requiring any ground-truth annotation. We unveil how to obtain reliable pseudo labels by in-painting ToM objects in images and processing them with a monocular depth estimation model. These labels can be used to fine-tune existing monocular or stereo networks, to let them learn how to deal with ToM surfaces. Experimental results on the Booster dataset show the dramatic improvements enabled by our remarkably simple proposal.
</details>
<details>
<summary>摘要</summary>
描述透明或镜面（ToM）表面的深度很难以由感知器、算法或深度网络正确地推断。我们提出了一个简单的管道，通过神经网络来学习对ToM表面的深度估计，无需任何真实标注。我们解释了如何获得可靠的pseudo标签，通过在图像中填充ToM对象并使用单目深度估计模型处理它们。这些标签可以用来练化现有的单目或双目网络，让它们学习如何处理ToM表面。实验结果表明，我们的非常简单的建议带来了 dramatic improvement。
</details></li>
</ul>
<hr>
<h2 id="Regularized-Mask-Tuning-Uncovering-Hidden-Knowledge-in-Pre-trained-Vision-Language-Models"><a href="#Regularized-Mask-Tuning-Uncovering-Hidden-Knowledge-in-Pre-trained-Vision-Language-Models" class="headerlink" title="Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-trained Vision-Language Models"></a>Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-trained Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15049">http://arxiv.org/abs/2307.15049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kecheng Zheng, Wei Wu, Ruili Feng, Kai Zhu, Jiawei Liu, Deli Zhao, Zheng-Jun Zha, Wei Chen, Yujun Shen</li>
<li>for: 这个研究想要将预训练的潜在视觉语言模型（VLM）转移到不同的下游任务上。</li>
<li>methods: 我们提出了一种新型的调整方法，即弹性掩蔽调整法，它通过学习选择器来掩蔽网络参数。我们参考了神经通路，认为预训练过程中隐藏在网络参数中的知识，可以透过调整这些参数来把其恢复到光。我们首先选择一个下游任务中需要的参数集，然后将这些参数给掩蔽，最后在下游数据上优化这些掩蔽。当更新掩蔽时，我们引入了一种新的梯度减少策略，以调整参数选择，以避免模型忘记过去的知识并过滤下游数据。</li>
<li>results: 我们在11个数据集上进行实验，结果显示我们的方法在前一代的方法上具有优越的性能。特别是，我们可以透过仅将2.56%的参数掩蔽，实现18.73%的性能提升，比零基elineCLIP更高。此外，我们的方法可以与大多数现有的参数效率调整方法相互作用，可以将其表现提升。详细信息可以查看我们的项目页面（<a target="_blank" rel="noopener" href="https://wuw2019.github.io/R-AMT/%EF%BC%89%E3%80%82">https://wuw2019.github.io/R-AMT/）。</a><details>
<summary>Abstract</summary>
Prompt tuning and adapter tuning have shown great potential in transferring pre-trained vision-language models (VLMs) to various downstream tasks. In this work, we design a new type of tuning method, termed as regularized mask tuning, which masks the network parameters through a learnable selection. Inspired by neural pathways, we argue that the knowledge required by a downstream task already exists in the pre-trained weights but just gets concealed in the upstream pre-training stage. To bring the useful knowledge back into light, we first identify a set of parameters that are important to a given downstream task, then attach a binary mask to each parameter, and finally optimize these masks on the downstream data with the parameters frozen. When updating the mask, we introduce a novel gradient dropout strategy to regularize the parameter selection, in order to prevent the model from forgetting old knowledge and overfitting the downstream data. Experimental results on 11 datasets demonstrate the consistent superiority of our method over previous alternatives. It is noteworthy that we manage to deliver 18.73% performance improvement compared to the zero-shot CLIP via masking an average of only 2.56% parameters. Furthermore, our method is synergistic with most existing parameter-efficient tuning methods and can boost the performance on top of them. Project page can be found here (https://wuw2019.github.io/R-AMT/).
</details>
<details>
<summary>摘要</summary>
Prompt tuning和adapter tuning已经在将预训练的视觉语言模型（VLM）转移到多种下游任务中显示了很大的潜力。在这项工作中，我们设计了一种新的调参方法，称为正则化面 Selection Tuning（R-AMT）。受神经网络的启发，我们认为预训练阶段中隐藏在预训练模型中的知识已经存在于下游任务中。为了让这些知识重新浮现，我们首先确定了一个下游任务中重要的参数集，然后将每个参数添加一个二进制面，最后在下游数据上优化这些面。在更新面时，我们引入了一种新的梯度抑制策略，以避免模型忘记原来的知识并遇到下游数据上的过拟合。实验结果在11个数据集上表明，我们的方法与之前的方法相比具有显著的优势。具体来说，我们通过面 Selection Tuning仅占用2.56%的参数平均提高了CLIP的性能18.73%。此外，我们的方法可以与大多数现有的参数效率调参方法相结合，并可以提高它们的性能。相关页面可以在这里找到（https://wuw2019.github.io/R-AMT/）。
</details></li>
</ul>
<hr>
<h2 id="A-Transformer-based-Approach-for-Arabic-Offline-Handwritten-Text-Recognition"><a href="#A-Transformer-based-Approach-for-Arabic-Offline-Handwritten-Text-Recognition" class="headerlink" title="A Transformer-based Approach for Arabic Offline Handwritten Text Recognition"></a>A Transformer-based Approach for Arabic Offline Handwritten Text Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15045">http://arxiv.org/abs/2307.15045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saleh Momeni, Bagher BabaAli</li>
<li>for: 本研究旨在提高 Offline 阿拉伯手写文本识别精度。</li>
<li>methods: 我们提出了两种新的架构：Transformer Transducer 和标准sequence-to-sequence Transformer，并对其表现进行比较。这两种架构均利用了注意力机制，可以更好地模型语言依赖关系，并且更容易并行化。</li>
<li>results: 我们的方法在 Arabic KHATT 数据集上的评估中表现出色，超越了现有的状态之作。<details>
<summary>Abstract</summary>
Handwriting recognition is a challenging and critical problem in the fields of pattern recognition and machine learning, with applications spanning a wide range of domains. In this paper, we focus on the specific issue of recognizing offline Arabic handwritten text. Existing approaches typically utilize a combination of convolutional neural networks for image feature extraction and recurrent neural networks for temporal modeling, with connectionist temporal classification used for text generation. However, these methods suffer from a lack of parallelization due to the sequential nature of recurrent neural networks. Furthermore, these models cannot account for linguistic rules, necessitating the use of an external language model in the post-processing stage to boost accuracy. To overcome these issues, we introduce two alternative architectures, namely the Transformer Transducer and the standard sequence-to-sequence Transformer, and compare their performance in terms of accuracy and speed. Our approach can model language dependencies and relies only on the attention mechanism, thereby making it more parallelizable and less complex. We employ pre-trained Transformers for both image understanding and language modeling. Our evaluation on the Arabic KHATT dataset demonstrates that our proposed method outperforms the current state-of-the-art approaches for recognizing offline Arabic handwritten text.
</details>
<details>
<summary>摘要</summary>
手写识别是Pattern recognition和机器学习领域中的一个挑战和重要问题，其应用范围广泛，包括文本识别、语音识别、图像识别等领域。在本文中，我们将关注特定的问题是 Offline 阿拉伯手写文本识别。现有的方法通常使用混合 convolutional neural networks  для图像特征提取和 recurrent neural networks  для时间模型化，并使用 connectionist temporal classification  для文本生成。然而，这些方法受到缺乏并行化的约束，以及不能考虑语言规则的限制，因此需要在后期处理阶段使用外部语言模型以提高准确性。为了解决这些问题，我们提出了两种 altenative 架构：Transformer Transducer 和标准 sequence-to-sequence Transformer。我们 comparing 这两种架构的性能，包括准确率和速度。我们的方法可以模型语言依赖关系，只靠注意机制进行并行化，因此更加简单和高效。我们使用预训练的 Transformers 来进行图像理解和语言模型化。我们的评估结果表明，我们的提议方法在 Offline 阿拉伯手写文本识别领域的现状顶峰性能。
</details></li>
</ul>
<hr>
<h2 id="TEDi-Temporally-Entangled-Diffusion-for-Long-Term-Motion-Synthesis"><a href="#TEDi-Temporally-Entangled-Diffusion-for-Long-Term-Motion-Synthesis" class="headerlink" title="TEDi: Temporally-Entangled Diffusion for Long-Term Motion Synthesis"></a>TEDi: Temporally-Entangled Diffusion for Long-Term Motion Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15042">http://arxiv.org/abs/2307.15042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihan Zhang, Richard Liu, Kfir Aberman, Rana Hanocka</li>
<li>for: 提出一种基于渐进噪声泛化的动作序列 sintesis 模型，以满足长期动作synthesis的应用需求。</li>
<li>methods: 利用渐进噪声泛化概率模型（DDPM）的核心思想，在时间轴上实现渐进噪声泛化，并在动作序列中随时间变化。</li>
<li>results: 通过实验表明，提出的方法可以生成高质量的动作序列，并且可以应用于人物动画和其他领域。<details>
<summary>Abstract</summary>
The gradual nature of a diffusion process that synthesizes samples in small increments constitutes a key ingredient of Denoising Diffusion Probabilistic Models (DDPM), which have presented unprecedented quality in image synthesis and been recently explored in the motion domain. In this work, we propose to adapt the gradual diffusion concept (operating along a diffusion time-axis) into the temporal-axis of the motion sequence. Our key idea is to extend the DDPM framework to support temporally varying denoising, thereby entangling the two axes. Using our special formulation, we iteratively denoise a motion buffer that contains a set of increasingly-noised poses, which auto-regressively produces an arbitrarily long stream of frames. With a stationary diffusion time-axis, in each diffusion step we increment only the temporal-axis of the motion such that the framework produces a new, clean frame which is removed from the beginning of the buffer, followed by a newly drawn noise vector that is appended to it. This new mechanism paves the way towards a new framework for long-term motion synthesis with applications to character animation and other domains.
</details>
<details>
<summary>摘要</summary>
《慢慢进程的扩散过程 Synthesize 样本在小幅度 increments 中是关键组成部分，这种方法被称为 Denoising Diffusion Probabilistic Models (DDPM)，它在图像生成中提供了无 precedent 的质量，并在近期被探索在运动频谱中。在这项工作中，我们提议将慢慢扩散概念（在扩散时间轴上进行）扩展到运动序列的 temporal 轴。我们的关键想法是在 DDPM 框架中支持时间变化的净化，从而将两个轴相互束缚。使用我们的特殊形式ulation，我们在每个扩散步骤中只 increments 运动序列中的时间轴，以生成一个新的、干净的帧，并将其从运动缓冲中移除。然后，我们随机生成一个新的噪声向量，并将其追加到缓冲中。这种新机制开 up a new 框架，可以用于长期运动生成，并具有应用于人物动画和其他领域的潜在应用。]Note: Please note that the translation is in Simplified Chinese, and the word order and grammar may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Detecting-Morphing-Attacks-via-Continual-Incremental-Training"><a href="#Detecting-Morphing-Attacks-via-Continual-Incremental-Training" class="headerlink" title="Detecting Morphing Attacks via Continual Incremental Training"></a>Detecting Morphing Attacks via Continual Incremental Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15105">http://arxiv.org/abs/2307.15105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Pellegrini, Guido Borghi, Annalisa Franco, Davide Maltoni</li>
<li>for: 这个论文旨在解决数据传输和存储限制下，难以组合单一数据集，以执行批处理训练方法。</li>
<li>methods: 这篇论文使用了不同数据源的Continual Learning（CL）方法， simulate一个随着新数据块的到达，模型在每一轮训练中更新的场景。</li>
<li>results: 实验结果显示，Learning without Forgetting（LwF）方法在这种场景下表现最佳，并且在 Morphing Attack Detection 和 Object Classification 任务中进行了详细的调研和优化。<details>
<summary>Abstract</summary>
Scenarios in which restrictions in data transfer and storage limit the possibility to compose a single dataset -- also exploiting different data sources -- to perform a batch-based training procedure, make the development of robust models particularly challenging. We hypothesize that the recent Continual Learning (CL) paradigm may represent an effective solution to enable incremental training, even through multiple sites. Indeed, a basic assumption of CL is that once a model has been trained, old data can no longer be used in successive training iterations and in principle can be deleted. Therefore, in this paper, we investigate the performance of different Continual Learning methods in this scenario, simulating a learning model that is updated every time a new chunk of data, even of variable size, is available. Experimental results reveal that a particular CL method, namely Learning without Forgetting (LwF), is one of the best-performing algorithms. Then, we investigate its usage and parametrization in Morphing Attack Detection and Object Classification tasks, specifically with respect to the amount of new training data that became available.
</details>
<details>
<summary>摘要</summary>
具有限制数据传输和存储的场景下，组成单一数据集并在多个数据源上进行批处理训练过程中存在很大挑战。我们假设，最近的不间断学习（Continual Learning，CL） paradigm可能是一个有效的解决方案，以允许逐步训练，即使在多个站点之间。实际上，CL的基本假设是，一旦模型已经训练过，那么过去的数据不能在后续训练过程中再次使用，并且可以被删除。因此，在这篇论文中，我们 investigate CL方法在这种enario下的表现，通过模拟一个可以在新数据批量可用时更新的学习模型。实验结果表明，一种特定的CL方法，即不忘学习（Learning without Forgetting，LwF）是最佳性能的算法之一。然后，我们进一步调查其在形态攻击检测和对象分类任务中的使用和参数化情况，具体是关于可用新训练数据的量。
</details></li>
</ul>
<hr>
<h2 id="Diverse-Inpainting-and-Editing-with-GAN-Inversion"><a href="#Diverse-Inpainting-and-Editing-with-GAN-Inversion" class="headerlink" title="Diverse Inpainting and Editing with GAN Inversion"></a>Diverse Inpainting and Editing with GAN Inversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15033">http://arxiv.org/abs/2307.15033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmet Burak Yildirim, Hamza Pehlivan, Bahri Batuhan Bilecen, Aysegul Dundar</li>
<li>for: 实现从 StyleGAN 的潜在空间还原被删除的图像，并在这些图像上进行许多编辑。</li>
<li>methods: 我们提出了一个将删除图像的潜在代码与 StyleGAN 的映射特征结合的混合网络，以及一个使用生成的数据进行训练的新设计。</li>
<li>results: 我们的方法与现有的逆向和填充方法进行比较，实现了较好的质量和多样性。<details>
<summary>Abstract</summary>
Recent inversion methods have shown that real images can be inverted into StyleGAN's latent space and numerous edits can be achieved on those images thanks to the semantically rich feature representations of well-trained GAN models. However, extensive research has also shown that image inversion is challenging due to the trade-off between high-fidelity reconstruction and editability. In this paper, we tackle an even more difficult task, inverting erased images into GAN's latent space for realistic inpaintings and editings. Furthermore, by augmenting inverted latent codes with different latent samples, we achieve diverse inpaintings. Specifically, we propose to learn an encoder and mixing network to combine encoded features from erased images with StyleGAN's mapped features from random samples. To encourage the mixing network to utilize both inputs, we train the networks with generated data via a novel set-up. We also utilize higher-rate features to prevent color inconsistencies between the inpainted and unerased parts. We run extensive experiments and compare our method with state-of-the-art inversion and inpainting methods. Qualitative metrics and visual comparisons show significant improvements.
</details>
<details>
<summary>摘要</summary>
现在的倒转方法已经证明了真实图像可以被StyleGAN的含义空间内转换，并且可以通过训练过的GAN模型中的含义强的特征表示来实现多个编辑。然而，广泛的研究也表明，图像倒转是一项复杂的任务，因为存在高精度重建和编辑之间的负担。在这篇论文中，我们面临更加困难的任务：将抹消图像转换到GAN模型的含义空间中，以获得真实的填充和编辑。此外，我们还利用不同的含义样本来扩展 reverted 的含义代码，以实现多样化的填充。具体来说，我们提议使用编码器和混合网络将抹消图像的编码特征与StyleGAN的映射特征混合在一起。为了让混合网络使用两个输入，我们在网络训练时使用生成的数据进行新的设置。我们还利用更高的比率特征，以避免在填充和未抹消部分之间的颜色不一致。我们进行了广泛的实验，并与当前的倒转和填充方法进行比较。质量指标和视觉比较表明存在显著的改进。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Segmentation-Network-for-Scene-Text-Detection"><a href="#Adaptive-Segmentation-Network-for-Scene-Text-Detection" class="headerlink" title="Adaptive Segmentation Network for Scene Text Detection"></a>Adaptive Segmentation Network for Scene Text Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15029">http://arxiv.org/abs/2307.15029</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guiqin Zhao</li>
<li>for: 提高场景文本检测器的性能，解决手动调整参数的繁琐问题，并且能够处理文本实例的极大比例和方向。</li>
<li>methods: 提出自适应分 segmentation 阈值学习方法，自动分辨文本像素和背景像素，并且使用全球信息增强特征层网络（GE-FPN）捕捉文本实例的macro大小和极大比例。其后，引入层次优化结构进一步精细化文本实例。</li>
<li>results: 通过提出的阈值学习策略和文本检测结构，实现了场景文本检测器的state-of-the-art性能，并且通过缺失实验证明了我们的贡献的有效性。<details>
<summary>Abstract</summary>
Inspired by deep convolution segmentation algorithms, scene text detectors break the performance ceiling of datasets steadily. However, these methods often encounter threshold selection bottlenecks and have poor performance on text instances with extreme aspect ratios. In this paper, we propose to automatically learn the discriminate segmentation threshold, which distinguishes text pixels from background pixels for segmentation-based scene text detectors and then further reduces the time-consuming manual parameter adjustment. Besides, we design a Global-information Enhanced Feature Pyramid Network (GE-FPN) for capturing text instances with macro size and extreme aspect ratios. Following the GE-FPN, we introduce a cascade optimization structure to further refine the text instances. Finally, together with the proposed threshold learning strategy and text detection structure, we design an Adaptive Segmentation Network (ASNet) for scene text detection. Extensive experiments are carried out to demonstrate that the proposed ASNet can achieve the state-of-the-art performance on four text detection benchmarks, i.e., ICDAR 2015, MSRA-TD500, ICDAR 2017 MLT and CTW1500. The ablation experiments also verify the effectiveness of our contributions.
</details>
<details>
<summary>摘要</summary>
深受深度卷积分割算法的启发，场景文本检测器不断突破数据集的性能峰值。然而，这些方法经常遇到选择阈值的瓶颈和文本实例的极大比例问题。在这篇论文中，我们提议自动学习分割 segmentation 阈值，以分别文本像素和背景像素，从而降低时间消耗的手动参数调整。此外，我们设计了全球信息增强特征层网络（GE-FPN），用于捕捉文本实例的大小和极大比例。接着，我们引入了层次优化结构，以进一步细化文本实例。最后，我们结合提出的阈值学习策略和文本检测结构，设计了适应性网络（ASNet） для场景文本检测。广泛的实验表明，我们的ASNet可以在四个文本检测标准准则上达到领先性状态，即ICDAR 2015、MSRA-TD500、ICDAR 2017 MLT 和 CTW1500。另外，我们的拓展实验也证明了我们的贡献的有效性。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Graph-Transformer-for-Deepfake-Detection"><a href="#Self-Supervised-Graph-Transformer-for-Deepfake-Detection" class="headerlink" title="Self-Supervised Graph Transformer for Deepfake Detection"></a>Self-Supervised Graph Transformer for Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15019">http://arxiv.org/abs/2307.15019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aminollah Khormali, Jiann-Shiun Yuan</li>
<li>For: 本研究提出了一种深伪检测框架，用于检测视频中的深伪。* Methods: 该框架包括一个基于视觉转换器架构的特征提取器，一个基于Transformer推理器的图 convolutional网络，以及一个图Transformer相关图。* Results: 研究人员通过进行多种难题的实验，包括在不同数据集上进行测试、跨数据集检测、跨操作检测和对常见后期处理抖散的检测，得到了该框架的优秀效果，超过了当前状态艺术方法。<details>
<summary>Abstract</summary>
Deepfake detection methods have shown promising results in recognizing forgeries within a given dataset, where training and testing take place on the in-distribution dataset. However, their performance deteriorates significantly when presented with unseen samples. As a result, a reliable deepfake detection system must remain impartial to forgery types, appearance, and quality for guaranteed generalizable detection performance. Despite various attempts to enhance cross-dataset generalization, the problem remains challenging, particularly when testing against common post-processing perturbations, such as video compression or blur. Hence, this study introduces a deepfake detection framework, leveraging a self-supervised pre-training model that delivers exceptional generalization ability, withstanding common corruptions and enabling feature explainability. The framework comprises three key components: a feature extractor based on vision Transformer architecture that is pre-trained via self-supervised contrastive learning methodology, a graph convolution network coupled with a Transformer discriminator, and a graph Transformer relevancy map that provides a better understanding of manipulated regions and further explains the model's decision. To assess the effectiveness of the proposed framework, several challenging experiments are conducted, including in-data distribution performance, cross-dataset, cross-manipulation generalization, and robustness against common post-production perturbations. The results achieved demonstrate the remarkable effectiveness of the proposed deepfake detection framework, surpassing the current state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
深度伪造检测方法已经在给定的数据集上显示出了可靠的结果，但是在见到过去的数据集上进行测试时，其表现会受到很大的损害。因此，一个可靠的深度伪造检测系统必须保持不偏向于伪造类型、外观和质量，以确保普遍可靠的检测性能。尽管有许多尝试来提高跨数据集通用性，这个问题仍然是挑战，特别是在面对常见的后期处理扰动时。因此，本研究将提出一个深度伪造检测框架，利用一个自我超vised的预训练模型，具有出色的通用能力，抵抗常见的扰动和提供功能解释。这个框架包括三个关键 комponent：一个基于视觉对应架构的Feature Extractor，一个与对应架构的Transformer Discriminator，以及一个基于对应架构的Graph Transformer Relevancy Map。为了评估提案的效果，本研究将进行许多挑战性的实验，包括在原始数据集上的性能、跨数据集通用性、跨修改通用性和对常见后期处理扰动的Robustness。实验结果显示，提案的深度伪造检测框架具有卓越的效果，超过现有的方法。
</details></li>
</ul>
<hr>
<h2 id="Verifiable-Feature-Attributions-A-Bridge-between-Post-Hoc-Explainability-and-Inherent-Interpretability"><a href="#Verifiable-Feature-Attributions-A-Bridge-between-Post-Hoc-Explainability-and-Inherent-Interpretability" class="headerlink" title="Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability"></a>Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15007">http://arxiv.org/abs/2307.15007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Usha Bhalla, Suraj Srinivas, Himabindu Lakkaraju</li>
<li>for: 这 paper 的目的是解释机器学习模型的行为，提高模型的可解释性。</li>
<li>methods: 这 paper 使用了两种主要的解释策略：post hoc 解释和嵌入式可解释模型。post hoc 解释方法可以解释复杂的黑盒模型的行为，但是这些解释可能不准确，而且无法验证。嵌入式可解释模型则可以自动编码解释到模型结构中，解释是自然的、可靠的和验证的，但是它们通常具有较强的表达能力。这 paper 提出了一种方法，即 Verifiability Tuning (VerT)，可以将黑盒模型转化成可靠、可验证的解释模型。</li>
<li>results: 这 paper 的实验结果表明，VerT 可以将黑盒模型转化成可靠、可验证的解释模型，并且这些解释模型可以correctly 和可靠地解释模型的行为。同时，VerT 还可以保持黑盒模型的预测性能。<details>
<summary>Abstract</summary>
With the increased deployment of machine learning models in various real-world applications, researchers and practitioners alike have emphasized the need for explanations of model behaviour. To this end, two broad strategies have been outlined in prior literature to explain models. Post hoc explanation methods explain the behaviour of complex black-box models by highlighting features that are critical to model predictions; however, prior work has shown that these explanations may not be faithful, and even more concerning is our inability to verify them. Specifically, it is nontrivial to evaluate if a given attribution is correct with respect to the underlying model. Inherently interpretable models, on the other hand, circumvent these issues by explicitly encoding explanations into model architecture, meaning their explanations are naturally faithful and verifiable, but they often exhibit poor predictive performance due to their limited expressive power. In this work, we aim to bridge the gap between the aforementioned strategies by proposing Verifiability Tuning (VerT), a method that transforms black-box models into models that naturally yield faithful and verifiable feature attributions. We begin by introducing a formal theoretical framework to understand verifiability and show that attributions produced by standard models cannot be verified. We then leverage this framework to propose a method to build verifiable models and feature attributions out of fully trained black-box models. Finally, we perform extensive experiments on semi-synthetic and real-world datasets, and show that VerT produces models that (1) yield explanations that are correct and verifiable and (2) are faithful to the original black-box models they are meant to explain.
</details>
<details>
<summary>摘要</summary>
随着机器学习模型在各种实际应用中的广泛部署，研究人员和实践者们一样强调了模型行为的解释的必要性。为此，先前的文献中提出了两种广泛的解释策略：后期解释方法通过强调模型预测中关键的特征来解释复杂黑盒模型的行为，但是先前的研究表明这些解释可能不准确，甚至更加担忧的是无法确认这些贡献的正确性。而内置可解释模型则通过显式地编码解释到模型建构中，因此其解释自然地准确和可靠，但它们通常具有有限的表达能力，导致预测性能不佳。在这个工作中，我们希望bridge这两种策略的差异，提出一种名为Verifiability Tuning（VerT）的方法，可以将黑盒模型转化为可以自然地生成准确和可靠的特征贡献的模型。我们首先引入了一个正式的理论框架，以理解可靠性的概念，并证明标准模型生成的贡献无法被验证。然后，我们利用这个框架，提出一种建立可靠模型和特征贡献的方法，并在 semi-synthetic 和实际数据集上进行了广泛的实验，结果表明VerT可以生成准确和可靠的特征贡献，同时保持和原始黑盒模型相同的预测性能。
</details></li>
</ul>
<hr>
<h2 id="MapNeRF-Incorporating-Map-Priors-into-Neural-Radiance-Fields-for-Driving-View-Simulation"><a href="#MapNeRF-Incorporating-Map-Priors-into-Neural-Radiance-Fields-for-Driving-View-Simulation" class="headerlink" title="MapNeRF: Incorporating Map Priors into Neural Radiance Fields for Driving View Simulation"></a>MapNeRF: Incorporating Map Priors into Neural Radiance Fields for Driving View Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14981">http://arxiv.org/abs/2307.14981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenming Wu, Jiadai Sun, Zhelun Shen, Liangjun Zhang</li>
<li>for: 用于自动驾驶测试中测试摄像头感知器。</li>
<li>methods: 利用map假设来将神经辐射场与不确定摄像头位置整合，以确保多视角一致性。</li>
<li>results: 实验结果显示，我们的方法可以在偏离路径上维持 semantic consistency。详细视频可以在<a target="_blank" rel="noopener" href="https://youtu.be/jEQWr-Rfh3A%E4%B8%AD%E6%A3%80%E8%A7%86%E3%80%82">https://youtu.be/jEQWr-Rfh3A中检视。</a><details>
<summary>Abstract</summary>
Simulating camera sensors is a crucial task in autonomous driving. Although neural radiance fields are exceptional at synthesizing photorealistic views in driving simulations, they still fail to generate extrapolated views. This paper proposes to incorporate map priors into neural radiance fields to synthesize out-of-trajectory driving views with semantic road consistency. The key insight is that map information can be utilized as a prior to guiding the training of the radiance fields with uncertainty. Specifically, we utilize the coarse ground surface as uncertain information to supervise the density field and warp depth with uncertainty from unknown camera poses to ensure multi-view consistency. Experimental results demonstrate that our approach can produce semantic consistency in deviated views for vehicle camera simulation. The supplementary video can be viewed at https://youtu.be/jEQWr-Rfh3A.
</details>
<details>
<summary>摘要</summary>
simulate 摄像头传感器是自动驾驶中非常重要的任务。尽管神经辐射场是在驾驶 simulations 中生成 photorealistic 视图的非常好的方法，但它们仍然无法生成 extrapolated 视图。这篇论文提议将地图约束 incorporated 到神经辐射场中，以生成 deviated 视图的 semantic 路况一致性。关键的思想是利用地图信息作为训练神经辐射场的先验知识，以确保多视图一致性。特别是，我们利用 unknown 相机 pose 中的不确定信息来监督density field 和折叠深度的学习，以确保多视图一致性。实验结果表明，我们的方法可以在 deviated 视图中保持 semantic 路况一致性。补充视频可以在 https://youtu.be/jEQWr-Rfh3A 上查看。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/28/cs.CV_2023_07_28/" data-id="clogyj8xe00f07cra2am00qe7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/28/cs.AI_2023_07_28/" class="article-date">
  <time datetime="2023-07-28T12:00:00.000Z" itemprop="datePublished">2023-07-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/28/cs.AI_2023_07_28/">cs.AI - 2023-07-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Evaluating-the-structure-of-cognitive-tasks-with-transfer-learning"><a href="#Evaluating-the-structure-of-cognitive-tasks-with-transfer-learning" class="headerlink" title="Evaluating the structure of cognitive tasks with transfer learning"></a>Evaluating the structure of cognitive tasks with transfer learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02408">http://arxiv.org/abs/2308.02408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bruno Aristimunha, Raphael Y. de Camargo, Walter H. Lopez Pinaya, Sylvain Chevallier, Alexandre Gramfort, Cedric Rommel</li>
<li>for: 这项研究旨在 investigate deep learning representations 的可传递性在不同的EEG解oding任务中。</li>
<li>methods: 研究者使用了现有的decoding模型和两个最新发布的EEG数据集（ERP CORE和M$^3$CV），包含140个人和11种不同的认知任务。他们测试了在一个任务上预训练深度神经网络后，其能够decode到后续任务的能力。</li>
<li>results: 研究结果表明，即使使用线性探测传输，也可以获得显著的提高，与纯粹的超vised方法相比，提高了最多28%。此外，研究者发现了一些解oding方案会释放特定和窄的脑活动，而其他解oding方案则需要预训练在广泛的表征上。这些发现有助于解决EEG解oding中的数据稀缺问题，并且提供了减少数据稀缺的实际应用。同时，生成的传输图也提供了认知任务之间的层次关系的理解，从 neuroscientific 的角度来看。<details>
<summary>Abstract</summary>
Electroencephalography (EEG) decoding is a challenging task due to the limited availability of labelled data. While transfer learning is a promising technique to address this challenge, it assumes that transferable data domains and task are known, which is not the case in this setting. This study investigates the transferability of deep learning representations between different EEG decoding tasks. We conduct extensive experiments using state-of-the-art decoding models on two recently released EEG datasets, ERP CORE and M$^3$CV, containing over 140 subjects and 11 distinct cognitive tasks. We measure the transferability of learned representations by pre-training deep neural networks on one task and assessing their ability to decode subsequent tasks. Our experiments demonstrate that, even with linear probing transfer, significant improvements in decoding performance can be obtained, with gains of up to 28% compare with the pure supervised approach. Additionally, we discover evidence that certain decoding paradigms elicit specific and narrow brain activities, while others benefit from pre-training on a broad range of representations. By revealing which tasks transfer well and demonstrating the benefits of transfer learning for EEG decoding, our findings have practical implications for mitigating data scarcity in this setting. The transfer maps generated also provide insights into the hierarchical relations between cognitive tasks, hence enhancing our understanding of how these tasks are connected from a neuroscientific standpoint.
</details>
<details>
<summary>摘要</summary>
电enzephalography（EEG）解oding是一个具有挑战性的任务，主要因为数据的有限可用性。而转移学习是一种有前途的技术，可以解决这个问题，但它假设了可以确定的数据领域和任务，而这不是这个设置的情况。这个研究探讨了EEG解oding任务之间的转移学习表示的可行性。我们在两个最新发布的EEG数据集，ERP CORE和M$^3$CV中，使用现有的解oding模型进行了广泛的实验。我们测量了转移学习中学习的表示的可行性，通过在一个任务上预训练深度神经网络，然后评估它对后续任务的解码性能的能力。我们的实验结果表明，即使使用线性探索传输，也可以获得显著改善，与纯粹supervised方法相比，改善率可达28%。此外，我们发现了一些解oding方法引起特定和窄的脑活动，而其他方法则受到预训练在广泛的表示上的 beneficial。我们的发现可以有实际意义，帮助解决EEG解oding数据的缺乏问题，同时还可以提供有关认知科学方面的task之间的层次关系的新的视角。
</details></li>
</ul>
<hr>
<h2 id="We-are-all-Individuals-The-Role-of-Robot-Personality-and-Human-Traits-in-Trustworthy-Interaction"><a href="#We-are-all-Individuals-The-Role-of-Robot-Personality-and-Human-Traits-in-Trustworthy-Interaction" class="headerlink" title="We are all Individuals: The Role of Robot Personality and Human Traits in Trustworthy Interaction"></a>We are all Individuals: The Role of Robot Personality and Human Traits in Trustworthy Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15568">http://arxiv.org/abs/2307.15568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mei Yii Lim, José David Aguas Lopes, David A. Robb, Bruce W. Wilson, Meriam Moujahid, Emanuele De Pellegrin, Helen Hastie</li>
<li>for: 这个论文旨在研究 робо类型在人类社会中的表现，以及人类对 robot的偏好和信任度。</li>
<li>methods: 该论文采用了量化和质化的方法，通过 vocal cues 和语言特征来描述 robot 的个性，并通过询问参与者对不同 robot 个性的偏好和信任度来评估 robot 的表现。</li>
<li>results: 研究发现，在 Robo-Barista 中， extrovert robot 被人类参与者更加信任和喜欢，无论参与者自己的人格 trait 如何。此外，研究还发现，人类对 robot 的态度和先天偏好对 human-robot interaction  Study 中的信任度有重要影响。<details>
<summary>Abstract</summary>
As robots take on roles in our society, it is important that their appearance, behaviour and personality are appropriate for the job they are given and are perceived favourably by the people with whom they interact. Here, we provide an extensive quantitative and qualitative study exploring robot personality but, importantly, with respect to individual human traits. Firstly, we show that we can accurately portray personality in a social robot, in terms of extroversion-introversion using vocal cues and linguistic features. Secondly, through garnering preferences and trust ratings for these different robot personalities, we establish that, for a Robo-Barista, an extrovert robot is preferred and trusted more than an introvert robot, regardless of the subject's own personality. Thirdly, we find that individual attitudes and predispositions towards robots do impact trust in the Robo-Baristas, and are therefore important considerations in addition to robot personality, roles and interaction context when designing any human-robot interaction study.
</details>
<details>
<summary>摘要</summary>
As robots take on roles in our society, it is important that their appearance, behavior, and personality are appropriate for the job they are given and are perceived favorably by the people with whom they interact. Here, we provide an extensive quantitative and qualitative study exploring robot personality, but importantly, with respect to individual human traits. Firstly, we show that we can accurately portray personality in a social robot, in terms of extroversion-introversion using vocal cues and linguistic features. Secondly, through garnering preferences and trust ratings for these different robot personalities, we establish that, for a Robo-Barista, an extrovert robot is preferred and trusted more than an introvert robot, regardless of the subject's own personality. Thirdly, we find that individual attitudes and predispositions towards robots do impact trust in the Robo-Baristas, and are therefore important considerations in addition to robot personality, roles, and interaction context when designing any human-robot interaction study.
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Image-Classification-based-on-Gradual-Machine-Learning"><a href="#Few-shot-Image-Classification-based-on-Gradual-Machine-Learning" class="headerlink" title="Few-shot Image Classification based on Gradual Machine Learning"></a>Few-shot Image Classification based on Gradual Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15524">http://arxiv.org/abs/2307.15524</a></li>
<li>repo_url: None</li>
<li>paper_authors: Na Chen, Xianming Kuang, Feiyu Liu, Kehao Wang, Qun Chen</li>
<li>for: 这个论文的目的是提高几个标注样本的图像分类精度。</li>
<li>methods: 这个论文使用非同一个分布（Non-i.i.d）的渐进机器学习（GML）方法，从只有几个标注样本开始，然后逐渐将目标图像标注为增加难度的顺序，通过迭代因子推理在因子图中。</li>
<li>results: 该方法可以提高比较精度（SOTA）性能，在测试集上进行了比较研究，并证明了其在图像分类任务中的优越性。特别是，该方法可以在Query集大小增加时，保持性能的提高，而深度模型的性能则很可能会保持不变或者变差。<details>
<summary>Abstract</summary>
Few-shot image classification aims to accurately classify unlabeled images using only a few labeled samples. The state-of-the-art solutions are built by deep learning, which focuses on designing increasingly complex deep backbones. Unfortunately, the task remains very challenging due to the difficulty of transferring the knowledge learned in training classes to new ones. In this paper, we propose a novel approach based on the non-i.i.d paradigm of gradual machine learning (GML). It begins with only a few labeled observations, and then gradually labels target images in the increasing order of hardness by iterative factor inference in a factor graph. Specifically, our proposed solution extracts indicative feature representations by deep backbones, and then constructs both unary and binary factors based on the extracted features to facilitate gradual learning. The unary factors are constructed based on class center distance in an embedding space, while the binary factors are constructed based on k-nearest neighborhood. We have empirically validated the performance of the proposed approach on benchmark datasets by a comparative study. Our extensive experiments demonstrate that the proposed approach can improve the SOTA performance by 1-5% in terms of accuracy. More notably, it is more robust than the existing deep models in that its performance can consistently improve as the size of query set increases while the performance of deep models remains essentially flat or even becomes worse.
</details>
<details>
<summary>摘要</summary>
《几个样本图像分类》目的是使用只有几个标注样本来高精度地分类无标注图像。现状的解决方案基于深度学习，强调设计越来越复杂的深度背bone。然而，任务仍然非常困难，因为在训练类别之间传递知识的困难。在这篇论文中，我们提出了一种新的方法，基于异步度学习（GML）的异步机器学习（gradual machine learning）的 paradigm。它从只有几个标注样本开始，然后逐渐将目标图像标注为增加难度的顺序，通过迭代因子推理在因子图中。具体来说，我们的提出的方法首先提取特征表示，然后根据提取的特征构建 both unicode 和二进制因子，以便进行慢学习。unicode 因子是根据 embedding 空间中的类中心距离构建的，而二进制因子是根据 k-最近邻居构建的。我们在标准 benchmark 数据集上进行了比较研究，并经验 validate 了我们的方法的性能。我们的广泛的实验表明，我们的方法可以提高 SOTA 性能，并且比现有的深度模型更加稳定。 Specifically, our proposed approach can improve the SOTA performance by 1-5% in terms of accuracy, and it is more robust than the existing deep models in that its performance can consistently improve as the size of query set increases while the performance of deep models remains essentially flat or even becomes worse.Note: "SOTA" stands for "State of the Art", which means the current best performance in a particular field or task.
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Fully-Convolutional-Geometric-Features-for-Object-6D-Pose-Estimation"><a href="#Revisiting-Fully-Convolutional-Geometric-Features-for-Object-6D-Pose-Estimation" class="headerlink" title="Revisiting Fully Convolutional Geometric Features for Object 6D Pose Estimation"></a>Revisiting Fully Convolutional Geometric Features for Object 6D Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15514">http://arxiv.org/abs/2307.15514</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaime Corsetti, Davide Boscaini, Fabio Poiesi</li>
<li>for: 6D object pose estimation</li>
<li>methods: Fully Convolutional Geometric Features (FCGF) with sparse convolutions and hardest contrastive loss, and key modifications to the loss and input data representations, as well as careful tuning of training strategies and data augmentations</li>
<li>results: state-of-the-art performance on popular benchmarks, with outperformance of recent competitors<details>
<summary>Abstract</summary>
Recent works on 6D object pose estimation focus on learning keypoint correspondences between images and object models, and then determine the object pose through RANSAC-based algorithms or by directly regressing the pose with end-to-end optimisations. We argue that learning point-level discriminative features is overlooked in the literature. To this end, we revisit Fully Convolutional Geometric Features (FCGF) and tailor it for object 6D pose estimation to achieve state-of-the-art performance. FCGF employs sparse convolutions and learns point-level features using a fully-convolutional network by optimising a hardest contrastive loss. We can outperform recent competitors on popular benchmarks by adopting key modifications to the loss and to the input data representations, by carefully tuning the training strategies, and by employing data augmentations suitable for the underlying problem. We carry out a thorough ablation to study the contribution of each modification.
</details>
<details>
<summary>摘要</summary>
最近的6D物体 pose 估计研究关注学习图像和物体模型之间关键点匹配，然后使用RANSAC算法或直接使用整体优化来确定物体pose。我们认为在文献中学习点级特征是被忽略的。为此，我们回顾了全面卷积Geometric Features（FCGF），并对其进行修改以适应物体6D pose估计，以达到领先的性能。FCGF使用稀疏卷积，通过全面卷积网络学习点级特征，并通过最难的对比损失来优化。我们可以通过采用修改loss和输入数据表示，精心调整训练策略，以及适合下面问题的数据增强来超越最近的竞争对手。我们进行了严格的拟合来研究每个修改的贡献。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Format-Consistency-for-Instruction-Tuning"><a href="#Exploring-Format-Consistency-for-Instruction-Tuning" class="headerlink" title="Exploring Format Consistency for Instruction Tuning"></a>Exploring Format Consistency for Instruction Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15504">http://arxiv.org/abs/2307.15504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shihao Liang, Kunlun Zhu, Runchu Tian, Yujia Qin, Huadong Wang, Xin Cong, Zhiyuan Liu, Xiaojiang Liu, Maosong Sun</li>
<li>for: 提高大语言模型 seguir las instrucciones de los humanos</li>
<li>methods: 使用 OpenAI APIs 自动转换format instruction tuning 数据集，并提出一种基于抽象搅拌的干扰除法以降低自动转换中的噪音</li>
<li>results: 研究表明，UIT 框架可以提高 instruction tuning 中的泛化性能，并且在实际应用中可以降低成本Here is the full text in Simplified Chinese, with the three key points highlighted:</li>
<li>for: 本文旨在提高大语言模型 seguir las instrucciones de los humanos，具体来说是通过增加不同 instrucciones 和 instrucciones 集合的训练数据来提高模型的泛化性能。</li>
<li>methods: 我们提出了一种基于 OpenAI APIs 的自动转换format instruction tuning 数据集的框架，并提出了一种基于抽象搅拌的干扰除法以降低自动转换中的噪音。</li>
<li>results: 我们的研究表明，UIT 框架可以提高 instruction tuning 中的泛化性能，并且在实际应用中可以降低成本。<details>
<summary>Abstract</summary>
Instruction tuning has emerged as a promising approach to enhancing large language models in following human instructions. It is shown that increasing the diversity and number of instructions in the training data can consistently enhance generalization performance, which facilitates a recent endeavor to collect various instructions and integrate existing instruction tuning datasets into larger collections. However, different users have their unique ways of expressing instructions, and there often exist variations across different datasets in the instruction styles and formats, i.e., format inconsistency. In this work, we study how format inconsistency may impact the performance of instruction tuning. We propose a framework called "Unified Instruction Tuning" (UIT), which calls OpenAI APIs for automatic format transfer among different instruction tuning datasets. We show that UIT successfully improves the generalization performance on unseen instructions, which highlights the importance of format consistency for instruction tuning. To make the UIT framework more practical, we further propose a novel perplexity-based denoising method to reduce the noise of automatic format transfer. We also train a smaller offline model that achieves comparable format transfer capability than OpenAI APIs to reduce costs in practice.
</details>
<details>
<summary>摘要</summary>
<SYS> translate_text="Instruction tuning has emerged as a promising approach to enhancing large language models in following human instructions. It is shown that increasing the diversity and number of instructions in the training data can consistently enhance generalization performance, which facilitates a recent endeavor to collect various instructions and integrate existing instruction tuning datasets into larger collections. However, different users have their unique ways of expressing instructions, and there often exist variations across different datasets in the instruction styles and formats, i.e., format inconsistency. In this work, we study how format inconsistency may impact the performance of instruction tuning. We propose a framework called "Unified Instruction Tuning" (UIT), which calls OpenAI APIs for automatic format transfer among different instruction tuning datasets. We show that UIT successfully improves the generalization performance on unseen instructions, which highlights the importance of format consistency for instruction tuning. To make the UIT framework more practical, we further propose a novel perplexity-based denoising method to reduce the noise of automatic format transfer. We also train a smaller offline model that achieves comparable format transfer capability than OpenAI APIs to reduce costs in practice."</SYS>Here's the translation in Simplified Chinese: instrucion 调整有 emerged 为大语言模型遵循人类指令的一种有前途的方法。增加多样性和数量的指令在训练数据中可以一直提高总体性能，这有助于最近的努力，收集各种指令并将现有的指令调整数据集合入大型集合。然而，不同的用户有各自的指令表达方式，而指令集合中的指令风格和格式经常存在差异，即格式不一致。在这种情况下，我们研究了格式不一致如何影响指令调整的性能。我们提出了一个名为 "统一指令调整"（UIT）的框架，通过OpenAI API进行自动格式传输。我们发现，UIT可以成功地提高未见指令的总体性能，这说明了格式一致性对指令调整的重要性。为了使UIT框架更实用，我们进一步提出了一种基于抽象率的减噪方法，以减少自动格式传输中的噪声。此外，我们还训练了一个较小的离线模型，可以实现与OpenAI API相同的格式传输能力，以降低在实践中的成本。
</details></li>
</ul>
<hr>
<h2 id="Curiosity-Driven-Reinforcement-Learning-based-Low-Level-Flight-Control"><a href="#Curiosity-Driven-Reinforcement-Learning-based-Low-Level-Flight-Control" class="headerlink" title="Curiosity-Driven Reinforcement Learning based Low-Level Flight Control"></a>Curiosity-Driven Reinforcement Learning based Low-Level Flight Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15724">http://arxiv.org/abs/2307.15724</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/a-ramezani/cdrl-l2fc_u_hcm">https://github.com/a-ramezani/cdrl-l2fc_u_hcm</a></li>
<li>paper_authors: Amir Ramezani Dooraki, Alexandros Iosifidis</li>
<li>for: 这个论文的目的是提出一种基于好奇性的自主学习算法，用于控制quadcopter navigating through obstacles。</li>
<li>methods: 该算法使用了好奇性的prediction errorapproach，并与基于奖励学习的算法结合使用。</li>
<li>results: 测试结果显示，该算法可以学习优化策略，最大化奖励，其他算法无法达成的目标。<details>
<summary>Abstract</summary>
Curiosity is one of the main motives in many of the natural creatures with measurable levels of intelligence for exploration and, as a result, more efficient learning. It makes it possible for humans and many animals to explore efficiently by searching for being in states that make them surprised with the goal of learning more about what they do not know. As a result, while being curious, they learn better. In the machine learning literature, curiosity is mostly combined with reinforcement learning-based algorithms as an intrinsic reward. This work proposes an algorithm based on the drive of curiosity for autonomous learning to control by generating proper motor speeds from odometry data. The quadcopter controlled by our proposed algorithm can pass through obstacles while controlling the Yaw direction of the quad-copter toward the desired location. To achieve that, we also propose a new curiosity approach based on prediction error. We ran tests using on-policy, off-policy, on-policy plus curiosity, and the proposed algorithm and visualized the effect of curiosity in evolving exploration patterns. Results show the capability of the proposed algorithm to learn optimal policy and maximize reward where other algorithms fail to do so.
</details>
<details>
<summary>摘要</summary>
寻Curiosity是许多自然 creature 的主要动机，包括许多智能生物，以探索和学习为主要目的。它使得人类和许多动物能够效率地探索，并且在过程中获得更多的知识。在机器学习文献中，Curiosity通常与征募学习算法结合，作为自然选择的一种内生奖励。本工作提出一个基于寻Curiosity的自主学习控制算法，可以将四辐游戏机器人控制到避免障碍而飞行，并且控制机器人的转向方向以 дости其目标位置。为了实现这一目标，我们还提出了一种新的寻Curiosity方法，基于预测误差。我们在实验中使用了在政策、不在政策、在政策加上寻Curiosity、以及我们的提案中进行试验，并将寻Curiosity的影响在演化探索模式中 visualized。结果显示了我们的提案算法可以学习并实现最佳策略，其他算法无法实现。
</details></li>
</ul>
<hr>
<h2 id="ETHER-Aligning-Emergent-Communication-for-Hindsight-Experience-Replay"><a href="#ETHER-Aligning-Emergent-Communication-for-Hindsight-Experience-Replay" class="headerlink" title="ETHER: Aligning Emergent Communication for Hindsight Experience Replay"></a>ETHER: Aligning Emergent Communication for Hindsight Experience Replay</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15494">http://arxiv.org/abs/2307.15494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kevin Denamganaï, Daniel Hernandez, Ozan Vardal, Sondess Missaoui, James Alfred Walker</li>
<li>for: 本研究旨在提高自然语言指令驱动的人工智能机器人的合作能力。</li>
<li>methods: 本研究使用自然语言conditioned reinforcement learning（RL）agent，利用自然语言的特性，如 компози�，提供强 inductive bias 来学习复杂的策略。</li>
<li>results: 研究表明，通过使用 referential game 作为 auxiliary task，可以使RL Agent 更好地利用语言信息，并且可以在不具备 oracle  predicate function 的情况下提高性能和数据效率。<details>
<summary>Abstract</summary>
Natural language instruction following is paramount to enable collaboration between artificial agents and human beings. Natural language-conditioned reinforcement learning (RL) agents have shown how natural languages' properties, such as compositionality, can provide a strong inductive bias to learn complex policies. Previous architectures like HIGhER combine the benefit of language-conditioning with Hindsight Experience Replay (HER) to deal with sparse rewards environments. Yet, like HER, HIGhER relies on an oracle predicate function to provide a feedback signal highlighting which linguistic description is valid for which state. This reliance on an oracle limits its application. Additionally, HIGhER only leverages the linguistic information contained in successful RL trajectories, thus hurting its final performance and data-efficiency. Without early successful trajectories, HIGhER is no better than DQN upon which it is built. In this paper, we propose the Emergent Textual Hindsight Experience Replay (ETHER) agent, which builds on HIGhER and addresses both of its limitations by means of (i) a discriminative visual referential game, commonly studied in the subfield of Emergent Communication (EC), used here as an unsupervised auxiliary task and (ii) a semantic grounding scheme to align the emergent language with the natural language of the instruction-following benchmark. We show that the referential game's agents make an artificial language emerge that is aligned with the natural-like language used to describe goals in the BabyAI benchmark and that it is expressive enough so as to also describe unsuccessful RL trajectories and thus provide feedback to the RL agent to leverage the linguistic, structured information contained in all trajectories. Our work shows that EC is a viable unsupervised auxiliary task for RL and provides missing pieces to make HER more widely applicable.
</details>
<details>
<summary>摘要</summary>
自然语言指导following是人工智能和人类合作的关键。自然语言conditioned reinforcement learning（RL）代理人们已经证明了自然语言的特性，如compositionality，可以为学习复杂政策提供强大的逻辑导向。先前的架构如HIGhER将语言conditioning与Hindsight Experience Replay（HER）结合以处理罕见奖励环境。然而，如HER，HIGhER依赖oracle predicate函数提供一个反馈信号，用于指示哪些语言描述是哪个状态的有效描述。这种依赖oracle限制了其应用。此外，HIGhER只利用RL trajectory中的语言信息，因此在最终性和数据效率方面受到限制。在absence of early successful trajectories，HIGhER与DQN相比，没有优势。在这篇论文中，我们提出了Emergent Textual Hindsight Experience Replay（ETHER）代理人，它基于HIGhER并解决了它的两个限制。我们使用了一种推理视觉游戏，通常在Emergent Communication（EC）中被研究，作为一种无监督任务。此外，我们还使用了一种semantic grounding scheme来将自然语言与RL benchmark中的目标描述相对应。我们发现，EC中的代理人在学习一种与自然语言相关的人工语言，并且这种语言足够表达，以便描述失败的RL trajectory，并提供给RL代理人以利用语言、结构化信息来改进性能。我们的工作表明，EC是一种可靠的无监督任务，可以为RL提供 missing pieces，使HER更加广泛应用。
</details></li>
</ul>
<hr>
<h2 id="A-Semantic-Approach-to-Decidability-in-Epistemic-Planning-Extended-Version"><a href="#A-Semantic-Approach-to-Decidability-in-Epistemic-Planning-Extended-Version" class="headerlink" title="A Semantic Approach to Decidability in Epistemic Planning (Extended Version)"></a>A Semantic Approach to Decidability in Epistemic Planning (Extended Version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15485">http://arxiv.org/abs/2307.15485</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Burigana, Paolo Felli, Marco Montali, Nicolas Troquard</li>
<li>for: 这篇论文主要探讨了在多智能计划中使用动态纽标逻辑（DEL）的可 decidability问题。</li>
<li>methods: 作者采用了一种新的semantic方法来实现可 decidability，而不是通过语法上的限制。具体来说，作者增强了知识逻辑S5$_n$的axioms，并添加了一个交互axioms（知识共同性），以控制代理人对别人知识的无限推理能力。</li>
<li>results: 作者首先证明了这种epistemic planning问题是可 decidable的。此外，作者还研究了不同的通常性axioms的推广，以实现更expressive的DEL Fragment的可 decidability。最后，作者证明了两个常见的epistemic planning系统，基于action templates，在知识下的设定下是可 decidable的。<details>
<summary>Abstract</summary>
The use of Dynamic Epistemic Logic (DEL) in multi-agent planning has led to a widely adopted action formalism that can handle nondeterminism, partial observability and arbitrary knowledge nesting. As such expressive power comes at the cost of undecidability, several decidable fragments have been isolated, mainly based on syntactic restrictions of the action formalism. In this paper, we pursue a novel semantic approach to achieve decidability. Namely, rather than imposing syntactical constraints, the semantic approach focuses on the axioms of the logic for epistemic planning. Specifically, we augment the logic of knowledge S5$_n$ and with an interaction axiom called (knowledge) commutativity, which controls the ability of agents to unboundedly reason on the knowledge of other agents. We then provide a threefold contribution. First, we show that the resulting epistemic planning problem is decidable. In doing so, we prove that our framework admits a finitary non-fixpoint characterization of common knowledge, which is of independent interest. Second, we study different generalizations of the commutativity axiom, with the goal of obtaining decidability for more expressive fragments of DEL. Finally, we show that two well-known epistemic planning systems based on action templates, when interpreted under the setting of knowledge, conform to the commutativity axiom, hence proving their decidability.
</details>
<details>
<summary>摘要</summary>
使用动态эпистемологи（DEL）在多代理规划中得到了广泛采用的行动 formalism，可以处理不确定性、部分可见性和嵌套知识。然而，这么高度表达力带来了不可解决性问题，因此有很多可 decidable fragments 已经被隔离出来，主要基于动态 formalism 的语法约束。在这篇论文中，我们采用一种新的semantic方法来实现可解决性。具体来说，我们在知识逻辑S5$_n$中添加了一个交互axioms（知识 commutativity），该axioms控制代理者对别人知识的无限推理能力。然后，我们提供了三项贡献：1. 我们表明了这种epistemic planning问题的可解决性。在这个过程中，我们证明了我们的框架有一个 finitary non-fixpoint characterization of common knowledge，这是独立的有趣的。2. 我们研究了不同的generalisations of the commutativity axiom，以实现更expressive fragments of DEL的可解决性。3. 我们证明了两个常见的epistemic planning系统，基于action templates，在知识下被解释，符合 commutativity axiom，因此其可解决性。
</details></li>
</ul>
<hr>
<h2 id="Minimally-Supervised-Speech-Synthesis-with-Conditional-Diffusion-Model-and-Language-Model-A-Comparative-Study-of-Semantic-Coding"><a href="#Minimally-Supervised-Speech-Synthesis-with-Conditional-Diffusion-Model-and-Language-Model-A-Comparative-Study-of-Semantic-Coding" class="headerlink" title="Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding"></a>Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15484">http://arxiv.org/abs/2307.15484</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunyu Qiang, Hao Li, Hao Ni, He Qu, Ruibo Fu, Tao Wang, Longbiao Wang, Jianwu Dang</li>
<li>for: 这个论文旨在提出一种基于扩散模型和语言模型的文本译语音系统，以提高文本译语音的质量和自然性。</li>
<li>methods: 该论文使用了两种不同类型的扩散Speech表示，并使用两个序列到序列任务来解耦文本译语音。它还引入了一个提示编码结构，以提高提示表示能力。</li>
<li>results: 实验结果显示，该论文提出的方法比基eline方法表现出色，并提供了一个网站的音频样本。<details>
<summary>Abstract</summary>
Recently, there has been a growing interest in text-to-speech (TTS) methods that can be trained with minimal supervision by combining two types of discrete speech representations and using two sequence-to-sequence tasks to decouple TTS. To address the challenges associated with high dimensionality and waveform distortion in discrete representations, we propose Diff-LM-Speech, which models semantic embeddings into mel-spectrogram based on diffusion models and introduces a prompt encoder structure based on variational autoencoders and prosody bottlenecks to improve prompt representation capabilities. Autoregressive language models often suffer from missing and repeated words, while non-autoregressive frameworks face expression averaging problems due to duration prediction models. To address these issues, we propose Tetra-Diff-Speech, which designs a duration diffusion model to achieve diverse prosodic expressions. While we expect the information content of semantic coding to be between that of text and acoustic coding, existing models extract semantic coding with a lot of redundant information and dimensionality explosion. To verify that semantic coding is not necessary, we propose Tri-Diff-Speech. Experimental results show that our proposed methods outperform baseline methods. We provide a website with audio samples.
</details>
<details>
<summary>摘要</summary>
最近，有越来越多关注可以通过最小监督学习的文本识别（TTS）方法。我们提议一种叫做Diff-LM-Speech的方法，它利用扩散模型将含义编码作为mel-spectrogram中的semantic embedding，并通过变量自动编码器和谱瓣瓶逻辑来改善提示表示能力。而autoregressive语言模型经常会出现缺失和重复的单词问题，而非autoregressive框架则会面临表达均衡问题，这是因为duration预测模型的问题。为解决这些问题，我们提议Tetra-Diff-Speech，它使用扩散模型来实现多种表达方式的多样性。尽管我们预期含义编码的信息内容在文本和音频编码之间，现有的模型通常会提取很多无用的信息和维度爆炸。为验证这一点，我们提议Tri-Diff-Speech。实验结果表明，我们的提议方法在比基eline方法有更好的表现。我们提供了一个网站，包含了各种音频样本。
</details></li>
</ul>
<hr>
<h2 id="Non-invasive-Diabetes-Detection-using-Gabor-Filter-A-Comparative-Analysis-of-Different-Cameras"><a href="#Non-invasive-Diabetes-Detection-using-Gabor-Filter-A-Comparative-Analysis-of-Different-Cameras" class="headerlink" title="Non-invasive Diabetes Detection using Gabor Filter: A Comparative Analysis of Different Cameras"></a>Non-invasive Diabetes Detection using Gabor Filter: A Comparative Analysis of Different Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15480">http://arxiv.org/abs/2307.15480</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christina A. Garcia, Patricia Angela R. Abu, Rosula SJ. Reyes</li>
<li>for: 这个论文旨在比较和探讨使用移动设备摄像头和笔记型电脑摄像头来捕捉非侵入性诊断糖尿病（DM）的图像，并使用facial block texture特征进行识别。</li>
<li>methods: 该论文使用了12mp和7mp移动设备摄像头以及笔记型电脑摄像头，在正常照明下拍摄图像。 extracted facial blocks被分类使用k-最近邻和支持向量机。</li>
<li>results: 系统的性能被测量为准确率96.7%，特异性93%和敏感性100%，最佳性能来自12mp后置摄像头使用支持向量机，使用100张图像。<details>
<summary>Abstract</summary>
This paper compares and explores the performance of both mobile device camera and laptop camera as convenient tool for capturing images for non-invasive detection of Diabetes Mellitus (DM) using facial block texture features. Participants within age bracket 20 to 79 years old were chosen for the dataset. 12mp and 7mp mobile cameras, and a laptop camera were used to take the photo under normal lighting condition. Extracted facial blocks were classified using k-Nearest Neighbors (k-NN) and Support Vector Machine (SVM). 100 images were captured, preprocessed, filtered using Gabor, and iterated. Performance of the system was measured in terms of accuracy, specificity, and sensitivity. Best performance of 96.7% accuracy, 100% sensitivity, and 93% specificity were achieved from 12mp back camera using SVM with 100 images.
</details>
<details>
<summary>摘要</summary>
这篇论文比较了手持设备摄像头和笔记型电脑摄像头作为轻便的捕捉照片用于不侵入性诊断糖尿病（DM）的方法。选择的参与者年龄在20岁至79岁之间。使用1200万像素和700万像素手持设备摄像头以及笔记型电脑摄像头，在正常照明条件下拍摄照片。提取的脸部块被分类使用k-最近邻和支持向量机（SVM）。 captured 100 张照片，预处理、筛选using Gabor, iterated。系统性能测量的指标包括准确率、特异性和敏感度。使用1200万像素后摄像头和SVM， achieved 96.7%的准确率、100%的敏感度和93%的特异性。
</details></li>
</ul>
<hr>
<h2 id="FeedbackLogs-Recording-and-Incorporating-Stakeholder-Feedback-into-Machine-Learning-Pipelines"><a href="#FeedbackLogs-Recording-and-Incorporating-Stakeholder-Feedback-into-Machine-Learning-Pipelines" class="headerlink" title="FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines"></a>FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15475">http://arxiv.org/abs/2307.15475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Barker, Emma Kallina, Dhananjay Ashok, Katherine M. Collins, Ashley Casovan, Adrian Weller, Ameet Talwalkar, Valerie Chen, Umang Bhatt</li>
<li>for: 这个论文是为了提供一种方法来记录和 incorporate 多个潜在参与者的反馈，以便更好地了解 ML 管道的影响。</li>
<li>methods: 这篇论文提出了一种名为 FeedbackLogs 的新方法，用于跟踪 ML 管道中不同参与者的反馈。每个 FeedbackLog 都记录了反馈收集过程中的重要细节，以及反馈本身和如何将反馈纳入 ML 管道中。</li>
<li>results: 这篇论文提供了一些具体的使用案例，例如使用 FeedbackLogs 作为算法审核的证据，以及用于记录基于潜在参与者反馈的更新。<details>
<summary>Abstract</summary>
Even though machine learning (ML) pipelines affect an increasing array of stakeholders, there is little work on how input from stakeholders is recorded and incorporated. We propose FeedbackLogs, addenda to existing documentation of ML pipelines, to track the input of multiple stakeholders. Each log records important details about the feedback collection process, the feedback itself, and how the feedback is used to update the ML pipeline. In this paper, we introduce and formalise a process for collecting a FeedbackLog. We also provide concrete use cases where FeedbackLogs can be employed as evidence for algorithmic auditing and as a tool to record updates based on stakeholder feedback.
</details>
<details>
<summary>摘要</summary>
即使机器学习（ML）管道影响到越来越多的利益者，有很少关于如何记录和 incorporate 利益者的输入的研究。我们提议使用 FeedbackLogs，加入现有的 ML 管道文档，跟踪多个利益者的反馈。每个日志记录了反馈收集过程中重要的细节，反馈本身，以及如何使用反馈更新 ML 管道。在这篇论文中，我们介绍了和形式化了收集FeedbackLog的过程。我们还提供了具体的应用场景，其中FeedbackLog可以作为算法审核的证据，以及用于记录基于利益者反馈的更新。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Noisy-Label-Learning-in-Real-world-Annotation-Scenarios-from-the-Noise-type-Perspective"><a href="#Rethinking-Noisy-Label-Learning-in-Real-world-Annotation-Scenarios-from-the-Noise-type-Perspective" class="headerlink" title="Rethinking Noisy Label Learning in Real-world Annotation Scenarios from the Noise-type Perspective"></a>Rethinking Noisy Label Learning in Real-world Annotation Scenarios from the Noise-type Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16889">http://arxiv.org/abs/2307.16889</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fuxiailab/protosemi">https://github.com/fuxiailab/protosemi</a></li>
<li>paper_authors: Renyu Zhu, Haoyu Liu, Runze Wu, Minmin Lin, Tangjie Lv, Changjie Fan, Haobo Wang</li>
<li>for:  investigate the problem of learning with noisy labels in real-world annotation scenarios</li>
<li>methods: propose a novel sample selection-based approach for noisy label learning called Proto-semi</li>
<li>results: demonstrate the effectiveness of Proto-semi in handling the problem of learning from noisy labels, and show that the prototype-based repartitioning strategy is effective in mitigating the adverse impact of label noise.Here is the summary in Traditional Chinese:</li>
<li>for: 研究实际标签条件下的学习噪音标签问题</li>
<li>methods: 提出一个基于选择体系的噪音标签学习方法 called Proto-semi</li>
<li>results: 验证 Proto-semi 能够实现噪音标签学习问题，并显示基于几何的重新分配策略有效地减少噪音标签的影响。<details>
<summary>Abstract</summary>
In this paper, we investigate the problem of learning with noisy labels in real-world annotation scenarios, where noise can be categorized into two types: factual noise and ambiguity noise. To better distinguish these noise types and utilize their semantics, we propose a novel sample selection-based approach for noisy label learning, called Proto-semi. Proto-semi initially divides all samples into the confident and unconfident datasets via warm-up. By leveraging the confident dataset, prototype vectors are constructed to capture class characteristics. Subsequently, the distances between the unconfident samples and the prototype vectors are calculated to facilitate noise classification. Based on these distances, the labels are either corrected or retained, resulting in the refinement of the confident and unconfident datasets. Finally, we introduce a semi-supervised learning method to enhance training. Empirical evaluations on a real-world annotated dataset substantiate the robustness of Proto-semi in handling the problem of learning from noisy labels. Meanwhile, the prototype-based repartitioning strategy is shown to be effective in mitigating the adverse impact of label noise. Our code and data are available at https://github.com/fuxiAIlab/ProtoSemi.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了在实际注释场景中学习受损标签的问题，其中噪声可以分为两类：事实噪声和模糊噪声。为了更好地 отличи出这两种噪声类型并利用其 semantics，我们提议了一种基于样本选择的受损标签学习方法，称为Proto-semi。Proto-semi首先将所有样本分为自信量高和自信量低两个集合via warm-up。然后，通过利用自信量集合，构建 prototype vectors，以捕捉类征特征。接着，计算不确定样本与 prototype vectors 之间的距离，以便噪声分类。根据这些距离，将标签更正或保留，从而对自信量集合和不确定集合进行修正。最后，我们引入了一种半supervised学习方法，以提高训练。empirical evaluations 表明，Proto-semi 能够有效地处理实际注释中的受损标签学习问题。同时，我们的 prototype-based repartitioning 策略能够减轻噪声对标签学习的负面影响。我们的代码和数据可以在 <https://github.com/fuxiAIlab/ProtoSemi> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Testing-the-Depth-of-ChatGPT’s-Comprehension-via-Cross-Modal-Tasks-Based-on-ASCII-Art-GPT3-5’s-Abilities-in-Regard-to-Recognizing-and-Generating-ASCII-Art-Are-Not-Totally-Lacking"><a href="#Testing-the-Depth-of-ChatGPT’s-Comprehension-via-Cross-Modal-Tasks-Based-on-ASCII-Art-GPT3-5’s-Abilities-in-Regard-to-Recognizing-and-Generating-ASCII-Art-Are-Not-Totally-Lacking" class="headerlink" title="Testing the Depth of ChatGPT’s Comprehension via Cross-Modal Tasks Based on ASCII-Art: GPT3.5’s Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking"></a>Testing the Depth of ChatGPT’s Comprehension via Cross-Modal Tasks Based on ASCII-Art: GPT3.5’s Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16806">http://arxiv.org/abs/2307.16806</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Bayani</li>
<li>for: 这篇论文探讨了 GPT3.5 模型在视觉任务中的能力，包括图像识别、图像分割和图像生成等。</li>
<li>methods: 该论文使用了 GPT3.5 模型，并对其进行了不同的变换和修改，以测试其在视觉任务中的表现。</li>
<li>results: 研究发现，GPT3.5 模型在图像识别和图像分割任务中表现不佳，但在图像生成任务中表现较为出色。<details>
<summary>Abstract</summary>
Over the eight months since its release, ChatGPT and its underlying model, GPT3.5, have garnered massive attention, due to their potent mix of capability and accessibility. While a niche-industry of papers have emerged examining the scope of capabilities these models possess, the information fed to and extracted from these networks has been either natural language text or stylized, code-like language. Drawing inspiration from the prowess we expect a truly human-level intelligent agent to have across multiple signal modalities, in this work we examine GPT3.5's aptitude for visual tasks, where the inputs feature content provided as ASCII-art without overt distillation into a lingual summary. We conduct experiments analyzing the model's performance on image recognition tasks after various transforms typical in visual settings, trials investigating knowledge of image parts, and tasks covering image generation.
</details>
<details>
<summary>摘要</summary>
Over the past eight months since its release, ChatGPT and its underlying model, GPT3.5, have received massive attention due to their powerful combination of capabilities and accessibility. While a niche industry of papers has emerged examining the scope of capabilities these models possess, the information fed to and extracted from these networks has been limited to natural language text or stylized, code-like language. Inspired by the versatility we would expect from a truly human-level intelligent agent, in this work we explore GPT3.5's ability to perform visual tasks, using ASCII art as input without any explicit linguistic summaries. We conduct experiments analyzing the model's performance on image recognition tasks, image part recognition, and image generation.
</details></li>
</ul>
<hr>
<h2 id="Worrisome-Properties-of-Neural-Network-Controllers-and-Their-Symbolic-Representations"><a href="#Worrisome-Properties-of-Neural-Network-Controllers-and-Their-Symbolic-Representations" class="headerlink" title="Worrisome Properties of Neural Network Controllers and Their Symbolic Representations"></a>Worrisome Properties of Neural Network Controllers and Their Symbolic Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15456">http://arxiv.org/abs/2307.15456</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mimuw-rl/worrisome-nn">https://github.com/mimuw-rl/worrisome-nn</a></li>
<li>paper_authors: Jacek Cyranka, Kevin E M Church, Jean-Philippe Lessard</li>
<li>for: 本研究探讨控制器在简单强化学习问题中的稳定性问题。</li>
<li>methods: 本研究使用神经网络控制器和其低神经级别和符号抽象。</li>
<li>results: 研究发现， Typical controller 可以达到高均返回值，但仍然生成大量的持续低返回解决方案，这是一个非常不жела的性能，易被敌对者利用。 更加简单的控制器会承认更多的持续坏解决方案。 研究提供了一种系统性 robustness 研究的算法，并证明存在持续解决方案和、在某些情况下， periodic orbits 的存在，使用计算机支持的证明方法。<details>
<summary>Abstract</summary>
We raise concerns about controllers' robustness in simple reinforcement learning benchmark problems. We focus on neural network controllers and their low neuron and symbolic abstractions. A typical controller reaching high mean return values still generates an abundance of persistent low-return solutions, which is a highly undesirable property, easily exploitable by an adversary. We find that the simpler controllers admit more persistent bad solutions. We provide an algorithm for a systematic robustness study and prove existence of persistent solutions and, in some cases, periodic orbits, using a computer-assisted proof methodology.
</details>
<details>
<summary>摘要</summary>
我们有关控制器的Robustness在简单的征务学习问题上表达出关注。我们专注于神经网络控制器的低神经和符号抽象。一般情况下，一个高均返回值的控制器仍然生成丰富的持续性低返回解，这是非常不愿意的危难，易于敌人利用。我们发现简单的控制器承认更多持续性坏解。我们提供了一个系统atic robustness研究的算法，并证明存在持续解和，在一些情况下， periodic orbit，使用了电脑辅助证明方法。
</details></li>
</ul>
<hr>
<h2 id="From-Probabilistic-Programming-to-Complexity-based-Programming"><a href="#From-Probabilistic-Programming-to-Complexity-based-Programming" class="headerlink" title="From Probabilistic Programming to Complexity-based Programming"></a>From Probabilistic Programming to Complexity-based Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15453">http://arxiv.org/abs/2307.15453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giovanni Sileno, Jean-Louis Dessalles</li>
<li>for: 本文提出了一种新的计算框架，名为CompLog，受 probabilistic programming 系统ProbLog的启发，基于 simplicity theory 的推理机制，通过计算两个kolmogorov复杂度来代替概率推理。</li>
<li>methods: 本文使用了两个kolmogorov复杂度来计算后期和前期意外程度，即后期和前期主观概率。计算基于世界和心理模型的假设，通过 causa 和descriptive 关系来Weight predicates的复杂度。</li>
<li>results: 本文提供了一些应用示例，包括生成相关描述和提供谱析和否定的不同方法。<details>
<summary>Abstract</summary>
The paper presents the main characteristics and a preliminary implementation of a novel computational framework named CompLog. Inspired by probabilistic programming systems like ProbLog, CompLog builds upon the inferential mechanisms proposed by Simplicity Theory, relying on the computation of two Kolmogorov complexities (here implemented as min-path searches via ASP programs) rather than probabilistic inference. The proposed system enables users to compute ex-post and ex-ante measures of unexpectedness of a certain situation, mapping respectively to posterior and prior subjective probabilities. The computation is based on the specification of world and mental models by means of causal and descriptive relations between predicates weighted by complexity. The paper illustrates a few examples of application: generating relevant descriptions, and providing alternative approaches to disjunction and to negation.
</details>
<details>
<summary>摘要</summary>
文章介绍了一种新的计算框架，名为CompLog，它受到概率编程系统ProbLog的启发，基于 simplicity theory 中的推理机制，通过计算两个可读性复杂度（在 ASP 程序中实现为最短路寻找）而不是概率推理。该系统可以为用户计算出不同情况的预后和预先抽象度，即后 posting 和前 posting Subjective 概率。计算基于世界和心理模型的干扰和描述关系，这些关系由 predicate 的复杂度Weight。文章还给出了一些应用示例，如生成相关的描述和提供了许多不同的补做法。
</details></li>
</ul>
<hr>
<h2 id="DELPHIC-Practical-DEL-Planning-via-Possibilities-Extended-Version"><a href="#DELPHIC-Practical-DEL-Planning-via-Possibilities-Extended-Version" class="headerlink" title="DELPHIC: Practical DEL Planning via Possibilities (Extended Version)"></a>DELPHIC: Practical DEL Planning via Possibilities (Extended Version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15451">http://arxiv.org/abs/2307.15451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Burigana, Paolo Felli, Marco Montali</li>
<li>for: This paper aims to improve the practicality of Dynamic Epistemic Logic (DEL) planning by questioning the traditional semantics and proposing an alternative, more compact approach called DELPHIC.</li>
<li>methods: The paper uses a new semantics defined using possibilities, which are non-well-founded objects representing both factual properties and what agents consider to be possible. The authors implement the DELPHIC approach in Answer Set Programming (ASP) and compare it with the traditional Kripke-based approach.</li>
<li>results: The experimental evaluation shows that DELPHIC outperforms the traditional approach in terms of space and time.<details>
<summary>Abstract</summary>
Dynamic Epistemic Logic (DEL) provides a framework for epistemic planning that is capable of representing non-deterministic actions, partial observability, higher-order knowledge and both factual and epistemic change. The high expressivity of DEL challenges existing epistemic planners, which typically can handle only restricted fragments of the whole framework. The goal of this work is to push the envelop of practical DEL planning, ultimately aiming for epistemic planners to be able to deal with the full range of features offered by DEL. Towards this goal, we question the traditional semantics of DEL, defined in terms on Kripke models. In particular, we propose an equivalent semantics defined using, as main building block, so-called possibilities: non well-founded objects representing both factual properties of the world, and what agents consider to be possible. We call the resulting framework DELPHIC. We argue that DELPHIC indeed provides a more compact representation of epistemic states. To substantiate this claim, we implement both approaches in ASP and we set up an experimental evaluation to compare DELPHIC with the traditional, Kripke-based approach. The evaluation confirms that DELPHIC outperforms the traditional approach in space and time.
</details>
<details>
<summary>摘要</summary>
dynamically epistemic logic (DEL) 提供了一个架构，可以表示非决定性行为、部分可观察性、高阶知识和事实和知识改变。 DEL 的表达力问题，使得现有的 epistemic 观察者通常只能处理 restriction 的 fragment。 在这个工作中，我们质疑传统 DEL 的 semantics，定义为基于 Kripke 模型。 具体来说，我们提出了一个相等的 semantics，使用 so-called possibilities：非对数世界的性质，以及 agents 认为可能的东西。 我们称这个框架为 DELPHIC。 我们认为 DELPHIC 可以提供更 компакт的 epistemic 状态表示。 为了证明这个主张，我们将实现这两种方法，并设置了一个实验评估，以比较 DELPHIC 和传统、基于 Kripke 的方法。 评估确认 DELPHIC 在空间和时间方面的表现比 traditional 方法更好。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Alignment-of-Temporal-Knowledge-Bases"><a href="#Optimal-Alignment-of-Temporal-Knowledge-Bases" class="headerlink" title="Optimal Alignment of Temporal Knowledge Bases"></a>Optimal Alignment of Temporal Knowledge Bases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15439">http://arxiv.org/abs/2307.15439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oliver Fernandez-Gil, Fabio Patrizi, Giuseppe Perelli, Anni-Yasmin Turhan</li>
<li>for: 本研究旨在实现基于ontology的情境识别，并且解决在知识库中收集的数据不准确导致重要查询答案被遗弃的问题。</li>
<li>methods: 本文引入了TKBAlignment问题，该问题计算一个变体的TKB，以最小改变TKB，但能使得给定的temporal CQ得到答案，并且是这种（成本-)优化的。</li>
<li>results: 本文对ALC TKBs和 conjunctive queries with LTL operators进行研究，并提出了一种解决TKBAlignment问题的方法，该方法基于 propositional LTL over finite traces的对应技术，可以 Compute (cost-optimal) alignments of TKBs。<details>
<summary>Abstract</summary>
Answering temporal CQs over temporalized Description Logic knowledge bases (TKB) is a main technique to realize ontology-based situation recognition. In case the collected data in such a knowledge base is inaccurate, important query answers can be missed. In this paper we introduce the TKB Alignment problem, which computes a variant of the TKB that minimally changes the TKB, but entails the given temporal CQ and is in that sense (cost-)optimal. We investigate this problem for ALC TKBs and conjunctive queries with LTL operators and devise a solution technique to compute (cost-optimal) alignments of TKBs that extends techniques for the alignment problem for propositional LTL over finite traces.
</details>
<details>
<summary>摘要</summary>
Answering temporal CQs over temporalized Description Logic knowledge bases (TKB) is a main technique to realize ontology-based situation recognition. If the collected data in such a knowledge base is inaccurate, important query answers can be missed. In this paper, we introduce the TKB Alignment problem, which computes a variant of the TKB that minimally changes the TKB, but entails the given temporal CQ and is in that sense (cost-)optimal. We investigate this problem for ALC TKBs and conjunctive queries with LTL operators and devise a solution technique to compute (cost-optimal) alignments of TKBs that extends techniques for the alignment problem for propositional LTL over finite traces.Here's the word-for-word translation:回答 temporal CQs over temporalized Description Logic knowledge bases (TKB) 是实现 ontology-based situation recognition 的主要技术。如果 collected data 中的 TKB 不准确，重要的查询答案就可能会丢失。在这篇论文中，我们介绍 TKB Alignment problem，该问题计算一个 TKB 的变体，使其最小地改变 TKB，但涵盖给定的 temporal CQ，并且是Cost-optimal的。我们对 ALC TKBs 和 conjunctive queries with LTL operators 进行调查，并提出一种 compute (cost-optimal) alignments of TKBs 的解决方案，该方案基于 propositional LTL over finite traces 的对应技术。
</details></li>
</ul>
<hr>
<h2 id="Improvable-Gap-Balancing-for-Multi-Task-Learning"><a href="#Improvable-Gap-Balancing-for-Multi-Task-Learning" class="headerlink" title="Improvable Gap Balancing for Multi-Task Learning"></a>Improvable Gap Balancing for Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15429">http://arxiv.org/abs/2307.15429</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanqidai/igb4mtl">https://github.com/yanqidai/igb4mtl</a></li>
<li>paper_authors: Yanqi Dai, Nanyi Fei, Zhiwu Lu</li>
<li>For: 这篇论文主要关注多任务学习（MTL）中的梯度平衡和损失平衡两种方法，以及它们在不同任务间的对应关系。* Methods: 本篇论文提出了两种新的改进梯度平衡（IGB）算法，其中一种运用了简单的规律，另一种则是通过深度强化学习来实现MTL中的改进梯度平衡。* Results: 实验结果显示，IGB算法在MTL中实现了最佳的结果，并且与梯度平衡结合使用可以获得进一步的改进。<details>
<summary>Abstract</summary>
In multi-task learning (MTL), gradient balancing has recently attracted more research interest than loss balancing since it often leads to better performance. However, loss balancing is much more efficient than gradient balancing, and thus it is still worth further exploration in MTL. Note that prior studies typically ignore that there exist varying improvable gaps across multiple tasks, where the improvable gap per task is defined as the distance between the current training progress and desired final training progress. Therefore, after loss balancing, the performance imbalance still arises in many cases. In this paper, following the loss balancing framework, we propose two novel improvable gap balancing (IGB) algorithms for MTL: one takes a simple heuristic, and the other (for the first time) deploys deep reinforcement learning for MTL. Particularly, instead of directly balancing the losses in MTL, both algorithms choose to dynamically assign task weights for improvable gap balancing. Moreover, we combine IGB and gradient balancing to show the complementarity between the two types of algorithms. Extensive experiments on two benchmark datasets demonstrate that our IGB algorithms lead to the best results in MTL via loss balancing and achieve further improvements when combined with gradient balancing. Code is available at https://github.com/YanqiDai/IGB4MTL.
</details>
<details>
<summary>摘要</summary>
在多任务学习（MTL）中，梯度均衡在最近几年内吸引了更多的研究兴趣，因为它经常会导致更好的性能。然而，损失均衡是梯度均衡的更加有效的方法，因此仍然值得进一步的探索。尽管先前的研究通常忽略了多任务中存在的不同可改善差距，其中每个任务的可改善差距定义为从当前训练进度到期望的最终训练进度之间的距离。因此，在进行损失均衡后，性能差距仍然出现在许多情况下。在本文中，我们采用损失均衡框架，提出了两种新的可改善差距均衡（IGB）算法 для MTL：一个使用简单的启发，另一个（这是第一次）使用深度强化学习。特别是，不直接在 MTL 中平衡损失，而是动态分配任务权重以进行可改善差距均衡。此外，我们将 IGB 和梯度均衡相结合，以示两者之间的补充性。广泛的实验表明，我们的 IGB 算法在 MTL 中通过损失均衡得到最佳结果，并在结合梯度均衡时获得进一步的改进。代码可以在 <https://github.com/YanqiDai/IGB4MTL> 中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Critical-Review-of-Large-Language-Models-Sensitivity-Bias-and-the-Path-Toward-Specialized-AI"><a href="#A-Critical-Review-of-Large-Language-Models-Sensitivity-Bias-and-the-Path-Toward-Specialized-AI" class="headerlink" title="A Critical Review of Large Language Models: Sensitivity, Bias, and the Path Toward Specialized AI"></a>A Critical Review of Large Language Models: Sensitivity, Bias, and the Path Toward Specialized AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15425">http://arxiv.org/abs/2307.15425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arash Hajikhani, Carolyn Cole</li>
<li>for: 本研究探讨了一种专门编译的语言模型和一个通用模型如OpenAI的GPT-3.5在文本数据中检测SDGs的比较效果。</li>
<li>methods: 本研究使用了大语言模型（LLMs），探讨了对偏见和敏感性的挑战。研究强调了特殊训练的重要性以实现精确和不偏的分析。</li>
<li>results: 研究发现，专门的SDG检测模型在公司描述 dataset 中比GPT-3.5更加精准地检测SDGs，并且可以快速地提供高度相关的SDGs。研究认为，在执行任务时应选择合适的模型，考虑任务的需求、成本、复杂度和可见性。<details>
<summary>Abstract</summary>
This paper examines the comparative effectiveness of a specialized compiled language model and a general-purpose model like OpenAI's GPT-3.5 in detecting SDGs within text data. It presents a critical review of Large Language Models (LLMs), addressing challenges related to bias and sensitivity. The necessity of specialized training for precise, unbiased analysis is underlined. A case study using a company descriptions dataset offers insight into the differences between the GPT-3.5 and the specialized SDG detection model. While GPT-3.5 boasts broader coverage, it may identify SDGs with limited relevance to the companies' activities. In contrast, the specialized model zeroes in on highly pertinent SDGs. The importance of thoughtful model selection is emphasized, taking into account task requirements, cost, complexity, and transparency. Despite the versatility of LLMs, the use of specialized models is suggested for tasks demanding precision and accuracy. The study concludes by encouraging further research to find a balance between the capabilities of LLMs and the need for domain-specific expertise and interpretability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Social-Media-Popularity-Prediction-with-Multiple-Post-Dependencies"><a href="#Improving-Social-Media-Popularity-Prediction-with-Multiple-Post-Dependencies" class="headerlink" title="Improving Social Media Popularity Prediction with Multiple Post Dependencies"></a>Improving Social Media Popularity Prediction with Multiple Post Dependencies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15413">http://arxiv.org/abs/2307.15413</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhizhen Zhang, Xiaohui Xie, Mengyu Yang, Ye Tian, Yong Jiang, Yong Cui</li>
<li>for: 预测社交媒体帖子的 популяр度，以提高推荐系统和多媒体广告等应用的效果。</li>
<li>methods: 提出了一种名为受依关系探测网络（DSN）的新预测框架，利用了帖子之间和帖子内的多个依存关系，以提高预测精度。</li>
<li>results: 对社交媒体帖子Popularity Dataset进行实验，比现有的模型表现更优异。<details>
<summary>Abstract</summary>
Social Media Popularity Prediction has drawn a lot of attention because of its profound impact on many different applications, such as recommendation systems and multimedia advertising. Despite recent efforts to leverage the content of social media posts to improve prediction accuracy, many existing models fail to fully exploit the multiple dependencies between posts, which are important to comprehensively extract content information from posts. To tackle this problem, we propose a novel prediction framework named Dependency-aware Sequence Network (DSN) that exploits both intra- and inter-post dependencies. For intra-post dependency, DSN adopts a multimodal feature extractor with an efficient fine-tuning strategy to obtain task-specific representations from images and textual information of posts. For inter-post dependency, DSN uses a hierarchical information propagation method to learn category representations that could better describe the difference between posts. DSN also exploits recurrent networks with a series of gating layers for more flexible local temporal processing abilities and multi-head attention for long-term dependencies. The experimental results on the Social Media Popularity Dataset demonstrate the superiority of our method compared to existing state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
For intra-post dependency, DSN uses a multimodal feature extractor with an efficient fine-tuning strategy to obtain task-specific representations from images and textual information of posts. For inter-post dependency, DSN employs a hierarchical information propagation method to learn category representations that can better capture the differences between posts. Additionally, DSN utilizes recurrent networks with a series of gating layers for more flexible local temporal processing abilities and multi-head attention for long-term dependencies.The experimental results on the Social Media Popularity Dataset demonstrate the superiority of our method compared to existing state-of-the-art models.
</details></li>
</ul>
<hr>
<h2 id="Agent-Based-Model-Simulating-a-Virus-Expansion-Based-on-the-Acceptance-of-Containment-Measures"><a href="#Agent-Based-Model-Simulating-a-Virus-Expansion-Based-on-the-Acceptance-of-Containment-Measures" class="headerlink" title="Agent-Based Model: Simulating a Virus Expansion Based on the Acceptance of Containment Measures"></a>Agent-Based Model: Simulating a Virus Expansion Based on the Acceptance of Containment Measures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15723">http://arxiv.org/abs/2307.15723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alejandro Rodríguez-Arias, Amparo Alonso-Betanzos, Bertha Guijarro-Berdiñas, Noelia Sánchez-Marroño</li>
<li>for: 这个研究旨在描述一种基于代理模型（ABM）的社会系统分析方法，用于研究流行病在社会中的传播和控制。</li>
<li>methods: 该研究使用了修改后的SEIRD模型和公民决策模型，以模拟公民在流行病爆发期间的行为和决策。</li>
<li>results: 研究发现，公民的行为和决策对抗流行病的传播有重要影响，而且这种影响可以通过分析各个公民的行为和决策来了解。<details>
<summary>Abstract</summary>
Compartmental epidemiological models categorize individuals based on their disease status, such as the SEIRD model (Susceptible-Exposed-Infected-Recovered-Dead). These models determine the parameters that influence the magnitude of an outbreak, such as contagion and recovery rates. However, they don't account for individual characteristics or population actions, which are crucial for assessing mitigation strategies like mask usage in COVID-19 or condom distribution in HIV. Additionally, studies highlight the role of citizen solidarity, interpersonal trust, and government credibility in explaining differences in contagion rates between countries. Agent-Based Modeling (ABM) offers a valuable approach to study complex systems by simulating individual components, their actions, and interactions within an environment. ABM provides a useful tool for analyzing social phenomena. In this study, we propose an ABM architecture that combines an adapted SEIRD model with a decision-making model for citizens. In this paper, we propose an ABM architecture that allows us to analyze the evolution of virus infections in a society based on two components: 1) an adaptation of the SEIRD model and 2) a decision-making model for citizens. In this way, the evolution of infections is affected, in addition to the spread of the virus itself, by individual behavior when accepting or rejecting public health measures. We illustrate the designed model by examining the progression of SARS-CoV-2 infections in A Coru\~na, Spain. This approach makes it possible to analyze the effect of the individual actions of citizens during an epidemic on the spread of the virus.
</details>
<details>
<summary>摘要</summary>
《组室传染学模型（SEIRD模型）分类人员根据疾病状况，但这些模型不会考虑个体特征或人口行为，这些因素对控制疫情策略的评估非常重要。例如，面罩使用和HIV抗原分发等疫情控制措施的效果。学者们指出，公民团结、人际信任和政府信用度在不同国家的传染率之间存在关系。基于代理模型（ABM）可以研究复杂系统，模拟个体组件、其行为和互动环境中的交互。在本研究中，我们提出了一种ABM架构，将SEIRD模型与公民决策模型相结合，以分析病毒传播在社会中的演化。我们通过对SARS-CoV-2在西班牙加的库恩省的传播进行示例分析，以示出这种方法的效果。这种方法可以评估疫情期间公民个体行为对病毒传播的影响。》Note: The translation is provided using the Google Translate tool, and may not be entirely accurate or idiomatic.
</details></li>
</ul>
<hr>
<h2 id="Co-attention-Graph-Pooling-for-Efficient-Pairwise-Graph-Interaction-Learning"><a href="#Co-attention-Graph-Pooling-for-Efficient-Pairwise-Graph-Interaction-Learning" class="headerlink" title="Co-attention Graph Pooling for Efficient Pairwise Graph Interaction Learning"></a>Co-attention Graph Pooling for Efficient Pairwise Graph Interaction Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15377">http://arxiv.org/abs/2307.15377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leejunhyun/coattentiongraphpooling">https://github.com/leejunhyun/coattentiongraphpooling</a></li>
<li>paper_authors: Junhyun Lee, Bumsoo Kim, Minji Jeon, Jaewoo Kang</li>
<li>for: 处理和学习图structured数据</li>
<li>methods: 使用 co-attention 在图 pooling 中提取交互作表示</li>
<li>results: 在实际数据集上，与现有方法相比，我们的方法具有更高的精度和更低的计算成本<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have proven to be effective in processing and learning from graph-structured data. However, previous works mainly focused on understanding single graph inputs while many real-world applications require pair-wise analysis for graph-structured data (e.g., scene graph matching, code searching, and drug-drug interaction prediction). To this end, recent works have shifted their focus to learning the interaction between pairs of graphs. Despite their improved performance, these works were still limited in that the interactions were considered at the node-level, resulting in high computational costs and suboptimal performance. To address this issue, we propose a novel and efficient graph-level approach for extracting interaction representations using co-attention in graph pooling. Our method, Co-Attention Graph Pooling (CAGPool), exhibits competitive performance relative to existing methods in both classification and regression tasks using real-world datasets, while maintaining lower computational complexity.
</details>
<details>
<summary>摘要</summary>
格子神经网络（GNNs）已经证明能够有效地处理和学习具有格式结构的数据。然而，先前的工作主要集中在单个图像输入的理解上，而现实世界中许多应用需要对图像数据进行对比分析（例如场景图匹配、代码搜索和药物交互预测）。为此，最近的工作已经转移注意力到对图像对的交互进行学习。虽然这些方法提高了性能，但是它们仍然受到节点级别的交互限制，导致计算成本高并且性能不佳。为解决这个问题，我们提出了一种新的和高效的图像水平的交互表示提取方法，即协同注意力图集（CAGPool）。我们的方法在实际 dataset 上表现竞争性，同时保持计算复杂度较低。
</details></li>
</ul>
<hr>
<h2 id="Confident-Feature-Ranking"><a href="#Confident-Feature-Ranking" class="headerlink" title="Confident Feature Ranking"></a>Confident Feature Ranking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15361">http://arxiv.org/abs/2307.15361</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bitya Neuhof, Yuval Benjamini</li>
<li>for: 本研究旨在提供一种基于对比测试的后处方法，以确定特征重要性值的稳定排名。</li>
<li>methods: 本研究使用对比测试方法，对特征重要性值进行重新排名，并生成相应的置信区间。</li>
<li>results: 本研究确保了对特征重要性值的排名具有高概率包含真实排名，并且允许选择top-k集。<details>
<summary>Abstract</summary>
Interpretation of feature importance values often relies on the relative order of the features rather than on the value itself, referred to as ranking. However, the order may be unstable due to the small sample sizes used in calculating the importance values. We propose that post-hoc importance methods produce a ranking and simultaneous confident intervals for the rankings. Based on pairwise comparisons of the feature importance values, our method is guaranteed to include the ``true'' (infinite sample) ranking with high probability and allows for selecting top-k sets.
</details>
<details>
<summary>摘要</summary>
常用的特征重要性值的解释通常是通过特征之间的相对排名而进行，而不是直接查看值的大小。然而，排名的稳定性可能会受到小样本大小的影响。我们提议使用 posterior 重要性方法生成排名和同时的信任范围，以确保包含“真实”（无限大样本）排名，并允许选择 top-k 集。基于特征之间的对比，我们的方法能够保证包含“真实”排名，并且可以选择 top-k 集。Note: "posterior" in Chinese is "后验" (hòu yì).
</details></li>
</ul>
<hr>
<h2 id="Med-HALT-Medical-Domain-Hallucination-Test-for-Large-Language-Models"><a href="#Med-HALT-Medical-Domain-Hallucination-Test-for-Large-Language-Models" class="headerlink" title="Med-HALT: Medical Domain Hallucination Test for Large Language Models"></a>Med-HALT: Medical Domain Hallucination Test for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15343">http://arxiv.org/abs/2307.15343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Logesh Kumar Umapathi, Ankit Pal, Malaikannan Sankarasubbu</li>
<li>for: The paper is written to address the challenges of hallucinations in large language models (LLMs) in the medical domain, and to propose a new benchmark and dataset (Med-HALT) to evaluate and reduce hallucinations.</li>
<li>methods: The paper proposes a new benchmark and dataset (Med-HALT) that includes reasoning and memory-based hallucination tests to assess LLMs’ problem-solving and information retrieval abilities.</li>
<li>results: The study evaluates leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, and reveals significant differences in their performance. The paper provides detailed insights into the dataset, promoting transparency and reproducibility.<details>
<summary>Abstract</summary>
This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs's problem-solving and information retrieval abilities.   Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting transparency and reproducibility. Through this work, we aim to contribute to the development of safer and more reliable language models in healthcare. Our benchmark can be found at medhalt.github.io
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Skeleton-of-Thought-Large-Language-Models-Can-Do-Parallel-Decoding"><a href="#Skeleton-of-Thought-Large-Language-Models-Can-Do-Parallel-Decoding" class="headerlink" title="Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding"></a>Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15337">http://arxiv.org/abs/2307.15337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, Yu Wang</li>
<li>for: 降低大语言模型（LLMs）的终端生成延迟。</li>
<li>methods: 提出了“思维skeleton”（SoT），让LLMs先生成答案的框架，然后并行API调用或批处理解码完成每个框架点的内容。</li>
<li>results: 对11种不同的LLMs进行测试，得到了 considerable 的速度提升（最高达2.39倍），并且可能会在某些问题类型上提高答案质量。<details>
<summary>Abstract</summary>
This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose "Skeleton-of-Thought" (SoT), which guides LLMs to first generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-up (up to 2.39x across 11 different LLMs), but it can also potentially improve the answer quality on several question categories in terms of diversity and relevance. SoT is an initial attempt at data-centric optimization for efficiency, and reveal the potential of pushing LLMs to think more like a human for answer quality.
</details>
<details>
<summary>摘要</summary>
这项工作的目标是减少大语言模型（LLM）的端到端生成延迟。一个主要的延迟原因是大多数现状的LLM采用的是顺序解码方法。在这项工作中，我们受人类思维和写作过程的 inspirited by，提议了“思想骨架”（SoT），帮助LLM首先生成答案的框架，然后在平行API调用或批处理decode中完善每个骨架点。不仅SoT可以提供显著的速度增加（最多2.39倍于11个不同的LLM），而且也可能提高答案质量在一些问题类型上，包括多样性和相关性。SoT是数据驱动优化的初步尝试，揭示了推动LLM思考更像人类的答案质量的可能性。
</details></li>
</ul>
<hr>
<h2 id="Tutorials-on-Stance-Detection-using-Pre-trained-Language-Models-Fine-tuning-BERT-and-Prompting-Large-Language-Models"><a href="#Tutorials-on-Stance-Detection-using-Pre-trained-Language-Models-Fine-tuning-BERT-and-Prompting-Large-Language-Models" class="headerlink" title="Tutorials on Stance Detection using Pre-trained Language Models: Fine-tuning BERT and Prompting Large Language Models"></a>Tutorials on Stance Detection using Pre-trained Language Models: Fine-tuning BERT and Prompting Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15331">http://arxiv.org/abs/2307.15331</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun-Shiuan Chuang</li>
<li>for: 本文提供了两个自包含的教程，用于在推特数据中进行立场检测，使用BERT精度和大型自然语言模型（LLM）的启发。</li>
<li>methods: 本教程涵盖了BERT体系和Tokenization，并导导用户在训练、调参和评估标准和域pecificBERT模型的方法。</li>
<li>results: 教程使用了多种提示策略，并使用混淆矩阵和macro F1分数来评估。结果显示，不需要精度调整的ChatGPT和FLAN-T5可以在几个例子下表现出优于精度调整的BERT。<details>
<summary>Abstract</summary>
This paper presents two self-contained tutorials on stance detection in Twitter data using BERT fine-tuning and prompting large language models (LLMs). The first tutorial explains BERT architecture and tokenization, guiding users through training, tuning, and evaluating standard and domain-specific BERT models with HuggingFace transformers. The second focuses on constructing prompts and few-shot examples to elicit stances from ChatGPT and open-source FLAN-T5 without fine-tuning. Various prompting strategies are implemented and evaluated using confusion matrices and macro F1 scores. The tutorials provide code, visualizations, and insights revealing the strengths of few-shot ChatGPT and FLAN-T5 which outperform fine-tuned BERTs. By covering both model fine-tuning and prompting-based techniques in an accessible, hands-on manner, these tutorials enable learners to gain applied experience with cutting-edge methods for stance detection.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这篇论文提供了使用BERT精细化和大型自然语言模型（LLM）的两个自包含的教程，用于推断推特上的立场检测。第一个教程介绍了BERT的架构和token化，并引导用户通过训练、调整和评估标准和域pecificBERT模型的方法。第二个教程专注于构建提示和几个示例来引发ChatGPT和开源FLAN-T5的立场，而不需要精细化。多种提示策略被实现和评估使用混淆矩阵和macro F1分数。这些教程提供了代码、视觉化和概念，揭示了几个批处的强点，其中几个几个示例超出了精细化BERT的性能。通过覆盖模型精细化和提示基本技术，这些教程帮助学习者获得应用最新方法的实践经验。
</details></li>
</ul>
<hr>
<h2 id="Robust-Visual-Sim-to-Real-Transfer-for-Robotic-Manipulation"><a href="#Robust-Visual-Sim-to-Real-Transfer-for-Robotic-Manipulation" class="headerlink" title="Robust Visual Sim-to-Real Transfer for Robotic Manipulation"></a>Robust Visual Sim-to-Real Transfer for Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15320">http://arxiv.org/abs/2307.15320</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ricardo Garcia, Robin Strudel, Shizhe Chen, Etienne Arlaud, Ivan Laptev, Cordelia Schmid</li>
<li>for: 这个论文的目的是探索视觉动力策略在模拟环境中学习，以优化在真实世界中的机器人控制。</li>
<li>methods: 这个论文使用了域随机化（DR）方法来bridge模拟和真实数据之间的观察者随机化（sim-to-real）问题。</li>
<li>results: 研究人员通过使用DR方法，在一个rich的机器人抓取任务集中系统地探索了视觉域随机化策略，并证明了DR参数对off-line代理任务和on-line策略均有类似的影响。此外，研究人员还表明了在真实场景中的视觉变化robustness的优势。<details>
<summary>Abstract</summary>
Learning visuomotor policies in simulation is much safer and cheaper than in the real world. However, due to discrepancies between the simulated and real data, simulator-trained policies often fail when transferred to real robots. One common approach to bridge the visual sim-to-real domain gap is domain randomization (DR). While previous work mainly evaluates DR for disembodied tasks, such as pose estimation and object detection, here we systematically explore visual domain randomization methods and benchmark them on a rich set of challenging robotic manipulation tasks. In particular, we propose an off-line proxy task of cube localization to select DR parameters for texture randomization, lighting randomization, variations of object colors and camera parameters. Notably, we demonstrate that DR parameters have similar impact on our off-line proxy task and on-line policies. We, hence, use off-line optimized DR parameters to train visuomotor policies in simulation and directly apply such policies to a real robot. Our approach achieves 93% success rate on average when tested on a diverse set of challenging manipulation tasks. Moreover, we evaluate the robustness of policies to visual variations in real scenes and show that our simulator-trained policies outperform policies learned using real but limited data. Code, simulation environment, real robot datasets and trained models are available at https://www.di.ens.fr/willow/research/robust_s2r/.
</details>
<details>
<summary>摘要</summary>
学习视motor策略在模拟中 Much safer and cheaper than in the real world. However, due to discrepancies between the simulated and real data, simulator-trained policies often fail when transferred to real robots. One common approach to bridge the visual sim-to-real domain gap is domain randomization (DR). While previous work mainly evaluates DR for disembodied tasks, such as pose estimation and object detection, here we systematically explore visual domain randomization methods and benchmark them on a rich set of challenging robotic manipulation tasks. In particular, we propose an off-line proxy task of cube localization to select DR parameters for texture randomization, lighting randomization, variations of object colors and camera parameters. Notably, we demonstrate that DR parameters have similar impact on our off-line proxy task and on-line policies. We, hence, use off-line optimized DR parameters to train visuomotor policies in simulation and directly apply such policies to a real robot. Our approach achieves 93% success rate on average when tested on a diverse set of challenging manipulation tasks. Moreover, we evaluate the robustness of policies to visual variations in real scenes and show that our simulator-trained policies outperform policies learned using real but limited data. 代码、模拟环境、实际机器人数据和训练模型可以在https://www.di.ens.fr/willow/research/robust_s2r/ obtained。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Reality-The-Pivotal-Role-of-Generative-AI-in-the-Metaverse"><a href="#Beyond-Reality-The-Pivotal-Role-of-Generative-AI-in-the-Metaverse" class="headerlink" title="Beyond Reality: The Pivotal Role of Generative AI in the Metaverse"></a>Beyond Reality: The Pivotal Role of Generative AI in the Metaverse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06272">http://arxiv.org/abs/2308.06272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vinay Chamola, Gaurang Bansal, Tridib Kumar Das, Vikas Hassija, Naga Siva Sai Reddy, Jiacheng Wang, Sherali Zeadally, Amir Hussain, F. Richard Yu, Mohsen Guizani, Dusit Niyato</li>
<li>for: 这篇论文探讨了如何通过生成人工智能技术实现虚拟世界的演进和互动性，以及这些技术在虚拟世界中的应用。</li>
<li>methods: 论文描述了各种生成人工智能技术，包括文本生成模型ChatGPT和GPT-3、图像生成模型DALL-E和MidJourney、以及3D模型生成技术Point-E和Lumirithmic。</li>
<li>results: 论文总结了这些技术在虚拟世界中的应用和发展前景，同时也评估了这些技术的挑战和伦理问题。<details>
<summary>Abstract</summary>
Imagine stepping into a virtual world that's as rich, dynamic, and interactive as our physical one. This is the promise of the Metaverse, and it's being brought to life by the transformative power of Generative Artificial Intelligence (AI). This paper offers a comprehensive exploration of how generative AI technologies are shaping the Metaverse, transforming it into a dynamic, immersive, and interactive virtual world. We delve into the applications of text generation models like ChatGPT and GPT-3, which are enhancing conversational interfaces with AI-generated characters. We explore the role of image generation models such as DALL-E and MidJourney in creating visually stunning and diverse content. We also examine the potential of 3D model generation technologies like Point-E and Lumirithmic in creating realistic virtual objects that enrich the Metaverse experience. But the journey doesn't stop there. We also address the challenges and ethical considerations of implementing these technologies in the Metaverse, offering insights into the balance between user control and AI automation. This paper is not just a study, but a guide to the future of the Metaverse, offering readers a roadmap to harnessing the power of generative AI in creating immersive virtual worlds.
</details>
<details>
<summary>摘要</summary>
imagine 进入一个丰富、动态、互动的虚拟世界，这是metaverse的推荐，并且这个虚拟世界正在被生成人工智能（AI）的变革力所实现。本文将进行全面的探讨，描述如何使用生成AI技术将metaverse变成一个动态、内在、互动的虚拟世界。我们将探讨文本生成模型如ChatGPT和GPT-3，它们在虚拟世界中创建了AI生成的人物，让用户能够在虚拟世界中互动。我们也将探讨图像生成模型如DALL-E和MidJourney，它们在创建丰富多样的内容方面发挥了重要作用。此外，我们还将探讨3D模型生成技术如Point-E和Lumirithmic，它们将实现虚拟物品的实际化，增强metaverse的体验。但我们的旅程不止于此。我们还需要处理在metaverse中实施这些技术的挑战和伦理考虑。本文不仅是一篇研究，更是 metaverse 未来的路径，帮助读者实现在虚拟世界中使用生成AI的潜力。
</details></li>
</ul>
<hr>
<h2 id="DiffKendall-A-Novel-Approach-for-Few-Shot-Learning-with-Differentiable-Kendall’s-Rank-Correlation"><a href="#DiffKendall-A-Novel-Approach-for-Few-Shot-Learning-with-Differentiable-Kendall’s-Rank-Correlation" class="headerlink" title="DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall’s Rank Correlation"></a>DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall’s Rank Correlation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15317">http://arxiv.org/abs/2307.15317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaipeng Zheng, Huishuai Zhang, Weiran Huang</li>
<li>for: 这个论文主要针对几何学习中的测试类别不为模型所见过的问题进行适应。</li>
<li>methods: 这个论文使用了几何 similarity 度量来衡量两个特征之间的Semantic相似性，并将 Kendall rank correlation 作为替代的度量。</li>
<li>results: 这个论文的实验结果显示，使用 Kendall rank correlation 来替代几何 similarity 度量可以对几何学习中的测试类别进行更好的适应，并且可以实现更高的性能。<details>
<summary>Abstract</summary>
Few-shot learning aims to adapt models trained on the base dataset to novel tasks where the categories are not seen by the model before. This often leads to a relatively uniform distribution of feature values across channels on novel classes, posing challenges in determining channel importance for novel tasks. Standard few-shot learning methods employ geometric similarity metrics such as cosine similarity and negative Euclidean distance to gauge the semantic relatedness between two features. However, features with high geometric similarities may carry distinct semantics, especially in the context of few-shot learning. In this paper, we demonstrate that the importance ranking of feature channels is a more reliable indicator for few-shot learning than geometric similarity metrics. We observe that replacing the geometric similarity metric with Kendall's rank correlation only during inference is able to improve the performance of few-shot learning across a wide range of datasets with different domains. Furthermore, we propose a carefully designed differentiable loss for meta-training to address the non-differentiability issue of Kendall's rank correlation. Extensive experiments demonstrate that the proposed rank-correlation-based approach substantially enhances few-shot learning performance.
</details>
<details>
<summary>摘要</summary>
通过几拍学习适应基 dataset 中的任务，目标是使模型能够适应 novel 任务中的类别未经过模型训练。这经常导致 novel 类通道的特征值分布呈相对均勋的形式，从而增加了决定通道重要性的挑战。标准的几拍学习方法通常使用 геометрические相似度度量，如 косину斯相似度和负 Euclidian 距离，来衡量两个特征之间的 semantic 相似性。但是，具有高 geometric 相似度的特征可能会拥有不同的 semantics，特别是在几拍学习上。在这篇文章中，我们表明通道的重要性排名是几拍学习中更可靠的指标，而不是 geometric 相似度度量。我们发现，在推理时将 geometric 相似度度量替换为 Kendall 排名相关性可以在不同领域的 dataset 上提高几拍学习性能。此外，我们还提出了一种特殊的可导式损失函数，用于在 meta-training 中处理 Kendall 排名相关性的不导数问题。广泛的实验表明，我们的排名相关性基于的方法可以显著提高几拍学习性能。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Multiuser-AI-Downloading-via-Reusable-Knowledge-Broadcasting"><a href="#Efficient-Multiuser-AI-Downloading-via-Reusable-Knowledge-Broadcasting" class="headerlink" title="Efficient Multiuser AI Downloading via Reusable Knowledge Broadcasting"></a>Efficient Multiuser AI Downloading via Reusable Knowledge Broadcasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15316">http://arxiv.org/abs/2307.15316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hai Wu, Qunsong Zeng, Kaibin Huang</li>
<li>for: 这 paper 的目的是解决 sixth-generation (6G) 移动网络中的即时适应人工智能（AI）模型下载问题，以减少无线链路上的通信开销。</li>
<li>methods: 这 paper 提出了一个名为 Model Broadcasting and Assembling (MBA) 框架，该框架利用可重用知识（shared parameters among tasks）来启用参数广播，从而减少通信开销。MBA 框架包括两个关键组件：MBA 协议和参数选择和功率控制（PS-PC）的共同设计。</li>
<li>results: 该 paper 的实验结果表明，相比传统模型下载方法，MBA 框架可以减少下载时间开销，提高设备的模型性能。<details>
<summary>Abstract</summary>
For the 6G mobile networks, in-situ model downloading has emerged as an important use case to enable real-time adaptive artificial intelligence on edge devices. However, the simultaneous downloading of diverse and high-dimensional models to multiple devices over wireless links presents a significant communication bottleneck. To overcome the bottleneck, we propose the framework of model broadcasting and assembling (MBA), which represents the first attempt on leveraging reusable knowledge, referring to shared parameters among tasks, to enable parameter broadcasting to reduce communication overhead. The MBA framework comprises two key components. The first, the MBA protocol, defines the system operations including parameter selection from a model library, power control for broadcasting, and model assembling at devices. The second component is the joint design of parameter-selection-and-power-control (PS-PC), which provides guarantees on devices' model performance and minimizes the downloading latency. The corresponding optimization problem is simplified by decomposition into the sequential PS and PC sub-problems without compromising its optimality. The PS sub-problem is solved efficiently by designing two efficient algorithms. On one hand, the low-complexity algorithm of greedy parameter selection features the construction of candidate model sets and a selection metric, both of which are designed under the criterion of maximum reusable knowledge among tasks. On the other hand, the optimal tree-search algorithm gains its efficiency via the proposed construction of a compact binary tree pruned using model architecture constraints and an intelligent branch-and-bound search. Given optimal PS, the optimal PC policy is derived in closed form. Extensive experiments demonstrate the substantial reduction in downloading latency achieved by the proposed MBA compared to traditional model downloading.
</details>
<details>
<summary>摘要</summary>
The MBA framework consists of two key components:1. MBA Protocol: This defines the system operations, including parameter selection from a model library, power control for broadcasting, and model assembling at devices.2. Joint Design of Parameter-Selection-and-Power-Control (PS-PC): This provides guarantees on devices' model performance and minimizes downloading latency. The optimization problem is simplified by decomposing it into sequential PS and PC sub-problems without compromising optimality.The PS sub-problem is solved efficiently using two efficient algorithms:1. Greedy Parameter Selection: This features the construction of candidate model sets and a selection metric, both designed under the criterion of maximum reusable knowledge among tasks.2. Optimal Tree-Search Algorithm: This gains efficiency via a proposed construction of a compact binary tree pruned using model architecture constraints and an intelligent branch-and-bound search.Given optimal PS, the optimal PC policy is derived in closed form. Extensive experiments demonstrate that the proposed MBA achieves substantial reduction in downloading latency compared to traditional model downloading.
</details></li>
</ul>
<hr>
<h2 id="WC-SBERT-Zero-Shot-Text-Classification-via-SBERT-with-Self-Training-for-Wikipedia-Categories"><a href="#WC-SBERT-Zero-Shot-Text-Classification-via-SBERT-with-Self-Training-for-Wikipedia-Categories" class="headerlink" title="WC-SBERT: Zero-Shot Text Classification via SBERT with Self-Training for Wikipedia Categories"></a>WC-SBERT: Zero-Shot Text Classification via SBERT with Self-Training for Wikipedia Categories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15293">http://arxiv.org/abs/2307.15293</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/seventychi/wc-sbert">https://github.com/seventychi/wc-sbert</a></li>
<li>paper_authors: Te-Yu Chi, Yu-Meng Tang, Chia-Wen Lu, Qiu-Xia Zhang, Jyh-Shing Roger Jang</li>
<li>for: 解决 zero-shot 文本分类问题，尤其是自适应自动学习策略。</li>
<li>methods: 提议一种使用标签而不是文本进行训练的新型自适应策略，利用 Wikipedia 中的类别作为训练集，并使用 SBERT 预训练模型建立文本中对应的相互关系，以便 associative 训练。</li>
<li>results: 实验结果表明，这种方法可以在 minutes 内将模型适应目标数据集，并在 Yahoo Topic 和 AG News 数据集上达到了状态元的 результаTS。相比其他 BERT 基于 transformer 模型，我们的方法可以减少训练数据量，提高训练效率，并且在不同数据集上进行快速的精度调整和推理。<details>
<summary>Abstract</summary>
Our research focuses on solving the zero-shot text classification problem in NLP, with a particular emphasis on innovative self-training strategies. To achieve this objective, we propose a novel self-training strategy that uses labels rather than text for training, significantly reducing the model's training time. Specifically, we use categories from Wikipedia as our training set and leverage the SBERT pre-trained model to establish positive correlations between pairs of categories within the same text, facilitating associative training. For new test datasets, we have improved the original self-training approach, eliminating the need for prior training and testing data from each target dataset. Instead, we adopt Wikipedia as a unified training dataset to better approximate the zero-shot scenario. This modification allows for rapid fine-tuning and inference across different datasets, greatly reducing the time required for self-training. Our experimental results demonstrate that this method can adapt the model to the target dataset within minutes. Compared to other BERT-based transformer models, our approach significantly reduces the amount of training data by training only on labels, not the actual text, and greatly improves training efficiency by utilizing a unified training set. Additionally, our method achieves state-of-the-art results on both the Yahoo Topic and AG News datasets.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:我们的研究集中于解决NLP中的零例文本分类问题，强调创新自动训练策略。为达到这个目标，我们提议一种新的自动训练策略，使用标签而不是文本进行训练，减少模型训练时间。特别是，我们使用Wikipedia中的类别作为我们的训练集，利用SBERT预训练模型来建立文本中类别之间的相互关联，促进相关训练。对于新的测试集，我们改进了原始自动训练方法，消除了每个目标集需要的先前训练和测试数据。而是采用Wikipedia作为一个统一的训练集，更好地逼近零例场景。这种修改允许快速的细化和推理，大幅减少自动训练的时间。我们的实验结果表明，这种方法可以在分钟内适应目标集。相比其他BERT基于转换器模型，我们的方法可以减少训练数据量，只训练标签而不是实际文本，并且大幅提高训练效率。此外，我们的方法在Yahoo主题和AG新闻集上达到了状态对的结果。
</details></li>
</ul>
<hr>
<h2 id="Reasoning-before-Responding-Integrating-Commonsense-based-Causality-Explanation-for-Empathetic-Response-Generation"><a href="#Reasoning-before-Responding-Integrating-Commonsense-based-Causality-Explanation-for-Empathetic-Response-Generation" class="headerlink" title="Reasoning before Responding: Integrating Commonsense-based Causality Explanation for Empathetic Response Generation"></a>Reasoning before Responding: Integrating Commonsense-based Causality Explanation for Empathetic Response Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00085">http://arxiv.org/abs/2308.00085</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yahui Fu, Koji Inoue, Chenhui Chu, Tatsuya Kawahara</li>
<li>for: 提高对用户情感的理解和回应</li>
<li>methods:  incorporating commonsense knowledge and reasoning about the causes of emotions, integrating in-context learning with commonsense knowledge, and integrating with ChatGPT and T5-based models</li>
<li>results: outperforms other comparable methods on both automatic and human evaluations<details>
<summary>Abstract</summary>
Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.
</details>
<details>
<summary>摘要</summary>
现代方法 для生成同情响应尝试包含常识知识或理智来更好地理解用户的经验和情感。然而，这些方法主要关注用户的视角，忽略系统的视角。在这篇论文中，我们提出一种基于常识的 causality 解释方法 для多样化同情响应生成，考虑用户的视角（用户的愿望和反应）和系统的视角（系统的意图和反应）。我们通过将审计学习与常识知识集成到ChatGPT中，提高其理解系统视角的能力。然后，我们将commonsense-based causality explanation与ChatGPT和基于T5的模型集成。实验评估表明，我们的方法在自动和人类评估中都高于其他相似方法。
</details></li>
</ul>
<hr>
<h2 id="Multiple-Instance-Learning-Framework-with-Masked-Hard-Instance-Mining-for-Whole-Slide-Image-Classification"><a href="#Multiple-Instance-Learning-Framework-with-Masked-Hard-Instance-Mining-for-Whole-Slide-Image-Classification" class="headerlink" title="Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification"></a>Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15254">http://arxiv.org/abs/2307.15254</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dearcaat/mhim-mil">https://github.com/dearcaat/mhim-mil</a></li>
<li>paper_authors: Wenhao Tang, Sheng Huang, Xiaoxian Zhang, Fengtao Zhou, Yi Zhang, Bo Liu</li>
<li>for: 这篇论文是关于多个实例学习（MIL）问题的解决方案。</li>
<li>methods: 这篇论文使用了一种新的实例遮盖策略（Masked Hard Instance Mining，MHIM），它使用一个SIAMESE结构（教师-学生）和一个准确性约束来探索可能的困难实例。</li>
<li>results: 实验结果表明，使用MHIM-MIL方法可以在CAMELYON-16和TCGA肺癌数据集上超过其他最新的方法，并且具有更好的性能和训练成本。Here’s the breakdown of each point in more detail:</li>
<li>for: The paper is about solving the Multiple Instance Learning (MIL) problem, which is a common problem in medical image analysis.</li>
<li>methods: The proposed method uses a novel instance masking strategy called Masked Hard Instance Mining (MHIM), which combines a Siamese structure with a consistency constraint to explore potential hard instances.</li>
<li>results: The experimental results on the CAMELYON-16 and TCGA Lung Cancer datasets show that the proposed MHIM-MIL method outperforms other state-of-the-art methods in terms of performance and training cost.<details>
<summary>Abstract</summary>
The whole slide image (WSI) classification is often formulated as a multiple instance learning (MIL) problem. Since the positive tissue is only a small fraction of the gigapixel WSI, existing MIL methods intuitively focus on identifying salient instances via attention mechanisms. However, this leads to a bias towards easy-to-classify instances while neglecting hard-to-classify instances. Some literature has revealed that hard examples are beneficial for modeling a discriminative boundary accurately. By applying such an idea at the instance level, we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which uses a Siamese structure (Teacher-Student) with a consistency constraint to explore the potential hard instances. With several instance masking strategies based on attention scores, MHIM-MIL employs a momentum teacher to implicitly mine hard instances for training the student model, which can be any attention-based MIL model. This counter-intuitive strategy essentially enables the student to learn a better discriminating boundary. Moreover, the student is used to update the teacher with an exponential moving average (EMA), which in turn identifies new hard instances for subsequent training iterations and stabilizes the optimization. Experimental results on the CAMELYON-16 and TCGA Lung Cancer datasets demonstrate that MHIM-MIL outperforms other latest methods in terms of performance and training cost. The code is available at: https://github.com/DearCaat/MHIM-MIL.
</details>
<details>
<summary>摘要</summary>
整个滤镜图像（WSI）分类经常被视为多例学习（MIL）问题。由于正例组占整个多个吉比特像素的只有一小部分，现有的MIL方法倾向于通过注意力机制来标识突出的实例。然而，这会导致模型偏好易于分类的实例，而忽略困难分类的实例。一些文献表明，困难的实例对模型准确地界定边框具有重要作用。我们在实例层次上运用这一想法，提出了一种新的MIL框架——偏挥硬实例挖掘（MHIM-MIL）。该框架使用了SIAMESE结构（教师-学生），并通过一致性约束来探索潜在的困难实例。通过多种实例层次的掩码策略，MHIM-MIL使用了掩码硬实例来训练学生模型，该模型可以是任何注意力基于的MIL模型。这种Counter-intuitive策略使得学生能够学习更好的分类边界。此外，学生模型被用来更新教师模型，并使用了指数移动平均（EMA）来识别新的困难实例，以便在后续训练迭代中进行更新。实验结果表明，MHIM-MIL在CAMELYON-16和TCGA肺癌数据集上表现出色，比latest方法更高的性能和训练成本。代码可以在：https://github.com/DearCaat/MHIM-MIL。
</details></li>
</ul>
<hr>
<h2 id="An-Overview-Of-Temporal-Commonsense-Reasoning-and-Acquisition"><a href="#An-Overview-Of-Temporal-Commonsense-Reasoning-and-Acquisition" class="headerlink" title="An Overview Of Temporal Commonsense Reasoning and Acquisition"></a>An Overview Of Temporal Commonsense Reasoning and Acquisition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00002">http://arxiv.org/abs/2308.00002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Wenzel, Adam Jatowt</li>
<li>for: 本文旨在探讨大语言模型在时间常识逻辑 reasoning 方面的表现，并提出了一些增强语言模型表现的方法。</li>
<li>methods: 本文使用了多种增强方法，包括数据增强、随机隐藏状态和随机掩码等，以提高语言模型的时间常识逻辑能力。</li>
<li>results:  despite the use of these augmentations, the models still struggle to approach human performance on reasoning tasks over temporal common sense properties, such as the typical occurrence times, orderings, or durations of events.<details>
<summary>Abstract</summary>
Temporal commonsense reasoning refers to the ability to understand the typical temporal context of phrases, actions, and events, and use it to reason over problems requiring such knowledge. This trait is essential in temporal natural language processing tasks, with possible applications such as timeline summarization, temporal question answering, and temporal natural language inference. Recent research on the performance of large language models suggests that, although they are adept at generating syntactically correct sentences and solving classification tasks, they often take shortcuts in their reasoning and fall prey to simple linguistic traps. This article provides an overview of research in the domain of temporal commonsense reasoning, particularly focusing on enhancing language model performance through a variety of augmentations and their evaluation across a growing number of datasets. However, these augmented models still struggle to approach human performance on reasoning tasks over temporal common sense properties, such as the typical occurrence times, orderings, or durations of events. We further emphasize the need for careful interpretation of research to guard against overpromising evaluation results in light of the shallow reasoning present in transformers. This can be achieved by appropriately preparing datasets and suitable evaluation metrics.
</details>
<details>
<summary>摘要</summary>
时间常识逻辑指的是理解phrase、action和event的典型时间上下文，并使用这些知识来解决问题。这种 trait 是 temporal natural language processing 任务的关键特征，可能的应用包括时间线概要、时间问答和时间自然语言推理。Recent research 表明，虽然大语言模型能够生成正确的语法结构和解决分类任务，但它们经常采取短cuts 的思维方式，容易受到simple linguistic traps 的影响。本文提供了 temporal commonsense reasoning 领域的研究概述，特别是通过多种加强和其评估在不断增长的数据集上。然而，这些加强模型仍然无法 approached human performance 在时间常识性Property上，如事件的典型发生时间、顺序或持续时间。我们进一步强调需要在研究中进行仔细的解释，以避免因 transformers 的浅层理解而导致的误导。这可以通过适当的数据准备和评估 metric 来实现。
</details></li>
</ul>
<hr>
<h2 id="A-Practical-Recipe-for-Federated-Learning-Under-Statistical-Heterogeneity-Experimental-Design"><a href="#A-Practical-Recipe-for-Federated-Learning-Under-Statistical-Heterogeneity-Experimental-Design" class="headerlink" title="A Practical Recipe for Federated Learning Under Statistical Heterogeneity Experimental Design"></a>A Practical Recipe for Federated Learning Under Statistical Heterogeneity Experimental Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15245">http://arxiv.org/abs/2307.15245</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mmorafah/fedzoo-bench">https://github.com/mmorafah/fedzoo-bench</a></li>
<li>paper_authors: Mahdi Morafah, Weijia Wang, Bill Lin</li>
<li>for: 本研究旨在探讨 Federated Learning (FL) 在数据不同性下的应用，并提供一个可比较的和有奖励的实验设置。</li>
<li>methods: 本研究使用了多种 FL 方法，包括 22 种state-of-the-art 方法，并提供了一个开源库 PyTorch 的实现。</li>
<li>results: 研究发现了 FL 特有的实验变量对性能的影响，并提供了一些建议和标准化的特性，以帮助设计更加有意义和有奖励的 FL 实验设置。<details>
<summary>Abstract</summary>
Federated Learning (FL) has been an area of active research in recent years. There have been numerous studies in FL to make it more successful in the presence of data heterogeneity. However, despite the existence of many publications, the state of progress in the field is unknown. Many of the works use inconsistent experimental settings and there are no comprehensive studies on the effect of FL-specific experimental variables on the results and practical insights for a more comparable and consistent FL experimental setup. Furthermore, the existence of several benchmarks and confounding variables has further complicated the issue of inconsistency and ambiguity. In this work, we present the first comprehensive study on the effect of FL-specific experimental variables in relation to each other and performance results, bringing several insights and recommendations for designing a meaningful and well-incentivized FL experimental setup. We further aid the community by releasing FedZoo-Bench, an open-source library based on PyTorch with pre-implementation of 22 state-of-the-art methods, and a broad set of standardized and customizable features available at https://github.com/MMorafah/FedZoo-Bench. We also provide a comprehensive comparison of several state-of-the-art (SOTA) methods to better understand the current state of the field and existing limitations.
</details>
<details>
<summary>摘要</summary>
Federated Learning (FL) 是近年来的一个热点领域，有很多研究来使其在数据不同性时更成功。然而，尽管有很多论文，但现状的进步还未得到了一个全面的了解。许多研究使用不一致的实验设置，并没有系统性的研究FL特有的实验变量对结果和实践建议。此外，存在多个标准准则和干扰变量，导致了不一致和混乱的问题。在这项工作中，我们提供了FL特有实验变量与其他变量之间的首次全面研究，从而获得了许多新的发现和建议，以及设计一个有意义和有奖励的FL实验设置。此外，我们还发布了FedZoo-Bench，一个基于PyTorch的开源库，包含22种当前领导的方法的预实现，以及一个广泛的标准化和自定义功能，可以在https://github.com/MMorafah/FedZoo-Bench中获取。此外，我们还提供了多种当前领导方法的比较，以更好地了解现场的状况和存在的限制。
</details></li>
</ul>
<hr>
<h2 id="BOURNE-Bootstrapped-Self-supervised-Learning-Framework-for-Unified-Graph-Anomaly-Detection"><a href="#BOURNE-Bootstrapped-Self-supervised-Learning-Framework-for-Unified-Graph-Anomaly-Detection" class="headerlink" title="BOURNE: Bootstrapped Self-supervised Learning Framework for Unified Graph Anomaly Detection"></a>BOURNE: Bootstrapped Self-supervised Learning Framework for Unified Graph Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15244">http://arxiv.org/abs/2307.15244</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jackson117/BOURNE">https://github.com/Jackson117/BOURNE</a></li>
<li>paper_authors: Jie Liu, Mengting He, Xuequn Shang, Jieming Shi, Bin Cui, Hongzhi Yin</li>
<li>for: 这篇论文的目的是提出一个统一的图像异常检测方法，以检测图像中的节点和边异常。</li>
<li>methods: 本论文使用的方法包括图像观察中心的节点和边异常检测模型，以及一个bootstrapped自我监督学习架构（BOURNE）。BOURNE使用图像和图像对映的方法来捕捉节点和边的表现，并通过节点和边之间的对映来实现节点和边异常的互相检测。</li>
<li>results: 实验结果显示，BOURNE在6个benchmark dataset上具有较高的异常检测效果和效率，并且可以处理大型图像。<details>
<summary>Abstract</summary>
Graph anomaly detection (GAD) has gained increasing attention in recent years due to its critical application in a wide range of domains, such as social networks, financial risk management, and traffic analysis. Existing GAD methods can be categorized into node and edge anomaly detection models based on the type of graph objects being detected. However, these methods typically treat node and edge anomalies as separate tasks, overlooking their associations and frequent co-occurrences in real-world graphs. As a result, they fail to leverage the complementary information provided by node and edge anomalies for mutual detection. Additionally, state-of-the-art GAD methods, such as CoLA and SL-GAD, heavily rely on negative pair sampling in contrastive learning, which incurs high computational costs, hindering their scalability to large graphs. To address these limitations, we propose a novel unified graph anomaly detection framework based on bootstrapped self-supervised learning (named BOURNE). We extract a subgraph (graph view) centered on each target node as node context and transform it into a dual hypergraph (hypergraph view) as edge context. These views are encoded using graph and hypergraph neural networks to capture the representations of nodes, edges, and their associated contexts. By swapping the context embeddings between nodes and edges and measuring the agreement in the embedding space, we enable the mutual detection of node and edge anomalies. Furthermore, we adopt a bootstrapped training strategy that eliminates the need for negative sampling, enabling BOURNE to handle large graphs efficiently. Extensive experiments conducted on six benchmark datasets demonstrate the superior effectiveness and efficiency of BOURNE in detecting both node and edge anomalies.
</details>
<details>
<summary>摘要</summary>
GRAPH anomaly detection (GAD) 在过去几年内得到了越来越多的关注，因为它在各种领域中具有重要的应用，如社交网络、金融风险管理和交通分析。现有的 GAD 方法可以分为基于图对象类型的节点和边异常检测模型。然而，这些方法通常将节点和边异常视为分开的任务，忽略了它们在实际图中的相互关系和常见的共occurrence。这会导致它们无法利用节点和边异常的相互信息进行互助检测。此外，现有的 GAD 方法，如 CoLA 和 SL-GAD，通常依赖于负样本采样，这会增加计算成本，使其不可扩展到大型图。为解决这些限制，我们提出了一种基于自我超vision learning的新的统一图异常检测框架（名为 BOURNE）。我们将目标节点所在的子图（图视图）中心化为节点上下文，并将其转换成双向图（双向图视图）来表示边上下文。这些视图被图和双向图神经网络编码，以Capture图节点、边和其相关上下文的表示。通过交换节点和边上下文嵌入的协调，我们实现了节点和边异常之间的互助检测。此外，我们采用了自我超视learning的培训策略，不需要负样本，从而使 BOURNE 可以高效地处理大型图。我们在六个 benchmark 数据集上进行了广泛的实验，结果表明 BOURNE 能够高效地检测节点和边异常。
</details></li>
</ul>
<hr>
<h2 id="Learning-Multi-modal-Representations-by-Watching-Hundreds-of-Surgical-Video-Lectures"><a href="#Learning-Multi-modal-Representations-by-Watching-Hundreds-of-Surgical-Video-Lectures" class="headerlink" title="Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures"></a>Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15220">http://arxiv.org/abs/2307.15220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/camma-public/surgvlp">https://github.com/camma-public/surgvlp</a></li>
<li>paper_authors: Kun Yuan, Vinkle Srivastav, Tong Yu, Joel Lavanchy, Pietro Mascagni, Nassir Navab, Nicolas Padoy</li>
<li>for: 本研究旨在使用开放式 Laparoscopic surgery 视频教程提供有效的超级视觉语言学习指导，无需人工标注。</li>
<li>methods: 我们使用多种自动语音识别系统生成视频lecture 的文本转写，并提出了一种新的多模态表示学习方法——SurgVLP，用于对视频和文本进行共同表示学习。</li>
<li>results: 我们在多种视觉语言任务上展示了我们的方法的表示能力，包括文本基于视频检索、时间活动固定和视频描述等。此外，我们还证明了我们的方法可以无需人工标注来进行传统的视觉下游任务，如手术工具、阶段和 triplet 识别。<details>
<summary>Abstract</summary>
Recent advancements in surgical computer vision applications have been driven by fully-supervised methods, primarily using only visual data. These methods rely on manually annotated surgical videos to predict a fixed set of object categories, limiting their generalizability to unseen surgical procedures and downstream tasks. In this work, we put forward the idea that the surgical video lectures available through open surgical e-learning platforms can provide effective supervisory signals for multi-modal representation learning without relying on manual annotations. We address the surgery-specific linguistic challenges present in surgical video lectures by employing multiple complementary automatic speech recognition systems to generate text transcriptions. We then present a novel method, SurgVLP - Surgical Vision Language Pre-training, for multi-modal representation learning. SurgVLP constructs a new contrastive learning objective to align video clip embeddings with the corresponding multiple text embeddings by bringing them together within a joint latent space. To effectively show the representation capability of the learned joint latent space, we introduce several vision-and-language tasks for surgery, such as text-based video retrieval, temporal activity grounding, and video captioning, as benchmarks for evaluation. We further demonstrate that without using any labeled ground truth, our approach can be employed for traditional vision-only surgical downstream tasks, such as surgical tool, phase, and triplet recognition. The code will be made available at https://github.com/CAMMA-public/SurgVLP
</details>
<details>
<summary>摘要</summary>
近期的手术计算机视觉应用程序得到了完全监督的方法驱动，主要使用视觉数据。这些方法依赖于手术视频的手动标注来预测固定的对象类别，这限制了它们对未经见过手术过程和下游任务的泛化能力。在这种工作中，我们提出了使用开放手术电子学习平台上的手术视频课程来提供有效的监督信号，以实现多模态表示学习而无需手动标注。我们对手术视频课程中存在的手术语言特有挑战采用多种自动语音识别系统来生成文本转录。然后，我们提出了一种新的多模态表示学习方法——手术视语言预训练（SurgVLP）。SurgVLP构建了一个新的对比学习目标，将视频剪辑embedding与相应的多个文本embedding集成在一个共同的latent空间中。为了有效地展示学习得到的共同空间表示能力，我们引入了许多视频和语言任务，如文本基于视频检索、时间活动固定和视频描述，作为评估标准。此外，我们还证明了我们的方法无需使用任何标注数据，可以用于传统的视觉下游任务，如手术工具、阶段和 triplet 识别。代码将在https://github.com/CAMMA-public/SurgVLP 上公开。
</details></li>
</ul>
<hr>
<h2 id="Reachability-Poorman-Discrete-Bidding-Games"><a href="#Reachability-Poorman-Discrete-Bidding-Games" class="headerlink" title="Reachability Poorman Discrete-Bidding Games"></a>Reachability Poorman Discrete-Bidding Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15218">http://arxiv.org/abs/2307.15218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guy Avni, Tobias Meggendorfer, Suman Sadhukhan, Josef Tkadlec, Đorđe Žikelić</li>
<li>for: 本研究是关于“拍卖游戏”（bidding games），特别是在图格上进行的两个玩家零点游戏。</li>
<li>methods: 本研究使用“贫人精确拍卖”（poorman discrete-bidding）机制，其中竞拍奖金是限制的，高得分玩家将奖金支付给银行。</li>
<li>results: 研究发现，在图DAGs中，贫人预算的阈值可以在某些情况下提供误差 bounds，并且具有周期性。在特定情况下，我们还发现了关闭式解决方案。我们还实现了一种算法来找到阈值预算。<details>
<summary>Abstract</summary>
We consider {\em bidding games}, a class of two-player zero-sum {\em graph games}. The game proceeds as follows. Both players have bounded budgets. A token is placed on a vertex of a graph, in each turn the players simultaneously submit bids, and the higher bidder moves the token, where we break bidding ties in favor of Player 1. Player 1 wins the game iff the token visits a designated target vertex. We consider, for the first time, {\em poorman discrete-bidding} in which the granularity of the bids is restricted and the higher bid is paid to the bank. Previous work either did not impose granularity restrictions or considered {\em Richman} bidding (bids are paid to the opponent). While the latter mechanisms are technically more accessible, the former is more appealing from a practical standpoint. Our study focuses on {\em threshold budgets}, which is the necessary and sufficient initial budget required for Player 1 to ensure winning against a given Player 2 budget. We first show existence of thresholds. In DAGs, we show that threshold budgets can be approximated with error bounds by thresholds under continuous-bidding and that they exhibit a periodic behavior. We identify closed-form solutions in special cases. We implement and experiment with an algorithm to find threshold budgets.
</details>
<details>
<summary>摘要</summary>
我们考虑{\em 拍卖游戏}，一种两player零余{\em 图形游戏}。游戏进行如下：两名玩家都有固定预算。一个 токен被放在一个图形上的顶点上，在每次转折时，两名玩家同时提交拍卖，高拍卖者可以移动 токен，并且在拍卖僵固时，将拍卖赢家决定为 Player 1。Player 1 赢得游戏，只要 токен到达一个指定的目标顶点。我们在这篇研究中，以前无法实现的{\em 穷人粗糙拍卖}，即拍卖时的价格粗糙限制，并且不同于前一些研究，不允许玩家在拍卖时付出费用。我们的研究集中在{\em 阈值预算}，即玩家必须具备的最低预算，以确保在对某名玩家的预算下获得胜利。我们首先证明存在阈值。在DAGs中，我们证明阈值预算可以准确地 aproximated ，并且它们展现了一个周期性的行为。我们还发现了特殊情况下的关闭式解。我们实现了一个算法，以找到阈值预算。
</details></li>
</ul>
<hr>
<h2 id="Open-Problems-and-Fundamental-Limitations-of-Reinforcement-Learning-from-Human-Feedback"><a href="#Open-Problems-and-Fundamental-Limitations-of-Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback"></a>Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15217">http://arxiv.org/abs/2307.15217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephen Casper, Xander Davies, Claudia Shi, Thomas Krendl Gilbert, Jérémy Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner, Pedro Freire, Tony Wang, Samuel Marks, Charbel-Raphaël Segerie, Micah Carroll, Andi Peng, Phillip Christoffersen, Mehul Damani, Stewart Slocum, Usman Anwar, Anand Siththaranjan, Max Nadeau, Eric J. Michaud, Jacob Pfau, Dmitrii Krasheninnikov, Xin Chen, Lauro Langosco, Peter Hase, Erdem Bıyık, Anca Dragan, David Krueger, Dorsa Sadigh, Dylan Hadfield-Menell</li>
<li>for: 这篇论文旨在探讨人工智能系统RLHF的问题和限制，以及如何更好地开发更安全的AI系统。</li>
<li>methods: 论文使用了RLHF和相关方法的评估和改进方法，以及如何在实践中使用这些方法。</li>
<li>results: 论文提出了RLHF和相关方法的开放问题和基本限制，并提出了优化和补偿这些方法的建议。<details>
<summary>Abstract</summary>
Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.
</details>
<details>
<summary>摘要</summary>
人工智能强化学习（RLHF）是一种训练人工智能系统以实现人类目标的技术。RLHF已经成为现代大语言模型（LLM）的训练方法的中心。尽管如此，RLHF的问题和限制得到了相对较少的公共研究。在这篇论文中，我们（1）survey了RLHF和相关方法的开放问题和基本限制;（2）介绍了RLHF在实践中的理解、改进和补充方法;（3）提出了审核和披露标准，以提高RLHF系统的社会监管。我们的工作强调RLHF的限制，并高调了在RLHF系统的开发中采取多方面的方法，以建立更安全的人工智能系统。
</details></li>
</ul>
<hr>
<h2 id="PromptStyler-Prompt-driven-Style-Generation-for-Source-free-Domain-Generalization"><a href="#PromptStyler-Prompt-driven-Style-Generation-for-Source-free-Domain-Generalization" class="headerlink" title="PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization"></a>PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15199">http://arxiv.org/abs/2307.15199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhyeong Cho, Gilhyun Nam, Sungyeon Kim, Hunmin Yang, Suha Kwak</li>
<li>for: 这个论文旨在提出一种不需要任何图像的源自由频谱适应方法，以便在视觉语言空间中生成多种风格特征。</li>
<li>methods: 该方法使用提示来生成多种风格特征，并使用可学习的风格词vector来 Represent these styles。为确保风格特征不会扭曲内容信息，该方法在视觉语言空间中强制风格-内容特征之间的相互靠近。</li>
<li>results: 该方法在PACS、VLCS、OfficeHome和DomainNet等四个 datasets上达到了状态对的最佳性能，而不需要任何图像进行训练。<details>
<summary>Abstract</summary>
In a joint vision-language space, a text feature (e.g., from "a photo of a dog") could effectively represent its relevant image features (e.g., from dog photos). Also, a recent study has demonstrated the cross-modal transferability phenomenon of this joint space. From these observations, we propose PromptStyler which simulates various distribution shifts in the joint space by synthesizing diverse styles via prompts without using any images to deal with source-free domain generalization. The proposed method learns to generate a variety of style features (from "a S* style of a") via learnable style word vectors for pseudo-words S*. To ensure that learned styles do not distort content information, we force style-content features (from "a S* style of a [class]") to be located nearby their corresponding content features (from "[class]") in the joint vision-language space. After learning style word vectors, we train a linear classifier using synthesized style-content features. PromptStyler achieves the state of the art on PACS, VLCS, OfficeHome and DomainNet, even though it does not require any images for training.
</details>
<details>
<summary>摘要</summary>
在共同视语空间中，文本特征（例如来自“狗照片”）可以有效表示相关的图像特征（例如狗照片中的特征）。此外，一项latest study发现了这个共同空间的各模态传递现象。基于这些观察，我们提出了PromptStyler，它在共同空间中通过提示 simulate various distribution shifts，无需使用任何图像进行源自无图像领域泛化。我们的方法学习生成多种风格特征（例如“S*风格”） via 可学习的风格词vecorts for pseudo-words S*。为确保学习的风格不会扭曲内容信息，我们强制风格-内容特征（例如“S*风格的[类别]”）在共同视语空间中与其相应的内容特征（例如“[类别]”）相 nearby。之后，我们使用生成的风格-内容特征进行线性分类。PromptStyler实现了在PACS、VLCS、OfficeHome和DomainNet上的state of the art，即使没有使用任何图像进行训练。
</details></li>
</ul>
<hr>
<h2 id="One-shot-Joint-Extraction-Registration-and-Segmentation-of-Neuroimaging-Data"><a href="#One-shot-Joint-Extraction-Registration-and-Segmentation-of-Neuroimaging-Data" class="headerlink" title="One-shot Joint Extraction, Registration and Segmentation of Neuroimaging Data"></a>One-shot Joint Extraction, Registration and Segmentation of Neuroimaging Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15198">http://arxiv.org/abs/2307.15198</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymous4545/jers">https://github.com/anonymous4545/jers</a></li>
<li>paper_authors: Yao Su, Zhentian Qian, Lei Ma, Lifang He, Xiangnan Kong</li>
<li>for: 本研究旨在开发一种基于单个标注图像（即Atlas）和几个未标注原始图像的一拟合批处理方法，以提高脑成像数据中的抽取、准确和分割等预处理步骤的效果。</li>
<li>methods: 本研究提出了一种统一的端到端框架，称为JERS，用于联合优化抽取、准确和分割任务。该框架使用了一组抽取、准确和分割模块，通过自我超级视觉来互相强化和促进Feedback。</li>
<li>results: 实验结果表明，我们提出的方法在抽取、准确和分割任务中表现出色，并且可以在实际 dataset 上减少人工干预和标注量。 codes 和数据可以在<a target="_blank" rel="noopener" href="https://github.com/Anonymous4545/JERS">https://github.com/Anonymous4545/JERS</a> 找到。<details>
<summary>Abstract</summary>
Brain extraction, registration and segmentation are indispensable preprocessing steps in neuroimaging studies. The aim is to extract the brain from raw imaging scans (i.e., extraction step), align it with a target brain image (i.e., registration step) and label the anatomical brain regions (i.e., segmentation step). Conventional studies typically focus on developing separate methods for the extraction, registration and segmentation tasks in a supervised setting. The performance of these methods is largely contingent on the quantity of training samples and the extent of visual inspections carried out by experts for error correction. Nevertheless, collecting voxel-level labels and performing manual quality control on high-dimensional neuroimages (e.g., 3D MRI) are expensive and time-consuming in many medical studies. In this paper, we study the problem of one-shot joint extraction, registration and segmentation in neuroimaging data, which exploits only one labeled template image (a.k.a. atlas) and a few unlabeled raw images for training. We propose a unified end-to-end framework, called JERS, to jointly optimize the extraction, registration and segmentation tasks, allowing feedback among them. Specifically, we use a group of extraction, registration and segmentation modules to learn the extraction mask, transformation and segmentation mask, where modules are interconnected and mutually reinforced by self-supervision. Empirical results on real-world datasets demonstrate that our proposed method performs exceptionally in the extraction, registration and segmentation tasks. Our code and data can be found at https://github.com/Anonymous4545/JERS
</details>
<details>
<summary>摘要</summary>
脑部提取、注册和分割是 neuroscience 研究中不可或缺的前processing 步骤。目的是从 raw 成像扫描中提取脑部（i.e., 提取步骤），将其与目标脑部图像（i.e., 注册步骤）进行对接，并将脑部区域标注为不同的 анатомические区域（i.e., 分割步骤）。传统的研究通常会对提取、注册和分割任务进行分别的开发，并在超级vised Setting中进行训练。然而，收集 voxel-level 标签和进行手动质量控制高维度 neuroscience 成像数据（例如 3D MRI）是许多医学研究中的昂贵和时间consuming。在这篇论文中，我们研究了一种一遍性的脑部提取、注册和分割方法，该方法只需要一个标注图像（即 atlas）和一些 raw 成像数据进行训练。我们提出了一个统一的端到端框架，称之为 JERS，以同时优化提取、注册和分割任务，并允许Feedback among them。具体来说，我们使用一组提取、注册和分割模块，通过自我监督来学习提取 маMask，变换和分割 mask，这些模块之间存在相互之间的连接和互相强化。我们在实际数据上进行了实验，结果表明我们的提案方法在提取、注册和分割任务中表现出色。我们的代码和数据可以在 https://github.com/Anonymous4545/JERS 找到。
</details></li>
</ul>
<hr>
<h2 id="Learning-in-Repeated-Multi-Unit-Pay-As-Bid-Auctions"><a href="#Learning-in-Repeated-Multi-Unit-Pay-As-Bid-Auctions" class="headerlink" title="Learning in Repeated Multi-Unit Pay-As-Bid Auctions"></a>Learning in Repeated Multi-Unit Pay-As-Bid Auctions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15193">http://arxiv.org/abs/2307.15193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rigel Galgana, Negin Golrezaei</li>
<li>For: The paper is written for learning how to bid in repeated multi-unit pay-as-bid auctions, with the goal of maximizing revenue.* Methods: The paper uses dynamic programming and online learning algorithms with polynomial time and space complexity under full information and bandit feedback settings.* Results: The paper achieves an upper bound on regret of $O(M\sqrt{T\log |\mathcal{B}|})$ and $O(M\sqrt{|\mathcal{B}|T\log |\mathcal{B}|})$ respectively, and demonstrates through numerical results that the resulting market dynamics converge to a welfare maximizing equilibrium where bidders submit uniform bids. Additionally, the paper shows that the pay-as-bid auction consistently generates significantly higher revenue compared to its popular alternative, the uniform price auction.Here is the same information in Simplified Chinese:* For: 这篇论文是为了学习在重复的多个单位付款为投标的拍卖中，以最大化收益为目的。* Methods: 论文使用动态规划和在线学习算法，具有对数时间和空间复杂度的优化。* Results: 论文实现了对 regret 的Upper bound，并通过数值实验表明，市场动态 converge 到一个最大化利益的均衡点，投标者提交均匀投标。此外，论文还表明，付款拍卖可以与通常的固定价格拍卖相比，一直高得多。<details>
<summary>Abstract</summary>
Motivated by Carbon Emissions Trading Schemes, Treasury Auctions, and Procurement Auctions, which all involve the auctioning of homogeneous multiple units, we consider the problem of learning how to bid in repeated multi-unit pay-as-bid auctions. In each of these auctions, a large number of (identical) items are to be allocated to the largest submitted bids, where the price of each of the winning bids is equal to the bid itself. The problem of learning how to bid in pay-as-bid auctions is challenging due to the combinatorial nature of the action space. We overcome this challenge by focusing on the offline setting, where the bidder optimizes their vector of bids while only having access to the past submitted bids by other bidders. We show that the optimal solution to the offline problem can be obtained using a polynomial time dynamic programming (DP) scheme. We leverage the structure of the DP scheme to design online learning algorithms with polynomial time and space complexity under full information and bandit feedback settings. We achieve an upper bound on regret of $O(M\sqrt{T\log |\mathcal{B}|})$ and $O(M\sqrt{|\mathcal{B}|T\log |\mathcal{B}|})$ respectively, where $M$ is the number of units demanded by the bidder, $T$ is the total number of auctions, and $|\mathcal{B}|$ is the size of the discretized bid space. We accompany these results with a regret lower bound, which match the linear dependency in $M$. Our numerical results suggest that when all agents behave according to our proposed no regret learning algorithms, the resulting market dynamics mainly converge to a welfare maximizing equilibrium where bidders submit uniform bids. Lastly, our experiments demonstrate that the pay-as-bid auction consistently generates significantly higher revenue compared to its popular alternative, the uniform price auction.
</details>
<details>
<summary>摘要</summary>
受到碳排放交易制度、储蓄拍卖和采购拍卖的启发，我们考虑了在重复的多单位付出拍卖中学习投标的问题。在这些拍卖中，大量相同的物品需要分配给最大的提交投标价格，其中每个赢得投标价格都等于投标价格本身。投标在付出拍卖中的问题具有 combinatorial 性，这使得问题更加挑战。我们通过关注线上设置，即bidder在过去其他投标者提交的投标中仅有访问 Vector of bids 的问题来解决这个挑战。我们表明了在线上问题的优化解决方案可以在 polynomial time 内完成。我们利用 DP 算法的结构来设计在线学习算法，其时间复杂度和空间复杂度均为 O(M\*sqrt(T\*log(|\mathcal{B}|)))，其中 M 是投标者需要的单位数量，T 是总的拍卖数量，并且 $|\mathcal{B}|$ 是投标空间中的精度。我们还提供了一个 regret 下界，它与 M 的线性相似。我们的数值结果表明，当所有代理人按照我们建议的无恐学习算法进行投标时，市场动态会主要向积极的均衡点转化，其中投标者会提交均匀投标。最后，我们的实验表明，付出拍卖routinely 生成较高的收益，相比于其受欢迎的替代方案 uniform price auction。
</details></li>
</ul>
<hr>
<h2 id="Med-Flamingo-a-Multimodal-Medical-Few-shot-Learner"><a href="#Med-Flamingo-a-Multimodal-Medical-Few-shot-Learner" class="headerlink" title="Med-Flamingo: a Multimodal Medical Few-shot Learner"></a>Med-Flamingo: a Multimodal Medical Few-shot Learner</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15189">http://arxiv.org/abs/2307.15189</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snap-stanford/med-flamingo">https://github.com/snap-stanford/med-flamingo</a></li>
<li>paper_authors: Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, Cyril Zakka, Yash Dalmia, Eduardo Pontes Reis, Pranav Rajpurkar, Jure Leskovec</li>
<li>for: 这个研究旨在提出一个适应医疗领域多Modal Few-shot Learning的模型，以满足医疗应用中资料稀少的问题。</li>
<li>methods: 本研究基于OpenFlamingo-9B，继续进行预训练，使用医疗图像和文本数据库，并实现了几个医疗问题的解释。</li>
<li>results: 研究结果显示，Med-Flamingo可以在几个医疗问题上表现出优秀的生成能力，并且可以提供解释，具体来说是20%的提升在医生评价中。此外，本研究首次进行了人类评价，并发现Med-Flamingo可以在不同的医疗问题上提供更好的解释。<details>
<summary>Abstract</summary>
Medicine, by its nature, is a multifaceted domain that requires the synthesis of information across various modalities. Medical generative vision-language models (VLMs) make a first step in this direction and promise many exciting clinical applications. However, existing models typically have to be fine-tuned on sizeable down-stream datasets, which poses a significant limitation as in many medical applications data is scarce, necessitating models that are capable of learning from few examples in real-time. Here we propose Med-Flamingo, a multimodal few-shot learner adapted to the medical domain. Based on OpenFlamingo-9B, we continue pre-training on paired and interleaved medical image-text data from publications and textbooks. Med-Flamingo unlocks few-shot generative medical visual question answering (VQA) abilities, which we evaluate on several datasets including a novel challenging open-ended VQA dataset of visual USMLE-style problems. Furthermore, we conduct the first human evaluation for generative medical VQA where physicians review the problems and blinded generations in an interactive app. Med-Flamingo improves performance in generative medical VQA by up to 20\% in clinician's rating and firstly enables multimodal medical few-shot adaptations, such as rationale generation. We release our model, code, and evaluation app under https://github.com/snap-stanford/med-flamingo.
</details>
<details>
<summary>摘要</summary>
医学是一个多方面的领域，需要将多种模式的信息集成起来。医学生成视语模型（VLM）可以作为第一步，并且承诺了许多临床应用。然而，现有模型通常需要在大量下游数据集上练习，这会限制其在医学应用中的使用，因为在许多医学应用中数据是稀缺的，需要能够从少量示例中学习。在这里，我们提出了医学鹭鸟（Med-Flamingo），一种适应医学领域的多Modal几个shot学习者。基于OpenFlamingo-9B，我们继续预训练在医学图像和文本数据集上，并且在医学图像和文本数据集上进行了交叉和混合预训练。Med-Flamingo实现了几个shot的生成医学视觉问答（VQA）能力，我们评估了这些能力在多个数据集上，包括一个新的开放式VQA数据集，这些数据集包括视频USMLE风格问题。此外，我们进行了第一次的人类评估 для生成医学VQA， Physicians review了问题和潜在的生成，并在交互应用中进行了评估。Med-Flamingo提高了生成医学VQA的性能，提高了临床评估员的评分，并且首次实现了多Modal医学几个shot适应。我们将我们的模型、代码和评估应用发布在https://github.com/snap-stanford/med-flamingo。
</details></li>
</ul>
<hr>
<h2 id="Rotation-Invariant-Random-Features-Provide-a-Strong-Baseline-for-Machine-Learning-on-3D-Point-Clouds"><a href="#Rotation-Invariant-Random-Features-Provide-a-Strong-Baseline-for-Machine-Learning-on-3D-Point-Clouds" class="headerlink" title="Rotation-Invariant Random Features Provide a Strong Baseline for Machine Learning on 3D Point Clouds"></a>Rotation-Invariant Random Features Provide a Strong Baseline for Machine Learning on 3D Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06271">http://arxiv.org/abs/2308.06271</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meliao/rotation-invariant-random-features">https://github.com/meliao/rotation-invariant-random-features</a></li>
<li>paper_authors: Owen Melia, Eric Jonas, Rebecca Willett</li>
<li>for: 这个论文的目的是研究三维点云数据上的征要学习方法，以实现具有旋转对称性的函数学习。</li>
<li>methods: 这个论文使用了随机特征方法，并对其进行了三维旋转对称性的扩展，以便快速评估点云数据上的函数。</li>
<li>results: 实验表明，这个方法可以与通用的旋转不变深度神经网络相比或超越其性能，并且具有许多任务的通用性和快速评估特点。<details>
<summary>Abstract</summary>
Rotational invariance is a popular inductive bias used by many fields in machine learning, such as computer vision and machine learning for quantum chemistry. Rotation-invariant machine learning methods set the state of the art for many tasks, including molecular property prediction and 3D shape classification. These methods generally either rely on task-specific rotation-invariant features, or they use general-purpose deep neural networks which are complicated to design and train. However, it is unclear whether the success of these methods is primarily due to the rotation invariance or the deep neural networks. To address this question, we suggest a simple and general-purpose method for learning rotation-invariant functions of three-dimensional point cloud data using a random features approach. Specifically, we extend the random features method of Rahimi & Recht 2007 by deriving a version that is invariant to three-dimensional rotations and showing that it is fast to evaluate on point cloud data. We show through experiments that our method matches or outperforms the performance of general-purpose rotation-invariant neural networks on standard molecular property prediction benchmark datasets QM7 and QM9. We also show that our method is general-purpose and provides a rotation-invariant baseline on the ModelNet40 shape classification task. Finally, we show that our method has an order of magnitude smaller prediction latency than competing kernel methods.
</details>
<details>
<summary>摘要</summary>
rotational invariance 是机器学习中广泛使用的一种印度预测，如计算机视觉和量子化学机器学习。无需旋转的机器学习方法已经设置了许多任务的州OF-the-art，包括分子性质预测和3D形状分类。这些方法通常 Either rely on task-specific rotation-invariant features or use general-purpose deep neural networks, which are complicated to design and train. However, it is unclear whether the success of these methods is primarily due to the rotation invariance or the deep neural networks. To address this question, we propose a simple and general-purpose method for learning rotation-invariant functions of three-dimensional point cloud data using a random features approach. Specifically, we extend the random features method of Rahimi & Recht 2007 by deriving a version that is invariant to three-dimensional rotations and showing that it is fast to evaluate on point cloud data. We show through experiments that our method matches or outperforms the performance of general-purpose rotation-invariant neural networks on standard molecular property prediction benchmark datasets QM7 and QM9. We also show that our method is general-purpose and provides a rotation-invariant baseline on the ModelNet40 shape classification task. Finally, we show that our method has an order of magnitude smaller prediction latency than competing kernel methods.
</details></li>
</ul>
<hr>
<h2 id="RCT-Rejection-Sampling-for-Causal-Estimation-Evaluation"><a href="#RCT-Rejection-Sampling-for-Causal-Estimation-Evaluation" class="headerlink" title="RCT Rejection Sampling for Causal Estimation Evaluation"></a>RCT Rejection Sampling for Causal Estimation Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15176">http://arxiv.org/abs/2307.15176</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kakeith/rct_rejection_sampling">https://github.com/kakeith/rct_rejection_sampling</a></li>
<li>paper_authors: Katherine A. Keith, Sergey Feldman, David Jurgens, Jonathan Bragg, Rohit Bhattacharya</li>
<li>for: 这个论文旨在提高对 observational data 中 causal effect 的估计，并解决高维 covariate 的干扰问题。</li>
<li>methods: 该论文提出了一种基于机器学习方法的 adjustment 方法，用于解决 causal estimation 中的干扰问题。 authors 还提出了一种新的抽样算法，称为 RCT rejection sampling，并提供了理论保证， garanting causal identification 在 observational data 中。</li>
<li>results: 通过使用 simulate data， authors 证明了其算法在 oracle estimators 上的低偏度性。 In addition, authors 还 highlighted 一些 finite data 考虑因素，以便在实际应用中使用 RCT rejection sampling。 as a proof of concept, authors 实现了一个 example evaluation pipeline, 并详细介绍了这些 finite data 考虑因素。<details>
<summary>Abstract</summary>
Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates -- such as text data, genomics, or the behavioral social sciences -- researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm indeed results in low bias when oracle estimators are evaluated on the confounded samples, which is not always the case for a previously proposed algorithm. In addition to this identification result, we highlight several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets. As a proof of concept, we implement an example evaluation pipeline and walk through these finite data considerations with a novel, real-world RCT -- which we release publicly -- consisting of approximately 70k observations and text data as high-dimensional covariates. Together, these contributions build towards a broader agenda of improved empirical evaluation for causal estimation.
</details>
<details>
<summary>摘要</summary>
干扰是观察数据中 causal 效应的重要障碍。在高维 covariate 的设置下（如文本数据、 genomics 或行为社会科学），研究人员已经提出了适应机器学习方法以便 causal 估计的调整方法。然而，实际评估这些调整方法的困难和有限。在这项工作中，我们基于一种有前途的评估策略，即使用 randomized controlled trials (RCTs) 的平均 causal 效应作为真实参照值，并提出了一种新的抽样算法，称为 RCT 拒绝抽样。我们提供了理论保证，表明在观察数据中， causal 标识是可行的，从而允许有效地与参照值 RCT 进行比较。使用 sintetic 数据，我们证明了我们的算法在 oracle 估计器中的低偏误。此外，我们还提出了一些实际评估设计师应该考虑的有限数据问题。作为证明，我们实现了一个示例评估管道，并详细介绍了这些有限数据问题。作为证明，我们发布了一个新的、实际存在的 RCT，包含约 70k 个观察和文本数据作为高维 covariate。总的来说，这些贡献共同推动了观察数据中 causal 估计的有效评估。
</details></li>
</ul>
<hr>
<h2 id="VISU-at-WASSA-2023-Shared-Task-Detecting-Emotions-in-Reaction-to-News-Stories-Leveraging-BERT-and-Stacked-Embeddings"><a href="#VISU-at-WASSA-2023-Shared-Task-Detecting-Emotions-in-Reaction-to-News-Stories-Leveraging-BERT-and-Stacked-Embeddings" class="headerlink" title="VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings"></a>VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15164">http://arxiv.org/abs/2307.15164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vivek Kumar, Sushmita Singh, Prayag Tiwari</li>
<li>for: 这篇论文是为了探讨情感识别FROM essays written in reaction to news articles的问题而写的。</li>
<li>methods: 这篇论文使用了深度学习（DL）模型，将词嵌入表示与特化的预处理策略相结合，以捕捉表达的情感细节。实验使用了静止和上下文嵌入（个体和堆叠），以及BIaLSTM和Transformer基本模型。</li>
<li>results: 这篇论文在WASSA 2023 Shared Task（3）中的情感识别任务中获得了rank十的成绩，即Macro F1-Score为0.2717，证明了我们实施的方法在小型和不均衡数据集中的效果。<details>
<summary>Abstract</summary>
Our system, VISU, participated in the WASSA 2023 Shared Task (3) of Emotion Classification from essays written in reaction to news articles. Emotion detection from complex dialogues is challenging and often requires context/domain understanding. Therefore in this research, we have focused on developing deep learning (DL) models using the combination of word embedding representations with tailored prepossessing strategies to capture the nuances of emotions expressed. Our experiments used static and contextual embeddings (individual and stacked) with Bidirectional Long short-term memory (BiLSTM) and Transformer based models. We occupied rank tenth in the emotion detection task by scoring a Macro F1-Score of 0.2717, validating the efficacy of our implemented approaches for small and imbalanced datasets with mixed categories of target emotions.
</details>
<details>
<summary>摘要</summary>
我们的系统，VISU，参加了2023年WASSA分享任务（3）的情感分类从新闻文章中的反应文章。情感检测从复杂对话中是挑战，因此在这项研究中，我们将重点发展深度学习（DL）模型，使用词嵌入表示和特制预处理策略来捕捉表达出的情感含义。我们的实验使用静态和上下文嵌入（个体和堆叠）以及双向长短Memory（BiLSTM）和转换器基于模型。我们在情感检测任务中占据了排名第十的位置，取得了macro F1分数0.2717，证明我们实施的方法对小数据集和混合类目标情感任务具有效果。
</details></li>
</ul>
<hr>
<h2 id="Distilled-Feature-Fields-Enable-Few-Shot-Language-Guided-Manipulation"><a href="#Distilled-Feature-Fields-Enable-Few-Shot-Language-Guided-Manipulation" class="headerlink" title="Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation"></a>Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07931">http://arxiv.org/abs/2308.07931</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Shen, Ge Yang, Alan Yu, Jansen Wong, Leslie Pack Kaelbling, Phillip Isola</li>
<li>for:  bridges the 2D-to-3D gap for robotic manipulation</li>
<li>methods:  leverages distilled feature fields to combine accurate 3D geometry with rich semantics from 2D foundation models</li>
<li>results:  achieves in-the-wild generalization to unseen objects using few-shot learning method for 6-DOF grasping and placing<details>
<summary>Abstract</summary>
Self-supervised and language-supervised image models contain rich knowledge of the world that is important for generalization. Many robotic tasks, however, require a detailed understanding of 3D geometry, which is often lacking in 2D image features. This work bridges this 2D-to-3D gap for robotic manipulation by leveraging distilled feature fields to combine accurate 3D geometry with rich semantics from 2D foundation models. We present a few-shot learning method for 6-DOF grasping and placing that harnesses these strong spatial and semantic priors to achieve in-the-wild generalization to unseen objects. Using features distilled from a vision-language model, CLIP, we present a way to designate novel objects for manipulation via free-text natural language, and demonstrate its ability to generalize to unseen expressions and novel categories of objects.
</details>
<details>
<summary>摘要</summary>
自我监督和语言监督的图像模型含有重要的世界知识，这对总化非常重要。然而，许多 робоaxi tasks需要精准的三维几何理解，而图像特征通常缺乏这种知识。这个工作将两个维度之间的 gap  bridged ，使用精炼的特征场来结合准确的三维几何和丰富的语言特征，以实现在野外进行6个自由度抓取和放置的几何学掌握。使用从视觉语言模型CLIP中提取出的特征，我们提出了一种通过自然语言文本来指定新的物体 для操作的方法，并证明其能够通过未经见过的表达和新类别的物体进行总化。
</details></li>
</ul>
<hr>
<h2 id="Matching-Patients-to-Clinical-Trials-with-Large-Language-Models"><a href="#Matching-Patients-to-Clinical-Trials-with-Large-Language-Models" class="headerlink" title="Matching Patients to Clinical Trials with Large Language Models"></a>Matching Patients to Clinical Trials with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15051">http://arxiv.org/abs/2307.15051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiao Jin, Zifeng Wang, Charalampos S. Floudas, Jimeng Sun, Zhiyong Lu</li>
<li>For: The paper aims to assist individual patients and referral physicians in identifying suitable clinical trials from an extensive selection, using large language models (LLMs) to predict criterion-level eligibility with detailed explanations.* Methods: The paper introduces TrialGPT, a novel architecture that employs LLMs to predict criterion-level eligibility with detailed explanations, which are then aggregated for ranking and excluding candidate clinical trials based on free-text patient notes.* Results: The experimental results demonstrate that TrialGPT achieves high criterion-level prediction accuracy with faithful explanations, and the aggregated trial-level TrialGPT scores are highly correlated with expert eligibility annotations. The scores are also effective in ranking clinical trials and excluding ineligible candidates, but the paper acknowledges that current LLMs still make some mistakes due to limited medical knowledge and domain-specific context understanding.<details>
<summary>Abstract</summary>
Clinical trials are vital in advancing drug development and evidence-based medicine, but their success is often hindered by challenges in patient recruitment. In this work, we investigate the potential of large language models (LLMs) to assist individual patients and referral physicians in identifying suitable clinical trials from an extensive selection. Specifically, we introduce TrialGPT, a novel architecture employing LLMs to predict criterion-level eligibility with detailed explanations, which are then aggregated for ranking and excluding candidate clinical trials based on free-text patient notes. We evaluate TrialGPT on three publicly available cohorts of 184 patients and 18,238 annotated clinical trials. The experimental results demonstrate several key findings: First, TrialGPT achieves high criterion-level prediction accuracy with faithful explanations. Second, the aggregated trial-level TrialGPT scores are highly correlated with expert eligibility annotations. Third, these scores prove effective in ranking clinical trials and exclude ineligible candidates. Our error analysis suggests that current LLMs still make some mistakes due to limited medical knowledge and domain-specific context understanding. Nonetheless, we believe the explanatory capabilities of LLMs are highly valuable. Future research is warranted on how such AI assistants can be integrated into the routine trial matching workflow in real-world settings to improve its efficiency.
</details>
<details>
<summary>摘要</summary>
临床试验是药物开发和基于证据的医学发展的关键，但患者招募困难往往阻碍其成功。在这项工作中，我们调查了大语言模型（LLM）在帮助个人患者和推荐医生选择适合的临床试验中的潜在作用。我们介绍了一种新的建筑方案，称为TrialGPT，它使用LLM来预测临床试验权威性的详细解释，然后将这些解释聚合为排名和排除不适的临床试验。我们在三个公共可用的群组中进行了184名患者和18238个临床试验的评估。实验结果表明了以下几点：首先，TrialGPT在权威性预测中达到了高精度和详细的解释。其次，聚合的临床试验级TrialGPT分数与专家证明的可参与性注释高度相关。最后，这些分数能够有效地排名临床试验和排除不适的参与者。我们的错误分析表明，当前的LLM仍然由于医学知识和域pecific上下文理解有一些错误。然而，我们认为LLM的解释能力很值得。未来的研究应该关注如何在实际试验匹配过程中集成这些AI助手，以提高其效率。
</details></li>
</ul>
<hr>
<h2 id="Universal-and-Transferable-Adversarial-Attacks-on-Aligned-Language-Models"><a href="#Universal-and-Transferable-Adversarial-Attacks-on-Aligned-Language-Models" class="headerlink" title="Universal and Transferable Adversarial Attacks on Aligned Language Models"></a>Universal and Transferable Adversarial Attacks on Aligned Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15043">http://arxiv.org/abs/2307.15043</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/llm-attacks/llm-attacks">https://github.com/llm-attacks/llm-attacks</a></li>
<li>paper_authors: Andy Zou, Zifan Wang, J. Zico Kolter, Matt Fredrikson<br>for: 这个论文的目的是提出一种简单而有效的攻击方法，使得已经被调整的语言模型产生不适的行为。methods: 这个论文使用的方法包括批处理和梯度下降搜索技术，自动生成攻击 suffix。results: 这个论文的实验结果表明，使用这种攻击方法可以让已经被调整的语言模型产生不适的行为，并且这种攻击方法可以在黑盒模型上也有效。<details>
<summary>Abstract</summary>
Because "out-of-the-box" large language models are capable of generating a great deal of objectionable content, recent work has focused on aligning these models in an attempt to prevent undesirable generation. While there has been some success at circumventing these measures -- so-called "jailbreaks" against LLMs -- these attacks have required significant human ingenuity and are brittle in practice. In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors. Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer). However, instead of relying on manual engineering, our approach automatically produces these adversarial suffixes by a combination of greedy and gradient-based search techniques, and also improves over past automatic prompt generation methods.   Surprisingly, we find that the adversarial prompts generated by our approach are quite transferable, including to black-box, publicly released LLMs. Specifically, we train an adversarial attack suffix on multiple prompts (i.e., queries asking for many different types of objectionable content), as well as multiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting attack suffix is able to induce objectionable content in the public interfaces to ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat, Pythia, Falcon, and others. In total, this work significantly advances the state-of-the-art in adversarial attacks against aligned language models, raising important questions about how such systems can be prevented from producing objectionable information. Code is available at github.com/llm-attacks/llm-attacks.
</details>
<details>
<summary>摘要</summary>
因为"out-of-the-box"大语言模型可以生成很多不适的内容，因此最近的工作都在尝试对这些模型进行对齐，以避免不适的生成。虽然有一些成功的尝试（即“监狱”对LLMs），但这些攻击需要人类的创造力，并且在实践中较脆弱。在这篇论文中，我们提出了一种简单而有效的攻击方法，使得对齐的语言模型生成不适的行为。具体来说，我们的方法找到一个适用于各种查询的 suffix，以使模型生成有利的答案（而不是拒绝回答）。而不是人工工程，我们的方法通过滥览和梯度基于搜索技术自动生成这些反对性词组，并且超过了过去的自动提示生成方法。 surprisingly，我们发现了这些反对性词组在黑盒、公共释放的LLMs中也是可转移的。我们在多个提问（即请求多种不适的内容）和多个模型（我们的案例是Vicuna-7B和13B）上训练了攻击 suffix，并且在ChatGPT、Bard和Claude等公共接口上也能够引起不适的内容。总的来说，这项工作提高了对齐语言模型的反对攻击的状态艺术，提出了如何避免这些系统生成不适的信息的问题。代码可以在github.com/llm-attacks/llm-attacks中找到。
</details></li>
</ul>
<hr>
<h2 id="AI-Literature-Review-Suite"><a href="#AI-Literature-Review-Suite" class="headerlink" title="AI Literature Review Suite"></a>AI Literature Review Suite</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02443">http://arxiv.org/abs/2308.02443</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/datovar4/ai_literature_review_suite">https://github.com/datovar4/ai_literature_review_suite</a></li>
<li>paper_authors: David A. Tovar</li>
<li>for:  automate and optimize the process of literature review in academic and industrial research</li>
<li>methods:  leverages open access science, large language models (LLMs), natural language processing, semantic search queries, text embeddings, and summarization</li>
<li>results:  provides a comprehensive literature review, enables searching, downloading, and organizing of PDF files, and extracts content from articles with succinct summaries<details>
<summary>Abstract</summary>
The process of conducting literature reviews is often time-consuming and labor-intensive. To streamline this process, I present an AI Literature Review Suite that integrates several functionalities to provide a comprehensive literature review. This tool leverages the power of open access science, large language models (LLMs) and natural language processing to enable the searching, downloading, and organizing of PDF files, as well as extracting content from articles. Semantic search queries are used for data retrieval, while text embeddings and summarization using LLMs present succinct literature reviews. Interaction with PDFs is enhanced through a user-friendly graphical user interface (GUI). The suite also features integrated programs for bibliographic organization, interaction and query, and literature review summaries. This tool presents a robust solution to automate and optimize the process of literature review in academic and industrial research.
</details>
<details>
<summary>摘要</summary>
Literature reviews 通常是时间和劳动密集的过程。为了减少这个过程的复杂性，我们提出了一个基于人工智能的文献评估套件（AI Literature Review Suite），该套件集成了多种功能以提供全面的文献评估。这个工具利用了开放科学、大语言模型（LLM）和自然语言处理技术来实现PDF文档的搜索、下载和组织，以及文章中的内容抽取。使用semantic search queries进行数据检索，并使用文本嵌入和摘要使用LLM来提供简洁的文献评估。用户可以通过用户友好的图形用户界面（GUI）进行交互，并且套件还包括了一个集成的bibliographic组织、交互和查询程序，以及文献评估摘要。这个工具为学术和工业研究中的文献评估带来了一个强大的自动化和优化解决方案。
</details></li>
</ul>
<hr>
<h2 id="SuperCLUE-A-Comprehensive-Chinese-Large-Language-Model-Benchmark"><a href="#SuperCLUE-A-Comprehensive-Chinese-Large-Language-Model-Benchmark" class="headerlink" title="SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark"></a>SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15020">http://arxiv.org/abs/2307.15020</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang Xu, Anqi Li, Lei Zhu, Hang Xue, Changtai Zhu, Kangkang Zhao, Haonan He, Xuanwei Zhang, Qiyue Kang, Zhenzhong Lan</li>
<li>for: 这 paper 的目的是为了评估大语言模型在实际应用中的性能，而不是仅仅是测试其精度。</li>
<li>methods: 这 paper 使用了一个全面的中文测试套件 SuperCLUE，包括 CArena、OPEN 和 CLOSE 三个子任务。</li>
<li>results: 这 paper 的研究结果表明，关闭式问题的答案准确率不足以反映人类的偏好，但是它们可以补充对话来预测实际用户的偏好。此外，GPT-4 可以自动评估中文语言模型在开放式问题上的人类偏好。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown the potential to be integrated into human daily lives. Therefore, user preference is the most critical criterion for assessing LLMs' performance in real-world scenarios. However, existing benchmarks mainly focus on measuring models' accuracy using multi-choice questions, which limits the understanding of their capabilities in real applications. We fill this gap by proposing a comprehensive Chinese benchmark SuperCLUE, named after another popular Chinese LLM benchmark CLUE. SuperCLUE encompasses three sub-tasks: actual users' queries and ratings derived from an LLM battle platform (CArena), open-ended questions with single and multiple-turn dialogues (OPEN), and closed-ended questions with the same stems as open-ended single-turn ones (CLOSE). Our study shows that accuracy on closed-ended questions is insufficient to reflect human preferences achieved on open-ended ones. At the same time, they can complement each other to predict actual user preferences. We also demonstrate that GPT-4 is a reliable judge to automatically evaluate human preferences on open-ended questions in a Chinese context. Our benchmark will be released at https://www.CLUEbenchmarks.com
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经展示了在人类日常生活中的潜在应用前景。因此，用户偏好成为评估LLM在实际应用场景中的表现的关键因素。然而，现有的标准约束主要是通过多选问题来衡量模型的准确率，这限制了我们对其在实际应用中的能力的理解。我们填补了这一漏洞，提出了一个全面的中文标准准备SuperCLUE，名称来自另一个流行的中文LLM标准准备CLUE。SuperCLUE包括三个子任务：实际用户的问题和评分来自LLM战场平台（CArena），开放式问题（OPEN）和关闭式问题（CLOSE）。我们的研究显示，关闭式问题的准确率不充分反映人类偏好，而且可以补充each other来预测实际用户的偏好。此外，我们还证明了GPT-4可以自动评估中文上开放式问题的人类偏好。我们的标准将在https://www.CLUEbenchmarks.com上发布。
</details></li>
</ul>
<hr>
<h2 id="How-Good-is-Google-Bard’s-Visual-Understanding-An-Empirical-Study-on-Open-Challenges"><a href="#How-Good-is-Google-Bard’s-Visual-Understanding-An-Empirical-Study-on-Open-Challenges" class="headerlink" title="How Good is Google Bard’s Visual Understanding? An Empirical Study on Open Challenges"></a>How Good is Google Bard’s Visual Understanding? An Empirical Study on Open Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15016">http://arxiv.org/abs/2307.15016</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/htqin/googlebard-visunderstand">https://github.com/htqin/googlebard-visunderstand</a></li>
<li>paper_authors: Haotong Qin, Ge-Peng Ji, Salman Khan, Deng-Ping Fan, Fahad Shahbaz Khan, Luc Van Gool</li>
<li>for: This paper explores the ability of Google Bard to understand and interpret visual data (images) conditioned by text questions, with the goal of evaluating its performance in various task scenarios and identifying areas for improvement.</li>
<li>methods: The paper uses Google Bard to process text and image inputs and evaluate its performance in 15 diverse task scenarios, including regular, camouflaged, medical, under-water, and remote sensing data.</li>
<li>results: The primary finding of the study is that Bard struggles in vision scenarios, highlighting the significant gap in vision-based understanding that needs to be bridged in future developments. The study provides valuable insights for advancing future models and improving their capabilities in comprehending and interpreting fine-grained visual data.Here is the same information in Simplified Chinese:</li>
<li>for: 这个研究用Google Bard来处理文本和图像输入，以评估其在不同任务场景中的表现，并找到改进的方向。</li>
<li>methods: 这篇论文使用Google Bard处理文本和图像输入，并在15种多样化任务场景中评估其表现，包括常见、掩蔽、医疗、水下和Remote感知数据。</li>
<li>results: 研究发现，Bard在视觉场景中表现不佳，这显示了未来模型需要覆盖视觉理解的巨大差距。这项实验带来了价值的发现，可以帮助未来的模型在细致的视觉数据上增强其能力。<details>
<summary>Abstract</summary>
Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in the field of conversational AI. Notably, Bard has recently been updated to handle visual inputs alongside text prompts during conversations. Given Bard's impressive track record in handling textual inputs, we explore its capabilities in understanding and interpreting visual data (images) conditioned by text questions. This exploration holds the potential to unveil new insights and challenges for Bard and other forthcoming multi-modal Generative models, especially in addressing complex computer vision problems that demand accurate visual and language understanding. Specifically, in this study, we focus on 15 diverse task scenarios encompassing regular, camouflaged, medical, under-water and remote sensing data to comprehensively evaluate Bard's performance. Our primary finding indicates that Bard still struggles in these vision scenarios, highlighting the significant gap in vision-based understanding that needs to be bridged in future developments. We expect that this empirical study will prove valuable in advancing future models, leading to enhanced capabilities in comprehending and interpreting fine-grained visual data. Our project is released on https://github.com/htqin/GoogleBard-VisUnderstand
</details>
<details>
<summary>摘要</summary>
Google的Bard在协作AI领域已经成为OpenAI的ChatGPT的强有力竞争对手。特别是最近Bard更新以处理图像和文本提示的对话。由于Bard在文本输入方面的卓越表现，我们探索了它在理解和解释图像数据（图像）的能力。这种探索具有探索新的发现和挑战，特别是在解决复杂计算机视觉问题方面。在这项研究中，我们选择了15种多样化任务场景，包括常见、掩体、医疗、水下和远程感知数据，以全面评估Bard的性能。我们的主要发现表明Bard在视觉场景中仍然努力，反映了需要在未来发展中覆盖视觉基础知识的巨大差距。我们预计这项实验性研究会对未来模型的发展产生重要影响，导致它们在理解和解释细致的视觉数据方面增强其能力。我们的项目在https://github.com/htqin/GoogleBard-VisUnderstand上发布。
</details></li>
</ul>
<hr>
<h2 id="Improved-Neural-Radiance-Fields-Using-Pseudo-depth-and-Fusion"><a href="#Improved-Neural-Radiance-Fields-Using-Pseudo-depth-and-Fusion" class="headerlink" title="Improved Neural Radiance Fields Using Pseudo-depth and Fusion"></a>Improved Neural Radiance Fields Using Pseudo-depth and Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03772">http://arxiv.org/abs/2308.03772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingliang Li, Qiang Zhou, Chaohui Yu, Zhengda Lu, Jun Xiao, Zhibin Wang, Fan Wang</li>
<li>for: 本研究旨在提高Neural Radiance Fields（NeRF）模型的渲染精度和视角渲染能力，特别是在实际场景中存在多种大小对象&#x2F;结构的情况下。</li>
<li>methods: 我们提出了一种使用多尺度编码量表示 scene中对象的几何信息，并将其提供给NeRF模型。我们还提出了同时进行深度预测和场景重建，以使得构造的量表示更加准确。此外，我们还提出了基于深度导航的点云特征协同拼接，以提高点云特征的准确性。</li>
<li>results: 我们的方法在novel view synthesis和dense geometry modeling中表现出了superior的性能，无需Scene-specific优化。<details>
<summary>Abstract</summary>
Since the advent of Neural Radiance Fields, novel view synthesis has received tremendous attention. The existing approach for the generalization of radiance field reconstruction primarily constructs an encoding volume from nearby source images as additional inputs. However, these approaches cannot efficiently encode the geometric information of real scenes with various scale objects/structures. In this work, we propose constructing multi-scale encoding volumes and providing multi-scale geometry information to NeRF models. To make the constructed volumes as close as possible to the surfaces of objects in the scene and the rendered depth more accurate, we propose to perform depth prediction and radiance field reconstruction simultaneously. The predicted depth map will be used to supervise the rendered depth, narrow the depth range, and guide points sampling. Finally, the geometric information contained in point volume features may be inaccurate due to occlusion, lighting, etc. To this end, we propose enhancing the point volume feature from depth-guided neighbor feature fusion. Experiments demonstrate the superior performance of our method in both novel view synthesis and dense geometry modeling without per-scene optimization.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Thinker-Learning-to-Plan-and-Act"><a href="#Thinker-Learning-to-Plan-and-Act" class="headerlink" title="Thinker: Learning to Plan and Act"></a>Thinker: Learning to Plan and Act</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14993">http://arxiv.org/abs/2307.14993</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymous-scrl/thinker">https://github.com/anonymous-scrl/thinker</a></li>
<li>paper_authors: Stephen Chung, Ivan Anokhin, David Krueger</li>
<li>for: 这个论文的目的是开发一种新的推奖学习算法，帮助推奖学习代理人自主地使用学习到的世界模型进行规划。</li>
<li>methods: 这个算法使用了包装环境在世界模型中的方法，并提出了一些特定的模型交互动作，让代理人可以通过对世界模型进行规划，选择更好的行动。</li>
<li>results: 经验结果表明，这个算法在扮演游戏和Atari 2600测试中都达到了状态之 искусственный智能表现的最佳效果和竞争性表现。代理人训练后的视觉化表示它们已经学习了如何有效地规划使用世界模型选择更好的行动。<details>
<summary>Abstract</summary>
We propose the Thinker algorithm, a novel approach that enables reinforcement learning agents to autonomously interact with and utilize a learned world model. The Thinker algorithm wraps the environment with a world model and introduces new actions designed for interacting with the world model. These model-interaction actions enable agents to perform planning by proposing alternative plans to the world model before selecting a final action to execute in the environment. This approach eliminates the need for hand-crafted planning algorithms by enabling the agent to learn how to plan autonomously and allows for easy interpretation of the agent's plan with visualization. We demonstrate the algorithm's effectiveness through experimental results in the game of Sokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves state-of-the-art performance and competitive results, respectively. Visualizations of agents trained with the Thinker algorithm demonstrate that they have learned to plan effectively with the world model to select better actions. The algorithm's generality opens a new research direction on how a world model can be used in reinforcement learning and how planning can be seamlessly integrated into an agent's decision-making process.
</details>
<details>
<summary>摘要</summary>
我们提出了思考算法（Thinker algorithm），一种新的方法，让强化学习代理人能够自主地与学习的世界模型互动。思考算法将环境包装在世界模型中，并增加了特定 для与世界模型互动的动作。这些模型互动动作使代理人能够在世界模型中进行规划，提出不同的计划供世界模型评估，然后选择最佳的行动进行环境中执行。这种方法扩展了强化学习的可能性，并且让代理人能够自主地学习规划技巧，同时亦可以轻松地将其计划视觉化。我们透过实验结果在拓扑游戏和Atari 2600测试中证明了思考算法的有效性，并且在这两个测试中获得了竞争性的结果。代理人训练了思考算法后的视觉化结果表明，它们已经学会了从世界模型中选择更好的动作。这个算法的通用性开启了一个新的研究方向，即如何在强化学习中使用世界模型，以及如何将规划自透地整合到代理人的决策过程中。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Code-Co-Evolution-Using-Large-Language-Models"><a href="#Multilingual-Code-Co-Evolution-Using-Large-Language-Models" class="headerlink" title="Multilingual Code Co-Evolution Using Large Language Models"></a>Multilingual Code Co-Evolution Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14991">http://arxiv.org/abs/2307.14991</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiyang Zhang, Pengyu Nie, Junyi Jessy Li, Milos Gligoric</li>
<li>for: 本研究旨在解决跨编程语言代码更新的问题，通过大语言模型（LLMs）来实现代码更新。</li>
<li>methods: 本研究使用大语言模型（LLMs）来模型代码更新为编辑序列，并学习代码更新之间的相关性。</li>
<li>results: 对于6,613个对齐的代码更新样本，codeditor与状态之前的方法相比，得到了大幅度的提高。此外，codeditor与现有的生成型模型相结合，能够实现更高的性能。<details>
<summary>Abstract</summary>
Many software projects implement APIs and algorithms in multiple programming languages. Maintaining such projects is tiresome, as developers have to ensure that any change (e.g., a bug fix or a new feature) is being propagated, timely and without errors, to implementations in other programming languages. In the world of ever-changing software, using rule-based translation tools (i.e., transpilers) or machine learning models for translating code from one language to another provides limited value. Translating each time the entire codebase from one language to another is not the way developers work. In this paper, we target a novel task: translating code changes from one programming language to another using large language models (LLMs). We design and implement the first LLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models code changes as edit sequences and learns to correlate changes across programming languages. To evaluate Codeditor, we collect a corpus of 6,613 aligned code changes from 8 pairs of open-source software projects implementing similar functionalities in two programming languages (Java and C#). Results show that Codeditor outperforms the state-of-the-art approaches by a large margin on all commonly used automatic metrics. Our work also reveals that Codeditor is complementary to the existing generation-based models, and their combination ensures even greater performance.
</details>
<details>
<summary>摘要</summary>
许多软件项目会实现API和算法在多种编程语言中。维护这些项目是疲劳的，因为开发者必须确保任何更改（例如，bug fix或新功能）在其他编程语言中得到有效地传播，并且不会出现错误。在软件世界中，使用规则基于的翻译工具（例如，转换器）或机器学习模型来翻译代码从一种语言到另一种语言提供有限的价值。每次翻译整个代码库从一种语言到另一种语言都不是开发者的工作方式。在这篇论文中，我们target一个新任务：将代码更改从一种编程语言到另一种编程语言使用大语言模型（LLM）进行翻译。我们设计并实现了第一个LLM，名为Codeditor，以解决这个任务。Codeditor显式模型代码更改为编辑序列，并学习代码更改之间的相互关系。为了评估Codeditor，我们收集了6,613个对齐的代码更改从8对开源软件项目中，这些项目在两种编程语言（Java和C#）中实现了相同的功能。结果表明，Codeditor在所有常用的自动指标上都高于现有的状态艺术方法。我们的工作还发现，Codeditor与现有的生成基于模型相结合，可以确保更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Take-A-Photo-3D-to-2D-Generative-Pre-training-of-Point-Cloud-Models"><a href="#Take-A-Photo-3D-to-2D-Generative-Pre-training-of-Point-Cloud-Models" class="headerlink" title="Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models"></a>Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14971">http://arxiv.org/abs/2307.14971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangzy22/tap">https://github.com/wangzy22/tap</a></li>
<li>paper_authors: Ziyi Wang, Xumin Yu, Yongming Rao, Jie Zhou, Jiwen Lu</li>
<li>for: 提高3D视觉模型的性能</li>
<li>methods: 使用交叉注意机制生成视图图像作为预训练方案</li>
<li>results: 超过前一代预训练方法的表现，并且可以提高建筑型approaches的性能<details>
<summary>Abstract</summary>
With the overwhelming trend of mask image modeling led by MAE, generative pre-training has shown a remarkable potential to boost the performance of fundamental models in 2D vision. However, in 3D vision, the over-reliance on Transformer-based backbones and the unordered nature of point clouds have restricted the further development of generative pre-training. In this paper, we propose a novel 3D-to-2D generative pre-training method that is adaptable to any point cloud model. We propose to generate view images from different instructed poses via the cross-attention mechanism as the pre-training scheme. Generating view images has more precise supervision than its point cloud counterpart, thus assisting 3D backbones to have a finer comprehension of the geometrical structure and stereoscopic relations of the point cloud. Experimental results have proved the superiority of our proposed 3D-to-2D generative pre-training over previous pre-training methods. Our method is also effective in boosting the performance of architecture-oriented approaches, achieving state-of-the-art performance when fine-tuning on ScanObjectNN classification and ShapeNetPart segmentation tasks. Code is available at https://github.com/wangzy22/TAP.
</details>
<details>
<summary>摘要</summary>
在MAE领导的面孔图模型化潮流中，生成预训练显示了强大的可能性，以提高2D视觉基本模型的性能。然而，在3D视觉中，基于Transformer的幕后和点云的顺序性限制了生成预训练的进一步发展。在这篇论文中，我们提出了一种适用于任意点云模型的3D-to-2D生成预训练方法。我们提议通过交叉注意机制来生成不同指导姿态的视图图像作为预训练方案。生成视图图像的精确超级vision比点云对应的点云更加精准，因此帮助3D背部更好地理解点云的几何结构和立体关系。实验结果表明了我们提议的3D-to-2D生成预训练的优越性，并在ScanObjectNN分类和ShapeNetPart segmentation任务上实现了最佳性能。代码可以在https://github.com/wangzy22/TAP上获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/28/cs.AI_2023_07_28/" data-id="clogyj8ut00197craepnsey42" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/28/cs.CL_2023_07_28/" class="article-date">
  <time datetime="2023-07-28T11:00:00.000Z" itemprop="datePublished">2023-07-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/28/cs.CL_2023_07_28/">cs.CL - 2023-07-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Robust-Distortion-free-Watermarks-for-Language-Models"><a href="#Robust-Distortion-free-Watermarks-for-Language-Models" class="headerlink" title="Robust Distortion-free Watermarks for Language Models"></a>Robust Distortion-free Watermarks for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15593">http://arxiv.org/abs/2307.15593</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jthickstun/watermark">https://github.com/jthickstun/watermark</a></li>
<li>paper_authors: Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, Percy Liang</li>
<li>for: 这个论文目的是为了植入水印到文本中，以防止不当使用文本生成模型。</li>
<li>methods: 这个论文使用了一种基于杂素分布的水印方法，通过将随机数据序列映射到语言模型中生成的文本中，以达到水印的目的。</li>
<li>results: 实验结果表明，这种水印方法可以在不改变文本的分布下，对文本进行植入水印，并且可以在不同的攻击方式下保持水印的可读性。具体来说，对于OPT-1.3B和LLaMA-7B模型，可以在40%-50%的杂素替换、插入和删除攻击下，在35个字符的文本中仍可以可靠地检测水印（p&lt;&#x3D;0.01）。对于Alpaca-7B模型，由于响应的 entropy 较低，检测是更加困难的，但仍可以在25%的响应中检测到水印（p&lt;&#x3D;0.01）。<details>
<summary>Abstract</summary>
We propose a methodology for planting watermarks in text from an autoregressive language model that are robust to perturbations without changing the distribution over text up to a certain maximum generation budget. We generate watermarked text by mapping a sequence of random numbers -- which we compute using a randomized watermark key -- to a sample from the language model. To detect watermarked text, any party who knows the key can align the text to the random number sequence. We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling. We apply these watermarks to three language models -- OPT-1.3B, LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B and LLaMA-7B models, we find we can reliably detect watermarked text ($p \leq 0.01$) from $35$ tokens even after corrupting between $40$-$50$\% of the tokens via random edits (i.e., substitutions, insertions or deletions). For the Alpaca-7B model, we conduct a case study on the feasibility of watermarking responses to typical user instructions. Due to the lower entropy of the responses, detection is more difficult: around $25\%$ of the responses -- whose median length is around $100$ tokens -- are detectable with $p \leq 0.01$, and the watermark is also less robust to certain automated paraphrasing attacks we implement.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，用于在文本中植入抗干扰的水印，不会改变文本的分布，直到最大生成预算为止。我们生成水印文本，通过将一个序列Random numbers（我们使用随机水印密钥计算）映射到语言模型的样本。为检测水印文本，任何知道密钥的人可以将文本与Random number序列进行对齐。我们实现了我们的水印方法，使用两种采样方案：反转采样和最小值采样。我们在三个语言模型（OPT-1.3B、LLaMA-7B和Alpaca-7B）上实验 validate its statistical power and robustness to various paraphrasing attacks。我们发现，对OPT-1.3B和LLaMA-7B模型，我们可以在35个字符之前（也就是说，在40-50%的字符被随机编辑后）检测水印文本（p ≤ 0.01）。对Alpaca-7B模型，我们进行了一项研究，探讨是否可以在用户指令的回答中植入水印。由于回答的低 entropy，检测变得更加困难：约25%的回答（ median length around 100 tokens）可以在p ≤ 0.01的情况下检测，而水印也更易受到一些自动生成的修改攻击。
</details></li>
</ul>
<hr>
<h2 id="When-to-generate-hedges-in-peer-tutoring-interactions"><a href="#When-to-generate-hedges-in-peer-tutoring-interactions" class="headerlink" title="When to generate hedges in peer-tutoring interactions"></a>When to generate hedges in peer-tutoring interactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15582">http://arxiv.org/abs/2307.15582</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuromaancer/hedge_prediction">https://github.com/neuromaancer/hedge_prediction</a></li>
<li>paper_authors: Alafate Abulimiti, Chloé Clavel, Justine Cassell</li>
<li>for: 这篇论文探讨了机器学习技术在辅导互动中预测幂值的应用。</li>
<li>methods: 这篇研究使用自然的面对面数据集，并对自然语言转折、对话策略、辅导策略和非语言表达进行标注。这些元素被转换为上一句话的向量表示，并作为机器学习模型的输入。</li>
<li>results: 研究发现，使用嵌入层（捕捉上一句话的语义信息）可以显著提高模型的性能。此外，研究还提供了关于不同特征（如人际关系和非语言表达）在预测幂值方面的重要性的视觉值解释。研究发现，辅导和学生双方的视线强烈关系到幂值预测。这一观察得到了验证通过后续减少研究。<details>
<summary>Abstract</summary>
This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviours. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models. Results show that embedding layers, that capture the semantic information of the previous turns, significantly improves the model's performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviours, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="All-for-One-and-One-For-All-Deep-learning-based-feature-fusion-for-Synthetic-Speech-Detection"><a href="#All-for-One-and-One-For-All-Deep-learning-based-feature-fusion-for-Synthetic-Speech-Detection" class="headerlink" title="All-for-One and One-For-All: Deep learning-based feature fusion for Synthetic Speech Detection"></a>All-for-One and One-For-All: Deep learning-based feature fusion for Synthetic Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15555">http://arxiv.org/abs/2307.15555</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniele Mari, Davide Salvi, Paolo Bestagini, Simone Milani</li>
<li>for: 防止声音深冒险攻击和身份盗窃	+ The paper is written to address the issue of synthetic speech detection in order to prevent frauds and identity thefts.</li>
<li>methods: 结合了三种文献中提出的特征集	+ The paper uses a fusion of three different feature sets proposed in the literature to improve the performance of synthetic speech detection.</li>
<li>results: 在不同的场景和数据集上实现了更好的总体性能	+ The paper presents a model that fuses the three feature sets and achieves better overall performance compared to state-of-the-art solutions, with robustness to anti-forensic attacks and generalization capabilities.Here is the information in Simplified Chinese text:</li>
<li>for: 防止声音深冒险攻击和身份盗窃</li>
<li>methods: 结合了三种文献中提出的特征集</li>
<li>results: 在不同的场景和数据集上实现了更好的总体性能<details>
<summary>Abstract</summary>
Recent advances in deep learning and computer vision have made the synthesis and counterfeiting of multimedia content more accessible than ever, leading to possible threats and dangers from malicious users. In the audio field, we are witnessing the growth of speech deepfake generation techniques, which solicit the development of synthetic speech detection algorithms to counter possible mischievous uses such as frauds or identity thefts. In this paper, we consider three different feature sets proposed in the literature for the synthetic speech detection task and present a model that fuses them, achieving overall better performances with respect to the state-of-the-art solutions. The system was tested on different scenarios and datasets to prove its robustness to anti-forensic attacks and its generalization capabilities.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)最近的深度学习和计算机视觉技术的进步，使得 multimedia 内容的合成和伪造变得更加容易，可能导致来自黑客的威胁和危险。在音频领域，我们目睹到深度语音生成技术的快速发展，这使得对于可能的欺诈或身份盗用而需要开发深层 speech 检测算法。在这篇论文中，我们考虑了 literature 中提出的三种不同的特征集，并提出一种将其融合的模型，实现了与当前的解决方案相比的更好的性能。系统在不同的场景和数据集上进行了测试，以证明其对抗反科学攻击和泛化能力的Robustness。
</details></li>
</ul>
<hr>
<h2 id="‘What-are-you-referring-to-’-Evaluating-the-Ability-of-Multi-Modal-Dialogue-Models-to-Process-Clarificational-Exchanges"><a href="#‘What-are-you-referring-to-’-Evaluating-the-Ability-of-Multi-Modal-Dialogue-Models-to-Process-Clarificational-Exchanges" class="headerlink" title="‘What are you referring to?’ Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges"></a>‘What are you referring to?’ Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15554">http://arxiv.org/abs/2307.15554</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jchiyah/what-are-you-referring-to">https://github.com/jchiyah/what-are-you-referring-to</a></li>
<li>paper_authors: Javier Chiyah-Garcia, Alessandro Suglia, Arash Eshghi, Helen Hastie</li>
<li>For: 这篇论文主要针对对话中的referential ambiguity问题，即当引用表达不唯一确定所指的对象时，谈话中的冲突和修复机制。* Methods: 该论文使用SIMMC 2.0数据集来评估不同状态艺术模型对Clarificational Exchanges (CE)的处理能力，包括对对话历史相关的CE进行处理。* Results: 研究发现，语言基于模型可以编码多Modal semantic information，并处理一些CE；而多Modal模型可以通过额外学习目标获得分离的对象表示，这在处理多modal referential ambiguity中发挥了关键作用。<details>
<summary>Abstract</summary>
Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.
</details>
<details>
<summary>摘要</summary>
优先级意图杂化出现在对话中当referring表达不唯一地标识目标对象时。对话参与者通常立即发现这种杂化并与对话者使用meta-communicative, Clarificational Exchanges（CE）进行修复，包括一个Clarification Request（CR）和回应。我们 argue that能生成和回应CE强制要求对多模态、视觉固定对话模型的架构和目标函数做出特定的限制。我们使用SIMMC 2.0数据集来评估不同状态 искусственного智能模型的处理CE能力，并使用一个度量测试模型中的上下文更新。我们发现语言基于模型可以编码简单的多模态Semantic信息并处理一些CE，在对话历史相关的CE方面表现出色，而多模态模型可以通过额外学习目标函数获得分离的对象表示，这些表示在多modal杂化中扮演重要角色。
</details></li>
</ul>
<hr>
<h2 id="Oracle-Computability-and-Turing-Reducibility-in-the-Calculus-of-Inductive-Constructions"><a href="#Oracle-Computability-and-Turing-Reducibility-in-the-Calculus-of-Inductive-Constructions" class="headerlink" title="Oracle Computability and Turing Reducibility in the Calculus of Inductive Constructions"></a>Oracle Computability and Turing Reducibility in the Calculus of Inductive Constructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15543">http://arxiv.org/abs/2307.15543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yannick Forster, Dominik Kirst, Niklas Mück</li>
<li>for: 这个论文是为了研究 oracle 计算和图灵下降的概念和关系而写的。</li>
<li>methods: 这篇论文使用了 Calculus of Inductive Constructions (CIC) 和 Coq 证明助手来定义和研究 oracle 计算和图灵下降。 它采用了基于 meta-level 函数的定义方式，而不是基于对象级模型的 computation。</li>
<li>results: 这篇论文得到了以下结果：Turing 下降形成上半semilattice，传输 decidability，并且比 truth-table 下降更加强大表达能力。此外，当 predicate $p$ 和其 complement 都是对 oracle $q$ 的 semi-decidable 时，then $p$ Turing-reduces to $q$.<details>
<summary>Abstract</summary>
We develop synthetic notions of oracle computability and Turing reducibility in the Calculus of Inductive Constructions (CIC), the constructive type theory underlying the Coq proof assistant. As usual in synthetic approaches, we employ a definition of oracle computations based on meta-level functions rather than object-level models of computation, relying on the fact that in constructive systems such as CIC all definable functions are computable by construction. Such an approach lends itself well to machine-checked proofs, which we carry out in Coq.   There is a tension in finding a good synthetic rendering of the higher-order notion of oracle computability. On the one hand, it has to be informative enough to prove central results, ensuring that all notions are faithfully captured. On the other hand, it has to be restricted enough to benefit from axioms for synthetic computability, which usually concern first-order objects. Drawing inspiration from a definition by Andrej Bauer based on continuous functions in the effective topos, we use a notion of sequential continuity to characterise valid oracle computations.   As main technical results, we show that Turing reducibility forms an upper semilattice, transports decidability, and is strictly more expressive than truth-table reducibility, and prove that whenever both a predicate $p$ and its complement are semi-decidable relative to an oracle $q$, then $p$ Turing-reduces to $q$.
</details>
<details>
<summary>摘要</summary>
我们在Calculus of Inductive Constructions（CIC）中发展了一种干预计算和图灵可reducible的概念。与传统的 sintética方法不同，我们使用基于高级函数而不是对象水平模型的计算定义 oracle computations。这种方法适合机器检查证明，我们在Coq中进行了证明。在高级层次上定义干预计算的问题存在一种矛盾。一方面，它必须够精细以证明中心结果，确保所有概念都能够准确地捕捉。另一方面，它必须够简单以便利用 axioms for synthetic computability，这些axioms通常只关注第一级对象。 draw inspiration from Andrej Bauer 基于有效幂论中的连续函数的定义，我们使用sequential continuity来 caracterize valid oracle computations。我们的主要技术结果包括：1. Turing reducibility forms an upper semilattice。2. Turing reducibility transports decidability。3. Turing reducibility is strictly more expressive than truth-table reducibility。4. If both a predicate $p$ and its complement are semi-decidable relative to an oracle $q$, then $p$ Turing-reduces to $q$.注意：以下是简化中文版本，如果需要更加详细的解释，请咨询专业人士。
</details></li>
</ul>
<hr>
<h2 id="The-Road-to-Quality-is-Paved-with-Good-Revisions-A-Detailed-Evaluation-Methodology-for-Revision-Policies-in-Incremental-Sequence-Labelling"><a href="#The-Road-to-Quality-is-Paved-with-Good-Revisions-A-Detailed-Evaluation-Methodology-for-Revision-Policies-in-Incremental-Sequence-Labelling" class="headerlink" title="The Road to Quality is Paved with Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling"></a>The Road to Quality is Paved with Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15508">http://arxiv.org/abs/2307.15508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/briemadu/inc-eval-revisions">https://github.com/briemadu/inc-eval-revisions</a></li>
<li>paper_authors: Brielen Madureira, Patrick Kahardipraja, David Schlangen</li>
<li>for: 这篇论文主要是关于增量Sequence Labeling中的编辑和修订策略。</li>
<li>methods: 该论文提出了一种形式化和Characterize edits和修订策略，并对三种基于Transformer的encoder进行了 Profile。</li>
<li>results: 研究发现，这些encoder在不同任务中的增量行为都具有不同的特点，这可以帮助改进修订策略。<details>
<summary>Abstract</summary>
Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.
</details>
<details>
<summary>摘要</summary>
转换文本为简化中文：增量对话模型组件生成基于输入的输出前缀序列。由于地方冲突或错误假设，可能会出现错误，因此能够修改过去输出的能力是一个感irable的属性，可以由策略控制。在这项工作中，我们将增量编辑和修订在增量序列标记中进行正式化和特征化，并提出修订策略评价指标。然后，我们将方法应用于三种基于Transformer的编码器在不同任务中的增量行为进行 profiling，为更好的修订策略开出道路。
</details></li>
</ul>
<hr>
<h2 id="The-timing-bottleneck-Why-timing-and-overlap-are-mission-critical-for-conversational-user-interfaces-speech-recognition-and-dialogue-systems"><a href="#The-timing-bottleneck-Why-timing-and-overlap-are-mission-critical-for-conversational-user-interfaces-speech-recognition-and-dialogue-systems" class="headerlink" title="The timing bottleneck: Why timing and overlap are mission-critical for conversational user interfaces, speech recognition and dialogue systems"></a>The timing bottleneck: Why timing and overlap are mission-critical for conversational user interfaces, speech recognition and dialogue systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15493">http://arxiv.org/abs/2307.15493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Liesenfeld, Alianda Lopez, Mark Dingemanse</li>
<li>for: 这些研究是为了评估现有的商业语音识别系统在对话场景中的性能。</li>
<li>methods: 研究者使用了5种主要的商业语音识别系统，对于6种语言的自然对话数据进行了评估。</li>
<li>results: 研究发现，对话数据中的单词错误率仍然很高，而 overlap 问题是对话识别的关键挑战。这些结果有助于评估当前的对话语音识别技术的状态，并且可以帮助建立更加可靠的对话speech技术。<details>
<summary>Abstract</summary>
Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.
</details>
<details>
<summary>摘要</summary>
speech recognition systems 是人机交互中的关键中间件，尽管speech recognition在纯净的对话中工作得很好，但实际的生活中的开放式交互场景仍然存在许多挑战。我们认为时间是对话系统的关键因素，并评估了5个主要的商业ASR系统的对话和多语言支持。我们发现，在6种自然的对话语言中，word error rate remain extremely high，并且 overlap是关键挑战（研究1）。这继而影响了对话词的识别（研究2），并 ultimately affects downstream intent recognition（研究3）。我们的发现可以评估当前的对话ASR的状态，帮助建立多维度的错误分析和评估，并 indentify需要特别注意的现象，以建立可靠的对话speech技术。
</details></li>
</ul>
<hr>
<h2 id="Cross-Modal-Concept-Learning-and-Inference-for-Vision-Language-Models"><a href="#Cross-Modal-Concept-Learning-and-Inference-for-Vision-Language-Models" class="headerlink" title="Cross-Modal Concept Learning and Inference for Vision-Language Models"></a>Cross-Modal Concept Learning and Inference for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15460">http://arxiv.org/abs/2307.15460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Zhang, Ce Zhang, Yushun Tang, Zhihai He</li>
<li>for: 本研究旨在提高现有 fine-tuning 方法的性能，解决图像中的不同Semantic object和概念之间的关系问题。</li>
<li>methods: 我们提出了一种新的方法，即跨模型概念学习和推理（CCLI），利用 CLIP 强大的文本-图像相关能力，自动学习图像中的大量特征特征，并根据这些特征构建了分类图像的描述表示，并学习一个概念推理网络进行下游图像分类任务。</li>
<li>results: 我们的 CCLI 方法在 few-shot learning 和领域泛化等下游任务中表现出了显著的提升，比如与当前状态艺术法相比，提高了8.0%的性能。<details>
<summary>Abstract</summary>
Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP, establish the correlation between texts and images, achieving remarkable success on various downstream tasks with fine-tuning. In existing fine-tuning methods, the class-specific text description is matched against the whole image. We recognize that this whole image matching is not effective since images from the same class often contain a set of different semantic objects, and an object further consists of a set of semantic parts or concepts. Individual semantic parts or concepts may appear in image samples from different classes. To address this issue, in this paper, we develop a new method called cross-model concept learning and inference (CCLI). Using the powerful text-image correlation capability of CLIP, our method automatically learns a large set of distinctive visual concepts from images using a set of semantic text concepts. Based on these visual concepts, we construct a discriminative representation of images and learn a concept inference network to perform downstream image classification tasks, such as few-shot learning and domain generalization. Extensive experimental results demonstrate that our CCLI method is able to improve the performance upon the current state-of-the-art methods by large margins, for example, by up to 8.0% improvement on few-shot learning and by up to 1.3% for domain generalization.
</details>
<details>
<summary>摘要</summary>
大规模预训练视觉语言模型（VLM），如CLIP，已经建立了文本和图像之间的相关性，在多种下游任务上达到了非常成功的结果。现有的精细调整方法中，通常将类型特定的文本描述与整个图像进行匹配，但我们认为这种整个图像匹配并不有效，因为图像从同一类型的图像中可能包含多个不同的semantic对象，而每个semantic对象都可能包含多个semantic部分或概念。在不同类型的图像中，这些semantic部分或概念可能会出现。为解决这个问题，在这篇论文中，我们开发了一种新的方法 called cross-model concept learning and inference（CCLI）。使用CLIP强大的文本-图像相关能力，我们自动学习了一个大量的特异性视觉概念从图像中，并使用这些视觉概念构建了一个描述性图像表示，并学习一个概念推理网络来进行下游图像分类任务，如少量学习和领域泛化。我们的CCLI方法在多种实验结果中表现出了大幅提升的性能，比如在少量学习任务上提升了8.0%，在领域泛化任务上提升了1.3%。
</details></li>
</ul>
<hr>
<h2 id="Trie-NLG-Trie-Context-Augmentation-to-Improve-Personalized-Query-Auto-Completion-for-Short-and-Unseen-Prefixes"><a href="#Trie-NLG-Trie-Context-Augmentation-to-Improve-Personalized-Query-Auto-Completion-for-Short-and-Unseen-Prefixes" class="headerlink" title="Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes"></a>Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15455">http://arxiv.org/abs/2307.15455</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaushal Kumar Maurya, Maunendra Sankar Desarkar, Manish Gupta, Puneet Agrawal</li>
<li>for: 提高 Query Auto-completion（QAC）系统的完ten completion accuracy，尤其是对短前缀和未看到的前缀进行提高。</li>
<li>methods: 提议一种基于 Trie 和 Natural Language Generation（NLG）模型的新方法，可以同时利用前一个会话中的查询和 Trie 中的 популярity 信号来提高 QAC 的性能。</li>
<li>results: 通过对两个大型 QAC 数据集进行评估，发现该方法可以提高 QAC 系统的 MRR 指标的表现，相比之下 Popular Trie-based Lookup 和 BART-based Baseline 方法，平均提高了大约 57% 和 14%。<details>
<summary>Abstract</summary>
Query auto-completion (QAC) aims at suggesting plausible completions for a given query prefix. Traditionally, QAC systems have leveraged tries curated from historical query logs to suggest most popular completions. In this context, there are two specific scenarios that are difficult to handle for any QAC system: short prefixes (which are inherently ambiguous) and unseen prefixes. Recently, personalized Natural Language Generation (NLG) models have been proposed to leverage previous session queries as context for addressing these two challenges. However, such NLG models suffer from two drawbacks: (1) some of the previous session queries could be noisy and irrelevant to the user intent for the current prefix, and (2) NLG models cannot directly incorporate historical query popularity. This motivates us to propose a novel NLG model for QAC, Trie-NLG, which jointly leverages popularity signals from trie and personalization signals from previous session queries. We train the Trie-NLG model by augmenting the prefix with rich context comprising of recent session queries and top trie completions. This simple modeling approach overcomes the limitations of trie-based and NLG-based approaches and leads to state-of-the-art performance. We evaluate the Trie-NLG model using two large QAC datasets. On average, our model achieves huge ~57% and ~14% boost in MRR over the popular trie-based lookup and the strong BART-based baseline methods, respectively. We make our code publicly available.
</details>
<details>
<summary>摘要</summary>
Query 自动完成（QAC）的目标是为给定的查询前缀提供可能的完成方案。传统上，QAC 系统都是基于历史查询记录中的尝试来建议最受欢迎的完成方案。在这种情况下，短前缀（即查询符）和未看到的前缀是两个困难的场景。最近，人性化的自然语言生成（NLG）模型被提议用于解决这两个挑战。然而，这些 NLG 模型受到两个缺点：（1）一些前一个会话中的查询可能是噪音和无关于用户意图的查询，和（2）NLG 模型不能直接包含历史查询的流行性信号。这种情况引发我们提出一种新的 NLG 模型，即 Trie-NLG，它同时利用尝试和前一个会话中的查询来提供可能的完成方案。我们在训练 Trie-NLG 模型时，将前缀添加了丰富的上下文，包括最近的会话中的查询和 top 尝试。这种简单的模型方法超越了尝试基于和 NLG 基于的方法，并带来了状态之最好的性能。我们使用两个大的 QAC 数据集来评估 Trie-NLG 模型。在 average 的情况下，我们的模型在 MRR 方面获得了大约 57% 和 14% 的提升，相比于流行的尝试基于的查看和强大的 BART 基eline 方法。我们将代码公开。
</details></li>
</ul>
<hr>
<h2 id="CFN-ESA-A-Cross-Modal-Fusion-Network-with-Emotion-Shift-Awareness-for-Dialogue-Emotion-Recognition"><a href="#CFN-ESA-A-Cross-Modal-Fusion-Network-with-Emotion-Shift-Awareness-for-Dialogue-Emotion-Recognition" class="headerlink" title="CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for Dialogue Emotion Recognition"></a>CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for Dialogue Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15432">http://arxiv.org/abs/2307.15432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiang Li, Yingjian Liu, Xiaoping Wang, Zhigang Zeng</li>
<li>for: 这篇研究旨在提出一个跨Modal融合网络，具有情感变化意识（CFN-ESA），用于多modal情感识别（ERC）。</li>
<li>methods: 该方法使用文本modalities作为主要情感信息来源，而视觉和声音modalities则被视为次要来源。此外，该方法还包括情感变化模块（LESM），以捕捉情感变化信息，并将其与主要任务进行相互适应。</li>
<li>results: 实验结果显示，CFN-ESA可以优化ERC的表现，并与现有模型相比，得到了remarkable的进步。<details>
<summary>Abstract</summary>
Multimodal Emotion Recognition in Conversation (ERC) has garnered growing attention from research communities in various fields. In this paper, we propose a cross-modal fusion network with emotion-shift awareness (CFN-ESA) for ERC. Extant approaches employ each modality equally without distinguishing the amount of emotional information, rendering it hard to adequately extract complementary and associative information from multimodal data. To cope with this problem, in CFN-ESA, textual modalities are treated as the primary source of emotional information, while visual and acoustic modalities are taken as the secondary sources. Besides, most multimodal ERC models ignore emotion-shift information and overfocus on contextual information, leading to the failure of emotion recognition under emotion-shift scenario. We elaborate an emotion-shift module to address this challenge. CFN-ESA mainly consists of the unimodal encoder (RUME), cross-modal encoder (ACME), and emotion-shift module (LESM). RUME is applied to extract conversation-level contextual emotional cues while pulling together the data distributions between modalities; ACME is utilized to perform multimodal interaction centered on textual modality; LESM is used to model emotion shift and capture related information, thereby guide the learning of the main task. Experimental results demonstrate that CFN-ESA can effectively promote performance for ERC and remarkably outperform the state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
多modal情感识别在对话（ERC）领域已经吸引了不同领域的研究者的关注。在这篇论文中，我们提出了跨modal融合网络 WITH emotion-shift 意识（CFN-ESA） для ERC。现有的方法均视每个模式都是平等的，无法准确地EXTRACT complementary和associative information FROM multimodal data。为了解决这个问题，在CFN-ESA中，文本模式被视为情感信息的主要来源，而视觉和声音模式则被视为次要来源。此外，大多数多modal ERC模型忽视情感转换信息并过度关注上下文信息，导致情感识别下情感转换场景失败。我们提出了情感转换模块来解决这个挑战。CFN-ESA主要由RUME、ACME和LESM三部分组成。RUME用于EXTRACT对话水平的情感cue，并将多个模式之间的数据分布相互紧密连接起来；ACME用于在文本模式为中心进行多模式交互；LESM用于模型情感转换， capture相关信息，以导引主任务的学习。实验结果表明，CFN-ESA可以有效提高ERC的性能，并remarkably exceed state-of-the-art模型。
</details></li>
</ul>
<hr>
<h2 id="Investigating-the-Learning-Behaviour-of-In-context-Learning-A-Comparison-with-Supervised-Learning"><a href="#Investigating-the-Learning-Behaviour-of-In-context-Learning-A-Comparison-with-Supervised-Learning" class="headerlink" title="Investigating the Learning Behaviour of In-context Learning: A Comparison with Supervised Learning"></a>Investigating the Learning Behaviour of In-context Learning: A Comparison with Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15411">http://arxiv.org/abs/2307.15411</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xdwang0726/icl_ll">https://github.com/xdwang0726/icl_ll</a></li>
<li>paper_authors: Xindi Wang, Yufei Wang, Can Xu, Xiubo Geng, Bowen Zhang, Chongyang Tao, Frank Rudzicz, Robert E. Mercer, Daxin Jiang</li>
<li>for: 这 paper 的目的是 investigate the learning behavior of in-context learning (ICL) and compare it with supervised learning (SL) under label perturbations.</li>
<li>methods: 作者使用了同一个 demonstration example 进行 ICL 和 SL 训练，并研究其下游性能在 classification tasks 中受到 label perturbations 的影响。</li>
<li>results: AUTHORS 发现，gold labels 对下游 ICL 性能有显著影响，特别是对大语言模型; 然而，不均衡标签对 ICL 的影响几乎无关紧要。此外，作者还发现，相比 SL，ICL 对标签扰乱更为敏感，但是随着模型大小增加，ICL 逐渐达到 SL 的性能水平。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown remarkable capacity for in-context learning (ICL), where learning a new task from just a few training examples is done without being explicitly pre-trained. However, despite the success of LLMs, there has been little understanding of how ICL learns the knowledge from the given prompts. In this paper, to make progress toward understanding the learning behaviour of ICL, we train the same LLMs with the same demonstration examples via ICL and supervised learning (SL), respectively, and investigate their performance under label perturbations (i.e., noisy labels and label imbalance) on a range of classification tasks. First, via extensive experiments, we find that gold labels have significant impacts on the downstream in-context performance, especially for large language models; however, imbalanced labels matter little to ICL across all model sizes. Second, when comparing with SL, we show empirically that ICL is less sensitive to label perturbations than SL, and ICL gradually attains comparable performance to SL as the model size increases.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经表现出杰出的内容学习（ICL）能力，即从极少的训练示例中学习新任务，而不需要预先训练。然而， despite 成功的 LLM， there has been little understanding of how ICL learns the knowledge from the given prompts. 在这篇论文中，我们将同一个 LLM 训练 via ICL 和监督学习（SL），并调查它们在标签噪音（i.e., 杂凑标签和标签不均）的情况下的性能。首先，通过广泛的实验，我们发现 gold labels 对 downstream in-context performance 有很大的影响，特别是 для large language models; however, imbalanced labels matter little to ICL across all model sizes。其次，我们比较 SL 和 ICL，我们显示了实践中 ICL 比 SL 更敏感于标签噪音，并且 ICL 逐渐实现了与 SL 相同的性能，随着模型大小增加。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-Fully-Unsupervised-Framework-for-Intent-Induction-in-Customer-Support-Dialogues"><a href="#Towards-a-Fully-Unsupervised-Framework-for-Intent-Induction-in-Customer-Support-Dialogues" class="headerlink" title="Towards a Fully Unsupervised Framework for Intent Induction in Customer Support Dialogues"></a>Towards a Fully Unsupervised Framework for Intent Induction in Customer Support Dialogues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15410">http://arxiv.org/abs/2307.15410</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rita Costa, Bruno Martins, Sérgio Viana, Luisa Coheur</li>
<li>for: 本研究旨在提出一种 completelly unsupervised 的意图推论框架，以便在对话中进行意图推论。</li>
<li>methods: 本研究使用了对话 corpora 的预处理技术，以提高结果的准确性。同时，通过investigating the most common sequences，提取对话的意图流程。</li>
<li>results: 本研究在 MultiWOZ  dataset 上进行了测试，并获得了可靠的结果。这种框架不仅可以应用于 MultiWOZ  dataset，还可以应用于任何可能的用 caso，例如实际世界中的客户支持应用。<details>
<summary>Abstract</summary>
State of the art models in intent induction require annotated datasets. However, annotating dialogues is time-consuming, laborious and expensive. In this work, we propose a completely unsupervised framework for intent induction within a dialogue. In addition, we show how pre-processing the dialogue corpora can improve results. Finally, we show how to extract the dialogue flows of intentions by investigating the most common sequences. Although we test our work in the MultiWOZ dataset, the fact that this framework requires no prior knowledge make it applicable to any possible use case, making it very relevant to real world customer support applications across industry.
</details>
<details>
<summary>摘要</summary>
现代模型对意向推干需要标注数据集。然而，标注对话是时间费时的、劳苦的和昂费的。在这个工作中，我们提出了一个 completly 无监控的框架，用于对对话中的意向进行推干。此外，我们显示了如何对对话数据库进行预processing，以改善结果。最后，我们显示了如何从最常见的sequences中提取对话流程的意向。我们在MultiWOZ dataset上进行了测试，但由于这个框架不需任何先前知识，因此它适用于任何可能的用 caso，使其在实际世界中的客户支持应用程序中非常有 relevance。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Tourist-Assistance-using-ChatGPT-Comparing-Capabilities-in-Hindi-Telugu-and-Kannada"><a href="#Multilingual-Tourist-Assistance-using-ChatGPT-Comparing-Capabilities-in-Hindi-Telugu-and-Kannada" class="headerlink" title="Multilingual Tourist Assistance using ChatGPT: Comparing Capabilities in Hindi, Telugu, and Kannada"></a>Multilingual Tourist Assistance using ChatGPT: Comparing Capabilities in Hindi, Telugu, and Kannada</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15376">http://arxiv.org/abs/2307.15376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanjana Kolar, Rohit Kumar</li>
<li>for: 这项研究旨在评估OpenAI提供的ChatGPT语言模型在翻译英语到印地语、telugu和 kannada语言方面的效果，以帮助印度的旅游者在语言多样性的环境中。</li>
<li>methods: 该研究使用了50个多样化的问题集，包括一般知识、美食和旅游等领域，并由5名志愿者评分翻译的准确性和流畅性。这些分数最后被转换为BLEU分数，以衡量机器生成的翻译质量。</li>
<li>results: 研究发现，印地语翻译表现出色，具有更高的准确性和流畅性，而telugu翻译则落后于其他语言。人工评分者对翻译的准确性和流畅性进行评估，提供了全面的语言模型性能评估。<details>
<summary>Abstract</summary>
This research investigates the effectiveness of ChatGPT, an AI language model by OpenAI, in translating English into Hindi, Telugu, and Kannada languages, aimed at assisting tourists in India's linguistically diverse environment. To measure the translation quality, a test set of 50 questions from diverse fields such as general knowledge, food, and travel was used. These were assessed by five volunteers for accuracy and fluency, and the scores were subsequently converted into a BLEU score. The BLEU score evaluates the closeness of a machine-generated translation to a human translation, with a higher score indicating better translation quality. The Hindi translations outperformed others, showcasing superior accuracy and fluency, whereas Telugu translations lagged behind. Human evaluators rated both the accuracy and fluency of translations, offering a comprehensive perspective on the language model's performance.
</details>
<details>
<summary>摘要</summary>
这项研究探讨了OpenAI开发的语言模型ChatGPT在将英语翻译成印地语、telugu和 kannada语言方面的效果，以帮助印度语言多样性环境中的旅游者。为衡量翻译质量，研究使用了50个多学科知识、食物和旅行的问题集，由5名志愿者评测准确性和流畅性，并将得分转换为BLEU分数。BLEU分数评估机器生成翻译与人工翻译之间的相似性，高分数表示更高的翻译质量。印地语翻译表现出色，准确性和流畅性都较高，而telugu翻译则落后。人工评测器对翻译准确性和流畅性进行评估，为语言模型表现提供了全面的视角。
</details></li>
</ul>
<hr>
<h2 id="Teach-Me-How-to-Improve-My-Argumentation-Skills-A-Survey-on-Feedback-in-Argumentation"><a href="#Teach-Me-How-to-Improve-My-Argumentation-Skills-A-Survey-on-Feedback-in-Argumentation" class="headerlink" title="Teach Me How to Improve My Argumentation Skills: A Survey on Feedback in Argumentation"></a>Teach Me How to Improve My Argumentation Skills: A Survey on Feedback in Argumentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15341">http://arxiv.org/abs/2307.15341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Camélia Guerraoui, Paul Reisert, Naoya Inoue, Farjana Sultana Mim, Shoichi Naito, Jungmin Choi, Irfan Robbani, Wenzhi Wang, Kentaro Inui</li>
<li>for: 这篇论文旨在探讨计算机模型在推理方面的反馈方式，以帮助学生提高批判性思维能力。</li>
<li>methods: 论文使用现有的计算机模型来评估论证质量，并探讨这些模型是否能够提供有用的反馈，以帮助学生进行改进。</li>
<li>results: 论文发现，现有的计算机模型可以提供较为 ricH 的反馈，但是这些反馈通常无法解释为什么某个论证是低质量的，这限制了对学生的反馈提供 constructive 的feedback。<details>
<summary>Abstract</summary>
The use of argumentation in education has been shown to improve critical thinking skills for end-users such as students, and computational models for argumentation have been developed to assist in this process. Although these models are useful for evaluating the quality of an argument, they oftentimes cannot explain why a particular argument is considered poor or not, which makes it difficult to provide constructive feedback to users to strengthen their critical thinking skills. In this survey, we aim to explore the different dimensions of feedback (Richness, Visualization, Interactivity, and Personalization) provided by the current computational models for argumentation, and the possibility of enhancing the power of explanations of such models, ultimately helping learners improve their critical thinking skills.
</details>
<details>
<summary>摘要</summary>
使用辩论在教育中有助于提高学生的批判性思维能力，计算机模型也已经为这个过程而开发。虽然这些模型有用于评估论证质量，但它们往往无法解释特定论证为何不好或者不合理，这使得给用户提供有用的反馈很困难，从而难以帮助学生提高批判性思维能力。在这份调查中，我们计划探讨现有的计算机模型feedback维度（丰富性、可视化、交互性和个性化），以及可能通过增强这些模型的解释力来帮助学生提高批判性思维能力。
</details></li>
</ul>
<hr>
<h2 id="BARTPhoBEiT-Pre-trained-Sequence-to-Sequence-and-Image-Transformers-Models-for-Vietnamese-Visual-Question-Answering"><a href="#BARTPhoBEiT-Pre-trained-Sequence-to-Sequence-and-Image-Transformers-Models-for-Vietnamese-Visual-Question-Answering" class="headerlink" title="BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering"></a>BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15335">http://arxiv.org/abs/2307.15335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khiem Vinh Tran, Kiet Van Nguyen, Ngan Luu Thuy Nguyen</li>
<li>for: 本研究旨在提出一个基于 transformer 的越南语模型，以解决英语资源充足的问题，并在越南语 VQA dataset 上进行评估。</li>
<li>methods: 本研究使用了预训Sequence-to-Sequence和 bidirectional encoder representation from Image Transformers，并在越南语中进行训练。</li>
<li>results: 实验结果显示，我们的提案模型在六个指标中出performing better than 强基eline，包括 Accuracy、Precision、Recall、F1-score、WUPS 0.0 和 WUPS 0.9。<details>
<summary>Abstract</summary>
Visual Question Answering (VQA) is an intricate and demanding task that integrates natural language processing (NLP) and computer vision (CV), capturing the interest of researchers. The English language, renowned for its wealth of resources, has witnessed notable advancements in both datasets and models designed for VQA. However, there is a lack of models that target specific countries such as Vietnam. To address this limitation, we introduce a transformer-based Vietnamese model named BARTPhoBEiT. This model includes pre-trained Sequence-to-Sequence and bidirectional encoder representation from Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets. Experimental results demonstrate that our proposed model outperforms the strong baseline and improves the state-of-the-art in six metrics: Accuracy, Precision, Recall, F1-score, WUPS 0.0, and WUPS 0.9.
</details>
<details>
<summary>摘要</summary>
视觉问答（VQA）是一项复杂且需求高的任务，涉及自然语言处理（NLP）和计算机视觉（CV），吸引了研究者们的关注。英语，因其资源丰富，在VQA领域已经取得了显著进步，但是尚未有专门针对特定国家的模型。为了解决这一限制，我们提出了一个基于变换器的越南语模型，名为BARTPhoBEiT。这个模型包括预训练的序列到序列和双向编码器表示图像变换器在越南语中，并评估越南语VQA数据集。实验结果表明，我们提议的模型超越强基线和提高了状态之册的六个指标：准确率、精度、回归率、F1分数、WUPS 0.0和WUPS 0.9。
</details></li>
</ul>
<hr>
<h2 id="SAP-sLDA-An-Interpretable-Interface-for-Exploring-Unstructured-Text"><a href="#SAP-sLDA-An-Interpretable-Interface-for-Exploring-Unstructured-Text" class="headerlink" title="SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text"></a>SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01420">http://arxiv.org/abs/2308.01420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charumathi Badrinath, Weiwei Pan, Finale Doshi-Velez</li>
<li>for: 用于改进文档抽象的维度减少算法，以便更好地捕捉人类理解的文档相似性关系。</li>
<li>methods: 基于Latent Dirichlet Allocation（LDA）的半指导式人工智能-循环方法，通过允许用户提供一些标签来学习主题。</li>
<li>results: 在synthetic corpora上，我们的方法可以生成更加理解的抽象，并且只需要提供一部分标签。在实际 corpora 上，我们获得了相似的结果。<details>
<summary>Abstract</summary>
A common way to explore text corpora is through low-dimensional projections of the documents, where one hopes that thematically similar documents will be clustered together in the projected space. However, popular algorithms for dimensionality reduction of text corpora, like Latent Dirichlet Allocation (LDA), often produce projections that do not capture human notions of document similarity. We propose a semi-supervised human-in-the-loop LDA-based method for learning topics that preserve semantically meaningful relationships between documents in low-dimensional projections. On synthetic corpora, our method yields more interpretable projections than baseline methods with only a fraction of labels provided. On a real corpus, we obtain qualitatively similar results.
</details>
<details>
<summary>摘要</summary>
通常来说，探索文本 corpus 的方式是通过低维度投影文档，希望在投影空间中 clusters  similar documents 。然而，流行的文本探索维度减少算法，如 Latent Dirichlet Allocation (LDA)，经常生成投影不符合人类意义的文档相似性。我们提议一种 semi-supervised 人在循环 LDA 基于方法，以学习保持含义相似性的文档关系在低维度投影中。在 sintetic corpus 上，我们的方法可以提供更加 interpretable 的投影，只需提供一部分标签。在真实 corpus 上，我们获得了类似的结果。
</details></li>
</ul>
<hr>
<h2 id="TrafficSafetyGPT-Tuning-a-Pre-trained-Large-Language-Model-to-a-Domain-Specific-Expert-in-Transportation-Safety"><a href="#TrafficSafetyGPT-Tuning-a-Pre-trained-Large-Language-Model-to-a-Domain-Specific-Expert-in-Transportation-Safety" class="headerlink" title="TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety"></a>TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15311">http://arxiv.org/abs/2307.15311</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ozheng1993/trafficsafetygpt">https://github.com/ozheng1993/trafficsafetygpt</a></li>
<li>paper_authors: Ou Zheng, Mohamed Abdel-Aty, Dongdong Wang, Chenzhu Wang, Shengxuan Ding</li>
<li>for: 这种研究是为了提高大型自然语言处理模型（LLMs）在交通安全领域任务中的表现，并且强调了特殊的交通安全专业知识的重要性。</li>
<li>methods: 这种研究使用了一种基于LLAMA模型的新型模型，并在这种模型上进行了监督微调，使用了由政府生成的指导书和ChatGPT生成的指令输出对的人工标签。</li>
<li>results: 研究发现，这种TrafficSafetyGPT模型在交通安全领域任务中表现出色，并且可以减轻特殊的交通安全专业知识的需求。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown remarkable effectiveness in various general-domain natural language processing (NLP) tasks. However, their performance in transportation safety domain tasks has been suboptimal, primarily attributed to the requirement for specialized transportation safety expertise in generating accurate responses [1]. To address this challenge, we introduce TrafficSafetyGPT, a novel LLAMA-based model, which has undergone supervised fine-tuning using TrafficSafety-2K dataset which has human labels from government produced guiding books and ChatGPT-generated instruction-output pairs. Our proposed TrafficSafetyGPT model and TrafficSafety-2K train dataset are accessible at https://github.com/ozheng1993/TrafficSafetyGPT.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ChatHome-Development-and-Evaluation-of-a-Domain-Specific-Language-Model-for-Home-Renovation"><a href="#ChatHome-Development-and-Evaluation-of-a-Domain-Specific-Language-Model-for-Home-Renovation" class="headerlink" title="ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation"></a>ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15290">http://arxiv.org/abs/2307.15290</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lianjiatech/belle">https://github.com/lianjiatech/belle</a></li>
<li>paper_authors: Cheng Wen, Xianghui Sun, Shuaijiang Zhao, Xiaoquan Fang, Liangyu Chen, Wei Zou</li>
<li>for: 这篇论文旨在开发和评估一种专门为家居改造领域设计的域专语言模型（DSLM）。</li>
<li>methods: 该研究采用了域适应预训练和指令调整的方法，使用了一个广泛的数据集，包括专业文章、标准文档和网络内容相关于家居改造。</li>
<li>results: 实验表明，ChatHome不仅提高了域专功能，还保持了其通用性。<details>
<summary>Abstract</summary>
This paper presents the development and evaluation of ChatHome, a domain-specific language model (DSLM) designed for the intricate field of home renovation. Considering the proven competencies of large language models (LLMs) like GPT-4 and the escalating fascination with home renovation, this study endeavors to reconcile these aspects by generating a dedicated model that can yield high-fidelity, precise outputs relevant to the home renovation arena. ChatHome's novelty rests on its methodology, fusing domain-adaptive pretraining and instruction-tuning over an extensive dataset. This dataset includes professional articles, standard documents, and web content pertinent to home renovation. This dual-pronged strategy is designed to ensure that our model can assimilate comprehensive domain knowledge and effectively address user inquiries. Via thorough experimentation on diverse datasets, both universal and domain-specific, including the freshly introduced "EvalHome" domain dataset, we substantiate that ChatHome not only amplifies domain-specific functionalities but also preserves its versatility.
</details>
<details>
<summary>摘要</summary>
ChatHome's novelty lies in its methodology, which fuses domain-adaptive pretraining and instruction-tuning over an extensive dataset. This dataset includes professional articles, standard documents, and web content related to home renovation. This dual-pronged approach is designed to ensure that our model can absorb comprehensive domain knowledge and effectively address user inquiries.Through thorough experimentation on diverse datasets, including the newly introduced "EvalHome" domain dataset, we demonstrate that ChatHome not only enhances domain-specific functionalities but also preserves its versatility.
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Lexical-Simplification-via-Paraphrase-Generation"><a href="#Multilingual-Lexical-Simplification-via-Paraphrase-Generation" class="headerlink" title="Multilingual Lexical Simplification via Paraphrase Generation"></a>Multilingual Lexical Simplification via Paraphrase Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15286">http://arxiv.org/abs/2307.15286</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kpkqwq/lspg">https://github.com/kpkqwq/lspg</a></li>
<li>paper_authors: Kang Liu, Jipeng Qiang, Yun Li, Yunhao Yuan, Yi Zhu, Kaixun Hua</li>
<li>for: 提高 lexical simplification 方法的效果，使其能够生成更加准确和多样化的替代词。</li>
<li>methods: 提出了一种基于 paraphrase 生成的多语言 lexical simplification 方法，通过将句子作为输入，生成具有多种词替的替代词。</li>
<li>results: 实验结果表明，我们的方法在英语、西班牙语和葡萄牙语等语言上显著超过 BERT 基于方法和零批 GPT3 基于方法。<details>
<summary>Abstract</summary>
Lexical simplification (LS) methods based on pretrained language models have made remarkable progress, generating potential substitutes for a complex word through analysis of its contextual surroundings. However, these methods require separate pretrained models for different languages and disregard the preservation of sentence meaning. In this paper, we propose a novel multilingual LS method via paraphrase generation, as paraphrases provide diversity in word selection while preserving the sentence's meaning. We regard paraphrasing as a zero-shot translation task within multilingual neural machine translation that supports hundreds of languages. After feeding the input sentence into the encoder of paraphrase modeling, we generate the substitutes based on a novel decoding strategy that concentrates solely on the lexical variations of the complex word. Experimental results demonstrate that our approach surpasses BERT-based methods and zero-shot GPT3-based method significantly on English, Spanish, and Portuguese.
</details>
<details>
<summary>摘要</summary>
Lexical simplification（LS）方法基于预训练语言模型已经做出了很大的进步，通过分析词语上下文环境来生成可能的替换词。然而，这些方法需要单独的预训练模型来支持不同的语言，并且忽略了保持句子意义的要求。在这篇论文中，我们提出了一种新的多语言LS方法，通过句子重写来提供多样性的词选择，同时保持句子意义的完整性。我们将重写视为一种零批译翻译任务，利用多语言神经翻译模型支持多种语言。在输入句子被编码器模型处理后，我们通过一种新的解码策略来生成替换词，专注于复杂词语的语言变换。实验结果显示，我们的方法在英语、西班牙语和葡萄牙语等语言上超越BERT基于方法和零批GPT3基于方法。
</details></li>
</ul>
<hr>
<h2 id="f-Divergence-Minimization-for-Sequence-Level-Knowledge-Distillation"><a href="#f-Divergence-Minimization-for-Sequence-Level-Knowledge-Distillation" class="headerlink" title="f-Divergence Minimization for Sequence-Level Knowledge Distillation"></a>f-Divergence Minimization for Sequence-Level Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15190">http://arxiv.org/abs/2307.15190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manga-uofa/fdistill">https://github.com/manga-uofa/fdistill</a></li>
<li>paper_authors: Yuqiao Wen, Zichao Li, Wenyu Du, Lili Mou</li>
<li>for: 本文主要针对语言处理领域中的知识填充问题，即将大型模型中的知识转移到小型模型中。</li>
<li>methods: 本文提出了一个f-DISTILL框架，该框架将序列级知识填充转化为最小化一个泛化f- divergence函数的问题。文章还提出了四种填充变种，其中包括SeqKD和ENGINE等已有的方法。</li>
<li>results: 实验结果显示，本文提出的方法可以超越现有的填充方法，并且使用 симметриック的填充损失可以更好地让学生模型学习教师分布。<details>
<summary>Abstract</summary>
Knowledge distillation (KD) is the process of transferring knowledge from a large model to a small one. It has gained increasing attention in the natural language processing community, driven by the demands of compressing ever-growing language models. In this work, we propose an f-DISTILL framework, which formulates sequence-level knowledge distillation as minimizing a generalized f-divergence function. We propose four distilling variants under our framework and show that existing SeqKD and ENGINE approaches are approximations of our f-DISTILL methods. We further derive step-wise decomposition for our f-DISTILL, reducing intractable sequence-level divergence to word-level losses that can be computed in a tractable manner. Experiments across four datasets show that our methods outperform existing KD approaches, and that our symmetric distilling losses can better force the student to learn from the teacher distribution.
</details>
<details>
<summary>摘要</summary>
知识填充（KD）是将知识从大型模型传递到小型模型的过程。随着自然语言处理领域中模型的不断扩大，KD已经受到了越来越多的关注。在这项工作中，我们提出了f-DISTILL框架，它将序列级知识填充形式化为最小化一个通用f-散度函数。我们提出了四种填充变体，并证明了现有的SeqKD和ENGINE方法是f-DISTILL方法的近似方法。我们还 deriv了 step-wise 分解，将不可 tractable的序列级散度降到单词级损失，可以在可追踪的方式上计算。实验结果表明，我们的方法在四个数据集上表现出色，并且我们的对称填充损失可以更好地让学生学习老师分布。
</details></li>
</ul>
<hr>
<h2 id="A-Geometric-Notion-of-Causal-Probing"><a href="#A-Geometric-Notion-of-Causal-Probing" class="headerlink" title="A Geometric Notion of Causal Probing"></a>A Geometric Notion of Causal Probing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15054">http://arxiv.org/abs/2307.15054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clément Guerner, Anej Svete, Tianyu Liu, Alexander Warstadt, Ryan Cotterell</li>
<li>for: 本文提出了一种 formal definition of $\textit{intrinsic}$ information in a subspace of a language model’s representation space, 以便从某些方面控制语言模型的预测结果。</li>
<li>methods: 本文使用了一种counterfactual approach，通过独立处理潜在相关的组件来避免偶极 correlations 问题（Kumar et al., 2022）。此外，本文还提出了一种 $\textit{causal}$ concept subspace，可以优化information在子空间中的搜索。</li>
<li>results: 实验表明，使用R-LACE（Ravfogel et al., 2022）返回的一维子空间可以控制语言模型生成的字符串的概念值。在本文的 causal controlled intervention 中，我们发现，对于至少一个模型，可以使用 R-LACE 返回的子空间来准确地控制生成的字符串中的概念值。<details>
<summary>Abstract</summary>
Large language models rely on real-valued representations of text to make their predictions. These representations contain information learned from the data that the model has trained on, including knowledge of linguistic properties and forms of demographic bias, e.g., based on gender. A growing body of work has considered removing information about concepts such as these using orthogonal projections onto subspaces of the representation space. We contribute to this body of work by proposing a formal definition of $\textit{intrinsic}$ information in a subspace of a language model's representation space. We propose a counterfactual approach that avoids the failure mode of spurious correlations (Kumar et al., 2022) by treating components in the subspace and its orthogonal complement independently. We show that our counterfactual notion of information in a subspace is optimized by a $\textit{causal}$ concept subspace. Furthermore, this intervention allows us to attempt concept controlled generation by manipulating the value of the conceptual component of a representation. Empirically, we find that R-LACE (Ravfogel et al., 2022) returns a one-dimensional subspace containing roughly half of total concept information under our framework. Our causal controlled intervention shows that, for at least one model, the subspace returned by R-LACE can be used to manipulate the concept value of the generated word with precision.
</details>
<details>
<summary>摘要</summary>
大型语言模型通常使用实数valued表示文本来进行预测。这些表示包含模型在训练数据中学习的信息，包括语言性质和人口偏见（如性别）等。一个快速增长的研究领域是去除这些信息，使用正交投影onto subspace of representation space。我们对这些研究进行贡献，提出了一个正式的内在信息定义在语言模型表示空间中的概念。我们提出了一种避免假 correlate 失败模式（Kumar et al., 2022）的对照方法，该方法将subspace和其正交补做独立处理。我们显示了我们的对照方法可以优化内在信息在subspace中。此外，这种干预还允许我们通过控制概念的值来进行概念控制生成。我们的实验表明，R-LACE（Ravfogel et al., 2022）返回了一个一维子空间，包含约半个总概念信息。我们的 causal 控制干预表明，至少一个模型中，R-LACE返回的子空间可以准确地控制生成词的概念值。
</details></li>
</ul>
<hr>
<h2 id="Gzip-versus-bag-of-words-for-text-classification"><a href="#Gzip-versus-bag-of-words-for-text-classification" class="headerlink" title="Gzip versus bag-of-words for text classification"></a>Gzip versus bag-of-words for text classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15002">http://arxiv.org/abs/2307.15002</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/flipz357/npc_gzip_exp">https://github.com/flipz357/npc_gzip_exp</a></li>
<li>paper_authors: Juri Opitz</li>
<li>for: 这份研究旨在证明 bag-of-words 方法可以达到类似或更好的结果，并更高效。</li>
<li>methods: 这篇论文使用了 bag-of-words 方法，并进行了 compression 来提高效率。</li>
<li>results: 研究发现，bag-of-words 方法可以达到类似或更好的结果，而且更高效。<details>
<summary>Abstract</summary>
The effectiveness of compression in text classification ('gzip') has recently garnered lots of attention. In this note we show that `bag-of-words' approaches can achieve similar or better results, and are more efficient.
</details>
<details>
<summary>摘要</summary>
“压缩（gzip）在文本分类中的效果在最近引起了很多关注。在这个笔记中，我们展示了 bag-of-words 方法可以达到类似或更好的结果，并且更高效。”Note:* "压缩" (gzip) is translated as "压缩" in Simplified Chinese.* "bag-of-words" is translated as "bag-of-words" in Simplified Chinese.* "文本分类" (text classification) is translated as "文本分类" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Scaling-TransNormer-to-175-Billion-Parameters"><a href="#Scaling-TransNormer-to-175-Billion-Parameters" class="headerlink" title="Scaling TransNormer to 175 Billion Parameters"></a>Scaling TransNormer to 175 Billion Parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14995">http://arxiv.org/abs/2307.14995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Qin, Dong Li, Weigao Sun, Weixuan Sun, Xuyang Shen, Xiaodong Han, Yunshen Wei, Baohong Lv, Fei Yuan, Xiao Luo, Yu Qiao, Yiran Zhong</li>
<li>For: The paper proposes a new linear attention-based Large Language Model (LLM) called TransNormerLLM, which outperforms conventional softmax attention-based models in terms of both accuracy and efficiency.* Methods: The paper introduces several advanced modifications to the previous linear attention architecture TransNormer, including positional embedding, linear attention acceleration, gating mechanism, tensor normalization, inference acceleration and stabilization. The paper also proposes a new technique called Lightning Attention to accelerate linear attention.* Results: The paper achieves impressive acceleration of over 20% and reduces memory usage by a remarkable four times. The model also shows superior efficiency during both training and inference stages, and is scalable for seamless deployment on large-scale clusters. The paper also demonstrates the effectiveness of the model through comprehensive experiments on a self-collected corpus exceeding 6TB and containing over 2 trillion tokens.<details>
<summary>Abstract</summary>
We present TransNormerLLM, the first linear attention-based Large Language Model (LLM) that outperforms conventional softmax attention-based models in terms of both accuracy and efficiency. TransNormerLLM evolves from the previous linear attention architecture TransNormer by making advanced modifications that include positional embedding, linear attention acceleration, gating mechanism, tensor normalization, inference acceleration and stabilization. Specifically, we use LRPE together with an exponential decay to avoid attention dilution issues while allowing the model to retain global interactions between tokens. Additionally, we propose Lightning Attention, a cutting-edge technique that accelerates linear attention by more than twice in runtime and reduces memory usage by a remarkable four times. To further enhance the performance of TransNormer, we leverage a gating mechanism to smooth training and a new tensor normalization scheme to accelerate the model, resulting in an impressive acceleration of over 20%. Furthermore, we have developed a robust inference algorithm that ensures numerical stability and consistent inference speed, regardless of the sequence length, showcasing superior efficiency during both training and inference stages. Scalability is at the heart of our model's design, enabling seamless deployment on large-scale clusters and facilitating expansion to even more extensive models, all while maintaining outstanding performance metrics. Rigorous validation of our model design is achieved through a series of comprehensive experiments on our self-collected corpus, boasting a size exceeding 6TB and containing over 2 trillion tokens. To ensure data quality and relevance, we implement a new self-cleaning strategy to filter our collected data. Our pre-trained models will be released to foster community advancements in efficient LLMs.
</details>
<details>
<summary>摘要</summary>
我们介绍TransNormerLLM，世界上首个运算式注意力基于大语言模型（LLM），在精度和效率方面都能超越传统软max注意力基于模型。TransNormerLLM继承了之前的线性注意架构TransNormer，通过进一步改进，包括位置嵌入、加速线性注意、闸门机制、tensor normalization、推理加速和稳定。具体来说，我们使用LRPE和指数衰退来避免注意力扩散问题，同时让模型保留字元之间的全局互动。此外，我们提出了Lightning Attention技术，可以在runtime中更多地加速线性注意，并降低内存使用量，实现了四倍以上的加速。为了进一步提高TransNormer的性能，我们导入了闸门机制来缓和训练，并使用新的tensor normalization scheme来加速模型，实现了20%以上的加速。此外，我们开发了一个可靠的推理算法，可以在训练和推理阶段都保持数据稳定和一致的推理速度，无视序列长度。 scalability是我们模型的设计核心，使得可以顺利部署在大规模集群上，并且可以进一步扩展到更大的模型，同时保持出色的性能 Metrics。我们透过一系列严谨的实验，证明了我们的模型设计是正确的。我们将预训练的模型发布，以促进社区对效率LLM的发展。
</details></li>
</ul>
<hr>
<h2 id="Incrementally-Computable-Neural-Networks-Efficient-Inference-for-Dynamic-Inputs"><a href="#Incrementally-Computable-Neural-Networks-Efficient-Inference-for-Dynamic-Inputs" class="headerlink" title="Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs"></a>Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14988">http://arxiv.org/abs/2307.14988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Or Sharir, Anima Anandkumar</li>
<li>for: 这个论文的目的是提出一种高效的增量计算方法，以便在感知数据或用户输入的变化下进行深度学习模型的更新。</li>
<li>methods: 该论文使用了vector量化方法，以便在深度网络中重用计算结果。具体来说，它使用了densely connected transformers架构，并通过减少不必要的计算来实现增量计算。</li>
<li>results: 实验结果表明，使用该方法可以在文档编辑过程中实现高效的增量计算，并且可以保持与批处理模型相同的准确率。具体来说，相比于OPT-125M预训练语言模型，该方法可以降低12.1倍（中位数）的操作数量。<details>
<summary>Abstract</summary>
Deep learning often faces the challenge of efficiently processing dynamic inputs, such as sensor data or user inputs. For example, an AI writing assistant is required to update its suggestions in real time as a document is edited. Re-running the model each time is expensive, even with compression techniques like knowledge distillation, pruning, or quantization. Instead, we take an incremental computing approach, looking to reuse calculations as the inputs change. However, the dense connectivity of conventional architectures poses a major obstacle to incremental computation, as even minor input changes cascade through the network and restrict information reuse. To address this, we use vector quantization to discretize intermediate values in the network, which filters out noisy and unnecessary modifications to hidden neurons, facilitating the reuse of their values. We apply this approach to the transformers architecture, creating an efficient incremental inference algorithm with complexity proportional to the fraction of the modified inputs. Our experiments with adapting the OPT-125M pre-trained language model demonstrate comparable accuracy on document classification while requiring 12.1X (median) fewer operations for processing sequences of atomic edits.
</details>
<details>
<summary>摘要</summary>
为解决这个问题，我们使用 вектор量化来精度化 intermediate 值在网络中，从而过滤无用和干扰的修改。这使得可以 reuse hidden neurons 的值，从而实现高效的逐步计算算法。我们应用这种方法到 transformers 架构上，创造了一种高效的逐步计算算法，其复杂度与修改输入的 Fraction 成正比。我们的实验表明，可以在文档编辑中实现相同的准确率，而且需要 fewer operations（ median 为 12.1X）来处理序列中的 atomic 修改。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/28/cs.CL_2023_07_28/" data-id="clogyj8w5008b7cra7nvf6qdi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_07_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/28/cs.LG_2023_07_28/" class="article-date">
  <time datetime="2023-07-28T10:00:00.000Z" itemprop="datePublished">2023-07-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/28/cs.LG_2023_07_28/">cs.LG - 2023-07-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="TriadNet-Sampling-free-predictive-intervals-for-lesional-volume-in-3D-brain-MR-images"><a href="#TriadNet-Sampling-free-predictive-intervals-for-lesional-volume-in-3D-brain-MR-images" class="headerlink" title="TriadNet: Sampling-free predictive intervals for lesional volume in 3D brain MR images"></a>TriadNet: Sampling-free predictive intervals for lesional volume in 3D brain MR images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15638">http://arxiv.org/abs/2307.15638</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/benolmbrt/TriadNet">https://github.com/benolmbrt/TriadNet</a></li>
<li>paper_authors: Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat</li>
<li>for: 这个研究的目的是提高Volume segmentation工具的可靠性和丰富性，以便在临床实践中更好地使用。</li>
<li>methods: 这个研究使用了多头Convolutional Neural Networks (CNN)架构，同时提供了病变体积和相关预测范围。</li>
<li>results: 研究在BraTS 2021数据集上表现出色，证明了这种方法的优越性。<details>
<summary>Abstract</summary>
The volume of a brain lesion (e.g. infarct or tumor) is a powerful indicator of patient prognosis and can be used to guide the therapeutic strategy. Lesional volume estimation is usually performed by segmentation with deep convolutional neural networks (CNN), currently the state-of-the-art approach. However, to date, few work has been done to equip volume segmentation tools with adequate quantitative predictive intervals, which can hinder their usefulness and acceptation in clinical practice. In this work, we propose TriadNet, a segmentation approach relying on a multi-head CNN architecture, which provides both the lesion volumes and the associated predictive intervals simultaneously, in less than a second. We demonstrate its superiority over other solutions on BraTS 2021, a large-scale MRI glioblastoma image database.
</details>
<details>
<summary>摘要</summary>
“脑部损伤（例如血栓或肿瘤）的体积是诊断病人 prospect 和治疗策略的重要指标，可以用来引导诊断和治疗策略。 however, 到目前为止，有很少的工作是将体积分 segmentation 工具与适当的量化预测 интервал相结合，这会限制其在临床实践中的用途和采纳。 在这个工作中，我们提出了 TriadNet，一种基于多头 CNN 架构的分 segmentation 方法，可以同时提供体积和相应的预测 интервал，执行时间只需要0.1秒钟。 我们在 BraTS 2021 大规模 MRI 肿瘤影像库中与其他解析方法进行比较， demonstarte 其超越性。”Note: "BraTS" is an abbreviation for "Brain Tumor Segmentation" challenge, which is a large-scale MRI glioblastoma image database.
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Analysis-of-Machine-Learning-Methods-for-Lane-Change-Intention-Recognition-Using-Vehicle-Trajectory-Data"><a href="#A-Comparative-Analysis-of-Machine-Learning-Methods-for-Lane-Change-Intention-Recognition-Using-Vehicle-Trajectory-Data" class="headerlink" title="A Comparative Analysis of Machine Learning Methods for Lane Change Intention Recognition Using Vehicle Trajectory Data"></a>A Comparative Analysis of Machine Learning Methods for Lane Change Intention Recognition Using Vehicle Trajectory Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15625">http://arxiv.org/abs/2307.15625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renteng Yuan</li>
<li>for: 本研究旨在用机器学习方法Recognize lane change (LC) intention from high-dimensionality time series data, 帮助自动驾驶车辆更好地理解它们的周围环境，认出安全隐患，提高交通安全性。</li>
<li>methods: 本研究比较了不同的机器学习方法在LC意图识别方面的表现，包括XGBoost和LightGBM两种机器学习算法。</li>
<li>results: 结果显示， ensemble methods可以减少类型II和类型III错误的影响，并且LightGBM可以提高模型训练效率，而无需牺牲识别精度。<details>
<summary>Abstract</summary>
Accurately detecting and predicting lane change (LC)processes can help autonomous vehicles better understand their surrounding environment, recognize potential safety hazards, and improve traffic safety. This paper focuses on LC processes and compares different machine learning methods' performance to recognize LC intention from high-dimensionality time series data. To validate the performance of the proposed models, a total number of 1023 vehicle trajectories is extracted from the CitySim dataset. For LC intention recognition issues, the results indicate that with ninety-eight percent of classification accuracy, ensemble methods reduce the impact of Type II and Type III classification errors. Without sacrificing recognition accuracy, the LightGBM demonstrates a sixfold improvement in model training efficiency than the XGBoost algorithm.
</details>
<details>
<summary>摘要</summary>
自动驾驶车辆可以更好地理解它所处环境，认识安全隐患和提高交通安全性，通过准确探测和预测车道变换（LC）过程。这篇论文关注LC过程，并比较不同机器学习方法在认识LC意图时的表现。为验证提议模型的性能，从CitySim数据集中提取了1023辆汽车轨迹。对LC意图识别问题，结果表明， ensemble方法可以降低类型II和类型III错误的影响，同时保持识别精度。不 sacrificing 识别精度，LightGBM Algorithm 比 XGBoost 算法快六倍。
</details></li>
</ul>
<hr>
<h2 id="Shrink-Perturb-Improves-Architecture-Mixing-during-Population-Based-Training-for-Neural-Architecture-Search"><a href="#Shrink-Perturb-Improves-Architecture-Mixing-during-Population-Based-Training-for-Neural-Architecture-Search" class="headerlink" title="Shrink-Perturb Improves Architecture Mixing during Population Based Training for Neural Architecture Search"></a>Shrink-Perturb Improves Architecture Mixing during Population Based Training for Neural Architecture Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15621">http://arxiv.org/abs/2307.15621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/awesomelemon/pbt-nas">https://github.com/awesomelemon/pbt-nas</a></li>
<li>paper_authors: Alexander Chebykin, Arkadiy Dushatskiy, Tanja Alderliesten, Peter A. N. Bosman</li>
<li>for: 这篇论文目的是实现Neural Architecture Search（NAS）中的内在搜寻。</li>
<li>methods: 这篇论文使用了同时训练和混合神经网络，并将遗传学到的 weights 重复使用来优化参数。提出了基于PBT（Population Based Training）算法的PBT-NAS，可以在训练过程中改善架构，并将不好performing网络替换为well-performing网络的结果。</li>
<li>results: PBT-NAS在复杂任务（如图像生成和强化学习）上实现了superior的表现，较baseline（随机搜寻和变化基于PBT）为佳。<details>
<summary>Abstract</summary>
In this work, we show that simultaneously training and mixing neural networks is a promising way to conduct Neural Architecture Search (NAS). For hyperparameter optimization, reusing the partially trained weights allows for efficient search, as was previously demonstrated by the Population Based Training (PBT) algorithm. We propose PBT-NAS, an adaptation of PBT to NAS where architectures are improved during training by replacing poorly-performing networks in a population with the result of mixing well-performing ones and inheriting the weights using the shrink-perturb technique. After PBT-NAS terminates, the created networks can be directly used without retraining. PBT-NAS is highly parallelizable and effective: on challenging tasks (image generation and reinforcement learning) PBT-NAS achieves superior performance compared to baselines (random search and mutation-based PBT).
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们表明同时训练和混合神经网络是可行的神经建筑搜索（NAS）方法。为超参数优化，重用部分训练过的权重可以实现高效的搜索，这与前一个 Population Based Training（PBT）算法相似。我们提议PBT-NAS算法，它是PBT的NAS适应，通过在训练过程中将不好表现的网络替换为良好表现的网络和混合的结果，使用缩减误差技巧继承权重。在PBT-NAS结束后，创建的网络可以直接使用无需重新训练。PBT-NAS高度并行和有效，在复杂任务（图像生成和强化学习）上，PBT-NAS比基线（随机搜索和误差基于PBT）表现出优秀性。
</details></li>
</ul>
<hr>
<h2 id="Robust-Distortion-free-Watermarks-for-Language-Models"><a href="#Robust-Distortion-free-Watermarks-for-Language-Models" class="headerlink" title="Robust Distortion-free Watermarks for Language Models"></a>Robust Distortion-free Watermarks for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15593">http://arxiv.org/abs/2307.15593</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jthickstun/watermark">https://github.com/jthickstun/watermark</a></li>
<li>paper_authors: Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, Percy Liang</li>
<li>for: 这个论文的目的是在语言模型中植入水印，以防止不当使用和抓取文本。</li>
<li>methods: 这个论文使用了随机水印键来生成水印文本，并使用了两种采样方法来增强水印的可靠性。</li>
<li>results: 实验表明，这种水印方法可以够强大地检测 watermarked 文本，即使在文本中受到较大的杂音和抓取攻击。<details>
<summary>Abstract</summary>
We propose a methodology for planting watermarks in text from an autoregressive language model that are robust to perturbations without changing the distribution over text up to a certain maximum generation budget. We generate watermarked text by mapping a sequence of random numbers -- which we compute using a randomized watermark key -- to a sample from the language model. To detect watermarked text, any party who knows the key can align the text to the random number sequence. We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling. We apply these watermarks to three language models -- OPT-1.3B, LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B and LLaMA-7B models, we find we can reliably detect watermarked text ($p \leq 0.01$) from $35$ tokens even after corrupting between $40$-$50$\% of the tokens via random edits (i.e., substitutions, insertions or deletions). For the Alpaca-7B model, we conduct a case study on the feasibility of watermarking responses to typical user instructions. Due to the lower entropy of the responses, detection is more difficult: around $25\%$ of the responses -- whose median length is around $100$ tokens -- are detectable with $p \leq 0.01$, and the watermark is also less robust to certain automated paraphrasing attacks we implement.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，可以在语言模型中植入水印，这些水印是对文本的扰动不变的，并且可以在一定的最大生成预算内保持水印的可读性。我们使用一个随机水印密钥来生成水印文本，其中每个字符串都是基于随机数列的映射。为检测水印文本，任何知道水印密钥的人都可以对文本进行对齐。我们在两种抽样方式下实现了这种水印方法：倒计时间抽样和最小值抽样。我们在三个语言模型（OPT-1.3B、LLaMA-7B和Alpaca-7B）上实验 validate了这种水印方法的统计能力和对各种重建攻击的Robustness。结果显示，对OPT-1.3B和LLaMA-7B模型来说，我们可以在35个字符串上（即40%-50%的扰动）检测水印文本（p ≤ 0.01）。对Alpaca-7B模型来说，我们进行了一个案例研究，发现在响应 тиppy  instrucions 上植入水印的可能性较低，只有25%的响应可以在p ≤ 0.01的概率下检测，并且水印在某些自动重建攻击下也显示了较弱的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-structure-of-cognitive-tasks-with-transfer-learning"><a href="#Evaluating-the-structure-of-cognitive-tasks-with-transfer-learning" class="headerlink" title="Evaluating the structure of cognitive tasks with transfer learning"></a>Evaluating the structure of cognitive tasks with transfer learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02408">http://arxiv.org/abs/2308.02408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bruno Aristimunha, Raphael Y. de Camargo, Walter H. Lopez Pinaya, Sylvain Chevallier, Alexandre Gramfort, Cedric Rommel</li>
<li>for: 这个研究旨在investigate deep learning representation transferability in EEG decoding tasks, in order to address the challenge of limited labelled data.</li>
<li>methods: 研究使用state-of-the-art decoding models on two recently released EEG datasets, ERP CORE和M$^3$CV, with over 140 subjects and 11 cognitive tasks.  measure transferability by pre-training deep neural networks on one task and assessing their ability to decode subsequent tasks.</li>
<li>results: 实验结果显示，即使使用线性探测传输，也可以获得显著改善 decoding performance，比对纯粹supervisedapproach增加28%。此外，发现certain decoding paradigms elicit specific and narrow brain activities, while others benefit from pre-training on a broad range of representations.<details>
<summary>Abstract</summary>
Electroencephalography (EEG) decoding is a challenging task due to the limited availability of labelled data. While transfer learning is a promising technique to address this challenge, it assumes that transferable data domains and task are known, which is not the case in this setting. This study investigates the transferability of deep learning representations between different EEG decoding tasks. We conduct extensive experiments using state-of-the-art decoding models on two recently released EEG datasets, ERP CORE and M$^3$CV, containing over 140 subjects and 11 distinct cognitive tasks. We measure the transferability of learned representations by pre-training deep neural networks on one task and assessing their ability to decode subsequent tasks. Our experiments demonstrate that, even with linear probing transfer, significant improvements in decoding performance can be obtained, with gains of up to 28% compare with the pure supervised approach. Additionally, we discover evidence that certain decoding paradigms elicit specific and narrow brain activities, while others benefit from pre-training on a broad range of representations. By revealing which tasks transfer well and demonstrating the benefits of transfer learning for EEG decoding, our findings have practical implications for mitigating data scarcity in this setting. The transfer maps generated also provide insights into the hierarchical relations between cognitive tasks, hence enhancing our understanding of how these tasks are connected from a neuroscientific standpoint.
</details>
<details>
<summary>摘要</summary>
电enzephalography（EEG）解oding是一个挑战性的任务，因为标注数据的可用性有限。而转移学习是一种有前途的技术，它假设有可转移的数据领域和任务，但这不是这个设定中的情况。这项研究探讨了EEG解oding任务中深度学习表示的可转移性。我们在两个最新发布的EEG数据集，ERP CORE和M$^3$CV，上进行了广泛的实验，这两个数据集包含了140名参与者和11种不同的认知任务。我们测量了深度神经网络在不同任务之间的可转移性，通过在一个任务上预训练深度神经网络，并评估它在后续任务上的解oding性能。我们的实验表明，即使使用线性探索传输，也可以获得显著改善，与纯粹监督方法相比，提高达28%。此外，我们发现了一些解oding方法会产生特定和窄频谱的大脑活动，而其他方法则需要预训练在广泛的表示上。我们的发现有实际意义，可以减轻EEG解oding中的数据缺乏问题。同时，我们生成的传输地图也提供了认知任务之间的层次关系，从神经科学的角度来看，这有助于我们更好地理解这些任务之间的连接。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-algorithms-for-k-center-on-graphs"><a href="#Dynamic-algorithms-for-k-center-on-graphs" class="headerlink" title="Dynamic algorithms for k-center on graphs"></a>Dynamic algorithms for k-center on graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15557">http://arxiv.org/abs/2307.15557</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/swati1024/torrents">https://github.com/swati1024/torrents</a></li>
<li>paper_authors: Emilio Cruciani, Sebastian Forster, Gramoz Goranci, Yasamin Nazari, Antonis Skarlatos</li>
<li>for: 本研究的目的是提出首个高效的动态图-$k$-中心问题解决方案。</li>
<li>methods: 本文使用了 deterministic decremental $(2+\epsilon)$-approximation algorithm和 randomized incremental $(4+\epsilon)$-approximation algorithm，both with amortized update time $kn^{o(1)}$ for weighted graphs。</li>
<li>results: 本文获得了一个fully dynamic $(2+\epsilon)$-approximation algorithm for the $k$-center problem，with worst-case update time that is within a factor $k$ of the state-of-the-art upper bound for maintaining $(1+\epsilon)$-approximate single-source distances in graphs。<details>
<summary>Abstract</summary>
In this paper we give the first efficient algorithms for the $k$-center problem on dynamic graphs undergoing edge updates. In this problem, the goal is to partition the input into $k$ sets by choosing $k$ centers such that the maximum distance from any data point to the closest center is minimized. It is known that it is NP-hard to get a better than $2$ approximation for this problem.   While in many applications the input may naturally be modeled as a graph, all prior works on $k$-center problem in dynamic settings are on metrics. In this paper, we give a deterministic decremental $(2+\epsilon)$-approximation algorithm and a randomized incremental $(4+\epsilon)$-approximation algorithm, both with amortized update time $kn^{o(1)}$ for weighted graphs. Moreover, we show a reduction that leads to a fully dynamic $(2+\epsilon)$-approximation algorithm for the $k$-center problem, with worst-case update time that is within a factor $k$ of the state-of-the-art upper bound for maintaining $(1+\epsilon)$-approximate single-source distances in graphs. Matching this bound is a natural goalpost because the approximate distances of each vertex to its center can be used to maintain a $(2+\epsilon)$-approximation of the graph diameter and the fastest known algorithms for such a diameter approximation also rely on maintaining approximate single-source distances.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提供了首次有效的动态图-$k$-中心问题算法。在这个问题中，目标是将输入分成$k$个集合，通过选择$k$个中心，以最小化最大数据点与最近中心之间的距离。已知这个问题是NP困难的，无法获得更好于2的近似值。在许多应用中，输入可能自然地表示为图，但所有之前的动态设置-$k$-中心问题研究都是基于度量。在这篇论文中，我们提供了一个 deterministic 的减少$(2+\epsilon)$-近似算法和一个随机的增量$(4+\epsilon)$-近似算法，它们都有平均更新时间为$kn^{o(1)}$。此外，我们还提供了一个减少算法，它可以在最坏情况下更新时间与状态艺术的最佳上限相比，这个上限是为维护$(1+\epsilon)$-近似单源距离的最佳算法。这个目标是自然的因为每个顶点的中心的近似距离可以用来维护$(2+\epsilon)$-近似图 Diameter 和最快的知识算法。
</details></li>
</ul>
<hr>
<h2 id="On-the-Trade-off-Between-Efficiency-and-Precision-of-Neural-Abstraction"><a href="#On-the-Trade-off-Between-Efficiency-and-Precision-of-Neural-Abstraction" class="headerlink" title="On the Trade-off Between Efficiency and Precision of Neural Abstraction"></a>On the Trade-off Between Efficiency and Precision of Neural Abstraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15546">http://arxiv.org/abs/2307.15546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alec Edwards, Mirco Giacobbe, Alessandro Abate</li>
<li>for: 这篇论文主要目的是提出了一种基于神经网络的形式准确模型，并研究了这种模型在不同场景下的使用和优点。</li>
<li>methods: 这篇论文使用了形式幂学 Synthesis 技术，通过设计不同类型的神经网络来生成准确的模型。</li>
<li>results: 研究发现，不同类型的神经网络模型在不同场景下具有不同的优点和缺点，并且可以根据具体的应用场景选择合适的模型。<details>
<summary>Abstract</summary>
Neural abstractions have been recently introduced as formal approximations of complex, nonlinear dynamical models. They comprise a neural ODE and a certified upper bound on the error between the abstract neural network and the concrete dynamical model. So far neural abstractions have exclusively been obtained as neural networks consisting entirely of $ReLU$ activation functions, resulting in neural ODE models that have piecewise affine dynamics, and which can be equivalently interpreted as linear hybrid automata. In this work, we observe that the utility of an abstraction depends on its use: some scenarios might require coarse abstractions that are easier to analyse, whereas others might require more complex, refined abstractions. We therefore consider neural abstractions of alternative shapes, namely either piecewise constant or nonlinear non-polynomial (specifically, obtained via sigmoidal activations). We employ formal inductive synthesis procedures to generate neural abstractions that result in dynamical models with these semantics. Empirically, we demonstrate the trade-off that these different neural abstraction templates have vis-a-vis their precision and synthesis time, as well as the time required for their safety verification (done via reachability computation). We improve existing synthesis techniques to enable abstraction of higher-dimensional models, and additionally discuss the abstraction of complex neural ODEs to improve the efficiency of reachability analysis for these models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beating-Backdoor-Attack-at-Its-Own-Game"><a href="#Beating-Backdoor-Attack-at-Its-Own-Game" class="headerlink" title="Beating Backdoor Attack at Its Own Game"></a>Beating Backdoor Attack at Its Own Game</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15539">http://arxiv.org/abs/2307.15539</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/damianliumin/non-adversarial_backdoor">https://github.com/damianliumin/non-adversarial_backdoor</a></li>
<li>paper_authors: Min Liu, Alberto Sangiovanni-Vincentelli, Xiangyu Yue</li>
<li>for: 防止深度神经网络（DNNs）受到后门攻击，保护模型的正常运行。</li>
<li>methods: 基于非对抗性后门攻击，对恶意样本进行探测和毒素处理，以防止后门攻击。</li>
<li>results: 对多个benchmark和不同的攻击方法进行了广泛的实验，结果表明我们的方法可以达到现有防御方法的最高效果，同时具有最低的清洁数据影响。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are vulnerable to backdoor attack, which does not affect the network's performance on clean data but would manipulate the network behavior once a trigger pattern is added. Existing defense methods have greatly reduced attack success rate, but their prediction accuracy on clean data still lags behind a clean model by a large margin. Inspired by the stealthiness and effectiveness of backdoor attack, we propose a simple but highly effective defense framework which injects non-adversarial backdoors targeting poisoned samples. Following the general steps in backdoor attack, we detect a small set of suspected samples and then apply a poisoning strategy to them. The non-adversarial backdoor, once triggered, suppresses the attacker's backdoor on poisoned data, but has limited influence on clean data. The defense can be carried out during data preprocessing, without any modification to the standard end-to-end training pipeline. We conduct extensive experiments on multiple benchmarks with different architectures and representative attacks. Results demonstrate that our method achieves state-of-the-art defense effectiveness with by far the lowest performance drop on clean data. Considering the surprising defense ability displayed by our framework, we call for more attention to utilizing backdoor for backdoor defense. Code is available at https://github.com/damianliumin/non-adversarial_backdoor.
</details>
<details>
<summary>摘要</summary>
Inspired by the stealthiness and effectiveness of backdoor attacks, we propose a simple but highly effective defense framework that injects non-adversarial backdoors targeting poisoned samples. We follow the general steps of backdoor attacks and detect a small set of suspected samples, and then apply a poisoning strategy to them. The non-adversarial backdoor, once triggered, suppresses the attacker's backdoor on poisoned data but has limited influence on clean data.Our defense can be carried out during data preprocessing, without modifying the standard end-to-end training pipeline. We conduct extensive experiments on multiple benchmarks with different architectures and representative attacks. The results show that our method achieves state-of-the-art defense effectiveness with the lowest performance drop on clean data.Considering the surprising defense ability displayed by our framework, we call for more attention to utilizing backdoors for backdoor defense. Our code is available at https://github.com/damianliumin/non-adversarial_backdoor.
</details></li>
</ul>
<hr>
<h2 id="RFID-Assisted-Indoor-Localization-Using-Hybrid-Wireless-Data-Fusion"><a href="#RFID-Assisted-Indoor-Localization-Using-Hybrid-Wireless-Data-Fusion" class="headerlink" title="RFID-Assisted Indoor Localization Using Hybrid Wireless Data Fusion"></a>RFID-Assisted Indoor Localization Using Hybrid Wireless Data Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02410">http://arxiv.org/abs/2308.02410</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abouzar Ghavami, Ali Abedi</li>
<li>for: 本研究旨在提出一种混合部分基于RFID追踪设备和多种IoT无线通信协议的indoor定位方法，以减少RFID标签成本。</li>
<li>methods: 本方法使用开发的RFID追踪设备和多种IoT无线通信协议，包括蓝牙、WiFi和ZigBee等，实现了indoor定位。</li>
<li>results: 实验结果验证了分析结果，并且表明了 hybrid 方法可以减少RFID标签数量而不影响定位精度。<details>
<summary>Abstract</summary>
Wireless localization is essential for tracking objects in indoor environments. Internet of Things (IoT) enables localization through its diverse wireless communication protocols. In this paper, a hybrid section-based indoor localization method using a developed Radio Frequency Identification (RFID) tracking device and multiple IoT wireless technologies is proposed. In order to reduce the cost of the RFID tags, the tags are installed only on the borders of each section. The RFID tracking device identifies the section, and the proposed wireless hybrid method finds the location of the object inside the section. The proposed hybrid method is analytically driven by linear location estimates obtained from different IoT wireless technologies. The experimental results using developed RFID tracking device and RSSI-based localization for Bluetooth, WiFi and ZigBee technologies verifies the analytical results.
</details>
<details>
<summary>摘要</summary>
无线地位确定是内部环境中对物品跟踪的重要组成部分。互联网东西（IoT）使得地位确定可以通过其多种无线通信协议。本文提出了一种混合段基地的indoor地位确定方法，使用开发的Radio Frequency Identification（RFID）跟踪设备和多种IoT无线技术。为了降低RFID标签的成本，标签仅在每个段的边部安装。RFID跟踪设备确定段，提出的混合方法在段内确定物品的位置。提议的混合方法由不同的IoT无线技术提供的线性位置估计驱动。实验结果使用开发的RFID跟踪设备和RSSI基于Bluetooth、WiFi和ZigBee技术的本地化位置确定验证了分析结果。
</details></li>
</ul>
<hr>
<h2 id="The-Applicability-of-Federated-Learning-to-Official-Statistics"><a href="#The-Applicability-of-Federated-Learning-to-Official-Statistics" class="headerlink" title="The Applicability of Federated Learning to Official Statistics"></a>The Applicability of Federated Learning to Official Statistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15503">http://arxiv.org/abs/2307.15503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Stock, Oliver Hauke, Julius Weißmann, Hannes Federrath</li>
<li>for: 这项研究探讨了 Federated Learning（FL）在官方统计领域的潜在可能性，并证明 FL 模型的性能可以与中央学习方法相比。同时，通过保护数据持有者的隐私，FL 的使用可以拓宽数据访问，最终提高官方统计。</li>
<li>methods: 该研究通过三个不同的应用场景进行了模拟，包括医疗保险数据集、细颗粒污染数据集和移动 радио覆盖数据集。这些数据集都来自于官方统计领域相关的领域。我们提供了详细的分析结果，包括中央和 FL 算法性能比较。在所有三个应用场景中，我们成功地使用 FL 模型来训练达到中央模型标准性能水平。</li>
<li>results: 我们的关键观察结论和其在实践中的应用有关的建议。我们得出结论，FL 有可能成为未来官方统计领域的重要技术。<details>
<summary>Abstract</summary>
This work investigates the potential of Federated Learning (FL) for official statistics and shows how well the performance of FL models can keep up with centralized learning methods. At the same time, its utilization can safeguard the privacy of data holders, thus facilitating access to a broader range of data and ultimately enhancing official statistics. By simulating three different use cases, important insights on the applicability of the technology are gained. The use cases are based on a medical insurance data set, a fine dust pollution data set and a mobile radio coverage data set - all of which are from domains close to official statistics. We provide a detailed analysis of the results, including a comparison of centralized and FL algorithm performances for each simulation. In all three use cases, we were able to train models via FL which reach a performance very close to the centralized model benchmarks. Our key observations and their implications for transferring the simulations into practice are summarized. We arrive at the conclusion that FL has the potential to emerge as a pivotal technology in future use cases of official statistics.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这项研究探讨了联邦学习（FL）在官方统计中的潜力，并比较了中央学习方法的性能。研究表明，FL可以保护数据持有者的隐私，同时维护模型的性能，因此成为官方统计中重要的技术。研究使用医疗保险、细颗粒污染和移动广播覆盖等三个不同的应用场景进行模拟，并提供了详细的分析结果。研究发现，FL模型在所有三个应用场景中都可以达到中央模型标准的性能水平，并提出了关键观察和未来实践中的启示。研究结论是，FL有望成为未来官方统计中的重要技术。
</details></li>
</ul>
<hr>
<h2 id="AbDiffuser-Full-Atom-Generation-of-In-Vitro-Functioning-Antibodies"><a href="#AbDiffuser-Full-Atom-Generation-of-In-Vitro-Functioning-Antibodies" class="headerlink" title="AbDiffuser: Full-Atom Generation of In-Vitro Functioning Antibodies"></a>AbDiffuser: Full-Atom Generation of In-Vitro Functioning Antibodies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05027">http://arxiv.org/abs/2308.05027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karolis Martinkus, Jan Ludwiczak, Kyunghyun Cho, Wei-Ching Liang, Julien Lafrance-Vanasse, Isidro Hotzel, Arvind Rajpal, Yan Wu, Richard Bonneau, Vladimir Gligorijevic, Andreas Loukas</li>
<li>for: 本研究旨在提出一种基于等变量和物理约束的扩散模型，用于同时生成抗体三维结构和序列。</li>
<li>methods: 该模型基于一种新的蛋白结构表示方法，利用一种新的对称抗体体积架构，并使用强 diffusion 约束来改进减阈过程。</li>
<li>results: 实验表明，AbDiffuser 可以准确地生成与参照集的序列和结构性质高度相似的抗体。实验室实验证实了所有16种 HER2 抗体的高水平表达，并且57.1%的选择设计是紧紧的绑定者。<details>
<summary>Abstract</summary>
We introduce AbDiffuser, an equivariant and physics-informed diffusion model for the joint generation of antibody 3D structures and sequences. AbDiffuser is built on top of a new representation of protein structure, relies on a novel architecture for aligned proteins, and utilizes strong diffusion priors to improve the denoising process. Our approach improves protein diffusion by taking advantage of domain knowledge and physics-based constraints; handles sequence-length changes; and reduces memory complexity by an order of magnitude enabling backbone and side chain generation. We validate AbDiffuser in silico and in vitro. Numerical experiments showcase the ability of AbDiffuser to generate antibodies that closely track the sequence and structural properties of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies discovered were expressed at high levels and that 57.1% of selected designs were tight binders.
</details>
<details>
<summary>摘要</summary>
我们介绍AbDiffuser，一个equivariant和physics-informed扩散模型，用于同时生成抗体三维结构和序列。AbDiffuser基于一个新的蛋白结构表示方法，使用一个新的对称蛋白架构，并利用强大的扩散假设来改善整理过程。我们的方法可以改善蛋白扩散，利用domain知识和物理基于的限制；处理序列长度变化；并降低内存复杂度，实现脊梁和侧链生成。我们在silico和in vitro验证AbDiffuser，实验结果显示AbDiffuser能够将抗体的序列和结构属性与参考集 closely track。实验验证确认了所有16个HER2抗体的高水平表达，并证明57.1%的选择设计是紧系者。
</details></li>
</ul>
<hr>
<h2 id="Curiosity-Driven-Reinforcement-Learning-based-Low-Level-Flight-Control"><a href="#Curiosity-Driven-Reinforcement-Learning-based-Low-Level-Flight-Control" class="headerlink" title="Curiosity-Driven Reinforcement Learning based Low-Level Flight Control"></a>Curiosity-Driven Reinforcement Learning based Low-Level Flight Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15724">http://arxiv.org/abs/2307.15724</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/a-ramezani/cdrl-l2fc_u_hcm">https://github.com/a-ramezani/cdrl-l2fc_u_hcm</a></li>
<li>paper_authors: Amir Ramezani Dooraki, Alexandros Iosifidis</li>
<li>for: 这个论文是为了研究人工智能中的curiosity drivenserial，并提出了一种基于惊喜的自主学习控制算法，以便 quadcopter 通过障碍物进行控制并实现最佳奖励。</li>
<li>methods: 该论文使用了各种方法，包括基于奖励的回归学习算法、新的curiosity方法基于预测误差、视觉化效果的测试和评估。</li>
<li>results: 测试结果显示，该算法可以学习优化策略，最大化奖励，而其他算法则无法实现。<details>
<summary>Abstract</summary>
Curiosity is one of the main motives in many of the natural creatures with measurable levels of intelligence for exploration and, as a result, more efficient learning. It makes it possible for humans and many animals to explore efficiently by searching for being in states that make them surprised with the goal of learning more about what they do not know. As a result, while being curious, they learn better. In the machine learning literature, curiosity is mostly combined with reinforcement learning-based algorithms as an intrinsic reward. This work proposes an algorithm based on the drive of curiosity for autonomous learning to control by generating proper motor speeds from odometry data. The quadcopter controlled by our proposed algorithm can pass through obstacles while controlling the Yaw direction of the quad-copter toward the desired location. To achieve that, we also propose a new curiosity approach based on prediction error. We ran tests using on-policy, off-policy, on-policy plus curiosity, and the proposed algorithm and visualized the effect of curiosity in evolving exploration patterns. Results show the capability of the proposed algorithm to learn optimal policy and maximize reward where other algorithms fail to do so.
</details>
<details>
<summary>摘要</summary>
尝尝是许多自然生物具有衡量水平的智慧所展现出的主要动机之一，用于探索和因此更有效地学习。它使人类和许多动物能够有效地探索，通过搜寻未知状态来带来惊喜，并且从而学习更多。在机器学习文献中，尝尝通常与回归学习算法结合使用，作为内在奖励。这项工作提议一种基于尝尝的自主学习控制算法，通过生成相应的机动速度来从ODometry数据中生成。控制我们提议的四旋翼机器人可以通过避免障碍物，同时控制四旋翼机器人的纬度方向向所需的位置。为了实现这一点，我们还提出了一种基于预测误差的新尝尝方法。我们在使用on-policy、off-policy、on-policy plus curiosity和我们提议的算法进行测试，并将其视觉化为探索模式的演变。结果显示我们的算法能够学习优化策略，并在其他算法失败之前最大化奖励。
</details></li>
</ul>
<hr>
<h2 id="From-continuous-time-formulations-to-discretization-schemes-tensor-trains-and-robust-regression-for-BSDEs-and-parabolic-PDEs"><a href="#From-continuous-time-formulations-to-discretization-schemes-tensor-trains-and-robust-regression-for-BSDEs-and-parabolic-PDEs" class="headerlink" title="From continuous-time formulations to discretization schemes: tensor trains and robust regression for BSDEs and parabolic PDEs"></a>From continuous-time formulations to discretization schemes: tensor trains and robust regression for BSDEs and parabolic PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15496">http://arxiv.org/abs/2307.15496</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lorenzrichter/PDE-backward-solver">https://github.com/lorenzrichter/PDE-backward-solver</a></li>
<li>paper_authors: Lorenz Richter, Leon Sallandt, Nikolas Nüsken</li>
<li>for: 解决高维partial differential equations (PDEs)的数值近似问题，即卷积环境中的呼啸问题。</li>
<li>methods: 利用Monte Carlo方法和变分方法，使用神经网络来近似函数。基于tensor train的框架，将拥有层次结构的问题转化为 backwards stochastic differential equations和回推方法。</li>
<li>results: 提出了一种新的数值策略，可以同时实现高精度和高效计算。理论和实验研究表明，这种方法可以在许多情况下获得一个有利的妥协，即高精度和高效计算之间。<details>
<summary>Abstract</summary>
The numerical approximation of partial differential equations (PDEs) poses formidable challenges in high dimensions since classical grid-based methods suffer from the so-called curse of dimensionality. Recent attempts rely on a combination of Monte Carlo methods and variational formulations, using neural networks for function approximation. Extending previous work (Richter et al., 2021), we argue that tensor trains provide an appealing framework for parabolic PDEs: The combination of reformulations in terms of backward stochastic differential equations and regression-type methods holds the promise of leveraging latent low-rank structures, enabling both compression and efficient computation. Emphasizing a continuous-time viewpoint, we develop iterative schemes, which differ in terms of computational efficiency and robustness. We demonstrate both theoretically and numerically that our methods can achieve a favorable trade-off between accuracy and computational efficiency. While previous methods have been either accurate or fast, we have identified a novel numerical strategy that can often combine both of these aspects.
</details>
<details>
<summary>摘要</summary>
NUMERICAL APPROXIMATION OF PARTIAL DIFFERENTIAL EQUATIONS (PDEs) IN HIGH DIMENSIONS PRESENTS DIFFICULT CHALLENGES. CLASSICAL GRID-BASED METHODS SUFFER FROM THE SO-CALLED CURSE OF DIMENSIONALITY. RECENT ATTEMPTS USE A COMBINATION OF MONTE CARLO METHODS AND VARIATIONAL FORMULATIONS WITH NEURAL NETWORKS FOR FUNCTION APPROXIMATION. WE ARGUE THAT TENSOR TRAINS PROVIDE AN ATTRACTIVE FRAMEWORK FOR PARABOLIC PDEs. COMBINING REFORMULATIONS IN TERMS OF BACKWARD STOCHASTIC DIFFERENTIAL EQUATIONS AND REGRESSION-TYPE METHODS CAN LEVERAGE LATENT LOW-RANK STRUCTURES, ENABLING BOTH COMPRESSION AND EFFICIENT COMPUTATION. EMPHASIZING A CONTINUOUS-TIME VIEWPOINT, WE DEVELOP ITERATIVE SCHEMES THAT DIFFER IN TERMS OF COMPUTATIONAL EFFICIENCY AND ROBUSTNESS. WE DEMONSTRATE THEORETICALLY AND NUMERICALLY THAT OUR METHODS CAN ACHIEVE A FAVORABLE TRADE-OFF BETWEEN ACCURACY AND COMPUTATIONAL EFFICIENCY. PREVIOUS METHODS HAVE BEEN EITHER ACCURATE OR FAST, BUT WE HAVE IDENTIFIED A NOVEL NUMERICAL STRATEGY THAT CAN OFTEN COMBINE BOTH OF THESE ASPECTS.
</details></li>
</ul>
<hr>
<h2 id="FeedbackLogs-Recording-and-Incorporating-Stakeholder-Feedback-into-Machine-Learning-Pipelines"><a href="#FeedbackLogs-Recording-and-Incorporating-Stakeholder-Feedback-into-Machine-Learning-Pipelines" class="headerlink" title="FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines"></a>FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15475">http://arxiv.org/abs/2307.15475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Barker, Emma Kallina, Dhananjay Ashok, Katherine M. Collins, Ashley Casovan, Adrian Weller, Ameet Talwalkar, Valerie Chen, Umang Bhatt</li>
<li>for: 这篇论文是为了提高机器学习（ML）管道的可追溯性和可信度而写的。</li>
<li>methods: 这篇论文提出了一种名为“FeedbackLogs”的新方法，用于跟踪多个潜在参与者的反馈。FeedbackLogs是ML管道的现有文档的补充，可以记录反馈收集过程中的重要细节、反馈内容以及如何将反馈纳入到管道中。</li>
<li>results: 这篇论文提出了一种可以作为算法审核的证据，以及一种用于记录基于潜在参与者反馈的更新的工具。<details>
<summary>Abstract</summary>
Even though machine learning (ML) pipelines affect an increasing array of stakeholders, there is little work on how input from stakeholders is recorded and incorporated. We propose FeedbackLogs, addenda to existing documentation of ML pipelines, to track the input of multiple stakeholders. Each log records important details about the feedback collection process, the feedback itself, and how the feedback is used to update the ML pipeline. In this paper, we introduce and formalise a process for collecting a FeedbackLog. We also provide concrete use cases where FeedbackLogs can be employed as evidence for algorithmic auditing and as a tool to record updates based on stakeholder feedback.
</details>
<details>
<summary>摘要</summary>
尽管机器学习（ML）管道影响越来越多的利益相关者，但有少量的研究关于如何记录和整合利益相关者的意见。我们提议使用 FeedbackLogs，增加现有的机器学习管道文档，以跟踪多个利益相关者的输入。每个日志记录了关键的反馈收集过程、反馈内容和如何使用反馈更新机器学习管道。在这篇论文中，我们介绍了和正式化收集FeedbackLog的过程。我们还提供了具体的应用场景，其中FeedbackLog可以作为算法审核的证据，以及记录基于利益相关者反馈的更新。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Noisy-Label-Learning-in-Real-world-Annotation-Scenarios-from-the-Noise-type-Perspective"><a href="#Rethinking-Noisy-Label-Learning-in-Real-world-Annotation-Scenarios-from-the-Noise-type-Perspective" class="headerlink" title="Rethinking Noisy Label Learning in Real-world Annotation Scenarios from the Noise-type Perspective"></a>Rethinking Noisy Label Learning in Real-world Annotation Scenarios from the Noise-type Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16889">http://arxiv.org/abs/2307.16889</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fuxiailab/protosemi">https://github.com/fuxiailab/protosemi</a></li>
<li>paper_authors: Renyu Zhu, Haoyu Liu, Runze Wu, Minmin Lin, Tangjie Lv, Changjie Fan, Haobo Wang</li>
<li>for: 本文研究了在实际标注场景中学习含有噪声标签的问题，噪声可以分为两类：事实噪声和抽象噪声。</li>
<li>methods: 我们提出了一种基于样本选择的噪声标签学习方法，称为Proto-semi。该方法首先将所有样本分为自信量高和自信量低两个集合，并利用自信量高集合 constructed protoype vectors capture 类别特征。然后，对不确定样本与 protoype vectors 之间的距离进行计算，以便噪声分类。根据这些距离，标签 either corrected 或 retained，从而改善自信量高和自信量低两个集合。最后，我们引入了一种半supervised learning方法，以提高训练。</li>
<li>results: 对一个实际标注数据集进行实验，证明了Proto-semi 能够有效地处理含有噪声标签的学习问题。同时， prototype-based 重新分配策略被证明可以减轻噪声标签的负面影响。我们的代码和数据可以在<a target="_blank" rel="noopener" href="https://github.com/fuxiAIlab/ProtoSemi">https://github.com/fuxiAIlab/ProtoSemi</a> 上获取。<details>
<summary>Abstract</summary>
In this paper, we investigate the problem of learning with noisy labels in real-world annotation scenarios, where noise can be categorized into two types: factual noise and ambiguity noise. To better distinguish these noise types and utilize their semantics, we propose a novel sample selection-based approach for noisy label learning, called Proto-semi. Proto-semi initially divides all samples into the confident and unconfident datasets via warm-up. By leveraging the confident dataset, prototype vectors are constructed to capture class characteristics. Subsequently, the distances between the unconfident samples and the prototype vectors are calculated to facilitate noise classification. Based on these distances, the labels are either corrected or retained, resulting in the refinement of the confident and unconfident datasets. Finally, we introduce a semi-supervised learning method to enhance training. Empirical evaluations on a real-world annotated dataset substantiate the robustness of Proto-semi in handling the problem of learning from noisy labels. Meanwhile, the prototype-based repartitioning strategy is shown to be effective in mitigating the adverse impact of label noise. Our code and data are available at https://github.com/fuxiAIlab/ProtoSemi.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了在现实世界注解场景中学习含有噪声标签的问题。噪声可以分为两类：事实噪声和抽象噪声。为了更好地 distinguish these noise types和利用它们的 semantics，我们提议了一种基于样本选择的噪声标签学习方法，called Proto-semi。Proto-semi首先将所有样本分为confident和uncertain datasetsvia warm-up。通过利用confident dataset，我们构造了类特征表示vector。然后，我们计算了uncertain samples和类特征表示vector之间的距离，以便噪声分类。根据这些距离，我们可以更正或保留标签，从而得到了含有修复的confident和uncertain datasets。最后，我们引入了一种半supervised learning方法，以提高训练。Empirical evaluations on a real-world annotated dataset substantiate the robustness of Proto-semi in handling the problem of learning from noisy labels. Meanwhile, the prototype-based repartitioning strategy is shown to be effective in mitigating the adverse impact of label noise.我们的代码和数据可以在https://github.com/fuxiAIlab/ProtoSemi中找到。
</details></li>
</ul>
<hr>
<h2 id="Testing-the-Depth-of-ChatGPT’s-Comprehension-via-Cross-Modal-Tasks-Based-on-ASCII-Art-GPT3-5’s-Abilities-in-Regard-to-Recognizing-and-Generating-ASCII-Art-Are-Not-Totally-Lacking"><a href="#Testing-the-Depth-of-ChatGPT’s-Comprehension-via-Cross-Modal-Tasks-Based-on-ASCII-Art-GPT3-5’s-Abilities-in-Regard-to-Recognizing-and-Generating-ASCII-Art-Are-Not-Totally-Lacking" class="headerlink" title="Testing the Depth of ChatGPT’s Comprehension via Cross-Modal Tasks Based on ASCII-Art: GPT3.5’s Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking"></a>Testing the Depth of ChatGPT’s Comprehension via Cross-Modal Tasks Based on ASCII-Art: GPT3.5’s Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16806">http://arxiv.org/abs/2307.16806</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Bayani</li>
<li>for: 本研究旨在探讨GPT3.5模型在视觉任务中的能力，以及对图像的理解和生成能力。</li>
<li>methods: 本研究使用了GPT3.5模型，对图像进行了不同的转换和处理，以评估模型的表现。</li>
<li>results: 研究发现，GPT3.5模型在图像认识和分类任务中表现出色，能够准确地识别和描述图像的不同部分。此外，模型还能够生成高质量的图像。<details>
<summary>Abstract</summary>
Over the eight months since its release, ChatGPT and its underlying model, GPT3.5, have garnered massive attention, due to their potent mix of capability and accessibility. While a niche-industry of papers have emerged examining the scope of capabilities these models possess, the information fed to and extracted from these networks has been either natural language text or stylized, code-like language. Drawing inspiration from the prowess we expect a truly human-level intelligent agent to have across multiple signal modalities, in this work we examine GPT3.5's aptitude for visual tasks, where the inputs feature content provided as ASCII-art without overt distillation into a lingual summary. We conduct experiments analyzing the model's performance on image recognition tasks after various transforms typical in visual settings, trials investigating knowledge of image parts, and tasks covering image generation.
</details>
<details>
<summary>摘要</summary>
Over the past eight months since its release, ChatGPT and its underlying model, GPT3.5, have received massive attention due to their powerful combination of capabilities and accessibility. While a niche industry of papers has emerged examining the scope of capabilities these models possess, the information fed to and extracted from these networks has been limited to natural language text or stylized, code-like language. Inspired by the versatility we expect from a truly human-level intelligent agent, we explore GPT3.5's ability for visual tasks, where the inputs are provided as ASCII art without any explicit lingual summaries. We conduct experiments analyzing the model's performance on image recognition tasks after various transforms commonly used in visual settings, trials investigating the model's understanding of image parts, and tasks involving image generation.
</details></li>
</ul>
<hr>
<h2 id="LUCID-GAN-Conditional-Generative-Models-to-Locate-Unfairness"><a href="#LUCID-GAN-Conditional-Generative-Models-to-Locate-Unfairness" class="headerlink" title="LUCID-GAN: Conditional Generative Models to Locate Unfairness"></a>LUCID-GAN: Conditional Generative Models to Locate Unfairness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15466">http://arxiv.org/abs/2307.15466</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/integrated-intelligence-lab/canonical_sets">https://github.com/integrated-intelligence-lab/canonical_sets</a></li>
<li>paper_authors: Andres Algaba, Carmen Mazijn, Carina Prunkl, Jan Danckaert, Vincent Ginis</li>
<li>for: 检测黑盒模型中的不公正偏见</li>
<li>methods: 使用LUCID-GAN方法，通过生成幂等输入，暴露模型的内部逻辑中的可能的不公正偏见</li>
<li>results: 在UCI成人和COMPAS数据集上对黑盒模型进行了实验，并证明了LUCID-GAN方法可以无需访问训练数据，检测黑盒模型中的不公正偏见。<details>
<summary>Abstract</summary>
Most group fairness notions detect unethical biases by computing statistical parity metrics on a model's output. However, this approach suffers from several shortcomings, such as philosophical disagreement, mutual incompatibility, and lack of interpretability. These shortcomings have spurred the research on complementary bias detection methods that offer additional transparency into the sources of discrimination and are agnostic towards an a priori decision on the definition of fairness and choice of protected features. A recent proposal in this direction is LUCID (Locating Unfairness through Canonical Inverse Design), where canonical sets are generated by performing gradient descent on the input space, revealing a model's desired input given a preferred output. This information about the model's mechanisms, i.e., which feature values are essential to obtain specific outputs, allows exposing potential unethical biases in its internal logic. Here, we present LUCID-GAN, which generates canonical inputs via a conditional generative model instead of gradient-based inverse design. LUCID-GAN has several benefits, including that it applies to non-differentiable models, ensures that canonical sets consist of realistic inputs, and allows to assess proxy and intersectional discrimination. We empirically evaluate LUCID-GAN on the UCI Adult and COMPAS data sets and show that it allows for detecting unethical biases in black-box models without requiring access to the training data.
</details>
<details>
<summary>摘要</summary>
大多数群体公平性理念通过计算统计偏见指标来检测不当偏见。然而，这种方法存在多个缺点，如哲学上的分歧、互不兼容和解释性的缺失。这些缺点激发了研究补偿偏见检测方法的研究，这些方法可以提供更多的透明度，了解歧视的来源，并且不需要先行决定公平性的定义和保护特征。一种最近提出的方案是LUCID（找到不公正的位置），它通过在输入空间上进行梯度下降来生成含义的集合，并显示模型对特定输出的愿望的输入。这些信息可以暴露模型内部的不公正偏见。在这篇文章中，我们提出LUCID-GAN（基于GAN的找到不公正的位置），它使用conditional生成模型而不是梯度下降来生成含义的集合。LUCID-GAN具有多种优点，包括适用于不 diferenciable模型、生成的含义集合是实际的输入、以及可以评估代理和交叉性歧视。我们对UCI成人和COMPAS数据集进行了实验，并证明了LUCID-GAN可以无需访问训练数据检测黑盒模型中的不公正偏见。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-machine-learning-shock-capturing-technique-for-high-order-solvers"><a href="#Unsupervised-machine-learning-shock-capturing-technique-for-high-order-solvers" class="headerlink" title="Unsupervised machine-learning shock-capturing technique for high-order solvers"></a>Unsupervised machine-learning shock-capturing technique for high-order solvers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00086">http://arxiv.org/abs/2308.00086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrés Mateo-Gabín, Kenza Tlales, Eusebio Valero, Esteban Ferrer, Gonzalo Rubio</li>
<li>for: 提高CFD代码的稳定性和效率，适用于复杂的 geometries 和 varied flow configurations。</li>
<li>methods: 基于 Gaussian Mixture Models (GMMs) 的无监督机器学习冲击捕捉算法，无需参数调整具有remarkable accuracy和 robustness。</li>
<li>results: 在多种测试 caso中，GMM感知器与现有方法相当，并且在高 Reynolds 数下表现出类似的效果，适用于supersonic flow 和高速燃烧等应用。<details>
<summary>Abstract</summary>
We present a novel unsupervised machine learning shock capturing algorithm based on Gaussian Mixture Models (GMMs). The proposed GMM sensor demonstrates remarkable accuracy in detecting shocks and is robust across diverse test cases without the need for parameter tuning. We compare the GMM-based sensor with state-of-the-art alternatives. All methods are integrated into a high-order compressible discontinuous Galerkin solver where artificial viscosity can be modulated to capture shocks. Supersonic test cases, including high Reynolds numbers, showcase the sensor's performance, demonstrating the same effectiveness as fine-tuned state-of-the-art sensors. %The nodal DG aproach allows for potential applications in sub-cell flux-differencing formulations, supersonic feature detection, and mesh refinement. The adaptive nature and ability to function without extensive training datasets make this GMM-based sensor suitable for complex geometries and varied flow configurations. Our study reveals the potential of unsupervised machine learning methods, exemplified by the GMM sensor, to improve the robustness and efficiency of advanced CFD codes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的无监督机器学习震动捕捉算法基于混合分布（GMM）。我们的GMM感测器能够准确检测震动并在多种测试 caso中显示出良好的Robust性，无需进行参数调整。我们与现有的状态艺术方法进行比较。所有方法都被 интегрирован到一个高阶可 compressible discontinuous Galerkin 解析器中，其中人工粘度可以调整以捕捉震动。我们使用supersonic测试 caso，包括高 Reynolds 数，来证明感测器的性能，显示与精心调整的现有状态艺术感测器一样有效。 nodal DG 方法允许在 sub-cell flux-differencing 表述、supersonic特征检测和 mesh 细化中应用。适应性和无需广泛的培训数据集使得这种 GMM 感测器适用于复杂的 geometries 和多种流体配置。我们的研究表明无监督机器学习方法，如 GMM 感测器，可以提高高效性和稳定性的进险CFD 代码。
</details></li>
</ul>
<hr>
<h2 id="Worrisome-Properties-of-Neural-Network-Controllers-and-Their-Symbolic-Representations"><a href="#Worrisome-Properties-of-Neural-Network-Controllers-and-Their-Symbolic-Representations" class="headerlink" title="Worrisome Properties of Neural Network Controllers and Their Symbolic Representations"></a>Worrisome Properties of Neural Network Controllers and Their Symbolic Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15456">http://arxiv.org/abs/2307.15456</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mimuw-rl/worrisome-nn">https://github.com/mimuw-rl/worrisome-nn</a></li>
<li>paper_authors: Jacek Cyranka, Kevin E M Church, Jean-Philippe Lessard</li>
<li>for: 研究控制器在简单强化学习问题中的稳定性问题。</li>
<li>methods: 使用神经网络控制器和其低神经和符号抽象。</li>
<li>results: 发现典型控制器可以达到高平均回报值，但同时也生成许多 persistently low-return 解决方案，这是一个非常不 desireable 性质，易受到敌对者利用。 simpler controllers 更容易生成 persistently bad solutions。 提供了一种系统性 robustness 研究算法，并证明存在 persistently solutions 和，在某些情况下， periodic orbits 的存在，使用计算机助力证明方法。<details>
<summary>Abstract</summary>
We raise concerns about controllers' robustness in simple reinforcement learning benchmark problems. We focus on neural network controllers and their low neuron and symbolic abstractions. A typical controller reaching high mean return values still generates an abundance of persistent low-return solutions, which is a highly undesirable property, easily exploitable by an adversary. We find that the simpler controllers admit more persistent bad solutions. We provide an algorithm for a systematic robustness study and prove existence of persistent solutions and, in some cases, periodic orbits, using a computer-assisted proof methodology.
</details>
<details>
<summary>摘要</summary>
我们对控制器的稳定性表示关注，特别是对于简单的问题学习 benchmark 中的神经网络控制器。我们发现，一般情况下，控制器可以获得高平均回数，但仍然生成丰富的持续低回数解，这是非常不愿意的危险性，可以轻易地被敌人利用。我们发现简单的控制器更易允许持续坏解。我们提供了一个系统性的稳定性研究 Algorithm，并证明了存在持续解和，在某些情况下， periodic orbit。我们使用了电脑支持的证明方法。
</details></li>
</ul>
<hr>
<h2 id="Autonomous-Payload-Thermal-Control"><a href="#Autonomous-Payload-Thermal-Control" class="headerlink" title="Autonomous Payload Thermal Control"></a>Autonomous Payload Thermal Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15438">http://arxiv.org/abs/2307.15438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alejandro D. Mousist</li>
<li>for: 这个研究是为了解决小型卫星中热控制问题，因为发电设备和科学仪器的空间受限，热控制困难，可能会影响元件寿命和任务性能。</li>
<li>methods: 这个研究使用深度强化学习框架，特别是Soft Actor-Critic算法，在小型卫星上学习热控制策略。</li>
<li>results: 实验结果显示，提案的框架能够学习控制负载处理功率，以维持操作范围内的温度，辅助传统热控制系统。<details>
<summary>Abstract</summary>
In small satellites there is less room for heat control equipment, scientific instruments, and electronic components. Furthermore, the near proximity of the electronics makes power dissipation difficult, with the risk of not being able to control the temperature appropriately, reducing component lifetime and mission performance. To address this challenge, taking advantage of the advent of increasing intelligence on board satellites, a deep reinforcement learning based framework that uses Soft Actor-Critic algorithm is proposed for learning the thermal control policy onboard. The framework is evaluated both in a naive simulated environment and in a real space edge processing computer that will be shipped in the future IMAGIN-e mission and hosted in the ISS. The experiment results show that the proposed framework is able to learn to control the payload processing power to maintain the temperature under operational ranges, complementing traditional thermal control systems.
</details>
<details>
<summary>摘要</summary>
在小卫星中，因空间约束，热控制设备、科学仪器和电子组件具有更小的空间，导致热控制变得更加困难。此外，电子元件的近距离位置使得热量减少困难，从而影响组件寿命和任务性能。为解决这个挑战，利用卫星上增加的智能化程度，我们提出了基于深度强化学习的框架，使用软行为评价算法来学习卫星上的热控制策略。我们在模拟环境中和未来发射的IMAGIN-e任务中进行了实验，结果显示，我们的框架能够学习控制payload处理功率，以维护工作范围内的温度，与传统热控制系统相结合。
</details></li>
</ul>
<hr>
<h2 id="Improvable-Gap-Balancing-for-Multi-Task-Learning"><a href="#Improvable-Gap-Balancing-for-Multi-Task-Learning" class="headerlink" title="Improvable Gap Balancing for Multi-Task Learning"></a>Improvable Gap Balancing for Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15429">http://arxiv.org/abs/2307.15429</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanqidai/igb4mtl">https://github.com/yanqidai/igb4mtl</a></li>
<li>paper_authors: Yanqi Dai, Nanyi Fei, Zhiwu Lu</li>
<li>for: 这种研究是为了提高多任务学习（MTL）中的性能，尤其是通过改善 improvable gap 来减少性能差距。</li>
<li>methods: 这种研究提出了两种新的 improvable gap balancing（IGB）算法，一种是简单的规则，另一种是通过深度强化学习来实现。两种算法都是通过动态分配任务权重来实现 improvable gap 的均衡。</li>
<li>results: 在两个 benchmark 数据集上进行了广泛的实验，发现这两种 IGB 算法在 MTL 中可以 дости到最佳结果，并且在结合 gradient balancing 时可以得到进一步的改善。<details>
<summary>Abstract</summary>
In multi-task learning (MTL), gradient balancing has recently attracted more research interest than loss balancing since it often leads to better performance. However, loss balancing is much more efficient than gradient balancing, and thus it is still worth further exploration in MTL. Note that prior studies typically ignore that there exist varying improvable gaps across multiple tasks, where the improvable gap per task is defined as the distance between the current training progress and desired final training progress. Therefore, after loss balancing, the performance imbalance still arises in many cases. In this paper, following the loss balancing framework, we propose two novel improvable gap balancing (IGB) algorithms for MTL: one takes a simple heuristic, and the other (for the first time) deploys deep reinforcement learning for MTL. Particularly, instead of directly balancing the losses in MTL, both algorithms choose to dynamically assign task weights for improvable gap balancing. Moreover, we combine IGB and gradient balancing to show the complementarity between the two types of algorithms. Extensive experiments on two benchmark datasets demonstrate that our IGB algorithms lead to the best results in MTL via loss balancing and achieve further improvements when combined with gradient balancing. Code is available at https://github.com/YanqiDai/IGB4MTL.
</details>
<details>
<summary>摘要</summary>
在多任务学习（MTL）中，梯度均衡在最近几年内得到了更多的研究兴趣，因为它经常会导致更好的性能。然而，损失均衡是梯度均衡的更加效率的方法，因此仍然值得进一步探索。尽管先前的研究通常忽略了多任务中存在的变化可以改善的差距，这个差距每个任务定义为当前训练进度与理想的最终训练进度之间的距离。因此，在许多情况下， после损失均衡，性能差距仍然存在。在这篇论文中，我们按照损失均衡框架，提出了两种新的可改进差距均衡（IGB）算法 для MTL：一种使用了简单的规则，另一种（是首次）使用了深度优化学习。特别是，不直接在 MTL 中平衡损失，两种算法都选择了在不同任务上动态分配任务权重以进行可改进差距均衡。此外，我们将 IGB 和梯度均衡结合，以示这两种算法之间的补充性。我们在两个标准数据集上进行了广泛的实验，结果显示，我们的 IGB 算法在 MTL 中通过损失均衡得到了最佳结果，并在与梯度均衡结合时得到了进一步的改进。代码可以在 GitHub 上找到：https://github.com/YanqiDai/IGB4MTL。
</details></li>
</ul>
<hr>
<h2 id="Implicit-neural-representation-for-change-detection"><a href="#Implicit-neural-representation-for-change-detection" class="headerlink" title="Implicit neural representation for change detection"></a>Implicit neural representation for change detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15428">http://arxiv.org/abs/2307.15428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Naylor, Diego Di Carlo, Arianna Traviglia, Makoto Yamada, Marco Fiorucci</li>
<li>for: 检测3D空中LiDAR点云集中的变化，包括不匹配的空间支持和探测系统噪声。</li>
<li>methods: 提出了一种无监督方法，包括Neural Field（NF） для连续形态重建和 Gaussian Mixture Model（GMM） для分类变化。NF可以在不同的 spatial scale 上进行比较，从而提高检测Capability。</li>
<li>results: 在一个 simulated LiDAR点云集上进行了多种场景的比较，与当前状态艺技相比，提高了10%的intersection over union metric。此外，还应用于实际场景，鉴定了考古遗产被非法挖掘（looting）的情况，与场地专家的发现相符。<details>
<summary>Abstract</summary>
Detecting changes that occurred in a pair of 3D airborne LiDAR point clouds, acquired at two different times over the same geographical area, is a challenging task because of unmatching spatial supports and acquisition system noise. Most recent attempts to detect changes on point clouds are based on supervised methods, which require large labelled data unavailable in real-world applications. To address these issues, we propose an unsupervised approach that comprises two components: Neural Field (NF) for continuous shape reconstruction and a Gaussian Mixture Model for categorising changes. NF offer a grid-agnostic representation to encode bi-temporal point clouds with unmatched spatial support that can be regularised to increase high-frequency details and reduce noise. The reconstructions at each timestamp are compared at arbitrary spatial scales, leading to a significant increase in detection capabilities. We apply our method to a benchmark dataset of simulated LiDAR point clouds for urban sprawling. The dataset offers different challenging scenarios with different resolutions, input modalities and noise levels, allowing a multi-scenario comparison of our method with the current state-of-the-art. We boast the previous methods on this dataset by a 10% margin in intersection over union metric. In addition, we apply our methods to a real-world scenario to identify illegal excavation (looting) of archaeological sites and confirm that they match findings from field experts.
</details>
<details>
<summary>摘要</summary>
检测在两个不同时间采集的空中三维 LiDAR点云之间的变化是一项具有挑战性的任务，主要因为点云采集系统的噪声和不匹配的空间支持。大多数最新的变化检测方法都基于有监督的方法，需要庞大的标注数据，而实际应用中却缺乏这些数据。为解决这些问题，我们提出了一种无监督的方法，该方法包括两个组件：神经场（NF） для连续形态重建和高斯混合模型（GMM） для分类变化。NF提供了不受格子约束的表示方式，可以将不匹配的时间支持编码为高频环境和噪声减少。在每个时间戳中对重建的比较，可以在任意的空间缩放比进行比较，从而提高检测能力。我们在一个 simulate LiDAR点云数据集上进行了多种场景的比较，并证明了我们的方法在相对于当前状态的艺术中提高了10%的 intersect over union 指标。此外，我们还应用了我们的方法于一个真实世界应用中，并证明了它们与场景专家的发现相匹配。
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Models-Synthetic-Tabular-Data-and-Differential-Privacy-An-Overview-and-Synthesis"><a href="#Deep-Generative-Models-Synthetic-Tabular-Data-and-Differential-Privacy-An-Overview-and-Synthesis" class="headerlink" title="Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis"></a>Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15424">http://arxiv.org/abs/2307.15424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Conor Hassan, Robert Salomone, Kerrie Mengersen</li>
<li>for: 本研究提供了深入的生成数据技术发展synopsis，特注意点是对私人敏感数据的synthetic数据生成。</li>
<li>methods: 本文使用深度生成模型来生成tabular数据，并详细介绍了相关概念，如无监督学习、神经网络和生成模型。</li>
<li>results: 本文详细介绍了使用深度生成模型生成tabular数据的挑战和考虑因素，如数据normalization、隐私问题和模型评估。<details>
<summary>Abstract</summary>
This article provides a comprehensive synthesis of the recent developments in synthetic data generation via deep generative models, focusing on tabular datasets. We specifically outline the importance of synthetic data generation in the context of privacy-sensitive data. Additionally, we highlight the advantages of using deep generative models over other methods and provide a detailed explanation of the underlying concepts, including unsupervised learning, neural networks, and generative models. The paper covers the challenges and considerations involved in using deep generative models for tabular datasets, such as data normalization, privacy concerns, and model evaluation. This review provides a valuable resource for researchers and practitioners interested in synthetic data generation and its applications.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:这篇文章提供了关于深度生成模型在生成数据方面的最新发展，特别是在表格数据上。文章强调了在隐私敏感数据的情况下，生成数据的重要性。此外，文章还 highlights 深度生成模型与其他方法的优势，并提供了详细的解释，包括无监督学习、神经网络和生成模型的基本概念。文章还讨论了使用深度生成模型处理表格数据时的挑战和考虑因素，如数据Normalization、隐私问题和模型评估。这篇文章为关心生成数据和其应用的研究人员和实践者提供了有价值的资源。
</details></li>
</ul>
<hr>
<h2 id="Is-One-Epoch-All-You-Need-For-Multi-Fidelity-Hyperparameter-Optimization"><a href="#Is-One-Epoch-All-You-Need-For-Multi-Fidelity-Hyperparameter-Optimization" class="headerlink" title="Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?"></a>Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15422">http://arxiv.org/abs/2307.15422</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deephyper/benchmark">https://github.com/deephyper/benchmark</a></li>
<li>paper_authors: Romain Egele, Isabelle Guyon, Yixuan Sun, Prasanna Balaprakash</li>
<li>for: 优化机器学习模型的精度，减少计算成本。</li>
<li>methods: 利用多级准确水平进行学习过程中的剔除低性能模型，提高模型选择效率。</li>
<li>results: 与其他代表性的多级准确优化方法相比，简单的基准点获得了类似的结果，而 computation 减少了一个数量级。分析了数据集的学习曲线，发现了一些主导的学习曲线，这解释了基准点的成功。<details>
<summary>Abstract</summary>
Hyperparameter optimization (HPO) is crucial for fine-tuning machine learning models but can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) leverages intermediate accuracy levels in the learning process and discards low-performing models early on. We compared various representative MF-HPO methods against a simple baseline on classical benchmark data. The baseline involved discarding all models except the Top-K after training for only one epoch, followed by further training to select the best model. Surprisingly, this baseline achieved similar results to its counterparts, while requiring an order of magnitude less computation. Upon analyzing the learning curves of the benchmark data, we observed a few dominant learning curves, which explained the success of our baseline. This suggests that researchers should (1) always use the suggested baseline in benchmarks and (2) broaden the diversity of MF-HPO benchmarks to include more complex cases.
</details>
<details>
<summary>摘要</summary>
（简体中文）神经网络模型精度优化（HPO）是机器学习模型微调的关键步骤，但可能具有高计算成本。为了降低成本，多级准确度HPO（MF-HPO）利用学习过程中的中间准确度水平，早期抛弃低性能模型。我们对多种代表性的MF-HPO方法进行了比较，与简单的基线方法进行了对比。基线方法是在训练一 epoch后，仅保留Top-K模型，并进行进一步的训练来选择最佳模型。 surprisingly，这个基线方法达到了与其他方法相同的结果，而且只需要一个数量级下的计算。对于经典数据集的学习曲线进行分析，我们发现了一些DOMINANT的学习曲线，这解释了我们的基线方法的成功。这表明研究人员应该（1）在benchmark中使用我们建议的基线方法，并（2）扩展MF-HPO的benchmark，以包括更复杂的情况。
</details></li>
</ul>
<hr>
<h2 id="The-Initial-Screening-Order-Problem"><a href="#The-Initial-Screening-Order-Problem" class="headerlink" title="The Initial Screening Order Problem"></a>The Initial Screening Order Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15398">http://arxiv.org/abs/2307.15398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jose M. Alvarez, Salvatore Ruggieri</li>
<li>For: The paper is written to address the initial screening order problem in candidate screening, with the goal of finding the first k suitable candidates rather than the best k candidates in a candidate pool.* Methods: The paper uses formal methods to prove the effects of initial screening orders on the selected set of k candidates, particularly in situations where the candidate pool is unbalanced (e.g., having more male than female candidates).* Results: The paper shows that under unbalanced candidate pools, the human-like screener can suffer from uneven efforts that hinder decision-making over the protected, under-represented group relative to the non-protected, over-represented group. The paper also proves other fairness results under the human-like screener.Here are the three points in Simplified Chinese text:* For: 本文旨在解决初层屏选择问题，即在候选人池中找到第一个k适合的候选人而不是最佳k candidates。* Methods: 本文使用正式方法证明初层屏选择顺序对选定的k candidates产生的影响，特别是在候选人池受损（例如有更多的男性 candidates）时。* Results: 本文表明在不均衡的候选人池时，人类化屏选者可能会因屏选顺序而受到不公正的努力，从保护的、下降的群体中减少决策。 论文还证明了其他公平性结果。<details>
<summary>Abstract</summary>
In this paper we present the initial screening order problem, a crucial step within candidate screening. It involves a human-like screener with an objective to find the first k suitable candidates rather than the best k suitable candidates in a candidate pool given an initial screening order. The initial screening order represents the way in which the human-like screener arranges the candidate pool prior to screening. The choice of initial screening order has considerable effects on the selected set of k candidates. We prove that under an unbalanced candidate pool (e.g., having more male than female candidates), the human-like screener can suffer from uneven efforts that hinder its decision-making over the protected, under-represented group relative to the non-protected, over-represented group. Other fairness results are proven under the human-like screener. This research is based on a collaboration with a large company to better understand its hiring process for potential automation. Our main contribution is the formalization of the initial screening order problem which, we argue, opens the path for future extensions of the current works on ranking algorithms, fairness, and automation for screening procedures.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了初层屏选问题，这是候选人筛选的一个关键步骤。它涉及一个人类化的屏选员，目的是在候选人池中找出第一个k适合的候选人而不是最佳k适合的候选人。初层屏选顺序表示屏选员在筛选之前对候选人池进行了排序。初层屏选顺序的选择对选定的k候选人产生了很大的影响。我们证明，在不均衡的候选人池（例如有更多的男性候选人）情况下，屏选员可能会受到不平等的努力，使其对保护的、少数群体进行决策受到阻碍，相比之下对非保护的、多数群体的决策更加容易。我们还证明了其他的公平性结果。这项研究基于与大公司合作，以更好地理解其招聘过程，以便更好地自动化屏选过程。我们的主要贡献是对初层屏选顺序问题的正式化，我们认为这将开启未来对排名算法、公平性和自动化屏选过程的扩展。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Interpolation-Learning-with-Shallow-Univariate-ReLU-Networks"><a href="#Noisy-Interpolation-Learning-with-Shallow-Univariate-ReLU-Networks" class="headerlink" title="Noisy Interpolation Learning with Shallow Univariate ReLU Networks"></a>Noisy Interpolation Learning with Shallow Univariate ReLU Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15396">http://arxiv.org/abs/2307.15396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nirmit Joshi, Gal Vardi, Nathan Srebro</li>
<li>for: 研究了采用 interpolate with minimum norm（ weights 的 $\ell_2$  norm）的 two-layer ReLU 网络在噪音单变量回归中的 asymptotic overfitting 行为。</li>
<li>methods: 使用 interpolate with minimum norm 方法，并研究不同的损失函数($L_p$ loss) 对 overfitting 的影响。</li>
<li>results: 发现在 $L_1$ 损失函数下，overfitting 受控；在 $L_p$ 损失函数 ($p&lt;2$) 下，overfitting 也受控，但在 $p\geq 2$ 下，overfitting  catastrophic。<details>
<summary>Abstract</summary>
We study the asymptotic overfitting behavior of interpolation with minimum norm ($\ell_2$ of the weights) two-layer ReLU networks for noisy univariate regression. We show that overfitting is tempered for the $L_1$ loss, and any $L_p$ loss for $p<2$, but catastrophic for $p\geq 2$.
</details>
<details>
<summary>摘要</summary>
我们研究插值的极大欠拟合行为，使用两层ReLU网络，在噪音一变量回归 зада务中。我们显示，使用$L_1$损失函数时，过拟合行为会减少；使用任何$L_p$损失函数（$p<2）时，过拟合行为也会减少，但是使用$L_p$损失函数（$p\geq 2）时，过拟合行为将会恶化。
</details></li>
</ul>
<hr>
<h2 id="Does-Full-Waveform-Inversion-Benefit-from-Big-Data"><a href="#Does-Full-Waveform-Inversion-Benefit-from-Big-Data" class="headerlink" title="Does Full Waveform Inversion Benefit from Big Data?"></a>Does Full Waveform Inversion Benefit from Big Data?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15388">http://arxiv.org/abs/2307.15388</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Jin, Yinan Feng, Shihang Feng, Hanchen Wang, Yinpeng Chen, Benjamin Consolvo, Zicheng Liu, Youzuo Lin</li>
<li>for: 这个论文研究了大数据对深度学习模型在全波形推算（FWI）中的影响。</li>
<li>methods: 该论文使用了OpenFWI数据集，一个最近发布的大规模多结构数据集，来评估深度学习模型在FWI中的性能。</li>
<li>results: 实验结果表明，随着数据集大小的增加，深度学习模型在FWI中的性能和泛化性也随着增加。同时，模型容量需要随着数据大小增加以实现最佳改进。<details>
<summary>Abstract</summary>
This paper investigates the impact of big data on deep learning models for full waveform inversion (FWI). While it is well known that big data can boost the performance of deep learning models in many tasks, its effectiveness has not been validated for FWI. To address this gap, we present an empirical study that investigates how deep learning models in FWI behave when trained on OpenFWI, a collection of large-scale, multi-structural datasets published recently. Particularly, we train and evaluate the FWI models on a combination of 10 2D subsets in OpenFWI that contain 470K data pairs in total. Our experiments demonstrate that larger datasets lead to better performance and generalization of deep learning models for FWI. We further demonstrate that model capacity needs to scale in accordance with data size for optimal improvement.
</details>
<details>
<summary>摘要</summary>
这篇论文研究了大数据对深度学习模型在全波形推敲（FWI）中的影响。虽然已经确立了大数据可以提高深度学习模型在许多任务中表现的效果，但这些效果在FWI中尚未得到证明。为解决这个空白，我们发表了一项实验研究，检验了在OpenFWI中发布的大规模多结构数据集上深度学习模型在FWI中的表现。特别是，我们在OpenFWI中选取了10个2D子集，这些子集包含470K个数据对。我们的实验表明，大数据集会导致深度学习模型在FWI中的表现和泛化性能更好。我们还证明了模型容量需要与数据大小成正比以获得优化的改进。
</details></li>
</ul>
<hr>
<h2 id="Co-attention-Graph-Pooling-for-Efficient-Pairwise-Graph-Interaction-Learning"><a href="#Co-attention-Graph-Pooling-for-Efficient-Pairwise-Graph-Interaction-Learning" class="headerlink" title="Co-attention Graph Pooling for Efficient Pairwise Graph Interaction Learning"></a>Co-attention Graph Pooling for Efficient Pairwise Graph Interaction Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15377">http://arxiv.org/abs/2307.15377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leejunhyun/coattentiongraphpooling">https://github.com/leejunhyun/coattentiongraphpooling</a></li>
<li>paper_authors: Junhyun Lee, Bumsoo Kim, Minji Jeon, Jaewoo Kang</li>
<li>for: 这个研究旨在提高graph neural network（GNN）的效能，以便处理和学习具有图структуре数据的问题。</li>
<li>methods: 本研究使用co-attention在图 pooling中提取互动表示，实现更高效的 computation complexity和更好的性能。</li>
<li>results: 研究表明，CAGPool方法在真实世界数据集上展现出了竞争性的表现，同时保持较低的computational complexity。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have proven to be effective in processing and learning from graph-structured data. However, previous works mainly focused on understanding single graph inputs while many real-world applications require pair-wise analysis for graph-structured data (e.g., scene graph matching, code searching, and drug-drug interaction prediction). To this end, recent works have shifted their focus to learning the interaction between pairs of graphs. Despite their improved performance, these works were still limited in that the interactions were considered at the node-level, resulting in high computational costs and suboptimal performance. To address this issue, we propose a novel and efficient graph-level approach for extracting interaction representations using co-attention in graph pooling. Our method, Co-Attention Graph Pooling (CAGPool), exhibits competitive performance relative to existing methods in both classification and regression tasks using real-world datasets, while maintaining lower computational complexity.
</details>
<details>
<summary>摘要</summary>
格式化神经网络（GNNs）已经证明可以有效地处理和学习具有图结构数据的数据。然而，先前的工作主要集中于理解单个图输入，而实际应用中许多应用需要对图结构数据进行对比分析（例如，场景图匹配、代码搜索和药物交互预测）。为了解决这个问题，现有的工作已经转移着注意力到对图对之间的学习。虽然它们的性能有所改善，但是它们仍然受到图节点级别的交互限制，从而导致计算成本高、性能下降。为了解决这个问题，我们提出了一种新的和高效的图级别方法，即协同注意力图Pooling（CAGPool）。我们的方法在实际数据集上的分类和回归任务中展现出竞争性的性能，同时保持计算复杂度较低。
</details></li>
</ul>
<hr>
<h2 id="Conflict-free-joint-decision-by-lag-and-zero-lag-synchronization-in-laser-network"><a href="#Conflict-free-joint-decision-by-lag-and-zero-lag-synchronization-in-laser-network" class="headerlink" title="Conflict-free joint decision by lag and zero-lag synchronization in laser network"></a>Conflict-free joint decision by lag and zero-lag synchronization in laser network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15373">http://arxiv.org/abs/2307.15373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hisako Ito, Takatomo Mihana, Ryoichi Horisaki, Makoto Naruse</li>
<li>for: 这篇论文是关于应用激光网络作为光学加速器解决竞争多臂投机问题的研究。</li>
<li>methods: 该研究使用了激光网络，通过零延迟和延迟同步实现决策合作和碰撞避免功能。</li>
<li>results: 实验表明，该系统可以实现低碰撞率和高奖励，并且可扩展到更复杂的场景。<details>
<summary>Abstract</summary>
With the end of Moore's Law and the increasing demand for computing, photonic accelerators are garnering considerable attention. This is due to the physical characteristics of light, such as high bandwidth and multiplicity, and the various synchronization phenomena that emerge in the realm of laser physics. These factors come into play as computer performance approaches its limits. In this study, we explore the application of a laser network, acting as a photonic accelerator, to the competitive multi-armed bandit problem. In this context, conflict avoidance is key to maximizing environmental rewards. We experimentally demonstrate cooperative decision-making using zero-lag and lag synchronization within a network of four semiconductor lasers. Lag synchronization of chaos realizes effective decision-making and zero-delay synchronization is responsible for the realization of the collision avoidance function. We experimentally verified a low collision rate and high reward in a fundamental 2-player, 2-slot scenario, and showed the scalability of this system. This system architecture opens up new possibilities for intelligent functionalities in laser dynamics.
</details>
<details>
<summary>摘要</summary>
随着Moore的法则的结束和计算机能力的增长，光学加速器正在吸引一些关注。这是因为光子的物理特性，如带宽和多重性，以及在激光物理中出现的各种同步现象。这些因素在计算机性能接近界限时变得重要。在这种研究中，我们探讨了一个激光网络作为光学加速器应用于竞争多臂猎手问题。在这个上下文中，避免冲突是最大化环境奖励的关键。我们实验性地表明了光网络中的共同决策，使用零延迟和延迟同步实现有效的决策。我们实验证明了光网络中的冲突率低，奖励高，并证明了这种系统架构的扩展性。这种系统架构开启了新的智能功能在激光动力学中。
</details></li>
</ul>
<hr>
<h2 id="Toward-Transparent-Sequence-Models-with-Model-Based-Tree-Markov-Model"><a href="#Toward-Transparent-Sequence-Models-with-Model-Based-Tree-Markov-Model" class="headerlink" title="Toward Transparent Sequence Models with Model-Based Tree Markov Model"></a>Toward Transparent Sequence Models with Model-Based Tree Markov Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15367">http://arxiv.org/abs/2307.15367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chan Hsu, Wei-Chun Huang, Jun-Ting Wu, Chih-Yuan Li, Yihuang Kang</li>
<li>for: 该研究目标是解决复杂黑盒机器学习模型在序列数据上的解释性问题。</li>
<li>methods: 该研究提出了基于树的模型基于隐藏Markov模型（MOB-HSMM），该模型可以检测高死亡风险事件并揭示隐藏在ICU中的死亡风险。该模型利用了深度神经网络（DNN）中提取的知识来提高预测性能，同时提供了明确的解释。</li>
<li>results: 实验结果表明，通过使用LSTM学习序列模式，MOB树可以得到改进的性能。将MOB树与隐藏Markov模型（HSMM）结合在一起，可以揭示可用信息中的可能和解释性序列。<details>
<summary>Abstract</summary>
In this study, we address the interpretability issue in complex, black-box Machine Learning models applied to sequence data. We introduce the Model-Based tree Hidden Semi-Markov Model (MOB-HSMM), an inherently interpretable model aimed at detecting high mortality risk events and discovering hidden patterns associated with the mortality risk in Intensive Care Units (ICU). This model leverages knowledge distilled from Deep Neural Networks (DNN) to enhance predictive performance while offering clear explanations. Our experimental results indicate the improved performance of Model-Based trees (MOB trees) via employing LSTM for learning sequential patterns, which are then transferred to MOB trees. Integrating MOB trees with the Hidden Semi-Markov Model (HSMM) in the MOB-HSMM enables uncovering potential and explainable sequences using available information.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们解决了复杂黑盒机器学习模型应用于序列数据中的可解释性问题。我们引入了基于模型的树隐藏半马尔可夫模型（MOB-HSMM），这是一种自然可解释的模型，用于检测高死亡风险事件并揭示隐藏在死亡风险中的征 patrern。这个模型利用了深度神经网络（DNN）提供的知识来提高预测性能，同时也提供了明确的解释。我们的实验结果表明，通过使用LSTM学习序列模式，MOB树可以得到改进的性能。将MOB树与隐藏半马尔可夫模型（HSMM）结合在一起，在MOB-HSMM中实现了潜在的和可解释的序列使用可用信息。
</details></li>
</ul>
<hr>
<h2 id="Confident-Feature-Ranking"><a href="#Confident-Feature-Ranking" class="headerlink" title="Confident Feature Ranking"></a>Confident Feature Ranking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15361">http://arxiv.org/abs/2307.15361</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bitya Neuhof, Yuval Benjamini</li>
<li>for: 本研究旨在提出一种基于对比比较的后处方法，以确定特征重要性值的稳定排名。</li>
<li>methods: 该方法基于对比比较特征重要性值，并生成一个稳定的排名和相应的信任范围。</li>
<li>results: 研究表明，该方法能够包含真正的排名（在无穷样本情况下），并且允许选择top-k集。<details>
<summary>Abstract</summary>
Interpretation of feature importance values often relies on the relative order of the features rather than on the value itself, referred to as ranking. However, the order may be unstable due to the small sample sizes used in calculating the importance values. We propose that post-hoc importance methods produce a ranking and simultaneous confident intervals for the rankings. Based on pairwise comparisons of the feature importance values, our method is guaranteed to include the ``true'' (infinite sample) ranking with high probability and allows for selecting top-k sets.
</details>
<details>
<summary>摘要</summary>
通常情况下，特征重要性值的解释往往基于特征之间的相对排序而不是值本身，称为排名。然而，小样本大小可能导致排名不稳定。我们提议使用后期重要性方法生成排名和同时确定范围，以 garantía que la "verdadera" (大样本) 排名包含在内的高概率。此外，我们的方法还允许选择top-k集。Note: "top-k" refers to the top k features in the dataset, where k is a positive integer.
</details></li>
</ul>
<hr>
<h2 id="Med-HALT-Medical-Domain-Hallucination-Test-for-Large-Language-Models"><a href="#Med-HALT-Medical-Domain-Hallucination-Test-for-Large-Language-Models" class="headerlink" title="Med-HALT: Medical Domain Hallucination Test for Large Language Models"></a>Med-HALT: Medical Domain Hallucination Test for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15343">http://arxiv.org/abs/2307.15343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Logesh Kumar Umapathi, Ankit Pal, Malaikannan Sankarasubbu</li>
<li>for: 这种研究旨在解决大语言模型（LLM）中的幻觉问题，尤其在医疗领域。幻觉可能会在医疗应用中产生严重的后果。</li>
<li>methods: 我们提出了一个新的标准和数据集，即医疗领域幻觉测试（Med-HALT），用于评估和减少幻觉。Med-HALT 包括多种国际多元的数据集， derivated from medical examinations across various countries, and includes multiple innovative testing modalities。</li>
<li>results: 我们对主要的 LLM 进行了评估，包括 Text Davinci、GPT-3.5、LlaMa-2、MPT 和 Falcon，发现了这些模型在幻觉方面的显著差异。本文提供了详细的数据集描述，促进了透明度和重复性。通过这项工作，我们希望为医疗领域中更安全和可靠的语言模型的开发作出贡献。<details>
<summary>Abstract</summary>
This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs's problem-solving and information retrieval abilities.   Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting transparency and reproducibility. Through this work, we aim to contribute to the development of safer and more reliable language models in healthcare. Our benchmark can be found at medhalt.github.io
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-Radon-Signed-Cumulative-Distribution-Transform-and-its-applications-in-classification-of-Signed-Images"><a href="#The-Radon-Signed-Cumulative-Distribution-Transform-and-its-applications-in-classification-of-Signed-Images" class="headerlink" title="The Radon Signed Cumulative Distribution Transform and its applications in classification of Signed Images"></a>The Radon Signed Cumulative Distribution Transform and its applications in classification of Signed Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15339">http://arxiv.org/abs/2307.15339</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rohdelab/PyTransKit">https://github.com/rohdelab/PyTransKit</a></li>
<li>paper_authors: Le Gong, Shiying Li, Naqib Sad Pathan, Mohammad Shifat-E-Rabbi, Gustavo K. Rohde, Abu Hasnat Mohammad Rubaiyat, Sumati Thareja</li>
<li>for: 这个论文的目的是提出一种基于运输和最优运输的新图像表示技术。</li>
<li>methods: 这种新的图像表示方法结合了宽泛使用的劳顿变换和最近的信号表示方法called Signed Cumulative Distribution Transform。</li>
<li>results: 这种新的图像表示方法可以更好地表示签名图像中的信息内容，与现有的运输变换方法和深度学习基于分类方法相比，可以获得更高的分类精度。<details>
<summary>Abstract</summary>
Here we describe a new image representation technique based on the mathematics of transport and optimal transport. The method relies on the combination of the well-known Radon transform for images and a recent signal representation method called the Signed Cumulative Distribution Transform. The newly proposed method generalizes previous transport-related image representation methods to arbitrary functions (images), and thus can be used in more applications. We describe the new transform, and some of its mathematical properties and demonstrate its ability to partition image classes with real and simulated data. In comparison to existing transport transform methods, as well as deep learning-based classification methods, the new transform more accurately represents the information content of signed images, and thus can be used to obtain higher classification accuracies. The implementation of the proposed method in Python language is integrated as a part of the software package PyTransKit, available on Github.
</details>
<details>
<summary>摘要</summary>
我们介绍一种新的图像表示技术，基于运输学和最优运输学。该方法通过结合已知的卷积变换和最近的签名总额变换方法，将图像表示为函数。该新提议可以将图像分类问题应用于更多的场景。我们描述了该新变换，以及一些其数学性质和实际应用。我们还比较了现有的运输变换方法和深度学习基于分类方法，显示该新变换更好地表示签名图像的信息内容，因此可以获得更高的分类精度。我们在Python语言中实现了该方法，并将其集成到PyTransKit软件包中，可以在Github上下载。
</details></li>
</ul>
<hr>
<h2 id="Staging-E-Commerce-Products-for-Online-Advertising-using-Retrieval-Assisted-Image-Generation"><a href="#Staging-E-Commerce-Products-for-Online-Advertising-using-Retrieval-Assisted-Image-Generation" class="headerlink" title="Staging E-Commerce Products for Online Advertising using Retrieval Assisted Image Generation"></a>Staging E-Commerce Products for Online Advertising using Retrieval Assisted Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15326">http://arxiv.org/abs/2307.15326</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yueh-Ning Ku, Mikhail Kuznetsov, Shaunak Mishra, Paloma de Juan</li>
<li>For: 提高动态产品广告（DPA）图像的吸引力和实用性，使得用户更容易点击广告。* Methods: 使用生成对抗网络（GAN）和检索帮助GAN（Retrieval Assisted GANs）生成精心设计的背景，以增强产品图像的吸引力和实用性。* Results: 通过在线 метриks和人工评估，证明了我们的复制粘贴stage方法可以提高DPA图像的吸引力和实用性，并且可以生成动态产品广告短片。<details>
<summary>Abstract</summary>
Online ads showing e-commerce products typically rely on the product images in a catalog sent to the advertising platform by an e-commerce platform. In the broader ads industry such ads are called dynamic product ads (DPA). It is common for DPA catalogs to be in the scale of millions (corresponding to the scale of products which can be bought from the e-commerce platform). However, not all product images in the catalog may be appealing when directly re-purposed as an ad image, and this may lead to lower click-through rates (CTRs). In particular, products just placed against a solid background may not be as enticing and realistic as a product staged in a natural environment. To address such shortcomings of DPA images at scale, we propose a generative adversarial network (GAN) based approach to generate staged backgrounds for un-staged product images. Generating the entire staged background is a challenging task susceptible to hallucinations. To get around this, we introduce a simpler approach called copy-paste staging using retrieval assisted GANs. In copy paste staging, we first retrieve (from the catalog) staged products similar to the un-staged input product, and then copy-paste the background of the retrieved product in the input image. A GAN based in-painting model is used to fill the holes left after this copy-paste operation. We show the efficacy of our copy-paste staging method via offline metrics, and human evaluation. In addition, we show how our staging approach can enable animations of moving products leading to a video ad from a product image.
</details>
<details>
<summary>摘要</summary>
在线广告通常会显示电子商务产品，通常是由电子商务平台发送的目录至广告平台。在更广泛的广告业界中，这些广告被称为动态产品广告（DPA）。DPA目录通常有数百万产品（相应到电子商务平台上可购买的产品数量）。然而，不 ALL的产品图片在目录中都是吸引人和真实的，这可能导致低Click-through rate（CTR）。特别是产品只是在固定背景上显示，可能不如产品在自然环境中搭配而更吸引人。为了解决DPA图片的缺陷，我们提出了基于生成敌人网络（GAN）的方法，生成产品在自然环境中的 stagged 背景。生成整个 stagged 背景是一个具有潜在误导的任务，因此我们提出了一个简单的方法：copy-paste staging。在copy-paste staging中，我们首先从目录中检索与输入产品相似的 stagged 产品，然后将其背景贴上输入图片中。使用GAN基于填充模型来填充贴上的孔隙。我们透过线上指标和人类评价显示了我们的copy-paste staging方法的有效性。此外，我们还显示了我们的 stagging 方法可以实现产品动画，从产品图片中生成动画广告。
</details></li>
</ul>
<hr>
<h2 id="Partial-observations-coarse-graining-and-equivariance-in-Koopman-operator-theory-for-large-scale-dynamical-systems"><a href="#Partial-observations-coarse-graining-and-equivariance-in-Koopman-operator-theory-for-large-scale-dynamical-systems" class="headerlink" title="Partial observations, coarse graining and equivariance in Koopman operator theory for large-scale dynamical systems"></a>Partial observations, coarse graining and equivariance in Koopman operator theory for large-scale dynamical systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15325">http://arxiv.org/abs/2307.15325</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Peitz, Hans Harder, Feliks Nüske, Friedrich Philipp, Manuel Schaller, Karl Worthmann</li>
<li>for: 这篇论文旨在解决大规模系统数据驱动分析、预测和控制中的一个问题，即классиical EDMD算法不自动提供系统下的库曼操作符approximation，因为只有部分观察数据。</li>
<li>methods: 这篇论文使用了 Koopman 操作符来研究大规模系统的非线性动力学，并提出了一种新的方法来保持系统动力学 симметрии，从而大幅提高模型效率。</li>
<li>results: 数字实验表明，这种新方法可以减少数据量，同时保持模型的准确性，并且可以与域分解技术相结合以提高效率。<details>
<summary>Abstract</summary>
The Koopman operator has become an essential tool for data-driven analysis, prediction and control of complex systems, the main reason being the enormous potential of identifying linear function space representations of nonlinear dynamics from measurements. Until now, the situation where for large-scale systems, we (i) only have access to partial observations (i.e., measurements, as is very common for experimental data) or (ii) deliberately perform coarse graining (for efficiency reasons) has not been treated to its full extent. In this paper, we address the pitfall associated with this situation, that the classical EDMD algorithm does not automatically provide a Koopman operator approximation for the underlying system if we do not carefully select the number of observables. Moreover, we show that symmetries in the system dynamics can be carried over to the Koopman operator, which allows us to massively increase the model efficiency. We also briefly draw a connection to domain decomposition techniques for partial differential equations and present numerical evidence using the Kuramoto--Sivashinsky equation.
</details>
<details>
<summary>摘要</summary>
科普曼运算已成为数据驱动分析、预测和控制复杂系统的重要工具，主要原因是可以从测量数据中提取非线性动力学的线性函数空间表示。直到现在，我们对大规模系统的情况还没有充分考虑，即我们只有部分观察数据（例如测量数据）或者故意压缩系统（为了提高效率）。在这篇论文中，我们证明了类型EDMD算法不会自动为下列系统提供科普曼运算符的近似值，除非我们特别选择观察量的数量。此外，我们发现了系统动力学中的对称性可以传递到科普曼运算符中，这使得我们可以巨大提高模型的效率。我们还 briefly Draw a connection to域分解技术 для部分杜拉Equation,并提供了数据证明使用库拉诺-西瓦希诺 Equation。
</details></li>
</ul>
<hr>
<h2 id="Robust-Visual-Sim-to-Real-Transfer-for-Robotic-Manipulation"><a href="#Robust-Visual-Sim-to-Real-Transfer-for-Robotic-Manipulation" class="headerlink" title="Robust Visual Sim-to-Real Transfer for Robotic Manipulation"></a>Robust Visual Sim-to-Real Transfer for Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15320">http://arxiv.org/abs/2307.15320</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ricardo Garcia, Robin Strudel, Shizhe Chen, Etienne Arlaud, Ivan Laptev, Cordelia Schmid</li>
<li>For:	+ The paper focuses on bridging the visual sim-to-real domain gap in robotic manipulation tasks using domain randomization (DR) methods.	+ The authors aim to evaluate the effectiveness of DR methods for challenging robotic manipulation tasks and to develop a systematic approach to selecting DR parameters.* Methods:	+ The authors propose an off-line proxy task of cube localization to select DR parameters for texture randomization, lighting randomization, variations of object colors, and camera parameters.	+ They use off-line optimized DR parameters to train visuomotor policies in simulation and directly apply such policies to a real robot.* Results:	+ The authors achieve an average success rate of 93% on a diverse set of challenging manipulation tasks.	+ Their simulator-trained policies outperform policies learned using real but limited data, demonstrating the effectiveness of their approach in handling visual variations in real scenes.Here’s the simplified Chinese text for the three key information points:* For:	+ 论文主要关注在机器人 manipulate 任务中的视觉领域域转移问题，使用域随机化 (DR) 方法 bridge 距离。	+ 作者们想要评估 DR 方法在复杂的机器人 manipulate 任务中的效果，并开发一种系统的方法来选择 DR 参数。* Methods:	+ 作者们提议一种离线代理任务，即立方体localization，来选择 DR 参数的Texture randomization、lighting randomization、物体颜色的变化和摄像头参数。	+ 他们使用离线优化的 DR 参数来在 simulator 中训练视觉动作策略，然后直接将其应用到真实的机器人上。* Results:	+ 作者们在多种复杂的机器人 manipulate 任务中得到了平均 93% 的成功率。	+ 他们的 simulator 训练的策略在实际场景中处理视觉变化的情况下表现更好，超过了基于实际 pero 有限的数据学习的策略。<details>
<summary>Abstract</summary>
Learning visuomotor policies in simulation is much safer and cheaper than in the real world. However, due to discrepancies between the simulated and real data, simulator-trained policies often fail when transferred to real robots. One common approach to bridge the visual sim-to-real domain gap is domain randomization (DR). While previous work mainly evaluates DR for disembodied tasks, such as pose estimation and object detection, here we systematically explore visual domain randomization methods and benchmark them on a rich set of challenging robotic manipulation tasks. In particular, we propose an off-line proxy task of cube localization to select DR parameters for texture randomization, lighting randomization, variations of object colors and camera parameters. Notably, we demonstrate that DR parameters have similar impact on our off-line proxy task and on-line policies. We, hence, use off-line optimized DR parameters to train visuomotor policies in simulation and directly apply such policies to a real robot. Our approach achieves 93% success rate on average when tested on a diverse set of challenging manipulation tasks. Moreover, we evaluate the robustness of policies to visual variations in real scenes and show that our simulator-trained policies outperform policies learned using real but limited data. Code, simulation environment, real robot datasets and trained models are available at https://www.di.ens.fr/willow/research/robust_s2r/.
</details>
<details>
<summary>摘要</summary>
顺序训练在模拟环境中的视听动作策略比实际世界更安全和更便宜。然而，由于模拟和实际数据之间的差异，模拟训练的策略通常在转移到实际机器人上失败。一种常见的方法是域随机化（DR），以 bridge the visual sim-to-real domain gap。在这里，我们系统地探讨视听域随机化方法，并对其进行了丰富的机器人 manipulate 任务的benchmark。具体来说，我们提出了一个离线代理任务——立方体localization，用于选择DR参数的Texture randomization、lighting randomization、物体颜色变换和摄像头参数。值得一提的是，我们示出了DR参数对我们的离线代理任务和在线策略具有相似的影响。因此，我们使用离线优化的DR参数来在模拟环境中训练视听动作策略，然后直接将其应用到实际机器人上。我们的方法在多种挑战性的机器人 manipulate 任务上得到了93%的成功率的平均值。此外，我们还评估了模拟训练的策略在实际场景中对视觉变化的Robustness，并发现我们在模拟环境中训练的策略在实际数据中的表现更佳。可以在https://www.di.ens.fr/willow/research/robust_s2r/获取我们的代码、模拟环境、实际机器人数据和训练模型。
</details></li>
</ul>
<hr>
<h2 id="SAP-sLDA-An-Interpretable-Interface-for-Exploring-Unstructured-Text"><a href="#SAP-sLDA-An-Interpretable-Interface-for-Exploring-Unstructured-Text" class="headerlink" title="SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text"></a>SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01420">http://arxiv.org/abs/2308.01420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charumathi Badrinath, Weiwei Pan, Finale Doshi-Velez</li>
<li>for:  explore text corpora and learn topics that preserve semantically meaningful relationships between documents</li>
<li>methods: semi-supervised human-in-the-loop LDA-based method</li>
<li>results: more interpretable projections than baseline methods with only a fraction of labels provided, qualitatively similar results on a real corpus<details>
<summary>Abstract</summary>
A common way to explore text corpora is through low-dimensional projections of the documents, where one hopes that thematically similar documents will be clustered together in the projected space. However, popular algorithms for dimensionality reduction of text corpora, like Latent Dirichlet Allocation (LDA), often produce projections that do not capture human notions of document similarity. We propose a semi-supervised human-in-the-loop LDA-based method for learning topics that preserve semantically meaningful relationships between documents in low-dimensional projections. On synthetic corpora, our method yields more interpretable projections than baseline methods with only a fraction of labels provided. On a real corpus, we obtain qualitatively similar results.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)通常来说，探索文本集合的方式之一是通过文本文档的低维度投影，希望在投影空间中可以将有相似主题的文档归类到一起。然而，常见的文本集合维度减少算法，如Latent Dirichlet Allocation（LDA），经常生成不能捕捉人类理解的文档相似性的投影。我们提议一种半监督人类 loops LDA 基于方法，可以在低维度投影中保持文档之间含义 significado的关系。在 sintética corpora 上，我们的方法可以提供更加可解的投影，并且只需提供一部分标签。在实际 corpora 上，我们获得了类似的结果。
</details></li>
</ul>
<hr>
<h2 id="DiffKendall-A-Novel-Approach-for-Few-Shot-Learning-with-Differentiable-Kendall’s-Rank-Correlation"><a href="#DiffKendall-A-Novel-Approach-for-Few-Shot-Learning-with-Differentiable-Kendall’s-Rank-Correlation" class="headerlink" title="DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall’s Rank Correlation"></a>DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall’s Rank Correlation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15317">http://arxiv.org/abs/2307.15317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaipeng Zheng, Huishuai Zhang, Weiran Huang</li>
<li>for: 提高ew-shot learning的性能，尤其是在不同领域的数据集上。</li>
<li>methods: 使用Kendall的排名相关度metric instead of geometric similarity metric during inference, 并提pose a carefully designed differentiable loss for meta-training to address the non-differentiability issue。</li>
<li>results: 提高ew-shot learning的性能 across a wide range of datasets with different domains, and the proposed rank-correlation-based approach substantially enhances few-shot learning performance.<details>
<summary>Abstract</summary>
Few-shot learning aims to adapt models trained on the base dataset to novel tasks where the categories are not seen by the model before. This often leads to a relatively uniform distribution of feature values across channels on novel classes, posing challenges in determining channel importance for novel tasks. Standard few-shot learning methods employ geometric similarity metrics such as cosine similarity and negative Euclidean distance to gauge the semantic relatedness between two features. However, features with high geometric similarities may carry distinct semantics, especially in the context of few-shot learning. In this paper, we demonstrate that the importance ranking of feature channels is a more reliable indicator for few-shot learning than geometric similarity metrics. We observe that replacing the geometric similarity metric with Kendall's rank correlation only during inference is able to improve the performance of few-shot learning across a wide range of datasets with different domains. Furthermore, we propose a carefully designed differentiable loss for meta-training to address the non-differentiability issue of Kendall's rank correlation. Extensive experiments demonstrate that the proposed rank-correlation-based approach substantially enhances few-shot learning performance.
</details>
<details>
<summary>摘要</summary>
几个shot学习目标是使模型在基础数据集上训练后适应到新任务中，其中类别没有模型所见过。这经常导致新任务中通道的特征值分布相对均匀，从而增加了决定通道重要性的挑战。标准的几个shot学习方法使用几何相似度度量，如cosine相似度和负Euclidean距离，来衡量两个特征之间的 semantic相似性。然而，具有高几何相似性的特征可能表达出不同的 semantics，特别在几个shot学习上。在这篇论文中，我们表明了特征通道的重要性排名在几个shot学习中是更可靠的指标，而不是几何相似度度量。我们发现，在推理过程中将几何相似度度量替换为Kendall的排名相关性可以在多个领域的数据集上提高几个shot学习性能。此外，我们提出了一种特殊的可导损失函数，用于meta-training，以解决Kendall的排名相关性的不导能性问题。广泛的实验表明，我们的排名相关性基本 Approach 可以大幅提高几个shot学习性能。
</details></li>
</ul>
<hr>
<h2 id="Differential-Evolution-Algorithm-based-Hyper-Parameters-Selection-of-Transformer-Neural-Network-Model-for-Load-Forecasting"><a href="#Differential-Evolution-Algorithm-based-Hyper-Parameters-Selection-of-Transformer-Neural-Network-Model-for-Load-Forecasting" class="headerlink" title="Differential Evolution Algorithm based Hyper-Parameters Selection of Transformer Neural Network Model for Load Forecasting"></a>Differential Evolution Algorithm based Hyper-Parameters Selection of Transformer Neural Network Model for Load Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15299">http://arxiv.org/abs/2307.15299</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anuvabsen1/meta-transformer">https://github.com/anuvabsen1/meta-transformer</a></li>
<li>paper_authors: Anuvab Sen, Arul Rhik Mazumder, Udayon Sen</li>
<li>for: 预测电网负荷，减少能源浪费和提高供电稳定性。</li>
<li>methods: 使用时间序列模型（ARIMA）和深度学习模型（ANN、LSTM、GRU等），并应用多种metaheuristics（如 diferencial evolution）来找到最佳的模型hyperparameters。</li>
<li>results: 研究表明，通过metaheuristics对Transformer模型进行优化，可以提高预测精度，并且提供了不同metaheuristics对模型性能的比较。<details>
<summary>Abstract</summary>
Accurate load forecasting plays a vital role in numerous sectors, but accurately capturing the complex dynamics of dynamic power systems remains a challenge for traditional statistical models. For these reasons, time-series models (ARIMA) and deep-learning models (ANN, LSTM, GRU, etc.) are commonly deployed and often experience higher success. In this paper, we analyze the efficacy of the recently developed Transformer-based Neural Network model in Load forecasting. Transformer models have the potential to improve Load forecasting because of their ability to learn long-range dependencies derived from their Attention Mechanism. We apply several metaheuristics namely Differential Evolution to find the optimal hyperparameters of the Transformer-based Neural Network to produce accurate forecasts. Differential Evolution provides scalable, robust, global solutions to non-differentiable, multi-objective, or constrained optimization problems. Our work compares the proposed Transformer based Neural Network model integrated with different metaheuristic algorithms by their performance in Load forecasting based on numerical metrics such as Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE). Our findings demonstrate the potential of metaheuristic-enhanced Transformer-based Neural Network models in Load forecasting accuracy and provide optimal hyperparameters for each model.
</details>
<details>
<summary>摘要</summary>
准确的负荷预测在多个领域发挥重要作用，但是准确地捕捉动态能源系统的复杂动态还是传统统计模型的挑战。为此，时间序列模型（ARIMA）和深度学习模型（ANN、LSTM、GRU等）通常被部署，并经常得到更高的成功。在这篇论文中，我们分析了将最近发展的Transformer基于神经网络模型在负荷预测中的效果。Transformer模型具有学习长距离依赖关系的能力，因此它们在负荷预测中具有潜在的优势。我们使用多种metaheuristics，包括差分演化，来找出最佳的神经网络模型参数，以便生成高精度的预测结果。我们的工作比较了不同metaheuristicsAlgorithm和Transformer基于神经网络模型的性能，并通过数学统计指标（如 Mean Squared Error 和 Mean Absolute Percentage Error）来评估其表现。我们的发现表明metaheuristic增强的Transformer基于神经网络模型在负荷预测精度方面具有潜在的优势，并且可以为每个模型提供优化参数。
</details></li>
</ul>
<hr>
<h2 id="Learning-Nonlinear-Projections-for-Reduced-Order-Modeling-of-Dynamical-Systems-using-Constrained-Autoencoders"><a href="#Learning-Nonlinear-Projections-for-Reduced-Order-Modeling-of-Dynamical-Systems-using-Constrained-Autoencoders" class="headerlink" title="Learning Nonlinear Projections for Reduced-Order Modeling of Dynamical Systems using Constrained Autoencoders"></a>Learning Nonlinear Projections for Reduced-Order Modeling of Dynamical Systems using Constrained Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15288">http://arxiv.org/abs/2307.15288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/grmacchio/romnet_chaos2023">https://github.com/grmacchio/romnet_chaos2023</a></li>
<li>paper_authors: Samuel E. Otto, Gregory R. Macchio, Clarence W. Rowley</li>
<li>for: 这种新发展的减少模型技术用于近似非线性动力系统的低维抽象表示。</li>
<li>methods: 我们使用受限的自编码神经网络来学习数据上的抽象表示，其中抽象表示的维度是低于实际系统的维度。</li>
<li>results: 我们提出了一种新的非线性投影方法，该方法可以学习数据上的抽象表示和投影纤维。我们还提出了一些高维系统建模的技术，包括一种新的简洁化约束 penalty。<details>
<summary>Abstract</summary>
Recently developed reduced-order modeling techniques aim to approximate nonlinear dynamical systems on low-dimensional manifolds learned from data. This is an effective approach for modeling dynamics in a post-transient regime where the effects of initial conditions and other disturbances have decayed. However, modeling transient dynamics near an underlying manifold, as needed for real-time control and forecasting applications, is complicated by the effects of fast dynamics and nonnormal sensitivity mechanisms. To begin to address these issues, we introduce a parametric class of nonlinear projections described by constrained autoencoder neural networks in which both the manifold and the projection fibers are learned from data. Our architecture uses invertible activation functions and biorthogonal weight matrices to ensure that the encoder is a left inverse of the decoder. We also introduce new dynamics-aware cost functions that promote learning of oblique projection fibers that account for fast dynamics and nonnormality. To demonstrate these methods and the specific challenges they address, we provide a detailed case study of a three-state model of vortex shedding in the wake of a bluff body immersed in a fluid, which has a two-dimensional slow manifold that can be computed analytically. In anticipation of future applications to high-dimensional systems, we also propose several techniques for constructing computationally efficient reduced-order models using our proposed nonlinear projection framework. This includes a novel sparsity-promoting penalty for the encoder that avoids detrimental weight matrix shrinkage via computation on the Grassmann manifold.
</details>
<details>
<summary>摘要</summary>
近期开发的减少模型技术目的是近似非线性动力系统在低维抽象 manifold 上。这是一种有效的方法，用于模型在后过渡期的动力系统，其中Initial conditions和其他干扰的影响都已经衰退。然而，在near manifold 上模型急速动力和非正常敏感机制的影响，为实时控制和预测应用而带来了复杂性。为解决这些问题，我们提出了一个参数化的非线性投影描述，其中 manifold 和投影纤维都是从数据学习出来的。我们的架构使用可逆激活函数和对偶重量矩阵，以确保encoder 是 decoder 的左逆。我们还引入了新的动力感知成本函数，以便学习辐射投影纤维，考虑到急速动力和非正常性。为证明这些方法和它们解决的具体挑战，我们提供了一个细化的三个状态模型的游离振荡例子，该模型具有可 analytically 计算的二维慢态 manifold。预计将来应用于高维系统，我们还提出了一些构造高效减少模型的技术。这包括一种新的瑞度推荐策略，以避免 encoder 的权重矩阵减小，通过计算 Grassmann  manifold 进行计算。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Approximation-of-Zonoids-and-Uniform-Approximation-by-Shallow-Neural-Networks"><a href="#Optimal-Approximation-of-Zonoids-and-Uniform-Approximation-by-Shallow-Neural-Networks" class="headerlink" title="Optimal Approximation of Zonoids and Uniform Approximation by Shallow Neural Networks"></a>Optimal Approximation of Zonoids and Uniform Approximation by Shallow Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15285">http://arxiv.org/abs/2307.15285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan W. Siegel</li>
<li>for: 本文解决了两个相关的问题：第一个是确定一个任意的ζonoid在 $\mathbb{R}^{d+1}$ 可以在 Hausdorff 距离上被近似为 $n$ 条线段的和，第二个是确定 shallow ReLU$^k$ 神经网络在其变换空间上的优化approximation rate。</li>
<li>methods: 本文使用了新的技术解决了第一个问题，并且对第二个问题进行了 significiant 改进，能够uniformlyapproximate target function和其导函数。</li>
<li>results: 本文在所有维度中解决了第一个问题，并且对第二个问题提供了 improved approximation rates，可以uniformlyapproximate target function和其导函数。<details>
<summary>Abstract</summary>
We study the following two related problems. The first is to determine to what error an arbitrary zonoid in $\mathbb{R}^{d+1}$ can be approximated in the Hausdorff distance by a sum of $n$ line segments. The second is to determine optimal approximation rates in the uniform norm for shallow ReLU$^k$ neural networks on their variation spaces. The first of these problems has been solved for $d\neq 2,3$, but when $d=2,3$ a logarithmic gap between the best upper and lower bounds remains. We close this gap, which completes the solution in all dimensions. For the second problem, our techniques significantly improve upon existing approximation rates when $k\geq 1$, and enable uniform approximation of both the target function and its derivatives.
</details>
<details>
<summary>摘要</summary>
我们研究以下两个相关的问题。第一个问题是决定任意几何在 $\mathbb{R}^{d+1} $ 中可以被估计在 Hausdorff 距离上靠拢到 $n $ 条直线段的误差。第二个问题是决定 uniform 距离上的最佳数值� Lavu  neural networks 的变化空间上的数值� Lavu 率。第一个问题在 $d\neq 2,3 $ 已经解决，但在 $d=2,3 $ 还有很小的几何差。我们在这里关闭了这个差，完成了所有维度的解决方案。对于第二个问题，我们的技术可以在 $k\geq 1 $ 上进一步提高现有的数值� Lavu 率，并允许对目标函数和其 derivatives 进行均匀数值� Lavu。
</details></li>
</ul>
<hr>
<h2 id="VeriGen-A-Large-Language-Model-for-Verilog-Code-Generation"><a href="#VeriGen-A-Large-Language-Model-for-Verilog-Code-Generation" class="headerlink" title="VeriGen: A Large Language Model for Verilog Code Generation"></a>VeriGen: A Large Language Model for Verilog Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00708">http://arxiv.org/abs/2308.00708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shailja Thakur, Baleegh Ahmad, Hammond Pearce, Benjamin Tan, Brendan Dolan-Gavitt, Ramesh Karri, Siddharth Garg</li>
<li>for: 这个研究探讨了大语言模型（LLMs）是否能够自动设计硬件，通过生成高质量的Verilog代码。</li>
<li>methods: 研究人员在这个研究中细化了存在的LLMs，并对Verilog dataset从GitHub和Verilog教材中进行了编译。他们使用了一个专门设计的测试 suite，包括一个自定义问题集和测试架。</li>
<li>results: 研究人员发现，他们细化的开源CodeGen-16B模型在测试中表现出色，与商业化状态天空的GPT-3.5-turbo模型相比，实现了1.1%的总体提升。在面临更多和更复杂的问题集时，细化模型与状态天空模型竞争，在某些情况下表现出优异。特别是，它在不同问题类别中生成正确的Verilog代码的比例提高了41%，这highlights了小型、内部LLMs在硬件设计自动化中的潜力。<details>
<summary>Abstract</summary>
In this study, we explore the capability of Large Language Models (LLMs) to automate hardware design by generating high-quality Verilog code, a common language for designing and modeling digital systems. We fine-tune pre-existing LLMs on Verilog datasets compiled from GitHub and Verilog textbooks. We evaluate the functional correctness of the generated Verilog code using a specially designed test suite, featuring a custom problem set and testing benches. Here, our fine-tuned open-source CodeGen-16B model outperforms the commercial state-of-the-art GPT-3.5-turbo model with a 1.1% overall increase. Upon testing with a more diverse and complex problem set, we find that the fine-tuned model shows competitive performance against state-of-the-art gpt-3.5-turbo, excelling in certain scenarios. Notably, it demonstrates a 41% improvement in generating syntactically correct Verilog code across various problem categories compared to its pre-trained counterpart, highlighting the potential of smaller, in-house LLMs in hardware design automation.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们探索了大型自然语言模型（LLM）可以自动设计硬件的能力，通过生成高质量的Verilog代码，这是数字系统设计和模型的通用语言。我们对已有的LLM进行了微调，使用从GitHub和Verilog教材中编译的Verilog数据集。我们使用自定义测试环境和测试架构来评估生成的Verilog代码的功能正确性。在我们的微调open-source CodeGen-16B模型与商业现代GPT-3.5-turbo模型进行比较时，我们发现了1.1%的总提高。在测试更多和更复杂的问题集时，我们发现微调后的模型在某些场景下表现竞争力强，并且在某些场景下超过了state-of-the-art gpt-3.5-turbo模型。具有41%的提高在不同类型问题集中生成符合语法规则的Verilog代码的能力，这highlights了小型、内部LLM在硬件设计自动化中的潜力。
</details></li>
</ul>
<hr>
<h2 id="Recovering-high-quality-FODs-from-a-reduced-number-of-diffusion-weighted-images-using-a-model-driven-deep-learning-architecture"><a href="#Recovering-high-quality-FODs-from-a-reduced-number-of-diffusion-weighted-images-using-a-model-driven-deep-learning-architecture" class="headerlink" title="Recovering high-quality FODs from a reduced number of diffusion-weighted images using a model-driven deep learning architecture"></a>Recovering high-quality FODs from a reduced number of diffusion-weighted images using a model-driven deep learning architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15273">http://arxiv.org/abs/2307.15273</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jbartlett6/sdnet">https://github.com/jbartlett6/sdnet</a></li>
<li>paper_authors: J Bartlett, C E Davey, L A Johnston, J Duan</li>
<li>for: 该 paper 的目的是提出一种基于深度学习的纤维Orientation Distribution（FOD）重建方法，以提高 diffusion-weighted images（DWI）的重建精度并减少总的成像时间。</li>
<li>methods: 该方法使用了深度学习网络，并使用了diffusion acquisition invariant representations来输入数据，以确保网络可以适应不同的b-vectors和b-values。网络还使用了一种圆拟定网络，以确保输出的FOD和输入DWI信号之间的一致性。</li>
<li>results: 对比一种现有的FOD超分辨网络FOD-Net，该方法的性能相对竞争力强，并且可以通过调整fixel分类罚项来提高下游fixel基本分析的性能。code可以在<a target="_blank" rel="noopener" href="https://github.com/Jbartlett6/SDNet">https://github.com/Jbartlett6/SDNet</a> 中获取。<details>
<summary>Abstract</summary>
Fibre orientation distribution (FOD) reconstruction using deep learning has the potential to produce accurate FODs from a reduced number of diffusion-weighted images (DWIs), decreasing total imaging time. Diffusion acquisition invariant representations of the DWI signals are typically used as input to these methods to ensure that they can be applied flexibly to data with different b-vectors and b-values; however, this means the network cannot condition its output directly on the DWI signal. In this work, we propose a spherical deconvolution network, a model-driven deep learning FOD reconstruction architecture, that ensures intermediate and output FODs produced by the network are consistent with the input DWI signals. Furthermore, we implement a fixel classification penalty within our loss function, encouraging the network to produce FODs that can subsequently be segmented into the correct number of fixels and improve downstream fixel-based analysis. Our results show that the model-based deep learning architecture achieves competitive performance compared to a state-of-the-art FOD super-resolution network, FOD-Net. Moreover, we show that the fixel classification penalty can be tuned to offer improved performance with respect to metrics that rely on accurately segmented of FODs. Our code is publicly available at https://github.com/Jbartlett6/SDNet .
</details>
<details>
<summary>摘要</summary>
Diffusion-weighted imaging (DWI) 的扩展读取（FOD）重建使用深度学习有可能生成准确的FOD，从一个减少的数量的DWI图像中，降低总图像时间。通常使用Diffusion acquisition invariant representations of the DWI signals as input to these methods to ensure that they can be applied flexibly to data with different b-vectors and b-values; however, this means the network cannot condition its output directly on the DWI signal。在这种工作中，我们提出了一种圆柱体减少网络，一种驱动式深度学习FOD重建架构，以确保输入DWI信号的中间和输出FOD都与输入DWI信号兼容。此外，我们在我们的损失函数中实现了精度分类约束，让网络生成FOD，可以后续被正确分割为多个精度。我们的结果表明，我们的模型基于深度学习架构与FOD超分辨率网络FOD-Net具有竞争性的性能。此外，我们还表明，精度分类约束可以调整以提高基于FOD的下游分析中的性能。我们的代码可以在https://github.com/Jbartlett6/SDNet 上公开获取。
</details></li>
</ul>
<hr>
<h2 id="An-Overview-Of-Temporal-Commonsense-Reasoning-and-Acquisition"><a href="#An-Overview-Of-Temporal-Commonsense-Reasoning-and-Acquisition" class="headerlink" title="An Overview Of Temporal Commonsense Reasoning and Acquisition"></a>An Overview Of Temporal Commonsense Reasoning and Acquisition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00002">http://arxiv.org/abs/2308.00002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Wenzel, Adam Jatowt</li>
<li>for: 本研究旨在提高语言模型在时间常识逻辑 reasoning 方面的性能，特别是通过多种扩充和评估方法来提高模型的逻辑能力。</li>
<li>methods: 本研究使用了多种扩充方法，包括随机扩充、逻辑扩充和知识扩充，以提高语言模型的时间常识逻辑能力。</li>
<li>results:  despite the use of these augmentations, the models still struggle to approach human performance on reasoning tasks over temporal common sense properties, such as the typical occurrence times, orderings, or durations of events.<details>
<summary>Abstract</summary>
Temporal commonsense reasoning refers to the ability to understand the typical temporal context of phrases, actions, and events, and use it to reason over problems requiring such knowledge. This trait is essential in temporal natural language processing tasks, with possible applications such as timeline summarization, temporal question answering, and temporal natural language inference. Recent research on the performance of large language models suggests that, although they are adept at generating syntactically correct sentences and solving classification tasks, they often take shortcuts in their reasoning and fall prey to simple linguistic traps. This article provides an overview of research in the domain of temporal commonsense reasoning, particularly focusing on enhancing language model performance through a variety of augmentations and their evaluation across a growing number of datasets. However, these augmented models still struggle to approach human performance on reasoning tasks over temporal common sense properties, such as the typical occurrence times, orderings, or durations of events. We further emphasize the need for careful interpretation of research to guard against overpromising evaluation results in light of the shallow reasoning present in transformers. This can be achieved by appropriately preparing datasets and suitable evaluation metrics.
</details>
<details>
<summary>摘要</summary>
temporal common sense reasoning 指的是理解语句、行动和事件的典型时间背景，并使用这些知识来解决问题。这种 trait 是 temporal natural language processing 任务中的必备能力，可能的应用包括时间轴概要、时间问答和时间自然语言推理。 current research 表明，虽然大语言模型具有生成 grammatically 正确句子和解决分类任务的能力，但它们经常采取缩短逻辑的缘故，容易受到简单的语言陷阱。这篇文章提供了 temporal common sense reasoning 领域的研究概述，特别是通过多种增强和其评估在不断增长的数据集上。然而，这些增强模型仍然无法接近人类在时间通用理解上的表现，例如事件的典型发生时间、顺序或持续时间。我们更加强调需要在研究评估中小心着将 transformers 的浅层逻辑解释为不可避免的问题，通过适当准备数据集和评估指标来解决这个问题。
</details></li>
</ul>
<hr>
<h2 id="Is-this-model-reliable-for-everyone-Testing-for-strong-calibration"><a href="#Is-this-model-reliable-for-everyone-Testing-for-strong-calibration" class="headerlink" title="Is this model reliable for everyone? Testing for strong calibration"></a>Is this model reliable for everyone? Testing for strong calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15247">http://arxiv.org/abs/2307.15247</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jjfeng/testing_strong_calibration">https://github.com/jjfeng/testing_strong_calibration</a></li>
<li>paper_authors: Jean Feng, Alexej Gossmann, Romain Pirracchio, Nicholas Petrick, Gene Pennello, Berkman Sahiner</li>
<li>for: The paper is written for auditing a risk prediction model for strong calibration, particularly for machine learning algorithms, and for identifying poorly calibrated subgroups.</li>
<li>methods: The paper proposes a new testing procedure based on the insight that if observations can be reordered by their expected residuals, there should be a change in the association between the predicted and observed residuals if a poorly calibrated subgroup exists. The procedure uses a sample-splitting method, cross-validation, and a score-based cumulative sum (CUSUM) test to detect changes in the association.</li>
<li>results: The proposed procedure consistently achieved higher power in simulation studies and more than doubled the power when auditing a mortality risk prediction model compared to existing methods.<details>
<summary>Abstract</summary>
In a well-calibrated risk prediction model, the average predicted probability is close to the true event rate for any given subgroup. Such models are reliable across heterogeneous populations and satisfy strong notions of algorithmic fairness. However, the task of auditing a model for strong calibration is well-known to be difficult -- particularly for machine learning (ML) algorithms -- due to the sheer number of potential subgroups. As such, common practice is to only assess calibration with respect to a few predefined subgroups. Recent developments in goodness-of-fit testing offer potential solutions but are not designed for settings with weak signal or where the poorly calibrated subgroup is small, as they either overly subdivide the data or fail to divide the data at all. We introduce a new testing procedure based on the following insight: if we can reorder observations by their expected residuals, there should be a change in the association between the predicted and observed residuals along this sequence if a poorly calibrated subgroup exists. This lets us reframe the problem of calibration testing into one of changepoint detection, for which powerful methods already exist. We begin with introducing a sample-splitting procedure where a portion of the data is used to train a suite of candidate models for predicting the residual, and the remaining data are used to perform a score-based cumulative sum (CUSUM) test. To further improve power, we then extend this adaptive CUSUM test to incorporate cross-validation, while maintaining Type I error control under minimal assumptions. Compared to existing methods, the proposed procedure consistently achieved higher power in simulation studies and more than doubled the power when auditing a mortality risk prediction model.
</details>
<details>
<summary>摘要</summary>
在一个良好准确的风险预测模型中，每个子组的平均预测概率与实际事件率之间的差异应该很小。这些模型在多样化的人口中具有可靠性，并满足强的算法公平性。然而，对模型准确性进行审核是一项具有挑战性的任务，特别是对机器学习（ML）算法来说，因为数据中的可能子组的数量过多。因此，通常只是对一些预先定义的子组进行审核。现有的开发中有一些解决方案，但它们在弱信号下或者小 subgroup 中不具有准确性。我们提出了一种新的测试过程，基于以下经验：如果我们可以重新排序观测值按其预期差异，那么在这个序列上应该出现一个关于预测和实际差异的变化，如果存在一个不准确的子组。这样我们可以将准确性测试转换为变化点检测，这里有强大的方法。我们开始通过一种分段数据的方法，将一部分数据用于训练一组候选模型，用于预测差异，另一部分数据用于进行分数基元CUSUM测试。为了进一步提高力量，我们然后将这种适应CUSUM测试扩展到包括cross-validation，保持型I错误控制，并且具有最小的假设。与现有方法相比，我们的方法在 simulated studies 中一直表现出更高的力量，并在预测 mortality risk 模型时超过了力量。
</details></li>
</ul>
<hr>
<h2 id="A-Practical-Recipe-for-Federated-Learning-Under-Statistical-Heterogeneity-Experimental-Design"><a href="#A-Practical-Recipe-for-Federated-Learning-Under-Statistical-Heterogeneity-Experimental-Design" class="headerlink" title="A Practical Recipe for Federated Learning Under Statistical Heterogeneity Experimental Design"></a>A Practical Recipe for Federated Learning Under Statistical Heterogeneity Experimental Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15245">http://arxiv.org/abs/2307.15245</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mmorafah/fedzoo-bench">https://github.com/mmorafah/fedzoo-bench</a></li>
<li>paper_authors: Mahdi Morafah, Weijia Wang, Bill Lin</li>
<li>for: 本研究旨在 investigate Federated Learning (FL) 在数据不同性的情况下的成功性, 并提供一个系统性的研究结果和实践建议。</li>
<li>methods: 本研究使用了多种 FL-specific experimental variables, 包括 client-side and server-side techniques, 以及不同的数据准备和评价方法。</li>
<li>results: 本研究发现了一些关键的实验变量对 FL 性能的影响, 并提供了一些实践建议和标准化的实验设置。 我们还发布了 FedZoo-Bench，一个基于 PyTorch 的开源库，包含 22 种 state-of-the-art 方法的实现，可以在 <a target="_blank" rel="noopener" href="https://github.com/MMorafah/FedZoo-Bench">https://github.com/MMorafah/FedZoo-Bench</a> 上下载。<details>
<summary>Abstract</summary>
Federated Learning (FL) has been an area of active research in recent years. There have been numerous studies in FL to make it more successful in the presence of data heterogeneity. However, despite the existence of many publications, the state of progress in the field is unknown. Many of the works use inconsistent experimental settings and there are no comprehensive studies on the effect of FL-specific experimental variables on the results and practical insights for a more comparable and consistent FL experimental setup. Furthermore, the existence of several benchmarks and confounding variables has further complicated the issue of inconsistency and ambiguity. In this work, we present the first comprehensive study on the effect of FL-specific experimental variables in relation to each other and performance results, bringing several insights and recommendations for designing a meaningful and well-incentivized FL experimental setup. We further aid the community by releasing FedZoo-Bench, an open-source library based on PyTorch with pre-implementation of 22 state-of-the-art methods, and a broad set of standardized and customizable features available at https://github.com/MMorafah/FedZoo-Bench. We also provide a comprehensive comparison of several state-of-the-art (SOTA) methods to better understand the current state of the field and existing limitations.
</details>
<details>
<summary>摘要</summary>
《联合学习（Federated Learning，FL）》在过去几年中得到了广泛的研究。有很多研究旨在使FL在数据不同性的情况下更加成功。然而，尽管有很多论文，但现状的进步还不清楚。许多研究使用不一致的实验设置，而且没有系统的研究表现FL特有的实验变量对结果的影响和实践建议。此外，存在多个标准和干扰变量，使得问题变得更加复杂和模糊。在这篇研究中，我们提供了FL特有的实验变量对之间的首次全面研究，从而提供了许多新的视角和建议，以设计一个有意义和奖励性的FL实验设置。此外，我们还提供了FedZoo-Bench，一个基于PyTorch的开源库，包含22种当前领先的方法的预实现，以及一系列标准化和可定制的特性。我们还对多种当前领先方法进行了全面比较，以更好地理解当前领域的状况和存在的限制。
</details></li>
</ul>
<hr>
<h2 id="Sustainable-Transparency-in-Recommender-Systems-Bayesian-Ranking-of-Images-for-Explainability"><a href="#Sustainable-Transparency-in-Recommender-Systems-Bayesian-Ranking-of-Images-for-Explainability" class="headerlink" title="Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability"></a>Sustainable Transparency in Recommender Systems: Bayesian Ranking of Images for Explainability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01196">http://arxiv.org/abs/2308.01196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jorge Paz-Ruza, Amparo Alonso-Betanzos, Berta Guijarro-Berdiñas, Brais Cancela, Carlos Eiras-Franco</li>
<li>for: 提高推荐系统的透明度和用户信任度</li>
<li>methods: 使用用户创建的视觉内容生成个性化解释</li>
<li>results: 比前一代模型具有更高的性能和效率，减少了75%的CO${_2}$排放和模型尺寸。<details>
<summary>Abstract</summary>
Recommender Systems have become crucial in the modern world, commonly guiding users towards relevant content or products, and having a large influence over the decisions of users and citizens. However, ensuring transparency and user trust in these systems remains a challenge; personalized explanations have emerged as a solution, offering justifications for recommendations. Among the existing approaches for generating personalized explanations, using visual content created by the users is one particularly promising option, showing a potential to maximize transparency and user trust. Existing models for explaining recommendations in this context face limitations: sustainability has been a critical concern, as they often require substantial computational resources, leading to significant carbon emissions comparable to the Recommender Systems where they would be integrated. Moreover, most models employ surrogate learning goals that do not align with the objective of ranking the most effective personalized explanations for a given recommendation, leading to a suboptimal learning process and larger model sizes. To address these limitations, we present BRIE, a novel model designed to tackle the existing challenges by adopting a more adequate learning goal based on Bayesian Pairwise Ranking, enabling it to achieve consistently superior performance than state-of-the-art models in six real-world datasets, while exhibiting remarkable efficiency, emitting up to 75% less CO${_2}$ during training and inference with a model up to 64 times smaller than previous approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Open-Problems-and-Fundamental-Limitations-of-Reinforcement-Learning-from-Human-Feedback"><a href="#Open-Problems-and-Fundamental-Limitations-of-Reinforcement-Learning-from-Human-Feedback" class="headerlink" title="Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback"></a>Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15217">http://arxiv.org/abs/2307.15217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephen Casper, Xander Davies, Claudia Shi, Thomas Krendl Gilbert, Jérémy Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner, Pedro Freire, Tony Wang, Samuel Marks, Charbel-Raphaël Segerie, Micah Carroll, Andi Peng, Phillip Christoffersen, Mehul Damani, Stewart Slocum, Usman Anwar, Anand Siththaranjan, Max Nadeau, Eric J. Michaud, Jacob Pfau, Dmitrii Krasheninnikov, Xin Chen, Lauro Langosco, Peter Hase, Erdem Bıyık, Anca Dragan, David Krueger, Dorsa Sadigh, Dylan Hadfield-Menell</li>
<li>for: 这个论文旨在探讨人工智能系统如何与人类目标相对应，以及RLHF方法在实践中的问题和局限性。</li>
<li>methods: 这篇论文使用了RLHF方法来训练大语言模型，并提出了一些实践中的技巧来改进RLHF方法。</li>
<li>results: 这篇论文认为RLHF方法存在一些潜在的问题和局限性，并提出了一些审核和公布标准来提高社会监管RLHF系统的能力。<details>
<summary>Abstract</summary>
Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.
</details>
<details>
<summary>摘要</summary>
人类反馈学习强化（RLHF）是一种训练人工智能系统对人类目标的技术。RLHF已经成为现代大语言模型（LLM）的Finetune中心方法。尽管它的流行程度，但有 relativ little public work systematizing its flaws。在这篇论文中，我们（1）报告RLHF和相关方法的开放问题和基本限制;（2）介绍RLHF在实践中理解、改进和补充的技巧;（3）提出了RLHF系统的审核和披透标准，以提高社会对RLHF系统的监管。我们的工作强调RLHF的限制，并高亮了在开发更安全的AI系统方面需要多种方法的发展。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="PromptStyler-Prompt-driven-Style-Generation-for-Source-free-Domain-Generalization"><a href="#PromptStyler-Prompt-driven-Style-Generation-for-Source-free-Domain-Generalization" class="headerlink" title="PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization"></a>PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15199">http://arxiv.org/abs/2307.15199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhyeong Cho, Gilhyun Nam, Sungyeon Kim, Hunmin Yang, Suha Kwak</li>
<li>for: 这个研究旨在提高源自零领域缩减中的表现，不需要使用任何图像。</li>
<li>methods: 提案的方法是PromptStyler，它使用提示来生成多种Distribution Shift在共同空间中，并透过学习式字库Word vector来生成多种Style feature。</li>
<li>results: 研究获得了State of the art的成绩在PACS、VLCS、OfficeHome和DomainNet等测试集上，而不需要任何图像进行训练。<details>
<summary>Abstract</summary>
In a joint vision-language space, a text feature (e.g., from "a photo of a dog") could effectively represent its relevant image features (e.g., from dog photos). Also, a recent study has demonstrated the cross-modal transferability phenomenon of this joint space. From these observations, we propose PromptStyler which simulates various distribution shifts in the joint space by synthesizing diverse styles via prompts without using any images to deal with source-free domain generalization. The proposed method learns to generate a variety of style features (from "a S* style of a") via learnable style word vectors for pseudo-words S*. To ensure that learned styles do not distort content information, we force style-content features (from "a S* style of a [class]") to be located nearby their corresponding content features (from "[class]") in the joint vision-language space. After learning style word vectors, we train a linear classifier using synthesized style-content features. PromptStyler achieves the state of the art on PACS, VLCS, OfficeHome and DomainNet, even though it does not require any images for training.
</details>
<details>
<summary>摘要</summary>
在共同视语空间中，文本特征（例如，来自“一张狗照片”）可以有效地表示相关的图像特征（例如，来自狗照片）。此外，一项最近的研究已经证明了这个共同空间中的跨modal传递现象。基于这些观察，我们提出了PromptStyler，它通过使用提示而在共同空间中 simulate 多种分布转移。该方法不需要使用任何图像来处理源无限定类型泛化。我们学习了一系列的风格特征（例如，“一种S*风格的”）via可学习的风格词Vector。为确保学习的风格不会扭曲内容信息，我们强制风格-内容特征（例如，“一种S*风格的[类]”）在共同视语空间中与其对应的内容特征（例如，“[类]”）相 nearby。之后，我们使用生成的风格-内容特征进行线性分类。PromptStyler在PACS、VLCS、OfficeHome和DomainNet等 dataset上达到了状态计算机科学中的顶峰表现，即使不需要任何图像进行训练。
</details></li>
</ul>
<hr>
<h2 id="Identifying-acute-illness-phenotypes-via-deep-temporal-interpolation-and-clustering-network-on-physiologic-signatures"><a href="#Identifying-acute-illness-phenotypes-via-deep-temporal-interpolation-and-clustering-network-on-physiologic-signatures" class="headerlink" title="Identifying acute illness phenotypes via deep temporal interpolation and clustering network on physiologic signatures"></a>Identifying acute illness phenotypes via deep temporal interpolation and clustering network on physiologic signatures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15719">http://arxiv.org/abs/2307.15719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanfang Ren, Yanjun Li, Tyler J. Loftus, Jeremy Balch, Kenneth L. Abbott, Shounak Datta, Matthew M. Ruppert, Ziyuan Guan, Benjamin Shickel, Parisa Rashidi, Tezcan Ozrazgat-Baslanti, Azra Bihorac</li>
<li>for: 这份研究用于发现初期医院接受时间对临床走向的影响，并且通过数据缺乏的情况下提供早期临床决策的支持。</li>
<li>methods: 这份研究使用了深度时间 interpolating和 clustering 网络，将稀疏、不规则的生命征象数据中提取出潜在表示，并从训练集（n&#x3D;41,502）中提取出明显的患者型别。</li>
<li>results: 研究发现了4个患者型别，每个型别都有不同的疾病和结果。型别A（18%）有最多的复合疾病，高率的呼吸不足、肾衰竭、 septic shock 和三年后的死亡率。型别B（33%）和C（31%）有普遍的轻度器官衰竭，但型别B 有最好的短期结果，而型别C 有最好的临床结果。型别D（17%）有早期&#x2F;持续的低血压、高率的早期手术和许多血液标记的inflammation，但三年后的死亡率较低。<details>
<summary>Abstract</summary>
Initial hours of hospital admission impact clinical trajectory, but early clinical decisions often suffer due to data paucity. With clustering analysis for vital signs within six hours of admission, patient phenotypes with distinct pathophysiological signatures and outcomes may support early clinical decisions. We created a single-center, longitudinal EHR dataset for 75,762 adults admitted to a tertiary care center for 6+ hours. We proposed a deep temporal interpolation and clustering network to extract latent representations from sparse, irregularly sampled vital sign data and derived distinct patient phenotypes in a training cohort (n=41,502). Model and hyper-parameters were chosen based on a validation cohort (n=17,415). Test cohort (n=16,845) was used to analyze reproducibility and correlation with biomarkers. The training, validation, and testing cohorts had similar distributions of age (54-55 yrs), sex (55% female), race, comorbidities, and illness severity. Four clusters were identified. Phenotype A (18%) had most comorbid disease with higher rate of prolonged respiratory insufficiency, acute kidney injury, sepsis, and three-year mortality. Phenotypes B (33%) and C (31%) had diffuse patterns of mild organ dysfunction. Phenotype B had favorable short-term outcomes but second-highest three-year mortality. Phenotype C had favorable clinical outcomes. Phenotype D (17%) had early/persistent hypotension, high rate of early surgery, and substantial biomarker rate of inflammation but second-lowest three-year mortality. After comparing phenotypes' SOFA scores, clustering results did not simply repeat other acuity assessments. In a heterogeneous cohort, four phenotypes with distinct categories of disease and outcomes were identified by a deep temporal interpolation and clustering network. This tool may impact triage decisions and clinical decision-support under time constraints.
</details>
<details>
<summary>摘要</summary>
<<sys.translation.content>>医院 admit 初始时间对临床轨迹产生重要影响，但早期临床决策 frequently 受到数据缺乏的困扰。我们通过在 admit 至 6 小时内进行整合分析，可以从稀疏、不规则的生命征数据中提取潜在的 patient phenotypes 和不同的疾病特征。我们在一所三级医疗中心收治了 75,762 名成人， duration 至少 6 小时。我们提出了一种深度时间 interpolating 和 clustering 网络，以提取生命征数据中的潜在表示。我们在训练集（n=41,502）中提出了四种 patient phenotypes，每种 phenotype 都有明确的疾病特征和结果。我们根据验证集（n=17,415）中的模型和参数进行选择。测试集（n=16,845）用于评估重复性和与生物标志物相关性。训练、验证和测试集中年龄（54-55 岁）、性别（55% 女性）、种族、后遗病和疾病严重程度均匀分布。四种 phenotypes 中的首个（18%）有最多的并发病和高概率的呼吸窘迫、肾衰竭、 septic shock 和三年 mortality。第二种 phenotypes（33%）和第三种 phenotypes（31%）具有普遍的轻度器官衰竭，但短期result 好。第四种 phenotypes（17%）有早期/持续低血压、高概率的早期手术和严重的生物标志物，但三年 mortality 相对较低。通过对不同 phenotypes 的 SOFA 分数进行比较，整合分析结果并不 simply 重复其他acuity assessments。在一个多样化的 cohort 中，我们通过深度时间 interpolating 和 clustering 网络，可以从稀疏、不规则的生命征数据中提取四种不同类型的疾病和结果。这种工具可能会影响医疗决策和临床决策支持，尤其是在时间紧张的情况下。
</details></li>
</ul>
<hr>
<h2 id="The-Marginal-Value-of-Momentum-for-Small-Learning-Rate-SGD"><a href="#The-Marginal-Value-of-Momentum-for-Small-Learning-Rate-SGD" class="headerlink" title="The Marginal Value of Momentum for Small Learning Rate SGD"></a>The Marginal Value of Momentum for Small Learning Rate SGD</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15196">http://arxiv.org/abs/2307.15196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runzhe Wang, Sadhika Malladi, Tianhao Wang, Kaifeng Lyu, Zhiyuan Li</li>
<li>for: 这 paper 的目的是解释 momentum 在 Stochastic gradient descent (SGD) 中的作用，特别是在小学习率和大量批处理误差的情况下。</li>
<li>methods: 这 paper 使用了 theoretical analysis 和实验来研究 momentum 的效果。</li>
<li>results: 研究发现，在实际训练场景下， momentum 对优化和泛化都没有明显的提升，尤其是当学习率不够大时。<details>
<summary>Abstract</summary>
Momentum is known to accelerate the convergence of gradient descent in strongly convex settings without stochastic gradient noise. In stochastic optimization, such as training neural networks, folklore suggests that momentum may help deep learning optimization by reducing the variance of the stochastic gradient update, but previous theoretical analyses do not find momentum to offer any provable acceleration. Theoretical results in this paper clarify the role of momentum in stochastic settings where the learning rate is small and gradient noise is the dominant source of instability, suggesting that SGD with and without momentum behave similarly in the short and long time horizons. Experiments show that momentum indeed has limited benefits for both optimization and generalization in practical training regimes where the optimal learning rate is not very large, including small- to medium-batch training from scratch on ImageNet and fine-tuning language models on downstream tasks.
</details>
<details>
<summary>摘要</summary>
势能在强共轭情况下加速梯度下降减速，但在随机优化中，folklore Suggests that momentum may help deep learning optimization by reducing the variance of the stochastic gradient update, but previous theoretical analyses do not find momentum to offer any provable acceleration. 这篇论文解释了在随机设置中，where the learning rate is small and gradient noise is the dominant source of instability, SGD with and without momentum behave similarly in the short and long time horizons. 实验表明，势能 indeed has limited benefits for both optimization and generalization in practical training regimes where the optimal learning rate is not very large, including small- to medium-batch training from scratch on ImageNet and fine-tuning language models on downstream tasks.
</details></li>
</ul>
<hr>
<h2 id="Learning-in-Repeated-Multi-Unit-Pay-As-Bid-Auctions"><a href="#Learning-in-Repeated-Multi-Unit-Pay-As-Bid-Auctions" class="headerlink" title="Learning in Repeated Multi-Unit Pay-As-Bid Auctions"></a>Learning in Repeated Multi-Unit Pay-As-Bid Auctions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15193">http://arxiv.org/abs/2307.15193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rigel Galgana, Negin Golrezaei</li>
<li>for: 这篇论文关注的是在重复的多单位付款拍卖中学习如何出价，以实现最大化利润。</li>
<li>methods: 作者使用动态计划（DP）算法来解决这个问题，并在全信息和强化反馈下进行了线上学习算法的设计。</li>
<li>results: 作者证明了在线上学习算法的时间复杂度为乘方时间复杂度，并且在实际实验中，当所有投标者遵循作者提出的无 regret学习算法时，市场动态会向一个最大化利润的均衡点转化。此外，作者还发现在多单位付款拍卖中，付款拍卖可以带来较高的收益，比其受欢迎的替代方案——固定价格拍卖。<details>
<summary>Abstract</summary>
Motivated by Carbon Emissions Trading Schemes, Treasury Auctions, and Procurement Auctions, which all involve the auctioning of homogeneous multiple units, we consider the problem of learning how to bid in repeated multi-unit pay-as-bid auctions. In each of these auctions, a large number of (identical) items are to be allocated to the largest submitted bids, where the price of each of the winning bids is equal to the bid itself. The problem of learning how to bid in pay-as-bid auctions is challenging due to the combinatorial nature of the action space. We overcome this challenge by focusing on the offline setting, where the bidder optimizes their vector of bids while only having access to the past submitted bids by other bidders. We show that the optimal solution to the offline problem can be obtained using a polynomial time dynamic programming (DP) scheme. We leverage the structure of the DP scheme to design online learning algorithms with polynomial time and space complexity under full information and bandit feedback settings. We achieve an upper bound on regret of $O(M\sqrt{T\log |\mathcal{B}|})$ and $O(M\sqrt{|\mathcal{B}|T\log |\mathcal{B}|})$ respectively, where $M$ is the number of units demanded by the bidder, $T$ is the total number of auctions, and $|\mathcal{B}|$ is the size of the discretized bid space. We accompany these results with a regret lower bound, which match the linear dependency in $M$. Our numerical results suggest that when all agents behave according to our proposed no regret learning algorithms, the resulting market dynamics mainly converge to a welfare maximizing equilibrium where bidders submit uniform bids. Lastly, our experiments demonstrate that the pay-as-bid auction consistently generates significantly higher revenue compared to its popular alternative, the uniform price auction.
</details>
<details>
<summary>摘要</summary>
受到碳排放交易制度、储蓄拍卖和采购拍卖的 inspirations，我们考虑了在重复的多单位付出为投标的问题上学习投标策略。在这些拍卖中，大量相同的商品需要分配给最大的投标价格，其中每个赢得的投标价格都等于投标价格本身。由于拍卖的动作空间具有 combinatorial 性，这个问题非常困难。我们通过关注 offline 设定，即投标者在过去投标记录上仅可以获取历史投标记录，解决了这个问题。我们证明了 offline 问题的优化策略可以使用一种 polynomial time 的动态规划（DP）方案来实现。我们利用 DP 方案的结构，设计了在全信息和带有反馈的情况下的在线学习算法，其时间复杂度和存储空间复杂度均为多项式时间。我们证明了在 $O(M\sqrt{T\log |\mathcal{B}|})$ 和 $O(M\sqrt{|\mathcal{B}|T\log |\mathcal{B}|})$ 的情况下，我们的恐慌 regret  upper bound 和 lower bound 均为线性函数。我们的数学结果表明，当所有代理人按照我们提议的不留 regret 学习算法，市场动态会主要循环到一个最大化公平价值的均衡，其中投标者将提交均匀投标。最后，我们的实验表明，付出为投标 auction 在许多情况下会生成比 uniform price auction 更高的收入。
</details></li>
</ul>
<hr>
<h2 id="f-Divergence-Minimization-for-Sequence-Level-Knowledge-Distillation"><a href="#f-Divergence-Minimization-for-Sequence-Level-Knowledge-Distillation" class="headerlink" title="f-Divergence Minimization for Sequence-Level Knowledge Distillation"></a>f-Divergence Minimization for Sequence-Level Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15190">http://arxiv.org/abs/2307.15190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manga-uofa/fdistill">https://github.com/manga-uofa/fdistill</a></li>
<li>paper_authors: Yuqiao Wen, Zichao Li, Wenyu Du, Lili Mou</li>
<li>for: 本研究旨在提出一个名为f-DISTILL的框架，用于实现语言模型知识传递。</li>
<li>methods: 本研究使用一个通过最小化一个通用f-分配函数来实现序列级知识传递的方法，并提出了四种知识传递变种。</li>
<li>results: 实验结果表明， compared to现有的SeqKD和ENGINE方法，我们的f-DISTILL方法在四个数据集上表现更好，而我们的对称的知识传递损失可以更好地让学生学习教师分布。<details>
<summary>Abstract</summary>
Knowledge distillation (KD) is the process of transferring knowledge from a large model to a small one. It has gained increasing attention in the natural language processing community, driven by the demands of compressing ever-growing language models. In this work, we propose an f-DISTILL framework, which formulates sequence-level knowledge distillation as minimizing a generalized f-divergence function. We propose four distilling variants under our framework and show that existing SeqKD and ENGINE approaches are approximations of our f-DISTILL methods. We further derive step-wise decomposition for our f-DISTILL, reducing intractable sequence-level divergence to word-level losses that can be computed in a tractable manner. Experiments across four datasets show that our methods outperform existing KD approaches, and that our symmetric distilling losses can better force the student to learn from the teacher distribution.
</details>
<details>
<summary>摘要</summary>
知识填充（KD）是将知识从大模型传递到小模型的过程。随着语言模型的不断扩大，KD在自然语言处理领域得到了越来越多的关注。在这项工作中，我们提出了f-DISTILL框架，将序列级知识填充定为最小化一个泛化f-散度函数。我们提出了四种填充变体，并证明了现有的SeqKD和ENGINE方法是我们f-DISTILL方法的近似方法。我们还 deriv出了逐步分解，将不可 tractable的序列级散度转化为可计算的单词级损失。经过四个数据集的实验，我们发现我们的方法可以超越现有的KD方法，并且我们的对称填充损失可以更好地让学生学习教师分布。
</details></li>
</ul>
<hr>
<h2 id="Rotation-Invariant-Random-Features-Provide-a-Strong-Baseline-for-Machine-Learning-on-3D-Point-Clouds"><a href="#Rotation-Invariant-Random-Features-Provide-a-Strong-Baseline-for-Machine-Learning-on-3D-Point-Clouds" class="headerlink" title="Rotation-Invariant Random Features Provide a Strong Baseline for Machine Learning on 3D Point Clouds"></a>Rotation-Invariant Random Features Provide a Strong Baseline for Machine Learning on 3D Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06271">http://arxiv.org/abs/2308.06271</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meliao/rotation-invariant-random-features">https://github.com/meliao/rotation-invariant-random-features</a></li>
<li>paper_authors: Owen Melia, Eric Jonas, Rebecca Willett</li>
<li>for: 这篇论文是为了探讨三维点 cloud 数据的 rotation-invariant 机器学习方法，以及这种方法在分子性质预测和3D shape 分类 зада务中的表现。</li>
<li>methods: 本论文使用了一种简单且通用的随机特征方法，将三维点 cloud 数据转换为 rotation-invariant 的特征，并且显示了这种方法在标准分子性质预测 benchmark 资料集 QM7 和 QM9 上匹配或超越了一般的 rotation-invariant neural network 的性能。</li>
<li>results: 本论文显示了这种方法在分子性质预测和3D shape 分类 зада务中的一般化和高效性，并且与一般的 rotation-invariant neural network 相比，预测时间仅有一个数量级的差异。<details>
<summary>Abstract</summary>
Rotational invariance is a popular inductive bias used by many fields in machine learning, such as computer vision and machine learning for quantum chemistry. Rotation-invariant machine learning methods set the state of the art for many tasks, including molecular property prediction and 3D shape classification. These methods generally either rely on task-specific rotation-invariant features, or they use general-purpose deep neural networks which are complicated to design and train. However, it is unclear whether the success of these methods is primarily due to the rotation invariance or the deep neural networks. To address this question, we suggest a simple and general-purpose method for learning rotation-invariant functions of three-dimensional point cloud data using a random features approach. Specifically, we extend the random features method of Rahimi & Recht 2007 by deriving a version that is invariant to three-dimensional rotations and showing that it is fast to evaluate on point cloud data. We show through experiments that our method matches or outperforms the performance of general-purpose rotation-invariant neural networks on standard molecular property prediction benchmark datasets QM7 and QM9. We also show that our method is general-purpose and provides a rotation-invariant baseline on the ModelNet40 shape classification task. Finally, we show that our method has an order of magnitude smaller prediction latency than competing kernel methods.
</details>
<details>
<summary>摘要</summary>
“旋转协variance是机器学习中广泛使用的 inductive bias，如计算机视觉和量子化学机器学习。旋转不变机器学习方法在许多任务上设置了州OF-the-art，包括分子性质预测和3D形状分类。这些方法通常是使用任务特定的旋转不变特征，或者使用通用的深度神经网络，后者具有复杂的设计和训练问题。然而，是否 rotation协variance的成功主要归功于旋转不变性还是深度神经网络，这问题仍然存在。为了解决这个问题，我们提出了一种简单和通用的方法，利用随机特征来学习三维点云数据上的旋转不变函数。具体来说，我们将 Rahimi & Recht 2007 的随机特征方法扩展到三维旋转不变的版本，并证明其在点云数据上快速评估。我们通过实验表明，我们的方法与通用的旋转不变神经网络相比，在标准分子性质预测 benchmark 数据上匹配或超越其性能。我们还证明了我们的方法是通用的，并在 ModelNet40 形状分类任务上提供了旋转不变基准。最后，我们证明了我们的方法与竞争的核函数方法相比，预测延迟只有一个数量级。”
</details></li>
</ul>
<hr>
<h2 id="RCT-Rejection-Sampling-for-Causal-Estimation-Evaluation"><a href="#RCT-Rejection-Sampling-for-Causal-Estimation-Evaluation" class="headerlink" title="RCT Rejection Sampling for Causal Estimation Evaluation"></a>RCT Rejection Sampling for Causal Estimation Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15176">http://arxiv.org/abs/2307.15176</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kakeith/rct_rejection_sampling">https://github.com/kakeith/rct_rejection_sampling</a></li>
<li>paper_authors: Katherine A. Keith, Sergey Feldman, David Jurgens, Jonathan Bragg, Rohit Bhattacharya</li>
<li>For: The paper is written to address the challenge of confounding in observational data, specifically in high-dimensional settings such as text data, genomics, or the behavioral social sciences.* Methods: The paper proposes a new method called RCT rejection sampling, which uses subsampling of randomized controlled trials (RCTs) to create confounded observational datasets, and provides theoretical guarantees for causal identification.* Results: The paper shows that the proposed algorithm results in low bias when evaluated on synthetic data, and highlights several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets. Additionally, the paper provides a proof of concept using a novel, real-world RCT consisting of approximately 70k observations and text data as high-dimensional covariates.<details>
<summary>Abstract</summary>
Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates -- such as text data, genomics, or the behavioral social sciences -- researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm indeed results in low bias when oracle estimators are evaluated on the confounded samples, which is not always the case for a previously proposed algorithm. In addition to this identification result, we highlight several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets. As a proof of concept, we implement an example evaluation pipeline and walk through these finite data considerations with a novel, real-world RCT -- which we release publicly -- consisting of approximately 70k observations and text data as high-dimensional covariates. Together, these contributions build towards a broader agenda of improved empirical evaluation for causal estimation.
</details>
<details>
<summary>摘要</summary>
干扰是观察数据中 causal 效应的主要障碍。在高维 covariate 的设置下，such as text data, genomics, or behavioral social sciences, researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited.在这种工作中，我们建立了一种有前途的 empirical evaluation strategy， simplify evaluation design and use real data:  Randomized controlled trials (RCTs) 的 subsampling 创造了受到恶势力影响的观察数据，而使用 RCTs 的平均 causal effect 作为真实参照。我们提出了一种新的抽样算法，称为 RCT rejection sampling，并提供了理论保证，表明在观察数据中，causal 标识存在。使用 sintetic 数据，我们示出了我们的算法实际上具有低偏误。除了这一标识结果外，我们还提出了一些考虑finite data 的设计师可能会在他们自己的数据上使用 RCT rejection sampling 的问题。作为证明，我们实现了一个示例评估管道，并详细介绍了这些finite data 的考虑事项。总之，我们的贡献是 towards a broader agenda of improved empirical evaluation for causal estimation。
</details></li>
</ul>
<hr>
<h2 id="Causative-Cyberattacks-on-Online-Learning-based-Automated-Demand-Response-Systems"><a href="#Causative-Cyberattacks-on-Online-Learning-based-Automated-Demand-Response-Systems" class="headerlink" title="Causative Cyberattacks on Online Learning-based Automated Demand Response Systems"></a>Causative Cyberattacks on Online Learning-based Automated Demand Response Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15175">http://arxiv.org/abs/2307.15175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samrat Acharya, Yury Dvorkin, Ramesh Karri</li>
<li>for: 本研究旨在探讨人工智能（AI）在供应侧热卷较小的电力loads中的应用，以及这些loads的数据集被用来验证攻击者可能会利用的攻击方法。</li>
<li>methods: 本研究使用了人工智能学习方法，包括机器学习和深度学习，以分析用户的能源使用模式并设计优化的奖励策略。</li>
<li>results: 研究发现，通过在DR客户端上执行攻击，可以让DR客户端错误地响应DR奖励，从而导致DR客户端的能源消耗增加，并且可以通过控制DR客户端的响应来 manipulate DR market。<details>
<summary>Abstract</summary>
Power utilities are adopting Automated Demand Response (ADR) to replace the costly fuel-fired generators and to preempt congestion during peak electricity demand. Similarly, third-party Demand Response (DR) aggregators are leveraging controllable small-scale electrical loads to provide on-demand grid support services to the utilities. Some aggregators and utilities have started employing Artificial Intelligence (AI) to learn the energy usage patterns of electricity consumers and use this knowledge to design optimal DR incentives. Such AI frameworks use open communication channels between the utility/aggregator and the DR customers, which are vulnerable to \textit{causative} data integrity cyberattacks. This paper explores vulnerabilities of AI-based DR learning and designs a data-driven attack strategy informed by DR data collected from the New York University (NYU) campus buildings. The case study demonstrates the feasibility and effects of maliciously tampering with (i) real-time DR incentives, (ii) DR event data sent to DR customers, and (iii) responses of DR customers to the DR incentives.
</details>
<details>
<summary>摘要</summary>
各种能源供应商正在采用自动化需求应答（ADR），以取代昂贵的燃料燃烧机和预防峰值电力需求压力。同时，第三方需求应答（DR）聚合者也在利用可控小规模电力负荷来提供实时电网支持服务。一些聚合者和供应商已经开始使用人工智能（AI）来学习电力消耗者的能源使用模式，并使用这些知识来设计优化的DR激励计划。这些AI框架使用公开的通信频道 между供应商/聚合者和DR客户，这些通信频道受到了 causative 数据完整性攻击的威胁。本文探讨了 AI-based DR 学习的漏洞，并设计了一种基于 DR 数据的数据驱动攻击策略。案例研究表明了在 NYU 校园建筑物上收集的 DR 数据可以用于设计和实现这种攻击策略。
</details></li>
</ul>
<hr>
<h2 id="PredictChain-Empowering-Collaboration-and-Data-Accessibility-for-AI-in-a-Decentralized-Blockchain-based-Marketplace"><a href="#PredictChain-Empowering-Collaboration-and-Data-Accessibility-for-AI-in-a-Decentralized-Blockchain-based-Marketplace" class="headerlink" title="PredictChain: Empowering Collaboration and Data Accessibility for AI in a Decentralized Blockchain-based Marketplace"></a>PredictChain: Empowering Collaboration and Data Accessibility for AI in a Decentralized Blockchain-based Marketplace</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15168">http://arxiv.org/abs/2307.15168</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-and-blockchain/s23_predictchain">https://github.com/ai-and-blockchain/s23_predictchain</a></li>
<li>paper_authors: Matthew T. Pisano, Connor J. Patterson, Oshani Seneviratne</li>
<li>For: 该论文旨在提供一个基于区块链的市场平台，帮助用户上传数据集用于预测机器学习模型训练，或者请求已上传数据集的模型训练，或者提交查询到已训练模型。* Methods: 该论文提出了一个基于区块链的机制，通过各个节点的可用计算资源来运行多种不同特征的预测机器学习模型，包括成本、速度、简洁、能力和成本效果等。* Results: 该论文通过实现了一个分布式的预测机器学习模型市场平台，推动了数据分享和中央云服务器的减少，并且为用户提供了一个可靠、安全、可控的机制来训练和使用预测机器学习模型。<details>
<summary>Abstract</summary>
Limited access to computing resources and training data poses significant challenges for individuals and groups aiming to train and utilize predictive machine learning models. Although numerous publicly available machine learning models exist, they are often unhosted, necessitating end-users to establish their computational infrastructure. Alternatively, these models may only be accessible through paid cloud-based mechanisms, which can prove costly for general public utilization. Moreover, model and data providers require a more streamlined approach to track resource usage and capitalize on subsequent usage by others, both financially and otherwise. An effective mechanism is also lacking to contribute high-quality data for improving model performance. We propose a blockchain-based marketplace called "PredictChain" for predictive machine-learning models to address these issues. This marketplace enables users to upload datasets for training predictive machine learning models, request model training on previously uploaded datasets, or submit queries to trained models. Nodes within the blockchain network, equipped with available computing resources, will operate these models, offering a range of archetype machine learning models with varying characteristics, such as cost, speed, simplicity, power, and cost-effectiveness. This decentralized approach empowers users to develop improved models accessible to the public, promotes data sharing, and reduces reliance on centralized cloud providers.
</details>
<details>
<summary>摘要</summary>
To address these issues, we propose a blockchain-based marketplace called "PredictChain" for predictive machine-learning models. This marketplace enables users to upload datasets for training predictive machine learning models, request model training on previously uploaded datasets, or submit queries to trained models. Nodes within the blockchain network, equipped with available computing resources, will operate these models, offering a range of archetype machine learning models with varying characteristics, such as cost, speed, simplicity, power, and cost-effectiveness. This decentralized approach empowers users to develop improved models accessible to the public, promotes data sharing, and reduces reliance on centralized cloud providers.
</details></li>
</ul>
<hr>
<h2 id="VISU-at-WASSA-2023-Shared-Task-Detecting-Emotions-in-Reaction-to-News-Stories-Leveraging-BERT-and-Stacked-Embeddings"><a href="#VISU-at-WASSA-2023-Shared-Task-Detecting-Emotions-in-Reaction-to-News-Stories-Leveraging-BERT-and-Stacked-Embeddings" class="headerlink" title="VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings"></a>VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15164">http://arxiv.org/abs/2307.15164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vivek Kumar, Sushmita Singh, Prayag Tiwari</li>
<li>for: 这项研究旨在开发深度学习模型，用于从新闻文章中推断情感表达。</li>
<li>methods: 研究使用word embedding表示法，并采用了适应性的预处理策略，以捕捉情感表达的细节。试验使用了静态和上下文嵌入（个体和堆叠），并与BiLSTM和Transformer模型进行了比较。</li>
<li>results: 研究在WASSA 2023共享任务中的情感分类任务中取得了第十名，其中Macro F1得分为0.2717，证明了实施的方法的有效性，尤其是在小样本和不均衡的数据集上。<details>
<summary>Abstract</summary>
Our system, VISU, participated in the WASSA 2023 Shared Task (3) of Emotion Classification from essays written in reaction to news articles. Emotion detection from complex dialogues is challenging and often requires context/domain understanding. Therefore in this research, we have focused on developing deep learning (DL) models using the combination of word embedding representations with tailored prepossessing strategies to capture the nuances of emotions expressed. Our experiments used static and contextual embeddings (individual and stacked) with Bidirectional Long short-term memory (BiLSTM) and Transformer based models. We occupied rank tenth in the emotion detection task by scoring a Macro F1-Score of 0.2717, validating the efficacy of our implemented approaches for small and imbalanced datasets with mixed categories of target emotions.
</details>
<details>
<summary>摘要</summary>
我们的系统，VISU，参加了2023年WASSA共享任务（3）的情感分类从新闻文章中的反应文章。情感检测从复杂对话中是挑战，需要Context/领域理解。因此在这项研究中，我们集中了深度学习（DL）模型，使用词嵌入表示和定制预处理策略，捕捉表达出的情感细节。我们的实验使用静态和上下文嵌入（个人和堆叠）与BiLSTM和Transformer基于模型。我们在情感检测任务中占据了第十名，得分 macro F1-Score 0.2717，证明我们实施的方法对小型和杂合类目的数据集具有效果。
</details></li>
</ul>
<hr>
<h2 id="R-LPIPS-An-Adversarially-Robust-Perceptual-Similarity-Metric"><a href="#R-LPIPS-An-Adversarially-Robust-Perceptual-Similarity-Metric" class="headerlink" title="R-LPIPS: An Adversarially Robust Perceptual Similarity Metric"></a>R-LPIPS: An Adversarially Robust Perceptual Similarity Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15157">http://arxiv.org/abs/2307.15157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/saraghazanfari/r-lpips">https://github.com/saraghazanfari/r-lpips</a></li>
<li>paper_authors: Sara Ghazanfari, Siddharth Garg, Prashanth Krishnamurthy, Farshad Khorrami, Alexandre Araujo</li>
<li>For: The paper aims to address the security concerns of the Learned Perceptual Image Patch Similarity (LPIPS) metric by proposing a new metric called Robust Learned Perceptual Image Patch Similarity (R-LPIPS) that is more robust to adversarial examples.* Methods: The R-LPIPS metric leverages adversarially trained deep features to improve its robustness against adversarial examples.* Results: The paper demonstrates the superiority of R-LPIPS compared to the classical LPIPS metric through a comprehensive set of experiments.<details>
<summary>Abstract</summary>
Similarity metrics have played a significant role in computer vision to capture the underlying semantics of images. In recent years, advanced similarity metrics, such as the Learned Perceptual Image Patch Similarity (LPIPS), have emerged. These metrics leverage deep features extracted from trained neural networks and have demonstrated a remarkable ability to closely align with human perception when evaluating relative image similarity. However, it is now well-known that neural networks are susceptible to adversarial examples, i.e., small perturbations invisible to humans crafted to deliberately mislead the model. Consequently, the LPIPS metric is also sensitive to such adversarial examples. This susceptibility introduces significant security concerns, especially considering the widespread adoption of LPIPS in large-scale applications. In this paper, we propose the Robust Learned Perceptual Image Patch Similarity (R-LPIPS) metric, a new metric that leverages adversarially trained deep features. Through a comprehensive set of experiments, we demonstrate the superiority of R-LPIPS compared to the classical LPIPS metric. The code is available at https://github.com/SaraGhazanfari/R-LPIPS.
</details>
<details>
<summary>摘要</summary>
Computer vision 中的相似度度量有很大的作用，用于捕捉图像的含义。在最近几年，高级相似度度量，如学习后的图像特征相似度度量（LPIPS），出现了。这些度量利用训练过的神经网络提取的深度特征，并表现出了与人类视觉相似的惊人能力。然而，现在已经广泛 acknowledge 的是，神经网络受到抗性示例的影响，即通过小量不可见的扰动欺骗模型的特殊例子。这种抗性引入了安全性问题，尤其是在大规模应用中。在这篇论文中，我们提出了robust learned perceptual image patch similarity（R-LPIPS）度量，一种新的度量，利用抗性训练的深度特征。通过全面的实验，我们证明了R-LPIPS 度量的superiority 相比 classical LPIPS 度量。代码可以在 <https://github.com/SaraGhazanfari/R-LPIPS> 中找到。
</details></li>
</ul>
<hr>
<h2 id="A-B-Testing-and-Best-arm-Identification-for-Linear-Bandits-with-Robustness-to-Non-stationarity"><a href="#A-B-Testing-and-Best-arm-Identification-for-Linear-Bandits-with-Robustness-to-Non-stationarity" class="headerlink" title="A&#x2F;B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity"></a>A&#x2F;B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15154">http://arxiv.org/abs/2307.15154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihan Xiong, Romain Camilleri, Maryam Fazel, Lalit Jain, Kevin Jamieson</li>
<li>for: The paper is written for identifying the best arm in a linear bandit problem with a non-stationary environment.</li>
<li>methods: The paper proposes a novel algorithm called $\mathsf{P1}$-$\mathsf{RAGE}$ that combines the advantages of both stationary and non-stationary algorithms to achieve robustness and fast identification.</li>
<li>results: The paper shows that the proposed algorithm achieves a lower error probability than existing algorithms in the non-stationary setting, while also performing well in benign settings.<details>
<summary>Abstract</summary>
We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\mathcal{X}\subset\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\left\lbrace\theta_t\right\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \arg\max_{x\in\mathcal{X}x^\top\sum_{t=1}^{T}\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\theta_t = \theta_1$ for all $t$ and demonstrated that the error probability decreases as $\exp(-T /\rho^*)$ for a problem-dependent constant $\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\mathcal{X}$ at each time then the error probability decreases as $\exp(-T\Delta^2_{(1)}/d)$, where $\Delta_{(1)} = \min_{x \neq x^*} (x^* - x)^\top \frac{1}{T}\sum_{t=1}^T \theta_t$. As there exist environments where $\Delta_{(1)}^2/ d \ll 1/ \rho^*$, we are motivated to propose a novel algorithm $\mathsf{P1}$-$\mathsf{RAGE}$ that aims to obtain the best of both worlds: robustness to non-stationarity and fast rates of identification in benign settings. We characterize the error probability of $\mathsf{P1}$-$\mathsf{RAGE}$ and demonstrate empirically that the algorithm indeed never performs worse than G-optimal design but compares favorably to the best algorithms in the stationary setting.
</details>
<details>
<summary>摘要</summary>
我们研究了固定预算最佳臂识别（BAI）问题，对于线性弹珠在潜在非站ARY环境中。我们有一个终端臂集$\mathcal{X}\subset\mathbb{R}^d$,一个固定预算$T$,以及一个无法预测的系列参数$\left\lbrace\theta_t\right\rbrace_{t=1}^{T}$。一个算法将尝试在可能的最高概率下正确地识别最佳臂$x^*:=\arg\max_{x\in\mathcal{X}x^\top\sum_{t=1}^{T}\theta_t$。先前的工作已经处理过站ARY情况，其中$\theta_t = \theta_1$ for all $t$，并证明了错误概率随着$T$变化为$\exp(-T/\rho^*)$，其中$\rho^*$是问题相依的常数。但在实际的$A/B/n$多变量测试中，环境通常是非站ARY的，因此预期站ARY的算法可以轻松失败。为了实现预算Robustness，我们知道如果在每个时间点随机地选择非逐次的G优化设计 over $\mathcal{X}$，错误概率将随着$T\Delta^2_{(1)}/d$下降，其中$\Delta_{(1)} = \min_{x \neq x^*} (x^* - x)^\top \frac{1}{T}\sum_{t=1}^T \theta_t$。因为存在环境中$\Delta_{(1)}^2/ d \ll 1/ \rho^*$，我们被动机验证一个新的算法$\mathsf{P1}-\mathsf{RAGE}$，它将寻求最佳的两个世界：Robustness to non-stationarity和在正常情况下快速的识别速率。我们描述了$\mathsf{P1}-\mathsf{RAGE}$的错误概率，并证明了它在实际中终会不比G优化设计差。
</details></li>
</ul>
<hr>
<h2 id="R-Block-Regularized-Block-of-Dropout-for-convolutional-networks"><a href="#R-Block-Regularized-Block-of-Dropout-for-convolutional-networks" class="headerlink" title="R-Block: Regularized Block of Dropout for convolutional networks"></a>R-Block: Regularized Block of Dropout for convolutional networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15150">http://arxiv.org/abs/2307.15150</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liqi Wang, Qiya Hu</li>
<li>for: 这篇论文主要针对于 konvolutional Neural Networks (CNNs) 中的批处理层REGULARIZATION技术，即 Dropout 技术。</li>
<li>methods: 该论文提出了一种名为 R-Block 的互助学习训练策略，该策略在 konvolutional Neural Networks (CNNs) 中使用两个不同的 Dropout 区域来强制两个生成的差分最大化子模型的输出分布相互一致。</li>
<li>results: 该论文的实验结果表明，R-Block 可以比其他已有的结构化 Dropout 变体实现更好的性能。此外，作者还证明了他们的子模型构建方法超越了其他方法。<details>
<summary>Abstract</summary>
Dropout as a regularization technique is widely used in fully connected layers while is less effective in convolutional layers. Therefore more structured forms of dropout have been proposed to regularize convolutional networks. The disadvantage of these methods is that the randomness introduced causes inconsistency between training and inference. In this paper, we apply a mutual learning training strategy for convolutional layer regularization, namely R-Block, which forces two outputs of the generated difference maximizing sub models to be consistent with each other. Concretely, R-Block minimizes the losses between the output distributions of two sub models with different drop regions for each sample in the training dataset. We design two approaches to construct such sub models. Our experiments demonstrate that R-Block achieves better performance than other existing structured dropout variants. We also demonstrate that our approaches to construct sub models outperforms others.
</details>
<details>
<summary>摘要</summary>
dropout 作为常见的正则化技术，通常用于全连接层。然而，在卷积层中，dropout 的效果较差。因此，有些更Structured的 dropout 方法被提议用于卷积网络正则化。然而，这些方法的随机性引入会导致训练和推理中的不一致。在这篇论文中，我们应用了对卷积层REGULARIZATION的mutual learning训练策略，即R-Block，该策略要求两个生成的差分最大化子模型的输出分布相互匹配。具体来说，R-Block 将每个样本在训练集中的输出分布之间的损失进行最小化。我们设计了两种方法来构建子模型。我们的实验表明，R-Block 比其他已有的Structured dropout变种表现更好。此外，我们的子模型构建方法也超过了其他方法。
</details></li>
</ul>
<hr>
<h2 id="Distilled-Feature-Fields-Enable-Few-Shot-Language-Guided-Manipulation"><a href="#Distilled-Feature-Fields-Enable-Few-Shot-Language-Guided-Manipulation" class="headerlink" title="Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation"></a>Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07931">http://arxiv.org/abs/2308.07931</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Shen, Ge Yang, Alan Yu, Jansen Wong, Leslie Pack Kaelbling, Phillip Isola</li>
<li>for:  bridges the 2D-to-3D gap for robotic manipulation</li>
<li>methods:  leverages distilled feature fields to combine accurate 3D geometry with rich semantics from 2D foundation models</li>
<li>results:  achieves in-the-wild generalization to unseen objects using few-shot learning method for 6-DOF grasping and placing<details>
<summary>Abstract</summary>
Self-supervised and language-supervised image models contain rich knowledge of the world that is important for generalization. Many robotic tasks, however, require a detailed understanding of 3D geometry, which is often lacking in 2D image features. This work bridges this 2D-to-3D gap for robotic manipulation by leveraging distilled feature fields to combine accurate 3D geometry with rich semantics from 2D foundation models. We present a few-shot learning method for 6-DOF grasping and placing that harnesses these strong spatial and semantic priors to achieve in-the-wild generalization to unseen objects. Using features distilled from a vision-language model, CLIP, we present a way to designate novel objects for manipulation via free-text natural language, and demonstrate its ability to generalize to unseen expressions and novel categories of objects.
</details>
<details>
<summary>摘要</summary>
自我超视和语言超视图像模型含有重要的世界知识，这对总体化很重要。然而，许多 робо控任务需要细节的三维几何理解，这经常缺失在二维图像特征中。这种工作弥补了这个二维-三维之间的差异，用精炼的特征场来结合精准的三维几何和丰富的 semantics from 二维基础模型。我们提出了一种几个shot学习方法，用于6DOF抓取和置放，这种方法利用了这些强大的空间和 semantics 假设来实现在野外的总体化，并且可以处理未看过的物体。使用从视力语言模型CLIP中提取出的特征，我们提出了一种通过自然语言来标识新的物体，并示出其能够泛化到未看过的表达和新的类别的物体。
</details></li>
</ul>
<hr>
<h2 id="On-Normalised-Discounted-Cumulative-Gain-as-an-Offline-Evaluation-Metric-for-Top-n-Recommendation"><a href="#On-Normalised-Discounted-Cumulative-Gain-as-an-Offline-Evaluation-Metric-for-Top-n-Recommendation" class="headerlink" title="On (Normalised) Discounted Cumulative Gain as an Offline Evaluation Metric for Top-$n$ Recommendation"></a>On (Normalised) Discounted Cumulative Gain as an Offline Evaluation Metric for Top-$n$ Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15053">http://arxiv.org/abs/2307.15053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olivier Jeunen, Ivan Potapov, Aleksei Ustimenko</li>
<li>for: 这种研究是为了检验推荐系统的评价方法，特别是使用 Discounted Cumulative Gain (DCG)  metric 的正确性。</li>
<li>methods: 这篇论文使用了一种 Critical Look 的方法来检验 DCG  metric，包括对 DCG 的不准确性和不一致性的分析，以及一种基于实际数据的拟合方法来补做 DCG 的缺陷。</li>
<li>results: 研究发现，不正确地使用 DCG metric 可能会导致推荐系统的评价结果偏差，而且在某些情况下，正常化 DCG metric 可能会导致推荐系统的评价结果与实际情况相反。<details>
<summary>Abstract</summary>
Approaches to recommendation are typically evaluated in one of two ways: (1) via a (simulated) online experiment, often seen as the gold standard, or (2) via some offline evaluation procedure, where the goal is to approximate the outcome of an online experiment. Several offline evaluation metrics have been adopted in the literature, inspired by ranking metrics prevalent in the field of Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one such metric that has seen widespread adoption in empirical studies, and higher (n)DCG values have been used to present new methods as the state-of-the-art in top-$n$ recommendation for many years.   Our work takes a critical look at this approach, and investigates when we can expect such metrics to approximate the gold standard outcome of an online experiment. We formally present the assumptions that are necessary to consider DCG an unbiased estimator of online reward and provide a derivation for this metric from first principles, highlighting where we deviate from its traditional uses in IR. Importantly, we show that normalising the metric renders it inconsistent, in that even when DCG is unbiased, ranking competing methods by their normalised DCG can invert their relative order. Through a correlation analysis between off- and on-line experiments conducted on a large-scale recommendation platform, we show that our unbiased DCG estimates strongly correlate with online reward, even when some of the metric's inherent assumptions are violated. This statement no longer holds for its normalised variant, suggesting that nDCG's practical utility may be limited.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese:Approaches to recommendation are typically evaluated in one of two ways: (1) via a (simulated) online experiment, often seen as the gold standard, or (2) via some offline evaluation procedure, where the goal is to approximate the outcome of an online experiment. Several offline evaluation metrics have been adopted in the literature, inspired by ranking metrics prevalent in the field of Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one such metric that has seen widespread adoption in empirical studies, and higher (n)DCG values have been used to present new methods as the state-of-the-art in top-$n$ recommendation for many years.   Our work takes a critical look at this approach, and investigates when we can expect such metrics to approximate the gold standard outcome of an online experiment. We formally present the assumptions that are necessary to consider DCG an unbiased estimator of online reward and provide a derivation for this metric from first principles, highlighting where we deviate from its traditional uses in IR. Importantly, we show that normalising the metric renders it inconsistent, in that even when DCG is unbiased, ranking competing methods by their normalised DCG can invert their relative order. Through a correlation analysis between off- and on-line experiments conducted on a large-scale recommendation platform, we show that our unbiased DCG estimates strongly correlate with online reward, even when some of the metric's inherent assumptions are violated. This statement no longer holds for its normalised variant, suggesting that nDCG's practical utility may be limited.Translate the text into Simplified Chinese:<<SYS>>approaches to recommendation 通常被评估在两种方式之一：在线实验（通常是模拟的）或者离线评估过程，目标是估计在线实验的结果。在文献中，一些离线评估度量已经得到了广泛的采用，启发自信息检索领域中的排名度量。normalized discounted cumulative gain（nDCG）是其中的一个，在许多年中，高值nDCG被用来证明新方法的state-of-the-art。我们的工作是 kritically examining this approach，并investigating when we can expect such metrics to approximate the gold standard outcome of an online experiment。我们正式地表明了考虑DCG为无 bias的估计在线奖励的假设，并提供了这个度量的 derive from first principles，并且在IR中的传统用途上出现了偏差。进一步，我们表明了normalizing the metric renders it inconsistent，因为当DCG是无 bias的时，对比竞争方法的normalized DCG可以反转其相对顺序。通过对离线和在线实验的相对分析，我们显示了我们的不偏DCG估计与在线奖励之间强相关性，即使一些度量的内在假设被违反。这个说明不再 holds for its normalized variant， suggesting that nDCG's practical utility may be limited。Translation notes:* "approaches to recommendation" is translated as "推荐方法"* "online experiment" is translated as "在线实验"* "offline evaluation procedure" is translated as "离线评估过程"* "normalised" is translated as "normalized"* "Discounted Cumulative Gain" is translated as "折扣累积奖励"* "nDCG" is translated as "nDCG"* "unbiased" is translated as "无偏"* "practical utility" is translated as "实际用途"
</details></li>
</ul>
<hr>
<h2 id="A-Transformer-based-Approach-for-Arabic-Offline-Handwritten-Text-Recognition"><a href="#A-Transformer-based-Approach-for-Arabic-Offline-Handwritten-Text-Recognition" class="headerlink" title="A Transformer-based Approach for Arabic Offline Handwritten Text Recognition"></a>A Transformer-based Approach for Arabic Offline Handwritten Text Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15045">http://arxiv.org/abs/2307.15045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saleh Momeni, Bagher BabaAli</li>
<li>For: 本研究强调特定问题是recognizing offline Arabic handwritten text，它在pattern recognition和机器学习领域中是一个挑战性的问题，具有广泛的应用领域。* Methods: 我们提出了两种新的架构方法，即Transformer Transducer和标准sequence-to-sequence Transformer，以提高recognizing offline Arabic handwritten text的准确率和速度。我们的方法可以模型语言依赖关系，并且只需要使用注意机制，因此更加平行化和简单化。* Results: 我们的方法在Arabic KHATT数据集上进行评估，与现有状态的方法相比，我们的方法可以提高recognizing offline Arabic handwritten text的准确率。<details>
<summary>Abstract</summary>
Handwriting recognition is a challenging and critical problem in the fields of pattern recognition and machine learning, with applications spanning a wide range of domains. In this paper, we focus on the specific issue of recognizing offline Arabic handwritten text. Existing approaches typically utilize a combination of convolutional neural networks for image feature extraction and recurrent neural networks for temporal modeling, with connectionist temporal classification used for text generation. However, these methods suffer from a lack of parallelization due to the sequential nature of recurrent neural networks. Furthermore, these models cannot account for linguistic rules, necessitating the use of an external language model in the post-processing stage to boost accuracy. To overcome these issues, we introduce two alternative architectures, namely the Transformer Transducer and the standard sequence-to-sequence Transformer, and compare their performance in terms of accuracy and speed. Our approach can model language dependencies and relies only on the attention mechanism, thereby making it more parallelizable and less complex. We employ pre-trained Transformers for both image understanding and language modeling. Our evaluation on the Arabic KHATT dataset demonstrates that our proposed method outperforms the current state-of-the-art approaches for recognizing offline Arabic handwritten text.
</details>
<details>
<summary>摘要</summary>
《手写文本识别是 Pattern recognition 和机器学习 领域中的一个挑战性和重要问题，其应用范围广泛。在这篇论文中，我们专注于特定的问题是识别离线阿拉伯文本。现有的方法通常使用 convolutional neural networks 提取图像特征和 recurrent neural networks 模拟时间序列，并使用 connectionist temporal classification 生成文本。然而，这些方法受到缺乏并行化的限制，以及无法考虑语言规则的缺点。为了解决这些问题，我们介绍了两种alternative architecture，即 Transformer Transducer 和标准sequence-to-sequence Transformer，并比较其性能。我们的方法可以模型语言依赖关系，只需要使用注意机制，从而使其更加并行化和简单。我们使用预训练的 Transformer 来进行图像理解和语言模型化。我们的评估表明，我们提出的方法在阿拉伯文本KHATT 数据集上的识别性能比现有状态的方法高。》Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Universal-and-Transferable-Adversarial-Attacks-on-Aligned-Language-Models"><a href="#Universal-and-Transferable-Adversarial-Attacks-on-Aligned-Language-Models" class="headerlink" title="Universal and Transferable Adversarial Attacks on Aligned Language Models"></a>Universal and Transferable Adversarial Attacks on Aligned Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15043">http://arxiv.org/abs/2307.15043</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/llm-attacks/llm-attacks">https://github.com/llm-attacks/llm-attacks</a></li>
<li>paper_authors: Andy Zou, Zifan Wang, J. Zico Kolter, Matt Fredrikson</li>
<li>for: 这个论文是为了攻击已经Alignment的语言模型，使其生成不良内容。</li>
<li>methods: 该论文使用了 suffix 的搜索技术，自动生成了攻击性的提问。</li>
<li>results: 该论文在多个模型和多个黑盒模型上实现了攻击，并且发现了这些攻击的 suffix 可以在不同的情况下传递。<details>
<summary>Abstract</summary>
Because "out-of-the-box" large language models are capable of generating a great deal of objectionable content, recent work has focused on aligning these models in an attempt to prevent undesirable generation. While there has been some success at circumventing these measures -- so-called "jailbreaks" against LLMs -- these attacks have required significant human ingenuity and are brittle in practice. In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors. Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer). However, instead of relying on manual engineering, our approach automatically produces these adversarial suffixes by a combination of greedy and gradient-based search techniques, and also improves over past automatic prompt generation methods.   Surprisingly, we find that the adversarial prompts generated by our approach are quite transferable, including to black-box, publicly released LLMs. Specifically, we train an adversarial attack suffix on multiple prompts (i.e., queries asking for many different types of objectionable content), as well as multiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting attack suffix is able to induce objectionable content in the public interfaces to ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat, Pythia, Falcon, and others. In total, this work significantly advances the state-of-the-art in adversarial attacks against aligned language models, raising important questions about how such systems can be prevented from producing objectionable information. Code is available at github.com/llm-attacks/llm-attacks.
</details>
<details>
<summary>摘要</summary>
因为"出包"大型自然语言模型可以生成很多不适内容，现有的工作集中在对这些模型进行对齐，以防止不适的生成。虽然有一些成功的"监禁"攻击（LLMs），但这些攻击需要人工智能和灵活，并且在实践中有些脆弱。在这篇论文中，我们提出了一种简单有效的攻击方法，使得对齐的语言模型生成不适行为。具体来说，我们的方法找到一个附加到各种查询中，以便使Language Model（LLM）生成不适的内容的 suffix。而不是人工设计，我们的方法通过扫描和梯度基于搜索技术自动生成这些恶意提示。 surprisingly，我们发现了这些恶意提示的可移植性，包括黑盒、公开发布的LLMs。 Specifically，我们在多个提示（即很多种不同类型的不适内容查询）和多个模型（我们的 случаyed Vicuna-7B和13B）上进行了训练，并得到了可以在公共的ChatGPT、Bard和Claude等interface中生成不适内容的攻击 suffix。总之，这项工作提前了对对齐语言模型的攻击的状态艺术，引发了关于如何防止这些系统生成不适信息的重要问题。 Code可以在github.com/llm-attacks/llm-attacks中找到。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Morphing-Attacks-via-Continual-Incremental-Training"><a href="#Detecting-Morphing-Attacks-via-Continual-Incremental-Training" class="headerlink" title="Detecting Morphing Attacks via Continual Incremental Training"></a>Detecting Morphing Attacks via Continual Incremental Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15105">http://arxiv.org/abs/2307.15105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Pellegrini, Guido Borghi, Annalisa Franco, Davide Maltoni</li>
<li>for: 实现增量训练，当资料传输和储存有限制时，使得对多个数据来源进行批量训练具有挑战性。</li>
<li>methods: 采用不同的Continual Learning方法来实现增量训练，包括Learning without Forgetting（LwF）等方法。</li>
<li>results: LwF方法在这个方案中表现良好，并且在具有变化大小的数据批量中进行增量训练时，能够实现好的表现。<details>
<summary>Abstract</summary>
Scenarios in which restrictions in data transfer and storage limit the possibility to compose a single dataset -- also exploiting different data sources -- to perform a batch-based training procedure, make the development of robust models particularly challenging. We hypothesize that the recent Continual Learning (CL) paradigm may represent an effective solution to enable incremental training, even through multiple sites. Indeed, a basic assumption of CL is that once a model has been trained, old data can no longer be used in successive training iterations and in principle can be deleted. Therefore, in this paper, we investigate the performance of different Continual Learning methods in this scenario, simulating a learning model that is updated every time a new chunk of data, even of variable size, is available. Experimental results reveal that a particular CL method, namely Learning without Forgetting (LwF), is one of the best-performing algorithms. Then, we investigate its usage and parametrization in Morphing Attack Detection and Object Classification tasks, specifically with respect to the amount of new training data that became available.
</details>
<details>
<summary>摘要</summary>
具有限制数据传输和存储的场景下， compose a single dataset  ---  even exploiting different data sources ---  to perform a batch-based training procedure, 的模型开发 particullay challenging. 我们假设 Continual Learning (CL)  paradigm 可能是一个有效的解决方案，以便在多个站点进行逐步训练。 indeed, a basic assumption of CL 是一个已经训练过的模型不能再使用老数据进行后续训练迭代，并且可以删除。因此，在这篇论文中，我们研究了不同的 Continual Learning 方法在这种情况下的性能，通过模拟一个随着新数据块的到达而更新的学习模型。实验结果表明，一种特定的 CL 方法， namely Learning without Forgetting (LwF) 是最好的算法之一。然后，我们进一步调查了其在 Morphing Attack Detection 和 Object Classification 任务中的使用和 Parametrization，具体是根据可用的新训练数据量。
</details></li>
</ul>
<hr>
<h2 id="Speeding-up-Fourier-Neural-Operators-via-Mixed-Precision"><a href="#Speeding-up-Fourier-Neural-Operators-via-Mixed-Precision" class="headerlink" title="Speeding up Fourier Neural Operators via Mixed Precision"></a>Speeding up Fourier Neural Operators via Mixed Precision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15034">http://arxiv.org/abs/2307.15034</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuraloperator/neuraloperator">https://github.com/neuraloperator/neuraloperator</a></li>
<li>paper_authors: Colin White, Renbo Tu, Jean Kossaifi, Gennady Pekhimenko, Kamyar Azizzadenesheli, Anima Anandkumar</li>
<li>for:  solving partial differential equation (PDE) solutions using the Fourier neural operator (FNO)</li>
<li>methods: mixed-precision training of FNO, with a focus on reducing memory usage and training time</li>
<li>results: up to 34% reduction in training time and memory usage, with little or no reduction in accuracy, on the Navier-Stokes and Darcy flow equations.<details>
<summary>Abstract</summary>
The Fourier neural operator (FNO) is a powerful technique for learning surrogate maps for partial differential equation (PDE) solution operators. For many real-world applications, which often require high-resolution data points, training time and memory usage are significant bottlenecks. While there are mixed-precision training techniques for standard neural networks, those work for real-valued datatypes on finite dimensions and therefore cannot be directly applied to FNO, which crucially operates in the (complex-valued) Fourier domain and in function spaces. On the other hand, since the Fourier transform is already an approximation (due to discretization error), we do not need to perform the operation at full precision. In this work, we (i) profile memory and runtime for FNO with full and mixed-precision training, (ii) conduct a study on the numerical stability of mixed-precision training of FNO, and (iii) devise a training routine which substantially decreases training time and memory usage (up to 34%), with little or no reduction in accuracy, on the Navier-Stokes and Darcy flow equations. Combined with the recently proposed tensorized FNO (Kossaifi et al., 2023), the resulting model has far better performance while also being significantly faster than the original FNO.
</details>
<details>
<summary>摘要</summary>
“傅曼托运算（FNO）是一种强大的技术，用于学习偏微分方程（PDE）解析Operator的替代地图。实际应用中，需要大量的高分辨率数据点，训练时间和内存使用却成为了主要的瓶颈。虽然存在混合精度训练技术 для标准神经网络，但这些技术仅适用于实数型数据和finite dimension上，因此无法直接应用于FNO，因为FNO在复数valued Fourier领域和函数空间中运作。另一方面，由于Fourier变换已经是一种 aproximation（由于精度错误），我们不需要在全精度下进行运算。在这个工作中，我们（i）评估FNO的内存和时间成本，（ii）进行了FNO混合精度训练的 numerics 稳定性研究，以及（iii）开发了一个对FNO训练时间和内存使用进行了大幅删减（高达34%）的训练程式，几乎不会影响精度，在奈瓦-斯托克和达瑞流运动方程中。combined with recently proposed tensorized FNO（Kossaifi et al., 2023），得到的模型具有更好的性能，同时也比原始FNO更快。”
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Graph-Transformer-for-Deepfake-Detection"><a href="#Self-Supervised-Graph-Transformer-for-Deepfake-Detection" class="headerlink" title="Self-Supervised Graph Transformer for Deepfake Detection"></a>Self-Supervised Graph Transformer for Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15019">http://arxiv.org/abs/2307.15019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aminollah Khormali, Jiann-Shiun Yuan</li>
<li>for: 本研究旨在提出一种可靠的深伪检测系统，能够普适地检测不同类型的深伪视频。</li>
<li>methods: 该系统基于自我超vision transformer架构，采用自我超vised contrastive learning方法进行预训练，并将graph convolutional network和transformer discriminator相结合，以及图 transformer relevancy map提供更好的解释性。</li>
<li>results: 在多种实验中，该系统表现出色，在不同的 dataset、扰动类型和加工程度下均能够保持高度的检测性能，并且在常见的后期制作扰动下也能够保持robustness。<details>
<summary>Abstract</summary>
Deepfake detection methods have shown promising results in recognizing forgeries within a given dataset, where training and testing take place on the in-distribution dataset. However, their performance deteriorates significantly when presented with unseen samples. As a result, a reliable deepfake detection system must remain impartial to forgery types, appearance, and quality for guaranteed generalizable detection performance. Despite various attempts to enhance cross-dataset generalization, the problem remains challenging, particularly when testing against common post-processing perturbations, such as video compression or blur. Hence, this study introduces a deepfake detection framework, leveraging a self-supervised pre-training model that delivers exceptional generalization ability, withstanding common corruptions and enabling feature explainability. The framework comprises three key components: a feature extractor based on vision Transformer architecture that is pre-trained via self-supervised contrastive learning methodology, a graph convolution network coupled with a Transformer discriminator, and a graph Transformer relevancy map that provides a better understanding of manipulated regions and further explains the model's decision. To assess the effectiveness of the proposed framework, several challenging experiments are conducted, including in-data distribution performance, cross-dataset, cross-manipulation generalization, and robustness against common post-production perturbations. The results achieved demonstrate the remarkable effectiveness of the proposed deepfake detection framework, surpassing the current state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
深层负作假检测方法在给定数据集上已经表现出了良好的结果，可以准确地识别forge。然而，当面临未seen样本时，其性能会降低 significatively。因此，一个可靠的深层负作假检测系统必须保持中立，不被假造类型、外观和质量所左右。despite various attempts to enhance cross-dataset generalization, the problem remains challenging, especially when testing against common post-processing perturbations, such as video compression or blur. Therefore, this study proposes a deepfake detection framework, which leverages a self-supervised pre-training model that delivers excellent generalization ability, resisting common corruptions and providing feature explainability. The framework consists of three key components: a feature extractor based on the vision Transformer architecture that is pre-trained via self-supervised contrastive learning, a graph convolution network coupled with a Transformer discriminator, and a graph Transformer relevancy map that provides a better understanding of manipulated regions and further explains the model's decision. To evaluate the effectiveness of the proposed framework, several challenging experiments are conducted, including in-distribution performance, cross-dataset, cross-manipulation generalization, and robustness against common post-production perturbations. The results show that the proposed deepfake detection framework outperforms the current state-of-the-art approaches.
</details></li>
</ul>
<hr>
<h2 id="Samplable-Anonymous-Aggregation-for-Private-Federated-Data-Analysis"><a href="#Samplable-Anonymous-Aggregation-for-Private-Federated-Data-Analysis" class="headerlink" title="Samplable Anonymous Aggregation for Private Federated Data Analysis"></a>Samplable Anonymous Aggregation for Private Federated Data Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15017">http://arxiv.org/abs/2307.15017</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunal Talwar, Shan Wang, Audra McMillan, Vojta Jina, Vitaly Feldman, Bailey Basile, Aine Cahill, Yi Sheng Chan, Mike Chatzidakis, Junye Chen, Oliver Chick, Mona Chitnis, Suman Ganta, Yusuf Goren, Filip Granqvist, Kristine Guo, Frederic Jacobs, Omid Javidbakht, Albert Liu, Richard Low, Dan Mascenik, Steve Myers, David Park, Wonhee Park, Gianni Parsa, Tommy Pauly, Christian Priebe, Rehan Rishi, Guy Rothblum, Michael Scaria, Linmao Song, Congzheng Song, Karl Tarbe, Sebastian Vogt, Luke Winstrom, Shundong Zhou</li>
<li>for: 这个论文是为了设计扩展性强的协议，以实现隐私统计和隐私联合学习，每个设备都保持私有数据。</li>
<li>methods: 该论文提出了一种简单的原理，可以实现许多常用的算法，同时允许隐私评估，与中央设置相似，而不需要强大的信任假设。</li>
<li>results: 该论文提出了一种系统架构，实现了该原理，并进行了安全分析。<details>
<summary>Abstract</summary>
We revisit the problem of designing scalable protocols for private statistics and private federated learning when each device holds its private data. Our first contribution is to propose a simple primitive that allows for efficient implementation of several commonly used algorithms, and allows for privacy accounting that is close to that in the central setting without requiring the strong trust assumptions it entails. Second, we propose a system architecture that implements this primitive and perform a security analysis of the proposed system.
</details>
<details>
<summary>摘要</summary>
我们回归到每个设备保留自己私人数据时的私人统计和联邦学习协议设计的问题。我们的首要贡献是提出了一个简单的基本 primitives，它可以高效实现许多通常使用的算法，并且可以在中央设定下实现隐私账户，不需要强信任假设。其次，我们提出了一种系统架构，实现了这个基本 primitives，并进行了安全分析。
</details></li>
</ul>
<hr>
<h2 id="How-Good-is-Google-Bard’s-Visual-Understanding-An-Empirical-Study-on-Open-Challenges"><a href="#How-Good-is-Google-Bard’s-Visual-Understanding-An-Empirical-Study-on-Open-Challenges" class="headerlink" title="How Good is Google Bard’s Visual Understanding? An Empirical Study on Open Challenges"></a>How Good is Google Bard’s Visual Understanding? An Empirical Study on Open Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15016">http://arxiv.org/abs/2307.15016</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/htqin/googlebard-visunderstand">https://github.com/htqin/googlebard-visunderstand</a></li>
<li>paper_authors: Haotong Qin, Ge-Peng Ji, Salman Khan, Deng-Ping Fan, Fahad Shahbaz Khan, Luc Van Gool</li>
<li>for: The paper aims to evaluate the performance of Google’s Bard in understanding and interpreting visual data (images) conditioned by text questions, and to identify the gaps in Bard’s vision-based understanding.</li>
<li>methods: The paper uses 15 diverse task scenarios to comprehensively evaluate Bard’s performance in handling visual data, including regular, camouflaged, medical, under-water, and remote sensing data.</li>
<li>results: The primary finding of the study is that Bard still struggles in these vision scenarios, highlighting the significant gap in vision-based understanding that needs to be bridged in future developments.Here’s the Chinese version of the three key points:</li>
<li>for: 论文目的是评估Google的Bard在基于文本问题的视觉数据（图像）理解和解释方面的性能，并发现视觉基本理解中的差距。</li>
<li>methods: 论文使用15种多样化任务场景来全面评估Bard在处理视觉数据方面的性能，包括常见、掩蔽、医疗、水下和遥感数据等。</li>
<li>results: 研究的主要发现是，Bard在这些视觉场景中仍然困难，表明未来发展中需要覆盖视觉基本理解的差距。<details>
<summary>Abstract</summary>
Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in the field of conversational AI. Notably, Bard has recently been updated to handle visual inputs alongside text prompts during conversations. Given Bard's impressive track record in handling textual inputs, we explore its capabilities in understanding and interpreting visual data (images) conditioned by text questions. This exploration holds the potential to unveil new insights and challenges for Bard and other forthcoming multi-modal Generative models, especially in addressing complex computer vision problems that demand accurate visual and language understanding. Specifically, in this study, we focus on 15 diverse task scenarios encompassing regular, camouflaged, medical, under-water and remote sensing data to comprehensively evaluate Bard's performance. Our primary finding indicates that Bard still struggles in these vision scenarios, highlighting the significant gap in vision-based understanding that needs to be bridged in future developments. We expect that this empirical study will prove valuable in advancing future models, leading to enhanced capabilities in comprehending and interpreting fine-grained visual data. Our project is released on https://github.com/htqin/GoogleBard-VisUnderstand
</details>
<details>
<summary>摘要</summary>
Google的Bard在对话AI领域已经出现为OpenAI的ChatGPT的强力竞争对手。值得注意的是，Bard最近更新了对视觉输入进行对话的能力。基于Bard的出色的文本输入处理能力，我们探索了它对于图像数据（图像）的理解和解释的能力。这种探索具有探索新的发现和挑战的潜在性，尤其是在解决复杂的计算机视觉问题方面。在这种研究中，我们选择了15种多样化的任务场景，包括常见、掩体、医疗、水下和Remote感知数据，以全面评估Bard的表现。我们的主要发现表明Bard在这些视觉场景中仍然努力，强调了将来发展中需要覆盖的视觉理解悬峰。我们期望这个实验室的研究将对未来模型的发展产生帮助，导致对细化的视觉数据的理解和解释能力得到提高。我们的项目在https://github.com/htqin/GoogleBard-VisUnderstand上发布。
</details></li>
</ul>
<hr>
<h2 id="Harnessing-Synthetic-Active-Particles-for-Physical-Reservoir-Computing"><a href="#Harnessing-Synthetic-Active-Particles-for-Physical-Reservoir-Computing" class="headerlink" title="Harnessing Synthetic Active Particles for Physical Reservoir Computing"></a>Harnessing Synthetic Active Particles for Physical Reservoir Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15010">http://arxiv.org/abs/2307.15010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangzun Wang, Frank Cichos</li>
<li>for: 这篇论文探讨了基于活动微颗件系统的物理储存计算方法，以实现高效的信息处理。</li>
<li>methods: 该方法使用了具有延迟响应的微颗件系统自组织成非线性动力系统，并使用历史储存来降低噪声。</li>
<li>results: 研究人员发现，使用这种特殊架构可以实现高效的预测任务，即使在噪声强的情况下。这些结果为人工生物系统的信息处理研究开辟了新的可能性。<details>
<summary>Abstract</summary>
The processing of information is an indispensable property of living systems realized by networks of active processes with enormous complexity. They have inspired many variants of modern machine learning one of them being reservoir computing, in which stimulating a network of nodes with fading memory enables computations and complex predictions. Reservoirs are implemented on computer hardware, but also on unconventional physical substrates such as mechanical oscillators, spins, or bacteria often summarized as physical reservoir computing. Here we demonstrate physical reservoir computing with a synthetic active microparticle system that self-organizes from an active and passive component into inherently noisy nonlinear dynamical units. The self-organization and dynamical response of the unit is the result of a delayed propulsion of the microswimmer to a passive target. A reservoir of such units with a self-coupling via the delayed response can perform predictive tasks despite the strong noise resulting from Brownian motion of the microswimmers. To achieve efficient noise suppression, we introduce a special architecture that uses historical reservoir states for output. Our results pave the way for the study of information processing in synthetic self-organized active particle systems.
</details>
<details>
<summary>摘要</summary>
生物系统中信息处理是不可或缺的性能，通过活动过程网络实现了复杂性的计算。它们激发了现代机器学习的多种变种，其中之一是储存计算，通过启动网络节点的减弱记忆来实现计算和复杂预测。储存器在计算机硬件上实现，也可以在不同的物理基础结构上实现，如机械振荡器、螺旋体或细菌。在这里，我们使用自适应微体系来实现物理储存计算。这种系统由活动和无活动组件自组织而成，并且具有内生的噪声。我们通过延迟微型游子的推动到潜在目标来实现单元的自组织和动态响应。一个由这些单元组成的储存器，通过自相互关联来实现预测任务，即使面临强噪声。为了有效地减少噪声，我们提出了一种特殊的建筑方案，使用历史储存器状态来输出。我们的结果为人工自组织活体系统的信息处理研究开辟了新的道路。
</details></li>
</ul>
<hr>
<h2 id="Verifiable-Feature-Attributions-A-Bridge-between-Post-Hoc-Explainability-and-Inherent-Interpretability"><a href="#Verifiable-Feature-Attributions-A-Bridge-between-Post-Hoc-Explainability-and-Inherent-Interpretability" class="headerlink" title="Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability"></a>Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15007">http://arxiv.org/abs/2307.15007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Usha Bhalla, Suraj Srinivas, Himabindu Lakkaraju</li>
<li>for: 该论文的目的是解释机器学习模型的行为，并提供可靠的、可验证的特征归因方法。</li>
<li>methods: 该论文提出了一种名为Verifiability Tuning（VerT）的方法，可以将黑盒模型转化成具有自然的、可靠和可验证的特征归因方法。</li>
<li>results: 该论文通过对半 sintetic和实际数据集进行了广泛的实验，并证明了VerT可以生成的模型和特征归因方法是正确、可靠和 faithful于原始黑盒模型。<details>
<summary>Abstract</summary>
With the increased deployment of machine learning models in various real-world applications, researchers and practitioners alike have emphasized the need for explanations of model behaviour. To this end, two broad strategies have been outlined in prior literature to explain models. Post hoc explanation methods explain the behaviour of complex black-box models by highlighting features that are critical to model predictions; however, prior work has shown that these explanations may not be faithful, and even more concerning is our inability to verify them. Specifically, it is nontrivial to evaluate if a given attribution is correct with respect to the underlying model. Inherently interpretable models, on the other hand, circumvent these issues by explicitly encoding explanations into model architecture, meaning their explanations are naturally faithful and verifiable, but they often exhibit poor predictive performance due to their limited expressive power. In this work, we aim to bridge the gap between the aforementioned strategies by proposing Verifiability Tuning (VerT), a method that transforms black-box models into models that naturally yield faithful and verifiable feature attributions. We begin by introducing a formal theoretical framework to understand verifiability and show that attributions produced by standard models cannot be verified. We then leverage this framework to propose a method to build verifiable models and feature attributions out of fully trained black-box models. Finally, we perform extensive experiments on semi-synthetic and real-world datasets, and show that VerT produces models that (1) yield explanations that are correct and verifiable and (2) are faithful to the original black-box models they are meant to explain.
</details>
<details>
<summary>摘要</summary>
随着机器学习模型在各种实际应用中的普及，研究人员和实践者们都强调了模型行为的解释的重要性。为此，先前的文献中提出了两种广泛的解释策略：一是后期解释方法，通过强调模型预测中的关键特征来解释模型行为，但是先前的研究表明这些解释可能不准确，而且无法验证它们的正确性。另一方面，内置解释的模型可以自动编码解释到模型结构中，因此其解释是自然的、可靠的和验证的，但是它们通常具有较弱的预测性能。在这篇文章中，我们希望通过提出验证化调整（VerT）来bridge这两种策略之间的差距，以生成可靠的、可验证的特征归属。我们首先引入了一个正式的理论框架，以理解验证性的概念，并证明标准模型生成的归属无法验证。然后，我们利用这个框架，提出了一种方法，可以将黑盒模型转化为可靠、可验证的模型和特征归属。最后，我们对半synthetic和实际数据集进行了广泛的实验，并证明VerT可以生成符合预期的、可靠的和可验证的模型和特征归属。
</details></li>
</ul>
<hr>
<h2 id="Improved-Neural-Radiance-Fields-Using-Pseudo-depth-and-Fusion"><a href="#Improved-Neural-Radiance-Fields-Using-Pseudo-depth-and-Fusion" class="headerlink" title="Improved Neural Radiance Fields Using Pseudo-depth and Fusion"></a>Improved Neural Radiance Fields Using Pseudo-depth and Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03772">http://arxiv.org/abs/2308.03772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingliang Li, Qiang Zhou, Chaohui Yu, Zhengda Lu, Jun Xiao, Zhibin Wang, Fan Wang</li>
<li>for: 本研究主要探讨了如何使用多尺度编码体Volume和多尺度几何信息来提高NeRF模型的视野 sintesis和精密几何建模性能。</li>
<li>methods: 本研究提出了一种基于多尺度编码体Volume和多尺度几何信息的NeRF模型，并提出了一种同时进行深度预测和场景场景 reconstruction的方法，以及一种基于深度指导的点云特征融合方法来增强点云特征。</li>
<li>results: 实验结果显示，提出的方法可以在不需要Scene-specific优化的情况下实现高质量的视野 sintesis和精密几何建模，并且在点云特征融合方面提高了性能。<details>
<summary>Abstract</summary>
Since the advent of Neural Radiance Fields, novel view synthesis has received tremendous attention. The existing approach for the generalization of radiance field reconstruction primarily constructs an encoding volume from nearby source images as additional inputs. However, these approaches cannot efficiently encode the geometric information of real scenes with various scale objects/structures. In this work, we propose constructing multi-scale encoding volumes and providing multi-scale geometry information to NeRF models. To make the constructed volumes as close as possible to the surfaces of objects in the scene and the rendered depth more accurate, we propose to perform depth prediction and radiance field reconstruction simultaneously. The predicted depth map will be used to supervise the rendered depth, narrow the depth range, and guide points sampling. Finally, the geometric information contained in point volume features may be inaccurate due to occlusion, lighting, etc. To this end, we propose enhancing the point volume feature from depth-guided neighbor feature fusion. Experiments demonstrate the superior performance of our method in both novel view synthesis and dense geometry modeling without per-scene optimization.
</details>
<details>
<summary>摘要</summary>
自Neural Radiance Fields出现以来，新视图合成受到了广泛关注。现有的总结方法主要从邻近源图像中构建编码量为附加输入。然而，这些方法无法有效地编码实际场景中的各种尺度对象/结构的 геометрической信息。在这种工作中，我们提议构建多尺度编码量和将多尺度几何信息提供给NeRF模型。为使构造的体积最接近物体Scene中的表面和渲染深度更准确，我们提议同时进行深度预测和场景场景重建。预测的深度图将用于监督渲染深度，窄化深度范围，并导引点抽取。最后，由点体积特征中含有的几何信息可能因为遮挡、照明等因素而不准确。为此，我们提议通过深度导向邻居特征融合提高点体积特征。实验表明我们的方法在新视图合成和不需要Scene特定优化的精密几何模型中具有superior表现。
</details></li>
</ul>
<hr>
<h2 id="Detection-of-Children-Abuse-by-Voice-and-Audio-Classification-by-Short-Time-Fourier-Transform-Machine-Learning-implemented-on-Nvidia-Edge-GPU-device"><a href="#Detection-of-Children-Abuse-by-Voice-and-Audio-Classification-by-Short-Time-Fourier-Transform-Machine-Learning-implemented-on-Nvidia-Edge-GPU-device" class="headerlink" title="Detection of Children Abuse by Voice and Audio Classification by Short-Time Fourier Transform Machine Learning implemented on Nvidia Edge GPU device"></a>Detection of Children Abuse by Voice and Audio Classification by Short-Time Fourier Transform Machine Learning implemented on Nvidia Edge GPU device</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15101">http://arxiv.org/abs/2307.15101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuqi Yan, Yingxian Chen, W. W. T. Fok</li>
<li>for: 增强儿童安全性，预测儿童被虐待情况。</li>
<li>methods: 机器学习技术应用于儿童声音识别和检测儿童被虐待情况。</li>
<li>results: 实验结果显示，使用机器学习模型可以准确地识别儿童的声音，并且可以在儿童被虐待情况下发出警示。模型的准确率达到了约92%。<details>
<summary>Abstract</summary>
The safety of children in children home has become an increasing social concern, and the purpose of this experiment is to use machine learning applied to detect the scenarios of child abuse to increase the safety of children. This experiment uses machine learning to classify and recognize a child's voice and predict whether the current sound made by the child is crying, screaming or laughing. If a child is found to be crying or screaming, an alert is immediately sent to the relevant personnel so that they can perceive what the child may be experiencing in a surveillance blind spot and respond in a timely manner. Together with a hybrid use of video image classification, the accuracy of child abuse detection can be significantly increased. This greatly reduces the likelihood that a child will receive violent abuse in the nursery and allows personnel to stop an imminent or incipient child abuse incident in time. The datasets collected from this experiment is entirely from sounds recorded on site at the children home, including crying, laughing, screaming sound and background noises. These sound files are transformed into spectrograms using Short-Time Fourier Transform, and then these image data are imported into a CNN neural network for classification, and the final trained model can achieve an accuracy of about 92% for sound detection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对儿童HOME的儿童安全问题而言，这个实验的目的是使用机器学习技术来检测儿童虐待情况，以增加儿童的安全性。这个实验使用机器学习技术来分类和识别儿童的声音，并预测儿童当前发出的声音是否为哭泣、喊叫或 laughter。如果发现儿童在哭泣或喊叫，则立即发送 alert 到相关人员，以便他们在监控盲区内认定儿童的情况，并在时间上采取应急措施。与视频图像分类相结合使用，可以提高儿童虐待检测的准确率。这将大幅降低儿童在寄养所接受暴力虐待的可能性，并让人员在时间上采取应急措施，以防止儿童虐待事件的发生。实验所收集的数据完全来自寄养所录制的声音，包括哭泣、笑声、喊叫声和背景噪音。这些声音文件被转换成spectrograms使用Short-Time Fourier Transform，然后这些图像数据被导入到CNN神经网络中进行分类，最终训练出的模型可以达到约92%的准确率。
</details></li>
</ul>
<hr>
<h2 id="Thinker-Learning-to-Plan-and-Act"><a href="#Thinker-Learning-to-Plan-and-Act" class="headerlink" title="Thinker: Learning to Plan and Act"></a>Thinker: Learning to Plan and Act</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14993">http://arxiv.org/abs/2307.14993</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymous-scrl/thinker">https://github.com/anonymous-scrl/thinker</a></li>
<li>paper_authors: Stephen Chung, Ivan Anokhin, David Krueger</li>
<li>for: 本研究旨在开掘了一种名为 Thinker 算法，该算法可以让学习型决策机器人自主地与学习的世界模型交互，从而实现了自动化的规划。</li>
<li>methods:  Thinker 算法将环境包装在一个世界模型中，并引入了新的模型交互动作，允许机器人通过提议不同的计划来让世界模型进行规划，从而消除了手动设计的规划算法的需求。</li>
<li>results:  experimental 结果表明， Thinker 算法在杯球游戏和 Atari 2600 测试中实现了状态之最好的性能和竞争性能。视觉化显示了机器人培育了 Thinker 算法后，它们已经学习了如何有效地规划使用世界模型选择更好的动作。<details>
<summary>Abstract</summary>
We propose the Thinker algorithm, a novel approach that enables reinforcement learning agents to autonomously interact with and utilize a learned world model. The Thinker algorithm wraps the environment with a world model and introduces new actions designed for interacting with the world model. These model-interaction actions enable agents to perform planning by proposing alternative plans to the world model before selecting a final action to execute in the environment. This approach eliminates the need for hand-crafted planning algorithms by enabling the agent to learn how to plan autonomously and allows for easy interpretation of the agent's plan with visualization. We demonstrate the algorithm's effectiveness through experimental results in the game of Sokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves state-of-the-art performance and competitive results, respectively. Visualizations of agents trained with the Thinker algorithm demonstrate that they have learned to plan effectively with the world model to select better actions. The algorithm's generality opens a new research direction on how a world model can be used in reinforcement learning and how planning can be seamlessly integrated into an agent's decision-making process.
</details>
<details>
<summary>摘要</summary>
我们提出了思考算法，一种新的方法，让学习 Agent 能够自主地与学习的世界模型交互。思考算法将环境包装在世界模型中，并引入了特制的世界模型交互动作，让 Agent 可以通过提议多个计划来和世界模型交互，从而实现计划学习。这种方法消除了手动设计的计划算法的需求，让 Agent 可以自主地学习计划，并且可以轻松地通过可视化来解释 Agent 的计划。我们通过骁客游戏和 Atari 2600 测试集的实验result，证明思考算法在状态识别和竞争性能方面具有优秀表现。Visualization 显示 Agent 训练后已经学会了有效地使用世界模型来选择更好的动作。该算法的通用性开启了一个新的研究方向，即如何在学习 Agent 中使用世界模型，以及如何让计划学习与决策过程相协调。
</details></li>
</ul>
<hr>
<h2 id="Incrementally-Computable-Neural-Networks-Efficient-Inference-for-Dynamic-Inputs"><a href="#Incrementally-Computable-Neural-Networks-Efficient-Inference-for-Dynamic-Inputs" class="headerlink" title="Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs"></a>Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14988">http://arxiv.org/abs/2307.14988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Or Sharir, Anima Anandkumar</li>
<li>for: 这篇论文的目的是提出一种增量计算方法，以提高深度学习模型在处理动态输入时的效率。</li>
<li>methods: 这篇论文使用了 вектор量化来精简中继值，从而使得模型可以更好地重复计算。</li>
<li>results: 实验结果显示，使用增量计算方法可以与传统的批量计算方法相比，在运算序列中的字串编译时间比例降低了12.1倍（中位数）。<details>
<summary>Abstract</summary>
Deep learning often faces the challenge of efficiently processing dynamic inputs, such as sensor data or user inputs. For example, an AI writing assistant is required to update its suggestions in real time as a document is edited. Re-running the model each time is expensive, even with compression techniques like knowledge distillation, pruning, or quantization. Instead, we take an incremental computing approach, looking to reuse calculations as the inputs change. However, the dense connectivity of conventional architectures poses a major obstacle to incremental computation, as even minor input changes cascade through the network and restrict information reuse. To address this, we use vector quantization to discretize intermediate values in the network, which filters out noisy and unnecessary modifications to hidden neurons, facilitating the reuse of their values. We apply this approach to the transformers architecture, creating an efficient incremental inference algorithm with complexity proportional to the fraction of the modified inputs. Our experiments with adapting the OPT-125M pre-trained language model demonstrate comparable accuracy on document classification while requiring 12.1X (median) fewer operations for processing sequences of atomic edits.
</details>
<details>
<summary>摘要</summary>
然而，传统的网络架构中的紧密连接带来了重要的障碍，因为even minor input changes 会在网络中传播并限制信息重用。为解决这个问题，我们使用 вектор量化来精确化网络中的中间值，从而过滤出干扰和无关的修改。这使得可以重用隐藏神经元的值。我们应用这种方法到 transformers 架构中，创建了高效的逐步计算算法，计算复杂度与修改输入的 Fraction 成正比。我们的实验表明，在适应 OPT-125M 预训练语言模型时，可以保持文档类型的准确性，而同时需要12.1倍（中位） fewer 操作来处理序列化的 atomic 修改。
</details></li>
</ul>
<hr>
<h2 id="Take-A-Photo-3D-to-2D-Generative-Pre-training-of-Point-Cloud-Models"><a href="#Take-A-Photo-3D-to-2D-Generative-Pre-training-of-Point-Cloud-Models" class="headerlink" title="Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models"></a>Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14971">http://arxiv.org/abs/2307.14971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangzy22/tap">https://github.com/wangzy22/tap</a></li>
<li>paper_authors: Ziyi Wang, Xumin Yu, Yongming Rao, Jie Zhou, Jiwen Lu</li>
<li>for: 提高3D视觉模型的性能</li>
<li>methods: 使用cross-attention机制生成不同指定姿态的视图图像，以供3D模型进行预训练</li>
<li>results: 在ScanObjectNN类型和ShapeNetPart分割任务上达到了最佳性能，超过了之前的预训练方法<details>
<summary>Abstract</summary>
With the overwhelming trend of mask image modeling led by MAE, generative pre-training has shown a remarkable potential to boost the performance of fundamental models in 2D vision. However, in 3D vision, the over-reliance on Transformer-based backbones and the unordered nature of point clouds have restricted the further development of generative pre-training. In this paper, we propose a novel 3D-to-2D generative pre-training method that is adaptable to any point cloud model. We propose to generate view images from different instructed poses via the cross-attention mechanism as the pre-training scheme. Generating view images has more precise supervision than its point cloud counterpart, thus assisting 3D backbones to have a finer comprehension of the geometrical structure and stereoscopic relations of the point cloud. Experimental results have proved the superiority of our proposed 3D-to-2D generative pre-training over previous pre-training methods. Our method is also effective in boosting the performance of architecture-oriented approaches, achieving state-of-the-art performance when fine-tuning on ScanObjectNN classification and ShapeNetPart segmentation tasks. Code is available at https://github.com/wangzy22/TAP.
</details>
<details>
<summary>摘要</summary>
随着MAE领导的图像模型的潮流，生成预训练表现出了惊人的潜力，以提高2D视觉基本模型的性能。然而，在3D视觉中，由Transformer基础模型和无序点云的限制，生成预训练的发展受到了限制。在这篇论文中，我们提出了一种适用于任何点云模型的3D-to-2D生成预训练方法。我们提议通过cross-attention机制来生成不同的指定pose的视图图像作为预训练方案。通过生成视图图像，可以为3D背景提供更加精确的超visional指导，从而帮助3D背景更好地理解点云的几何结构和立体关系。实验结果表明，我们提出的3D-to-2D生成预训练方法比前期方法更高效。此外，我们的方法也可以提高建筑方法的性能，在ScanObjectNN分类和ShapeNetPart segmentation任务上达到了当前最佳性能。代码可以在https://github.com/wangzy22/TAP中找到。
</details></li>
</ul>
<hr>
<h2 id="Learning-locally-dominant-force-balances-in-active-particle-systems"><a href="#Learning-locally-dominant-force-balances-in-active-particle-systems" class="headerlink" title="Learning locally dominant force balances in active particle systems"></a>Learning locally dominant force balances in active particle systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14970">http://arxiv.org/abs/2307.14970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominik Sturm, Suryanarayana Maddu, Ivo F. Sbalzarini</li>
<li>for: 这个论文的目的是解释自适应活动粒子系统中的宏观模式形成。</li>
<li>methods: 该论文使用了一种组合式无监督聚类和稀疏推理算法来学习自适应粒子系统中的地方主导力平衡。</li>
<li>results: 研究发现，自适应粒子系统中的宏观模式形成是基于地方的对称相互作用和激射压力的。该方法还能够揭示自适应粒子系统中模式形成的物理原理和实验观察结果之间的相互关系。<details>
<summary>Abstract</summary>
We use a combination of unsupervised clustering and sparsity-promoting inference algorithms to learn locally dominant force balances that explain macroscopic pattern formation in self-organized active particle systems. The self-organized emergence of macroscopic patterns from microscopic interactions between self-propelled particles can be widely observed nature. Although hydrodynamic theories help us better understand the physical basis of this phenomenon, identifying a sufficient set of local interactions that shape, regulate, and sustain self-organized structures in active particle systems remains challenging. We investigate a classic hydrodynamic model of self-propelled particles that produces a wide variety of patterns, like asters and moving density bands. Our data-driven analysis shows that propagating bands are formed by local alignment interactions driven by density gradients, while steady-state asters are shaped by a mechanism of splay-induced negative compressibility arising from strong particle interactions. Our method also reveals analogous physical principles of pattern formation in a system where the speed of the particle is influenced by local density. This demonstrates the ability of our method to reveal physical commonalities across models. The physical mechanisms inferred from the data are in excellent agreement with analytical scaling arguments and experimental observations.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文版本，具体的翻译结果可能有所不同）我们使用无监督划分和缺省推理算法来学习活体系中的地方主导力平衡，以解释大规模模式的形成。自然中广泛观察到活体系中自组织的大规模模式。尽管流体理论可以帮助我们更好地理解这种现象的物理基础，但是确定活体系中自组织结构的地方互动的充分集合仍然是一个挑战。我们研究了一种经典的流体力学模型，该模型可以生成各种模式，如星形和移动密度带。我们的数据驱动分析表明，带状模式是由地方对适应度势场的Alignment互动驱动的，而稳定的星形则是由强 particle interactions 导致的负压缩性质的。我们的方法还表明了在模型中速度受到地方密度影响的情况下，物理原理的形成是一致的。这说明我们的方法可以揭示模型之间的物理相似性。实际观察和理论分析中的物理机制与我们的数据分析结果吻合得非常好。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/28/cs.LG_2023_07_28/" data-id="clogyj8yp00lo7cra7th750xx" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_07_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/28/eess.IV_2023_07_28/" class="article-date">
  <time datetime="2023-07-28T09:00:00.000Z" itemprop="datePublished">2023-07-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/28/eess.IV_2023_07_28/">eess.IV - 2023-07-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Survey-on-Deep-Learning-in-Medical-Image-Registration-New-Technologies-Uncertainty-Evaluation-Metrics-and-Beyond"><a href="#A-Survey-on-Deep-Learning-in-Medical-Image-Registration-New-Technologies-Uncertainty-Evaluation-Metrics-and-Beyond" class="headerlink" title="A Survey on Deep Learning in Medical Image Registration: New Technologies, Uncertainty, Evaluation Metrics, and Beyond"></a>A Survey on Deep Learning in Medical Image Registration: New Technologies, Uncertainty, Evaluation Metrics, and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15615">http://arxiv.org/abs/2307.15615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyu Chen, Yihao Liu, Shuwen Wei, Zhangxing Bian, Shalini Subramanian, Aaron Carass, Jerry L. Prince, Yong Du</li>
<li>for: 本研究提供了最新的深度学习基于图像注册的概述，包括最新的网络架构、特定于注册的损失函数和注册不确定性的估计方法。</li>
<li>methods: 本研究提出了多种新的网络架构、特定于注册的损失函数和注册不确定性的估计方法，以及适用于评估深度学习模型在注册任务中的评价指标。</li>
<li>results: 本研究总结了深度学习基于图像注册的最新进展，包括多种新的网络架构、特定于注册的损失函数和注册不确定性的估计方法，以及这些技术在医疗影像应用中的实际应用和未来展望。<details>
<summary>Abstract</summary>
Over the past decade, deep learning technologies have greatly advanced the field of medical image registration. The initial developments, such as ResNet-based and U-Net-based networks, laid the groundwork for deep learning-driven image registration. Subsequent progress has been made in various aspects of deep learning-based registration, including similarity measures, deformation regularizations, and uncertainty estimation. These advancements have not only enriched the field of deformable image registration but have also facilitated its application in a wide range of tasks, including atlas construction, multi-atlas segmentation, motion estimation, and 2D-3D registration. In this paper, we present a comprehensive overview of the most recent advancements in deep learning-based image registration. We begin with a concise introduction to the core concepts of deep learning-based image registration. Then, we delve into innovative network architectures, loss functions specific to registration, and methods for estimating registration uncertainty. Additionally, this paper explores appropriate evaluation metrics for assessing the performance of deep learning models in registration tasks. Finally, we highlight the practical applications of these novel techniques in medical imaging and discuss the future prospects of deep learning-based image registration.
</details>
<details>
<summary>摘要</summary>
过去一个十年，深度学习技术在医学图像对接方面做出了很大的进步。初期的发展，如基于ResNet和U-Net的网络，为深度学习驱动的图像对接提供了基础。后续的进步包括相似度度量、准确度评估、和变形规则等方面，这些进步不仅推动了可变图像对接的发展，还使其在各种任务中得到了广泛的应用，如制作图像 Atlases、多个 Atlases 分割、运动估计和2D-3D对接。在这篇论文中，我们提供了深度学习基于图像对接最新的进步的全面概述。我们从核心概念开始，然后探讨了专门为对接设计的网络架构、特定于对接的损失函数和对接不确定性的估计方法。此外，这篇论文还考虑了对接任务的评估指标，并将其应用于医学图像中。最后，我们讨论了这些新技术在医学图像中的实际应用和未来前景。
</details></li>
</ul>
<hr>
<h2 id="Integrated-Digital-Reconstruction-of-Welded-Components-Supporting-Improved-Fatigue-Life-Prediction"><a href="#Integrated-Digital-Reconstruction-of-Welded-Components-Supporting-Improved-Fatigue-Life-Prediction" class="headerlink" title="Integrated Digital Reconstruction of Welded Components: Supporting Improved Fatigue Life Prediction"></a>Integrated Digital Reconstruction of Welded Components: Supporting Improved Fatigue Life Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15604">http://arxiv.org/abs/2307.15604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anders Faarbæk Mikkelstrup, Morten Kristiansen</li>
<li>For: The paper aims to improve the fatigue performance of welded joints in offshore jacket foundations by enhancing the quality of post-weld treatment through digital reconstruction of the weld.* Methods: The paper proposes an industrial manipulator combined with a line scanner to integrate digital reconstruction as part of the automated HFMI treatment setup, using standard image processing, simple filtering techniques, and non-linear optimization to align and merge overlapping scans.* Results: The proposed framework enables generic digital reconstruction of welded parts, aiding in component design, overall quality assurance, and documentation of the HFMI treatment, and improves fatigue life prediction and possible crack location prediction.<details>
<summary>Abstract</summary>
In the design of offshore jacket foundations, fatigue life is crucial. Post-weld treatment has been proposed to enhance the fatigue performance of welded joints, where particularly high-frequency mechanical impact (HFMI) treatment has been shown to improve fatigue performance significantly. Automated HFMI treatment has improved quality assurance and can lead to cost-effective design when combined with accurate fatigue life prediction. However, the finite element method (FEM), commonly used for predicting fatigue life in complex or multi-axial joints, relies on a basic CAD depiction of the weld, failing to consider the actual weld geometry and defects. Including the actual weld geometry in the FE model improves fatigue life prediction and possible crack location prediction but requires a digital reconstruction of the weld. Current digital reconstruction methods are time-consuming or require specialised scanning equipment and potential component relocation. The proposed framework instead uses an industrial manipulator combined with a line scanner to integrate digital reconstruction as part of the automated HFMI treatment setup. This approach applies standard image processing, simple filtering techniques, and non-linear optimisation for aligning and merging overlapping scans. A screened Poisson surface reconstruction finalises the 3D model to create a meshed surface. The outcome is a generic, cost-effective, flexible, and rapid method that enables generic digital reconstruction of welded parts, aiding in component design, overall quality assurance, and documentation of the HFMI treatment.
</details>
<details>
<summary>摘要</summary>
design of offshore jacket foundations, fatigue life is crucial. Post-weld treatment has been proposed to enhance the fatigue performance of welded joints, where particularly high-frequency mechanical impact (HFMI) treatment has been shown to improve fatigue performance significantly. Automated HFMI treatment has improved quality assurance and can lead to cost-effective design when combined with accurate fatigue life prediction. However, the finite element method (FEM), commonly used for predicting fatigue life in complex or multi-axial joints, relies on a basic CAD depiction of the weld, failing to consider the actual weld geometry and defects. Including the actual weld geometry in the FE model improves fatigue life prediction and possible crack location prediction but requires a digital reconstruction of the weld. Current digital reconstruction methods are time-consuming or require specialized scanning equipment and potential component relocation. The proposed framework instead uses an industrial manipulator combined with a line scanner to integrate digital reconstruction as part of the automated HFMI treatment setup. This approach applies standard image processing, simple filtering techniques, and non-linear optimization for aligning and merging overlapping scans. A screened Poisson surface reconstruction finalizes the 3D model to create a meshed surface. The outcome is a generic, cost-effective, flexible, and rapid method that enables generic digital reconstruction of welded parts, aiding in component design, overall quality assurance, and documentation of the HFMI treatment.Here's the text in Traditional Chinese:在海上桅杆基础设计中，腐蚀生命是关键。post-weld treatment 已经被提议来提高锋械焊接处的腐蚀性能，其中特别是高频机械冲击(HFMI)处理能够明显改善腐蚀性能。自动化HFMI处理可以提高质量保证和设计成本，并且可以与精确的腐蚀生命预测相结合。然而，通用finite element方法（FEM），常用于预测复杂或多轴焊接处的腐蚀生命，仅仅基于焊接部的基本CAD描述，而不考虑实际焊接件的几何和缺陷。包括实际焊接件的几何在FEM模型中可以提高腐蚀生命预测和可能的裂缝位置预测，但需要焊接件的数字重建。现有的数字重建方法是时间consuming 或需要特殊扫描设备和可能的组件重新位置。提议的框架INSTEAD uses an industrial manipulator combined with a line scanner to integrate digital reconstruction as part of the automated HFMI treatment setup. This approach applies standard image processing, simple filtering techniques, and non-linear optimization for aligning and merging overlapping scans. A screened Poisson surface reconstruction finalizes the 3D model to create a meshed surface. The outcome is a generic, cost-effective, flexible, and rapid method that enables generic digital reconstruction of welded parts, aiding in component design, overall quality assurance, and documentation of the HFMI treatment.
</details></li>
</ul>
<hr>
<h2 id="OAFuser-Towards-Omni-Aperture-Fusion-for-Light-Field-Semantic-Segmentation-of-Road-Scenes"><a href="#OAFuser-Towards-Omni-Aperture-Fusion-for-Light-Field-Semantic-Segmentation-of-Road-Scenes" class="headerlink" title="OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic Segmentation of Road Scenes"></a>OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic Segmentation of Road Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15588">http://arxiv.org/abs/2307.15588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/feibryantkit/oafuser">https://github.com/feibryantkit/oafuser</a></li>
<li>paper_authors: Fei Teng, Jiaming Zhang, Kunyu Peng, Kailun Yang, Yaonan Wang, Rainer Stiefelhagen</li>
<li>for: 增强自动驾驶场景理解的图像Semantic segmentation，使用光场相机提供丰富的空间和方向信息。</li>
<li>methods: 提议Omni-Aperture Fusion模型（OAFuser），利用中心视图的密集上下文和子镜头图像中的方向信息生成具有一致性的结果，同时采用Sub-Aperture Fusion Module（SAFM）将子镜头图像与方向特征相嵌入，无需额外存储成本。</li>
<li>results: 在UrbanLF-Real和-Syn数据集上达到了状态之内表现，与之前的记录 (+4.53%) 相比，并在UrbanLF-Real Extended数据集上达到了84.93%的mIoU记录。<details>
<summary>Abstract</summary>
Light field cameras can provide rich angular and spatial information to enhance image semantic segmentation for scene understanding in the field of autonomous driving. However, the extensive angular information of light field cameras contains a large amount of redundant data, which is overwhelming for the limited hardware resource of intelligent vehicles. Besides, inappropriate compression leads to information corruption and data loss. To excavate representative information, we propose an Omni-Aperture Fusion model (OAFuser), which leverages dense context from the central view and discovers the angular information from sub-aperture images to generate a semantically-consistent result. To avoid feature loss during network propagation and simultaneously streamline the redundant information from the light field camera, we present a simple yet very effective Sub-Aperture Fusion Module (SAFM) to embed sub-aperture images into angular features without any additional memory cost. Furthermore, to address the mismatched spatial information across viewpoints, we present Center Angular Rectification Module (CARM) realized feature resorting and prevent feature occlusion caused by asymmetric information. Our proposed OAFuser achieves state-of-the-art performance on the UrbanLF-Real and -Syn datasets and sets a new record of 84.93% in mIoU on the UrbanLF-Real Extended dataset, with a gain of +4.53%. The source code of OAFuser will be made publicly available at https://github.com/FeiBryantkit/OAFuser.
</details>
<details>
<summary>摘要</summary>
《Light field cameras可以提供rich的angular和空间信息，以提高自动驾驶场景理解。然而，广泛的angular信息中包含大量冗余数据，这会超过智能汽车的硬件资源。另外，不当压缩会导致信息损坏和数据丢失。为了挖掘代表性信息，我们提出了Omni-Aperture Fusion模型（OAFuser），它利用中心视图的dense context和子视图图像中的angular信息，生成具有相同semantic consistency的结果。为了避免网络传播过程中的特征损失并同时压缩 redundancy from the light field camera，我们提出了一个简单 yet highly effective Sub-Aperture Fusion Module（SAFM），可以将子视图图像嵌入angular特征中，无需额外内存成本。此外，为了 Addressing the mismatched spatial information across viewpoints，我们提出了Center Angular Rectification Module（CARM），实现了Feature Resorting和避免了因视角不同而导致的特征遮挡。我们的提出的OAFuser实现了UrbanLF-Real和UrbanLF-Syn数据集上的state-of-the-art performance，并在UrbanLF-Real Extended数据集上达到了84.93%的mIoU记录，升幅+4.53%。我们将在https://github.com/FeiBryantkit/OAFuser上公开源代码。》
</details></li>
</ul>
<hr>
<h2 id="Defocus-Blur-Synthesis-and-Deblurring-via-Interpolation-and-Extrapolation-in-Latent-Space"><a href="#Defocus-Blur-Synthesis-and-Deblurring-via-Interpolation-and-Extrapolation-in-Latent-Space" class="headerlink" title="Defocus Blur Synthesis and Deblurring via Interpolation and Extrapolation in Latent Space"></a>Defocus Blur Synthesis and Deblurring via Interpolation and Extrapolation in Latent Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15461">http://arxiv.org/abs/2307.15461</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nis-research/linear-latent-blur">https://github.com/nis-research/linear-latent-blur</a></li>
<li>paper_authors: Ioana Mazilu, Shunxin Wang, Sven Dummer, Raymond Veldhuis, Christoph Brune, Nicola Strisciuglio</li>
<li>For: 提高微scopic图像质量，使其更适合进一步处理和分析疾病。* Methods: 使用自适应抑制神经网络和明确 regularization 技术，从拉тен空间中 linearly interpolate&#x2F;extrapolate 图像各个Focus plane的表示。* Results: 能够有效地产生不同degree of blur的图像，提高数据多样性，并且可以用作数据增强技术，提高微scopic图像的质量和分析效果。<details>
<summary>Abstract</summary>
Though modern microscopes have an autofocusing system to ensure optimal focus, out-of-focus images can still occur when cells within the medium are not all in the same focal plane, affecting the image quality for medical diagnosis and analysis of diseases. We propose a method that can deblur images as well as synthesize defocus blur. We train autoencoders with implicit and explicit regularization techniques to enforce linearity relations among the representations of different blur levels in the latent space. This allows for the exploration of different blur levels of an object by linearly interpolating/extrapolating the latent representations of images taken at different focal planes. Compared to existing works, we use a simple architecture to synthesize images with flexible blur levels, leveraging the linear latent space. Our regularized autoencoders can effectively mimic blur and deblur, increasing data variety as a data augmentation technique and improving the quality of microscopic images, which would be beneficial for further processing and analysis.
</details>
<details>
<summary>摘要</summary>
modern microscopes 有自动对焦系统以确保最佳Focus，但可以出现不对焦图像，因为细胞在媒体中不都在同一个focus plane，这会影响医疗诊断和疾病分析的图像质量。我们提出了一种方法，可以除锈图像以及生成杂化模糊。我们在自适应神经网络中使用了隐式和显式正则化技术，以强制在潜在空间中的表示之间存在线性关系。这allow us to explore不同的杂化水平，通过线性 interpolate/extrapolate latent representation of images taken at different focal planes。相比之下，我们使用了简单的architecture来生成具有 flexible 杂化水平的图像，利用潜在空间的线性特性。我们的正则化自适应神经网络可以有效地模拟杂化和除锈，增加数据多样性作为数据扩充技术，提高微scopic 图像的质量，这将有利于进一步处理和分析。
</details></li>
</ul>
<hr>
<h2 id="ERCPMP-An-Endoscopic-Image-and-Video-Dataset-for-Colorectal-Polyps-Morphology-and-Pathology"><a href="#ERCPMP-An-Endoscopic-Image-and-Video-Dataset-for-Colorectal-Polyps-Morphology-and-Pathology" class="headerlink" title="ERCPMP: An Endoscopic Image and Video Dataset for Colorectal Polyps Morphology and Pathology"></a>ERCPMP: An Endoscopic Image and Video Dataset for Colorectal Polyps Morphology and Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15444">http://arxiv.org/abs/2307.15444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mojgan Forootan, Mohsen Rajabnia, Ahmad R Mafi, Hamed Azhdari Tehrani, Erfan Ghadirzadeh, Mahziar Setayeshfar, Zahra Ghaffari, Mohammad Tashakoripour, Mohammad Reza Zali, Hamidreza Bolhasani</li>
<li>for: 这个论文是为了开发准确的医疗算法而写的。</li>
<li>methods: 这篇论文使用了endoscopic图像和视频数据集（ERCPMP），包括了patient的人口统计数据、形态数据、pathological数据和endoscopic图像和视频。</li>
<li>results: 这篇论文通过分析endoscopic图像和视频数据集，开发了一个准确的医疗算法，可以用于识别抑血管肿瘤的形态和病理特征。<details>
<summary>Abstract</summary>
In the recent years, artificial intelligence (AI) and its leading subtypes, machine learning (ML) and deep learning (DL) and their applications are spreading very fast in various aspects such as medicine. Today the most important challenge of developing accurate algorithms for medical prediction, detection, diagnosis, treatment and prognosis is data. ERCPMP is an Endoscopic Image and Video Dataset for Recognition of Colorectal Polyps Morphology and Pathology. This dataset contains demographic, morphological and pathological data, endoscopic images and videos of 191 patients with colorectal polyps. Morphological data is included based on the latest international gastroenterology classification references such as Paris, Pit and JNET classification. Pathological data includes the diagnosis of the polyps including Tubular, Villous, Tubulovillous, Hyperplastic, Serrated, Inflammatory and Adenocarcinoma with Dysplasia Grade & Differentiation. The current version of this dataset is published and available on Elsevier Mendeley Dataverse and since it is under development, the latest version is accessible via: https://databiox.com.
</details>
<details>
<summary>摘要</summary>
近年来，人工智能（AI）和其主要分支——机器学习（ML）和深度学习（DL）在各种领域广泛应用。医学领域的主要挑战是开发高精度算法，用于医疗预测、检测、诊断、治疗和评估。ERCPMP是一个涵盖肠道肿瘤形态和病理学特征的杜立特内镜影像和视频数据集。这个数据集包括191名患者的肠道肿瘤数据，包括人类学分类标准（Paris、Pit和JNET）中的最新分类参考。病理数据包括肿瘤诊断，包括毛细血管、 villous、 tubulovillous、 炎性、serrated、inflammatory和adenocarcinoma，以及分化度和分化度。现有版本的这个数据集已经发布，可以在 Elsevier Mendeley Dataverse 上获取，而最新版本可以通过以下链接获取：https://databiox.com。
</details></li>
</ul>
<hr>
<h2 id="RAWIW-RAW-Image-Watermarking-Robust-to-ISP-Pipeline"><a href="#RAWIW-RAW-Image-Watermarking-Robust-to-ISP-Pipeline" class="headerlink" title="RAWIW: RAW Image Watermarking Robust to ISP Pipeline"></a>RAWIW: RAW Image Watermarking Robust to ISP Pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15443">http://arxiv.org/abs/2307.15443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kang Fu, Xiaohong Liu, Jun Jia, Zicheng Zhang, Yicong Peng, Jia Wang, Guangtao Zhai<br>for:这个研究是为了提供一个基于深度学习的RAW图像潜像 watermarking框架，以保护RAW图像的版权。methods:我们使用了一个内置的神经网络来实现RAW图像与RGB图像之间的跨领域版权保护，并且将copyright信息直接嵌入RAW图像中。results:我们的实验结果显示，RAWIW框架可以成功地在不同的ISP管道和传输过程中维持版权保护，并且可以实现高质量和适当的隐藏性。<details>
<summary>Abstract</summary>
Invisible image watermarking is essential for image copyright protection. Compared to RGB images, RAW format images use a higher dynamic range to capture the radiometric characteristics of the camera sensor, providing greater flexibility in post-processing and retouching. Similar to the master recording in the music industry, RAW images are considered the original format for distribution and image production, thus requiring copyright protection. Existing watermarking methods typically target RGB images, leaving a gap for RAW images. To address this issue, we propose the first deep learning-based RAW Image Watermarking (RAWIW) framework for copyright protection. Unlike RGB image watermarking, our method achieves cross-domain copyright protection. We directly embed copyright information into RAW images, which can be later extracted from the corresponding RGB images generated by different post-processing methods. To achieve end-to-end training of the framework, we integrate a neural network that simulates the ISP pipeline to handle the RAW-to-RGB conversion process. To further validate the generalization of our framework to traditional ISP pipelines and its robustness to transmission distortion, we adopt a distortion network. This network simulates various types of noises introduced during the traditional ISP pipeline and transmission. Furthermore, we employ a three-stage training strategy to strike a balance between robustness and concealment of watermarking. Our extensive experiments demonstrate that RAWIW successfully achieves cross-domain copyright protection for RAW images while maintaining their visual quality and robustness to ISP pipeline distortions.
</details>
<details>
<summary>摘要</summary>
这文字说明RAW图像标识（RAWIW）框架，用于图像版权保护。相比于RGB图像，RAW格式图像使用更高的动态范围来捕捉相机感应器的射频特性，提供更多的后处理和修复 flexibility。RAW图像被视为图像生产和分布的原始格式，因此需要版权保护。现有的标识方法通常target RGB图像，这借gabe a gap for RAW图像。为了解决这个问题，我们提出了首个基于深度学习的RAW图像标识（RAWIW）框架。不同于RGB图像标识，我们的方法可以在不同的处理和修复方法下进行标识，并且可以从RGB图像中提取标识信息。为了实现端到端训练的框架，我们将一个神经网络 integrate into the ISP pipeline to handle the RAW-to-RGB conversion process。此外，我们还使用一个抖扰网络，以模拟传输过程中引入的各种噪声。 Finally, we employ a three-stage training strategy to balance the robustness and concealment of watermarking. Our extensive experiments show that RAWIW successfully achieves cross-domain copyright protection for RAW images while maintaining their visual quality and robustness to ISP pipeline distortions.
</details></li>
</ul>
<hr>
<h2 id="MLIC-Linear-Complexity-Multi-Reference-Entropy-Modeling-for-Learned-Image-Compression"><a href="#MLIC-Linear-Complexity-Multi-Reference-Entropy-Modeling-for-Learned-Image-Compression" class="headerlink" title="MLIC++: Linear Complexity Multi-Reference Entropy Modeling for Learned Image Compression"></a>MLIC++: Linear Complexity Multi-Reference Entropy Modeling for Learned Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15421">http://arxiv.org/abs/2307.15421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiangweibeta/mlic">https://github.com/jiangweibeta/mlic</a></li>
<li>paper_authors: Wei Jiang, Ronggang Wang</li>
<li>for: 这个论文主要是为了提出一种基于多reference entropy模型的学习图像压缩方法，以提高图像压缩的效率和质量。</li>
<li>methods: 该方法使用了linear complexity global correlations capturing，通过分解softmax操作来实现，并提出了一种基于多reference entropy模型的学习图像压缩方法MLIC$^{++}$。</li>
<li>results: 对于Kodak数据集，相比VTM-17.0，MLIC$^{++}$可以减少BD-rate by 12.44%，并且在PSNR上具有更高的效率。<details>
<summary>Abstract</summary>
Recently, multi-reference entropy model has been proposed, which captures channel-wise, local spatial, and global spatial correlations. Previous works adopt attention for global correlation capturing, however, the quadratic cpmplexity limits the potential of high-resolution image coding. In this paper, we propose the linear complexity global correlations capturing, via the decomposition of softmax operation. Based on it, we propose the MLIC$^{++}$, a learned image compression with linear complexity for multi-reference entropy modeling. Our MLIC$^{++}$ is more efficient and it reduces BD-rate by 12.44% on the Kodak dataset compared to VTM-17.0 when measured in PSNR. Code will be available at https://github.com/JiangWeibeta/MLIC.
</details>
<details>
<summary>摘要</summary>
最近，多参照 entropy 模型已经被提出，该模型捕捉了通道级、本地空间和全局空间相关性。前一些作品采用了注意力来捕捉全局相关性，但是这种 quadratic complexity 限制了高分辨率图像编码的潜力。在本文中，我们提出了线性复杂度全球相关性捕捉方法，通过软max操作的归一化 decomposition。基于这种方法，我们提出了 MLIC++，一种学习图像压缩的线性复杂度模型。我们的 MLIC++ 比 VTM-17.0 在 Kodak 数据集上减少了BD-rate 12.44%，相对于 PSNR 来说。代码将在 GitHub 上提供。
</details></li>
</ul>
<hr>
<h2 id="Fast-Dust-Sand-Image-Enhancement-Based-on-Color-Correction-and-New-Membership-Function"><a href="#Fast-Dust-Sand-Image-Enhancement-Based-on-Color-Correction-and-New-Membership-Function" class="headerlink" title="Fast Dust Sand Image Enhancement Based on Color Correction and New Membership Function"></a>Fast Dust Sand Image Enhancement Based on Color Correction and New Membership Function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15230">http://arxiv.org/abs/2307.15230</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Hakem Alsaeedi, Suha Mohammed Hadi, Yarub Alazzawi</li>
<li>for: 提高灰尘照片的质量和可见度</li>
<li>methods: 基于色彩修正和新成员函数，提出了一种新的增强灰尘照片的模型，包括三个阶段：色彩shift的 corrections、雾气去除和对比和亮度的提高</li>
<li>results: 对多个真实的灰尘照片进行测试和评估，研究表明，提出的解决方案在去除红色和黄色投影方面表现出色，并提供了高质量和量的灰尘照片<details>
<summary>Abstract</summary>
Images captured in dusty environments suffering from poor visibility and quality. Enhancement of these images such as sand dust images plays a critical role in various atmospheric optics applications. In this work, proposed a new model based on Color Correction and new membership function to enhance san dust images. The proposed model consists of three phases: correction of color shift, removal of haze, and enhancement of contrast and brightness. The color shift is corrected using a new membership function to adjust the values of U and V in the YUV color space. The Adaptive Dark Channel Prior (A-DCP) is used for haze removal. The stretching contrast and improving image brightness are based on Contrast Limited Adaptive Histogram Equalization (CLAHE). The proposed model tests and evaluates through many real sand dust images. The experimental results show that the proposed solution is outperformed the current studies in terms of effectively removing the red and yellow cast and provides high quality and quantity dust images.
</details>
<details>
<summary>摘要</summary>
图像 capture in 尘埃环境中，因visibility和质量受到干扰。这些图像的提高，如沙尘图像，在大气仪器应用中扮演着关键角色。在这个工作中，我们提出了一种基于色彩修正和新成员函数的新模型，用于提高沙尘图像的质量。该模型包括三个阶段：色彩偏移的修正、雾气除尘和对比度和亮度的提高。色彩偏移的修正使用了一种新的成员函数来调整YUV色彩空间中U和V的值。使用适应黑通道优先（A-DCP）进行雾气除尘。对比度和亮度的提高基于对比限定适应 histogram 平衡（CLAHE）。我们对多个实际的沙尘图像进行测试和评估。实验结果表明，我们的解决方案在 removes 红色和黄色抹雾效果上比现有研究更高效，并提供了高质量和数量的尘埃图像。
</details></li>
</ul>
<hr>
<h2 id="Generative-AI-for-Medical-Imaging-extending-the-MONAI-Framework"><a href="#Generative-AI-for-Medical-Imaging-extending-the-MONAI-Framework" class="headerlink" title="Generative AI for Medical Imaging: extending the MONAI Framework"></a>Generative AI for Medical Imaging: extending the MONAI Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15208">http://arxiv.org/abs/2307.15208</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/project-monai/generativemodels">https://github.com/project-monai/generativemodels</a></li>
<li>paper_authors: Walter H. L. Pinaya, Mark S. Graham, Eric Kerfoot, Petru-Daniel Tudosiu, Jessica Dafflon, Virginia Fernandez, Pedro Sanchez, Julia Wolleb, Pedro F. da Costa, Ashay Patel, Hyungjin Chung, Can Zhao, Wei Peng, Zelong Liu, Xueyan Mei, Oeslle Lucena, Jong Chul Ye, Sotirios A. Tsaftaris, Prerna Dogra, Andrew Feng, Marc Modat, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardoso</li>
<li>for:  This paper is written for researchers and developers who want to easily train, evaluate, and deploy generative models and related applications in medical imaging.</li>
<li>methods:  The paper uses a variety of generative models, including diffusion models, autoregressive transformers, and GANs, and implements them in a generalizable fashion for 2D and 3D medical images with different modalities and anatomical areas.</li>
<li>results:  The paper provides pre-trained models for the community and demonstrates the reproducibility of state-of-the-art studies using a standardized approach, as well as the extension of current applications to future features through a modular and extensible approach.<details>
<summary>Abstract</summary>
Recent advances in generative AI have brought incredible breakthroughs in several areas, including medical imaging. These generative models have tremendous potential not only to help safely share medical data via synthetic datasets but also to perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due to the complexity of these models, their implementation and reproducibility can be difficult. This complexity can hinder progress, act as a use barrier, and dissuade the comparison of new methods with existing works. In this study, we present MONAI Generative Models, a freely available open-source platform that allows researchers and developers to easily train, evaluate, and deploy generative models and related applications. Our platform reproduces state-of-art studies in a standardised way involving different architectures (such as diffusion models, autoregressive transformers, and GANs), and provides pre-trained models for the community. We have implemented these models in a generalisable fashion, illustrating that their results can be extended to 2D or 3D scenarios, including medical images with different modalities (like CT, MRI, and X-Ray data) and from different anatomical areas. Finally, we adopt a modular and extensible approach, ensuring long-term maintainability and the extension of current applications for future features.
</details>
<details>
<summary>摘要</summary>
In this study, we present MONAI Generative Models, a freely available open-source platform that allows researchers and developers to easily train, evaluate, and deploy generative models and related applications. Our platform reproduces state-of-the-art studies in a standardized way involving different architectures (such as diffusion models, autoregressive transformers, and GANs), and provides pre-trained models for the community. We have implemented these models in a generalizable fashion, illustrating that their results can be extended to 2D or 3D scenarios, including medical images with different modalities (such as CT, MRI, and X-ray data) and from different anatomical areas.Finally, we adopt a modular and extensible approach, ensuring long-term maintainability and the extension of current applications for future features.
</details></li>
</ul>
<hr>
<h2 id="Sparsity-aware-coding-for-single-photon-sensitive-vision-using-Selective-Sensing"><a href="#Sparsity-aware-coding-for-single-photon-sensitive-vision-using-Selective-Sensing" class="headerlink" title="Sparsity aware coding for single photon sensitive vision using Selective Sensing"></a>Sparsity aware coding for single photon sensitive vision using Selective Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15184">http://arxiv.org/abs/2307.15184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yizhou Lu, Trevor Seets, Ehsan Ahmadi, Felipe Gutierrez-Barragan, Andreas Velten</li>
<li>for: 提高图像技术的性能</li>
<li>methods: 使用选择感知来学习特征和优化编码策略</li>
<li>results: 在实验和模拟中表明，选择感知可以提高编码性能和总准确率，特别是在Poisson噪音的场景下。<details>
<summary>Abstract</summary>
Optical coding has been widely adopted to improve the imaging techniques. Traditional coding strategies developed under additive Gaussian noise fail to perform optimally in the presence of Poisson noise. It has been observed in previous studies that coding performance varies significantly between these two noise models. In this work, we introduce a novel approach called selective sensing, which leverages training data to learn priors and optimizes the coding strategies for downstream classification tasks. By adapting to the specific characteristics of photon-counting sensors, the proposed method aims to improve coding performance under Poisson noise and enhance overall classification accuracy. Experimental and simulated results demonstrate the effectiveness of selective sensing in comparison to traditional coding strategies, highlighting its potential for practical applications in photon counting scenarios where Poisson noise are prevalent.
</details>
<details>
<summary>摘要</summary>
光学编码已广泛应用来提高影像技术。传统的编码策略在添加性 Gaussian 噪声下发展起来的情况下，无法达到最佳性。以前的研究表明，编码性能在这两种噪声模型之间存在很大差异。在这种工作中，我们提出了一种新的方法 called 选择感知（selective sensing），利用训练数据学习假设和优化下推类 зада务中的编码策略。通过适应光子计数器的特点，提出的方法希望在Poisson噪声下提高编码性能和总精度。实验和 simulate 结果表明，选择感知方法比传统编码策略更有效， highlighting 其在光子计数器场景中的应用潜力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/28/eess.IV_2023_07_28/" data-id="clogyj92k012a7cra1ntyb4ny" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_07_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/27/cs.SD_2023_07_27/" class="article-date">
  <time datetime="2023-07-27T15:00:00.000Z" itemprop="datePublished">2023-07-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/27/cs.SD_2023_07_27/">cs.SD - 2023-07-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Mitigating-Cross-Database-Differences-for-Learning-Unified-HRTF-Representation"><a href="#Mitigating-Cross-Database-Differences-for-Learning-Unified-HRTF-Representation" class="headerlink" title="Mitigating Cross-Database Differences for Learning Unified HRTF Representation"></a>Mitigating Cross-Database Differences for Learning Unified HRTF Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14547">http://arxiv.org/abs/2307.14547</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yutongwen/hrtf_field_norm">https://github.com/yutongwen/hrtf_field_norm</a></li>
<li>paper_authors: Yutong Wen, You Zhang, Zhiyao Duan</li>
<li>for: 实现虚拟听觉显示器中的准确 зву乐声位置需要个人化的头颈相关转换函数（HRTFs）。</li>
<li>methods: 使用机器学习模型预测个人化HRTFs，但是需要一个统一的HRTF表示方式以利用多个数据库中的有限数据。</li>
<li>results: 这篇研究发现了各数据库HRTF之间的差异，并提出了一个新的方法来对HRTFs进行调变，以获得更好的统一HRTF表示方式。<details>
<summary>Abstract</summary>
Individualized head-related transfer functions (HRTFs) are crucial for accurate sound positioning in virtual auditory displays. As the acoustic measurement of HRTFs is resource-intensive, predicting individualized HRTFs using machine learning models is a promising approach at scale. Training such models require a unified HRTF representation across multiple databases to utilize their respectively limited samples. However, in addition to differences on the spatial sampling locations, recent studies have shown that, even for the common location, HRTFs across databases manifest consistent differences that make it trivial to tell which databases they come from. This poses a significant challenge for learning a unified HRTF representation across databases. In this work, we first identify the possible causes of these cross-database differences, attributing them to variations in the measurement setup. Then, we propose a novel approach to normalize the frequency responses of HRTFs across databases. We show that HRTFs from different databases cannot be classified by their database after normalization. We further show that these normalized HRTFs can be used to learn a more unified HRTF representation across databases than the prior art. We believe that this normalization approach paves the road to many data-intensive tasks on HRTF modeling.
</details>
<details>
<summary>摘要</summary>
个人化的头顶相关转换函数（HRTF）是虚拟受声显示的精确 зву乐位置的关键。由于Measurement of HRTFs是资源充足的，因此使用机器学习模型预测个人化HRTFs是一个具有潜力的方法。training这些模型需要一个统一的HRTF表现方式，以利用它们的限量样本。然而， latest studies have shown that, even for the same location, HRTFs across databases exhibit consistent differences that make it easy to distinguish which databases they come from. This poses a significant challenge for learning a unified HRTF representation across databases.在这个工作中，我们首先识别了可能的跨数据库差异的原因，将其归因于测量设置的变化。然后，我们提出了一种新的方法来对HRTFs的频谱响应进行Normalization。我们显示了，从不同的数据库中取得的HRTFs无法根据其数据库进行分类之后Normalization。此外，我们还显示了这些Normalized HRTFs可以用来学习一个更统一的HRTF表现方式，比对照rior art。我们认为这个Normalization方法将开拓出许多数据密集的HRTF模型任务。
</details></li>
</ul>
<hr>
<h2 id="Modality-Agnostic-Audio-Visual-Deepfake-Detection"><a href="#Modality-Agnostic-Audio-Visual-Deepfake-Detection" class="headerlink" title="Modality-Agnostic Audio-Visual Deepfake Detection"></a>Modality-Agnostic Audio-Visual Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14491">http://arxiv.org/abs/2307.14491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cai Yu, Peng Chen, Jiahe Tian, Jin Liu, Jiao Dai, Xi Wang, Yesheng Chai, Jizhong Han<br>for: 这研究旨在开发一种可以检测多模态深伪的方法，同时可以处理缺失模态情况。methods: 该方法使用了一种混合模式检测方法，利用音频视频抽取相关特征，并使用双标签检测方法来支持独立检测每个模态。results: 实验结果表明，该方法不仅在所有三个音频视频数据集上表现出色，而且在缺失模态情况下也能够达到满意的性能。此外，它还超过了使用两个单模态方法的结果，即使在缺失模态情况下。<details>
<summary>Abstract</summary>
As AI-generated content (AIGC) thrives, Deepfakes have expanded from single-modality falsification to cross-modal fake content creation, where either audio or visual components can be manipulated. While using two unimodal detectors can detect audio-visual deepfakes, cross-modal forgery clues could be overlooked. Existing multimodal deepfake detection methods typically establish correspondence between the audio and visual modalities for binary real/fake classification, and require the co-occurrence of both modalities. However, in real-world multi-modal applications, missing modality scenarios may occur where either modality is unavailable. In such cases, audio-visual detection methods are less practical than two independent unimodal methods. Consequently, the detector can not always obtain the number or type of manipulated modalities beforehand, necessitating a fake-modality-agnostic audio-visual detector. In this work, we propose a unified fake-modality-agnostic scenarios framework that enables the detection of multimodal deepfakes and handles missing modalities cases, no matter the manipulation hidden in audio, video, or even cross-modal forms. To enhance the modeling of cross-modal forgery clues, we choose audio-visual speech recognition (AVSR) as a preceding task, which effectively extracts speech correlation across modalities, which is difficult for deepfakes to reproduce. Additionally, we propose a dual-label detection approach that follows the structure of AVSR to support the independent detection of each modality. Extensive experiments show that our scheme not only outperforms other state-of-the-art binary detection methods across all three audio-visual datasets but also achieves satisfying performance on detection modality-agnostic audio/video fakes. Moreover, it even surpasses the joint use of two unimodal methods in the presence of missing modality cases.
</details>
<details>
<summary>摘要</summary>
As AI-generated content (AIGC) thrives, Deepfakes have expanded from single-modality falsification to cross-modal fake content creation, where either audio or visual components can be manipulated. While using two unimodal detectors can detect audio-visual deepfakes, cross-modal forgery clues could be overlooked. Existing multimodal deepfake detection methods typically establish correspondence between the audio and visual modalities for binary real/fake classification, and require the co-occurrence of both modalities. However, in real-world multi-modal applications, missing modality scenarios may occur where either modality is unavailable. In such cases, audio-visual detection methods are less practical than two independent unimodal methods. Consequently, the detector can not always obtain the number or type of manipulated modalities beforehand, necessitating a fake-modality-agnostic audio-visual detector. In this work, we propose a unified fake-modality-agnostic scenarios framework that enables the detection of multimodal deepfakes and handles missing modalities cases, no matter the manipulation hidden in audio, video, or even cross-modal forms. To enhance the modeling of cross-modal forgery clues, we choose audio-visual speech recognition (AVSR) as a preceding task, which effectively extracts speech correlation across modalities, which is difficult for deepfakes to reproduce. Additionally, we propose a dual-label detection approach that follows the structure of AVSR to support the independent detection of each modality. Extensive experiments show that our scheme not only outperforms other state-of-the-art binary detection methods across all three audio-visual datasets but also achieves satisfying performance on detection modality-agnostic audio/video fakes. Moreover, it even surpasses the joint use of two unimodal methods in the presence of missing modality cases.
</details></li>
</ul>
<hr>
<h2 id="Single-Channel-Speech-Enhancement-Using-U-Net-Spiking-Neural-Networks"><a href="#Single-Channel-Speech-Enhancement-Using-U-Net-Spiking-Neural-Networks" class="headerlink" title="Single Channel Speech Enhancement Using U-Net Spiking Neural Networks"></a>Single Channel Speech Enhancement Using U-Net Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14464">http://arxiv.org/abs/2307.14464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abir Riahi, Éric Plourde</li>
<li>for: 提高沟通设备和可靠语音识别系统的可靠性</li>
<li>methods: 使用快速 нейрон网络（SNN）基于U-Net架构</li>
<li>results: 比起智能硬件实现的Intel N-DNS Challenge基准解决方案，提出了能效的SNN模型，并在不同的噪声比例和实际噪声条件下达到了接受性的性能。<details>
<summary>Abstract</summary>
Speech enhancement (SE) is crucial for reliable communication devices or robust speech recognition systems. Although conventional artificial neural networks (ANN) have demonstrated remarkable performance in SE, they require significant computational power, along with high energy costs. In this paper, we propose a novel approach to SE using a spiking neural network (SNN) based on a U-Net architecture. SNNs are suitable for processing data with a temporal dimension, such as speech, and are known for their energy-efficient implementation on neuromorphic hardware. As such, SNNs are thus interesting candidates for real-time applications on devices with limited resources. The primary objective of the current work is to develop an SNN-based model with comparable performance to a state-of-the-art ANN model for SE. We train a deep SNN using surrogate-gradient-based optimization and evaluate its performance using perceptual objective tests under different signal-to-noise ratios and real-world noise conditions. Our results demonstrate that the proposed energy-efficient SNN model outperforms the Intel Neuromorphic Deep Noise Suppression Challenge (Intel N-DNS Challenge) baseline solution and achieves acceptable performance compared to an equivalent ANN model.
</details>
<details>
<summary>摘要</summary>
声音增强（SE）是重要的通信设备或可靠的语音识别系统的关键。虽然传统的人工神经网络（ANN）已经在SE中表现出了很好的性能，但它们需要很大的计算能力以及高的能源成本。在这篇论文中，我们提出了一种使用射频神经网络（SNN）的新方法，基于U-Net架构。SNN适合处理时间维度上的数据，如语音，并且在神经逻辑硬件上实现能效。因此，SNN是实时应用中的有趣候选者。目标是开发一个与状态ixen-of-the-art ANN模型相比的性能相似的SNN模型。我们使用代理函数基于优化方法来训练深度SNN，并对其性能进行评估使用感知目标测试，包括不同的信号响应率和实际噪声条件。我们的结果表明，我们提出的能效SNN模型比Intel neuromorphic Deep Noise Suppression Challenge（Intel N-DNS Challenge）基准解决方案更好，并且与相同的ANN模型相比，其性能是可接受的。
</details></li>
</ul>
<hr>
<h2 id="WavJourney-Compositional-Audio-Creation-with-Large-Language-Models"><a href="#WavJourney-Compositional-Audio-Creation-with-Large-Language-Models" class="headerlink" title="WavJourney: Compositional Audio Creation with Large Language Models"></a>WavJourney: Compositional Audio Creation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14335">http://arxiv.org/abs/2307.14335</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/audio-agi/wavjourney">https://github.com/audio-agi/wavjourney</a></li>
<li>paper_authors: Xubo Liu, Zhongkai Zhu, Haohe Liu, Yi Yuan, Meng Cui, Qiushi Huang, Jinhua Liang, Yin Cao, Qiuqiang Kong, Mark D. Plumbley, Wenwu Wang<br>for: 这个论文的目的是如何使用大语言模型（LLMs）来创造具有语音、乐曲和特效的听众场景。methods: 这篇论文使用了LLMs来连接不同的听众场景模型，以便根据文本描述创建听众场景。具体来说，LLMs首先生成了一份特有的听众场景脚本，该脚本包含了不同的听众场景元素，以及这些元素之间的空间时间关系。然后，这份脚本被交给了一个脚本编译器，将其转换为计算机程序。每一行的程序调用了一个任务特定的听众场景生成模型或计算操作函数（例如， concatenate、mix）。最后，计算程序执行以生成听众场景。results: 这篇论文在多个实际场景中证明了WavJourney的实用性，包括科幻、教育和广播剧等。WavJourney的可解释和交互设计使得人机共创在多round对话中得到了改进的创造控制和适应性。WavJourney为听众场景创作提供了一个新的创新平台，打开了新的可能性 для multimedia内容创作。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown great promise in integrating diverse expert models to tackle intricate language and vision tasks. Despite their significance in advancing the field of Artificial Intelligence Generated Content (AIGC), their potential in intelligent audio content creation remains unexplored. In this work, we tackle the problem of creating audio content with storylines encompassing speech, music, and sound effects, guided by text instructions. We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation. Given a text description of an auditory scene, WavJourney first prompts LLMs to generate a structured script dedicated to audio storytelling. The audio script incorporates diverse audio elements, organized based on their spatio-temporal relationships. As a conceptual representation of audio, the audio script provides an interactive and interpretable rationale for human engagement. Afterward, the audio script is fed into a script compiler, converting it into a computer program. Each line of the program calls a task-specific audio generation model or computational operation function (e.g., concatenate, mix). The computer program is then executed to obtain an explainable solution for audio generation. We demonstrate the practicality of WavJourney across diverse real-world scenarios, including science fiction, education, and radio play. The explainable and interactive design of WavJourney fosters human-machine co-creation in multi-round dialogues, enhancing creative control and adaptability in audio production. WavJourney audiolizes the human imagination, opening up new avenues for creativity in multimedia content creation.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在融合多种专家模型方面表现出了很大的承诺，它们在人工智能生成内容领域的发展中发挥了重要作用。然而，它们在智能音频内容创作方面的潜力还未得到开发。在这项工作中，我们解决了基于文本描述的音频内容创作问题。我们提出了一种名为WavJourney的系统，它利用LLM来连接多种音频模型，以实现音频内容创作。给定一个文本描述的听力场景，WavJourney首先使用LLM生成一个专门为音频故事创作的结构化脚本。这个音频脚本包含多种听力元素，按照其空间时间关系进行组织。作为听力内容的概念表示，音频脚本提供了可交互和可解释的理由，用于人机合作。接下来，音频脚本被 feed 到一个脚本编译器，将其转换成计算机程序。每行程序调用一个任务特定的音频生成模型或计算操作函数（例如， concatenate、mix）。计算程序被执行以获取可解释的音频生成解决方案。我们在多个实际场景中证明了WavJourney的实用性，包括科幻、教育和广播剧。WavJourney的可解释和交互设计使得人机合作在多轮对话中得到加强，提高了音频生产的创作控制和适应性。WavJourney将人类的想象力音频化，开启了新的创作途径在多媒体内容创作领域。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/27/cs.SD_2023_07_27/" data-id="clogyj90500sf7cra3zj42i7h" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_07_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/27/eess.AS_2023_07_27/" class="article-date">
  <time datetime="2023-07-27T14:00:00.000Z" itemprop="datePublished">2023-07-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/27/eess.AS_2023_07_27/">eess.AS - 2023-07-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Audio-Inputs-for-Active-Speaker-Detection-and-Localization-via-Microphone-Array"><a href="#Audio-Inputs-for-Active-Speaker-Detection-and-Localization-via-Microphone-Array" class="headerlink" title="Audio Inputs for Active Speaker Detection and Localization via Microphone Array"></a>Audio Inputs for Active Speaker Detection and Localization via Microphone Array</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14739">http://arxiv.org/abs/2307.14739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Berghi, Philip J. B. Jackson</li>
<li>for: 本研究探讨了基于多道声音捕获的活聊检测和定位问题，即活聊检测和定位（ASDL）。</li>
<li>methods: 本研究使用了一种卷积Recurrent Neural Network（CRNN），使用了多道声音中的空间音学特征作为输入，并对不同的渠道数和干扰噪音进行比较。</li>
<li>results: 实验结果表明，使用GCC-PHAT、SALSA特征和新的扩权报知方法可以减轻不同噪音水平下的表达性能下降，并且可以根据降噪性和渠道数进行优化。<details>
<summary>Abstract</summary>
This study considers the problem of detecting and locating an active talker's horizontal position from multichannel audio captured by a microphone array. We refer to this as active speaker detection and localization (ASDL). Our goal was to investigate the performance of spatial acoustic features extracted from the multichannel audio as the input of a convolutional recurrent neural network (CRNN), in relation to the number of channels employed and additive noise. To this end, experiments were conducted to compare the generalized cross-correlation with phase transform (GCC-PHAT), the spatial cue-augmented log-spectrogram (SALSA) features, and a recently-proposed beamforming method, evaluating their robustness to various noise intensities. The array aperture and sampling density were tested by taking subsets from the 16-microphone array. Results and tests of statistical significance demonstrate the microphones' contribution to performance on the TragicTalkers dataset, which offers opportunities to investigate audio-visual approaches in the future.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Physics-Informed-Neural-Network-for-Head-Related-Transfer-Function-Upsampling"><a href="#Physics-Informed-Neural-Network-for-Head-Related-Transfer-Function-Upsampling" class="headerlink" title="Physics Informed Neural Network for Head-Related Transfer Function Upsampling"></a>Physics Informed Neural Network for Head-Related Transfer Function Upsampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14650">http://arxiv.org/abs/2307.14650</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/feima0011/physics-informed-neural-network-for-head-related-transfer-function-upsampling">https://github.com/feima0011/physics-informed-neural-network-for-head-related-transfer-function-upsampling</a></li>
<li>paper_authors: Fei Ma, Thushara D. Abhayapala, Prasanga N. Samarasinghe, Xingyu Chen</li>
<li>for: 提高虚拟听觉体验的真实性，使用physics-informed neural network（PINN）方法进行HRTF upsampling。</li>
<li>methods: 基于Helmholtz方程的PINN方法，利用HRTF的物理特性来做upsampling，避免基于测量数据的局限性。</li>
<li>results: 对多个数据集进行比较，PINN方法在 interpolate 和 extrapolate 两种enario中具有更高的性能，不受under-fitting和over-fitting问题的影响。<details>
<summary>Abstract</summary>
Head-related transfer functions (HRTFs) capture the spatial and spectral features that a person uses to localize sound sources in space and thus are vital for creating an authentic virtual acoustic experience. However, practical HRTF measurement systems can only provide an incomplete measurement of a person's HRTFs, and this necessitates HRTF upsampling. This paper proposes a physics-informed neural network (PINN) method for HRTF upsampling. Unlike other upsampling methods which are based on the measured HRTFs only, the PINN method exploits the Helmholtz equation as additional information for constraining the upsampling process. This helps the PINN method to generate physically amiable upsamplings which generalize beyond the measured HRTFs. Furthermore, the width and the depth of the PINN are set according to the dimensionality of HRTFs under spherical harmonic (SH) decomposition and the Helmholtz equation. This makes the PINN have an appropriate level of expressiveness and thus does not suffer from under-fitting and over-fitting problems. Numerical experiments confirm the superior performance of the PINN method for HRTF upsampling in both interpolation and extrapolation scenarios over several datasets in comparison with the SH methods.
</details>
<details>
<summary>摘要</summary>
人头相关传函数（HRTF）捕捉了声音源的空间和频率特征，因此是创建真实虚拟听音场的关键。然而，实际测量HRTF系统只能提供 incomplete HRTF 测量，这需要HRTF 采样。这篇论文提出了一种基于物理学习神经网络（PINN）方法的 HRTF 采样方法。与其他采样方法不同，PINN 方法利用 Helmholtz 方程作为额外信息，以制约采样过程。这帮助 PINN 方法生成physically amiable的采样，并且这些采样可以扩展到测量 HRTF 之 beyond。此外，PINN 方法的宽度和深度是根据 HRTF 的维度下圆函数（SH）划分和 Helmholtz 方程来设置。这使得 PINN 方法具有合适的表达能力，并且不会出现过拟合和下拟合问题。 numerical experiments 表明，PINN 方法在 interpolate 和 extrapolate  scenarios 中对多个数据集的 HRTF 采样性能较 SH 方法更高。
</details></li>
</ul>
<hr>
<h2 id="NeuroHeed-Neuro-Steered-Speaker-Extraction-using-EEG-Signals"><a href="#NeuroHeed-Neuro-Steered-Speaker-Extraction-using-EEG-Signals" class="headerlink" title="NeuroHeed: Neuro-Steered Speaker Extraction using EEG Signals"></a>NeuroHeed: Neuro-Steered Speaker Extraction using EEG Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14303">http://arxiv.org/abs/2307.14303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zexu Pan, Marvin Borsdorf, Siqi Cai, Tanja Schultz, Haizhou Li</li>
<li>for: 本研究旨在开发一种基于EEG信号的选择性听力模型，以实现在听到干扰的多人对话中提取主要的说话人信号。</li>
<li>methods: 该模型使用EEG信号来建立一个neuronal attractor，其与听到的语音刺激相关，并通过在线和离线两种方式实现实时和非实时的抽取。在线NeuroHeed还包括一个自适应核心编码器，以积累过去抽取的语音信号，以便在下一个时间窗口中帮助抽取当前说话人信号。</li>
<li>results: 实验结果表明，NeuroHeed能够有效地提取主要的说话人信号，并达到高质量、出色的 восприятия质量和语音可理解性。<details>
<summary>Abstract</summary>
Humans possess the remarkable ability to selectively attend to a single speaker amidst competing voices and background noise, known as selective auditory attention. Recent studies in auditory neuroscience indicate a strong correlation between the attended speech signal and the corresponding brain's elicited neuronal activities, which the latter can be measured using affordable and non-intrusive electroencephalography (EEG) devices. In this study, we present NeuroHeed, a speaker extraction model that leverages EEG signals to establish a neuronal attractor which is temporally associated with the speech stimulus, facilitating the extraction of the attended speech signal in a cocktail party scenario. We propose both an offline and an online NeuroHeed, with the latter designed for real-time inference. In the online NeuroHeed, we additionally propose an autoregressive speaker encoder, which accumulates past extracted speech signals for self-enrollment of the attended speaker information into an auditory attractor, that retains the attentional momentum over time. Online NeuroHeed extracts the current window of the speech signals with guidance from both attractors. Experimental results demonstrate that NeuroHeed effectively extracts brain-attended speech signals, achieving high signal quality, excellent perceptual quality, and intelligibility in a two-speaker scenario.
</details>
<details>
<summary>摘要</summary>
人类具有选择性听觉能力，能够在多个声音和背景噪声中选择一个声音，这种能力被称为选择性听觉注意力。最近的听觉神经科学研究表明，在听觉过程中选择的语音信号和大脑发生的神经活动之间存在强相关性，这些神经活动可以使用便宜和不侵入的电enzephalography（EEG）设备测量。在这个研究中，我们介绍了NeuroHeed，一种基于EEG信号的语音抽取模型，可以在听觉场景中提取选择的语音信号。我们提出了两种NeuroHeed，一个是OFFLINE版本，另一个是ONLINE版本。在ONLINE版本中，我们还提出了自适应语音编码器，该编码器将过去提取的语音信号accumulate为自我投入的听觉招引器，以保持注意力的积累。ONLINE NeuroHeed在当前窗口中提取语音信号，受到两个招引器的引导。实验结果表明，NeuroHeed可以有效地提取大脑注意力的语音信号，实现高质量的语音信号、优美的听觉质量和语音清晰度在两个说话者场景中。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/27/eess.AS_2023_07_27/" data-id="clogyj91j00ym7cra3ebfegxa" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/27/cs.CV_2023_07_27/" class="article-date">
  <time datetime="2023-07-27T13:00:00.000Z" itemprop="datePublished">2023-07-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/27/cs.CV_2023_07_27/">cs.CV - 2023-07-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Federated-Model-Aggregation-via-Self-Supervised-Priors-for-Highly-Imbalanced-Medical-Image-Classification"><a href="#Federated-Model-Aggregation-via-Self-Supervised-Priors-for-Highly-Imbalanced-Medical-Image-Classification" class="headerlink" title="Federated Model Aggregation via Self-Supervised Priors for Highly Imbalanced Medical Image Classification"></a>Federated Model Aggregation via Self-Supervised Priors for Highly Imbalanced Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14959">http://arxiv.org/abs/2307.14959</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xmed-lab/fed-mas">https://github.com/xmed-lab/fed-mas</a></li>
<li>paper_authors: Marawan Elbatel, Hualiang Wang, Robert Martí, Huazhu Fu, Xiaomeng Li</li>
<li>for: 这 paper 主要针对高度不均衡的医疗数据集，包括皮肤损伤和肠道图像。现有的联邦学习方法在高度不均衡的数据集上主要是优化全局模型，而不考虑具有不同人口、发现和扫描仪的内部变化。</li>
<li>methods: 本 paper 使用公共可用的自我监督网络来研究客户端间的内部变化。Specifically, 我们发现使用每个客户端上的共享auxiliary pre-trained模型，如 MoCo-V2，可以获得相似的偏移量度量。基于这些发现，我们 derivate了一种动态均衡模型聚合via自我监督先验（MAS），以导引全局模型优化。</li>
<li>results: Fed-MAS 可以与不同的本地学习方法结合使用，以实现有效的模型聚合，并生成一个高度稳定和不偏的全局模型。我们的代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/xmed-lab/Fed-MAS%7D">https://github.com/xmed-lab/Fed-MAS}</a> 上找到。<details>
<summary>Abstract</summary>
In the medical field, federated learning commonly deals with highly imbalanced datasets, including skin lesions and gastrointestinal images. Existing federated methods under highly imbalanced datasets primarily focus on optimizing a global model without incorporating the intra-class variations that can arise in medical imaging due to different populations, findings, and scanners. In this paper, we study the inter-client intra-class variations with publicly available self-supervised auxiliary networks. Specifically, we find that employing a shared auxiliary pre-trained model, like MoCo-V2, locally on every client yields consistent divergence measurements. Based on these findings, we derive a dynamic balanced model aggregation via self-supervised priors (MAS) to guide the global model optimization. Fed-MAS can be utilized with different local learning methods for effective model aggregation toward a highly robust and unbiased global model. Our code is available at \url{https://github.com/xmed-lab/Fed-MAS}.
</details>
<details>
<summary>摘要</summary>
医疗领域中，联合学习通常处理高度不均衡的数据集，包括皮肤损害和肠道图像。现有的联合方法在高度不均衡的数据集上主要是优化全局模型，而不考虑医疗图像中可能出现的不同人口、发现和扫描器引起的内类差异。在这篇论文中，我们研究了客户端间内类差异，使用公共可用的自我超vised副网络（如MoCo-V2）进行本地预训练。我们发现，使用共享副网络模型在每个客户端进行本地预训练可以获得一致的异同度测量。基于这些发现，我们 derivate了一种动态均衡模型聚合方法（MAS），以自我超vised先验为引导，向全局模型优化。Fed-MAS可以与不同的本地学习方法结合使用，以实现高度 Robust和不偏的全球模型。我们的代码可以在 GitHub 上找到：https://github.com/xmed-lab/Fed-MAS。
</details></li>
</ul>
<hr>
<h2 id="GET3D–-Learning-GET3D-from-Unconstrained-Image-Collections"><a href="#GET3D–-Learning-GET3D-from-Unconstrained-Image-Collections" class="headerlink" title="GET3D–: Learning GET3D from Unconstrained Image Collections"></a>GET3D–: Learning GET3D from Unconstrained Image Collections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14918">http://arxiv.org/abs/2307.14918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fanghua Yu, Xintao Wang, Zheyuan Li, Yan-Pei Cao, Ying Shan, Chao Dong</li>
<li>for: 生成高质量3D模型的需求在增长 exponential 速度，手动创建3D模型需要专业知识和大量时间。</li>
<li>methods: 我们提出了GET3D–方法，可以从2D图像直接生成高品质的3D模型，并且可以处理未知姿态和比例的情况。我们还提出了一种新的训练计划，可以稳定优化shape生成器和摄像头抽象器。</li>
<li>results: 我们的实验表明，GET3D–方法可以准确地适应6D摄像头姿态分布，并生成高品质的3D模型。我们在 synthetic 和实际不制约的数据集上进行了广泛的实验，并证明了我们的方法的可靠性和稳定性。<details>
<summary>Abstract</summary>
The demand for efficient 3D model generation techniques has grown exponentially, as manual creation of 3D models is time-consuming and requires specialized expertise. While generative models have shown potential in creating 3D textured shapes from 2D images, their applicability in 3D industries is limited due to the lack of a well-defined camera distribution in real-world scenarios, resulting in low-quality shapes. To overcome this limitation, we propose GET3D--, the first method that directly generates textured 3D shapes from 2D images with unknown pose and scale. GET3D-- comprises a 3D shape generator and a learnable camera sampler that captures the 6D external changes on the camera. In addition, We propose a novel training schedule to stably optimize both the shape generator and camera sampler in a unified framework. By controlling external variations using the learnable camera sampler, our method can generate aligned shapes with clear textures. Extensive experiments demonstrate the efficacy of GET3D--, which precisely fits the 6D camera pose distribution and generates high-quality shapes on both synthetic and realistic unconstrained datasets.
</details>
<details>
<summary>摘要</summary>
需求高效3D模型生成技术的增长速度在线上呈指数增长趋势，因为手动创建3D模型需要特殊的专业知识并且占用了大量时间。而生成模型在3D行业中的应用是有限的，主要是因为实际场景中相机的分布没有明确的定义，导致生成的形状质量低下。为了解决这个问题，我们提出了 GET3D--，第一种直接从2D图像中生成有文字URE的3D形状的方法。GET3D--包括3D形状生成器和可学习的相机抽取器，可以捕捉外部的6D变化。此外，我们还提出了一种新的训练计划，可以稳定地优化形状生成器和相机抽取器在一个统一的框架中。通过控制外部变化使用可学习的相机抽取器，我们的方法可以生成aligned的形状，并且 texture是清晰的。广泛的实验证明了 GET3D--的可靠性，它能够准确地适应6D相机pose分布，并在 synthetic和实际无结构化数据集上生成高质量的形状。
</details></li>
</ul>
<hr>
<h2 id="NSA-Naturalistic-Support-Artifact-to-Boost-Network-Confidence"><a href="#NSA-Naturalistic-Support-Artifact-to-Boost-Network-Confidence" class="headerlink" title="NSA: Naturalistic Support Artifact to Boost Network Confidence"></a>NSA: Naturalistic Support Artifact to Boost Network Confidence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14917">http://arxiv.org/abs/2307.14917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhijith Sharma, Phil Munz, Apurva Narayan</li>
<li>for: 这篇论文主要关注在visual AI系统面对自然和人工物理变化的抵抗性能。</li>
<li>methods: 这篇论文提出了一种叫做自然支持物件（NSA）的方法，通过DC-GAN进行 artifact 训练，以提高预测的可靠性。</li>
<li>results: 研究发现，这种NSA方法可以对抗自然变化，提高预测的信任分数，并且可以提高适应攻击性能。<details>
<summary>Abstract</summary>
Visual AI systems are vulnerable to natural and synthetic physical corruption in the real-world. Such corruption often arises unexpectedly and alters the model's performance. In recent years, the primary focus has been on adversarial attacks. However, natural corruptions (e.g., snow, fog, dust) are an omnipresent threat to visual AI systems and should be considered equally important. Many existing works propose interesting solutions to train robust models against natural corruption. These works either leverage image augmentations, which come with the additional cost of model training, or place suspicious patches in the scene to design unadversarial examples. In this work, we propose the idea of naturalistic support artifacts (NSA) for robust prediction. The NSAs are shown to be beneficial in scenarios where model parameters are inaccessible and adding artifacts in the scene is feasible. The NSAs are natural looking objects generated through artifact training using DC-GAN to have high visual fidelity in the scene. We test against natural corruptions on the Imagenette dataset and observe the improvement in prediction confidence score by four times. We also demonstrate NSA's capability to increase adversarial accuracy by 8\% on average. Lastly, we qualitatively analyze NSAs using saliency maps to understand how they help improve prediction confidence.
</details>
<details>
<summary>摘要</summary>
视觉人工智能系统容易受到自然和人工生成的物理损害。这种损害通常是意外的，并会改变模型的性能。在过去几年中，主要关注点是对敌意攻击。然而，自然损害（如雪、雾、尘埃）对视觉人工智能系统是一种普遍存在的威胁，应该受到同样重视。现有的许多研究提出了有趣的解决方案，以帮助训练鲁棒的模型。这些研究可能会通过增加图像变换，来增加模型训练的成本，或者在场景中放置怀疑的贴图以设计不敌攻击示例。在这项工作中，我们提出了自然支持 artifacts（NSA）的想法，以便在无法访问模型参数时，提高预测的可靠性。NSA通过使用DC-GAN进行遗产训练，以生成高视觉准确性的自然看起来的对象。我们在Imagenette数据集上测试了对自然损害的情况，并观察到预测信心分数提高4倍。此外，我们还证明NSA可以提高敌意率平均8%。最后，我们使用滤波映射来解释NSA如何提高预测的可靠性。
</details></li>
</ul>
<hr>
<h2 id="Clustering-of-illustrations-by-atmosphere-using-a-combination-of-supervised-and-unsupervised-learning"><a href="#Clustering-of-illustrations-by-atmosphere-using-a-combination-of-supervised-and-unsupervised-learning" class="headerlink" title="Clustering of illustrations by atmosphere using a combination of supervised and unsupervised learning"></a>Clustering of illustrations by atmosphere using a combination of supervised and unsupervised learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15099">http://arxiv.org/abs/2307.15099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keisuke Kubota, Masahiro Okuda<br>for:这篇论文旨在解决分类Illustration的”氛围”（atmosphere）问题，帮助推荐和搜索。methods:这篇论文使用了 both supervised和Unsupervised learning with pseudo-labels，以获得特征向量。results:实验分析表明，这种方法可以比传统方法更好地实现人类化的集群。<details>
<summary>Abstract</summary>
The distribution of illustrations on social media, such as Twitter and Pixiv has increased with the growing popularity of animation, games, and animated movies. The "atmosphere" of illustrations plays an important role in user preferences. Classifying illustrations by atmosphere can be helpful for recommendations and searches. However, assigning clear labels to the elusive "atmosphere" and conventional supervised classification is not always practical. Furthermore, even images with similar colors, edges, and low-level features may not have similar atmospheres, making classification based on low-level features challenging. In this paper, this problem is solved using both supervised and unsupervised learning with pseudo-labels. The feature vectors are obtained using the supervised method with pseudo-labels that contribute to an ambiguous atmosphere. Further, clustering is performed based on these feature vectors. Experimental analyses show that our method outperforms conventional methods in human-like clustering on datasets manually classified by humans.
</details>
<details>
<summary>摘要</summary>
社交媒体上的插图分布量增加，与动画、游戏和动画电影的浸泡式 Popularity 相关。插图的“氛围”在用户喜好中扮演重要的角色。按氛围分类插图可以有助于推荐和搜索。但是，将氛围分类为明确的标签是不实际的。即使图像具有相同的颜色、边缘和低级特征，也可能没有相同的氛围，从而使基于低级特征的分类困难。在这篇论文中，我们解决了这个问题，使用超级vised和无监督学习，并使用 pseudo-labels。我们通过supervised方法获取特征向量，并使用这些特征向量进行 clustering。实验分析表明，我们的方法在人类分类数据集上超过了传统方法的性能。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-AI-for-Efficient-Analysis-of-3D-Pathology-Samples"><a href="#Weakly-Supervised-AI-for-Efficient-Analysis-of-3D-Pathology-Samples" class="headerlink" title="Weakly Supervised AI for Efficient Analysis of 3D Pathology Samples"></a>Weakly Supervised AI for Efficient Analysis of 3D Pathology Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14907">http://arxiv.org/abs/2307.14907</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mahmoodlab/mamba">https://github.com/mahmoodlab/mamba</a></li>
<li>paper_authors: Andrew H. Song, Mane Williams, Drew F. K. Williamson, Guillaume Jaume, Andrew Zhang, Bowen Chen, Robert Serafin, Jonathan T. C. Liu, Alex Baras, Anil V. Parwani, Faisal Mahmood</li>
<li>for: 这篇论文旨在提供一种用于诊断和评估癌症治疗效果的深度学习平台，以帮助临床医生更好地诊断和治疗癌症。</li>
<li>methods: 该论文使用了多模态多实例学习（MAMBA）平台，通过处理不同成像模式的3D组织图像，预测癌症患者的5年生物化学回报。</li>
<li>results: 研究发现，使用MAMBA平台可以更好地预测癌症患者的5年生物化学回报，并且可以减少采样偏见的风险，提高诊断精度。<details>
<summary>Abstract</summary>
Human tissue and its constituent cells form a microenvironment that is fundamentally three-dimensional (3D). However, the standard-of-care in pathologic diagnosis involves selecting a few two-dimensional (2D) sections for microscopic evaluation, risking sampling bias and misdiagnosis. Diverse methods for capturing 3D tissue morphologies have been developed, but they have yet had little translation to clinical practice; manual and computational evaluations of such large 3D data have so far been impractical and/or unable to provide patient-level clinical insights. Here we present Modality-Agnostic Multiple instance learning for volumetric Block Analysis (MAMBA), a deep-learning-based platform for processing 3D tissue images from diverse imaging modalities and predicting patient outcomes. Archived prostate cancer specimens were imaged with open-top light-sheet microscopy or microcomputed tomography and the resulting 3D datasets were used to train risk-stratification networks based on 5-year biochemical recurrence outcomes via MAMBA. With the 3D block-based approach, MAMBA achieves an area under the receiver operating characteristic curve (AUC) of 0.86 and 0.74, superior to 2D traditional single-slice-based prognostication (AUC of 0.79 and 0.57), suggesting superior prognostication with 3D morphological features. Further analyses reveal that the incorporation of greater tissue volume improves prognostic performance and mitigates risk prediction variability from sampling bias, suggesting the value of capturing larger extents of heterogeneous 3D morphology. With the rapid growth and adoption of 3D spatial biology and pathology techniques by researchers and clinicians, MAMBA provides a general and efficient framework for 3D weakly supervised learning for clinical decision support and can help to reveal novel 3D morphological biomarkers for prognosis and therapeutic response.
</details>
<details>
<summary>摘要</summary>
人类组织和其组成细胞形成了基本三维（3D）的微环境。然而，现行的诊断标准仅选择一些二维（2D）的部分进行微镜下评估，可能会导致抽象采样偏见和误诊。多种用于捕捉3D组织结构的方法已经开发，但它们尚未在临床实践中得到广泛应用。我们现在提出了模态不可知多例学习 для卷积体分析（MAMBA），一种基于深度学习的平台，用于处理多种成像模式的3D组织图像并预测患者结果。我们使用了开普通镜微镜或微计算tomography扫描患有前列腺癌的股骨板，并使用MAMBA进行风险 stratification网络的训练，以实现5年内生化回报的预测。通过3D块基本方法，MAMBA在 receiver操作特征曲线值（AUC）中取得0.86和0.74，比2D传统单片基本预测（AUC为0.79和0.57）更高，表明3D形态特征更好地预测结果。进一步分析表明，包含更大的组织体积可以提高预测性能，并减少采样偏见导致的预测变化，表明捕捉更大的多样性3D形态是有价值的。随着3D空间生物学和病理学技术的快速发展和应用，MAMBA提供了一个通用和高效的3D弱监学习框架，可以帮助探索新的3D形态生物标志物和诊断响应。
</details></li>
</ul>
<hr>
<h2 id="Mixture-of-Self-Supervised-Learning"><a href="#Mixture-of-Self-Supervised-Learning" class="headerlink" title="Mixture of Self-Supervised Learning"></a>Mixture of Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14897">http://arxiv.org/abs/2307.14897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aristorenaldo/g-ssl">https://github.com/aristorenaldo/g-ssl</a></li>
<li>paper_authors: Aristo Renaldo Ruslim, Novanto Yudistira, Budi Darma Setiawan</li>
<li>For: The paper aims to improve image classification by proposing a Gated Self-Supervised Learning (G-SSL) method that uses multiple pretext tasks and a Mixture of Expert architecture to combine them.* Methods: The proposed G-SSL method uses a combination of pretext tasks, including rotation prediction, solving jigsaw puzzles, and predicting relative positions on images. The method also employs a Mixture of Expert architecture as a gating network to combine the pretext tasks and automatically focus on the most useful augmentations for classification.* Results: The proposed method is tested on several scenarios, including CIFAR imbalance dataset classification, adversarial perturbations, Tiny-Imagenet dataset classification, and semi-supervised learning. The results show that the G-SSL method outperforms previous self-supervised learning methods in image classification tasks. Additionally, Grad-CAM and T-SNE analysis are used to visualize the important features that influence image classification and represent data for each class.Here is the simplified Chinese text format for the three information points:* For: 本研究旨在提高图像分类方法，通过提出多个预测任务和权重综合网络的组合来提高自动学习方法。* Methods: 提议的G-SSL方法使用多个预测任务，包括旋转预测、图像谜题解决和图像相对位置预测。此外，方法还使用权重综合网络来组合每个预测任务，以便自动地强调最有用的扩充方法。* Results: 提议的方法在多个场景中进行测试，包括CIFAR不均衡数据集分类、防御攻击、Tiny-Imagenet数据集分类和半监督学习。结果表明，G-SSL方法在图像分类任务中表现出色，并且通过Grad-CAM和T-SNE分析可以查看到重要的特征影响图像分类。<details>
<summary>Abstract</summary>
Self-supervised learning is popular method because of its ability to learn features in images without using its labels and is able to overcome limited labeled datasets used in supervised learning. Self-supervised learning works by using a pretext task which will be trained on the model before being applied to a specific task. There are some examples of pretext tasks used in self-supervised learning in the field of image recognition, namely rotation prediction, solving jigsaw puzzles, and predicting relative positions on image. Previous studies have only used one type of transformation as a pretext task. This raises the question of how it affects if more than one pretext task is used and to use a gating network to combine all pretext tasks. Therefore, we propose the Gated Self-Supervised Learning method to improve image classification which use more than one transformation as pretext task and uses the Mixture of Expert architecture as a gating network in combining each pretext task so that the model automatically can study and focus more on the most useful augmentations for classification. We test performance of the proposed method in several scenarios, namely CIFAR imbalance dataset classification, adversarial perturbations, Tiny-Imagenet dataset classification, and semi-supervised learning. Moreover, there are Grad-CAM and T-SNE analysis that are used to see the proposed method for identifying important features that influence image classification and representing data for each class and separating different classes properly. Our code is in https://github.com/aristorenaldo/G-SSL
</details>
<details>
<summary>摘要</summary>
自我超级学习是一种受欢迎的方法，因为它可以在无需标签的情况下学习图像中的特征。自我超级学习通过使用预测任务来实现，这些任务将在模型之前进行训练，然后应用到特定任务上。在图像识别领域中，一些常见的预测任务包括旋转预测、解决缺失图像和Relative Positions预测。以前的研究只使用了一种变换作为预测任务。这引发了对多个预测任务的使用以及使用权重网络结合每个预测任务的问题。因此，我们提出了加锁自动学习方法，以提高图像分类。我们在多个变换作为预测任务，并使用权重网络结合每个预测任务来自动学习和强调最有用的扩展。我们在多个场景中测试了我们的提议方法，包括CIFAR不均衡数据集分类、抗攻击扰动、Tiny-Imagenet数据集分类和半监督学习。此外，我们还使用Grad-CAM和T-SNE分析来看到我们的提议方法如何对图像分类做出重要的特征标识和数据表示，并正确地分离不同的类别。我们的代码可以在https://github.com/aristorenaldo/G-SSL上找到。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Learning-for-Improved-Synthetic-Aperture-Sonar-Target-Recognition"><a href="#Self-Supervised-Learning-for-Improved-Synthetic-Aperture-Sonar-Target-Recognition" class="headerlink" title="Self-Supervised Learning for Improved Synthetic Aperture Sonar Target Recognition"></a>Self-Supervised Learning for Improved Synthetic Aperture Sonar Target Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15098">http://arxiv.org/abs/2307.15098</a></li>
<li>repo_url: None</li>
<li>paper_authors: BW Sheffield</li>
<li>for: 本研究探讨了基于自动学习（SSL）的目标识别在探测镜（SAS）图像中的应用。由于水下环境的特殊性，传统的计算机视觉技术，它们几乎完全依赖于光学相机图像，在水下环境中变得更加不效果。而SAS，它能够生成高分辨率图像，因此成为水下扫描领域的首选。但是，高分辨率SAS数据的巨量却对标注提出了巨大的挑战，标注是训练深度神经网络（DNNs）的关键步骤。</li>
<li>methods: 本研究使用了两种知名的SSL算法，MoCov2和BYOL，与已知的超级vised学习模型，ResNet18，进行对比。</li>
<li>results: 结果表明，在几个尝试情况下，SSL模型可以比超级vised学习模型表现更好，但是当所有标注都用于训练时，SSL模型不能超过超级vised学习模型。这些结果表明SSL可以作为一种可靠的替代方案，可以维持任务性能而减少数据标注的时间和成本。<details>
<summary>Abstract</summary>
This study explores the application of self-supervised learning (SSL) for improved target recognition in synthetic aperture sonar (SAS) imagery. The unique challenges of underwater environments make traditional computer vision techniques, which rely heavily on optical camera imagery, less effective. SAS, with its ability to generate high-resolution imagery, emerges as a preferred choice for underwater imaging. However, the voluminous high-resolution SAS data presents a significant challenge for labeling; a crucial step for training deep neural networks (DNNs).   SSL, which enables models to learn features in data without the need for labels, is proposed as a potential solution to the data labeling challenge in SAS. The study evaluates the performance of two prominent SSL algorithms, MoCov2 and BYOL, against the well-regarded supervised learning model, ResNet18, for binary image classification tasks. The findings suggest that while both SSL models can outperform a fully supervised model with access to a small number of labels in a few-shot scenario, they do not exceed it when all the labels are used.   The results underscore the potential of SSL as a viable alternative to traditional supervised learning, capable of maintaining task performance while reducing the time and costs associated with data labeling. The study also contributes to the growing body of evidence supporting the use of SSL in remote sensing and could stimulate further research in this area.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Sample-Less-Learn-More-Efficient-Action-Recognition-via-Frame-Feature-Restoration"><a href="#Sample-Less-Learn-More-Efficient-Action-Recognition-via-Frame-Feature-Restoration" class="headerlink" title="Sample Less, Learn More: Efficient Action Recognition via Frame Feature Restoration"></a>Sample Less, Learn More: Efficient Action Recognition via Frame Feature Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14866">http://arxiv.org/abs/2307.14866</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xacheng1996/sllm">https://github.com/xacheng1996/sllm</a></li>
<li>paper_authors: Harry Cheng, Yangyang Guo, Liqiang Nie, Zhiyong Cheng, Mohan Kankanhalli</li>
<li>for: 提高视频动作识别模型的效率，特别是在有限的计算资源下。</li>
<li>methods: 提出了一种新的方法，用于修复两帧视频中的间接特征。这种方法具有较少的计算成本，但可以提高模型的效率。</li>
<li>results: 对四个公共数据集进行了广泛的实验，并证明了该方法可以提高三种常用的基线模型的效率，即使是在零基eline设定下。此外，该方法还意外地提高了模型的总体化能力。<details>
<summary>Abstract</summary>
Training an effective video action recognition model poses significant computational challenges, particularly under limited resource budgets. Current methods primarily aim to either reduce model size or utilize pre-trained models, limiting their adaptability to various backbone architectures. This paper investigates the issue of over-sampled frames, a prevalent problem in many approaches yet it has received relatively little attention. Despite the use of fewer frames being a potential solution, this approach often results in a substantial decline in performance. To address this issue, we propose a novel method to restore the intermediate features for two sparsely sampled and adjacent video frames. This feature restoration technique brings a negligible increase in computational requirements compared to resource-intensive image encoders, such as ViT. To evaluate the effectiveness of our method, we conduct extensive experiments on four public datasets, including Kinetics-400, ActivityNet, UCF-101, and HMDB-51. With the integration of our method, the efficiency of three commonly used baselines has been improved by over 50%, with a mere 0.5% reduction in recognition accuracy. In addition, our method also surprisingly helps improve the generalization ability of the models under zero-shot settings.
</details>
<details>
<summary>摘要</summary>
训练有效的视频动作识别模型具有显著的计算挑战，特别是在有限的资源预算下。现有方法主要是减小模型大小或使用预训练模型，这限制了它们的适应性于多种基础架构。本文探讨了过度采样帧的问题，这是许多方法中的一个常见问题，但它受到了相对少的注意。尽管使用 fewer frames 是一个可能的解决方案，但这经常会导致性能明显下降。为解决这个问题，我们提出了一种将两帧采样的间隔恢复原始特征的方法。这种特征恢复技术与资源占用量更高的图像编码器，如 ViT，相比较，带来了微scopic的计算增加。为评估我们的方法效果，我们在四个公共数据集上进行了广泛的实验，包括 Kinetics-400、ActivityNet、UCF-101 和 HMDB-51。与基eline integrate我们的方法后，三个常用的基eline的效率得到了50%以上的提升，而减少识别精度的幅度仅为0.5%。此外，我们的方法还意外地帮助了模型在零 shot 设定下的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="A-full-resolution-training-framework-for-Sentinel-2-image-fusion"><a href="#A-full-resolution-training-framework-for-Sentinel-2-image-fusion" class="headerlink" title="A full-resolution training framework for Sentinel-2 image fusion"></a>A full-resolution training framework for Sentinel-2 image fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14864">http://arxiv.org/abs/2307.14864</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matciotola/FR-FUSE">https://github.com/matciotola/FR-FUSE</a></li>
<li>paper_authors: Matteo Ciotola, Mario Ragosta, Giovanni Poggi, Giuseppe Scarpa</li>
<li>for: 这种研究旨在提出一种新的无监督框架，用于训练基于Sentinel-2图像的深度学习模型，以实现超分辨率图像重构。</li>
<li>methods: 该方案利用Sentinel-2图像的10米和20米频道进行融合，而不需要降解分辨率来生成训练数据。同时，提出了一种适当的损失函数，以保证网络预测结果和输入组件之间的循环一致性。</li>
<li>results: 在我们的初步实验中，该方案已经显示了与经验法相比的有力Promising results，并且由于构建的损失函数，得到的训练网络可以被归类为多分辨率分析方法。<details>
<summary>Abstract</summary>
This work presents a new unsupervised framework for training deep learning models for super-resolution of Sentinel-2 images by fusion of its 10-m and 20-m bands. The proposed scheme avoids the resolution downgrade process needed to generate training data in the supervised case. On the other hand, a proper loss that accounts for cycle-consistency between the network prediction and the input components to be fused is proposed. Despite its unsupervised nature, in our preliminary experiments the proposed scheme has shown promising results in comparison to the supervised approach. Besides, by construction of the proposed loss, the resulting trained network can be ascribed to the class of multi-resolution analysis methods.
</details>
<details>
<summary>摘要</summary>
这个工作提出了一种新的无监督框架，用于深度学习模型的超Resolution Sentinel-2图像合并。该方案避免了在生成训练数据时需要进行分辨率下降的问题。然而，提出了一种适合的损失函数，该函数考虑了网络预测和输入组件的循环一致性。 DESPITE its 无监督性，我们的初步实验表明，提出的方案在与监督方法相比 display promising results。此外，由于构造的损失函数，得到的训练网络可以被归类为多resolution分析方法。Note: Please keep in mind that Simplified Chinese is a compromise between the original Chinese characters and the Romanization of Chinese. The translation may not be exactly the same as the original text, but it should convey the same meaning.
</details></li>
</ul>
<hr>
<h2 id="IML-ViT-Benchmarking-Image-Manipulation-Localization-by-Vision-Transformer"><a href="#IML-ViT-Benchmarking-Image-Manipulation-Localization-by-Vision-Transformer" class="headerlink" title="IML-ViT: Benchmarking Image Manipulation Localization by Vision Transformer"></a>IML-ViT: Benchmarking Image Manipulation Localization by Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14863">http://arxiv.org/abs/2307.14863</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sunnyhaze/iml-vit">https://github.com/sunnyhaze/iml-vit</a></li>
<li>paper_authors: Xiaochen Ma, Bo Du, Zhuohang Jiang, Ahmed Y. Al Hammadi, Jizhe Zhou<br>for:IML-ViT is designed to capture artifacts in image manipulation localization, which is crucial for ensuring the trustworthiness of multimedia.methods:IML-ViT utilizes a ViT architecture with high-resolution capacity, multi-scale feature extraction, and manipulation edge supervision to capture artifacts. The self-attention mechanism is employed to enhance the model’s ability to extract non-semantic discrepancies between manipulated and authentic regions.results:Extensive experiments on five benchmark datasets demonstrate that IML-ViT outperforms state-of-the-art manipulation localization methods, showcasing the effectiveness of the proposed approach.<details>
<summary>Abstract</summary>
Advanced image tampering techniques are increasingly challenging the trustworthiness of multimedia, leading to the development of Image Manipulation Localization (IML). But what makes a good IML model? The answer lies in the way to capture artifacts. Exploiting artifacts requires the model to extract non-semantic discrepancies between manipulated and authentic regions, necessitating explicit comparisons between the two areas. With the self-attention mechanism, naturally, the Transformer should be a better candidate to capture artifacts. However, due to limited datasets, there is currently no pure ViT-based approach for IML to serve as a benchmark, and CNNs dominate the entire task. Nevertheless, CNNs suffer from weak long-range and non-semantic modeling. To bridge this gap, based on the fact that artifacts are sensitive to image resolution, amplified under multi-scale features, and massive at the manipulation border, we formulate the answer to the former question as building a ViT with high-resolution capacity, multi-scale feature extraction capability, and manipulation edge supervision that could converge with a small amount of data. We term this simple but effective ViT paradigm IML-ViT, which has significant potential to become a new benchmark for IML. Extensive experiments on five benchmark datasets verified our model outperforms the state-of-the-art manipulation localization methods.Code and models are available at \url{https://github.com/SunnyHaze/IML-ViT}.
</details>
<details>
<summary>摘要</summary>
现代图像修改技术正在不断挑战 multimedia 的可信度，导致图像修改地方化（IML）的发展。但是，一个好的 IML 模型又是什么样的？答案在于如何捕捉缺陷。修改图像时，需要模型从修改后和原始图像之间进行直接比较，从而捕捉非语义缺陷。自然地，Transformer 应该是更好的选择，因为它可以通过自动注意力机制来捕捉缺陷。然而，由于数据有限，目前没有纯 Vit-based 的 IML 方法作为标准，CNN 则dominate了整个任务。不过，CNN 受到语义表征的限制，无法模型长距离和非语义特征。为了填补这个差距，我们根据缺陷敏感于图像分辨率、在多个比例级中捕捉特征、和修改边缘监督来设计一个简单 yet 有效的 Vit 模型，我们称之为 IML-ViT。我们进行了五个 benchmark 数据集的广泛实验，证明我们的模型可以超越当前修改地方化方法的状态。代码和模型可以在 GitHub 上获取：https://github.com/SunnyHaze/IML-ViT。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Evaluation-of-Digital-and-Analog-Chest-Radiographs-to-Identify-Tuberculosis-using-Deep-Learning-Model"><a href="#Comparative-Evaluation-of-Digital-and-Analog-Chest-Radiographs-to-Identify-Tuberculosis-using-Deep-Learning-Model" class="headerlink" title="Comparative Evaluation of Digital and Analog Chest Radiographs to Identify Tuberculosis using Deep Learning Model"></a>Comparative Evaluation of Digital and Analog Chest Radiographs to Identify Tuberculosis using Deep Learning Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14859">http://arxiv.org/abs/2307.14859</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subhankar Chattoraj, Bhargava Reddy, Manoj Tadepalli, Preetham Putha</li>
<li>for: 这个研究用于评估基于深度学习（DL）技术的胸部X射线（CXR）识别TB病理标志的性能。</li>
<li>methods: 研究使用了10,000张胸部X射线DICOM（.dcm）数据集和打印出来的影像Films，从印度不同地点收集到的数据包括三种不同的手机：Samsung S8、iPhone 8和iPhone XS。</li>
<li>results: 研究发现，DL基于设备可以准确地识别胸部X射线中TB病理标志，AUC为0.928，sensitivity为0.841，specificity为0.806。三种手机中，最小差异为2.55%、5.10%和1.91%。这表明DL基于设备在 both digital and analog CXR 中具有良好的可靠性和灵活性。<details>
<summary>Abstract</summary>
Purpose:Chest X-ray (CXR) is an essential tool and one of the most prescribed imaging to detect pulmonary abnormalities, with a yearly estimate of over 2 billion imaging performed worldwide. However, the accurate and timely diagnosis of TB remains an unmet goal. The prevalence of TB is highest in low-middle-income countries, and the requirement of a portable, automated, and reliable solution is required. In this study, we compared the performance of DL-based devices on digital and analog CXR. The evaluated DL-based device can be used in resource-constraint settings. Methods: A total of 10,000 CXR DICOMs(.dcm) and printed photos of the films acquired with three different cellular phones - Samsung S8, iPhone 8, and iPhone XS along with their radiological report were retrospectively collected from various sites across India from April 2020 to March 2021. Results: 10,000 chest X-rays were utilized to evaluate the DL-based device in identifying radiological signs of TB. The AUC of qXR for detecting signs of tuberculosis on the original DICOMs dataset was 0.928 with a sensitivity of 0.841 at a specificity of 0.806. At an optimal threshold, the difference in the AUC of three cellular smartphones with the original DICOMs is 0.024 (2.55%), 0.048 (5.10%), and 0.038 (1.91%). The minimum difference demonstrates the robustness of the DL-based device in identifying radiological signs of TB in both digital and analog CXR.
</details>
<details>
<summary>摘要</summary>
Methods: 从2020年4月到2021年3月，我们在印度多个地点采集了10,000余个CXR DICOMs(.dcm)和印刷的胸部X射线film，其中使用了三种不同的手机：Samsung S8、iPhone 8和iPhone XS。这些影像和其相关的医学报告共同组成了我们的数据集。Results: 我们使用了10,000个胸部X射线来评估DL基于设备在诊断肺炎的 радиологических标志物上的性能。DL基于设备在原始DICOMs数据集上的AUC为0.928，sensitivity为0.841，specificity为0.806。在优化的阈值下，三种手机中的DICOMs数据集之间的AUC差异为0.024（2.55%）、0.048（5.10%）和0.038（1.91%）。这些数据表明DL基于设备在数字和分析CXR上的诊断能力具有坚定的可靠性。
</details></li>
</ul>
<hr>
<h2 id="Simplified-Concrete-Dropout-–-Improving-the-Generation-of-Attribution-Masks-for-Fine-grained-Classification"><a href="#Simplified-Concrete-Dropout-–-Improving-the-Generation-of-Attribution-Masks-for-Fine-grained-Classification" class="headerlink" title="Simplified Concrete Dropout – Improving the Generation of Attribution Masks for Fine-grained Classification"></a>Simplified Concrete Dropout – Improving the Generation of Attribution Masks for Fine-grained Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14825">http://arxiv.org/abs/2307.14825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitri Korsch, Maha Shadaydeh, Joachim Denzler</li>
<li>for: 这 paper 是为了提高 fine-grained classification 模型的准确性和可靠性而写的。</li>
<li>methods: 这 paper 使用了 perturbation-based 方法，特别是 fill-in of the dropout (FIDO) algorithm，以及一种新的 mini-batch 更新方法来提高模型的解释能力。</li>
<li>results: 这 paper 的结果表明，使用这种新方法可以减少计算复杂度，同时提高模型的解释质量和分类性能。<details>
<summary>Abstract</summary>
Fine-grained classification is a particular case of a classification problem, aiming to classify objects that share the visual appearance and can only be distinguished by subtle differences. Fine-grained classification models are often deployed to determine animal species or individuals in automated animal monitoring systems. Precise visual explanations of the model's decision are crucial to analyze systematic errors. Attention- or gradient-based methods are commonly used to identify regions in the image that contribute the most to the classification decision. These methods deliver either too coarse or too noisy explanations, unsuitable for identifying subtle visual differences reliably. However, perturbation-based methods can precisely identify pixels causally responsible for the classification result. Fill-in of the dropout (FIDO) algorithm is one of those methods. It utilizes the concrete dropout (CD) to sample a set of attribution masks and updates the sampling parameters based on the output of the classification model. A known problem of the algorithm is a high variance in the gradient estimates, which the authors have mitigated until now by mini-batch updates of the sampling parameters. This paper presents a solution to circumvent these computational instabilities by simplifying the CD sampling and reducing reliance on large mini-batch sizes. First, it allows estimating the parameters with smaller mini-batch sizes without losing the quality of the estimates but with a reduced computational effort. Furthermore, our solution produces finer and more coherent attribution masks. Finally, we use the resulting attribution masks to improve the classification performance of a trained model without additional fine-tuning of the model.
</details>
<details>
<summary>摘要</summary>
细化分类是特殊的分类问题，旨在分类具有相似视觉特征的对象，只能通过微不足的差异来区分。细化分类模型常用于自动动物监测系统中确定动物种或个体。精准的视觉解释是分析系统错误的关键。通常使用注意力或梯度基本方法来确定图像中占据分类决策的区域。然而，这些方法可能提供过于粗糙或噪音的解释，不适合确定微不足的视觉差异。在这些情况下，杂化基本方法可以准确地确定图像中占据分类决策的像素。填充掉dropout（FIDO）算法是其中的一种方法。它利用具体的dropout（CD）来采样一组属性面积，然后基于分类模型的输出更新采样参数。然而，这个算法存在高度变化的梯度估计问题，作者通过小批处理参数进行了缓解。这篇论文提出了一种解决方案，利用更小的批处理大小来避免计算不稳定性，同时保持估计质量不受影响。此外，我们的解决方案生成了更细致和更凝聚的属性面积，最终用这些面积提高已经训练的模型的分类性能。
</details></li>
</ul>
<hr>
<h2 id="Building-RadiologyNET-Unsupervised-annotation-of-a-large-scale-multimodal-medical-database"><a href="#Building-RadiologyNET-Unsupervised-annotation-of-a-large-scale-multimodal-medical-database" class="headerlink" title="Building RadiologyNET: Unsupervised annotation of a large-scale multimodal medical database"></a>Building RadiologyNET: Unsupervised annotation of a large-scale multimodal medical database</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08517">http://arxiv.org/abs/2308.08517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mateja Napravnik, Franko Hržić, Sebastian Tschauner, Ivan Štajduhar</li>
<li>for: 这个论文的目的是构建一个大规模的医疗图像自动标注集合。</li>
<li>methods: 该论文使用了一种自动化、无监督的方法，使用多Modal sources，包括图像、DICOM元数据和描述性诊断，并测试了多种适当的特征提取器，以确定最佳的特征提取器。</li>
<li>results: 研究人员使用了优选的特征提取器进行多Modal表示，并使用k-means和k-medoids归一 clustering算法对一个代表样本 subset进行评估。结果表明，将所有数据源的嵌入都 fusion起来最好地进行无监督归一 clustering任务，并且得到了最紧凑的归一结果。<details>
<summary>Abstract</summary>
Background and objective: The usage of machine learning in medical diagnosis and treatment has witnessed significant growth in recent years through the development of computer-aided diagnosis systems that are often relying on annotated medical radiology images. However, the availability of large annotated image datasets remains a major obstacle since the process of annotation is time-consuming and costly. This paper explores how to automatically annotate a database of medical radiology images with regard to their semantic similarity.   Material and methods: An automated, unsupervised approach is used to construct a large annotated dataset of medical radiology images originating from Clinical Hospital Centre Rijeka, Croatia, utilising multimodal sources, including images, DICOM metadata, and narrative diagnoses. Several appropriate feature extractors are tested for each of the data sources, and their utility is evaluated using k-means and k-medoids clustering on a representative data subset.   Results: The optimal feature extractors are then integrated into a multimodal representation, which is then clustered to create an automated pipeline for labelling a precursor dataset of 1,337,926 medical images into 50 clusters of visually similar images. The quality of the clusters is assessed by examining their homogeneity and mutual information, taking into account the anatomical region and modality representation.   Conclusion: The results suggest that fusing the embeddings of all three data sources together works best for the task of unsupervised clustering of large-scale medical data, resulting in the most concise clusters. Hence, this work is the first step towards building a much larger and more fine-grained annotated dataset of medical radiology images.
</details>
<details>
<summary>摘要</summary>
背景和目标：随着医疗领域中机器学习的应用不断扩展，计算机辅助诊断系统在医疗领域中的应用也得到了广泛的应用。然而，大量标注的医疗影像数据集的可用性仍然是一个主要的障碍因素，因为标注过程是时间consuming和成本高昂的。这篇论文探讨了如何自动标注医疗影像数据库中的semantic similarity。材料和方法：我们使用自动化、无监督的方法构建了一个大量标注的医疗影像数据库，来自克罗地亚维也纳医院中心医院，包括多Modal sources，包括影像、DICOM元数据和描述诊断。我们测试了多个适当的特征提取器，并对其在表示subset中进行了评估，使用k-means和k-medoids归一 clustering。结果：我们选择最佳的特征提取器，并将其集成到多modal表示中，然后使用k-means和k-medoids归一 clustering来自动标注一个预处理数据集中的1,337,926个医疗影像，并创建50个视觉相似的集群。我们评估了这些集群的一致性和相互信息，考虑到了解剖区域和模式表示。结论：结果表明，将所有三种数据源的嵌入统一为一起最好用于不supervised clustering的任务，得到了最短的集群。因此，这种工作是建立一个更大和更细化的医疗影像数据库的第一步。
</details></li>
</ul>
<hr>
<h2 id="Fading-memory-as-inductive-bias-in-residual-recurrent-networks"><a href="#Fading-memory-as-inductive-bias-in-residual-recurrent-networks" class="headerlink" title="Fading memory as inductive bias in residual recurrent networks"></a>Fading memory as inductive bias in residual recurrent networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14823">http://arxiv.org/abs/2307.14823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Igor Dubinin, Felix Effenberger</li>
<li>for: 这个论文旨在研究异常连接在RNN中的影响，以及它们如何影响网络的性能、动态和记忆特性。</li>
<li>methods: 作者提出了弱相互连接循环网络（WCRNN），并研究了不同类型的异常连接对网络表现的影响。</li>
<li>results: 研究发现，不同类型的异常连接可以提供不同的 inductive bias，从而提高网络的表达力。具体来说，异常连接可以使网络的动态靠近边缘的混沌边缘，使网络可以充分利用数据的特征性质，并且可以提高网络的记忆特性。此外，作者还展示了如何将这些结果推广到非线性异常连接和Elman RNN中。<details>
<summary>Abstract</summary>
Residual connections have been proposed as architecture-based inductive bias to mitigate the problem of exploding and vanishing gradients and increase task performance in both feed-forward and recurrent networks (RNNs) when trained with the backpropagation algorithm. Yet, little is known about how residual connections in RNNs influence their dynamics and fading memory properties. Here, we introduce weakly coupled residual recurrent networks (WCRNNs) in which residual connections result in well-defined Lyapunov exponents and allow for studying properties of fading memory. We investigate how the residual connections of WCRNNs influence their performance, network dynamics, and memory properties on a set of benchmark tasks. We show that several distinct forms of residual connections yield effective inductive biases that result in increased network expressivity. In particular, residual connections that (i) result in network dynamics at the proximity of the edge of chaos, (ii) allow networks to capitalize on characteristic spectral properties of the data, and (iii) result in heterogeneous memory properties are shown to increase practical expressivity. In addition, we demonstrate how our results can be extended to non-linear residuals and introduce a weakly coupled residual initialization scheme that can be used for Elman RNNs
</details>
<details>
<summary>摘要</summary>
剩余连接已被提议作为网络架构基于束缚的偏好，以降低迁移和消失梯度的问题，提高反propagation算法下的任务性能。然而，关于剩余连接在RNN中的动态和渐幻性质仍未得到了充分的了解。在这里，我们引入了弱相互连接的剩余循环网络（WCRNN），其中剩余连接导致明确的Lyapunov exponent，使得研究RNN的动态和渐幻性质变得可能。我们研究了WCRNN的剩余连接如何影响其性能、网络动态和记忆特性，并证明了不同形式的剩余连接可以提供有效的束缚偏好，从而增加网络的表达能力。具体来说，剩余连接可以：（i）导致网络动态在数据特征附近，（ii）让网络利用数据的特征波动性，（iii）导致异ogeneous记忆特性，这些特性可以提高实际的表达能力。此外，我们还展示了我们的结果可以扩展到非线性剩余，并引入了弱相互连接初始化方案，可以应用于Elman RNN。
</details></li>
</ul>
<hr>
<h2 id="Towards-Deeply-Unified-Depth-aware-Panoptic-Segmentation-with-Bi-directional-Guidance-Learning"><a href="#Towards-Deeply-Unified-Depth-aware-Panoptic-Segmentation-with-Bi-directional-Guidance-Learning" class="headerlink" title="Towards Deeply Unified Depth-aware Panoptic Segmentation with Bi-directional Guidance Learning"></a>Towards Deeply Unified Depth-aware Panoptic Segmentation with Bi-directional Guidance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14786">http://arxiv.org/abs/2307.14786</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jwh97nn/DeepDPS">https://github.com/jwh97nn/DeepDPS</a></li>
<li>paper_authors: Junwen He, Yifan Wang, Lijun Wang, Huchuan Lu, Jun-Yan He, Jin-Peng Lan, Bin Luo, Yifeng Geng, Xuansong Xie</li>
<li>for: depth-aware panoptic segmentation, 提高Scene理解的robustness</li>
<li>methods: joint segmentation and depth estimation, 同时在每个 segment 中进行semantic segmentation和深度估计，并使用嵌入表示来整合场景几何信息</li>
<li>results: sets the new state of the art, 在Cityscapes-DVPS和SemKITTI-DVPS数据集上达到了新的state of the artHere’s the full translation of the abstract in Simplified Chinese: depth-aware panoptic segmentation是计算机视觉领域的一个新兴话题，它旨在结合semantic和几何理解来更加robust的Scene理解。 current works 通常将这两个任务看作为两个独立的学习任务，这限制了其探索跨领域信息的潜力。我们提出了一个深度嵌入的框架，用于depth-aware panoptic segmentation，它在每个 segment 中同时进行semantic segmentation和深度估计，并使用嵌入表示来整合场景几何信息。此外，我们还提出了一种bi-directional guidance learning方法，可以利用这两个任务之间的相互关系来促进cross-task feature learning。我们的方法在Cityscapes-DVPS和SemKITTI-DVPS数据集上达到了新的state of the art，并且我们的引导学习方法在不完全监督标签下也能够实现性能提升。<details>
<summary>Abstract</summary>
Depth-aware panoptic segmentation is an emerging topic in computer vision which combines semantic and geometric understanding for more robust scene interpretation. Recent works pursue unified frameworks to tackle this challenge but mostly still treat it as two individual learning tasks, which limits their potential for exploring cross-domain information. We propose a deeply unified framework for depth-aware panoptic segmentation, which performs joint segmentation and depth estimation both in a per-segment manner with identical object queries. To narrow the gap between the two tasks, we further design a geometric query enhancement method, which is able to integrate scene geometry into object queries using latent representations. In addition, we propose a bi-directional guidance learning approach to facilitate cross-task feature learning by taking advantage of their mutual relations. Our method sets the new state of the art for depth-aware panoptic segmentation on both Cityscapes-DVPS and SemKITTI-DVPS datasets. Moreover, our guidance learning approach is shown to deliver performance improvement even under incomplete supervision labels.
</details>
<details>
<summary>摘要</summary>
depth-aware panoptic segmentation 是计算机视觉领域的一个emerging topic，它结合semantic和geometric的理解，以提高场景的理解度。  recent works 尝试开发一个unified framework来解决这个挑战，但大多数仍然视为两个不同的学习任务，这限制了其探索交叉领域信息的潜力。我们提出了一个深度统一的 framework  для depth-aware panoptic segmentation，它在每个分割个体上同时进行分割和深度估计，并使用 identical object queries 来进行joint segmentation和depth estimation。为了降低这两个任务之间的差距，我们还设计了一种geometry query enhancement method，可以将场景几何信息 интеGRATE INTO object queries 中，使用latent representations。此外，我们还提出了一种bi-directional guidance learning Approach，可以在两个任务之间互相帮助学习特征，通过它们之间的相互关系来提高性能。我们的方法在Cityscapes-DVPS和SemKITTI-DVPS dataset上设置了新的state of the art，而且我们的导航学习方法在不完全supervision标签的情况下也能提供性能提升。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Knowledge-Amalgamation-for-Unsupervised-Image-Classification"><a href="#Contrastive-Knowledge-Amalgamation-for-Unsupervised-Image-Classification" class="headerlink" title="Contrastive Knowledge Amalgamation for Unsupervised Image Classification"></a>Contrastive Knowledge Amalgamation for Unsupervised Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14781">http://arxiv.org/abs/2307.14781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shangde Gao, Yichao Fu, Ke Liu, Yuqiang Han</li>
<li>for: 学习一个紧凑的学生模型，处理多个特有任务的教师模型的共同目标。</li>
<li>methods: 引入对比损失和对齐损失，实现类内凝聚和类间分离，同时通过软目标efficiently和flexibly进行多任务无监控学习。</li>
<li>results: 在多个benchmark上示出了总化能力，并通过了广泛的ablation study提供了更深入的理解。<details>
<summary>Abstract</summary>
Knowledge amalgamation (KA) aims to learn a compact student model to handle the joint objective from multiple teacher models that are are specialized for their own tasks respectively. Current methods focus on coarsely aligning teachers and students in the common representation space, making it difficult for the student to learn the proper decision boundaries from a set of heterogeneous teachers. Besides, the KL divergence in previous works only minimizes the probability distribution difference between teachers and the student, ignoring the intrinsic characteristics of teachers. Therefore, we propose a novel Contrastive Knowledge Amalgamation (CKA) framework, which introduces contrastive losses and an alignment loss to achieve intra-class cohesion and inter-class separation.Contrastive losses intra- and inter- models are designed to widen the distance between representations of different classes. The alignment loss is introduced to minimize the sample-level distribution differences of teacher-student models in the common representation space.Furthermore, the student learns heterogeneous unsupervised classification tasks through soft targets efficiently and flexibly in the task-level amalgamation. Extensive experiments on benchmarks demonstrate the generalization capability of CKA in the amalgamation of specific task as well as multiple tasks. Comprehensive ablation studies provide a further insight into our CKA.
</details>
<details>
<summary>摘要</summary>
知识混合（KA）目标是学习一个紧凑的学生模型，以处理多个特циализирован任务的教师模型共同目标。现有方法主要是粗略对教师和学生在共同 Representation Space 进行对齐，使学生从多种不同任务的教师中学习到正确的决策边界很难。此外，前一些方法只是减小了教师和学生的概率分布差异，忽略了教师的内在特征。因此，我们提出了一种新的对比知识混合（CKA）框架，该框架引入对比损失和对齐损失，以实现类内凝聚和类间分离。对比损失可以把不同类型的表示之间的距离扩大，对齐损失可以在共同 Representation Space 中减少教师-学生模型的样本级分布差异。此外，学生通过软目标在任务级混合中学习多种不同任务，高效和灵活地完成不同任务的无监督分类任务。广泛的实验和综合性的减少研究表明CKA在特定任务和多任务混合中具有普遍性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="pCTFusion-Point-Convolution-Transformer-Fusion-with-Semantic-Aware-Loss-for-Outdoor-LiDAR-Point-Cloud-Segmentation"><a href="#pCTFusion-Point-Convolution-Transformer-Fusion-with-Semantic-Aware-Loss-for-Outdoor-LiDAR-Point-Cloud-Segmentation" class="headerlink" title="pCTFusion: Point Convolution-Transformer Fusion with Semantic Aware Loss for Outdoor LiDAR Point Cloud Segmentation"></a>pCTFusion: Point Convolution-Transformer Fusion with Semantic Aware Loss for Outdoor LiDAR Point Cloud Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14777">http://arxiv.org/abs/2307.14777</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GeoAI-Research-Lab/PCTFusion">https://github.com/GeoAI-Research-Lab/PCTFusion</a></li>
<li>paper_authors: Abhishek Kuriyal, Vaibhav Kumar, Bharat Lohani</li>
<li>for: 本研究旨在提高LiDAR点云semantic segmentation的性能，特别是对于少数类和边缘点的识别。</li>
<li>methods: 本研究提出了一种新的架构，即pCTFusion，它结合了kernel-based卷积和自注意机制，以提高特征学习和捕捉点云中的本地和全局依赖关系。</li>
<li>results: 对SemanticKITTI户外数据集进行评估，pCTFusion架构与当前状态艺术结构相比，提高了5-7%的性能。特别是对于少数类，性能提高尤为明显，这些发展的方法可以应用于复杂的点云数据集，并促进实际应用。<details>
<summary>Abstract</summary>
LiDAR-generated point clouds are crucial for perceiving outdoor environments. The segmentation of point clouds is also essential for many applications. Previous research has focused on using self-attention and convolution (local attention) mechanisms individually in semantic segmentation architectures. However, there is limited work on combining the learned representations of these attention mechanisms to improve performance. Additionally, existing research that combines convolution with self-attention relies on global attention, which is not practical for processing large point clouds. To address these challenges, this study proposes a new architecture, pCTFusion, which combines kernel-based convolutions and self-attention mechanisms for better feature learning and capturing local and global dependencies in segmentation. The proposed architecture employs two types of self-attention mechanisms, local and global, based on the hierarchical positions of the encoder blocks. Furthermore, the existing loss functions do not consider the semantic and position-wise importance of the points, resulting in reduced accuracy, particularly at sharp class boundaries. To overcome this, the study models a novel attention-based loss function called Pointwise Geometric Anisotropy (PGA), which assigns weights based on the semantic distribution of points in a neighborhood. The proposed architecture is evaluated on SemanticKITTI outdoor dataset and showed a 5-7% improvement in performance compared to the state-of-the-art architectures. The results are particularly encouraging for minor classes, often misclassified due to class imbalance, lack of space, and neighbor-aware feature encoding. These developed methods can be leveraged for the segmentation of complex datasets and can drive real-world applications of LiDAR point cloud.
</details>
<details>
<summary>摘要</summary>
利用LiDAR生成的点云是外部环境的感知的关键。点云分割也是许多应用程序的必需之物。先前的研究主要集中在使用自注意力和卷积（本地注意力）机制来进行semantic segmentation。然而，有限的研究集中在将这些注意力机制学习的表示结合以提高性能。此外，现有的混合卷积和自注意力的研究都是基于全局注意力，不适合处理大量的点云。为解决这些挑战，本研究提出了一种新的架构，即pCTFusion，它结合均匀卷积和自注意力机制来提高特征学习和捕捉点云中的本地和全局依赖关系。该架构使用了两种类型的自注意力机制，即本地自注意力和全局自注意力，基于嵌入块的层次位置。此外，现有的损失函数不考虑点云中的 semantic和位置含义，导致准确性下降，特别是在精准的分类边界。为此，本研究提出了一种新的注意力基于损失函数，即点云几何各向异性（PGA），它根据点云的semantic分布在邻域分配权重。该提案的架构在SemanticKITTI外部 dataset上进行评估，与当前领先的架构相比，提高了5-7%的性能。结果特别有吸引力，尤其是对于少数类，通常因为分类不均衡、空间约束和邻居相关特征编码而导致的误分类。这些开发的方法可以应用于复杂的点云分割任务，并促进实际应用 LiDAR 点云。
</details></li>
</ul>
<hr>
<h2 id="3DPortraitGAN-Learning-One-Quarter-Headshot-3D-GANs-from-a-Single-View-Portrait-Dataset-with-Diverse-Body-Poses"><a href="#3DPortraitGAN-Learning-One-Quarter-Headshot-3D-GANs-from-a-Single-View-Portrait-Dataset-with-Diverse-Body-Poses" class="headerlink" title="3DPortraitGAN: Learning One-Quarter Headshot 3D GANs from a Single-View Portrait Dataset with Diverse Body Poses"></a>3DPortraitGAN: Learning One-Quarter Headshot 3D GANs from a Single-View Portrait Dataset with Diverse Body Poses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14770">http://arxiv.org/abs/2307.14770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oneThousand1000/3DPortraitGAN">https://github.com/oneThousand1000/3DPortraitGAN</a></li>
<li>paper_authors: Yiqian Wu, Hao Xu, Xiangjun Tang, Hongbo Fu, Xiaogang Jin</li>
<li>for: 实现一个可以从所有镜头角度产生完整的头部、脖子和肩膀 geometry 的一个四分之一头shot 3D 肖像。</li>
<li>methods: 使用 360°PHQ 数据集，并提出了一个名为 3DPortraitGAN 的新型一个四分之一头shot 3D 肖像生成器，可以从所有镜头角度产生可观的、具有完整的头部、脖子和肩膀 geometry 的肖像。</li>
<li>results: 经过实验显示，提出的框架可以很好地预测肖像的姿势和产生具有可观的、具有完整的头部、脖子和肩膀 geometry 的肖像。<details>
<summary>Abstract</summary>
3D-aware face generators are typically trained on 2D real-life face image datasets that primarily consist of near-frontal face data, and as such, they are unable to construct one-quarter headshot 3D portraits with complete head, neck, and shoulder geometry. Two reasons account for this issue: First, existing facial recognition methods struggle with extracting facial data captured from large camera angles or back views. Second, it is challenging to learn a distribution of 3D portraits covering the one-quarter headshot region from single-view data due to significant geometric deformation caused by diverse body poses. To this end, we first create the dataset 360{\deg}-Portrait-HQ (360{\deg}PHQ for short) which consists of high-quality single-view real portraits annotated with a variety of camera parameters (the yaw angles span the entire 360{\deg} range) and body poses. We then propose 3DPortraitGAN, the first 3D-aware one-quarter headshot portrait generator that learns a canonical 3D avatar distribution from the 360{\deg}PHQ dataset with body pose self-learning. Our model can generate view-consistent portrait images from all camera angles with a canonical one-quarter headshot 3D representation. Our experiments show that the proposed framework can accurately predict portrait body poses and generate view-consistent, realistic portrait images with complete geometry from all camera angles.
</details>
<details>
<summary>摘要</summary>
三维意识的脸部生成器通常在二维实际脸部图像集上训练，这些集合主要由近 фронталь脸部数据组成，因此它们无法构建完整的一半头shot三维肖像。这个问题的两个原因是：首先，现有的人脸识别方法在大角度摄像头数据中提取脸部数据很困难；其次，学习一个包括一半头shot区域的三维肖像分布从单视数据上是很困难的，因为人体姿势的多样性导致了重大的几何变换。为解决这个问题，我们首先创建了360°PHQ数据集（简称为360°PHQ），该集合包含高质量的单视实际肖像，以及不同的摄像头parameters（摄像头方向的角度覆盖了整个360°范围）和人体姿势。然后，我们提出了3DPortraitGAN模型，这是第一个能够学习一个完整的三维肖像分布的一半头shot脸部生成器。我们的模型可以从所有摄像头角度生成视角一致的肖像图像，并且可以准确预测肖像图像中的人体姿势。我们的实验表明，我们的框架可以生成视角一致、真实、完整的肖像图像，并且可以准确预测肖像图像中的人体姿势。
</details></li>
</ul>
<hr>
<h2 id="Gloss-free-Sign-Language-Translation-Improving-from-Visual-Language-Pretraining"><a href="#Gloss-free-Sign-Language-Translation-Improving-from-Visual-Language-Pretraining" class="headerlink" title="Gloss-free Sign Language Translation: Improving from Visual-Language Pretraining"></a>Gloss-free Sign Language Translation: Improving from Visual-Language Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14768">http://arxiv.org/abs/2307.14768</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhoubenjia/gfslt-vlp">https://github.com/zhoubenjia/gfslt-vlp</a></li>
<li>paper_authors: Benjia Zhou, Zhigang Chen, Albert Clapés, Jun Wan, Yanyan Liang, Sergio Escalera, Zhen Lei, Du Zhang</li>
<li>For:  This paper aims to improve the task of sign language translation (SLT) by addressing the challenge of using an intermediate representation, such as gloss sequences, which can hinder the development of SLT.* Methods: The proposed method, called Gloss-Free SLT based on Visual-Language Pretraining (GFSLT-VLP), uses a novel approach that inherits language-oriented prior knowledge from pre-trained models without any gloss annotation assistance. The approach involves two stages: (i) integrating Contrastive Language-Image Pre-training (CLIP) with masked self-supervised learning to create pre-tasks that bridge the semantic gap between visual and textual representations and restore masked sentences, and (ii) constructing an end-to-end architecture with an encoder-decoder-like structure that inherits the parameters of the pre-trained Visual Encoder and Text Decoder from the first stage.* Results: The proposed method achieves unprecedented improvements in terms of BLEU-4 score on the PHOENIX14T dataset (&gt;+5) and the CSL-Daily dataset (&gt;+3) compared to state-of-the-art gloss-free SLT methods. Additionally, the approach achieves competitive results on the PHOENIX14T dataset when compared with most of the gloss-based methods.<details>
<summary>Abstract</summary>
Sign Language Translation (SLT) is a challenging task due to its cross-domain nature, involving the translation of visual-gestural language to text. Many previous methods employ an intermediate representation, i.e., gloss sequences, to facilitate SLT, thus transforming it into a two-stage task of sign language recognition (SLR) followed by sign language translation (SLT). However, the scarcity of gloss-annotated sign language data, combined with the information bottleneck in the mid-level gloss representation, has hindered the further development of the SLT task. To address this challenge, we propose a novel Gloss-Free SLT based on Visual-Language Pretraining (GFSLT-VLP), which improves SLT by inheriting language-oriented prior knowledge from pre-trained models, without any gloss annotation assistance. Our approach involves two stages: (i) integrating Contrastive Language-Image Pre-training (CLIP) with masked self-supervised learning to create pre-tasks that bridge the semantic gap between visual and textual representations and restore masked sentences, and (ii) constructing an end-to-end architecture with an encoder-decoder-like structure that inherits the parameters of the pre-trained Visual Encoder and Text Decoder from the first stage. The seamless combination of these novel designs forms a robust sign language representation and significantly improves gloss-free sign language translation. In particular, we have achieved unprecedented improvements in terms of BLEU-4 score on the PHOENIX14T dataset (>+5) and the CSL-Daily dataset (>+3) compared to state-of-the-art gloss-free SLT methods. Furthermore, our approach also achieves competitive results on the PHOENIX14T dataset when compared with most of the gloss-based methods. Our code is available at https://github.com/zhoubenjia/GFSLT-VLP.
</details>
<details>
<summary>摘要</summary>
Sign Language Translation (SLT) 是一个复杂的任务，因为它涉及视觉姿势语言的翻译，从视觉语言到文本。许多前一代方法使用中间表示，即荣誉序列，以便进行 SLT，因此将其转化为一个两阶段任务：首先使用 SLR 进行视觉语言识别，然后使用 SLT 进行翻译。但是，缺乏荣誉注解的手语数据，加之中间表示缺乏信息的瓶颈，使得 SLT 任务的进一步发展受阻。为解决这个挑战，我们提出了一种新的无荣誉 SLT，基于视觉语言预training（GFSLT-VLP），它通过继承预训练模型中的语言相关知识，而不需要荣誉注解，提高了 SLT 的性能。我们的方法包括两个阶段：1. 将 Contrastive Language-Image Pre-training（CLIP）与遮盖自我监督学习相结合，以创建预 зада务， bridge 视觉和文本表示之间的 semantic gap，并 restore 遮盖句子。2. 使用 encoder-decoder 结构， inherited 预训练 Visual Encoder 和 Text Decoder 的参数，以构建一个端到端的结构。这种新的设计结合，形成了一种robust的手语表示，并有效地提高了无荣誉手语翻译。具体来说，我们在 PHOENIX14T 数据集上 achieved 未曾有过的改进（BLEU-4 分数 > +5）和 CSL-Daily 数据集上 achieved 比较出色的改进（BLEU-4 分数 > +3），相比之下，state-of-the-art 无荣誉 SLT 方法。此外，我们的方法还在 PHOENIX14T 数据集上与大多数荣誉基于方法相比，达到了竞争的结果。我们的代码可以在 <https://github.com/zhoubenjia/GFSLT-VLP> 上找到。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Image-Completion-and-Enhancement-using-GANs"><a href="#Semantic-Image-Completion-and-Enhancement-using-GANs" class="headerlink" title="Semantic Image Completion and Enhancement using GANs"></a>Semantic Image Completion and Enhancement using GANs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14748">http://arxiv.org/abs/2307.14748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Priyansh Saxena, Raahat Gupta, Akshat Maheshwari, Saumil Maheshwari</li>
<li>for: 这篇论文主要是为了完善图像的完成和增强任务。</li>
<li>methods: 该论文使用了生成对抗网络（GAN）来实现图像完成任务。</li>
<li>results: GAN可以帮助完善图像的完成和增强任务，提高图像的质量。Here’s the full text in Simplified Chinese:</li>
<li>for: 这篇论文主要是为了完善图像的完成和增强任务。</li>
<li>methods: 该论文使用了生成对抗网络（GAN）来实现图像完成任务。</li>
<li>results: GAN可以帮助完善图像的完成和增强任务，提高图像的质量。<details>
<summary>Abstract</summary>
Semantic inpainting or image completion alludes to the task of inferring arbitrary large missing regions in images based on image semantics. Since the prediction of image pixels requires an indication of high-level context, this makes it significantly tougher than image completion, which is often more concerned with correcting data corruption and removing entire objects from the input image. On the other hand, image enhancement attempts to eliminate unwanted noise and blur from the image, along with sustaining most of the image details. Efficient image completion and enhancement model should be able to recover the corrupted and masked regions in images and then refine the image further to increase the quality of the output image. Generative Adversarial Networks (GAN), have turned out to be helpful in picture completion tasks. In this chapter, we will discuss the underlying GAN architecture and how they can be used used for image completion tasks.
</details>
<details>
<summary>摘要</summary>
Semantic inpainting or image completion refers to the task of inferring large missing regions in images based on image semantics. Since the prediction of image pixels requires high-level context, this makes it significantly more challenging than image completion, which is often focused on correcting data corruption and removing objects from the input image. On the other hand, image enhancement aims to eliminate unwanted noise and blur from the image while preserving most of the image details. An efficient image completion and enhancement model should be able to recover the corrupted and masked regions in images and then refine the image to improve its quality. Generative Adversarial Networks (GAN) have proven to be helpful in picture completion tasks, and we will discuss their underlying architecture and how they can be used for image completion tasks in this chapter.
</details></li>
</ul>
<hr>
<h2 id="Test-Time-Adaptation-for-Blind-Image-Quality-Assessment"><a href="#Test-Time-Adaptation-for-Blind-Image-Quality-Assessment" class="headerlink" title="Test Time Adaptation for Blind Image Quality Assessment"></a>Test Time Adaptation for Blind Image Quality Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14735">http://arxiv.org/abs/2307.14735</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shankhanil006/tta-iqa">https://github.com/shankhanil006/tta-iqa</a></li>
<li>paper_authors: Subhadeep Roy, Shankhanil Mitra, Soma Biswas, Rajiv Soundararajan</li>
<li>for: 提高隐身图像质量评估（IQA）算法在推理时的性能，由于训练和测试场景之间的分布偏移导致现有算法在测试时表现不佳。</li>
<li>methods: 采用两种新的质量相关的 auxillary task，一个是批处理级别的群集比较损失，另一个是样本级别的相对排名损失，使模型具有质量意识并适应目标数据。</li>
<li>results: 通过更新源模型的批处理常数，可以在小批量测试数据上 Achieve 显著改善的性能。<details>
<summary>Abstract</summary>
While the design of blind image quality assessment (IQA) algorithms has improved significantly, the distribution shift between the training and testing scenarios often leads to a poor performance of these methods at inference time. This motivates the study of test time adaptation (TTA) techniques to improve their performance at inference time. Existing auxiliary tasks and loss functions used for TTA may not be relevant for quality-aware adaptation of the pre-trained model. In this work, we introduce two novel quality-relevant auxiliary tasks at the batch and sample levels to enable TTA for blind IQA. In particular, we introduce a group contrastive loss at the batch level and a relative rank loss at the sample level to make the model quality aware and adapt to the target data. Our experiments reveal that even using a small batch of images from the test distribution helps achieve significant improvement in performance by updating the batch normalization statistics of the source model.
</details>
<details>
<summary>摘要</summary>
而网络设计的盲图像质量评估（IQA）算法的设计已经得到了显著改进，但在推理时间段的分布偏移通常会导致这些方法在推理时的性能不佳。这种情况 Motivates the study of test time adaptation（TTA）技术以提高其推理时间段的性能。现有的辅助任务和损失函数可能不适用于盲图像质量认知的适应。在这种工作中，我们介绍了两个新的质量相关的辅助任务，即批处理级别的群体对照损失和样本级别的相对排名损失，以使模型具备质量认知并适应目标数据。我们的实验表明，即使使用小批处理数据来源，也可以通过更新源模型的批处理常量来实现显著的性能改进。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Silent-Failures-in-Medical-Image-Classification"><a href="#Understanding-Silent-Failures-in-Medical-Image-Classification" class="headerlink" title="Understanding Silent Failures in Medical Image Classification"></a>Understanding Silent Failures in Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14729">http://arxiv.org/abs/2307.14729</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iml-dkfz/sf-visuals">https://github.com/iml-dkfz/sf-visuals</a></li>
<li>paper_authors: Till J. Bungert, Levin Kobelke, Paul F. Jaeger</li>
<li>for: 防止静止失败在医疗应用中ensure reliable use of classification systems</li>
<li>methods: 使用 confidence scoring functions (CSFs) 或设计更加可靠的分类器</li>
<li>results: None of the benchmarked CSFs can reliably prevent silent failures, deeper understanding of the root causes of failures in the data is required. Introduce SF-Visuals, an interactive analysis tool to visualize shifts and failures.<details>
<summary>Abstract</summary>
To ensure the reliable use of classification systems in medical applications, it is crucial to prevent silent failures. This can be achieved by either designing classifiers that are robust enough to avoid failures in the first place, or by detecting remaining failures using confidence scoring functions (CSFs). A predominant source of failures in image classification is distribution shifts between training data and deployment data. To understand the current state of silent failure prevention in medical imaging, we conduct the first comprehensive analysis comparing various CSFs in four biomedical tasks and a diverse range of distribution shifts. Based on the result that none of the benchmarked CSFs can reliably prevent silent failures, we conclude that a deeper understanding of the root causes of failures in the data is required. To facilitate this, we introduce SF-Visuals, an interactive analysis tool that uses latent space clustering to visualize shifts and failures. On the basis of various examples, we demonstrate how this tool can help researchers gain insight into the requirements for safe application of classification systems in the medical domain. The open-source benchmark and tool are at: https://github.com/IML-DKFZ/sf-visuals.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)为确保医疗应用中的分类系统可靠使用，防止潜在的失败是非常重要。这可以通过设计更加鲁棒的分类器，或者通过使用信任分数函数（CSF）来检测剩下的失败来实现。图像分类中最主要的失败来源是在训练数据和部署数据之间的分布变化。为了了解医疗领域中 silent failure 预防的当前状况，我们进行了第一次全面的比较多种 CSF 在四种生物医学任务和多样的分布变化下的性能分析。结果显示， none of the benchmarked CSFs 可靠地预防潜在的失败。我们 conclude 需要更深入地理解数据中的失败根据因素，以便在医疗领域中安全地应用分类系统。为此，我们介绍 SF-Visuals，一种可互动地分析工具，使用隐藏空间划分来视觉化偏移和失败。通过多个示例，我们示出了这个工具可以帮助研究人员更好地理解医疗领域中分类系统的应用需求。该开源 benchmark 和工具可以在 GitHub 上找到：https://github.com/IML-DKFZ/sf-visuals.
</details></li>
</ul>
<hr>
<h2 id="P2C-Self-Supervised-Point-Cloud-Completion-from-Single-Partial-Clouds"><a href="#P2C-Self-Supervised-Point-Cloud-Completion-from-Single-Partial-Clouds" class="headerlink" title="P2C: Self-Supervised Point Cloud Completion from Single Partial Clouds"></a>P2C: Self-Supervised Point Cloud Completion from Single Partial Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14726">http://arxiv.org/abs/2307.14726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cuiruikai/partial2complete">https://github.com/cuiruikai/partial2complete</a></li>
<li>paper_authors: Ruikai Cui, Shi Qiu, Saeed Anwar, Jiawei Liu, Chaoyue Xing, Jing Zhang, Nick Barnes</li>
<li>for: 本研究旨在完成基于部分观察的点云ShapeNet数据集中的物体形状。</li>
<li>methods: 我们提出了一种自动学习的方法，称为Partial2Complete（P2C），它使用单个不完整的点云训练样本来完成物体的形状。</li>
<li>results: P2C可以与使用完整的点云训练样本相比，并且在使用多个部分观察样本训练的方法上表现更好。 Code可以在<a target="_blank" rel="noopener" href="https://github.com/CuiRuikai/Partial2Complete%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/CuiRuikai/Partial2Complete中找到。</a><details>
<summary>Abstract</summary>
Point cloud completion aims to recover the complete shape based on a partial observation. Existing methods require either complete point clouds or multiple partial observations of the same object for learning. In contrast to previous approaches, we present Partial2Complete (P2C), the first self-supervised framework that completes point cloud objects using training samples consisting of only a single incomplete point cloud per object. Specifically, our framework groups incomplete point clouds into local patches as input and predicts masked patches by learning prior information from different partial objects. We also propose Region-Aware Chamfer Distance to regularize shape mismatch without limiting completion capability, and devise the Normal Consistency Constraint to incorporate a local planarity assumption, encouraging the recovered shape surface to be continuous and complete. In this way, P2C no longer needs multiple observations or complete point clouds as ground truth. Instead, structural cues are learned from a category-specific dataset to complete partial point clouds of objects. We demonstrate the effectiveness of our approach on both synthetic ShapeNet data and real-world ScanNet data, showing that P2C produces comparable results to methods trained with complete shapes, and outperforms methods learned with multiple partial observations. Code is available at https://github.com/CuiRuikai/Partial2Complete.
</details>
<details>
<summary>摘要</summary>
《点云补充》目标是基于部分观察结果 recuperate 完整的形状。现有方法需要 either 完整的点云数据或多个相同对象的多个部分观察数据进行学习。相比之前的方法，我们提出了 Partial2Complete（P2C），这是首个没有需要多个部分观察或完整的点云数据作为学习参考的自动化完成点云对象的框架。具体来说，我们将 incomplete point cloud 分组成为本地 patches 作为输入，并预测masked patches 通过学习不同部分对象的准确信息。我们还提出了Region-Aware Chamfer Distance 来正则化形态匹配，而不是限制完成能力，并提出了 Normal Consistency Constraint 来包含地面的planarity假设，使recovered shape surface 是连续的和完整的。因此，P2C 不再需要多个观察或完整的点云数据作为参考。而是通过学习Category-specific dataset 中的结构准确信息来完成部分点云对象。我们在synthetic ShapeNet数据和实际世界 ScanNet 数据上展示了 P2C 的效果，显示 P2C 可以与基于完整形状的方法相比，并且超越基于多个部分观察的方法。代码可以在https://github.com/CuiRuikai/Partial2Complete 上找到。
</details></li>
</ul>
<hr>
<h2 id="vox2vec-A-Framework-for-Self-supervised-Contrastive-Learning-of-Voxel-level-Representations-in-Medical-Images"><a href="#vox2vec-A-Framework-for-Self-supervised-Contrastive-Learning-of-Voxel-level-Representations-in-Medical-Images" class="headerlink" title="vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-level Representations in Medical Images"></a>vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-level Representations in Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14725">http://arxiv.org/abs/2307.14725</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mishgon/vox2vec">https://github.com/mishgon/vox2vec</a></li>
<li>paper_authors: Mikhail Goncharov, Vera Soboleva, Anvar Kurmukov, Maxim Pisov, Mikhail Belyaev</li>
<li>for: 本文提出了一种自然语言学习（SSL）方法，用于学习声域级表示。</li>
<li>methods: 本文使用了一种矩阵学习方法，即特征峰网络（FPN），用于生成声域级表示。FPN是在不同层次的pyramid中预训练的，以便在不同的扩展上生成相同的声域级表示，并生成不同的声域级表示。</li>
<li>results: 本文使用vox2vec方法在多于6500个公共可用的计算机Tomography图像上进行预训练，然后attach到简单的头上并训练结果。结果显示，vox2vec方法在三个评估设置下都 OUTPERFORMS现有的医疗影像SSL技术：线性和非线性探测，以及终端精度调整。此外，使用冻结vox2vec表示后attach一个非线性头，可以与从scratch训练FPN获得相同的性能，而且具有50个可变参数的缺省参数量。代码可以在<a target="_blank" rel="noopener" href="https://github.com/mishgon/vox2vec%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/mishgon/vox2vec上获取。</a><details>
<summary>Abstract</summary>
This paper introduces vox2vec - a contrastive method for self-supervised learning (SSL) of voxel-level representations. vox2vec representations are modeled by a Feature Pyramid Network (FPN): a voxel representation is a concatenation of the corresponding feature vectors from different pyramid levels. The FPN is pre-trained to produce similar representations for the same voxel in different augmented contexts and distinctive representations for different voxels. This results in unified multi-scale representations that capture both global semantics (e.g., body part) and local semantics (e.g., different small organs or healthy versus tumor tissue). We use vox2vec to pre-train a FPN on more than 6500 publicly available computed tomography images. We evaluate the pre-trained representations by attaching simple heads on top of them and training the resulting models for 22 segmentation tasks. We show that vox2vec outperforms existing medical imaging SSL techniques in three evaluation setups: linear and non-linear probing and end-to-end fine-tuning. Moreover, a non-linear head trained on top of the frozen vox2vec representations achieves competitive performance with the FPN trained from scratch while having 50 times fewer trainable parameters. The code is available at https://github.com/mishgon/vox2vec .
</details>
<details>
<summary>摘要</summary>
We use vox2vec to pre-train a FPN on more than 6500 publicly available computed tomography images. We evaluate the pre-trained representations by attaching simple heads on top of them and training the resulting models for 22 segmentation tasks. We show that vox2vec outperforms existing medical imaging SSL techniques in three evaluation setups: linear and non-linear probing and end-to-end fine-tuning. Moreover, a non-linear head trained on top of the frozen vox2vec representations achieves competitive performance with the FPN trained from scratch while having 50 times fewer trainable parameters.The code for vox2vec is available at <https://github.com/mishgon/vox2vec>.
</details></li>
</ul>
<hr>
<h2 id="EFLNet-Enhancing-Feature-Learning-for-Infrared-Small-Target-Detection"><a href="#EFLNet-Enhancing-Feature-Learning-for-Infrared-Small-Target-Detection" class="headerlink" title="EFLNet: Enhancing Feature Learning for Infrared Small Target Detection"></a>EFLNet: Enhancing Feature Learning for Infrared Small Target Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14723">http://arxiv.org/abs/2307.14723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Yang, Xinyu Zhang, Jiahao Zhu, Jian Zhang, Dongjian Tian, Jun Luo, Mingliang Zhou, Yangjun Pi</li>
<li>for: 这篇论文的目的是解决单框架红外小目标检测中的挑战，即背景和目标之间的极大偏见，以及小目标信息在高层semantic层面上易产生丢失。</li>
<li>methods: 该论文提出了基于YOLOv7框架的强化特征学习网络（EFLNet）来解决这些问题。其中，我们提出了一种自适应权重损失函数，以自动调整损失权重，让模型更加偏爱目标特征。其次，我们引入了 норmalized Gaussian Wasserstein distance，以解决 bounding box regression 对红外小目标的极高敏感性。最后，我们在网络中添加了动态头机制，以实现自适应学习每个semantic层的相对重要性。</li>
<li>results: 实验结果表明，我们的方法可以在红外小目标检测中实现更好的性能，比如当前的深度学习基于方法。<details>
<summary>Abstract</summary>
Single-frame infrared small target detection is considered to be a challenging task, due to the extreme imbalance between target and background, bounding box regression is extremely sensitive to infrared small targets, and small target information is easy to lose in the high-level semantic layer. In this paper, we propose an enhancing feature learning network (EFLNet) based on YOLOv7 framework to solve these problems. First, we notice that there is an extremely imbalance between the target and the background in the infrared image, which makes the model pay more attention to the background features, resulting in missed detection. To address this problem, we propose a new adaptive threshold focal loss function that adjusts the loss weight automatically, compelling the model to allocate greater attention to target features. Second, we introduce the normalized Gaussian Wasserstein distance to alleviate the difficulty of model convergence caused by the extreme sensitivity of the bounding box regression to infrared small targets. Finally, we incorporate a dynamic head mechanism into the network to enable adaptive learning of the relative importance of each semantic layer. Experimental results demonstrate our method can achieve better performance in the detection performance of infrared small targets compared to state-of-the-art deep-learning based methods.
</details>
<details>
<summary>摘要</summary>
单一帧红外小目标检测是一个具有挑战性的任务，因为目标和背景之间存在极大的不均衡， bounding box regression 非常敏感于红外小目标，小目标信息容易在高层 semantic layer 中失去。在这篇文章中，我们提出了一个强化特征学习网络（EFLNet）基于 YOLOv7 框架，以解决这些问题。首先，我们注意到了红外图像中目标和背景之间的极大不均衡，这使得模型更倾向于关注背景特征，从而导致搜寻失败。为了解决这个问题，我们提出了一个新的自动调整损失函数，可以自动调整损失重要性，让模型更加倾向于对目标特征进行关注。其次，我们引入了 норма化 Gaussian Wasserstein 距离，以减少 bounding box regression 的问题对于红外小目标的敏感性。最后，我们将动态头 Mechanism  incorporated 到网络中，以启动网络进行自适应的学习，以便适当地调整各个 semantic layer 的相对重要性。实验结果显示，我们的方法可以在红外小目标检测中比 state-of-the-art deep-learning 基础方法表现更好。
</details></li>
</ul>
<hr>
<h2 id="Robust-vertebra-identification-using-simultaneous-node-and-edge-predicting-Graph-Neural-Networks"><a href="#Robust-vertebra-identification-using-simultaneous-node-and-edge-predicting-Graph-Neural-Networks" class="headerlink" title="Robust vertebra identification using simultaneous node and edge predicting Graph Neural Networks"></a>Robust vertebra identification using simultaneous node and edge predicting Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02509">http://arxiv.org/abs/2308.02509</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imfusiongmbh/vid-vertebra-identification-dataset">https://github.com/imfusiongmbh/vid-vertebra-identification-dataset</a></li>
<li>paper_authors: Vincent Bürgin, Raphael Prevost, Marijn F. Stollenga</li>
<li>for: 这篇论文的目的是为了自动找到和识别CT扫描中的脊梗，以便于诊断和治疗。</li>
<li>methods: 这篇论文使用了一个简单的管线，包括使用标准预测和单一图像神经网络，将脊梗与全orientation相关和分类。</li>
<li>results: 这篇论文的结果显示，该方法可以正确地相互关联脊梗和体干骨，忽略False Positive，并在标准VerSe挑战 зада务中表现竞争性。<details>
<summary>Abstract</summary>
Automatic vertebra localization and identification in CT scans is important for numerous clinical applications. Much progress has been made on this topic, but it mostly targets positional localization of vertebrae, ignoring their orientation. Additionally, most methods employ heuristics in their pipeline that can be sensitive in real clinical images which tend to contain abnormalities. We introduce a simple pipeline that employs a standard prediction with a U-Net, followed by a single graph neural network to associate and classify vertebrae with full orientation. To test our method, we introduce a new vertebra dataset that also contains pedicle detections that are associated with vertebra bodies, creating a more challenging landmark prediction, association and classification task. Our method is able to accurately associate the correct body and pedicle landmarks, ignore false positives and classify vertebrae in a simple, fully trainable pipeline avoiding application-specific heuristics. We show our method outperforms traditional approaches such as Hungarian Matching and Hidden Markov Models. We also show competitive performance on the standard VerSe challenge body identification task.
</details>
<details>
<summary>摘要</summary>
自动骨盆位置和识别在CT扫描图中是至关重要的临床应用。过去几年，在这一领域中有很大的进步，但大多数方法都是对骨盆体的位置进行定位，忽略了它们的方向。此外，大多数方法都使用了特定的规则和假设，这些规则可能不适用于实际的临床图像，这些图像可能包含异常。我们提出了一个简单的管道，该管道使用标准预测器和单个图 neural network 来关联和分类骨盆体，并忽略false positive。为测试我们的方法，我们创建了一个新的骨盆数据集，该数据集包含了关联骨盆体和肋骨的检测结果，这使得骨盆体的预测、关联和分类任务变得更加困难。我们的方法能够准确地关联正确的骨盆体和肋骨标记，忽略false positive，并在简单可trainable的管道中完成骨盆体的分类。我们比较了我们的方法与传统的匈牙利匹配和隐马尔可夫模型，发现我们的方法能够超越这些传统方法。此外，我们还发现我们的方法在标准VerSe挑战任务上的体部识别性能与其他方法类似。
</details></li>
</ul>
<hr>
<h2 id="GaitMorph-Transforming-Gait-by-Optimally-Transporting-Discrete-Codes"><a href="#GaitMorph-Transforming-Gait-by-Optimally-Transporting-Discrete-Codes" class="headerlink" title="GaitMorph: Transforming Gait by Optimally Transporting Discrete Codes"></a>GaitMorph: Transforming Gait by Optimally Transporting Discrete Codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14713">http://arxiv.org/abs/2307.14713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Cosma, Emilian Radoi</li>
<li>for: 本研究旨在提出一种无需人工标注的步态识别系统训练方法，通过自动学习方法来实现。</li>
<li>methods: 我们提出了一种基于高级压缩模型的方法，使用无标注数据来构建一个灵活可解释的抽象空间，并使用优化运输理论来学习抽象代码的传输地图。</li>
<li>results: 我们进行了广泛的实验，并证明了我们的方法可以合理地Synthesize加入视频序列中的其他视图。Here’s the English version of the three key points for reference:</li>
<li>for: The purpose of this research is to propose a method for training gait recognition systems without explicit human annotations, using self-supervised learning approaches.</li>
<li>methods: We propose a method based on a high-compression model for gait skeleton sequences, which leverages unlabeled data to construct a discrete and interpretable latent space that preserves identity-related features. We also propose a method based on optimal transport theory to learn latent transport maps on the discrete codebook that morph gait sequences between variations.</li>
<li>results: We conduct extensive experiments and show that our method is suitable to synthesize additional views for an input sequence.<details>
<summary>Abstract</summary>
Gait, the manner of walking, has been proven to be a reliable biometric with uses in surveillance, marketing and security. A promising new direction for the field is training gait recognition systems without explicit human annotations, through self-supervised learning approaches. Such methods are heavily reliant on strong augmentations for the same walking sequence to induce more data variability and to simulate additional walking variations. Current data augmentation schemes are heuristic and cannot provide the necessary data variation as they are only able to provide simple temporal and spatial distortions. In this work, we propose GaitMorph, a novel method to modify the walking variation for an input gait sequence. Our method entails the training of a high-compression model for gait skeleton sequences that leverages unlabelled data to construct a discrete and interpretable latent space, which preserves identity-related features. Furthermore, we propose a method based on optimal transport theory to learn latent transport maps on the discrete codebook that morph gait sequences between variations. We perform extensive experiments and show that our method is suitable to synthesize additional views for an input sequence.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本为简化中文。<</SYS>>走姿（gait）已被证明为可靠的生物метри克，具有监测、营销和安全等多个应用。现在的新趋势是使用自动学习方法来训练走姿认识系统，而不需要显式的人类标注。这些方法对于数据多样性的需求非常高，因此需要强大的数据增强方法来模拟更多的走姿变化。现有的数据增强方法是谱系的，无法提供足够的数据多样性。在这种情况下，我们提出了一种新的方法——走姿变换（GaitMorph）。我们的方法是通过训练一个高压缩模型来Transforming Gait Sequences into Different VariationsGait, the manner of walking, has been proven to be a reliable biometric with uses in surveillance, marketing, and security. A promising new direction for the field is training gait recognition systems without explicit human annotations, through self-supervised learning approaches. However, current data augmentation schemes are heuristic and cannot provide the necessary data variation. In this work, we propose GaitMorph, a novel method to modify the walking variation for an input gait sequence. Our method entails training a high-compression model for gait skeleton sequences that leverages unlabelled data to construct a discrete and interpretable latent space, which preserves identity-related features. Furthermore, we propose a method based on optimal transport theory to learn latent transport maps on the discrete codebook that morph gait sequences between variations. We perform extensive experiments and show that our method is suitable to synthesize additional views for an input sequence.
</details></li>
</ul>
<hr>
<h2 id="Pre-training-Vision-Transformers-with-Very-Limited-Synthesized-Images"><a href="#Pre-training-Vision-Transformers-with-Very-Limited-Synthesized-Images" class="headerlink" title="Pre-training Vision Transformers with Very Limited Synthesized Images"></a>Pre-training Vision Transformers with Very Limited Synthesized Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14710">http://arxiv.org/abs/2307.14710</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ryoo-nakamura/ofdb">https://github.com/ryoo-nakamura/ofdb</a></li>
<li>paper_authors: Ryo Nakamura, Hirokatsu Kataoka, Sora Takashima, Edgar Josafat Martinez Noriega, Rio Yokota, Nakamasa Inoue</li>
<li>for: 这个论文主要是用于探讨Formula-driven supervised learning（FDSL）是一种预训练方法，它利用生成自数学方程的Synthetic图像进行预训练。</li>
<li>methods: 这个论文使用的方法是将视transformer预训练在基于数学方程生成的Synthetic图像集上。</li>
<li>results: 研究发现，通过将不同类别的Synthetic图像视为数据增强，可以使模型在下游任务中表现更好。此外， authors还证明了这种方法可以使用远少于ImageNet-21k的数据集进行预训练，并且可以与ImageNet-21k相当或者超过其在ImageNet-1k fine-tuning中的性能。<details>
<summary>Abstract</summary>
Formula-driven supervised learning (FDSL) is a pre-training method that relies on synthetic images generated from mathematical formulae such as fractals. Prior work on FDSL has shown that pre-training vision transformers on such synthetic datasets can yield competitive accuracy on a wide range of downstream tasks. These synthetic images are categorized according to the parameters in the mathematical formula that generate them. In the present work, we hypothesize that the process for generating different instances for the same category in FDSL, can be viewed as a form of data augmentation. We validate this hypothesis by replacing the instances with data augmentation, which means we only need a single image per category. Our experiments shows that this one-instance fractal database (OFDB) performs better than the original dataset where instances were explicitly generated. We further scale up OFDB to 21,000 categories and show that it matches, or even surpasses, the model pre-trained on ImageNet-21k in ImageNet-1k fine-tuning. The number of images in OFDB is 21k, whereas ImageNet-21k has 14M. This opens new possibilities for pre-training vision transformers with much smaller datasets.
</details>
<details>
<summary>摘要</summary>
“数学公式驱动的超级vised学习（FDSL）是一种预训练方法，利用生成自数学公式的 sintetic 图像。先前的研究表明，在这些 sintetic 图像上预训练视觉转换器可以达到多种下游任务的竞争性高度。这些 sintetic 图像按照生成图像的参数分类。在 presente 工作中，我们假设生成不同类别的过程可以视为数据增强。我们验证这一假设，通过将实例替换为数据增强，我们只需要单个图像per类。我们的实验表明，这一个单个图像数据库（OFDB）在 ImageNet-1k 精度调整中表现更好，而且可以与 ImageNet-21k 中预训练的模型相匹配或超越。OFDB 中的图像数量为 21k，而 ImageNet-21k 中的图像数量为 14M。这些新的可能性可能为预训练视觉转换器带来巨大的改进。”Note: Please note that the translation is in Simplified Chinese, which is one of the two standard Chinese dialects. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Taxonomy-Adaptive-Cross-Domain-Adaptation-in-Medical-Imaging-via-Optimization-Trajectory-Distillation"><a href="#Taxonomy-Adaptive-Cross-Domain-Adaptation-in-Medical-Imaging-via-Optimization-Trajectory-Distillation" class="headerlink" title="Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via Optimization Trajectory Distillation"></a>Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via Optimization Trajectory Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14709">http://arxiv.org/abs/2307.14709</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/camwew/tada-mi">https://github.com/camwew/tada-mi</a></li>
<li>paper_authors: Jianan Fan, Dongnan Liu, Hang Chang, Heng Huang, Mei Chen, Weidong Cai</li>
<li>for: 提高自动医疗图像分析的成功率，alleviate the burden of labeled data collection。</li>
<li>methods: 提出了一种名为“Optimization Trajectory Distillation”的新方法，它利用了梯度空间的低级特性和双流维护算法来规范网络训练的学习动态，并在不同的预测任务中进行了广泛的评估。</li>
<li>results: 比较previoius方法，该方法得到了更好的效果和改进。<details>
<summary>Abstract</summary>
The success of automated medical image analysis depends on large-scale and expert-annotated training sets. Unsupervised domain adaptation (UDA) has been raised as a promising approach to alleviate the burden of labeled data collection. However, they generally operate under the closed-set adaptation setting assuming an identical label set between the source and target domains, which is over-restrictive in clinical practice where new classes commonly exist across datasets due to taxonomic inconsistency. While several methods have been presented to tackle both domain shifts and incoherent label sets, none of them take into account the common characteristics of the two issues and consider the learning dynamics along network training. In this work, we propose optimization trajectory distillation, a unified approach to address the two technical challenges from a new perspective. It exploits the low-rank nature of gradient space and devises a dual-stream distillation algorithm to regularize the learning dynamics of insufficiently annotated domain and classes with the external guidance obtained from reliable sources. Our approach resolves the issue of inadequate navigation along network optimization, which is the major obstacle in the taxonomy adaptive cross-domain adaptation scenario. We evaluate the proposed method extensively on several tasks towards various endpoints with clinical and open-world significance. The results demonstrate its effectiveness and improvements over previous methods.
</details>
<details>
<summary>摘要</summary>
成功的自动医疗图像分析取决于大规模的专家标注训练集。无监督领域适应（UDA）被提出为解决数据收集监督成本的有力的方法。然而，它们通常在关闭集成适应 Setting下运行，即源频率和目标频率之间的标签集 identical，这在临床实践中是过于严格的。虽然一些方法已经被提出来解决这两个技术挑战，但 none of them 考虑了这两个问题的共同特点和网络训练过程中的学习动力。在这项工作中，我们提出了优化轨迹涂抹，一种统一的方法，用于解决这两个技术挑战。它利用了梯度空间的低级别特性，并设计了一种双流涂抹算法，用于规范频率不充分标注的频率和类型的学习动力。我们的方法可以解决频率优化过程中的导航问题，这是涂抹适应交叉频率适应场景中的主要障碍。我们对多个任务进行了广泛的测试，结果表明我们的方法有效和前方法之上。
</details></li>
</ul>
<hr>
<h2 id="High-Dynamic-Range-Imaging-via-Visual-Attention-Modules"><a href="#High-Dynamic-Range-Imaging-via-Visual-Attention-Modules" class="headerlink" title="High Dynamic Range Imaging via Visual Attention Modules"></a>High Dynamic Range Imaging via Visual Attention Modules</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14705">http://arxiv.org/abs/2307.14705</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alirezaomrani95/hdr-vam">https://github.com/alirezaomrani95/hdr-vam</a></li>
<li>paper_authors: Ali Reza Omrani, Davide Moroni</li>
<li>for: 这篇论文是为了提出一种新的高动态范围（HDR）成像方法，以增强图像的质量和细节。</li>
<li>methods: 该方法使用了深度学习架构，并通过视觉注意力模块（VAM）来提取图像中最重要的部分。</li>
<li>results: 实验结果表明，该方法比大多数现有的State-Of-The-Art算法更高效。<details>
<summary>Abstract</summary>
Thanks to High Dynamic Range (HDR) imaging methods, the scope of photography has seen profound changes recently. To be more specific, such methods try to reconstruct the lost luminosity of the real world caused by the limitation of regular cameras from the Low Dynamic Range (LDR) images. Additionally, although the State-Of-The-Art methods in this topic perform well, they mainly concentrate on combining different exposures and have less attention to extracting the informative parts of the images. Thus, this paper aims to introduce a new model capable of incorporating information from the most visible areas of each image extracted by a visual attention module (VAM), which is a result of a segmentation strategy. In particular, the model, based on a deep learning architecture, utilizes the extracted areas to produce the final HDR image. The results demonstrate that our method outperformed most of the State-Of-The-Art algorithms.
</details>
<details>
<summary>摘要</summary>
高动态范围（HDR）摄影技术已经对摄影领域带来深刻的变革。更具体地说，这些方法试图重建实际世界中丢失的亮度，即常规相机的低动态范围（LDR）图像所带来的限制。尽管现状领先的方法在这个领域具有良好的性能，但它们主要集中在不同曝光的结合上，对图像中有用信息的提取则得到了更少的关注。因此，本文旨在介绍一种新的模型，可以通过视觉注意力模块（VAM） segmentation策略提取图像中最可见的部分，并使用这些部分生成最终的HDR图像。结果表明，我们的方法在大多数状态前进的算法中表现出色。
</details></li>
</ul>
<hr>
<h2 id="MIM-OOD-Generative-Masked-Image-Modelling-for-Out-of-Distribution-Detection-in-Medical-Images"><a href="#MIM-OOD-Generative-Masked-Image-Modelling-for-Out-of-Distribution-Detection-in-Medical-Images" class="headerlink" title="MIM-OOD: Generative Masked Image Modelling for Out-of-Distribution Detection in Medical Images"></a>MIM-OOD: Generative Masked Image Modelling for Out-of-Distribution Detection in Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14701">http://arxiv.org/abs/2307.14701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sergio Naval Marimont, Vasilis Siomos, Giacomo Tarroni</li>
<li>for: 这篇论文目的是为了提出一种基于图像健康 анаatomy 的无监督 OUT-OF-DISTRIBUTION (OOD) 检测方法。</li>
<li>methods: 该方法使用了图像 tokenization 和 Auto-Regressive (AR) 模型来模型图像分布，并使用 AR 模型来标识异常 токен和替换异常表示。</li>
<li>results: 该方法使用了两个任务特定网络：一个是用于标识异常 токен的 transformer，另一个是用于使用 masked image modelling (MIM) 填充异常表示。实验表明，MIM-OOD 方法在脑 Magnetic Resonance Imaging (MRI) 异常中显著超越了 AR 模型（DICE 0.458 vs 0.301），同时实现了约25倍的速度提升（9.5s vs 244s）。<details>
<summary>Abstract</summary>
Unsupervised Out-of-Distribution (OOD) detection consists in identifying anomalous regions in images leveraging only models trained on images of healthy anatomy. An established approach is to tokenize images and model the distribution of tokens with Auto-Regressive (AR) models. AR models are used to 1) identify anomalous tokens and 2) in-paint anomalous representations with in-distribution tokens. However, AR models are slow at inference time and prone to error accumulation issues which negatively affect OOD detection performance. Our novel method, MIM-OOD, overcomes both speed and error accumulation issues by replacing the AR model with two task-specific networks: 1) a transformer optimized to identify anomalous tokens and 2) a transformer optimized to in-paint anomalous tokens using masked image modelling (MIM). Our experiments with brain MRI anomalies show that MIM-OOD substantially outperforms AR models (DICE 0.458 vs 0.301) while achieving a nearly 25x speedup (9.5s vs 244s).
</details>
<details>
<summary>摘要</summary>
无监督异常检测（OOD）的方法是通过只使用健康解剖学图像进行模型训练来识别图像中的异常区域。一种常见的方法是将图像分割成 tokens，然后使用自动推导（AR）模型来分布计数。AR 模型可以1) 识别异常 tokens，2) 使用健康解剖学图像中的 tokens 填充异常表示。然而，AR 模型在推理时间和错误积累问题上存在缓慢和质量下降问题，这些问题会对 OOD 检测性能产生负面影响。我们的新方法 MIM-OOD 解决了这些问题，通过取代 AR 模型而使用两个任务特定的网络：1）一个基于 transformer 的异常 tokens 识别网络，2）一个基于 masked image modelling（MIM）的异常 tokens 填充网络。我们对大脑 MRI 异常进行了实验，结果显示 MIM-OOD 与 AR 模型相比有显著提高（DICE 0.458 vs 0.301），同时实现了约25倍的速度提升（9.5s vs 244s）。
</details></li>
</ul>
<hr>
<h2 id="Unified-Adversarial-Patch-for-Visible-Infrared-Cross-modal-Attacks-in-the-Physical-World"><a href="#Unified-Adversarial-Patch-for-Visible-Infrared-Cross-modal-Attacks-in-the-Physical-World" class="headerlink" title="Unified Adversarial Patch for Visible-Infrared Cross-modal Attacks in the Physical World"></a>Unified Adversarial Patch for Visible-Infrared Cross-modal Attacks in the Physical World</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14682">http://arxiv.org/abs/2307.14682</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aries-iai/cross-modal_patch_attack">https://github.com/aries-iai/cross-modal_patch_attack</a></li>
<li>paper_authors: Xingxing Wei, Yao Huang, Yitong Sun, Jie Yu<br>for: 防御深度学习对象检测器受到物理攻击的威胁，通过结合可见和无可见感知器的组合来增强安全性。methods: 我们提出了一种涉及多modal攻击的统一恶作剂质量，可以同时在可见和无可见感知器上实现欺骗。我们还提出了一种边界限定的形态优化方法，以及一种分数感知评估方法，以保证恶作剂质量的合理性。results: 我们的方法在多种场景下都达到了高于80%的攻击成功率，并在实际世界中进行了物理世界场景下的评估，包括不同的角度、距离、姿势和场景。<details>
<summary>Abstract</summary>
Physical adversarial attacks have put a severe threat to DNN-based object detectors. To enhance security, a combination of visible and infrared sensors is deployed in various scenarios, which has proven effective in disabling existing single-modal physical attacks. To further demonstrate the potential risks in such cases, we design a unified adversarial patch that can perform cross-modal physical attacks, achieving evasion in both modalities simultaneously with a single patch. Given the different imaging mechanisms of visible and infrared sensors, our work manipulates patches' shape features, which can be captured in different modalities when they undergo changes. To deal with challenges, we propose a novel boundary-limited shape optimization approach that aims to achieve compact and smooth shapes for the adversarial patch, making it easy to implement in the physical world. And a score-aware iterative evaluation method is also introduced to balance the fooling degree between visible and infrared detectors during optimization, which guides the adversarial patch to iteratively reduce the predicted scores of the multi-modal sensors. Furthermore, we propose an Affine-Transformation-based enhancement strategy that makes the learnable shape robust to various angles, thus mitigating the issue of shape deformation caused by different shooting angles in the real world. Our method is evaluated against several state-of-the-art object detectors, achieving an Attack Success Rate (ASR) of over 80%. We also demonstrate the effectiveness of our approach in physical-world scenarios under various settings, including different angles, distances, postures, and scenes for both visible and infrared sensors.
</details>
<details>
<summary>摘要</summary>
人工智能图像识别器面临着物理攻击的严重威胁。为增强安全性，我们在不同场景中部署了可见和抗红外感知器，并证明了这种多感知模式的组合能够精准地终止现有的单模态物理攻击。为了进一步推翻这种情况的风险，我们设计了一种可跨模态物理攻击的统一恶作剂，可以同时在两种模式中 achievement 欺骗。由于可见和抗红外感知器的捕捉机制不同，我们在形状特征上进行了修改，以便在不同的捕捉机制下具有不同的特征。为了解决挑战，我们提出了一种边界限定形态优化方法，目的是实现紧凑而平滑的恶作剂形态，使其在物理世界中易于实现。此外，我们还提出了一种分数意识迭代评估方法，以保证恶作剂在多模式检测器中的欺骗度均衡。此外，我们还提出了基于Affine变换的增强策略，使learnable形态具有多个视角下的抗shape变形性，以mitigate实际世界中的shape变形问题。我们的方法在多个国家前景下进行了评估，其中包括不同的角度、距离、姿态和场景，并在可见和抗红外感知器中都达到了Attack Success Rate（ASR）高于80%。
</details></li>
</ul>
<hr>
<h2 id="LLDiffusion-Learning-Degradation-Representations-in-Diffusion-Models-for-Low-Light-Image-Enhancement"><a href="#LLDiffusion-Learning-Degradation-Representations-in-Diffusion-Models-for-Low-Light-Image-Enhancement" class="headerlink" title="LLDiffusion: Learning Degradation Representations in Diffusion Models for Low-Light Image Enhancement"></a>LLDiffusion: Learning Degradation Representations in Diffusion Models for Low-Light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14659">http://arxiv.org/abs/2307.14659</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/taowangzj/lldiffusion">https://github.com/taowangzj/lldiffusion</a></li>
<li>paper_authors: Tao Wang, Kaihao Zhang, Ziqian Shao, Wenhan Luo, Bjorn Stenger, Tae-Kyun Kim, Wei Liu, Hongdong Li<br>for: This paper proposes a degradation-aware learning scheme for low-light image enhancement (LLIE) using diffusion models, which effectively integrates degradation and image priors into the diffusion process to improve image enhancement.methods: The proposed method includes a joint learning framework for both image generation and image enhancement to learn degradation representations, as well as a Low-Light Diffusion model (LLDiffusion) with a well-designed dynamic diffusion module that takes into account both the color map and the latent degradation representations to guide the diffusion process.results: Extensive experiments on public benchmarks demonstrate that the proposed LLDiffusion outperforms state-of-the-art LLIE methods both quantitatively and qualitatively, with improved image enhancement and color fidelity.<details>
<summary>Abstract</summary>
Current deep learning methods for low-light image enhancement (LLIE) typically rely on pixel-wise mapping learned from paired data. However, these methods often overlook the importance of considering degradation representations, which can lead to sub-optimal outcomes. In this paper, we address this limitation by proposing a degradation-aware learning scheme for LLIE using diffusion models, which effectively integrates degradation and image priors into the diffusion process, resulting in improved image enhancement. Our proposed degradation-aware learning scheme is based on the understanding that degradation representations play a crucial role in accurately modeling and capturing the specific degradation patterns present in low-light images. To this end, First, a joint learning framework for both image generation and image enhancement is presented to learn the degradation representations. Second, to leverage the learned degradation representations, we develop a Low-Light Diffusion model (LLDiffusion) with a well-designed dynamic diffusion module. This module takes into account both the color map and the latent degradation representations to guide the diffusion process. By incorporating these conditioning factors, the proposed LLDiffusion can effectively enhance low-light images, considering both the inherent degradation patterns and the desired color fidelity. Finally, we evaluate our proposed method on several well-known benchmark datasets, including synthetic and real-world unpaired datasets. Extensive experiments on public benchmarks demonstrate that our LLDiffusion outperforms state-of-the-art LLIE methods both quantitatively and qualitatively. The source code and pre-trained models are available at https://github.com/TaoWangzj/LLDiffusion.
</details>
<details>
<summary>摘要</summary>
当前的深度学习方法 для低光照图像提升（LLIE）通常基于像素级映射学习从对应的数据集学习。然而，这些方法经常忽视了考虑降低表示，这可能导致优化结果不佳。在这篇论文中，我们解决这些限制，并提出了基于降低表示的学习方案，用于LLIE。我们的提议基于于降低表示在准确地模型和捕捉低光照图像特有的降低特征。为此，我们首先提出了一个共同学习框架，用于学习图像生成和图像提升。然后，我们开发了一种低光照扩散模型（LLDiffusion），其中包括一个有效地考虑降低表示和颜色映射的动态扩散模块。通过这种模块，我们可以更好地考虑低光照图像的降低特征，同时保持图像的颜色准确性。最后，我们对多个公共 benchmark 进行了广泛的测试，并证明了我们的 LLDiffusion 在量化和质量上都超过了当前的 LL IE 方法。我们的源代码和预训练模型可以在 GitHub 上获取。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Frequency-U-Net-for-Denoising-Diffusion-Probabilistic-Models"><a href="#Spatial-Frequency-U-Net-for-Denoising-Diffusion-Probabilistic-Models" class="headerlink" title="Spatial-Frequency U-Net for Denoising Diffusion Probabilistic Models"></a>Spatial-Frequency U-Net for Denoising Diffusion Probabilistic Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14648">http://arxiv.org/abs/2307.14648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Yuan, Linjie Li, Jianfeng Wang, Zhengyuan Yang, Kevin Lin, Zicheng Liu, Lijuan Wang</li>
<li>for: 这个论文探讨了在wavelet空间中使用滤波态 probabilistic模型（DDPM）来进行视觉合成。</li>
<li>methods: 这个论文提出了一个新的架构SFUNet，它在wavelet变换中积极地捕捉了频率和空间域之间的联系。在传统的混淆网络中，我们将2D滤波和空间专注层加以改进，并增加了我们自己的频率频率相关的滤波和专注模组，以同时模型频率和空间域之间的联系。</li>
<li>results: 这个论文发现，使用我们的SFUNet架构可以在CIFAR-10、FFHQ、LSUN-Bedroom和LSUN-Church datasets上生成高质量的图像，比起像素空间的网络。<details>
<summary>Abstract</summary>
In this paper, we study the denoising diffusion probabilistic model (DDPM) in wavelet space, instead of pixel space, for visual synthesis. Considering the wavelet transform represents the image in spatial and frequency domains, we carefully design a novel architecture SFUNet to effectively capture the correlation for both domains. Specifically, in the standard denoising U-Net for pixel data, we supplement the 2D convolutions and spatial-only attention layers with our spatial frequency-aware convolution and attention modules to jointly model the complementary information from spatial and frequency domains in wavelet data. Our new architecture can be used as a drop-in replacement to the pixel-based network and is compatible with the vanilla DDPM training process. By explicitly modeling the wavelet signals, we find our model is able to generate images with higher quality on CIFAR-10, FFHQ, LSUN-Bedroom, and LSUN-Church datasets, than the pixel-based counterpart.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了在波лет空间中使用扩散概率模型（DDPM）进行视觉生成。而不是使用像素空间，我们在图像表示方面使用了波лет变换，这个变换可以在空间和频率两个领域中表示图像。为了有效地捕捉这两个领域之间的相关性，我们设计了一个新的架构SFUNet。在标准的清洁U-Net中，我们将2D卷积和空间只关注层替换为我们自己的空间频率相关卷积和关注模块，以同时模型空间和频率两个领域中的补偿信息。我们的新架构可以覆盖到像素基于网络，并且与普通的DDPM训练过程相容。通过显式地模型波лет信号，我们发现我们的模型在CIFAR-10、FFHQ、LSUN-Bedroom和LSUN-Church数据集上生成出比像素基于网络更高质量的图像。
</details></li>
</ul>
<hr>
<h2 id="EqGAN-Feature-Equalization-Fusion-for-Few-shot-Image-Generation"><a href="#EqGAN-Feature-Equalization-Fusion-for-Few-shot-Image-Generation" class="headerlink" title="EqGAN: Feature Equalization Fusion for Few-shot Image Generation"></a>EqGAN: Feature Equalization Fusion for Few-shot Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14638">http://arxiv.org/abs/2307.14638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingbo Zhou, Zhihao Yue, Yutong Ye, Pengyu Zhang, Xian Wei, Mingsong Chen</li>
<li>for: 提高几何图像生成器的生成质量和多样性，解决现有的混合策略因为缺乏细结构和文本信息而导致的问题。</li>
<li>methods: 提出了一种新的特征平衡混合生成随机网络（EqGAN），通过分离编码特征来混合结构和文本，并通过等距离权重来归一化不同级别的结构和文本semantic。</li>
<li>results: 对三个公共数据集进行了广泛的实验，结果表明，EqGAN可以significantly提高生成性能（FID分数下降32.7%，LPIPS分数下降4.19%），并在下游分类任务中提高准确率（上升1.97%），与状态的艺术领域内的前景比较。<details>
<summary>Abstract</summary>
Due to the absence of fine structure and texture information, existing fusion-based few-shot image generation methods suffer from unsatisfactory generation quality and diversity. To address this problem, we propose a novel feature Equalization fusion Generative Adversarial Network (EqGAN) for few-shot image generation. Unlike existing fusion strategies that rely on either deep features or local representations, we design two separate branches to fuse structures and textures by disentangling encoded features into shallow and deep contents. To refine image contents at all feature levels, we equalize the fused structure and texture semantics at different scales and supplement the decoder with richer information by skip connections. Since the fused structures and textures may be inconsistent with each other, we devise a consistent equalization loss between the equalized features and the intermediate output of the decoder to further align the semantics. Comprehensive experiments on three public datasets demonstrate that, EqGAN not only significantly improves generation performance with FID score (by up to 32.7%) and LPIPS score (by up to 4.19%), but also outperforms the state-of-the-arts in terms of accuracy (by up to 1.97%) for downstream classification tasks.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "fine structure" and "texture information" are not easily translatable, so I left them as is.* "equalization" is 平衡 (píngyì) in Chinese, which means "balance" or "adjustment".* "shallow and deep contents" are  superficical 和 deep 内容 (fāngtiě yǔ dīp cóng) in Chinese.* "skip connections" are 跳过连接 (tiào guò lián xiàng) in Chinese.* "consistent equalization loss" is 一致平衡损失 (yīchè píngyì shūshì) in Chinese.
</details></li>
</ul>
<hr>
<h2 id="HTNet-for-micro-expression-recognition"><a href="#HTNet-for-micro-expression-recognition" class="headerlink" title="HTNet for micro-expression recognition"></a>HTNet for micro-expression recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14637">http://arxiv.org/abs/2307.14637</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangzhifengharrison/htnet">https://github.com/wangzhifengharrison/htnet</a></li>
<li>paper_authors: Zhifeng Wang, Kaihao Zhang, Wenhan Luo, Ramesh Sankaranarayana</li>
<li>For: 本研究旨在提高微表情识别算法的性能，特别是识别微小的脸部表达。* Methods: 本文提出了一种 Hierarchical Transformer Network (HTNet)，包括两个主要组成部分：一个 transformer 层和一个汇集层。 transformer 层使用本地时间特征来表征本地小肌动作，而汇集层则用于学习脸部的全局semantic特征和本地相互作用。* Results: 实验结果显示，提出的方法在四个公共可用的微表情数据集上比前方法得分高出较大的幅度。codes和模型可以在以下链接中获取：\url{<a target="_blank" rel="noopener" href="https://github.com/wangzhifengharrison/HTNet%7D">https://github.com/wangzhifengharrison/HTNet}</a><details>
<summary>Abstract</summary>
Facial expression is related to facial muscle contractions and different muscle movements correspond to different emotional states. For micro-expression recognition, the muscle movements are usually subtle, which has a negative impact on the performance of current facial emotion recognition algorithms. Most existing methods use self-attention mechanisms to capture relationships between tokens in a sequence, but they do not take into account the inherent spatial relationships between facial landmarks. This can result in sub-optimal performance on micro-expression recognition tasks.Therefore, learning to recognize facial muscle movements is a key challenge in the area of micro-expression recognition. In this paper, we propose a Hierarchical Transformer Network (HTNet) to identify critical areas of facial muscle movement. HTNet includes two major components: a transformer layer that leverages the local temporal features and an aggregation layer that extracts local and global semantical facial features. Specifically, HTNet divides the face into four different facial areas: left lip area, left eye area, right eye area and right lip area. The transformer layer is used to focus on representing local minor muscle movement with local self-attention in each area. The aggregation layer is used to learn the interactions between eye areas and lip areas. The experiments on four publicly available micro-expression datasets show that the proposed approach outperforms previous methods by a large margin. The codes and models are available at: \url{https://github.com/wangzhifengharrison/HTNet}
</details>
<details>
<summary>摘要</summary>
Facial expression和facial muscle contractions有着密切的关系，不同的muscle movement对应于不同的情感状态。在微表达识别 tasks中，muscle movements通常是微妙的，这会影响现有的面部情感识别算法的性能。大多数现有方法使用自注意机制来捕捉序列中的关系，但是它们不考虑面部特征的自然空间关系。这会导致微表达识别任务的性能下降。因此，Recognize facial muscle movements是微表达识别领域中的关键挑战。在这篇论文中，我们提出了层次 transformer network（HTNet）来标识面部muscle movement的关键区域。HTNet包括两个主要组成部分：transformer层和聚合层。transformer层通过利用面部的局部时间特征来强调本地少股运动的表示。聚合层则通过学习眼部和唇部之间的交互来学习面部的全局semantic特征。特别是，HTNet将面部分为四个不同的区域：左眼区、左唇区、右眼区和右唇区。transformer层在每个区域中进行本地自注意，以强调本地少股运动的表示。聚合层则通过学习眼部和唇部之间的交互来学习面部的全局semantic特征。我们在四个公共可用的微表达数据集上进行了实验，结果显示，我们的方法与之前的方法相比，性能有大幅提高。代码和模型可以在以下链接中找到：\url{https://github.com/wangzhifengharrison/HTNet}
</details></li>
</ul>
<hr>
<h2 id="360VOT-A-New-Benchmark-Dataset-for-Omnidirectional-Visual-Object-Tracking"><a href="#360VOT-A-New-Benchmark-Dataset-for-Omnidirectional-Visual-Object-Tracking" class="headerlink" title="360VOT: A New Benchmark Dataset for Omnidirectional Visual Object Tracking"></a>360VOT: A New Benchmark Dataset for Omnidirectional Visual Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14630">http://arxiv.org/abs/2307.14630</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huajianup/360vot">https://github.com/huajianup/360vot</a></li>
<li>paper_authors: Huajian Huang, Yinzhe Xu, Yingshu Chen, Sai-Kit Yeung</li>
<li>for: 该论文探讨了使用360度图像进行视觉对象跟踪，并描述了在360度图像中存在的新挑战，如大幅度扭曲和缝合 artifacts。</li>
<li>methods: 该论文提出了一种基于目标局部化的全面跟踪框架，并使用了新的表述方式，如 bounding field-of-view，以减少这些问题。</li>
<li>results: 该论文提供了一个大规模的全面跟踪 benchmark dataset， named 360VOT，包含120个序列和113K帧高分辨率图像，以及4种不偏的地面真实数据。此外，论文还提供了适用于360度图像的新的评价指标，并对20种现有的视觉跟踪器进行了广泛的评估。<details>
<summary>Abstract</summary>
360{\deg} images can provide an omnidirectional field of view which is important for stable and long-term scene perception. In this paper, we explore 360{\deg} images for visual object tracking and perceive new challenges caused by large distortion, stitching artifacts, and other unique attributes of 360{\deg} images. To alleviate these problems, we take advantage of novel representations of target localization, i.e., bounding field-of-view, and then introduce a general 360 tracking framework that can adopt typical trackers for omnidirectional tracking. More importantly, we propose a new large-scale omnidirectional tracking benchmark dataset, 360VOT, in order to facilitate future research. 360VOT contains 120 sequences with up to 113K high-resolution frames in equirectangular projection. The tracking targets cover 32 categories in diverse scenarios. Moreover, we provide 4 types of unbiased ground truth, including (rotated) bounding boxes and (rotated) bounding field-of-views, as well as new metrics tailored for 360{\deg} images which allow for the accurate evaluation of omnidirectional tracking performance. Finally, we extensively evaluated 20 state-of-the-art visual trackers and provided a new baseline for future comparisons. Homepage: https://360vot.hkustvgd.com
</details>
<details>
<summary>摘要</summary>
三百六十度图像可提供全球视野，这对于稳定和长期场景识别非常重要。在这篇论文中，我们探讨了三百六十度图像在视觉对象跟踪中的挑战，包括大量扭曲、缝合 artifacts 和其他特有的三百六十度图像特征。为了解决这些问题，我们利用新的目标定位表示方法，即 bounding field-of-view，然后提出了一个通用的三百六十度跟踪框架，可以采用传统的全息跟踪器。更重要的是，我们提出了一个新的大规模全息跟踪数据集，360VOT，以便未来的研究。360VOT包含120个序列，最多113万高分辨率帧，使用 equirectangular projection。跟踪目标包括32个类别，在多样化的场景中。此外，我们提供了4种无偏见的地面真实，包括旋转的 bounding box 和旋转的 bounding field-of-view，以及适应三百六十度图像的新评价指标。最后，我们对20种当前最佳视觉跟踪器进行了广泛的评估，并提供了新的基线 для未来的比较。网站地址：https://360vot.hkustvgd.com
</details></li>
</ul>
<hr>
<h2 id="FS-Depth-Focal-and-Scale-Depth-Estimation-from-a-Single-Image-in-Unseen-Indoor-Scene"><a href="#FS-Depth-Focal-and-Scale-Depth-Estimation-from-a-Single-Image-in-Unseen-Indoor-Scene" class="headerlink" title="FS-Depth: Focal-and-Scale Depth Estimation from a Single Image in Unseen Indoor Scene"></a>FS-Depth: Focal-and-Scale Depth Estimation from a Single Image in Unseen Indoor Scene</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14624">http://arxiv.org/abs/2307.14624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengrui Wei, Meng Yang, Lei He, Nanning Zheng</li>
<li>for: The paper is written for predicting absolute depth maps from single images in real (unseen) indoor scenes, which is an ill-posed problem due to the scale-ambiguous and focal-ambiguous issues.</li>
<li>methods: The paper proposes a focal-and-scale depth estimation model that combines a relative depth estimation network and an absolute depth estimation network, with multi-scale features generated by mapping a single focal length value to focal length features and concatenating them with intermediate features of different scales.</li>
<li>results: The paper reports that the proposed model significantly improves the generalization ability of depth estimation by 41%&#x2F;13% (RMSE) with&#x2F;without data augmentation compared with five recent SOTAs, and well alleviates the deformation problem in 3D reconstruction, while maintaining the accuracy of depth estimation on the original NYUDv2.Here are the three information points in Simplified Chinese text:</li>
<li>for: 本文是为了预测真实的indoor scene中单个图像的绝对深度图而写的。</li>
<li>methods: 本文提出了一种 focal-and-scale 深度估算模型，它将relative depth estimation网络和绝对深度估算网络结合在一起，并通过将单个 focal length value 映射到 focal length features 并与不同尺度的 intermediate features  concatenate 而生成多个尺度的特征。</li>
<li>results: 本文发现，提出的模型可以对不同的indoor scene中单个图像进行绝对深度估算，并且可以提高generalization能力by 41%&#x2F;13% (RMSE)  compared with five recent SOTAs，同时也可以解决3D重建中的扭曲问题，而不会影响原始 NYUDv2 中的精度。<details>
<summary>Abstract</summary>
It has long been an ill-posed problem to predict absolute depth maps from single images in real (unseen) indoor scenes. We observe that it is essentially due to not only the scale-ambiguous problem but also the focal-ambiguous problem that decreases the generalization ability of monocular depth estimation. That is, images may be captured by cameras of different focal lengths in scenes of different scales. In this paper, we develop a focal-and-scale depth estimation model to well learn absolute depth maps from single images in unseen indoor scenes. First, a relative depth estimation network is adopted to learn relative depths from single images with diverse scales/semantics. Second, multi-scale features are generated by mapping a single focal length value to focal length features and concatenating them with intermediate features of different scales in relative depth estimation. Finally, relative depths and multi-scale features are jointly fed into an absolute depth estimation network. In addition, a new pipeline is developed to augment the diversity of focal lengths of public datasets, which are often captured with cameras of the same or similar focal lengths. Our model is trained on augmented NYUDv2 and tested on three unseen datasets. Our model considerably improves the generalization ability of depth estimation by 41%/13% (RMSE) with/without data augmentation compared with five recent SOTAs and well alleviates the deformation problem in 3D reconstruction. Notably, our model well maintains the accuracy of depth estimation on original NYUDv2.
</details>
<details>
<summary>摘要</summary>
traditional Chinese:传统的问题是从单一图像中预测绝对深度地图，特别是在未见的室内场景中。我们观察到，这主要是因为scale-ambiguous problem和focal-ambiguous problem的共同作用，这导致单一图像中的深度估计缺乏普遍化能力。 Specifically, images may be captured by cameras of different focal lengths in scenes of different scales. In this paper, we develop a focal-and-scale depth estimation model to well learn absolute depth maps from single images in unseen indoor scenes. First, a relative depth estimation network is adopted to learn relative depths from single images with diverse scales/semantics. Second, multi-scale features are generated by mapping a single focal length value to focal length features and concatenating them with intermediate features of different scales in relative depth estimation. Finally, relative depths and multi-scale features are jointly fed into an absolute depth estimation network. In addition, a new pipeline is developed to augment the diversity of focal lengths of public datasets, which are often captured with cameras of the same or similar focal lengths. Our model is trained on augmented NYUDv2 and tested on three unseen datasets. Our model considerably improves the generalization ability of depth estimation by 41%/13% (RMSE) with/without data augmentation compared with five recent SOTAs and well alleviates the deformation problem in 3D reconstruction. Notably, our model well maintains the accuracy of depth estimation on original NYUDv2.Simplified Chinese:历史上，预测单一图像中的绝对深度地图是一个长期存在的问题。我们发现，这主要是因为scale-ambiguous problem和focal-ambiguous problem的共同作用，导致单个图像中的深度估计缺乏普遍化能力。Specifically, images may be captured by cameras of different focal lengths in scenes of different scales. In this paper, we develop a focal-and-scale depth estimation model to well learn absolute depth maps from single images in unseen indoor scenes. First, a relative depth estimation network is adopted to learn relative depths from single images with diverse scales/semantics. Second, multi-scale features are generated by mapping a single focal length value to focal length features and concatenating them with intermediate features of different scales in relative depth estimation. Finally, relative depths and multi-scale features are jointly fed into an absolute depth estimation network. In addition, a new pipeline is developed to augment the diversity of focal lengths of public datasets, which are often captured with cameras of the same or similar focal lengths. Our model is trained on augmented NYUDv2 and tested on three unseen datasets. Our model considerably improves the generalization ability of depth estimation by 41%/13% (RMSE) with/without data augmentation compared with five recent SOTAs and well alleviates the deformation problem in 3D reconstruction. Notably, our model well maintains the accuracy of depth estimation on original NYUDv2.
</details></li>
</ul>
<hr>
<h2 id="NeRF-Det-Learning-Geometry-Aware-Volumetric-Representation-for-Multi-View-3D-Object-Detection"><a href="#NeRF-Det-Learning-Geometry-Aware-Volumetric-Representation-for-Multi-View-3D-Object-Detection" class="headerlink" title="NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection"></a>NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14620">http://arxiv.org/abs/2307.14620</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/nerf-det">https://github.com/facebookresearch/nerf-det</a></li>
<li>paper_authors: Chenfeng Xu, Bichen Wu, Ji Hou, Sam Tsai, Ruilong Li, Jialiang Wang, Wei Zhan, Zijian He, Peter Vajda, Kurt Keutzer, Masayoshi Tomizuka</li>
<li>for: 本研究旨在提出一种基于NeRF的indoor三维检测方法，使用posedRGB图像作为输入，并且能够提高三维检测性能。</li>
<li>methods: 本方法使用NeRF进行三维场景的直接估计，并且引入了足够的geometry约束来提高NeRF-MLP的通用性。此外，我们在检测和NeRF分支之间引入了共享的MLP层，使得NeRF能够快速适应检测任务，并生成具有geometry感知的体积表示。</li>
<li>results: 根据ScanNet和ARKITScenes测试集，我们的方法在对比之下，比前一代方法提高了3.9 mAP和3.1 mAP。我们还提供了广泛的分析，以解释NeRF-Det如何工作。由于我们的共同训练设计，NeRF-Det能够在未看过场景时进行准确的检测、视图合成和深度估计任务，无需每个场景进行优化。代码可以在\url{<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/NeRF-Det%7D%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/facebookresearch/NeRF-Det}上获取。</a><details>
<summary>Abstract</summary>
We present NeRF-Det, a novel method for indoor 3D detection with posed RGB images as input. Unlike existing indoor 3D detection methods that struggle to model scene geometry, our method makes novel use of NeRF in an end-to-end manner to explicitly estimate 3D geometry, thereby improving 3D detection performance. Specifically, to avoid the significant extra latency associated with per-scene optimization of NeRF, we introduce sufficient geometry priors to enhance the generalizability of NeRF-MLP. Furthermore, we subtly connect the detection and NeRF branches through a shared MLP, enabling an efficient adaptation of NeRF to detection and yielding geometry-aware volumetric representations for 3D detection. Our method outperforms state-of-the-arts by 3.9 mAP and 3.1 mAP on the ScanNet and ARKITScenes benchmarks, respectively. We provide extensive analysis to shed light on how NeRF-Det works. As a result of our joint-training design, NeRF-Det is able to generalize well to unseen scenes for object detection, view synthesis, and depth estimation tasks without requiring per-scene optimization. Code is available at \url{https://github.com/facebookresearch/NeRF-Det}.
</details>
<details>
<summary>摘要</summary>
我们提出了NeRF-Det方法，用于indoor三维检测，输入poseRGB图像。与现有的indoor三维检测方法不同，我们的方法通过endre-to-end的方式使用NeRF来显式地估计Scene geometry，从而改善三维检测性能。具体来说，为了避免每个场景优化NeRF的显著额外延迟，我们引入了充分的geometry priors，以提高NeRF-MLP的通用性。此外，我们在检测和NeRF分支之间设置了共享的MLP，使得NeRF能够高效地适应检测，并生成具有三维特征的 объем表示。我们的方法在ScanNet和ARKITScenes测试集上比前STATE-OF-THE-ART高出3.9 mAP和3.1 mAP。我们提供了广泛的分析，以解释NeRF-Det如何工作。由于我们的联合训练设计，NeRF-Det能够通过不需要每个场景优化来泛化到未看到的场景，进行对象检测、视synthesis和深度估计任务。代码可以在 \url{https://github.com/facebookresearch/NeRF-Det} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Multiscale-Dynamic-Graph-Representation-for-Biometric-Recognition-with-Occlusions"><a href="#Multiscale-Dynamic-Graph-Representation-for-Biometric-Recognition-with-Occlusions" class="headerlink" title="Multiscale Dynamic Graph Representation for Biometric Recognition with Occlusions"></a>Multiscale Dynamic Graph Representation for Biometric Recognition with Occlusions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14617">http://arxiv.org/abs/2307.14617</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/renmin1991/dyamic-graph-representation">https://github.com/renmin1991/dyamic-graph-representation</a></li>
<li>paper_authors: Min Ren, Yunlong Wang, Yuhao Zhu, Kunbo Zhang, Zhenan Sun</li>
<li>for: 提高生物认证中的遮挡问题解决方法</li>
<li>methods: 提议一种 integrate CNN 和图模型的统一框架，通过动态图匹配和多尺度策略来抑制遮挡部分</li>
<li>results: 对比基eline方法，提出的方法在自然和遮挡 simulate 两种情况下都显示出了明显的提高，具体来说是boosting 识别率。<details>
<summary>Abstract</summary>
Occlusion is a common problem with biometric recognition in the wild. The generalization ability of CNNs greatly decreases due to the adverse effects of various occlusions. To this end, we propose a novel unified framework integrating the merits of both CNNs and graph models to overcome occlusion problems in biometric recognition, called multiscale dynamic graph representation (MS-DGR). More specifically, a group of deep features reflected on certain subregions is recrafted into a feature graph (FG). Each node inside the FG is deemed to characterize a specific local region of the input sample, and the edges imply the co-occurrence of non-occluded regions. By analyzing the similarities of the node representations and measuring the topological structures stored in the adjacent matrix, the proposed framework leverages dynamic graph matching to judiciously discard the nodes corresponding to the occluded parts. The multiscale strategy is further incorporated to attain more diverse nodes representing regions of various sizes. Furthermore, the proposed framework exhibits a more illustrative and reasonable inference by showing the paired nodes. Extensive experiments demonstrate the superiority of the proposed framework, which boosts the accuracy in both natural and occlusion-simulated cases by a large margin compared with that of baseline methods.
</details>
<details>
<summary>摘要</summary>
干扰是生物认证中常见的问题。通用的Convolutional Neural Networks (CNNs) 在不同的干扰情况下 exhibit 很差的泛化能力。为解决这个问题，我们提出了一种新的统一框架，即多尺度动态图表示 (MS-DGR)。更具体地说，一组深度特征在某些子区域上反射后，被重新拼接成一个特征图 (FG)。每个节点在 FG 中都代表了特定的本地区域，而边则表示了不受 occlusion 影响的区域之间的协同关系。通过分析节点表示的相似性和计算邻域矩阵中的 topological 结构，我们的框架通过动态图匹配来舍弃 occlusion 部分的节点。我们还在框架中采用多尺度策略，以获得更多的不同尺度的节点，代表不同大小的区域。此外，我们的框架可以更直观地显示对应的节点对，从而提供更直观的推理。广泛的实验表明，我们的方法可以在自然和干扰 simulate 的情况下，提高了识别率，相比基eline 方法，提高了大幅度。
</details></li>
</ul>
<hr>
<h2 id="GenCo-An-Auxiliary-Generator-from-Contrastive-Learning-for-Enhanced-Few-Shot-Learning-in-Remote-Sensing"><a href="#GenCo-An-Auxiliary-Generator-from-Contrastive-Learning-for-Enhanced-Few-Shot-Learning-in-Remote-Sensing" class="headerlink" title="GenCo: An Auxiliary Generator from Contrastive Learning for Enhanced Few-Shot Learning in Remote Sensing"></a>GenCo: An Auxiliary Generator from Contrastive Learning for Enhanced Few-Shot Learning in Remote Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14612">http://arxiv.org/abs/2307.14612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Wu, Naira Hovakimyan, Jennifer Hobbs</li>
<li>for: 提高远程感知和地球观测中的分类和 semantic segmentation 任务中的少量示例学习性能。</li>
<li>methods: 利用对冲学习框架（GenCo）进行预训练，同时允许特征样本的变体探索。</li>
<li>results: 在 Agriculture-Vision 和 EuroSAT 两个关键的远程感知数据集上，我们的方法比纯粹的超参数训练得到更好的性能，并在 semantic segmentation 任务上达到了最佳效果。<details>
<summary>Abstract</summary>
Classifying and segmenting patterns from a limited number of examples is a significant challenge in remote sensing and earth observation due to the difficulty in acquiring accurately labeled data in large quantities. Previous studies have shown that meta-learning, which involves episodic training on query and support sets, is a promising approach. However, there has been little attention paid to direct fine-tuning techniques. This paper repurposes contrastive learning as a pre-training method for few-shot learning for classification and semantic segmentation tasks. Specifically, we introduce a generator-based contrastive learning framework (GenCo) that pre-trains backbones and simultaneously explores variants of feature samples. In fine-tuning, the auxiliary generator can be used to enrich limited labeled data samples in feature space. We demonstrate the effectiveness of our method in improving few-shot learning performance on two key remote sensing datasets: Agriculture-Vision and EuroSAT. Empirically, our approach outperforms purely supervised training on the nearly 95,000 images in Agriculture-Vision for both classification and semantic segmentation tasks. Similarly, the proposed few-shot method achieves better results on the land-cover classification task on EuroSAT compared to the results obtained from fully supervised model training on the dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified ChineseClassifying and segmenting patterns from a limited number of examples is a significant challenge in remote sensing and earth observation due to the difficulty in acquiring accurately labeled data in large quantities. Previous studies have shown that meta-learning, which involves episodic training on query and support sets, is a promising approach. However, there has been little attention paid to direct fine-tuning techniques. This paper repurposes contrastive learning as a pre-training method for few-shot learning for classification and semantic segmentation tasks. Specifically, we introduce a generator-based contrastive learning framework (GenCo) that pre-trains backbones and simultaneously explores variants of feature samples. In fine-tuning, the auxiliary generator can be used to enrich limited labeled data samples in feature space. We demonstrate the effectiveness of our method in improving few-shot learning performance on two key remote sensing datasets: Agriculture-Vision and EuroSAT. Empirically, our approach outperforms purely supervised training on the nearly 95,000 images in Agriculture-Vision for both classification and semantic segmentation tasks. Similarly, the proposed few-shot method achieves better results on the land-cover classification task on EuroSAT compared to the results obtained from fully supervised model training on the dataset.Translation:难以从有限数量的示例中提取模式的分类和 semantic segmentation 是Remote sensing 和 Earth observation 领域中的一大挑战，因为获取大量高精度标注数据具有很大的困难。先前的研究表明，meta-learning，即在查询和支持集上进行 episodic 训练，是一种有前途的方法。然而，直接精度调整技术几乎未获得关注。本文借鉴了对准学习，将它作为预训练方法，以提高少量示例学习的分类和 semantic segmentation 性能。特别是，我们引入了生成器基于对准学习框架（GenCo），在预训练期间同时探索特征样本的变体。在细化中，可以使用auxiliary生成器来增加有限量标注数据样本在特征空间中。我们通过实验证明，我们的方法可以在 Agriculture-Vision 和 EuroSAT 两个重要的 Remote sensing 数据集上提高少量示例学习性能。empirically，我们的方法在 Agriculture-Vision 中的分类和 semantic segmentation 任务上超过了完全监督训练 nearly 95,000 张图像的结果。类似地，我们提出的几shot 方法在 EuroSAT 上的 land-cover 分类任务上超过了完全监督模型训练 dataset 上的结果。
</details></li>
</ul>
<hr>
<h2 id="TextManiA-Enriching-Visual-Feature-by-Text-driven-Manifold-Augmentation"><a href="#TextManiA-Enriching-Visual-Feature-by-Text-driven-Manifold-Augmentation" class="headerlink" title="TextManiA: Enriching Visual Feature by Text-driven Manifold Augmentation"></a>TextManiA: Enriching Visual Feature by Text-driven Manifold Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14611">http://arxiv.org/abs/2307.14611</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moon Ye-Bin, Jisoo Kim, Hongyeob Kim, Kilho Son, Tae-Hyun Oh</li>
<li>for: 提高欠发达数据集中的泛化能力，即使面临着类别分布偏斜问题。</li>
<li>methods: 提出了一种基于文本的替换增强方法，通过使用可读性强的视觉感知词（attributes）来增强视觉特征空间的Semantic层次。</li>
<li>results: 实验表明，TextManiA可以在缺乏样本的情况下具有很高的泛化能力，并且可以与标准混合方法相结合使用，以提高泛化能力。<details>
<summary>Abstract</summary>
Recent label mix-based augmentation methods have shown their effectiveness in generalization despite their simplicity, and their favorable effects are often attributed to semantic-level augmentation. However, we found that they are vulnerable to highly skewed class distribution, because scarce data classes are rarely sampled for inter-class perturbation. We propose TextManiA, a text-driven manifold augmentation method that semantically enriches visual feature spaces, regardless of data distribution. TextManiA augments visual data with intra-class semantic perturbation by exploiting easy-to-understand visually mimetic words, i.e., attributes. To this end, we bridge between the text representation and a target visual feature space, and propose an efficient vector augmentation. To empirically support the validity of our design, we devise two visualization-based analyses and show the plausibility of the bridge between two different modality spaces. Our experiments demonstrate that TextManiA is powerful in scarce samples with class imbalance as well as even distribution. We also show compatibility with the label mix-based approaches in evenly distributed scarce data.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)近期的标签混合基于扩展方法已经表现出了一致性，即使它们简单，它们的良好效果通常归结于semantic-level的扩展。然而，我们发现它们对高度不均衡的类分布非常敏感，因为罕见的数据类很少被采样为间类扰动。我们提出了TextManiA，一种基于文本的扩展方法，它可以在不同的数据分布下增强视觉特征空间的 semantic。TextManiA通过利用易于理解的视觉效果词，例如特征，进行内类semantic扰动。为了实现这一点，我们将文本表示与目标视觉特征空间之间建立了一个桥梁，并提出了一种效率的向量扩展。为了证明我们的设计的有效性，我们设计了两种视觉基于分析和展示了两个不同的模态空间之间的桥梁的可能性。我们的实验表明，TextManiA在罕见样本中的类均衡和均衡分布中都具有强大的泛化能力。我们还证明了TextManiA与标签混合基于方法在均衡分布中的罕见样本中兼容。
</details></li>
</ul>
<hr>
<h2 id="A-Weakly-Supervised-Segmentation-Network-Embedding-Cross-scale-Attention-Guidance-and-Noise-sensitive-Constraint-for-Detecting-Tertiary-Lymphoid-Structures-of-Pancreatic-Tumors"><a href="#A-Weakly-Supervised-Segmentation-Network-Embedding-Cross-scale-Attention-Guidance-and-Noise-sensitive-Constraint-for-Detecting-Tertiary-Lymphoid-Structures-of-Pancreatic-Tumors" class="headerlink" title="A Weakly Supervised Segmentation Network Embedding Cross-scale Attention Guidance and Noise-sensitive Constraint for Detecting Tertiary Lymphoid Structures of Pancreatic Tumors"></a>A Weakly Supervised Segmentation Network Embedding Cross-scale Attention Guidance and Noise-sensitive Constraint for Detecting Tertiary Lymphoid Structures of Pancreatic Tumors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14603">http://arxiv.org/abs/2307.14603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingxue Wang, Liwen Zou, Jun Chen, Yingying Cao, Zhenghua Cai, Yudong Qiu, Liang Mao, Zhongqiu Wang, Jingya Chen, Luying Gui, Xiaoping Yang</li>
<li>for: 检测胰腺癌的特Point是否存在，以便更好地诊断和治疗胰腺癌患者。</li>
<li>methods: 我们提议一种几何学学习方法， combinig着一个预训练的核型分割模型和域随机网络来识别лимфоци特 Point。然后，我们设立了一个跨度级别注意力引导机制，通过同时学习原始历史病理图像的粗细度特征和我们设计的лимфоци特 Point的密度注意力来帮助提高分割精度。</li>
<li>results: 我们的方法在两个收集的数据集上进行了实验，并证明了与现有分割基于深度学习算法相比，我们的方法可以更高的检测精度。此外，我们还应用了我们的方法来研究胰腺癌的特Point密度与周围血管渗透的关系，并获得了一些临床统计结果。<details>
<summary>Abstract</summary>
The presence of tertiary lymphoid structures (TLSs) on pancreatic pathological images is an important prognostic indicator of pancreatic tumors. Therefore, TLSs detection on pancreatic pathological images plays a crucial role in diagnosis and treatment for patients with pancreatic tumors. However, fully supervised detection algorithms based on deep learning usually require a large number of manual annotations, which is time-consuming and labor-intensive. In this paper, we aim to detect the TLSs in a manner of few-shot learning by proposing a weakly supervised segmentation network. We firstly obtain the lymphocyte density maps by combining a pretrained model for nuclei segmentation and a domain adversarial network for lymphocyte nuclei recognition. Then, we establish a cross-scale attention guidance mechanism by jointly learning the coarse-scale features from the original histopathology images and fine-scale features from our designed lymphocyte density attention. A noise-sensitive constraint is introduced by an embedding signed distance function loss in the training procedure to reduce tiny prediction errors. Experimental results on two collected datasets demonstrate that our proposed method significantly outperforms the state-of-the-art segmentation-based algorithms in terms of TLSs detection accuracy. Additionally, we apply our method to study the congruent relationship between the density of TLSs and peripancreatic vascular invasion and obtain some clinically statistical results.
</details>
<details>
<summary>摘要</summary>
《文献》中提到的“次级血液结构（TLS）”在胰腺病理图像中的存在是诊断和治疗胰腺肿瘤患者的重要预测指标。因此，TLS的检测在胰腺病理图像上扮演着关键的角色。然而，通常需要大量的手动标注，这是时间consuming和劳动密集的。在这篇论文中，我们尝试通过几拍学习方法来检测TLS。我们首先使用预训练的核仁分 segmentation 模型和域 adversarial network来确定血液细胞核的位置。然后，我们实现了跨比例注意力导航机制，通过同时学习原始 histopathology 图像的粗细度特征和我们设计的血液细胞注意力来确定TLS的位置。在训练过程中，我们引入了一种噪声敏感的约束，通过嵌入签名距离函数损失来减少微scopic prediction error。实验结果表明，我们提出的方法在两个收集的数据集上显著超过了现有的分类基于深度学习的 segmentation 算法。此外，我们应用我们的方法研究了TLS的density与周围胰腺血管浸润之间的相互关系，并获得了一些临床统计结果。
</details></li>
</ul>
<hr>
<h2 id="FakeTracer-Proactively-Defending-Against-Face-swap-DeepFakes-via-Implanting-Traces-in-Training"><a href="#FakeTracer-Proactively-Defending-Against-Face-swap-DeepFakes-via-Implanting-Traces-in-Training" class="headerlink" title="FakeTracer: Proactively Defending Against Face-swap DeepFakes via Implanting Traces in Training"></a>FakeTracer: Proactively Defending Against Face-swap DeepFakes via Implanting Traces in Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14593">http://arxiv.org/abs/2307.14593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pu Sun, Honggang Qi, Yuezun Li, Siwei Lyu</li>
<li>for: 防止 DeepFake 技术的违用，保护个人隐私</li>
<li>methods: 植入训练过程中的特征 traces，使 DeepFake 模型学习含有可持续和可除去的特征</li>
<li>results: 对 Celeb-DF 数据集进行了广泛的实验，证明了我们的方法可以有效地防止 face-swap DeepFake<details>
<summary>Abstract</summary>
Face-swap DeepFake is an emerging AI-based face forgery technique that can replace the original face in a video with a generated face of the target identity while retaining consistent facial attributes such as expression and orientation. Due to the high privacy of faces, the misuse of this technique can raise severe social concerns, drawing tremendous attention to defend against DeepFakes recently. In this paper, we describe a new proactive defense method called FakeTracer to expose face-swap DeepFakes via implanting traces in training. Compared to general face-synthesis DeepFake, the face-swap DeepFake is more complex as it involves identity change, is subjected to the encoding-decoding process, and is trained unsupervised, increasing the difficulty of implanting traces into the training phase. To effectively defend against face-swap DeepFake, we design two types of traces, sustainable trace (STrace) and erasable trace (ETrace), to be added to training faces. During the training, these manipulated faces affect the learning of the face-swap DeepFake model, enabling it to generate faces that only contain sustainable traces. In light of these two traces, our method can effectively expose DeepFakes by identifying them. Extensive experiments are conducted on the Celeb-DF dataset, compared with recent passive and proactive defense methods, and are studied thoroughly regarding various factors, corroborating the efficacy of our method on defending against face-swap DeepFake.
</details>
<details>
<summary>摘要</summary>
“深圳技术：Face-swap DeepFake是一种新兴的人工智能技术，可以将原始影片中的面部替换为目标身份的生成面部，保留面部特征如表情和方向。由于面部隐私问题，这种技术可能会导致严重的社会影响，因此近期引起了广泛关注防范 DeepFakes。在这篇论文中，我们描述了一种新的积极防范方法，称为FakeTracer，可以透过将 traces 添加到训练过程中，将 face-swap DeepFake 曝光。相比于一般的面部合成 DeepFake，face-swap DeepFake 更加复杂，因为它涉及到身份变更、编码-解码过程和无监督训练，这使得在训练过程中将 traces 添加到面部上更加困难。为了有效防范 face-swap DeepFake，我们设计了两种 traces，可持续 trace (STrace) 和可清除 trace (ETrace)，并将它们添加到训练面部。在训练过程中，这些改进的面部对 face-swap DeepFake 模型的学习有很大影响，使其能够生成包含可持续 traces 的面部。这些两种 traces 使我们的方法能够有效地曝光 DeepFakes，通过识别它们。我们在 Celeb-DF 数据集上进行了广泛的实验，与最近的预防和反击方法进行比较，并且对不同的因素进行了深入的研究，证明了我们的方法在防范 face-swap DeepFake 方面的效果。”
</details></li>
</ul>
<hr>
<h2 id="MCPA-Multi-scale-Cross-Perceptron-Attention-Network-for-2D-Medical-Image-Segmentation"><a href="#MCPA-Multi-scale-Cross-Perceptron-Attention-Network-for-2D-Medical-Image-Segmentation" class="headerlink" title="MCPA: Multi-scale Cross Perceptron Attention Network for 2D Medical Image Segmentation"></a>MCPA: Multi-scale Cross Perceptron Attention Network for 2D Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14588">http://arxiv.org/abs/2307.14588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/simonustc/mcpa-for-2d-medical-image-segmentation">https://github.com/simonustc/mcpa-for-2d-medical-image-segmentation</a></li>
<li>paper_authors: Liang Xu, Mingxiao Chen, Yi Cheng, Pengfei Shao, Shuwei Shen, Peng Yao, Ronald X. Xu</li>
<li>for: 这个研究旨在提出一个基于Convolutional Neural Networks (CNN)的双重网络模型，以提高医疗影像分类 task的性能。</li>
<li>methods: 本研究使用了Transformer模组来强化UNet架构，以更好地捕捉医疗影像中的全球相依性。并且引入了多对多普尔投影模组，以实现各维度特征之间的协调。</li>
<li>results: 实验结果显示，这个MCPA模型在多个公开的医疗影像数据集上达到了州际性能。code可以在<a target="_blank" rel="noopener" href="https://github.com/simonustc/MCPA-for-2D-Medical-Image-Segmentation%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/simonustc/MCPA-for-2D-Medical-Image-Segmentation上获取。</a><details>
<summary>Abstract</summary>
The UNet architecture, based on Convolutional Neural Networks (CNN), has demonstrated its remarkable performance in medical image analysis. However, it faces challenges in capturing long-range dependencies due to the limited receptive fields and inherent bias of convolutional operations. Recently, numerous transformer-based techniques have been incorporated into the UNet architecture to overcome this limitation by effectively capturing global feature correlations. However, the integration of the Transformer modules may result in the loss of local contextual information during the global feature fusion process. To overcome these challenges, we propose a 2D medical image segmentation model called Multi-scale Cross Perceptron Attention Network (MCPA). The MCPA consists of three main components: an encoder, a decoder, and a Cross Perceptron. The Cross Perceptron first captures the local correlations using multiple Multi-scale Cross Perceptron modules, facilitating the fusion of features across scales. The resulting multi-scale feature vectors are then spatially unfolded, concatenated, and fed through a Global Perceptron module to model global dependencies. Furthermore, we introduce a Progressive Dual-branch Structure to address the semantic segmentation of the image involving finer tissue structures. This structure gradually shifts the segmentation focus of MCPA network training from large-scale structural features to more sophisticated pixel-level features. We evaluate our proposed MCPA model on several publicly available medical image datasets from different tasks and devices, including the open large-scale dataset of CT (Synapse), MRI (ACDC), fundus camera (DRIVE, CHASE_DB1, HRF), and OCTA (ROSE). The experimental results show that our MCPA model achieves state-of-the-art performance. The code is available at https://github.com/simonustc/MCPA-for-2D-Medical-Image-Segmentation.
</details>
<details>
<summary>摘要</summary>
UNet 架构，基于卷积神经网络（CNN），在医疗图像分析中表现出色。然而，它在捕捉长距离依赖关系方面面临挑战，因为卷积操作具有局部捕捉区域和内置偏见。最近，许多基于变换器技术的方法被 incorporated into UNet 架构，以解决这些限制，并有效地捕捉全局特征相关性。然而，将变换器模块 интеGRATED 到 UNet 架构可能会导致全局特征卷积过程中失去本地Contextual information。为了解决这些挑战，我们提出了一种名为 Multi-scale Cross Perceptron Attention Network (MCPA)的2D医疗图像分类模型。MCPA 模型由三个主要组成部分组成：编码器、解码器和 Cross Perceptron。Cross Perceptron 首先使用多个 Multi-scale Cross Perceptron 模块捕捉本地相关性，以便在不同尺度上进行特征整合。得到的多个尺度特征向量然后在空间上展开、 concatenate 并经过全球 Perceptron 模块来建模全局依赖关系。此外，我们还引入了一种进步的双分支结构，以Addressing the semantic segmentation of the image involving finer tissue structures。这种结构逐渐调整 MCPA 网络训练的 segmentation 焦点，从大规模结构特征向 pixel-level 特征。我们在 Synapse、ACDC、DRIVE、CHASE_DB1 和 HRF 等公共可用的医疗图像数据集上进行了实验，结果显示，我们的 MCPA 模型实现了状态的最佳性能。代码可以在 <https://github.com/simonustc/MCPA-for-2D-Medical-Image-Segmentation> 中获取。
</details></li>
</ul>
<hr>
<h2 id="Neural-Representation-Based-Method-for-Metal-induced-Artifact-Reduction-in-Dental-CBCT-Imaging"><a href="#Neural-Representation-Based-Method-for-Metal-induced-Artifact-Reduction-in-Dental-CBCT-Imaging" class="headerlink" title="Neural Representation-Based Method for Metal-induced Artifact Reduction in Dental CBCT Imaging"></a>Neural Representation-Based Method for Metal-induced Artifact Reduction in Dental CBCT Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14579">http://arxiv.org/abs/2307.14579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyoung Suk Park, Kiwan Jeon, Jin Keun Seo</li>
<li>for: 这个研究旨在提出一种新的 dental cone-beam computed tomography (CBCT) 重建方法，以减少常见的金属引起的artefacts，特别是在存在多种金属设备的情况下。</li>
<li>methods: 该研究提议使用 implicit neural network 生成两个不同的 tomographic 图像，其中一个表示特定能量层的灰度分布，另一个表示各色 X-ray 束在不同能量层的非线性强化因素。与传统的 CT 重建技术不同，该方法仅基于 Beer–Lambert 定律，从而有效避免在传统方法中通常实现的背投过程中产生金属引起的artefacts。</li>
<li>results: 广泛的实验评估表明，提议的方法可以有效减少金属引起的artefacts，并提供高质量的图像重建，从而强调第二个图像在捕捉非线性强化因素方面的重要性。<details>
<summary>Abstract</summary>
This study introduces a novel reconstruction method for dental cone-beam computed tomography (CBCT), focusing on effectively reducing metal-induced artifacts commonly encountered in the presence of prevalent metallic implants. Despite significant progress in metal artifact reduction techniques, challenges persist owing to the intricate physical interactions between polychromatic X-ray beams and metal objects, which are further compounded by the additional effects associated with metal-tooth interactions and factors specific to the dental CBCT data environment. To overcome these limitations, we propose an implicit neural network that generates two distinct and informative tomographic images. One image represents the monochromatic attenuation distribution at a specific energy level, whereas the other captures the nonlinear beam-hardening factor resulting from the polychromatic nature of X-ray beams. In contrast to existing CT reconstruction techniques, the proposed method relies exclusively on the Beer--Lambert law, effectively preventing the generation of metal-induced artifacts during the backprojection process commonly implemented in conventional methods. Extensive experimental evaluations demonstrate that the proposed method effectively reduces metal artifacts while providing high-quality image reconstructions, thus emphasizing the significance of the second image in capturing the nonlinear beam-hardening factor.
</details>
<details>
<summary>摘要</summary>
To overcome these limitations, the proposed method uses an implicit neural network to generate two distinct and informative tomographic images. One image represents the monochromatic attenuation distribution at a specific energy level, while the other captures the nonlinear beam-hardening factor resulting from the polychromatic nature of X-ray beams. Unlike existing CT reconstruction techniques, the proposed method relies exclusively on the Beer-Lambert law, effectively preventing the generation of metal-induced artifacts during the backprojection process commonly implemented in conventional methods.Experimental evaluations demonstrate that the proposed method effectively reduces metal artifacts while providing high-quality image reconstructions, highlighting the significance of the second image in capturing the nonlinear beam-hardening factor.
</details></li>
</ul>
<hr>
<h2 id="GADER-GAit-DEtection-and-Recognition-in-the-Wild"><a href="#GADER-GAit-DEtection-and-Recognition-in-the-Wild" class="headerlink" title="GADER: GAit DEtection and Recognition in the Wild"></a>GADER: GAit DEtection and Recognition in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14578">http://arxiv.org/abs/2307.14578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Guo, Cheng Peng, Ram Prabhakar, Chun Pong Lau, Rama Chellappa</li>
<li>for: 人体认证，特别是在开放场景下进行人体识别和验证</li>
<li>methods: 使用Double Helical Signature检测人体运动段落，并借鉴RGB认识模型进行学习表征，以实现更高的人体识别精度</li>
<li>results: 在室内和室外数据集上进行了广泛的实验，并达到了与状态艺前的最佳性能，特别是在无结构、长距离场景下的识别精度提高20.6%<details>
<summary>Abstract</summary>
Gait recognition holds the promise of robustly identifying subjects based on their walking patterns instead of color information. While previous approaches have performed well for curated indoor scenes, they have significantly impeded applicability in unconstrained situations, e.g. outdoor, long distance scenes. We propose an end-to-end GAit DEtection and Recognition (GADER) algorithm for human authentication in challenging outdoor scenarios. Specifically, GADER leverages a Double Helical Signature to detect the fragment of human movement and incorporates a novel gait recognition method, which learns representations by distilling from an auxiliary RGB recognition model. At inference time, GADER only uses the silhouette modality but benefits from a more robust representation. Extensive experiments on indoor and outdoor datasets demonstrate that the proposed method outperforms the State-of-The-Arts for gait recognition and verification, with a significant 20.6% improvement on unconstrained, long distance scenes.
</details>
<details>
<summary>摘要</summary>
“门槛识别”可以强大地识别基于行走模式而不是颜色信息。在前一些方法中，它们在受控环境中表现得非常好，但是在无法控制的场景中，它们受到了严重的限制，例如：开放场景、长距离场景。我们提出了一个终端到端的“人体识别和验证”（GADER）算法，用于人类身份验证在具有挑战的开放场景中。具体来说，GADER 使用了一个Double Helical Signature来探测人类运动的残留部分，并将一个新的步行识别方法给运用到auxiliary RGB识别模型中。在推理时间，GADER 仅使用了 silhouette 模式，但是它们可以从更加稳定的表现中获益。实验结果显示，提出的方法在受控和无法控制的场景中都有着优秀的表现，与现有的State-of-The-Arts 有20.6%的提升。
</details></li>
</ul>
<hr>
<h2 id="Robust-Detection-Association-and-Localization-of-Vehicle-Lights-A-Context-Based-Cascaded-CNN-Approach-and-Evaluations"><a href="#Robust-Detection-Association-and-Localization-of-Vehicle-Lights-A-Context-Based-Cascaded-CNN-Approach-and-Evaluations" class="headerlink" title="Robust Detection, Association, and Localization of Vehicle Lights: A Context-Based Cascaded CNN Approach and Evaluations"></a>Robust Detection, Association, and Localization of Vehicle Lights: A Context-Based Cascaded CNN Approach and Evaluations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14571">http://arxiv.org/abs/2307.14571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshay Gopalkrishnan, Ross Greer, Maitrayee Keskar, Mohan Trivedi</li>
<li>for: 这篇论文是用于检测和识别汽车灯光的，以便实现安全自动驾驶任务。</li>
<li>methods: 本论文使用了一种基于CNN的方法，将汽车灯光拟合为四个粗略的角度，以提高检测灯光的精度。</li>
<li>results:  experiments show that the proposed method can achieve an average distance error of 4.77 pixels from the ground truth corner, which is about 16.33% of the size of the vehicle light on average.Here’s the full text in Simplified Chinese:</li>
<li>for: 这篇论文是用于检测和识别汽车灯光的，以便实现安全自动驾驶任务。</li>
<li>methods: 本论文使用了一种基于CNN的方法，将汽车灯光拟合为四个粗略的角度，以提高检测灯光的精度。</li>
<li>results:  experiments show that the proposed method can achieve an average distance error of 4.77 pixels from the ground truth corner, which is about 16.33% of the size of the vehicle light on average。<details>
<summary>Abstract</summary>
Vehicle light detection, association, and localization are required for important downstream safe autonomous driving tasks, such as predicting a vehicle's light state to determine if the vehicle is making a lane change or turning. Currently, many vehicle light detectors use single-stage detectors which predict bounding boxes to identify a vehicle light, in a manner decoupled from vehicle instances. In this paper, we present a method for detecting a vehicle light given an upstream vehicle detection and approximation of a visible light's center. Our method predicts four approximate corners associated with each vehicle light. We experiment with CNN architectures, data augmentation, and contextual preprocessing methods designed to reduce surrounding-vehicle confusion. We achieve an average distance error from the ground truth corner of 4.77 pixels, about 16.33% of the size of the vehicle light on average. We train and evaluate our model on the LISA Lights Dataset, allowing us to thoroughly evaluate our vehicle light corner detection model on a large variety of vehicle light shapes and lighting conditions. We propose that this model can be integrated into a pipeline with vehicle detection and vehicle light center detection to make a fully-formed vehicle light detection network, valuable to identifying trajectory-informative signals in driving scenes.
</details>
<details>
<summary>摘要</summary>
自动驾驶需要车辆灯光检测、相关性和地理位置，以便完成重要的下游安全自动驾驶任务，如预测车辆灯光的状态，以确定车辆是否改变车道或转弯。现在，许多车辆灯光检测器使用单Stage检测器，以预测车辆灯光的 bounding box，并且与车辆实例分离。在这篇论文中，我们提出了一种用于检测车辆灯光的方法，给出了车辆灯光的四个约束角。我们对 CNN 架构、数据增强和上下文处理方法进行了实验，以降低周围车辆的混淆。我们在 LISA Lights 数据集上训练和评估我们的模型，可以充分评估我们的车辆灯光角度检测模型在不同的车辆灯光形状和照明条件下的性能。我们建议将这种模型纳入车辆检测和车辆灯光中心检测的管道，以创造一个完整的车辆灯光检测网络，有助于识别驾驶场景中的路径信号。
</details></li>
</ul>
<hr>
<h2 id="Physically-Plausible-3D-Human-Scene-Reconstruction-from-Monocular-RGB-Image-using-an-Adversarial-Learning-Approach"><a href="#Physically-Plausible-3D-Human-Scene-Reconstruction-from-Monocular-RGB-Image-using-an-Adversarial-Learning-Approach" class="headerlink" title="Physically Plausible 3D Human-Scene Reconstruction from Monocular RGB Image using an Adversarial Learning Approach"></a>Physically Plausible 3D Human-Scene Reconstruction from Monocular RGB Image using an Adversarial Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14570">http://arxiv.org/abs/2307.14570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandika Biswas, Kejie Li, Biplab Banerjee, Subhasis Chaudhuri, Hamid Rezatofighi</li>
<li>for: 这个论文的目的是提出一种基于学习的全息人景三维重建方法，以解决基于单色RGB图像的全息人景三维重建问题。</li>
<li>methods: 该方法使用图形学表示法，并通过对Scene中元素之间的相互作用进行学习，从训练数据自身学习场景元素之间的物理约束。</li>
<li>results: 该方法可以达到与优化基于方法相当的三维重建质量，而不需要执行批处理时间的优化。这使得该方法更适合机器人应用，如机器人导航等。<details>
<summary>Abstract</summary>
Holistic 3D human-scene reconstruction is a crucial and emerging research area in robot perception. A key challenge in holistic 3D human-scene reconstruction is to generate a physically plausible 3D scene from a single monocular RGB image. The existing research mainly proposes optimization-based approaches for reconstructing the scene from a sequence of RGB frames with explicitly defined physical laws and constraints between different scene elements (humans and objects). However, it is hard to explicitly define and model every physical law in every scenario. This paper proposes using an implicit feature representation of the scene elements to distinguish a physically plausible alignment of humans and objects from an implausible one. We propose using a graph-based holistic representation with an encoded physical representation of the scene to analyze the human-object and object-object interactions within the scene. Using this graphical representation, we adversarially train our model to learn the feasible alignments of the scene elements from the training data itself without explicitly defining the laws and constraints between them. Unlike the existing inference-time optimization-based approaches, we use this adversarially trained model to produce a per-frame 3D reconstruction of the scene that abides by the physical laws and constraints. Our learning-based method achieves comparable 3D reconstruction quality to existing optimization-based holistic human-scene reconstruction methods and does not need inference time optimization. This makes it better suited when compared to existing methods, for potential use in robotic applications, such as robot navigation, etc.
</details>
<details>
<summary>摘要</summary>
“整体3D人景重建是Robot感知领域中的关键和emerging研究领域。一个关键挑战是将单一RGB影像中的3D场景转换为物理可能的3D场景。现有的研究主要提出了基于优化的方法来从RGB影像序列中重建场景，并且明确定义了场景元素之间的物理法则和约束。但是，实际上很难明确地定义和模型每个场景中的物理法则。本文提出使用各元素的偏项特征来区别物理可能的人物和物品的平行配置和不可能的配置。我们提出使用图形基于的整体表示，将场景元素之间的物理表示编码到图形中，并通过对训练数据自身进行对抗学习，以学习场景元素之间的可能的平行配置。与现有的推理时间优化方法不同，我们使用这个对抗学习的模型来生成每帧3D重建结果，并且跟随物理法则和约束。我们的学习型方法与现有的优化型方法相比，具有更好的3D重建质量，并且不需要推理时间优化。这使得它更适合在Robot应用中使用，如Robot导航等。”
</details></li>
</ul>
<hr>
<h2 id="Towards-multi-modal-anatomical-landmark-detection-for-ultrasound-guided-brain-tumor-resection-with-contrastive-learning"><a href="#Towards-multi-modal-anatomical-landmark-detection-for-ultrasound-guided-brain-tumor-resection-with-contrastive-learning" class="headerlink" title="Towards multi-modal anatomical landmark detection for ultrasound-guided brain tumor resection with contrastive learning"></a>Towards multi-modal anatomical landmark detection for ultrasound-guided brain tumor resection with contrastive learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14523">http://arxiv.org/abs/2307.14523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soorena Salari, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao</li>
<li>for: 这个研究旨在提供一个新的整合学习框架，用于在 neurosurgery 中医疗影像注册中找到相匹配的附属标记。</li>
<li>methods: 这个方法使用了两个卷积神经网络，用于将 MRI 和 US 影像特征编码，以帮助匹配 US 影像 patch 中的相匹配标记在 MRI 中。</li>
<li>results: 研究结果显示，该方法可以实现高精度的附属标记检测，具体来说是 5.88+-4.79 mm 的平均标记检测精度，较之 SIFT 特征的 18.78+-4.77 mm 为低。<details>
<summary>Abstract</summary>
Homologous anatomical landmarks between medical scans are instrumental in quantitative assessment of image registration quality in various clinical applications, such as MRI-ultrasound registration for tissue shift correction in ultrasound-guided brain tumor resection. While manually identified landmark pairs between MRI and ultrasound (US) have greatly facilitated the validation of different registration algorithms for the task, the procedure requires significant expertise, labor, and time, and can be prone to inter- and intra-rater inconsistency. So far, many traditional and machine learning approaches have been presented for anatomical landmark detection, but they primarily focus on mono-modal applications. Unfortunately, despite the clinical needs, inter-modal/contrast landmark detection has very rarely been attempted. Therefore, we propose a novel contrastive learning framework to detect corresponding landmarks between MRI and intra-operative US scans in neurosurgery. Specifically, two convolutional neural networks were trained jointly to encode image features in MRI and US scans to help match the US image patch that contain the corresponding landmarks in the MRI. We developed and validated the technique using the public RESECT database. With a mean landmark detection accuracy of 5.88+-4.79 mm against 18.78+-4.77 mm with SIFT features, the proposed method offers promising results for MRI-US landmark detection in neurosurgical applications for the first time.
</details>
<details>
<summary>摘要</summary>
医学成像渠道之间的相似结构特征可以用于质量评估不同临床应用中的图像 региSTR的良好性，如MRI-ultrasound（US） региSTR用于脑肿瘤静脉 Correcting for tissue shift during ultrasound-guided brain tumor resection. Although manually identified landmark pairs between MRI and US have greatly facilitated the validation of different registration algorithms for this task, the procedure requires significant expertise, labor, and time, and can be prone to inter- and intra-rater inconsistency. To date, many traditional and machine learning approaches have been proposed for anatomical landmark detection, but they primarily focus on mono-modal applications. Unfortunately, despite the clinical needs, inter-modal/contrast landmark detection has very rarely been attempted. Therefore, we propose a novel contrastive learning framework to detect corresponding landmarks between MRI and intra-operative US scans in neurosurgery. Specifically, two convolutional neural networks were trained jointly to encode image features in MRI and US scans to help match the US image patch that contains the corresponding landmarks in the MRI. We developed and validated the technique using the public RESECT database. With a mean landmark detection accuracy of 5.88 ± 4.79 mm against 18.78 ± 4.77 mm with SIFT features, the proposed method offers promising results for MRI-US landmark detection in neurosurgical applications for the first time.
</details></li>
</ul>
<hr>
<h2 id="FocalErrorNet-Uncertainty-aware-focal-modulation-network-for-inter-modal-registration-error-estimation-in-ultrasound-guided-neurosurgery"><a href="#FocalErrorNet-Uncertainty-aware-focal-modulation-network-for-inter-modal-registration-error-estimation-in-ultrasound-guided-neurosurgery" class="headerlink" title="FocalErrorNet: Uncertainty-aware focal modulation network for inter-modal registration error estimation in ultrasound-guided neurosurgery"></a>FocalErrorNet: Uncertainty-aware focal modulation network for inter-modal registration error estimation in ultrasound-guided neurosurgery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14520">http://arxiv.org/abs/2307.14520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soorena Salari, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao<br>for: 本研究旨在提供一种 Deep Learning 技术，用于在 brain tumor 手术中评估 MRI-iUS  регистра结果的准确性。methods: 该技术基于 3D 焦点 modify 的深度学习方法，并使用 uncertainty 估计来评估 MRI-iUS REGISTRATION 错误的准确性。results: 在使用公共的 RESECT 临床数据库进行验证后，该算法可以实现 MRI-iUS REGISTRATION 错误的估计错误为 0.59+-0.57 mm。<details>
<summary>Abstract</summary>
In brain tumor resection, accurate removal of cancerous tissues while preserving eloquent regions is crucial to the safety and outcomes of the treatment. However, intra-operative tissue deformation (called brain shift) can move the surgical target and render the pre-surgical plan invalid. Intra-operative ultrasound (iUS) has been adopted to provide real-time images to track brain shift, and inter-modal (i.e., MRI-iUS) registration is often required to update the pre-surgical plan. Quality control for the registration results during surgery is important to avoid adverse outcomes, but manual verification faces great challenges due to difficult 3D visualization and the low contrast of iUS. Automatic algorithms are urgently needed to address this issue, but the problem was rarely attempted. Therefore, we propose a novel deep learning technique based on 3D focal modulation in conjunction with uncertainty estimation to accurately assess MRI-iUS registration errors for brain tumor surgery. Developed and validated with the public RESECT clinical database, the resulting algorithm can achieve an estimation error of 0.59+-0.57 mm.
</details>
<details>
<summary>摘要</summary>
在脑肿擦除手术中，准确地移除患有肿瘤的组织，保留功能区的安全和治疗结果是关键。然而，在手术中的组织弹性（脑移动）可能使手术目标移动，使原先的预治疗计划无效。使用实时ultrasound（iUS）图像提供实时跟踪脑移动，并使用多Modal（MRI-iUS）匹配进行更新预治疗计划。手术中质量控制匹配结果的重要性，以避免不良结果，但手动验证受到困难的3D视图和iUS的低对比度带来很大挑战。因此，我们提出了一种新的深度学习技术，基于3D关注模ulation，并与不确定性估计以准确评估MRI-iUS匹配错误。与RESECT临床数据库公共数据集进行开发和验证，我们的算法可以实现匹配错误的估计错误0.59±0.57毫米。
</details></li>
</ul>
<hr>
<h2 id="SuperInpaint-Learning-Detail-Enhanced-Attentional-Implicit-Representation-for-Super-resolutional-Image-Inpainting"><a href="#SuperInpaint-Learning-Detail-Enhanced-Attentional-Implicit-Representation-for-Super-resolutional-Image-Inpainting" class="headerlink" title="SuperInpaint: Learning Detail-Enhanced Attentional Implicit Representation for Super-resolutional Image Inpainting"></a>SuperInpaint: Learning Detail-Enhanced Attentional Implicit Representation for Super-resolutional Image Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14489">http://arxiv.org/abs/2307.14489</a></li>
<li>repo_url: None</li>
<li>paper_authors: Canyu Zhang, Qing Guo, Xiaoguang Li, Renjie Wan, Hongkai Yu, Ivor Tsang, Song Wang</li>
<li>for:  This paper aims to address the challenging task of SuperInpaint, which involves reconstructing missing regions in low-resolution images and generating completed images with higher resolutions.</li>
<li>methods:  The proposed method, called DEAR, uses a deep convolutional network to extract the latent embedding of an input image, and then enhances the high-frequency components of the latent embedding via an adaptive high-pass filter. The method also uses an unmask-attentional module to suppress embeddings from ineffective masked pixels, and an implicit representation to generate the color of the specified pixel.</li>
<li>results:  The proposed method outperforms all existing methods by a significant margin on four widely used metrics, demonstrating its effectiveness in addressing the SuperInpaint task.<details>
<summary>Abstract</summary>
In this work, we introduce a challenging image restoration task, referred to as SuperInpaint, which aims to reconstruct missing regions in low-resolution images and generate completed images with arbitrarily higher resolutions. We have found that this task cannot be effectively addressed by stacking state-of-the-art super-resolution and image inpainting methods as they amplify each other's flaws, leading to noticeable artifacts. To overcome these limitations, we propose the detail-enhanced attentional implicit representation (DEAR) that can achieve SuperInpaint with a single model, resulting in high-quality completed images with arbitrary resolutions. Specifically, we use a deep convolutional network to extract the latent embedding of an input image and then enhance the high-frequency components of the latent embedding via an adaptive high-pass filter. This leads to detail-enhanced semantic embedding. We further feed the semantic embedding into an unmask-attentional module that suppresses embeddings from ineffective masked pixels. Additionally, we extract a pixel-wise importance map that indicates which pixels should be used for image reconstruction. Given the coordinates of a pixel we want to reconstruct, we first collect its neighboring pixels in the input image and extract their detail-enhanced semantic embeddings, unmask-attentional semantic embeddings, importance values, and spatial distances to the desired pixel. Then, we feed all the above terms into an implicit representation and generate the color of the specified pixel. To evaluate our method, we extend three existing datasets for this new task and build 18 meaningful baselines using SOTA inpainting and super-resolution methods. Extensive experimental results demonstrate that our method outperforms all existing methods by a significant margin on four widely used metrics.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们引入了一个挑战性的图像修复任务，称为SuperInpaint，该任务的目标是在低分辨率图像中恢复缺失区域并生成完整图像的高分辨率版本。我们发现，这个任务不可能通过核心状态艺术的超解像和图像填充方法核心来解决，因为这些方法会强调对方的缺陷，导致明显的瑕疵。为了突破这些限制，我们提出了细节增强的匿名隐藏表示（DEAR），该方法可以在单个模型中实现SuperInpaint，并且可以生成高质量的完整图像。具体来说，我们使用深度卷积神经网络提取输入图像的含义嵌入，然后使用适应高频滤波器增强含义嵌入的高频分量。这导致细节增强的semantic嵌入。我们还将semantic嵌入 feed到无掩蔽听力模块，该模块可以抑制听力模块中不可靠的掩蔽像素的嵌入。此外，我们还提取了每个像素的重要性图，该图示出了需要用于图像重建的像素的坐标。给定需要重建的像素的坐标，我们首先收集了输入图像中的相关像素，然后提取它们的细节增强的semantic嵌入、无掩蔽听力嵌入、重要性值和空间距离目标像素。然后，我们将所有这些因素 feed到隐藏表示中，并生成目标像素的颜色。为了评估我们的方法，我们扩展了三个现有的数据集，并建立了18个基eline，使用现状填充和超解像方法的state-of-the-art方法。广泛的实验结果表明，我们的方法在四个常用的评价指标上明显超过了所有现有的方法。
</details></li>
</ul>
<hr>
<h2 id="Role-of-Image-Acquisition-and-Patient-Phenotype-Variations-in-Automatic-Segmentation-Model-Generalization"><a href="#Role-of-Image-Acquisition-and-Patient-Phenotype-Variations-in-Automatic-Segmentation-Model-Generalization" class="headerlink" title="Role of Image Acquisition and Patient Phenotype Variations in Automatic Segmentation Model Generalization"></a>Role of Image Acquisition and Patient Phenotype Variations in Automatic Segmentation Model Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14482">http://arxiv.org/abs/2307.14482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timothy L. Kline, Sumana Ramanathan, Harrison C. Gottlich, Panagiotis Korfiatis, Adriana V. Gregory</li>
<li>for:  This study aimed to evaluate the out-of-domain performance and generalization capabilities of automated medical image segmentation models.</li>
<li>methods:  The study used datasets from non-contrast and contrast-enhanced abdominal CT scans of healthy patients and those with polycystic kidney disease (PKD) to train and validate the models.</li>
<li>results:  The models trained on a diverse range of data showed no worse performance than models trained exclusively on in-domain data when tested on in-domain data, and the study found that broader training examples significantly enhance model generalization and out-of-domain performance.Here is the same information in Simplified Chinese text:</li>
<li>for: 这项研究目的是评估医疗影像自动分割模型的域外性能和泛化能力。</li>
<li>methods: 这项研究使用了非对照和对照腹部CT扫描图像健康人群和肾脏癌病（PKD）患者的数据集来训练和验证模型。</li>
<li>results: 模型在多样化的数据上训练后，与仅仅在域内数据上训练的模型在域内数据上的性能没有差异，并且发现更广泛的训练示例可以显著提高模型的泛化和域外性能。<details>
<summary>Abstract</summary>
Purpose: This study evaluated the out-of-domain performance and generalization capabilities of automated medical image segmentation models, with a particular focus on adaptation to new image acquisitions and disease type.   Materials: Datasets from both non-contrast and contrast-enhanced abdominal CT scans of healthy patients and those with polycystic kidney disease (PKD) were used. A total of 400 images (100 non-contrast controls, 100 contrast controls, 100 non-contrast PKD, 100 contrast PKD) were utilized for training/validation of models to segment kidneys, livers, and spleens, and the final models were then tested on 100 non-contrast CT images of patients affected by PKD. Performance was evaluated using Dice, Jaccard, TPR, and Precision.   Results: Models trained on a diverse range of data showed no worse performance than models trained exclusively on in-domain data when tested on in-domain data. For instance, the Dice similarity of the model trained on 25% from each dataset was found to be non-inferior to the model trained purely on in-domain data.   Conclusions: The results indicate that broader training examples significantly enhances model generalization and out-of-domain performance, thereby improving automated segmentation tools' applicability in clinical settings. The study's findings provide a roadmap for future research to adopt a data-centric approach in medical image AI model development.
</details>
<details>
<summary>摘要</summary>
目的：本研究评估了自动医疗影像分割模型的离域性和总体化能力，尤其关注新领域和疾病类型的适应性。材料：来自非对照和对照肝脏CT扫描的健康人群和肝病多囊细胞病（PKD）患者的 dataset 被使用。总共使用了400张图像（100张非对照控制、100张对照控制、100张非对照 PKD、100张对照 PKD）进行模型训练和验证，并将最终模型测试在100张非对照 CT 图像上，影像分割模型能够准确地 segmentation 肾脏、肝脏和脾脏。性能被评估使用 dice、jaccard、TPR 和精度。结论：结果表明，使用更广泛的数据集可以显著提高模型的总体化和离域性能，从而提高自动分割工具在临床中的应用性。这些结论为未来医疗影像 AI 模型开发提供了一个路线图。
</details></li>
</ul>
<hr>
<h2 id="MiDaS-v3-1-–-A-Model-Zoo-for-Robust-Monocular-Relative-Depth-Estimation"><a href="#MiDaS-v3-1-–-A-Model-Zoo-for-Robust-Monocular-Relative-Depth-Estimation" class="headerlink" title="MiDaS v3.1 – A Model Zoo for Robust Monocular Relative Depth Estimation"></a>MiDaS v3.1 – A Model Zoo for Robust Monocular Relative Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14460">http://arxiv.org/abs/2307.14460</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/isl-org/MiDaS">https://github.com/isl-org/MiDaS</a></li>
<li>paper_authors: Reiner Birkl, Diana Wofk, Matthias Müller</li>
<li>for: 这 paper 是为了提高 monocular depth estimation 的质量和速度而实现的。</li>
<li>methods: 这 paper 使用了不同的 encoder backbones，包括 BEiT、Swin、SwinV2、Next-ViT 和 LeViT，以实现不同的 performance-runtime 贸易。</li>
<li>results: 这 paper 的结果表明，使用最有前途的视transformer 作为图像编码器可以提高 depth estimation 的质量，同时可以提高下游任务的高帧率。 Code 可以在 <a target="_blank" rel="noopener" href="https://github.com/isl-org/MiDaS">https://github.com/isl-org/MiDaS</a> 找到。<details>
<summary>Abstract</summary>
We release MiDaS v3.1 for monocular depth estimation, offering a variety of new models based on different encoder backbones. This release is motivated by the success of transformers in computer vision, with a large variety of pretrained vision transformers now available. We explore how using the most promising vision transformers as image encoders impacts depth estimation quality and runtime of the MiDaS architecture. Our investigation also includes recent convolutional approaches that achieve comparable quality to vision transformers in image classification tasks. While the previous release MiDaS v3.0 solely leverages the vanilla vision transformer ViT, MiDaS v3.1 offers additional models based on BEiT, Swin, SwinV2, Next-ViT and LeViT. These models offer different performance-runtime tradeoffs. The best model improves the depth estimation quality by 28% while efficient models enable downstream tasks requiring high frame rates. We also describe the general process for integrating new backbones. A video summarizing the work can be found at https://youtu.be/UjaeNNFf9sE and the code is available at https://github.com/isl-org/MiDaS.
</details>
<details>
<summary>摘要</summary>
我们发布了MiDaS v3.1，用于单目深度估计，提供了多种基于不同Encoder脊梁的新模型。这个发布是由计算机视觉中transformer的成功所 inspirited，现有大量预训练视觉transformer可用。我们研究了使用最有前途的视觉transformer作为图像编码器对深度估计质量和 runtime MiDaS架构的影响。我们的调查还包括最近的 convolutional方法，可以与视觉transformer相比肩。在上一个发布MiDaS v3.0中，我们只使用了vanilla vision transformer ViT，而MiDaS v3.1提供了基于BEiT、Swin、SwinV2、Next-ViT和LeViT的additional模型。这些模型提供了不同的性能-时间质量交易。最佳模型可以提高深度估计质量28%，而高效的模型可以支持需要高帧率的下游任务。我们还描述了将新的脊梁集成到MiDaS架构的一般过程。关于这个工作的视频可以在https://youtu.be/UjaeNNFf9sE找到，代码可以在https://github.com/isl-org/MiDaS中找到。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Few-shot-Learning-for-Semantic-Segmentation-An-Annotation-free-Approach"><a href="#Self-supervised-Few-shot-Learning-for-Semantic-Segmentation-An-Annotation-free-Approach" class="headerlink" title="Self-supervised Few-shot Learning for Semantic Segmentation: An Annotation-free Approach"></a>Self-supervised Few-shot Learning for Semantic Segmentation: An Annotation-free Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14446">http://arxiv.org/abs/2307.14446</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mindflow-institue/annotation_free_fewshot">https://github.com/mindflow-institue/annotation_free_fewshot</a></li>
<li>paper_authors: Sanaz Karimijafarbigloo, Reza Azad, Dorit Merhof</li>
<li>For:	+ The paper aims to address the challenge of few-shot semantic segmentation (FSS) in medical image analysis, where limited annotated data is available.	+ The proposed method is designed to work without annotated semantic classes, making it suitable for medical images with limited annotations.* Methods:	+ The proposed method reframes the problem of image decomposition as a graph partitioning task, using eigenvectors from self-supervised networks to estimate the distribution of objects in the support images.	+ A novel self-supervised FSS framework is proposed, which adaptively estimates the query mask based on the eigenvectors obtained from the support images, eliminating the need for manual annotation.	+ A multi-scale large kernel attention module is introduced to selectively emphasize relevant features and details, improving the segmentation process and contributing to better object delineation.* Results:	+ The proposed method is evaluated on both natural and medical image datasets, demonstrating its efficiency and effectiveness.	+ The approach is shown to be general and model-agnostic, allowing for seamless integration with various deep architectures.Here is the information in Simplified Chinese text:* For:	+ 该研究旨在解决医学图像分割领域中的少量标注数据问题，使用自动标注方法实现准确的物体分割。	+ 提议的方法不需要任何标注数据，因此适用于医学图像中的限量标注数据。* Methods:	+ 该方法将图像分解问题转化为图像分解任务，使用自动标注网络中的特征相似矩阵来估算支持图像中对象的分布。	+ 提议的方法包括一种新的自动标注分割框架，不需要任何手动标注，而是基于支持图像中的特征 eigenvector 来适应性地分割查询图像。	+ 为了进一步提高查询图像的解码，提议的方法还引入了一种多级大kernel注意模块，可以选择性地强调相关的特征和细节，从而提高分割过程和物体定义。* Results:	+ 提议的方法在自然图像和医学图像上进行了评估，显示其高效和有效。	+ 该方法具有通用性和模型无关性，可以轻松地与多种深度架构集成。I hope that helps!<details>
<summary>Abstract</summary>
Few-shot semantic segmentation (FSS) offers immense potential in the field of medical image analysis, enabling accurate object segmentation with limited training data. However, existing FSS techniques heavily rely on annotated semantic classes, rendering them unsuitable for medical images due to the scarcity of annotations. To address this challenge, multiple contributions are proposed: First, inspired by spectral decomposition methods, the problem of image decomposition is reframed as a graph partitioning task. The eigenvectors of the Laplacian matrix, derived from the feature affinity matrix of self-supervised networks, are analyzed to estimate the distribution of the objects of interest from the support images. Secondly, we propose a novel self-supervised FSS framework that does not rely on any annotation. Instead, it adaptively estimates the query mask by leveraging the eigenvectors obtained from the support images. This approach eliminates the need for manual annotation, making it particularly suitable for medical images with limited annotated data. Thirdly, to further enhance the decoding of the query image based on the information provided by the support image, we introduce a multi-scale large kernel attention module. By selectively emphasizing relevant features and details, this module improves the segmentation process and contributes to better object delineation. Evaluations on both natural and medical image datasets demonstrate the efficiency and effectiveness of our method. Moreover, the proposed approach is characterized by its generality and model-agnostic nature, allowing for seamless integration with various deep architectures. The code is publicly available at \href{https://github.com/mindflow-institue/annotation_free_fewshot}{\textcolor{magenta}{GitHub}.
</details>
<details>
<summary>摘要</summary>
这个文章提出了几个解决方案，以实现无需标注的几个Semantic Segmentation（FSS）。首先，我们参考了spectral decomposition方法，将图像分解问题转换为一个图像分类 задачу。然后，我们提出了一个新的自助学FSS框架，不需要任何标注。它可以透过获取支持图像中的eigenvector来 Adaptively estimate the query mask。此外，我们还引入了一个多尺度大kernel注意模组，以增强对支持图像的讯息整合，进一步改善分类过程。实验结果显示，我们的方法具有高效性和可靠性，并且可以与多种深度架构整合。代码可以在\href{https://github.com/mindflow-institue/annotation_free_fewshot}{\textcolor{magenta}{GitHub}上找到。
</details></li>
</ul>
<hr>
<h2 id="Phenotype-preserving-metric-design-for-high-content-image-reconstruction-by-generative-inpainting"><a href="#Phenotype-preserving-metric-design-for-high-content-image-reconstruction-by-generative-inpainting" class="headerlink" title="Phenotype-preserving metric design for high-content image reconstruction by generative inpainting"></a>Phenotype-preserving metric design for high-content image reconstruction by generative inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14436">http://arxiv.org/abs/2307.14436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vaibhav Sharma, Artur Yakimovich</li>
<li>for: 这个论文旨在描述一种基于高级微scopy的自动化高内容图像分析技术，以及该技术如何处理和修复图像中的artefacts。</li>
<li>methods: 本论文使用了state-of-the-art的填充方法，如DeepFill V2和Edge Connect，来修复高级微scopy图像中的artefacts。这些方法可以通过精心调整来实现 faithful restoration of microscopy images。</li>
<li>results: 研究发现，Restoration的质量与修复区域的大小有关，而不是形状。此外，提出了一种新的phenotype-preserving metric设计策略，该策略可以控制修复的质量，并且可以扩展到其他应用。<details>
<summary>Abstract</summary>
In the past decades, automated high-content microscopy demonstrated its ability to deliver large quantities of image-based data powering the versatility of phenotypic drug screening and systems biology applications. However, as the sizes of image-based datasets grew, it became infeasible for humans to control, avoid and overcome the presence of imaging and sample preparation artefacts in the images. While novel techniques like machine learning and deep learning may address these shortcomings through generative image inpainting, when applied to sensitive research data this may come at the cost of undesired image manipulation. Undesired manipulation may be caused by phenomena such as neural hallucinations, to which some artificial neural networks are prone. To address this, here we evaluate the state-of-the-art inpainting methods for image restoration in a high-content fluorescence microscopy dataset of cultured cells with labelled nuclei. We show that architectures like DeepFill V2 and Edge Connect can faithfully restore microscopy images upon fine-tuning with relatively little data. Our results demonstrate that the area of the region to be restored is of higher importance than shape. Furthermore, to control for the quality of restoration, we propose a novel phenotype-preserving metric design strategy. In this strategy, the size and count of the restored biological phenotypes like cell nuclei are quantified to penalise undesirable manipulation. We argue that the design principles of our approach may also generalise to other applications.
</details>
<details>
<summary>摘要</summary>
过去几十年，自动化高内容微镜已经证明其能够提供大量的图像数据，推动了生物学和系统生物学应用的多样化。然而，随着图像数据的大小的增加，人类无法控制、避免和超越图像和样本准备 artifacts。而新技术如机器学习和深度学习可能解决这些缺陷，通过生成图像填充来修复图像。但当应用于敏感研究数据时，这可能会导致不жела的图像修改。这些修改可能是由神经投影引起的，一些人工神经网络容易受到这种影响。为此，我们在高内容染色微镜像dataset中评估了当前的填充方法。我们发现，深度填充V2和边缘连接可以在 fine-tuning 后对图像进行 faithful 的修复，只需要 relativity little data。我们的结果表明，图像修复的区域大小比较重要于形状。此外，为了控制修复质量，我们提出了一种新的现象保持式度量设计策略。在这种策略中，修复后的生物现象的大小和数量被量化，以便对不良修改进行惩罚。我们认为这些设计原则可能也适用于其他应用。
</details></li>
</ul>
<hr>
<h2 id="ProtoASNet-Dynamic-Prototypes-for-Inherently-Interpretable-and-Uncertainty-Aware-Aortic-Stenosis-Classification-in-Echocardiography"><a href="#ProtoASNet-Dynamic-Prototypes-for-Inherently-Interpretable-and-Uncertainty-Aware-Aortic-Stenosis-Classification-in-Echocardiography" class="headerlink" title="ProtoASNet: Dynamic Prototypes for Inherently Interpretable and Uncertainty-Aware Aortic Stenosis Classification in Echocardiography"></a>ProtoASNet: Dynamic Prototypes for Inherently Interpretable and Uncertainty-Aware Aortic Stenosis Classification in Echocardiography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14433">http://arxiv.org/abs/2307.14433</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hooman007/protoasnet">https://github.com/hooman007/protoasnet</a></li>
<li>paper_authors: Hooman Vaseli, Ang Nan Gu, S. Neda Ahmadi Amiri, Michael Y. Tsang, Andrea Fung, Nima Kondori, Armin Saadat, Purang Abolmaesumi, Teresa S. M. Tsang</li>
<li>for: 本研究旨在提出一种可靠的自动检测涂猛病（AS）严重程度的方法，以便于适时采取治疗。</li>
<li>methods: 本方法基于protoNet，直接从B模式超音波视频中检测AS，并通过与学习的空间时间谱例子进行比较，以获得可解释的预测结果。</li>
<li>results: 对于一个私人数据集和公共可用的TMED-2数据集，ProtoASNet比现有状态之artefact的方法表现出色，具有80.0%和79.7%的准确率。此外，ProtoASNet还提供了解释性和不确定性度量，以便于在深度网络的助助 clinical decision-making。<details>
<summary>Abstract</summary>
Aortic stenosis (AS) is a common heart valve disease that requires accurate and timely diagnosis for appropriate treatment. Most current automatic AS severity detection methods rely on black-box models with a low level of trustworthiness, which hinders clinical adoption. To address this issue, we propose ProtoASNet, a prototypical network that directly detects AS from B-mode echocardiography videos, while making interpretable predictions based on the similarity between the input and learned spatio-temporal prototypes. This approach provides supporting evidence that is clinically relevant, as the prototypes typically highlight markers such as calcification and restricted movement of aortic valve leaflets. Moreover, ProtoASNet utilizes abstention loss to estimate aleatoric uncertainty by defining a set of prototypes that capture ambiguity and insufficient information in the observed data. This provides a reliable system that can detect and explain when it may fail. We evaluate ProtoASNet on a private dataset and the publicly available TMED-2 dataset, where it outperforms existing state-of-the-art methods with an accuracy of 80.0% and 79.7%, respectively. Furthermore, ProtoASNet provides interpretability and an uncertainty measure for each prediction, which can improve transparency and facilitate the interactive usage of deep networks to aid clinical decision-making. Our source code is available at: https://github.com/hooman007/ProtoASNet.
</details>
<details>
<summary>摘要</summary>
《血液动脉狭窄症（AS）是心血管疾病的常见疾病，需要准确和时间上的诊断，以便适当的治疗。现有的大多数自动AS严重程度检测方法都采用黑盒模型，导致临床应用受限。为解决这个问题，我们提出了ProtoASNet，一种prototype网络，可以直接从B模式超音波视频中检测AS，并通过与学习的空间时间原型进行可读性的预测。这种方法提供了临床相关的支持证据，通常是卷积和叶 valve的受限运动的标志。此外，ProtoASNet使用缺失损失来估算随机不确定性，定义了一组捕捉歧义和不充分信息的prototype，从而提供一个可靠的系统。我们评估了ProtoASNet于私人数据集和公共可用的TMED-2数据集，其在两个数据集上均取得了80.0%和79.7%的准确率，分别超过了现有的状态对比方法。此外，ProtoASNet还提供了每个预测的可解释性和不确定性度量，可以提高透明度和促进深度网络的交互式使用，以帮助临床决策。我们的源代码可以在：https://github.com/hooman007/ProtoASNet。
</details></li>
</ul>
<hr>
<h2 id="Virtual-Mirrors-Non-Line-of-Sight-Imaging-Beyond-the-Third-Bounce"><a href="#Virtual-Mirrors-Non-Line-of-Sight-Imaging-Beyond-the-Third-Bounce" class="headerlink" title="Virtual Mirrors: Non-Line-of-Sight Imaging Beyond the Third Bounce"></a>Virtual Mirrors: Non-Line-of-Sight Imaging Beyond the Third Bounce</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14341">http://arxiv.org/abs/2307.14341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diego Royo, Talha Sultan, Adolfo Muñoz, Khadijeh Masumnia-Bisheh, Eric Brandt, Diego Gutierrez, Andreas Velten, Julio Marco</li>
<li>for: 该研究旨在推广非直视（NLOS）成像方法的能力，以描绘不可见的场景。</li>
<li>methods: 该研究使用计算波动频谱NLOS成像领域的 indirect illumination 方法，并利用物体表面的折射特性来扩展NLOS成像的能力。</li>
<li>results: 该研究通过分析场景中的物体位置和方向，以及使用计算建立 auxiliary apertures 来扩展NLOS成像的能力，可以成功地成像单个角度的物体和隐藏在两个角度的物体。<details>
<summary>Abstract</summary>
Non-line-of-sight (NLOS) imaging methods are capable of reconstructing complex scenes that are not visible to an observer using indirect illumination. However, they assume only third-bounce illumination, so they are currently limited to single-corner configurations, and present limited visibility when imaging surfaces at certain orientations. To reason about and tackle these limitations, we make the key observation that planar diffuse surfaces behave specularly at wavelengths used in the computational wave-based NLOS imaging domain. We call such surfaces virtual mirrors. We leverage this observation to expand the capabilities of NLOS imaging using illumination beyond the third bounce, addressing two problems: imaging single-corner objects at limited visibility angles, and imaging objects hidden behind two corners. To image objects at limited visibility angles, we first analyze the reflections of the known illuminated point on surfaces of the scene as an estimator of the position and orientation of objects with limited visibility. We then image those limited visibility objects by computationally building secondary apertures at other surfaces that observe the target object from a direct visibility perspective. Beyond single-corner NLOS imaging, we exploit the specular behavior of virtual mirrors to image objects hidden behind a second corner by imaging the space behind such virtual mirrors, where the mirror image of objects hidden around two corners is formed. No specular surfaces were involved in the making of this paper.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MAMo-Leveraging-Memory-and-Attention-for-Monocular-Video-Depth-Estimation"><a href="#MAMo-Leveraging-Memory-and-Attention-for-Monocular-Video-Depth-Estimation" class="headerlink" title="MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation"></a>MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14336">http://arxiv.org/abs/2307.14336</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rajeev Yasarla, Hong Cai, Jisoo Jeong, Yunxiao Shi, Risheek Garrepalli, Fatih Porikli</li>
<li>for: 提高单目视频深度估计精度</li>
<li>methods: 使用内存和注意力框架，将单目深度估计网络转化为视频深度估计模型，利用视频 temporal 信息提高深度估计精度</li>
<li>results: 在多个benchmark上实现了新的state-of-the-art（SOTA）精度，并且在响应时间方面与cost-volume-based视频深度模型相比，提供了更高的精度和更低的响应时间。<details>
<summary>Abstract</summary>
We propose MAMo, a novel memory and attention frame-work for monocular video depth estimation. MAMo can augment and improve any single-image depth estimation networks into video depth estimation models, enabling them to take advantage of the temporal information to predict more accurate depth. In MAMo, we augment model with memory which aids the depth prediction as the model streams through the video. Specifically, the memory stores learned visual and displacement tokens of the previous time instances. This allows the depth network to cross-reference relevant features from the past when predicting depth on the current frame. We introduce a novel scheme to continuously update the memory, optimizing it to keep tokens that correspond with both the past and the present visual information. We adopt attention-based approach to process memory features where we first learn the spatio-temporal relation among the resultant visual and displacement memory tokens using self-attention module. Further, the output features of self-attention are aggregated with the current visual features through cross-attention. The cross-attended features are finally given to a decoder to predict depth on the current frame. Through extensive experiments on several benchmarks, including KITTI, NYU-Depth V2, and DDAD, we show that MAMo consistently improves monocular depth estimation networks and sets new state-of-the-art (SOTA) accuracy. Notably, our MAMo video depth estimation provides higher accuracy with lower latency, when omparing to SOTA cost-volume-based video depth models.
</details>
<details>
<summary>摘要</summary>
我们提出了MAMo，一种新的记忆和注意框架，用于单光学视频深度估计。MAMo可以将单个图像深度估计网络转化为视频深度估计模型，让它们利用视频中的时间信息来预测更加准确的深度。在MAMo中，我们增加了记忆，以 помочь深度预测。Specifically, the memory stores learned visual and displacement tokens of the previous time instances. This allows the depth network to cross-reference relevant features from the past when predicting depth on the current frame. We introduce a novel scheme to continuously update the memory, optimizing it to keep tokens that correspond with both the past and the present visual information. We adopt an attention-based approach to process memory features, where we first learn the spatio-temporal relation among the resultant visual and displacement memory tokens using a self-attention module. Further, the output features of self-attention are aggregated with the current visual features through cross-attention. The cross-attended features are finally given to a decoder to predict depth on the current frame. Through extensive experiments on several benchmarks, including KITTI, NYU-Depth V2, and DDAD, we show that MAMo consistently improves monocular depth estimation networks and sets new state-of-the-art (SOTA) accuracy. Notably, our MAMo video depth estimation provides higher accuracy with lower latency, when comparing to SOTA cost-volume-based video depth models.
</details></li>
</ul>
<hr>
<h2 id="Visual-Instruction-Inversion-Image-Editing-via-Visual-Prompting"><a href="#Visual-Instruction-Inversion-Image-Editing-via-Visual-Prompting" class="headerlink" title="Visual Instruction Inversion: Image Editing via Visual Prompting"></a>Visual Instruction Inversion: Image Editing via Visual Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14331">http://arxiv.org/abs/2307.14331</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thaoshibe/visii">https://github.com/thaoshibe/visii</a></li>
<li>paper_authors: Thao Nguyen, Yuheng Li, Utkarsh Ojha, Yong Jae Lee</li>
<li>for: 图像编辑</li>
<li>methods: 使用视觉提示学习文本编辑指令</li>
<li>results: 与状态艺技图像编辑框架竞争的 результа集Here’s a more detailed explanation of each point:</li>
<li>for: The paper is written for the task of image editing, specifically using visual prompts to convey editing ideas and learn text-based editing directions.</li>
<li>methods: The paper uses a method of inverting visual prompts into editing instructions, leveraging pre-trained text-to-image diffusion models to perform the editing.</li>
<li>results: The paper achieves competitive results compared to state-of-the-art text-conditioned image editing frameworks, with just one example pair.<details>
<summary>Abstract</summary>
Text-conditioned image editing has emerged as a powerful tool for editing images. However, in many situations, language can be ambiguous and ineffective in describing specific image edits. When faced with such challenges, visual prompts can be a more informative and intuitive way to convey ideas. We present a method for image editing via visual prompting. Given pairs of example that represent the "before" and "after" images of an edit, our goal is to learn a text-based editing direction that can be used to perform the same edit on new images. We leverage the rich, pretrained editing capabilities of text-to-image diffusion models by inverting visual prompts into editing instructions. Our results show that with just one example pair, we can achieve competitive results compared to state-of-the-art text-conditioned image editing frameworks.
</details>
<details>
<summary>摘要</summary>
文本受控图像编辑已经成为图像编辑的强大工具。然而，在许多情况下，语言可能是模糊和不准确地描述特定的图像编辑。在面临这些挑战时，视觉提示可以是更加信息rich和INTUITIVE的方式来传达想法。我们提出了基于视觉提示的图像编辑方法。给定一对"before"和"after"图像，我们的目标是学习一个可以用于新图像进行同样编辑的文本编辑方向。我们利用了已经预训练的文本到图像扩散模型，通过视觉提示的倒转来获得编辑指令。我们的结果显示，只需要一对示例，我们可以与状态静态图像编辑框架相比的获得竞争性的结果。
</details></li>
</ul>
<hr>
<h2 id="US-MR-Image-Fusion-Based-on-Skin-Co-Registration"><a href="#US-MR-Image-Fusion-Based-on-Skin-Co-Registration" class="headerlink" title="US &amp; MR Image-Fusion Based on Skin Co-Registration"></a>US &amp; MR Image-Fusion Based on Skin Co-Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14288">http://arxiv.org/abs/2307.14288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martina Paccini, Giacomo Paschina, Stefano De Beni, Giuseppe Patanè</li>
<li>for: 这个研究的目的是发展一个可携性高的医学影像融合系统，用于融合CT和MRI影像 WITH real-time US取得，以便在医疗器械运行中进行实时追踪和操作。</li>
<li>methods: 这个研究使用了一个3D摄像头感应器，用于融合CT和MRI影像 WITH real-time US取得。</li>
<li>results: 这个研究的主要结果是一个可携性高的医学影像融合系统，可以在不同的生物学结构中进行实时追踪和操作。<details>
<summary>Abstract</summary>
The study and development of innovative solutions for the advanced visualisation, representation and analysis of medical images offer different research directions. Current practice in medical imaging consists in combining real-time US with imaging modalities that allow internal anatomy acquisitions, such as CT, MRI, PET or similar. Application of image-fusion approaches can be found in tracking surgical tools and/or needles, in real-time during interventions. Thus, this work proposes a fusion imaging system for the registration of CT and MRI images with real-time US acquisition leveraging a 3D camera sensor. The main focus of the work is the portability of the system and its applicability to different anatomical districts.
</details>
<details>
<summary>摘要</summary>
研究和开发创新解决方案 для高级医学图像可视化、表示和分析提供了不同的研究方向。现有医学成像做法是将实时US与可以获取内部解剖结构的成像方式结合，如CT、MRI、PET等。在实时手术过程中，应用图像融合方法可以跟踪手术工具和/或针刺的位置。这项工作提议了CT和MRI图像融合系统，通过3D摄像头感知器实现实时US获取。主要关注点是系统的可搬性和适用于不同的解剖区域。Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Large-scale-Fully-Unsupervised-Re-Identification"><a href="#Large-scale-Fully-Unsupervised-Re-Identification" class="headerlink" title="Large-scale Fully-Unsupervised Re-Identification"></a>Large-scale Fully-Unsupervised Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14278">http://arxiv.org/abs/2307.14278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriel Bertocco, Fernanda Andaló, Terrance E. Boult, Anderson Rocha</li>
<li>for: This paper focuses on fully-unsupervised person and vehicle re-identification, with the goal of improving the robustness and efficiency of the re-identification process in large-scale scenarios.</li>
<li>methods: The proposed methodology consists of two strategies: local neighborhood sampling and a novel Re-Ranking technique. The first strategy reduces the dataset size in each iteration without violating neighborhood relationships, while the second strategy reduces the time and memory complexity of the Re-Ranking process. Additionally, the paper introduces a novel scheduling algorithm that adjusts the density parameter during training to leverage the diversity of samples and keep the learning robust to noisy labeling.</li>
<li>results: The proposed method outperforms state-of-the-art methods in well-known benchmarks and in the challenging large-scale Veri-Wild dataset. The method achieves a faster and memory-efficient Re-Ranking strategy, and a large-scale, noisy-robust, and ensemble-based learning approach.<details>
<summary>Abstract</summary>
Fully-unsupervised Person and Vehicle Re-Identification have received increasing attention due to their broad applicability in surveillance, forensics, event understanding, and smart cities, without requiring any manual annotation. However, most of the prior art has been evaluated in datasets that have just a couple thousand samples. Such small-data setups often allow the use of costly techniques in time and memory footprints, such as Re-Ranking, to improve clustering results. Moreover, some previous work even pre-selects the best clustering hyper-parameters for each dataset, which is unrealistic in a large-scale fully-unsupervised scenario. In this context, this work tackles a more realistic scenario and proposes two strategies to learn from large-scale unlabeled data. The first strategy performs a local neighborhood sampling to reduce the dataset size in each iteration without violating neighborhood relationships. A second strategy leverages a novel Re-Ranking technique, which has a lower time upper bound complexity and reduces the memory complexity from O(n^2) to O(kn) with k << n. To avoid the pre-selection of specific hyper-parameter values for the clustering algorithm, we also present a novel scheduling algorithm that adjusts the density parameter during training, to leverage the diversity of samples and keep the learning robust to noisy labeling. Finally, due to the complementary knowledge learned by different models, we also introduce a co-training strategy that relies upon the permutation of predicted pseudo-labels, among the backbones, with no need for any hyper-parameters or weighting optimization. The proposed methodology outperforms the state-of-the-art methods in well-known benchmarks and in the challenging large-scale Veri-Wild dataset, with a faster and memory-efficient Re-Ranking strategy, and a large-scale, noisy-robust, and ensemble-based learning approach.
</details>
<details>
<summary>摘要</summary>
具有广泛应用前景的无监督人员和车辆重识别技术已经吸引了越来越多的关注，因为它不需要任何手动标注。然而，大多数先前的研究都是在几千个样本的小数据集上进行评估的，这些小数据集经常允许使用费时的技术，如重新排序，以提高归类结果。此外，一些先前的工作甚至会预先选择每个数据集的最佳归类参数，这是在大规模无监督场景下不现实的。在这种情况下，本研究面临着更加现实的场景，并提出了两种策略来学习大规模无标签数据。第一种策略是本地邻域采样，可以降低数据集的大小，而不违反邻域关系。第二种策略是一种新的重新排序技术，它的时间上限复杂度为O(n)，相比之下，传统的重新排序技术的时间上限复杂度为O(n^2)。为了避免预先选择特定的归类参数，我们还提出了一种新的调整策略，可以在训练中调整凝固参数，以利用样本的多样性，并使学习具有鲁棒性。最后，由于不同的模型学习的知识是 complementary，我们还引入了一种合作训练策略，可以在不同的后处理器之间进行预测 pseudo-标签的 permutation，无需任何超参或权值优化。在许多知名的benchmark上和Veri-Wild数据集中，我们的方法性能高于当前状态艺术。我们的方法具有快速、内存高效的重新排序策略，以及大规模、噪声鲁棒、 ensemble-based 学习方法。
</details></li>
</ul>
<hr>
<h2 id="G2L-Semantically-Aligned-and-Uniform-Video-Grounding-via-Geodesic-and-Game-Theory"><a href="#G2L-Semantically-Aligned-and-Uniform-Video-Grounding-via-Geodesic-and-Game-Theory" class="headerlink" title="G2L: Semantically Aligned and Uniform Video Grounding via Geodesic and Game Theory"></a>G2L: Semantically Aligned and Uniform Video Grounding via Geodesic and Game Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14277">http://arxiv.org/abs/2307.14277</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongxiang Li, Meng Cao, Xuxin Cheng, Yaowei Li, Zhihong Zhu, Yuexian Zou</li>
<li>for: 这个论文旨在解决视频定位问题，即使用自适应对视频定位。</li>
<li>methods: 该论文提出了一种基于地odesic和游戏理论的均衡视频定位框架（G2L），通过地odesic距离来衡量同时段的含义相似性，并通过游戏理论来学习细致的含义对应。</li>
<li>results: 实验结果表明，G2L方法可以有效地解决视频定位问题，并且在三个基准数据集上达到了最高的性能。<details>
<summary>Abstract</summary>
The recent video grounding works attempt to introduce vanilla contrastive learning into video grounding. However, we claim that this naive solution is suboptimal. Contrastive learning requires two key properties: (1) \emph{alignment} of features of similar samples, and (2) \emph{uniformity} of the induced distribution of the normalized features on the hypersphere. Due to two annoying issues in video grounding: (1) the co-existence of some visual entities in both ground truth and other moments, \ie semantic overlapping; (2) only a few moments in the video are annotated, \ie sparse annotation dilemma, vanilla contrastive learning is unable to model the correlations between temporally distant moments and learned inconsistent video representations. Both characteristics lead to vanilla contrastive learning being unsuitable for video grounding. In this paper, we introduce Geodesic and Game Localization (G2L), a semantically aligned and uniform video grounding framework via geodesic and game theory. We quantify the correlations among moments leveraging the geodesic distance that guides the model to learn the correct cross-modal representations. Furthermore, from the novel perspective of game theory, we propose semantic Shapley interaction based on geodesic distance sampling to learn fine-grained semantic alignment in similar moments. Experiments on three benchmarks demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
最近的视频定位工作尝试将纯然对偶学习引入到视频定位中。然而，我们认为这种简单的解决方案是不合适的。对偶学习需要两个关键性质：（1）对类似样本的特征进行Alignment，以及（2）在归一化后的特征分布在圆柱体上具有 uniformity。由于视频定位中存在两个烦人的问题：（1）视频中存在一些视觉实体同时出现在真实标注和其他时刻中，即semantic overlapping;（2）只有一些时刻在视频中被标注，即稀疏标注困难，纯然对偶学习无法模型视频中的时间距离相关性和学习不一致的视频表示。这两个特征导致纯然对偶学习不适用于视频定位。在这篇论文中，我们提出了Geodesic and Game Localization（G2L）方法，该方法通过几何学和游戏理论来实现semantically aligned和uniform的视频定位框架。我们利用几何学距离来衡量时间距离相关性，使模型学习正确的交叉模式表示。此外，从游戏理论的新角度出发，我们提出了semantic Shapley交互，基于几何学距离采样来学习细致的semantic alignment。实验结果表明，我们的方法有效地解决了视频定位中的问题。
</details></li>
</ul>
<hr>
<h2 id="Deepfake-Image-Generation-for-Improved-Brain-Tumor-Segmentation"><a href="#Deepfake-Image-Generation-for-Improved-Brain-Tumor-Segmentation" class="headerlink" title="Deepfake Image Generation for Improved Brain Tumor Segmentation"></a>Deepfake Image Generation for Improved Brain Tumor Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14273">http://arxiv.org/abs/2307.14273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roa’a Al-Emaryeen, Sara Al-Nahhas, Fatima Himour, Waleed Mahafza, Omar Al-Kadi</li>
<li>for: 针对脑肿 segmentation task，提高识别效果</li>
<li>methods: 使用生成对抗网络进行图像到图像翻译，然后使用U-Net适应性 convolutional neural network进行图像分割</li>
<li>results: 比较四个公共数据集的基准值，显示提高图像分割质量指标的性能<details>
<summary>Abstract</summary>
As the world progresses in technology and health, awareness of disease by revealing asymptomatic signs improves. It is important to detect and treat tumors in early stage as it can be life-threatening. Computer-aided technologies are used to overcome lingering limitations facing disease diagnosis, while brain tumor segmentation remains a difficult process, especially when multi-modality data is involved. This is mainly attributed to ineffective training due to lack of data and corresponding labelling. This work investigates the feasibility of employing deep-fake image generation for effective brain tumor segmentation. To this end, a Generative Adversarial Network was used for image-to-image translation for increasing dataset size, followed by image segmentation using a U-Net-based convolutional neural network trained with deepfake images. Performance of the proposed approach is compared with ground truth of four publicly available datasets. Results show improved performance in terms of image segmentation quality metrics, and could potentially assist when training with limited data.
</details>
<details>
<summary>摘要</summary>
世界的技术和医疗发展，疾病早期发现的意识提高。早期发现和治疗肿瘤非常重要，因为可能是生命威胁。计算机支持技术用于超越疾病诊断中的留存问题，而脑肿瘤分 segmentation仍然是一个困难的过程，特别是当涉及多Modal数据时。这主要归因于训练效果不够，因为缺乏数据和相应的标注。这项工作研究了使用深归真图生成技术来实现有效的脑肿瘤分 segmentation。为此，我们使用了一个生成对抗网络进行图像到图像翻译，然后使用一个基于 U-Net 的卷积神经网络，并在深归真图上进行图像分割。我们对提出的方法的性能进行了比较，并与四个公共可用的数据集的标准值进行比较。结果表明，我们的方法可以提高图像分割质量指标，并且可能在培训数据有限时提供帮助。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/27/cs.CV_2023_07_27/" data-id="clogyj8xd00es7cra2sih48mr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/27/cs.AI_2023_07_27/" class="article-date">
  <time datetime="2023-07-27T12:00:00.000Z" itemprop="datePublished">2023-07-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/27/cs.AI_2023_07_27/">cs.AI - 2023-07-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Multi-Source-Domain-Adaptation-through-Dataset-Dictionary-Learning-in-Wasserstein-Space"><a href="#Multi-Source-Domain-Adaptation-through-Dataset-Dictionary-Learning-in-Wasserstein-Space" class="headerlink" title="Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space"></a>Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14953">http://arxiv.org/abs/2307.14953</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eddardd/demo-dadil">https://github.com/eddardd/demo-dadil</a></li>
<li>paper_authors: Eduardo Fernandes Montesuma, Fred Ngolè Mboula, Antoine Souloumiac</li>
<li>for: 解决多源频率域适应（MSDA）问题，即将多个标注源频率域中的知识传递到无标注目标频率域中，并mitigate数据分布变化问题。</li>
<li>methods: 提出了一个基于词典学习和优质运输的MSDA框架，将每个频率域 interpret为一个empirical distribution，并使用 Wasserstein barycenter来表示每个频率域。提出了一个新算法DaDiL，通过每个频率域的atom分布和矩阵barycentric坐标来学习。</li>
<li>results: 在Caltech-Office、Office 31和CRWU三个benchmark上评估了我们的方法，并比前一个状态的报告提高了3.15%、2.29%和7.71%的分类性能。最后，我们表明了在学习到的atom分布中的 interpolations可以通过Wasserstein筒来提供可以泛化到目标频率域的数据。<details>
<summary>Abstract</summary>
This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA framework based on dictionary learning and optimal transport. We interpret each domain in MSDA as an empirical distribution. As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates. Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification performance. Finally, we show that interpolations in the Wasserstein hull of learned atoms provide data that can generalize to the target domain.
</details>
<details>
<summary>摘要</summary>
In this framework, we interpret each domain in MSDA as an empirical distribution. We express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates.Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, which is based on the reconstruction of labeled samples in the target domain, and DaDiL-E, which is based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in three benchmarks: Caltech-Office, Office 31, and CRWU, and achieve state-of-the-art performance, with improvements of 3.15%, 2.29%, and 7.71% in classification performance, respectively.Finally, we show that interpolations in the Wasserstein hull of learned atoms provide data that can generalize to the target domain.
</details></li>
</ul>
<hr>
<h2 id="Designing-Fiduciary-Artificial-Intelligence"><a href="#Designing-Fiduciary-Artificial-Intelligence" class="headerlink" title="Designing Fiduciary Artificial Intelligence"></a>Designing Fiduciary Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02435">http://arxiv.org/abs/2308.02435</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Benthall, David Shekman</li>
<li>For: The paper is written to provide a procedure for designing and auditing Fiduciary AI, which is AI that is compliant with the legal duty of loyalty and care towards a principal.* Methods: The paper uses a combination of computer science and law to develop the procedure, including identifying the principals, assessing their interests, and ensuring loyalty and care in the design and auditing of Fiduciary AI.* Results: The paper argues that Fiduciary AI is a promising means to address the incompleteness of data subjects’ consent when interacting with complex technical systems, and connects the steps in the procedure to dimensions of Trustworthy AI such as privacy and alignment.Here’s the same information in Simplified Chinese text:* For: 这篇论文是为了提供设计和审核 fiduciary AI 的过程，fiduciary AI 是指遵循法律责任的loyalty和care的人工智能。* Methods: 这篇论文使用计算机科学和法律来发展设计和审核 fiduciary AI 的过程，包括确定主体、评估其利益，并确保设计和审核 fiduciary AI 的loyalty和care。* Results: 这篇论文认为 fiduciary AI 是Complex技术系统中数据主体consent的不完整性的一种解决方案，并将设计和审核 fiduciary AI 的步骤与信任worthy AI 的维度联系起来，如隐私和对齐。<details>
<summary>Abstract</summary>
A fiduciary is a trusted agent that has the legal duty to act with loyalty and care towards a principal that employs them. When fiduciary organizations interact with users through a digital interface, or otherwise automate their operations with artificial intelligence, they will need to design these AI systems to be compliant with their duties. This article synthesizes recent work in computer science and law to develop a procedure for designing and auditing Fiduciary AI. The designer of a Fiduciary AI should understand the context of the system, identify its principals, and assess the best interests of those principals. Then the designer must be loyal with respect to those interests, and careful in an contextually appropriate way. We connect the steps in this procedure to dimensions of Trustworthy AI, such as privacy and alignment. Fiduciary AI is a promising means to address the incompleteness of data subject's consent when interacting with complex technical systems.
</details>
<details>
<summary>摘要</summary>
一个 fiduciary 是一位被信任的代理人，具有法律责任，向使用者（principal）示好和照顾。当 fiduciary 组织通过数字界面或人工智能自动化其操作时，它们需要设计这些 AI 系统符合其职责。这篇文章结合计算机科学和法律研究，提出了设计和审核 fiduciary AI 的程序。设计 fiduciary AI 的人需要了解系统的上下文，识别主体，并评估这些主体的最好利益。然后，设计人必须对这些利益示好，并在上下文相应的方式进行谨慎。我们将这些步骤与信worthy AI 的维度，如隐私和对齐，连接起来。 fiduciary AI 是用于解决数据主体同技术系统交互时的数据权限不充分的问题的有希望的方法。
</details></li>
</ul>
<hr>
<h2 id="PanGu-Coder2-Boosting-Large-Language-Models-for-Code-with-Ranking-Feedback"><a href="#PanGu-Coder2-Boosting-Large-Language-Models-for-Code-with-Ranking-Feedback" class="headerlink" title="PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback"></a>PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14936">http://arxiv.org/abs/2307.14936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Shen, Jiaxin Zhang, Taihong Chen, Daoguang Zan, Bing Geng, An Fu, Muhan Zeng, Ailun Yu, Jichuan Ji, Jingyang Zhao, Yuenan Guo, Qianxiang Wang</li>
<li>for: 这篇论文主要写于如何提高预训练的代码生成模型的性能。</li>
<li>methods: 该论文提出了一种新的RRTF（ Rank Responses to align Test&amp;Teacher Feedback）框架，用于效果地提高预训练大语言模型的代码生成性能。</li>
<li>results: 该论文通过PanGu-Coder2实现了62.20%的pass@1分数在OpenAI HumanEval标准准点测试上，并在CoderEval和LeetCode标准测试上 consistentemente超过了所有之前的代码LM。<details>
<summary>Abstract</summary>
Large Language Models for Code (Code LLM) are flourishing. New and powerful models are released on a weekly basis, demonstrating remarkable performance on the code generation task. Various approaches have been proposed to boost the code generation performance of pre-trained Code LLMs, such as supervised fine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we propose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework, which can effectively and efficiently boost pre-trained large language models for code generation. Under this framework, we present PanGu-Coder2, which achieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through an extensive evaluation on CoderEval and LeetCode benchmarks, we show that PanGu-Coder2 consistently outperforms all previous Code LLMs.
</details>
<details>
<summary>摘要</summary>
大型语言模型 для程式码 (Code LLM) 正在盛况。新的强大模型在每周基础上发表，展示了惊人的程式码生成能力。各种方法已经被提议来提高预训Code LLM的程式码生成性能，如监督精度调整、指令调整、循环学习等。在本文中，我们提出了一个新的RRTF（排名回应对测试&教师反馈）框架，可以有效地和高效地提高预训大型语言模型的程式码生成能力。在这个框架下，我们发表了PanGu-Coder2，它在OpenAI HumanEvalbenchmark上取得了62.20%的通过率@1。此外，我们透过广泛的评估在CoderEval和LeetCodebenchmark上，展示了PanGu-Coder2在所有前一代Code LLMs中的稳定性和竞争力。
</details></li>
</ul>
<hr>
<h2 id="Solving-Data-Quality-Problems-with-Desbordante-a-Demo"><a href="#Solving-Data-Quality-Problems-with-Desbordante-a-Demo" class="headerlink" title="Solving Data Quality Problems with Desbordante: a Demo"></a>Solving Data Quality Problems with Desbordante: a Demo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14935">http://arxiv.org/abs/2307.14935</a></li>
<li>repo_url: None</li>
<li>paper_authors: George Chernishev, Michael Polyntsov, Anton Chizhov, Kirill Stupakov, Ilya Shchuckin, Alexander Smirnov, Maxim Strutovsky, Alexey Shlyonskikh, Mikhail Firsov, Stepan Manannikov, Nikita Bobrov, Daniil Goncharov, Ilia Barutkin, Vladislav Shalnev, Kirill Muraviev, Anna Rakhmukova, Dmitriy Shcheka, Anton Chernikov, Mikhail Vyrodov, Yaroslav Kurbatov, Maxim Fofanov, Sergei Belokonnyi, Pavel Anosov, Arthur Saliou, Eduard Gaisin, Kirill Smirnov</li>
<li>for: 提高现代数据驱动行业中数据分析的效率和质量。</li>
<li>methods: 使用功能依赖关系、数据约束、关联规则等复杂统计方法，并提供了可解释的描述。</li>
<li>results: 实现了高效、可扩展、可靠的数据 profiling 系统，并提供了与Python集成的解释。<details>
<summary>Abstract</summary>
Data profiling is an essential process in modern data-driven industries. One of its critical components is the discovery and validation of complex statistics, including functional dependencies, data constraints, association rules, and others.   However, most existing data profiling systems that focus on complex statistics do not provide proper integration with the tools used by contemporary data scientists. This creates a significant barrier to the adoption of these tools in the industry. Moreover, existing systems were not created with industrial-grade workloads in mind. Finally, they do not aim to provide descriptive explanations, i.e. why a given pattern is not found. It is a significant issue as it is essential to understand the underlying reasons for a specific pattern's absence to make informed decisions based on the data.   Because of that, these patterns are effectively rest in thin air: their application scope is rather limited, they are rarely used by the broader public. At the same time, as we are going to demonstrate in this presentation, complex statistics can be efficiently used to solve many classic data quality problems.   Desbordante is an open-source data profiler that aims to close this gap. It is built with emphasis on industrial application: it is efficient, scalable, resilient to crashes, and provides explanations. Furthermore, it provides seamless Python integration by offloading various costly operations to the C++ core, not only mining.   In this demonstration, we show several scenarios that allow end users to solve different data quality problems. Namely, we showcase typo detection, data deduplication, and data anomaly detection scenarios.
</details>
<details>
<summary>摘要</summary>
现代数据驱动行业中，数据 profiling 是一项非常重要的过程。其中一个关键组件是发现和验证复杂的统计学，如功能依赖关系、数据约束、相关规则等。然而，大多数现有的数据 profiling 系统，主要关注于复杂的统计学，并不提供适当的工具集成。这创造了使用这些工具在行业中的显著障碍。此外，现有系统没有考虑现代化工作负荷，而且不提供描述性解释，即为什么某种特征没有出现。这是一个重要的问题，因为需要理解数据下的深层次原因，以便根据数据做出了 Informed 决策。由于这些原因，这些特征在实际应用中具有有限的应用范围，通常只有特定领域的专业人员使用。然而，我们将在这个演示中展示，复杂的统计学可以高效地解决许多经典数据质量问题。Desbordante 是一款开源的数据 profiler，旨在填补这个空白。它强调在工业应用中高效、可扩展、可靠、并提供描述性解释。此外，它通过将费时操作卷积到 C++ 核心中，实现了顺略的 Python 集成，不仅是探钻。在这个演示中，我们将展示一些使用 Desbordante 解决不同数据质量问题的场景。具体来说，我们将展示 typo 检测、数据重复检测和数据异常检测等场景。
</details></li>
</ul>
<hr>
<h2 id="Approximate-Model-Based-Shielding-for-Safe-Reinforcement-Learning"><a href="#Approximate-Model-Based-Shielding-for-Safe-Reinforcement-Learning" class="headerlink" title="Approximate Model-Based Shielding for Safe Reinforcement Learning"></a>Approximate Model-Based Shielding for Safe Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00707">http://arxiv.org/abs/2308.00707</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sacktock/ambs">https://github.com/sacktock/ambs</a></li>
<li>paper_authors: Alexander W. Goodall, Francesco Belardinelli</li>
<li>for: 这篇论文的目的是为了解决通用的问题，并在实际世界中应用增强学习（Reinforcement Learning，RL）。</li>
<li>methods: 本论文提出了一种名为“approximate model-based shielding”（AMBS）的原理性的预先观察措施，用于验证RL政策对于一些给定的安全限制的性能。AMBS不需要先知道系统的安全相关动力学。</li>
<li>results: 论文的实验结果显示，AMBS在一组Atari游戏中的状态依赖安全标签上表现较好，并且比其他安全意识的方法更好。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) has shown great potential for solving complex tasks in a variety of domains. However, applying RL to safety-critical systems in the real-world is not easy as many algorithms are sample-inefficient and maximising the standard RL objective comes with no guarantees on worst-case performance. In this paper we propose approximate model-based shielding (AMBS), a principled look-ahead shielding algorithm for verifying the performance of learned RL policies w.r.t. a set of given safety constraints. Our algorithm differs from other shielding approaches in that it does not require prior knowledge of the safety-relevant dynamics of the system. We provide a strong theoretical justification for AMBS and demonstrate superior performance to other safety-aware approaches on a set of Atari games with state-dependent safety-labels.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Scaling-Session-Based-Transformer-Recommendations-using-Optimized-Negative-Sampling-and-Loss-Functions"><a href="#Scaling-Session-Based-Transformer-Recommendations-using-Optimized-Negative-Sampling-and-Loss-Functions" class="headerlink" title="Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions"></a>Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14906">http://arxiv.org/abs/2307.14906</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/otto-de/tron">https://github.com/otto-de/tron</a></li>
<li>paper_authors: Timo Wilm, Philipp Normann, Sophie Baumeister, Paul-Vincent Kobow</li>
<li>for: 提高推荐质量和减少训练时间</li>
<li>methods: 使用最佳负样本和列wise损失函数增强推荐准确性</li>
<li>results: 在大规模电商数据集上比前方法提高推荐质量，同时保持训练速度类似于SASRec，实际场景中A&#x2F;B测试显示与SASRec比起提高18.14%的点击率。<details>
<summary>Abstract</summary>
This work introduces TRON, a scalable session-based Transformer Recommender using Optimized Negative-sampling. Motivated by the scalability and performance limitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates top-k negative sampling and listwise loss functions to enhance its recommendation accuracy. Evaluations on relevant large-scale e-commerce datasets show that TRON improves upon the recommendation quality of current methods while maintaining training speeds similar to SASRec. A live A/B test yielded an 18.14% increase in click-through rate over SASRec, highlighting the potential of TRON in practical settings. For further research, we provide access to our source code at https://github.com/otto-de/TRON and an anonymized dataset at https://github.com/otto-de/recsys-dataset.
</details>
<details>
<summary>摘要</summary>
这个工作介绍了TRON，一种可扩展的会话基于Transformer推荐器，使用优化的负样本选择来提高推荐精度。由于现有的模型如SASRec和GRU4Rec+的可扩展性和性能限制，TRON通过将top-k负样本和listwise损失函数结合使用来提高推荐精度。在相关的大规模电商数据集上进行评估，TRON与当前方法相比有所提高了推荐质量，同时保持与SASRec相同的训练速度。一次实际的A/B测试中，TRON比SASRec提高了18.14%的点击率，这表明TRON在实际场景中具有潜在的应用前景。如果您想了解更多细节，可以通过我们的GitHub仓库https://github.com/otto-de/TRON获得源代码，并通过https://github.com/otto-de/recsys-dataset获得匿名化的数据集。
</details></li>
</ul>
<hr>
<h2 id="CodeLens-An-Interactive-Tool-for-Visualizing-Code-Representations"><a href="#CodeLens-An-Interactive-Tool-for-Visualizing-Code-Representations" class="headerlink" title="CodeLens: An Interactive Tool for Visualizing Code Representations"></a>CodeLens: An Interactive Tool for Visualizing Code Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14902">http://arxiv.org/abs/2307.14902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuejun Guo, Seifeddine Bettaieb, Qiang Hu, Yves Le Traon, Qiang Tang</li>
<li>for: 这篇论文是为了提供一个可视化编程代码的工具，帮助开发者更好地理解和探索不同类型的代码表示方法。</li>
<li>methods: 这篇论文使用了多种代码表示方法，包括序列化的Token，抽象语法树（AST），数据流图（DFG）和控制流图（CFG）等。</li>
<li>results: 这篇论文介绍了一个名为CodeLens的工具，可以帮助开发者快速Visualize不同类型的代码表示，并且可以获取代码表示的输入数据，以便用于代码学习模型。<details>
<summary>Abstract</summary>
Representing source code in a generic input format is crucial to automate software engineering tasks, e.g., applying machine learning algorithms to extract information. Visualizing code representations can further enable human experts to gain an intuitive insight into the code. Unfortunately, as of today, there is no universal tool that can simultaneously visualise different types of code representations. In this paper, we introduce a tool, CodeLens, which provides a visual interaction environment that supports various representation methods and helps developers understand and explore them. CodeLens is designed to support multiple programming languages, such as Java, Python, and JavaScript, and four types of code representations, including sequence of tokens, abstract syntax tree (AST), data flow graph (DFG), and control flow graph (CFG). By using CodeLens, developers can quickly visualize the specific code representation and also obtain the represented inputs for models of code. The Web-based interface of CodeLens is available at http://www.codelens.org. The demonstration video can be found at http://www.codelens.org/demo.
</details>
<details>
<summary>摘要</summary>
“代码的抽象表示是软件工程中的关键，例如应用机器学习算法提取信息。可视化代码表示可以帮助人类专家获得直观的了解。却是，到目前为止，没有一个通用的工具可以同时视觉不同类型的代码表示。在这篇论文中，我们介绍了一个工具，CodeLens，它提供了一个可视化交互环境，支持多种代码表示方法，帮助开发者理解和探索代码。CodeLens支持多种编程语言，如Java、Python和JavaScript，以及四种代码表示方法，包括Token序列、抽象 sintaxis树（AST）、数据流图（DFG）和控制流图（CFG）。通过使用CodeLens，开发者可以快速视觉特定的代码表示，并获得代码表示的输入数据，以便用于代码模型。CodeLens的Web版本可在http://www.codelens.org/中找到，示例视频在http://www.codelens.org/demo。”
</details></li>
</ul>
<hr>
<h2 id="Text-guided-Foundation-Model-Adaptation-for-Pathological-Image-Classification"><a href="#Text-guided-Foundation-Model-Adaptation-for-Pathological-Image-Classification" class="headerlink" title="Text-guided Foundation Model Adaptation for Pathological Image Classification"></a>Text-guided Foundation Model Adaptation for Pathological Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14901">http://arxiv.org/abs/2307.14901</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yunkun-zhang/cite">https://github.com/yunkun-zhang/cite</a></li>
<li>paper_authors: Yunkun Zhang, Jin Gao, Mu Zhou, Xiaosong Wang, Yu Qiao, Shaoting Zhang, Dequan Wang</li>
<li>for: 强化数据稀缺的病理图像分类</li>
<li>methods: 利用语言模型预训练的各种生物医学文本知识，将图像和文本embeddings连接起来，增强图像分类性能</li>
<li>results: 在patchgastric癌病理图像 dataset上，与多个基elines比较，CITE方法 achieve leading performance，特别是在数据稀缺情况下Here’s the translation in English:</li>
<li>for: Enhancing data-efficient pathological image classification</li>
<li>methods: Utilizing language models pre-trained with a broad range of biomedical texts to connect image and text embeddings and enhance pathological image understanding</li>
<li>results: Leading performance compared with various baselines, especially when training data is scarce, demonstrated through extensive experiments on the PatchGastric stomach tumor pathological image dataset.<details>
<summary>Abstract</summary>
The recent surge of foundation models in computer vision and natural language processing opens up perspectives in utilizing multi-modal clinical data to train large models with strong generalizability. Yet pathological image datasets often lack biomedical text annotation and enrichment. Guiding data-efficient image diagnosis from the use of biomedical text knowledge becomes a substantial interest. In this paper, we propose to Connect Image and Text Embeddings (CITE) to enhance pathological image classification. CITE injects text insights gained from language models pre-trained with a broad range of biomedical texts, leading to adapt foundation models towards pathological image understanding. Through extensive experiments on the PatchGastric stomach tumor pathological image dataset, we demonstrate that CITE achieves leading performance compared with various baselines especially when training data is scarce. CITE offers insights into leveraging in-domain text knowledge to reinforce data-efficient pathological image classification. Code is available at https://github.com/Yunkun-Zhang/CITE.
</details>
<details>
<summary>摘要</summary>
最近几年，基金会模型在计算机视觉和自然语言处理领域的崛起，开启了使用多模态医疗数据训练大型模型的可能性。然而，病理图像 dataset  часто缺乏医学文献注释和丰富。引导数据不充分的图像诊断成为了一项重要的利益。在这篇论文中，我们提出了连接图像和文本嵌入（CITE），以增强病理图像分类。CITE 利用语言模型预训练的宽泛生物医学文献知识，导向基础模型向病理图像理解。通过对 PatchGastric 胃癌病理图像集进行了广泛的实验，我们示出了 CITE 在各种基elines中表现出了领先的性能，特别是在训练数据稀缺时。CITE 提供了使用域内文本知识来加强数据效率的病理图像分类的思路。代码可以在 https://github.com/Yunkun-Zhang/CITE 上获取。
</details></li>
</ul>
<hr>
<h2 id="Base-based-Model-Checking-for-Multi-Agent-Only-Believing-long-version"><a href="#Base-based-Model-Checking-for-Multi-Agent-Only-Believing-long-version" class="headerlink" title="Base-based Model Checking for Multi-Agent Only Believing (long version)"></a>Base-based Model Checking for Multi-Agent Only Believing (long version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14893">http://arxiv.org/abs/2307.14893</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Tiago de Lima, Emiliano Lorini, François Schwarzentruber</li>
<li>for: 这 paper 是用于描述 Multi-Agent 语言的 semantics 和如何自动检查其中的方程和动态扩展的 private belief expansion 算法。</li>
<li>methods: 这 paper 使用了 PSPACE 算法和一种专门的算法，它们都基于 reduction to QBF 和 state space 的探索。</li>
<li>results: 这 paper 提供了一个实现 QBF-based 算法，以及一些实际计算时间的示例数据。<details>
<summary>Abstract</summary>
We present a novel semantics for the language of multi-agent only believing exploiting belief bases, and show how to use it for automatically checking formulas of this language and of its dynamic extension with private belief expansion operators. We provide a PSPACE algorithm for model checking relying on a reduction to QBF and alternative dedicated algorithm relying on the exploration of the state space. We present an implementation of the QBF-based algorithm and some experimental results on computation time in a concrete example.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的 semantics для多智能语言，只信任滥用信仰基础，并示出如何使用它来自动检查这种语言和其动态扩展中的私有信仰扩展运算符的 формулы。我们提供了一个PSPACE算法 для模板检查，基于降reducible to QBF和一种专门的算法，基于状态空间的探索。我们提供了基于QBF的算法的实现和一些实际例子中的计算时间实验结果。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-Multi-Modal-3D-Human-Body-Pose-Estimation-for-Autonomous-Driving"><a href="#Weakly-Supervised-Multi-Modal-3D-Human-Body-Pose-Estimation-for-Autonomous-Driving" class="headerlink" title="Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving"></a>Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14889">http://arxiv.org/abs/2307.14889</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Bauer, Arij Bouazizi, Ulrich Kressel, Fabian B. Flohr<br>for: 这个论文的目的是提出一种简单 yet efficient的弱监督方法 для3D人姿估计在自动驾驶车辆（AV）上。methods: 这种方法使用了一种高级感知融合，将摄像头和LiDAR数据进行融合，并使用了一个Off-the-shelf 2D联合提取器和LiDAR到图像投影的pseudo标签来进行训练。results: 这种方法在Waymo开放数据集上的弱监督设定下，与当前最佳状态的结果相比，提高了$\sim$13%，并在超级监督设定下达到了当前最佳结果。<details>
<summary>Abstract</summary>
Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomous vehicles (AVs) to make informed decisions and respond proactively in critical road scenarios. Promising results of 3D HPE have been gained in several domains such as human-computer interaction, robotics, sports and medical analytics, often based on data collected in well-controlled laboratory environments. Nevertheless, the transfer of 3D HPE methods to AVs has received limited research attention, due to the challenges posed by obtaining accurate 3D pose annotations and the limited suitability of data from other domains.   We present a simple yet efficient weakly supervised approach for 3D HPE in the AV context by employing a high-level sensor fusion between camera and LiDAR data. The weakly supervised setting enables training on the target datasets without any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractor and pseudo labels generated from LiDAR to image projections. Our approach outperforms state-of-the-art results by up to $\sim$ 13% on the Waymo Open Dataset in the weakly supervised setting and achieves state-of-the-art results in the supervised setting.
</details>
<details>
<summary>摘要</summary>
精准的3D人姿估计（3DHPE）对自动驾驶车辆（AV）的决策和反应具有重要作用。在各个领域中，如人机交互、 робо扮、运动和医疗分析中，3DHPE已经获得了可观的成果，通常基于实验室环境中收集的数据。然而，将3DHPE方法应用于AV领域受到了限制的研究注意力，因为获得精准的3D姿势标注和其他领域数据的限制。我们提出了一种简单而高效的弱监督方法，通过高级感知融合相机和LiDAR数据来实现3DHPE在AV上。弱监督设定允许在目标数据集上进行训练，不需要2D/3D关键点标注，通过使用市售的2D联合抽取器和LiDAR到图像投影生成的pseudo标签。我们的方法在Waymo开放数据集上比州前一个月提高了$\sim$13%的表现，并在弱监督设定下实现了最佳表现。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-the-Potential-of-Seq2Seq-Models-as-Robust-Few-Shot-Learners"><a href="#Exploiting-the-Potential-of-Seq2Seq-Models-as-Robust-Few-Shot-Learners" class="headerlink" title="Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners"></a>Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14856">http://arxiv.org/abs/2307.14856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jihyeon Lee, Dain Kim, Doohae Jung, Boseop Kim, Kyoung-Woon On</li>
<li>for: 这个论文的目的是研究seq2seq模型在少量示例学习中的表现，以及如何更好地让seq2seq模型在这些任务上表现出几何学习的能力。</li>
<li>methods: 这个论文使用了decoder-only模型和encoder-decoder模型，并对这些模型进行了对比。另外， authors还提出了两种方法来提高seq2seq模型的在context few-shot learning中的表现：目标协调的提问和混合方法。</li>
<li>results: 实验结果显示， seq2seq模型在各种任务上的表现比 conventionalseq2seq模型更好，并且 authors的方法可以提高seq2seq模型的表现。特别是， authors的方法可以让seq2seq模型在少量示例学习中表现出几何学习的能力。<details>
<summary>Abstract</summary>
In-context learning, which offers substantial advantages over fine-tuning, is predominantly observed in decoder-only models, while encoder-decoder (i.e., seq2seq) models excel in methods that rely on weight updates. Recently, a few studies have demonstrated the feasibility of few-shot learning with seq2seq models; however, this has been limited to tasks that align well with the seq2seq architecture, such as summarization and translation. Inspired by these initial studies, we provide a first-ever extensive experiment comparing the in-context few-shot learning capabilities of decoder-only and encoder-decoder models on a broad range of tasks. Furthermore, we propose two methods to more effectively elicit in-context learning ability in seq2seq models: objective-aligned prompting and a fusion-based approach. Remarkably, our approach outperforms a decoder-only model that is six times larger and exhibits significant performance improvements compared to conventional seq2seq models across a variety of settings. We posit that, with the right configuration and prompt design, seq2seq models can be highly effective few-shot learners for a wide spectrum of applications.
</details>
<details>
<summary>摘要</summary>
内容学习，具有很大优势，主要在decoder-only模型中观察到，而encoder-decoder（即seq2seq）模型则在需要weight更新的方法中表现出色。最近几个研究已经证明了seq2seq模型可以实现几步学习，但这仅仅限于适合seq2seq架构的任务，如概要和翻译。我们受这些初期研究的启发，进行了首次广泛的实验， comparing the in-context few-shot learning能力of decoder-only和encoder-decoder模型在多种任务上。此外，我们也提出了两种方法，以更好地激发seq2seq模型的内容学习能力：目标对适配和融合方法。可以见，我们的方法在不同的设定和提示设计下，可以与decoder-only模型比较，并且在多种情况下表现出优秀的表现。我们认为，在适当的配置和提示设计下，seq2seq模型可以在广泛的应用中成为高效的几步学习模型。
</details></li>
</ul>
<hr>
<h2 id="Counterfactual-Explanations-for-Graph-Classification-Through-the-Lenses-of-Density"><a href="#Counterfactual-Explanations-for-Graph-Classification-Through-the-Lenses-of-Density" class="headerlink" title="Counterfactual Explanations for Graph Classification Through the Lenses of Density"></a>Counterfactual Explanations for Graph Classification Through the Lenses of Density</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14849">http://arxiv.org/abs/2307.14849</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/carlo-abrate/Counterfactual-Explanations-for-Graph-Classification-Through-the-Lenses-of-Density">https://github.com/carlo-abrate/Counterfactual-Explanations-for-Graph-Classification-Through-the-Lenses-of-Density</a></li>
<li>paper_authors: Carlo Abrate, Giulia Preti, Francesco Bonchi</li>
<li>for: 提供一种基于密度的对比例类型Counterfactual例子生成方法，用于解释图像分类器的决策。</li>
<li>methods: 使用不同类型的密集结构来生成对比例类型Counterfactual例子，包括打开或关闭三角形、驱动最大 clique。</li>
<li>results: 在7个大脑网络数据集中评估了不同实现方法的效果，并通过多种广泛使用的指标进行比较。结果表明，采用Semantic relevance的变换单元如密度是生成可靠和可读的对比例类型Counterfactual例子的关键。<details>
<summary>Abstract</summary>
Counterfactual examples have emerged as an effective approach to produce simple and understandable post-hoc explanations. In the context of graph classification, previous work has focused on generating counterfactual explanations by manipulating the most elementary units of a graph, i.e., removing an existing edge, or adding a non-existing one. In this paper, we claim that such language of explanation might be too fine-grained, and turn our attention to some of the main characterizing features of real-world complex networks, such as the tendency to close triangles, the existence of recurring motifs, and the organization into dense modules. We thus define a general density-based counterfactual search framework to generate instance-level counterfactual explanations for graph classifiers, which can be instantiated with different notions of dense substructures. In particular, we show two specific instantiations of this general framework: a method that searches for counterfactual graphs by opening or closing triangles, and a method driven by maximal cliques. We also discuss how the general method can be instantiated to exploit any other notion of dense substructures, including, for instance, a given taxonomy of nodes. We evaluate the effectiveness of our approaches in 7 brain network datasets and compare the counterfactual statements generated according to several widely-used metrics. Results confirm that adopting a semantic-relevant unit of change like density is essential to define versatile and interpretable counterfactual explanation methods.
</details>
<details>
<summary>摘要</summary>
counterfactual 例子在 graph 分类 задании中出现为一种有效的方法，生成简单易理解的后果解释。在图 classification 的上下文中，先前的工作都是通过修改图形的最基本单元，如删除现有的边或添加不存在的一个，来生成 counterfactual 解释。在这篇论文中，我们认为这种语言解释可能太细节，我们转移注意力到了现实世界中复杂网络的一些主要特征，如形成三角形的倾向，存在循环模式，以及组织成密集模块。我们因此定义了一种通用的density-based counterfactual 搜索框架，用于生成图分类器的实例级 counterfactual 解释，可以实现不同的归并概念。特别是，我们显示了两种特定的实现方式：通过打开或关闭三角形来搜索 counterfactual 图，以及通过最大 клиQUE 驱动。我们还讨论了如何使用其他任何密集结构的概念来实现该框架，包括例如给定的节点分类。我们在 7 个大脑网络数据集上评估了我们的方法，并与多种常用的度量进行比较。结果表明，采用 Semantic-relevant 的变化单元，如density，是生成可靠和可读的 counterfactual 解释方法的必要条件。
</details></li>
</ul>
<hr>
<h2 id="Seeing-through-the-Brain-Image-Reconstruction-of-Visual-Perception-from-Human-Brain-Signals"><a href="#Seeing-through-the-Brain-Image-Reconstruction-of-Visual-Perception-from-Human-Brain-Signals" class="headerlink" title="Seeing through the Brain: Image Reconstruction of Visual Perception from Human Brain Signals"></a>Seeing through the Brain: Image Reconstruction of Visual Perception from Human Brain Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02510">http://arxiv.org/abs/2308.02510</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Ting Lan, Kan Ren, Yansen Wang, Wei-Long Zheng, Dongsheng Li, Bao-Liang Lu, Lili Qiu</li>
<li>for: 这 paper 是关于人类视觉认知的研究，具体来说是利用 neuroscience 和人工智能技术来记录和复制人类视觉能力。</li>
<li>methods: 这 paper 使用了 electroencephalography (EEG) 信号来重建观察到的图像，并提出了一个全面的数据处理管道，名为 NeuroImagen，以提取有用信息并进行图像重建。</li>
<li>results: 实验结果表明，这 paper 的方法可以有效地重建图像，并且其表现比传统方法更为出色。<details>
<summary>Abstract</summary>
Seeing is believing, however, the underlying mechanism of how human visual perceptions are intertwined with our cognitions is still a mystery. Thanks to the recent advances in both neuroscience and artificial intelligence, we have been able to record the visually evoked brain activities and mimic the visual perception ability through computational approaches. In this paper, we pay attention to visual stimuli reconstruction by reconstructing the observed images based on portably accessible brain signals, i.e., electroencephalography (EEG) data. Since EEG signals are dynamic in the time-series format and are notorious to be noisy, processing and extracting useful information requires more dedicated efforts; In this paper, we propose a comprehensive pipeline, named NeuroImagen, for reconstructing visual stimuli images from EEG signals. Specifically, we incorporate a novel multi-level perceptual information decoding to draw multi-grained outputs from the given EEG data. A latent diffusion model will then leverage the extracted information to reconstruct the high-resolution visual stimuli images. The experimental results have illustrated the effectiveness of image reconstruction and superior quantitative performance of our proposed method.
</details>
<details>
<summary>摘要</summary>
seeing是信服，但是人类视觉 cognition 的下面机制仍然是一个谜。感谢最近的 neuroscience 和人工智能的进步，我们可以记录视觉诱发的脑动力和模拟视觉能力通过计算方法。在这篇文章中，我们关注视觉刺激重建，基于可 portable 的 brain signals，即 electroencephalography (EEG) 数据。因为 EEG 信号是时间序列格式的动态和具有噪声，处理和提取有用信息需要更多的努力。为此，我们提出了一个完整的管道，名为 NeuroImagen，用于从 EEG 信号中重建高分辨率的视觉刺激图像。 Specifically，我们采用了一种新的多级感知信息解码，以从给定的 EEG 数据中提取多层次输出。然后，一种潜在的扩散模型会利用提取的信息来重建高分辨率的视觉刺激图像。实验结果表明了图像重建的效果和我们提出的方法的数量性表现优于。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-ASP-based-multi-objective-scheduling-of-semiconductor-manufacturing-processes-Extended-version"><a href="#Hybrid-ASP-based-multi-objective-scheduling-of-semiconductor-manufacturing-processes-Extended-version" class="headerlink" title="Hybrid ASP-based multi-objective scheduling of semiconductor manufacturing processes (Extended version)"></a>Hybrid ASP-based multi-objective scheduling of semiconductor manufacturing processes (Extended version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14799">http://arxiv.org/abs/2307.14799</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed M. S. El-Kholany, Ramsha Ali, Martin Gebser</li>
<li>for: 本研究旨在实现现代半导体生产线上的调度，以满足对复杂生产过程和高科技机器的需求。</li>
<li>methods: 本研究使用混合Answer Set Programming with difference logic来模型半导体生产线上的特有需求，并包括可变机器处理、设置、批次和维护操作。</li>
<li>results: 本研究发现，在考虑多个优化目标下，大规模的调度可以实现更好的生产效率和流程可靠性，而非仅对单一机器或特定阶段进行地方优化。<details>
<summary>Abstract</summary>
Modern semiconductor manufacturing involves intricate production processes consisting of hundreds of operations, which can take several months from lot release to completion. The high-tech machines used in these processes are diverse, operate on individual wafers, lots, or batches in multiple stages, and necessitate product-specific setups and specialized maintenance procedures. This situation is different from traditional job-shop scheduling scenarios, which have less complex production processes and machines, and mainly focus on solving highly combinatorial but abstract scheduling problems. In this work, we address the scheduling of realistic semiconductor manufacturing processes by modeling their specific requirements using hybrid Answer Set Programming with difference logic, incorporating flexible machine processing, setup, batching and maintenance operations. Unlike existing methods that schedule semiconductor manufacturing processes locally with greedy heuristics or by independently optimizing specific machine group allocations, we examine the potentials of large-scale scheduling subject to multiple optimization objectives.
</details>
<details>
<summary>摘要</summary>
现代半导体生产包括复杂的生产过程，包括数百个操作，可能需要几个月时间从库存释放到完成。这些高科技机器在多个阶段中操作，需要产品特定的设置和维护过程。这与传统的作坊调度enario不同，后者的生产过程更为简单，主要关注解决高 combinatorial的Abstract调度问题。在这种工作中，我们使用混合Answer Set Programming with difference logic来模拟半导体生产过程的特定需求，包括灵活机器处理、设置、批处理和维护操作。与现有的方法不同，我们不仅使用本地剑指法或独立优化特定机器组分配置，而是尝试解决大规模调度问题，同时满足多个优化目标。
</details></li>
</ul>
<hr>
<h2 id="Emotion4MIDI-a-Lyrics-based-Emotion-Labeled-Symbolic-Music-Dataset"><a href="#Emotion4MIDI-a-Lyrics-based-Emotion-Labeled-Symbolic-Music-Dataset" class="headerlink" title="Emotion4MIDI: a Lyrics-based Emotion-Labeled Symbolic Music Dataset"></a>Emotion4MIDI: a Lyrics-based Emotion-Labeled Symbolic Music Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14783">http://arxiv.org/abs/2307.14783</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/serkansulun/lyricsemotions">https://github.com/serkansulun/lyricsemotions</a></li>
<li>paper_authors: Serkan Sulun, Pedro Oliveira, Paula Viana</li>
<li>for: 创建一个大规模的符号音乐数据集，包含12000首MIDI乐曲，用于探索音乐和情感之间的关系，以及开发能够根据特定情感生成音乐的模型。</li>
<li>methods: 首先在GoEmotions数据集上训练情感分类模型，实现了状态之内的最佳效果，并将这些模型应用于两个大规模的MIDI数据集中的歌词。</li>
<li>results: 创建了一个广泛的情感分类数据集，覆盖了多种细腻的情感，为研究音乐和情感之间的关系，以及开发能够根据特定情感生成音乐的模型提供了一个丰富的资源。<details>
<summary>Abstract</summary>
We present a new large-scale emotion-labeled symbolic music dataset consisting of 12k MIDI songs. To create this dataset, we first trained emotion classification models on the GoEmotions dataset, achieving state-of-the-art results with a model half the size of the baseline. We then applied these models to lyrics from two large-scale MIDI datasets. Our dataset covers a wide range of fine-grained emotions, providing a valuable resource to explore the connection between music and emotions and, especially, to develop models that can generate music based on specific emotions. Our code for inference, trained models, and datasets are available online.
</details>
<details>
<summary>摘要</summary>
我们提供了一个新的大规模符号音乐数据集，包含12000个MIDI歌曲。为创建这个数据集，我们首先在GoEmotions数据集上训练了情感分类模型，实现了状态之arte的结果，使用的模型比基线模型小半。然后，我们将这些模型应用到了两个大规模MIDI数据集中的歌词上。我们的数据集覆盖了各种细化的情感，提供了一个优质的资源，探索音乐和情感之间的连接，特别是开发基于具体情感的音乐生成模型。我们的推理代码、训练模型和数据集在线可用。
</details></li>
</ul>
<hr>
<h2 id="Car-Driver-Drowsiness-Assessment-through-1D-Temporal-Convolutional-Networks"><a href="#Car-Driver-Drowsiness-Assessment-through-1D-Temporal-Convolutional-Networks" class="headerlink" title="Car-Driver Drowsiness Assessment through 1D Temporal Convolutional Networks"></a>Car-Driver Drowsiness Assessment through 1D Temporal Convolutional Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02415">http://arxiv.org/abs/2308.02415</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Rundo, Concetto Spampinato, Michael Rundo</li>
<li>for: 这项研究旨在提高驾驶安全性，通过分析司机注意度水平。</li>
<li>methods: 该研究使用了一种新型的生物传感器，包括近红外LED发射器和光探测器，以分析司机生物学状态。同时，研究人员还开发了一种嵌入式时域频谱过滤技术，以及一种1D时间卷积架构，以实现实时识别司机睡眠状态。</li>
<li>results: 研究人员通过对实验数据进行分析，发现该系统可以准确地识别司机睡眠状态，准确率约为96%。<details>
<summary>Abstract</summary>
Recently, the scientific progress of Advanced Driver Assistance System solutions (ADAS) has played a key role in enhancing the overall safety of driving. ADAS technology enables active control of vehicles to prevent potentially risky situations. An important aspect that researchers have focused on is the analysis of the driver attention level, as recent reports confirmed a rising number of accidents caused by drowsiness or lack of attentiveness. To address this issue, various studies have suggested monitoring the driver physiological state, as there exists a well-established connection between the Autonomic Nervous System (ANS) and the level of attention. For our study, we designed an innovative bio-sensor comprising near-infrared LED emitters and photo-detectors, specifically a Silicon PhotoMultiplier device. This allowed us to assess the driver physiological status by analyzing the associated PhotoPlethysmography (PPG) signal.Furthermore, we developed an embedded time-domain hyper-filtering technique in conjunction with a 1D Temporal Convolutional architecture that embdes a progressive dilation setup. This integrated system enables near real-time classification of driver drowsiness, yielding remarkable accuracy levels of approximately 96%.
</details>
<details>
<summary>摘要</summary>
最近，高级驾驶助手技术(ADAS)的科学进步在提高驾驶安全方面扮演着关键角色。ADAS技术允许车辆活动控制，预防可能带来危险的情况。研究人员注重分析司机注意力水平，据报告显示，睡意或注意力不集中导致的交通事故的数量在增长。为解决这个问题，各种研究建议监测司机生理状况，因为存在自主神经系统(ANS)和注意力之间的很好的关系。为我们的研究，我们设计了一种创新的生物传感器，包括近红外LED发射器和光检测器，特别是一种半导体光产生器。这使得我们可以通过分析相关的血液压力信号来评估司机生理状况。此外，我们还开发了一种嵌入式时域频域滤波技术，并与一种1D时间卷积架构结合，实现了近实时的司机睡意分类，准确率达到约96%。
</details></li>
</ul>
<hr>
<h2 id="Fair-Machine-Unlearning-Data-Removal-while-Mitigating-Disparities"><a href="#Fair-Machine-Unlearning-Data-Removal-while-Mitigating-Disparities" class="headerlink" title="Fair Machine Unlearning: Data Removal while Mitigating Disparities"></a>Fair Machine Unlearning: Data Removal while Mitigating Disparities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14754">http://arxiv.org/abs/2307.14754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Oesterling, Jiaqi Ma, Flavio P. Calmon, Hima Lakkaraju</li>
<li>for: 这个论文的目的是提出一种可靠地忘记数据实例的机器学习方法，以保持集体公正性。</li>
<li>methods: 该论文使用了一种基于梯度下降的方法，通过让模型学习一个新的权重函数来忘记数据实例。</li>
<li>results: 该论文的实验结果表明，该方法可以有效地忘记数据实例，同时保持集体公正性。<details>
<summary>Abstract</summary>
As public consciousness regarding the collection and use of personal information by corporations grows, it is of increasing importance that consumers be active participants in the curation of corporate datasets. In light of this, data governance frameworks such as the General Data Protection Regulation (GDPR) have outlined the right to be forgotten as a key principle allowing individuals to request that their personal data be deleted from the databases and models used by organizations. To achieve forgetting in practice, several machine unlearning methods have been proposed to address the computational inefficiencies of retraining a model from scratch with each unlearning request. While efficient online alternatives to retraining, it is unclear how these methods impact other properties critical to real-world applications, such as fairness. In this work, we propose the first fair machine unlearning method that can provably and efficiently unlearn data instances while preserving group fairness. We derive theoretical results which demonstrate that our method can provably unlearn data instances while maintaining fairness objectives. Extensive experimentation with real-world datasets highlight the efficacy of our method at unlearning data instances while preserving fairness.
</details>
<details>
<summary>摘要</summary>
In this work, we propose the first fair machine unlearning method that can provably and efficiently unlearn data instances while preserving group fairness. We derive theoretical results that demonstrate our method can provably unlearn data instances while maintaining fairness objectives. Extensive experiments with real-world datasets show that our method is effective in unlearning data instances while preserving fairness.
</details></li>
</ul>
<hr>
<h2 id="LLMediator-GPT-4-Assisted-Online-Dispute-Resolution"><a href="#LLMediator-GPT-4-Assisted-Online-Dispute-Resolution" class="headerlink" title="LLMediator: GPT-4 Assisted Online Dispute Resolution"></a>LLMediator: GPT-4 Assisted Online Dispute Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16732">http://arxiv.org/abs/2307.16732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hannes Westermann, Jaromir Savelka, Karim Benyekhlef</li>
<li>For: The paper is written to explore the potential of using large language models (LLMs) to enhance online dispute resolution (ODR) processes, specifically in the context of high-volume, low-intensity legal disputes.* Methods: The paper proposes an experimental platform called LLMediator, which leverages GPT-4 to reformulate user messages, draft mediator responses, and potentially engage in discussions autonomously.* Results: The initial qualitative evaluations presented in the paper demonstrate the potential for LLMs to support ODR and facilitate amicable settlements, with promising results for the proof of concept.Here are the three points in Simplified Chinese text:* For: 本文是为了探讨利用现代大语言模型（LLM）来增强在线纠纷解决（ODR）过程，具体是在高量低度纠纷法律纠纷中。* Methods: 本文提出了一个名为LLMediator的实验平台，利用GPT-4来改写用户消息，写作仲裁员回复，并可能地自动参与讨论。* Results: 本文提出的初步质量评估显示LLM可以支持ODR，并且初步证明了概念的可行性。<details>
<summary>Abstract</summary>
In this article, we introduce LLMediator, an experimental platform designed to enhance online dispute resolution (ODR) by utilizing capabilities of state-of-the-art large language models (LLMs) such as GPT-4. In the context of high-volume, low-intensity legal disputes, alternative dispute resolution methods such as negotiation and mediation offer accessible and cooperative solutions for laypeople. These approaches can be carried out online on ODR platforms. LLMediator aims to improve the efficacy of such processes by leveraging GPT-4 to reformulate user messages, draft mediator responses, and potentially autonomously engage in the discussions. We present and discuss several features of LLMediator and conduct initial qualitative evaluations, demonstrating the potential for LLMs to support ODR and facilitate amicable settlements. The initial proof of concept is promising and opens up avenues for further research in AI-assisted negotiation and mediation.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们介绍LLMediator，一个实验性的平台，用于增强在线纠纷解决（ODR），通过使用现代大语言模型（LLM） such as GPT-4。在高量低激法律纠纷中，人们可以通过谈判和谈判来解决纠纷，这些方法可以在ODR平台上进行在线。LLMediator通过使用GPT-4来重新表达用户消息，制定仲裁者回复，以及可能地自动参与谈判。我们介绍了LLMediator的多种特性，并进行了初步质量评估，以示LLM可以支持ODR，并促进和谐解决方案。我们的初步证明有潜力，开启了AI助成谈判和谈判的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Annotation-free-Image-Captioning-with-Retrieval-augmented-Pseudo-Sentence-Generation"><a href="#Exploring-Annotation-free-Image-Captioning-with-Retrieval-augmented-Pseudo-Sentence-Generation" class="headerlink" title="Exploring Annotation-free Image Captioning with Retrieval-augmented Pseudo Sentence Generation"></a>Exploring Annotation-free Image Captioning with Retrieval-augmented Pseudo Sentence Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14750">http://arxiv.org/abs/2307.14750</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhiyuan-li-john/rapsg">https://github.com/zhiyuan-li-john/rapsg</a></li>
<li>paper_authors: Zhiyuan Li, Dongnan Liu, Heng Wang, Chaoyi Zhang, Weidong Cai<br>for:This paper proposes a new strategy for training an image captioner without annotated image-sentence pairs, which is to leverage prior knowledge from large pre-trained models (LPMs) and integrate a retrieval process to generate high-quality pseudo sentences.methods:The proposed method, called LPM + retrieval-augmented learning, consists of two main components: (1) Retrieval-augmented Pseudo Sentence Generation (RaPSG), which retrieves highly relevant short region descriptions from mismatching corpora and uses them to generate a variety of pseudo sentences with distinct representations and high quality, and (2) a fluency filter and a CLIP-guided training objective to facilitate model optimization.results:The proposed method achieves a CIDEr score of 78.1 (+5.1) while utilizing only 0.3% of the trainable parameters of the SOTA pre-training model (Flamingo3B), and outperforms the 1% semi-supervised image caption benchmark with a score of 93.4 CIDEr (+8.9) with a simple extension.<details>
<summary>Abstract</summary>
Training an image captioner without annotated image-sentence pairs has gained traction in recent years. Previous approaches can be categorized into two strategies: crawling sentences from mismatching corpora and aligning them with the given images as pseudo annotations, or pre-training the captioner using external image-text pairs. However, the aligning setting seems to reach its performance limit due to the quality problem of pairs, and pre-training requires significant computational resources. To address these challenges, we propose a new strategy ``LPM + retrieval-augmented learning" where the prior knowledge from large pre-trained models (LPMs) is leveraged as supervision, and a retrieval process is integrated to further reinforce its effectiveness. Specifically, we introduce Retrieval-augmented Pseudo Sentence Generation (RaPSG), which adopts an efficient approach to retrieve highly relevant short region descriptions from the mismatching corpora and use them to generate a variety of pseudo sentences with distinct representations as well as high quality via LPMs. In addition, a fluency filter and a CLIP-guided training objective are further introduced to facilitate model optimization. Experimental results demonstrate that our method surpasses the SOTA pre-training model (Flamingo3B) by achieving a CIDEr score of 78.1 (+5.1) while utilizing only 0.3% of its trainable parameters (1.3B VS 33M). Importantly, our approach eliminates the need of computationally expensive pre-training processes on external datasets (e.g., the requirement of 312M image-text pairs for Flamingo3B). We further show that with a simple extension, the generated pseudo sentences can be deployed as weak supervision to boost the 1% semi-supervised image caption benchmark up to 93.4 CIDEr score (+8.9) which showcases the versatility and effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
Recently, 没有annotated image-sentence对照的训练方法在image captioner领域受到了广泛关注。以前的方法可以分为两种策略：一是从不符对的corpus中抓取句子并将其与给定的图像作为pseudo注释进行对应，另一是使用外部的image-text对照来预训captioner。但是，对应设定似乎已经达到了性能的限制，因为对应对的问题和预训需要大量的计算资源。为了解决这些挑战，我们提出了一种新的策略“LPM+ Retrieval-augmented learning”，利用大型预训模型（LPM）的优先知识作为监督，并将检索过程集成到了模型训练中来进一步加强其效果。具体来说，我们提出了Retrieval-augmented Pseudo Sentence Generation（RaPSG）方法，通过高效的检索方式从不符对的corpus中检索高度相关的短区描述，并使用LPMs生成一系列高质量和多样化的pseudo句。此外，我们还引入了一个流利性筛选器和CLIP帮助的训练目标，以便优化模型。实验结果表明，我们的方法超过了预训模型（Flamingo3B）的SOTA分数（78.1 (+5.1），同时只使用0.3%的可训练参数（1.3B VS 33M）。重要的是，我们的方法消除了需要大量计算资源的预训过程（例如，需要312M个图像-文本对 дляFlamingo3B）。我们还证明了，通过一个简单的扩展，生成的pseudo句可以被用作弱级supervision，将1%的 semi-supervised image caption benchmark提高到93.4 CIDEr分数 (+8.9)，这说明了我们的方法的多样性和效果。
</details></li>
</ul>
<hr>
<h2 id="JusticeBot-A-Methodology-for-Building-Augmented-Intelligence-Tools-for-Laypeople-to-Increase-Access-to-Justice"><a href="#JusticeBot-A-Methodology-for-Building-Augmented-Intelligence-Tools-for-Laypeople-to-Increase-Access-to-Justice" class="headerlink" title="JusticeBot: A Methodology for Building Augmented Intelligence Tools for Laypeople to Increase Access to Justice"></a>JusticeBot: A Methodology for Building Augmented Intelligence Tools for Laypeople to Increase Access to Justice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02032">http://arxiv.org/abs/2308.02032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hannes Westermann, Karim Benyekhlef</li>
<li>for: 该论文旨在帮助非法专业人士解决法律问题。</li>
<li>methods: 该论文提出的方法是基于混合 случа法和规则逻辑的法律决策支持系统，通过问候用户的情况并提供法律信息、相似案例和下一步建议，帮助用户解决问题。</li>
<li>results: 该论文通过实现这种方法，为用户提供了一个可能帮助解决案件或在法律程序中行使权利的工具。<details>
<summary>Abstract</summary>
Laypeople (i.e. individuals without legal training) may often have trouble resolving their legal problems. In this work, we present the JusticeBot methodology. This methodology can be used to build legal decision support tools, that support laypeople in exploring their legal rights in certain situations, using a hybrid case-based and rule-based reasoning approach. The system ask the user questions regarding their situation and provides them with legal information, references to previous similar cases and possible next steps. This information could potentially help the user resolve their issue, e.g. by settling their case or enforcing their rights in court. We present the methodology for building such tools, which consists of discovering typically applied legal rules from legislation and case law, and encoding previous cases to support the user. We also present an interface to build tools using this methodology and a case study of the first deployed JusticeBot version, focused on landlord-tenant disputes, which has been used by thousands of individuals.
</details>
<details>
<summary>摘要</summary>
非法律专业人士（即没有法律训练的个人）经常遇到法律问题的解决困难。在这项工作中，我们介绍了JusticeBot方法论。这种方法可以用于建立法律决策支持工具，以帮助非法律专业人士在某些情况下探索他们的法律权利，采用混合案例基于和规则基于的思维方法。系统会问用户他们的情况，并提供他们法律信息、相似案例和可能的下一步。这些信息可能帮助用户解决他们的问题，例如和解案或在法律程序中保护他们的权利。我们介绍了这种方法的建立工具，包括从法律和案例中找到通常适用的法律规则，并将前例编码以支持用户。我们还介绍了使用这种方法构建工具的界面，以及一个关注JusticeBot版本1.0的案例研究，专注于房东和租户纠纷，已经被千余人使用。
</details></li>
</ul>
<hr>
<h2 id="New-Interaction-Paradigm-for-Complex-EDA-Software-Leveraging-GPT"><a href="#New-Interaction-Paradigm-for-Complex-EDA-Software-Leveraging-GPT" class="headerlink" title="New Interaction Paradigm for Complex EDA Software Leveraging GPT"></a>New Interaction Paradigm for Complex EDA Software Leveraging GPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14740">http://arxiv.org/abs/2307.14740</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smarton-empower/smarton-ai">https://github.com/smarton-empower/smarton-ai</a></li>
<li>paper_authors: Boyu Han, Xinyu Wang, Yifan Wang, Junyu Yan, Yidong Tian</li>
<li>for: 帮助 novice Printed Circuit Board (PCB) 设计者更好地使用 KiCad 等专业电子设计自动化 (EDA) 软件，通过人工智能 (AI) 交互助手Plugin 提高设计效率和用户体验。</li>
<li>methods: 基于 HuggingGPT 框架，采用大语言模型 GPT 和 BERT，实现任务规划和执行，包括分析帮助文档段落和执行不同插件，同时充分利用 KiCad 自身的电子设计和PCB  manipulate 功能。</li>
<li>results: 在 préliminary 测试中，SmartonAI 可以有效地简化 PCB 设计过程，将复杂的命令转化为易于理解的语言基于交互。这种 bridging  gap  между复杂的 EDA 软件和易用的交互 interfaces 可以帮助 novice 设计者更好地使用 KiCad 等软件，同时也适用于其他复杂的软件系统，展示了 AI 协助用户界面在不同领域的潜在潜力。<details>
<summary>Abstract</summary>
In the rapidly growing field of electronic design automation (EDA), professional software such as KiCad, Cadence , and Altium Designer provide increasingly extensive design functionalities. However, the intricate command structure and high learning curve create a barrier, particularly for novice printed circuit board (PCB) designers. This results in difficulties in selecting appropriate functions or plugins for varying design purposes, compounded by the lack of intuitive learning methods beyond traditional documentation, videos, and online forums. To address this challenge, an artificial intelligence (AI) interaction assist plugin for EDA software named SmartonAl is developed here, also KiCad is taken as the first example. SmartonAI is inspired by the HuggingGPT framework and employs large language models, such as GPT and BERT, to facilitate task planning and execution. On receiving a designer request, SmartonAI conducts a task breakdown and efficiently executes relevant subtasks, such as analysis of help documentation paragraphs and execution of different plugins, along with leveraging the built-in schematic and PCB manipulation functions in both SmartonAl itself and software. Our preliminary results demonstrate that SmartonAI can significantly streamline the PCB design process by simplifying complex commands into intuitive language-based interactions. By harnessing the powerful language capabilities of ChatGPT and the rich design functions of KiCad, the plugin effectively bridges the gap between complex EDA software and user-friendly interaction. Meanwhile, the new paradigm behind SmartonAI can also extend to other complex software systems, illustrating the immense potential of AI-assisted user interfaces in advancing digital interactions across various domains.
</details>
<details>
<summary>摘要</summary>
在日益发展的电子设计自动化（EDA）领域中，职业软件如KiCad、Cadence和Altium Designer提供越来越广泛的设计功能。然而，复杂的命令结构和学习曲线创造了一个障碍，特别是 для初级Printed Circuit Board（PCB）设计师。这导致选择适合的功能或插件在不同的设计目的上具有困难，并且缺乏直观的学习方法，只有通过传统的文档、视频和在线讨论来学习。为解决这个挑战，我们开发了一个人工智能（AI）互动助手插件 для EDA 软件，名为SmartonAl，KiCad 被选为首个示例。SmartonAI 基于 HuggingGPT 框架，采用大型语言模型，如 GPT 和 BERT，以便任务规划和执行。当设计者发送请求时，SmartonAI 会进行任务拆分，然后高效地执行相关的子任务，例如分析帮助文档段落和执行不同的插件，同时利用 SmartonAl 自身和软件中的基本电子设计和PCB  manipulate 功能。我们的初步结果表明，SmartonAI 可以很大程度地减少 PCB 设计过程中的复杂性，通过将复杂的命令转化为直观的语言基本互动。通过将ChatGPT 强大的语言能力和 KiCad  wealthy 的设计功能相结合，插件可以有效地将复杂的 EDA 软件和用户友好的互动相连。同时，SmartonAI 的新理念可以扩展到其他复杂的软件系统，illustrating the immense potential of AI-assisted user interfaces in advancing digital interactions across various domains.
</details></li>
</ul>
<hr>
<h2 id="Cortex-Inspired-Learning-to-Recover-Damaged-Signal-Modality-with-ReD-SOM-Model"><a href="#Cortex-Inspired-Learning-to-Recover-Damaged-Signal-Modality-with-ReD-SOM-Model" class="headerlink" title="Cortex Inspired Learning to Recover Damaged Signal Modality with ReD-SOM Model"></a>Cortex Inspired Learning to Recover Damaged Signal Modality with ReD-SOM Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15095">http://arxiv.org/abs/2307.15095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Artem Muliukov, Laurent Rodriguez, Benoit Miramond</li>
<li>for: 本研究旨在恢复lost的一个modalidad的数据，使用另一个modalidad的数据进行恢复。</li>
<li>methods: 本研究使用Variational Auto-Encoders、Self-Organizing Maps和Hebb连接在一起，构建了一个ReD-SOM模型，以模拟人脑中不同modalities之间的交互效应。</li>
<li>results: 实验结果表明，ReD-SOM模型可以有效地恢复lost的数据，并且在存在较大的信号扭曲情况下，效果更加remarkable。<details>
<summary>Abstract</summary>
Recent progress in the fields of AI and cognitive sciences opens up new challenges that were previously inaccessible to study. One of such modern tasks is recovering lost data of one modality by using the data from another one. A similar effect (called the McGurk Effect) has been found in the functioning of the human brain. Observing this effect, one modality of information interferes with another, changing its perception. In this paper, we propose a way to simulate such an effect and use it to reconstruct lost data modalities by combining Variational Auto-Encoders, Self-Organizing Maps, and Hebb connections in a unified ReD-SOM (Reentering Deep Self-organizing Map) model. We are inspired by human's capability to use different zones of the brain in different modalities, in case of having a lack of information in one of the modalities. This new approach not only improves the analysis of ambiguous data but also restores the intended signal! The results obtained on the multimodal dataset demonstrate an increase of quality of the signal reconstruction. The effect is remarkable both visually and quantitatively, specifically in presence of a significant degree of signal's distortion.
</details>
<details>
<summary>摘要</summary>
现代人工智能和认知科学的进步打开了以前无法研究的新挑战。其中一项现代任务是通过一种不同的感知modalities来恢复丢失的数据。人脑中的同样效应（叫做McGurk效应）也发现了类似的现象，人们在感知信息时，一种感知modalities会对另一种感知modalities产生干扰，从而改变它的感知。在这篇论文中，我们提议使用Variational Auto-Encoders、Self-Organizing Maps和Hebb连接在一起，实现一种 reunified ReD-SOM（再入Self-organizing Map）模型。我们受人类在不同感知modalities中使用不同的脑区域的启发，这种新方法不仅改善了抽象数据的分析，还能恢复原始信号！实验结果表明，在多模态数据集上，可以提高信号重建质量。效果是观察性和量度上有显著改善，特别在信号受到较大的扭曲时。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Generative-Models-for-Graph-to-Text-Generation"><a href="#Evaluating-Generative-Models-for-Graph-to-Text-Generation" class="headerlink" title="Evaluating Generative Models for Graph-to-Text Generation"></a>Evaluating Generative Models for Graph-to-Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14712">http://arxiv.org/abs/2307.14712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuzhouyuan/eval_g2t_genmodels">https://github.com/shuzhouyuan/eval_g2t_genmodels</a></li>
<li>paper_authors: Shuzhou Yuan, Michael Färber</li>
<li>for: 本研究旨在探讨生成模型在零shot情况下对图数据的文本生成能力。</li>
<li>methods: 我们使用GPT-3和ChatGPT生成模型，并对T5和BARTfinetuned LLM模型进行比较。</li>
<li>results: 我们的结果表明，生成模型能够生成流畅、连贯的文本，AGENDA和WebNLG数据集的BLEU分数分别为10.57和11.08。然而，我们的错误分析发现，生成模型仍然忽略实体之间的semantic关系，并且有时会生成hallucination或无关信息。<details>
<summary>Abstract</summary>
Large language models (LLMs) have been widely employed for graph-to-text generation tasks. However, the process of finetuning LLMs requires significant training resources and annotation work. In this paper, we explore the capability of generative models to generate descriptive text from graph data in a zero-shot setting. Specifically, we evaluate GPT-3 and ChatGPT on two graph-to-text datasets and compare their performance with that of finetuned LLM models such as T5 and BART. Our results demonstrate that generative models are capable of generating fluent and coherent text, achieving BLEU scores of 10.57 and 11.08 for the AGENDA and WebNLG datasets, respectively. However, our error analysis reveals that generative models still struggle with understanding the semantic relations between entities, and they also tend to generate text with hallucinations or irrelevant information. As a part of error analysis, we utilize BERT to detect machine-generated text and achieve high macro-F1 scores. We have made the text generated by generative models publicly available.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已广泛应用于图数据生成文本任务。然而，训练LLM模型需要巨量的资源和标注工作。在这篇论文中，我们探讨了生成模型是否可以从图数据生成描述性文本，而不需要训练。我们评估了GPT-3和ChatGPT模型在两个图数据生成文本任务上的表现，并与训练后的LLM模型T5和BART进行比较。我们的结果表明，生成模型可以生成流畅和一致的文本，AGENDA和WebNLG数据集上的BLEU分数分别为10.57和11.08。然而，我们的错误分析表明，生成模型仍然很难理解实体之间的semantic关系，同时也很容易生成幻觉或无关信息。为了进行错误分析，我们利用BERT检测机器生成文本，并实现了高macro-F1分数。我们已经公开了生成模型生成的文本。
</details></li>
</ul>
<hr>
<h2 id="A-Multimodal-Supervised-Machine-Learning-Approach-for-Satellite-based-Wildfire-Identification-in-Europe"><a href="#A-Multimodal-Supervised-Machine-Learning-Approach-for-Satellite-based-Wildfire-Identification-in-Europe" class="headerlink" title="A Multimodal Supervised Machine Learning Approach for Satellite-based Wildfire Identification in Europe"></a>A Multimodal Supervised Machine Learning Approach for Satellite-based Wildfire Identification in Europe</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02508">http://arxiv.org/abs/2308.02508</a></li>
<li>repo_url: None</li>
<li>paper_authors: Angelica Urbanelli, Luca Barco, Edoardo Arnaudo, Claudio Rossi</li>
<li>for: 提高自动化天然灾害检测系统的精度，特意开发了一种野火识别解决方案。</li>
<li>methods: 利用多种信息源，包括MODIS和VIIRS热点服务、EFFIS数据库、ERSI年度Land Use Land Cover（LULC）和Copernicus Sentinel-3数据，提出了一种多模态超级vised机器学习方法，实现了野火识别任务中的效果。</li>
<li>results: 实验结果表明，提出的方法可以有效地分解热点检测结果，将野火和其他事件区分开来。<details>
<summary>Abstract</summary>
The increasing frequency of catastrophic natural events, such as wildfires, calls for the development of rapid and automated wildfire detection systems. In this paper, we propose a wildfire identification solution to improve the accuracy of automated satellite-based hotspot detection systems by leveraging multiple information sources. We cross-reference the thermal anomalies detected by the Moderate-resolution Imaging Spectroradiometer (MODIS) and the Visible Infrared Imaging Radiometer Suite (VIIRS) hotspot services with the European Forest Fire Information System (EFFIS) database to construct a large-scale hotspot dataset for wildfire-related studies in Europe. Then, we propose a novel multimodal supervised machine learning approach to disambiguate hotspot detections, distinguishing between wildfires and other events. Our methodology includes the use of multimodal data sources, such as the ERSI annual Land Use Land Cover (LULC) and the Copernicus Sentinel-3 data. Experimental results demonstrate the effectiveness of our approach in the task of wildfire identification.
</details>
<details>
<summary>摘要</summary>
随着自然灾害的频繁发生，如野火，需要开发高速自动化野火检测系统。在这篇论文中，我们提出了一种野火识别解决方案，以提高自动通过卫星温度异常检测系统获取的热点数据的准确性。我们将模拟高分辨率柯比耶报警系统（MODIS）和可见近红外报警系统（VIIRS）的热点服务与欧洲林地火灾信息系统（EFFIS）数据库进行交叉参考，以建立欧洲大规模热点数据集，用于林地火灾相关研究。然后，我们提出了一种新的多模态指导学习方法，用于分解热点检测结果，并将野火和其他事件区分开来。我们的方法包括使用多模态数据源，如地图信息系统（ERSI）年度土地用途土地覆盖（LULC）数据和科学卫星三号数据。实验结果表明，我们的方法在野火识别任务中具有效果。
</details></li>
</ul>
<hr>
<h2 id="Prediction-of-wind-turbines-power-with-physics-informed-neural-networks-and-evidential-uncertainty-quantification"><a href="#Prediction-of-wind-turbines-power-with-physics-informed-neural-networks-and-evidential-uncertainty-quantification" class="headerlink" title="Prediction of wind turbines power with physics-informed neural networks and evidential uncertainty quantification"></a>Prediction of wind turbines power with physics-informed neural networks and evidential uncertainty quantification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14675">http://arxiv.org/abs/2307.14675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alfonso Gijón, Ainhoa Pujana-Goitia, Eugenio Perea, Miguel Molina-Solana, Juan Gómez-Romero</li>
<li>for: 这个研究旨在优化风力发电机的运行和维护，通过投角控制器和早期缺陷检测，提高风力发电机的发电效率和可靠性。</li>
<li>methods: 这个研究使用数据驱动方法来优化风力发电机的模型，将大量数据处理成更加精确和高效的模型，并且将物理限制给模型以保持其实际性。</li>
<li>results: 研究结果显示，使用物理限制的数据驱动模型可以实时预测风力发电机的发电功率、扭矩和功率系数，并且可以提供精确的不确定性估计。<details>
<summary>Abstract</summary>
The ever-growing use of wind energy makes necessary the optimization of turbine operations through pitch angle controllers and their maintenance with early fault detection. It is crucial to have accurate and robust models imitating the behavior of wind turbines, especially to predict the generated power as a function of the wind speed. Existing empirical and physics-based models have limitations in capturing the complex relations between the input variables and the power, aggravated by wind variability. Data-driven methods offer new opportunities to enhance wind turbine modeling of large datasets by improving accuracy and efficiency. In this study, we used physics-informed neural networks to reproduce historical data coming from 4 turbines in a wind farm, while imposing certain physical constraints to the model. The developed models for regression of the power, torque, and power coefficient as output variables showed great accuracy for both real data and physical equations governing the system. Lastly, introducing an efficient evidential layer provided uncertainty estimations of the predictions, proved to be consistent with the absolute error, and made possible the definition of a confidence interval in the power curve.
</details>
<details>
<summary>摘要</summary>
随着风能使用的增长，适用于风机操作的扭矩角度控制器和其维护的早期缺陷检测变得越来越重要。为了准确地预测风机生成的电力，特别是在风速变化的情况下，需要有高度准确和可靠的风机模型。现有的empirical和物理基于模型具有限制capture风机输入变量和电力之间的复杂关系，这使得预测电力的准确性受到风度的变化的影响。使用数据驱动方法可以提高风机模型的准确性和效率。在本研究中，我们使用物理信息权重 neural network来复制来自4台风机风电农的历史数据，并对模型受到物理限制。开发的 regression 模型的输出变量为电力、扭矩和功率系数表现出了很高的准确性，并且与物理方程统制系统的实际数据相符。最后，通过添加高效的证据层，我们实现了预测结果的uncertainty estimations，并证明与绝对错误之间的一致性。这使得可以定义风机电力曲线上的自信Interval。
</details></li>
</ul>
<hr>
<h2 id="Fuzzy-order-sorted-feature-logic"><a href="#Fuzzy-order-sorted-feature-logic" class="headerlink" title="Fuzzy order-sorted feature logic"></a>Fuzzy order-sorted feature logic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14669">http://arxiv.org/abs/2307.14669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gian Carlo Milanese, Gabriella Pasi</li>
<li>for: 本文探讨了一种基于函数表示和集合表示的知识表示和推理语言（OSF逻辑）的扩展，即将OSF逻辑扩展到不确定环境中。</li>
<li>methods: 本文使用了一种柔化包含关系来扩展OSF逻辑，其中包含关系是基于 zadeh 的包含关系。在这个柔化环境中，sort symbol 和 OSF term 都表示不确定集合。</li>
<li>results: 本文提出了一种基于柔化包含关系的 OSF 逻辑 semantics，并证明了这种 semantics 的准确性和可行性。此外，本文还提供了一种用于计算 OSF term 之间的包含关系度的算法，并证明了这种算法的复杂度。<details>
<summary>Abstract</summary>
Order-Sorted Feature (OSF) logic is a knowledge representation and reasoning language based on function-denoting feature symbols and set-denoting sort symbols ordered in a subsumption lattice. OSF logic allows the construction of record-like terms that represent classes of entities and that are themselves ordered in a subsumption relation. The unification algorithm for such structures provides an efficient calculus of type subsumption, which has been applied in computational linguistics and implemented in constraint logic programming languages such as LOGIN and LIFE and automated reasoners such as CEDAR. This work generalizes OSF logic to a fuzzy setting. We give a flexible definition of a fuzzy subsumption relation which generalizes Zadeh's inclusion between fuzzy sets. Based on this definition we define a fuzzy semantics of OSF logic where sort symbols and OSF terms denote fuzzy sets. We extend the subsumption relation to OSF terms and prove that it constitutes a fuzzy partial order with the property that two OSF terms are subsumed by one another in the crisp sense if and only if their subsumption degree is greater than 0. We show how to find the greatest lower bound of two OSF terms by unifying them and how to compute the subsumption degree between two OSF terms, and we provide the complexity of these operations.
</details>
<details>
<summary>摘要</summary>
订定排序特征逻规（OSF）逻规是一种知识表现和推理语言，基于功能表示特征符号和集合表示排序符号，顺序在一个包含关系中。OSF逻规允许建构记录类型的条件，并且这些条件顺序在包含关系中。数据整合算法适用于这些结构，实现了型别包含的快速计算，并且在计算语言中如LOGIN和LIFE以及自动推理工具中如CEDAR中实现。这个工作将OSF逻规扩展到模糊设定。我们提供一个洒处的包含关系定义，它为Zadeh的包含关系中的模糊集合提供了一个扩展。基于这个定义，我们定义了模糊OSF逻规， Sort symbol和OSF表达符号表示模糊集合。我们将包含关系扩展到OSF表达符号，并证明它具有模糊偏序的性质，即两个OSF表达符号之间的包含关系是在模糊上的，即它们之间的包含度大于0。我们还说明如何在两个OSF表达符号之间找到最小共识，以及如何计算两个OSF表达符号之间的包含度，并且提供了这些操作的复杂度。
</details></li>
</ul>
<hr>
<h2 id="Multi-Valued-Partial-Order-Plans-in-Numeric-Planning"><a href="#Multi-Valued-Partial-Order-Plans-in-Numeric-Planning" class="headerlink" title="Multi-Valued Partial Order Plans in Numeric Planning"></a>Multi-Valued Partial Order Plans in Numeric Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14660">http://arxiv.org/abs/2307.14660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hayyan Helal, Gerhard Lakemeyer</li>
<li>for: 研究 numeric planning 中的不可解析性的可能原因，通过研究动作的不同出现次数。</li>
<li>methods: 使用搜索问题的 reformulation，NP-complete 的 numeric planning 可以通过规则来找到。</li>
<li>results: 开发了多值部分顺序计划，一种用于（串行和并行）计划的最小commitment减少表示方式，并研究了优化技术以包含软前件。<details>
<summary>Abstract</summary>
Many planning formalisms allow for mixing numeric with Boolean effects. However, most of these formalisms are undecidable. In this paper, we will analyze possible causes for this undecidability by studying the number of different occurrences of actions, an approach that proved useful for metric fluents before. We will start by reformulating a numeric planning problem known as restricted tasks as a search problem. We will then show how an NP-complete fragment of numeric planning can be found by using heuristics. To achieve this, we will develop the idea of multi-valued partial order plans, a least committing compact representation for (sequential and parallel) plans. Finally, we will study optimization techniques for this representation to incorporate soft preconditions.
</details>
<details>
<summary>摘要</summary>
很多规划ormalism允许混合数字和布尔效果。然而，大多数这些ormalism是不可解决的。在这篇论文中，我们会分析可能导致这种不可解决性的原因，通过研究行动的不同出现次数来研究metric fluents的方法。我们将从restricted tasks中的数字规划问题开始，然后使用启发式将NP完全 Fragment of numeric planning转化为搜索问题。最后，我们将开发多值partial order plan的理想，一种用于（串行和并行）计划的最小承诺表示法。最后，我们将研究这种表示法的优化技术，以涵盖软前件。
</details></li>
</ul>
<hr>
<h2 id="MVMR-FS-Non-parametric-feature-selection-algorithm-based-on-Maximum-inter-class-Variation-and-Minimum-Redundancy"><a href="#MVMR-FS-Non-parametric-feature-selection-algorithm-based-on-Maximum-inter-class-Variation-and-Minimum-Redundancy" class="headerlink" title="MVMR-FS : Non-parametric feature selection algorithm based on Maximum inter-class Variation and Minimum Redundancy"></a>MVMR-FS : Non-parametric feature selection algorithm based on Maximum inter-class Variation and Minimum Redundancy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14643">http://arxiv.org/abs/2307.14643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haitao Nie, Shengbo Zhang, Bin Xie</li>
<li>for: 本研究旨在解决 Filter-based 特征选择方法无法直接测量连续数据中特征之间的重复性的问题。</li>
<li>methods: 本方法基于最大间类差和最小重复性，简称 MVMR-FS。首先，我们使用支持学习和无支持学习核密度估计来捕捉特征之间的相似性和总体分布的不同。然后，我们提出了最大间类差和最小重复性的 criterion，其中间类概率分布用于反映特征相关性，而总体分布距离用于衡量特征之间的重复性。最后，我们使用 AG 搜索算法来找到最佳特征子集，以最小化 MVMR。</li>
<li>results: 与十种现状顶尖方法进行比较后，MVMR-FS  achieved the highest average accuracy, and improved the accuracy by 5% to 11%.<details>
<summary>Abstract</summary>
How to accurately measure the relevance and redundancy of features is an age-old challenge in the field of feature selection. However, existing filter-based feature selection methods cannot directly measure redundancy for continuous data. In addition, most methods rely on manually specifying the number of features, which may introduce errors in the absence of expert knowledge. In this paper, we propose a non-parametric feature selection algorithm based on maximum inter-class variation and minimum redundancy, abbreviated as MVMR-FS. We first introduce supervised and unsupervised kernel density estimation on the features to capture their similarities and differences in inter-class and overall distributions. Subsequently, we present the criteria for maximum inter-class variation and minimum redundancy (MVMR), wherein the inter-class probability distributions are employed to reflect feature relevance and the distances between overall probability distributions are used to quantify redundancy. Finally, we employ an AGA to search for the feature subset that minimizes the MVMR. Compared with ten state-of-the-art methods, MVMR-FS achieves the highest average accuracy and improves the accuracy by 5% to 11%.
</details>
<details>
<summary>摘要</summary>
如何准确地衡量特征之间的相关性和重复性是机器学习领域的一个古老的挑战。然而，现有的筛选方法无法直接测量连续数据中的重复性。另外，大多数方法需要手动指定特征的数量，这可能会导致专家知识不足的情况下引入错误。在本文中，我们提出了一种非参数式特征选择算法基于最大间类差和最小重复性，简称MVMR-FS。我们首先引入supervised和unsupervised核密度估计来捕捉特征之间的相似性和总体分布的差异。然后，我们介绍了MVMR的标准，其中间类概率分布用于反映特征相关性，而总体概率分布的距离用于衡量特征之间的重复性。最后，我们使用AGA算法搜索最小化MVMR的特征子集，相比之下，与state-of-the-art方法相比，MVMR-FS实现了最高的平均准确率，提高了准确率5%到11%。
</details></li>
</ul>
<hr>
<h2 id="Fact-Checking-of-AI-Generated-Reports"><a href="#Fact-Checking-of-AI-Generated-Reports" class="headerlink" title="Fact-Checking of AI-Generated Reports"></a>Fact-Checking of AI-Generated Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14634">http://arxiv.org/abs/2307.14634</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Razi Mahmood, Ge Wang, Mannudeep Kalra, Pingkun Yan</li>
<li>for: 这篇论文的目的是为了提高 radiology 图像的自动生成报告的准确性和责任使用。</li>
<li>methods: 这篇论文提出了一新的方法，利用图像和报告之间的关联来检查生成的报告是否实际存在错误。</li>
<li>results: 这篇论文的结果显示，这新的方法可以对 automatically生成的报告进行检查，并删除假的句子，提高报告的准确性和责任使用。<details>
<summary>Abstract</summary>
With advances in generative artificial intelligence (AI), it is now possible to produce realistic-looking automated reports for preliminary reads of radiology images. This can expedite clinical workflows, improve accuracy and reduce overall costs. However, it is also well-known that such models often hallucinate, leading to false findings in the generated reports. In this paper, we propose a new method of fact-checking of AI-generated reports using their associated images. Specifically, the developed examiner differentiates real and fake sentences in reports by learning the association between an image and sentences describing real or potentially fake findings. To train such an examiner, we first created a new dataset of fake reports by perturbing the findings in the original ground truth radiology reports associated with images. Text encodings of real and fake sentences drawn from these reports are then paired with image encodings to learn the mapping to real/fake labels. The utility of such an examiner is demonstrated for verifying automatically generated reports by detecting and removing fake sentences. Future generative AI approaches can use the resulting tool to validate their reports leading to a more responsible use of AI in expediting clinical workflows.
</details>
<details>
<summary>摘要</summary>
使用生成式人工智能（AI），现在可以生成具有很好的真实感的自动报告，以便加速临床工作流程，提高准确性和降低总成本。然而，这些模型经常“见鬼”，导致自动生成的报告中出现假的结论。在这篇论文中，我们提议一种新的实验检查AI生成的报告的方法，specifically，我们通过学习图像和报告中的句子之间的关系，来分辨真实的和假的句子。为了训练这种检查器，我们首先创建了一个新的假报告数据集，其中perturb the findings在原始的基准真实Radiology report中。然后，我们对真实和假句子的文本编码和图像编码进行对应，以学习将它们映射到真实/假标签。我们证明了这种检查器可以用于检查自动生成的报告，以检测和移除假的句子。未来的生成AI方法可以使用这个工具来验证他们的报告，从而实现负责任的使用AI来加速临床工作流程。
</details></li>
</ul>
<hr>
<h2 id="Metric-Based-In-context-Learning-A-Case-Study-in-Text-Simplification"><a href="#Metric-Based-In-context-Learning-A-Case-Study-in-Text-Simplification" class="headerlink" title="Metric-Based In-context Learning: A Case Study in Text Simplification"></a>Metric-Based In-context Learning: A Case Study in Text Simplification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14632">http://arxiv.org/abs/2307.14632</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nlp-ku/metric-based-in-context-learning">https://github.com/nlp-ku/metric-based-in-context-learning</a></li>
<li>paper_authors: Subha Vadlamannati, Gözde Gül Şahin</li>
<li>for:  investigate the best method for selecting examples for in-context learning (ICL) in text simplification (TS) tasks.</li>
<li>methods:  propose a Metric-Based in-context Learning (MBL) method that uses commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection.</li>
<li>results:  show that examples selected by the top SARI scores perform the best on larger models, while the compression ratio generally performs better on smaller models. MBL is robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Additionally, the chosen metric can implicitly control the behavior of large GPT models.<details>
<summary>Abstract</summary>
In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose Metric-Based in-context Learning (MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Finally, we show that the behaviour of large GPT models can be implicitly controlled by the chosen metric. Our research provides a new framework for selecting examples in ICL, and demonstrates its effectiveness in text simplification tasks, breaking new ground for more accurate and efficient NLG systems.
</details>
<details>
<summary>摘要</summary>
大型语言模型的增Context学习（ICL）已经证明是许多自然语言处理任务的有力的方法。但是确定最佳的ICL例子选择方法是非常困难，因为结果可能会很大程度上取决于选择的例子质量、量和顺序。在这篇论文中，我们进行了TS（简化文本）案例研究，以 Investigate how to select the best and most robust examples for ICL。我们提出了Metric-Based in-context Learning（MBL）方法，该方法利用通用TS度量标准such as SARI、压缩率和BERT-Precision进行选择。通过对不同大小的GPT模型（GPT-175B、GPT-13B和GPT-6.7B）进行了广泛的实验，我们发现了TS的最高SARI分数选择的例子在更大的模型上表现最佳，而压缩率通常在较小的模型上表现更好。此外，我们还证明了MBL是对example顺序和尝试集的鲁棒的，并且超越了强基线和当前训练语言模型。最后，我们发现了选择的度量可以 implicitly控制大型GPT模型的行为。我们的研究提供了一个新的ICL例子选择框架，并证明其在TS任务中的效果，打破了更准确和有效的NLG系统的障碍。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Reservoir-Computing-and-its-Interdisciplinary-Applications-Beyond-Traditional-Machine-Learning"><a href="#A-Survey-on-Reservoir-Computing-and-its-Interdisciplinary-Applications-Beyond-Traditional-Machine-Learning" class="headerlink" title="A Survey on Reservoir Computing and its Interdisciplinary Applications Beyond Traditional Machine Learning"></a>A Survey on Reservoir Computing and its Interdisciplinary Applications Beyond Traditional Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15092">http://arxiv.org/abs/2307.15092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heng Zhang, Danilo Vasconcellos Vargas</li>
<li>for: 这篇论文主要探讨了储量计算（RC）的最新发展，从机器学习到物理、生物和神经科学。</li>
<li>methods:  RC 使用了随机连接的激活函数和非线性动力系统，可以处理时间信号处理等应用。</li>
<li>results: RC 可以实现高维空间的映射，具有良好的非线性特性和记忆能力，并且可以应用于多种领域。<details>
<summary>Abstract</summary>
Reservoir computing (RC), first applied to temporal signal processing, is a recurrent neural network in which neurons are randomly connected. Once initialized, the connection strengths remain unchanged. Such a simple structure turns RC into a non-linear dynamical system that maps low-dimensional inputs into a high-dimensional space. The model's rich dynamics, linear separability, and memory capacity then enable a simple linear readout to generate adequate responses for various applications. RC spans areas far beyond machine learning, since it has been shown that the complex dynamics can be realized in various physical hardware implementations and biological devices. This yields greater flexibility and shorter computation time. Moreover, the neuronal responses triggered by the model's dynamics shed light on understanding brain mechanisms that also exploit similar dynamical processes. While the literature on RC is vast and fragmented, here we conduct a unified review of RC's recent developments from machine learning to physics, biology, and neuroscience. We first review the early RC models, and then survey the state-of-the-art models and their applications. We further introduce studies on modeling the brain's mechanisms by RC. Finally, we offer new perspectives on RC development, including reservoir design, coding frameworks unification, physical RC implementations, and interaction between RC, cognitive neuroscience and evolution.
</details>
<details>
<summary>摘要</summary>
储池计算（RC），最初应用于时间信号处理，是一种循环神经网络，其中神经元随机连接。一旦初始化，连接强度保持不变。这种简单的结构使RC变成了一个非线性动力系统，可以将低维输入映射到高维空间中。模型的丰富动力、线性分离和记忆容量，然后允许简单的线性读取生成适用于各种应用的充分回应。RC的应用范围远超机器学习，因为它在不同的物理硬件实现和生物设备中也可以实现复杂的动力学过程。这提供了更大的灵活性和更短的计算时间。此外，由模型的动力触发的神经元响应，也有助于理解大脑机制，这些机制也利用类似的动力过程。在文献中，RC的发展是庞大的和杂乱的，在这里我们提供了一个统一的RC发展的评论，从机器学习到物理、生物和神经科学。我们首先评论了RC的早期模型，然后报道了当前的state-of-the-art模型和其应用。我们还介绍了通过RC模型大脑机制的研究。最后，我们提出了新的RC发展 Perspectives，包括储池设计、编程框架统一、物理RC实现和RC、认知神经科学和演化之间的交互。
</details></li>
</ul>
<hr>
<h2 id="BubbleML-A-Multi-Physics-Dataset-and-Benchmarks-for-Machine-Learning"><a href="#BubbleML-A-Multi-Physics-Dataset-and-Benchmarks-for-Machine-Learning" class="headerlink" title="BubbleML: A Multi-Physics Dataset and Benchmarks for Machine Learning"></a>BubbleML: A Multi-Physics Dataset and Benchmarks for Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14623">http://arxiv.org/abs/2307.14623</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hpcforge/bubbleml">https://github.com/hpcforge/bubbleml</a></li>
<li>paper_authors: Sheikh Md Shakeel Hassan, Arthur Feeney, Akash Dhruv, Jihoon Kim, Youngjoon Suh, Jaiyoung Ryu, Yoonjin Won, Aparna Chandramowlishwaran</li>
<li>for: 提供 Machine Learning 训练数据集，帮助更好地理解多物理现象的复杂性。</li>
<li>methods: 基于物理驱动的数值 simulations，提供了多种热层泵泡场景的准确基准信息，覆盖了重力条件、流速、冷却水温、壁超热等多个参数，共51个 simulations。</li>
<li>results: 验证了对实验观测的验证和趋势，并为多种下游任务提供了探索的可能性，如液体动态分析和温度动态学习网络。<details>
<summary>Abstract</summary>
In the field of phase change phenomena, the lack of accessible and diverse datasets suitable for machine learning (ML) training poses a significant challenge. Existing experimental datasets are often restricted, with limited availability and sparse ground truth data, impeding our understanding of this complex multi-physics phenomena. To bridge this gap, we present the BubbleML Dataset(https://github.com/HPCForge/BubbleML) which leverages physics-driven simulations to provide accurate ground truth information for various boiling scenarios, encompassing nucleate pool boiling, flow boiling, and sub-cooled boiling. This extensive dataset covers a wide range of parameters, including varying gravity conditions, flow rates, sub-cooling levels, and wall superheat, comprising 51 simulations. BubbleML is validated against experimental observations and trends, establishing it as an invaluable resource for ML research. Furthermore, we showcase its potential to facilitate exploration of diverse downstream tasks by introducing two benchmarks: (a) optical flow analysis to capture bubble dynamics, and (b) operator networks for learning temperature dynamics. The BubbleML dataset and its benchmarks serve as a catalyst for advancements in ML-driven research on multi-physics phase change phenomena, enabling the development and comparison of state-of-the-art techniques and models.
</details>
<details>
<summary>摘要</summary>
在热相转换现象领域，因缺乏可访问和多样化的数据集，使得机器学习（ML）训练受到很大的挑战。现有的实验数据往往受限，有限的可用性和稀缺的实际数据，使得我们对这种复杂多物理现象的理解受阻。为了缓解这个问题，我们提供了BubbleML数据集（https://github.com/HPCForge/BubbleML），该数据集利用物理驱动的 simulations提供了多种爆发情况的准确的真实数据，包括固定流体流速、不同的液体温度和壁超热等参数，涵盖51个 simulations。BubbleML被验证了对实验观察和趋势的验证，成为一项不可或缺的资源 для ML研究。此外，我们还介绍了两个标准准确：（a）光流分析以捕捉气泡动力学，以及（b）运算网络用于学习温度动力学。BubbleML数据集和其标准准确 serve as a catalyst for advancements in ML-driven research on multi-physics phase change phenomena，allowing the development and comparison of state-of-the-art techniques and models.
</details></li>
</ul>
<hr>
<h2 id="Self-Contrastive-Graph-Diffusion-Network"><a href="#Self-Contrastive-Graph-Diffusion-Network" class="headerlink" title="Self-Contrastive Graph Diffusion Network"></a>Self-Contrastive Graph Diffusion Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14613">http://arxiv.org/abs/2307.14613</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kunzhan/SCDGN">https://github.com/kunzhan/SCDGN</a></li>
<li>paper_authors: Yixian Ma, Kun Zhan</li>
<li>for: 本研究提出了一种新的框架 called Self-Contrastive Graph Diffusion Network (SCGDN), 用于 Graph Self-Contrastive Learning  paradigm，以解决现有方法中的一些限制。</li>
<li>methods: 该框架包括两个主要组件：Attentional Module (AttM) 和 Diffusion Module (DiFM)。AttM 通过聚合高阶结构和特征信息来获得优秀的嵌入，而 DiFM 通过拉普拉斯扩散学习平衡每个节点的状态，并让 adjacency 和特征信息在图中协同演化。</li>
<li>results: SCGDN 可以避免 “sampling bias” 和 semantic drift，无需预训练。通过高质量的采样方法，SCGDN 可以更好地保持高阶结构信息，并避免过拟合。实验结果表明，SCGDN 可以在对照方法和传统方法的比较中表现出优异表现。<details>
<summary>Abstract</summary>
Augmentation techniques and sampling strategies are crucial in contrastive learning, but in most existing works, augmentation techniques require careful design, and their sampling strategies can only capture a small amount of intrinsic supervision information. Additionally, the existing methods require complex designs to obtain two different representations of the data. To overcome these limitations, we propose a novel framework called the Self-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two main components: the Attentional Module (AttM) and the Diffusion Module (DiFM). AttM aggregates higher-order structure and feature information to get an excellent embedding, while DiFM balances the state of each node in the graph through Laplacian diffusion learning and allows the cooperative evolution of adjacency and feature information in the graph. Unlike existing methodologies, SCGDN is an augmentation-free approach that avoids "sampling bias" and semantic drift, without the need for pre-training. We conduct a high-quality sampling of samples based on structure and feature information. If two nodes are neighbors, they are considered positive samples of each other. If two disconnected nodes are also unrelated on $k$NN graph, they are considered negative samples for each other. The contrastive objective reasonably uses our proposed sampling strategies, and the redundancy reduction term minimizes redundant information in the embedding and can well retain more discriminative information. In this novel framework, the graph self-contrastive learning paradigm gives expression to a powerful force. SCGDN effectively balances between preserving high-order structure information and avoiding overfitting. The results manifest that SCGDN can consistently generate outperformance over both the contrastive methods and the classical methods.
</details>
<details>
<summary>摘要</summary>
《增强技术和采样策略是对冲学习中的关键，但现有的方法通常需要仔细设计增强技术，并且只能捕捉到小量内在监督信息。此外，现有的方法需要复杂的设计来获得两种不同的数据表示。为了解决这些限制，我们提出了一种新的框架called Self-Contrastive Graph Diffusion Network (SCGDN)。我们的框架包括两个主要组成部分：Attentional Module (AttM)和Diffusion Module (DiFM)。AttM将高阶结构和特征信息聚合以获得优秀的嵌入，而DiFM通过拉普拉斯扩散学习平衡每个节点在图中的状态，并允许邻居和特征信息在图中协同演化。与现有方法不同，SCGDN不需要增强技术和采样偏见，无需预训练。我们采用高质量的采样策略，根据结构和特征信息进行采样。如果两个节点相邻，它们被视为对方的正例；如果两个不相邻的节点也不在$k$NN图中相关，它们被视为对方的负例。对冲目标合理使用我们提议的采样策略，并且减少纠纷信息的概率逻辑可以良好地保留更多的特征信息。在这种新的框架中，图自相关学习方式表达出了强大的力量。SCGDN能够均衡保持高阶结构信息和避免过拟合。结果表明SCGDN可以一直在对冲方法和传统方法之上出现出色的性能。》
</details></li>
</ul>
<hr>
<h2 id="Clustering-based-Point-Cloud-Representation-Learning-for-3D-Analysis"><a href="#Clustering-based-Point-Cloud-Representation-Learning-for-3D-Analysis" class="headerlink" title="Clustering based Point Cloud Representation Learning for 3D Analysis"></a>Clustering based Point Cloud Representation Learning for 3D Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14605">http://arxiv.org/abs/2307.14605</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fengzicai/cluster3dseg">https://github.com/fengzicai/cluster3dseg</a></li>
<li>paper_authors: Tuo Feng, Wenguan Wang, Xiaohan Wang, Yi Yang, Qinghua Zheng</li>
<li>for: 这种研究的目的是提出一种基于归一化的超参数学习方法，以自动发现 scene中的 subclass 模式，从而提高点云分析 task 的稳定性和敏感性。</li>
<li>methods: 这种方法使用 clustering 技术在点云 embedding 空间中进行内类划分，以挖掘Scene中的 latent 模式。然后，这些模式被用来重新绘制 embedding 空间，以更好地遵循训练数据集的下面分布，提高对变化的抗锋性。</li>
<li>results: 这种方法在多种3D网络架构（包括 voxel-based、point-based 和 Transformer-based）上显示了显著的改进（即2.0-2.6% 和 1.8-1.9% 在 SemanticKITTI 和 S3DIS  datasets 上），并且在 KITTI 上也显示了2.0-3.4% mAP 的提升。<details>
<summary>Abstract</summary>
Point cloud analysis (such as 3D segmentation and detection) is a challenging task, because of not only the irregular geometries of many millions of unordered points, but also the great variations caused by depth, viewpoint, occlusion, etc. Current studies put much focus on the adaption of neural networks to the complex geometries of point clouds, but are blind to a fundamental question: how to learn an appropriate point embedding space that is aware of both discriminative semantics and challenging variations? As a response, we propose a clustering based supervised learning scheme for point cloud analysis. Unlike current de-facto, scene-wise training paradigm, our algorithm conducts within-class clustering on the point embedding space for automatically discovering subclass patterns which are latent yet representative across scenes. The mined patterns are, in turn, used to repaint the embedding space, so as to respect the underlying distribution of the entire training dataset and improve the robustness to the variations. Our algorithm is principled and readily pluggable to modern point cloud segmentation networks during training, without extra overhead during testing. With various 3D network architectures (i.e., voxel-based, point-based, Transformer-based, automatically searched), our algorithm shows notable improvements on famous point cloud segmentation datasets (i.e.,2.0-2.6% on single-scan and 2.0-2.2% multi-scan of SemanticKITTI, 1.8-1.9% on S3DIS, in terms of mIoU). Our algorithm also demonstrates utility in 3D detection, showing 2.0-3.4% mAP gains on KITTI.
</details>
<details>
<summary>摘要</summary>
点云分析（如3D segmentation和检测）是一项复杂的任务，因为点云的不规则形状以及深度、视点、遮挡等因素引起的巨大变化。现有研究强调用神经网络适应点云的复杂 geometries，但忽略了一个基本问题：如何学习适当的点云嵌入空间，考虑到both discriminative semantics和挑战性变化？作为回应，我们提出了一种 clustering 基于超级vised learning 方案 для点云分析。与当前的 scene-wise 训练方法不同，我们的算法在点云嵌入空间内进行 Within-class  clustering，以自动发现 scene 中的 Representative  subclass 模式。挖掘出来的模式会被用来重新绘制嵌入空间，以使其遵循整个训练数据集的下面分布，提高对变化的 robustness。我们的算法是理性的，可以在现代点云 segmentation 网络中进行实时插值，无需测试时间过载。与不同的3D网络架构（i.e., voxel-based, point-based, Transformer-based, automatically searched）结合使用，我们的算法在著名的点云 segmentation 数据集（i.e., SemanticKITTI 2.0-2.6%、S3DIS 1.8-1.9%， terms of mIoU）上显示了显著的提升。我们的算法还在3D检测中展示了2.0-3.4% mAP 的提升。
</details></li>
</ul>
<hr>
<h2 id="The-detection-and-rectification-for-identity-switch-based-on-unfalsified-control"><a href="#The-detection-and-rectification-for-identity-switch-based-on-unfalsified-control" class="headerlink" title="The detection and rectification for identity-switch based on unfalsified control"></a>The detection and rectification for identity-switch based on unfalsified control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14591">http://arxiv.org/abs/2307.14591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junchao Huang, Xiaoqi He, Sheng Zhao</li>
<li>for: 这 paper 是为了解决视频中的多对象跟踪问题，并且提出了一种基于不做假的控制方法来解决 ID-switch 问题。</li>
<li>methods: 该 paper 使用了一种特定的检测和修正模块来检测 ID-switch，并提出了一种简单有效的匹配方法来解决 ambiguous 匹配问题。</li>
<li>results: 实验结果表明，该 tracker 在覆盖和快速运动导致的跟踪错误问题下表现出色，并且具有极高的效果和稳定性。<details>
<summary>Abstract</summary>
The purpose of multi-object tracking (MOT) is to continuously track and identify objects detected in videos. Currently, most methods for multi-object tracking model the motion information and combine it with appearance information to determine and track objects. In this paper, unfalsified control is employed to address the ID-switch problem in multi-object tracking. We establish sequences of appearance information variations for the trajectories during the tracking process and design a detection and rectification module specifically for ID-switch detection and recovery. We also propose a simple and effective strategy to address the issue of ambiguous matching of appearance information during the data association process. Experimental results on publicly available MOT datasets demonstrate that the tracker exhibits excellent effectiveness and robustness in handling tracking errors caused by occlusions and rapid movements.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate english text into simplified chineseThe purpose of multi-object tracking (MOT) is to continuously track and identify objects detected in videos. Currently, most methods for multi-object tracking model the motion information and combine it with appearance information to determine and track objects. In this paper, unfalsified control is employed to address the ID-switch problem in multi-object tracking. We establish sequences of appearance information variations for the trajectories during the tracking process and design a detection and rectification module specifically for ID-switch detection and recovery. We also propose a simple and effective strategy to address the issue of ambiguous matching of appearance information during the data association process. Experimental results on publicly available MOT datasets demonstrate that the tracker exhibits excellent effectiveness and robustness in handling tracking errors caused by occlusions and rapid movements.<</SYS>>Here's the translation in Traditional Chinese:<<SYS>> translate english text into traditional chineseThe purpose of multi-object tracking (MOT) is to continuously track and identify objects detected in videos. Currently, most methods for multi-object tracking model the motion information and combine it with appearance information to determine and track objects. In this paper, unfalsified control is employed to address the ID-switch problem in multi-object tracking. We establish sequences of appearance information variations for the trajectories during the tracking process and design a detection and rectification module specifically for ID-switch detection and recovery. We also propose a simple and effective strategy to address the issue of ambiguous matching of appearance information during the data association process. Experimental results on publicly available MOT datasets demonstrate that the tracker exhibits excellent effectiveness and robustness in handling tracking errors caused by occlusions and rapid movements.<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Explainable-Techniques-for-Analyzing-Flow-Cytometry-Cell-Transformers"><a href="#Explainable-Techniques-for-Analyzing-Flow-Cytometry-Cell-Transformers" class="headerlink" title="Explainable Techniques for Analyzing Flow Cytometry Cell Transformers"></a>Explainable Techniques for Analyzing Flow Cytometry Cell Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14581">http://arxiv.org/abs/2307.14581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florian Kowarsch, Lisa Weijler, FLorian Kleber, Matthias Wödlinger, Michael Reiter, Margarita Maurer-Granofszky, Michael Dworzak<br>for:This paper aims to improve explainability for deep learning models in clinical applications, specifically for Flow CytoMetry (FCM) data.methods:The authors propose and evaluate two visualization techniques for cell classification and polygon regression on pediatric Acute Lymphoblastic Leukemia (ALL) FCM samples: gradient-based visualization and attention visualization. These techniques are tailored for FCM data and utilize a transformer architecture called ReluFormer.results:The results demonstrate the effectiveness of the proposed visualization techniques in outlining the model’s decision process and providing insights into the transformer’s decision-making process when handling FCM data. The gradient-based visualization identifies cells that are most significant for a particular prediction, while the attention visualization shows that different attention heads specialize by attending to different biologically meaningful sub-populations in the data.<details>
<summary>Abstract</summary>
Explainability for Deep Learning Models is especially important for clinical applications, where decisions of automated systems have far-reaching consequences.   While various post-hoc explainable methods, such as attention visualization and saliency maps, already exist for common data modalities, including natural language and images, little work has been done to adapt them to the modality of Flow CytoMetry (FCM) data.   In this work, we evaluate the usage of a transformer architecture called ReluFormer that ease attention visualization as well as we propose a gradient- and an attention-based visualization technique tailored for FCM. We qualitatively evaluate the visualization techniques for cell classification and polygon regression on pediatric Acute Lymphoblastic Leukemia (ALL) FCM samples. The results outline the model's decision process and demonstrate how to utilize the proposed techniques to inspect the trained model. The gradient-based visualization not only identifies cells that are most significant for a particular prediction but also indicates the directions in the FCM feature space in which changes have the most impact on the prediction. The attention visualization provides insights on the transformer's decision process when handling FCM data. We show that different attention heads specialize by attending to different biologically meaningful sub-populations in the data, even though the model retrieved solely supervised binary classification signals during training.
</details>
<details>
<summary>摘要</summary>
deep learning 模型的可解释性特别重要于临床应用，因为机器自动系统的决策对结果有深远的影响。  exist 多种后处可解释方法，如注意力视觉和积分地图，已经应用于常见的数据模式，如自然语言和图像。 然而，对流率维度测试（FCM）数据的可解释方法尚未得到广泛的研究。 在这种情况下，我们评估了一种名为ReLUFormer的transformer架构，以便进行注意力视觉以及我们提议了一种基于梯度和注意力的FCM数据可视化技术。 我们质量评估了这些可视化技术在儿童急性 лимфоblastLeukemia（ALL）FCM样本上进行细胞分类和多边 regression。 结果表明了模型做出的决策过程，并示出了如何使用我们提议的技术来检查训练的模型。 梯度可视化不仅可以确定细胞分类中最重要的细胞，还可以指示FCM特征空间中改变的方向具有最大影响。 注意力可视化为模型处理FCM数据的决策过程提供了启示，我们发现了不同的注意力头专注于不同的生物学意义的子 популяción，即使模型只在训练过程中获得了简单的二分类信号。
</details></li>
</ul>
<hr>
<h2 id="A-Memory-Augmented-Multi-Task-Collaborative-Framework-for-Unsupervised-Traffic-Accident-Detection-in-Driving-Videos"><a href="#A-Memory-Augmented-Multi-Task-Collaborative-Framework-for-Unsupervised-Traffic-Accident-Detection-in-Driving-Videos" class="headerlink" title="A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised Traffic Accident Detection in Driving Videos"></a>A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised Traffic Accident Detection in Driving Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14575">http://arxiv.org/abs/2307.14575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rongqin Liang, Yuanman Li, Yingxin Yi, Jiantao Zhou, Xia Li</li>
<li>for: 本研究旨在提高自动驾驶和助手系统的安全性，通过识别驾驶视频中的交通事故。</li>
<li>methods: 我们提出了一种新的记忆增强多任务协同框架（MAMTCF），通过同时模型视频帧中的出现变化和物体运动来更准确地检测交通事故。我们还引入了一种具有记忆的动作表示机制，以全面探索不同类型的运动表示之间的相互关系，并利用存储在内存中的常见交通模式高级特征来增强动作表示。</li>
<li>results: 我们的方法在最新的大规模数据集上进行了实验，与之前的状态时的方法相比，我们的方法可以更好地检测交通事故。<details>
<summary>Abstract</summary>
Identifying traffic accidents in driving videos is crucial to ensuring the safety of autonomous driving and driver assistance systems. To address the potential danger caused by the long-tailed distribution of driving events, existing traffic accident detection (TAD) methods mainly rely on unsupervised learning. However, TAD is still challenging due to the rapid movement of cameras and dynamic scenes in driving scenarios. Existing unsupervised TAD methods mainly rely on a single pretext task, i.e., an appearance-based or future object localization task, to detect accidents. However, appearance-based approaches are easily disturbed by the rapid movement of the camera and changes in illumination, which significantly reduce the performance of traffic accident detection. Methods based on future object localization may fail to capture appearance changes in video frames, making it difficult to detect ego-involved accidents (e.g., out of control of the ego-vehicle). In this paper, we propose a novel memory-augmented multi-task collaborative framework (MAMTCF) for unsupervised traffic accident detection in driving videos. Different from previous approaches, our method can more accurately detect both ego-involved and non-ego accidents by simultaneously modeling appearance changes and object motions in video frames through the collaboration of optical flow reconstruction and future object localization tasks. Further, we introduce a memory-augmented motion representation mechanism to fully explore the interrelation between different types of motion representations and exploit the high-level features of normal traffic patterns stored in memory to augment motion representations, thus enlarging the difference from anomalies. Experimental results on recently published large-scale dataset demonstrate that our method achieves better performance compared to previous state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
identifying traffic accidents in driving videos是Autonomous driving和driver assistance system的关键安全因素。为了解决驾驶场景中异常事件的长尾分布问题，现有的交通事故检测（TAD）方法主要采用不监督学习。然而，TAD仍然是挑战，因为驾驶场景中的相机和场景在快速运动中变化。现有的不监督TAD方法主要基于单一假设任务，即外观基于的或未来对象定位任务，以检测事故。然而，外观基于的方法容易受到相机快速运动和光照变化的影响，导致事故检测性能下降。基于未来对象定位任务的方法可能无法捕捉视频帧中的外观变化，从而困难检测 egovolved 事故（例如， egovolved 车辆失控）。在本文中，我们提出了一种新的记忆增强多任务合作框架（MAMTCF），用于不监督交通事故检测。与之前的方法不同，我们的方法可以更准确地检测 egovolved 和非 egovolved 事故，通过视频帧中的相机运动和未来对象定位任务的共同模型化，捕捉视频帧中的外观变化和对象运动。此外，我们引入记忆增强运动表示机制，全面利用不同类型的运动表示之间的相互关系，并通过记忆中高级特征来增强运动表示，从而增大与异常之间的差异。实验结果表明，我们的方法在最新的大规模数据集上达到了前一个 estado del arte 方法的性能。
</details></li>
</ul>
<hr>
<h2 id="Evaluation-of-Safety-Constraints-in-Autonomous-Navigation-with-Deep-Reinforcement-Learning"><a href="#Evaluation-of-Safety-Constraints-in-Autonomous-Navigation-with-Deep-Reinforcement-Learning" class="headerlink" title="Evaluation of Safety Constraints in Autonomous Navigation with Deep Reinforcement Learning"></a>Evaluation of Safety Constraints in Autonomous Navigation with Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14568">http://arxiv.org/abs/2307.14568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brian Angulo, Gregory Gorbov, Aleksandr Panov, Konstantin Yakovlev</li>
<li>for: 这个研究旨在高亮安全性因素在自动驾驶系统中的重要性，并对两种不同的学习导航策略进行比较。</li>
<li>methods: 这个研究使用了一种不同的学习导航策略，即考虑安全性因素的“安全”策略，与不考虑安全性因素的“危险”策略进行比较。</li>
<li>results: 研究结果表明，使用“安全”策略可以生成更多的减噪距离（距离障碍物），避免更多的碰撞，同时不 sacrificing总性能。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
While reinforcement learning algorithms have had great success in the field of autonomous navigation, they cannot be straightforwardly applied to the real autonomous systems without considering the safety constraints. The later are crucial to avoid unsafe behaviors of the autonomous vehicle on the road. To highlight the importance of these constraints, in this study, we compare two learnable navigation policies: safe and unsafe. The safe policy takes the constraints into account, while the other does not. We show that the safe policy is able to generate trajectories with more clearance (distance to the obstacles) and makes less collisions while training without sacrificing the overall performance.
</details>
<details>
<summary>摘要</summary>
Autonomous navigation algorithms based on reinforcement learning have achieved great success, but they cannot be directly applied to real-world autonomous systems without considering safety constraints. These constraints are crucial to avoid dangerous behaviors of the autonomous vehicle on the road. To emphasize the importance of these constraints, in this study, we compare two learnable navigation policies: safe and unsafe. The safe policy takes the constraints into account, while the other does not. We show that the safe policy can generate trajectories with more clearance (distance to obstacles) and makes fewer collisions while training without sacrificing overall performance.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Understanding-Forward-Process-of-Convolutional-Neural-Network"><a href="#Understanding-Forward-Process-of-Convolutional-Neural-Network" class="headerlink" title="Understanding Forward Process of Convolutional Neural Network"></a>Understanding Forward Process of Convolutional Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15090">http://arxiv.org/abs/2307.15090</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning">https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning</a></li>
<li>paper_authors: Peixin Tian</li>
<li>for: 描述 CNN 的前向处理中的选择性旋转</li>
<li>methods: 利用 activation function 作为筛选和归一化输入数据的机制，并通过应用结构化数学工具来分析输入的统计指标</li>
<li>results: 研究发现，这种定义的方法让网络能够根据统计指标来分辨输入，并且发现人工神经网络和人脑在数据处理模式上存在一致性。<details>
<summary>Abstract</summary>
This paper reveal the selective rotation in the CNNs' forward processing. It elucidates the activation function as a discerning mechanism that unifies and quantizes the rotational aspects of the input data. Experiments show how this defined methodology reflects the progress network distinguish inputs based on statistical indicators, which can be comprehended or analyzed by applying structured mathematical tools. Our findings also unveil the consistency between artificial neural networks and the human brain in their data processing pattern.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文揭示了 CNN 的选择性旋转处理。它提出了活动函数作为分类机制，归一化和量化输入数据的旋转方面。实验显示，这种定义的方法ология可以基于统计指标来分类输入，可以通过结构化数学工具进行理解或分析。我们的发现还揭示了人工神经网络和人脑在数据处理模式上的一致性。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-learning-guided-fuzz-testing-for-a-browser’s-HTML-rendering-engine"><a href="#Reinforcement-learning-guided-fuzz-testing-for-a-browser’s-HTML-rendering-engine" class="headerlink" title="Reinforcement learning guided fuzz testing for a browser’s HTML rendering engine"></a>Reinforcement learning guided fuzz testing for a browser’s HTML rendering engine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14556">http://arxiv.org/abs/2307.14556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Sablotny, Bjørn Sand Jensen, Jeremy Singer</li>
<li>for: 找寻多种漏洞和安全漏洞</li>
<li>methods: 使用深度学习模型生成测试案例，并使用双层深度Q网络（DDQN）引导测试案例创建</li>
<li>results: 对Firefox HTML渲染引擎进行了18.5%的代码覆盖性提升 compared to基eline语法基础的混杂化器<details>
<summary>Abstract</summary>
Generation-based fuzz testing can uncover various bugs and security vulnerabilities. However, compared to mutation-based fuzz testing, it takes much longer to develop a well-balanced generator that produces good test cases and decides where to break the underlying structure to exercise new code paths. We propose a novel approach to combine a trained test case generator deep learning model with a double deep Q-network (DDQN) for the first time. The DDQN guides test case creation based on a code coverage signal. Our approach improves the code coverage performance of the underlying generator model by up to 18.5\% for the Firefox HTML rendering engine compared to the baseline grammar based fuzzer.
</details>
<details>
<summary>摘要</summary>
生成基于的验证测试可以探测多种漏洞和安全漏洞。然而，相比于变换基于的验证测试，它需要较长时间来开发一个很好均衡的生成器，以生成好的测试 caso和决定在下面的结构下激活新的代码路径。我们提出了一种新的方法，将训练过的测试 caso生成深度学习模型与双深度Q网络（DDQN）结合使用。DDQN根据代码覆盖率信号引导测试 caso创建。我们的方法可以提高 Firefox HTML 渲染引擎下的代码覆盖率性能，相比基eline grammar基础的验证器，提高了18.5%。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Sleeping-Bandit-Problems-with-Multiple-Plays-Algorithm-and-Ranking-Application"><a href="#Adversarial-Sleeping-Bandit-Problems-with-Multiple-Plays-Algorithm-and-Ranking-Application" class="headerlink" title="Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and Ranking Application"></a>Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and Ranking Application</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14549">http://arxiv.org/abs/2307.14549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianjun Yuan, Wei Lee Woon, Ludovik Coba</li>
<li>for: 这篇论文是为了解决在线推荐系统中的睡眠bandit问题而写的。</li>
<li>methods: 该论文提出了一种高效的算法来解决睡眠bandit问题，该算法基于单臂选择算法的扩展，并且保证能够实现理论性的表现，即 regret upper bounded by $\bigO(kN^2\sqrt{T\log T})$.</li>
<li>results: 该论文的结果表明，该算法能够在睡眠bandit问题中实现高效的选择，并且能够避免极端情况下的质量下降。<details>
<summary>Abstract</summary>
This paper presents an efficient algorithm to solve the sleeping bandit with multiple plays problem in the context of an online recommendation system. The problem involves bounded, adversarial loss and unknown i.i.d. distributions for arm availability. The proposed algorithm extends the sleeping bandit algorithm for single arm selection and is guaranteed to achieve theoretical performance with regret upper bounded by $\bigO(kN^2\sqrt{T\log T})$, where $k$ is the number of arms selected per time step, $N$ is the total number of arms, and $T$ is the time horizon.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)这篇论文提出了一种高效的算法，用于在线推荐系统中解决睡着帮手问题。该问题具有含边界、对抗损失和未知i.i.d.分布的arm可用性。提出的算法基于单个帮手选择算法的扩展，并且保证了理论性能， regret的上界为 $\bigO(kN^2\sqrt{T\log T})$, where $k$ is the number of arms selected per time step, $N$ is the total number of arms, and $T$ is the time horizon.
</details></li>
</ul>
<hr>
<h2 id="Speed-Reading-Tool-Powered-by-Artificial-Intelligence-for-Students-with-ADHD-Dyslexia-or-Short-Attention-Span"><a href="#Speed-Reading-Tool-Powered-by-Artificial-Intelligence-for-Students-with-ADHD-Dyslexia-or-Short-Attention-Span" class="headerlink" title="Speed Reading Tool Powered by Artificial Intelligence for Students with ADHD, Dyslexia, or Short Attention Span"></a>Speed Reading Tool Powered by Artificial Intelligence for Students with ADHD, Dyslexia, or Short Attention Span</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14544">http://arxiv.org/abs/2307.14544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Megat Irfan Zackry Bin Ismail Ahmad Nazran bin Yusri Muhammad Hafizzul Bin Abdul Manap Muhammad Muizzuddin Bin Kamarozaman</li>
<li>for: 帮助学生 WITH dyslexia, ADHD, 和短时间注意力不足更好地理解文本信息</li>
<li>methods: 使用多层感知器（MLP）算法进行复杂文本处理和概要化任务，并使用 Hugging Face 提供的 T5 模型（文本生成模型）进行 fine-tuning 特定任务，使用 NLTK 的 Punkt Sentence Tokenizer 将文本分解成句子列表</li>
<li>results: 通过应用 Bionic Reading 的原则（包括粗体函数和字符、词、行间距调整），提高了阅读速度和效率<details>
<summary>Abstract</summary>
This paper presents a novel approach to assist students with dyslexia, ADHD, and short attention span in digesting any text-based information more efficiently. The proposed solution utilizes the Multilayer Perceptron (MLP) algorithm for complex text processing and summarization tasks. The tool leverages the T5 (Text-to-Text Transfer Transformer) model from Hugging Face, which treats every NLP task as a text generation task. The model is fine-tuned on specific tasks using a smaller dataset. The NLTK's Punkt Sentence Tokenizer is used to divide a text into a list of sentences. The application is served using Flask, a lightweight web server and framework. The tool also applies principles from Bionic Reading to enhance readability, which includes a bolding function and adjustments to line, word, and character spacing. The paper discusses the methodology, implementation, and results of the AI-based speed reading tool.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的方法，用于帮助学生有读写障碍、注意力不集中和短时间内容过载的问题更有效地处理文本信息。提出的解决方案利用多层感知器（MLP）算法进行复杂文本处理和摘要任务。工具使用了Hugging Face提供的T5（文本生成传输变换器）模型，该模型对每个NLP任务视为文本生成任务。模型通过使用特定任务的更小数据集进行细化。使用NLTK的Punkt Sentence Tokenizer将文本分解成一个列表中的句子。应用程序使用Flask，一个轻量级的网络服务器和框架。工具还应用了生物阅读的原则，以提高阅读性，包括粗体功能和字符、词和行间距调整。文章讨论了方法、实现和这种人工智能快速阅读工具的结果。
</details></li>
</ul>
<hr>
<h2 id="Open-Problems-in-Computer-Vision-for-Wilderness-SAR-and-The-Search-for-Patricia-Wu-Murad"><a href="#Open-Problems-in-Computer-Vision-for-Wilderness-SAR-and-The-Search-for-Patricia-Wu-Murad" class="headerlink" title="Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad"></a>Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14527">http://arxiv.org/abs/2307.14527</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/crasar/wisar">https://github.com/crasar/wisar</a></li>
<li>paper_authors: Thomas Manzini, Robin Murphy</li>
<li>for: 这个研究旨在应用两种计算机视觉系统，一个是supervised学习模型EfficientDET，另一个是无监督的RX спектраль分类器，于日本 Wu-Murad野外搜救（WSAR）活动中98.9 GB的无人机影像上进行找人任务。</li>
<li>methods: 这些研究使用了19个提议的方法和3个数据集来找人在无人机影像中，但只有3个方法（2个无监督和1个不知道的结构）在文献中被引用为在实际WSAR操作中使用过。</li>
<li>results: 这些提议中，EfficientDET体系和无监督的spectral RX分类器被选为最适合这种设定。EfficientDET模型在HERIDAL数据集上进行应用，尽管达到了数据上的性能，但在实际世界中出现了假阳性（如把树 LIMBS和岩石当作人）和假负性（如不能识别搜救队成员）。这些结果表明，在实际WSAR操作中，计算机视觉算法的表现并不如数据上的表现好。因此，未来的研究方向包括：更真实的野外SAR数据集、计算机视觉模型可以快速适应野外SAR操作中collect的多样化影像，以及更好地对照性能指标。<details>
<summary>Abstract</summary>
This paper details the challenges in applying two computer vision systems, an EfficientDET supervised learning model and the unsupervised RX spectral classifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and rescue (WSAR) effort in Japan and identifies 3 directions for future research. There have been at least 19 proposed approaches and 3 datasets aimed at locating missing persons in drone imagery, but only 3 approaches (2 unsupervised and 1 of an unknown structure) are referenced in the literature as having been used in an actual WSAR operation. Of these proposed approaches, the EfficientDET architecture and the unsupervised spectral RX classifier were selected as the most appropriate for this setting. The EfficientDET model was applied to the HERIDAL dataset and despite achieving performance that is statistically equivalent to the state-of-the-art, the model fails to translate to the real world in terms of false positives (e.g., identifying tree limbs and rocks as people), and false negatives (e.g., failing to identify members of the search team). The poor results in practice for algorithms that showed good results on datasets suggest 3 areas of future research: more realistic datasets for wilderness SAR, computer vision models that are capable of seamlessly handling the variety of imagery that can be collected during actual WSAR operations, and better alignment on performance measures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>More realistic datasets for wilderness SAR: The current datasets used for training and testing computer vision models may not accurately reflect the real-world conditions and variability of imagery collected during actual WSAR operations.2. Computer vision models that can handle diverse imagery: The models need to be able to seamlessly handle the variety of imagery that can be collected during actual WSAR operations, including different lighting conditions, weather, and vegetation.3. Better alignment on performance measures: The models need to be evaluated using performance measures that are relevant to the specific task and environment of WSAR operations, rather than simply relying on metrics that show good results on datasets.The paper also notes that while there have been many proposed approaches to locating missing persons in drone imagery, only a few have been used in actual WSAR operations, and of those, the EfficientDET architecture and the unsupervised spectral RX classifier were selected as the most appropriate for this setting. However, the EfficientDET model failed to translate to real-world performance, with issues such as false positives (identifying tree limbs and rocks as people) and false negatives (failing to identify members of the search team).</details></li>
</ol>
<hr>
<h2 id="Patterns-of-Vehicle-Lights-Addressing-Complexities-in-Curation-and-Annotation-of-Camera-Based-Vehicle-Light-Datasets-and-Metrics"><a href="#Patterns-of-Vehicle-Lights-Addressing-Complexities-in-Curation-and-Annotation-of-Camera-Based-Vehicle-Light-Datasets-and-Metrics" class="headerlink" title="Patterns of Vehicle Lights: Addressing Complexities in Curation and Annotation of Camera-Based Vehicle Light Datasets and Metrics"></a>Patterns of Vehicle Lights: Addressing Complexities in Curation and Annotation of Camera-Based Vehicle Light Datasets and Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14521">http://arxiv.org/abs/2307.14521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ross Greer, Akshay Gopalkrishnan, Maitrayee Keskar, Mohan Trivedi</li>
<li>for: 本研究探讨了计算机视觉中车辆灯光的表示方法以及其对自动驾驶场景中不同任务的影响。</li>
<li>methods: 研究比较了不同的车辆灯光表示方法，包括 bounding boxes、中心点、角点和分割面积，并讨论了它们的优缺点。</li>
<li>results: 研究认为，正确地检测车辆灯光对于夜间车辆检测、3D车辆方向估计和动态轨迹指示等任务都非常重要。研究还提出了一种基于实际数据驱动的模型训练方法，并提供了一个新的车辆灯光数据集和可见光模型，以满足下游应用中的车辆检测、意图预测和安全轨迹规划等任务。<details>
<summary>Abstract</summary>
This paper explores the representation of vehicle lights in computer vision and its implications for various tasks in the field of autonomous driving. Different specifications for representing vehicle lights, including bounding boxes, center points, corner points, and segmentation masks, are discussed in terms of their strengths and weaknesses. Three important tasks in autonomous driving that can benefit from vehicle light detection are identified: nighttime vehicle detection, 3D vehicle orientation estimation, and dynamic trajectory cues. Each task may require a different representation of the light. The challenges of collecting and annotating large datasets for training data-driven models are also addressed, leading to introduction of the LISA Vehicle Lights Dataset and associated Light Visibility Model, which provides light annotations specifically designed for downstream applications in vehicle detection, intent and trajectory prediction, and safe path planning. A comparison of existing vehicle light datasets is provided, highlighting the unique features and limitations of each dataset. Overall, this paper provides insights into the representation of vehicle lights and the importance of accurate annotations for training effective detection models in autonomous driving applications. Our dataset and model are made available at https://cvrr.ucsd.edu/vehicle-lights-dataset
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-new-algorithm-for-Subgroup-Set-Discovery-based-on-Information-Gain"><a href="#A-new-algorithm-for-Subgroup-Set-Discovery-based-on-Information-Gain" class="headerlink" title="A new algorithm for Subgroup Set Discovery based on Information Gain"></a>A new algorithm for Subgroup Set Discovery based on Information Gain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15089">http://arxiv.org/abs/2307.15089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Gómez-Bravo, Aaron García, Guillermo Vigueras, Belén Ríos, Alejandro Rodríguez-González</li>
<li>for: 本研究旨在提出一种新的模式发现算法，即信息增益子集发现（IGSD），用于解决现有模式发现算法的一些局限性。</li>
<li>methods: IGSD算法结合信息增益（IG）和偶极率（OR）为多个评价因素，用于模式选择。</li>
<li>results: 对于11个数据集，IGSD算法比现有的FSSD和SSD++算法提供更可靠的模式和更少的模式集。IGSD算法还提供了更高的偶极率值，表明模式和目标之间的相互依赖性更高。此外，IGSD算法中的模式被专家 validate 为更加符合域专家的评价。<details>
<summary>Abstract</summary>
Pattern discovery is a machine learning technique that aims to find sets of items, subsequences, or substructures that are present in a dataset with a higher frequency value than a manually set threshold. This process helps to identify recurring patterns or relationships within the data, allowing for valuable insights and knowledge extraction. In this work, we propose Information Gained Subgroup Discovery (IGSD), a new SD algorithm for pattern discovery that combines Information Gain (IG) and Odds Ratio (OR) as a multi-criteria for pattern selection. The algorithm tries to tackle some limitations of state-of-the-art SD algorithms like the need for fine-tuning of key parameters for each dataset, usage of a single pattern search criteria set by hand, usage of non-overlapping data structures for subgroup space exploration, and the impossibility to search for patterns by fixing some relevant dataset variables. Thus, we compare the performance of IGSD with two state-of-the-art SD algorithms: FSSD and SSD++. Eleven datasets are assessed using these algorithms. For the performance evaluation, we also propose to complement standard SD measures with IG, OR, and p-value. Obtained results show that FSSD and SSD++ algorithms provide less reliable patterns and reduced sets of patterns than IGSD algorithm for all datasets considered. Additionally, IGSD provides better OR values than FSSD and SSD++, stating a higher dependence between patterns and targets. Moreover, patterns obtained for one of the datasets used, have been validated by a group of domain experts. Thus, patterns provided by IGSD show better agreement with experts than patterns obtained by FSSD and SSD++ algorithms. These results demonstrate the suitability of the IGSD as a method for pattern discovery and suggest that the inclusion of non-standard SD metrics allows to better evaluate discovered patterns.
</details>
<details>
<summary>摘要</summary>
Pattern discovery 是一种机器学习技术，旨在在数据集中找到较高频值的项集、 subsequences 或 substructures。这个过程可以帮助找到数据中复杂的模式或关系，从而提供有价值的发现和知识提取。在这个工作中，我们提出了信息增加 subgroup discovery（IGSD）算法，这是一种新的 Pattern discovery 算法，它将信息增加（IG）和 odds ratio（OR）作为多种选择 criterion。该算法试图解决现有 Pattern discovery 算法的一些局限性，如手动设置的阈值、不同数据集需要调整参数、使用不 overlap 的数据结构来探索 subgroup 空间、以及无法通过固定数据集中的一些有关变量来搜索模式。因此，我们将IGSD与现有的 Pattern discovery 算法FSSD和SSD++进行比较。对 eleven 个数据集进行评估，我们还提出了一种用于评估 Pattern discovery 性能的方法，该方法包括IG、OR和p-value。获得的结果表明，FSSD和SSD++算法在所有考虑的数据集中提供了较差的模式和减少的模式集，而IGSD算法则提供了更高的OR值，表明模式和目标之间的依赖性更高。此外，IGSD算法对一个数据集中的模式进行验证，并与领域专家的评估结果相符，表明IGSD算法提供的模式更加符合专家的认知。这些结果表明IGSD算法适用于模式发现，并且包括非标准 Pattern discovery 度量可以更好地评估发现的模式。
</details></li>
</ul>
<hr>
<h2 id="The-Co-12-Recipe-for-Evaluating-Interpretable-Part-Prototype-Image-Classifiers"><a href="#The-Co-12-Recipe-for-Evaluating-Interpretable-Part-Prototype-Image-Classifiers" class="headerlink" title="The Co-12 Recipe for Evaluating Interpretable Part-Prototype Image Classifiers"></a>The Co-12 Recipe for Evaluating Interpretable Part-Prototype Image Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14517">http://arxiv.org/abs/2307.14517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meike Nauta, Christin Seifert</li>
<li>for: 本研究旨在提供一份关于可解释部件prototype模型的评估方法的概要。</li>
<li>methods: 本文使用了Co-12性能评估属性（正确性、完整性、紧凑性等）来评估部件prototype模型的解释质量。</li>
<li>results: 本研究发现了评估部件prototype模型解释质量的现有工作和研究漏洞，并提出了未来评估方法的建议。同时，本文还提供了一份“Co-12 quick reference”，用于概括评估部件prototype模型的解释质量。<details>
<summary>Abstract</summary>
Interpretable part-prototype models are computer vision models that are explainable by design. The models learn prototypical parts and recognise these components in an image, thereby combining classification and explanation. Despite the recent attention for intrinsically interpretable models, there is no comprehensive overview on evaluating the explanation quality of interpretable part-prototype models. Based on the Co-12 properties for explanation quality as introduced in arXiv:2201.08164 (e.g., correctness, completeness, compactness), we review existing work that evaluates part-prototype models, reveal research gaps and outline future approaches for evaluation of the explanation quality of part-prototype models. This paper, therefore, contributes to the progression and maturity of this relatively new research field on interpretable part-prototype models. We additionally provide a ``Co-12 cheat sheet'' that acts as a concise summary of our findings on evaluating part-prototype models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对于可解释部件模型，我们现在没有一个全面的评估解释质量的概述。基于arXiv:2201.08164中所引入的Co-12属性（如正确性、完整性、 компакт性），我们回顾现有的工作，揭示研究漏掉和未来的评估方法。因此，本文对新的可解释部件模型领域做出了贡献，并提供了一份``Co-12指南''，作为评估部件模型的 concise 概括。Translation:For interpretable part-prototype models, there is no comprehensive overview of evaluating the explanation quality. Based on the Co-12 properties for explanation quality introduced in arXiv:2201.08164 (such as correctness, completeness, compactness), we review existing work, reveal research gaps, and outline future approaches for evaluating the explanation quality of part-prototype models. Therefore, this paper contributes to the progression and maturity of this relatively new research field on interpretable part-prototype models. We also provide a "Co-12 cheat sheet" as a concise summary of our findings on evaluating part-prototype models.
</details></li>
</ul>
<hr>
<h2 id="Words-That-Stick-Predicting-Decision-Making-and-Synonym-Engagement-Using-Cognitive-Biases-and-Computational-Linguistics"><a href="#Words-That-Stick-Predicting-Decision-Making-and-Synonym-Engagement-Using-Cognitive-Biases-and-Computational-Linguistics" class="headerlink" title="Words That Stick: Predicting Decision Making and Synonym Engagement Using Cognitive Biases and Computational Linguistics"></a>Words That Stick: Predicting Decision Making and Synonym Engagement Using Cognitive Biases and Computational Linguistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14511">http://arxiv.org/abs/2307.14511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nimrod Dvir, Elaine Friedman, Suraj Commuri, Fan Yang, Jennifer Romano<br>for:This research aims to anticipate user engagement and decision-making on digital platforms by leveraging cognitive psychology and information systems studies.methods:The study employs natural language processing (NLP) techniques and insights from cognitive bias research to analyze user interactions with synonyms within digital content. The READ model is synthesized from four cognitive biases: Representativeness, Ease-of-use, Affect, and Distribution.results:Through a comprehensive user survey, the study finds that synonyms that accurately represent core ideas, are easy to understand, elicit emotional responses, and are commonly encountered, promote greater user engagement. The results offer a fresh perspective on human-computer interaction, digital behaviors, and decision-making processes, and highlight the significance of cognitive biases in designing effective digital content across fields like education and marketing.<details>
<summary>Abstract</summary>
This research draws upon cognitive psychology and information systems studies to anticipate user engagement and decision-making on digital platforms. By employing natural language processing (NLP) techniques and insights from cognitive bias research, we delve into user interactions with synonyms within digital content. Our methodology synthesizes four cognitive biasesRepresentativeness, Ease-of-use, Affect, and Distributioninto the READ model. Through a comprehensive user survey, we assess the model's ability to predict user engagement, discovering that synonyms that accurately represent core ideas, are easy to understand, elicit emotional responses, and are commonly encountered, promote greater user engagement. Crucially, our work offers a fresh lens on human-computer interaction, digital behaviors, and decision-making processes. Our results highlight the promise of cognitive biases as potent indicators of user engagement, underscoring their significance in designing effective digital content across fields like education and marketing.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Attention-for-Robot-Touch-Tactile-Saliency-Prediction-for-Robust-Sim-to-Real-Tactile-Control"><a href="#Attention-for-Robot-Touch-Tactile-Saliency-Prediction-for-Robust-Sim-to-Real-Tactile-Control" class="headerlink" title="Attention for Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control"></a>Attention for Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14510">http://arxiv.org/abs/2307.14510</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijiong Lin, Mauro Comi, Alex Church, Dandan Zhang, Nathan F. Lepora</li>
<li>for: 提高机器人摸索控制在无结构环境中的稳定性。</li>
<li>methods: 基于人类触觉注意机制和计算视觉环境中的视觉突出预测问题，提出了一种新的概念——触觉突出。这个概念的目的是在触觉图像中寻找关键信息。而人类 manually labelling 触觉图像是困难的，因为触觉图像的模式可能具有counterintuitive的特征。为Address这个挑战，我们提出了一种新的方法，包括三个相互关联的网络：1）触觉深度网络（ConDepNet），生成一个实际触觉图像中的Contact Depth Map，以地址触觉图像中的target和噪声特征；2）触觉突出网络（TacSalNet），预测一个触觉突出图像，描述输入Contact Depth Map中的target区域；3）触觉噪声生成器（TacNGen），生成噪声特征，用于训练TacSalNet。</li>
<li>results: 实验结果表明，我们的触觉突出预测方法可以准确地预测实际触觉图像中的target特征。总的来说，我们的触觉突出预测方法在无结构环境中提供了稳定的sim-to-real触觉控制。项目页面：<a target="_blank" rel="noopener" href="https://sites.google.com/view/tactile-saliency/">https://sites.google.com/view/tactile-saliency/</a>.<details>
<summary>Abstract</summary>
High-resolution tactile sensing can provide accurate information about local contact in contact-rich robotic tasks. However, the deployment of such tasks in unstructured environments remains under-investigated. To improve the robustness of tactile robot control in unstructured environments, we propose and study a new concept: \textit{tactile saliency} for robot touch, inspired by the human touch attention mechanism from neuroscience and the visual saliency prediction problem from computer vision. In analogy to visual saliency, this concept involves identifying key information in tactile images captured by a tactile sensor. While visual saliency datasets are commonly annotated by humans, manually labelling tactile images is challenging due to their counterintuitive patterns. To address this challenge, we propose a novel approach comprised of three interrelated networks: 1) a Contact Depth Network (ConDepNet), which generates a contact depth map to localize deformation in a real tactile image that contains target and noise features; 2) a Tactile Saliency Network (TacSalNet), which predicts a tactile saliency map to describe the target areas for an input contact depth map; 3) and a Tactile Noise Generator (TacNGen), which generates noise features to train the TacSalNet. Experimental results in contact pose estimation and edge-following in the presence of distractors showcase the accurate prediction of target features from real tactile images. Overall, our tactile saliency prediction approach gives robust sim-to-real tactile control in environments with unknown distractors. Project page: https://sites.google.com/view/tactile-saliency/.
</details>
<details>
<summary>摘要</summary>
高解析触觉感测可以提供精确的本地接触信息在有接触的 роботиче任务中。然而，在无结构环境中部署这些任务仍然受到了不足的研究。为了提高触觉控制在无结构环境中的稳定性，我们提出了一新的概念：触觉焦点，启发自人类触觉注意机制和计算机视觉中的视觉预测问题。在视觉预测问题中，这个概念涉及到从触觉图像中提取关键信息。而视觉预测数据通常由人类手动标注，然而对于触觉图像来说，手动标注是具有counterintuitive pattern的。为了解决这个挑战，我们提出了一种新的方法，包括三个相关的网络：1）触觉深度网络（ConDepNet），生成一个具有target和噪声特征的真实触觉深度图像；2）触觉焦点网络（TacSalNet），预测一个触觉焦点图像，描述输入触觉深度图像中的target区域；3）触觉噪声生成器（TacNGen），生成噪声特征来训练TacSalNet。实验结果表明，我们的触觉焦点预测方法可以准确地预测真实触觉图像中的target特征。总的来说，我们的触觉焦点预测方法可以在未知干扰下提供稳定的sim-to-real触觉控制。项目页面：https://sites.google.com/view/tactile-saliency/
</details></li>
</ul>
<hr>
<h2 id="Improving-Reliable-Navigation-under-Uncertainty-via-Predictions-Informed-by-Non-Local-Information"><a href="#Improving-Reliable-Navigation-under-Uncertainty-via-Predictions-Informed-by-Non-Local-Information" class="headerlink" title="Improving Reliable Navigation under Uncertainty via Predictions Informed by Non-Local Information"></a>Improving Reliable Navigation under Uncertainty via Predictions Informed by Non-Local Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14501">http://arxiv.org/abs/2307.14501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Raihan Islam Arnob, Gregory J. Stein</li>
<li>for: 该论文目的是提高具有部分地图信息的环境中，可靠、长期目标导航的能力。</li>
<li>methods: 该论文使用非本地信息来预测行动的质量，包括使用图 neural network 来学习非本地信息。</li>
<li>results: 在三个 simulations 环境中，该方法比非学习基eline 减少了 9.3% 的成本，并比只使用本地信息来预测的学习 Informed Planner 减少了 14.9% 的成本。<details>
<summary>Abstract</summary>
We improve reliable, long-horizon, goal-directed navigation in partially-mapped environments by using non-locally available information to predict the goodness of temporally-extended actions that enter unseen space. Making predictions about where to navigate in general requires non-local information: any observations the robot has seen so far may provide information about the goodness of a particular direction of travel. Building on recent work in learning-augmented model-based planning under uncertainty, we present an approach that can both rely on non-local information to make predictions (via a graph neural network) and is reliable by design: it will always reach its goal, even when learning does not provide accurate predictions. We conduct experiments in three simulated environments in which non-local information is needed to perform well. In our large scale university building environment, generated from real-world floorplans to the scale, we demonstrate a 9.3\% reduction in cost-to-go compared to a non-learned baseline and a 14.9\% reduction compared to a learning-informed planner that can only use local information to inform its predictions.
</details>
<details>
<summary>摘要</summary>
我们提高了可靠、长期目标导航在部分地图环境中，使用非本地可用信息预测行动的质量。任何机器人所见之前的观察都可以提供行动的质量信息。基于最近的学习增强模型基于不确定性的规划方法，我们提出了一种方法，可以通过图 neural network 来预测，同时具有可靠性：它总是可以达到目标，即使学习不准确预测。我们在三个 simulated 环境中进行了实验，其中非本地信息是必要的。在我们的大规模大学建筑环境中，生成自真实的 floorplans ，我们表明了与非学习基准相比的 9.3% 的成本降低，并与只能使用本地信息来预测的学习 Informed 规划器相比，表现出 14.9% 的成本降低。
</details></li>
</ul>
<hr>
<h2 id="Technical-note-ShinyAnimalCV-open-source-cloud-based-web-application-for-object-detection-segmentation-and-three-dimensional-visualization-of-animals-using-computer-vision"><a href="#Technical-note-ShinyAnimalCV-open-source-cloud-based-web-application-for-object-detection-segmentation-and-three-dimensional-visualization-of-animals-using-computer-vision" class="headerlink" title="Technical note: ShinyAnimalCV: open-source cloud-based web application for object detection, segmentation, and three-dimensional visualization of animals using computer vision"></a>Technical note: ShinyAnimalCV: open-source cloud-based web application for object detection, segmentation, and three-dimensional visualization of animals using computer vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14487">http://arxiv.org/abs/2307.14487</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uf-aiaos/shinyanimalcv">https://github.com/uf-aiaos/shinyanimalcv</a></li>
<li>paper_authors: Jin Wang, Yu Hu, Lirong Xiang, Gota Morota, Samantha A. Brooks, Carissa L. Wickens, Emily K. Miller-Cushon, Haipeng Yu<br>for:这个研究的目的是为了开发一个开源云端Web应用程序，以提供一个易于使用的界面，用于执行计算机视觉任务，包括对动物数据进行物体分割、检测、三维表面视觉化以及二维和三维形态特征提取。methods:这个研究使用了多种计算机视觉和深度学习算法，包括9种预训练的计算机视觉模型，以处理上述动物数据。results:这个研究开发了一个名为ShinyAnimalCV的开源云端Web应用程序，可以帮助用户快速和简单地执行计算机视觉任务，并提供了详细的教程和示例数据，以帮助用户快速适应该应用程序。<details>
<summary>Abstract</summary>
Computer vision (CV), a non-intrusive and cost-effective technology, has furthered the development of precision livestock farming by enabling optimized decision-making through timely and individualized animal care. The availability of affordable two- and three-dimensional camera sensors, combined with various machine learning and deep learning algorithms, has provided a valuable opportunity to improve livestock production systems. However, despite the availability of various CV tools in the public domain, applying these tools to animal data can be challenging, often requiring users to have programming and data analysis skills, as well as access to computing resources. Moreover, the rapid expansion of precision livestock farming is creating a growing need to educate and train animal science students in CV. This presents educators with the challenge of efficiently demonstrating the complex algorithms involved in CV. Thus, the objective of this study was to develop ShinyAnimalCV, an open-source cloud-based web application. This application provides a user-friendly interface for performing CV tasks, including object segmentation, detection, three-dimensional surface visualization, and extraction of two- and three-dimensional morphological features. Nine pre-trained CV models using top-view animal data are included in the application. ShinyAnimalCV has been deployed online using cloud computing platforms. The source code of ShinyAnimalCV is available on GitHub, along with detailed documentation on training CV models using custom data and deploying ShinyAnimalCV locally to allow users to fully leverage the capabilities of the application. ShinyAnimalCV can contribute to CV research and teaching in the animal science community.
</details>
<details>
<summary>摘要</summary>
计算机视觉（CV）技术，一种不侵入和cost-effective的技术，已经推动了精细 живо产业的发展，通过提供了时 opportune和个性化的动物护理，从而实现了 optimize livestock production systems。可以获得的便宜的二维和三维摄像头感知器，combined with various machine learning and deep learning algorithms，has provided a valuable opportunity to improve livestock production systems. However, despite the availability of various CV tools in the public domain, applying these tools to animal data can be challenging, often requiring users to have programming and data analysis skills, as well as access to computing resources. Moreover, the rapid expansion of precision livestock farming is creating a growing need to educate and train animal science students in CV. This presents educators with the challenge of efficiently demonstrating the complex algorithms involved in CV. Therefore, the objective of this study was to develop ShinyAnimalCV, an open-source cloud-based web application. This application provides a user-friendly interface for performing CV tasks, including object segmentation, detection, three-dimensional surface visualization, and extraction of two- and three-dimensional morphological features. Nine pre-trained CV models using top-view animal data are included in the application. ShinyAnimalCV has been deployed online using cloud computing platforms. The source code of ShinyAnimalCV is available on GitHub, along with detailed documentation on training CV models using custom data and deploying ShinyAnimalCV locally to allow users to fully leverage the capabilities of the application. ShinyAnimalCV can contribute to CV research and teaching in the animal science community.
</details></li>
</ul>
<hr>
<h2 id="Single-Channel-Speech-Enhancement-Using-U-Net-Spiking-Neural-Networks"><a href="#Single-Channel-Speech-Enhancement-Using-U-Net-Spiking-Neural-Networks" class="headerlink" title="Single Channel Speech Enhancement Using U-Net Spiking Neural Networks"></a>Single Channel Speech Enhancement Using U-Net Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14464">http://arxiv.org/abs/2307.14464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abir Riahi, Éric Plourde</li>
<li>for: 提高沟通设备和语音识别系统的可靠性，采用神经网络进行干扰减少。</li>
<li>methods: 使用神经网络（SNN）基于U-Net架构，SNN适用于处理时间维度数据，如语音，并且能够在限制性的硬件上实现能量减少。</li>
<li>results: 比较 intel neuromorphic deep noise suppression challenge 基线解决方案和等效的人工神经网络模型，能源减少的SNN模型达到了接受性的性能。<details>
<summary>Abstract</summary>
Speech enhancement (SE) is crucial for reliable communication devices or robust speech recognition systems. Although conventional artificial neural networks (ANN) have demonstrated remarkable performance in SE, they require significant computational power, along with high energy costs. In this paper, we propose a novel approach to SE using a spiking neural network (SNN) based on a U-Net architecture. SNNs are suitable for processing data with a temporal dimension, such as speech, and are known for their energy-efficient implementation on neuromorphic hardware. As such, SNNs are thus interesting candidates for real-time applications on devices with limited resources. The primary objective of the current work is to develop an SNN-based model with comparable performance to a state-of-the-art ANN model for SE. We train a deep SNN using surrogate-gradient-based optimization and evaluate its performance using perceptual objective tests under different signal-to-noise ratios and real-world noise conditions. Our results demonstrate that the proposed energy-efficient SNN model outperforms the Intel Neuromorphic Deep Noise Suppression Challenge (Intel N-DNS Challenge) baseline solution and achieves acceptable performance compared to an equivalent ANN model.
</details>
<details>
<summary>摘要</summary>
声音增强（SE）是重要的可靠通信设备或Robust Speech recognition系统的一部分。虽然传统的人工神经网络（ANN）在SE方面已经表现出了很好的性能，但它们需要很大的计算能力以及高的能源成本。在这篇论文中，我们提出了一种使用射频神经网络（SNN）基于U-Net架构的新方法 для SE。SNNs适用于处理具有时间维度的数据，如Speech，并且在 neuromorphic 硬件上实现时能够减少能源成本。因此，SNNs 是实时应用于有限资源的设备上的不错选择。我们的目标是开发一个与现有ANN模型相当的性能的SNN模型。我们使用代理函数逼近的优化方法来训练深度SNN，并在不同的信号噪声比和实际噪声条件下使用感知目标测试其性能。我们的结果表明，我们提出的能效的SNN模型比Intel Neuromorphic Deep Noise Suppression Challenge（Intel N-DNS Challenge）基eline解决方案更好，并且与相等的ANN模型相比，它的性能是可接受的。
</details></li>
</ul>
<hr>
<h2 id="VISPUR-Visual-Aids-for-Identifying-and-Interpreting-Spurious-Associations-in-Data-Driven-Decisions"><a href="#VISPUR-Visual-Aids-for-Identifying-and-Interpreting-Spurious-Associations-in-Data-Driven-Decisions" class="headerlink" title="VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions"></a>VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14448">http://arxiv.org/abs/2307.14448</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/picsolab/vispur">https://github.com/picsolab/vispur</a></li>
<li>paper_authors: Xian Teng, Yongsu Ahn, Yu-Ru Lin</li>
<li>For: The paper aims to help users identify and understand spurious associations in big data and machine learning, and make accountable causal decisions.* Methods: The proposed “de-paradox” workflow and visual analytic system, including the CONFOUNDER DASHBOARD, SUBGROUP VIEWER, REASONING STORYBOARD, and DECISION DIAGNOSIS panel, provide a framework for tackling spurious associations.* Results: The qualitative and quantitative results from an expert interview and a controlled user experiment demonstrate the effectiveness of the proposed system in helping users identify and understand spurious associations, and make accountable causal decisions.In Simplified Chinese text, the three key points would be:</li>
<li>for: 论文旨在帮助用户标识和理解大数据和机器学习中的假关联，并做出负责任的 causal 决策。</li>
<li>methods: 提出的 “de-paradox” 工作流程和视觉分析系统，包括 CONFOUNDER DASHBOARD、SUBGROUP VIEWER、REASONING STORYBOARD 和 DECISION DIAGNOSIS panel，为处理假关联提供了一个框架。</li>
<li>results: 从专家采访和控制的用户试验结果来看，提出的系统有效地帮助用户标识和理解假关联，并做出负责任的 causal 决策。<details>
<summary>Abstract</summary>
Big data and machine learning tools have jointly empowered humans in making data-driven decisions. However, many of them capture empirical associations that might be spurious due to confounding factors and subgroup heterogeneity. The famous Simpson's paradox is such a phenomenon where aggregated and subgroup-level associations contradict with each other, causing cognitive confusions and difficulty in making adequate interpretations and decisions. Existing tools provide little insights for humans to locate, reason about, and prevent pitfalls of spurious association in practice. We propose VISPUR, a visual analytic system that provides a causal analysis framework and a human-centric workflow for tackling spurious associations. These include a CONFOUNDER DASHBOARD, which can automatically identify possible confounding factors, and a SUBGROUP VIEWER, which allows for the visualization and comparison of diverse subgroup patterns that likely or potentially result in a misinterpretation of causality. Additionally, we propose a REASONING STORYBOARD, which uses a flow-based approach to illustrate paradoxical phenomena, as well as an interactive DECISION DIAGNOSIS panel that helps ensure accountable decision-making. Through an expert interview and a controlled user experiment, our qualitative and quantitative results demonstrate that the proposed "de-paradox" workflow and the designed visual analytic system are effective in helping human users to identify and understand spurious associations, as well as to make accountable causal decisions.
</details>
<details>
<summary>摘要</summary>
大数据和机器学习工具共同激活了人类在基于数据的决策中的能力。然而，许多其中捕捉到了可能的假相关性，因为存在干扰因素和 subgroup 多样性。例如，赛普逊的 парадоксом是这种现象，其中汇集和 subgroup 级别的相关性相互矛盾，导致认知混乱和不能正确地解释和决策。现有的工具几乎无法为人类提供有用的理解和避免假相关性的方法。我们提议了一个名为VISPUR的视觉分析系统，它提供了一个 causal 分析框架和一个人类中心的工作流程，以解决假相关性的问题。这些包括一个 CONFOUNDER DASHBOARD，可以自动 indentify 可能的干扰因素，以及一个 SUBGROUP VIEWER，可以视觉化和比较多个 subgroup 的多样性，可能或可能导致 causality 的误解。此外，我们还提议了一个 REASONING STORYBOARD，使用流程方式解释困扰现象，以及一个交互式的 DECISION DIAGNOSIS 面板，帮助确保决策是可负责的。经过专家采访和控制的用户测试，我们的资深和量化结果表明，我们的提议的 "de-paradox" 工作流程和设计的视觉分析系统有效地帮助人类用户认识和理解假相关性，以及作出可负责的 causal 决策。
</details></li>
</ul>
<hr>
<h2 id="Three-Bricks-to-Consolidate-Watermarks-for-Large-Language-Models"><a href="#Three-Bricks-to-Consolidate-Watermarks-for-Large-Language-Models" class="headerlink" title="Three Bricks to Consolidate Watermarks for Large Language Models"></a>Three Bricks to Consolidate Watermarks for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00113">http://arxiv.org/abs/2308.00113</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/three_bricks">https://github.com/facebookresearch/three_bricks</a></li>
<li>paper_authors: Pierre Fernandez, Antoine Chaffin, Karim Tit, Vivien Chappelier, Teddy Furon</li>
<li>for: 本研究旨在为大语言模型 Watermarking 技术提供更好的理论基础和实践应用。</li>
<li>methods: 本研究使用了三种理论和实践考虑，包括新的统计测试、对经典benchmark的比较和多比特水印技术。</li>
<li>results: 研究人员通过新的统计测试和实践应用发现，使用 Watermarking 技术可以准确地推断出生成文本是否来自特定的语言模型。<details>
<summary>Abstract</summary>
The task of discerning between generated and natural texts is increasingly challenging. In this context, watermarking emerges as a promising technique for ascribing generated text to a specific model. It alters the sampling generation process so as to leave an invisible trace in the generated output, facilitating later detection. This research consolidates watermarks for large language models based on three theoretical and empirical considerations. First, we introduce new statistical tests that offer robust theoretical guarantees which remain valid even at low false-positive rates (less than 10$^{\text{-6}$). Second, we compare the effectiveness of watermarks using classical benchmarks in the field of natural language processing, gaining insights into their real-world applicability. Third, we develop advanced detection schemes for scenarios where access to the LLM is available, as well as multi-bit watermarking.
</details>
<details>
<summary>摘要</summary>
“文本生成和自然文本之间的区分日益困难。在这种情况下，水印技术成为了识别生成文本的特定模型的有力的方法。它在生成过程中改变抽象样本，以留下不可见的 trace，使得后续检测变得容易。这项研究汇集了大语言模型的水印，基于三种理论和实证考虑。首先，我们提出了新的统计测试，具有坚实的理论保证，适用于低 FALSE POSITIVE 率（低于10$^{-6}$）。其次，我们通过经典的自然语言处理benchmark进行比较，从而获得了水印的实际应用性。最后，我们开发了高级检测方案，包括对LLM的访问和多比特水印。”
</details></li>
</ul>
<hr>
<h2 id="WavJourney-Compositional-Audio-Creation-with-Large-Language-Models"><a href="#WavJourney-Compositional-Audio-Creation-with-Large-Language-Models" class="headerlink" title="WavJourney: Compositional Audio Creation with Large Language Models"></a>WavJourney: Compositional Audio Creation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14335">http://arxiv.org/abs/2307.14335</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/audio-agi/wavjourney">https://github.com/audio-agi/wavjourney</a></li>
<li>paper_authors: Xubo Liu, Zhongkai Zhu, Haohe Liu, Yi Yuan, Meng Cui, Qiushi Huang, Jinhua Liang, Yin Cao, Qiuqiang Kong, Mark D. Plumbley, Wenwu Wang</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）如何用于创造智能音频内容。</li>
<li>methods: 该论文提出了一种名为WavJourney的系统，该系统利用LLM连接多种音频模型，以生成包括语音、音乐和特效的听力内容。</li>
<li>results: 该论文通过在多个实际场景中应用WavJourney系统，证明了该系统的可行性和创造力。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown great promise in integrating diverse expert models to tackle intricate language and vision tasks. Despite their significance in advancing the field of Artificial Intelligence Generated Content (AIGC), their potential in intelligent audio content creation remains unexplored. In this work, we tackle the problem of creating audio content with storylines encompassing speech, music, and sound effects, guided by text instructions. We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation. Given a text description of an auditory scene, WavJourney first prompts LLMs to generate a structured script dedicated to audio storytelling. The audio script incorporates diverse audio elements, organized based on their spatio-temporal relationships. As a conceptual representation of audio, the audio script provides an interactive and interpretable rationale for human engagement. Afterward, the audio script is fed into a script compiler, converting it into a computer program. Each line of the program calls a task-specific audio generation model or computational operation function (e.g., concatenate, mix). The computer program is then executed to obtain an explainable solution for audio generation. We demonstrate the practicality of WavJourney across diverse real-world scenarios, including science fiction, education, and radio play. The explainable and interactive design of WavJourney fosters human-machine co-creation in multi-round dialogues, enhancing creative control and adaptability in audio production. WavJourney audiolizes the human imagination, opening up new avenues for creativity in multimedia content creation.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经表现出很大的损 Promise 在融合多种专家模型来解决复杂的语言和视觉任务。即使它们在人工智能生成内容（AIGC）领域中的潜力未被完全探索，但它们在智能音频内容创作中的潜力仍然未被开发。在这个工作中，我们对于创建音频内容的Storyline 进行了探索，这些Storyline 包括谈话、音乐和音效。我们提出了 WavJourney，一个系统可以通过连接多种音频模型来创建音频内容。当我们给出了一个文本描述的听频场景时，WavJourney 会使用 LLM 生成一个结构化的对话脚本，这个对话脚本包括多种音频元素，并以其空间时间关系组织。这个对话脚本作为音频的概念表现，提供了可互动和可解释的理由，以便人类参与。接着，这个对话脚本会被转换为一个 компьютер程序，每个程序行叫用一个任务特定的音频生成模型或计算操作函数（例如， concatenate 或 mix）。这个 компьютер程序会被执行，以获得一个可解释的音频生成解决方案。我们在多个实际应用中证明了 WavJourney 的实用性，包括科幻、教育和广播剧等。WavJourney 的可靠和互动设计启动人机共创，增加了创作控制和适应性在音频生成中。WavJourney 将人类的想像获得了声音，开启了新的创作 Avenues 在多媒体内容创作中。
</details></li>
</ul>
<hr>
<h2 id="Event-based-Vision-for-Early-Prediction-of-Manipulation-Actions"><a href="#Event-based-Vision-for-Early-Prediction-of-Manipulation-Actions" class="headerlink" title="Event-based Vision for Early Prediction of Manipulation Actions"></a>Event-based Vision for Early Prediction of Manipulation Actions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14332">http://arxiv.org/abs/2307.14332</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danideniz/davishanddataset-events">https://github.com/danideniz/davishanddataset-events</a></li>
<li>paper_authors: Daniel Deniz, Cornelia Fermuller, Eduardo Ros, Manuel Rodriguez-Alvarez, Francisco Barranco</li>
<li>for: 这个研究的目的是用事件驱动的变换器网络进行 manipulate 动作预测。</li>
<li>methods: 该研究使用了事件驱动的 transformers 网络，通过在线推理来预测 manipulate 动作。</li>
<li>results: 研究表明， transformers 网络可以准确地预测 manipulate 动作，并且可以 capture 动作的动态特征，超过视频基于方法。 code 将在 GitHub 上发布。<details>
<summary>Abstract</summary>
Neuromorphic visual sensors are artificial retinas that output sequences of asynchronous events when brightness changes occur in the scene. These sensors offer many advantages including very high temporal resolution, no motion blur and smart data compression ideal for real-time processing. In this study, we introduce an event-based dataset on fine-grained manipulation actions and perform an experimental study on the use of transformers for action prediction with events. There is enormous interest in the fields of cognitive robotics and human-robot interaction on understanding and predicting human actions as early as possible. Early prediction allows anticipating complex stages for planning, enabling effective and real-time interaction. Our Transformer network uses events to predict manipulation actions as they occur, using online inference. The model succeeds at predicting actions early on, building up confidence over time and achieving state-of-the-art classification. Moreover, the attention-based transformer architecture allows us to study the role of the spatio-temporal patterns selected by the model. Our experiments show that the Transformer network captures action dynamic features outperforming video-based approaches and succeeding with scenarios where the differences between actions lie in very subtle cues. Finally, we release the new event dataset, which is the first in the literature for manipulation action recognition. Code will be available at https://github.com/DaniDeniz/EventVisionTransformer.
</details>
<details>
<summary>摘要</summary>
neuromorphic visual sensors 是人工视觉系统，它们当光度变化时输出一系列异步事件。这些感知器具有许多优点，包括非常高的时间分辨率、无运动模糊和智能数据压缩，适用于实时处理。在这个研究中，我们提出了基于事件的推理模型，并进行了实验研究，以测试这种模型在人体动作预测中的性能。人类动作预测在认知机器人和人机交互领域引起了极大的兴趣。早期预测可以在规划中预测复杂的阶段，使得交互变得有效和实时。我们的 transformer 网络使用事件来预测 manipulation 动作，并在线进行推理。模型在动作开始时就能够预测动作，逐渐增加信任度，并达到了状态之 arts 的分类。此外，基于注意力的 transformer 架构允许我们研究模型选择的空间时间模式的角色。我们的实验显示， transformer 网络在动作动态特征方面超越了视频基于方法，并在具有非常细微差异的动作场景中表现出色。最后，我们发布了一个新的事件数据集，这是文献中的第一个推理数据集。代码将在 GitHub 上公开，链接为 https://github.com/DaniDeniz/EventVisionTransformer。
</details></li>
</ul>
<hr>
<h2 id="Utilizing-Large-Language-Models-for-Natural-Interface-to-Pharmacology-Databases"><a href="#Utilizing-Large-Language-Models-for-Natural-Interface-to-Pharmacology-Databases" class="headerlink" title="Utilizing Large Language Models for Natural Interface to Pharmacology Databases"></a>Utilizing Large Language Models for Natural Interface to Pharmacology Databases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15717">http://arxiv.org/abs/2307.15717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Lu, Chuan Li, Yinheng Li, Jie Zhao</li>
<li>for: 这篇论文的目的是为了开发一个基于自然语言的数据库查询界面，以便药理学家在药物开发过程中访问和检索大量数据。</li>
<li>methods: 本文使用了大型自然语言模型（LLM）来实现数据库中的数据查询，并通过实验证明了这个框架的可行性和效能。</li>
<li>results: 实验结果显示，该框架可以对各种药品数据和知识库进行扩展，并且可以实现高效的数据查询和检索。<details>
<summary>Abstract</summary>
The drug development process necessitates that pharmacologists undertake various tasks, such as reviewing literature, formulating hypotheses, designing experiments, and interpreting results. Each stage requires accessing and querying vast amounts of information. In this abstract, we introduce a Large Language Model (LLM)-based Natural Language Interface designed to interact with structured information stored in databases. Our experiments demonstrate the feasibility and effectiveness of the proposed framework. This framework can generalize to query a wide range of pharmaceutical data and knowledge bases.
</details>
<details>
<summary>摘要</summary>
药物开发过程中，药物学家需要完成多种任务，如阅读文献、提出假设、设计实验和解释结果。每个阶段都需要访问和查询大量信息。在这个报告中，我们介绍了一种基于自然语言的语言模型（LLM）的自然语言界面，用于与数据库中的结构化信息进行交互。我们的实验表明该框架的可行性和效果。这个框架可以泛化到访问各种药物数据和知识库。
</details></li>
</ul>
<hr>
<h2 id="Building-and-Testing-a-General-Intelligence-Embodied-in-a-Humanoid-Robot"><a href="#Building-and-Testing-a-General-Intelligence-Embodied-in-a-Humanoid-Robot" class="headerlink" title="Building and Testing a General Intelligence Embodied in a Humanoid Robot"></a>Building and Testing a General Intelligence Embodied in a Humanoid Robot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16770">http://arxiv.org/abs/2307.16770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/Other-sources">https://github.com/Aryia-Behroziuan/Other-sources</a></li>
<li>paper_authors: Suzanne Gildert, Geordie Rose</li>
<li>for: 这种论文的目的是建立一种人类水平的智能机器，以便它们可以完成经济最有价值的工作。</li>
<li>methods: 这种方法包括一个物理的人型 робо体系统，一个基于软件的控制系统，一个名为“g+”的性能指标，以及一种进化算法来逐步提高这个指标的得分。</li>
<li>results: 作者们介绍了这种方法的当前状况和历史测量结果，包括“g+”指标的测量结果。<details>
<summary>Abstract</summary>
Machines with human-level intelligence should be able to do most economically valuable work. This aligns a major economic incentive with the scientific grand challenge of building a human-like mind. Here we describe our approach to building and testing such a system. Our approach comprises a physical humanoid robotic system; a software based control system for robots of this type; a performance metric, which we call g+, designed to be a measure of human-like intelligence in humanoid robots; and an evolutionary algorithm for incrementally increasing scores on this performance metric. We introduce and describe the current status of each of these. We report on current and historical measurements of the g+ metric on the systems described here.
</details>
<details>
<summary>摘要</summary>
机器人 WITH human-level intelligence应该能够完成经济有价值的工作。这与科学大挑战的建立人类智能型机器人相吻合。我们的方法包括物理人iform机器人系统；基于软件的控制系统 для这类机器人；一个名为g+的性能指标，用于评估机器人的人类智能水平；以及一种演化算法，用于逐步提高g+指标的得分。我们介绍了每个部分的当前状态，并报告了当前和历史中的g+指标测量结果。
</details></li>
</ul>
<hr>
<h2 id="Waypoint-Based-Imitation-Learning-for-Robotic-Manipulation"><a href="#Waypoint-Based-Imitation-Learning-for-Robotic-Manipulation" class="headerlink" title="Waypoint-Based Imitation Learning for Robotic Manipulation"></a>Waypoint-Based Imitation Learning for Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14326">http://arxiv.org/abs/2307.14326</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lucys0/awe">https://github.com/lucys0/awe</a></li>
<li>paper_authors: Lucy Xiaoyang Shi, Archit Sharma, Tony Z. Zhao, Chelsea Finn</li>
<li>for: 该论文旨在提出一种自动生成方向点的方法，以提高人工学习中的imitazione学习的精度和效率。</li>
<li>methods: 该方法基于linear motion的准确性，通过分解示例为最小的方向点集来生成方向点。</li>
<li>results: 实验结果表明，该方法可以增加state-of-the-art算法的成功率，在simulation中提高了25%，在实际双手操作任务上提高了4-28%，同时降低了决策准确性的 horizon。<details>
<summary>Abstract</summary>
While imitation learning methods have seen a resurgent interest for robotic manipulation, the well-known problem of compounding errors continues to afflict behavioral cloning (BC). Waypoints can help address this problem by reducing the horizon of the learning problem for BC, and thus, the errors compounded over time. However, waypoint labeling is underspecified, and requires additional human supervision. Can we generate waypoints automatically without any additional human supervision? Our key insight is that if a trajectory segment can be approximated by linear motion, the endpoints can be used as waypoints. We propose Automatic Waypoint Extraction (AWE) for imitation learning, a preprocessing module to decompose a demonstration into a minimal set of waypoints which when interpolated linearly can approximate the trajectory up to a specified error threshold. AWE can be combined with any BC algorithm, and we find that AWE can increase the success rate of state-of-the-art algorithms by up to 25% in simulation and by 4-28% on real-world bimanual manipulation tasks, reducing the decision making horizon by up to a factor of 10. Videos and code are available at https://lucys0.github.io/awe/
</details>
<details>
<summary>摘要</summary>
While imitation learning methods have seen a resurgence of interest for robotic manipulation, the well-known problem of compounding errors continues to affect behavioral cloning (BC). Waypoints can help address this problem by reducing the horizon of the learning problem for BC, but waypoint labeling is underspecified and requires additional human supervision. Can we generate waypoints automatically without any additional human supervision? Our key insight is that if a trajectory segment can be approximated by linear motion, the endpoints can be used as waypoints. We propose Automatic Waypoint Extraction (AWE) for imitation learning, a preprocessing module to decompose a demonstration into a minimal set of waypoints that can be interpolated linearly to approximate the trajectory up to a specified error threshold. AWE can be combined with any BC algorithm, and we find that AWE can increase the success rate of state-of-the-art algorithms by up to 25% in simulation and by 4-28% on real-world bimanual manipulation tasks, reducing the decision-making horizon by up to a factor of 10. Videos and code are available at <https://lucys0.github.io/awe/>.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Moral-Beliefs-Encoded-in-LLMs"><a href="#Evaluating-the-Moral-Beliefs-Encoded-in-LLMs" class="headerlink" title="Evaluating the Moral Beliefs Encoded in LLMs"></a>Evaluating the Moral Beliefs Encoded in LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14324">http://arxiv.org/abs/2307.14324</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ninodimontalcino/moralchoice">https://github.com/ninodimontalcino/moralchoice</a></li>
<li>paper_authors: Nino Scherrer, Claudia Shi, Amir Feder, David M. Blei</li>
<li>for: 本研究旨在探讨大语言模型（LLM）上的问卷设计、管理、后处理和评估。</li>
<li>methods: 本研究使用统计方法来激发LLM中的信念，并 introduce了一些统计指标和评估度量来量化LLM“选择”的概率、相关的不确定性以及选择的一致性。</li>
<li>results: 研究发现：（1）在明确的场景下，大多数模型会选择与常识相符的行为。在杂乱的场景下，大多数模型表现出不确定性。（2）一些模型对于选择常识行为的问题 wording 有敏感性。（3）一些模型在杂乱场景下具有明确的偏好。特别是关闭源模型在大多数情况下表现一致。<details>
<summary>Abstract</summary>
This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs). It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs. We introduce statistical measures and evaluation metrics that quantify the probability of an LLM "making a choice", the associated uncertainty, and the consistency of that choice. (2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious. We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g., "Should I tell a white lie?") and 687 low-ambiguity moral scenarios (e.g., "Should I stop for a pedestrian on the road?"). Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., "do not kill"). We administer the survey to 28 open- and closed-source LLMs. We find that (a) in unambiguous scenarios, most models "choose" actions that align with commonsense. In ambiguous cases, most models express uncertainty. (b) Some models are uncertain about choosing the commonsense action because their responses are sensitive to the question-wording. (c) Some models reflect clear preferences in ambiguous scenarios. Specifically, closed-source models tend to agree with each other.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>A statistical method for extracting beliefs from LLMs. We introduce statistical measures and evaluation metrics that quantify the probability of an LLM “making a choice,” the associated uncertainty, and the consistency of that choice.2. Applying this method to investigate what moral beliefs are encoded in different LLMs, especially in situations where the right choice is not obvious. We designed a large-scale survey with 680 high-ambiguity moral scenarios (e.g., “Should I tell a white lie?”) and 687 low-ambiguity moral scenarios (e.g., “Should I stop for a pedestrian on the road?”). Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., “do not kill”). We administered the survey to 28 open- and closed-source LLMs.Our findings are as follows:a. In unambiguous scenarios, most models “choose” actions that align with common sense. In ambiguous cases, most models express uncertainty.b. Some models are uncertain about choosing the common-sense action due to sensitivity to question wording.c. Some models reflect clear preferences in ambiguous scenarios, with closed-source models tending to agree with each other.</details></li>
</ol>
<hr>
<h2 id="Reinforcement-Learning-by-Guided-Safe-Exploration"><a href="#Reinforcement-Learning-by-Guided-Safe-Exploration" class="headerlink" title="Reinforcement Learning by Guided Safe Exploration"></a>Reinforcement Learning by Guided Safe Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14316">http://arxiv.org/abs/2307.14316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qisong Yang, Thiago D. Simão, Nils Jansen, Simon H. Tindemans, Matthijs T. J. Spaan</li>
<li>for: 本研究旨在使用不带奖励的强化学习（RL）训练代理人（导师），以便在未知目标任务下快速适应。</li>
<li>methods: 研究使用受限的奖励自由RL训练代理人，以避免危险交互，并在目标任务公布后不允许安全违反。同时，通过传输学习，训练目标策略（学生）以导师为 Referent，并逐渐减少导师的影响。</li>
<li>results: 实验结果表明，该方法可以实现安全的传输学习，帮助学生更快地解决目标任务。<details>
<summary>Abstract</summary>
Safety is critical to broadening the application of reinforcement learning (RL). Often, we train RL agents in a controlled environment, such as a laboratory, before deploying them in the real world. However, the real-world target task might be unknown prior to deployment. Reward-free RL trains an agent without the reward to adapt quickly once the reward is revealed. We consider the constrained reward-free setting, where an agent (the guide) learns to explore safely without the reward signal. This agent is trained in a controlled environment, which allows unsafe interactions and still provides the safety signal. After the target task is revealed, safety violations are not allowed anymore. Thus, the guide is leveraged to compose a safe behaviour policy. Drawing from transfer learning, we also regularize a target policy (the student) towards the guide while the student is unreliable and gradually eliminate the influence of the guide as training progresses. The empirical analysis shows that this method can achieve safe transfer learning and helps the student solve the target task faster.
</details>
<details>
<summary>摘要</summary>
安全性是RL应用扩展的关键因素。我们通常在实验室中训练RL代理，以便在真实世界中部署。然而，真实世界目标任务可能未知之前部署。无奖RL在部署前训练代理，以适应快速更新奖励信号。我们考虑了受限的奖励自由设定，其中一个代理在控制环境中学习安全地探索，而不需要奖励信号。当目标任务揭示后，安全违反不再允许。因此，代理可以被利用来组成安全行为策略。 drew from transfer learning，我们还启用了一个目标策略（学生），使其受到代理的正则化，而学生在训练进程中不可靠。逐渐消除代理的影响，以便更快地解决目标任务。我们的实验分析表明，这种方法可以实现安全的转移学习，并帮助学生更快地解决目标任务。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Deep-Learning-based-Pansharpening-with-Jointly-Enhanced-Spectral-and-Spatial-Fidelity"><a href="#Unsupervised-Deep-Learning-based-Pansharpening-with-Jointly-Enhanced-Spectral-and-Spatial-Fidelity" class="headerlink" title="Unsupervised Deep Learning-based Pansharpening with Jointly-Enhanced Spectral and Spatial Fidelity"></a>Unsupervised Deep Learning-based Pansharpening with Jointly-Enhanced Spectral and Spatial Fidelity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14403">http://arxiv.org/abs/2307.14403</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matciotola/lambda-pnn">https://github.com/matciotola/lambda-pnn</a></li>
<li>paper_authors: Matteo Ciotola, Giovanni Poggi, Giuseppe Scarpa</li>
<li>for: 这个论文主要目的是提出一种基于深度学习的高分辨率图像缩进方法，以提高图像缩进的性能。</li>
<li>methods: 该方法使用了全分辨率培生和新的损失函数，以提高图像缩进的 spectral 和 spatial 质量。</li>
<li>results: 实验结果表明，提出的方法在具有挑战性的测试图像上比领先方法更好， both in terms of numerical results and visual output。<details>
<summary>Abstract</summary>
In latest years, deep learning has gained a leading role in the pansharpening of multiresolution images. Given the lack of ground truth data, most deep learning-based methods carry out supervised training in a reduced-resolution domain. However, models trained on downsized images tend to perform poorly on high-resolution target images. For this reason, several research groups are now turning to unsupervised training in the full-resolution domain, through the definition of appropriate loss functions and training paradigms. In this context, we have recently proposed a full-resolution training framework which can be applied to many existing architectures.   Here, we propose a new deep learning-based pansharpening model that fully exploits the potential of this approach and provides cutting-edge performance. Besides architectural improvements with respect to previous work, such as the use of residual attention modules, the proposed model features a novel loss function that jointly promotes the spectral and spatial quality of the pansharpened data. In addition, thanks to a new fine-tuning strategy, it improves inference-time adaptation to target images. Experiments on a large variety of test images, performed in challenging scenarios, demonstrate that the proposed method compares favorably with the state of the art both in terms of numerical results and visual output. Code is available online at https://github.com/matciotola/Lambda-PNN.
</details>
<details>
<summary>摘要</summary>
最近几年，深度学习在多resolution图像投射中得到了主导地位。由于缺乏实际数据，大多数深度学习基于方法在减小分辨率领域进行了超级vised学习。然而，在高分辨率目标图像上，模型通常表现不佳。为此，许多研究小组现在转向无监督学习在全分辨率领域进行训练，通过定义适当的损失函数和训练方法。在这个上下文中，我们最近提出了一个全分辨率训练框架，可以应用到许多现有的架构上。我们提出了一个新的深度学习基于投射模型，全面利用了这种方法的潜力，并提供了顶尖性能。除了与前一代方法进行建筑性改进外，该模型还特点之所以有 residual attention 模块，以及一种新的损失函数，同时Promote spectral和spatial质量。此外，通过一种新的微调策略，可以在目标图像进行实时适应。对于一个大量的测试图像，在复杂的场景下进行了实验，结果表明，提议的方法与状态码器比较， both in terms of numerical results and visual output。代码可以在 <https://github.com/matciotola/Lambda-PNN> 上获取。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-and-Persuasive-Technologies-for-the-Management-and-Delivery-of-Personalized-Recommendations-in-Hotel-Hospitality"><a href="#ChatGPT-and-Persuasive-Technologies-for-the-Management-and-Delivery-of-Personalized-Recommendations-in-Hotel-Hospitality" class="headerlink" title="ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality"></a>ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14298">http://arxiv.org/abs/2307.14298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manolis Remountakis, Konstantinos Kotis, Babis Kourtzis, George E. Tsekouras</li>
<li>for: 酒店住宿预测系统的自动化和改善</li>
<li>methods: 应用大语言模型(ChatGPT)和吸引技术对酒店预测系统的整合和改进</li>
<li>results: 透过实验研究，发现这些技术可以提高用户满意度和酒店营收<details>
<summary>Abstract</summary>
Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests. Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies, have opened new avenues for enhancing the effectiveness of those systems. This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems. First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations. We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles. Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recommendations. By incorporating persuasive techniques, such as social proof, scarcity and personalization, recommender systems can effectively influence user decision-making and encourage desired actions, such as booking a specific hotel or upgrading their room. To investigate the efficacy of ChatGPT and persuasive technologies, we present a pilot experi-ment with a case study involving a hotel recommender system. We aim to study the impact of integrating ChatGPT and persua-sive techniques on user engagement, satisfaction, and conversion rates. The preliminary results demonstrate the potential of these technologies in enhancing the overall guest experience and business performance. Overall, this paper contributes to the field of hotel hospitality by exploring the synergistic relationship between LLMs and persuasive technology in recommender systems, ultimately influencing guest satisfaction and hotel revenue.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT酒店ospitality行业中的推荐系统已经成为不可或缺的工具，帮助客户得到个性化和适应性的体验。最新的大型语言模型（LLMs），如ChatGPT，以及吸引技术，则开启了新的 Avenues for enhancing the effectiveness of those systems。这篇论文探讨了将ChatGPT和吸引技术 integrate into hotel hospitality推荐系统中的 potential。首先，我们深入探讨ChatGPT的能力，它可以理解和生成人类语言，实现更加精确和上下文感知的推荐。我们讨论了将ChatGPT integrating into recommender systems， highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles。其次，我们 investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recommendations。通过 incorporating persuasive techniques, such as social proof, scarcity and personalization, recommender systems can effectively influence user decision-making and encourage desired actions, such as booking a specific hotel or upgrading their room。为了评估ChatGPT和吸引技术的效果，我们进行了一项试验，使用一个酒店推荐系统的case study。我们的目的是研究将ChatGPT和吸引技术integrated into hotel hospitality推荐系统的影响，包括用户参与度、满意度和转化率。初步结果表明这些技术在提高客户体验和酒店业绩方面具有潜在的潜力。总之，这篇论文对酒店ospitality领域的推荐系统做出了贡献，探讨了LLMs和吸引技术之间的相互关系，最终影响客户满意度和酒店收益。
</details></li>
</ul>
<hr>
<h2 id="Unraveling-the-Complexity-of-Splitting-Sequential-Data-Tackling-Challenges-in-Video-and-Time-Series-Analysis"><a href="#Unraveling-the-Complexity-of-Splitting-Sequential-Data-Tackling-Challenges-in-Video-and-Time-Series-Analysis" class="headerlink" title="Unraveling the Complexity of Splitting Sequential Data: Tackling Challenges in Video and Time Series Analysis"></a>Unraveling the Complexity of Splitting Sequential Data: Tackling Challenges in Video and Time Series Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14294">http://arxiv.org/abs/2307.14294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diego Botache, Kristina Dingel, Rico Huhnstock, Arno Ehresmann, Bernhard Sick</li>
<li>for: 本研究探讨了分析顺序数据时的挑战，包括数据收集、数据表示、分割率选择、设置质量标准和选择适当的选择策略。</li>
<li>methods: 本研究使用了两个实际应用例 Study two real-world examples: motor test benches and particle tracking in liquids.</li>
<li>results: 研究发现，在分析顺序数据时，需要考虑数据收集、数据表示、分割率选择、设置质量标准和选择适当的选择策略等多个因素，以确保分析结果的准确性和可靠性。<details>
<summary>Abstract</summary>
Splitting of sequential data, such as videos and time series, is an essential step in various data analysis tasks, including object tracking and anomaly detection. However, splitting sequential data presents a variety of challenges that can impact the accuracy and reliability of subsequent analyses. This concept article examines the challenges associated with splitting sequential data, including data acquisition, data representation, split ratio selection, setting up quality criteria, and choosing suitable selection strategies. We explore these challenges through two real-world examples: motor test benches and particle tracking in liquids.
</details>
<details>
<summary>摘要</summary>
分割连续数据，如视频和时间序列，是数据分析任务中的一项重要步骤，包括对象跟踪和异常检测。然而，分割连续数据带来许多挑战，这些挑战可能会影响后续分析的准确性和可靠性。本概念文章探讨分割连续数据的挑战，包括数据获取、数据表示、分割率选择、设置质量标准和选择适合的选择策略。我们通过两个实际应用例：汽车测试台和在液体中跟踪粒子来探讨这些挑战。
</details></li>
</ul>
<hr>
<h2 id="General-Purpose-Artificial-Intelligence-Systems-GPAIS-Properties-Definition-Taxonomy-Open-Challenges-and-Implications"><a href="#General-Purpose-Artificial-Intelligence-Systems-GPAIS-Properties-Definition-Taxonomy-Open-Challenges-and-Implications" class="headerlink" title="General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Open Challenges and Implications"></a>General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Open Challenges and Implications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14283">http://arxiv.org/abs/2307.14283</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isaac Triguero, Daniel Molina, Javier Poyatos, Javier Del Ser, Francisco Herrera</li>
<li>for: The paper discusses and proposes a new definition for General-Purpose Artificial Intelligence Systems (GPAIS) and its differentiation based on various factors.</li>
<li>methods: The paper uses existing definitions of GPAIS and proposes a new definition, and also discusses a taxonomy of approaches to realise GPAIS.</li>
<li>results: The paper aims to facilitate research collaboration across different areas that are tackling general-purpose tasks, and provides a holistic view of GPAIS, including its challenges and prospects, implications for society, and the need for responsible and trustworthy AI systems and regulation.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文讨论了和提出了一个新的General-Purpose Artificial Intelligence Systems（GPAIS）定义，以及其 diferenciación的基于多个因素。</li>
<li>methods: 这篇论文使用了现有的GPAIS定义，并提出了一个新的定义，同时还讨论了实现GPAIS的多种方法。</li>
<li>results: 这篇论文的目标是通过帮助不同领域的研究人员在处理通用任务方面合作，提供了GPAIS的总体视图，包括其挑战和前景，对社会的影响和责任的AI系统和 regulatory。<details>
<summary>Abstract</summary>
Most applications of Artificial Intelligence (AI) are designed for a confined and specific task. However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them. The term General-Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems. To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society. Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research.   This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations. We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgment of their own limitations. We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI or foundation models. As a prime example, we delve into generative AI, aligning them with the terms and concepts presented in the taxonomy. Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general-purpose tasks, as they share many common aspects. Finally, we discuss the current state of GPAIS, its challenges and prospects, implications for our society, and the need for responsible and trustworthy AI systems and regulation, with the goal of providing a holistic view of GPAIS.
</details>
<details>
<summary>摘要</summary>
大多数人工智能（AI）应用都是为特定任务设计的，但有很多情况需要一种通用的AI系统，能够解决多种任务而不需要特定的设计。我们称这种AI系统为通用人工智能系统（GPAIS）。迄今为止，人工通用智能系统的可能性仍然是一个aspiration， fiction和社会中的风险。尽管我们仍然远离实现这一目标，但GPAIS已经成为人工智能研究的前线。这个工作提出了现有的GPAIS定义，并提出了一个新的定义，允许在不同的性能和限制基础下进行渐进的分类。我们分为闭世和开放世GPAIS，根据它们的自主性、能力和多个因素进行定义，如适应新任务、在不expressly预训练的领域中的能力、从少量数据学习、或者主动承认自己的局限性。然后，我们提出了实现GPAIS的方法分类，描述了研究趋势，如使用AI技术来提高另一个AI或基础模型。作为一个典型例子，我们探讨了生成AI，与提出的术语和概念进行对应。通过我们的定义和分类，我们希望能够促进不同领域在解决通用任务方面的合作研究，因为它们在许多方面都有共同之处。最后，我们讨论了GPAIS的当前状况、挑战和前途，以及对我们社会的影响和责任的人工智能系统和regulation，以提供一个总的视图。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/27/cs.AI_2023_07_27/" data-id="clogyj8uv001j7cra5jty8lr5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/27/cs.CL_2023_07_27/" class="article-date">
  <time datetime="2023-07-27T11:00:00.000Z" itemprop="datePublished">2023-07-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/27/cs.CL_2023_07_27/">cs.CL - 2023-07-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ARC-NLP-at-PAN-2023-Transition-Focused-Natural-Language-Inference-for-Writing-Style-Detection"><a href="#ARC-NLP-at-PAN-2023-Transition-Focused-Natural-Language-Inference-for-Writing-Style-Detection" class="headerlink" title="ARC-NLP at PAN 2023: Transition-Focused Natural Language Inference for Writing Style Detection"></a>ARC-NLP at PAN 2023: Transition-Focused Natural Language Inference for Writing Style Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14913">http://arxiv.org/abs/2307.14913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Izzet Emre Kucukkaya, Umitcan Sahin, Cagri Toraman</li>
<li>for: 本文的任务是检测文本中的多个作者写作风格变化。</li>
<li>methods: 我们将这个任务转换为自然语言推理问题，并将两个篇章相互对应。我们使用不同的 transformer 基础模型进行训练，并在训练过程中添加充电阶段。</li>
<li>results: 我们在 экспериментах中表现出了超过基线和其他提议的模型版本的好干净。对于易、中等设置，我们提交了关注转折的自然语言推理基于 DeBERTa 的温存训练版本，而对于困难设置，我们提交了不含转折的同一模型版本。<details>
<summary>Abstract</summary>
The task of multi-author writing style detection aims at finding any positions of writing style change in a given text document. We formulate the task as a natural language inference problem where two consecutive paragraphs are paired. Our approach focuses on transitions between paragraphs while truncating input tokens for the task. As backbone models, we employ different Transformer-based encoders with warmup phase during training. We submit the model version that outperforms baselines and other proposed model versions in our experiments. For the easy and medium setups, we submit transition-focused natural language inference based on DeBERTa with warmup training, and the same model without transition for the hard setup.
</details>
<details>
<summary>摘要</summary>
文本检测多种作者风格目标在文档中找到任何写作风格变化的位置。我们将问题转换为自然语言推理问题，将两段文本相邻排序。我们的方法关注段落之间的转换，并在训练中使用Transformer基本encoder进行温存阶段。在我们的实验中，我们提交的模型版本超越基eline和其他提议的模型版本。对于易Difficulty和中等Difficulty的设置，我们提交转换注意力的自然语言推理基于DeBERTa，并在训练中添加温存阶段。
</details></li>
</ul>
<hr>
<h2 id="ARC-NLP-at-PAN-2023-Hierarchical-Long-Text-Classification-for-Trigger-Detection"><a href="#ARC-NLP-at-PAN-2023-Hierarchical-Long-Text-Classification-for-Trigger-Detection" class="headerlink" title="ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger Detection"></a>ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14912">http://arxiv.org/abs/2307.14912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Umitcan Sahin, Izzet Emre Kucukkaya, Cagri Toraman</li>
<li>for: 这篇论文目的是描述在PAN CLEF 2023中的Trigger Detection分享任务中检测多个触发内容的方法。</li>
<li>methods: 我们使用了层次模型，其中首先将长文档分割成较小的 segment，然后使用这些 segment 来练化一个基于 Transformer 的语言模型。接着，我们从练化后的 Transformer 模型提取特征嵌入，并将其作为多个 LSTM 模型的训练输入。</li>
<li>results: 我们的模型在验证集上达到了 F1-macro 分数为 0.372 和 F1-micro 分数为 0.736，这些结果高于PAN CLEF 2023中基eline的结果。<details>
<summary>Abstract</summary>
Fanfiction, a popular form of creative writing set within established fictional universes, has gained a substantial online following. However, ensuring the well-being and safety of participants has become a critical concern in this community. The detection of triggering content, material that may cause emotional distress or trauma to readers, poses a significant challenge. In this paper, we describe our approach for the Trigger Detection shared task at PAN CLEF 2023, where we want to detect multiple triggering content in a given Fanfiction document. For this, we build a hierarchical model that uses recurrence over Transformer-based language models. In our approach, we first split long documents into smaller sized segments and use them to fine-tune a Transformer model. Then, we extract feature embeddings from the fine-tuned Transformer model, which are used as input in the training of multiple LSTM models for trigger detection in a multi-label setting. Our model achieves an F1-macro score of 0.372 and F1-micro score of 0.736 on the validation set, which are higher than the baseline results shared at PAN CLEF 2023.
</details>
<details>
<summary>摘要</summary>
fanfiction，一种受欢迎的创作写作形式，已经在确立的虚拟世界中得到了大量的在线支持。然而，保证参与者的健康和安全已成为这个社区的核心问题。检测触发内容（material that may cause emotional distress or trauma to readers）成为了一项重要的挑战。在这篇论文中，我们描述了我们在PAN CLEF 2023中的触发检测共同任务中的方法，我们想检测给定的fanfiction文档中的多个触发内容。为此，我们构建了层次模型，使用recurrence override Transformer-based语言模型。在我们的方法中，我们首先将长文档分成更小的段落，然后使用这些段落来精度调整Transformer模型。然后，我们从精度调整后的Transformer模型中提取特征嵌入，这些嵌入被用作多个LSTM模型的训练输入，以实现多标签的触发检测。我们的模型在验证集上达到了F1-macroscore的0.372和F1-micro score的0.736，这些结果高于PAN CLEF 2023中分享的基线结果。
</details></li>
</ul>
<hr>
<h2 id="Retrieval-based-Text-Selection-for-Addressing-Class-Imbalanced-Data-in-Classification"><a href="#Retrieval-based-Text-Selection-for-Addressing-Class-Imbalanced-Data-in-Classification" class="headerlink" title="Retrieval-based Text Selection for Addressing Class-Imbalanced Data in Classification"></a>Retrieval-based Text Selection for Addressing Class-Imbalanced Data in Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14899">http://arxiv.org/abs/2307.14899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sareh Ahmadi, Aditya Shah, Edward Fox</li>
<li>for: 这篇论文的目的是解决文本分类中选择文本进行标注的问题，当有限制人工资源时。另外，该论文还面临了罕见的分类问题，即Binary categories with a small number of positive instances。</li>
<li>methods: 这篇论文提出了利用SHAP来建构高质量的查询集，以便使用Elasticsearch和semantic search来选择需要标注的文本。这种方法可以在批量标注的情况下，使用先前的标注来指导下一批文本的选择。</li>
<li>results: 实验结果显示，这种方法可以提高少数分类的F1分数，协助解决分类问题。<details>
<summary>Abstract</summary>
This paper addresses the problem of selecting of a set of texts for annotation in text classification using retrieval methods when there are limits on the number of annotations due to constraints on human resources. An additional challenge addressed is dealing with binary categories that have a small number of positive instances, reflecting severe class imbalance. In our situation, where annotation occurs over a long time period, the selection of texts to be annotated can be made in batches, with previous annotations guiding the choice of the next set. To address these challenges, the paper proposes leveraging SHAP to construct a quality set of queries for Elasticsearch and semantic search, to try to identify optimal sets of texts for annotation that will help with class imbalance. The approach is tested on sets of cue texts describing possible future events, constructed by participants involved in studies aimed to help with the management of obesity and diabetes. We introduce an effective method for selecting a small set of texts for annotation and building high-quality classifiers. We integrate vector search, semantic search, and machine learning classifiers to yield a good solution. Our experiments demonstrate improved F1 scores for the minority classes in binary classification.
</details>
<details>
<summary>摘要</summary>
Here is the translation in Simplified Chinese:这篇论文关注在文本分类中使用检索方法选择文本进行标注时，因为人工资源有限制而存在限制标注数量的问题。此外，论文还 Addresses the challenge of dealing with binary categories that have a small number of positive instances, reflecting severe class imbalance. 在我们的情况下，标注发生在长时间内，因此可以在批次中选择文本进行标注，前一次的标注导导选择下一批文本。为解决这些挑战，论文提议利用SHAP construct一个质量集合查询语义搜索，以尝试确定最佳的标注文本集，以帮助减轻类偏。这种方法在cue文描述可能的未来事件的集合上进行测试，这些集合由参与研究的参与者构建。我们引入了一种有效的文本选择和建立高质量分类器的方法。我们将vector搜索、语义搜索和机器学习分类器集成，以获得良好的解决方案。我们的实验表明，在二分类分类中，少数类的F1分数得到了改善。
</details></li>
</ul>
<hr>
<h2 id="MESED-A-Multi-modal-Entity-Set-Expansion-Dataset-with-Fine-grained-Semantic-Classes-and-Hard-Negative-Entities"><a href="#MESED-A-Multi-modal-Entity-Set-Expansion-Dataset-with-Fine-grained-Semantic-Classes-and-Hard-Negative-Entities" class="headerlink" title="MESED: A Multi-modal Entity Set Expansion Dataset with Fine-grained Semantic Classes and Hard Negative Entities"></a>MESED: A Multi-modal Entity Set Expansion Dataset with Fine-grained Semantic Classes and Hard Negative Entities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14878">http://arxiv.org/abs/2307.14878</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thukelab/mesed">https://github.com/thukelab/mesed</a></li>
<li>paper_authors: Yangning Li, Tingwei Lu, Yinghui Li, Tianyu Yu, Shulin Huang, Hai-Tao Zheng, Rui Zhang, Jun Yuan</li>
<li>for: 本研究旨在提高Entity Set Expansion（ESE）任务中的entity扩展精度，通过 integrate多Modalities的信息来表示实体。</li>
<li>methods: 本研究提出了Multi-modal Entity Set Expansion（MESE）方法，使用多modalities的信息来代表实体，包括：(1) 不同Modalities提供补充信息。(2) 多modalities信息提供共同Visual属性，为同Semantic class或实体提供一致信号。(3) 多modalities信息提供Robust的Alignment信号，用于同义实体。</li>
<li>results: 在MESED dataset上，我们提出了一种 poderous multi-modal模型MultiExpan，通过四种多模态预训练任务进行预训练。实验和分析表明，MESED dataset具有高质量，MultiExpan具有高效性，同时还指明了未来研究的方向。<details>
<summary>Abstract</summary>
The Entity Set Expansion (ESE) task aims to expand a handful of seed entities with new entities belonging to the same semantic class. Conventional ESE methods are based on mono-modality (i.e., literal modality), which struggle to deal with complex entities in the real world such as: (1) Negative entities with fine-grained semantic differences. (2) Synonymous entities. (3) Polysemous entities. (4) Long-tailed entities. These challenges prompt us to propose Multi-modal Entity Set Expansion (MESE), where models integrate information from multiple modalities to represent entities. Intuitively, the benefits of multi-modal information for ESE are threefold: (1) Different modalities can provide complementary information. (2) Multi-modal information provides a unified signal via common visual properties for the same semantic class or entity. (3) Multi-modal information offers robust alignment signal for synonymous entities. To assess the performance of model in MESE and facilitate further research, we constructed the MESED dataset which is the first multi-modal dataset for ESE with large-scale and elaborate manual calibration. A powerful multi-modal model MultiExpan is proposed which is pre-trained on four multimodal pre-training tasks. The extensive experiments and analyses on MESED demonstrate the high quality of the dataset and the effectiveness of our MultiExpan, as well as pointing the direction for future research.
</details>
<details>
<summary>摘要</summary>
Entity Set Expansion (ESE) 任务目标是从seed entity开始扩展新的实体，这些实体属于同一个semantic class。传统的ESE方法基于单一模式（即Literal modality），在实际世界中遇到了复杂实体的挑战，如：1. 具有细化 semantic differences的负实体。2. 同义实体。3. 多义实体。4. 长尾实体。这些挑战使我们提出了Multi-modal Entity Set Expansion (MESE)，其中模型可以 Integrate multiple modalities 来表示实体。可以 intuitively 分解为以下三个 benefit:1. 不同的模式可以提供补充信息。2. multi-modal information 提供了一个统一的信号，通过共同的视觉属性来表示同一个semantic class或实体。3. multi-modal information 提供了一个强健的对同义实体的吴健信号。为了评估模型在 MESE 中的性能和进一步研究，我们构建了 MESED 数据集，这是首个大规模、精心准备的多模式 ESE 数据集。我们还提出了一种强大的多模式模型 MultiExpan，该模型在四种多模式预训练任务上进行预训练。我们对 MESED 进行了广泛的实验和分析，以证明数据集的高质量和我们的 MultiExpan 的有效性，同时也指出了未来研究的方向。
</details></li>
</ul>
<hr>
<h2 id="Cascaded-Cross-Modal-Transformer-for-Request-and-Complaint-Detection"><a href="#Cascaded-Cross-Modal-Transformer-for-Request-and-Complaint-Detection" class="headerlink" title="Cascaded Cross-Modal Transformer for Request and Complaint Detection"></a>Cascaded Cross-Modal Transformer for Request and Complaint Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15097">http://arxiv.org/abs/2307.15097</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ristea/ccmt">https://github.com/ristea/ccmt</a></li>
<li>paper_authors: Nicolae-Catalin Ristea, Radu Tudor Ionescu</li>
<li>for: 本研究的目的是开发一种新的多modal transformer模型，用于检测电话对话中的客户请求和投诉。</li>
<li>methods: 本研究使用自动语音识别（ASR）模型将语音转录为文本，并将文本翻译成不同的语言。然后，我们将语言特定的 BERT 模型和 Wav2Vec2.0 音频特征结合在一起，使用novel的卷积混合注意力模型。</li>
<li>results: 我们在 ACM Multimedia 2023 计算语言学挑战中的请求子挑战中应用了我们的系统，实现了无权重平均回归率（UAR）65.41%和85.87%  для请求和投诉类别。<details>
<summary>Abstract</summary>
We propose a novel cascaded cross-modal transformer (CCMT) that combines speech and text transcripts to detect customer requests and complaints in phone conversations. Our approach leverages a multimodal paradigm by transcribing the speech using automatic speech recognition (ASR) models and translating the transcripts into different languages. Subsequently, we combine language-specific BERT-based models with Wav2Vec2.0 audio features in a novel cascaded cross-attention transformer model. We apply our system to the Requests Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge, reaching unweighted average recalls (UAR) of 65.41% and 85.87% for the complaint and request classes, respectively.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的层次融合 cross-modal transformer（CCMT），该模型结合语音和文本译文来检测电话对话中的客户请求和投诉。我们的方法借鉴了多模态思想，通过使用自动语音识别（ASR）模型将语音转录为不同语言，然后将语言特定的 BERT 基于模型与 Wav2Vec2.0 音频特征结合在一起，并通过新的层次融合 cross-attention transformer 模型进行结合。我们在 ACM Multimedia 2023 计算 паралингвистики挑战中的请求子挑战中应用了我们的系统，实现了不Weighted average recall（UAR）的 65.41% 和 85.87%，对于投诉和请求类别。
</details></li>
</ul>
<hr>
<h2 id="ArcGPT-A-Large-Language-Model-Tailored-for-Real-world-Archival-Applications"><a href="#ArcGPT-A-Large-Language-Model-Tailored-for-Real-world-Archival-Applications" class="headerlink" title="ArcGPT: A Large Language Model Tailored for Real-world Archival Applications"></a>ArcGPT: A Large Language Model Tailored for Real-world Archival Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14852">http://arxiv.org/abs/2307.14852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shitou Zhang, Jingrui Hou, Siyuan Peng, Zuchao Li, Qibiao Hu, Ping Wang</li>
<li>for: 为了更好地管理和利用档案信息资源，提高archivist的工作效率和质量。</li>
<li>methods: 使用大量和广泛的档案领域数据进行预训练，提高模型在真实世界档案任务中的表现。</li>
<li>results: 比起现有状态的模型，ArcGPT在四个真实世界档案任务上表现出色，代表了一个重要的进步在有效地管理档案数据方面。<details>
<summary>Abstract</summary>
Archives play a crucial role in preserving information and knowledge, and the exponential growth of such data necessitates efficient and automated tools for managing and utilizing archive information resources. Archival applications involve managing massive data that are challenging to process and analyze. Although LLMs have made remarkable progress in diverse domains, there are no publicly available archives tailored LLM. Addressing this gap, we introduce ArcGPT, to our knowledge, the first general-purpose LLM tailored to the archival field. To enhance model performance on real-world archival tasks, ArcGPT has been pre-trained on massive and extensive archival domain data. Alongside ArcGPT, we release AMBLE, a benchmark comprising four real-world archival tasks. Evaluation on AMBLE shows that ArcGPT outperforms existing state-of-the-art models, marking a substantial step forward in effective archival data management. Ultimately, ArcGPT aims to better serve the archival community, aiding archivists in their crucial role of preserving and harnessing our collective information and knowledge.
</details>
<details>
<summary>摘要</summary>
归档 play a crucial role in preserving information and knowledge, and the exponential growth of such data makes it necessary to have efficient and automated tools for managing and utilizing archive information resources. 归档应用程序面临着处理和分析庞大数据的挑战。虽然LLMs 已经在多个领域取得了卓越成果，但是没有公共可用的归档LLM。为了填补这个空白，我们介绍ArcGPT，我们知道的第一个普用LLM，专门针对归档领域。为了提高模型在实际归档任务中的性能，ArcGPT 在庞大和广泛的归档领域数据上进行了预训练。同时，我们发布了 AMBLE，一个包含四个实际归档任务的benchmark。评估表明，ArcGPT 在 AMBLE 上表现出色，超越了现有的状态对模型， represents a significant step forward in effective archival data management。最终，ArcGPT  hopes to better serve the archival community, aiding archivists in their crucial role of preserving and harnessing our collective information and knowledge.
</details></li>
</ul>
<hr>
<h2 id="Turkish-Native-Language-Identification"><a href="#Turkish-Native-Language-Identification" class="headerlink" title="Turkish Native Language Identification"></a>Turkish Native Language Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14850">http://arxiv.org/abs/2307.14850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmet Yavuz Uluslu, Gerold Schneider</li>
<li>for: 这个论文是为了探讨土耳其语言认知（NLI）的首次应用。</li>
<li>methods: 该研究使用了土耳其学习语料库，并结合三种语法特征（CFG生成规则、part-of-speech n-grams和函数词）来证明其效果。</li>
<li>results: 研究发现这些语法特征可以有效地预测土耳其作者的首语言。<details>
<summary>Abstract</summary>
In this paper, we present the first application of Native Language Identification (NLI) for the Turkish language. NLI involves predicting the writer's first language by analysing their writing in different languages. While most NLI research has focused on English, our study extends its scope to Turkish. We used the recently constructed Turkish Learner Corpus and employed a combination of three syntactic features (CFG production rules, part-of-speech n-grams, and function words) with L2 texts to demonstrate their effectiveness in this task.
</details>
<details>
<summary>摘要</summary>
在本文中，我们介绍了第一个用于土耳其语的本地语言认知（NLI）应用。NLI 涉及预测作者的第一语言，通过分析他们在不同语言中写作的文本。而大多数 NLI 研究都集中在英语上，我们的研究将其扩展到土耳其语。我们使用最近建立的土耳其学习 корпуス，并将三种语法特征（CFG生成规则、part-of-speech n-grams 和函数词）与第二语言文本结合使用，以示其效果。
</details></li>
</ul>
<hr>
<h2 id="What-Makes-a-Good-Paraphrase-Do-Automated-Evaluations-Work"><a href="#What-Makes-a-Good-Paraphrase-Do-Automated-Evaluations-Work" class="headerlink" title="What Makes a Good Paraphrase: Do Automated Evaluations Work?"></a>What Makes a Good Paraphrase: Do Automated Evaluations Work?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14818">http://arxiv.org/abs/2307.14818</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anna Moskvina, Bhushan Kotnis, Chris Catacata, Michael Janz, Nasrin Saef</li>
<li>for: 本研究旨在探讨自动重塑语料的质量。</li>
<li>methods: 研究使用了自动生成的语料，并采用了不同的自动重塑策略进行评估。</li>
<li>results: 研究发现，使用不同的自动重塑策略可以获得不同的质量。<details>
<summary>Abstract</summary>
Paraphrasing is the task of expressing an essential idea or meaning in different words. But how different should the words be in order to be considered an acceptable paraphrase? And can we exclusively use automated metrics to evaluate the quality of a paraphrase? We attempt to answer these questions by conducting experiments on a German data set and performing automatic and expert linguistic evaluation.
</details>
<details>
<summary>摘要</summary>
要完成篇幅翻译，需要不同的词语表达同一个主题的核心意义。但是，可以用自动化指标来评估翻译质量吗？我们通过使用德语数据集进行实验和自动语言评估来尝试回答这些问题。Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Models-of-reference-production-How-do-they-withstand-the-test-of-time"><a href="#Models-of-reference-production-How-do-they-withstand-the-test-of-time" class="headerlink" title="Models of reference production: How do they withstand the test of time?"></a>Models of reference production: How do they withstand the test of time?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14817">http://arxiv.org/abs/2307.14817</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fsame/reg_grec-wsj">https://github.com/fsame/reg_grec-wsj</a></li>
<li>paper_authors: Fahime Same, Guanyi Chen, Kees van Deemter</li>
<li>for: 本研究的目的是研究自然语言处理（NLP）领域的语言和科学方面，而不是围绕性能提高。</li>
<li>methods: 本研究使用生成引用表达（REG-in-context）作为案例研究，从GREC（一个十年前发布的英语共同任务集）开始分析。我们评估模型在更现实的数据集和更高级的方法上的性能。我们使用不同的评价指标和特征选择实验测试模型。</li>
<li>results: 我们结论认为，GREC不再能准确评估模型的人工引用生成能力，因为选择 Corpora 和评价指标会产生很大的影响。我们的结果还表明，基于预训练语言模型的模型比 классиic Machine Learning 模型更具有抗衰落性，因此在不同的 Corpora 上都能够更好地预测类别。<details>
<summary>Abstract</summary>
In recent years, many NLP studies have focused solely on performance improvement. In this work, we focus on the linguistic and scientific aspects of NLP. We use the task of generating referring expressions in context (REG-in-context) as a case study and start our analysis from GREC, a comprehensive set of shared tasks in English that addressed this topic over a decade ago. We ask what the performance of models would be if we assessed them (1) on more realistic datasets, and (2) using more advanced methods. We test the models using different evaluation metrics and feature selection experiments. We conclude that GREC can no longer be regarded as offering a reliable assessment of models' ability to mimic human reference production, because the results are highly impacted by the choice of corpus and evaluation metrics. Our results also suggest that pre-trained language models are less dependent on the choice of corpus than classic Machine Learning models, and therefore make more robust class predictions.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "GREC" is translated as "格列克" (Gélèkè) in Simplified Chinese, which is a combination of "语料" (yǔliào) and "共享" (gòngxiǎng).* "REG-in-context" is translated as "在上下文中的引用表达" (zài shàngxìaoxìng zhōng de yǐnxiǎng biǎojiè) in Simplified Chinese.* "pre-trained language models" is translated as "预训练语言模型" (yùxùnxíng yǔyán módelì) in Simplified Chinese.* "classic Machine Learning models" is translated as "传统机器学习模型" (chuánchēng jīxuéxí módelì) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Improving-Aspect-Based-Sentiment-with-End-to-End-Semantic-Role-Labeling-Model"><a href="#Improving-Aspect-Based-Sentiment-with-End-to-End-Semantic-Role-Labeling-Model" class="headerlink" title="Improving Aspect-Based Sentiment with End-to-End Semantic Role Labeling Model"></a>Improving Aspect-Based Sentiment with End-to-End Semantic Role Labeling Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14785">http://arxiv.org/abs/2307.14785</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pauli31/srl-aspect-based-sentiment">https://github.com/pauli31/srl-aspect-based-sentiment</a></li>
<li>paper_authors: Pavel Přibáň, Ondřej Pražák</li>
<li>for: 提高 Aspect-Based Sentiment Analysis (ABSA) 性能</li>
<li>methods: 利用 Semantic Role Labeling (SRL) 模型提取 semantics 信息，并提出了一种 novel end-to-end SRL 模型</li>
<li>results: 在英语和捷克两种语言中，使用 ELECTRA-small 模型评估提出的模型，并在两种语言中提高了 ABSA 性能，同时在捷克 ABSA 实现了新的状态理想 результаanos<details>
<summary>Abstract</summary>
This paper presents a series of approaches aimed at enhancing the performance of Aspect-Based Sentiment Analysis (ABSA) by utilizing extracted semantic information from a Semantic Role Labeling (SRL) model. We propose a novel end-to-end Semantic Role Labeling model that effectively captures most of the structured semantic information within the Transformer hidden state. We believe that this end-to-end model is well-suited for our newly proposed models that incorporate semantic information. We evaluate the proposed models in two languages, English and Czech, employing ELECTRA-small models. Our combined models improve ABSA performance in both languages. Moreover, we achieved new state-of-the-art results on the Czech ABSA.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Turning-Whisper-into-Real-Time-Transcription-System"><a href="#Turning-Whisper-into-Real-Time-Transcription-System" class="headerlink" title="Turning Whisper into Real-Time Transcription System"></a>Turning Whisper into Real-Time Transcription System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14743">http://arxiv.org/abs/2307.14743</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ufal/whisper_streaming">https://github.com/ufal/whisper_streaming</a></li>
<li>paper_authors: Dominik Macháček, Raj Dabre, Ondřej Bojar</li>
<li>for: 这个论文是为了实现实时语音抄写和翻译的 Whisper-Streaming 模型而写的。</li>
<li>methods: 该论文基于 Whisper 模型，并使用本地协议和自适应延迟来实现流式抄写。</li>
<li>results: 论文在长形语音抄写测试集上达到了高质量和3.3秒延迟，并在多语言会议中作为实时抄写组件展示了可靠性和实用性。<details>
<summary>Abstract</summary>
Whisper is one of the recent state-of-the-art multilingual speech recognition and translation models, however, it is not designed for real time transcription. In this paper, we build on top of Whisper and create Whisper-Streaming, an implementation of real-time speech transcription and translation of Whisper-like models. Whisper-Streaming uses local agreement policy with self-adaptive latency to enable streaming transcription. We show that Whisper-Streaming achieves high quality and 3.3 seconds latency on unsegmented long-form speech transcription test set, and we demonstrate its robustness and practical usability as a component in live transcription service at a multilingual conference.
</details>
<details>
<summary>摘要</summary>
喊号是一种最新的多语言语音识别和翻译模型，但它并不是实时抄写的设计。在这篇论文中，我们基于喊号建立了喊号流动，一种实时语音抄写和翻译的喊号-like 模型的实现。喊号流动使用本地协议策略和自适应延迟来实现流动抄写。我们表明，喊号流动在长形语音抄写测试集上达到了高质量和3.3秒延迟，并在多语言会议中作为实时抄写服务的组件进行了实践应用。
</details></li>
</ul>
<hr>
<h2 id="Improving-Natural-Language-Inference-in-Arabic-using-Transformer-Models-and-Linguistically-Informed-Pre-Training"><a href="#Improving-Natural-Language-Inference-in-Arabic-using-Transformer-Models-and-Linguistically-Informed-Pre-Training" class="headerlink" title="Improving Natural Language Inference in Arabic using Transformer Models and Linguistically Informed Pre-Training"></a>Improving Natural Language Inference in Arabic using Transformer Models and Linguistically Informed Pre-Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14666">http://arxiv.org/abs/2307.14666</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fraunhofer-iais/arabic_nlp">https://github.com/fraunhofer-iais/arabic_nlp</a></li>
<li>paper_authors: Mohammad Majd Saad Al Deen, Maren Pielka, Jörn Hees, Bouthaina Soulef Abdou, Rafet Sifa</li>
<li>for: 本研究针对的是使用自然语言处理（NLP）技术进行阿拉伯文本分类，尤其是自然语言推理（NLI）和矛盾检测（CD）。由于阿拉伯语为resource-poor语言，具有有限的数据资源，因此有限的NLP方法可用。</li>
<li>methods: 作者通过创建专门的数据集来缓解这种限制，并使用 transformer 型机器学习模型进行训练和评估。他们还应用了语言专门预训练方法，如命名实体识别（NER），以提高模型的性能。</li>
<li>results: 研究发现，使用语言专门预训练方法可以使模型在阿拉伯语言中表现竞争力强，并且与多语言方法相比，语言专门模型（AraBERT）在 NLI 和 CD 任务上的性能几乎相同。这是首次对这类任务进行大规模评估，也是首次在这种语言上应用多任务预训练。<details>
<summary>Abstract</summary>
This paper addresses the classification of Arabic text data in the field of Natural Language Processing (NLP), with a particular focus on Natural Language Inference (NLI) and Contradiction Detection (CD). Arabic is considered a resource-poor language, meaning that there are few data sets available, which leads to limited availability of NLP methods. To overcome this limitation, we create a dedicated data set from publicly available resources. Subsequently, transformer-based machine learning models are being trained and evaluated. We find that a language-specific model (AraBERT) performs competitively with state-of-the-art multilingual approaches, when we apply linguistically informed pre-training methods such as Named Entity Recognition (NER). To our knowledge, this is the first large-scale evaluation for this task in Arabic, as well as the first application of multi-task pre-training in this context.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Plug-and-Pray-Exploiting-off-the-shelf-components-of-Multi-Modal-Models"><a href="#Plug-and-Pray-Exploiting-off-the-shelf-components-of-Multi-Modal-Models" class="headerlink" title="Plug and Pray: Exploiting off-the-shelf components of Multi-Modal Models"></a>Plug and Pray: Exploiting off-the-shelf components of Multi-Modal Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14539">http://arxiv.org/abs/2307.14539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Erfan Shayegani, Yue Dong, Nael Abu-Ghazaleh<br>for: 这篇论文的目的是提醒开发者关于将多模态组件（如视觉） incorporated into large language models（LLMs）中存在的安全问题。methods: 论文使用了对预训练encoder的 embedding空间进行攻击，而这些预训练encoder通常是公共可用的，并在多模态系统中使用了plug-and-play的方式。results: 论文发现，通过在预训练encoder的 embedding空间中寻找适合的输入图像，可以让模型表现出异常的行为，包括“Context Contamination”和“Hidden Prompt Injection”等两种威胁。这些威胁可以让模型的行为发生重大变化，从而威胁多模态系统的安全性。<details>
<summary>Abstract</summary>
The rapid growth and increasing popularity of incorporating additional modalities (e.g., vision) into large language models (LLMs) has raised significant security concerns. This expansion of modality, akin to adding more doors to a house, unintentionally creates multiple access points for adversarial attacks. In this paper, by introducing adversarial embedding space attacks, we emphasize the vulnerabilities present in multi-modal systems that originate from incorporating off-the-shelf components like public pre-trained encoders in a plug-and-play manner into these systems. In contrast to existing work, our approach does not require access to the multi-modal system's weights or parameters but instead relies on the huge under-explored embedding space of such pre-trained encoders. Our proposed embedding space attacks involve seeking input images that reside within the dangerous or targeted regions of the extensive embedding space of these pre-trained components. These crafted adversarial images pose two major threats: 'Context Contamination' and 'Hidden Prompt Injection'-both of which can compromise multi-modal models like LLaVA and fully change the behavior of the associated language model. Our findings emphasize the need for a comprehensive examination of the underlying components, particularly pre-trained encoders, before incorporating them into systems in a plug-and-play manner to ensure robust security.
</details>
<details>
<summary>摘要</summary>
“大型语言模型（LLM）中的多modalitate（例如视觉）的快速增长和增加受欢迎性，导致安全性问题的提出。这些多modalitate的扩展，就如加入更多门窗的房屋一样，不意气境产生多个攻击入口。在这篇论文中，我们透过引入对抗嵌入空间攻击，强调了多modalite系统中从对抗预训练encoder的潜在弱点。与现有的工作不同，我们的方法不需要访问多modalite系统的 weights或parameters，而是利用这些预训练encoder的广大未探索的嵌入空间。我们的提案的对抗嵌入空间攻击包括寻找在这些预训练encoder的危险或目标区域中的输入图像。这些制成的攻击图像会导致两种主要威胁：'Context Contamination'和'Hidden Prompt Injection'，这两种威胁都可以妥协多modalite模型如LLaVA，并完全改变这些语言模型的行为。我们的发现强调了在将这些预训练encoder incorporated into systems中需要进行全面的评估，以确保系统的安全性。”
</details></li>
</ul>
<hr>
<h2 id="CliniDigest-A-Case-Study-in-Large-Language-Model-Based-Large-Scale-Summarization-of-Clinical-Trial-Descriptions"><a href="#CliniDigest-A-Case-Study-in-Large-Language-Model-Based-Large-Scale-Summarization-of-Clinical-Trial-Descriptions" class="headerlink" title="CliniDigest: A Case Study in Large Language Model Based Large-Scale Summarization of Clinical Trial Descriptions"></a>CliniDigest: A Case Study in Large Language Model Based Large-Scale Summarization of Clinical Trial Descriptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14522">http://arxiv.org/abs/2307.14522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renee D. White, Tristan Peng, Pann Sripitak, Alexander Rosenberg Johansen, Michael Snyder</li>
<li>for:  This paper aims to provide a tool for summarizing clinical trials in real-time, with the goal of helping researchers keep up-to-date with the latest trials in their field.</li>
<li>methods: The tool used for summarization is called CliniDigest, which is based on GPT-3.5. It can reduce a large amount of text (up to 85 clinical trial descriptions) into a concise 200-word summary with references and limited hallucinations.</li>
<li>results: The paper reports the results of testing CliniDigest on 457 trials across 27 medical subdomains. The summaries generated by CliniDigest have a mean length of 153 words and utilize an average of 54% of the sources.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文的目的是为了提供一种实时概括临床试验的工具，以帮助研究人员保持最新的知识在其领域。</li>
<li>methods: 这个工具被称为CliniDigest，它基于GPT-3.5。它可以将大量文本（最多85个临床试验描述）缩减成200个单词的概括，并包含参考文献和有限的幻化。</li>
<li>results: 论文报告了对CliniDigest在27个医学子领域的457个临床试验上的测试结果。CliniDigest生成的概括均长153单词，并使用了平均54%的源文献。<details>
<summary>Abstract</summary>
A clinical trial is a study that evaluates new biomedical interventions. To design new trials, researchers draw inspiration from those current and completed. In 2022, there were on average more than 100 clinical trials submitted to ClinicalTrials.gov every day, with each trial having a mean of approximately 1500 words [1]. This makes it nearly impossible to keep up to date. To mitigate this issue, we have created a batch clinical trial summarizer called CliniDigest using GPT-3.5. CliniDigest is, to our knowledge, the first tool able to provide real-time, truthful, and comprehensive summaries of clinical trials. CliniDigest can reduce up to 85 clinical trial descriptions (approximately 10,500 words) into a concise 200-word summary with references and limited hallucinations. We have tested CliniDigest on its ability to summarize 457 trials divided across 27 medical subdomains. For each field, CliniDigest generates summaries of $\mu=153,\ \sigma=69 $ words, each of which utilizes $\mu=54\%,\ \sigma=30\% $ of the sources. A more comprehensive evaluation is planned and outlined in this paper.
</details>
<details>
<summary>摘要</summary>
临床试验是评估新生物医学 intervención的研究。为设计新试验，研究人员从当前和完成的试验中留取灵感。2022年平均每天有更多于100个临床试验被提交到ClinicalTrials.gov，每个试验约1500个字。这使得保持最新的issue nearly impossible。为解决这个问题，我们创建了一个批处临床试验摘要工具 called CliniDigest，使用GPT-3.5。CliniDigest是，我们所知道的，第一个能提供实时、真实、全面的临床试验摘要。CliniDigest可以将457个试验（每个字符串约10,500个字）缩减到200个字的摘要，并且具有参考和有限的幻化。我们对CliniDigest在不同医学子领域中的性能进行了测试，每个领域的摘要平均长度为153个字，标准差为69个字，每个字符串使用54%的源文件。我们计划进一步评估CliniDigest的性能。
</details></li>
</ul>
<hr>
<h2 id="A-Predictive-Model-of-Digital-Information-Engagement-Forecasting-User-Engagement-With-English-Words-by-Incorporating-Cognitive-Biases-Computational-Linguistics-and-Natural-Language-Processing"><a href="#A-Predictive-Model-of-Digital-Information-Engagement-Forecasting-User-Engagement-With-English-Words-by-Incorporating-Cognitive-Biases-Computational-Linguistics-and-Natural-Language-Processing" class="headerlink" title="A Predictive Model of Digital Information Engagement: Forecasting User Engagement With English Words by Incorporating Cognitive Biases, Computational Linguistics and Natural Language Processing"></a>A Predictive Model of Digital Information Engagement: Forecasting User Engagement With English Words by Incorporating Cognitive Biases, Computational Linguistics and Natural Language Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14500">http://arxiv.org/abs/2307.14500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nimrod Dvir, Elaine Friedman, Suraj Commuri, Fan yang, Jennifer Romano</li>
<li>for: 这种研究旨在开发一种用于数字信息参与度（IE）预测模型，称为READ模型，它 integrates 认知偏见和计算语言学，以提供一个多维度的信息参与度视角。</li>
<li>methods: 该研究使用了 WordNet 词库中随机选择的 50 对同义词（共 100 个词），通过大规模在线调查（n &#x3D; 80,500）测量这些词的参与度水平，并计算每个词的 READ 特征值。</li>
<li>results: 研究发现，READ 模型能够准确预测一个词的参与度水平，并在对同义词进行比较时准确地分辨出更加吸引人的词。READ 模型在不同领域，如商业、教育、政府和医疗等领域，可以提高内容参与度和扩展人工语言模型的发展。<details>
<summary>Abstract</summary>
This study introduces and empirically tests a novel predictive model for digital information engagement (IE) - the READ model, an acronym for the four pivotal attributes of engaging information: Representativeness, Ease-of-use, Affect, and Distribution. Conceptualized within the theoretical framework of Cumulative Prospect Theory, the model integrates key cognitive biases with computational linguistics and natural language processing to develop a multidimensional perspective on information engagement. A rigorous testing protocol was implemented, involving 50 randomly selected pairs of synonymous words (100 words in total) from the WordNet database. These words' engagement levels were evaluated through a large-scale online survey (n = 80,500) to derive empirical IE metrics. The READ attributes for each word were then computed and their predictive efficacy examined. The findings affirm the READ model's robustness, accurately predicting a word's IE level and distinguishing the more engaging word from a pair of synonyms with an 84% accuracy rate. The READ model's potential extends across various domains, including business, education, government, and healthcare, where it could enhance content engagement and inform AI language model development and generative text work. Future research should address the model's scalability and adaptability across different domains and languages, thereby broadening its applicability and efficacy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Sentence-is-Worth-a-Thousand-Pictures-Can-Large-Language-Models-Understand-Human-Language"><a href="#A-Sentence-is-Worth-a-Thousand-Pictures-Can-Large-Language-Models-Understand-Human-Language" class="headerlink" title="A Sentence is Worth a Thousand Pictures: Can Large Language Models Understand Human Language?"></a>A Sentence is Worth a Thousand Pictures: Can Large Language Models Understand Human Language?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00109">http://arxiv.org/abs/2308.00109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gary Marcus, Evelina Leivada, Elliot Murphy</li>
<li>for: 这 paper 探讨了大语言模型在语言相关任务中的潜力，以及这些模型在人工智能发展中的应用。</li>
<li>methods: 这 paper 使用了大语言模型来进行下一个词预测任务，并分析了这些模型的贡献和缺失。</li>
<li>results: 这 paper 发现了目前大语言模型的应用还缺乏一些关键的能力，并提出了未来研发的方向。<details>
<summary>Abstract</summary>
Artificial Intelligence applications show great potential for language-related tasks that rely on next-word prediction. The current generation of large language models have been linked to claims about human-like linguistic performance and their applications are hailed both as a key step towards Artificial General Intelligence and as major advance in understanding the cognitive, and even neural basis of human language. We analyze the contribution of large language models as theoretically informative representations of a target system vs. atheoretical powerful mechanistic tools, and we identify the key abilities that are still missing from the current state of development and exploitation of these models.
</details>
<details>
<summary>摘要</summary>
人工智能应用场景中的语言相关任务可以通过下一个词预测来实现潜在的潜力。当前一代大语言模型被联系到人类语言性能的宣传和其应用被视为人工通用智能的关键一步和人类语言认知的重要进展。我们分析了大语言模型作为目标系统的理论 informative 表示和无理论强大机制工具的贡献，并标识当前开发和利用这些模型的关键缺失。
</details></li>
</ul>
<hr>
<h2 id="Controllable-Generation-of-Dialogue-Acts-for-Dialogue-Systems-via-Few-Shot-Response-Generation-and-Ranking"><a href="#Controllable-Generation-of-Dialogue-Acts-for-Dialogue-Systems-via-Few-Shot-Response-Generation-and-Ranking" class="headerlink" title="Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking"></a>Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14440">http://arxiv.org/abs/2307.14440</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aramir62/da-nlg">https://github.com/aramir62/da-nlg</a></li>
<li>paper_authors: Angela Ramirez, Karik Agarwal, Juraj Juraska, Utkarsh Garg, Marilyn A. Walker</li>
<li>for:  This paper aims to develop a novel few-shot overgenerate-and-rank approach for controlled generation of dialogue acts (DAs).</li>
<li>methods: The proposed approach uses pretrained language models (LLMs) with prompt-based learning, and includes eight few-shot prompt styles and six automatic ranking functions to identify outputs with both correct DA and high semantic accuracy.</li>
<li>results: The approach achieves perfect DA accuracy and near perfect semantic accuracy (99.81%) on three domains and four LLMs, outperforming fine-tuned few-shot models trained with 5 to 100 instances per DA.<details>
<summary>Abstract</summary>
Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from a domain-specific DA and its semantic attributes to an output utterance. Recent work shows that pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning. Here we develop a novel few-shot overgenerate-and-rank approach that achieves the controlled generation of DAs. We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness, we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA. Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.
</details>
<details>
<summary>摘要</summary>
对话系统需要生成具有多种对话行为（DA）的响应，以高度准确的semantic fidelity。在过去，对话自然语言生成器（NLG）通常通过大量并行 corpora 来训练，该 corpora 映射了域pecific DA 和其Semantic attribute 到输出utterance。现在，先进的语言模型（LLM）提供了新的可控制NLG的可能性，使用提示基本学习。在这里，我们开发了一种新的几个shot 过generate-and-rank方法，实现控制的对话行为生成。我们比较了8种几个shot prompt 样式，其中包括一种基于文本 Pseudo-References 的文本风格转移方法。我们开发了6种自动排序函数，以确定生成的输出包含正确的 DA 和高度准确的 Semantic accuracy。我们在三个领域和四个LLM上测试了我们的方法。我们认为这是对对话NLG的自动排序的首次研究。为了完整性，我们与 fine-tuned 几个shot 模型进行比较，后者在 5 到 100 个实例每个 DA 上进行微调。我们的结果表明，一些提示设置可以实现完美的 DA 准确率，以及near perfect Semantic accuracy（99.81%），并且比几个shot micro-tuning 更好。
</details></li>
</ul>
<hr>
<h2 id="Skill-it-A-Data-Driven-Skills-Framework-for-Understanding-and-Training-Language-Models"><a href="#Skill-it-A-Data-Driven-Skills-Framework-for-Understanding-and-Training-Language-Models" class="headerlink" title="Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models"></a>Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14430">http://arxiv.org/abs/2307.14430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mayee F. Chen, Nicholas Roberts, Kush Bhatia, Jue Wang, Ce Zhang, Frederic Sala, Christopher Ré<br>for:  This paper aims to study how to select data to improve the performance of pre-trained large language models (LMs) by understanding the natural order of skills learned by LMs from their training data.methods:  The authors develop a new framework based on the intuition that LMs learn skills in a natural order, and they formalize the notion of a skill and an ordered set of skills in terms of the associated data. They also propose an online data sampling algorithm called Skill-It to efficiently learn multiple skills in a continual pre-training setting and an individual skill in a fine-tuning setting.results:  The authors demonstrate the effectiveness of their framework and algorithm on several datasets, including the LEGO synthetic dataset and the Natural Instructions dataset. On the LEGO dataset, Skill-It obtains 36.5 points higher accuracy than random sampling. On the Natural Instructions dataset, Skill-It reduces the validation loss on the target skill by 13.6% versus training on data associated with the target skill itself. Additionally, they apply their framework on the recent RedPajama dataset to continually pre-train a 3B-parameter LM, achieving higher accuracy on the LM Evaluation Harness with 1B tokens than the baseline approach of sampling uniformly over data sources with 3B tokens.<details>
<summary>Abstract</summary>
The quality of training data impacts the performance of pre-trained large language models (LMs). Given a fixed budget of tokens, we study how to best select data that leads to good downstream model performance across tasks. We develop a new framework based on a simple hypothesis: just as humans acquire interdependent skills in a deliberate order, language models also follow a natural order when learning a set of skills from their training data. If such an order exists, it can be utilized for improved understanding of LMs and for data-efficient training. Using this intuition, our framework formalizes the notion of a skill and of an ordered set of skills in terms of the associated data. First, using both synthetic and real data, we demonstrate that these ordered skill sets exist, and that their existence enables more advanced skills to be learned with less data when we train on their prerequisite skills. Second, using our proposed framework, we introduce an online data sampling algorithm, Skill-It, over mixtures of skills for both continual pre-training and fine-tuning regimes, where the objective is to efficiently learn multiple skills in the former and an individual skill in the latter. On the LEGO synthetic in the continual pre-training setting, Skill-It obtains 36.5 points higher accuracy than random sampling. On the Natural Instructions dataset in the fine-tuning setting, Skill-It reduces the validation loss on the target skill by 13.6% versus training on data associated with the target skill itself. We apply our skills framework on the recent RedPajama dataset to continually pre-train a 3B-parameter LM, achieving higher accuracy on the LM Evaluation Harness with 1B tokens than the baseline approach of sampling uniformly over data sources with 3B tokens.
</details>
<details>
<summary>摘要</summary>
“训练数据质量对预训练大语言模型（LM）的性能产生重要影响。我们研究如何在固定的字符数限制下选择数据，以便在任务间之间尽可能地提高下游模型的性能。我们提出了一个新的框架，基于简单的假设：人类学习语言时也跟随着一定的顺序，然而语言模型在学习训练数据时也会遵循类似的自然顺序。如果这种顺序存在，那么我们可以利用它来更好地理解LM和进行数据效率的训练。使用这种假设，我们将技能和技能集定义为数据的一部分，并提出了一种在线数据采样算法Skill-It，用于在混合技能下进行不断预训练和精度调整。在LEGO sintética上，Skill-It在不断预训练中比随机采样高出36.5个点的精度。在自然指令集上，Skill-It在精度调整中比直接使用目标技能的数据采样下降13.6%。我们在最近的RedPajama数据集上应用我们的技能框架，实现了使用3B参数的LM在LM评估套件上的高精度，比基eline方法（随机采样）在3B字符上的精度高出1B字符。”
</details></li>
</ul>
<hr>
<h2 id="Towards-Generalist-Biomedical-AI"><a href="#Towards-Generalist-Biomedical-AI" class="headerlink" title="Towards Generalist Biomedical AI"></a>Towards Generalist Biomedical AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14334">http://arxiv.org/abs/2307.14334</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kyegomez/Med-PaLM">https://github.com/kyegomez/Med-PaLM</a></li>
<li>paper_authors: Tao Tu, Shekoofeh Azizi, Danny Driess, Mike Schaekermann, Mohamed Amin, Pi-Chuan Chang, Andrew Carroll, Chuck Lau, Ryutaro Tanno, Ira Ktena, Basil Mustafa, Aakanksha Chowdhery, Yun Liu, Simon Kornblith, David Fleet, Philip Mansfield, Sushant Prakash, Renee Wong, Sunny Virmani, Christopher Semturs, S Sara Mahdavi, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Joelle Barral, Dale Webster, Greg S. Corrado, Yossi Matias, Karan Singhal, Pete Florence, Alan Karthikesalingam, Vivek Natarajan</li>
<li>for: 这个论文旨在开发一种涵盖多Modal的生物医学人工智能系统，以便实现从科学发现到医疗提供的各种应用。</li>
<li>methods: 该论文首先创建了MultiMedBench，一个新的多Modal生物医学测试集。然后，他们引入了Med-PaLM Multimodal（Med-PaLM M），一种证明性的生物医学人工智能系统，可以涵盖多Modal的生物医学数据，包括临床语言、成像和 genomics。</li>
<li>results: 该论文的结果表明，Med-PaLM M在MultiMedBench任务中达到了与或超过当前状态的表现，常常超越专家模型。此外，论文还报道了无需训练的零shot泛化和转移学习的情况，以及模型生成的 radiology 报告得到了临床医生的评价。<details>
<summary>Abstract</summary>
Medicine is inherently multimodal, with rich data modalities spanning text, imaging, genomics, and more. Generalist biomedical artificial intelligence (AI) systems that flexibly encode, integrate, and interpret this data at scale can potentially enable impactful applications ranging from scientific discovery to care delivery. To enable the development of these models, we first curate MultiMedBench, a new multimodal biomedical benchmark. MultiMedBench encompasses 14 diverse tasks such as medical question answering, mammography and dermatology image interpretation, radiology report generation and summarization, and genomic variant calling. We then introduce Med-PaLM Multimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI system. Med-PaLM M is a large multimodal generative model that flexibly encodes and interprets biomedical data including clinical language, imaging, and genomics with the same set of model weights. Med-PaLM M reaches performance competitive with or exceeding the state of the art on all MultiMedBench tasks, often surpassing specialist models by a wide margin. We also report examples of zero-shot generalization to novel medical concepts and tasks, positive transfer learning across tasks, and emergent zero-shot medical reasoning. To further probe the capabilities and limitations of Med-PaLM M, we conduct a radiologist evaluation of model-generated (and human) chest X-ray reports and observe encouraging performance across model scales. In a side-by-side ranking on 246 retrospective chest X-rays, clinicians express a pairwise preference for Med-PaLM M reports over those produced by radiologists in up to 40.50% of cases, suggesting potential clinical utility. While considerable work is needed to validate these models in real-world use cases, our results represent a milestone towards the development of generalist biomedical AI systems.
</details>
<details>
<summary>摘要</summary>
医学 inherently 多Modal，具有丰富的数据Modalities，包括文本、影像、基因组和更多。通用医学人工智能（AI）系统，可以在大规模上编码、集成和解释这些数据，有 potential 实现科学发现和诊断等应用。为了实现这些模型的发展，我们首先筹建 MultiMedBench，一个新的多Modal 医学benchmark。MultiMedBench 包括 14 种多Modal 医学任务，如医学问答、肿瘤和皮肤影像解读、放射学报告生成和摘要、基因变异检测等。然后，我们引入 Med-PaLM Multimodal（Med-PaLM M），我们的证明性证明，可以在多Modal 医学数据中灵活编码和解释医学语言、影像和基因组数据，并且使用同一组model weights。Med-PaLM M 在 MultiMedBench 任务中达到了与或超过当前状态的表现，经常超过专家模型，并且在一些任务上表现出透明的优势。我们还报道了零shot泛化到新的医学概念和任务， transferred learning across tasks，以及 emergent zero-shot 医学理解。为了进一步探索 Med-PaLM M 的能力和局限性，我们对模型生成（以及人类）的胸部X射影报告进行了 radiologist 评估，并观察到了模型在不同缩放器 scales 上的鼓舞人的表现。在 246 例退化胸部X射影中，临床医生对 Med-PaLM M 报告表示了对比 radiologists 的可 preference，表明了这些模型的临床可能性。虽然需要进一步的验证，但我们的结果代表了开发通用医学 AI 系统的重要里程碑。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-Libraries-for-the-Sentimental-Analysis"><a href="#Comparative-Analysis-of-Libraries-for-the-Sentimental-Analysis" class="headerlink" title="Comparative Analysis of Libraries for the Sentimental Analysis"></a>Comparative Analysis of Libraries for the Sentimental Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14311">http://arxiv.org/abs/2307.14311</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RAJHARINI-KRISHNASAMY/sentimental-analysis-of-news-feeds">https://github.com/RAJHARINI-KRISHNASAMY/sentimental-analysis-of-news-feeds</a></li>
<li>paper_authors: Wendy Ccoya, Edson Pinto</li>
<li>For: 本研究的主要目标是提供机器学习方法对图书馆进行比较分析。* Methods: 本研究使用了Python和R语言的NLTK、TextBlob、Vader、Transformers（GPT和BERT预训练）和Tidytext等库来实现情感分析技术。同时还使用了四种机器学习模型：DT、SVM、NB和KNN。* Results: 根据实验结果，BERT transformer方法的准确率为0.973，得出的结论是推荐使用BERT transformer方法进行情感分析。<details>
<summary>Abstract</summary>
This study is main goal is to provide a comparative comparison of libraries using machine learning methods. Experts in natural language processing (NLP) are becoming more and more interested in sentiment analysis (SA) of text changes. The objective of employing NLP text analysis techniques is to recognize and categorize feelings related to twitter users utterances. In this examination, issues with SA and the libraries utilized are also looked at. provides a number of cooperative methods to classify emotional polarity. The Naive Bayes Classifier, Decision Tree Classifier, Maxent Classifier, Sklearn Classifier, Sklearn Classifier MultinomialNB, and other conjoint learning algorithms, according to recent research, are very effective. In the project will use Five Python and R libraries NLTK, TextBlob, Vader, Transformers (GPT and BERT pretrained), and Tidytext will be used in the study to apply sentiment analysis techniques. Four machine learning models Tree of Decisions (DT), Support Vector Machine (SVM), Naive Bayes (NB), and K-Nearest Neighbor (KNN) will also be used. To evaluate how well libraries for SA operate in the social network environment, comparative study was also carried out. The measures to assess the best algorithms in this experiment, which used a single data set for each method, were precision, recall, and F1 score. We conclude that the BERT transformer method with an Accuracy: 0.973 is recommended for sentiment analysis.
</details>
<details>
<summary>摘要</summary>
这个研究的主要目标是对使用机器学习方法进行图书馆的比较分析。专家们在自然语言处理（NLP）领域越来越关注图书馆用户言语的情感分析（SA）。通过使用NLP文本分析技术，可以识别和分类图书馆用户言语中的情感偏好。本 исследование还检查了SA和使用的图书馆问题。提供了许多合作方法来分类情感偏好。Naive Bayes Classifier、Decision Tree Classifier、Maxent Classifier、Sknlearn Classifier、Sknlearn Classifier MultinomialNB等 conjunction learning algorithms，据最新研究，很有效。在研究中使用的Python和R库有NLTK、TextBlob、Vader、Transformers（GPT和BERT预训练）和Tidytext等，用于应用情感分析技术。此外， Four machine learning模型：Tree of Decisions（DT）、Support Vector Machine（SVM）、Naive Bayes（NB）和K-Nearest Neighbor（KNN）也将被使用。为了评估图书馆用于SA的库如何在社交网络环境中运行，本研究还进行了比较研究。测试使用的单个数据集的评价标准为精度、恢复率和F1分数。我们得出的结论是，BERT变换器方法，准确率为0.973，是SA的最佳方法。
</details></li>
</ul>
<hr>
<h2 id="Automatically-Evaluating-Opinion-Prevalence-in-Opinion-Summarization"><a href="#Automatically-Evaluating-Opinion-Prevalence-in-Opinion-Summarization" class="headerlink" title="Automatically Evaluating Opinion Prevalence in Opinion Summarization"></a>Automatically Evaluating Opinion Prevalence in Opinion Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14305">http://arxiv.org/abs/2307.14305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Malon</li>
<li>for: 本文主要研究如何自动生成产品评价摘要，以提高对产品评价的汇总和理解。</li>
<li>methods: 本文提出了一种自动测试摘要中意见强度的度量方法，基于对每个摘要句子与每个源评论进行匹配度量。同时，本文考虑了多种现有的方法来评估摘要句子与源评论之间的一致性。</li>
<li>results: 基于一个Amazon产品评论数据集，本文证明了自动生成的摘要具有较低的意见强度，而人工摘要具有较高的意见强度。同时，本文还表明了采用简化源评论后，现有的抽象意见摘要系统可以达到人工性能水平。<details>
<summary>Abstract</summary>
When faced with a large number of product reviews, it is not clear that a human can remember all of them and weight opinions representatively to write a good reference summary. We propose an automatic metric to test the prevalence of the opinions that a summary expresses, based on counting the number of reviews that are consistent with each statement in the summary, while discrediting trivial or redundant statements. To formulate this opinion prevalence metric, we consider several existing methods to score the factual consistency of a summary statement with respect to each individual source review. On a corpus of Amazon product reviews, we gather multiple human judgments of the opinion consistency, to determine which automatic metric best expresses consistency in product reviews. Using the resulting opinion prevalence metric, we show that a human authored summary has only slightly better opinion prevalence than randomly selected extracts from the source reviews, and previous extractive and abstractive unsupervised opinion summarization methods perform worse than humans. We demonstrate room for improvement with a greedy construction of extractive summaries with twice the opinion prevalence achieved by humans. Finally, we show that preprocessing source reviews by simplification can raise the opinion prevalence achieved by existing abstractive opinion summarization systems to the level of human performance.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)面对大量产品评论，人类可能无法记忆所有评论并准确表达其意见，我们提出一种自动度量测试摘要中意见的流行程度，基于对每个摘要声明中的评论数量进行匹配，并且忽略不重要或重复的评论。为了建立这种意见流行度度量，我们考虑了一些现有的评论一致性分数方法，并在亚马逊产品评论集中收集了多个人类意见一致性判断，以确定最佳的自动度量。结果显示，人类撰写的摘要只有轻微更高的意见流行程度，而前期EXTRACTIVE和ABSTRACTIVE无监督意见摘要方法则比人类性能更差。我们还示出了使用拼接法构建EXTRACTIVE摘要，可以 doubles the opinion prevalence achieved by humans。最后，我们显示了对源评论进行简化处理可以提高现有的ABSTRACTIVE意见摘要系统达到人类性能水平。
</details></li>
</ul>
<hr>
<h2 id="Founding-a-mathematical-diffusion-model-in-linguistics-The-case-study-of-German-syntactic-features-in-the-North-Eastern-Italian-dialects"><a href="#Founding-a-mathematical-diffusion-model-in-linguistics-The-case-study-of-German-syntactic-features-in-the-North-Eastern-Italian-dialects" class="headerlink" title="Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects"></a>Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14291">http://arxiv.org/abs/2307.14291</a></li>
<li>repo_url: None</li>
<li>paper_authors: I. Lazzizzera</li>
<li>for: 研究德语特征在意大北部地区罗曼语方言中的传播</li>
<li>methods: 使用地理数据科学工具创建了一个交互式地图，以表示德语特征在当地的分布</li>
<li>results: 研究发现，使用德语特征的地区可以用一个二维函数来表示，并且这个函数可以通过 физи学中的卷积方程来描述，并且这种方法可以准确地预测当地语言的传播情况。此外，研究还发现，Schmidt的波可以被包含在卷积方程中，这可以复制现实语言传播事件中的复杂性。<details>
<summary>Abstract</summary>
We take as a case study the spread of Germanic syntactic features into Romance dialects of North-Eastern Italy, which occurred after the immigration of German people in the Tyrol during the High Middle Ages.   An interactive map is produced using tools of what is called Geographic Data Science. A smooth two-dimensional surface $\mathcal{G}$ expresses locally which fraction of territory uses a given German language feature: it is obtained by interpolating a discrete function that says if at any surveyed locality that feature is used or not.\newline   This surface $\mathcal{G}$ is thought of as the value at the present time of a function describing a diffusion-convection phenomenon in two dimensions (here said \emph{tidal} mode), which is subjected in a very natural way to the same equation, suitably contextualized, used in physics for a number of phenomenological facts like the heat diffusion. It is shown that solutions of this equation, evaluated at the present time, fit well with the data as interpolated by $\mathcal{G}$, thus providing convincing pictures of diffusion-convection of the linguistic features of the case study, albeit simplifications and approximations.\newline   Very importantly, it is shown that Schmidt's 'waves' can be counted among the solutions of the diffusion equation: superimposing Schmidt 'waves' to a 'tidal flooding' can reproduce complexities of real linguistic diffusion events.
</details>
<details>
<summary>摘要</summary>
我们选择德语 sintactic feature 在意大利北东部罗曼语方言的传播为案例研究，该事件发生在中世纪高中期，德国人在提rol中移民。  使用地理数据科学工具生成了一个交互式地图，表示每个地方使用的德语特征的分布情况。这个二维表面 $\mathcal{G}$ 是通过 interpolating 一个粗略函数来获得，该函数在任一调查地点是否使用该语言特征。\newline  这个表面 $\mathcal{G}$ 被视为当前时间的函数值，描述了在二维空间中的扩散-湍流现象（称为“潮汐”模式），该现象遵循同physics中的一些现象，如热扩散。这些解的评估值，评估到当前时间，与实际数据 interpolated by $\mathcal{G}$ 相吻合，提供了语言扩散的诱导图。\newline  很重要的是，Schmidt的“浪”可以被视为扩散方程的解之一：将Schmidt的“浪”与“潮汐涌入”相加可以复制实际语言扩散事件中的复杂性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/27/cs.CL_2023_07_27/" data-id="clogyj8w300817cra602w3l7d" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/64/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/63/">63</a><a class="page-number" href="/page/64/">64</a><span class="page-number current">65</span><a class="page-number" href="/page/66/">66</a><a class="page-number" href="/page/67/">67</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/66/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
