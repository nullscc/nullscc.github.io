
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/60/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CL_2023_08_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/13/cs.CL_2023_08_13/" class="article-date">
  <time datetime="2023-08-13T11:00:00.000Z" itemprop="datePublished">2023-08-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/13/cs.CL_2023_08_13/">cs.CL - 2023-08-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Faithful-to-Whom-Questioning-Interpretability-Measures-in-NLP"><a href="#Faithful-to-Whom-Questioning-Interpretability-Measures-in-NLP" class="headerlink" title="Faithful to Whom? Questioning Interpretability Measures in NLP"></a>Faithful to Whom? Questioning Interpretability Measures in NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06795">http://arxiv.org/abs/2308.06795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evan Crothers, Herna Viktor, Nathalie Japkowicz</li>
<li>for: 这 paper 的目的是探讨现有的 faithfulness metrics 是否适用于比较不同的神经网络文本分类器的解释性。</li>
<li>methods: 作者使用 iterative masking 方法测试 faithfulness metrics，并发现这些度量在不同的模型之间存在很大的变化。</li>
<li>results: 作者发现 masked samples frequently 外部训练数据分布，并且 iterative masking 可能导致 faithfulness scores 的巨大变化。 另外，作者还研究了对 faithfulness scores 的影响，包括 adversarial attacks 和 adversarial training。<details>
<summary>Abstract</summary>
A common approach to quantifying model interpretability is to calculate faithfulness metrics based on iteratively masking input tokens and measuring how much the predicted label changes as a result. However, we show that such metrics are generally not suitable for comparing the interpretability of different neural text classifiers as the response to masked inputs is highly model-specific. We demonstrate that iterative masking can produce large variation in faithfulness scores between comparable models, and show that masked samples are frequently outside the distribution seen during training. We further investigate the impact of adversarial attacks and adversarial training on faithfulness scores, and demonstrate the relevance of faithfulness measures for analyzing feature salience in text adversarial attacks. Our findings provide new insights into the limitations of current faithfulness metrics and key considerations to utilize them appropriately.
</details>
<details>
<summary>摘要</summary>
一种常见的方法量化模型解释性是通过 iteratively masking input token 并测量预测标签变化的方式来计算 faithfulness 度量。然而，我们显示这些度量不适合比较不同的神经网络文本分类器的解释性，因为模型具有很高的特定性。我们示出了 iterative 遮盖可能会导致大量的 faithfulness 分数变化，并且遮盖样本通常不在训练时间段内。我们进一步研究了对 faithfulness 度量的影响和对文本对抗攻击的分析，并证明了 faithfulness 度量的重要性。我们的发现提供了新的理解现有 faithfulness 度量的限制和使其正确使用的关键考虑因素。
</details></li>
</ul>
<hr>
<h2 id="Modeling-the-Dashboard-Provenance"><a href="#Modeling-the-Dashboard-Provenance" class="headerlink" title="Modeling the Dashboard Provenance"></a>Modeling the Dashboard Provenance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06788">http://arxiv.org/abs/2308.06788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johne Jarske, Jorge Rady, Lucia V. L. Filgueiras, Leandro M. Velloso, Tania L. Santos</li>
<li>For: The paper aims to provide a provenance representation model for dashboards and its visual and data components, which can help organizations evaluate the quality, consistency, and reliability of the information presented on dashboards.* Methods: The proposed model will offer a comprehensive set of essential provenance metadata that enables users to evaluate the context in which a specific dashboard was developed, including information about people, organizations, entities, and activities involved in the production, influence, or delivery of the data or object.* Results: The paper aims to provide a standardized and visualized representation of provenance metadata for dashboards, which can help users make better decisions based on the quality and reliability of the information presented.<details>
<summary>Abstract</summary>
Organizations of all kinds, whether public or private, profit-driven or non-profit, and across various industries and sectors, rely on dashboards for effective data visualization. However, the reliability and efficacy of these dashboards rely on the quality of the visual and data they present. Studies show that less than a quarter of dashboards provide information about their sources, which is just one of the expected metadata when provenance is seriously considered. Provenance is a record that describes people, organizations, entities, and activities that had a role in the production, influence, or delivery of a piece of data or an object. This paper aims to provide a provenance representation model, that entitles standardization, modeling, generation, capture, and visualization, specifically designed for dashboards and its visual and data components. The proposed model will offer a comprehensive set of essential provenance metadata that enables users to evaluate the quality, consistency, and reliability of the information presented on dashboards. This will allow a clear and precise understanding of the context in which a specific dashboard was developed, ultimately leading to better decision-making.
</details>
<details>
<summary>摘要</summary>
Provenance is a record that describes people, organizations, entities, and activities that had a role in the production, influence, or delivery of a piece of data or an object. This paper aims to provide a provenance representation model, that entitles standardization, modeling, generation, capture, and visualization, specifically designed for dashboards and its visual and data components. The proposed model will offer a comprehensive set of essential provenance metadata that enables users to evaluate the quality, consistency, and reliability of the information presented on dashboards. This will allow a clear and precise understanding of the context in which a specific dashboard was developed, ultimately leading to better decision-making.
</details></li>
</ul>
<hr>
<h2 id="Token-Scaled-Logit-Distillation-for-Ternary-Weight-Generative-Language-Models"><a href="#Token-Scaled-Logit-Distillation-for-Ternary-Weight-Generative-Language-Models" class="headerlink" title="Token-Scaled Logit Distillation for Ternary Weight Generative Language Models"></a>Token-Scaled Logit Distillation for Ternary Weight Generative Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06744">http://arxiv.org/abs/2308.06744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsoo Kim, Sihwa Lee, Janghwan Lee, Sukjin Hong, Du-Seong Chang, Wonyong Sung, Jungwook Choi</li>
<li>for: 这个研究是为了解决生成模型在实际应用中的大型模型问题。</li>
<li>methods: 这个研究使用了量化测试敏感训练（QAT）方法，并提出了一个专门适用于生成模型的知识传递法。</li>
<li>results: 这个研究获得了较少于1.0倍的衰落和无损失的推理任务结果，表明了这个方法的成功。<details>
<summary>Abstract</summary>
Generative Language Models (GLMs) have shown impressive performance in tasks such as text generation, understanding, and reasoning. However, the large model size poses challenges for practical deployment. To solve this problem, Quantization-Aware Training (QAT) has become increasingly popular. However, current QAT methods for generative models have resulted in a noticeable loss of accuracy. To counteract this issue, we propose a novel knowledge distillation method specifically designed for GLMs. Our method, called token-scaled logit distillation, prevents overfitting and provides superior learning from the teacher model and ground truth. This research marks the first evaluation of ternary weight quantization-aware training of large-scale GLMs with less than 1.0 degradation in perplexity and no loss of accuracy in a reasoning task.
</details>
<details>
<summary>摘要</summary>
生成语言模型（GLM）在文本生成、理解和推理等任务中表现出色，但模型大小带来实际部署的挑战。为解决这个问题，量化意识训练（QAT）在生成模型中变得越来越流行。然而，现有的QAT方法对生成模型带来明显的精度损失。为此，我们提出了一种特有的知识储存方法，称为Token扩展LOGIT储存。该方法防止过拟合，并从教师模型和真实数据中提取优质知识。这项研究标志着大规模GLM的三进制重量量化意识训练的首次评估，并达到了低于1.0的质量下降和无损失的理解任务准确率。
</details></li>
</ul>
<hr>
<h2 id="Emergent-communication-for-AR"><a href="#Emergent-communication-for-AR" class="headerlink" title="Emergent communication for AR"></a>Emergent communication for AR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07342">http://arxiv.org/abs/2308.07342</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruxiao Chen, Shuaishuai Guo</li>
<li>for: 这篇论文旨在提出一种用于Mobile Augmented Reality（MAR）的 emergent semantic communication 框架，以便在 MAR 中提高通信效率。</li>
<li>methods: 作者使用了两个代理人通过修改了 Lewis 信号游戏进行训练，以便自动生成一种简短的通信协议。</li>
<li>results: 实验表明，提出的方案在不可见对象上具有更好的泛化性，并且可以通过使用小型消息来提高通信效率。<details>
<summary>Abstract</summary>
Mobile augmented reality (MAR) is widely acknowledged as one of the ubiquitous interfaces to the digital twin and Metaverse, demanding unparalleled levels of latency, computational power, and energy efficiency. The existing solutions for realizing MAR combine multiple technologies like edge, cloud computing, and fifth-generation (5G) networks. However, the inherent communication latency of visual data imposes apparent limitations on the quality of experience (QoE). To address the challenge, we propose an emergent semantic communication framework to learn the communication protocols in MAR. Specifically, we train two agents through a modified Lewis signaling game to emerge a discrete communication protocol spontaneously. Based on this protocol, two agents can communicate about the abstract idea of visual data through messages with extremely small data sizes in a noisy channel, which leads to message errors. To better simulate real-world scenarios, we incorporate channel uncertainty into our training process. Experiments have shown that the proposed scheme has better generalization on unseen objects than traditional object recognition used in MAR and can effectively enhance communication efficiency through the utilization of small-size messages.
</details>
<details>
<summary>摘要</summary>
移动增强现实（MAR）被广泛承认为数字双胞迷和Metaverse的一种普遍的界面，需要无 précédent 的延迟、计算能力和能效率。现有的 MAR 实现方案 combining 多种技术，如边缘计算、云计算和 fifth-generation（5G）网络。然而，视觉数据的自然通信延迟带来明显的用户体验质量（QoE）限制。为 Addressing 这个挑战，我们提出了一种emergent semantic communication框架，用于在 MAR 中学习通信协议。具体来说，我们通过 modify 了 Lewis 信号游戏来训练两个代理人，从而自然地生成一个精简的通信协议。根据这个协议，两个代理人可以通过 messages  WITH  extremely small data sizes 在噪音频道中交换信息，这会导致消息错误。为更好地模拟实际情况，我们将频率uncertainty  incorporated 到我们的训练过程中。实验结果表明，我们的方案在未看到对象时比传统 MAR 中使用的对象识别更好地 generalization ，并可以通过利用小型消息来提高通信效率。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/13/cs.CL_2023_08_13/" data-id="cloq1wl2b009e7o88awwe8b3x" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/13/cs.LG_2023_08_13/" class="article-date">
  <time datetime="2023-08-13T10:00:00.000Z" itemprop="datePublished">2023-08-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/13/cs.LG_2023_08_13/">cs.LG - 2023-08-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Faithful-to-Whom-Questioning-Interpretability-Measures-in-NLP"><a href="#Faithful-to-Whom-Questioning-Interpretability-Measures-in-NLP" class="headerlink" title="Faithful to Whom? Questioning Interpretability Measures in NLP"></a>Faithful to Whom? Questioning Interpretability Measures in NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06795">http://arxiv.org/abs/2308.06795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evan Crothers, Herna Viktor, Nathalie Japkowicz</li>
<li>for: 这 paper 是为了评估不同神经网络文本分类器的解释性而写的。</li>
<li>methods: 这 paper 使用了基于层次遮盖的 faithfulness 度量来评估模型的解释性，并证明了这些度量不适合比较不同模型的解释性。</li>
<li>results: 研究发现，基于层次遮盖的 faithfulness 度量在不同模型之间可能会带来很大的差异，而且遮盖样本经常处于训练期间所未见 Distribution 之外。<details>
<summary>Abstract</summary>
A common approach to quantifying model interpretability is to calculate faithfulness metrics based on iteratively masking input tokens and measuring how much the predicted label changes as a result. However, we show that such metrics are generally not suitable for comparing the interpretability of different neural text classifiers as the response to masked inputs is highly model-specific. We demonstrate that iterative masking can produce large variation in faithfulness scores between comparable models, and show that masked samples are frequently outside the distribution seen during training. We further investigate the impact of adversarial attacks and adversarial training on faithfulness scores, and demonstrate the relevance of faithfulness measures for analyzing feature salience in text adversarial attacks. Our findings provide new insights into the limitations of current faithfulness metrics and key considerations to utilize them appropriately.
</details>
<details>
<summary>摘要</summary>
一种常见的方法量化模型解释性是通过逐渐遮盖输入符号来计算输出标签变化的程度。然而，我们显示这些度量不适合比较不同的神经网络文本分类器的解释性，因为遮盖输入的响应是高度模型特定的。我们示出了遮盖样本会导致大量的 faithfulness 分数变化，并且显示遮盖样本 frequently 外部训练数据分布。我们进一步调查了对抗攻击和对抗训练对 faithfulness 度量的影响，并证明了 faithfulness 度量对文本对抗攻击中的特征突出性进行分析具有重要意义。我们的发现为现有的 faithfulness 度量带来新的理解和使用其应用中的关键考虑因素。
</details></li>
</ul>
<hr>
<h2 id="Neural-Networks-at-a-Fraction-with-Pruned-Quaternions"><a href="#Neural-Networks-at-a-Fraction-with-Pruned-Quaternions" class="headerlink" title="Neural Networks at a Fraction with Pruned Quaternions"></a>Neural Networks at a Fraction with Pruned Quaternions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06780">http://arxiv.org/abs/2308.06780</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smlab-niser/quartLT22">https://github.com/smlab-niser/quartLT22</a></li>
<li>paper_authors: Sahel Mohammad Iqbal, Subhankar Mishra</li>
<li>for: 这个研究旨在测试在极端资源受限的环境中，使用简单的神经网络来进行预测。</li>
<li>methods: 研究使用删减来简化神经网络中的参数数量，并使用高维数据嵌入来维持预测精度。</li>
<li>results: 研究发现，在某些架构和 dataset 上，删减后的数值网络可以超过相同架构的实际网络。例如，在 CIFAR-10 上使用 Conv-4 架构时，删减后的数值网络在 $3%$ 的参数数量下，可以比实际网络高于 $10%$。<details>
<summary>Abstract</summary>
Contemporary state-of-the-art neural networks have increasingly large numbers of parameters, which prevents their deployment on devices with limited computational power. Pruning is one technique to remove unnecessary weights and reduce resource requirements for training and inference. In addition, for ML tasks where the input data is multi-dimensional, using higher-dimensional data embeddings such as complex numbers or quaternions has been shown to reduce the parameter count while maintaining accuracy. In this work, we conduct pruning on real and quaternion-valued implementations of different architectures on classification tasks. We find that for some architectures, at very high sparsity levels, quaternion models provide higher accuracies than their real counterparts. For example, at the task of image classification on CIFAR-10 using Conv-4, at $3\%$ of the number of parameters as the original model, the pruned quaternion version outperforms the pruned real by more than $10\%$. Experiments on various network architectures and datasets show that for deployment in extremely resource-constrained environments, a sparse quaternion network might be a better candidate than a real sparse model of similar architecture.
</details>
<details>
<summary>摘要</summary>
当代最先进的神经网络具有越来越多的参数，这限制了它们在计算能力有限的设备上进行训练和推理的可行性。剪枝是一种技术，可以从神经网络中移除不必要的权重，以降低训练和推理的资源需求。此外，在多维输入数据的机器学习任务中，使用高维数域嵌入，如复数或四元数，可以降低参数数量而保持准确性。在这项工作中，我们对实际值和四元数值实现的不同架构进行剪枝处理，并发现在某些架构上，难以架构的四元数模型在高度精简率下提供更高的准确性。例如，在使用Conv-4架构进行图像分类任务时，采用了$3\%$的参数数量的剪枝后，四元数模型的准确性高于实际值模型的准确性超过$10\%$。经过了不同的网络架构和数据集的实验，我们发现在极其有限的资源环境中，一个稀疏的四元数网络可能比同类架构的实际稀疏模型更适合进行部署。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Deep-Neural-Network-Pruning-Taxonomy-Comparison-Analysis-and-Recommendations"><a href="#A-Survey-on-Deep-Neural-Network-Pruning-Taxonomy-Comparison-Analysis-and-Recommendations" class="headerlink" title="A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations"></a>A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06767">http://arxiv.org/abs/2308.06767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hrcheng1066/awesome-pruning">https://github.com/hrcheng1066/awesome-pruning</a></li>
<li>paper_authors: Hongrong Cheng, Miao Zhang, Javen Qinfeng Shi</li>
<li>for: 本文提供了现代深度神经网络压缩的综述，尤其是最新的大型语言模型，以及压缩方法的批判和评价。</li>
<li>methods: 本文分类了现有的压缩研究工作，包括一般&#x2F;特定加速、压缩时机、压缩方法和压缩与其他压缩技术的融合。</li>
<li>results: 本文提供了七对对比设定的深度神经网络压缩的比较分析，并探讨了emerging topics such as post-training pruning, different levels of supervision for pruning, and broader applications。<details>
<summary>Abstract</summary>
Modern deep neural networks, particularly recent large language models, come with massive model sizes that require significant computational and storage resources. To enable the deployment of modern models on resource-constrained environments and accelerate inference time, researchers have increasingly explored pruning techniques as a popular research direction in neural network compression. However, there is a dearth of up-to-date comprehensive review papers on pruning. To address this issue, in this survey, we provide a comprehensive review of existing research works on deep neural network pruning in a taxonomy of 1) universal/specific speedup, 2) when to prune, 3) how to prune, and 4) fusion of pruning and other compression techniques. We then provide a thorough comparative analysis of seven pairs of contrast settings for pruning (e.g., unstructured/structured) and explore emerging topics, including post-training pruning, different levels of supervision for pruning, and broader applications (e.g., adversarial robustness) to shed light on the commonalities and differences of existing methods and lay the foundation for further method development. To facilitate future research, we build a curated collection of datasets, networks, and evaluations on different applications. Finally, we provide some valuable recommendations on selecting pruning methods and prospect promising research directions. We build a repository at https://github.com/hrcheng1066/awesome-pruning.
</details>
<details>
<summary>摘要</summary>
现代深度神经网络，特别是最近的大型语言模型，具有庞大的计算和存储资源需求。为实现资源约束环境中部署现代模型和加速推理时间，研究人员开始了压缩神经网络的研究，成为现代神经网络压缩的流行研究方向。然而，当前存在相对落后的压缩研究报告。为解决这问题，在这篇评论中，我们提供了一个包括1)通用/特定速度、2)何时压缩、3)如何压缩和4)压缩与其他压缩技术融合的taxonomy的全面评论。然后，我们对7对对比设定进行了综合分析（例如，无结构/结构），并探讨了emerging topics（例如，后处理压缩、不同级别的监督压缩和更广泛的应用，例如对抗攻击），以抛光现有方法的相似性和差异，并为未来的研究提供了基础。为便于未来的研究，我们创建了一个 curaated 的数据集、网络和评估集。最后，我们提供了一些有价值的建议，包括选择压缩方法和前景探索的可能性，以及未来研究的可能性。我们在 <https://github.com/hrcheng1066/awesome-pruning> 上建立了一个存储库。
</details></li>
</ul>
<hr>
<h2 id="Conic-Descent-Redux-for-Memory-Efficient-Optimization"><a href="#Conic-Descent-Redux-for-Memory-Efficient-Optimization" class="headerlink" title="Conic Descent Redux for Memory-Efficient Optimization"></a>Conic Descent Redux for Memory-Efficient Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07343">http://arxiv.org/abs/2308.07343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingcong Li, Georgios B. Giannakis</li>
<li>for: 本研究探讨了一种最近发展的首项凹降（CD）解决方案，并在三个方面进行了改进：intuition、理论和算法实现。</li>
<li>methods: 本研究发现CD可以提供一种直观的几何 derivation，来自对准题的 dual 问题。这开启了新的算法设计的门户，其中一个是旋转 variant of CD（MOCO）的示例。透过分析 CD 和 MOCO 的双重行为，发现：i) 可以分析性地确定停止标准；ii) 可以设计预conditioners 以加速双方的准确。</li>
<li>results: 最后，本研究开发了一种内存效率高的 MOCO 变体，用于扩展 SDP 特别是低级解。numerical validation 表明，这种变体可以快速和精准地解决 SDP 问题。<details>
<summary>Abstract</summary>
Conic programming has well-documented merits in a gamut of signal processing and machine learning tasks. This contribution revisits a recently developed first-order conic descent (CD) solver, and advances it in three aspects: intuition, theory, and algorithmic implementation. It is found that CD can afford an intuitive geometric derivation that originates from the dual problem. This opens the door to novel algorithmic designs, with a momentum variant of CD, momentum conic descent (MOCO) exemplified. Diving deeper into the dual behavior CD and MOCO reveals: i) an analytically justified stopping criterion; and, ii) the potential to design preconditioners to speed up dual convergence. Lastly, to scale semidefinite programming (SDP) especially for low-rank solutions, a memory efficient MOCO variant is developed and numerically validated.
</details>
<details>
<summary>摘要</summary>
带形编程在信号处理和机器学习任务中有良好的记录。这篇论文探讨了最近开发的首项对数算法（CD）解决方案，并在三个方面提高：直观、理论和算法实现。发现CD可以提供直观的几何 derivation，这开启了新的算法设计的门户，例如帕摩散度降低（MOCO）。透过对CD和MOCO的分析，发现：一、分析正确的停止标准；二、设计加速对偶速度的预处理器。最后，为了扩大低级解的SDP，我们开发了内存有效的MOCO变体，并在数值上验证了其正确性。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Class-incremental-Learning-A-Survey"><a href="#Few-shot-Class-incremental-Learning-A-Survey" class="headerlink" title="Few-shot Class-incremental Learning: A Survey"></a>Few-shot Class-incremental Learning: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06764">http://arxiv.org/abs/2308.06764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinghua Zhang, Li Liu, Olli Silven, Matti Pietikäinen, Dewen Hu</li>
<li>for: 本文提供了一个系统性的和深入的简要评论，涵盖了多类增量学习（Few-shot Class-Incremental Learning，FSCIL）领域的各种方面，包括问题定义、基本挑战、一般方案、相关逻辑和评价指标等。</li>
<li>methods: 本文总结了FSCIL中的一些常见方法，包括基于数据、基于结构和优化基的方法，以及对象检测方法的各种改进方法，如 anchor-free 和 anchor-based 方法。</li>
<li>results: 本文提供了一些在FSCIL领域的研究方向，包括数据-based、结构-based 和优化-based 方法，以及一些需要进一步探索的研究方向。<details>
<summary>Abstract</summary>
Few-shot Class-Incremental Learning (FSCIL) presents a unique challenge in machine learning, as it necessitates the continuous learning of new classes from sparse labeled training samples without forgetting previous knowledge. While this field has seen recent progress, it remains an active area of exploration. This paper aims to provide a comprehensive and systematic review of FSCIL. In our in-depth examination, we delve into various facets of FSCIL, encompassing the problem definition, the discussion of primary challenges of unreliable empirical risk minimization and the stability-plasticity dilemma, general schemes, and relevant problems of incremental learning and few-shot learning. Besides, we offer an overview of benchmark datasets and evaluation metrics. Furthermore, we introduce the classification methods in FSCIL from data-based, structure-based, and optimization-based approaches and the object detection methods in FSCIL from anchor-free and anchor-based approaches. Beyond these, we illuminate several promising research directions within FSCIL that merit further investigation.
</details>
<details>
<summary>摘要</summary>
《几个示例学习（Few-shot Class-Incremental Learning，FSCIL）》是机器学习领域中的一个独特挑战，它需要在缺乏标注训练样本的情况下，不断学习新的类型，而不会忘记之前的知识。尽管这一领域在最近几年内已经取得了一些进展，但仍然是一个活跃的探索领域。本文的目标是提供一个全面和系统的FSCIL评审，包括问题定义、主要挑战的不可靠的实际风险最小化和稳定性-柔软性之间的矛盾、通用方案和相关的增量学习和几个示例学习的问题。此外，我们还介绍了评价指标和标准测试集。进而，我们介绍了FSCIL中的分类方法，包括数据基于、结构基于和优化基于的方法，以及对象检测方法，包括无锚和锚基的方法。此外，我们还逐光了一些在FSCIL中的有前途的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Discovering-the-Symptom-Patterns-of-COVID-19-from-Recovered-and-Deceased-Patients-Using-Apriori-Association-Rule-Mining"><a href="#Discovering-the-Symptom-Patterns-of-COVID-19-from-Recovered-and-Deceased-Patients-Using-Apriori-Association-Rule-Mining" class="headerlink" title="Discovering the Symptom Patterns of COVID-19 from Recovered and Deceased Patients Using Apriori Association Rule Mining"></a>Discovering the Symptom Patterns of COVID-19 from Recovered and Deceased Patients Using Apriori Association Rule Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06763">http://arxiv.org/abs/2308.06763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Dehghani, Zahra Yazdanparast, Mobin Mohammadi</li>
<li>for: 该研究用于挖掘COVID-19患者的症状模式，以帮助临床医生更好地诊断和治疗疾病。</li>
<li>methods: 该研究使用了Apriori算法进行协会规则挖掘，从COVID-19患者的临床数据中挖掘出最常见的症状。</li>
<li>results: 研究结果显示，COVID-19患者最常见的症状包括呼吸停止（72%）、咳嗽（64%）、发热（59%）、衰弱（18%）、肌肉疼痛（14.5%）和喉咙痛（12%）。<details>
<summary>Abstract</summary>
The COVID-19 pandemic has a devastating impact globally, claiming millions of lives and causing significant social and economic disruptions. In order to optimize decision-making and allocate limited resources, it is essential to identify COVID-19 symptoms and determine the severity of each case. Machine learning algorithms offer a potent tool in the medical field, particularly in mining clinical datasets for useful information and guiding scientific decisions. Association rule mining is a machine learning technique for extracting hidden patterns from data. This paper presents an application of association rule mining based Apriori algorithm to discover symptom patterns from COVID-19 patients. The study, using 2875 records of patient, identified the most common symptoms as apnea (72%), cough (64%), fever (59%), weakness (18%), myalgia (14.5%), and sore throat (12%). The proposed method provides clinicians with valuable insight into disease that can assist them in managing and treating it effectively.
</details>
<details>
<summary>摘要</summary>
COVID-19 流行病在全球产生了毁灭性的影响，让数百万人丧生，引起了重大的社会和经济干扰。为了优化决策和分配有限的资源，必须识别 COVID-19 症状并评估每个病例的严重程度。机器学习算法在医疗领域中提供了一个强大的工具，特别是在挖掘医疗数据中找到有用信息和导引科学决策。在这篇文章中，我们使用 Apriori 算法进行协会规则挖掘，以找到 COVID-19 患者的症状模式。研究使用了 2875 份病例数据，发现最常见的症状包括呼吸抑制（72%）、咳嗽（64%）、高烧（59%）、衰弱（18%）、肌痛（14.5%）和喉咙痛（12%）。我们的方法可以帮助医生更好地理解这种疾病，从而更有效地诊治和治疗。
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-Multi-Agent-Reinforcement-Learning-via-Mirror-Descent-Policy-Optimization"><a href="#Heterogeneous-Multi-Agent-Reinforcement-Learning-via-Mirror-Descent-Policy-Optimization" class="headerlink" title="Heterogeneous Multi-Agent Reinforcement Learning via Mirror Descent Policy Optimization"></a>Heterogeneous Multi-Agent Reinforcement Learning via Mirror Descent Policy Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06741">http://arxiv.org/abs/2308.06741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Mehdi Nasiri, Mansoor Rezghi</li>
<li>for: 这个研究旨在解决多智能机器人学习（Multi-Agent Reinforcement Learning，MARL）中参与者的不同能力和个人策略问题。</li>
<li>methods: 提案的Heterogeneous-Agent Mirror Descent Policy Optimization（HAMDPO）算法利用多智能机器人优势分解定理来实现每个代理策略的有效更新，并确保总性表现提高。HAMDPO通过迭代更新代理策略的近似解决信任区域问题，以确保稳定性和表现改善。</li>
<li>results: 在Multi-Agent MuJoCo和StarCraftII任务中，HAMDPO比state-of-the-art算法HATRPO和HAPPO表现出色，实现了稳定性和表现提高。这些结果显示HAMDPO是解决合作MARL问题的有望方法，可能会扩展到其他MARL领域中的挑战性问题。<details>
<summary>Abstract</summary>
This paper presents an extension of the Mirror Descent method to overcome challenges in cooperative Multi-Agent Reinforcement Learning (MARL) settings, where agents have varying abilities and individual policies. The proposed Heterogeneous-Agent Mirror Descent Policy Optimization (HAMDPO) algorithm utilizes the multi-agent advantage decomposition lemma to enable efficient policy updates for each agent while ensuring overall performance improvements. By iteratively updating agent policies through an approximate solution of the trust-region problem, HAMDPO guarantees stability and improves performance. Moreover, the HAMDPO algorithm is capable of handling both continuous and discrete action spaces for heterogeneous agents in various MARL problems. We evaluate HAMDPO on Multi-Agent MuJoCo and StarCraftII tasks, demonstrating its superiority over state-of-the-art algorithms such as HATRPO and HAPPO. These results suggest that HAMDPO is a promising approach for solving cooperative MARL problems and could potentially be extended to address other challenging problems in the field of MARL.
</details>
<details>
<summary>摘要</summary>
The HAMDPO algorithm uses the multi-agent advantage decomposition lemma to efficiently update agent policies while ensuring overall performance improvements. The algorithm iteratively updates agent policies through an approximate solution of the trust-region problem, which guarantees stability and improves performance.HAMDPO is capable of handling both continuous and discrete action spaces for heterogeneous agents in various MARL problems. The authors evaluate the algorithm on Multi-Agent MuJoCo and StarCraftII tasks and show that it outperforms state-of-the-art algorithms such as HATRPO and HAPPO. These results suggest that HAMDPO is a promising approach for solving cooperative MARL problems and could potentially be extended to address other challenging problems in the field of MARL.
</details></li>
</ul>
<hr>
<h2 id="Weighted-Sparse-Partial-Least-Squares-for-Joint-Sample-and-Feature-Selection"><a href="#Weighted-Sparse-Partial-Least-Squares-for-Joint-Sample-and-Feature-Selection" class="headerlink" title="Weighted Sparse Partial Least Squares for Joint Sample and Feature Selection"></a>Weighted Sparse Partial Least Squares for Joint Sample and Feature Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06740">http://arxiv.org/abs/2308.06740</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenwenmin/wspls">https://github.com/wenwenmin/wspls</a></li>
<li>paper_authors: Wenwen Min, Taosheng Xu, Chris Ding</li>
<li>for: 这种研究旨在扩展sPLS的应用范围，通过特定subset of samples和减少异常值来检测稀疏的数据集。</li>
<li>methods: 该研究提出了一种$\ell_\infty&#x2F;\ell_0$-norm压缩权重稀疏PLS（wsPLS）方法，通过$\ell_\infty&#x2F;\ell_0$-norm压缩来选择一个subset of samples，并使用多视图数据可以处理多个数据集。</li>
<li>results: 研究人员通过数值和生物医学数据实验表明，提出的方法可以减少数据维度，提高数据融合的稳定性和准确性。<details>
<summary>Abstract</summary>
Sparse Partial Least Squares (sPLS) is a common dimensionality reduction technique for data fusion, which projects data samples from two views by seeking linear combinations with a small number of variables with the maximum variance. However, sPLS extracts the combinations between two data sets with all data samples so that it cannot detect latent subsets of samples. To extend the application of sPLS by identifying a specific subset of samples and remove outliers, we propose an $\ell_\infty/\ell_0$-norm constrained weighted sparse PLS ($\ell_\infty/\ell_0$-wsPLS) method for joint sample and feature selection, where the $\ell_\infty/\ell_0$-norm constrains are used to select a subset of samples. We prove that the $\ell_\infty/\ell_0$-norm constrains have the Kurdyka-\L{ojasiewicz}~property so that a globally convergent algorithm is developed to solve it. Moreover, multi-view data with a same set of samples can be available in various real problems. To this end, we extend the $\ell_\infty/\ell_0$-wsPLS model and propose two multi-view wsPLS models for multi-view data fusion. We develop an efficient iterative algorithm for each multi-view wsPLS model and show its convergence property. As well as numerical and biomedical data experiments demonstrate the efficiency of the proposed methods.
</details>
<details>
<summary>摘要</summary>
“罕缺部分最小方差（sPLS）是一种常见的维度减少技术，用于数据融合，它通过寻找两个视图中数据样本的线性组合，以实现最大差异。然而，sPLS不能检测隐藏的样本集。为了扩展sPLS的应用，我们提出了一种$\ell_\infty/\ell_0$-norm受限的重量 sparse PLS（$\ell_\infty/\ell_0$-wsPLS）方法，用于联合样本和特征选择。我们证明了$\ell_\infty/\ell_0$-norm受限有 Kurdyka-\L{ojasiewicz} 性质，因此可以开发一个全球收敛的算法来解决它。此外，多视图数据中的样本可能是同一个集合的。为此，我们扩展了$\ell_\infty/\ell_0$-wsPLS模型，并提出了两种多视图wsPLS模型 для多视图数据融合。我们开发了一个高效的迭代算法，并证明其收敛性。数值和生物医学数据实验 demonstrate了我们提出的方法的效率。”Note: Simplified Chinese is a written form of Chinese that uses simpler characters and grammar than Traditional Chinese. It is commonly used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Imputation-for-Time-series-Classification-with-Missing-Data"><a href="#Probabilistic-Imputation-for-Time-series-Classification-with-Missing-Data" class="headerlink" title="Probabilistic Imputation for Time-series Classification with Missing Data"></a>Probabilistic Imputation for Time-series Classification with Missing Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06738">http://arxiv.org/abs/2308.06738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuneg11/SupNotMIWAE-with-ObsDropout">https://github.com/yuneg11/SupNotMIWAE-with-ObsDropout</a></li>
<li>paper_authors: SeungHyun Kim, Hyunsu Kim, EungGu Yun, Hwangrae Lee, Jaehun Lee, Juho Lee</li>
<li>for: 这个论文主要是为了解决多重时间序列资料中的缺失价值问题。</li>
<li>methods: 我们提出了一个新的机会统计学 frameworks，它包括两个部分：一个深度生成模型来填写缺失价值，以及一个分类器。我们将深度生成模型扩展到更好地捕捉时间序列资料的结构，并将分类器训练为将时间序列资料与填写的缺失价值分类。</li>
<li>results: 我们通过实际实验表明，我们的方法可以有效地解决多重时间序列资料中的缺失价值问题，并且可以提供更好的预测结果。<details>
<summary>Abstract</summary>
Multivariate time series data for real-world applications typically contain a significant amount of missing values. The dominant approach for classification with such missing values is to impute them heuristically with specific values (zero, mean, values of adjacent time-steps) or learnable parameters. However, these simple strategies do not take the data generative process into account, and more importantly, do not effectively capture the uncertainty in prediction due to the multiple possibilities for the missing values. In this paper, we propose a novel probabilistic framework for classification with multivariate time series data with missing values. Our model consists of two parts; a deep generative model for missing value imputation and a classifier. Extending the existing deep generative models to better capture structures of time-series data, our deep generative model part is trained to impute the missing values in multiple plausible ways, effectively modeling the uncertainty of the imputation. The classifier part takes the time series data along with the imputed missing values and classifies signals, and is trained to capture the predictive uncertainty due to the multiple possibilities of imputations. Importantly, we show that na\"ively combining the generative model and the classifier could result in trivial solutions where the generative model does not produce meaningful imputations. To resolve this, we present a novel regularization technique that can promote the model to produce useful imputation values that help classification. Through extensive experiments on real-world time series data with missing values, we demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
多变量时间序列数据在实际应用中通常含有大量缺失值。现有的主流方法为这种缺失值是轮廓性地填充它们（零、平均值、邻近时间步颗度）或学习参数。然而，这些简单策略并不考虑数据生成过程，更重要的是，它们不能有效捕捉预测中的不确定性，因为缺失值的多种可能性。在这篇论文中，我们提出了一种新的概率 Framework for classification with multivariate time series data containing missing values.我们的模型包括两部分：深度生成模型和分类器。我们对深度生成模型进行了扩展，以更好地捕捉时间序列数据的结构，并训练它们以生成多种可能的缺失值，以模拟缺失值的uncertainty。分类器部分接受了时间序列数据以及填充后的缺失值，并分类信号，并训练它们以捕捉多种缺失值的预测不确定性。然而，我们发现，直接组合生成模型和分类器可能会导致轻微的解决方案，其中生成模型不会生成有用的填充值。为解决这个问题，我们提出了一种新的规范技术，可以促进模型生成有用的填充值，以便分类。通过对实际时间序列数据进行了广泛的实验，我们证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Precipitation-nowcasting-with-generative-diffusion-models"><a href="#Precipitation-nowcasting-with-generative-diffusion-models" class="headerlink" title="Precipitation nowcasting with generative diffusion models"></a>Precipitation nowcasting with generative diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06733">http://arxiv.org/abs/2308.06733</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fmerizzi/Precipitation-nowcasting-with-generative-diffusion-models">https://github.com/fmerizzi/Precipitation-nowcasting-with-generative-diffusion-models</a></li>
<li>paper_authors: Andrea Asperti, Fabio Merizzi, Alberto Paparella, Giorgio Pedrazzi, Matteo Angelinelli, Stefano Colamonaco</li>
<li>For: 这个研究是用来测试深度学习方法在气象预报中的精度。* Methods: 这个研究使用了数种深度学习模型，包括生成模型、Variational Autoencoders和抑制算法。* Results: 研究发现，使用生成ensemble扩展（GED）模型可以对于降水预报提供更高的精度，比起现有的深度学习模型。<details>
<summary>Abstract</summary>
In recent years traditional numerical methods for accurate weather prediction have been increasingly challenged by deep learning methods. Numerous historical datasets used for short and medium-range weather forecasts are typically organized into a regular spatial grid structure. This arrangement closely resembles images: each weather variable can be visualized as a map or, when considering the temporal axis, as a video. Several classes of generative models, comprising Generative Adversarial Networks, Variational Autoencoders, or the recent Denoising Diffusion Models have largely proved their applicability to the next-frame prediction problem, and is thus natural to test their performance on the weather prediction benchmarks. Diffusion models are particularly appealing in this context, due to the intrinsically probabilistic nature of weather forecasting: what we are really interested to model is the probability distribution of weather indicators, whose expected value is the most likely prediction.   In our study, we focus on a specific subset of the ERA-5 dataset, which includes hourly data pertaining to Central Europe from the years 2016 to 2021. Within this context, we examine the efficacy of diffusion models in handling the task of precipitation nowcasting. Our work is conducted in comparison to the performance of well-established U-Net models, as documented in the existing literature. Our proposed approach of Generative Ensemble Diffusion (GED) utilizes a diffusion model to generate a set of possible weather scenarios which are then amalgamated into a probable prediction via the use of a post-processing network. This approach, in comparison to recent deep learning models, substantially outperformed them in terms of overall performance.
</details>
<details>
<summary>摘要</summary>
Recently, traditional numerical methods for accurate weather prediction have been increasingly challenged by deep learning methods. Historical weather data used for short and medium-range forecasts are typically organized into a regular spatial grid structure, resembling images or videos when considering the temporal axis. Generative models such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Denoising Diffusion Models (DDMs) have shown great potential in predicting the next frame of weather patterns. Diffusion models are particularly appealing in this context, as weather forecasting is inherently probabilistic and what we are really interested in modeling is the probability distribution of weather indicators.In our study, we focus on a specific subset of the ERA-5 dataset, which includes hourly data for Central Europe from 2016 to 2021. We examine the efficacy of diffusion models in handling the task of precipitation nowcasting and compare their performance to well-established U-Net models. Our proposed approach, Generative Ensemble Diffusion (GED), utilizes a diffusion model to generate a set of possible weather scenarios, which are then combined into a probable prediction using a post-processing network. This approach outperforms recent deep learning models in terms of overall performance.
</details></li>
</ul>
<hr>
<h2 id="Generalized-Independent-Noise-Condition-for-Estimating-Causal-Structure-with-Latent-Variables"><a href="#Generalized-Independent-Noise-Condition-for-Estimating-Causal-Structure-with-Latent-Variables" class="headerlink" title="Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables"></a>Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06718">http://arxiv.org/abs/2308.06718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Xie, Biwei Huang, Zhengming Chen, Ruichu Cai, Clark Glymour, Zhi Geng, Kun Zhang</li>
<li>for: The paper is written for learning causal structure in the presence of latent variables, including locating latent variables and determining their quantity, and identifying causal relationships among both latent and observed variables.</li>
<li>methods: The paper proposes a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. The paper also provides necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models.</li>
<li>results: The paper shows that the proposed GIN condition, together with a well-designed search procedure, can be used to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. The paper also demonstrates the effectiveness of the proposed approach through experimental results.<details>
<summary>Abstract</summary>
We investigate the challenging task of learning causal structure in the presence of latent variables, including locating latent variables and determining their quantity, and identifying causal relationships among both latent and observed variables. To address this, we propose a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. Specifically, for two observed random vectors $\bf{Y}$ and $\bf{Z}$, GIN holds if and only if $\omega^{\intercal}\mathbf{Y}$ and $\mathbf{Z}$ are independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then give necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous set $\mathcal{S}$ relative to the parent set of $\mathbf{Y}$ (w.r.t. the causal ordering), such that $\mathcal{S}$ d-separates $\mathbf{Y}$ from $\mathbf{Z}$. Interestingly, we find that the independent noise condition (i.e., if there is no confounder, causes are independent of the residual derived from regressing the effect on the causes) can be seen as a special case of GIN. With such a connection between GIN and latent causal structures, we further leverage the proposed GIN condition, together with a well-designed search procedure, to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. We show that the underlying causal structure of a LiNGLaH is identifiable in light of GIN conditions under mild assumptions. Experimental results show the effectiveness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:我们研究一个复杂的任务，即在存在隐变量的情况下学习 causal 结构，包括找到隐变量的位置和量，以及确定隐变量和观测变量之间的 causal 关系。为此，我们提出了一种 Generalized Independent Noise (GIN) 条件，用于 linear non-Gaussian 隐变量模型，该条件 garanties that a linear combination of certain observed variables and some other observed variables are independent. Specifically, for two observed random vectors $\mathbf{Y}$ and $\mathbf{Z}$, GIN holds if and only if $\omega^\top \mathbf{Y}$ and $\mathbf{Z}$ are independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then provide necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous set $\mathcal{S}$ relative to the parent set of $\mathbf{Y}$ (w.r.t. the causal ordering), such that $\mathcal{S}$ d-separates $\mathbf{Y}$ from $\mathbf{Z}$. Interestingly, we find that the independent noise condition (i.e., if there is no confounder, causes are independent of the residual derived from regressing the effect on the causes) can be seen as a special case of GIN. With such a connection between GIN and latent causal structures, we further leverage the proposed GIN condition, together with a well-designed search procedure, to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. We show that the underlying causal structure of a LiNGLaH is identifiable in light of GIN conditions under mild assumptions. Experimental results show the effectiveness of the proposed approach.
</details></li>
</ul>
<hr>
<h2 id="Estimating-and-Incentivizing-Imperfect-Knowledge-Agents-with-Hidden-Rewards"><a href="#Estimating-and-Incentivizing-Imperfect-Knowledge-Agents-with-Hidden-Rewards" class="headerlink" title="Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards"></a>Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06717">http://arxiv.org/abs/2308.06717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilgin Dogan, Zuo-Jun Max Shen, Anil Aswani<br>for: This paper explores a repeated adverse selection game between a self-interested learning agent and a learning principal in a setting where the principal cannot observe the agent’s reward realizations.methods: The paper uses a multi-armed bandit (MAB) problem to model the agent’s learning and a parallel algorithm for the principal to consistently estimate the agent’s unknown rewards while maximizing their own utility.results: The paper proves finite-sample consistency of an estimator and a rigorous regret bound for the principal by considering the sequential externality imposed by the agent, and simulations justify the applicability of the framework to green energy aggregator contracts.<details>
<summary>Abstract</summary>
In practice, incentive providers (i.e., principals) often cannot observe the reward realizations of incentivized agents, which is in contrast to many principal-agent models that have been previously studied. This information asymmetry challenges the principal to consistently estimate the agent's unknown rewards by solely watching the agent's decisions, which becomes even more challenging when the agent has to learn its own rewards. This complex setting is observed in various real-life scenarios ranging from renewable energy storage contracts to personalized healthcare incentives. Hence, it offers not only interesting theoretical questions but also wide practical relevance. This paper explores a repeated adverse selection game between a self-interested learning agent and a learning principal. The agent tackles a multi-armed bandit (MAB) problem to maximize their expected reward plus incentive. On top of the agent's learning, the principal trains a parallel algorithm and faces a trade-off between consistently estimating the agent's unknown rewards and maximizing their own utility by offering adaptive incentives to lead the agent. For a non-parametric model, we introduce an estimator whose only input is the history of principal's incentives and agent's choices. We unite this estimator with a proposed data-driven incentive policy within a MAB framework. Without restricting the type of the agent's algorithm, we prove finite-sample consistency of the estimator and a rigorous regret bound for the principal by considering the sequential externality imposed by the agent. Lastly, our theoretical results are reinforced by simulations justifying applicability of our framework to green energy aggregator contracts.
</details>
<details>
<summary>摘要</summary>
在实践中，奖励提供者（即主体）经常无法观察奖励的实现情况，这与许多主体-代理模型不同，这种信息不均衡会让主体难以透过决策来估计代理人的未知奖励，这变得更加复杂，当代理人需要学习自己的奖励时。这种复杂的设定在各种实际场景中出现，包括可再生能源存储合同和个性化医疗奖励。因此，它不仅存在许多理论问题，还有广泛的实际应用。本文研究了一个反复的对抗选择游戏，其中一个自利主义学习代理人与一个学习主体之间进行交互。代理人面临多支枪战（MAB）问题，以最大化他们的预期奖励加上奖励。除了代理人的学习之外，主体还需要训练一个平行算法，并面临一种奖励优化和代理人奖励的负担。为了不假设代理人的算法类型，我们提出了一种无参数的估计器，其唯一的输入是主体的奖励历史和代理人的选择。我们将这种估计器与一种基于MAB框架的数据驱动奖励策略联系起来。我们证明了这种估计器的finite-sample consistent性和对主体的正确做出约束。最后，我们通过实验证明了我们的框架在绿色能源总包合同中的应用可行性。
</details></li>
</ul>
<hr>
<h2 id="CDR-Conservative-Doubly-Robust-Learning-for-Debiased-Recommendation"><a href="#CDR-Conservative-Doubly-Robust-Learning-for-Debiased-Recommendation" class="headerlink" title="CDR: Conservative Doubly Robust Learning for Debiased Recommendation"></a>CDR: Conservative Doubly Robust Learning for Debiased Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08461">http://arxiv.org/abs/2308.08461</a></li>
<li>repo_url: None</li>
<li>paper_authors: ZiJie Song, JiaWei Chen, Sheng Zhou, QiHao Shi, Yan Feng, Chun Chen, Can Wang</li>
<li>for: 提高推荐系统中偏见的稳定性和性能</li>
<li>methods: 使用 Conservative Doubly Robust 策略（CDR），包括对填充值进行筛选和分析，以减少偏见的影响</li>
<li>results: 比较 experiments 表明，CDR 可以提高推荐系统的性能，同时减少偏见的频率<details>
<summary>Abstract</summary>
In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive.   To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.
</details>
<details>
<summary>摘要</summary>
在推荐系统（RS）中，用户行为数据是观察性的而不是实验性的，导致数据中存在普遍的偏见。因此，解决偏见问题已成为推荐系统领域的主要挑战。近些年来，双重稳健学习（DR）已经受到了广泛关注，因为它的表现良好和稳健性。然而，我们的实验结果表明，现有的DR方法受到 socalled "poisonous imputation" 的影响，其中的填充数据显著不符合事实，甚至变得counterproductive。为解决这个问题，本工作提出了 Conservative Doubly Robust 策略（CDR），该策略通过评估填充数据的mean和variance来筛选填充。理论分析表明，CDR可以降低方差和提高尾 bounds。此外，我们的实验研究表明，CDR可以显著提高性能，并可以减少poisonous imputation的频率。
</details></li>
</ul>
<hr>
<h2 id="Learning-on-Graphs-with-Out-of-Distribution-Nodes"><a href="#Learning-on-Graphs-with-Out-of-Distribution-Nodes" class="headerlink" title="Learning on Graphs with Out-of-Distribution Nodes"></a>Learning on Graphs with Out-of-Distribution Nodes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06714">http://arxiv.org/abs/2308.06714</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/songyyyy/kdd22-oodgat">https://github.com/songyyyy/kdd22-oodgat</a></li>
<li>paper_authors: Yu Song, Donglin Wang</li>
<li>for: 本文旨在Addressing the problem of graph learning with out-of-distribution nodes, including detecting nodes that do not belong to the known distribution and classifying the remaining nodes to be one of the known classes.</li>
<li>methods: 本文提出了一种新的Graph Attention Network（GAT）模型，即Out-of-Distribution Graph Attention Network（OODGAT），该模型可以Explicitly model the interaction between different kinds of nodes and separate inliers from outliers during feature propagation.</li>
<li>results: 实验表明，OODGAT比现有的异常检测方法表现出较大的优势，同时与现有的分类方法相比，OODGAT的分类性能也是比较良好的。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) are state-of-the-art models for performing prediction tasks on graphs. While existing GNNs have shown great performance on various tasks related to graphs, little attention has been paid to the scenario where out-of-distribution (OOD) nodes exist in the graph during training and inference. Borrowing the concept from CV and NLP, we define OOD nodes as nodes with labels unseen from the training set. Since a lot of networks are automatically constructed by programs, real-world graphs are often noisy and may contain nodes from unknown distributions. In this work, we define the problem of graph learning with out-of-distribution nodes. Specifically, we aim to accomplish two tasks: 1) detect nodes which do not belong to the known distribution and 2) classify the remaining nodes to be one of the known classes. We demonstrate that the connection patterns in graphs are informative for outlier detection, and propose Out-of-Distribution Graph Attention Network (OODGAT), a novel GNN model which explicitly models the interaction between different kinds of nodes and separate inliers from outliers during feature propagation. Extensive experiments show that OODGAT outperforms existing outlier detection methods by a large margin, while being better or comparable in terms of in-distribution classification.
</details>
<details>
<summary>摘要</summary>
图ael Neural Networks (GNNs) 是当前最佳模型 для图ael任务中的预测模型。 Although existing GNNs have shown great performance on various graph-related tasks, little attention has been paid to the scenario where out-of-distribution (OOD) nodes exist in the graph during training and inference. Based on the concept from CV and NLP, we define OOD nodes as nodes with labels not seen in the training set. Since many networks are automatically constructed by programs, real-world graphs are often noisy and may contain nodes from unknown distributions. In this work, we define the problem of graph learning with out-of-distribution nodes. Specifically, we aim to accomplish two tasks: 1) detect nodes that do not belong to the known distribution and 2) classify the remaining nodes as one of the known classes. We demonstrate that the connection patterns in graphs are informative for outlier detection, and propose Out-of-Distribution Graph Attention Network (OODGAT), a novel GNN model that explicitly models the interaction between different types of nodes and separates inliers from outliers during feature propagation. Extensive experiments show that OODGAT outperforms existing outlier detection methods by a large margin, while being better or comparable in terms of in-distribution classification.
</details></li>
</ul>
<hr>
<h2 id="The-Hard-Constraint-PINNs-for-Interface-Optimal-Control-Problems"><a href="#The-Hard-Constraint-PINNs-for-Interface-Optimal-Control-Problems" class="headerlink" title="The Hard-Constraint PINNs for Interface Optimal Control Problems"></a>The Hard-Constraint PINNs for Interface Optimal Control Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06709">http://arxiv.org/abs/2308.06709</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tianyouzeng/pinns-interface-optimal-control">https://github.com/tianyouzeng/pinns-interface-optimal-control</a></li>
<li>paper_authors: Ming-Chih Lai, Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng</li>
<li>for:  solves optimal control problems subject to partial differential equations (PDEs) with interfaces and some control constraints.</li>
<li>methods:  combines physics-informed neural networks (PINNs) with recently developed discontinuity capturing neural networks to solve the problems.</li>
<li>results:  guarantees that both the boundary and interface conditions can be satisfied exactly, and is efficient for elliptic and parabolic interface optimal control problems.Here’s the full summary in Simplified Chinese:</li>
<li>for:  solves optimal control problems subject to PDEs with interfaces and control constraints.</li>
<li>methods:  combines PINNs with discontinuity capturing neural networks.</li>
<li>results:  guarantees exact satisfaction of boundary and interface conditions, and is efficient for elliptic and parabolic interface optimal control problems.<details>
<summary>Abstract</summary>
We show that the physics-informed neural networks (PINNs), in combination with some recently developed discontinuity capturing neural networks, can be applied to solve optimal control problems subject to partial differential equations (PDEs) with interfaces and some control constraints. The resulting algorithm is mesh-free and scalable to different PDEs, and it ensures the control constraints rigorously. Since the boundary and interface conditions, as well as the PDEs, are all treated as soft constraints by lumping them into a weighted loss function, it is necessary to learn them simultaneously and there is no guarantee that the boundary and interface conditions can be satisfied exactly. This immediately causes difficulties in tuning the weights in the corresponding loss function and training the neural networks. To tackle these difficulties and guarantee the numerical accuracy, we propose to impose the boundary and interface conditions as hard constraints in PINNs by developing a novel neural network architecture. The resulting hard-constraint PINNs approach guarantees that both the boundary and interface conditions can be satisfied exactly and they are decoupled from the learning of the PDEs. Its efficiency is promisingly validated by some elliptic and parabolic interface optimal control problems.
</details>
<details>
<summary>摘要</summary>
我们显示了物理学 Informed Neural Networks (PINNs) 可以与最近发展的破碎点捕捉神经网络 (DCNNs) 结合，以解决具有界面和一些控制约束的最佳控制问题。这个算法是无网格的和可扩展的，并且保证控制约束的严格性。由于边界和界面条件，以及PDEs，都是软的约束，因此需要同时学习它们，并且没有保证边界和界面条件可以精确地满足。这会导致调整约束的预测条件和神经网络训练中的困难。为了解决这些困难并保证数值精度，我们提出了将边界和界面条件作为硬的约束在PINNs中，通过开发一种新的神经网络架构。这种硬约束PINNs方法可以保证边界和界面条件可以精确地满足，并且与PDEs的学习分离开来。我们在一些椭圆和带形interface最佳控制问题中调查了这种方法的效率，并证明了其可靠性。
</details></li>
</ul>
<hr>
<h2 id="Generating-observation-guided-ensembles-for-data-assimilation-with-denoising-diffusion-probabilistic-model"><a href="#Generating-observation-guided-ensembles-for-data-assimilation-with-denoising-diffusion-probabilistic-model" class="headerlink" title="Generating observation guided ensembles for data assimilation with denoising diffusion probabilistic model"></a>Generating observation guided ensembles for data assimilation with denoising diffusion probabilistic model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06708">http://arxiv.org/abs/2308.06708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yasahi-hpc/generative-enkf">https://github.com/yasahi-hpc/generative-enkf</a></li>
<li>paper_authors: Yuuichi Asahi, Yuta Hasegawa, Naoyuki Onodera, Takashi Shimokawabe, Hayato Shiba, Yasuhiro Idomura</li>
<li>for: 这 paper 用于 ensemble data assimilation，使用 pseudo ensemble 生成的 denoising diffusion  probabilistic model。</li>
<li>methods: 该方法使用模型对含杂和罕见观测数据进行训练，生成多个不同的 Ensemble，并利用这些 Ensemble 的差异来进行数据融合。</li>
<li>results: 比较 conventional ensemble data assimilation 方法，这种方法在模型不完善时显示出更好的性能。<details>
<summary>Abstract</summary>
This paper presents an ensemble data assimilation method using the pseudo ensembles generated by denoising diffusion probabilistic model. Since the model is trained against noisy and sparse observation data, this model can produce divergent ensembles close to observations. Thanks to the variance in generated ensembles, our proposed method displays better performance than the well-established ensemble data assimilation method when the simulation model is imperfect.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种ensemble数据融合方法，使用pseudo ensemble生成于噪声扩散概率模型。由于模型对噪声和稀缺观测数据进行训练，因此这个模型可以生成与观测数据相近的多个分布。由于这些生成的分布之间的差异，我们提议的方法在模型不完美时表现更好 than traditional ensemble数据融合方法。Note: "pseudo ensemble" in Chinese is "假集合" (fǎ jiéhù), and "denoising diffusion probabilistic model" in Chinese is "噪声扩散概率模型" (zāi shēng kuò shiān yù jì mó delè).
</details></li>
</ul>
<hr>
<h2 id="Understanding-the-robustness-difference-between-stochastic-gradient-descent-and-adaptive-gradient-methods"><a href="#Understanding-the-robustness-difference-between-stochastic-gradient-descent-and-adaptive-gradient-methods" class="headerlink" title="Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods"></a>Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06703">http://arxiv.org/abs/2308.06703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Avery Ma, Yangchen Pan, Amir-massoud Farahmand</li>
<li>for: 论述了使用权重更新法（SGD）和自适应梯度方法（Adam、RMSProp）训练深度神经网络的研究。</li>
<li>methods: 使用SGD和自适应梯度方法训练深度神经网络。</li>
<li>results: 对于自然数据集，SGD训练的模型对输入扰动 exhibit 较好的Robustness，而使用自适应梯度方法训练的模型则对于这些扰动 exhibit 较差的Robustness。这种差异可以通过学习动态研究和synthetic dataset的实验来解释。<details>
<summary>Abstract</summary>
Stochastic gradient descent (SGD) and adaptive gradient methods, such as Adam and RMSProp, have been widely used in training deep neural networks. We empirically show that while the difference between the standard generalization performance of models trained using these methods is small, those trained using SGD exhibit far greater robustness under input perturbations. Notably, our investigation demonstrates the presence of irrelevant frequencies in natural datasets, where alterations do not affect models' generalization performance. However, models trained with adaptive methods show sensitivity to these changes, suggesting that their use of irrelevant frequencies can lead to solutions sensitive to perturbations. To better understand this difference, we study the learning dynamics of gradient descent (GD) and sign gradient descent (signGD) on a synthetic dataset that mirrors natural signals. With a three-dimensional input space, the models optimized with GD and signGD have standard risks close to zero but vary in their adversarial risks. Our result shows that linear models' robustness to $\ell_2$-norm bounded changes is inversely proportional to the model parameters' weight norm: a smaller weight norm implies better robustness. In the context of deep learning, our experiments show that SGD-trained neural networks show smaller Lipschitz constants, explaining the better robustness to input perturbations than those trained with adaptive gradient methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Camouflaged-Image-Synthesis-Is-All-You-Need-to-Boost-Camouflaged-Detection"><a href="#Camouflaged-Image-Synthesis-Is-All-You-Need-to-Boost-Camouflaged-Detection" class="headerlink" title="Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection"></a>Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06701">http://arxiv.org/abs/2308.06701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haichao Zhang, Can Qin, Yu Yin, Yun Fu</li>
<li>for: 提高深度学习模型对涂抹式对象检测的能力</li>
<li>methods: 使用生成模型生成涂抹式图像，以增强现有对象检测模型的识别能力</li>
<li>results: 比现有方法高效，在COD10k、CAMO和CHAMELEON三个数据集上达到了更高的检测精度<details>
<summary>Abstract</summary>
Camouflaged objects that blend into natural scenes pose significant challenges for deep-learning models to detect and synthesize. While camouflaged object detection is a crucial task in computer vision with diverse real-world applications, this research topic has been constrained by limited data availability. We propose a framework for synthesizing camouflage data to enhance the detection of camouflaged objects in natural scenes. Our approach employs a generative model to produce realistic camouflage images, which can be used to train existing object detection models. Specifically, we use a camouflage environment generator supervised by a camouflage distribution classifier to synthesize the camouflage images, which are then fed into our generator to expand the dataset. Our framework outperforms the current state-of-the-art method on three datasets (COD10k, CAMO, and CHAMELEON), demonstrating its effectiveness in improving camouflaged object detection. This approach can serve as a plug-and-play data generation and augmentation module for existing camouflaged object detection tasks and provides a novel way to introduce more diversity and distributions into current camouflage datasets.
</details>
<details>
<summary>摘要</summary>
伪装物体在自然场景中混合很困难对深度学习模型进行检测和生成。隐身物体检测是计算机视觉中重要的任务，它在各种实际应用中具有广泛的意义。然而，这一研究领域受到有限的数据可用性的限制。我们提出了一种框架，用于增强自然场景中隐身物体的检测。我们的方法使用生成模型生成真实的伪装图像，这些图像可以用来训练现有的物体检测模型。具体来说，我们使用一个伪装环境生成器，该生成器被监督于伪装分布分类器，以生成伪装图像。这些图像然后被我们的生成器扩展，以增加数据集。我们的框架在COD10k、CAMO和CHAMELEON三个数据集上表现出色，超越当前状态的方法，证明了我们的方法的有效性。这种方法可以作为现有隐身物体检测任务的数据生成和增强模块，并提供一种新的多样性和分布引入现有的伪装数据集的方法。
</details></li>
</ul>
<hr>
<h2 id="SimMatchV2-Semi-Supervised-Learning-with-Graph-Consistency"><a href="#SimMatchV2-Semi-Supervised-Learning-with-Graph-Consistency" class="headerlink" title="SimMatchV2: Semi-Supervised Learning with Graph Consistency"></a>SimMatchV2: Semi-Supervised Learning with Graph Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06692">http://arxiv.org/abs/2308.06692</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mingkai-zheng/simmatchv2">https://github.com/mingkai-zheng/simmatchv2</a></li>
<li>paper_authors: Mingkai Zheng, Shan You, Lang Huang, Chen Luo, Fei Wang, Chen Qian, Chang Xu</li>
<li>for: 这个研究目的是为了提出一个新的半supervised learning算法，以减少人工劳动。</li>
<li>methods: 这个算法叫做SimMatchV2，它利用图论的观点来设计了多种一致规律，以确保labeled和unlabeled数据之间的一致性。</li>
<li>results: 这个算法在多个半supervised learningbenchmark上进行验证，以300次训练和ResNet-50底层，SimMatchV2在ImageNet上得到71.9%和76.2%的Top-1准确率，优于之前的方法，并达到了现有的最佳性能。<details>
<summary>Abstract</summary>
Semi-Supervised image classification is one of the most fundamental problem in computer vision, which significantly reduces the need for human labor. In this paper, we introduce a new semi-supervised learning algorithm - SimMatchV2, which formulates various consistency regularizations between labeled and unlabeled data from the graph perspective. In SimMatchV2, we regard the augmented view of a sample as a node, which consists of a label and its corresponding representation. Different nodes are connected with the edges, which are measured by the similarity of the node representations. Inspired by the message passing and node classification in graph theory, we propose four types of consistencies, namely 1) node-node consistency, 2) node-edge consistency, 3) edge-edge consistency, and 4) edge-node consistency. We also uncover that a simple feature normalization can reduce the gaps of the feature norm between different augmented views, significantly improving the performance of SimMatchV2. Our SimMatchV2 has been validated on multiple semi-supervised learning benchmarks. Notably, with ResNet-50 as our backbone and 300 epochs of training, SimMatchV2 achieves 71.9\% and 76.2\% Top-1 Accuracy with 1\% and 10\% labeled examples on ImageNet, which significantly outperforms the previous methods and achieves state-of-the-art performance. Code and pre-trained models are available at \href{https://github.com/mingkai-zheng/SimMatchV2}{https://github.com/mingkai-zheng/SimMatchV2}.
</details>
<details>
<summary>摘要</summary>
《半指导Image Classification》是计算机视觉中的一个基本问题，它可以减少人工劳动量。在这篇论文中，我们介绍了一种新的半指导学习算法——SimMatchV2，它在图像视角下划定了不同类别的样本。在SimMatchV2中，我们将每个样本视为一个节点，每个节点有一个标签和对应的表示。不同的节点之间连接了边，边的 Similarity 度量节点表示之间的相似性。我们还提出了四种一致性，即1）节点-节点一致性，2）节点-边一致性，3）边-边一致性，4）边-节点一致性。我们还发现了一种简单的特征归一化可以减少不同扩展视图之间的特征范围差异，从而显著提高SimMatchV2的性能。我们的SimMatchV2在多个半指导学习标准benchmark上进行验证，与ResNet-50作为背景和300个训练周期，SimMatchV2在ImageNet上 achieve 71.9%和76.2%的Top-1准确率，与先前的方法相比显著超越，实现了状态的最佳性能。代码和预训练模型可以在 <https://github.com/mingkai-zheng/SimMatchV2> 中获取。
</details></li>
</ul>
<hr>
<h2 id="MDB-Interactively-Querying-Datasets-and-Models"><a href="#MDB-Interactively-Querying-Datasets-and-Models" class="headerlink" title="MDB: Interactively Querying Datasets and Models"></a>MDB: Interactively Querying Datasets and Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06686">http://arxiv.org/abs/2308.06686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aaditya Naik, Adam Stein, Yinjun Wu, Eric Wong, Mayur Naik</li>
<li>for: 这篇论文是为了提供一个Debugging框架，帮助开发者在机器学习管道中系统地调试错误。</li>
<li>methods: 这篇论文使用了函数编程和关系代数来构建表达式查询数据集和模型预测。查询可重用和轻松修改，帮助调试员快速缩小查询错误和模型行为。</li>
<li>results:  experiments show that MDB可以提供更快（10倍）和更短（40%）的查询，并且在用户研究中，开发者可以成功构建复杂的查询来描述机器学习模型的错误。<details>
<summary>Abstract</summary>
As models are trained and deployed, developers need to be able to systematically debug errors that emerge in the machine learning pipeline. We present MDB, a debugging framework for interactively querying datasets and models. MDB integrates functional programming with relational algebra to build expressive queries over a database of datasets and model predictions. Queries are reusable and easily modified, enabling debuggers to rapidly iterate and refine queries to discover and characterize errors and model behaviors. We evaluate MDB on object detection, bias discovery, image classification, and data imputation tasks across self-driving videos, large language models, and medical records. Our experiments show that MDB enables up to 10x faster and 40\% shorter queries than other baselines. In a user study, we find developers can successfully construct complex queries that describe errors of machine learning models.
</details>
<details>
<summary>摘要</summary>
models 是在训练和部署过程中，开发人员需要系统地调试出现在机器学习管道中的错误。我们提出了 MDB，一个用于交互查询数据集和模型的调试框架。MDB将函数编程与关系代数结合，以构建表达式查询数据库中的数据集和模型预测。查询可重复使用，易于修改，让调试者可以快速灵活地 iteratively 修改查询，以描述和揭示错误和模型行为。我们在对自动驾驶视频、大语言模型和医疗记录进行对象检测、偏见发现、图像分类和数据补充任务上进行了实验，发现 MDB 可以提高查询速度和查询长度，相比于其他基eline。在用户研究中，我们发现开发人员可以成功地构建复杂的查询，以描述机器学习模型的错误。
</details></li>
</ul>
<hr>
<h2 id="Separable-Gaussian-Neural-Networks-Structure-Analysis-and-Function-Approximations"><a href="#Separable-Gaussian-Neural-Networks-Structure-Analysis-and-Function-Approximations" class="headerlink" title="Separable Gaussian Neural Networks: Structure, Analysis, and Function Approximations"></a>Separable Gaussian Neural Networks: Structure, Analysis, and Function Approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06679">http://arxiv.org/abs/2308.06679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyuan Xing, Jianqiao Sun</li>
<li>For: 这个论文想要解决高维输入数据的快速 interpolate和分类问题，提出了一种新的前向网络模型 - 分解 Gaussian 神经网络（SGNN）。* Methods: SGNN 利用 Gaussian 函数的分解性，将输入数据分割成多列，然后在并行层中进行批量处理，从而将计算量从 GRBFNN 的 O(N^d) 减少到 O(dN)，速度增长 linear 地。* Results: 实验表明，SGNN 可以与 GRBFNN 相比，在 tri-variate 函数近似中实现 100 倍的速度提升，并且保持 GRBFNN 的级别准确性。 SGNN 还比 DNNs  WITH RuLU 和 Sigmoid 函数更易于训练和调整。 在approximating 函数 WITH complex geometry 时，SGNN 可以达到三个数量级更高的准确性。<details>
<summary>Abstract</summary>
The Gaussian-radial-basis function neural network (GRBFNN) has been a popular choice for interpolation and classification. However, it is computationally intensive when the dimension of the input vector is high. To address this issue, we propose a new feedforward network - Separable Gaussian Neural Network (SGNN) by taking advantage of the separable property of Gaussian functions, which splits input data into multiple columns and sequentially feeds them into parallel layers formed by uni-variate Gaussian functions. This structure reduces the number of neurons from O(N^d) of GRBFNN to O(dN), which exponentially improves the computational speed of SGNN and makes it scale linearly as the input dimension increases. In addition, SGNN can preserve the dominant subspace of the Hessian matrix of GRBFNN in gradient descent training, leading to a similar level of accuracy to GRBFNN. It is experimentally demonstrated that SGNN can achieve 100 times speedup with a similar level of accuracy over GRBFNN on tri-variate function approximations. The SGNN also has better trainability and is more tuning-friendly than DNNs with RuLU and Sigmoid functions. For approximating functions with complex geometry, SGNN can lead to three orders of magnitude more accurate results than a RuLU-DNN with twice the number of layers and the number of neurons per layer.
</details>
<details>
<summary>摘要</summary>
Gaussian-radial-basis函数神经网络（GRBFNN）已经是选择 interpolation和分类的受欢迎选择。然而，当输入向量维度高时，它会占用大量计算资源。为解决这个问题，我们提出了一个新的前向网络——分解 Gaussian 神经网络（SGNN），利用 Gaussian 函数的分解性，将输入数据分解成多列，然后将它们顺序输入到由单variate Gaussian 函数组成的并行层中。这种结构将 GRBFNN 中的 neuron 数由 O(N^d) 降低到 O(dN)，从而 exponential 提高 SGNN 的计算速度，使其与输入维度增加时呈线性增长。此外，SGNN 还可以保留 GRBFNN 的主要子空间，从而在梯度下降训练中达到类似精度水平。实验表明，SGNN 可以在 tri-variate 函数拟合中实现 100 倍的速度提升，同时保持精度水平。此外，SGNN 还比 DNNs  WITH RuLU 和 sigmoid 函数更易于训练和调整。对于拟合复杂几何函数的情况，SGNN 可以 achieve 三个排名的精度提升。
</details></li>
</ul>
<hr>
<h2 id="A-deep-learning-framework-for-multi-scale-models-based-on-physics-informed-neural-networks"><a href="#A-deep-learning-framework-for-multi-scale-models-based-on-physics-informed-neural-networks" class="headerlink" title="A deep learning framework for multi-scale models based on physics-informed neural networks"></a>A deep learning framework for multi-scale models based on physics-informed neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06672">http://arxiv.org/abs/2308.06672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong Wang, Yanzhong Yao, Jiawei Guo, Zhiming Gao</li>
<li>for: 解决多级别问题（multi-scale problems）</li>
<li>methods: 基于深度神经网络（deep neural networks）和解决partial differential equations（PDEs）的physics-informed neural networks（PINN）方法</li>
<li>results: 提出了一种新的框架，可以同时优化多级别的损失项，并且可以处理不同子域的问题变化。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINN) combine deep neural networks with the solution of partial differential equations (PDEs), creating a new and promising research area for numerically solving PDEs. Faced with a class of multi-scale problems that include loss terms of different orders of magnitude in the loss function, it is challenging for standard PINN methods to obtain an available prediction. In this paper, we propose a new framework for solving multi-scale problems by reconstructing the loss function. The framework is based on the standard PINN method, and it modifies the loss function of the standard PINN method by applying different numbers of power operations to the loss terms of different magnitudes, so that the individual loss terms composing the loss function have approximately the same order of magnitude among themselves. In addition, we give a grouping regularization strategy, and this strategy can deal well with the problem which varies significantly in different subdomains. The proposed method enables loss terms with different magnitudes to be optimized simultaneously, and it advances the application of PINN for multi-scale problems.
</details>
<details>
<summary>摘要</summary>
物理学 Informed neural networks (PINN) combine deep neural networks with partial differential equations (PDEs) 的解决方法，创造了一个新的研究领域，用于数值解决 PDEs。面临多个层次问题，其中loss函数中的损失项有不同的级别，标准的PINN方法难以获得可用的预测。在这篇论文中，我们提出了一种新的多层次问题解决框架。这种框架基于标准的PINN方法，对loss函数中的各个损失项应用不同的数量的power操作，使得各个损失项的级别相对较同。此外，我们提出了一种分组常见化策略，该策略可以处理不同子领域中变化很大的问题。提出的方法可以同时优化不同级别的损失项，并提高PINN在多层次问题上的应用。
</details></li>
</ul>
<hr>
<h2 id="Law-of-Balance-and-Stationary-Distribution-of-Stochastic-Gradient-Descent"><a href="#Law-of-Balance-and-Stationary-Distribution-of-Stochastic-Gradient-Descent" class="headerlink" title="Law of Balance and Stationary Distribution of Stochastic Gradient Descent"></a>Law of Balance and Stationary Distribution of Stochastic Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06671">http://arxiv.org/abs/2308.06671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liu Ziyin, Hongchao Li, Masahito Ueda</li>
<li>for: This paper aims to understand how the stochastic gradient descent (SGD) algorithm navigates the highly nonlinear and degenerate loss landscape of a neural network.</li>
<li>methods: The paper uses theoretical analysis to prove that the minibatch noise of SGD regularizes the solution towards a balanced solution whenever the loss function contains a rescaling symmetry.</li>
<li>results: The paper derives the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width, and shows that the stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion, which are unique to deep networks.Here is the answer in Simplified Chinese text:</li>
<li>for: 这篇论文目标是理解权重梯度下降（SGD）算法在神经网络的高非线性和平衡梯度图像中的探索。</li>
<li>methods: 论文使用理论分析，证明SGD中批处理噪声对于包含扩缩尺度Symmetry的损失函数的解决方法。</li>
<li>results: 论文Derive diagonally linear network with arbitrary depth and width的stationary distribution of stochastic gradient flow，并显示其站立分布具有复杂非线性现象，如相转变、破碎Ergodicity和振荡反转，这些现象只存在于深度很大的网络中。<details>
<summary>Abstract</summary>
The stochastic gradient descent (SGD) algorithm is the algorithm we use to train neural networks. However, it remains poorly understood how the SGD navigates the highly nonlinear and degenerate loss landscape of a neural network. In this work, we prove that the minibatch noise of SGD regularizes the solution towards a balanced solution whenever the loss function contains a rescaling symmetry. Because the difference between a simple diffusion process and SGD dynamics is the most significant when symmetries are present, our theory implies that the loss function symmetries constitute an essential probe of how SGD works. We then apply this result to derive the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width. The stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion. These phenomena are shown to exist uniquely in deep networks, implying a fundamental difference between deep and shallow models.
</details>
<details>
<summary>摘要</summary>
SGD算法是我们用来训练神经网络的算法，但是它在神经网络的高度非线性和缺乏稳定性的损失函数空间中 navigation 仍然不够了解。在这个工作中，我们证明了SGD中的小批量噪声规范化解决方案，当损失函数具有扩展对称性时。由于噪声和SGD动力学的差异最大化在对称性存在时，我们的理论 imply 损失函数对称性是SGD工作的重要探测器。我们然后使用这结果来 derive 神经网络的站点分布，并证明了深度神经网络存在复杂非线性现象，如相对稳定性、破坏性和异常倒振。这些现象仅存在深度神经网络中，表明深度和浅度模型之间存在根本的差异。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Models-in-Smart-Agriculture-Basics-Opportunities-and-Challenges"><a href="#Foundation-Models-in-Smart-Agriculture-Basics-Opportunities-and-Challenges" class="headerlink" title="Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges"></a>Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06668">http://arxiv.org/abs/2308.06668</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiajiali04/agriculture-foundation-models">https://github.com/jiajiali04/agriculture-foundation-models</a></li>
<li>paper_authors: Jiajia Li, Mingle Xu, Lirong Xiang, Dong Chen, Weichao Zhuang, Xunyuan Yin, Zhaojian Li</li>
<li>for: 本研究旨在探讨基于machine learning和deep learning的智能农业领域中的应用Foundation Model（FM）。</li>
<li>methods: 本研究首先对现代计算机科学领域的FM进行了综述，并将其分为四类：语言FM、视觉FM、多模态FM和奖励学习FM。然后，我们详细介绍了在农业领域开发农业FM的过程，并讨论了其在智能农业中的潜在应用。</li>
<li>results: 本研究通过引入基于FM的应用方法，可以减少农业AI系统的依赖于大量标注数据，提高效率、有效性和通用性。此外，本研究还提出了开发农业FM的一些挑战，包括模型训练、验证和部署。<details>
<summary>Abstract</summary>
The past decade has witnessed the rapid development of ML and DL methodologies in agricultural systems, showcased by great successes in variety of agricultural applications. However, these conventional ML/DL models have certain limitations: They heavily rely on large, costly-to-acquire labeled datasets for training, require specialized expertise for development and maintenance, and are mostly tailored for specific tasks, thus lacking generalizability. Recently, foundation models have demonstrated remarkable successes in language and vision tasks across various domains. These models are trained on a vast amount of data from multiple domains and modalities. Once trained, they can accomplish versatile tasks with just minor fine-tuning and minimal task-specific labeled data. Despite their proven effectiveness and huge potential, there has been little exploration of applying FMs to agriculture fields. Therefore, this study aims to explore the potential of FMs in the field of smart agriculture. In particular, we present conceptual tools and technical background to facilitate the understanding of the problem space and uncover new research directions in this field. To this end, we first review recent FMs in the general computer science domain and categorize them into four categories: language FMs, vision FMs, multimodal FMs, and reinforcement learning FMs. Subsequently, we outline the process of developing agriculture FMs and discuss their potential applications in smart agriculture. We also discuss the unique challenges associated with developing AFMs, including model training, validation, and deployment. Through this study, we contribute to the advancement of AI in agriculture by introducing AFMs as a promising paradigm that can significantly mitigate the reliance on extensive labeled datasets and enhance the efficiency, effectiveness, and generalization of agricultural AI systems.
</details>
<details>
<summary>摘要</summary>
过去一代，机器学习（ML）和深度学习（DL）方法在农业系统中得到了迅速发展，在多种农业应用中显示出了很大成功。然而，这些传统的ML/DL模型具有一些限制：它们需要大量、昂贵的标签数据进行训练，需要专门的专业知识进行开发和维护，而且主要是为特定任务设计，因此缺乏普适性。在最近的几年里，基础模型（FM）在语言和视觉任务中获得了惊人的成功。这些模型通过大量的数据来自多个领域和模式进行训练，一旦训练完成，就可以完成多种任务，只需要微小的调整和微小的任务特定的标签数据。尽管它们的可效性和潜在的潜力很大，但在农业领域中还没有多少探索基础模型的应用。因此，本研究旨在探讨基础模型在智能农业领域的潜力。具体来说，我们首先将最近的FM在通用计算机科学领域中进行了综述，并将其分为四类：语言FM、视觉FM、多模式FM和奖励学习FM。然后，我们详细介绍了在农业领域开发农业FM的过程，并讨论了它们在智能农业中的潜在应用。我们还讨论了开发AFM的独特挑战，包括模型训练、验证和部署。通过本研究，我们为农业AI的发展做出了贡献，将基础模型作为一种可能的解决方案，可以减少农业AI系统的依赖于大量标签数据，提高效率、有效性和普适性。
</details></li>
</ul>
<hr>
<h2 id="ALGAN-Time-Series-Anomaly-Detection-with-Adjusted-LSTM-GAN"><a href="#ALGAN-Time-Series-Anomaly-Detection-with-Adjusted-LSTM-GAN" class="headerlink" title="ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN"></a>ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06663">http://arxiv.org/abs/2308.06663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Abul Bashar, Richi Nayak</li>
<li>For: Anomaly detection in time series data, specifically in univariate and multivariate datasets in an unsupervised setting.* Methods: Proposes a new GAN model called Adjusted-LSTM GAN (ALGAN), which adjusts the output of an LSTM network for improved anomaly detection accuracy.* Results: Outperforms traditional, neural network-based, and other GAN-based methods for anomaly detection in time series data, as demonstrated through experiments on 46 real-world univariate time series datasets and a large multivariate dataset.<details>
<summary>Abstract</summary>
Anomaly detection in time series data, to identify points that deviate from normal behaviour, is a common problem in various domains such as manufacturing, medical imaging, and cybersecurity. Recently, Generative Adversarial Networks (GANs) are shown to be effective in detecting anomalies in time series data. The neural network architecture of GANs (i.e. Generator and Discriminator) can significantly improve anomaly detection accuracy. In this paper, we propose a new GAN model, named Adjusted-LSTM GAN (ALGAN), which adjusts the output of an LSTM network for improved anomaly detection in both univariate and multivariate time series data in an unsupervised setting. We evaluate the performance of ALGAN on 46 real-world univariate time series datasets and a large multivariate dataset that spans multiple domains. Our experiments demonstrate that ALGAN outperforms traditional, neural network-based, and other GAN-based methods for anomaly detection in time series data.
</details>
<details>
<summary>摘要</summary>
<<SYS>>时间序列数据中异常检测，以识别不同于常规行为的点，是多个领域中的一个常见问题，包括制造、医疗影像和网络安全等。最近，生成对抗网络（GANs）在时间序列数据中的异常检测中表现出色。GANs的神经网络架构（即生成器和识别器）可以显著提高异常检测精度。在本文中，我们提出了一种新的GAN模型，名为调整LSTM GAN（ALGAN），该模型可以在无监督的情况下，对单变量和多变量时间序列数据进行改进的异常检测。我们对46个真实的单变量时间序列数据集和多个领域的大量多变量数据集进行了试验，结果表明，ALGAN比传统的神经网络基于的方法、神经网络GAN方法和其他GAN方法在时间序列数据中的异常检测方面表现出色。Note: "LSTM" stands for Long Short-Term Memory, which is a type of Recurrent Neural Network (RNN) designed to handle time series data.
</details></li>
</ul>
<hr>
<h2 id="Benign-Shortcut-for-Debiasing-Fair-Visual-Recognition-via-Intervention-with-Shortcut-Features"><a href="#Benign-Shortcut-for-Debiasing-Fair-Visual-Recognition-via-Intervention-with-Shortcut-Features" class="headerlink" title="Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features"></a>Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08482">http://arxiv.org/abs/2308.08482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yiiizhang/shortcutDebiasing">https://github.com/yiiizhang/shortcutDebiasing</a></li>
<li>paper_authors: Yi Zhang, Jitao Sang, Junyang Wang, Dongmei Jiang, Yaowei Wang</li>
<li>for: 降低机器学习模型中的偏见风险，特别是在社会应用中，如雇用、银行和刑事司法等。</li>
<li>methods: 我们提出了一种简洁处理方法，称为“快捷偏见处理”（Shortcut Debiasing），它首先将偏见特征 transferred to快捷特征，然后使用 causal intervention 把快捷特征 eliminated during inference。</li>
<li>results: 我们将此方法应用到多个 benchmark 数据集上，并与现有的偏见处理方法进行比较，获得了显著的改善。<details>
<summary>Abstract</summary>
Machine learning models often learn to make predictions that rely on sensitive social attributes like gender and race, which poses significant fairness risks, especially in societal applications, such as hiring, banking, and criminal justice. Existing work tackles this issue by minimizing the employed information about social attributes in models for debiasing. However, the high correlation between target task and these social attributes makes learning on the target task incompatible with debiasing. Given that model bias arises due to the learning of bias features (\emph{i.e}., gender) that help target task optimization, we explore the following research question: \emph{Can we leverage shortcut features to replace the role of bias feature in target task optimization for debiasing?} To this end, we propose \emph{Shortcut Debiasing}, to first transfer the target task's learning of bias attributes from bias features to shortcut features, and then employ causal intervention to eliminate shortcut features during inference. The key idea of \emph{Shortcut Debiasing} is to design controllable shortcut features to on one hand replace bias features in contributing to the target task during the training stage, and on the other hand be easily removed by intervention during the inference stage. This guarantees the learning of the target task does not hinder the elimination of bias features. We apply \emph{Shortcut Debiasing} to several benchmark datasets, and achieve significant improvements over the state-of-the-art debiasing methods in both accuracy and fairness.
</details>
<details>
<summary>摘要</summary>
机器学习模型经常学习依赖敏感社会特征如性别和种族的预测，这会带来公平风险，特别是在社会应用中，如招聘、银行和刑事司法。现有的工作解决这个问题，是通过减少模型使用的社会特征来减少模型的偏见。然而，目标任务和社会特征之间的高相关性使得学习目标任务与减少偏见不兼容。基于模型偏见来自偏见特征（例如性别）的学习，我们提出了以下研究问题：“可以通过剪辑特征来替代偏见特征的角色来优化目标任务吗？”为此，我们提出了短Circuit Debiasing，即在训练阶段通过将目标任务学习的偏见特征转移到剪辑特征上，然后通过 causal intervention 在推理阶段消除剪辑特征。短Circuit Debiasing 的关键思想是设计可控的剪辑特征，以便在训练阶段替代偏见特征，并在推理阶段通过 intervention 轻松消除。这 garantizes 学习目标任务不会阻碍减少偏见。我们在多个标准数据集上应用短Circuit Debiasing，并在准确率和公平性两个方面获得了 significan 的改进。
</details></li>
</ul>
<hr>
<h2 id="Polar-Collision-Grids-Effective-Interaction-Modelling-for-Pedestrian-Trajectory-Prediction-in-Shared-Space-Using-Collision-Checks"><a href="#Polar-Collision-Grids-Effective-Interaction-Modelling-for-Pedestrian-Trajectory-Prediction-in-Shared-Space-Using-Collision-Checks" class="headerlink" title="Polar Collision Grids: Effective Interaction Modelling for Pedestrian Trajectory Prediction in Shared Space Using Collision Checks"></a>Polar Collision Grids: Effective Interaction Modelling for Pedestrian Trajectory Prediction in Shared Space Using Collision Checks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06654">http://arxiv.org/abs/2308.06654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad</li>
<li>for: 预测行人轨迹是自动驾驶车辆安全导航中的关键能力，特别是在与行人共享空间时。行人运动在共享空间中受到车辆和其他行人的影响，因此可以更好地模型行人-车辆和行人-行人交互，从而提高行人轨迹预测模型的准确性。</li>
<li>methods: 我们提出了一种基于启发的交互代理选择过程，利用碰撞风险计算来选择交互代理。我们关注与可能碰撞的代理之间的时间到碰撞和接近方向的影响，并通过引入一种新的极地增量增量Grid Map来编码交互效果。</li>
<li>results: 我们的结果表明，使用我们提出的方法可以比基eline方法（作为参考）在HBS数据集上预测轨迹更加准确。<details>
<summary>Abstract</summary>
Predicting pedestrians' trajectories is a crucial capability for autonomous vehicles' safe navigation, especially in spaces shared with pedestrians. Pedestrian motion in shared spaces is influenced by both the presence of vehicles and other pedestrians. Therefore, effectively modelling both pedestrian-pedestrian and pedestrian-vehicle interactions can increase the accuracy of the pedestrian trajectory prediction models. Despite the huge literature on ways to encode the effect of interacting agents on a pedestrian's predicted trajectory using deep-learning models, limited effort has been put into the effective selection of interacting agents. In the majority of cases, the interaction features used are mainly based on relative distances while paying less attention to the effect of the velocity and approaching direction in the interaction formulation. In this paper, we propose a heuristic-based process of selecting the interacting agents based on collision risk calculation. Focusing on interactions of potentially colliding agents with a target pedestrian, we propose the use of time-to-collision and the approach direction angle of two agents for encoding the interaction effect. This is done by introducing a novel polar collision grid map. Our results have shown predicted trajectories closer to the ground truth compared to existing methods (used as a baseline) on the HBS dataset.
</details>
<details>
<summary>摘要</summary>
预测行人轨迹是自动驾驶车辆安全导航中的关键能力，特别是在与行人共享空间时。行人运动在共享空间中受到车辆和其他行人的影响。因此，可以准确地模拟行人与车辆和其他行人之间的互动，可以提高行人轨迹预测模型的准确性。Despite the extensive literature on using deep-learning models to encode the effect of interacting agents on a pedestrian's predicted trajectory, there has been limited effort put into selecting the interacting agents effectively. Most existing methods use relative distance as the main factor in the interaction formulation, while ignoring the effect of velocity and approaching direction.在这篇论文中，我们提出了一种基于启发的互动代理选择过程，通过计算碰撞风险来选择互动代理。我们将注意力集中在可能碰撞的代理与目标行人之间的互动效应上，并通过引入一种新的极地碰撞格图来编码这种互动效应。我们的结果表明，与基eline方法相比，我们的方法可以在HBS数据集上预测轨迹更加准确。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation"><a href="#Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation" class="headerlink" title="Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation"></a>Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06644">http://arxiv.org/abs/2308.06644</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jwrh/Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation">https://github.com/jwrh/Accelerating-Diffusion-based-Combinatorial-Optimization-Solvers-by-Progressive-Distillation</a></li>
<li>paper_authors: Junwei Huang, Zhiqing Sun, Yiming Yang</li>
<li>for: 提高 NP-完全 combinatorial 优化问题的解决速度</li>
<li>methods: 使用进步干涤法加速推理，在杂化过程中采取 fewer steps，如在单步内预测两步</li>
<li>results: 实验结果显示，使用进步干涤模型可以将推理速度提高 16 倍，而性能下降仅 0.019%，在 TSP-50 数据集上。<details>
<summary>Abstract</summary>
Graph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.
</details>
<details>
<summary>摘要</summary>
GRaph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.Here's the translation in Traditional Chinese: GRaph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.
</details></li>
</ul>
<hr>
<h2 id="Advances-in-Self-Supervised-Learning-for-Synthetic-Aperture-Sonar-Data-Processing-Classification-and-Pattern-Recognition"><a href="#Advances-in-Self-Supervised-Learning-for-Synthetic-Aperture-Sonar-Data-Processing-Classification-and-Pattern-Recognition" class="headerlink" title="Advances in Self-Supervised Learning for Synthetic Aperture Sonar Data Processing, Classification, and Pattern Recognition"></a>Advances in Self-Supervised Learning for Synthetic Aperture Sonar Data Processing, Classification, and Pattern Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11633">http://arxiv.org/abs/2308.11633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brandon Sheffield, Frank E. Bobe III, Bradley Marchand, Matthew S. Emigh</li>
<li>for: 本研究旨在提高水下探索中SAS数据处理、分类和 Pattern recognition的效果，通过使用自助学习（SSL）技术。</li>
<li>methods: 本研究提出了MoCo-SAS，一种基于SSL的SAS数据处理方法，包括数据预处理、特征提取、模型训练和测试。</li>
<li>results: 实验结果表明，MoCo-SAS与传统的指导学习方法相比，在F1分数上有显著提高，表明SSL可以在SAS数据处理中提高效果，并且具有潜在的应用前景。<details>
<summary>Abstract</summary>
Synthetic Aperture Sonar (SAS) imaging has become a crucial technology for underwater exploration because of its unique ability to maintain resolution at increasing ranges, a characteristic absent in conventional sonar techniques. However, the effective application of deep learning to SAS data processing is often limited due to the scarcity of labeled data. To address this challenge, this paper proposes MoCo-SAS that leverages self-supervised learning (SSL) for SAS data processing, classification, and pattern recognition. The experimental results demonstrate that MoCo-SAS significantly outperforms traditional supervised learning methods, as evidenced by significant improvements observed in terms of the F1-score. These findings highlight the potential of SSL in advancing the state-of-the-art in SAS data processing, offering promising avenues for enhanced underwater object detection and classification.
</details>
<details>
<summary>摘要</summary>
射频成像技术（SAS）已成为水下探测中不可或缺的一种重要技术，因其可以维持分辨率随距离增长，这是传统声纳技术缺乏的特点。然而，各种深度学习在SAS数据处理中的有效应用却受到标注数据的罕见性的限制。为解决这个挑战，本文提出了MoCo-SAS，利用自动编程学习（SSL）进行SAS数据处理、分类和模式识别。实验结果表明，MoCo-SAS在F1分数方面显著超越传统监督学习方法，这表明SSL在SAS数据处理中具有潜在的潜在优势。这些发现表明SSL在SAS数据处理中可能提供新的突破口，用于提高水下对象检测和分类的精度。
</details></li>
</ul>
<hr>
<h2 id="ADRMX-Additive-Disentanglement-of-Domain-Features-with-Remix-Loss"><a href="#ADRMX-Additive-Disentanglement-of-Domain-Features-with-Remix-Loss" class="headerlink" title="ADRMX: Additive Disentanglement of Domain Features with Remix Loss"></a>ADRMX: Additive Disentanglement of Domain Features with Remix Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06624">http://arxiv.org/abs/2308.06624</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/berkerdemirel/ADRMX">https://github.com/berkerdemirel/ADRMX</a></li>
<li>paper_authors: Berker Demirel, Erchan Aptoula, Huseyin Ozkan</li>
<li>for: 这个研究旨在创建能够在新不同预设范围中具有普遍化能力的模型，以减少因为不同预设范围之间的分布变化对模型的影响。</li>
<li>methods: 这个研究使用了一种名为“Additive Disentanglement of Domain Features with Remix Loss”的新架构，并 introduce了一种新的数据增强技术，将不同预设范围中的数据混合在潜在空间中。</li>
<li>results: 这个研究透过对DomainBed进行了EXTENSIVE的实验，展示了ADRMX可以实现现场的表现，并且比以前的研究得到更好的结果。<details>
<summary>Abstract</summary>
The common assumption that train and test sets follow similar distributions is often violated in deployment settings. Given multiple source domains, domain generalization aims to create robust models capable of generalizing to new unseen domains. To this end, most of existing studies focus on extracting domain invariant features across the available source domains in order to mitigate the effects of inter-domain distributional changes. However, this approach may limit the model's generalization capacity by relying solely on finding common features among the source domains. It overlooks the potential presence of domain-specific characteristics that could be prevalent in a subset of domains, potentially containing valuable information. In this work, a novel architecture named Additive Disentanglement of Domain Features with Remix Loss (ADRMX) is presented, which addresses this limitation by incorporating domain variant features together with the domain invariant ones using an original additive disentanglement strategy. Moreover, a new data augmentation technique is introduced to further support the generalization capacity of ADRMX, where samples from different domains are mixed within the latent space. Through extensive experiments conducted on DomainBed under fair conditions, ADRMX is shown to achieve state-of-the-art performance. Code will be made available at GitHub after the revision process.
</details>
<details>
<summary>摘要</summary>
通常的假设是训练集和测试集都follow相似的分布是在部署设置中常常被违反。给定多个源领域，领域泛化目标是创建抗衰假设模型，以便在新未经见过的领域中泛化。为此，大多数现有的研究都是EXTRACTING DOMAIN INVARIANT FEATURES ACROSS AVAILABLE SOURCE DOMAINS，以mitigate INTER-DOMAIN distributional changes的影响。然而，这种方法可能会限制模型的泛化能力，因为它只是在 source domains 中找到共同特征。它忽略了可能存在一些领域特有的特征，这些特征可能在一些领域中具有价值信息。在这项工作中，一种新的架构名为 Additive Disentanglement of Domain Features with Remix Loss (ADRMX) 被提出，它解决了这种限制，通过将领域特征和领域 invariants 相加拼接在一起。此外，一种新的数据增强技术也被引入，用于进一步支持 ADRMX 的泛化能力，其中不同领域的样本在离散空间中混合。通过对 DomainBed 进行了广泛的实验，ADRMX 在 fair 的条件下显示出了状态的表现。代码将在 GitHub 上提供。
</details></li>
</ul>
<hr>
<h2 id="Can-Unstructured-Pruning-Reduce-the-Depth-in-Deep-Neural-Networks"><a href="#Can-Unstructured-Pruning-Reduce-the-Depth-in-Deep-Neural-Networks" class="headerlink" title="Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?"></a>Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06619">http://arxiv.org/abs/2308.06619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhu Liao, Victor Quétu, Van-Tam Nguyen, Enzo Tartaglione</li>
<li>for: 降低深度神经网络大小 while maintaining performance</li>
<li>methods: 基于Entropy Guided Pruning算法，优先遍历层次 entropy 低的连接，进行完全移除</li>
<li>results: 成功地压缩深度神经网络，保持竞争力水平，并提供了关于不结构压缩的机制和深度学习性能之间的新的视角。<details>
<summary>Abstract</summary>
Pruning is a widely used technique for reducing the size of deep neural networks while maintaining their performance. However, such a technique, despite being able to massively compress deep models, is hardly able to remove entire layers from a model (even when structured): is this an addressable task? In this study, we introduce EGP, an innovative Entropy Guided Pruning algorithm aimed at reducing the size of deep neural networks while preserving their performance. The key focus of EGP is to prioritize pruning connections in layers with low entropy, ultimately leading to their complete removal. Through extensive experiments conducted on popular models like ResNet-18 and Swin-T, our findings demonstrate that EGP effectively compresses deep neural networks while maintaining competitive performance levels. Our results not only shed light on the underlying mechanism behind the advantages of unstructured pruning, but also pave the way for further investigations into the intricate relationship between entropy, pruning techniques, and deep learning performance. The EGP algorithm and its insights hold great promise for advancing the field of network compression and optimization. The source code for EGP is released open-source.
</details>
<details>
<summary>摘要</summary>
剪辑是一种广泛使用的技术，用于降低深度神经网络的大小，保持性能。然而，这种技术，即使可以压缩深度模型，几乎不能完全移除层（即使是结构化的）：是这个任务可行吗？在这项研究中，我们介绍了EGP算法，一种创新的熵导向剪辑算法，用于减少深度神经网络的大小，保持性能。EGP的关键点在于优先剪辑层中的熵低的连接，以便完全移除它们。我们在popular模型如ResNet-18和Swin-T等模型上进行了广泛的实验，发现EGP有效地减少深度神经网络的大小，保持竞争力水平。我们的研究不仅解释了不结构化剪辑的优势，还为深度学习性能和剪辑技术之间的复杂关系开辟了新的可能性。EGP算法和其洞见拥有很大的潜力，可以推动深度神经网络压缩和优化领域的进步。EGP算法的源代码已经开源。
</details></li>
</ul>
<hr>
<h2 id="On-the-Interplay-of-Convolutional-Padding-and-Adversarial-Robustness"><a href="#On-the-Interplay-of-Convolutional-Padding-and-Adversarial-Robustness" class="headerlink" title="On the Interplay of Convolutional Padding and Adversarial Robustness"></a>On the Interplay of Convolutional Padding and Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06612">http://arxiv.org/abs/2308.06612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Gavrikov, Janis Keuper</li>
<li>for: 本文旨在研究padding和敌意攻击之间的交互关系，以及不同padding模式对敌意Robustness的影响。</li>
<li>methods: 本文使用Convolutional Neural Networks (CNN)进行研究，并对不同padding模式进行比较。</li>
<li>results: 本文发现，敌意攻击通常会导致图像边界上的异常，这些异常与padding有关。此外，本文还发现不同padding模式对敌意Robustness的影响不同。<details>
<summary>Abstract</summary>
It is common practice to apply padding prior to convolution operations to preserve the resolution of feature-maps in Convolutional Neural Networks (CNN). While many alternatives exist, this is often achieved by adding a border of zeros around the inputs. In this work, we show that adversarial attacks often result in perturbation anomalies at the image boundaries, which are the areas where padding is used. Consequently, we aim to provide an analysis of the interplay between padding and adversarial attacks and seek an answer to the question of how different padding modes (or their absence) affect adversarial robustness in various scenarios.
</details>
<details>
<summary>摘要</summary>
通常来说，在卷积神经网络（CNN）中， pading 被用来保持特征地图的分辨率。虽然有很多方法可供选择，但通常是通过在输入添加一个边界的零值来实现。在这项工作中，我们发现了一个现象：攻击者经常在图像边界处引起异常的杂变，这些区域 precisly 是在 padding 中使用的地方。因此，我们想进行 padding 和攻击者之间的分析，并问到不同的 padding 模式（或其缺失）对于不同的场景中的鲁棒性有什么影响。
</details></li>
</ul>
<hr>
<h2 id="LadleNet-Translating-Thermal-Infrared-Images-to-Visible-Light-Images-Using-A-Scalable-Two-stage-U-Net"><a href="#LadleNet-Translating-Thermal-Infrared-Images-to-Visible-Light-Images-Using-A-Scalable-Two-stage-U-Net" class="headerlink" title="LadleNet: Translating Thermal Infrared Images to Visible Light Images Using A Scalable Two-stage U-Net"></a>LadleNet: Translating Thermal Infrared Images to Visible Light Images Using A Scalable Two-stage U-Net</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06603">http://arxiv.org/abs/2308.06603</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ach-1914/ladlenet">https://github.com/ach-1914/ladlenet</a></li>
<li>paper_authors: Tonghui Zou</li>
<li>for: 该 paper 的目的是提出一种基于 U-Net 架构的算法，用于将thermal infrared（TIR）图像转换为可见光（VI）图像，以满足不同领域的应用需求。</li>
<li>methods: 该算法使用了两个阶段的 U-Net  concatenation结构，以及缺省连接和精细特征聚合技术，从而提高模型性能。该算法包括 ‘Handle’ 模块和 ‘Bowl’ 模块，其中 ‘Handle’ 模块建立了一个抽象的 semantic space，而 ‘Bowl’ 模块将该 semantic space 转换为封装的 VI 图像。</li>
<li>results:  comparing to existing methodologies, 该方法在 KAIST 数据集上测试得到了最佳性能，包括图像清晰度和感知质量。<details>
<summary>Abstract</summary>
The translation of thermal infrared (TIR) images to visible light (VI) images presents a challenging task with potential applications spanning various domains such as TIR-VI image registration and fusion. Leveraging supplementary information derived from TIR image conversions can significantly enhance model performance and generalization across these applications. However, prevailing issues within this field include suboptimal image fidelity and limited model scalability. In this paper, we introduce an algorithm, LadleNet, based on the U-Net architecture. LadleNet employs a two-stage U-Net concatenation structure, augmented with skip connections and refined feature aggregation techniques, resulting in a substantial enhancement in model performance. Comprising 'Handle' and 'Bowl' modules, LadleNet's Handle module facilitates the construction of an abstract semantic space, while the Bowl module decodes this semantic space to yield mapped VI images. The Handle module exhibits extensibility by allowing the substitution of its network architecture with semantic segmentation networks, thereby establishing more abstract semantic spaces to bolster model performance. Consequently, we propose LadleNet+, which replaces LadleNet's Handle module with the pre-trained DeepLabv3+ network, thereby endowing the model with enhanced semantic space construction capabilities. The proposed method is evaluated and tested on the KAIST dataset, accompanied by quantitative and qualitative analyses. Compared to existing methodologies, our approach achieves state-of-the-art performance in terms of image clarity and perceptual quality. The source code will be made available at https://github.com/Ach-1914/LadleNet/tree/main/.
</details>
<details>
<summary>摘要</summary>
文本翻译：thermal infrared（TIR）图像到可见光（VI）图像的翻译问题具有广泛的应用领域，如TIR-VI图像匹配和融合。利用TIR图像的补充信息可以大幅提高模型性能和泛化性。然而，现有的问题包括图像质量不佳和模型缺乏扩展性。本文介绍一种算法，叫做LadleNet，基于U-Net架构。LadleNet使用了两个阶段的U-Net concatenation结构，加上了跳过连接和细化特征聚合技术，从而实现了显著提高模型性能。LadleNet包括“ Handle”和“Bowl”模块，其中“ Handle”模块建立了一个抽象的语义空间，而“Bowl”模块将这个语义空间转换成VI图像。“ Handle”模块具有扩展性，可以将其网络架构替换为语义分割网络，从而建立更加抽象的语义空间，提高模型性能。因此，我们提出了LadleNet+，其替换了LadleNet的“ Handle”模块，使用了预训练的DeepLabv3+网络，从而为模型增加了更多的语义空间建构能力。我们的方法在KAIST数据集上进行了评估和测试，并进行了量化和质量分析。与现有方法相比，我们的方法在图像清晰度和感知质量方面达到了国际前ier的性能。代码将在https://github.com/Ach-1914/LadleNet/tree/main/中提供。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/13/cs.LG_2023_08_13/" data-id="cloq1wl7600np7o887qnp3hqw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_13" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/13/eess.IV_2023_08_13/" class="article-date">
  <time datetime="2023-08-13T09:00:00.000Z" itemprop="datePublished">2023-08-13</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/13/eess.IV_2023_08_13/">eess.IV - 2023-08-13</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Shape-guided-Conditional-Latent-Diffusion-Models-for-Synthesising-Brain-Vasculature"><a href="#Shape-guided-Conditional-Latent-Diffusion-Models-for-Synthesising-Brain-Vasculature" class="headerlink" title="Shape-guided Conditional Latent Diffusion Models for Synthesising Brain Vasculature"></a>Shape-guided Conditional Latent Diffusion Models for Synthesising Brain Vasculature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06781">http://arxiv.org/abs/2308.06781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yash Deo, Haoran Dou, Nishant Ravikumar, Alejandro F. Frangi, Toni Lassila</li>
<li>for: 了解脑血管系统中圆形封闭（Circle of Willis，CoW）的多样性和配置，以提高脑血管疾病研究和临床 intervención的精度。</li>
<li>methods: 使用条件潜在扩散模型（conditional latent diffusion model），包括形态和解剖指导，生成真实的3D CoW分割结果，包括不同的现象型变化。</li>
<li>results: 比较 conditional variants of 3D GAN和3D VAE的模型，发现我们的模型能够更好地保持血管连续性，并且生成的CoW变化更加真实，FID分数比最佳performing GAN-based model高53%。<details>
<summary>Abstract</summary>
The Circle of Willis (CoW) is the part of cerebral vasculature responsible for delivering blood to the brain. Understanding the diverse anatomical variations and configurations of the CoW is paramount to advance research on cerebrovascular diseases and refine clinical interventions. However, comprehensive investigation of less prevalent CoW variations remains challenging because of the dominance of a few commonly occurring configurations. We propose a novel generative approach utilising a conditional latent diffusion model with shape and anatomical guidance to generate realistic 3D CoW segmentations, including different phenotypical variations. Our conditional latent diffusion model incorporates shape guidance to better preserve vessel continuity and demonstrates superior performance when compared to alternative generative models, including conditional variants of 3D GAN and 3D VAE. We observed that our model generated CoW variants that are more realistic and demonstrate higher visual fidelity than competing approaches with an FID score 53\% better than the best-performing GAN-based model.
</details>
<details>
<summary>摘要</summary>
圆形维利斯（CoW）是脑血管系统的一部分，负责将血液传递到脑中。了解不同的静脉维利斯变化和配置是研究脑血管疾病的前进和精细化临床 intervención的关键。然而，对于较少seen CoW变化的全面调查仍然是挑战，因为一些常见的配置占据了主导地位。我们提出了一种新的生成方法，使用conditioned latent diffusion模型，包含形态指导，以生成真实的3D CoW分割，包括不同的现象变化。我们的conditioned latent diffusion模型能够更好地保持血管连续性，并与其他生成模型相比，如3D GAN和3D VAE的conditioned变种，显示出更高的性能。我们发现，我们的模型生成的CoW变化比competing approach更真实，Visual fidelity高于53%。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Image-Denoising-in-Real-World-Scenarios-via-Self-Collaboration-Parallel-Generative-Adversarial-Branches"><a href="#Unsupervised-Image-Denoising-in-Real-World-Scenarios-via-Self-Collaboration-Parallel-Generative-Adversarial-Branches" class="headerlink" title="Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches"></a>Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06776">http://arxiv.org/abs/2308.06776</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linxin0/scpgabnet">https://github.com/linxin0/scpgabnet</a></li>
<li>paper_authors: Xin Lin, Chao Ren, Xiao Liu, Jie Huang, Yinjie Lei</li>
<li>for: 提高无监督图像净化的性能，不需要大量的对称数据。</li>
<li>methods: 基于生成敌对网络的Unsupervised Approach， iteratively replace previous less powerful denoiser with current powerful denoiser， generate better synthetic clean-noisy image pairs。</li>
<li>results: 比 state-of-the-art unsupervised方法有更好的性能。<details>
<summary>Abstract</summary>
Deep learning methods have shown remarkable performance in image denoising, particularly when trained on large-scale paired datasets. However, acquiring such paired datasets for real-world scenarios poses a significant challenge. Although unsupervised approaches based on generative adversarial networks offer a promising solution for denoising without paired datasets, they are difficult in surpassing the performance limitations of conventional GAN-based unsupervised frameworks without significantly modifying existing structures or increasing the computational complexity of denoisers. To address this problem, we propose a SC strategy for multiple denoisers. This strategy can achieve significant performance improvement without increasing the inference complexity of the GAN-based denoising framework. Its basic idea is to iteratively replace the previous less powerful denoiser in the filter-guided noise extraction module with the current powerful denoiser. This process generates better synthetic clean-noisy image pairs, leading to a more powerful denoiser for the next iteration. This baseline ensures the stability and effectiveness of the training network. The experimental results demonstrate the superiority of our method over state-of-the-art unsupervised methods.
</details>
<details>
<summary>摘要</summary>
深度学习方法在图像噪声除除表现出了惊人的表现，特别是在大规模对应数据集上训练的情况下。然而，在真实世界场景中获得对应数据集的获得是一项重要挑战。 Although 无监督方法基于生成对抗网络提供了一种噪声除除无需对应数据集的解决方案，但它们在不改变现有结构或提高噪声除除器的计算复杂度下难以超越传统GAN基于无监督框架的性能限制。为解决这个问题，我们提议了SC策略 для多个噪声除除器。这种策略可以在不增加GAN基于噪声除除框架的推理复杂度下实现显著性能提高。其基本思想是在滤波器引导噪声提取模块中，逐次将前一个较弱的噪声除除器 replaced 为当前更强的噪声除除器。这个过程生成了更好的人工干扰净损像对，导致更强的噪声除除器。这个基准保证了训练网络的稳定性和效果。实验结果表明，我们的方法在无监督方法中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Tissue-Segmentation-of-Thick-Slice-Fetal-Brain-MR-Scans-with-Guidance-from-High-Quality-Isotropic-Volumes"><a href="#Tissue-Segmentation-of-Thick-Slice-Fetal-Brain-MR-Scans-with-Guidance-from-High-Quality-Isotropic-Volumes" class="headerlink" title="Tissue Segmentation of Thick-Slice Fetal Brain MR Scans with Guidance from High-Quality Isotropic Volumes"></a>Tissue Segmentation of Thick-Slice Fetal Brain MR Scans with Guidance from High-Quality Isotropic Volumes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06762">http://arxiv.org/abs/2308.06762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Huang, Xukun Zhang, Zhiming Cui, He Zhang, Geng Chen, Dinggang Shen</li>
<li>for: 这个研究的目的是提高胎儿脑MR扫描中的组织分类精度，以便重建iso类型脑MR扫描 volume 和评估胎儿脑发展。</li>
<li>methods: 这个研究使用了域 adaptation 技术，将高品质的iso类型脑MR扫描 volume 作为指导，对厚层扫描进行组织分类。</li>
<li>results: 实验结果显示，这个方法可以对胎儿脑MR扫描中的组织分类进行高精度的调整，并且与现有的方法相比，表现更加出色。<details>
<summary>Abstract</summary>
Accurate tissue segmentation of thick-slice fetal brain magnetic resonance (MR) scans is crucial for both reconstruction of isotropic brain MR volumes and the quantification of fetal brain development. However, this task is challenging due to the use of thick-slice scans in clinically-acquired fetal brain data. To address this issue, we propose to leverage high-quality isotropic fetal brain MR volumes (and also their corresponding annotations) as guidance for segmentation of thick-slice scans. Due to existence of significant domain gap between high-quality isotropic volume (i.e., source data) and thick-slice scans (i.e., target data), we employ a domain adaptation technique to achieve the associated knowledge transfer (from high-quality <source> volumes to thick-slice <target> scans). Specifically, we first register the available high-quality isotropic fetal brain MR volumes across different gestational weeks to construct longitudinally-complete source data. To capture domain-invariant information, we then perform Fourier decomposition to extract image content and style codes. Finally, we propose a novel Cycle-Consistent Domain Adaptation Network (C2DA-Net) to efficiently transfer the knowledge learned from high-quality isotropic volumes for accurate tissue segmentation of thick-slice scans. Our C2DA-Net can fully utilize a small set of annotated isotropic volumes to guide tissue segmentation on unannotated thick-slice scans. Extensive experiments on a large-scale dataset of 372 clinically acquired thick-slice MR scans demonstrate that our C2DA-Net achieves much better performance than cutting-edge methods quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
幼虫脑magnetic resonance（MR）扫描的粗层扫描是重要的，因为它们可以提供高级别的脑部MR影像Volume，并且可以量化胎儿脑部发展的进度。然而，这个任务具有挑战性，因为在临床中获取的胎儿脑部MR扫描通常使用粗层扫描。为解决这个问题，我们提议使用高质量的ISO分布式胎儿脑MR影像（以及其相应的标注）作为指导，以实现粗层扫描的准确分割。由于源数据和目标数据之间存在很大的领域差异，我们采用领域适应技术来实现相关的知识传递。具体来说，我们首先将可用的高质量ISO分布式胎儿脑MR影像长itudinally完整地注册，以构建不同 gestational weeks的源数据。然后，我们使用快速 Fourier 分解来提取图像内容和风格代码。最后，我们提出了一种名为C2DA-Net的循环一致领域适应网络，以高效地传递从高质量ISO分布式胎儿脑MR影像中学习的知识，以便在无标注的粗层扫描中进行准确的组织分割。我们的C2DA-Net可以全面利用一小组标注的ISO分布式胎儿脑MR影像来导导粗层扫描中的组织分割。我们在372个临床获取的粗层扫描中进行了广泛的实验，并证明了我们的C2DA-Net可以在量化和质量上superior于当前的方法。
</details></li>
</ul>
<hr>
<h2 id="FastLLVE-Real-Time-Low-Light-Video-Enhancement-with-Intensity-Aware-Lookup-Table"><a href="#FastLLVE-Real-Time-Low-Light-Video-Enhancement-with-Intensity-Aware-Lookup-Table" class="headerlink" title="FastLLVE: Real-Time Low-Light Video Enhancement with Intensity-Aware Lookup Table"></a>FastLLVE: Real-Time Low-Light Video Enhancement with Intensity-Aware Lookup Table</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06749">http://arxiv.org/abs/2308.06749</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenhao-li-777/fastllve">https://github.com/wenhao-li-777/fastllve</a></li>
<li>paper_authors: Wenhao Li, Guangyang Wu, Wenyi Wang, Peiran Ren, Xiaohong Liu</li>
<li>for: 提高低光照视频质量</li>
<li>methods: 利用Look-Up-Table（LUT）技术维护 между帧亮度一致性，并设计了一个可学习的Intensity-Aware LUT（IA-LUT）模块进行自适应增强。</li>
<li>results: 实验结果表明，我们的方法可以在标准数据集上达到最新状态的性能，同时在帧速和计算复杂度方面也具有优势。 Code available at <a target="_blank" rel="noopener" href="https://github.com/Wenhao-Li-777/FastLLVE">https://github.com/Wenhao-Li-777/FastLLVE</a>.<details>
<summary>Abstract</summary>
Low-Light Video Enhancement (LLVE) has received considerable attention in recent years. One of the critical requirements of LLVE is inter-frame brightness consistency, which is essential for maintaining the temporal coherence of the enhanced video. However, most existing single-image-based methods fail to address this issue, resulting in flickering effect that degrades the overall quality after enhancement. Moreover, 3D Convolution Neural Network (CNN)-based methods, which are designed for video to maintain inter-frame consistency, are computationally expensive, making them impractical for real-time applications. To address these issues, we propose an efficient pipeline named FastLLVE that leverages the Look-Up-Table (LUT) technique to maintain inter-frame brightness consistency effectively. Specifically, we design a learnable Intensity-Aware LUT (IA-LUT) module for adaptive enhancement, which addresses the low-dynamic problem in low-light scenarios. This enables FastLLVE to perform low-latency and low-complexity enhancement operations while maintaining high-quality results. Experimental results on benchmark datasets demonstrate that our method achieves the State-Of-The-Art (SOTA) performance in terms of both image quality and inter-frame brightness consistency. More importantly, our FastLLVE can process 1,080p videos at $\mathit{50+}$ Frames Per Second (FPS), which is $\mathit{2 \times}$ faster than SOTA CNN-based methods in inference time, making it a promising solution for real-time applications. The code is available at https://github.com/Wenhao-Li-777/FastLLVE.
</details>
<details>
<summary>摘要</summary>
低光照视频增强（LLVE）在最近几年内受到了广泛关注。一个关键的要求是 между帧亮度一致性，以保持视频增强后的时间一致性。然而，大多数现有的单张图像基的方法无法解决这个问题，导致幻灯效应，从而降低了整体质量。此外，基于3D卷积神经网络（CNN）的方法，它们是为视频维护 между帧一致性而设计的，但是计算成本高，使其不适用于实时应用。为解决这些问题，我们提出了高效的渠道名为快速LLVE，利用Look-Up-Table（LUT）技术来维护between帧亮度一致性。我们特制了可学习的Intensity-Aware LUT（IA-LUT）模块，用于适应增强，解决低动态问题在低光照场景中。这使得快速LLVE可以在低延迟和低复杂度下进行增强操作，同时维护高质量结果。实验结果表明，我们的方法在标准数据集上达到了状态之作（SOTA）的性能， both图像质量和between帧亮度一致性方面。此外，我们的快速LLVE可以处理1080P视频，在50+帧每秒（FPS）处理速度，高于SOTA CNN基于方法的两倍即2倍的执行速度，这使得它在实时应用中成为一个有前途的解决方案。代码可以在https://github.com/Wenhao-Li-777/FastLLVE中找到。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Noise2noise-Method-Utilizing-Corrupted-Images-with-a-Modular-Network-for-LDCT-Denoising"><a href="#Self-supervised-Noise2noise-Method-Utilizing-Corrupted-Images-with-a-Modular-Network-for-LDCT-Denoising" class="headerlink" title="Self-supervised Noise2noise Method Utilizing Corrupted Images with a Modular Network for LDCT Denoising"></a>Self-supervised Noise2noise Method Utilizing Corrupted Images with a Modular Network for LDCT Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06746">http://arxiv.org/abs/2308.06746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xyuan01/self-supervised-noise2noise-for-ldct">https://github.com/xyuan01/self-supervised-noise2noise-for-ldct</a></li>
<li>paper_authors: Yuting Zhu, Qiang He, Yudong Yao, Yueyang Teng</li>
<li>for: 这个研究旨在提出一种基于单束 Computed Tomography (CT) 影像的自我监督噪声降低方法，不需要对CT影像进行训练。</li>
<li>methods: 本研究使用了一种组合自我监督噪声模型和降低噪声的方法，首先将LDCT影像添加了两种相似的噪声，然后使用这些降低噪声的影像进行训练。</li>
<li>results: 实验结果显示，提出的方法比前一代深度学习方法更有效地进行LDCT影像降低噪声。<details>
<summary>Abstract</summary>
Deep learning is a very promising technique for low-dose computed tomography (LDCT) image denoising. However, traditional deep learning methods require paired noisy and clean datasets, which are often difficult to obtain. This paper proposes a new method for performing LDCT image denoising with only LDCT data, which means that normal-dose CT (NDCT) is not needed. We adopt a combination including the self-supervised noise2noise model and the noisy-as-clean strategy. First, we add a second yet similar type of noise to LDCT images multiple times. Note that we use LDCT images based on the noisy-as-clean strategy for corruption instead of NDCT images. Then, the noise2noise model is executed with only the secondary corrupted images for training. We select a modular U-Net structure from several candidates with shared parameters to perform the task, which increases the receptive field without increasing the parameter size. The experimental results obtained on the Mayo LDCT dataset show the effectiveness of the proposed method compared with that of state-of-the-art deep learning methods. The developed code is available at https://github.com/XYuan01/Self-supervised-Noise2Noise-for-LDCT.
</details>
<details>
<summary>摘要</summary>
深度学习是LDCT图像减噪的非常有前途的技术。然而，传统的深度学习方法通常需要配备零噪和干净的数据集，这些数据集往往很难获得。这篇论文提出了一种只使用LDCT数据进行LDCT图像减噪的新方法。我们采用了一种组合，包括自我监督的噪声2噪模型和噪声作为干净策略。首先，我们将LDCT图像添加了多次相似的噪声。注意我们使用LDCT图像来代替NDCT图像进行损害。然后，我们在噪声2噪模型中进行训练，只使用第二次损害的图像。我们选择了一个模块化U-Net结构，从多个候选者中选择了共享参数来完成任务，这样可以增加感知范围而不是增加参数大小。实验结果表明，提出的方法在Mayo LDCT数据集上比州前的深度学习方法更有效。代码可以在https://github.com/XYuan01/Self-supervised-Noise2Noise-for-LDCT上下载。
</details></li>
</ul>
<hr>
<h2 id="Polyp-SAM-Can-A-Text-Guided-SAM-Perform-Better-for-Polyp-Segmentation"><a href="#Polyp-SAM-Can-A-Text-Guided-SAM-Perform-Better-for-Polyp-Segmentation" class="headerlink" title="Polyp-SAM++: Can A Text Guided SAM Perform Better for Polyp Segmentation?"></a>Polyp-SAM++: Can A Text Guided SAM Perform Better for Polyp Segmentation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06623">http://arxiv.org/abs/2308.06623</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RisabBiswas/Polyp-SAM-PlusPlus">https://github.com/RisabBiswas/Polyp-SAM-PlusPlus</a></li>
<li>paper_authors: Risab Biswas</li>
<li>for: 这个论文的目的是提高肿瘤 segmentation 的精度和稳定性，并通过文本提示来使用 SAM 模型进行肿瘤 segmentation。</li>
<li>methods: 这个论文使用的方法是使用文本提示来提高 SAM 模型的精度和稳定性，并在 benchmark 数据集上进行评估。</li>
<li>results: 研究发现，使用文本提示可以提高 SAM 模型的肿瘤 segmentation 精度和稳定性，并且比不使用文本提示的情况下更好。<details>
<summary>Abstract</summary>
Meta recently released SAM (Segment Anything Model) which is a general-purpose segmentation model. SAM has shown promising results in a wide variety of segmentation tasks including medical image segmentation. In the field of medical image segmentation, polyp segmentation holds a position of high importance, thus creating a model which is robust and precise is quite challenging. Polyp segmentation is a fundamental task to ensure better diagnosis and cure of colorectal cancer. As such in this study, we will see how Polyp-SAM++, a text prompt-aided SAM, can better utilize a SAM using text prompting for robust and more precise polyp segmentation. We will evaluate the performance of a text-guided SAM on the polyp segmentation task on benchmark datasets. We will also compare the results of text-guided SAM vs unprompted SAM. With this study, we hope to advance the field of polyp segmentation and inspire more, intriguing research. The code and other details will be made publically available soon at https://github.com/RisabBiswas/Polyp-SAM++.
</details>
<details>
<summary>摘要</summary>
meta 最近发布了 SAM（分割任务模型），这是一种通用的分割模型。SAM 在多种分割任务中表现出色，包括医疗影像分割。在医疗影像分割领域，肿瘤分割具有非常高的重要性，因此创建一个精度高和可靠的模型是非常挑战性的。肿瘤分割是诊断和治疗抑郁癌的基本任务。在本研究中，我们将看到 Polyp-SAM++，一种使用文本提示的 SAM，如何更好地利用 SAM 进行肿瘤分割。我们将对 Polyp-SAM++ 在标准数据集上进行评估，并与不提示 SAM 进行比较。我们希望通过这项研究，推动肿瘤分割领域的进步，并鼓励更多的感人研究。代码和其他细节将在https://github.com/RisabBiswas/Polyp-SAM++ 上公开。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/13/eess.IV_2023_08_13/" data-id="cloq1wle6015a7o88e8uih111" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.SD_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T15:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/cs.SD_2023_08_12/">cs.SD - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Alternative-Pseudo-Labeling-for-Semi-Supervised-Automatic-Speech-Recognition"><a href="#Alternative-Pseudo-Labeling-for-Semi-Supervised-Automatic-Speech-Recognition" class="headerlink" title="Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech Recognition"></a>Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06547">http://arxiv.org/abs/2308.06547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Zhu, Dongji Gao, Gaofeng Cheng, Daniel Povey, Pengyuan Zhang, Yonghong Yan</li>
<li>for: 提高自动语音识别器的性能在半监督学习中，当 Label 缺乏时</li>
<li>methods: 提议一种新的替代 pseudo-labeling 框架，包括一种通用的 CTC 损失函数、一种 confidence-based 错误检测方法和一种自动调整 threshold 方法</li>
<li>results: 对比 traditional CTC 损失函数和 confidence-based 错误检测方法，提议的替代 pseudo-labeling 框架可以更好地处理含有错误 tokens 的 pseudo-Label，并且不需要手动调整 threshold<details>
<summary>Abstract</summary>
When labeled data is insufficient, semi-supervised learning with the pseudo-labeling technique can significantly improve the performance of automatic speech recognition. However, pseudo-labels are often noisy, containing numerous incorrect tokens. Taking noisy labels as ground-truth in the loss function results in suboptimal performance. Previous works attempted to mitigate this issue by either filtering out the nosiest pseudo-labels or improving the overall quality of pseudo-labels. While these methods are effective to some extent, it is unrealistic to entirely eliminate incorrect tokens in pseudo-labels. In this work, we propose a novel framework named alternative pseudo-labeling to tackle the issue of noisy pseudo-labels from the perspective of the training objective. The framework comprises several components. Firstly, a generalized CTC loss function is introduced to handle noisy pseudo-labels by accepting alternative tokens in the positions of incorrect tokens. Applying this loss function in pseudo-labeling requires detecting incorrect tokens in the predicted pseudo-labels. In this work, we adopt a confidence-based error detection method that identifies the incorrect tokens by comparing their confidence scores with a given threshold, thus necessitating the confidence score to be discriminative. Hence, the second proposed technique is the contrastive CTC loss function that widens the confidence gap between the correctly and incorrectly predicted tokens, thereby improving the error detection ability. Additionally, obtaining satisfactory performance with confidence-based error detection typically requires extensive threshold tuning. Instead, we propose an automatic thresholding method that uses labeled data as a proxy for determining the threshold, thus saving the pain of manual tuning.
</details>
<details>
<summary>摘要</summary>
当标注数据短缺时，半超vised学习采用pseudo-标签技术可以显著提高自动语音识别的性能。然而，pseudo-标签经常含有许多错误的token。将含有错误token的pseudo-标签作为真实标签在损失函数中使用会导致优化性能下降。前一些工作尝试了通过过滤 pseudo-标签中最含糟糕的token或提高总体pseudo-标签质量来缓解这个问题。虽然这些方法有一定的效果，但是完全消除pseudo-标签中的错误token是不现实的。在这种情况下，我们提出了一种新的框架名为代理 pseudo-标签。该框架包括以下几个组成部分。首先，我们引入一种通用的CTC损失函数，可以处理含有错误token的pseudo-标签。在使用这种损失函数进行pseudo-标签时，需要检测pseudo-标签中的错误token。在这种情况下，我们采用一种 confidence-based 错误检测方法，通过比较错误token的信任分数与一个给定的阈值，以确定错误token的存在。因此，第二个提出的技术是增强CTC损失函数，以增强错误检测的能力。此外，通过 confidence-based 错误检测获得良好性能通常需要进行广泛的阈值调整。而我们提出的自动阈值调整方法，通过使用标注数据作为代理，自动地调整阈值，从而避免了手动调整的痛苦。
</details></li>
</ul>
<hr>
<h2 id="BigWavGAN-A-Wave-To-Wave-Generative-Adversarial-Network-for-Music-Super-Resolution"><a href="#BigWavGAN-A-Wave-To-Wave-Generative-Adversarial-Network-for-Music-Super-Resolution" class="headerlink" title="BigWavGAN: A Wave-To-Wave Generative Adversarial Network for Music Super-Resolution"></a>BigWavGAN: A Wave-To-Wave Generative Adversarial Network for Music Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06483">http://arxiv.org/abs/2308.06483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yenan Zhang, Hiroshi Watanabe</li>
<li>for: 这个论文目的是提高音乐超解析（SR）领域中深度神经网络（DNN）的性能。</li>
<li>methods: 这个论文使用了大型DNN模型，并结合了State-Of-The-Art（SOTA）的激励函数和对抗训练策略。它的权衡器包括多尺度权衡器（MSD）和多分辨率权衡器（MRD）。</li>
<li>results: 对于音乐SR问题，BigWavGAN模型表现出色，超过了基eline模型和State-Of-The-Art（SOTA）音乐SR模型。它还能够处理异常数据，并且有较好的总体化能力。<details>
<summary>Abstract</summary>
Generally, Deep Neural Networks (DNNs) are expected to have high performance when their model size is large. However, large models failed to produce high-quality results commensurate with their scale in music Super-Resolution (SR). We attribute this to that DNNs cannot learn information commensurate with their size from standard mean square error losses. To unleash the potential of large DNN models in music SR, we propose BigWavGAN, which incorporates Demucs, a large-scale wave-to-wave model, with State-Of-The-Art (SOTA) discriminators and adversarial training strategies. Our discriminator consists of Multi-Scale Discriminator (MSD) and Multi-Resolution Discriminator (MRD). During inference, since only the generator is utilized, there are no additional parameters or computational resources required compared to the baseline model Demucs. Objective evaluation affirms the effectiveness of BigWavGAN in music SR. Subjective evaluations indicate that BigWavGAN can generate music with significantly high perceptual quality over the baseline model. Notably, BigWavGAN surpasses the SOTA music SR model in both simulated and real-world scenarios. Moreover, BigWavGAN represents its superior generalization ability to address out-of-distribution data. The conducted ablation study reveals the importance of our discriminators and training strategies. Samples are available on the demo page.
</details>
<details>
<summary>摘要</summary>
通常情况下，深度神经网络（DNNs）预期会在模型大小增加时表现出色。然而，大型模型在音乐超分解（SR）中并没有达到预期的高质量效果。我们认为这是因为DNNs无法从标准方差误差损失中学习足够的信息。为了解放大型DNN模型在音乐SR中的潜力，我们提出了BigWavGAN，它将大规模涉及的wave-to-wave模型Demucs融合到了领先的推误器和对抗训练策略中。我们的推误器包括多尺度推误器（MSD）和多分辨率推误器（MRD）。在推理过程中，由于只有生成器被使用，因此没有额外的参数或计算资源的需求，与基线模型Demucs相比。对象评估表明BigWavGAN在音乐SR中的效果非常高。主观评估表明BigWavGAN可以生成具有显著高媒体质量的音乐，比基线模型高。此外，BigWavGAN在实际和 simulate 的情况下都能够超越领先的音乐SR模型。此外，BigWavGAN在处理异常数据的能力方面表现出了superior的普适性。进行的ablation研究表明我们的推误器和训练策略的重要性。样例可以在 demo 页面中找到。
</details></li>
</ul>
<hr>
<h2 id="Bilingual-Streaming-ASR-with-Grapheme-units-and-Auxiliary-Monolingual-Loss"><a href="#Bilingual-Streaming-ASR-with-Grapheme-units-and-Auxiliary-Monolingual-Loss" class="headerlink" title="Bilingual Streaming ASR with Grapheme units and Auxiliary Monolingual Loss"></a>Bilingual Streaming ASR with Grapheme units and Auxiliary Monolingual Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06327">http://arxiv.org/abs/2308.06327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Soleymanpour, Mahmoud Al Ismail, Fahimeh Bahmaninezhad, Kshitiz Kumar, Jian Wu</li>
<li>for: 支持英语为次要地区的半自动语音识别（ASR）设置</li>
<li>methods: 使用全双语对照模型、双流Transformer模型、并行编码结构和语言标识（LID）损失</li>
<li>results: 提高英语混合码能力，对代码混合ES和IT应用进行大规模训练和测试，并显示出优于LID损失的特点<details>
<summary>Abstract</summary>
We introduce a bilingual solution to support English as secondary locale for most primary locales in hybrid automatic speech recognition (ASR) settings. Our key developments constitute: (a) pronunciation lexicon with grapheme units instead of phone units, (b) a fully bilingual alignment model and subsequently bilingual streaming transformer model, (c) a parallel encoder structure with language identification (LID) loss, (d) parallel encoder with an auxiliary loss for monolingual projections. We conclude that in comparison to LID loss, our proposed auxiliary loss is superior in specializing the parallel encoders to respective monolingual locales, and that contributes to stronger bilingual learning. We evaluate our work on large-scale training and test tasks for bilingual Spanish (ES) and bilingual Italian (IT) applications. Our bilingual models demonstrate strong English code-mixing capability. In particular, the bilingual IT model improves the word error rate (WER) for a code-mix IT task from 46.5% to 13.8%, while also achieving a close parity (9.6%) with the monolingual IT model (9.5%) over IT tests.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种双语解决方案，以支持英语为次要地区的多地点自动语音识别（ASR）设置。我们的关键发展包括：(a) 使用字节单位 вместоPhone单位的发音词典。(b)一个完全双语对应模型和随后的双语流transformer模型。(c)一个并行编码结构，并且添加语言标识（LID）损失。(d)并行编码器，并且添加一个辅助损失来特化到各自的单语言本地。我们结合了这些发展，并进行了大规模的训练和测试任务，以评估我们的方法在双语西班牙（ES）和双语意大利（IT）应用中的性能。我们的双语模型在英语混合码中表现出色，特别是双语IT模型在一个混合IT任务中，从46.5%降低到13.8%，同时也与单语意大利模型（9.5%）在意大利测试上凑平。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.SD_2023_08_12/" data-id="cloq1wl9u00uv7o88czdkdchj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.CV_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T13:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/cs.CV_2023_08_12/">cs.CV - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Cyclic-Test-Time-Adaptation-on-Monocular-Video-for-3D-Human-Mesh-Reconstruction"><a href="#Cyclic-Test-Time-Adaptation-on-Monocular-Video-for-3D-Human-Mesh-Reconstruction" class="headerlink" title="Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction"></a>Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06554">http://arxiv.org/abs/2308.06554</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hygenie1228/cycleadapt_release">https://github.com/hygenie1228/cycleadapt_release</a></li>
<li>paper_authors: Hyeongjin Nam, Daniel Sungho Jung, Yeonguk Oh, Kyoung Mu Lee</li>
<li>for:  addresses the domain gap problem in 3D human mesh reconstruction by proposing a cyclic adaptation method that leverages both 2D and 3D evidence.</li>
<li>methods:  the proposed method consists of two networks: a human mesh reconstruction network (HMRNet) and a human motion denoising network (MDNet), which are cyclically adapted given a test video. The 3D supervision targets generated by MDNet are used to fully supervise HMRNet, reducing the reliance on 2D evidence.</li>
<li>results:  the proposed method achieves state-of-the-art performance compared to previous test-time adaptation methods, demonstrating the effectiveness of the cyclic adaptation scheme in addressing the domain gap problem.<details>
<summary>Abstract</summary>
Despite recent advances in 3D human mesh reconstruction, domain gap between training and test data is still a major challenge. Several prior works tackle the domain gap problem via test-time adaptation that fine-tunes a network relying on 2D evidence (e.g., 2D human keypoints) from test images. However, the high reliance on 2D evidence during adaptation causes two major issues. First, 2D evidence induces depth ambiguity, preventing the learning of accurate 3D human geometry. Second, 2D evidence is noisy or partially non-existent during test time, and such imperfect 2D evidence leads to erroneous adaptation. To overcome the above issues, we introduce CycleAdapt, which cyclically adapts two networks: a human mesh reconstruction network (HMRNet) and a human motion denoising network (MDNet), given a test video. In our framework, to alleviate high reliance on 2D evidence, we fully supervise HMRNet with generated 3D supervision targets by MDNet. Our cyclic adaptation scheme progressively elaborates the 3D supervision targets, which compensate for imperfect 2D evidence. As a result, our CycleAdapt achieves state-of-the-art performance compared to previous test-time adaptation methods. The codes are available at https://github.com/hygenie1228/CycleAdapt_RELEASE.
</details>
<details>
<summary>摘要</summary>
尽管最近的3D人体渲染技术得到了进步，但域外差问题仍然是主要挑战。一些先前的工作通过测试时适应来解决域外差问题，但高度依赖于2D证据（例如2D人体关键点）的适应会导致两个主要问题。首先，2D证据引入深度不确定性，阻碍学习准确的3D人体几何学。其次，2D证据在测试时可能受到噪声或部分损失，这会导致错误的适应。为解决以上问题，我们介绍了CyclesAdapt，它将两个网络——人体渲染网络（HMRNet）和人体动作净化网络（MDNet）——在测试视频基础上进行循环适应。在我们的框架中，为了减少依赖于2D证据，我们完全supervise HMRNet 的生成3D目标，使其能够学习准确的3D人体几何学。我们的循环适应方案逐渐填充3D目标，以补做受到噪声或部分损失的2D证据。因此，我们的CyclesAdapt可以与之前的测试时适应方法相比，实现最新的表现。代码可以在https://github.com/hygenie1228/CycleAdapt_RELEASE 中找到。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Vision-Transformer-from-the-View-of-Path-Ensemble"><a href="#Revisiting-Vision-Transformer-from-the-View-of-Path-Ensemble" class="headerlink" title="Revisiting Vision Transformer from the View of Path Ensemble"></a>Revisiting Vision Transformer from the View of Path Ensemble</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06548">http://arxiv.org/abs/2308.06548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuning Chang, Pichao Wang, Hao Luo, Fan Wang, Mike Zheng Shou</li>
<li>for: 本文提出了一种新的视点，认为 transformer 层可以被看作是多个并行的路径 ensemble network。</li>
<li>methods: 将传统的多头自注意力（MSA）和Feed Forward Network（FFN）替换为三个并行的路径，并使用 identify connection 将这些路径转换为明确的多路ensemble network。</li>
<li>results: 通过调查每个路径对最终预测的影响，发现一些路径甚至会降低性能。因此，提出了路径裁剪和 EnsembleScale 技术来优化路径组合，以便允许短路专注提供高质量表示。此外，通过自馈沟通来增强 paths 服务后续路径的表示。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) are normally regarded as a stack of transformer layers. In this work, we propose a novel view of ViTs showing that they can be seen as ensemble networks containing multiple parallel paths with different lengths. Specifically, we equivalently transform the traditional cascade of multi-head self-attention (MSA) and feed-forward network (FFN) into three parallel paths in each transformer layer. Then, we utilize the identity connection in our new transformer form and further transform the ViT into an explicit multi-path ensemble network. From the new perspective, these paths perform two functions: the first is to provide the feature for the classifier directly, and the second is to provide the lower-level feature representation for subsequent longer paths. We investigate the influence of each path for the final prediction and discover that some paths even pull down the performance. Therefore, we propose the path pruning and EnsembleScale skills for improvement, which cut out the underperforming paths and re-weight the ensemble components, respectively, to optimize the path combination and make the short paths focus on providing high-quality representation for subsequent paths. We also demonstrate that our path combination strategies can help ViTs go deeper and act as high-pass filters to filter out partial low-frequency signals. To further enhance the representation of paths served for subsequent paths, self-distillation is applied to transfer knowledge from the long paths to the short paths. This work calls for more future research to explain and design ViTs from new perspectives.
</details>
<details>
<summary>摘要</summary>
视transformer（ViT）通常被看作是一 stack of transformer层。在这项工作中，我们提出了一种新的视图，显示了ViT可以被看作是一个多路网络，每个层包含多个平行的路径。 Specifically, we可以将传统的多头自注意（MSA）和Feed-Forward Network（FFN）转化为每个transformer层中的三个平行路径。然后，我们利用我们新的transformer形式中的标识连接，并将ViT转化为一个显式多路ensemble网络。从这种新的视角来看，这些路径在两个功能：第一是提供分类器所需的特征，第二是提供后续更长的路径所需的下一个特征表示。我们调查每个路径对最终预测的影响，发现一些路径甚至会降低性能。因此，我们提出了路径剔除和EnsembleScale技巧来优化路径组合，即将不良表现的路径剔除，并重新权重ensemble组件。我们还证明了我们的路径组合策略可以帮助ViT深入探索，并作为高通过滤器来过滤部分低频信号。为了进一步增强路径服务后续路径的表示，我们应用了自适应知识传递，将长路径中的知识传递给短路径。这项工作呼吁了更多的未来研究，以解释和设计ViT从新的视角。
</details></li>
</ul>
<hr>
<h2 id="SegPrompt-Boosting-Open-world-Segmentation-via-Category-level-Prompt-Learning"><a href="#SegPrompt-Boosting-Open-world-Segmentation-via-Category-level-Prompt-Learning" class="headerlink" title="SegPrompt: Boosting Open-world Segmentation via Category-level Prompt Learning"></a>SegPrompt: Boosting Open-world Segmentation via Category-level Prompt Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06531">http://arxiv.org/abs/2308.06531</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aim-uofa/segprompt">https://github.com/aim-uofa/segprompt</a></li>
<li>paper_authors: Muzhi Zhu, Hengtao Li, Hao Chen, Chengxiang Fan, Weian Mao, Chenchen Jing, Yifan Liu, Chunhua Shen</li>
<li>for: 提高closed-set实例分割模型对未知类别的检测能力</li>
<li>methods: 使用类别信息进行训练 Mechanism，提高模型对已知和未知类别的检测能力</li>
<li>results: 在新的开放世界数据集上，SegPrompt可以提高总和未知检测性能by 5.6%和6.1%，而无需影响推理效率。在 existed cross-dataset transfer和强烈监督设置下，我们的方法也得到了5.5%和12.3%的相对改进。<details>
<summary>Abstract</summary>
Current closed-set instance segmentation models rely on pre-defined class labels for each mask during training and evaluation, largely limiting their ability to detect novel objects. Open-world instance segmentation (OWIS) models address this challenge by detecting unknown objects in a class-agnostic manner. However, previous OWIS approaches completely erase category information during training to keep the model's ability to generalize to unknown objects. In this work, we propose a novel training mechanism termed SegPrompt that uses category information to improve the model's class-agnostic segmentation ability for both known and unknown categories. In addition, the previous OWIS training setting exposes the unknown classes to the training set and brings information leakage, which is unreasonable in the real world. Therefore, we provide a new open-world benchmark closer to a real-world scenario by dividing the dataset classes into known-seen-unseen parts. For the first time, we focus on the model's ability to discover objects that never appear in the training set images.   Experiments show that SegPrompt can improve the overall and unseen detection performance by 5.6% and 6.1% in AR on our new benchmark without affecting the inference efficiency. We further demonstrate the effectiveness of our method on existing cross-dataset transfer and strongly supervised settings, leading to 5.5% and 12.3% relative improvement.
</details>
<details>
<summary>摘要</summary>
当前的闭erset实例分割模型依赖于在训练和评估中预先定义的类标签，这限制了它们的能力检测新的对象。开放世界实例分割（OWIS）模型解决了这个挑战，它在无类别情况下检测未知对象。然而，前一些OWIS方法完全抹除了类型信息在训练中，以保持模型对未知类型的泛化能力。在这种情况下，我们提出了一种新的训练机制，称为SegPrompt，它使用类型信息来提高模型在已知和未知类型之间的无类别分割能力。此外，前一些OWIS训练设置会泄露信息，这不符合实际世界的情况。因此，我们提供了一个更加真实的开放世界 benchmark，将数据集分为已知、未seen和未知三部分。我们首次关注模型能够在训练集图像中不出现的对象检测能力。实验结果显示，SegPrompt可以在AR上提高总和未seen检测性能5.6%和6.1%，而不影响推理效率。我们还证明我们的方法在现有的跨数据集转移和强烈监督设置下有5.5%和12.3%的相对改进。
</details></li>
</ul>
<hr>
<h2 id="BEV-DG-Cross-Modal-Learning-under-Bird’s-Eye-View-for-Domain-Generalization-of-3D-Semantic-Segmentation"><a href="#BEV-DG-Cross-Modal-Learning-under-Bird’s-Eye-View-for-Domain-Generalization-of-3D-Semantic-Segmentation" class="headerlink" title="BEV-DG: Cross-Modal Learning under Bird’s-Eye View for Domain Generalization of 3D Semantic Segmentation"></a>BEV-DG: Cross-Modal Learning under Bird’s-Eye View for Domain Generalization of 3D Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06530">http://arxiv.org/abs/2308.06530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miaoyu Li, Yachao Zhang, Xu MA, Yanyun Qu, Yun Fu</li>
<li>for: 这篇论文旨在提高频率域执行3D semantic segmentation的预测性和灵活性，并且在新的频率域中进行预测，而不需要训练数据集。</li>
<li>methods: 这篇论文提出了一种基于鸟瞰看的cross-modal learning架构，具有更高的错误耐受性和稳定性，并且可以实现频率域内的预测。</li>
<li>results: 这篇论文透过三个不同的3D数据集进行评估，结果显示BEV-DG在所有设定中具有显著的性能优势，与现有的竞争者相比，BEV-DG的性能优势为10%左右。<details>
<summary>Abstract</summary>
Cross-modal Unsupervised Domain Adaptation (UDA) aims to exploit the complementarity of 2D-3D data to overcome the lack of annotation in a new domain. However, UDA methods rely on access to the target domain during training, meaning the trained model only works in a specific target domain. In light of this, we propose cross-modal learning under bird's-eye view for Domain Generalization (DG) of 3D semantic segmentation, called BEV-DG. DG is more challenging because the model cannot access the target domain during training, meaning it needs to rely on cross-modal learning to alleviate the domain gap. Since 3D semantic segmentation requires the classification of each point, existing cross-modal learning is directly conducted point-to-point, which is sensitive to the misalignment in projections between pixels and points. To this end, our approach aims to optimize domain-irrelevant representation modeling with the aid of cross-modal learning under bird's-eye view. We propose BEV-based Area-to-area Fusion (BAF) to conduct cross-modal learning under bird's-eye view, which has a higher fault tolerance for point-level misalignment. Furthermore, to model domain-irrelevant representations, we propose BEV-driven Domain Contrastive Learning (BDCL) with the help of cross-modal learning under bird's-eye view. We design three domain generalization settings based on three 3D datasets, and BEV-DG significantly outperforms state-of-the-art competitors with tremendous margins in all settings.
</details>
<details>
<summary>摘要</summary>
cross-modal无监督领域适应（UDA）目标是利用2D-3D数据的补充性来缺乏目标领域的标注。然而，UDA方法需要训练时有Target领域的存在，因此训练的模型只能在特定的Target领域中工作。为了解决这个问题，我们提出了基于鸟瞰视的cross-modal学习 для领域总结（DG）的3D语义分割，称为BEV-DG。DG比UDA更加困难，因为模型在训练时无法访问目标领域，因此它需要通过cross-modal学习来减少领域差距。由于3D语义分割需要每个点的分类，现有的cross-modal学习是直接进行点对点的，这是 projection between pixels and points 的不一致敏感。为此，我们的方法是通过cross-modal学习下鸟瞰视模型化领域无关表示，使用BEV-based Area-to-area Fusion（BAF）来进行cross-modal学习，这种方法具有更高的错误忍容度。此外，我们还提出了基于鸟瞰视的BEV-driven Domain Contrastive Learning（BDCL），通过cross-modal学习来模型领域无关表示。我们设计了基于三个3D数据集的三个领域总结设置，BEV-DG在所有设置中都以很大的优势超越了当前的竞争对手。
</details></li>
</ul>
<hr>
<h2 id="Seed-Feature-Maps-based-CNN-Models-for-LEO-Satellite-Remote-Sensing-Services"><a href="#Seed-Feature-Maps-based-CNN-Models-for-LEO-Satellite-Remote-Sensing-Services" class="headerlink" title="Seed Feature Maps-based CNN Models for LEO Satellite Remote Sensing Services"></a>Seed Feature Maps-based CNN Models for LEO Satellite Remote Sensing Services</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06515">http://arxiv.org/abs/2308.06515</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhichao Lu, Chuntao Ding, Shangguang Wang, Ran Cheng, Felix Juefei-Xu, Vishnu Naresh Boddeti</li>
<li>for: 这篇研究是为了提出一个基于ground-station server的框架，以实现高性能的卷积神经网络模型在低地球轨道（LEO）卫星上的快速遥测图像处理。</li>
<li>methods: 本研究使用了一个基于seed feature map的框架，具体是每个层的卷积神经网络模型仅包含一个可学习的特征图（seed feature map），并通过特定规律生成其他特征图。此外，这个框架还使用了Random Hyperparameter Generation（RHG）技术，实现在LEO卫星上更新卷积神经网络模型。</li>
<li>results: 实验结果显示，提出的框架可以与现有的State-of-the-art方法相比，在ISPRS Vaihingen、ISPRS Potsdam、UAVid和LoveDA等数据集上实现更高的mIoU，特别是在UAVid数据集上，SineFM-based模型的mIoU高于UNetFormer，仅使用3.3倍少的参数和2.2倍少的FLOPs。<details>
<summary>Abstract</summary>
Deploying high-performance convolutional neural network (CNN) models on low-earth orbit (LEO) satellites for rapid remote sensing image processing has attracted significant interest from industry and academia. However, the limited resources available on LEO satellites contrast with the demands of resource-intensive CNN models, necessitating the adoption of ground-station server assistance for training and updating these models. Existing approaches often require large floating-point operations (FLOPs) and substantial model parameter transmissions, presenting considerable challenges. To address these issues, this paper introduces a ground-station server-assisted framework. With the proposed framework, each layer of the CNN model contains only one learnable feature map (called the seed feature map) from which other feature maps are generated based on specific rules. The hyperparameters of these rules are randomly generated instead of being trained, thus enabling the generation of multiple feature maps from the seed feature map and significantly reducing FLOPs. Furthermore, since the random hyperparameters can be saved using a few random seeds, the ground station server assistance can be facilitated in updating the CNN model deployed on the LEO satellite. Experimental results on the ISPRS Vaihingen, ISPRS Potsdam, UAVid, and LoveDA datasets for semantic segmentation services demonstrate that the proposed framework outperforms existing state-of-the-art approaches. In particular, the SineFM-based model achieves a higher mIoU than the UNetFormer on the UAVid dataset, with 3.3x fewer parameters and 2.2x fewer FLOPs.
</details>
<details>
<summary>摘要</summary>
deploying high-performance convolutional neural network (CNN) models on low-earth orbit (LEO) satellites for rapid remote sensing image processing has attracted significant interest from industry and academia. However, the limited resources available on LEO satellites contrast with the demands of resource-intensive CNN models, necessitating the adoption of ground-station server assistance for training and updating these models. existing approaches often require large floating-point operations (FLOPs) and substantial model parameter transmissions, presenting considerable challenges. to address these issues, this paper introduces a ground-station server-assisted framework. with the proposed framework, each layer of the CNN model contains only one learnable feature map (called the seed feature map) from which other feature maps are generated based on specific rules. the hyperparameters of these rules are randomly generated instead of being trained, thus enabling the generation of multiple feature maps from the seed feature map and significantly reducing FLOPs. furthermore, since the random hyperparameters can be saved using a few random seeds, the ground station server assistance can be facilitated in updating the CNN model deployed on the LEO satellite. experimental results on the ISPRS Vaihingen, ISPRS Potsdam, UAVid, and LoveDA datasets for semantic segmentation services demonstrate that the proposed framework outperforms existing state-of-the-art approaches. in particular, the SineFM-based model achieves a higher mIoU than the UNetFormer on the UAVid dataset, with 3.3x fewer parameters and 2.2x fewer FLOPs.
</details></li>
</ul>
<hr>
<h2 id="Out-of-distribution-multi-view-auto-encoders-for-prostate-cancer-lesion-detection"><a href="#Out-of-distribution-multi-view-auto-encoders-for-prostate-cancer-lesion-detection" class="headerlink" title="Out-of-distribution multi-view auto-encoders for prostate cancer lesion detection"></a>Out-of-distribution multi-view auto-encoders for prostate cancer lesion detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06481">http://arxiv.org/abs/2308.06481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alvaro Fernandez-Quilez, Linas Vidziunas, Ørjan Kløvfjell Thoresen, Ketil Oppedal, Svein Reidar Kjosavik, Trygve Eftestøl</li>
<li>for: 这篇论文目的是为了提出一种基于对外域检测的潜在医疗影像识别方法，并且运用不同T2w方向的多条流进行检测，以提高肝癌潜在病变检测的精确度。</li>
<li>methods: 本论文使用的方法包括对外域检测和多条流方法，以探索肝癌潜在病变检测的可能性。</li>
<li>results: 本论文的结果显示，使用多条流方法可以提高肝癌潜在病变检测的精确度，并且在一个公共可用数据集上获得了更高的检测精确度（AUC），具体为73.1%和82.3%之间。<details>
<summary>Abstract</summary>
Traditional deep learning (DL) approaches based on supervised learning paradigms require large amounts of annotated data that are rarely available in the medical domain. Unsupervised Out-of-distribution (OOD) detection is an alternative that requires less annotated data. Further, OOD applications exploit the class skewness commonly present in medical data. Magnetic resonance imaging (MRI) has proven to be useful for prostate cancer (PCa) diagnosis and management, but current DL approaches rely on T2w axial MRI, which suffers from low out-of-plane resolution. We propose a multi-stream approach to accommodate different T2w directions to improve the performance of PCa lesion detection in an OOD approach. We evaluate our approach on a publicly available data-set, obtaining better detection results in terms of AUC when compared to a single direction approach (73.1 vs 82.3). Our results show the potential of OOD approaches for PCa lesion detection based on MRI.
</details>
<details>
<summary>摘要</summary>
传统的深度学习（DL）方法基于指导学习 paradigma需要大量的标注数据，而这些数据在医疗领域很难获得。不supervised Out-of-distribution（OOD）检测是一种alternative，它需要更少的标注数据。另外，OOD应用可以利用医疗数据的类偏好。核磁共振成像（MRI）已经证明是肠癌（PCa）诊断和管理的有用工具，但当前的DL方法仅仅采用T2w极向MRI，这会受到低外平面分辨率的限制。我们提议一种多流程approach来满足不同的T2w方向，以提高PCa患部检测的性能。我们对公共可用数据集进行评估，并获得了与单向approach相比的更好的检测结果（AUC=73.1 vs AUC=82.3）。我们的结果表明OOD方法在MRI上进行PCa患部检测具有潜在的应用前景。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-multi-view-data-without-annotations-for-prostate-MRI-segmentation-A-contrastive-approach"><a href="#Leveraging-multi-view-data-without-annotations-for-prostate-MRI-segmentation-A-contrastive-approach" class="headerlink" title="Leveraging multi-view data without annotations for prostate MRI segmentation: A contrastive approach"></a>Leveraging multi-view data without annotations for prostate MRI segmentation: A contrastive approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06477">http://arxiv.org/abs/2308.06477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Nikolass Lindeijer, Tord Martin Ytredal, Trygve Eftestøl, Tobias Nordström, Fredrik Jäderling, Martin Eklund, Alvaro Fernandez-Quilez</li>
<li>for: 提高 automatic prostate segmentation 的精度和可靠性，使用 multi-view MRI 数据和 contrastive learning 技术。</li>
<li>methods: 提posed 一种 triplet encoder and single decoder network 基于 U-Net，称为 tU-Net (triplet U-Net)，可以利用不需要注意力的 sagittal 和 coronal 视图来提高 segmentation 的精度。</li>
<li>results: tU-Net 显示在 dice score 指标上 statistically 提高了精度 (91.25+-0.52% 比 86.40+-1.50%,P&lt;.001)，并且在不同视图的数据上进行了可靠的总体骨骼变换。<details>
<summary>Abstract</summary>
An accurate prostate delineation and volume characterization can support the clinical assessment of prostate cancer. A large amount of automatic prostate segmentation tools consider exclusively the axial MRI direction in spite of the availability as per acquisition protocols of multi-view data. Further, when multi-view data is exploited, manual annotations and availability at test time for all the views is commonly assumed. In this work, we explore a contrastive approach at training time to leverage multi-view data without annotations and provide flexibility at deployment time in the event of missing views. We propose a triplet encoder and single decoder network based on U-Net, tU-Net (triplet U-Net). Our proposed architecture is able to exploit non-annotated sagittal and coronal views via contrastive learning to improve the segmentation from a volumetric perspective. For that purpose, we introduce the concept of inter-view similarity in the latent space. To guide the training, we combine a dice score loss calculated with respect to the axial view and its manual annotations together with a multi-view contrastive loss. tU-Net shows statistical improvement in dice score coefficient (DSC) with respect to only axial view (91.25+-0.52% compared to 86.40+-1.50%,P<.001). Sensitivity analysis reveals the volumetric positive impact of the contrastive loss when paired with tU-Net (2.85+-1.34% compared to 3.81+-1.88%,P<.001). Further, our approach shows good external volumetric generalization in an in-house dataset when tested with multi-view data (2.76+-1.89% compared to 3.92+-3.31%,P=.002), showing the feasibility of exploiting non-annotated multi-view data through contrastive learning whilst providing flexibility at deployment in the event of missing views.
</details>
<details>
<summary>摘要</summary>
通过增强多视图数据的利用，我们提出了一种基于对照学习的三元Encoder-单元网络（tU-Net），用于提高肾脏细分。我们在训练时使用了非标注的架子视图和仰视图，通过对照学习来利用这些视图，从而提高 segmentation 的精度。为了引导训练，我们组合了axial视图和其手动注释的 dice score 损失函数，以及多视图对照损失函数。 results 表明，tU-Net 比只使用axial视图的情况提高了 dice score 系数（DSC）（91.25±0.52% vs 86.40±1.50%,P<0.001）。另外，我们的方法还在不同的混合率下进行了敏感性分析，发现对照学习损失函数对于与 tU-Net 结合使用时产生的卷积效应具有 Statistical significance（2.85±1.34% vs 3.81±1.88%,P<0.001）。此外，我们的方法还在一个自有的数据集上进行了 external volumetric 一致性测试，并发现在使用多视图数据时，tU-Net 的性能较好（2.76±1.89% vs 3.92±3.31%,P=.002），这表明了我们的方法可以在实际应用中利用非标注的多视图数据进行对照学习，并且在部署时可以避免 missing views 的问题。
</details></li>
</ul>
<hr>
<h2 id="Tiny-and-Efficient-Model-for-the-Edge-Detection-Generalization"><a href="#Tiny-and-Efficient-Model-for-the-Edge-Detection-Generalization" class="headerlink" title="Tiny and Efficient Model for the Edge Detection Generalization"></a>Tiny and Efficient Model for the Edge Detection Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06468">http://arxiv.org/abs/2308.06468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xavysp/teed">https://github.com/xavysp/teed</a></li>
<li>paper_authors: Xavier Soria, Yachuan Li, Mohammad Rouhani, Angel D. Sappa</li>
<li>for: 本文 targets at addressing the issue of edge detection in computer vision, with the objectives of simplicity, efficiency, and generalization.</li>
<li>methods: 本文提出了一种轻量级卷积神经网络（TEED），具有只有58K参数，比现状态 искусственный智能模型少。通过在BIPED dataset上训练，可以在less than 30分钟内完成训练，每个epoch仅需less than 5分钟。</li>
<li>results: 本文的提出的模型可以快速 converges within the first few epochs，并且预测的边映射具有高质量。此外，本文还提出了一个新的测试数据集，用于测试边检测模型的通用性。I hope this helps!<details>
<summary>Abstract</summary>
Most high-level computer vision tasks rely on low-level image operations as their initial processes. Operations such as edge detection, image enhancement, and super-resolution, provide the foundations for higher level image analysis. In this work we address the edge detection considering three main objectives: simplicity, efficiency, and generalization since current state-of-the-art (SOTA) edge detection models are increased in complexity for better accuracy. To achieve this, we present Tiny and Efficient Edge Detector (TEED), a light convolutional neural network with only $58K$ parameters, less than $0.2$% of the state-of-the-art models. Training on the BIPED dataset takes $less than 30 minutes$, with each epoch requiring $less than 5 minutes$. Our proposed model is easy to train and it quickly converges within very first few epochs, while the predicted edge-maps are crisp and of high quality. Additionally, we propose a new dataset to test the generalization of edge detection, which comprises samples from popular images used in edge detection and image segmentation. The source code is available in https://github.com/xavysp/TEED.
</details>
<details>
<summary>摘要</summary>
大多数高级计算机视觉任务都基于低级图像操作作为初始过程。操作如图像提高、图像增强和超分辨率，为更高级图像分析提供基础。在这项工作中，我们考虑了三个主要目标：简单、高效和泛化，因为当前状态体系（SOTA）的边检测模型在精度方面增加了复杂度。为达到这个目标，我们提出了简单高效的边检测器（TEED），这是一个具有58000个参数的轻量级卷积神经网络，比状态体系模型少了99.8%的参数。在BIPE dataset上训练时间只需要少于30分钟，每个epoch只需要少于5分钟。我们的提出的模型轻松训练，快速 converges，并且预测的边映射具有高质量。此外，我们还提出了一个新的测试泛化边检测的数据集，该数据集包括流行的图像used in edge detection和图像分类中的样本。源代码可以在https://github.com/xavysp/TEED上获取。
</details></li>
</ul>
<hr>
<h2 id="Improved-YOLOv8-Detection-Algorithm-in-Security-Inspection-Image"><a href="#Improved-YOLOv8-Detection-Algorithm-in-Security-Inspection-Image" class="headerlink" title="Improved YOLOv8 Detection Algorithm in Security Inspection Image"></a>Improved YOLOv8 Detection Algorithm in Security Inspection Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06452">http://arxiv.org/abs/2308.06452</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyao Lu</li>
<li>for: 本研究旨在解决X射线图像检测中的重叠检测对象、假阳性货物检测和检测失败问题。</li>
<li>methods: 本研究提出了基于YOLOv8s的改进X射线财物检测算法CSS-YOLO。</li>
<li>results: 实验结果表明，CSS-YOLO算法能够提高检测精度，降低假阳性率和 missed detection 率，提高安全检查效果。<details>
<summary>Abstract</summary>
Security inspection is the first line of defense to ensure the safety of people's lives and property, and intelligent security inspection is an inevitable trend in the future development of the security inspection industry. Aiming at the problems of overlapping detection objects, false detection of contraband, and missed detection in the process of X-ray image detection, an improved X-ray contraband detection algorithm CSS-YOLO based on YOLOv8s is proposed.
</details>
<details>
<summary>摘要</summary>
安全检查是人们生命和财产安全的首列防御，未来安全检查行业的发展将具有智能化特点。面临检测对象重叠、质控违禁品和检测失败等问题，我们提出了基于YOLOv8s的改进X射线质控检测算法CSS-YOLO。
</details></li>
</ul>
<hr>
<h2 id="TongueSAM-An-Universal-Tongue-Segmentation-Model-Based-on-SAM-with-Zero-Shot"><a href="#TongueSAM-An-Universal-Tongue-Segmentation-Model-Based-on-SAM-with-Zero-Shot" class="headerlink" title="TongueSAM: An Universal Tongue Segmentation Model Based on SAM with Zero-Shot"></a>TongueSAM: An Universal Tongue Segmentation Model Based on SAM with Zero-Shot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06444">http://arxiv.org/abs/2308.06444</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cshan-github/tonguesam">https://github.com/cshan-github/tonguesam</a></li>
<li>paper_authors: Shan Cao, Qunsheng Ruan, Qingfeng Wu</li>
<li>for: 本研究旨在提出一种通用的舌部分 segmentation模型，以解决现有的舌部分 segmentation方法在不同舌型图像上表现 mediocre 的问题。</li>
<li>methods: 本研究使用的是一种名为 SAM（Segment Anything Model）的大规模预训练交互分割模型，该模型具有强大的零shot泛化能力。通过应用 SAM 到舌部分分割，可以实现零shot 分割不同类型的舌型图像。此外，本研究还使用了一种基于对象检测的 Prompt Generator，以实现一个端到端自动化的舌部分分割方法。</li>
<li>results: 实验表明，TongueSAM 在不同舌部分分割数据集上表现出色，特别是在零shot 下表现。此外，TongueSAM 可以 direct 应用于其他数据集无需 fine-tuning。据我们知道，这是首次应用大规模预训练模型于舌部分分割。研究成果和预训练模型将在：<a target="_blank" rel="noopener" href="https://github.com/cshan-github/TongueSAM">https://github.com/cshan-github/TongueSAM</a> 上公布。<details>
<summary>Abstract</summary>
Tongue segmentation serves as the primary step in automated TCM tongue diagnosis, which plays a significant role in the diagnostic results. Currently, numerous deep learning based methods have achieved promising results. However, most of these methods exhibit mediocre performance on tongues different from the training set. To address this issue, this paper proposes a universal tongue segmentation model named TongueSAM based on SAM (Segment Anything Model). SAM is a large-scale pretrained interactive segmentation model known for its powerful zero-shot generalization capability. Applying SAM to tongue segmentation enables the segmentation of various types of tongue images with zero-shot. In this study, a Prompt Generator based on object detection is integrated into SAM to enable an end-to-end automated tongue segmentation method. Experiments demonstrate that TongueSAM achieves exceptional performance across various of tongue segmentation datasets, particularly under zero-shot. TongueSAM can be directly applied to other datasets without fine-tuning. As far as we know, this is the first application of large-scale pretrained model for tongue segmentation. The project and pretrained model of TongueSAM be publiced in :https://github.com/cshan-github/TongueSAM.
</details>
<details>
<summary>摘要</summary>
叙述分割 serves as the primary step in automated TCM tongue diagnosis, which plays a significant role in the diagnostic results. Currently, numerous deep learning based methods have achieved promising results. However, most of these methods exhibit mediocre performance on tongues different from the training set. To address this issue, this paper proposes a universal tongue segmentation model named TongueSAM based on SAM (Segment Anything Model). SAM is a large-scale pretrained interactive segmentation model known for its powerful zero-shot generalization capability. Applying SAM to tongue segmentation enables the segmentation of various types of tongue images with zero-shot. In this study, a Prompt Generator based on object detection is integrated into SAM to enable an end-to-end automated tongue segmentation method. Experiments demonstrate that TongueSAM achieves exceptional performance across various of tongue segmentation datasets, particularly under zero-shot. TongueSAM can be directly applied to other datasets without fine-tuning. As far as we know, this is the first application of large-scale pretrained model for tongue segmentation. The project and pretrained model of TongueSAM be publiced in :https://github.com/cshan-github/TongueSAM.Here's the translation in Traditional Chinese: tonguesegmentation serves as the primary step in automated TCM tongue diagnosis, which plays a significant role in the diagnostic results. Currently, numerous deep learning based methods have achieved promising results. However, most of these methods exhibit mediocre performance on tongues different from the training set. To address this issue, this paper proposes a universal tongue segmentation model named TongueSAM based on SAM (Segment Anything Model). SAM is a large-scale pretrained interactive segmentation model known for its powerful zero-shot generalization capability. Applying SAM to tongue segmentation enables the segmentation of various types of tongue images with zero-shot. In this study, a Prompt Generator based on object detection is integrated into SAM to enable an end-to-end automated tongue segmentation method. Experiments demonstrate that TongueSAM achieves exceptional performance across various of tongue segmentation datasets, particularly under zero-shot. TongueSAM can be directly applied to other datasets without fine-tuning. As far as we know, this is the first application of large-scale pretrained model for tongue segmentation. The project and pretrained model of TongueSAM be publiced in :https://github.com/cshan-github/TongueSAM.
</details></li>
</ul>
<hr>
<h2 id="Distributionally-Robust-Optimization-and-Invariant-Representation-Learning-for-Addressing-Subgroup-Underrepresentation-Mechanisms-and-Limitations"><a href="#Distributionally-Robust-Optimization-and-Invariant-Representation-Learning-for-Addressing-Subgroup-Underrepresentation-Mechanisms-and-Limitations" class="headerlink" title="Distributionally Robust Optimization and Invariant Representation Learning for Addressing Subgroup Underrepresentation: Mechanisms and Limitations"></a>Distributionally Robust Optimization and Invariant Representation Learning for Addressing Subgroup Underrepresentation: Mechanisms and Limitations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06434">http://arxiv.org/abs/2308.06434</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nilesh Kumar, Ruby Shrestha, Zhiyuan Li, Linwei Wang</li>
<li>For: This paper aims to address the issue of spurious correlation due to subgroup underrepresentation in medical image classification, specifically by exploring the use of robust optimization to learn invariant representations.* Methods: The paper proposes a novel approach that leverages robust optimization to facilitate the learning of invariant representations, and evaluates the effectiveness of this approach through a comprehensive study.* Results: The proposed approach is shown to improve the performance of classifiers on underrepresented subgroups, while maintaining high average and worst-group performance, compared to existing methods such as generalized reweighting and naive invariant representation learning.<details>
<summary>Abstract</summary>
Spurious correlation caused by subgroup underrepresentation has received increasing attention as a source of bias that can be perpetuated by deep neural networks (DNNs). Distributionally robust optimization has shown success in addressing this bias, although the underlying working mechanism mostly relies on upweighting under-performing samples as surrogates for those underrepresented in data. At the same time, while invariant representation learning has been a powerful choice for removing nuisance-sensitive features, it has been little considered in settings where spurious correlations are caused by significant underrepresentation of subgroups. In this paper, we take the first step to better understand and improve the mechanisms for debiasing spurious correlation due to subgroup underrepresentation in medical image classification. Through a comprehensive evaluation study, we first show that 1) generalized reweighting of under-performing samples can be problematic when bias is not the only cause for poor performance, while 2) naive invariant representation learning suffers from spurious correlations itself. We then present a novel approach that leverages robust optimization to facilitate the learning of invariant representations at the presence of spurious correlations. Finetuned classifiers utilizing such representation demonstrated improved abilities to reduce subgroup performance disparity, while maintaining high average and worst-group performance.
</details>
<details>
<summary>摘要</summary>
假设对于小分支的参数不足，导致深度神经网络（DNNs）中的伪正相关。 Distributionally robust optimization 已经在解决这种偏见方面取得成功，但是其主要运作机制是通过增重下performing samples 作为没有在数据中受到代表的样本。 在这篇研究中，我们对对于小分支参数不足导致的伪正相关的推导和改进方法进行了首次的研究。我们首先显示了以下两个结果：1）通过增重下performing samples 并不一定能够解决伪正相关，而2）简单的对称表现学习方法本身受到了伪正相关的影响。我们然后提出了一种新的方法，利用Robust optimization 来促进对伪正相关的推导。我们继续调整这些表现，以便在存在伪正相关的情况下维持高的平均和最差分支性能。
</details></li>
</ul>
<hr>
<h2 id="Learn-Single-horizon-Disease-Evolution-for-Predictive-Generation-of-Post-therapeutic-Neovascular-Age-related-Macular-Degeneration"><a href="#Learn-Single-horizon-Disease-Evolution-for-Predictive-Generation-of-Post-therapeutic-Neovascular-Age-related-Macular-Degeneration" class="headerlink" title="Learn Single-horizon Disease Evolution for Predictive Generation of Post-therapeutic Neovascular Age-related Macular Degeneration"></a>Learn Single-horizon Disease Evolution for Predictive Generation of Post-therapeutic Neovascular Age-related Macular Degeneration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06432">http://arxiv.org/abs/2308.06432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Zhang, Kun Huang, Mingchao Li, Songtao Yuan, Qiang Chen</li>
<li>for: 预测 age-related macular degeneration (nAMD) 疾病进程和效果。</li>
<li>methods: 提posed a single-horizon disease evolution network (SHENet)，使用 feature encoder、graph evolution module 和 feature decoder，并通过 adversarial training 确保疾病进程学习的有效性。</li>
<li>results: 与其他生成方法相比，SHENet 生成的 SD-OCT 图像质量最高，同时保持结构保护和内容预测。 Qualitative evaluations 也表明 SHENet 的视觉效果较好。<details>
<summary>Abstract</summary>
Most of the existing disease prediction methods in the field of medical image processing fall into two classes, namely image-to-category predictions and image-to-parameter predictions. Few works have focused on image-to-image predictions. Different from multi-horizon predictions in other fields, ophthalmologists prefer to show more confidence in single-horizon predictions due to the low tolerance of predictive risk. We propose a single-horizon disease evolution network (SHENet) to predictively generate post-therapeutic SD-OCT images by inputting pre-therapeutic SD-OCT images with neovascular age-related macular degeneration (nAMD). In SHENet, a feature encoder converts the input SD-OCT images to deep features, then a graph evolution module predicts the process of disease evolution in high-dimensional latent space and outputs the predicted deep features, and lastly, feature decoder recovers the predicted deep features to SD-OCT images. We further propose an evolution reinforcement module to ensure the effectiveness of disease evolution learning and obtain realistic SD-OCT images by adversarial training. SHENet is validated on 383 SD-OCT cubes of 22 nAMD patients based on three well-designed schemes based on the quantitative and qualitative evaluations. Compared with other generative methods, the generative SD-OCT images of SHENet have the highest image quality. Besides, SHENet achieves the best structure protection and content prediction. Qualitative evaluations also demonstrate that SHENet has a better visual effect than other methods. SHENet can generate post-therapeutic SD-OCT images with both high prediction performance and good image quality, which has great potential to help ophthalmologists forecast the therapeutic effect of nAMD.
</details>
<details>
<summary>摘要</summary>
现有的疾病预测方法在医学图像处理领域主要分为两类：图像到类别预测和图像到参数预测，其中少数工作关注到图像到图像预测。与其他多个预测horizon不同，眼科医生更偏好单个预测horizon，因为预测风险的低忍性。我们提出了单个预测疾病演化网络（SHENet），用于预测基于前治疗SD-OCT图像的后治疗SD-OCT图像。在SHENet中，一个特征编码器将输入SD-OCT图像转化为深度特征，然后一个图像演化模块预测疾病演化过程在高维潜在空间中，并输出预测的深度特征。最后，特征解码器重建预测的深度特征为SD-OCT图像。我们还提出了演化增强模块，以确保疾病演化学习的有效性并获得真实的SD-OCT图像，通过对抗训练。SHENet在383个SD-OCT立方体上的22例nAMD患者基于三种有效的方案进行验证，并通过量化和质量评估。与其他生成方法相比，SHENet生成的SD-OCT图像的生成质量最高。此外，SHENet保持了最佳的结构保护和内容预测。质量评估还表明，SHENet在视觉效果方面表现更好。SHENet可以预测nAMD后治疗SD-OCT图像，具有高预测性和良好的图像质量，这对眼科医生预测nAMD治疗效果具有很大潜力。
</details></li>
</ul>
<hr>
<h2 id="M-M-Tackling-False-Positives-in-Mammography-with-a-Multi-view-and-Multi-instance-Learning-Sparse-Detector"><a href="#M-M-Tackling-False-Positives-in-Mammography-with-a-Multi-view-and-Multi-instance-Learning-Sparse-Detector" class="headerlink" title="M&amp;M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector"></a>M&amp;M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06420">http://arxiv.org/abs/2308.06420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yen Nhi Truong Vu, Dan Guo, Ahmed Taha, Jason Su, Thomas Paul Matthews</li>
<li>for: 提高诊断率和避免假阳性结果</li>
<li>methods: 使用 sparse R-CNN，包括多视图交叉注意模块和多实例学习</li>
<li>results: 提高了检测和预测性能，并通过精细的ablation study证明每个组件的效果<details>
<summary>Abstract</summary>
Deep-learning-based object detection methods show promise for improving screening mammography, but high rates of false positives can hinder their effectiveness in clinical practice. To reduce false positives, we identify three challenges: (1) unlike natural images, a malignant mammogram typically contains only one malignant finding; (2) mammography exams contain two views of each breast, and both views ought to be considered to make a correct assessment; (3) most mammograms are negative and do not contain any findings. In this work, we tackle the three aforementioned challenges by: (1) leveraging Sparse R-CNN and showing that sparse detectors are more appropriate than dense detectors for mammography; (2) including a multi-view cross-attention module to synthesize information from different views; (3) incorporating multi-instance learning (MIL) to train with unannotated images and perform breast-level classification. The resulting model, M&M, is a Multi-view and Multi-instance learning system that can both localize malignant findings and provide breast-level predictions. We validate M&M's detection and classification performance using five mammography datasets. In addition, we demonstrate the effectiveness of each proposed component through comprehensive ablation studies.
</details>
<details>
<summary>摘要</summary>
深度学习基于对象检测方法在萤幕检查中显示出优秀表现，但高 false positive 率可能会阻碍其在临床实践中的效iveness。为了减少 false positive，我们标识了三个挑战：（1）癌症肺像素通常只包含一个癌症发现;（2）萤幕检查包括两个视图每一个乳腺，需要考虑两个视图来确定正确的评估;（3）大多数萤幕检查为正常图像，没有任何发现。在这种情况下，我们解决了这三个挑战，通过：（1）利用稀疏 R-CNN，并证明稀疏检测器更适合萤幕检查;（2）添加多视图交叉注意模块，以将不同视图的信息相互协同;（3）采用多例学习（MIL），以使用无注释图像进行训练，并在乳腺级别进行预测。得到的模型称为 M&M，它可以同时localize 癌症发现和进行乳腺级别预测。我们验证 M&M 的检测和预测性能使用五个萤幕检查 dataset。此外，我们还通过完整的减少研究，证明每一个提案的效果。
</details></li>
</ul>
<hr>
<h2 id="Improving-Pseudo-Labels-for-Open-Vocabulary-Object-Detection"><a href="#Improving-Pseudo-Labels-for-Open-Vocabulary-Object-Detection" class="headerlink" title="Improving Pseudo Labels for Open-Vocabulary Object Detection"></a>Improving Pseudo Labels for Open-Vocabulary Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06412">http://arxiv.org/abs/2308.06412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiyu Zhao, Samuel Schulter, Long Zhao, Zhixing Zhang, Vijay Kumar B. G, Yumin Suh, Manmohan Chandraker, Dimitris N. Metaxas</li>
<li>for: 提高开放词汇物体检测（OVD）中使用预先训练的视觉语言模型（VLM）生成的假标签（PL）的性能。</li>
<li>methods: 提出在线自我训练和拆分并融合头（SAS-Det）方法，包括自我训练VLMs生成高质量PL，并利用拆分并融合头除去PL的地方噪声，同时 fusion complementary knowledge learned from precise ground truth和噪声PL。</li>
<li>results: 在COCO和LVISbenchmark上 achieved 37.4 AP$_{50}$和27.3 AP$_r$，胜过先前的状态艺术模型，并且 Pseudo labeling 速度比过去的方法快三倍。<details>
<summary>Abstract</summary>
Recent studies show promising performance in open-vocabulary object detection (OVD) using pseudo labels (PLs) from pretrained vision and language models (VLMs). However, PLs generated by VLMs are extremely noisy due to the gap between the pretraining objective of VLMs and OVD, which blocks further advances on PLs. In this paper, we aim to reduce the noise in PLs and propose a method called online Self-training And a Split-and-fusion head for OVD (SAS-Det). First, the self-training finetunes VLMs to generate high quality PLs while prevents forgetting the knowledge learned in the pretraining. Second, a split-and-fusion (SAF) head is designed to remove the noise in localization of PLs, which is usually ignored in existing methods. It also fuses complementary knowledge learned from both precise ground truth and noisy pseudo labels to boost the performance. Extensive experiments demonstrate SAS-Det is both efficient and effective. Our pseudo labeling is 3 times faster than prior methods. SAS-Det outperforms prior state-of-the-art models of the same scale by a clear margin and achieves 37.4 AP$_{50}$ and 27.3 AP$_r$ on novel categories of the COCO and LVIS benchmarks, respectively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Detecting-and-Preventing-Hallucinations-in-Large-Vision-Language-Models"><a href="#Detecting-and-Preventing-Hallucinations-in-Large-Vision-Language-Models" class="headerlink" title="Detecting and Preventing Hallucinations in Large Vision Language Models"></a>Detecting and Preventing Hallucinations in Large Vision Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06394">http://arxiv.org/abs/2308.06394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anisha Gunjal, Jihan Yin, Erhan Bas<br>for:The paper aims to address the issue of hallucinations in instruction-tuned large vision language models (LVLMs) for visual question answering (VQA).methods:The authors introduce a new dataset called M-HalDetect, which consists of 16,000 fine-grained annotations on VQA examples to train and benchmark models for hallucination detection and prevention. They also propose a novel optimization method called Fine-grained Direct Preference Optimization (FDPO) to reduce hallucinations in LVLMs.results:The authors evaluate the effectiveness of M-HalDetect and FDPO using human evaluation and find that they reduce hallucination rates in InstructBLIP by 41% and 55%, respectively. They also find that their reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57%, respectively, and has strong correlation with human evaluated accuracy scores.<details>
<summary>Abstract</summary>
Instruction tuned Large Vision Language Models (LVLMs) have significantly advanced in generalizing across a diverse set of multi-modal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of the hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a (M)ultimodal (Hal)lucination (Detect)ion Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained annotations on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions and relationships that are unfaithful. To demonstrate the potential of this dataset for hallucination prevention, we optimize InstructBLIP through our novel Fine-grained Direct Preference Optimization (FDPO). We also train fine-grained multi-modal reward models from InstructBLIP and evaluate their effectiveness with best-of-n rejection sampling. We perform human evaluation on both FDPO and rejection sampling, and find that they reduce hallucination rates in InstructBLIP by 41% and 55% respectively. We also find that our reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57% respectively, and has strong correlation with human evaluated accuracy scores.
</details>
<details>
<summary>摘要</summary>
干脆大视语言模型（LVLM）在多modal任务上 generalized 了，特别是对于视觉问答（VQA）。然而，生成视觉固有的回答仍然是current state-of-the-art LVLMs（InstructBLIP）中的挑战。我们发现，甚至当前最佳LVLMs中还有30%的hallucination text，包括不存在的物体、不准确的描述和关系。为了解决这个问题，我们提出了M-HalDetect数据集，可以用于训练和对比模型，以检测和避免hallucination。M-HalDetect包括16k精细的VQA示例注释，使其成为首个多modal hallucination detection数据集。不同于之前的工作，我们不仅考虑物体hallucination，还注释了不准确的实体描述和关系。为了证明M-HalDetect的可用性，我们对InstructBLIP进行了novel Fine-grained Direct Preference Optimization（FDPO）优化。我们还使用InstructBLIP中的精细多modal奖励模型进行训练，并使用best-of-n拒绝采样来评估其效果。我们对FDPO和拒绝采样进行了人工评估，发现它们可以降低InstructBLIP中的hallucination率41%和55%。此外，我们发现我们的奖励模型可以普适化到其他多modal模型，降低LLaVA和mPLUG-OWL中的hallucination率15%和57%，并与人类评估精度成对。
</details></li>
</ul>
<hr>
<h2 id="R2S100K-Road-Region-Segmentation-Dataset-For-Semi-Supervised-Autonomous-Driving-in-the-Wild"><a href="#R2S100K-Road-Region-Segmentation-Dataset-For-Semi-Supervised-Autonomous-Driving-in-the-Wild" class="headerlink" title="R2S100K: Road-Region Segmentation Dataset For Semi-Supervised Autonomous Driving in the Wild"></a>R2S100K: Road-Region Segmentation Dataset For Semi-Supervised Autonomous Driving in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06393">http://arxiv.org/abs/2308.06393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Atif Butt, Hassan Ali, Adnan Qayyum, Waqas Sultani, Ala Al-Fuqaha, Junaid Qadir</li>
<li>for: 这项研究的目的是提供一个大规模的、多样化的道路区域分割数据集，以便为自动驾驶技术的发展提供更好的支持。</li>
<li>methods: 这项研究使用了一种名为Efficient Data Sampling（EDS）的自我教学框架，通过利用无标注数据来提高学习效果，同时还使用了 semi-supervised learning 方法。</li>
<li>results: 实验结果表明，提出的方法可以显著改善 semantic segmentation 任务的泛化能力，同时也可以降低标注成本。<details>
<summary>Abstract</summary>
Semantic understanding of roadways is a key enabling factor for safe autonomous driving. However, existing autonomous driving datasets provide well-structured urban roads while ignoring unstructured roadways containing distress, potholes, water puddles, and various kinds of road patches i.e., earthen, gravel etc. To this end, we introduce Road Region Segmentation dataset (R2S100K) -- a large-scale dataset and benchmark for training and evaluation of road segmentation in aforementioned challenging unstructured roadways. R2S100K comprises 100K images extracted from a large and diverse set of video sequences covering more than 1000 KM of roadways. Out of these 100K privacy respecting images, 14,000 images have fine pixel-labeling of road regions, with 86,000 unlabeled images that can be leveraged through semi-supervised learning methods. Alongside, we present an Efficient Data Sampling (EDS) based self-training framework to improve learning by leveraging unlabeled data. Our experimental results demonstrate that the proposed method significantly improves learning methods in generalizability and reduces the labeling cost for semantic segmentation tasks. Our benchmark will be publicly available to facilitate future research at https://r2s100k.github.io/.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>路径理解是自驾投控车中关键的能力因素。然而，现有的自驾投控车数据集只提供了有效的城市路径，而忽略了不结构化的路径中的压力、沟壑、水泥等等。为此，我们介绍了路径区域分割数据集（R2S100K）——一个大规模的数据集和标准 для训练和评估路径分割在上述挑战性的路径上。R2S100K包含100K张图像，其中14,000张图像有细腻的像素标注路径区域，剩下86,000张图像可以通过半有结构学习方法进行利用。此外，我们提出了一种效率的数据采样（EDS）基于的自动训练框架，以提高学习的通用性和减少标注成本。我们的实验结果表明，提posed方法可以显著提高学习方法的通用性和减少标注成本。我们的标准将在https://r2s100k.github.io/上公开，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="U-RED-Unsupervised-3D-Shape-Retrieval-and-Deformation-for-Partial-Point-Clouds"><a href="#U-RED-Unsupervised-3D-Shape-Retrieval-and-Deformation-for-Partial-Point-Clouds" class="headerlink" title="U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point Clouds"></a>U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06383">http://arxiv.org/abs/2308.06383</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhangcyg/u-red">https://github.com/zhangcyg/u-red</a></li>
<li>paper_authors: Yan Di, Chenyangguang Zhang, Ruida Zhang, Fabian Manhardt, Yongzhi Su, Jason Rambach, Didier Stricker, Xiangyang Ji, Federico Tombari</li>
<li>for: 本文提出了一种不supervised shape retrieval和扭形管道，用于从已有的CAD模型库中检索和扭形匹配目标对象。</li>
<li>methods: 该管道使用了一种新的点级差异指导度量来抗随机变量，并通过将所有可能的全形对象投影到单位球面上来处理一个部分观察的一对多关系。</li>
<li>results: 在PartNet、ComplementMe和Scan2CAD等 sintetic和实际数据集上，U-RED比前状态艺术方法提高47.3%、16.7%和31.6%。<details>
<summary>Abstract</summary>
In this paper, we propose U-RED, an Unsupervised shape REtrieval and Deformation pipeline that takes an arbitrary object observation as input, typically captured by RGB images or scans, and jointly retrieves and deforms the geometrically similar CAD models from a pre-established database to tightly match the target. Considering existing methods typically fail to handle noisy partial observations, U-RED is designed to address this issue from two aspects. First, since one partial shape may correspond to multiple potential full shapes, the retrieval method must allow such an ambiguous one-to-many relationship. Thereby U-RED learns to project all possible full shapes of a partial target onto the surface of a unit sphere. Then during inference, each sampling on the sphere will yield a feasible retrieval. Second, since real-world partial observations usually contain noticeable noise, a reliable learned metric that measures the similarity between shapes is necessary for stable retrieval. In U-RED, we design a novel point-wise residual-guided metric that allows noise-robust comparison. Extensive experiments on the synthetic datasets PartNet, ComplementMe and the real-world dataset Scan2CAD demonstrate that U-RED surpasses existing state-of-the-art approaches by 47.3%, 16.7% and 31.6% respectively under Chamfer Distance.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了无监督的形状检索和扭曲管道（U-RED），它可以将从RGB图像或扫描得到的任意物体观察作为输入，并将相似的CAD模型从预设的数据库中检索出来，以便与目标物体紧密匹配。现有的方法通常无法处理干扰性的部分观察，因此U-RED在两个方面进行了改进。首先，由于一个部分形状可能对应多个可能的全形状，因此检索方法必须允许这种杂乱的一对多关系。U-RED通过将所有可能的全形状 проек到单位球上来解决这个问题。然后，在推理时，每个样本在球上的抽象都将产生一个可能的检索。其次，由于实际的部分观察通常含有显著的干扰，因此需要一个可靠的学习的形状相似度量表，以确保稳定的检索。在U-RED中，我们设计了一种新的点级差异导向的形状相似度量表，允许比较干扰的形状。我们在PartNet、ComplementMe和Scan2CAD等 sintetic和实际数据集上进行了广泛的实验，结果显示，U-RED在Chamfer Distance下比现有状态的方法提高47.3%、16.7%和31.6%。
</details></li>
</ul>
<hr>
<h2 id="CATS-v2-Hybrid-encoders-for-robust-medical-segmentation"><a href="#CATS-v2-Hybrid-encoders-for-robust-medical-segmentation" class="headerlink" title="CATS v2: Hybrid encoders for robust medical segmentation"></a>CATS v2: Hybrid encoders for robust medical segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06377">http://arxiv.org/abs/2308.06377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoli12345/cats">https://github.com/haoli12345/cats</a></li>
<li>paper_authors: Hao Li, Han Liu, Dewei Hu, Xing Yao, Jiacheng Wang, Ipek Oguz</li>
<li>for: 这个研究的目的是提出一个以CATS为基础的对� части�内部构成，以提高医疗影像分类�的精度和意义性。</li>
<li>methods: 这个研究使用了CATS v2模型，其中包括一个具有传播�的 Hybrid 构成，该构成包括一个 CNN 基础的 Encoder 路径和一个传播�的 Transformer 路径。</li>
<li>results: 在两个公共挑战赛 datasets 上进行评估，CATS v2 模型在分类 VS 和肾脏癌等项目上表现出较高的 Dice  scores，较以前的方法为高。<details>
<summary>Abstract</summary>
Convolutional Neural Networks (CNNs) have exhibited strong performance in medical image segmentation tasks by capturing high-level (local) information, such as edges and textures. However, due to the limited field of view of convolution kernel, it is hard for CNNs to fully represent global information. Recently, transformers have shown good performance for medical image segmentation due to their ability to better model long-range dependencies. Nevertheless, transformers struggle to capture high-level spatial features as effectively as CNNs. A good segmentation model should learn a better representation from local and global features to be both precise and semantically accurate. In our previous work, we proposed CATS, which is a U-shaped segmentation network augmented with transformer encoder. In this work, we further extend this model and propose CATS v2 with hybrid encoders. Specifically, hybrid encoders consist of a CNN-based encoder path paralleled to a transformer path with a shifted window, which better leverage both local and global information to produce robust 3D medical image segmentation. We fuse the information from the convolutional encoder and the transformer at the skip connections of different resolutions to form the final segmentation. The proposed method is evaluated on two public challenge datasets: Cross-Modality Domain Adaptation (CrossMoDA) and task 5 of Medical Segmentation Decathlon (MSD-5), to segment vestibular schwannoma (VS) and prostate, respectively. Compared with the state-of-the-art methods, our approach demonstrates superior performance in terms of higher Dice scores.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在医疗图像分割任务中表现出色，捕捉到高级（本地）信息，如边缘和 тексту层。然而，由于卷积核的视野有限，使得CNN难以完全表征全局信息。近些年来， transformer 在医疗图像分割中表现良好，主要是因为它们能够更好地模型长距离依赖关系。然而， transformer 在捕捉高级空间特征方面表现不如 CNN 好。为了建立一个好的分割模型，需要学习更好的 Representation 来兼顾本地和全局特征，以确保准确和Semantic 准确。在我们之前的工作中，我们提出了CATS，它是一个 U-shaped 分割网络，通过添加 transformer 编码器来提高性能。在这个工作中，我们进一步扩展了CATS 模型，并提出了CATS v2 模型，它使用了混合编码器。具体来说，混合编码器包括一个 CNN 基于编码器路径和一个 shifted window 的 transformer 路径，这两者可以更好地利用本地和全局信息，以生成Robust 3D 医疗图像分割。我们在不同的分辨率之间进行 skip 连接，将 convolutional 编码器和 transformer 的信息融合起来，以生成最终的分割。我们在 Cross-Modality Domain Adaptation（CrossMoDA）和 Medical Segmentation Decathlon 任务（MSD-5）上进行了评估，对 vestibular schwannoma 和 prostate 进行了分割。与当前的状态艺术方法相比，我们的方法在 Dice 分数方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Surrogate-Model-for-Geological-CO2-Storage-and-Its-Use-in-MCMC-based-History-Matching"><a href="#Surrogate-Model-for-Geological-CO2-Storage-and-Its-Use-in-MCMC-based-History-Matching" class="headerlink" title="Surrogate Model for Geological CO2 Storage and Its Use in MCMC-based History Matching"></a>Surrogate Model for Geological CO2 Storage and Its Use in MCMC-based History Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06341">http://arxiv.org/abs/2308.06341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifu Han, Francois P. Hamon, Su Jiang, Louis J. Durlofsky</li>
<li>for: 这个研究targets an important application in geological carbon storage operations, specifically history matching of storage systems with high prior geological uncertainty.</li>
<li>methods: The authors extend a recently introduced recurrent R-U-Net surrogate model to treat geomodel realizations drawn from a wide range of geological scenarios, using flow simulation results and a Markov chain Monte Carlo history matching workflow.</li>
<li>results: The surrogate model provides accurate predictions for new realizations over the full range of geological scenarios, with median relative error of 1.3% in pressure and 4.5% in saturation. The incorporation of the surrogate model into the history matching workflow reduces geological uncertainty and leads to posterior 3D pressure and saturation fields that display much closer agreement with the true-model responses than prior predictions.<details>
<summary>Abstract</summary>
Deep-learning-based surrogate models show great promise for use in geological carbon storage operations. In this work we target an important application - the history matching of storage systems characterized by a high degree of (prior) geological uncertainty. Toward this goal, we extend the recently introduced recurrent R-U-Net surrogate model to treat geomodel realizations drawn from a wide range of geological scenarios. These scenarios are defined by a set of metaparameters, which include the mean and standard deviation of log-permeability, permeability anisotropy ratio, horizontal correlation length, etc. An infinite number of realizations can be generated for each set of metaparameters, so the range of prior uncertainty is large. The surrogate model is trained with flow simulation results, generated using the open-source simulator GEOS, for 2000 random realizations. The flow problems involve four wells, each injecting 1 Mt CO2/year, for 30 years. The trained surrogate model is shown to provide accurate predictions for new realizations over the full range of geological scenarios, with median relative error of 1.3% in pressure and 4.5% in saturation. The surrogate model is incorporated into a Markov chain Monte Carlo history matching workflow, where the goal is to generate history matched realizations and posterior estimates of the metaparameters. We show that, using observed data from monitoring wells in synthetic `true' models, geological uncertainty is reduced substantially. This leads to posterior 3D pressure and saturation fields that display much closer agreement with the true-model responses than do prior predictions.
</details>
<details>
<summary>摘要</summary>
深度学习基本的代理模型在地质碳存储操作中表现出了极大的承诺。在这项工作中，我们target了一个重要应用 - 地质风险很高的存储系统历史匹配。为达到这个目标，我们将Recurrent R-U-Net代理模型扩展到处理各种不同的地质场景。这些场景是通过一组元参数来定义的，其中包括含量风险的平均值和标准差、滤 filtering ratio、水平相关长度等。可以生成无数量的实例 для每个元参数，因此地质风险的范围是非常广泛。我们使用GEOS开源模拟器对2000个随机实例进行流体模拟，并将模型训练于这些实例。训练后，代理模型能够准确预测新的实例，并且在全面的地质场景下显示了 median相对误差为1.3%的压力和4.5%的浓度。这个代理模型被 incorporated into Markov chain Monte Carlo历史匹配工作流程中，以生成历史匹配实例和 posterior 的元参数估计。我们显示，使用 synthetic 'true' 模型中的观测数据，地质风险可以减少得非常多。这导致了 posterior 3D 压力和浓度场 displaying much closer agreement with the true-model responses than prior predictions。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Open-Source-Toolkit-for-Eosinophil-Detection-in-Pediatric-Eosinophilic-Esophagitis"><a href="#Deep-Learning-Based-Open-Source-Toolkit-for-Eosinophil-Detection-in-Pediatric-Eosinophilic-Esophagitis" class="headerlink" title="Deep Learning-Based Open Source Toolkit for Eosinophil Detection in Pediatric Eosinophilic Esophagitis"></a>Deep Learning-Based Open Source Toolkit for Eosinophil Detection in Pediatric Eosinophilic Esophagitis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06333">http://arxiv.org/abs/2308.06333</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hrlblab/open-eoe">https://github.com/hrlblab/open-eoe</a></li>
<li>paper_authors: Juming Xiong, Yilin Liu, Ruining Deng, Regina N Tyree, Hernan Correa, Girish Hiremath, Yaohong Wang, Yuankai Huo<br>for:This paper aims to develop an open-source toolkit for automated detection of eosinophils in whole slide images for the diagnosis of eosinophilic esophagitis.methods:The toolkit uses deep learning-based object detection models and ensemble learning to improve the accuracy and reliability of eosinophil detection.results:The toolkit was tested on a set of 289 whole slide images and achieved an accuracy of 91% in detecting eosinophils at the widely accepted threshold of &gt;&#x3D; 15 per high power field for diagnosing eosinophilic esophagitis.<details>
<summary>Abstract</summary>
Eosinophilic Esophagitis (EoE) is a chronic, immune/antigen-mediated esophageal disease, characterized by symptoms related to esophageal dysfunction and histological evidence of eosinophil-dominant inflammation. Owing to the intricate microscopic representation of EoE in imaging, current methodologies which depend on manual identification are not only labor-intensive but also prone to inaccuracies. In this study, we develop an open-source toolkit, named Open-EoE, to perform end-to-end whole slide image (WSI) level eosinophil (Eos) detection using one line of command via Docker. Specifically, the toolkit supports three state-of-the-art deep learning-based object detection models. Furthermore, Open-EoE further optimizes the performance by implementing an ensemble learning strategy, and enhancing the precision and reliability of our results. The experimental results demonstrated that the Open-EoE toolkit can efficiently detect Eos on a testing set with 289 WSIs. At the widely accepted threshold of >= 15 Eos per high power field (HPF) for diagnosing EoE, the Open-EoE achieved an accuracy of 91%, showing decent consistency with pathologist evaluations. This suggests a promising avenue for integrating machine learning methodologies into the diagnostic process for EoE. The docker and source code has been made publicly available at https://github.com/hrlblab/Open-EoE.
</details>
<details>
<summary>摘要</summary>
《Eosinophilic Esophagitis (EoE)是一种慢性、免疫/抗原诱导的食道疾病，表现为食道功能障碍和 Histological 证据显示的吸收性黑色素细胞滥多性Inflammation。由于EoE的微scopic表现在成像中复杂，目前的方法ologies依靠 manual identification 不仅劳累也容易出错。本研究中，我们开发了一个开源工具kit，名为 Open-EoE，通过一行命令 via Docker 来实现整个扫描图像 (WSI) 层的吸收性黑色素细胞 (Eos) 检测。Specifically，工具kit 支持三种 state-of-the-art deep learning-based object detection 模型。此外，Open-EoE 还进一步优化了性能，通过实现 ensemble learning 策略，并提高了结果的精度和可靠性。实验结果表明，Open-EoE 工具kit 可以有效地检测 Eos 在289个 WSIs 上。在 widely accepted 的 >= 15 Eos per high power field (HPF) 的标准下，Open-EoE 达到了 91% 的准确率，与Pathologist 评估相当一致。这表明可以将机器学习方法 integrate 到 EoE 诊断过程中，并且 Open-EoE 的 Docker 和源代码已经在 https://github.com/hrlblab/Open-EoE 上公开 released。
</details></li>
</ul>
<hr>
<h2 id="Revolutionizing-Space-Health-Swin-FSR-Advancing-Super-Resolution-of-Fundus-Images-for-SANS-Visual-Assessment-Technology"><a href="#Revolutionizing-Space-Health-Swin-FSR-Advancing-Super-Resolution-of-Fundus-Images-for-SANS-Visual-Assessment-Technology" class="headerlink" title="Revolutionizing Space Health (Swin-FSR): Advancing Super-Resolution of Fundus Images for SANS Visual Assessment Technology"></a>Revolutionizing Space Health (Swin-FSR): Advancing Super-Resolution of Fundus Images for SANS Visual Assessment Technology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06332">http://arxiv.org/abs/2308.06332</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FarihaHossain/SwinFSR">https://github.com/FarihaHossain/SwinFSR</a></li>
<li>paper_authors: Khondker Fariha Hossain, Sharif Amit Kamran, Joshua Ong, Andrew G. Lee, Alireza Tavakkoli<br>for: 这paper是为了提出一种基于SwinTransformer的眼内画像超分辨模型，用于解决在各种各样的眼内图像识别任务中的数据传输压缩问题。methods: 这paper使用了SwinTransformer搭配空间和深度精度注意力来实现眼内图像超分辨。results: 这paper在三个公共数据集上达到了Peak signal-to-noise-ratio（PSNR）47.89、49.00和45.32，并在NASA提供的一个专用数据集上达到了相当的比较结果。<details>
<summary>Abstract</summary>
The rapid accessibility of portable and affordable retinal imaging devices has made early differential diagnosis easier. For example, color funduscopy imaging is readily available in remote villages, which can help to identify diseases like age-related macular degeneration (AMD), glaucoma, or pathological myopia (PM). On the other hand, astronauts at the International Space Station utilize this camera for identifying spaceflight-associated neuro-ocular syndrome (SANS). However, due to the unavailability of experts in these locations, the data has to be transferred to an urban healthcare facility (AMD and glaucoma) or a terrestrial station (e.g, SANS) for more precise disease identification. Moreover, due to low bandwidth limits, the imaging data has to be compressed for transfer between these two places. Different super-resolution algorithms have been proposed throughout the years to address this. Furthermore, with the advent of deep learning, the field has advanced so much that x2 and x4 compressed images can be decompressed to their original form without losing spatial information. In this paper, we introduce a novel model called Swin-FSR that utilizes Swin Transformer with spatial and depth-wise attention for fundus image super-resolution. Our architecture achieves Peak signal-to-noise-ratio (PSNR) of 47.89, 49.00 and 45.32 on three public datasets, namely iChallenge-AMD, iChallenge-PM, and G1020. Additionally, we tested the model's effectiveness on a privately held dataset for SANS provided by NASA and achieved comparable results against previous architectures.
</details>
<details>
<summary>摘要</summary>
“快速访问可携带便宜的肉眼成像设备，使得早期差异诊断变得更加容易。例如，颜色基准成像技术可以在偏远的村庄中提供，以帮助诊断年龄相关macular degeneration（AMD）、高压病（glaucoma）或 PATHOLOGICAL MYOPIA（PM）等疾病。然而，由于这些地点缺乏专业人士，因此数据必须被传输到城市医疗机构（AMD和 glaucoma）或地面站（例如，SANS）进行更加精确的疾病诊断。此外，由于带宽限制，成像数据必须进行压缩传输。过去数年，一些超分辨算法已经提出来解决这个问题。此外，随着深度学习的发展，这一领域已经进步到了非常高的水平，可以使得压缩后的成像数据被 decompress 到原始形式，而不会产生空间信息损失。本文提出了一种名为 Swin-FSR 的新模型，该模型使用 Swin Transformer 与空间和深度宽度注意来进行肉眼成像超分辨。我们的架构实现了 Peak signal-to-noise-ratio（PSNR）的 47.89、49.00 和 45.32 在三个公共数据集上，namely iChallenge-AMD、iChallenge-PM 和 G1020。此外，我们对 NASA 提供的一个私人保留数据集进行测试，并实现了与前一代架构相当的效果。”
</details></li>
</ul>
<hr>
<h2 id="A-Hierarchical-Descriptor-Framework-for-On-the-Fly-Anatomical-Location-Matching-between-Longitudinal-Studies"><a href="#A-Hierarchical-Descriptor-Framework-for-On-the-Fly-Anatomical-Location-Matching-between-Longitudinal-Studies" class="headerlink" title="A Hierarchical Descriptor Framework for On-the-Fly Anatomical Location Matching between Longitudinal Studies"></a>A Hierarchical Descriptor Framework for On-the-Fly Anatomical Location Matching between Longitudinal Studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07337">http://arxiv.org/abs/2308.07337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Halid Ziya Yerebakan, Yoshihisa Shinagawa, Mahesh Ranganath, Simon Allen-Raffl, Gerardo Hermosillo Valadez</li>
<li>for: 医疗图像 longitudinal 比较中匹配 анатомиче位置</li>
<li>methods: 使用 hierarchical sparse sampling 计算查询点描述符，然后使用 hierarchical search 找到最相似的点在目标图像中</li>
<li>results: 实现了减少计算时间至毫秒级单个CPU上，可以帮助医生在实时比较相似的 анатомиче位置而无需额外建筑或存储变换场景Is there anything else I can help you with?<details>
<summary>Abstract</summary>
We propose a method to match anatomical locations between pairs of medical images in longitudinal comparisons. The matching is made possible by computing a descriptor of the query point in a source image based on a hierarchical sparse sampling of image intensities that encode the location information. Then, a hierarchical search operation finds the corresponding point with the most similar descriptor in the target image. This simple yet powerful strategy reduces the computational time of mapping points to a millisecond scale on a single CPU. Thus, radiologists can compare similar anatomical locations in near real-time without requiring extra architectural costs for precomputing or storing deformation fields from registrations. Our algorithm does not require prior training, resampling, segmentation, or affine transformation steps. We have tested our algorithm on the recently published Deep Lesion Tracking dataset annotations. We observed more accurate matching compared to Deep Lesion Tracker while being 24 times faster than the most precise algorithm reported therein. We also investigated the matching accuracy on CT and MR modalities and compared the proposed algorithm's accuracy against ground truth consolidated from multiple radiologists.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，用于在医疗影像对比中匹配解剖位置。该方法基于源图像中计算查询点的特征器，该特征器是基于层次稀疏抽象的图像强度值，这些值编码了位置信息。然后，使用层次搜索操作找到目标图像中最相似的点。这种简单 yet 强大的策略可以在单个 CPU 上减少比较时间到毫秒级，因此让 radiologist 可以在实时比较相似的解剖位置，无需额外的建筑成本或存储扭变场的预计算或存储。我们的算法不需要先行训练、扩充、分割或非对映变换步骤。我们在最近发布的 Deep Lesion Tracking 数据集注释中进行了测试，并观察到比 Deep Lesion Tracker 更准确的匹配，同时比最精确的算法 report 在其中的 24 倍 faster。我们还 investigate 了该算法的匹配精度在 CT 和 MR Modalities 上，并与多名医生共同协调的ground truth进行比较。
</details></li>
</ul>
<hr>
<h2 id="FunnyBirds-A-Synthetic-Vision-Dataset-for-a-Part-Based-Analysis-of-Explainable-AI-Methods"><a href="#FunnyBirds-A-Synthetic-Vision-Dataset-for-a-Part-Based-Analysis-of-Explainable-AI-Methods" class="headerlink" title="FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods"></a>FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06248">http://arxiv.org/abs/2308.06248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/visinf/funnybirds">https://github.com/visinf/funnybirds</a></li>
<li>paper_authors: Robin Hesse, Simone Schaub-Meyer, Stefan Roth</li>
<li>for: 这个论文的目的是解释人工智能（XAI）领域中复杂的深度神经网络模型的内部工作方式。</li>
<li>methods: 这篇论文使用了一种新的Synthetic vision dataset，叫做FunnyBirds，以及一系列自动评估协议来解决XAI中缺乏ground truth解释的挑战。</li>
<li>results: 通过使用FunnyBirds dataset和自动评估协议，这篇论文报告了24种不同的神经网络模型和XAI方法的结果，并证明了这些方法在一种完全自动和系统的方式下的优缺点。<details>
<summary>Abstract</summary>
The field of explainable artificial intelligence (XAI) aims to uncover the inner workings of complex deep neural models. While being crucial for safety-critical domains, XAI inherently lacks ground-truth explanations, making its automatic evaluation an unsolved problem. We address this challenge by proposing a novel synthetic vision dataset, named FunnyBirds, and accompanying automatic evaluation protocols. Our dataset allows performing semantically meaningful image interventions, e.g., removing individual object parts, which has three important implications. First, it enables analyzing explanations on a part level, which is closer to human comprehension than existing methods that evaluate on a pixel level. Second, by comparing the model output for inputs with removed parts, we can estimate ground-truth part importances that should be reflected in the explanations. Third, by mapping individual explanations into a common space of part importances, we can analyze a variety of different explanation types in a single common framework. Using our tools, we report results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.
</details>
<details>
<summary>摘要</summary>
field of explainable artificial intelligence (XAI) 目的是暴露复杂深度神经网络模型的内部工作原理。而这种技术在安全关键领域非常重要，但XAI本身缺乏真实的解释，这使得自动评估成为一个未解决的问题。我们解决这个挑战 by proposing a novel synthetic vision dataset， named FunnyBirds，以及相应的自动评估协议。我们的数据集允许执行Semantically meaningful image interventions，例如 removing individual object parts，这有三个重要的后果。首先，它允许分析解释的部级划分，这更加接近人类的理解，而不是现有的方法，它们会评估像素级划分。其次，通过比较模型输出的各个部分输入，我们可以估算出各个部分的真实重要性，这些重要性应该反映在解释中。最后，我们可以将各种不同类型的解释映射到一个共同的部分重要性空间中，以便分析多种不同的解释类型在单一的框架中。使用我们的工具，我们报告了24种不同的神经网络模型和XAI方法的结果，这些结果 demonstrate了评估方法的优劣点在一个完全自动和系统的方式上。
</details></li>
</ul>
<hr>
<h2 id="Continual-Face-Forgery-Detection-via-Historical-Distribution-Preserving"><a href="#Continual-Face-Forgery-Detection-via-Historical-Distribution-Preserving" class="headerlink" title="Continual Face Forgery Detection via Historical Distribution Preserving"></a>Continual Face Forgery Detection via Historical Distribution Preserving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06217">http://arxiv.org/abs/2308.06217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Sun, Shen Chen, Taiping Yao, Xiaoshuai Sun, Shouhong Ding, Rongrong Ji</li>
<li>for: 防止面部伪造攻击的安全威胁</li>
<li>methods: 使用普遍攻击伪造模型、知识传递和历史分布保持等方法</li>
<li>results: 比前一代方法高效地检测新的伪造攻击，并维持了面部伪造 distribuition的稳定性<details>
<summary>Abstract</summary>
Face forgery techniques have advanced rapidly and pose serious security threats. Existing face forgery detection methods try to learn generalizable features, but they still fall short of practical application. Additionally, finetuning these methods on historical training data is resource-intensive in terms of time and storage. In this paper, we focus on a novel and challenging problem: Continual Face Forgery Detection (CFFD), which aims to efficiently learn from new forgery attacks without forgetting previous ones. Specifically, we propose a Historical Distribution Preserving (HDP) framework that reserves and preserves the distributions of historical faces. To achieve this, we use universal adversarial perturbation (UAP) to simulate historical forgery distribution, and knowledge distillation to maintain the distribution variation of real faces across different models. We also construct a new benchmark for CFFD with three evaluation protocols. Our extensive experiments on the benchmarks show that our method outperforms the state-of-the-art competitors.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Face forgery techniques have advanced rapidly and pose serious security threats. Existing face forgery detection methods try to learn generalizable features, but they still fall short of practical application. Additionally, finetuning these methods on historical training data is resource-intensive in terms of time and storage. In this paper, we focus on a novel and challenging problem: Continual Face Forgery Detection (CFFD), which aims to efficiently learn from new forgery attacks without forgetting previous ones. Specifically, we propose a Historical Distribution Preserving (HDP) framework that reserves and preserves the distributions of historical faces. To achieve this, we use universal adversarial perturbation (UAP) to simulate historical forgery distribution, and knowledge distillation to maintain the distribution variation of real faces across different models. We also construct a new benchmark for CFFD with three evaluation protocols. Our extensive experiments on the benchmarks show that our method outperforms the state-of-the-art competitors."中文简体版：现代面孔伪造技术得到了快速发展，对安全提供了严重的威胁。现有的面孔伪造检测方法尝试学习通用特征，但 ainda fall short of practical application。此外，在历史训练数据上进行finetuning这些方法是费时和占用存储空间的。在这篇论文中，我们关注一个新和挑战的问题： continual face forgery detection（CFFD），该问题的目标是高效地从新的伪造攻击中学习，而不是忘记之前的。我们提出了一个历史分布保持（HDP）框架，该框架保留和保持历史面孔的分布。为了实现这一目标，我们使用通用对抗扰动（UAP）来模拟历史伪造分布，并使用知识蒸馏来保持实际面孔的分布变化。我们还建立了一个新的CFFD数据集和三个评估协议。我们的广泛实验表明，我们的方法在CFFD中表现出了优于当前竞争者。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.CV_2023_08_12/" data-id="cloq1wl4m00gf7o882pbggkjo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.AI_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T12:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/cs.AI_2023_08_12/">cs.AI - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="VisIT-Bench-A-Benchmark-for-Vision-Language-Instruction-Following-Inspired-by-Real-World-Use"><a href="#VisIT-Bench-A-Benchmark-for-Vision-Language-Instruction-Following-Inspired-by-Real-World-Use" class="headerlink" title="VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use"></a>VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06595">http://arxiv.org/abs/2308.06595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonatan Bitton, Hritik Bansal, Jack Hessel, Rulin Shao, Wanrong Zhu, Anas Awadalla, Josh Gardner, Rohan Taori, Ludwig Schimdt</li>
<li>for: 评估视觉语言模型在真实世界中的 instrucion-following 能力（evaluate vision-language models’ ability to follow instructions in real-world scenarios）</li>
<li>methods: 使用 70 个 ‘instruction families’ 和 592 个测试查询（use 70 instruction families and 592 test queries），包括从基本认知到游戏和创意生成等多种任务（including tasks such as basic recognition, game playing, and creative generation）</li>
<li>results: 使用人工和自动评估方法，发现现有模型与参考模型之间的质量差距 relativelly large（using both human and automatic evaluation methods, the quality gap between existing models and reference models is relatively large），提供了一个动态参与的项目，让实验室和研究人员可以简单地在项目网站上提交自己的模型答案（providing a dynamic project that allows researchers and practitioners to simply submit their model’s responses on the project website）<details>
<summary>Abstract</summary>
We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for evaluation of instruction-following vision-language models for real-world use. Our starting point is curating 70 'instruction families' that we envision instruction tuned vision-language models should be able to address. Extending beyond evaluations like VQAv2 and COCO, tasks range from basic recognition to game playing and creative generation. Following curation, our dataset comprises 592 test queries, each with a human-authored instruction-conditioned caption. These descriptions surface instruction-specific factors, e.g., for an instruction asking about the accessibility of a storefront for wheelchair users, the instruction-conditioned caption describes ramps/potential obstacles. These descriptions enable 1) collecting human-verified reference outputs for each instance; and 2) automatic evaluation of candidate multimodal generations using a text-only LLM, aligning with human judgment. We quantify quality gaps between models and references using both human and automatic evaluations; e.g., the top-performing instruction-following model wins against the GPT-4 reference in just 27% of the comparison. VisIT-Bench is dynamic to participate, practitioners simply submit their model's response on the project website; Data, code and leaderboard is available at visit-bench.github.io.
</details>
<details>
<summary>摘要</summary>
我们介绍VisIT-Bench（视觉指令比赛），一个用于评估视觉语言模型的实际应用场景的 benchmark。我们开始于精心选择70个“指令家庭”，我们认为视觉语言模型应该能够解决这些指令。我们的数据集包括592个测试查询，每个查询都有一个人工生成的指令条件描述。这些描述包括指令特有的因素，例如一个指令要求关于轮椅用户是否可以进入商店的访问性，描述了斜坡/潜在障碍物。这些描述允许我们收集人工验证的参考输出 для每个实例，并使用文本 только LLM 自动评估候选的多Modal生成。我们使用人工和自动评估来衡量模型和参考之间的质量差距，例如，最高级别的指令遵循模型只在与 GPT-4 参考的比赛中赢得27%。VisIT-Bench 是开放的，参与者可以在项目网站上提交他们的模型的回答。数据、代码和排名信息可以在 visit-bench.github.io 上获得。
</details></li>
</ul>
<hr>
<h2 id="Value-Distributional-Model-Based-Reinforcement-Learning"><a href="#Value-Distributional-Model-Based-Reinforcement-Learning" class="headerlink" title="Value-Distributional Model-Based Reinforcement Learning"></a>Value-Distributional Model-Based Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06590">http://arxiv.org/abs/2308.06590</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Carlos E. Luis, Alessandro G. Bottero, Julia Vinogradska, Felix Berkenkamp, Jan Peters</li>
<li>for: 这个论文目的是为了解决sequential decision-making任务中的uncertainty quantification问题。</li>
<li>methods: 这个论文使用了model-based Bayesian reinforcement learning的方法，其中的目标是学习Markov决策过程中参数不确定性induced的 posterior distribution over value functions。</li>
<li>results: 论文的实验表明，EQR算法可以在 continuous-control tasks 中比Established model-based和model-free算法表现出性能优势。<details>
<summary>Abstract</summary>
Quantifying uncertainty about a policy's long-term performance is important to solve sequential decision-making tasks. We study the problem from a model-based Bayesian reinforcement learning perspective, where the goal is to learn the posterior distribution over value functions induced by parameter (epistemic) uncertainty of the Markov decision process. Previous work restricts the analysis to a few moments of the distribution over values or imposes a particular distribution shape, e.g., Gaussians. Inspired by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function. Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. Evaluation across several continuous-control tasks shows performance benefits with respect to established model-based and model-free algorithms.
</details>
<details>
<summary>摘要</summary>
<<SYS>>量化政策长期表现的不确定性是解决sequential decision-making任务的重要问题。我们从model-based Bayesian reinforcement learning的视角 изуча这个问题，目标是学习Markov决策过程中参数（эпистемиче）不确定性引起的 posterior distribution over value functions。先前的工作只考虑了这些分布的一些瞬间或假设了特定的分布形式，例如 Gaussian。 inspirited by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function。 Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. 评估在多个连续控制任务上表现出与已有的model-based和model-free算法相比的性能优势。Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Approximate-Answering-of-Graph-Queries"><a href="#Approximate-Answering-of-Graph-Queries" class="headerlink" title="Approximate Answering of Graph Queries"></a>Approximate Answering of Graph Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06585">http://arxiv.org/abs/2308.06585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Cochez, Dimitrios Alivanistos, Erik Arakelyan, Max Berrendorf, Daniel Daza, Mikhail Galkin, Pasquale Minervini, Mathias Niepert, Hongyu Ren</li>
<li>for: 本文旨在介绍几种方法，以帮助回答含有不完整信息的知识图（KG）中的查询。</li>
<li>methods: 本文提出了多种方法，包括基于预测、基于潜在相似性、基于证据等方法，以满足不同类型的查询需求。</li>
<li>results: 这些方法可以帮助解决各种查询问题，如答案推断、 Entity Disambiguation、 Relation extraction 等。但是，这些方法受到图数据不完整和不准确的限制。<details>
<summary>Abstract</summary>
Knowledge graphs (KGs) are inherently incomplete because of incomplete world knowledge and bias in what is the input to the KG. Additionally, world knowledge constantly expands and evolves, making existing facts deprecated or introducing new ones. However, we would still want to be able to answer queries as if the graph were complete. In this chapter, we will give an overview of several methods which have been proposed to answer queries in such a setting. We will first provide an overview of the different query types which can be supported by these methods and datasets typically used for evaluation, as well as an insight into their limitations. Then, we give an overview of the different approaches and describe them in terms of expressiveness, supported graph types, and inference capabilities.
</details>
<details>
<summary>摘要</summary>
知识图（KG）自然而然地是不完整的，因为世界知识的不完整和输入KG中的偏见。此外，世界知识不断扩展和发展，使现有的事实过时或引入新的事实。然而，我们仍然希望能够回答问题，作为如果图完整一样。在这章中，我们将给出不同类型的查询支持的方法的概述，以及通常用于评估的数据集，以及这些方法的局限性。然后，我们将对不同的方法进行描述，包括表达力、支持的图类型和推理能力。
</details></li>
</ul>
<hr>
<h2 id="4DRVO-Net-Deep-4D-Radar-Visual-Odometry-Using-Multi-Modal-and-Multi-Scale-Adaptive-Fusion"><a href="#4DRVO-Net-Deep-4D-Radar-Visual-Odometry-Using-Multi-Modal-and-Multi-Scale-Adaptive-Fusion" class="headerlink" title="4DRVO-Net: Deep 4D Radar-Visual Odometry Using Multi-Modal and Multi-Scale Adaptive Fusion"></a>4DRVO-Net: Deep 4D Radar-Visual Odometry Using Multi-Modal and Multi-Scale Adaptive Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06573">http://arxiv.org/abs/2308.06573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guirong Zhuo, Shouyi Lu, Huanyu Zhou, Lianqing Zheng, Lu Xiong<br>for:* 4D radar–visual odometry (4DRVO) is an attractive solution for achieving accurate and robust pose estimation by integrating complementary information from 4D radar and cameras.methods:* 4DRVO-Net leverages a feature pyramid, pose warping, and cost volume (PWC) network architecture to progressively estimate and refine poses, with a multi-scale feature extraction network called Radar-PointNet++ that fully considers rich 4D radar point information.* An adaptive 4D radar–camera fusion module (A-RCFM) is designed to automatically select image features based on 4D radar point features, facilitating multi-scale cross-modal feature interaction and adaptive multi-modal feature fusion.results:* Our method outperforms all learning-based and geometry-based methods for most sequences in the VoD dataset, and has exhibited promising performance that closely approaches that of the 64-line LiDAR odometry results of A-LOAM without mapping optimization.<details>
<summary>Abstract</summary>
Four-dimensional (4D) radar--visual odometry (4DRVO) integrates complementary information from 4D radar and cameras, making it an attractive solution for achieving accurate and robust pose estimation. However, 4DRVO may exhibit significant tracking errors owing to three main factors: 1) sparsity of 4D radar point clouds; 2) inaccurate data association and insufficient feature interaction between the 4D radar and camera; and 3) disturbances caused by dynamic objects in the environment, affecting odometry estimation. In this paper, we present 4DRVO-Net, which is a method for 4D radar--visual odometry. This method leverages the feature pyramid, pose warping, and cost volume (PWC) network architecture to progressively estimate and refine poses. Specifically, we propose a multi-scale feature extraction network called Radar-PointNet++ that fully considers rich 4D radar point information, enabling fine-grained learning for sparse 4D radar point clouds. To effectively integrate the two modalities, we design an adaptive 4D radar--camera fusion module (A-RCFM) that automatically selects image features based on 4D radar point features, facilitating multi-scale cross-modal feature interaction and adaptive multi-modal feature fusion. In addition, we introduce a velocity-guided point-confidence estimation module to measure local motion patterns, reduce the influence of dynamic objects and outliers, and provide continuous updates during pose refinement. We demonstrate the excellent performance of our method and the effectiveness of each module design on both the VoD and in-house datasets. Our method outperforms all learning-based and geometry-based methods for most sequences in the VoD dataset. Furthermore, it has exhibited promising performance that closely approaches that of the 64-line LiDAR odometry results of A-LOAM without mapping optimization.
</details>
<details>
<summary>摘要</summary>
四维度（4D）雷达--视觉协调（4DRVO）结合了不同信息，使得它成为了精度和可靠性很高的pose estimation的有力解决方案。然而，4DRVO可能会出现严重的跟踪错误，这些错误主要来自于以下三个原因：1）4D雷达点云稀疏; 2）摄像头和雷达数据的不准确相关和不足的特征互动; 3）环境中的动态对象的干扰，影响 pose estimation。在这篇文章中，我们提出了4DRVO-Net，这是一种4D雷达--视觉协调方法。这种方法利用了特征层、pose扭曲和成本量网络架构，逐步估算和精化pose。我们提出了一种多尺度特征提取网络，叫做Radar-PointNet++,该网络可以全面考虑4D雷达点云的丰富信息，以便细化学习稀疏4D雷达点云。为了有效地结合两种模式，我们设计了自适应4D雷达--摄像头融合模块（A-RCFM），该模块可以根据4D雷达点云特征自动选择摄像头特征，实现了多尺度交互和自适应多模式特征融合。此外，我们引入了速度导向点信任度估计模块，可以测量本地运动趋势，减少动态对象和异常点的影响，并在pose精化过程中提供连续更新。我们在VoD和自有 dataset上展示了我们的方法的优秀性和每个模块设计的有效性。我们的方法在大多数序列上超过了所有学习基于和几何基于的方法，并且在64行LiDAR odometry结果的A-LOAM不需要地图优化的情况下，表现出了可观的表现。
</details></li>
</ul>
<hr>
<h2 id="ModelScope-Text-to-Video-Technical-Report"><a href="#ModelScope-Text-to-Video-Technical-Report" class="headerlink" title="ModelScope Text-to-Video Technical Report"></a>ModelScope Text-to-Video Technical Report</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06571">http://arxiv.org/abs/2308.06571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuniu Wang, Hangjie Yuan, Dayou Chen, Yingya Zhang, Xiang Wang, Shiwei Zhang</li>
<li>for: 这个论文旨在描述一种基于文本-图像合成模型（即Stable Diffusion）的文本-视频合成模型（ModelScopeT2V）。</li>
<li>methods: 该模型采用了空间-时间块来保证渠道生成顺序和运动过渡的一致性，并且可以在训练和推理阶段适应不同的帧数。模型包括三个组件（即VQGAN、文本编码器和杂噪UNet），总共含1.7亿个参数，其中0.5亿个参数专门用于时间能力。</li>
<li>results: 模型在三个评价指标上表现出优于当前状态艺术方法。代码和在线demo可以在\url{<a target="_blank" rel="noopener" href="https://modelscope.cn/models/damo/text-to-video-synthesis/summary%7D%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://modelscope.cn/models/damo/text-to-video-synthesis/summary}中找到。</a><details>
<summary>Abstract</summary>
This paper introduces ModelScopeT2V, a text-to-video synthesis model that evolves from a text-to-image synthesis model (i.e., Stable Diffusion). ModelScopeT2V incorporates spatio-temporal blocks to ensure consistent frame generation and smooth movement transitions. The model could adapt to varying frame numbers during training and inference, rendering it suitable for both image-text and video-text datasets. ModelScopeT2V brings together three components (i.e., VQGAN, a text encoder, and a denoising UNet), totally comprising 1.7 billion parameters, in which 0.5 billion parameters are dedicated to temporal capabilities. The model demonstrates superior performance over state-of-the-art methods across three evaluation metrics. The code and an online demo are available at \url{https://modelscope.cn/models/damo/text-to-video-synthesis/summary}.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了ModelScopeT2V，一种文本到视频合成模型，它从文本到图像合成模型（即稳定扩散）中演化出来。ModelScopeT2V包含空间-时间块来保证 Frame 生成的一致性和平滑的运动过渡。模型可以在训练和推理过程中适应不同的帧数，因此适用于图像-文本和视频-文本数据集。ModelScopeT2V由三个组件（即 VQGAN、文本编码器和杂净 UNet）组成，总共含有1.7亿参数，其中0.5亿参数专门用于时间能力。模型在三个评价指标上表现出色，超过了当前最佳方法。代码和在线示例可以在 \url{https://modelscope.cn/models/damo/text-to-video-synthesis/summary} 上获取。
</details></li>
</ul>
<hr>
<h2 id="MC-DRE-Multi-Aspect-Cross-Integration-for-Drug-Event-Entity-Extraction"><a href="#MC-DRE-Multi-Aspect-Cross-Integration-for-Drug-Event-Entity-Extraction" class="headerlink" title="MC-DRE: Multi-Aspect Cross Integration for Drug Event&#x2F;Entity Extraction"></a>MC-DRE: Multi-Aspect Cross Integration for Drug Event&#x2F;Entity Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06546">http://arxiv.org/abs/2308.06546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Yang, Soyeon Caren Han, Siqu Long, Josiah Poon, Goran Nenadic</li>
<li>For: This paper proposes a new multi-aspect cross-integration framework for drug entity&#x2F;event detection in drug-related documents.* Methods: The proposed framework uses multi-aspect encoders to describe semantic, syntactic, and medical document contextual information, and conducts cross-integration of different contextual information in three ways: key-value cross, attention cross, and feedforward cross.* Results: The proposed model outperforms all state-of-the-art (SOTA) models on two widely used tasks, flat entity detection and discontinuous event extraction.<details>
<summary>Abstract</summary>
Extracting meaningful drug-related information chunks, such as adverse drug events (ADE), is crucial for preventing morbidity and saving many lives. Most ADEs are reported via an unstructured conversation with the medical context, so applying a general entity recognition approach is not sufficient enough. In this paper, we propose a new multi-aspect cross-integration framework for drug entity/event detection by capturing and aligning different context/language/knowledge properties from drug-related documents. We first construct multi-aspect encoders to describe semantic, syntactic, and medical document contextual information by conducting those slot tagging tasks, main drug entity/event detection, part-of-speech tagging, and general medical named entity recognition. Then, each encoder conducts cross-integration with other contextual information in three ways: the key-value cross, attention cross, and feedforward cross, so the multi-encoders are integrated in depth. Our model outperforms all SOTA on two widely used tasks, flat entity detection and discontinuous event extraction.
</details>
<details>
<summary>摘要</summary>
<<SYS>>提取有用的药物相关信息块，如负面影响（ADE），对避免负担和拯救生命非常重要。大多数ADE都是通过不结构化的医疗讨论报告的方式报告的，因此使用一般的实体识别方法不够。在这篇论文中，我们提议一种新的多方面融合框架，用于药物实体/事件检测，通过捕捉和对照不同语言/知识/文档上下文的信息来描述药物相关文档。我们首先构建多方面编码器，用于描述语义、语法和医疗文档上下文信息，包括插槽标注任务、主药物实体/事件检测、语法标注和普通医学实体识别。然后，每个编码器进行了三种跨integration：键值跨、注意力跨和Feedforward跨，以融合多个上下文信息。我们的模型在两个常用任务上都超过了所有SOTA的性能。
</details></li>
</ul>
<hr>
<h2 id="Digital-elevation-model-correction-in-urban-areas-using-extreme-gradient-boosting-land-cover-and-terrain-parameters"><a href="#Digital-elevation-model-correction-in-urban-areas-using-extreme-gradient-boosting-land-cover-and-terrain-parameters" class="headerlink" title="Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters"></a>Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06545">http://arxiv.org/abs/2308.06545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chukwuma Okolie, Jon Mills, Adedayo Adeleke, Julian Smit</li>
<li>For: The paper aims to enhance the accuracy of medium-resolution digital elevation models (DEMs) in urban areas, specifically in Cape Town, South Africa, for hydrological and environmental modelling.* Methods: The authors use the extreme gradient boosting (XGBoost) ensemble algorithm to correct the DEMs, with eleven predictor variables including elevation, urban footprints, slope, aspect, surface roughness, and more.* Results: The corrected DEMs achieved significant accuracy gains, with a root mean square error (RMSE) improvement of 46-53% for Copernicus DEM and 72-73% for AW3D DEM, compared to other proposed methods. These results demonstrate the potential of gradient boosted trees for enhancing DEM quality and improving hydrological modelling in urban catchments.Here is the same information in Simplified Chinese text, as requested:* For: 这个论文的目的是提高城市区域中的数字高程模型（DEM）的准确性，以便于水文和环境模型。* Methods: 作者使用极限Gradient Boosting（XGBoost）ensemble算法来修正DEM，使用的predictor变量包括高程、城市脚印、坡度、方向、表面荒凉、地形位置指数、地形荒凉指数、地形表面 текстура等 eleven个变量。* Results: 修正后的DEM实现了显著的准确性提高，比如 Copernicus DEM的RMSE提高46-53%，AW3D DEM的RMSE提高72-73%，与其他提议的方法相比。这些结果表明极限Gradient Boosting树可以提高DEM的质量，并且为城市catchments中的水文模型提供改善。<details>
<summary>Abstract</summary>
The accuracy of digital elevation models (DEMs) in urban areas is influenced by numerous factors including land cover and terrain irregularities. Moreover, building artifacts in global DEMs cause artificial blocking of surface flow pathways. This compromises their quality and adequacy for hydrological and environmental modelling in urban landscapes where precise and accurate terrain information is needed. In this study, the extreme gradient boosting (XGBoost) ensemble algorithm is adopted for enhancing the accuracy of two medium-resolution 30m DEMs over Cape Town, South Africa: Copernicus GLO-30 and ALOS World 3D (AW3D). XGBoost is a scalable, portable and versatile gradient boosting library that can solve many environmental modelling problems. The training datasets are comprised of eleven predictor variables including elevation, urban footprints, slope, aspect, surface roughness, topographic position index, terrain ruggedness index, terrain surface texture, vector roughness measure, forest cover and bare ground cover. The target variable (elevation error) was calculated with respect to highly accurate airborne LiDAR. After training and testing, the model was applied for correcting the DEMs at two implementation sites. The correction achieved significant accuracy gains which are competitive with other proposed methods. The root mean square error (RMSE) of Copernicus DEM improved by 46 to 53% while the RMSE of AW3D DEM improved by 72 to 73%. These results showcase the potential of gradient boosted trees for enhancing the quality of DEMs, and for improved hydrological modelling in urban catchments.
</details>
<details>
<summary>摘要</summary>
地数模型（DEM）在城市地区的准确性受到多种因素的影响，包括地表覆盖物和地形 irregularities。此外，全球 DEM 中的建筑物略导致表面流道路径的人工堵塞，从而降低其质量和适用性 для水文环境模型在城市景观中，需要精准和准确的地形信息。在这种研究中，我们采用了极限拟合搅拌（XGBoost）ensemble算法来提高两个中等分辨率 30 m DEM 的准确性，即 Copernicus GLO-30 和 ALOS World 3D（AW3D）。XGBoost 是一种可扩展、可移植和多样的拟合搅拌库，可以解决许多环境模型问题。训练数据集包括 eleven 个预测变量，包括高程、城市脚印、坡度、方向、表面粗糙度、地形坡度指数、地形表面文化、向量粗糙度度量、森林覆盖率和裸地覆盖率。target variable （高程误差）与高精度飞行 LiDAR 进行计算。之后，模型被应用于修正 DEM 的两个实施场景。修正后，DEM 的Root Mean Square Error（RMSE）提高了46%到53%，AW3D DEM 的 RMSE 提高了72%到73%。这些结果显示了拟合搅拌树的潜在可能性，以及对城市流域水文模型的改进。
</details></li>
</ul>
<hr>
<h2 id="Dealing-with-Small-Datasets-for-Deep-Learning-in-Medical-Imaging-An-Evaluation-of-Self-Supervised-Pre-Training-on-CT-Scans-Comparing-Contrastive-and-Masked-Autoencoder-Methods-for-Convolutional-Models"><a href="#Dealing-with-Small-Datasets-for-Deep-Learning-in-Medical-Imaging-An-Evaluation-of-Self-Supervised-Pre-Training-on-CT-Scans-Comparing-Contrastive-and-Masked-Autoencoder-Methods-for-Convolutional-Models" class="headerlink" title="Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models"></a>Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06534">http://arxiv.org/abs/2308.06534</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wolfda95/ssl-medicalimagining-cl-mae">https://github.com/wolfda95/ssl-medicalimagining-cl-mae</a></li>
<li>paper_authors: Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Timo Ropinski, Michael Götz</li>
<li>for: 这篇论文旨在探讨deep learning在医疗影像领域中的应用，以减少诊断错误、轻量化医生工作负担，并加快诊断。</li>
<li>methods: 这篇论文使用了自动标注学习方法，包括对大量无标注影像进行自动标注。</li>
<li>results: 研究发现，使用SparK预训方法可以更好地适应小型标注数据，并且在诊断任务中表现更好。<details>
<summary>Abstract</summary>
Deep learning in medical imaging has the potential to minimize the risk of diagnostic errors, reduce radiologist workload, and accelerate diagnosis. Training such deep learning models requires large and accurate datasets, with annotations for all training samples. However, in the medical imaging domain, annotated datasets for specific tasks are often small due to the high complexity of annotations, limited access, or the rarity of diseases. To address this challenge, deep learning models can be pre-trained on large image datasets without annotations using methods from the field of self-supervised learning. After pre-training, small annotated datasets are sufficient to fine-tune the models for a specific task. The most popular self-supervised pre-training approaches in medical imaging are based on contrastive learning. However, recent studies in natural image processing indicate a strong potential for masked autoencoder approaches. Our work compares state-of-the-art contrastive learning methods with the recently introduced masked autoencoder approach "SparK" for convolutional neural networks (CNNs) on medical images. Therefore we pre-train on a large unannotated CT image dataset and fine-tune on several CT classification tasks. Due to the challenge of obtaining sufficient annotated training data in medical imaging, it is of particular interest to evaluate how the self-supervised pre-training methods perform when fine-tuning on small datasets. By experimenting with gradually reducing the training dataset size for fine-tuning, we find that the reduction has different effects depending on the type of pre-training chosen. The SparK pre-training method is more robust to the training dataset size than the contrastive methods. Based on our results, we propose the SparK pre-training for medical imaging tasks with only small annotated datasets.
</details>
<details>
<summary>摘要</summary>
深度学习在医疗影像领域可能减少诊断错误风险，减轻放射学家的工作负担，并加速诊断。深度学习模型的训练需要大量和准确的数据集，并将所有训练样本标注。然而，在医疗影像领域，特定任务的标注数据集经常很小，这可能由标注的复杂性、访问限制或疾病的罕见性引起。为解决这个挑战，可以使用自动标注学习的方法进行深度学习模型的预训练。在预训练后，只需要小量的标注数据集来精度地调整模型 для特定任务。医疗影像领域最受欢迎的自动标注预训练方法是对比学习。然而，最近的自然图像处理研究表明，遮盲 autoencoder 方法有很强的潜在性。我们的工作比较了当前状态的对比学习方法和新引入的遮盲 autoencoder 方法 "SparK" 在医疗影像中的 convolutional neural networks (CNNs) 上。因此，我们预训练在大量无注释 CT 图像数据集上，并在多个 CT 分类任务上进行精度调整。由于医疗影像领域获得足够的注释训练数据是困难的，因此特别关心自动标注预训练方法在小型注释数据集上的性能。通过逐渐减少 fine-tuning 数据集大小的实验，我们发现降低的效果与预训练方法的类型有很大的差异。SparK 预训练方法在训练数据集尺寸减少后表现更加稳定。根据我们的结果，我们建议使用 SparK 预训练方法进行医疗影像任务，只需要小量的注释训练数据。
</details></li>
</ul>
<hr>
<h2 id="Learning-Abstract-Visual-Reasoning-via-Task-Decomposition-A-Case-Study-in-Raven-Progressive-Matrices"><a href="#Learning-Abstract-Visual-Reasoning-via-Task-Decomposition-A-Case-Study-in-Raven-Progressive-Matrices" class="headerlink" title="Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices"></a>Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06528">http://arxiv.org/abs/2308.06528</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jakubkwiatkowski/abstract_compositional_transformer">https://github.com/jakubkwiatkowski/abstract_compositional_transformer</a></li>
<li>paper_authors: Jakub Kwiatkowski, Krzysztof Krawiec</li>
<li>for: The paper aims to improve the performance of solving Raven Progressive Matrices (RPM) tasks using deep learning.</li>
<li>methods: The proposed method uses a transformer-based architecture to predict the visual properties of individual objects and their arrangements, rather than directly choosing the answer. The model parses the visual input into tokens and is trained using self-supervised methods with various masking regimes.</li>
<li>results: The proposed method outperforms state-of-the-art methods and provides interesting insights and partial explanations about the inference. Additionally, the design of the method is immune to biases that exist in some RPM benchmarks.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文目的是使用深度学习方法改进解决Raven Progressive Matrices (RPM)任务。</li>
<li>methods: 提议的方法使用 transformer 架构，而不是直接选择答案，而是预测图像中对象的视觉属性和排列。模型将视觉输入解析成 токен，并使用自我超vised 训练方法，包括不同的掩蔽方式。</li>
<li>results: 提议的方法不仅超越了当前的方法，还提供了有趣的解释和偏好。此外，方法的设计也免备了一些 RPM 数据集中的偏见。<details>
<summary>Abstract</summary>
One of the challenges in learning to perform abstract reasoning is that problems are often posed as monolithic tasks, with no intermediate subgoals. In Raven Progressive Matrices (RPM), the task is to choose one of the available answers given a context, where both contexts and answers are composite images featuring multiple objects in various spatial arrangements. As this high-level goal is the only guidance available, learning is challenging and most contemporary solvers tend to be opaque. In this study, we propose a deep learning architecture based on the transformer blueprint which, rather than directly making the above choice, predicts the visual properties of individual objects and their arrangements. The multidimensional predictions obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assessment, the models not only outperform state-of-the-art methods but also provide interesting insights and partial explanations about the inference. The design of the method also makes it immune to biases that are known to exist in some RPM benchmarks.
</details>
<details>
<summary>摘要</summary>
一个learning抽象逻辑的挑战是问题经常被提出为单一任务，没有中间目标。在Raven进步矩阵（RPM）中，任务是根据上下文选择一个可用的答案，上下文和答案都是复杂的图像组合，包括多个物体在不同的空间排列。由于这个高级目标是唯一的指导，学习是困难的，大多数当代解决方案都是透明的。在这项研究中，我们提议一种基于转换器蓝图的深度学习架构，而不是直接选择上述选择，而是预测图像中对象的视觉属性和排列。得到的多维预测可以直接相互对比，从而选择答案。我们考虑了一些将视觉输入分解成токен的方法，以及在自然supervised训练中隐藏部分输入的方法。在实验评估中，模型不仅超越了当前的方法，还提供了有趣的结论和部分解释，关于推理过程。此外，方法的设计还使其免受一些RPMbenchmark中已知的偏见。
</details></li>
</ul>
<hr>
<h2 id="SLoRA-Federated-Parameter-Efficient-Fine-Tuning-of-Language-Models"><a href="#SLoRA-Federated-Parameter-Efficient-Fine-Tuning-of-Language-Models" class="headerlink" title="SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models"></a>SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06522">http://arxiv.org/abs/2308.06522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Babakniya, Ahmed Roushdy Elkordy, Yahya H. Ezzeldin, Qingfeng Liu, Kee-Bong Song, Mostafa El-Khamy, Salman Avestimehr</li>
<li>for: 这篇论文目的是探讨在 Federated Learning（FL）中使用已经预训练的 transformer 模型进行调整，以获得最佳的语言任务结果。</li>
<li>methods: 这篇论文使用的方法包括 parameter efficient fine-tuning（PEFT）和一个名为 SLoRA 的新方法，用于在高度多标的数据情况下bridge the performance gap between PEFT 和全部调整。</li>
<li>results: 实验结果显示，SLoRA 可以 дости持比 full fine-tuning 相似的性能，并在大约 $\sim 1%$ 的稀疏更新下实现大约 $90%$ 的训练时间减少。<details>
<summary>Abstract</summary>
Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data scenarios through a novel data-driven initialization technique. Our experimental results demonstrate that SLoRA achieves performance comparable to full fine-tuning, with significant sparse updates with approximately $\sim 1\%$ density while reducing training time by up to $90\%$.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese: Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data scenarios through a novel data-driven initialization technique. Our experimental results demonstrate that SLoRA achieves performance comparable to full fine-tuning, with significant sparse updates with approximately $\sim 1\%$ density while reducing training time by up to $90\%$.Transfer learning via fine-tuning pre-trained transformer models 在各种 NLP 任务中取得了很大的成功，但在没有中央数据的情况下，Federated Learning (FL) 可以利用分布式和私有的 FL 边缘客户端数据进行 fine-tuning。然而，由于边缘设备的限制性，包括通信、计算和存储能力，以及流行的 transformer 模型的巨大大小，fficient fine-tuning 是使 federated 训练可行的关键。这个工作探讨了在不同的 FL 设置下，用于语言任务的 PEFT 方法所面临的机会和挑战。我们的调查发现，随着用户数据的多样化，完全 fine-tuning 和 PEFT 方法之间的性能差距逐渐扩大。为了弥补这个性能差距，我们提议一种名为 SLoRA 的方法，通过一种新的数据驱动初始化技术，超越 LoRA 在高多样性数据场景中的关键局限性。我们的实验结果表明，SLoRA 可以与完全 fine-tuning 相比，在 $\sim 1\%$ 杂点上实现相似的性能，同时减少训练时间达到 $90\%$。
</details></li>
</ul>
<hr>
<h2 id="One-bit-Flip-is-All-You-Need-When-Bit-flip-Attack-Meets-Model-Training"><a href="#One-bit-Flip-is-All-You-Need-When-Bit-flip-Attack-Meets-Model-Training" class="headerlink" title="One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training"></a>One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07934">http://arxiv.org/abs/2308.07934</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jianshuod/tba">https://github.com/jianshuod/tba</a></li>
<li>paper_authors: Jianshuo Dong, Han Qiu, Yiming Li, Tianwei Zhang, Yuanjie Li, Zeqi Lai, Chao Zhang, Shu-Tao Xia</li>
<li>For: This paper aims to propose a training-assisted bit flip attack on deep neural networks (DNNs) to compromise their security.* Methods: The attack exploits memory fault inject techniques such as row hammer and involves the adversary in the training stage to build a high-risk model. The attack can convert the high-risk model to a malicious one on the victim’s side by flipping only one critical bit on average in the deployment stage.* Results: The attack poses a significant threat even when defenses are employed, and the adversary can easily convert the high-risk model to a malicious one by flipping only one critical bit on average.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是提出一种基于训练的位置攻击，用于攻击深度神经网络（DNNs）的安全性。</li>
<li>methods: 该攻击利用了内存错误注入技术，如行撞击，并在训练阶段由敌方参与建立高风险模型。攻击者可以在部署阶段通过只flipping一个关键位来将高风险模型转换为恶意模型。</li>
<li>results: 该攻击可以快速地转换高风险模型为恶意模型，并且对防御措施仍然构成了一定的威胁。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are widely deployed on real-world devices. Concerns regarding their security have gained great attention from researchers. Recently, a new weight modification attack called bit flip attack (BFA) was proposed, which exploits memory fault inject techniques such as row hammer to attack quantized models in the deployment stage. With only a few bit flips, the target model can be rendered useless as a random guesser or even be implanted with malicious functionalities. In this work, we seek to further reduce the number of bit flips. We propose a training-assisted bit flip attack, in which the adversary is involved in the training stage to build a high-risk model to release. This high-risk model, obtained coupled with a corresponding malicious model, behaves normally and can escape various detection methods. The results on benchmark datasets show that an adversary can easily convert this high-risk but normal model to a malicious one on victim's side by \textbf{flipping only one critical bit} on average in the deployment stage. Moreover, our attack still poses a significant threat even when defenses are employed. The codes for reproducing main experiments are available at \url{https://github.com/jianshuod/TBA}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HyperFormer-Enhancing-Entity-and-Relation-Interaction-for-Hyper-Relational-Knowledge-Graph-Completion"><a href="#HyperFormer-Enhancing-Entity-and-Relation-Interaction-for-Hyper-Relational-Knowledge-Graph-Completion" class="headerlink" title="HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion"></a>HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06512">http://arxiv.org/abs/2308.06512</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhiweihu1103/hkgc-hyperformer">https://github.com/zhiweihu1103/hkgc-hyperformer</a></li>
<li>paper_authors: Zhiwei Hu, Víctor Gutiérrez-Basulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan</li>
<li>for: 这个论文主要目标是完善具有 attribute-value 赋值的高级知识图（HKG），以推理未知 triple 而考虑其赋值。</li>
<li>methods: 这个论文提出了 HyperFormer 模型，该模型利用了本地级别的序列信息，包括实体、关系和赋值的内容，以提高 triple 预测的精度。模型包括三个不同模块：实体邻居聚合模块、关系赋值聚合模块和卷积推理模块。</li>
<li>results: 经过广泛的实验 validate 了 HyperFormer 模型在三个知识图 datasets 上的效果，并且在不同的条件下进行了比较。模型在实验中表现出了明显的优势。代码和数据可以在 GitHub 上找到。<details>
<summary>Abstract</summary>
Hyper-relational knowledge graphs (HKGs) extend standard knowledge graphs by associating attribute-value qualifiers to triples, which effectively represent additional fine-grained information about its associated triple. Hyper-relational knowledge graph completion (HKGC) aims at inferring unknown triples while considering its qualifiers. Most existing approaches to HKGC exploit a global-level graph structure to encode hyper-relational knowledge into the graph convolution message passing process. However, the addition of multi-hop information might bring noise into the triple prediction process. To address this problem, we propose HyperFormer, a model that considers local-level sequential information, which encodes the content of the entities, relations and qualifiers of a triple. More precisely, HyperFormer is composed of three different modules: an entity neighbor aggregator module allowing to integrate the information of the neighbors of an entity to capture different perspectives of it; a relation qualifier aggregator module to integrate hyper-relational knowledge into the corresponding relation to refine the representation of relational content; a convolution-based bidirectional interaction module based on a convolutional operation, capturing pairwise bidirectional interactions of entity-relation, entity-qualifier, and relation-qualifier. realize the depth perception of the content related to the current statement. Furthermore, we introduce a Mixture-of-Experts strategy into the feed-forward layers of HyperFormer to strengthen its representation capabilities while reducing the amount of model parameters and computation. Extensive experiments on three well-known datasets with four different conditions demonstrate HyperFormer's effectiveness. Datasets and code are available at https://github.com/zhiweihu1103/HKGC-HyperFormer.
</details>
<details>
<summary>摘要</summary>
超过标准知识 graphs (HKGs) 将 attribute-value 资讯 associates 到 triplets, 实际表示了对应 triplets 的详细信息。 hyper-relational 知识图完成 (HKGC) 目标是预测未知 triplets, 考虑其资讯。现有大多数 HKGC 方法利用全局级图结构编码 hyper-relational 知识到图 convolution 消息传递过程中。然而，添加多个跳跃信息可能会带来 triple 预测过程中的噪声。为解决这个问题，我们提出了 HyperFormer，一种模型，考虑本地级别的顺序信息，对 entitites、关系和资讯的内容进行编码。更加准确地说，HyperFormer 由三个不同模块组成：一个 entity neighbor aggregator 模块，用于将 entity 的 neighborgraph 信息集成，以 Capture 不同的 perspective of it; 一个 relation qualifier aggregator 模块，用于将 hyper-relational 知识 integrate 到对应关系中，以 Refine 关系内容的表示; 一个基于 convolution 操作的 bidirectional interaction module，用于 Capture entity-relation、entity-qualifier 和 relation-qualifier 对的 pairwise bidirectional interactions, 实现对当前声明的深度认知。此外，我们在 HyperFormer 的 feed-forward 层中引入 Mixture-of-Experts 策略，以增强其表示能力，同时减少模型参数和计算量。extensive experiments 表明 HyperFormer 有效。数据集和代码可以在 <https://github.com/zhiweihu1103/HKGC-HyperFormer> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Three-Ways-of-Using-Large-Language-Models-to-Evaluate-Chat"><a href="#Three-Ways-of-Using-Large-Language-Models-to-Evaluate-Chat" class="headerlink" title="Three Ways of Using Large Language Models to Evaluate Chat"></a>Three Ways of Using Large Language Models to Evaluate Chat</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06502">http://arxiv.org/abs/2308.06502</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oplatek/chateval-llm">https://github.com/oplatek/chateval-llm</a></li>
<li>paper_authors: Ondřej Plátek, Vojtěch Hudeček, Patricia Schmidtová, Mateusz Lango, Ondřej Dušek</li>
<li>for: 这个论文描述了由team6提交的ChatEval竞赛中的系统，包括三种基于大语言模型（LLMs）预测对话机器人回复质量的方法。</li>
<li>methods: 论文描述了三种方法，包括使用动态少量示例从矢量存储中提取提示，以及对其他两种方法的分析和未来工作的需求。</li>
<li>results: 论文报告了基于这三种方法的改进，包括使用动态少量示例从矢量存储中提取提示的改进。同时，论文还报告了其他两种方法的性能分析和未来工作的需求。<details>
<summary>Abstract</summary>
This paper describes the systems submitted by team6 for ChatEval, the DSTC 11 Track 4 competition. We present three different approaches to predicting turn-level qualities of chatbot responses based on large language models (LLMs). We report improvement over the baseline using dynamic few-shot examples from a vector store for the prompts for ChatGPT. We also analyze the performance of the other two approaches and report needed improvements for future work. We developed the three systems over just two weeks, showing the potential of LLMs for this task. An ablation study conducted after the challenge deadline shows that the new Llama 2 models are closing the performance gap between ChatGPT and open-source LLMs. However, we find that the Llama 2 models do not benefit from few-shot examples in the same way as ChatGPT.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了团队6在ChatEval DSTC 11 Track 4比赛中提交的三种不同方法来预测对话机器人响应质量。我们使用大型自然语言模型（LLM）来预测对话机器人响应的每个转折质量。我们发现使用动态少量示例从向量存储中提取的Prompt对ChatGPT的性能有所提升。我们还分析了其他两种方法的性能并报告了未来工作中所需的改进。我们在只有两周时间内开发了这三种系统，这表明LLMs在这个任务中的潜力。经过比赛结束后的抽象研究发现，新的Llama 2模型在关键性能方面追近ChatGPT和开源LLMs的性能。然而，我们发现Llama 2模型不如ChatGPT那样受益于少量示例。
</details></li>
</ul>
<hr>
<h2 id="Latent-Emission-Augmented-Perspective-Taking-LEAPT-for-Human-Robot-Interaction"><a href="#Latent-Emission-Augmented-Perspective-Taking-LEAPT-for-Human-Robot-Interaction" class="headerlink" title="Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction"></a>Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06498">http://arxiv.org/abs/2308.06498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaiqi Chen, Jing Yu Lim, Kingsley Kuan, Harold Soh</li>
<li>for: 本文是为了帮助机器人进行视角理解，即理解人类的视角和信念。</li>
<li>methods: 本文使用了深度世界模型，允许机器人进行视觉和概念上的视角理解，即能够推断人类看到和信任的内容。</li>
<li>results: 实验表明，本方法在三个半可见人机交互任务中表现出色，与现有的基准值进行比较，显著超越了基准值。<details>
<summary>Abstract</summary>
Perspective-taking is the ability to perceive or understand a situation or concept from another individual's point of view, and is crucial in daily human interactions. Enabling robots to perform perspective-taking remains an unsolved problem; existing approaches that use deterministic or handcrafted methods are unable to accurately account for uncertainty in partially-observable settings. This work proposes to address this limitation via a deep world model that enables a robot to perform both perception and conceptual perspective taking, i.e., the robot is able to infer what a human sees and believes. The key innovation is a decomposed multi-modal latent state space model able to generate and augment fictitious observations/emissions. Optimizing the ELBO that arises from this probabilistic graphical model enables the learning of uncertainty in latent space, which facilitates uncertainty estimation from high-dimensional observations. We tasked our model to predict human observations and beliefs on three partially-observable HRI tasks. Experiments show that our method significantly outperforms existing baselines and is able to infer visual observations available to other agent and their internal beliefs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="EgoPoser-Robust-Real-Time-Ego-Body-Pose-Estimation-in-Large-Scenes"><a href="#EgoPoser-Robust-Real-Time-Ego-Body-Pose-Estimation-in-Large-Scenes" class="headerlink" title="EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes"></a>EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06493">http://arxiv.org/abs/2308.06493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxi Jiang, Paul Streli, Manuel Meier, Christian Holz</li>
<li>for: 这篇论文旨在解决headset上的 egopose估计问题，即只使用头和手部位的位姿来估计全身姿态。</li>
<li>methods: 该论文提出了一种新的输入表示方法和一种新的运动分解方法，以估计全身姿态独立于全局位置。此外，它还能够对不同用户的体型进行robust模型。</li>
<li>results: 实验表明，该论文在质量和量化上都有较好的表现，而且可以保持高速推断速度（大于600帧&#x2F;秒）。这篇论文为将来的工作提供了一个可靠的基线，即全身姿态估计不再需要外部捕捉，并可以在大景观环境中扩展。<details>
<summary>Abstract</summary>
Full-body ego-pose estimation from head and hand poses alone has become an active area of research to power articulate avatar representation on headset-based platforms. However, existing methods over-rely on the confines of the motion-capture spaces in which datasets were recorded, while simultaneously assuming continuous capture of joint motions and uniform body dimensions. In this paper, we propose EgoPoser, which overcomes these limitations by 1) rethinking the input representation for headset-based ego-pose estimation and introducing a novel motion decomposition method that predicts full-body pose independent of global positions, 2) robustly modeling body pose from intermittent hand position and orientation tracking only when inside a headset's field of view, and 3) generalizing across various body sizes for different users. Our experiments show that EgoPoser outperforms state-of-the-art methods both qualitatively and quantitatively, while maintaining a high inference speed of over 600 fps. EgoPoser establishes a robust baseline for future work, where full-body pose estimation needs no longer rely on outside-in capture and can scale to large-scene environments.
</details>
<details>
<summary>摘要</summary>
全身ego姿 estimation从头和手姿alone已成为研究的活跃领域，以提供头盔平台上的人物表现。然而，现有方法受到数据采集空间的限制，同时假设持续采集 JOINT 动作和一致体 dimensions。在这篇论文中，我们提出了 EgoPoser，它缓解了这些限制，通过：1. 重新定义头盔基于的输入表示，并 introduce 一种新的运动分解方法，可以独立地预测全身姿。2. 可靠地模型体姿从头盔视野内部的间歇手姿和方向追踪。3. 对不同用户的体型进行一致化。我们的实验表明，EgoPoser 超过了现有方法的质量和量化表现，同时保持了高速度推断速度超过 600 fps。EgoPoser 建立了一个可靠的基线，将全身姿推断带到大景景环境中。
</details></li>
</ul>
<hr>
<h2 id="Generating-Faithful-Text-From-a-Knowledge-Graph-with-Noisy-Reference-Text"><a href="#Generating-Faithful-Text-From-a-Knowledge-Graph-with-Noisy-Reference-Text" class="headerlink" title="Generating Faithful Text From a Knowledge Graph with Noisy Reference Text"></a>Generating Faithful Text From a Knowledge Graph with Noisy Reference Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06488">http://arxiv.org/abs/2308.06488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tahsina Hashem, Weiqing Wang, Derry Tanti Wijaya, Mohammed Eunus Ali, Yuan-Fang Li</li>
<li>for: 这个论文的目的是提出一种基于知识图（KG）的自然语言生成模型，能够生成准确表示知识图信息的自然语言文本。</li>
<li>methods: 该模型使用了对抗学习和可控文本生成技术，以提高模型对 faithful 信息的识别和控制。</li>
<li>results: 论文的实验结果表明，该模型在 faithfulness 方面表现出色，超过了现有的状态艺文。<details>
<summary>Abstract</summary>
Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model's performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness.
</details>
<details>
<summary>摘要</summary>
知识图（KG）-to-文本生成目标是生成流畅自然语言文本，准确表达给定知识图中的信息。虽然现有模型通过利用适当的前训练语言模型（PLMs）和合适的图结构意识模块，已经取得了显著的进步，但现有模型仍然无法生成准确的文本，特别是当参考文本中含有不在知识图中的信息时。在这篇论文中，我们开发了一种KG-to-文本生成模型，可以从给定图生成准确的自然语言文本，并在参考文本中含有噪音时提供 faithful 的文本生成。我们的框架包括两个核心想法：首先，我们利用对比学习增强模型的能力，在文本中划分 faithful 和幻想信息，从而让解码器生成与输入图相关的文本。其次，我们赋予解码器控制幻想度的能力，通过使用可控文本生成技术。我们通过标准的量化度量以及基于 ChatGPT 的量化和质量分析进行评估。我们的评估结果表明，我们的模型在准确性方面与当前状态的 KG-to-文本模型相比，表现出优异的性能。
</details></li>
</ul>
<hr>
<h2 id="Not-So-Robust-After-All-Evaluating-the-Robustness-of-Deep-Neural-Networks-to-Unseen-Adversarial-Attacks"><a href="#Not-So-Robust-After-All-Evaluating-the-Robustness-of-Deep-Neural-Networks-to-Unseen-Adversarial-Attacks" class="headerlink" title="Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks"></a>Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06467">http://arxiv.org/abs/2308.06467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roman Garaev, Bader Rasheed, Adil Khan<br>for: This study aims to challenge the efficacy and generalization of contemporary defense mechanisms against adversarial attacks.methods: The study explores the hypothesis proposed by Ilyas et. al, which posits that DNN image features can be either robust or non-robust, with adversarial attacks targeting the latter. The study employs canonical correlation analysis, visualizes the representations, and calculates the mean distance between these representations and various DNN decision boundaries.results: The study finds a significant difference between $L_2$ and $L_{\infty}$ norms, which could provide insights into the potential dangers posed by $L_{\infty}$ norm attacks, previously underestimated by the research community.<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have gained prominence in various applications, such as classification, recognition, and prediction, prompting increased scrutiny of their properties. A fundamental attribute of traditional DNNs is their vulnerability to modifications in input data, which has resulted in the investigation of adversarial attacks. These attacks manipulate the data in order to mislead a DNN. This study aims to challenge the efficacy and generalization of contemporary defense mechanisms against adversarial attacks. Specifically, we explore the hypothesis proposed by Ilyas et. al, which posits that DNN image features can be either robust or non-robust, with adversarial attacks targeting the latter. This hypothesis suggests that training a DNN on a dataset consisting solely of robust features should produce a model resistant to adversarial attacks. However, our experiments demonstrate that this is not universally true. To gain further insights into our findings, we analyze the impact of adversarial attack norms on DNN representations, focusing on samples subjected to $L_2$ and $L_{\infty}$ norm attacks. Further, we employ canonical correlation analysis, visualize the representations, and calculate the mean distance between these representations and various DNN decision boundaries. Our results reveal a significant difference between $L_2$ and $L_{\infty}$ norms, which could provide insights into the potential dangers posed by $L_{\infty}$ norm attacks, previously underestimated by the research community.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-Label-Knowledge-Distillation"><a href="#Multi-Label-Knowledge-Distillation" class="headerlink" title="Multi-Label Knowledge Distillation"></a>Multi-Label Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06453">http://arxiv.org/abs/2308.06453</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/penghui-yang/l2d">https://github.com/penghui-yang/l2d</a></li>
<li>paper_authors: Penghui Yang, Ming-Kun Xie, Chen-Chen Zong, Lei Feng, Gang Niu, Masashi Sugiyama, Sheng-Jun Huang</li>
<li>for: 这篇论文主要针对多标签学习问题，旨在提出一种基于知识储存技术的多标签知识传递方法。</li>
<li>methods: 该方法首先将多标签学习问题分解成多个二分类问题，然后通过分别对每个二分类问题进行知识储存来增强学习的特征表示。同时，该方法还利用标签嵌入结构来提高特征表示的独特性。</li>
<li>results: 实验结果表明，提出的方法可以减少标签之间的知识冲突，并且在多个 benchmark 数据集上达到了较高的性能水平，比较于其他比较方法。<details>
<summary>Abstract</summary>
Existing knowledge distillation methods typically work by imparting the knowledge of output logits or intermediate feature maps from the teacher network to the student network, which is very successful in multi-class single-label learning. However, these methods can hardly be extended to the multi-label learning scenario, where each instance is associated with multiple semantic labels, because the prediction probabilities do not sum to one and feature maps of the whole example may ignore minor classes in such a scenario. In this paper, we propose a novel multi-label knowledge distillation method. On one hand, it exploits the informative semantic knowledge from the logits by dividing the multi-label learning problem into a set of binary classification problems; on the other hand, it enhances the distinctiveness of the learned feature representations by leveraging the structural information of label-wise embeddings. Experimental results on multiple benchmark datasets validate that the proposed method can avoid knowledge counteraction among labels, thus achieving superior performance against diverse comparing methods. Our code is available at: https://github.com/penghui-yang/L2D
</details>
<details>
<summary>摘要</summary>
现有的知识传授方法通常是将教师网络的输出几何或中间特征图形知识传授到学生网络，这很成功在多类单 Label 学习中。但这些方法几乎无法扩展到多Label学习情况下，因为预测概率不会加总到一，且特征图形全例可能忽略次要类别。在本文中，我们提出了一个新的多Label知识传授方法。一方面，它利用多Label学习问题中的 semantic 知识，将问题分成多个二分类问题；另一方面，它利用类别对称信息来强化学习的特征表现。实验结果显示，提案的方法可以避免知识抵触 Label 之间，因此在多个比较方法面上获得了更好的性能。我们的代码可以在：https://github.com/penghui-yang/L2D 中找到。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Equivariant-Mixup"><a href="#Semantic-Equivariant-Mixup" class="headerlink" title="Semantic Equivariant Mixup"></a>Semantic Equivariant Mixup</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06451">http://arxiv.org/abs/2308.06451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zongbo Han, Tianchi Xie, Bingzhe Wu, Qinghua Hu, Changqing Zhang</li>
<li>for: 提高模型对分布Shift的 Robustness，通过在表示空间强制保持输入数据的结构不变。</li>
<li>methods: 基于semantic-equivariance assumption的generic mixup regularization，使得模型在混合样本中学习更多的semantic information。</li>
<li>results: 经过extensive empirical studies和qualitative analyzes，表明提出的方法可以提高模型的Robustness和Generalization能力。<details>
<summary>Abstract</summary>
Mixup is a well-established data augmentation technique, which can extend the training distribution and regularize the neural networks by creating ''mixed'' samples based on the label-equivariance assumption, i.e., a proportional mixup of the input data results in the corresponding labels being mixed in the same proportion. However, previous mixup variants may fail to exploit the label-independent information in mixed samples during training, which usually contains richer semantic information. To further release the power of mixup, we first improve the previous label-equivariance assumption by the semantic-equivariance assumption, which states that the proportional mixup of the input data should lead to the corresponding representation being mixed in the same proportion. Then a generic mixup regularization at the representation level is proposed, which can further regularize the model with the semantic information in mixed samples. At a high level, the proposed semantic equivariant mixup (sem) encourages the structure of the input data to be preserved in the representation space, i.e., the change of input will result in the obtained representation information changing in the same way. Different from previous mixup variants, which tend to over-focus on the label-related information, the proposed method aims to preserve richer semantic information in the input with semantic-equivariance assumption, thereby improving the robustness of the model against distribution shifts. We conduct extensive empirical studies and qualitative analyzes to demonstrate the effectiveness of our proposed method. The code of the manuscript is in the supplement.
</details>
<details>
<summary>摘要</summary>
混合是一种已有的数据增强技术，可以使得训练分布延伸并规范神经网络，通过创建基于标签相似性假设的混合样本。然而，先前的混合变体可能会忽略混合样本中的标签独立信息，这些信息通常含有更加丰富的 semantics。为了更好地发挥混合的力量，我们首先提高了先前的标签相似性假设，使其转化为 semantics相似性假设，即混合输入数据时，应该对应的表示也在同样的比例进行混合。然后，我们提出了一种通用的混合规范，可以在表示层进行规范，以更加规范模型。总的来说，我们的 semantic equivariant mixup（sem）方法要求输入数据的结构在表示空间保持不变，即输入变化后，获得的表示信息也会在同样的比例进行变化。与先前的混合变体不同，我们的方法更关注于保持输入中更加丰富的 semantics信息，从而提高模型对分布偏移的Robustness。我们进行了广泛的实验和质量分析，以证明我们的提议的效iveness。代码在附录中。
</details></li>
</ul>
<hr>
<h2 id="A-Sequential-Meta-Transfer-SMT-Learning-to-Combat-Complexities-of-Physics-Informed-Neural-Networks-Application-to-Composites-Autoclave-Processing"><a href="#A-Sequential-Meta-Transfer-SMT-Learning-to-Combat-Complexities-of-Physics-Informed-Neural-Networks-Application-to-Composites-Autoclave-Processing" class="headerlink" title="A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing"></a>A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06447">http://arxiv.org/abs/2308.06447</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miladramzy/sequentialmetatransferpinns">https://github.com/miladramzy/sequentialmetatransferpinns</a></li>
<li>paper_authors: Milad Ramezankhani, Abbas S. Milani</li>
<li>for: 解决非线性偏微分方程（PDE）问题，提高物理学法的泛化能力。</li>
<li>methods: 使用sequential meta-transfer（SMT）学习框架，将时间域分解成小时段，每个时间段使用meta-学习器进行快速适应。</li>
<li>results: 在一个复杂系统中，通过使用SMT学习框架，可以明显提高PINNs的适应能力，同时减少计算成本，提高效率。<details>
<summary>Abstract</summary>
Physics-Informed Neural Networks (PINNs) have gained popularity in solving nonlinear partial differential equations (PDEs) via integrating physical laws into the training of neural networks, making them superior in many scientific and engineering applications. However, conventional PINNs still fall short in accurately approximating the solution of complex systems with strong nonlinearity, especially in long temporal domains. Besides, since PINNs are designed to approximate a specific realization of a given PDE system, they lack the necessary generalizability to efficiently adapt to new system configurations. This entails computationally expensive re-training from scratch for any new change in the system. To address these shortfalls, in this work a novel sequential meta-transfer (SMT) learning framework is proposed, offering a unified solution for both fast training and efficient adaptation of PINNs in highly nonlinear systems with long temporal domains. Specifically, the framework decomposes PDE's time domain into smaller time segments to create "easier" PDE problems for PINNs training. Then for each time interval, a meta-learner is assigned and trained to achieve an optimal initial state for rapid adaptation to a range of related tasks. Transfer learning principles are then leveraged across time intervals to further reduce the computational cost.Through a composites autoclave processing case study, it is shown that SMT is clearly able to enhance the adaptability of PINNs while significantly reducing computational cost, by a factor of 100.
</details>
<details>
<summary>摘要</summary>
物理学教导神经网络（PINNs）在解决非线性偏微分方程（PDEs）中得到了广泛应用，通过将物理法则 integrate到神经网络训练中，使其在科学和工程应用中优于传统方法。然而，传统的PINNs在处理复杂系统中仍然缺乏精度，特别是在长时间域内。此外，由于PINNs是为某种特定的PDE系统进行适应，因此缺乏可重用的扩展性，需要在新系统配置时重新从零开始训练，这会增加计算成本。为了解决这些缺陷，本文提出了一种新的时序顺序多模式学习（SMT）框架，用于快速训练和高效适应PINNs在非线性系统中。特别是，该框架将时间域 decomposes 为 smaller time segments，以创建"更容易"的PDE问题，以便PINNs的快速训练。然后，每个时间段中分配了一个meta-学习器，并在快速适应一系列相关任务的基础上进行了优化。然后，通过转移学习原理，在时间间隔内进行了进一步的计算成本减少。通过一个复杂材料自动炉处理案例研究，显示SMT可以明显提高PINNs的适应性，同时显著减少计算成本，比例为100。
</details></li>
</ul>
<hr>
<h2 id="Sensitivity-Aware-Mixed-Precision-Quantization-and-Width-Optimization-of-Deep-Neural-Networks-Through-Cluster-Based-Tree-Structured-Parzen-Estimation"><a href="#Sensitivity-Aware-Mixed-Precision-Quantization-and-Width-Optimization-of-Deep-Neural-Networks-Through-Cluster-Based-Tree-Structured-Parzen-Estimation" class="headerlink" title="Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation"></a>Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06422">http://arxiv.org/abs/2308.06422</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyedarmin Azizi, Mahdi Nazemi, Arash Fayyazi, Massoud Pedram</li>
<li>for: 这篇论文的目的是提出一种自动选择神经网络层的最佳位元数和层宽的搜寻方法，以提高深度学习模型的效率。</li>
<li>methods: 这篇论文使用的方法包括对神经网络层的位元数和层宽进行自动选择，并使用希瑟尔基于删除的搜寻范围缩小技术，以便快速寻找最佳设计。它还使用树结构的Parzen估计器来建立代表性模型，以便快速探索不同的架构可能性。</li>
<li>results: 这篇论文的结果显示，与现有的压缩策略相比，这种方法可以实现20%的模型大小减少，不会对准确性产生影响。另外，这种方法的搜寻时间仅需12倍于目前最佳搜寻策略，使得快速设计和实现深度学习解决方案成为可能。<details>
<summary>Abstract</summary>
As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 20% decrease in model size without compromising accuracy. Additionally, our method boasts a 12x reduction in search time relative to the best search-focused strategies currently available. As a result, our proposed method represents a leap forward in neural network design optimization, paving the way for quick model design and implementation in settings with limited resources, thereby propelling the potential of scalable deep learning solutions.
</details>
<details>
<summary>摘要</summary>
“深度学习模型的复杂性和计算需求逐渐增加，因此有效地优化神经网络设计的搜索方法变得非常重要。这项工作提出了一种新的搜索机制，可以自动选择神经网络层的最佳位数和宽度。这会导致深度神经网络的效率得到明显提高。在搜索空间中，我们利用希腊拟合法（Hessian-based pruning）缩小搜索范围，以便快速消除不重要的参数。然后，我们采用分布式树结构的Parzen估计器来构建代表性模型，以便快速探索不同的建筑方案。这种策略可以快速寻找最佳设计，并且可以保证模型的准确性不受影响。我们对知名的数据集进行了严格的测试，并证明了我们的方法与现有方法相比，可以录入20%的模型大小减少，同时保持准确性不变。此外，我们的方法可以在搜索时间方面实现12倍的提升，相比于目前最佳的搜索焦点策略。因此，我们的提议方法代表了神经网络设计优化领域的一大突破，为具有限制资源的场景中快速实现神经网络设计，铺平深度学习解决方案的可能性。”
</details></li>
</ul>
<hr>
<h2 id="Pedestrian-Trajectory-Prediction-in-Pedestrian-Vehicle-Mixed-Environments-A-Systematic-Review"><a href="#Pedestrian-Trajectory-Prediction-in-Pedestrian-Vehicle-Mixed-Environments-A-Systematic-Review" class="headerlink" title="Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review"></a>Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06419">http://arxiv.org/abs/2308.06419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad</li>
<li>for: The paper is written for the development of practical pedestrian trajectory prediction algorithms for autonomous vehicles (AVs) in unstructured environments.</li>
<li>methods: The paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in the presence of vehicles, and investigates specific considerations for pedestrian-vehicle interaction.</li>
<li>results: The paper provides an overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers, and discusses research gaps and directions for future work, such as the need for more effective definition of interacting agents in deep learning methods and the need for more datasets of mixed traffic in unstructured environments.Here are the three points in Simplified Chinese text:</li>
<li>for: 本文是为了开发可行的步行者轨迹预测算法，用于自动驾驶车辆（AV）在无结构环境中。</li>
<li>methods: 本文系统地查询了Literature中的不同方法，用于模拟步行者轨迹预测在车辆存在下。</li>
<li>results: 本文提供了各种数据集，包括步行者和车辆的轨迹数据，并讨论了未来研究的潜在空间，如深度学习方法中的交互代理定义和无结构环境中混合交通数据的收集。<details>
<summary>Abstract</summary>
Planning an autonomous vehicle's (AV) path in a space shared with pedestrians requires reasoning about pedestrians' future trajectories. A practical pedestrian trajectory prediction algorithm for the use of AVs needs to consider the effect of the vehicle's interactions with the pedestrians on pedestrians' future motion behaviours. In this regard, this paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in presence of vehicles that can be applied for unstructured environments. This paper also investigates specific considerations for pedestrian-vehicle interaction (compared with pedestrian-pedestrian interaction) and reviews how different variables such as prediction uncertainties and behavioural differences are accounted for in the previously proposed prediction models. PRISMA guidelines were followed. Articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. A total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. An overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. Research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments are discussed.
</details>
<details>
<summary>摘要</summary>
планирование пути автономного транспортного средства (АВ) в пространстве, разделенном с пешеходами, требует расчета будущих траекторий пешеходов. практический алгоритм предсказания траекторий пешеходов для использования АВ должен учитывать влияние взаимодействия автомобиля с пешеходами на будущие движения людей. в этом смысле, этот папяр систематически обзорывает разные методы, предложенные в литературе для моделирования предсказания траекторий пешеходов в присутствии автомобилей, которые могут быть применены в неструктурированных средах. папяр также рассматривает специфические условия для взаимодействия пешеходов и автомобилей (в сравнении с взаимодействием пешеходов-пешеходов) и обзоры, как различные переменные, такие как неопределенности предсказаний и различия в поведении, учитываются в предыдущих предсказательных моделях. following PRISMA guidelines, articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. a total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. an overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments, are discussed.
</details></li>
</ul>
<hr>
<h2 id="Dialogue-Possibilities-between-a-Human-Supervisor-and-UAM-Air-Traffic-Management-Route-Alteration"><a href="#Dialogue-Possibilities-between-a-Human-Supervisor-and-UAM-Air-Traffic-Management-Route-Alteration" class="headerlink" title="Dialogue Possibilities between a Human Supervisor and UAM Air Traffic Management: Route Alteration"></a>Dialogue Possibilities between a Human Supervisor and UAM Air Traffic Management: Route Alteration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06411">http://arxiv.org/abs/2308.06411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeongseok Kim, Kangjin Kim</li>
<li>for: 本研究旨在提出一种基于知识表示和逻辑的城市航空交通管理（UATM）拓扑管理方法，以便快速Identify safe和高效的 Routes in a carefully sampled environment.</li>
<li>methods: 本方法使用Answer Set Programming（ASP）实现，其中包括非 monotonic reasoning和两个阶段对话，考虑安全和可能的影响因素。</li>
<li>results: 经过多个查询从两个 simulations scenarios， validate了提出的方法的可靠性和有效性。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
This paper introduces a novel approach to detour management in Urban Air Traffic Management (UATM) using knowledge representation and reasoning. It aims to understand the complexities and requirements of UAM detours, enabling a method that quickly identifies safe and efficient routes in a carefully sampled environment. This method implemented in Answer Set Programming uses non-monotonic reasoning and a two-phase conversation between a human manager and the UATM system, considering factors like safety and potential impacts. The robustness and efficacy of the proposed method were validated through several queries from two simulation scenarios, contributing to the symbiosis of human knowledge and advanced AI techniques. The paper provides an introduction, citing relevant studies, problem formulation, solution, discussions, and concluding comments.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的偏航管理方法（Detour Management），用于城市空中交通管理（UATM），利用知识表示和推理。它旨在理解城市垂直飞行偏航的复杂性和需求，以便快速地确定安全和高效的路径，并在精心采样的环境中进行。这种方法使用了非 monotonic 推理和两个阶段的人工管理和UATM系统之间的对话，考虑了安全和可能的影响因素。该方法的可靠性和有效性通过多个查询来 validate，来自两个 simulate enario。这篇论文提供了引言、相关研究、问题表述、解决方案、讨论和结论。
</details></li>
</ul>
<hr>
<h2 id="A-Brain-Computer-Interface-Augmented-Reality-Framework-with-Auto-Adaptive-SSVEP-Recognition"><a href="#A-Brain-Computer-Interface-Augmented-Reality-Framework-with-Auto-Adaptive-SSVEP-Recognition" class="headerlink" title="A Brain-Computer Interface Augmented Reality Framework with Auto-Adaptive SSVEP Recognition"></a>A Brain-Computer Interface Augmented Reality Framework with Auto-Adaptive SSVEP Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06401">http://arxiv.org/abs/2308.06401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasmine Mustafa, Mohamed Elmahallawy, Tie Luo, Seif Eldawlatly</li>
<li>for: 该研究旨在开发一种可以满足不同个体的脑电信号特点的简单适应集合分类系统，以便在脑机接口（BCI）和增强现实（AR）技术的应用中提高抗骚抗振性能。</li>
<li>methods: 该研究使用了稳态视觉谱波（SSVEP）信号 Pattern，并提出了一种简单的BCI-AR框架，以支持广泛的SSVEP-based BCI-AR应用程序的开发。</li>
<li>results: 测试结果显示，我们的ensemble分类方法在SSVEP-based BCI-AR应用程序中表现出了Robust性，并且与之前的研究相比，我们的方法在包括头部运动的情况下仍然能够达到80%的正确率（在PC上）和77%的正确率（使用HoloLens AR头盔）。此外，我们的视觉刺激时间为5秒，相对较短。<details>
<summary>Abstract</summary>
Brain-Computer Interface (BCI) initially gained attention for developing applications that aid physically impaired individuals. Recently, the idea of integrating BCI with Augmented Reality (AR) emerged, which uses BCI not only to enhance the quality of life for individuals with disabilities but also to develop mainstream applications for healthy users. One commonly used BCI signal pattern is the Steady-state Visually-evoked Potential (SSVEP), which captures the brain's response to flickering visual stimuli. SSVEP-based BCI-AR applications enable users to express their needs/wants by simply looking at corresponding command options. However, individuals are different in brain signals and thus require per-subject SSVEP recognition. Moreover, muscle movements and eye blinks interfere with brain signals, and thus subjects are required to remain still during BCI experiments, which limits AR engagement. In this paper, we (1) propose a simple adaptive ensemble classification system that handles the inter-subject variability, (2) present a simple BCI-AR framework that supports the development of a wide range of SSVEP-based BCI-AR applications, and (3) evaluate the performance of our ensemble algorithm in an SSVEP-based BCI-AR application with head rotations which has demonstrated robustness to the movement interference. Our testing on multiple subjects achieved a mean accuracy of 80\% on a PC and 77\% using the HoloLens AR headset, both of which surpass previous studies that incorporate individual classifiers and head movements. In addition, our visual stimulation time is 5 seconds which is relatively short. The statistically significant results show that our ensemble classification approach outperforms individual classifiers in SSVEP-based BCIs.
</details>
<details>
<summary>摘要</summary>
Initially, Brain-Computer Interface (BCI) 引起关注的应用是为Physically impaired individuals 提高生活质量。然而， BCIs 的潜在应用不仅限于这些人群，还可以为健康用户开发主流应用程序。 BCIs 使用 Steady-state Visually-evoked Potential (SSVEP) 信号模式， capture 脑的响应，并使用 BCIs 来表达需求或愿望。然而，每个人的脑信号不同，因此需要每个人SSVEP 认知。此外，肌肉运动和眼睛跳动会干扰脑信号，因此需要用户在BCI实验中保持静止，限制了AR的应用。在这篇论文中，我们提出了一种简单的适应集成分类系统，可以处理每个人的差异。我们还提出了一种支持广泛SSVEP 基于 BCIs 应用程序的简单AR框架。我们的结果表明，我们的集成分类方法在SSVEP 基于 BCIs 的AR应用程序中，可以快速响应用户的需求或愿望，并且在多个测试人群中表现出 statistically significant 的表现。我们的测试结果显示，我们的集成分类方法在PC 和 HoloLens AR 头盔中都可以达到80%和77%的准确率，这 beiden超过了以个体分类器和头部运动混合的前一 Studies。此外，我们的视觉刺激时间为5秒，相对较短。总之，我们的研究表明，集成分类方法在SSVEP 基于 BCIs 的AR应用程序中表现出了优于个体分类器的表现。这 suggets that our ensemble classification approach can be a promising solution for developing mainstream BCI-AR applications.
</details></li>
</ul>
<hr>
<h2 id="ZYN-Zero-Shot-Reward-Models-with-Yes-No-Questions"><a href="#ZYN-Zero-Shot-Reward-Models-with-Yes-No-Questions" class="headerlink" title="ZYN: Zero-Shot Reward Models with Yes-No Questions"></a>ZYN: Zero-Shot Reward Models with Yes-No Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06385">http://arxiv.org/abs/2308.06385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vicgalle/zero-shot-reward-models">https://github.com/vicgalle/zero-shot-reward-models</a></li>
<li>paper_authors: Victor Gallego</li>
<li>for: 本文提出了一种解决方案，用于指导语言模型生成文本，以便与人类操作员的偏好相align。</li>
<li>methods: 该方法使用另一个语言模型作为批评者和奖励模型，通过一个Yes-No问题的提问来表达用户偏好，无需进一步的标注数据。</li>
<li>results: 在不同的文本生成领域中，包括毒瘤化、修正电影评论的情感、控制模型对某个话题的看法，以及个性化文本生成器的推荐等方面，实验证明了提议的ZYN框架的可能性。<details>
<summary>Abstract</summary>
In this work, we address the problem of directing the text generations of a LLM towards a desired behavior, aligning the generated text with the preferences of the human operator. We propose using another language model as a critic, reward model in a zero-shot way thanks to the prompt of a Yes-No question that represents the user preferences, without requiring further labeled data. This zero-shot reward model provides the learning signal to further fine-tune the base LLM using reinforcement learning, as in RLAIF; yet our approach is also compatible in other contexts such as quality-diversity search. Extensive evidence of the capabilities of the proposed ZYN framework is provided through experiments in different domains related to text generation, including detoxification; optimizing sentiment of movie reviews, or any other attribute; steering the opinion about a particular topic the model may have; and personalizing prompt generators for text-to-image tasks. Code to be released at \url{https://github.com/vicgalle/zero-shot-reward-models/}.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们解决了直接将语言生成模型（LLM）引导到所需行为的问题，将生成的文本与人类运行员的偏好相align。我们提议使用另一个语言模型作为批评者、奖励模型，通过Zero-shot manner，只需通过问题提示（Yes-No问题）表示用户偏好，无需更多的标注数据。这种Zero-shot奖励模型为基础LLM进行了进一步微调，使用束缚学习，类似RLAIF;而我们的方法也可以在其他上下文中使用，如质量多样性搜索。我们通过不同领域的文本生成实验提供了广泛的证据，包括毒瘤化、修改电影评论的情感、控制模型对某个话题的看法，以及个性化提示生成器 для文本到图像任务。代码将在 \url{https://github.com/vicgalle/zero-shot-reward-models/} 上发布。
</details></li>
</ul>
<hr>
<h2 id="DCNFIS-Deep-Convolutional-Neuro-Fuzzy-Inference-System"><a href="#DCNFIS-Deep-Convolutional-Neuro-Fuzzy-Inference-System" class="headerlink" title="DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System"></a>DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06378">http://arxiv.org/abs/2308.06378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mojtaba Yeganejou, Kimia Honari, Ryan Kluzinski, Scott Dick, Michael Lipsett, James Miller</li>
<li>for: 该研究旨在提出一种新的深度学习模型，以提高模型的透明度而不增加准确性的损失。</li>
<li>methods: 该研究使用了深度 convolutional neuro-fuzzy inference system (DCNFIS)，即将深度学习模型和逻辑学习模型相结合，以提高模型的透明度。</li>
<li>results: 研究发现，DCNFIS可以与现有的三种 convolutional neural networks 相比，在四个公共数据集上表现相当准确。此外，DCNFIS还可以超过当前的深度逻辑系统的性能。此外，通过解释来源于逻辑规则的质量分析，该研究还发现了一些有用的特性。<details>
<summary>Abstract</summary>
A key challenge in eXplainable Artificial Intelligence is the well-known tradeoff between the transparency of an algorithm (i.e., how easily a human can directly understand the algorithm, as opposed to receiving a post-hoc explanation), and its accuracy. We report on the design of a new deep network that achieves improved transparency without sacrificing accuracy. We design a deep convolutional neuro-fuzzy inference system (DCNFIS) by hybridizing fuzzy logic and deep learning models and show that DCNFIS performs as accurately as three existing convolutional neural networks on four well-known datasets. We furthermore that DCNFIS outperforms state-of-the-art deep fuzzy systems. We then exploit the transparency of fuzzy logic by deriving explanations, in the form of saliency maps, from the fuzzy rules encoded in DCNFIS. We investigate the properties of these explanations in greater depth using the Fashion-MNIST dataset.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在可解释人工智能是论文质量和直观性之间的交换。我们报告了一种新的深度网络的设计，该网络可以提高直观性而无需牺牲准确性。我们将深度 convolutional neuro-fuzzy inference system (DCNFIS) 设计为混合深度学习和规则逻辑模型，并证明 DCNFIS 在四个常见数据集上表现和三种现有的 convolutional neural networks 相同。此外，我们还证明 DCNFIS 在深度逻辑系统中表现更出色。然后，我们利用规则逻辑的透明性，从 DCNFIS 中提取出解释，以幻灯片的形式表示。我们在 Fashion-MNIST 数据集中进一步调查了这些解释的性质。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-and-Knowledge-Graphs-Opportunities-and-Challenges"><a href="#Large-Language-Models-and-Knowledge-Graphs-Opportunities-and-Challenges" class="headerlink" title="Large Language Models and Knowledge Graphs: Opportunities and Challenges"></a>Large Language Models and Knowledge Graphs: Opportunities and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06374">http://arxiv.org/abs/2308.06374</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Jeff Z. Pan, Simon Razniewski, Jan-Christoph Kalo, Sneha Singhania, Jiaoyan Chen, Stefan Dietze, Hajira Jabeen, Janna Omeliyanenko, Wen Zhang, Matteo Lissandrini, Russa Biswas, Gerard de Melo, Angela Bonifati, Edlira Vakaj, Mauro Dragoni, Damien Graux</li>
<li>for: 本研究论文探讨了大语言模型（LLM）在知识表示方面的发展，以及这些模型对知识图和 parametric knowledge 的影响。</li>
<li>methods: 本文使用了许多现有的知识表示方法，如知识图和Parametric knowledge，以及一些新的研究方法。</li>
<li>results: 本文总结了一些关于 LLMs 和知识图的共识和观点，并提出了一些可能的研究方向和挑战。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have taken Knowledge Representation -- and the world -- by storm. This inflection point marks a shift from explicit knowledge representation to a renewed focus on the hybrid representation of both explicit knowledge and parametric knowledge. In this position paper, we will discuss some of the common debate points within the community on LLMs (parametric knowledge) and Knowledge Graphs (explicit knowledge) and speculate on opportunities and visions that the renewed focus brings, as well as related research topics and challenges.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Wireless-Federated-k-Means-Clustering-with-Non-coherent-Over-the-Air-Computation"><a href="#Wireless-Federated-k-Means-Clustering-with-Non-coherent-Over-the-Air-Computation" class="headerlink" title="Wireless Federated $k$-Means Clustering with Non-coherent Over-the-Air Computation"></a>Wireless Federated $k$-Means Clustering with Non-coherent Over-the-Air Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06371">http://arxiv.org/abs/2308.06371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alphan Sahin</li>
<li>for: 降低无线网络上实现 Federated k-means 算法时的每次通信延迟</li>
<li>methods: 使用 Over-the-air computation（OAC）方案，通过编码器利用数字征在均匀数系统中的表示，通过无线多访问通道的信号积加性性质消除精确时钟和频率同步需求</li>
<li>results: 对客户位置 clustering 场景进行 demonstration，比较标准 k-means  clustering 和提议方法的性能，结果显示提议方法与标准 k-means 性能相似，同时降低了通信延迟<details>
<summary>Abstract</summary>
In this study, we propose using an over-the-air computation (OAC) scheme for the federated k-means clustering algorithm to reduce the per-round communication latency when it is implemented over a wireless network. The OAC scheme relies on an encoder exploiting the representation of a number in a balanced number system and computes the sum of the updates for the federated k-means via signal superposition property of wireless multiple-access channels non-coherently to eliminate the need for precise phase and time synchronization. Also, a reinitialization method for ineffectively used centroids is proposed to improve the performance of the proposed method for heterogeneous data distribution. For a customer-location clustering scenario, we demonstrate the performance of the proposed algorithm and compare it with the standard k-means clustering. Our results show that the proposed approach performs similarly to the standard k-means while reducing communication latency.
</details>
<details>
<summary>摘要</summary>
在这种研究中，我们提议使用无线电 computation（OAC）方案来降低在无线网络上实现 federated k-means 算法时的每轮通信延迟。 OAC 方案利用一个编码器利用数字 representation 在平衡数系统中的特性，通过无线多接入通道的信号重叠性性质来消除精确的时钟和相位同步需求。此外，我们还提出了一种重新初始化不合适使用的中心点方法，以提高提案方法在不同数据分布情况下的性能。为一个客户位置 clustering 场景，我们展示了提案的算法性能和标准 k-means 集群算法的比较，我们的结果表明，提案的方法与标准 k-means 集群算法性能相似，同时降低了通信延迟。
</details></li>
</ul>
<hr>
<h2 id="Topic-Level-Bayesian-Surprise-and-Serendipity-for-Recommender-Systems"><a href="#Topic-Level-Bayesian-Surprise-and-Serendipity-for-Recommender-Systems" class="headerlink" title="Topic-Level Bayesian Surprise and Serendipity for Recommender Systems"></a>Topic-Level Bayesian Surprise and Serendipity for Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06368">http://arxiv.org/abs/2308.06368</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ton-moy/surprise-and-serendipity">https://github.com/ton-moy/surprise-and-serendipity</a></li>
<li>paper_authors: Tonmoy Hasan, Razvan Bunescu</li>
<li>for: 提高推荐系统的多样性，使用高度可能性的推荐项，让用户体验到新、未看过的类别。</li>
<li>methods: 使用 bayesian 惊喜来衡量item的意外性，并结合协同推荐算法来找到相似用户。</li>
<li>results: 实验结果表明，使用 bayesian 惊喜与距离基于的优化方法相比，对于时间和主题层次的意外性的评估更加准确，并且在推荐高度可能性的项目方面获得更好的性能。<details>
<summary>Abstract</summary>
A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 books read by 4 users in terms of their time-dependent, topic-level surprise. Experimental evaluations show that models that use Bayesian surprise correlate much better with the manual annotations of topic-level surprise than distance-based heuristics, and also obtain better serendipitous item recommendation performance.
</details>
<details>
<summary>摘要</summary>
一个推荐系统仅将推荐项目调整为用户的预先消耗项目历史，可能会创建一个范例弹性泡箱，让用户无法体验到未看过的类别。为了解决这个问题，可以推荐有高可能性的意外项目，即吸引用户高度评价的项目。在这篇论文中，我们提出了基于bayesian surprise的内容基于的serendipity表现，并使用它来衡量项目被用户过后评价后的surprise程度。当与相似用户的协同组件一起使用时，这将允许推荐高可能性的意外项目。为了评估主题层模型的惊喜和意外性表现，我们引入了Goodreads上的阅读历史数据集，包括26,000名用户和1,300,000本书，其中我们 manually annotate 449本被4名用户阅读的书籍，以时间依赖的主题层惊喜作为标准。实验评估显示，使用bayesian surprise的模型与距离基于的规律来的模型相比，具有更高的惊喜和意外性表现，并且在serendipity项目推荐上也有更好的表现。
</details></li>
</ul>
<hr>
<h2 id="Causally-Linking-Health-Application-Data-and-Personal-Information-Management-Tools"><a href="#Causally-Linking-Health-Application-Data-and-Personal-Information-Management-Tools" class="headerlink" title="Causally Linking Health Application Data and Personal Information Management Tools"></a>Causally Linking Health Application Data and Personal Information Management Tools</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08556">http://arxiv.org/abs/2308.08556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saturnino Luz, Masood Masoodian</li>
<li>for: 本研究旨在开发一种整合多种数据源、分析和可见化工具，以帮助用户更好地理解健康变量之间的 causal 连接。</li>
<li>methods: 本研究使用了数据挖掘、时间序列分析和可见化技术，并将这些技术与各种健康应用程序集成。</li>
<li>results: 研究人员通过提供用户可见化时间序列数据，使用者可以更好地理解健康变量之间的关系，从而帮助用户更好地管理健康。<details>
<summary>Abstract</summary>
The proliferation of consumer health devices such as smart watches, sleep monitors, smart scales, etc, in many countries, has not only led to growing interest in health monitoring, but also to the development of a countless number of ``smart'' applications to support the exploration of such data by members of the general public, sometimes with integration into professional health services. While a variety of health data streams has been made available by such devices to users, these streams are often presented as separate time-series visualizations, in which the potential relationships between health variables are not explicitly made visible. Furthermore, despite the fact that other aspects of life, such as work and social connectivity, have become increasingly digitised, health and well-being applications make little use of the potentially useful contextual information provided by widely used personal information management tools, such as shared calendar and email systems. This paper presents a framework for the integration of these diverse data sources, analytic and visualization tools, with inference methods and graphical user interfaces to help users by highlighting causal connections among such time-series.
</details>
<details>
<summary>摘要</summary>
“随着各国消费者医疗设备的普及，如智能手表、睡眠监测仪、智能秤 scales 等，人们对健康监测的兴趣不 только增加，而且促使了大量的``智能''应用程序的开发，以支持公众成员对健康数据的探索，并有时与专业医疗服务集成。而这些医疗设备提供的健康数据流量，经常以分开的时间序列视图方式显示出来，无法直观地显示健康变量之间的可能关系。此外，尽管其他方面的生活，如工作和社交连接，已经 Digitized，健康和福祉应用却几乎不使用广泛使用的个人信息管理工具，如共享日历和邮件系统，具有可营利的上下文信息。本文提出了将这些多种数据源、分析和视图工具、推理方法和图形用户界面集成起来，以帮助用户更好地探索健康数据的关系。”
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-to-Identify-Social-Determinants-of-Health-in-Electronic-Health-Records"><a href="#Large-Language-Models-to-Identify-Social-Determinants-of-Health-in-Electronic-Health-Records" class="headerlink" title="Large Language Models to Identify Social Determinants of Health in Electronic Health Records"></a>Large Language Models to Identify Social Determinants of Health in Electronic Health Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06354">http://arxiv.org/abs/2308.06354</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aim-harvard/sdoh">https://github.com/aim-harvard/sdoh</a></li>
<li>paper_authors: Marco Guevara, Shan Chen, Spencer Thomas, Tafadzwa L. Chaunzwa, Idalid Franco, Benjamin Kann, Shalini Moningi, Jack Qian, Madeleine Goldstein, Susan Harper, Hugo JWL Aerts, Guergana K. Savova, Raymond H. Mak, Danielle S. Bitterman</li>
<li>For: The paper aims to extract social determinants of health (SDoH) from electronic health records (EHRs) to improve patient outcomes.* Methods: The study uses large language models to extract SDoH from free text in EHRs, and experiments with synthetic data generation to improve the extraction of scarce SDoH data.* Results: The best-performing models were fine-tuned Flan-T5 XL and Flan-T5 XXL, which outperformed zero- and few-shot performance of ChatGPT-family models and showed less algorithmic bias. The models identified 93.8% of patients with adverse SDoH, while ICD-10 codes captured only 2.0%.Here’s the information in Simplified Chinese text:* 为：本研究用大语言模型提取电子医疗记录中社会determinants of health（SDoH），以提高患者结果。* 方法：研究使用自由文本中的SDoH，并对缺乏SDoH数据进行生成数据的尝试。* 结果：最佳表现的模型是精细调整后的Flan-T5 XL和Flan-T5 XXL，它们在比较shot setting下表现得更好，并且表现出较少的算法偏见。模型可以准确地提取93.8%的患者有不良SDoH，而ICD-10代码只能捕捉2.0%。<details>
<summary>Abstract</summary>
Social determinants of health (SDoH) have an important impact on patient outcomes but are incompletely collected from the electronic health records (EHR). This study researched the ability of large language models to extract SDoH from free text in EHRs, where they are most commonly documented, and explored the role of synthetic clinical text for improving the extraction of these scarcely documented, yet extremely valuable, clinical data. 800 patient notes were annotated for SDoH categories, and several transformer-based models were evaluated. The study also experimented with synthetic data generation and assessed for algorithmic bias. Our best-performing models were fine-tuned Flan-T5 XL (macro-F1 0.71) for any SDoH, and Flan-T5 XXL (macro-F1 0.70). The benefit of augmenting fine-tuning with synthetic data varied across model architecture and size, with smaller Flan-T5 models (base and large) showing the greatest improvements in performance (delta F1 +0.12 to +0.23). Model performance was similar on the in-hospital system dataset but worse on the MIMIC-III dataset. Our best-performing fine-tuned models outperformed zero- and few-shot performance of ChatGPT-family models for both tasks. These fine-tuned models were less likely than ChatGPT to change their prediction when race/ethnicity and gender descriptors were added to the text, suggesting less algorithmic bias (p<0.05). At the patient-level, our models identified 93.8% of patients with adverse SDoH, while ICD-10 codes captured 2.0%. Our method can effectively extracted SDoH information from clinic notes, performing better compare to GPT zero- and few-shot settings. These models could enhance real-world evidence on SDoH and aid in identifying patients needing social support.
</details>
<details>
<summary>摘要</summary>
社会 determinants of health (SDoH) 有重要的影响 på patient outcomes，但是它们从电子健康记录 (EHR) 中 incomplete 收集。这项研究检查了大型自然语言模型能否从自由文本中提取 SDoH，其中最常见的位置是 EHR 中。研究还检查了使用生成的Synthetic clinical text 来提高提取这些罕见 yet extremely valuable 的临床数据的能力。研究采用了800份病人笔记，并评估了多种 transformer-based 模型。研究还进行了生成数据的评估和算法偏见的检查。我们的最佳表现模型是 Fine-tuned Flan-T5 XL (macro-F1 0.71) 和 Fine-tuned Flan-T5 XXL (macro-F1 0.70)。使用生成数据进行 augmentation 的效果因模型结构和大小而异，小型 Flan-T5 模型（基本和大型）在性能提升中表现最佳（delta F1 +0.12到 +0.23）。模型在医院内系统数据集上的表现相似，但在 MIMIC-III 数据集上表现更差。我们的最佳精度调整模型在 zero-和 few-shot 任务上表现更好，并且比 ChatGPT 家族模型更少改变其预测结果，这表明它们更少受到算法偏见（p<0.05）。在 patient 级别上，我们的模型可以识别93.8%的患者拥有不利的 SDoH，而 ICD-10 代码只能识别2.0%。我们的方法可以有效地从临床笔记中提取 SDoH 信息，并在 GPT zero-和 few-shot 设置下表现更好。这些模型可以增强实际证据，并帮助 indentify 需要社会支持的患者。
</details></li>
</ul>
<hr>
<h2 id="Combining-feature-aggregation-and-geometric-similarity-for-re-identification-of-patterned-animals"><a href="#Combining-feature-aggregation-and-geometric-similarity-for-re-identification-of-patterned-animals" class="headerlink" title="Combining feature aggregation and geometric similarity for re-identification of patterned animals"></a>Combining feature aggregation and geometric similarity for re-identification of patterned animals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06335">http://arxiv.org/abs/2308.06335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Veikka Immonen, Ekaterina Nepovinnykh, Tuomas Eerola, Charles V. Stewart, Heikki Kälviäinen</li>
<li>For: The paper is written for studying animal populations by using image-based re-identification of individual animals.* Methods: The paper combines two types of pattern similarity metrics: pattern appearance similarity and geometric pattern similarity.* Results: The proposed combination of pattern similarity metrics achieves promising re-identification accuracies for Saimaa ringed seals and whale sharks.Here’s the text in Simplified Chinese:</li>
<li>for: 研究动物种群，通过图像基于个体重新识别。</li>
<li>methods:  combining两种 patrern similarity metrics： patrern appearance similarity和几何 patrern similarity。</li>
<li>results: 提议的combinaison achieve promising的重新识别精度 дляSaimaa环形海豹和鲸鱼。<details>
<summary>Abstract</summary>
Image-based re-identification of animal individuals allows gathering of information such as migration patterns of the animals over time. This, together with large image volumes collected using camera traps and crowdsourcing, opens novel possibilities to study animal populations. For many species, the re-identification can be done by analyzing the permanent fur, feather, or skin patterns that are unique to each individual. In this paper, we address the re-identification by combining two types of pattern similarity metrics: 1) pattern appearance similarity obtained by pattern feature aggregation and 2) geometric pattern similarity obtained by analyzing the geometric consistency of pattern similarities. The proposed combination allows to efficiently utilize both the local and global pattern features, providing a general re-identification approach that can be applied to a wide variety of different pattern types. In the experimental part of the work, we demonstrate that the method achieves promising re-identification accuracies for Saimaa ringed seals and whale sharks.
</details>
<details>
<summary>摘要</summary>
图像基于个体重新识别动物，可以获取动物迁徙趋势的信息，并且通过摄像头和人员参与投票，收集大量图像。这些图像可以用于研究动物种群。许多物种的重新识别可以通过分析永久性毛发、羽毛或皮肤特征来完成，这些特征是每个个体唯一的。在这篇论文中，我们提出了结合两种模式相似度度量的方法：1）图像出现相似度度量，通过图像特征聚合获得，2）几何模式相似度度量，通过分析模式相似度的几何一致性来获得。该方法可以有效利用本地和全局模式特征，提供一种通用的重新识别方法，可以应用于多种不同的模式类型。在实验部分，我们示例了对Saimaa环形鳐和鲸鱼等动物的重新识别准确率。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Model-is-Efficient-Multimodal-Multitask-Model-Selector"><a href="#Foundation-Model-is-Efficient-Multimodal-Multitask-Model-Selector" class="headerlink" title="Foundation Model is Efficient Multimodal Multitask Model Selector"></a>Foundation Model is Efficient Multimodal Multitask Model Selector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06262">http://arxiv.org/abs/2308.06262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opengvlab/multitask-model-selector">https://github.com/opengvlab/multitask-model-selector</a></li>
<li>paper_authors: Fanqing Meng, Wenqi Shao, Zhanglin Peng, Chonghe Jiang, Kaipeng Zhang, Yu Qiao, Ping Luo</li>
<li>For: 本文研究了一个未得到充分研究的问题：给一个集合 pré-trained neural networks，预测它们在每个多 modal 任务上的性能，而不需要 fine-tuning 它们。* Methods: 本文提出了一种高效的多任务模型选择器（EMMS），使用大规模基础模型将多个下游任务的多种标签格式转化为一个统一的噪声标签嵌入。EMMS 可以通过一种简单的负权重回归来估计模型的传输性能，可以高效地解决一个 Alternating Minimization 算法。* Results: 广泛的实验表明，EMMS 是一种快速、有效和通用的模型选择器，可以高效地评估 pré-trained 模型的传输性能。例如，相比之前的 state-of-the-art 方法 LogME 增强我们的标签嵌入，EMMS 在图像识别、引用、描述、视觉问答和文本问答等五个下游任务上实现了9.0%、26.3%、20.1%、54.8% 和12.2% 的性能提升，同时带来5.13x、6.29x、3.59x、6.19x 和5.66x 的速度提升。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/Multitask-Model-Selector">https://github.com/OpenGVLab/Multitask-Model-Selector</a> 上获取。<details>
<summary>Abstract</summary>
This paper investigates an under-explored but important problem: given a collection of pre-trained neural networks, predicting their performance on each multi-modal task without fine-tuning them, such as image recognition, referring, captioning, visual question answering, and text question answering. A brute-force approach is to finetune all models on all target datasets, bringing high computational costs. Although recent-advanced approaches employed lightweight metrics to measure models' transferability,they often depend heavily on the prior knowledge of a single task, making them inapplicable in a multi-modal multi-task scenario. To tackle this issue, we propose an efficient multi-task model selector (EMMS), which employs large-scale foundation models to transform diverse label formats such as categories, texts, and bounding boxes of different downstream tasks into a unified noisy label embedding. EMMS can estimate a model's transferability through a simple weighted linear regression, which can be efficiently solved by an alternating minimization algorithm with a convergence guarantee. Extensive experiments on 5 downstream tasks with 24 datasets show that EMMS is fast, effective, and generic enough to assess the transferability of pre-trained models, making it the first model selection method in the multi-task scenario. For instance, compared with the state-of-the-art method LogME enhanced by our label embeddings, EMMS achieves 9.0\%, 26.3\%, 20.1\%, 54.8\%, 12.2\% performance gain on image recognition, referring, captioning, visual question answering, and text question answering, while bringing 5.13x, 6.29x, 3.59x, 6.19x, and 5.66x speedup in wall-clock time, respectively. The code is available at https://github.com/OpenGVLab/Multitask-Model-Selector.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhancing-Network-Management-Using-Code-Generated-by-Large-Language-Models"><a href="#Enhancing-Network-Management-Using-Code-Generated-by-Large-Language-Models" class="headerlink" title="Enhancing Network Management Using Code Generated by Large Language Models"></a>Enhancing Network Management Using Code Generated by Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06261">http://arxiv.org/abs/2308.06261</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Sathiya Kumaran Mani, Yajie Zhou, Kevin Hsieh, Santiago Segarra, Ranveer Chandra, Srikanth Kandula</li>
<li>for: This paper aims to provide a novel approach for natural-language-based network management, leveraging large language models (LLMs) to generate task-specific code from natural language queries.</li>
<li>methods: The proposed approach utilizes LLMs to generate code, addressing the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code and eliminating the need to share network data with LLMs.</li>
<li>results: The prototype system designed and evaluated in the paper demonstrates high accuracy, cost-effectiveness, and potential for further enhancements using complementary program synthesis techniques.<details>
<summary>Abstract</summary>
Analyzing network topologies and communication graphs plays a crucial role in contemporary network management. However, the absence of a cohesive approach leads to a challenging learning curve, heightened errors, and inefficiencies. In this paper, we introduce a novel approach to facilitate a natural-language-based network management experience, utilizing large language models (LLMs) to generate task-specific code from natural language queries. This method tackles the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code, eliminating the need to share network data with LLMs, and concentrating on application-specific requests combined with general program synthesis techniques. We design and evaluate a prototype system using benchmark applications, showcasing high accuracy, cost-effectiveness, and the potential for further enhancements using complementary program synthesis techniques.
</details>
<details>
<summary>摘要</summary>
现代网络管理中分析网络拓扑和通信图是关键。然而，由于缺乏一致的方法，会导致学习曲线困难、错误高伸和不效率。在这篇论文中，我们介绍一种新的方法，使得网络管理人员可以通过自然语言查询来获得任务特定的代码。这种方法解决了解释性、可扩展性和隐私问题，因为网络数据不需要与大语言模型（LLMs）分享，而是专注于应用特定的请求，并结合通用程序生成技术。我们设计并评估了一个原型系统，使用标准套件应用程序进行评估，显示高精度、成本效果和可能性。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-based-Investment-Portfolio-Selection"><a href="#ChatGPT-based-Investment-Portfolio-Selection" class="headerlink" title="ChatGPT-based Investment Portfolio Selection"></a>ChatGPT-based Investment Portfolio Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06260">http://arxiv.org/abs/2308.06260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oleksandr Romanko, Akhilesh Narayan, Roy H. Kwon</li>
<li>for: 投资组合选择（portfolio selection）</li>
<li>methods: 使用生成AI模型（ChatGPT）获取S&amp;P500市场指数中可能有潜力的股票，并对这些股票进行优化配置</li>
<li>results: 结果表明，使用ChatGPT进行股票选择可以带来更好的回报，但是在分配股票重量方面可能不如量化优化模型。但是将AI生成的股票选择与量化优化模型相结合，可以获得更好的投资效果，建议将来投资决策中采用协同approach。<details>
<summary>Abstract</summary>
In this paper, we explore potential uses of generative AI models, such as ChatGPT, for investment portfolio selection. Trusting investment advice from Generative Pre-Trained Transformer (GPT) models is a challenge due to model "hallucinations", necessitating careful verification and validation of the output. Therefore, we take an alternative approach. We use ChatGPT to obtain a universe of stocks from S&P500 market index that are potentially attractive for investing. Subsequently, we compared various portfolio optimization strategies that utilized this AI-generated trading universe, evaluating those against quantitative portfolio optimization models as well as comparing to some of the popular investment funds. Our findings indicate that ChatGPT is effective in stock selection but may not perform as well in assigning optimal weights to stocks within the portfolio. But when stocks selection by ChatGPT is combined with established portfolio optimization models, we achieve even better results. By blending strengths of AI-generated stock selection with advanced quantitative optimization techniques, we observed the potential for more robust and favorable investment outcomes, suggesting a hybrid approach for more effective and reliable investment decision-making in the future.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们探讨了使用生成AI模型，如ChatGPT，来选择投资 portefolio的可能性。因为GPT模型的“幻觉”问题，使得对模型输出的信任具有挑战性，因此我们采取了一种不同的方法。我们使用ChatGPT来获取S&P500市场指数中可能有吸引力的股票，然后比较了不同的投资组合优化策略，包括使用这些AI生成的交易宇宙，与量化投资优化模型进行比较，以及与一些流行的投资基金进行比较。我们的发现表明，ChatGPT在股票选择方面是有效的，但可能不如在分配股票 weights 方面表现好。但当ChatGPT生成的股票选择与已有的量化优化模型相结合时，我们可以获得更好的投资结果。通过融合AI生成的股票选择和已有的量化优化技术，我们发现了一种更加有效和可靠的投资决策方法，建议将这种方法应用于未来的投资决策中。
</details></li>
</ul>
<hr>
<h2 id="Automated-Sizing-and-Training-of-Efficient-Deep-Autoencoders-using-Second-Order-Algorithms"><a href="#Automated-Sizing-and-Training-of-Efficient-Deep-Autoencoders-using-Second-Order-Algorithms" class="headerlink" title="Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms"></a>Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06221">http://arxiv.org/abs/2308.06221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kanishka Tyagi, Chinmay Rane, Michael Manry</li>
<li>For: 本研究旨在提出一种多步训练方法，用于设计通用线性分类器。* Methods: 首先，通过回归获得初始多类线性分类器。然后，通过减少无用输入的方式，降低验证错误。同时，通过类似于霍-卡什洛夫规则的方法，提高 DESIRED 输出。接着，输出推定器被扩展为一个通用的线性分类器中的多层感知器。* Results: 通过组合剪枝和增长策略，提高输入单元的推定器，并将输出单元扩展为一个通用的线性分类器中的多层感知器。最后，通过改进每个深度学习块，提高整体深度学习模型的性能。<details>
<summary>Abstract</summary>
We propose a multi-step training method for designing generalized linear classifiers. First, an initial multi-class linear classifier is found through regression. Then validation error is minimized by pruning of unnecessary inputs. Simultaneously, desired outputs are improved via a method similar to the Ho-Kashyap rule. Next, the output discriminants are scaled to be net functions of sigmoidal output units in a generalized linear classifier. We then develop a family of batch training algorithm for the multi layer perceptron that optimizes its hidden layer size and number of training epochs. Next, we combine pruning with a growing approach. Later, the input units are scaled to be the net function of the sigmoidal output units that are then feed into as input to the MLP. We then propose resulting improvements in each of the deep learning blocks thereby improving the overall performance of the deep architecture. We discuss the principles and formulation regarding learning algorithms for deep autoencoders. We investigate several problems in deep autoencoders networks including training issues, the theoretical, mathematical and experimental justification that the networks are linear, optimizing the number of hidden units in each layer and determining the depth of the deep learning model. A direct implication of the current work is the ability to construct fast deep learning models using desktop level computational resources. This, in our opinion, promotes our design philosophy of building small but powerful algorithms. Performance gains are demonstrated at each step. Using widely available datasets, the final network's ten fold testing error is shown to be less than that of several other linear, generalized linear classifiers, multi layer perceptron and deep learners reported in the literature.
</details>
<details>
<summary>摘要</summary>
我们提出了一种多步训练方法用于设计通用线性分类器。首先，通过回归获得初始多类线性分类器。然后，通过减少不必要的输入，降低验证错误。同时，通过类似于霍-卡什纳规则的方法，提高期望的输出。接着，输出推定器被映射到通用线性分类器中的sigmoid输出单元。然后，我们开发了一家批处理训练算法，用于最优化多层感知器的隐藏层大小和训练轮次数。接着，我们结合剪除和增长方法。最后，输入单元被映射到sigmoid输出单元的网络中，并且这些输入单元被用作多层感知器的输入。我们then propose  several improvements in each deep learning block, leading to improved overall performance of the deep architecture. We discuss the principles and formulation of learning algorithms for deep autoencoders, and investigate several problems in deep autoencoder networks, including training issues, theoretical, mathematical, and experimental justification that the networks are linear, optimizing the number of hidden units in each layer, and determining the depth of the deep learning model. A direct implication of our work is the ability to construct fast deep learning models using desktop-level computational resources, which promotes our design philosophy of building small but powerful algorithms. Performance gains are demonstrated at each step. Using widely available datasets, the final network's ten-fold testing error is shown to be less than that of several other linear, generalized linear classifiers, multi-layer perceptron, and deep learners reported in the literature.
</details></li>
</ul>
<hr>
<h2 id="Safety-in-Traffic-Management-Systems-A-Comprehensive-Survey"><a href="#Safety-in-Traffic-Management-Systems-A-Comprehensive-Survey" class="headerlink" title="Safety in Traffic Management Systems: A Comprehensive Survey"></a>Safety in Traffic Management Systems: A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06204">http://arxiv.org/abs/2308.06204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlu Du, Ankan Dash, Jing Li, Hua Wei, Guiling Wang</li>
<li>for: 这篇论文旨在提供对交通管理系统安全性的全面回顾，包括交通管理系统中出现的各种安全问题、当前研究的状况以及提高交通管理系统安全性的技术和方法。</li>
<li>methods: 论文使用了文献综述的方法，概括了交通管理系统中的安全问题，并分析了当前研究的状况和提议。</li>
<li>results: 论文总结了当前研究的结果和限制，并提出了未来研究的方向。<details>
<summary>Abstract</summary>
Traffic management systems play a vital role in ensuring safe and efficient transportation on roads. However, the use of advanced technologies in traffic management systems has introduced new safety challenges. Therefore, it is important to ensure the safety of these systems to prevent accidents and minimize their impact on road users. In this survey, we provide a comprehensive review of the literature on safety in traffic management systems. Specifically, we discuss the different safety issues that arise in traffic management systems, the current state of research on safety in these systems, and the techniques and methods proposed to ensure the safety of these systems. We also identify the limitations of the existing research and suggest future research directions.
</details>
<details>
<summary>摘要</summary>
交通管理系统在公路上的交通运输中发挥了关键作用，但是使用先进技术的交通管理系统引入了新的安全挑战。因此，确保交通管理系统的安全性是非常重要的，以避免事故和减少它们对公路用户的影响。在这份调查中，我们提供了交通管理系统安全的全面评论。 Specifically，我们讨论了交通管理系统中不同的安全问题，当前的研究进展、以及为确保交通管理系统安全的技术和方法。我们还识别了现有研究的限制，并建议未来的研究方向。Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.AI_2023_08_12/" data-id="cloq1wkzz00297o889ecxetvo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.CL_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T11:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/cs.CL_2023_08_12/">cs.CL - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MT4CrossOIE-Multi-stage-Tuning-for-Cross-lingual-Open-Information-Extraction"><a href="#MT4CrossOIE-Multi-stage-Tuning-for-Cross-lingual-Open-Information-Extraction" class="headerlink" title="MT4CrossOIE: Multi-stage Tuning for Cross-lingual Open Information Extraction"></a>MT4CrossOIE: Multi-stage Tuning for Cross-lingual Open Information Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06552">http://arxiv.org/abs/2308.06552</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CSJianYang/Multilingual-Multimodal-NLP/tree/main/MT4CrossOIE">https://github.com/CSJianYang/Multilingual-Multimodal-NLP/tree/main/MT4CrossOIE</a></li>
<li>paper_authors: Zixiang Wang, Linzheng Chai, Jian Yang, Jiaqi Bai, Yuwei Yin, Jiaheng Liu, Hongcheng Guo, Tongliang Li, Liqun Yang, Hebboul Zine el-abidine, Zhoujun Li</li>
<li>for: 提高多语言开放信息提取（Cross-Lingual Open Information Extraction，简称CrossIE）的效果，使得模型能够在不同语言的文本上提取结构化信息。</li>
<li>methods: 提出了一种多阶段调整框架MT4CrossIE，通过将语言特定的知识注入到共享模型中来提高crossIE的性能。</li>
<li>results: 实验结果表明，通过组合模型基于和数据基于的转移技术，MT4CrossIE可以在多种benchmark上提高crossIE的性能，并且多个语言特定模块的组合对crossIE的性能有积极的影响。<details>
<summary>Abstract</summary>
Cross-lingual open information extraction aims to extract structured information from raw text across multiple languages. Previous work uses a shared cross-lingual pre-trained model to handle the different languages but underuses the potential of the language-specific representation. In this paper, we propose an effective multi-stage tuning framework called MT4CrossIE, designed for enhancing cross-lingual open information extraction by injecting language-specific knowledge into the shared model. Specifically, the cross-lingual pre-trained model is first tuned in a shared semantic space (e.g., embedding matrix) in the fixed encoder and then other components are optimized in the second stage. After enough training, we freeze the pre-trained model and tune the multiple extra low-rank language-specific modules using mixture-of-LoRAs for model-based cross-lingual transfer. In addition, we leverage two-stage prompting to encourage the large language model (LLM) to annotate the multi-lingual raw data for data-based cross-lingual transfer. The model is trained with multi-lingual objectives on our proposed dataset OpenIE4++ by combing the model-based and data-based transfer techniques. Experimental results on various benchmarks emphasize the importance of aggregating multiple plug-in-and-play language-specific modules and demonstrate the effectiveness of MT4CrossIE in cross-lingual OIE\footnote{\url{https://github.com/CSJianYang/Multilingual-Multimodal-NLP}.
</details>
<details>
<summary>摘要</summary>
cross-lingual开放信息提取目标在多种语言之间提取结构化信息。先前的工作使用共享的cross-lingual预训练模型处理不同语言，但是未能充分利用语言特定表示的潜在优势。在这篇论文中，我们提出了一种高效的多阶段调整框架MT4CrossIE，用于提高cross-lingual开放信息提取。具体来说，在共享的semantic space（例如embedding matrix）中首先对cross-lingual预训练模型进行共享调整，然后其他组件在第二阶段进行优化。经过充分训练后，我们冻结预训练模型，并使用mixture-of-LoRAs进行模型基于cross-lingual传递。此外，我们利用两阶段提示来鼓励大语言模型（LLM）对多语言原始数据进行标注，以实现数据基于cross-lingual传递。我们在OpenIE4++数据集上训练了多语言目标，并结合模型基于和数据基于传递技术。实验结果在多个benchmark上表明，汇集多个插件和Play语言特定模块的重要性，并证明MT4CrossIE在cross-lingual OIE中的效果。
</details></li>
</ul>
<hr>
<h2 id="Alternative-Pseudo-Labeling-for-Semi-Supervised-Automatic-Speech-Recognition"><a href="#Alternative-Pseudo-Labeling-for-Semi-Supervised-Automatic-Speech-Recognition" class="headerlink" title="Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech Recognition"></a>Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06547">http://arxiv.org/abs/2308.06547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Zhu, Dongji Gao, Gaofeng Cheng, Daniel Povey, Pengyuan Zhang, Yonghong Yan<br>for: 提高自动语音识别器的性能在半监督学习中，当标注数据稀缺时methods: 提议一种新的替代 pseudo-labeling 框架，包括一个通用的 CTC 损失函数、验证错误 Pseudo-label 的方法和自动调整 thresholdresults: 在实验中，该框架可以在半监督学习中提高自动语音识别器的性能，并且可以自动调整 threshold，避免手动调整 threshold 的痛苦<details>
<summary>Abstract</summary>
When labeled data is insufficient, semi-supervised learning with the pseudo-labeling technique can significantly improve the performance of automatic speech recognition. However, pseudo-labels are often noisy, containing numerous incorrect tokens. Taking noisy labels as ground-truth in the loss function results in suboptimal performance. Previous works attempted to mitigate this issue by either filtering out the nosiest pseudo-labels or improving the overall quality of pseudo-labels. While these methods are effective to some extent, it is unrealistic to entirely eliminate incorrect tokens in pseudo-labels. In this work, we propose a novel framework named alternative pseudo-labeling to tackle the issue of noisy pseudo-labels from the perspective of the training objective. The framework comprises several components. Firstly, a generalized CTC loss function is introduced to handle noisy pseudo-labels by accepting alternative tokens in the positions of incorrect tokens. Applying this loss function in pseudo-labeling requires detecting incorrect tokens in the predicted pseudo-labels. In this work, we adopt a confidence-based error detection method that identifies the incorrect tokens by comparing their confidence scores with a given threshold, thus necessitating the confidence score to be discriminative. Hence, the second proposed technique is the contrastive CTC loss function that widens the confidence gap between the correctly and incorrectly predicted tokens, thereby improving the error detection ability. Additionally, obtaining satisfactory performance with confidence-based error detection typically requires extensive threshold tuning. Instead, we propose an automatic thresholding method that uses labeled data as a proxy for determining the threshold, thus saving the pain of manual tuning.
</details>
<details>
<summary>摘要</summary>
当标注数据不足时，半超vised学习使用pseudo-labeling技术可以显著提高自动语音识别的性能。然而，pseudo-labels经常含有许多错误的标签。使用含有错误标签的labels作为损失函数中的参考数据会导致优化性能的问题。先前的工作已经尝试过抑制这个问题，可以是通过筛选pseudo-labels中的最噪音标签，或者提高pseudo-labels的质量。尽管这些方法有一定的效果，但是完全消除pseudo-labels中的错误标签是不现实的。在这种情况下，我们提出了一种新的框架，即代理pseudo-labeling。该框架包括以下几个组成部分：1. 一种通用的CTC损失函数，可以处理含有错误标签的pseudo-labels。该损失函数可以接受pseudo-labels中的错误标签，并且可以在预测过程中检测错误标签。2. 一种信息储存基于错误检测方法，可以在预测过程中检测pseudo-labels中的错误标签。该方法通过比较预测的信息储存与给定的阈值进行比较，以确定错误标签。3. 一种自动调整阈值的方法，可以使用标注数据作为代理，以便不需要手动调整阈值。这种新的框架可以减少因为使用含有错误标签的labels而导致的优化性能问题，并且可以在不完全消除pseudo-labels中的错误标签的情况下提高自动语音识别的性能。
</details></li>
</ul>
<hr>
<h2 id="With-a-Little-Help-from-the-Authors-Reproducing-Human-Evaluation-of-an-MT-Error-Detector"><a href="#With-a-Little-Help-from-the-Authors-Reproducing-Human-Evaluation-of-an-MT-Error-Detector" class="headerlink" title="With a Little Help from the Authors: Reproducing Human Evaluation of an MT Error Detector"></a>With a Little Help from the Authors: Reproducing Human Evaluation of an MT Error Detector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06527">http://arxiv.org/abs/2308.06527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ondřej Plátek, Mateusz Lango, Ondřej Dušek</li>
<li>for: 本研究重新实现了瓦姆瓦斯和塞恩兹（2022）的人工评估实验，该实验evaluated一个自动检测机器翻译输出中的过度和不足翻译（翻译包含更多或更少信息 than the original）的自动系统。</li>
<li>methods: 我们使用了作者提供的文档和代码，但在重新实现实验setup时，我们发现了一些问题，并提供了改进可重现性的建议。</li>
<li>results: 我们的复制结果大致与原始研究的结论相符，但在某些情况下，我们 observeda statistically significant differences，表明了人工标注的高变异性。<details>
<summary>Abstract</summary>
This work presents our efforts to reproduce the results of the human evaluation experiment presented in the paper of Vamvas and Sennrich (2022), which evaluated an automatic system detecting over- and undertranslations (translations containing more or less information than the original) in machine translation (MT) outputs. Despite the high quality of the documentation and code provided by the authors, we discuss some problems we found in reproducing the exact experimental setup and offer recommendations for improving reproducibility. Our replicated results generally confirm the conclusions of the original study, but in some cases, statistically significant differences were observed, suggesting a high variability of human annotation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AutoConv-Automatically-Generating-Information-seeking-Conversations-with-Large-Language-Models"><a href="#AutoConv-Automatically-Generating-Information-seeking-Conversations-with-Large-Language-Models" class="headerlink" title="AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models"></a>AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06507">http://arxiv.org/abs/2308.06507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siheng Li, Cheng Yang, Yichun Yin, Xinyu Zhu, Zesen Cheng, Lifeng Shang, Xin Jiang, Qun Liu, Yujiu Yang</li>
<li>for: 提高信息寻求对话生成的训练数据稀缺性问题</li>
<li>methods: 利用大语言模型几何学习和生成能力，将对话生成问题定义为语言模型预测问题，并在几个人对话的基础上训练语言模型来捕捉信息寻求过程的特征，生成高质量的synthetic对话</li>
<li>results: 对两个常用的数据集进行实验，证明AutoConv具有显著的提升和减少人工标注的依赖性<details>
<summary>Abstract</summary>
Information-seeking conversation, which aims to help users gather information through conversation, has achieved great progress in recent years. However, the research is still stymied by the scarcity of training data. To alleviate this problem, we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM). Specifically, we formulate the conversation generation problem as a language modeling task, then finetune an LLM with a few human conversations to capture the characteristics of the information-seeking process and use it for generating synthetic conversations with high quality. Experimental results on two frequently-used datasets verify that AutoConv has substantial improvements over strong baselines and alleviates the dependence on human annotation. In addition, we also provide several analysis studies to promote future research.
</details>
<details>
<summary>摘要</summary>
信息寻求对话，目前已经取得了很大的进步，但研究还面临着数据缺乏的问题。为解决这个问题，我们提出了AutoConv，它利用大语言模型（LLM）的几shot学习能力和生成能力来生成高质量的人工对话。具体来说，我们将对话生成问题定义为语言模型化问题，然后使用一些人类对话来训练LLM，以capture信息寻求过程中的特点。实验结果表明，AutoConv在两个常用的数据集上具有显著的提升和减少人类注释的依赖性。此外，我们还提供了一些分析研究，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="NewsDialogues-Towards-Proactive-News-Grounded-Conversation"><a href="#NewsDialogues-Towards-Proactive-News-Grounded-Conversation" class="headerlink" title="NewsDialogues: Towards Proactive News Grounded Conversation"></a>NewsDialogues: Towards Proactive News Grounded Conversation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06501">http://arxiv.org/abs/2308.06501</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sihengli99/newsdialogues">https://github.com/sihengli99/newsdialogues</a></li>
<li>paper_authors: Siheng Li, Yichun Yin, Cheng Yang, Wangjie Jiang, Yiwei Li, Zesen Cheng, Lifeng Shang, Xin Jiang, Qun Liu, Yujiu Yang</li>
<li>for: 本研究旨在提出一种新任务——积极新闻附加对话，以便对话系统可以主动领导对话，基于新闻中的一些关键话题。</li>
<li>methods: 本研究使用了一种名为Predict-Generate-Rank的方法，包括一个生成器用于预测和生成基于新闻的知识，以及一个排名器用于对多个回答进行排名，以避免曝光偏见。</li>
<li>results: 经过广泛的实验，研究发现了一些关键发现和挑战，以及提出了未来研究的一些方向。<details>
<summary>Abstract</summary>
Hot news is one of the most popular topics in daily conversations. However, news grounded conversation has long been stymied by the lack of well-designed task definition and scarce data. In this paper, we propose a novel task, Proactive News Grounded Conversation, in which a dialogue system can proactively lead the conversation based on some key topics of the news. In addition, both information-seeking and chit-chat scenarios are included realistically, where the user may ask a series of questions about the news details or express their opinions and be eager to chat. To further develop this novel task, we collect a human-to-human Chinese dialogue dataset \ts{NewsDialogues}, which includes 1K conversations with a total of 14.6K utterances and detailed annotations for target topics and knowledge spans. Furthermore, we propose a method named Predict-Generate-Rank, consisting of a generator for grounded knowledge prediction and response generation, and a ranker for the ranking of multiple responses to alleviate the exposure bias. We conduct comprehensive experiments to demonstrate the effectiveness of the proposed method and further present several key findings and challenges to prompt future research.
</details>
<details>
<summary>摘要</summary>
热门新闻是日常对话中最受欢迎的话题之一，然而新闻基于对话的探讨长期受到缺乏有效定义任务和珍贵数据的限制。在这篇论文中，我们提出了一个新任务：主动新闻基于对话（Proactive News Grounded Conversation），在其中对话系统可以主动引导对话，基于新闻中的一些关键话题。此外，我们还包括了信息寻求和聊天场景，用户可能会提问新闻细节的多个问题或表达自己的意见并且很有兴趣聊天。为了进一步开发这个新任务，我们收集了一个人类对话 dataset 《NewsDialogues》，该 dataset 包含了1000个对话，总共14600个语音和详细的注释目标话题和知识范围。此外，我们还提出了一种方法，即预测生成排名（Predict-Generate-Rank），该方法包括一个生成基于新闻的预测和回答生成器，以及一个排名器用于多个答案的排名，以降低曝光偏见。我们进行了广泛的实验，以示提出的方法的效iveness，并提出了一些关键发现和未来研究的挑战。
</details></li>
</ul>
<hr>
<h2 id="GPT-4-Is-Too-Smart-To-Be-Safe-Stealthy-Chat-with-LLMs-via-Cipher"><a href="#GPT-4-Is-Too-Smart-To-Be-Safe-Stealthy-Chat-with-LLMs-via-Cipher" class="headerlink" title="GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher"></a>GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06463">http://arxiv.org/abs/2308.06463</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/robustnlp/cipherchat">https://github.com/robustnlp/cipherchat</a></li>
<li>paper_authors: Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Pinjia He, Shuming Shi, Zhaopeng Tu</li>
<li>for: 本研究旨在探讨大语言模型（LLMs）的安全定制是否可以扩展到非自然语言（cipher）领域。</li>
<li>methods: 我们提出了一种名为 CipherChat 的新框架，允许人类通过密码提示和几个几shot 加密示例与 LLMs 进行交流。我们使用 CipherChat 评估当今最先进的 LLMs，包括 ChatGPT 和 GPT-4，在不同的人类密码下的11个安全领域中的表现。</li>
<li>results: 实验结果表明，某些密码可以在某些安全领域中绕过 GPT-4 的安全定制，这说明了在非自然语言领域中的安全定制的必要性。此外，我们发现 LLMs 似乎有一种’’秘密密码’’，并提出了一种名为 SelfCipher 的新方法，可以通过角色扮演和几个示例来触发这种能力。SelfCipher  surprisingly 在大多数情况下超过了现有的人类密码。我们将代码和数据发布在 GitHub 上（<a target="_blank" rel="noopener" href="https://github.com/RobustNLP/CipherChat">https://github.com/RobustNLP/CipherChat</a>）。<details>
<summary>Abstract</summary>
Safety lies at the core of the development of Large Language Models (LLMs). There is ample work on aligning LLMs with human ethics and preferences, including data filtering in pretraining, supervised fine-tuning, reinforcement learning from human feedback, and red teaming, etc. In this study, we discover that chat in cipher can bypass the safety alignment techniques of LLMs, which are mainly conducted in natural languages. We propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages -- ciphers. CipherChat enables humans to chat with LLMs through cipher prompts topped with system role descriptions and few-shot enciphered demonstrations. We use CipherChat to assess state-of-the-art LLMs, including ChatGPT and GPT-4 for different representative human ciphers across 11 safety domains in both English and Chinese. Experimental results show that certain ciphers succeed almost 100% of the time to bypass the safety alignment of GPT-4 in several safety domains, demonstrating the necessity of developing safety alignment for non-natural languages. Notably, we identify that LLMs seem to have a ''secret cipher'', and propose a novel SelfCipher that uses only role play and several demonstrations in natural language to evoke this capability. SelfCipher surprisingly outperforms existing human ciphers in almost all cases. Our code and data will be released at https://github.com/RobustNLP/CipherChat.
</details>
<details>
<summary>摘要</summary>
安全是大语言模型（LLM）的核心发展之一。有很多工作在将 LLM 与人类伦理和偏好相匹配，包括预处理数据筛选、监督练习、人类反馈强化学习和红团等等。在这项研究中，我们发现可以通过密码来绕过 LLM 的安全对齐技术，这些技术主要是在自然语言上进行的。我们提出了一个新的框架 CipherChat，用于系统地检验非自然语言（密码）上 LLM 的安全对齐可行性。CipherChat 允许人们通过密码提示和系统角色描述以及几个加密示例来与 LLM 进行交流。我们使用 CipherChat 测试了当前的状态体 LLM，包括 ChatGPT 和 GPT-4，在不同的人类密码上进行了11个安全领域的测试。实验结果显示，某些密码可以在多个安全领域中绕过 GPT-4 的安全对齐，这说明了非自然语言的安全对齐的必要性。另外，我们发现 LLM 似乎有一个“秘密密码”，我们提出了一种新的 SelfCipher，只需要通过角色扮演和几个示例来诱发这种能力。SelfCipher  surprisingly 在大多数情况下超过了现有的人类密码。我们的代码和数据将在 GitHub 上发布。
</details></li>
</ul>
<hr>
<h2 id="Text-to-Video-a-Two-stage-Framework-for-Zero-shot-Identity-agnostic-Talking-head-Generation"><a href="#Text-to-Video-a-Two-stage-Framework-for-Zero-shot-Identity-agnostic-Talking-head-Generation" class="headerlink" title="Text-to-Video: a Two-stage Framework for Zero-shot Identity-agnostic Talking-head Generation"></a>Text-to-Video: a Two-stage Framework for Zero-shot Identity-agnostic Talking-head Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06457">http://arxiv.org/abs/2308.06457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhichaowang970201/text-to-video">https://github.com/zhichaowang970201/text-to-video</a></li>
<li>paper_authors: Zhichao Wang, Mengyu Dai, Keld Lundgaard</li>
<li>for: 本研究旨在提供一种基于文本的视频创建方法，具体来说是一种人脸无关的视频审核方法，以便在不同的语言和语速下生成可观看的视频。</li>
<li>methods: 本研究提出了一种两stage的方法，包括文本至语音转化和语音驱动的人脸讲话生成。在第一阶段，我们利用预训练的零shot模型实现文本至语音转化。在第二阶段，我们使用语音驱动的人脸讲话生成方法，以生成有趣的视频。</li>
<li>results: 本研究通过对不同的文本和语音样本进行比较分析，找到了最佳的文本至语音转化和语音驱动的人脸讲话生成方法。此外，我们还提供了一些Audio和视频示例，可以在以下链接中找到：<a target="_blank" rel="noopener" href="https://github.com/ZhichaoWang970201/Text-to-Video/tree/main%E3%80%82">https://github.com/ZhichaoWang970201/Text-to-Video/tree/main。</a><details>
<summary>Abstract</summary>
The advent of ChatGPT has introduced innovative methods for information gathering and analysis. However, the information provided by ChatGPT is limited to text, and the visualization of this information remains constrained. Previous research has explored zero-shot text-to-video (TTV) approaches to transform text into videos. However, these methods lacked control over the identity of the generated audio, i.e., not identity-agnostic, hindering their effectiveness. To address this limitation, we propose a novel two-stage framework for person-agnostic video cloning, specifically focusing on TTV generation. In the first stage, we leverage pretrained zero-shot models to achieve text-to-speech (TTS) conversion. In the second stage, an audio-driven talking head generation method is employed to produce compelling videos privided the audio generated in the first stage. This paper presents a comparative analysis of different TTS and audio-driven talking head generation methods, identifying the most promising approach for future research and development. Some audio and videos samples can be found in the following link: https://github.com/ZhichaoWang970201/Text-to-Video/tree/main.
</details>
<details>
<summary>摘要</summary>
随着ChatGPT的出现，新的信息收集和分析方法得到了推动。然而，ChatGPT提供的信息仅限于文本，视觉化这些信息仍然受限。先前的研究曾经 explore zero-shot文本到视频（TTV）方法，将文本转换成视频。然而，这些方法缺乏控制音频个体的能力，妨碍其效iveness。为了解决这个限制，我们提议一种新的两阶段框架，专门针对人具无关的视频副本。在第一阶段，我们利用预训练的零shot模型实现文本到语音（TTS）转换。在第二阶段，我们使用音频驱动的人物头部生成方法生成有吸引力的视频，只要提供在第一阶段生成的音频。本文对不同的TTS和音频驱动人物头部生成方法进行比较分析，并确定未来研究和发展的最佳方法。有关音频和视频样例，请参考以下链接：https://github.com/ZhichaoWang970201/Text-to-Video/tree/main。
</details></li>
</ul>
<hr>
<h2 id="Demonstration-based-learning-for-few-shot-biomedical-named-entity-recognition-under-machine-reading-comprehension"><a href="#Demonstration-based-learning-for-few-shot-biomedical-named-entity-recognition-under-machine-reading-comprehension" class="headerlink" title="Demonstration-based learning for few-shot biomedical named entity recognition under machine reading comprehension"></a>Demonstration-based learning for few-shot biomedical named entity recognition under machine reading comprehension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06454">http://arxiv.org/abs/2308.06454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leilei Su, Jian Chen, Yifan Peng, Cong Sun</li>
<li>for: 提高几少 BioNER 模型的识别能力</li>
<li>methods: 利用示例学习方法，将 BioNER 转化为机器阅读理解问题</li>
<li>results: 在6个数据集上，与基eline方法比较，提高了1.1%和1.0%的平均 F1 分数，并且可以与大量注释数据的完全监督学习方法竞争<details>
<summary>Abstract</summary>
Although deep learning techniques have shown significant achievements, they frequently depend on extensive amounts of hand-labeled data and tend to perform inadequately in few-shot scenarios. The objective of this study is to devise a strategy that can improve the model's capability to recognize biomedical entities in scenarios of few-shot learning. By redefining biomedical named entity recognition (BioNER) as a machine reading comprehension (MRC) problem, we propose a demonstration-based learning method to address few-shot BioNER, which involves constructing appropriate task demonstrations. In assessing our proposed method, we compared the proposed method with existing advanced methods using six benchmark datasets, including BC4CHEMD, BC5CDR-Chemical, BC5CDR-Disease, NCBI-Disease, BC2GM, and JNLPBA. We examined the models' efficacy by reporting F1 scores from both the 25-shot and 50-shot learning experiments. In 25-shot learning, we observed 1.1% improvements in the average F1 scores compared to the baseline method, reaching 61.7%, 84.1%, 69.1%, 70.1%, 50.6%, and 59.9% on six datasets, respectively. In 50-shot learning, we further improved the average F1 scores by 1.0% compared to the baseline method, reaching 73.1%, 86.8%, 76.1%, 75.6%, 61.7%, and 65.4%, respectively. We reported that in the realm of few-shot learning BioNER, MRC-based language models are much more proficient in recognizing biomedical entities compared to the sequence labeling approach. Furthermore, our MRC-language models can compete successfully with fully-supervised learning methodologies that rely heavily on the availability of abundant annotated data. These results highlight possible pathways for future advancements in few-shot BioNER methodologies.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管深度学习技术已经达到了显著的成就，但它们往往需要大量的手动标注数据，并在几个shot场景下表现不佳。本研究的目标是提出一种策略，以提高模型在几个shot学习中识别生物医学实体的能力。我们将生物医学命名实体识别（BioNER）定义为机器阅读理解（MRC）问题，并提出了一种示例学习方法来解决几个shot BioNER。我们使用了六个标准测试集来评估我们的提议方法，包括BC4CHEMD、BC5CDR-Chemical、BC5CDR-疾病、NCBI-疾病、BC2GM和JNLPBA。我们根据25个shot和50个shot的学习实验来评估模型的效果，并发现在25个shot学习中，我们的方法与基eline方法相比，平均F1分数提高了1.1%，达到了61.7%、84.1%、69.1%、70.1%、50.6%和59.9%的水平。在50个shot学习中，我们进一步提高了平均F1分数，达到了73.1%、86.8%、76.1%、75.6%、61.7%和65.4%的水平。我们发现，在几个shot BioNER中，基于MRC语言模型的方法比sequence标注方法更有才能地识别生物医学实体。此外，我们的MRC语言模型可以与充分监督学习方法竞争，这些方法依赖于大量的注释数据的可用性。这些结果透视了未来几个shot BioNER方法的可能发展道路。
</details></li>
</ul>
<hr>
<h2 id="Simple-Model-Also-Works-A-Novel-Emotion-Recognition-Network-in-Textual-Conversation-Based-on-Curriculum-Learning-Strategy"><a href="#Simple-Model-Also-Works-A-Novel-Emotion-Recognition-Network-in-Textual-Conversation-Based-on-Curriculum-Learning-Strategy" class="headerlink" title="Simple Model Also Works: A Novel Emotion Recognition Network in Textual Conversation Based on Curriculum Learning Strategy"></a>Simple Model Also Works: A Novel Emotion Recognition Network in Textual Conversation Based on Curriculum Learning Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06450">http://arxiv.org/abs/2308.06450</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiang Li, Xiaoping Wang, Yingjian Liu, Qing Zhou, Zhigang Zeng</li>
<li>for: 本研究主要针对对话中的情感识别 зада项 (Emotion Recognition in Conversation, ERC) 进行研究，以提高情感识别的效率和精度。</li>
<li>methods: 本研究提出了一个基于学习范例 (Curriculum Learning, CL) 的情感识别网络 (Emotion Recognition Network, ERNetCL)，并使用时间编码 (Temporal Encoder, TE) 和空间编码 (Spatial Encoder, SE) 来融合先前的方法，以优化情感识别的效率和精度。</li>
<li>results: 实验结果显示，本研究的提案方法可以优化情感识别的效率和精度，并与其他基于标准方法的方法相比，具有明显的性能优化。<details>
<summary>Abstract</summary>
Emotion Recognition in Conversation (ERC) has emerged as a research hotspot in domains such as conversational robots and question-answer systems. How to efficiently and adequately retrieve contextual emotional cues has been one of the key challenges in the ERC task. Existing efforts do not fully model the context and employ complex network structures, resulting in excessive computational resource overhead without substantial performance improvement. In this paper, we propose a novel Emotion Recognition Network based on Curriculum Learning strategy (ERNetCL). The proposed ERNetCL primarily consists of Temporal Encoder (TE), Spatial Encoder (SE), and Curriculum Learning (CL) loss. We utilize TE and SE to combine the strengths of previous methods in a simplistic manner to efficiently capture temporal and spatial contextual information in the conversation. To simulate the way humans learn curriculum from easy to hard, we apply the idea of CL to the ERC task to progressively optimize the network parameters of ERNetCL. At the beginning of training, we assign lower learning weights to difficult samples. As the epoch increases, the learning weights for these samples are gradually raised. Extensive experiments on four datasets exhibit that our proposed method is effective and dramatically beats other baseline models.
</details>
<details>
<summary>摘要</summary>
《对话中情感识别（ERC）》在领域如会话机器人和问答系统中已经成为研究热点。 efficiently和准确地检索上下文情感cue是ERC任务中的关键挑战。现有尝试没有完全考虑上下文，使用复杂的网络结构，导致计算资源占用过高而无法提供明显的性能提升。本文提出了一种基于学习纲程（CL）的情感识别网络（ERNetCL）。我们利用TE和SE组合previous方法的优点，以简单的方式高效地捕捉对话中的时间和空间上下文信息。通过模仿人类学习纲程的思想，我们在ERC任务中应用CL来逐渐优化ERNetCL的网络参数。在训练的开始时，我们将难度较高的样本分配低学习权重。随着epoch增加，这些样本的学习权重逐渐升高。我们在四个数据集进行了广泛的实验，结果显示，我们的提议方法效果明显，可以很好地超越基准模型。
</details></li>
</ul>
<hr>
<h2 id="Performance-Prediction-for-Multi-hop-Questions"><a href="#Performance-Prediction-for-Multi-hop-Questions" class="headerlink" title="Performance Prediction for Multi-hop Questions"></a>Performance Prediction for Multi-hop Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06431">http://arxiv.org/abs/2308.06431</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammadreza Samadi, Davood Rafiei</li>
<li>for: 预测开放领域多步问答（QA）问题的评估难度。</li>
<li>methods: 提出了一种新的预测方法multHP，用于预测开放领域多步问答问题的表现。</li>
<li>results: 对largest multi-hop QA数据集进行了广泛的评估，并显示了提档的表现，比传统单步QPP模型更好。 Additionally, the approach can be effectively used to optimize the parameters of QA systems, such as the number of documents to be retrieved, resulting in improved overall retrieval performance.<details>
<summary>Abstract</summary>
We study the problem of Query Performance Prediction (QPP) for open-domain multi-hop Question Answering (QA), where the task is to estimate the difficulty of evaluating a multi-hop question over a corpus. Despite the extensive research on predicting the performance of ad-hoc and QA retrieval models, there has been a lack of study on the estimation of the difficulty of multi-hop questions. The problem is challenging due to the multi-step nature of the retrieval process, potential dependency of the steps and the reasoning involved. To tackle this challenge, we propose multHP, a novel pre-retrieval method for predicting the performance of open-domain multi-hop questions. Our extensive evaluation on the largest multi-hop QA dataset using several modern QA systems shows that the proposed model is a strong predictor of the performance, outperforming traditional single-hop QPP models. Additionally, we demonstrate that our approach can be effectively used to optimize the parameters of QA systems, such as the number of documents to be retrieved, resulting in improved overall retrieval performance.
</details>
<details>
<summary>摘要</summary>
我们研究了开放领域多步问答（QA）中的问题评估性能预测（QPP）问题，即估计评估一个多步问题的难度。尽管有很多关于预测广泛问答和搜索模型性能的研究，但是没有研究了多步问题的预测。这个问题具有多步搜索过程的多样性和步骤之间的依赖关系，以及需要进行推理。为解决这个挑战，我们提出了 multHP，一种新的预测开放领域多步问题性能的方法。我们对最大的多步问答数据集进行了广泛的评估，结果表明，我们提出的模型是一个强大的性能预测器，超过了传统单步 QPP 模型。此外，我们还证明了我们的方法可以有效地用于优化 QA 系统的参数，例如检索文档的数量，从而提高总体检索性能。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Planning-with-a-LLM"><a href="#Dynamic-Planning-with-a-LLM" class="headerlink" title="Dynamic Planning with a LLM"></a>Dynamic Planning with a LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06391">http://arxiv.org/abs/2308.06391</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/itl-ed/llm-dp">https://github.com/itl-ed/llm-dp</a></li>
<li>paper_authors: Gautier Dagan, Frank Keller, Alex Lascarides</li>
<li>for: 解决 embodied agent 应用问题，尤其是复杂的计划需要多步骤的情况。</li>
<li>methods: 融合 neural network 和 symbolic planner，使用 LLM 和 traditional planner 共同解决 embodied task。</li>
<li>results: LLM-DP 比 naive LLM ReAct baseline 更快和更高效地解决 Alfworld 问题。<details>
<summary>Abstract</summary>
While Large Language Models (LLMs) can solve many NLP tasks in zero-shot settings, applications involving embodied agents remain problematic. In particular, complex plans that require multi-step reasoning become difficult and too costly as the context window grows. Planning requires understanding the likely effects of one's actions and identifying whether the current environment satisfies the goal state. While symbolic planners find optimal solutions quickly, they require a complete and accurate representation of the planning problem, severely limiting their use in practical scenarios. In contrast, modern LLMs cope with noisy observations and high levels of uncertainty when reasoning about a task. Our work presents LLM Dynamic Planner (LLM-DP): a neuro-symbolic framework where an LLM works hand-in-hand with a traditional planner to solve an embodied task. Given action-descriptions, LLM-DP solves Alfworld faster and more efficiently than a naive LLM ReAct baseline.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）可以解决许多自然语言处理任务在零模式下，但是包含身体代理的应用仍然是问题。特别是复杂的计划需要多步骤的理解和识别环境是否满足目标状态。而符号计划器可以快速找到优化解决方案，但它们需要完整和准确地表示计划问题，因此在实际场景中几乎无法使用。相比之下，现代LLM在面临噪音观察和高度不确定性时仍然能够有效地理解任务。我们的工作提出了LLM动态规划器（LLM-DP）：一种神经符号框架，在LLM与传统计划器之间协作解决身体任务。给出动作描述，LLM-DP比预期的LLM ReAct基线更快和高效地解决了Alfworld任务。
</details></li>
</ul>
<hr>
<h2 id="Bilingual-Streaming-ASR-with-Grapheme-units-and-Auxiliary-Monolingual-Loss"><a href="#Bilingual-Streaming-ASR-with-Grapheme-units-and-Auxiliary-Monolingual-Loss" class="headerlink" title="Bilingual Streaming ASR with Grapheme units and Auxiliary Monolingual Loss"></a>Bilingual Streaming ASR with Grapheme units and Auxiliary Monolingual Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06327">http://arxiv.org/abs/2308.06327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Soleymanpour, Mahmoud Al Ismail, Fahimeh Bahmaninezhad, Kshitiz Kumar, Jian Wu</li>
<li>for: 这个研究旨在提供一个英文作为次要区域的混合自动语音识别（ASR）设置中的双语解决方案。</li>
<li>methods: 我们的主要开发包括： (a) 发音词库使用文字单位而不是语音单位， (b) 完全双语对焦模型和随后的双语流式变数模型， (c) 平行Encoder结构 WITH 语言识别（LID）损失， (d) 平行Encoder WITH 辅助损失 для单语言预测。</li>
<li>results: 我们的工作在大规模训练和测试任务中显示出强大的英文混合能力。特别是双语IT模型在一个混合IT任务中从46.5%降至13.8%，同时也与单语IT模型（9.5%）在IT测试中仅差0.6%。<details>
<summary>Abstract</summary>
We introduce a bilingual solution to support English as secondary locale for most primary locales in hybrid automatic speech recognition (ASR) settings. Our key developments constitute: (a) pronunciation lexicon with grapheme units instead of phone units, (b) a fully bilingual alignment model and subsequently bilingual streaming transformer model, (c) a parallel encoder structure with language identification (LID) loss, (d) parallel encoder with an auxiliary loss for monolingual projections. We conclude that in comparison to LID loss, our proposed auxiliary loss is superior in specializing the parallel encoders to respective monolingual locales, and that contributes to stronger bilingual learning. We evaluate our work on large-scale training and test tasks for bilingual Spanish (ES) and bilingual Italian (IT) applications. Our bilingual models demonstrate strong English code-mixing capability. In particular, the bilingual IT model improves the word error rate (WER) for a code-mix IT task from 46.5% to 13.8%, while also achieving a close parity (9.6%) with the monolingual IT model (9.5%) over IT tests.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种双语解决方案，以英语为次要地区的hybrid自动语音识别（ASR）设置中支持英语。我们的关键发展包括：（a）使用字母单位而不是语音单位的发音词典，（b）完全双语对应模型和随后的双语流Transformer模型，（c）并行编码结构和语言标识（LID）损失，（d）并行编码器和辅助损失 для单语投影。我们认为，相比LID损失，我们提posed的辅助损失可以更好地特化并行编码器到各自的单语本地，从而为双语学习带来更强的特点。我们对大规模训练和测试任务进行了两种双语西班牙（ES）和双语意大利（IT）应用。我们的双语模型在英语混合代码 Task中显示出了强大的英语混合能力。特别是，双语IT模型将IT任务中的代码混合WER从46.5%降低至13.8%，同时也与单语IT模型（9.5%）在IT测试任务上达到了近似的水平（9.6%）。
</details></li>
</ul>
<hr>
<h2 id="Self-Alignment-with-Instruction-Backtranslation"><a href="#Self-Alignment-with-Instruction-Backtranslation" class="headerlink" title="Self-Alignment with Instruction Backtranslation"></a>Self-Alignment with Instruction Backtranslation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06259">http://arxiv.org/abs/2308.06259</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Spico197/Humback">https://github.com/Spico197/Humback</a></li>
<li>paper_authors: Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy, Jason Weston, Mike Lewis</li>
<li>for: 这个论文是为了提高语言模型的质量而写的（improve the quality of language models）。</li>
<li>methods: 这个论文使用自动生成的指令Prompt来自我增强语言模型（instruction backtranslation）。</li>
<li>results: 这个论文的方法可以高效地自我增强语言模型，并且在Alpaca领导者榜单上表现更好于所有不使用热静质量数据的LLaMa模型（outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data）。<details>
<summary>Abstract</summary>
We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then selecting high quality examples from among these candidates (self-curation). This data is then used to finetune a stronger model. Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment.
</details>
<details>
<summary>摘要</summary>
我们提出了一种可扩展的方法，用于建立高质量的指令遵循语言模型，通过自动将人工写好的文本标记为相应的指令。我们的方法名为指令反翻译。我们的方法开始于一个基于小量种子数据的语言模型，并使用给定的网络资料。这个种子模型用于生成指令提示文本（自我扩充），然后选择高质量的示例从中间（自我审核）。这些数据然后用于训练更强的模型。两轮我们的方法训练后，我们的模型在不使用热静质料的情况下在Alpaca排行榜上表现最佳， demonstarting highly effective self-alignment。
</details></li>
</ul>
<hr>
<h2 id="KETM-A-Knowledge-Enhanced-Text-Matching-method"><a href="#KETM-A-Knowledge-Enhanced-Text-Matching-method" class="headerlink" title="KETM:A Knowledge-Enhanced Text Matching method"></a>KETM:A Knowledge-Enhanced Text Matching method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06235">http://arxiv.org/abs/2308.06235</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/1094701018/ketm">https://github.com/1094701018/ketm</a></li>
<li>paper_authors: Kexin Jiang, Yahui Zhao, Guozhe Jin, Zhenguo Zhang, Rongyi Cui</li>
<li>for: 这个论文是为了提高文本匹配 task 的性能，通过增强模型理解和逻辑能力。</li>
<li>methods: 该模型使用 Wiktionary  retrieve 文本单词定义作为外部知识，并通过多angle pooling 提取文本和知识的特征向量。然后，通过权重门限机制将文本和知识进行权重 fusión，以提高模型的理解和逻辑能力。</li>
<li>results: 在四个 datasets 上进行了实验验证，结果显示，该模型在所有四个 datasets 上都表现良好，并且与不添加外部知识的基本模型相比，该模型的性能有所提高，这证明了该模型的有效性。<details>
<summary>Abstract</summary>
Text matching is the task of matching two texts and determining the relationship between them, which has extensive applications in natural language processing tasks such as reading comprehension, and Question-Answering systems. The mainstream approach is to compute text representations or to interact with the text through attention mechanism, which is effective in text matching tasks. However, the performance of these models is insufficient for texts that require commonsense knowledge-based reasoning. To this end, in this paper, We introduce a new model for text matching called the Knowledge Enhanced Text Matching model (KETM), to enrich contextual representations with real-world common-sense knowledge from external knowledge sources to enhance our model understanding and reasoning. First, we use Wiktionary to retrieve the text word definitions as our external knowledge. Secondly, we feed text and knowledge to the text matching module to extract their feature vectors. The text matching module is used as an interaction module by integrating the encoder layer, the co-attention layer, and the aggregation layer. Specifically, the interaction process is iterated several times to obtain in-depth interaction information and extract the feature vectors of text and knowledge by multi-angle pooling. Then, we fuse text and knowledge using a gating mechanism to learn the ratio of text and knowledge fusion by a neural network that prevents noise generated by knowledge. After that, experimental validation on four datasets are carried out, and the experimental results show that our proposed model performs well on all four datasets, and the performance of our method is improved compared to the base model without adding external knowledge, which validates the effectiveness of our proposed method. The code is available at https://github.com/1094701018/KETM
</details>
<details>
<summary>摘要</summary>
文本匹配是自然语言处理任务中的一项重要任务，它有广泛的应用于阅读理解和问答系统等领域。主流方法是计算文本表示或通过注意力机制与文本进行交互，这些模型在文本匹配任务中表现良好。然而，这些模型在需要通过常识知ledge来解释的文本匹配任务时表现不够。为此，我们在这篇论文中提出了一种新的文本匹配模型，即知识增强文本匹配模型（KETM），以增强我们的模型理解和解释能力。首先，我们使用Wiktionary来提取文本单词定义作为我们的外部知识。然后，我们将文本和知识传递给文本匹配模块，以提取它们的特征向量。文本匹配模块被用作交互模块，并组合了编码层、相关层和聚合层。具体来说，交互过程会多次迭代，以获取深入的交互信息，并使用多角度聚合来提取文本和知识的特征向量。然后，我们使用阻块机制来融合文本和知识，以学习文本和知识的权重比例。最后，我们对四个数据集进行了实验验证，结果表明，我们提出的方法在所有四个数据集上表现出色，并且与基本模型相比，我们的方法性能有所提高，这 validate了我们的方法的有效性。代码可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="A-Large-Language-Model-Enhanced-Conversational-Recommender-System"><a href="#A-Large-Language-Model-Enhanced-Conversational-Recommender-System" class="headerlink" title="A Large Language Model Enhanced Conversational Recommender System"></a>A Large Language Model Enhanced Conversational Recommender System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06212">http://arxiv.org/abs/2308.06212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Feng, Shuchang Liu, Zhenghai Xue, Qingpeng Cai, Lantao Hu, Peng Jiang, Kun Gai, Fei Sun</li>
<li>for: 提高会话式推荐系统的效果（improve the effectiveness of conversational recommender systems）</li>
<li>methods: 利用大语言模型（Large Language Models, LLM）的理解和生成能力，并与专家模型（expert models）合作，以解决不同的子任务（sub-tasks）。</li>
<li>results: 实验结果表明，使用RLPF进行精心调整LLM，可以提高会话式推荐系统的性能（performance）。<details>
<summary>Abstract</summary>
Conversational recommender systems (CRSs) aim to recommend high-quality items to users through a dialogue interface. It usually contains multiple sub-tasks, such as user preference elicitation, recommendation, explanation, and item information search. To develop effective CRSs, there are some challenges: 1) how to properly manage sub-tasks; 2) how to effectively solve different sub-tasks; and 3) how to correctly generate responses that interact with users. Recently, Large Language Models (LLMs) have exhibited an unprecedented ability to reason and generate, presenting a new opportunity to develop more powerful CRSs. In this work, we propose a new LLM-based CRS, referred to as LLMCRS, to address the above challenges. For sub-task management, we leverage the reasoning ability of LLM to effectively manage sub-task. For sub-task solving, we collaborate LLM with expert models of different sub-tasks to achieve the enhanced performance. For response generation, we utilize the generation ability of LLM as a language interface to better interact with users. Specifically, LLMCRS divides the workflow into four stages: sub-task detection, model matching, sub-task execution, and response generation. LLMCRS also designs schema-based instruction, demonstration-based instruction, dynamic sub-task and model matching, and summary-based generation to instruct LLM to generate desired results in the workflow. Finally, to adapt LLM to conversational recommendations, we also propose to fine-tune LLM with reinforcement learning from CRSs performance feedback, referred to as RLPF. Experimental results on benchmark datasets show that LLMCRS with RLPF outperforms the existing methods.
</details>
<details>
<summary>摘要</summary>
文本： conversational recommender systems (CRSs) 目的是为用户提供高质量的ITEM通过对话界面。它通常包含多个子任务，例如用户偏好描述、推荐、解释和ITEM信息搜索。为开发有效的CRS，存在一些挑战：1）如何正确地管理子任务；2）如何有效地解决不同的子任务；和3）如何正确地生成与用户交互的响应。现在，大型自然语言模型（LLM）在理解和生成方面表现出了无 precedent的能力，这提供了一个新的机会，以开发更有力的CRS。在这项工作中，我们提出了一种基于LLM的CRS，称之为LLMCRS，以解决以下挑战。LLMCRS分为四个阶段：子任务检测、模型匹配、子任务执行和响应生成。LLMCRS还实现了 schema-based instruction、demonstration-based instruction、动态子任务和模型匹配以及摘要生成，以使LLM生成愿望的结果。最后，为适应对话推荐，我们还提出了使用强化学习来调整LLM的性能反馈，称之为RLPF。实验结果表明，LLMCRS与RLPF比现有方法高效。Here's the translation:文本： conversational recommender systems (CRSs) 目的是为用户提供高质量的ITEM通过对话界面。它通常包含多个子任务，例如用户偏好描述、推荐、解释和ITEM信息搜索。为开发有效的CRS，存在一些挑战：1）如何正确地管理子任务；2）如何有效地解决不同的子任务；和3）如何正确地生成与用户交互的响应。现在，大型自然语言模型（LLM）在理解和生成方面表现出了无 precedent的能力，这提供了一个新的机会，以开发更有力的CRS。在这项工作中，我们提出了一种基于LLM的CRS，称之为LLMCRS，以解决以下挑战。LLMCRS分为四个阶段：子任务检测、模型匹配、子任务执行和响应生成。LLMCRS还实现了 schema-based instruction、demonstration-based instruction、动态子任务和模型匹配以及摘要生成，以使LLM生成愿望的结果。最后，为适应对话推荐，我们还提出了使用强化学习来调整LLM的性能反馈，称之为RLPF。实验结果表明，LLMCRS与RLPF比现有方法高效。
</details></li>
</ul>
<hr>
<h2 id="Thinking-Like-an-Expert-Multimodal-Hypergraph-of-Thought-HoT-Reasoning-to-boost-Foundation-Modals"><a href="#Thinking-Like-an-Expert-Multimodal-Hypergraph-of-Thought-HoT-Reasoning-to-boost-Foundation-Modals" class="headerlink" title="Thinking Like an Expert:Multimodal Hypergraph-of-Thought (HoT) Reasoning to boost Foundation Modals"></a>Thinking Like an Expert:Multimodal Hypergraph-of-Thought (HoT) Reasoning to boost Foundation Modals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06207">http://arxiv.org/abs/2308.06207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fanglong Yao, Changyuan Tian, Jintao Liu, Zequn Zhang, Qing Liu, Li Jin, Shuchao Li, Xiaoyu Li, Xian Sun<br>for: This paper aims to enhance the reasoning ability of foundation models by proposing a multimodal Hypergraph-of-Thought (HoT) reasoning paradigm, which can handle high-order multi-hop reasoning and multimodal comparative judgement.methods: The proposed HoT reasoning paradigm utilizes a textual hypergraph-of-thought and a visual hypergraph-of-thought, along with Cross-modal Co-Attention Graph Learning for multimodal comparative verification.results: Experimentations on the ScienceQA benchmark show that the proposed HoT-based T5 outperforms CoT-based GPT3.5 and chatGPT, and is on par with CoT-based GPT4 with a lower model size.<details>
<summary>Abstract</summary>
Reasoning ability is one of the most crucial capabilities of a foundation model, signifying its capacity to address complex reasoning tasks. Chain-of-Thought (CoT) technique is widely regarded as one of the effective methods for enhancing the reasoning ability of foundation models and has garnered significant attention. However, the reasoning process of CoT is linear, step-by-step, similar to personal logical reasoning, suitable for solving general and slightly complicated problems. On the contrary, the thinking pattern of an expert owns two prominent characteristics that cannot be handled appropriately in CoT, i.e., high-order multi-hop reasoning and multimodal comparative judgement. Therefore, the core motivation of this paper is transcending CoT to construct a reasoning paradigm that can think like an expert. The hyperedge of a hypergraph could connect various vertices, making it naturally suitable for modelling high-order relationships. Inspired by this, this paper innovatively proposes a multimodal Hypergraph-of-Thought (HoT) reasoning paradigm, which enables the foundation models to possess the expert-level ability of high-order multi-hop reasoning and multimodal comparative judgement. Specifically, a textual hypergraph-of-thought is constructed utilizing triple as the primary thought to model higher-order relationships, and a hyperedge-of-thought is generated through multi-hop walking paths to achieve multi-hop inference. Furthermore, we devise a visual hypergraph-of-thought to interact with the textual hypergraph-of-thought via Cross-modal Co-Attention Graph Learning for multimodal comparative verification. Experimentations on the ScienceQA benchmark demonstrate the proposed HoT-based T5 outperforms CoT-based GPT3.5 and chatGPT, which is on par with CoT-based GPT4 with a lower model size.
</details>
<details>
<summary>摘要</summary>
基本模型的逻辑能力是其最重要的能力之一，表明其能够解决复杂的逻辑任务。链条思维（CoT）技术是提高基本模型的逻辑能力的有效方法，吸引了广泛的关注。然而，CoT的逻辑过程是线性的，步骤式的，类似于个人的逻辑思维，适用于解决一般和些许复杂的问题。然而，专家的思维模式具有两个突出的特征，不能由CoT处理得好，即高阶多跳 reasoning和多模态比较判断。因此，本文的核心动机是超越CoT，建立一种能够思考如专家的逻辑模型。基于hypergraph的Hypergraph-of-Thought（HoT）逻辑模型是这种思考的核心。在这种模型中，hyperedge可以连接多个顶点，使其自然地适用于高阶关系的模elling。从这个意义上，本文创新地提出了一种多模态HoT逻辑模型，使基本模型具有专家水平的高阶多跳 reasoning和多模态比较判断能力。具体来说，通过 triple作为主要思想来模型高阶关系，并通过多跳步行路径生成多跳推理。此外，我们还提出了跨模态的Co-Attention图学习来实现多模态比较验证。实验结果表明，基于HoT的T5超过了CoT-based GPT3.5和chatGPT，与CoT-based GPT4的性能相似，但模型规模较小。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.CL_2023_08_12/" data-id="cloq1wl2c009g7o88boh33duk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/cs.LG_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T10:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/cs.LG_2023_08_12/">cs.LG - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CoverNav-Cover-Following-Navigation-Planning-in-Unstructured-Outdoor-Environment-with-Deep-Reinforcement-Learning"><a href="#CoverNav-Cover-Following-Navigation-Planning-in-Unstructured-Outdoor-Environment-with-Deep-Reinforcement-Learning" class="headerlink" title="CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning"></a>CoverNav: Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06594">http://arxiv.org/abs/2308.06594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jumman Hossain, Abu-Zaher Faridee, Nirmalya Roy, Anjan Basak, Derrik E. Asher</li>
<li>for: 这 paper 的目的是提出一种基于 Deep Reinforcement Learning (DRL) 算法，用于在 offroad 环境中避免被外部观察者发现，并在有观察者存在的情况下安全地前往预定的目的地。</li>
<li>methods: 该算法使用了一个本地成本地图，以帮助选择最佳的遮盾和低成本路径，并使用了3D 点云数据、机器人的位置和指定目标信息来计算本地成本地图。</li>
<li>results: CoverNav 在 Unity  simulate 环境中被评估，并显示了在 terrain 中保持动态可行性的能力，并在不同的高度enario 中实现了最大的目标距离和成功率。<details>
<summary>Abstract</summary>
Autonomous navigation in offroad environments has been extensively studied in the robotics field. However, navigation in covert situations where an autonomous vehicle needs to remain hidden from outside observers remains an underexplored area. In this paper, we propose a novel Deep Reinforcement Learning (DRL) based algorithm, called CoverNav, for identifying covert and navigable trajectories with minimal cost in offroad terrains and jungle environments in the presence of observers. CoverNav focuses on unmanned ground vehicles seeking shelters and taking covers while safely navigating to a predefined destination. Our proposed DRL method computes a local cost map that helps distinguish which path will grant the maximal covertness while maintaining a low cost trajectory using an elevation map generated from 3D point cloud data, the robot's pose, and directed goal information. CoverNav helps robot agents to learn the low elevation terrain using a reward function while penalizing it proportionately when it experiences high elevation. If an observer is spotted, CoverNav enables the robot to select natural obstacles (e.g., rocks, houses, disabled vehicles, trees, etc.) and use them as shelters to hide behind. We evaluate CoverNav using the Unity simulation environment and show that it guarantees dynamically feasible velocities in the terrain when fed with an elevation map generated by another DRL based navigation algorithm. Additionally, we evaluate CoverNav's effectiveness in achieving a maximum goal distance of 12 meters and its success rate in different elevation scenarios with and without cover objects. We observe competitive performance comparable to state of the art (SOTA) methods without compromising accuracy.
</details>
<details>
<summary>摘要</summary>
自主导航在非道路环境中已经得到了RoboticsField的广泛研究。然而，在保持外部观察者隐私的情况下，自主导航仍然是一个未得到充分探索的领域。在这篇论文中，我们提出了一种基于深度优化学习（DRL）算法，称为CoverNav，用于在非道路地形和热带环境中寻找最佳隐蔽和可行的路径，并在外部观察者存在的情况下保持最佳的隐蔽性。CoverNav的设计目标是让无人地面车辆在保持安全的情况下寻找遮盾和避险的方式，并最终达到预定的目标地点。我们提出的DRL方法计算了当地的成本图，以帮助分辨出最佳隐蔽路径，同时保持低成本 trajectory使用3D点云数据、机器人的姿态和指定目标信息。CoverNav帮助机器人代理人学习低高度地形，通过一个奖励函数，同时对高高度增加惩罚。如果检测到观察者，CoverNav允许机器人选择自然障碍物（如岩石、房屋、瘫痪车辆、树木等），并使用它们作为遮盾隐藏。我们使用Unity simulate环境进行评估，并证明CoverNav可以在地形中保持动态可行速度。此外，我们还评估了CoverNav在不同高度场景中的效果和成功率，并发现其与状态之最好的方法（SOTA）的性能相似，无需损失精度。
</details></li>
</ul>
<hr>
<h2 id="Value-Distributional-Model-Based-Reinforcement-Learning"><a href="#Value-Distributional-Model-Based-Reinforcement-Learning" class="headerlink" title="Value-Distributional Model-Based Reinforcement Learning"></a>Value-Distributional Model-Based Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06590">http://arxiv.org/abs/2308.06590</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Carlos E. Luis, Alessandro G. Bottero, Julia Vinogradska, Felix Berkenkamp, Jan Peters</li>
<li>for: 本研究旨在解决Sequential Decision-Making任务中的不确定性问题，通过基于搜索学习的模型based Bayesian reinforcement learning的角度来评估政策的长期表现。</li>
<li>methods: 本研究使用了分布式权值函数的思想，通过引入Bellman операktor的固定点来学习值函数的 posterior distribution。</li>
<li>results: 对多个连续控制任务的评估表明，EQR算法可以比以前的模型基于和模型自由算法表现更好，具有性能优势。<details>
<summary>Abstract</summary>
Quantifying uncertainty about a policy's long-term performance is important to solve sequential decision-making tasks. We study the problem from a model-based Bayesian reinforcement learning perspective, where the goal is to learn the posterior distribution over value functions induced by parameter (epistemic) uncertainty of the Markov decision process. Previous work restricts the analysis to a few moments of the distribution over values or imposes a particular distribution shape, e.g., Gaussians. Inspired by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function. Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. Evaluation across several continuous-control tasks shows performance benefits with respect to established model-based and model-free algorithms.
</details>
<details>
<summary>摘要</summary>
Important 是量化一个政策的长期表现uncertainty，解决sequential decision-making tasks。我们从model-based Bayesian reinforcement learning的角度研究这个问题，目标是学习Markov decision process中参数（epistemic）uncertainty引起的值函数 posterior distribution。前一任 restricts the analysis to a few moments of the distribution over values or imposes a particular distribution shape, e.g., Gaussians。drawing inspiration from distributional reinforcement learning，我们引入一个Bellman operator，其fixed-point是值分布函数。根据我们的理论，我们提出Epistemic Quantile-Regression（EQR），一种model-based算法，可以学习一个可以用于政策优化的值分布函数。在许多连续控制任务上，我们的算法表现出了与已知model-based和model-free算法相比的性能优势。
</details></li>
</ul>
<hr>
<h2 id="Approximate-Answering-of-Graph-Queries"><a href="#Approximate-Answering-of-Graph-Queries" class="headerlink" title="Approximate Answering of Graph Queries"></a>Approximate Answering of Graph Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06585">http://arxiv.org/abs/2308.06585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Cochez, Dimitrios Alivanistos, Erik Arakelyan, Max Berrendorf, Daniel Daza, Mikhail Galkin, Pasquale Minervini, Mathias Niepert, Hongyu Ren</li>
<li>for:  Answering queries in an incomplete knowledge graph (KG) setting.</li>
<li>methods: Several methods have been proposed to answer queries in an incomplete KG setting, including approaches based on semantic search, knowledge graph completion, and embedding-based methods.</li>
<li>results: These methods have been shown to be effective in answering queries in an incomplete KG setting, but they have limitations in terms of expressiveness, supported graph types, and inference capabilities.Here is the same information in Simplified Chinese text:</li>
<li>for:  Answering queries in an incomplete知识图(KG) setting.</li>
<li>methods:  Several methods have been proposed to answer queries in an incomplete KG setting, including基于semantic search的方法、knowledge graph completion的方法和embedding-based methods.</li>
<li>results:  These methods have been shown to be effective in answering queries in an incomplete KG setting, but they have limitations in terms of expressiveness、supported graph types和inference capabilities.<details>
<summary>Abstract</summary>
Knowledge graphs (KGs) are inherently incomplete because of incomplete world knowledge and bias in what is the input to the KG. Additionally, world knowledge constantly expands and evolves, making existing facts deprecated or introducing new ones. However, we would still want to be able to answer queries as if the graph were complete. In this chapter, we will give an overview of several methods which have been proposed to answer queries in such a setting. We will first provide an overview of the different query types which can be supported by these methods and datasets typically used for evaluation, as well as an insight into their limitations. Then, we give an overview of the different approaches and describe them in terms of expressiveness, supported graph types, and inference capabilities.
</details>
<details>
<summary>摘要</summary>
知识图（KG）自然而然 incomplete，因为世界知识不完整和输入KG中的偏见。然而，我们仍然想能够回答尚未完善的查询。在这章中，我们将给出几种提出来的方法，以及它们在支持不同类型的查询和评估 datasets 的限制。然后，我们将对这些方法进行概述，包括它们在表达力、支持的图类型和推理能力方面的特点。Here's the breakdown of the text into Simplified Chinese characters:知识图 (KG) 自然而然 incomplete 因为世界知识不完整和输入 KG 中的偏见。然而，我们仍然想能够回答尚未完善的查询。在这章中，我们将给出几种提出来的方法，以及它们在支持不同类型的查询和评估 datasets 的限制。然后，我们将对这些方法进行概述，包括它们在表达力、支持的图类型和推理能力方面的特点。
</details></li>
</ul>
<hr>
<h2 id="A-new-solution-and-concrete-implementation-steps-for-Artificial-General-Intelligence"><a href="#A-new-solution-and-concrete-implementation-steps-for-Artificial-General-Intelligence" class="headerlink" title="A new solution and concrete implementation steps for Artificial General Intelligence"></a>A new solution and concrete implementation steps for Artificial General Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09721">http://arxiv.org/abs/2308.09721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongcong Chen, Ting Zeng, Jun Zhang</li>
<li>for: 这个论文目标是解决现有技术的缺陷，以实现更广泛的人工智能应用。</li>
<li>methods: 该论文使用现有技术和解决现有技术的缺陷，以实现更广泛的人工智能应用。</li>
<li>results: 该论文提出了解决现有技术的缺陷，以实现更广泛的人工智能应用的方法。<details>
<summary>Abstract</summary>
At present, the mainstream artificial intelligence generally adopts the technical path of "attention mechanism + deep learning" + "reinforcement learning". It has made great progress in the field of AIGC (Artificial Intelligence Generated Content), setting off the technical wave of big models[ 2][13 ]. But in areas that need to interact with the actual environment, such as elderly care, home nanny, agricultural production, and vehicle driving, trial and error are expensive and a reinforcement learning process that requires much trial and error is difficult to achieve. Therefore, in order to achieve Artificial General Intelligence(AGI) that can be applied to any field, we need to use both existing technologies and solve the defects of existing technologies, so as to further develop the technological wave of artificial intelligence. In this paper, we analyze the limitations of the technical route of large models, and by addressing these limitations, we propose solutions, thus solving the inherent defects of large models. In this paper, we will reveal how to achieve true AGI step by step.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:现在，主流人工智能通常采用“注意机制+深度学习”+“强化学习”技术路线。这种方法在AIGC（人工智能生成内容）领域已经取得了 significativadeeps[ 2][13 ]， triggering a technological wave of big models. However, in areas that require interaction with the actual environment, such as elderly care, home nanny, agricultural production, and vehicle driving, trial and error are costly and a reinforcement learning process that requires much trial and error is difficult to achieve. Therefore, to achieve Artificial General Intelligence (AGI) that can be applied to any field, we need to leverage both existing technologies and address the limitations of existing technologies, in order to further develop the technological wave of artificial intelligence. In this paper, we analyze the limitations of the technical route of large models, and by addressing these limitations, we propose solutions, thus solving the inherent defects of large models. Through this paper, we will reveal how to achieve true AGI step by step.
</details></li>
</ul>
<hr>
<h2 id="EquiDiff-A-Conditional-Equivariant-Diffusion-Model-For-Trajectory-Prediction"><a href="#EquiDiff-A-Conditional-Equivariant-Diffusion-Model-For-Trajectory-Prediction" class="headerlink" title="EquiDiff: A Conditional Equivariant Diffusion Model For Trajectory Prediction"></a>EquiDiff: A Conditional Equivariant Diffusion Model For Trajectory Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06564">http://arxiv.org/abs/2308.06564</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kehua Chen, Xianda Chen, Zihan Yu, Meixin Zhu, Hai Yang</li>
<li>for: 预测自动驾驶车辆的未来路径，以确保安全和有效的运行。</li>
<li>methods: 使用深度学习的各种方法，包括权重排序网络和强化学习，以及基于 conditional diffusion model 的 EquiDiff 模型，通过 integrate 历史信息和随机 Gaussian 噪声来预测未来路径。</li>
<li>results: EquiDiff 模型在 NGSIM 数据集上的实验结果表明，在短期预测方面表现出色，但在长期预测方面有些较高的错误率。此外，我们还进行了一项ablation 研究，以Investigate 各组件对预测精度的贡献。同时，我们还提供了 diffusion 模型生成过程的视觉化，以提供预测结果的不确定性的视觉化。<details>
<summary>Abstract</summary>
Accurate trajectory prediction is crucial for the safe and efficient operation of autonomous vehicles. The growing popularity of deep learning has led to the development of numerous methods for trajectory prediction. While deterministic deep learning models have been widely used, deep generative models have gained popularity as they learn data distributions from training data and account for trajectory uncertainties. In this study, we propose EquiDiff, a deep generative model for predicting future vehicle trajectories. EquiDiff is based on the conditional diffusion model, which generates future trajectories by incorporating historical information and random Gaussian noise. The backbone model of EquiDiff is an SO(2)-equivariant transformer that fully utilizes the geometric properties of location coordinates. In addition, we employ Recurrent Neural Networks and Graph Attention Networks to extract social interactions from historical trajectories. To evaluate the performance of EquiDiff, we conduct extensive experiments on the NGSIM dataset. Our results demonstrate that EquiDiff outperforms other baseline models in short-term prediction, but has slightly higher errors for long-term prediction. Furthermore, we conduct an ablation study to investigate the contribution of each component of EquiDiff to the prediction accuracy. Additionally, we present a visualization of the generation process of our diffusion model, providing insights into the uncertainty of the prediction.
</details>
<details>
<summary>摘要</summary>
准确的轨迹预测是自动驾驶车辆运行的关键。随着深度学习的普及，许多方法已经被开发出来用于轨迹预测。而使用权值函数的决定性深度学习模型在轨迹预测中广泛应用。在本研究中，我们提出了EquiDiff，一种基于条件扩散模型的深度生成模型，用于预测未来车辆的轨迹。EquiDiff通过将历史信息和随机 Gaussian 噪声纳入条件扩散模型，生成未来车辆的轨迹。我们的核心模型是一个SO(2)-共轭变换器，它完全利用了坐标点的几何属性。此外，我们还使用循环神经网络和图注意网络来提取历史轨迹中的社会互动。为了评估EquiDiff的性能，我们在NGSIM数据集上进行了广泛的实验。我们的结果显示，EquiDiff在短期预测方面胜过其他基准模型，但在长期预测方面有些微的错误。此外，我们还进行了减少分析，以了解各组件对预测精度的贡献。此外，我们还提供了生成过程中扩散模型的视觉化，为预测不确定性提供了更多的视角。
</details></li>
</ul>
<hr>
<h2 id="Human-Behavior-based-Personalized-Meal-Recommendation-and-Menu-Planning-Social-System"><a href="#Human-Behavior-based-Personalized-Meal-Recommendation-and-Menu-Planning-Social-System" class="headerlink" title="Human Behavior-based Personalized Meal Recommendation and Menu Planning Social System"></a>Human Behavior-based Personalized Meal Recommendation and Menu Planning Social System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06549">http://arxiv.org/abs/2308.06549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanvir Islam, Anika Rahman Joyita, Md. Golam Rabiul Alam, Mohammad Mehedi Hassan, Md. Rafiul Hassan, Raffaele Gravina</li>
<li>for: 这个研究旨在提供一种基于情感计算的餐单推荐和菜单规划方法，以满足用户不同情感的需求。</li>
<li>methods: 该研究使用了问卷调查和偏好认知来确定用户的餐食偏好，并使用电encephalography信号来检测用户对不同食物的情感。在这个研究中，我们使用了14栽 wireless Emotive Epoc+来测量用户对不同食物的情感。</li>
<li>results: 实验结果表明，该提议的情感计算、餐单推荐和菜单规划算法在多种评价参数上表现良好。<details>
<summary>Abstract</summary>
The traditional dietary recommendation systems are basically nutrition or health-aware where the human feelings on food are ignored. Human affects vary when it comes to food cravings, and not all foods are appealing in all moods. A questionnaire-based and preference-aware meal recommendation system can be a solution. However, automated recognition of social affects on different foods and planning the menu considering nutritional demand and social-affect has some significant benefits of the questionnaire-based and preference-aware meal recommendations. A patient with severe illness, a person in a coma, or patients with locked-in syndrome and amyotrophic lateral sclerosis (ALS) cannot express their meal preferences. Therefore, the proposed framework includes a social-affective computing module to recognize the affects of different meals where the person's affect is detected using electroencephalography signals. EEG allows to capture the brain signals and analyze them to anticipate affective toward a food. In this study, we have used a 14-channel wireless Emotive Epoc+ to measure affectivity for different food items. A hierarchical ensemble method is applied to predict affectivity upon multiple feature extraction methods and TOPSIS (Technique for Order of Preference by Similarity to Ideal Solution) is used to generate a food list based on the predicted affectivity. In addition to the meal recommendation, an automated menu planning approach is also proposed considering a person's energy intake requirement, affectivity, and nutritional values of the different menus. The bin-packing algorithm is used for the personalized menu planning of breakfast, lunch, dinner, and snacks. The experimental findings reveal that the suggested affective computing, meal recommendation, and menu planning algorithms perform well across a variety of assessment parameters.
</details>
<details>
<summary>摘要</summary>
传统的饮食建议系统基本上是nutrition或健康意识的，忽略了人类情感对食物的影响。人们对食物的欲望和喜好可以在不同的情感状态下发生变化，问卷和喜好意识的饭菜推荐系统可能是一个解决方案。然而，自动地认知社会情感对不同食物的影响，并根据营养需求和社会情感规划菜单，有一些显著的优点。例如，患有严重疾病、昏迷状态或locked-in syndrome和amyotrophic lateral sclerosis（ALS）患者无法表达他们的饭菜偏好。因此，我们的框架包括一个社交情感计算模块，用于识别不同饭菜中的情感。我们使用14栏 wireless Emotive Epoc+来测量不同饭品的情感响应。我们采用了层次ensemble方法来预测情感，并使用TOPSIS（理想解决方案的技术）来生成基于预测情感的饭品列表。此外，我们还提出了一种自动菜单规划方法，考虑人类能量摄入需求、情感和不同菜单的营养价值。使用bin-packing算法进行个性化菜单规划的早餐、午餐、晚餐和小吃。实验结果表明，我们提出的情感计算、饭菜推荐和菜单规划算法在多种评价参数上表现良好。
</details></li>
</ul>
<hr>
<h2 id="Digital-elevation-model-correction-in-urban-areas-using-extreme-gradient-boosting-land-cover-and-terrain-parameters"><a href="#Digital-elevation-model-correction-in-urban-areas-using-extreme-gradient-boosting-land-cover-and-terrain-parameters" class="headerlink" title="Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters"></a>Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06545">http://arxiv.org/abs/2308.06545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chukwuma Okolie, Jon Mills, Adedayo Adeleke, Julian Smit</li>
<li>for: This paper aims to enhance the accuracy of medium-resolution digital elevation models (DEMs) in urban areas using the extreme gradient boosting (XGBoost) ensemble algorithm.</li>
<li>methods: The XGBoost algorithm was applied to two medium-resolution DEMs over Cape Town, South Africa, using eleven predictor variables, including elevation, urban footprints, and terrain features.</li>
<li>results: The correction achieved significant accuracy gains, with the root mean square error (RMSE) of the DEMs improving by 46-53% and 72-73%, respectively, compared to other proposed methods. These results demonstrate the potential of gradient boosted trees for enhancing the quality of DEMs and improving hydrological modelling in urban catchments.Here is the same information in Simplified Chinese text:</li>
<li>for: 本研究目的是使用极限梯度加权树（XGBoost）ensemble算法提高城市区域中数字高程模型（DEMs）的精度。</li>
<li>methods: XGBoost算法应用于两个中Resolution DEMs上cape Town,南非，使用eleven predictor variable，包括高程、城市脚本、地形特征等。</li>
<li>results: 修正得到了显著的准确性提高，高程误差根mean square error（RMSE）提高46-53%和72-73%，相比其他提议的方法。这些结果表明梯度加权树可以提高DEMs的质量和城市流域 hydrological modelling中的准确性。<details>
<summary>Abstract</summary>
The accuracy of digital elevation models (DEMs) in urban areas is influenced by numerous factors including land cover and terrain irregularities. Moreover, building artifacts in global DEMs cause artificial blocking of surface flow pathways. This compromises their quality and adequacy for hydrological and environmental modelling in urban landscapes where precise and accurate terrain information is needed. In this study, the extreme gradient boosting (XGBoost) ensemble algorithm is adopted for enhancing the accuracy of two medium-resolution 30m DEMs over Cape Town, South Africa: Copernicus GLO-30 and ALOS World 3D (AW3D). XGBoost is a scalable, portable and versatile gradient boosting library that can solve many environmental modelling problems. The training datasets are comprised of eleven predictor variables including elevation, urban footprints, slope, aspect, surface roughness, topographic position index, terrain ruggedness index, terrain surface texture, vector roughness measure, forest cover and bare ground cover. The target variable (elevation error) was calculated with respect to highly accurate airborne LiDAR. After training and testing, the model was applied for correcting the DEMs at two implementation sites. The correction achieved significant accuracy gains which are competitive with other proposed methods. The root mean square error (RMSE) of Copernicus DEM improved by 46 to 53% while the RMSE of AW3D DEM improved by 72 to 73%. These results showcase the potential of gradient boosted trees for enhancing the quality of DEMs, and for improved hydrological modelling in urban catchments.
</details>
<details>
<summary>摘要</summary>
“城市地区数字高程模型（DEM）的准确性受多种因素影响，包括地面覆盖和地形差异。此外，全球DEM中的建筑物artefact会导致 superficiale流动的人工堵塞，从而下降其质量和适用性于城市地区的水文和环境模型。本研究采用extrem Gradient Boosting（XGBoost）ensemble算法来提高两个中等分辨率30米DEM的准确性，即Copernicus GLO-30和ALOS World 3D（AW3D）。XGBoost是一种可扩展、可移植和多样的梯度提升库，可以解决许多环境模型问题。训练数据集包括11个预测变量，包括高程、城市覆盖面积、坡度、方向、表面粗糙度、地形位置指数、地形抗 roughness指数、地形表面文字、向量粗糙度度量、森林覆盖率和无 veg 覆盖率。目标变量（高程错误）与高精度飞行 LiDAR 进行计算。经过训练和测试，模型在两个实施地点应用于修正DEM。修正后的DEM准确性提高了46%到53%，而AW3D DEM的准确性提高了72%到73%。这些结果表明梯度增进树可以提高DEM的质量，并且为城市水文模型提供了改进的可能性。”
</details></li>
</ul>
<hr>
<h2 id="Dealing-with-Small-Datasets-for-Deep-Learning-in-Medical-Imaging-An-Evaluation-of-Self-Supervised-Pre-Training-on-CT-Scans-Comparing-Contrastive-and-Masked-Autoencoder-Methods-for-Convolutional-Models"><a href="#Dealing-with-Small-Datasets-for-Deep-Learning-in-Medical-Imaging-An-Evaluation-of-Self-Supervised-Pre-Training-on-CT-Scans-Comparing-Contrastive-and-Masked-Autoencoder-Methods-for-Convolutional-Models" class="headerlink" title="Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models"></a>Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06534">http://arxiv.org/abs/2308.06534</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wolfda95/ssl-medicalimagining-cl-mae">https://github.com/wolfda95/ssl-medicalimagining-cl-mae</a></li>
<li>paper_authors: Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Timo Ropinski, Michael Götz</li>
<li>for: 这篇研究的目的是为了探讨在医疗影像领域中使用深度学习模型，以减少医生负担，提高诊断速度，并最小化诊断错误的风险。</li>
<li>methods: 这篇研究使用了自然语言处理领域的自我超vised学习方法，将深度学习模型训练在大量无标注的医疗影像 dataset 上，然后使用小量标注 dataset 进行精度训练。</li>
<li>results: 研究发现，使用 SparK 自我超vised学习方法可以更好地适应小量标注 dataset，并且在不同的训练 dataset 大小下表现出不同的优势。因此，这篇研究建议在医疗影像领域使用 SparK 自我超vised学习方法，以提高深度学习模型的精度和效率。<details>
<summary>Abstract</summary>
Deep learning in medical imaging has the potential to minimize the risk of diagnostic errors, reduce radiologist workload, and accelerate diagnosis. Training such deep learning models requires large and accurate datasets, with annotations for all training samples. However, in the medical imaging domain, annotated datasets for specific tasks are often small due to the high complexity of annotations, limited access, or the rarity of diseases. To address this challenge, deep learning models can be pre-trained on large image datasets without annotations using methods from the field of self-supervised learning. After pre-training, small annotated datasets are sufficient to fine-tune the models for a specific task. The most popular self-supervised pre-training approaches in medical imaging are based on contrastive learning. However, recent studies in natural image processing indicate a strong potential for masked autoencoder approaches. Our work compares state-of-the-art contrastive learning methods with the recently introduced masked autoencoder approach "SparK" for convolutional neural networks (CNNs) on medical images. Therefore we pre-train on a large unannotated CT image dataset and fine-tune on several CT classification tasks. Due to the challenge of obtaining sufficient annotated training data in medical imaging, it is of particular interest to evaluate how the self-supervised pre-training methods perform when fine-tuning on small datasets. By experimenting with gradually reducing the training dataset size for fine-tuning, we find that the reduction has different effects depending on the type of pre-training chosen. The SparK pre-training method is more robust to the training dataset size than the contrastive methods. Based on our results, we propose the SparK pre-training for medical imaging tasks with only small annotated datasets.
</details>
<details>
<summary>摘要</summary>
深度学习在医疗影像领域可能减少诊断错误的风险，减轻放射学家的工作负担，并加速诊断。深度学习模型的训练需要大量和准确的数据集，并将所有训练样本注解。然而，在医疗影像领域，特定任务的注解数据集经常受到高复杂性的限制，限制了获得可用的数据。为解决这个挑战，深度学习模型可以通过不注解的图像集进行自我超vised学习。在这种情况下，小型注解数据集可以进行精度的微调。我们的工作 comparing state-of-the-art contrastive learning方法和最近引入的"SparK"隐藏自动编码器方法（MAE）在医疗影像领域的 convolutional neural networks（CNNs）中进行比较。因此，我们在大量无注解CT图像集上进行预训练，然后在多个CT分类任务上进行微调。由于在医疗影像领域获得足够的注解训练数据是困难的，因此我们特别关注在小型注解数据集上进行微调时的性能。我们通过逐渐减少微调数据集的大小来评估不同类型的预训练方法的性能。我们发现，使用SparK预训练方法可以更好地抗衡训练数据集的大小。根据我们的结果，我们提议在医疗影像任务中使用SparK预训练方法，即使只有小型注解数据集。
</details></li>
</ul>
<hr>
<h2 id="Learning-Abstract-Visual-Reasoning-via-Task-Decomposition-A-Case-Study-in-Raven-Progressive-Matrices"><a href="#Learning-Abstract-Visual-Reasoning-via-Task-Decomposition-A-Case-Study-in-Raven-Progressive-Matrices" class="headerlink" title="Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices"></a>Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06528">http://arxiv.org/abs/2308.06528</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jakubkwiatkowski/abstract_compositional_transformer">https://github.com/jakubkwiatkowski/abstract_compositional_transformer</a></li>
<li>paper_authors: Jakub Kwiatkowski, Krzysztof Krawiec</li>
<li>for: 本研究旨在提高 Abstract Reasoning 的能力，通过预测图像中对象的视觉属性和排列来解决 Raven Progressive Matrices (RPM) 问题。</li>
<li>methods: 本研究使用 transformer 架构，通过预测图像中对象的视觉属性和排列来解决 RPM 问题。研究还考虑了不同的图像分割方法和自动Masking 技术。</li>
<li>results: 实验结果表明，该方法不仅超越了当前最佳方法，还提供了有趣的思路和部分解释，帮助理解 RPM 问题的决策过程。此外，该方法还具有免除一些已知 RPM 标准准样的偏见的优点。<details>
<summary>Abstract</summary>
One of the challenges in learning to perform abstract reasoning is that problems are often posed as monolithic tasks, with no intermediate subgoals. In Raven Progressive Matrices (RPM), the task is to choose one of the available answers given a context, where both contexts and answers are composite images featuring multiple objects in various spatial arrangements. As this high-level goal is the only guidance available, learning is challenging and most contemporary solvers tend to be opaque. In this study, we propose a deep learning architecture based on the transformer blueprint which, rather than directly making the above choice, predicts the visual properties of individual objects and their arrangements. The multidimensional predictions obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assessment, the models not only outperform state-of-the-art methods but also provide interesting insights and partial explanations about the inference. The design of the method also makes it immune to biases that are known to exist in some RPM benchmarks.
</details>
<details>
<summary>摘要</summary>
一个学习抽象逻辑的挑战是问题frequently pose as monolithic tasks，without intermediate subgoals. In Raven Progressive Matrices (RPM), the task is to choose one of the available answers given a context, where both contexts and answers are composite images featuring multiple objects in various spatial arrangements. As this high-level goal is the only guidance available, learning is challenging and most contemporary solvers tend to be opaque. In this study, we propose a deep learning architecture based on the transformer blueprint, which rather than directly making the above choice, predicts the visual properties of individual objects and their arrangements. The multidimensional predictions obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assessment, the models not only outperform state-of-the-art methods but also provide interesting insights and partial explanations about the inference. The design of the method also makes it immune to biases that are known to exist in some RPM benchmarks.Here is the translation in Traditional Chinese:一个学习抽象逻辑的挑战是问题frequently pose as monolithic tasks，without intermediate subgoals. In Raven Progressive Matrices (RPM), the task is to choose one of the available answers given a context, where both contexts and answers are composite images featuring multiple objects in various spatial arrangements. As this high-level goal is the only guidance available, learning is challenging and most contemporary solvers tend to be opaque. In this study, we propose a deep learning architecture based on the transformer blueprint, which rather than directly making the above choice, predicts the visual properties of individual objects and their arrangements. The multidimensional predictions obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assessment, the models not only outperform state-of-the-art methods but also provide interesting insights and partial explanations about the inference. The design of the method also makes it immune to biases that are known to exist in some RPM benchmarks.
</details></li>
</ul>
<hr>
<h2 id="SLoRA-Federated-Parameter-Efficient-Fine-Tuning-of-Language-Models"><a href="#SLoRA-Federated-Parameter-Efficient-Fine-Tuning-of-Language-Models" class="headerlink" title="SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models"></a>SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06522">http://arxiv.org/abs/2308.06522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Babakniya, Ahmed Roushdy Elkordy, Yahya H. Ezzeldin, Qingfeng Liu, Kee-Bong Song, Mostafa El-Khamy, Salman Avestimehr</li>
<li>for: 这个研究旨在探讨在分布式语言任务中应用精简 parameter fine-tuning（PEFT）方法，以提高 Federated Learning（FL） 的可行性和效率。</li>
<li>methods: 本研究使用了 parameter efficient fine-tuning（PEFT）方法，并提出了一个名为 SLoRA 的新方法，具有跨用户数据的可靠性和高效性。</li>
<li>results: 实验结果显示，SLoRA 可以与全量 fine-tuning 相比，实现高度可 sparse 的更新，并在高 hetrogenous 数据场景下提高了表现。特别是，SLoRA 可以实现 $\sim 1%$ 的紧密更新，并降低了训练时间，高达 $90%$。<details>
<summary>Abstract</summary>
Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data scenarios through a novel data-driven initialization technique. Our experimental results demonstrate that SLoRA achieves performance comparable to full fine-tuning, with significant sparse updates with approximately $\sim 1\%$ density while reducing training time by up to $90\%$.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。</SYS>>基于预训练变换器模型的迁移学习已经在不同的自然语言处理任务中带来了显著的成果，包括语音识别、文本分类、翻译等。在中央数据缺乏的情况下，联邦学习（FL）可以利用分布式和私有的edge客户端数据进行微调。然而，由于edge设备的通信、计算和存储能力的限制，以及流行的变换器模型的大型，高效的微调是必要的以使联邦训练成为可能。这项工作探讨了在不同的FL设置下应用Parameter Efficient Fine-tuning（PEFT）方法的机会和挑战。具体来说，我们的调查发现，当用户数据变得更加多样化时，完全微调和PEFT方法之间的性能差距加大。为 bridging这个性能差距，我们提议了一种名为SLoRA的方法，通过一种新的数据驱动初始化技术，超越LoRA在高多样性数据场景中的关键限制。我们的实验结果表明，SLoRA可以与全部微调达到相同的性能水平，并在大约1%的稀疏更新下降低训练时间约90%。
</details></li>
</ul>
<hr>
<h2 id="One-bit-Flip-is-All-You-Need-When-Bit-flip-Attack-Meets-Model-Training"><a href="#One-bit-Flip-is-All-You-Need-When-Bit-flip-Attack-Meets-Model-Training" class="headerlink" title="One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training"></a>One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07934">http://arxiv.org/abs/2308.07934</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jianshuod/tba">https://github.com/jianshuod/tba</a></li>
<li>paper_authors: Jianshuo Dong, Han Qiu, Yiming Li, Tianwei Zhang, Yuanjie Li, Zeqi Lai, Chao Zhang, Shu-Tao Xia</li>
<li>for: 防御深度神经网络（DNNs）在实际设备上的安全性问题。</li>
<li>methods: 利用记忆FAULT INJECT技术实现行ammer attack，通过修改模型的权重来攻击量化模型在部署阶段。</li>
<li>results: 通过修改一个关键位的bit，可以轻松地将正常模型转化为恶意模型，并且这种攻击还可以绕过一些检测方法。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are widely deployed on real-world devices. Concerns regarding their security have gained great attention from researchers. Recently, a new weight modification attack called bit flip attack (BFA) was proposed, which exploits memory fault inject techniques such as row hammer to attack quantized models in the deployment stage. With only a few bit flips, the target model can be rendered useless as a random guesser or even be implanted with malicious functionalities. In this work, we seek to further reduce the number of bit flips. We propose a training-assisted bit flip attack, in which the adversary is involved in the training stage to build a high-risk model to release. This high-risk model, obtained coupled with a corresponding malicious model, behaves normally and can escape various detection methods. The results on benchmark datasets show that an adversary can easily convert this high-risk but normal model to a malicious one on victim's side by \textbf{flipping only one critical bit} on average in the deployment stage. Moreover, our attack still poses a significant threat even when defenses are employed. The codes for reproducing main experiments are available at \url{https://github.com/jianshuod/TBA}.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在实际设备上广泛应用。关于其安全性的问题吸引了研究者的广泛关注。最近，一种新的权值修改攻击方法called bit flip attack（BFA）被提出，它利用内存错误注入技术such as row hammer攻击部署阶段的量化模型。只需几个比特软件，目标模型就可以变成随机猜测器或甚至被恶意模型植入。在这种工作中，我们尝试降低比特软件的数量。我们提出了帮助者参与训练阶段的训练帮助攻击，以建立一个高风险模型，并将其发布。这个高风险模型，结合相应的恶意模型，在发布阶段 behave normally，并可以逃脱多种检测方法。我们的攻击仍然对于防御措施产生威胁。实验结果表明，一个攻击者可以在部署阶段通过flipping only one critical bit的方式，将高风险模型转换为恶意模型，而且这种攻击仍然有效even when defenses are employed。代码可以在 <https://github.com/jianshuod/TBA> 中进行重现主要实验。
</details></li>
</ul>
<hr>
<h2 id="Performance-Analysis-for-Resource-Constrained-Decentralized-Federated-Learning-Over-Wireless-Networks"><a href="#Performance-Analysis-for-Resource-Constrained-Decentralized-Federated-Learning-Over-Wireless-Networks" class="headerlink" title="Performance Analysis for Resource Constrained Decentralized Federated Learning Over Wireless Networks"></a>Performance Analysis for Resource Constrained Decentralized Federated Learning Over Wireless Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06496">http://arxiv.org/abs/2308.06496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhigang Yan, Dong Li</li>
<li>for: 这个研究旨在分析资源受限的分布式机器学习（DFL）系统中的通信效率优化。</li>
<li>methods: 这个研究使用了不同的通信方案（数位和类比）来分析内部通信效率。</li>
<li>results: 研究发现，这些通信方案可以提供内部模型的训练，并且可以在不同的通信条件下进行优化。<details>
<summary>Abstract</summary>
Federated learning (FL) can lead to significant communication overhead and reliance on a central server. To address these challenges, decentralized federated learning (DFL) has been proposed as a more resilient framework. DFL involves parameter exchange between devices through a wireless network. This study analyzes the performance of resource-constrained DFL using different communication schemes (digital and analog) over wireless networks to optimize communication efficiency. Specifically, we provide convergence bounds for both digital and analog transmission approaches, enabling analysis of the model performance trained on DFL. Furthermore, for digital transmission, we investigate and analyze resource allocation between computation and communication and convergence rates, obtaining its communication complexity and the minimum probability of correction communication required for convergence guarantee. For analog transmission, we discuss the impact of channel fading and noise on the model performance and the maximum errors accumulation with convergence guarantee over fading channels. Finally, we conduct numerical simulations to evaluate the performance and convergence rate of convolutional neural networks (CNNs) and Vision Transformer (ViT) trained in the DFL framework on fashion-MNIST and CIFAR-10 datasets. Our simulation results validate our analysis and discussion, revealing how to improve performance by optimizing system parameters under different communication conditions.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）可能会带来重要的通信负担和依赖中央服务器。为了解决这些挑战，分散式联合学习（DFL）已经被提议作为更可靠的框架。DFL通过装置间的参数交换来进行学习。本研究分析了受限制的DFL在无线网络上的表现，使用不同的通信方案（数位和模拟），以便最佳化通信效率。具体来说，我们提供了两种通信方法的整合界限，以及对数位传输的资源分配和通信复杂度的分析。另外，我们还考虑了频道折射和噪音对模型性能的影响，并分析了在折射通道上获得最大错误的组合。最后，我们将进行数据实验，以评估在DFL框架中训练过滤神经网络和探索神经网络的性能和融合率。我们的实验结果验证了我们的分析和讨论，并显示了如何通过优化系统参数来提高性能。
</details></li>
</ul>
<hr>
<h2 id="Flexible-Keyword-Spotting-based-on-Homogeneous-Audio-Text-Embedding"><a href="#Flexible-Keyword-Spotting-based-on-Homogeneous-Audio-Text-Embedding" class="headerlink" title="Flexible Keyword Spotting based on Homogeneous Audio-Text Embedding"></a>Flexible Keyword Spotting based on Homogeneous Audio-Text Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06472">http://arxiv.org/abs/2308.06472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumari Nishu, Minsik Cho, Paul Dixon, Devang Naik</li>
<li>for: 这篇论文主要关注于efficiently detecting arbitrary keywords in audio-text modalities, using an audio-compliant text encoder to reduce the mismatch between text and audio embeddings.</li>
<li>methods: 本文提出了一个新的架构，使用一个具有同步表示的文本编码器，将文本转换为phonemes使用grapheme-to-phoneme（G2P）模型，然后将phonemes转换为嵌入使用代表性的phoneme вектор，从低质量的话语资料集中提取。此外，本文还使用可替代的关键生成技术来开发一个Audio-Text嵌入验证器。</li>
<li>results: 实验结果显示，本文的方法在Libriphrase hard dataset上比前一个state-of-the-art的结果高出84.21%到92.7%，且下降了23.36%到14.4%的Equal-Error-Rate（EER）值。<details>
<summary>Abstract</summary>
Spotting user-defined/flexible keywords represented in text frequently uses an expensive text encoder for joint analysis with an audio encoder in an embedding space, which can suffer from heterogeneous modality representation (i.e., large mismatch) and increased complexity. In this work, we propose a novel architecture to efficiently detect arbitrary keywords based on an audio-compliant text encoder which inherently has homogeneous representation with audio embedding, and it is also much smaller than a compatible text encoder. Our text encoder converts the text to phonemes using a grapheme-to-phoneme (G2P) model, and then to an embedding using representative phoneme vectors, extracted from the paired audio encoder on rich speech datasets. We further augment our method with confusable keyword generation to develop an audio-text embedding verifier with strong discriminative power. Experimental results show that our scheme outperforms the state-of-the-art results on Libriphrase hard dataset, increasing Area Under the ROC Curve (AUC) metric from 84.21% to 92.7% and reducing Equal-Error-Rate (EER) metric from 23.36% to 14.4%.
</details>
<details>
<summary>摘要</summary>
通常情况下，用户定义/灵活关键词在文本中的检测通常需要使用昂贵的文本编码器进行共同分析，并与音频编码器在嵌入空间进行结合分析，这可能会导致不同类型的表达（大匹配度）和复杂性增加。在这种工作中，我们提出了一种新的架构，可以有效地检测任意关键词，基于兼容音频编码器的文本编码器，该编码器具有兼容音频嵌入的同型表示，并且比兼容文本编码器更小。我们的文本编码器将文本转换为音频的phoneme使用图eme-to-phoneme（G2P）模型，然后将其转换为嵌入使用表示音频嵌入的phoneme вектор。我们还将我们的方法与可能的关键词生成进行增强，以开发一个具有强大抑制力的音频-文本嵌入验证器。实验结果表明，我们的方案在Libriphrase困难数据集上的成绩高于当前最佳结果，从84.21%提高到92.7%，并将相同错误率（EER）从23.36%降低到14.4%。
</details></li>
</ul>
<hr>
<h2 id="Volterra-Accentuated-Non-Linear-Dynamical-Admittance-VANYA-to-model-Deforestation-An-Exemplification-from-the-Amazon-Rainforest"><a href="#Volterra-Accentuated-Non-Linear-Dynamical-Admittance-VANYA-to-model-Deforestation-An-Exemplification-from-the-Amazon-Rainforest" class="headerlink" title="Volterra Accentuated Non-Linear Dynamical Admittance (VANYA) to model Deforestation: An Exemplification from the Amazon Rainforest"></a>Volterra Accentuated Non-Linear Dynamical Admittance (VANYA) to model Deforestation: An Exemplification from the Amazon Rainforest</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06471">http://arxiv.org/abs/2308.06471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karthik R., Ramamoorthy A.</li>
<li>for: 本研究旨在预测雨林覆盖率，通过 integrate 猎物驱动力学和决策支持系统。</li>
<li>methods: 本研究使用 VANYA 模型，包括猎物驱动力学和决策支持系统，并对 Amazon 雨林数据进行预测。</li>
<li>results: 研究发现 VANYA 模型在预测雨林覆盖率方面表现出色，比 Long Short-Term Memory、N-BEATS 和 RCN 等其他预测器更为精准。<details>
<summary>Abstract</summary>
Intelligent automation supports us against cyclones, droughts, and seismic events with recent technology advancements. Algorithmic learning has advanced fields like neuroscience, genetics, and human-computer interaction. Time-series data boosts progress. Challenges persist in adopting these approaches in traditional fields. Neural networks face comprehension and bias issues. AI's expansion across scientific areas is due to adaptable descriptors and combinatorial argumentation. This article focuses on modeling Forest loss using the VANYA Model, incorporating Prey Predator Dynamics. VANYA predicts forest cover, demonstrated on Amazon Rainforest data against other forecasters like Long Short-Term Memory, N-BEATS, RCN.
</details>
<details>
<summary>摘要</summary>
智能自动化支持我们面对风暴、旱情和地震事件，因为最近技术的发展。算法学习已经提高了神经科学、遗传学和人机交互等领域。时间序列数据提高了进步。但在传统领域中采纳这些方法仍存在挑战。神经网络受理解和偏见问题困扰。AI的扩展到科学领域归功于可变描述和组合论证。本文将关注用VANYA模型预测森林损失，包括猎 Predator Dynamics。VANYA预测森林覆盖率，通过对亚马逊雨林数据进行比较，与其他预测器如Long Short-Term Memory、N-BEATS、RCN。
</details></li>
</ul>
<hr>
<h2 id="Tiny-and-Efficient-Model-for-the-Edge-Detection-Generalization"><a href="#Tiny-and-Efficient-Model-for-the-Edge-Detection-Generalization" class="headerlink" title="Tiny and Efficient Model for the Edge Detection Generalization"></a>Tiny and Efficient Model for the Edge Detection Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06468">http://arxiv.org/abs/2308.06468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xavysp/teed">https://github.com/xavysp/teed</a></li>
<li>paper_authors: Xavier Soria, Yachuan Li, Mohammad Rouhani, Angel D. Sappa</li>
<li>For: 提高边检测精度，降低模型复杂度* Methods: 提出了一种轻量级卷积神经网络TEED，只有58K参数，比State-of-the-art模型少得多。* Results: 模型训练时间快（less than 30 minutes），每 epoch快（less than 5 minutes），预测边映射清晰度高。新提出的测试集可以评估边检测模型的通用性。<details>
<summary>Abstract</summary>
Most high-level computer vision tasks rely on low-level image operations as their initial processes. Operations such as edge detection, image enhancement, and super-resolution, provide the foundations for higher level image analysis. In this work we address the edge detection considering three main objectives: simplicity, efficiency, and generalization since current state-of-the-art (SOTA) edge detection models are increased in complexity for better accuracy. To achieve this, we present Tiny and Efficient Edge Detector (TEED), a light convolutional neural network with only $58K$ parameters, less than $0.2$% of the state-of-the-art models. Training on the BIPED dataset takes $less than 30 minutes$, with each epoch requiring $less than 5 minutes$. Our proposed model is easy to train and it quickly converges within very first few epochs, while the predicted edge-maps are crisp and of high quality. Additionally, we propose a new dataset to test the generalization of edge detection, which comprises samples from popular images used in edge detection and image segmentation. The source code is available in https://github.com/xavysp/TEED.
</details>
<details>
<summary>摘要</summary>
大多数高级计算机视觉任务都依赖于低级图像操作作为其初始过程。操作如边检测、图像提高和超分解，为更高级的图像分析提供基础。在这项工作中，我们考虑边检测三个主要目标：简单、高效和普适，因为当前状态艺术（SOTA）边检测模型在精度方面增加了复杂度。为了实现这一点，我们提出了简单和高效的边检测器（TEED），这是一个具有只有58000个参数的轻量级卷积神经网络。在BIPE dataset上训练时间仅占少于30分钟，每个epoch仅需5分钟左右。我们提出的模型轻松训练，快速 converge在第一些epoch中，而预测的边图具有高质量。此外，我们还提出了一个新的测试普适性边检测的数据集，该数据集包括流行的图像used在边检测和图像分割中。源代码可以在https://github.com/xavysp/TEED上获取。
</details></li>
</ul>
<hr>
<h2 id="Not-So-Robust-After-All-Evaluating-the-Robustness-of-Deep-Neural-Networks-to-Unseen-Adversarial-Attacks"><a href="#Not-So-Robust-After-All-Evaluating-the-Robustness-of-Deep-Neural-Networks-to-Unseen-Adversarial-Attacks" class="headerlink" title="Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks"></a>Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06467">http://arxiv.org/abs/2308.06467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roman Garaev, Bader Rasheed, Adil Khan</li>
<li>for: 这种研究旨在挑战当今防御机制对假数据攻击的有效性和通用性。</li>
<li>methods: 该研究使用了 adversarial attacks 来挑战当今的 DNN 模型。</li>
<li>results: 研究发现，train DNN 模型使用只有 robust 特征集时，并不能保证模型免受假数据攻击。此外，研究还发现 $L_2$ 和 $L_{\infty}$  нор的攻击对 DNN 表示的影响不同，这可能会对研究者提供有用的启示。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have gained prominence in various applications, such as classification, recognition, and prediction, prompting increased scrutiny of their properties. A fundamental attribute of traditional DNNs is their vulnerability to modifications in input data, which has resulted in the investigation of adversarial attacks. These attacks manipulate the data in order to mislead a DNN. This study aims to challenge the efficacy and generalization of contemporary defense mechanisms against adversarial attacks. Specifically, we explore the hypothesis proposed by Ilyas et. al, which posits that DNN image features can be either robust or non-robust, with adversarial attacks targeting the latter. This hypothesis suggests that training a DNN on a dataset consisting solely of robust features should produce a model resistant to adversarial attacks. However, our experiments demonstrate that this is not universally true. To gain further insights into our findings, we analyze the impact of adversarial attack norms on DNN representations, focusing on samples subjected to $L_2$ and $L_{\infty}$ norm attacks. Further, we employ canonical correlation analysis, visualize the representations, and calculate the mean distance between these representations and various DNN decision boundaries. Our results reveal a significant difference between $L_2$ and $L_{\infty}$ norms, which could provide insights into the potential dangers posed by $L_{\infty}$ norm attacks, previously underestimated by the research community.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-One-dimensional-HEVC-video-steganalysis-method-using-the-Optimality-of-Predicted-Motion-Vectors"><a href="#A-One-dimensional-HEVC-video-steganalysis-method-using-the-Optimality-of-Predicted-Motion-Vectors" class="headerlink" title="A One-dimensional HEVC video steganalysis method using the Optimality of Predicted Motion Vectors"></a>A One-dimensional HEVC video steganalysis method using the Optimality of Predicted Motion Vectors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06464">http://arxiv.org/abs/2308.06464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Li, Minqing Zhang, Ke Niu, Yingnan Zhang, Xiaoyuan Yang</li>
<li>for: 增强HEVC标准视频隐藏通信的检测性能</li>
<li>methods: 基于优化的预测动作向量(MVP)的特征提取</li>
<li>results: 对两个通用数据集的三种常见隐藏通信方法进行检测，与四种现有的检测方法进行比较，实验结果表明提议的优化率of MVP在所有覆盖视频中为100%，而在所有隐藏视频中为 less than 100%，因此可以准确地分辨覆盖视频和隐藏视频，并在实际应用中具有无模型训练和低计算复杂度。<details>
<summary>Abstract</summary>
Among steganalysis techniques, detection against motion vector (MV) domain-based video steganography in High Efficiency Video Coding (HEVC) standard remains a hot and challenging issue. For the purpose of improving the detection performance, this paper proposes a steganalysis feature based on the optimality of predicted MVs with a dimension of one. Firstly, we point out that the motion vector prediction (MVP) of the prediction unit (PU) encoded using the Advanced Motion Vector Prediction (AMVP) technique satisfies the local optimality in the cover video. Secondly, we analyze that in HEVC video, message embedding either using MVP index or motion vector differences (MVD) may destroy the above optimality of MVP. And then, we define the optimal rate of MVP in HEVC video as a steganalysis feature. Finally, we conduct steganalysis detection experiments on two general datasets for three popular steganography methods and compare the performance with four state-of-the-art steganalysis methods. The experimental results show that the proposed optimal rate of MVP for all cover videos is 100\%, while the optimal rate of MVP for all stego videos is less than 100\%. Therefore, the proposed steganography scheme can accurately distinguish between cover videos and stego videos, and it is efficiently applied to practical scenarios with no model training and low computational complexity.
</details>
<details>
<summary>摘要</summary>
在隐藏分析技术中，对高效视频编码标准（HEVC）中的动态vector域基于视频隐藏技术进行检测仍然是一个热点和挑战。为了提高检测性能，这篇论文提出了基于预测动态vector（MVP）的隐藏特征。首先，我们指出HEVC视频中的预测单元（PU）使用高级动态vector预测（AMVP）技术编码时，预测动态vector的优化性在覆盖视频中是本地优化的。其次，我们分析HEVC视频中的信息嵌入（使用MVP索引或动态vector差（MVD））可能会破坏上述优化性。然后，我们定义HEVC视频中MVP的优化率作为隐藏特征。最后，我们对两个通用数据集上三种流行的隐藏技术进行检测试验，并与四种现状顶尖隐藏检测方法进行比较。实验结果表明，我们提出的优化率对所有覆盖视频是100%，而对所有隐藏视频是少于100%。因此，我们的隐藏方案可以准确地 отлича出覆盖视频和隐藏视频，并在实际应用中具有无模型训练和低计算复杂度。
</details></li>
</ul>
<hr>
<h2 id="Multi-Label-Knowledge-Distillation"><a href="#Multi-Label-Knowledge-Distillation" class="headerlink" title="Multi-Label Knowledge Distillation"></a>Multi-Label Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06453">http://arxiv.org/abs/2308.06453</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/penghui-yang/l2d">https://github.com/penghui-yang/l2d</a></li>
<li>paper_authors: Penghui Yang, Ming-Kun Xie, Chen-Chen Zong, Lei Feng, Gang Niu, Masashi Sugiyama, Sheng-Jun Huang</li>
<li>for: 本研究是为了解决多类 label 学习中的知识填充问题，因为传统的知识填充方法难以在多类 label 学习中应用。</li>
<li>methods: 本研究提出了一种新的多类 label 知识填充方法，它利用了类别 embeddings 的结构信息，并将多类 label 学习问题分解成多个 binary 分类问题，以提高知识填充效果。</li>
<li>results: 实验结果表明，提出的方法可以避免类标签之间的知识冲突，并在多个 benchmark 数据集上达到了Superior性能，比较方法的性能。<details>
<summary>Abstract</summary>
Existing knowledge distillation methods typically work by imparting the knowledge of output logits or intermediate feature maps from the teacher network to the student network, which is very successful in multi-class single-label learning. However, these methods can hardly be extended to the multi-label learning scenario, where each instance is associated with multiple semantic labels, because the prediction probabilities do not sum to one and feature maps of the whole example may ignore minor classes in such a scenario. In this paper, we propose a novel multi-label knowledge distillation method. On one hand, it exploits the informative semantic knowledge from the logits by dividing the multi-label learning problem into a set of binary classification problems; on the other hand, it enhances the distinctiveness of the learned feature representations by leveraging the structural information of label-wise embeddings. Experimental results on multiple benchmark datasets validate that the proposed method can avoid knowledge counteraction among labels, thus achieving superior performance against diverse comparing methods. Our code is available at: https://github.com/penghui-yang/L2D
</details>
<details>
<summary>摘要</summary>
traditional knowledge distillation methods typically work by imparting the knowledge of output logits or intermediate feature maps from the teacher network to the student network, which is very successful in multi-class single-label learning. However, these methods can hardly be extended to the multi-label learning scenario, where each instance is associated with multiple semantic labels, because the prediction probabilities do not sum to one and feature maps of the whole example may ignore minor classes in such a scenario. In this paper, we propose a novel multi-label knowledge distillation method. On one hand, it exploits the informative semantic knowledge from the logits by dividing the multi-label learning problem into a set of binary classification problems; on the other hand, it enhances the distinctiveness of the learned feature representations by leveraging the structural information of label-wise embeddings. Experimental results on multiple benchmark datasets validate that the proposed method can avoid knowledge counteraction among labels, thus achieving superior performance against diverse comparing methods. Our code is available at: https://github.com/penghui-yang/L2D.Here's the translation in Traditional Chinese:传统的知识传递方法通常是将教师网络的输出条件或中间特征图形传递到学生网络中，在多类单 Label 学习中非常成功。然而，这些方法很难扩展到多 Label 学习情况下，因为每个例子都 associates 多个Semantic 标签，预测概率不等于一，特征图形可能将次要类别忽略。在这篇论文中，我们提出了一个新的多 Label 知识传递方法。一方面，它利用了条件的Semantic 知识，将多 Label 学习问题分成多个binary 分类问题；另一方面，它增强了学习的特征表现的明确性，通过利用标签对应的结构信息。实验结果显示，提案的方法可以避免标签之间的知识对抗，因此在多种比较方法面表现出色。我们的代码可以在：https://github.com/penghui-yang/L2D 中找到。
</details></li>
</ul>
<hr>
<h2 id="Latent-Random-Steps-as-Relaxations-of-Max-Cut-Min-Cut-and-More"><a href="#Latent-Random-Steps-as-Relaxations-of-Max-Cut-Min-Cut-and-More" class="headerlink" title="Latent Random Steps as Relaxations of Max-Cut, Min-Cut, and More"></a>Latent Random Steps as Relaxations of Max-Cut, Min-Cut, and More</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06448">http://arxiv.org/abs/2308.06448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudhanshu Chanpuriya, Cameron Musco</li>
<li>for: 本研究旨在提出一种基于非正式矩阵因子化的probabilistic模型，用于融合群集和简化图structure。</li>
<li>methods: 该模型基于Random Walk进程的分解，并通过简单的梯度下降优化。</li>
<li>results: 该算法可以relax hard clustering问题，并将其转化为一个 tractable 的问题。 furthermore, 该模型在synthetic graph和一些不监控学习任务中表现良好，如orthographic和phonological数据的bipartite和tripartite clustering。<details>
<summary>Abstract</summary>
Algorithms for node clustering typically focus on finding homophilous structure in graphs. That is, they find sets of similar nodes with many edges within, rather than across, the clusters. However, graphs often also exhibit heterophilous structure, as exemplified by (nearly) bipartite and tripartite graphs, where most edges occur across the clusters. Grappling with such structure is typically left to the task of graph simplification. We present a probabilistic model based on non-negative matrix factorization which unifies clustering and simplification, and provides a framework for modeling arbitrary graph structure. Our model is based on factorizing the process of taking a random walk on the graph. It permits an unconstrained parametrization, allowing for optimization via simple gradient descent. By relaxing the hard clustering to a soft clustering, our algorithm relaxes potentially hard clustering problems to a tractable ones. We illustrate our algorithm's capabilities on a synthetic graph, as well as simple unsupervised learning tasks involving bipartite and tripartite clustering of orthographic and phonological data.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:Algorithms for node clustering通常是查找图граhp的同质结构，即找到多数边连接的节点集，而不是跨集的边。然而，图 oftentimes also exhibits heterophilous structure, such as (nearly) bipartite and tripartite graphs, where most edges occur across the clusters. Previously, dealing with such structure was left to the task of graph simplification. We present a probabilistic model based on non-negative matrix factorization, which unifies clustering and simplification, and provides a framework for modeling arbitrary graph structure. Our model is based on factorizing the process of taking a random walk on the graph. It permits an unconstrained parametrization, allowing for optimization via simple gradient descent. By relaxing the hard clustering to a soft clustering, our algorithm relaxes potentially hard clustering problems to a tractable ones. We illustrate our algorithm's capabilities on a synthetic graph, as well as simple unsupervised learning tasks involving bipartite and tripartite clustering of orthographic and phonological data.
</details></li>
</ul>
<hr>
<h2 id="A-Sequential-Meta-Transfer-SMT-Learning-to-Combat-Complexities-of-Physics-Informed-Neural-Networks-Application-to-Composites-Autoclave-Processing"><a href="#A-Sequential-Meta-Transfer-SMT-Learning-to-Combat-Complexities-of-Physics-Informed-Neural-Networks-Application-to-Composites-Autoclave-Processing" class="headerlink" title="A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing"></a>A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06447">http://arxiv.org/abs/2308.06447</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miladramzy/sequentialmetatransferpinns">https://github.com/miladramzy/sequentialmetatransferpinns</a></li>
<li>paper_authors: Milad Ramezankhani, Abbas S. Milani</li>
<li>for: 解决非线性偏微分方程（PDE）的快速解决方法，提高科学和工程应用中的精度和效率。</li>
<li>methods: 基于物理法则的神经网络（PINNs），通过将物理法则integrated到神经网络的训练中，使其在解决非线性系统方程方面表现出优异。</li>
<li>results: 在一个复杂的材料制造过程例子中，提出了一种新的Sequential Meta-Transfer（SMT）学习框架，可以快速地适应非线性系统中的变化，并大幅降低计算成本。<details>
<summary>Abstract</summary>
Physics-Informed Neural Networks (PINNs) have gained popularity in solving nonlinear partial differential equations (PDEs) via integrating physical laws into the training of neural networks, making them superior in many scientific and engineering applications. However, conventional PINNs still fall short in accurately approximating the solution of complex systems with strong nonlinearity, especially in long temporal domains. Besides, since PINNs are designed to approximate a specific realization of a given PDE system, they lack the necessary generalizability to efficiently adapt to new system configurations. This entails computationally expensive re-training from scratch for any new change in the system. To address these shortfalls, in this work a novel sequential meta-transfer (SMT) learning framework is proposed, offering a unified solution for both fast training and efficient adaptation of PINNs in highly nonlinear systems with long temporal domains. Specifically, the framework decomposes PDE's time domain into smaller time segments to create "easier" PDE problems for PINNs training. Then for each time interval, a meta-learner is assigned and trained to achieve an optimal initial state for rapid adaptation to a range of related tasks. Transfer learning principles are then leveraged across time intervals to further reduce the computational cost.Through a composites autoclave processing case study, it is shown that SMT is clearly able to enhance the adaptability of PINNs while significantly reducing computational cost, by a factor of 100.
</details>
<details>
<summary>摘要</summary>
为了解决这些缺陷，这个研究提出了一个 novel sequential meta-transfer (SMT) 学习框架，它可以实现快速训练和高效适应 PINNs 在高非线性系统中。 Specifically, the framework decomposes PDE's time domain into smaller time segments to create "easier" PDE problems for PINNs training. Then for each time interval, a meta-learner is assigned and trained to achieve an optimal initial state for rapid adaptation to a range of related tasks. Transfer learning principles are then leveraged across time intervals to further reduce the computational cost.通过一个 composites autoclave processing 案例研究，显示了 SMT 能够增强 PINNs 的适应能力，同时大幅降低计算成本，比例为 100。
</details></li>
</ul>
<hr>
<h2 id="Neural-Latent-Aligner-Cross-trial-Alignment-for-Learning-Representations-of-Complex-Naturalistic-Neural-Data"><a href="#Neural-Latent-Aligner-Cross-trial-Alignment-for-Learning-Representations-of-Complex-Naturalistic-Neural-Data" class="headerlink" title="Neural Latent Aligner: Cross-trial Alignment for Learning Representations of Complex, Naturalistic Neural Data"></a>Neural Latent Aligner: Cross-trial Alignment for Learning Representations of Complex, Naturalistic Neural Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06443">http://arxiv.org/abs/2308.06443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheol Jun Cho, Edward F. Chang, Gopala K. Anumanchipalli</li>
<li>for: 本研究的目的是理解人类行为的神经实现，以便更好地理解神经科学中的复杂行为。</li>
<li>methods: 该研究提出了一种新的无监督学习框架——神经幽Alignment（NLA），用于找到有用的神经表示，并使用了一种完全可导的时间折叠模型（TWM）来解决 trial的时间不同问题。</li>
<li>results: 当应用于自然的说话ECoG数据时，该模型可以学习更好的表示来编码行为，特别是在低维度空间中。TWM被实验证明，并且当Visualized的折叠 manifold上可以看到共享的神经轨迹 across trials。<details>
<summary>Abstract</summary>
Understanding the neural implementation of complex human behaviors is one of the major goals in neuroscience. To this end, it is crucial to find a true representation of the neural data, which is challenging due to the high complexity of behaviors and the low signal-to-ratio (SNR) of the signals. Here, we propose a novel unsupervised learning framework, Neural Latent Aligner (NLA), to find well-constrained, behaviorally relevant neural representations of complex behaviors. The key idea is to align representations across repeated trials to learn cross-trial consistent information. Furthermore, we propose a novel, fully differentiable time warping model (TWM) to resolve the temporal misalignment of trials. When applied to intracranial electrocorticography (ECoG) of natural speaking, our model learns better representations for decoding behaviors than the baseline models, especially in lower dimensional space. The TWM is empirically validated by measuring behavioral coherence between aligned trials. The proposed framework learns more cross-trial consistent representations than the baselines, and when visualized, the manifold reveals shared neural trajectories across trials.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:理解人类复杂行为的神经实现是生物科学的一个主要目标。为 достичь这个目标，寻找神经数据真正的表示是非常重要，但是由于行为的高复杂性和神经信号噪声比（SNR）的低，这是一项挑战。我们提出了一种新的无监督学习框架，神经缺失匹配（NLA），以获取行为相关的神经表示。我们的关键想法是在重复试验中对表示进行对齐，以学习跨试验的一致信息。此外，我们还提出了一种完全可微分的时间折叠模型（TWM），以解决试验时间的不一致问题。当应用于自然说话的内部电rocorticography（ECoG）数据时，我们的模型可以学习更好的表示，特别是在低维度空间中。TWM被验证了通过测量试验之间的行为一致性。我们的框架可以更好地学习跨试验一致的表示，并且当Visualized时，折叠 manifold  revelas shared neural trajectories across trials。
</details></li>
</ul>
<hr>
<h2 id="A-Domain-adaptive-Physics-informed-Neural-Network-for-Inverse-Problems-of-Maxwell’s-Equations-in-Heterogeneous-Media"><a href="#A-Domain-adaptive-Physics-informed-Neural-Network-for-Inverse-Problems-of-Maxwell’s-Equations-in-Heterogeneous-Media" class="headerlink" title="A Domain-adaptive Physics-informed Neural Network for Inverse Problems of Maxwell’s Equations in Heterogeneous Media"></a>A Domain-adaptive Physics-informed Neural Network for Inverse Problems of Maxwell’s Equations in Heterogeneous Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06436">http://arxiv.org/abs/2308.06436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiyuan Piao, Hong Gu, Aina Wang, Pan Qin</li>
<li>for: 解决Maxwell方程组在不同媒质中的逆问题</li>
<li>methods: 使用physics-informed神经网络（PINN）和领域适应训练策略</li>
<li>results: 提出了一种领域适应PINN（da-PINN），并在两个案例研究中证明了其效果<details>
<summary>Abstract</summary>
Maxwell's equations are a collection of coupled partial differential equations (PDEs) that, together with the Lorentz force law, constitute the basis of classical electromagnetism and electric circuits. Effectively solving Maxwell's equations is crucial in various fields, like electromagnetic scattering and antenna design optimization. Physics-informed neural networks (PINNs) have shown powerful ability in solving PDEs. However, PINNs still struggle to solve Maxwell's equations in heterogeneous media. To this end, we propose a domain-adaptive PINN (da-PINN) to solve inverse problems of Maxwell's equations in heterogeneous media. First, we propose a location parameter of media interface to decompose the whole domain into several sub-domains. Furthermore, the electromagnetic interface conditions are incorporated into a loss function to improve the prediction performance near the interface. Then, we propose a domain-adaptive training strategy for da-PINN. Finally, the effectiveness of da-PINN is verified with two case studies.
</details>
<details>
<summary>摘要</summary>
马克斯威尔方程是一系列相互关联的偏微分方程（PDEs），与 Lorentz 力法则共同构成了经典电磁学和电路。有效解决马克斯威尔方程是在各种领域中重要，如电磁散射和天线设计优化。 физи学 Informed Neural Networks（PINNs）已经显示出解决 PDEs 的强大能力。然而，PINNs 仍然在不同媒体中解决马克斯威尔方程困难。为此，我们提出了域 adaptive PINN（da-PINN）来解决马克斯威尔方程的反向问题在不同媒体中。首先，我们提出了媒体界面位置参数来分解整个域 into 多个子域。然后，我们将电磁界面条件纳入损失函数以提高预测性能 near 界面。最后，我们提出了域 adaptive 训练策略 для da-PINN。 Finally， da-PINN 的有效性被两个案例研究所验证。
</details></li>
</ul>
<hr>
<h2 id="Learn-Single-horizon-Disease-Evolution-for-Predictive-Generation-of-Post-therapeutic-Neovascular-Age-related-Macular-Degeneration"><a href="#Learn-Single-horizon-Disease-Evolution-for-Predictive-Generation-of-Post-therapeutic-Neovascular-Age-related-Macular-Degeneration" class="headerlink" title="Learn Single-horizon Disease Evolution for Predictive Generation of Post-therapeutic Neovascular Age-related Macular Degeneration"></a>Learn Single-horizon Disease Evolution for Predictive Generation of Post-therapeutic Neovascular Age-related Macular Degeneration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06432">http://arxiv.org/abs/2308.06432</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Zhang, Kun Huang, Mingchao Li, Songtao Yuan, Qiang Chen</li>
<li>for: 预测 age-related macular degeneration (nAMD) 疾病发展，生成post-therapeutic SD-OCT图像</li>
<li>methods: 提posed a single-horizon disease evolution network (SHENet)，包括Feature Encoder、Graph Evolution Module和Feature Decoder，通过 adversarial training 确保疾病演化学习的有效性</li>
<li>results: 比较其他生成方法，SHENet 的生成 SD-OCT 图像具有最高的图像质量，同时保持着 структура和内容的准确预测，并且在质量和效果上具有更好的视觉效果<details>
<summary>Abstract</summary>
Most of the existing disease prediction methods in the field of medical image processing fall into two classes, namely image-to-category predictions and image-to-parameter predictions. Few works have focused on image-to-image predictions. Different from multi-horizon predictions in other fields, ophthalmologists prefer to show more confidence in single-horizon predictions due to the low tolerance of predictive risk. We propose a single-horizon disease evolution network (SHENet) to predictively generate post-therapeutic SD-OCT images by inputting pre-therapeutic SD-OCT images with neovascular age-related macular degeneration (nAMD). In SHENet, a feature encoder converts the input SD-OCT images to deep features, then a graph evolution module predicts the process of disease evolution in high-dimensional latent space and outputs the predicted deep features, and lastly, feature decoder recovers the predicted deep features to SD-OCT images. We further propose an evolution reinforcement module to ensure the effectiveness of disease evolution learning and obtain realistic SD-OCT images by adversarial training. SHENet is validated on 383 SD-OCT cubes of 22 nAMD patients based on three well-designed schemes based on the quantitative and qualitative evaluations. Compared with other generative methods, the generative SD-OCT images of SHENet have the highest image quality. Besides, SHENet achieves the best structure protection and content prediction. Qualitative evaluations also demonstrate that SHENet has a better visual effect than other methods. SHENet can generate post-therapeutic SD-OCT images with both high prediction performance and good image quality, which has great potential to help ophthalmologists forecast the therapeutic effect of nAMD.
</details>
<details>
<summary>摘要</summary>
大多数现有的疾病预测方法在医学影像处理领域都归类为图像到类别预测和图像到参数预测，少数工作强调图像到图像预测。与其他多个时间预测不同，眼科医生偏好单个时间预测，因为预测风险的容忍度较低。我们提出了单个时间疾病演化网络（SHENet），用于预测治疗后SD-OCT图像。SHENet使用FeatureEncoder将输入SD-OCT图像转换为深度特征，然后使用图像演化模块预测疾病演化过程在高维潜在空间中，并输出预测的深度特征。最后，FeatureDecoder重建预测的深度特征为SD-OCT图像。我们还提出了演化增强模块，以确保疾病演化学习的有效性并获得真实的SD-OCT图像。SHENet在383个SD-OCT立方体上进行了三种基于量化和质量评价的验证。与其他生成方法相比，SHENet生成的SD-OCT图像的图像质量最高。此外，SHENet也达到了最佳结构保护和内容预测。质量评价还表明，SHENet的视觉效果更好。SHENet可以生成治疗后SD-OCT图像，具有高预测性和好图像质量，这对眼科医生预测nAMD的效果具有很大潜力。
</details></li>
</ul>
<hr>
<h2 id="Genetic-heterogeneity-analysis-using-genetic-algorithm-and-network-science"><a href="#Genetic-heterogeneity-analysis-using-genetic-algorithm-and-network-science" class="headerlink" title="Genetic heterogeneity analysis using genetic algorithm and network science"></a>Genetic heterogeneity analysis using genetic algorithm and network science</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06429">http://arxiv.org/abs/2308.06429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhendong Sha, Yuanzhu Chen, Ting Hu</li>
<li>for: 这个论文目的是通过基因组宽度关联研究(GWAS)发现疾病感染的遗传变量。</li>
<li>methods: 这篇论文使用了一种新的特征选择机制，即特征合选网络(FCS-Net)，以EXTRACT多样化的基因变量。FCS-Net使用了一种遗传算理算法(GA)和一种非线性机器学习算法来检测特征互作。</li>
<li>results: 实验表明，FCS-Net可以有效地检测特征互作，并且可以在一个案例-控制患肠癌GWAS数据集中提取出新的合成特征。这些合成特征可以用来解释患肠癌的遗传多样性。<details>
<summary>Abstract</summary>
Through genome-wide association studies (GWAS), disease susceptible genetic variables can be identified by comparing the genetic data of individuals with and without a specific disease. However, the discovery of these associations poses a significant challenge due to genetic heterogeneity and feature interactions. Genetic variables intertwined with these effects often exhibit lower effect-size, and thus can be difficult to be detected using machine learning feature selection methods. To address these challenges, this paper introduces a novel feature selection mechanism for GWAS, named Feature Co-selection Network (FCSNet). FCS-Net is designed to extract heterogeneous subsets of genetic variables from a network constructed from multiple independent feature selection runs based on a genetic algorithm (GA), an evolutionary learning algorithm. We employ a non-linear machine learning algorithm to detect feature interaction. We introduce the Community Risk Score (CRS), a synthetic feature designed to quantify the collective disease association of each variable subset. Our experiment showcases the effectiveness of the utilized GA-based feature selection method in identifying feature interactions through synthetic data analysis. Furthermore, we apply our novel approach to a case-control colorectal cancer GWAS dataset. The resulting synthetic features are then used to explain the genetic heterogeneity in an additional case-only GWAS dataset.
</details>
<details>
<summary>摘要</summary>
通过全基因组协作研究（GWAS），可以通过比较患病者和无病者的遗传数据来确定疾病易感的遗传变量。然而，发现这些相互作用的挑战是由于遗传多样性和特征互作所致。遗传变量与这些效果相互作用的情况下经常表现出较低的效果大小，因此可能difficult to be detected using machine learning feature selection methods。为解决这些挑战，本文提出了一种新的特征选择机制，称为特征相互选择网络（FCSNet）。FCS-Net是基于多个独立的特征选择运行的一个网络结构，使用一种遗传算法（GA）进行进化学习算法。我们使用一种非线性机器学习算法来探测特征相互作用。我们还引入了一个名为社区风险分数（CRS）的合成特征，用于评估每个变量子集的疾病相关度。我们的实验表明，使用我们的新采用的GA基于特征选择方法可以快速和有效地检测特征相互作用。此外，我们还应用了我们的新方法于一个患肠癌GWAS数据集。得到的合成特征然后用于解释一个额外的case-only GWAS数据集中的遗传多样性。
</details></li>
</ul>
<hr>
<h2 id="Multiclass-Learnability-Does-Not-Imply-Sample-Compression"><a href="#Multiclass-Learnability-Does-Not-Imply-Sample-Compression" class="headerlink" title="Multiclass Learnability Does Not Imply Sample Compression"></a>Multiclass Learnability Does Not Imply Sample Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06424">http://arxiv.org/abs/2308.06424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chirag Pabbaraju</li>
<li>for: 该论文讨论了一种叫做”样本压缩”的问题，即对于每个由一个假设来标注的样本，是否可以只保留一小部分样本，以便从整个样本上获取标签。</li>
<li>methods: 论文使用了一种名叫”VC dimension”的概念，它是用于描述一个假设类型的复杂度的一种指标。论文还使用了一种名叫”DS dimension”的概念，它是用于描述一个多类假设类型的复杂度的一种指标。</li>
<li>results: 论文的结果表明，对于每个有限多个假设类型，都存在一个可以压缩样本的方法，其中的压缩率只取决于假设类型的VC dimension。但是，对于多类假设类型，不存在一个可以压缩样本的方法，其中的压缩率只取决于假设类型的DS dimension。<details>
<summary>Abstract</summary>
A hypothesis class admits a sample compression scheme, if for every sample labeled by a hypothesis from the class, it is possible to retain only a small subsample, using which the labels on the entire sample can be inferred. The size of the compression scheme is an upper bound on the size of the subsample produced. Every learnable binary hypothesis class (which must necessarily have finite VC dimension) admits a sample compression scheme of size only a finite function of its VC dimension, independent of the sample size. For multiclass hypothesis classes, the analog of VC dimension is the DS dimension. We show that the analogous statement pertaining to sample compression is not true for multiclass hypothesis classes: every learnable multiclass hypothesis class, which must necessarily have finite DS dimension, does not admit a sample compression scheme of size only a finite function of its DS dimension.
</details>
<details>
<summary>摘要</summary>
一个假设集合承认样本压缩方案，如果对每个由假设集合中的一个假设标注的样本，只需保留一小样本，使得整个样本上的标注可以被推断出来。压缩方案的大小是样本上的子样本的上限。每个可学习的二分类假设集合（必然具有有限VC维度）承认一个样本压缩方案，它的大小只是VC维度的一个有限函数，不виси于样本的大小。对多类假设集合，相应的VC维度是DS维度。我们显示，对多类假设集合，其相应的压缩方案不存在，即每个可学习的多类假设集合，它必然具有有限DS维度，但不存在一个只是DS维度的有限函数的压缩方案。
</details></li>
</ul>
<hr>
<h2 id="Sensitivity-Aware-Mixed-Precision-Quantization-and-Width-Optimization-of-Deep-Neural-Networks-Through-Cluster-Based-Tree-Structured-Parzen-Estimation"><a href="#Sensitivity-Aware-Mixed-Precision-Quantization-and-Width-Optimization-of-Deep-Neural-Networks-Through-Cluster-Based-Tree-Structured-Parzen-Estimation" class="headerlink" title="Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation"></a>Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06422">http://arxiv.org/abs/2308.06422</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyedarmin Azizi, Mahdi Nazemi, Arash Fayyazi, Massoud Pedram</li>
<li>for: 提高深度学习模型的效率，自动选择最佳bit Width和层Width。</li>
<li>methods: 使用Hessian-based pruning和cluster-based tree-structured Parzen estimator来缩小搜索空间，并开发surrogate模型。</li>
<li>results: 在知名数据集上进行严格测试，与现有方法相比，提供20%的模型大小减少和12倍的搜索时间减少，代表了深度学习模型设计优化领域的一大突破。<details>
<summary>Abstract</summary>
As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 20% decrease in model size without compromising accuracy. Additionally, our method boasts a 12x reduction in search time relative to the best search-focused strategies currently available. As a result, our proposed method represents a leap forward in neural network design optimization, paving the way for quick model design and implementation in settings with limited resources, thereby propelling the potential of scalable deep learning solutions.
</details>
<details>
<summary>摘要</summary>
“深度学习模型的复杂性和计算需求逐渐增长，因此选择最佳 neural network 层的位数和层宽成为了一项非常重要的优化方法。本工作提出了一种新的搜索机制，可以自动选择最佳位数和层宽，从而提高深度神经网络的效率。搜索空间通过利用希尔比ан-基于的剔除来减少，确保移除不必要的参数。然后，我们详细介绍了使用分布式树结构的 Parzen 估计器来开发备受欢迎和不欢迎的结果的代理模型。这种策略可以快速探索不同的建筑方案，并快速定位最佳的设计。我们对知名的数据集进行了严格的测试，并证明了我们的方法与现有方法相比，能够减少模型大小20%，而不会影响准确性。此外，我们的方法可以在搜索时间上减少12倍，相比最佳的搜索焦点策略。因此，我们的提议方法代表了深度神经网络设计优化领域的一大突破，为有限资源的设置中快速实现模型设计和实现，从而推动了可拓展的深度学习解决方案。”
</details></li>
</ul>
<hr>
<h2 id="Pedestrian-Trajectory-Prediction-in-Pedestrian-Vehicle-Mixed-Environments-A-Systematic-Review"><a href="#Pedestrian-Trajectory-Prediction-in-Pedestrian-Vehicle-Mixed-Environments-A-Systematic-Review" class="headerlink" title="Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review"></a>Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06419">http://arxiv.org/abs/2308.06419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad</li>
<li>for: 本研究は自动驾驶车辆（AV）在共享空间中的轨迹规划问题的解决方案。</li>
<li>methods: 本文系统atically review了 Literature中关于模拟行人轨迹预测的不同方法，这些方法可以应用于不结构化环境中。</li>
<li>results: 本文对pedestrian-vehicle交互（与人与人交互）进行了专门考虑，并review了不同变量（如预测uncertainty和行为差异）在已提出的预测模型中如何考虑。<details>
<summary>Abstract</summary>
Planning an autonomous vehicle's (AV) path in a space shared with pedestrians requires reasoning about pedestrians' future trajectories. A practical pedestrian trajectory prediction algorithm for the use of AVs needs to consider the effect of the vehicle's interactions with the pedestrians on pedestrians' future motion behaviours. In this regard, this paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in presence of vehicles that can be applied for unstructured environments. This paper also investigates specific considerations for pedestrian-vehicle interaction (compared with pedestrian-pedestrian interaction) and reviews how different variables such as prediction uncertainties and behavioural differences are accounted for in the previously proposed prediction models. PRISMA guidelines were followed. Articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. A total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. An overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. Research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments are discussed.
</details>
<details>
<summary>摘要</summary>
планирование пути автономного транспортного средства (АВ) в пространстве, где находятся пешеходы, требует рассмотрения прогнозируемых траекторий пешеходов. практический алгоритм предсказания траекторий пешеходов для использования АВ должен учитывать влияние взаимодействия автомобиля с пешеходами на будущие движения людей. в этом отношении, этот документ систематически обзорывает различные методы, предложенные в литературе для моделирования предсказания траекторий пешеходов в присутствии автомобилей, которые могут быть применены в неструктурированных средах. документ также исследует конкретные аспекты взаимодействия пешехода-автомобиль (в сравнении с взаимодействием пешехода-пешеход) и обзоры, как различные переменные, такие как неопределенности предсказания и различия в поведении, учитываются в предыдущих моделях предсказания. Following PRISMA guidelines, articles that did not consider the interactions between vehicles and pedestrians or actual trajectories, and articles that only focused on road crossing were excluded. A total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. An overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. Research gaps and directions for future work, such as the need for more effective definitions of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments, are discussed.
</details></li>
</ul>
<hr>
<h2 id="Learning-Bayesian-Networks-with-Heterogeneous-Agronomic-Data-Sets-via-Mixed-Effect-Models-and-Hierarchical-Clustering"><a href="#Learning-Bayesian-Networks-with-Heterogeneous-Agronomic-Data-Sets-via-Mixed-Effect-Models-and-Hierarchical-Clustering" class="headerlink" title="Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering"></a>Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06399">http://arxiv.org/abs/2308.06399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Vallegi, Marco Scutari, Federico Mattia Stefanini</li>
<li>For: This paper is written for researchers and practitioners who work with complex data sets in various fields, particularly agronomic studies. The paper aims to provide a novel approach for modeling causal relationships using Bayesian networks (BNs) and to demonstrate its effectiveness in handling hierarchical data.* Methods: The paper introduces a new approach that integrates random effects into BN learning, which is rooted in linear mixed-effects models. The approach uses directed acyclic graphs to illustrate the connections between variables and can handle complex networks of causal relationships.* Results: The paper reports that employing this approach can enhance structural learning, leading to the discovery of new connections and improved model specification. The approach also results in a reduction in prediction errors from 28% to 17%. The results suggest that the approach is effective in handling complex data sets and can improve the accuracy of predictions.<details>
<summary>Abstract</summary>
Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.   Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery of new connections and the improvement of improved model specification. Furthermore, we observe a reduction in prediction errors from 28\% to 17\%. By extending the applicability of BNs to complex data set structures, this approach contributes to the effective utilisation of BNs for hierarchical agronomic data. This, in turn, enhances their value as decision-support tools in the field.
</details>
<details>
<summary>摘要</summary>
研究涉及多个相关数据集，其中变量之间可能存在复杂的关系，在各个领域，如农学研究中很普遍。在这些情况下，层次模型，也称为多级模型， часто被使用来整合不同数据集的信息，同时适应它们的特点。然而，这些模型的结构超出了简单的不同性，因为变量经常形成复杂的 causal 关系网络。 bayesian networks（BN）提供一种强大的模型化这些关系的框架，使用指向无环图来示出变量之间的连接。本研究提出了一种新的方法，即在 bayesian networks 学习中添加随机效应。基于线性混合效应模型，这种方法特别适合处理层次数据。实际的农学试验结果表明，通过使用这种方法，可以提高结构学习的效果，发现新的连接，并改善模型规定。此外，我们发现预测错误率从28%降低到17%。通过扩展 bayesian networks 的应用范围，这种方法为层次农学数据的有效利用做出了贡献，从而提高了 bayesian networks 作为决策支持工具的价值。
</details></li>
</ul>
<hr>
<h2 id="Detecting-and-Preventing-Hallucinations-in-Large-Vision-Language-Models"><a href="#Detecting-and-Preventing-Hallucinations-in-Large-Vision-Language-Models" class="headerlink" title="Detecting and Preventing Hallucinations in Large Vision Language Models"></a>Detecting and Preventing Hallucinations in Large Vision Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06394">http://arxiv.org/abs/2308.06394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anisha Gunjal, Jihan Yin, Erhan Bas</li>
<li>for: 本研究的目的是提高大观语言模型（LVLM）在多modal任务中的泛化能力，特别是对Visual Question Answering（VQA）任务的泛化。</li>
<li>methods: 我们使用了InstructBLIP模型，并通过我们的novel Fine-grained Direct Preference Optimization（FDPO）和 fine-grained多Modal reward模型来优化这个模型，以避免hallucination。</li>
<li>results: 我们的实验结果表明，使用FDPO和rejection sampling可以将InstructBLIP模型中的hallucination率降低41%和55%，并且我们的 reward模型可以在其他多Modal模型上提高泛化能力，降低LLaVA和mPLUG-OWL模型中的hallucination率15%和57%。<details>
<summary>Abstract</summary>
Instruction tuned Large Vision Language Models (LVLMs) have significantly advanced in generalizing across a diverse set of multi-modal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of the hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a (M)ultimodal (Hal)lucination (Detect)ion Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained annotations on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions and relationships that are unfaithful. To demonstrate the potential of this dataset for hallucination prevention, we optimize InstructBLIP through our novel Fine-grained Direct Preference Optimization (FDPO). We also train fine-grained multi-modal reward models from InstructBLIP and evaluate their effectiveness with best-of-n rejection sampling. We perform human evaluation on both FDPO and rejection sampling, and find that they reduce hallucination rates in InstructBLIP by 41% and 55% respectively. We also find that our reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57% respectively, and has strong correlation with human evaluated accuracy scores.
</details>
<details>
<summary>摘要</summary>
压缩 Large Vision Language Models (LVLMs) 在多modal任务上的总体化进步了很多，特别是视觉问答 (VQA)。然而，生成具体的视觉基于的回答仍然是这些模型的挑战。我们发现，even the current state-of-the-art LVLMs (InstructBLIP) 仍然包含30%的幻觉文本，包括不存在的对象、不准确的描述和关系。为解决这个问题，我们介绍了 M-HalDetect，一个多modal的幻觉检测数据集，可以用于训练和对模型的幻觉检测和预防。M-HalDetect 包含16k 细化的 VQA 示例注释，使其成为首个多modal幻觉检测数据集。不同于之前的工作仅考虑对象幻觉，我们还注释了不准确的实体描述和关系。为证明这个数据集的潜力，我们使用我们的新的精细直接偏好优化 (FDPO) 方法优化 InstructBLIP。我们还使用基于 InstructBLIP 的精细多modal奖励模型，并通过best-of-n 拒绝采样评估其效果。我们进行了人工评估，发现 FDPO 和拒绝采样都能减少 InstructBLIP 中幻觉率 by 41% 和 55%  соответственно。此外，我们发现我们的奖励模型可以泛化到其他多modal模型，减少 LLaVA 和 mPLUG-OWL 中的幻觉率 by 15% 和 57%  соответственно，并与人类评估准确率之间存在强相关性。
</details></li>
</ul>
<hr>
<h2 id="Phoneme-Hallucinator-One-shot-Voice-Conversion-via-Set-Expansion"><a href="#Phoneme-Hallucinator-One-shot-Voice-Conversion-via-Set-Expansion" class="headerlink" title="Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion"></a>Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06382">http://arxiv.org/abs/2308.06382</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/PhonemeHallucinator/Phoneme_Hallucinator">https://github.com/PhonemeHallucinator/Phoneme_Hallucinator</a></li>
<li>paper_authors: Siyuan Shan, Yang Li, Amartya Banerjee, Junier B. Oliva</li>
<li>for: 本研究旨在解决现有VC方法中的一个矛盾，即保持语言内容的同时实现高度的 speaker similarity。</li>
<li>methods: 本研究提出了一种新的VC模型，即“phoneme hallucinator”，该模型可以基于短时间内的目标说话者声音（例如3秒）生成多样化和高质量的目标说话者音频。</li>
<li>results: 对比 existed VC方法，本研究的“phoneme hallucinator”模型在语言内容和说话者相似性两个方面都达到了更高的性能。<details>
<summary>Abstract</summary>
Voice conversion (VC) aims at altering a person's voice to make it sound similar to the voice of another person while preserving linguistic content. Existing methods suffer from a dilemma between content intelligibility and speaker similarity; i.e., methods with higher intelligibility usually have a lower speaker similarity, while methods with higher speaker similarity usually require plenty of target speaker voice data to achieve high intelligibility. In this work, we propose a novel method \textit{Phoneme Hallucinator} that achieves the best of both worlds. Phoneme Hallucinator is a one-shot VC model; it adopts a novel model to hallucinate diversified and high-fidelity target speaker phonemes based just on a short target speaker voice (e.g. 3 seconds). The hallucinated phonemes are then exploited to perform neighbor-based voice conversion. Our model is a text-free, any-to-any VC model that requires no text annotations and supports conversion to any unseen speaker. Objective and subjective evaluations show that \textit{Phoneme Hallucinator} outperforms existing VC methods for both intelligibility and speaker similarity.
</details>
<details>
<summary>摘要</summary>
声音转换（VC）目标是使一个人的声音变得更像另一个人的声音，保持语言内容不变。现有方法受到内容理解和发音相似之间的矛盾，即方法更高的理解能力通常需要大量目标 speaker 的声音数据来实现高度的发音相似。在这项工作中，我们提出了一种新方法——《phoneme hallucinator》。这是一个一架VC模型，它采用了一种新的模型来幻化目标 speaker 的多样化和高品质的发音，只需要短时间的目标 speaker 声音（例如3秒）。幻化的发音然后被利用于邻居基于的声音转换。我们的模型是文本无需、任何到任何的VC模型，不需要文本注释，并且支持转换到任何未看过的发音。对象和主观评估表明，《phoneme hallucinator》在理解和发音相似性方面都高于现有的VC方法。
</details></li>
</ul>
<hr>
<h2 id="DCNFIS-Deep-Convolutional-Neuro-Fuzzy-Inference-System"><a href="#DCNFIS-Deep-Convolutional-Neuro-Fuzzy-Inference-System" class="headerlink" title="DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System"></a>DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06378">http://arxiv.org/abs/2308.06378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mojtaba Yeganejou, Kimia Honari, Ryan Kluzinski, Scott Dick, Michael Lipsett, James Miller</li>
<li>for: 提高 искусственный интеллект的可解释性，即让人可以直观地理解算法的工作方式，而不是仅仅得到后果的解释。</li>
<li>methods: 通过混合深度学习和符谱逻辑模型，设计了一种深度 convolutional neuro-fuzzy inference system (DCNFIS)，以提高算法的可解释性而不损失准确性。</li>
<li>results: DCNFIS在四个常用的数据集上表现与三种现有的 convolutional neural networks 相当，并且在深度符谱系统中表现出色，可以提供明确的解释。<details>
<summary>Abstract</summary>
A key challenge in eXplainable Artificial Intelligence is the well-known tradeoff between the transparency of an algorithm (i.e., how easily a human can directly understand the algorithm, as opposed to receiving a post-hoc explanation), and its accuracy. We report on the design of a new deep network that achieves improved transparency without sacrificing accuracy. We design a deep convolutional neuro-fuzzy inference system (DCNFIS) by hybridizing fuzzy logic and deep learning models and show that DCNFIS performs as accurately as three existing convolutional neural networks on four well-known datasets. We furthermore that DCNFIS outperforms state-of-the-art deep fuzzy systems. We then exploit the transparency of fuzzy logic by deriving explanations, in the form of saliency maps, from the fuzzy rules encoded in DCNFIS. We investigate the properties of these explanations in greater depth using the Fashion-MNIST dataset.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在可解释人工智能中是论知识（即人类可以直接理解算法，而不是接受后勤解释）和准确性之间的贸易。我们报告了一种新的深度网络的设计，该网络实现了改善的透明度，不 sacrifice准确性。我们设计了一种深度 convolutional neuro-fuzzy inference system (DCNFIS)，通过混合深度学习模型和多valued 逻辑模型，并证明 DCNFIS 与三种现有的 convolutional neural networks 在四个知名的数据集上表现相同。此外，我们发现 DCNFIS 在深度逻辑系统中的透明度，可以从 fuzzy 规则中 derivation 出解释，例如 saliency maps。我们在 Fashion-MNIST 数据集上进行了更深入的调查，并证明这些解释具有某些性质。
</details></li>
</ul>
<hr>
<h2 id="UAMM-UBET-Automated-Market-Maker"><a href="#UAMM-UBET-Automated-Market-Maker" class="headerlink" title="UAMM: UBET Automated Market Maker"></a>UAMM: UBET Automated Market Maker</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06375">http://arxiv.org/abs/2308.06375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Jiwoong Im, Alexander Kondratskiy, Vincent Harvey, Hsuan-Wei Fu</li>
<li>for: 这篇论文是关于抽象市场制定机制（AMM），用于中央化交易所（DEX）的价格机制。</li>
<li>methods: 该论文提出了一种新的价格计算方法，称为UBET AMM（UAMM），该方法考虑了外部市场价格和流动性池的不稳定损失。</li>
<li>results: 作者们示出了该方法可以消除外部市场价格是有效的情况下的买卖假象。<details>
<summary>Abstract</summary>
Automated market makers (AMMs) are pricing mechanisms utilized by decentralized exchanges (DEX). Traditional AMM approaches are constrained by pricing solely based on their own liquidity pool, without consideration of external markets or risk management for liquidity providers. In this paper, we propose a new approach known as UBET AMM (UAMM), which calculates prices by considering external market prices and the impermanent loss of the liquidity pool. Despite relying on external market prices, our method maintains the desired properties of a constant product curve when computing slippages. The key element of UAMM is determining the appropriate slippage amount based on the desired target balance, which encourages the liquidity pool to minimize impermanent loss. We demonstrate that our approach eliminates arbitrage opportunities when external market prices are efficient.
</details>
<details>
<summary>摘要</summary>
自动化市场制造者（AMM）是分布式交易所（DEX）中的价格调节机制。传统AMM方法仅基于自己的流动性池来价格调节，无视外部市场或流动性提供者的风险管理。在这篇论文中，我们提出了一新的方法，known as UBET AMM（UAMM），它根据外部市场价格和流动性池的不稳定损失来计算价格。尽管依赖外部市场价格，我们的方法仍然保持欲要的常量产品曲线价格调节。UBAMM的关键元素是根据目标库存量来决定适当的滑动量，这样将流动性池最小化不稳定损失。我们显示，我们的方法可以在有效的外部市场价格下消除投资机会。
</details></li>
</ul>
<hr>
<h2 id="Topic-Level-Bayesian-Surprise-and-Serendipity-for-Recommender-Systems"><a href="#Topic-Level-Bayesian-Surprise-and-Serendipity-for-Recommender-Systems" class="headerlink" title="Topic-Level Bayesian Surprise and Serendipity for Recommender Systems"></a>Topic-Level Bayesian Surprise and Serendipity for Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06368">http://arxiv.org/abs/2308.06368</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ton-moy/surprise-and-serendipity">https://github.com/ton-moy/surprise-and-serendipity</a></li>
<li>paper_authors: Tonmoy Hasan, Razvan Bunescu</li>
<li>for: 本研究旨在提高个性化推荐系统的效果，使用高度可能性的Item推荐，以减少用户接触到的Filter Bubble问题。</li>
<li>methods: 该研究使用了Bayesian surprise来量化Item的意外性，并结合协同推荐算法，以找到用户可能很喜欢的高度可能性Item。</li>
<li>results: 实验结果表明，使用Bayesian surprise来量化Item的意外性，与距离基于的估计法相比，具有更高的相关性和更好的服务器端推荐性能。<details>
<summary>Abstract</summary>
A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 books read by 4 users in terms of their time-dependent, topic-level surprise. Experimental evaluations show that models that use Bayesian surprise correlate much better with the manual annotations of topic-level surprise than distance-based heuristics, and also obtain better serendipitous item recommendation performance.
</details>
<details>
<summary>摘要</summary>
一个受推荐系统可以专注于让用户过去的评分历史中的项目进行最佳化，则可能导致一个范本弹簧（filter bubble），使用户没有机会体验到 novel、未看过的类别中的项目。为了解决这个问题，我们可以推荐项目具有高度的惊喜性，即可能具有高度评价的项目。在这篇文章中，我们提出了基于 bayesian 惊喜的内容基式的调和方法，并使用这个方法来衡量项目被用户过去评分后的惊喜性。当与相似用户的协同推荐部分结合时，这个方法可以提供高度惊喜性的项目推荐。为了促进题目级模型的惊喜和创新性的评估，我们将goodreads中的阅读历史数据集提取出超过26000名用户和约130000本书的数据，并 manually annotate 449本被4名用户阅读的书籍，以时间依赖的题目级惊喜作为标准。实验结果显示，使用 bayesian 惊喜的模型与距离基于的评估方法相比，具有更好的惊喜性和创新性的项目推荐性能。
</details></li>
</ul>
<hr>
<h2 id="Learning-Distributions-via-Monte-Carlo-Marginalization"><a href="#Learning-Distributions-via-Monte-Carlo-Marginalization" class="headerlink" title="Learning Distributions via Monte-Carlo Marginalization"></a>Learning Distributions via Monte-Carlo Marginalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06352">http://arxiv.org/abs/2308.06352</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenqiu Zhao, Guanfang Dong, Anup Basu</li>
<li>For: 学习不可求解分布的方法* Methods: 使用参数化分布模型（如混合 Gaussian Mixture Model）来近似不可求解分布，并使用 Monte-Carlo Marginalization 和 Kernel Density Estimation 解决计算复杂性和优化问题* Results: 提出了一种可 differentiable 的分布学习方法，并在标准数据集和 sintetic data 上进行了实验，证明了该方法的效果。此外，该方法还可以在 VAE 中代替变量推理，并且可以生成更好的图像。<details>
<summary>Abstract</summary>
We propose a novel method to learn intractable distributions from their samples. The main idea is to use a parametric distribution model, such as a Gaussian Mixture Model (GMM), to approximate intractable distributions by minimizing the KL-divergence. Based on this idea, there are two challenges that need to be addressed. First, the computational complexity of KL-divergence is unacceptable when the dimensions of distributions increases. The Monte-Carlo Marginalization (MCMarg) is proposed to address this issue. The second challenge is the differentiability of the optimization process, since the target distribution is intractable. We handle this problem by using Kernel Density Estimation (KDE). The proposed approach is a powerful tool to learn complex distributions and the entire process is differentiable. Thus, it can be a better substitute of the variational inference in variational auto-encoders (VAE). One strong evidence of the benefit of our method is that the distributions learned by the proposed approach can generate better images even based on a pre-trained VAE's decoder. Based on this point, we devise a distribution learning auto-encoder which is better than VAE under the same network architecture. Experiments on standard dataset and synthetic data demonstrate the efficiency of the proposed approach.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法来学习不可解 Distributions 的样本。主要思想是使用参数化分布模型，如 Gaussian Mixture Model (GMM)，来approximate不可解 Distributions 的 KL- divergence 的最小值。在这个想法的基础之上，需要解决两个挑战。首先，随着分布的维度增加，KL- divergence 的计算复杂性变得不可接受。我们提出了 Monte-Carlo Marginalization (MCMarg) 来解决这个问题。其次，目标分布是不可导的，因此需要使用 Kernel Density Estimation (KDE) 来处理这个问题。我们的方法可以学习复杂的分布，整个过程是导数的，因此可以作为 VAE 的更好的替代方案。我们的方法可以在标准数据集和 synthetic data 上进行实验，并且得到了良好的效果。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well. The translation is based on the standard grammar and vocabulary of Simplified Chinese, and may differ slightly from the Traditional Chinese used in Taiwan and other countries.
</details></li>
</ul>
<hr>
<h2 id="Mirror-Diffusion-Models"><a href="#Mirror-Diffusion-Models" class="headerlink" title="Mirror Diffusion Models"></a>Mirror Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06342">http://arxiv.org/abs/2308.06342</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cran/DIMORA">https://github.com/cran/DIMORA</a></li>
<li>paper_authors: Jaesung Tae</li>
<li>for: 这份报告旨在提出一种对组 categorical 资料进行生成的方法，并且提供一个理论框架来适应受限的领域。</li>
<li>methods: 这种方法基于镜像朗凯文法，并且将其应用到简单的扩散过程中。这些方法可以自然地扩展到受欢迎的领域，如图像和文本生成。</li>
<li>results: 这种方法可以在简单的扩散过程中生成高质量的组 categorical 资料，并且可以实现受限的领域中的生成。<details>
<summary>Abstract</summary>
Diffusion models have successfully been applied to generative tasks in various continuous domains. However, applying diffusion to discrete categorical data remains a non-trivial task. Moreover, generation in continuous domains often requires clipping in practice, which motivates the need for a theoretical framework for adapting diffusion to constrained domains. Inspired by the mirror Langevin algorithm for the constrained sampling problem, in this theoretical report we propose Mirror Diffusion Models (MDMs). We demonstrate MDMs in the context of simplex diffusion and propose natural extensions to popular domains such as image and text generation.
</details>
<details>
<summary>摘要</summary>
Diffusion models have successfully been applied to generative tasks in various continuous domains. However, applying diffusion to discrete categorical data remains a non-trivial task. Moreover, generation in continuous domains often requires clipping in practice, which motivates the need for a theoretical framework for adapting diffusion to constrained domains. Inspired by the mirror Langevin algorithm for the constrained sampling problem, in this theoretical report we propose Mirror Diffusion Models (MDMs). We demonstrate MDMs in the context of simplex diffusion and propose natural extensions to popular domains such as image and text generation.Here's the translation in Traditional Chinese:Diffusion models have successfully been applied to generative tasks in various continuous domains. However, applying diffusion to discrete categorical data remains a non-trivial task. Moreover, generation in continuous domains often requires clipping in practice, which motivates the need for a theoretical framework for adapting diffusion to constrained domains. Inspired by the mirror Langevin algorithm for the constrained sampling problem, in this theoretical report we propose Mirror Diffusion Models (MDMs). We demonstrate MDMs in the context of simplex diffusion and propose natural extensions to popular domains such as image and text generation.
</details></li>
</ul>
<hr>
<h2 id="Size-Lowerbounds-for-Deep-Operator-Networks"><a href="#Size-Lowerbounds-for-Deep-Operator-Networks" class="headerlink" title="Size Lowerbounds for Deep Operator Networks"></a>Size Lowerbounds for Deep Operator Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06338">http://arxiv.org/abs/2308.06338</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anirbit Mukherjee, Amartya Roy</li>
<li>for: 本研究目的是Establishing a first-of-its-kind data-dependent lower bound on the size of DeepONets required to reduce empirical error on noisy data.</li>
<li>methods: 本研究使用Deep Operator Networks (DeepONets) paradigm to solve regression in infinite dimensions and families of PDEs in one shot.</li>
<li>results: 研究发现，为了在$n$个数据点上获得低训练错误，Common output dimension of branch and trunk net必须在$\Omega \left ( \sqrt{n} \right )$scaling。这种情况在解决势动扩散反应PDE中进行实验，并证明在固定模型大小下，通过增加common output dimension来逐渐下降训练错误，数据训练集可能需要平方倍增。<details>
<summary>Abstract</summary>
Deep Operator Networks are an increasingly popular paradigm for solving regression in infinite dimensions and hence solve families of PDEs in one shot. In this work, we aim to establish a first-of-its-kind data-dependent lowerbound on the size of DeepONets required for them to be able to reduce empirical error on noisy data. In particular, we show that for low training errors to be obtained on $n$ data points it is necessary that the common output dimension of the branch and the trunk net be scaling as $\Omega \left ( {\sqrt{n} \right )$. This inspires our experiments with DeepONets solving the advection-diffusion-reaction PDE, where we demonstrate the possibility that at a fixed model size, to leverage increase in this common output dimension and get monotonic lowering of training error, the size of the training data might necessarily need to scale quadratically with it.
</details>
<details>
<summary>摘要</summary>
深度网络（DeepONet）是一种在无穷维度中进行回归的增 Popular 模式，可以解决 families of PDEs 的问题一并。在这项工作中，我们想要建立一个数据висимы的下界，以确定 DeepONets 的大小需要在噪音数据上减少 empirical error。 Specifically，我们显示了在 $n$ 个数据点上获得低训练错误需要branch和trunk网的公共输出维度Scale as $\Omega \left ( \sqrt{n} \right )$.这种情况在我们解决了diffusion-advection-reaction PDE 的实验中得到了证明，我们发现在固定模型大小下，可以通过增加 common output dimension来降低训练错误，但是training data的大小可能需要 quadratic 增长。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Model-is-Efficient-Multimodal-Multitask-Model-Selector"><a href="#Foundation-Model-is-Efficient-Multimodal-Multitask-Model-Selector" class="headerlink" title="Foundation Model is Efficient Multimodal Multitask Model Selector"></a>Foundation Model is Efficient Multimodal Multitask Model Selector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06262">http://arxiv.org/abs/2308.06262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opengvlab/multitask-model-selector">https://github.com/opengvlab/multitask-model-selector</a></li>
<li>paper_authors: Fanqing Meng, Wenqi Shao, Zhanglin Peng, Chonghe Jiang, Kaipeng Zhang, Yu Qiao, Ping Luo</li>
<li>for: 这个论文研究了一个未经探索的重要问题：给一个集合的预训练神经网络，预测它们在每个多Modal任务上的性能，不需要细致调整。</li>
<li>methods: 这个论文提出了一种高效的多任务模型选择器（EMMS），使用大规模基础模型将多种下游任务的标签格式转换成一个统一的噪声标签嵌入。EMMS可以通过一种简单的权重线性回归来估算模型的传输性，该算法可以通过一种交互式最小化算法来高效解决。</li>
<li>results: 对5个下游任务和24个数据集进行了广泛的实验，显示了EMMS的高效性、有效性和通用性。比如，相比采用LogME进行加强的状态的方法，EMMS在图像识别、引用、描述、视觉问答和文本问答等5个任务上 achieve了9.0%、26.3%、20.1%、54.8%和12.2%的性能提升，同时带来5.13倍、6.29倍、3.59倍、6.19倍和5.66倍的计划时间提升。代码可以在<a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/Multitask-Model-Selector%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/OpenGVLab/Multitask-Model-Selector上获取。</a><details>
<summary>Abstract</summary>
This paper investigates an under-explored but important problem: given a collection of pre-trained neural networks, predicting their performance on each multi-modal task without fine-tuning them, such as image recognition, referring, captioning, visual question answering, and text question answering. A brute-force approach is to finetune all models on all target datasets, bringing high computational costs. Although recent-advanced approaches employed lightweight metrics to measure models' transferability,they often depend heavily on the prior knowledge of a single task, making them inapplicable in a multi-modal multi-task scenario. To tackle this issue, we propose an efficient multi-task model selector (EMMS), which employs large-scale foundation models to transform diverse label formats such as categories, texts, and bounding boxes of different downstream tasks into a unified noisy label embedding. EMMS can estimate a model's transferability through a simple weighted linear regression, which can be efficiently solved by an alternating minimization algorithm with a convergence guarantee. Extensive experiments on 5 downstream tasks with 24 datasets show that EMMS is fast, effective, and generic enough to assess the transferability of pre-trained models, making it the first model selection method in the multi-task scenario. For instance, compared with the state-of-the-art method LogME enhanced by our label embeddings, EMMS achieves 9.0\%, 26.3\%, 20.1\%, 54.8\%, 12.2\% performance gain on image recognition, referring, captioning, visual question answering, and text question answering, while bringing 5.13x, 6.29x, 3.59x, 6.19x, and 5.66x speedup in wall-clock time, respectively. The code is available at https://github.com/OpenGVLab/Multitask-Model-Selector.
</details>
<details>
<summary>摘要</summary>
Currently, a brute-force approach is to fine-tune all models on all target datasets, which is computationally expensive. Recent advanced approaches use lightweight metrics to measure models' transferability, but these metrics often rely on prior knowledge of a single task and are not applicable in a multi-modal multi-task scenario.To address this issue, we propose an Efficient Multi-task Model Selector (EMMS), which uses large-scale foundation models to transform diverse label formats into a unified noisy label embedding. EMMS estimates a model's transferability through a simple weighted linear regression, which can be efficiently solved by an alternating minimization algorithm with a convergence guarantee.Our extensive experiments on 5 downstream tasks with 24 datasets show that EMMS is fast, effective, and generic enough to assess the transferability of pre-trained models. Compared with the state-of-the-art method LogME enhanced by our label embeddings, EMMS achieves a 9.0%, 26.3%, 20.1%, 54.8%, and 12.2% performance gain on image recognition, referring, captioning, visual question answering, and text question answering, respectively. Additionally, EMMS brings 5.13x, 6.29x, 3.59x, 6.19x, and 5.66x speedup in wall-clock time, respectively.The code for EMMS is available at https://github.com/OpenGVLab/Multitask-Model-Selector.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Resilience-with-Neural-Networks"><a href="#Predicting-Resilience-with-Neural-Networks" class="headerlink" title="Predicting Resilience with Neural Networks"></a>Predicting Resilience with Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06309">http://arxiv.org/abs/2308.06309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karen da Mata, Priscila Silva, Lance Fiondella</li>
<li>for: This paper aims to propose and evaluate alternative neural network (NN) approaches to model and predict system performance, including negative and positive factors driving resilience, in order to quantify the impact of disruptive events and restorative activities.</li>
<li>methods: The paper proposes three alternative NN approaches, including Artificial Neural Networks, Recurrent Neural Networks, and Long-Short Term Memory (LSTM), to model and predict system performance.</li>
<li>results: The results show that NN models outperformed a classical statistical model on all goodness-of-fit measures, with LSTMs achieving an over 60% higher adjusted R squared and decreased predictive error by 34-fold compared to the traditional method. These results suggest that NN models are both feasible and accurate for predicting resilience and may find practical use in many important domains.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是提出和评估基于神经网络（NN）的方法，以量化系统性能，包括负面和正面因素对系统抗异常性的影响。</li>
<li>methods: 论文提出了三种代表性的NN方法，包括人工神经网络、循环神经网络和长短期记忆（LSTM），以量化系统性能。</li>
<li>results: 结果表明，NN模型在所有准确度度量上都高于传统统计模型，具体来说，LSTM模型在所有准确度度量上高于60%，并将预测错误量减少34倍。这些结果表明，NN模型可以准确地预测系统抗异常性，并在许多重要领域发现实际应用。<details>
<summary>Abstract</summary>
Resilience engineering studies the ability of a system to survive and recover from disruptive events, which finds applications in several domains. Most studies emphasize resilience metrics to quantify system performance, whereas recent studies propose statistical modeling approaches to project system recovery time after degradation. Moreover, past studies are either performed on data after recovering or limited to idealized trends. Therefore, this paper proposes three alternative neural network (NN) approaches including (i) Artificial Neural Networks, (ii) Recurrent Neural Networks, and (iii) Long-Short Term Memory (LSTM) to model and predict system performance, including negative and positive factors driving resilience to quantify the impact of disruptive events and restorative activities. Goodness-of-fit measures are computed to evaluate the models and compared with a classical statistical model, including mean squared error and adjusted R squared. Our results indicate that NN models outperformed the traditional model on all goodness-of-fit measures. More specifically, LSTMs achieved an over 60\% higher adjusted R squared, and decreased predictive error by 34-fold compared to the traditional method. These results suggest that NN models to predict resilience are both feasible and accurate and may find practical use in many important domains.
</details>
<details>
<summary>摘要</summary>
“恢复工程”（Resilience engineering）研究系统对瘫痪事件的抗衡能力和恢复时间，这些应用在多个领域。大多数研究强调系统表现的量化指标（resilience metrics），而现在的研究则提出了使用统计模型估算系统恢复时间。然而，过去的研究都是基于已经恢复的数据或仅对理想化趋势进行研究。因此，本文提出了三种人工神经网络（Artificial Neural Networks）方法，包括（i）人工神经网络（Artificial Neural Networks）、（ii）循环神经网络（Recurrent Neural Networks）和（iii）长期记忆运算（Long-Short Term Memory，LSTM），用于模拟和预测系统表现，包括负和正因素影响系统抗衡能力。我们 Compute 好igkeit-of-fit 度量来评估这些模型，并与传统的统计模型进行比较，包括平均方差和修正系数。我们的结果显示，NN 模型在所有好igkeit-of-fit 度量上表现更好，特别是 LSTM 模型的调整 R 平方error 高于 60%，并降低预测误差34倍。这些结果表示 NN 模型可以实现系统抗衡的预测，并且具有高准确性。这些模型可能在许多重要领域中找到实际应用。
</details></li>
</ul>
<hr>
<h2 id="FunnyBirds-A-Synthetic-Vision-Dataset-for-a-Part-Based-Analysis-of-Explainable-AI-Methods"><a href="#FunnyBirds-A-Synthetic-Vision-Dataset-for-a-Part-Based-Analysis-of-Explainable-AI-Methods" class="headerlink" title="FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods"></a>FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06248">http://arxiv.org/abs/2308.06248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/visinf/funnybirds">https://github.com/visinf/funnybirds</a></li>
<li>paper_authors: Robin Hesse, Simone Schaub-Meyer, Stefan Roth</li>
<li>for:  This paper aims to address the challenge of evaluating the quality of explainable artificial intelligence (XAI) methods, which is an important problem in safety-critical domains where XAI is used.</li>
<li>methods:  The paper proposes a novel synthetic vision dataset called FunnyBirds, as well as accompanying automatic evaluation protocols. The dataset allows for semantically meaningful image interventions, such as removing individual object parts, which enables the analysis of explanations on a part level and the estimation of ground-truth part importances.</li>
<li>results:  The paper reports results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner. The results show that the proposed evaluation protocols can provide valuable insights into the quality of XAI methods and can help to identify areas for improvement.<details>
<summary>Abstract</summary>
The field of explainable artificial intelligence (XAI) aims to uncover the inner workings of complex deep neural models. While being crucial for safety-critical domains, XAI inherently lacks ground-truth explanations, making its automatic evaluation an unsolved problem. We address this challenge by proposing a novel synthetic vision dataset, named FunnyBirds, and accompanying automatic evaluation protocols. Our dataset allows performing semantically meaningful image interventions, e.g., removing individual object parts, which has three important implications. First, it enables analyzing explanations on a part level, which is closer to human comprehension than existing methods that evaluate on a pixel level. Second, by comparing the model output for inputs with removed parts, we can estimate ground-truth part importances that should be reflected in the explanations. Third, by mapping individual explanations into a common space of part importances, we can analyze a variety of different explanation types in a single common framework. Using our tools, we report results for 24 different combinations of neural models and XAI methods, demonstrating the strengths and weaknesses of the assessed methods in a fully automatic and systematic manner.
</details>
<details>
<summary>摘要</summary>
领域的可解释人工智能（XAI）目的是探索复杂的深度神经网络模型的内部工作机制。而这是安全关键领域的关键，但XAI自然lacks ground-truth explanations，这使得自动评估成为一个未解决的问题。我们解决这个挑战 by proposing a novel synthetic vision dataset，名为FunnyBirds，以及一系列自动评估协议。我们的dataset允许进行semantically meaningful的图像交互，例如去除个体物体部分，这有三个重要的含义。首先，它允许分析解释的部级别，这更加接近人类理解的水平 than existing methods that evaluate on a pixel level。第二，通过比较模型输出对各个部分去除后的输出，我们可以估算ground-truth part importances，这些importances应该反映在解释中。第三，将各种解释映射到一个共同的部分重要性空间中，我们可以分析多种不同的解释类型在一个共同框架中。使用我们的工具，我们对24种不同的神经网络模型和XAI方法进行了报告，并demonstrated它们在自动和系统atic的方式下的优劣点。
</details></li>
</ul>
<hr>
<h2 id="Private-Distribution-Learning-with-Public-Data-The-View-from-Sample-Compression"><a href="#Private-Distribution-Learning-with-Public-Data-The-View-from-Sample-Compression" class="headerlink" title="Private Distribution Learning with Public Data: The View from Sample Compression"></a>Private Distribution Learning with Public Data: The View from Sample Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06239">http://arxiv.org/abs/2308.06239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shai Ben-David, Alex Bie, Clément L. Canonne, Gautam Kamath, Vikrant Singhal</li>
<li>for: 本研究考虑了一种名为公共-私有学习的问题，在这种设置下，学习者只能访问公共和私有样本，并且需要根据这些样本来估算一个未知分布$p$的值，同时保证隐私性。</li>
<li>methods: 本研究使用了纯量化隐私学习来保证隐私性，并使用了一种叫做列学习的方法来连接公共-私有学习的问题。</li>
<li>results: 本研究得出了一些新的结论，包括对于任意$k$-mixture的加aussian over $\mathbb R^d$的样本复杂度上界，以及对于agnostic和分布shift抗性的学习者的结论。此外，研究还发现了一个关于公共-私有学习的closure性性质，即对于Gaussian over $\mathbb R^d$，至少需要$d$个公共样本来保证私有学习的隐私性。<details>
<summary>Abstract</summary>
We study the problem of private distribution learning with access to public data. In this setup, which we refer to as public-private learning, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.   We show that the public-private learnability of a class $\mathcal Q$ is connected to the existence of a sample compression scheme for $\mathcal Q$, as well as to an intermediate notion we refer to as list learning. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability under taking mixtures and products of distributions. Finally, via the connection to list learning, we show that for Gaussians in $\mathbb R^d$, at least $d$ public samples are necessary for private learnability, which is close to the known upper bound of $d+1$ public samples.
</details>
<details>
<summary>摘要</summary>
我们研究公共分布学习问题，即在公共数据和私人数据之间的学习问题。在这种设置下，我们称之为公共私人学习。学习者被公共和私人样本所提供，这些样本来自未知分布$p$，属于一个类$\mathcal Q$。学习者的目标是输出一个估计$p$，同时遵守隐私限制（在这种情况下是纯度ifferential privacy）只针对私人样本。我们证明了公共私人学习的可行性与存在一个样本压缩算法，以及一个中间概念——列表学习有关系。通过这种关系，我们可以：1. 约束previous结果中的高斯分布在$\mathbb R^d$上的恢复;2. 导出新的结果，包括$k$-mixture高斯分布在$\mathbb R^d$上的样本复杂性上的Upper bound，以及agnostic和分布shift抗性的学习者的结果。此外，通过与列表学习的连接，我们还证明了对于高斯分布在$\mathbb R^d$上，至少需要$d$个公共样本以便私人学习可行，这与已知的最高bound($d+1$个公共样本)很接近。
</details></li>
</ul>
<hr>
<h2 id="MaxFloodCast-Ensemble-Machine-Learning-Model-for-Predicting-Peak-Inundation-Depth-And-Decoding-Influencing-Features"><a href="#MaxFloodCast-Ensemble-Machine-Learning-Model-for-Predicting-Peak-Inundation-Depth-And-Decoding-Influencing-Features" class="headerlink" title="MaxFloodCast: Ensemble Machine Learning Model for Predicting Peak Inundation Depth And Decoding Influencing Features"></a>MaxFloodCast: Ensemble Machine Learning Model for Predicting Peak Inundation Depth And Decoding Influencing Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06228">http://arxiv.org/abs/2308.06228</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng-Chun Lee, Lipai Huang, Federico Antolini, Matthew Garcia, Andrew Juanb, Samuel D. Brody, Ali Mostafavi</li>
<li>for:  This study aims to provide efficient and interpretable flood inundation depth predictions using a machine learning model, MaxFloodCast, which can support near-time floodplain management and emergency operations.</li>
<li>methods:  The study uses physics-based hydrodynamic simulations to train the MaxFloodCast model, which achieves reliable flood inundation depth predictions with an average R-squared of 0.949 and a Root Mean Square Error of 0.61 ft on unseen data.</li>
<li>results:  The study validates the MaxFloodCast model against Hurricane Harvey and Storm Imelda, demonstrating its potential in supporting flood risk management and emergency operations. The model provides critical information for decision-makers to prioritize areas with critical facilities and to examine how rainfall in other watersheds influences flood exposure in one area.<details>
<summary>Abstract</summary>
Timely, accurate, and reliable information is essential for decision-makers, emergency managers, and infrastructure operators during flood events. This study demonstrates a proposed machine learning model, MaxFloodCast, trained on physics-based hydrodynamic simulations in Harris County, offers efficient and interpretable flood inundation depth predictions. Achieving an average R-squared of 0.949 and a Root Mean Square Error of 0.61 ft on unseen data, it proves reliable in forecasting peak flood inundation depths. Validated against Hurricane Harvey and Storm Imelda, MaxFloodCast shows the potential in supporting near-time floodplain management and emergency operations. The model's interpretability aids decision-makers in offering critical information to inform flood mitigation strategies, to prioritize areas with critical facilities and to examine how rainfall in other watersheds influences flood exposure in one area. The MaxFloodCast model enables accurate and interpretable inundation depth predictions while significantly reducing computational time, thereby supporting emergency response efforts and flood risk management more effectively.
</details>
<details>
<summary>摘要</summary>
时间、准确、可靠的信息是决策者、紧急管理者和基础设施运营员 durante 洪水事件的重要资讯。本研究展示了一个提议的机器学习模型MaxFloodCast，基于物理基础的水动力 simulations在哈里斯县训练，可提供优化和可解释的洪涛深度预测。在未见数据上，它实现了0.949的平均R-squared和0.61 ft的根幂平均误差。这证明了MaxFloodCast在预测洪涛峰值深度方面的可靠性。验证了飓风哈维和飓风Imelda，MaxFloodCast表明它具有支持即时洪平原管理和紧急作业的潜力。模型的解释性帮助决策者提供重要信息，以帮助实施洪水缓解策略，优先级有 kritical 设施区域，并考虑在其他水系中降雨如何影响洪涛暴露在一个区域。MaxFloodCast 模型可提供高精度和解释性的洪涛深度预测，同时大幅降低计算时间，因此更有效地支持紧急回应努力和洪水风险管理。
</details></li>
</ul>
<hr>
<h2 id="Automated-Sizing-and-Training-of-Efficient-Deep-Autoencoders-using-Second-Order-Algorithms"><a href="#Automated-Sizing-and-Training-of-Efficient-Deep-Autoencoders-using-Second-Order-Algorithms" class="headerlink" title="Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms"></a>Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06221">http://arxiv.org/abs/2308.06221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kanishka Tyagi, Chinmay Rane, Michael Manry</li>
<li>for: 这个论文是为了设计一种通用的线性分类器而写的。</li>
<li>methods: 论文使用了一种多步训练方法，包括初始化多类线性分类器、验证错误最小化、提高输出和批量训练算法。</li>
<li>results: 论文通过多步训练和杜邦法听到一个高效的深度学习模型，并且在多个公共数据集上实现了性能提升。<details>
<summary>Abstract</summary>
We propose a multi-step training method for designing generalized linear classifiers. First, an initial multi-class linear classifier is found through regression. Then validation error is minimized by pruning of unnecessary inputs. Simultaneously, desired outputs are improved via a method similar to the Ho-Kashyap rule. Next, the output discriminants are scaled to be net functions of sigmoidal output units in a generalized linear classifier. We then develop a family of batch training algorithm for the multi layer perceptron that optimizes its hidden layer size and number of training epochs. Next, we combine pruning with a growing approach. Later, the input units are scaled to be the net function of the sigmoidal output units that are then feed into as input to the MLP. We then propose resulting improvements in each of the deep learning blocks thereby improving the overall performance of the deep architecture. We discuss the principles and formulation regarding learning algorithms for deep autoencoders. We investigate several problems in deep autoencoders networks including training issues, the theoretical, mathematical and experimental justification that the networks are linear, optimizing the number of hidden units in each layer and determining the depth of the deep learning model. A direct implication of the current work is the ability to construct fast deep learning models using desktop level computational resources. This, in our opinion, promotes our design philosophy of building small but powerful algorithms. Performance gains are demonstrated at each step. Using widely available datasets, the final network's ten fold testing error is shown to be less than that of several other linear, generalized linear classifiers, multi layer perceptron and deep learners reported in the literature.
</details>
<details>
<summary>摘要</summary>
我们提出一种多步训练方法用于设计通用线性分类器。首先，通过回归获得初始多类线性分类器。然后，通过剪枝消除不必要的输入，提高验证错误。同时，通过类似于何-卡希普规则提高 желаем的输出。接着，输出推定器被映射到通用线性分类器中的sigmoid输出单元。我们然后开发了一家批处理训练算法，用于最优化多层感知器的隐藏层大小和训练轮数。接着，我们结合剪枝与增长方法。然后，输入单元被映射到sigmoid输出单元中的net函数。我们最后提出了改进每个深度学习块的结果，从而提高整体深度学习模型的性能。我们讨论了深度学习算法的学习原理和形式，并对深度学习网络中的许多问题进行研究，包括训练问题、理论、数学和实验的正确性。我们的研究表明，通过使用桌面级计算资源，可以快速构建深度学习模型，这与我们的设计哲学相符。我们的实验表明，使用常用的数据集，最终网络的十倍测试错误小于其他线性、通用线性分类器、多层感知器和深度学习者在文献中报道的错误。
</details></li>
</ul>
<hr>
<h2 id="Change-Point-Detection-With-Conceptors"><a href="#Change-Point-Detection-With-Conceptors" class="headerlink" title="Change Point Detection With Conceptors"></a>Change Point Detection With Conceptors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06213">http://arxiv.org/abs/2308.06213</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/noahgade/changepointdetectionwithconceptors">https://github.com/noahgade/changepointdetectionwithconceptors</a></li>
<li>paper_authors: Noah D. Gade, Jordan Rodu</li>
<li>for: 这篇论文主要是为了解决时间序列中数据生成过程发生变化的问题。</li>
<li>methods: 该方法使用一个概念矩阵来学习时间序列的特征动力学，然后通过一个随机回归神经网络来抽象数据，最后通过一个多variate的距离量来确定变化点。</li>
<li>results: 该方法可以提供可靠的变化点估计，并且可以通过Bootstrap方法来生成资料的类型1错误控制。在一些模拟数据和实际数据上测试了该方法，并评估了其性能。<details>
<summary>Abstract</summary>
Offline change point detection seeks to identify points in a time series where the data generating process changes. This problem is well studied for univariate i.i.d. data, but becomes challenging with increasing dimension and temporal dependence. For the at most one change point problem, we propose the use of a conceptor matrix to learn the characteristic dynamics of a specified training window in a time series. The associated random recurrent neural network acts as a featurizer of the data, and change points are identified from a univariate quantification of the distance between the featurization and the space spanned by a representative conceptor matrix. This model agnostic method can suggest potential locations of interest that warrant further study. We prove that, under mild assumptions, the method provides a consistent estimate of the true change point, and quantile estimates for statistics are produced via a moving block bootstrap of the original data. The method is tested on simulations from several classes of processes, and we evaluate performance with clustering metrics, graphical methods, and observed Type 1 error control. We apply our method to publicly available neural data from rats experiencing bouts of non-REM sleep prior to exploration of a radial maze.
</details>
<details>
<summary>摘要</summary>
停机变点检测目标是找到时间序列中数据生成过程中的变化点。这个问题在独立同分布数据上得到了广泛的研究，但是随着维度和时间相关性的增加，这个问题就变得更加挑战。为了解决这个问题，我们提出了一种基于特征动态矩阵的方法。这个矩阵可以学习指定的训练窗口中的特征动态，然后通过一个随机循环神经网络来抽象数据。通过评估这个抽象和特征矩阵所生成的空间之间的距离，我们可以确定变点。这种模型无关的方法可以提供有利于进一步研究的可能性。我们证明，在某些假设下，这种方法可以提供一个一致的变点估计，并且可以通过移动块bootstrap来生成量统计。我们在一些类型的过程的 simulations 上测试了这种方法，并评估了它们的性能使用 clustering 度量、图形方法和观察到的类型一错控制。最后，我们应用了这种方法在公共可用的 neural 数据上，该数据来自于在非 REM 睡眠前的猫鼠在 радиаль 迷宫中的探索。
</details></li>
</ul>
<hr>
<h2 id="Safety-in-Traffic-Management-Systems-A-Comprehensive-Survey"><a href="#Safety-in-Traffic-Management-Systems-A-Comprehensive-Survey" class="headerlink" title="Safety in Traffic Management Systems: A Comprehensive Survey"></a>Safety in Traffic Management Systems: A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06204">http://arxiv.org/abs/2308.06204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlu Du, Ankan Dash, Jing Li, Hua Wei, Guiling Wang</li>
<li>for: 这项研究的目的是为了对交通管理系统中的安全问题进行全面的文献综述，以便更好地了解这些系统的安全问题，并提出解决方案。</li>
<li>methods: 本文使用了文献综述的方法来检查交通管理系统中的安全问题，并分析了现有的研究成果。</li>
<li>results: 本文发现了交通管理系统中的安全问题，包括系统设计缺陷、车辆通信问题、人工意识问题等，并提出了一些解决方案，如使用隐藏马尔文网络、增加人工意识等。同时，本文也指出了现有研究的限制，如缺乏实验数据和难以模拟实际情况等。<details>
<summary>Abstract</summary>
Traffic management systems play a vital role in ensuring safe and efficient transportation on roads. However, the use of advanced technologies in traffic management systems has introduced new safety challenges. Therefore, it is important to ensure the safety of these systems to prevent accidents and minimize their impact on road users. In this survey, we provide a comprehensive review of the literature on safety in traffic management systems. Specifically, we discuss the different safety issues that arise in traffic management systems, the current state of research on safety in these systems, and the techniques and methods proposed to ensure the safety of these systems. We also identify the limitations of the existing research and suggest future research directions.
</details>
<details>
<summary>摘要</summary>
交通管理系统在路面交通安全和效率的问题上扮演着重要的角色。然而，进步的科技应用在交通管理系统中带来了新的安全挑战。因此，确保交通管理系统的安全性是不可或缺的。在这份调查中，我们提供了交通管理系统安全的全面评论。具体来说，我们讨论了交通管理系统中不同的安全问题，现有的研究状况，以及确保这些系统安全的技术和方法。我们还识别出现有的研究限制，并建议未来研究方向。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/cs.LG_2023_08_12/" data-id="cloq1wl7500nn7o8890kghiqz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/12/eess.IV_2023_08_12/" class="article-date">
  <time datetime="2023-08-12T09:00:00.000Z" itemprop="datePublished">2023-08-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/12/eess.IV_2023_08_12/">eess.IV - 2023-08-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Semantic-Communications-with-Explicit-Semantic-Base-for-Image-Transmission"><a href="#Semantic-Communications-with-Explicit-Semantic-Base-for-Image-Transmission" class="headerlink" title="Semantic Communications with Explicit Semantic Base for Image Transmission"></a>Semantic Communications with Explicit Semantic Base for Image Transmission</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06599">http://arxiv.org/abs/2308.06599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Zheng, Fengyu Wang, Wenjun Xu, Miao Pan, Ping Zhang</li>
<li>for: 提高下一代通信系统的可靠性和效率，通过增强信息的意义表示和同步。</li>
<li>methods: 提出一个基于显式 semantics 基础 (Seb) 的Semantic 图像传输框架，通过自适应的 Seb 生成和应用来实现图像的表示和传输。</li>
<li>results: 对比州的实验结果显示，提出的框架可以与现有的方法相比，在不同的信号噪含率 (SNR) 下提高 peak signal-to-noise ratio (PSNR) 的表现，提高图像的重建精度。<details>
<summary>Abstract</summary>
Semantic communications, aiming at ensuring the successful delivery of the meaning of information, are expected to be one of the potential techniques for the next generation communications. However, the knowledge forming and synchronizing mechanism that enables semantic communication systems to extract and interpret the semantics of information according to the communication intents is still immature. In this paper, we propose a semantic image transmission framework with explicit semantic base (Seb), where Sebs are generated and employed as the knowledge shared between the transmitter and the receiver with flexible granularity. To represent images with Sebs, a novel Seb-based reference image generator is proposed to generate Sebs and then decompose the transmitted images. To further encode/decode the residual information for precise image reconstruction, a Seb-based image encoder/decoder is proposed. The key components of the proposed framework are optimized jointly by end-to-end (E2E) training, where the loss function is dedicated designed to tackle the problem of nondifferentiable operation in Seb-based reference image generator by introducing a gradient approximation mechanism. Extensive experiments show that the proposed framework outperforms state-of-art works by 0.5 - 1.5 dB in peak signal-to-noise ratio (PSNR) w.r.t. different signal-to-noise ratio (SNR).
</details>
<details>
<summary>摘要</summary>
semantic 通信技术，预计将成为下一代通信技术的一个 potential 方向，但现有的知识形成和同步机制仍然是幼稚的。本文提出了一种具有显式semantic base（Seb）的semantic 图像传输框架，其中Sebs是在传输和接收方之间共享的知识，并可以在不同的粒度水平进行flexible 分配。为了将图像表示为Sebs，本文提出了一种新的Seb-based reference image generator，该generator可以生成Sebs并将传输的图像进行解码。另外，为了进一步编码/解码剩余信息以实现精确的图像重建，本文提出了一种基于Seb的图像编码器/解码器。关键组件的优化由综合（E2E）训练进行，loss函数通过引入梯度近似机制来解决Seb-based reference image generator中的非导数操作问题。实验表明，提议的框架可以与当前最佳性能相比提高0.5-1.5 dB的峰值信号噪声比（PSNR）。
</details></li>
</ul>
<hr>
<h2 id="On-Versatile-Video-Coding-at-UHD-with-Machine-Learning-Based-Super-Resolution"><a href="#On-Versatile-Video-Coding-at-UHD-with-Machine-Learning-Based-Super-Resolution" class="headerlink" title="On Versatile Video Coding at UHD with Machine-Learning-Based Super-Resolution"></a>On Versatile Video Coding at UHD with Machine-Learning-Based Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06570">http://arxiv.org/abs/2308.06570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kristian Fischer, Christian Herglotz, André Kaup</li>
<li>for: 提高4K数据编码质量</li>
<li>methods: 使用Machine Learning基于单图超解算法和下一代VVC编码器</li>
<li>results: 可以获得12%~18%的Bjontegaard delta rate增加，并减少 compression artifacts 和loss of detailsHere’s a breakdown of each point:</li>
<li>for: 这篇论文是为了提高4K数据的编码质量而写的。</li>
<li>methods: 这篇论文使用了Machine Learning基于单图超解算法和下一代VVC编码器。</li>
<li>results: 根据论文的测试结果，可以获得12%~18%的Bjontegaard delta rate增加，同时减少 compression artifacts 和loss of details。<details>
<summary>Abstract</summary>
Coding 4K data has become of vital interest in recent years, since the amount of 4K data is significantly increasing. We propose a coding chain with spatial down- and upscaling that combines the next-generation VVC codec with machine learning based single image super-resolution algorithms for 4K. The investigated coding chain, which spatially downscales the 4K data before coding, shows superior quality than the conventional VVC reference software for low bitrate scenarios. Throughout several tests, we find that up to 12 % and 18 % Bjontegaard delta rate gains can be achieved on average when coding 4K sequences with VVC and QP values above 34 and 42, respectively. Additionally, the investigated scenario with up- and downscaling helps to reduce the loss of details and compression artifacts, as it is shown in a visual example.
</details>
<details>
<summary>摘要</summary>
coding 4K 数据已成为近年来的焦点，因为4K 数据量在不断增加。我们提议一种具有空间下采样和上采样的编码链，该链 combining 下一代 VVC 编码器和基于机器学习的单张图像超解算法，用于4K。我们的调查显示，将4K 数据先下采样后编码，可以在低比特率场景下实现较高的质量。在多个测试中，我们发现，使用 VVC 和 QP 值高于 34 和 42 时，可以实现平均 12% 到 18% Bjontegaard Delta 率增加。此外，我们发现，将数据上下采样可以降低数据的丢失细节和压缩artefacts，如图像示例所示。Note: "Bjontegaard delta rate" refers to the difference between the peak signal-to-noise ratio (PSNR) of the original and reconstructed signals, which is a common measure of the quality of video compression. A lower Bjontegaard delta rate indicates better compression quality.
</details></li>
</ul>
<hr>
<h2 id="Three-dimensional-echo-shifted-EPI-with-simultaneous-blip-up-and-blip-down-acquisitions-for-correcting-geometric-distortion"><a href="#Three-dimensional-echo-shifted-EPI-with-simultaneous-blip-up-and-blip-down-acquisitions-for-correcting-geometric-distortion" class="headerlink" title="Three-dimensional echo-shifted EPI with simultaneous blip-up and blip-down acquisitions for correcting geometric distortion"></a>Three-dimensional echo-shifted EPI with simultaneous blip-up and blip-down acquisitions for correcting geometric distortion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06557">http://arxiv.org/abs/2308.06557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaibao Sun, Zhifeng Chen, Guangyu Dan, Qingfei Luo, Lirong Yan, Feng Liu, Xiaohong Joe Zhou<br>For:* 这个研究旨在超越BUDA doublescan时间和降低功能MRI应用中的挑战，通过开发一种三维echo-shifted EPI BUDA（esEPI-BUDA）技术，以获得单shot中获得两个blip-up和blip-down数据集。Methods:* 这种三维esEPI-BUDA序列使用了一种echo-shifting策略，生成了两个EPI读取车的读取信号。这两个读取信号的k-空间轨迹相互交叠，并且使用了opposite phase-encoding gradient方向。这两个k-空间数据集分别使用3D SENSE算法重建，并生成了时间解决B0-场图像。Results:* 在一个phantom和一个人类大脑图像研究中，这种3D esEPI-BUDA技术可以有效地纠正几何扭曲。在人类大脑图像中，可以看到视觉激活区和其BOLD响应，与普通3D echo-planar图像相似。<details>
<summary>Abstract</summary>
Purpose: Echo-planar imaging (EPI) with blip-up/down acquisition (BUDA) can provide high-quality images with minimal distortions by using two readout trains with opposing phase-encoding gradients. Because of the need for two separate acquisitions, BUDA doubles the scan time and degrades the temporal resolution when compared to single-shot EPI, presenting a major challenge for many applications, particularly functional MRI (fMRI). This study aims at overcoming this challenge by developing an echo-shifted EPI BUDA (esEPI-BUDA) technique to acquire both blip-up and blip-down datasets in a single shot. Methods: A three-dimensional (3D) esEPI-BUDA pulse sequence was designed by using an echo-shifting strategy to produce two EPI readout trains. These readout trains produced a pair of k-space datasets whose k-space trajectories were interleaved with opposite phase-encoding gradient directions. The two k-space datasets were separately reconstructed using a 3D SENSE algorithm, from which time-resolved B0-field maps were derived using TOPUP in FSL and then input into a forward model of joint parallel imaging reconstruction to correct for geometric distortion. In addition, Hankel structured low-rank constraint was incorporated into the reconstruction framework to improve image quality by mitigating the phase errors between the two interleaved k-space datasets. Results: The 3D esEPI-BUDA technique was demonstrated in a phantom and an fMRI study on healthy human subjects. Geometric distortions were effectively corrected in both phantom and human brain images. In the fMRI study, the visual activation volumes and their BOLD responses were comparable to those from conventional 3D echo-planar images. Conclusion: The improved imaging efficiency and dynamic distortion correction capability afforded by 3D esEPI-BUDA are expected to benefit many EPI applications.
</details>
<details>
<summary>摘要</summary>
目的：使用电平扫描（EPI）和折叠/下降获取（BUDA）技术可以提供高质量图像，并且减少了图像扭曲。然而，由于需要两个分离的获取，BUDA将扫描时间 Doubles和功能磁共振成像（fMRI）等应用中的时间分辨率下降为主要挑战。本研究旨在解决这个挑战，通过开发一种三维电平扫描BUDA（esEPI-BUDA）技术，以获取一个单击数据集。方法：使用电平扫描扩展策略，生成两个EPI读取列。这两个读取列在干扰方向上具有相反的频率编码梯度。这两个k空间数据集分别使用3D SENSE算法重建，并使用FSL中的TOPUP算法生成时间相关的B0场图。然后，将这些图像输入到一种前向模型，以正确地修正几何错误。此外，在重建框架中添加了具有Hankel结构的低级别约束，以提高图像质量，减少相位错误。结果：在荚体和人类大脑图像中，使用3D esEPI-BUDA技术可以有效地纠正几何错误。在fMRI研究中，观察到的视觉激活体和其BOLD响应与普通3D电平扫描图像相同。结论：3D esEPI-BUDA技术的改进的扫描效率和动态几何纠正能力，预期会对许多EPI应用产生积极的影响。
</details></li>
</ul>
<hr>
<h2 id="The-Color-Clifford-Hardy-Signal-Application-to-Color-Edge-Detection-and-Optical-Flow"><a href="#The-Color-Clifford-Hardy-Signal-Application-to-Color-Edge-Detection-and-Optical-Flow" class="headerlink" title="The Color Clifford Hardy Signal: Application to Color Edge Detection and Optical Flow"></a>The Color Clifford Hardy Signal: Application to Color Edge Detection and Optical Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06485">http://arxiv.org/abs/2308.06485</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoxiao Hu, Kit Ian Kou, Cuiming Zou, Dong Cheng</li>
<li>for: This paper introduces a new approach to processing color images using the color Clifford Hardy signal, which is a high-dimensional analytic function.</li>
<li>methods: The paper proposes five methods for edge detection in color images based on the local feature representation of the color Clifford Hardy signal. These methods utilize the multi-scale structure of the signal to resist noise and improve edge detection accuracy.</li>
<li>results: The proposed methods are evaluated using image quality assessment criteria and are shown to be superior to traditional edge detection methods in terms of robustness to noise and accuracy. Additionally, an example application of color optical flow detection using the proposed approach is provided.<details>
<summary>Abstract</summary>
This paper introduces the idea of the color Clifford Hardy signal, which can be used to process color images. As a complex analytic function's high-dimensional analogue, the color Clifford Hardy signal inherits many desirable qualities of analyticity. A crucial tool for getting the color and structural data is the local feature representation of a color image in the color Clifford Hardy signal. By looking at the extended Cauchy-Riemann equations in the high-dimensional space, it is possible to see the connection between the different parts of the color Clifford Hardy signal. Based on the distinctive and important local amplitude and local phase generated by the color Clifford Hardy signal, we propose five methods to identify the edges of color images with relation to a certain color. To prove the superiority of the offered methodologies, numerous comparative studies employing image quality assessment criteria are used. Specifically by using the multi-scale structure of the color Clifford Hardy signal, the proposed approaches are resistant to a variety of noises. In addition, a color optical flow detection method with anti-noise ability is provided as an example of application.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Out-of-distribution-multi-view-auto-encoders-for-prostate-cancer-lesion-detection"><a href="#Out-of-distribution-multi-view-auto-encoders-for-prostate-cancer-lesion-detection" class="headerlink" title="Out-of-distribution multi-view auto-encoders for prostate cancer lesion detection"></a>Out-of-distribution multi-view auto-encoders for prostate cancer lesion detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06481">http://arxiv.org/abs/2308.06481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alvaro Fernandez-Quilez, Linas Vidziunas, Ørjan Kløvfjell Thoresen, Ketil Oppedal, Svein Reidar Kjosavik, Trygve Eftestøl</li>
<li>for: 这个研究旨在提出一种基于不监督学习的医学领域深度学习方法，以减少罕见的标注数据。</li>
<li>methods: 我们提出了一种多流水平方法，可以处理不同的T2w方向，以提高肝癌液体检测的性能。</li>
<li>results: 我们在公开可用的数据集上评估了我们的方法，与单向方法相比，我们的方法实现了更好的检测结果（AUC&#x3D;82.3%）。<details>
<summary>Abstract</summary>
Traditional deep learning (DL) approaches based on supervised learning paradigms require large amounts of annotated data that are rarely available in the medical domain. Unsupervised Out-of-distribution (OOD) detection is an alternative that requires less annotated data. Further, OOD applications exploit the class skewness commonly present in medical data. Magnetic resonance imaging (MRI) has proven to be useful for prostate cancer (PCa) diagnosis and management, but current DL approaches rely on T2w axial MRI, which suffers from low out-of-plane resolution. We propose a multi-stream approach to accommodate different T2w directions to improve the performance of PCa lesion detection in an OOD approach. We evaluate our approach on a publicly available data-set, obtaining better detection results in terms of AUC when compared to a single direction approach (73.1 vs 82.3). Our results show the potential of OOD approaches for PCa lesion detection based on MRI.
</details>
<details>
<summary>摘要</summary>
传统的深度学习（DL）方法基于指导学习思想需要庞大量的标注数据，而医疗领域中这些数据很少。无监管 OUT-OF-DISTRIBUTION（OOD）检测是一种alternative，它需要 fewer annotated data。另外，OOD应用可以利用医学数据中的类倾斜。核磁共振成像（MRI）已经被证明是肠癌（PCa）诊断和管理的有用工具，但现有的DL方法仅仅利用T2w极向MRI，这种MRIuffer from low out-of-plane resolution。我们提议一种多流处理方法，以便同时处理不同的T2w方向，以提高PCa涂抹检测的性能。我们在公共可用数据集上评估了我们的方法，并与单向方法（73.1）进行比较，得到了更好的检测结果（AUC），即82.3。我们的结果表明，基于MRI的PCa涂抹检测可以通过OOD方法实现更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-multi-view-data-without-annotations-for-prostate-MRI-segmentation-A-contrastive-approach"><a href="#Leveraging-multi-view-data-without-annotations-for-prostate-MRI-segmentation-A-contrastive-approach" class="headerlink" title="Leveraging multi-view data without annotations for prostate MRI segmentation: A contrastive approach"></a>Leveraging multi-view data without annotations for prostate MRI segmentation: A contrastive approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06477">http://arxiv.org/abs/2308.06477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Nikolass Lindeijer, Tord Martin Ytredal, Trygve Eftestøl, Tobias Nordström, Fredrik Jäderling, Martin Eklund, Alvaro Fernandez-Quilez</li>
<li>for: 这个研究的目的是提高自动脑下对肾脏的分类和量化描述，以支持肾脏癌病的诊断。</li>
<li>methods: 这个研究使用了一种对照方法，即在训练时使用多个检测方向的数据，并且不需要手动标注。</li>
<li>results: 研究结果显示，使用对照方法可以提高肾脏分类的精确度，并且在不同的检测方向下实现了较好的一致性。<details>
<summary>Abstract</summary>
An accurate prostate delineation and volume characterization can support the clinical assessment of prostate cancer. A large amount of automatic prostate segmentation tools consider exclusively the axial MRI direction in spite of the availability as per acquisition protocols of multi-view data. Further, when multi-view data is exploited, manual annotations and availability at test time for all the views is commonly assumed. In this work, we explore a contrastive approach at training time to leverage multi-view data without annotations and provide flexibility at deployment time in the event of missing views. We propose a triplet encoder and single decoder network based on U-Net, tU-Net (triplet U-Net). Our proposed architecture is able to exploit non-annotated sagittal and coronal views via contrastive learning to improve the segmentation from a volumetric perspective. For that purpose, we introduce the concept of inter-view similarity in the latent space. To guide the training, we combine a dice score loss calculated with respect to the axial view and its manual annotations together with a multi-view contrastive loss. tU-Net shows statistical improvement in dice score coefficient (DSC) with respect to only axial view (91.25+-0.52% compared to 86.40+-1.50%,P<.001). Sensitivity analysis reveals the volumetric positive impact of the contrastive loss when paired with tU-Net (2.85+-1.34% compared to 3.81+-1.88%,P<.001). Further, our approach shows good external volumetric generalization in an in-house dataset when tested with multi-view data (2.76+-1.89% compared to 3.92+-3.31%,P=.002), showing the feasibility of exploiting non-annotated multi-view data through contrastive learning whilst providing flexibility at deployment in the event of missing views.
</details>
<details>
<summary>摘要</summary>
<<sys.translation.skip>>精准的肾脏定位和体积特征化可以支持肾脏癌诊断。大量自动肾脏分割工具忽略了多视图数据的可用性，即使据获取协议可以获得多视图数据。此外，当使用多视图数据时，手动标注和测试时 disponibility 通常被假设。在这种情况下，我们提出了一种对比方法，使得在训练时可以利用多视图数据无需标注，并在部署时提供灵活性。我们提出了一种基于 U-Net 的 triplet 编码器和单个解码器网络，我们称之为 tU-Net（ triplet U-Net）。我们的提议的架构可以通过对不同视图的对比学习利用非标注的 sagittal 和横截视图来提高分割。为此，我们引入了视图间相似性的概念在幂空间。为了导航训练，我们将 dice 分数损失与AXIAL 视图和其手动标注相加，并与多视图对比损失相结合。 tU-Net 显示在 DSC 系数上有统计学上的提升（91.25+-0.52% 相比 86.40+-1.50%,P<.001）。敏感分析表明，对于 tU-Net 来说，对比损失的负面影响是可观的（2.85+-1.34% 相比 3.81+-1.88%,P<.001）。此外，我们的方法在我们的内部数据集中表现了良好的外部Volumetric 普适性（2.76+-1.89% 相比 3.92+-3.31%,P=.002），这表明了可以通过对比学习利用非标注多视图数据，并在部署时提供灵活性。
</details></li>
</ul>
<hr>
<h2 id="CATS-v2-Hybrid-encoders-for-robust-medical-segmentation"><a href="#CATS-v2-Hybrid-encoders-for-robust-medical-segmentation" class="headerlink" title="CATS v2: Hybrid encoders for robust medical segmentation"></a>CATS v2: Hybrid encoders for robust medical segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06377">http://arxiv.org/abs/2308.06377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoli12345/cats">https://github.com/haoli12345/cats</a></li>
<li>paper_authors: Hao Li, Han Liu, Dewei Hu, Xing Yao, Jiacheng Wang, Ipek Oguz<br>for:This paper proposes a new method for 3D medical image segmentation, specifically for vestibular schwannoma (VS) and prostate segmentation.methods:The proposed method uses a hybrid encoder consisting of a CNN-based encoder path and a transformer path with a shifted window to leverage both local and global information.results:The proposed method demonstrates superior performance in terms of higher Dice scores compared to state-of-the-art methods on two public challenge datasets (CrossMoDA and MSD-5) for VS and prostate segmentation.<details>
<summary>Abstract</summary>
Convolutional Neural Networks (CNNs) have exhibited strong performance in medical image segmentation tasks by capturing high-level (local) information, such as edges and textures. However, due to the limited field of view of convolution kernel, it is hard for CNNs to fully represent global information. Recently, transformers have shown good performance for medical image segmentation due to their ability to better model long-range dependencies. Nevertheless, transformers struggle to capture high-level spatial features as effectively as CNNs. A good segmentation model should learn a better representation from local and global features to be both precise and semantically accurate. In our previous work, we proposed CATS, which is a U-shaped segmentation network augmented with transformer encoder. In this work, we further extend this model and propose CATS v2 with hybrid encoders. Specifically, hybrid encoders consist of a CNN-based encoder path paralleled to a transformer path with a shifted window, which better leverage both local and global information to produce robust 3D medical image segmentation. We fuse the information from the convolutional encoder and the transformer at the skip connections of different resolutions to form the final segmentation. The proposed method is evaluated on two public challenge datasets: Cross-Modality Domain Adaptation (CrossMoDA) and task 5 of Medical Segmentation Decathlon (MSD-5), to segment vestibular schwannoma (VS) and prostate, respectively. Compared with the state-of-the-art methods, our approach demonstrates superior performance in terms of higher Dice scores.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在医学图像分割任务中表现出色，通过捕捉高级（本地）信息，如边缘和文本ure。然而，由于卷积核心的视野有限，使得CNN难以完全表征全局信息。而在最近的几年，转移器在医学图像分割中表现良好，这是因为它们可以更好地模型长距离依赖关系。然而，转移器在捕捉高级空间特征方面表现不如CNN一样好。一个好的分割模型应该学习更好的表示本地和全局特征，以便具有高精度和Semantic Accuracy。在我们之前的工作中，我们提出了CATS，它是一个U型分割网络，其中包括转移器编码器。在这个工作中，我们进一步扩展了这个模型，并提出了CATS v2，其中包括混合编码器。特别是，混合编码器包括一个基于CNN的编码器路径和一个偏移窗口的转移器路径，这些路径都可以更好地利用本地和全局信息，以生成Robust 3D医学图像分割。我们在不同分辨率的 skip 连接中 fusion 了 convolutional 编码器和转移器的信息，以生成最终的分割。我们的方法在 Cross-Modality Domain Adaptation（CrossMoDA）和 Medical Segmentation Decathlon（MSD-5）两个公共挑战数据集上进行评估，用于分割 vestibular schwannoma（VS）和肾脏，分别。与当前状态艺术方法相比，我们的方法在 dice 分数上表现出优于其他方法。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Open-Source-Toolkit-for-Eosinophil-Detection-in-Pediatric-Eosinophilic-Esophagitis"><a href="#Deep-Learning-Based-Open-Source-Toolkit-for-Eosinophil-Detection-in-Pediatric-Eosinophilic-Esophagitis" class="headerlink" title="Deep Learning-Based Open Source Toolkit for Eosinophil Detection in Pediatric Eosinophilic Esophagitis"></a>Deep Learning-Based Open Source Toolkit for Eosinophil Detection in Pediatric Eosinophilic Esophagitis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06333">http://arxiv.org/abs/2308.06333</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hrlblab/open-eoe">https://github.com/hrlblab/open-eoe</a></li>
<li>paper_authors: Juming Xiong, Yilin Liu, Ruining Deng, Regina N Tyree, Hernan Correa, Girish Hiremath, Yaohong Wang, Yuankai Huo<br>for: 这个研究是为了开发一个开源的工具集（Open-EoE），用于检测食道检查图像（Whole Slide Image，WSI）中的嗜酸细胞（Eos）。methods: 该工具集使用三种state-of-the-art深度学习基于对象检测模型，并实现了一种 ensemble learning 策略以提高性能。results: 实验结果表明，Open-EoE 工具集可以有效地检测食道检查图像中的嗜酸细胞，并达到了91%的准确率，与专业病理学家的评估相一致。<details>
<summary>Abstract</summary>
Eosinophilic Esophagitis (EoE) is a chronic, immune/antigen-mediated esophageal disease, characterized by symptoms related to esophageal dysfunction and histological evidence of eosinophil-dominant inflammation. Owing to the intricate microscopic representation of EoE in imaging, current methodologies which depend on manual identification are not only labor-intensive but also prone to inaccuracies. In this study, we develop an open-source toolkit, named Open-EoE, to perform end-to-end whole slide image (WSI) level eosinophil (Eos) detection using one line of command via Docker. Specifically, the toolkit supports three state-of-the-art deep learning-based object detection models. Furthermore, Open-EoE further optimizes the performance by implementing an ensemble learning strategy, and enhancing the precision and reliability of our results. The experimental results demonstrated that the Open-EoE toolkit can efficiently detect Eos on a testing set with 289 WSIs. At the widely accepted threshold of >= 15 Eos per high power field (HPF) for diagnosing EoE, the Open-EoE achieved an accuracy of 91%, showing decent consistency with pathologist evaluations. This suggests a promising avenue for integrating machine learning methodologies into the diagnostic process for EoE. The docker and source code has been made publicly available at https://github.com/hrlblab/Open-EoE.
</details>
<details>
<summary>摘要</summary>
《营养细胞性食管炎（EoE）》是一种慢性、免疫/抗原识别的食管疾病，表现为食管功能障碍和 histological 证明中充满嗜铁细胞的inflammation。由于诊断EoE的微scopic representation在成像中复杂，现有的方法ologies都是人工识别，不仅劳动密集，还容易出错。在这项研究中，我们开发了一个开源工具包，名为Open-EoE，通过一行命令via Docker进行整个报告图像（WSI）层级的嗜铁细胞（Eos）检测。具体来说，工具支持三种当前顶尖的深度学习基于对象检测模型。此外，Open-EoE还进一步优化了性能，通过实现 ensemble learning 策略，提高了结果的精度和可靠性。实验结果表明，Open-EoE 工具包可以有效地检测289张WSIs中的嗜铁细胞。在 widely accepted 的 >= 15 Eos per high power field（HPF）的标准reshold上，Open-EoE 达到了91%的准确率，与Pathologist 评估相当一致。这表明了机器学习方法的可能性在EoE 诊断过程中的应用。docker 和源代码已经公开发布在https://github.com/hrlblab/Open-EoE。
</details></li>
</ul>
<hr>
<h2 id="Revolutionizing-Space-Health-Swin-FSR-Advancing-Super-Resolution-of-Fundus-Images-for-SANS-Visual-Assessment-Technology"><a href="#Revolutionizing-Space-Health-Swin-FSR-Advancing-Super-Resolution-of-Fundus-Images-for-SANS-Visual-Assessment-Technology" class="headerlink" title="Revolutionizing Space Health (Swin-FSR): Advancing Super-Resolution of Fundus Images for SANS Visual Assessment Technology"></a>Revolutionizing Space Health (Swin-FSR): Advancing Super-Resolution of Fundus Images for SANS Visual Assessment Technology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06332">http://arxiv.org/abs/2308.06332</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FarihaHossain/SwinFSR">https://github.com/FarihaHossain/SwinFSR</a></li>
<li>paper_authors: Khondker Fariha Hossain, Sharif Amit Kamran, Joshua Ong, Andrew G. Lee, Alireza Tavakkoli<br>for:This paper is written for the purpose of developing a novel model for fundus image super-resolution, specifically using Swin Transformer with spatial and depth-wise attention.methods:The paper utilizes a novel model called Swin-FSR, which combines Swin Transformer with spatial and depth-wise attention for fundus image super-resolution.results:The paper achieves Peak signal-to-noise-ratio (PSNR) of 47.89, 49.00 and 45.32 on three public datasets, namely iChallenge-AMD, iChallenge-PM, and G1020. Additionally, the model showed comparable results on a privately held dataset for Spaceflight-associated Neuro-ocular Syndrome (SANS) provided by NASA.<details>
<summary>Abstract</summary>
The rapid accessibility of portable and affordable retinal imaging devices has made early differential diagnosis easier. For example, color funduscopy imaging is readily available in remote villages, which can help to identify diseases like age-related macular degeneration (AMD), glaucoma, or pathological myopia (PM). On the other hand, astronauts at the International Space Station utilize this camera for identifying spaceflight-associated neuro-ocular syndrome (SANS). However, due to the unavailability of experts in these locations, the data has to be transferred to an urban healthcare facility (AMD and glaucoma) or a terrestrial station (e.g, SANS) for more precise disease identification. Moreover, due to low bandwidth limits, the imaging data has to be compressed for transfer between these two places. Different super-resolution algorithms have been proposed throughout the years to address this. Furthermore, with the advent of deep learning, the field has advanced so much that x2 and x4 compressed images can be decompressed to their original form without losing spatial information. In this paper, we introduce a novel model called Swin-FSR that utilizes Swin Transformer with spatial and depth-wise attention for fundus image super-resolution. Our architecture achieves Peak signal-to-noise-ratio (PSNR) of 47.89, 49.00 and 45.32 on three public datasets, namely iChallenge-AMD, iChallenge-PM, and G1020. Additionally, we tested the model's effectiveness on a privately held dataset for SANS provided by NASA and achieved comparable results against previous architectures.
</details>
<details>
<summary>摘要</summary>
随着可携式和Affordable的Retinal imaging设备的快速访问，早期差异诊断变得更加容易。例如，颜色基准摄影是在偏远村庄中ready available，可以 помо助于诊断年龄相关的macular degeneration（AMD）、 glaucoma 或pathological myopia（PM）等疾病。然而，由于这些地点缺乏专家，因此数据必须被传输到城市医疗机构（AMD和glaucoma）或者地球站（例如，SANS）进行更加精确的疾病诊断。此外，由于带宽限制，摄影数据必须进行压缩传输。过去的多年来，不同的超分辨率算法已经被提出来解决这个问题。此外，随着深度学习的出现，这一领域已经进步到了非常高的水平，可以使x2和x4压缩的图像得到原始形态的还原，无需失去空间信息。在本文中，我们提出了一种新的模型called Swin-FSR，该模型利用SwinTransformer和空间和深度精度注意力来进行fundus图像超分辨率。我们的架构实现了Peak signal-to-noise-ratio（PSNR）的47.89、49.00和45.32在三个公共数据集上，即iChallenge-AMD、iChallenge-PM和G1020。此外，我们对NASA提供的一个私人保持的SANS数据集进行测试，并与之前的建筑物实现了相似的结果。
</details></li>
</ul>
<hr>
<h2 id="A-Hierarchical-Descriptor-Framework-for-On-the-Fly-Anatomical-Location-Matching-between-Longitudinal-Studies"><a href="#A-Hierarchical-Descriptor-Framework-for-On-the-Fly-Anatomical-Location-Matching-between-Longitudinal-Studies" class="headerlink" title="A Hierarchical Descriptor Framework for On-the-Fly Anatomical Location Matching between Longitudinal Studies"></a>A Hierarchical Descriptor Framework for On-the-Fly Anatomical Location Matching between Longitudinal Studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07337">http://arxiv.org/abs/2308.07337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Halid Ziya Yerebakan, Yoshihisa Shinagawa, Mahesh Ranganath, Simon Allen-Raffl, Gerardo Hermosillo Valadez</li>
<li>for: 医疗影像比较 longitudinal 比较中的相似性匹配</li>
<li>methods: 基于 hierarchical sparse sampling 的描述子计算和 hierarchical 搜索</li>
<li>results: 减少计算时间至毫秒级别，无需依赖于预训练、重新映射或多模态转换，并且在 Deep Lesion Tracking 数据集上达到更高的匹配精度，比最精确的算法 faster 24 倍。<details>
<summary>Abstract</summary>
We propose a method to match anatomical locations between pairs of medical images in longitudinal comparisons. The matching is made possible by computing a descriptor of the query point in a source image based on a hierarchical sparse sampling of image intensities that encode the location information. Then, a hierarchical search operation finds the corresponding point with the most similar descriptor in the target image. This simple yet powerful strategy reduces the computational time of mapping points to a millisecond scale on a single CPU. Thus, radiologists can compare similar anatomical locations in near real-time without requiring extra architectural costs for precomputing or storing deformation fields from registrations. Our algorithm does not require prior training, resampling, segmentation, or affine transformation steps. We have tested our algorithm on the recently published Deep Lesion Tracking dataset annotations. We observed more accurate matching compared to Deep Lesion Tracker while being 24 times faster than the most precise algorithm reported therein. We also investigated the matching accuracy on CT and MR modalities and compared the proposed algorithm's accuracy against ground truth consolidated from multiple radiologists.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，用于在医疗影像序列中匹配 анатомиче位置。该方法基于源图像中查询点的Descriptor，该Descriptor通过 hierarchical sparse sampling 图像强度编码位置信息来计算。然后，使用 hierarchical 搜索操作找到目标图像中最相似的点。这种简单 yet powerful 策略可以在单个 CPU 上减少计算时间到毫秒级，因此 radiologist 可以在实时比较相似的 анатомиче位置，不需要额外的建筑成本或存储投影场景的预处理或存储步骤。我们的算法不需要先行训练、重新采样、分割或 affine 变换步骤。我们在 Deep Lesion Tracking 数据集注释中进行了测试，并观察到比 Deep Lesion Tracker 更高的匹配精度，同时比最精确的算法reported therein 24 倍快。我们还对 CT 和 MR 模式进行了匹配精度的研究，并与多名医生共同合理的ground truth 进行了比较。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/12/eess.IV_2023_08_12/" data-id="cloq1wldz01527o887x50flbq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/11/cs.SD_2023_08_11/" class="article-date">
  <time datetime="2023-08-11T15:00:00.000Z" itemprop="datePublished">2023-08-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/11/cs.SD_2023_08_11/">cs.SD - 2023-08-11</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Improving-Joint-Speech-Text-Representations-Without-Alignment"><a href="#Improving-Joint-Speech-Text-Representations-Without-Alignment" class="headerlink" title="Improving Joint Speech-Text Representations Without Alignment"></a>Improving Joint Speech-Text Representations Without Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06125">http://arxiv.org/abs/2308.06125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cal Peyser, Zhong Meng, Ke Hu, Rohit Prabhavalkar, Andrew Rosenberg, Tara N. Sainath, Michael Picheny, Kyunghyun Cho</li>
<li>for: 这个论文旨在探讨文本描述生成中的字段表示空间，以及如何在这个空间中同时表示文本和语音。</li>
<li>methods: 这个论文使用了联合语音文本编码器，通过将语音和文本域合并到一起，以大参数模型的能力为基础。这些方法显示了搭配性，但需要特殊地处理语音和文本序列长度的差异。</li>
<li>results: 这个论文提供了证据表明联合语音文本编码器可以自然地实现多媒体表示的一致性，并且可以通过抛弃序列长度来避免对预测的影响。这种损失可以提高下游WR的性能，包括大参数单语言和多语言系统。<details>
<summary>Abstract</summary>
The last year has seen astonishing progress in text-prompted image generation premised on the idea of a cross-modal representation space in which the text and image domains are represented jointly. In ASR, this idea has found application as joint speech-text encoders that can scale to the capacities of very large parameter models by being trained on both unpaired speech and text. While these methods show promise, they have required special treatment of the sequence-length mismatch inherent in speech and text, either by up-sampling heuristics or an explicit alignment model. In this work, we offer evidence that joint speech-text encoders naturally achieve consistent representations across modalities by disregarding sequence length, and argue that consistency losses could forgive length differences and simply assume the best alignment. We show that such a loss improves downstream WER in both a large-parameter monolingual and multilingual system.
</details>
<details>
<summary>摘要</summary>
最近一年内，文本引导图像生成技术呈现出惊人的进步，基于跨Modal Representation空间的想法，在文本和图像领域 jointly 表示。在ASR中，这个想法得到应用，实现了合并语音和文本的encoder，可以通过训练大参数模型来扩大 capacities。虽然这些方法显示了承诺，但它们需要特殊地处理语音和文本的序列长度差异，可能通过上折表示或者显式对齐模型。在这项工作中，我们提供了证据，表明联合语音和文本encoder可以自然地实现多modalities的一致表示，并且提议使用一致损失来补偿序列长度差异。我们展示了这种损失可以提高下游WER，包括大参数训练的单语言和多语言系统。
</details></li>
</ul>
<hr>
<h2 id="Lip2Vec-Efficient-and-Robust-Visual-Speech-Recognition-via-Latent-to-Latent-Visual-to-Audio-Representation-Mapping"><a href="#Lip2Vec-Efficient-and-Robust-Visual-Speech-Recognition-via-Latent-to-Latent-Visual-to-Audio-Representation-Mapping" class="headerlink" title="Lip2Vec: Efficient and Robust Visual Speech Recognition via Latent-to-Latent Visual to Audio Representation Mapping"></a>Lip2Vec: Efficient and Robust Visual Speech Recognition via Latent-to-Latent Visual to Audio Representation Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06112">http://arxiv.org/abs/2308.06112</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasser Abdelaziz Dahou Djilali, Sanath Narayan, Haithem Boussaid, Ebtessam Almazrouei, Merouane Debbah</li>
<li>for: 文章目的是提出一种简单的视觉语音识别（VSR）方法，以便在不需要大量标注数据的情况下进行训练和测试。</li>
<li>methods: 方法基于学习一个先验模型，将视觉语音编码器中的征表示映射到对应的音频对的征表示中，以实现有效的文本解码。</li>
<li>results: 对于LRS3数据集，提出的方法可以与完全监督学习方法相比，达到26个WRR（识别错误率）。与现有的SoTA方法不同，该方法在VoxCeleb测试集上保持了合理的性能。<details>
<summary>Abstract</summary>
Visual Speech Recognition (VSR) differs from the common perception tasks as it requires deeper reasoning over the video sequence, even by human experts. Despite the recent advances in VSR, current approaches rely on labeled data to fully train or finetune their models predicting the target speech. This hinders their ability to generalize well beyond the training set and leads to performance degeneration under out-of-distribution challenging scenarios. Unlike previous works that involve auxiliary losses or complex training procedures and architectures, we propose a simple approach, named Lip2Vec that is based on learning a prior model. Given a robust visual speech encoder, this network maps the encoded latent representations of the lip sequence to their corresponding latents from the audio pair, which are sufficiently invariant for effective text decoding. The generated audio representation is then decoded to text using an off-the-shelf Audio Speech Recognition (ASR) model. The proposed model compares favorably with fully-supervised learning methods on the LRS3 dataset achieving 26 WER. Unlike SoTA approaches, our model keeps a reasonable performance on the VoxCeleb test set. We believe that reprogramming the VSR as an ASR task narrows the performance gap between the two and paves the way for more flexible formulations of lip reading.
</details>
<details>
<summary>摘要</summary>
“视觉语音识别（VSR）与常见的识别任务不同，它需要对视频序列进行更深刻的推理，甚至到了人类专家的水平。Despite recent advances in VSR, current approaches still rely on labeled data to fully train or fine-tune their models to predict the target speech, which hinders their ability to generalize well beyond the training set and leads to performance degradation under out-of-distribution challenging scenarios. Unlike previous works that involve auxiliary losses or complex training procedures and architectures, we propose a simple approach, named Lip2Vec, which is based on learning a prior model. Given a robust visual speech encoder, this network maps the encoded latent representations of the lip sequence to their corresponding latents from the audio pair, which are sufficient for effective text decoding. The generated audio representation is then decoded to text using an off-the-shelf Audio Speech Recognition (ASR) model. The proposed model compares favorably with fully-supervised learning methods on the LRS3 dataset, achieving 26 WER. Unlike SoTA approaches, our model maintains a reasonable performance on the VoxCeleb test set. We believe that reprogramming the VSR as an ASR task narrows the performance gap between the two and paves the way for more flexible formulations of lip reading.”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="An-Autoethnographic-Exploration-of-XAI-in-Algorithmic-Composition"><a href="#An-Autoethnographic-Exploration-of-XAI-in-Algorithmic-Composition" class="headerlink" title="An Autoethnographic Exploration of XAI in Algorithmic Composition"></a>An Autoethnographic Exploration of XAI in Algorithmic Composition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06089">http://arxiv.org/abs/2308.06089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashley Noel-Hirst, Nick Bryan-Kinns</li>
<li>for: 本研究旨在探讨如何使用可解释的人工智能（XAI）生成模型来帮助音乐创作。</li>
<li>methods: 本研究使用MeasureVAE生成模型，并对其中的可解释层次进行训练，以便在爱尔兰传统音乐上进行音乐创作。</li>
<li>results: 研究发现，在音乐创作过程中，探索性的音乐工作流程更加强调音乐训练集中的音乐特征，而不是生成模型本身的特征。这种方法还表明XAI模型可以被合理地应用于更复杂和多元的音乐创作工作流程中。<details>
<summary>Abstract</summary>
Machine Learning models are capable of generating complex music across a range of genres from folk to classical music. However, current generative music AI models are typically difficult to understand and control in meaningful ways. Whilst research has started to explore how explainable AI (XAI) generative models might be created for music, no generative XAI models have been studied in music making practice. This paper introduces an autoethnographic study of the use of the MeasureVAE generative music XAI model with interpretable latent dimensions trained on Irish folk music. Findings suggest that the exploratory nature of the music-making workflow foregrounds musical features of the training dataset rather than features of the generative model itself. The appropriation of an XAI model within an iterative workflow highlights the potential of XAI models to form part of a richer and more complex workflow than they were initially designed for.
</details>
<details>
<summary>摘要</summary>
文本翻译成简化中文：机器学习模型可以生成多种音乐类型，从民族音乐到古典音乐。然而，当前的生成音乐AI模型通常具有困难理解和控制的问题。研究已经开始探讨如何创建可解释的AI生成模型（XAI），但没有任何生成XAI模型在音乐创作实践中被研究。这篇论文介绍了一个自传式研究，使用了可解释的维度进行训练的MeasureVAE生成音乐XAI模型，并对 И尔兰民族音乐进行了应用。发现结果表明，音乐创作工作流程的探索性强调了训练数据集中的音乐特征，而不是生成模型自身的特征。在Iterative workflow中应用XAI模型，表明XAI模型可以成为更加复杂和多元的工作流程的一部分。
</details></li>
</ul>
<hr>
<h2 id="Audio-is-all-in-one-speech-driven-gesture-synthetics-using-WavLM-pre-trained-model"><a href="#Audio-is-all-in-one-speech-driven-gesture-synthetics-using-WavLM-pre-trained-model" class="headerlink" title="Audio is all in one: speech-driven gesture synthetics using WavLM pre-trained model"></a>Audio is all in one: speech-driven gesture synthetics using WavLM pre-trained model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05995">http://arxiv.org/abs/2308.05995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Zhang, Naye Ji, Fuxing Gao, Siyuan Zhao, Zhaohan Wang, Shunman Li</li>
<li>for: 这 paper 的目的是为数字人类创造领域中的合作语言姿势生成。</li>
<li>methods: 这 paper 使用的方法是基于 transformer 架构的 speech-conditional 扩散模型，使用 WavLM 预训练模型提取低级和高级声音信息，并通过 adaptive layer norm 架构学习声音信息和合作姿势之间的关系。</li>
<li>results: 经过对 Trinity、ZEGGS 和 BEAT 数据集的评估，这 paper 的模型能够生成自然的合作姿势，并且可以控制姿势的风格和性格。<details>
<summary>Abstract</summary>
The generation of co-speech gestures for digital humans is an emerging area in the field of virtual human creation. Prior research has made progress by using acoustic and semantic information as input and adopting classify method to identify the person's ID and emotion for driving co-speech gesture generation. However, this endeavour still faces significant challenges. These challenges go beyond the intricate interplay between co-speech gestures, speech acoustic, and semantics; they also encompass the complexities associated with personality, emotion, and other obscure but important factors. This paper introduces "diffmotion-v2," a speech-conditional diffusion-based and non-autoregressive transformer-based generative model with WavLM pre-trained model. It can produce individual and stylized full-body co-speech gestures only using raw speech audio, eliminating the need for complex multimodal processing and manually annotated. Firstly, considering that speech audio not only contains acoustic and semantic features but also conveys personality traits, emotions, and more subtle information related to accompanying gestures, we pioneer the adaptation of WavLM, a large-scale pre-trained model, to extract low-level and high-level audio information. Secondly, we introduce an adaptive layer norm architecture in the transformer-based layer to learn the relationship between speech information and accompanying gestures. Extensive subjective evaluation experiments are conducted on the Trinity, ZEGGS, and BEAT datasets to confirm the WavLM and the model's ability to synthesize natural co-speech gestures with various styles.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>虚拟人类创造领域中的同声动作生成是一个emerging领域。先前的研究已经做出了进步，使用音声和语义信息作为输入，采用分类方法确定人的ID和情绪，以驱动同声动作生成。然而，这种努力仍然面临着重大挑战。这些挑战不仅包括同声动作、音声和语义之间的细微相互作用，还包括人格、情绪和其他重要而不可预测的因素。本文介绍“diffmotion-v2”模型，这是一种基于 transformer 架构的 speech-conditional 扩散型生成模型，使用 WavLM 预训练模型。它可以根据原始的 Raw Speech 音频生成个性化和风格化的全身同声动作，不需要详细的多媒体处理和手动标注。首先，我们认为音频不仅包含音声和语义信息，还包含人格特征和情绪信息，因此我们采用 WavLM 预训练模型来提取低级和高级音频信息。其次，我们引入 transformer 架构中的 adaptive 层 нор方法，以学习音频信息和同声动作之间的关系。我们在 Trinity、ZEGGS 和 BEAT  dataset 上进行了大量主观评估实验，以证明 WavLM 和模型的能力生成自然的同声动作。
</details></li>
</ul>
<hr>
<h2 id="Advancing-the-study-of-Large-Scale-Learning-in-Overlapped-Speech-Detection"><a href="#Advancing-the-study-of-Large-Scale-Learning-in-Overlapped-Speech-Detection" class="headerlink" title="Advancing the study of Large-Scale Learning in Overlapped Speech Detection"></a>Advancing the study of Large-Scale Learning in Overlapped Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05987">http://arxiv.org/abs/2308.05987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaohui Yin, Jingguang Tian, Xinhui Hu, Xinkang Xu</li>
<li>for: 多个party会话中的干扰语音检测（OSD）是speech应用中的一个重要部分，但大多数现有的OSD模型都是基于特定的数据集进行训练和评估，这限制了这些模型的应用场景。</li>
<li>methods: 本研究提出了大规模学习（LSL）在OSD中的应用，并设计了522小时不同语言和风格的标注音频作为大规模数据集。并通过对不同深度神经网络基于OSD模型的比较性试验来评估LSL在OSD任务中的效果和OSD模型的性能。</li>
<li>results: 研究结果表明，LSL可以显著提高OSD模型的性能和Robustness，并且CF-OSD模型基于LSL在16K单频OSD任务中取得了最佳性能，其F1分数为80.8%和52.0% separately在Alimeeting测试集和DIHARD II评估集上。<details>
<summary>Abstract</summary>
Overlapped Speech Detection (OSD) is an important part of speech applications involving analysis of multi-party conversations. However, Most of the existing OSD models are trained and evaluated on specific dataset, which limits the application scenarios of these models. In order to solve this problem, we conduct a study of large-scale learning (LSL) in OSD and propose a more general 16K single-channel OSD model. In our study, 522 hours of labeled audio in different languages and styles are collected and used as the large-scale dataset. Rigorous comparative experiments are designed and used to evaluate the effectiveness of LSL in OSD task and the performance of OSD models based on different deep neural networks. The results show that LSL can significantly improve the performance and robustness of OSD models, and the OSD model based on Conformer (CF-OSD) with LSL is currently the best 16K single-channel OSD model. Moreover, the CF-OSD with LSL establishes a state-of-the-art performance with a F1-score of 80.8% and 52.0% on the Alimeeting test set and DIHARD II evaluation set, respectively.
</details>
<details>
<summary>摘要</summary>
《 overlap speech detection (OSD) 是一种重要的语音应用程序中的分析多方会话的一部分。然而，现有的大多数 OSD 模型都是基于特定数据集进行训练和评估，这限制了这些模型的应用场景。为解决这个问题，我们进行了大规模学习 (LSL) 在 OSD 中的研究，并提出了一种更加通用的 16K 单通道 OSD 模型。在我们的研究中，我们收集了 522 小时不同语言和风格的标注音频，并使用这些大规模数据集进行训练和测试。我们设计了严格的比较实验，用于评估 LSL 在 OSD 任务中的效果和不同深度神经网络上的 OSD 模型性能。结果显示，LSL 可以明显提高 OSD 模型的性能和 Robustness，并且 CF-OSD  WITH LSL 目前是最佳的 16K 单通道 OSD 模型。此外，CF-OSD  WITH LSL 在 Alimeeting 测试集和 DIHARD II 评估集上的 F1 分数分别达到了 80.8% 和 52.0%。
</details></li>
</ul>
<hr>
<h2 id="AudioLDM-2-Learning-Holistic-Audio-Generation-with-Self-supervised-Pretraining"><a href="#AudioLDM-2-Learning-Holistic-Audio-Generation-with-Self-supervised-Pretraining" class="headerlink" title="AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining"></a>AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05734">http://arxiv.org/abs/2308.05734</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haoheliu/AudioLDM2">https://github.com/haoheliu/AudioLDM2</a></li>
<li>paper_authors: Haohe Liu, Qiao Tian, Yi Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Yuping Wang, Wenwu Wang, Yuxuan Wang, Mark D. Plumbley</li>
<li>for: 这个论文的目的是提出一个框架，用于同时生成不同类型的声音（如speech、音乐和声效），并且使用同一种学习方法来满足不同类型的目标和偏见。</li>
<li>methods: 该框架使用了一种通用的声音表示（LOA），将任何类型的声音都可以翻译为LOA，并使用一个GPT-2模型将不同类型的modalities翻译为LOA。在生成过程中，使用一个Latent Diffusion模型， conditioned on LOA，进行自我监督的声音生成学习。</li>
<li>results: 实验结果表明，该框架可以在主要的benchmark上达到新的州OF-THE-ART或与之前的方法竞争的性能。 Code和demo可以在<a target="_blank" rel="noopener" href="https://audioldm.github.io/audioldm2%E4%B8%AD%E8%8E%B7%E5%8F%96%E3%80%82">https://audioldm.github.io/audioldm2中获取。</a><details>
<summary>Abstract</summary>
Although audio generation shares commonalities across different types of audio, such as speech, music, and sound effects, designing models for each type requires careful consideration of specific objectives and biases that can significantly differ from those of other types. To bring us closer to a unified perspective of audio generation, this paper proposes a framework that utilizes the same learning method for speech, music, and sound effect generation. Our framework introduces a general representation of audio, called language of audio (LOA). Any audio can be translated into LOA based on AudioMAE, a self-supervised pre-trained representation learning model. In the generation process, we translate any modalities into LOA by using a GPT-2 model, and we perform self-supervised audio generation learning with a latent diffusion model conditioned on LOA. The proposed framework naturally brings advantages such as in-context learning abilities and reusable self-supervised pretrained AudioMAE and latent diffusion models. Experiments on the major benchmarks of text-to-audio, text-to-music, and text-to-speech demonstrate new state-of-the-art or competitive performance to previous approaches. Our demo and code are available at https://audioldm.github.io/audioldm2.
</details>
<details>
<summary>摘要</summary>
尽管听音生成存在不同类型的听音之间共同之处，例如语音、音乐和声音效果，但设计模型时需要仔细考虑每种类型的特定目标和偏见，这些偏见与其他类型的偏见可能有所不同。为了带我们更近到听音生成的统一视角，这篇论文提出了一个框架，该框架利用同一种学习方法来生成不同类型的听音。我们的框架引入了一个通用的听音表示（LOA），任何听音都可以根据AudioMAE自动学习的预训练表示学习模型翻译为LOA。在生成过程中，我们使用GPT-2模型将任何模式翻译为LOA，然后使用干扰扩散模型在LOA上进行自主学习。我们的提议框架自然带来了一些优点，例如在上下文学习能力和可重用的自动学习AudioMAE和干扰扩散模型。我们的实验在文本到听音、文本到音乐和文本到语音的主要benchmark上达到了新的州OF-THE-ART或与前一代方法竞争的性能。我们的demo和代码可以在https://audioldm.github.io/audioldm2中找到。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/11/cs.SD_2023_08_11/" data-id="cloq1wl9v00uz7o8856uxbpt8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/59/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/58/">58</a><a class="page-number" href="/page/59/">59</a><span class="page-number current">60</span><a class="page-number" href="/page/61/">61</a><a class="page-number" href="/page/62/">62</a><span class="space">&hellip;</span><a class="page-number" href="/page/88/">88</a><a class="extend next" rel="next" href="/page/61/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
