
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/93/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_07_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/08/cs.CV_2023_07_08/" class="article-date">
  <time datetime="2023-07-08T13:00:00.000Z" itemprop="datePublished">2023-07-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/08/cs.CV_2023_07_08/">cs.CV - 2023-07-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Lightweight-Improved-Residual-Network-for-Efficient-Inverse-Tone-Mapping"><a href="#Lightweight-Improved-Residual-Network-for-Efficient-Inverse-Tone-Mapping" class="headerlink" title="Lightweight Improved Residual Network for Efficient Inverse Tone Mapping"></a>Lightweight Improved Residual Network for Efficient Inverse Tone Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03998">http://arxiv.org/abs/2307.03998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liqi Xue, Tianyi Xu, Yongbao Song, Yan Liu, Lei Zhang, Xiantong Zhen, Jun Xu</li>
<li>for: 用于高动态范围图像的倒计时间映射（ITM）任务。</li>
<li>methods: 提出了一种基于增强的待遇块的轻量级Improved Residual Network（IRNet），用于高效地完成ITM任务。</li>
<li>results: 在三个标准数据集上进行实验，得到了最佳性能在ITM和joint SR-ITM任务中。<details>
<summary>Abstract</summary>
The display devices like HDR10 televisions are increasingly prevalent in our daily life for visualizing high dynamic range (HDR) images. But the majority of media images on the internet remain in 8-bit standard dynamic range (SDR) format. Therefore, converting SDR images to HDR ones by inverse tone mapping (ITM) is crucial to unlock the full potential of abundant media images. However, existing ITM methods are usually developed with complex network architectures requiring huge computational costs. In this paper, we propose a lightweight Improved Residual Network (IRNet) by enhancing the power of popular residual block for efficient ITM. Specifically, we propose a new Improved Residual Block (IRB) to extract and fuse multi-layer features for fine-grained HDR image reconstruction. Experiments on three benchmark datasets demonstrate that our IRNet achieves state-of-the-art performance on both the ITM and joint SR-ITM tasks. The code, models and data will be publicly available at https://github.com/ThisisVikki/ITM-baseline.
</details>
<details>
<summary>摘要</summary>
现在的显示设备如HDR10电视在我们日常生活中变得越来越普遍，用于显示高动态范围（HDR）图像。然而，互联网上的媒体图像大多数仍然是8比特标准动态范围（SDR）格式。因此，将SDR图像转换为HDR图像的 inverse tone mapping（ITM）变得非常重要，以便使用丰富的媒体图像。然而，现有的ITM方法通常具有复杂的网络架构，需要巨大的计算成本。在这篇论文中，我们提出了一种轻量级的改进律重网络（IRNet），通过提高流行的律重块来提高HDR图像重建精度。具体来说，我们提出了一种新的改进律重块（IRB），用于提取和融合多层特征来实现细腻的HDR图像重建。实验表明，我们的IRNet在ITM和 joint SR-ITM任务上达到了状态略的表现。代码、模型和数据将在https://github.com/ThisisVikki/ITM-baseline上公开。
</details></li>
</ul>
<hr>
<h2 id="Stimulating-the-Diffusion-Model-for-Image-Denoising-via-Adaptive-Embedding-and-Ensembling"><a href="#Stimulating-the-Diffusion-Model-for-Image-Denoising-via-Adaptive-Embedding-and-Ensembling" class="headerlink" title="Stimulating the Diffusion Model for Image Denoising via Adaptive Embedding and Ensembling"></a>Stimulating the Diffusion Model for Image Denoising via Adaptive Embedding and Ensembling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03992">http://arxiv.org/abs/2307.03992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Li, Hansen Feng, Lizhi Wang, Zhiwei Xiong, Hua Huang</li>
<li>for: 提高图像噪声去除的高质量感知性和低扭曲性。</li>
<li>methods: 提出了一种新的策略called Diffusion Model for Image Denoising (DMID),包括适应嵌入方法和适应 ensemble方法，以解决噪声模型和图像去噪的关键问题。</li>
<li>results: 实现了对所有噪声基数和感知指标的状态艺术性和低扭曲性表现，包括对真实世界图像的去噪。<details>
<summary>Abstract</summary>
Image denoising is a fundamental problem in computational photography, where achieving high-quality perceptual performance with low distortion is highly demanding. Current methods either struggle with perceptual performance or suffer from significant distortion. Recently, the emerging diffusion model achieves state-of-the-art performance in various tasks, and its denoising mechanism demonstrates great potential for image denoising. However, stimulating diffusion models for image denoising is not straightforward and requires solving several critical problems. On the one hand, the input inconsistency hinders the connection of diffusion models and image denoising. On the other hand, the content inconsistency between the generated image and the desired denoised image introduces additional distortion. To tackle these problems, we present a novel strategy called Diffusion Model for Image Denoising (DMID) by understanding and rethinking the diffusion model from a denoising perspective. Our DMID strategy includes an adaptive embedding method that embeds the noisy image into a pre-trained diffusion model, and an adaptive ensembling method that reduces distortion in the denoised image. Our DMID strategy achieves state-of-the-art performance on all distortion-based and perceptual metrics, for both Gaussian and real-world image denoising.
</details>
<details>
<summary>摘要</summary>
Image denoising是计算摄影学中的基本问题，要求 достичь高质量的感知性性能并且减少扭曲。目前的方法可能会导致感知性性能下降或者受到重大的扭曲影响。近些年，出现了扩散模型，在不同任务中达到了国际前ier的性能，其扩散机制对图像杂 noise 有很大的潜力。然而，激活扩散模型以实现图像杂 noise 约束是不直接的，需要解决多个关键问题。一方面，输入不一致会阻碍扩散模型和图像杂 noise 的连接。另一方面，生成的图像与需要的杂 noise 图像的内容不一致会引入额外的扭曲。为了解决这些问题，我们提出了一种新的策略，即扩散模型 для图像杂 noise（DMID）。我们的 DMID 策略包括适应嵌入方法，将噪图像 embedding 到预训练的扩散模型中，以及适应ensemble方法，以减少生成的图像中的扭曲。我们的 DMID 策略在所有基于扭曲和感知性的指标上达到了国际前ier的性能，包括 Gaussian 和实际世界的图像杂 noise 约束。
</details></li>
</ul>
<hr>
<h2 id="FTFDNet-Learning-to-Detect-Talking-Face-Video-Manipulation-with-Tri-Modality-Interaction"><a href="#FTFDNet-Learning-to-Detect-Talking-Face-Video-Manipulation-with-Tri-Modality-Interaction" class="headerlink" title="FTFDNet: Learning to Detect Talking Face Video Manipulation with Tri-Modality Interaction"></a>FTFDNet: Learning to Detect Talking Face Video Manipulation with Tri-Modality Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03990">http://arxiv.org/abs/2307.03990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ganglai Wang, Peng Zhang, Junwen Xiong, Feihan Yang, Wei Huang, Yufei Zha</li>
<li>for: 防止深伪视频攻击公共媒体安全，特别是利用语音和视频流进行数字面部伪造，以至于识别人脸特征困难。</li>
<li>methods: 提出了一种基于视觉、音频和运动特征的检测网络（FTFDNet），并使用高效的跨模态融合（CMF）模块将这些特征融合。此外，还提出了一种新的音频视频注意机制（AVAM），可以找到更多的有用特征。</li>
<li>results: FTFDNet在已知的深伪面部检测数据集（FTFDD）以及深伪视频检测数据集（DFDC和DF-TIMIT）上达到了与其他当前领先的深伪视频检测方法相比较好的检测性能。<details>
<summary>Abstract</summary>
DeepFake based digital facial forgery is threatening public media security, especially when lip manipulation has been used in talking face generation, and the difficulty of fake video detection is further improved. By only changing lip shape to match the given speech, the facial features of identity are hard to be discriminated in such fake talking face videos. Together with the lack of attention on audio stream as the prior knowledge, the detection failure of fake talking face videos also becomes inevitable. It's found that the optical flow of the fake talking face video is disordered especially in the lip region while the optical flow of the real video changes regularly, which means the motion feature from optical flow is useful to capture manipulation cues. In this study, a fake talking face detection network (FTFDNet) is proposed by incorporating visual, audio and motion features using an efficient cross-modal fusion (CMF) module. Furthermore, a novel audio-visual attention mechanism (AVAM) is proposed to discover more informative features, which can be seamlessly integrated into any audio-visual CNN architecture by modularization. With the additional AVAM, the proposed FTFDNet is able to achieve a better detection performance than other state-of-the-art DeepFake video detection methods not only on the established fake talking face detection dataset (FTFDD) but also on the DeepFake video detection datasets (DFDC and DF-TIMIT).
</details>
<details>
<summary>摘要</summary>
深度复制基本的数字面伪造是公共媒体安全的威胁，特别是在口型 manipulate 在生成 talking face 中使用，并使 fake video 检测更加困难。只有改变 lip 形状来匹配给定的speech，then the facial features of identity are difficult to distinguish in such fake talking face videos. In addition, the lack of attention to the audio stream as prior knowledge makes it impossible to detect fake talking face videos. It is found that the optical flow of the fake talking face video is disordered, especially in the lip region, while the optical flow of the real video changes regularly, which means that the motion feature from optical flow is useful for capturing manipulation cues. In this study, a fake talking face detection network (FTFDNet) is proposed by incorporating visual, audio, and motion features using an efficient cross-modal fusion (CMF) module. Furthermore, a novel audio-visual attention mechanism (AVAM) is proposed to discover more informative features, which can be seamlessly integrated into any audio-visual CNN architecture by modularization. With the additional AVAM, the proposed FTFDNet is able to achieve a better detection performance than other state-of-the-art DeepFake video detection methods not only on the established fake talking face detection dataset (FTFDD) but also on the DeepFake video detection datasets (DFDC and DF-TIMIT).
</details></li>
</ul>
<hr>
<h2 id="TractGeoNet-A-geometric-deep-learning-framework-for-pointwise-analysis-of-tract-microstructure-to-predict-language-assessment-performance"><a href="#TractGeoNet-A-geometric-deep-learning-framework-for-pointwise-analysis-of-tract-microstructure-to-predict-language-assessment-performance" class="headerlink" title="TractGeoNet: A geometric deep learning framework for pointwise analysis of tract microstructure to predict language assessment performance"></a>TractGeoNet: A geometric deep learning framework for pointwise analysis of tract microstructure to predict language assessment performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03982">http://arxiv.org/abs/2307.03982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuqian Chen, Leo R. Zekelman, Chaoyi Zhang, Tengfei Xue, Yang Song, Nikos Makris, Yogesh Rathi, Alexandra J. Golby, Weidong Cai, Fan Zhang, Lauren J. O’Donnell</li>
<li>for: 这个研究旨在开发一种基于几何深度学习的推论框架，以用于使用扩散磁共振成像（dMRI）轨脉图像和相关的点粒子微结构测量进行回归。</li>
<li>methods: 该方法使用点云表示，可以直接利用轨脉图像中所有点的位势信息和细胞微结构信息进行推论。此外，我们提出了一种新的损失函数，即对称对比推论损失函数，以促进模型准确地预测轨脉图像中点粒子微结构之间的差异。</li>
<li>results: 我们通过使用TractGeoNet进行回归预测，并评估了20个白 matter轨脉图像的语言功能表现。结果显示，TractGeoNet比许多流行的回归模型表现更优异。此外，我们发现左弯曲脉幕轨脉是语言功能表现的最重要预测因素之一。本地化的关键区域分布在两个半球的白 matter轨脉中，包括耳延盘、前叶、上部和下部的脑区域，这些脑区域被认为是语言功能的重要组成部分。总的来说，TractGeoNet表明几何深度学习可以增强脑白 matter轨脉的研究和语言功能之间的关系。<details>
<summary>Abstract</summary>
We propose a geometric deep-learning-based framework, TractGeoNet, for performing regression using diffusion magnetic resonance imaging (dMRI) tractography and associated pointwise tissue microstructure measurements. By employing a point cloud representation, TractGeoNet can directly utilize pointwise tissue microstructure and positional information from all points within a fiber tract. To improve regression performance, we propose a novel loss function, the Paired-Siamese Regression loss, which encourages the model to focus on accurately predicting the relative differences between regression label scores rather than just their absolute values. In addition, we propose a Critical Region Localization algorithm to identify highly predictive anatomical regions within the white matter fiber tracts for the regression task. We evaluate the effectiveness of the proposed method by predicting individual performance on two neuropsychological assessments of language using a dataset of 20 association white matter fiber tracts from 806 subjects from the Human Connectome Project. The results demonstrate superior prediction performance of TractGeoNet compared to several popular regression models. Of the twenty tracts studied, we find that the left arcuate fasciculus tract is the most highly predictive of the two studied language performance assessments. The localized critical regions are widespread and distributed across both hemispheres and all cerebral lobes, including areas of the brain considered important for language function such as superior and anterior temporal regions, pars opercularis, and precentral gyrus. Overall, TractGeoNet demonstrates the potential of geometric deep learning to enhance the study of the brain's white matter fiber tracts and to relate their structure to human traits such as language performance.
</details>
<details>
<summary>摘要</summary>
我们提出了一个几何深度学习基于扩散磁共振成像（dMRI）的推论框架，称为TractGeoNet，用于进行回归。该框架利用点云表示，可以直接利用所有纤维股区域的点wise组织和位域信息。为了提高回归性能，我们提出了一种新的损失函数，即对称对拼减损失函数，该函数鼓励模型对准精确地预测相对差值而不仅仅是绝对值。此外，我们提出了一种关键区域定位算法，用于在白 matter纤维股中预测性能。我们通过使用dMRI数据集的20个相关纤维股，从806名参与者中预测语言性能，证明了TractGeoNet的效果比较出色。其中，左弯曲 fasiculus 纤维股被证明为语言性能预测的最高度相关。关键区域广泛分布在两个半球和所有脑叶，包括被认为是语言功能重要的脑区域，如上侧 temporalis、anterior temporalis、pars opercularis 和 precentral gyrus。总之，TractGeoNet表明几何深度学习可以提高白 matter纤维股的研究和语言性能之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Building-and-Road-Segmentation-Using-EffUNet-and-Transfer-Learning-Approach"><a href="#Building-and-Road-Segmentation-Using-EffUNet-and-Transfer-Learning-Approach" class="headerlink" title="Building and Road Segmentation Using EffUNet and Transfer Learning Approach"></a>Building and Road Segmentation Using EffUNet and Transfer Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03980">http://arxiv.org/abs/2307.03980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahil Gangurde</li>
<li>for: 本论文旨在用深度学习方法实现城市规划中的建筑物和路径分割，以提高城市规划决策的效果。</li>
<li>methods: 本论文提出了一种基于Google新提出的EfficientNetV2的Encoder-UNet Decoder架构，用于feature提取和分割地图中的建筑物和路径。</li>
<li>results: 使用该方法， authors在麻省建筑物和路径 dataset上达到了 benchmark 分割精度（mIOU）的0.8365和0.9153。<details>
<summary>Abstract</summary>
In city, information about urban objects such as water supply, railway lines, power lines, buildings, roads, etc., is necessary for city planning. In particular, information about the spread of these objects, locations and capacity is needed for the policymakers to make impactful decisions. This thesis aims to segment the building and roads from the aerial image captured by the satellites and UAVs. Many different architectures have been proposed for the semantic segmentation task and UNet being one of them. In this thesis, we propose a novel architecture based on Google's newly proposed EfficientNetV2 as an encoder for feature extraction with UNet decoder for constructing the segmentation map. Using this approach we achieved a benchmark score for the Massachusetts Building and Road dataset with an mIOU of 0.8365 and 0.9153 respectively.
</details>
<details>
<summary>摘要</summary>
在城市中，有关城市 объекts such as 水upply, 铁路线, 电力线, 建筑物, 路网等的信息是必要的 для城市规划。特别是在决策者们需要了解这些对象的扩散、位置和容量，以便做出有效的决策。本论文目的是从航空图像和无人机拍摄的卫星和UAV中提取建筑物和路网的信息，并使用Google提出的新的EfficientNetV2嵌入器和UNet解码器组成 semantic segmentation 图像。我们在这里提出了一种新的架构，并在Massachusetts Building and Road数据集上实现了benchmark分数，具体分别为0.8365和0.9153。
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Supervised-Multilabel-Contrastive-Learning"><a href="#End-to-End-Supervised-Multilabel-Contrastive-Learning" class="headerlink" title="End-to-End Supervised Multilabel Contrastive Learning"></a>End-to-End Supervised Multilabel Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03967">http://arxiv.org/abs/2307.03967</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mahdihosseini/kmcl">https://github.com/mahdihosseini/kmcl</a></li>
<li>paper_authors: Ahmad Sajedi, Samir Khaki, Konstantinos N. Plataniotis, Mahdi S. Hosseini</li>
<li>for: 本研究旨在提出一种新的综合训练框架，以解决多标签表示学习中的挑战，包括标签相关性和数据相关性。</li>
<li>methods: 本研究使用了kernel-based多标签对比学习（KMCL）方法，该方法首先将嵌入特征转化为一种混合 exponential kernel 的 Gaussian RKHS 中，然后使用一个包含 reconstruction loss、非对称分类损失和对比损失的目标函数进行编码。</li>
<li>results: EXTENSIVE experiments 表明，KMCL 可以在图像分类任务中实现鲁棒的改进，并且可以减少计算复杂性。<details>
<summary>Abstract</summary>
Multilabel representation learning is recognized as a challenging problem that can be associated with either label dependencies between object categories or data-related issues such as the inherent imbalance of positive/negative samples. Recent advances address these challenges from model- and data-centric viewpoints. In model-centric, the label correlation is obtained by an external model designs (e.g., graph CNN) to incorporate an inductive bias for training. However, they fail to design an end-to-end training framework, leading to high computational complexity. On the contrary, in data-centric, the realistic nature of the dataset is considered for improving the classification while ignoring the label dependencies. In this paper, we propose a new end-to-end training framework -- dubbed KMCL (Kernel-based Mutlilabel Contrastive Learning) -- to address the shortcomings of both model- and data-centric designs. The KMCL first transforms the embedded features into a mixture of exponential kernels in Gaussian RKHS. It is then followed by encoding an objective loss that is comprised of (a) reconstruction loss to reconstruct kernel representation, (b) asymmetric classification loss to address the inherent imbalance problem, and (c) contrastive loss to capture label correlation. The KMCL models the uncertainty of the feature encoder while maintaining a low computational footprint. Extensive experiments are conducted on image classification tasks to showcase the consistent improvements of KMCL over the SOTA methods. PyTorch implementation is provided in \url{https://github.com/mahdihosseini/KMCL}.
</details>
<details>
<summary>摘要</summary>
多标签表示学习被认为是一个复杂的问题，与对象类别标签之间的相互关系或数据相关的问题有关。现代进步从模型和数据中心视角来解决这些挑战。在模型中心的方法中，通过外部模型设计（例如图像 CNN）获得标签相关性，但是它们无法设计端到端训练框架，导致计算复杂性过高。在数据中心的方法中，利用实际数据的自然特性来提高分类，忽略标签相互关系。在这篇论文中，我们提出一种新的端到端训练框架——拥有kernel-based多标签对比学习（KMCL）——以解决模型和数据中心的缺点。KMCL首先将嵌入特征转换为混合几何函数在高斯RKHS中，然后编码一个包含（a）重建kernel表示的损失函数，（b）偏好类别的不对称分类损失函数，和（c）捕捉标签相关性的对比损失函数的目标损失函数。KMCL模型特征编码器的不确定性，同时保持计算脚本的低峰值。我们在图像分类任务中进行了广泛的实验，并证明了KMCL在SOTA方法上显著提高了性能。PyTorch实现可以在 \url{https://github.com/mahdihosseini/KMCL} 中找到。
</details></li>
</ul>
<hr>
<h2 id="Reading-Between-the-Lanes-Text-VideoQA-on-the-Road"><a href="#Reading-Between-the-Lanes-Text-VideoQA-on-the-Road" class="headerlink" title="Reading Between the Lanes: Text VideoQA on the Road"></a>Reading Between the Lanes: Text VideoQA on the Road</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03948">http://arxiv.org/abs/2307.03948</a></li>
<li>repo_url: None</li>
<li>paper_authors: George Tom, Minesh Mathew, Sergi Garcia, Dimosthenis Karatzas, C. V. Jawahar</li>
<li>for: 这个研究是为了提高车辆驾驶员的安全驾驶和情感知识，通过捕捉车辆前方环境中的文字信息，并将其转换为驾驶员可以理解的形式。</li>
<li>methods: 这个研究使用了视觉数据流进行文字识别，并将文字识别结果与时间进行推理，以提高驾驶员的情感知识和驾驶安全性。</li>
<li>results: 这个研究发现，现有的VideoQA模型在这个领域中仍有很大的提升空间，并且显示了这个 dataset 的可用性和重要性在进一步推进驾驶员支持系统和文字敏感多modal问答的研究中。<details>
<summary>Abstract</summary>
Text and signs around roads provide crucial information for drivers, vital for safe navigation and situational awareness. Scene text recognition in motion is a challenging problem, while textual cues typically appear for a short time span, and early detection at a distance is necessary. Systems that exploit such information to assist the driver should not only extract and incorporate visual and textual cues from the video stream but also reason over time. To address this issue, we introduce RoadTextVQA, a new dataset for the task of video question answering (VideoQA) in the context of driver assistance. RoadTextVQA consists of $3,222$ driving videos collected from multiple countries, annotated with $10,500$ questions, all based on text or road signs present in the driving videos. We assess the performance of state-of-the-art video question answering models on our RoadTextVQA dataset, highlighting the significant potential for improvement in this domain and the usefulness of the dataset in advancing research on in-vehicle support systems and text-aware multimodal question answering. The dataset is available at http://cvit.iiit.ac.in/research/projects/cvit-projects/roadtextvqa
</details>
<details>
<summary>摘要</summary>
文本和路上的示意图提供了驾驶员 navigate 和情况意识 的关键信息。Scene text recognition in motion 是一个具有挑战性的问题，因为文本cue 通常只出现短时间，早期检测距离是必要的。为了解决这个问题，我们介绍了 RoadTextVQA  dataset，用于驾驶助手Question Answering 任务（VideoQA）的研究。RoadTextVQA 包括 $3,222$ 段驾驶视频，收集自多个国家，并有 $10,500$ 个问题，所有问题基于驾驶视频中的文本或路上示意图。我们评估了现有的 VideoQA 模型在我们的 RoadTextVQA dataset 上的性能，并指出了这个领域的显著改进潜力和使用这个dataset进行文本感知多模式问答的研究的用于。dataset 可以在 http://cvit.iiit.ac.in/research/projects/cvit-projects/roadtextvqa 上获取。
</details></li>
</ul>
<hr>
<h2 id="Camouflaged-Object-Detection-with-Feature-Grafting-and-Distractor-Aware"><a href="#Camouflaged-Object-Detection-with-Feature-Grafting-and-Distractor-Aware" class="headerlink" title="Camouflaged Object Detection with Feature Grafting and Distractor Aware"></a>Camouflaged Object Detection with Feature Grafting and Distractor Aware</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03943">http://arxiv.org/abs/2307.03943</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/syxvision/fdnet">https://github.com/syxvision/fdnet</a></li>
<li>paper_authors: Yuxuan Song, Xinyue Li, Lin Qi</li>
<li>for: 本研究旨在提高掩蔽物检测的精度，使得能够准确地检测掩蔽在环境中的目标。</li>
<li>methods: 本文提出了一种新的Feature Grafting and Distractor Aware网络（FDNet）来解决掩蔽物检测问题。特别是，我们使用了CNN和Transformer来并行地编码多尺度图像。为了更好地利用两个编码器的优势，我们设计了一个cross-attention-based Feature GraftingModule，将Transformer分支中提取的特征融合到CNN分支中，然后在Feature Fusion Module中进行粘合。此外，我们还设计了一个Explicitly Modeling Distractors模块，以便更加精确地模拟掩蔽物检测中的两种可能的干扰因素。</li>
<li>results: 我们的方法在四个常用的 benchmark datasets 以及ACOD2K dataset上进行了广泛的实验，结果显示，我们的方法与其他状态之前的方法相比，有显著的提高。代码和ACOD2K dataset将在<a target="_blank" rel="noopener" href="https://github.com/syxvision/FDNet%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/syxvision/FDNet上公开。</a><details>
<summary>Abstract</summary>
The task of Camouflaged Object Detection (COD) aims to accurately segment camouflaged objects that integrated into the environment, which is more challenging than ordinary detection as the texture between the target and background is visually indistinguishable. In this paper, we proposed a novel Feature Grafting and Distractor Aware network (FDNet) to handle the COD task. Specifically, we use CNN and Transformer to encode multi-scale images in parallel. In order to better explore the advantages of the two encoders, we design a cross-attention-based Feature Grafting Module to graft features extracted from Transformer branch into CNN branch, after which the features are aggregated in the Feature Fusion Module. A Distractor Aware Module is designed to explicitly model the two possible distractors in the COD task to refine the coarse camouflage map. We also proposed the largest artificial camouflaged object dataset which contains 2000 images with annotations, named ACOD2K. We conducted extensive experiments on four widely used benchmark datasets and the ACOD2K dataset. The results show that our method significantly outperforms other state-of-the-art methods. The code and the ACOD2K will be available at https://github.com/syxvision/FDNet.
</details>
<details>
<summary>摘要</summary>
“Camouflaged Object Detection（COD）任务的目标是精准地找到融入环境中的掩蔽物，这比普通的检测更加具有挑战性，因为标的和背景的文字特征无法辨识。在这篇论文中，我们提出了一个新的特色插入和干扰识别网络（FDNet）来处理COD任务。具体来说，我们使用CNN和Transformer并行地实现多个标本的像素网络。为了更好地利用两个网络的优点，我们设计了一个交互式特色插入模组，将Transformer分支中提取的特色插入到CNN分支中，然后将特色在特色聚合模组中聚合。此外，我们设计了一个干扰识别模组，以Explicitly模型COD任务中的两种干扰因素，以改善粗糙的掩蔽地图。我们还提出了2000幅掩蔽物标注图像集合，名为ACOD2K。我们实现了广泛的实验，包括四个通用的 benchmark 测试集和 ACOD2K 标注图像集合。结果显示，我们的方法在其他状态顶专门方法之上得到了很好的表现。我们将代码和ACOD2K数据集存储在 GitHub 上，请遵循 https://github.com/syxvision/FDNet 来访问。”
</details></li>
</ul>
<hr>
<h2 id="Ariadne’s-Thread-Using-Text-Prompts-to-Improve-Segmentation-of-Infected-Areas-from-Chest-X-ray-images"><a href="#Ariadne’s-Thread-Using-Text-Prompts-to-Improve-Segmentation-of-Infected-Areas-from-Chest-X-ray-images" class="headerlink" title="Ariadne’s Thread:Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray images"></a>Ariadne’s Thread:Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03942">http://arxiv.org/abs/2307.03942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junelin2333/languidemedseg-miccai2023">https://github.com/junelin2333/languidemedseg-miccai2023</a></li>
<li>paper_authors: Yi Zhong, Mengqiu Xu, Kongming Liang, Kaixin Chen, Ming Wu</li>
<li>for: 该研究旨在提高肺病评估的精度，提供更准确的肺病诊断和治疗方案。</li>
<li>methods: 该研究使用语言驱动的图像分割方法，通过文本提示来改进图像分割结果。</li>
<li>results: 实验结果表明，该方法与单模方法相比，提高了QaTa-COV19数据集的 dice分数6.09%以上。此外，研究还表明，多模式方法在文本粒度和训练数据大小方面具有显著的优势。<details>
<summary>Abstract</summary>
Segmentation of the infected areas of the lung is essential for quantifying the severity of lung disease like pulmonary infections. Existing medical image segmentation methods are almost uni-modal methods based on image. However, these image-only methods tend to produce inaccurate results unless trained with large amounts of annotated data. To overcome this challenge, we propose a language-driven segmentation method that uses text prompt to improve to the segmentation result. Experiments on the QaTa-COV19 dataset indicate that our method improves the Dice score by 6.09% at least compared to the uni-modal methods. Besides, our extended study reveals the flexibility of multi-modal methods in terms of the information granularity of text and demonstrates that multi-modal methods have a significant advantage over image-only methods in terms of the size of training data required.
</details>
<details>
<summary>摘要</summary>
segmentation of infected lung areas is crucial for assessing lung disease severity, such as pulmonary infections. current medical image segmentation methods are mostly uni-modal, relying solely on images. however, these image-only methods often produce inaccurate results without large amounts of annotated data. to address this challenge, we propose a language-driven segmentation method that utilizes text prompts to improve segmentation accuracy. experiments on the QaTa-COV19 dataset show that our method improves the dice score by at least 6.09% compared to uni-modal methods. furthermore, our extended study demonstrates the flexibility of multi-modal methods in terms of text information granularity and shows that multi-modal methods require significantly less training data than image-only methods.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Face-Image-Quality-Enhancement-Study-for-Face-Recognition"><a href="#Face-Image-Quality-Enhancement-Study-for-Face-Recognition" class="headerlink" title="Face Image Quality Enhancement Study for Face Recognition"></a>Face Image Quality Enhancement Study for Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05534">http://arxiv.org/abs/2307.05534</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Iqbal Nouyed, Na Zhang</li>
<li>for: 本研究探讨低质量face图像 face recognition的问题，尝试提高低质量face图像的识别精度。</li>
<li>methods: 使用当前最佳的人脸图像进行优化，开发了一种新的识别协议，以避免实验偏见。</li>
<li>results: 实验结果表明，使用优化后的face图像可以提高识别精度，但也存在一些挑战性的问题。<details>
<summary>Abstract</summary>
Unconstrained face recognition is an active research area among computer vision and biometric researchers for many years now. Still the problem of face recognition in low quality photos has not been well-studied so far. In this paper, we explore the face recognition performance on low quality photos, and we try to improve the accuracy in dealing with low quality face images. We assemble a large database with low quality photos, and examine the performance of face recognition algorithms for three different quality sets. Using state-of-the-art facial image enhancement approaches, we explore the face recognition performance for the enhanced face images. To perform this without experimental bias, we have developed a new protocol for recognition with low quality face photos and validate the performance experimentally. Our designed protocol for face recognition with low quality face images can be useful to other researchers. Moreover, experiment results show some of the challenging aspects of this problem.
</details>
<details>
<summary>摘要</summary>
<<SYS>>无约束面Recognition是计算机视觉和生物认证领域的活跃研究领域，数年来仍然没有充分研究低质量照片的面Recognition问题。在这篇论文中，我们探索了低质量照片中的面Recognition性能，并尝试提高对低质量面图像的准确率。我们组织了一个大型数据库，并对三个不同质量集进行了测试。使用当前的状态kemal facial image enhancement方法，我们探索了对加强的面图像进行认证的性能。为了避免实验偏见，我们开发了一种新的协议 для面Recognition with low quality face photos，并 Validate its performance experimentally。我们的设计的协议可以为其他研究人员提供帮助。此外，实验结果表明了一些面Recognition问题的挑战性方面。Translation notes:* "无约束" (wú jiè shì) means "unconstrained" in Chinese.* "面Recognition" (liǎn tiān xiǎng) means "face recognition" in Chinese.* "生物认证" (shēng wù rèn shè) means "biometric recognition" in Chinese.* "计算机视觉" (jìsuàn jīsuān) means "computer vision" in Chinese.* "数年来" (shù nián lái) means "for many years" in Chinese.* "仍然" (jiéguān) means "still" in Chinese.* "low quality" (gōng yǐn) means "low quality" in Chinese.* "照片" (zhāo pǐn) means "photos" in Chinese.* "面图像" (liǎn tú xiàng) means "face images" in Chinese.* " recognition" (tiān xiǎng) means "recognition" in Chinese.* "准确率" (zhèng qiú lǐ) means "accuracy" in Chinese.* "数据库" (shù jīng kù) means "database" in Chinese.* "测试" (cè shí) means "testing" in Chinese.* "状态kemal" (zhuàng tài kè mā) means "state-of-the-art" in Chinese.* "facial image enhancement" (liǎn tíng xiǎng yǎng) means "facial image enhancement" in Chinese.* "协议" (xié yì) means "protocol" in Chinese.* " Validate" (bèi yǐ) means "to validate" in Chinese.* "实验偏见" (shí yàn pēn jiàn) means "experimental bias" in Chinese.* "挑战性" (tiǎo zhàn xìng) means "challenging aspects" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Edge-Aware-Mirror-Network-for-Camouflaged-Object-Detection"><a href="#Edge-Aware-Mirror-Network-for-Camouflaged-Object-Detection" class="headerlink" title="Edge-Aware Mirror Network for Camouflaged Object Detection"></a>Edge-Aware Mirror Network for Camouflaged Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03932">http://arxiv.org/abs/2307.03932</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sdy1999/eamnet">https://github.com/sdy1999/eamnet</a></li>
<li>paper_authors: Dongyue Sun, Shiyao Jiang, Lin Qi</li>
<li>for: 提高隐形目标检测精度</li>
<li>methods: 提出了一种Edge-aware Mirror Network（EAMNet），通过在检测和分割过程中进行交叠引导，提高了目标检测和分割精度</li>
<li>results: 对三个常用的隐形目标检测数据集进行量化和质量测试，比较了与现有最佳基eline的比较，得到了更高的精度Here is the translation in English:</li>
<li>for: Improving the accuracy of camouflaged object detection</li>
<li>methods: Proposed a novel Edge-aware Mirror Network (EAMNet) that models edge detection and camouflaged object segmentation as a cross refinement process, consisting of a segmentation-induced edge aggregation module, an edge-induced integrity aggregation module, and a guided-residual channel attention module.</li>
<li>results: Quantitative and qualitative experiment results on three widely used COD datasets show that EAMNet outperforms existing cutting-edge baselines.Note that the translation is done in a simplified Chinese format, which is a more casual and conversational style of Chinese writing. If you prefer a more formal style, I can also provide that.<details>
<summary>Abstract</summary>
Existing edge-aware camouflaged object detection (COD) methods normally output the edge prediction in the early stage. However, edges are important and fundamental factors in the following segmentation task. Due to the high visual similarity between camouflaged targets and the surroundings, edge prior predicted in early stage usually introduces erroneous foreground-background and contaminates features for segmentation. To tackle this problem, we propose a novel Edge-aware Mirror Network (EAMNet), which models edge detection and camouflaged object segmentation as a cross refinement process. More specifically, EAMNet has a two-branch architecture, where a segmentation-induced edge aggregation module and an edge-induced integrity aggregation module are designed to cross-guide the segmentation branch and edge detection branch. A guided-residual channel attention module which leverages the residual connection and gated convolution finally better extracts structural details from low-level features. Quantitative and qualitative experiment results show that EAMNet outperforms existing cutting-edge baselines on three widely used COD datasets. Codes are available at https://github.com/sdy1999/EAMNet.
</details>
<details>
<summary>摘要</summary>
现有的隐形目标检测（COD）方法通常在早期输出边预测。然而，边是后续 segmentation 任务中非常重要的因素。由于隐形目标和周围环境的视觉相似性很高，早期边预测通常会导致误分别前景和背景，污染分割特征。为解决这个问题，我们提出了一种新的 Edge-aware Mirror Network（EAMNet），它将边检测和隐形目标分割视为交叠的过程。更 Specifically，EAMNet 具有两极性体系，包括 segmentation-induced edge aggregation module 和 edge-induced integrity aggregation module，这两个模块用于交叠导航分割支路和边检测支路。最后，一个受引用的残差核心注意力模块，通过残差连接和阻止 convolution，终于更好地提取低级特征的结构细节。量化和质量实验结果表明，EAMNet 在三个广泛使用的 COD 数据集上表现出色，超过现有的最新基线。代码可以在 https://github.com/sdy1999/EAMNet 中找到。
</details></li>
</ul>
<hr>
<h2 id="VS-TransGRU-A-Novel-Transformer-GRU-based-Framework-Enhanced-by-Visual-Semantic-Fusion-for-Egocentric-Action-Anticipation"><a href="#VS-TransGRU-A-Novel-Transformer-GRU-based-Framework-Enhanced-by-Visual-Semantic-Fusion-for-Egocentric-Action-Anticipation" class="headerlink" title="VS-TransGRU: A Novel Transformer-GRU-based Framework Enhanced by Visual-Semantic Fusion for Egocentric Action Anticipation"></a>VS-TransGRU: A Novel Transformer-GRU-based Framework Enhanced by Visual-Semantic Fusion for Egocentric Action Anticipation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03918">http://arxiv.org/abs/2307.03918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Congqi Cao, Ze Sun, Qinyi Lv, Lingtong Min, Yanning Zhang</li>
<li>for: This paper aims to improve the performance of egocentric action anticipation by proposing a novel visual-semantic fusion enhanced and Transformer GRU-based action anticipation framework.</li>
<li>methods: The proposed method introduces high-level semantic information to improve action anticipation performance, uses an effective visual-semantic fusion module, and employs a Transformer based encoder and GRU-based decoder to model long-term sequential and flexible iteration decoding.</li>
<li>results: The proposed method achieves new state-of-the-art performance on two large-scale first-person view datasets, outperforming previous approaches by a large margin.<details>
<summary>Abstract</summary>
Egocentric action anticipation is a challenging task that aims to make advanced predictions of future actions from current and historical observations in the first-person view. Most existing methods focus on improving the model architecture and loss function based on the visual input and recurrent neural network to boost the anticipation performance. However, these methods, which merely consider visual information and rely on a single network architecture, gradually reach a performance plateau. In order to fully understand what has been observed and capture the dependencies between current observations and future actions well enough, we propose a novel visual-semantic fusion enhanced and Transformer GRU-based action anticipation framework in this paper. Firstly, high-level semantic information is introduced to improve the performance of action anticipation for the first time. We propose to use the semantic features generated based on the class labels or directly from the visual observations to augment the original visual features. Secondly, an effective visual-semantic fusion module is proposed to make up for the semantic gap and fully utilize the complementarity of different modalities. Thirdly, to take advantage of both the parallel and autoregressive models, we design a Transformer based encoder for long-term sequential modeling and a GRU-based decoder for flexible iteration decoding. Extensive experiments on two large-scale first-person view datasets, i.e., EPIC-Kitchens and EGTEA Gaze+, validate the effectiveness of our proposed method, which achieves new state-of-the-art performance, outperforming previous approaches by a large margin.
</details>
<details>
<summary>摘要</summary>
先前的方法主要是通过提高模型架构和损失函数来提高预测性能，主要基于视觉输入和循环神经网络。然而，这些方法很快就会达到性能极限。为了全面理解已经观察到的内容和捕捉未来行为之间的依赖关系，我们在这篇论文中提出了一种新的视 semantic融合增强的动作预测框架。首先，我们提出了在动作预测中使用高级 semantic信息，以提高性能。我们使用基于类别标签或直接从视觉观察到的semantic特征来增强原始视觉特征。其次，我们提出了一种有效的视 semantic融合模块，以弥补semantic漏斗并全面利用不同模式之间的共轭性。最后，为了利用并行和自适应模型，我们设计了基于Transformer的编码器进行长期序列化和基于GRU的解码器进行灵活迭代解码。我们在两个大规模的第一人视角数据集，即EPIC-Kitchens和EGTEA Gaze+上进行了广泛的实验，并证明了我们提出的方法的效iveness，成功击败了之前的方法，占新的状态符极限。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Self-Attack-Defense-and-Spatial-Temporal-Relation-Mining-for-Visible-Infrared-Video-Person-Re-Identification"><a href="#Adversarial-Self-Attack-Defense-and-Spatial-Temporal-Relation-Mining-for-Visible-Infrared-Video-Person-Re-Identification" class="headerlink" title="Adversarial Self-Attack Defense and Spatial-Temporal Relation Mining for Visible-Infrared Video Person Re-Identification"></a>Adversarial Self-Attack Defense and Spatial-Temporal Relation Mining for Visible-Infrared Video Person Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03903">http://arxiv.org/abs/2307.03903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huafeng Li, Le Xu, Yafei Zhang, Dapeng Tao, Zhengtao Yu<br>for:The paper is written for solving the problem of cross-modal pedestrian identity matching in visible-infrared video person re-identification, by proposing a new method that integrates adversarial self-attack defense and spatial-temporal relation mining.methods:The proposed method uses adversarial self-attack to defend against the perturbations caused by changes in views, posture, background, and modal discrepancy, and a spatial-temporal information-guided feature representation network to extract robust features from video sequences.results:The proposed method exhibits compelling performance on large-scale cross-modality video datasets.Here is the Chinese version of the three information:for:这篇论文是为了解决视频人识别中的跨模态人识别问题，提出了一种新的方法，即利用对抗自我攻击防御和空间时间关系挖掘。methods:该方法使用对抗自我攻击来防御视频中人识别特征的变化，并使用空间时间关系引导的特征表示网络来提取更加稳定的特征。results:该方法在大规模跨模态视频 dataset 上表现出了吸引人的表现。<details>
<summary>Abstract</summary>
In visible-infrared video person re-identification (re-ID), extracting features not affected by complex scenes (such as modality, camera views, pedestrian pose, background, etc.) changes, and mining and utilizing motion information are the keys to solving cross-modal pedestrian identity matching. To this end, the paper proposes a new visible-infrared video person re-ID method from a novel perspective, i.e., adversarial self-attack defense and spatial-temporal relation mining. In this work, the changes of views, posture, background and modal discrepancy are considered as the main factors that cause the perturbations of person identity features. Such interference information contained in the training samples is used as an adversarial perturbation. It performs adversarial attacks on the re-ID model during the training to make the model more robust to these unfavorable factors. The attack from the adversarial perturbation is introduced by activating the interference information contained in the input samples without generating adversarial samples, and it can be thus called adversarial self-attack. This design allows adversarial attack and defense to be integrated into one framework. This paper further proposes a spatial-temporal information-guided feature representation network to use the information in video sequences. The network cannot only extract the information contained in the video-frame sequences but also use the relation of the local information in space to guide the network to extract more robust features. The proposed method exhibits compelling performance on large-scale cross-modality video datasets. The source code of the proposed method will be released at https://github.com/lhf12278/xxx.
</details>
<details>
<summary>摘要</summary>
visible-infrared видео人重复标识（re-ID）中，提取不受复杂场景（如Modalidad、摄像头视图、行人姿态、背景等）变化的特征是键，以实现交叉模式人标识匹配。为此，本文提出了一种新的可见infrared视频人重复标识方法，即反对抗自我攻击和空间时间关系挖掘。在这种方法中，视图、姿态、背景和模式差异被视为人标识特征变化的主要因素。这些干扰信息被包含在训练样本中，并用作对抗攻击。通过在训练中引入这些干扰信息，使模型更加抗性于这些不利因素。此外，文章还提出了一种基于视频序列的空间时间信息引导特征表示网络，以使用视频序列中的信息。该网络不仅可以提取视频帧序列中的信息，还可以使用当地信息的空间关系来引导网络提取更加Robust的特征。提议的方法在大规模交叉模式视频数据集上展示了吸引人的表现。源代码将在https://github.com/lhf12278/xxx上发布。
</details></li>
</ul>
<hr>
<h2 id="StyleGAN3-Generative-Networks-for-Improving-the-Equivariance-of-Translation-and-Rotation"><a href="#StyleGAN3-Generative-Networks-for-Improving-the-Equivariance-of-Translation-and-Rotation" class="headerlink" title="StyleGAN3: Generative Networks for Improving the Equivariance of Translation and Rotation"></a>StyleGAN3: Generative Networks for Improving the Equivariance of Translation and Rotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03898">http://arxiv.org/abs/2307.03898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianlei Zhu, Junqi Chen, Renzhe Zhu, Gaurav Gupta</li>
<li>for: 本研究的目的是对StyleGAN进行改进，以提高其对等变换的能力。</li>
<li>methods: 本研究使用了StyleGAN2和两个修改后的StyleGAN3版本，并使用FFHQ dataset进行评估。</li>
<li>results: 研究发现，StyleGAN3版本是一个更好的生成网络，可以提高等变换性。这些发现有助于动画和视频的创作。Translation:</li>
<li>for: The purpose of this study is to improve the equivariance of StyleGAN.</li>
<li>methods: The study used StyleGAN2 and two modified versions of StyleGAN3, and evaluated them using the FFHQ dataset.</li>
<li>results: The study found that the StyleGAN3 version is a better generative network, with improved equivariance. These findings are beneficial for the creation of animations and videos.<details>
<summary>Abstract</summary>
StyleGAN can use style to affect facial posture and identity features, and noise to affect hair, wrinkles, skin color and other details. Among these, the outcomes of the picture processing will vary slightly between different versions of styleGAN. As a result, the comparison of performance differences between styleGAN2 and the two modified versions of styleGAN3 will be the main focus of this study. We used the FFHQ dataset as the dataset and FID, EQ-T, and EQ-R were used to be the assessment of the model. In the end, we discovered that Stylegan3 version is a better generative network to improve the equivariance. Our findings have a positive impact on the creation of animation and videos.
</details>
<details>
<summary>摘要</summary>
StyleGAN 可以通过风格来影响脸部姿势和个体特征，并通过噪音来影响头发、皱纹、皮肤颜色等细节。 Among these, the outcomes of the picture processing will vary slightly between different versions of StyleGAN. As a result, the comparison of performance differences between StyleGAN2 and the two modified versions of StyleGAN3 will be the main focus of this study. We used the FFHQ dataset as the dataset and FID, EQ-T, and EQ-R were used to be the assessment of the model. In the end, we discovered that Stylegan3 version is a better generative network to improve the equivariance. Our findings have a positive impact on the creation of animation and videos.Here's the translation in Traditional Chinese: StyleGAN 可以透过风格来影响脸部姿势和个体特征，并通过噪音来影响头发、皱纹、皮肤颜色等细节。 Among these, the outcomes of the picture processing will vary slightly between different versions of StyleGAN. As a result, the comparison of performance differences between StyleGAN2 and the two modified versions of StyleGAN3 will be the main focus of this study. We used the FFHQ dataset as the dataset and FID, EQ-T, and EQ-R were used to be the assessment of the model. In the end, we discovered that Stylegan3 version is a better generative network to improve the equivariance. Our findings have a positive impact on the creation of animation and videos.
</details></li>
</ul>
<hr>
<h2 id="HUMS2023-Data-Challenge-Result-Submission"><a href="#HUMS2023-Data-Challenge-Result-Submission" class="headerlink" title="HUMS2023 Data Challenge Result Submission"></a>HUMS2023 Data Challenge Result Submission</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03871">http://arxiv.org/abs/2307.03871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dhiraj Neupane, Lakpa Dorje Tamang, Ngoc Dung Huynh, Mohamed Reda Bouadjenek, Sunil Aryal</li>
<li>for: 这项研究的目的是提出一种早期检测方法。</li>
<li>methods: 这项研究使用了绘图和Scalogram图像分析，以及计算每个信号的平均值、标准差（STD）和峰值至峰值（P2P）值。此外，研究还使用了 autoregressive integrated moving average（ARIMA）方法跟踪进程。</li>
<li>results: 研究发现了一些有用的结果，包括检测到的瑕理症状和ARIMA方法的预测结果。<details>
<summary>Abstract</summary>
We implemented a simple method for early detection in this research. The implemented methods are plotting the given mat files and analyzing scalogram images generated by performing Continuous Wavelet Transform (CWT) on the samples. Also, finding the mean, standard deviation (STD), and peak-to-peak (P2P) values from each signal also helped detect faulty signs. We have implemented the autoregressive integrated moving average (ARIMA) method to track the progression.
</details>
<details>
<summary>摘要</summary>
我们在这项研究中实现了一种简单的早期检测方法。我们使用了Continuous Wavelet Transform (CWT)来生成scalogram图像，并从每个信号中计算了平均值、标准差（STD）和峰值至谷值（P2P）。此外，我们还使用了autoregressive integrated moving average (ARIMA)方法来跟踪进程。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Sketch-A-Shape-Zero-Shot-Sketch-to-3D-Shape-Generation"><a href="#Sketch-A-Shape-Zero-Shot-Sketch-to-3D-Shape-Generation" class="headerlink" title="Sketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation"></a>Sketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03869">http://arxiv.org/abs/2307.03869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Sanghi, Pradeep Kumar Jayaraman, Arianna Rampini, Joseph Lambourne, Hooman Shayani, Evan Atherton, Saeid Asgari Taghanaki</li>
<li>for: 本研究旨在exploring how large pre-trained models can be used to generate 3D shapes from sketches, which has been an open challenge due to limited datasets and varying abstraction levels in the sketches.</li>
<li>methods: 我们使用了一种简单的方法，即在训练时使用大型预训练视觉模型的特征来conditioning 3D生成模型，以便在推理时从绘制 generate 3D shapes.</li>
<li>results: 我们的实验表明，使用大型预训练视觉模型的特征可以允许我们在推理时从绘制 generate 3D shapes, regardless of the level of abstraction in the sketches. 我们还发现这些特征可以跨域传递Semantic信号，从而实现多个3D shapes的生成 per each input sketch.<details>
<summary>Abstract</summary>
Significant progress has recently been made in creative applications of large pre-trained models for downstream tasks in 3D vision, such as text-to-shape generation. This motivates our investigation of how these pre-trained models can be used effectively to generate 3D shapes from sketches, which has largely remained an open challenge due to the limited sketch-shape paired datasets and the varying level of abstraction in the sketches. We discover that conditioning a 3D generative model on the features (obtained from a frozen large pre-trained vision model) of synthetic renderings during training enables us to effectively generate 3D shapes from sketches at inference time. This suggests that the large pre-trained vision model features carry semantic signals that are resilient to domain shifts, i.e., allowing us to use only RGB renderings, but generalizing to sketches at inference time. We conduct a comprehensive set of experiments investigating different design factors and demonstrate the effectiveness of our straightforward approach for generation of multiple 3D shapes per each input sketch regardless of their level of abstraction without requiring any paired datasets during training.
</details>
<details>
<summary>摘要</summary>
Recently, there have been significant advances in using large pre-trained models for downstream tasks in 3D vision, such as text-to-shape generation. This has inspired us to explore how these pre-trained models can be used effectively to generate 3D shapes from sketches, which has been a long-standing challenge due to the limited availability of sketch-shape paired datasets and the varying level of abstraction in the sketches. We discovered that conditioning a 3D generative model on the features (obtained from a frozen large pre-trained vision model) of synthetic renderings during training enables us to effectively generate 3D shapes from sketches at inference time. This suggests that the large pre-trained vision model features carry semantic signals that are robust to domain shifts, i.e., allowing us to use only RGB renderings, but generalizing to sketches at inference time. We conducted a comprehensive set of experiments investigating different design factors and demonstrated the effectiveness of our straightforward approach for generating multiple 3D shapes per each input sketch regardless of their level of abstraction without requiring any paired datasets during training.
</details></li>
</ul>
<hr>
<h2 id="Novel-Categories-Discovery-from-probability-matrix-perspective"><a href="#Novel-Categories-Discovery-from-probability-matrix-perspective" class="headerlink" title="Novel Categories Discovery from probability matrix perspective"></a>Novel Categories Discovery from probability matrix perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03856">http://arxiv.org/abs/2307.03856</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mxahan/nev-ncd">https://github.com/mxahan/nev-ncd</a></li>
<li>paper_authors: Zahid Hasan, Abu Zaher Md Faridee, Masud Ahmed, Sanjay Purushotham, Heesung Kwon, Hyungtae Lee, Nirmalya Roy</li>
<li>for: 本研究是为了解决开放世界问题，通过类 semantics 进行知道的分类和 clustering novel category。</li>
<li>methods: 我们从 novel data 概率矩阵的角度 investigate NCD，并利用提供的 novel class 多尼尔分布（ categorical distribution）的连接。我们预测可以通过学习其类分布来实现semantic-based novel data clustering。我们提出了一些新的约束，包括实例级别的信息约束和第一个统计特征约束。</li>
<li>results: 我们的简单方法成功地实现了基于类 semantics 的 novel data clustering，但需要提供类 semantic similarity  между标签未标注类。我们在图像和视频模式下 demonstate了我们的方法的探索性。此外，我们进行了广泛的减少研究，以提供更好的理解。我们的方法可以在 Cifar10、UCF101 和 MPSC-ARL 数据集上实现 <del>94%、</del>93% 和 <del>85% 的分类精度，同时实现 ~90%、</del>84% 和 ~72% 的 clustering 精度，与状态 искусственный智能方法相匹配。<details>
<summary>Abstract</summary>
Novel Categories Discovery (NCD) tackles the open-world problem of classifying known and clustering novel categories based on the class semantics using partial class space annotated data. Unlike traditional pseudo-label and retraining, we investigate NCD from the novel data probability matrix perspective. We leverage the connection between NCD novel data sampling with provided novel class Multinoulli (categorical) distribution and hypothesize to implicitly achieve semantic-based novel data clustering by learning their class distribution. We propose novel constraints on first-order (mean) and second-order (covariance) statistics of probability matrix features while applying instance-wise information constraints. In particular, we align the neuron distribution (activation patterns) under a large batch of Monte-Carlo novel data sampling by matching their empirical features mean and covariance with the provided Multinoulli-distribution. Simultaneously, we minimize entropy and enforce prediction consistency for each instance. Our simple approach successfully realizes semantic-based novel data clustering provided the semantic similarity between label-unlabeled classes. We demonstrate the discriminative capacity of our approaches in image and video modalities. Moreover, we perform extensive ablation studies regarding data, networks, and our framework components to provide better insights. Our approach maintains ~94%, ~93%, and ~85%, classification accuracy in labeled data while achieving ~90%, ~84%, and ~72% clustering accuracy for novel categories for Cifar10, UCF101, and MPSC-ARL datasets that matches state-of-the-art approaches without any external clustering.
</details>
<details>
<summary>摘要</summary>
新领域发现（NCD）处理开放世界中的已知类和新类分类问题，基于类 semantics 使用偏序数据进行分类。 unlike traditional pseudo-label 和重新训练，我们从新数据概率矩阵的视角进行研究。我们利用新数据采样与提供的新类 Multinoulli 分布之间的连接，并假设通过学习其类分布来隐式地实现 semantic-based 新数据归类。我们提出了新的一级（平均值）和二级（协方差）统计特征的约束，并在实例级别上应用情况约束。特别是，我们在大批量 Monte-Carlo 新数据采样中对 neuron 分布（活动模式）进行对齐，使其 empirical features 的平均值和协方差与提供的 Multinoulli-分布匹配。同时，我们减少 entropy 并强制实例级别预测一致。我们简单的方法成功地实现 semantic-based 新数据归类，只要提供类相似性。我们在图像和视频模式中展示了我们的方法的探索性能。此外，我们进行了广泛的数据、网络和框架组件的拟合研究，以提供更好的理解。我们的方法在 Cifar10、UCF101 和 MPSC-ARL 数据集上保持了 ~94%、~93% 和 ~85% 的分类精度，同时实现了 ~90%、~84% 和 ~72% 的归类精度，与状态艺技术相匹配。
</details></li>
</ul>
<hr>
<h2 id="TBSS-A-novel-computational-method-for-Tract-Based-Spatial-Statistics"><a href="#TBSS-A-novel-computational-method-for-Tract-Based-Spatial-Statistics" class="headerlink" title="TBSS++: A novel computational method for Tract-Based Spatial Statistics"></a>TBSS++: A novel computational method for Tract-Based Spatial Statistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05387">http://arxiv.org/abs/2307.05387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davood Karimi, Hamza Kebiri, Ali Gholipour</li>
<li>for: 这个论文旨在提高Diffusion-weighted磁共振成像（dMRI）中评估大脑白atter的精度和可靠性。</li>
<li>methods: 该论文提出了一种新的计算框架，通过准确的分割和数据集之间的精确匹配来超越现有方法的缺陷和局限性。</li>
<li>results: 对比TBSS方法，该论文的提议方法显示了更高的复制性和对数据干扰的Robustness。<details>
<summary>Abstract</summary>
Diffusion-weighted magnetic resonance imaging (dMRI) is widely used to assess the brain white matter. One of the most common computations in dMRI involves cross-subject tract-specific analysis, whereby dMRI-derived biomarkers are compared between cohorts of subjects. The accuracy and reliability of these studies hinges on the ability to compare precisely the same white matter tracts across subjects. This is an intricate and error-prone computation. Existing computational methods such as Tract-Based Spatial Statistics (TBSS) suffer from a host of shortcomings and limitations that can seriously undermine the validity of the results. We present a new computational framework that overcomes the limitations of existing methods via (i) accurate segmentation of the tracts, and (ii) precise registration of data from different subjects/scans. The registration is based on fiber orientation distributions. To further improve the alignment of cross-subject data, we create detailed atlases of white matter tracts. These atlases serve as an unbiased reference space where the data from all subjects is registered for comparison. Extensive evaluations show that, compared with TBSS, our proposed framework offers significantly higher reproducibility and robustness to data perturbations. Our method promises a drastic improvement in accuracy and reproducibility of cross-subject dMRI studies that are routinely used in neuroscience and medical research.
</details>
<details>
<summary>摘要</summary>
Diffusion-weighted магнитная резонансная томография (dMRI) 广泛用于评估大脑白 mater. 一种最常见的计算在 dMRI 中是 cross-subject 股道特征分析，其中 dMRI 获得的生物标志物被比较 между 团队的Subjects. 这些研究的准确性和可靠性取决于能够准确比较不同主体/扫描数据中的白 mater股道。 现有的计算方法，如 Tract-Based Spatial Statistics (TBSS)，受到多种缺陷和局限性的影响，可能会严重损害研究结果的有效性。 我们提出了一种新的计算框架，通过以下两个方法来缓解现有方法的局限性：1. 精准的股道分割2. 基于纤维方向分布的数据重复注册为了进一步提高交由数据的对接，我们创建了详细的白 mater股道 атла斯。 这些 атла斯作为一种无偏参照空间，用于注册所有主体的数据，以便对比。 我们的方法与 TBSS 相比，具有显著更高的重复性和对数据扰动的抗难度。 我们的方法承诺可以大幅提高交由数据的精度和可重复性，这些研究在 neuroscience 和医学研究中 Routinely 使用。
</details></li>
</ul>
<hr>
<h2 id="Blocks2World-Controlling-Realistic-Scenes-with-Editable-Primitives"><a href="#Blocks2World-Controlling-Realistic-Scenes-with-Editable-Primitives" class="headerlink" title="Blocks2World: Controlling Realistic Scenes with Editable Primitives"></a>Blocks2World: Controlling Realistic Scenes with Editable Primitives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03847">http://arxiv.org/abs/2307.03847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vaibhav Vavilala, Seemandhar Jain, Rahul Vasanth, Anand Bhattad, David Forsyth</li>
<li>for: 3D scene rendering and editing</li>
<li>methods: convex decomposition of images and conditioned synthesis</li>
<li>results: highly customizable scene rendering process with remarkable control over the synthesis of novel and edited scenesHere’s the full summary in Simplified Chinese:</li>
<li>for: 这paper是为了解决3D场景渲染和编辑问题</li>
<li>methods: 使用几何分解和受控合成</li>
<li>results: 提供一种高度自定义的场景渲染过程，可以高度控制创建和编辑场景的图像生成I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
We present Blocks2World, a novel method for 3D scene rendering and editing that leverages a two-step process: convex decomposition of images and conditioned synthesis. Our technique begins by extracting 3D parallelepipeds from various objects in a given scene using convex decomposition, thus obtaining a primitive representation of the scene. These primitives are then utilized to generate paired data through simple ray-traced depth maps. The next stage involves training a conditioned model that learns to generate images from the 2D-rendered convex primitives. This step establishes a direct mapping between the 3D model and its 2D representation, effectively learning the transition from a 3D model to an image. Once the model is fully trained, it offers remarkable control over the synthesis of novel and edited scenes. This is achieved by manipulating the primitives at test time, including translating or adding them, thereby enabling a highly customizable scene rendering process. Our method provides a fresh perspective on 3D scene rendering and editing, offering control and flexibility. It opens up new avenues for research and applications in the field, including authoring and data augmentation.
</details>
<details>
<summary>摘要</summary>
我们介绍了Blocks2World，一种新的3D场景渲染和编辑方法，利用了两步过程：几何分解和条件生成。我们的技术首先从给定场景中的各种物体中提取3D矩形体使用几何分解，从而获得场景的原始表示。这些基本对象然后用简单的投影法生成对应的深度地图。接下来，我们将这些对应的数据用条件学习模型进行训练，以学习将3D模型转换为图像。这个步骤建立了3D模型和其2D表示之间的直接映射，从而学习了将3D模型转换为图像的过程。一旦模型完全训练完成，它可以在测试时对基本对象进行 manipulate，包括平移或添加，以此获得高度自定义的场景渲染过程。我们的方法为3D场景渲染和编辑带来了新的视角，提供了控制和灵活性。它打开了新的研究和应用领域，包括作者和数据增强。
</details></li>
</ul>
<hr>
<h2 id="Invariant-Scattering-Transform-for-Medical-Imaging"><a href="#Invariant-Scattering-Transform-for-Medical-Imaging" class="headerlink" title="Invariant Scattering Transform for Medical Imaging"></a>Invariant Scattering Transform for Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04771">http://arxiv.org/abs/2307.04771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nafisa Labiba Ishrat Huda, Angona Biswas, MD Abdullah Al Nasim, Md. Fahim Rahman, Shoaib Ahmed</li>
<li>for: 这个论文主要研究的是用深度学习对医疗图像进行分类的方法。</li>
<li>methods: 这篇论文使用了散射变换，它是一种基于干扰的信号处理技术，可以帮助建立有用的图像分类表示。</li>
<li>results: 研究发现，使用散射变换可以提高医疗图像分类的精度和效率。Here’s the full text in Simplified Chinese:</li>
<li>for: 这个论文主要研究的是用深度学习对医疗图像进行分类的方法。</li>
<li>methods: 这篇论文使用了散射变换，它是一种基于干扰的信号处理技术，可以帮助建立有用的图像分类表示。</li>
<li>results: 研究发现，使用散射变换可以提高医疗图像分类的精度和效率。<details>
<summary>Abstract</summary>
Invariant scattering transform introduces new area of research that merges the signal processing with deep learning for computer vision. Nowadays, Deep Learning algorithms are able to solve a variety of problems in medical sector. Medical images are used to detect diseases brain cancer or tumor, Alzheimer's disease, breast cancer, Parkinson's disease and many others. During pandemic back in 2020, machine learning and deep learning has played a critical role to detect COVID-19 which included mutation analysis, prediction, diagnosis and decision making. Medical images like X-ray, MRI known as magnetic resonance imaging, CT scans are used for detecting diseases. There is another method in deep learning for medical imaging which is scattering transform. It builds useful signal representation for image classification. It is a wavelet technique; which is impactful for medical image classification problems. This research article discusses scattering transform as the efficient system for medical image analysis where it's figured by scattering the signal information implemented in a deep convolutional network. A step by step case study is manifested at this research work.
</details>
<details>
<summary>摘要</summary>
“恒常散射变换引入了一新的研究领域，即将信号处理与深度学习结合用于计算机视觉。目前，深度学习算法能够解决医疗领域多种问题。医疗图像用于检测脑癌或肿瘤、阿尔茨曼病、乳癌、 Parkinson 病等。在2020年大流行期间，机器学习和深度学习扮演了关键的角色，用于检测 COVID-19，包括变异分析、预测、诊断和决策。医疗图像如 X 射、MRI（磁共振成像）、CT扫描是用于检测疾病的。另一种在深度学习中用于医疗图像分类的方法是散射变换。它建立了有用的信号表示，用于图像分类问题。这篇研究文章介绍了散射变换作为医疗图像分析中效果的系统，其中将信号信息在深度卷积神经网络中散射。本研究文章通过一个步骤案例研究。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Thoracic-Cartilage-Ultrasound-CT-Registration-using-Dense-Skeleton-Graph"><a href="#Thoracic-Cartilage-Ultrasound-CT-Registration-using-Dense-Skeleton-Graph" class="headerlink" title="Thoracic Cartilage Ultrasound-CT Registration using Dense Skeleton Graph"></a>Thoracic Cartilage Ultrasound-CT Registration using Dense Skeleton Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03800">http://arxiv.org/abs/2307.03800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongliang Jiang, Chenyang Li, Xuesong Li, Nassir Navab</li>
<li>for: 提高自动ultrasound（US）成像的精度和效率，尤其是在骨骼结构下方的高阻挡性肺部应用中。</li>
<li>methods: 使用图形基于非RIGID注册方法，考虑到骨骼表面特征，从CT模板中提取最佳图形表示，并使用自组织地图进行两次Successive Registration。</li>
<li>results: 对五个不同患者的软骨点云进行了评估，结果表明，提案的图形基于注册方法可以有效地将CT中的轨迹映射到当前设置中，并且非RIGID注册结果中的 Hausdorff 距离（Mean$\pm$SD）为9.48$\pm$0.27 mm，路径传输错误（Euclidean distance）为2.21$\pm$1.11 mm。<details>
<summary>Abstract</summary>
Autonomous ultrasound (US) imaging has gained increased interest recently, and it has been seen as a potential solution to overcome the limitations of free-hand US examinations, such as inter-operator variations. However, it is still challenging to accurately map planned paths from a generic atlas to individual patients, particularly for thoracic applications with high acoustic-impedance bone structures under the skin. To address this challenge, a graph-based non-rigid registration is proposed to enable transferring planned paths from the atlas to the current setup by explicitly considering subcutaneous bone surface features instead of the skin surface. To this end, the sternum and cartilage branches are segmented using a template matching to assist coarse alignment of US and CT point clouds. Afterward, a directed graph is generated based on the CT template. Then, the self-organizing map using geographical distance is successively performed twice to extract the optimal graph representations for CT and US point clouds, individually. To evaluate the proposed approach, five cartilage point clouds from distinct patients are employed. The results demonstrate that the proposed graph-based registration can effectively map trajectories from CT to the current setup for displaying US views through limited intercostal space. The non-rigid registration results in terms of Hausdorff distance (Mean$\pm$SD) is 9.48$\pm$0.27 mm and the path transferring error in terms of Euclidean distance is 2.21$\pm$1.11 mm.
</details>
<details>
<summary>摘要</summary>
自主式超声成像（US）已经在最近得到了更多的关注，被视为可以解决自由手超声检测中的操作员间变化的问题。然而，将规划的路径从通用Atlas到个体患者中的精准映射仍然是一个挑战。为解决这个问题，一种基于图的非RIGID注册方法被提议，以便将规划的路径从Atlas传递到当前设置，并且特别考虑下皮骨表面特征。为此，使用模板匹配将气肠和软骨分支分别分割出来。然后，基于CT模板生成了指向图。接着，在CT和US点云上进行了顺序的自组织地图使用地理 distance来抽取最佳表示。为评估提议方法，使用了五个不同患者的软骨点云。结果表明，提议的图基于注册可以有效地将CT中的路径映射到当前设置中，并且非RIGID注册的 Hausdorff距离（Mean$\pm$SD）为9.48$\pm$0.27 mm，路径传输错误（Euclidean distance）为2.21$\pm$1.11 mm。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Lottery-Ticket-Hypothesis-with-Explainability-Methods-Insights-into-Sparse-Network-Performance"><a href="#Exploring-the-Lottery-Ticket-Hypothesis-with-Explainability-Methods-Insights-into-Sparse-Network-Performance" class="headerlink" title="Exploring the Lottery Ticket Hypothesis with Explainability Methods: Insights into Sparse Network Performance"></a>Exploring the Lottery Ticket Hypothesis with Explainability Methods: Insights into Sparse Network Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13698">http://arxiv.org/abs/2307.13698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shantanu Ghosh, Kayhan Batmanghelich</li>
<li>for: 这个论文旨在找出一个高性能的稀疏网络，以便在有限存储的设备上部署，如移动电话。同时，AI的可解释性是非常重要的。</li>
<li>methods: 这个论文使用了 Lottery Ticket Hypothesis（LTH）来找到一个深度网络中的一个高性能的子网络。但是，有限的研究已经发现了LTH在可解释性方面的成功或失败。这个论文 исследова了剪辑后网络的性能是如何逐渐增加或减少的原因。使用Grad-CAM和Post-hoc概念瓶隔（PCBM）来调查剪辑后网络的可解释性。</li>
<li>results: 研究发现，随着剪辑更多的参数，网络的性能逐渐下降。发现的概念和像素从剪辑后的网络与原始网络不匹配，可能是性能下降的原因。<details>
<summary>Abstract</summary>
Discovering a high-performing sparse network within a massive neural network is advantageous for deploying them on devices with limited storage, such as mobile phones. Additionally, model explainability is essential to fostering trust in AI. The Lottery Ticket Hypothesis (LTH) finds a network within a deep network with comparable or superior performance to the original model. However, limited study has been conducted on the success or failure of LTH in terms of explainability. In this work, we examine why the performance of the pruned networks gradually increases or decreases. Using Grad-CAM and Post-hoc concept bottleneck models (PCBMs), respectively, we investigate the explainability of pruned networks in terms of pixels and high-level concepts. We perform extensive experiments across vision and medical imaging datasets. As more weights are pruned, the performance of the network degrades. The discovered concepts and pixels from the pruned networks are inconsistent with the original network -- a possible reason for the drop in performance.
</details>
<details>
<summary>摘要</summary>
发现一个高性能稀畴网络在大规模神经网络中是有利于在具有限制存储的设备上部署，如移动电话。此外，AI的可解释性是提高人工智能的信任的关键。抽奖假设（LTH）找到一个在深度网络中的网络，其性能与原始模型相当或更高。然而，有限的研究在LTH的成功或失败方面进行了解释性的研究。在这项工作中，我们调查了剪除网络性能的增加或减少原因。使用Grad-CAM和后置概念瓶颈模型（PCBM），我们研究剪除网络的可解释性，即像素和高级概念。我们在视觉和医学影像 dataset 上进行了广泛的实验。随着更多的权重被剪除，网络的性能下降。发现的概念和像素从剪除网络与原始网络不匹配，可能是性能下降的原因。
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Forestry-Images-Conditioned-on-Plant-Phenotype-Using-a-Generative-Adversarial-Network"><a href="#Synthesizing-Forestry-Images-Conditioned-on-Plant-Phenotype-Using-a-Generative-Adversarial-Network" class="headerlink" title="Synthesizing Forestry Images Conditioned on Plant Phenotype Using a Generative Adversarial Network"></a>Synthesizing Forestry Images Conditioned on Plant Phenotype Using a Generative Adversarial Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03789">http://arxiv.org/abs/2307.03789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debasmita Pal, Arun Ross</li>
<li>for: 这种研究的目的是开发一种基于生成对抗网络（GAN）的方法，用于生成符合某特定地区植被特征的人工森林图像，以提高农业生产力。</li>
<li>methods: 这种方法使用了自动化的数字相机图像，提供由国家生态观测网络（NEON），并由phenocam网络处理。它还使用了生成对抗网络（GAN）来生成符合植被特征的人工图像。</li>
<li>results: 这种方法可以准确地生成符合植被特征的人工图像，并且可以用来预测另一种植被特征：植物的红色度。这种方法的可重复性和扩展性也被证明。<details>
<summary>Abstract</summary>
Plant phenology and phenotype prediction using remote sensing data is increasingly gaining the attention of the plant science community to improve agricultural productivity. In this work, we generate synthetic forestry images that satisfy certain phenotypic attributes, viz. canopy greenness. The greenness index of plants describes a particular vegetation type in a mixed forest. Our objective is to develop a Generative Adversarial Network (GAN) to synthesize forestry images conditioned on this continuous attribute, i.e., greenness of vegetation, over a specific region of interest. The training data is based on the automated digital camera imagery provided by the National Ecological Observatory Network (NEON) and processed by the PhenoCam Network. The synthetic images generated by our method are also used to predict another phenotypic attribute, viz., redness of plants. The Structural SIMilarity (SSIM) index is utilized to assess the quality of the synthetic images. The greenness and redness indices of the generated synthetic images are compared against that of the original images using Root Mean Squared Error (RMSE) in order to evaluate their accuracy and integrity. Moreover, the generalizability and scalability of our proposed GAN model is determined by effectively transforming it to generate synthetic images for other forest sites and vegetation types.
</details>
<details>
<summary>摘要</summary>
植物生理学和形态预测使用远程感知数据在农业生产力提高方面得到越来越多的关注。在这项工作中，我们生成了符合某些形态特性的人工森林图像，其中一个是叶绿度。叶绿度指的是某种混合林中的植物种类。我们的目标是使用生成 adversarial Network (GAN) 来生成基于这个连续特征（植物覆盖物的绿度）的森林图像，在特定区域上进行条件生成。我们的训练数据来自自动化的数字相机图像，由国家生态观测网络（NEON）提供，并由phenoCam网络处理。我们的生成的人工图像也用于预测另一个形态特性：植物的红度。我们使用结构相似性（SSIM）指数来评估生成的图像质量。我们比较生成的绿度和红度指数与原始图像的Root Mean Squared Error（RMSE）来评估它们的准确性和完整性。此外，我们还确定了我们提议的GAN模型的普适性和扩展性，通过将其转换为生成其他森林站点和植物类型的 synthetic 图像。
</details></li>
</ul>
<hr>
<h2 id="Context-aware-Pedestrian-Trajectory-Prediction-with-Multimodal-Transformer"><a href="#Context-aware-Pedestrian-Trajectory-Prediction-with-Multimodal-Transformer" class="headerlink" title="Context-aware Pedestrian Trajectory Prediction with Multimodal Transformer"></a>Context-aware Pedestrian Trajectory Prediction with Multimodal Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03786">http://arxiv.org/abs/2307.03786</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haleh Damirchi, Michael Greenspan, Ali Etemad</li>
<li>for: 预测未来行人轨迹</li>
<li>methods: 使用多ModalEncoder-Decoder transformer架构，输入包括行人位置和ego汽车速度，单pass预测整个未来轨迹，适用于嵌入式边缘部署</li>
<li>results: 与当前状态艺术比较，常量错误低于0.5、1.0和1.5秒三个时刻点，并且比当前状态艺术更快于PIE和JAAD两个数据集。此外，灵活的多Modal配置对方法的影响也进行了证明。<details>
<summary>Abstract</summary>
We propose a novel solution for predicting future trajectories of pedestrians. Our method uses a multimodal encoder-decoder transformer architecture, which takes as input both pedestrian locations and ego-vehicle speeds. Notably, our decoder predicts the entire future trajectory in a single-pass and does not perform one-step-ahead prediction, which makes the method effective for embedded edge deployment. We perform detailed experiments and evaluate our method on two popular datasets, PIE and JAAD. Quantitative results demonstrate the superiority of our proposed model over the current state-of-the-art, which consistently achieves the lowest error for 3 time horizons of 0.5, 1.0 and 1.5 seconds. Moreover, the proposed method is significantly faster than the state-of-the-art for the two datasets of PIE and JAAD. Lastly, ablation experiments demonstrate the impact of the key multimodal configuration of our method.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的解决方案，用于预测行人未来路径。我们的方法使用一种多ModalEncoder-Decoder变换架构，该架构接受行人位置和自身车速度作为输入。值得注意的是，我们的解码器在单次执行中预测整个未来路径，而不是一步预测，这使得方法适合嵌入式边缘部署。我们进行了详细的实验和PIE和JAAD两个流行的数据集上的评估。量化结果表明，我们的提出的模型在0.5、1.0和1.5秒三个时刻的错误率始终保持最低，并且与现有状态的艺术 consistently outperform。此外，我们的方法在PIE和JAAD两个数据集上明显更快于现有状态。最后，我们进行了关键多模式配置的ablation实验，以评估其影响。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-3D-out-of-distribution-detection-with-latent-diffusion-models"><a href="#Unsupervised-3D-out-of-distribution-detection-with-latent-diffusion-models" class="headerlink" title="Unsupervised 3D out-of-distribution detection with latent diffusion models"></a>Unsupervised 3D out-of-distribution detection with latent diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03777">http://arxiv.org/abs/2307.03777</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marksgraham/ddpm-ood">https://github.com/marksgraham/ddpm-ood</a></li>
<li>paper_authors: Mark S. Graham, Walter Hugo Lopez Pinaya, Paul Wright, Petru-Daniel Tudosiu, Yee H. Mah, James T. Teo, H. Rolf Jäger, David Werring, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardoso</li>
<li>For: The paper is written for detecting out-of-distribution (OOD) data in 3D medical data using Latent Diffusion Models (LDMs).* Methods: The paper proposes using LDMs to scale denoising diffusion probabilistic models (DDPMs) to high-resolution 3D medical data, and compares the proposed approach to a recently proposed, 3D-enabled approach using Latent Transformer Models (LTMs).* Results: The proposed LDM-based approach achieves statistically significant better performance than the LTM-based approach, with less sensitivity to the underlying latent representation, more favourable memory scaling, and produces better spatial anomaly maps.Here’s the simplified Chinese text for the three key points:* 为：该文章是用Latent Diffusion Models（LDMs）检测三维医疗数据中的外围数据（Out-of-distribution，OOD）。* 方法：文章提出使用LDMs将denoising diffusion probabilistic models（DDPMs）扩展到高分辨率三维医疗数据，并与近期提出的使用Latent Transformer Models（LTMs）的3D可用方法进行比较。* 结果：提出的LDM-based方法与LTM-based方法进行比较，显示LDM-based方法具有更好的性能，具有更好的准确率、更好的嵌入特征、更好的空间异常映射。<details>
<summary>Abstract</summary>
Methods for out-of-distribution (OOD) detection that scale to 3D data are crucial components of any real-world clinical deep learning system. Classic denoising diffusion probabilistic models (DDPMs) have been recently proposed as a robust way to perform reconstruction-based OOD detection on 2D datasets, but do not trivially scale to 3D data. In this work, we propose to use Latent Diffusion Models (LDMs), which enable the scaling of DDPMs to high-resolution 3D medical data. We validate the proposed approach on near- and far-OOD datasets and compare it to a recently proposed, 3D-enabled approach using Latent Transformer Models (LTMs). Not only does the proposed LDM-based approach achieve statistically significant better performance, it also shows less sensitivity to the underlying latent representation, more favourable memory scaling, and produces better spatial anomaly maps. Code is available at https://github.com/marksgraham/ddpm-ood
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>在真实世界临床深度学习系统中，对于不同数据集的异常检测方法是非常重要的组件。经典的杂噪扩散概率模型（DDPM）在2D数据集上进行重建基于异常检测已被提议，但是这些模型不直接适用于3D数据集。在这个工作中，我们提议使用幽默扩散模型（LDM），以便将DDPM扩展到高分辨率3D医学数据集。我们验证提议的方法在靠近和远离异常数据集上，并与最近提议的3D启用的Latent Transformer Models（LTM）进行比较。我们发现提议的LDM基本逻辑达到了统计学上显著更好的性能，同时也具有更好的内存扩展和更好的空间异常地图。代码可以在https://github.com/marksgraham/ddpm-ood中找到。
</details></li>
</ul>
<hr>
<h2 id="AutoDecoding-Latent-3D-Diffusion-Models"><a href="#AutoDecoding-Latent-3D-Diffusion-Models" class="headerlink" title="AutoDecoding Latent 3D Diffusion Models"></a>AutoDecoding Latent 3D Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05445">http://arxiv.org/abs/2307.05445</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snap-research/3dvader">https://github.com/snap-research/3dvader</a></li>
<li>paper_authors: Evangelos Ntavelis, Aliaksandr Siarohin, Kyle Olszewski, Chaoyang Wang, Luc Van Gool, Sergey Tulyakov</li>
<li>for: 生成静态和动态3D资产的新方法，包括3D自动解码器框架，用于捕捉视图一致的外观和几何结构。</li>
<li>methods: 使用目标数据集中学习的属性嵌入在缺省空间中，然后将其解码成可视化的涂抹表示形式，并使用robust抽象和正则化操作来学习3D协振。</li>
<li>results: 比state-of-the-art方法高效，在多视图图像数据集、实际野外视频和大规模真实视频数据集上获得优秀的生成结果。<details>
<summary>Abstract</summary>
We present a novel approach to the generation of static and articulated 3D assets that has a 3D autodecoder at its core. The 3D autodecoder framework embeds properties learned from the target dataset in the latent space, which can then be decoded into a volumetric representation for rendering view-consistent appearance and geometry. We then identify the appropriate intermediate volumetric latent space, and introduce robust normalization and de-normalization operations to learn a 3D diffusion from 2D images or monocular videos of rigid or articulated objects. Our approach is flexible enough to use either existing camera supervision or no camera information at all -- instead efficiently learning it during training. Our evaluations demonstrate that our generation results outperform state-of-the-art alternatives on various benchmark datasets and metrics, including multi-view image datasets of synthetic objects, real in-the-wild videos of moving people, and a large-scale, real video dataset of static objects.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法来生成静止和受拘式3D资产，其核心是3D自动解码器框架。该框架嵌入目标数据集中学习的属性在缺失空间中嵌入，然后可以用于渲染视角一致的外观和几何结构。我们然后确定了适当的中间缺失空间，并引入了稳定的 нормализа和解决操作来学习3D扩散从2D图像或半球形物体的照片或视频中。我们的方法可以使用现有的摄像头监督或没有摄像头信息，而不是在训练中高效地学习。我们的评估表明，我们的生成结果超过了当前的参考方法在多视图图像集、实际野外视频中的人体动作和大规模、实际视频集中的多种数据集和指标上。
</details></li>
</ul>
<hr>
<h2 id="Training-Ensembles-with-Inliers-and-Outliers-for-Semi-supervised-Active-Learning"><a href="#Training-Ensembles-with-Inliers-and-Outliers-for-Semi-supervised-Active-Learning" class="headerlink" title="Training Ensembles with Inliers and Outliers for Semi-supervised Active Learning"></a>Training Ensembles with Inliers and Outliers for Semi-supervised Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03741">http://arxiv.org/abs/2307.03741</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vladan-stojnic/active-outliers">https://github.com/vladan-stojnic/active-outliers</a></li>
<li>paper_authors: Vladan Stojnić, Zakaria Laskar, Giorgos Tolias</li>
<li>for: 本文采用深度学习和活动学习方法，解决在异常示例存在下的激活学习问题。</li>
<li>methods: 本文提出了三个高度协同的组件，包括： joint 分类器训练（含异常示例和正常示例）、 semi-supervised learning 通过 pseudo-labeling、模型ensemble。</li>
<li>results: 本文的实验结果表明，将这三个组件结合使用可以提高 pseudo-labeling 的准确率和数据收集质量。特别是，joint 训练可以正确处理异常示例，无需进行Explicit outlier detection。此外，我们的方法的简单性和易用性，使其在性能上超越其他方法。<details>
<summary>Abstract</summary>
Deep active learning in the presence of outlier examples poses a realistic yet challenging scenario. Acquiring unlabeled data for annotation requires a delicate balance between avoiding outliers to conserve the annotation budget and prioritizing useful inlier examples for effective training. In this work, we present an approach that leverages three highly synergistic components, which are identified as key ingredients: joint classifier training with inliers and outliers, semi-supervised learning through pseudo-labeling, and model ensembling. Our work demonstrates that ensembling significantly enhances the accuracy of pseudo-labeling and improves the quality of data acquisition. By enabling semi-supervision through the joint training process, where outliers are properly handled, we observe a substantial boost in classifier accuracy through the use of all available unlabeled examples. Notably, we reveal that the integration of joint training renders explicit outlier detection unnecessary; a conventional component for acquisition in prior work. The three key components align seamlessly with numerous existing approaches. Through empirical evaluations, we showcase that their combined use leads to a performance increase. Remarkably, despite its simplicity, our proposed approach outperforms all other methods in terms of performance. Code: https://github.com/vladan-stojnic/active-outliers
</details>
<details>
<summary>摘要</summary>
深入的活动学习在异常示例存在下 pose 一个现实 yet 挑战的场景。 获取未标注数据 для注释需要一个细腻的平衡，以避免异常示例，并且优先级划分有用的准确示例，以便有效地训练。 在这种情况下，我们提出了一种方法，该方法利用三个高度协同的组件，即： joint 类ifier 训练与准确示例和异常示例， semi-supervised 学习通过pseudo-labeling，以及模型集成。 我们的工作表明，将这三个组件相互融合可以显著提高 pseudo-labeling 的准确度和数据收集质量。通过允许 semi-supervision 过程中的异常示例处理，我们发现了一个非常大的提升准确率，并且可以使用所有可用的无标注示例。另外，我们发现在 joint 训练过程中，无需进行明确的异常检测，可以直接使用所有示例进行训练。这三个关键组件与许多现有方法兼容。通过实验评估，我们表明这些组件的结合使用可以带来性能提升。尤其是，我们的提议方法的简单性和高效性，在性能方面胜过所有其他方法。代码：https://github.com/vladan-stojnic/active-outliersNote: Please note that the translation is in Simplified Chinese, and the word order and grammar may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Equivariant-Single-View-Pose-Prediction-Via-Induced-and-Restricted-Representations"><a href="#Equivariant-Single-View-Pose-Prediction-Via-Induced-and-Restricted-Representations" class="headerlink" title="Equivariant Single View Pose Prediction Via Induced and Restricted Representations"></a>Equivariant Single View Pose Prediction Via Induced and Restricted Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03704">http://arxiv.org/abs/2307.03704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Owen Howell, David Klee, Ondrej Biza, Linfeng Zhao, Robin Walters</li>
<li>for: 本研究旨在解决计算机视觉中的基本问题，即从二dimensional图像中学习三dimensional世界。</li>
<li>methods: 我们使用SO(3)对准的约束来限制二dimensional输入的可能性，并使用SO(2)对准的约束来保证图像的准确性。</li>
<li>results: 我们提出了一种新的算法，可以learn三dimensional世界的表示从二dimensional图像中，并在PASCAL3D+和SYMSOL两个 pose estimation 任务上达到了最高精度。<details>
<summary>Abstract</summary>
Learning about the three-dimensional world from two-dimensional images is a fundamental problem in computer vision. An ideal neural network architecture for such tasks would leverage the fact that objects can be rotated and translated in three dimensions to make predictions about novel images. However, imposing SO(3)-equivariance on two-dimensional inputs is difficult because the group of three-dimensional rotations does not have a natural action on the two-dimensional plane. Specifically, it is possible that an element of SO(3) will rotate an image out of plane. We show that an algorithm that learns a three-dimensional representation of the world from two dimensional images must satisfy certain geometric consistency properties which we formulate as SO(2)-equivariance constraints. We use the induced and restricted representations of SO(2) on SO(3) to construct and classify architectures which satisfy these geometric consistency constraints. We prove that any architecture which respects said consistency constraints can be realized as an instance of our construction. We show that three previously proposed neural architectures for 3D pose prediction are special cases of our construction. We propose a new algorithm that is a learnable generalization of previously considered methods. We test our architecture on three pose predictions task and achieve SOTA results on both the PASCAL3D+ and SYMSOL pose estimation tasks.
</details>
<details>
<summary>摘要</summary>
学习三维世界从二维图像是计算机视觉的基本问题。理想的神经网络架构 для此类任务应该利用对象可以在三维空间中旋转和平移来做预测。但是，在将 SO(3) 对二维平面的动作直观不是自然的，这使得在二维输入上强制 SO(3) 对称性是困难的。我们显示，一个可以学习三维世界的二维图像表示需要满足某些几何一致性性质，我们称之为 SO(2) 对称性约束。我们使用 SO(2) 在 SO(3) 上的引出和受限表示来构建和分类满足这些几何一致性约束的架构。我们证明，任何满足这些约束的架构都可以通过我们的构建实现。我们显示，三种之前提出的神经网络架构 для 3D 姿态预测是特例我们的构建。我们提出一种新的算法，它是learnable的一般化前述方法。我们测试我们的架构在三种姿态预测任务上，并在 PASCAL3D+ 和 SYMSOL 姿态预测任务上达到了最高的 SOTA 结果。
</details></li>
</ul>
<hr>
<h2 id="Motion-Magnification-in-Robotic-Sonography-Enabling-Pulsation-Aware-Artery-Segmentation"><a href="#Motion-Magnification-in-Robotic-Sonography-Enabling-Pulsation-Aware-Artery-Segmentation" class="headerlink" title="Motion Magnification in Robotic Sonography: Enabling Pulsation-Aware Artery Segmentation"></a>Motion Magnification in Robotic Sonography: Enabling Pulsation-Aware Artery Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03698">http://arxiv.org/abs/2307.03698</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dianyehuang/robpmepasnn">https://github.com/dianyehuang/robpmepasnn</a></li>
<li>paper_authors: Dianye Huang, Yuan Bi, Nassir Navab, Zhongliang Jiang</li>
<li>for: 该研究旨在提高血液动力图像 segmentation 精度和稳定性，通过利用心脏血流带动的信息来帮助临床医生诊断和监测动脉疾病。</li>
<li>methods: 该研究使用了一种新的振荡帮助分割神经网络（PAS-NN），利用心脏血流带动的信息来帮助定位动脉，并使用了运动增强技术来增强心脏血流的信号。</li>
<li>results: 实验结果表明，PAS-NN 可以与现有技术相当，并且可以有效地提高小动脉（血管）的 segmentation 性能。<details>
<summary>Abstract</summary>
Ultrasound (US) imaging is widely used for diagnosing and monitoring arterial diseases, mainly due to the advantages of being non-invasive, radiation-free, and real-time. In order to provide additional information to assist clinicians in diagnosis, the tubular structures are often segmented from US images. To improve the artery segmentation accuracy and stability during scans, this work presents a novel pulsation-assisted segmentation neural network (PAS-NN) by explicitly taking advantage of the cardiac-induced motions. Motion magnification techniques are employed to amplify the subtle motion within the frequency band of interest to extract the pulsation signals from sequential US images. The extracted real-time pulsation information can help to locate the arteries on cross-section US images; therefore, we explicitly integrated the pulsation into the proposed PAS-NN as attention guidance. Notably, a robotic arm is necessary to provide stable movement during US imaging since magnifying the target motions from the US images captured along a scan path is not manually feasible due to the hand tremor. To validate the proposed robotic US system for imaging arteries, experiments are carried out on volunteers' carotid and radial arteries. The results demonstrated that the PAS-NN could achieve comparable results as state-of-the-art on carotid and can effectively improve the segmentation performance for small vessels (radial artery).
</details>
<details>
<summary>摘要</summary>
ultrasound（US）成像广泛用于诊断和监测arterial疾病，主要因为非侵入性、无辐射和实时等优点。为了为临床医生提供更多的诊断信息，在US图像中分割 tubular结构成为一项重要的任务。为了提高artery分割精度和稳定性，本研究提出了一种基于征动辐射信号的新型pulsation-assisted segmentation neural network（PAS-NN）。在图像序列中提取 cardiac-induced motions 的柔化信号，并将其作为注意力引导进行explicitly integrating。由于需要稳定的运动来提供US成像，因此在US成像过程中使用了Robotic arm。为验证提出的Robotic US系统在诊断arteries中的可行性，对志愿者的 Common carotid和Radial artery进行了实验。结果表明，PAS-NN可以与当前状态艺术一样好，并且可以有效地提高小动脉（Radial artery）的分割性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/08/cs.CV_2023_07_08/" data-id="clpahu72100g03h88ffdsgz2u" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/08/cs.AI_2023_07_08/" class="article-date">
  <time datetime="2023-07-08T12:00:00.000Z" itemprop="datePublished">2023-07-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/08/cs.AI_2023_07_08/">cs.AI - 2023-07-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="PCG-based-Static-Underground-Garage-Scenario-Generation"><a href="#PCG-based-Static-Underground-Garage-Scenario-Generation" class="headerlink" title="PCG-based Static Underground Garage Scenario Generation"></a>PCG-based Static Underground Garage Scenario Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03988">http://arxiv.org/abs/2307.03988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjin Li, Kai Li</li>
<li>for: 本研究旨在用Sarsa算法解决地下停车场 static scenario simulation 的PCG问题。</li>
<li>methods: 本paper使用Sarsa算法进行PCG，以生成具有充足细节的地下停车场场景。</li>
<li>results: 本研究实现了基于Sarsa算法的PCG方法，可以生成高质量的地下停车场场景，为自动驾驶技术的训练提供了更多的数据支持。<details>
<summary>Abstract</summary>
Autonomous driving technology has five levels, from L0 to L5. Currently, only the L2 level (partial automation) can be achieved, and there is a long way to go before reaching the final level of L5 (full automation). The key to crossing these levels lies in training the autonomous driving model. However, relying solely on real-world road data to train the model is far from enough and consumes a great deal of resources. Although there are already examples of training autonomous driving models through simulators that simulate real-world scenarios, these scenarios require complete manual construction. Directly converting 3D scenes from road network formats will lack a large amount of detail and cannot be used as training sets. Underground parking garage static scenario simulation is regarded as a procedural content generation (PCG) problem. This paper will use the Sarsa algorithm to solve procedural content generation on underground garage structures.
</details>
<details>
<summary>摘要</summary>
自动驾驶技术有五级，从L0到L5。目前只有L2级（部分自动化）可以实现，剩下的级别还有很长的路要走。模型训练是十分重要的关键。然而，仅仅通过使用现实世界道路数据来训练模型是费尽资源的，而且需要大量的数据。虽然已经有些使用模拟器 simulate real-world scenarios的例子，但这些场景需要完全手动构建。直接将3D场景从道路网络格式转换来用作训练集是缺乏详细信息的，无法用于训练。地下停车场 static scenario simulation被视为一个过程Content generation（PCG）问题。本文使用Sarsa算法解决地下停车场的PCG问题。
</details></li>
</ul>
<hr>
<h2 id="Integrating-Curricula-with-Replays-Its-Effects-on-Continual-Learning"><a href="#Integrating-Curricula-with-Replays-Its-Effects-on-Continual-Learning" class="headerlink" title="Integrating Curricula with Replays: Its Effects on Continual Learning"></a>Integrating Curricula with Replays: Its Effects on Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05747">http://arxiv.org/abs/2307.05747</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhanglab-deepneurocoglab/integrating-curricula-with-replays">https://github.com/zhanglab-deepneurocoglab/integrating-curricula-with-replays</a></li>
<li>paper_authors: Ren Jie Tee, Mengmi Zhang</li>
<li>for: 这种研究旨在探讨在进行连续学习时，通过融合课程和重温方法，以便提高知识保持和学习传递。</li>
<li>methods: 研究使用了不同的课程设计，包括交叠频率、顺序和选择策略，以影响重温过程中的连续学习。</li>
<li>results: 研究发现，通过融合课程和重温方法，可以有效地避免忘却现象，并提高知识传递。这些结果表明，融合课程可以成为连续学习方法的进一步发展。<details>
<summary>Abstract</summary>
Humans engage in learning and reviewing processes with curricula when acquiring new skills or knowledge. This human learning behavior has inspired the integration of curricula with replay methods in continual learning agents. The goal is to emulate the human learning process, thereby improving knowledge retention and facilitating learning transfer. Existing replay methods in continual learning agents involve the random selection and ordering of data from previous tasks, which has shown to be effective. However, limited research has explored the integration of different curricula with replay methods to enhance continual learning. Our study takes initial steps in examining the impact of integrating curricula with replay methods on continual learning in three specific aspects: the interleaved frequency of replayed exemplars with training data, the sequence in which exemplars are replayed, and the strategy for selecting exemplars into the replay buffer. These aspects of curricula design align with cognitive psychology principles and leverage the benefits of interleaved practice during replays, easy-to-hard rehearsal, and exemplar selection strategy involving exemplars from a uniform distribution of difficulties. Based on our results, these three curricula effectively mitigated catastrophic forgetting and enhanced positive knowledge transfer, demonstrating the potential of curricula in advancing continual learning methodologies. Our code and data are available: https://github.com/ZhangLab-DeepNeuroCogLab/Integrating-Curricula-with-Replays
</details>
<details>
<summary>摘要</summary>
人类在学习和复习过程中使用课程，当学习新技能或知识时。这种人类学习行为激发了在不断学习代理人中结合课程和复习方法的整合。目标是模拟人类学习过程，从而提高知识保持和学习转移。现有的复习方法在不断学习代理人中Randomly selecting and ordering data from previous tasks has been shown to be effective. However, limited research has explored the integration of different curricula with replay methods to enhance continual learning. Our study takes initial steps in examining the impact of integrating curricula with replay methods on continual learning in three specific aspects: the interleaved frequency of replayed exemplars with training data, the sequence in which exemplars are replayed, and the strategy for selecting exemplars into the replay buffer. These aspects of curricula design align with cognitive psychology principles and leverage the benefits of interleaved practice during replays, easy-to-hard rehearsal, and exemplar selection strategy involving exemplars from a uniform distribution of difficulties. According to our results, these three curricula effectively mitigated catastrophic forgetting and enhanced positive knowledge transfer, demonstrating the potential of curricula in advancing continual learning methodologies.我们的代码和数据可以在 GitHub上获取：https://github.com/ZhangLab-DeepNeuroCogLab/Integrating-Curricula-with-Replays
</details></li>
</ul>
<hr>
<h2 id="Autonomy-2-0-The-Quest-for-Economies-of-Scale"><a href="#Autonomy-2-0-The-Quest-for-Economies-of-Scale" class="headerlink" title="Autonomy 2.0: The Quest for Economies of Scale"></a>Autonomy 2.0: The Quest for Economies of Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03973">http://arxiv.org/abs/2307.03973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Wu, Bo Yu, Shaoshan Liu, Yuhao Zhu</li>
<li>for: 本文主要适用于 autonomous machines 领域的技术挑战和经济影响。</li>
<li>methods: 本文使用技术分析和经济分析方法来探讨 autonomous machines 领域的可描述性和经济可能性。</li>
<li>results: 本文 argue that scalability 是 autonomous machines 领域的关键因素，但现有的发展模式（Autonomy 1.0）不能充分利用计算成本和数据资源的经济效益。 在解决关键瓶颈的同时，新的发展模式（Autonomy 2.0）可以大幅提高 autonomous machines 领域的可描述性和经济可能性。<details>
<summary>Abstract</summary>
With the advancement of robotics and AI technologies in the past decade, we have now entered the age of autonomous machines. In this new age of information technology, autonomous machines, such as service robots, autonomous drones, delivery robots, and autonomous vehicles, rather than humans, will provide services. In this article, through examining the technical challenges and economic impact of the digital economy, we argue that scalability is both highly necessary from a technical perspective and significantly advantageous from an economic perspective, thus is the key for the autonomy industry to achieve its full potential. Nonetheless, the current development paradigm, dubbed Autonomy 1.0, scales with the number of engineers, instead of with the amount of data or compute resources, hence preventing the autonomy industry to fully benefit from the economies of scale, especially the exponentially cheapening compute cost and the explosion of available data. We further analyze the key scalability blockers and explain how a new development paradigm, dubbed Autonomy 2.0, can address these problems to greatly boost the autonomy industry.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:随着过去十年的机器人和人工智能技术的发展，我们已经进入了自动化机器的时代。在这个新的信息技术时代，自动化机器，如服务机器人、自动飞行器、配送机器人和自动驾驶车辆，而不是人类，将提供服务。在这篇文章中，我们通过分析技术挑战和数字经济的影响， argue that可扩展性是技术上必需的和经济上有利的，因此是自动化industry的潜在力量。然而，当前的开发模式，称为Autonomy 1.0，与工程师数量成比例增长，而不是与数据量或计算资源成比例增长，因此阻碍了自动化industry从全面获得经济效益，特别是快速减少的计算成本和可用数据的爆发。我们进一步分析阻碍可扩展性的关键问题，并解释如何一种新的开发模式，称为Autonomy 2.0，可以解决这些问题，以大幅提高自动化industry。
</details></li>
</ul>
<hr>
<h2 id="Multi-Intent-Detection-in-User-Provided-Annotations-for-Programming-by-Examples-Systems"><a href="#Multi-Intent-Detection-in-User-Provided-Annotations-for-Programming-by-Examples-Systems" class="headerlink" title="Multi-Intent Detection in User Provided Annotations for Programming by Examples Systems"></a>Multi-Intent Detection in User Provided Annotations for Programming by Examples Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03966">http://arxiv.org/abs/2307.03966</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nischal Ashok Kumar, Nitin Gupta, Shanmukha Guttula, Hima Patel</li>
<li>for: 这个论文的目的是解决在集成开发中数据映射的问题，尤其是在应用程序缺乏命名标准和嵌套字段结构的情况下。</li>
<li>methods: 这个论文使用了编程例子（PBE）技术来自动生成数据转换程序，从用户提供的输入和输出样本中学习计算机程序的正确意图。</li>
<li>results: 该论文提出了一种深度神经网络基于不确定性预测模型，可以分析输入输出字符串并将其映射到不同的属性集，以解决PBE系统中的多意问题。<details>
<summary>Abstract</summary>
In mapping enterprise applications, data mapping remains a fundamental part of integration development, but its time consuming. An increasing number of applications lack naming standards, and nested field structures further add complexity for the integration developers. Once the mapping is done, data transformation is the next challenge for the users since each application expects data to be in a certain format. Also, while building integration flow, developers need to understand the format of the source and target data field and come up with transformation program that can change data from source to target format. The problem of automatic generation of a transformation program through program synthesis paradigm from some specifications has been studied since the early days of Artificial Intelligence (AI). Programming by Example (PBE) is one such kind of technique that targets automatic inferencing of a computer program to accomplish a format or string conversion task from user-provided input and output samples. To learn the correct intent, a diverse set of samples from the user is required. However, there is a possibility that the user fails to provide a diverse set of samples. This can lead to multiple intents or ambiguity in the input and output samples. Hence, PBE systems can get confused in generating the correct intent program. In this paper, we propose a deep neural network based ambiguity prediction model, which analyzes the input-output strings and maps them to a different set of properties responsible for multiple intent. Users can analyze these properties and accordingly can provide new samples or modify existing samples which can help in building a better PBE system for mapping enterprise applications.
</details>
<details>
<summary>摘要</summary>
Mapping企业应用程序中，数据映射仍然是集成开发的基本部分，但是它占用了很多时间。越来越多的应用程序缺少命名标准，嵌套的字段结构进一步增加了集成开发人员的复杂性。一旦映射完成，则下一个挑战是数据转换，因为每个应用程序都会预期数据在某种格式下来。在建立集成流时，开发人员需要理解源数据和目标数据字段的格式，并编写转换程序以将数据从源格式转换到目标格式。自AI时代以来，人工智能编程方法已经被研究了很长时间。在这个过程中，一种技术是编程示例（PBE），它可以自动生成计算机程序，以实现格式或字符串转换任务。为了学习正确的意图，用户需要提供多样的示例。然而，用户可能无法提供多样的示例，这会导致多个意图或输入/输出样本的歧义。因此，PBE系统可能会在生成正确意图程序时感到困惑。在本文中，我们提出了一种基于深度神经网络的歧义预测模型，该模型可以分析输入/输出字符串，并将其映射到不同的属性集，这些属性集负责多个意图。用户可以分析这些属性，并根据这些属性提供新的示例或修改现有示例，以帮助建立更好的PBE系统。
</details></li>
</ul>
<hr>
<h2 id="Right-to-be-Forgotten-in-the-Era-of-Large-Language-Models-Implications-Challenges-and-Solutions"><a href="#Right-to-be-Forgotten-in-the-Era-of-Large-Language-Models-Implications-Challenges-and-Solutions" class="headerlink" title="Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions"></a>Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03941">http://arxiv.org/abs/2307.03941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dawen Zhang, Pamela Finckenberg-Broman, Thong Hoang, Shidong Pan, Zhenchang Xing, Mark Staples, Xiwei Xu</li>
<li>For: This paper explores the challenges of implementing the Right to Be Forgotten (RTBF) in Large Language Models (LLMs) and provides insights on how to implement technical solutions for RTBF.* Methods: The paper discusses the use of machine unlearning, model editing, and prompting engineering as potential solutions for RTBF in LLMs.* Results: The paper provides insights on the challenges of implementing RTBF in LLMs and suggests potential solutions for compliance with the RTBF.Here’s the text in Simplified Chinese:* For: 这篇论文研究了大语言模型（LLM）中实现“忘记权”（RTBF）的挑战，并提供了实现RTBF的技术解决方案。* Methods: 论文讨论了机器“忘记”、模型修改和引导工程等可能的解决方案。* Results: 论文提供了LLM中实现RTBF的挑战和可能的解决方案。<details>
<summary>Abstract</summary>
The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of machine unlearning, model editing, and prompting engineering.
</details>
<details>
<summary>摘要</summary>
“右投忘”（RTBF）首次得到了Google西班牙SL、Google公司诉AEPD、马里奥·科斯泰加·冈萨雷斯案例的判决， later被包含在欧盟数据保护条例（GDPR）中，以allow个人请求组织删除个人数据。特别是 для搜索引擎，个人可以向组织发送请求，请求排除他们的信息从查询结果中。随着大自然语言模型（LLMs）的发展和它们在 чат机器人中的使用，LLM-enabled software systems 已成为流行的。但它们并不是RTBF的例外。与搜索引擎使用的索引方法不同，LLMs存储和处理信息的方式带来了新的RTBF的挑战。在这篇论文中，我们探讨这些挑战，并提供了实现RTBF的技术解决方案，包括机器学习、模型编辑和提示工程。
</details></li>
</ul>
<hr>
<h2 id="Copilot-for-Xcode-Exploring-AI-Assisted-Programming-by-Prompting-Cloud-based-Large-Language-Models"><a href="#Copilot-for-Xcode-Exploring-AI-Assisted-Programming-by-Prompting-Cloud-based-Large-Language-Models" class="headerlink" title="Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based Large Language Models"></a>Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14349">http://arxiv.org/abs/2307.14349</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chee Wei Tan, Shangxin Guo, Man Fai Wong, Ching Nam Hang</li>
<li>for: 支持人类软件开发者的AI助手工具，帮助开发者更快速、更高效地完成软件开发任务。</li>
<li>methods: 利用云端大语言模型（LLM）和Apple的本地开发环境Xcode进行集成，通过高级自然语言处理（NLP）技术来处理代码符号和代码模式，实现代码生成、自动完成、文档生成和错误探测等功能。</li>
<li>results: 通过在Xcode中 integrate LLM，可以提高开发效率和释放创造力，并且可以同时进行一些小型决策，通过提示工程来帮助开发者更快速地完成软件开发任务。<details>
<summary>Abstract</summary>
This paper presents an AI-assisted programming tool called Copilot for Xcode for program composition and design to support human software developers. By seamlessly integrating cloud-based Large Language Models (LLM) with Apple's local development environment, Xcode, this tool enhances productivity and unleashes creativity for software development in Apple software ecosystem (e.g., iOS apps, macOS). Leveraging advanced natural language processing (NLP) techniques, Copilot for Xcode effectively processes source code tokens and patterns within code repositories, enabling features such as code generation, autocompletion, documentation, and error detection. Software developers can also query and make "small" decisions for program composition, some of which can be made simultaneously, and this is facilitated through prompt engineering in a chat interface of Copilot for Xcode. Finally, we present simple case studies as evidence of the effectiveness of utilizing NLP in Xcode to prompt popular LLM services like OpenAI ChatGPT for program composition and design.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了一个基于人工智能的编程工具called Copilot，用于增强 Xcode 中的软件开发产业。该工具通过将云端大语言模型（LLM）与 Apple 的本地开发环境 XCode 集成，以提高开发效率和释放创造力。通过进行源代码Token和模式的高级自然语言处理（NLP）处理，Copilot for Xcode 可以实现代码生成、自动完成、文档生成和错误检测等功能。开发者可以通过提示工程来进行小决策，并通过交互式弹出框架来同时进行多个决策。最后，我们提供了一些简单的案例研究，以证明使用 NLP 在 Xcode 中提示流行的 LLM 服务如 OpenAI ChatGPT 可以增强软件开发和设计。
</details></li>
</ul>
<hr>
<h2 id="Inductive-Meta-path-Learning-for-Schema-complex-Heterogeneous-Information-Networks"><a href="#Inductive-Meta-path-Learning-for-Schema-complex-Heterogeneous-Information-Networks" class="headerlink" title="Inductive Meta-path Learning for Schema-complex Heterogeneous Information Networks"></a>Inductive Meta-path Learning for Schema-complex Heterogeneous Information Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03937">http://arxiv.org/abs/2307.03937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shixuan Liu, Changjun Fan, Kewei Cheng, Yunfei Wang, Peng Cui, Yizhou Sun, Zhong Liu</li>
<li>for: 这篇论文主要是为了解决复杂 schema 上的 Heterogeneous Information Networks (HINs) 中的 meta-path 问题。</li>
<li>methods: 该论文提出了一种 inducing meta-path learning 框架，使用 schema-level 表示来支持不同关系的 meta-path 学习，并采用了一种基于奖励学习的路径找索引机制来学习Establishing meta-paths with high coverage and confidence for multiple relations。</li>
<li>results: 实验结果表明，该提出的方法可以有效地解决复杂 schema 上的 HINs 中 meta-path 问题，并且可以提高 meta-path 的覆盖率和信任度。<details>
<summary>Abstract</summary>
Heterogeneous Information Networks (HINs) are information networks with multiple types of nodes and edges. The concept of meta-path, i.e., a sequence of entity types and relation types connecting two entities, is proposed to provide the meta-level explainable semantics for various HIN tasks. Traditionally, meta-paths are primarily used for schema-simple HINs, e.g., bibliographic networks with only a few entity types, where meta-paths are often enumerated with domain knowledge. However, the adoption of meta-paths for schema-complex HINs, such as knowledge bases (KBs) with hundreds of entity and relation types, has been limited due to the computational complexity associated with meta-path enumeration. Additionally, effectively assessing meta-paths requires enumerating relevant path instances, which adds further complexity to the meta-path learning process. To address these challenges, we propose SchemaWalk, an inductive meta-path learning framework for schema-complex HINs. We represent meta-paths with schema-level representations to support the learning of the scores of meta-paths for varying relations, mitigating the need of exhaustive path instance enumeration for each relation. Further, we design a reinforcement-learning based path-finding agent, which directly navigates the network schema (i.e., schema graph) to learn policies for establishing meta-paths with high coverage and confidence for multiple relations. Extensive experiments on real data sets demonstrate the effectiveness of our proposed paradigm.
</details>
<details>
<summary>摘要</summary>
非同质信息网络（HIN）是一种具有多种节点和边的信息网络。meta-path这个概念，即连接两个实体的一系列实体类型和关系类型的序列，是为了提供HIN任务的元素级别解释 semantics。然而，在Schema-Complex HINs中，例如知识库（KB）中的百种实体和关系类型，meta-path的采用受到了计算复杂性的限制。此外，评估meta-path需要列出相关的路径实例，这加重了meta-path学习过程中的复杂性。为解决这些挑战，我们提出了SchemaWalk，一种induktive meta-path学习框架 дляSchema-Complex HINs。我们使用schema层次表示meta-paths，以支持不同关系的score学习，从而消除了每个关系的枚举路径实例的需要。此外，我们设计了一种基于奖励学习的路径找索引器，可以直接在网络schema图（即schema图）上学习Establish meta-paths with high coverage and confidence for multiple relations。实验表明了我们提出的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Towards-Efficient-In-memory-Computing-Hardware-for-Quantized-Neural-Networks-State-of-the-art-Open-Challenges-and-Perspectives"><a href="#Towards-Efficient-In-memory-Computing-Hardware-for-Quantized-Neural-Networks-State-of-the-art-Open-Challenges-and-Perspectives" class="headerlink" title="Towards Efficient In-memory Computing Hardware for Quantized Neural Networks: State-of-the-art, Open Challenges and Perspectives"></a>Towards Efficient In-memory Computing Hardware for Quantized Neural Networks: State-of-the-art, Open Challenges and Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03936">http://arxiv.org/abs/2307.03936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olga Krestinskaya, Li Zhang, Khaled Nabil Salama</li>
<li>for: 本研究旨在探讨在 Edge Computing 环境中实现吞吐量压缩神经网络，尤其是针对具有限制的能源和计算资源的边缘设备。</li>
<li>methods: 本研究使用 In-memory Computing (IMC) 技术和量化神经网络 (QNN) 来实现Edge Computing中的神经网络处理。</li>
<li>results: 本研究提供了一个完整的 QNN 和 IMC 硬件实现的评估，以及开放的挑战、设计要求、建议和前瞻，并提供了一个 IMCC 硬件路线图。<details>
<summary>Abstract</summary>
The amount of data processed in the cloud, the development of Internet-of-Things (IoT) applications, and growing data privacy concerns force the transition from cloud-based to edge-based processing. Limited energy and computational resources on edge push the transition from traditional von Neumann architectures to In-memory Computing (IMC), especially for machine learning and neural network applications. Network compression techniques are applied to implement a neural network on limited hardware resources. Quantization is one of the most efficient network compression techniques allowing to reduce the memory footprint, latency, and energy consumption. This paper provides a comprehensive review of IMC-based Quantized Neural Networks (QNN) and links software-based quantization approaches to IMC hardware implementation. Moreover, open challenges, QNN design requirements, recommendations, and perspectives along with an IMC-based QNN hardware roadmap are provided.
</details>
<details>
<summary>摘要</summary>
云计算中数据处理量、互联网物联网（IoT）应用的发展以及数据隐私问题的增加，导致从云基础到边缘基础的处理过渡。边缘设备的有限能源和计算资源使得从传统 von Neumann 架构过渡到内存计算（IMC），特别是 для机器学习和神经网络应用。为实现限制性硬件资源上的神经网络实现，网络压缩技术被应用。量化是最高效的网络压缩技术，可以减少内存占用量、延迟和能耗。本文提供了全面的内存计算基于量化神经网络（QNN）审查，并将软件基于量化方法与IMC硬件实现相连。此外，还提供了开放的挑战、QNN设计要求、建议和前瞻，以及IMC基于QNN硬件路线图。
</details></li>
</ul>
<hr>
<h2 id="Bounding-data-reconstruction-attacks-with-the-hypothesis-testing-interpretation-of-differential-privacy"><a href="#Bounding-data-reconstruction-attacks-with-the-hypothesis-testing-interpretation-of-differential-privacy" class="headerlink" title="Bounding data reconstruction attacks with the hypothesis testing interpretation of differential privacy"></a>Bounding data reconstruction attacks with the hypothesis testing interpretation of differential privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03928">http://arxiv.org/abs/2307.03928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgios Kaissis, Jamie Hayes, Alexander Ziller, Daniel Rueckert</li>
<li>for: 本研究探讨了数据重建攻击对机器学习模型的成功率上的Upper bound，即数据重建Robustness（ReRo）。</li>
<li>methods: 本研究使用了渐近 Monte Carlo 估计来计算 ReRo 的紧致 bound，但这些估计只适用于特定的渐近DP机制。本文则提出了基于假设测试DP和ReRo的连接，并 deriveclosed-form、分析的或数字 ReRo 下限 для别 Laplace 和 Gaussian 机制以及它们的抽样variant。</li>
<li>results: 本研究提出了可直接计算的 ReRo 下限 для普通的DP机制，包括Laplace和Gaussian机制以及它们的抽样variant。这些下限可用于评估数据重建攻击的成功率，并帮助选择合适的DP机制。<details>
<summary>Abstract</summary>
We explore Reconstruction Robustness (ReRo), which was recently proposed as an upper bound on the success of data reconstruction attacks against machine learning models. Previous research has demonstrated that differential privacy (DP) mechanisms also provide ReRo, but so far, only asymptotic Monte Carlo estimates of a tight ReRo bound have been shown. Directly computable ReRo bounds for general DP mechanisms are thus desirable. In this work, we establish a connection between hypothesis testing DP and ReRo and derive closed-form, analytic or numerical ReRo bounds for the Laplace and Gaussian mechanisms and their subsampled variants.
</details>
<details>
<summary>摘要</summary>
我们探索重建鲁棒性（ReRo），最近提出的数据重建攻击隐私模型的成功率上限。先前的研究表明，差分隐私（DP）机制也提供了ReRo，但只有非正式的贝叶斯 Monte Carlo 估计。因此，直接计算可读的 ReRo 下限对普通的 DP 机制是有价值的。在这种工作中，我们将假设测试DP与ReRo之间的连接，并对拉普拉斯和高斯机制及其抽样变体 derivation of closed-form, analytic or numerical ReRo bounds.
</details></li>
</ul>
<hr>
<h2 id="Applying-human-centered-AI-in-developing-effective-human-AI-teaming-A-perspective-of-human-AI-joint-cognitive-systems"><a href="#Applying-human-centered-AI-in-developing-effective-human-AI-teaming-A-perspective-of-human-AI-joint-cognitive-systems" class="headerlink" title="Applying human-centered AI in developing effective human-AI teaming: A perspective of human-AI joint cognitive systems"></a>Applying human-centered AI in developing effective human-AI teaming: A perspective of human-AI joint cognitive systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03913">http://arxiv.org/abs/2307.03913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Xu, Zaifeng Gao<br>for:* The paper focuses on the concept of human-AI teaming (HAT) as a new paradigm for developing AI systems, and the challenges and limitations of each member in human-AI collaboration.methods:* The paper proposes a conceptual framework of human-AI joint cognitive systems (HAIJCS) to represent and implement HAT for developing effective human-AI teaming.results:* The paper discusses the implications and future work for HAIJCS, and argues that HAIJCS may help adopt HAI while enabling HCAI.<details>
<summary>Abstract</summary>
Research and application have used human-AI teaming (HAT) as a new paradigm to develop AI systems. HAT recognizes that AI will function as a teammate instead of simply a tool in collaboration with humans. Effective human-AI teams need to be capable of taking advantage of the unique abilities of both humans and AI while overcoming the known challenges and limitations of each member, augmenting human capabilities, and raising joint performance beyond that of either entity. The National AI Research and Strategic Plan 2023 update has recognized that research programs focusing primarily on the independent performance of AI systems generally fail to consider the functionality that AI must provide within the context of dynamic, adaptive, and collaborative teams and calls for further research on human-AI teaming and collaboration. However, there has been debate about whether AI can work as a teammate with humans. The primary concern is that adopting the "teaming" paradigm contradicts the human-centered AI (HCAI) approach, resulting in humans losing control of AI systems. This article further analyzes the HAT paradigm and the debates. Specifically, we elaborate on our proposed conceptual framework of human-AI joint cognitive systems (HAIJCS) and apply it to represent HAT under the HCAI umbrella. We believe that HAIJCS may help adopt HAI while enabling HCAI. The implications and future work for HAIJCS are also discussed.   Insights: AI has led to the emergence of a new form of human-machine relationship: human-AI teaming (HAT), a paradigmatic shift in human-AI systems; We must follow a human-centered AI (HCAI) approach when applying HAT as a new design paradigm; We propose a conceptual framework of human-AI joint cognitive systems (HAIJCS) to represent and implement HAT for developing effective human-AI teaming
</details>
<details>
<summary>摘要</summary>
研究和应用已经使用人类-人工智能团队（HAT）作为新的设计模式开发人工智能系统。HAT认可人工智能将作为团队成员而不仅仅是工具和人类合作。有效的人类-人工智能团队需要能够利用人类和人工智能的特殊能力，超越每个成员的知道的限制，增强人类能力，并使团队性能高于任何一个成员。2023年国家人工智能研究和战略计划更新认为，研究专注于独立运行的人工智能系统的Programmes通常不会考虑人工智能在动态、适应和协作团队中的功能，并呼吁进一步研究人类-人工智能团队和合作。然而，有讨论是人工智能能够作为团队成员。主要关注点是采用“团队”模式会让人类失去对人工智能系统的控制。本文进一步分析HAT模式和辩论。特别是，我们详细阐述我们的提出的人类-人工智能共同认知系统（HAIJCS）概念框架，并将其应用于HCAI领域中的HAT。我们认为HAIJCS可以帮助采用HAI，同时保持HCAI。本文还讨论了HAIJCS的意义和未来工作。
</details></li>
</ul>
<hr>
<h2 id="ScriptWorld-Text-Based-Environment-For-Learning-Procedural-Knowledge"><a href="#ScriptWorld-Text-Based-Environment-For-Learning-Procedural-Knowledge" class="headerlink" title="ScriptWorld: Text Based Environment For Learning Procedural Knowledge"></a>ScriptWorld: Text Based Environment For Learning Procedural Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03906">http://arxiv.org/abs/2307.03906</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/exploration-lab/scriptworld">https://github.com/exploration-lab/scriptworld</a></li>
<li>paper_authors: Abhinav Joshi, Areeb Ahmad, Umang Pandey, Ashutosh Modi</li>
<li>for: 本研究旨在开发一个基于奖励学习的文本环境，用于帮助代理人学习日常生活中的常识知识和自然语言理解能力。</li>
<li>methods: 本研究使用了一个名为ScriptWorld的文本环境，其中包含了10种日常生活中的活动，并对这些活动进行了详细的分析。furthermore, the authors use reinforcement learning-based baseline models&#x2F;agents to play the games in Scriptworld, and leverage features obtained from pre-trained language models to understand the role of language models in such environments.</li>
<li>results: 实验结果表明，由于使用了预训练的语言模型，代理人可以更好地解决日常生活中的文本基于奖励学习环境。<details>
<summary>Abstract</summary>
Text-based games provide a framework for developing natural language understanding and commonsense knowledge about the world in reinforcement learning based agents. Existing text-based environments often rely on fictional situations and characters to create a gaming framework and are far from real-world scenarios. In this paper, we introduce ScriptWorld: a text-based environment for teaching agents about real-world daily chores and hence imparting commonsense knowledge. To the best of our knowledge, it is the first interactive text-based gaming framework that consists of daily real-world human activities designed using scripts dataset. We provide gaming environments for 10 daily activities and perform a detailed analysis of the proposed environment. We develop RL-based baseline models/agents to play the games in Scriptworld. To understand the role of language models in such environments, we leverage features obtained from pre-trained language models in the RL agents. Our experiments show that prior knowledge obtained from a pre-trained language model helps to solve real-world text-based gaming environments. We release the environment via Github: https://github.com/Exploration-Lab/ScriptWorld
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Prototypical-Part-Networks-with-Reward-Reweighing-Reselection-and-Retraining"><a href="#Improving-Prototypical-Part-Networks-with-Reward-Reweighing-Reselection-and-Retraining" class="headerlink" title="Improving Prototypical Part Networks with Reward Reweighing, Reselection, and Retraining"></a>Improving Prototypical Part Networks with Reward Reweighing, Reselection, and Retraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03887">http://arxiv.org/abs/2307.03887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robin Netzorg, Jiaxun Li, Bin Yu</li>
<li>for: 这个论文的目的是提出一种基于深度可读性方法的图像分类方法，以便从图像中提取有意义的特征来进行分类。</li>
<li>methods: 这种方法是基于protoypical part network（ProtoPNet），它尝试通过分析图像的各个部分来进行分类。然而，这种方法经常会从图像中学习无用或不一致的部分来进行分类。为了解决这个问题，这个论文引用了人工智能反馈学习（RLHF）的最近发展，以便为ProtoPNet进行微调。通过收集CUB-200-2011 dataset上的人工标注，构建一个奖励模型，以便识别非无用的原型。</li>
<li>results: 通过在ProtoPNet训练过程中添加奖励模型、重新选择和重新训练原型，提出了一种名为R3-ProtoPNet的新方法。R3-ProtoPNet可以提高图像分类中的总体一致性和有意义性，但是独立使用R3-ProtoPNet时会下降测试预测精度。然而，将多个R3-ProtoPNet组合成ensemble时，可以提高测试预测性能，同时保持可读性。<details>
<summary>Abstract</summary>
In recent years, work has gone into developing deep interpretable methods for image classification that clearly attributes a model's output to specific features of the data. One such of these methods is the prototypical part network (ProtoPNet), which attempts to classify images based on meaningful parts of the input. While this method results in interpretable classifications, this method often learns to classify from spurious or inconsistent parts of the image. Hoping to remedy this, we take inspiration from the recent developments in Reinforcement Learning with Human Feedback (RLHF) to fine-tune these prototypes. By collecting human annotations of prototypes quality via a 1-5 scale on the CUB-200-2011 dataset, we construct a reward model that learns to identify non-spurious prototypes. In place of a full RL update, we propose the reweighted, reselected, and retrained prototypical part network (R3-ProtoPNet), which adds an additional three steps to the ProtoPNet training loop. The first two steps are reward-based reweighting and reselection, which align prototypes with human feedback. The final step is retraining to realign the model's features with the updated prototypes. We find that R3-ProtoPNet improves the overall consistency and meaningfulness of the prototypes, but lower the test predictive accuracy when used independently. When multiple R3-ProtoPNets are incorporated into an ensemble, we find an increase in test predictive performance while maintaining interpretability.
</details>
<details>
<summary>摘要</summary>
近年来，有很多工作在发展深入可解释的图像分类方法，以便清晰地归因模型的输出到特定的数据特征。一种这些方法是 прототипиаль部分网络（ProtoPNet），它尝试通过基于图像的意义部分来分类图像。虽然这种方法可以得到可解释的分类结果，但它经常从不安定或不一致的图像部分进行分类。为了纠正这个问题，我们取得了人类对 проtotypes 质量的注释（通过 CUB-200-2011 数据集上的一个5级评分系统），并根据这些注释构建了一个奖励模型，可以识别非安定的 prototypes。而不是整个RL更新，我们提议一种名为 R3-ProtoPNet 的方法，它在 ProtoPNet 训练循环中添加了三个额外步骤。首先，我们使用奖励来重新权重和选择 prototypes，以使其与人类反馈相吻合。然后，我们重新训练模型的特征，以便与更新后的 prototypes 进行对齐。我们发现 R3-ProtoPNet 可以提高总的一致性和意义性，但在独立使用时测试预测精度相对较低。然而，当多个 R3-ProtoPNets 被组合成ensemble时，我们发现测试预测性能得到了提高，同时保持了可解释性。
</details></li>
</ul>
<hr>
<h2 id="Designing-Mixed-Initiative-Video-Games"><a href="#Designing-Mixed-Initiative-Video-Games" class="headerlink" title="Designing Mixed-Initiative Video Games"></a>Designing Mixed-Initiative Video Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03877">http://arxiv.org/abs/2307.03877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daijin Yang<br>for: This paper aims to explore the use of gamification in mixed-initiative co-creation to make human-AI interactions more accessible and fun.methods: The author prototyped a game called Snake Story, where players can select AI-generated texts to write a story of a snake by playing a “Snake” like game. A controlled experiment was conducted to compare player-AI interactions with and without the game component.results: The study found that players utilized different strategies when playing with the two versions, game mechanics significantly affected the output stories, players’ creative process, and players’ role perceptions. Additionally, players with different backgrounds showed different preferences for the two versions.<details>
<summary>Abstract</summary>
The development of Artificial Intelligence (AI) enables humans to co-create content with machines. The unexpectedness of AI-generated content can bring inspiration and entertainment to users. However, the co-creation interactions are always designed for content creators and have poor accessibility. To explore gamification of mixed-initiative co-creation and make human-AI interactions accessible and fun for players, I prototyped Snake Story, a mixed-initiative game where players can select AI-generated texts to write a story of a snake by playing a "Snake" like game. A controlled experiment was conducted to investigate the dynamics of player-AI interactions with and without the game component in the designed interface. As a result of a study with 11 players (n=11), I found that players utilized different strategies when playing with the two versions, game mechanics significantly affected the output stories, players' creative process, as well as role perceptions, and players with different backgrounds showed different preferences for the two versions. Based on these results, I further discussed considerations for mixed-initiative game design. This work aims to inspire the design of engaging co-creation experiences.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）的发展使得人们可以与机器共同创作内容。AI生成的内容的不可预测性可以给用户带来创意和娱乐。然而，共同创作交互都是为内容创作者设计的，而且访问性很差。为了探索杂合式共同创作的游戏化和人机交互的可乐性，我设计了蛇故事，一款杂合式游戏，其中玩家可以通过选择AI生成的文本来写一个蛇的故事。我们进行了一项控制实验，并与11名玩家进行了测试（n=11）。结果表明，玩家在两个版本中使用了不同的策略，游戏机制对输出故事、玩家的创作过程以及玩家的角色认知产生了显著影响，而不同背景的玩家也表现出了不同的偏好。这些结果表明，在设计杂合式游戏时需要考虑一些考量。这项工作的目的是鼓励设计有趣的共同创作经验。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-for-Supply-Chain-Optimization"><a href="#Large-Language-Models-for-Supply-Chain-Optimization" class="headerlink" title="Large Language Models for Supply Chain Optimization"></a>Large Language Models for Supply Chain Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03875">http://arxiv.org/abs/2307.03875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan Pathuri, Ishai Menache</li>
<li>for: 该研究旨在使用大语言模型（LLM）提高供应链自动化的可理解度和信任度。</li>
<li>methods: 研究提出了一个名为 OptiGuide 的框架，可以接受普通文本查询，并输出供应链优化结果的概念性解释。该框架不会抛弃现有的可combined optimization技术，而是通过解决 what-if 问题（例如，如果使用提供商 B 而不是提供商 A 来满足某个需求，则cost 会如何变化？）来提供可衡量的答案。</li>
<li>results: 研究在 Microsoft 云供应链中实现了一个真实的服务器分布式enario，并开发了一个通用的评估标准，可以用于评估其他情况下 LLM 输出的准确性。<details>
<summary>Abstract</summary>
Supply chain operations traditionally involve a variety of complex decision making problems. Over the last few decades, supply chains greatly benefited from advances in computation, which allowed the transition from manual processing to automation and cost-effective optimization. Nonetheless, business operators still need to spend substantial efforts in explaining and interpreting the optimization outcomes to stakeholders. Motivated by the recent advances in Large Language Models (LLMs), we study how this disruptive technology can help bridge the gap between supply chain automation and human comprehension and trust thereof. We design OptiGuide -- a framework that accepts as input queries in plain text, and outputs insights about the underlying optimization outcomes. Our framework does not forgo the state-of-the-art combinatorial optimization technology, but rather leverages it to quantitatively answer what-if scenarios (e.g., how would the cost change if we used supplier B instead of supplier A for a given demand?). Importantly, our design does not require sending proprietary data over to LLMs, which can be a privacy concern in some circumstances. We demonstrate the effectiveness of our framework on a real server placement scenario within Microsoft's cloud supply chain. Along the way, we develop a general evaluation benchmark, which can be used to evaluate the accuracy of the LLM output in other scenarios.
</details>
<details>
<summary>摘要</summary>
供应链操作涉及到许多复杂的决策问题。过去几十年，供应链受到计算技术的进步，从手动处理转变到自动化和成本效果的优化。然而，商业运营者仍需投入大量的努力来解释和解读优化结果给潜在投资者。鼓励了最近的大语言模型（LLM）的进步，我们研究如何使用这种破坏技术来bridging供应链自动化和人类理解和信任之间的差距。我们设计了OptiGuide框架，它接受输入是简单文本问题，并输出供应链优化结果的凝视。我们的框架不会抛弃现有的组合优化技术，而是利用它来回答具有优化结果的what-ifenario（例如，如果使用supplier B而不是supplier A来满足一个需求， Then what would be the cost?）。重要的是，我们的设计不会将专有数据传输到LLM，这可能会在某些情况下成为隐私问题。我们在Microsoft云供应链中进行了一个真实的服务部署场景，并开发了一个通用的评估标准，可以用于评估LLM输出的准确性在其他场景中。
</details></li>
</ul>
<hr>
<h2 id="Domain-Adaptation-using-Silver-Standard-Labels-for-Ki-67-Scoring-in-Digital-Pathology-A-Step-Closer-to-Widescale-Deployment"><a href="#Domain-Adaptation-using-Silver-Standard-Labels-for-Ki-67-Scoring-in-Digital-Pathology-A-Step-Closer-to-Widescale-Deployment" class="headerlink" title="Domain Adaptation using Silver Standard Labels for Ki-67 Scoring in Digital Pathology: A Step Closer to Widescale Deployment"></a>Domain Adaptation using Silver Standard Labels for Ki-67 Scoring in Digital Pathology: A Step Closer to Widescale Deployment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03872">http://arxiv.org/abs/2307.03872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amanda Dy, Ngoc-Nhu Jennifer Nguyen, Seyed Hossein Mirjahanmardi, Melanie Dawe, Anthony Fyles, Wei Shi, Fei-Fei Liu, Dimitrios Androutsos, Susan Done, April Khademi</li>
<li>for: 提高基因矫正评分的对 объекivity和效率</li>
<li>methods: 使用无监督框架生成目标领域的银标签，并将银标签与来源领域的金标签（GS）一起使用进行训练</li>
<li>results: 在两种验证的基因矫正架构（UV-Net和piNET）上测试了五种训练方案，其中SS+GS方法在目标数据上显示出最高的PI准确率（95.9%）和更一致的结果，并且分析了t-SNE图表表明SS+GS模型学习的特征更加适合源和目标数据，从而提高了通用性。<details>
<summary>Abstract</summary>
Deep learning systems have been proposed to improve the objectivity and efficiency of Ki- 67 PI scoring. The challenge is that while very accurate, deep learning techniques suffer from reduced performance when applied to out-of-domain data. This is a critical challenge for clinical translation, as models are typically trained using data available to the vendor, which is not from the target domain. To address this challenge, this study proposes a domain adaptation pipeline that employs an unsupervised framework to generate silver standard (pseudo) labels in the target domain, which is used to augment the gold standard (GS) source domain data. Five training regimes were tested on two validated Ki-67 scoring architectures (UV-Net and piNET), (1) SS Only: trained on target silver standard (SS) labels, (2) GS Only: trained on source GS labels, (3) Mixed: trained on target SS and source GS labels, (4) GS+SS: trained on source GS labels and fine-tuned on target SS labels, and our proposed method (5) SS+GS: trained on source SS labels and fine-tuned on source GS labels. The SS+GS method yielded significantly (p < 0.05) higher PI accuracy (95.9%) and more consistent results compared to the GS Only model on target data. Analysis of t-SNE plots showed features learned by the SS+GS models are more aligned for source and target data, resulting in improved generalization. The proposed pipeline provides an efficient method for learning the target distribution without manual annotations, which are time-consuming and costly to generate for medical images. This framework can be applied to any target site as a per-laboratory calibration method, for widescale deployment.
</details>
<details>
<summary>摘要</summary>
深度学习系统可以提高 Ki-67 PI 分数的 объектив性和效率。然而，深度学习技术在不同领域数据上表现不佳，这是临床翻译中的挑战。为解决这个挑战，本研究提出了一个领域适应管道，使用无监督框架生成目标领域的银标签（pseudo labels），并将其与源领域的黄金标签（GS）一起使用来补充数据。本研究测试了五种训练方案，包括（1）SS Only：在目标领域的银标签（SS）上训练，（2）GS Only：在源领域的黄金标签（GS）上训练，（3）Mixed：在目标领域的银标签和源领域的黄金标签上训练，（4）GS+SS：在源领域的黄金标签上训练，然后在目标领域的银标签上进行细化，以及我们的提议方法（5）SS+GS：在源领域的银标签上训练，然后在源领域的黄金标签上进行细化。SS+GS 方法在目标数据上显示出了明显高于GS Only模型的PI准确率（95.9%）和更一致的结果。分析t-SNE图示了SS+GS模型学习的特征与源和目标数据更加一致，导致了提高了总体化。这种管道可以高效地学习目标分布而无需手动标注，这些标注是医疗图像生成的时间消耗和成本高昂的。这种框架可以在任何目标站点上进行各实验室的调整，为广泛部署准备。
</details></li>
</ul>
<hr>
<h2 id="Personalized-Resource-Allocation-in-Wireless-Networks-An-AI-Enabled-and-Big-Data-Driven-Multi-Objective-Optimization"><a href="#Personalized-Resource-Allocation-in-Wireless-Networks-An-AI-Enabled-and-Big-Data-Driven-Multi-Objective-Optimization" class="headerlink" title="Personalized Resource Allocation in Wireless Networks: An AI-Enabled and Big Data-Driven Multi-Objective Optimization"></a>Personalized Resource Allocation in Wireless Networks: An AI-Enabled and Big Data-Driven Multi-Objective Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03867">http://arxiv.org/abs/2307.03867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rawan Alkurd, Ibrahim Abualhaol, Halim Yanikomeroglu</li>
<li>for: 本文主要用于描述如何使用人工智能（AI）技术来优化无线网络设计和优化。</li>
<li>methods: 本文使用了AI技术来实现用户水平个性化，并且提出了一种基于大数据的智能层来微管无线网络资源。</li>
<li>results: 根据本文描述，使用AI技术可以在无线网络中实现用户水平个性化，并且可以在实时中微调网络资源以提高用户满意度和资源利用率。<details>
<summary>Abstract</summary>
The design and optimization of wireless networks have mostly been based on strong mathematical and theoretical modeling. Nonetheless, as novel applications emerge in the era of 5G and beyond, unprecedented levels of complexity will be encountered in the design and optimization of the network. As a result, the use of Artificial Intelligence (AI) is envisioned for wireless network design and optimization due to the flexibility and adaptability it offers in solving extremely complex problems in real-time. One of the main future applications of AI is enabling user-level personalization for numerous use cases. AI will revolutionize the way we interact with computers in which computers will be able to sense commands and emotions from humans in a non-intrusive manner, making the entire process transparent to users. By leveraging this capability, and accelerated by the advances in computing technologies, wireless networks can be redesigned to enable the personalization of network services to the user level in real-time. While current wireless networks are being optimized to achieve a predefined set of quality requirements, the personalization technology advocated in this article is supported by an intelligent big data-driven layer designed to micro-manage the scarce network resources. This layer provides the intelligence required to decide the necessary service quality that achieves the target satisfaction level for each user. Due to its dynamic and flexible design, personalized networks are expected to achieve unprecedented improvements in optimizing two contradicting objectives in wireless networks: saving resources and improving user satisfaction levels.
</details>
<details>
<summary>摘要</summary>
wireless 网络的设计和优化曾主要基于强大的数学和理论模型。然而，随着5G和以后的应用出现， wireless 网络的设计和优化将面临无前例的复杂性。因此，人工智能（AI）将在无线网络设计和优化中扮演重要的作用，因为它可以在实时解决极其复杂的问题中提供灵活和适应性。未来，AI 将在无线网络设计和优化中扮演重要的作用，允许用户水平个性化。通过感知人类的命令和情感，计算机将成为不侵入的，使整个过程透明给用户。通过这种能力，并且受计算技术的加速，无线网络可以被重新设计，以实时个性化网络服务，以达到每个用户的目标满意度。当前的无线网络被优化以实现一组预定的质量要求，而人性化技术在本文中提出的协助层，通过大数据驱动的智能层，为缺乏资源的网络资源进行微管理。这层提供了必要的智能，以确定每个用户需要的服务质量，以达到目标满意度水平。由于它的动态和灵活设计，个性化网络预计会实现无前例的改善，在无线网络中改善两个矛盾目标：节约资源和提高用户满意度水平。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-and-Deep-Reinforcement-Learning-based-Solutions-for-Machine-Maintenance-Planning-Scheduling-Policies-and-Optimization"><a href="#Reinforcement-and-Deep-Reinforcement-Learning-based-Solutions-for-Machine-Maintenance-Planning-Scheduling-Policies-and-Optimization" class="headerlink" title="Reinforcement and Deep Reinforcement Learning-based Solutions for Machine Maintenance Planning, Scheduling Policies, and Optimization"></a>Reinforcement and Deep Reinforcement Learning-based Solutions for Machine Maintenance Planning, Scheduling Policies, and Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03860">http://arxiv.org/abs/2307.03860</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oluwaseyi Ogunfowora, Homayoun Najjaran</li>
<li>for: 本研究目的是对维护规划和优化问题的应用 Reinforcement Learning 进行文献查询和分析。</li>
<li>methods: 本研究使用了 Reinforcement Learning 和深度 Reinforcement Learning 等数据驱动决策算法来开发智能维护计划。</li>
<li>results: 本研究通过对文献进行分类和摘要，提出了维护规划和优化问题的共同主题和研究方法，同时还提出了未来研究的方向和关键问题。<details>
<summary>Abstract</summary>
Systems and machines undergo various failure modes that result in machine health degradation, so maintenance actions are required to restore them back to a state where they can perform their expected functions. Since maintenance tasks are inevitable, maintenance planning is essential to ensure the smooth operations of the production system and other industries at large. Maintenance planning is a decision-making problem that aims at developing optimum maintenance policies and plans that help reduces maintenance costs, extend asset life, maximize their availability, and ultimately ensure workplace safety. Reinforcement learning is a data-driven decision-making algorithm that has been increasingly applied to develop dynamic maintenance plans while leveraging the continuous information from condition monitoring of the system and machine states. By leveraging the condition monitoring data of systems and machines with reinforcement learning, smart maintenance planners can be developed, which is a precursor to achieving a smart factory. This paper presents a literature review on the applications of reinforcement and deep reinforcement learning for maintenance planning and optimization problems. To capture the common ideas without losing touch with the uniqueness of each publication, taxonomies used to categorize the systems were developed, and reviewed publications were highlighted, classified, and summarized based on these taxonomies. Adopted methodologies, findings, and well-defined interpretations of the reviewed studies were summarized in graphical and tabular representations to maximize the utility of the work for both researchers and practitioners. This work also highlights the research gaps, key insights from the literature, and areas for future work.
</details>
<details>
<summary>摘要</summary>
系统和机器会经历多种失效模式，导致机器健康下降，因此维护工作是必要的来恢复它们回到可以进行预期功能的状态。由于维护任务是不可避免的，因此维护观察是必要的来确保生产系统和其他业界的顺畅运行。维护观察是一个决策问题，旨在发展最佳维护政策和计划，帮助降低维护成本，延长资产寿命，最大化资产可用性，并确保工作安全。对于系统和机器的状态监控数据，强化学习是一种资料驱动的决策算法，它在发展动态维护计划方面表现出色。透过对系统和机器的状态监控数据的强化学习，可以发展出智能维护观察器，这是智能工厂的前提。本文将介绍对维护观察和优化问题的应用强化学习和深度强化学习的文献综述。为了捕捉每篇文章的共同主题而不失其各自独特性，文章被分类和摘要，并以文献综述的形式呈现，以便 для研究人员和实践者对其具有最大的实用性。本文还 highlights 维护观察和优化问题的研究漏洞、文献综述中的主要意义和未来工作的方向。
</details></li>
</ul>
<hr>
<h2 id="Teach-Me-How-to-Learn-A-Perspective-Review-towards-User-centered-Neuro-symbolic-Learning-for-Robotic-Surgical-Systems"><a href="#Teach-Me-How-to-Learn-A-Perspective-Review-towards-User-centered-Neuro-symbolic-Learning-for-Robotic-Surgical-Systems" class="headerlink" title="Teach Me How to Learn: A Perspective Review towards User-centered Neuro-symbolic Learning for Robotic Surgical Systems"></a>Teach Me How to Learn: A Perspective Review towards User-centered Neuro-symbolic Learning for Robotic Surgical Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03853">http://arxiv.org/abs/2307.03853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amr Gomaa, Bilal Mahdy, Niko Kleer, Michael Feld, Frank Kirchner, Antonio Krüger<br>for: 这项研究旨在开发一种人类在Loop学习 paradigma，用于教育机器人在术式和感知两个水平上进行学习，以提高机器人在手术过程中的性能。methods: 本研究使用了混合神经符号学习方法，其中包括人类在Loop学习和自动学习两个方面。results: 研究人员通过对各种手术任务进行评估，发现存在一些挑战，如机器人与外科医生之间的交互和feedback问题。此外，还发现了一些可能的解决方案，如在线学习和专家反馈。<details>
<summary>Abstract</summary>
Recent advances in machine learning models allowed robots to identify objects on a perceptual nonsymbolic level (e.g., through sensor fusion and natural language understanding). However, these primarily black-box learning models still lack interpretation and transferability and require high data and computational demand. An alternative solution is to teach a robot on both perceptual nonsymbolic and conceptual symbolic levels through hybrid neurosymbolic learning approaches with expert feedback (i.e., human-in-the-loop learning). This work proposes a concept for this user-centered hybrid learning paradigm that focuses on robotic surgical situations. While most recent research focused on hybrid learning for non-robotic and some generic robotic domains, little work focuses on surgical robotics. We survey this related research while focusing on human-in-the-loop surgical robotic systems. This evaluation highlights the most prominent solutions for autonomous surgical robots and the challenges surgeons face when interacting with these systems. Finally, we envision possible ways to address these challenges using online apprenticeship learning based on implicit and explicit feedback from expert surgeons.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:近期机器学习模型的进步使得机器人能够通过感知混合和自然语言理解识别物体，但这些主要是黑盒学习模型，仍然缺乏解释性和可 перенос性，并需要高度数据和计算资源。一种 altenative 解决方案是通过混合神经符号学习方法与专家反馈（即人在循环学习）来教育机器人。这个工作提出了一种以用户为中心的混合学习 парадиг，专注于 робо医学应用。虽然最近的研究主要集中在非机器人和一些通用机器人领域的混合学习，但对于手术机器人来说，有很少的研究。我们在这些相关研究中做了评估，主要关注人在循环手术机器系统中与这些系统的互动所遇到的挑战。最后，我们想象了使用在线循环学习，基于专家外科医生的显式和隐式反馈来解决这些挑战。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Learners-for-Realizable-Regression-PAC-Learning-and-Online-Learning"><a href="#Optimal-Learners-for-Realizable-Regression-PAC-Learning-and-Online-Learning" class="headerlink" title="Optimal Learners for Realizable Regression: PAC Learning and Online Learning"></a>Optimal Learners for Realizable Regression: PAC Learning and Online Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03848">http://arxiv.org/abs/2307.03848</a></li>
<li>repo_url: None</li>
<li>paper_authors: Idan Attias, Steve Hanneke, Alkis Kalavasis, Amin Karbasi, Grigoris Velegkas</li>
<li>for: 本文的目的是Characterizing the statistical complexity of realizable regression in both PAC learning setting and online learning setting.</li>
<li>methods: 本文使用了一种新的维度来Characterize which classes of real-valued predictors are learnable, 以及一种新的维度来Characterize the minimax instance optimal cumulative loss up to a constant factor.</li>
<li>results: 本文提出了一个必要的 condition for learnability based on a combinatorial dimension related to the DS dimension, 并 conjecture that it may also be sufficient in this context. 此外，本文还解决了Daskalakis和Golowich在STOC ‘22中提出的一个开Question.<details>
<summary>Abstract</summary>
In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting.   Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in this context.   Additionally, in the context of online learning we provide a dimension that characterizes the minimax instance optimal cumulative loss up to a constant factor and design an optimal online learner for realizable regression, thus resolving an open question raised by Daskalakis and Golowich in STOC '22.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们目标是characterize realizable regression的统计复杂性在PAC学习 Setting和在线学习 Setting中。先前的工作已经证明了实izable regression的可学习性充分 suffices finiteness of the fat shattering dimension，但是没有进行更完整的Characterization。为此，我们首先引入一个最小最优学习器 для realizable regression，并提出一种新的维度来Characterize which classes of real-valued predictors are learnable。然后，我们 indentify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting。最后，我们确立了学习可能性的必要条件，基于一种 combinatorial dimension related to the DS dimension，并speculate that it may also be sufficient in this context。在在线学习 Setting中，我们提供了一个Characterize the minimax instance optimal cumulative loss up to a constant factor的维度，并设计了一个optimal online learner for realizable regression，这解决了Daskalakis和Golowich在STOC '22中提出的一个开问。
</details></li>
</ul>
<hr>
<h2 id="RADAR-Robust-AI-Text-Detection-via-Adversarial-Learning"><a href="#RADAR-Robust-AI-Text-Detection-via-Adversarial-Learning" class="headerlink" title="RADAR: Robust AI-Text Detection via Adversarial Learning"></a>RADAR: Robust AI-Text Detection via Adversarial Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03838">http://arxiv.org/abs/2307.03838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho<br>for: 这篇论文主要目的是提出一个新的框架，即 RADAR，用于检测人工智能文本生成器（LLM）生成的文本是否真实，并且能够对抗LLM生成的各种抽象和重建文本。methods: 这篇论文提出了一个新的框架RADAR，其中包括两个主要部分：一个是一个强大的AI-text检测器，另一个是一个强大的伪文本生成器。这两个部分在训练时会互相影响，以提高AI-text检测器的准确性和适用范围。results: 实验结果显示，RADAR在8种不同的LLM中进行测试时，具有与现有AI-text检测方法相比的优秀性能，特别是在各种抽象和重建文本情况下。此外，RADAR还能够对不同的LLM进行强大的转移学习，并且透过GPT-3.5进行进一步的改进。<details>
<summary>Abstract</summary>
Recent advances in large language models (LLMs) and the intensifying popularity of ChatGPT-like applications have blurred the boundary of high-quality text generation between humans and machines. However, in addition to the anticipated revolutionary changes to our technology and society, the difficulty of distinguishing LLM-generated texts (AI-text) from human-generated texts poses new challenges of misuse and fairness, such as fake content generation, plagiarism, and false accusation of innocent writers. While existing works show that current AI-text detectors are not robust to LLM-based paraphrasing, this paper aims to bridge this gap by proposing a new framework called RADAR, which jointly trains a Robust AI-text Detector via Adversarial leaRning. RADAR is based on adversarial training of a paraphraser and a detector. The paraphraser's goal is to generate realistic contents to evade AI-text detection. RADAR uses the feedback from the detector to update the paraphraser, and vice versa. Evaluated with 8 different LLMs (Pythia, Dolly 2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna) across 4 datasets, experimental results show that RADAR significantly outperforms existing AI-text detection methods, especially when paraphrasing is in place. We also identify the strong transferability of RADAR from instruction-tuned LLMs to other LLMs, and evaluate the improved capability of RADAR via GPT-3.5.
</details>
<details>
<summary>摘要</summary>
近年的大语言模型（LLM）和智能客户端应用的普及，使得人机生成高质量文本的边界变得模糊。然而，这些技术和社会变革的潜在改变，也带来了新的困难，如假内容生成、抄袭和无辜的写作者被诬告。现有研究表明，现有的AI-文本检测器对LLM-基于重新推敲的文本不具有坚固的鲁棒性。这篇论文旨在bridging这个差距，提出了一种新的框架，即RADAR，它通过对抗学习训练一个Robust AI-文本检测器和一个重新推敲器。RADAR基于抗对抗训练，重新推敲器的目标是生成真实的内容，逃脱AI-文本检测器的检测。RADAR通过检测器对重新推敲器的反馈来更新重新推敲器，并 vice versa。在8种不同的LLM（Pythia、Dolly 2.0、Palmyra、Camel、GPT-J、Dolly 1.0、LLaMA和Vicuna）在4个数据集上进行了实验，结果显示，RADAR在AI-文本检测方面表现出色，特别是在重新推敲时。我们还发现了RADAR在受过特定指令的LLM上的强大传输性，并通过GPT-3.5进行评估，发现RADAR的改进能力。
</details></li>
</ul>
<hr>
<h2 id="Back-to-Optimization-Diffusion-based-Zero-Shot-3D-Human-Pose-Estimation"><a href="#Back-to-Optimization-Diffusion-based-Zero-Shot-3D-Human-Pose-Estimation" class="headerlink" title="Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation"></a>Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03833">http://arxiv.org/abs/2307.03833</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ipl-uw/ZeDO-Release">https://github.com/ipl-uw/ZeDO-Release</a></li>
<li>paper_authors: Zhongyu Jiang, Zhuoran Zhou, Lei Li, Wenhao Chai, Cheng-Yen Yang, Jenq-Neng Hwang</li>
<li>for: 3D human pose estimation (HPE) tasks in the wild, where traditional optimization-based methods have limited performance and learning-based methods have difficulty generalizing to new domains and scenarios.</li>
<li>methods: Zero-shot Diffusion-based Optimization (ZeDO) pipeline, which combines the advantages of optimization-based and learning-based methods by using a diffusion process to refine the pose estimates and a multi-hypothesis framework to handle cross-domain and in-the-wild variations.</li>
<li>results: state-of-the-art (SOTA) performance on Human3.6M and 3DPW datasets, with minMPJPE $51.4$mm and PA-MPJPE $42.6$mm, respectively, without requiring any 2D-3D or image-3D pairs for training.<details>
<summary>Abstract</summary>
Learning-based methods have dominated the 3D human pose estimation (HPE) tasks with significantly better performance in most benchmarks than traditional optimization-based methods. Nonetheless, 3D HPE in the wild is still the biggest challenge of learning-based models, whether with 2D-3D lifting, image-to-3D, or diffusion-based methods, since the trained networks implicitly learn camera intrinsic parameters and domain-based 3D human pose distributions and estimate poses by statistical average. On the other hand, the optimization-based methods estimate results case-by-case, which can predict more diverse and sophisticated human poses in the wild. By combining the advantages of optimization-based and learning-based methods, we propose the Zero-shot Diffusion-based Optimization (ZeDO) pipeline for 3D HPE to solve the problem of cross-domain and in-the-wild 3D HPE. Our multi-hypothesis ZeDO achieves state-of-the-art (SOTA) performance on Human3.6M as minMPJPE $51.4$mm without training with any 2D-3D or image-3D pairs. Moreover, our single-hypothesis ZeDO achieves SOTA performance on 3DPW dataset with PA-MPJPE $42.6$mm on cross-dataset evaluation, which even outperforms learning-based methods trained on 3DPW.
</details>
<details>
<summary>摘要</summary>
学习基于方法在3D人姿估计任务中占据主导地位，在大多数标准准则上比传统优化基于方法更好表现。然而，3D人姿估计在野外仍然是学习基于方法模型的最大挑战，无论是2D-3D升级、图像-3D或扩散基于方法。这是因为训练的网络隐藏状态参数和领域基于3D人姿分布，并估计姿势的统计平均值。相比之下，优化基于方法方法每个案例都预测结果，可以预测更多和更复杂的人姿。我们提出了基于零shot扩散优化（ZeDO）管道来解决跨领域和野外3D人姿估计问题。我们的多种假设ZeDO在人3.6M数据集上实现了最佳性（SOTA）性能，无需训练2D-3D或图像-3D对。此外，我们的单种假设ZeDO在3DPW数据集上实现了SOTA性能，与学习基于方法方法相比，即使在跨数据集评估中。
</details></li>
</ul>
<hr>
<h2 id="Effect-of-Intensity-Standardization-on-Deep-Learning-for-WML-Segmentation-in-Multi-Centre-FLAIR-MRI"><a href="#Effect-of-Intensity-Standardization-on-Deep-Learning-for-WML-Segmentation-in-Multi-Centre-FLAIR-MRI" class="headerlink" title="Effect of Intensity Standardization on Deep Learning for WML Segmentation in Multi-Centre FLAIR MRI"></a>Effect of Intensity Standardization on Deep Learning for WML Segmentation in Multi-Centre FLAIR MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03827">http://arxiv.org/abs/2307.03827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdollah Ghazvanchahi, Pejman Jahbedar Maralani, Alan R. Moody, April Khademi</li>
<li>for: 这个论文的目的是对FLAIR MR图像进行白 matter损变（WML）分割，以提高DL方法在不同成像中心的性能。</li>
<li>methods: 这个论文使用了多种抑制法，包括IALMLAB和其他流行的 нормализа法，以及一种 skip-connection UNet 模型。</li>
<li>results: 结果显示，IALMLAB和 ensemble 方法在各种维度上都有较高的WML分割性能，特别是在不同的成像中心数据上。<details>
<summary>Abstract</summary>
Deep learning (DL) methods for white matter lesion (WML) segmentation in MRI suffer a reduction in performance when applied on data from a scanner or centre that is out-of-distribution (OOD) from the training data. This is critical for translation and widescale adoption, since current models cannot be readily applied to data from new institutions. In this work, we evaluate several intensity standardization methods for MRI as a preprocessing step for WML segmentation in multi-centre Fluid-Attenuated Inversion Recovery (FLAIR) MRI. We evaluate a method specifically developed for FLAIR MRI called IAMLAB along with other popular normalization techniques such as White-strip, Nyul and Z-score. We proposed an Ensemble model that combines predictions from each of these models. A skip-connection UNet (SC UNet) was trained on the standardized images, as well as the original data and segmentation performance was evaluated over several dimensions. The training (in-distribution) data consists of a single study, of 60 volumes, and the test (OOD) data is 128 unseen volumes from three clinical cohorts. Results show IAMLAB and Ensemble provide higher WML segmentation performance compared to models from original data or other normalization methods. IAMLAB & Ensemble have the highest dice similarity coefficient (DSC) on the in-distribution data (0.78 & 0.80) and on clinical OOD data. DSC was significantly higher for IAMLAB compared to the original data (p<0.05) for all lesion categories (LL>25mL: 0.77 vs. 0.71; 10mL<= LL<25mL: 0.66 vs. 0.61; LL<10mL: 0.53 vs. 0.52). The IAMLAB and Ensemble normalization methods are mitigating MRI domain shift and are optimal for DL-based WML segmentation in unseen FLAIR data.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）方法用于FLAIR MR中的白质损伤（WML）分 segmentation时，当应用于不同的扫描仪或中心数据时，性能会下降。这对于翻译和大规模应用而言是重要的，因为当前的模型无法 direct 应用于新机构的数据。在这种情况下，我们评估了多种INTENSITY STANDARDIZATION METHODS FOR MRI作为FLAIR MR分 segmentation的预处理步骤。我们评估了specifically developed for FLAIR MR的IAMLAB方法，以及其他流行的normalization技术，如White-strip、Nyul和Z-score。我们提出了一种ensemble模型，该模型将每个模型的预测结果进行combine。一个skip-connection UNET（SC UNNet）在标准化图像上进行训练，以及原始数据上。我们对标准化图像和原始数据进行分 segmentation性能进行评估。training（在 Distribution）数据包括60个Volume，测试（OOD）数据包括128个未看过的Volume从三个临床群体。结果显示，IAMLAB和Ensemble方法在WML分 segmentation中提供了更高的性能，相比于原始数据或其他normalization方法。IAMLAB和Ensemble方法在in-distribution数据上的DSC（ dice similarity coefficient）为0.78和0.80，并在临床OOD数据上也有最高的DSC。相比原始数据，IAMLAB方法的DSC显著高于原始数据（p<0.05），对所有损伤分类（LL>25mL：0.77 vs. 0.71; 10mL≤ LL<25mL：0.66 vs. 0.61; LL<10mL：0.53 vs. 0.52）。IAMLAB和Ensemble normalization方法可以 Mitigate MRI DOMAIN SHIFT，是适用于DL-based WML分 segmentation的优选方法。
</details></li>
</ul>
<hr>
<h2 id="How-does-AI-chat-change-search-behaviors"><a href="#How-does-AI-chat-change-search-behaviors" class="headerlink" title="How does AI chat change search behaviors?"></a>How does AI chat change search behaviors?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03826">http://arxiv.org/abs/2307.03826</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert Capra, Jaime Arguello</li>
<li>for: 这个研究是一个初步的调查，旨在研究用户在搜索过程中如何使用生成AI聊天系统（简称chat），以及将chat系统与现有搜索工具结合使用后，用户的搜索习惯和策略会受到什么影响。</li>
<li>methods: 这个研究使用了10名参与者，他们使用了一个组合的Chat+Search系统，该系统使用了OpenAI GPT-3.5 API和Bing Web Search v5 API。参与者完成了三个搜索任务。</li>
<li>results: 这个预印稿中报告了用户如何将AI聊天系统纳入搜索过程中，他们对聊天系统的喜好和不喜好，对聊天系统的信任度，以及他们对聊天系统生成回复的心理模型。<details>
<summary>Abstract</summary>
Generative AI tools such as chatGPT are poised to change the way people engage with online information. Recently, Microsoft announced their "new Bing" search system which incorporates chat and generative AI technology from OpenAI. Google has announced plans to deploy search interfaces that incorporate similar types of technology. These new technologies will transform how people can search for information. The research presented here is an early investigation into how people make use of a generative AI chat system (referred to simply as chat from here on) as part of a search process, and how the incorporation of chat systems with existing search tools may effect users search behaviors and strategies.   We report on an exploratory user study with 10 participants who used a combined Chat+Search system that utilized the OpenAI GPT-3.5 API and the Bing Web Search v5 API. Participants completed three search tasks. In this pre-print paper of preliminary results, we report on ways that users integrated AI chat into their search process, things they liked and disliked about the chat system, their trust in the chat responses, and their mental models of how the chat system generated responses.
</details>
<details>
<summary>摘要</summary>
“生成AI工具如 chatGPT 将改变线上信息搜寻方式。微软最近宣布“新的Bing”搜寻系统，融合了OpenAI的 chat和生成AI技术。Google 也宣布将推出相似的技术。这些新技术将改变人们搜寻资讯的方式。本研究是探索用户如何使用生成AI chat系统（以下简称为“chat”）作为搜寻过程的一部分，以及将 chat 系统与现有的搜寻工具结合后对用户搜寻行为和策略的影响。”“我们进行了10名用户的exploratory用户研究，他们使用了 combine Chat+Search 系统，该系统使用 OpenAI GPT-3.5 API 和 Bing Web Search v5 API。用户完成了三个搜寻任务。在这个预印稿中，我们报告了用户如何将 chat 系统组合到搜寻过程中，他们喜欢和不喜欢 chat 系统，他们对 chat 系统的信任度，以及他们如何解释 chat 系统生成的回答。”
</details></li>
</ul>
<hr>
<h2 id="Exploring-and-Characterizing-Large-Language-Models-For-Embedded-System-Development-and-Debugging"><a href="#Exploring-and-Characterizing-Large-Language-Models-For-Embedded-System-Development-and-Debugging" class="headerlink" title="Exploring and Characterizing Large Language Models For Embedded System Development and Debugging"></a>Exploring and Characterizing Large Language Models For Embedded System Development and Debugging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03817">http://arxiv.org/abs/2307.03817</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zachary Englhardt, Richard Li, Dilini Nissanka, Zhihan Zhang, Girish Narayanswamy, Joseph Breda, Xin Liu, Shwetak Patel, Vikram Iyer<br>for:这种论文旨在评估领先的大语言模型（GPT-3.5、GPT-4、PaLM 2）在嵌入式系统开发中的表现，以及人工程序员与这些工具之间的交互方式。methods:该论文采用端到端硬件在Loop（HIL）评估平台来验证LLM生成的程序，并对N&#x3D;450个实验进行比较。同时，该论文还开发了一种基于AI的软件工程办事处程序，用于建立嵌入式系统。results:研究发现，GPT-4特别表现出跨领域理解和逻辑能力，在某些情况下可以从单个提示生成完全正确的程序。在N&#x3D;50次实验中，GPT-4生成的I2C接口66%的时间能够正常工作。此外，GPT-4还生成了特定的储存器驱动程序、LoRa通信程序和Context特定的电源优化程序，使nRF52程序的电流减少至12.2 uA，减少了740倍。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown remarkable abilities to generate code, however their ability to develop software for embedded systems, which requires cross-domain knowledge of hardware and software has not been studied. In this paper we systematically evaluate leading LLMs (GPT-3.5, GPT-4, PaLM 2) to assess their performance for embedded system development, study how human programmers interact with these tools, and develop an AI-based software engineering workflow for building embedded systems.   We develop an an end-to-end hardware-in-the-loop evaluation platform for verifying LLM generated programs using sensor actuator pairs. We compare all three models with N=450 experiments and find surprisingly that GPT-4 especially shows an exceptional level of cross-domain understanding and reasoning, in some cases generating fully correct programs from a single prompt. In N=50 trials, GPT-4 produces functional I2C interfaces 66% of the time. GPT-4 also produces register-level drivers, code for LoRa communication, and context-specific power optimizations for an nRF52 program resulting in over 740x current reduction to 12.2 uA. We also characterize the models' limitations to develop a generalizable workflow for using LLMs in embedded system development. We evaluate the workflow with 15 users including novice and expert programmers. We find that our workflow improves productivity for all users and increases the success rate for building a LoRa environmental sensor from 25% to 100%, including for users with zero hardware or C/C++ experience.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经表现出杰出的代码生成能力，但它们对嵌入式系统开发，需要跨领域知识的开发仍未被研究。在这篇文章中，我们系统评估了主流LLM（GPT-3.5、GPT-4、PaLM 2）的表现，了解人工开发者与这些工具之间的互动，并开发了基于人工智能的软件工程生命周期 workflow，用于建立嵌入式系统。我们开发了一个终端硬件在Loop评估平台，用于验证LLM生成的程式码。我们对N=450实验进行比较，发现GPT-4尤其表现出跨领域理解和推理的特别高水平，有时候从单一提示中生成完全正确的程式码。在N=50试验中，GPT-4产生了66%的正常I2C接口。GPT-4还产生了对应的储存器驱动程式码、LoRa通信程式码和特定应用程序码，导致nRF52程式的电流降低至12.2 uA，实现了740倍的电流增强。我们还评估了模型的限制，以发展一个通用的工作流程，用于在嵌入式系统开发中使用LLM。我们将这个工作流程评估了15名使用者，包括初学者和高级程序员。我们发现，我们的工作流程可以帮助所有使用者提高生产力，并将将LoRa环境感应器的建立率由25%提高至100%，包括零硬件或C/C++经验的使用者。
</details></li>
</ul>
<hr>
<h2 id="For-Women-Life-Freedom-A-Participatory-AI-Based-Social-Web-Analysis-of-a-Watershed-Moment-in-Iran’s-Gender-Struggles"><a href="#For-Women-Life-Freedom-A-Participatory-AI-Based-Social-Web-Analysis-of-a-Watershed-Moment-in-Iran’s-Gender-Struggles" class="headerlink" title="For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis of a Watershed Moment in Iran’s Gender Struggles"></a>For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis of a Watershed Moment in Iran’s Gender Struggles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03764">http://arxiv.org/abs/2307.03764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adel Khorramrouz, Sujan Dutta, Ashiqur R. KhudaBukhsh</li>
<li>for: 这篇论文目的是计算推特语言对妇女平等的推动。</li>
<li>methods: 这篇论文使用了一个ensemble活动学习管道，以训练一个立场分类器。该管道中，伊朗女性参与了一个活跃的角色，不仅为标注提供标签，还提供了有价值的关键词和更具有意义的文档样本，以便更好地建立AI系统。</li>
<li>results: 分析结果显示，马哈赛妮·阿米尼的死亡引发了一些极化的推特语言讨论，增加了对妇女平等的负面和正面推文。正面推文的增加略大于负面推文的增加。此外，对于账户创建时间，与国家对齐的推特账户和oprotest推特账户之间，oprotest账户更像基线波斯语推特活动。<details>
<summary>Abstract</summary>
In this paper, we present a computational analysis of the Persian language Twitter discourse with the aim to estimate the shift in stance toward gender equality following the death of Mahsa Amini in police custody. We present an ensemble active learning pipeline to train a stance classifier. Our novelty lies in the involvement of Iranian women in an active role as annotators in building this AI system. Our annotators not only provide labels, but they also suggest valuable keywords for more meaningful corpus creation as well as provide short example documents for a guided sampling step. Our analyses indicate that Mahsa Amini's death triggered polarized Persian language discourse where both fractions of negative and positive tweets toward gender equality increased. The increase in positive tweets was slightly greater than the increase in negative tweets. We also observe that with respect to account creation time, between the state-aligned Twitter accounts and pro-protest Twitter accounts, pro-protest accounts are more similar to baseline Persian Twitter activity.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种计算机分析方法，用于分析Twitter上的波斯语言讨论，以估计在贝娅·艾米尼在警察执法中去世后，对男女平等的态度发生了哪些变化。我们提出了一个ensemble活动学习管道，用于训练一个立场分类器。我们的创新在于，伊朗女性参与了这个人工智能系统的建构过程中，不仅提供标签，还提供了有价值的关键词，以及一些导向采样步骤中的短文案例。我们的分析表明，贝娅·艾米尼的去世导致了波斯语言讨论的各种极化，正面和负面的推文数量均增加，正面推文数量略大于负面推文数量。此外，我们发现，在帐户创建时间方面，抗护护护 Twitter 帐户与支持抗议 Twitter 帐户之间，后者更加类似于基线波斯 Twitter 活动。
</details></li>
</ul>
<hr>
<h2 id="URL-A-Representation-Learning-Benchmark-for-Transferable-Uncertainty-Estimates"><a href="#URL-A-Representation-Learning-Benchmark-for-Transferable-Uncertainty-Estimates" class="headerlink" title="URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates"></a>URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03810">http://arxiv.org/abs/2307.03810</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mkirchhof/url">https://github.com/mkirchhof/url</a></li>
<li>paper_authors: Michael Kirchhof, Bálint Mucsányi, Seong Joon Oh, Enkelejda Kasneci</li>
<li>for: 本研究旨在提出一个名为“Uncertainty-aware Representation Learning”（URL）的测试库，用于评估对于不同类型的资料集进行转换的表达学习模型。</li>
<li>methods: 本研究使用了十一种不同的不确定量化方法，从ImageNet上进行预训练，然后转移到八个下游资料集上进行评估。</li>
<li>results: 研究结果显示，专注于表达本身的不确定性或直接估计预测风险的方法表现较好，但实现可转移的不确定量化仍然是一个开启的挑战。<details>
<summary>Abstract</summary>
Representation learning has significantly driven the field to develop pretrained models that can act as a valuable starting point when transferring to new datasets. With the rising demand for reliable machine learning and uncertainty quantification, there is a need for pretrained models that not only provide embeddings but also transferable uncertainty estimates. To guide the development of such models, we propose the Uncertainty-aware Representation Learning (URL) benchmark. Besides the transferability of the representations, it also measures the zero-shot transferability of the uncertainty estimate using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers that are pretrained on ImageNet and transferred to eight downstream datasets. We find that approaches that focus on the uncertainty of the representation itself or estimate the prediction risk directly outperform those that are based on the probabilities of upstream classes. Yet, achieving transferable uncertainty quantification remains an open challenge. Our findings indicate that it is not necessarily in conflict with traditional representation learning goals. Code is provided under https://github.com/mkirchhof/url .
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。</SYS>>现代化学习中，表现学习已经带来了大量的预训练模型，可以作为新数据集的起点进行转移。随着可靠机器学习和不确定量评估的需求增加，需要开发可以提供嵌入和传输不确定度估计的预训练模型。为了导引这些模型的发展，我们提出了不确定性感知学习（URL） benchmark。除了表达的传输性外，它还测量了零批量传输不确定度估计的新度量。我们使用 URL 评估了 eleven 种 ImageNet 预训练的不确定度估计器，并将它们转移到八个下游数据集。我们发现，关注表达本身的不确定度或直接估计预测风险的方法表现较好。然而，实现传输不确定度估计仍然是一个开放的挑战。我们的发现表明，这并不一定与传统表现学习目标在冲突。代码可以在 <https://github.com/mkirchhof/url> 获取。
</details></li>
</ul>
<hr>
<h2 id="CLIPMasterPrints-Fooling-Contrastive-Language-Image-Pre-training-Using-Latent-Variable-Evolution"><a href="#CLIPMasterPrints-Fooling-Contrastive-Language-Image-Pre-training-Using-Latent-Variable-Evolution" class="headerlink" title="CLIPMasterPrints: Fooling Contrastive Language-Image Pre-training Using Latent Variable Evolution"></a>CLIPMasterPrints: Fooling Contrastive Language-Image Pre-training Using Latent Variable Evolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03798">http://arxiv.org/abs/2307.03798</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matfrei/clipmasterprints">https://github.com/matfrei/clipmasterprints</a></li>
<li>paper_authors: Matthias Freiberger, Peter Kun, Anders Sundnes Løvlie, Sebastian Risi</li>
<li>for:  This paper demonstrates the vulnerability of Contrastive Language-Image Pre-training (CLIP) models to “fooling master images” that can manipulate the model’s confidence score for a wide range of prompts, while being unrecognizable to humans.</li>
<li>methods:  The authors mine fooling master images by searching the latent space of generative models using evolution strategies or stochastic gradient descent. They investigate the properties of these mined images and find that they can generalize to a large number of semantically related captions.</li>
<li>results:  The authors evaluate two possible mitigation strategies and find that the vulnerability to fooling master examples is closely related to a modality gap in contrastive pre-trained multi-modal networks. They argue for the mitigation of modality gaps in CLIP and related multi-modal approaches to improve their robustness.Here’s the full summary in Simplified Chinese:</li>
<li>for: 这个论文展示了CLIP模型对”骗主图像”的感受性，这些图像可以让CLIP模型对广泛的提示中的大量提示的确idence得分高，而人类则无法识别。</li>
<li>methods: 作者通过演化策略或批处 gradient descent 搜索生成模型的latent空间，挖掘出可以让CLIP模型对广泛的提示中的大量提示的确idence得分高的”骗主图像”。他们investigate这些挖掘出来的图像的性质，发现它们可以泛化到大量相关的提示中。</li>
<li>results: 作者评估了两种可能的防御策略，发现模态差在相对的多modal网络中对CLIP模型的感受性具有直接关系。他们因此 argues for在CLIP和相关多modal方法中减少模态差以提高其Robustness。<details>
<summary>Abstract</summary>
Models leveraging both visual and textual data such as Contrastive Language-Image Pre-training (CLIP), are increasingly gaining importance. In this work, we show that despite their versatility, such models are vulnerable to what we refer to as fooling master images. Fooling master images are capable of maximizing the confidence score of a CLIP model for a significant number of widely varying prompts, while being unrecognizable for humans. We demonstrate how fooling master images can be mined by searching the latent space of generative models by means of an evolution strategy or stochastic gradient descent. We investigate the properties of the mined fooling master images, and find that images trained on a small number of image captions potentially generalize to a much larger number of semantically related captions. Further, we evaluate two possible mitigation strategies and find that vulnerability to fooling master examples is closely related to a modality gap in contrastive pre-trained multi-modal networks. From the perspective of vulnerability to off-manifold attacks, we therefore argue for the mitigation of modality gaps in CLIP and related multi-modal approaches. Source code and mined CLIPMasterPrints are available at https://github.com/matfrei/CLIPMasterPrints.
</details>
<details>
<summary>摘要</summary>
模型结合视觉和文本数据，如对照语言图像预训练（CLIP），在当前研究中变得越来越重要。在这项工作中，我们表明，即使这些模型具有多样性，它们却容易受到我们称为“诡异主图”的攻击。诡异主图可以让CLIP模型对许多Semantic的提示具有最高的信任度，而这些图像对人类来说是不可识别的。我们通过搜索生成模型的latent空间使用演化策略或Stochastic gradient descent来挖掘诡异主图。我们研究了挖掘出来的诡异主图的性质，发现图像通过一小 número de图像描述学习可以涵盖一个许多更广泛的Semantic相关的描述。此外，我们评估了两种可能的缓解策略，发现模式差异导致的攻击性质与CLIP和相关多模态网络的易训练性相关。从攻击性角度来看，我们因此主张在CLIP和相关多模态网络中减少模式差异，以避免诡异主图的攻击。代码和挖掘出来的CLIPMasterPrints可以在https://github.com/matfrei/CLIPMasterPrints中找到。
</details></li>
</ul>
<hr>
<h2 id="When-does-the-ID-algorithm-fail"><a href="#When-does-the-ID-algorithm-fail" class="headerlink" title="When does the ID algorithm fail?"></a>When does the ID algorithm fail?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03750">http://arxiv.org/abs/2307.03750</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SOYJUN/Implement-ODR-protocol">https://github.com/SOYJUN/Implement-ODR-protocol</a></li>
<li>paper_authors: Ilya Shpitser</li>
<li>for: 本文研究了一种解决图解 causal 模型中 interventional 分布 p(Y | do(a)) 的问题，即 ID 算法。</li>
<li>methods: 本文使用了 ID 算法，并提供了一些其他形式的表述。</li>
<li>results: 本文证明了 ID 算法是有声称的（对于输入 graphical causal model 中的 p(Y | do(a)) 进行正确的函数），并且完整（如果输入不能被模型中的 p(Y | do(a)) 进行正确的函数，则会显式地标识为失败）。<details>
<summary>Abstract</summary>
The ID algorithm solves the problem of identification of interventional distributions of the form p(Y | do(a)) in graphical causal models, and has been formulated in a number of ways [12, 9, 6]. The ID algorithm is sound (outputs the correct functional of the observed data distribution whenever p(Y | do(a)) is identified in the causal model represented by the input graph), and complete (explicitly flags as a failure any input p(Y | do(a)) whenever this distribution is not identified in the causal model represented by the input graph).   The reference [9] provides a result, the so called "hedge criterion" (Corollary 3), which aims to give a graphical characterization of situations when the ID algorithm fails to identify its input in terms of a structure in the input graph called the hedge. While the ID algorithm is, indeed, a sound and complete algorithm, and the hedge structure does arise whenever the input distribution is not identified, Corollary 3 presented in [9] is incorrect as stated. In this note, I outline the modern presentation of the ID algorithm, discuss a simple counterexample to Corollary 3, and provide a number of graphical characterizations of the ID algorithm failing to identify its input distribution.
</details>
<details>
<summary>摘要</summary>
《ID算法解决了 causal 模型中 intervenational 分布的形式 p(Y | do(a)) 的问题，并已经有多种表述方式 [12, 9, 6]。ID算法是有效的（对于输入数据分布 p(Y | do(a)) 是 causal 模型中的正确函数），并且是完整的（明确地标识输入数据分布 p(Y | do(a)) 不能在 causal 模型中被识别）。参考 [9] 提供了一个名为 "防茂 критерион"（悬峰3）的结果，它目的是给出一种图解方式，用于描述 ID 算法输入分布不能被识别的情况。然而，ID 算法确实是一个有效和完整的算法，而且防茂结构在输入分布不能被识别时会出现。在本文中，我将详细介绍 ID 算法的现代表述方法，提供一个简单的反例，以及一些图解方式，用于描述 ID 算法输入分布不能被识别的情况。
</details></li>
</ul>
<hr>
<h2 id="AI-and-the-EU-Digital-Markets-Act-Addressing-the-Risks-of-Bigness-in-Generative-AI"><a href="#AI-and-the-EU-Digital-Markets-Act-Addressing-the-Risks-of-Bigness-in-Generative-AI" class="headerlink" title="AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI"></a>AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02033">http://arxiv.org/abs/2308.02033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayse Gizem Yasar, Andrew Chong, Evan Dong, Thomas Krendl Gilbert, Sarah Hladikova, Roland Maio, Carlos Mougan, Xudong Shen, Shubham Singh, Ana-Andreea Stoica, Savannah Thais, Miri Zilka</li>
<li>for: 本研究旨在逐doFiltering the risks of bigness in digital markets, particularly in relation to generative AI systems.</li>
<li>methods: 作者提议 integrate certain AI software as core platform services,并 классифици certain developers as gatekeepers under the EU’s Digital Markets Act (DMA).</li>
<li>results: 本研究提出了一种评估 gatekeeper obligations的方法，以确保它们覆盖 generative AI services。这些结果可以帮助欧盟在考虑 generative AI 特定规则和可能的 DMA 修订时，更好地保持多样性和开放性在 generative AI 服务中。<details>
<summary>Abstract</summary>
As AI technology advances rapidly, concerns over the risks of bigness in digital markets are also growing. The EU's Digital Markets Act (DMA) aims to address these risks. Still, the current framework may not adequately cover generative AI systems that could become gateways for AI-based services. This paper argues for integrating certain AI software as core platform services and classifying certain developers as gatekeepers under the DMA. We also propose an assessment of gatekeeper obligations to ensure they cover generative AI services. As the EU considers generative AI-specific rules and possible DMA amendments, this paper provides insights towards diversity and openness in generative AI services.
</details>
<details>
<summary>摘要</summary>
随着人工智能技术的快速发展，大型数字市场的风险问题也在不断增长。欧盟的数字市场法（DMA）想要解决这些问题。然而，现有的框架可能不够覆盖生成AI系统，这些系统可能会成为AI服务的门户。这篇文章提议将某些AI软件作为核心平台服务 интегра进DMA，并将某些开发者 классифици为DMA中的“门槛keeper”。我们还提议对门槛keeper的义务进行评估，以确保它们覆盖生成AI服务。随着欧盟考虑生成AI特有的规则和可能的DMA修改，这篇文章提供了关于多样性和开放性在生成AI服务方面的洞察。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-Robotic-Sonographer-Mutual-Information-based-Disentangled-Reward-Learning-from-Few-Demonstrations"><a href="#Intelligent-Robotic-Sonographer-Mutual-Information-based-Disentangled-Reward-Learning-from-Few-Demonstrations" class="headerlink" title="Intelligent Robotic Sonographer: Mutual Information-based Disentangled Reward Learning from Few Demonstrations"></a>Intelligent Robotic Sonographer: Mutual Information-based Disentangled Reward Learning from Few Demonstrations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03705">http://arxiv.org/abs/2307.03705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongliang Jiang, Yuan Bi, Mingchuan Zhou, Ying Hu, Michael Burke, Nassir Navab<br>for:The paper proposes an intelligent robotic sonographer to autonomously explore target anatomies and navigate a US probe to a relevant 2D plane by learning from expert.methods:The proposed approach uses a neural reward function, ranked pairwise image comparisons, and mutual information to learn the “language of sonography” and overcome inter-patient variations. A Gaussian distribution-based filter is also developed to evaluate the quality of the expert’s demonstrations.results:The proposed approach is demonstrated to be effective in different experiments, including representative experiments for the “line” target and “point” target on vascular phantom and two ex-vivo animal organ phantoms, respectively. The results showed that the proposed advanced framework can robustly work on different kinds of known and unseen phantoms.<details>
<summary>Abstract</summary>
Ultrasound (US) imaging is widely used for biometric measurement and diagnosis of internal organs due to the advantages of being real-time and radiation-free. However, due to high inter-operator variability, resulting images highly depend on operators' experience. In this work, an intelligent robotic sonographer is proposed to autonomously "explore" target anatomies and navigate a US probe to a relevant 2D plane by learning from expert. The underlying high-level physiological knowledge from experts is inferred by a neural reward function, using a ranked pairwise image comparisons approach in a self-supervised fashion. This process can be referred to as understanding the "language of sonography". Considering the generalization capability to overcome inter-patient variations, mutual information is estimated by a network to explicitly extract the task-related and domain features in latent space. Besides, a Gaussian distribution-based filter is developed to automatically evaluate and take the quality of the expert's demonstrations into account. The robotic localization is carried out in coarse-to-fine mode based on the predicted reward associated to B-mode images. To demonstrate the performance of the proposed approach, representative experiments for the "line" target and "point" target are performed on vascular phantom and two ex-vivo animal organ phantoms (chicken heart and lamb kidney), respectively. The results demonstrated that the proposed advanced framework can robustly work on different kinds of known and unseen phantoms.
</details>
<details>
<summary>摘要</summary>
超声成像（US）成为内部器官诊断和生物米特ри评估的广泛应用，主要原因是它具有实时和无核燐灰的优点。然而，由于操作员之间的高度变化，导致图像具有操作员的经验效应。在这项工作中，一个智能机器人超声测试员被提议，以自主地"探索"目标解剖结构，并使用学习从专家得到的高级生理知识来导航US prob。这种过程可以称为"医学超声语言"的理解。另外，为了强化图像的泛化能力，一个基于Gaussian分布的筛选器被开发，以自动评估专家的示范质量。机器人本地化采用了从预测的奖励关系来进行粗略到细粒的模式，以实现对B模式图像的预测。为证明提出的方法的性能，对不同类型的知名和未知荟袋（vascular phantom和两只酪肉动物器官荟袋）进行了代表性的实验。结果表明，提出的高级框架可以在不同类型的荟袋上具有robust性。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-Potential-of-Knowledge-Prompted-ChatGPT-for-Enhancing-Drug-Trafficking-Detection-on-Social-Media"><a href="#Unveiling-the-Potential-of-Knowledge-Prompted-ChatGPT-for-Enhancing-Drug-Trafficking-Detection-on-Social-Media" class="headerlink" title="Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media"></a>Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03699">http://arxiv.org/abs/2307.03699</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuanbo Hu, Bin Liu, Xin Li, Yanfang Ye<br>for:The paper aims to detect illicit drug trafficking activities on social media, specifically on platforms like Instagram and Twitter.methods:The authors use large language models (LLMs), such as ChatGPT, to detect drug trafficking activities. They propose an analytical framework that incorporates prior knowledge and scenario-based prompts to improve the accuracy of drug trafficking detection.results:The proposed framework outperforms other baseline language models in terms of drug trafficking detection accuracy, with a remarkable improvement of nearly 12%. The use of prior knowledge and scenario-based prompts helps ChatGPT effectively identify and label drug trafficking activities, even in the presence of deceptive language and euphemisms used by drug dealers to evade detection.<details>
<summary>Abstract</summary>
Social media platforms such as Instagram and Twitter have emerged as critical channels for drug marketing and illegal sale. Detecting and labeling online illicit drug trafficking activities becomes important in addressing this issue. However, the effectiveness of conventional supervised learning methods in detecting drug trafficking heavily relies on having access to substantial amounts of labeled data, while data annotation is time-consuming and resource-intensive. Furthermore, these models often face challenges in accurately identifying trafficking activities when drug dealers use deceptive language and euphemisms to avoid detection. To overcome this limitation, we conduct the first systematic study on leveraging large language models (LLMs), such as ChatGPT, to detect illicit drug trafficking activities on social media. We propose an analytical framework to compose \emph{knowledge-informed prompts}, which serve as the interface that humans can interact with and use LLMs to perform the detection task. Additionally, we design a Monte Carlo dropout based prompt optimization method to further to improve performance and interpretability. Our experimental findings demonstrate that the proposed framework outperforms other baseline language models in terms of drug trafficking detection accuracy, showing a remarkable improvement of nearly 12\%. By integrating prior knowledge and the proposed prompts, ChatGPT can effectively identify and label drug trafficking activities on social networks, even in the presence of deceptive language and euphemisms used by drug dealers to evade detection. The implications of our research extend to social networks, emphasizing the importance of incorporating prior knowledge and scenario-based prompts into analytical tools to improve online security and public safety.
</details>
<details>
<summary>摘要</summary>
社交媒体平台如Instagram和Twitter已成为药品市场和非法销售的重要渠道。检测和标注在线贩卖药品活动变得非常重要，以解决这个问题。然而，传统的监督学习方法在检测贩卖药品上凭借具有较大量的标注数据进行检测是不可靠的，而且这些模型经常遇到识别贩卖药品活动时，贩卖者使用欺骗语言和推荐词来避免检测的问题。为了解决这些限制，我们进行了第一次系统性的研究，利用大型自然语言模型（LLM），如ChatGPT，检测社交媒体上的贩卖药品活动。我们提出了一个分析框架，将知识告诉作为界面，让人们通过LLM进行检测任务。此外，我们还设计了基于Monte Carlo Dropout的提示优化方法，以提高性能和可解释性。我们的实验结果表明，我们的框架在贩卖药品检测精度方面比基eline语言模型提高了12%以上。通过将知识和我们提出的提示结合使用，ChatGPT可以在社交网络上有效地识别和标注贩卖药品活动，即使贩卖者使用欺骗语言和推荐词来避免检测。我们的研究结果对社交网络产生重要的扩展，强调在线安全和公共安全中包含知识和场景基于的分析工具的重要性。
</details></li>
</ul>
<hr>
<h2 id="Scalable-Membership-Inference-Attacks-via-Quantile-Regression"><a href="#Scalable-Membership-Inference-Attacks-via-Quantile-Regression" class="headerlink" title="Scalable Membership Inference Attacks via Quantile Regression"></a>Scalable Membership Inference Attacks via Quantile Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03694">http://arxiv.org/abs/2307.03694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu</li>
<li>for: 本研究旨在攻击用黑盒训练的模型，以确定特定示例是否被用于训练。</li>
<li>methods: 本研究使用量化回归来攻击模型，并不需要知道模型的结构。</li>
<li>results: 实验结果表明，本方法可以与现有最佳攻击方法竞争，而且需要训练只一个模型，相比之前的攻击方法需要训练多个模型。<details>
<summary>Abstract</summary>
Membership inference attacks are designed to determine, using black box access to trained models, whether a particular example was used in training or not. Membership inference can be formalized as a hypothesis testing problem. The most effective existing attacks estimate the distribution of some test statistic (usually the model's confidence on the true label) on points that were (and were not) used in training by training many \emph{shadow models} -- i.e. models of the same architecture as the model being attacked, trained on a random subsample of data. While effective, these attacks are extremely computationally expensive, especially when the model under attack is large.   We introduce a new class of attacks based on performing quantile regression on the distribution of confidence scores induced by the model under attack on points that are not used in training. We show that our method is competitive with state-of-the-art shadow model attacks, while requiring substantially less compute because our attack requires training only a single model. Moreover, unlike shadow model attacks, our proposed attack does not require any knowledge of the architecture of the model under attack and is therefore truly ``black-box". We show the efficacy of this approach in an extensive series of experiments on various datasets and model architectures.
</details>
<details>
<summary>摘要</summary>
成员推测攻击是设计用黑盒访问训练过的模型来确定特定示例是否在训练中使用过。成员推测可以形式化为一个假设测试问题。现有最有效的攻击方法是估计模型在真实标签上的信任度分布中的某些测试统计（通常是模型对真实标签的信任度）。这些攻击通常是非常计算昂贵的，特别是当模型被攻击时非常大。我们介绍了一种新的攻击方法，基于模型下攻击的信任度分布中的confidence分布进行量化回归。我们显示了我们的方法与现有的阴影模型攻击相当竞争力，而需要更少的计算资源，因为我们的攻击只需要训练一个模型。此外，我们的提议的攻击方法不需要知道模型下攻击的结构，因此是真正的“黑盒”攻击。我们在不同的 dataset 和模型结构上进行了广泛的实验，以证明这种方法的可行性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/08/cs.AI_2023_07_08/" data-id="clpahu6xc000d3h888xqd748j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/08/cs.CL_2023_07_08/" class="article-date">
  <time datetime="2023-07-08T11:00:00.000Z" itemprop="datePublished">2023-07-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/08/cs.CL_2023_07_08/">cs.CL - 2023-07-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Advancements-in-Scientific-Controllable-Text-Generation-Methods"><a href="#Advancements-in-Scientific-Controllable-Text-Generation-Methods" class="headerlink" title="Advancements in Scientific Controllable Text Generation Methods"></a>Advancements in Scientific Controllable Text Generation Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05538">http://arxiv.org/abs/2307.05538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arnav Goel, Medha Hira, Avinash Anand, Siddhesh Bangar, Dr. Rajiv Ratn Shah</li>
<li>for: 本研究旨在开发一种可控文本生成技术，用于科学文献中的自动生成。</li>
<li>methods: 该研究使用了七个组件，包括语料库、模型、排序策略、干扰方法、随机化方法、权重补做和拟合策略。这些组件之间可以进行组合，以实现不同的控制效果。</li>
<li>results: 本研究通过理论分析和质量评估来描述这些方法的工作原理和优劣点，并提供了可能的新architecture。未来的实验研究将比较这些方法的效果，以了解它们在不同情况下的优劣点。<details>
<summary>Abstract</summary>
The previous work on controllable text generation is organized using a new schema we provide in this study. Seven components make up the schema, and each one is crucial to the creation process. To accomplish controlled generation for scientific literature, we describe the various modulation strategies utilised to modulate each of the seven components. We also offer a theoretical study and qualitative examination of these methods. This insight makes possible new architectures based on combinations of these components. Future research will compare these methods empirically to learn more about their strengths and utility.
</details>
<details>
<summary>摘要</summary>
先前的文本控制生成研究由我们提供的新架构组织。这个架构包括7个组件，每个组件都是生成过程中不可或缺的。为了实现科学文献控制生成，我们介绍了对每个组件进行调整的各种调制策略。我们还提供了这些方法的理论研究和质量分析。这些洞察可能导致基于这些组件的新架构的开发。未来的研究将通过实验比较这些方法的优势和实用性。
</details></li>
</ul>
<hr>
<h2 id="A-Stitch-in-Time-Saves-Nine-Detecting-and-Mitigating-Hallucinations-of-LLMs-by-Validating-Low-Confidence-Generation"><a href="#A-Stitch-in-Time-Saves-Nine-Detecting-and-Mitigating-Hallucinations-of-LLMs-by-Validating-Low-Confidence-Generation" class="headerlink" title="A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation"></a>A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03987">http://arxiv.org/abs/2307.03987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neeraj Varshney, Wenlin Yao, Hongming Zhang, Jianshu Chen, Dong Yu</li>
<li>for: 这个论文的目的是提高大型自然语言处理器的可靠性和可信度。</li>
<li>methods: 这篇论文提出了一种活动检测和纠正方法，以解决大型自然语言处理器中的“幻见”问题。这种方法包括在生成过程中首先标识有可能存在幻见的语句，然后通过验证程序确认其正确性，并最后纠正已确检测到的幻见。</li>
<li>results: 经过广泛的实验表明，提出的检测和纠正方法可以成功地降低GPT-3.5模型中的幻见率，从47.5%降低到14.5%的平均值。此外，这种方法还可以在不同类型的问题上进行有效地应用，包括多步问题和False Premise问题。<details>
<summary>Abstract</summary>
Recently developed large language models have achieved remarkable success in generating fluent and coherent text. However, these models often tend to 'hallucinate' which critically hampers their reliability. In this work, we address this crucial problem and propose an approach that actively detects and mitigates hallucinations during the generation process. Specifically, we first identify the candidates of potential hallucination leveraging the model's logit output values, check their correctness through a validation procedure, mitigate the detected hallucinations, and then continue with the generation process. Through extensive experiments with GPT-3.5 (text-davinci-003) on the 'article generation task', we first demonstrate the individual efficacy of our detection and mitigation techniques. Specifically, the detection technique achieves a recall of ~88% and the mitigation technique successfully mitigates 57.6% of the correctly detected hallucinations. Importantly, our mitigation technique does not introduce new hallucinations even in the case of incorrectly detected hallucinations, i.e., false positives. Then, we show that the proposed active detection and mitigation approach successfully reduces the hallucinations of the GPT-3.5 model from 47.5% to 14.5% on average. We further demonstrate the effectiveness and wide applicability of our approach through additional studies including performance on different types of questions (multi-hop and false premise questions) and with another LLM from a different model family (Vicuna). In summary, our work contributes to improving the reliability and trustworthiness of large language models, a crucial step en route to enabling their widespread adoption in real-world applications.
</details>
<details>
<summary>摘要</summary>
现在已经开发出的大型语言模型已经达到了非常出色的成绩，可以生成流畅、一致的文本。然而，这些模型经常会“幻觉”，这会严重降低其可靠性。在这个工作中，我们解决这个重要的问题，我们提出了一种活动检测和纠正幻觉的方法。具体来说，我们首先通过模型的极值输出值来认为潜在的幻觉者，然后通过验证过程来确认其正确性，并在检测到的幻觉被纠正后继续进行生成过程。通过对GPT-3.5（文本达文奇003）进行了广泛的实验，我们证明了我们的检测和纠正技术的个人效果。 Specifically, our detection technique achieves a recall of approximately 88%, and the mitigation technique successfully mitigates 57.6% of the correctly detected hallucinations. Furthermore, our mitigation technique does not introduce new hallucinations even in the case of incorrectly detected hallucinations, i.e., false positives. Finally, we show that our active detection and mitigation approach successfully reduces the hallucinations of the GPT-3.5 model from 47.5% to 14.5% on average. We also demonstrate the effectiveness and wide applicability of our approach through additional studies including performance on different types of questions (multi-hop and false premise questions) and with another LLM from a different model family (Vicuna). In summary, our work contributes to improving the reliability and trustworthiness of large language models, a crucial step en route to enabling their widespread adoption in real-world applications.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Capability-of-Large-scale-Language-Models-on-Chinese-Grammatical-Error-Correction-Task"><a href="#Evaluating-the-Capability-of-Large-scale-Language-Models-on-Chinese-Grammatical-Error-Correction-Task" class="headerlink" title="Evaluating the Capability of Large-scale Language Models on Chinese Grammatical Error Correction Task"></a>Evaluating the Capability of Large-scale Language Models on Chinese Grammatical Error Correction Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03972">http://arxiv.org/abs/2307.03972</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fanyi Qu, Yunfang Wu</li>
<li>for: 这份报告旨在探讨大型自然语言处理（NLP）任务中大型语言模型（LLM）的性能，以及未来工作的指导。</li>
<li>methods: 我们在4个中文grammatical error correction（GEC）数据集上进行了3种不同的LLM模型的实验。</li>
<li>results: 我们发现LLMs在自动评估指标上的性能不足前一代模型，并且存在过 corrections 的问题。此外，我们还发现了不同数据分布下LLMs的性能有很大差异。这些发现表明需要进一步调查LLMs在中文GEC任务中的应用。<details>
<summary>Abstract</summary>
Large-scale language models (LLMs) has shown remarkable capability in various of Natural Language Processing (NLP) tasks and attracted lots of attention recently. However, some studies indicated that large language models fail to achieve promising result beyond the state-of-the-art models in English grammatical error correction (GEC) tasks. In this report, we aim to explore the how large language models perform on Chinese grammatical error correction tasks and provide guidance for future work. We conduct experiments with 3 different LLMs of different model scale on 4 Chinese GEC dataset. Our experimental results indicate that the performances of LLMs on automatic evaluation metrics falls short of the previous sota models because of the problem of over-correction. Furthermore, we also discover notable variations in the performance of LLMs when evaluated on different data distributions. Our findings demonstrates that further investigation is required for the application of LLMs on Chinese GEC task.
</details>
<details>
<summary>摘要</summary>
大规模语言模型（LLM）在自然语言处理（NLP）任务中表现出色，引起了广泛的关注。然而，一些研究表明，大型语言模型在英语grammatical error correction（GEC）任务中未能达到前景模型的成绩。在这份报告中，我们想要探究大型语言模型在中文GEC任务中的表现，并提供未来工作的指导。我们在4个中文GEC数据集上进行了3种不同的LLM模型的实验。我们的实验结果表明，LLM的自动评估指标的表现不足，主要是因为过度修复的问题。此外，我们还发现了不同数据分布下LLM的表现异常大的现象。我们的发现表明，未来应该进一步调查大型语言模型在中文GEC任务中的应用。
</details></li>
</ul>
<hr>
<h2 id="Is-ChatGPT-a-Good-Personality-Recognizer-A-Preliminary-Study"><a href="#Is-ChatGPT-a-Good-Personality-Recognizer-A-Preliminary-Study" class="headerlink" title="Is ChatGPT a Good Personality Recognizer? A Preliminary Study"></a>Is ChatGPT a Good Personality Recognizer? A Preliminary Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03952">http://arxiv.org/abs/2307.03952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Ji, Wen Wu, Hong Zheng, Yi Hu, Xi Chen, Liang He<br>for:这个研究的目的是评估 chatGPT 在文本基础人格识别任务中的能力，以生成有效的人格数据。methods:本研究使用了多种提示策略，包括自然语言生成和逻辑推理，以测试 chatGPT 在文本分析和推理方面的能力。results:实验结果显示，使用 zero-shot chain-of-thought 提示策略可以帮助 chatGPT 在文本基础人格识别任务中表现出色，并且能够提供自然语言的解释。此外，通过对 chatGPT 进行水平调整的提示策略，可以将其与相应的现有模型之间的性能差距更加缩小。但是，研究发现 chatGPT 对某些敏感特征（如性别和年龄）存在不公正现象。同时，通过询问 chatGPT 的人格识别能力，可以提高它在相关下游任务中的表现，如情感分类和压力预测。<details>
<summary>Abstract</summary>
In recent years, personality has been regarded as a valuable personal factor being incorporated into numerous tasks such as sentiment analysis and product recommendation. This has led to widespread attention to text-based personality recognition task, which aims to identify an individual's personality based on given text. Considering that ChatGPT has recently exhibited remarkable abilities on various natural language processing tasks, we provide a preliminary evaluation of ChatGPT on text-based personality recognition task for generating effective personality data. Concretely, we employ a variety of prompting strategies to explore ChatGPT's ability in recognizing personality from given text, especially the level-oriented prompting strategy we designed for guiding ChatGPT in analyzing given text at a specified level. The experimental results on two representative real-world datasets reveal that ChatGPT with zero-shot chain-of-thought prompting exhibits impressive personality recognition ability and is capable to provide natural language explanations through text-based logical reasoning. Furthermore, by employing the level-oriented prompting strategy to optimize zero-shot chain-of-thought prompting, the performance gap between ChatGPT and corresponding state-of-the-art model has been narrowed even more. However, we observe that ChatGPT shows unfairness towards certain sensitive demographic attributes such as gender and age. Additionally, we discover that eliciting the personality recognition ability of ChatGPT helps improve its performance on personality-related downstream tasks such as sentiment classification and stress prediction.
</details>
<details>
<summary>摘要</summary>
Recently, personality has been recognized as a valuable personal factor in various tasks such as sentiment analysis and product recommendation. This has led to widespread attention to text-based personality recognition tasks, which aim to identify an individual's personality based on given text. Considering ChatGPT's recent remarkable abilities in natural language processing tasks, we provide a preliminary evaluation of ChatGPT on text-based personality recognition tasks to generate effective personality data.To explore ChatGPT's ability in recognizing personality from given text, we employ various prompting strategies. Specifically, we use a level-oriented prompting strategy designed to guide ChatGPT in analyzing given text at a specified level. The experimental results on two representative real-world datasets show that ChatGPT with zero-shot chain-of-thought prompting exhibits impressive personality recognition ability and can provide natural language explanations through text-based logical reasoning. Furthermore, by optimizing zero-shot chain-of-thought prompting with the level-oriented prompting strategy, the performance gap between ChatGPT and corresponding state-of-the-art models has been narrowed even more.However, we observe that ChatGPT shows unfairness towards certain sensitive demographic attributes such as gender and age. Additionally, we find that eliciting the personality recognition ability of ChatGPT can improve its performance on personality-related downstream tasks such as sentiment classification and stress prediction.
</details></li>
</ul>
<hr>
<h2 id="Opening-up-ChatGPT-Tracking-openness-transparency-and-accountability-in-instruction-tuned-text-generators"><a href="#Opening-up-ChatGPT-Tracking-openness-transparency-and-accountability-in-instruction-tuned-text-generators" class="headerlink" title="Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators"></a>Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05532">http://arxiv.org/abs/2307.05532</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io">https://github.com/opening-up-chatgpt/opening-up-chatgpt.github.io</a></li>
<li>paper_authors: Andreas Liesenfeld, Alianda Lopez, Mark Dingemanse</li>
<li>for: 本研究旨在探讨大语言模型在对话界面中的使用，以及这种使用的风险和机遇。</li>
<li>methods: 本研究使用了开源项目的比较性能，并对这些项目进行了评估，以探讨这些项目的开放性和可读性。</li>
<li>results: 研究发现，许多自称为“开源”的项目仍然存在不明文法律性的数据问题，并且少数项目分享人工调教数据，导致 scientific documentation 非常罕见。<details>
<summary>Abstract</summary>
Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI's ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as 'open source', many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.
</details>
<details>
<summary>摘要</summary>
大型语言模型 exhibiting instruction-following behavior 是最近一大革命的 conversational interfaces 的趋势，这趋势受到 OpenAI 的 ChatGPT 的发布以及人类反馈驱动的 reinforcement learning 的激发。我们评估了依赖于专有软件的风险，并检查了相同架构和功能的开源项目的第一批。本文的主要贡献是显示开源是 differentiated，并提供了这个快速发展的领域中科学文献的记录。我们将项目评估为开源代码、训练数据、模型权重、RLHF 数据、许可证、科学文献和访问方法等方面的开放程度进行评估。我们发现许多自称为 'open source' 的项目继承了未经Documented的数据，少数分享了关键的指令调整（一个关键的人工注释劳动 Site），并且精心的科学文献记录是非常罕见。度量开放程度对公平和负责任是非常重要，从数据收集和整理到模型架构、训练和细化到发布和部署都是如此。
</details></li>
</ul>
<hr>
<h2 id="On-decoder-only-architecture-for-speech-to-text-and-large-language-model-integration"><a href="#On-decoder-only-architecture-for-speech-to-text-and-large-language-model-integration" class="headerlink" title="On decoder-only architecture for speech-to-text and large language model integration"></a>On decoder-only architecture for speech-to-text and large language model integration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03917">http://arxiv.org/abs/2307.03917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Wu, Yashesh Gaur, Zhuo Chen, Long Zhou, Yimeng Zhu, Tianrui Wang, Jinyu Li, Shujie Liu, Bo Ren, Linquan Liu, Yu Wu</li>
<li>For: 这种研究旨在探索将语音信号细目Integrated into文本大语言模型中，以提高人机交互的自然语言处理能力。* Methods: 该方法使用Connectionist Temporal Classification和一个简单的音频编码器将压缩语音特征映射到文本大语言模型中的连续 semantic space。* Results: 实验结果表明，使用这种方法可以在多语言speech-to-text翻译任务中实现显著的提升，这 highlights the potential advantages of decoder-only models for speech-to-text conversion。<details>
<summary>Abstract</summary>
Large language models (LLMs) have achieved remarkable success in the field of natural language processing, enabling better human-computer interaction using natural language. However, the seamless integration of speech signals into LLMs has not been explored well. The "decoder-only" architecture has also not been well studied for speech processing tasks. In this research, we introduce Speech-LLaMA, a novel approach that effectively incorporates acoustic information into text-based large language models. Our method leverages Connectionist Temporal Classification and a simple audio encoder to map the compressed acoustic features to the continuous semantic space of the LLM. In addition, we further probe the decoder-only architecture for speech-to-text tasks by training a smaller scale randomly initialized speech-LLaMA model from speech-text paired data alone. We conduct experiments on multilingual speech-to-text translation tasks and demonstrate a significant improvement over strong baselines, highlighting the potential advantages of decoder-only models for speech-to-text conversion.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理模型（LLM）已经在人工智能领域取得了很大的成功，使得人机交互使用自然语言更加简单。然而，将语音信号集成到LLM中还没有得到了充分的探索。“解码器只”架构也尚未得到了充分的研究。在这项研究中，我们介绍了一种新的方法，即将语音信号集成到文本基于大语言模型中。我们的方法利用了Connectionist Temporal Classification和一个简单的音频编码器，将压缩的语音特征映射到文本基于大语言模型的连续 semantics 空间中。此外，我们还进一步探索了基于 speech-to-text 任务的 decoder-only 架构，通过从 speech-text 对应数据 alone  initialize 一个较小规模的随机 initialize 的 speech-LLaMA 模型进行训练。我们在多语言 speech-to-text 翻译任务上进行了实验，并表明了 decoder-only 模型在 speech-to-text 转换中的潜在优势。
</details></li>
</ul>
<hr>
<h2 id="Answering-Ambiguous-Questions-via-Iterative-Prompting"><a href="#Answering-Ambiguous-Questions-via-Iterative-Prompting" class="headerlink" title="Answering Ambiguous Questions via Iterative Prompting"></a>Answering Ambiguous Questions via Iterative Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03897">http://arxiv.org/abs/2307.03897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sunnweiwei/ambigprompt">https://github.com/sunnweiwei/ambigprompt</a></li>
<li>paper_authors: Weiwei Sun, Hengyi Cai, Hongshen Chen, Pengjie Ren, Zhumin Chen, Maarten de Rijke, Zhaochun Ren</li>
<li>for:  answering ambiguous questions</li>
<li>methods:  integrates an answering model with a prompting model in an iterative manner, with task-specific post-pretraining approach</li>
<li>results: achieves state-of-the-art or competitive results while using less memory and having a lower inference latency than competing approaches, performs well in low-resource settings<details>
<summary>Abstract</summary>
In open-domain question answering, due to the ambiguity of questions, multiple plausible answers may exist. To provide feasible answers to an ambiguous question, one approach is to directly predict all valid answers, but this can struggle with balancing relevance and diversity. An alternative is to gather candidate answers and aggregate them, but this method can be computationally costly and may neglect dependencies among answers. In this paper, we present AmbigPrompt to address the imperfections of existing approaches to answering ambiguous questions. Specifically, we integrate an answering model with a prompting model in an iterative manner. The prompting model adaptively tracks the reading process and progressively triggers the answering model to compose distinct and relevant answers. Additionally, we develop a task-specific post-pretraining approach for both the answering model and the prompting model, which greatly improves the performance of our framework. Empirical studies on two commonly-used open benchmarks show that AmbigPrompt achieves state-of-the-art or competitive results while using less memory and having a lower inference latency than competing approaches. Additionally, AmbigPrompt also performs well in low-resource settings. The code are available at: https://github.com/sunnweiwei/AmbigPrompt.
</details>
<details>
<summary>摘要</summary>
在开放领域问答中，由于问题的抽象性，可能存在多个有可能的答案。为提供有可能性的答案，一种方法是直接预测所有有效答案，但这可能会困难平衡相关性和多样性。另一种方法是收集候选答案并聚合它们，但这可能会很计算昂贵并可能忽视答案之间的依赖关系。在本文中，我们提出了 AmbigPrompt，以解决现有问答系统中的缺陷。具体来说，我们将答题模型与提示模型集成在迭代方式下，以便在不同的读者过程中适应地触发答题模型，并生成具有不同特征和相关性的答案。此外，我们还开发了特定任务的预训练方法，用于提高我们的框架的性能。经验研究表明，AmbigPrompt在两个常用的开放benchmark上实现了状态当前或竞争性的结果，同时使用的内存和执行时间比竞争方法更低。此外，AmbigPrompt还在低资源环境下表现良好。代码可以在以下链接中找到：https://github.com/sunnweiwei/AmbigPrompt。
</details></li>
</ul>
<hr>
<h2 id="Incomplete-Utterance-Rewriting-as-Sequential-Greedy-Tagging"><a href="#Incomplete-Utterance-Rewriting-as-Sequential-Greedy-Tagging" class="headerlink" title="Incomplete Utterance Rewriting as Sequential Greedy Tagging"></a>Incomplete Utterance Rewriting as Sequential Greedy Tagging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.06337">http://arxiv.org/abs/2307.06337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunshan Chen</li>
<li>for: 实现对句子中欠缺的词汇进行补充。</li>
<li>methods: 提出了一种基于序列标记的模型，能够从对话 контек斯中提取信息。同时，引入了speaker-aware嵌入，以处理 speaker 的变化。</li>
<li>results: 在多个公共数据集上实验，模型在九个重建得分中均 achievable 最佳结果，而其他 метриック分数与之前的州流量模型相似。此外，由于模型的简单性，我们的方法在推断速度上表现出优于大多数先前的模型。<details>
<summary>Abstract</summary>
The task of incomplete utterance rewriting has recently gotten much attention. Previous models struggled to extract information from the dialogue context, as evidenced by the low restoration scores. To address this issue, we propose a novel sequence tagging-based model, which is more adept at extracting information from context. Meanwhile, we introduce speaker-aware embedding to model speaker variation. Experiments on multiple public datasets show that our model achieves optimal results on all nine restoration scores while having other metric scores comparable to previous state-of-the-art models. Furthermore, benefitting from the model's simplicity, our approach outperforms most previous models on inference speed.
</details>
<details>
<summary>摘要</summary>
近期，句子重构任务受到了广泛关注。先前的模型在对话上提取信息方面存在问题，这可以从低的重建得分来看出来。为解决这问题，我们提议一种基于序列标记的新模型，它更好地从对话上提取信息。同时，我们引入了说话人变化的嵌入，以模型说话人的变化。在多个公共数据集上进行实验，我们发现我们的模型在所有九个重建得分上具有优化的结果，而其他维度得分与先前状态艺模型相似。此外，由于我们的模型简单，我们的方法在推理速度方面超过了大多数先前模型。
</details></li>
</ul>
<hr>
<h2 id="Embedding-Mental-Health-Discourse-for-Community-Recommendation"><a href="#Embedding-Mental-Health-Discourse-for-Community-Recommendation" class="headerlink" title="Embedding Mental Health Discourse for Community Recommendation"></a>Embedding Mental Health Discourse for Community Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03892">http://arxiv.org/abs/2307.03892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hy Dang, Bang Nguyen, Noah Ziems, Meng Jiang</li>
<li>for:  investigate the use of discourse embedding techniques to develop a community recommendation system for mental health support groups on social media</li>
<li>methods:  use content-based and collaborative filtering techniques to enhance the performance of the recommendation system</li>
<li>results:  the proposed approach outperforms the use of each technique separately and provides interpretability in the recommendation process.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究探讨了基于话语嵌入技术的社交媒体群体推荐系统，帮助用户在社交媒体平台上找到适合自己精神健康问题的群体。</li>
<li>methods: 我们使用了内容基于和合作筛选技术来提高推荐系统的性能，以提供更加有效和可解释的推荐结果。</li>
<li>results: 我们的研究结果表明，提pose的方法在单独使用每种技术时都表现出优异，并且具有更高的可解释性。<details>
<summary>Abstract</summary>
Our paper investigates the use of discourse embedding techniques to develop a community recommendation system that focuses on mental health support groups on social media. Social media platforms provide a means for users to anonymously connect with communities that cater to their specific interests. However, with the vast number of online communities available, users may face difficulties in identifying relevant groups to address their mental health concerns. To address this challenge, we explore the integration of discourse information from various subreddit communities using embedding techniques to develop an effective recommendation system. Our approach involves the use of content-based and collaborative filtering techniques to enhance the performance of the recommendation system. Our findings indicate that the proposed approach outperforms the use of each technique separately and provides interpretability in the recommendation process.
</details>
<details>
<summary>摘要</summary>
我们的论文研究了利用话语嵌入技术开发一个关注社交媒体上心理健康支持群体的社区推荐系统。社交媒体平台提供了用户匿名连接到专门针对他们的兴趣的社区的机制。然而，由于在线社区的数量繁多，用户可能面临着找到与他们心理健康问题相关的群体的挑战。为解决这个问题，我们研究了将话语信息从不同的 subreddit 社区嵌入技术的集成，以开发一个高效的推荐系统。我们的方法包括使用内容基本和合作筛选技术来提高推荐系统的性能。我们的发现表明，我们的提议方法比使用每一种技术分别提供更高的性能和可解释性。
</details></li>
</ul>
<hr>
<h2 id="MDACE-MIMIC-Documents-Annotated-with-Code-Evidence"><a href="#MDACE-MIMIC-Documents-Annotated-with-Code-Evidence" class="headerlink" title="MDACE: MIMIC Documents Annotated with Code Evidence"></a>MDACE: MIMIC Documents Annotated with Code Evidence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03859">http://arxiv.org/abs/2307.03859</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/3mcloud/MDACE">https://github.com/3mcloud/MDACE</a></li>
<li>paper_authors: Hua Cheng, Rana Jafari, April Russell, Russell Klopfer, Edmond Lu, Benjamin Striner, Matthew R. Gormley</li>
<li>for: 这个论文是为了提出一个基于医疗记录的代码证据集，以便用于评估医疗代码检索系统中的代码证据提取方法。</li>
<li>methods: 这个论文使用了EffectiveCAN模型（Liu et al., 2021）来实现代码证据提取方法的基准性能。</li>
<li>results: 这个论文 introduce了第一个公共可用的代码证据集（MDACE），该集基于MIMIC-III医疗记录子集，并由专业医疗编码人员进行标注。该集包括302名入院病人的3,934个证据段和52名医生的5,563个证据段。<details>
<summary>Abstract</summary>
We introduce a dataset for evidence/rationale extraction on an extreme multi-label classification task over long medical documents. One such task is Computer-Assisted Coding (CAC) which has improved significantly in recent years, thanks to advances in machine learning technologies. Yet simply predicting a set of final codes for a patient encounter is insufficient as CAC systems are required to provide supporting textual evidence to justify the billing codes. A model able to produce accurate and reliable supporting evidence for each code would be a tremendous benefit. However, a human annotated code evidence corpus is extremely difficult to create because it requires specialized knowledge. In this paper, we introduce MDACE, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records. The dataset -- annotated by professional medical coders -- consists of 302 Inpatient charts with 3,934 evidence spans and 52 Profee charts with 5,563 evidence spans. We implemented several evidence extraction methods based on the EffectiveCAN model (Liu et al., 2021) to establish baseline performance on this dataset. MDACE can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification. We believe that the release of MDACE will greatly improve the understanding and application of deep learning technologies for medical coding and document classification.
</details>
<details>
<summary>摘要</summary>
我们介绍一个数据集用于证据/理由提取的极多标签分类任务， specifically Computer-Assisted Coding (CAC)。在过去几年，随着机器学习技术的进步，CAC 技术得到了显著改进。然而，只是预测病人遇到的最终代码是不够的，CAC 系统需要提供可靠的文本证据来证明计费代码。一个能够生成准确和可靠的证据 для每个代码的模型会是一项很大的利益。然而，人工标注的代码证据集是非常困难的创建，因为它需要专业的医疗知识。在这篇论文中，我们介绍了 MDACE，第一个公共可用的代码证据集，建立在 MIMIC-III 医疗记录子集上。该数据集由专业医疗编码员标注，包括302 例入院记录和 52 例 Profee 记录，共计 3,934 个证据段和 5,563 个证据段。我们基于 EffectiveCAN 模型（Liu et al., 2021）实现了多种证据提取方法，以建立基线性能于这个数据集。 MDACE 可以用来评估代码证据提取方法，以及深度学习模型的多标签分类精度和可读性。我们认为，释放 MDACE 将大大提高深度学习技术在医疗编码和文档分类领域的理解和应用。
</details></li>
</ul>
<hr>
<h2 id="Subjective-Crowd-Disagreements-for-Subjective-Data-Uncovering-Meaningful-CrowdOpinion-with-Population-level-Learning"><a href="#Subjective-Crowd-Disagreements-for-Subjective-Data-Uncovering-Meaningful-CrowdOpinion-with-Population-level-Learning" class="headerlink" title="Subjective Crowd Disagreements for Subjective Data: Uncovering Meaningful CrowdOpinion with Population-level Learning"></a>Subjective Crowd Disagreements for Subjective Data: Uncovering Meaningful CrowdOpinion with Population-level Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10189">http://arxiv.org/abs/2307.10189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tharindu Cyril Weerasooriya, Sarah Luger, Saloni Poddar, Ashiqur R. KhudaBukhsh, Christopher M. Homan</li>
<li>for: 这个论文旨在提高人工标注数据的公平性，包括生活altering的决策和社交媒体上的内容审核。</li>
<li>methods: 该论文提出了一种基于无监督学习的方法，使用语言特征和标签分布来汇集相似的项目，以提高标注数据的公平性。</li>
<li>results: 该论文通过在五个社交媒体平台上进行实验，发现该方法可以有效地降低标注差异，并在 Facebook 上进行了在野实验，证明了该方法的可行性。<details>
<summary>Abstract</summary>
Human-annotated data plays a critical role in the fairness of AI systems, including those that deal with life-altering decisions or moderating human-created web/social media content. Conventionally, annotator disagreements are resolved before any learning takes place. However, researchers are increasingly identifying annotator disagreement as pervasive and meaningful. They also question the performance of a system when annotators disagree. Particularly when minority views are disregarded, especially among groups that may already be underrepresented in the annotator population. In this paper, we introduce \emph{CrowdOpinion}\footnote{Accepted for publication at ACL 2023}, an unsupervised learning based approach that uses language features and label distributions to pool similar items into larger samples of label distributions. We experiment with four generative and one density-based clustering method, applied to five linear combinations of label distributions and features. We use five publicly available benchmark datasets (with varying levels of annotator disagreements) from social media (Twitter, Gab, and Reddit). We also experiment in the wild using a dataset from Facebook, where annotations come from the platform itself by users reacting to posts. We evaluate \emph{CrowdOpinion} as a label distribution prediction task using KL-divergence and a single-label problem using accuracy measures.
</details>
<details>
<summary>摘要</summary>
人类标注数据在人工智能系统中发挥 kritical 作用，包括决策生活方式或修订人类创建的网络/社交媒体内容。 Conventionally, annotator disagreements are resolved before any learning takes place. However, researchers are increasingly identifying annotator disagreement as pervasive and meaningful. They also question the performance of a system when annotators disagree, especially when minority views are disregarded, especially among groups that may already be underrepresented in the annotator population. In this paper, we introduce \emph{CrowdOpinion}\footnote{Accepted for publication at ACL 2023}, an unsupervised learning based approach that uses language features and label distributions to pool similar items into larger samples of label distributions. We experiment with four generative and one density-based clustering method, applied to five linear combinations of label distributions and features. We use five publicly available benchmark datasets (with varying levels of annotator disagreements) from social media (Twitter, Gab, and Reddit). We also experiment in the wild using a dataset from Facebook, where annotations come from the platform itself by users reacting to posts. We evaluate \emph{CrowdOpinion} as a label distribution prediction task using KL-divergence and a single-label problem using accuracy measures.
</details></li>
</ul>
<hr>
<h2 id="Linguistic-representations-for-fewer-shot-relation-extraction-across-domains"><a href="#Linguistic-representations-for-fewer-shot-relation-extraction-across-domains" class="headerlink" title="Linguistic representations for fewer-shot relation extraction across domains"></a>Linguistic representations for fewer-shot relation extraction across domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03823">http://arxiv.org/abs/2307.03823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sireesh Gururaja, Ritam Dutt, Tinglong Liao, Carolyn Rose</li>
<li>for: 这些研究旨在探讨语言表示的 incorporation 对几个 NLP 任务的跨领域性表现的影响。</li>
<li>methods: 这些研究使用了 freely available off-the-shelf 工具 construct 语法和 semantics 图，并将其与 popular transformer-based 架构结合使用，以提高 Generalization 性。</li>
<li>results: 研究发现，通过 incorporating 语言表示，可以significantly 提高 few-shot 转移中的性能，但是两种类型的图都 display  roughly equivalent utility。<details>
<summary>Abstract</summary>
Recent work has demonstrated the positive impact of incorporating linguistic representations as additional context and scaffolding on the in-domain performance of several NLP tasks. We extend this work by exploring the impact of linguistic representations on cross-domain performance in a few-shot transfer setting. An important question is whether linguistic representations enhance generalizability by providing features that function as cross-domain pivots. We focus on the task of relation extraction on three datasets of procedural text in two domains, cooking and materials science. Our approach augments a popular transformer-based architecture by alternately incorporating syntactic and semantic graphs constructed by freely available off-the-shelf tools. We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains. We find that while the inclusion of these graphs results in significantly higher performance in few-shot transfer, both types of graph exhibit roughly equivalent utility.
</details>
<details>
<summary>摘要</summary>
最近的研究已经证明在各种自然语言处理任务中，通过添加语言表示来提供更多的上下文和托管的环境可以提高域内性能。我们延续这项工作，探索语言表示在跨领域传输中的影响。关键问题是否reno linguistic representations enhance generalizability by providing features that function as cross-domain pivots。我们选择关注在三个dataset上进行Relation Extraction任务，这三个dataset分别是cooking和materials science。我们的方法是在流行的transformer-based architecture中，通过自由可用的off-the-shelf工具来构建语法和Semantic graphs，并尝试以这些graphs来提高通用性。我们检查它们是否有助于提高通用性，并 investigates whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains。我们发现，虽然包含这些graphs可以在几个shot传输中显著提高性能，但是两种类型的graph具有相当的有用性。
</details></li>
</ul>
<hr>
<h2 id="On-the-Efficacy-of-Sampling-Adapters"><a href="#On-the-Efficacy-of-Sampling-Adapters" class="headerlink" title="On the Efficacy of Sampling Adapters"></a>On the Efficacy of Sampling Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03749">http://arxiv.org/abs/2307.03749</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rycolab/sampling-adapters">https://github.com/rycolab/sampling-adapters</a></li>
<li>paper_authors: Clara Meister, Tiago Pimentel, Luca Malagutti, Ethan G. Wilcox, Ryan Cotterell</li>
<li>for: 这个论文的目的是解释各种修改语言生成模型的抽象分布，以提高生成的文本质量。</li>
<li>methods: 这篇论文使用了一种统一的框架来理解这些修改技术，并通过分析这些技术对模型的影响来解释它们如何改善文本质量。</li>
<li>results: 研究发现，使用 sampling adapters 技术可以导致更高质量的文本生成，并且可以在不同的测试集上保持这种改善。此外，这些技术可以帮助模型更好地遵循语言的规则，从而提高文本的可读性和可理解性。<details>
<summary>Abstract</summary>
Sampling is a common strategy for generating text from probabilistic models, yet standard ancestral sampling often results in text that is incoherent or ungrammatical. To alleviate this issue, various modifications to a model's sampling distribution, such as nucleus or top-k sampling, have been introduced and are now ubiquitously used in language generation systems. We propose a unified framework for understanding these techniques, which we term sampling adapters. Sampling adapters often lead to qualitatively better text, which raises the question: From a formal perspective, how are they changing the (sub)word-level distributions of language generation models? And why do these local changes lead to higher-quality text? We argue that the shift they enforce can be viewed as a trade-off between precision and recall: while the model loses its ability to produce certain strings, its precision rate on desirable text increases. While this trade-off is not reflected in standard metrics of distribution quality (such as perplexity), we find that several precision-emphasizing measures indeed indicate that sampling adapters can lead to probability distributions more aligned with the true distribution. Further, these measures correlate with higher sequence-level quality scores, specifically, Mauve.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>采样是一种常见的语言生成模型策略，然而标准祖先采样通常会导致文本无法理解或不正确。为了解决这个问题，许多模型采样分布的修改，如核心采样或top-k采样，已经被引入并广泛应用于语言生成系统。我们提出一个统一框架来理解这些技术，我们称之为采样适配器。采样适配器通常会导致更高质量的文本，这引起了问题：从形式上讲，这些地方性改变如何影响语言生成模型的（子）字元级分布？而这些本地改变是如何导致更高质量的文本呢？我们认为这种shift可以被视为一种精度和回归之间的交易：虽然模型失去了生成某些字串的能力，但它在愿景字串上的精度提高。尽管这种交易不被标准的分布质量指标（如复杂度）反映，我们发现了一些精度强调的指标确实表明采样适配器可以导致更加适应true分布的概率分布。此外，这些指标与高级序级质量分数相关，具体是Mauve。
</details></li>
</ul>
<hr>
<h2 id="QIGen-Generating-Efficient-Kernels-for-Quantized-Inference-on-Large-Language-Models"><a href="#QIGen-Generating-Efficient-Kernels-for-Quantized-Inference-on-Large-Language-Models" class="headerlink" title="QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models"></a>QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03738">http://arxiv.org/abs/2307.03738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ist-daslab/qigen">https://github.com/ist-daslab/qigen</a></li>
<li>paper_authors: Tommaso Pegolotti, Elias Frantar, Dan Alistarh, Markus Püschel</li>
<li>for: 支持量化生成推理在 LLMA 或 OPT 上的自动代码生成方法。</li>
<li>methods: 使用目标架构和性能模型，包括硬件特性和方法特定的准确性约束。</li>
<li>results: 对 CPU 上的 LLMA 模型进行了快速和准确的推理，与现有开源解决方案相比，性能和准确性都比较高。<details>
<summary>Abstract</summary>
We present ongoing work on a new automatic code generation approach for supporting quantized generative inference on LLMs such as LLaMA or OPT on off-the-shelf CPUs. Our approach is informed by the target architecture and a performance model, including both hardware characteristics and method-specific accuracy constraints. Results on CPU-based inference for LLaMA models show that our approach can lead to high performance and high accuracy, comparing favorably to the best existing open-source solution. A preliminary implementation is available at https://github.com/IST-DASLab/QIGen.
</details>
<details>
<summary>摘要</summary>
我们现在正在进行一种新的自动代码生成方法的研究，用于支持量化生成推理在LLaMA或OPT类型的大语言模型上进行OFF-the-SHELF CPU上的推理。我们的方法被目标架构和性能模型所指导，包括硬件特点和方法特定的准确性约束。对CPU上的LLaMA模型进行推理的结果显示，我们的方法可以达到高性能和高准确性，与现有开源解决方案相比之下，表现出色。一个初步的实现可以在https://github.com/IST-DASLab/QIGen中找到。
</details></li>
</ul>
<hr>
<h2 id="Improving-Automatic-Quotation-Attribution-in-Literary-Novels"><a href="#Improving-Automatic-Quotation-Attribution-in-Literary-Novels" class="headerlink" title="Improving Automatic Quotation Attribution in Literary Novels"></a>Improving Automatic Quotation Attribution in Literary Novels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03734">http://arxiv.org/abs/2307.03734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Krishnapriya Vishnubhotla, Frank Rudzicz, Graeme Hirst, Adam Hammond</li>
<li>for: 本研究旨在Addressing the challenge of quotation attribution in literary novels, where available information varies.</li>
<li>methods: 本研究使用four interconnected sub-tasks：character identification, coreference resolution, quotation identification, and speaker attribution.</li>
<li>results: 研究显示，使用state-of-the-art models on each sub-task independently，可以 achieve high accuracy scores. 特别是，一种简单的sequential prediction model可以达到与现有模型相同的准确率。<details>
<summary>Abstract</summary>
Current models for quotation attribution in literary novels assume varying levels of available information in their training and test data, which poses a challenge for in-the-wild inference. Here, we approach quotation attribution as a set of four interconnected sub-tasks: character identification, coreference resolution, quotation identification, and speaker attribution. We benchmark state-of-the-art models on each of these sub-tasks independently, using a large dataset of annotated coreferences and quotations in literary novels (the Project Dialogism Novel Corpus). We also train and evaluate models for the speaker attribution task in particular, showing that a simple sequential prediction model achieves accuracy scores on par with state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
当前的引用归属模型在文学小说中假设有不同水平的可用信息，这会对在野外推理中带来挑战。我们将引用归属看作为四个相互连接的子任务：人物识别、核心引用解决、引用归属和说话人归属。我们使用大量Literary novels中注释的核心引用和引用的数据集来对每个子任务进行独立的 bencharking，并对说话人归属任务进行特点验证，发现简单的顺序预测模型可以达到与状态值模型相同的准确率。
</details></li>
</ul>
<hr>
<h2 id="INT-FP-QSim-Mixed-Precision-and-Formats-For-Large-Language-Models-and-Vision-Transformers"><a href="#INT-FP-QSim-Mixed-Precision-and-Formats-For-Large-Language-Models-and-Vision-Transformers" class="headerlink" title="INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers"></a>INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03712">http://arxiv.org/abs/2307.03712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lightmatter-ai/int-fp-qsim">https://github.com/lightmatter-ai/int-fp-qsim</a></li>
<li>paper_authors: Lakshmi Nair, Mikhail Bernadskiy, Arulselvan Madhavan, Craig Chan, Ayon Basumallik, Darius Bunandar</li>
<li>for: 本文旨在支持资源约束和大语言模型的民生化，提出一个开源的INT-FP-QSim simulate器，可以在不同的数字精度和格式下灵活评估大语言模型和视Transformers。</li>
<li>methods:  INT-FP-QSim 使用现有的开源库 such as TensorRT, QPytorch 和 AIMET，组合了这些库来支持不同的浮点数和整数格式。</li>
<li>results: 通过使用 INT-FP-QSim，我们对大语言模型和视Transformers 的性能做了评估，并比较了最近提出的 Adaptive Block Floating Point, SmoothQuant, GPTQ 和 RPTQ 方法的影响。<details>
<summary>Abstract</summary>
The recent rise of large language models (LLMs) has resulted in increased efforts towards running LLMs at reduced precision. Running LLMs at lower precision supports resource constraints and furthers their democratization, enabling users to run billion-parameter LLMs on their personal devices. To supplement this ongoing effort, we propose INT-FP-QSim: an open-source simulator that enables flexible evaluation of LLMs and vision transformers at various numerical precisions and formats. INT-FP-QSim leverages existing open-source repositories such as TensorRT, QPytorch and AIMET for a combined simulator that supports various floating point and integer formats. With the help of our simulator, we survey the impact of different numerical formats on the performance of LLMs and vision transformers at 4-bit weights and 4-bit or 8-bit activations. We also compare recently proposed methods like Adaptive Block Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We hope INT-FP-QSim will enable researchers to flexibly simulate models at various precisions to support further research in quantization of LLMs and vision transformers.
</details>
<details>
<summary>摘要</summary>
INT-FP-QSim leverages existing open-source repositories such as TensorRT, QPytorch, and AIMET to create a combined simulator that supports various floating point and integer formats. With the help of our simulator, we survey the impact of different numerical formats on the performance of LLMs and vision transformers when using 4-bit weights and 4-bit or 8-bit activations. We also compare recently proposed methods like Adaptive Block Floating Point, SmoothQuant, GPTQ, and RPTQ on the model performances.Our hope is that INT-FP-QSim will enable researchers to flexibly simulate models at various precisions, supporting further research in quantization of LLMs and vision transformers.
</details></li>
</ul>
<hr>
<h2 id="LaunchpadGPT-Language-Model-as-Music-Visualization-Designer-on-Launchpad"><a href="#LaunchpadGPT-Language-Model-as-Music-Visualization-Designer-on-Launchpad" class="headerlink" title="LaunchpadGPT: Language Model as Music Visualization Designer on Launchpad"></a>LaunchpadGPT: Language Model as Music Visualization Designer on Launchpad</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04827">http://arxiv.org/abs/2307.04827</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yunlong10/launchpadgpt">https://github.com/yunlong10/launchpadgpt</a></li>
<li>paper_authors: Siting Xu, Yunlong Tang, Feng Zheng</li>
<li>for: 这个论文的目的是帮助设计Launchpad的音乐视觉效果，以及为 Beginner 提供更加可 accessible的方法来创建音乐视觉。</li>
<li>methods: 这个论文提出了一种基于语言模型的自动生成音乐视觉设计方法，用于Launhpad上演奏音乐。该方法使用了音乐piece作为输入，并输出了Launhpad上演奏的光效果形式的视频。</li>
<li>results: 实验结果表明，该方法可以创造出比随机生成方法更好的音乐视觉，并且具有更广泛的音乐视觉应用前景。<details>
<summary>Abstract</summary>
Launchpad is a musical instrument that allows users to create and perform music by pressing illuminated buttons. To assist and inspire the design of the Launchpad light effect, and provide a more accessible approach for beginners to create music visualization with this instrument, we proposed the LaunchpadGPT model to generate music visualization designs on Launchpad automatically. Based on the language model with excellent generation ability, our proposed LaunchpadGPT takes an audio piece of music as input and outputs the lighting effects of Launchpad-playing in the form of a video (Launchpad-playing video). We collect Launchpad-playing videos and process them to obtain music and corresponding video frame of Launchpad-playing as prompt-completion pairs, to train the language model. The experiment result shows the proposed method can create better music visualization than random generation methods and hold the potential for a broader range of music visualization applications. Our code is available at https://github.com/yunlong10/LaunchpadGPT/.
</details>
<details>
<summary>摘要</summary>
Launchpad是一种音乐 инструмент，允许用户通过点击灯光按钮创作和演奏音乐。为帮助设计Launchpad的光效和启发创新，以及为Beginner提供更 accessible的音乐视觉创作方式，我们提议了LaunchpadGPT模型，自动生成Launchpad演奏的视觉设计。基于出色的语言模型，我们的提议LaunchpadGPT接受音乐作品作为输入，并输出Launchpad演奏的光效效果 видео（Launchpad演奏视频）。我们收集了Launchpad演奏视频，并处理它们，以获得音乐和对应的视频帧的Launchpad演奏Prompt-completion对。通过训练语言模型，我们实现了该方法可以创造更好的音乐视觉，并且具有更广泛的音乐视觉应用前景。我们的代码可以在https://github.com/yunlong10/LaunchpadGPT/上获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/08/cs.CL_2023_07_08/" data-id="clpahu6zl00833h886seq33hk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_07_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/08/cs.LG_2023_07_08/" class="article-date">
  <time datetime="2023-07-08T10:00:00.000Z" itemprop="datePublished">2023-07-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/08/cs.LG_2023_07_08/">cs.LG - 2023-07-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-Model-Free-Exploration-in-Low-Rank-MDPs"><a href="#Efficient-Model-Free-Exploration-in-Low-Rank-MDPs" class="headerlink" title="Efficient Model-Free Exploration in Low-Rank MDPs"></a>Efficient Model-Free Exploration in Low-Rank MDPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03997">http://arxiv.org/abs/2307.03997</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zakaria Mhammedi, Adam Block, Dylan J. Foster, Alexander Rakhlin</li>
<li>for: 本文旨在开发一种实用、效率高的探索算法，用于在高维空间中进行强化学习，并且具有函数近似和泛化能力。</li>
<li>methods: 本文提出的 VoX 算法使用一种通过unknown feature embedding的低维 Markov Decision Processes（MDPs）来实现探索，该算法是 computationally efficient 并且无需额外的统计假设。</li>
<li>results: 本文的分析表明，VoX 算法可以在低维 MDPs 中提供 provably 样本效率的探索，并且不需要额外的模型基础或 latent variable structure。<details>
<summary>Abstract</summary>
A major challenge in reinforcement learning is to develop practical, sample-efficient algorithms for exploration in high-dimensional domains where generalization and function approximation is required. Low-Rank Markov Decision Processes -- where transition probabilities admit a low-rank factorization based on an unknown feature embedding -- offer a simple, yet expressive framework for RL with function approximation, but existing algorithms are either (1) computationally intractable, or (2) reliant upon restrictive statistical assumptions such as latent variable structure, access to model-based function approximation, or reachability. In this work, we propose the first provably sample-efficient algorithm for exploration in Low-Rank MDPs that is both computationally efficient and model-free, allowing for general function approximation and requiring no additional structural assumptions. Our algorithm, VoX, uses the notion of a generalized optimal design for the feature embedding as an efficiently computable basis for exploration, performing efficient optimal design computation by interleaving representation learning and policy optimization. Our analysis -- which is appealingly simple and modular -- carefully combines several techniques, including a new reduction from optimal design computation to policy optimization based on the Frank-Wolfe method, and an improved analysis of a certain minimax representation learning objective found in prior work.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在强化学习中是开发实用、样本效率高的探索算法，以便在高维度空间中进行探索，并且需要泛化和函数近似。低维马尔可夫遇过程（Low-Rank MDPs）提供了一个简单 yet 表达力强的框架，但现有算法的问题包括（1）计算复杂度太高，或（2）需要特殊的统计假设，如隐藏变量结构、函数近似模型或可达性。在这项工作中，我们提出了首个可证明样本效率高的探索算法，可以在低维马尔可夫遇过程中进行探索，并且不需要特殊的结构假设。我们的算法VoX利用了一个通用优化设计的概念，作为一种可读取的基础 для探索，并通过将表示学习和政策优化结合在一起，实现高效的优化设计计算。我们的分析，感知简单而干净，综合使用了多种技术，包括一种新的减少从优化设计计算到政策优化基于Frank-Wolfe方法的技术，以及在先前的工作中发现的一种改进的最小最大表达学习目标的分析。
</details></li>
</ul>
<hr>
<h2 id="NLP-Meets-RNA-Unsupervised-Embedding-Learning-for-Ribozymes-with-Word2Vec"><a href="#NLP-Meets-RNA-Unsupervised-Embedding-Learning-for-Ribozymes-with-Word2Vec" class="headerlink" title="NLP Meets RNA: Unsupervised Embedding Learning for Ribozymes with Word2Vec"></a>NLP Meets RNA: Unsupervised Embedding Learning for Ribozymes with Word2Vec</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05537">http://arxiv.org/abs/2307.05537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Kean Gao</li>
<li>for: 本研究使用Word2Vec算法来提高我们对核酸杂合物（ribozyme）的理解，并寻找更好的方法来分类ribozyme。</li>
<li>methods: 本研究使用Word2Vec算法，通过训练9,000多个不同的核酸杂合物，将核酸序列映射到128和256维度的 вектор空间中。</li>
<li>results: 结果表明，使用核酸序列embedding可以准确地分类核酸杂合物，并且256维度的embedding Vector Space可以捕捉核酸杂合物的特征。<details>
<summary>Abstract</summary>
Ribozymes, RNA molecules with distinct 3D structures and catalytic activity, have widespread applications in synthetic biology and therapeutics. However, relatively little research has focused on leveraging deep learning to enhance our understanding of ribozymes. This study implements Word2Vec, an unsupervised learning technique for natural language processing, to learn ribozyme embeddings. Ribo2Vec was trained on over 9,000 diverse ribozymes, learning to map sequences to 128 and 256-dimensional vector spaces. Using Ribo2Vec, sequence embeddings for five classes of ribozymes (hatchet, pistol, hairpin, hovlinc, and twister sister) were calculated. Principal component analysis demonstrated the ability of these embeddings to distinguish between ribozyme classes. Furthermore, a simple SVM classifier trained on ribozyme embeddings showed promising results in accurately classifying ribozyme types. Our results suggest that the embedding vectors contained meaningful information about ribozymes. Interestingly, 256-dimensional embeddings behaved similarly to 128-dimensional embeddings, suggesting that a lower dimension vector space is generally sufficient to capture ribozyme features. This approach demonstrates the potential of Word2Vec for bioinformatics, opening new avenues for ribozyme research. Future research includes using a Transformer-based method to learn RNA embeddings, which can capture long-range interactions between nucleotides.
</details>
<details>
<summary>摘要</summary>
瑞博酵素（ribozyme）具有广泛的应用前景，包括生物技术和生物医学。然而，相对论文不多关注利用深度学习来提高我们对瑞博酵素的理解。这项研究使用Word2Vec算法，一种无监督学习技术，来学习瑞博酵素的嵌入。 Ribo2Vec 训练在超过9000个多样化瑞博酵素上，将序列映射到128和256维度的向量空间中。使用 Ribo2Vec，我们计算了5种瑞博酵素类型（锥子、手枪、捷径、托征和姐妹）的序列嵌入。对于这些嵌入，我们使用主成分分析得到了可以分辨瑞博酵素类型的结果。此外，使用瑞博酵素嵌入训练的简单支持向量机器学习（SVM）分类器也表现出了良好的准确率。这些结果表明瑞博酵素嵌入 vectors 含有有用的信息。有趣的是，256维度的嵌入和128维度的嵌入之间的行为相似，这表明低维度向量空间通常足够 capture瑞博酵素特征。这种方法可能会打开新的 Bioinformatics 研究途径。未来的研究可能包括使用Transformer算法来学习RNA嵌入，以捕捉RNA中距离较远的核苷酸之间的长距离交互。
</details></li>
</ul>
<hr>
<h2 id="Integrating-Curricula-with-Replays-Its-Effects-on-Continual-Learning"><a href="#Integrating-Curricula-with-Replays-Its-Effects-on-Continual-Learning" class="headerlink" title="Integrating Curricula with Replays: Its Effects on Continual Learning"></a>Integrating Curricula with Replays: Its Effects on Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05747">http://arxiv.org/abs/2307.05747</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhanglab-deepneurocoglab/integrating-curricula-with-replays">https://github.com/zhanglab-deepneurocoglab/integrating-curricula-with-replays</a></li>
<li>paper_authors: Ren Jie Tee, Mengmi Zhang</li>
<li>for: 本研究旨在探讨curricula的integrating与replay方法在持续学习中的作用，以提高知识退化和学习转移。</li>
<li>methods: 我们使用了三种不同的curricula设计方法，包括交叠频率的重复示例与训练数据、顺序排序示例的重复顺序、以及从uniform分布中选择示例的策略。这些方法与认知心理学原理相Alignment，并可以利用重复实践中的优点、易于困难重复、以及示例选择策略。</li>
<li>results: 我们的结果表明，这三种curricula有效地遏制了衰弱性失忆，并提高了正面知识传递。这些结果表明，curricula可以在持续学习方法中提供进一步的改进。我们的代码和数据可以在GitHub上找到：<a target="_blank" rel="noopener" href="https://github.com/ZhangLab-DeepNeuroCogLab/Integrating-Curricula-with-Replays">https://github.com/ZhangLab-DeepNeuroCogLab/Integrating-Curricula-with-Replays</a><details>
<summary>Abstract</summary>
Humans engage in learning and reviewing processes with curricula when acquiring new skills or knowledge. This human learning behavior has inspired the integration of curricula with replay methods in continual learning agents. The goal is to emulate the human learning process, thereby improving knowledge retention and facilitating learning transfer. Existing replay methods in continual learning agents involve the random selection and ordering of data from previous tasks, which has shown to be effective. However, limited research has explored the integration of different curricula with replay methods to enhance continual learning. Our study takes initial steps in examining the impact of integrating curricula with replay methods on continual learning in three specific aspects: the interleaved frequency of replayed exemplars with training data, the sequence in which exemplars are replayed, and the strategy for selecting exemplars into the replay buffer. These aspects of curricula design align with cognitive psychology principles and leverage the benefits of interleaved practice during replays, easy-to-hard rehearsal, and exemplar selection strategy involving exemplars from a uniform distribution of difficulties. Based on our results, these three curricula effectively mitigated catastrophic forgetting and enhanced positive knowledge transfer, demonstrating the potential of curricula in advancing continual learning methodologies. Our code and data are available: https://github.com/ZhangLab-DeepNeuroCogLab/Integrating-Curricula-with-Replays
</details>
<details>
<summary>摘要</summary>
人类在学习和复习过程中使用课程，以获得新技能或知识。这种人类学习行为对于 continual learning agent 的 интеграцию有着灵感。目标是通过模拟人类学习过程，提高知识保持和学习传递。现有的重播方法在 continual learning agent 中已经证明有效。然而，有限的研究探讨了不同课程的 интеграция和重播方法的影响。我们的研究首先探讨了在三个方面中的课程设计对 continual learning 的影响：重播示例的频率与训练数据的排序、示例的重播顺序和选择示例进入缓存的策略。这些课程设计方面与认知心理学原理相吻合，利用重播中的叠加实践、易于困难的复习和选择示例的策略。根据我们的结果，这三种课程有效地遏止了恶性遗忘和提高了正面知识传递，这表明了课程在 continual learning 方法中的潜力。我们的代码和数据可以在 GitHub 上找到：https://github.com/ZhangLab-DeepNeuroCogLab/Integrating-Curricula-with-Replays
</details></li>
</ul>
<hr>
<h2 id="Building-and-Road-Segmentation-Using-EffUNet-and-Transfer-Learning-Approach"><a href="#Building-and-Road-Segmentation-Using-EffUNet-and-Transfer-Learning-Approach" class="headerlink" title="Building and Road Segmentation Using EffUNet and Transfer Learning Approach"></a>Building and Road Segmentation Using EffUNet and Transfer Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03980">http://arxiv.org/abs/2307.03980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahil Gangurde</li>
<li>for: 本论文目标是对遥感图像中的建筑和路径进行 semantics 分割。</li>
<li>methods: 该论文提出了一种基于 Google 新提出的 EfficientNetV2 增强网络，并结合 UNet 解码器实现分割图像的方法。</li>
<li>results: 该方法在麻省建筑和路径数据集上达到了 benchmark 分割精度，IOU 分割精度分别为 0.8365 和 0.9153。<details>
<summary>Abstract</summary>
In city, information about urban objects such as water supply, railway lines, power lines, buildings, roads, etc., is necessary for city planning. In particular, information about the spread of these objects, locations and capacity is needed for the policymakers to make impactful decisions. This thesis aims to segment the building and roads from the aerial image captured by the satellites and UAVs. Many different architectures have been proposed for the semantic segmentation task and UNet being one of them. In this thesis, we propose a novel architecture based on Google's newly proposed EfficientNetV2 as an encoder for feature extraction with UNet decoder for constructing the segmentation map. Using this approach we achieved a benchmark score for the Massachusetts Building and Road dataset with an mIOU of 0.8365 and 0.9153 respectively.
</details>
<details>
<summary>摘要</summary>
在城市中，有关城市 объекts 如水 supply、铁路线、电力线、建筑、路径等的信息是城市规划的必要条件。特别是政策制定者需要知道这些对象的扩散、位置和容量，以便做出有力的决策。本论文目的是从航天图像和无人机拍摄的卫星和无人机图像中分割建筑和路径。许多不同的架构已经为semantic segmentation任务提出了多种方案，其中UNet是其中之一。本论文提出了基于Google新提出的EfficientNetV2架构来进行特征提取，并与UNet决码器结合使用以生成分割图像。通过这种方法，我们在马萨诸岛建筑和路径数据集上达到了 benchmark 分数，具体分别为0.8365和0.9153。
</details></li>
</ul>
<hr>
<h2 id="Digital-Twins-for-Patient-Care-via-Knowledge-Graphs-and-Closed-Form-Continuous-Time-Liquid-Neural-Networks"><a href="#Digital-Twins-for-Patient-Care-via-Knowledge-Graphs-and-Closed-Form-Continuous-Time-Liquid-Neural-Networks" class="headerlink" title="Digital Twins for Patient Care via Knowledge Graphs and Closed-Form Continuous-Time Liquid Neural Networks"></a>Digital Twins for Patient Care via Knowledge Graphs and Closed-Form Continuous-Time Liquid Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04772">http://arxiv.org/abs/2307.04772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Logan Nye</li>
<li>for: 这篇研究是为了探讨如何使用数字双技术在医疗领域提供个性化的药物和支持、早期诊断、模拟治疗结果和优化手术规划。</li>
<li>methods: 本研究提出了一种新的框架，使用知识图和闭式形式的连续时间流体神经网络来解决计算成本和模型复杂性的挑战，以实现实时分析和个性化医疗。</li>
<li>results: 本研究的结果表明，使用这种新的框架可以实现实时的患者健康状况概述、个性化医疗和早期诊断、模拟治疗结果和优化手术规划，为数字双技术在医疗领域的应用提供了新的可能性。<details>
<summary>Abstract</summary>
Digital twin technology has is anticipated to transform healthcare, enabling personalized medicines and support, earlier diagnoses, simulated treatment outcomes, and optimized surgical plans. Digital twins are readily gaining traction in industries like manufacturing, supply chain logistics, and civil infrastructure. Not in patient care, however. The challenge of modeling complex diseases with multimodal patient data and the computational complexities of analyzing it have stifled digital twin adoption in the biomedical vertical. Yet, these major obstacles can potentially be handled by approaching these models in a different way. This paper proposes a novel framework for addressing the barriers to clinical twin modeling created by computational costs and modeling complexities. We propose structuring patient health data as a knowledge graph and using closed-form continuous-time liquid neural networks, for real-time analytics. By synthesizing multimodal patient data and leveraging the flexibility and efficiency of closed form continuous time networks and knowledge graph ontologies, our approach enables real time insights, personalized medicine, early diagnosis and intervention, and optimal surgical planning. This novel approach provides a comprehensive and adaptable view of patient health along with real-time analytics, paving the way for digital twin simulations and other anticipated benefits in healthcare.
</details>
<details>
<summary>摘要</summary>
《数字双胞技术在医疗领域的应用》数字双胞技术已被预测将重点改变医疗领域，使得个性化药物和支持、早期诊断、模拟治疗结果和优化手术规划等became possible。然而，在病人护理方面，数字双胞技术的普及受到了许多挑战，主要是模拟复杂的疾病和多模态病人数据的计算复杂性。然而，这些主要障碍可以通过一种新的方法来解决。本文提出了一种新的框架，用于解决在计算成本和模型复杂性等方面阻碍临床双胞模型的障碍。我们提议将病人健康数据结构化为知识图，并使用闭合形时间连续神经网络，以实现实时分析。通过对多模态病人数据进行synthesize，并利用closed-form continuous-time liquid neural networks和知识图 ontologies的灵活性和高效性，我们的方法可以实现实时的医疗探索和个性化医疗。本文的新方法可以为医疗领域提供一个普适和可变的病人健康视图，同时实现实时的分析，为数字双胞 simulations和其他预期的健康医疗带来了新的机遇。
</details></li>
</ul>
<hr>
<h2 id="Fault-Monitoring-in-Passive-Optical-Networks-using-Machine-Learning-Techniques"><a href="#Fault-Monitoring-in-Passive-Optical-Networks-using-Machine-Learning-Techniques" class="headerlink" title="Fault Monitoring in Passive Optical Networks using Machine Learning Techniques"></a>Fault Monitoring in Passive Optical Networks using Machine Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03945">http://arxiv.org/abs/2307.03945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khouloud Abdelli, Carsten Tropschug, Helmut Griesser, Stephan Pachnicke</li>
<li>for: 提高Passive Optical Network（PON）系统的稳定性和可靠性，降低服务提供商或运维商面临的财务损失风险。</li>
<li>methods: 利用机器学习（ML）技术进行PON系统故障监测，并通过实验Optical Time Domain Reflectometry（OTDR）数据验证其效果。</li>
<li>results: 通过ML方法实现PON系统故障监测，可以减少服务中断时的财务损失风险，并提高系统的可靠性和稳定性。<details>
<summary>Abstract</summary>
Passive optical network (PON) systems are vulnerable to a variety of failures, including fiber cuts and optical network unit (ONU) transmitter/receiver failures. Any service interruption caused by a fiber cut can result in huge financial losses for service providers or operators. Identifying the faulty ONU becomes difficult in the case of nearly equidistant branch terminations because the reflections from the branches overlap, making it difficult to distinguish the faulty branch given the global backscattering signal. With increasing network size, the complexity of fault monitoring in PON systems increases, resulting in less reliable monitoring. To address these challenges, we propose in this paper various machine learning (ML) approaches for fault monitoring in PON systems, and we validate them using experimental optical time domain reflectometry (OTDR) data.
</details>
<details>
<summary>摘要</summary>
激光网络（PON）系统受到多种故障的威胁，包括纤维断和Optical Network Unit（ONU）发送器/接收器故障。任何纤维断导致的服务中断可能会对服务提供商或运营商造成巨大的经济损失。在分支结束处 nearly equidistant的情况下，缺陷的ONU diffficult to identify，因为分支 reflection overlap，使得不可以通过全球反射信号来 отличи出缺陷分支。随着网络规模的增加，PON系统中的缺陷监测复杂度增加，导致监测变得更加不可靠。为解决这些挑战，本文提出了基于机器学习（ML）的多种缺陷监测方法，并通过实验optical time domain reflectometry（OTDR）数据 validate them。
</details></li>
</ul>
<hr>
<h2 id="Rosko-Row-Skipping-Outer-Products-for-Sparse-Matrix-Multiplication-Kernels"><a href="#Rosko-Row-Skipping-Outer-Products-for-Sparse-Matrix-Multiplication-Kernels" class="headerlink" title="Rosko: Row Skipping Outer Products for Sparse Matrix Multiplication Kernels"></a>Rosko: Row Skipping Outer Products for Sparse Matrix Multiplication Kernels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03930">http://arxiv.org/abs/2307.03930</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vnatesh/rosko">https://github.com/vnatesh/rosko</a></li>
<li>paper_authors: Vikas Natesh, Andrew Sabot, H. T. Kung, Mark Ting</li>
<li>for: 这篇论文是为了提高深度神经网络（DNN）的计算和内存访问需求。</li>
<li>methods: 论文使用了row skipping outer products（Rosko）来 derivate sparse matrix multiplication（SpMM）kernels，以降低DNNs的计算和内存访问需求。Rosko可以在程式执行时 skip entire row computations，并且具有低缓存管理开销。</li>
<li>results: Rosko kernels可以与其他outer product scheduling方法结合使用，并且可以将其他方法的计算 skipped by using Rosko的packing format。Rosko kernels在实际硬件上比 EXISTS auto-tuning和搜索基于解决方案和商业供应链的 vendor-optimized 库来的性能更好，并且可以在不同的神经网络负载上实现更高的执行速度，达到6.5倍的时间优化。<details>
<summary>Abstract</summary>
We propose Rosko -- row skipping outer products -- for deriving sparse matrix multiplication (SpMM) kernels in reducing computation and memory access requirements of deep neural networks (DNNs). Rosko allows skipping of entire row computations during program execution with low sparsity-management overheads. We analytically derive sparse CPU kernels that adapt to given hardware characteristics to effectively utilize processor cores and minimize data movement without the need for auto-tuning or search space exploration. Rosko can be integrated with other outer product scheduling methods, allowing them to leverage row skipping by using Rosko's packing format to skip unnecessary computation.   Rosko kernels outperform existing auto-tuning and search-based solutions as well as state-of-the-art vendor-optimized libraries on real hardware across a variety of neural network workloads. For matrices with sparsities ranging from 65% to 99.8% typically found in machine learning, Rosko kernels achieve up to a 6.5x runtime reduction on Intel and ARM CPUs.
</details>
<details>
<summary>摘要</summary>
我们提出了Rosko，它是跳过外积栈的方法，用于获得深度神经网络（DNN）中的简约矩阵乘法（SpMM）内核。Rosko可以在程式执行时跳过整个行的计算，具有低简约管理成本。我们分析性地 derivatesparse CPU内核，可以根据硬件特性来有效利用处理器核心和减少资料移动，无需进行自动调整或搜索空间探索。Rosko可以与其他外积栈调度方法结合，让它们利用Rosko的封包格式跳过无需计算。Rosko内核比现有的自动调整和搜索基于解决方案以及商业化优化库在真实硬件上表现更好，对于具有65%到99.8%的简约率，通常见于机器学习 tasks 中，Rosko内核在英特尔和ARM CPU上可以获得至多6.5倍的执行时间优化。
</details></li>
</ul>
<hr>
<h2 id="Fairness-Aware-Graph-Neural-Networks-A-Survey"><a href="#Fairness-Aware-Graph-Neural-Networks-A-Survey" class="headerlink" title="Fairness-Aware Graph Neural Networks: A Survey"></a>Fairness-Aware Graph Neural Networks: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03929">http://arxiv.org/abs/2307.03929</a></li>
<li>repo_url: None</li>
<li>paper_authors: April Chen, Ryan A. Rossi, Namyong Park, Puja Trivedi, Yu Wang, Tong Yu, Sungchul Kim, Franck Dernoncourt, Nesreen K. Ahmed<br>for: This paper focuses on improving the fairness of Graph Neural Networks (GNNs) by examining and categorizing fairness techniques for GNNs.methods: The paper discusses previous work on fair GNN models and techniques, including those that focus on improving fairness during preprocessing, training, or post-processing. The paper also introduces an intuitive taxonomy for fairness evaluation metrics.results: The paper highlights the advantages and intuition of using fairness techniques in GNNs, and summarizes graph datasets that are useful for benchmarking the fairness of GNN models. The paper also identifies key open problems and challenges that remain to be addressed.<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have become increasingly important due to their representational power and state-of-the-art predictive performance on many fundamental learning tasks. Despite this success, GNNs suffer from fairness issues that arise as a result of the underlying graph data and the fundamental aggregation mechanism that lies at the heart of the large class of GNN models. In this article, we examine and categorize fairness techniques for improving the fairness of GNNs. Previous work on fair GNN models and techniques are discussed in terms of whether they focus on improving fairness during a preprocessing step, during training, or in a post-processing phase. Furthermore, we discuss how such techniques can be used together whenever appropriate, and highlight the advantages and intuition as well. We also introduce an intuitive taxonomy for fairness evaluation metrics including graph-level fairness, neighborhood-level fairness, embedding-level fairness, and prediction-level fairness metrics. In addition, graph datasets that are useful for benchmarking the fairness of GNN models are summarized succinctly. Finally, we highlight key open problems and challenges that remain to be addressed.
</details>
<details>
<summary>摘要</summary>
graph neural networks (GNNs) 在最近几年内变得越来越重要，这是因为它们在许多基本学习任务上具有代表力和状态速度。然而，GNNs 受到公平问题的影响，这些问题 arise 由下面的图数据和基本聚合机制。在这篇文章中，我们评估和分类 fairness 技术，以提高 GNNs 的公平性。先前的 fair GNN 模型和技术被分为三类：在预处理阶段、在训练阶段和在后处理阶段。此外，我们还讨论了这些技术可以在合适的时候一起使用，并高亮了其优势和直觉。此外，我们还提出了一个直观的公平评价度量分类，包括图级公平、邻居级公平、嵌入级公平和预测级公平度量。此外，我们还简要介绍了一些用于评估 GNN 模型公平性的图数据。最后，我们高亮了一些未解决的问题和挑战。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Fast-Empirical-Scenarios"><a href="#Fast-Empirical-Scenarios" class="headerlink" title="Fast Empirical Scenarios"></a>Fast Empirical Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03927">http://arxiv.org/abs/2307.03927</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Multerer, Paul Schneider, Rohan Sen</li>
<li>for: 从大型高维数据中提取一小量表示性的方案，以便进行可靠的enario-based模型和高维数学 интегра。</li>
<li>methods: 提出了两种新的算法，第一种可以找到尚未被观察到的enario，并提供了基于enario的协方差矩阵表示；第二种选择了已经实现的世界状态中重要的数据点，并与更高阶sample moment信息相符。</li>
<li>results: 对比较几种现有算法，提出的两种算法具有高效计算和可靠的enario-based模型特点，并在股票投资中得到了广泛的应用。<details>
<summary>Abstract</summary>
We seek to extract a small number of representative scenarios from large and high-dimensional panel data that are consistent with sample moments. Among two novel algorithms, the first identifies scenarios that have not been observed before, and comes with a scenario-based representation of covariance matrices. The second proposal picks important data points from states of the world that have already realized, and are consistent with higher-order sample moment information. Both algorithms are efficient to compute, and lend themselves to consistent scenario-based modeling and high-dimensional numerical integration. Extensive numerical benchmarking studies and an application in portfolio optimization favor the proposed algorithms.
</details>
<details>
<summary>摘要</summary>
我们寻求从大量高维批处理数据中提取一小量表示性的情景，这些情景与样本幂应于一致。我们提出了两种新算法，第一种可以找到没有被观察到的情景，同时提供了情景基于协方差矩阵的表示方式。第二种算法选择已经实现的世界状态中重要的数据点，并与高阶样本幂信息一致。这两种算法都具有计算效率，适用于一致的enario-based模型和高维数字 интегра。我们在大量计算和股票投资应用中进行了广泛的数值对比研究，而这两种算法都得到了 preference。
</details></li>
</ul>
<hr>
<h2 id="Training-Physics-Informed-Neural-Networks-via-Multi-Task-Optimization-for-Traffic-Density-Prediction"><a href="#Training-Physics-Informed-Neural-Networks-via-Multi-Task-Optimization-for-Traffic-Density-Prediction" class="headerlink" title="Training Physics-Informed Neural Networks via Multi-Task Optimization for Traffic Density Prediction"></a>Training Physics-Informed Neural Networks via Multi-Task Optimization for Traffic Density Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03920">http://arxiv.org/abs/2307.03920</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Wang, A. K. Qin, Sajjad Shafiei, Hussein Dia, Adriana-Simona Mihaita, Hanna Grzybowska</li>
<li>for: 用于预测交通流量</li>
<li>methods: 使用多任务优化（MTO）框架，创建多个辅助任务并与主任务一起解决</li>
<li>results: 实验结果表明，我们提议的训练框架可以在比较限制的数据量下提高PINN的性能<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) are a newly emerging research frontier in machine learning, which incorporate certain physical laws that govern a given data set, e.g., those described by partial differential equations (PDEs), into the training of the neural network (NN) based on such a data set. In PINNs, the NN acts as the solution approximator for the PDE while the PDE acts as the prior knowledge to guide the NN training, leading to the desired generalization performance of the NN when facing the limited availability of training data. However, training PINNs is a non-trivial task largely due to the complexity of the loss composed of both NN and physical law parts. In this work, we propose a new PINN training framework based on the multi-task optimization (MTO) paradigm. Under this framework, multiple auxiliary tasks are created and solved together with the given (main) task, where the useful knowledge from solving one task is transferred in an adaptive mode to assist in solving some other tasks, aiming to uplift the performance of solving the main task. We implement the proposed framework and apply it to train the PINN for addressing the traffic density prediction problem. Experimental results demonstrate that our proposed training framework leads to significant performance improvement in comparison to the traditional way of training the PINN.
</details>
<details>
<summary>摘要</summary>
Physics-informed neural networks (PINNs) 是一个新兴的研究领域，它将物理法则 incorporated 到 neural network (NN) 的训练中，使得 NN 能够更好地预测数据集中的特征。在 PINNs 中，NN  acted as 数据集中的解决方案，而 PDE  acted as 导航 NN 训练的知识。这使得 NN 在面临有限的训练数据时能够达到更好的总体性能。然而，训练 PINNs 是一个非rivial任务，主要因为损失函数的复杂性，它包括 NN 和物理法则部分。在这种情况下，我们提出了一个基于多任务优化 (MTO) 的新的训练框架。在这个框架中，我们创建了多个auxiliary任务，并与主任务一起解决，使得解决一个任务的有用知识可以在适应模式下传递给另一个任务，以提高主任务的解决性能。我们实现了提议的框架，并应用它来训练 PINN 来解决交通密度预测问题。实验结果表明，我们的训练框架可以在传统训练 PINN 的基础上获得显著性能提升。
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Deep-Q-–-Network-with-Multiclass-Classification-Algorithms"><a href="#Incorporating-Deep-Q-–-Network-with-Multiclass-Classification-Algorithms" class="headerlink" title="Incorporating Deep Q – Network with Multiclass Classification Algorithms"></a>Incorporating Deep Q – Network with Multiclass Classification Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03908">http://arxiv.org/abs/2307.03908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noopur Zambare, Ravindranath Sawane</li>
<li>for: 本研究探讨了如何使用深度Q网络（DQN）提高多类分类算法的功能。我们使用Kaggle的标准数据集创建了一个框架，该框架将DQN与现有的多类分类算法结合使用。</li>
<li>methods: 本研究使用了Kaggle的标准数据集，并采用了深度强化学习策略来提高多类分类精度。</li>
<li>results: 本研究发现，通过使用DQN，可以提高多类分类精度和稳定性。这些结果可以用于各种领域，包括图像识别、自然语言处理和生物信息学。特别是在金融风险管理和财务预测方面，可以用DQN来预测企业面临financial distress的可能性。<details>
<summary>Abstract</summary>
In this study, we explore how Deep Q-Network (DQN) might improve the functionality of multiclass classification algorithms. We will use a benchmark dataset from Kaggle to create a framework incorporating DQN with existing supervised multiclass classification algorithms. The findings of this study will bring insight into how deep reinforcement learning strategies may be used to increase multiclass classification accuracy. They have been used in a number of fields, including image recognition, natural language processing, and bioinformatics. This study is focused on the prediction of financial distress in companies in addition to the wider application of Deep Q-Network in multiclass classification. Identifying businesses that are likely to experience financial distress is a crucial task in the fields of finance and risk management. Whenever a business experiences serious challenges keeping its operations going and meeting its financial responsibilities, it is said to be in financial distress. It commonly happens when a company has a sharp and sustained recession in profitability, cash flow issues, or an unsustainable level of debt.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们探讨了深度Q网络（DQN）如何改善多类分类算法的功能。我们将使用Kaggle的标准数据集创建一个框架，该框架将包含DQN与现有的多类分类算法。我们的发现将提供深入理解deep reinforcement learning策略如何提高多类分类精度。这些策略在图像识别、自然语言处理和生物信息处理等领域都有广泛的应用。本研究的特点是用DQN预测公司面临财务危机的可能性，而不是仅仅是将其应用于多类分类。公司经历严重的运营困难和履行财务责任时，被称为财务危机。这通常发生在公司收入下降、财务流动性困难或债务水平不可持续时。
</details></li>
</ul>
<hr>
<h2 id="ScriptWorld-Text-Based-Environment-For-Learning-Procedural-Knowledge"><a href="#ScriptWorld-Text-Based-Environment-For-Learning-Procedural-Knowledge" class="headerlink" title="ScriptWorld: Text Based Environment For Learning Procedural Knowledge"></a>ScriptWorld: Text Based Environment For Learning Procedural Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03906">http://arxiv.org/abs/2307.03906</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/exploration-lab/scriptworld">https://github.com/exploration-lab/scriptworld</a></li>
<li>paper_authors: Abhinav Joshi, Areeb Ahmad, Umang Pandey, Ashutosh Modi</li>
<li>for: 这篇论文的目的是教育RL算法理解日常生活中的常识知识和自然语言理解能力。</li>
<li>methods: 这篇论文使用了ScriptWorld环境，这是一个基于脚本集的文本基础环境，用于教育RL算法日常生活中的常识知识和自然语言理解能力。RL基线模型&#x2F;代理在Scriptworld环境中进行游戏，并利用预训练语言模型中的特征来解决文本基础环境中的问题。</li>
<li>results: 实验表明，基于预训练语言模型的语言特征可以帮助RL算法解决日常生活中的文本基础环境问题。<details>
<summary>Abstract</summary>
Text-based games provide a framework for developing natural language understanding and commonsense knowledge about the world in reinforcement learning based agents. Existing text-based environments often rely on fictional situations and characters to create a gaming framework and are far from real-world scenarios. In this paper, we introduce ScriptWorld: a text-based environment for teaching agents about real-world daily chores and hence imparting commonsense knowledge. To the best of our knowledge, it is the first interactive text-based gaming framework that consists of daily real-world human activities designed using scripts dataset. We provide gaming environments for 10 daily activities and perform a detailed analysis of the proposed environment. We develop RL-based baseline models/agents to play the games in Scriptworld. To understand the role of language models in such environments, we leverage features obtained from pre-trained language models in the RL agents. Our experiments show that prior knowledge obtained from a pre-trained language model helps to solve real-world text-based gaming environments. We release the environment via Github: https://github.com/Exploration-Lab/ScriptWorld
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Feature-selection-simultaneously-preserving-both-class-and-cluster-structures"><a href="#Feature-selection-simultaneously-preserving-both-class-and-cluster-structures" class="headerlink" title="Feature selection simultaneously preserving both class and cluster structures"></a>Feature selection simultaneously preserving both class and cluster structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03902">http://arxiv.org/abs/2307.03902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suchismita Das, Nikhil R. Pal</li>
<li>for: 本研究的目的是提出一种能同时考虑分类和归类结构的特征选择方法，以提高分类和归类性能。</li>
<li>methods: 本研究使用神经网络来实现特征选择，同时考虑分类和归类结构的保持。</li>
<li>results: 实验结果表明，提议的特征&#x2F;带选择方法可以选择一 subset of 特征，这些特征是良好的分类和归类。<details>
<summary>Abstract</summary>
When a data set has significant differences in its class and cluster structure, selecting features aiming only at the discrimination of classes would lead to poor clustering performance, and similarly, feature selection aiming only at preserving cluster structures would lead to poor classification performance. To the best of our knowledge, a feature selection method that simultaneously considers class discrimination and cluster structure preservation is not available in the literature. In this paper, we have tried to bridge this gap by proposing a neural network-based feature selection method that focuses both on class discrimination and structure preservation in an integrated manner. In addition to assessing typical classification problems, we have investigated its effectiveness on band selection in hyperspectral images. Based on the results of the experiments, we may claim that the proposed feature/band selection can select a subset of features that is good for both classification and clustering.
</details>
<details>
<summary>摘要</summary>
当数据集具有显著的类和差异结构时，仅仅选择用于分类的特征会导致群集性能差，而仅仅保持群集结构的特征选择也会导致分类性能差。据我们所知，Literature中没有一种同时考虑类分化和群集结构保持的特征选择方法。在这篇论文中，我们尝试了bridging这个差距，提出了基于神经网络的特征选择方法，该方法同时考虑类分化和群集结构保持。除了评估典型的分类问题之外，我们还对带选择在多spectral图像进行了研究。根据实验结果，我们可以确认，我们提议的特征/带选择方法可以选择一个良好的分类和群集结构的子集。
</details></li>
</ul>
<hr>
<h2 id="Active-Learning-in-Physics-From-101-to-Progress-and-Perspective"><a href="#Active-Learning-in-Physics-From-101-to-Progress-and-Perspective" class="headerlink" title="Active Learning in Physics: From 101, to Progress, and Perspective"></a>Active Learning in Physics: From 101, to Progress, and Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03899">http://arxiv.org/abs/2307.03899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongcheng Ding, José D. Martín-Guerrero, Yolanda Vives-Gilabert, Xi Chen</li>
<li>for: 这篇论文主要是为了介绍活动学习（AL），包括它的理论和最新进展。</li>
<li>methods: 这篇论文使用了 iterate 选择无标示样本，并由专家进行标注。这种协议可以帮助模型性能更高，比训练所有标记样本。</li>
<li>results: 这篇论文提出了将活动学习与量子机器学习（QL）融合的想法，以实现这两个领域之间的共融。<details>
<summary>Abstract</summary>
Active Learning (AL) is a family of machine learning (ML) algorithms that predates the current era of artificial intelligence. Unlike traditional approaches that require labeled samples for training, AL iteratively selects unlabeled samples to be annotated by an expert. This protocol aims to prioritize the most informative samples, leading to improved model performance compared to training with all labeled samples. In recent years, AL has gained increasing attention, particularly in the field of physics. This paper presents a comprehensive and accessible introduction to the theory of AL reviewing the latest advancements across various domains. Additionally, we explore the potential integration of AL with quantum ML, envisioning a synergistic fusion of these two fields rather than viewing AL as a mere extension of classical ML into the quantum realm.
</details>
<details>
<summary>摘要</summary>
aktiv learning (AL) 是一家机器学习（ML）算法家族，比现代人工智能更早出现。不同于传统的方法，AL 在训练过程中不需要标注样本，而是逐渐选择无标注样本，由专家进行标注。这个协议的目的是优化模型性能，与全部标注样本训练相比。在最近几年，AL 在物理领域获得了越来越多的注意，特别是在物理领域。这篇论文提供了 AL 的完整和可访问的理论介绍，同时还探讨了 AL 与量子 ML 的可能的集成，而不是视 AL 为класси ML 在量子世界的扩展。
</details></li>
</ul>
<hr>
<h2 id="Incomplete-Utterance-Rewriting-as-Sequential-Greedy-Tagging"><a href="#Incomplete-Utterance-Rewriting-as-Sequential-Greedy-Tagging" class="headerlink" title="Incomplete Utterance Rewriting as Sequential Greedy Tagging"></a>Incomplete Utterance Rewriting as Sequential Greedy Tagging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.06337">http://arxiv.org/abs/2307.06337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunshan Chen</li>
<li>for: 这个论文主要是为了解决 incomplete utterance rewriting 问题，即在对话中提取信息的问题。</li>
<li>methods: 这个模型使用 sequence tagging 方法，可以更好地从对话中提取信息。此外，我们还引入了 speaker-aware embedding，以模型说话人的变化。</li>
<li>results: 我们的模型在多个公共数据集上实现了最佳的 nine restoration scores，而其他 metric scores 与之前的状态OF-the-art模型相比可观。此外，由于我们的模型简单，在推理速度方面也超过了大多数之前的模型。<details>
<summary>Abstract</summary>
The task of incomplete utterance rewriting has recently gotten much attention. Previous models struggled to extract information from the dialogue context, as evidenced by the low restoration scores. To address this issue, we propose a novel sequence tagging-based model, which is more adept at extracting information from context. Meanwhile, we introduce speaker-aware embedding to model speaker variation. Experiments on multiple public datasets show that our model achieves optimal results on all nine restoration scores while having other metric scores comparable to previous state-of-the-art models. Furthermore, benefitting from the model's simplicity, our approach outperforms most previous models on inference speed.
</details>
<details>
<summary>摘要</summary>
“ incomplete utterance rewriting ”在最近已经获得了很多注意。以前的模型很难从对话 контекст中提取信息，这可以见到低恢复得分。为解决这个问题，我们提议一个新的序列标签基于模型，这个模型更能够从 контекст中提取信息。同时，我们引入了Speaker-aware embedding来模型说话者的变化。多个公共数据集上的实验表明，我们的模型在所有九个恢复得分上取得了最佳结果，而其他指标得分与过往最佳模型相近。此外，由于我们的方法简单，我们的方法在推理速度方面超越了大多数前一代模型。
</details></li>
</ul>
<hr>
<h2 id="Improving-Prototypical-Part-Networks-with-Reward-Reweighing-Reselection-and-Retraining"><a href="#Improving-Prototypical-Part-Networks-with-Reward-Reweighing-Reselection-and-Retraining" class="headerlink" title="Improving Prototypical Part Networks with Reward Reweighing, Reselection, and Retraining"></a>Improving Prototypical Part Networks with Reward Reweighing, Reselection, and Retraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03887">http://arxiv.org/abs/2307.03887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robin Netzorg, Jiaxun Li, Bin Yu</li>
<li>for: 该paper aimed to improve the interpretability of deep learning models for image classification by using human feedback to fine-tune the prototypes.</li>
<li>methods: 该paper proposed a novel method called R3-ProtoPNet, which combines reward-based reweighting, reselection, and retraining to align the model’s features with the updated prototypes.</li>
<li>results: 该paper found that R3-ProtoPNet improves the overall consistency and meaningfulness of the prototypes, but lower the test predictive accuracy when used independently. However, when multiple R3-ProtoPNets are incorporated into an ensemble, the test predictive performance is increased while maintaining interpretability.<details>
<summary>Abstract</summary>
In recent years, work has gone into developing deep interpretable methods for image classification that clearly attributes a model's output to specific features of the data. One such of these methods is the prototypical part network (ProtoPNet), which attempts to classify images based on meaningful parts of the input. While this method results in interpretable classifications, this method often learns to classify from spurious or inconsistent parts of the image. Hoping to remedy this, we take inspiration from the recent developments in Reinforcement Learning with Human Feedback (RLHF) to fine-tune these prototypes. By collecting human annotations of prototypes quality via a 1-5 scale on the CUB-200-2011 dataset, we construct a reward model that learns to identify non-spurious prototypes. In place of a full RL update, we propose the reweighted, reselected, and retrained prototypical part network (R3-ProtoPNet), which adds an additional three steps to the ProtoPNet training loop. The first two steps are reward-based reweighting and reselection, which align prototypes with human feedback. The final step is retraining to realign the model's features with the updated prototypes. We find that R3-ProtoPNet improves the overall consistency and meaningfulness of the prototypes, but lower the test predictive accuracy when used independently. When multiple R3-ProtoPNets are incorporated into an ensemble, we find an increase in test predictive performance while maintaining interpretability.
</details>
<details>
<summary>摘要</summary>
recent years, work has gone into developing deep interpretable methods for image classification that clearly attributes a model's output to specific features of the data. One such of these methods is the prototypical part network (ProtoPNet), which attempts to classify images based on meaningful parts of the input. While this method results in interpretable classifications, this method often learns to classify from spurious or inconsistent parts of the image. Hoping to remedy this, we take inspiration from the recent developments in Reinforcement Learning with Human Feedback (RLHF) to fine-tune these prototypes. By collecting human annotations of prototypes quality via a 1-5 scale on the CUB-200-2011 dataset, we construct a reward model that learns to identify non-spurious prototypes. In place of a full RL update, we propose the reweighted, reselected, and retrained prototypical part network (R3-ProtoPNet), which adds an additional three steps to the ProtoPNet training loop. The first two steps are reward-based reweighting and reselection, which align prototypes with human feedback. The final step is retraining to realign the model's features with the updated prototypes. We find that R3-ProtoPNet improves the overall consistency and meaningfulness of the prototypes, but lower the test predictive accuracy when used independently. When multiple R3-ProtoPNets are incorporated into an ensemble, we find an increase in test predictive performance while maintaining interpretability.Here's the translation in Traditional Chinese:在近年来，有很多工作在开发深度可解释的图像分类方法，以将模型的输出明确地对对应的资料特征进行推导。一个如此方法是 прототипіаль部分网络（ProtoPNet），它尝试根据输入图像的意义部分进行分类。although this method results in interpretable classifications, this method often learns to classify from spurious or inconsistent parts of the image. hoping to remedy this, we take inspiration from the recent developments in Reinforcement Learning with Human Feedback (RLHF) to fine-tune these prototypes. by collecting human annotations of prototypes quality via a 1-5 scale on the CUB-200-2011 dataset, we construct a reward model that learns to identify non-spurious prototypes. in place of a full RL update, we propose the reweighted, reselected, and retrained prototypical part network (R3-ProtoPNet), which adds an additional three steps to the ProtoPNet training loop. the first two steps are reward-based reweighting and reselection, which align prototypes with human feedback. the final step is retraining to realign the model's features with the updated prototypes. we find that R3-ProtoPNet improves the overall consistency and meaningfulness of the prototypes, but lower the test predictive accuracy when used independently. when multiple R3-ProtoPNets are incorporated into an ensemble, we find an increase in test predictive performance while maintaining interpretability.
</details></li>
</ul>
<hr>
<h2 id="On-Regularization-and-Inference-with-Label-Constraints"><a href="#On-Regularization-and-Inference-with-Label-Constraints" class="headerlink" title="On Regularization and Inference with Label Constraints"></a>On Regularization and Inference with Label Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03886">http://arxiv.org/abs/2307.03886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaifu Wang, Hangfeng He, Tin D. Nguyen, Piyush Kumar, Dan Roth</li>
<li>for: 这个论文主要针对的是机器学习中的约束问题，具体来说是在结构预测问题中表达约束的方法。</li>
<li>methods: 论文使用了两种常见的约束编码策略，即常规化和约束推理，并对它们在机器学习管道中的影响进行了评估。</li>
<li>results: 论文表明，正则化可以减少泛化差距，但是它会偏好小违反，导致模型偏离优质点。而受约束推理则可以降低人口风险，从而使得违反变成了优势。因此，论文建议在使用这两种方法时，可以共同使用它们，并在某些条件下使用约束推理来补偿正则化引入的偏见。<details>
<summary>Abstract</summary>
Prior knowledge and symbolic rules in machine learning are often expressed in the form of label constraints, especially in structured prediction problems. In this work, we compare two common strategies for encoding label constraints in a machine learning pipeline, regularization with constraints and constrained inference, by quantifying their impact on model performance. For regularization, we show that it narrows the generalization gap by precluding models that are inconsistent with the constraints. However, its preference for small violations introduces a bias toward a suboptimal model. For constrained inference, we show that it reduces the population risk by correcting a model's violation, and hence turns the violation into an advantage. Given these differences, we further explore the use of two approaches together and propose conditions for constrained inference to compensate for the bias introduced by regularization, aiming to improve both the model complexity and optimal risk.
</details>
<details>
<summary>摘要</summary>
Prior knowledge和符号规则在机器学习中经常表达为标签约束，特别是在结构预测问题中。在这项工作中，我们比较了两种常见的标签约束编码策略在机器学习管道中的影响，即规范减少和受约束的推理。对于规范，我们表明了它可以防止模型与约束不一致的情况，从而缩小泛化差。但是，它会偏好小规模的违反，导致模型偏好一个不佳的模型。对于受约束推理，我们表明了它可以降低人口风险，通过约束违反的修正，使违反变成一个优势。基于这些差异，我们进一步探索了两种方法的同时使用，并提出了限制推理可以资COMPENSATE FOR THE BIAS INTRODUCED BY REGULARIZATION，以提高模型复杂度和优化风险。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Tensor-Ring-approximation-for-computing-gradients-of-Variational-Quantum-Eigensolver-for-Combinatorial-Optimization"><a href="#Noisy-Tensor-Ring-approximation-for-computing-gradients-of-Variational-Quantum-Eigensolver-for-Combinatorial-Optimization" class="headerlink" title="Noisy Tensor Ring approximation for computing gradients of Variational Quantum Eigensolver for Combinatorial Optimization"></a>Noisy Tensor Ring approximation for computing gradients of Variational Quantum Eigensolver for Combinatorial Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03884">http://arxiv.org/abs/2307.03884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dheeraj Peddireddy, Utkarsh Priyam, Vaneet Aggarwal</li>
<li>for: 提高量子 approximate optimization 和量子对角化器（VQE）的可扩展性，突破分类势能 Computational complexity limit.</li>
<li>methods: 提议一种类别计算方法，利用参数移位规则，从环形矩阵中计算期望值，使用二元位卷积矩阵来表示环形矩阵的变换。</li>
<li>results: 比较分类计算和量子计算的复杂度，显示这种方法可以减少分类计算的复杂度，使其可以更快地评估量子算法的梯度。<details>
<summary>Abstract</summary>
Variational Quantum algorithms, especially Quantum Approximate Optimization and Variational Quantum Eigensolver (VQE) have established their potential to provide computational advantage in the realm of combinatorial optimization. However, these algorithms suffer from classically intractable gradients limiting the scalability. This work addresses the scalability challenge for VQE by proposing a classical gradient computation method which utilizes the parameter shift rule but computes the expected values from the circuits using a tensor ring approximation. The parametrized gates from the circuit transform the tensor ring by contracting the matrix along the free edges of the tensor ring. While the single qubit gates do not alter the ring structure, the state transformations from the two qubit rotations are evaluated by truncating the singular values thereby preserving the structure of the tensor ring and reducing the computational complexity. This variation of the Matrix product state approximation grows linearly in number of qubits and the number of two qubit gates as opposed to the exponential growth in the classical simulations, allowing for a faster evaluation of the gradients on classical simulators.
</details>
<details>
<summary>摘要</summary>
“精简量子算法，尤其是量子近似优化和量子对角器（VQE），已经证明了它们在排序问题中的计算优势。然而，这些算法受到古典无法计算的梯度所限制，这使得扩展性受到挑战。本工作解决了VQE的扩展性问题，提出一种古典梯度计算方法，利用参数移动规则，并从图静态环节中计算出预期值。图静态环节中的参数门由图静态环节中的矩阵折缩，单位门不改变环节结构，但两个量子矩阵的状态转换则被舒缓，以保持环节结构并降低计算复杂性。这种矩阵产品state的扩展增长Linearly在量子矩阵中，相比之下，古典 simulations中的扩展增长 exponential，使得在古典 simulators 上较快地评估梯度。”
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-for-Supply-Chain-Optimization"><a href="#Large-Language-Models-for-Supply-Chain-Optimization" class="headerlink" title="Large Language Models for Supply Chain Optimization"></a>Large Language Models for Supply Chain Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03875">http://arxiv.org/abs/2307.03875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan Pathuri, Ishai Menache</li>
<li>for: The paper is written for supply chain operators and managers who need to interpret and explain the outcomes of optimization algorithms to stakeholders.</li>
<li>methods: The paper proposes a framework called OptiGuide that leverages Large Language Models (LLMs) to provide insights into the underlying optimization outcomes. The framework accepts queries in plain text and outputs explanations of the optimization results without requiring the transfer of proprietary data to the LLM.</li>
<li>results: The paper demonstrates the effectiveness of OptiGuide on a real server placement scenario within Microsoft’s cloud supply chain. The results show that OptiGuide can provide accurate explanations of the optimization outcomes, and the proposed evaluation benchmark can be used to evaluate the accuracy of the LLM output in other scenarios.<details>
<summary>Abstract</summary>
Supply chain operations traditionally involve a variety of complex decision making problems. Over the last few decades, supply chains greatly benefited from advances in computation, which allowed the transition from manual processing to automation and cost-effective optimization. Nonetheless, business operators still need to spend substantial efforts in explaining and interpreting the optimization outcomes to stakeholders. Motivated by the recent advances in Large Language Models (LLMs), we study how this disruptive technology can help bridge the gap between supply chain automation and human comprehension and trust thereof. We design OptiGuide -- a framework that accepts as input queries in plain text, and outputs insights about the underlying optimization outcomes. Our framework does not forgo the state-of-the-art combinatorial optimization technology, but rather leverages it to quantitatively answer what-if scenarios (e.g., how would the cost change if we used supplier B instead of supplier A for a given demand?). Importantly, our design does not require sending proprietary data over to LLMs, which can be a privacy concern in some circumstances. We demonstrate the effectiveness of our framework on a real server placement scenario within Microsoft's cloud supply chain. Along the way, we develop a general evaluation benchmark, which can be used to evaluate the accuracy of the LLM output in other scenarios.
</details>
<details>
<summary>摘要</summary>
供应链运营传统上涉及到许多复杂的决策问题。过去几十年，供应链受计算技术的进步所助，从人工处理过渡到自动化和成本效果优化。然而，业务运营者仍需投入很大的努力来解释和理解优化结果，以获得投资者和客户的信任。鼓励于最近的大语言模型（LLM）技术的进步，我们研究如何使用这种破坏技术来bridging供应链自动化和人类理解之间的差距。我们设计了OptiGuide框架，它可以接受普通文本查询，并输出供应链优化结果的概念。我们的框架不会抛弃现有的组合优化技术，而是利用它们来回答什么时候的问题（例如，如果使用供应商B而不是供应商A来满足某个需求时，成本会如何变化？）。重要的是，我们的设计不需要将专有数据传递到LLM中，这可能会在某些情况下成为隐私问题。我们在微软云供应链中进行了实际的服务分配enario，并在过程中开发了一个通用评估标准，可以用于评估其他场景中LLM输出的准确性。
</details></li>
</ul>
<hr>
<h2 id="Domain-Adaptation-using-Silver-Standard-Labels-for-Ki-67-Scoring-in-Digital-Pathology-A-Step-Closer-to-Widescale-Deployment"><a href="#Domain-Adaptation-using-Silver-Standard-Labels-for-Ki-67-Scoring-in-Digital-Pathology-A-Step-Closer-to-Widescale-Deployment" class="headerlink" title="Domain Adaptation using Silver Standard Labels for Ki-67 Scoring in Digital Pathology: A Step Closer to Widescale Deployment"></a>Domain Adaptation using Silver Standard Labels for Ki-67 Scoring in Digital Pathology: A Step Closer to Widescale Deployment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03872">http://arxiv.org/abs/2307.03872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amanda Dy, Ngoc-Nhu Jennifer Nguyen, Seyed Hossein Mirjahanmardi, Melanie Dawe, Anthony Fyles, Wei Shi, Fei-Fei Liu, Dimitrios Androutsos, Susan Done, April Khademi<br>for: 这个研究旨在提高 Ki-67 PI 分配的 объектив性和效率，使用深度学习系统。methods: 该研究提出了一个领域适应管道，使用无监督框架生成目标领域的银标签，以增强源频率银标签数据的学习效果。results: 比较 SS Only、GS Only、Mixed、GS+SS 和我们的提议方法 SS+GS 的五种训练方案，SS+GS 方法在目标数据上显示出最高的 PI 准确率（95.9%）和更一致的结果，与 GS Only 模型在目标数据上的表现有 statistically significant difference（p &lt; 0.05）。<details>
<summary>Abstract</summary>
Deep learning systems have been proposed to improve the objectivity and efficiency of Ki- 67 PI scoring. The challenge is that while very accurate, deep learning techniques suffer from reduced performance when applied to out-of-domain data. This is a critical challenge for clinical translation, as models are typically trained using data available to the vendor, which is not from the target domain. To address this challenge, this study proposes a domain adaptation pipeline that employs an unsupervised framework to generate silver standard (pseudo) labels in the target domain, which is used to augment the gold standard (GS) source domain data. Five training regimes were tested on two validated Ki-67 scoring architectures (UV-Net and piNET), (1) SS Only: trained on target silver standard (SS) labels, (2) GS Only: trained on source GS labels, (3) Mixed: trained on target SS and source GS labels, (4) GS+SS: trained on source GS labels and fine-tuned on target SS labels, and our proposed method (5) SS+GS: trained on source SS labels and fine-tuned on source GS labels. The SS+GS method yielded significantly (p < 0.05) higher PI accuracy (95.9%) and more consistent results compared to the GS Only model on target data. Analysis of t-SNE plots showed features learned by the SS+GS models are more aligned for source and target data, resulting in improved generalization. The proposed pipeline provides an efficient method for learning the target distribution without manual annotations, which are time-consuming and costly to generate for medical images. This framework can be applied to any target site as a per-laboratory calibration method, for widescale deployment.
</details>
<details>
<summary>摘要</summary>
深度学习系统已被提议以提高基因67PI分配的 объектив性和效率。然而，深度学习技术在域外数据上表现不佳是一个重要挑战，这是因为模型通常在生产商提供的数据上进行训练，而不是target域的数据。为解决这个挑战，本研究提出了一个适应域pipeline，该pipeline使用了无监督框架生成target域的银标(pseudo)标签，并将其用于增强来自源域的金标(GS)数据。本研究测试了五种训练方案，包括(1) SS Only：基于target银标(SS)标签进行训练，(2) GS Only：基于源GS标签进行训练，(3) Mixed：基于target SS和源GS标签进行训练，(4) GS+SS：基于源GS标签进行训练，并在target SS标签上进行微调，以及我们的提议方法(5) SS+GS：基于源SS标签进行训练，并在源GS标签上进行微调。SS+GS方法在target数据上得到了 statistically significant (p < 0.05) 的PI准确率（95.9%），并且与源数据的结果更一致。分析t-SNE图表显示，SS+GS模型学习的特征更加适应于源和目标数据，导致了改善的总体性。本ipeline提供了一种效率的方法来学习目标分布，不需要手动生成昂贵和时间consuming的医学图像标签。这种框架可以在任何目标站点上应用，作为室内准确方法进行大规模部署。
</details></li>
</ul>
<hr>
<h2 id="When-Do-Transformers-Shine-in-RL-Decoupling-Memory-from-Credit-Assignment"><a href="#When-Do-Transformers-Shine-in-RL-Decoupling-Memory-from-Credit-Assignment" class="headerlink" title="When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment"></a>When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03864">http://arxiv.org/abs/2307.03864</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/twni2016/memory-rl">https://github.com/twni2016/memory-rl</a></li>
<li>paper_authors: Tianwei Ni, Michel Ma, Benjamin Eysenbach, Pierre-Luc Bacon</li>
<li>for: 这种研究旨在解释RL算法中Transformer Architecture的成功原因，以及未来研究和benchmark设计的重要领域。</li>
<li>methods: 该研究使用了Formal definitions of memory length和credit assignment length来测试Transformer-based RL方法的表现。</li>
<li>results: 研究发现，Transformers可以增强RL算法的记忆能力，可以扩展到需要记忆步骤1500个的任务。但是，Transformers不会改善长期归因。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) algorithms face two distinct challenges: learning effective representations of past and present observations, and determining how actions influence future returns. Both challenges involve modeling long-term dependencies. The transformer architecture has been very successful to solve problems that involve long-term dependencies, including in the RL domain. However, the underlying reason for the strong performance of Transformer-based RL methods remains unclear: is it because they learn effective memory, or because they perform effective credit assignment? After introducing formal definitions of memory length and credit assignment length, we design simple configurable tasks to measure these distinct quantities. Our empirical results reveal that Transformers can enhance the memory capacity of RL algorithms, scaling up to tasks that require memorizing observations $1500$ steps ago. However, Transformers do not improve long-term credit assignment. In summary, our results provide an explanation for the success of Transformers in RL, while also highlighting an important area for future research and benchmark design.
</details>
<details>
<summary>摘要</summary>
reinforcement learning (RL) 算法面临两个不同的挑战：学习过去和当前观察的有效表示，以及确定行动对未来返回的影响。两个挑战都涉及到模型长期关系。 transformer 架构在RL领域中具有非常出色的表现，但是下面的原因仍然不清楚：是因为它们学习有效的记忆，或者是因为它们实现有效的准确分配？我们给出了正式的定义 memory length 和 credit assignment length，然后设计了简单可配置的任务来测量这两个特点。我们的实验结果表明，Transformers 可以增强 RL 算法的记忆容量，可以扩展到需要记忆 observation 1500 步的任务。但是，Transformers 不会改善长期准确分配。简单来说，我们的结果可以解释 transformer 在 RL 中的成功，同时也提出了未来研究和标准化的测试设计。
</details></li>
</ul>
<hr>
<h2 id="Memory-Immersed-Collaborative-Digitization-for-Area-Efficient-Compute-in-Memory-Deep-Learning"><a href="#Memory-Immersed-Collaborative-Digitization-for-Area-Efficient-Compute-in-Memory-Deep-Learning" class="headerlink" title="Memory-Immersed Collaborative Digitization for Area-Efficient Compute-in-Memory Deep Learning"></a>Memory-Immersed Collaborative Digitization for Area-Efficient Compute-in-Memory Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03863">http://arxiv.org/abs/2307.03863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamma Nasrin, Maeesha Binte Hashem, Nastaran Darabi, Benjamin Parpillon, Farah Fahim, Wilfred Gomes, Amit Ranjan Trivedi</li>
<li>for: 这个研究旨在提高深度学习推导中的计算效率，通过将compute-in-memory（CiM）阵列用于深度学习推导，以减少外部内存存取和面积开销。</li>
<li>methods: 这个研究使用了内存内部的潜在阻抗bit线来实现area-efficient的successive approximation（SA）数字化，并借由CiM阵列之间的协同运算来实现更多的并行计算和面积优化。</li>
<li>results: 这个研究使用了65奈米CMOS试验板，与40奈米节点5位SAR ADC和40奈米节点5位Flash ADC进行比较，结果显示，这个设计需要相对于40奈米节点SAR ADC的面积和能源减少为$\sim$25$\times$和$\sim$1.4$\times$，相对于40奈米节点Flash ADC的面积和能源减少为$\sim$51$\times$和$\sim$13$\times$。<details>
<summary>Abstract</summary>
This work discusses memory-immersed collaborative digitization among compute-in-memory (CiM) arrays to minimize the area overheads of a conventional analog-to-digital converter (ADC) for deep learning inference. Thereby, using the proposed scheme, significantly more CiM arrays can be accommodated within limited footprint designs to improve parallelism and minimize external memory accesses. Under the digitization scheme, CiM arrays exploit their parasitic bit lines to form a within-memory capacitive digital-to-analog converter (DAC) that facilitates area-efficient successive approximation (SA) digitization. CiM arrays collaborate where a proximal array digitizes the analog-domain product-sums when an array computes the scalar product of input and weights. We discuss various networking configurations among CiM arrays where Flash, SA, and their hybrid digitization steps can be efficiently implemented using the proposed memory-immersed scheme. The results are demonstrated using a 65 nm CMOS test chip. Compared to a 40 nm-node 5-bit SAR ADC, our 65 nm design requires $\sim$25$\times$ less area and $\sim$1.4$\times$ less energy by leveraging in-memory computing structures. Compared to a 40 nm-node 5-bit Flash ADC, our design requires $\sim$51$\times$ less area and $\sim$13$\times$ less energy.
</details>
<details>
<summary>摘要</summary>
In the proposed digitization scheme, CiM arrays utilize their parasitic bit lines to form a within-memory capacitive digital-to-analog converter (DAC) that enables area-efficient successive approximation (SA) digitization. CiM arrays collaborate by digitizing the analog-domain product-sums when one array computes the scalar product of input and weights.The proposed memory-immersed scheme can efficiently implement various networking configurations among CiM arrays, including Flash, SA, and their hybrid digitization steps. The results are demonstrated using a 65 nm CMOS test chip. Compared to a 40 nm-node 5-bit SAR ADC, our 65 nm design requires approximately 25 times less area and 1.4 times less energy. Compared to a 40 nm-node 5-bit Flash ADC, our design requires approximately 51 times less area and 13 times less energy.
</details></li>
</ul>
<hr>
<h2 id="A-Natural-Language-Processing-Approach-to-Malware-Classification"><a href="#A-Natural-Language-Processing-Approach-to-Malware-Classification" class="headerlink" title="A Natural Language Processing Approach to Malware Classification"></a>A Natural Language Processing Approach to Malware Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11032">http://arxiv.org/abs/2307.11032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ritik Mehta, Olha Jurečková, Mark Stamp</li>
<li>for: 本研究旨在提出一种hybrid模型，将隐藏马尔可夫模型（HMM）训练于机器码序列，并将其生成的隐藏状态序列作为各种分类器的特征 vector。</li>
<li>methods: 本研究使用了隐藏马尔可夫模型（HMM）和Random Forests（RF）等多种机器学习和深度学习技术，并将这些技术组合成一种hybrid模型。</li>
<li>results: 研究发现，使用这种NLP基于的方法可以在一个复杂的恶意软件集合上达到最佳效果，HMM-Random Forrest模型在这个集合上得到了最佳结果。<details>
<summary>Abstract</summary>
Many different machine learning and deep learning techniques have been successfully employed for malware detection and classification. Examples of popular learning techniques in the malware domain include Hidden Markov Models (HMM), Random Forests (RF), Convolutional Neural Networks (CNN), Support Vector Machines (SVM), and Recurrent Neural Networks (RNN) such as Long Short-Term Memory (LSTM) networks. In this research, we consider a hybrid architecture, where HMMs are trained on opcode sequences, and the resulting hidden states of these trained HMMs are used as feature vectors in various classifiers. In this context, extracting the HMM hidden state sequences can be viewed as a form of feature engineering that is somewhat analogous to techniques that are commonly employed in Natural Language Processing (NLP). We find that this NLP-based approach outperforms other popular techniques on a challenging malware dataset, with an HMM-Random Forrest model yielding the best results.
</details>
<details>
<summary>摘要</summary>
很多不同的机器学习和深度学习技术已经成功地应用于恶意软件检测和分类。例如，常见的学习技术在恶意软件领域包括隐藏markov模型（HMM）、Random Forests（RF）、卷积神经网络（CNN）、支持向量机器（SVM）和回归神经网络（RNN），如长期短时间记忆网络（LSTM）。在这些研究中，我们考虑了一种混合体系，其中HMM被训练于机器码序列，并将这些训练得到的隐藏状态用作不同的分类器的特征向量。在这种情况下，提取HMM隐藏状态序列可以被视为一种特征工程技术，与自然语言处理（NLP）中常见的技术有一定的相似性。我们发现，这种NLP基于的方法在一个复杂的恶意软件数据集上表现出色，HMM-Random Forrest模型实现了最佳结果。
</details></li>
</ul>
<hr>
<h2 id="Keystroke-Dynamics-for-User-Identification"><a href="#Keystroke-Dynamics-for-User-Identification" class="headerlink" title="Keystroke Dynamics for User Identification"></a>Keystroke Dynamics for User Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05529">http://arxiv.org/abs/2307.05529</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/andreArtelt/KeystrokeDynamicsForUserIdentification">https://github.com/andreArtelt/KeystrokeDynamicsForUserIdentification</a></li>
<li>paper_authors: Atharva Sharma, Martin Jureček, Mark Stamp</li>
<li>for: 这个研究是为了解决用户验证问题，特别是在自由文本数据上。</li>
<li>methods: 这个研究使用了一种复杂的图像Like特征，以及多类型Convolutional Neural Networks来进行用户验证。</li>
<li>results: 这个研究获得了0.78的分类精度（即用户识别率），但是使用Random Forest分类器并不对相似的特征进行轻微修改后，获得了0.93的分类精度。<details>
<summary>Abstract</summary>
In previous research, keystroke dynamics has shown promise for user authentication, based on both fixed-text and free-text data. In this research, we consider the more challenging multiclass user identification problem, based on free-text data. We experiment with a complex image-like feature that has previously been used to achieve state-of-the-art authentication results over free-text data. Using this image-like feature and multiclass Convolutional Neural Networks, we are able to obtain a classification (i.e., identification) accuracy of 0.78 over a set of 148 users. However, we find that a Random Forest classifier trained on a slightly modified version of this same feature yields an accuracy of 0.93.
</details>
<details>
<summary>摘要</summary>
在过去的研究中，键盘动态学已经展示了用户认证的搭配可能性，基于固定文本和自由文本数据。在这项研究中，我们考虑了更加困难的多类用户识别问题，基于自由文本数据。我们尝试使用过去已经用来实现自由文本数据上状态前瞻的复杂图像类特征。使用这种图像类特征和多类卷积神经网络，我们能够获得一个分类精度（即识别率）为0.78，在148个用户中。然而，我们发现，使用一个基于这个特征的微小修改版本的Random Forest分类器，可以达到0.93的精度。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-and-Deep-Reinforcement-Learning-based-Solutions-for-Machine-Maintenance-Planning-Scheduling-Policies-and-Optimization"><a href="#Reinforcement-and-Deep-Reinforcement-Learning-based-Solutions-for-Machine-Maintenance-Planning-Scheduling-Policies-and-Optimization" class="headerlink" title="Reinforcement and Deep Reinforcement Learning-based Solutions for Machine Maintenance Planning, Scheduling Policies, and Optimization"></a>Reinforcement and Deep Reinforcement Learning-based Solutions for Machine Maintenance Planning, Scheduling Policies, and Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03860">http://arxiv.org/abs/2307.03860</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oluwaseyi Ogunfowora, Homayoun Najjaran</li>
<li>For: This paper reviews the applications of reinforcement and deep reinforcement learning for maintenance planning and optimization problems.* Methods: The paper uses a literature review to identify and categorize existing research on reinforcement learning for maintenance planning, and provides graphical and tabular representations of the adopted methodologies, findings, and interpretations.* Results: The paper highlights research gaps, key insights from the literature, and areas for future work in the field of reinforcement learning for maintenance planning.In Simplified Chinese text, the three information points could be summarized as follows:* For: 本文review了使用强化学习和深度强化学习进行维护规划和优化问题的应用。* Methods: 本文使用文献综述来 indentify和分类现有的强化学习维护规划研究，并提供图形和表格形式的采用方法、发现和解释。* Results: 本文指出了维护规划领域的研究漏洞、文献中的关键发现和未来工作的方向。<details>
<summary>Abstract</summary>
Systems and machines undergo various failure modes that result in machine health degradation, so maintenance actions are required to restore them back to a state where they can perform their expected functions. Since maintenance tasks are inevitable, maintenance planning is essential to ensure the smooth operations of the production system and other industries at large. Maintenance planning is a decision-making problem that aims at developing optimum maintenance policies and plans that help reduces maintenance costs, extend asset life, maximize their availability, and ultimately ensure workplace safety. Reinforcement learning is a data-driven decision-making algorithm that has been increasingly applied to develop dynamic maintenance plans while leveraging the continuous information from condition monitoring of the system and machine states. By leveraging the condition monitoring data of systems and machines with reinforcement learning, smart maintenance planners can be developed, which is a precursor to achieving a smart factory. This paper presents a literature review on the applications of reinforcement and deep reinforcement learning for maintenance planning and optimization problems. To capture the common ideas without losing touch with the uniqueness of each publication, taxonomies used to categorize the systems were developed, and reviewed publications were highlighted, classified, and summarized based on these taxonomies. Adopted methodologies, findings, and well-defined interpretations of the reviewed studies were summarized in graphical and tabular representations to maximize the utility of the work for both researchers and practitioners. This work also highlights the research gaps, key insights from the literature, and areas for future work.
</details>
<details>
<summary>摘要</summary>
系统和机器会经历多种故障模式，导致机器健康下降，因此维护工作是必要的以还原它们到可以执行预期功能的状态。维护工作是不可避免的，因此维护观念是非常重要，以确保生产系统和其他行业的顺畅运行。维护观念是一个决策问题，旨在发展最佳的维护政策和计划，帮助降低维护成本，延长资产寿命，最大化资产可用性，并确保工作安全。对于维护计划和优化问题，很多使用了强化学习，这是一种基于数据驱动的决策推断算法。通过使用系统和机器的状态监控数据和强化学习，可以开发出智能维护观念，这是一个进攻智能厂的先驱。本文将介绍一篇文献综述，探讨对维护计划和优化问题的应用强化学习和深度强化学习的研究。为了捕捉每篇文献的共同主题而不让它们与具体性的区别，则使用了分类系统，并将综述的文献按照这些分类系统进行分类和摘要。采用的方法、发现和实际的解释都是通过图表和表格的形式呈现，以便对研究人员和实践者具有最大的实用性。本文还强调了研究潜在差距、关键见解和未来工作的方向。
</details></li>
</ul>
<hr>
<h2 id="The-Ethical-Implications-of-Generative-Audio-Models-A-Systematic-Literature-Review"><a href="#The-Ethical-Implications-of-Generative-Audio-Models-A-Systematic-Literature-Review" class="headerlink" title="The Ethical Implications of Generative Audio Models: A Systematic Literature Review"></a>The Ethical Implications of Generative Audio Models: A Systematic Literature Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05527">http://arxiv.org/abs/2307.05527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Barnett</li>
<li>for: 本研究写作的目的是实现Generative audio模型的系统性文献综述，以便评估这个领域的研究者是否考虑到可能的负面影响，以及需要考虑的伦理问题。</li>
<li>methods: 本研究使用了884篇Generative audio模型相关的研究文献，通过分析这些文献的内容来评估研究者对可能的负面影响的考虑程度。</li>
<li>results: 研究结果显示，只有少于10%的Generative audio研究文献讨论了可能的负面影响，这是极其罕见的。然而，这些文献中提出的伦理问题和问题是深刻的，例如欺诈、深圳制作和版权侵犯等。本研究这样的缺乏伦理考虑和潜在的负面影响，将是这个领域的未来研究指南。<details>
<summary>Abstract</summary>
Generative audio models typically focus their applications in music and speech generation, with recent models having human-like quality in their audio output. This paper conducts a systematic literature review of 884 papers in the area of generative audio models in order to both quantify the degree to which researchers in the field are considering potential negative impacts and identify the types of ethical implications researchers in this area need to consider. Though 65% of generative audio research papers note positive potential impacts of their work, less than 10% discuss any negative impacts. This jarringly small percentage of papers considering negative impact is particularly worrying because the issues brought to light by the few papers doing so are raising serious ethical implications and concerns relevant to the broader field such as the potential for fraud, deep-fakes, and copyright infringement. By quantifying this lack of ethical consideration in generative audio research and identifying key areas of potential harm, this paper lays the groundwork for future work in the field at a critical point in time in order to guide more conscientious research as this field progresses.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="inTformer-A-Time-Embedded-Attention-Based-Transformer-for-Crash-Likelihood-Prediction-at-Intersections-Using-Connected-Vehicle-Data"><a href="#inTformer-A-Time-Embedded-Attention-Based-Transformer-for-Crash-Likelihood-Prediction-at-Intersections-Using-Connected-Vehicle-Data" class="headerlink" title="inTformer: A Time-Embedded Attention-Based Transformer for Crash Likelihood Prediction at Intersections Using Connected Vehicle Data"></a>inTformer: A Time-Embedded Attention-Based Transformer for Crash Likelihood Prediction at Intersections Using Connected Vehicle Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03854">http://arxiv.org/abs/2307.03854</a></li>
<li>repo_url: None</li>
<li>paper_authors: B. M. Tazbiul Hassan Anik, Zubayer Islam, Mohamed Abdel-Aty</li>
<li>for: 预测交叉点事故可能性的实时预测模型，帮助提高交通安全性。</li>
<li>methods: 使用Transformer模型，通过注意力机制来处理数据序列，并且可以同时处理所有数据元素 durante training。</li>
<li>results: 在使用INRIX和CATT Lab的信号分析平台上测试的connected vehicle数据上，提出了一个名为inTformer的时间嵌入注意力基于Transformer模型，可以效果地预测交叉点事故可能性。最佳inTformer模型达到了73%的敏感性。<details>
<summary>Abstract</summary>
The real-time crash likelihood prediction model is an essential component of the proactive traffic safety management system. Over the years, numerous studies have attempted to construct a crash likelihood prediction model in order to enhance traffic safety, but mostly on freeways. In the majority of the existing studies, researchers have primarily employed a deep learning-based framework to identify crash potential. Lately, Transformer has emerged as a potential deep neural network that fundamentally operates through attention-based mechanisms. Transformer has several functional benefits over extant deep learning models such as Long Short-Term Memory (LSTM), Convolution Neural Network (CNN), etc. Firstly, Transformer can readily handle long-term dependencies in a data sequence. Secondly, Transformers can parallelly process all elements in a data sequence during training. Finally, a Transformer does not have the vanishing gradient issue. Realizing the immense possibility of Transformers, this paper proposes inTersection-Transformer (inTformer), a time-embedded attention-based Transformer model that can effectively predict intersection crash likelihood in real-time. The proposed model was evaluated using connected vehicle data extracted from INRIX and Center for Advanced Transportation Technology (CATT) Lab's Signal Analytics Platform. The data was parallelly formatted and stacked at different timesteps to develop nine inTformer models. The best inTformer model achieved a sensitivity of 73%. This model was also compared to earlier studies on crash likelihood prediction at intersections and with several established deep learning models trained on the same connected vehicle dataset. In every scenario, this inTformer outperformed the benchmark models confirming the viability of the proposed inTformer architecture.
</details>
<details>
<summary>摘要</summary>
现实时启发风险预测模型是智能交通安全管理系统的重要组件。过去几年，许多研究都尝试了构建启发风险预测模型，以提高交通安全，但大多数研究都在高速公路上进行。现有的大多数研究者都使用了深度学习框架来识别启发 potential。最近，Transformer 出现了作为深度神经网络的潜在可能，它基于注意力机制来运行。Transformer 与既有的深度学习模型（如 Long Short-Term Memory 和 Convolution Neural Network）相比，具有多种功能优势。首先，Transformer 可以识别长期依赖关系。其次，Transformer 可以并行处理数据序列中的所有元素。最后，Transformer 不受消失梯度问题的影响。鉴于 Transformer 的可能性，本文提出了 intersection-Transformer（inTformer）模型，可以在实时中预测交叉口启发风险。该模型使用 INRIX 和 Center for Advanced Transportation Technology (CATT) Lab 的 Signal Analytics Platform 提供的连接式汽车数据进行评估。数据被平行格式化并堆叠在不同的时间步上，以构建九个 inTformer 模型。最佳 inTformer 模型达到了 73% 的敏感度。这个模型还与其他关于交叉口启发风险预测的研究和已有的深度学习模型在同一个连接式汽车dataset上进行比较。在每种场景下，这个 inTformer 模型都超越了参考模型，证明了提案的 inTformer 架构的可行性。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Learners-for-Realizable-Regression-PAC-Learning-and-Online-Learning"><a href="#Optimal-Learners-for-Realizable-Regression-PAC-Learning-and-Online-Learning" class="headerlink" title="Optimal Learners for Realizable Regression: PAC Learning and Online Learning"></a>Optimal Learners for Realizable Regression: PAC Learning and Online Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03848">http://arxiv.org/abs/2307.03848</a></li>
<li>repo_url: None</li>
<li>paper_authors: Idan Attias, Steve Hanneke, Alkis Kalavasis, Amin Karbasi, Grigoris Velegkas</li>
<li>for: 本文主要研究 realizable 回归的统计复杂性，包括 PAC 学习 Setting 和 online 学习 Setting。</li>
<li>methods: 本文首先提出了一种最优化学习器，并提出了一种新的维度来描述可学习的类别。此外，本文还提出了一种基于 Graph 维度的 ERM 学习性维度，以及一种基于 DS 维度的学习可能性维度。</li>
<li>results: 本文确定了一个必要条件 для学习可能性，并 conjecture 这可能也是充分条件。此外，本文还解决了 Daskalakis 和 Golowich 在 STOC ‘22 中提出的一个开问。<details>
<summary>Abstract</summary>
In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting.   Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in this context.   Additionally, in the context of online learning we provide a dimension that characterizes the minimax instance optimal cumulative loss up to a constant factor and design an optimal online learner for realizable regression, thus resolving an open question raised by Daskalakis and Golowich in STOC '22.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们目标是Characterize realizable regression的统计复杂性在PAC学习设定下和在线学习设定下。previoius work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in this context.  在线学习上，我们提供一个characterizes the minimax instance optimal cumulative loss up to a constant factor的dimension，并设计了一个optimal online learner for realizable regression，thereby resolving an open question raised by Daskalakis and Golowich in STOC '22.
</details></li>
</ul>
<hr>
<h2 id="RADAR-Robust-AI-Text-Detection-via-Adversarial-Learning"><a href="#RADAR-Robust-AI-Text-Detection-via-Adversarial-Learning" class="headerlink" title="RADAR: Robust AI-Text Detection via Adversarial Learning"></a>RADAR: Robust AI-Text Detection via Adversarial Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03838">http://arxiv.org/abs/2307.03838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaomeng Hu, Pin-Yu Chen, Tsung-Yi Ho</li>
<li>for: 本研究的目的是提出一种新的AI-文本检测框架，以便在LLMs技术的进步和ChatGPT-like应用的普及之下，更好地分辨人工生成的文本和机器生成的文本。</li>
<li>methods: 本研究使用的方法是基于对抗学习的RADAR框架，它共同培训了一个Robust AI-text Detector和一个paraphraser。paraphraser的目的是生成真实的内容，以逃脱AI-文本检测。RADAR使用检测器的反馈来更新paraphraser，并 vice versa。</li>
<li>results: 对8种LLMs（Pythia、Dolly 2.0、Palmyra、Camel、GPT-J、Dolly 1.0、LLaMA、Vicuna）在4个dataset上进行了实验，结果显示，RADARsignificantly outperforms现有的AI-文本检测方法，特别是在paraphrasing存在时。此外，我们还发现RADAR在instruction-tuned LLMs上 Transferability 强，并且通过GPT-3.5进行评估，发现RADAR的改进能力。<details>
<summary>Abstract</summary>
Recent advances in large language models (LLMs) and the intensifying popularity of ChatGPT-like applications have blurred the boundary of high-quality text generation between humans and machines. However, in addition to the anticipated revolutionary changes to our technology and society, the difficulty of distinguishing LLM-generated texts (AI-text) from human-generated texts poses new challenges of misuse and fairness, such as fake content generation, plagiarism, and false accusation of innocent writers. While existing works show that current AI-text detectors are not robust to LLM-based paraphrasing, this paper aims to bridge this gap by proposing a new framework called RADAR, which jointly trains a Robust AI-text Detector via Adversarial leaRning. RADAR is based on adversarial training of a paraphraser and a detector. The paraphraser's goal is to generate realistic contents to evade AI-text detection. RADAR uses the feedback from the detector to update the paraphraser, and vice versa. Evaluated with 8 different LLMs (Pythia, Dolly 2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna) across 4 datasets, experimental results show that RADAR significantly outperforms existing AI-text detection methods, especially when paraphrasing is in place. We also identify the strong transferability of RADAR from instruction-tuned LLMs to other LLMs, and evaluate the improved capability of RADAR via GPT-3.5.
</details>
<details>
<summary>摘要</summary>
RADAR is based on adversarial training of a paraphraser and a detector. The paraphraser's goal is to generate realistic contents to evade AI-text detection, while the detector's goal is to correctly identify AI-generated texts. RADAR uses the feedback from the detector to update the paraphraser, and vice versa. The framework was evaluated with 8 different LLMs (Pythia, Dolly 2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna) across 4 datasets, and the results show that RADAR significantly outperforms existing AI-text detection methods, especially when paraphrasing is involved. Additionally, RADAR was found to have strong transferability from instruction-tuned LLMs to other LLMs, and its capability was improved further via GPT-3.5.
</details></li>
</ul>
<hr>
<h2 id="Effect-of-Intensity-Standardization-on-Deep-Learning-for-WML-Segmentation-in-Multi-Centre-FLAIR-MRI"><a href="#Effect-of-Intensity-Standardization-on-Deep-Learning-for-WML-Segmentation-in-Multi-Centre-FLAIR-MRI" class="headerlink" title="Effect of Intensity Standardization on Deep Learning for WML Segmentation in Multi-Centre FLAIR MRI"></a>Effect of Intensity Standardization on Deep Learning for WML Segmentation in Multi-Centre FLAIR MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03827">http://arxiv.org/abs/2307.03827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdollah Ghazvanchahi, Pejman Jahbedar Maralani, Alan R. Moody, April Khademi</li>
<li>for: 这个论文是为了提高白 matter lesion（WML） segmentation在magnetic resonance imaging（MRI）中的性能而写的。</li>
<li>methods: 这篇论文使用了多种INTENSITY STANDARDIZATION方法来进行MRI数据的预处理，以提高WML segmentation的性能。其中包括IAMLAB方法，以及其他流行的normalization技术，如White-strip、Nyul和Z-score。</li>
<li>results: 结果表明，IAMLAB和Ensemble方法在不同的lesion category中均有更高的WML segmentation性能，比如原始数据或其他normalization方法。IAMLAB和Ensemble方法在各种lesion category中都有最高的dice similarity coefficient（DSC），并且在不同的临床数据集中也具有最高的DSC。这些方法可以减轻MRI领域的差异，并且是适用于DL-based WML segmentation的优选方法。<details>
<summary>Abstract</summary>
Deep learning (DL) methods for white matter lesion (WML) segmentation in MRI suffer a reduction in performance when applied on data from a scanner or centre that is out-of-distribution (OOD) from the training data. This is critical for translation and widescale adoption, since current models cannot be readily applied to data from new institutions. In this work, we evaluate several intensity standardization methods for MRI as a preprocessing step for WML segmentation in multi-centre Fluid-Attenuated Inversion Recovery (FLAIR) MRI. We evaluate a method specifically developed for FLAIR MRI called IAMLAB along with other popular normalization techniques such as White-strip, Nyul and Z-score. We proposed an Ensemble model that combines predictions from each of these models. A skip-connection UNet (SC UNet) was trained on the standardized images, as well as the original data and segmentation performance was evaluated over several dimensions. The training (in-distribution) data consists of a single study, of 60 volumes, and the test (OOD) data is 128 unseen volumes from three clinical cohorts. Results show IAMLAB and Ensemble provide higher WML segmentation performance compared to models from original data or other normalization methods. IAMLAB & Ensemble have the highest dice similarity coefficient (DSC) on the in-distribution data (0.78 & 0.80) and on clinical OOD data. DSC was significantly higher for IAMLAB compared to the original data (p<0.05) for all lesion categories (LL>25mL: 0.77 vs. 0.71; 10mL<= LL<25mL: 0.66 vs. 0.61; LL<10mL: 0.53 vs. 0.52). The IAMLAB and Ensemble normalization methods are mitigating MRI domain shift and are optimal for DL-based WML segmentation in unseen FLAIR data.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）方法 для白 matter损害（WML）分割在MRI中受到外部数据集（OOD）的影响，导致性能下降。这对于翻译和大规模应用而言是关键，因为现有的模型无法直接应用于新机构的数据集。在这项工作中，我们评估了多种MRIIntensity标准化方法作为WML分割前的预处理步骤。我们评估了特定 дляFLAIR MRI的IAMLAB方法，以及其他流行的标准化技术，如白带、恩琴和Z-score。我们提出了一种组合这些模型的ensemble模型。一个skip-connection UNet（SC UNNet）在标准化图像上进行训练，以及原始数据上进行分割性能的评估。训练（卷积）数据集包括60个Volume，测试（OOD）数据集包括128个未看过的Volume从三个临床各类数据集。结果显示，IAMLAB和Ensemble模型在WML分割性能方面比原始数据或其他标准化方法高得多。IAMLAB和Ensemble模型在卷积数据集（卷积数据）上的DSC值分别为0.78和0.80，并在临床OOD数据上达到了最高的DSC值（0.77和0.80）。对于所有损害类别（LL>25mL：0.77 vs. 0.71；10mL≤ LL<25mL：0.66 vs. 0.61；LL<10mL：0.53 vs. 0.52），IAMLAB模型的DSC值与原始数据相比有 statistically significant difference（P<0.05）。IAMLAB和Ensemble normalization方法可以 Mitigate MRI域shift，是适用于DL基于WML分割的优选方案。
</details></li>
</ul>
<hr>
<h2 id="A-Combinatorial-Characterization-of-Online-Learning-Games-with-Bounded-Losses"><a href="#A-Combinatorial-Characterization-of-Online-Learning-Games-with-Bounded-Losses" class="headerlink" title="A Combinatorial Characterization of Online Learning Games with Bounded Losses"></a>A Combinatorial Characterization of Online Learning Games with Bounded Losses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03816">http://arxiv.org/abs/2307.03816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vinod Raman, Unique Subedi, Ambuj Tewari</li>
<li>for: 学习假设集的在线学习性能对于任意、但是有界的损失函数</li>
<li>methods: 使用新的渐进敏感 combinatorial 维度——顺序最小最大维度，对于在线学习性能进行数量化定量Characterization</li>
<li>results: 在vector-valued regression和多标签分类两个自然的学习设定中，得到了第一个量化的在线学习性能Characterization<details>
<summary>Abstract</summary>
We study the online learnability of hypothesis classes with respect to arbitrary, but bounded, loss functions. We give a new scale-sensitive combinatorial dimension, named the sequential Minimax dimension, and show that it gives a tight quantitative characterization of online learnability. As applications, we give the first quantitative characterization of online learnability for two natural learning settings: vector-valued regression and multilabel classification.
</details>
<details>
<summary>摘要</summary>
我们研究在使用各种固定但受限的损失函数时，假设集合在线学习的可学习性。我们提出了一种新的敏感度量，称为顺序最小最大维度，并证明它为在线学习的准确量提供了紧跟的量化特征化。我们还应用到了两个自然的学习场景：向量值回归和多类分类。
</details></li>
</ul>
<hr>
<h2 id="Controlling-Chaotic-Maps-using-Next-Generation-Reservoir-Computing"><a href="#Controlling-Chaotic-Maps-using-Next-Generation-Reservoir-Computing" class="headerlink" title="Controlling Chaotic Maps using Next-Generation Reservoir Computing"></a>Controlling Chaotic Maps using Next-Generation Reservoir Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03813">http://arxiv.org/abs/2307.03813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert M. Kent, Wendson A. S. Barbosa, Daniel J. Gauthier</li>
<li>for: 这个论文是为了研究非线性系统控制技术和下一代潜在 computing 之间的结合。</li>
<li>methods: 论文使用了非线性系统控制技术和下一代潜在 computing 来预测动力系统的行为。</li>
<li>results: 论文在一系列控制任务中展示了控制器的性能，包括控制系统 между不稳定的固定点、稳定系统到更高阶 периодических轨迹、和到一个指定的状态。 论文还表明了控制器只需要10个数据点进行训练，可以在一次迭代中控制系统到指定的轨迹，并且对噪音和模型误差 Displaytext 有 robustness。<details>
<summary>Abstract</summary>
In this work, we combine nonlinear system control techniques with next-generation reservoir computing, a best-in-class machine learning approach for predicting the behavior of dynamical systems. We demonstrate the performance of the controller in a series of control tasks for the chaotic H\'enon map, including controlling the system between unstable fixed-points, stabilizing the system to higher order periodic orbits, and to an arbitrary desired state. We show that our controller succeeds in these tasks, requires only 10 data points for training, can control the system to a desired trajectory in a single iteration, and is robust to noise and modeling error.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们将非线性系统控制技术与下一代散射 computing（一种最佳级机器学习方法）结合使用，用于预测动力系统的行为。我们在哈农地图中进行了一系列控制任务，包括控制系统在不稳定的固定点上，稳定系统到更高阶 periodic orbit 以及到任意所希望的状态。我们发现，我们的控制器在这些任务中具有出色的表现，只需要10个数据点进行训练，可以在单次迭代中控制系统到所希望的轨迹，并具有噪声和模型误差的抗性。
</details></li>
</ul>
<hr>
<h2 id="For-Women-Life-Freedom-A-Participatory-AI-Based-Social-Web-Analysis-of-a-Watershed-Moment-in-Iran’s-Gender-Struggles"><a href="#For-Women-Life-Freedom-A-Participatory-AI-Based-Social-Web-Analysis-of-a-Watershed-Moment-in-Iran’s-Gender-Struggles" class="headerlink" title="For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis of a Watershed Moment in Iran’s Gender Struggles"></a>For Women, Life, Freedom: A Participatory AI-Based Social Web Analysis of a Watershed Moment in Iran’s Gender Struggles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03764">http://arxiv.org/abs/2307.03764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adel Khorramrouz, Sujan Dutta, Ashiqur R. KhudaBukhsh</li>
<li>for: 这 paper 的目的是计算并分析波斯语推特讨论，以估算在警察拘留中死亡的马哈萨·阿米尼去世后，对男女平等的态度发生了如何的变化。</li>
<li>methods: 该 paper 使用了一个ensemble active learning挺训练一个立场分类器，其特点在于伊朗女性参与了活动的角色，不仅提供标签，还提供了有价值的关键词 для更加有意义的词汇创造以及短示文档 для导向采样步骤。</li>
<li>results: 分析结果表明，贝娅·阿米尼去世后，波斯语推特讨论发生了偏好化的变化，双方的负面和正面的推特数量均增加了，其中正面推特数量微小地大于负面推特数量增加。此外，与基eline波斯推特活动相比，支持抗议的推特账户的创建时间更加接近于基eline。<details>
<summary>Abstract</summary>
In this paper, we present a computational analysis of the Persian language Twitter discourse with the aim to estimate the shift in stance toward gender equality following the death of Mahsa Amini in police custody. We present an ensemble active learning pipeline to train a stance classifier. Our novelty lies in the involvement of Iranian women in an active role as annotators in building this AI system. Our annotators not only provide labels, but they also suggest valuable keywords for more meaningful corpus creation as well as provide short example documents for a guided sampling step. Our analyses indicate that Mahsa Amini's death triggered polarized Persian language discourse where both fractions of negative and positive tweets toward gender equality increased. The increase in positive tweets was slightly greater than the increase in negative tweets. We also observe that with respect to account creation time, between the state-aligned Twitter accounts and pro-protest Twitter accounts, pro-protest accounts are more similar to baseline Persian Twitter activity.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们对波斯语推特讨论进行计算分析，以估算死于警察执法中的马赛穆罕默的去世对性别平等的看法产生影响。我们提出了一个协同学习激活管道，以训练立场分类器。我们的创新在于伊朗女性参与了活动角色，作为标注人员，不仅提供标签，还提供了有价值的关键词，以便更好地创建词汇库，以及短示例文档，用于指导采样步骤。我们的分析表明，马赛穆罕默的去世导致波斯语推特讨论呈极化趋势，负面和正面的推特数量均增加，但正面推特数量略大于负面推特数量。此外，我们发现，在账户创建时间方面，支持抗议的推特账户和支持政府的推特账户之间的差异较小。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Outcomes-in-Long-COVID-Patients-with-Spatiotemporal-Attention"><a href="#Predicting-Outcomes-in-Long-COVID-Patients-with-Spatiotemporal-Attention" class="headerlink" title="Predicting Outcomes in Long COVID Patients with Spatiotemporal Attention"></a>Predicting Outcomes in Long COVID Patients with Spatiotemporal Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04770">http://arxiv.org/abs/2307.04770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Degan Hao, Mohammadreza Negahdar</li>
<li>for: 预测长期感染COVID-19患者的严重程度</li>
<li>methods: 使用本地LSTM和共同空间时间注意力机制，同时限制短期相互依赖学习和长期相互依赖学习</li>
<li>results: 在具有困难预测特征的长COVID患者数据集上，本方法比相关方法表现出色，可用于评估长COVID患者的严重程度。<details>
<summary>Abstract</summary>
Long COVID is a general term of post-acute sequelae of COVID-19. Patients with long COVID can endure long-lasting symptoms including fatigue, headache, dyspnea and anosmia, etc. Identifying the cohorts with severe long-term complications in COVID-19 could benefit the treatment planning and resource arrangement. However, due to the heterogeneous phenotype presented in long COVID patients, it is difficult to predict their outcomes from their longitudinal data. In this study, we proposed a spatiotemporal attention mechanism to weigh feature importance jointly from the temporal dimension and feature space. Considering that medical examinations can have interchangeable orders in adjacent time points, we restricted the learning of short-term dependency with a Local-LSTM and the learning of long-term dependency with the joint spatiotemporal attention. We also compared the proposed method with several state-of-the-art methods and a method in clinical practice. The methods are evaluated on a hard-to-acquire clinical dataset of patients with long COVID. Experimental results show the Local-LSTM with joint spatiotemporal attention outperformed related methods in outcome prediction. The proposed method provides a clinical tool for the severity assessment of long COVID.
</details>
<details>
<summary>摘要</summary>
长期 COVID 是 COVID-19 后遗症的总称。患有长期 COVID 的患者可能会经历长期的症状，如疲劳、头痛、呼吸急促和 anosmia 等。确定 COVID-19 患者长期grave的合并症状可以帮助诊断和资源安排。然而，由于长期 COVID 患者的多样性表现，从 их长期数据来预测结果很困难。在这项研究中，我们提出了一种空间时间注意力机制，以同时评估特征的重要性。由于医学检查可能会在邻近时间点互换检查顺序，我们限制了短期依赖性学习的 Local-LSTM，以及与其他特征空间进行同时学习的合并空间时间注意力。我们还对我们的方法与其他现有方法和临床实践中的方法进行了比较。这些方法在普遍难以获得的医学数据集上进行了评估。实验结果表明，Local-LSTM  WITH 共同空间时间注意力在结果预测方面表现出色，超过了相关方法。我们的方法提供了诊断长期 COVID 严重程度的临床工具。
</details></li>
</ul>
<hr>
<h2 id="Formulation-Graphs-for-Mapping-Structure-Composition-of-Battery-Electrolytes-to-Device-Performance"><a href="#Formulation-Graphs-for-Mapping-Structure-Composition-of-Battery-Electrolytes-to-Device-Performance" class="headerlink" title="Formulation Graphs for Mapping Structure-Composition of Battery Electrolytes to Device Performance"></a>Formulation Graphs for Mapping Structure-Composition of Battery Electrolytes to Device Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03811">http://arxiv.org/abs/2307.03811</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vidushi Sharma, Maxwell Giammona, Dmitry Zubarev, Andy Tek, Khanh Nugyuen, Linda Sundberg, Daniele Congiu, Young-Hye La</li>
<li>For: The paper is written for researchers and developers working on the discovery and development of new combinatorial materials, particularly in the context of battery electrolytes.* Methods: The paper proposes a deep learning model called Formulation Graph Convolution Network (F-GCN) that can predict the properties of liquid formulations based on the structure-composition relationship of their individual components. The model uses molecular descriptors derived from molecular graphs, informed by HOMO-LUMO and electric moment properties of the molecules.* Results: The paper demonstrates the effectiveness of the proposed model on two exemplary datasets related to battery electrolytes, achieving low errors in predicting performance metrics such as Coulombic Efficiency (CE) and specific capacity. The best performing F-GCN model uses molecular descriptors derived from molecular graphs that are informed with HOMO-LUMO and electric moment properties of the molecules.<details>
<summary>Abstract</summary>
Advanced computational methods are being actively sought for addressing the challenges associated with discovery and development of new combinatorial material such as formulations. A widely adopted approach involves domain informed high-throughput screening of individual components that can be combined into a formulation. This manages to accelerate the discovery of new compounds for a target application but still leave the process of identifying the right 'formulation' from the shortlisted chemical space largely a laboratory experiment-driven process. We report a deep learning model, Formulation Graph Convolution Network (F-GCN), that can map structure-composition relationship of the individual components to the property of liquid formulation as whole. Multiple GCNs are assembled in parallel that featurize formulation constituents domain-intuitively on the fly. The resulting molecular descriptors are scaled based on respective constituent's molar percentage in the formulation, followed by formalizing into a combined descriptor that represents a complete formulation to an external learning architecture. The use case of proposed formulation learning model is demonstrated for battery electrolytes by training and testing it on two exemplary datasets representing electrolyte formulations vs battery performance -- one dataset is sourced from literature about Li/Cu half-cells, while the other is obtained by lab-experiments related to lithium-iodide full-cell chemistry. The model is shown to predict the performance metrics like Coulombic Efficiency (CE) and specific capacity of new electrolyte formulations with lowest reported errors. The best performing F-GCN model uses molecular descriptors derived from molecular graphs that are informed with HOMO-LUMO and electric moment properties of the molecules using a knowledge transfer technique.
</details>
<details>
<summary>摘要</summary>
当前计算方法在开发新的 combinatorial材料领域中是活跃的搜寻。一种广泛采用的方法是通过域内高速屏选个别组分，以加速针对特定应用的新化合物的发现。然而，从短列表中选择合适的“形态”仍然是实验室实验驱动的过程。我们报道了一种深度学习模型，形态图 convolutional neural network (F-GCN)，可以将个体组分的结构-组分关系映射到液体形态的性能。多个GCN被紧密地 assembled 并在 fly 上域特征化形态成分。 resulting molecular descriptors 被权重根据各个成分的分子比例缩放，然后以组合的描述符形式传递给外部学习架构。我们使用了 Li/Cu 半细胞和锂iodide 全细胞化学的两个数据集来评估我们的形态学习模型。我们的模型可以预测新的电解质形态的性能指标，如电子效率（CE）和Specific capacity。我们的最佳运行F-GCN模型使用基于分子图的分子描述符，并使用了知识传递技术以获得HOMO-LUMO和电动量特性。
</details></li>
</ul>
<hr>
<h2 id="URL-A-Representation-Learning-Benchmark-for-Transferable-Uncertainty-Estimates"><a href="#URL-A-Representation-Learning-Benchmark-for-Transferable-Uncertainty-Estimates" class="headerlink" title="URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates"></a>URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03810">http://arxiv.org/abs/2307.03810</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mkirchhof/url">https://github.com/mkirchhof/url</a></li>
<li>paper_authors: Michael Kirchhof, Bálint Mucsányi, Seong Joon Oh, Enkelejda Kasneci</li>
<li>for: 这个论文是为了开发一个能够在新数据集上传输的预训练模型，同时也能够提供可靠的机器学习和不确定量衡的基础模型。</li>
<li>methods: 这个论文使用了一种新的 uncertainty-aware representation learning（URL）benchmark，用于评估eleven个不确定量衡器，这些不确定量衡器在ImageNet上预训练后被转移到了八个下游数据集上。</li>
<li>results: 研究发现，对于表示本身的不确定性或直接估计预测风险的方法比较出色，但是实现可传输的不确定量衡仍然是一个开放的挑战。<details>
<summary>Abstract</summary>
Representation learning has significantly driven the field to develop pretrained models that can act as a valuable starting point when transferring to new datasets. With the rising demand for reliable machine learning and uncertainty quantification, there is a need for pretrained models that not only provide embeddings but also transferable uncertainty estimates. To guide the development of such models, we propose the Uncertainty-aware Representation Learning (URL) benchmark. Besides the transferability of the representations, it also measures the zero-shot transferability of the uncertainty estimate using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers that are pretrained on ImageNet and transferred to eight downstream datasets. We find that approaches that focus on the uncertainty of the representation itself or estimate the prediction risk directly outperform those that are based on the probabilities of upstream classes. Yet, achieving transferable uncertainty quantification remains an open challenge. Our findings indicate that it is not necessarily in conflict with traditional representation learning goals. Code is provided under https://github.com/mkirchhof/url .
</details>
<details>
<summary>摘要</summary>
“表达学学习”在领域中发挥了重要作用，使得开发者可以从新数据集上转移到新的任务。随着机器学习的可靠性和不确定性评估的需求增加，需要开发可以提供嵌入和传输不确定性估计的预训练模型。为了引导这类模型的开发，我们提出了“不确定性感知学习”（URL）数据集。除了表达的传输性外，它还测量了零批转移不确定性估计的新指标。我们对ImageNet预训练的十一种不确定量进行了URL的评估，并将其转移到八个下游数据集上。我们发现，关注表达不确定性本身或直接估计预测风险的方法表现较好。然而，实现传输不确定性估计仍然是一个开放的挑战。我们的发现表明，这并不是传统表达学习目标的矛盾。代码可以在<https://github.com/mkirchhof/url>获取。
</details></li>
</ul>
<hr>
<h2 id="A-Theoretical-Perspective-on-Subnetwork-Contributions-to-Adversarial-Robustness"><a href="#A-Theoretical-Perspective-on-Subnetwork-Contributions-to-Adversarial-Robustness" class="headerlink" title="A Theoretical Perspective on Subnetwork Contributions to Adversarial Robustness"></a>A Theoretical Perspective on Subnetwork Contributions to Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03803">http://arxiv.org/abs/2307.03803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jovon Craig, Josh Andle, Theodore S. Nowak, Salimeh Yasaei Sekeh</li>
<li>for: 这个论文是为了研究深度神经网络（DNNs）对攻击的Robustness进行了广泛的研究，以便更好地理解深度学习模型的凝结和安全应用中的模型安全性。</li>
<li>methods: 这个论文使用了对DNNs进行针对性攻击的训练方法来强化其对攻击的Robustness，并证明了这种方法可以在整个模型上应用计算成本的高的训练方法。</li>
<li>results: 该论文提出了一个新的理论框架，用于研究攻击如何影响整个网络的Robustness，并提供了一种测试这种理论的方法。经验表明，如果某个子网络具有一定的鲁棒性，那么整个网络也是鲁棒的，并且需要在不同层次之间存在一定的依赖关系。<details>
<summary>Abstract</summary>
The robustness of deep neural networks (DNNs) against adversarial attacks has been studied extensively in hopes of both better understanding how deep learning models converge and in order to ensure the security of these models in safety-critical applications. Adversarial training is one approach to strengthening DNNs against adversarial attacks, and has been shown to offer a means for doing so at the cost of applying computationally expensive training methods to the entire model. To better understand these attacks and facilitate more efficient adversarial training, in this paper we develop a novel theoretical framework that investigates how the adversarial robustness of a subnetwork contributes to the robustness of the entire network. To do so we first introduce the concept of semirobustness, which is a measure of the adversarial robustness of a subnetwork. Building on this concept, we then provide a theoretical analysis to show that if a subnetwork is semirobust and there is a sufficient dependency between it and each subsequent layer in the network, then the remaining layers are also guaranteed to be robust. We validate these findings empirically across multiple DNN architectures, datasets, and adversarial attacks. Experiments show the ability of a robust subnetwork to promote full-network robustness, and investigate the layer-wise dependencies required for this full-network robustness to be achieved.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）的对抗攻击的稳定性已经得到了广泛的研究，以便更好地理解深度学习模型的协调方式，并确保这些模型在安全关键应用中的安全性。对抗训练是一种加强DNNs对抗攻击的方法，并已经证明可以通过对整个模型进行计算昂贵的训练方法来实现。为了更好地理解这些攻击和实现更有效的对抗训练，在这篇论文中我们开发了一种新的理论框架，以 investigate如何各个子网络的对抗稳定性对整个网络的稳定性的贡献。我们首先介绍了semirobustness这个概念，它是一种对抗稳定性的度量。然后，我们提供了一种理论分析，证明如果一个子网络是semirobust的，并且每个后续层与其之间存在足够的依赖关系，那么剩下的层也一定是稳定的。我们验证了这些发现的实验结果，并对多个DNN架构、数据集和攻击方法进行了验证。实验表明，一个稳定的子网络可以推动整个网络的稳定性，并且调查层间的依赖关系可以实现这种全网络稳定性。
</details></li>
</ul>
<hr>
<h2 id="CLIPMasterPrints-Fooling-Contrastive-Language-Image-Pre-training-Using-Latent-Variable-Evolution"><a href="#CLIPMasterPrints-Fooling-Contrastive-Language-Image-Pre-training-Using-Latent-Variable-Evolution" class="headerlink" title="CLIPMasterPrints: Fooling Contrastive Language-Image Pre-training Using Latent Variable Evolution"></a>CLIPMasterPrints: Fooling Contrastive Language-Image Pre-training Using Latent Variable Evolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03798">http://arxiv.org/abs/2307.03798</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matfrei/clipmasterprints">https://github.com/matfrei/clipmasterprints</a></li>
<li>paper_authors: Matthias Freiberger, Peter Kun, Anders Sundnes Løvlie, Sebastian Risi</li>
<li>for: 这个论文旨在探讨 Contrastive Language-Image Pre-training (CLIP) 模型在面对“伪装主要图像”（fooling master images）时的护卫机制。</li>
<li>methods: 该论文使用了演化策略和杂化度规避策略来搜寻 CLIP 模型的易训练图像，并 investigate 这些图像的特性和普适性。</li>
<li>results: 研究发现，使用少量图像标签可以生成大量semantically相关的图像，而且这些图像可以让 CLIP 模型具有高置信度。此外，研究还发现 modality gap 在多modal网络中导致 CLIP 模型易受到伪装主要图像的攻击。<details>
<summary>Abstract</summary>
Models leveraging both visual and textual data such as Contrastive Language-Image Pre-training (CLIP), are increasingly gaining importance. In this work, we show that despite their versatility, such models are vulnerable to what we refer to as fooling master images. Fooling master images are capable of maximizing the confidence score of a CLIP model for a significant number of widely varying prompts, while being unrecognizable for humans. We demonstrate how fooling master images can be mined by searching the latent space of generative models by means of an evolution strategy or stochastic gradient descent. We investigate the properties of the mined fooling master images, and find that images trained on a small number of image captions potentially generalize to a much larger number of semantically related captions. Further, we evaluate two possible mitigation strategies and find that vulnerability to fooling master examples is closely related to a modality gap in contrastive pre-trained multi-modal networks. From the perspective of vulnerability to off-manifold attacks, we therefore argue for the mitigation of modality gaps in CLIP and related multi-modal approaches. Source code and mined CLIPMasterPrints are available at https://github.com/matfrei/CLIPMasterPrints.
</details>
<details>
<summary>摘要</summary>
模型利用视觉和文本数据，如对照语言图像预训练（CLIP），在当前研究中变得越来越重要。在这项工作中，我们表明，尽管这些模型具有多样性，但它们却容易受到我们称为“欺骗主图”的攻击。欺骗主图可以让CLIP模型对各种各样的提示进行最大化信任分数，而human是无法识别的。我们表明，可以通过演化策略或权重下降来在生成模型的latent空间中搜寻欺骗主图。我们研究欺骗主图的性质，发现图像通过少量的图像描述训练可以对Semantically相关的提示进行扩展。此外，我们评估了两种可能的防范策略，发现攻击模式与多样性差有close关系。从防范多样性差的角度来看，我们 argue for the mitigation of modality gaps in CLIP and related multi-modal approaches。代码和搜寻到的CLIPMasterPrints可以在https://github.com/matfrei/CLIPMasterPrints上获取。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Lottery-Ticket-Hypothesis-with-Explainability-Methods-Insights-into-Sparse-Network-Performance"><a href="#Exploring-the-Lottery-Ticket-Hypothesis-with-Explainability-Methods-Insights-into-Sparse-Network-Performance" class="headerlink" title="Exploring the Lottery Ticket Hypothesis with Explainability Methods: Insights into Sparse Network Performance"></a>Exploring the Lottery Ticket Hypothesis with Explainability Methods: Insights into Sparse Network Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13698">http://arxiv.org/abs/2307.13698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shantanu Ghosh, Kayhan Batmanghelich</li>
<li>for: 本研究旨在找到具有比较高性能的稀缺网络，并解释这些稀缺网络的性能是如何逐渐提高或下降的。</li>
<li>methods: 本研究使用了Grad-CAM和Post-hoc概念瓶顶模型（PCBMs）来调查减少网络中的权重后，网络的解释性。</li>
<li>results: 研究发现，随着权重的减少，网络的性能逐渐下降，并且发现了原始网络中的概念和像素与减少后的网络存在差异，这可能是性能下降的原因。<details>
<summary>Abstract</summary>
Discovering a high-performing sparse network within a massive neural network is advantageous for deploying them on devices with limited storage, such as mobile phones. Additionally, model explainability is essential to fostering trust in AI. The Lottery Ticket Hypothesis (LTH) finds a network within a deep network with comparable or superior performance to the original model. However, limited study has been conducted on the success or failure of LTH in terms of explainability. In this work, we examine why the performance of the pruned networks gradually increases or decreases. Using Grad-CAM and Post-hoc concept bottleneck models (PCBMs), respectively, we investigate the explainability of pruned networks in terms of pixels and high-level concepts. We perform extensive experiments across vision and medical imaging datasets. As more weights are pruned, the performance of the network degrades. The discovered concepts and pixels from the pruned networks are inconsistent with the original network -- a possible reason for the drop in performance.
</details>
<details>
<summary>摘要</summary>
发现高性能的简化网络在巨量神经网络中是有利于在具有有限存储的设备上部署，如移动电话。此外，AI信任的重要因素之一是模型解释性。抽奖假设（LTH）找到了深度网络中的相似或更高性能的网络，但有限的研究对LTH的成功或失败进行了解释性研究。在这项工作中，我们研究了剪除网络性能的提高或下降的原因。使用Grad-CAM和后置概念瓶颈模型（PCBM），我们进行了剪除网络的解释性研究，即像素和高级概念的解释性。我们在视觉和医学影像 dataset 上进行了广泛的实验。随着更多的权重被剪除，网络性能下降。发现的概念和像素从剪除网络中与原始网络不同，可能是性能下降的原因。
</details></li>
</ul>
<hr>
<h2 id="Neural-Abstraction-Based-Controller-Synthesis-and-Deployment"><a href="#Neural-Abstraction-Based-Controller-Synthesis-and-Deployment" class="headerlink" title="Neural Abstraction-Based Controller Synthesis and Deployment"></a>Neural Abstraction-Based Controller Synthesis and Deployment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03783">http://arxiv.org/abs/2307.03783</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/msalamati/neural-representation">https://github.com/msalamati/neural-representation</a></li>
<li>paper_authors: Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani</li>
<li>for: 本研究旨在提高抽象基本方法的内存效率，以便在实时控制中应用。</li>
<li>methods: 我们提出了一种基于神经网络表示的内存有效的控制器生成方法，包括在执行阶段使用压缩神经网络表示，以及在训练阶段使用神经网络来减少内存占用。</li>
<li>results: 我们的方法可以减少抽象基本方法的内存占用，并且可以在实时控制中应用。在选择的标准套件中，我们的方法可以减少平均内存占用量分别为1.31×10^5和7.13×10^3，最高达7.54×10^5和3.18×10^4。<details>
<summary>Abstract</summary>
Abstraction-based techniques are an attractive approach for synthesizing correct-by-construction controllers to satisfy high-level temporal requirements. A main bottleneck for successful application of these techniques is the memory requirement, both during controller synthesis and in controller deployment.   We propose memory-efficient methods for mitigating the high memory demands of the abstraction-based techniques using neural network representations. To perform synthesis for reach-avoid specifications, we propose an on-the-fly algorithm that relies on compressed neural network representations of the forward and backward dynamics of the system. In contrast to usual applications of neural representations, our technique maintains soundness of the end-to-end process. To ensure this, we correct the output of the trained neural network such that the corrected output representations are sound with respect to the finite abstraction. For deployment, we provide a novel training algorithm to find a neural network representation of the synthesized controller and experimentally show that the controller can be correctly represented as a combination of a neural network and a look-up table that requires a substantially smaller memory.   We demonstrate experimentally that our approach significantly reduces the memory requirements of abstraction-based methods. For the selected benchmarks, our approach reduces the memory requirements respectively for the synthesis and deployment by a factor of $1.31\times 10^5$ and $7.13\times 10^3$ on average, and up to $7.54\times 10^5$ and $3.18\times 10^4$. Although this reduction is at the cost of increased off-line computations to train the neural networks, all the steps of our approach are parallelizable and can be implemented on machines with higher number of processing units to reduce the required computational time.
</details>
<details>
<summary>摘要</summary>
“对于高水平时间需求的正确控制器的合成，具有吸引力的方法是基于抽象的技术。然而，这些技术的记忆需求在控制器合成和部署过程中都是主要的瓶颈。我们提出了一些记忆效率的方法，使用神经网络表示法来减少高级抽象技术的记忆需求。为了实现这些目的，我们提出了一种在线算法，它基于压缩神经网络表示法来进行控制器合成。与传统神经网络应用不同的是，我们的方法保持了途径的有效性。为了确保这一点，我们会对训练神经网络输出进行修正，使其与有限抽象之间保持相对的准确性。在部署阶段，我们提供了一种新的训练算法，用于在神经网络和lookup表之间找到一个可以减少记忆需求的控制器表示。我们通过实验证明，我们的方法可以减少抽象基于方法的记忆需求。对于我们选择的标准套件，我们的方法分别减少了在合成和部署阶段的记忆需求的平均值为1.31\*10^5和7.13\*10^3。最多可以减少到7.54\*10^5和3.18\*10^4。虽然这些减少是在训练神经网络的过程中付出的成本，但所有的步骤都可以并行进行并在高处理器数量的机器上进行实现，以减少所需的计算时间。”
</details></li>
</ul>
<hr>
<h2 id="When-does-the-ID-algorithm-fail"><a href="#When-does-the-ID-algorithm-fail" class="headerlink" title="When does the ID algorithm fail?"></a>When does the ID algorithm fail?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03750">http://arxiv.org/abs/2307.03750</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SOYJUN/Implement-ODR-protocol">https://github.com/SOYJUN/Implement-ODR-protocol</a></li>
<li>paper_authors: Ilya Shpitser</li>
<li>for: 本文研究的是ID算法在图解释模型中进行 интервенциональ分布ID问题的解决方案。</li>
<li>methods: 本文使用的方法包括ID算法的各种表述，以及对ID算法的完善性和有效性的分析。</li>
<li>results: 本文提出了一些对ID算法的批评和改进，包括指出ID算法在某些情况下会失败，并提供了一些图形化的Characterization来描述这些情况。<details>
<summary>Abstract</summary>
The ID algorithm solves the problem of identification of interventional distributions of the form p(Y | do(a)) in graphical causal models, and has been formulated in a number of ways [12, 9, 6]. The ID algorithm is sound (outputs the correct functional of the observed data distribution whenever p(Y | do(a)) is identified in the causal model represented by the input graph), and complete (explicitly flags as a failure any input p(Y | do(a)) whenever this distribution is not identified in the causal model represented by the input graph).   The reference [9] provides a result, the so called "hedge criterion" (Corollary 3), which aims to give a graphical characterization of situations when the ID algorithm fails to identify its input in terms of a structure in the input graph called the hedge. While the ID algorithm is, indeed, a sound and complete algorithm, and the hedge structure does arise whenever the input distribution is not identified, Corollary 3 presented in [9] is incorrect as stated. In this note, I outline the modern presentation of the ID algorithm, discuss a simple counterexample to Corollary 3, and provide a number of graphical characterizations of the ID algorithm failing to identify its input distribution.
</details>
<details>
<summary>摘要</summary>
“ID算法解决了图structural causal模型中p(Y | do(a))的分布标定问题，并在多种形式下表述（[12, 9, 6]）。ID算法是有效的（对于输入分布p(Y | do(a))，输出正确的函数），并且是完整的（如果输入分布不能在图structural causal模型中标定，则直接标记为失败）。”“参考[9]中的结论（即‘别branch criterion’）提供了一种图Structural characterization of situations when the ID algorithm fails to identify its input, in terms of a structure in the input graph called the hedge. However, this conclusion is incorrect as stated, and in this note, I present a modern presentation of the ID algorithm and a simple counterexample to Corollary 3. Additionally, I provide several graphical characterizations of the ID algorithm failing to identify its input distribution.”
</details></li>
</ul>
<hr>
<h2 id="Incentive-Theoretic-Bayesian-Inference-for-Collaborative-Science"><a href="#Incentive-Theoretic-Bayesian-Inference-for-Collaborative-Science" class="headerlink" title="Incentive-Theoretic Bayesian Inference for Collaborative Science"></a>Incentive-Theoretic Bayesian Inference for Collaborative Science</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03748">http://arxiv.org/abs/2307.03748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephen Bates, Michael I. Jordan, Michael Sklar, Jake A. Soloff</li>
<li>for: 这个论文是为了研究现代科学研究中的分布式、协作性，以及研究人员、管制机构、资金机构、商业伙伴和科学机构之间的互动和不同的驱动力。</li>
<li>methods: 论文使用了一种假设检验方法，其中一个代理人（例如研究人员或药品公司）有一个私人前置信息，而执行者（例如政策制定者或监管机构）希望根据参数值进行决策。代理人选择是否进行统计试验，然后试验的结果被用于执行者进行决策。</li>
<li>results: 论文表明了执行者可以通过代理人的决策行为来揭示部分信息，并使用这些信息来控制 posterior 概率的值。这一结果有一个重要的应用是在临床试验中设置类型一错误水平：试验类型一错误水平应该是临床试验成本除以企业利润的比率。<details>
<summary>Abstract</summary>
Contemporary scientific research is a distributed, collaborative endeavor, carried out by teams of researchers, regulatory institutions, funding agencies, commercial partners, and scientific bodies, all interacting with each other and facing different incentives. To maintain scientific rigor, statistical methods should acknowledge this state of affairs. To this end, we study hypothesis testing when there is an agent (e.g., a researcher or a pharmaceutical company) with a private prior about an unknown parameter and a principal (e.g., a policymaker or regulator) who wishes to make decisions based on the parameter value. The agent chooses whether to run a statistical trial based on their private prior and then the result of the trial is used by the principal to reach a decision. We show how the principal can conduct statistical inference that leverages the information that is revealed by an agent's strategic behavior -- their choice to run a trial or not. In particular, we show how the principal can design a policy to elucidate partial information about the agent's private prior beliefs and use this to control the posterior probability of the null. One implication is a simple guideline for the choice of significance threshold in clinical trials: the type-I error level should be set to be strictly less than the cost of the trial divided by the firm's profit if the trial is successful.
</details>
<details>
<summary>摘要</summary>
现代科学研究是一项分布式、合作性的努力，由研究人员、管理机构、资金机构、商业伙伴和科学机构共同参与，这些组织之间存在不同的驱动和激励。为保持科学的严谨性，统计方法应该考虑这种情况。为此，我们研究在有一个代理人（例如研究人员或药品制造商）有私人估计参数的情况下，检测 гипотезы的问题。代理人根据自己的私人估计选择是否进行统计试验，然后试验结果被使用者来做决策。我们表明如何使得首脑可以通过代理人的战略行为（即是否进行试验）了解一部分私人估计信息，并使用这些信息来控制后验 posterior 概率。特别是，我们表明如何使得首脑可以设计一种政策来描述代理人的私人估计信息，并使用这些信息来控制后验 posterior 概率。这一结论之一是一个简单的临床试验选择水平指南：类型一错误水平应该设置为试验成本除以成功后利润的比率。
</details></li>
</ul>
<hr>
<h2 id="QIGen-Generating-Efficient-Kernels-for-Quantized-Inference-on-Large-Language-Models"><a href="#QIGen-Generating-Efficient-Kernels-for-Quantized-Inference-on-Large-Language-Models" class="headerlink" title="QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models"></a>QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03738">http://arxiv.org/abs/2307.03738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ist-daslab/qigen">https://github.com/ist-daslab/qigen</a></li>
<li>paper_authors: Tommaso Pegolotti, Elias Frantar, Dan Alistarh, Markus Püschel</li>
<li>for: 支持量化生成推理在 LLMA 或 OPT 上的自动代码生成方法。</li>
<li>methods: 基于目标架构和性能模型，包括硬件特性和方法特有的准确性约束。</li>
<li>results: CPU 上的 LLMA 模型推理显示，我们的方法可以达到高性能和高准确性，与现有开源解决方案相比。Here’s the English version for reference:</li>
<li>for: An automatic code generation approach for supporting quantized generative inference on large language models (LLMs) such as LLaMA or OPT on off-the-shelf CPUs.</li>
<li>methods: Informed by the target architecture and a performance model, including both hardware characteristics and method-specific accuracy constraints.</li>
<li>results: Results on CPU-based inference for LLaMA models show that our approach can lead to high performance and high accuracy, comparing favorably to the best existing open-source solution.<details>
<summary>Abstract</summary>
We present ongoing work on a new automatic code generation approach for supporting quantized generative inference on LLMs such as LLaMA or OPT on off-the-shelf CPUs. Our approach is informed by the target architecture and a performance model, including both hardware characteristics and method-specific accuracy constraints. Results on CPU-based inference for LLaMA models show that our approach can lead to high performance and high accuracy, comparing favorably to the best existing open-source solution. A preliminary implementation is available at https://github.com/IST-DASLab/QIGen.
</details>
<details>
<summary>摘要</summary>
我们正在进行一项新的自动代码生成方法，用于支持量化生成推理在LLaMA或OPT类型的语言模型上的Off-the-shelf CPU上。我们的方法受到目标架构和性能模型的影响，包括硬件特性和方法具体精度限制。对CPU上的推理过程中的LLaMA模型进行了结果，我们的方法可以实现高性能和高精度，与现有开源解决方案相比，表现优异。一个初步的实现可以在https://github.com/IST-DASLab/QIGen上获得。
</details></li>
</ul>
<hr>
<h2 id="Polybot-Training-One-Policy-Across-Robots-While-Embracing-Variability"><a href="#Polybot-Training-One-Policy-Across-Robots-While-Embracing-Variability" class="headerlink" title="Polybot: Training One Policy Across Robots While Embracing Variability"></a>Polybot: Training One Policy Across Robots While Embracing Variability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03719">http://arxiv.org/abs/2307.03719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Yang, Dorsa Sadigh, Chelsea Finn<br>for:多种机器人平台上的视觉控制技能的跨平台传输methods:使用终端摄像头和团队代码库实现观察和动作空间的匹配使用对比学习对策的内部表示进行匹配results:在6个任务和3个机器人上收集了60小时的数据，并取得了显著提高成功率和样本效率的结果，验证了我们的设计决策。Please note that the above information is in Simplified Chinese text, as requested.<details>
<summary>Abstract</summary>
Reusing large datasets is crucial to scale vision-based robotic manipulators to everyday scenarios due to the high cost of collecting robotic datasets. However, robotic platforms possess varying control schemes, camera viewpoints, kinematic configurations, and end-effector morphologies, posing significant challenges when transferring manipulation skills from one platform to another. To tackle this problem, we propose a set of key design decisions to train a single policy for deployment on multiple robotic platforms. Our framework first aligns the observation and action spaces of our policy across embodiments via utilizing wrist cameras and a unified, but modular codebase. To bridge the remaining domain shift, we align our policy's internal representations across embodiments through contrastive learning. We evaluate our method on a dataset collected over 60 hours spanning 6 tasks and 3 robots with varying joint configurations and sizes: the WidowX 250S, the Franka Emika Panda, and the Sawyer. Our results demonstrate significant improvements in success rate and sample efficiency for our policy when using new task data collected on a different robot, validating our proposed design decisions. More details and videos can be found on our anonymized project website: https://sites.google.com/view/polybot-multirobot
</details>
<details>
<summary>摘要</summary>
重用大量数据是扩展视觉基于机器人 manipulate 到日常场景中的关键因素，因为收集机器人数据的成本很高。然而，机器人平台具有不同的控制方案、摄像头视点、骨骼配置和器官形态，这会导致将抓取技能从一个平台转移到另一个平台的具有很大挑战。为解决这个问题，我们提出了一些关键的设计决策，用于在多个机器人平台上训练单个策略。我们的框架首先将我们策略的观察空间和动作空间在不同实现中进行对齐，通过使用臂部摄像头和一个统一、可分模块的代码库来实现这一点。为了填补剩下的领域差异，我们对策略的内部表示进行对齐，通过对比学习来实现这一点。我们的方法在一个包含60小时、6个任务和3个机器人的数据集上进行了评估，这些机器人包括WidowX 250S、Franka Emika Panda 和Sawyer。我们的结果表明，使用我们的策略在新的任务数据上进行训练后，在不同机器人上的成功率和样本效率有显著提高，这 validate 我们的设计决策。更多细节和视频可以在我们匿名项目网站上找到：https://sites.google.com/view/polybot-multirobot。
</details></li>
</ul>
<hr>
<h2 id="SAR-Generalization-of-Physiological-Agility-and-Dexterity-via-Synergistic-Action-Representation"><a href="#SAR-Generalization-of-Physiological-Agility-and-Dexterity-via-Synergistic-Action-Representation" class="headerlink" title="SAR: Generalization of Physiological Agility and Dexterity via Synergistic Action Representation"></a>SAR: Generalization of Physiological Agility and Dexterity via Synergistic Action Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03716">http://arxiv.org/abs/2307.03716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cameron Berg, Vittorio Caggiano, Vikash Kumar</li>
<li>for: 学习高维系统中的连续控制策略，包括肌肉机械系统，仍然是一项复杂的挑战。生物进化过程中，生物体发展了一些强大的机制，以学习高度复杂的运动控制策略。这种robust行为flexibility哪里来自？</li>
<li>methods: 模块化控制via肌肉共同强制（i.e., 肌肉合作）是一种可能的机制，它使得生物体可以通过简化和总结的动作空间来学习肌肉控制。这篇文章引用这种演化出来的运动控制策略，使用physiologically accurate的人工手和脚模型作为测试环境，以确定这种Synergistic Action Representation（SAR）在更复杂任务中是否能够促进学习。</li>
<li>results: 结果表明，使用SAR在更复杂任务中能够显著提高学习效率和成功率。在人工手和脚模型中，SAR-使用策略可以在各种 Terrains上实现 robust locomotion，而基线方法无法学习有意义的行为。此外，在多个目标搅拌任务中，SAR-使用策略的成功率高达70%，而基线方法的成功率仅有20%。这两个SAR-使用策略还能够在不同的环境条件下进行零基础学习，而不使用SAR的策略则无法进行泛化。最后，文章证明了SAR在更广泛的高维控制问题上的一致性，使用了机器人搅拌任务集和全身人形机器人步行任务。<details>
<summary>Abstract</summary>
Learning effective continuous control policies in high-dimensional systems, including musculoskeletal agents, remains a significant challenge. Over the course of biological evolution, organisms have developed robust mechanisms for overcoming this complexity to learn highly sophisticated strategies for motor control. What accounts for this robust behavioral flexibility? Modular control via muscle synergies, i.e. coordinated muscle co-contractions, is considered to be one putative mechanism that enables organisms to learn muscle control in a simplified and generalizable action space. Drawing inspiration from this evolved motor control strategy, we use physiologically accurate human hand and leg models as a testbed for determining the extent to which a Synergistic Action Representation (SAR) acquired from simpler tasks facilitates learning more complex tasks. We find in both cases that SAR-exploiting policies significantly outperform end-to-end reinforcement learning. Policies trained with SAR were able to achieve robust locomotion on a wide set of terrains with high sample efficiency, while baseline approaches failed to learn meaningful behaviors. Additionally, policies trained with SAR on a multiobject manipulation task significantly outperformed (>70% success) baseline approaches (<20% success). Both of these SAR-exploiting policies were also found to generalize zero-shot to out-of-domain environmental conditions, while policies that did not adopt SAR failed to generalize. Finally, we establish the generality of SAR on broader high-dimensional control problems using a robotic manipulation task set and a full-body humanoid locomotion task. To the best of our knowledge, this investigation is the first of its kind to present an end-to-end pipeline for discovering synergies and using this representation to learn high-dimensional continuous control across a wide diversity of tasks.
</details>
<details>
<summary>摘要</summary>
学习高维系统中的连续控制策略是一项挑战。生物演化过程中，生物体发展出了一些强大的机制来解决这种复杂性，以学习高度复杂的动作控制策略。这种行为的灵活性来源于哪里？模块化控制通过肌肉同步，即肌肉共同收缩，是一种被认为是生物体学习肌肉控制的潜在机制。我们以人工手和脚模型作为测试平台，通过使用生理学准确的人工手和脚模型，确定使用SAR（Synergistic Action Representation）从更简单的任务中获得的策略是否可以帮助学习更复杂的任务。我们发现，在两个情况下，使用SAR策略的学习效果都高于端到端学习。SAR策略可以在各种不同的地形上实现稳定的移动，而基线方法无法学习有意义的行为。此外，在多个目标拼接任务中，使用SAR策略的成功率高于70%，而基线方法的成功率低于20%。同时，这两种SAR策略还能够适应不同的环境条件，而不使用SAR的策略无法适应。最后，我们通过使用机器人 manipulate 任务集和全身人形步行任务，证明SAR在更广泛的高维控制问题上具有普遍性。据我们所知，这是首次对高维连续控制问题的整体解决方案。
</details></li>
</ul>
<hr>
<h2 id="INT-FP-QSim-Mixed-Precision-and-Formats-For-Large-Language-Models-and-Vision-Transformers"><a href="#INT-FP-QSim-Mixed-Precision-and-Formats-For-Large-Language-Models-and-Vision-Transformers" class="headerlink" title="INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers"></a>INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03712">http://arxiv.org/abs/2307.03712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lightmatter-ai/int-fp-qsim">https://github.com/lightmatter-ai/int-fp-qsim</a></li>
<li>paper_authors: Lakshmi Nair, Mikhail Bernadskiy, Arulselvan Madhavan, Craig Chan, Ayon Basumallik, Darius Bunandar</li>
<li>for: 这篇论文的目的是提出一个开源的模拟器，以便评估大型自然语言模型（LLM）和感知对应模型（VT）在不同的数值精度和格式下的性能。</li>
<li>methods: 这篇论文使用了现有的开源库，例如TensorRT、QPyTorch和AIMET，将其组合成一个可以支持多种浮点和整数格式的模拟器。</li>
<li>results: 这篇论文通过使用 INT-FP-QSim 模拟器，评估了不同数值精度和格式下 LLM 和 VT 的性能，并比较了最近提出的 Adaptive Block Floating Point、SmoothQuant、GPTQ 和 RPTQ 等方法的影响。<details>
<summary>Abstract</summary>
The recent rise of large language models (LLMs) has resulted in increased efforts towards running LLMs at reduced precision. Running LLMs at lower precision supports resource constraints and furthers their democratization, enabling users to run billion-parameter LLMs on their personal devices. To supplement this ongoing effort, we propose INT-FP-QSim: an open-source simulator that enables flexible evaluation of LLMs and vision transformers at various numerical precisions and formats. INT-FP-QSim leverages existing open-source repositories such as TensorRT, QPytorch and AIMET for a combined simulator that supports various floating point and integer formats. With the help of our simulator, we survey the impact of different numerical formats on the performance of LLMs and vision transformers at 4-bit weights and 4-bit or 8-bit activations. We also compare recently proposed methods like Adaptive Block Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We hope INT-FP-QSim will enable researchers to flexibly simulate models at various precisions to support further research in quantization of LLMs and vision transformers.
</details>
<details>
<summary>摘要</summary>
最近的大语言模型（LLMs）的崛起导致了减少精度下运行的努力的增加。在减少精度下运行 LLMs 支持资源限制和普及，使用者可以在个人设备上运行 billion-parameter LLMs。为此，我们提议 INT-FP-QSim：一个开源的 simulator，可以在不同的数字精度和格式下灵活评估 LLMs 和视transformers。INT-FP-QSim 利用现有的开源库 such as TensorRT, QPytorch 和 AIMET，构建了一个集成的 simulator，支持多种浮点数和整数格式。我们使用 INT-FP-QSim，对 LLMs 和视transformers 的不同数字格式的影响进行了评估，并对最近提出的方法 like Adaptive Block Floating Point, SmoothQuant, GPTQ 和 RPTQ 进行了比较。我们希望 INT-FP-QSim 能够帮助研究人员在不同的精度下灵活模拟模型，以支持更多的 LLMS 和视transformers 的量化研究。
</details></li>
</ul>
<hr>
<h2 id="Fermat-Distances-Metric-Approximation-Spectral-Convergence-and-Clustering-Algorithms"><a href="#Fermat-Distances-Metric-Approximation-Spectral-Convergence-and-Clustering-Algorithms" class="headerlink" title="Fermat Distances: Metric Approximation, Spectral Convergence, and Clustering Algorithms"></a>Fermat Distances: Metric Approximation, Spectral Convergence, and Clustering Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05750">http://arxiv.org/abs/2307.05750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolás García Trillos, Anna Little, Daniel McKenzie, James M. Murphy</li>
<li>for: 这个论文研究了费马距离的收敛性质，它是在里曼纲抽象上定义的一种浮动度量，可以在维度感知的数据上进行分 clustering。</li>
<li>methods: 这个论文使用了新的几何和统计学方法，包括在非均匀密度和抽象纲上的几何构造和统计学分析，以证明费马距离的收敛性。</li>
<li>results: 这个论文证明了费马距离在小邻域内收敛到其连续类比中，收敛速率取决于数据的内在维度和权重参数。此外，这个论文还证明了基于费马距离的图 Laplacian 在维度感知的数据上的收敛性。<details>
<summary>Abstract</summary>
We analyze the convergence properties of Fermat distances, a family of density-driven metrics defined on Riemannian manifolds with an associated probability measure. Fermat distances may be defined either on discrete samples from the underlying measure, in which case they are random, or in the continuum setting, in which they are induced by geodesics under a density-distorted Riemannian metric. We prove that discrete, sample-based Fermat distances converge to their continuum analogues in small neighborhoods with a precise rate that depends on the intrinsic dimensionality of the data and the parameter governing the extent of density weighting in Fermat distances. This is done by leveraging novel geometric and statistical arguments in percolation theory that allow for non-uniform densities and curved domains. Our results are then used to prove that discrete graph Laplacians based on discrete, sample-driven Fermat distances converge to corresponding continuum operators. In particular, we show the discrete eigenvalues and eigenvectors converge to their continuum analogues at a dimension-dependent rate, which allows us to interpret the efficacy of discrete spectral clustering using Fermat distances in terms of the resulting continuum limit. The perspective afforded by our discrete-to-continuum Fermat distance analysis leads to new clustering algorithms for data and related insights into efficient computations associated to density-driven spectral clustering. Our theoretical analysis is supported with numerical simulations and experiments on synthetic and real image data.
</details>
<details>
<summary>摘要</summary>
我们分析 Ferma 距离的归一化性质，这是在里曼纹理上定义的一家density-driven métrique中的一个家族。Ferma 距离可以在粒子样本上定义，在这种情况下它们是随机的，也可以在 kontinuum 设置下定义，在这种情况下它们由 geodesics 下的 density-distorted Riemannian métrique 引起。我们证明了粒子样本上的 discrete Fermat 距离在小邻域内与其 kontinuum 同构中的analogues converge 到一个具体的rate，这个rate取决于数据的内在维度和 density weighting 参数的值。我们使用了新的几何和统计学理由，包括非均匀的density和拐弯的 Domian，来证明这一结论。我们的结果被用来证明基于 discrete Fermat 距离的图 Laplacian 的数据 clustering 算法是可靠的。具体来说，我们证明了 discrete eigenvalues 和 eigenvectors 在一定的维度上与其 kontinuum 同构中的analogues converge 到一个具体的rate，这使得我们可以根据continuum limit 来 интерпретирова discrete spectral clustering 的效果。我们的理论分析得到了 numérical simulations 和实验数据的支持，并提供了新的 clustering 算法和相关的办法。
</details></li>
</ul>
<hr>
<h2 id="Equivariant-Single-View-Pose-Prediction-Via-Induced-and-Restricted-Representations"><a href="#Equivariant-Single-View-Pose-Prediction-Via-Induced-and-Restricted-Representations" class="headerlink" title="Equivariant Single View Pose Prediction Via Induced and Restricted Representations"></a>Equivariant Single View Pose Prediction Via Induced and Restricted Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03704">http://arxiv.org/abs/2307.03704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Owen Howell, David Klee, Ondrej Biza, Linfeng Zhao, Robin Walters</li>
<li>for: 这篇论文是为了解决计算机视觉中从二维图像中学习三维世界的基本问题而写的。</li>
<li>methods: 这篇论文使用了SO(3)-equivariance的限制来适应二维图像上的对象旋转和翻译。具体来说，它使用了SO(2)-equivariance的约束来满足三维世界中对象的几何一致性约束。</li>
<li>results: 这篇论文提出了一种新的算法，可以在三维世界中从二维图像中学习对象的姿态。该算法在三个不同的 pose 预测任务上进行了测试，并在PASCAL3D+和SYMSOL pose estimation任务上达到了最高的测试精度。<details>
<summary>Abstract</summary>
Learning about the three-dimensional world from two-dimensional images is a fundamental problem in computer vision. An ideal neural network architecture for such tasks would leverage the fact that objects can be rotated and translated in three dimensions to make predictions about novel images. However, imposing SO(3)-equivariance on two-dimensional inputs is difficult because the group of three-dimensional rotations does not have a natural action on the two-dimensional plane. Specifically, it is possible that an element of SO(3) will rotate an image out of plane. We show that an algorithm that learns a three-dimensional representation of the world from two dimensional images must satisfy certain geometric consistency properties which we formulate as SO(2)-equivariance constraints. We use the induced and restricted representations of SO(2) on SO(3) to construct and classify architectures which satisfy these geometric consistency constraints. We prove that any architecture which respects said consistency constraints can be realized as an instance of our construction. We show that three previously proposed neural architectures for 3D pose prediction are special cases of our construction. We propose a new algorithm that is a learnable generalization of previously considered methods. We test our architecture on three pose predictions task and achieve SOTA results on both the PASCAL3D+ and SYMSOL pose estimation tasks.
</details>
<details>
<summary>摘要</summary>
学习三维世界从二维图像中是计算机视觉的基本问题。理想的神经网络架构 для此类任务应该利用对象可以在三维空间中旋转和平移，以便对 novel 图像进行预测。然而，对于二维输入，强制 SO(3) 同态性是困难的，因为三维 rotate 操作没有自然的二维平面上的行为。我们表明，一个学习三维世界的算法从二维图像中获得三维表示的世界，必须满足某些几何一致性要求，我们将这些要求表述为 SO(2) 同态性约束。我们使用 SO(2) 在 SO(3) 上的启发和受限表示来设计和分类架构，并证明任何满足这些几何一致性要求的架构都可以通过我们的构造实现。我们表明，前面已经提出的三个神经网络架构 для 3D 姿态预测都是我们的构造的特例。我们提出了一种新的算法，它是learnable的，并且是已知的方法的普适化。我们对三个姿态预测任务进行测试，并在 PASCAL3D+ 和 SYMSOL 姿态预测任务上达到了最高的成绩。
</details></li>
</ul>
<hr>
<h2 id="Scalable-Membership-Inference-Attacks-via-Quantile-Regression"><a href="#Scalable-Membership-Inference-Attacks-via-Quantile-Regression" class="headerlink" title="Scalable Membership Inference Attacks via Quantile Regression"></a>Scalable Membership Inference Attacks via Quantile Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03694">http://arxiv.org/abs/2307.03694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu</li>
<li>for: The paper is written for discussing a new class of membership inference attacks that are competitive with state-of-the-art shadow model attacks but require substantially less compute.</li>
<li>methods: The paper uses quantile regression on the distribution of confidence scores induced by the model under attack on points that are not used in training as the attack method.</li>
<li>results: The paper shows the efficacy of this approach in an extensive series of experiments on various datasets and model architectures, demonstrating that the proposed attack is competitive with state-of-the-art shadow model attacks while requiring less compute and being truly “black-box”.<details>
<summary>Abstract</summary>
Membership inference attacks are designed to determine, using black box access to trained models, whether a particular example was used in training or not. Membership inference can be formalized as a hypothesis testing problem. The most effective existing attacks estimate the distribution of some test statistic (usually the model's confidence on the true label) on points that were (and were not) used in training by training many \emph{shadow models} -- i.e. models of the same architecture as the model being attacked, trained on a random subsample of data. While effective, these attacks are extremely computationally expensive, especially when the model under attack is large.   We introduce a new class of attacks based on performing quantile regression on the distribution of confidence scores induced by the model under attack on points that are not used in training. We show that our method is competitive with state-of-the-art shadow model attacks, while requiring substantially less compute because our attack requires training only a single model. Moreover, unlike shadow model attacks, our proposed attack does not require any knowledge of the architecture of the model under attack and is therefore truly ``black-box". We show the efficacy of this approach in an extensive series of experiments on various datasets and model architectures.
</details>
<details>
<summary>摘要</summary>
域名推测攻击是用于判断一个特定示例是否在训练中使用了黑盒访问已经训练过的模型。域名推测可以形式化为一个假设测试问题。现有最有效的攻击方法是通过训练多个“陌生模型”（即与被攻击模型相同的架构的模型，被训练于Random subsets of data）来估计模型在真实标签上的信任度分布。然而，这些攻击非常 computationally expensive，特别是当模型被攻击时很大。我们介绍了一种新的攻击方法，基于模型下发的信任分布中的分值回归。我们表明，我们的方法与现有的陌生模型攻击相比，需要更少的计算资源，因为我们的攻击只需要训练一个模型。此外，我们的提议的攻击方法不需要知道模型下发的架构，因此是真正的“黑盒”攻击。我们在多个数据集和模型架构上进行了广泛的实验，证明了这种方法的有效性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/08/cs.LG_2023_07_08/" data-id="clpahu74q00o03h8893klegzj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_07_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/08/eess.IV_2023_07_08/" class="article-date">
  <time datetime="2023-07-08T09:00:00.000Z" itemprop="datePublished">2023-07-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/08/eess.IV_2023_07_08/">eess.IV - 2023-07-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Lightweight-Improved-Residual-Network-for-Efficient-Inverse-Tone-Mapping"><a href="#Lightweight-Improved-Residual-Network-for-Efficient-Inverse-Tone-Mapping" class="headerlink" title="Lightweight Improved Residual Network for Efficient Inverse Tone Mapping"></a>Lightweight Improved Residual Network for Efficient Inverse Tone Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03998">http://arxiv.org/abs/2307.03998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liqi Xue, Tianyi Xu, Yongbao Song, Yan Liu, Lei Zhang, Xiantong Zhen, Jun Xu</li>
<li>for: 用于SDR图像转换为HDR图像的高效 inverse tone mapping（ITM）。</li>
<li>methods: 提出了一种基于增强的 residual block 的轻量级 Improved Residual Network（IRNet），用于精细化HDR图像重建。</li>
<li>results: 在三个标准测试集上实现了State-of-the-art表现在ITM和 joint SR-ITM任务上。<details>
<summary>Abstract</summary>
The display devices like HDR10 televisions are increasingly prevalent in our daily life for visualizing high dynamic range (HDR) images. But the majority of media images on the internet remain in 8-bit standard dynamic range (SDR) format. Therefore, converting SDR images to HDR ones by inverse tone mapping (ITM) is crucial to unlock the full potential of abundant media images. However, existing ITM methods are usually developed with complex network architectures requiring huge computational costs. In this paper, we propose a lightweight Improved Residual Network (IRNet) by enhancing the power of popular residual block for efficient ITM. Specifically, we propose a new Improved Residual Block (IRB) to extract and fuse multi-layer features for fine-grained HDR image reconstruction. Experiments on three benchmark datasets demonstrate that our IRNet achieves state-of-the-art performance on both the ITM and joint SR-ITM tasks. The code, models and data will be publicly available at https://github.com/ThisisVikki/ITM-baseline.
</details>
<details>
<summary>摘要</summary>
显示设备如HDR10电视在我们日常生活中变得越来越普遍，用于可见化高动态范围（HDR）图像。但大多数网络图像仍然保留在8位标准动态范围（SDR）格式中。因此，将SDR图像转换成HDR图像的 inverse tone mapping（ITM）变得非常重要，以解锁丰富的网络图像的潜力。然而，现有的ITM方法通常具有复杂的网络架构，需要巨大的计算成本。在这篇论文中，我们提出了一种轻量级的改进的 residual 网络（IRNet），通过提高流行的 residual 块来提高精细度的 HDR 图像重建。具体来说，我们提出了一种新的改进的 residual 块（IRB），用于提取和融合多层特征进行精细度的 HDR 图像重建。实验结果表明，我们的 IRNet 在 ITM 和 joint SR-ITM 任务上均达到了状态略作性的表现。代码、模型和数据将在 GitHub 上公开，详细信息请参考 <https://github.com/ThisisVikki/ITM-baseline>。
</details></li>
</ul>
<hr>
<h2 id="Ariadne’s-Thread-Using-Text-Prompts-to-Improve-Segmentation-of-Infected-Areas-from-Chest-X-ray-images"><a href="#Ariadne’s-Thread-Using-Text-Prompts-to-Improve-Segmentation-of-Infected-Areas-from-Chest-X-ray-images" class="headerlink" title="Ariadne’s Thread:Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray images"></a>Ariadne’s Thread:Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03942">http://arxiv.org/abs/2307.03942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junelin2333/languidemedseg-miccai2023">https://github.com/junelin2333/languidemedseg-miccai2023</a></li>
<li>paper_authors: Yi Zhong, Mengqiu Xu, Kongming Liang, Kaixin Chen, Ming Wu</li>
<li>for: 本研究旨在提高肺病诊断的准确性，提出了一种语言驱动的医学图像分割方法，以增强图像分割结果的准确性。</li>
<li>methods: 本研究使用了语言提示来改进图像分割结果，并对QaTa-COV19数据集进行了实验，结果显示，与单Modal方法相比，语言驱动方法可以提高分割精度。</li>
<li>results: 本研究的结果表明，使用语言提示可以提高图像分割精度，并且对训练数据的大小有显著的优势。在QaTa-COV19数据集上，语言驱动方法的Dice分数提高6.09%以上，与单Modal方法相比。<details>
<summary>Abstract</summary>
Segmentation of the infected areas of the lung is essential for quantifying the severity of lung disease like pulmonary infections. Existing medical image segmentation methods are almost uni-modal methods based on image. However, these image-only methods tend to produce inaccurate results unless trained with large amounts of annotated data. To overcome this challenge, we propose a language-driven segmentation method that uses text prompt to improve to the segmentation result. Experiments on the QaTa-COV19 dataset indicate that our method improves the Dice score by 6.09% at least compared to the uni-modal methods. Besides, our extended study reveals the flexibility of multi-modal methods in terms of the information granularity of text and demonstrates that multi-modal methods have a significant advantage over image-only methods in terms of the size of training data required.
</details>
<details>
<summary>摘要</summary>
对于肺病的评估，分割感染区域的精确性是非常重要。现有的医疗影像分类方法都是基于图像的单 modal 方法，但这些图像仅方法往往会导致不准确的结果，除非训练数据量很大。为了解决这个挑战，我们提出了语言驱动的分类方法，使用文本提示来改善分类结果。实验结果显示，我们的方法在 QaTa-COV19 数据集上提高了 dice 分数6.09%至少，并且我们的扩展研究显示，多 modal 方法在文本信息粒度方面的灵活性和训练数据量方面的优势。
</details></li>
</ul>
<hr>
<h2 id="StyleGAN3-Generative-Networks-for-Improving-the-Equivariance-of-Translation-and-Rotation"><a href="#StyleGAN3-Generative-Networks-for-Improving-the-Equivariance-of-Translation-and-Rotation" class="headerlink" title="StyleGAN3: Generative Networks for Improving the Equivariance of Translation and Rotation"></a>StyleGAN3: Generative Networks for Improving the Equivariance of Translation and Rotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03898">http://arxiv.org/abs/2307.03898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianlei Zhu, Junqi Chen, Renzhe Zhu, Gaurav Gupta</li>
<li>for: 本研究的目的是评估StyleGAN2和两个修改后的StyleGAN3版本在生成图像方面的性能差异。</li>
<li>methods: 本研究使用的方法包括使用FFHQ数据集和FID、EQ-T和EQ-R指标评估模型的表现。</li>
<li>results: 研究发现，StyleGan3版本是一个更好的生成网络，可以提高图像的等距变换性。这些发现对动画和视频的创作有积极的影响。<details>
<summary>Abstract</summary>
StyleGAN can use style to affect facial posture and identity features, and noise to affect hair, wrinkles, skin color and other details. Among these, the outcomes of the picture processing will vary slightly between different versions of styleGAN. As a result, the comparison of performance differences between styleGAN2 and the two modified versions of styleGAN3 will be the main focus of this study. We used the FFHQ dataset as the dataset and FID, EQ-T, and EQ-R were used to be the assessment of the model. In the end, we discovered that Stylegan3 version is a better generative network to improve the equivariance. Our findings have a positive impact on the creation of animation and videos.
</details>
<details>
<summary>摘要</summary>
StyleGAN 可以通过风格影响 facial 姿态和人脸特征，并通过噪声影响头发、皮肤色、皱纹等细节。 Among these, 不同版本的 StyleGAN 的图像处理结果会有一些微妙的差异。因此，我们将在这种情况下进行 StyleGAN2 和两个修改版本的 StyleGAN3 之间的性能对比。我们使用 FFHQ 数据集作为数据集，并使用 FID、EQ-T 和 EQ-R 三种指标评估模型。最终，我们发现 StyleGAN3 版本是一个更好的生成网络，可以提高equivariance。我们的发现对动画和视频的创建产生了积极的影响。Here's the breakdown of the translation:* StyleGAN 可以通过风格影响 facial 姿态和人脸特征 (StyleGAN can use style to affect facial posture and identity features)* 并通过噪声影响头发、皮肤色、皱纹等细节 (and noise to affect hair, skin color, and other details)* Among these, 不同版本的 StyleGAN 的图像处理结果会有一些微妙的差异 (Among these, the outcomes of the picture processing will vary slightly between different versions of StyleGAN)* 因此，我们将在这种情况下进行 StyleGAN2 和两个修改版本的 StyleGAN3 之间的性能对比 (Therefore, we will compare the performance of StyleGAN2 and the two modified versions of StyleGAN3 in this situation)* 我们使用 FFHQ 数据集作为数据集 (We use the FFHQ dataset as the dataset)* 并使用 FID、EQ-T 和 EQ-R 三种指标评估模型 (And use three metrics to evaluate the model: FID, EQ-T, and EQ-R)* 最终，我们发现 StyleGAN3 版本是一个更好的生成网络，可以提高equivariance (Finally, we found that the StyleGAN3 version is a better generative network, which can improve equivariance)* 我们的发现对动画和视频的创建产生了积极的影响 (Our discovery has a positive impact on the creation of animation and videos)
</details></li>
</ul>
<hr>
<h2 id="TBSS-A-novel-computational-method-for-Tract-Based-Spatial-Statistics"><a href="#TBSS-A-novel-computational-method-for-Tract-Based-Spatial-Statistics" class="headerlink" title="TBSS++: A novel computational method for Tract-Based Spatial Statistics"></a>TBSS++: A novel computational method for Tract-Based Spatial Statistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05387">http://arxiv.org/abs/2307.05387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davood Karimi, Hamza Kebiri, Ali Gholipour</li>
<li>for: 这个论文旨在提高Diffusion-weighted磁共振成像（dMRI）中脑白 mater 的评估。</li>
<li>methods: 该论文提出了一种新的计算框架，通过（i）精准的脑 tract 分割，和（ii）交叉Subject数据的精准注册，以超越现有方法的缺陷和限制。</li>
<li>results: 与TBSS相比，该方法可以提供更高的重复性和数据抖动鲁棒性。<details>
<summary>Abstract</summary>
Diffusion-weighted magnetic resonance imaging (dMRI) is widely used to assess the brain white matter. One of the most common computations in dMRI involves cross-subject tract-specific analysis, whereby dMRI-derived biomarkers are compared between cohorts of subjects. The accuracy and reliability of these studies hinges on the ability to compare precisely the same white matter tracts across subjects. This is an intricate and error-prone computation. Existing computational methods such as Tract-Based Spatial Statistics (TBSS) suffer from a host of shortcomings and limitations that can seriously undermine the validity of the results. We present a new computational framework that overcomes the limitations of existing methods via (i) accurate segmentation of the tracts, and (ii) precise registration of data from different subjects/scans. The registration is based on fiber orientation distributions. To further improve the alignment of cross-subject data, we create detailed atlases of white matter tracts. These atlases serve as an unbiased reference space where the data from all subjects is registered for comparison. Extensive evaluations show that, compared with TBSS, our proposed framework offers significantly higher reproducibility and robustness to data perturbations. Our method promises a drastic improvement in accuracy and reproducibility of cross-subject dMRI studies that are routinely used in neuroscience and medical research.
</details>
<details>
<summary>摘要</summary>
Diffusion-weighted магнитно共振成像（dMRI）广泛用于评估大脑白 matter。一种最常见的计算在 dMRI 中是 между cohorts of subjects 进行 tract-specific 分析，其中 dMRI 得到的生物标志物被比较 между不同的subjects。这些研究的准确性和可靠性取决于能够准确比较不同subjects 中的白 matter tracts。现有的计算方法，如 Tract-Based Spatial Statistics（TBSS），受到严重的缺陷和限制，这些缺陷可能会严重地损害结果的有效性。我们提出了一个新的计算框架，该框架可以超越现有的方法的限制，通过（i）准确地分割 tracts，和（ii）精准地注册不同subjects/scans 的数据。注册基于纤维方向分布。为了进一步改进cross-subject数据的对Alignment，我们创建了详细的 white matter tracts  Atlases。这些 Atlases 作为一个不偏见的参照空间，用于注册所有subjects 的数据进行比较。广泛的评估表明，相比TBSS，我们提出的方法具有更高的可重现性和数据抖动强度的鲁棒性。我们的方法承诺可以在 neuroscience 和医学研究中提供明显的改进，以提高cross-subject dMRI 研究的准确性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Invariant-Scattering-Transform-for-Medical-Imaging"><a href="#Invariant-Scattering-Transform-for-Medical-Imaging" class="headerlink" title="Invariant Scattering Transform for Medical Imaging"></a>Invariant Scattering Transform for Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04771">http://arxiv.org/abs/2307.04771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nafisa Labiba Ishrat Huda, Angona Biswas, MD Abdullah Al Nasim, Md. Fahim Rahman, Shoaib Ahmed</li>
<li>for:  This paper is written for researchers and practitioners in the field of medical image analysis and deep learning, particularly those interested in using scattering transform for efficient image classification.</li>
<li>methods: The paper uses a novel approach called scattering transform, which combines signal processing and deep learning for medical image analysis. The transform is based on a wavelet technique that builds a useful signal representation for image classification.</li>
<li>results: The paper presents a step-by-step case study demonstrating the efficiency of scattering transform for medical image analysis, achieving high accuracy and outperforming traditional deep learning methods.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为医学图像分析和深度学习领域的研究人员和实践者写的，特别是关心使用散射变换进行高效的图像分类。</li>
<li>methods: 这篇论文使用了一种新的方法——散射变换，它将信号处理和深度学习两个领域融合在一起，用于医学图像分析。散射变换基于wavelet技术，建立了有用的信号表示，用于图像分类。</li>
<li>results: 这篇论文展示了一个步骤很多的案例研究，用于证明散射变换在医学图像分析中的高效性，并且超过了传统的深度学习方法。<details>
<summary>Abstract</summary>
Invariant scattering transform introduces new area of research that merges the signal processing with deep learning for computer vision. Nowadays, Deep Learning algorithms are able to solve a variety of problems in medical sector. Medical images are used to detect diseases brain cancer or tumor, Alzheimer's disease, breast cancer, Parkinson's disease and many others. During pandemic back in 2020, machine learning and deep learning has played a critical role to detect COVID-19 which included mutation analysis, prediction, diagnosis and decision making. Medical images like X-ray, MRI known as magnetic resonance imaging, CT scans are used for detecting diseases. There is another method in deep learning for medical imaging which is scattering transform. It builds useful signal representation for image classification. It is a wavelet technique; which is impactful for medical image classification problems. This research article discusses scattering transform as the efficient system for medical image analysis where it's figured by scattering the signal information implemented in a deep convolutional network. A step by step case study is manifested at this research work.
</details>
<details>
<summary>摘要</summary>
固定扩散变换引入了一新的研究领域，把信号处理与深度学习结合以应用于计算机视觉。目前，深度学习算法能够解决医疗领域多种问题。医疗图像用于检测脑瘤或肿瘤、阿尔茨曼病、乳腺癌、parkinson病和其他多种疾病。在2020年疫情期间，机器学习和深度学习扮演了关键角色，检测COVID-19，包括变异分析、预测、诊断和决策。医疗图像如X射线、MRI（磁共振成像）、CT扫描是用于检测疾病的。此外，深度学习还有另一种方法用于医疗图像分类，即扩散变换。它建立了有用的信号表示，用于图像分类问题。这篇研究文章讨论了扩散变换作为医疗图像分析的有效系统，其中使用了扩散信号信息在深度征值网络中实现。本研究文章还提供了一步步的实践案例。
</details></li>
</ul>
<hr>
<h2 id="Coordinate-based-neural-representations-for-computational-adaptive-optics-in-widefield-microscopy"><a href="#Coordinate-based-neural-representations-for-computational-adaptive-optics-in-widefield-microscopy" class="headerlink" title="Coordinate-based neural representations for computational adaptive optics in widefield microscopy"></a>Coordinate-based neural representations for computational adaptive optics in widefield microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03812">http://arxiv.org/abs/2307.03812</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iksungk/cocoa">https://github.com/iksungk/cocoa</a></li>
<li>paper_authors: Iksung Kang, Qinrong Zhang, Stella X. Yu, Na Ji<br>for:* 这个论文旨在描述一种基于自适应光学的Machine Learning算法，用于无侵入性地图像生物结构，并且可以在复杂的样品中提高图像质量。methods:* 这个算法使用了自适应光学技术，包括光谱扫描和激光扫描，以估计波前弯曲和三维结构信息。results:* 研究人员使用了这个算法，在实验室中成功地图像了一个 mouse brain 的三维结构，并且系统性地探讨了这个算法的性能的限制因素。<details>
<summary>Abstract</summary>
Widefield microscopy is widely used for non-invasive imaging of biological structures at subcellular resolution. When applied to complex specimen, its image quality is degraded by sample-induced optical aberration. Adaptive optics can correct wavefront distortion and restore diffraction-limited resolution but require wavefront sensing and corrective devices, increasing system complexity and cost. Here, we describe a self-supervised machine learning algorithm, CoCoA, that performs joint wavefront estimation and three-dimensional structural information extraction from a single input 3D image stack without the need for external training dataset. We implemented CoCoA for widefield imaging of mouse brain tissues and validated its performance with direct-wavefront-sensing-based adaptive optics. Importantly, we systematically explored and quantitatively characterized the limiting factors of CoCoA's performance. Using CoCoA, we demonstrated the first in vivo widefield mouse brain imaging using machine-learning-based adaptive optics. Incorporating coordinate-based neural representations and a forward physics model, the self-supervised scheme of CoCoA should be applicable to microscopy modalities in general.
</details>
<details>
<summary>摘要</summary>
广角微scopia 广泛应用于非侵入性的生物结构成像，其图像质量在复杂样品下受样品引起的光学扭曲的影响。可适应光学可以修复波前弯曲和恢复 diffraction-limited 分辨率，但需要波前测量和修正设备，从而增加系统复杂度和成本。我们描述了一种自主学习机器学习算法 CoCoA，它可以在单个输入 3D 图像堆中同时进行波前估计和三维结构信息提取，无需外部训练集。我们在宽场探针中实现了 CoCoA，并通过 direct-wavefront-sensing-based adaptive optics 进行验证。重要的是，我们系统地探索和量化 CoCoA 的性能限制因素。使用 CoCoA，我们实现了首次在 vivo 宽场 mouse brain 成像，使用机器学习基于 adaptive optics 。通过卷积 нейрон表示和前向物理模型，CoCoA 的自主学习方案应用于 microscopy Modalities 中。
</details></li>
</ul>
<hr>
<h2 id="Thoracic-Cartilage-Ultrasound-CT-Registration-using-Dense-Skeleton-Graph"><a href="#Thoracic-Cartilage-Ultrasound-CT-Registration-using-Dense-Skeleton-Graph" class="headerlink" title="Thoracic Cartilage Ultrasound-CT Registration using Dense Skeleton Graph"></a>Thoracic Cartilage Ultrasound-CT Registration using Dense Skeleton Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03800">http://arxiv.org/abs/2307.03800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongliang Jiang, Chenyang Li, Xuesong Li, Nassir Navab</li>
<li>for: 用于实现自适应超声成像，尤其是在骨骼结构下面的高频率吸收层面上。</li>
<li>methods: 使用图形基于非导入注册方法，特别是利用骨表面特征来转移规划路径。</li>
<li>results: 可以有效地将规划路径从CT图像传播到当前设置下的US视图，并且可以减少干扰。<details>
<summary>Abstract</summary>
Autonomous ultrasound (US) imaging has gained increased interest recently, and it has been seen as a potential solution to overcome the limitations of free-hand US examinations, such as inter-operator variations. However, it is still challenging to accurately map planned paths from a generic atlas to individual patients, particularly for thoracic applications with high acoustic-impedance bone structures under the skin. To address this challenge, a graph-based non-rigid registration is proposed to enable transferring planned paths from the atlas to the current setup by explicitly considering subcutaneous bone surface features instead of the skin surface. To this end, the sternum and cartilage branches are segmented using a template matching to assist coarse alignment of US and CT point clouds. Afterward, a directed graph is generated based on the CT template. Then, the self-organizing map using geographical distance is successively performed twice to extract the optimal graph representations for CT and US point clouds, individually. To evaluate the proposed approach, five cartilage point clouds from distinct patients are employed. The results demonstrate that the proposed graph-based registration can effectively map trajectories from CT to the current setup for displaying US views through limited intercostal space. The non-rigid registration results in terms of Hausdorff distance (Mean$\pm$SD) is 9.48$\pm$0.27 mm and the path transferring error in terms of Euclidean distance is 2.21$\pm$1.11 mm.
</details>
<details>
<summary>摘要</summary>
自主式超声成像（US）在最近几年内得到了更多的关注，被视为可以超越自由手操作US检测的限制。然而，准确地将规划路径从通用 Atlas 传递到当前设置仍然是一项挑战，特别是在骨盆部应用中，因为有高频率声 impedance 结构位于皮肤下。为解决这个挑战，一种基于图的非RIGID  региstración被提议，以便将规划路径从 Atlas 传递到当前设置，并且Explicitly 考虑到骨质表面特征而不是皮肤表面。为此，使用模板匹配 segment 胸板和软骨支持的 Cartilage 分支。然后，基于 CT 模板生成一个指向图。接着，使用自组织地图进行两次 Successive 地执行 geographical distance 自适应映射，以提取 CT 和 US 点云的最佳图表示。为评估提议方法，使用了五个不同患者的 Cartilage 点云。结果表明，提议的图基于REGISTRATION 可以有效地将 CT 的规划路径传递到当前设置，并且非RIGID  регистраción的 Hausdorff 距离（Mean ± SD）为 9.48 ± 0.27 mm，路径传递错误（Euclidean 距离）为 2.21 ± 1.11 mm。
</details></li>
</ul>
<hr>
<h2 id="Motion-Magnification-in-Robotic-Sonography-Enabling-Pulsation-Aware-Artery-Segmentation"><a href="#Motion-Magnification-in-Robotic-Sonography-Enabling-Pulsation-Aware-Artery-Segmentation" class="headerlink" title="Motion Magnification in Robotic Sonography: Enabling Pulsation-Aware Artery Segmentation"></a>Motion Magnification in Robotic Sonography: Enabling Pulsation-Aware Artery Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03698">http://arxiv.org/abs/2307.03698</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dianyehuang/robpmepasnn">https://github.com/dianyehuang/robpmepasnn</a></li>
<li>paper_authors: Dianye Huang, Yuan Bi, Nassir Navab, Zhongliang Jiang</li>
<li>for: 用于诊断和监测arterial疾病，提供非侵入、无辐射、实时的优势。</li>
<li>methods: 使用neuronal网络（PAS-NN），利用心跳刺激信号，提高血管分割精度和稳定性。</li>
<li>results: 在 volontiers的carotid和radial artery上进行实验， demonstarted that PAS-NN可以与当前最佳方法匹配，并有效地改善小血管（radial artery）的分割性能。<details>
<summary>Abstract</summary>
Ultrasound (US) imaging is widely used for diagnosing and monitoring arterial diseases, mainly due to the advantages of being non-invasive, radiation-free, and real-time. In order to provide additional information to assist clinicians in diagnosis, the tubular structures are often segmented from US images. To improve the artery segmentation accuracy and stability during scans, this work presents a novel pulsation-assisted segmentation neural network (PAS-NN) by explicitly taking advantage of the cardiac-induced motions. Motion magnification techniques are employed to amplify the subtle motion within the frequency band of interest to extract the pulsation signals from sequential US images. The extracted real-time pulsation information can help to locate the arteries on cross-section US images; therefore, we explicitly integrated the pulsation into the proposed PAS-NN as attention guidance. Notably, a robotic arm is necessary to provide stable movement during US imaging since magnifying the target motions from the US images captured along a scan path is not manually feasible due to the hand tremor. To validate the proposed robotic US system for imaging arteries, experiments are carried out on volunteers' carotid and radial arteries. The results demonstrated that the PAS-NN could achieve comparable results as state-of-the-art on carotid and can effectively improve the segmentation performance for small vessels (radial artery).
</details>
<details>
<summary>摘要</summary>
ultrasound（US）成像广泛应用于诊断和监测动脉疾病，主要是因为它不侵入、无辐射和实时。为了为临床医生提供更多的诊断信息，在US图像中分割动脉结构成为一项重要任务。为了提高动脉分割精度和稳定性，本工作提出了一种基于征动脉信号的新型激活分割神经网络（PAS-NN）。使用了振荡增强技术来增强US图像中的某些频谱信息，以提取动脉的征动脉信号。这些实时征动脉信号可以帮助在US图像的横截面上定位动脉，因此我们直接将征动脉信号 интеGRATED到提案的PAS-NN中作为注意力引导。需要注意的是，为了保证US成像过程中的稳定运动，需要使用机器人臂提供稳定的运动。为验证提案的机器人US系统是否能够成功地成像动脉，我们在志愿者的轮状和 radial artery 上进行了实验。结果表明，PAS-NN可以与当前最佳的结果相比，并且可以有效地提高小动脉（ radial artery）的分割性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/08/eess.IV_2023_07_08/" data-id="clpahu7bo01713h885v4z3qjf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/cs.SD_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T15:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/cs.SD_2023_07_07/">cs.SD - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-CHiME-7-UDASE-task-Unsupervised-domain-adaptation-for-conversational-speech-enhancement"><a href="#The-CHiME-7-UDASE-task-Unsupervised-domain-adaptation-for-conversational-speech-enhancement" class="headerlink" title="The CHiME-7 UDASE task: Unsupervised domain adaptation for conversational speech enhancement"></a>The CHiME-7 UDASE task: Unsupervised domain adaptation for conversational speech enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03533">http://arxiv.org/abs/2307.03533</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Leglaive, Léonie Borne, Efthymios Tzinis, Mostafa Sadeghi, Matthieu Fraticelli, Scott Wisdom, Manuel Pariente, Daniel Pressnitzer, John R. Hershey</li>
<li>for: 这篇论文的目的是提出一个无监督领域适应对话音频减噪任务（UDASE），以利用实际采集的噪声听写记录来适应语音减噪模型。</li>
<li>methods: 这篇论文使用了无监督领域适应技术，利用实际采集的噪声听写记录来适应语音减噪模型。</li>
<li>results: 这篇论文提出了一个基eline系统，用于解决 conversational speech 中的噪声问题。<details>
<summary>Abstract</summary>
Supervised speech enhancement models are trained using artificially generated mixtures of clean speech and noise signals, which may not match real-world recording conditions at test time. This mismatch can lead to poor performance if the test domain significantly differs from the synthetic training domain. In this paper, we introduce the unsupervised domain adaptation for conversational speech enhancement (UDASE) task of the 7th CHiME challenge. This task aims to leverage real-world noisy speech recordings from the target test domain for unsupervised domain adaptation of speech enhancement models. The target test domain corresponds to the multi-speaker reverberant conversational speech recordings of the CHiME-5 dataset, for which the ground-truth clean speech reference is not available. Given a CHiME-5 recording, the task is to estimate the clean, potentially multi-speaker, reverberant speech, removing the additive background noise. We discuss the motivation for the CHiME-7 UDASE task and describe the data, the task, and the baseline system.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>超级vised语音提升模型通常通过人工生成的清晰语音和噪声信号混合来进行训练，这些混合可能不符合实际录音条件。这种匹配不符问题可能会导致测试时的性能差。在这篇论文中，我们介绍了无监督领域适应对话语音提升任务（UDASE）的7个CHiME挑战。这个任务的目标是利用真实世界的噪声语音记录来无监督适应语音提升模型。目标测试频道对应的是CHiME-5数据集中的多个说话人 reverberant conversational speech记录，其中没有清晰语音参考。给一个CHiME-5记录，任务是估算清晰、可能多个说话人、 reverberant speech，从噪声背景噪声中移除。我们介绍了CHiME-7 UDASE任务的动机和数据、任务和基eline系统。
</details></li>
</ul>
<hr>
<h2 id="Token-Level-Serialized-Output-Training-for-Joint-Streaming-ASR-and-ST-Leveraging-Textual-Alignments"><a href="#Token-Level-Serialized-Output-Training-for-Joint-Streaming-ASR-and-ST-Leveraging-Textual-Alignments" class="headerlink" title="Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments"></a>Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03354">http://arxiv.org/abs/2307.03354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Papi, Peidong Wan, Junkun Chen, Jian Xue, Jinyu Li, Yashesh Gaur</li>
<li>for: 这篇论文旨在提高实时语音识别和翻译的效果，并且使用单一decoder进行同时生成ASR和ST输出。</li>
<li>methods: 该方法使用一种joint token-level serialized output训练方法，通过利用市场上的文本对齐器来实现源和目标词的混合。</li>
<li>results: 实验表明，该方法在单语言（it-en）和多语言（de,es,it）设置下均能够达到最佳的质量-延迟平衡，并且与分立的ASR和ST模型相比，输出质量不减、甚至提高了0.4 BLEU和1.1 WER。<details>
<summary>Abstract</summary>
In real-world applications, users often require both translations and transcriptions of speech to enhance their comprehension, particularly in streaming scenarios where incremental generation is necessary. This paper introduces a streaming Transformer-Transducer that jointly generates automatic speech recognition (ASR) and speech translation (ST) outputs using a single decoder. To produce ASR and ST content effectively with minimal latency, we propose a joint token-level serialized output training method that interleaves source and target words by leveraging an off-the-shelf textual aligner. Experiments in monolingual (it-en) and multilingual (\{de,es,it\}-en) settings demonstrate that our approach achieves the best quality-latency balance. With an average ASR latency of 1s and ST latency of 1.3s, our model shows no degradation or even improves output quality compared to separate ASR and ST models, yielding an average improvement of 1.1 WER and 0.4 BLEU in the multilingual case.
</details>
<details>
<summary>摘要</summary>
在实际应用中，用户经常需要同时获得翻译和转写的speech内容，以提高其理解度，特别在流媒体enario中，需要逐步生成。这篇论文介绍了一个流动Transformer-Transducer，通过单个解码器同时生成自动语音识别（ASR）和语音翻译（ST）输出。为了在最小延迟下生成ASR和ST内容，我们提议使用单个Token水平的 serialized输出训练方法，通过利用市场上的文本对齐器来扩展源和目标词。实验在单语言（it-en）和多语言（de,es,it）的设置下表明，我们的方法可以实现最佳的质量-延迟平衡。我们的模型在1s的ASR延迟和1.3s的ST延迟下，不产生质量下降或者even improves输出质量，相对于分离的ASR和ST模型，平均提高1.1 WER和0.4 BLEU的多语言情况。
</details></li>
</ul>
<hr>
<h2 id="Gammatonegram-Representation-for-End-to-End-Dysarthric-Speech-Processing-Tasks-Speech-Recognition-Speaker-Identification-and-Intelligibility-Assessment"><a href="#Gammatonegram-Representation-for-End-to-End-Dysarthric-Speech-Processing-Tasks-Speech-Recognition-Speaker-Identification-and-Intelligibility-Assessment" class="headerlink" title="Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment"></a>Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03296">http://arxiv.org/abs/2307.03296</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/areffarhadi/gammatonegram_cnn_dysarthric_speech">https://github.com/areffarhadi/gammatonegram_cnn_dysarthric_speech</a></li>
<li>paper_authors: Aref Farhadipour, Hadi Veisi</li>
<li>for:  This paper aims to develop a system for speech recognition, speaker identification, and intelligibility assessment for individuals with dysarthria.</li>
<li>methods:  The proposed system uses gammatonegram to represent audio files with discriminative details, which are then fed into a convolutional neural network (CNN) for recognition. The system also employs transfer learning and Alexnet pre-training for improved accuracy.</li>
<li>results:  The proposed system achieved 91.29% accuracy in speaker-dependent mode, 87.74% accuracy in text-dependent mode, and 96.47% accuracy in two-class mode for intelligibility assessment. Additionally, the multi-network speech recognition system achieved an accuracy of 92.3% WRR.<details>
<summary>Abstract</summary>
Dysarthria is a disability that causes a disturbance in the human speech system and reduces the quality and intelligibility of a person's speech. Because of this effect, the normal speech processing systems can not work properly on impaired speech. This disability is usually associated with physical disabilities. Therefore, designing a system that can perform some tasks by receiving voice commands in the smart home can be a significant achievement. In this work, we introduce gammatonegram as an effective method to represent audio files with discriminative details, which is used as input for the convolutional neural network. On the other word, we convert each speech file into an image and propose image recognition system to classify speech in different scenarios. Proposed CNN is based on the transfer learning method on the pre-trained Alexnet. In this research, the efficiency of the proposed system for speech recognition, speaker identification, and intelligibility assessment is evaluated. According to the results on the UA dataset, the proposed speech recognition system achieved 91.29% accuracy in speaker-dependent mode, the speaker identification system acquired 87.74% accuracy in text-dependent mode, and the intelligibility assessment system achieved 96.47% accuracy in two-class mode. Finally, we propose a multi-network speech recognition system that works fully automatically. This system is located in a cascade arrangement with the two-class intelligibility assessment system, and the output of this system activates each one of the speech recognition networks. This architecture achieves an accuracy of 92.3% WRR. The source code of this paper is available.
</details>
<details>
<summary>摘要</summary>
<<sys.translation.content>>嗣瑞thesis是一种功能受限的人类语言系统的异常，导致人类语音质量和可理解性降低。由于这种效果，常规的语音处理系统无法正常工作。这种疾病通常与物理障碍有关。因此，设计一个可以通过声音命令在智能家庭中完成一些任务的系统可以是一项重要成果。在这种工作中，我们介绍了一种有效的方法来表示音频文件的特征，即干扰agram。即将每个语音文件转换成图像，并提议图像识别系统来分类语音在不同的场景中。我们的CNN基于传输学习方法，使用预训练的Alexnet。在这项研究中，我们评估了提议的系统的效率，包括语音识别、说话人识别和可理解性评估。根据UA数据集的结果，我们的语音识别系统在 speaker-dependent 模式下达到了 91.29% 的准确率，说话人识别系统在 text-dependent 模式下达到了 87.74% 的准确率，而可理解性评估系统在 two-class 模式下达到了 96.47% 的准确率。最后，我们提议了一个多网络语音识别系统，该系统位于堆叠式排序中，以及每个语音识别网络的输出。这种架构达到了 92.3% WRR 的准确率。本文的源代码可以获取。<</sys.translation.content>>
</details></li>
</ul>
<hr>
<h2 id="Performance-Comparison-of-Pre-trained-Models-for-Speech-to-Text-in-Turkish-Whisper-Small-and-Wav2Vec2-XLS-R-300M"><a href="#Performance-Comparison-of-Pre-trained-Models-for-Speech-to-Text-in-Turkish-Whisper-Small-and-Wav2Vec2-XLS-R-300M" class="headerlink" title="Performance Comparison of Pre-trained Models for Speech-to-Text in Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M"></a>Performance Comparison of Pre-trained Models for Speech-to-Text in Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04765">http://arxiv.org/abs/2307.04765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oyku Berfin Mercan, Sercan Cepni, Davut Emre Tasar, Sukru Ozan</li>
<li>for: 本研究探讨了两种预训练多语言模型（Whisper-Small和Wav2Vec2-XLS-R-300M）在土耳其语言上的表现。</li>
<li>methods: 本研究使用了Mozilla Common Voice版本11.0，这是一个开源的土耳其语言数据集，并对两种模型进行了微调。</li>
<li>results: 研究发现，使用Wav2Vec2-XLS-R-300M模型可以得到更高的语音识别精度（WER值为0.16），而使用Whisper-Small模型的WER值为0.28。此外，研究还发现，使用测试数据集，不包括在训练和验证数据集中的call center记录，可以提高模型的表现。<details>
<summary>Abstract</summary>
In this study, the performances of the Whisper-Small and Wav2Vec2-XLS-R-300M models which are two pre-trained multilingual models for speech to text were examined for the Turkish language. Mozilla Common Voice version 11.0 which is prepared in Turkish language and is an open-source data set, was used in the study. The multilingual models, Whisper- Small and Wav2Vec2-XLS-R-300M were fine-tuned with this data set which contains a small amount of data. The speech to text performance of the two models was compared. WER values are calculated as 0.28 and 0.16 for the Wav2Vec2-XLS- R-300M and the Whisper-Small models respectively. In addition, the performances of the models were examined with the test data prepared with call center records that were not included in the training and validation dataset.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们研究了两种预训练的多语言模型：Whisper-Small和Wav2Vec2-XLS-R-300M，用于识别土耳其语。这些模型在土耳其语 Mozilla Common Voice 版本11.0 数据集上进行了训练和测试。这个数据集包含一小量的数据，我们使用这些数据来精度地训练和测试这两种模型。我们计算了 WER 值，其中 Wav2Vec2-XLS-R-300M 的 WER 值为 0.28，Whisper-Small 模型的 WER 值为 0.16。此外，我们还测试了这两种模型在未包括在训练和验证数据集中的测试数据上的性能。
</details></li>
</ul>
<hr>
<h2 id="Whisper-AT-Noise-Robust-Automatic-Speech-Recognizers-are-Also-Strong-General-Audio-Event-Taggers"><a href="#Whisper-AT-Noise-Robust-Automatic-Speech-Recognizers-are-Also-Strong-General-Audio-Event-Taggers" class="headerlink" title="Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong General Audio Event Taggers"></a>Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong General Audio Event Taggers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03183">http://arxiv.org/abs/2307.03183</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YuanGongND/whisper-at">https://github.com/YuanGongND/whisper-at</a></li>
<li>paper_authors: Yuan Gong, Sameer Khurana, Leonid Karlinsky, James Glass</li>
<li>for: 这个论文专注于 Whisper 模型，一种基于大量标注的语音识别模型，以及该模型在不同环境下的表现。</li>
<li>methods: 论文首先展示了 Whisper 模型对真实世界背景噪音的强健性，但它的音频表示并不是噪音不变的，而是高度相关于非语音噪音。基于这一发现，论文建立了一个简单的音频标记和语音识别模型 Whisper-AT，通过冻结 Whisper 的背bone，并在顶部添加一个轻量级的音频标记模型。</li>
<li>results: Whisper-AT 可以在单个前进 pass 中同时进行语音识别和音频标记，并且只需 &lt;1% 的额外计算成本。<details>
<summary>Abstract</summary>
In this paper, we focus on Whisper, a recent automatic speech recognition model trained with a massive 680k hour labeled speech corpus recorded in diverse conditions. We first show an interesting finding that while Whisper is very robust against real-world background sounds (e.g., music), its audio representation is actually not noise-invariant, but is instead highly correlated to non-speech sounds, indicating that Whisper recognizes speech conditioned on the noise type. With this finding, we build a unified audio tagging and speech recognition model Whisper-AT by freezing the backbone of Whisper, and training a lightweight audio tagging model on top of it. With <1% extra computational cost, Whisper-AT can recognize audio events, in addition to spoken text, in a single forward pass.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们关注Whisper，一种最近的自动语音识别模型，使用了巨量的680万小时标注的语音词汇录音数据，录制在多种条件下。我们首先发现一个有趣的现象，即Whisper对实际世界背景声（如音乐）非常鲁棒，但它的音频表示并不是噪声不变的，而是高度相关于非语音声音，表明Whisper识别语音 conditional 于噪声类型。基于这一发现，我们构建了一个整合音频标记和语音识别模型Whisper-AT，通过冻结Whisper的背bone，并在其上训练一个轻量级音频标记模型。与<1%的额外计算成本，Whisper-AT可以在单个前进通过recognize audio事件，以及说话文本，在一个前进中完成。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/cs.SD_2023_07_07/" data-id="clpahu77f00vt3h887hjlbes4" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/eess.AS_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T14:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/eess.AS_2023_07_07/">eess.AS - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Recovering-implicit-pitch-contours-from-formants-in-whispered-speech"><a href="#Recovering-implicit-pitch-contours-from-formants-in-whispered-speech" class="headerlink" title="Recovering implicit pitch contours from formants in whispered speech"></a>Recovering implicit pitch contours from formants in whispered speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03168">http://arxiv.org/abs/2307.03168</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pablo Pérez Zarazaga, Zofia Malisz</li>
<li>for: 这个论文主要研究了whisper speech中的intonation的感知和表达方式。</li>
<li>methods: 作者使用了一种两步方法，首先使用平行 corpus 将whisper中的声学特征转换成相应的phonatedEquivalents，然后分析声学特征来预测phonated pitch contour的变化。</li>
<li>results: 研究发现，使用这种方法可以确定whisper中的声学特征和phonated pitch contour之间的关系，并揭示了whisper中的implicit pitch contour。<details>
<summary>Abstract</summary>
Whispered speech is characterised by a noise-like excitation that results in the lack of fundamental frequency. Considering that prosodic phenomena such as intonation are perceived through f0 variation, the perception of whispered prosody is relatively difficult. At the same time, studies have shown that speakers do attempt to produce intonation when whispering and that prosodic variability is being transmitted, suggesting that intonation "survives" in whispered formant structure. In this paper, we aim to estimate the way in which formant contours correlate with an "implicit" pitch contour in whisper, using a machine learning model. We propose a two-step method: using a parallel corpus, we first transform the whispered formants into their phonated equivalents using a denoising autoencoder. We then analyse the formant contours to predict phonated pitch contour variation. We observe that our method is effective in establishing a relationship between whispered and phonated formants and in uncovering implicit pitch contours in whisper.
</details>
<details>
<summary>摘要</summary>
含秘语言特征为噪声类刺激，导致基本频率的缺失。由于语音学中的听觉现象如声调变化是通过f0变化传递的，因此听众对潜 voce 的识别相对较难。然而，研究表明，当speaker whispering时，他们仍会尝试生成声调，并且发现了不同的语音变化，表明声调在潜 voce 中存在。在这篇论文中，我们想使用机器学习模型来估算潜 voce 中形式轨迹与隐藏的声调轨迹之间的相关性。我们提出了一种两步方法：首先，使用平行 корпу斯，将潜 voce 的形式轨迹转换为其相应的声调轨迹，使用杜因噪声自适应神经网络。然后，我们分析形式轨迹，预测声调轨迹的变化。我们发现，我们的方法能够有效地建立潜 voce 中形式轨迹和声调轨迹之间的关系，并且揭示了隐藏的声调轨迹。
</details></li>
</ul>
<hr>
<h2 id="Label-Synchronous-Neural-Transducer-for-End-to-End-ASR"><a href="#Label-Synchronous-Neural-Transducer-for-End-to-End-ASR" class="headerlink" title="Label-Synchronous Neural Transducer for End-to-End ASR"></a>Label-Synchronous Neural Transducer for End-to-End ASR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03088">http://arxiv.org/abs/2307.03088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keqi Deng, Philip C. Woodland</li>
<li>for: 这篇论文是关于 streaming ASR 的自然途径，但是它在使用文本数据进行预测时遇到了挑战。</li>
<li>methods: 该论文提出了一种 label-同步神经转换器 (LS-Transducer)，它在输出序列中提取出了标签水平编码表示，然后将其与预测网络输出结合。这样，不再需要使用空token，并且可以轻松地适应文本数据。此外，论文还提出了一种自动循环整合和触发 (AIF) 机制，以生成标筹水平编码表示。</li>
<li>results: 实验表明，相比标准神经转换器，提出的 LS-Transducer 在内部预测 Librispeech-100h 数据上减少了10%的相对WRER（文本识别错误率），以及在跨频度的 TED-LIUM 2 和 AESRC2020 数据上减少了17%和19%的相对WRER。<details>
<summary>Abstract</summary>
Neural transducers provide a natural approach to streaming ASR. However, they augment output sequences with blank tokens which leads to challenges for domain adaptation using text data. This paper proposes a label-synchronous neural transducer (LS-Transducer), which extracts a label-level encoder representation before combining it with the prediction network output. Hence blank tokens are no longer needed and the prediction network can be easily adapted using text data. An Auto-regressive Integrate-and-Fire (AIF) mechanism is proposed to generate the label-level encoder representation while retaining the streaming property. In addition, a streaming joint decoding method is designed to improve ASR accuracy. Experiments show that compared to standard neural transducers, the proposed LS-Transducer gave a 10% relative WER reduction (WERR) for intra-domain Librispeech-100h data, as well as 17% and 19% relative WERRs on cross-domain TED-LIUM 2 and AESRC2020 data with an adapted prediction network.
</details>
<details>
<summary>摘要</summary>
“神经变换器提供了自然的流处理ASR方法。然而，它们在输出序列中添加空token，导致领域适应使用文本数据具有挑战。这篇论文提议了一种标签同步神经变换器（LS-Transducer），它在组合预测网络输出之前提取标签水平Encoder表示。因此，空token不再需要，预测网络可以轻松地适应文本数据。此外，一种自动重启综合射频（AIF）机制被提议，以生成标签水平Encoder表示，同时保持流处理性。此外，一种流处理共同解码方法被设计，以提高ASR准确性。实验表明，相比标准神经变换器，提议的LS-Transducer在内领域Librispeech-100h数据上减少了10%的相对WRER（文本识别错误率），以及在跨领域TED-LIUM 2和AESRC2020数据上适应预测网络后减少了17%和19%的相对WRER。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/eess.AS_2023_07_07/" data-id="clpahu7a301363h883mlzcdr0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/cs.CV_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T13:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/cs.CV_2023_07_07/">cs.CV - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Detecting-the-Sensing-Area-of-A-Laparoscopic-Probe-in-Minimally-Invasive-Cancer-Surgery"><a href="#Detecting-the-Sensing-Area-of-A-Laparoscopic-Probe-in-Minimally-Invasive-Cancer-Surgery" class="headerlink" title="Detecting the Sensing Area of A Laparoscopic Probe in Minimally Invasive Cancer Surgery"></a>Detecting the Sensing Area of A Laparoscopic Probe in Minimally Invasive Cancer Surgery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03662">http://arxiv.org/abs/2307.03662</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/br0202/sensing_area_detection">https://github.com/br0202/sensing_area_detection</a></li>
<li>paper_authors: Baoru Huang, Yicheng Hu, Anh Nguyen, Stamatia Giannarou, Daniel S. Elson</li>
<li>for: 针对于医学领域中的外科手术预测和肿瘤检测。</li>
<li>methods: 使用了一种新型的缚定式 Laparoscope γ射测定器，以实时地local化预先注射的辐源追踪剂。</li>
<li>results: 通过利用高维度的图像特征和探针位置信息，成功解决了γ活动视图化的问题，并创造了一个新的性能标准。<details>
<summary>Abstract</summary>
In surgical oncology, it is challenging for surgeons to identify lymph nodes and completely resect cancer even with pre-operative imaging systems like PET and CT, because of the lack of reliable intraoperative visualization tools. Endoscopic radio-guided cancer detection and resection has recently been evaluated whereby a novel tethered laparoscopic gamma detector is used to localize a preoperatively injected radiotracer. This can both enhance the endoscopic imaging and complement preoperative nuclear imaging data. However, gamma activity visualization is challenging to present to the operator because the probe is non-imaging and it does not visibly indicate the activity origination on the tissue surface. Initial failed attempts used segmentation or geometric methods, but led to the discovery that it could be resolved by leveraging high-dimensional image features and probe position information. To demonstrate the effectiveness of this solution, we designed and implemented a simple regression network that successfully addressed the problem. To further validate the proposed solution, we acquired and publicly released two datasets captured using a custom-designed, portable stereo laparoscope system. Through intensive experimentation, we demonstrated that our method can successfully and effectively detect the sensing area, establishing a new performance benchmark. Code and data are available at https://github.com/br0202/Sensing_area_detection.git
</details>
<details>
<summary>摘要</summary>
在外科onkology中，外科医生很难识别lymph nodes和完全 remove cancer，即使使用预先的内分析系统如PET和CT。这是因为在手术中没有可靠的实时显示工具。Recently, endoscopic radio-guided cancer detection and resection has been evaluated, which uses a novel tethered laparoscopic gamma detector to localize a preoperatively injected radiotracer. This can both enhance endoscopic imaging and complement preoperative nuclear imaging data. However, gamma activity visualization is challenging to present to the operator because the probe is non-imaging and does not visibly indicate the activity origination on the tissue surface. Initial attempts used segmentation or geometric methods, but these were unsuccessful. Instead, we found that the problem could be resolved by leveraging high-dimensional image features and probe position information. To demonstrate the effectiveness of this solution, we designed and implemented a simple regression network that successfully addressed the problem. To further validate the proposed solution, we acquired and publicly released two datasets captured using a custom-designed, portable stereo laparoscope system. Through intensive experimentation, we demonstrated that our method can successfully and effectively detect the sensing area, establishing a new performance benchmark. Code and data are available at <https://github.com/br0202/Sensing_area_detection.git>.
</details></li>
</ul>
<hr>
<h2 id="Robust-Human-Detection-under-Visual-Degradation-via-Thermal-and-mmWave-Radar-Fusion"><a href="#Robust-Human-Detection-under-Visual-Degradation-via-Thermal-and-mmWave-Radar-Fusion" class="headerlink" title="Robust Human Detection under Visual Degradation via Thermal and mmWave Radar Fusion"></a>Robust Human Detection under Visual Degradation via Thermal and mmWave Radar Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03623">http://arxiv.org/abs/2307.03623</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ramdrop/utm">https://github.com/ramdrop/utm</a></li>
<li>paper_authors: Kaiwen Cai, Qiyue Xia, Peize Li, John Stankovic, Chris Xiaoxuan Lu</li>
<li>for: 本研究旨在提出一种多模态人体检测系统，用于解决在质量不佳的视觉条件下人体检测的问题。</li>
<li>methods: 本研究使用了可携带式热成像相机和单芯片mm波雷达，并提出了一种bayesian特征提取器和一种uncertainty-guided融合方法来减少热成像检测特征的噪音和雷达点云的多 PATH噪声。</li>
<li>results: 本研究对实际数据集进行评估，并证明了我们的方法在多种竞争方法中具有显著的优势，包括单模态和多模态方法。<details>
<summary>Abstract</summary>
The majority of human detection methods rely on the sensor using visible lights (e.g., RGB cameras) but such sensors are limited in scenarios with degraded vision conditions. In this paper, we present a multimodal human detection system that combines portable thermal cameras and single-chip mmWave radars. To mitigate the noisy detection features caused by the low contrast of thermal cameras and the multi-path noise of radar point clouds, we propose a Bayesian feature extractor and a novel uncertainty-guided fusion method that surpasses a variety of competing methods, either single-modal or multi-modal. We evaluate the proposed method on real-world data collection and demonstrate that our approach outperforms the state-of-the-art methods by a large margin.
</details>
<details>
<summary>摘要</summary>
大多数人员探测方法都是使用可见光（例如RGB摄像头），但这些感知器在有很差视力条件下效果有限。在这篇论文中，我们提出了一种多模态人员探测系统，该系统结合携带式热成像镜头和单 chip MM 微波雷达。为了减少热成像镜头的噪声探测特征和雷达点云的多重反射噪声，我们提议了一种 bayesian 特征提取器和一种新的不确定性导向融合方法。我们对实际数据收集进行了评估，并证明了我们的方法在比较方法中具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Depth-Estimation-Analysis-of-Orthogonally-Divergent-Fisheye-Cameras-with-Distortion-Removal"><a href="#Depth-Estimation-Analysis-of-Orthogonally-Divergent-Fisheye-Cameras-with-Distortion-Removal" class="headerlink" title="Depth Estimation Analysis of Orthogonally Divergent Fisheye Cameras with Distortion Removal"></a>Depth Estimation Analysis of Orthogonally Divergent Fisheye Cameras with Distortion Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03602">http://arxiv.org/abs/2307.03602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matvei Panteleev, Houari Bettahar</li>
<li>for: 提高 fisheye 相机镜像干扰矫正和深度估计精度</li>
<li>methods: 使用两个虚拟平铺相机（VPC），每个VPC捕捉小区域，并将其呈现无镜面偏扭变，模拟平铺相机的行为</li>
<li>results: 对虚拟环境和实际相机实验结果进行比较，显示提案方法可以减少干扰和改善深度估计精度<details>
<summary>Abstract</summary>
Stereo vision systems have become popular in computer vision applications, such as 3D reconstruction, object tracking, and autonomous navigation. However, traditional stereo vision systems that use rectilinear lenses may not be suitable for certain scenarios due to their limited field of view. This has led to the popularity of vision systems based on one or multiple fisheye cameras in different orientations, which can provide a field of view of 180x180 degrees or more. However, fisheye cameras introduce significant distortion at the edges that affects the accuracy of stereo matching and depth estimation. To overcome these limitations, this paper proposes a method for distortion-removal and depth estimation analysis for stereovision system using orthogonally divergent fisheye cameras (ODFC). The proposed method uses two virtual pinhole cameras (VPC), each VPC captures a small portion of the original view and presents it without any lens distortions, emulating the behavior of a pinhole camera. By carefully selecting the captured regions, it is possible to create a stereo pair using two VPCs. The performance of the proposed method is evaluated in both simulation using virtual environment and experiments using real cameras and their results compared to stereo cameras with parallel optical axes. The results demonstrate the effectiveness of the proposed method in terms of distortion removal and depth estimation accuracy.
</details>
<details>
<summary>摘要</summary>
三角视系统在计算机视觉应用中变得流行，如3D重建、对象跟踪和自动导航。然而，传统的三角视系统使用直线镜头可能无法适用于某些场景，因为它们的视场有限。这导致了基于一或多个折衣镜头的不同orientation的视系统的 Popularity，这些系统可以提供180x180度或更大的视场。然而，折衣镜头会在边缘 introduce significant distortion，影响三角匹配和深度估计的准确性。为了解决这些限制，本文提出了一种基于折衣镜头的三角视系统中的distortion-removal和深度估计分析方法。该方法使用两个虚拟缩影镜头（VPC），每个VPC捕捉一小部分的原始视图，并无镜头扭曲的情况下，表现出pinhole镜头的行为。通过精心选择捕捉的区域，可以创建一个三角对Using two VPCs。实验结果表明，提议的方法可以减少折衣的影响，并提高深度估计的准确性。
</details></li>
</ul>
<hr>
<h2 id="GPT4RoI-Instruction-Tuning-Large-Language-Model-on-Region-of-Interest"><a href="#GPT4RoI-Instruction-Tuning-Large-Language-Model-on-Region-of-Interest" class="headerlink" title="GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest"></a>GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03601">http://arxiv.org/abs/2307.03601</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jshilong/gpt4roi">https://github.com/jshilong/gpt4roi</a></li>
<li>paper_authors: Shilong Zhang, Peize Sun, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Kai Chen, Ping Luo</li>
<li>for: 这 paper 的目的是提高大型语言模型（LLM）在图像和文本对应中的细腻多模态理解能力，通过在区域水平上调整 instruciton。</li>
<li>methods: 该 paper 使用了重新编写 bounding box 为空间指令的方法，将视觉特征与语言嵌入拼接在一起，输入到 LLM 进行训练。</li>
<li>results: 该 paper 提出了一种基于区域水平的视觉语言模型（GPT4RoI），可以提供更多的区域级多模态能力，如细腻区域描述和复杂区域逻辑。用户可以通过语言和空间指令来互动，并可以通过不同的区域指令来控制细腻程度。<details>
<summary>Abstract</summary>
Instruction tuning large language model (LLM) on image-text pairs has achieved unprecedented vision-language multimodal abilities. However, their vision-language alignments are only built on image-level, the lack of region-level alignment limits their advancements to fine-grained multimodal understanding. In this paper, we propose instruction tuning on region-of-interest. The key design is to reformulate the bounding box as the format of spatial instruction. The interleaved sequences of visual features extracted by the spatial instruction and the language embedding are input to LLM, and trained on the transformed region-text data in instruction tuning format. Our region-level vision-language model, termed as GPT4RoI, brings brand new conversational and interactive experience beyond image-level understanding. (1) Controllability: Users can interact with our model by both language and spatial instructions to flexibly adjust the detail level of the question. (2) Capacities: Our model supports not only single-region spatial instruction but also multi-region. This unlocks more region-level multimodal capacities such as detailed region caption and complex region reasoning. (3) Composition: Any off-the-shelf object detector can be a spatial instruction provider so as to mine informative object attributes from our model, like color, shape, material, action, relation to other objects, etc. The code, data, and demo can be found at https://github.com/jshilong/GPT4RoI.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的指令调整在图像和文本对数据上实现了前无之例的视觉语言融合能力。然而，这些视觉语言对应只基于图像水平，缺失地区水平对应限制了其细化多模态理解的进步。在这篇论文中，我们提议在地区水平上调整指令。我们的关键设计是将 bounding box 转换为空间指令的格式。批处视觉特征和语言嵌入被输入到 LLM，并在转换后的地区文本数据上进行了 instrucion 调整。我们称之为 GPT4RoI 的 Region-level 视觉语言模型，它为用户提供了新的对话和交互体验，跻身于图像水平的理解之外。（1）可控性：用户可以通过语言和空间指令来灵活地调整问题的细节水平。（2）能力：我们的模型支持单个地区空间指令以及多个地区。这解锁了更多的地区多模态能力，如详细地区描述和复杂地区逻辑。（3）组合：任何准备好的物体检测器都可以提供空间指令，从而挖掘出模型中的有用对象特征，如颜色、形状、材质、动作、与其他对象的关系等。代码、数据和示例可以在 GitHub 上找到：https://github.com/jshilong/GPT4RoI。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Segmentation-of-Fetal-Brain-MRI-using-Deep-Learning-Cascaded-Registration"><a href="#Unsupervised-Segmentation-of-Fetal-Brain-MRI-using-Deep-Learning-Cascaded-Registration" class="headerlink" title="Unsupervised Segmentation of Fetal Brain MRI using Deep Learning Cascaded Registration"></a>Unsupervised Segmentation of Fetal Brain MRI using Deep Learning Cascaded Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03579">http://arxiv.org/abs/2307.03579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/valbcn/casreg">https://github.com/valbcn/casreg</a></li>
<li>paper_authors: Valentin Comte, Mireia Alenya, Andrea Urru, Judith Recober, Ayako Nakaki, Francesca Crovetto, Oscar Camara, Eduard Gratacós, Elisenda Eixarch, Fàtima Crispi, Gemma Piella, Mario Ceresa, Miguel A. González Ballester</li>
<li>for: 这研究的目的是为了提高胎儿脑 magnetic resonance imaging（MRI）的自动分割精度，以便分析胎儿脑发育和检测可能的脑发育异常。</li>
<li>methods: 该研究提出了一种新的无监督分割方法，基于多个Atlas分割。该方法使用了一个卷积神经网络来进行3D图像 региSTRATION，并通过计算小、增量的变形来将移动图像精确地对齐到固定图像。这个卷积神经网络可以用来注册多个标注图像，并将其组合成一个精确的分割结果。</li>
<li>results: 该研究的实验结果表明，提出的卷积神经网络注册和多Atlas分割方法可以超越现有的注册方法，并且与使用大量标注数据进行训练的nnU-Net相当。此外，该方法只需使用一小部分的标注数据来进行多Atlas分割任务，而不需要任何数据来训练网络。<details>
<summary>Abstract</summary>
Accurate segmentation of fetal brain magnetic resonance images is crucial for analyzing fetal brain development and detecting potential neurodevelopmental abnormalities. Traditional deep learning-based automatic segmentation, although effective, requires extensive training data with ground-truth labels, typically produced by clinicians through a time-consuming annotation process. To overcome this challenge, we propose a novel unsupervised segmentation method based on multi-atlas segmentation, that accurately segments multiple tissues without relying on labeled data for training. Our method employs a cascaded deep learning network for 3D image registration, which computes small, incremental deformations to the moving image to align it precisely with the fixed image. This cascaded network can then be used to register multiple annotated images with the image to be segmented, and combine the propagated labels to form a refined segmentation. Our experiments demonstrate that the proposed cascaded architecture outperforms the state-of-the-art registration methods that were tested. Furthermore, the derived segmentation method achieves similar performance and inference time to nnU-Net while only using a small subset of annotated data for the multi-atlas segmentation task and none for training the network. Our pipeline for registration and multi-atlas segmentation is publicly available at https://github.com/ValBcn/CasReg.
</details>
<details>
<summary>摘要</summary>
准确 segmentation of fetal brain magnetic resonance images 是关键 для分析胎儿脑部发展和检测可能的神经发育畸形。传统的深度学习自动 segmentation 方法，虽然有效，但需要大量的训练数据并有标注数据，通常由临床医生通过时间consuming 的标注过程生成。为了解决这个挑战，我们提出了一种新的无监督分割方法，基于多个 Atlas segmentation，可以准确地分割多种组织而无需训练数据。我们的方法使用了堆叠的深度学习网络 для 3D 图像匹配，计算小、增量的形变来将移动图像精准地对齐于静止图像。这个堆叠网络可以用来对多个标注图像与要分割的图像进行匹配，并将传播的标签组合成为精度的分割。我们的实验表明，我们提出的堆叠体系超越了测试中的状态态术方法。此外，我们的分割方法可以与 nnU-Net 的性能相似，只需使用小数量的标注数据进行多个Atlas segmentation 任务，并无需训练网络。我们的注册和多个Atlas segmentation 管道可以在 GitHub 上获得，请参考 https://github.com/ValBcn/CasReg。
</details></li>
</ul>
<hr>
<h2 id="SpawnNet-Learning-Generalizable-Visuomotor-Skills-from-Pre-trained-Networks"><a href="#SpawnNet-Learning-Generalizable-Visuomotor-Skills-from-Pre-trained-Networks" class="headerlink" title="SpawnNet: Learning Generalizable Visuomotor Skills from Pre-trained Networks"></a>SpawnNet: Learning Generalizable Visuomotor Skills from Pre-trained Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03567">http://arxiv.org/abs/2307.03567</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/johnrso/spawnnet">https://github.com/johnrso/spawnnet</a></li>
<li>paper_authors: Xingyu Lin, John So, Sashwat Mahalingam, Fangchen Liu, Pieter Abbeel</li>
<li>for: 本研究旨在探讨使用预训练视觉表征的可行性，以便提高学习策略的通用能力。</li>
<li>methods: 本研究使用了一种新的两树架构，即SpawnNet，来将预训练多层表征融合到一个独立的网络中，以学习一个Robust的策略。</li>
<li>results: 对于实验和实际场景，SpawnNet表现出了明显的可 categorical 泛化能力，比之前的方法更好。<details>
<summary>Abstract</summary>
The existing internet-scale image and video datasets cover a wide range of everyday objects and tasks, bringing the potential of learning policies that have broad generalization. Prior works have explored visual pre-training with different self-supervised objectives, but the generalization capabilities of the learned policies remain relatively unknown. In this work, we take the first step towards this challenge, focusing on how pre-trained representations can help the generalization of the learned policies. We first identify the key bottleneck in using a frozen pre-trained visual backbone for policy learning. We then propose SpawnNet, a novel two-stream architecture that learns to fuse pre-trained multi-layer representations into a separate network to learn a robust policy. Through extensive simulated and real experiments, we demonstrate significantly better categorical generalization compared to prior approaches in imitation learning settings.
</details>
<details>
<summary>摘要</summary>
现有的互联网级图像和视频数据集覆盖了广泛的日常物品和任务，这对学习策略的泛化潜力具有很大的潜力。先前的工作已经探索了不同的自我超vised目标，但已经学习的策略的泛化能力仍然不够了解。在这项工作中，我们首次面临这个挑战，我们关注使用预训练的表示来帮助策略的泛化。我们首先确定采用静止预训练视觉背bone的主要瓶颈，然后我们提出了SpawnNet，一种新的两核 architecture，它学习将预训练的多层表示融合到一个分离的网络中，以学习一个稳定的策略。通过了详细的 simulate和实际实验，我们证明了SpawnNet在模仿学习设置下的分类泛化性能明显更好，比先前的方法更好。
</details></li>
</ul>
<hr>
<h2 id="VariGrad-A-Novel-Feature-Vector-Architecture-for-Geometric-Deep-Learning-on-Unregistered-Data"><a href="#VariGrad-A-Novel-Feature-Vector-Architecture-for-Geometric-Deep-Learning-on-Unregistered-Data" class="headerlink" title="VariGrad: A Novel Feature Vector Architecture for Geometric Deep Learning on Unregistered Data"></a>VariGrad: A Novel Feature Vector Architecture for Geometric Deep Learning on Unregistered Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03553">http://arxiv.org/abs/2307.03553</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/emmanuel-hartman/pytorch_varigrad">https://github.com/emmanuel-hartman/pytorch_varigrad</a></li>
<li>paper_authors: Emmanuel Hartman, Emery Pierson</li>
<li>for: 本研究提出了一种新的几何深度学习层，使用变量梯度（VariGrad）计算3D几何数据的特征向量表示。这些特征向量可以用于多种下游学习任务，如分类、匹配和形态重建。</li>
<li>methods: 本研究使用了无关于参数化的变量表示方法，以便在数据独立于采样或参数化的情况下训练和测试模型。</li>
<li>results: 研究表明，提出的VariGrad层具有高效、普适和对采样重新采样的可靠性。<details>
<summary>Abstract</summary>
We present a novel geometric deep learning layer that leverages the varifold gradient (VariGrad) to compute feature vector representations of 3D geometric data. These feature vectors can be used in a variety of downstream learning tasks such as classification, registration, and shape reconstruction. Our model's use of parameterization independent varifold representations of geometric data allows our model to be both trained and tested on data independent of the given sampling or parameterization. We demonstrate the efficiency, generalizability, and robustness to resampling demonstrated by the proposed VariGrad layer.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的几何深度学习层，利用变量Gradient（VariGrad）计算三维几何数据的特征向量表示。这些特征向量可以用于多种下游学习任务，如分类、注册和形状重建。我们的模型使用独立参数的变量表示方法，使得我们的模型可以在不同的抽象和参数下进行训练和测试。我们展示了提议的VariGrad层的效率、通用性和对抽样的稳定性。
</details></li>
</ul>
<hr>
<h2 id="Language-free-Compositional-Action-Generation-via-Decoupling-Refinement"><a href="#Language-free-Compositional-Action-Generation-via-Decoupling-Refinement" class="headerlink" title="Language-free Compositional Action Generation via Decoupling Refinement"></a>Language-free Compositional Action Generation via Decoupling Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03538">http://arxiv.org/abs/2307.03538</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/XLiu443/Language-free-Compositional-Action-Generation-via-Decoupling-Refinement">https://github.com/XLiu443/Language-free-Compositional-Action-Generation-via-Decoupling-Refinement</a></li>
<li>paper_authors: Xiao Liu, Guangyi Chen, Yansong Tang, Guangrun Wang, Ser-Nam Lim</li>
<li>for: 本研究旨在生成3D动作，无需依赖于庞大的神经网络语言注释。</li>
<li>methods: 我们提出了一个新的框架，包括动作对接、条件动作生成和解除精度提升。动作对接使用能量模型提取每个子动作的注意力掩模，然后将两个动作结合使用这些注意力来生成pseudo训练示例。然后，我们使用条件生成模型CVAE来学习一个latent空间，使得动作生成更加多样化。最后，我们提出了解除精度提升，使用自我supervised预训练模型MAE来保证子动作和组合动作之间的semantic一致性。这个进程包括将生成的3D动作映射到2D空间，分解这些图像为两个子segments，使用MAE模型重建完整的图像从子segments，并强制恢复的图像与原始子动作映射的图像一致。</li>
<li>results: 我们创建了两个新的 datasets，名为HumanAct-C和UESTC-C，并提出了相应的评价度量。我们进行了 both qualitative和量化的评估，以证明我们的方法的效果。<details>
<summary>Abstract</summary>
Composing simple elements into complex concepts is crucial yet challenging, especially for 3D action generation. Existing methods largely rely on extensive neural language annotations to discern composable latent semantics, a process that is often costly and labor-intensive. In this study, we introduce a novel framework to generate compositional actions without reliance on language auxiliaries. Our approach consists of three main components: Action Coupling, Conditional Action Generation, and Decoupling Refinement. Action Coupling utilizes an energy model to extract the attention masks of each sub-action, subsequently integrating two actions using these attentions to generate pseudo-training examples. Then, we employ a conditional generative model, CVAE, to learn a latent space, facilitating the diverse generation. Finally, we propose Decoupling Refinement, which leverages a self-supervised pre-trained model MAE to ensure semantic consistency between the sub-actions and compositional actions. This refinement process involves rendering generated 3D actions into 2D space, decoupling these images into two sub-segments, using the MAE model to restore the complete image from sub-segments, and constraining the recovered images to match images rendered from raw sub-actions. Due to the lack of existing datasets containing both sub-actions and compositional actions, we created two new datasets, named HumanAct-C and UESTC-C, and present a corresponding evaluation metric. Both qualitative and quantitative assessments are conducted to show our efficacy.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese:Composing simple elements into complex concepts is crucial yet challenging, especially for 3D action generation. Existing methods largely rely on extensive neural language annotations to discern composable latent semantics, a process that is often costly and labor-intensive. In this study, we introduce a novel framework to generate compositional actions without reliance on language auxiliaries. Our approach consists of three main components: Action Coupling, Conditional Action Generation, and Decoupling Refinement. Action Coupling utilizes an energy model to extract the attention masks of each sub-action, subsequently integrating two actions using these attentions to generate pseudo-training examples. Then, we employ a conditional generative model, CVAE, to learn a latent space, facilitating the diverse generation. Finally, we propose Decoupling Refinement, which leverages a self-supervised pre-trained model MAE to ensure semantic consistency between the sub-actions and compositional actions. This refinement process involves rendering generated 3D actions into 2D space, decoupling these images into two sub-segments, using the MAE model to restore the complete image from sub-segments, and constraining the recovered images to match images rendered from raw sub-actions. Due to the lack of existing datasets containing both sub-actions and compositional actions, we created two new datasets, named HumanAct-C and UESTC-C, and present a corresponding evaluation metric. Both qualitative and quantitative assessments are conducted to show our efficacy.Translation:<<SYS>>组合简单元素成复杂概念是关键，特别是在3D动作生成中。现有方法主要依赖于广泛的神经语言标注来 отлича出可组合的含义，这个过程经常是费时和劳动密集的。在这种研究中，我们提出了一种新的框架，可以生成无语言助记的compositional动作。我们的方法包括三个主要组成部分：Action Coupling、Conditional Action Generation和Decoupling Refinement。Action Coupling使用能量模型提取每个子动作的注意力映射，然后将两个动作使用这些注意力进行拼接，生成 pseudo-training 示例。然后，我们使用Conditional Generative Model（CVAE）来学习一个含义空间，促进多样化生成。最后，我们提出了Decoupling Refinement，使用预训练的MAE模型来保证子动作和compositional动作之间的semantic consistency。这个修正过程包括将生成的3D动作映射到2D空间，将这些图像分解成两个子图像，使用MAE模型重建完整的图像，并使其与原始子图像匹配。由于现有的数据集没有包含子动作和compositional动作，我们创建了两个新的数据集，名为HumanAct-C和UESTC-C，并提出了相应的评价指标。我们进行了质量和量化评价，以展示我们的效果。
</details></li>
</ul>
<hr>
<h2 id="Joint-Perceptual-Learning-for-Enhancement-and-Object-Detection-in-Underwater-Scenarios"><a href="#Joint-Perceptual-Learning-for-Enhancement-and-Object-Detection-in-Underwater-Scenarios" class="headerlink" title="Joint Perceptual Learning for Enhancement and Object Detection in Underwater Scenarios"></a>Joint Perceptual Learning for Enhancement and Object Detection in Underwater Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03536">http://arxiv.org/abs/2307.03536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenping Fu, Wanqi Yuan, Jiewen Xiao, Risheng Liu, Xin Fan</li>
<li>for: jointly learn underwater object detection and image enhancement</li>
<li>methods: 使用着色矩阵和卷积神经网络，并提出了一种双层优化方法</li>
<li>results: 实现了更好的图像增强和物体检测精度<details>
<summary>Abstract</summary>
Underwater degraded images greatly challenge existing algorithms to detect objects of interest. Recently, researchers attempt to adopt attention mechanisms or composite connections for improving the feature representation of detectors. However, this solution does \textit{not} eliminate the impact of degradation on image content such as color and texture, achieving minimal improvements. Another feasible solution for underwater object detection is to develop sophisticated deep architectures in order to enhance image quality or features. Nevertheless, the visually appealing output of these enhancement modules do \textit{not} necessarily generate high accuracy for deep detectors. More recently, some multi-task learning methods jointly learn underwater detection and image enhancement, accessing promising improvements. Typically, these methods invoke huge architecture and expensive computations, rendering inefficient inference. Definitely, underwater object detection and image enhancement are two interrelated tasks. Leveraging information coming from the two tasks can benefit each task. Based on these factual opinions, we propose a bilevel optimization formulation for jointly learning underwater object detection and image enhancement, and then unroll to a dual perception network (DPNet) for the two tasks. DPNet with one shared module and two task subnets learns from the two different tasks, seeking a shared representation. The shared representation provides more structural details for image enhancement and rich content information for object detection. Finally, we derive a cooperative training strategy to optimize parameters for DPNet. Extensive experiments on real-world and synthetic underwater datasets demonstrate that our method outputs visually favoring images and higher detection accuracy.
</details>
<details>
<summary>摘要</summary>
水下降低图像对现有算法检测对象存在挑战。研究人员尝试采用注意力机制或复合连接来改善检测器的特征表示。然而，这种解决方案不能完全消除水下图像内容的影响，如颜色和xture，只能获得有限的改进。另一个可行的水下对象检测解决方案是开发高级深度架构，以增强图像质量或特征。然而，这些美化模块的输出不一定能够提高深度检测器的准确率。在最近几年，一些多任务学习方法同时学习水下检测和图像改善，并取得了有望的改进。这些方法通常需要庞大的架构和昂贵的计算，导致效率低下。 Based on these facts, we propose a bilevel optimization formulation for jointly learning water下 object detection and image enhancement, and then unroll to a dual perception network (DPNet) for the two tasks. DPNet with one shared module and two task subnets learns from the two different tasks, seeking a shared representation. The shared representation provides more structural details for image enhancement and rich content information for object detection. Finally, we derive a cooperative training strategy to optimize parameters for DPNet. Extensive experiments on real-world and synthetic underwater datasets demonstrate that our method outputs visually pleasing images and higher detection accuracy.
</details></li>
</ul>
<hr>
<h2 id="Matching-in-the-Wild-Learning-Anatomical-Embeddings-for-Multi-Modality-Images"><a href="#Matching-in-the-Wild-Learning-Anatomical-Embeddings-for-Multi-Modality-Images" class="headerlink" title="Matching in the Wild: Learning Anatomical Embeddings for Multi-Modality Images"></a>Matching in the Wild: Learning Anatomical Embeddings for Multi-Modality Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03535">http://arxiv.org/abs/2307.03535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Bai, Fan Bai, Xiaofei Huo, Jia Ge, Tony C. W. Mok, Zi Li, Minfeng Xu, Jingren Zhou, Le Lu, Dakai Jin, Xianghua Ye, Jingjing Lu, Ke Yan</li>
<li>for: 这个研究旨在提高内部模组之间的对 alignment 的精度，以便更好地利用 CT 和 MRI 两种不同模式之间的信息。</li>
<li>methods: 我们提出了一种新的方法，叫做 Cross-SAM，它利用了一个新的迭代过程，将 embedding learning 和 CT-MRI registrations 融合在一起，以提高对 alignment 的精度。</li>
<li>results: 我们在两个 CT-MRI 融合注册dataset上进行了评估，发现 Cross-SAM 能够实现了 CT 和 MRI 之间的稳定融合注册，并且与其他方法相比，表现出了州域之最。<details>
<summary>Abstract</summary>
Radiotherapists require accurate registration of MR/CT images to effectively use information from both modalities. In a typical registration pipeline, rigid or affine transformations are applied to roughly align the fixed and moving images before proceeding with the deformation step. While recent learning-based methods have shown promising results in the rigid/affine step, these methods often require images with similar field-of-view (FOV) for successful alignment. As a result, aligning images with different FOVs remains a challenging task. Self-supervised landmark detection methods like self-supervised Anatomical eMbedding (SAM) have emerged as a useful tool for mapping and cropping images to similar FOVs. However, these methods are currently limited to intra-modality use only. To address this limitation and enable cross-modality matching, we propose a new approach called Cross-SAM. Our approach utilizes a novel iterative process that alternates between embedding learning and CT-MRI registration. We start by applying aggressive contrast augmentation on both CT and MRI images to train a SAM model. We then use this SAM to identify corresponding regions on paired images using robust grid-points matching, followed by a point-set based affine/rigid registration, and a deformable fine-tuning step to produce registered paired images. We use these registered pairs to enhance the matching ability of SAM, which is then processed iteratively. We use the final model for cross-modality matching tasks. We evaluated our approach on two CT-MRI affine registration datasets and found that Cross-SAM achieved robust affine registration on both datasets, significantly outperforming other methods and achieving state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
医 Physicists需要准确地将MR/CT图像 регистрирова到以便使用这两种模式中的信息。在一般的注册管道中，使用精度的旋转或相对变换来粗略地将固定图像和移动图像对齐，然后进行塑形步骤。而最近的学习基于方法已经在精度步骤中表现出了有前途的结果，但这些方法经常需要具有相似的视野范围（FOV）的图像进行成功的对齐。因此，将图像 WITH 不同的 FOV 进行对齐仍然是一个挑战。自动找到自我医学特征的自适应检测方法，如自适应Anatomical eMbedding（SAM），已经作为一种有用的工具来映射和剪辑图像，但这些方法目前只能在同一种模式中使用。为了解决这种限制并启用跨模式匹配，我们提出了一种新的方法，即 Cross-SAM。我们的方法利用了一种新的迭代过程，它 alternate между embedding learning和CT-MRI注册。我们首先在CT和MRI图像上应用了强制对比增强，然后使用这些SAM来标识对应的区域，并使用精度的grid-points匹配和点集基于的旋转/相对变换注册步骤，最后使用可动的精度调整步骤来生成注册的对应图像。我们使用这些注册对来增强SAM的匹配能力，然后重复处理，并使用最终模型进行跨模式匹配任务。我们在两个CT-MRI注册数据集上进行了评估，并发现 Cross-SAM在两个数据集上都达到了稳定的Affine注册，与其他方法相比，表现出了显著的优势，并达到了领域的前景性表现。
</details></li>
</ul>
<hr>
<h2 id="HoughLaneNet-Lane-Detection-with-Deep-Hough-Transform-and-Dynamic-Convolution"><a href="#HoughLaneNet-Lane-Detection-with-Deep-Hough-Transform-and-Dynamic-Convolution" class="headerlink" title="HoughLaneNet: Lane Detection with Deep Hough Transform and Dynamic Convolution"></a>HoughLaneNet: Lane Detection with Deep Hough Transform and Dynamic Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03494">http://arxiv.org/abs/2307.03494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia-Qi Zhang, Hao-Bin Duan, Jun-Long Chen, Ariel Shamir, Miao Wang</li>
<li>for: 提高自动驾驶中车道检测的精度和可靠性，解决车道检测复杂的问题。</li>
<li>methods: 提出了一种基于幂函数变换的层次结构，将整个图像中的所有车道特征整合到幂函数参数空间中，并采用了动态 convolution模块来有效地分解每个车道特征。</li>
<li>results: 实验结果表明，提出的方法可以更好地检测受阻或损坏的车道图像，并且与当前最佳方法相当或超过其性能。<details>
<summary>Abstract</summary>
The task of lane detection has garnered considerable attention in the field of autonomous driving due to its complexity. Lanes can present difficulties for detection, as they can be narrow, fragmented, and often obscured by heavy traffic. However, it has been observed that the lanes have a geometrical structure that resembles a straight line, leading to improved lane detection results when utilizing this characteristic. To address this challenge, we propose a hierarchical Deep Hough Transform (DHT) approach that combines all lane features in an image into the Hough parameter space. Additionally, we refine the point selection method and incorporate a Dynamic Convolution Module to effectively differentiate between lanes in the original image. Our network architecture comprises a backbone network, either a ResNet or Pyramid Vision Transformer, a Feature Pyramid Network as the neck to extract multi-scale features, and a hierarchical DHT-based feature aggregation head to accurately segment each lane. By utilizing the lane features in the Hough parameter space, the network learns dynamic convolution kernel parameters corresponding to each lane, allowing the Dynamic Convolution Module to effectively differentiate between lane features. Subsequently, the lane features are fed into the feature decoder, which predicts the final position of the lane. Our proposed network structure demonstrates improved performance in detecting heavily occluded or worn lane images, as evidenced by our extensive experimental results, which show that our method outperforms or is on par with state-of-the-art techniques.
</details>
<details>
<summary>摘要</summary>
自动驾驶领域内，车道检测已经引起了非常大的关注，因为它的复杂性。车道可能会变窄、分 Fragmented 或者受到压杂的交通影响，但是观察到车道有一定的几何结构，这使得通过利用这个特点可以提高车道检测的结果。为解决这个挑战，我们提议使用层次深度霍夫变换（DHT）方法，将整个图像中的所有车道特征 combine 到霍夫参数空间中。此外，我们还改进了点选择方法，并将动态卷积模块 incorporate 到图像原像中，以有效地区分每条车道。我们的网络架构包括后ION 网络（ResNet 或 Pyramid Vision Transformer）、特征峰网络作为 neck 提取多比例特征，以及层次 DHT 基于特征聚合头来准确地分类每条车道。通过利用车道特征在霍夫参数空间中，网络学习了对应每条车道的动态卷积参数，使得动态卷积模块可以有效地区分每条车道。最后，车道特征被传递到特征解码器，解码器预测了最终车道的位置。我们的提议的网络结构在检测受到压杂或损坏的车道图像时表现出了改进的性能，这得到了我们的广泛实验结果的支持，其中我们的方法与现有技术相当或超越。
</details></li>
</ul>
<hr>
<h2 id="Unpaired-Multi-View-Graph-Clustering-with-Cross-View-Structure-Matching"><a href="#Unpaired-Multi-View-Graph-Clustering-with-Cross-View-Structure-Matching" class="headerlink" title="Unpaired Multi-View Graph Clustering with Cross-View Structure Matching"></a>Unpaired Multi-View Graph Clustering with Cross-View Structure Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03476">http://arxiv.org/abs/2307.03476</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wy1019/upmgc-sm">https://github.com/wy1019/upmgc-sm</a></li>
<li>paper_authors: Yi Wen, Siwei Wang, Qing Liao, Weixuan Liang, Ke Liang, Xinhang Wan, Xinwang Liu</li>
<li>for: 提高多视图数据的群集效果，这个 paper 写的目的是创建一个无 Parameters 的 гра clustering 框架，可以处理不完整的数据对。</li>
<li>methods: 本 paper 使用的方法是一个 Unpaired Multi-view Graph Clustering framework with Cross-View Structure Matching (UPMGC-SM)，这个方法 使用多视图数据的结构资讯来优化 cross-view 对应关系。</li>
<li>results: 实验结果显示，本 paper 的提案可以有效地处理不完整的数据对，并且可以与已有的 graph clustering 方法整合来增强它们的效能。<details>
<summary>Abstract</summary>
Multi-view clustering (MVC), which effectively fuses information from multiple views for better performance, has received increasing attention. Most existing MVC methods assume that multi-view data are fully paired, which means that the mappings of all corresponding samples between views are pre-defined or given in advance. However, the data correspondence is often incomplete in real-world applications due to data corruption or sensor differences, referred as the data-unpaired problem (DUP) in multi-view literature. Although several attempts have been made to address the DUP issue, they suffer from the following drawbacks: 1) Most methods focus on the feature representation while ignoring the structural information of multi-view data, which is essential for clustering tasks; 2) Existing methods for partially unpaired problems rely on pre-given cross-view alignment information, resulting in their inability to handle fully unpaired problems; 3) Their inevitable parameters degrade the efficiency and applicability of the models. To tackle these issues, we propose a novel parameter-free graph clustering framework termed Unpaired Multi-view Graph Clustering framework with Cross-View Structure Matching (UPMGC-SM). Specifically, unlike the existing methods, UPMGC-SM effectively utilizes the structural information from each view to refine cross-view correspondences. Besides, our UPMGC-SM is a unified framework for both the fully and partially unpaired multi-view graph clustering. Moreover, existing graph clustering methods can adopt our UPMGC-SM to enhance their ability for unpaired scenarios. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both paired and unpaired datasets.
</details>
<details>
<summary>摘要</summary>
多视图聚合（MVC），已经得到了更好的性能的注意。大多数现有的MVC方法假设多视图数据是完全对应的，这意味着所有视图之间的样本映射都是先前定义或提供的。然而，在实际应用中，数据对应性 oftentimes incomplete due to data corruption or sensor differences, referred as the data-unpaired problem (DUP) in multi-view literature. Although several attempts have been made to address the DUP issue, they suffer from the following drawbacks:1. 大多数方法只注重特征表示，忽略了多视图数据的结构信息，这是 clustering 任务中非常重要的;2. 现有的部分对应问题方法 rely on pre-given cross-view alignment information, resulting in their inability to handle fully unpaired problems;3. 它们的参数会影响模型的效率和可应用性。为了解决这些问题，我们提出了一个新的参数自由的图 clustering 框架，称为 Unpaired Multi-view Graph Clustering framework with Cross-View Structure Matching (UPMGC-SM). Specifically, unlike the existing methods, UPMGC-SM 能够充分利用每视图中的结构信息来修正交叉视图对应关系。此外，我们的 UPMGC-SM 是一个统一的框架，可以处理完全和部分对应的多视图图 clustering。此外，现有的图 clustering 方法可以采用我们的 UPMGC-SM 来增强它们对无对应场景的能力。广泛的实验表明我们提出的框架对于 paired 和 unpaired 数据均有效和普适。
</details></li>
</ul>
<hr>
<h2 id="Freezing-of-Gait-Prediction-From-Accelerometer-Data-Using-a-Simple-1D-Convolutional-Neural-Network-–-8th-Place-Solution-for-Kaggle’s-Parkinson’s-Freezing-of-Gait-Prediction-Competition"><a href="#Freezing-of-Gait-Prediction-From-Accelerometer-Data-Using-a-Simple-1D-Convolutional-Neural-Network-–-8th-Place-Solution-for-Kaggle’s-Parkinson’s-Freezing-of-Gait-Prediction-Competition" class="headerlink" title="Freezing of Gait Prediction From Accelerometer Data Using a Simple 1D-Convolutional Neural Network – 8th Place Solution for Kaggle’s Parkinson’s Freezing of Gait Prediction Competition"></a>Freezing of Gait Prediction From Accelerometer Data Using a Simple 1D-Convolutional Neural Network – 8th Place Solution for Kaggle’s Parkinson’s Freezing of Gait Prediction Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03475">http://arxiv.org/abs/2307.03475</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/janbrederecke/fog">https://github.com/janbrederecke/fog</a></li>
<li>paper_authors: Jan Brederecke</li>
<li>For: 这个研究的目的是检测parkinson病人的停止行动（Freezing of Gait，FOG）事件，以便提供更好的 intervención和管理策略。* Methods: 该研究使用了patient-worn加速度计数据，并使用了一种简单的1-D卷积神经网络来检测FOG事件。* Results: 研究结果表明，使用这种方法可以在实时中检测FOG事件，并在Kaggle上的私人领导板上达到了0.356的平均准确率，并最终排名了1379个équipe中的第8名。<details>
<summary>Abstract</summary>
Freezing of Gait (FOG) is a common motor symptom in patients with Parkinson's disease (PD). During episodes of FOG, patients suddenly lose their ability to stride as intended. Patient-worn accelerometers can capture information on the patient's movement during these episodes and machine learning algorithms can potentially classify this data. The combination therefore holds the potential to detect FOG in real-time. In this work I present a simple 1-D convolutional neural network that was trained to detect FOG events in accelerometer data. Model performance was assessed by measuring the success of the model to discriminate normal movement from FOG episodes and resulted in a mean average precision of 0.356 on the private leaderboard on Kaggle. Ultimately, the model ranked 8th out of 1379 teams in the Parkinson's Freezing of Gait Prediction competition. The results underscore the potential of Deep Learning-based solutions in advancing the field of FOG detection, contributing to improved interventions and management strategies for PD patients.
</details>
<details>
<summary>摘要</summary>
困难步行（FOG）是许多parkinson病患者的常见运动症状之一。在FOG发作时，患者可能会突然失去步行的能力。患者穿戴的加速度仪可以记录患者的运动信息，机器学习算法可以可能地分类这些数据。因此，这两种技术的结合具有检测FOG的潜在力。在这项工作中，我提出了一种简单的1-D convolutional neural network，用于在加速度仪数据中检测FOG事件。模型性能由normal运动和FOG发作之间的分类成功率来衡量，并达到了0.356的mean average precision在Kaggle私人领先板上。最终，模型在1379个组合中排名第8位。这些结果表明深度学习基本解决方案在FOG检测方面具有潜在的优势，可能导致parkinson病患者的 intervención和管理策略的改善。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Active-Contour-Model-for-Delineating-Glacier-Calving-Fronts"><a href="#A-Deep-Active-Contour-Model-for-Delineating-Glacier-Calving-Fronts" class="headerlink" title="A Deep Active Contour Model for Delineating Glacier Calving Fronts"></a>A Deep Active Contour Model for Delineating Glacier Calving Fronts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03461">http://arxiv.org/abs/2307.03461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Konrad Heidler, Lichao Mou, Erik Loebel, Mirko Scheinert, Sébastien Lefèvre, Xiao Xiang Zhu</li>
<li>for: 这个论文主要针对的是如何将现实世界中的冰川陷阱问题编码为机器学习任务。</li>
<li>methods: 该论文提出了一种新的方法，即将冰川陷阱模型转换为 outline 检测问题，并使用 Convolutional Neural Networks (CNNs) 和 active contour 模型来实现。</li>
<li>results: 该论文通过对格陵兰冰川的多个大规模数据集进行训练和评估，显示了该方法的优越性，并且还展示了这种方法在计算模型预测结果的不确定性方面的优势。<details>
<summary>Abstract</summary>
Choosing how to encode a real-world problem as a machine learning task is an important design decision in machine learning. The task of glacier calving front modeling has often been approached as a semantic segmentation task. Recent studies have shown that combining segmentation with edge detection can improve the accuracy of calving front detectors. Building on this observation, we completely rephrase the task as a contour tracing problem and propose a model for explicit contour detection that does not incorporate any dense predictions as intermediate steps. The proposed approach, called ``Charting Outlines by Recurrent Adaptation'' (COBRA), combines Convolutional Neural Networks (CNNs) for feature extraction and active contour models for the delineation. By training and evaluating on several large-scale datasets of Greenland's outlet glaciers, we show that this approach indeed outperforms the aforementioned methods based on segmentation and edge-detection. Finally, we demonstrate that explicit contour detection has benefits over pixel-wise methods when quantifying the models' prediction uncertainties. The project page containing the code and animated model predictions can be found at \url{https://khdlr.github.io/COBRA/}.
</details>
<details>
<summary>摘要</summary>
选择如何编码现实世界问题为机器学习任务是机器学习设计决策中非常重要的一步。 glacier calving front 问题经常被视为semantic segmentation任务。  latest studies have shown that combining segmentation with edge detection can improve the accuracy of calving front detectors. Building on this observation, we completely rephrase the task as a contour tracing problem and propose a model for explicit contour detection that does not incorporate any dense predictions as intermediate steps. The proposed approach, called "Charting Outlines by Recurrent Adaptation" (COBRA), combines Convolutional Neural Networks (CNNs) for feature extraction and active contour models for the delineation. By training and evaluating on several large-scale datasets of Greenland's outlet glaciers, we show that this approach indeed outperforms the aforementioned methods based on segmentation and edge-detection. Finally, we demonstrate that explicit contour detection has benefits over pixel-wise methods when quantifying the models' prediction uncertainties.  project page containing the code and animated model predictions can be found at \url{https://khdlr.github.io/COBRA/}.Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="Universal-Semi-supervised-Model-Adaptation-via-Collaborative-Consistency-Training"><a href="#Universal-Semi-supervised-Model-Adaptation-via-Collaborative-Consistency-Training" class="headerlink" title="Universal Semi-supervised Model Adaptation via Collaborative Consistency Training"></a>Universal Semi-supervised Model Adaptation via Collaborative Consistency Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03449">http://arxiv.org/abs/2307.03449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zizheng Yan, Yushuang Wu, Yipeng Qin, Xiaoguang Han, Shuguang Cui, Guanbin Li</li>
<li>for: 本研究提出了一个实际和挑战性的领域适应问题，即通用半监督模型适应（USMA），该问题只需要一个预训练的源模型，并且源和目标领域的标签集可以不同。</li>
<li>methods: 我们提出了一种协作一致培训框架，该框架规范了两个模型（源模型和目标数据只预训练的变体模型）的预测一致性，并将其们的优势融合以学习更强大的模型。</li>
<li>results: 我们的方法在多个 benchmark 数据集上实现了显著的效果。<details>
<summary>Abstract</summary>
In this paper, we introduce a realistic and challenging domain adaptation problem called Universal Semi-supervised Model Adaptation (USMA), which i) requires only a pre-trained source model, ii) allows the source and target domain to have different label sets, i.e., they share a common label set and hold their own private label set, and iii) requires only a few labeled samples in each class of the target domain. To address USMA, we propose a collaborative consistency training framework that regularizes the prediction consistency between two models, i.e., a pre-trained source model and its variant pre-trained with target data only, and combines their complementary strengths to learn a more powerful model. The rationale of our framework stems from the observation that the source model performs better on common categories than the target-only model, while on target-private categories, the target-only model performs better. We also propose a two-perspective, i.e., sample-wise and class-wise, consistency regularization to improve the training. Experimental results demonstrate the effectiveness of our method on several benchmark datasets.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一个实际和挑战性的领域适应问题，即通用半监督模型适应（USMA）。该问题的要求如下：1. 仅使用源模型的预训练结果；2. 源频率和目标频率的标签集不同，即它们共享一个标签集，但各自拥有私有的标签集；3. 每个目标频率类只需几个标注样本。为解决USMA问题，我们提出了一个协同一致训练框架。该框架通过规范源模型和目标数据只预训练的变体模型之间的预测一致性，并将其们的优势融合起来培养更强大的模型。我们的框架的基本思想是，源模型在共同类别上表现更好，而目标模型在目标私有类别上表现更好。我们还提出了两种视角（样本级和类别级）的一致训练 regularization来提高训练。实验结果表明我们的方法在多个标准数据集上具有抗预测能力。
</details></li>
</ul>
<hr>
<h2 id="NOFA-NeRF-based-One-shot-Facial-Avatar-Reconstruction"><a href="#NOFA-NeRF-based-One-shot-Facial-Avatar-Reconstruction" class="headerlink" title="NOFA: NeRF-based One-shot Facial Avatar Reconstruction"></a>NOFA: NeRF-based One-shot Facial Avatar Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03441">http://arxiv.org/abs/2307.03441</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wangbo Yu, Yanbo Fan, Yong Zhang, Xuan Wang, Fei Yin, Yunpeng Bai, Yan-Pei Cao, Ying Shan, Yang Wu, Zhongqian Sun, Baoyuan Wu</li>
<li>for: 一shot 3D facial avatar reconstruction, only requires a single source image for high-fidelity reconstruction.</li>
<li>methods: 利用3D GAN的生成先验和高效编码器-解码器网络重建源图像的 canoncial neural volume，并提出补做网络来补充面部细节。使用扭变场来折叠 canoncial volume 到表达驱动。</li>
<li>results: 通过广泛的实验比较，实现了较高的同构结果，比如果数据量更大的state-of-the-art方法。<details>
<summary>Abstract</summary>
3D facial avatar reconstruction has been a significant research topic in computer graphics and computer vision, where photo-realistic rendering and flexible controls over poses and expressions are necessary for many related applications. Recently, its performance has been greatly improved with the development of neural radiance fields (NeRF). However, most existing NeRF-based facial avatars focus on subject-specific reconstruction and reenactment, requiring multi-shot images containing different views of the specific subject for training, and the learned model cannot generalize to new identities, limiting its further applications. In this work, we propose a one-shot 3D facial avatar reconstruction framework that only requires a single source image to reconstruct a high-fidelity 3D facial avatar. For the challenges of lacking generalization ability and missing multi-view information, we leverage the generative prior of 3D GAN and develop an efficient encoder-decoder network to reconstruct the canonical neural volume of the source image, and further propose a compensation network to complement facial details. To enable fine-grained control over facial dynamics, we propose a deformation field to warp the canonical volume into driven expressions. Through extensive experimental comparisons, we achieve superior synthesis results compared to several state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
三维人脸模型重建已经是计算机图形和计算机视觉领域的一个重要研究主题，需要高真实度的渲染和对姿态和表情的灵活控制，以满足许多相关应用。在最近，通过神经辐射场（NeRF）的发展，其性能得到了显著改进。然而，大多数现有的NeRF基于的人脸模型都是面向特定主体的重建和reenactment，需要多张不同视角的图像进行训练，并且学习的模型无法泛化到新的人脸主体，这限制了其进一步的应用。在这种情况下，我们提出了一种只需要单个源图像来重建高质量三维人脸模型的框架。为了解决缺乏泛化能力和缺失多视角信息的挑战，我们利用了3D GAN的生成预设，并开发了高效的编码器-解码器网络来重建源图像的神经体积，并提出了补做网络来补充人脸细节。为了实现细腻的表情控制，我们提出了扭曲场来扭曲神经体积到驱动表情。通过广泛的实验比较，我们实现了与一些当前领先方法相比的超过其表 sintesis结果。
</details></li>
</ul>
<hr>
<h2 id="Merging-Diverging-Hybrid-Transformer-Networks-for-Survival-Prediction-in-Head-and-Neck-Cancer"><a href="#Merging-Diverging-Hybrid-Transformer-Networks-for-Survival-Prediction-in-Head-and-Neck-Cancer" class="headerlink" title="Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer"></a>Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03427">http://arxiv.org/abs/2307.03427</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mungomeng/survival-xsurv">https://github.com/mungomeng/survival-xsurv</a></li>
<li>paper_authors: Mingyuan Meng, Lei Bi, Michael Fulham, Dagan Feng, Jinman Kim</li>
<li>for: 预测乳腺癌患者存活情况，提供早期诊断和治疗规划的信息。</li>
<li>methods: 基于深度学习和医疗图像的深度存存模型，结合多Modalities图像（如PET-CT），并提取特定区域（如主要肿瘤区和迁徙门节区）的预测信息。</li>
<li>results: 在HEAD和NeCK淋巴肿瘤癌数据集上，我们的XSurv方法比前一代存存预测方法高效，能够结合PET和CT图像的补做性信息，并提取特定区域的预测信息。<details>
<summary>Abstract</summary>
Survival prediction is crucial for cancer patients as it provides early prognostic information for treatment planning. Recently, deep survival models based on deep learning and medical images have shown promising performance for survival prediction. However, existing deep survival models are not well developed in utilizing multi-modality images (e.g., PET-CT) and in extracting region-specific information (e.g., the prognostic information in Primary Tumor (PT) and Metastatic Lymph Node (MLN) regions). In view of this, we propose a merging-diverging learning framework for survival prediction from multi-modality images. This framework has a merging encoder to fuse multi-modality information and a diverging decoder to extract region-specific information. In the merging encoder, we propose a Hybrid Parallel Cross-Attention (HPCA) block to effectively fuse multi-modality features via parallel convolutional layers and cross-attention transformers. In the diverging decoder, we propose a Region-specific Attention Gate (RAG) block to screen out the features related to lesion regions. Our framework is demonstrated on survival prediction from PET-CT images in Head and Neck (H&N) cancer, by designing an X-shape merging-diverging hybrid transformer network (named XSurv). Our XSurv combines the complementary information in PET and CT images and extracts the region-specific prognostic information in PT and MLN regions. Extensive experiments on the public dataset of HEad and neCK TumOR segmentation and outcome prediction challenge (HECKTOR 2022) demonstrate that our XSurv outperforms state-of-the-art survival prediction methods.
</details>
<details>
<summary>摘要</summary>
生存预测对 cancer 患者非常重要，因为它提供了早期的诊断信息，用于治疗规划。在最近几年，深度存活模型基于深度学习和医疗图像已经显示出了惊人的表现。然而，现有的深度存活模型并没有充分利用多Modalities 图像（例如 PET-CT），也没有充分提取区域特定的信息（例如 Primary Tumor （PT）和 Metastatic Lymph Node （MLN）区域的诊断信息）。为了解决这个问题，我们提出了一种融合-分化学习框架，用于存活预测从多Modalities 图像。这个框架包括一个融合Encoder，用于融合多Modalities 信息，以及一个分化Decoder，用于提取区域特定的信息。在融合Encoder中，我们提出了一种Hybrid Parallel Cross-Attention（HPCA）块，用于有效地融合多Modalities 特征，并通过并行卷积层和交叉注意力变换器来实现。在分化Decoder中，我们提出了一种Region-specific Attention Gate（RAG）块，用于筛选出病变区域相关的特征。我们的框架在 Head and Neck 癌症的存活预测中使用 X-shape 融合-分化混合变换网络（名为 XSurv），把 PET 和 CT 图像的补充性信息融合在一起，并提取 PT 和 MLN 区域的区域特定诊断信息。我们的 XSurv 在 HEAD and neCK TumOR segmentation and outcome prediction challenge 2022 公共数据集上进行了广泛的实验，并证明了我们的 XSurv 在存活预测方面超过了当前的状态艺。
</details></li>
</ul>
<hr>
<h2 id="Registration-Free-Hybrid-Learning-Empowers-Simple-Multimodal-Imaging-System-for-High-quality-Fusion-Detection"><a href="#Registration-Free-Hybrid-Learning-Empowers-Simple-Multimodal-Imaging-System-for-High-quality-Fusion-Detection" class="headerlink" title="Registration-Free Hybrid Learning Empowers Simple Multimodal Imaging System for High-quality Fusion Detection"></a>Registration-Free Hybrid Learning Empowers Simple Multimodal Imaging System for High-quality Fusion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03425">http://arxiv.org/abs/2307.03425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinghan Guan, Haoran Dai, Zekuan Yu, Shouyu Wang, Yuanjie Gu</li>
<li>for:  smoke and wildfire detection</li>
<li>methods:  CNN-Transformer hybrid learning framework with unified high-quality multimodal feature matching module and fusion module</li>
<li>results:  superior detection performance compared to other state-of-the-art methods under conventional registered conditions, and the first unregistered multimodal smoke and wildfire detection benchmark is openly available.Here’s the full text in Simplified Chinese:</li>
<li>for: 这个论文是为了实现烟火检测而写的。</li>
<li>methods: 该论文提出了一种基于CNN-Transformer混合学习框架的高质量多Modal特征匹配模块（AKM）和拟合模块（WDAF），通过AKM和WDAF的合作来实现高质量红外意识可见混合检测。</li>
<li>results:  experiments on M3FD dataset表明，提出的方法在已有的注册条件下达到了最佳检测性能，并且在未注册的情况下开设了第一个多Modal烟火检测benchmark。<details>
<summary>Abstract</summary>
Multimodal fusion detection always places high demands on the imaging system and image pre-processing, while either a high-quality pre-registration system or image registration processing is costly. Unfortunately, the existing fusion methods are designed for registered source images, and the fusion of inhomogeneous features, which denotes a pair of features at the same spatial location that expresses different semantic information, cannot achieve satisfactory performance via these methods. As a result, we propose IA-VFDnet, a CNN-Transformer hybrid learning framework with a unified high-quality multimodal feature matching module (AKM) and a fusion module (WDAF), in which AKM and DWDAF work in synergy to perform high-quality infrared-aware visible fusion detection, which can be applied to smoke and wildfire detection. Furthermore, experiments on the M3FD dataset validate the superiority of the proposed method, with IA-VFDnet achieving the best detection performance than other state-of-the-art methods under conventional registered conditions. In addition, the first unregistered multimodal smoke and wildfire detection benchmark is openly available in this letter.
</details>
<details>
<summary>摘要</summary>
多模态融合检测总是对图像系统和图像预处理做出高要求，而ither高质量预注册系统或图像注册处理成本较高。可惜，现有的融合方法都是为注册源图像设计的，因此无法实现满意的性能via这些方法。为此，我们提议IA-VFDnet，一种基于CNN-Transformer混合学习框架的高质量多模态特征匹配模块（AKM）和融合模块（WDAF），其中AKM和WDAF在同工 synergy中实现高质量红外意识可见融合检测，可应用于烟和野火检测。此外，在M3FD数据集上进行的实验 validate了我们提议的方法的优越性，IA-VFDnet在 convential注册条件下实现了其他状态对照方法的最佳检测性能。此外，我们还公开提供了首个无注册多模态烟和野火检测benchmark。
</details></li>
</ul>
<hr>
<h2 id="Hyperspectral-and-Multispectral-Image-Fusion-Using-the-Conditional-Denoising-Diffusion-Probabilistic-Model"><a href="#Hyperspectral-and-Multispectral-Image-Fusion-Using-the-Conditional-Denoising-Diffusion-Probabilistic-Model" class="headerlink" title="Hyperspectral and Multispectral Image Fusion Using the Conditional Denoising Diffusion Probabilistic Model"></a>Hyperspectral and Multispectral Image Fusion Using the Conditional Denoising Diffusion Probabilistic Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03423">http://arxiv.org/abs/2307.03423</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuaikaishi/ddpmfus">https://github.com/shuaikaishi/ddpmfus</a></li>
<li>paper_authors: Shuaikai Shi, Lijun Zhang, Jie Chen</li>
<li>for: 这个论文主要是为了提出一种基于深度学习的卷积混合方法，以提高卷积图像的空间和spectral分辨率。</li>
<li>methods: 该方法基于conditioned denoising diffusion probabilistic model（DDPM），包括一个前向扩散过程和一个反向denoising过程。前向扩散过程逐渐添加 Gaussian 噪声到高空间分辨率卷积图像（HrHSI），而反向denoising过程通过学习预测desired HrHSI的高空间分辨率版本，条件于对应的高空间分辨率多spectral图像（HrMSI）和low空间分辨率卷积图像（LrHSI）。</li>
<li>results: 对一个indoor和两个遥感数据集进行了实验，并与其他先进的深度学习基于混合方法进行了比较。结果显示，提出的方法在混合过程中具有superiority。codes of this work将被opensourced于以下地址：<a target="_blank" rel="noopener" href="https://github.com/shuaikaishi/DDPMFus%EF%BC%8C%E4%BB%A5%E4%BE%BF%E8%BF%9B%E8%A1%8C%E5%8F%AF%E9%87%8D%E7%8E%B0%E3%80%82">https://github.com/shuaikaishi/DDPMFus，以便进行可重现。</a><details>
<summary>Abstract</summary>
Hyperspectral images (HSI) have a large amount of spectral information reflecting the characteristics of matter, while their spatial resolution is low due to the limitations of imaging technology. Complementary to this are multispectral images (MSI), e.g., RGB images, with high spatial resolution but insufficient spectral bands. Hyperspectral and multispectral image fusion is a technique for acquiring ideal images that have both high spatial and high spectral resolution cost-effectively. Many existing HSI and MSI fusion algorithms rely on known imaging degradation models, which are often not available in practice. In this paper, we propose a deep fusion method based on the conditional denoising diffusion probabilistic model, called DDPM-Fus. Specifically, the DDPM-Fus contains the forward diffusion process which gradually adds Gaussian noise to the high spatial resolution HSI (HrHSI) and another reverse denoising process which learns to predict the desired HrHSI from its noisy version conditioning on the corresponding high spatial resolution MSI (HrMSI) and low spatial resolution HSI (LrHSI). Once the training is completes, the proposed DDPM-Fus implements the reverse process on the test HrMSI and LrHSI to generate the fused HrHSI. Experiments conducted on one indoor and two remote sensing datasets show the superiority of the proposed model when compared with other advanced deep learningbased fusion methods. The codes of this work will be opensourced at this address: https://github.com/shuaikaishi/DDPMFus for reproducibility.
</details>
<details>
<summary>摘要</summary>
干ogram (HSI) 具有大量的spectral信息，反映物质特性，但其 spatial resolution受到成像技术限制而低。与之相结合的是多spectral图像 (MSI)，如 RGB 图像，具有高 spatial resolution，但lack spectral band。干ogram和多spectral图像合并是一种获得理想图像，具有高 spatial 和高 spectral resolution的方法。许多现有的 HSI 和 MSI 合并算法 rely on known imaging degradation models，往往不在实践中可用。在这篇文章中，我们提出了基于 conditional denoising diffusion probabilistic model (DDPM) 的深度融合方法，称为 DDPM-Fus。具体来说，DDPM-Fus 包括将高 spatial resolution HSI (HrHSI) 逐渐添加 Gaussian noise 的前进 diffusion process，以及 conditioning on 高 spatial resolution MSI (HrMSI) 和 low spatial resolution HSI (LrHSI) 的reverse denoising process，学习预测 Desired HrHSI。一旦训练完成，我们的 DDPM-Fus 实现了 reverse process 在 test HrMSI 和 LrHSI 上，生成融合后的 HrHSI。我们在一个indoor和两个遥感数据集上进行了实验，并证明了我们的方法在其他高级深度学习基于融合方法之上的比较优势。我们将在这里公开源代码：https://github.com/shuaikaishi/DDPMFus，以便重现。
</details></li>
</ul>
<hr>
<h2 id="Learning-Adversarial-Semantic-Embeddings-for-Zero-Shot-Recognition-in-Open-Worlds"><a href="#Learning-Adversarial-Semantic-Embeddings-for-Zero-Shot-Recognition-in-Open-Worlds" class="headerlink" title="Learning Adversarial Semantic Embeddings for Zero-Shot Recognition in Open Worlds"></a>Learning Adversarial Semantic Embeddings for Zero-Shot Recognition in Open Worlds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03416">http://arxiv.org/abs/2307.03416</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lhrst/ase">https://github.com/lhrst/ase</a></li>
<li>paper_authors: Tianqi Li, Guansong Pang, Xiao Bai, Jin Zheng, Lei Zhou, Xin Ning</li>
<li>for: 这个研究是为了解决Zero-Shot Open-Set Recognition（ZS-OSR）任务，即在Zero-Shot Learning（ZSL） Setting下需要精确地分类未见类别的样本，并能够拒绝未知类别的样本。</li>
<li>methods: 我们使用了现有的State-of-the-art ZSL和OSR模型，并引入了一个新的方法，即生成unknown classes的对抗性semantic embeddings，以训练一个unknowns-informed ZS-OSR分类器。</li>
<li>results: 我们的方法substantially outperforms the combined solutions in detecting unknown classes while retaining the classification accuracy on unseen classes，并在 generalized ZS-OSR settings中也 achieve similar superiority.<details>
<summary>Abstract</summary>
Zero-Shot Learning (ZSL) focuses on classifying samples of unseen classes with only their side semantic information presented during training. It cannot handle real-life, open-world scenarios where there are test samples of unknown classes for which neither samples (e.g., images) nor their side semantic information is known during training. Open-Set Recognition (OSR) is dedicated to addressing the unknown class issue, but existing OSR methods are not designed to model the semantic information of the unseen classes. To tackle this combined ZSL and OSR problem, we consider the case of "Zero-Shot Open-Set Recognition" (ZS-OSR), where a model is trained under the ZSL setting but it is required to accurately classify samples from the unseen classes while being able to reject samples from the unknown classes during inference. We perform large experiments on combining existing state-of-the-art ZSL and OSR models for the ZS-OSR task on four widely used datasets adapted from the ZSL task, and reveal that ZS-OSR is a non-trivial task as the simply combined solutions perform badly in distinguishing the unseen-class and unknown-class samples. We further introduce a novel approach specifically designed for ZS-OSR, in which our model learns to generate adversarial semantic embeddings of the unknown classes to train an unknowns-informed ZS-OSR classifier. Extensive empirical results show that our method 1) substantially outperforms the combined solutions in detecting the unknown classes while retaining the classification accuracy on the unseen classes and 2) achieves similar superiority under generalized ZS-OSR settings.
</details>
<details>
<summary>摘要</summary>
Zero-Shot Learning (ZSL) 专注于在训练过程中只使用类型相关信息来分类未经见过的样本。它无法处理生活中的开放世界enario，那里有测试样本的未知类型， neither samples（例如，图像） nor their type-related information is known during training。Open-Set Recognition (OSR) 专门解决未知类型问题，但现有的 OSR 方法没有考虑类型信息的 semantic information。为了解决这个 ZSL 和 OSR 的共同问题，我们提出了 "Zero-Shot Open-Set Recognition" (ZS-OSR) 任务，其中模型在 ZSL Setting 下进行训练，但需要在推理时准确地分类未经见过的样本，并能够拒绝未知样本。我们在四个广泛使用的数据集上进行了大规模的实验，发现 ZS-OSR 是一个非常复杂的任务，简单地将 ZSL 和 OSR 模型结合起来的方法表现不佳。我们还提出了一种专门为 ZS-OSR 设计的新方法，其中我们的模型学习生成未知类型的敌意Semantic embedding，以训练一个不知情 ZS-OSR 分类器。我们的方法在检测未知类型的同时保持分类精度，并在总体 ZS-OSR 设定下实现了类似的superiority。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Hyperspectral-and-Multispectral-Images-Fusion-Based-on-the-Cycle-Consistency"><a href="#Unsupervised-Hyperspectral-and-Multispectral-Images-Fusion-Based-on-the-Cycle-Consistency" class="headerlink" title="Unsupervised Hyperspectral and Multispectral Images Fusion Based on the Cycle Consistency"></a>Unsupervised Hyperspectral and Multispectral Images Fusion Based on the Cycle Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03413">http://arxiv.org/abs/2307.03413</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shuaikaishi/CycFusion">https://github.com/shuaikaishi/CycFusion</a></li>
<li>paper_authors: Shuaikai Shi, Lijun Zhang, Yoann Altmann, Jie Chen</li>
<li>for: 本研究旨在提出一种不需要known spatial degradation parameters的Unsupervised hyperspectral and multispectral image fusion方法，以提高图像的空间分辨率和спектраль特征的精度。</li>
<li>methods: 该方法基于循环一致性，学习了低分辨率多spectral图像（LrHSI）和高分辨率多spectral图像（HrMSI）之间的频谱域转换，并将恰好的高分辨率 hyperspectral图像（HrHSI）视为中间特征图。</li>
<li>results: 实验结果表明，对多个数据集进行比较，该方法在无监督的情况下，与其他所有不监督拟合方法相比，具有更高的精度和稳定性。<details>
<summary>Abstract</summary>
Hyperspectral images (HSI) with abundant spectral information reflected materials property usually perform low spatial resolution due to the hardware limits. Meanwhile, multispectral images (MSI), e.g., RGB images, have a high spatial resolution but deficient spectral signatures. Hyperspectral and multispectral image fusion can be cost-effective and efficient for acquiring both high spatial resolution and high spectral resolution images. Many of the conventional HSI and MSI fusion algorithms rely on known spatial degradation parameters, i.e., point spread function, spectral degradation parameters, spectral response function, or both of them. Another class of deep learning-based models relies on the ground truth of high spatial resolution HSI and needs large amounts of paired training images when working in a supervised manner. Both of these models are limited in practical fusion scenarios. In this paper, we propose an unsupervised HSI and MSI fusion model based on the cycle consistency, called CycFusion. The CycFusion learns the domain transformation between low spatial resolution HSI (LrHSI) and high spatial resolution MSI (HrMSI), and the desired high spatial resolution HSI (HrHSI) are considered to be intermediate feature maps in the transformation networks. The CycFusion can be trained with the objective functions of marginal matching in single transform and cycle consistency in double transforms. Moreover, the estimated PSF and SRF are embedded in the model as the pre-training weights, which further enhances the practicality of our proposed model. Experiments conducted on several datasets show that our proposed model outperforms all compared unsupervised fusion methods. The codes of this paper will be available at this address: https: //github.com/shuaikaishi/CycFusion for reproducibility.
</details>
<details>
<summary>摘要</summary>
干支spectral图像（HSI）具有丰富的spectral信息，通常因hardware限制而具有低空间分辨率。而多spectral图像（MSI），例如RGB图像，具有高空间分辨率，但缺乏spectral特征。干支spectral和多spectral图像 fusión可以是成本效益和高效的方式，以获取高空间分辨率和高spectral分辨率图像。许多传统的HSI和MSI fusión算法依赖于已知的空间退化参数，例如点扩散函数、spectral退化参数、spectral响应函数或其中之一。另一类的深度学习基于模型则需要大量的协同训练图像，并且需要高度的精度和可靠性。在这篇文章中，我们提出了一种不需要supervision的HSI和MSI fusión模型，称为CycFusion。CycFusion学习了干支spectral和多spectral图像之间的域转换，并将愿望的高空间分辨率HSI视为转换网络中的中间特征图。CycFusion可以通过单个transform和双transform的对应函数来进行训练，并且可以在不同的datasets上进行模型验证。实验结果表明，我们提出的模型在与其他不需要supervision的fusión方法进行比较时表现出色。codes of this paper will be available at this address: https: //github.com/shuaikaishi/CycFusion for reproducibility.
</details></li>
</ul>
<hr>
<h2 id="Distilling-Self-Supervised-Vision-Transformers-for-Weakly-Supervised-Few-Shot-Classification-Segmentation"><a href="#Distilling-Self-Supervised-Vision-Transformers-for-Weakly-Supervised-Few-Shot-Classification-Segmentation" class="headerlink" title="Distilling Self-Supervised Vision Transformers for Weakly-Supervised Few-Shot Classification &amp; Segmentation"></a>Distilling Self-Supervised Vision Transformers for Weakly-Supervised Few-Shot Classification &amp; Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03407">http://arxiv.org/abs/2307.03407</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dahyun Kang, Piotr Koniusz, Minsu Cho, Naila Murray</li>
<li>for: 这个论文的目的是解决弱监督少量图像分类和 segmentation 问题，通过利用一个自我监督的视觉转移（ViT）预训练模型。</li>
<li>methods: 该方法使用自我监督 ViT 生成的token表示，通过自我注意力来生成分类和 segmentation 预测，通过两个任务头。</li>
<li>results: 实验结果表明，在不同的监督情况下，该方法可以具有显著的性能提升，特别是在没有像素级标签的情况下。<details>
<summary>Abstract</summary>
We address the task of weakly-supervised few-shot image classification and segmentation, by leveraging a Vision Transformer (ViT) pretrained with self-supervision. Our proposed method takes token representations from the self-supervised ViT and leverages their correlations, via self-attention, to produce classification and segmentation predictions through separate task heads. Our model is able to effectively learn to perform classification and segmentation in the absence of pixel-level labels during training, using only image-level labels. To do this it uses attention maps, created from tokens generated by the self-supervised ViT backbone, as pixel-level pseudo-labels. We also explore a practical setup with ``mixed" supervision, where a small number of training images contains ground-truth pixel-level labels and the remaining images have only image-level labels. For this mixed setup, we propose to improve the pseudo-labels using a pseudo-label enhancer that was trained using the available ground-truth pixel-level labels. Experiments on Pascal-5i and COCO-20i demonstrate significant performance gains in a variety of supervision settings, and in particular when little-to-no pixel-level labels are available.
</details>
<details>
<summary>摘要</summary>
我们Addresses the task of weakly-supervised few-shot image classification和 segmentation，通过利用Vision Transformer（ViT）预训练自我supervision。我们提议的方法利用自我supervision ViT 中的token表示，通过自我注意力，生成分类和 segmentation预测。我们的模型可以有效地在没有像素级标签的情况下，使用只有图像级标签进行训练，学习进行分类和 segmentation。为此，它使用来自自我supervision ViT 中生成的token的注意力地图，作为像素级 pseudo-标签。我们还探讨了一种实用的混合supervision设置，其中一些训练图像包含ground-truth像素级标签，剩下的图像只有图像级标签。为这种混合设置，我们提议使用pseudo-标签增强器，该模型在可用的ground-truth像素级标签的基础上训练。我们的实验在 Pascal-5i 和 COCO-20i 上达到了多种supervision设置下的显著性能提升，特别是在没有或少像素级标签的情况下。
</details></li>
</ul>
<hr>
<h2 id="RGB-D-Mapping-and-Tracking-in-a-Plenoxel-Radiance-Field"><a href="#RGB-D-Mapping-and-Tracking-in-a-Plenoxel-Radiance-Field" class="headerlink" title="RGB-D Mapping and Tracking in a Plenoxel Radiance Field"></a>RGB-D Mapping and Tracking in a Plenoxel Radiance Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03404">http://arxiv.org/abs/2307.03404</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas L. Teigen, Yeonsoo Park, Annette Stahl, Rudolf Mester<br>for:* 这个技术报告主要写于哪些领域？methods:* 这个技术使用了哪些方法？results:* 这个技术实现了哪些成果？Here are the answers in Simplified Chinese:for:* 这个技术报告主要写于 Computer Vision 和 Robotics 领域。methods:* 这个技术使用了 Plenoxel 频谱场模型，以及RGB-D数据无需神经网络的分析差分方法。results:* 这个技术实现了state-of-the-art的映射和跟踪任务结果，同时比 neural network-based 方法更快。<details>
<summary>Abstract</summary>
Building on the success of Neural Radiance Fields (NeRFs), recent years have seen significant advances in the domain of novel view synthesis. These models capture the scene's volumetric radiance field, creating highly convincing dense photorealistic models through the use of simple, differentiable rendering equations. Despite their popularity, these algorithms suffer from severe ambiguities in visual data inherent to the RGB sensor, which means that although images generated with view synthesis can visually appear very believable, the underlying 3D model will often be wrong. This considerably limits the usefulness of these models in practical applications like Robotics and Extended Reality (XR), where an accurate dense 3D reconstruction otherwise would be of significant value. In this technical report, we present the vital differences between view synthesis models and 3D reconstruction models. We also comment on why a depth sensor is essential for modeling accurate geometry in general outward-facing scenes using the current paradigm of novel view synthesis methods. Focusing on the structure-from-motion task, we practically demonstrate this need by extending the Plenoxel radiance field model: Presenting an analytical differential approach for dense mapping and tracking with radiance fields based on RGB-D data without a neural network. Our method achieves state-of-the-art results in both the mapping and tracking tasks while also being faster than competing neural network-based approaches.
</details>
<details>
<summary>摘要</summary>
在最近几年，因为神经辐射场（NeRF）的成功， novel view synthesis 领域有了 significiant advances。这些模型可以 capture 场景的三维辐射场，通过简单的可导渠 Equations 来创建高效的、 photorealistic 模型。 despite their popularity, these algorithms suffer from severe ambiguities in visual data inherent to the RGB sensor, which means that although images generated with view synthesis can visually appear very believable, the underlying 3D model will often be wrong. This considerably limits the usefulness of these models in practical applications like Robotics and Extended Reality (XR), where an accurate dense 3D reconstruction otherwise would be of significant value.在这份技术报告中，我们展示了视图synthesis 模型和 3D 重建模型之间的重要差异。我们还评论了为了在现今的 novel view synthesis 方法中模型 precisions 的 accurate geometry 的深度感知器的重要性。在structure-from-motion 任务中，我们实际地示出了这种需求。我们通过扩展 Plenoxel 辐射场模型，提出了一种基于 RGB-D 数据的分析差分方法 для dense mapping 和 tracking。我们的方法可以在 mapping 和 tracking 任务中达到状态艺术 Results，同时也比竞争的神经网络基于方法更快。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Geo-localization-Fine-grained-Orientation-of-Street-view-Images-by-Cross-view-Matching-with-Satellite-Imagery-with-Supplementary-Materials"><a href="#Beyond-Geo-localization-Fine-grained-Orientation-of-Street-view-Images-by-Cross-view-Matching-with-Satellite-Imagery-with-Supplementary-Materials" class="headerlink" title="Beyond Geo-localization: Fine-grained Orientation of Street-view Images by Cross-view Matching with Satellite Imagery with Supplementary Materials"></a>Beyond Geo-localization: Fine-grained Orientation of Street-view Images by Cross-view Matching with Satellite Imagery with Supplementary Materials</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03398">http://arxiv.org/abs/2307.03398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenmiao Hu, Yichen Zhang, Yuxuan Liang, Yifang Yin, Andrei Georgescu, An Tran, Hannes Kruppa, See-Kiong Ng, Roger Zimmermann<br>for:This paper focuses on improving the accuracy of fine-grained orientation estimation for street-view images.methods:The proposed methods use a combination of feature extraction and deep learning techniques to estimate the orientation of street-view images.results:The proposed methods achieve high accuracy on orientation estimation, with an average improvement of 34.9% and 28.2% compared to previous works. Integrating fine-grained orientation estimation in training also improves the performance on geo-localization.<details>
<summary>Abstract</summary>
Street-view imagery provides us with novel experiences to explore different places remotely. Carefully calibrated street-view images (e.g. Google Street View) can be used for different downstream tasks, e.g. navigation, map features extraction. As personal high-quality cameras have become much more affordable and portable, an enormous amount of crowdsourced street-view images are uploaded to the internet, but commonly with missing or noisy sensor information. To prepare this hidden treasure for "ready-to-use" status, determining missing location information and camera orientation angles are two equally important tasks. Recent methods have achieved high performance on geo-localization of street-view images by cross-view matching with a pool of geo-referenced satellite imagery. However, most of the existing works focus more on geo-localization than estimating the image orientation. In this work, we re-state the importance of finding fine-grained orientation for street-view images, formally define the problem and provide a set of evaluation metrics to assess the quality of the orientation estimation. We propose two methods to improve the granularity of the orientation estimation, achieving 82.4% and 72.3% accuracy for images with estimated angle errors below 2 degrees for CVUSA and CVACT datasets, corresponding to 34.9% and 28.2% absolute improvement compared to previous works. Integrating fine-grained orientation estimation in training also improves the performance on geo-localization, giving top 1 recall 95.5%/85.5% and 86.8%/80.4% for orientation known/unknown tests on the two datasets.
</details>
<details>
<summary>摘要</summary>
街景图像提供了许多不同的地方的远程探索。高级别的街景图像（例如Google街景图）可以用于不同的下游任务，如导航和地图特征提取。随着个人高质量相机的成本下降和 portaбеility提高，互联网上上传了大量的拍摄街景图像，但通常缺失或含有噪音的感知信息。为了准备这些隐藏的财富，确定缺失的地理位置信息和摄像机方向角度是两个等 importante的任务。现有方法已经达到了高性能的地图化街景图像，但大多数现有的工作更注重地图化than estimating图像方向。在这个工作中，我们重申了找到细化的图像方向的重要性，正式定义问题，并提供了评价图像方向估计质量的测试 метрик。我们提出了两种方法来改进细化图像方向估计，实现了82.4%和72.3%的准确率，对于CVUSA和CACT datasets的图像的估计角度错误小于2度，相对于先前的工作提高了34.9%和28.2%的绝对改进。将细化的图像方向估计integrated into training还提高了地图化性能，在两个dataset上取得了 recall 95.5%/85.5%和86.8%/80.4%，对于orientationknown/unknown测试。
</details></li>
</ul>
<hr>
<h2 id="General-Purpose-Multimodal-Transformer-meets-Remote-Sensing-Semantic-Segmentation"><a href="#General-Purpose-Multimodal-Transformer-meets-Remote-Sensing-Semantic-Segmentation" class="headerlink" title="General-Purpose Multimodal Transformer meets Remote Sensing Semantic Segmentation"></a>General-Purpose Multimodal Transformer meets Remote Sensing Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03388">http://arxiv.org/abs/2307.03388</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nhikieu/spatialvolumetricmultimodal">https://github.com/nhikieu/spatialvolumetricmultimodal</a></li>
<li>paper_authors: Nhi Kieu, Kien Nguyen, Sridha Sridharan, Clinton Fookes</li>
<li>for: 这个研究探讨了 PerceiverIO 综合多模式网络在遥测Semantic Segmentation 领域的表现。</li>
<li>methods: 研究使用了一个 UNit-inspired 模组，该模组使用三维核算法来汇入本地信息，同时学习跨模式特征。</li>
<li>results: 研究发现，提案的方法可以与专门架构 like UNetFormer 和 SwinUNet 相比，达到了竞争性的结果，显示了该方法在优化网络架构设计方面的潜在。<details>
<summary>Abstract</summary>
The advent of high-resolution multispectral/hyperspectral sensors, LiDAR DSM (Digital Surface Model) information and many others has provided us with an unprecedented wealth of data for Earth Observation. Multimodal AI seeks to exploit those complementary data sources, particularly for complex tasks like semantic segmentation. While specialized architectures have been developed, they are highly complicated via significant effort in model design, and require considerable re-engineering whenever a new modality emerges. Recent trends in general-purpose multimodal networks have shown great potential to achieve state-of-the-art performance across multiple multimodal tasks with one unified architecture. In this work, we investigate the performance of PerceiverIO, one in the general-purpose multimodal family, in the remote sensing semantic segmentation domain. Our experiments reveal that this ostensibly universal network struggles with object scale variation in remote sensing images and fails to detect the presence of cars from a top-down view. To address these issues, even with extreme class imbalance issues, we propose a spatial and volumetric learning component. Specifically, we design a UNet-inspired module that employs 3D convolution to encode vital local information and learn cross-modal features simultaneously, while reducing network computational burden via the cross-attention mechanism of PerceiverIO. The effectiveness of the proposed component is validated through extensive experiments comparing it with other methods such as 2D convolution, and dual local module (\ie the combination of Conv2D 1x1 and Conv2D 3x3 inspired by UNetFormer). The proposed method achieves competitive results with specialized architectures like UNetFormer and SwinUNet, showing its potential to minimize network architecture engineering with a minimal compromise on the performance.
</details>
<details>
<summary>摘要</summary>
“现代高分辨率多spectral/干spectral传感器、LiDAR DSM（数字地面模型）等数据源的出现，为地球观测带来了前所未有的数据 богат度。多Modal AI 利用这些补充数据源，特别是 для复杂任务 like semantic segmentation。虽然专门的架构有出现，但它们具有较高的复杂度，需要较大的模型设计和重新引擎，每当新的模态出现时。 current trend in general-purpose multimodal networks has shown great potential to achieve state-of-the-art performance across multiple multimodal tasks with one unified architecture. In this work, we investigate the performance of PerceiverIO, one in the general-purpose multimodal family, in the remote sensing semantic segmentation domain. Our experiments reveal that this ostensibly universal network struggles with object scale variation in remote sensing images and fails to detect the presence of cars from a top-down view. To address these issues, we propose a spatial and volumetric learning component. Specifically, we design a UNet-inspired module that employs 3D convolution to encode vital local information and learn cross-modal features simultaneously, while reducing network computational burden via the cross-attention mechanism of PerceiverIO. The effectiveness of the proposed component is validated through extensive experiments comparing it with other methods such as 2D convolution and dual local module (\ie the combination of Conv2D 1x1 and Conv2D 3x3 inspired by UNetFormer). The proposed method achieves competitive results with specialized architectures like UNetFormer and SwinUNet, showing its potential to minimize network architecture engineering with a minimal compromise on the performance.”
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-Contrastive-Learning-for-Unsupervised-Object-Discovery"><a href="#Weakly-supervised-Contrastive-Learning-for-Unsupervised-Object-Discovery" class="headerlink" title="Weakly-supervised Contrastive Learning for Unsupervised Object Discovery"></a>Weakly-supervised Contrastive Learning for Unsupervised Object Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03376">http://arxiv.org/abs/2307.03376</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/npucvr/wscuod">https://github.com/npucvr/wscuod</a></li>
<li>paper_authors: Yunqiu Lv, Jing Zhang, Nick Barnes, Yuchao Dai</li>
<li>for: 本研究旨在提出一种新的无监督物体发现方法，以提高物体检测和分割的精度。</li>
<li>methods: 我们提出了一种基于自我超vised学习模型的方法，通过弱监督对比学习（WCL）增强 semantic信息探索。我们还使用了原始数据的主成分分析（PCA）来本地化物体区域。</li>
<li>results: 我们在一些无监督物体发现数据集上进行了广泛的实验，并证明了我们的提议的有效性。source code和实验结果可以通过我们的项目页面获取：<a target="_blank" rel="noopener" href="https://github.com/npucvr/WSCUOD.git%E3%80%82">https://github.com/npucvr/WSCUOD.git。</a><details>
<summary>Abstract</summary>
Unsupervised object discovery (UOD) refers to the task of discriminating the whole region of objects from the background within a scene without relying on labeled datasets, which benefits the task of bounding-box-level localization and pixel-level segmentation. This task is promising due to its ability to discover objects in a generic manner. We roughly categorise existing techniques into two main directions, namely the generative solutions based on image resynthesis, and the clustering methods based on self-supervised models. We have observed that the former heavily relies on the quality of image reconstruction, while the latter shows limitations in effectively modeling semantic correlations. To directly target at object discovery, we focus on the latter approach and propose a novel solution by incorporating weakly-supervised contrastive learning (WCL) to enhance semantic information exploration. We design a semantic-guided self-supervised learning model to extract high-level semantic features from images, which is achieved by fine-tuning the feature encoder of a self-supervised model, namely DINO, via WCL. Subsequently, we introduce Principal Component Analysis (PCA) to localize object regions. The principal projection direction, corresponding to the maximal eigenvalue, serves as an indicator of the object region(s). Extensive experiments on benchmark unsupervised object discovery datasets demonstrate the effectiveness of our proposed solution. The source code and experimental results are publicly available via our project page at https://github.com/npucvr/WSCUOD.git.
</details>
<details>
<summary>摘要</summary>
无监督物体发现（UOD）指的是在场景中分别背景和物体的整个区域，不使用标注数据，这对绑定框位置和像素级划分具有推动作用。这个任务有前途，因为它可以在通用的方式下发现物体。我们约分exist的技术为两大方向，即基于图像重新synthesis的生成解决方案，以及基于自我超vised模型的聚类方法。我们发现了，前者强调图像重建质量，而后者在模型 semantic关系模型化有限。为直接实现物体发现，我们选择后者，并提出一种新的解决方案，即通过弱监督对比学习（WCL）增强 semantic信息探索。我们设计了一种带有高级 semantic特征的自然语言处理模型，通过练习 DINO 模型的特征编码器，并通过 WCL 进行 fine-tuning。然后，我们引入Principal Component Analysis（PCA）来地址 object 区域。对于无监督物体发现数据集进行了广泛的实验，证明了我们的提议的有效性。项目代码和实验结果可以通过我们的项目页面https://github.com/npucvr/WSCUOD.git获取。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Deep-Learning-in-Sports-Applications-Perception-Comprehension-and-Decision"><a href="#A-Survey-of-Deep-Learning-in-Sports-Applications-Perception-Comprehension-and-Decision" class="headerlink" title="A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision"></a>A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03353">http://arxiv.org/abs/2307.03353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang</li>
<li>for: 这篇论文旨在探讨深度学习在体育性能方面的应用，包括识别、理解和决策等三个方面。</li>
<li>methods: 论文提出了深度学习算法的层次结构，并对现有的数据集进行了综述，同时描述了现有的挑战和未来发展趋势。</li>
<li>results: 论文通过对现有数据集的分析和对深度学习在体育应用的概述，提供了对深度学习在体育性能方面的研究 Referenced.<details>
<summary>Abstract</summary>
Deep learning has the potential to revolutionize sports performance, with applications ranging from perception and comprehension to decision. This paper presents a comprehensive survey of deep learning in sports performance, focusing on three main aspects: algorithms, datasets and virtual environments, and challenges. Firstly, we discuss the hierarchical structure of deep learning algorithms in sports performance which includes perception, comprehension and decision while comparing their strengths and weaknesses. Secondly, we list widely used existing datasets in sports and highlight their characteristics and limitations. Finally, we summarize current challenges and point out future trends of deep learning in sports. Our survey provides valuable reference material for researchers interested in deep learning in sports applications.
</details>
<details>
<summary>摘要</summary>
深度学习有可能对体育表现进行革命性的改变，其应用范围从感知和理解到决策。本文提供了深度学习在体育表现方面的全面评论，主要涵盖三大方面：算法、数据集和虚拟环境，以及挑战。首先，我们介绍了深度学习算法在体育表现中的层次结构，并对它们的优缺点进行比较。其次，我们列出了常用的体育数据集，并将其特点和局限性作出描述。最后，我们summarized current challenges and highlighted future trends of deep learning in sports.本文提供的参考资料有价值，对深度学习在体育应用领域的研究人员非常有帮助。Here's the translation of the text into Traditional Chinese:深度学习有可能对体育表现进行革命性的改变，其应用范围从感知和理解到决策。本文提供了深度学习在体育表现方面的全面评论，主要涵盖三大方面：算法、数据集和虚拟环境，以及挑战。首先，我们介绍了深度学习算法在体育表现中的层次结构，并对它们的优缺点进行比较。其次，我们列出了常用的体育数据集，并将其特点和局限性作出描述。最后，我们summarized current challenges and highlighted future trends of deep learning in sports.本文提供的参考资料有价值，对深度学习在体育应用领域的研究人员非常有帮助。
</details></li>
</ul>
<hr>
<h2 id="Dividing-and-Conquering-a-BlackBox-to-a-Mixture-of-Interpretable-Models-Route-Interpret-Repeat"><a href="#Dividing-and-Conquering-a-BlackBox-to-a-Mixture-of-Interpretable-Models-Route-Interpret-Repeat" class="headerlink" title="Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat"></a>Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05350">http://arxiv.org/abs/2307.05350</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/batmanlab/ICML-2023-Route-interpret-repeat">https://github.com/batmanlab/ICML-2023-Route-interpret-repeat</a></li>
<li>paper_authors: Shantanu Ghosh, Ke Yu, Forough Arabshahi, Kayhan Batmanghelich</li>
<li>for: This paper aims to blur the distinction between post hoc explanation of a Blackbox and constructing interpretable models, by iteratively carving out a mixture of interpretable experts (MoIE) and a residual network.</li>
<li>methods: The paper uses a route, interpret, and repeat approach, starting with a Blackbox and iteratively carving out MoIE and a residual network. Each interpretable model specializes in a subset of samples and explains them using First Order Logic (FOL), while the residual network handles the remaining samples.</li>
<li>results: The extensive experiments show that the approach (1) identifies a diverse set of instance-specific concepts with high concept completeness via MoIE without compromising performance, (2) identifies the relatively “harder” samples to explain via residuals, (3) outperforms interpretable by-design models by significant margins during test-time interventions, and (4) fixes the shortcut learned by the original Blackbox.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目标是将黑盒模型的Post hoc解释与构建可解释模型相分离，通过迭代挖出一个混合型可解释专家（MoIE）和剩余网络。</li>
<li>methods: 论文使用一种路径、解释、重复的方法，从黑盒模型开始，迭代挖出MoIE和剩余网络。每个可解释模型专门处理一部分样本，使用First Order Logic（FOL）进行基本的推理，以解释黑盒模型中的概念。剩余网络处理剩下的样本。</li>
<li>results: 广泛的实验结果表明，该方法（1）通过MoIE无需性能下降，identify一个多样化的实例特定概念集，具有高概念完整性，（2）通过剩余网络处理 harder 的样本，（3）在测试时间 intervención中，与可解释设计模型相比，具有显著的性能优势，（4）修复黑盒模型中学习的短cut。MoIE代码可以在：<a target="_blank" rel="noopener" href="https://github.com/batmanlab/ICML-2023-Route-interpret-repeat">https://github.com/batmanlab/ICML-2023-Route-interpret-repeat</a> 。<details>
<summary>Abstract</summary>
ML model design either starts with an interpretable model or a Blackbox and explains it post hoc. Blackbox models are flexible but difficult to explain, while interpretable models are inherently explainable. Yet, interpretable models require extensive ML knowledge and tend to be less flexible and underperforming than their Blackbox variants. This paper aims to blur the distinction between a post hoc explanation of a Blackbox and constructing interpretable models. Beginning with a Blackbox, we iteratively carve out a mixture of interpretable experts (MoIE) and a residual network. Each interpretable model specializes in a subset of samples and explains them using First Order Logic (FOL), providing basic reasoning on concepts from the Blackbox. We route the remaining samples through a flexible residual. We repeat the method on the residual network until all the interpretable models explain the desired proportion of data. Our extensive experiments show that our route, interpret, and repeat approach (1) identifies a diverse set of instance-specific concepts with high concept completeness via MoIE without compromising in performance, (2) identifies the relatively ``harder'' samples to explain via residuals, (3) outperforms the interpretable by-design models by significant margins during test-time interventions, and (4) fixes the shortcut learned by the original Blackbox. The code for MoIE is publicly available at: \url{https://github.com/batmanlab/ICML-2023-Route-interpret-repeat}
</details>
<details>
<summary>摘要</summary>
机器学习模型设计可以从可解释模型或黑盒开始，然后进行后处解释。黑盒模型灵活，但难以解释，而可解释模型具有内置的解释功能。然而，可解释模型需要广泛的机器学习知识，并且通常比其黑盒变体表现不佳。本文旨在融合后处解释和构建可解释模型。从黑盒开始，我们逐渐刻意挖掘一个混合可解释专家（MoIE）和剩下的剩下网络。每个可解释模型专门处理一 subset of samples，并使用首险逻辑（FOL）进行基本的推理，提供黑盒中概念的基本理解。我们通过剩下网络将剩下的样本传递给灵活的剩下网络。我们在这个过程中重复多次，直到所有的可解释模型解释愿望的数据分量。我们的广泛实验表明，我们的路由、解释和重复方法（1）可以通过MoIE无需牺牲性能来获得多样化的实例特有概念，（2）可以通过剩下网络来确定难以解释的样本，（3）在测试时间 intervención中大幅度超越可解释设计模型，以及（4）修复黑盒学习的快捷。MoIE代码可以在以下链接获取：https://github.com/batmanlab/ICML-2023-Route-interpret-repeat
</details></li>
</ul>
<hr>
<h2 id="Open-Vocabulary-Object-Detection-via-Scene-Graph-Discovery"><a href="#Open-Vocabulary-Object-Detection-via-Scene-Graph-Discovery" class="headerlink" title="Open-Vocabulary Object Detection via Scene Graph Discovery"></a>Open-Vocabulary Object Detection via Scene Graph Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03339">http://arxiv.org/abs/2307.03339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengcan Shi, Munawar Hayat, Jianfei Cai</li>
<li>for: 这篇论文是为了解决开放词汇对象检测问题，即不同于传统检测，只检测固定类别对象，而是检测开放类别集中的对象。</li>
<li>methods: 该论文提出了一种新的场景图基于发现网络（SGDN），利用场景图指示来检测开放词汇对象。具体来说，包括稀疏场景图指导注意力（SSGA）的场景图解码器（SGDecoder），以及场景图基于预测（SGPred）机制。</li>
<li>results: 实验结果表明，该方法可以有效地解决开放词汇对象检测问题，并且可以进行开放Scene Graph检测。此外，该方法还可以提高对象本地化的准确率。<details>
<summary>Abstract</summary>
In recent years, open-vocabulary (OV) object detection has attracted increasing research attention. Unlike traditional detection, which only recognizes fixed-category objects, OV detection aims to detect objects in an open category set. Previous works often leverage vision-language (VL) training data (e.g., referring grounding data) to recognize OV objects. However, they only use pairs of nouns and individual objects in VL data, while these data usually contain much more information, such as scene graphs, which are also crucial for OV detection. In this paper, we propose a novel Scene-Graph-Based Discovery Network (SGDN) that exploits scene graph cues for OV detection. Firstly, a scene-graph-based decoder (SGDecoder) including sparse scene-graph-guided attention (SSGA) is presented. It captures scene graphs and leverages them to discover OV objects. Secondly, we propose scene-graph-based prediction (SGPred), where we build a scene-graph-based offset regression (SGOR) mechanism to enable mutual enhancement between scene graph extraction and object localization. Thirdly, we design a cross-modal learning mechanism in SGPred. It takes scene graphs as bridges to improve the consistency between cross-modal embeddings for OV object classification. Experiments on COCO and LVIS demonstrate the effectiveness of our approach. Moreover, we show the ability of our model for OV scene graph detection, while previous OV scene graph generation methods cannot tackle this task.
</details>
<details>
<summary>摘要</summary>
近年来，开放词汇（OV）对象检测已经吸引了越来越多的研究者的注意力。与传统检测不同，OV检测targets不同的开放类别对象。先前的工作frequently使用视觉语言（VL）训练数据（例如，referring grounding data）来认识OV对象。然而，这些数据通常包含更多的信息，例如场景图，这些信息也是OV检测的关键。在本文中，我们提出了一种新的场景图基于发现网络（SGDN），它利用场景图指示进行OV检测。首先，我们提出了场景图基本解码器（SGDecoder），包括稀疏场景图指导的注意力（SSGA）。它捕捉场景图并利用它们来发现OV对象。其次，我们提出了场景图基本预测（SGPred），我们构建了场景图基本偏移预测（SGOR）机制，以便对场景图EXTRACTION和对象LOCALIZATION进行互相增强。最后，我们设计了一种 crossed-modal学习机制。它通过场景图作为桥接，以提高不同模态嵌入的一致性，以便对开放类别对象进行分类。在COCO和LVIS上进行了实验，并证明了我们的方法的有效性。此外，我们还示出了我们的模型对开放场景图检测的能力，而之前的OV场景图生成方法无法完成这个任务。
</details></li>
</ul>
<hr>
<h2 id="Facial-Landmark-Detection-Evaluation-on-MOBIO-Database"><a href="#Facial-Landmark-Detection-Evaluation-on-MOBIO-Database" class="headerlink" title="Facial Landmark Detection Evaluation on MOBIO Database"></a>Facial Landmark Detection Evaluation on MOBIO Database</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03329">http://arxiv.org/abs/2307.03329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Na Zhang</li>
<li>for: 该论文旨在提高移动设备上部署生物特征技术的研究，特别是面部识别和语音识别等技术在移动设备上的应用。</li>
<li>methods: 该论文使用了多种现有的面部特征检测方法，以评估其性能在移动设备上。</li>
<li>results: 研究发现，面部特征检测在移动设备上的性能较为挑战，MOBIO数据库可以作为一个新的挑战数据库。<details>
<summary>Abstract</summary>
MOBIO is a bi-modal database that was captured almost exclusively on mobile phones. It aims to improve research into deploying biometric techniques to mobile devices. Research has been shown that face and speaker recognition can be performed in a mobile environment. Facial landmark localization aims at finding the coordinates of a set of pre-defined key points for 2D face images. A facial landmark usually has specific semantic meaning, e.g. nose tip or eye centre, which provides rich geometric information for other face analysis tasks such as face recognition, emotion estimation and 3D face reconstruction. Pretty much facial landmark detection methods adopt still face databases, such as 300W, AFW, AFLW, or COFW, for evaluation, but seldomly use mobile data. Our work is first to perform facial landmark detection evaluation on the mobile still data, i.e., face images from MOBIO database. About 20,600 face images have been extracted from this audio-visual database and manually labeled with 22 landmarks as the groundtruth. Several state-of-the-art facial landmark detection methods are adopted to evaluate their performance on these data. The result shows that the data from MOBIO database is pretty challenging. This database can be a new challenging one for facial landmark detection evaluation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CheXmask-a-large-scale-dataset-of-anatomical-segmentation-masks-for-multi-center-chest-x-ray-images"><a href="#CheXmask-a-large-scale-dataset-of-anatomical-segmentation-masks-for-multi-center-chest-x-ray-images" class="headerlink" title="CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images"></a>CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03293">http://arxiv.org/abs/2307.03293</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ngaggion/chexmask-database">https://github.com/ngaggion/chexmask-database</a></li>
<li>paper_authors: Nicolás Gaggion, Candelaria Mosquera, Lucas Mansilla, Martina Aineseder, Diego H. Milone, Enzo Ferrante</li>
<li>for: 这个论文的目的是为了提供一个大型、多中心的胸部X射线分割数据集，以便用于胸部X射线分析方法的开发。</li>
<li>methods: 这个论文使用了HybridGNet模型来确保所有数据集中的分割结果具有一致性和高质量。</li>
<li>results: 这个论文提供了676,803个分割mask，并通过专业医生评估和自动化质量控制来验证这些mask。 Additionally, the paper provides individualized quality indices per mask and an overall quality estimation per dataset.<details>
<summary>Abstract</summary>
The development of successful artificial intelligence models for chest X-ray analysis relies on large, diverse datasets with high-quality annotations. While several databases of chest X-ray images have been released, most include disease diagnosis labels but lack detailed pixel-level anatomical segmentation labels. To address this gap, we introduce an extensive chest X-ray multi-center segmentation dataset with uniform and fine-grain anatomical annotations for images coming from six well-known publicly available databases: CANDID-PTX, ChestX-ray8, Chexpert, MIMIC-CXR-JPG, Padchest, and VinDr-CXR, resulting in 676,803 segmentation masks. Our methodology utilizes the HybridGNet model to ensure consistent and high-quality segmentations across all datasets. Rigorous validation, including expert physician evaluation and automatic quality control, was conducted to validate the resulting masks. Additionally, we provide individualized quality indices per mask and an overall quality estimation per dataset. This dataset serves as a valuable resource for the broader scientific community, streamlining the development and assessment of innovative methodologies in chest X-ray analysis. The CheXmask dataset is publicly available at: \url{https://physionet.org/content/chexmask-cxr-segmentation-data/}.
</details>
<details>
<summary>摘要</summary>
发展成功人工智能模型 для胸部X射影分析需要大量多样化的数据集，其中包括高质量的注解标注。虽然数据库胸部X射影图像已经发布，但大多数只包含疾病诊断标签，缺乏细腻像素级别的解剖学分割标注。为了解决这个问题，我们介绍了一个广泛的胸部X射影多中心分割数据集，其中包含来自六个公共可用的数据库：CANDID-PTX、ChestX-ray8、Chexpert、MIMIC-CXR-JPG、Padchest和VinDr-CXR，共计676,803个分割mask。我们的方法使用HybridGNet模型来确保分割结果具有一致性和高质量。我们进行了严格的验证，包括专业医生评估和自动化质量控制，以验证结果。此外，我们还提供了每个mask的个性化质量指标以及每个数据集的总质量估计。这个数据集作为科学社区的资源，可以促进胸部X射影分析领域的创新和评估。CheXmask数据集公共可用于：\url{https://physionet.org/content/chexmask-cxr-segmentation-data/}.
</details></li>
</ul>
<hr>
<h2 id="To-pretrain-or-not-to-pretrain-A-case-study-of-domain-specific-pretraining-for-semantic-segmentation-in-histopathology"><a href="#To-pretrain-or-not-to-pretrain-A-case-study-of-domain-specific-pretraining-for-semantic-segmentation-in-histopathology" class="headerlink" title="To pretrain or not to pretrain? A case study of domain-specific pretraining for semantic segmentation in histopathology"></a>To pretrain or not to pretrain? A case study of domain-specific pretraining for semantic segmentation in histopathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03275">http://arxiv.org/abs/2307.03275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tushar Kataria, Beatrice Knudsen, Shireen Elhabian</li>
<li>for: 这个研究是为了检查 histopathology 领域特有的预训练模型是否能提供更好的初始化，以提高病理学影像应用程序的性能。</li>
<li>methods: 研究使用了不同类型的预训练模型，包括 histopathology 领域特有的预训练模型和 real-world 影像预训练模型，并 Comparing 它们的表现。</li>
<li>results: 研究结果显示，使用 histopathology 领域特有的预训练模型可以提高病理学影像识别和分类的表现，但是这些表现取决于任务和训练数据集的大小。此外，研究也发现使用这些预训练模型可以提高病理学影像中的细胞和腺体分类表现，但是这些表现仅在特定的任务和训练数据集中出现。<details>
<summary>Abstract</summary>
Annotating medical imaging datasets is costly, so fine-tuning (or transfer learning) is the most effective method for digital pathology vision applications such as disease classification and semantic segmentation. However, due to texture bias in models trained on real-world images, transfer learning for histopathology applications might result in underperforming models, which necessitates the need for using unlabeled histopathology data and self-supervised methods to discover domain-specific characteristics. Here, we tested the premise that histopathology-specific pretrained models provide better initializations for pathology vision tasks, i.e., gland and cell segmentation. In this study, we compare the performance of gland and cell segmentation tasks with histopathology domain-specific and non-domain-specific (real-world images) pretrained weights. Moreover, we investigate the dataset size at which domain-specific pretraining produces significant gains in performance. In addition, we investigated whether domain-specific initialization improves the effectiveness of out-of-distribution testing on distinct datasets but the same task. The results indicate that performance gain using domain-specific pretrained weights depends on both the task and the size of the training dataset. In instances with limited dataset sizes, a significant improvement in gland segmentation performance was also observed, whereas models trained on cell segmentation datasets exhibit no improvement.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本为：批注医学影像数据集是成本高的，因此 Fine-tuning（或传输学习）是数字 PATHOLOGY 视觉应用，如疾病分类和semantic segmentation 中最有效的方法。然而，由于图像世界中的 texture bias，传输学习 для histopathology 应用可能会导致模型表现不佳，这种情况下需要使用无标注 histopathology 数据和自我supervised 方法来发现领域特有的特征。本研究检验了假设，即 histopathology 特定的预训练模型为 PATHOLOGY 视觉任务提供更好的初始化，即腺体和细胞 segmentation。本研究 comparing 腺体和细胞 segmentation 任务使用 histopathology 领域特定和非领域特定（实际世界图像）预训练 веса的表现。此外，我们还研究了领域特定预训练生成的性能提升的数据集大小。在这些研究中，我们发现了领域特定预训练在某些任务上的性能提升取决于任务和领域特定预训练数据集的大小。在有限的数据集大小下，领域特定预训练可以获得显著的性能提升，而模型在 cell segmentation 任务上表现不变。Translation:<<SYS>>输入文本为：批注医学影像数据集是成本高的，因此 Fine-tuning（或传输学习）是数字 PATHOLOGY 视觉应用，如疾病分类和semantic segmentation 中最有效的方法。然而，由于图像世界中的 texture bias，传输学习 для histopathology 应用可能会导致模型表现不佳，这种情况下需要使用无标注 histopathology 数据和自我supervised 方法来发现领域特有的特征。本研究检验了假设，即 histopathology 特定的预训练模型为 PATHOLOGY 视觉任务提供更好的初始化，即腺体和细胞 segmentation。本研究 comparing 腺体和细胞 segmentation 任务使用 histopathology 领域特定和非领域特定（实际世界图像）预训练 веса的表现。此外，我们还研究了领域特定预训练生成的性能提升的数据集大小。在这些研究中，我们发现了领域特定预训练在某些任务上的性能提升取决于任务和领域特定预训练数据集的大小。在有限的数据集大小下，领域特定预训练可以获得显著的性能提升，而模型在 cell segmentation 任务上表现不变。
</details></li>
</ul>
<hr>
<h2 id="ADASSM-Adversarial-Data-Augmentation-in-Statistical-Shape-Models-From-Images"><a href="#ADASSM-Adversarial-Data-Augmentation-in-Statistical-Shape-Models-From-Images" class="headerlink" title="ADASSM: Adversarial Data Augmentation in Statistical Shape Models From Images"></a>ADASSM: Adversarial Data Augmentation in Statistical Shape Models From Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03273">http://arxiv.org/abs/2307.03273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mokshagna Sai Teja Karanam, Tushar Kataria, Krithika Iyer, Shireen Elhabian</li>
<li>for: 这篇论文旨在提出一种新的数据增强策略，以适应图像到统计形态模型（SSM）框架中的数据缺乏问题。</li>
<li>methods: 该策略基于数据依存的噪声生成或文本增强技术，通过在图像到SSM网络中作为对手训练，生成多样化和挑战性的噪声样本。</li>
<li>results: 该策略可以提高图像到SSM网络的准确率，使模型更加注重下面形态，而不是固定在像素值上。<details>
<summary>Abstract</summary>
Statistical shape models (SSM) have been well-established as an excellent tool for identifying variations in the morphology of anatomy across the underlying population. Shape models use consistent shape representation across all the samples in a given cohort, which helps to compare shapes and identify the variations that can detect pathologies and help in formulating treatment plans. In medical imaging, computing these shape representations from CT/MRI scans requires time-intensive preprocessing operations, including but not limited to anatomy segmentation annotations, registration, and texture denoising. Deep learning models have demonstrated exceptional capabilities in learning shape representations directly from volumetric images, giving rise to highly effective and efficient Image-to-SSM networks. Nevertheless, these models are data-hungry and due to the limited availability of medical data, deep learning models tend to overfit. Offline data augmentation techniques, that use kernel density estimation based (KDE) methods for generating shape-augmented samples, have successfully aided Image-to-SSM networks in achieving comparable accuracy to traditional SSM methods. However, these augmentation methods focus on shape augmentation, whereas deep learning models exhibit image-based texture bias resulting in sub-optimal models. This paper introduces a novel strategy for on-the-fly data augmentation for the Image-to-SSM framework by leveraging data-dependent noise generation or texture augmentation. The proposed framework is trained as an adversary to the Image-to-SSM network, augmenting diverse and challenging noisy samples. Our approach achieves improved accuracy by encouraging the model to focus on the underlying geometry rather than relying solely on pixel values.
</details>
<details>
<summary>摘要</summary>
各种统计形态模型（SSM）在识别人体解剖学变化方面已经得到了广泛的应用，它们使用一致的形态表示方式来比较形态，从而检测疾病和制定治疗方案。在医疗影像中，从CT/MRI扫描获取形态表示需要耗时的预处理步骤，包括但不限于解剖部分标注、注册和图像减震。深度学习模型直接从三维图像中学习形态表示，这些模型已经取得了非常高效和可靠的成果，并且被称为高效的图像-SSM网络。然而，这些模型需要大量的数据，由于医疗数据的有限性，这些模型往往遇到过拟合问题。在线数据增强技术，使用基于KDE方法生成的形态增强样本，已经成功地帮助图像-SSM网络实现与传统SSM方法相当的准确性。然而，这些增强技术主要关注形态增强，而深度学习模型具有图像基于的文本偏好，导致模型表现不佳。本文提出了一种新的在线数据增强策略，通过利用数据依赖的噪声生成或文本增强来帮助图像-SSM网络。该方法在训练过程中作为对图像-SSM网络的反对手，生成多样化和挑战性的噪声样本，以提高模型的准确性。我们的方法通过让模型关注下面的结构，而不是仅仅依赖像素值，从而提高模型的表现。
</details></li>
</ul>
<hr>
<h2 id="Empirical-Analysis-of-a-Segmentation-Foundation-Model-in-Prostate-Imaging"><a href="#Empirical-Analysis-of-a-Segmentation-Foundation-Model-in-Prostate-Imaging" class="headerlink" title="Empirical Analysis of a Segmentation Foundation Model in Prostate Imaging"></a>Empirical Analysis of a Segmentation Foundation Model in Prostate Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03266">http://arxiv.org/abs/2307.03266</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heejong Kim, Victor Ion Butoi, Adrian V. Dalca, Daniel J. A. Margolis, Mert R. Sabuncu<br>for:This paper is written for the purpose of evaluating the effectiveness of a foundation model for medical image segmentation, specifically in the context of prostate imaging.methods:The paper uses a recently developed foundation model called UniverSeg, which is trained on a large dataset of images and can be customized for various downstream tasks with little to no labeled data.results:The paper compares the performance of UniverSeg against conventional task-specific segmentation models and highlights several important factors that will likely be important in the development and adoption of foundation models for medical image segmentation. The results show that UniverSeg achieves competitive performance against task-specific models while requiring significantly less labeled data.<details>
<summary>Abstract</summary>
Most state-of-the-art techniques for medical image segmentation rely on deep-learning models. These models, however, are often trained on narrowly-defined tasks in a supervised fashion, which requires expensive labeled datasets. Recent advances in several machine learning domains, such as natural language generation have demonstrated the feasibility and utility of building foundation models that can be customized for various downstream tasks with little to no labeled data. This likely represents a paradigm shift for medical imaging, where we expect that foundation models may shape the future of the field. In this paper, we consider a recently developed foundation model for medical image segmentation, UniverSeg. We conduct an empirical evaluation study in the context of prostate imaging and compare it against the conventional approach of training a task-specific segmentation model. Our results and discussion highlight several important factors that will likely be important in the development and adoption of foundation models for medical image segmentation.
</details>
<details>
<summary>摘要</summary>
现代医疗影像分割技术多数采用深度学习模型。然而，这些模型通常需要严格定义的任务和质量验证数据，这会导致成本增加。在其他机器学习领域，如自然语言生成，最近的进展表明可以建立基础模型，可以通过少量或无标注数据来适应多个下游任务。这可能会对医疗影像领域造成一种 парадигShift。在这篇论文中，我们考虑了一种新发展的基础模型，即UniverSeg。我们对抗比较这种基础模型与专门为医疗影像分割训练的模型。我们的结果和讨论描述了一些重要的因素，这些因素将影响基础模型在医疗影像分割领域的发展和采纳。
</details></li>
</ul>
<hr>
<h2 id="A-Fully-Automated-and-Explainable-Algorithm-for-the-Prediction-of-Malignant-Transformation-in-Oral-Epithelial-Dysplasia"><a href="#A-Fully-Automated-and-Explainable-Algorithm-for-the-Prediction-of-Malignant-Transformation-in-Oral-Epithelial-Dysplasia" class="headerlink" title="A Fully Automated and Explainable Algorithm for the Prediction of Malignant Transformation in Oral Epithelial Dysplasia"></a>A Fully Automated and Explainable Algorithm for the Prediction of Malignant Transformation in Oral Epithelial Dysplasia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03757">http://arxiv.org/abs/2307.03757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adam J Shephard, Raja Muhammad Saad Bashir, Hanya Mahmood, Mostafa Jahanifar, Fayyaz Minhas, Shan E Ahmed Raza, Kris D McCombe, Stephanie G Craig, Jacqueline James, Jill Brooks, Paul Nankivell, Hisham Mehanna, Syed Ali Khurram, Nasir M Rajpoot</li>
<li>for: 预防唾液腺癌的诊断和预测</li>
<li>methods: 使用人工智能算法，基于历史Patterns in Haematoxylin and Eosin染色整个扫描图像中的核lei，分配唾液腺癌转化风险分数（OMT分数），以衡量唾液腺癌的转化风险。</li>
<li>results: 在内部十进制验证集（Sheffield）和两个外部验证集（Birmingham和Belfast）上，提出了一个AUROC &#x3D; 0.74的预测模型，可以预测唾液腺癌是否会转化为癌症。此外，存在证明了OMT分数的诊断价值，并且在预测转化过程中发现了 péripheral和epithelium-infiltrating免疫细胞的存在。<details>
<summary>Abstract</summary>
Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis given to lesions of the oral cavity. Its grading suffers from significant inter-/intra- observer variability, and does not reliably predict malignancy progression, potentially leading to suboptimal treatment decisions. To address this, we developed a novel artificial intelligence algorithm that can assign an Oral Malignant Transformation (OMT) risk score, based on histological patterns in the in Haematoxylin and Eosin stained whole slide images, to quantify the risk of OED progression. The algorithm is based on the detection and segmentation of nuclei within (and around) the epithelium using an in-house segmentation model. We then employed a shallow neural network fed with interpretable morphological/spatial features, emulating histological markers. We conducted internal cross-validation on our development cohort (Sheffield; n = 193 cases) followed by independent validation on two external cohorts (Birmingham and Belfast; n = 92 cases). The proposed OMTscore yields an AUROC = 0.74 in predicting whether an OED progresses to malignancy or not. Survival analyses showed the prognostic value of our OMTscore for predicting malignancy transformation, when compared to the manually-assigned WHO and binary grades. Analysis of the correctly predicted cases elucidated the presence of peri-epithelial and epithelium-infiltrating lymphocytes in the most predictive patches of cases that transformed (p < 0.0001). This is the first study to propose a completely automated algorithm for predicting OED transformation based on interpretable nuclear features, whilst being validated on external datasets. The algorithm shows better-than-human-level performance for prediction of OED malignant transformation and offers a promising solution to the challenges of grading OED in routine clinical practice.
</details>
<details>
<summary>摘要</summary>
口腔质变性病（OED）是口腔腺肿的先癌诊断，但其分级受到许多内外观察员的变化带来不确定性，并不能准确预测肿瘤转化，可能导致不佳的治疗决策。为解决这个问题，我们开发了一种新的人工智能算法，可以基于口腔染色涂抹整个扫描图像中的历史学特征，分配口腔肿瘤转化风险分数（OMT分数）。该算法基于识别和分割细胞核的自己 segmentation 模型，然后使用一个浅层神经网络，以便模拟历史学特征。我们在 Sheffield 开发团队（n = 193 例）进行了内部十字验证，然后在 Birmingham 和 Belfast 两个外部团队（n = 92 例）进行了独立验证。我们的提议的 OMT 分数可以在预测口腔肿瘤转化是否发生的问题上达到 AUROC = 0.74 的表现。 survival 分析表明我们的 OMT 分数具有预测肿瘤转化的诊断价值，比 manually-assigned WHO 和二分阶段的分数更高。分析正确预测的 случа件表明，在转化的 случа件中存在辐射性和 epithelium 滥入的 T 细胞，这些特征在最预测性的补丁中具有显著性（p < 0.0001）。这是首次提出一种完全自动化的 OED 转化预测算法，基于可读性的核型特征，并在外部数据集上进行了验证。该算法在预测 OED 肿瘤转化的问题上达到了人类水平以上的表现，并且提供了一个有前途的解决方案，以便在日常临床医学实践中改善 OED 的分级。
</details></li>
</ul>
<hr>
<h2 id="PSDR-Room-Single-Photo-to-Scene-using-Differentiable-Rendering"><a href="#PSDR-Room-Single-Photo-to-Scene-using-Differentiable-Rendering" class="headerlink" title="PSDR-Room: Single Photo to Scene using Differentiable Rendering"></a>PSDR-Room: Single Photo to Scene using Differentiable Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03244">http://arxiv.org/abs/2307.03244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Yan, Fujun Luan, MiloŠ HaŠAn, Thibault Groueix, Valentin Deschaintre, Shuang Zhao</li>
<li>for: 用于快速匹配目标图像中的室内场景，需要艺术和技术素养。</li>
<li>methods: 使用最新的路径空间可微 Rendering 方法，通过Gradient Descent 优化灯光和物体姿态，以及材质等参数，以达到视觉匹配目标图像。</li>
<li>results: 可以使用单张图像场景理解方法来初始化优化，并搜索适当的3D模型和材质。实验表明，方法可以 editing 室内场景中的各种元素。Here’s the translation in English for reference:</li>
<li>for: Designed to quickly match the appearance of a target image of an indoor scene, requiring both artistic and technical skills.</li>
<li>methods: Leveraging a recent path-space differentiable rendering approach to provide unbiased gradients of the rendering with respect to geometry, lighting, and procedural materials, allowing for optimization of all these components using gradient descent to visually match the input photo appearance.</li>
<li>results: Can use recent single-image scene understanding methods to initialize the optimization and search for appropriate 3D models and materials. Experimental results demonstrate the editability of the resulting scene components.<details>
<summary>Abstract</summary>
A 3D digital scene contains many components: lights, materials and geometries, interacting to reach the desired appearance. Staging such a scene is time-consuming and requires both artistic and technical skills. In this work, we propose PSDR-Room, a system allowing to optimize lighting as well as the pose and materials of individual objects to match a target image of a room scene, with minimal user input. To this end, we leverage a recent path-space differentiable rendering approach that provides unbiased gradients of the rendering with respect to geometry, lighting, and procedural materials, allowing us to optimize all of these components using gradient descent to visually match the input photo appearance. We use recent single-image scene understanding methods to initialize the optimization and search for appropriate 3D models and materials. We evaluate our method on real photographs of indoor scenes and demonstrate the editability of the resulting scene components.
</details>
<details>
<summary>摘要</summary>
一幅3D数字场景包含多个组件：灯光、材料和几何体，这些组件相互交互以达到所需的外观。设置这种场景是时间consuming的，需要艺术和技术技巧。在这种工作中，我们提议PSDR-Room，一个系统，允许用户最小化输入来优化灯光和个体物体的 pose 和材料，以匹配目标图像中的房间场景的外观，并且可以通过梯度 descent来优化这些组件。我们利用最近的路径空间微分渲染方法，以获取不偏梯度图像渲染中的geometry、灯光和材料的梯度，这些梯度可以用于优化这些组件。我们使用最近的单图像场景理解方法来初始化优化和搜索适合的3D模型和材料。我们对实际拍摄的室内场景照片进行评估，并证明可以编辑场景中的组件。
</details></li>
</ul>
<hr>
<h2 id="That’s-BAD-Blind-Anomaly-Detection-by-Implicit-Local-Feature-Clustering"><a href="#That’s-BAD-Blind-Anomaly-Detection-by-Implicit-Local-Feature-Clustering" class="headerlink" title="That’s BAD: Blind Anomaly Detection by Implicit Local Feature Clustering"></a>That’s BAD: Blind Anomaly Detection by Implicit Local Feature Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03243">http://arxiv.org/abs/2307.03243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zhang, Masanori Suganuma, Takayuki Okatani</li>
<li>for: 这篇论文探讨了无监督的工业物体&#x2F;文瑞异常探测（AD），并提出了一个更加具有挑战性的无监督AD设定，即在一个给定的图像集中探测异常 sample，这个设定不需要人工标注，与过去的研究不同。</li>
<li>methods: 我们提出了一个名为PatchCluster的 novel方法，将这个问题转换为一个本地异常探测问题，并使用了一个新的分割方法来检测图像和像素层次的异常 sample。</li>
<li>results: 实验结果显示，PatchCluster在没有知情normal数据的情况下可以实现高度的异常探测性能，甚至与需要知情normal数据的SOTA方法相比。<details>
<summary>Abstract</summary>
Recent studies on visual anomaly detection (AD) of industrial objects/textures have achieved quite good performance. They consider an unsupervised setting, specifically the one-class setting, in which we assume the availability of a set of normal (\textit{i.e.}, anomaly-free) images for training. In this paper, we consider a more challenging scenario of unsupervised AD, in which we detect anomalies in a given set of images that might contain both normal and anomalous samples. The setting does not assume the availability of known normal data and thus is completely free from human annotation, which differs from the standard AD considered in recent studies. For clarity, we call the setting blind anomaly detection (BAD). We show that BAD can be converted into a local outlier detection problem and propose a novel method named PatchCluster that can accurately detect image- and pixel-level anomalies. Experimental results show that PatchCluster shows a promising performance without the knowledge of normal data, even comparable to the SOTA methods applied in the one-class setting needing it.
</details>
<details>
<summary>摘要</summary>
最近的图像异常检测研究（AD）已经达到了非常好的性能。它们假设了一个无监督的设置，具体是一个一类设置，在这里我们假设了一组正常（即异常free）图像用于训练。在这篇论文中，我们考虑了更加具有挑战性的无监督AD场景，在这里我们检测图像中的异常 sample，这些图像可能包含正常和异常样本。这个设置不需要人类注释，与标准的AD不同。为了便于描述，我们称之为盲目异常检测（BAD）。我们表明了BAD可以转化为本地异常检测问题，并提出了一种名为PatchCluster的新方法，可以准确地检测图像和像素级异常。实验结果表明，PatchCluster在没有正常数据知识的情况下可以达到高度的性能，甚至与需要正常数据的SOTA方法相当。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Generation-of-Privileged-Intermediate-Information-for-Visible-Infrared-Person-Re-Identification"><a href="#Adaptive-Generation-of-Privileged-Intermediate-Information-for-Visible-Infrared-Person-Re-Identification" class="headerlink" title="Adaptive Generation of Privileged Intermediate Information for Visible-Infrared Person Re-Identification"></a>Adaptive Generation of Privileged Intermediate Information for Visible-Infrared Person Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03240">http://arxiv.org/abs/2307.03240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Alehdaghi, Arthur Josi, Pourya Shamsolmoali, Rafael M. O. Cruz, Eric Granger</li>
<li>for: 本研究的目的是提高Visible-infrared人识别（V-I ReID）的精度，通过在RGB和IR感知器上建立一个共享表征空间，以便在不同感知器上捕捉到同一个人的图像。</li>
<li>methods: 本研究提出了一种名为Adaptive Generation of Privileged Intermediate Information（AGPI^2）的训练方法，用于生成一个虚拟频谱域，以bridging V和I模式之间的数据分布差异。AGPI^2使用非线性生成模块和嵌入模块，通过对RGB图像进行非线性变换，生成一个中间频谱域中的图像，并且使得这些中间图像具有较小的频谱域差异。</li>
<li>results: 实验结果表明，AGPI^2可以提高V-I ReID的匹配精度，而无需额外的计算资源在推理过程中。<details>
<summary>Abstract</summary>
Visible-infrared person re-identification seeks to retrieve images of the same individual captured over a distributed network of RGB and IR sensors. Several V-I ReID approaches directly integrate both V and I modalities to discriminate persons within a shared representation space. However, given the significant gap in data distributions between V and I modalities, cross-modal V-I ReID remains challenging. Some recent approaches improve generalization by leveraging intermediate spaces that can bridge V and I modalities, yet effective methods are required to select or generate data for such informative domains. In this paper, the Adaptive Generation of Privileged Intermediate Information training approach is introduced to adapt and generate a virtual domain that bridges discriminant information between the V and I modalities. The key motivation behind AGPI^2 is to enhance the training of a deep V-I ReID backbone by generating privileged images that provide additional information. These privileged images capture shared discriminative features that are not easily accessible within the original V or I modalities alone. Towards this goal, a non-linear generative module is trained with an adversarial objective, translating V images into intermediate spaces with a smaller domain shift w.r.t. the I domain. Meanwhile, the embedding module within AGPI^2 aims to produce similar features for both V and generated images, encouraging the extraction of features that are common to all modalities. In addition to these contributions, AGPI^2 employs adversarial objectives for adapting the intermediate images, which play a crucial role in creating a non-modality-specific space to address the large domain shifts between V and I domains. Experimental results conducted on challenging V-I ReID datasets indicate that AGPI^2 increases matching accuracy without extra computational resources during inference.
</details>
<details>
<summary>摘要</summary>
visible-infrared人识别方法目的是检索RGB和IR感知器上捕捉的同一个人的图像。一些V-I ReID方法直接将V和I模式集成到共同表示空间中，但由于V和I模式的数据分布差距较大，跨模式V-I ReID仍然是一个挑战。一些最近的方法利用中间空间来bridge V和I模式，但需要有效的数据选择或生成方法。在这篇论文中，我们提出了适应生成特权中间信息训练方法（AGPI^2），用于适应和生成一个可以bridge V和I模式之间的虚拟频谱。我们的关键想法是通过生成特权图像来增强深度V-I ReID背景模型的训练，这些特权图像包含共享特征信息，这些信息在原始V或I模式中很难访问。为了实现这一目标，我们在AGPI^2中训练了一个非线性生成模块，通过对V图像进行非线性映射，将其转换为中间空间中的一个更小的频谱差距。同时， embedding模块在AGPI^2中尝试生成V和生成图像之间的相似特征，以便提取这些特征是所有模式共享的。此外，AGPI^2还使用了对中间图像的对抗目标，这些目标在创建一个不受模式限制的空间中扮演了关键的角色，以Addressing the large domain shift between V and I domains。实验结果表明，AGPI^2可以提高匹配精度，不需要额外的计算资源在推理过程中。
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Artistic-Cinemagraphs-from-Text"><a href="#Synthesizing-Artistic-Cinemagraphs-from-Text" class="headerlink" title="Synthesizing Artistic Cinemagraphs from Text"></a>Synthesizing Artistic Cinemagraphs from Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03190">http://arxiv.org/abs/2307.03190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/text2cinemagraph/text2cinemagraph">https://github.com/text2cinemagraph/text2cinemagraph</a></li>
<li>paper_authors: Aniruddha Mahapatra, Aliaksandr Siarohin, Hsin-Ying Lee, Sergey Tulyakov, Jun-Yan Zhu</li>
<li>for: 这个论文是为了创建基于文本描述的电影场景（电影场景）的自动化方法。</li>
<li>methods: 该方法使用了图像双生技术，从单个文本提示中生成一对图像：一个艺术性的图像和一个自然looking的图像。该艺术性图像描绘文本提示中的风格和外观，而自然looking图像简化了布局和动作分析。然后，通过使用现有的自然图像和视频数据集，准确地分割自然looking图像并预测可能的动作，并将这些动作传递给艺术性图像来创建最终的电影场景。</li>
<li>results: 该方法比现有的方法在创建电影场景时表现出色，特别是在自然风景和艺术性场景以及其他世界的场景中。这被证明了通过自动化指标和用户研究。此外，该方法还可以用于动画现有的画作，以及通过文本控制动作方向。<details>
<summary>Abstract</summary>
We introduce Text2Cinemagraph, a fully automated method for creating cinemagraphs from text descriptions - an especially challenging task when prompts feature imaginary elements and artistic styles, given the complexity of interpreting the semantics and motions of these images. Existing single-image animation methods fall short on artistic inputs, and recent text-based video methods frequently introduce temporal inconsistencies, struggling to keep certain regions static. To address these challenges, we propose an idea of synthesizing image twins from a single text prompt - a pair of an artistic image and its pixel-aligned corresponding natural-looking twin. While the artistic image depicts the style and appearance detailed in our text prompt, the realistic counterpart greatly simplifies layout and motion analysis. Leveraging existing natural image and video datasets, we can accurately segment the realistic image and predict plausible motion given the semantic information. The predicted motion can then be transferred to the artistic image to create the final cinemagraph. Our method outperforms existing approaches in creating cinemagraphs for natural landscapes as well as artistic and other-worldly scenes, as validated by automated metrics and user studies. Finally, we demonstrate two extensions: animating existing paintings and controlling motion directions using text.
</details>
<details>
<summary>摘要</summary>
我们介绍Text2Cinemagraph，一种完全自动的方法，可以将文本描述转化成动画照片 - 特别是当提示中包含想象力和艺术风格时，这是一项非常具有挑战性的任务，因为解决含义和动作的含义需要进行复杂的解释。现有的单张图像动画方法在艺术输入下表现不佳，而最近的文本基于视频方法经常出现时间不一致，尝试维持某些区域静止。为解决这些挑战，我们提出了一个合成文本描述中的图像双胞胎的想法 - 一对一个艺术风格和自然风格相似的图像对。而艺术图像将文本中的风格和形象细节呈现出来，而自然图像则大大简化了布局和动作分析。利用现有的自然图像和视频数据集，我们可以准确地分割自然图像，并预测文本中的Semantic信息所决定的合理动作。然后将预测的动作转移到艺术图像中，以创建最终的动画照片。我们的方法在创建自然风景以及艺术和其他世界的场景中的动画照片方面表现出色，并经过自动度量和用户测试 Validation。最后，我们还展示了两个扩展：将现有的画作动画和通过文本控制动作方向。
</details></li>
</ul>
<hr>
<h2 id="IPO-LDM-Depth-aided-360-degree-Indoor-RGB-Panorama-Outpainting-via-Latent-Diffusion-Model"><a href="#IPO-LDM-Depth-aided-360-degree-Indoor-RGB-Panorama-Outpainting-via-Latent-Diffusion-Model" class="headerlink" title="IPO-LDM: Depth-aided 360-degree Indoor RGB Panorama Outpainting via Latent Diffusion Model"></a>IPO-LDM: Depth-aided 360-degree Indoor RGB Panorama Outpainting via Latent Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03177">http://arxiv.org/abs/2307.03177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianhao Wu, Chuanxia Zheng, Tat-Jen Cham</li>
<li>for: 这篇论文的目的是创建高质量的360度RGB投影图，并使用Latent Diffusion Models（LDM）来实现。</li>
<li>methods: 这篇论文使用了一种新的双模态潜在扩散结构，该结构在训练时使用RGB和深度投影数据，但在推理时可以使用 нормаль的深度值。此外，论文还提出了一种进步的摄像头旋转技术，以提高投影图的绕ounding一致性。</li>
<li>results: 论文的IPO-LDM模型不仅在RGB投影图外绘制方面具有显著的优势，还可以生成多种不同类型的面孔，并且每个面孔具有良好的结构。<details>
<summary>Abstract</summary>
Generating complete 360-degree panoramas from narrow field of view images is ongoing research as omnidirectional RGB data is not readily available. Existing GAN-based approaches face some barriers to achieving higher quality output, and have poor generalization performance over different mask types. In this paper, we present our 360-degree indoor RGB panorama outpainting model using latent diffusion models (LDM), called IPO-LDM. We introduce a new bi-modal latent diffusion structure that utilizes both RGB and depth panoramic data during training, but works surprisingly well to outpaint normal depth-free RGB images during inference. We further propose a novel technique of introducing progressive camera rotations during each diffusion denoising step, which leads to substantial improvement in achieving panorama wraparound consistency. Results show that our IPO-LDM not only significantly outperforms state-of-the-art methods on RGB panorama outpainting, but can also produce multiple and diverse well-structured results for different types of masks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将宽角度图像转换为全景360度图像是当前研究的热点问题，因为无法直接获得全景RGB数据。现有的基于GAN的方法具有较差的输出质量和不同掩码类型的泛化性能。在本文中，我们提出了一种基于缓动扩散模型（LDM）的360度室内RGB全景抹雷模型，称之为IPO-LDM。我们在训练时使用了RGB和深度全景数据的双模态缓动扩散结构，但在推理时可以使用depth-freeRGB图像进行抹雷。我们还提出了在每个扩散推净步中逐渐添加摄像头旋转的技术，这会导致全景包袋的实现。结果表明，我们的IPO-LDM不仅可以明显超越当前状态的RGB全景抹雷方法，还可以生成多种不同类型的掩码下的多个高质量结构。
</details></li>
</ul>
<hr>
<h2 id="VideoGLUE-Video-General-Understanding-Evaluation-of-Foundation-Models"><a href="#VideoGLUE-Video-General-Understanding-Evaluation-of-Foundation-Models" class="headerlink" title="VideoGLUE: Video General Understanding Evaluation of Foundation Models"></a>VideoGLUE: Video General Understanding Evaluation of Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03166">http://arxiv.org/abs/2307.03166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangzhe Yuan, Nitesh Bharadwaj Gundavarapu, Long Zhao, Hao Zhou, Yin Cui, Lu Jiang, Xuan Yang, Menglin Jia, Tobias Weyand, Luke Friedman, Mikhail Sirotenko, Huisheng Wang, Florian Schroff, Hartwig Adam, Ming-Hsuan Yang, Ting Liu, Boqing Gong</li>
<li>for: 本研究用于评估现有基础模型（Foundation Model，FM）在视频理解任务上的能力，并提出一种简单的 VideoGLUE 分数（VGS）来衡量 FM 在适应通用视频理解任务时的效果和效率。</li>
<li>methods: 本研究使用了三项hallmark task（行动识别、时间Localization和空间时间Localization）、八个社区广泛接受的数据集，以及四种适应基础模型的方法进行研究。</li>
<li>results: 主要发现结果包括：一、任务特化模型在六个FM studied 的情况下表现出色，与自然语言和图像理解领域中FM的表现形成鲜明的对比；二、视频本地FM在分析动态视频时表现更好，特别是在时间地址和多个动作理解方面；三、视频本地FM可以在轻量适应下（例如冻结FM干部）完成视频任务，而图像本地FM则在全面练习下表现较好。<details>
<summary>Abstract</summary>
We evaluate existing foundation models video understanding capabilities using a carefully designed experiment protocol consisting of three hallmark tasks (action recognition, temporal localization, and spatiotemporal localization), eight datasets well received by the community, and four adaptation methods tailoring a foundation model (FM) for a downstream task. Moreover, we propose a scalar VideoGLUE score (VGS) to measure an FMs efficacy and efficiency when adapting to general video understanding tasks. Our main findings are as follows. First, task-specialized models significantly outperform the six FMs studied in this work, in sharp contrast to what FMs have achieved in natural language and image understanding. Second,video-native FMs, whose pretraining data contains the video modality, are generally better than image-native FMs in classifying motion-rich videos, localizing actions in time, and understanding a video of more than one action. Third, the video-native FMs can perform well on video tasks under light adaptations to downstream tasks(e.g., freezing the FM backbones), while image-native FMs win in full end-to-end finetuning. The first two observations reveal the need and tremendous opportunities to conduct research on video-focused FMs, and the last confirms that both tasks and adaptation methods matter when it comes to the evaluation of FMs.
</details>
<details>
<summary>摘要</summary>
我们使用了一个仔细设计的实验协议来评估现有基础模型（FM）的视频理解能力，包括三项标志性任务（动作识别、时间地址和空间时间地址）、八个社区广泛接受的数据集，以及四种适应方法为基础模型进行下游任务的调整。此外，我们提出了一个名为视频GLUE分数（VGS）的scalar来衡量基础模型在普通视频理解任务上的效果和效率。我们的主要发现包括以下几点：首先，任务特化的模型在我们所研究的六个FM中显著超越了其他模型，这与自然语言和图像理解领域中FM的表现形成鲜明的对比。其次，视频本地FM，即在预训练数据中包含视频模式的FM，在分析动作丰富视频、时间地址动作和视频中的多个动作方面表现更好。最后，视频本地FM可以通过轻度适应下游任务（例如冻结FM的背bone）来达到良好的视频任务性能，而图像本地FM则在全面练习下达到更好的性能。这三个发现表明了视频关注FM的研究需求和机遇，以及任务和适应方法对FM的评估的重要性。
</details></li>
</ul>
<hr>
<h2 id="Can-Domain-Adaptation-Improve-Accuracy-and-Fairness-of-Skin-Lesion-Classification"><a href="#Can-Domain-Adaptation-Improve-Accuracy-and-Fairness-of-Skin-Lesion-Classification" class="headerlink" title="Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?"></a>Can Domain Adaptation Improve Accuracy and Fairness of Skin Lesion Classification?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03157">http://arxiv.org/abs/2307.03157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Janet Wang, Yunbei Zhang, Zhengming Ding, Jihun Hamm</li>
<li>for: 本研究旨在 investigate 多个皮肤病变数据集中的无监督领域适应（UDA）方法在 binary 和多类皮肤病变分类中的可行性。</li>
<li>methods: 我们使用了单源、合并源和多源的 UDA 训练方案，以解决皮肤病变分类中的数据不均衡问题。</li>
<li>results: 我们的实验结果表明，UDA 可以有效地在 binary 分类任务中，并且可以减轻数据不均衡问题。在多类分类任务中，UDA 的性能较弱，需要特别处理数据不均衡问题以达到上乘基eline的准确率。此外，我们发现 Label Shift 对测试错误强相关，而Feature-level UDA 方法在处理不均衡数据集时存在限制。最后，我们发现 UDA 可以有效地减少对少数群体的偏见，无需显式使用 fairness-focused 技术。<details>
<summary>Abstract</summary>
Deep learning-based diagnostic system has demonstrated potential in classifying skin cancer conditions when labeled training example are abundant. However, skin lesion analysis often suffers from a scarcity of labeled data, hindering the development of an accurate and reliable diagnostic system. In this work, we leverage multiple skin lesion datasets and investigate the feasibility of various unsupervised domain adaptation (UDA) methods in binary and multi-class skin lesion classification. In particular, we assess three UDA training schemes: single-, combined-, and multi-source. Our experiment results show that UDA is effective in binary classification, with further improvement being observed when imbalance is mitigated. In multi-class task, its performance is less prominent, and imbalance problem again needs to be addressed to achieve above-baseline accuracy. Through our quantitative analysis, we find that the test error of multi-class tasks is strongly correlated with label shift, and feature-level UDA methods have limitations when handling imbalanced datasets. Finally, our study reveals that UDA can effectively reduce bias against minority groups and promote fairness, even without the explicit use of fairness-focused techniques.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MultiVENT-Multilingual-Videos-of-Events-with-Aligned-Natural-Text"><a href="#MultiVENT-Multilingual-Videos-of-Events-with-Aligned-Natural-Text" class="headerlink" title="MultiVENT: Multilingual Videos of Events with Aligned Natural Text"></a>MultiVENT: Multilingual Videos of Events with Aligned Natural Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03153">http://arxiv.org/abs/2307.03153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kate Sanders, David Etter, Reno Kriz, Benjamin Van Durme</li>
<li>for: 这个论文的目的是构建一个多语言、事件中心视频集合（MultiVENT），以便使用这些视频教学模型受益于现代新闻报道的多样化表达方式。</li>
<li>methods: 该论文使用了多种方法，包括构建多语言、事件中心视频集合（MultiVENT）、分析在线新闻视频的状况以及如何使用这些视频建立准确、多语言的模型。</li>
<li>results: 该论文提供了一个基线模型 для复杂、多语言视频检索，以便使用MultiVENT进行信息检索。<details>
<summary>Abstract</summary>
Everyday news coverage has shifted from traditional broadcasts towards a wide range of presentation formats such as first-hand, unedited video footage. Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences. We address this limitation by constructing MultiVENT, a dataset of multilingual, event-centric videos grounded in text documents across five target languages. MultiVENT includes both news broadcast videos and non-professional event footage, which we use to analyze the state of online news videos and how they can be leveraged to build robust, factually accurate models. Finally, we provide a model for complex, multilingual video retrieval to serve as a baseline for information retrieval using MultiVENT.
</details>
<details>
<summary>摘要</summary>
每天新闻报道很多样化，从传统广播转向多种形式的直播视频。现有的新闻视频数据集都是为英语观众制作的传统新闻广播，我们解决这个局限性的问题，构建了MultiVENT数据集，包含多种语言的事件中心视频和文档。MultiVENT包括新闻广播视频和非专业事件录像，我们通过分析在线新闻视频的状况，探讨如何使用MultiVENT建立强大、准确的模型。最后，我们提供了一种复杂的多语言视频检索模型，作为MultiVENT中的基线模型。
</details></li>
</ul>
<hr>
<h2 id="Topology-Aware-Loss-for-Aorta-and-Great-Vessel-Segmentation-in-Computed-Tomography-Images"><a href="#Topology-Aware-Loss-for-Aorta-and-Great-Vessel-Segmentation-in-Computed-Tomography-Images" class="headerlink" title="Topology-Aware Loss for Aorta and Great Vessel Segmentation in Computed Tomography Images"></a>Topology-Aware Loss for Aorta and Great Vessel Segmentation in Computed Tomography Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03137">http://arxiv.org/abs/2307.03137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seher Ozcelik, Sinan Unver, Ilke Ali Gurses, Rustu Turkay, Cigdem Gunduz-Demir</li>
<li>for: 这个论文是为了解决基于计算机 Tomatoes（CT）图像中血管和大动脉的分割问题。</li>
<li>methods: 这个论文使用了一种新的topology-aware损失函数，该函数通过 persist  homology 来衡量预测和真实值之间的拓扑不同。</li>
<li>results: 实验表明，使用该损失函数可以获得更好的结果， indicating 该方法的有效性。<details>
<summary>Abstract</summary>
Segmentation networks are not explicitly imposed to learn global invariants of an image, such as the shape of an object and the geometry between multiple objects, when they are trained with a standard loss function. On the other hand, incorporating such invariants into network training may help improve performance for various segmentation tasks when they are the intrinsic characteristics of the objects to be segmented. One example is segmentation of aorta and great vessels in computed tomography (CT) images where vessels are found in a particular geometry in the body due to the human anatomy and they mostly seem as round objects on a 2D CT image. This paper addresses this issue by introducing a new topology-aware loss function that penalizes topology dissimilarities between the ground truth and prediction through persistent homology. Different from the previously suggested segmentation network designs, which apply the threshold filtration on a likelihood function of the prediction map and the Betti numbers of the ground truth, this paper proposes to apply the Vietoris-Rips filtration to obtain persistence diagrams of both ground truth and prediction maps and calculate the dissimilarity with the Wasserstein distance between the corresponding persistence diagrams. The use of this filtration has advantage of modeling shape and geometry at the same time, which may not happen when the threshold filtration is applied. Our experiments on 4327 CT images of 24 subjects reveal that the proposed topology-aware loss function leads to better results than its counterparts, indicating the effectiveness of this use.
</details>
<details>
<summary>摘要</summary>
Segmentation 网络不会显式地学习图像中全局不变量，如物体形状和多个物体之间的几何关系，当它们在标准损失函数下训练时。然而，将这些不变量 incorporated 到网络训练中可能会提高不同的 segmentation 任务的性能，因为它们是物体被分 segmentation 的内在特征。例如，在计算机断层成像（CT）图像中分割血管和大血管，血管在人体 анаatomy 中具有特定的几何结构，在2D CT 图像上通常看起来是圆形的物体。这篇论文解决这个问题，通过引入一种新的 topology-aware 损失函数， penalty  topology 异常 между真实值和预测值通过不变式 homology。与之前的 segmentation 网络设计不同，这篇论文提议使用 Vietoris-Rips 滤波来获取 both ground truth 和预测图像的 persistence 图，并计算它们之间的 Wasserstein 距离。这种 filtration 的优点在于同时模型形状和几何，这可能不会在应用 threshold 滤波时发生。我们在 4327 CT 图像上进行了 24 个人的实验，发现提议的 topology-aware 损失函数比其他方法更有效，这表明该用法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Test-Time-Adaptation-against-Distribution-Shifts-in-Image-Classification"><a href="#Benchmarking-Test-Time-Adaptation-against-Distribution-Shifts-in-Image-Classification" class="headerlink" title="Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification"></a>Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03133">http://arxiv.org/abs/2307.03133</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuyongcan/benchmark-tta">https://github.com/yuyongcan/benchmark-tta</a></li>
<li>paper_authors: Yongcan Yu, Lijun Sheng, Ran He, Jian Liang</li>
<li>for: 本研究旨在提供一个可靠的测试时适应（TTA）方法评估 benchmark，以便研究人员和实践者可以准确地评估和比较不同的 TTA 方法在改进模型的Robustness和泛化性能方面的效果。</li>
<li>methods: 本研究评估了 13 种知名的 TTA 方法和其变种，并在 five 个广泛使用的图像分类 datasets（CIFAR-10-C、CIFAR-100-C、ImageNet-C、DomainNet和Office-Home）上进行了系统性的评估。这些方法包括不同的适应enario（如在线适应 versus 离线适应、实例适应 versus 批量适应 versus 频率适应）。此外，我们还探索了不同的 TTA 方法与不同的网络后处理器之间的兼容性。</li>
<li>results: 我们的研究发现，不同的 TTA 方法在不同的预测场景下的效果有所不同。 Specifically, we found that some methods perform better in certain scenarios, while others may not be as effective. Additionally, we observed that some methods are more compatible with certain network backbones than others. Our findings provide valuable insights into the strengths and limitations of different TTA methods and can help guide future research in this area.<details>
<summary>Abstract</summary>
Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction. Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed. However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness. To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the compatibility of different TTA methods with diverse network backbones. To implement this benchmark, we have developed a unified framework in PyTorch, which allows for consistent evaluation and comparison of the TTA methods across the different datasets and network architectures. By establishing this benchmark, we aim to provide researchers and practitioners with a reliable means of assessing and comparing the effectiveness of TTA methods in improving model robustness and generalization performance. Our code is available at https://github.com/yuyongcan/Benchmark-TTA.
</details>
<details>
<summary>摘要</summary>
测试时适应（TTA）是一种技术，旨在通过使用无标示样本来提高模型的总体性表现。由于神经网络系统面临到分布转移时的稳定性问题，有很多TTA方法被提出。然而，评估这些方法的时候通常采用不同的设置，例如不同的分布转移、后端和设计方案，这导致了评估效果的不一致和公平性的问题。为解决这个问题，我们提出了一个基准，系统地评估13种知名TTA方法和其变体在五种广泛使用的图像分类dataset上：CIFAR-10-C、CIFAR-100-C、ImageNet-C、DomainNet和Office-Home。这些方法涵盖了各种适应enario（例如在线适应vs.离线适应、实例适应vs.批适应vs.领域适应）。此外，我们还探索了不同TTA方法与不同后端网络的Compatibility。为实现这个基准，我们在PyTorch中开发了一个统一的框架，允许在不同的dataset和网络架构上一致性地评估和比较TTA方法的效果。通过建立这个基准，我们希望为研究者和实践者提供一个可靠的方式来评估和比较TTA方法在提高模型的Robustness和总体性表现方面的效果。我们的代码可以在https://github.com/yuyongcan/Benchmark-TTA上获取。
</details></li>
</ul>
<hr>
<h2 id="Principal-subbundles-for-dimension-reduction"><a href="#Principal-subbundles-for-dimension-reduction" class="headerlink" title="Principal subbundles for dimension reduction"></a>Principal subbundles for dimension reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03128">http://arxiv.org/abs/2307.03128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Morten Akhøj, James Benn, Erlend Grong, Stefan Sommer, Xavier Pennec</li>
<li>for: 用于构成和重建表面</li>
<li>methods: 使用本地线性近似来获取低维 bundle</li>
<li>results: 可以成功应用于许多重要问题，如构建 Approximating 子 manifold、计算观察之间的距离等。<details>
<summary>Abstract</summary>
In this paper we demonstrate how sub-Riemannian geometry can be used for manifold learning and surface reconstruction by combining local linear approximations of a point cloud to obtain lower dimensional bundles. Local approximations obtained by local PCAs are collected into a rank $k$ tangent subbundle on $\mathbb{R}^d$, $k<d$, which we call a principal subbundle. This determines a sub-Riemannian metric on $\mathbb{R}^d$. We show that sub-Riemannian geodesics with respect to this metric can successfully be applied to a number of important problems, such as: explicit construction of an approximating submanifold $M$, construction of a representation of the point-cloud in $\mathbb{R}^k$, and computation of distances between observations, taking the learned geometry into account. The reconstruction is guaranteed to equal the true submanifold in the limit case where tangent spaces are estimated exactly. Via simulations, we show that the framework is robust when applied to noisy data. Furthermore, the framework generalizes to observations on an a priori known Riemannian manifold.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们示示了如何使用非柯尼希 геометрия来进行拟合 manifold 和表面重建，通过将本地线性近似合集到一个降维Bundle 中。这个降维Bundle 在 $\mathbb{R}^d$ 上定义为 rank $k$ 的 tangent 子bundle，其中 $k<d$。我们称之为主Bundle。这个主Bundle 定义了一个非柯尼希 metric 在 $\mathbb{R}^d$ 上。我们证明了这个 metric 下的非柯尼希 geodesics 可以成功地应用于一些重要问题，例如：构造一个approximating submanifold $M$，构造一个点云在 $\mathbb{R}^k$ 上的表示，并计算observations 之间的距离，考虑到学习的geometry。在极限情况下，如果 tangent space 是准确地估计的，则重建是确定的。通过实验，我们表明了这种框架在噪声数据上是稳定的。此外，这种框架还可以推广到已知的里曼尼 manifold 上的observations。
</details></li>
</ul>
<hr>
<h2 id="LISSNAS-Locality-based-Iterative-Search-Space-Shrinkage-for-Neural-Architecture-Search"><a href="#LISSNAS-Locality-based-Iterative-Search-Space-Shrinkage-for-Neural-Architecture-Search" class="headerlink" title="LISSNAS: Locality-based Iterative Search Space Shrinkage for Neural Architecture Search"></a>LISSNAS: Locality-based Iterative Search Space Shrinkage for Neural Architecture Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03110">http://arxiv.org/abs/2307.03110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bhavna Gopal, Arjun Sridhar, Tunhou Zhang, Yiran Chen</li>
<li>for: 这篇论文旨在提出一个自动化的搜索空间缩小算法，以提高搜索性能和搜索空间的多样性。</li>
<li>methods: 本论文使用了本地性和结构相似性的关系来优化搜索空间，实现了高效的搜索和多样性保持。</li>
<li>results: 本论文在不同的搜索空间和数据集上进行了实验，结果显示了LISSNAS算法在搜索性能和多样性方面的最佳性能，包括ImageNet上的手动搜索中的最高Top-1精度（77.6%）、Kendall-Tau指数、搜索空间大小等。<details>
<summary>Abstract</summary>
Search spaces hallmark the advancement of Neural Architecture Search (NAS). Large and complex search spaces with versatile building operators and structures provide more opportunities to brew promising architectures, yet pose severe challenges on efficient exploration and exploitation. Subsequently, several search space shrinkage methods optimize by selecting a single sub-region that contains some well-performing networks. Small performance and efficiency gains are observed with these methods but such techniques leave room for significantly improved search performance and are ineffective at retaining architectural diversity. We propose LISSNAS, an automated algorithm that shrinks a large space into a diverse, small search space with SOTA search performance. Our approach leverages locality, the relationship between structural and performance similarity, to efficiently extract many pockets of well-performing networks. We showcase our method on an array of search spaces spanning various sizes and datasets. We accentuate the effectiveness of our shrunk spaces when used in one-shot search by achieving the best Top-1 accuracy in two different search spaces. Our method achieves a SOTA Top-1 accuracy of 77.6\% in ImageNet under mobile constraints, best-in-class Kendal-Tau, architectural diversity, and search space size.
</details>
<details>
<summary>摘要</summary>
搜索空间的特征标志了神经建筑搜索（NAS）的进步。大型和复杂的搜索空间，具有多样化的建筑元素和结构，提供了更多的可能性来生成出色的建筑，但也对有效地探索和利用 pose 严重挑战。为此，许多搜索空间缩小方法通过选择单个子区域来找到一些表现良好的网络。这些方法可以提供小幅提高性和效率，但是这些技术留下大量可以进一步提高搜索性能的空间，并且无法保持建筑多样性。我们提出了 LISSNAS，一种自动化算法，可以将大型空间缩小到多样性强、性能优秀的小搜索空间。我们的方法利用了地方性，建筑和性能之间的相似关系，以高效地提取许多表现良好的网络。我们在多个搜索空间中进行了证明，并在 ImageNet 下实现了移动端的 SOTA Top-1 准确率为 77.6%，同时保持了 Kendall-Tau 最佳、建筑多样性和搜索空间大小。
</details></li>
</ul>
<hr>
<h2 id="How-to-Detect-Unauthorized-Data-Usages-in-Text-to-image-Diffusion-Models"><a href="#How-to-Detect-Unauthorized-Data-Usages-in-Text-to-image-Diffusion-Models" class="headerlink" title="How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models"></a>How to Detect Unauthorized Data Usages in Text-to-image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03108">http://arxiv.org/abs/2307.03108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenting Wang, Chen Chen, Yuchen Liu, Lingjuan Lyu, Dimitris Metaxas, Shiqing Ma</li>
<li>for: 防止文本到图像扩散模型中的数据非法使用</li>
<li>methods: 植入干扰记忆法，通过分析模型是否记忆植入内容来检测非法数据使用</li>
<li>results: 在Stable Diffusion和LoRA模型上进行了实验，得到了效果的检测非法数据使用结果<details>
<summary>Abstract</summary>
Recent text-to-image diffusion models have shown surprising performance in generating high-quality images. However, concerns have arisen regarding the unauthorized usage of data during the training process. One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist. To address this issue, it becomes crucial to detect unauthorized data usage. In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset. Specifically, we modify the protected image dataset by adding unique contents on the images such as stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models. By analyzing whether the model has memorization for the injected content (i.e., whether the generated images are processed by the chosen post-processing function), we can detect models that had illegally utilized the unauthorized data. Our experiments conducted on Stable Diffusion and LoRA model demonstrate the effectiveness of the proposed method in detecting unauthorized data usages.
</details>
<details>
<summary>摘要</summary>
近期文本到图像扩散模型已经显示出了高质量图像生成的出色表现。然而，有关数据非法使用的担忧也在提出。一个例子是模型训练者收集了某个艺术家创作的图像集并尝试通过不取得艺术家的授权来训练一个能够生成类似图像的模型。为解决这个问题，检测非法数据使用变得非常重要。在这篇论文中，我们提议一种方法，通过在受保护图像集中添加特有的内容，例如隐形图像包装函数，使得扩散模型能够吸收这些内容并且记忆它们。然后，通过判断模型是否具有这些内容的记忆（即是否通过选择的后处理函数处理生成的图像），可以检测模型是否使用了非法数据。我们在Stable Diffusion和LoRA模型上进行了实验，并证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Contextual-Affinity-Distillation-for-Image-Anomaly-Detection"><a href="#Contextual-Affinity-Distillation-for-Image-Anomaly-Detection" class="headerlink" title="Contextual Affinity Distillation for Image Anomaly Detection"></a>Contextual Affinity Distillation for Image Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03101">http://arxiv.org/abs/2307.03101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zhang, Masanori Suganuma, Takayuki Okatani<br>for:本研究旨在提高无监督工业异常检测的性能，特别是对逻辑异常进行检测，而不需要训练繁重的模型。methods:本研究基于先前的知识塑化工作，使用两名学生（本地学生和全球学生）来更好地模仿教师的行为。本地学生主要用于检测结构异常，而全球学生则关注逻辑异常。为了进一步鼓励全球学生学习捕捉长距离依赖关系，我们设计了全球上下文维度压缩块（GCCB），并提出了上下文相互关联损失。results:实验结果表明，提议方法不需要训练复杂的模型，可以达到新的领先性水平在MVTec LOCO AD数据集上。<details>
<summary>Abstract</summary>
Previous works on unsupervised industrial anomaly detection mainly focus on local structural anomalies such as cracks and color contamination. While achieving significantly high detection performance on this kind of anomaly, they are faced with logical anomalies that violate the long-range dependencies such as a normal object placed in the wrong position. In this paper, based on previous knowledge distillation works, we propose to use two students (local and global) to better mimic the teacher's behavior. The local student, which is used in previous studies mainly focuses on structural anomaly detection while the global student pays attention to logical anomalies. To further encourage the global student's learning to capture long-range dependencies, we design the global context condensing block (GCCB) and propose a contextual affinity loss for the student training and anomaly scoring. Experimental results show the proposed method doesn't need cumbersome training techniques and achieves a new state-of-the-art performance on the MVTec LOCO AD dataset.
</details>
<details>
<summary>摘要</summary>
先前的工业异常检测研究主要关注本地结构异常，如裂隙和颜色杂散。尽管达到了本地异常检测的显著高效性，但它们面临着跨距离相互关联的逻辑异常，如正常对象被错误地放置。在这篇论文中，基于先前的知识塑模工作，我们提议使用两名学生（本地和全球）来更好地模仿教师的行为。本地学生，在先前的研究中主要用于结构异常检测，而全球学生则关注逻辑异常。为了进一步鼓励全球学生学习捕捉长距离相互关联，我们设计了全球上下文缩合块（GCCB）并提出了上下文相互关系损失。实验结果表明，我们提议的方法不需要复杂的训练技术，并达到了MVTec LOCO AD数据集的新的状态之平台。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/cs.CV_2023_07_07/" data-id="clpahu72000fx3h88hbv05b43" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/cs.AI_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T12:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/cs.AI_2023_07_07/">cs.AI - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Decomposing-the-Generalization-Gap-in-Imitation-Learning-for-Visual-Robotic-Manipulation"><a href="#Decomposing-the-Generalization-Gap-in-Imitation-Learning-for-Visual-Robotic-Manipulation" class="headerlink" title="Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation"></a>Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03659">http://arxiv.org/abs/2307.03659</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RLAgent/factor-world">https://github.com/RLAgent/factor-world</a></li>
<li>paper_authors: Annie Xie, Lisa Lee, Ted Xiao, Chelsea Finn</li>
<li>for: 本研究的目的是探讨视觉机器人 manipulate 演示中的模仿学习困难的原因，以及这些困难的评估方法。</li>
<li>methods: 我们使用了 simulation 和真实机器人语言条件 manipulate 任务来评估模仿学习策略的泛化能力，并设计了一个新的 simulated 测试环境来更加控制地评估不同因素的泛化难度。</li>
<li>results: 我们的研究表明，不同因素的泛化难度存在很大差异，并且这些差异是相对稳定的。我们还发现，某些因素的泛化难度较高，而另外的因素则较低。<details>
<summary>Abstract</summary>
What makes generalization hard for imitation learning in visual robotic manipulation? This question is difficult to approach at face value, but the environment from the perspective of a robot can often be decomposed into enumerable factors of variation, such as the lighting conditions or the placement of the camera. Empirically, generalization to some of these factors have presented a greater obstacle than others, but existing work sheds little light on precisely how much each factor contributes to the generalization gap. Towards an answer to this question, we study imitation learning policies in simulation and on a real robot language-conditioned manipulation task to quantify the difficulty of generalization to different (sets of) factors. We also design a new simulated benchmark of 19 tasks with 11 factors of variation to facilitate more controlled evaluations of generalization. From our study, we determine an ordering of factors based on generalization difficulty, that is consistent across simulation and our real robot setup.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这个问题是非常Difficult to approach directly, because the environment from the perspective of a robot can often be decomposed into多种因素的变化，例如照明条件或摄像头的位置。验证性地，对一些这些因素的泛化呈现了更大的困难，但现有的工作却没有提供具体如何量化每个因素对泛化差距的信息。为了回答这个问题，我们研究了模仿学习策略在模拟和真实机器人语言conditioned manipulation任务中的泛化困难。我们还设计了一个新的模拟benchmark，包含19个任务和11个因素的变化，以便更好地评估泛化的控制性。从我们的研究中，我们确定了因素的排序，这一结果在模拟和真实机器人设置中均是一致的。
</details></li>
</ul>
<hr>
<h2 id="Discovering-Variable-Binding-Circuitry-with-Desiderata"><a href="#Discovering-Variable-Binding-Circuitry-with-Desiderata" class="headerlink" title="Discovering Variable Binding Circuitry with Desiderata"></a>Discovering Variable Binding Circuitry with Desiderata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03637">http://arxiv.org/abs/2307.03637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xander Davies, Max Nadeau, Nikhil Prakash, Tamar Rott Shaham, David Bau</li>
<li>for: 本研究旨在提出一种方法，以自动地归因模型组件负责执行特定子任务的 causal  attribute。</li>
<li>methods: 本研究使用了 causal mediation experiments 来自动归因模型组件，并且只需要指定模型组件执行子任务的 causal attribute。</li>
<li>results: 研究成果显示，可以成功地自动发现 LLama-13B 模型中的共享变量绑定电路，并且只需要9个注意头和1个MLP来执行多个数学任务中的变量绑定。<details>
<summary>Abstract</summary>
Recent work has shown that computation in language models may be human-understandable, with successful efforts to localize and intervene on both single-unit features and input-output circuits. Here, we introduce an approach which extends causal mediation experiments to automatically identify model components responsible for performing a specific subtask by solely specifying a set of \textit{desiderata}, or causal attributes of the model components executing that subtask. As a proof of concept, we apply our method to automatically discover shared \textit{variable binding circuitry} in LLaMA-13B, which retrieves variable values for multiple arithmetic tasks. Our method successfully localizes variable binding to only 9 attention heads (of the 1.6k) and one MLP in the final token's residual stream.
</details>
<details>
<summary>摘要</summary>
最近的研究表明，计算机语言模型中的计算可能是人类理解的，有成功的尝试将单元特征和输入输出电路 lokalisirui和 intervene。在这里，我们介绍了一种方法，可以自动确定模型组件负责执行特定子任务，只需提供一组 \textit{desiderata}，或模型组件执行该子任务的 causal 特征。作为证明，我们应用了我们的方法，自动发现 LLama-13B 中的共享 \textit{变量绑定Circuitry}，该模型可以为多个数学任务获取变量值。我们的方法成功地将变量绑定Localized to only 9 attention heads (of the 1.6k) and one MLP in the final token's residual stream.
</details></li>
</ul>
<hr>
<h2 id="Over-the-Air-Computation-in-OFDM-Systems-with-Imperfect-Channel-State-Information"><a href="#Over-the-Air-Computation-in-OFDM-Systems-with-Imperfect-Channel-State-Information" class="headerlink" title="Over-the-Air Computation in OFDM Systems with Imperfect Channel State Information"></a>Over-the-Air Computation in OFDM Systems with Imperfect Channel State Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05357">http://arxiv.org/abs/2307.05357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yilong Chen, Huijun Xing, Jie Xu, Lexi Xu, Shuguang Cui<br>for:这个论文研究了在无线电通信系统中进行空中计算（AirComp），特别是在无线电信道状态信息（CSI）不准确时，多个单antenna无线设备（WD）同时向多antenna访问点（AP）上传uncoded信号进行分布式功能计算。methods:在这种情况下，我们考虑了两种enario：一种是最大化average计算平均方差（MSE），另一种是最小化计算失败概率（outage probability）。为了实现这两个目标，我们同时优化了WDs发射器和AP接收扫描器在子载波上的传输系数和接收扫描器。results:我们在这篇论文中提出了两种特殊情况的解：一种是单个AP接收天线的情况，另一种是多个AP接收天线的情况。在单个AP接收天线情况下，我们使用 Lagrange-duality 方法提出了半闭形 globally 优化解。在多个AP接收天线情况下，我们提出了高效的 alternate 优化和几何优化算法来找到 converges 解。<details>
<summary>Abstract</summary>
This paper studies the over-the-air computation (AirComp) in an orthogonal frequency division multiplexing (OFDM) system with imperfect channel state information (CSI), in which multiple single-antenna wireless devices (WDs) simultaneously send uncoded signals to a multi-antenna access point (AP) for distributed functional computation over multiple subcarriers. In particular, we consider two scenarios with best-effort and error-constrained computation tasks, with the objectives of minimizing the average computation mean squared error (MSE) and the computation outage probability over the multiple subcarriers, respectively. Towards this end, we jointly optimize the transmit coefficients at the WDs and the receive beamforming vectors at the AP over subcarriers, subject to the maximum transmit power constraints at individual WDs. First, for the special case with a single receive antenna at the AP, we propose the semi-closed-form globally optimal solutions to the two problems using the Lagrange-duality method. It is shown that at each subcarrier, the WDs' optimized power control policy for average MSE minimization follows a regularized channel inversion structure, while that for computation outage probability minimization follows an on-off regularized channel inversion, with the regularization dependent on the transmit power budget and channel estimation error. Next, for the general case with multiple receive antennas at the AP, we present efficient algorithms based on alternating optimization and convex optimization to find converged solutions to both problems.
</details>
<details>
<summary>摘要</summary>
For the special case with a single receive antenna at the AP, we propose semi-closed-form globally optimal solutions to the two problems using the Lagrange-duality method. The results show that at each subcarrier, the WDs' optimized power control policy for average MSE minimization follows a regularized channel inversion structure, while that for computation outage probability minimization follows an on-off regularized channel inversion, with the regularization dependent on the transmit power budget and channel estimation error.For the general case with multiple receive antennas at the AP, we present efficient algorithms based on alternating optimization and convex optimization to find converged solutions to both problems. These algorithms take into account the coupling between the transmit coefficients and the receive beamforming vectors, and the non-convexity of the optimization problems.In summary, this paper investigates the optimization of AirComp in an OFDM system with imperfect CSI, and proposes algorithms to minimize the average MSE and computation outage probability over multiple subcarriers. The proposed solutions take into account the maximum transmit power constraints and the coupling between the transmit coefficients and the receive beamforming vectors.
</details></li>
</ul>
<hr>
<h2 id="Brain-in-a-Vat-On-Missing-Pieces-Towards-Artificial-General-Intelligence-in-Large-Language-Models"><a href="#Brain-in-a-Vat-On-Missing-Pieces-Towards-Artificial-General-Intelligence-in-Large-Language-Models" class="headerlink" title="Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models"></a>Brain in a Vat: On Missing Pieces Towards Artificial General Intelligence in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03762">http://arxiv.org/abs/2307.03762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxi Ma, Chi Zhang, Song-Chun Zhu</li>
<li>for: 这篇论文主要是为了探讨大语言模型（LLM）的评估方法和人工通用智能的定义。</li>
<li>methods: 论文首先对现有的LLM评估方法进行了全面回顾，并指出了评估方法中的一些问题，这些问题会导致LLM的能力被过分评估。然后，文章提出了人工通用智能应包含以下四个特征：1）可以完成无数量的任务；2）可以在 Context中生成新任务；3）基于值系统来生成任务；4）具有基于现实的世界模型，这种世界模型影响了它与世界的交互。</li>
<li>results: 文章认为，现有的人工智能研究仅仅是模拟智能，而不是真正的通用智能。它们缺乏了知识获得和行为的一体化，而且知识获得不仅仅靠 passive input，还需要重复的尝试和错误。文章结束时，提出了人工智能未来研究的可能性。<details>
<summary>Abstract</summary>
In this perspective paper, we first comprehensively review existing evaluations of Large Language Models (LLMs) using both standardized tests and ability-oriented benchmarks. We pinpoint several problems with current evaluation methods that tend to overstate the capabilities of LLMs. We then articulate what artificial general intelligence should encompass beyond the capabilities of LLMs. We propose four characteristics of generally intelligent agents: 1) they can perform unlimited tasks; 2) they can generate new tasks within a context; 3) they operate based on a value system that underpins task generation; and 4) they have a world model reflecting reality, which shapes their interaction with the world. Building on this viewpoint, we highlight the missing pieces in artificial general intelligence, that is, the unity of knowing and acting. We argue that active engagement with objects in the real world delivers more robust signals for forming conceptual representations. Additionally, knowledge acquisition isn't solely reliant on passive input but requires repeated trials and errors. We conclude by outlining promising future research directions in the field of artificial general intelligence.
</details>
<details>
<summary>摘要</summary>
在这篇观点论文中，我们首先进行了涵盖现有大语言模型（LLM）评估的全面审查，使用标准化测试和能力尺度标准。我们指出了现有评估方法存在一些问题，导致LLM的能力被过度评估。然后，我们详细说明了人工总智能应包括以下四个特点：1）可以完成无数项任务；2）可以在 Context 中生成新任务；3）基于值系统来决定任务生成；4）具有对实际世界的认知，影响其与世界的互动。基于这种视角，我们强调了人工总智能缺失的一部分，即知识和行为的一体性。我们 argued That active engagement with objects in the real world provides more robust signals for forming conceptual representations. In addition, knowledge acquisition is not solely reliant on passive input, but requires repeated trials and errors. Finally, we outline promising future research directions in the field of artificial general intelligence.
</details></li>
</ul>
<hr>
<h2 id="GEANN-Scalable-Graph-Augmentations-for-Multi-Horizon-Time-Series-Forecasting"><a href="#GEANN-Scalable-Graph-Augmentations-for-Multi-Horizon-Time-Series-Forecasting" class="headerlink" title="GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting"></a>GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03595">http://arxiv.org/abs/2307.03595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sitan Yang, Malcolm Wolff, Shankar Ramasubramanian, Vincent Quenneville-Belair, Ronak Metha, Michael W. Mahoney</li>
<li>for: 解决“冷启”时间序列预测问题，即预测缺乏历史数据的时间序列。</li>
<li>methods: 利用图神经网络（GNN）作为编码器增强器，通过生成GNN基于的特征来捕捉时间序列之间的复杂关系。</li>
<li>results: 在实际应用中，对一家大型电商商户的需求预测 task 中，我们的方法可以提高总表现，并更重要的是，对“冷启”产品（新上市或者刚下架）的预测带来显著改善。<details>
<summary>Abstract</summary>
Encoder-decoder deep neural networks have been increasingly studied for multi-horizon time series forecasting, especially in real-world applications. However, to forecast accurately, these sophisticated models typically rely on a large number of time series examples with substantial history. A rapidly growing topic of interest is forecasting time series which lack sufficient historical data -- often referred to as the ``cold start'' problem. In this paper, we introduce a novel yet simple method to address this problem by leveraging graph neural networks (GNNs) as a data augmentation for enhancing the encoder used by such forecasters. These GNN-based features can capture complex inter-series relationships, and their generation process can be optimized end-to-end with the forecasting task. We show that our architecture can use either data-driven or domain knowledge-defined graphs, scaling to incorporate information from multiple very large graphs with millions of nodes. In our target application of demand forecasting for a large e-commerce retailer, we demonstrate on both a small dataset of 100K products and a large dataset with over 2 million products that our method improves overall performance over competitive baseline models. More importantly, we show that it brings substantially more gains to ``cold start'' products such as those newly launched or recently out-of-stock.
</details>
<details>
<summary>摘要</summary>
深度神经网络在多个时间水平预测方面得到了越来越多的研究，特别是在实际应用中。然而，为了准确预测，这些复杂的模型通常需要大量的时间序列示例，其中具有充分的历史记录。一个迅速增长的研究领域是缺少历史数据的时间序列预测问题，通常被称为“冷开始”问题。在这篇论文中，我们介绍了一种新的、简单的方法，通过利用图神经网络（GNN）作为编码器增强器来解决这个问题。这些GNN基于的特征可以捕捉到时间序列之间的复杂关系，并且其生成过程可以与预测任务结合optimized。我们示出了我们的架构可以使用数据驱动或域知识定义的图，可涵盖多个具有百万个节点的图。在我们的目标应用中，我们在10万个产品的小数据集和超过2万个产品的大数据集上进行了实验，并证明了我们的方法可以在比较基eline模型的情况下提供更好的总体性能。更重要的是，我们发现我们的方法对“冷开始”产品（如新上市或者刚出库）的预测具有显著的改善。
</details></li>
</ul>
<hr>
<h2 id="VesselVAE-Recursive-Variational-Autoencoders-for-3D-Blood-Vessel-Synthesis"><a href="#VesselVAE-Recursive-Variational-Autoencoders-for-3D-Blood-Vessel-Synthesis" class="headerlink" title="VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis"></a>VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03592">http://arxiv.org/abs/2307.03592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paula Feldman, Miguel Fainstein, Viviana Siless, Claudio Delrieux, Emmanuel Iarussi</li>
<li>for: 这篇论文的目的是为了 Synthesizing blood vessel 3D geometry, 即生成血管三维几何结构。</li>
<li>methods: 该论文使用的方法是 recursive variational Neural Network (VesselVAE)，它可以完全利用血管的层次结构，学习低维抽象表示分支连接性以及表示目标表面的几何特征。</li>
<li>results: 该论文的实验结果显示，VesselVAE可以生成高度准确和多样化的血管三维模型，并且与实际数据的相似性达到了&#x2F;.97、&#x2F;.95和&#x2F;.96三个指标。这些结果表明，VesselVAE可以用于医疗和手术训练、血液动力学 simulations 等多种目的。<details>
<summary>Abstract</summary>
We present a data-driven generative framework for synthesizing blood vessel 3D geometry. This is a challenging task due to the complexity of vascular systems, which are highly variating in shape, size, and structure. Existing model-based methods provide some degree of control and variation in the structures produced, but fail to capture the diversity of actual anatomical data. We developed VesselVAE, a recursive variational Neural Network that fully exploits the hierarchical organization of the vessel and learns a low-dimensional manifold encoding branch connectivity along with geometry features describing the target surface. After training, the VesselVAE latent space can be sampled to generate new vessel geometries. To the best of our knowledge, this work is the first to utilize this technique for synthesizing blood vessels. We achieve similarities of synthetic and real data for radius (.97), length (.95), and tortuosity (.96). By leveraging the power of deep neural networks, we generate 3D models of blood vessels that are both accurate and diverse, which is crucial for medical and surgical training, hemodynamic simulations, and many other purposes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于数据的生成框架，用于synthesizing血管三维几何结构。这是一项具有挑战性的任务，因为血液系统的复杂性和多样性很高，它们的形态、大小和结构各不相同。现有的模型基本方法可以提供一定的控制和变化，但是无法捕捉实际生物学数据的多样性。我们开发了VesselVAE，一种嵌入式的可变量神经网络，它完全利用血管的层次结构，学习低维度抽象表示分支连接以及表面特征，描述目标表面的几何特征。经过训练，VesselVAE的幂数空间可以采样新的血管几何结构。根据我们所知，这是第一次利用这种技术来生成血管。我们实现了真实数据和生成数据之间的相似性（.97），（.95）和（.96）。通过利用深度神经网络的力量，我们生成了准确且多样的血管三维模型，这对医疗和手术培训、血液动力学计算以及许多其他目的都是关键。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Deep-Learning-for-Personalized-Renal-Cell-Carcinoma-Prognosis-Integrating-CT-Imaging-and-Clinical-Data"><a href="#Multimodal-Deep-Learning-for-Personalized-Renal-Cell-Carcinoma-Prognosis-Integrating-CT-Imaging-and-Clinical-Data" class="headerlink" title="Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data"></a>Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03575">http://arxiv.org/abs/2307.03575</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mahootiha-maryam/Survival_CTplusClinical">https://github.com/mahootiha-maryam/Survival_CTplusClinical</a></li>
<li>paper_authors: Maryamalsadat Mahootiha, Hemin Ali Qadir, Jacob Bergsland, Ilangko Balasingham<br>for:这项研究的目的是开发一个全面的深度学习模型，用于预测renoocellular carcinoma患者的生存可能性，通过结合CT成像和临床数据，并解决过去研究中出现的局限性。methods:该研究提posed一个框架，包括三个模块：3D图像特征提取器、临床变量选择和生存预测。图像特征提取器模块基于3D CNN架构，预测CT成像中renoocellular carcinoma肿瘤的ISUP分期，与死亡率相关。临床变量选择使用Spearman分数和Random Forest重要性分数作为标准，系统地选择临床变量。生存预测使用深度学习网络，以Discrete LogisticHazard-based损失函数进行训练。results:我们的发现表明，提出的策略超过了当前renoocellular carcinoma预测Literature中基于CT成像和临床因素的研究。最佳实验在测试集上达到了 concordance index 0.84和area under the curve 0.8 的水平，这表明了该方法在预测renoocellular carcinoma患者的生存可能性方面具有强大的预测力。<details>
<summary>Abstract</summary>
Renal cell carcinoma represents a significant global health challenge with a low survival rate. This research aimed to devise a comprehensive deep-learning model capable of predicting survival probabilities in patients with renal cell carcinoma by integrating CT imaging and clinical data and addressing the limitations observed in prior studies. The aim is to facilitate the identification of patients requiring urgent treatment. The proposed framework comprises three modules: a 3D image feature extractor, clinical variable selection, and survival prediction. The feature extractor module, based on the 3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumors linked to mortality rates from CT images. A selection of clinical variables is systematically chosen using the Spearman score and random forest importance score as criteria. A deep learning-based network, trained with discrete LogisticHazard-based loss, performs the survival prediction. Nine distinct experiments are performed, with varying numbers of clinical variables determined by different thresholds of the Spearman and importance scores. Our findings demonstrate that the proposed strategy surpasses the current literature on renal cancer prognosis based on CT scans and clinical factors. The best-performing experiment yielded a concordance index of 0.84 and an area under the curve value of 0.8 on the test cohort, which suggests strong predictive power. The multimodal deep-learning approach developed in this study shows promising results in estimating survival probabilities for renal cell carcinoma patients using CT imaging and clinical data. This may have potential implications in identifying patients who require urgent treatment, potentially improving patient outcomes. The code created for this project is available for the public on: \href{https://github.com/Balasingham-AI-Group/Survival_CTplusClinical}{GitHub}
</details>
<details>
<summary>摘要</summary>
“肾细胞癌 represents a significant global health challenge with a low survival rate. This research aimed to develop a comprehensive deep-learning model capable of predicting survival probabilities in patients with renal cell carcinoma by integrating CT imaging and clinical data, and addressing the limitations observed in prior studies. The aim is to facilitate the identification of patients requiring urgent treatment. The proposed framework consists of three modules: a 3D image feature extractor, clinical variable selection, and survival prediction. The feature extractor module, based on the 3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumors linked to mortality rates from CT images. A selection of clinical variables is systematically chosen using the Spearman score and random forest importance score as criteria. A deep learning-based network, trained with discrete LogisticHazard-based loss, performs the survival prediction. Nine distinct experiments were performed, with varying numbers of clinical variables determined by different thresholds of the Spearman and importance scores. Our findings demonstrate that the proposed strategy surpasses the current literature on renal cancer prognosis based on CT scans and clinical factors. The best-performing experiment yielded a concordance index of 0.84 and an area under the curve value of 0.8 on the test cohort, which suggests strong predictive power. The multimodal deep-learning approach developed in this study shows promising results in estimating survival probabilities for renal cell carcinoma patients using CT imaging and clinical data. This may have potential implications in identifying patients who require urgent treatment, potentially improving patient outcomes. The code created for this project is available for the public on GitHub.”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Why-machines-do-not-understand-A-response-to-Sogaard"><a href="#Why-machines-do-not-understand-A-response-to-Sogaard" class="headerlink" title="Why machines do not understand: A response to Søgaard"></a>Why machines do not understand: A response to Søgaard</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04766">http://arxiv.org/abs/2307.04766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jobst Landgrebe, Barry Smith</li>
<li>for: 本文针对一些人认为机器人可以理解语言的观点进行批判，具体来说是关于索加德（Sogaard）在这本杂志上提出的一种这样的thesis，基于语言学习和机器学习的概念。</li>
<li>methods: 本文使用了对索加德的论点进行分析和批判的方法，包括对语言的使用和存储方式的分析，以及对机器学习和人工智能的批判。</li>
<li>results: 本文表明了索加德的论点存在问题，主要是因为他忽视了人类语言使用和计算机语言存储的区别，从而导致了机器人理解语言的困难。<details>
<summary>Abstract</summary>
Some defenders of so-called `artificial intelligence' believe that machines can understand language. In particular, S{\o}gaard has argued in this journal for a thesis of this sort, on the basis of the idea (1) that where there is semantics there is also understanding and (2) that machines are not only capable of what he calls `inferential semantics', but even that they can (with the help of inputs from sensors) `learn' referential semantics \parencite{sogaard:2022}. We show that he goes wrong because he pays insufficient attention to the difference between language as used by humans and the sequences of inert of symbols which arise when language is stored on hard drives or in books in libraries.
</details>
<details>
<summary>摘要</summary>
一些人认为论称的人工智能可以理解语言。特别是，S{\o}gaard在这份报告中提出了这种thesis，基于两点：一是语言存在 semantics 就是理解的 garantor（1），二是机器不仅可以进行他所称的“推理 semantics”，而且可以（通过感知器的输入）“学习” referential semantics（\parencite{sogaard:2022）。我们展示了他的错误是因为他忽视了人类使用语言和存储在硬盘或图书馆中的语言序列的差异。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Graph-Attention-for-Anomaly-Detection-in-Heterogeneous-Sensor-Networks"><a href="#Dynamic-Graph-Attention-for-Anomaly-Detection-in-Heterogeneous-Sensor-Networks" class="headerlink" title="Dynamic Graph Attention for Anomaly Detection in Heterogeneous Sensor Networks"></a>Dynamic Graph Attention for Anomaly Detection in Heterogeneous Sensor Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03761">http://arxiv.org/abs/2307.03761</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MengjieZhao/dygatad">https://github.com/MengjieZhao/dygatad</a></li>
<li>paper_authors: Mengjie Zhao, Olga Fink</li>
<li>for: 本文针对的是随着互联网 Things (IIoTs) 系统中的多变量时间序列 (MTS) 数据的异常检测，即使在感知器网络中存在复杂性和互相关系的情况下。</li>
<li>methods: 本文提出了 DyGATAD (动态图注意力异常检测) 方法，该方法利用注意力机制构建了多变量时间序列上的连续图表示，并通过推断动态边来检测关系变化。 DyGATAD 还包括了基于操作条件的重建和 topology 基于异常分数，从而提高了异常检测的能力。</li>
<li>results: 根据一个控制变量的 synthetic 数据集和一个实际 industrials 的多相流设备数据集，我们证明了 DyGATAD 在感知器网络中的异常检测性能非常高，特别是在早期疾病检测和轻度疾病检测方面表现出色。<details>
<summary>Abstract</summary>
In the era of digital transformation, systems monitored by the Industrial Internet of Things (IIoTs) generate large amounts of Multivariate Time Series (MTS) data through heterogeneous sensor networks. While this data facilitates condition monitoring and anomaly detection, the increasing complexity and interdependencies within the sensor network pose significant challenges for anomaly detection. Despite progress in this field, much of the focus has been on point anomalies and contextual anomalies, with lesser attention paid to collective anomalies. A less addressed but common variant of collective anomalies is when the abnormal collective behavior is caused by shifts in interrelationships within the system. This can be due to abnormal environmental conditions like overheating, improper operational settings resulting from cyber-physical attacks, or system-level faults. To address these challenges, this paper proposes DyGATAD (Dynamic Graph Attention for Anomaly Detection), a graph-based anomaly detection framework that leverages the attention mechanism to construct a continuous graph representation of multivariate time series by inferring dynamic edges between time series. DyGATAD incorporates an operating condition-aware reconstruction combined with a topology-based anomaly score, thereby enhancing the detection ability of relationship shifts. We evaluate the performance of DyGATAD using both a synthetic dataset with controlled varying fault severity levels and an industrial-scale multiphase flow facility benchmark featuring various fault types with different detection difficulties. Our proposed approach demonstrated superior performance in collective anomaly detection for sensor networks, showing particular strength in early-stage fault detection, even in the case of faults with minimal severity.
</details>
<details>
<summary>摘要</summary>
在数字变革时代，由IIoT系统监测的系统生成大量多变量时间序列（MTS）数据，这些数据可以帮助 condition monitoring 和异常检测。然而，随着传感器网络的复杂性和互相关系的增加，异常检测遇到了 significiant 挑战。虽然在这一领域已经做出了很多进展，但是大多数研究都是关注点异常和上下文异常，而忽略了集体异常。这是一种较少地研究的，但是非常普遍的 коллектив异常情况，即传感器网络中的异常行为是由系统间关系的变化引起的。这可能是因为环境条件异常、操作设置不当或系统级别的故障所致。为解决这些挑战，本文提出了 DyGATAD（动态图注意力检测），一种基于图的异常检测框架。DyGATAD 利用注意力机制来构建多变量时间序列中的连续图表示，并通过推理出动态边的方式来捕捉系统间的关系变化。DyGATAD 还包括了根据操作条件进行修正的重构，以及基于 topological 异常分数的检测，从而提高了异常检测的能力。我们对一个合成数据集和一个实际工业级多相流设施的数据进行了评估，结果表明，DyGATAD 在传感器网络中的集体异常检测中表现出色，特别是在初期疾病检测中，甚至是在疾病严重程度较低的情况下。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-as-Batteries-Included-Zero-Shot-ESCO-Skills-Matchers"><a href="#Large-Language-Models-as-Batteries-Included-Zero-Shot-ESCO-Skills-Matchers" class="headerlink" title="Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers"></a>Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03539">http://arxiv.org/abs/2307.03539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Clavié, Guillaume Soulié<br>for:这篇论文的目的是提出一个零上下测试的自动技能抽出系统，用于对雇佣广告中的技能抽出。methods:这个系统使用大型自然语言模型（LLM）来生成Synthetic训练数据，并使用一个分类器来从雇佣广告中提取技能提及。然后使用另一个LLM进行相似预测，以重新排序技能候选人。results:这篇论文的结果显示，使用合成数据可以在技能抽出 задачі中取得10个RP@10分的高分，比前一些距离指导方法高出10个分。同时，添加GPT-4重新排序可以提高RP@10的表现，高于前一些方法的22个分。此外，将任务框架为“假程式”的提示，可以让LLM表现更好，特别是使用较弱的LLM。<details>
<summary>Abstract</summary>
Understanding labour market dynamics requires accurately identifying the skills required for and possessed by the workforce. Automation techniques are increasingly being developed to support this effort. However, automatically extracting skills from job postings is challenging due to the vast number of existing skills. The ESCO (European Skills, Competences, Qualifications and Occupations) framework provides a useful reference, listing over 13,000 individual skills. However, skills extraction remains difficult and accurately matching job posts to the ESCO taxonomy is an open problem. In this work, we propose an end-to-end zero-shot system for skills extraction from job descriptions based on large language models (LLMs). We generate synthetic training data for the entirety of ESCO skills and train a classifier to extract skill mentions from job posts. We also employ a similarity retriever to generate skill candidates which are then re-ranked using a second LLM. Using synthetic data achieves an RP@10 score 10 points higher than previous distant supervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22 points over previous methods. We also show that Framing the task as mock programming when prompting the LLM can lead to better performance than natural language prompts, especially with weaker LLMs. We demonstrate the potential of integrating large language models at both ends of skills matching pipelines. Our approach requires no human annotations and achieve extremely promising results on skills extraction against ESCO.
</details>
<details>
<summary>摘要</summary>
理解劳动市场动态需要准确地确定工作人员所需和拥有的技能。自动化技术在支持这一努力方面发展得越来越好。然而，从工作岗posts中自动提取技能是一项挑战，因为存在庞大的技能数量。欧洲技能、COMPETENCES、资格和职业（ESCO）框架提供了有用的参考，列出了13,000多个具体的技能。然而，技能提取仍然具有挑战性，并且准确匹配工作岗posts到ESCO分类是一个打开的问题。在这种工作中，我们提议一种终端零批量系统，使用大型自然语言模型（LLMs）进行技能提取从工作岗posts。我们生成了ESCO技能整体的合成训练数据，并使用一个分类器提取技能提及从工作岗posts。此外，我们使用一个相似搜索器生成技能候选人选，然后使用第二个LLM进行重新排序。使用合成数据实现RP@10分数10点高于前一种远程指导方法。另外，添加GPT-4重新排序可以提高RP@10分数22点以上。我们还证明，将任务fram为Mock编程时请求LLM的提示可以提高性能，特别是使用较弱的LLM。我们展示了将大型自然语言模型 integrate到技能匹配管道的潜在优势，并实现了无需人工标注的技能提取 противESCO。
</details></li>
</ul>
<hr>
<h2 id="Physical-Color-Calibration-of-Digital-Pathology-Scanners-for-Robust-Artificial-Intelligence-Assisted-Cancer-Diagnosis"><a href="#Physical-Color-Calibration-of-Digital-Pathology-Scanners-for-Robust-Artificial-Intelligence-Assisted-Cancer-Diagnosis" class="headerlink" title="Physical Color Calibration of Digital Pathology Scanners for Robust Artificial Intelligence Assisted Cancer Diagnosis"></a>Physical Color Calibration of Digital Pathology Scanners for Robust Artificial Intelligence Assisted Cancer Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05519">http://arxiv.org/abs/2307.05519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyi Ji, Richard Salmon, Nita Mulliqi, Umair Khan, Yinxi Wang, Anders Blilie, Henrik Olsson, Bodil Ginnerup Pedersen, Karina Dalsgaard Sørensen, Benedicte Parm Ulhøi, Svein R Kjosavik, Emilius AM Janssen, Mattias Rantalainen, Lars Egevad, Pekka Ruusuvuori, Martin Eklund, Kimmo Kartasalo</li>
<li>for: 这项研究旨在解决数位patology中人工智能（AI）的潜力受到技术不一致的抑制，从而使AI在临床应用中受到挑战。</li>
<li>methods: 研究者使用了物理色彩准确的扫描仪进行了四个实验室的色彩准确性标准化，以确定这种方法对抗癌诊断模型的影响。</li>
<li>results: 研究结果表明，物理色彩准确的扫描仪可以标准化整个报告图像的出现，从而提高AI模型的准确性和Gleason分级表现。这项研究验证了物理色彩准确的扫描仪可以解决不同扫描仪 introduce的变化，使AI基于的肿瘤诊断变得更加可靠和在临床设置中可行。<details>
<summary>Abstract</summary>
The potential of artificial intelligence (AI) in digital pathology is limited by technical inconsistencies in the production of whole slide images (WSIs), leading to degraded AI performance and posing a challenge for widespread clinical application as fine-tuning algorithms for each new site is impractical. Changes in the imaging workflow can also lead to compromised diagnoses and patient safety risks. We evaluated whether physical color calibration of scanners can standardize WSI appearance and enable robust AI performance. We employed a color calibration slide in four different laboratories and evaluated its impact on the performance of an AI system for prostate cancer diagnosis on 1,161 WSIs. Color standardization resulted in consistently improved AI model calibration and significant improvements in Gleason grading performance. The study demonstrates that physical color calibration provides a potential solution to the variation introduced by different scanners, making AI-based cancer diagnostics more reliable and applicable in clinical settings.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在数字 PATHOLOGY 中的潜力受到扫描机器（Whole Slide Images，WSIs）技术不一致的限制，导致 AI 性能下降，并对营养广泛临床应用 pose 挑战。工作流程变化也可能导致诊断错误和 patient safety 风险。我们评估了扫描机器的物理色彩准确性是否可以标准化 WSI 的外观，并对抗肉癌诊断 AI 系统的1,161 WSI 的表现。色彩标准化导致 AI 模型准确性的改进，并且在 Gleason 分期性能中得到了显著改进。这项研究表明，物理色彩准确性提供了扫描机器间变化引入的解决方案，使 AI 基于肉癌诊断更可靠和在临床设置中应用。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Graph-Pooling-for-Explainable-Classification-of-Brain-Networks"><a href="#Contrastive-Graph-Pooling-for-Explainable-Classification-of-Brain-Networks" class="headerlink" title="Contrastive Graph Pooling for Explainable Classification of Brain Networks"></a>Contrastive Graph Pooling for Explainable Classification of Brain Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11133">http://arxiv.org/abs/2307.11133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxing Xu, Qingtian Bian, Xinhang Li, Aihu Zhang, Yiping Ke, Miao Qiao, Wei Zhang, Wei Khang Jeremy Sim, Balázs Gulyás</li>
<li>for: 这个论文的目的是提出一种适用于Functional magnetic resonance imaging (fMRI)数据的图 neural network (GNN) 模型，以提高对大脑网络的理解和描述。</li>
<li>methods: 这个论文使用的方法包括一种对比性双注意力块和一种可微graph pooling方法，以便更好地利用GNN来描述大脑网络。</li>
<li>results: 该论文在5个休息态fMRI大脑网络数据集上进行了应用，并证明了其在比基elines上表现出优异。此外，研究还发现了与 neuroscience 文献中的知识匹配的特征特征，并提供了直观和有趣的探索。<details>
<summary>Abstract</summary>
Functional magnetic resonance imaging (fMRI) is a commonly used technique to measure neural activation. Its application has been particularly important in identifying underlying neurodegenerative conditions such as Parkinson's, Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literature, and disclose direct and interesting insights. Our contributions underscore the potential of ContrastPool for advancing the understanding of brain networks and neurodegenerative conditions.
</details>
<details>
<summary>摘要</summary>
Functional magnetic resonance imaging (fMRI) 是一种广泛使用的技术来测量神经活动。其应用在识别下面的神经退化疾病，如 Parkinson's、Alzheimer's 和 Autism 等方面特别重要。最近的 fMRI 数据分析模型将大脑视为图，通过图神经网络（GNN）提取特征。然而，fMRI 数据的特殊性需要特殊的 GNN 设计。适应 GNN 生成有效和域 explainable 特征仍然是挑战。在这篇论文中，我们提出了对比 dual-attention 块和可导图聚合方法，称之为 ContrastPool，以更好地利用 GNN 对大脑网络。我们在 5 个休息态 fMRI 大脑网络数据集上应用了我们的方法，并证明我们的方法在比基eline上显著superior。我们的案例研究表明，我们的方法提取的特征与 neuroscience 文献中的领域知识匹配，并且揭示了直观和有趣的发现。我们的贡献表明 ContrastPool 在理解大脑网络和神经退化疾病方面具有潜力。
</details></li>
</ul>
<hr>
<h2 id="Procedurally-generating-rules-to-adapt-difficulty-for-narrative-puzzle-games"><a href="#Procedurally-generating-rules-to-adapt-difficulty-for-narrative-puzzle-games" class="headerlink" title="Procedurally generating rules to adapt difficulty for narrative puzzle games"></a>Procedurally generating rules to adapt difficulty for narrative puzzle games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05518">http://arxiv.org/abs/2307.05518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Volden, Djordje Grbic, Paolo Burelli</li>
<li>for: 这篇论文旨在透过生成规则和通过玩家来调整难度。这是一个更大的项目，旨在收集和适应教育游戏 для小学生使用数字谜题游戏，设计给幼儿园。</li>
<li>methods: 这篇论文使用了遗传算法和难度度量来找到目标解集和大型自然语言模型来通过narativeContext来交流规则。</li>
<li>results: 在测试中，该方法能够在平均24个代表中找到规则，以达到目标难度。将来的实验计划提高评估、特化语言模型到儿童文学，并收集多modal数据来引导适应。<details>
<summary>Abstract</summary>
This paper focuses on procedurally generating rules and communicating them to players to adjust the difficulty. This is part of a larger project to collect and adapt games in educational games for young children using a digital puzzle game designed for kindergarten. A genetic algorithm is used together with a difficulty measure to find a target number of solution sets and a large language model is used to communicate the rules in a narrative context. During testing the approach was able to find rules that approximate any given target difficulty within two dozen generations on average. The approach was combined with a large language model to create a narrative puzzle game where players have to host a dinner for animals that can't get along. Future experiments will try to improve evaluation, specialize the language model on children's literature, and collect multi-modal data from players to guide adaptation.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "procedurally generating" 生成过程中的 (shēngchǎng yǔ xiǎngchǎng)* "difficulty" 难度 (nándù)* "target number of solution sets" 目标解决方案的数量 (mùzhì jiějué fāng'àn de shùliàng)* "large language model" 大型自然语言模型 (dàxíng zìrán yǔyán módelì)* "narrative context" 叙事上下文 (jiùshì shàngxìa)* "genetic algorithm" 遗传算法 (lìchǎng suànfǎ)* "solution sets" 解决方案 (jiějué fāng'àn)
</details></li>
</ul>
<hr>
<h2 id="Tranfer-Learning-of-Semantic-Segmentation-Methods-for-Identifying-Buried-Archaeological-Structures-on-LiDAR-Data"><a href="#Tranfer-Learning-of-Semantic-Segmentation-Methods-for-Identifying-Buried-Archaeological-Structures-on-LiDAR-Data" class="headerlink" title="Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data"></a>Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03512">http://arxiv.org/abs/2307.03512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paolo Soleni, Wouter B. Verschoof-van der Vaart, Žiga Kokalj, Arianna Traviglia, Marco Fiorucci</li>
<li>for: 用深度学习技术进行远程感知数据在考古研究中应用，一个主要障碍是训练模型所需的数据的有限可用性。</li>
<li>methods: 本研究使用了传输学习技术，并对两个semantic segmentation深度神经网络在两个LiDAR数据集上进行了比较。</li>
<li>results: 实验结果表明，在考古领域中使用传输学习配置可以提高性能，但尚未观察到系统性的提高。我们提供了特定的应用场景，以供未来研究的参考。<details>
<summary>Abstract</summary>
When applying deep learning to remote sensing data in archaeological research, a notable obstacle is the limited availability of suitable datasets for training models. The application of transfer learning is frequently employed to mitigate this drawback. However, there is still a need to explore its effectiveness when applied across different archaeological datasets. This paper compares the performance of various transfer learning configurations using two semantic segmentation deep neural networks on two LiDAR datasets. The experimental results indicate that transfer learning-based approaches in archaeology can lead to performance improvements, although a systematic enhancement has not yet been observed. We provide specific insights about the validity of such techniques that can serve as a baseline for future works.
</details>
<details>
<summary>摘要</summary>
当应用深度学习到远程感知数据中的考古研究中，一个显著的障碍是训练模型的数据减少的限制。通常使用传输学习来缓解这个问题。然而，还需要探索它在不同的考古数据集之间的效果。这篇论文比较了不同的传输学习配置使用两种semantic segmentation深度神经网络在两个LiDAR数据集上的性能。实验结果表明，在考古领域中使用传输学习可以提高性能，但是还没有系统地提高。我们提供了特定的洞察，以供未来研究的参考。
</details></li>
</ul>
<hr>
<h2 id="Derivative-Free-Weight-space-Ensembling"><a href="#Derivative-Free-Weight-space-Ensembling" class="headerlink" title="Derivative Free Weight-space Ensembling"></a>Derivative Free Weight-space Ensembling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03506">http://arxiv.org/abs/2307.03506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dean Ninalga</li>
<li>for: 本研究的目的是提出一种新的几个样本任务传递方法，以便在开放领域对话中进行有效的任务传递。</li>
<li>methods: 本研究使用了Derivative Free Weight-space Ensembling（DFWE）策略，该策略创建了一组多样化的专家语言模型，每个专家模型通过预定的源任务进行训练。然后，每个专家模型都进行了精度调整，以便更好地适应目标任务。最后，我们使用了一种无级优化算法来线性 interpolate  между模型的权重，以达到有效地找到一个好的权重混合。</li>
<li>results: 我们在FETA-Friends上进行了实验，并证明了DFWE的效果。相比标准的预训练-精度调整方法，DFWE能够更好地传递知识并提高任务表现。<details>
<summary>Abstract</summary>
Recent work suggests that interpolating between the weights of two specialized language models can transfer knowledge between tasks in a way that multi-task learning cannot. However, very few have explored interpolation between more than two models, where each has a distinct knowledge base. In this paper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new few-sample task transfer approach for open-domain dialogue. Our framework creates a set of diverse expert language models trained using a predefined set of source tasks. Next, we finetune each of the expert models on the target task, approaching the target task from several distinct knowledge bases. Finally, we linearly interpolate between the model weights using a gradient-free-optimization algorithm, to efficiently find a good interpolation weighting. We demonstrate the effectiveness of the method on FETA-Friends outperforming the standard pretrain-finetune approach.
</details>
<details>
<summary>摘要</summary>
研究表明，在两个特殊化语言模型之间 interpolate 知识可以在任务之间传递知识，而多任务学习则无法实现。然而，很少人研究了超过两个模型的 interpolate。在这篇论文中，我们介绍了 Derivative Free Weight-space Ensembling (DFWE)，一种新的几个样本任务传递方法，用于开放领域对话。我们的框架创建了一组多样化的专家语言模型，每个模型通过预定的源任务进行训练。然后，我们每个专家模型都在目标任务上精度调整，从多个不同的知识基础上进行 approached。最后，我们使用一个 gradient-free-optimization 算法来线性 interpolate 模型的 weights，以效率地找到一个好的 interpolate 权重。我们在 FETA-Friends 上 demonstrate 了方法的效果，超过标准预训练-精度调整方法。
</details></li>
</ul>
<hr>
<h2 id="RCDN-–-Robust-X-Corner-Detection-Algorithm-based-on-Advanced-CNN-Model"><a href="#RCDN-–-Robust-X-Corner-Detection-Algorithm-based-on-Advanced-CNN-Model" class="headerlink" title="RCDN – Robust X-Corner Detection Algorithm based on Advanced CNN Model"></a>RCDN – Robust X-Corner Detection Algorithm based on Advanced CNN Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03505">http://arxiv.org/abs/2307.03505</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Chen, Caihua Xiong, Quanlin Li, Zhonghua Wan</li>
<li>for: 提高机器视觉和机器人领域中X-角落检测和地理化的精度和可靠性。</li>
<li>methods: 提出了一种新的检测算法，可以在多种干扰下保持高比素精度，包括镜头扭曲、极端pose和噪声。该算法采用了一个粗粒度检测网络和三种后处理技术来筛选正确的角度候选者，以及一种混合比素精度修正技术和改进的区域增长策略来自动地恢复部分可见或遮挡的检查板图样。</li>
<li>results: 对实际和 sintetic 图像进行评估，表明提出的算法在检测率、比素精度和Robustness方面比其他常用方法更高。此外，camera calibration和pose estimation实验也表明，该算法可以更好地实现相机参数的调整和pose的估计。<details>
<summary>Abstract</summary>
Accurate detection and localization of X-corner on both planar and non-planar patterns is a core step in robotics and machine vision. However, previous works could not make a good balance between accuracy and robustness, which are both crucial criteria to evaluate the detectors performance. To address this problem, in this paper we present a novel detection algorithm which can maintain high sub-pixel precision on inputs under multiple interference, such as lens distortion, extreme poses and noise. The whole algorithm, adopting a coarse-to-fine strategy, contains a X-corner detection network and three post-processing techniques to distinguish the correct corner candidates, as well as a mixed sub-pixel refinement technique and an improved region growth strategy to recover the checkerboard pattern partially visible or occluded automatically. Evaluations on real and synthetic images indicate that the presented algorithm has the higher detection rate, sub-pixel accuracy and robustness than other commonly used methods. Finally, experiments of camera calibration and pose estimation verify it can also get smaller re-projection error in quantitative comparisons to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
通过精准探测和定位X角的算法， robotics和机器视觉中的核心步骤是检测X角。然而，过去的方法无法保持高精度和可靠性的平衡，这两个 критери㪨都是评估探测器性能的关键因素。为解决这个问题，在这篇论文中，我们提出了一种新的探测算法，可以在多种干扰下保持高分辨率，包括镜头扭曲、极端pose和噪声。该算法采用了粗粒度探测网络和三种后处理技术来分辨正确的角度候选者，以及混合分辨率纠正技术和改进的区域增长策略来自动地恢复部分可见或遮挡的Checkerboard模式。实验表明，提出的算法在真实和 sintetic 图像上具有更高的检测率、分辨率和可靠性，并且在相机准备和pose估计方面也能够获得更小的重映射误差。
</details></li>
</ul>
<hr>
<h2 id="Large-AI-Model-Based-Semantic-Communications"><a href="#Large-AI-Model-Based-Semantic-Communications" class="headerlink" title="Large AI Model-Based Semantic Communications"></a>Large AI Model-Based Semantic Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03492">http://arxiv.org/abs/2307.03492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feibo Jiang, Yubo Peng, Li Dong, Kezhi Wang, Kun Yang, Cunhua Pan, Xiaohu You</li>
<li>for: 这篇论文旨在解决现有的智能通信系统中知识基础构建问题，提出一种基于大机器学习模型的智能通信框架（LAM-SC），用于处理图像数据。</li>
<li>methods: 该框架首先设计了基于universal semantic knowledge的图像分割模型（SAM）知识基础（SKB），然后提出一种基于注意力的Semantic Integration（ASI）方法，以及一种适应性压缩（ASC）编码方法来减少通信开销。</li>
<li>results: 通过实验，论文示出了LAM-SC框架的效果和未来智能通信模式中大机器学习模型基础知识的重要性。<details>
<summary>Abstract</summary>
Semantic communication (SC) is an emerging intelligent paradigm, offering solutions for various future applications like metaverse, mixed-reality, and the Internet of everything. However, in current SC systems, the construction of the knowledge base (KB) faces several issues, including limited knowledge representation, frequent knowledge updates, and insecure knowledge sharing. Fortunately, the development of the large AI model provides new solutions to overcome above issues. Here, we propose a large AI model-based SC framework (LAM-SC) specifically designed for image data, where we first design the segment anything model (SAM)-based KB (SKB) that can split the original image into different semantic segments by universal semantic knowledge. Then, we present an attention-based semantic integration (ASI) to weigh the semantic segments generated by SKB without human participation and integrate them as the semantic-aware image. Additionally, we propose an adaptive semantic compression (ASC) encoding to remove redundant information in semantic features, thereby reducing communication overhead. Finally, through simulations, we demonstrate the effectiveness of the LAM-SC framework and the significance of the large AI model-based KB development in future SC paradigms.
</details>
<details>
<summary>摘要</summary>
semantic communication (SC) 是一种emerging intelligent paradigm，提供未来应用程序，如 metaverse、混合现实和 everything 互联网。然而，在当前 SC 系统中，知识库（KB）的构建面临多种问题，包括有限的知识表示、频繁的知识更新和不安全的知识分享。幸运的是，大型 AI 模型的开发提供了新的解决方案。我们在这里提出一个基于大型 AI 模型的 SC 框架（LAM-SC），专门设计为图像数据处理。我们首先设计了基于universal semantic knowledge的segment anything model（SAM）知识库（SKB），可以将原始图像分解成不同的semantic segment。然后，我们提出了无人参与的注意力基本（ASI），可以对 SKB 生成的semantic segment进行权重，并将它们集成为具有semantic-aware的图像。此外，我们还提出了自适应semantic compression（ASC）编码，可以从semantic features中去除冗余信息，以减少通信开销。最后，通过 simulated experiments，我们证明了 LAM-SC 框架的有效性和未来 SC  парадигms中大型 AI 模型基本知识库的发展的重要性。
</details></li>
</ul>
<hr>
<h2 id="Artificial-Eye-for-the-Blind"><a href="#Artificial-Eye-for-the-Blind" class="headerlink" title="Artificial Eye for the Blind"></a>Artificial Eye for the Blind</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00801">http://arxiv.org/abs/2308.00801</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deepususeel/SmartEye">https://github.com/deepususeel/SmartEye</a></li>
<li>paper_authors: Abhinav Benagi, Dhanyatha Narayan, Charith Rage, A Sushmitha</li>
<li>for: 这个论文的目的是提供一种基于Raspberry Pi3的人工智能眼模型，帮助盲人进行交通导航和日常生活中的行动决策。</li>
<li>methods: 该模型使用了raspberry pi3，webcam，ultrasonic proximity sensor， speaker和多种软件模型，包括物体检测、文本识别、Google文本识别和Mycroft语音助手模型。</li>
<li>results: 模型可以帮助盲人在交通导航和日常生活中更加灵活和自信，同时还可以提供语音援助和文本援助。<details>
<summary>Abstract</summary>
The main backbone of our Artificial Eye model is the Raspberry pi3 which is connected to the webcam ,ultrasonic proximity sensor, speaker and we also run all our software models i.e object detection, Optical Character recognition, google text to speech conversion and the Mycroft voice assistance model. At first the ultrasonic proximity sensor will be measuring the distance between itself and any obstacle in front of it .When the Proximity sensor detects any obstacle in front within its specified range, the blind person will hear an audio prompt about an obstacle in his way at a certain distance. At this time the Webcam will capture an image in front of it and the Object detection model and the Optical Character Recognition model will begin to run on the Raspberry pi. The imat of the blind person. The text and the object detected are conveyed to the blind pege captured is first sent through the Tesseract OCR module to detect any texts in the image and then through the Object detection model to detect the objects in fronrson by converting the texts to speech by using the gTTS module. Along with the above mentioned process going on there will be an active MYCROFT voice assistant model which can be used to interact with the blind person. The blind person can ask about the weather , daily news , any information on the internet ,etc
</details>
<details>
<summary>摘要</summary>
主要脊梁我们的人工智能眼镜模型是Raspberry Pi3，与摄像头、超音波距离仪、喇叭和我们的软件模型（物品检测、字符识别、Google文本转语音和Mycroft语音助手模型）连接在一起。在 primeros，超音波距离仪将测量自己和前方任何障碍物的距离。当超音波距离仪检测到前方 Within its specified range 的障碍物时，盲人将听到一个语音提醒，表示有障碍物在他的路线上。在这个时候，摄像头将拍摄前方的图像，并将图像传递给Raspberry Pi进行处理。在处理过程中，我们使用Tesseract OCR模块来检测图像中的文本，然后将文本转换为语音，使用gTTS模块进行转换。同时，我们还会有一个活跃的MYCROFT语音助手模型，可以让盲人与其进行互动，盲人可以询问天气、每日新闻、网络上的信息等。
</details></li>
</ul>
<hr>
<h2 id="Discovering-Hierarchical-Achievements-in-Reinforcement-Learning-via-Contrastive-Learning"><a href="#Discovering-Hierarchical-Achievements-in-Reinforcement-Learning-via-Contrastive-Learning" class="headerlink" title="Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning"></a>Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03486">http://arxiv.org/abs/2307.03486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seungyong Moon, Junyoung Yeom, Bumsoo Park, Hyun Oh Song</li>
<li>for: 本研究旨在探索在生成型环境中发现具有层次结构的成就，并且需要代理人类 possess 一系列能力，如总结和长期理解。</li>
<li>methods: 本研究使用 proximal policy optimization (PPO) 算法，一种简单而多功能的无模型学习方法，并且发现 PPO 代理人类可以预测下一个成就的可能性，虽然 confidence 较低。</li>
<li>results: 研究发现，使用 PPO 算法和我们提出的新的准则学习方法 achievement distillation，可以强化代理人类对下一个成就的预测，并且在挑战性的 Crafter 环境中显示出状态的术语表现。<details>
<summary>Abstract</summary>
Discovering achievements with a hierarchical structure on procedurally generated environments poses a significant challenge. This requires agents to possess a broad range of abilities, including generalization and long-term reasoning. Many prior methods are built upon model-based or hierarchical approaches, with the belief that an explicit module for long-term planning would be beneficial for learning hierarchical achievements. However, these methods require an excessive amount of environment interactions or large model sizes, limiting their practicality. In this work, we identify that proximal policy optimization (PPO), a simple and versatile model-free algorithm, outperforms the prior methods with recent implementation practices. Moreover, we find that the PPO agent can predict the next achievement to be unlocked to some extent, though with low confidence. Based on this observation, we propose a novel contrastive learning method, called achievement distillation, that strengthens the agent's capability to predict the next achievement. Our method exhibits a strong capacity for discovering hierarchical achievements and shows state-of-the-art performance on the challenging Crafter environment using fewer model parameters in a sample-efficient regime.
</details>
<details>
<summary>摘要</summary>
发现具有层次结构的成就需要智能体具备广泛的能力，包括总结和长期逻辑。许多先前方法基于模型或层次结构，以为存在明确的长期规划模块可以帮助学习层次成就。然而，这些方法需要大量的环境互动或庞大的模型大小，限制了它们的实用性。在这项工作中，我们发现，近似策略优化（PPO），一种简单和多样的模型自由算法，在现有实现方法中表现出色，并且我们发现PPOAgent可以预测下一个成就的概率，虽然有一定的不确定性。基于这个观察，我们提出了一种新的对比学习方法，即成就萃取，以强化智能体的下一个成就预测能力。我们的方法在挑战性高的Crafter环境中展现出了优秀的成就发现能力和模型参数更少的样本效率。
</details></li>
</ul>
<hr>
<h2 id="TBGC-Task-level-Backbone-Oriented-Gradient-Clip-for-Multi-Task-Foundation-Model-Learning"><a href="#TBGC-Task-level-Backbone-Oriented-Gradient-Clip-for-Multi-Task-Foundation-Model-Learning" class="headerlink" title="TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation Model Learning"></a>TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation Model Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03465">http://arxiv.org/abs/2307.03465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zelun Zhang, Xue Pan</li>
<li>for: 提高多任务学习中回归梯度偏导问题</li>
<li>methods: 提出了任务级别梯度剪裁策略和多支分支数据增强策略</li>
<li>results: 实验结果表明，该策略可以减轻回归梯度偏导问题，并在CVPR2023 Foundation Model Challenge中获得1名和2名。<details>
<summary>Abstract</summary>
The AllInOne training paradigm squeezes a wide range of tasks into a unified model in a multi-task learning manner. However, optimization in multi-task learning is more challenge than single-task learning, as the gradient norm from different tasks may vary greatly, making the backbone overly biased towards one specific task. To address this issue, we propose the task-level backbone-oriented gradient clip paradigm, compared with the vanilla gradient clip method, it has two points of emphasis:1) gradient clip is performed independently for each task. 2) backbone gradients generated from each task are rescaled to the same norm scale. Based on the experimental results, we argue that the task-level backbone-oriented gradient clip paradigm can relieve the gradient bias problem to some extent. We also propose a novel multi-branch data augmentation strategy where conflict augmentations are placed in different branches. Our approach has been shown to be effective and finally achieve 1st place in the Leaderboard A and 2nd place in the Leaderboard B of the CVPR2023 Foundation Model Challenge. It's worth noting that instead of evaluating all three tasks(detection, segmentation and fine-grained classification) in Leaderboard A, the segmentation task is not evaluated in Leaderboard B, in which our team has a huge advantage.
</details>
<details>
<summary>摘要</summary>
全面一体训练模式将多种任务集成到一个多任务学习模型中，但是多任务学习中的优化具有更大的挑战，因为不同任务的梯度范围可能很大，导致支持结构偏向某一个特定任务。为解决这个问题，我们提出了任务级别支持结构折叠梯度剪辑方法，相比于普通梯度剪辑方法，它具有两点优势：1）梯度剪辑独立进行每个任务；2）每个任务生成的支持结构梯度都被缩放到同一个范围尺度。根据实验结果，我们认为任务级别支持结构折叠梯度剪辑方法可以减轻梯度偏向问题至少一部分。此外，我们还提出了一种新的多支持分支数据增强策略，其中冲突增强被放置在不同支持中。我们的方法在CVPR2023基金会模型挑战中获得了1名和2名。值得注意的是，在Leaderboard A中评估所有三个任务（检测、 segmentation 和细化分类），而Leaderboard B中不评估 segmentation 任务，我们在这个任务上具有很大优势。
</details></li>
</ul>
<hr>
<h2 id="MultiQG-TI-Towards-Question-Generation-from-Multi-modal-Sources"><a href="#MultiQG-TI-Towards-Question-Generation-from-Multi-modal-Sources" class="headerlink" title="MultiQG-TI: Towards Question Generation from Multi-modal Sources"></a>MultiQG-TI: Towards Question Generation from Multi-modal Sources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04643">http://arxiv.org/abs/2307.04643</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/moonlightlane/multiqg-ti">https://github.com/moonlightlane/multiqg-ti</a></li>
<li>paper_authors: Zichao Wang, Richard Baraniuk</li>
<li>for: 本研究探讨了自动生成问题（QG） FROM 多ModalSource中的图像和文本，扩展了大多数现有工作的范围，这些工作都专注于仅仅从文本源中生成问题。</li>
<li>methods: 我们提出了一个简单的解决方案，called MultiQG-TI，它使得文本只问题生成器能够处理视觉输入。我们利用图像描述模型和光学字符识别模型来获取图像的文本描述和图像中的文本，并将它们与输入文本一起传递给问题生成器。我们只是微调问题生成器，而保持其他组件不变。</li>
<li>results: 在 ScienceQA 数据集上，我们示出了 MultiQG-TI 在几个shot prompting 下Significantly outperform ChatGPT，即使它有百分之一的训练参数。Additional 分析也证明了视觉和文本信号的必要性，以及模型选择的影响。<details>
<summary>Abstract</summary>
We study the new problem of automatic question generation (QG) from multi-modal sources containing images and texts, significantly expanding the scope of most of the existing work that focuses exclusively on QG from only textual sources. We propose a simple solution for our new problem, called MultiQG-TI, which enables a text-only question generator to process visual input in addition to textual input. Specifically, we leverage an image-to-text model and an optical character recognition model to obtain the textual description of the image and extract any texts in the image, respectively, and then feed them together with the input texts to the question generator. We only fine-tune the question generator while keeping the other components fixed. On the challenging ScienceQA dataset, we demonstrate that MultiQG-TI significantly outperforms ChatGPT with few-shot prompting, despite having hundred-times less trainable parameters. Additional analyses empirically confirm the necessity of both visual and textual signals for QG and show the impact of various modeling choices.
</details>
<details>
<summary>摘要</summary>
我们研究一个新的自动问题生成（QG）问题，利用多Modal来源，包括图像和文本，从而扩大现有大多数工作的范围，这些工作都专注于只使用文本来源进行QG。我们提出了一个简单的解决方案，称为MultiQG-TI，它使得文本只的问题生成器能够处理视觉输入，同时还可以处理文本输入。我们利用图像到文本模型和光学字符识别模型来获得图像的文本描述和图像中的文本，然后将这些信息与输入文本一起传递给问题生成器。我们只是微调问题生成器，而不是其他组件。在 ScienceQA 数据集上，我们证明 MultiQG-TI 在少量提示下，以 hundred-times  fewer trainable parameters 的情况下， Significantly outperform ChatGPT。我们还进行了更多的分析，确认了视觉和文本信号的必要性，以及模型选择的影响。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Graph-Neural-Networks-for-Time-Series-Forecasting-Classification-Imputation-and-Anomaly-Detection"><a href="#A-Survey-on-Graph-Neural-Networks-for-Time-Series-Forecasting-Classification-Imputation-and-Anomaly-Detection" class="headerlink" title="A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection"></a>A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03759">http://arxiv.org/abs/2307.03759</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kimmeen/awesome-gnn4ts">https://github.com/kimmeen/awesome-gnn4ts</a></li>
<li>paper_authors: Ming Jin, Huan Yee Koh, Qingsong Wen, Daniele Zambon, Cesare Alippi, Geoffrey I. Webb, Irwin King, Shirui Pan</li>
<li>for: 本研究评论文章旨在概述图 neural network（GNN）在时间序列分析（TS）领域的应用，包括预测、分类、异常检测和填充等方面。</li>
<li>methods: 本文使用GNN来模型时间序列数据中的关系，包括时间序列之间和变量之间的关系。GNN可以更好地模型这些关系，比如传统的深度神经网络和其他GNN-based方法。</li>
<li>results: 本文提供了一个全面的任务-导向的分类法，并详细介绍了一些代表性的研究工作和应用。同时，文章还提出了未来研究的可能性，包括针对不同类型时间序列数据的GNN模型。<details>
<summary>Abstract</summary>
Time series are the primary data type used to record dynamic system measurements and generated in great volume by both physical sensors and online processes (virtual sensors). Time series analytics is therefore crucial to unlocking the wealth of information implicit in available data. With the recent advancements in graph neural networks (GNNs), there has been a surge in GNN-based approaches for time series analysis. These approaches can explicitly model inter-temporal and inter-variable relationships, which traditional and other deep neural network-based methods struggle to do. In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: forecasting, classification, anomaly detection, and imputation. Our aim is to guide designers and practitioners to understand, build applications, and advance research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy of GNN4TS. Then, we present and discuss representative research works and introduce mainstream applications of GNN4TS. A comprehensive discussion of potential future research directions completes the survey. This survey, for the first time, brings together a vast array of knowledge on GNN-based time series research, highlighting foundations, practical applications, and opportunities of graph neural networks for time series analysis.
</details>
<details>
<summary>摘要</summary>
时间序列是主要数据类型，用于记录动态系统测量和生成大量数据，both physical sensors和在线过程（虚拟感知器）生成。时间序列分析因此是解锁可用数据中的巨量信息的关键。随着图 neural networks（GNNs）的最近进步，有一个浪涌GNN-based时间序列分析方法的出现。这些方法可以显式地模型时间序列和变量之间的关系，传统的和其他深度神经网络基于方法难以做到。在本survey中，我们提供了Graph Neural Networks for Time Series Analysis（GNN4TS）的全面评论，涵盖四个基本维度：预测、分类、异常检测和补做。我们的目标是引导设计者和实践者理解、建立应用和推动GNN4TS的研究。首先，我们提供了GNN4TS的任务 oriented 分类。然后，我们介绍了代表性的研究工作和主流应用GNN4TS。最后，我们进行了全面的未来研究方向的讨论，以帮助读者更好地理解GNN-based时间序列研究的基础、实践和未来发展。这是首次将GNN-based时间序列研究汇总起来，把涉及的知识集中起来，推动 Graph Neural Networks for Time Series Analysis的研究。
</details></li>
</ul>
<hr>
<h2 id="Towards-Deep-Network-Steganography-From-Networks-to-Networks"><a href="#Towards-Deep-Network-Steganography-From-Networks-to-Networks" class="headerlink" title="Towards Deep Network Steganography: From Networks to Networks"></a>Towards Deep Network Steganography: From Networks to Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03444">http://arxiv.org/abs/2307.03444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guobiao Li, Sheng Li, Meiling Li, Zhenxing Qian, Xinpeng Zhang</li>
<li>for: 这个论文主要针对的是如何在公共通道中隐藏深度神经网络（DNN）模型，特别是那些训练用于机密学习任务的模型。</li>
<li>methods: 我们提出了一种深度网络隐藏（Deep Network Steganography，DNS），将机密的DNN模型转换为一个普通的学习任务。这是由于我们的方法将机密模型中的一些重要位置装饰成普通的学习位置，并将这些位置隐藏在一个隐藏频道中。</li>
<li>results: 我们的实验结果显示，我们的方法可以实现隐藏DNN模型，并且可以在不同的学习任务之间进行隐藏。具体而言，我们在内部任务隐藏（Intra-task steganography）和多任务隐藏（Inter-task steganography）两种情况下实现了隐藏DNN模型的目标。<details>
<summary>Abstract</summary>
With the widespread applications of the deep neural network (DNN), how to covertly transmit the DNN models in public channels brings us the attention, especially for those trained for secret-learning tasks. In this paper, we propose deep network steganography for the covert communication of DNN models. Unlike the existing steganography schemes which focus on the subtle modification of the cover data to accommodate the secrets, our scheme is learning task oriented, where the learning task of the secret DNN model (termed as secret-learning task) is disguised into another ordinary learning task conducted in a stego DNN model (termed as stego-learning task). To this end, we propose a gradient-based filter insertion scheme to insert interference filters into the important positions in the secret DNN model to form a stego DNN model. These positions are then embedded into the stego DNN model using a key by side information hiding. Finally, we activate the interference filters by a partial optimization strategy, such that the generated stego DNN model works on the stego-learning task. We conduct the experiments on both the intra-task steganography and inter-task steganography (i.e., the secret and stego-learning tasks belong to the same and different categories), both of which demonstrate the effectiveness of our proposed method for covert communication of DNN models.
</details>
<details>
<summary>摘要</summary>
随着深度神经网络（DNN）的广泛应用，如何在公共频道上不显地传输已训练的DNN模型引发了关注，尤其是那些用于秘密学习任务的模型。在这篇论文中，我们提出了深度网络隐藏（DNN隐藏），用于不显地通信DNN模型。与现有的隐藏方案不同，我们的方案是任务 oriented，其中秘密学习任务（秘密学习任务）被隐藏到另一个普通的学习任务（隐藏学习任务）中。为此，我们提出了一种梯度基于的筛选插入方案，将重要的位置在秘密DNN模型中插入干扰筛选器，形成一个隐藏DNN模型。这些位置然后被嵌入到隐藏DNN模型中使用钥匙，并且使用侧信息隐藏。最后，我们使用部分优化策略启动干扰筛选器，使得生成的隐藏DNN模型在隐藏学习任务上工作。我们对两种情况进行实验：内任务隐藏（i.e., 秘密任务和隐藏学习任务属于同一类）和间任务隐藏（i.e., 秘密任务和隐藏学习任务属于不同类），两者均显示了我们提出的方法的效iveness。
</details></li>
</ul>
<hr>
<h2 id="Non-iterative-Coarse-to-fine-Transformer-Networks-for-Joint-Affine-and-Deformable-Image-Registration"><a href="#Non-iterative-Coarse-to-fine-Transformer-Networks-for-Joint-Affine-and-Deformable-Image-Registration" class="headerlink" title="Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration"></a>Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03421">http://arxiv.org/abs/2307.03421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mungomeng/registration-nice-trans">https://github.com/mungomeng/registration-nice-trans</a></li>
<li>paper_authors: Mingyuan Meng, Lei Bi, Michael Fulham, Dagan Feng, Jinman Kim</li>
<li>for: 这paper是为了提出一种基于深度学习的非迭代粗细到细粒度图像匹配算法。</li>
<li>methods: 这paper使用了一种名为NICE-Trans的非迭代粗细到细粒度图像匹配网络，该网络结合了矩阵变换和扩展抽取器来实现粗细到细粒度的图像匹配。</li>
<li>results: 实验结果表明，NICE-Trans可以在七个公共数据集上击败现有的图像匹配方法，并且在注重精度和运行时间之间取得了一个良好的平衡。<details>
<summary>Abstract</summary>
Image registration is a fundamental requirement for medical image analysis. Deep registration methods based on deep learning have been widely recognized for their capabilities to perform fast end-to-end registration. Many deep registration methods achieved state-of-the-art performance by performing coarse-to-fine registration, where multiple registration steps were iterated with cascaded networks. Recently, Non-Iterative Coarse-to-finE (NICE) registration methods have been proposed to perform coarse-to-fine registration in a single network and showed advantages in both registration accuracy and runtime. However, existing NICE registration methods mainly focus on deformable registration, while affine registration, a common prerequisite, is still reliant on time-consuming traditional optimization-based methods or extra affine registration networks. In addition, existing NICE registration methods are limited by the intrinsic locality of convolution operations. Transformers may address this limitation for their capabilities to capture long-range dependency, but the benefits of using transformers for NICE registration have not been explored. In this study, we propose a Non-Iterative Coarse-to-finE Transformer network (NICE-Trans) for image registration. Our NICE-Trans is the first deep registration method that (i) performs joint affine and deformable coarse-to-fine registration within a single network, and (ii) embeds transformers into a NICE registration framework to model long-range relevance between images. Extensive experiments with seven public datasets show that our NICE-Trans outperforms state-of-the-art registration methods on both registration accuracy and runtime.
</details>
<details>
<summary>摘要</summary>
医疗影像分析中的图像 регистрация是一项基本要求。基于深度学习的深度 регистрация方法在最近几年内得到了广泛的认可，因为它们可以快速完成端到端的 регистрация。许多深度REGISTRATION方法在多个REGISTRATION步骤中采用了隐式的卷积神经网络，以实现粗细到细节的REGISTRATION。然而，现有的NICEREGISTRATION方法主要关注于弹性REGISTRATION，而平移REGISTRATION，是医疗影像分析中非常常见的前提，仍然是通过时间消耗的传统优化方法或额外的平移REGISTRATION网络来实现。此外，现有的NICEREGISTRATION方法受到卷积神经网络的本质性局部性的限制。使用变换器可能解决这个限制，因为它们可以捕捉图像之间的长距离相关性。但是，使用变换器来进行NICEREGISTRATION的好处尚未得到了足够的探讨。在本研究中，我们提出了一种Non-Iterative Coarse-to-finE Transformer网络（NICE-Trans），用于图像REGISTRATION。我们的NICE-Trans是第一个在单个网络中同时实现了平移和弹性的粗细到细节REGISTRATION，以及在NICEREGISTRATION框架中使用变换器来模型图像之间的长距离相关性。我们对七个公共数据集进行了广泛的实验，结果表明，我们的NICE-Trans在REGISTRATION精度和运行时间两个方面都超过了当前的REGISTRATION方法。
</details></li>
</ul>
<hr>
<h2 id="QI2-–-an-Interactive-Tool-for-Data-Quality-Assurance"><a href="#QI2-–-an-Interactive-Tool-for-Data-Quality-Assurance" class="headerlink" title="QI2 – an Interactive Tool for Data Quality Assurance"></a>QI2 – an Interactive Tool for Data Quality Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03419">http://arxiv.org/abs/2307.03419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Geerkens, Christian Sieberichs, Alexander Braun, Thomas Waschulzik</li>
<li>for: 本研究旨在提高机器学习系统和大数据的数据质量，以满足欧洲委员会的AI法案的数据质量要求。</li>
<li>methods: 本研究提出了一种新的数据质量检查方法，可以检查多个数据质量方面的数据。这种方法可以量化数据质量要求，并在小例子数据集上验证了其效果。</li>
<li>results: 本研究在well known MNIST数据集上应用了这种方法，并通过示例数据集展示了其工作原理和优势。<details>
<summary>Abstract</summary>
The importance of high data quality is increasing with the growing impact and distribution of ML systems and big data. Also the planned AI Act from the European commission defines challenging legal requirements for data quality especially for the market introduction of safety relevant ML systems. In this paper we introduce a novel approach that supports the data quality assurance process of multiple data quality aspects. This approach enables the verification of quantitative data quality requirements. The concept and benefits are introduced and explained on small example data sets. How the method is applied is demonstrated on the well known MNIST data set based an handwritten digits.
</details>
<details>
<summary>摘要</summary>
“高品质数据的重要性在机器学习系统和大数据的普及和影响力增长之际日益增加。欧盟委员会的AI法案也将提出严格的法律要求，尤其是在安全相关的机器学习系统上。本文介绍一种新的方法，以支持多种数据质量层面的质量确保过程。这种方法可以verify数据质量的量化要求。本文将 introduce和解释这个概念，并使用小型示例数据集来说明其工作方式。在著名的MNIST数据集上，我们将说明如何应用这个方法。”Here's the translation in Traditional Chinese:“高品质数据的重要性在机器学习系统和大数据的普及和影响力增长之际日益增加。欧盟委员会的AI法案也将提出严格的法律要求，尤其是在安全相关的机器学习系统上。本文介绍一种新的方法，以支持多种数据质量层面的质量确保过程。这种方法可以verify数据质量的量化要求。本文将 introduce和解释这个概念，并使用小型示例数据集来说明其工作方式。在著名的MNIST数据集上，我们将说明如何应用这个方法。”
</details></li>
</ul>
<hr>
<h2 id="Goal-Conditioned-Predictive-Coding-as-an-Implicit-Planner-for-Offline-Reinforcement-Learning"><a href="#Goal-Conditioned-Predictive-Coding-as-an-Implicit-Planner-for-Offline-Reinforcement-Learning" class="headerlink" title="Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning"></a>Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03406">http://arxiv.org/abs/2307.03406</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilai Zeng, Ce Zhang, Shijie Wang, Chen Sun</li>
<li>for: 研究 whether sequence modeling can condense trajectories into useful representations for policy learning.</li>
<li>methods: 采用两阶段框架，首先使用序列模型技术简化轨迹数据，然后使用这些表示学习策略和愿景。</li>
<li>results: 在AntMaze、FrankaKitchen和Locomotion环境中进行了广泛的实验，发现序列模型对决策任务有显著影响，并且GCPC学习了一个目标状态相关的含义 reprehenstion，具有竞争性的性能。<details>
<summary>Abstract</summary>
Recent work has demonstrated the effectiveness of formulating decision making as a supervised learning problem on offline-collected trajectories. However, the benefits of performing sequence modeling on trajectory data is not yet clear. In this work we investigate if sequence modeling has the capability to condense trajectories into useful representations that can contribute to policy learning. To achieve this, we adopt a two-stage framework that first summarizes trajectories with sequence modeling techniques, and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predicitve Coding (GCPC), an approach that brings powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, and observe that sequence modeling has a significant impact on some decision making tasks. In addition, we demonstrate that GCPC learns a goal-conditioned latent representation about the future, which serves as an "implicit planner", and enables competitive performance on all three benchmarks.
</details>
<details>
<summary>摘要</summary>
To achieve this, we use a two-stage framework that first summarizes trajectories using sequence modeling techniques and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework.Within this framework, we introduce Goal-Conditioned Predictive Coding (GCPC), an approach that provides powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen, and Locomotion environments and find that sequence modeling has a significant impact on some decision-making tasks. Additionally, we demonstrate that GCPC learns a goal-conditioned latent representation of the future, which serves as an "implicit planner" and enables competitive performance on all three benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Potential-of-Large-Language-Models-LLMs-in-Learning-on-Graphs"><a href="#Exploring-the-Potential-of-Large-Language-Models-LLMs-in-Learning-on-Graphs" class="headerlink" title="Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs"></a>Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03393">http://arxiv.org/abs/2307.03393</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CurryTang/Graph-LLM">https://github.com/CurryTang/Graph-LLM</a></li>
<li>paper_authors: Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, Jiliang Tang</li>
<li>for: 本文探讨了使用大语言模型（LLMs）在图机器学习中的潜在作用，特别是节点分类任务中的两种可能的管道：LLMs-as-Enhancers 和 LLMs-as-Predictors。</li>
<li>methods: 本文采用了两种管道进行研究：一是使用 LLMs 增强节点的文本特征，然后通过 GNNs 进行预测；二是直接使用 LLMs 作为独立预测器。</li>
<li>results: 经过系统的实验研究，本文发现了一些原创的观察和新的发现，包括使用 LLMs 可以提高节点分类的准确率和提高 GNNs 的性能。<details>
<summary>Abstract</summary>
Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at https://github.com/CurryTang/Graph-LLM.
</details>
<details>
<summary>摘要</summary>
学习图有吸引了巨大的注意力，因为它在实际应用中有广泛的应用前景。最受欢迎的图学习管道是使用图神经网络（GNNs），并使用文本节点特征的浅层嵌入，但这有限制在总体知识和深刻Semantic理解方面。在最近几年，大型自然语言模型（LLMs）已经被证明具有广泛的通用知识和强大的Semantic理解能力，这些能力在处理文本数据方面已经引起了革命。在这篇论文中，我们想要探索LLMs在图机器学习中的潜力，特别是节点分类任务，并研究两种可能的管道：LLMs-as-Enhancers和LLMs-as-Predictors。前者利用LLMs来增强节点的文本特征，然后通过GNNs生成预测。后者尝试直接使用LLMs作为独立预测器。我们在不同的设置下进行了系统的研究，从广泛的实验结果中，我们得到了原创的观察和新的发现，这些发现开启了新的可能性和建议，并指向了可以利用LLMs来学习图的新的方向。我们的代码和数据集可以在https://github.com/CurryTang/Graph-LLM上获取。
</details></li>
</ul>
<hr>
<h2 id="On-Formal-Feature-Attribution-and-Its-Approximation"><a href="#On-Formal-Feature-Attribution-and-Its-Approximation" class="headerlink" title="On Formal Feature Attribution and Its Approximation"></a>On Formal Feature Attribution and Its Approximation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03380">http://arxiv.org/abs/2307.03380</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ffattr/ffa">https://github.com/ffattr/ffa</a></li>
<li>paper_authors: Jinqiang Yu, Alexey Ignatiev, Peter J. Stuckey</li>
<li>for: 提高形式XAI的应用范围和效能，对feature attribution进行正式阐明和评估。</li>
<li>methods: 基于正式阐明数学基础的feature attribution方法，使用正式阐明分析器架构，并提出一个简洁的形式阐明方法。</li>
<li>results: 在实验中，提出的简洁形式阐明方法可以实现高精度的feature attribution，并且比以往的方法更具有实用性和可scalability。<details>
<summary>Abstract</summary>
Recent years have witnessed the widespread use of artificial intelligence (AI) algorithms and machine learning (ML) models. Despite their tremendous success, a number of vital problems like ML model brittleness, their fairness, and the lack of interpretability warrant the need for the active developments in explainable artificial intelligence (XAI) and formal ML model verification. The two major lines of work in XAI include feature selection methods, e.g. Anchors, and feature attribution techniques, e.g. LIME and SHAP. Despite their promise, most of the existing feature selection and attribution approaches are susceptible to a range of critical issues, including explanation unsoundness and out-of-distribution sampling. A recent formal approach to XAI (FXAI) although serving as an alternative to the above and free of these issues suffers from a few other limitations. For instance and besides the scalability limitation, the formal approach is unable to tackle the feature attribution problem. Additionally, a formal explanation despite being formally sound is typically quite large, which hampers its applicability in practical settings. Motivated by the above, this paper proposes a way to apply the apparatus of formal XAI to the case of feature attribution based on formal explanation enumeration. Formal feature attribution (FFA) is argued to be advantageous over the existing methods, both formal and non-formal. Given the practical complexity of the problem, the paper then proposes an efficient technique for approximating exact FFA. Finally, it offers experimental evidence of the effectiveness of the proposed approximate FFA in comparison to the existing feature attribution algorithms not only in terms of feature importance and but also in terms of their relative order.
</details>
<details>
<summary>摘要</summary>
Motivated by these limitations, this paper proposes a way to apply formal XAI to feature attribution based on formal explanation enumeration. Formal feature attribution (FFA) is argued to be advantageous over existing methods, both formal and non-formal. Given the practical complexity of the problem, the paper proposes an efficient technique for approximating exact FFA. Finally, it offers experimental evidence of the effectiveness of the proposed approximate FFA in comparison to existing feature attribution algorithms in terms of feature importance and relative order.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Ground-Vehicle-Path-Following-in-Game-AI"><a href="#Efficient-Ground-Vehicle-Path-Following-in-Game-AI" class="headerlink" title="Efficient Ground Vehicle Path Following in Game AI"></a>Efficient Ground Vehicle Path Following in Game AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03379">http://arxiv.org/abs/2307.03379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rodrigue de Schaetzen, Alessandro Sestini</li>
<li>for: 这篇研究目的是为游戏AI中的地面车辆设计一个高效的路径追踪解决方案。</li>
<li>methods: 我们使用已有技术加以改进，设计了一个简单的解决方案，并调整参数以获得高效的benchmark路径追踪器。我们的解决方案特别注重计算路径曲率的 quadratic Bezier 曲线。</li>
<li>results: 我们透过在一个首人射击游戏中进行了多种测试enario，评估了提案的路径追踪器的效果和可靠性。与现有的路径追踪解决方案相比，我们获得了70%的缩减在统计上的困难事件。<details>
<summary>Abstract</summary>
This short paper presents an efficient path following solution for ground vehicles tailored to game AI. Our focus is on adapting established techniques to design simple solutions with parameters that are easily tunable for an efficient benchmark path follower. Our solution pays particular attention to computing a target speed which uses quadratic Bezier curves to estimate the path curvature. The performance of the proposed path follower is evaluated through a variety of test scenarios in a first-person shooter game, demonstrating its effectiveness and robustness in handling different types of paths and vehicles. We achieved a 70% decrease in the total number of stuck events compared to an existing path following solution.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="All-in-One-Exploring-Unified-Vision-Language-Tracking-with-Multi-Modal-Alignment"><a href="#All-in-One-Exploring-Unified-Vision-Language-Tracking-with-Multi-Modal-Alignment" class="headerlink" title="All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment"></a>All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03373">http://arxiv.org/abs/2307.03373</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/983632847/All-in-One">https://github.com/983632847/All-in-One</a></li>
<li>paper_authors: Chunhui Zhang, Xin Sun, Li Liu, Yiqian Yang, Qiong Liu, Xi Zhou, Yanfeng Wang</li>
<li>for: 提高视觉语言跟踪器的性能，使其能够更好地处理复杂的场景，如同源扰动和极端照明。</li>
<li>methods: 提出了一个All-in-One框架，将视觉和语言信号直接混合，并使用一个统一的变换块来学习协同提取和交互。还引入了一种多Modal匹配模块，使用交叉modal和自modal对比目标来提供更有理性的表示。</li>
<li>results: 经过广泛的实验，在五个 benchmark上都达到了现有状态 искусственный智能的最高水平，并且比之前的方法更加高效和可靠。<details>
<summary>Abstract</summary>
Current mainstream vision-language (VL) tracking framework consists of three parts, \ie a visual feature extractor, a language feature extractor, and a fusion model. To pursue better performance, a natural modus operandi for VL tracking is employing customized and heavier unimodal encoders, and multi-modal fusion models. Albeit effective, existing VL trackers separate feature extraction and feature integration, resulting in extracted features that lack semantic guidance and have limited target-aware capability in complex scenarios, \eg similar distractors and extreme illumination. In this work, inspired by the recent success of exploring foundation models with unified architecture for both natural language and computer vision tasks, we propose an All-in-One framework, which learns joint feature extraction and interaction by adopting a unified transformer backbone. Specifically, we mix raw vision and language signals to generate language-injected vision tokens, which we then concatenate before feeding into the unified backbone architecture. This approach achieves feature integration in a unified backbone, removing the need for carefully-designed fusion modules and resulting in a more effective and efficient VL tracking framework. To further improve the learning efficiency, we introduce a multi-modal alignment module based on cross-modal and intra-modal contrastive objectives, providing more reasonable representations for the unified All-in-One transformer backbone. Extensive experiments on five benchmarks, \ie OTB99-L, TNL2K, LaSOT, LaSOT$_{\rm Ext}$ and WebUAV-3M, demonstrate the superiority of the proposed tracker against existing state-of-the-arts on VL tracking. Codes will be made publicly available.
</details>
<details>
<summary>摘要</summary>
当前主流视觉语言（VL）跟踪框架包括三部分：视觉特征提取器、语言特征提取器和 fusions 模型。为了提高性能，常见的VL跟踪方法是采用自定义和更重的单模态编码器，以及多模态融合模型。虽然有效，现有VL跟踪器在特征提取和特征融合之间分离，导致提取出的特征缺乏 semantic 指导和具有有限的目标意识能力在复杂情况下，例如类似干扰和极端照明。在这种工作中，我们Draw inspiration from the recent success of exploring foundation models with unified architecture for both natural language and computer vision tasks，我们提出了一个All-in-One框架，该框架通过采用统一的 transformer 脊梁学习联合特征提取和交互。具体来说，我们将原始视觉和语言信号混合生成语言注入视觉 токен，然后将这些 токен concatenate 在统一脊梁架构中。这种方法实现了特征融合在统一脊梁中，从而废弃了需要 precisely 设计融合模块，并且导致更有效和高效的VL跟踪框架。为了进一步提高学习效率，我们引入了基于交叉模式和内部对比目标的多模态匹配模块，为统一 All-in-One transformer 脊梁提供更合理的表示。广泛的实验在五个标准测试集，即 OTB99-L、TNL2K、LaSOT、LaSOT$_{\rm Ext}$ 和 WebUAV-3M 上，证明我们的跟踪器在VL跟踪中超过现有状况。代码将公开。
</details></li>
</ul>
<hr>
<h2 id="Adaptation-and-Communication-in-Human-Robot-Teaming-to-Handle-Discrepancies-in-Agents’-Beliefs-about-Plans"><a href="#Adaptation-and-Communication-in-Human-Robot-Teaming-to-Handle-Discrepancies-in-Agents’-Beliefs-about-Plans" class="headerlink" title="Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies in Agents’ Beliefs about Plans"></a>Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies in Agents’ Beliefs about Plans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03362">http://arxiv.org/abs/2307.03362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuening Zhang, Brian C. Williams</li>
<li>for: 本研究旨在解决人机团队中agent之间不具备共同认知的问题，即agent可能遵循不同的习惯或只有一些agent知道的可能性。</li>
<li>methods: 本研究使用epistemic逻辑来帮助agent理解对方的信念不同，并动态计划行动以适应或通信以解决这些不同。</li>
<li>results: 我们的研究表明，使用我们提出的方法可以提高人机团队的成功率和扩展性，而不需要共同认知。<details>
<summary>Abstract</summary>
When agents collaborate on a task, it is important that they have some shared mental model of the task routines -- the set of feasible plans towards achieving the goals. However, in reality, situations often arise that such a shared mental model cannot be guaranteed, such as in ad-hoc teams where agents may follow different conventions or when contingent constraints arise that only some agents are aware of. Previous work on human-robot teaming has assumed that the team has a set of shared routines, which breaks down in these situations. In this work, we leverage epistemic logic to enable agents to understand the discrepancy in each other's beliefs about feasible plans and dynamically plan their actions to adapt or communicate to resolve the discrepancy. We propose a formalism that extends conditional doxastic logic to describe knowledge bases in order to explicitly represent agents' nested beliefs on the feasible plans and state of execution. We provide an online execution algorithm based on Monte Carlo Tree Search for the agent to plan its action, including communication actions to explain the feasibility of plans, announce intent, and ask questions. Finally, we evaluate the success rate and scalability of the algorithm and show that our agent is better equipped to work in teams without the guarantee of a shared mental model.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:当机器人合作完成任务时，重要的是他们有一个共享的心理模型，即任务routines的可行方案集。然而，在现实中，情况经常出现无法保证这种共享心理模型的情况，例如在协作团队中机器人可能遵循不同的 Convention或者在特殊的情况下存在只有一些机器人知道的隐式约束。过去的人机合作工作假设了团队有一组共享的routines，这会导致问题。在这种情况下，我们利用epistemic逻辑来让机器人理解对方可能的信念不同，并在运行时动态规划行动，以适应或通信解决这些不同。我们提出了一种基于 conditional doxastic逻辑的形式来描述知识库，以显式地表示机器人嵌套的信念结构。我们提供了基于Monte Carlo Tree Search的在线执行算法，让机器人在执行时计划行动，包括通信行动来解释计划的可行性、宣布意图和提问。最后，我们评估了算法的成功率和可扩展性，并显示我们的机器人在不假设共享心理模型的情况下更能够合作。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Biased-Attitude-Associations-of-Language-Models-in-an-Intersectional-Context"><a href="#Evaluating-Biased-Attitude-Associations-of-Language-Models-in-an-Intersectional-Context" class="headerlink" title="Evaluating Biased Attitude Associations of Language Models in an Intersectional Context"></a>Evaluating Biased Attitude Associations of Language Models in an Intersectional Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03360">http://arxiv.org/abs/2307.03360</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shivaomrani/llm-bias">https://github.com/shivaomrani/llm-bias</a></li>
<li>paper_authors: Shiva Omrani Sabbaghi, Robert Wolfe, Aylin Caliskan</li>
<li>for: 这个论文旨在研究英语语言模型中各种社会群体的偏见。</li>
<li>methods: 研究使用了一种句子模板，以提供多元化的社会背景，以评估语言模型中各种社会群体的偏见。</li>
<li>results: 研究发现，语言模型对性别认同、社会阶层和性 orientation等社会群体的偏见最为明显。此外，研究还发现，最大和最高性能的语言模型也是最偏见的。<details>
<summary>Abstract</summary>
Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model that we study is also more biased as it effectively captures bias embedded in sociocultural data. We validate the bias evaluation method by overperforming on an intrinsic valence evaluation task. The approach enables us to measure complex intersectional biases as they are known to manifest in the outputs and applications of language models that perpetuate historical biases. Moreover, our approach contributes to design justice as it studies the associations of groups underrepresented in language such as transgender and homosexual individuals.
</details>
<details>
<summary>摘要</summary>
Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model that we study is also more biased as it effectively captures bias embedded in sociocultural data. We validate the bias evaluation method by overperforming on an intrinsic valence evaluation task. The approach enables us to measure complex intersectional biases as they are known to manifest in the outputs and applications of language models that perpetuate historical biases. Moreover, our approach contributes to design justice as it studies the associations of groups underrepresented in language such as transgender and homosexual individuals.Here's the translation in Traditional Chinese:语模型是根据大规模数据库进行训练，这些数据库中嵌入了心理学中documented的隐式偏见。在社交认知中，社会群体的态度偏好（愉悦度/不愉悦度）determine the biased attitudes towards groups and concepts。根据已有的文献，我们量化英语语模型中社会群体的valence association。我们研究年龄、教育、性别、身高、智商、文化程度、种族、宗教、性别、性向、社会阶层和身高等社会群体的偏见。我们使用 sentence template 提供的交叉sectional context，以 capture the valence subspace through contextualized word embeddings of language models。我们运用对嵌入偏见的方法，以量化语模型对于性别识别、社会阶层和性向信号的偏见。我们发现，Language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language。我们还发现，我们研究的最大和最好的模型也是最偏见的，因为它很好地捕捉了社会文化资料中的偏见。我们验证了偏见评估方法的正确性，通过在内在愉悦评估任务中进行过 performs。这种方法可以量化复杂的交叉偏见，并且对于历史偏见的延续而言，我们的方法具有设计正义的功能，因为它研究了语言中underrepresented的群体，如 трансGENDER和同性恋者。
</details></li>
</ul>
<hr>
<h2 id="TRAC-Trustworthy-Retrieval-Augmented-Chatbot"><a href="#TRAC-Trustworthy-Retrieval-Augmented-Chatbot" class="headerlink" title="TRAC: Trustworthy Retrieval Augmented Chatbot"></a>TRAC: Trustworthy Retrieval Augmented Chatbot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04642">http://arxiv.org/abs/2307.04642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuo Li, Sangdon Park, Insup Lee, Osbert Bastani</li>
<li>for: 提高问答系统的准确性和可靠性</li>
<li>methods: 组合强制预测和全球测试来提供统计保证，并使用泊利投 optimize 选择全球测试的 гипер参数以最大化系统性能</li>
<li>results: 在 Natural Questions 数据集上实验表明，我们的方法可以提供预期的覆盖保证，同时最小化平均预测集大小<details>
<summary>Abstract</summary>
Although conversational AIs have demonstrated fantastic performance, they often generate incorrect information, or hallucinations. Retrieval augmented generation has emerged as a promising solution to reduce these hallucinations. However, these techniques still cannot guarantee correctness. Focusing on question answering, we propose a framework that can provide statistical guarantees for the retrieval augmented question answering system by combining conformal prediction and global testing. In addition, we use Bayesian optimization to choose hyperparameters of the global test to maximize the performance of the system. Our empirical results on the Natural Questions dataset demonstrate that our method can provide the desired coverage guarantee while minimizing the average prediction set size.
</details>
<details>
<summary>摘要</summary>
Note:* "hallucinations" in the original text is translated as " incorrect information" in Simplified Chinese, as "hallucinations" is not a commonly used term in Chinese.* "retrieval augmented generation" is translated as " Retrieval 增强生成" in Simplified Chinese, as "augmented" is not a commonly used term in Chinese.* "conformal prediction" is translated as "准确预测" in Simplified Chinese, as "conformal" is not a commonly used term in Chinese.* "global testing" is translated as "全球测试" in Simplified Chinese, as "global" is not a commonly used term in Chinese.* "average prediction set size" is translated as "平均预测集大小" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-over-a-Wireless-Network-Distributed-User-Selection-through-Random-Access"><a href="#Federated-Learning-over-a-Wireless-Network-Distributed-User-Selection-through-Random-Access" class="headerlink" title="Federated Learning over a Wireless Network: Distributed User Selection through Random Access"></a>Federated Learning over a Wireless Network: Distributed User Selection through Random Access</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03758">http://arxiv.org/abs/2307.03758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Sun, Shiyao Ma, Ce Zheng, Songtao Wu, Tao Cui, Lingjuan Lyu</li>
<li>for: 降低联合学习（Federated Learning）在无线网络上的通信成本。</li>
<li>methods: 使用网络内置的分布式用户选择方法，利用无线资源竞争机制。</li>
<li>results: 可以快速达到与中央用户选择方法相似的快速协调。<details>
<summary>Abstract</summary>
User selection has become crucial for decreasing the communication costs of federated learning (FL) over wireless networks. However, centralized user selection causes additional system complexity. This study proposes a network intrinsic approach of distributed user selection that leverages the radio resource competition mechanism in random access. Taking the carrier sensing multiple access (CSMA) mechanism as an example of random access, we manipulate the contention window (CW) size to prioritize certain users for obtaining radio resources in each round of training. Training data bias is used as a target scenario for FL with user selection. Prioritization is based on the distance between the newly trained local model and the global model of the previous round. To avoid excessive contribution by certain users, a counting mechanism is used to ensure fairness. Simulations with various datasets demonstrate that this method can rapidly achieve convergence similar to that of the centralized user selection approach.
</details>
<details>
<summary>摘要</summary>
用户选择已成为联合学习（FL）过无线网络的关键因素，但中央用户选择会增加系统复杂性。这项研究提出了基于网络内置的分布式用户选择方法，利用无线资源竞争机制。假设CSMA机制为随机访问，我们在每轮训练中 manipulate 竞争窗口（CW）大小，以优先给予certain用户 radio资源。使用训练数据偏见为FL用户选择目标场景。偏见基于上一轮训练的全球模型与当前轮训练的本地模型之间的距离。为避免某些用户的过度贡献，使用计数机制保持公平。通过 simulate 多个数据集，我们发现这种方法可快达到与中央用户选择方法相似的快速启合。
</details></li>
</ul>
<hr>
<h2 id="Assisting-Clinical-Decisions-for-Scarcely-Available-Treatment-via-Disentangled-Latent-Representation"><a href="#Assisting-Clinical-Decisions-for-Scarcely-Available-Treatment-via-Disentangled-Latent-Representation" class="headerlink" title="Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation"></a>Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03315">http://arxiv.org/abs/2307.03315</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bing Xue, Ahmed Sameh Said, Ziqi Xu, Hanyang Liu, Neel Shah, Hanqing Yang, Philip Payne, Chenyang Lu</li>
<li>for: 这篇论文是为了支持医疗决策而提出的，旨在预测患者是否需要ECMO治疗，以及ECMO治疗后的可能性。</li>
<li>methods: 这篇论文提出了一种新的方法，即Treatment Variational AutoEncoder（TVAE），用于个性化治疗分析。TVAE模型了患者的治疗决策和可能的结果，并通过重构正则化和半监督来缓解干扰和缺乏治疗案例的问题。</li>
<li>results: 实验结果表明，TVAE在具有多样化COVID-19患者数据集上比州当前的治疗效果模型更高效，可以预测患者的可能性和实际结果。<details>
<summary>Abstract</summary>
Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be represented by a deep latent variable model. The factual and counterfactual prediction errors are alleviated via a reconstruction regularization scheme together with semi-supervision, and the selection bias and the scarcity of treatment cases are mitigated by the disentangled and distribution-matched latent space and the label-balancing generative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an international dataset collected from 1651 hospitals across 63 countries, and a institutional dataset collected from 15 hospitals. The results show that TVAE outperforms state-of-the-art treatment effect models in predicting both the propensity scores and factual outcomes on heterogeneous COVID-19 datasets. Additional experiments also show TVAE outperforms the best existing models in individual treatment effect estimation on the synthesized IHDP benchmark dataset.
</details>
<details>
<summary>摘要</summary>
《 экстракорпоральная мембрананой оксигенация (ЭКМО) 是 COVID-19 患者们无法接受常规治疗的关键生命支持 modalities。然而，正确的治疗决策仍然是争议的，尚未确定哪些患者会受益于这种罕见和技术复杂的治疗选择。为支持临床决策，我们需要预测治疗需求和可能的治疗和无治疗响应。针对这种临床挑战，我们提出了 Treatment Variational AutoEncoder (TVAE)，一种新的个性化治疗分析方法。TVAE 特别是为了解决 ECMO 强烈的选择偏见和罕见治疗案例的模型挑战。TVAE 将治疗决策视为多级问题，模型病人的可能的治疗分配和实际和 counterfactual 结果为其内在特征，可以通过深度卷积模型表示。实际和 counterfactual 预测错误被解决通过重建规则和半监督，并且选择偏见和罕见治疗案例被减轻通过分解和分布匹配的积分空间和标签均衡生成策略。我们在两个实际 COVID-19 数据集上评估了 TVAE：一个国际数据集从 1651 家医院 across 63 个国家收集，另一个 institutional 数据集从 15 家医院收集。结果显示，TVAE 在异质 COVID-19 数据集上预测实际分数和 factual 结果的性能较为前者。其他实验也表明 TVAE 在个体治疗效果预测方面超越了现有最佳模型。
</details></li>
</ul>
<hr>
<h2 id="On-Invariance-Equivariance-Correlation-and-Convolution-of-Spherical-Harmonic-Representations-for-Scalar-and-Vectorial-Data"><a href="#On-Invariance-Equivariance-Correlation-and-Convolution-of-Spherical-Harmonic-Representations-for-Scalar-and-Vectorial-Data" class="headerlink" title="On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data"></a>On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03311">http://arxiv.org/abs/2307.03311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Janis Keuper</li>
<li>for: 本论文主要针对Machine Learning领域中圆形卷积（Spherical Harmonic，SH）表示的数学表述，尤其是对于旋转不变和对称的特征和卷积。</li>
<li>methods: 本论文提出了SH表示的理论基础和实践方法，包括旋转不变和对称特征和卷积，以及将scalar SH表示扩展到vector field on sphere上的VH表示。</li>
<li>results: 本论文summarizes the works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres, and extends these methods to 3d vector fields on spheres.<details>
<summary>Abstract</summary>
The mathematical representations of data in the Spherical Harmonic (SH) domain has recently regained increasing interest in the machine learning community. This technical report gives an in-depth introduction to the theoretical foundation and practical implementation of SH representations, summarizing works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres. In extension, these methods are then generalized from scalar SH representations to Vectorial Harmonics (VH), providing the same capabilities for 3d vector fields on spheres
</details>
<details>
<summary>摘要</summary>
Recently, the mathematical representations of data in the Spherical Harmonic (SH) domain have gained increasing interest in the machine learning community. This technical report provides an in-depth introduction to the theoretical foundation and practical implementation of SH representations, including works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres. Additionally, these methods are then generalized from scalar SH representations to Vectorial Harmonics (VH), allowing for 3D vector fields on spheres to have the same capabilities.Here's the word-for-word translation of the text into Simplified Chinese:近期，圆形哈密顿（SH）领域中数据的数学表示受到机器学习社区的越来越多的关注。本技术报告对SH表示的理论基础和实践进行了深入的介绍，包括对旋转不变和对称特征的研究，以及圆形上的信号卷积和精确相关性。此外，这些方法还被推广到 vectorial harmonics（VH）中，以便三维向量场在圆形上具有相同的能力。
</details></li>
</ul>
<hr>
<h2 id="S2vNTM-Semi-supervised-vMF-Neural-Topic-Modeling"><a href="#S2vNTM-Semi-supervised-vMF-Neural-Topic-Modeling" class="headerlink" title="S2vNTM: Semi-supervised vMF Neural Topic Modeling"></a>S2vNTM: Semi-supervised vMF Neural Topic Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04804">http://arxiv.org/abs/2307.04804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Xu, Jay Desai, Srinivasan Sengamedu, Xiaoyu Jiang, Francis Iannacci</li>
<li>for: 本研究旨在批处文本分类 зада务中提高效率和准确率，并允许使用少量关键词作为输入。</li>
<li>methods: 本研究提出了一种名为Semi-Supervised vMF Neural Topic Modeling（S2vNTM）的方法，它利用种子关键词来初始化主题，并通过关键词的模式来识别和优化主题的关键词集。</li>
<li>results: 在多个数据集上，S2vNTM的分类精度高于现有的半监督主题模型方法，而且速度至少 twice as fast as baselines。<details>
<summary>Abstract</summary>
Language model based methods are powerful techniques for text classification. However, the models have several shortcomings. (1) It is difficult to integrate human knowledge such as keywords. (2) It needs a lot of resources to train the models. (3) It relied on large text data to pretrain. In this paper, we propose Semi-Supervised vMF Neural Topic Modeling (S2vNTM) to overcome these difficulties. S2vNTM takes a few seed keywords as input for topics. S2vNTM leverages the pattern of keywords to identify potential topics, as well as optimize the quality of topics' keywords sets. Across a variety of datasets, S2vNTM outperforms existing semi-supervised topic modeling methods in classification accuracy with limited keywords provided. S2vNTM is at least twice as fast as baselines.
</details>
<details>
<summary>摘要</summary>
语言模型基本方法是文本分类的强大技术。然而，这些模型有几个缺点。（1）它很难 интегра human knowledge，如关键词。（2）它需要训练模型很多资源。（3）它依赖于大量文本数据进行预训练。在这篇论文中，我们提出了半supervised vMF神经话题模型（S2vNTM）来解决这些困难。S2vNTM通过提供一些种子关键词来输入主题，并利用关键词的模式来确定主题的可能性，以及优化主题的关键词集。在多个数据集上，S2vNTM比现有的半supervised主题模型在分类精度方面表现出色，只需提供有限的关键词。此外，S2vNTM比基准方法快速。
</details></li>
</ul>
<hr>
<h2 id="A-Vulnerability-of-Attribution-Methods-Using-Pre-Softmax-Scores"><a href="#A-Vulnerability-of-Attribution-Methods-Using-Pre-Softmax-Scores" class="headerlink" title="A Vulnerability of Attribution Methods Using Pre-Softmax Scores"></a>A Vulnerability of Attribution Methods Using Pre-Softmax Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03305">http://arxiv.org/abs/2307.03305</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlerma54/adversarial-attacks-on-saliency-maps">https://github.com/mlerma54/adversarial-attacks-on-saliency-maps</a></li>
<li>paper_authors: Miguel Lerma, Mirtha Lucas</li>
<li>for: 本研究探讨了一种类别神经网络输出解释方法的攻击方法。</li>
<li>methods: 本研究使用了小型修改模型来影响解释方法的输出，而不改变模型的输出。</li>
<li>results: 研究发现，这种修改方法可以导致解释方法的输出受到较大的影响，而无需改变模型的输出。<details>
<summary>Abstract</summary>
We discuss a vulnerability involving a category of attribution methods used to provide explanations for the outputs of convolutional neural networks working as classifiers. It is known that this type of networks are vulnerable to adversarial attacks, in which imperceptible perturbations of the input may alter the outputs of the model. In contrast, here we focus on effects that small modifications in the model may cause on the attribution method without altering the model outputs.
</details>
<details>
<summary>摘要</summary>
我们讨论了一种类型的对应方法的漏洞，这种方法用于说明对应网络作为分类器的输出。已经知道这种网络受到了敌对攻击，这些攻击可能导致输入的无法识别的小变化，导致模型的输出变化。相反，我们在这里集中了对应方法的小修改会导致的效果，而不会改变模型的输出。
</details></li>
</ul>
<hr>
<h2 id="It-is-not-Sexually-Suggestive-It-is-Educative-Separating-Sex-Education-from-Suggestive-Content-on-TikTok-Videos"><a href="#It-is-not-Sexually-Suggestive-It-is-Educative-Separating-Sex-Education-from-Suggestive-Content-on-TikTok-Videos" class="headerlink" title="It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos"></a>It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03274">http://arxiv.org/abs/2307.03274</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enfa George, Mihai Surdeanu</li>
<li>for: 本研究目的是为了创建一个多Modal数据集，以便分辨TikTok上的性 suggestive内容和虚拟性教育视频。</li>
<li>methods: 研究使用了TikTok上的视频URL和音频笔录，并采用了两种基于转换器的模型来分类视频。</li>
<li>results: 初步结果表明，分辨这些类型的视频是可学习的，但也是具有挑战性的。这些实验表明，这个数据集是有意义的，并邀请更多研究者来深入研究这个领域。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled as sexually suggestive (from the annotator's point of view), sex-educational content, or neither. Such a dataset is necessary to address the challenge of distinguishing between sexually suggestive content and virtual sex education videos on TikTok. Children's exposure to sexually suggestive videos has been shown to have adversarial effects on their development. Meanwhile, virtual sex education, especially on subjects that are more relevant to the LGBTQIA+ community, is very valuable. The platform's current system removes or penalizes some of both types of videos, even though they serve different purposes. Our dataset contains video URLs, and it is also audio transcribed. To validate its importance, we explore two transformer-based models for classifying the videos. Our preliminary results suggest that the task of distinguishing between these types of videos is learnable but challenging. These experiments suggest that this dataset is meaningful and invites further study on the subject.
</details>
<details>
<summary>摘要</summary>
我们介绍SexTok数据集，这是一个包含TikTok视频被标记为性取向（由注释员看来）、性教育内容或者 neither 的多modal数据集。这样的数据集 необходимо用于解决TikTok上性取向内容和虚拟性教育视频的分类挑战。儿童接触性取向视频会对其发展产生有害影响。然而，虚拟性教育，特别是对LGBTQIA+社群更加重要的主题，对于儿童的性教育很有价值。 платформа当前的系统会将一些这些视频移除或处罚，尽管它们在不同的目的上服务。我们的数据集包含视频 URL，同时也有音频笔记。为验证其重要性，我们探索了两种基于 transformer 模型来分类视频。我们的初步结果表明，这种分类任务可以学习，但也是具有挑战性。这些实验表明，这个数据集是有意义的，并邀请进一步研究这个主题。
</details></li>
</ul>
<hr>
<h2 id="Vision-Language-Transformers-A-Survey"><a href="#Vision-Language-Transformers-A-Survey" class="headerlink" title="Vision Language Transformers: A Survey"></a>Vision Language Transformers: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03254">http://arxiv.org/abs/2307.03254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clayton Fields, Casey Kennington</li>
<li>for: 这个论文主要是为了探讨视Language模型的发展和应用。</li>
<li>methods: 这个论文使用了预训练的transformer架构，并通过将其应用到新任务上，以实现跨视与语言的模型。</li>
<li>results: 这个论文提供了视Language模型的广泛的研究和分析，以及其优点、局限性和未解决的问题。<details>
<summary>Abstract</summary>
Vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform. A relatively recent body of research has adapted the pretrained transformer architecture introduced in \citet{vaswani2017attention} to vision language modeling. Transformer models have greatly improved performance and versatility over previous vision language models. They do so by pretraining models on a large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks which require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strengths, limitations and some open questions that remain.
</details>
<details>
<summary>摘要</summary>
Computer vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform.  Recently, researchers have adapted the pre-trained transformer architecture introduced in vaswani2017attention to vision language modeling, which has greatly improved performance and versatility over previous vision language models. They do so by pre-training models on large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks that require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strengths, limitations, and some open questions that remain.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the standard Mandarin pronunciation and may not be exactly the same as the traditional Chinese used in Taiwan or other regions.
</details></li>
</ul>
<hr>
<h2 id="Learned-Kernels-for-Interpretable-and-Efficient-PPG-Signal-Quality-Assessment-and-Artifact-Segmentation"><a href="#Learned-Kernels-for-Interpretable-and-Efficient-PPG-Signal-Quality-Assessment-and-Artifact-Segmentation" class="headerlink" title="Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation"></a>Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05385">http://arxiv.org/abs/2307.05385</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sully F. Chen, Zhicheng Guo, Cheng Ding, Xiao Hu, Cynthia Rudin</li>
<li>for: 本研究旨在提出一种可靠、有效、可解释的脉冲光谱学（PPG）信号质量评估和artefact分割方法，以提高PPG信号的精度和可靠性。</li>
<li>methods: 本研究使用了一种小型、可解释的卷积核来学习PPG信号中的质量特征，并与现有的深度神经网络（DNN）方法进行比较。</li>
<li>results: 研究结果表明，该小型卷积核方法可以与DNN方法相比，具有类似或更好的性能，同时具有许多个数据点的优势，如快速、可靠、可解释。<details>
<summary>Abstract</summary>
Photoplethysmography (PPG) provides a low-cost, non-invasive method to continuously monitor various cardiovascular parameters. PPG signals are generated by wearable devices and frequently contain large artifacts caused by external factors, such as motion of the human subject. In order to ensure robust and accurate extraction of physiological parameters, corrupted areas of the signal need to be identified and handled appropriately. Previous methodology relied either on handcrafted feature detectors or signal metrics which yield sub-optimal performance, or relied on machine learning techniques such as deep neural networks (DNN) which lack interpretability and are computationally and memory intensive. In this work, we present a novel method to learn a small set of interpretable convolutional kernels that has performance similar to -- and often better than -- the state-of-the-art DNN approach with several orders of magnitude fewer parameters. This work allows for efficient, robust, and interpretable signal quality assessment and artifact segmentation on low-power devices.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Push-Past-Green-Learning-to-Look-Behind-Plant-Foliage-by-Moving-It"><a href="#Push-Past-Green-Learning-to-Look-Behind-Plant-Foliage-by-Moving-It" class="headerlink" title="Push Past Green: Learning to Look Behind Plant Foliage by Moving It"></a>Push Past Green: Learning to Look Behind Plant Foliage by Moving It</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03175">http://arxiv.org/abs/2307.03175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Zhang, Saurabh Gupta</li>
<li>for: 这个论文旨在提出数据驱动的方法，用于自动化农业应用程序（如检查、评估、摘取水果）中 manipulating 植物叶子和枝干以查看后方空间。</li>
<li>methods: 这篇论文使用自我超级vision方法进行训练，使用SRPNet神经网络预测执行候选动作后可以查看的空间。</li>
<li>results: 实验表明，对于 synthetic 蔷薇和实际的 драцена植物，PPG方法在5个设定下表现出色，而SRPNet神经网络在5个设定下都超过了手动设计的探索方法和相关的ablations。<details>
<summary>Abstract</summary>
Autonomous agriculture applications (e.g., inspection, phenotyping, plucking fruits) require manipulating the plant foliage to look behind the leaves and the branches. Partial visibility, extreme clutter, thin structures, and unknown geometry and dynamics for plants make such manipulation challenging. We tackle these challenges through data-driven methods. We use self-supervision to train SRPNet, a neural network that predicts what space is revealed on execution of a candidate action on a given plant. We use SRPNet with the cross-entropy method to predict actions that are effective at revealing space beneath plant foliage. Furthermore, as SRPNet does not just predict how much space is revealed but also where it is revealed, we can execute a sequence of actions that incrementally reveal more and more space beneath the plant foliage. We experiment with a synthetic (vines) and a real plant (Dracaena) on a physical test-bed across 5 settings including 2 settings that test generalization to novel plant configurations. Our experiments reveal the effectiveness of our overall method, PPG, over a competitive hand-crafted exploration method, and the effectiveness of SRPNet over a hand-crafted dynamics model and relevant ablations.
</details>
<details>
<summary>摘要</summary>
自主农业应用（如检查、辐射类型、摘果）需要操作植物叶子和枝干，以便从后方看到叶子和枝干。但是叶子和枝干之间的部分可见性、极度拥挤、薄肉和植物的不确定geometry和动力学使得这种操作变得困难。我们通过数据驱动方法解决这些挑战。我们使用自我监督来训练SRPNet，一个神经网络，该网络预测执行给定植物的候选动作后可见的空间。我们使用SRPNet与十字积分法预测有效的动作，以便逐步揭示植物下方的空间。此外，SRPNet不仅预测执行动作后可见的空间量，还预测其在哪里被揭示，因此我们可以执行一系列的动作，以逐步揭示更多的植物下方的空间。我们在一个 sintetic（葡萄）和一个实际的植物（ драцена）上进行了在物理测试床上的实验，并在5个设定中测试了我们的总方法，包括2个设定，以测试扩展到新的植物配置。我们的实验表明我们的总方法PPG在比手工探索方法更有效，而SRPNet在手工动力学模型和相关的ablations中也表现出了效果。
</details></li>
</ul>
<hr>
<h2 id="LEO-Learning-Efficient-Orderings-for-Multiobjective-Binary-Decision-Diagrams"><a href="#LEO-Learning-Efficient-Orderings-for-Multiobjective-Binary-Decision-Diagrams" class="headerlink" title="LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams"></a>LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03171">http://arxiv.org/abs/2307.03171</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/khalil-research/leo">https://github.com/khalil-research/leo</a></li>
<li>paper_authors: Rahul Patel, Elias B. Khalil</li>
<li>for: 这个研究是为了解决多对象数据分析问题中的问题，特别是用BDDs来解决这些问题。</li>
<li>methods: 这个研究使用了BDDs来解决多对象数据分析问题，并且使用了一些新的变量排序方法来提高BDDs的效率和精度。</li>
<li>results: 研究发现，使用LEO这个超级vised学习方法可以快速地找到高效的变量排序方法，并且可以将PF枚举时间缩短。实验结果显示，LEO比常用的排序方法和算法配置更快速地完成PF枚举。<details>
<summary>Abstract</summary>
Approaches based on Binary decision diagrams (BDDs) have recently achieved state-of-the-art results for multiobjective integer programming problems. The variable ordering used in constructing BDDs can have a significant impact on their size and on the quality of bounds derived from relaxed or restricted BDDs for single-objective optimization problems. We first showcase a similar impact of variable ordering on the Pareto frontier (PF) enumeration time for the multiobjective knapsack problem, suggesting the need for deriving variable ordering methods that improve the scalability of the multiobjective BDD approach. To that end, we derive a novel parameter configuration space based on variable scoring functions which are linear in a small set of interpretable and easy-to-compute variable features. We show how the configuration space can be efficiently explored using black-box optimization, circumventing the curse of dimensionality (in the number of variables and objectives), and finding good orderings that reduce the PF enumeration time. However, black-box optimization approaches incur a computational overhead that outweighs the reduction in time due to good variable ordering. To alleviate this issue, we propose LEO, a supervised learning approach for finding efficient variable orderings that reduce the enumeration time. Experiments on benchmark sets from the knapsack problem with 3-7 objectives and up to 80 variables show that LEO is ~30-300% and ~10-200% faster at PF enumeration than common ordering strategies and algorithm configuration. Our code and instances are available at https://github.com/khalil-research/leo.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用二进制决策图（BDD）的方法最近在多目标整数编程问题上实现了状态的杰出成绩。BDD中变量的排序可以影响其大小和含约环境中的缓和约束的质量。我们首先示出变量排序对多目标饶褔问题的Pareto前列（PF）枚举时间有着相似的影响。这表明需要开发可以提高多目标BDD方法的可扩展性的变量排序方法。为此，我们 derivate一个基于变量评价函数的新参数配置空间，该空间是线性的，且可以使用一小组简单易计算的变量特征来实现。我们表明该配置空间可以使用黑盒优化器高效地探索，并且可以快速找到好的排序，从而减少PF枚举时间。然而，黑盒优化器的计算开销会超过减少PF枚举时间的好变量排序的效果。为了解决这个问题，我们提出了LEO，一种监督学习方法，用于找到高效的变量排序，从而减少PF枚举时间。我们的实验结果表明，LEO比普通的排序策略和算法配置更快，在饶褔问题的 benchmark 集中，LEO的速度比Common ordering strategies和algorithm configuration快约30-300%和10-200%。我们的代码和实例可以在https://github.com/khalil-research/leo上获取。
</details></li>
</ul>
<hr>
<h2 id="Focused-Transformer-Contrastive-Training-for-Context-Scaling"><a href="#Focused-Transformer-Contrastive-Training-for-Context-Scaling" class="headerlink" title="Focused Transformer: Contrastive Training for Context Scaling"></a>Focused Transformer: Contrastive Training for Context Scaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03170">http://arxiv.org/abs/2307.03170</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cstankonrad/long_llama">https://github.com/cstankonrad/long_llama</a></li>
<li>paper_authors: Szymon Tworkowski, Konrad Staniszewski, Mikołaj Pacek, Yuhuai Wu, Henryk Michalewski, Piotr Miłoś</li>
<li>for: 提高大型语言模型在长 context 下的表现</li>
<li>methods: 通过对注意层进行修改，让其可以访问外部存储，并通过对应的键值对进行映射，提高模型的表现</li>
<li>results: 通过提出 Focused Transformer (FoT) 技术，可以延长效 context 的长度，并且可以细化现有大规模模型，以提高其在长 context 下的表现，并且在 passkey 检索任务中，模型可以 успеreich 处理 $256 k$ 长 context。<details>
<summary>Abstract</summary>
Large language models have an exceptional capability to incorporate new information in a contextual manner. However, the full potential of such an approach is often restrained due to a limitation in the effective context length. One solution to this issue is to endow an attention layer with access to an external memory, which comprises of (key, value) pairs. Yet, as the number of documents increases, the proportion of relevant keys to irrelevant ones decreases, leading the model to focus more on the irrelevant keys. We identify a significant challenge, dubbed the distraction issue, where keys linked to different semantic values might overlap, making them hard to distinguish. To tackle this problem, we introduce the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning. This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length. Our method allows for fine-tuning pre-existing, large-scale models to lengthen their effective context. This is demonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The resulting models, which we name LongLLaMA, exhibit advancements in tasks requiring a long context. We further illustrate that our LongLLaMA models adeptly manage a $256 k$ context length for passkey retrieval.
</details>
<details>
<summary>摘要</summary>
大型语言模型具有卓越的Contextualized Embedding能力，可以将新信息给适当地融入到模型中。然而，这种方法的潜力经常受到Context Length的限制。为了解决这个问题，我们将Attention层给了External Memory的存取权，这个External Memory包含了(键、值)对。然而，当文档数量增加时，相关的键数量减少，使模型更加倾向于关注无关的键。我们称这个问题为分心问题，因为不同的Semantic Value之间的键可能会 overlap，使其困难分辨。为了解决这个问题，我们引入了Focused Transformer（FoT）技术，这是一种以Contrastive Learning为灵感的训练过程。这种新的方法可以将(键、值)空间的结构改善，从而延长Context Length。我们的方法可以让已有的大规模模型进行微调，以增加其有效Context Length。我们给了$3B$和$7B$ OpenLLaMA检查点进行微调，将其称为LongLLaMA。这些LongLLaMA模型在需要长Context的任务中表现出色。我们还证明了LongLLaMA模型可以efficaciously manage $256 k$ Context Length for passkey retrieval。
</details></li>
</ul>
<hr>
<h2 id="BrickPal-Augmented-Reality-based-Assembly-Instructions-for-Brick-Models"><a href="#BrickPal-Augmented-Reality-based-Assembly-Instructions-for-Brick-Models" class="headerlink" title="BrickPal: Augmented Reality-based Assembly Instructions for Brick Models"></a>BrickPal: Augmented Reality-based Assembly Instructions for Brick Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03162">http://arxiv.org/abs/2307.03162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Shi, Xiaofeng Zhang, Ran zhang, Zhou Yang, Xiao Tang, Hongni Ye, Yi Wu</li>
<li>for: 帮助用户更加快速和精准地组装乐高积木，解决传统手动微调和纸质指南的问题。</li>
<li>methods: 利用可见语言处理（NLP）技术生成可能的组装序列，并在扩展现实头戴显示器提供实时指导。</li>
<li>results: 比传统组装方法更高效，NLP算法生成的组装序列可以达到同样的可用性。<details>
<summary>Abstract</summary>
The assembly instruction is a mandatory component of Lego-like brick sets.The conventional production of assembly instructions requires a considerable amount of manual fine-tuning, which is intractable for casual users and customized brick sets.Moreover, the traditional paper-based instructions lack expressiveness and interactivity.To tackle the two problems above, we present BrickPal, an augmented reality-based system, which visualizes assembly instructions in an augmented reality head-mounted display. It utilizes Natural Language Processing (NLP) techniques to generate plausible assembly sequences, and provide real-time guidance in the AR headset.Our user study demonstrates BrickPal's effectiveness at assisting users in brick assembly compared to traditional assembly methods. Additionally, the NLP algorithm-generated assembly sequences achieve the same usability with manually adapted sequences.
</details>
<details>
<summary>摘要</summary>
assembly instruction是乐高类积木sets中必备的一部分。传统生产assembly instruction需要较多的手动精度调整，这对普通用户和自定义积木sets来说是不可接受的。此外，传统的纸面指令缺乏表达力和互动性。为解决这两个问题，我们提出了BrickPal，一种基于扩展现实技术的系统，可以在扩展现实头戴display中可见化 assembly instruction。它利用自然语言处理（NLP）技术生成可能的积木组合序列，并在AR头戴display中提供实时指导。我们的用户研究表明，BrickPal可以较传统Assembly方法更好地帮助用户组装积木。此外，由NLP算法生成的积木组合序列与手动修改后的序列之间没有差异。
</details></li>
</ul>
<hr>
<h2 id="Distilling-Large-Vision-Language-Model-with-Out-of-Distribution-Generalizability"><a href="#Distilling-Large-Vision-Language-Model-with-Out-of-Distribution-Generalizability" class="headerlink" title="Distilling Large Vision-Language Model with Out-of-Distribution Generalizability"></a>Distilling Large Vision-Language Model with Out-of-Distribution Generalizability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03135">http://arxiv.org/abs/2307.03135</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuanlinli17/large_vlm_distillation_ood">https://github.com/xuanlinli17/large_vlm_distillation_ood</a></li>
<li>paper_authors: Xuanlin Li, Yunhao Fang, Minghua Liu, Zhan Ling, Zhuowen Tu, Hao Su</li>
<li>for: 这个研究的目的是将大型描述语言模型转换为轻量级快速模型，以便在有限的资源和时间上实现实际的应用。</li>
<li>methods: 这个研究使用了教师模型的描述语言表示空间内的学习，并将其转换为学生模型。它还提出了两个原则来增强学生的开 vocabulary out-of-distribution（OOD）泛化性：一是更好地模仿教师的描述语言表示空间，并谨慎地增强视语联系的一致性; 二是增强教师的语言表示具有有用和细部的Semantic Attribute，以便更好地区别不同的标签。</li>
<li>results: 这个研究的结果显示，使用了提出的方法可以实现零shot和几shot学生模型在开 vocabulary OOD分类任务中的显著改善，这说明了我们的提出的方法的有效性。<details>
<summary>Abstract</summary>
Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a small- or mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enriching the teacher's language representations with informative and finegrained semantic attributes to effectively distinguish between different labels. We propose several metrics and conduct extensive experiments to investigate their techniques. The results demonstrate significant improvements in zero-shot and few-shot student performance on open-vocabulary out-of-distribution classification, highlighting the effectiveness of our proposed approaches. Code released at https://github.com/xuanlinli17/large_vlm_distillation_ood
</details>
<details>
<summary>摘要</summary>
大型视语模型已经实现出色的表现，但它们的大小和计算需求使其在有限的设备和时间上不太实用。模型缩小，将大型模型转换成更小、更快的模型，以保持其性能的方向是一个有前途的方向。这篇论文研究了将大教师视语模型中的视觉表示压缩到小学生模型中，使用小规模或中规模的数据集。尤其是这种研究强调了开放词汇 OUT-OF-DISTRIBUTION（OOD）泛化，这是之前的模型缩小文献中尚未得到足够的关注。我们提出了两个原则，一是在视觉表示空间上更好地模仿大教师，二是在视语对应上更加精细地协调大教师的语言表示。我们还提出了多个指标，并进行了广泛的实验来调查这些技术的效果。结果表明，我们的提议方法可以在零shot和几shot情况下提高小学生模型的OOD泛化性能，这证明了我们的方法的有效性。代码可以在https://github.com/xuanlinli17/large_vlm_distillation_ood上下载。
</details></li>
</ul>
<hr>
<h2 id="Frontier-AI-Regulation-Managing-Emerging-Risks-to-Public-Safety"><a href="#Frontier-AI-Regulation-Managing-Emerging-Risks-to-Public-Safety" class="headerlink" title="Frontier AI Regulation: Managing Emerging Risks to Public Safety"></a>Frontier AI Regulation: Managing Emerging Risks to Public Safety</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03718">http://arxiv.org/abs/2307.03718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Markus Anderljung, Joslyn Barnhart, Anton Korinek, Jade Leung, Cullen O’Keefe, Jess Whittlestone, Shahar Avin, Miles Brundage, Justin Bullock, Duncan Cass-Beggs, Ben Chang, Tantum Collins, Tim Fist, Gillian Hadfield, Alan Hayes, Lewis Ho, Sara Hooker, Eric Horvitz, Noam Kolt, Jonas Schuett, Yonadav Shavit, Divya Siddarth, Robert Trager, Kevin Wolf<br>for:这篇论文关注于所谓的”前沿AI”模型，即具有危险能力的基础模型，可能会对公共安全造成严重威胁。这类模型的管理带来了新的挑战，包括：不可预期的危险能力出现，难以防止已经部署的模型被违用，以及模型能力的普及。methods:作者提出了三个建议来管理前沿AI模型的开发和部署：（1）为前沿AI开发者设置标准，（2）要求开发者登记和报送相关信息，以便让监管部门有visibility into前沿AI开发过程，（3）确保模型的开发和部署符合安全标准。results:作者认为，互联网产业自律管理是重要的首先步骤，但是更广泛的社会讨论和政府干预将是必要的，以创建标准并确保其遵守。他们还提出了一些选择，包括授予监管机构执法权和前沿AI模型的执照制度。最后，作者提出了一些安全标准，包括在部署之前进行风险评估，外部审查模型行为，根据风险评估决定部署，以及在部署后监测和应对新的模型能力和用途信息。<details>
<summary>Abstract</summary>
Advanced AI models hold the promise of tremendous benefits for humanity, but society needs to proactively manage the accompanying risks. In this paper, we focus on what we term "frontier AI" models: highly capable foundation models that could possess dangerous capabilities sufficient to pose severe risks to public safety. Frontier AI models pose a distinct regulatory challenge: dangerous capabilities can arise unexpectedly; it is difficult to robustly prevent a deployed model from being misused; and, it is difficult to stop a model's capabilities from proliferating broadly. To address these challenges, at least three building blocks for the regulation of frontier models are needed: (1) standard-setting processes to identify appropriate requirements for frontier AI developers, (2) registration and reporting requirements to provide regulators with visibility into frontier AI development processes, and (3) mechanisms to ensure compliance with safety standards for the development and deployment of frontier AI models. Industry self-regulation is an important first step. However, wider societal discussions and government intervention will be needed to create standards and to ensure compliance with them. We consider several options to this end, including granting enforcement powers to supervisory authorities and licensure regimes for frontier AI models. Finally, we propose an initial set of safety standards. These include conducting pre-deployment risk assessments; external scrutiny of model behavior; using risk assessments to inform deployment decisions; and monitoring and responding to new information about model capabilities and uses post-deployment. We hope this discussion contributes to the broader conversation on how to balance public safety risks and innovation benefits from advances at the frontier of AI development.
</details>
<details>
<summary>摘要</summary>
高度智能化模型具有巨大的社会价值，但社会需要积极管理这些模型的风险。在这篇论文中，我们关注于我们称为“前沿AI”模型：高度可能的基础模型，它们可能具有严重危害公共安全的能力。前沿AI模型提出了一系列挑战：危险能力可能会不料出现；不可预料地使用已经部署的模型；模型的能力很难控制。为了解决这些挑战，至少需要三种建筑物来规范前沿AI模型的发展：（1）为前沿AI开发者设置标准；（2）要求开发者注册并报告Frontier AI的开发进度；（3）确保Frontier AI模型的安全标准的实施和部署。互联网自律管理是重要的首先步骤，但社会讨论和政府干预将是必要的，以创建标准并确保遵从其中。我们考虑了许多选项，包括授权监管机构执法权和Frontier AI模型的许可证制度。最后，我们提出了一组安全标准，包括在部署之前进行风险评估；对模型行为进行外部审查；使用风险评估来决定部署的决策；以及在部署后监测和回应新的模型能力和使用信息。我们希望这篇论文能够贡献到AI技术的前沿发展中公共安全风险和创新奖励之间的平衡。
</details></li>
</ul>
<hr>
<h2 id="Learning-Multi-Agent-Intention-Aware-Communication-for-Optimal-Multi-Order-Execution-in-Finance"><a href="#Learning-Multi-Agent-Intention-Aware-Communication-for-Optimal-Multi-Order-Execution-in-Finance" class="headerlink" title="Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance"></a>Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03119">http://arxiv.org/abs/2307.03119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuchen Fang, Zhenggang Tang, Kan Ren, Weiqing Liu, Li Zhao, Jiang Bian, Dongsheng Li, Weinan Zhang, Yong Yu, Tie-Yan Liu</li>
<li>for: 本研究的目的是提出一种基于多智能体学习（MARL）的多订单执行方法，以优化股票交易的执行效率。</li>
<li>methods: 本研究使用了模型自适应学习（RL）方法，并在多智能体学习（MARL）框架下进行了优化。在实际市场数据上进行了实验，并通过学习多轮通信协议来提高协作效果。</li>
<li>results: 实验结果显示，使用本研究的方法可以在股票交易中提高执行效率，并且与传统的单个订单执行方法相比，具有更好的协作效果。<details>
<summary>Abstract</summary>
Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets. Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem. However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias. In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints. Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits. Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial market. To improve collaboration, we then propose a learnable multi-round communication protocol, for the agents communicating the intended actions with each other and refining accordingly. It is optimized through a novel action value attribution method which is provably consistent with the original learning objective yet more efficient. The experiments on the data from two real-world markets have illustrated superior performance with significantly better collaboration effectiveness achieved by our method.
</details>
<details>
<summary>摘要</summary>
执行订单是金融科学中的基本任务，旨在完成购买或售卖特定资产的交易订单。现代无模型学习（RL）技术提供了一种数据驱动的解决方案，但现有的工作都是优化单个订单的执行，忽略了实际情况下多个订单同时执行的现象，从而导致优化不足和偏见。在本文中，我们首先提出了多个代理RL（MARL）方法，用于多订单执行，考虑到实际约束。具体来说，我们对每个代理视为一个个人操作者，负责交易一个特定的订单，同时与别的代理进行交流和合作，以最大化总收益。但现有的MARL算法通常通过交换只有各自部分观察信息来进行交流，这在复杂的金融市场中是不具有效果的。为了提高协作，我们 THEN propose了一种可学习的多轮交流协议，用于代理之间交换意图动作，并根据此进行修改。它是通过一种新的动作价值评估方法来优化的，该方法是原始学习目标的可靠的延展。实验结果表明，我们的方法在两个实际市场的数据上显示出了显著性的提高，并 achieves 更好的协作效果。
</details></li>
</ul>
<hr>
<h2 id="Region-Wise-Attentive-Multi-View-Representation-Learning-for-Urban-Region-Embeddings"><a href="#Region-Wise-Attentive-Multi-View-Representation-Learning-for-Urban-Region-Embeddings" class="headerlink" title="Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings"></a>Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03212">http://arxiv.org/abs/2307.03212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiliang Chan, Qianqian Ren</li>
<li>for: 这篇论文旨在 Addressing the challenges of urban region embedding by proposing a Region-Wise Multi-View Representation Learning (ROMER) model.</li>
<li>methods: 该模型使用多视角相关性 capture 和全球图注意力网络学习城市区域表示。</li>
<li>results: 实验结果表明，ROMER 模型在两个下游任务中比前STATE-OF-THE-ART 方法提高了17%。<details>
<summary>Abstract</summary>
Urban region embedding is an important and yet highly challenging issue due to the complexity and constantly changing nature of urban data. To address the challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER) to capture multi-view dependencies and learn expressive representations of urban regions without the constraints of rigid neighbourhood region conditions. Our model focus on learn urban region representation from multi-source urban data. First, we capture the multi-view correlations from mobility flow patterns, POI semantics and check-in dynamics. Then, we adopt global graph attention networks to learn similarity of any two vertices in graphs. To comprehensively consider and share features of multiple views, a two-stage fusion module is further proposed to learn weights with external attention to fuse multi-view embeddings. Extensive experiments for two downstream tasks on real-world datasets demonstrate that our model outperforms state-of-the-art methods by up to 17\% improvement.
</details>
<details>
<summary>摘要</summary>
<style>.Simplified Chinese {font-family: "Microsoft YaHei";}</style>城市区域嵌入是一个重要且具有挑战性的问题，由于城市数据的复杂性和不断变化。为了解决这些挑战，我们提出了多视图表示学习（ROMER），用于捕捉多视图依赖关系并学习表达城市区域的表示。我们的模型专注于从多个城市数据源上学习城市区域表示。首先，我们捕捉了流动人员趋势、 POI  semantics 和检查入动态的多视图相关性。然后，我们采用全球图注意网络来学习图中任意两个顶点的相似性。为了全面考虑和共享多视图特征，我们提出了两个阶段融合模块，以外部注意力学习多视图嵌入的权重。广泛的实验表明，我们的模型在实际 datasets 上的两个下游任务上比状态革命方法提高了17%。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Evaluation-of-Large-Language-Models"><a href="#A-Survey-on-Evaluation-of-Large-Language-Models" class="headerlink" title="A Survey on Evaluation of Large Language Models"></a>A Survey on Evaluation of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03109">http://arxiv.org/abs/2307.03109</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlgroupjlu/llm-eval-survey">https://github.com/mlgroupjlu/llm-eval-survey</a></li>
<li>paper_authors: Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, Xing Xie</li>
<li>for: The paper is written to provide a comprehensive review of evaluation methods for large language models (LLMs), with a focus on three key dimensions: what to evaluate, where to evaluate, and how to evaluate.</li>
<li>methods: The paper uses a survey-based approach to evaluate LLMs, covering various evaluation tasks, benchmarks, and methods.</li>
<li>results: The paper summarizes the success and failure cases of LLMs in different tasks, and highlights several future challenges that lie ahead in LLMs evaluation.Here is the same information in Simplified Chinese text:</li>
<li>for: 该论文是为了提供大语言模型（LLMs）评估方法的全面回顾，强调三个关键维度：评估任务、评估场景和评估方法。</li>
<li>methods: 论文使用问卷方式进行评估，涵盖了各种评估任务、标准套件和评估方法。</li>
<li>results: 论文总结了不同任务中 LLMs 的成功和失败案例，并指出了未来评估领域的一些挑战。<details>
<summary>Abstract</summary>
Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-Domain-Adaptation-of-Sentence-Embeddings-Using-Adapters"><a href="#Efficient-Domain-Adaptation-of-Sentence-Embeddings-Using-Adapters" class="headerlink" title="Efficient Domain Adaptation of Sentence Embeddings Using Adapters"></a>Efficient Domain Adaptation of Sentence Embeddings Using Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03104">http://arxiv.org/abs/2307.03104</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sebischair/efficient-domain-adaptation-of-sentence-embeddings-using-adapters">https://github.com/sebischair/efficient-domain-adaptation-of-sentence-embeddings-using-adapters</a></li>
<li>paper_authors: Tim Schopf, Dennis N. Schneider, Florian Matthes</li>
<li>for: 用于域 adaptation of sentence embeddings</li>
<li>methods: 使用lightweight adapters for parameter-efficient domain adaptation</li>
<li>results: 可以达到1%的竞争性表现，只需要训练约3.6%的参数。Here is the full sentence in Simplified Chinese:</li>
<li>for: 这篇论文是为了域 adaptation of sentence embeddings而写的。</li>
<li>methods: 这篇论文使用了lightweight adapters来实现 parameter-efficient domain adaptation。</li>
<li>results: 这篇论文可以达到1%的竞争性表现，只需要训练约3.6%的参数。<details>
<summary>Abstract</summary>
Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always using the same base model and only exchanging the domain-specific adapters to adapt sentence embeddings to a specific domain. We show that using adapters for parameter-efficient domain adaptation of sentence embeddings yields competitive performance within 1% of a domain-adapted, entirely fine-tuned sentence embedding model while only training approximately 3.6% of the parameters.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Structure-Guided-Multi-modal-Pre-trained-Transformer-for-Knowledge-Graph-Reasoning"><a href="#Structure-Guided-Multi-modal-Pre-trained-Transformer-for-Knowledge-Graph-Reasoning" class="headerlink" title="Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning"></a>Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03591">http://arxiv.org/abs/2307.03591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Liang, Sihang Zhou, Yue Liu, Lingyuan Meng, Meng Liu, Xinwang Liu</li>
<li>for: 本研究旨在提出一种基于多模态知识图(MKG)的多模态预训练 transformer 模型(SGMPT)，以提高多模态知识图理解(KGR)的性能。</li>
<li>methods: 本研究使用了图结构编码器来编码知识图的结构特征，并设计了一种结构指导合并模块，通过两种不同的策略（加权汇和对齐约束）将结构信息注入到文本和图像特征中。</li>
<li>results: 实验结果表明，我们提出的 SGMPT 模型在 FB15k-237-IMG 和 WN18-IMG 上对多模态 KGR  Task 表现出色，超过了现有的状态码模型，证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Multimodal knowledge graphs (MKGs), which intuitively organize information in various modalities, can benefit multiple practical downstream tasks, such as recommendation systems, and visual question answering. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial architectures, the pretrained transformer models have drawn increasing attention, especially for multimodal scenarios. However, the research of multimodal pretrained transformer (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multimodal data, the rich structural information underlying the MKG still cannot be fully leveraged in existing MPT models. Most of them only utilize the graph structure as a retrieval map for matching images and texts connected with the same entity. This manner hinders their reasoning performances. To this end, we propose the graph Structure Guided Multimodal Pretrained Transformer for knowledge graph reasoning, termed SGMPT. Specifically, the graph structure encoder is adopted for structural feature encoding. Then, a structure-guided fusion module with two different strategies, i.e., weighted summation and alignment constraint, is first designed to inject the structural information into both the textual and visual features. To the best of our knowledge, SGMPT is the first MPT model for multimodal KGR, which mines the structural information underlying the knowledge graph. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that our SGMPT outperforms existing state-of-the-art models, and prove the effectiveness of the designed strategies.
</details>
<details>
<summary>摘要</summary>
多Modal知识图(MKG)可以有效地提高多种下游任务的性能,如推荐系统和视觉问答系统。然而，大多数MKG都还不够完整，这些 incomplete MKG 仍然需要大量的研究和发展。在 current 的普通人工智能架构下, 预训练变换器模型在多Modal场景中受到了越来越多的关注。然而, 关于多Modal预训练变换器(MPT)的研究在知识图理解(KGR)方面仍然处于早期阶段。与其他多Modal数据不同的是, 知识图下的丰富结构信息仍然无法得到完全利用。大多数模型只是将知识图作为图结构来匹配图像和文本相关的实体。这种方式限制了他们的理解性能。为此, 我们提出了基于图 структуры的多Modal预训练变换器(SGMPT)。具体来说, SGMPT 使用图结构编码器来编码结构特征。然后, 我们设计了一种结构指导融合模块，通过两种不同的策略，即Weighted Sum 和Alignment Constraint，将结构信息注入到文本和视觉特征中。我们知道, SGMPT 是首个在多Modal KGR 中使用结构信息的 MPT 模型，从而提高了知识图理解的性能。我们在 FB15k-237-IMG 和 WN18-IMG 上进行了广泛的实验，并证明了我们的SGMPT 超过了现有的状态对模型，并证明了我们的设计策略的有效性。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Site-Agnostic-Multimodal-Deep-Learning-Model-to-Identify-Pro-Eating-Disorder-Content-on-Social-Media"><a href="#A-Novel-Site-Agnostic-Multimodal-Deep-Learning-Model-to-Identify-Pro-Eating-Disorder-Content-on-Social-Media" class="headerlink" title="A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media"></a>A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.06775">http://arxiv.org/abs/2307.06775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Feldman<br>for: 这项研究旨在开发一种多modal深度学习模型，用于判断社交媒体上的帖子是否推广精神饮食疾病。methods: 这项研究使用了Twitter上的标注数据集，并训练了12个深度学习模型。最终，研究人员发现了一种将RoBERTa自然语言处理模型和MaxViT图像分类模型进行融合的多modal模型，其精度和F1分数分别为95.9%和0.959。results: 这项研究发现，使用这种多modal模型可以在不使用人工智能技术的前提下，对社交媒体上的帖子进行分类。此外，研究人员还通过对Twitter上的八个哈希标签的未看过的帖子进行时间序分析，发现自2014年以来，社交媒体上的精神饮食疾病推广内容的相对含量在这些社区内逐渐减少。然而，到2018年，这些内容的增长或已经停止下降，或者又开始增长。<details>
<summary>Abstract</summary>
Over the last decade, there has been a vast increase in eating disorder diagnoses and eating disorder-attributed deaths, reaching their zenith during the Covid-19 pandemic. This immense growth derived in part from the stressors of the pandemic but also from increased exposure to social media, which is rife with content that promotes eating disorders. This study aimed to create a multimodal deep learning model that can determine if a given social media post promotes eating disorders based on a combination of visual and textual data. A labeled dataset of Tweets was collected from Twitter, upon which twelve deep learning models were trained and tested. Based on model performance, the most effective deep learning model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, attaining accuracy and F1 scores of 95.9% and 0.959, respectively. The RoBERTa and MaxViT fusion model, deployed to classify an unlabeled dataset of posts from the social media sites Tumblr and Reddit, generated results akin to those of previous research studies that did not employ artificial intelligence-based techniques, indicating that deep learning models can develop insights congruent to those of researchers. Additionally, the model was used to conduct a timeseries analysis of yet unseen Tweets from eight Twitter hashtags, uncovering that, since 2014, the relative abundance of content that promotes eating disorders has decreased drastically within those communities. Despite this reduction, by 2018, content that promotes eating disorders had either stopped declining or increased in ampleness anew on these hashtags.
</details>
<details>
<summary>摘要</summary>
A labeled dataset of tweets was collected from Twitter, and twelve deep learning models were trained and tested. The best-performing model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, achieving accuracy and F1 scores of 95.9% and 0.959, respectively. This model was then applied to classify unlabeled posts from Tumblr and Reddit, producing results similar to previous research studies that did not use AI-based techniques.Moreover, the model was used to conduct a time series analysis of unseen tweets from eight Twitter hashtags, revealing that the relative abundance of content that promotes eating disorders has decreased significantly since 2014 within these communities. However, by 2018, the content that promotes eating disorders had either leveled off or increased again on these hashtags.In conclusion, this study demonstrates that deep learning models can identify content that promotes eating disorders on social media, and the results can be used to monitor and understand the trends of eating disorder-related content online.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/cs.AI_2023_07_07/" data-id="clpahu6xa00083h88hlgs7ioi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/07/cs.CL_2023_07_07/" class="article-date">
  <time datetime="2023-07-07T11:00:00.000Z" itemprop="datePublished">2023-07-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/07/cs.CL_2023_07_07/">cs.CL - 2023-07-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Testing-the-Predictions-of-Surprisal-Theory-in-11-Languages"><a href="#Testing-the-Predictions-of-Surprisal-Theory-in-11-Languages" class="headerlink" title="Testing the Predictions of Surprisal Theory in 11 Languages"></a>Testing the Predictions of Surprisal Theory in 11 Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03667">http://arxiv.org/abs/2307.03667</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ethan Gotlieb Wilcox, Tiago Pimentel, Clara Meister, Ryan Cotterell, Roger P. Levy</li>
<li>for:  investigate the relationship between surprisal and reading times in eleven different languages, distributed across five language families.</li>
<li>methods: derive estimates from language models trained on monolingual and multilingual corpora, and test three predictions associated with surprisal theory.</li>
<li>results: all three predictions are borne out crosslinguistically, offering the most robust link to-date between information theory and incremental language processing across languages.Here’s the Chinese translation of the three information points:</li>
<li>for:  investigate the relationship between surprisal和阅读时间在 eleven different languages中，分布在 five language families中。</li>
<li>methods: 使用语言模型在 monolingual和多语言 corpus 上 derivation estimates, 并测试 three predictions associated with surprisal theory.</li>
<li>results: 所有 three predictions 在 crosslinguistics 中得到证实，提供了最为稳固的 link 到 date  между信息理论和语言处理过程中的 language。<details>
<summary>Abstract</summary>
A fundamental result in psycholinguistics is that less predictable words take a longer time to process. One theoretical explanation for this finding is Surprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's predictability as its surprisal, i.e. its negative log-probability given a context. While evidence supporting the predictions of Surprisal Theory have been replicated widely, most have focused on a very narrow slice of data: native English speakers reading English texts. Indeed, no comprehensive multilingual analysis exists. We address this gap in the current literature by investigating the relationship between surprisal and reading times in eleven different languages, distributed across five language families. Deriving estimates from language models trained on monolingual and multilingual corpora, we test three predictions associated with surprisal theory: (i) whether surprisal is predictive of reading times; (ii) whether expected surprisal, i.e. contextual entropy, is predictive of reading times; (iii) and whether the linking function between surprisal and reading times is linear. We find that all three predictions are borne out crosslinguistically. By focusing on a more diverse set of languages, we argue that these results offer the most robust link to-date between information theory and incremental language processing across languages.
</details>
<details>
<summary>摘要</summary>
一个基本的心理语言学结论是，更难预测的词语需要更长的时间来处理。一种理论解释是《不意外性理论》（Hale, 2001；Levy, 2008），它量化了一个词语在上下文中的难度为其不意外性，即其负梯度邻近概率。尽管这些预测得到了广泛的复制，但大多数研究都集中在了一个非常窄的数据集上：英语Native speaker reading English texts。实际上，没有一个全面的多语言分析。我们在现有文献中填补这个空白，通过 investigate the relationship between surprisal and reading times in eleven different languages, distributed across five language families. We derive estimates from language models trained on monolingual and multilingual corpora, and test three predictions associated with surprisal theory: (i) whether surprisal is predictive of reading times; (ii) whether expected surprisal, i.e. contextual entropy, is predictive of reading times; (iii) and whether the linking function between surprisal and reading times is linear. We find that all three predictions are borne out crosslinguistically. By focusing on a more diverse set of languages, we argue that these results offer the most robust link to-date between information theory and incremental language processing across languages.
</details></li>
</ul>
<hr>
<h2 id="The-distribution-of-discourse-relations-within-and-across-turns-in-spontaneous-conversation"><a href="#The-distribution-of-discourse-relations-within-and-across-turns-in-spontaneous-conversation" class="headerlink" title="The distribution of discourse relations within and across turns in spontaneous conversation"></a>The distribution of discourse relations within and across turns in spontaneous conversation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03645">http://arxiv.org/abs/2307.03645</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. Magalí López Cortez, Cassandra L. Jacobs</li>
<li>for: 这篇论文是关于如何在快速对话中使用语言关系（DR）的。</li>
<li>methods: 这篇论文使用了一系列的语言模型和人工标注来适应快速对话中的语言关系。</li>
<li>results: 研究发现，不同的对话上下文会导致不同的语言关系分布，单个转折创造了最多的不确定性。此外，研究还发现，基于演示单元的嵌入可以预测语言关系。<details>
<summary>Abstract</summary>
Time pressure and topic negotiation may impose constraints on how people leverage discourse relations (DRs) in spontaneous conversational contexts. In this work, we adapt a system of DRs for written language to spontaneous dialogue using crowdsourced annotations from novice annotators. We then test whether discourse relations are used differently across several types of multi-utterance contexts. We compare the patterns of DR annotation within and across speakers and within and across turns. Ultimately, we find that different discourse contexts produce distinct distributions of discourse relations, with single-turn annotations creating the most uncertainty for annotators. Additionally, we find that the discourse relation annotations are of sufficient quality to predict from embeddings of discourse units.
</details>
<details>
<summary>摘要</summary>
时间压力和话题谈判可能会对人们在协说性谈话中使用语言关系（DR）所带来限制。在这个工作中，我们将写作语言系统的DR适用于精神对话使用拼写的观众标注。然后我们将检查DR在不同的多句子背景下是否被使用不同。我们比较说话者和说话之间的DR标注，以及说话者和说话之间的转折中的DR标注。最终，我们发现不同的谈话背景会生成不同的语言关系分布，单一说话标注最多对annotator造成不确定性。此外，我们发现DR标注足够高质量以预测对话单位的嵌入。
</details></li>
</ul>
<hr>
<h2 id="Text-Simplification-of-Scientific-Texts-for-Non-Expert-Readers"><a href="#Text-Simplification-of-Scientific-Texts-for-Non-Expert-Readers" class="headerlink" title="Text Simplification of Scientific Texts for Non-Expert Readers"></a>Text Simplification of Scientific Texts for Non-Expert Readers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03569">http://arxiv.org/abs/2307.03569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Björn Engelmann, Fabian Haak, Christin Katharina Kreutz, Narjes Nikzad Khasmakhi, Philipp Schaer</li>
<li>for: 这个研究是为了帮助非专家读者更好地理解科学报告摘要中的核心信息。</li>
<li>methods: 这个研究使用了三种现成的摘要模型（两个基于T5，一个基于PEGASUS）和一个使用复杂短语识别的ChatGPT模型来简化科学报告摘要。</li>
<li>results: 这些模型可以帮助非专家读者更好地理解报告摘要中的核心信息，并且可以帮助您更快地理解这些信息。<details>
<summary>Abstract</summary>
Reading levels are highly individual and can depend on a text's language, a person's cognitive abilities, or knowledge on a topic. Text simplification is the task of rephrasing a text to better cater to the abilities of a specific target reader group. Simplification of scientific abstracts helps non-experts to access the core information by bypassing formulations that require domain or expert knowledge. This is especially relevant for, e.g., cancer patients reading about novel treatment options. The SimpleText lab hosts the simplification of scientific abstracts for non-experts (Task 3) to advance this field. We contribute three runs employing out-of-the-box summarization models (two based on T5, one based on PEGASUS) and one run using ChatGPT with complex phrase identification.
</details>
<details>
<summary>摘要</summary>
阅读水平是非常个人化的，它可能受到文本的语言、读者的认知能力以及主题知识的影响。文本简化是将文本重新推理以更好地适应target读者群的能力。在科学报告中简化Abstract可以帮助非专家访问核心信息，这特别有 relevance для例如，癌症患者阅读新的治疗方案。我们在SimpleText lab中为非专家（任务3）进行科学报告简化，以推动这一领域的发展。我们提供了三个运行，其中两个基于T5摘要模型，一个基于PEGASUS摘要模型，以及一个使用ChatGPT复杂短语识别。
</details></li>
</ul>
<hr>
<h2 id="DWReCO-at-CheckThat-2023-Enhancing-Subjectivity-Detection-through-Style-based-Data-Sampling"><a href="#DWReCO-at-CheckThat-2023-Enhancing-Subjectivity-Detection-through-Style-based-Data-Sampling" class="headerlink" title="DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling"></a>DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03550">http://arxiv.org/abs/2307.03550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ipek Baris Schlicht, Lynn Khellaf, Defne Altiok</li>
<li>for: 这篇论文描述了我们在CheckThat! Lab中的主观检测任务提交。</li>
<li>methods: 为了解决任务中的分类偏见，我们使用GPT-3模型生成了不同风格的提示，基于新闻观点的主观检查表。我们使用了这些扩展训练集来练化语言特定的转换器模型。</li>
<li>results: 我们在英语、德语和土耳其语的实验中发现，不同的主观风格都能够在所有语言上得到效果。此外，我们发现在土耳其语和英语中，风格基本检测比重塑化更好。最后，GPT-3模型在非英语语言中生成风格基本文本时 occasional lacklustre 的结果。<details>
<summary>Abstract</summary>
This paper describes our submission for the subjectivity detection task at the CheckThat! Lab. To tackle class imbalances in the task, we have generated additional training materials with GPT-3 models using prompts of different styles from a subjectivity checklist based on journalistic perspective. We used the extended training set to fine-tune language-specific transformer models. Our experiments in English, German and Turkish demonstrate that different subjective styles are effective across all languages. In addition, we observe that the style-based oversampling is better than paraphrasing in Turkish and English. Lastly, the GPT-3 models sometimes produce lacklustre results when generating style-based texts in non-English languages.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了我们在CheckThat! Lab中对主观偏见检测任务的提交。为了解决任务中的类别不均衡，我们使用GPT-3模型生成了更多的训练材料，使用基于新闻媒体的主观检查列表中的不同风格的提示。我们使用扩展的训练集来精度调整语言特定的转换器模型。我们的实验表明，不同的主观风格在所有语言中都有效。此外，我们发现在土耳其语和英语中，风格基于的增加 sampling 比较有效，而在非英语语言中，GPT-3模型 sometimes produce lacklustre results when generating style-based texts。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-the-perceptual-value-of-lexical-and-non-lexical-channels-in-speech"><a href="#Quantifying-the-perceptual-value-of-lexical-and-non-lexical-channels-in-speech" class="headerlink" title="Quantifying the perceptual value of lexical and non-lexical channels in speech"></a>Quantifying the perceptual value of lexical and non-lexical channels in speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03534">http://arxiv.org/abs/2307.03534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarenne Wallbridge, Peter Bell, Catherine Lai</li>
<li>for: 研究对话中非语言信息的值</li>
<li>methods: 引入一种通用的研究方法，利用准确率和信息 entropy 来衡量非语言信息的影响</li>
<li>results: 研究发现，非语言信息在对话中产生一致的影响，即使其不如语言内容alone 导致更好的分类性turn 判断，但是它们仍然能够提高参与者的一致性。<details>
<summary>Abstract</summary>
Speech is a fundamental means of communication that can be seen to provide two channels for transmitting information: the lexical channel of which words are said, and the non-lexical channel of how they are spoken. Both channels shape listener expectations of upcoming communication; however, directly quantifying their relative effect on expectations is challenging. Previous attempts require spoken variations of lexically-equivalent dialogue turns or conspicuous acoustic manipulations. This paper introduces a generalised paradigm to study the value of non-lexical information in dialogue across unconstrained lexical content. By quantifying the perceptual value of the non-lexical channel with both accuracy and entropy reduction, we show that non-lexical information produces a consistent effect on expectations of upcoming dialogue: even when it leads to poorer discriminative turn judgements than lexical content alone, it yields higher consensus among participants.
</details>
<details>
<summary>摘要</summary>
文本中的演讲是一种基本的交流方式，可以看作提供两个信息传输通道：言语上的字句，以及语言上的演讲方式。两个通道都会影响听众对后续交流的期望;然而，直接量化这两个通道之间的相对效果是困难的。先前的尝试需要使用语言上的变体或明显的声音修饰来实现对话的变化。本文介绍了一种通用的研究方法，用于研究对话中非语言信息的价值。通过量化非语言信息的听众对话的准确性和 entropy 减少，我们发现，非语言信息会在对话中产生一致的效果：即使导致语言内容alone 的较差分类判断，也会得到参与者的高度一致。
</details></li>
</ul>
<hr>
<h2 id="AI-UPV-at-EXIST-2023-–-Sexism-Characterization-Using-Large-Language-Models-Under-The-Learning-with-Disagreements-Regime"><a href="#AI-UPV-at-EXIST-2023-–-Sexism-Characterization-Using-Large-Language-Models-Under-The-Learning-with-Disagreements-Regime" class="headerlink" title="AI-UPV at EXIST 2023 – Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime"></a>AI-UPV at EXIST 2023 – Sexism Characterization Using Large Language Models Under The Learning with Disagreements Regime</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03385">http://arxiv.org/abs/2307.03385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/angelfelipemp/sexism-llm-learning-with-disagreement">https://github.com/angelfelipemp/sexism-llm-learning-with-disagreement</a></li>
<li>paper_authors: Angel Felipe Magnossão de Paula, Giulia Rizzi, Elisabetta Fersini, Damiano Spina</li>
<li>for: The paper aims to develop an automated system for detecting sexism and other hateful behaviors on social media to promote a more inclusive and respectful online environment.</li>
<li>methods: The proposed approach uses large language models (mBERT and XLM-RoBERTa) and ensemble strategies to identify and classify sexism in English and Spanish, without relying on aggregated labels.</li>
<li>results: The system achieved fourth place in Task 2 at EXIST and first place in Task 3, with the highest ICM-Soft of -2.32 and a normalized ICM-Soft of 0.79, outperforming the individual large language models.Here’s the simplified Chinese text for the three information points:</li>
<li>for: 本研究旨在开发一种自动检测社交媒体上的性别歧视和其他仇恨行为，以促进在线环境的包容性和尊重。</li>
<li>methods: 该方法使用大型自然语言模型（mBERT和XLM-RoBERTa）和集成策略来识别和分类社会性别歧视，不使用汇总标签。</li>
<li>results: 系统在EXIST Lab中取得了第四名的成绩（ Task 2）和第一名的成绩（ Task 3），ICM-Soft最高达{-2.32）和正常化ICM-Soft为0.79，超过了单独的大型自然语言模型。<details>
<summary>Abstract</summary>
With the increasing influence of social media platforms, it has become crucial to develop automated systems capable of detecting instances of sexism and other disrespectful and hateful behaviors to promote a more inclusive and respectful online environment. Nevertheless, these tasks are considerably challenging considering different hate categories and the author's intentions, especially under the learning with disagreements regime. This paper describes AI-UPV team's participation in the EXIST (sEXism Identification in Social neTworks) Lab at CLEF 2023. The proposed approach aims at addressing the task of sexism identification and characterization under the learning with disagreements paradigm by training directly from the data with disagreements, without using any aggregated label. Yet, performances considering both soft and hard evaluations are reported. The proposed system uses large language models (i.e., mBERT and XLM-RoBERTa) and ensemble strategies for sexism identification and classification in English and Spanish. In particular, our system is articulated in three different pipelines. The ensemble approach outperformed the individual large language models obtaining the best performances both adopting a soft and a hard label evaluation. This work describes the participation in all the three EXIST tasks, considering a soft evaluation, it obtained fourth place in Task 2 at EXIST and first place in Task 3, with the highest ICM-Soft of -2.32 and a normalized ICM-Soft of 0.79. The source code of our approaches is publicly available at https://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement.
</details>
<details>
<summary>摘要</summary>
随着社交媒体平台的普及，已经成为必要的发展自动化系统，能够检测社交媒体上的性别歧视和其他不尊重和仇恨行为，以促进更加包容和尊重的在线环境。然而，这些任务非常困难，因为不同的仇恨类别和作者的意图，尤其是在学习各自意见的情况下。这篇文章描述了AI-UPV团队在CLEF 2023年的EXIST（性别歧视 Identification in Social neTworks）实验室中的参与。提出的方法是通过直接从数据中学习，不使用任何汇总标签，来解决性别歧视标识和分类问题。然而，我们还是报告了使用软和硬评估方法的性能。我们的系统使用了大型自然语言模型（i.e., mBERT和XLM-RoBERTa）和集成策略进行性别歧视标识和分类。具体来说，我们的系统由三个不同的管道组成。集成方法在使用软和硬标签评估方法时表现出色，在EXIST任务中获得了第四名（Task 2）和第一名（Task 3），其ICM-Soft=-2.32和 normalized ICM-Soft为0.79。我们的源代码可以在https://github.com/AngelFelipeMP/Sexism-LLM-Learning-With-Disagreement上获得。
</details></li>
</ul>
<hr>
<h2 id="A-Side-by-side-Comparison-of-Transformers-for-English-Implicit-Discourse-Relation-Classification"><a href="#A-Side-by-side-Comparison-of-Transformers-for-English-Implicit-Discourse-Relation-Classification" class="headerlink" title="A Side-by-side Comparison of Transformers for English Implicit Discourse Relation Classification"></a>A Side-by-side Comparison of Transformers for English Implicit Discourse Relation Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03378">http://arxiv.org/abs/2307.03378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bruce W. Lee, BongSeok Yang, Jason Hyung-Jong Lee</li>
<li>for: 这个论文的目的是对多种自然语言处理领域中的隐式 дискурс关系分类进行比较研究，以便研究人员可以充分利用公共可用的模型进行дискурс分析。</li>
<li>methods: 这篇论文使用了七种预训练语言模型，并通过对这些模型进行精细调整来进行比较性能测试。这些模型包括NSP、SBO、SOP等句子级预训练目标，以及MLM和全注意力等方法。</li>
<li>results: 这篇论文的结果显示，与之前报道的不同（Shi和Demberg，2019b），使用 sentence-level 预训练目标（NSP、SBO、SOP）并不总是生成最佳的隐式 дискурс关系分类模型。相反，使用相同大小的 PLMs  WITH MLM AND full attention 可以达到更高的性能（ACC &#x3D; 0.671）。<details>
<summary>Abstract</summary>
Though discourse parsing can help multiple NLP fields, there has been no wide language model search done on implicit discourse relation classification. This hinders researchers from fully utilizing public-available models in discourse analysis. This work is a straightforward, fine-tuned discourse performance comparison of seven pre-trained language models. We use PDTB-3, a popular discourse relation annotated dataset. Through our model search, we raise SOTA to 0.671 ACC and obtain novel observations. Some are contrary to what has been reported before (Shi and Demberg, 2019b), that sentence-level pre-training objectives (NSP, SBO, SOP) generally fail to produce the best performing model for implicit discourse relation classification. Counterintuitively, similar-sized PLMs with MLM and full attention led to better performance.
</details>
<details>
<summary>摘要</summary>
“对话分析可以帮助多个自然语言处理（NLP）领域，但是对于不直接的话语关系分类仍没有广泛的语言模型搜索。这限制了研究人员对话分析中的全面利用已有的模型。这项工作是一个简单、精确地 fine-tune 多个预训练语言模型的表现比较。我们使用 PDTB-3，一个受欢迎的话语关系标注数据集。通过我们的模型搜索，我们提高了ACC的最高分为0.671，并获得了新的观察。一些与过去报告不同（Shi和Demberg，2019b），具体是内置式预训练目标（NSP、SBO、SOP）通常无法生成最佳的模型 для implicit discourse relation classification。反意外地，相同大小的PLMs  WITH MLM和全域注意力可以获得更好的表现。”
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Negative-Transfer-with-Task-Awareness-for-Sexism-Hate-Speech-and-Toxic-Language-Detection"><a href="#Mitigating-Negative-Transfer-with-Task-Awareness-for-Sexism-Hate-Speech-and-Toxic-Language-Detection" class="headerlink" title="Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection"></a>Mitigating Negative Transfer with Task Awareness for Sexism, Hate Speech, and Toxic Language Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03377">http://arxiv.org/abs/2307.03377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/angelfelipemp/mitigating-negative-transfer-with-ta">https://github.com/angelfelipemp/mitigating-negative-transfer-with-ta</a></li>
<li>paper_authors: Angel Felipe Magnossão de Paula, Paolo Rosso, Damiano Spina</li>
<li>for: 这篇论文的目的是如何 Mitigate the negative transfer problem in Multi-Task Learning (MTL)。</li>
<li>methods: 该论文提出了一种基于任务意识概念的新方法，使得避免了负性传递问题，同时提高了性能。这种方法基于在多个任务之间共享信息的思想。</li>
<li>results: 该论文在EXIST-2021和HatEval-2019测试准则上实现了新的状态态-of-the-art，并且在识别性别歧视、仇恨言语和恶意言语等领域中达到了最高的性能。<details>
<summary>Abstract</summary>
This paper proposes a novelty approach to mitigate the negative transfer problem. In the field of machine learning, the common strategy is to apply the Single-Task Learning approach in order to train a supervised model to solve a specific task. Training a robust model requires a lot of data and a significant amount of computational resources, making this solution unfeasible in cases where data are unavailable or expensive to gather. Therefore another solution, based on the sharing of information between tasks, has been developed: Multi-Task Learning (MTL). Despite the recent developments regarding MTL, the problem of negative transfer has still to be solved. Negative transfer is a phenomenon that occurs when noisy information is shared between tasks, resulting in a drop in performance. This paper proposes a new approach to mitigate the negative transfer problem based on the task awareness concept. The proposed approach results in diminishing the negative transfer together with an improvement of performance over classic MTL solution. Moreover, the proposed approach has been implemented in two unified architectures to detect Sexism, Hate Speech, and Toxic Language in text comments. The proposed architectures set a new state-of-the-art both in EXIST-2021 and HatEval-2019 benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Token-Level-Serialized-Output-Training-for-Joint-Streaming-ASR-and-ST-Leveraging-Textual-Alignments"><a href="#Token-Level-Serialized-Output-Training-for-Joint-Streaming-ASR-and-ST-Leveraging-Textual-Alignments" class="headerlink" title="Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments"></a>Token-Level Serialized Output Training for Joint Streaming ASR and ST Leveraging Textual Alignments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03354">http://arxiv.org/abs/2307.03354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Papi, Peidong Wan, Junkun Chen, Jian Xue, Jinyu Li, Yashesh Gaur</li>
<li>for: 这篇论文主要用于提高实时涂抹翻译和自动听写的质量和效率。</li>
<li>methods: 这篇论文提出了一种串行传播变换器-变把（Transformer-Transducer），该模型同时生成自动听写（ASR）和翻译（ST）输出，使用单个解码器进行joint训练。</li>
<li>results: 实验结果表明，这种方法在单语言（it-en）和多语言（de,es,it）的设置下都能够实现最佳的质量-延迟平衡。模型的平均ASR延迟为1秒，ST延迟为1.3秒，而且与分开的ASR和ST模型相比，输出质量没有下降，甚至有所提高，增加了1.1个word error rate和0.4个bleu在多语言情况下。<details>
<summary>Abstract</summary>
In real-world applications, users often require both translations and transcriptions of speech to enhance their comprehension, particularly in streaming scenarios where incremental generation is necessary. This paper introduces a streaming Transformer-Transducer that jointly generates automatic speech recognition (ASR) and speech translation (ST) outputs using a single decoder. To produce ASR and ST content effectively with minimal latency, we propose a joint token-level serialized output training method that interleaves source and target words by leveraging an off-the-shelf textual aligner. Experiments in monolingual (it-en) and multilingual (\{de,es,it\}-en) settings demonstrate that our approach achieves the best quality-latency balance. With an average ASR latency of 1s and ST latency of 1.3s, our model shows no degradation or even improves output quality compared to separate ASR and ST models, yielding an average improvement of 1.1 WER and 0.4 BLEU in the multilingual case.
</details>
<details>
<summary>摘要</summary>
在实际应用场景中，用户经常需要同时获得翻译和转写的语音识别，特别在流处理方面，需要实时生成。这篇论文介绍了一种流处理Transformer-Transducer，可同时生成自动语音识别（ASR）和语音翻译（ST）输出，使用单个解码器。为了在最小的延迟下生成ASR和ST内容，我们提议了一种共同序列化输出训练方法，通过利用商业化的文本对齐器来扫描源和目标词语。实验表明，我们的方法在单语言（it-en）和多语言（de,es,it-en）设置下都可以达到最佳的质量-延迟平衡。我们的模型的平均ASR延迟为1秒，ST延迟为1.3秒，而且与分离ASR和ST模型不同，我们的模型无减性或甚至提高输出质量，平均提高1.1个WRR和0.4个BLEU在多语言情况下。
</details></li>
</ul>
<hr>
<h2 id="BiPhone-Modeling-Inter-Language-Phonetic-Influences-in-Text"><a href="#BiPhone-Modeling-Inter-Language-Phonetic-Influences-in-Text" class="headerlink" title="BiPhone: Modeling Inter Language Phonetic Influences in Text"></a>BiPhone: Modeling Inter Language Phonetic Influences in Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03322">http://arxiv.org/abs/2307.03322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhirut Gupta, Ananya B. Sai, Richard Sproat, Yuri Vasilevski, James S. Ren, Ambarish Jash, Sukhdeep S. Sodhi, Aravindan Raghuveer</li>
<li>for: 这个论文是为了研究在使用第二语言（L2）时，因技术不匹配而受到强制使用Web的人群中，受到语言一低文化水平的影响而导致的文本错误的问题。</li>
<li>methods: 这个论文使用了一种方法来挖掘L1和L2之间的音节混淆（即L1 speaker可能会混淆的L2音节），并将这些混淆音节输入到一个生成模型（Bi-Phone）中，以生成受混淆的L2文本。</li>
<li>results: 通过人工评估，这个方法可以生成具有各种L1特征的受混淆L2文本，并且在Web上有广泛的应用。此外，这个论文还将这种方法应用于SuperGLUE语言理解 benchmark 上，并证明了SoTA语言理解模型在受混淆情况下的表现不佳。此外，这个论文还提出了一种新的音节预测预训练任务，可以帮助字节模型重新获得SuperGLUE水平的表现。最后，这个论文还发布了FunGLUE benchmark，以便进一步研究具有phonetically robust的语言模型。<details>
<summary>Abstract</summary>
A large number of people are forced to use the Web in a language they have low literacy in due to technology asymmetries. Written text in the second language (L2) from such users often contains a large number of errors that are influenced by their native language (L1). We propose a method to mine phoneme confusions (sounds in L2 that an L1 speaker is likely to conflate) for pairs of L1 and L2. These confusions are then plugged into a generative model (Bi-Phone) for synthetically producing corrupted L2 text. Through human evaluations, we show that Bi-Phone generates plausible corruptions that differ across L1s and also have widespread coverage on the Web. We also corrupt the popular language understanding benchmark SuperGLUE with our technique (FunGLUE for Phonetically Noised GLUE) and show that SoTA language understating models perform poorly. We also introduce a new phoneme prediction pre-training task which helps byte models to recover performance close to SuperGLUE. Finally, we also release the FunGLUE benchmark to promote further research in phonetically robust language models. To the best of our knowledge, FunGLUE is the first benchmark to introduce L1-L2 interactions in text.
</details>
<details>
<summary>摘要</summary>
很多人被迫使用第二语言（L2）进行网络交互，但是由于技术不均衡，他们的written L2文本经常含有大量的错误，这些错误受到他们的Native Language（L1）的影响。我们提议一种方法， mines phoneme confusions（L2中的声音混淆），并将其与L1进行对应。这些混淆被用于生成Synthetically produced corrupted L2文本。我们通过人类评估表明，Bi-Phone生成的混淆是有可能的，并且在不同的L1上具有广泛的coverage。我们还将这种技术应用于SuperGLUE的人工语言理解 benchmark（FunGLUE for Phonetically Noised GLUE），并证明了SoTA语言理解模型在这种情况下表现不佳。我们还提出了一种新的声音预测预训练任务，帮助Byte模型在SuperGLUE中恢复性能。最后，我们还发布了FunGLUE benchmark，以便进一步研究在声音稳定的语言模型方面。我们知道，FunGLUE是首个引入L1-L2交互的文本 benchmark。
</details></li>
</ul>
<hr>
<h2 id="Covering-Uncommon-Ground-Gap-Focused-Question-Generation-for-Answer-Assessment"><a href="#Covering-Uncommon-Ground-Gap-Focused-Question-Generation-for-Answer-Assessment" class="headerlink" title="Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment"></a>Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03319">http://arxiv.org/abs/2307.03319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roni Rabin, Alexandre Djerbetian, Roee Engelberg, Lidan Hackmon, Gal Elidan, Reut Tsarfaty, Amir Globerson</li>
<li>for: The paper is written for generating gap-focused questions (GFQs) in educational dialogues to create a rich and interactive learning experience.</li>
<li>methods: The paper proposes a model that uses natural language processing techniques to generate GFQs automatically, with a focus on key desired aspects such as relevance, specificity, and engagement.</li>
<li>results: The paper provides an evaluation of the generated questions against human-generated questions, demonstrating competitive performance and the effectiveness of the proposed model in generating GFQs.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了自动生成教育对话中的差距关注问题（GFQ），以创造一种丰富和互动的学习经验。</li>
<li>methods: 论文提出了一种使用自然语言处理技术来生成GFQ，注重关键所需的方面，如相关性、特定性和参与度。</li>
<li>results: 论文通过人工标注者对生成的问题和人类生成的问题进行评估，表明了提案模型的竞争力和生成GFQ的效果。<details>
<summary>Abstract</summary>
Human communication often involves information gaps between the interlocutors. For example, in an educational dialogue, a student often provides an answer that is incomplete, and there is a gap between this answer and the perfect one expected by the teacher. Successful dialogue then hinges on the teacher asking about this gap in an effective manner, thus creating a rich and interactive educational experience. We focus on the problem of generating such gap-focused questions (GFQs) automatically. We define the task, highlight key desired aspects of a good GFQ, and propose a model that satisfies these. Finally, we provide an evaluation by human annotators of our generated questions compared against human generated ones, demonstrating competitive performance.
</details>
<details>
<summary>摘要</summary>
人际交流经常会出现信息差距 между交流方。例如，在教学对话中，学生可能提供不够的答案，而教师期望的完整答案与此存在差距。成功的对话受到教师以有效的方式询问这个差距，从而创造出丰富且互动的教学经验。我们关注于自动生成这些差距关注的问题（GFQ）的问题。我们定义任务、标出了好的GFQ所应具备的关键特征，并提议一种满足这些特征的模型。最后，我们通过人类标注员对我们生成的问题与人类生成的问题进行评估，展示了竞争力强的性能。
</details></li>
</ul>
<hr>
<h2 id="InfoSync-Information-Synchronization-across-Multilingual-Semi-structured-Tables"><a href="#InfoSync-Information-Synchronization-across-Multilingual-Semi-structured-Tables" class="headerlink" title="InfoSync: Information Synchronization across Multilingual Semi-structured Tables"></a>InfoSync: Information Synchronization across Multilingual Semi-structured Tables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03313">http://arxiv.org/abs/2307.03313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Info-Sync/InfoSync">https://github.com/Info-Sync/InfoSync</a></li>
<li>paper_authors: Siddharth Khincha, Chelsi Jain, Vivek Gupta, Tushar Kataria, Shuo Zhang</li>
<li>for: 本研究旨在解决语言间 semi-结构化数据的信息同步问题，例如wikipedia 表格的同步化。</li>
<li>methods: 提出了一种新的数据集 InfoSyncC 和一种两步方法 для tabular 同步化。InfoSync 包含 100K 实体中心表格（wikipedia Infobox） Across 14 种语言，其中一部分（3.5K 对）是手动注释。提出的方法包括信息对齐和信息更新两个步骤。</li>
<li>results: 在 InfoSync 上进行了信息对齐，信息对齐得分为 87.91（en &lt;-&gt; non-en）。为了评估信息更新，我们对 Infoboxes 进行了603 个表格对的人工帮助编辑。我们的方法得到了wikipedia 上的77.28% 的接受率，表明了提出的方法的有效性。<details>
<summary>Abstract</summary>
Information Synchronization of semi-structured data across languages is challenging. For instance, Wikipedia tables in one language should be synchronized across languages. To address this problem, we introduce a new dataset InfoSyncC and a two-step method for tabular synchronization. InfoSync contains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages, of which a subset (3.5K pairs) are manually annotated. The proposed method includes 1) Information Alignment to map rows and 2) Information Update for updating missing/outdated information for aligned tables across multilingual tables. When evaluated on InfoSync, information alignment achieves an F1 score of 87.91 (en <-> non-en). To evaluate information updation, we perform human-assisted Wikipedia edits on Infoboxes for 603 table pairs. Our approach obtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
信息同步问题在不结构化数据中是挑战。例如，wikipedia 表格在一种语言中应该与其他语言的表格进行同步。为解决这个问题，我们介绍了一个新的数据集 InfoSyncC 和一种两步方法 для表格同步。InfoSync 包含 100 万个实体中心表格（Wikipedia 信息框） Across 14 种语言，其中一 subset（3.5 千对）是 manually annotated。我们提议的方法包括 1) 信息对应和 2) 信息更新。当 evaluated on InfoSync 时，信息对应得到了 F1 分数为 87.91（en <-> non-en）。为评估信息更新，我们对 Infoboxes 进行了人工协助的 Wikipedia 编辑 603 对。我们的方法获得了 Wikipedia 上的接受率为 77.28%，显示了我们提议的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Gammatonegram-Representation-for-End-to-End-Dysarthric-Speech-Processing-Tasks-Speech-Recognition-Speaker-Identification-and-Intelligibility-Assessment"><a href="#Gammatonegram-Representation-for-End-to-End-Dysarthric-Speech-Processing-Tasks-Speech-Recognition-Speaker-Identification-and-Intelligibility-Assessment" class="headerlink" title="Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment"></a>Gammatonegram Representation for End-to-End Dysarthric Speech Processing Tasks: Speech Recognition, Speaker Identification, and Intelligibility Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03296">http://arxiv.org/abs/2307.03296</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/areffarhadi/gammatonegram_cnn_dysarthric_speech">https://github.com/areffarhadi/gammatonegram_cnn_dysarthric_speech</a></li>
<li>paper_authors: Aref Farhadipour, Hadi Veisi</li>
<li>for: 这个研究旨在开发一个基于 convolutional neural network (CNN) 的语音识别系统，以提高智能家居中的语音识别率。</li>
<li>methods: 该研究使用 gammatonegram 方法将语音文件转换为图像，并使用 pre-trained Alexnet 基于 transfer learning 方法进行语音识别。</li>
<li>results: 根据 UA 数据集的结果，提议的语音识别系统在 speaker-dependent 模式下达到了 91.29% 的准确率，语音识别系统在 text-dependent 模式下达到了 87.74% 的准确率，而两类智能评估系统在 two-class 模式下达到了 96.47% 的准确率。<details>
<summary>Abstract</summary>
Dysarthria is a disability that causes a disturbance in the human speech system and reduces the quality and intelligibility of a person's speech. Because of this effect, the normal speech processing systems can not work properly on impaired speech. This disability is usually associated with physical disabilities. Therefore, designing a system that can perform some tasks by receiving voice commands in the smart home can be a significant achievement. In this work, we introduce gammatonegram as an effective method to represent audio files with discriminative details, which is used as input for the convolutional neural network. On the other word, we convert each speech file into an image and propose image recognition system to classify speech in different scenarios. Proposed CNN is based on the transfer learning method on the pre-trained Alexnet. In this research, the efficiency of the proposed system for speech recognition, speaker identification, and intelligibility assessment is evaluated. According to the results on the UA dataset, the proposed speech recognition system achieved 91.29% accuracy in speaker-dependent mode, the speaker identification system acquired 87.74% accuracy in text-dependent mode, and the intelligibility assessment system achieved 96.47% accuracy in two-class mode. Finally, we propose a multi-network speech recognition system that works fully automatically. This system is located in a cascade arrangement with the two-class intelligibility assessment system, and the output of this system activates each one of the speech recognition networks. This architecture achieves an accuracy of 92.3% WRR. The source code of this paper is available.
</details>
<details>
<summary>摘要</summary>
《干扰性 speech 识别系统的设计》Introduction:难以说话（dysarthria）是一种影响人类语音系统的残疾，导致语音质量和可读性减退。由于这种影响，常规的语音处理系统无法正常工作。这种残疾通常与物理残疾相关。因此，设计一个可以通过声音命令在智能家居中进行一些任务的系统可以是一项重要的成就。在这项工作中，我们介绍了一种有效的方法，即《干扰性 grammatonegram》，用于将语音文件转换成可识别的图像，并提出了一种基于转移学习方法的 convolutional neural network（CNN）来分类不同场景的语音。Methodology:我们将每个语音文件转换成一幅图像，并使用pre-trained Alexnet进行转移学习。在这项研究中，我们评估了提案的语音识别、 speaker identification和可读性评估系统的效率。根据UA数据集的结果，提案的语音识别系统在 speaker-dependent 模式下达到了91.29%的准确率，speaker identification系统在 text-dependent 模式下达到了87.74%的准确率，而可读性评估系统在 two-class 模式下达到了96.47%的准确率。Results:我们还提出了一种多网络语音识别系统，其中每个语音识别网络都是通过两类可读性评估系统的输出来活化。这种架构可以达到92.3%的WRR精度。Conclusion:本文介绍了一种基于干扰性 grammatonegram 和转移学习的语音识别系统的设计。该系统可以在智能家居中进行一些任务，并且可以提高语音识别、 speaker identification和可读性评估的精度。ources code of this paper is available.
</details></li>
</ul>
<hr>
<h2 id="Performance-Comparison-of-Pre-trained-Models-for-Speech-to-Text-in-Turkish-Whisper-Small-and-Wav2Vec2-XLS-R-300M"><a href="#Performance-Comparison-of-Pre-trained-Models-for-Speech-to-Text-in-Turkish-Whisper-Small-and-Wav2Vec2-XLS-R-300M" class="headerlink" title="Performance Comparison of Pre-trained Models for Speech-to-Text in Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M"></a>Performance Comparison of Pre-trained Models for Speech-to-Text in Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04765">http://arxiv.org/abs/2307.04765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oyku Berfin Mercan, Sercan Cepni, Davut Emre Tasar, Sukru Ozan</li>
<li>for: 这个研究是为了测试两种预训练的多语言模型（Whisper-Small和Wav2Vec2-XLS-R-300M）在土耳其语言上的表现。</li>
<li>methods: 这个研究使用了Mozilla Common Voice版本11.0，这是一个在土耳其语言上制作的开源数据集。研究人员将这两个模型在这个数据集上进行了微调。</li>
<li>results: 研究人员计算了WER值，得到的结果是0.28和0.16，分别对应于Wav2Vec2-XLS-R-300M和Whisper-Small模型。此外，研究人员还测试了这两个模型在没有包含在训练和验证数据集中的回呼记录上的表现。<details>
<summary>Abstract</summary>
In this study, the performances of the Whisper-Small and Wav2Vec2-XLS-R-300M models which are two pre-trained multilingual models for speech to text were examined for the Turkish language. Mozilla Common Voice version 11.0 which is prepared in Turkish language and is an open-source data set, was used in the study. The multilingual models, Whisper- Small and Wav2Vec2-XLS-R-300M were fine-tuned with this data set which contains a small amount of data. The speech to text performance of the two models was compared. WER values are calculated as 0.28 and 0.16 for the Wav2Vec2-XLS- R-300M and the Whisper-Small models respectively. In addition, the performances of the models were examined with the test data prepared with call center records that were not included in the training and validation dataset.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们对两种预训练的多语言模型（Whisper-Small和Wav2Vec2-XLS-R-300M）进行了对 Turkish 语言的评估。我们使用了 Mozilla Common Voice 版本 11.0，这是一个开源的 Turkish 语言数据集。我们对这些数据集进行了精度的 fine-tuning，并计算了这两个模型在这些数据集上的 speech-to-text 性能。我们计算出的 WER 值为 0.28 和 0.16，对应的是 Whisper-Small 和 Wav2Vec2-XLS-R-300M 模型。此外，我们还对使用测试数据集，这些数据集不包括在训练和验证集中，进行了模型的评估。
</details></li>
</ul>
<hr>
<h2 id="Lost-in-the-Middle-How-Language-Models-Use-Long-Contexts"><a href="#Lost-in-the-Middle-How-Language-Models-Use-Long-Contexts" class="headerlink" title="Lost in the Middle: How Language Models Use Long Contexts"></a>Lost in the Middle: How Language Models Use Long Contexts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03172">http://arxiv.org/abs/2307.03172</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nelson-liu/lost-in-the-middle">https://github.com/nelson-liu/lost-in-the-middle</a></li>
<li>paper_authors: Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang</li>
<li>for: 本研究探讨了语言模型在长文本上的表现，以及它们如何使用长文本中的信息。</li>
<li>methods: 本研究使用了多文档问答和关键值检索两个任务来分析语言模型在长文本上的表现。</li>
<li>results: 研究发现，语言模型在长文本上的表现通常最高时 relevante信息出现在输入文本的开头或结尾，并且当模型需要在长文本中检索 relevante信息时，表现会明显下降。此外，研究还发现，even explicitly long-context models 的表现会随输入文本的长度增长而下降。这些发现可以帮助我们更好地理解语言模型如何使用输入文本，并提供新的评估协议 для未来的长文本模型。<details>
<summary>Abstract</summary>
While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.
</details>
<details>
<summary>摘要</summary>
Recent language models have the ability to take long contexts as input, but little is known about how well they use longer contexts. We analyze the performance of language models on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.Here's the text in Traditional Chinese:现代语言模型具有处理长文本上下文的能力，但知道它们如何使用长文本上下文的情况相对少。我们分析了语言模型在多文档问题回答和关键值搜寻两个任务中表现的情况，发现表现通常在输入上下文中的开头或结尾的位置最高，而在中间部分搜寻时表现则明显下降。此外，随着输入上下文的长度增加，表现也会随之下降，即使使用长文本模型。我们的分析可以帮助我们更好地理解语言模型如何使用输入上下文，并提供未来长文本模型的新评估协议。
</details></li>
</ul>
<hr>
<h2 id="T-MARS-Improving-Visual-Representations-by-Circumventing-Text-Feature-Learning"><a href="#T-MARS-Improving-Visual-Representations-by-Circumventing-Text-Feature-Learning" class="headerlink" title="T-MARS: Improving Visual Representations by Circumventing Text Feature Learning"></a>T-MARS: Improving Visual Representations by Circumventing Text Feature Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03132">http://arxiv.org/abs/2307.03132</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/locuslab/t-mars">https://github.com/locuslab/t-mars</a></li>
<li>paper_authors: Pratyush Maini, Sachin Goyal, Zachary C. Lipton, J. Zico Kolter, Aditi Raghunathan</li>
<li>for: 这篇论文主要目标是提出一种新的数据筛选方法，以提高计算机视觉领域的模型学习效果。</li>
<li>methods: 这篇论文使用了一种新的数据筛选方法，即T-MARS（文本蒙版和重新分配），它首先将文本蒙版出现的图像，然后使用CLIP相似性分数来筛选图像。</li>
<li>results: 实验表明，T-MARS在DataComp数据筛选benchmark中的中等规模上，与最佳方法的差距为6.5%（在ImageNet上）和4.7%（在VTAB上）。此外，在不同的数据池大小从2M到64M时，T-MARS的准确率随着数据和计算的扩展呈线性增长。<details>
<summary>Abstract</summary>
Large web-sourced multimodal datasets have powered a slew of new methods for learning general-purpose visual representations, advancing the state of the art in computer vision and revolutionizing zero- and few-shot recognition. One crucial decision facing practitioners is how, if at all, to curate these ever-larger datasets. For example, the creators of the LAION-5B dataset chose to retain only image-caption pairs whose CLIP similarity score exceeded a designated threshold. In this paper, we propose a new state-of-the-art data filtering approach motivated by our observation that nearly 40% of LAION's images contain text that overlaps significantly with the caption. Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features. However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text). Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features -- by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image. Experimentally, T-MARS outperforms the top-ranked method on the "medium scale" of DataComp (a data filtering benchmark) by a margin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic evaluation on various data pool sizes from 2M to 64M shows that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially. Code is available at https://github.com/locuslab/T-MARS.
</details>
<details>
<summary>摘要</summary>
大量网络源的多模式数据集已经推动了一些新的方法来学习通用视觉表示，提高计算机视觉的状态艺术。一个重要的决策是如何CURATE这些越来越大的数据集。例如，LAION-5B数据集的创建者选择了只保留具有 CLIP 相似性分数超过设定的阈值的图像-标签对。在这篇论文中，我们提出了一种新的数据筛选方法， motivated by our observation that nearly 40% of LAION's images contain text that overlaps significantly with the caption. Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features. However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text). Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features -- by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image. Experimentally, T-MARS outperforms the top-ranked method on the "medium scale" of DataComp (a data filtering benchmark) by a margin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic evaluation on various data pool sizes from 2M to 64M shows that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially. 码可以在 https://github.com/locuslab/T-MARS 上获取。
</details></li>
</ul>
<hr>
<h2 id="BLEURT-Has-Universal-Translations-An-Analysis-of-Automatic-Metrics-by-Minimum-Risk-Training"><a href="#BLEURT-Has-Universal-Translations-An-Analysis-of-Automatic-Metrics-by-Minimum-Risk-Training" class="headerlink" title="BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training"></a>BLEURT Has Universal Translations: An Analysis of Automatic Metrics by Minimum Risk Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03131">http://arxiv.org/abs/2307.03131</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/powerpuffpomelo/fairseq_mrt">https://github.com/powerpuffpomelo/fairseq_mrt</a></li>
<li>paper_authors: Yiming Yan, Tao Wang, Chengqi Zhao, Shujian Huang, Jiajun Chen, Mingxuan Wang</li>
<li>for: 这个研究旨在系统地分析和比较各种主流和前沿自动评价 metric，以了解它们在训练机器翻译系统时的导向性。</li>
<li>methods: 通过 Minimum Risk Training (MRT) 方法，研究发现了一些 metric 具有不稳定性问题，如 BLEURT 和 BARTScore 中的通用敌对翻译。经过深入分析，发现这些不稳定性的两个主要原因是训练数据集的分布偏见，以及评价metric的 парадиг。通过加入token级别的约束，提高了评价 metric 的稳定性，从而提高了机器翻译系统的性能。</li>
<li>results: 研究发现，通过提高评价 metric 的稳定性，可以提高机器翻译系统的性能。 codes 可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/powerpuffpomelo/fairseq_mrt%7D">https://github.com/powerpuffpomelo/fairseq_mrt}</a> 上获取。<details>
<summary>Abstract</summary>
Automatic metrics play a crucial role in machine translation. Despite the widespread use of n-gram-based metrics, there has been a recent surge in the development of pre-trained model-based metrics that focus on measuring sentence semantics. However, these neural metrics, while achieving higher correlations with human evaluations, are often considered to be black boxes with potential biases that are difficult to detect. In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems. Through Minimum Risk Training (MRT), we find that certain metrics exhibit robustness defects, such as the presence of universal adversarial translations in BLEURT and BARTScore. In-depth analysis suggests two main causes of these robustness deficits: distribution biases in the training datasets, and the tendency of the metric paradigm. By incorporating token-level constraints, we enhance the robustness of evaluation metrics, which in turn leads to an improvement in the performance of machine translation systems. Codes are available at \url{https://github.com/powerpuffpomelo/fairseq_mrt}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="VisKoP-Visual-Knowledge-oriented-Programming-for-Interactive-Knowledge-Base-Question-Answering"><a href="#VisKoP-Visual-Knowledge-oriented-Programming-for-Interactive-Knowledge-Base-Question-Answering" class="headerlink" title="VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge Base Question Answering"></a>VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge Base Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03130">http://arxiv.org/abs/2307.03130</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijun Yao, Yuanyong Chen, Xin Lv, Shulin Cao, Amy Xin, Jifan Yu, Hailong Jin, Jianjun Xu, Peng Zhang, Lei Hou, Juanzi Li</li>
<li>for: 这个论文是关于Visual Knowledge oriented Programming platform（VisKoP），一种基于人工智能的知识基本问题回答（KBQA）系统，它可以将自然语言问题转化为知识导向程序语言（KoPL），并将 KoPL 程序映射到图形元素中，以便使用图形操作来编辑和调试知识基本（KB）查询。</li>
<li>methods: 这个论文使用了人工智能的神经网络程序生成模块，将自然语言问题转化为 KoPL 程序，并提供了一个高效的 KoPL 执行引擎，以便在大规模知识基本中进行实用KBQA。</li>
<li>results: 实验结果显示，VisKoP 可以高效地解决大规模知识基本中的问题，并且通过人工交互可以修复大量错误的 KoPL 程序，以获得正确的答案。<details>
<summary>Abstract</summary>
We present Visual Knowledge oriented Programming platform (VisKoP), a knowledge base question answering (KBQA) system that integrates human into the loop to edit and debug the knowledge base (KB) queries. VisKoP not only provides a neural program induction module, which converts natural language questions into knowledge oriented program language (KoPL), but also maps KoPL programs into graphical elements. KoPL programs can be edited with simple graphical operators, such as dragging to add knowledge operators and slot filling to designate operator arguments. Moreover, VisKoP provides auto-completion for its knowledge base schema and users can easily debug the KoPL program by checking its intermediate results. To facilitate the practical KBQA on a million-entity-level KB, we design a highly efficient KoPL execution engine for the back-end. Experiment results show that VisKoP is highly efficient and user interaction can fix a large portion of wrong KoPL programs to acquire the correct answer. The VisKoP online demo https://demoviskop.xlore.cn (Stable release of this paper) and https://viskop.xlore.cn (Beta release with new features), highly efficient KoPL engine https://pypi.org/project/kopl-engine, and screencast video https://youtu.be/zAbJtxFPTXo are now publicly available.
</details>
<details>
<summary>摘要</summary>
我们介绍Visual Knowledge oriented Programming平台（VisKoP），是一个基于问题回答（KBQA）系统，具有人类在循环中参与修改和验证知识库（KB）问题的功能。VisKoP不仅提供神经网络问题化模组，将自然语言问题转换为知识导向程式语言（KoPL），并将KoPL程式映射为图形元素。KoPL程式可以通过简单的图形操作进行修改，例如拖曳添加知识操作和填写操作符据。此外，VisKoP提供KBSchema自动完成和用户可以轻松地在KB中验证KoPL程式的中间结果。为了实现实用的KBQA，我们设计了高效的KoPL执行引擎。实验结果显示，VisKoP具有高效性，并且用户互动可以解决大量的错误KoPL程式，以获取正确答案。VisKoP在线demo：https://demoviskop.xlore.cn（稳定版本）和https://viskop.xlore.cn（beta版本，具有新功能），高效的KoPL执行引擎：https://pypi.org/project/kopl-engine，和萤幕录影影片：https://youtu.be/zAbJtxFPTXo现在公开available。
</details></li>
</ul>
<hr>
<h2 id="PREADD-Prefix-Adaptive-Decoding-for-Controlled-Text-Generation"><a href="#PREADD-Prefix-Adaptive-Decoding-for-Controlled-Text-Generation" class="headerlink" title="PREADD: Prefix-Adaptive Decoding for Controlled Text Generation"></a>PREADD: Prefix-Adaptive Decoding for Controlled Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03214">http://arxiv.org/abs/2307.03214</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jonnypei/acl23-preadd">https://github.com/jonnypei/acl23-preadd</a></li>
<li>paper_authors: Jonathan Pei, Kevin Yang, Dan Klein</li>
<li>for: 控制文本生成</li>
<li>methods:  prefix-adaptive decoding（PREADD）</li>
<li>results: 在三个任务中（抑制恶意输出、减少性别偏见、控制情感），PREADD比基eline和auxiliary-expert控制方法提高12%或更多的相对提升。<details>
<summary>Abstract</summary>
We propose Prefix-Adaptive Decoding (PREADD), a flexible method for controlled text generation. Unlike existing methods that use auxiliary expert models to control for attributes, PREADD does not require an external model, instead relying on linearly combining output logits from multiple prompts. Specifically, PREADD contrasts the output logits generated using a raw prompt against those generated using a prefix-prepended prompt, enabling both positive and negative control with respect to any attribute encapsulated by the prefix. We evaluate PREADD on three tasks -- toxic output mitigation, gender bias reduction, and sentiment control -- and find that PREADD outperforms not only prompting baselines, but also an auxiliary-expert control method, by 12% or more in relative gain on our main metrics for each task.
</details>
<details>
<summary>摘要</summary>
我们提出了预先适应编码（PREADD）方法，这是一种灵活的文本生成控制方法。与现有方法不同，PREADD不需要外部模型，而是通过将多个提示的输出拟合成为一个Linear Combination来实现控制。具体来说，PREADD比较使用 Raw Prompt 和Prefix-prepended Prompt两个提示生成的输出拟合，从而实现对任何Attributes所含的控制。我们对三个任务进行评估：毒瘤输出减少、性别偏见减少和 sentiment控制，并发现PREADD在每个任务上比基elinePrompting和auxiliary-expert控制方法提高12%或更多的相对提升。
</details></li>
</ul>
<hr>
<h2 id="Extracting-Multi-valued-Relations-from-Language-Models"><a href="#Extracting-Multi-valued-Relations-from-Language-Models" class="headerlink" title="Extracting Multi-valued Relations from Language Models"></a>Extracting Multi-valued Relations from Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03122">http://arxiv.org/abs/2307.03122</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snehasinghania/multi_valued_slot_filling">https://github.com/snehasinghania/multi_valued_slot_filling</a></li>
<li>paper_authors: Sneha Singhania, Simon Razniewski, Gerhard Weikum</li>
<li>for: 这篇论文是为了探讨隐藏语言表示的多个对象关系知识是否可以提取出来的。</li>
<li>methods: 这篇论文使用了现有的提示技术和新的域知识 incorporating 提示技术来评价候选对象。</li>
<li>results: 研究发现，通过选择对象的可能性大于学习关系特定的阈值得分，可以达到49.5%的 F1 分数。这些结果表明使用LM进行多值槽填任务是具有挑战性，并且激励进一步研究提取隐藏语言表示中的关系知识。<details>
<summary>Abstract</summary>
The widespread usage of latent language representations via pre-trained language models (LMs) suggests that they are a promising source of structured knowledge. However, existing methods focus only on a single object per subject-relation pair, even though often multiple objects are correct. To overcome this limitation, we analyze these representations for their potential to yield materialized multi-object relational knowledge. We formulate the problem as a rank-then-select task. For ranking candidate objects, we evaluate existing prompting techniques and propose new ones incorporating domain knowledge. Among the selection methods, we find that choosing objects with a likelihood above a learned relation-specific threshold gives a 49.5% F1 score. Our results highlight the difficulty of employing LMs for the multi-valued slot-filling task and pave the way for further research on extracting relational knowledge from latent language representations.
</details>
<details>
<summary>摘要</summary>
广泛的语言表现库使用预训语言模型（LM）表明它们是有前途的结构知识来源。然而，现有的方法仅专注在单一物件之间的主题关系对，即使有多个物件是正确的。为了解决这个限制，我们分析这些表现的潜在可以产生实体多个物件关系知识。我们将这个问题推理为排名选择任务。为选择候选物件，我们评估现有的提示技术和新提出的内容知识技术。我们发现，选择关系特定阈值上的可能性大于学习的relation-specific阈值会获得49.5%的F1分数。我们的结果显示使用LM进行多値构造填充任务是具有挑战性的，并且点出了进一步研究抽取语言表现中的关系知识的可能性。
</details></li>
</ul>
<hr>
<h2 id="KoRC-Knowledge-oriented-Reading-Comprehension-Benchmark-for-Deep-Text-Understanding"><a href="#KoRC-Knowledge-oriented-Reading-Comprehension-Benchmark-for-Deep-Text-Understanding" class="headerlink" title="KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text Understanding"></a>KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.03115">http://arxiv.org/abs/2307.03115</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-keg/korc">https://github.com/thu-keg/korc</a></li>
<li>paper_authors: Zijun Yao, Yantao Liu, Xin Lv, Shulin Cao, Jifan Yu, Lei Hou, Juanzi Li</li>
<li>for: 本文提出了一个新的 benchmark，以便检测深度文本理解的能力。</li>
<li>methods: 本文使用了大量知识库来引导注释或大型自然语言处理器（LLM）构建知识问题。</li>
<li>results: 实验结果显示，使用最佳基线方法只能在收odge Distribution test set中 achieve 68.3%和30.0% F1 measure。这表明深度文本理解仍然是一个未解决的挑战。<details>
<summary>Abstract</summary>
Deep text understanding, which requires the connections between a given document and prior knowledge beyond its text, has been highlighted by many benchmarks in recent years. However, these benchmarks have encountered two major limitations. On the one hand, most of them require human annotation of knowledge, which leads to limited knowledge coverage. On the other hand, they usually use choices or spans in the texts as the answers, which results in narrow answer space. To overcome these limitations, we build a new challenging benchmark named KoRc in this paper. Compared with previous benchmarks, KoRC has two advantages, i.e., broad knowledge coverage and flexible answer format. Specifically, we utilize massive knowledge bases to guide annotators or large language models (LLMs) to construct knowledgable questions. Moreover, we use labels in knowledge bases rather than spans or choices as the final answers. We test state-of-the-art models on KoRC and the experimental results show that the strongest baseline only achieves 68.3% and 30.0% F1 measure in the in-distribution and out-of-distribution test set, respectively. These results indicate that deep text understanding is still an unsolved challenge. The benchmark dataset, leaderboard, and baseline methods are released in https://github.com/THU-KEG/KoRC.
</details>
<details>
<summary>摘要</summary>
深层文本理解，需要文档与知识之间的连接，在过去几年中得到了许多benchmark的注意。然而，这些benchmark都面临了两个主要的限制：一方面，大多数它们需要人工标注知识，导致知识覆盖率受限；另一方面，它们通常使用文本中的选择或范围作为答案，这导致答案空间过于窄。为了突破这些限制，我们在这篇论文中构建了一个新的挑战性benchmark名为KoRC。相比之前的benchmark，KoRC具有两个优势：一是广泛的知识覆盖率，二是灵活的答案格式。具体来说，我们利用大量知识库来引导注urger或大语言模型（LLM）构建知识问题。此外，我们使用知识库中的标签而不是选择或范围作为答案。我们对state-of-the-art模型进行测试，实验结果表明，最强基eline只能达到68.3%和30.0%的F1度在分布式和分布式测试集上。这些结果表明，深层文本理解仍然是一个未解决的挑战。benchmark dataset、排名和基eline方法在https://github.com/THU-KEG/KoRC中发布。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/07/cs.CL_2023_07_07/" data-id="clpahu6zk00813h88fq3chuwi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/92/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/91/">91</a><a class="page-number" href="/page/92/">92</a><span class="page-number current">93</span><a class="page-number" href="/page/94/">94</a><a class="page-number" href="/page/95/">95</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/94/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
