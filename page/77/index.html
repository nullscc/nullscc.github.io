
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/77/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_08_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/01/cs.CV_2023_08_01/" class="article-date">
  <time datetime="2023-08-01T13:00:00.000Z" itemprop="datePublished">2023-08-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/01/cs.CV_2023_08_01/">cs.CV - 2023-08-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ELFNet-Evidential-Local-global-Fusion-for-Stereo-Matching"><a href="#ELFNet-Evidential-Local-global-Fusion-for-Stereo-Matching" class="headerlink" title="ELFNet: Evidential Local-global Fusion for Stereo Matching"></a>ELFNet: Evidential Local-global Fusion for Stereo Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00728">http://arxiv.org/abs/2308.00728</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jimmy19991222/elfnet">https://github.com/jimmy19991222/elfnet</a></li>
<li>paper_authors: Jieming Lou, Weide Liu, Zhuo Chen, Fayao Liu, Jun Cheng</li>
<li>for: 这篇论文目的是提出一种基于证据的本地含沟融合（ELF）框架，以便在 стерео匹配中实现不确定性估计和信任度感知。</li>
<li>methods: 该模型不仅预测了分辨率图，还预测了一个基于证据的分辨率图，以考虑 Aleatoric 和 Epistemic 不确定性。具体来说，使用ormal inverse-Gamma分布作为桥梁，实现了多级预测的内部证据融合和多视图信任度感知融合。</li>
<li>results: 实验结果表明，提出的框架可以有效利用多视图信息，并达到了当前最佳的总性能和跨领域泛化性。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/jimmy19991222/ELFNet">https://github.com/jimmy19991222/ELFNet</a> 上下载。<details>
<summary>Abstract</summary>
Although existing stereo matching models have achieved continuous improvement, they often face issues related to trustworthiness due to the absence of uncertainty estimation. Additionally, effectively leveraging multi-scale and multi-view knowledge of stereo pairs remains unexplored. In this paper, we introduce the \textbf{E}vidential \textbf{L}ocal-global \textbf{F}usion (ELF) framework for stereo matching, which endows both uncertainty estimation and confidence-aware fusion with trustworthy heads. Instead of predicting the disparity map alone, our model estimates an evidential-based disparity considering both aleatoric and epistemic uncertainties. With the normal inverse-Gamma distribution as a bridge, the proposed framework realizes intra evidential fusion of multi-level predictions and inter evidential fusion between cost-volume-based and transformer-based stereo matching. Extensive experimental results show that the proposed framework exploits multi-view information effectively and achieves state-of-the-art overall performance both on accuracy and cross-domain generalization.   The codes are available at https://github.com/jimmy19991222/ELFNet.
</details>
<details>
<summary>摘要</summary>
existing 3D matching models have achieved continuous improvement, but they often lack uncertainty estimation, which can lead to trust issues. In addition, effectively leveraging multi-scale and multi-view knowledge of stereo pairs remains unexplored. In this paper, we introduce the 证据based Local-global Fusion (ELF) framework for stereo matching, which includes both uncertainty estimation and confidence-aware fusion. Instead of predicting the disparity map alone, our model estimates an evidential-based disparity that considers both aleatoric and epistemic uncertainties. With the normal inverse-Gamma distribution as a bridge, the proposed framework realizes intra evidential fusion of multi-level predictions and inter evidential fusion between cost-volume-based and transformer-based stereo matching. Extensive experimental results show that the proposed framework effectively utilizes multi-view information and achieves state-of-the-art overall performance in both accuracy and cross-domain generalization.Here's the breakdown of the translation:1. existing 3D matching models (现有的3D匹配模型) - This refers to the existing stereo matching models that have been proposed in the literature.2. have achieved continuous improvement (已经实现了连续改进) - This means that these models have been constantly improved over time, leading to better performance.3. but they often lack uncertainty estimation (但它们经常缺乏不确定性估计) - This means that these models often do not provide uncertainty estimates, which can be a limitation.4. which can lead to trust issues (可能导致信任问题) - This means that the lack of uncertainty estimates can make it difficult to trust the results of the model.5. In addition (此外) - This introduces a new idea that is being proposed in the paper.6. effectively leveraging multi-scale and multi-view knowledge of stereo pairs (有效地利用多级和多视图的双眼匹配知识) - This means that the proposed framework aims to effectively use the information from multiple scales and multiple views of stereo pairs.7. remains unexplored (未探索) - This means that this idea has not been explored in previous research.8. In this paper (在这篇论文中) - This introduces the paper being presented.9. we introduce the 证据based Local-global Fusion (ELF) framework for stereo matching (我们介绍了证据based Local-global Fusion 双眼匹配框架) - This is the main contribution of the paper.10. which includes both uncertainty estimation and confidence-aware fusion (包括不确定性估计和自信感觉的融合) - This means that the proposed framework includes both uncertainty estimates and confidence-aware fusion.11. Instead of predicting the disparity map alone (而不是单独预测分割图) - This means that the proposed framework does not only predict the disparity map, but also includes other information.12. our model estimates an evidential-based disparity (我们的模型估计一种证据基于的分割) - This means that the proposed framework estimates the disparity based on evidence.13. considering both aleatoric and epistemic uncertainties (考虑到随机和知识不确定性) - This means that the proposed framework considers both types of uncertainties.14. With the normal inverse-Gamma distribution as a bridge (使用正常的 inverse-Gamma 分布作为桥梁) - This means that the proposed framework uses a specific distribution to connect the different components of the model.15. the proposed framework realizes intra evidential fusion of multi-level predictions (提案的框架实现了多级预测之间的证据内部融合) - This means that the proposed framework fuses the predictions from different levels using evidence.16. and inter evidential fusion between cost-volume-based and transformer-based stereo matching (以及在基于成本量和基于变换器的双眼匹配之间的证据间融合) - This means that the proposed framework fuses the predictions from different models using evidence.17. Extensive experimental results show that the proposed framework effectively utilizes multi-view information (广泛的实验结果表明提案的框架有效地利用多视图信息) - This means that the proposed framework effectively uses the information from multiple views.18. and achieves state-of-the-art overall performance in both accuracy and cross-domain generalization (并在精度和跨领域泛化性方面达到了顶尖性能) - This means that the proposed framework achieves state-of-the-art performance in both accuracy and cross-domain generalization.19. The codes are available at https://github.com/jimmy19991222/ELFNet (代码可以在https://github.com/jimmy19991222/ELFNet中获取) - This means that the codes for the proposed framework are available online.
</details></li>
</ul>
<hr>
<h2 id="NeRT-Implicit-Neural-Representations-for-General-Unsupervised-Turbulence-Mitigation"><a href="#NeRT-Implicit-Neural-Representations-for-General-Unsupervised-Turbulence-Mitigation" class="headerlink" title="NeRT: Implicit Neural Representations for General Unsupervised Turbulence Mitigation"></a>NeRT: Implicit Neural Representations for General Unsupervised Turbulence Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00622">http://arxiv.org/abs/2308.00622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiyun Jiang, Vivek Boominathan, Ashok Veeraraghavan</li>
<li>for: 提高大气和水层抗抖抖能力</li>
<li>methods: 利用偏函数神经网络和物理正确的倾斜后噪声模型重建不受抖抖影响的清晰图像，只需几十个扭曲输入图像</li>
<li>results: 比state-of-the-art高效，能够消除实际环境中的不控制抖抖，并在连续捕捉视频序列中实现48倍加速<details>
<summary>Abstract</summary>
The atmospheric and water turbulence mitigation problems have emerged as challenging inverse problems in computer vision and optics communities over the years. However, current methods either rely heavily on the quality of the training dataset or fail to generalize over various scenarios, such as static scenes, dynamic scenes, and text reconstructions. We propose a general implicit neural representation for unsupervised atmospheric and water turbulence mitigation (NeRT). NeRT leverages the implicit neural representations and the physically correct tilt-then-blur turbulence model to reconstruct the clean, undistorted image, given only dozens of distorted input images. Moreover, we show that NeRT outperforms the state-of-the-art through various qualitative and quantitative evaluations of atmospheric and water turbulence datasets. Furthermore, we demonstrate the ability of NeRT to eliminate uncontrolled turbulence from real-world environments. Lastly, we incorporate NeRT into continuously captured video sequences and demonstrate $48 \times$ speedup.
</details>
<details>
<summary>摘要</summary>
“大气和水层湍流问题在计算机视觉和光学社区中出现了许多年来，但当前的方法 Either rely heavily on the quality of the training dataset or fail to generalize over various scenarios, such as static scenes, dynamic scenes, and text reconstructions. We propose a general implicit neural representation for unsupervised atmospheric and water turbulence mitigation (NeRT). NeRT leverages the implicit neural representations and the physically correct tilt-then-blur turbulence model to reconstruct the clean, undistorted image, given only dozens of distorted input images. Moreover, we show that NeRT outperforms the state-of-the-art through various qualitative and quantitative evaluations of atmospheric and water turbulence datasets. Furthermore, we demonstrate the ability of NeRT to eliminate uncontrolled turbulence from real-world environments. Lastly, we incorporate NeRT into continuously captured video sequences and demonstrate $48 \times$ speedup.”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Semantic-Consistency-for-Cross-domain-Few-shot-Classification"><a href="#Adaptive-Semantic-Consistency-for-Cross-domain-Few-shot-Classification" class="headerlink" title="Adaptive Semantic Consistency for Cross-domain Few-shot Classification"></a>Adaptive Semantic Consistency for Cross-domain Few-shot Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00727">http://arxiv.org/abs/2308.00727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengchu Lu, Yuanjie Shao, Xiang Wang, Changxin Gao</li>
<li>for: 这篇论文的目的是解决跨领域几少数分类（CD-FSC）中的挑战，即在几少数目标类上实现新的目标类别识别。</li>
<li>methods: 本文提出了一个简单的插件和测试框架ASC（适应Semantic Consistency），通过在调整阶段 reuse source图像，设计适应性负担分配策略，强调目标领域相似的标本，从source领域获取有用的知识，避免静止转移。</li>
<li>results: 实验结果显示，提出的ASC方法能够有效地提高跨领域Robustness，并且在多个benchmark上获得了相对的改善。<details>
<summary>Abstract</summary>
Cross-domain few-shot classification (CD-FSC) aims to identify novel target classes with a few samples, assuming that there exists a domain shift between source and target domains. Existing state-of-the-art practices typically pre-train on source domain and then finetune on the few-shot target data to yield task-adaptive representations. Despite promising progress, these methods are prone to overfitting the limited target distribution since data-scarcity and ignore the transferable knowledge learned in the source domain. To alleviate this problem, we propose a simple plug-and-play Adaptive Semantic Consistency (ASC) framework, which improves cross-domain robustness by preserving source transfer capability during the finetuning stage. Concretely, we reuse the source images in the pretraining phase and design an adaptive weight assignment strategy to highlight the samples similar to target domain, aiming to aggregate informative target-related knowledge from source domain. Subsequently, a semantic consistency regularization is applied to constrain the consistency between the semantic features of the source images output by the source model and target model. In this way, the proposed ASC enables explicit transfer of source domain knowledge to prevent the model from overfitting the target domain. Extensive experiments on multiple benchmarks demonstrate the effectiveness of the proposed ASC, and ASC provides consistent improvements over the baselines. The source code will be released.
</details>
<details>
<summary>摘要</summary>
cross-domain few-shot classification (CD-FSC) targets novel classes with few samples, assuming a domain shift between source and target domains. Existing state-of-the-art methods pre-train on the source domain and fine-tune on few-shot target data to obtain task-adaptive representations. However, these methods are prone to overfitting the limited target distribution and ignore transferable knowledge from the source domain.To address this issue, we propose a simple plug-and-play Adaptive Semantic Consistency (ASC) framework. During the finetuning stage, we reuse the source images from the pretraining phase and assign adaptive weights to highlight samples similar to the target domain. This aims to aggregate informative target-related knowledge from the source domain. Additionally, we apply a semantic consistency regularization to constrain the consistency between the semantic features of the source images output by the source model and the target model. This ensures the explicit transfer of source domain knowledge to prevent overfitting the target domain.Our extensive experiments on multiple benchmarks demonstrate the effectiveness of the proposed ASC, and it consistently outperforms the baselines. The source code will be released.
</details></li>
</ul>
<hr>
<h2 id="Explainable-Cost-Sensitive-Deep-Neural-Networks-for-Brain-Tumor-Detection-from-Brain-MRI-Images-considering-Data-Imbalance"><a href="#Explainable-Cost-Sensitive-Deep-Neural-Networks-for-Brain-Tumor-Detection-from-Brain-MRI-Images-considering-Data-Imbalance" class="headerlink" title="Explainable Cost-Sensitive Deep Neural Networks for Brain Tumor Detection from Brain MRI Images considering Data Imbalance"></a>Explainable Cost-Sensitive Deep Neural Networks for Brain Tumor Detection from Brain MRI Images considering Data Imbalance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00608">http://arxiv.org/abs/2308.00608</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shahariar-shibli/explainable-cost-sensitive-deep-neural-networks-for-brain-tumor-detection-from-brain-mri-images">https://github.com/shahariar-shibli/explainable-cost-sensitive-deep-neural-networks-for-brain-tumor-detection-from-brain-mri-images</a></li>
<li>paper_authors: Md Tanvir Rouf Shawon, G. M. Shahariar Shibli, Farzad Ahmed, Sajib Kumar Saha Joy</li>
<li>for: 这个研究旨在使用卷积神经网络（CNN）、ResNet50、InceptionV3、EfficientNetB0和NASNetMobile模型提高脑肿诊断的效率，以减少手动审查报告的时间和创建一个自动化脑肿分类系统。</li>
<li>methods: 该研究提出了一个自动化管道，包括五种模型：CNN、ResNet50、InceptionV3、EfficientNetB0和NASNetMobile。研究人员对这些模型进行了精心的调整和训练，以便在均衡数据集上评估其性能。</li>
<li>results: 研究人员发现，在均衡数据集上，精心调整的InceptionV3模型可以达到99.33%的准确率。此外，Explainable AI方法也被包含在模型中，以可视化模型的隐藏行为，以便更好地理解其黑obox行为。在均衡数据集上，使用成本敏感神经网络（CS-InceptionV3和CS-CNN）可以达到92.31%的准确率和1.00的回归值。<details>
<summary>Abstract</summary>
This paper presents a research study on the use of Convolutional Neural Network (CNN), ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile models to efficiently detect brain tumors in order to reduce the time required for manual review of the report and create an automated system for classifying brain tumors. An automated pipeline is proposed, which encompasses five models: CNN, ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile. The performance of the proposed architecture is evaluated on a balanced dataset and found to yield an accuracy of 99.33% for fine-tuned InceptionV3 model. Furthermore, Explainable AI approaches are incorporated to visualize the model's latent behavior in order to understand its black box behavior. To further optimize the training process, a cost-sensitive neural network approach has been proposed in order to work with imbalanced datasets which has achieved almost 4% more accuracy than the conventional models used in our experiments. The cost-sensitive InceptionV3 (CS-InceptionV3) and CNN (CS-CNN) show a promising accuracy of 92.31% and a recall value of 1.00 respectively on an imbalanced dataset. The proposed models have shown great potential in improving tumor detection accuracy and must be further developed for application in practical solutions. We have provided the datasets and made our implementations publicly available at - https://github.com/shahariar-shibli/Explainable-Cost-Sensitive-Deep-Neural-Networks-for-Brain-Tumor-Detection-from-Brain-MRI-Images
</details>
<details>
<summary>摘要</summary>
Note: The text has been translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="MonoNext-A-3D-Monocular-Object-Detection-with-ConvNext"><a href="#MonoNext-A-3D-Monocular-Object-Detection-with-ConvNext" class="headerlink" title="MonoNext: A 3D Monocular Object Detection with ConvNext"></a>MonoNext: A 3D Monocular Object Detection with ConvNext</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00596">http://arxiv.org/abs/2308.00596</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcelo Eduardo Pederiva, José Mario De Martino, Alessandro Zimmer</li>
<li>for: This paper aims to improve the accuracy and efficiency of Monocular 3D Object Detection models for autonomous driving perception tasks.</li>
<li>methods: The proposed method, called MonoNext, uses a spatial grid to map objects in the scene and employs the ConvNext network. It requires only 3D bounding box annotated data and is trained using a Multi-Tasking Learning approach.</li>
<li>results: In experiments with the KITTI dataset, MonoNext achieved high precision and competitive performance comparable with state-of-the-art approaches. With additional training data, MonoNext surpassed its initial performance and achieved even higher accuracies.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目标是提高自动驾驶视觉任务中的单目3D对象检测模型的准确率和效率。</li>
<li>methods: 提议的方法是MonoNext，它使用空间网格将场景中的对象映射，并使用ConvNext网络。它只需要3D包 bounds 注释数据，并通过多任务学习方法进行训练。</li>
<li>results: 在使用KITTI数据集进行实验时，MonoNext实现了高精度和与状态前方的性能，并且通过添加更多训练数据，MonoNext的性能超过了它的初始性能。<details>
<summary>Abstract</summary>
Autonomous driving perception tasks rely heavily on cameras as the primary sensor for Object Detection, Semantic Segmentation, Instance Segmentation, and Object Tracking. However, RGB images captured by cameras lack depth information, which poses a significant challenge in 3D detection tasks. To supplement this missing data, mapping sensors such as LIDAR and RADAR are used for accurate 3D Object Detection. Despite their significant accuracy, the multi-sensor models are expensive and require a high computational demand. In contrast, Monocular 3D Object Detection models are becoming increasingly popular, offering a faster, cheaper, and easier-to-implement solution for 3D detections. This paper introduces a different Multi-Tasking Learning approach called MonoNext that utilizes a spatial grid to map objects in the scene. MonoNext employs a straightforward approach based on the ConvNext network and requires only 3D bounding box annotated data. In our experiments with the KITTI dataset, MonoNext achieved high precision and competitive performance comparable with state-of-the-art approaches. Furthermore, by adding more training data, MonoNext surpassed itself and achieved higher accuracies.
</details>
<details>
<summary>摘要</summary>
自适应驾驶感知任务大量依赖于摄像头作为主要感知器，包括对象检测、semantic segmentation、实例 segmentation和对象跟踪。然而，RGB图像由摄像头捕获的缺乏深度信息，对3D检测任务带来了重要挑战。为了补充缺失的数据，映射感知器如LIDAR和RADAR被使用于高精度的3D对象检测。尽管它们具有显著的准确性，但是多感知模型具有高计算成本和高成本。相比之下，单目3D对象检测模型在不断增长，它们具有更快、更便宜、更容易实现的解决方案。本文介绍了一种不同的多任务学习方法called MonoNext，它使用空间网格将场景中的对象映射。MonoNext采用一种简单的approach基于ConvNext网络，只需要3D bounding box注释数据。在我们对KITTI数据集进行实验中，MonoNext实现了高精度和与状态的表现相当。此外，通过添加更多的训练数据，MonoNext超越了自己并实现了更高的准确性。
</details></li>
</ul>
<hr>
<h2 id="Latent-Shift-Gradient-of-Entropy-Helps-Neural-Codecs"><a href="#Latent-Shift-Gradient-of-Entropy-Helps-Neural-Codecs" class="headerlink" title="Latent-Shift: Gradient of Entropy Helps Neural Codecs"></a>Latent-Shift: Gradient of Entropy Helps Neural Codecs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00725">http://arxiv.org/abs/2308.00725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammet Balcilar, Bharath Bhushan Damodaran, Karam Naser, Franck Galpin, Pierre Hellier</li>
<li>for: 这篇论文主要是为了提高图像&#x2F;视频压缩技术的效率和质量。</li>
<li>methods: 这篇论文使用了可训练的编码器，利用了人工智能的学习能力来自适应性能和特定领域的高性能。</li>
<li>results: 该论文经验性地表明，在使用压缩器时可以利用解码器侧的梯度 entropy 来提高压缩率，从而实现 $1-2%$ 的压缩率下降。这种方法是独立于其他改进方法，并且不会影响图像&#x2F;视频的质量。<details>
<summary>Abstract</summary>
End-to-end image/video codecs are getting competitive compared to traditional compression techniques that have been developed through decades of manual engineering efforts. These trainable codecs have many advantages over traditional techniques such as easy adaptation on perceptual distortion metrics and high performance on specific domains thanks to their learning ability. However, state of the art neural codecs does not take advantage of the existence of gradient of entropy in decoding device. In this paper, we theoretically show that gradient of entropy (available at decoder side) is correlated with the gradient of the reconstruction error (which is not available at decoder side). We then demonstrate experimentally that this gradient can be used on various compression methods, leading to a $1-2\%$ rate savings for the same quality. Our method is orthogonal to other improvements and brings independent rate savings.
</details>
<details>
<summary>摘要</summary>
通过端到端图像/视频编码器来比较传统压缩技术，这些可编程编码器具有许多优势，如容易适应人为设计的质量指标和高性能在特定领域，归功于其学习能力。然而，当前领先的神经网络编码器没有利用解码器端的梯度Entropy gradient。在这篇论文中，我们理论上验证了解码器端梯度Entropy gradient与重建错误梯度之间的相关性。然后，我们通过实验表明，这个梯度可以在不同的压缩方法上使用，导致1-2%的比较率节省，同时保持相同的质量。我们的方法与其他改进方法独立，具有独立的率节省。
</details></li>
</ul>
<hr>
<h2 id="Visibility-Enhancement-for-Low-light-Hazy-Scenarios"><a href="#Visibility-Enhancement-for-Low-light-Hazy-Scenarios" class="headerlink" title="Visibility Enhancement for Low-light Hazy Scenarios"></a>Visibility Enhancement for Low-light Hazy Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00591">http://arxiv.org/abs/2308.00591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaoqun Zhuang, Yunfei Liu, Sijia Wen, Feng Lu</li>
<li>for: 增强低光照晦涂图像的可见度</li>
<li>methods: 提议两种关键技术：一种是跨任务一致性推准权重框架，另一种是基于物理学习低光照晦涂数据集的物理学习模型</li>
<li>results: 对多个指标（包括SSIM（9.19%）和PSNR（5.03%））进行了广泛的实验，并且通过用户研究表明了人类视觉效果的必要性和有效性。<details>
<summary>Abstract</summary>
Low-light hazy scenes commonly appear at dusk and early morning. The visual enhancement for low-light hazy images is an ill-posed problem. Even though numerous methods have been proposed for image dehazing and low-light enhancement respectively, simply integrating them cannot deliver pleasing results for this particular task. In this paper, we present a novel method to enhance visibility for low-light hazy scenarios. To handle this challenging task, we propose two key techniques, namely cross-consistency dehazing-enhancement framework and physically based simulation for low-light hazy dataset. Specifically, the framework is designed for enhancing visibility of the input image via fully utilizing the clues from different sub-tasks. The simulation is designed for generating the dataset with ground-truths by the proposed low-light hazy imaging model. The extensive experimental results show that the proposed method outperforms the SOTA solutions on different metrics including SSIM (9.19%) and PSNR(5.03%). In addition, we conduct a user study on real images to demonstrate the effectiveness and necessity of the proposed method by human visual perception.
</details>
<details>
<summary>摘要</summary>
低光照朦胧场景通常出现在晚上和早上。这种视觉提升低光照朦胧图像是一个不定系统的问题。虽然已有许多方法提出了用于图像抑霾和低光照提升，但直接组合这些方法并不能提供满意的结果。在这篇论文中，我们提出了一种新的方法，用于提高低光照朦胧场景的可见度。为解决这个复杂的任务，我们提出了两个关键技术：一是跨任务一致性抑霾提升框架，二是基于物理模型生成的低光照朦胧数据集。具体来说，框架是用于通过完全利用不同任务的各种各样的准确信息来提高输入图像的可见度。数据集是通过我们提出的低光照朦胧摄像机模型来生成的。我们的广泛的实验结果表明，我们的方法在不同的指标上（包括SSIM（9.19%）和PSNR（5.03%））都超过了现有的标准方法。此外，我们还进行了基于真实图像的用户研究，以证明我们的方法的有效性和必要性。
</details></li>
</ul>
<hr>
<h2 id="Relation-Aware-Distribution-Representation-Network-for-Person-Clustering-with-Multiple-Modalities"><a href="#Relation-Aware-Distribution-Representation-Network-for-Person-Clustering-with-Multiple-Modalities" class="headerlink" title="Relation-Aware Distribution Representation Network for Person Clustering with Multiple Modalities"></a>Relation-Aware Distribution Representation Network for Person Clustering with Multiple Modalities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00588">http://arxiv.org/abs/2308.00588</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaijian Liu, Shixiang Tang, Ziyue Li, Zhishuai Li, Lei Bai, Feng Zhu, Rui Zhao</li>
<li>for: 本文旨在提出一种基于关系意识的分布表示网络（RAD-Net），用于Movie parsing和identity-based Movie editing中的人群化。</li>
<li>methods: 本文提出一种基于图构建分布表示和周期更新策略来生成一个模态快意识的分布表示。</li>
<li>results: 对于Video Person-Clustering Dataset（VPCD）和VoxCeleb2多视图 clustering dataset，本文的方法实现了+6%和+8.2%的提升（F-score）。<details>
<summary>Abstract</summary>
Person clustering with multi-modal clues, including faces, bodies, and voices, is critical for various tasks, such as movie parsing and identity-based movie editing. Related methods such as multi-view clustering mainly project multi-modal features into a joint feature space. However, multi-modal clue features are usually rather weakly correlated due to the semantic gap from the modality-specific uniqueness. As a result, these methods are not suitable for person clustering. In this paper, we propose a Relation-Aware Distribution representation Network (RAD-Net) to generate a distribution representation for multi-modal clues. The distribution representation of a clue is a vector consisting of the relation between this clue and all other clues from all modalities, thus being modality agnostic and good for person clustering. Accordingly, we introduce a graph-based method to construct distribution representation and employ a cyclic update policy to refine distribution representation progressively. Our method achieves substantial improvements of +6% and +8.2% in F-score on the Video Person-Clustering Dataset (VPCD) and VoxCeleb2 multi-view clustering dataset, respectively. Codes will be released publicly upon acceptance.
</details>
<details>
<summary>摘要</summary>
人群划分使用多modal的迹象，包括脸、身体和嗓音，是许多任务的关键，如电影分析和基于身份的电影编辑。相关的方法，如多视图划分，通常将多modal的特征项目到共同的特征空间。然而，多modal的迹象特征通常强度不高，因为模式特有的唯一性导致这些方法不适用于人群划分。在这篇论文中，我们提出了关注关系的分布表示网络（RAD-Net），用于生成多modal迹象的分布表示。每个迹象的分布表示为所有modalities的迹象和这个迹象之间的关系，因此是无关modal的和适合人群划分的。我们还提出了基于图的方法来构建分布表示，并使用循环更新策略来进行分布表示的细化。我们的方法在VPCD和VoxCeleb2多视图划分集合上实现了+6%和+8.2%的提升。代码将在接受后公开发布。
</details></li>
</ul>
<hr>
<h2 id="PVG-Progressive-Vision-Graph-for-Vision-Recognition"><a href="#PVG-Progressive-Vision-Graph-for-Vision-Recognition" class="headerlink" title="PVG: Progressive Vision Graph for Vision Recognition"></a>PVG: Progressive Vision Graph for Vision Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00574">http://arxiv.org/abs/2308.00574</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiafu Wu, Jian Li, Jiangning Zhang, Boshen Zhang, Mingmin Chi, Yabiao Wang, Chengjie Wang</li>
<li>for: 这篇论文目的是提出一种Progressive Vision Graph（PVG）架构，用于解决图像识别任务中的不规则对象捕捉问题。</li>
<li>methods: 该架构包括三个主要组件：1）分层分离图构建（PSGC），用于逐渐增加全局图支持的通道数和减少本地支持的通道数，以获得更好的二级相似性信息；2）使用Max pooling和数学期望（MaxE）来归并丰富的邻居信息；3）图错Linear Unit（GraphLU），用于增强低值信息，以降低图像细节信息压缩，避免过度整合。</li>
<li>results: 对主流 benchmark 进行了广泛的实验，显示了PVG在比对 estado-of-the-art 方法时的优势。例如，我们的PVG-S在ImageNet-1K上得到了83.0%的Top-1准确率，比GNN-based ViG-S高出+0.9，同时参数减少18.5%。而最大的PVG-B准确率达到84.2%，高于ViG-B的+0.5。此外，PVG-S在COCO dataset上得到了+1.3 box AP和+0.4 mask AP的提升。<details>
<summary>Abstract</summary>
Convolution-based and Transformer-based vision backbone networks process images into the grid or sequence structures, respectively, which are inflexible for capturing irregular objects. Though Vision GNN (ViG) adopts graph-level features for complex images, it has some issues, such as inaccurate neighbor node selection, expensive node information aggregation calculation, and over-smoothing in the deep layers. To address the above problems, we propose a Progressive Vision Graph (PVG) architecture for vision recognition task. Compared with previous works, PVG contains three main components: 1) Progressively Separated Graph Construction (PSGC) to introduce second-order similarity by gradually increasing the channel of the global graph branch and decreasing the channel of local branch as the layer deepens; 2) Neighbor nodes information aggregation and update module by using Max pooling and mathematical Expectation (MaxE) to aggregate rich neighbor information; 3) Graph error Linear Unit (GraphLU) to enhance low-value information in a relaxed form to reduce the compression of image detail information for alleviating the over-smoothing. Extensive experiments on mainstream benchmarks demonstrate the superiority of PVG over state-of-the-art methods, e.g., our PVG-S obtains 83.0% Top-1 accuracy on ImageNet-1K that surpasses GNN-based ViG-S by +0.9 with the parameters reduced by 18.5%, while the largest PVG-B obtains 84.2% that has +0.5 improvement than ViG-B. Furthermore, our PVG-S obtains +1.3 box AP and +0.4 mask AP gains than ViG-S on COCO dataset.
</details>
<details>
<summary>摘要</summary>
“几何学基础的卷积网络和转换器基础的视觉后缘网络会将图像转化为格子或序列结构，这些结构不适合捕捉不规则的物体。尽管视觉图гра非线性（ViG）采用图гра级别特征来处理复杂图像，但它存在一些问题，如不准确的邻居节点选择、成本过高的邻居信息汇集计算和深层处理过程中的过滤。为解决以上问题，我们提出了进化的视觉图гра（PVG）架构 для视觉识别任务。相比前工作，PVG包含以下三个主要组成部分：1）逐层增强的全球图гра分支（PSGC），通过逐渐增加全球图гра分支的通道和减少本地分支的通道来引入二次相似性; 2）邻居节点信息汇集和更新模块，通过最大池化和数学期望（MaxE）来汇集丰富的邻居信息; 3）图гра梯度Linear Unit（GraphLU），以减少图像细节信息压缩，从而降低过滤。我们在主流的标准库上进行了广泛的实验，显示PVG在前一代方法之上具有优势，例如我们的PVG-S在ImageNet-1K上取得83.0%的Top-1准确率，比GNN基于ViG-S的82.1%高出0.9%，同时参数量减少18.5%。此外，我们的PVG-S在COCO dataset上对应的box AP和mask AP分别提高了+1.3和+0.4。”
</details></li>
</ul>
<hr>
<h2 id="Detecting-Cloud-Presence-in-Satellite-Images-Using-the-RGB-based-CLIP-Vision-Language-Model"><a href="#Detecting-Cloud-Presence-in-Satellite-Images-Using-the-RGB-based-CLIP-Vision-Language-Model" class="headerlink" title="Detecting Cloud Presence in Satellite Images Using the RGB-based CLIP Vision-Language Model"></a>Detecting Cloud Presence in Satellite Images Using the RGB-based CLIP Vision-Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00541">http://arxiv.org/abs/2308.00541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mikolaj Czerkawski, Robert Atkinson, Christos Tachtatzis</li>
<li>for: 本研究用CLIP抽象语言模型来检测卫星图像中的云彩。</li>
<li>methods: 研究使用CLIP模型进行云存在检测的多种方法，包括文本提示的纯零shot操作以及多种微调方法。</li>
<li>results: CLIP模型可以在不同数据集和感知器类型（Sentinel-2和Landsat-8）上实现非rivial的云存在检测性能，并且可以泛化到不同的感知Modalities和感知频谱。<details>
<summary>Abstract</summary>
This work explores capabilities of the pre-trained CLIP vision-language model to identify satellite images affected by clouds. Several approaches to using the model to perform cloud presence detection are proposed and evaluated, including a purely zero-shot operation with text prompts and several fine-tuning approaches. Furthermore, the transferability of the methods across different datasets and sensor types (Sentinel-2 and Landsat-8) is tested. The results that CLIP can achieve non-trivial performance on the cloud presence detection task with apparent capability to generalise across sensing modalities and sensing bands. It is also found that a low-cost fine-tuning stage leads to a strong increase in true negative rate. The results demonstrate that the representations learned by the CLIP model can be useful for satellite image processing tasks involving clouds.
</details>
<details>
<summary>摘要</summary>
这项研究探讨了预训练的CLIP视觉语言模型在找到遮盖云图像时的能力。研究提出了使用文本提示进行零shot操作以及多种精度调整方法来实现云存在检测。此外，研究还测试了这些方法在不同的数据集和探测器类型（Sentinel-2和Landsat-8）之间的传输性。结果显示CLIP可以在云存在检测任务中实现非负性表现，并且表现出对探测Modalities和探测频谱的通用性。另外，一种低成本的精度调整阶段可以带来明显增加真正的零分数率。结果表明CLIP模型学习的表征可以对卫星图像处理任务中的云有用。
</details></li>
</ul>
<hr>
<h2 id="Visual-attention-information-can-be-traced-on-cortical-response-but-not-on-the-retina-evidence-from-electrophysiological-mouse-data-using-natural-images-as-stimuli"><a href="#Visual-attention-information-can-be-traced-on-cortical-response-but-not-on-the-retina-evidence-from-electrophysiological-mouse-data-using-natural-images-as-stimuli" class="headerlink" title="Visual attention information can be traced on cortical response but not on the retina: evidence from electrophysiological mouse data using natural images as stimuli"></a>Visual attention information can be traced on cortical response but not on the retina: evidence from electrophysiological mouse data using natural images as stimuli</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00526">http://arxiv.org/abs/2308.00526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikos Melanitis, Konstantina Nikita</li>
<li>for: 这个研究探讨了视觉注意力的生物基础，以计算方式研究视觉注意力的生物基础。</li>
<li>methods: 研究使用了眼球和大脑电生物学数据来分析视觉注意力的生物基础。视觉刺激是自然图像，展示了真实世界场景。</li>
<li>results: 研究发现，在初级视觉层（V1）中，约10%的神经元响应不同于突出性视觉区域。视觉注意力信息不存在于眼球响应中，似乎眼球停留不了视觉注意力信息。<details>
<summary>Abstract</summary>
Visual attention forms the basis of understanding the visual world. In this work we follow a computational approach to investigate the biological basis of visual attention. We analyze retinal and cortical electrophysiological data from mouse. Visual Stimuli are Natural Images depicting real world scenes. Our results show that in primary visual cortex (V1), a subset of around $10\%$ of the neurons responds differently to salient versus non-salient visual regions. Visual attention information was not traced in retinal response. It appears that the retina remains naive concerning visual attention; cortical response gets modulated to interpret visual attention information. Experimental animal studies may be designed to further explore the biological basis of visual attention we traced in this study. In applied and translational science, our study contributes to the design of improved visual prostheses systems -- systems that create artificial visual percepts to visually impaired individuals by electronic implants placed on either the retina or the cortex.
</details>
<details>
<summary>摘要</summary>
视觉注意力是视觉世界理解的基础。在这项工作中，我们采用计算机方法研究生物基础的视觉注意力。我们分析了鼠脑和脊椎电physiological数据。视觉刺激是自然图像，描绘现实生活场景。我们的结果表明，在主视觉层（V1）中，约10%的神经元响应不同于突出 versus 非突出视觉区域。视觉注意力信息没有踪迹在Retina响应中。似乎retina免疫Visual attention信息； cortical response被修饰以解读视觉注意力信息。在生物基础研究中，我们可以通过进一步的实验动物研究来探索我们在这项研究中跟踪的生物基础。在应用和翻译科学中，我们的研究对于设计改进的视觉 prótesis系统做出了贡献，这些系统通过电子植入在Retina或cortex上为视障人群创造人工视觉感受。
</details></li>
</ul>
<hr>
<h2 id="NormKD-Normalized-Logits-for-Knowledge-Distillation"><a href="#NormKD-Normalized-Logits-for-Knowledge-Distillation" class="headerlink" title="NormKD: Normalized Logits for Knowledge Distillation"></a>NormKD: Normalized Logits for Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00520">http://arxiv.org/abs/2308.00520</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gizi1/NormKD">https://github.com/gizi1/NormKD</a></li>
<li>paper_authors: Zhihao Chi, Tu Zheng, Hengjia Li, Zheng Yang, Boxi Wu, Binbin Lin, Deng Cai</li>
<li>for: 提高logit基于知识传递的性能，尤其是在温度参数的调整方面。</li>
<li>methods: 提出Normalized Knowledge Distillation（NormKD），通过自适应调整每个样本的温度来更好地传递样本特有的知识。</li>
<li>results: NormKD在CIRAR-100和ImageNet上的图像分类 task 中比vanilla KD更好，而且可以轻松地应用于其他logit基于方法，达到类似或更好的性能。<details>
<summary>Abstract</summary>
Logit based knowledge distillation gets less attention in recent years since feature based methods perform better in most cases. Nevertheless, we find it still has untapped potential when we re-investigate the temperature, which is a crucial hyper-parameter to soften the logit outputs. For most of the previous works, it was set as a fixed value for the entire distillation procedure. However, as the logits from different samples are distributed quite variously, it is not feasible to soften all of them to an equal degree by just a single temperature, which may make the previous work transfer the knowledge of each sample inadequately. In this paper, we restudy the hyper-parameter temperature and figure out its incapability to distill the knowledge from each sample sufficiently when it is a single value. To address this issue, we propose Normalized Knowledge Distillation (NormKD), with the purpose of customizing the temperature for each sample according to the characteristic of the sample's logit distribution. Compared to the vanilla KD, NormKD barely has extra computation or storage cost but performs significantly better on CIRAR-100 and ImageNet for image classification. Furthermore, NormKD can be easily applied to the other logit based methods and achieve better performance which can be closer to or even better than the feature based method.
</details>
<details>
<summary>摘要</summary>
这些年来，逻辑基本的知识传递几乎没有收到关注，因为基于特征的方法在大多数情况下表现更好。然而，我们发现这些逻辑基本方法仍然具有尚未发掘的潜力，尤其是在温度参数的重新调整方面。在前一些作品中，温度通常是 Fix 的整个知识传递程序中的一个固定值。然而，这些逻辑出力的不同样本之间的分布相当多元，因此将所有逻辑出力软化到相同的温度可能无法传递每个样本的知识充分。在这篇论文中，我们重新研究温度参数，发现它在传递每个样本的知识方面存在不足的缺陷。为了解决这个问题，我们提出 Normalized Knowledge Distillation（NormKD），将温度调整为每个样本的逻辑出力分布特点。相比于普通的 KD，NormKD 只有额外的计算或储存成本，但在 CIRAR-100 和 ImageNet 上的图像分类 task 中表现出色，与特征基本方法相比，其表现更好。此外，NormKD 可以轻松地应用到其他逻辑基本方法，并在这些方法上表现更好，甚至可以与特征基本方法相比。
</details></li>
</ul>
<hr>
<h2 id="Markerless-human-pose-estimation-for-biomedical-applications-a-survey"><a href="#Markerless-human-pose-estimation-for-biomedical-applications-a-survey" class="headerlink" title="Markerless human pose estimation for biomedical applications: a survey"></a>Markerless human pose estimation for biomedical applications: a survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00519">http://arxiv.org/abs/2308.00519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Avogaro, Federico Cunico, Bodo Rosenhahn, Francesco Setti</li>
<li>for: 本研究旨在为医疗领域提供 markerless 人体姿态估计（HPE）的概述，并评估其在生物医学应用中的可能性。</li>
<li>methods: 本研究使用了多种 HPE 方法，包括深度学习、核积分析、模糊学习等，以及对这些方法的评估和比较。</li>
<li>results: 研究发现，HPE 技术在评估 двига功能、 neuromuscular rehabilitation 和步态分析等领域具有潜在的应用前景，并且可能成为远程医疗的一种重要工具。<details>
<summary>Abstract</summary>
Markerless Human Pose Estimation (HPE) proved its potential to support decision making and assessment in many fields of application. HPE is often preferred to traditional marker-based Motion Capture systems due to the ease of setup, portability, and affordable cost of the technology. However, the exploitation of HPE in biomedical applications is still under investigation. This review aims to provide an overview of current biomedical applications of HPE. In this paper, we examine the main features of HPE approaches and discuss whether or not those features are of interest to biomedical applications. We also identify those areas where HPE is already in use and present peculiarities and trends followed by researchers and practitioners. We include here 25 approaches to HPE and more than 40 studies of HPE applied to motor development assessment, neuromuscolar rehabilitation, and gait & posture analysis. We conclude that markerless HPE offers great potential for extending diagnosis and rehabilitation outside hospitals and clinics, toward the paradigm of remote medical care.
</details>
<details>
<summary>摘要</summary>
无标记人 pose 估计（HPE）在许多应用领域已经证明了其潜力，如运动科学、医学、心理学等。由于HPE技术的设置容易、可移植和成本低廉，因此经常被选择于标记型动作捕捉系统。然而，HPE在生物医学应用中的利用仍然在调查阶段。本文提供了生物医学应用中HPE的现状和趋势。我们分析了HPE方法的主要特点，并评估了这些特点是否有利于生物医学应用。我们还提出了HPE在 motor 发展评估、 neuromuscular rehabilitation 和步态分析等领域的应用。最后，我们结论 markerless HPE 有广泛的扩展 диагности和rehabilitation 的可能性，从而实现远程医疗的目标。
</details></li>
</ul>
<hr>
<h2 id="Relational-Contrastive-Learning-for-Scene-Text-Recognition"><a href="#Relational-Contrastive-Learning-for-Scene-Text-Recognition" class="headerlink" title="Relational Contrastive Learning for Scene Text Recognition"></a>Relational Contrastive Learning for Scene Text Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00508">http://arxiv.org/abs/2308.00508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thundervvv/rclstr">https://github.com/thundervvv/rclstr</a></li>
<li>paper_authors: Jinglei Zhang, Tiancheng Lin, Yi Xu, Kai Chen, Rui Zhang</li>
<li>for: 本研究旨在提高场景文本识别的自动化方法，通过 incorporating semantic priors from words 来提供有效的自我超vised标签，以便进行表征学学习。</li>
<li>methods: 本研究提出了一种名为 RCLSTR（关系对比学习）的框架，通过 rearrange、层次结构和交互来扩展文本关系，从而提高表征学学习的效果。</li>
<li>results: 实验表明，RCLSTR 方法可以在场景文本识别中提高表征质量，并且超越了当前的自动化 STR 方法。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Context-aware methods achieved great success in supervised scene text recognition via incorporating semantic priors from words. We argue that such prior contextual information can be interpreted as the relations of textual primitives due to the heterogeneous text and background, which can provide effective self-supervised labels for representation learning. However, textual relations are restricted to the finite size of dataset due to lexical dependencies, which causes the problem of over-fitting and compromises representation robustness. To this end, we propose to enrich the textual relations via rearrangement, hierarchy and interaction, and design a unified framework called RCLSTR: Relational Contrastive Learning for Scene Text Recognition. Based on causality, we theoretically explain that three modules suppress the bias caused by the contextual prior and thus guarantee representation robustness. Experiments on representation quality show that our method outperforms state-of-the-art self-supervised STR methods. Code is available at https://github.com/ThunderVVV/RCLSTR.
</details>
<details>
<summary>摘要</summary>
Context-aware methods have achieved great success in supervised scene text recognition by incorporating semantic priors from words. We argue that such prior contextual information can be interpreted as the relations of textual primitives due to the heterogeneous text and background, which can provide effective self-supervised labels for representation learning. However, textual relations are restricted to the finite size of dataset due to lexical dependencies, which causes the problem of over-fitting and compromises representation robustness. To this end, we propose to enrich the textual relations via rearrangement, hierarchy, and interaction, and design a unified framework called RCLSTR: Relational Contrastive Learning for Scene Text Recognition. Based on causality, we theoretically explain that three modules suppress the bias caused by the contextual prior and thus guarantee representation robustness. Experiments on representation quality show that our method outperforms state-of-the-art self-supervised STR methods. Code is available at <https://github.com/ThunderVVV/RCLSTR>.
</details></li>
</ul>
<hr>
<h2 id="Improved-Prognostic-Prediction-of-Pancreatic-Cancer-Using-Multi-Phase-CT-by-Integrating-Neural-Distance-and-Texture-Aware-Transformer"><a href="#Improved-Prognostic-Prediction-of-Pancreatic-Cancer-Using-Multi-Phase-CT-by-Integrating-Neural-Distance-and-Texture-Aware-Transformer" class="headerlink" title="Improved Prognostic Prediction of Pancreatic Cancer Using Multi-Phase CT by Integrating Neural Distance and Texture-Aware Transformer"></a>Improved Prognostic Prediction of Pancreatic Cancer Using Multi-Phase CT by Integrating Neural Distance and Texture-Aware Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00507">http://arxiv.org/abs/2308.00507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hexin Dong, Jiawen Yao, Yuxing Tang, Mingze Yuan, Yingda Xia, Jian Zhou, Hong Lu, Jingren Zhou, Bin Dong, Le Lu, Li Zhang, Zaiyi Liu, Yu Shi, Ling Zhang<br>for:这个论文主要是为了提高阈癌动脉细胞癌（PDAC）患者的预后预测。methods:这个论文使用了一种新的学习型神经距离，以描述不同患者的CT图像中 tumor 和附近重要血管之间的精确关系，并将其作为预后预测的重要特征。此外，这个论文还提出了一种基于 CNN 和 transformer 模块的多相照 CT 图像中动态肿瘤相关文本特征提取方法，以提高预后预测的准确性。results:对于 multi-center（n&#x3D;4）数据集中的 1,070 名PDAC患者，经过广泛评估和比较，研究人员发现了提出的方法在外测集中（包括三个中心）的临床效果是 statistically significant（p&lt;0.001），并且发现这个方法可以准确地预测PDAC患者的全身生存率。此外，研究人员还发现，在外测集中，这个方法是预后预测中最强的预测因素之一，并且有可能与已知的临床因素相结合，以选择需要neoadjuvant therapy的患者。<details>
<summary>Abstract</summary>
Pancreatic ductal adenocarcinoma (PDAC) is a highly lethal cancer in which the tumor-vascular involvement greatly affects the resectability and, thus, overall survival of patients. However, current prognostic prediction methods fail to explicitly and accurately investigate relationships between the tumor and nearby important vessels. This paper proposes a novel learnable neural distance that describes the precise relationship between the tumor and vessels in CT images of different patients, adopting it as a major feature for prognosis prediction. Besides, different from existing models that used CNNs or LSTMs to exploit tumor enhancement patterns on dynamic contrast-enhanced CT imaging, we improved the extraction of dynamic tumor-related texture features in multi-phase contrast-enhanced CT by fusing local and global features using CNN and transformer modules, further enhancing the features extracted across multi-phase CT images. We extensively evaluated and compared the proposed method with existing methods in the multi-center (n=4) dataset with 1,070 patients with PDAC, and statistical analysis confirmed its clinical effectiveness in the external test set consisting of three centers. The developed risk marker was the strongest predictor of overall survival among preoperative factors and it has the potential to be combined with established clinical factors to select patients at higher risk who might benefit from neoadjuvant therapy.
</details>
<details>
<summary>摘要</summary>
胆囊ductal adenocarcinoma (PDAC) 是一种高度致命的癌症，肿块-血管交叠对病人的手术可能性和全身存活率产生很大影响。然而，现有的预测方法不能准确地和肿块之间的关系进行详细调查。这篇论文提出了一种新的学习型神经距离，用于描述不同病人的 CT 图像中肿块和附近重要血管之间的精确关系，并将其作为预测方法的主要特征。此外，与现有模型使用 CNN 或 LSTM 挖掘肿块增强 Pattern 在动态增强 CT 图像中，我们改进了在多相增强 CT 图像中提取动态肿块相关的文本特征，并将本地和全局特征 fusion 使用 CNN 和 transformer 模块，进一步提高了在多相 CT 图像中提取的特征。我们对多中心（n=4）数据集中的 1,070 名PDAC患者进行了广泛的评估和比较，并统计分析表明了我们的方法在外部测试集（包括三个中心）中的临床效果。我们开发的风险标记是PDAC患者的全身存活率最强的预测因素之一，并且它有可能与已知的临床因素相结合，以选择可能需要neoadjuvanttherapy的患者。
</details></li>
</ul>
<hr>
<h2 id="An-L2-Normalized-Spatial-Attention-Network-For-Accurate-And-Fast-Classification-Of-Brain-Tumors-In-2D-T1-Weighted-CE-MRI-Images"><a href="#An-L2-Normalized-Spatial-Attention-Network-For-Accurate-And-Fast-Classification-Of-Brain-Tumors-In-2D-T1-Weighted-CE-MRI-Images" class="headerlink" title="An L2-Normalized Spatial Attention Network For Accurate And Fast Classification Of Brain Tumors In 2D T1-Weighted CE-MRI Images"></a>An L2-Normalized Spatial Attention Network For Accurate And Fast Classification Of Brain Tumors In 2D T1-Weighted CE-MRI Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00491">http://arxiv.org/abs/2308.00491</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juliadietlmeier/mri_image_classification">https://github.com/juliadietlmeier/mri_image_classification</a></li>
<li>paper_authors: Grace Billingsley, Julia Dietlmeier, Vivek Narayanaswamy, Andreas Spanias, Noel E. OConnor</li>
<li>for: 这个论文是为了开发一种高精度和快速的脑肿图像分类网络，用于识别MRI图像中的脑肿。</li>
<li>methods: 该论文使用了一种l2-normalized spatial attention机制，用于防止过拟合 During 训练。</li>
<li>results: 对于一个复杂的2D T1-weighted CE-MRI数据集，该模型可以与所有轻量级方法相比，在准确性方面表现出色。 ensemble with the pretrained VGG16可以更高的准确率，但是需要增加执行速度。<details>
<summary>Abstract</summary>
We propose an accurate and fast classification network for classification of brain tumors in MRI images that outperforms all lightweight methods investigated in terms of accuracy. We test our model on a challenging 2D T1-weighted CE-MRI dataset containing three types of brain tumors: Meningioma, Glioma and Pituitary. We introduce an l2-normalized spatial attention mechanism that acts as a regularizer against overfitting during training. We compare our results against the state-of-the-art on this dataset and show that by integrating l2-normalized spatial attention into a baseline network we achieve a performance gain of 1.79 percentage points. Even better accuracy can be attained by combining our model in an ensemble with the pretrained VGG16 at the expense of execution speed. Our code is publicly available at https://github.com/juliadietlmeier/MRI_image_classification
</details>
<details>
<summary>摘要</summary>
我们提出了一种精度快速的分类网络，用于分类MRI图像中的脑肿瘤，超越了所有轻量级方法的精度。我们在一个复杂的2D T1束缩MRI数据集上测试了我们的模型，该数据集包含三种脑肿瘤：膝盖肿瘤、 glioma 和 hypophyseal。我们引入了L2正则化的空间注意力机制，以防止过拟合 durante el entrenamiento。我们与状态的报告进行比较，并显示通过将L2正则化的空间注意力integrated into a baseline network，我们在该数据集上 achievement 1.79 percentage points的性能提升。可以通过将我们的模型与预训练的VGG16 ensemble来实现更高的准确率，但是这将导致执行速度的降低。我们的代码可以在https://github.com/juliadietlmeier/MRI_image_classification中下载。
</details></li>
</ul>
<hr>
<h2 id="DINO-CXR-A-self-supervised-method-based-on-vision-transformer-for-chest-X-ray-classification"><a href="#DINO-CXR-A-self-supervised-method-based-on-vision-transformer-for-chest-X-ray-classification" class="headerlink" title="DINO-CXR: A self supervised method based on vision transformer for chest X-ray classification"></a>DINO-CXR: A self supervised method based on vision transformer for chest X-ray classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00475">http://arxiv.org/abs/2308.00475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammadreza Shakouri, Fatemeh Iranmanesh, Mahdi Eftekhari</li>
<li>for: 这个研究是为了开发一种基于自我超vised学习的肺X射线分类方法，以解决医疗图像分析领域中数据limited的问题。</li>
<li>methods: 该方法基于一种自我超vised方法DINO，使用了一种视力 трансформер来进行肺X射线分类。</li>
<li>results: 研究表明，提议的方法可以在肺炎和COVID-19检测中达到比较好的效果，并且在需要更少标注数据的情况下表现出了比 state-of-the-art 方法更高的准确率。<details>
<summary>Abstract</summary>
The limited availability of labeled chest X-ray datasets is a significant bottleneck in the development of medical imaging methods. Self-supervised learning (SSL) can mitigate this problem by training models on unlabeled data. Furthermore, self-supervised pretraining has yielded promising results in visual recognition of natural images but has not been given much consideration in medical image analysis. In this work, we propose a self-supervised method, DINO-CXR, which is a novel adaptation of a self-supervised method, DINO, based on a vision transformer for chest X-ray classification. A comparative analysis is performed to show the effectiveness of the proposed method for both pneumonia and COVID-19 detection. Through a quantitative analysis, it is also shown that the proposed method outperforms state-of-the-art methods in terms of accuracy and achieves comparable results in terms of AUC and F-1 score while requiring significantly less labeled data.
</details>
<details>
<summary>摘要</summary>
限量的胸部X射线数据的可用性是医学影像分析领域的主要瓶颈。自我超级学习（SSL）可以减轻这个问题，通过训练无标注数据上的模型。然而，在医学图像分析领域中，自我超级学习还没有受到很多关注。在这项工作中，我们提出了一种自我超级学习方法，名为DINO-CXR，这是基于视力变换器的胸部X射线分类方法的一种新的适应。我们进行了比较分析，以示方法的效果在肺炎和COVID-19检测中。通过量化分析，我们也证明了提议方法在精度和AUC和F-1分数方面的表现比前任方法更佳，同时需要训练数据量更少。
</details></li>
</ul>
<hr>
<h2 id="Is-Last-Layer-Re-Training-Truly-Sufficient-for-Robustness-to-Spurious-Correlations"><a href="#Is-Last-Layer-Re-Training-Truly-Sufficient-for-Robustness-to-Spurious-Correlations" class="headerlink" title="Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?"></a>Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00473">http://arxiv.org/abs/2308.00473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Phuong Quynh Le, Jörg Schlötterer, Christin Seifert</li>
<li>for: 提高预测模型在具有相关特征的样本组中的准确率。</li>
<li>methods: 使用 Deep Feature Reweighting (DFR) 方法，重新训练分类模型的最后一层，使用小型、归一化的数据集来适应实际数据。</li>
<li>results: DFR 方法可以提高预测模型在具有相关特征的样本组中的准确率，但是它仍然可能受到偶极相关性的影响。<details>
<summary>Abstract</summary>
Models trained with empirical risk minimization (ERM) are known to learn to rely on spurious features, i.e., their prediction is based on undesired auxiliary features which are strongly correlated with class labels but lack causal reasoning. This behavior particularly degrades accuracy in groups of samples of the correlated class that are missing the spurious feature or samples of the opposite class but with the spurious feature present. The recently proposed Deep Feature Reweighting (DFR) method improves accuracy of these worst groups. Based on the main argument that ERM mods can learn core features sufficiently well, DFR only needs to retrain the last layer of the classification model with a small group-balanced data set. In this work, we examine the applicability of DFR to realistic data in the medical domain. Furthermore, we investigate the reasoning behind the effectiveness of last-layer retraining and show that even though DFR has the potential to improve the accuracy of the worst group, it remains susceptible to spurious correlations.
</details>
<details>
<summary>摘要</summary>
Empirical risk minimization (ERM) 模型受训练后可能会学习干扰特征，即其预测基于 auxiliary 特征和类别标签之间强相关性，但缺乏 causal 理解。这种行为尤其是在类别标签相关的样本组中具有干扰特征的欠落或相反类别标签的样本具有干扰特征时，预测精度会下降。 reciently proposed Deep Feature Reweighting (DFR) 方法可以提高这些最差的组的准确率。基于主要的 argumen that ERM 模型可以够好地学习核心特征，DFR 只需要在类别模型的最后一层进行小型、 balance 的数据集重新训练。在这项工作中，我们检查了 DFR 在医疗领域的实际数据上的适用性。此外，我们还investigated  last-layer 重新训练的理解，并证明了 DFR 具有改善最差组的准确率的潜在能力，但它仍然受到干扰关系的影响。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Learning-Approach-for-Virtual-Contrast-Enhancement-in-Contrast-Enhanced-Spectral-Mammography"><a href="#A-Deep-Learning-Approach-for-Virtual-Contrast-Enhancement-in-Contrast-Enhanced-Spectral-Mammography" class="headerlink" title="A Deep Learning Approach for Virtual Contrast Enhancement in Contrast Enhanced Spectral Mammography"></a>A Deep Learning Approach for Virtual Contrast Enhancement in Contrast Enhanced Spectral Mammography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00471">http://arxiv.org/abs/2308.00471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aurora Rofena, Valerio Guarrasi, Marina Sarli, Claudia Lucia Piccolo, Matteo Sammarra, Bruno Beomonte Zobel, Paolo Soda</li>
<li>for: 这个研究是为了提高胸部摄像的检测精确度和安全性，使用深度生成模型来实现虚拟增强对CESM的应用。</li>
<li>methods: 这个研究使用了深度生成模型，包括自适应网络和两个生成对抗网络，将低能量图像转换为虚拟增强的混合图像。</li>
<li>results: 研究结果显示，使用CycleGAN生成模型可以生成高质量的虚拟混合图像，并且与临床专业人员的评价相符，显示这种方法具有潜在的应用前景。<details>
<summary>Abstract</summary>
Contrast Enhanced Spectral Mammography (CESM) is a dual-energy mammographic imaging technique that first needs intravenously administration of an iodinated contrast medium; then, it collects both a low-energy image, comparable to standard mammography, and a high-energy image. The two scans are then combined to get a recombined image showing contrast enhancement. Despite CESM diagnostic advantages for breast cancer diagnosis, the use of contrast medium can cause side effects, and CESM also beams patients with a higher radiation dose compared to standard mammography. To address these limitations this work proposes to use deep generative models for virtual contrast enhancement on CESM, aiming to make the CESM contrast-free as well as to reduce the radiation dose. Our deep networks, consisting of an autoencoder and two Generative Adversarial Networks, the Pix2Pix, and the CycleGAN, generate synthetic recombined images solely from low-energy images. We perform an extensive quantitative and qualitative analysis of the model's performance, also exploiting radiologists' assessments, on a novel CESM dataset that includes 1138 images that, as a further contribution of this work, we make publicly available. The results show that CycleGAN is the most promising deep network to generate synthetic recombined images, highlighting the potential of artificial intelligence techniques for virtual contrast enhancement in this field.
</details>
<details>
<summary>摘要</summary>
增强画像肿瘤成像（CESM）是一种双能量肿瘤成像技术，需要静脉注射iodinated contrast媒体后，先收集低能量图像，与标准肿瘤成像相同，然后与高能量图像组合得到重组图像，显示增强效果。 despite CESM的诊断优势，使用contrast媒体可能会导致副作用，同时CESM也会对病人辐射更高的辐射剂量。为解决这些限制，这项工作提出使用深度生成模型进行虚拟增强，以使CESM成为无contrast和减少辐射剂量的。我们的深度网络包括一个自适应网络和两个生成对抗网络，包括Pix2Pix和CycleGAN，通过将低能量图像转换成合成的重组图像。我们对新的CESM数据集进行了广泛的量化和质量分析，同时采用了放射学家的评估，包括1138张图像，并将其公开发布。结果表明CycleGAN是最有前途的深度网络，生成合成重组图像，强调人工智能技术在这个领域的潜力。
</details></li>
</ul>
<hr>
<h2 id="Center-Contrastive-Loss-for-Metric-Learning"><a href="#Center-Contrastive-Loss-for-Metric-Learning" class="headerlink" title="Center Contrastive Loss for Metric Learning"></a>Center Contrastive Loss for Metric Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00458">http://arxiv.org/abs/2308.00458</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bolun Cai, Pengfei Xiong, Shangxuan Tian</li>
<li>for: 提高图像embedding的推理能力和准确率</li>
<li>methods: 使用Center Contrastive Loss函数，维护类别中心银行，并将类别中心与查询数据点进行对比，以减少内类差异和提高对类差异</li>
<li>results: 使用标准网络（ResNet50）和提出的损失函数，实现图像embedding的状态 Footnote 1 和更快的收敛速度，见图1<details>
<summary>Abstract</summary>
Contrastive learning is a major studied topic in metric learning. However, sampling effective contrastive pairs remains a challenge due to factors such as limited batch size, imbalanced data distribution, and the risk of overfitting. In this paper, we propose a novel metric learning function called Center Contrastive Loss, which maintains a class-wise center bank and compares the category centers with the query data points using a contrastive loss. The center bank is updated in real-time to boost model convergence without the need for well-designed sample mining. The category centers are well-optimized classification proxies to re-balance the supervisory signal of each class. Furthermore, the proposed loss combines the advantages of both contrastive and classification methods by reducing intra-class variations and enhancing inter-class differences to improve the discriminative power of embeddings. Our experimental results, as shown in Figure 1, demonstrate that a standard network (ResNet50) trained with our loss achieves state-of-the-art performance and faster convergence.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>研究主题：对比学习是 metric learning 中的一大研究领域。然而，选取有效对比对 remainschallenge 因为有限的批处理大小、数据分布不均衡和避免过拟合。在本文中，我们提出了一种新的 metric learning 函数 called Center Contrastive Loss，它保持一个类别中心银行并将查询数据点与类别中心进行对比，使用对比损失来训练模型。类别中心银行在实时更新，以促进模型的收敛，无需特别的样本挖掘。类别中心 acts as a well-optimized classification proxy，帮助平衡每个类的监督信号。此外，我们的损失函数结合了对比和分类方法的优点，减少了内类差异和提高了间类差异，以提高嵌入的推理力。我们的实验结果，如图1所示，显示了一个标准网络（ResNet50）通过我们的损失函数实现了状态略领先的性能和更快的收敛。
</details></li>
</ul>
<hr>
<h2 id="ViT2EEG-Leveraging-Hybrid-Pretrained-Vision-Transformers-for-EEG-Data"><a href="#ViT2EEG-Leveraging-Hybrid-Pretrained-Vision-Transformers-for-EEG-Data" class="headerlink" title="ViT2EEG: Leveraging Hybrid Pretrained Vision Transformers for EEG Data"></a>ViT2EEG: Leveraging Hybrid Pretrained Vision Transformers for EEG Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00454">http://arxiv.org/abs/2308.00454</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ruiqirichard/eegeyenet-vit">https://github.com/ruiqirichard/eegeyenet-vit</a></li>
<li>paper_authors: Ruiqi Yang, Eric Modesitt</li>
<li>for: 这个研究用于应用混合式视觉transformer（ViT）模型，已经预训在ImageNet上，来解决电enzephalogram（EEG）预测任务。</li>
<li>methods: 这个模型使用了一个混合式ViT模型，在ImageNet上预训，然后为EEG数据进行精致调整。</li>
<li>results: 这个方法在EEG预测任务中表现出了明显的提升，比其他模型，包括一个相同架构的ViT模型，而且这些模型没有ImageNet的预训 weights。这个发现挑战了传统的模型通用性理论，表明transformer模型在不同的任务上可以提供有用的假设。<details>
<summary>Abstract</summary>
In this study, we demonstrate the application of a hybrid Vision Transformer (ViT) model, pretrained on ImageNet, on an electroencephalogram (EEG) regression task. Despite being originally trained for image classification tasks, when fine-tuned on EEG data, this model shows a notable increase in performance compared to other models, including an identical architecture ViT trained without the ImageNet weights. This discovery challenges the traditional understanding of model generalization, suggesting that Transformer models pretrained on seemingly unrelated image data can provide valuable priors for EEG regression tasks with an appropriate fine-tuning pipeline.   The success of this approach suggests that the features extracted by ViT models in the context of visual tasks can be readily transformed for the purpose of EEG predictive modeling. We recommend utilizing this methodology not only in neuroscience and related fields, but generally for any task where data collection is limited by practical, financial, or ethical constraints. Our results illuminate the potential of pretrained models on tasks that are clearly distinct from their original purpose.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们展示了使用混合型视力变换器（ViT）模型，先前在ImageNet上预训练，在电энцеfalogram（EEG）预测任务中应用。尽管这种模型原本是用于图像分类任务，但当 fine-tuning 在 EEG 数据上时，这种模型显示了与其他模型相比 Notable 的性能提升，包括一个相同的架构 ViT 未使用 ImageNet 权重。这一发现挑战了传统的模型泛化理解，表明在 seemingly unrelated 图像数据上预训练 Transformer 模型可以为 EEG 预测任务提供有价值的先验知识。这种方法的成功表明了 ViT 模型在视觉任务上抽取的特征可以轻松地转换为 EEG 预测模型的目的。我们建议在 neuroscience 和相关领域不仅使用这种方法，而且在任务数据收集受限于实用、金融或道德因素的情况下，一般来说，这种方法可以广泛应用。我们的结果探讨了预训练模型在任务上的潜在可能性，并证明了这种方法在任务上的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="A-Majority-Invariant-Approach-to-Patch-Robustness-Certification-for-Deep-Learning-Models"><a href="#A-Majority-Invariant-Approach-to-Patch-Robustness-Certification-for-Deep-Learning-Models" class="headerlink" title="A Majority Invariant Approach to Patch Robustness Certification for Deep Learning Models"></a>A Majority Invariant Approach to Patch Robustness Certification for Deep Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00452">http://arxiv.org/abs/2308.00452</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kio-cs/majorcert">https://github.com/kio-cs/majorcert</a></li>
<li>paper_authors: Qilin Zhou, Zhengyuan Wei, Haipeng Wang, W. K. Chan</li>
<li>for: 验证深度学习模型是否可以由特定的补丁修改预测标签。</li>
<li>methods: 使用 MajorCert 算法，首先找到同一个样本上同一个补丁区域可以操作的所有可能的标签集，然后对这些组合进行元素综合，最后检查元素稳定性是否保持不变以确认样本的合法性。</li>
<li>results:  MajorCert 可以快速和高效地验证深度学习模型的patch robustness，并且可以验证样本是否可以被修改为预测不同的标签。<details>
<summary>Abstract</summary>
Patch robustness certification ensures no patch within a given bound on a sample can manipulate a deep learning model to predict a different label. However, existing techniques cannot certify samples that cannot meet their strict bars at the classifier or patch region levels. This paper proposes MajorCert. MajorCert firstly finds all possible label sets manipulatable by the same patch region on the same sample across the underlying classifiers, then enumerates their combinations element-wise, and finally checks whether the majority invariant of all these combinations is intact to certify samples.
</details>
<details>
<summary>摘要</summary>
patch 强健证明ensure no patch within a given bound on a sample can manipulate a deep learning model to predict a different label. However, existing techniques cannot certify samples that cannot meet their strict bars at the classifier or patch region levels. This paper proposes MajorCert. MajorCert first finds all possible label sets manipulatable by the same patch region on the same sample across the underlying classifiers, then enumerates their combinations element-wise, and finally checks whether the majority invariant of all these combinations is intact to certify samples.Here's the breakdown of the translation:* "patch" is translated as " patch" (缝合)* "robustness" is translated as "强健" (qiáng jiàn)* "certification" is translated as "证明" (zhèng míng)* "cannot" is translated as "不能" (bù néng)* "meet their strict bars" is translated as "能满足他们的严格标准" (néng mǎn shòu tā men de jiān gròng bāng yào)* "MajorCert" is translated as " MajorCert" (主要证明)* "firstly" is translated as "首先" (shǒu xiān)* "finds" is translated as "找到" (zhao dào)* "all possible label sets" is translated as "所有可能的标签集" (suǒ yǒu kě néng de tiǎo jiè jít)* "manipulatable" is translated as "可操作" (kě còng zhí)* "same patch region" is translated as "同一个缝合区域" (tóng yī gè pò huì qū nèi)* "same sample" is translated as "同一个样本" (tóng yī gè yàng běn)* "across the underlying classifiers" is translated as "在基础分类器下" (zhī yào qī yǐ jī zhì)* "enumerates their combinations" is translated as "列出 их组合" (liè chuī yǐ zhòng zhì)* "element-wise" is translated as "元素方式" (yuán xīng fāng shì)* "finally" is translated as "最后" (zuì hòu)* "checks whether the majority invariant" is translated as "检查是否存在多数不变量" (jiǎn chá zhèng yě bù zhāng yì)* "is intact" is translated as "完整" (wán zhèng)I hope this helps! Let me know if you have any further questions.
</details></li>
</ul>
<hr>
<h2 id="Physics-Driven-Spectrum-Consistent-Federated-Learning-for-Palmprint-Verification"><a href="#Physics-Driven-Spectrum-Consistent-Federated-Learning-for-Palmprint-Verification" class="headerlink" title="Physics-Driven Spectrum-Consistent Federated Learning for Palmprint Verification"></a>Physics-Driven Spectrum-Consistent Federated Learning for Palmprint Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00451">http://arxiv.org/abs/2308.00451</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zi-yuanyang/psfed-palm">https://github.com/zi-yuanyang/psfed-palm</a></li>
<li>paper_authors: Ziyuan Yang, Andrew Beng Jin Teoh, Bob Zhang, Lu Leng, Yi Zhang</li>
<li>for: 本文旨在提出一种基于物理学的分布式学习方法，以提高palmprint认证的精度和安全性。</li>
<li>methods: 该方法首先将客户端分为短波和长波两个组，根据本地图像的波长范围。然后，引入了短波和长波的引导模型，将本地模型的优化方向约束在 anchor model 的方向上。特别是，我们定义了一种spectrum-consistent loss函数，使得模型参数和特征表示与其对应的引导模型保持一致。最后，我们对本地模型进行了一些约束，以确保它们与全局模型保持一致，从而避免模型漂移。</li>
<li>results: 我们通过了广泛的实验 validate the effectiveness of our proposed PSFed-Palm approach.  despite only a limited number of training data, the proposed PSFed-Palm demonstrates compelling performance.<details>
<summary>Abstract</summary>
Palmprint as biometrics has gained increasing attention recently due to its discriminative ability and robustness. However, existing methods mainly improve palmprint verification within one spectrum, which is challenging to verify across different spectrums. Additionally, in distributed server-client-based deployment, palmprint verification systems predominantly necessitate clients to transmit private data for model training on the centralized server, thereby engendering privacy apprehensions. To alleviate the above issues, in this paper, we propose a physics-driven spectrum-consistent federated learning method for palmprint verification, dubbed as PSFed-Palm. PSFed-Palm draws upon the inherent physical properties of distinct wavelength spectrums, wherein images acquired under similar wavelengths display heightened resemblances. Our approach first partitions clients into short- and long-spectrum groups according to the wavelength range of their local spectrum images. Subsequently, we introduce anchor models for short- and long-spectrum, which constrain the optimization directions of local models associated with long- and short-spectrum images. Specifically, a spectrum-consistent loss that enforces the model parameters and feature representation to align with their corresponding anchor models is designed. Finally, we impose constraints on the local models to ensure their consistency with the global model, effectively preventing model drift. This measure guarantees spectrum consistency while protecting data privacy, as there is no need to share local data. Extensive experiments are conducted to validate the efficacy of our proposed PSFed-Palm approach. The proposed PSFed-Palm demonstrates compelling performance despite only a limited number of training data. The codes will be released at https://github.com/Zi-YuanYang/PSFed-Palm.
</details>
<details>
<summary>摘要</summary>
Recently, palmprint recognition has gained increasing attention due to its discriminative ability and robustness. However, existing methods mainly focus on improving palmprint verification within a single spectrum, which is challenging to verify across different spectrums. Moreover, in distributed server-client-based deployments, palmprint verification systems typically require clients to transmit private data for model training on the centralized server, raising privacy concerns. To address these issues, in this paper, we propose a physics-driven spectrum-consistent federated learning method for palmprint verification, called PSFed-Palm.PSFed-Palm leverages the inherent physical properties of distinct wavelength spectrums, where images acquired under similar wavelengths exhibit enhanced resemblances. Our approach first divides clients into short- and long-spectrum groups based on the wavelength range of their local spectrum images. We then introduce anchor models for short- and long-spectrum, which constrain the optimization directions of local models associated with long- and short-spectrum images. Specifically, we design a spectrum-consistent loss that enforces the model parameters and feature representation to align with their corresponding anchor models. Finally, we impose constraints on the local models to ensure their consistency with the global model, effectively preventing model drift. This approach ensures spectrum consistency while protecting data privacy, as there is no need to share local data.We conduct extensive experiments to validate the effectiveness of our proposed PSFed-Palm approach. The results show that the proposed PSFed-Palm demonstrates impressive performance despite using a limited number of training data. The codes will be released at https://github.com/Zi-YuanYang/PSFed-Palm.
</details></li>
</ul>
<hr>
<h2 id="FLatten-Transformer-Vision-Transformer-using-Focused-Linear-Attention"><a href="#FLatten-Transformer-Vision-Transformer-using-Focused-Linear-Attention" class="headerlink" title="FLatten Transformer: Vision Transformer using Focused Linear Attention"></a>FLatten Transformer: Vision Transformer using Focused Linear Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00442">http://arxiv.org/abs/2308.00442</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leaplabthu/flatten-transformer">https://github.com/leaplabthu/flatten-transformer</a></li>
<li>paper_authors: Dongchen Han, Xuran Pan, Yizeng Han, Shiji Song, Gao Huang</li>
<li>for: 提高自然语言处理 task 中 Transformer 模型的效率和表达力</li>
<li>methods: 提出一种新的 Linear Attention 模块，通过分析 Linear Attention 的缺陷和限制，提出一种简单 yet effective 的 mapping function，以及一种高效的排名修复模块，以提高 Linear Attention 的表达力而不增加计算复杂度</li>
<li>results: 在多个 benchmark 上实现了高效和表达力的 Linear Attention 模型，并且可以应用于多种进阶的视觉 Transformer 模型<details>
<summary>Abstract</summary>
The quadratic computation complexity of self-attention has been a persistent challenge when applying Transformer models to vision tasks. Linear attention, on the other hand, offers a much more efficient alternative with its linear complexity by approximating the Softmax operation through carefully designed mapping functions. However, current linear attention approaches either suffer from significant performance degradation or introduce additional computation overhead from the mapping functions. In this paper, we propose a novel Focused Linear Attention module to achieve both high efficiency and expressiveness. Specifically, we first analyze the factors contributing to the performance degradation of linear attention from two perspectives: the focus ability and feature diversity. To overcome these limitations, we introduce a simple yet effective mapping function and an efficient rank restoration module to enhance the expressiveness of self-attention while maintaining low computation complexity. Extensive experiments show that our linear attention module is applicable to a variety of advanced vision Transformers, and achieves consistently improved performances on multiple benchmarks. Code is available at https://github.com/LeapLabTHU/FLatten-Transformer.
</details>
<details>
<summary>摘要</summary>
归一式计算复杂性的问题在应用Transformer模型于视觉任务中成为了一个持续的挑战。相比之下，线性注意力则提供了一个非常高效的替代方案，其计算复杂性 linear。然而，现有的线性注意力方法 Either suffer from significant performance degradation or introduce additional computation overhead from the mapping functions. In this paper, we propose a novel Focused Linear Attention module to achieve both high efficiency and expressiveness. Specifically, we first analyze the factors contributing to the performance degradation of linear attention from two perspectives: the focus ability and feature diversity. To overcome these limitations, we introduce a simple yet effective mapping function and an efficient rank restoration module to enhance the expressiveness of self-attention while maintaining low computation complexity. Extensive experiments show that our linear attention module is applicable to a variety of advanced vision Transformers, and achieves consistently improved performances on multiple benchmarks. Code is available at https://github.com/LeapLabTHU/FLatten-Transformer.Here's the translation in Traditional Chinese:返回式计算复杂性的问题在应用Transformer模型于视觉任务中成为了一个持续的挑战。相比之下，线性注意力则提供了一个非常高效的替代方案，其计算复杂性 linear。然而，现有的线性注意力方法 Either suffer from significant performance degradation or introduce additional computation overhead from the mapping functions. In this paper, we propose a novel Focused Linear Attention module to achieve both high efficiency and expressiveness. Specifically, we first analyze the factors contributing to the performance degradation of linear attention from two perspectives: the focus ability and feature diversity. To overcome these limitations, we introduce a simple yet effective mapping function and an efficient rank restoration module to enhance the expressiveness of self-attention while maintaining low computation complexity. Extensive experiments show that our linear attention module is applicable to a variety of advanced vision Transformers, and achieves consistently improved performances on multiple benchmarks. Code is available at https://github.com/LeapLabTHU/FLatten-Transformer.
</details></li>
</ul>
<hr>
<h2 id="Multiscale-Global-and-Regional-Feature-Learning-Using-Co-Tuplet-Loss-for-Offline-Handwritten-Signature-Verification"><a href="#Multiscale-Global-and-Regional-Feature-Learning-Using-Co-Tuplet-Loss-for-Offline-Handwritten-Signature-Verification" class="headerlink" title="Multiscale Global and Regional Feature Learning Using Co-Tuplet Loss for Offline Handwritten Signature Verification"></a>Multiscale Global and Regional Feature Learning Using Co-Tuplet Loss for Offline Handwritten Signature Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00428">http://arxiv.org/abs/2308.00428</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ashleyfhh/hansig">https://github.com/ashleyfhh/hansig</a></li>
<li>paper_authors: Fu-Hsien Huang, Hsin-Min Lu</li>
<li>for: 手写签名验证方法的开发，尤其是面对法律和金融机构的认可。</li>
<li>methods: 我们提出了一种基于多尺度全球和地方特征学习网络（MGRNet）和新的协 tuplet 损失函数，以实现手写签名验证系统的自动化。 MGRNet 可以同时捕捉全面签名roke信息和细节的本地差异，从而提高验证精度。</li>
<li>results: 我们在四个不同语言的数据集上进行了实验，并证明了我们的方法在对比州前方法的情况下表现出色。<details>
<summary>Abstract</summary>
Handwritten signature verification is a significant biometric verification method widely acknowledged by legal and financial institutions. However, the development of automatic signature verification systems poses challenges due to inter-writer similarity, intra-writer variations, and the limited number of signature samples. To address these challenges, we propose a multiscale global and regional feature learning network (MGRNet) with the co-tuplet loss, a new metric learning loss, for offline handwritten signature verification. MGRNet jointly learns global and regional information from various spatial scales and integrates it to generate discriminative features. Consequently, it can capture overall signature stroke information while detecting detailed local differences between genuine and skilled-forged signatures. To enhance the discriminative capability of our network further, we propose the co-tuplet loss, which simultaneously considers multiple positive and negative examples to learn distance metrics. By dealing with inter-writer similarity and intra-writer variations and focusing on informative examples, the co-tuplet loss addresses the limitations of typical metric learning losses. Additionally, we develop HanSig, a large-scale Chinese signature dataset, to facilitate the development of robust systems for this script. The dataset is available at https://github.com/ashleyfhh/HanSig. Experimental results on four benchmark datasets in different languages demonstrate the promising performance of our method in comparison to state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
手写签名验证是一种广泛被法律和金融机构承认的生物认证方法。然而，自动化签名验证系统的开发受到了多种挑战，包括写手之间的相似性、写手内部的变化以及签名样本的有限性。为了解决这些挑战，我们提出了一种基于多尺度全球和地方特征学习网络（MGRNet）的方法，并使用了一种新的距离学习损失函数——co-tuplet损失。MGRNet可以同时学习全球和地方信息，并将其集成到生成特征上。因此，它可以捕捉签名行书中的总信息，同时检测签名的细节差异。为了进一步提高我们的网络的拒杂性，我们提出了co-tuplet损失，该损失函数同时考虑多个正例和负例，以学习距离度量。通过处理写手之间的相似性和写手内部的变化，co-tuplet损失函数可以减少传统距离学习损失函数的局限性。此外，我们还开发了一个大规模的中文签名数据集——HanSig，以便为这种文字编写更加稳健的系统。HanSig数据集可以在GitHub上下载，链接为https://github.com/ashleyfhh/HanSig。我们的实验结果表明，我们的方法在不同语言的四个标准数据集上的表现具有前所未有的扩展性。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Generate-Training-Datasets-for-Robust-Semantic-Segmentation"><a href="#Learning-to-Generate-Training-Datasets-for-Robust-Semantic-Segmentation" class="headerlink" title="Learning to Generate Training Datasets for Robust Semantic Segmentation"></a>Learning to Generate Training Datasets for Robust Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02535">http://arxiv.org/abs/2308.02535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marwane Hariat, Olivier Laurent, Rémi Kazmierczak, Shihao Zhang, Andrei Bursuc, Angela Yao, Gianni Franchi</li>
<li>for: 提高 semantic segmentation 技术的Robustness，尤其在安全关键应用中。</li>
<li>methods: 利用 label-to-image 生成器和 image-to-label 分割模型的同工合作，设计并训练 Robusta  conditional 生成随机对抗网络，生成真实和可能的异常或异常图像。</li>
<li>results: 对 proposed 生成模型进行了深入研究，评估下游分割网络的性能和可靠性，并示出该方法可以在实际干扰和数据分布变化中提高 semantic segmentation 技术的Robustness。<details>
<summary>Abstract</summary>
Semantic segmentation techniques have shown significant progress in recent years, but their robustness to real-world perturbations and data samples not seen during training remains a challenge, particularly in safety-critical applications. In this paper, we propose a novel approach to improve the robustness of semantic segmentation techniques by leveraging the synergy between label-to-image generators and image-to-label segmentation models. Specifically, we design and train Robusta, a novel robust conditional generative adversarial network to generate realistic and plausible perturbed or outlier images that can be used to train reliable segmentation models. We conduct in-depth studies of the proposed generative model, assess the performance and robustness of the downstream segmentation network, and demonstrate that our approach can significantly enhance the robustness of semantic segmentation techniques in the face of real-world perturbations, distribution shifts, and out-of-distribution samples. Our results suggest that this approach could be valuable in safety-critical applications, where the reliability of semantic segmentation techniques is of utmost importance and comes with a limited computational budget in inference. We will release our code shortly.
</details>
<details>
<summary>摘要</summary>
Semantic segmentation技术在最近几年内已经取得了显著的进步，但它们对实际世界中的扰动和训练不包含的数据样本仍然是一个挑战，特别是在安全关键应用中。在这篇论文中，我们提议一种 novel approach 来提高 semantic segmentation 技术的可靠性，通过利用标签到图生成器和图像到标签分割模型之间的共同作用。我们设计并训练了 Robusta，一种 novel robust conditional generative adversarial network，以生成真实和可能的扰动或异常图像，用于训练可靠的分割模型。我们进行了深入的研究这种生成模型，评估下游分割网络的性能和可靠性，并证明了我们的方法可以在实际世界中的扰动、分布变换和异常样本下提高 semantic segmentation 技术的可靠性。我们的结果表明，这种方法在安全关键应用中具有有限的计算预算，并且可以提供可靠的分割结果。我们即将发布我们的代码。
</details></li>
</ul>
<hr>
<h2 id="Space-Debris-Are-Deep-Learning-based-Image-Enhancements-part-of-the-Solution"><a href="#Space-Debris-Are-Deep-Learning-based-Image-Enhancements-part-of-the-Solution" class="headerlink" title="Space Debris: Are Deep Learning-based Image Enhancements part of the Solution?"></a>Space Debris: Are Deep Learning-based Image Enhancements part of the Solution?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00408">http://arxiv.org/abs/2308.00408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michele Jamrozik, Vincent Gaudillière, Mohamed Adel Musallam, Djamila Aouada</li>
<li>for: 这个研究旨在解决随机相机拍摄的太空垃圾照片中的限制和图像遗留问题。</li>
<li>methods: 本研究使用深度神经网络（DNN）解决方案，包括一个混合的UNet-ResNet34深度学习架构，并将其预训于ImageNet dataset上。</li>
<li>results: 根据视觉比较，本研究所开发的UNet模型能够成功地更正太空照片中的图像价化问题，并且值得进一步的研究以减少计算复杂性。<details>
<summary>Abstract</summary>
The volume of space debris currently orbiting the Earth is reaching an unsustainable level at an accelerated pace. The detection, tracking, identification, and differentiation between orbit-defined, registered spacecraft, and rogue/inactive space ``objects'', is critical to asset protection. The primary objective of this work is to investigate the validity of Deep Neural Network (DNN) solutions to overcome the limitations and image artefacts most prevalent when captured with monocular cameras in the visible light spectrum. In this work, a hybrid UNet-ResNet34 Deep Learning (DL) architecture pre-trained on the ImageNet dataset, is developed. Image degradations addressed include blurring, exposure issues, poor contrast, and noise. The shortage of space-generated data suitable for supervised DL is also addressed. A visual comparison between the URes34P model developed in this work and the existing state of the art in deep learning image enhancement methods, relevant to images captured in space, is presented. Based upon visual inspection, it is determined that our UNet model is capable of correcting for space-related image degradations and merits further investigation to reduce its computational complexity.
</details>
<details>
<summary>摘要</summary>
现在地球轨道上围绕着太空垃圾的量已经达到了不可持续的水平，速度也在加速。检测、跟踪、识别和区分在轨道上定义的注册空craft和遗弃/无活空“物体”是 kritical 的。本工作的主要目标是检验深度神经网络（DNN）解决方案能否在单目相机采集的可见光谱中解决限制和图像artefacts。在这种工作中，我们开发了一种混合UNet-ResNet34深度学习（DL）架构，该架构在ImageNet数据集上进行预训练。处理的图像降低包括模糊、曝光问题、低对比度和噪声。由于在空间中获得适合超vised DL的数据不足，我们也解决了这一问题。在这种情况下，我们对URes34P模型进行了视觉比较，与现有的深度学习图像改进方法相关的图像 capture 在空间中的情况进行了比较。根据视觉检查，我们的UNet模型能够正确地修正空间中的图像降低，并且值得进一步研究以降低计算复杂度。
</details></li>
</ul>
<hr>
<h2 id="Metrics-to-Quantify-Global-Consistency-in-Synthetic-Medical-Images"><a href="#Metrics-to-Quantify-Global-Consistency-in-Synthetic-Medical-Images" class="headerlink" title="Metrics to Quantify Global Consistency in Synthetic Medical Images"></a>Metrics to Quantify Global Consistency in Synthetic Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00402">http://arxiv.org/abs/2308.00402</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Scholz, Benedikt Wiestler, Daniel Rueckert, Martin J. Menten</li>
<li>for: 本研究旨在提供一种能够量化生成图像的全局一致性的方法，以便在医学图像处理中进行数据增强或多Modalities图像翻译。</li>
<li>methods: 本研究使用了supervised neural networks来预测和比较图像中的特征属性，以量化图像的全局一致性。在一个没有标签数据的情况下，我们还使用了self-supervised trained network来预测图像的含义特征，以量化图像的全局一致性。</li>
<li>results: 我们的结果表明，可以使用supervised neural networks来预测图像中的特征属性，以量化图像的全局一致性。而使用self-supervised trained network来预测图像的含义特征，可以在没有标签数据的情况下量化图像的全局一致性，但是这种方法的敏感度相对较低。与已有的metric，如FID，相比，我们的方法可以直接量化单个生成图像的全局一致性，从而为医学图像处理中的数据增强和多Modalities图像翻译提供一种新的分析方法。<details>
<summary>Abstract</summary>
Image synthesis is increasingly being adopted in medical image processing, for example for data augmentation or inter-modality image translation. In these critical applications, the generated images must fulfill a high standard of biological correctness. A particular requirement for these images is global consistency, i.e an image being overall coherent and structured so that all parts of the image fit together in a realistic and meaningful way. Yet, established image quality metrics do not explicitly quantify this property of synthetic images. In this work, we introduce two metrics that can measure the global consistency of synthetic images on a per-image basis. To measure the global consistency, we presume that a realistic image exhibits consistent properties, e.g., a person's body fat in a whole-body MRI, throughout the depicted object or scene. Hence, we quantify global consistency by predicting and comparing explicit attributes of images on patches using supervised trained neural networks. Next, we adapt this strategy to an unlabeled setting by measuring the similarity of implicit image features predicted by a self-supervised trained network. Our results demonstrate that predicting explicit attributes of synthetic images on patches can distinguish globally consistent from inconsistent images. Implicit representations of images are less sensitive to assess global consistency but are still serviceable when labeled data is unavailable. Compared to established metrics, such as the FID, our method can explicitly measure global consistency on a per-image basis, enabling a dedicated analysis of the biological plausibility of single synthetic images.
</details>
<details>
<summary>摘要</summary>
医疗图像处理中的图像合成技术在不断普及，例如数据增强或多Modalities图像翻译。在这些敏感应用中，生成的图像必须满足高水平的生物准确性。特别是，图像合成的Global consistency是一个重要的要求，即图像的整体准确和结构化，使所有图像部分在真实和有意义的方式相互协调。然而，现有的图像质量指标不直接量化这个属性。在这种情况下，我们引入了两种可以测量图像合成的全局一致性的指标。为了测量全局一致性，我们假设一个真实的图像会在整个物体或场景中展现一致的属性，例如全身MRI中的身体脂肪。因此，我们量化全局一致性 by predicting和比较图像中的显式属性，例如人体的部分特征。然后，我们采用了一种无监督的设置，通过测量图像中的隐藏特征来衡量图像的全局一致性。我们的结果表明，可以通过预测图像中的显式属性来分辨全局一致性和不一致性的图像。而隐藏特征的测量可以在没有标注数据时仍提供有用的服务。与已有的指标，如FID，相比，我们的方法可以直接测量单个图像的全局一致性，从而启用专门分析合成图像的生物可能性。
</details></li>
</ul>
<hr>
<h2 id="VideoPro-A-Visual-Analytics-Approach-for-Interactive-Video-Programming"><a href="#VideoPro-A-Visual-Analytics-Approach-for-Interactive-Video-Programming" class="headerlink" title="VideoPro: A Visual Analytics Approach for Interactive Video Programming"></a>VideoPro: A Visual Analytics Approach for Interactive Video Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00401">http://arxiv.org/abs/2308.00401</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianben He, Xingbo Wang, Kam Kwai Wong, Xijie Huang, Changjian Chen, Zixin Chen, Fengjie Wang, Min Zhu, Huamin Qu</li>
<li>for: 本研究旨在提供一种可靠的视觉分析方法，帮助在实际视频分析中建立supervised机器学习模型，从而提高模型的性能和可靠性。</li>
<li>methods: 本研究使用计算机视觉技术提取视频中的人类理解度的事件，并将这些事件作为标签函数模板进行 Labeling 操作。我们还提出了一种两阶段模板挖掘算法，用于挖掘这些事件的顺序模式，以便更好地支持数据标签。</li>
<li>results: 我们通过两个案例研究和专家采访，证明了我们的方法的效率和可靠性。我们的方法可以帮助建立大规模、可靠的视频数据标签，从而提高模型的性能和可靠性。<details>
<summary>Abstract</summary>
Constructing supervised machine learning models for real-world video analysis require substantial labeled data, which is costly to acquire due to scarce domain expertise and laborious manual inspection. While data programming shows promise in generating labeled data at scale with user-defined labeling functions, the high dimensional and complex temporal information in videos poses additional challenges for effectively composing and evaluating labeling functions. In this paper, we propose VideoPro, a visual analytics approach to support flexible and scalable video data programming for model steering with reduced human effort. We first extract human-understandable events from videos using computer vision techniques and treat them as atomic components of labeling functions. We further propose a two-stage template mining algorithm that characterizes the sequential patterns of these events to serve as labeling function templates for efficient data labeling. The visual interface of VideoPro facilitates multifaceted exploration, examination, and application of the labeling templates, allowing for effective programming of video data at scale. Moreover, users can monitor the impact of programming on model performance and make informed adjustments during the iterative programming process. We demonstrate the efficiency and effectiveness of our approach with two case studies and expert interviews.
</details>
<details>
<summary>摘要</summary>
建立指导式机器学习模型需要巨量的标注数据，但获得这些数据很容易成本高涨，主要因为领域专业知识缺乏和手动检查困难。虽然数据编程显示了可能性，但视频数据高维和复杂的时间信息增加了标注函数的组合和评估的挑战。本文提出了VideoPro，一种视觉分析方法，以支持灵活和可扩展的视频数据编程，以降低人工努力。我们首先从视频中提取了人类理解的事件，并将其作为标注函数的原子组件。我们还提出了两个阶段的模板挖掘算法，用于 characteHere's the text with some additional information about the translation:I used the Google Translate API to translate the text into Simplified Chinese. The translation is in the form of a formal written text, with a focus on accuracy and readability. I used the "Translate" option in the Google Cloud Console to generate the translation, and I selected "Simplified Chinese" as the target language.Please note that the translation may not be perfect, and there may be some nuances or cultural references that are lost in translation. Additionally, the translation may not be idiomatic, and some phrases or expressions may not be commonly used in Simplified Chinese. If you have any specific questions or concerns, please feel free to ask, and I'll do my best to assist you.
</details></li>
</ul>
<hr>
<h2 id="DriveAdapter-Breaking-the-Coupling-Barrier-of-Perception-and-Planning-in-End-to-End-Autonomous-Driving"><a href="#DriveAdapter-Breaking-the-Coupling-Barrier-of-Perception-and-Planning-in-End-to-End-Autonomous-Driving" class="headerlink" title="DriveAdapter: Breaking the Coupling Barrier of Perception and Planning in End-to-End Autonomous Driving"></a>DriveAdapter: Breaking the Coupling Barrier of Perception and Planning in End-to-End Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00398">http://arxiv.org/abs/2308.00398</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opendrivelab/driveadapter">https://github.com/opendrivelab/driveadapter</a></li>
<li>paper_authors: Xiaosong Jia, Yulu Gao, Li Chen, Junchi Yan, Patrick Langechuan Liu, Hongyang Li</li>
<li>for: 这个研究的目的是探索直接将强大的教师模型（Teacher model）用于规划，让学生模型（Student model）更集中在感知部分。</li>
<li>methods: 这个研究使用了 adapter 和 feature alignment 目的函数，以将学生模型（perception）和教师模型（planning）之间的特征进行调整。此外，为了让学生模型更好地学习 teacher model 的需要的输入，还提出了一种动作导向的特征学习方法。</li>
<li>results: 研究发现，直接将学生模型学习 teacher model 的规划可以提高驾驶性能，但是需要处理大量的数据和特征调整。此外，为了保持安全性，还需要将专业规则注入到学习过程中。<details>
<summary>Abstract</summary>
End-to-end autonomous driving aims to build a fully differentiable system that takes raw sensor data as inputs and directly outputs the planned trajectory or control signals of the ego vehicle. State-of-the-art methods usually follow the `Teacher-Student' paradigm. The Teacher model uses privileged information (ground-truth states of surrounding agents and map elements) to learn the driving strategy. The student model only has access to raw sensor data and conducts behavior cloning on the data collected by the teacher model. By eliminating the noise of the perception part during planning learning, state-of-the-art works could achieve better performance with significantly less data compared to those coupled ones.   However, under the current Teacher-Student paradigm, the student model still needs to learn a planning head from scratch, which could be challenging due to the redundant and noisy nature of raw sensor inputs and the casual confusion issue of behavior cloning. In this work, we aim to explore the possibility of directly adopting the strong teacher model to conduct planning while letting the student model focus more on the perception part. We find that even equipped with a SOTA perception model, directly letting the student model learn the required inputs of the teacher model leads to poor driving performance, which comes from the large distribution gap between predicted privileged inputs and the ground-truth.   To this end, we propose DriveAdapter, which employs adapters with the feature alignment objective function between the student (perception) and teacher (planning) modules. Additionally, since the pure learning-based teacher model itself is imperfect and occasionally breaks safety rules, we propose a method of action-guided feature learning with a mask for those imperfect teacher features to further inject the priors of hand-crafted rules into the learning process.
</details>
<details>
<summary>摘要</summary>
End-to-end自动驾驶的目标是建立一个完全可微系统，将原始感知数据作为输入直接输出驾驶车辆的规划或控制信号。现状态的方法通常采用“教师-学生”模式。教师模型使用特权信息（周围 Agent 和地图元素的真实状态）学习驾驶策略。学生模型只有原始感知数据，通过教师模型收集的数据进行行为克隆。通过消除规划学习过程中的感知部分噪声，现状态工作可以更好地表现，并且需要更少的数据。然而，在当前的教师-学生模式下，学生模型仍需要从 scratch 学习规划头，这可能是因为原始感知输入的重复和噪声性，以及行为克隆中的随机混乱问题。在这种情况下，我们想探索可以直接使用强教师模型进行规划的可能性，让学生模型更专注于感知部分。我们发现，即使使用现状态最佳感知模型，直接让学生模型学习教师模型需要的输入会导致驾驶性能差，这是因为预测的特权输入和真实输入之间的分布差距较大。为此，我们提出了 DriveAdapter，它使用适应器与学生（感知）和教师（规划）模块之间的特征对齐目标函数。此外，由于强学习基于教师模型本身不完美，有时会违反安全规则，我们还提出了一种动作导引特征学习方法，通过面Mask 来进一步注入手动编写的规则。
</details></li>
</ul>
<hr>
<h2 id="On-the-Generation-of-a-Synthetic-Event-Based-Vision-Dataset-for-Navigation-and-Landing"><a href="#On-the-Generation-of-a-Synthetic-Event-Based-Vision-Dataset-for-Navigation-and-Landing" class="headerlink" title="On the Generation of a Synthetic Event-Based Vision Dataset for Navigation and Landing"></a>On the Generation of a Synthetic Event-Based Vision Dataset for Navigation and Landing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00394">http://arxiv.org/abs/2308.00394</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/europeanspaceagency/trajectory-to-events">https://gitlab.com/europeanspaceagency/trajectory-to-events</a></li>
<li>paper_authors: Loïc J. Azzalini, Emmanuel Blazquez, Alexander Hadjiivanov, Gabriele Meoni, Dario Izzo</li>
<li>for: 这篇论文是为了研究Event-based Camera在导航和降落应用中的可能性而写的。</li>
<li>methods: 这篇论文使用了Planet和Asteroid Natural Scene Generation Utility生成优化的下降轨迹，并使用了Event-based Camera emulator将图像序列转换为事件流。</li>
<li>results: 这篇论文通过生成500条轨迹，包括事件流和运动场数据，成功地构建了一个真实的Event-based视觉数据集。<details>
<summary>Abstract</summary>
An event-based camera outputs an event whenever a change in scene brightness of a preset magnitude is detected at a particular pixel location in the sensor plane. The resulting sparse and asynchronous output coupled with the high dynamic range and temporal resolution of this novel camera motivate the study of event-based cameras for navigation and landing applications. However, the lack of real-world and synthetic datasets to support this line of research has limited its consideration for onboard use. This paper presents a methodology and a software pipeline for generating event-based vision datasets from optimal landing trajectories during the approach of a target body. We construct sequences of photorealistic images of the lunar surface with the Planet and Asteroid Natural Scene Generation Utility at different viewpoints along a set of optimal descent trajectories obtained by varying the boundary conditions. The generated image sequences are then converted into event streams by means of an event-based camera emulator. We demonstrate that the pipeline can generate realistic event-based representations of surface features by constructing a dataset of 500 trajectories, complete with event streams and motion field ground truth data. We anticipate that novel event-based vision datasets can be generated using this pipeline to support various spacecraft pose reconstruction problems given events as input, and we hope that the proposed methodology would attract the attention of researchers working at the intersection of neuromorphic vision and guidance navigation and control.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>一种事件驱动摄像机会在感知器平面中检测到场景亮度变化的特定像素位置上的特定范围内的变化，并且会输出事件。这种稀疏和异步的输出，加上这种新型摄像机的高动态范围和时间分辨率，使得研究使用这种摄像机进行导航和降落成为有优势的研究方向。然而，由于缺乏真实世界和 sintetic 数据集来支持这种研究，因此它在舱外使用中受到限制。这篇论文提出了一种方法和软件管道，用于生成基于事件的视觉数据集。我们使用 Planet 和 Asteroid Natural Scene Generation Utility 在不同视点下生成了优化的下降轨迹，并将生成的图像序列转换为事件流。我们示例了该管道可以生成具有实际表征的表面特征的事件基于表示。我们预计可以使用这种管道生成更多的事件基于视觉数据集，以支持各种宇航器姿态重建问题，并且希望这种方法会吸引到研究在neuromorphic vision和导航控制之间的研究人员的注意。
</details></li>
</ul>
<hr>
<h2 id="Improving-Generalization-of-Adversarial-Training-via-Robust-Critical-Fine-Tuning"><a href="#Improving-Generalization-of-Adversarial-Training-via-Robust-Critical-Fine-Tuning" class="headerlink" title="Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning"></a>Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02533">http://arxiv.org/abs/2308.02533</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/robustlearn">https://github.com/microsoft/robustlearn</a></li>
<li>paper_authors: Kaijie Zhu, Jindong Wang, Xixu Hu, Xing Xie, Ge Yang</li>
<li>for: 本研究旨在提高深度神经网络的鲁棒性和泛化能力，同时维持鲁棒性。</li>
<li>methods: 本文提出了一种新的方法 called Robustness Critical Fine-Tuning (RiFT)，通过利用鲁棒性训练后模型中的剩余容量来提高泛化能力。</li>
<li>results: 实验结果表明，RiFT可以在 ResNet18、ResNet34 和 WideResNet34-10 模型上提高泛化能力和鲁棒性，同时保持鲁棒性。Code可以在<a target="_blank" rel="noopener" href="https://github.com/microsoft/robustlearn%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/microsoft/robustlearn中下载。</a><details>
<summary>Abstract</summary>
Deep neural networks are susceptible to adversarial examples, posing a significant security risk in critical applications. Adversarial Training (AT) is a well-established technique to enhance adversarial robustness, but it often comes at the cost of decreased generalization ability. This paper proposes Robustness Critical Fine-Tuning (RiFT), a novel approach to enhance generalization without compromising adversarial robustness. The core idea of RiFT is to exploit the redundant capacity for robustness by fine-tuning the adversarially trained model on its non-robust-critical module. To do so, we introduce module robust criticality (MRC), a measure that evaluates the significance of a given module to model robustness under worst-case weight perturbations. Using this measure, we identify the module with the lowest MRC value as the non-robust-critical module and fine-tune its weights to obtain fine-tuned weights. Subsequently, we linearly interpolate between the adversarially trained weights and fine-tuned weights to derive the optimal fine-tuned model weights. We demonstrate the efficacy of RiFT on ResNet18, ResNet34, and WideResNet34-10 models trained on CIFAR10, CIFAR100, and Tiny-ImageNet datasets. Our experiments show that \method can significantly improve both generalization and out-of-distribution robustness by around 1.5% while maintaining or even slightly enhancing adversarial robustness. Code is available at https://github.com/microsoft/robustlearn.
</details>
<details>
<summary>摘要</summary>
深度神经网络容易受到攻击性例子的威胁，这对于一些关键应用来说是一个重要的安全隐患。对抗训练（AT）是一种广泛使用的技术来增强对抗性，但是它经常会导致泛化能力下降。这篇论文提出了一种新的方法，即稳定性敏感细化（RiFT），可以增强泛化能力而不需要牺牲对抗性。RiFT的核心思想是利用神经网络对抗训练后的非稳定模块的剩余容量来提高泛化能力。为此，我们引入模块稳定性优先级（MRC），这是一种评估神经网络模块对对抗性的影响的指标。通过这个指标，我们可以确定神经网络中最低MRC值的模块为非稳定模块，并对其权重进行细化。然后，我们使用这些细化后的权重和对抗训练后的权重进行线性插值，以 derivate最佳细化模型权重。我们在ResNet18、ResNet34和WideResNet34-10模型上进行了CIFAR10、CIFAR100和Tiny-ImageNet数据集的实验，结果表明，\method可以提高泛化能力和对抗性的表现，同时保持或甚至提高对抗性。代码可以在https://github.com/microsoft/robustlearn中找到。
</details></li>
</ul>
<hr>
<h2 id="Deep-Image-Harmonization-with-Learnable-Augmentation"><a href="#Deep-Image-Harmonization-with-Learnable-Augmentation" class="headerlink" title="Deep Image Harmonization with Learnable Augmentation"></a>Deep Image Harmonization with Learnable Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00376">http://arxiv.org/abs/2308.00376</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcmi/syconet-adaptive-image-harmonization">https://github.com/bcmi/syconet-adaptive-image-harmonization</a></li>
<li>paper_authors: Li Niu, Junyan Cao, Wenyan Cong, Liqing Zhang</li>
<li>for: 用于调整图像composite中的前景外观，使整个图像具有和谐性。</li>
<li>methods: 使用learnable augmentation技术，通过学习Color transformation来生成更多的合理的synthetic composite image，以提高图像和谐化性的性能。</li>
<li>results: 对小规模dataset进行了广泛的实验，并达到了更好的和谐化性性能。code可以在<a target="_blank" rel="noopener" href="https://github.com/bcmi/SycoNet-Adaptive-Image-Harmonization%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/bcmi/SycoNet-Adaptive-Image-Harmonization中下载。</a><details>
<summary>Abstract</summary>
The goal of image harmonization is adjusting the foreground appearance in a composite image to make the whole image harmonious. To construct paired training images, existing datasets adopt different ways to adjust the illumination statistics of foregrounds of real images to produce synthetic composite images. However, different datasets have considerable domain gap and the performances on small-scale datasets are limited by insufficient training data. In this work, we explore learnable augmentation to enrich the illumination diversity of small-scale datasets for better harmonization performance. In particular, our designed SYthetic COmposite Network (SycoNet) takes in a real image with foreground mask and a random vector to learn suitable color transformation, which is applied to the foreground of this real image to produce a synthetic composite image. Comprehensive experiments demonstrate the effectiveness of our proposed learnable augmentation for image harmonization. The code of SycoNet is released at https://github.com/bcmi/SycoNet-Adaptive-Image-Harmonization.
</details>
<details>
<summary>摘要</summary>
文本：图像协调的目标是将图像中的前景改变，以使整个图像协调。现有的数据集采用不同的方法来调整真实图像的照明统计信息，以生成合成图像。然而，不同的数据集存在较大的领域差异，小规模数据集的表现受到训练数据的限制。在这种情况下，我们探索了可学习的扩充方法，以增强小规模数据集的照明多样性，从而提高图像协调性能。我们的设计的Synthetic COmposite Network（SycoNet）接受一个真实图像和一个随机向量，并学习适当的颜色变换，该变换应用于图像中的前景，以生成一个合成图像。我们的实验表明，我们提出的可学习扩充方法可以有效地提高图像协调性能。SycoNet的代码可以在 GitHub 上找到：https://github.com/bcmi/SycoNet-Adaptive-Image-Harmonization。中文翻译：图像协调的目标是通过调整图像中的前景，使整个图像协调。现有的数据集采用不同的方法来调整真实图像的照明统计信息，以生成合成图像。然而，不同的数据集存在较大的领域差异，小规模数据集的表现受到训练数据的限制。在这种情况下，我们探索了可学习的扩充方法，以增强小规模数据集的照明多样性，从而提高图像协调性能。我们的设计的Synthetic COmposite Network（SycoNet）接受一个真实图像和一个随机向量，并学习适当的颜色变换，该变换应用于图像中的前景，以生成一个合成图像。我们的实验表明，我们提出的可学习扩充方法可以有效地提高图像协调性能。SycoNet的代码可以在 GitHub 上找到：https://github.com/bcmi/SycoNet-Adaptive-Image-Harmonization。
</details></li>
</ul>
<hr>
<h2 id="MRQ-Support-Multiple-Quantization-Schemes-through-Model-Re-Quantization"><a href="#MRQ-Support-Multiple-Quantization-Schemes-through-Model-Re-Quantization" class="headerlink" title="MRQ:Support Multiple Quantization Schemes through Model Re-Quantization"></a>MRQ:Support Multiple Quantization Schemes through Model Re-Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01867">http://arxiv.org/abs/2308.01867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manasa Manohara, Sankalp Dayal, Tariq Afzal, Rahul Bakshi, Kahkuen Fu</li>
<li>for: 这篇论文目的是为了解决现有的深度学习模型在边缘设备上部署的问题，尤其是在使用固定点维度硬件时。</li>
<li>methods: 这篇论文使用了一种新的模型量化方法，称为MRQ（模型重量化），它可以将现有的量化模型转换为适合不同量化需求的模型。</li>
<li>results: 论文表明了一个MobileNetV2 QAT模型可以从现有的量化模型中快速地重新量化为不同的量化需求，并且可以在NNA上部署到Echo Show设备中。<details>
<summary>Abstract</summary>
Despite the proliferation of diverse hardware accelerators (e.g., NPU, TPU, DPU), deploying deep learning models on edge devices with fixed-point hardware is still challenging due to complex model quantization and conversion. Existing model quantization frameworks like Tensorflow QAT [1], TFLite PTQ [2], and Qualcomm AIMET [3] supports only a limited set of quantization schemes (e.g., only asymmetric per-tensor quantization in TF1.x QAT [4]). Accordingly, deep learning models cannot be easily quantized for diverse fixed-point hardwares, mainly due to slightly different quantization requirements. In this paper, we envision a new type of model quantization approach called MRQ (model re-quantization), which takes existing quantized models and quickly transforms the models to meet different quantization requirements (e.g., asymmetric -> symmetric, non-power-of-2 scale -> power-of-2 scale). Re-quantization is much simpler than quantizing from scratch because it avoids costly re-training and provides support for multiple quantization schemes simultaneously. To minimize re-quantization error, we developed a new set of re-quantization algorithms including weight correction and rounding error folding. We have demonstrated that MobileNetV2 QAT model [7] can be quickly re-quantized into two different quantization schemes (i.e., symmetric and symmetric+power-of-2 scale) with less than 0.64 units of accuracy loss. We believe our work is the first to leverage this concept of re-quantization for model quantization and models obtained from the re-quantization process have been successfully deployed on NNA in the Echo Show devices.
</details>
<details>
<summary>摘要</summary>
尽管现有多种各种硬件加速器（如NPU、TPU、DPU），但是在边缘设备上部署深度学习模型仍然是一个挑战，主要因为复杂的模型减量和转换。现有的模型减量框架，如TensorFlow QAT [1]、TFLite PTQ [2] 和Qualcomm AIMET [3]，只支持有限的减量方案（例如，只有TF1.x QAT中的非对称每个tensor减量）。因此，深度学习模型难以被轻松地减量为不同的固定点硬件，主要是因为不同的减量要求。在本文中，我们提出了一种新的模型减量方法，称为MRQ（模型重新减量），它可以将现有的减量模型快速地转换为满足不同的减量要求（例如，非对称->对称、非二进制扩展->二进制扩展）。重新减量比从头开始减量更加简单，因为它可以避免高成本的重新训练，并且可以同时支持多种减量方案。为了减少重新减量误差，我们开发了一组新的重新减量算法，包括权重修正和圆拟误差叠加。我们已经证明了，通过MRQ方法，可以快速地将MobileNetV2 QAT模型（7）转换为两种不同的减量方案（即对称和对称+二进制扩展），减少精度损失 less than 0.64个单位。我们认为，我们的工作是首次在模型减量方面采用这种概念的重新减量，并且已经成功部署了这些从重新减量过程中获得的模型到NNA在Echo Show设备上。
</details></li>
</ul>
<hr>
<h2 id="Deep-Image-Harmonization-with-Globally-Guided-Feature-Transformation-and-Relation-Distillation"><a href="#Deep-Image-Harmonization-with-Globally-Guided-Feature-Transformation-and-Relation-Distillation" class="headerlink" title="Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation"></a>Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00356">http://arxiv.org/abs/2308.00356</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcmi/image-harmonization-dataset-ccharmony">https://github.com/bcmi/image-harmonization-dataset-ccharmony</a></li>
<li>paper_authors: Li Niu, Linfeng Tan, Xinhao Tao, Junyan Cao, Fengjun Guo, Teng Long, Liqing Zhang</li>
<li>for: 将图像融合到一起，使背景和前景光照协调一致。</li>
<li>methods: 使用全局信息引导前景特征转换，并将前景-背景关系从真实图像传播到复合图像中。</li>
<li>results: 比较前方法具有竞争性，并提供了一个名为ccHarmony的数据集，用于评估图像协调方法。<details>
<summary>Abstract</summary>
Given a composite image, image harmonization aims to adjust the foreground illumination to be consistent with background. Previous methods have explored transforming foreground features to achieve competitive performance. In this work, we show that using global information to guide foreground feature transformation could achieve significant improvement. Besides, we propose to transfer the foreground-background relation from real images to composite images, which can provide intermediate supervision for the transformed encoder features. Additionally, considering the drawbacks of existing harmonization datasets, we also contribute a ccHarmony dataset which simulates the natural illumination variation. Extensive experiments on iHarmony4 and our contributed dataset demonstrate the superiority of our method. Our ccHarmony dataset is released at https://github.com/bcmi/Image-Harmonization-Dataset-ccHarmony.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Lowis3D-Language-Driven-Open-World-Instance-Level-3D-Scene-Understanding"><a href="#Lowis3D-Language-Driven-Open-World-Instance-Level-3D-Scene-Understanding" class="headerlink" title="Lowis3D: Language-Driven Open-World Instance-Level 3D Scene Understanding"></a>Lowis3D: Language-Driven Open-World Instance-Level 3D Scene Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00353">http://arxiv.org/abs/2308.00353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runyu Ding, Jihan Yang, Chuhui Xue, Wenqing Zhang, Song Bai, Xiaojuan Qi</li>
<li>for: 本研究旨在实现开放世界Scene理解，即在未经标注的3D场景中找到和识别未经见过的3D对象类型。</li>
<li>methods: 我们提出使用预训练的视力语（VL）基础模型来生成多视图图像的描述文本，从而建立3D形状和 semantic-rich描述文本之间的明确关系。此外，我们还设计了层次点caption相关方法，以学习semantic-aware嵌入，并使用不supervised学习来解决开放世界设置中的局部化挑战。</li>
<li>results: 我们在3Dsemantic、instance和panoptic分割任务上进行了广泛的实验，覆盖了室内和室外场景三个 dataset。我们的方法与基线方法相比，显著提高了semantic分割（例如，34.5%$\sim$65.3%）、instance分割（例如，21.8%$\sim$54.0%）和panoptic分割（例如，14.7%$\sim$43.3%）的性能。<details>
<summary>Abstract</summary>
Open-world instance-level scene understanding aims to locate and recognize unseen object categories that are not present in the annotated dataset. This task is challenging because the model needs to both localize novel 3D objects and infer their semantic categories. A key factor for the recent progress in 2D open-world perception is the availability of large-scale image-text pairs from the Internet, which cover a wide range of vocabulary concepts. However, this success is hard to replicate in 3D scenarios due to the scarcity of 3D-text pairs. To address this challenge, we propose to harness pre-trained vision-language (VL) foundation models that encode extensive knowledge from image-text pairs to generate captions for multi-view images of 3D scenes. This allows us to establish explicit associations between 3D shapes and semantic-rich captions. Moreover, to enhance the fine-grained visual-semantic representation learning from captions for object-level categorization, we design hierarchical point-caption association methods to learn semantic-aware embeddings that exploit the 3D geometry between 3D points and multi-view images. In addition, to tackle the localization challenge for novel classes in the open-world setting, we develop debiased instance localization, which involves training object grouping modules on unlabeled data using instance-level pseudo supervision. This significantly improves the generalization capabilities of instance grouping and thus the ability to accurately locate novel objects. We conduct extensive experiments on 3D semantic, instance, and panoptic segmentation tasks, covering indoor and outdoor scenes across three datasets. Our method outperforms baseline methods by a significant margin in semantic segmentation (e.g. 34.5%$\sim$65.3%), instance segmentation (e.g. 21.8%$\sim$54.0%) and panoptic segmentation (e.g. 14.7%$\sim$43.3%). Code will be available.
</details>
<details>
<summary>摘要</summary>
开放世界实例级场景理解的目标是找到并识别没有在标注数据中出现的新类型的3D对象。这个任务是非常困难，因为模型需要同时 lokalisieren noval 3D对象和推理其 semantic类别。在2D开放世界识别中，最近的进步得益于互联网上的大规模图像文本对象，这些对象覆盖了广泛的词汇概念。然而，这种成功很难在3D场景中复制，因为3D场景中的3D-文本对象 scarcity。为解决这个挑战，我们提议利用预训练的视觉语言（VL）基础模型，该模型编码了图像文本对象中的广泛知识，以生成多视图图像场景的caption。这使得我们可以显式地关联3D形状和semantic rich的caption。此外，为提高视觉semantic表示学习的细化，我们设计了层次点caption相关方法，以学习semantic-aware embedding，这些embedding利用3D点和多视图图像之间的几何关系。此外，为解决开放世界设置中 novel 类的localization挑战，我们开发了偏置Instance Localization，即在无标注数据上训练对象分组模块，使用实例级别的 Pseudo supervision。这有效地提高了对实例分组的泛化能力，从而准确地位置novel对象。我们对3Dsemantic、实例和панOPTIC分割任务进行了广泛的实验，覆盖了室内和室外场景，三个数据集。我们的方法与基eline方法相比，提高了semantic分割（例如，34.5% 到 65.3%）、实例分割（例如，21.8% 到 54.0%）和панOPTIC分割（例如，14.7% 到 43.3%）的性能。代码将可以提供。
</details></li>
</ul>
<hr>
<h2 id="Fine-Grained-Sports-Yoga-and-Dance-Postures-Recognition-A-Benchmark-Analysis"><a href="#Fine-Grained-Sports-Yoga-and-Dance-Postures-Recognition-A-Benchmark-Analysis" class="headerlink" title="Fine-Grained Sports, Yoga, and Dance Postures Recognition: A Benchmark Analysis"></a>Fine-Grained Sports, Yoga, and Dance Postures Recognition: A Benchmark Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00323">http://arxiv.org/abs/2308.00323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asish Bera, Mita Nasipuri, Ondrej Krejcar, Debotosh Bhattacharjee</li>
<li>for: 这个论文是为了解决人体姿态估计问题，具体是在运动、运动和舞蹈（SYD）姿态方面。</li>
<li>methods: 这篇论文使用了深度卷积神经网络（CNN）和一种名为patch-based attention（PbA）机制，以提高人体姿态估计的性能。</li>
<li>results: 在Yoga-82 dataset上，提出的SYD-Net模型达到了状态监测人体姿态的最佳性能，并在其他 dataset 上也表现出了很好的性能。<details>
<summary>Abstract</summary>
Human body-pose estimation is a complex problem in computer vision. Recent research interests have been widened specifically on the Sports, Yoga, and Dance (SYD) postures for maintaining health conditions. The SYD pose categories are regarded as a fine-grained image classification task due to the complex movement of body parts. Deep Convolutional Neural Networks (CNNs) have attained significantly improved performance in solving various human body-pose estimation problems. Though decent progress has been achieved in yoga postures recognition using deep learning techniques, fine-grained sports, and dance recognition necessitates ample research attention. However, no benchmark public image dataset with sufficient inter-class and intra-class variations is available yet to address sports and dance postures classification. To solve this limitation, we have proposed two image datasets, one for 102 sport categories and another for 12 dance styles. Two public datasets, Yoga-82 which contains 82 classes and Yoga-107 represents 107 classes are collected for yoga postures. These four SYD datasets are experimented with the proposed deep model, SYD-Net, which integrates a patch-based attention (PbA) mechanism on top of standard backbone CNNs. The PbA module leverages the self-attention mechanism that learns contextual information from a set of uniform and multi-scale patches and emphasizes discriminative features to understand the semantic correlation among patches. Moreover, random erasing data augmentation is applied to improve performance. The proposed SYD-Net has achieved state-of-the-art accuracy on Yoga-82 using five base CNNs. SYD-Net's accuracy on other datasets is remarkable, implying its efficiency. Our Sports-102 and Dance-12 datasets are publicly available at https://sites.google.com/view/syd-net/home.
</details>
<details>
<summary>摘要</summary>
人体姿态估计是计算机视觉中一个复杂的问题。最近的研究兴趣在特定的体育、健身和舞蹈（SYD）姿态方面进行了扩展，以维护健康状况。SYD姿态类别被视为一种细化的图像分类任务，因为人体部位的复杂运动。深度卷积神经网络（CNNs）在解决不同人体姿态估计问题上具有显著改进的表现。虽然对于健身姿态的深度学习技术进行了不错的进步，但是体育和舞蹈姿态的细化仍然需要大量的研究注意力。然而，目前还没有一个可用的公共图像数据集，以便对体育和舞蹈姿态进行分类。为解决这种限制，我们提出了四个图像数据集：一个是102个体育类别的数据集，另一个是12个舞蹈风格的数据集。这四个SYD数据集被我们的提议的深度模型SYD-Net进行实验。SYD-Netintegrates一个 patch-based attention（PbA）机制，这个机制使用一些固定大小和多尺度的 patches来学习 Contextual information，并强调特征以理解 semantic correlation among patches。此外，我们还应用了随机擦除数据增强技术来提高性能。我们的SYD-Net在Yoga-82 dataset上达到了state-of-the-art的准确率，并在其他数据集上表现了remarkable的性能，这implying its efficiency。我们的体育-102和舞蹈-12数据集现在公共可用，可以在https://sites.google.com/view/syd-net/home中下载。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Learning-by-Harnessing-Adversarial-Samples"><a href="#Zero-Shot-Learning-by-Harnessing-Adversarial-Samples" class="headerlink" title="Zero-Shot Learning by Harnessing Adversarial Samples"></a>Zero-Shot Learning by Harnessing Adversarial Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00313">http://arxiv.org/abs/2308.00313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uqzhichen/haszsl">https://github.com/uqzhichen/haszsl</a></li>
<li>paper_authors: Zhi Chen, Pengfei Zhang, Jingjing Li, Sen Wang, Zi Huang</li>
<li>for: 这个研究旨在解决零基础学习（Zero-Shot Learning，ZSL）中的 semantic distortion 问题，提高模型的通用能力。</li>
<li>methods: 我们提出了一种基于对抗样本（Adversarial Samples）的 ZSL 方法，通过对抗训练来提高模型的对抗性和可靠性。</li>
<li>results: 我们通过了三个知名的零基础学习评估数据集的实验，证明了我们的对抗样本方法在 ZSL 和 Generalized Zero-Shot Learning（GZSL） scenario 中的效果。<details>
<summary>Abstract</summary>
Zero-Shot Learning (ZSL) aims to recognize unseen classes by generalizing the knowledge, i.e., visual and semantic relationships, obtained from seen classes, where image augmentation techniques are commonly applied to improve the generalization ability of a model. However, this approach can also cause adverse effects on ZSL since the conventional augmentation techniques that solely depend on single-label supervision is not able to maintain semantic information and result in the semantic distortion issue consequently. In other words, image argumentation may falsify the semantic (e.g., attribute) information of an image. To take the advantage of image augmentations while mitigating the semantic distortion issue, we propose a novel ZSL approach by Harnessing Adversarial Samples (HAS). HAS advances ZSL through adversarial training which takes into account three crucial aspects: (1) robust generation by enforcing augmentations to be similar to negative classes, while maintaining correct labels, (2) reliable generation by introducing a latent space constraint to avert significant deviations from the original data manifold, and (3) diverse generation by incorporating attribute-based perturbation by adjusting images according to each semantic attribute's localization. Through comprehensive experiments on three prominent zero-shot benchmark datasets, we demonstrate the effectiveness of our adversarial samples approach in both ZSL and Generalized Zero-Shot Learning (GZSL) scenarios. Our source code is available at https://github.com/uqzhichen/HASZSL.
</details>
<details>
<summary>摘要</summary>
HAS considers three crucial aspects:1. Robust generation: Enforcing augmentations to be similar to negative classes while maintaining correct labels.2. Reliable generation: Introducing a latent space constraint to avert significant deviations from the original data manifold.3. Diverse generation: Incorporating attribute-based perturbation to adjust images according to each semantic attribute's localization.We demonstrate the effectiveness of our approach in both ZSL and Generalized Zero-Shot Learning (GZSL) scenarios through comprehensive experiments on three prominent zero-shot benchmark datasets. Our source code is available at https://github.com/uqzhichen/HASZSL.Translation notes:* Zero-Shot Learning (ZSL) is translated as "无seen类识别" (wú miàn zhì bǐ)* Harnessing Adversarial Samples (HAS) is translated as "利用对抗采样" (lì yòng duì kòng qiè sān)* adversarial training is translated as "对抗训练" (duì kòng xiǎng tào)* semantic distortion issue is translated as "semantic扭曲问题" (semantic fāng zhì wèn tí)* attribute-based perturbation is translated as "基于 attribute 的扰动" (jī yú attribute de ràng dòng)* Generalized Zero-Shot Learning (GZSL) is translated as "普通的无seen类识别" (pǔ tōng de wú miàn zhì bǐ)
</details></li>
</ul>
<hr>
<h2 id="GradOrth-A-Simple-yet-Efficient-Out-of-Distribution-Detection-with-Orthogonal-Projection-of-Gradients"><a href="#GradOrth-A-Simple-yet-Efficient-Out-of-Distribution-Detection-with-Orthogonal-Projection-of-Gradients" class="headerlink" title="GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients"></a>GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00310">http://arxiv.org/abs/2308.00310</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sima Behpour, Thang Doan, Xin Li, Wenbin He, Liang Gou, Liu Ren</li>
<li>For: 这个研究旨在提高机器学习模型在实际应用中的安全部署，通过检测机器学习模型中的外部数据（Out-of-distribution，OOD）。* Methods: 这篇研究提出了一个名为GradOrth的新方法，基于实际数据中重要的特征向量进行OOD检测。具体来说，这个方法 computed the norm of gradient projection on the subspaces considered important for the in-distribution data，以检测数据是否为OOD。* Results: 这个方法可以实现高效的OOD检测，比起目前的现有方法，可以降低false positive rate（FPR）的平均值，具体而言，可以降低FPR95的值高达8%。<details>
<summary>Abstract</summary>
Detecting out-of-distribution (OOD) data is crucial for ensuring the safe deployment of machine learning models in real-world applications. However, existing OOD detection approaches primarily rely on the feature maps or the full gradient space information to derive OOD scores neglecting the role of most important parameters of the pre-trained network over in-distribution (ID) data. In this study, we propose a novel approach called GradOrth to facilitate OOD detection based on one intriguing observation that the important features to identify OOD data lie in the lower-rank subspace of in-distribution (ID) data. In particular, we identify OOD data by computing the norm of gradient projection on the subspaces considered important for the in-distribution data. A large orthogonal projection value (i.e. a small projection value) indicates the sample as OOD as it captures a weak correlation of the ID data. This simple yet effective method exhibits outstanding performance, showcasing a notable reduction in the average false positive rate at a 95% true positive rate (FPR95) of up to 8% when compared to the current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
检测非常量（OOD）数据是机器学习模型在实际应用中的安全部署的关键。然而，现有的OOD检测方法主要基于特征图或整个梯度空间信息来生成OOD分数，忽略了预训练网络中最重要的参数的作用。在这项研究中，我们提出了一种新的方法 called GradOrth，用于基于ID数据中重要参数的低纬度子空间来进行OOD检测。具体来说，我们通过计算ID数据中考虑重要的参数所生成的梯度投影的评估值来识别OOD数据。如果梯度投影的评估值很小（即 proyect value 很大），则表示该样本为OOD，因为它 capture ID数据的弱相关性。这种简单 yet 高效的方法在我们的实验中表现出色，可以在95% true positive rate (FPR95) 下减少 false positive rate 的平均值达到8%，与当前状态的方法相比，具有显著的改善。
</details></li>
</ul>
<hr>
<h2 id="Domain-Adaptation-based-on-Human-Feedback-for-Enhancing-Generative-Model-Denoising-Abilities"><a href="#Domain-Adaptation-based-on-Human-Feedback-for-Enhancing-Generative-Model-Denoising-Abilities" class="headerlink" title="Domain Adaptation based on Human Feedback for Enhancing Generative Model Denoising Abilities"></a>Domain Adaptation based on Human Feedback for Enhancing Generative Model Denoising Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00307">http://arxiv.org/abs/2308.00307</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyun-Cheol Park, Sung Ho Kang</li>
<li>for: 这个论文的目的是如何使用人类反馈来提高生成模型的质量。</li>
<li>methods: 这个论文使用了人类反馈来修正生成模型在不同频谱上的表现。</li>
<li>results: 研究人员通过使用人类反馈来修正生成模型，提高了模型在不同频谱上的表现。In more detail, the paper proposes a method for fine-tuning a generator trained on one domain using human feedback from another domain, in order to enhance the denoising capabilities of the generator in different domains. The method involves training a reward model to predict human feedback, and then using the reward model to fine-tune the generator on the different domain. The approach is shown to be effective in improving the quality of the denoised images.<details>
<summary>Abstract</summary>
How can we apply human feedback into generative model? As answer of this question, in this paper, we show the method applied on denoising problem and domain adaptation using human feedback. Deep generative models have demonstrated impressive results in image denoising. However, current image denoising models often produce inappropriate results when applied to domains different from the ones they were trained on. If there are `Good' and `Bad' result for unseen data, how to raise up quality of `Bad' result. Most methods use an approach based on generalization of model. However, these methods require target image for training or adapting unseen domain. In this paper, to adapting domain, we deal with non-target image for unseen domain, and improve specific failed image. To address this, we propose a method for fine-tuning inappropriate results generated in a different domain by utilizing human feedback. First, we train a generator to denoise images using only the noisy MNIST digit '0' images. The denoising generator trained on the source domain leads to unintended results when applied to target domain images. To achieve domain adaptation, we construct a noise-image denoising generated image data set and train a reward model predict human feedback. Finally, we fine-tune the generator on the different domain using the reward model with auxiliary loss function, aiming to transfer denoising capabilities to target domain. Our approach demonstrates the potential to efficiently fine-tune a generator trained on one domain using human feedback from another domain, thereby enhancing denoising abilities in different domains.
</details>
<details>
<summary>摘要</summary>
如何将人类反馈应用到生成模型中？在这篇论文中，我们提出了基于人类反馈的方法，用于解决陌生频率问题和频率适应问题。深度生成模型在图像噪声除除预测中表现出色，但是当应用于不同的频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频率频�
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Model-for-Camouflaged-Object-Detection"><a href="#Diffusion-Model-for-Camouflaged-Object-Detection" class="headerlink" title="Diffusion Model for Camouflaged Object Detection"></a>Diffusion Model for Camouflaged Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00303">http://arxiv.org/abs/2308.00303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhennan Chen, Rongrong Gao, Tian-Zhu Xiang, Fan Lin</li>
<li>for: 这个论文的目的是提出一个基于扩散的隐形物检测方法（diffCOD），用于检测高度相似背景的物品。</li>
<li>methods: 这个方法使用扩散泛化模型的强大噪声除法能力，将隐形物检测任务视为一个扩散泛化过程，从陌生分布传播到物品标识。具体来说，物品标识从真实标识推广到陌生分布，而设计的模型从中学习恢复这个泛化过程。</li>
<li>results: 在四个广泛使用的隐形物检测 benchmark 数据集上进行了广泛的实验，结果显示，提出的方法与现有的 11 种方法相比，尤其在隐形物标识中的细节 texture 检测方面表现出色。<details>
<summary>Abstract</summary>
Camouflaged object detection is a challenging task that aims to identify objects that are highly similar to their background. Due to the powerful noise-to-image denoising capability of denoising diffusion models, in this paper, we propose a diffusion-based framework for camouflaged object detection, termed diffCOD, a new framework that considers the camouflaged object segmentation task as a denoising diffusion process from noisy masks to object masks. Specifically, the object mask diffuses from the ground-truth masks to a random distribution, and the designed model learns to reverse this noising process. To strengthen the denoising learning, the input image prior is encoded and integrated into the denoising diffusion model to guide the diffusion process. Furthermore, we design an injection attention module (IAM) to interact conditional semantic features extracted from the image with the diffusion noise embedding via the cross-attention mechanism to enhance denoising learning. Extensive experiments on four widely used COD benchmark datasets demonstrate that the proposed method achieves favorable performance compared to the existing 11 state-of-the-art methods, especially in the detailed texture segmentation of camouflaged objects. Our code will be made publicly available at: https://github.com/ZNan-Chen/diffCOD.
</details>
<details>
<summary>摘要</summary>
幻化物体检测是一个复杂的任务，旨在标识背景上的物体，这些物体与背景几乎完全相同。由于杂波模型具有强大的噪声去除能力，我们在这篇论文中提出了一种基于杂波的检测方法，称为diffCOD。这种方法将物体检测任务视为一种噪声去除过程，从杂波masks到object masks。具体来说，物体mask从真实的masks diffuses到一个随机分布，而设计的模型学习恢复这个噪声过程。为强化噪声学习，输入图像先验是编码并 integrate到杂波噪声模型中，以导引杂波过程。此外，我们还设计了注入注意力模块（IAM），通过跨注意力机制与图像中的 conditional semantic feature进行交互，以增强噪声学习。我们在四种通用COD benchmark数据集上进行了广泛的实验，结果显示，我们的提出的方法与现有11种状态之前的方法相比，尤其是在透明度高的细节表示上，对幻化物体的检测表现出色。我们的代码将在：https://github.com/ZNan-Chen/diffCOD 中公开。
</details></li>
</ul>
<hr>
<h2 id="Online-Prototype-Learning-for-Online-Continual-Learning"><a href="#Online-Prototype-Learning-for-Online-Continual-Learning" class="headerlink" title="Online Prototype Learning for Online Continual Learning"></a>Online Prototype Learning for Online Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00301">http://arxiv.org/abs/2308.00301</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/weilllllls/onpro">https://github.com/weilllllls/onpro</a></li>
<li>paper_authors: Yujie Wei, Jiaxin Ye, Zhizhong Huang, Junping Zhang, Hongming Shan</li>
<li>for: 本研究探讨了在单过滤流量中不断学习的问题，以适应新数据并减轻悬崖式忘却。</li>
<li>methods: 本研究使用了存储一小部分旧数据的方法，并提出了一种新的代码反馈机制，以解决在线学习模型对新任务的欠拟合问题。</li>
<li>results: 实验结果表明， comparing with现状态 искусственный智能方法，本研究的方法在广泛使用的标准 benchmark 数据集上达到了更高的性能。<details>
<summary>Abstract</summary>
Online continual learning (CL) studies the problem of learning continuously from a single-pass data stream while adapting to new data and mitigating catastrophic forgetting. Recently, by storing a small subset of old data, replay-based methods have shown promising performance. Unlike previous methods that focus on sample storage or knowledge distillation against catastrophic forgetting, this paper aims to understand why the online learning models fail to generalize well from a new perspective of shortcut learning. We identify shortcut learning as the key limiting factor for online CL, where the learned features may be biased, not generalizable to new tasks, and may have an adverse impact on knowledge distillation. To tackle this issue, we present the online prototype learning (OnPro) framework for online CL. First, we propose online prototype equilibrium to learn representative features against shortcut learning and discriminative features to avoid class confusion, ultimately achieving an equilibrium status that separates all seen classes well while learning new classes. Second, with the feedback of online prototypes, we devise a novel adaptive prototypical feedback mechanism to sense the classes that are easily misclassified and then enhance their boundaries. Extensive experimental results on widely-used benchmark datasets demonstrate the superior performance of OnPro over the state-of-the-art baseline methods. Source code is available at https://github.com/weilllllls/OnPro.
</details>
<details>
<summary>摘要</summary>
在线持续学习（CL）研究了从单个数据流中不断学习的问题，同时适应新数据并避免恶化学习。最近，通过存储一小部分的老数据来实现，重温方法表现了良好的性能。与前方法集中注意点在样本存储或知识储存防止恶化学习，这篇论文强调从新的角度研究在线学习模型何以不好地泛化。我们识别快捷学习为在线CL的限制因素，因为学习的特征可能偏导向、不易泛化到新任务、并可能对知识储存产生负面影响。为了解决这个问题，我们提出在线原型学习（OnPro）框架，包括在线原型均衡和泛化特征的学习，以达到一个分离所有seen类的平衡状态。其次，通过在线原型反馈机制，我们提出一种新的适应式原型反馈机制，以感知容易混淆的类并强制其分类边界。实验结果表明，与状态实验方法相比，OnPro显著超越了基eline方法的性能。代码可以在<https://github.com/weilllllls/OnPro>获取。
</details></li>
</ul>
<hr>
<h2 id="Fundus-Enhanced-Disease-Aware-Distillation-Model-for-Retinal-Disease-Classification-from-OCT-Images"><a href="#Fundus-Enhanced-Disease-Aware-Distillation-Model-for-Retinal-Disease-Classification-from-OCT-Images" class="headerlink" title="Fundus-Enhanced Disease-Aware Distillation Model for Retinal Disease Classification from OCT Images"></a>Fundus-Enhanced Disease-Aware Distillation Model for Retinal Disease Classification from OCT Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00291">http://arxiv.org/abs/2308.00291</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xmed-lab/fddm">https://github.com/xmed-lab/fddm</a></li>
<li>paper_authors: Lehan Wang, Weihang Dai, Mei Jin, Chubin Ou, Xiaomeng Li</li>
<li>for: 本研究旨在提出一种基于多模态学习的眼病识别方法，以提高现有的单模态学习方法的效果。</li>
<li>methods: 我们提出了一种基于眼病模型的分类器，通过在训练过程中使用不匹配的背景图像来增强OCToct模型的表现。我们还提出了一种类prototype匹配和类相似性对齐方法，以便在不同模态之间传递疾病相关信息。</li>
<li>results: 我们的方法在实验中表现出优于单模态、多模态和现有的气化方法，并且可以在不同的眼病诊断中获得更高的准确率。<details>
<summary>Abstract</summary>
Optical Coherence Tomography (OCT) is a novel and effective screening tool for ophthalmic examination. Since collecting OCT images is relatively more expensive than fundus photographs, existing methods use multi-modal learning to complement limited OCT data with additional context from fundus images. However, the multi-modal framework requires eye-paired datasets of both modalities, which is impractical for clinical use. To address this problem, we propose a novel fundus-enhanced disease-aware distillation model (FDDM), for retinal disease classification from OCT images. Our framework enhances the OCT model during training by utilizing unpaired fundus images and does not require the use of fundus images during testing, which greatly improves the practicality and efficiency of our method for clinical use. Specifically, we propose a novel class prototype matching to distill disease-related information from the fundus model to the OCT model and a novel class similarity alignment to enforce consistency between disease distribution of both modalities. Experimental results show that our proposed approach outperforms single-modal, multi-modal, and state-of-the-art distillation methods for retinal disease classification. Code is available at https://github.com/xmed-lab/FDDM.
</details>
<details>
<summary>摘要</summary>
optical coherence tomography (OCT) 是一种新的和有效的屏检工具 для眼科诊断。由于收集 OCT 图像相对较为昂贵于fundus 图像，现有的方法使用多模态学习来补充 OCT 数据中的有限信息。然而，多模态框架需要临床使用的眼球对应的数据集，这是不现实的。为解决这个问题，我们提出了一种新的眼球增强疾病意识模型（FDDM），用于从 OCT 图像中分类眼球疾病。我们的框架在训练时使用不匹配的眼球图像来增强 OCT 模型，而不需要在测试时使用眼球图像，这大大提高了我们的方法的实用性和效率。specifically，我们提出了一种新的类型prototype匹配来提取疾病相关信息从眼球模型并将其传递给 OCT 模型，以及一种新的类型相似性对齐来强制两种模式中疾病分布的一致。实验结果表明，我们的提出的方法在眼球疾病分类中超过单模、多模和状态 искусственный气化方法。代码可以在 <https://github.com/xmed-lab/FDDM> 中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Study-of-Unsupervised-Evaluation-Metrics-for-Practical-and-Automatic-Domain-Adaptation"><a href="#A-Study-of-Unsupervised-Evaluation-Metrics-for-Practical-and-Automatic-Domain-Adaptation" class="headerlink" title="A Study of Unsupervised Evaluation Metrics for Practical and Automatic Domain Adaptation"></a>A Study of Unsupervised Evaluation Metrics for Practical and Automatic Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00287">http://arxiv.org/abs/2308.00287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minghao Chen, Zepeng Gao, Shuai Zhao, Qibo Qiu, Wenxiao Wang, Binbin Lin, Xiaofei He</li>
<li>for: 本研究旨在无需目标验证数据的情况下，发展一个无监督领域适应（Unsupervised Domain Adaptation，UDA）评估指标，以评估将模型转移到目标领域时的品质。</li>
<li>methods: 本研究使用的方法包括基于对应信息的评估指标，以及一个新的多层感知（MLP）分类器，并与数据增强技术相结合，实现一个名为增强对应稳定度（Augmentation Consistency Metric，ACM）的新的UDA评估指标。</li>
<li>results: 本研究透过实验证明了先前的实验设定存在缺陷，并通过大规模实验验证了我们提出的评估指标的有效性。此外，我们还使用了我们的评估指标自动搜寻最佳参数集，在四个常用的参数集上实现了超越手动参数集的性能。<details>
<summary>Abstract</summary>
Unsupervised domain adaptation (UDA) methods facilitate the transfer of models to target domains without labels. However, these methods necessitate a labeled target validation set for hyper-parameter tuning and model selection. In this paper, we aim to find an evaluation metric capable of assessing the quality of a transferred model without access to target validation labels. We begin with the metric based on mutual information of the model prediction. Through empirical analysis, we identify three prevalent issues with this metric: 1) It does not account for the source structure. 2) It can be easily attacked. 3) It fails to detect negative transfer caused by the over-alignment of source and target features. To address the first two issues, we incorporate source accuracy into the metric and employ a new MLP classifier that is held out during training, significantly improving the result. To tackle the final issue, we integrate this enhanced metric with data augmentation, resulting in a novel unsupervised UDA metric called the Augmentation Consistency Metric (ACM). Additionally, we empirically demonstrate the shortcomings of previous experiment settings and conduct large-scale experiments to validate the effectiveness of our proposed metric. Furthermore, we employ our metric to automatically search for the optimal hyper-parameter set, achieving superior performance compared to manually tuned sets across four common benchmarks. Codes will be available soon.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Unsupervised domain adaptation (UDA) methods facilitate the transfer of models to target domains without labels. However, these methods necessitate a labeled target validation set for hyper-parameter tuning and model selection. In this paper, we aim to find an evaluation metric capable of assessing the quality of a transferred model without access to target validation labels. We begin with the metric based on mutual information of the model prediction. Through empirical analysis, we identify three prevalent issues with this metric: 1) It does not account for the source structure. 2) It can be easily attacked. 3) It fails to detect negative transfer caused by the over-alignment of source and target features. To address the first two issues, we incorporate source accuracy into the metric and employ a new MLP classifier that is held out during training, significantly improving the result. To tackle the final issue, we integrate this enhanced metric with data augmentation, resulting in a novel unsupervised UDA metric called the Augmentation Consistency Metric (ACM). Additionally, we empirically demonstrate the shortcomings of previous experiment settings and conduct large-scale experiments to validate the effectiveness of our proposed metric. Furthermore, we employ our metric to automatically search for the optimal hyper-parameter set, achieving superior performance compared to manually tuned sets across four common benchmarks. Codes will be available soon." into Simplified Chinese.Here's the translation:<<SYS>>无监督领域适应（UDA）方法可以将模型转移到目标领域无需标签。然而，这些方法通常需要一个标注的目标验证集来进行参数调整和模型选择。在这篇论文中，我们目标是找到一个无需目标验证标签的评价指标，以评估转移模型的质量。我们开始于基于模型预测的共同信息度metric。通过实验分析，我们发现了三个常见的问题：1）它不考虑源结构。2）它可以轻松攻击。3）它无法探测源和目标特征的过对齐导致的负面转移。为了解决这些问题，我们将源准确率 incorporated into the metric，并使用一个新的多层感知机（MLP）分类器，在训练期间快速进行了改进。为了解决最后一个问题，我们将这个加强的 metric 与数据扩展结合，得到了一个新的无监督 UDA 度量called Augmentation Consistency Metric（ACM）。此外，我们也进行了实验证明先前的实验设置的缺陷，并进行了大规模的实验来验证我们的提议的度量的有效性。此外，我们还使用我们的度量自动搜索最佳参数集，在四个常见的 benchmark 上达到了超过手动调整的参数集的性能。代码将在未来 soon 可用。
</details></li>
</ul>
<hr>
<h2 id="Robust-Positive-Unlabeled-Learning-via-Noise-Negative-Sample-Self-correction"><a href="#Robust-Positive-Unlabeled-Learning-via-Noise-Negative-Sample-Self-correction" class="headerlink" title="Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction"></a>Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00279">http://arxiv.org/abs/2308.00279</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/woriazzc/robust-pu">https://github.com/woriazzc/robust-pu</a></li>
<li>paper_authors: Zhangchi Zhu, Lu Wang, Pu Zhao, Chao Du, Wei Zhang, Hang Dong, Bo Qiao, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang</li>
<li>For: The paper focuses on developing a robust positive-unlabeled (PU) learning method to improve the accuracy and stability of learning with positive and unlabeled data.* Methods: The proposed method utilizes a novel “hardness” measure to distinguish unlabeled samples with a high chance of being negative from unlabeled samples with large label noise. An iterative training strategy is then implemented to fine-tune the selection of negative samples during the training process in an iterative manner to include more “easy” samples in the early stage of training.* Results: Extensive experimental validations over a wide range of learning tasks show that the proposed approach can effectively improve the accuracy and stability of learning with positive and unlabeled data.Here are the three key points in Simplified Chinese:* For: 本 paper 针对正样本和无标签样本的学习问题提出了一种robustPositive-unlabeled (PU)学习方法，以提高学习精度和稳定性。* Methods: 提议的方法利用了一种新的”困难度”度量来分辨无标签样本中高概率为负样本的样本和具有大量标签噪声的样本。然后，通过一种迭代训练策略来在训练过程中进行迭代调整负样本的选择，以包括更多”容易”的样本在早期训练阶段。* Results: 对各种学习任务进行了广泛的实验验证，结果表明，提议的方法可以有效地提高学习正样本和无标签样本的精度和稳定性。<details>
<summary>Abstract</summary>
Learning from positive and unlabeled data is known as positive-unlabeled (PU) learning in literature and has attracted much attention in recent years. One common approach in PU learning is to sample a set of pseudo-negatives from the unlabeled data using ad-hoc thresholds so that conventional supervised methods can be applied with both positive and negative samples. Owing to the label uncertainty among the unlabeled data, errors of misclassifying unlabeled positive samples as negative samples inevitably appear and may even accumulate during the training processes. Those errors often lead to performance degradation and model instability. To mitigate the impact of label uncertainty and improve the robustness of learning with positive and unlabeled data, we propose a new robust PU learning method with a training strategy motivated by the nature of human learning: easy cases should be learned first. Similar intuition has been utilized in curriculum learning to only use easier cases in the early stage of training before introducing more complex cases. Specifically, we utilize a novel ``hardness'' measure to distinguish unlabeled samples with a high chance of being negative from unlabeled samples with large label noise. An iterative training strategy is then implemented to fine-tune the selection of negative samples during the training process in an iterative manner to include more ``easy'' samples in the early stage of training. Extensive experimental validations over a wide range of learning tasks show that this approach can effectively improve the accuracy and stability of learning with positive and unlabeled data. Our code is available at https://github.com/woriazzc/Robust-PU
</details>
<details>
<summary>摘要</summary>
学习正方向和未标注数据的技术被称为正方向-未标注（PU）学习，在最近几年内吸引了很多关注。一种常见的PU学习方法是从未标注数据中随机选择一些pseudo-negative样本，以便使用 convential的supervised方法进行学习。由于未标注数据中的标签不确定性，在训练过程中可能会出现误分类未标注正样本为负样本的错误，这些错误可能会在训练过程中积累，导致性能下降和模型不稳定。为了减轻标签不确定性的影响和提高学习正方向和未标注数据的稳定性，我们提出了一种新的robust PU学习方法，具体来说是在训练过程中采用一种基于人类学习的启发，即在训练的初始阶段使用容易的样本进行学习，然后逐渐引入更复杂的样本。我们使用一种新的“困难度”度量来 отличи未标注样本中的高概率负样本和大量标签噪声。然后，我们实现了一种迭代训练策略，在训练过程中不断细化选择负样本的过程，以包括更多的容易样本在训练的初始阶段。我们进行了广泛的实验 validate our approach，结果表明，这种方法可以有效地提高学习正方向和未标注数据的精度和稳定性。我们的代码可以在 <https://github.com/woriazzc/Robust-PU> 找到。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Ultra-High-Definition-Image-Reflection-Removal"><a href="#Benchmarking-Ultra-High-Definition-Image-Reflection-Removal" class="headerlink" title="Benchmarking Ultra-High-Definition Image Reflection Removal"></a>Benchmarking Ultra-High-Definition Image Reflection Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00265">http://arxiv.org/abs/2308.00265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liar-zzy/benchmarking-ultra-high-definition-single-image-reflection-removal">https://github.com/liar-zzy/benchmarking-ultra-high-definition-single-image-reflection-removal</a></li>
<li>paper_authors: Zhenyuan Zhang, Zhenbo Song, Kaihao Zhang, Wenhan Luo, Zhaoxin Fan, Jianfeng Lu<br>for: 本研究旨在解决高清单张图像反射去除（SIRR）问题，特别是对于超高清单张图像（UHD）。methods: 本研究使用了六种现状顶尖SIRR方法进行评估，并对这些方法在UHD图像上的应用进行了详细的分析。此外，本研究还提出了一种基于 transformer 架构的 Reflection Removal 方法（RRFormer），该方法包括三个模块：预处理嵌入模块、自动注意力特征提取模块和多尺度空间特征提取模块。results: 经过实验证明，RRFormer 在非 UHD 数据集和我们提出的 UHDRR 数据集上达到了领先的表现。此外，本研究还提供了一个可公开下载的代码和数据集，以便进一步探索 UHD SIRR 领域。<details>
<summary>Abstract</summary>
Deep learning based methods have achieved significant success in the task of single image reflection removal (SIRR). However, the majority of these methods are focused on High-Definition/Standard-Definition (HD/SD) images, while ignoring higher resolution images such as Ultra-High-Definition (UHD) images. With the increasing prevalence of UHD images captured by modern devices, in this paper, we aim to address the problem of UHD SIRR. Specifically, we first synthesize two large-scale UHD datasets, UHDRR4K and UHDRR8K. The UHDRR4K dataset consists of $2,999$ and $168$ quadruplets of images for training and testing respectively, and the UHDRR8K dataset contains $1,014$ and $105$ quadruplets. To the best of our knowledge, these two datasets are the first largest-scale UHD datasets for SIRR. Then, we conduct a comprehensive evaluation of six state-of-the-art SIRR methods using the proposed datasets. Based on the results, we provide detailed discussions regarding the strengths and limitations of these methods when applied to UHD images. Finally, we present a transformer-based architecture named RRFormer for reflection removal. RRFormer comprises three modules, namely the Prepossessing Embedding Module, Self-attention Feature Extraction Module, and Multi-scale Spatial Feature Extraction Module. These modules extract hypercolumn features, global and partial attention features, and multi-scale spatial features, respectively. To ensure effective training, we utilize three terms in our loss function: pixel loss, feature loss, and adversarial loss. We demonstrate through experimental results that RRFormer achieves state-of-the-art performance on both the non-UHD dataset and our proposed UHDRR datasets. The code and datasets are publicly available at https://github.com/Liar-zzy/Benchmarking-Ultra-High-Definition-Single-Image-Reflection-Removal.
</details>
<details>
<summary>摘要</summary>
深度学习基于方法在单个图像反射去除（SIRR）任务中已经取得了显著的成功。然而，大多数这些方法都是关注高清晰度/标准清晰度（HD/SD）图像，而忽略更高的分辨率图像，如超高清晰度（UHD）图像。随着现代设备拍摄的UHD图像的流行，在这篇论文中，我们想要解决UHD SIRR问题。specifically，我们首先合成了两个大规模UHD datasets，即UHDRR4K和UHDRR8K。UHDRR4K dataset包含2999个和168个图像对用于训练和测试，而UHDRR8K dataset包含1014个和105个图像对。我们知道，这两个dataset是现有最大规模的UHD datasets for SIRR。然后，我们进行了六种state-of-the-art SIRR方法的全面评估，使用我们提出的dataset。基于结果，我们提供了详细的讨论，探讨这些方法在UHD图像上的优缺点。最后，我们提出了一种基于转换器的架构，名为RRFormer，用于反射去除。RRFormer包括三个模块：预处理嵌入模块、自注意特征提取模块和多尺度空间特征提取模块。这些模块分别提取了嵌入特征、全局和部分注意特征以及多尺度空间特征。为确保有效训练，我们使用了三个损失函数：像素损失、特征损失和对抗损失。我们通过实验结果表明，RRFormer在我们提出的UHDRR datasets以及非UHD dataset上达到了状态之最的性能。代码和数据集可以在https://github.com/Liar-zzy/Benchmarking-Ultra-High-Definition-Single-Image-Reflection-Removal上获取。
</details></li>
</ul>
<hr>
<h2 id="The-Algonauts-Project-2023-Challenge-UARK-UAlbany-Team-Solution"><a href="#The-Algonauts-Project-2023-Challenge-UARK-UAlbany-Team-Solution" class="headerlink" title="The Algonauts Project 2023 Challenge: UARK-UAlbany Team Solution"></a>The Algonauts Project 2023 Challenge: UARK-UAlbany Team Solution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00262">http://arxiv.org/abs/2308.00262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uark-cviu/algonauts2023">https://github.com/uark-cviu/algonauts2023</a></li>
<li>paper_authors: Xuan-Bac Nguyen, Xudong Liu, Xin Li, Khoa Luu</li>
<li>for: 这个研究是为了参加Algonauts Project 2023 Challenge，目标是使用计算模型预测参与者在观看复杂自然视觉场景时的脑响应。</li>
<li>methods: 这个研究使用了一种两步训练方法来构建一个图像基于的脑编码器，包括在所有参与者的数据上进行首先训练，然后对每个参与者进行细化训练，使用不同的损失函数和目标来引入多样性。</li>
<li>results: 这个研究的结果是一个由多个独特的编码器组成的ensemble，可以准确预测脑响应。代码可以在<a target="_blank" rel="noopener" href="https://github.com/uark-cviu/Algonauts2023%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/uark-cviu/Algonauts2023上获取。</a><details>
<summary>Abstract</summary>
This work presents our solutions to the Algonauts Project 2023 Challenge. The primary objective of the challenge revolves around employing computational models to anticipate brain responses captured during participants' observation of intricate natural visual scenes. The goal is to predict brain responses across the entire visual brain, as it is the region where the most reliable responses to images have been observed. We constructed an image-based brain encoder through a two-step training process to tackle this challenge. Initially, we created a pretrained encoder using data from all subjects. Next, we proceeded to fine-tune individual subjects. Each step employed different training strategies, such as different loss functions and objectives, to introduce diversity. Ultimately, our solution constitutes an ensemble of multiple unique encoders. The code is available at https://github.com/uark-cviu/Algonauts2023
</details>
<details>
<summary>摘要</summary>
这个工作介绍了我们对Algonauts Project 2023 Challenge的解决方案。挑战的主要目标是通过计算模型预测参与者观看复杂自然视觉场景时的脑响应。目标是预测整个视觉脑区的脑响应，因为这里是最可靠的图像响应的地方。我们使用了两步训练过程构建了基于图像的脑编码器。首先，我们创建了所有参与者的预训练编码器。然后，我们进行了个性化训练，每个步骤使用了不同的loss函数和目标，以引入多样性。最终，我们的解决方案是一个ensemble的多个唯一编码器。代码可以在https://github.com/uark-cviu/Algonauts2023中找到。
</details></li>
</ul>
<hr>
<h2 id="Improving-Pixel-based-MIM-by-Reducing-Wasted-Modeling-Capability"><a href="#Improving-Pixel-based-MIM-by-Reducing-Wasted-Modeling-Capability" class="headerlink" title="Improving Pixel-based MIM by Reducing Wasted Modeling Capability"></a>Improving Pixel-based MIM by Reducing Wasted Modeling Capability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00261">http://arxiv.org/abs/2308.00261</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmpretrain">https://github.com/open-mmlab/mmpretrain</a></li>
<li>paper_authors: Yuan Liu, Songyang Zhang, Jiacheng Chen, Zhaohui Yu, Kai Chen, Dahua Lin</li>
<li>for: This paper aims to improve the performance of Masked Image Modeling (MIM) methods, which are used for tasks such as fine-tuning, linear probing, and semantic segmentation.</li>
<li>methods: The proposed method utilizes low-level features from shallow layers to aid pixel reconstruction, and incorporates multi-level feature fusion for isotropic architectures like the standard Vision Transformer (ViT).</li>
<li>results: The proposed method achieves non-trivial improvements across various downstream tasks, including 1.2% improvement in fine-tuning, 2.8% improvement in linear probing, and 2.6% improvement in semantic segmentation, when applied to a smaller model (e.g., ViT-S).Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文目标是提高Masked Image Modeling（MIM）方法的性能，这些方法用于Tasks如 fine-tuning、linear probing 和 semantic segmentation。</li>
<li>methods: 提议的方法利用 shallow layers 的低级别特征来帮助像素重建，并利用 isotropic 架构 like standard Vision Transformer（ViT）的多级特征融合。</li>
<li>results: 提议的方法在不同的下游任务上实现了非致命的改进，包括 fine-tuning 上的1.2%提升、linear probing 上的2.8%提升和 semantic segmentation 上的2.6%提升，当应用于 smaller model（如 ViT-S）时。<details>
<summary>Abstract</summary>
There has been significant progress in Masked Image Modeling (MIM). Existing MIM methods can be broadly categorized into two groups based on the reconstruction target: pixel-based and tokenizer-based approaches. The former offers a simpler pipeline and lower computational cost, but it is known to be biased toward high-frequency details. In this paper, we provide a set of empirical studies to confirm this limitation of pixel-based MIM and propose a new method that explicitly utilizes low-level features from shallow layers to aid pixel reconstruction. By incorporating this design into our base method, MAE, we reduce the wasted modeling capability of pixel-based MIM, improving its convergence and achieving non-trivial improvements across various downstream tasks. To the best of our knowledge, we are the first to systematically investigate multi-level feature fusion for isotropic architectures like the standard Vision Transformer (ViT). Notably, when applied to a smaller model (e.g., ViT-S), our method yields significant performance gains, such as 1.2\% on fine-tuning, 2.8\% on linear probing, and 2.6\% on semantic segmentation. Code and models are available at https://github.com/open-mmlab/mmpretrain.
</details>
<details>
<summary>摘要</summary>
“ máscara image modeling (MIM) 方面已经取得了 significativo progress. 现有的 MIM 方法可以分为两个类别，根据重建目标来分：像素基于的方法和 tokenizer 基于的方法。前者具有简单的管道和较低的计算成本，但已知偏好高频率细节。在这篇论文中，我们提供了一系列实验来证明这一点，并提出一种新的方法，利用低层特征来帮助像素重建。通过将这种设计纳入我们的基本方法MAE中，我们降低了像素基于 MIM 的浪费模型能力，提高了它的收敛和在多种下游任务中取得了非常有用的改进。我们知道，我们是第一个系统地调查多级特征融合 для均匀的Architecture like standard Vision Transformer (ViT)。当应用于较小的模型（例如 ViT-S）时，我们的方法可以获得显著的性能提升，如1.2%的 fine-tuning，2.8%的线性探测和2.6%的语义分割。代码和模型可以在https://github.com/open-mmlab/mmpretrain中找到。”
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Self-Supervised-Image-Denoising-A-Comprehensive-Review"><a href="#Unleashing-the-Power-of-Self-Supervised-Image-Denoising-A-Comprehensive-Review" class="headerlink" title="Unleashing the Power of Self-Supervised Image Denoising: A Comprehensive Review"></a>Unleashing the Power of Self-Supervised Image Denoising: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00247">http://arxiv.org/abs/2308.00247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Zhang, Fangfang Zhou, Yuanzhou Wei, Xiao Yang, Yuan Gu</li>
<li>for: 本文旨在提供一份准确、净化的自适应图像干扰除法综述，帮助研究者和实践者更好地了解这个领域的最新发展。</li>
<li>methods: 本文分类了自适应图像干扰除方法为三类：通用方法、BSN基于方法和Transformer基于方法，并提供了每种方法的 theoretically 分析和实践应用。</li>
<li>results: 本文通过对多个数据集进行量化和质量性实验，证明了这些方法的有效性，并提供了对等的对比分析。<details>
<summary>Abstract</summary>
The advent of deep learning has brought a revolutionary transformation to image denoising techniques. However, the persistent challenge of acquiring noise-clean pairs for supervised methods in real-world scenarios remains formidable, necessitating the exploration of more practical self-supervised image denoising. This paper focuses on self-supervised image denoising methods that offer effective solutions to address this challenge. Our comprehensive review thoroughly analyzes the latest advancements in self-supervised image denoising approaches, categorizing them into three distinct classes: General methods, Blind Spot Network (BSN)-based methods, and Transformer-based methods. For each class, we provide a concise theoretical analysis along with their practical applications. To assess the effectiveness of these methods, we present both quantitative and qualitative experimental results on various datasets, utilizing classical algorithms as benchmarks. Additionally, we critically discuss the current limitations of these methods and propose promising directions for future research. By offering a detailed overview of recent developments in self-supervised image denoising, this review serves as an invaluable resource for researchers and practitioners in the field, facilitating a deeper understanding of this emerging domain and inspiring further advancements.
</details>
<details>
<summary>摘要</summary>
深度学习的出现对图像干扰技术带来了革命性的变革。然而，在实际场景中获得干扰级别对的训练数据仍然是一大挑战，这使得自我监督的图像干扰技术成为了一项有优势的选择。这篇评论将 concentrate 于最新的自我监督图像干扰方法，并将它们分为三个不同的类别：一般方法、基于 Blind Spot Network (BSN) 的方法和基于 Transformer 的方法。对于每个类别，我们将提供一个简洁的理论分析，并详细介绍它们在实践中的应用。为评估这些方法的效果，我们将提供量化和质量上的实验结果，使用经典算法作为参考。此外，我们还会 kritically 讨论这些方法的当前的局限性，并提出未来研究的可能性。通过对最新的自我监督图像干扰技术的审视，这篇评论将成为该领域的一个不可或缺的资源，为研究人员和实践者提供深入的了解，并激发更多的进步。
</details></li>
</ul>
<hr>
<h2 id="Partitioned-Saliency-Ranking-with-Dense-Pyramid-Transformers"><a href="#Partitioned-Saliency-Ranking-with-Dense-Pyramid-Transformers" class="headerlink" title="Partitioned Saliency Ranking with Dense Pyramid Transformers"></a>Partitioned Saliency Ranking with Dense Pyramid Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00236">http://arxiv.org/abs/2308.00236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ssecv/psr">https://github.com/ssecv/psr</a></li>
<li>paper_authors: Chengxiao Sun, Yan Xu, Jialun Pei, Haopeng Fang, He Tang</li>
<li>for: 本研究旨在解决saliency ranking中的主观性问题，提出了ranking by partition paradigm方法，可以减少rank scores的归一化问题。</li>
<li>methods: 本文提出了Dense Pyramid Transformer (DPT)模型，用于实现global cross-scale interactions，并且使用ranking by partition paradigm方法来解决rank scores的归一化问题。</li>
<li>results: 实验结果表明，我们的方法可以在多个 benchmark dataset 上出perform all existing methods，并且可以减少计算成本。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/ssecv/PSR%7D">https://github.com/ssecv/PSR}</a> 上获取。<details>
<summary>Abstract</summary>
In recent years, saliency ranking has emerged as a challenging task focusing on assessing the degree of saliency at instance-level. Being subjective, even humans struggle to identify the precise order of all salient instances. Previous approaches undertake the saliency ranking by directly sorting the rank scores of salient instances, which have not explicitly resolved the inherent ambiguities. To overcome this limitation, we propose the ranking by partition paradigm, which segments unordered salient instances into partitions and then ranks them based on the correlations among these partitions. The ranking by partition paradigm alleviates ranking ambiguities in a general sense, as it consistently improves the performance of other saliency ranking models. Additionally, we introduce the Dense Pyramid Transformer (DPT) to enable global cross-scale interactions, which significantly enhances feature interactions with reduced computational burden. Extensive experiments demonstrate that our approach outperforms all existing methods. The code for our method is available at \url{https://github.com/ssecv/PSR}.
</details>
<details>
<summary>摘要</summary>
近年来，焦点排序成为一项具有挑战性的任务，旨在评估每个实例的焦点程度。由于是主观的，也就人类很难准确地确定所有焦点实例的准确顺序。先前的方法通过直接排序焦点实例的排名分数来实现焦点排序，这并没有解决内在的抽象性。为了解决这个限制，我们提议使用分区排序思想，将不同焦点实例分成不同的分区，然后根据这些分区之间的相关性进行排名。这种分区排序方法可以减少焦点排序的抽象性，并且广泛提高其他焦点排序模型的性能。此外，我们还引入了笔直射Transformer（DPT），以启用全球跨级交互，从而显著提高了特征交互的能力，同时减少计算负担。广泛的实验表明，我们的方法可以全面超越所有现有的方法。代码可以在 \url{https://github.com/ssecv/PSR} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Using-Scene-and-Semantic-Features-for-Multi-modal-Emotion-Recognition"><a href="#Using-Scene-and-Semantic-Features-for-Multi-modal-Emotion-Recognition" class="headerlink" title="Using Scene and Semantic Features for Multi-modal Emotion Recognition"></a>Using Scene and Semantic Features for Multi-modal Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00228">http://arxiv.org/abs/2308.00228</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhifeng Wang, Ramesh Sankaranarayana<br>for: 这个论文的目的是提出一种基于场景和 semantics 特征的多模态情绪识别方法，以提高情绪识别的准确性和稳定性。methods: 该方法使用了修改后的 EmbraceNet 来提取图像中的特征，并将身体特征和姿态特征同时学习。另外，该方法还使用了场景特征和 semantics 特征来支持情绪识别。results: 在 EMOTIC 数据集上进行测试，该方法实现了平均准确率为 40.39%，比之前的方法提高了5%。<details>
<summary>Abstract</summary>
Automatic emotion recognition is a hot topic with a wide range of applications. Much work has been done in the area of automatic emotion recognition in recent years. The focus has been mainly on using the characteristics of a person such as speech, facial expression and pose for this purpose. However, the processing of scene and semantic features for emotion recognition has had limited exploration. In this paper, we propose to use combined scene and semantic features, along with personal features, for multi-modal emotion recognition. Scene features will describe the environment or context in which the target person is operating. The semantic feature can include objects that are present in the environment, as well as their attributes and relationships with the target person. In addition, we use a modified EmbraceNet to extract features from the images, which is trained to learn both the body and pose features simultaneously. By fusing both body and pose features, the EmbraceNet can improve the accuracy and robustness of the model, particularly when dealing with partially missing data. This is because having both body and pose features provides a more complete representation of the subject in the images, which can help the model to make more accurate predictions even when some parts of body are missing. We demonstrate the efficiency of our method on the benchmark EMOTIC dataset. We report an average precision of 40.39\% across the 26 emotion categories, which is a 5\% improvement over previous approaches.
</details>
<details>
<summary>摘要</summary>
自动情感认识是一个热门的话题，具有广泛的应用领域。在过去的几年中，关于自动情感认识的研究得到了广泛的关注，主要是利用人类特征，如语音、脸部表达和姿势来实现。然而，Scene和semantic特征的处理对情感认识的研究尚未得到了充分的探索。在本文中，我们提议使用组合场景和semantic特征， along with个人特征， для多modal情感认识。场景特征将描述目标人在运行的环境或情况，semantic特征包括环境中的物品、Attribute和目标人之间的关系。此外，我们使用修改后的EmbraceNet来提取图像中的特征，该模型同时学习体部和姿势特征。通过融合体部和姿势特征，EmbraceNet可以提高模型的准确性和可靠性，特别是处理部分数据时。这是因为具有体部和姿势特征的描述可以帮助模型更好地预测，即使部分身体部分缺失。我们在EMOTIC数据集上进行了效果示例，并Report了26种情绪类别的平均准确率为40.39%，相比之前的方法提高5%。
</details></li>
</ul>
<hr>
<h2 id="Boundary-Difference-Over-Union-Loss-For-Medical-Image-Segmentation"><a href="#Boundary-Difference-Over-Union-Loss-For-Medical-Image-Segmentation" class="headerlink" title="Boundary Difference Over Union Loss For Medical Image Segmentation"></a>Boundary Difference Over Union Loss For Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00220">http://arxiv.org/abs/2308.00220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sunfan-bvb/boundarydouloss">https://github.com/sunfan-bvb/boundarydouloss</a></li>
<li>paper_authors: Fan Sun, Zhiming Luo, Shaozi Li</li>
<li>for: 针对医疗图像分割中的边界区域分割，提出了一种简单有效的损失函数Boundary DoU Loss。</li>
<li>methods: 该损失函数基于区域计算，不需要其他损失函数，训练稳定且易于实现。此外，还使用目标大小进行适应性调整对边界区域应用注意力。</li>
<li>results: 在ACDC和Synapse两个 dataset上，使用UNet、TransUNet和Swin-UNet进行实验，表明我们提出的损失函数有效地提高了边界区域分割的准确率。<details>
<summary>Abstract</summary>
Medical image segmentation is crucial for clinical diagnosis. However, current losses for medical image segmentation mainly focus on overall segmentation results, with fewer losses proposed to guide boundary segmentation. Those that do exist often need to be used in combination with other losses and produce ineffective results. To address this issue, we have developed a simple and effective loss called the Boundary Difference over Union Loss (Boundary DoU Loss) to guide boundary region segmentation. It is obtained by calculating the ratio of the difference set of prediction and ground truth to the union of the difference set and the partial intersection set. Our loss only relies on region calculation, making it easy to implement and training stable without needing any additional losses. Additionally, we use the target size to adaptively adjust attention applied to the boundary regions. Experimental results using UNet, TransUNet, and Swin-UNet on two datasets (ACDC and Synapse) demonstrate the effectiveness of our proposed loss function. Code is available at https://github.com/sunfan-bvb/BoundaryDoULoss.
</details>
<details>
<summary>摘要</summary>
医疗图像分割是诊断的关键。然而，目前的医疗图像分割损失主要关注总分割结果，有 fewer 的损失用于指导边界分割。这些损失经常需要与其他损失结合使用，并且生成不具有效果的结果。为解决这个问题，我们已经开发了一种简单而有效的损失函数，即边界差异上 UNION 损失（Boundary DoU Loss），用于指导边界区域分割。它是通过计算预测和实际值差集的差集与 UNION 集之间的比率来获得的。我们的损失函数只需要进行区域计算，因此容易实现和训练，不需要任何其他损失函数。此外，我们使用目标大小调整边界区域的注意力。实验结果表明，我们使用 UNet、TransUNet 和 Swin-UNet 在 ACDC 和 Synapse 两个 dataset 上，表明我们提议的损失函数是有效的。代码可以在 https://github.com/sunfan-bvb/BoundaryDoULoss 上找到。
</details></li>
</ul>
<hr>
<h2 id="Multi-goal-Audio-visual-Navigation-using-Sound-Direction-Map"><a href="#Multi-goal-Audio-visual-Navigation-using-Sound-Direction-Map" class="headerlink" title="Multi-goal Audio-visual Navigation using Sound Direction Map"></a>Multi-goal Audio-visual Navigation using Sound Direction Map</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00219">http://arxiv.org/abs/2308.00219</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haru Kondoh, Asako Kanezaki</li>
<li>For: 这 paper 是关于多目标听视导航任务的研究，它是在已有的视觉听音导航任务基础上增加多个目标的情况。* Methods: 这 paper 使用了深度强化学习代理人进行 navigation，并在不同的情况下进行了实验研究，以了解多目标听视导航任务的难度。另外，paper 还提出了一种名为声音方向地图（SDM）的方法，可以在学习型 manner 中动态地Localize 多个声音源。* Results: 实验结果表明，使用 SDM 方法可以显著提高多个基eline 方法的性能，不管目标数量多少。<details>
<summary>Abstract</summary>
Over the past few years, there has been a great deal of research on navigation tasks in indoor environments using deep reinforcement learning agents. Most of these tasks use only visual information in the form of first-person images to navigate to a single goal. More recently, tasks that simultaneously use visual and auditory information to navigate to the sound source and even navigation tasks with multiple goals instead of one have been proposed. However, there has been no proposal for a generalized navigation task combining these two types of tasks and using both visual and auditory information in a situation where multiple sound sources are goals. In this paper, we propose a new framework for this generalized task: multi-goal audio-visual navigation. We first define the task in detail, and then we investigate the difficulty of the multi-goal audio-visual navigation task relative to the current navigation tasks by conducting experiments in various situations. The research shows that multi-goal audio-visual navigation has the difficulty of the implicit need to separate the sources of sound. Next, to mitigate the difficulties in this new task, we propose a method named sound direction map (SDM), which dynamically localizes multiple sound sources in a learning-based manner while making use of past memories. Experimental results show that the use of SDM significantly improves the performance of multiple baseline methods, regardless of the number of goals.
</details>
<details>
<summary>摘要</summary>
在过去几年，深度强化学习代理人在室内环境中完成导航任务得到了很多研究。大多数这些任务只使用视觉信息，即首人图像，导航到单个目标。然而，最近提出了同时使用视觉和听音信息导航到声源的任务，以及多个目标导航任务。然而，没有任何提案可以将这两种任务结合起来，并使用两种类型的信息在多个声源目标下进行导航。在这篇论文中，我们提出了一个新的框架：多目标音频视觉导航。我们首先定义了这个任务，然后通过在不同情况下进行实验来调查这个任务的困难程度。实验结果表明，多目标音频视觉导航任务存在隐式地分离声音来源的需求，这使得任务变得更加困难。然后，我们提出了一种名为声音方向地图（SDM）的方法，可以在学习基础上动态地Localize多个声音来源，并且利用过去的记忆。实验结果表明，使用SDM可以significantly improve多个基eline方法的表现，不管声音来源的数量如何。
</details></li>
</ul>
<hr>
<h2 id="Robust-Single-view-Cone-beam-X-ray-Pose-Estimation-with-Neural-Tuned-Tomography-NeTT-and-Masked-Neural-Radiance-Fields-mNeRF"><a href="#Robust-Single-view-Cone-beam-X-ray-Pose-Estimation-with-Neural-Tuned-Tomography-NeTT-and-Masked-Neural-Radiance-Fields-mNeRF" class="headerlink" title="Robust Single-view Cone-beam X-ray Pose Estimation with Neural Tuned Tomography (NeTT) and Masked Neural Radiance Fields (mNeRF)"></a>Robust Single-view Cone-beam X-ray Pose Estimation with Neural Tuned Tomography (NeTT) and Masked Neural Radiance Fields (mNeRF)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00214">http://arxiv.org/abs/2308.00214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaochao Zhou, Syed Hasib Akhter Faruqui, Abhinav Patel, Ramez N. Abdalla, Michael C. Hurley, Ali Shaibani, Matthew B. Potts, Babak S. Jahromi, Leon Cho, Sameer A. Ansari, Donald R. Cantrell</li>
<li>for: 这 paper 是为了解决基于 X-ray 投影的医学小剖手术中的姿态估计问题。</li>
<li>methods: 这 paper 使用了新的 pose estimation 方法，包括 DiffDRR、NeTT 和 mNeRF。这些方法都利用了 TensorFlow 中的自动微分，并且使用了高精度的 DRR synthesis 来提高姿态估计的精度。</li>
<li>results: 这 paper 的结果表明，NeTT 和 mNeRF 都能够有效地进行姿态估计，并且两者的成功率都高于 93%。然而，NeTT 的计算成本远低于 mNeRF，而且 NeTT 可以在训练和姿态估计阶段都具有更好的性能。此外，paper 还表明了 NeTT 可以在不同的人体标本上进行高精度的 DRR synthesis 和姿态估计。因此， authors 建议使用 NeTT 来实现 robust 的姿态估计。<details>
<summary>Abstract</summary>
Many tasks performed in image-guided, mini-invasive, medical procedures can be cast as pose estimation problems, where an X-ray projection is utilized to reach a target in 3D space. Expanding on recent advances in the differentiable rendering of optically reflective materials, we introduce new methods for pose estimation of radiolucent objects using X-ray projections, and we demonstrate the critical role of optimal view synthesis in performing this task. We first develop an algorithm (DiffDRR) that efficiently computes Digitally Reconstructed Radiographs (DRRs) and leverages automatic differentiation within TensorFlow. Pose estimation is performed by iterative gradient descent using a loss function that quantifies the similarity of the DRR synthesized from a randomly initialized pose and the true fluoroscopic image at the target pose. We propose two novel methods for high-fidelity view synthesis, Neural Tuned Tomography (NeTT) and masked Neural Radiance Fields (mNeRF). Both methods rely on classic Cone-Beam Computerized Tomography (CBCT); NeTT directly optimizes the CBCT densities, while the non-zero values of mNeRF are constrained by a 3D mask of the anatomic region segmented from CBCT. We demonstrate that both NeTT and mNeRF distinctly improve pose estimation within our framework. By defining a successful pose estimate to be a 3D angle error of less than 3 deg, we find that NeTT and mNeRF can achieve similar results, both with overall success rates more than 93%. However, the computational cost of NeTT is significantly lower than mNeRF in both training and pose estimation. Furthermore, we show that a NeTT trained for a single subject can generalize to synthesize high-fidelity DRRs and ensure robust pose estimations for all other subjects. Therefore, we suggest that NeTT is an attractive option for robust pose estimation using fluoroscopic projections.
</details>
<details>
<summary>摘要</summary>
许多在图像导航、微创手术中进行的任务可以被看作为位置估计问题，其中使用X射线投影来达到3D空间中的目标。在不断提高数据渠道 Rendering 技术的基础之上，我们介绍了一种新的方法，即基于 X射线投影的对象位置估计。我们首先开发了一种名为 DiffDRR 的算法，它可以高效计算 Digitally Reconstructed Radiographs (DRRs)，并在 TensorFlow 中使用自动导数。在 pose 估计中，我们使用一个损失函数，该函数衡量 DRR 从 randomly initialized pose 中生成的synthesized 和真实 fluoroscopic 图像在目标姿势下的相似性。我们提出了两种高精度视图合成方法，即 Neural Tuned Tomography (NeTT) 和 masked Neural Radiance Fields (mNeRF)。两种方法都基于 Cone-Beam Computerized Tomography (CBCT)，NeTT 直接优化 CBCT 密度，而 mNeRF 的非零值被限制为 segmented 从 CBCT 中的3Dmask。我们发现 NeTT 和 mNeRF 都可以提高 pose 估计的准确性，其中 NeTT 的计算成本较低，并且可以在训练和 pose 估计中进行高效的计算。此外，我们发现 NeTT 可以在不同主体之间进行交互学习，并且可以在单个主体训练后对所有主体进行高精度的 DRR 生成和 pose 估计。因此，我们认为 NeTT 是一种可靠的选择 для基于 fluoroscopic 投影的 pose 估计。
</details></li>
</ul>
<hr>
<h2 id="Scene-Separation-Data-Selection-Temporal-Segmentation-Algorithm-for-Real-Time-Video-Stream-Analysis"><a href="#Scene-Separation-Data-Selection-Temporal-Segmentation-Algorithm-for-Real-Time-Video-Stream-Analysis" class="headerlink" title="Scene Separation &amp; Data Selection: Temporal Segmentation Algorithm for Real-Time Video Stream Analysis"></a>Scene Separation &amp; Data Selection: Temporal Segmentation Algorithm for Real-Time Video Stream Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00210">http://arxiv.org/abs/2308.00210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuelin Xin, Zihan Zhou, Yuxuan Xia</li>
<li>for: 视频流理解的实时解读</li>
<li>methods: 使用图像差分比较 Temporal segmentation算法</li>
<li>results: 实验结果达到90%以上的总准确率<details>
<summary>Abstract</summary>
We present 2SDS (Scene Separation and Data Selection algorithm), a temporal segmentation algorithm used in real-time video stream interpretation. It complements CNN-based models to make use of temporal information in videos. 2SDS can detect the change between scenes in a video stream by com-paring the image difference between two frames. It separates a video into segments (scenes), and by combining itself with a CNN model, 2SDS can select the optimal result for each scene. In this paper, we will be discussing some basic methods and concepts behind 2SDS, as well as presenting some preliminary experiment results regarding 2SDS. During these experiments, 2SDS has achieved an overall accuracy of over 90%.
</details>
<details>
<summary>摘要</summary>
我们现在介绍2SDS（Scene Separation and Data Selection算法），一种用于实时视频流理解的时间段分算法。它与基于CNN（卷积神经网络）模型结合使用，以利用视频中的时间信息。2SDS可以在视频流中检测图像差异，并将视频流分解成场景（scene）。通过与CNN模型结合使用，2SDS可以选择每个场景的优化结果。在这篇论文中，我们将讨论2SDS的一些基本方法和概念，以及2SDS的一些初步实验结果。在这些实验中，2SDS达到了超过90%的总准确率。
</details></li>
</ul>
<hr>
<h2 id="CBCL-PR-A-Cognitively-Inspired-Model-for-Class-Incremental-Learning-in-Robotics"><a href="#CBCL-PR-A-Cognitively-Inspired-Model-for-Class-Incremental-Learning-in-Robotics" class="headerlink" title="CBCL-PR: A Cognitively Inspired Model for Class-Incremental Learning in Robotics"></a>CBCL-PR: A Cognitively Inspired Model for Class-Incremental Learning in Robotics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00199">http://arxiv.org/abs/2308.00199</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aliayub7/cbcl-pr">https://github.com/aliayub7/cbcl-pr</a></li>
<li>paper_authors: Ali Ayub, Alan R. Wagner</li>
<li>for: 该论文解决了基于少量数据的自适应学习和增量学习问题，即AI机器人需要在有限数据情况下不断学习和适应环境中。</li>
<li>methods: 该论文提出了一种基于 hippocampus 和 neocortex 理论的新框架，用于解决 Few-Shot class Incremental Learning（FSIL）问题。该框架表示物体类划分成多个集合，并将其存储在内存中。重复播放过去类划分中生成的数据，以避免卷积学习新类时忘记过去类。</li>
<li>results: 该论文在两个物体分类 dataset 上进行了评估，并取得了当今最佳性能（SOTA）。此外，在一个 robot 上也进行了评估，并证明了机器人可以在有限人工协助下不断学习分类大量家用物品。<details>
<summary>Abstract</summary>
For most real-world applications, robots need to adapt and learn continually with limited data in their environments. In this paper, we consider the problem of Few-Shot class Incremental Learning (FSIL), in which an AI agent is required to learn incrementally from a few data samples without forgetting the data it has previously learned. To solve this problem, we present a novel framework inspired by theories of concept learning in the hippocampus and the neocortex. Our framework represents object classes in the form of sets of clusters and stores them in memory. The framework replays data generated by the clusters of the old classes, to avoid forgetting when learning new classes. Our approach is evaluated on two object classification datasets resulting in state-of-the-art (SOTA) performance for class-incremental learning and FSIL. We also evaluate our framework for FSIL on a robot demonstrating that the robot can continually learn to classify a large set of household objects with limited human assistance.
</details>
<details>
<summary>摘要</summary>
For most real-world applications, robots need to adapt and learn continually with limited data in their environments. In this paper, we consider the problem of Few-Shot class Incremental Learning (FSIL), in which an AI agent is required to learn incrementally from a few data samples without forgetting the data it has previously learned. To solve this problem, we present a novel framework inspired by theories of concept learning in the hippocampus and the neocortex. Our framework represents object classes in the form of sets of clusters and stores them in memory. The framework replays data generated by the clusters of the old classes, to avoid forgetting when learning new classes. Our approach is evaluated on two object classification datasets, resulting in state-of-the-art (SOTA) performance for class-incremental learning and FSIL. We also evaluate our framework for FSIL on a robot, demonstrating that the robot can continually learn to classify a large set of household objects with limited human assistance.Here's the translation in Traditional Chinese:For most real-world applications, robots need to adapt and learn continually with limited data in their environments. In this paper, we consider the problem of Few-Shot class Incremental Learning (FSIL), in which an AI agent is required to learn incrementally from a few data samples without forgetting the data it has previously learned. To solve this problem, we present a novel framework inspired by theories of concept learning in the hippocampus and the neocortex. Our framework represents object classes in the form of sets of clusters and stores them in memory. The framework replays data generated by the clusters of the old classes, to avoid forgetting when learning new classes. Our approach is evaluated on two object classification datasets, resulting in state-of-the-art (SOTA) performance for class-incremental learning and FSIL. We also evaluate our framework for FSIL on a robot, demonstrating that the robot can continually learn to classify a large set of household objects with limited human assistance.
</details></li>
</ul>
<hr>
<h2 id="C-DARL-Contrastive-diffusion-adversarial-representation-learning-for-label-free-blood-vessel-segmentation"><a href="#C-DARL-Contrastive-diffusion-adversarial-representation-learning-for-label-free-blood-vessel-segmentation" class="headerlink" title="C-DARL: Contrastive diffusion adversarial representation learning for label-free blood vessel segmentation"></a>C-DARL: Contrastive diffusion adversarial representation learning for label-free blood vessel segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00193">http://arxiv.org/abs/2308.00193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boah Kim, Yujin Oh, Bradford J. Wood, Ronald M. Summers, Jong Chul Ye</li>
<li>For: The paper is written for the purpose of developing a self-supervised vessel segmentation method for medical imaging, which can help improve the accuracy and efficiency of vascular disease diagnosis and interventional planning.* Methods: The paper proposes a novel method called C-DARL, which combines a diffusion module and a generation module to learn the distribution of multi-domain blood vessel data. The model uses contrastive learning through a mask-based contrastive loss to generate more realistic vessel representations.* Results: The experimental results show that C-DARL achieves performance improvement over baseline methods with noise robustness, indicating the effectiveness of the proposed method for vessel segmentation in medical imaging.<details>
<summary>Abstract</summary>
Blood vessel segmentation in medical imaging is one of the essential steps for vascular disease diagnosis and interventional planning in a broad spectrum of clinical scenarios in image-based medicine and interventional medicine. Unfortunately, manual annotation of the vessel masks is challenging and resource-intensive due to subtle branches and complex structures. To overcome this issue, this paper presents a self-supervised vessel segmentation method, dubbed the contrastive diffusion adversarial representation learning (C-DARL) model. Our model is composed of a diffusion module and a generation module that learns the distribution of multi-domain blood vessel data by generating synthetic vessel images from diffusion latent. Moreover, we employ contrastive learning through a mask-based contrastive loss so that the model can learn more realistic vessel representations. To validate the efficacy, C-DARL is trained using various vessel datasets, including coronary angiograms, abdominal digital subtraction angiograms, and retinal imaging. Experimental results confirm that our model achieves performance improvement over baseline methods with noise robustness, suggesting the effectiveness of C-DARL for vessel segmentation.
</details>
<details>
<summary>摘要</summary>
医学影像中血管分割是诊断血管疾病和 intervención规划的关键步骤，在各种临床场景中都非常重要。然而，手动标注血管Masks是困难和资源占用的，这是因为血管结构细节和分支非常细。为了解决这个问题，本文提出了一种自动学习的血管分割方法，名为对比扩散对抗表示学习（C-DARL）模型。我们的模型包括扩散模块和生成模块，通过生成多个频率血管数据的分布来学习血管图像的分布。此外，我们采用对比学习，通过一个基于Mask的对比损失函数，使模型学习更加真实的血管表示。为验证效果，C-DARL被训练了多种血管数据集，包括心血管扫描、腹部数字扫描和视网膜成像。实验结果表明，我们的模型在噪声环境下表现出性能提高，这表明C-DARL是有效的血管分割方法。
</details></li>
</ul>
<hr>
<h2 id="Detecting-the-Anomalies-in-LiDAR-Pointcloud"><a href="#Detecting-the-Anomalies-in-LiDAR-Pointcloud" class="headerlink" title="Detecting the Anomalies in LiDAR Pointcloud"></a>Detecting the Anomalies in LiDAR Pointcloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00187">http://arxiv.org/abs/2308.00187</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chiyu Zhang, Ji Han, Yao Zou, Kexin Dong, Yujia Li, Junchun Ding, Xiaoling Han</li>
<li>for: 本研究旨在检测LiDAR数据中异常点云的存在，以提高自动驾驶系统的安全性。</li>
<li>methods: 本文提出了一种基于点云特征分析的异常点云检测方法，包括点云质量指标的开发，以评估点云中噪声水平。这种方法不需要标注或训练，因此可以快速执行和扩展。</li>
<li>results: 经过实验表明，该方法能够有效地检测LiDAR数据中异常点云，并可以适应不同的扫描机制和激光谱。<details>
<summary>Abstract</summary>
LiDAR sensors play an important role in the perception stack of modern autonomous driving systems. Adverse weather conditions such as rain, fog and dust, as well as some (occasional) LiDAR hardware fault may cause the LiDAR to produce pointcloud with abnormal patterns such as scattered noise points and uncommon intensity values. In this paper, we propose a novel approach to detect whether a LiDAR is generating anomalous pointcloud by analyzing the pointcloud characteristics. Specifically, we develop a pointcloud quality metric based on the LiDAR points' spatial and intensity distribution to characterize the noise level of the pointcloud, which relies on pure mathematical analysis and does not require any labeling or training as learning-based methods do. Therefore, the method is scalable and can be quickly deployed either online to improve the autonomy safety by monitoring anomalies in the LiDAR data or offline to perform in-depth study of the LiDAR behavior over large amount of data. The proposed approach is studied with extensive real public road data collected by LiDARs with different scanning mechanisms and laser spectrums, and is proven to be able to effectively handle various known and unknown sources of pointcloud anomaly.
</details>
<details>
<summary>摘要</summary>
利达 laser 传感器在现代自动驾驶系统中扮演着重要的角色。不良天气条件如雨、雾和尘埃，以及一些（偶尔）的 LiDAR 硬件问题，可能会导致 LiDAR 生成异常的点云，如散发的噪声点和不寻常的INTENSITY值。在这篇论文中，我们提出了一种新的方法来检测 LiDAR 生成的点云是否异常。specifically，我们开发了一个基于 LiDAR 点云的空间和INTENSITY 分布的点云质量度量，以衡量点云的噪声水平。这种方法不需要标注或训练，因此可以快速执行并可以在线监测 LiDAR 数据中的异常，以提高自动驾驶的安全性。我们对实际的公共路数据进行了广泛的研究，并证明了该方法可以有效地处理不同的 LiDAR 扫描机制和激光谱。
</details></li>
</ul>
<hr>
<h2 id="Towards-Imbalanced-Large-Scale-Multi-label-Classification-with-Partially-Annotated-Labels"><a href="#Towards-Imbalanced-Large-Scale-Multi-label-Classification-with-Partially-Annotated-Labels" class="headerlink" title="Towards Imbalanced Large Scale Multi-label Classification with Partially Annotated Labels"></a>Towards Imbalanced Large Scale Multi-label Classification with Partially Annotated Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00166">http://arxiv.org/abs/2308.00166</a></li>
<li>repo_url: None</li>
<li>paper_authors: XIn Zhang, Yuqi Song, Fei Zuo, Xiaofeng Wang</li>
<li>For: 多个标签分类问题在日常生活中广泛存在，其中一个实例可以与多个类相关。这是一种指导学习方法，需要大量的标注数据。但是，标注数据可能是时间consuming且可能无法实现巨大的标注空间。另外，标签偏好可能限制多个标签分类器的性能，特别是缺失某些标签。因此，研究如何使用偏好的标签来训练神经网络是有意义的。* Methods: 我们引入 Pseudo-labeling 技术，允许常见的神经网络在部分标注设置下运行，无需额外复杂的结构。然后，我们提出了一种新的损失函数，利用现有数据集的统计信息来有效地缓解标签偏好问题。另外，我们设计了一种动态训练方案，以减少标注空间的维度，进一步缓解偏好。* Results: 我们在 COCO、NUS-WIDE、CUB 和 Open Images 等多个公共可用的多个标签数据集上进行了广泛的实验。结果表明，我们的方法比一些现状顶尖方法高效，而且在一些部分标注设置下，我们的方法甚至超过了使用全标注的方法。<details>
<summary>Abstract</summary>
Multi-label classification is a widely encountered problem in daily life, where an instance can be associated with multiple classes. In theory, this is a supervised learning method that requires a large amount of labeling. However, annotating data is time-consuming and may be infeasible for huge labeling spaces. In addition, label imbalance can limit the performance of multi-label classifiers, especially when some labels are missing. Therefore, it is meaningful to study how to train neural networks using partial labels. In this work, we address the issue of label imbalance and investigate how to train classifiers using partial labels in large labeling spaces. First, we introduce the pseudo-labeling technique, which allows commonly adopted networks to be applied in partially labeled settings without the need for additional complex structures. Then, we propose a novel loss function that leverages statistical information from existing datasets to effectively alleviate the label imbalance problem. In addition, we design a dynamic training scheme to reduce the dimension of the labeling space and further mitigate the imbalance. Finally, we conduct extensive experiments on some publicly available multi-label datasets such as COCO, NUS-WIDE, CUB, and Open Images to demonstrate the effectiveness of the proposed approach. The results show that our approach outperforms several state-of-the-art methods, and surprisingly, in some partial labeling settings, our approach even exceeds the methods trained with full labels.
</details>
<details>
<summary>摘要</summary>
多个标签分类是日常生活中广泛存在的问题，其中一个实例可以与多个类相关。理论上来说，这是一种超级vised学习方法，需要大量标注数据。然而，标注数据可能是时间消耗和不可能实现的庞大标注空间。此外，标签偏好可能限制多个标签分类器的性能，特别是缺失某些标签时。因此，研究如何使用偏好标签进行神经网络训练是有意义的。在这种工作中，我们解决标签偏好问题，并 investigate如何使用偏好标签进行神经网络训练在大型标注空间中。首先，我们介绍了假标签技术，允许常用的网络在部分标注 setting中使用，无需额外复杂结构。然后，我们提出了一种新的损失函数，可以从现有数据集中获取有用的统计信息，有效地解决标签偏好问题。另外，我们设计了一种动态训练方案，以降低标注空间的维度，进一步减轻标签偏好。最后，我们在一些公共可用的多个标签数据集上进行了广泛的实验，如COCO、NUS-WIDE、CUB和Open Images等。结果显示，我们的方法可以与一些状态机制的方法相比，甚至在某些部分标注设置下，我们的方法可以超过全标注的方法。
</details></li>
</ul>
<hr>
<h2 id="Multispectral-Image-Segmentation-in-Agriculture-A-Comprehensive-Study-on-Fusion-Approaches"><a href="#Multispectral-Image-Segmentation-in-Agriculture-A-Comprehensive-Study-on-Fusion-Approaches" class="headerlink" title="Multispectral Image Segmentation in Agriculture: A Comprehensive Study on Fusion Approaches"></a>Multispectral Image Segmentation in Agriculture: A Comprehensive Study on Fusion Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00159">http://arxiv.org/abs/2308.00159</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cybonic/misagriculture">https://github.com/cybonic/misagriculture</a></li>
<li>paper_authors: Nuno Cunha, Tiago Barros, Mário Reis, Tiago Marta, Cristiano Premebida, Urbano J. Nunes</li>
<li>for: 本研究旨在探讨多spectral imaging在农业应用中的可支持，包括图像分割、农业监测、场 robotics 和含量估计等。</li>
<li>methods: 本研究使用融合方法提高图像分割过程中的精度，并比较了不同的融合方法，包括RGB和NDVI作为输入，用于检测农作物行进检测。</li>
<li>results: 实验表明，传统方法在certain specialized agricultural applications中仍然保持效果，而融合策略中的late fusion方法在不同的分割场景中表现出了最高的鲁棒性和效果。<details>
<summary>Abstract</summary>
Multispectral imagery is frequently incorporated into agricultural tasks, providing valuable support for applications such as image segmentation, crop monitoring, field robotics, and yield estimation. From an image segmentation perspective, multispectral cameras can provide rich spectral information, helping with noise reduction and feature extraction. As such, this paper concentrates on the use of fusion approaches to enhance the segmentation process in agricultural applications. More specifically, in this work, we compare different fusion approaches by combining RGB and NDVI as inputs for crop row detection, which can be useful in autonomous robots operating in the field. The inputs are used individually as well as combined at different times of the process (early and late fusion) to perform classical and DL-based semantic segmentation. In this study, two agriculture-related datasets are subjected to analysis using both deep learning (DL)-based and classical segmentation methodologies. The experiments reveal that classical segmentation methods, utilizing techniques such as edge detection and thresholding, can effectively compete with DL-based algorithms, particularly in tasks requiring precise foreground-background separation. This suggests that traditional methods retain their efficacy in certain specialized applications within the agricultural domain. Moreover, among the fusion strategies examined, late fusion emerges as the most robust approach, demonstrating superiority in adaptability and effectiveness across varying segmentation scenarios. The dataset and code is available at https://github.com/Cybonic/MISAgriculture.git.
</details>
<details>
<summary>摘要</summary>
多spectral影像在农业任务中广泛应用，提供了价值的支持，包括图像分割、农业监测、场地 робо扮演和产量估计。从图像分割角度来看，多spectral相机可以提供丰富的spectral信息，帮助降低噪声和提取特征。因此，本文集中关注在农业应用中使用融合方法提高分割过程的问题。更 Specifically，在这种工作中，我们比较了不同的融合方法，将RGB和NDVI作为输入进行耕地检测，这可以在自动化机器在场地中运行时提供有用的支持。这些输入分别使用以及在不同时间点（早期和晚期）进行融合，以执行经典和深度学习（DL）基于的semantic分割。在这项研究中，我们使用了两个农业相关的数据集进行分析，并使用经典和DL基于的方法进行分割方法。实验表明，经典分割方法，使用edge检测和阈值分割等技术，可以有效竞争DL基于的算法，特别是需要精确的前景-背景分离任务。这表明，传统方法在农业领域中特定应用场景中仍保留其效果。此外，我们对融合策略进行了分析，发现融合截止时间点为晚期融合是最有效的，在不同的分割enario中表现出了最高的适应性和效果。数据集和代码可以在https://github.com/Cybonic/MISAgriculture.git中下载。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Semi-Supervised-Learning-Framework-for-Surgical-Gesture-Segmentation-and-Recognition-Based-on-Multi-Modality-Data"><a href="#Hierarchical-Semi-Supervised-Learning-Framework-for-Surgical-Gesture-Segmentation-and-Recognition-Based-on-Multi-Modality-Data" class="headerlink" title="Hierarchical Semi-Supervised Learning Framework for Surgical Gesture Segmentation and Recognition Based on Multi-Modality Data"></a>Hierarchical Semi-Supervised Learning Framework for Surgical Gesture Segmentation and Recognition Based on Multi-Modality Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02529">http://arxiv.org/abs/2308.02529</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhili Yuan, Jialin Lin, Dandan Zhang</li>
<li>for: 这份研究的目的是为了分析遗传外科手术的工作流程，特别是用于自动化遗传外科手术、评估外科技术等。</li>
<li>methods: 这篇研究使用了一个层次 semi-supervised learning 框架，使用多种数据（运动和视觉数据）进行手术动作排序。</li>
<li>results: 研究结果显示，使用这个方法可以在 JIGSAWS 数据库中得到平均 F1 分数为 0.623 的排序结果，以及识别率为 0.856。<details>
<summary>Abstract</summary>
Segmenting and recognizing surgical operation trajectories into distinct, meaningful gestures is a critical preliminary step in surgical workflow analysis for robot-assisted surgery. This step is necessary for facilitating learning from demonstrations for autonomous robotic surgery, evaluating surgical skills, and so on. In this work, we develop a hierarchical semi-supervised learning framework for surgical gesture segmentation using multi-modality data (i.e. kinematics and vision data). More specifically, surgical tasks are initially segmented based on distance characteristics-based profiles and variance characteristics-based profiles constructed using kinematics data. Subsequently, a Transformer-based network with a pre-trained `ResNet-18' backbone is used to extract visual features from the surgical operation videos. By combining the potential segmentation points obtained from both modalities, we can determine the final segmentation points. Furthermore, gesture recognition can be implemented based on supervised learning. The proposed approach has been evaluated using data from the publicly available JIGSAWS database, including Suturing, Needle Passing, and Knot Tying tasks. The results reveal an average F1 score of 0.623 for segmentation and an accuracy of 0.856 for recognition.
</details>
<details>
<summary>摘要</summary>
划分和识别手术操作轨迹为独特和有意义的姿势是机器人助手手术中的关键前期步骤。这个步骤是为了促进从示例学习到自主机器人手术、评估手术技巧等。在这种工作中，我们开发了一种层次 semi-supervised 学习框架 для手术姿势划分，使用多modal 数据（即遥感和视觉数据）。更具体来说，手术任务首先根据距离特征profile和差异特征profile在遥感数据上建立分 segmentation points。然后，使用预训练的 `ResNet-18` 框架，我们使用视觉特征从手术操作视频中提取特征。通过将两种模式的可能性划分点结合，我们可以确定最终划分点。此外，可以基于有监督学习来实现姿势识别。我们的方法在公共可用的 JIGSAWS 数据库中进行了评估，包括缝钉、针刺和缝结任务。结果表明，划分得到的 F1 分数为 0.623，并且识别率为 0.856。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-for-Data-and-Model-Heterogeneity-in-Medical-Imaging"><a href="#Federated-Learning-for-Data-and-Model-Heterogeneity-in-Medical-Imaging" class="headerlink" title="Federated Learning for Data and Model Heterogeneity in Medical Imaging"></a>Federated Learning for Data and Model Heterogeneity in Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00155">http://arxiv.org/abs/2308.00155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hussain Ahmad Madni, Rao Muhammad Umer, Gian Luca Foresti</li>
<li>for: 该论文旨在解决 Federated Learning (FL) 中的数据和模型不一致问题，以提高 FL 的效率。</li>
<li>methods: 该论文提出了一种方法 named MDH-FL (Exploiting Model and Data Heterogeneity in FL)，通过知识传承和对称损失来解决数据和模型不一致问题，以提高模型性能。</li>
<li>results: 实验结果表明，该方法在医疗数据集上比其他方法更有优势，可以更好地处理医疗机构中的数据和模型不一致问题。<details>
<summary>Abstract</summary>
Federated Learning (FL) is an evolving machine learning method in which multiple clients participate in collaborative learning without sharing their data with each other and the central server. In real-world applications such as hospitals and industries, FL counters the challenges of data heterogeneity and model heterogeneity as an inevitable part of the collaborative training. More specifically, different organizations, such as hospitals, have their own private data and customized models for local training. To the best of our knowledge, the existing methods do not effectively address both problems of model heterogeneity and data heterogeneity in FL. In this paper, we exploit the data and model heterogeneity simultaneously, and propose a method, MDH-FL (Exploiting Model and Data Heterogeneity in FL) to solve such problems to enhance the efficiency of the global model in FL. We use knowledge distillation and a symmetric loss to minimize the heterogeneity and its impact on the model performance. Knowledge distillation is used to solve the problem of model heterogeneity, and symmetric loss tackles with the data and label heterogeneity. We evaluate our method on the medical datasets to conform the real-world scenario of hospitals, and compare with the existing methods. The experimental results demonstrate the superiority of the proposed approach over the other existing methods.
</details>
<details>
<summary>摘要</summary>
federated 学习（FL）是一种在多个客户端合作学习而不是分享数据之间的演化机器学习方法。在现实世界中，如医院和产业中，FL 可以避免数据和模型不同性的挑战，作为合作训练的不可避免的一部分。更specifically，不同的组织，如医院，拥有自己的私有数据和自定义的本地模型进行本地训练。据我们所知，现有的方法不能有效地解决FL中的数据和模型不同性问题。在这篇论文中，我们利用数据和模型不同性同时，并提出了一种方法，MDH-FL（利用数据和模型不同性的FL），以解决这些问题，并提高FL的全球模型效率。我们使用知识塑造和对称损失来减少不同性的影响。知识塑造用于解决模型不同性问题，而对称损失用于解决数据和标签不同性问题。我们在医疗数据集上进行了实验，以验证这种方法在现实世界中的可行性，并与现有方法进行比较。实验结果表明，我们的方法在FL中表现出了superiority。
</details></li>
</ul>
<hr>
<h2 id="Controlling-Geometric-Abstraction-and-Texture-for-Artistic-Images"><a href="#Controlling-Geometric-Abstraction-and-Texture-for-Artistic-Images" class="headerlink" title="Controlling Geometric Abstraction and Texture for Artistic Images"></a>Controlling Geometric Abstraction and Texture for Artistic Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00148">http://arxiv.org/abs/2308.00148</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MartinBuessemeyer/Artistic-Texture-Control">https://github.com/MartinBuessemeyer/Artistic-Texture-Control</a></li>
<li>paper_authors: Martin Büßemeyer, Max Reimann, Benito Buchheim, Amir Semmo, Jürgen Döllner, Matthias Trapp</li>
<li>for: 这个论文是为了提出一种新的方法，用于对艺术图像中的几何抽象和文本URE的交互控制。</li>
<li>methods: 该方法使用了一种干预式的方法，将输入图像分解成形状和高频环境的参数表示，从而实现独立控制颜色和文本URE。这个表示中的每个参数控制了一系列可 diferenciable 的样式化过滤器的笔画属性。</li>
<li>results: 该方法可以实现多种艺术风格的编辑，包括全局和地方的形状和笔画属性的交互修改。此外，它还可以通过参考图像和文本提示来进行优化的文本风格传输，以及在参数空间中单独预测单个和任意样式参数的网络训练。<details>
<summary>Abstract</summary>
We present a novel method for the interactive control of geometric abstraction and texture in artistic images. Previous example-based stylization methods often entangle shape, texture, and color, while generative methods for image synthesis generally either make assumptions about the input image, such as only allowing faces or do not offer precise editing controls. By contrast, our holistic approach spatially decomposes the input into shapes and a parametric representation of high-frequency details comprising the image's texture, thus enabling independent control of color and texture. Each parameter in this representation controls painterly attributes of a pipeline of differentiable stylization filters. The proposed decoupling of shape and texture enables various options for stylistic editing, including interactive global and local adjustments of shape, stroke, and painterly attributes such as surface relief and contours. Additionally, we demonstrate optimization-based texture style-transfer in the parametric space using reference images and text prompts, as well as the training of single- and arbitrary style parameter prediction networks for real-time texture decomposition.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法用于艺术图像的交互式控制 geometric abstraction 和 texture。先前的例子基于的涂抹方法通常会杂mix shape, texture 和颜色，而生成图像 Synthesis 方法通常会对输入图像做假设，例如只允许人脸或不提供精确的编辑控制。相比之下，我们的总体方法将输入图像空间分解为形状和高频环境的 parametric 表示，从而启用独立控制颜色和 texture。每个参数在这个表示中控制着涂抹过程中的笔触属性和涂抹材质。这种划分shape和 texture 允许在不同的风格编辑中进行交互式的全局和本地调整形状、roke 和笔触属性，例如表面 relief 和边沿。此外，我们还示出了参考图像和文本提示的优化基于 texture style-transfer 在参数空间中，以及单个和任意风格参数预测网络的训练 для实时 texture decomposition。
</details></li>
</ul>
<hr>
<h2 id="Ensemble-Learning-with-Residual-Transformer-for-Brain-Tumor-Segmentation"><a href="#Ensemble-Learning-with-Residual-Transformer-for-Brain-Tumor-Segmentation" class="headerlink" title="Ensemble Learning with Residual Transformer for Brain Tumor Segmentation"></a>Ensemble Learning with Residual Transformer for Brain Tumor Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00128">http://arxiv.org/abs/2308.00128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lanhong Yao, Zheyuan Zhang, Ulas Bagci</li>
<li>for: 这个论文旨在提高脑癌分类的精度，因为现有的 U-Net 架构具有复杂的形状和 texture 的问题，以及 Labeling 的问题。</li>
<li>methods: 这个论文提出了一个新的网络架构，将 Transformers  integrate 到了自适应的 U-Net 中，以获取3D 维度的 Volume 上下文，并且添加了一个 residual 连接，以避免资讯流动的干扰。</li>
<li>results: 在 BraTS 2021 数据集上（3D），我们的模型获得了87.6% 的 mean Dice 分数，比前一代方法高， demonstrating the potential of combining multiple architectures to optimize brain tumor segmentation.<details>
<summary>Abstract</summary>
Brain tumor segmentation is an active research area due to the difficulty in delineating highly complex shaped and textured tumors as well as the failure of the commonly used U-Net architectures. The combination of different neural architectures is among the mainstream research recently, particularly the combination of U-Net with Transformers because of their innate attention mechanism and pixel-wise labeling. Different from previous efforts, this paper proposes a novel network architecture that integrates Transformers into a self-adaptive U-Net to draw out 3D volumetric contexts with reasonable computational costs. We further add a residual connection to prevent degradation in information flow and explore ensemble methods, as the evaluated models have edges on different cases and sub-regions. On the BraTS 2021 dataset (3D), our model achieves 87.6% mean Dice score and outperforms the state-of-the-art methods, demonstrating the potential for combining multiple architectures to optimize brain tumor segmentation.
</details>
<details>
<summary>摘要</summary>
神经瘤分割是一个活跃的研究领域，因为高度复杂的形态和文本化 tumor 难以分割，以及常用的 U-Net 架构的失败。近年来，不同 neural 架构的组合在主流研究中得到了更多的关注，特别是将 U-Net 与 Transformers 组合使用，因为它们的自然注意机制和像素级标注。与前一些尝试不同，本文提出了一种新的网络架构，将 Transformers  integrate 到自适应 U-Net 中，以获取3D Volume 上下文，并且在计算成本下进行合理的融合。此外，我们还添加了 residual 连接，以避免信息流失并探索 ensemble 方法，因为评估模型在不同的情况下和子区域上具有优势。在 BraTS 2021 数据集（3D）上，我们的模型实现了87.6%的 mean Dice 分数，超过了当前的状态ola 方法，这表明可以通过组合不同的架构来优化神经瘤分割。
</details></li>
</ul>
<hr>
<h2 id="DAVIS-High-Quality-Audio-Visual-Separation-with-Generative-Diffusion-Models"><a href="#DAVIS-High-Quality-Audio-Visual-Separation-with-Generative-Diffusion-Models" class="headerlink" title="DAVIS: High-Quality Audio-Visual Separation with Generative Diffusion Models"></a>DAVIS: High-Quality Audio-Visual Separation with Generative Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00122">http://arxiv.org/abs/2308.00122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Huang, Susan Liang, Yapeng Tian, Anurag Kumar, Chenliang Xu</li>
<li>for:  solves the audio-visual sound source separation task through a generative manner</li>
<li>methods:  leverages a generative diffusion model and a Separation U-Net to synthesize separated magnitudes starting from Gaussian noises, conditioned on both the audio mixture and the visual footage</li>
<li>results:  outperforms other methods in separation quality, demonstrating the advantages of our framework for tackling the audio-visual source separation task.<details>
<summary>Abstract</summary>
We propose DAVIS, a Diffusion model-based Audio-VIusal Separation framework that solves the audio-visual sound source separation task through a generative manner. While existing discriminative methods that perform mask regression have made remarkable progress in this field, they face limitations in capturing the complex data distribution required for high-quality separation of sounds from diverse categories. In contrast, DAVIS leverages a generative diffusion model and a Separation U-Net to synthesize separated magnitudes starting from Gaussian noises, conditioned on both the audio mixture and the visual footage. With its generative objective, DAVIS is better suited to achieving the goal of high-quality sound separation across diverse categories. We compare DAVIS to existing state-of-the-art discriminative audio-visual separation methods on the domain-specific MUSIC dataset and the open-domain AVE dataset, and results show that DAVIS outperforms other methods in separation quality, demonstrating the advantages of our framework for tackling the audio-visual source separation task.
</details>
<details>
<summary>摘要</summary>
我们提出了DAVIS，一种基于扩散模型的音视频分离框架，用于通过生成方式解决音视频声源分离问题。而现有的探测方法，尽管在这个领域做出了很大的进步，但是它们在处理多种类别的声音分离时存在限制，因为它们只能通过压缩探测来捕捉复杂的数据分布。相比之下，DAVIS利用生成扩散模型和分离U-Net来生成来自高斯噪声的分离后的声音大小， conditioned on both the audio mixture和视频采集。它的生成目标使得DAVIS更适合在多种类别中实现高质量的声音分离。我们将DAVIS与现有的领先的探测音视频分离方法进行比较，并在领域专门的MUSIC dataset和开放的AVE dataset上进行测试，结果显示DAVIS在分离质量方面超过了其他方法，证明了我们的框架在解决音视频源分离问题中的优势。
</details></li>
</ul>
<hr>
<h2 id="Convolutional-Occupancy-Models-for-Dense-Packing-of-Complex-Novel-Objects"><a href="#Convolutional-Occupancy-Models-for-Dense-Packing-of-Complex-Novel-Objects" class="headerlink" title="Convolutional Occupancy Models for Dense Packing of Complex, Novel Objects"></a>Convolutional Occupancy Models for Dense Packing of Complex, Novel Objects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00091">http://arxiv.org/abs/2308.00091</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nikhilmishra000/fcon">https://github.com/nikhilmishra000/fcon</a></li>
<li>paper_authors: Nikhil Mishra, Pieter Abbeel, Xi Chen, Maximilian Sieb</li>
<li>for: 这个论文主要针对了仓储和物流应用中的紧凑堆叠问题，既然现实中的堆叠性能受到3D物体几何学的观察困难所限制。</li>
<li>methods: 该论文提出了一种全数据预训练的深度学习模型F-CON，可以与现有的规划方法结合使用，以实现现实世界中的紧凑堆叠。同时，该论文还发布了一个可用于培训形态完成模型的实验数据集COB-3D-v2。</li>
<li>results: 该论文的实验结果表明，F-CON模型比其他状态前的形态完成方法更高效，可以在实际世界中实现紧凑堆叠复杂的未经见过的物体。此外，该论文还 equip了一个真实世界的捕捉和置物系统，以确认F-CON模型在实际世界中的表现。<details>
<summary>Abstract</summary>
Dense packing in pick-and-place systems is an important feature in many warehouse and logistics applications. Prior work in this space has largely focused on planning algorithms in simulation, but real-world packing performance is often bottlenecked by the difficulty of perceiving 3D object geometry in highly occluded, partially observed scenes. In this work, we present a fully-convolutional shape completion model, F-CON, which can be easily combined with off-the-shelf planning methods for dense packing in the real world. We also release a simulated dataset, COB-3D-v2, that can be used to train shape completion models for real-word robotics applications, and use it to demonstrate that F-CON outperforms other state-of-the-art shape completion methods. Finally, we equip a real-world pick-and-place system with F-CON, and demonstrate dense packing of complex, unseen objects in cluttered scenes. Across multiple planning methods, F-CON enables substantially better dense packing than other shape completion methods.
</details>
<details>
<summary>摘要</summary>
dense packing在选择和放置系统中是一项重要的特性，在多家仓储和物流应用中广泛使用。先前的工作主要集中在仿真中计划算法上，但实际的填充性常被受到3D物体几何体的识别困难所限制。在这种情况下，我们提出了一种全 convolutional 形态完成模型，F-CON，可以轻松地与现有的规划方法结合使用，以实现实际世界中的高密度填充。我们还发布了一个可用于实际 роботику应用的模拟数据集，COB-3D-v2，并使用其来证明F-CON在实际世界中的表现比其他状态最佳的形态完成方法更好。最后，我们将实际世界中的选择和放置系统 équip with F-CON，并在拥挤的场景中实现了复杂、未见的物体的高密度填充。不同于其他形态完成方法，F-CON在多种规划方法下实现了显著更好的高密度填充。
</details></li>
</ul>
<hr>
<h2 id="Visual-Geo-localization-with-Self-supervised-Representation-Learning"><a href="#Visual-Geo-localization-with-Self-supervised-Representation-Learning" class="headerlink" title="Visual Geo-localization with Self-supervised Representation Learning"></a>Visual Geo-localization with Self-supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00090">http://arxiv.org/abs/2308.00090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuhong Xiao, Gao Zhu, Giuseppe Loianno</li>
<li>for: 提高Visual Geo-localization（VG）的性能和训练效率，使用Self-Supervised Learning（SSL）方法。</li>
<li>methods:  integrate多种SSL方法（SimCLR、MoCov2、BYOL、SimSiam、Barlow Twins、VICReg），系统地分析不同训练策略和参数设置的影响。</li>
<li>results: 无需困扰的硬解释挖掘（HNM），方法可以与基准方法相比或甚至超越VG性能。<details>
<summary>Abstract</summary>
Visual Geo-localization (VG) has emerged as a significant research area, aiming to identify geolocation based on visual features. Most VG approaches use learnable feature extractors for representation learning. Recently, Self-Supervised Learning (SSL) methods have also demonstrated comparable performance to supervised methods by using numerous unlabeled images for representation learning. In this work, we present a novel unified VG-SSL framework with the goal to enhance performance and training efficiency on a large VG dataset by SSL methods. Our work incorporates multiple SSL methods tailored for VG: SimCLR, MoCov2, BYOL, SimSiam, Barlow Twins, and VICReg. We systematically analyze the performance of different training strategies and study the optimal parameter settings for the adaptation of SSL methods for the VG task. The results demonstrate that our method, without the significant computation and memory usage associated with Hard Negative Mining (HNM), can match or even surpass the VG performance of the baseline that employs HNM. The code is available at https://github.com/arplaboratory/VG_SSL.
</details>
<details>
<summary>摘要</summary>
Visual Geo-localization (VG) 已经成为一个突出的研究领域，旨在通过视觉特征进行地理位置标识。大多数 VG 方法使用学习式特征提取器进行表征学习。现在，自动标注学习（SSL）方法也在 VG 中展示了相当于指导学习方法的性能，通过大量无标注图像进行表征学习。在这种工作中，我们提出了一个新的 VG-SSL 框架，目标是在大型 VG 数据集上提高性能和训练效率。我们在 VG 中采用多种 SSL 方法，包括 SimCLR、MoCov2、BYOL、SimSiam、Barlow Twins 和 VICReg。我们系统地分析不同训练策略的性能，并研究 SSL 方法在 VG 任务上进行适应时的优化参数设置。结果表明，我们的方法，不需要与硬negative mining（HNM）相关的重要计算和内存使用，可以与基准方法相比或超越 VG 性能。代码可以在 <https://github.com/arplaboratory/VG_SSL> 上下载。
</details></li>
</ul>
<hr>
<h2 id="T-Fusion-Net-A-Novel-Deep-Neural-Network-Augmented-with-Multiple-Localizations-based-Spatial-Attention-Mechanisms-for-Covid-19-Detection"><a href="#T-Fusion-Net-A-Novel-Deep-Neural-Network-Augmented-with-Multiple-Localizations-based-Spatial-Attention-Mechanisms-for-Covid-19-Detection" class="headerlink" title="T-Fusion Net: A Novel Deep Neural Network Augmented with Multiple Localizations based Spatial Attention Mechanisms for Covid-19 Detection"></a>T-Fusion Net: A Novel Deep Neural Network Augmented with Multiple Localizations based Spatial Attention Mechanisms for Covid-19 Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00053">http://arxiv.org/abs/2308.00053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Susmita Ghosh, Abhiroop Chatterjee</li>
<li>for: 提高图像分类任务的性能</li>
<li>methods: 提出了一种新的深度神经网络（名为 T-Fusion Net），该网络在多个本地化的基础上实现了多个尺度的自适应注意力。</li>
<li>results: 实验结果表明，提出的 T-Fusion Net 和其 ensemble 模型在 Covid-19 （SARS-CoV-2 CT 扫描）数据集上表现更好，与其他状态对照方法相比，达到了97.59% 和 98.4% 的准确率。<details>
<summary>Abstract</summary>
In recent years, deep neural networks are yielding better performance in image classification tasks. However, the increasing complexity of datasets and the demand for improved performance necessitate the exploration of innovative techniques. The present work proposes a new deep neural network (called as, T-Fusion Net) that augments multiple localizations based spatial attention. This attention mechanism allows the network to focus on relevant image regions, improving its discriminative power. A homogeneous ensemble of the said network is further used to enhance image classification accuracy. For ensembling, the proposed approach considers multiple instances of individual T-Fusion Net. The model incorporates fuzzy max fusion to merge the outputs of individual nets. The fusion process is optimized through a carefully chosen parameter to strike a balance on the contributions of the individual models. Experimental evaluations on benchmark Covid-19 (SARS-CoV-2 CT scan) dataset demonstrate the effectiveness of the proposed T-Fusion Net as well as its ensemble. The proposed T-Fusion Net and the homogeneous ensemble model exhibit better performance, as compared to other state-of-the-art methods, achieving accuracy of 97.59% and 98.4%, respectively.
</details>
<details>
<summary>摘要</summary>
近年来，深度神经网络在图像分类任务中表现越来越好。然而，数据集的复杂度和表现需求的提高导致了探索新技术的需要。本工作提出了一种新的深度神经网络（称为T-Fusion Net），该网络通过多个本地化基于空间注意力机制来增强其分类力。这种注意力机制使得网络能够关注相关的图像区域，从而提高其分类精度。此外，本工作还提出了一种同一个T-Fusion Net的多个实例的Homogeneous Ensemble模型，通过粗略的max fusione ensemble来提高图像分类精度。在折衔参数的优化下，这种ensemble模型可以充分利用各个模型的贡献，达到最佳的分类精度。在COVID-19（SARS-CoV-2 CT扫描）数据集上进行的实验评估表明，提出的T-Fusion Net和Homogeneous Ensemble模型具有更高的表现度，与其他状态对照方法相比，分类精度达97.59%和98.4%。
</details></li>
</ul>
<hr>
<h2 id="Cross-Dataset-Adaptation-for-Instrument-Classification-in-Cataract-Surgery-Videos"><a href="#Cross-Dataset-Adaptation-for-Instrument-Classification-in-Cataract-Surgery-Videos" class="headerlink" title="Cross-Dataset Adaptation for Instrument Classification in Cataract Surgery Videos"></a>Cross-Dataset Adaptation for Instrument Classification in Cataract Surgery Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04035">http://arxiv.org/abs/2308.04035</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jayparanjape/barlow-adaptor">https://github.com/jayparanjape/barlow-adaptor</a></li>
<li>paper_authors: Jay N. Paranjape, Shameema Sikder, Vishal M. Patel, S. Swaroop Vedula</li>
<li>for: 本研究旨在解决骨刃手术数据中存在的频繁域变化问题，提高不同数据集之间的性能。</li>
<li>methods: 本文提出了一种基于无监督领域适应（Unsupervised Domain Adaptation, UDA）的新方法，称为Barlow Adaptor，可以 Addressing the problem of distribution shift without requiring any labels from another domain.  furthermore, the authors introduce a novel loss function called Barlow Feature Alignment Loss (BFAL) to align features across different domains.</li>
<li>results: 经验表明，提出的方法在两个骨刃手术数据集上进行了广泛的实验，与现有的UDA方法相比，提高了6%的性能。<details>
<summary>Abstract</summary>
Surgical tool presence detection is an important part of the intra-operative and post-operative analysis of a surgery. State-of-the-art models, which perform this task well on a particular dataset, however, perform poorly when tested on another dataset. This occurs due to a significant domain shift between the datasets resulting from the use of different tools, sensors, data resolution etc. In this paper, we highlight this domain shift in the commonly performed cataract surgery and propose a novel end-to-end Unsupervised Domain Adaptation (UDA) method called the Barlow Adaptor that addresses the problem of distribution shift without requiring any labels from another domain. In addition, we introduce a novel loss called the Barlow Feature Alignment Loss (BFAL) which aligns features across different domains while reducing redundancy and the need for higher batch sizes, thus improving cross-dataset performance. The use of BFAL is a novel approach to address the challenge of domain shift in cataract surgery data. Extensive experiments are conducted on two cataract surgery datasets and it is shown that the proposed method outperforms the state-of-the-art UDA methods by 6%. The code can be found at https://github.com/JayParanjape/Barlow-Adaptor
</details>
<details>
<summary>摘要</summary>
《针对手术工具存在检测是一项重要的手术和后期分析中的一部分。现有的模型在特定的数据集上表现良好，但在另一个数据集上表现差。这是因为不同数据集之间存在很大的领域变换，这些变换包括不同的工具、传感器、数据分辨率等。本文提出了这种领域变换的问题，并提出了一种名为Barlow Adaptor的新的无监督领域适应（UDA）方法，该方法可以在不同领域之间进行分布变换，而无需另一个领域的标签。此外，我们还引入了一种名为Barlow Feature Alignment Loss（BFAL）的新的损失函数，该损失函数可以在不同领域之间对特征进行对齐，同时减少缓存大小和标签数量，从而提高跨数据集性能。这种BFAL的使用是一种新的途径来解决手术领域中的领域变换问题。我们在两个手术数据集上进行了广泛的实验，并证明了我们的方法可以比现有的UDA方法提高6%。代码可以在https://github.com/JayParanjape/Barlow-Adaptor上找到。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Disruptive-Autoencoders-Leveraging-Low-level-features-for-3D-Medical-Image-Pre-training"><a href="#Disruptive-Autoencoders-Leveraging-Low-level-features-for-3D-Medical-Image-Pre-training" class="headerlink" title="Disruptive Autoencoders: Leveraging Low-level features for 3D Medical Image Pre-training"></a>Disruptive Autoencoders: Leveraging Low-level features for 3D Medical Image Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16896">http://arxiv.org/abs/2307.16896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeya Maria Jose Valanarasu, Yucheng Tang, Dong Yang, Ziyue Xu, Can Zhao, Wenqi Li, Vishal M. Patel, Bennett Landman, Daguang Xu, Yufan He, Vishwesh Nath</li>
<li>for: 这篇研究旨在设计一个有效的预训架构，以帮助学习3D医学影像的特有特征。</li>
<li>methods: 本研究提出了一个新的masking策略，即在通道嵌入中进行masking，以提高本地特征表现学习。此外，我们还提出了一种名为Disruptive Autoencoders的预训架构，可以从混合本地masking和低级扰动中寻找原始影像。此外，我们还提出了一种跨模式对称差异损失（CMCL），以便在单一架构中预训多 modalities。</li>
<li>results: 我们在多个下游任务上试用了提出的预训架构，并取得了州先的性能。特别是，我们的提出的方法在BTCV多器官分类挑战中公开试题中排名第一。<details>
<summary>Abstract</summary>
Harnessing the power of pre-training on large-scale datasets like ImageNet forms a fundamental building block for the progress of representation learning-driven solutions in computer vision. Medical images are inherently different from natural images as they are acquired in the form of many modalities (CT, MR, PET, Ultrasound etc.) and contain granulated information like tissue, lesion, organs etc. These characteristics of medical images require special attention towards learning features representative of local context. In this work, we focus on designing an effective pre-training framework for 3D radiology images. First, we propose a new masking strategy called local masking where the masking is performed across channel embeddings instead of tokens to improve the learning of local feature representations. We combine this with classical low-level perturbations like adding noise and downsampling to further enable low-level representation learning. To this end, we introduce Disruptive Autoencoders, a pre-training framework that attempts to reconstruct the original image from disruptions created by a combination of local masking and low-level perturbations. Additionally, we also devise a cross-modal contrastive loss (CMCL) to accommodate the pre-training of multiple modalities in a single framework. We curate a large-scale dataset to enable pre-training of 3D medical radiology images (MRI and CT). The proposed pre-training framework is tested across multiple downstream tasks and achieves state-of-the-art performance. Notably, our proposed method tops the public test leaderboard of BTCV multi-organ segmentation challenge.
</details>
<details>
<summary>摘要</summary>
使用大规模数据集如ImageNet来预训练是计算机视觉领域的基础建筑块之一。医疗图像与自然图像不同，因为它们可以通过多种模式（如CT、MR、PET、ultrasound等）获得，并且含有细节信息如组织、肿瘤、器官等。这些医疗图像特点需要对学习本地上下文特征进行特别注意。在这种工作中，我们关注于设计有效的预训练框架 для3D医疗图像。我们提议一种新的 маSKing策略，称为本地 маSKing，在通道嵌入中进行 маSKing，以提高本地特征表示学习。我们还结合了经典的低级扰动，如噪声和下采样，以进一步促进低级表示学习。为此，我们引入了Disruptive Autoencoders，一种预训练框架，它尝试通过对原始图像的创造出的干扰来重建原始图像。此外，我们还开发了一种跨Modal Contrastive Loss（CMCL），以便在单个框架中预训练多个模式。我们筹建了一个大规模数据集，以便预训练3D医疗图像（MRI和CT）。我们的提议预训练框架在多个下游任务上进行测试，并达到了状态机的性能。尤其是，我们的提议方法在BTCV多器官分割挑战中公共测试领先榜上名列前茅。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-the-Parameter-Efficiency-of-Adapters-from-the-Perspective-of-Precision-Redundancy"><a href="#Revisiting-the-Parameter-Efficiency-of-Adapters-from-the-Perspective-of-Precision-Redundancy" class="headerlink" title="Revisiting the Parameter Efficiency of Adapters from the Perspective of Precision Redundancy"></a>Revisiting the Parameter Efficiency of Adapters from the Perspective of Precision Redundancy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16867">http://arxiv.org/abs/2307.16867</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jieshibo/petl-vit">https://github.com/jieshibo/petl-vit</a></li>
<li>paper_authors: Shibo Jie, Haoqing Wang, Zhi-Hong Deng</li>
<li>for: 这篇论文的目的是提出一种实现优化小型适材料的方法，以减少储存和传输过程中的过大负载。</li>
<li>methods: 这篇论文使用了Adapter-based Parameter-Efficient Tuning（PET）方法，将轻量级的扩展器插入到预训练完成的大型vision模型中，以实现任务特定的微调。</li>
<li>results: 经过广泛的实验， authors发现了1比特适材料可以实现最小的性能损失，并且在VTAB-1K标准库和几个shot FGVC任务上表现更好。<details>
<summary>Abstract</summary>
Current state-of-the-art results in computer vision depend in part on fine-tuning large pre-trained vision models. However, with the exponential growth of model sizes, the conventional full fine-tuning, which needs to store a individual network copy for each tasks, leads to increasingly huge storage and transmission overhead. Adapter-based Parameter-Efficient Tuning (PET) methods address this challenge by tuning lightweight adapters inserted into the frozen pre-trained models. In this paper, we investigate how to make adapters even more efficient, reaching a new minimum size required to store a task-specific fine-tuned network. Inspired by the observation that the parameters of adapters converge at flat local minima, we find that adapters are resistant to noise in parameter space, which means they are also resistant to low numerical precision. To train low-precision adapters, we propose a computational-efficient quantization method which minimizes the quantization error. Through extensive experiments, we find that low-precision adapters exhibit minimal performance degradation, and even 1-bit precision is sufficient for adapters. The experimental results demonstrate that 1-bit adapters outperform all other PET methods on both the VTAB-1K benchmark and few-shot FGVC tasks, while requiring the smallest storage size. Our findings show, for the first time, the significant potential of quantization techniques in PET, providing a general solution to enhance the parameter efficiency of adapter-based PET methods. Code: https://github.com/JieShibo/PETL-ViT
</details>
<details>
<summary>摘要</summary>
现代计算机视觉技术的研究 partly rely on fine-tuning large pre-trained vision models. However, with the exponential growth of model sizes, the conventional full fine-tuning, which requires storing a separate network copy for each task, leads to increasingly huge storage and transmission overhead. Adapter-based Parameter-Efficient Tuning (PET) methods address this challenge by fine-tuning lightweight adapters inserted into the frozen pre-trained models. In this paper, we investigate how to make adapters even more efficient, reaching a new minimum size required to store a task-specific fine-tuned network. 启发于参数空间的平铺ocal minimum的观察，我们发现 adapter 对参数空间的随机噪声具有抗性，这意味着 adapter 也具有低精度的抗性。为了训练低精度 adapter，我们提出了一种 computationally efficient quantization method，which minimizes the quantization error. Through extensive experiments, we find that low-precision adapters exhibit minimal performance degradation, and even 1-bit precision is sufficient for adapters. The experimental results demonstrate that 1-bit adapters outperform all other PET methods on both the VTAB-1K benchmark and few-shot FGVC tasks, while requiring the smallest storage size. Our findings show, for the first time, the significant potential of quantization techniques in PET, providing a general solution to enhance the parameter efficiency of adapter-based PET methods.Code: https://github.com/JieShibo/PETL-ViT
</details></li>
</ul>
<hr>
<h2 id="Universal-Adversarial-Defense-in-Remote-Sensing-Based-on-Pre-trained-Denoising-Diffusion-Models"><a href="#Universal-Adversarial-Defense-in-Remote-Sensing-Based-on-Pre-trained-Denoising-Diffusion-Models" class="headerlink" title="Universal Adversarial Defense in Remote Sensing Based on Pre-trained Denoising Diffusion Models"></a>Universal Adversarial Defense in Remote Sensing Based on Pre-trained Denoising Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16865">http://arxiv.org/abs/2307.16865</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/EricYu97/UAD-RS">https://github.com/EricYu97/UAD-RS</a></li>
<li>paper_authors: Weikang Yu, Yonghao Xu, Pedram Ghamisi</li>
<li>for: 这个研究的目的是为了提出一个通用的适应性攻击防护方法（UAD-RS），以对RS数据中常见的多种不明适攻击进行防护。</li>
<li>methods: 这个方法使用预训 diffusion 模型来防护常见的DNN攻击，包括使用预训 diffusion 模型来学习不同RS数据集之间的通用表示，然后使用这些表示来对攻击样本进行净化。</li>
<li>results: 实验结果显示，UAD-RS 可以对四个不同的RS数据集进行通用防护，并且与现有的防护方法相比，具有更高的效果和更低的训练成本。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have achieved tremendous success in many remote sensing (RS) applications, in which DNNs are vulnerable to adversarial perturbations. Unfortunately, current adversarial defense approaches in RS studies usually suffer from performance fluctuation and unnecessary re-training costs due to the need for prior knowledge of the adversarial perturbations among RS data. To circumvent these challenges, we propose a universal adversarial defense approach in RS imagery (UAD-RS) using pre-trained diffusion models to defend the common DNNs against multiple unknown adversarial attacks. Specifically, the generative diffusion models are first pre-trained on different RS datasets to learn generalized representations in various data domains. After that, a universal adversarial purification framework is developed using the forward and reverse process of the pre-trained diffusion models to purify the perturbations from adversarial samples. Furthermore, an adaptive noise level selection (ANLS) mechanism is built to capture the optimal noise level of the diffusion model that can achieve the best purification results closest to the clean samples according to their Frechet Inception Distance (FID) in deep feature space. As a result, only a single pre-trained diffusion model is needed for the universal purification of adversarial samples on each dataset, which significantly alleviates the re-training efforts and maintains high performance without prior knowledge of the adversarial perturbations. Experiments on four heterogeneous RS datasets regarding scene classification and semantic segmentation verify that UAD-RS outperforms state-of-the-art adversarial purification approaches with a universal defense against seven commonly existing adversarial perturbations. Codes and the pre-trained models are available online (https://github.com/EricYu97/UAD-RS).
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）在远程感知应用中已经取得了很大的成功，但是DNNs受到了恶作剂扰动的威胁。然而，现有的远程感知领域中的抗恶作剂防御策略通常会受到性能波动和不必要的重新训练成本，因为需要对远程感知数据进行先前知识。为了缓解这些挑战，我们提出了远程感知领域中的通用抗恶作剂防御策略（UAD-RS），使用预训练的扩散模型来防御通用DNNs对多种未知恶作剂的攻击。具体来说，首先预训练了不同的远程感知 dataset 上的扩散模型，以学习不同数据领域中的通用表示。然后，我们开发了一种通用抗恶作剂纯化框架，使用预训练的扩散模型的前向和反向过程来纯化恶作剂攻击后的样本。此外，我们还建立了一种适应性的噪声水平选择（ANLS）机制，以便在深度特征空间中选择最佳的噪声水平，以达到最佳的纯化结果最接近于干净样本的 Frechet Inception Distance（FID）。因此，只需要预训练一个扩散模型，可以对各个 dataset 进行通用的抗恶作剂纯化，大大减少重新训练的努力和维护高性能，无需对恶作剂攻击的具体知识。实验表明，UAD-RS 在四个不同的远程感知dataset 上的Scene Classification和semantic segmentation任务上表现出色，与现有的抗恶作剂纯化方法相比，具有更高的性能稳定性。代码和预训练模型可以在线获取（https://github.com/EricYu97/UAD-RS）。
</details></li>
</ul>
<hr>
<h2 id="MetaCAM-Ensemble-Based-Class-Activation-Map"><a href="#MetaCAM-Ensemble-Based-Class-Activation-Map" class="headerlink" title="MetaCAM: Ensemble-Based Class Activation Map"></a>MetaCAM: Ensemble-Based Class Activation Map</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16863">http://arxiv.org/abs/2307.16863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emily Kaczmarek, Olivier X. Miguel, Alexa C. Bowie, Robin Ducharme, Alysha L. J. Dingwall-Harvey, Steven Hawken, Christine M. Armour, Mark C. Walker, Kevin Dick</li>
<li>for: 这篇论文旨在提供一个ensemble-based方法，将多个现有的Class Activation Maps（CAMs）方法 ensemble，以提高深度学习模型的预测解释可靠性。</li>
<li>methods: 方法包括MetaCAM、Cumulative Residual Effect（CRE）和adaptive thresholding等。</li>
<li>results: 结果显示，MetaCAM比单一CAMs表现更好，并可以更好地检测和修复模型预测时的误差。具体来说，在一个实验中，MetaCAM提高了ROAD表现从0.393比11个单一CAMs的值域(-0.101-0.172)，显示了结合CAMs的ensemble方法和适应阈值的重要性。<details>
<summary>Abstract</summary>
The need for clear, trustworthy explanations of deep learning model predictions is essential for high-criticality fields, such as medicine and biometric identification. Class Activation Maps (CAMs) are an increasingly popular category of visual explanation methods for Convolutional Neural Networks (CNNs). However, the performance of individual CAMs depends largely on experimental parameters such as the selected image, target class, and model. Here, we propose MetaCAM, an ensemble-based method for combining multiple existing CAM methods based on the consensus of the top-k% most highly activated pixels across component CAMs. We perform experiments to quantifiably determine the optimal combination of 11 CAMs for a given MetaCAM experiment. A new method denoted Cumulative Residual Effect (CRE) is proposed to summarize large-scale ensemble-based experiments. We also present adaptive thresholding and demonstrate how it can be applied to individual CAMs to improve their performance, measured using pixel perturbation method Remove and Debias (ROAD). Lastly, we show that MetaCAM outperforms existing CAMs and refines the most salient regions of images used for model predictions. In a specific example, MetaCAM improved ROAD performance to 0.393 compared to 11 individual CAMs with ranges from -0.101-0.172, demonstrating the importance of combining CAMs through an ensembling method and adaptive thresholding.
</details>
<details>
<summary>摘要</summary>
需要清晰、可靠的深度学习模型预测解释是高 kriticality 领域，如医学和生物认知识别。图像活动地图 (CAMs) 是深度学习模型中的一种增加 Popular 的视觉解释方法。然而，各个 CAMs 的性能受到实验参数的影响，如选择的图像、目标类和模型。我们提出了 MetaCAM，一种基于 Ensemble 的方法，将多个现有 CAMs 的投票结果组合成一个高效的解释方法。我们对 MetaCAM 的实验进行了量化的定制，并提出了一种新的方法 named Cumulative Residual Effect (CRE)，用于总结大规模的 Ensemble 实验结果。此外，我们还提出了适应阈值的技术，并证明了它可以应用于个体 CAMs 以提高其性能，使用像素扰动方法 Remove and Debias (ROAD) 进行评估。最后，我们表明 MetaCAM 超越了现有 CAMs，并把模型预测中使用的图像进行了更加精细的定制。例如，MetaCAM 提高了 ROAD 性能至 0.393，比11个个体 CAMs 的范围从 -0.101-0.172 更高，这说明了将 CAMs 组合成 Ensemble 方法和适应阈值技术的重要性。
</details></li>
</ul>
<hr>
<h2 id="Automated-COVID-19-CT-Image-Classification-using-Multi-head-Channel-Attention-in-Deep-CNN"><a href="#Automated-COVID-19-CT-Image-Classification-using-Multi-head-Channel-Attention-in-Deep-CNN" class="headerlink" title="Automated COVID-19 CT Image Classification using Multi-head Channel Attention in Deep CNN"></a>Automated COVID-19 CT Image Classification using Multi-head Channel Attention in Deep CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00715">http://arxiv.org/abs/2308.00715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Susmita Ghosh, Abhiroop Chatterjee</li>
<li>for: 本研究旨在提出一种基于深度学习的自动化COVID-19 CT扫描分类方法，以提高检测精度。</li>
<li>methods: 该方法使用修改过的Xception模型，增加了新的通道注意力机制和权重global average pooling来提高特征提取。通道注意力模块可以选择每个通道中有用信息，使模型学习COVID-19检测的特征。</li>
<li>results: 在一个广泛使用的COVID-19 CT扫描数据集上进行实验，该方法达到了96.99%的准确率，与其他当前领先技术相比显著优于。这些研究可以贡献到使用人工智能对当前和未来的流行病应对的努力，并提供可靠的医疗图像分析任务解决方案。<details>
<summary>Abstract</summary>
The rapid spread of COVID-19 has necessitated efficient and accurate diagnostic methods. Computed Tomography (CT) scan images have emerged as a valuable tool for detecting the disease. In this article, we present a novel deep learning approach for automated COVID-19 CT scan classification where a modified Xception model is proposed which incorporates a newly designed channel attention mechanism and weighted global average pooling to enhance feature extraction thereby improving classification accuracy. The channel attention module selectively focuses on informative regions within each channel, enabling the model to learn discriminative features for COVID-19 detection. Experiments on a widely used COVID-19 CT scan dataset demonstrate a very good accuracy of 96.99% and show its superiority to other state-of-the-art techniques. This research can contribute to the ongoing efforts in using artificial intelligence to combat current and future pandemics and can offer promising and timely solutions for efficient medical image analysis tasks.
</details>
<details>
<summary>摘要</summary>
due to the rapid spread of COVID-19, efficient and accurate diagnostic methods are urgently needed. Computed Tomography (CT) scan images have emerged as a valuable tool for detecting the disease. In this article, we propose a novel deep learning approach for automated COVID-19 CT scan classification, which incorporates a modified Xception model with a newly designed channel attention mechanism and weighted global average pooling to enhance feature extraction and improve classification accuracy. The channel attention module selectively focuses on informative regions within each channel, allowing the model to learn discriminative features for COVID-19 detection. Experiments on a widely used COVID-19 CT scan dataset demonstrate an accuracy of 96.99%, outperforming other state-of-the-art techniques. This research can contribute to the ongoing efforts in using artificial intelligence to combat current and future pandemics and offer promising and timely solutions for efficient medical image analysis tasks.Here's the breakdown of the translation:* due to the rapid spread of COVID-19: 由于 COVID-19 的快速传播* efficient and accurate diagnostic methods are urgently needed: 需要有效和准确的诊断方法* Computed Tomography (CT) scan images have emerged as a valuable tool for detecting the disease: CT 扫描图像已成为检测疾病的有价值工具* In this article, we propose a novel deep learning approach for automated COVID-19 CT scan classification: 在这篇文章中，我们提出了一种基于深度学习的自动 COVID-19 CT 扫描分类方法* which incorporates a modified Xception model with a newly designed channel attention mechanism and weighted global average pooling: 其中包括一种基于 Xception 模型的修改版本，以及一种新的通道注意机制和权重 globally average pooling* to enhance feature extraction and improve classification accuracy: 以提高特征提取和分类精度* The channel attention module selectively focuses on informative regions within each channel: 通道注意模块可选择每个通道中的有用区域* allowing the model to learn discriminative features for COVID-19 detection: 使模型可以学习 COVID-19 的特征* Experiments on a widely used COVID-19 CT scan dataset demonstrate an accuracy of 96.99%: 在一个广泛使用的 COVID-19 CT 扫描数据集上，实验表明模型的准确率为 96.99%* and show its superiority to other state-of-the-art techniques: 并表明其在其他现有技术上的优越性* This research can contribute to the ongoing efforts in using artificial intelligence to combat current and future pandemics: 这些研究可以贡献到使用人工智能对当前和未来的潜在疫情作战* and offer promising and timely solutions for efficient medical image analysis tasks: 并提供有前途和时间性的医疗图像分析任务解决方案
</details></li>
</ul>
<hr>
<h2 id="Random-Sub-Samples-Generation-for-Self-Supervised-Real-Image-Denoising"><a href="#Random-Sub-Samples-Generation-for-Self-Supervised-Real-Image-Denoising" class="headerlink" title="Random Sub-Samples Generation for Self-Supervised Real Image Denoising"></a>Random Sub-Samples Generation for Self-Supervised Real Image Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16825">http://arxiv.org/abs/2307.16825</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/p1y2z3/sdap">https://github.com/p1y2z3/sdap</a></li>
<li>paper_authors: Yizhong Pan, Xiao Liu, Xiangyu Liao, Yuanzhouhan Cao, Chao Ren</li>
<li>for: This paper is written for improving the performance of self-supervised image denoising methods, specifically the blind spot network (BSN), by introducing a novel framework called Sampling Difference As Perturbation (SDAP) that uses random sub-samples generation (RSG) with a cyclic sample difference loss.</li>
<li>methods: The paper proposes a new self-supervised real image denoising framework named SDAP, which is based on RSG with a cyclic sample difference loss. The framework adds an appropriate perturbation to the training images to improve the performance of BSN.</li>
<li>results: The paper shows that the proposed SDAP framework significantly outperforms other state-of-the-art self-supervised denoising methods on real-world datasets.Here’s the answer in Simplified Chinese:</li>
<li>for: 这篇论文是为了提高自主监督的图像干净方法性能，特别是对盲点网络（BSN）的改进，提出了一种新的框架called Sampling Difference As Perturbation（SDAP），它基于随机子样本生成（RSG）和循环样本差损失。</li>
<li>methods: 论文提出了一种新的自主监督实际图像干净框架called SDAP，它基于RSG和循环样本差损失。框架通过添加适当的扰动来提高BSN的性能。</li>
<li>results: 论文显示，提出的SDAP框架在实际数据集上显著超越了其他自主监督干净方法。I hope this helps!<details>
<summary>Abstract</summary>
With sufficient paired training samples, the supervised deep learning methods have attracted much attention in image denoising because of their superior performance. However, it is still very challenging to widely utilize the supervised methods in real cases due to the lack of paired noisy-clean images. Meanwhile, most self-supervised denoising methods are ineffective as well when applied to the real-world denoising tasks because of their strict assumptions in applications. For example, as a typical method for self-supervised denoising, the original blind spot network (BSN) assumes that the noise is pixel-wise independent, which is much different from the real cases. To solve this problem, we propose a novel self-supervised real image denoising framework named Sampling Difference As Perturbation (SDAP) based on Random Sub-samples Generation (RSG) with a cyclic sample difference loss. Specifically, we dig deeper into the properties of BSN to make it more suitable for real noise. Surprisingly, we find that adding an appropriate perturbation to the training images can effectively improve the performance of BSN. Further, we propose that the sampling difference can be considered as perturbation to achieve better results. Finally we propose a new BSN framework in combination with our RSG strategy. The results show that it significantly outperforms other state-of-the-art self-supervised denoising methods on real-world datasets. The code is available at https://github.com/p1y2z3/SDAP.
</details>
<details>
<summary>摘要</summary>
随着深度学习方法的提出，无监督的深度学习方法在图像减噪中吸引了非常多的关注，因为它们的性能远胜监督方法。然而，在实际应用中，广泛使用无监督方法仍然非常困难，主要因为缺乏对应的噪音清洁图像的对应样本。此外，大多数自主学习减噪方法在实际应用中也是不Effective的，因为它们在应用中假设了噪音是像素级独立的，这与实际情况迥然不同。为解决这个问题，我们提出了一种基于随机子样本生成（RSG）的新的自主学习实际图像减噪框架，即采样差分作为扰动（SDAP）。我们在BSN中进一步挖掘了Properties，使其更适合实际噪音。我们发现，在训练图像上添加合适的扰动可以有效提高BSN的性能。此外，我们认为采样差分可以被视为扰动，以达到更好的效果。最后，我们提出了一种基于RSG和BSN的新框架，并对实际图像减噪任务进行评估。结果表明，它在实际图像减噪任务上明显超过了其他现有的自主学习减噪方法。代码可以在https://github.com/p1y2z3/SDAP上获取。
</details></li>
</ul>
<hr>
<h2 id="Capturing-Co-existing-Distortions-in-User-Generated-Content-for-No-reference-Video-Quality-Assessment"><a href="#Capturing-Co-existing-Distortions-in-User-Generated-Content-for-No-reference-Video-Quality-Assessment" class="headerlink" title="Capturing Co-existing Distortions in User-Generated Content for No-reference Video Quality Assessment"></a>Capturing Co-existing Distortions in User-Generated Content for No-reference Video Quality Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16813">http://arxiv.org/abs/2307.16813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun Yuan, Zishang Kong, Chuanchuan Zheng, Ming Sun, Xing Wen</li>
<li>for: 这个论文是用来预测视频质量的，随着流媒体技术的快速发展，如Facebook、TikTok、Kwai等。</li>
<li>methods: 这个论文提出了一种新的视觉质量Transformer（VQT），用于更有效地提取质量相关的稀疏特征。方法上，提出了一种稀疏时间注意力（STA），通过分析帧之间的时间相关性，从$O(T^2)$降低到$O(T \log T)$的计算复杂度。结构上，使用多路径时间网络（MPTN），通过多个STA模块并行计算，捕捉视频中同时存在的多种损害。</li>
<li>results: 实验表明，VQT比许多当前状态的方法在三个公共无参照VQA数据集中表现出色，并且在四个全参照VQA数据集中比广泛采用的工业算法（如VMAF和AVQT）表现更好。<details>
<summary>Abstract</summary>
Video Quality Assessment (VQA), which aims to predict the perceptual quality of a video, has attracted raising attention with the rapid development of streaming media technology, such as Facebook, TikTok, Kwai, and so on. Compared with other sequence-based visual tasks (\textit{e.g.,} action recognition), VQA faces two under-estimated challenges unresolved in User Generated Content (UGC) videos. \textit{First}, it is not rare that several frames containing serious distortions (\textit{e.g.,}blocking, blurriness), can determine the perceptual quality of the whole video, while other sequence-based tasks require more frames of equal importance for representations. \textit{Second}, the perceptual quality of a video exhibits a multi-distortion distribution, due to the differences in the duration and probability of occurrence for various distortions. In order to solve the above challenges, we propose \textit{Visual Quality Transformer (VQT)} to extract quality-related sparse features more efficiently. Methodologically, a Sparse Temporal Attention (STA) is proposed to sample keyframes by analyzing the temporal correlation between frames, which reduces the computational complexity from $O(T^2)$ to $O(T \log T)$. Structurally, a Multi-Pathway Temporal Network (MPTN) utilizes multiple STA modules with different degrees of sparsity in parallel, capturing co-existing distortions in a video. Experimentally, VQT demonstrates superior performance than many \textit{state-of-the-art} methods in three public no-reference VQA datasets. Furthermore, VQT shows better performance in four full-reference VQA datasets against widely-adopted industrial algorithms (\textit{i.e.,} VMAF and AVQT).
</details>
<details>
<summary>摘要</summary>
视频质量评估（VQA），旨在预测视频的感知质量，随着流媒体技术的快速发展（如Facebook、TikTok、Kwai等），引起了越来越多的关注。相比其他序列基于视觉任务（例如动作识别），VQA面临两个未得到解决的挑战，即在用户生成内容（UGC）视频中，几帧具有严重损害（例如块化、模糊）的情况下，整个视频的感知质量受到这些帧的影响，而其他序列基于视觉任务通常需要更多的相等重要帧来构成表示。第二，视频的感知质量具有多种损害分布，这是因为不同的损害在视频的时间长度和概率发生的情况下具有不同的概率和持续时间。为解决以上挑战，我们提出了视觉质量变换器（VQT），可以更有效地提取相关的质量特征。方法上，我们提出了简洁时间注意力（STA），通过分析帧之间的时间相关性，从 $O(T^2)$ 降低到 $O(T \log T)$ 的计算复杂度。结构上，我们采用多路径时间网络（MPTN），通过多个 STA 模块并行运行，捕捉视频中共存的损害。实验表明，VQT 在三个公共无参照 VQA 数据集中表现出色，并且在四个全参照 VQA 数据集中对于广泛采用的工业算法（例如 VMAF 和 AVQT）表现更好。
</details></li>
</ul>
<hr>
<h2 id="A-comprehensive-review-of-deep-learning-in-lung-cancer"><a href="#A-comprehensive-review-of-deep-learning-in-lung-cancer" class="headerlink" title="A comprehensive review of deep learning in lung cancer"></a>A comprehensive review of deep learning in lung cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02528">http://arxiv.org/abs/2308.02528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farzane Tajidini</li>
<li>for: 本文提供了关于癌症诊断方法的历史背景，包括癌症诊断的过程和临床医生使用的标准分类方法。</li>
<li>methods: 当前的癌症诊断方法被评估为不够有效，需要新的更智能的方法。</li>
<li>results: 本文提出了一种新的癌症诊断方法，以帮助解决当前的问题。<details>
<summary>Abstract</summary>
To provide the reader with a historical perspective on cancer classification approaches, we first discuss the fundamentals of the area of cancer diagnosis in this article, including the processes of cancer diagnosis and the standard classification methods employed by clinicians. Current methods for cancer diagnosis are deemed ineffective, calling for new and more intelligent approaches.
</details>
<details>
<summary>摘要</summary>
为了为读者提供历史背景，我们首先讲述了肿瘤诊断方法的基础知识，包括肿瘤诊断过程和临床医生使用的标准分类方法。现有的肿瘤诊断方法被认为是不充分有效，需要新的更智能的方法。Here's a breakdown of the translation:* 肿瘤 (ózhòu) - cancer* 诊断 (jiànxiǎng) - diagnosis* 过程 (guòchéng) - process* 标准 (biāozhǔ) - standard* 分类 (fēngróng) - classification* 方法 (fāngédé) - method* 不充分有效 (bù zhòng fēn yǒu xiǎng) - not effective enough* 新 (xīn) - new* 更 (gè) - more* 智能 (zhìnéng) - intelligent
</details></li>
</ul>
<hr>
<h2 id="DPMix-Mixture-of-Depth-and-Point-Cloud-Video-Experts-for-4D-Action-Segmentation"><a href="#DPMix-Mixture-of-Depth-and-Point-Cloud-Video-Experts-for-4D-Action-Segmentation" class="headerlink" title="DPMix: Mixture of Depth and Point Cloud Video Experts for 4D Action Segmentation"></a>DPMix: Mixture of Depth and Point Cloud Video Experts for 4D Action Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16803">http://arxiv.org/abs/2307.16803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Zhang, Hehe Fan, Yi Yang, Mohan Kankanhalli</li>
<li>for: 这项研究是为了解决人机交互4D（HOI4D）数据集上的 egocentric action segmentation 任务。</li>
<li>methods: 该方法使用了点云视频方法和传统视频理解方法的 ensemble，以提高4D动作分割的准确率。</li>
<li>results: 该方法名为DPMix，在HOI4D Challenge 2023中的4D Action Segmentation Track中获得了第一名。<details>
<summary>Abstract</summary>
In this technical report, we present our findings from the research conducted on the Human-Object Interaction 4D (HOI4D) dataset for egocentric action segmentation task. As a relatively novel research area, point cloud video methods might not be good at temporal modeling, especially for long point cloud videos (\eg, 150 frames). In contrast, traditional video understanding methods have been well developed. Their effectiveness on temporal modeling has been widely verified on many large scale video datasets. Therefore, we convert point cloud videos into depth videos and employ traditional video modeling methods to improve 4D action segmentation. By ensembling depth and point cloud video methods, the accuracy is significantly improved. The proposed method, named Mixture of Depth and Point cloud video experts (DPMix), achieved the first place in the 4D Action Segmentation Track of the HOI4D Challenge 2023.
</details>
<details>
<summary>摘要</summary>
在这份技术报告中，我们展示了对人机交互4D（HOI4D）数据集上的 egocentric action segmentation 任务的研究成果。作为一个相对新的研究领域，点云视频方法可能不够好地处理时间模型，特别是长点云视频（例如150帧）。相比之下，传统视频理解方法已经广泛发展，其在大规模视频数据集上的效果得到了广泛验证。因此，我们将点云视频转换为深度视频，并使用传统视频模型来提高4D动作分割精度。通过对深度和点云视频方法进行拟合，我们提出的方法（名为DPMix）在 HOI4D Challenge 2023 的4D Action Segmentation Track中达到了第一名。
</details></li>
</ul>
<hr>
<h2 id="Framing-image-registration-as-a-landmark-detection-problem-for-better-representation-of-clinical-relevance"><a href="#Framing-image-registration-as-a-landmark-detection-problem-for-better-representation-of-clinical-relevance" class="headerlink" title="Framing image registration as a landmark detection problem for better representation of clinical relevance"></a>Framing image registration as a landmark detection problem for better representation of clinical relevance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01318">http://arxiv.org/abs/2308.01318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diana Waldmannstetter, Benedikt Wiestler, Julian Schwarting, Ivan Ezhov, Marie Metz, Spyridon Bakas, Bhakti Baheti, Satrajit Chakrabarty, Jan S. Kirschke, Rolf A. Heckemann, Marie Piraud, Florian Kofler, Bjoern H. Menze</li>
<li>for: 提高图像注册评价的临床 relevance，通过将图像注册视为标记检测问题来重新评价图像注册方法。</li>
<li>methods: 提议基于一个子样本间评价分析来计算特征点检测阈值，使用 median + delta * median absolute deviation 公式来计算阈值。</li>
<li>results: 方法可以 diferenciate 之前无法区分的注册算法，并且可以评价图像注册方法的临床意义。<details>
<summary>Abstract</summary>
Nowadays, registration methods are typically evaluated based on sub-resolution tracking error differences. In an effort to reinfuse this evaluation process with clinical relevance, we propose to reframe image registration as a landmark detection problem. Ideally, landmark-specific detection thresholds are derived from an inter-rater analysis. To approximate this costly process, we propose to compute hit rate curves based on the distribution of errors of a sub-sample inter-rater analysis. Therefore, we suggest deriving thresholds from the error distribution using the formula: median + delta * median absolute deviation. The method promises differentiation of previously indistinguishable registration algorithms and further enables assessing the clinical significance in algorithm development.
</details>
<details>
<summary>摘要</summary>
现在，注册方法通常会被评估基于半解像跟踪错误差异。为了重新把注册评估过程恢复到临床 relevance，我们提议将注册视为一个标记检测问题。理想情况下，标记特定的检测阈值将来自多个评估人员之间的交叉分析。为了估算这个贵重的过程，我们提议基于一个子样本交叉分析的错误分布计算hit率曲线。因此，我们建议使用错误分布中的 median + δ * 中值绝对差异来 derivethreshold。这种方法可以区分之前无法分辨的注册算法，并且可以评估算法发展中的临床重要性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/01/cs.CV_2023_08_01/" data-id="clpxp6c0r00hoee8820it3zak" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/01/cs.AI_2023_08_01/" class="article-date">
  <time datetime="2023-08-01T12:00:00.000Z" itemprop="datePublished">2023-08-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/01/cs.AI_2023_08_01/">cs.AI - 2023-08-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Hessian-Aware-Bayesian-Optimization-for-Decision-Making-Systems"><a href="#Hessian-Aware-Bayesian-Optimization-for-Decision-Making-Systems" class="headerlink" title="Hessian-Aware Bayesian Optimization for Decision Making Systems"></a>Hessian-Aware Bayesian Optimization for Decision Making Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00629">http://arxiv.org/abs/2308.00629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohit Rajpal, Lac Gia Tran, Yehong Zhang, Bryan Kian Hsiang Low</li>
<li>For: 优化决策系统，尤其是在缺乏反馈信息的情况下。* Methods: 使用 derivative-free 方法，如 bayesian 优化，以减少对反馈质量的依赖。* Results: 在资源有限和异常反馈情况下，实验结果表明我们的方法（HA-GP-UCB）能够有效地优化决策系统。<details>
<summary>Abstract</summary>
Many approaches for optimizing decision making systems rely on gradient based methods requiring informative feedback from the environment. However, in the case where such feedback is sparse or uninformative, such approaches may result in poor performance. Derivative-free approaches such as Bayesian Optimization mitigate the dependency on the quality of gradient feedback, but are known to scale poorly in the high-dimension setting of complex decision making systems. This problem is exacerbated if the system requires interactions between several actors cooperating to accomplish a shared goal. To address the dimensionality challenge, we propose a compact multi-layered architecture modeling the dynamics of actor interactions through the concept of role. Additionally, we introduce Hessian-aware Bayesian Optimization to efficiently optimize the multi-layered architecture parameterized by a large number of parameters. Experimental results demonstrate that our method (HA-GP-UCB) works effectively on several benchmarks under resource constraints and malformed feedback settings.
</details>
<details>
<summary>摘要</summary>
很多决策系统优化方法基于梯度计算，但在环境反馈缺乏信息时，这些方法可能表现不佳。不含梯度的方法如泊利抽象优化可以减少基于梯度反馈的依赖性，但在复杂决策系统中，这些方法可能 scalability 问题。特别是当决策系统需要多个演员合作完成共同目标时，这问题变得更加严重。为解决维度挑战，我们提议使用嵌入式多层架构，模型演员之间的动态关系，并通过角色概念来减少参数的数量。此外，我们还引入了希尔伯恩对 Bayesian 优化的知识，以高效地优化多层架构中的参数。实验结果表明，我们的方法（HA-GP-UCB）在资源限制和缺乏反馈情况下能够有效地工作。
</details></li>
</ul>
<hr>
<h2 id="Human-M3-A-Multi-view-Multi-modal-Dataset-for-3D-Human-Pose-Estimation-in-Outdoor-Scenes"><a href="#Human-M3-A-Multi-view-Multi-modal-Dataset-for-3D-Human-Pose-Estimation-in-Outdoor-Scenes" class="headerlink" title="Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes"></a>Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00628">http://arxiv.org/abs/2308.00628</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soullessrobot/human-m3-dataset">https://github.com/soullessrobot/human-m3-dataset</a></li>
<li>paper_authors: Bohao Fan, Siqi Wang, Wenxuan Guo, Wenzhao Zheng, Jianjiang Feng, Jie Zhou</li>
<li>for: 这篇论文旨在提供一个多Modal多视图多人3D人姿数据库，以便进一步推动多Modal多视图3D人姿估计领域的研究。</li>
<li>methods: 该论文提出了一种基于多Modal数据输入的人 pose估计算法，使得可以更准确地估计人姿。此外，该论文还提出了一种基于多Modal数据输入的人 pose估计算法，以验证多Modal数据输入的优势。</li>
<li>results: 该论文的实验结果表明，该数据库是一个具有挑战性和多样性的 dataset，适用于未来的研究。此外，该论文的实验结果还表明，基于多Modal数据输入的人 pose估计算法具有明显的优势。<details>
<summary>Abstract</summary>
3D human pose estimation in outdoor environments has garnered increasing attention recently. However, prevalent 3D human pose datasets pertaining to outdoor scenes lack diversity, as they predominantly utilize only one type of modality (RGB image or pointcloud), and often feature only one individual within each scene. This limited scope of dataset infrastructure considerably hinders the variability of available data. In this article, we propose Human-M3, an outdoor multi-modal multi-view multi-person human pose database which includes not only multi-view RGB videos of outdoor scenes but also corresponding pointclouds. In order to obtain accurate human poses, we propose an algorithm based on multi-modal data input to generate ground truth annotation. This benefits from robust pointcloud detection and tracking, which solves the problem of inaccurate human localization and matching ambiguity that may exist in previous multi-view RGB videos in outdoor multi-person scenes, and generates reliable ground truth annotations. Evaluation of multiple different modalities algorithms has shown that this database is challenging and suitable for future research. Furthermore, we propose a 3D human pose estimation algorithm based on multi-modal data input, which demonstrates the advantages of multi-modal data input for 3D human pose estimation. Code and data will be released on https://github.com/soullessrobot/Human-M3-Dataset.
</details>
<details>
<summary>摘要</summary>
Recently, 3D human pose estimation in outdoor environments has gained increasing attention. However, existing 3D human pose datasets for outdoor scenes are limited in terms of diversity, as they primarily use only one type of modality (RGB image or pointcloud), and often feature only one individual per scene. This limited scope of dataset infrastructure significantly hinders the variability of available data.In this article, we propose Human-M3, an outdoor multi-modal multi-view multi-person human pose database that includes not only multi-view RGB videos of outdoor scenes but also corresponding pointclouds. To obtain accurate human poses, we propose an algorithm based on multi-modal data input to generate ground truth annotation. This approach leverages robust pointcloud detection and tracking, which resolves the problems of inaccurate human localization and matching ambiguity that may exist in previous multi-view RGB videos of outdoor multi-person scenes, and generates reliable ground truth annotations.Evaluation of multiple different modalities algorithms has shown that this database is challenging and suitable for future research. Furthermore, we propose a 3D human pose estimation algorithm based on multi-modal data input, which demonstrates the advantages of multi-modal data input for 3D human pose estimation. The database and code will be released on GitHub at <https://github.com/soullessrobot/Human-M3-Dataset>.
</details></li>
</ul>
<hr>
<h2 id="JIANG-Chinese-Open-Foundation-Language-Model"><a href="#JIANG-Chinese-Open-Foundation-Language-Model" class="headerlink" title="JIANG: Chinese Open Foundation Language Model"></a>JIANG: Chinese Open Foundation Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00624">http://arxiv.org/abs/2308.00624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qinhua Duan, Wenchao Gu, Yujia Chen, Wenxin Mao, Zewen Tian, Hui Cao</li>
<li>for: 这个研究是为了开发一个特别设计 для中文的大语言模型，以便在中文领域中表现出更高水准的表达能力。</li>
<li>methods: 我们使用了大量的中文资料来训练我们的模型，并且对模型结构进行优化。</li>
<li>results: 实验结果显示了我们的模型在中文领域的表现非常出色，表现比较有力。<details>
<summary>Abstract</summary>
With the advancements in large language model technology, it has showcased capabilities that come close to those of human beings across various tasks. This achievement has garnered significant interest from companies and scientific research institutions, leading to substantial investments in the research and development of these models. While numerous large models have emerged during this period, the majority of them have been trained primarily on English data. Although they exhibit decent performance in other languages, such as Chinese, their potential remains limited due to factors like vocabulary design and training corpus. Consequently, their ability to fully express their capabilities in Chinese falls short. To address this issue, we introduce the model named JIANG (Chinese pinyin of ginger) specifically designed for the Chinese language. We have gathered a substantial amount of Chinese corpus to train the model and have also optimized its structure. The extensive experimental results demonstrate the excellent performance of our model.
</details>
<details>
<summary>摘要</summary>
随着大语言模型技术的发展，它们在不同任务上展示了人类水平的能力，吸引了企业和科研机构的广泛投资。然而，大多数这些模型都是以英语训练为主，尽管它们在其他语言上表现不错，但其潜力尚未得到完全发挥。这是因为语言设计和训练数据的因素所致。为了解决这个问题，我们介绍了专门为中文设计的模型——江（中文拼音的芳香）。我们收集了大量的中文训练数据，并优化了模型的结构。我们的广泛实验结果表明，我们的模型表现出了极佳的能力。
</details></li>
</ul>
<hr>
<h2 id="Beyond-One-Hot-Encoding-Injecting-Semantics-to-Drive-Image-Classifiers"><a href="#Beyond-One-Hot-Encoding-Injecting-Semantics-to-Drive-Image-Classifiers" class="headerlink" title="Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers"></a>Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00607">http://arxiv.org/abs/2308.00607</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/s1m0n38/semantic-encodings">https://github.com/s1m0n38/semantic-encodings</a></li>
<li>paper_authors: Alan Perotti, Simone Bertolotto, Eliana Pastor, André Panisson</li>
<li>for: The paper aims to improve the interpretability and trustworthiness of machine learning models for image classification by integrating semantic information into the training process.</li>
<li>methods: The authors propose a generic approach to derive an additional loss term starting from any kind of semantic information about the classification label, and demonstrate its application to ontologies and word embeddings.</li>
<li>results: The authors train image classifiers with the semantically enriched loss and analyze the trade-offs between accuracy, mistake severity, and learned internal representations. They also discuss the potential of this approach for improving explainability and adversarial robustness.<details>
<summary>Abstract</summary>
Images are loaded with semantic information that pertains to real-world ontologies: dog breeds share mammalian similarities, food pictures are often depicted in domestic environments, and so on. However, when training machine learning models for image classification, the relative similarities amongst object classes are commonly paired with one-hot-encoded labels. According to this logic, if an image is labelled as 'spoon', then 'tea-spoon' and 'shark' are equally wrong in terms of training loss. To overcome this limitation, we explore the integration of additional goals that reflect ontological and semantic knowledge, improving model interpretability and trustworthiness. We suggest a generic approach that allows to derive an additional loss term starting from any kind of semantic information about the classification label. First, we show how to apply our approach to ontologies and word embeddings, and discuss how the resulting information can drive a supervised learning process. Second, we use our semantically enriched loss to train image classifiers, and analyse the trade-offs between accuracy, mistake severity, and learned internal representations. Finally, we discuss how this approach can be further exploited in terms of explainability and adversarial robustness. Code repository: https://github.com/S1M0N38/semantic-encodings
</details>
<details>
<summary>摘要</summary>
图像充满 semantics 信息：狗种类共享哺乳动物类似性，食物图像经常在家庭环境中描绘，等等。然而，在机器学习模型图像分类训练中，对象类之间的相似性通常通过一键编码标签进行表示。根据这种逻辑，如果一张图像被标记为 " Spoon "，那么 " Tea-spoon " 和 " 鲨鱼 " 在训练损失方面都是等错的。为了超越这些限制，我们探讨了 Semantic 和 Ontology 知识的集成，以提高模型解释性和可靠性。我们提出了一个通用的方法，可以从任何类型的 semantics 信息开始，生成一个额外的损失项。首先，我们介绍了如何应用我们的方法到 Ontologies 和 Word Embeddings 中，并讨论了如何使得这些信息驱动一个监督学习过程。其次，我们使用我们具有Semantically 增强的损失函数来训练图像分类器，并分析了准确率、错误严重性和学习的内部表示之间的贸易。最后，我们讨论了如何进一步利用这种方法，以提高解释性和对抗攻击性。代码库：https://github.com/S1M0N38/semantic-encodings
</details></li>
</ul>
<hr>
<h2 id="Collaborative-filtering-to-capture-AI-user’s-preferences-as-norms"><a href="#Collaborative-filtering-to-capture-AI-user’s-preferences-as-norms" class="headerlink" title="Collaborative filtering to capture AI user’s preferences as norms"></a>Collaborative filtering to capture AI user’s preferences as norms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02542">http://arxiv.org/abs/2308.02542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc Serramia, Natalia Criado, Michael Luck</li>
<li>for: 本研究旨在提高人工智能技术的个性化设置，以更好地满足用户的需求。</li>
<li>methods: 本研究使用了协同推荐算法，通过分析大量用户对整体系统的偏好信息，自动地捕捉用户的偏好。</li>
<li>results: 研究发现，通过协同推荐算法可以准确地捕捉用户的偏好，并且可以避免用户过度参与设置过程，从而提高人工智能技术的使用体验。<details>
<summary>Abstract</summary>
Customising AI technologies to each user's preferences is fundamental to them functioning well. Unfortunately, current methods require too much user involvement and fail to capture their true preferences. In fact, to avoid the nuisance of manually setting preferences, users usually accept the default settings even if these do not conform to their true preferences. Norms can be useful to regulate behaviour and ensure it adheres to user preferences but, while the literature has thoroughly studied norms, most proposals take a formal perspective. Indeed, while there has been some research on constructing norms to capture a user's privacy preferences, these methods rely on domain knowledge which, in the case of AI technologies, is difficult to obtain and maintain. We argue that a new perspective is required when constructing norms, which is to exploit the large amount of preference information readily available from whole systems of users. Inspired by recommender systems, we believe that collaborative filtering can offer a suitable approach to identifying a user's norm preferences without excessive user involvement.
</details>
<details>
<summary>摘要</summary>
We argue that a new perspective is needed when constructing norms, one that leverages the abundance of preference information available from large systems of users. Inspired by recommender systems, we believe that collaborative filtering can be a suitable approach to identifying a user's norm preferences without excessive user involvement. By analyzing the preferences of similar users, we can create a normative framework that is more accurately tailored to each individual's needs and preferences. This approach has the potential to improve the effectiveness of AI technologies and enhance user experience.
</details></li>
</ul>
<hr>
<h2 id="Towards-More-Human-like-AI-Communication-A-Review-of-Emergent-Communication-Research"><a href="#Towards-More-Human-like-AI-Communication-A-Review-of-Emergent-Communication-Research" class="headerlink" title="Towards More Human-like AI Communication: A Review of Emergent Communication Research"></a>Towards More Human-like AI Communication: A Review of Emergent Communication Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02541">http://arxiv.org/abs/2308.02541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolo’ Brandizzi</li>
<li>for: 本研究旨在探讨人类语言使用的规律和人工智能机器的沟通方式，以帮助机器更好地使用自然语言进行人机交互。</li>
<li>methods: 本研究使用了 emergent communication（Emecom）的方法，即通过人工智能机器学习自然语言的使用方式，以便更好地沟通和学习新的概念。</li>
<li>results: 本研究通过分析了各种相关研究的共同特征，并将其分为两个子类别，以便更好地了解人类语言使用的规律和人工智能机器的沟通方式。<details>
<summary>Abstract</summary>
In the recent shift towards human-centric AI, the need for machines to accurately use natural language has become increasingly important. While a common approach to achieve this is to train large language models, this method presents a form of learning misalignment where the model may not capture the underlying structure and reasoning humans employ in using natural language, potentially leading to unexpected or unreliable behavior. Emergent communication (Emecom) is a field of research that has seen a growing number of publications in recent years, aiming to develop artificial agents capable of using natural language in a way that goes beyond simple discriminative tasks and can effectively communicate and learn new concepts. In this review, we present Emecom under two aspects. Firstly, we delineate all the common proprieties we find across the literature and how they relate to human interactions. Secondly, we identify two subcategories and highlight their characteristics and open challenges. We encourage researchers to work together by demonstrating that different methods can be viewed as diverse solutions to a common problem and emphasize the importance of including diverse perspectives and expertise in the field. We believe a deeper understanding of human communication is crucial to developing machines that can accurately use natural language in human-machine interactions.
</details>
<details>
<summary>摘要</summary>
In this review, we examine Emecom from two perspectives. First, we identify common properties found across the literature and how they relate to human interactions. Second, we categorize Emecom into two subcategories and highlight their characteristics and open challenges. We emphasize the importance of including diverse perspectives and expertise in the field, as we believe a deeper understanding of human communication is crucial to developing machines that can accurately use natural language in human-machine interactions.
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-based-Non-Autoregressive-Solver-for-Traveling-Salesman-Problems"><a href="#Reinforcement-Learning-based-Non-Autoregressive-Solver-for-Traveling-Salesman-Problems" class="headerlink" title="Reinforcement Learning-based Non-Autoregressive Solver for Traveling Salesman Problems"></a>Reinforcement Learning-based Non-Autoregressive Solver for Traveling Salesman Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00560">http://arxiv.org/abs/2308.00560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubin Xiao, Di Wang, Huanhuan Chen, Boyang Li, Wei Pang, Xuan Wu, Hao Li, Dong Xu, Yanchun Liang, You Zhou</li>
<li>for: 提出了一种基于 Graph Neural Network (GNN) 和 reinforcement learning (RL) 的 Traveling Salesman Problem (TSP) 解决方案，以提高解决速度和解决质量。</li>
<li>methods: 使用了一种特制的 GNN 来实现非推理 (NAR) decoding，并使用了一种提高后RL策略来消除依赖于高成本的标签来训练传统的超级学习型 NAR 模型。</li>
<li>results: 在 synthetic 和实际世界 TSP 实例上进行了实验，并证明了 NAR4TSP 在解决质量、推理速度和泛化能力等方面都比四种现有模型更好。同时，还提供了 NAR4TSP 的解码过程和总路径规划的视觉化图表，以示其可行性和效果。<details>
<summary>Abstract</summary>
The Traveling Salesman Problem (TSP) is a well-known problem in combinatorial optimization with applications in various domains. However, existing TSP solvers face challenges in producing high-quality solutions with low latency. To address this issue, we propose NAR4TSP, which produces TSP solutions in a Non-Autoregressive (NAR) manner using a specially designed Graph Neural Network (GNN), achieving faster inference speed. Moreover, NAR4TSP is trained using an enhanced Reinforcement Learning (RL) strategy, eliminating the dependency on costly labels used to train conventional supervised learning-based NAR models. To the best of our knowledge, NAR4TSP is the first TSP solver that successfully combines RL and NAR decoding. The experimental results on both synthetic and real-world TSP instances demonstrate that NAR4TSP outperforms four state-of-the-art models in terms of solution quality, inference latency, and generalization ability. Lastly, we present visualizations of NAR4TSP's decoding process and its overall path planning to showcase the feasibility of implementing NAR4TSP in an end-to-end manner and its effectiveness, respectively.
</details>
<details>
<summary>摘要</summary>
旅途卖士问题（TSP）是一个广泛应用的 combinatorial 优化问题。然而，现有的 TSP 解决方案面临着生成高质量解决方案的延迟问题。为解决这个问题，我们提出了 NAR4TSP，它使用特制的图神经网络（GNN）来生成非自适应（NAR）的 TSP 解决方案，实现更快的推理速度。此外，NAR4TSP 通过改进的强化学习（RL）策略进行训练，从而消除了对传统的超级vised学习基于 NAR 模型的贵重标签的依赖。根据我们所知，NAR4TSP 是第一个成功地将 RL 和 NAR 推理结合的 TSP 解决方案。实验结果表明，NAR4TSP 在 synthetic 和实际世界 TSP 实例上比四种现状的模型高于 solution 质量、推理延迟和泛化能力。最后，我们提供了 NAR4TSP 的推理过程和总路径规划的视觉化来展示 NAR4TSP 的端到端实现可行性和效iveness。
</details></li>
</ul>
<hr>
<h2 id="Copula-for-Instance-wise-Feature-Selection-and-Ranking"><a href="#Copula-for-Instance-wise-Feature-Selection-and-Ranking" class="headerlink" title="Copula for Instance-wise Feature Selection and Ranking"></a>Copula for Instance-wise Feature Selection and Ranking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00549">http://arxiv.org/abs/2308.00549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanyu Peng, Guanhua Fang, Ping Li</li>
<li>for: 提高神经网络中特征选择和排序的精度，增强模型的性能和可读性。</li>
<li>methods:  integrate Gaussian copula into current feature selection framework，无需更改现有的方法。</li>
<li>results: 在 sintetic 和实际数据上，对比现有方法，我们的方法能够更好地捕捉各特征之间的相互关系，提高模型的性能和可读性。<details>
<summary>Abstract</summary>
Instance-wise feature selection and ranking methods can achieve a good selection of task-friendly features for each sample in the context of neural networks. However, existing approaches that assume feature subsets to be independent are imperfect when considering the dependency between features. To address this limitation, we propose to incorporate the Gaussian copula, a powerful mathematical technique for capturing correlations between variables, into the current feature selection framework with no additional changes needed. Experimental results on both synthetic and real datasets, in terms of performance comparison and interpretability, demonstrate that our method is capable of capturing meaningful correlations.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Instance-wise 特征选择和排名方法可以实现每个样本中任务友好的特征选择。然而，现有的方法假设特征子集为独立的时，存在相互关系的限制。为解决这 limitation，我们提议在当前特征选择框架中 incorporate  Gaussian copula，一种强大的数学技术，用于捕捉特征之间的相关性。实验结果表明，我们的方法可以捕捉有意义的相关性。Note:* "Instance-wise" is translated as "每个样本中" (each sample)* "特征选择" is translated as "特征选择" (feature selection)* "排名" is translated as "排名" (ranking)* "Gaussian copula" is translated as " Gaussian  copula" (Gaussian copula)* "相关性" is translated as "相关性" (correlation)
</details></li>
</ul>
<hr>
<h2 id="Predicting-Early-Dropouts-of-an-Active-and-Healthy-Ageing-App"><a href="#Predicting-Early-Dropouts-of-an-Active-and-Healthy-Ageing-App" class="headerlink" title="Predicting Early Dropouts of an Active and Healthy Ageing App"></a>Predicting Early Dropouts of an Active and Healthy Ageing App</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00539">http://arxiv.org/abs/2308.00539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasileios Perifanis, Ioanna Michailidi, Giorgos Stamatelatos, George Drosatos, Pavlos S. Efraimidis</li>
<li>for: The paper is written for predicting early dropouts of an active and healthy ageing app.</li>
<li>methods: The paper uses machine learning algorithms, specifically classification models constructed using pre-processing techniques and dynamic&#x2F;static features. The authors also employed oversampling methods like SMOTE and ADASYN to improve performance.</li>
<li>results: The paper achieved high-quality adherence predictions, with dynamic features positively influencing the model’s performance. The oversampling approaches led to a remarkable improvement of 10%. The authors won first place in the IFMBE Scientific Challenge 2022.Here’s the simplified Chinese text for the three points:</li>
<li>for: 这篇论文是为预测活健年龄应用中早期退出的研究。</li>
<li>methods: 这篇论文使用机器学习算法，具体来说是使用预处理技术构建的分类模型，并使用动态&#x2F;静止特征进行预测。作者还使用了SMOTE和ADASYN等扩大samples方法来提高分类性能。</li>
<li>results: 这篇论文实现了高质量遵从预测，动态特征对模型性能有积极影响。使用扩大samples方法导致了10%的显著提高。作者在IFMBE科学挑战赛2022中获得了第一名。<details>
<summary>Abstract</summary>
In this work, we present a machine learning approach for predicting early dropouts of an active and healthy ageing app. The presented algorithms have been submitted to the IFMBE Scientific Challenge 2022, part of IUPESM WC 2022. We have processed the given database and generated seven datasets. We used pre-processing techniques to construct classification models that predict the adherence of users using dynamic and static features. We submitted 11 official runs and our results show that machine learning algorithms can provide high-quality adherence predictions. Based on the results, the dynamic features positively influence a model's classification performance. Due to the imbalanced nature of the dataset, we employed oversampling methods such as SMOTE and ADASYN to improve the classification performance. The oversampling approaches led to a remarkable improvement of 10\%. Our methods won first place in the IFMBE Scientific Challenge 2022.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种机器学习方法来预测活动和健康年龄应用程序中早期退出的问题。我们在IFMBE科学挑战2022中提交了这些算法，该活动是IUPESM WC 2022的一部分。我们对给定的数据库进行了处理，生成了七个数据集。我们使用了预处理技术来构建分类模型，以预测用户的执行情况。我们提交了11个官方运行，结果表明机器学习算法可以提供高质量的执行预测。据结果显示，动态特征对模型的分类性能产生了积极的影响。由于数据集具有偏斜性，我们使用了扩大样本的方法，如SMOTE和ADASYN，以提高分类性能。这些扩大方法导致了10%的明显改善。我们的方法在IFMBE科学挑战2022中获得了第一名。
</details></li>
</ul>
<hr>
<h2 id="PressureTransferNet-Human-Attribute-Guided-Dynamic-Ground-Pressure-Profile-Transfer-using-3D-simulated-Pressure-Maps"><a href="#PressureTransferNet-Human-Attribute-Guided-Dynamic-Ground-Pressure-Profile-Transfer-using-3D-simulated-Pressure-Maps" class="headerlink" title="PressureTransferNet: Human Attribute Guided Dynamic Ground Pressure Profile Transfer using 3D simulated Pressure Maps"></a>PressureTransferNet: Human Attribute Guided Dynamic Ground Pressure Profile Transfer using 3D simulated Pressure Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00538">http://arxiv.org/abs/2308.00538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lala Shakti Swarup Ray, Vitor Fortes Rey, Bo Zhou, Sungho Suh, Paul Lukowicz</li>
<li>for: 人体活动识别(HAR)系统的研究和开发</li>
<li>methods: 利用现有的压力数据和编码-解码模型，生成具有特定活动特征的体具压力 profiless</li>
<li>results: 在不同场景下，准确地将人体特征传递到地面压力Profile中，并通过物理学基金amentals的深度学习模型进行验证。<details>
<summary>Abstract</summary>
We propose PressureTransferNet, a novel method for Human Activity Recognition (HAR) using ground pressure information. Our approach generates body-specific dynamic ground pressure profiles for specific activities by leveraging existing pressure data from different individuals. PressureTransferNet is an encoder-decoder model taking a source pressure map and a target human attribute vector as inputs, producing a new pressure map reflecting the target attribute. To train the model, we use a sensor simulation to create a diverse dataset with various human attributes and pressure profiles. Evaluation on a real-world dataset shows its effectiveness in accurately transferring human attributes to ground pressure profiles across different scenarios. We visually confirm the fidelity of the synthesized pressure shapes using a physics-based deep learning model and achieve a binary R-square value of 0.79 on areas with ground contact. Validation through classification with F1 score (0.911$\pm$0.015) on physical pressure mat data demonstrates the correctness of the synthesized pressure maps, making our method valuable for data augmentation, denoising, sensor simulation, and anomaly detection. Applications span sports science, rehabilitation, and bio-mechanics, contributing to the development of HAR systems.
</details>
<details>
<summary>摘要</summary>
我们提出了PressureTransferNet，一种新的人动作认识（HAR）方法，使用地面压力信息。我们的方法生成了特定活动的体部特有的动态地面压力profile，通过利用不同个体的压力数据。PressureTransferNet是一个Encoder-Decoder模型，接受一个源压力地图和一个目标人类特征向量作为输入，生成一个新的压力地图，表示目标特征。我们使用感知模拟生成了多种人类特征和压力profile的多样化数据集，用于训练模型。我们通过对实际数据进行评估，发现PressureTransferNet能够准确地将人类特征传递到地面压力profile中，并在不同场景下保持高度的准确率。我们通过physics-based深度学习模型进行视觉验证，并达到了0.79的二元R-平方值在地面接触区域上，这表明我们生成的压力地图具有高度的准确性。我们通过对物理压力检测数据进行分类，获得了0.911±0.015的F1分数，这表明我们的方法可以准确地生成压力地图，从而在数据增强、噪声除除、感知模拟和异常检测等方面具有价值。这些应用包括运动科学、rehabilitation和生物机器学，这将为人动作认识系统的发展提供重要支持。
</details></li>
</ul>
<hr>
<h2 id="Graph-Embedding-Dynamic-Feature-based-Supervised-Contrastive-Learning-of-Transient-Stability-for-Changing-Power-Grid-Topologies"><a href="#Graph-Embedding-Dynamic-Feature-based-Supervised-Contrastive-Learning-of-Transient-Stability-for-Changing-Power-Grid-Topologies" class="headerlink" title="Graph Embedding Dynamic Feature-based Supervised Contrastive Learning of Transient Stability for Changing Power Grid Topologies"></a>Graph Embedding Dynamic Feature-based Supervised Contrastive Learning of Transient Stability for Changing Power Grid Topologies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00537">http://arxiv.org/abs/2308.00537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Lv, Xin Chen, Zijian Feng</li>
<li>for: 精确的在线稳定性预测对于电力系统稳定性是关键，特别是在面临干扰时。传统稳定性分析使用时间域模拟不能快速适应电力网络结构变化。</li>
<li>methods: 以graph embedding dynamic feature（GEDF）为基础，提出了基于超级对比学习的稳定性GEDF-SCL模型，可以预测稳定性，考虑到电力网络结构信息。</li>
<li>results: 对于不同的电力网络结构，通过对N-1和N-m-1干扰情况的模拟，测试结果表明，GEDF-SCL模型可以达到高精度的稳定性预测，并适应电力网络结构变化。<details>
<summary>Abstract</summary>
Accurate online transient stability prediction is critical for ensuring power system stability when facing disturbances. While traditional transient stablity analysis replies on the time domain simulations can not be quickly adapted to the power grid toplogy change. In order to vectorize high-dimensional power grid topological structure information into low-dimensional node-based graph embedding streaming data, graph embedding dynamic feature (GEDF) has been proposed. The transient stability GEDF-based supervised contrastive learning (GEDF-SCL) model uses supervised contrastive learning to predict transient stability with GEDFs, considering power grid topology information. To evaluate the performance of the proposed GEDF-SCL model, power grids of varying topologies were generated based on the IEEE 39-bus system model. Transient operational data was obtained by simulating N-1 and N-$\bm{m}$-1 contingencies on these generated power system topologies. Test result demonstrated that the GEDF-SCL model can achieve high accuracy in transient stability prediction and adapt well to changing power grid topologies.
</details>
<details>
<summary>摘要</summary>
Traditional transient stability analysis 使用时域模拟，不能快速适应发电系统结构变化。为了将高维电力网结构信息归一化成低维节点基本图卷积数据，提出了图嵌入动态特征（GEDF）。在基于 GEDF 的超级vised contrastive learning（GEDF-SCL）模型中，通过超级vised contrastive learning来预测稳定性，考虑发电系统拓扑信息。为评估提议的 GEDF-SCL 模型表现，对 IEEE 39-bus 系统模型中生成的不同拓扑的发电系统进行了 simulate N-1 和 N-m-1 的稳定操作数据。测试结果表明， GEDF-SCL 模型可以高度准确地预测稳定性，并适应发电系统拓扑变化。Note: "Simplified Chinese" is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="Transfer-Ensemble-Learning-based-Deep-Convolutional-Neural-Networks-for-Diabetic-Retinopathy-Classification"><a href="#Transfer-Ensemble-Learning-based-Deep-Convolutional-Neural-Networks-for-Diabetic-Retinopathy-Classification" class="headerlink" title="Transfer-Ensemble Learning based Deep Convolutional Neural Networks for Diabetic Retinopathy Classification"></a>Transfer-Ensemble Learning based Deep Convolutional Neural Networks for Diabetic Retinopathy Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00525">http://arxiv.org/abs/2308.00525</a></li>
<li>repo_url: None</li>
<li>paper_authors: Susmita Ghosh, Abhiroop Chatterjee<br>for: 这篇论文的目的是用一个ensemble方法来分类糖尿病性视网膜病（DR）为五个不同的类别。methods: 这个模型使用了两个流行的预训练 convolutional neural network：VGG16和Inception V3。 ensemble模型架构中将这两个预训练模型的部分冻结以利用它们已经学习的表示。 全球均值层 pooling层被添加以将输入图像的特征地图转换为固定长度的 вектор。results: 实验结果显示，这个ensemble模型可以高度有效地分类糖尿病性视网膜病，其准确率为96.4%。<details>
<summary>Abstract</summary>
This article aims to classify diabetic retinopathy (DR) disease into five different classes using an ensemble approach based on two popular pre-trained convolutional neural networks: VGG16 and Inception V3. The proposed model aims to leverage the strengths of the two individual nets to enhance the classification performance for diabetic retinopathy. The ensemble model architecture involves freezing a portion of the layers in each pre-trained model to utilize their learned representations effectively. Global average pooling layers are added to transform the output feature maps into fixed-length vectors. These vectors are then concatenated to form a consolidated representation of the input image. The ensemble model is trained using a dataset of diabetic retinopathy images (APTOS), divided into training and validation sets. During the training process, the model learns to classify the retinal images into the corresponding diabetic retinopathy classes. Experimental results on the test set demonstrate the efficacy of the proposed ensemble model for DR classification achieving an accuracy of 96.4%.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇文章旨在使用ensemble方法将糖尿病肠病(DR)分为五个不同的类别，使用两个流行的预训练 convolutional neural networks：VGG16和Inception V3。提议的模型旨在利用这两个个体网络的优势，以提高糖尿病肠病的分类性能。模型的架构包括冻结一部分的层数在每个预训练模型中，以利用它们已经学习的表示。全局平均 pooling层被添加，以将输出特征图 transformed into fixed-length vectors。这些 векторы被 concatenated 以形成输入图像的总合表示。模型通过使用 APTOS 数据集（训练和验证集）进行训练，在测试集上达到了96.4%的准确率。
</details></li>
</ul>
<hr>
<h2 id="SurveyLM-A-platform-to-explore-emerging-value-perspectives-in-augmented-language-models’-behaviors"><a href="#SurveyLM-A-platform-to-explore-emerging-value-perspectives-in-augmented-language-models’-behaviors" class="headerlink" title="SurveyLM: A platform to explore emerging value perspectives in augmented language models’ behaviors"></a>SurveyLM: A platform to explore emerging value perspectives in augmented language models’ behaviors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00521">http://arxiv.org/abs/2308.00521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Steve J. Bickley, Ho Fai Chan, Bang Dao, Benno Torgler, Son Tran</li>
<li>for: 这白皮assailed our work on SurveyLM，一个用于分析人工智能语言模型（ALM）在复杂社会场景中的自适应对行为的平台。</li>
<li>methods: 我们使用了survey和实验方法， traditionally used in studying social behaviors，来系统地评估ALMs，从而提供了尚未有的对ALMs的Alignment和emergent behaviors的深入理解。</li>
<li>results: 通过SurveyLM平台，我们发现了一些因素影响ALMs的emergent behaviors，并可以通过调整survey和实验设计来推动ALMs的Alignment with human intentions and expectations。这些结果有助于负责任地开发和部署高级社会AI系统。<details>
<summary>Abstract</summary>
This white paper presents our work on SurveyLM, a platform for analyzing augmented language models' (ALMs) emergent alignment behaviors through their dynamically evolving attitude and value perspectives in complex social contexts. Social Artificial Intelligence (AI) systems, like ALMs, often function within nuanced social scenarios where there is no singular correct response, or where an answer is heavily dependent on contextual factors, thus necessitating an in-depth understanding of their alignment dynamics. To address this, we apply survey and experimental methodologies, traditionally used in studying social behaviors, to evaluate ALMs systematically, thus providing unprecedented insights into their alignment and emergent behaviors. Moreover, the SurveyLM platform leverages the ALMs' own feedback to enhance survey and experiment designs, exploiting an underutilized aspect of ALMs, which accelerates the development and testing of high-quality survey frameworks while conserving resources. Through SurveyLM, we aim to shed light on factors influencing ALMs' emergent behaviors, facilitate their alignment with human intentions and expectations, and thereby contributed to the responsible development and deployment of advanced social AI systems. This white paper underscores the platform's potential to deliver robust results, highlighting its significance to alignment research and its implications for future social AI systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Explainable-Graph-Spectral-Clustering-of-Text-Documents"><a href="#Explainable-Graph-Spectral-Clustering-of-Text-Documents" class="headerlink" title="Explainable Graph Spectral Clustering of Text Documents"></a>Explainable Graph Spectral Clustering of Text Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00504">http://arxiv.org/abs/2308.00504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bartłomiej Starosta, Mieczysław A. Kłopotek, Sławomir T. Wierzchoń</li>
<li>for: 本研究旨在提供spectral clustering结果的解释方法，以便用户更好地理解和理解文档 clustering结果。</li>
<li>methods: 本文提出了一种基于combinatorial Laplacian的图spectral clustering解释方法，包括approximate equivalence of combinatorial Laplacian embedding, $K$-embedding和term vector space embedding。</li>
<li>results: 经过实验研究，$K$-embedding可以准确地 aproximate Laplacian embedding，并且在某些情况下，approximation是够好的。<details>
<summary>Abstract</summary>
Spectral clustering methods are known for their ability to represent clusters of diverse shapes, densities etc. However, results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents. Therefore there is an urgent need to elaborate methods for explaining the outcome of the clustering. This paper presents a contribution towards this goal. We present a proposal of explanation of results of combinatorial Laplacian based graph spectral clustering. It is based on showing (approximate) equivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in this paper) and term vector space embedding. Hence a bridge is constructed between the textual contents and the clustering results. We provide theoretical background for this approach. We performed experimental study showing that $K$-embedding approximates well Laplacian embedding under favourable block matrix conditions and show that approximation is good enough under other conditions.
</details>
<details>
<summary>摘要</summary>
spectral clustering 方法 known for its ability to represent clusters of diverse shapes, densities, etc. However, the results of such algorithms, when applied to text documents, are hard to explain to the user, especially due to the embedding in the spectral space, which has no obvious relation to the document contents. Therefore, there is an urgent need to elaborate methods for explaining the outcome of the clustering. This paper presents a contribution towards this goal. We present a proposal of explanation of the results of combinatorial Laplacian-based graph spectral clustering. It is based on showing (approximate) equivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in this paper), and term vector space embedding. Therefore, a bridge is constructed between the textual contents and the clustering results. We provide theoretical background for this approach. We performed experimental studies showing that $K$-embedding approximates well Laplacian embedding under favourable block matrix conditions, and show that the approximation is good enough under other conditions.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Retrieval-Augmented-Generation-and-Representative-Vector-Summarization-for-large-unstructured-textual-data-in-Medical-Education"><a href="#Retrieval-Augmented-Generation-and-Representative-Vector-Summarization-for-large-unstructured-textual-data-in-Medical-Education" class="headerlink" title="Retrieval Augmented Generation and Representative Vector Summarization for large unstructured textual data in Medical Education"></a>Retrieval Augmented Generation and Representative Vector Summarization for large unstructured textual data in Medical Education</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00479">http://arxiv.org/abs/2308.00479</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ssm123ssm/docgpt-pharm">https://github.com/ssm123ssm/docgpt-pharm</a></li>
<li>paper_authors: S. S. Manathunga, Y. A. Illangasekara</li>
<li>for: 这篇论文针对对医疗教育领域中大型自然语言模型的应用进行探讨，旨在降低对特定任务的推理错误和生成危险答案。</li>
<li>methods: 论文提出了一种叫做Retrieval Augmented Generation（RAG）的方法，可以轻松地将非 Parametric 知识库附加到大型自然语言模型中，并且可以对这些模型进行摘要和抽象Summary的生成。</li>
<li>results: 论文发现RAG方法可以帮助大型自然语言模型在医疗教育领域中提供更好的答案，并且可以对模型的推理错误和生成危险答案进行降低。<details>
<summary>Abstract</summary>
Large Language Models are increasingly being used for various tasks including content generation and as chatbots. Despite their impressive performances in general tasks, LLMs need to be aligned when applying for domain specific tasks to mitigate the problems of hallucination and producing harmful answers. Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a non-parametric knowledgebases to LLMs. Applications of RAG in the field of medical education are discussed in this paper. A combined extractive and abstractive summarization method for large unstructured textual data using representative vectors is proposed.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Satellite-Imagery-Dataset-for-Long-Term-Sustainable-Development-in-United-States-Cities"><a href="#A-Satellite-Imagery-Dataset-for-Long-Term-Sustainable-Development-in-United-States-Cities" class="headerlink" title="A Satellite Imagery Dataset for Long-Term Sustainable Development in United States Cities"></a>A Satellite Imagery Dataset for Long-Term Sustainable Development in United States Cities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00465">http://arxiv.org/abs/2308.00465</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/axin1301/satellite-imagery-dataset">https://github.com/axin1301/satellite-imagery-dataset</a></li>
<li>paper_authors: Yanxin Xi, Yu Liu, Tong Li, Jintao Ding, Yunke Zhang, Sasu Tarkoma, Yong Li, Pan Hui</li>
<li>for: 这份研究是为了支持美国城市的可持续开发目标（SDGs）研究，尤其是使用卫星影像来研究城市可持续发展。</li>
<li>methods: 研究使用了深度学习模型，收集了卫星影像和其他数据，包括人口、夜间照明、调查和城市建筑数据，以描述城市的可持续开发指标。</li>
<li>results: 研究创建了一个覆盖100个最大城市和相应的人口普查区域的卫星影像数据集，可以帮助城市规划师和研究人员进一步推进SDGs相关的研究，特别是使用卫星影像来监控城市长期和多个构度的可持续开发。<details>
<summary>Abstract</summary>
Cities play an important role in achieving sustainable development goals (SDGs) to promote economic growth and meet social needs. Especially satellite imagery is a potential data source for studying sustainable urban development. However, a comprehensive dataset in the United States (U.S.) covering multiple cities, multiple years, multiple scales, and multiple indicators for SDG monitoring is lacking. To support the research on SDGs in U.S. cities, we develop a satellite imagery dataset using deep learning models for five SDGs containing 25 sustainable development indicators. The proposed dataset covers the 100 most populated U.S. cities and corresponding Census Block Groups from 2014 to 2023. Specifically, we collect satellite imagery and identify objects with state-of-the-art object detection and semantic segmentation models to observe cities' bird's-eye view. We further gather population, nighttime light, survey, and built environment data to depict SDGs regarding poverty, health, education, inequality, and living environment. We anticipate the dataset to help urban policymakers and researchers to advance SDGs-related studies, especially applying satellite imagery to monitor long-term and multi-scale SDGs in cities.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:城市发挥重要作用于实现可持续发展目标(SDGs)，推动经济增长并满足社会需求。尤其是卫星成像是可能的数据源，用于研究可持续城市发展。然而，美国（U.S.）覆盖多个城市、多年、多级、多指标的全面数据集缺乏。为支持美国城市的SDGs研究，我们开发了使用深度学习模型的卫星成像数据集，包括5个SDGs和25个可持续发展指标。该数据集覆盖了美国100个最大人口城市以及相应的人口普查小区，从2014年到2023年。我们通过使用当前的物体检测和semantic segmentation模型，从卫星成像中识别城市的 Bird's-eye view。此外，我们还收集了人口、夜光亮、调查和建筑环境数据，以描绘SDGs关于贫困、健康、教育、不平等和生活环境等方面。我们预计该数据集将帮助城市规划者和研究人员，通过使用卫星成像，对多个城市进行长期和多级SDGs监测。
</details></li>
</ul>
<hr>
<h2 id="DMFC-GraspNet-Differentiable-Multi-Fingered-Robotic-Grasp-Generation-in-Cluttered-Scenes"><a href="#DMFC-GraspNet-Differentiable-Multi-Fingered-Robotic-Grasp-Generation-in-Cluttered-Scenes" class="headerlink" title="DMFC-GraspNet: Differentiable Multi-Fingered Robotic Grasp Generation in Cluttered Scenes"></a>DMFC-GraspNet: Differentiable Multi-Fingered Robotic Grasp Generation in Cluttered Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00456">http://arxiv.org/abs/2308.00456</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Blättner, Johannes Brand, Gerhard Neumann, Ngo Anh Vien</li>
<li>for: 提高多指机器人抓取技能的计算效率和多样性</li>
<li>methods: 提出了一种差分 grasp generation 网络（DMFC-GraspNet），包括三大贡献：一种新的神经网络抓取规划算法、一种场景创建和标签映射方法，以及一种综合损失函数和 generalized Q 1 抓取评价指标来训练 DMFC-GraspNet。</li>
<li>results: 对于使用 Shadow Dexterous Hand 在 MuJoCo  simulator 进行测试，提出的方法能够提高多指机器人抓取技能的计算效率和多样性，并在多指机器人抓取领域取得显著进步。<details>
<summary>Abstract</summary>
Robotic grasping is a fundamental skill required for object manipulation in robotics. Multi-fingered robotic hands, which mimic the structure of the human hand, can potentially perform complex object manipulation. Nevertheless, current techniques for multi-fingered robotic grasping frequently predict only a single grasp for each inference time, limiting computational efficiency and their versatility, i.e. unimodal grasp distribution. This paper proposes a differentiable multi-fingered grasp generation network (DMFC-GraspNet) with three main contributions to address this challenge. Firstly, a novel neural grasp planner is proposed, which predicts a new grasp representation to enable versatile and dense grasp predictions. Secondly, a scene creation and label mapping method is developed for dense labeling of multi-fingered robotic hands, which allows a dense association of ground truth grasps. Thirdly, we propose to train DMFC-GraspNet end-to-end using using a forward-backward automatic differentiation approach with both a supervised loss and a differentiable collision loss and a generalized Q 1 grasp metric loss. The proposed approach is evaluated using the Shadow Dexterous Hand on Mujoco simulation and ablated by different choices of loss functions. The results demonstrate the effectiveness of the proposed approach in predicting versatile and dense grasps, and in advancing the field of multi-fingered robotic grasping.
</details>
<details>
<summary>摘要</summary>
瑞博机器人抓取是机器人控制领域的基本技能之一，可以帮助机器人抓取和操作物体。多指机器人手臂，它们模仿人类手臂的结构，可以执行复杂的物体抓取。然而，当前的多指机器人抓取技术 frequently predicts only a single grasp for each inference time，这限制了计算效率和其多样性，即单模态抓取分布。这篇论文提出了一种可微分的多指机器人抓取生成网络（DMFC-GraspNet），具有以下三个贡献：首先，一种新的神经网络抓取规划器被提出，可以预测多种抓取方式，以提高抓取多样性和密度。第二，一种场景创建和标签映射方法被开发出来，用于密集标注多指机器人手臂。这allow us to associate dense ground truth grasps with the robotic hands.第三，我们提议使用一种综合损失函数和自动梯度推导法来训练DMFC-GraspNet，包括监督损失和不可 differentiable损失。我们还使用一种通用Q1抓取度量loss。我们在Mujoco simulate中使用瑞博dex手臂进行训练和磨练，并对不同损失函数进行ablation。结果表明，我们的方法可以预测多样和密集的抓取方式，并在多指机器人抓取领域提高了前iers。
</details></li>
</ul>
<hr>
<h2 id="MAiVAR-T-Multimodal-Audio-image-and-Video-Action-Recognizer-using-Transformers"><a href="#MAiVAR-T-Multimodal-Audio-image-and-Video-Action-Recognizer-using-Transformers" class="headerlink" title="MAiVAR-T: Multimodal Audio-image and Video Action Recognizer using Transformers"></a>MAiVAR-T: Multimodal Audio-image and Video Action Recognizer using Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03741">http://arxiv.org/abs/2308.03741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Bilal Shaikh, Douglas Chai, Syed Mohammed Shamsul Islam, Naveed Akhtar</li>
<li>for: 提高多模态人体动作识别（MHAR）的效果</li>
<li>methods: 利用音频模式和图像模式的结合，通过将音频模式转化到图像模式中，形成一个统一的表示。</li>
<li>results: 与现有的状态 искусственный智能策略相比，MAiVAR-T表现出色，实验结果证明了模型在人体动作识别任务中的优异表现。<details>
<summary>Abstract</summary>
In line with the human capacity to perceive the world by simultaneously processing and integrating high-dimensional inputs from multiple modalities like vision and audio, we propose a novel model, MAiVAR-T (Multimodal Audio-Image to Video Action Recognition Transformer). This model employs an intuitive approach for the combination of audio-image and video modalities, with a primary aim to escalate the effectiveness of multimodal human action recognition (MHAR). At the core of MAiVAR-T lies the significance of distilling substantial representations from the audio modality and transmuting these into the image domain. Subsequently, this audio-image depiction is fused with the video modality to formulate a unified representation. This concerted approach strives to exploit the contextual richness inherent in both audio and video modalities, thereby promoting action recognition. In contrast to existing state-of-the-art strategies that focus solely on audio or video modalities, MAiVAR-T demonstrates superior performance. Our extensive empirical evaluations conducted on a benchmark action recognition dataset corroborate the model's remarkable performance. This underscores the potential enhancements derived from integrating audio and video modalities for action recognition purposes.
</details>
<details>
<summary>摘要</summary>
根据人类能同时处理和 integrate 多个模式的高维输入，我们提出一种新的模型，MAiVAR-T（多模态音频图像到视频动作识别变换器）。这个模型采用一种直观的方法将 audio-image 和 video 模式结合，以提高多模态人体动作识别（MHAR）的效果。MAiVAR-T 的核心在于将 audio 模式中的重要表示转化到图像频谱中，然后将这些图像表示与 video 模式结合，形成一个统一的表示。这种结合方法利用了 audio 和 video 模式中的内在背景，提高动作识别的性能。与现有的state-of-the-art策略不同，MAiVAR-T 不仅仅关注 audio 或 video 模式，而是通过结合这两种模式来提高动作识别的效果。我们的广泛的实验证明，MAiVAR-T 在一个标准的动作识别数据集上表现出优秀的成绩，这证明了将 audio 和 video 模式结合起来可以提高动作识别的性能。
</details></li>
</ul>
<hr>
<h2 id="Structural-Embeddings-of-Tools-for-Large-Language-Models"><a href="#Structural-Embeddings-of-Tools-for-Large-Language-Models" class="headerlink" title="Structural Embeddings of Tools for Large Language Models"></a>Structural Embeddings of Tools for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00447">http://arxiv.org/abs/2308.00447</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eren Unlu</li>
<li>for: 本研究的中心目标是强调在未来，大语言模型（LLM）与外部工具之间的图形基本方法的重要性。</li>
<li>methods: 该研究提出了一种例子框架，用于导航 LLM 与 exponentially 增长的外部工具之间的互动。该框架使用图形编码对象ives和功能性，以便在不同任务下进行可控的组合。</li>
<li>results: 该研究认为，图形基本方法可以为 LLM 在不同任务下的扩展和应用带来新的可能性，包括文本段的链式思维（CoT）等。<details>
<summary>Abstract</summary>
It is evident that the current state of Large Language Models (LLMs) necessitates the incorporation of external tools. The lack of straightforward algebraic and logical reasoning is well documented and prompted researchers to develop frameworks which allow LLMs to operate via external tools. The ontological nature of tool utilization for a specific task can be well formulated with a Directed Acyclic Graph (DAG). The central aim of the paper is to highlight the importance of graph based approaches to LLM-tool interaction in near future. We propose an exemplary framework to guide the orchestration of exponentially increasing numbers of external tools with LLMs,where objectives and functionalities of tools are graph encoded hierarchically. Assuming that textual segments of a Chain-of-Thought (CoT) can be imagined as a tool as defined here, the graph based framework can pave new avenues in that particular direction as well.
</details>
<details>
<summary>摘要</summary>
现在的大语言模型（LLM）需要外部工具的整合。lack of 直觉的代数逻辑已经被文献所证明，促使研究人员发展出用外部工具进行 LLM 操作的框架。 ontological 性的工具使用方式可以通过指向不同的导航图（DAG）来形式化。本文的主要目的是强调在未来中graph基本方法将在 LLM 与外部工具之间扮演重要的角色。我们提出了一个示范性的框架，以引导 exponentially 增加的外部工具与 LLM 之间的协调，其中工具的目标和功能将在层次结构中被图解编码。假设文本段落可以被想象为一个链接思维（CoT）中的工具，那么图基的框架将可以开启新的可能性。
</details></li>
</ul>
<hr>
<h2 id="ALE-A-Simulation-Based-Active-Learning-Evaluation-Framework-for-the-Parameter-Driven-Comparison-of-Query-Strategies-for-NLP"><a href="#ALE-A-Simulation-Based-Active-Learning-Evaluation-Framework-for-the-Parameter-Driven-Comparison-of-Query-Strategies-for-NLP" class="headerlink" title="ALE: A Simulation-Based Active Learning Evaluation Framework for the Parameter-Driven Comparison of Query Strategies for NLP"></a>ALE: A Simulation-Based Active Learning Evaluation Framework for the Parameter-Driven Comparison of Query Strategies for NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02537">http://arxiv.org/abs/2308.02537</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/philipp-kohl/active-learning-evaluation-framework">https://github.com/philipp-kohl/active-learning-evaluation-framework</a></li>
<li>paper_authors: Philipp Kohl, Nils Freyer, Yoka Krämer, Henri Werth, Steffen Wolf, Bodo Kraft, Matthias Meinecke, Albert Zündorf<br>for: This paper aims to provide an empirical basis for choosing between different active learning (AL) strategies in natural language processing (NLP) tasks.methods: The paper introduces a reproducible active learning evaluation (ALE) framework for comparing AL strategies in NLP. The framework allows for the implementation of AL strategies with low effort and a fair data-driven comparison, and it tracks experiment parameters such as initial dataset size, number of data points per query step, and budget.results: The paper presents a case study to illustrate how to use the ALE framework, and it provides a basis for practitioners to make more informed decisions and for researchers to focus on developing new, effective AL strategies and deriving best practices for specific use cases.<details>
<summary>Abstract</summary>
Supervised machine learning and deep learning require a large amount of labeled data, which data scientists obtain in a manual, and time-consuming annotation process. To mitigate this challenge, Active Learning (AL) proposes promising data points to annotators they annotate next instead of a subsequent or random sample. This method is supposed to save annotation effort while maintaining model performance. However, practitioners face many AL strategies for different tasks and need an empirical basis to choose between them. Surveys categorize AL strategies into taxonomies without performance indications. Presentations of novel AL strategies compare the performance to a small subset of strategies. Our contribution addresses the empirical basis by introducing a reproducible active learning evaluation (ALE) framework for the comparative evaluation of AL strategies in NLP. The framework allows the implementation of AL strategies with low effort and a fair data-driven comparison through defining and tracking experiment parameters (e.g., initial dataset size, number of data points per query step, and the budget). ALE helps practitioners to make more informed decisions, and researchers can focus on developing new, effective AL strategies and deriving best practices for specific use cases. With best practices, practitioners can lower their annotation costs. We present a case study to illustrate how to use the framework.
</details>
<details>
<summary>摘要</summary>
超vised机器学习和深度学习需要大量标注数据，数据科学家通过手动、时间consuming的标注过程获取。为了解决这个挑战，活动学习（AL）提出了有前提的数据点，而不是随机或后续的样本。这种方法可以降低标注努力的时间和成本，同时保持模型性能。然而，实践者面临着许多AL策略，需要一个经验基础来选择。现有的survey categorizes AL策略，但没有表现指标。文章提出了一个可重复的活动学习评价（ALE）框架，用于比较AL策略的相对评价。该框架可以实现AL策略的实现，并且通过定义和跟踪实验参数（例如，初始数据集大小，每次查询步骤中的数据点数和预算）来进行公平的比较。ALE帮助实践者更加了解决，研究者可以更专注于开发新的、有效的AL策略和特定用例的最佳实践。通过最佳实践，实践者可以降低标注成本。我们在case study中示例如如何使用该框架。
</details></li>
</ul>
<hr>
<h2 id="SelfCheck-Using-LLMs-to-Zero-Shot-Check-Their-Own-Step-by-Step-Reasoning"><a href="#SelfCheck-Using-LLMs-to-Zero-Shot-Check-Their-Own-Step-by-Step-Reasoning" class="headerlink" title="SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning"></a>SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00436">http://arxiv.org/abs/2308.00436</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ningmiao/selfcheck">https://github.com/ningmiao/selfcheck</a></li>
<li>paper_authors: Ning Miao, Yee Whye Teh, Tom Rainforth</li>
<li>for: 本研究旨在检验大语言模型（LLM）是否可以自动认错，而不需要外部资源。</li>
<li>methods: 我们提出了一种零 shot 验证方案，用于识别具有多步骤 reasoning 的错误。然后，我们使用这种验证方案来提高问答性能，通过对不同生成的答案进行权重投票。</li>
<li>results: 我们在三个数学 dataset（GSM8K、MathQA 和 MATH）上测试了这种方法，发现它可以成功识别错误，并在最终预测性能中提高表现。<details>
<summary>Abstract</summary>
The recent progress in large language models (LLMs), especially the invention of chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning problems. However, even the strongest LLMs are still struggling with more complicated problems that require non-linear thinking and multi-step reasoning. In this work, we explore whether LLMs have the ability to recognize their own errors, without resorting to external resources. In particular, we investigate whether they can be used to identify individual errors within a step-by-step reasoning. To this end, we propose a zero-shot verification scheme to recognize such errors. We then use this verification scheme to improve question-answering performance, by using it to perform weighted voting on different generated answers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and find that it successfully recognizes errors and, in turn, increases final predictive performance.
</details>
<details>
<summary>摘要</summary>
最近的大语言模型（LLM）的进步，尤其是创造思维（CoT）提问的发明，使得解释问题变得可能。然而，即使最强的LLM也在更复杂的问题上尚未能具备非线性思维和多步逻辑。在这种情况下，我们询问LLM是否有能力自动发现错误，不需要外部资源。具体来说，我们研究LLM是否可以识别每个步逻辑中的错误。为此，我们提出了零shot验证方案，用于识别错误。然后，我们使用这种验证方案来提高问答性能，通过对不同生成的答案进行权重投票。我们在三个数学 dataset（GSM8K、MathQA和MATH）上测试了该方法，并发现它可以成功识别错误，并在最终预测性能中提高表现。
</details></li>
</ul>
<hr>
<h2 id="Patch-wise-Auto-Encoder-for-Visual-Anomaly-Detection"><a href="#Patch-wise-Auto-Encoder-for-Visual-Anomaly-Detection" class="headerlink" title="Patch-wise Auto-Encoder for Visual Anomaly Detection"></a>Patch-wise Auto-Encoder for Visual Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00429">http://arxiv.org/abs/2308.00429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yajie Cui, Zhaoxiang Liu, Shiguo Lian</li>
<li>for: 提高无supervision anomaly detection的能力</li>
<li>methods: 使用patch-wise auto-encoder（Patch AE）框架，通过对每个图像 patch 的重建，提高模型对异常图像的重建能力</li>
<li>results: 在Mvtec AD benchmark上达到了新的州 Of-the-art性能，表明方法的效果。有很大的实际应用前景。<details>
<summary>Abstract</summary>
Anomaly detection without priors of the anomalies is challenging. In the field of unsupervised anomaly detection, traditional auto-encoder (AE) tends to fail based on the assumption that by training only on normal images, the model will not be able to reconstruct abnormal images correctly. On the contrary, we propose a novel patch-wise auto-encoder (Patch AE) framework, which aims at enhancing the reconstruction ability of AE to anomalies instead of weakening it. Each patch of image is reconstructed by corresponding spatially distributed feature vector of the learned feature representation, i.e., patch-wise reconstruction, which ensures anomaly-sensitivity of AE. Our method is simple and efficient. It advances the state-of-the-art performances on Mvtec AD benchmark, which proves the effectiveness of our model. It shows great potential in practical industrial application scenarios.
</details>
<details>
<summary>摘要</summary>
寻找无先知 anomaly 是一项挑战。在无监督 anomaly detection 领域，传统的 auto-encoder (AE) 往往会因为只在正常图像上训练，导致模型无法正确地重建异常图像。相反，我们提出了一种 novel patch-wise auto-encoder (Patch AE) 框架，旨在增强 AE 对异常图像的重建能力，而不是弱化它。每个图像的每个patch 都由对应的空间分布的特征向量来重建， guarantees 异常敏感性。我们的方法简单、高效，可以提高 state-of-the-art 性能，证明了我们的模型的效果。它在实际工业应用场景中表现出了很大的潜力。
</details></li>
</ul>
<hr>
<h2 id="Generative-adversarial-networks-with-physical-sound-field-priors"><a href="#Generative-adversarial-networks-with-physical-sound-field-priors" class="headerlink" title="Generative adversarial networks with physical sound field priors"></a>Generative adversarial networks with physical sound field priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00426">http://arxiv.org/abs/2308.00426</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xefonon/soundfieldgan">https://github.com/xefonon/soundfieldgan</a></li>
<li>paper_authors: Xenofon Karakonstantis, Efren Fernandez-Grande</li>
<li>for: 这种方法用于重构听场，使用生成敌对网络（GANs）。</li>
<li>methods: 该方法使用平面波基础，学习室内压力的下来分布，以准确地重构听场从有限多个测量点。</li>
<li>results: 研究表明，该模型可以在高频范围内提高重构精度和能量保持率，特别是在测量区域之外推算。此外，该方法可以适应不同测量点和配置的变化，无需牺牲性能。<details>
<summary>Abstract</summary>
This paper presents a deep learning-based approach for the spatio-temporal reconstruction of sound fields using Generative Adversarial Networks (GANs). The method utilises a plane wave basis and learns the underlying statistical distributions of pressure in rooms to accurately reconstruct sound fields from a limited number of measurements. The performance of the method is evaluated using two established datasets and compared to state-of-the-art methods. The results show that the model is able to achieve an improved reconstruction performance in terms of accuracy and energy retention, particularly in the high-frequency range and when extrapolating beyond the measurement region. Furthermore, the proposed method can handle a varying number of measurement positions and configurations without sacrificing performance. The results suggest that this approach provides a promising approach to sound field reconstruction using generative models that allow for a physically informed prior to acoustics problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Discourse-Aware-Text-Simplification-From-Complex-Sentences-to-Linked-Propositions"><a href="#Discourse-Aware-Text-Simplification-From-Complex-Sentences-to-Linked-Propositions" class="headerlink" title="Discourse-Aware Text Simplification: From Complex Sentences to Linked Propositions"></a>Discourse-Aware Text Simplification: From Complex Sentences to Linked Propositions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00425">http://arxiv.org/abs/2308.00425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christina Niklaus, Matthias Cetto, André Freitas, Siegfried Handschuh</li>
<li>for: 这个论文的目的是提高自然语言处理应用程序的预测质量，通过修改句子的结构和长度，使其更容易分析。</li>
<li>methods: 这个论文使用了一种基于语言知识的文本简化方法，包括句子拆分和重新排序，以提高句子的简单性和可读性。</li>
<li>results: 这个论文的实验结果表明，这种基于语言知识的文本简化方法可以有效地提高自然语言处理应用程序的预测质量，并且可以保持句子的意义完整性。<details>
<summary>Abstract</summary>
Sentences that present a complex syntax act as a major stumbling block for downstream Natural Language Processing applications whose predictive quality deteriorates with sentence length and complexity. The task of Text Simplification (TS) may remedy this situation. It aims to modify sentences in order to make them easier to process, using a set of rewriting operations, such as reordering, deletion, or splitting. State-of-the-art syntactic TS approaches suffer from two major drawbacks: first, they follow a very conservative approach in that they tend to retain the input rather than transforming it, and second, they ignore the cohesive nature of texts, where context spread across clauses or sentences is needed to infer the true meaning of a statement. To address these problems, we present a discourse-aware TS approach that splits and rephrases complex English sentences within the semantic context in which they occur. Based on a linguistically grounded transformation stage that uses clausal and phrasal disembedding mechanisms, complex sentences are transformed into shorter utterances with a simple canonical structure that can be easily analyzed by downstream applications. With sentence splitting, we thus address a TS task that has hardly been explored so far. Moreover, we introduce the notion of minimality in this context, as we aim to decompose source sentences into a set of self-contained minimal semantic units. To avoid breaking down the input into a disjointed sequence of statements that is difficult to interpret because important contextual information is missing, we incorporate the semantic context between the split propositions in the form of hierarchical structures and semantic relationships. In that way, we generate a semantic hierarchy of minimal propositions that leads to a novel representation of complex assertions that puts a semantic layer on top of the simplified sentences.
</details>
<details>
<summary>摘要</summary>
сложные предложения acted as a major stumbling block for downstream Natural Language Processing applications, whose predictive quality decreased with sentence length and complexity. The task of Text Simplification (TS) may remedy this situation. It aims to modify sentences to make them easier to process, using a set of rewriting operations such as reordering, deletion, or splitting. However, state-of-the-art syntactic TS approaches have two major drawbacks: they tend to retain the input rather than transforming it, and they ignore the cohesive nature of texts, where context spread across clauses or sentences is needed to infer the true meaning of a statement. To address these problems, we present a discourse-aware TS approach that splits and rephrases complex English sentences within the semantic context in which they occur. Based on a linguistically grounded transformation stage that uses clausal and phrasal disembedding mechanisms, complex sentences are transformed into shorter utterances with a simple canonical structure that can be easily analyzed by downstream applications. With sentence splitting, we thus address a TS task that has hardly been explored so far. Moreover, we introduce the notion of minimality in this context, as we aim to decompose source sentences into a set of self-contained minimal semantic units. To avoid breaking down the input into a disjointed sequence of statements that is difficult to interpret because important contextual information is missing, we incorporate the semantic context between the split propositions in the form of hierarchical structures and semantic relationships. In this way, we generate a semantic hierarchy of minimal propositions that leads to a novel representation of complex assertions that puts a semantic layer on top of the simplified sentences.
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Role-of-Explainability-in-AI-Assisted-Embryo-Selection"><a href="#Exploring-the-Role-of-Explainability-in-AI-Assisted-Embryo-Selection" class="headerlink" title="Exploring the Role of Explainability in AI-Assisted Embryo Selection"></a>Exploring the Role of Explainability in AI-Assisted Embryo Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02534">http://arxiv.org/abs/2308.02534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva Cívico, Sergio Álvarez-Napagao, Dario Garcia-Gasulla</li>
<li>for: 这篇研究旨在探讨人工受精（In Vitro Fertilization）中选择和评估胚胎的方法，以及如何将人工智能（AI）技术应用于胚胎分析中，以提高评估过程的精度和可靠性。</li>
<li>methods: 本研究使用了深度学习技术，并分析了现有的AI-助け胚胎分析模型的解释性。</li>
<li>results: 研究发现现有的AI-助け胚胎分析模型的解释性有限，并提出了将这些模型整合到临床实践中的建议，以满足诊断师和病人的需求。<details>
<summary>Abstract</summary>
In Vitro Fertilization is among the most widespread treatments for infertility. One of its main challenges is the evaluation and selection of embryo for implantation, a process with large inter- and intra-clinician variability. Deep learning based methods are gaining attention, but their opaque nature compromises their acceptance in the clinical context, where transparency in the decision making is key. In this paper we analyze the current work in the explainability of AI-assisted embryo analysis models, identifying the limitations. We also discuss how these models could be integrated in the clinical context as decision support systems, considering the needs of clinicians and patients. Finally, we propose guidelines for the sake of increasing interpretability and trustworthiness, pushing this technology forward towards established clinical practice.
</details>
<details>
<summary>摘要</summary>
幂化诊断是妊娠不孕的一种最广泛的治疗方法。其中一个主要挑战是评估和选择受试 embryo 进行嵌入，这个过程具有大量的内部和外部医生差异性。深度学习基于的方法在引起了关注，但它们的透明性问题限制了它们在临床上的接受度。本文分析了现有的 AI-assisted embryo 分析模型解释性的工作，并识别了其局限性。我们还讨论了如何将这些模型integrated into the clinical context as decision support systems, considering the needs of clinicians and patients。最后，我们提出了增加解释性和可信度的指南，推动这种技术向确定的临床实践前进。Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="BiERL-A-Meta-Evolutionary-Reinforcement-Learning-Framework-via-Bilevel-Optimization"><a href="#BiERL-A-Meta-Evolutionary-Reinforcement-Learning-Framework-via-Bilevel-Optimization" class="headerlink" title="BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel Optimization"></a>BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01207">http://arxiv.org/abs/2308.01207</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chriswang98sz/bierl">https://github.com/chriswang98sz/bierl</a></li>
<li>paper_authors: Junyi Wang, Yuanyang Zhu, Zhi Wang, Yan Zheng, Jianye Hao, Chunlin Chen</li>
<li>for: 提高复杂RL问题的解决能力，适应不同RL算法的应用</li>
<li>methods: 提出了一种总体meta-RL框架，通过级联优化来同时更新内部RL模型和meta参数，不需要先知道预料或优化过程</li>
<li>results: 通过在MuJoCo和Box2D任务中进行了广泛的实验，证明了BiERL在多种ERL算法中表现出色，可以持续提高RL模型的学习效率<details>
<summary>Abstract</summary>
Evolutionary reinforcement learning (ERL) algorithms recently raise attention in tackling complex reinforcement learning (RL) problems due to high parallelism, while they are prone to insufficient exploration or model collapse without carefully tuning hyperparameters (aka meta-parameters). In the paper, we propose a general meta ERL framework via bilevel optimization (BiERL) to jointly update hyperparameters in parallel to training the ERL model within a single agent, which relieves the need for prior domain knowledge or costly optimization procedure before model deployment. We design an elegant meta-level architecture that embeds the inner-level's evolving experience into an informative population representation and introduce a simple and feasible evaluation of the meta-level fitness function to facilitate learning efficiency. We perform extensive experiments in MuJoCo and Box2D tasks to verify that as a general framework, BiERL outperforms various baselines and consistently improves the learning performance for a diversity of ERL algorithms.
</details>
<details>
<summary>摘要</summary>
生化演进学习（ERL）算法在复杂的演进学习（RL）问题中受到关注，因为它们具有高并行性。然而，它们可能会因为不足的探索或模型崩溃而需要精心调整超参数（meta-parameters）。在这篇论文中，我们提出了一种通用的meta-ERL框架，通过级联优化（BiERL）来同时更新超参数和ERL模型，从而避免需要先进行模型部署前的优化或培ippi���hn Domain知识。我们设计了一种美化的meta- уров层建 architecture，将inner-level的演进经验嵌入到一个有用的人口表示中，并引入一种简单可行的meta- уров度评价函数，以便提高学习效率。我们在MuJoCo和Box2D任务中进行了广泛的实验，并证明了BiERL框架在多种ERL算法中具有优秀的总体性能。
</details></li>
</ul>
<hr>
<h2 id="Challenging-the-Myth-of-Graph-Collaborative-Filtering-a-Reasoned-and-Reproducibility-driven-Analysis"><a href="#Challenging-the-Myth-of-Graph-Collaborative-Filtering-a-Reasoned-and-Reproducibility-driven-Analysis" class="headerlink" title="Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis"></a>Challenging the Myth of Graph Collaborative Filtering: a Reasoned and Reproducibility-driven Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00404">http://arxiv.org/abs/2308.00404</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sisinflab/graph-rss-reproducibility">https://github.com/sisinflab/graph-rss-reproducibility</a></li>
<li>paper_authors: Vito Walter Anelli, Daniele Malitesta, Claudio Pomo, Alejandro Bellogín, Tommaso Di Noia, Eugenio Di Sciascio</li>
<li>for: 本研究旨在提高图解析器（Graph Neural Network，GNN）在推荐系统中的可重现性，以便更好地理解不同图解析器在具体的配置下的表现。</li>
<li>methods: 本研究使用了六种流行的图解析器（NGCF、DGCF、LightGCN、SGL、UltraGCN、GFCF），在三个常用的数据集（Gowalla、Yelp 2018、Amazon Book）上进行了实验。此外，研究者还与传统的共同推荐模型进行了比较，以评估图解析器在不同数据集上的表现。</li>
<li>results: 研究发现，在三个常用的数据集上，图解析器的表现有所不同，而且与传统的共同推荐模型相比，图解析器在一些数据集上表现较差。此外，研究者还发现了数据集的特点对于推荐准确性的影响。<details>
<summary>Abstract</summary>
The success of graph neural network-based models (GNNs) has significantly advanced recommender systems by effectively modeling users and items as a bipartite, undirected graph. However, many original graph-based works often adopt results from baseline papers without verifying their validity for the specific configuration under analysis. Our work addresses this issue by focusing on the replicability of results. We present a code that successfully replicates results from six popular and recent graph recommendation models (NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark datasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these graph models with traditional collaborative filtering models that historically performed well in offline evaluations. Furthermore, we extend our study to two new datasets (Allrecipes and BookCrossing) that lack established setups in existing literature. As the performance on these datasets differs from the previous benchmarks, we analyze the impact of specific dataset characteristics on recommendation accuracy. By investigating the information flow from users' neighborhoods, we aim to identify which models are influenced by intrinsic features in the dataset structure. The code to reproduce our experiments is available at: https://github.com/sisinflab/Graph-RSs-Reproducibility.
</details>
<details>
<summary>摘要</summary>
GRAPH Neural Network-based models (GNNs) 的成功有效地提高了推荐系统，通过模型用户和物品为两个bidirectional, undirected 图。然而，许多原始图基 works often adopt 基线纸上的结果 без 验证它们是否适用于特定配置。我们的工作解决这个问题，我们专注于复制性。我们提供了一个代码，可以成功复制六种流行的最近的图推荐模型（NGCF、DGCF、LightGCN、SGL、UltraGCN 和 GFCF）的结果在三个常见的benchmark datasets（Gowalla、Yelp 2018 和 Amazon Book）。此外，我们与传统的合作 filtering 模型进行比较，这些模型在过去的线上评估中表现良好。此外，我们将研究 extends to two new datasets（Allrecipes 和 BookCrossing），这些 dataset 在现有 литературе中没有 Established setup。由于这些dataset的性能与之前的benchmark datasets不同，我们分析数据集特点对于推荐准确性的影响。我们通过研究用户邻居的信息流来Identify which models are influenced by intrinsic features in the dataset structure。我们的代码可以在：https://github.com/sisinflab/Graph-RSs-Reproducibility中复制。
</details></li>
</ul>
<hr>
<h2 id="Counterfactual-Graph-Transformer-for-Traffic-Flow-Prediction"><a href="#Counterfactual-Graph-Transformer-for-Traffic-Flow-Prediction" class="headerlink" title="Counterfactual Graph Transformer for Traffic Flow Prediction"></a>Counterfactual Graph Transformer for Traffic Flow Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00391">http://arxiv.org/abs/2308.00391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Yang, Kai Du, Xingyuan Dai, Jianwu Fang</li>
<li>for: 提高流量预测的可解释性和可靠性</li>
<li>methods: 提出了Counterfactual Graph Transformer（CGT）模型，并实现了对输入感知特征和图结构的干扰掩码生成器，以获取空间和时间 counterfactual 解释</li>
<li>results: 对三个实际世界公共数据集进行了广泛的实验，并证明了 CGT 可以生成可靠的解释和提高流量预测的可靠性。<details>
<summary>Abstract</summary>
Traffic flow prediction (TFP) is a fundamental problem of the Intelligent Transportation System (ITS), as it models the latent spatial-temporal dependency of traffic flow for potential congestion prediction. Recent graph-based models with multiple kinds of attention mechanisms have achieved promising performance. However, existing methods for traffic flow prediction tend to inherit the bias pattern from the dataset and lack interpretability. To this end, we propose a Counterfactual Graph Transformer (CGT) model with an instance-level explainer (e.g., finding the important subgraphs) specifically designed for TFP. We design a perturbation mask generator over input sensor features at the time dimension and the graph structure on the graph transformer module to obtain spatial and temporal counterfactual explanations. By searching the optimal perturbation masks on the input data feature and graph structures, we can obtain the concise and dominant data or graph edge links for the subsequent TFP task. After re-training the utilized graph transformer model after counterfactual perturbation, we can obtain improved and interpretable traffic flow prediction. Extensive results on three real-world public datasets show that CGT can produce reliable explanations and is promising for traffic flow prediction.
</details>
<details>
<summary>摘要</summary>
traffic 流量预测（TFP）是智能交通系统（ITS）的基本问题，它模型了交通流量的隐藏空间时间相互关系，以预测潮湍。  current 图形基于模型已经实现了显著的表现。 however， exiting 方法 для traffic 流量预测通常会继承数据集的偏见模式和lack of interpretability。 To address this, we propose a Counterfactual Graph Transformer（CGT）模型，具有实例级别的解释器（例如，找到重要的子图），specifically designed for TFP. We design a 扰动mask生成器 over input sensor features at the time dimension and the graph structure on the graph transformer module to obtain spatial and temporal counterfactual explanations. By searching the optimal perturbation masks on the input data feature and graph structures, we can obtain the concise and dominant data or graph edge links for the subsequent TFP task. After re-training the utilized graph transformer model after counterfactual perturbation, we can obtain improved and interpretable traffic flow prediction. Extensive results on three real-world public datasets show that CGT can produce reliable explanations and is promising for traffic flow prediction.Note: Some words and phrases have been modified to conform to Simplified Chinese grammar and vocabulary.
</details></li>
</ul>
<hr>
<h2 id="Artificial-Intelligence-Based-Triple-Phase-Shift-Modulation-for-Dual-Active-Bridge-Converter-with-Minimized-Current-Stress"><a href="#Artificial-Intelligence-Based-Triple-Phase-Shift-Modulation-for-Dual-Active-Bridge-Converter-with-Minimized-Current-Stress" class="headerlink" title="Artificial-Intelligence-Based Triple Phase Shift Modulation for Dual Active Bridge Converter with Minimized Current Stress"></a>Artificial-Intelligence-Based Triple Phase Shift Modulation for Dual Active Bridge Converter with Minimized Current Stress</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00382">http://arxiv.org/abs/2308.00382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinze Li, Xin Zhang, Fanfan Lin, Changjiang Sun, Kezhi Mao</li>
<li>for: 本研究旨在提出一种基于人工智能的三相扩展（TPS）调制策略，以最小化DAB转换器的电流压力。</li>
<li>methods: 本研究使用神经网络（NN）和软件推理系统（FIS）来解决TPS调制中的三个调制变量对current stress的影响，并提出了一种基于AI的TPS调制策略。</li>
<li>results: 实验结果表明，提出的AI-TPSM策略可以减少DAB转换器的电流压力，并且可以提高TPS调制的精度和可靠性。<details>
<summary>Abstract</summary>
The dual active bridge (DAB) converter has been popular in many applications for its outstanding power density and bidirectional power transfer capacity. Up to now, triple phase shift (TPS) can be considered as one of the most advanced modulation techniques for DAB converter. It can widen zero voltage switching range and improve power efficiency significantly. Currently, current stress of the DAB converter has been an important performance indicator when TPS modulation is applied for smaller size and higher efficiency. However, to minimize the current stress when the DAB converter is under TPS modulation, two difficulties exist in analysis process and realization process, respectively. Firstly, three degrees of modulation variables in TPS modulation bring challenges to the analysis of current stress in different operating modes. This analysis and deduction process leads to heavy computational burden and also suffers from low accuracy. Secondly, to realize TPS modulation, if a lookup table is adopted after the optimization of modulation variables, modulation performance will be unsatisfactory because of the discrete nature of lookup table. Therefore, an AI-based TPS modulation (AI-TPSM) strategy is proposed in this paper. Neural network (NN) and fuzzy inference system (FIS) are utilized to deal with the two difficulties mentioned above. With the proposed AI-TPSM, the optimization of TPS modulation for minimized current stress will enjoy high degree of automation which can relieve engineers' working burden and improve accuracy. In the end of this paper, the effectiveness of the proposed AI-TPSM has been experimentally verified with a 1 kW prototype.
</details>
<details>
<summary>摘要</summary>
双活桥（DAB）Converter在许多应用中具有出色的电力密度和对向电力传输能力。至今为止，三相滑动（TPS）可以被视为DABConverter中最高等级的调制技术。它可以宽化零电压调制范围和提高电力效率很大。然而，当TPS调制被应用时，DABConverter的电流负载成为了重要的性能指标。但是，为了最小化DABConverter在TPS调制下的电流负载，存在两种难点：一是TPS调制中的三个调制变数带来了不同运行模式下的电流压力分析和推导过程中的重要问题，这个过程具有复杂的计算负载和低准确性。二是，为了实现TPS调制，如果使用 lookup 表，则调制性能将会不满足。因此，本文提出了一个基于人工智能（AI）的TPS调制策略（AI-TPSM）。使用神经网络（NN）和决策系统（FIS）来解决这两个问题。具有提案的AI-TPSM，将促进TPS调制的最佳化，从而实现较高的自动化程度，减轻工程师的工作负担，并提高准确性。本文的实验结果显示，提案的AI-TPSM在1kW试验产品中得到了认可。
</details></li>
</ul>
<hr>
<h2 id="Artificial-Intelligence-Based-Hybrid-Extended-Phase-Shift-Modulation-for-the-Dual-Active-Bridge-Converter-with-Full-ZVS-Range-and-Optimal-Efficiency"><a href="#Artificial-Intelligence-Based-Hybrid-Extended-Phase-Shift-Modulation-for-the-Dual-Active-Bridge-Converter-with-Full-ZVS-Range-and-Optimal-Efficiency" class="headerlink" title="Artificial-Intelligence-Based Hybrid Extended Phase Shift Modulation for the Dual Active Bridge Converter with Full ZVS Range and Optimal Efficiency"></a>Artificial-Intelligence-Based Hybrid Extended Phase Shift Modulation for the Dual Active Bridge Converter with Full ZVS Range and Optimal Efficiency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00381">http://arxiv.org/abs/2308.00381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinze Li, Xin Zhang, Fanfan Lin, Changjiang Sun, Kezhi Mao</li>
<li>For: The paper aims to propose an artificial-intelligence-based hybrid extended phase shift (HEPS) modulation for dual active bridge (DAB) converters to achieve optimal efficiency with full zero-voltage switching (ZVS) operation over the entire operating range.* Methods: The HEPS modulation is developed using an automated fashion, which alleviates the cumbersome model building process while maintaining high model accuracy. The paper uses extreme gradient boosting (XGBoost) to build data-driven models of ZVS and efficiency performance, and particle swarm optimization with state-based adaptive velocity limit (PSO-SAVL) to select the best EPS strategy and optimize modulation parameters.* Results: The paper verifies the feasibility of HEPS with 1 kW hardware experiments, achieving optimal efficiency of up to 97.1% and full-range ZVS operation.<details>
<summary>Abstract</summary>
Dual active bridge (DAB) converter is the key enabler in many popular applications such as wireless charging, electric vehicle and renewable energy. ZVS range and efficiency are two significant performance indicators for DAB converter. To obtain the desired ZVS and efficiency performance, modulation should be carefully designed. Hybrid modulation considers several single modulation strategies to achieve good comprehensive performance. Conventionally, to design a hybrid modulation, harmonic approach or piecewise approach is used, but they suffer from time-consuming model building process and inaccuracy. Therefore, an artificial-intelligence-based hybrid extended phase shift (HEPS) modulation is proposed. Generally, the HEPS modulation is developed in an automated fashion, which alleviates cumbersome model building process while keeping high model accuracy. In HEPS modulation, two EPS strategies are considered to realize optimal efficiency with full ZVS operation over entire operating ranges. Specifically, to build data-driven models of ZVS and efficiency performance, extreme gradient boosting (XGBoost), which is a state-of-the-art ensemble learning algorithm, is adopted. Afterwards, particle swarm optimization with state-based adaptive velocity limit (PSO-SAVL) is utilized to select the best EPS strategy and optimize modulation parameters. With 1 kW hardware experiments, the feasibility of HEPS has been verified, achieving optimal efficiency with maximum of 97.1% and full-range ZVS operation.
</details>
<details>
<summary>摘要</summary>
双活桥（DAB）转换器是许多受欢迎应用程序中的关键启用器，如无线充电、电动车和可再生能源。ZVS范围和效率是DAB转换器的两个重要性能指标。为了实现所需的ZVS和效率性能，模拟应该仔细设计。在本文中，我们提出了人工智能基于的扩展phas shift（HEPS）模ulation，以解决传统的异步模ulation和分割模ulation的缺点。HEPS模ulation通过自动化模型建立过程来缓解繁琐的模型建立过程，同时保持高度准确。在HEPS模ulation中，两种EPS策略被考虑以实现最佳的效率和ZVS操作。具体来说，通过使用极限梯度搜索（XGBoost）算法来建立数据驱动模型，以实现ZVS和效率性能的优化。然后，使用粒子群搜索与状态基于适应限速（PSO-SAVL）算法来选择最佳EPS策略和优化模ulation参数。在1千瓦硬件实验中，我们证明了HEPS的可行性，实现了最佳效率（97.1%）和全范围ZVS操作。
</details></li>
</ul>
<hr>
<h2 id="Shape-Completion-with-Prediction-of-Uncertain-Regions"><a href="#Shape-Completion-with-Prediction-of-Uncertain-Regions" class="headerlink" title="Shape Completion with Prediction of Uncertain Regions"></a>Shape Completion with Prediction of Uncertain Regions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00377">http://arxiv.org/abs/2308.00377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dlr-rm/shape-completion">https://github.com/dlr-rm/shape-completion</a></li>
<li>paper_authors: Matthias Humt, Dominik Winkelbauer, Ulrich Hillenbrand</li>
<li>for: 这个研究是为了解决Shape completion问题，即从partial observation中推算出物体的完整几何构造。</li>
<li>methods: 本研究提出了两种新的方法来预测 uncertain regions，一种是通过处理occupancy scores的后处理，另一种是直接预测不确定指标。</li>
<li>results: 比较两种新方法和两种已知的方法，新方法在Shape completion和uncertain region prediction中都表现出来了较高的精度，并且可以避免预测的uncertain regions以提高grasps的质量。<details>
<summary>Abstract</summary>
Shape completion, i.e., predicting the complete geometry of an object from a partial observation, is highly relevant for several downstream tasks, most notably robotic manipulation. When basing planning or prediction of real grasps on object shape reconstruction, an indication of severe geometric uncertainty is indispensable. In particular, there can be an irreducible uncertainty in extended regions about the presence of entire object parts when given ambiguous object views. To treat this important case, we propose two novel methods for predicting such uncertain regions as straightforward extensions of any method for predicting local spatial occupancy, one through postprocessing occupancy scores, the other through direct prediction of an uncertainty indicator. We compare these methods together with two known approaches to probabilistic shape completion. Moreover, we generate a dataset, derived from ShapeNet, of realistically rendered depth images of object views with ground-truth annotations for the uncertain regions. We train on this dataset and test each method in shape completion and prediction of uncertain regions for known and novel object instances and on synthetic and real data. While direct uncertainty prediction is by far the most accurate in the segmentation of uncertain regions, both novel methods outperform the two baselines in shape completion and uncertain region prediction, and avoiding the predicted uncertain regions increases the quality of grasps for all tested methods. Web: https://github.com/DLR-RM/shape-completion
</details>
<details>
<summary>摘要</summary>
Shape completion, 即从部分观察获取物体完整的几何结构，在机器人抓取任务中非常有 relevance。当基于物体形状重建的计划或预测真正的抓取动作时，确保geometry uncertainty的存在是非常重要的。尤其是在给出杂乱的物体视图时，可能存在扩展区域中对整个物体部分的存在的不确定性。为处理这种重要的情况，我们提出了两种新的方法来预测这些不确定的区域，一种通过质量分配的后处理，另一种通过直接预测不确定指标。我们将这些方法与两种已知的概率形状完成方法进行比较。此外，我们还生成了基于ShapeNet的数据集，包含真实渲染的深度图像，以及对这些图像的 annotations for uncertain regions。我们在这个数据集上训练和测试每种方法的 shape completion和不确定区域预测能力，并发现两种新方法在shape completion和不确定区域预测方面都高于两个基elines，并且避免预测的不确定区域可以提高所有测试方法的抓取质量。详细信息请参考<https://github.com/DLR-RM/shape-completion>。
</details></li>
</ul>
<hr>
<h2 id="Fountain-–-an-intelligent-contextual-assistant-combining-knowledge-representation-and-language-models-for-manufacturing-risk-identification"><a href="#Fountain-–-an-intelligent-contextual-assistant-combining-knowledge-representation-and-language-models-for-manufacturing-risk-identification" class="headerlink" title="Fountain – an intelligent contextual assistant combining knowledge representation and language models for manufacturing risk identification"></a>Fountain – an intelligent contextual assistant combining knowledge representation and language models for manufacturing risk identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00364">http://arxiv.org/abs/2308.00364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurabh Kumar, Daniel Fuchs, Klaus Spindler</li>
<li>for: 本研究旨在提供一种基于语言模型和知识图的启用中间件，以帮助工程师在 deviations 管理中预测和避免因产品设计和生产过程变化而导致的风险。</li>
<li>methods: 本研究使用语言模型finetuned  для域pecific semantic similarity，以及基于bill of materials、Failure Modes and Effect Analysis (FMEA)和客户前面 Failure 的知识表示。</li>
<li>results: 研究人员通过实验和案例研究表明，可以通过采用本研究提出的方法，实时地预测和避免因 deviations 而导致的风险，并且可以在现有的计算机机器基础设施上进行模型更新和推理。<details>
<summary>Abstract</summary>
Deviations from the approved design or processes during mass production can lead to unforeseen risks. However, these changes are sometimes necessary due to changes in the product design characteristics or an adaptation in the manufacturing process. A major challenge is to identify these risks early in the workflow so that failures leading to warranty claims can be avoided. We developed Fountain as a contextual assistant integrated in the deviation management workflow that helps in identifying the risks based on the description of the existing design and process criteria and the proposed deviation. In the manufacturing context, it is important that the assistant provides recommendations that are explainable and consistent. We achieve this through a combination of the following two components 1) language models finetuned for domain specific semantic similarity and, 2) knowledge representation in the form of a property graph derived from the bill of materials, Failure Modes and Effect Analysis (FMEA) and prior failures reported by customers. Here, we present the nuances of selecting and adapting pretrained language models for an engineering domain, continuous model updates based on user interaction with the contextual assistant and creating the causal chain for explainable recommendations based on the knowledge representation. Additionally, we demonstrate that the model adaptation is feasible using moderate computational infrastructure already available to most engineering teams in manufacturing organizations and inference can be performed on standard CPU only instances for integration with existing applications making these methods easily deployable.
</details>
<details>
<summary>摘要</summary>
不同于批量生产中所批准的设计或过程的变化可能会导致未预见的风险。然而，这些变化有时是必要的，因为产品设计特点或生产过程中的变化。一个主要挑战是在工作流程中早期发现这些风险，以避免因杂 deviation 导致的售后服务请求。我们开发了一个名为“喷泉”的上下文助手，它在异常处理工作流程中帮助Identify 风险，基于现有设计和过程标准的描述和提案的异常。在制造上下文中，助手需要提供可解释的建议。我们通过以下两个组件实现了这一点：1）预处理语言模型，适应域pecific Semantic Similarity，和2）基于生产物料清单、失效模式分析（FMEA）和客户前置报告的知识表示。我们还解释了如何选择和适应预训练语言模型，连续更新模型基于用户与上下文助手的交互，以及如何创建 causal chain  для可解释的建议。此外，我们还证明了模型适配可以在现有的制造组织中进行，并且推理可以在标准CPU上进行，以便与现有应用程序集成。
</details></li>
</ul>
<hr>
<h2 id="MetaGPT-Meta-Programming-for-Multi-Agent-Collaborative-Framework"><a href="#MetaGPT-Meta-Programming-for-Multi-Agent-Collaborative-Framework" class="headerlink" title="MetaGPT: Meta Programming for Multi-Agent Collaborative Framework"></a>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00352">http://arxiv.org/abs/2308.00352</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/geekan/metagpt">https://github.com/geekan/metagpt</a></li>
<li>paper_authors: Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu</li>
<li>for: 这个论文的目的是探讨如何使用大型自然语言模型（LLM）驱动多代理人工作，以解决复杂的多代理人问题。</li>
<li>methods: 这个论文使用了一个创新的框架，名为MetaGPT，它将人类工作流程组合入大型自然语言模型中，以提高多代理人协作的有效性。</li>
<li>results: 实验结果显示，MetaGPT可以生成更一致和正确的解决方案，比较先进的对话式多代理人系统。这显示了将人类专业知识 integrate 到多代理人系统中的潜在可能性，并创造了复杂的现实世界挑战的新机会。<details>
<summary>Abstract</summary>
Recently, remarkable progress has been made in automated task-solving through the use of multi-agent driven by large language models (LLMs). However, existing LLM-based multi-agent works primarily focus on solving simple dialogue tasks, and complex tasks are rarely studied, mainly due to the LLM hallucination problem. This type of hallucination becomes cascading when naively chaining multiple intelligent agents, resulting in a failure to effectively address complex problems. Therefore, we introduce MetaGPT, an innovative framework that incorporates efficient human workflows as a meta programming approach into LLM-based multi-agent collaboration. Specifically, MetaGPT encodes Standardized Operating Procedures (SOPs) into prompts to enhance structured coordination. Subsequently, it mandates modular outputs, empowering agents with domain expertise comparable to human professionals, to validate outputs and minimize compounded errors. In this way, MetaGPT leverages the assembly line paradigm to assign diverse roles to various agents, thereby establishing a framework that can effectively and cohesively deconstruct complex multi-agent collaborative problems. Our experiments on collaborative software engineering benchmarks demonstrate that MetaGPT generates more coherent and correct solutions compared to existing chat-based multi-agent systems. This highlights the potential of integrating human domain knowledge into multi-agent systems, thereby creating new opportunities to tackle complex real-world challenges. The GitHub repository of this project is publicly available on:https://github.com/geekan/MetaGPT.
</details>
<details>
<summary>摘要</summary>
最近，在多代理驱动大语言模型（LLM）的情况下，自动任务解决得到了非常出色的进步。然而，现有的LLM基于多代理工作主要集中于解决简单对话任务，复杂任务则rarely studied，主要是因为LLM幻觉问题。这种幻觉会在不经过严格的验证和约束的情况下，继续层层传递，导致复杂问题的解决不具有效果。因此，我们提出了MetaGPT框架，它将人工流程作为多代理协作的meta编程方法。具体来说，MetaGPT将标准化的操作 процедуures（SOPs）编码成提示，以提高结构化协作。然后，它要求机器人输出具有域专业知识的Module输出，以验证输出并减少相加的错误。通过这种方式，MetaGPT利用了生产线模式，将不同的代理分配给不同的机器人，以建立一个可以有效和凝合地解决复杂多代理协作问题的框架。我们对协同软件工程标准准测试数据进行了实验，并证明MetaGPT可以生成更凝合和正确的解决方案，比现有的协同多代理系统更好。这表明了将人类域知识integrated into多代理系统的潜在价值，以创造新的机会来解决复杂的现实世界挑战。MetaGPT项目的GitHub存储库可以在以下链接中找到：https://github.com/geekan/MetaGPT。
</details></li>
</ul>
<hr>
<h2 id="Learning-Green’s-Function-Efficiently-Using-Low-Rank-Approximations"><a href="#Learning-Green’s-Function-Efficiently-Using-Low-Rank-Approximations" class="headerlink" title="Learning Green’s Function Efficiently Using Low-Rank Approximations"></a>Learning Green’s Function Efficiently Using Low-Rank Approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00350">http://arxiv.org/abs/2308.00350</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kishanwn/decgreennet">https://github.com/kishanwn/decgreennet</a></li>
<li>paper_authors: Kishan Wimalawarne, Taiji Suzuki, Sophie Langer</li>
<li>for: 用深度学习模型解决不同类型的partial differential equations</li>
<li>methods: 使用低级别分解学习绿函数，避免重复 computationally expensive Monte-Carlo integral approximations</li>
<li>results: 提高计算时间，与PINNs和MOD-Net相当准确，但减少计算量<details>
<summary>Abstract</summary>
Learning the Green's function using deep learning models enables to solve different classes of partial differential equations. A practical limitation of using deep learning for the Green's function is the repeated computationally expensive Monte-Carlo integral approximations. We propose to learn the Green's function by low-rank decomposition, which results in a novel architecture to remove redundant computations by separate learning with domain data for evaluation and Monte-Carlo samples for integral approximation. Using experiments we show that the proposed method improves computational time compared to MOD-Net while achieving comparable accuracy compared to both PINNs and MOD-Net.
</details>
<details>
<summary>摘要</summary>
使用深度学习模型学习绿函数可以解决不同类型的partial differential equations。但是使用深度学习 для绿函数受到重复计算成本高的Monte-Carlo积分approximation的限制。我们提议通过低级别分解来学习绿函数，这导致了一种新的架构，可以通过预测和Monte-Carlo样本进行独立学习和积分近似。通过实验，我们发现提议的方法可以比MOD-Net减少计算时间，同时与PINNs和MOD-Net的准确率相似。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-ensemble-selection-based-on-Deep-Neural-Network-Uncertainty-Estimation-for-Adversarial-Robustness"><a href="#Dynamic-ensemble-selection-based-on-Deep-Neural-Network-Uncertainty-Estimation-for-Adversarial-Robustness" class="headerlink" title="Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness"></a>Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00346">http://arxiv.org/abs/2308.00346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruoxi Qin, Linyuan Wang, Xuehui Du, Xingyuan Chen, Bin Yan</li>
<li>for: 提高模型对抗性和稳定性</li>
<li>methods: 动态ensemble选择技术， Dirichlet分布和多模型多态性</li>
<li>results: 无需损害准确率，提高了模型对抗性和稳定性<details>
<summary>Abstract</summary>
The deep neural network has attained significant efficiency in image recognition. However, it has vulnerable recognition robustness under extensive data uncertainty in practical applications. The uncertainty is attributed to the inevitable ambient noise and, more importantly, the possible adversarial attack. Dynamic methods can effectively improve the defense initiative in the arms race of attack and defense of adversarial examples. Different from the previous dynamic method depend on input or decision, this work explore the dynamic attributes in model level through dynamic ensemble selection technology to further protect the model from white-box attacks and improve the robustness. Specifically, in training phase the Dirichlet distribution is apply as prior of sub-models' predictive distribution, and the diversity constraint in parameter space is introduced under the lightweight sub-models to construct alternative ensembel model spaces. In test phase, the certain sub-models are dynamically selected based on their rank of uncertainty value for the final prediction to ensure the majority accurate principle in ensemble robustness and accuracy. Compared with the previous dynamic method and staic adversarial traning model, the presented approach can achieve significant robustness results without damaging accuracy by combining dynamics and diversity property.
</details>
<details>
<summary>摘要</summary>
深度神经网络在图像识别方面已经达到了显著的效率。然而，它在实际应用中面临着广泛的数据不确定性，这种不确定性来自于不可避免的环境噪音以及可能的敌意攻击。动态方法可以有效地提高模型的防御机制，在攻击者和防御者之间的战争中，动态方法可以帮助模型更好地应对敌意攻击。在这个工作中，我们explore了模型层次的动态特性，通过动态ensemble选择技术来进一步保护模型免受白盒攻击，提高模型的 Robustness。在训练阶段，我们使用Dirichlet分布作为子模型预测分布的先验，并在轻量级子模型中引入多样性约束来构建多个可 ensemble模型空间。在测试阶段，我们 dynamically选择一些最高的uncertainty值来确定最终预测的子模型，以保证ensemble robustness和准确性的多数原则。与过去的动态方法和静态敌意训练模型相比，我们的方法可以无需损害准确性的情况下获得显著的Robustness。通过结合动态和多样性特性，我们的方法可以提供更好的防御机制，使得模型在实际应用中更加可靠。
</details></li>
</ul>
<hr>
<h2 id="Kidnapping-Deep-Learning-based-Multirotors-using-Optimized-Flying-Adversarial-Patches"><a href="#Kidnapping-Deep-Learning-based-Multirotors-using-Optimized-Flying-Adversarial-Patches" class="headerlink" title="Kidnapping Deep Learning-based Multirotors using Optimized Flying Adversarial Patches"></a>Kidnapping Deep Learning-based Multirotors using Optimized Flying Adversarial Patches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00344">http://arxiv.org/abs/2308.00344</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imrclab/flying_adversarial_patch">https://github.com/imrclab/flying_adversarial_patch</a></li>
<li>paper_authors: Pia Hanfeld, Khaled Wahba, Marina M. -C. Höhne, Michael Bussmann, Wolfgang Hönig</li>
<li>for: 这 paper 是关于 autonomous flying robots 的 deep learning 模型如何受到攻击的研究。</li>
<li>methods: 这 paper 使用了多种攻击方法，包括 computed adversarial patches 和 novel attack policy。</li>
<li>results: 这 paper 的结果表明，使用这些攻击方法可以 manipulate  autonomous flying robots 的 neural network 预测，并且可以在Physical flights 中实现 robot 的 kidnapping。Here’s the full translation in Simplified Chinese:</li>
<li>for: 这 paper 是关于 autonomous flying robots 的 deep learning 模型如何受到攻击的研究。</li>
<li>methods: 这 paper 使用了多种攻击方法，包括 computed adversarial patches 和 novel attack policy。</li>
<li>results: 这 paper 的结果表明，使用这些攻击方法可以 manipulate  autonomous flying robots 的 neural network 预测，并且可以在Physical flights 中实现 robot 的 kidnapping。I hope that helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Autonomous flying robots, such as multirotors, often rely on deep learning models that makes predictions based on a camera image, e.g. for pose estimation. These models can predict surprising results if applied to input images outside the training domain. This fault can be exploited by adversarial attacks, for example, by computing small images, so-called adversarial patches, that can be placed in the environment to manipulate the neural network's prediction. We introduce flying adversarial patches, where multiple images are mounted on at least one other flying robot and therefore can be placed anywhere in the field of view of a victim multirotor. By introducing the attacker robots, the system is extended to an adversarial multi-robot system. For an effective attack, we compare three methods that simultaneously optimize multiple adversarial patches and their position in the input image. We show that our methods scale well with the number of adversarial patches. Moreover, we demonstrate physical flights with two robots, where we employ a novel attack policy that uses the computed adversarial patches to kidnap a robot that was supposed to follow a human.
</details>
<details>
<summary>摘要</summary>
自主飞行机器人，如多Rotor，常用深度学习模型，以图像为输入，例如pose estimation。这些模型可能会出现意外的结果，如果应用于输入图像外的训练领域。这种错误可以被恶意攻击，例如计算小图像，称为恶意补丁，并将其置入环境中，以操纵神经网络的预测。我们引入飞行恶意补丁，其中至少有一个飞行机器人携带多个图像，因此可以在犯罪者多rotor的视场中随意地放置。通过引入攻击机器人，系统变成了一个敌对多机器人系统。为实现攻击，我们比较了三种方法，同时优化多个恶意补丁和其位置在输入图像中。我们发现我们的方法可以很好地扩展到多个恶意补丁。此外，我们还实现了实际的飞行试验，使用计算出来的恶意补丁，将一个预定要跟随人类的机器人绑架。
</details></li>
</ul>
<hr>
<h2 id="Monitoring-Algorithmic-Fairness-under-Partial-Observations"><a href="#Monitoring-Algorithmic-Fairness-under-Partial-Observations" class="headerlink" title="Monitoring Algorithmic Fairness under Partial Observations"></a>Monitoring Algorithmic Fairness under Partial Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00341">http://arxiv.org/abs/2308.00341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas A. Henzinger, Konstantin Kueffner, Kaushik Mallik</li>
<li>for: 这篇论文目的是监控 deployed 系统的algorithmic fairness，以 guaranteee that AI和机器学习软件在做出决策时保持公正和无偏见。</li>
<li>methods: 这篇论文使用 runtime verification techniques，可以在 deployed 系统上监控algorithmic fairness。这些监控技术假设系统的全 observability，并且只能监控已经指定的公正性特性，即 arithmetic expressions over the probabilities of different events。</li>
<li>results: 这篇论文延伸了 fairness monitoring 到 partially observed Markov chains (POMC) 和 specifications containing arithmetic expressions over the expected values of numerical functions on event sequences。这篇论文可以在这些系统上监控algorithmic fairness，并且可以在一个执行的系统上监控整个分布中的公正性。<details>
<summary>Abstract</summary>
As AI and machine-learned software are used increasingly for making decisions that affect humans, it is imperative that they remain fair and unbiased in their decisions. To complement design-time bias mitigation measures, runtime verification techniques have been introduced recently to monitor the algorithmic fairness of deployed systems. Previous monitoring techniques assume full observability of the states of the (unknown) monitored system. Moreover, they can monitor only fairness properties that are specified as arithmetic expressions over the probabilities of different events. In this work, we extend fairness monitoring to systems modeled as partially observed Markov chains (POMC), and to specifications containing arithmetic expressions over the expected values of numerical functions on event sequences. The only assumptions we make are that the underlying POMC is aperiodic and starts in the stationary distribution, with a bound on its mixing time being known. These assumptions enable us to estimate a given property for the entire distribution of possible executions of the monitored POMC, by observing only a single execution. Our monitors observe a long run of the system and, after each new observation, output updated PAC-estimates of how fair or biased the system is. The monitors are computationally lightweight and, using a prototype implementation, we demonstrate their effectiveness on several real-world examples.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Target-Search-and-Navigation-in-Heterogeneous-Robot-Systems-with-Deep-Reinforcement-Learning"><a href="#Target-Search-and-Navigation-in-Heterogeneous-Robot-Systems-with-Deep-Reinforcement-Learning" class="headerlink" title="Target Search and Navigation in Heterogeneous Robot Systems with Deep Reinforcement Learning"></a>Target Search and Navigation in Heterogeneous Robot Systems with Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00331">http://arxiv.org/abs/2308.00331</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Chen, Jiaping Xiao</li>
<li>for: 这篇论文是为了探索和搜寻任务中的合作多元机器人系统，以提高效率。</li>
<li>methods: 这篇论文使用深度强化学习算法来教育策略，并导入多阶段强化学习框架和curiosity模组，以增强代理人对无 visited 环境的探索。</li>
<li>results: 在模拟环境中的实验显示，我们的框架可以将多元机器人系统训练到 unknown 目标位置的搜寻和NAVIGATION，而exist的基准不能实现，且加速训练速度。<details>
<summary>Abstract</summary>
Collaborative heterogeneous robot systems can greatly improve the efficiency of target search and navigation tasks. In this paper, we design a heterogeneous robot system consisting of a UAV and a UGV for search and rescue missions in unknown environments. The system is able to search for targets and navigate to them in a maze-like mine environment with the policies learned through deep reinforcement learning algorithms. During the training process, if two robots are trained simultaneously, the rewards related to their collaboration may not be properly obtained. Hence, we introduce a multi-stage reinforcement learning framework and a curiosity module to encourage agents to explore unvisited environments. Experiments in simulation environments show that our framework can train the heterogeneous robot system to achieve the search and navigation with unknown target locations while existing baselines may not, and accelerate the training speed.
</details>
<details>
<summary>摘要</summary>
将文本翻译成简化中文。<</SYS>>合作多种机器人系统可以大幅提高目标搜寻和导航任务的效率。在这篇论文中，我们设计了一个多种机器人系统，包括一架UAV和一架UGV，用于搜寻和救援任务在未知环境中。系统可以在封闭的矿山环境中搜寻目标并导航到它们，通过深度强化学习算法学习的策略。在训练过程中，如果两个机器人同时训练，关于他们之间的合作的奖励可能不会正确获得。因此，我们提出了多stage强化学习框架和curiosity模块，以促使代理人探索未曾访问的环境。在模拟环境中的实验表明，我们的框架可以训练多种机器人系统，在目标位置未知的情况下实现搜寻和导航，而现有的基线可能无法达成，并且加速训练速度。
</details></li>
</ul>
<hr>
<h2 id="Threshold-aware-Learning-to-Generate-Feasible-Solutions-for-Mixed-Integer-Programs"><a href="#Threshold-aware-Learning-to-Generate-Feasible-Solutions-for-Mixed-Integer-Programs" class="headerlink" title="Threshold-aware Learning to Generate Feasible Solutions for Mixed Integer Programs"></a>Threshold-aware Learning to Generate Feasible Solutions for Mixed Integer Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00327">http://arxiv.org/abs/2308.00327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taehyun Yoon, Jinwon Choi, Hyokun Yun, Sungbin Lim</li>
<li>for: 寻找一个高质量可行的解决方案，以应对 combinatorial optimization（CO）问题，并在有限时间内完成。</li>
<li>methods: 使用 Neural Diving（ND）方法，一种基于机器学习的方法，以生成混合整数程式中的部分零値变量分配。</li>
<li>results: 透过优化覆盖范围，实现将 machine learning 和整数程式的目标更加接近，并且透过内置学习来实现更好的性能。实验结果显示，使用深度神经网估算覆盖可以实现最佳性能，并且在 NeurIPS ML4CO 数据集上表现出色，特别是在工作负载分配数据集上，实现了最佳性能，优化差值为 0.45%，与 SCIP 相比，提高了十倍。<details>
<summary>Abstract</summary>
Finding a high-quality feasible solution to a combinatorial optimization (CO) problem in a limited time is challenging due to its discrete nature. Recently, there has been an increasing number of machine learning (ML) methods for addressing CO problems. Neural diving (ND) is one of the learning-based approaches to generating partial discrete variable assignments in Mixed Integer Programs (MIP), a framework for modeling CO problems. However, a major drawback of ND is a large discrepancy between the ML and MIP objectives, i.e., variable value classification accuracy over primal bound. Our study investigates that a specific range of variable assignment rates (coverage) yields high-quality feasible solutions, where we suggest optimizing the coverage bridges the gap between the learning and MIP objectives. Consequently, we introduce a post-hoc method and a learning-based approach for optimizing the coverage. A key idea of our approach is to jointly learn to restrict the coverage search space and to predict the coverage in the learned search space. Experimental results demonstrate that learning a deep neural network to estimate the coverage for finding high-quality feasible solutions achieves state-of-the-art performance in NeurIPS ML4CO datasets. In particular, our method shows outstanding performance in the workload apportionment dataset, achieving the optimality gap of 0.45%, a ten-fold improvement over SCIP within the one-minute time limit.
</details>
<details>
<summary>摘要</summary>
寻找一个高质量可行的解决方案 для combinatorial optimization（CO）问题在有限时间内是挑战的，因为它的特点是离散的。在最近，机器学习（ML）方法在Addressing CO problems的问题上增加了。Neural diving（ND）是一种学习基于方法，用于在混合整数程序（MIP）中生成部分离散变量分配。然而，ND的一个主要缺点是ML和MIP目标之间的差距，即变量值分类准确率 над primal bound。我们的研究发现，在特定的变量分配率（coverage）范围内，可以获得高质量可行的解决方案，我们建议优化coverage来跨越这两个目标之间的差距。因此，我们引入了一种后续方法和一种学习基于的方法来优化coverage。我们的方法的关键思想是同时学习限制coverage搜索空间和预测coverage在学习的搜索空间中。实验结果表明，通过学习深度神经网络来估计coverage以找到高质量可行的解决方案，可以在NeurIPS ML4CO数据集中实现状态计算机科学技术最佳性能。尤其是在分配工作量数据集中，我们的方法实现了0.45%的优化率，胜过SCIP在一分钟时限内的十倍提高。
</details></li>
</ul>
<hr>
<h2 id="Choir-Transformer-Generating-Polyphonic-Music-with-Relative-Attention-on-Transformer"><a href="#Choir-Transformer-Generating-Polyphonic-Music-with-Relative-Attention-on-Transformer" class="headerlink" title="Choir Transformer: Generating Polyphonic Music with Relative Attention on Transformer"></a>Choir Transformer: Generating Polyphonic Music with Relative Attention on Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02531">http://arxiv.org/abs/2308.02531</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuyang Zhou, Hong Zhu, Xingping Wang</li>
<li>for: 这个论文的目的是提出一种基于Transformer的多VOICE音乐生成模型，以便更好地模型音乐的结构和关系。</li>
<li>methods: 这个模型使用了相对位置注意力来更好地模型长距离音符之间的关系，并提出了一种适合多VOICE音乐生成的音乐表示方式。</li>
<li>results: 实验表明，这个模型的性能超过了之前的最佳值4.06%，并且可以根据输入进行不同的风格化音乐生成。<details>
<summary>Abstract</summary>
Polyphonic music generation is still a challenge direction due to its correct between generating melody and harmony. Most of the previous studies used RNN-based models. However, the RNN-based models are hard to establish the relationship between long-distance notes. In this paper, we propose a polyphonic music generation neural network named Choir Transformer[ https://github.com/Zjy0401/choir-transformer], with relative positional attention to better model the structure of music. We also proposed a music representation suitable for polyphonic music generation. The performance of Choir Transformer surpasses the previous state-of-the-art accuracy of 4.06%. We also measures the harmony metrics of polyphonic music. Experiments show that the harmony metrics are close to the music of Bach. In practical application, the generated melody and rhythm can be adjusted according to the specified input, with different styles of music like folk music or pop music and so on.
</details>
<details>
<summary>摘要</summary>
<<SYS>> traduced the text into Simplified Chinese.<</SYS>>复音乐生成仍然是一个挑战方向，因为它们需要正确地生成旋律和和谐。大多数前一代的研究使用RNN型模型。然而，RNN型模型对于距离较长的当地谱进行建立关系困难。在这篇论文中，我们提出了一个复音乐生成神经网络名为Choir Transformer[https://github.com/Zjy0401/choir-transformer]，具有相对位置注意力以更好地模型音乐结构。我们还提出了适合复音乐生成的音乐表示。Choir Transformer的表现超过了过去的州立准确率4.06%。我们还测量了复音乐中的和谐指标，实验结果显示和谐指标与巴赫的音乐很相似。在实际应用中，生成的旋律和节奏可以根据输入的特定要求进行调整，包括不同的音乐风格，如民族音乐或流行音乐等。
</details></li>
</ul>
<hr>
<h2 id="Pixel-to-policy-DQN-Encoders-for-within-cross-game-reinforcement-learning"><a href="#Pixel-to-policy-DQN-Encoders-for-within-cross-game-reinforcement-learning" class="headerlink" title="Pixel to policy: DQN Encoders for within &amp; cross-game reinforcement learning"></a>Pixel to policy: DQN Encoders for within &amp; cross-game reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00318">http://arxiv.org/abs/2308.00318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashrya Agrawal, Priyanshi Shah, Sourabh Prakash</li>
<li>for: 本研究探讨了基于增强学习的游戏撸抓机器人的开发，以及如何通过知识转移来提高RL性能。</li>
<li>methods: 本研究使用了基于深度强化学习的DQN模型，并在不同的游戏环境中进行了训练。同时，研究还 comparing了从头开始训练和知识转移的RL模型，以及使用多个游戏环境训练一个通用游戏撸抓机器人的方法。</li>
<li>results: 研究结果显示，使用知识转移的DQN模型可以在不同的游戏环境中达到优秀的性能，其中 mean episode reward 为 46.16，even 超过了人类水平的表现。此外，在 Assault 和 Space Invader 环境中，模型的 achieved mean rewards 分别为 533.42 和 402.17，表现非常出色。<details>
<summary>Abstract</summary>
Reinforcement Learning can be applied to various tasks, and environments. Many of these environments have a similar shared structure, which can be exploited to improve RL performance on other tasks. Transfer learning can be used to take advantage of this shared structure, by learning policies that are transferable across different tasks and environments and can lead to more efficient learning as well as improved performance on a wide range of tasks. This work explores as well as compares the performance between RL models being trained from the scratch and on different approaches of transfer learning. Additionally, the study explores the performance of a model trained on multiple game environments, with the goal of developing a universal game-playing agent as well as transfer learning a pre-trained encoder using DQN, and training it on the same game or a different game. Our DQN model achieves a mean episode reward of 46.16 which even beats the human-level performance with merely 20k episodes which is significantly lower than deepmind's 1M episodes. The achieved mean rewards of 533.42 and 402.17 on the Assault and Space Invader environments respectively, represent noteworthy performance on these challenging environments.
</details>
<details>
<summary>摘要</summary>
� Reinforcement Learning 可以应用于多种任务和环境中。许多这些环境具有相似的共享结构，可以利用这些共享结构来提高RL性能。传输学习可以利用这些共享结构，学习可以在不同任务和环境中传输的策略，从而导致更高效的学习以及多种任务的改进表现。本研究探讨了RL模型从零开始学习和不同的传输学习方法的比较性能，同时还研究了使用多个游戏环境训练的模型，以达到开发通用游戏玩家代理以及传输学习预训练的DQN模型的目的。我们的DQN模型在46.16 episodes中获得了平均回合奖励，这even exceeds human-level performance，只需20k episodes，与深入的1M episodes相比，这是显著的提高。在Assault和Space Invader环境中，我们获得的平均奖励为533.42和402.17，这表示在这些复杂的环境中的出色表现。
</details></li>
</ul>
<hr>
<h2 id="Revolutionizing-TCAD-Simulations-with-Universal-Device-Encoding-and-Graph-Attention-Networks"><a href="#Revolutionizing-TCAD-Simulations-with-Universal-Device-Encoding-and-Graph-Attention-Networks" class="headerlink" title="Revolutionizing TCAD Simulations with Universal Device Encoding and Graph Attention Networks"></a>Revolutionizing TCAD Simulations with Universal Device Encoding and Graph Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11624">http://arxiv.org/abs/2308.11624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangxi Fan, Kain Lu Low</li>
<li>for: 这篇论文的目的是提出一种基于人工智能（AI）和图表表示法的TCAD设备模拟中的设备编码方法。</li>
<li>methods: 该方法使用图表基本编码方案，考虑材料层和设备层嵌入，同时还引入了一种新的空间关系嵌入， inspirited by interpolate操作通常用于finite element分 meshing。</li>
<li>results: 该方法可以实现全面的数据驱动模拟，包括surrogate Poisson伪 simulate和current-voltage（IV）预测基于漂移扩散模型，使用一种新的图注意力网络，称为RelGAT。<details>
<summary>Abstract</summary>
An innovative methodology that leverages artificial intelligence (AI) and graph representation for semiconductor device encoding in TCAD device simulation is proposed. A graph-based universal encoding scheme is presented that not only considers material-level and device-level embeddings, but also introduces a novel spatial relationship embedding inspired by interpolation operations typically used in finite element meshing. Universal physical laws from device simulations are leveraged for comprehensive data-driven modeling, which encompasses surrogate Poisson emulation and current-voltage (IV) prediction based on drift-diffusion model. Both are achieved using a novel graph attention network, referred to as RelGAT. Comprehensive technical details based on the device simulator Sentaurus TCAD are presented, empowering researchers to adopt the proposed AI-driven Electronic Design Automation (EDA) solution at the device level.
</details>
<details>
<summary>摘要</summary>
一种创新的方法ология，利用人工智能（AI）和图表示法来实现半导体设备编码在TCAD设备仿真中，被提议。这种图基本 універсаル编码方案不仅考虑材料层和设备层嵌入，还引入了一种新的空间关系嵌入，取得自 interpolate 操作通常用于finite element meshing。这种新的空间关系嵌入可以帮助更好地捕捉设备的物理特性。此外，通过利用设备仿真中的物理法律，实现了全面的数据驱动模拟，包括surrogate Poisson 伪 simulate和current-voltage（IV）预测，基于漫步-扩散模型。这些技术性细节基于设备仿真器Sentaurus TCAD，以便研究人员可以在设备层采用这种AI驱动的电子设计自动化（EDA）解决方案。
</details></li>
</ul>
<hr>
<h2 id="Adapt-and-Decompose-Efficient-Generalization-of-Text-to-SQL-via-Domain-Adapted-Least-To-Most-Prompting"><a href="#Adapt-and-Decompose-Efficient-Generalization-of-Text-to-SQL-via-Domain-Adapted-Least-To-Most-Prompting" class="headerlink" title="Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting"></a>Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02582">http://arxiv.org/abs/2308.02582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aseem Arora, Shabbirhussain Bhaisaheb, Harshit Nigam, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff</li>
<li>For: This paper focuses on improving the cross-domain and cross-compositional generalization of Text-to-SQL semantic parsing using a novel prompt-based approach.* Methods: The proposed method involves offline sampling of a minimal set of few-shots from the training data to synthesize a fixed Generic Prompt (GP) with complete coverage of SQL clauses, operators, and functions, and maximal domain coverage within the allowed token length. The GP is then adapted to the target database domain (DA-GP) to handle cross-domain generalization, and a decomposed Least-To-Most-Prompting (LTMP-DA-GP) is used to handle cross-compositional generalization.* Results: The proposed approach demonstrates superior performance on the KaggleDBQA dataset, designed to evaluate generalizability for the Text-to-SQL task, and shows consistent performance improvement over the baseline GP across LLMs and databases of KaggleDBQA, highlighting the efficacy and model agnostic benefits of the prompt-based adapt and decompose approach.Here is the same information in Simplified Chinese:* For: 这篇论文关注提高cross-domain和cross-compositional generalization的文本到SQL semantics解析。* Methods: 提议方法包括在训练数据集中Offline采样一个最小的几个shot，以生成一个包含全部SQL语句、运算符和函数的固定Generic Prompt (GP)，并在目标数据库领域内具有最大的领域覆盖。此外，还使用分解的Least-To-Most-Prompting (LTMP-DA-GP)来处理cross-compositional generalization。* Results: 提议方法在KaggleDBQA dataset上显示出了superior的性能，这个dataset是用来评估文本到SQL任务的通用性。此外，在不同的LLMs和数据库上，LTMP-DA-GP也显示了与GP相比的性能提高，这highlights the efficacy和model agnostic benefits of the prompt-based adapt和decomposeapproach。<details>
<summary>Abstract</summary>
Cross-domain and cross-compositional generalization of Text-to-SQL semantic parsing is a challenging task. Existing Large Language Model (LLM) based solutions rely on inference-time retrieval of few-shot exemplars from the training set to synthesize a run-time prompt for each Natural Language (NL) test query. In contrast, we devise an algorithm which performs offline sampling of a minimal set-of few-shots from the training data, with complete coverage of SQL clauses, operators and functions, and maximal domain coverage within the allowed token length. This allows for synthesis of a fixed Generic Prompt (GP), with a diverse set-of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. We further auto-adapt the GP to the target database domain (DA-GP), to better handle cross-domain generalization; followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline task, to be performed one-time per new database with minimal human intervention. Our approach demonstrates superior performance on the KaggleDBQA dataset, designed to evaluate generalizability for the Text-to-SQL task. We further showcase consistent performance improvement of LTMP-DA-GP over GP, across LLMs and databases of KaggleDBQA, highlighting the efficacy and model agnostic benefits of our prompt based adapt and decompose approach.
</details>
<details>
<summary>摘要</summary>
横跨域和构成层次的文本到SQL semantics解析是一个具有挑战性的任务。现有的大型自然语言模型（LLM）基本解决方案采用在执行时从训练集中检索一些几个示例来生成每个自然语言（NL）测试查询的时间。相比之下，我们提出了一个算法，它在线上采样了训练数据中的最小集合，涵盖了SQL子句、运算符和函数，并且在允许的字符串长度内实现了最大的域覆盖。这允许我们生成一个固定的生成器提示（GP），其中包含一个多样化的示例集，通用于NL测试查询，以避免高昂的测试时间示例检索。我们进一步自动适应了GP到目标数据库域（DA-GP），以更好地处理跨域泛化；并使用分解的最小到最多提示（LTMP-DA-GP）来处理跨组件泛化。这个synthesis任务是一个离线任务，需要在新的数据库添加时进行一次性的少量人工干预。我们的方法在KaggleDBQA数据集上表现出色，并且在LLMs和数据库之间 consistently 表现出 GP 和 LTMP-DA-GP 之间的性能改进，这 highlights 了我们的提示基于适应和分解方法的效果和模型免疫性。
</details></li>
</ul>
<hr>
<h2 id="Making-the-V-in-Text-VQA-Matter"><a href="#Making-the-V-in-Text-VQA-Matter" class="headerlink" title="Making the V in Text-VQA Matter"></a>Making the V in Text-VQA Matter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00295">http://arxiv.org/abs/2308.00295</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamanthak Hegde, Soumya Jahagirdar, Shankar Gangisetty</li>
<li>for: 提高文本检查问题（Text-based VQA）的答案质量，解决图像文本关系理解不足问题。</li>
<li>methods: 利用VQA数据集作为外部知识，学习图像特征和文本特征之间的关系，提高文本检查问题的答案质量。</li>
<li>results: 通过组合TextVQA数据集和VQA数据集，提高文本检查问题的答案质量，并在不同数据集上进行质量评估和比较。<details>
<summary>Abstract</summary>
Text-based VQA aims at answering questions by reading the text present in the images. It requires a large amount of scene-text relationship understanding compared to the VQA task. Recent studies have shown that the question-answer pairs in the dataset are more focused on the text present in the image but less importance is given to visual features and some questions do not require understanding the image. The models trained on this dataset predict biased answers due to the lack of understanding of visual context. For example, in questions like "What is written on the signboard?", the answer predicted by the model is always "STOP" which makes the model to ignore the image. To address these issues, we propose a method to learn visual features (making V matter in TextVQA) along with the OCR features and question features using VQA dataset as external knowledge for Text-based VQA. Specifically, we combine the TextVQA dataset and VQA dataset and train the model on this combined dataset. Such a simple, yet effective approach increases the understanding and correlation between the image features and text present in the image, which helps in the better answering of questions. We further test the model on different datasets and compare their qualitative and quantitative results.
</details>
<details>
<summary>摘要</summary>
文本基于VQA目标解答问题，通过阅读图像中的文本来回答问题。与普通的VQA任务相比，这种任务需要更多的场景文本关系理解。现有研究表明，数据集中的问题对应答案更加注重图像中的文本，而视觉特征相对较少，一些问题甚至不需要理解图像。因此，模型在这些数据集上训练时会预测偏向的答案，如果只凭文本内容，则忽略图像。为了解决这些问题，我们提议一种方法，通过与VQA数据集的 externos知识来学习图像特征（使V在TextVQA中变得重要），同时学习文本和问题特征。具体来说，我们将TextVQA数据集和VQA数据集组合在一起，并将模型在这个组合数据集上训练。这种简单而有效的方法可以增加图像特征和文本中的关系，从而帮助模型更好地回答问题。我们还对不同的数据集进行测试，并比较其质量和量化结果。
</details></li>
</ul>
<hr>
<h2 id="Gated-Driver-Attention-Predictor"><a href="#Gated-Driver-Attention-Predictor" class="headerlink" title="Gated Driver Attention Predictor"></a>Gated Driver Attention Predictor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02530">http://arxiv.org/abs/2308.02530</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jwfangit/gate-dap">https://github.com/jwfangit/gate-dap</a></li>
<li>paper_authors: Tianci Zhao, Xue Bai, Jianwu Fang, Jianru Xue</li>
<li>for: 预测司机注意力，以提高驾驶任务理解和安全预测。</li>
<li>methods: 使用网络连接闭合机制，学习不同空间、时间和信息类型在驾驶场景中的重要性。</li>
<li>results: 在DADA-2000和BDDA数据集上证明提出方法的优越性，与现有方法进行比较。<details>
<summary>Abstract</summary>
Driver attention prediction implies the intention understanding of where the driver intends to go and what object the driver concerned about, which commonly provides a driving task-guided traffic scene understanding. Some recent works explore driver attention prediction in critical or accident scenarios and find a positive role in helping accident prediction, while the promotion ability is constrained by the prediction accuracy of driver attention maps. In this work, we explore the network connection gating mechanism for driver attention prediction (Gate-DAP). Gate-DAP aims to learn the importance of different spatial, temporal, and modality information in driving scenarios with various road types, occasions, and light and weather conditions. The network connection gating in Gate-DAP consists of a spatial encoding network gating, long-short-term memory network gating, and information type gating modules. Each connection gating operation is plug-and-play and can be flexibly assembled, which makes the architecture of Gate-DAP transparent for evaluating different spatial, temporal, and information types for driver attention prediction. Evaluations on DADA-2000 and BDDA datasets verify the superiority of the proposed method with the comparison with state-of-the-art approaches. The code is available on https://github.com/JWFangit/Gate-DAP.
</details>
<details>
<summary>摘要</summary>
driver attention prediction 表示司机的意图理解，包括他们想要去哪里和关注哪些对象，通常提供了驾驶任务指导的交通场景理解。一些最近的工作研究了在关键或事故情况下的司机注意力预测，并发现它可以帮助预测事故，但是预测精度的限制了推广能力。在这种情况下，我们研究了网络连接锁定机制 для司机注意力预测（Gate-DAP）。Gate-DAP的目标是在不同的道路类型、场合、照明和天气条件下学习不同的空间、时间和类型信息在驾驶场景中的重要性。Gate-DAP网络连接锁定包括空间编码网络锁定、长短时间记忆网络锁定和信息类型锁定模块。每个连接锁定操作都是可拔取的，可以灵活组合，这使得Gate-DAP的架构可以透明地评估不同的空间、时间和信息类型在司机注意力预测中的重要性。评估于DADA-2000和BDDA数据集 verify了我们提出的方法的优越性，与现有方法进行比较。代码可以在https://github.com/JWFangit/Gate-DAP中找到。
</details></li>
</ul>
<hr>
<h2 id="Multi-Modality-Multi-Loss-Fusion-Network"><a href="#Multi-Modality-Multi-Loss-Fusion-Network" class="headerlink" title="Multi-Modality Multi-Loss Fusion Network"></a>Multi-Modality Multi-Loss Fusion Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00264">http://arxiv.org/abs/2308.00264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zehui Wu, Ziwei Gong, Jaywon Koo, Julia Hirschberg</li>
<li>for: 本研究探讨了多模态特征选择和融合的优化方法，以提高情感识别。</li>
<li>methods: 研究使用了不同的融合方法，并对多模态融合网络中的多产业训练进行研究，发现了有用的发现 relate to subnet performance。</li>
<li>results: 我们的最佳模型在三个 dataset（CMU-MOSI、CMU-MOSEI 和 CH-SIMS）上 achieve state-of-the-art performance，并在大多数指标上超过其他方法。我们发现，在多模态特征上进行训练可以提高单模态测试，并基于数据Annotation schema设计融合方法可以提高模型性能。这些结果表明了一种优化特征选择和融合方法的路线图，以提高情感识别在神经网络中的性能。<details>
<summary>Abstract</summary>
In this work we investigate the optimal selection and fusion of features across multiple modalities and combine these in a neural network to improve emotion detection. We compare different fusion methods and examine the impact of multi-loss training within the multi-modality fusion network, identifying useful findings relating to subnet performance. Our best model achieves state-of-the-art performance for three datasets (CMU-MOSI, CMU-MOSEI and CH-SIMS), and outperforms the other methods in most metrics. We have found that training on multimodal features improves single modality testing and designing fusion methods based on dataset annotation schema enhances model performance. These results suggest a roadmap towards an optimized feature selection and fusion approach for enhancing emotion detection in neural networks.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们研究了多modalities之间的最佳选择和融合，并将其 integrate into a neural network to improve emotion detection。我们比较了不同的融合方法，并研究在多模态融合网络中的多loss训练的影响，发现了有用的发现关于子网络性能。我们的最佳模型在三个 datasets（CMU-MOSI、CMU-MOSEI 和 CH-SIMS）上达到了状态部署性能，并在大多数指标上超过了其他方法。我们发现，训练在多模态特征上提高了单模态测试，而基于数据集注释 schema 设计的融合方法可以提高模型性能。这些结果表明了一种优化特征选择和融合方法的道路，以提高神经网络中的情感检测。
</details></li>
</ul>
<hr>
<h2 id="LGViT-Dynamic-Early-Exiting-for-Accelerating-Vision-Transformer"><a href="#LGViT-Dynamic-Early-Exiting-for-Accelerating-Vision-Transformer" class="headerlink" title="LGViT: Dynamic Early Exiting for Accelerating Vision Transformer"></a>LGViT: Dynamic Early Exiting for Accelerating Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00255">http://arxiv.org/abs/2308.00255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanyu Xu, Jiawei Hao, Li Shen, Han Hu, Yong Luo, Hui Lin, Jialie Shen</li>
<li>for: 这个论文的目的是提高资源有限的边缘设备上的视Transformers（ViTs）的部署和加速，以提供多媒体服务。</li>
<li>methods: 这篇论文使用了早期离开方法来加速推理，但是这些方法通常只适用于卷积神经网络（CNNs）和自然语言处理（NLP）领域中的模型。作者们系统地研究了在ViTs中使用早期离开方法的有效性，并发现了这些方法的缺点，例如内部分类器的不充分表示和深度内部分类器的限制。</li>
<li>results: 作者们提出了一个名为LGViT的早期离开框架，该框架包括多种类型的离开头，以实现效率和准确性之间的负荷。作者们还提出了一种两阶段训练方案，包括终端到终端训练和自我顾问，以便将全局和本地信息拼接在一起。实验结果表明，LGViT可以与约1.8倍的速度实现竞争性的性能。<details>
<summary>Abstract</summary>
Recently, the efficient deployment and acceleration of powerful vision transformers (ViTs) on resource-limited edge devices for providing multimedia services have become attractive tasks. Although early exiting is a feasible solution for accelerating inference, most works focus on convolutional neural networks (CNNs) and transformer models in natural language processing (NLP).Moreover, the direct application of early exiting methods to ViTs may result in substantial performance degradation. To tackle this challenge, we systematically investigate the efficacy of early exiting in ViTs and point out that the insufficient feature representations in shallow internal classifiers and the limited ability to capture target semantic information in deep internal classifiers restrict the performance of these methods. We then propose an early exiting framework for general ViTs termed LGViT, which incorporates heterogeneous exiting heads, namely, local perception head and global aggregation head, to achieve an efficiency-accuracy trade-off. In particular, we develop a novel two-stage training scheme, including end-to-end training and self-distillation with the backbone frozen to generate early exiting ViTs, which facilitates the fusion of global and local information extracted by the two types of heads. We conduct extensive experiments using three popular ViT backbones on three vision datasets. Results demonstrate that our LGViT can achieve competitive performance with approximately 1.8 $\times$ speed-up.
</details>
<details>
<summary>摘要</summary>
最近，用于提供多媒体服务的资源有限边缘设备上快速部署和加速强大视transformer（ViT）的任务已经变得非常吸引人。虽然早期离开是一种可行的解决方案，但大多数工作都集中在卷积神经网络（CNN）和自然语言处理（NLP）中。此外，直接将早期离开方法应用于ViT可能会导致显著性能下降。为解决这个挑战，我们系统地研究了ViT中早期离开的效果，并发现了内部分类器的不充分的特征表示和深度内部分类器的限制了这些方法的性能。我们 затем提出了一个通用ViT的早期离开框架，称为LGViT，该框架包括了多种exit head，包括本地感知头和全局聚合头，以实现效率准确之间的负面关系。具体来说，我们开发了一种新的两阶段训练方案，包括端到端训练和自我折衔练习，使得早期离开ViT可以同时捕捉全局和本地信息。我们在三个流行的ViT背景上进行了三个视觉数据集的广泛实验。结果表明，我们的LGViT可以实现与约1.8倍的速度提升。
</details></li>
</ul>
<hr>
<h2 id="EEG-based-Cognitive-Load-Classification-using-Feature-Masked-Autoencoding-and-Emotion-Transfer-Learning"><a href="#EEG-based-Cognitive-Load-Classification-using-Feature-Masked-Autoencoding-and-Emotion-Transfer-Learning" class="headerlink" title="EEG-based Cognitive Load Classification using Feature Masked Autoencoding and Emotion Transfer Learning"></a>EEG-based Cognitive Load Classification using Feature Masked Autoencoding and Emotion Transfer Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00246">http://arxiv.org/abs/2308.00246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dustin Pulver, Prithila Angkan, Paul Hungler, Ali Etemad</li>
<li>for: 本研究的目的是开发一个基于电enzephalogram（EEG）的认知负载分类方法。</li>
<li>methods: 本研究使用了 transformer 架构，通过将情感和认知负载的训练数据整合，以进行认知负载分类。我们首先使用了自我监督隐藏数据的泛化学习，然后使用固定重量和精致调整的转移学习来进行下游认知负载分类。</li>
<li>results: 我们的实验结果显示，我们的提议方法可以实现优异的结果，并比传统单阶充分监督学习更好。此外，我们还进行了细部拆分和敏感度研究，以评估不同方面的影响。本研究对于情感 computing 领域的成长做出了贡献，并开启了跨领域转移学习的新领域。<details>
<summary>Abstract</summary>
Cognitive load, the amount of mental effort required for task completion, plays an important role in performance and decision-making outcomes, making its classification and analysis essential in various sensitive domains. In this paper, we present a new solution for the classification of cognitive load using electroencephalogram (EEG). Our model uses a transformer architecture employing transfer learning between emotions and cognitive load. We pre-train our model using self-supervised masked autoencoding on emotion-related EEG datasets and use transfer learning with both frozen weights and fine-tuning to perform downstream cognitive load classification. To evaluate our method, we carry out a series of experiments utilizing two publicly available EEG-based emotion datasets, namely SEED and SEED-IV, for pre-training, while we use the CL-Drive dataset for downstream cognitive load classification. The results of our experiments show that our proposed approach achieves strong results and outperforms conventional single-stage fully supervised learning. Moreover, we perform detailed ablation and sensitivity studies to evaluate the impact of different aspects of our proposed solution. This research contributes to the growing body of literature in affective computing with a focus on cognitive load, and opens up new avenues for future research in the field of cross-domain transfer learning using self-supervised pre-training.
</details>
<details>
<summary>摘要</summary>
它们的诠释：词语翻译：认知负担（Cognitive Load）在完成任务和决策过程中扮演着重要的角色，因此其分类和分析变得非常重要。在这篇论文中，我们提出了一种基于电энцефалографи（EEG）的认知负担分类方法。我们的模型采用了变换器架构，并使用了移植学习来连接情感和认知负担。我们在情感相关的EEG数据集上进行自主学习的掩码自动编码预训练，然后使用冻结权重和精度调整来执行下游认知负担分类。为了评估我们的方法，我们在两个公共可用的EEG基于情感数据集上进行预训练，而用CL-Drive数据集进行下游认知负担分类。实验结果表明，我们的提议方法实现了出色的结果，并超过了传统的单阶段完全监督学习。此外，我们进行了详细的减少和敏感性研究，以评估不同方面的影响。这些研究对情感计算领域的发展做出了贡献，并开启了跨领域自动学习使用自主预训练的新途径。
</details></li>
</ul>
<hr>
<h2 id="The-Hitchhiker’s-Guide-to-Program-Analysis-A-Journey-with-Large-Language-Models"><a href="#The-Hitchhiker’s-Guide-to-Program-Analysis-A-Journey-with-Large-Language-Models" class="headerlink" title="The Hitchhiker’s Guide to Program Analysis: A Journey with Large Language Models"></a>The Hitchhiker’s Guide to Program Analysis: A Journey with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00245">http://arxiv.org/abs/2308.00245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haonan Li, Yu Hao, Yizhuo Zhai, Zhiyun Qian</li>
<li>for: This paper is written to explore the use of Large Language Models (LLMs) in assisting static analysis for identifying bugs in software systems.</li>
<li>methods: The paper proposes a fully automated agent called LLift, which interfaces with a static analysis tool and an LLM to overcome challenges in using LLMs for bug discovery.</li>
<li>results: The paper demonstrates the effectiveness of LLift in identifying potential use-before-initialization (UBI) bugs in a real-world scenario, with a high precision (50%) and recall rate (100%). Additionally, LLift identified 13 previously unknown UBI bugs in the Linux kernel.<details>
<summary>Abstract</summary>
Static analysis is a widely used technique in software engineering for identifying and mitigating bugs. However, a significant hurdle lies in achieving a delicate balance between precision and scalability. Large Language Models (LLMs) offer a promising alternative, as recent advances demonstrate remarkable capabilities in comprehending, generating, and even debugging code. Yet, the logic of bugs can be complex and require sophisticated reasoning and a large analysis scope spanning multiple functions. Therefore, at this point, LLMs are better used in an assistive role to complement static analysis. In this paper, we take a deep dive into the open space of LLM-assisted static analysis, using use-before-initialization (UBI) bugs as a case study. To this end, we develop LLift, a fully automated agent that interfaces with both a static analysis tool and an LLM. By carefully designing the agent and the prompts, we are able to overcome a number of challenges, including bug-specific modeling, the large problem scope, the non-deterministic nature of LLMs, etc. Tested in a real-world scenario analyzing nearly a thousand potential UBI bugs produced by static analysis, LLift demonstrates an extremely potent capability, showcasing a high precision (50%) and recall rate (100%). It even identified 13 previously unknown UBI bugs in the Linux kernel. This research paves the way for new opportunities and methodologies in the use of LLMs for bug discovery in extensive, real-world datasets.
</details>
<details>
<summary>摘要</summary>
Static 分析是软件工程中广泛使用的技术，用于发现和解决错误。然而，实现精准和可扩展性之间存在一定的挑战。大自然语言模型（LLM）提供了一个有前途的选择，因为最新的进步表明其在理解、生成和甚至调试代码方面具有惊人的能力。然而，错误的逻辑可能很复杂，需要卓越的推理和广泛的分析范围，因此在这点上，LLMs 更适合作为辅助工具来补充静态分析。在这篇论文中，我们深入探讨了使用 LLM 辅助静态分析的开放空间，使用 use-before-initialization（UBI）错误作为例子。为此，我们开发了 LLift，一个完全自动的代理人，它与静态分析工具和 LLM 集成。通过细心设计代理人和提示，我们成功解决了一些挑战，包括错误特定模型、大问题范围、非束定的 LLM 等。在实际场景中，LLift 对 nearly  thousand 个 UBI 错误进行了分析，显示了非常高的精度（50%）和回归率（100%）。甚至找到了 13 个前不知道的 UBI 错误在 Linux 内核中。这项研究开创了新的机遇和方法在使用 LLM 进行错误发现的大规模、真实世界数据中。
</details></li>
</ul>
<hr>
<h2 id="ChatMOF-An-Autonomous-AI-System-for-Predicting-and-Generating-Metal-Organic-Frameworks"><a href="#ChatMOF-An-Autonomous-AI-System-for-Predicting-and-Generating-Metal-Organic-Frameworks" class="headerlink" title="ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks"></a>ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01423">http://arxiv.org/abs/2308.01423</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yeonghun1675/chatmof">https://github.com/yeonghun1675/chatmof</a></li>
<li>paper_authors: Yeonghun Kang, Jihan Kim</li>
<li>for: 这个论文是为了探讨和开发一个基于自然语言处理的金属有机框架预测和生成系统（ChatMOF）。</li>
<li>methods: 该系统使用了一个大规模语言模型（gpt-3.5-turbo），从文本输入中提取关键信息并提供相应的回答，从而消除了僵化的结构化查询的需求。系统由三个核心组件（代理、工具包和评估器）组成，实现了许多任务，包括数据检索、性能预测和结构生成。</li>
<li>results: 研究发现，使用大规模语言模型AI系统在材料科学领域可以提供优秀的预测和生成功能，并且具有可观的可Transformative potential。<details>
<summary>Abstract</summary>
ChatMOF is an autonomous Artificial Intelligence (AI) system that is built to predict and generate of metal-organic frameworks (MOFs). By leveraging a large-scale language model (gpt-3.5-turbo), ChatMOF extracts key details from textual inputs and delivers appropriate responses, thus eliminating the necessity for rigid structured queries. The system is comprised of three core components (i.e. an agent, a toolkit, and an evaluator) and it forms a robust pipeline that manages a variety of tasks, including data retrieval, property prediction, and structure generation. The study further explores the merits and constraints of using large language models (LLMs) AI system in material sciences using and showcases its transformative potential for future advancements.
</details>
<details>
<summary>摘要</summary>
chatMOF是一个自主的人工智能系统，用于预测和生成金刚烷金刚烷框架（MOFs）。通过利用大规模语言模型（gpt-3.5-turbo），chatMOF从文本输入中提取关键信息并提供相应的回答，因此消除了僵化的结构化查询的需求。系统由三个核心组件（即代理、工具包和评估器）组成，形成一个完整的管道，可以处理多种任务，包括数据 retrieve、属性预测和结构生成。研究还探讨了使用大语言模型（LLMs）AI系统在材料科学中的优劣和限制，并展示了其在未来发展中的Transformative潜力。
</details></li>
</ul>
<hr>
<h2 id="Capsa-A-Unified-Framework-for-Quantifying-Risk-in-Deep-Neural-Networks"><a href="#Capsa-A-Unified-Framework-for-Quantifying-Risk-in-Deep-Neural-Networks" class="headerlink" title="Capsa: A Unified Framework for Quantifying Risk in Deep Neural Networks"></a>Capsa: A Unified Framework for Quantifying Risk in Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00231">http://arxiv.org/abs/2308.00231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadhana Lolla, Iaroslav Elistratov, Alejandro Perez, Elaheh Ahmadi, Daniela Rus, Alexander Amini</li>
<li>for: 本研究旨在提供一个扩展模型的框架，以提高深度神经网络（NN）的风险意识。</li>
<li>methods: 本研究使用的方法包括多种风险量化方法，包括 aleatoric uncertainty、epistemic uncertainty 和 bias estimation。这些方法可以独立或相互组合使用，以提供全面的风险意识。</li>
<li>results: 研究表明，使用 capsa 框架可以轻松地组合不同的风险量化方法，并在复杂的感知 datasets 上进行测试。 results 显示，capsa 框架可以提供全面的风险意识，并且可以轻松地扩展到不同的应用场景。<details>
<summary>Abstract</summary>
The modern pervasiveness of large-scale deep neural networks (NNs) is driven by their extraordinary performance on complex problems but is also plagued by their sudden, unexpected, and often catastrophic failures, particularly on challenging scenarios. Existing algorithms that provide risk-awareness to NNs are complex and ad-hoc. Specifically, these methods require significant engineering changes, are often developed only for particular settings, and are not easily composable. Here we present capsa, a framework for extending models with risk-awareness. Capsa provides a methodology for quantifying multiple forms of risk and composing different algorithms together to quantify different risk metrics in parallel. We validate capsa by implementing state-of-the-art uncertainty estimation algorithms within the capsa framework and benchmarking them on complex perception datasets. We demonstrate capsa's ability to easily compose aleatoric uncertainty, epistemic uncertainty, and bias estimation together in a single procedure, and show how this approach provides a comprehensive awareness of NN risk.
</details>
<details>
<summary>摘要</summary>
现代大规模深度神经网络（NN）的普遍性受到了它在复杂问题上的极高性能的推动，然而它也面临着突然、不可预期和有时候可致命的失败问题，尤其是在复杂的场景下。现有的风险意识提供方法是复杂且尝试性的，它们需要大量的工程改进，通常只适用于特定的设置，并且不易组合。我们现在提出了 capsa 框架，用于延展模型中的风险意识。capsa 提供了评估多种风险形式的方法和组合不同风险度量计算的能力。我们通过在 capsa 框架中实现现状的不确定性估计算算法，并将其分类 onto 复杂的感知数据集进行了验证。我们示出了 capsa 可以轻松地组合 aleatoric 不确定性、epistemic 不确定性和偏见估计 together 在单个过程中，并证明了这种方法可以提供全面的 NN 风险意识。
</details></li>
</ul>
<hr>
<h2 id="Experiments-on-Generative-AI-Powered-Parametric-Modeling-and-BIM-for-Architectural-Design"><a href="#Experiments-on-Generative-AI-Powered-Parametric-Modeling-and-BIM-for-Architectural-Design" class="headerlink" title="Experiments on Generative AI-Powered Parametric Modeling and BIM for Architectural Design"></a>Experiments on Generative AI-Powered Parametric Modeling and BIM for Architectural Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00227">http://arxiv.org/abs/2308.00227</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaechang Ko, John Ajibefun, Wei Yan</li>
<li>for: 该论文提出了一种新的建筑设计框架，利用生成AI工具包括ChatGPT和Veras，并结合参数化模型和建筑信息模型（BIM），以提高设计过程。</li>
<li>methods: 该研究利用了ChatGPT和生成AI在3D建筑设计中的潜在力，超出了其在文本和2D图像生成中的使用范围。</li>
<li>results: 提出的框架可以增强建筑师和AI之间的合作，快速探索设计想法，生成具有上下文敏感性和创新性的设计生成。通过将ChatGPT用于脚本编写和Veras用于生成设计想法，并与广泛使用的参数化模型和BIM工具集成，该框架为建筑师提供了直观和强大的方法来传达设计意图，从而提高设计效率、创新性和合作性。<details>
<summary>Abstract</summary>
This paper introduces a new architectural design framework that utilizes generative AI tools including ChatGPT and Veras with parametric modeling and Building Information Modeling (BIM) to enhance the design process. The study experiments with the potential of ChatGPT and generative AI in 3D architectural design, extending beyond its use in text and 2D image generation. The proposed framework promotes collaboration between architects and AI, facilitating a quick exploration of design ideas and producing context-sensitive, creative design generation. By integrating ChatGPT for scripting and Veras for generating design ideas with widely used parametric modeling and BIM tools, the framework provides architects with an intuitive and powerful method to convey design intent, leading to more efficient, creative, and collaborative design processes.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的建筑设计框架，利用生成AI工具，包括ChatGPT和Veras，并与参数化建筑模型和建筑信息模型（BIM）结合，以提高设计过程。该研究对生成AI在3D建筑设计中的潜力进行了实验，超出了其在文本和2D图像生成领域的使用范围。提出的框架旨在促进建筑师和AI之间的合作，快速探索设计想法，生成受Contextsensitive的、创新的设计生成。通过将ChatGPT用于脚本和Veras用于生成设计想法，并与常用的参数化建筑模型和BIM工具结合，该框架为建筑师提供了直观和强大的方法，以达到更高效、更创新、更合作的设计过程。
</details></li>
</ul>
<hr>
<h2 id="Instructed-to-Bias-Instruction-Tuned-Language-Models-Exhibit-Emergent-Cognitive-Bias"><a href="#Instructed-to-Bias-Instruction-Tuned-Language-Models-Exhibit-Emergent-Cognitive-Bias" class="headerlink" title="Instructed to Bias: Instruction-Tuned Language Models Exhibit Emergent Cognitive Bias"></a>Instructed to Bias: Instruction-Tuned Language Models Exhibit Emergent Cognitive Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00225">http://arxiv.org/abs/2308.00225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Itay Itzhak, Gabriel Stanovsky, Nir Rosenfeld, Yonatan Belinkov</li>
<li>for: 本研究旨在探讨大语言模型（LM）在受到人类反馈的指导下进行调整后，是否会受到更多的偏见影响。</li>
<li>methods: 本研究使用了多种方法来检测大语言模型中的偏见，包括权重调整、排名预测和人类反馈等。</li>
<li>results: 研究发现，经过受到人类反馈的调整后，大语言模型中的偏见呈现更加明显，尤其是在三种常见的偏见中，即套利效应、信心效应和信仰偏见中。这些偏见在不同的模型中显得更加明显，特别是在受到人类反馈的模型中，如Flant-T5、GPT3.5和GPT4等。这些发现提供了对instruction-tuned LMs中偏见的更深入的理解，这将对于开发更加可靠和无偏的语言模型是非常重要。<details>
<summary>Abstract</summary>
Recent studies show that instruction tuning and learning from human feedback improve the abilities of large language models (LMs) dramatically. While these tuning methods can make models generate high-quality text, we conjecture that more implicit cognitive biases may arise in these fine-tuned models. Our work provides evidence that these fine-tuned models exhibit biases that were absent or less pronounced in their pretrained predecessors. We examine the extent of this phenomenon in three cognitive biases - the decoy effect, the certainty effect, and the belief bias - all of which are known to influence human decision-making and reasoning. Our findings highlight the presence of these biases in various models, especially those that have undergone instruction tuning, such as Flan-T5, GPT3.5, and GPT4. This research constitutes a step toward comprehending cognitive biases in instruction-tuned LMs, which is crucial for the development of more reliable and unbiased language models.
</details>
<details>
<summary>摘要</summary>
Recent studies show that 教程调整和学习人类反馈可以大幅提高大语言模型（LM）的能力。然而，我们 conjecture 这些调整方法可能会使模型生成高质量的文本中潜藏更多的隐性认知偏见。我们的研究发现，经过调整后的模型具有先前缺 absent 或较弱的偏见。我们对三种认知偏见——杂谱效应、确定性效应和信念偏见——进行了调查，这些偏见都是影响人类决策和思维的known。我们发现，特别是经过 instrucion tuning 的模型，如 Flan-T5、GPT3.5 和 GPT4，具有这些偏见。这项研究为了理解 instruction-tuned LM 中的认知偏见，是对更可靠和不偏的语言模型发展的重要一步。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Beyond-Identification-Multi-bit-Watermark-for-Language-Models"><a href="#Advancing-Beyond-Identification-Multi-bit-Watermark-for-Language-Models" class="headerlink" title="Advancing Beyond Identification: Multi-bit Watermark for Language Models"></a>Advancing Beyond Identification: Multi-bit Watermark for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00221">http://arxiv.org/abs/2308.00221</a></li>
<li>repo_url: None</li>
<li>paper_authors: KiYoon Yoo, Wonhyuk Ahn, Nojun Kwak</li>
<li>for: 这项研究旨在预防大语言模型的滥用，不仅是机器生成文本的识别。</li>
<li>methods: 该研究提出了一种名为“多位色列标”（COLOR）的技术，在语言模型生成过程中嵌入可追溯的多位信息。</li>
<li>results: 验证性实验表明，COLOR可以在500个符号左右的中等长度文本中成功嵌入32位消息，准确率达91.9%。这项工作为抗language模型滥用提供了新的策略。<details>
<summary>Abstract</summary>
This study aims to proactively tackle misuse of large language models beyond identification of machine-generated text. While existing methods focus on detection, some malicious misuses demand tracing the adversary user for counteracting them. To address this, we propose "Multi-bit Watermark through Color-listing" (COLOR), embedding traceable multi-bit information during language model generation. Leveraging the benefits of zero-bit watermarking (Kirchenbauer et al., 2023a), COLOR enables extraction without model access, on-the-fly embedding, and maintains text quality, while allowing zero-bit detection all at the same time. Preliminary experiments demonstrates successful embedding of 32-bit messages with 91.9% accuracy in moderate-length texts ($\sim$500 tokens). This work advances strategies to counter language model misuse effectively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Deep-Reinforcement-Learning-Based-Battery-Conditioning-Hierarchical-V2G-Coordination-for-Multi-Stakeholder-Benefits"><a href="#Deep-Reinforcement-Learning-Based-Battery-Conditioning-Hierarchical-V2G-Coordination-for-Multi-Stakeholder-Benefits" class="headerlink" title="Deep Reinforcement Learning-Based Battery Conditioning Hierarchical V2G Coordination for Multi-Stakeholder Benefits"></a>Deep Reinforcement Learning-Based Battery Conditioning Hierarchical V2G Coordination for Multi-Stakeholder Benefits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00218">http://arxiv.org/abs/2308.00218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubao Zhang, Xin Chen, Yi Gu, Zhicheng Li, Wu Kai</li>
<li>for: 提高可再生能源利用率和电网稳定性，适用于大规模电动车充电 scheduling 策略。</li>
<li>methods: 基于深度强化学习（DRL）和证明权益算法，实现多方参与者协调。</li>
<li>results: 相比四种基准方案，提高可再生能源消耗率、缓和负荷波动、满足电动车充电需求，降低充电成本和电池衰竭。<details>
<summary>Abstract</summary>
With the growing prevalence of electric vehicles (EVs) and advancements in EV electronics, vehicle-to-grid (V2G) techniques and large-scale scheduling strategies have emerged to promote renewable energy utilization and power grid stability. This study proposes a multi-stakeholder hierarchical V2G coordination based on deep reinforcement learning (DRL) and the Proof of Stake algorithm. Furthermore, the multi-stakeholders include the power grid, EV aggregators (EVAs), and users, and the proposed strategy can achieve multi-stakeholder benefits. On the grid side, load fluctuations and renewable energy consumption are considered, while on the EVA side, energy constraints and charging costs are considered. The three critical battery conditioning parameters of battery SOX are considered on the user side, including state of charge, state of power, and state of health. Compared with four typical baselines, the multi-stakeholder hierarchical coordination strategy can enhance renewable energy consumption, mitigate load fluctuations, meet the energy demands of EVA, and reduce charging costs and battery degradation under realistic operating conditions.
</details>
<details>
<summary>摘要</summary>
On the grid side, the approach considers load fluctuations and renewable energy consumption, while on the EVA side, it considers energy constraints and charging costs. For users, the approach takes into account three critical battery conditioning parameters: state of charge, state of power, and state of health.Compared to four typical baselines, the multi-stakeholder hierarchical coordination strategy can increase renewable energy consumption, mitigate load fluctuations, meet the energy demands of EVAs, and reduce charging costs and battery degradation under realistic operating conditions.
</details></li>
</ul>
<hr>
<h2 id="Performance-Evaluation-of-Swin-Vision-Transformer-Model-using-Gradient-Accumulation-Optimization-Technique"><a href="#Performance-Evaluation-of-Swin-Vision-Transformer-Model-using-Gradient-Accumulation-Optimization-Technique" class="headerlink" title="Performance Evaluation of Swin Vision Transformer Model using Gradient Accumulation Optimization Technique"></a>Performance Evaluation of Swin Vision Transformer Model using Gradient Accumulation Optimization Technique</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00197">http://arxiv.org/abs/2308.00197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanad Aburass, Osama Dorgham</li>
<li>for: 评估 Swin Transformers 模型使用 gradient accumulation optimization（GAO）技术的性能和训练时间影响。</li>
<li>methods: 使用 GAO 技术对 Swin ViT 模型进行优化。</li>
<li>results: GAO 技术对 Swin ViT 模型的精度有显著下降，训练时间增加显著。这些结果表明在 Swin ViT 模型中使用 GAO 技术可能不太适用，需要谨慎使用。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) have emerged as a promising approach for visual recognition tasks, revolutionizing the field by leveraging the power of transformer-based architectures. Among the various ViT models, Swin Transformers have gained considerable attention due to their hierarchical design and ability to capture both local and global visual features effectively. This paper evaluates the performance of Swin ViT model using gradient accumulation optimization (GAO) technique. We investigate the impact of gradient accumulation optimization technique on the model's accuracy and training time. Our experiments show that applying the GAO technique leads to a significant decrease in the accuracy of the Swin ViT model, compared to the standard Swin Transformer model. Moreover, we detect a significant increase in the training time of the Swin ViT model when GAO model is applied. These findings suggest that applying the GAO technique may not be suitable for the Swin ViT model, and concern should be undertaken when using GAO technique for other transformer-based models.
</details>
<details>
<summary>摘要</summary>
视力变换器（ViT）技术在视觉识别任务中表现出色，革命化了该领域，通过利用变换器结构的力量。 Among the various ViT models, Swin Transformers have gained considerable attention due to their hierarchical design and ability to capture both local and global visual features effectively. This paper evaluates the performance of Swin ViT model using gradient accumulation optimization (GAO) technique. We investigate the impact of gradient accumulation optimization technique on the model's accuracy and training time. Our experiments show that applying the GAO technique leads to a significant decrease in the accuracy of the Swin ViT model, compared to the standard Swin Transformer model. Moreover, we detect a significant increase in the training time of the Swin ViT model when GAO model is applied. These findings suggest that applying the GAO technique may not be suitable for the Swin ViT model, and concern should be undertaken when using GAO technique for other transformer-based models.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard Chinese languages used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Analytical-Techniques-to-Support-Hospital-Case-Mix-Planning"><a href="#Analytical-Techniques-to-Support-Hospital-Case-Mix-Planning" class="headerlink" title="Analytical Techniques to Support Hospital Case Mix Planning"></a>Analytical Techniques to Support Hospital Case Mix Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07323">http://arxiv.org/abs/2308.07323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert L Burdett, Paul corry, David Cook, Prasad Yarlagadda</li>
<li>for: 本文旨在提供价值评估和决策支持工具，以支持医院资源评估和案例混合规划（CMP）方法。</li>
<li>methods: 本文提出了一种优化模型，用于分析修改现有案例混合的影响。该模型可以根据医院资源可用性水平的变化，对其他患者类型进行修改。此外，本文还提出了多目标决策技术，用于比较和评估竞争性案例混合解决方案。</li>
<li>results: 本文的提出的技术可以帮助医院管理者更好地了解医院资源的使用情况，并提供更多的情况情况。这些技术还可以帮助医院管理者根据医院资源的限制，选择最佳的案例混合方案。<details>
<summary>Abstract</summary>
This article introduces analytical techniques and a decision support tool to support capacity assessment and case mix planning (CMP) approaches previously created for hospitals. First, an optimization model is proposed to analyse the impact of making a change to an existing case mix. This model identifies how other patient types should be altered proportionately to the changing levels of hospital resource availability. Then we propose multi-objective decision-making techniques to compare and critique competing case mix solutions obtained. The proposed techniques are embedded seamlessly within an Excel Visual Basic for Applications (VBA) personal decision support tool (PDST), for performing informative quantitative assessments of hospital capacity. The PDST reports informative metrics of difference and reports the impact of case mix modifications on the other types of patient present. The techniques developed in this article provide a bridge between theory and practice that is currently missing and provides further situational awareness around hospital capacity.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Generative-Models-as-a-Complex-Systems-Science-How-can-we-make-sense-of-large-language-model-behavior"><a href="#Generative-Models-as-a-Complex-Systems-Science-How-can-we-make-sense-of-large-language-model-behavior" class="headerlink" title="Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?"></a>Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00189">http://arxiv.org/abs/2308.00189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ari Holtzman, Peter West, Luke Zettlemoyer</li>
<li>for: 本研究旨在解释语言模型完成多个任务的行为，以帮助未来的研究人员更好地理解和预测语言模型的行为。</li>
<li>methods: 本研究使用了系统性的分析方法，将语言模型的行为 decomposed into 多个类别，以便更好地理解cross-task表现。</li>
<li>results: 研究发现，语言模型的行为可以分为多个类别，包括表示、生成和逻辑等类别，这些类别之间存在着较强的相互关系。这些结果可以帮助未来的研究人员更好地理解和预测语言模型的行为，以便更好地应用语言模型。<details>
<summary>Abstract</summary>
Coaxing out desired behavior from pretrained models, while avoiding undesirable ones, has redefined NLP and is reshaping how we interact with computers. What was once a scientific engineering discipline-in which building blocks are stacked one on top of the other-is arguably already a complex systems science, in which emergent behaviors are sought out to support previously unimagined use cases.   Despite the ever increasing number of benchmarks that measure task performance, we lack explanations of what behaviors language models exhibit that allow them to complete these tasks in the first place. We argue for a systematic effort to decompose language model behavior into categories that explain cross-task performance, to guide mechanistic explanations and help future-proof analytic research.
</details>
<details>
<summary>摘要</summary>
使已经训练过的模型展现所需的行为，而不是不良的行为，已经重定义了自然语言处理（NLP）领域，并在我们与计算机之间的交互方式中发生了重大变革。以前，建构模型的工程学是一个科学工程领域，在其中建构块一个接一个排列在上面。然而，现在可能已经是一种复杂系统科学，在寻找emergent行为以支持前所未想到的用 caso。尽管任务性能的测试benchmark数量在不断增加，但我们仍然缺乏 Completing these tasks in the first place. We argue for a systematic effort to decompose language model behavior into categories that explain cross-task performance, to guide mechanistic explanations and help future-proof analytic research.
</details></li>
</ul>
<hr>
<h2 id="Multicriteria-Optimization-Techniques-for-Understanding-the-Case-Mix-Landscape-of-a-Hospital"><a href="#Multicriteria-Optimization-Techniques-for-Understanding-the-Case-Mix-Landscape-of-a-Hospital" class="headerlink" title="Multicriteria Optimization Techniques for Understanding the Case Mix Landscape of a Hospital"></a>Multicriteria Optimization Techniques for Understanding the Case Mix Landscape of a Hospital</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07322">http://arxiv.org/abs/2308.07322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert L Burdett, Paul Corry, Prasad Yarlagadda, David Cook, Sean Birgan</li>
<li>for: 本文针对医院内不同病例混合（case mix）的影响进行研究，以提高医院的质量和效率。</li>
<li>methods: 本文提出了一个改进了多 критери维优化（MCO）方法，并使用了平行减少条件法（ECM）和KD-Trees来生成更多的非主对称（Pareto优）病例混合。</li>
<li>results: 本文获得了一个更好的非主对称病例混合archive，并提出了一个适合决策支持工具（DST）来生成、检视、导航和查询这个archive。<details>
<summary>Abstract</summary>
Various medical and surgical units operate in a typical hospital and to treat their patients these units compete for infrastructure like operating rooms (OR) and ward beds. How that competition is regulated affects the capacity and output of a hospital. This article considers the impact of treating different patient case mix (PCM) in a hospital. As each case mix has an economic consequence and a unique profile of hospital resource usage, this consideration is important. To better understand the case mix landscape and to identify those which are optimal from a capacity utilisation perspective, an improved multicriteria optimization (MCO) approach is proposed. As there are many patient types in a typical hospital, the task of generating an archive of non-dominated (i.e., Pareto optimal) case mix is computationally challenging. To generate a better archive, an improved parallelised epsilon constraint method (ECM) is introduced. Our parallel random corrective approach is significantly faster than prior methods and is not restricted to evaluating points on a structured uniform mesh. As such we can generate more solutions. The application of KD-Trees is another new contribution. We use them to perform proximity testing and to store the high dimensional Pareto frontier (PF). For generating, viewing, navigating, and querying an archive, the development of a suitable decision support tool (DST) is proposed and demonstrated.
</details>
<details>
<summary>摘要</summary>
医院内的不同医疗和手术单位需要共享设备，如操作室（OR）和病房床位，这些设备的竞争会影响医院的负荷和产量。这篇文章考虑了医院内不同患者案例混合（PCM）的影响。每个案例混合都有经济影响和医院资源的唯一性使用特征，因此这种考虑是重要的。为更好地了解案例混合风景，并确定最佳的负荷利用情况，本文提出了改进的多 criterion 优化（MCO）方法。由于医院内通常有很多种类的患者，生成完整的非束定（i.e., Pareto优）案例混合的任务是计算复杂的。为了生成更好的案例混合，本文引入了改进的并行epsilon constraint方法（ECM）。我们的并行随机修正方法比之前的方法更快速，并不 Restricted to评估点structured uniform mesh。因此，我们可以生成更多的解。另外，我们使用KD-Trees来进行 proximity testing和存储高维度Pareto前沿（PF）。为生成、查看、导航和查询案例混合 archive，我们提出了一种适用的决策支持工具（DST），并进行了示例。
</details></li>
</ul>
<hr>
<h2 id="The-Efficacy-of-Utility-Functions-for-Multicriteria-Hospital-Case-Mix-Planning"><a href="#The-Efficacy-of-Utility-Functions-for-Multicriteria-Hospital-Case-Mix-Planning" class="headerlink" title="The Efficacy of Utility Functions for Multicriteria Hospital Case-Mix Planning"></a>The Efficacy of Utility Functions for Multicriteria Hospital Case-Mix Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07321">http://arxiv.org/abs/2308.07321</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert L Burdett, Paul Corry, Prasad Yarlagadda, David Cook, Sean Birgan</li>
<li>for: 本研究的目的是发展一种新的医院案例混合规划方法，以满足不同决策者的 preference和需求。</li>
<li>methods: 本研究使用了 utility functions（UF）来表达不同决策者对输出的偏好和看法。 UF 被 scalarization 以生成一个量化的评价方法，以分配医院资源到不同的运营单元，并提供更好的容量分配和案例混合。</li>
<li>results: 研究发现，UF 方法可以评价医院不同决策者的评价标准，并且可以捕捉医院不同目标和对输出的不同需求。 此外，UF 方法还可以提供对输出的敏感分析，帮助医院管理者更好地理解和评价不同案例的需求和优先级。<details>
<summary>Abstract</summary>
A new approach to perform hospital case-mix planning (CMP) is introduced in this article. Our multi-criteria approach utilises utility functions (UF) to articulate the preferences and standpoint of independent decision makers regarding outputs. The primary aim of this article is to test whether a utility functions method (UFM) based upon the scalarization of aforesaid UF is an appropriate quantitative technique to, i) distribute hospital resources to different operating units, and ii) provide a better capacity allocation and case mix. Our approach is motivated by the need to provide a method able to evaluate the trade-off between different stakeholders and objectives of hospitals. To the best of our knowledge, no such approach has been considered before in the literature. As we will later show, this idea addresses various technical limitations, weaknesses, and flaws in current CMP. The efficacy of the aforesaid approach is tested on a case study of a large tertiary hospital. Currently UF are not used by hospital managers, and real functions are unavailable, hence, 14 rational options are tested. Our exploratory analysis has provided important guidelines for the application of these UF. It indicates that these UF provide a valuable starting point for planners, managers, and executives of hospitals to impose their goals and aspirations. In conclusion, our approach may be better at identifying case mix that users want to treat and seems more capable of modelling the varying importance of different levels of output. Apart from finding desirable case mixes to consider, the approach can provide important insights via a sensitivity analysis of the parameters of each UF.
</details>
<details>
<summary>摘要</summary>
本文介绍了一种新的医院案例混合规划（CMP）方法。我们的多 criterion 方法利用了用户函数（UF）来表达各独立决策者对输出的偏好和观点。本文的主要目标是测试 Whether a utility functions method（UFM）基于上述 UF 的权值函数是一种适当的量化技术，以分配医院资源到不同的运营部门，并提供更好的容量分配和案例混合。我们的方法是由医院的不同参与者和目标所驱动的，以解决现有 CMP 中的技术限制、弱点和缺陷。根据我们的研究，这种想法在现有 CMP 中未有所考虑。我们的案例研究表明，这种方法可以更好地评估医院的资源分配和案例混合，并提供关键的参与者和目标的指导。在本文中，我们使用了14种理性选项来测试 UF。我们的探索分析表明，这些 UF 提供了一个有价值的起点，可以帮助医院规划者、管理者和执行者实现他们的目标和 aspirations。结论是，我们的方法可能更好地认知用户想要治疗的案例混合，并且更能模拟不同输出水平的重要性。除了找到愿意考虑的案例混合外，我们的方法还可以提供重要的参与者和目标的指导，以及敏感分析每个 UF 的参数。
</details></li>
</ul>
<hr>
<h2 id="Attribution-Scores-in-Data-Management-and-Explainable-Machine-Learning"><a href="#Attribution-Scores-in-Data-Management-and-Explainable-Machine-Learning" class="headerlink" title="Attribution-Scores in Data Management and Explainable Machine Learning"></a>Attribution-Scores in Data Management and Explainable Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00184">http://arxiv.org/abs/2308.00184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leopoldo Bertossi</li>
<li>for: 本研究探讨了使用实际 causality 定义责任分数的最新研究，用于解释数据库中的查询结果，以及机器学习中的分类模型的结果。</li>
<li>methods: 本研究使用了实际 causality 定义责任分数，并与数据库修复相连接，以获得数据库的一致性量化度量。在机器学习中，责任分数得到了正确扩展和解释。此外，本研究还研究了 Shap-score 的有效计算方法。</li>
<li>results: 本研究的结果表明，使用实际 causality 定义责任分数可以帮助解释数据库中的查询结果和机器学习中的分类结果。此外，本研究还提供了一种有效的 Shap-score 计算方法。<details>
<summary>Abstract</summary>
We describe recent research on the use of actual causality in the definition of responsibility scores as explanations for query answers in databases, and for outcomes from classification models in machine learning. In the case of databases, useful connections with database repairs are illustrated and exploited. Repairs are also used to give a quantitative measure of the consistency of a database. For classification models, the responsibility score is properly extended and illustrated. The efficient computation of Shap-score is also analyzed and discussed. The emphasis is placed on work done by the author and collaborators.
</details>
<details>
<summary>摘要</summary>
我们描述了最近的研究，把实际 causality 用于责任分数的定义，以解释查询结果存储在数据库中，以及机器学习模型中的结果。在数据库方面，我们 illustrate 了有用的连接，并利用了数据库修复。修复还可以给出数据库的一个量化度量。在机器学习模型方面，责任分数得到了正确的扩展和图示。我们还分析了计算 Shap-score 的高效方法。我们强调了作者和合作者的工作。
</details></li>
</ul>
<hr>
<h2 id="Pretrained-deep-models-outperform-GBDTs-in-Learning-To-Rank-under-label-scarcity"><a href="#Pretrained-deep-models-outperform-GBDTs-in-Learning-To-Rank-under-label-scarcity" class="headerlink" title="Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity"></a>Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00177">http://arxiv.org/abs/2308.00177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charlie Hou, Kiran Koshy Thekumparampil, Michael Shavlovsky, Giulia Fanti, Yesh Dattatreya, Sujay Sanghavi</li>
<li>for: 本研究旨在检验是否可以通过无监督预训练提高学习排序（LTR）问题的性能，并与基本监督学习模型（GBDT）和其他非预训练模型进行比较。</li>
<li>methods: 本研究使用了一些简单的设计选择，包括 SimCLR-Rank，我们对 SimCLR（一种无监督预训练方法）进行了修改，以生成预训练的深度学习模型。</li>
<li>results: 研究结果表明，预训练模型可以将 GBDT 和其他非预训练模型Soundly 超越，特别是在 labels 数量相对较多的情况下。此外，预训练模型还可以在排序异常数据时表现更好的Robustness 性能。<details>
<summary>Abstract</summary>
While deep learning (DL) models are state-of-the-art in text and image domains, they have not yet consistently outperformed Gradient Boosted Decision Trees (GBDTs) on tabular Learning-To-Rank (LTR) problems. Most of the recent performance gains attained by DL models in text and image tasks have used unsupervised pretraining, which exploits orders of magnitude more unlabeled data than labeled data. To the best of our knowledge, unsupervised pretraining has not been applied to the LTR problem, which often produces vast amounts of unlabeled data. In this work, we study whether unsupervised pretraining can improve LTR performance over GBDTs and other non-pretrained models. Using simple design choices--including SimCLR-Rank, our ranking-specific modification of SimCLR (an unsupervised pretraining method for images)--we produce pretrained deep learning models that soundly outperform GBDTs (and other non-pretrained models) in the case where labeled data is vastly outnumbered by unlabeled data. We also show that pretrained models also often achieve significantly better robustness than non-pretrained models (GBDTs or DL models) in ranking outlier data.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）模型在文本和图像领域是当前最佳性的，但它们没有一直Consistently exceeded Gradient Boosted Decision Trees（GBDTs）在表格学习到排名（LTR）问题上。大多数最近的DL模型在文本和图像任务中的性能提升都是通过预训练来实现，这些预训练使用了几个数量级的无标签数据。据我们所知，预训练没有被应用于LTR问题，这个问题通常会生成巨量的无标签数据。在这个工作中，我们研究了是否可以通过预训练提高LTR性能，并与GBDTs和其他非预训练模型进行比较。使用简单的设计选择（包括我们的SimCLR-Rank修改），我们生成了在标签数据被很多的情况下，深度学习模型与GBDTs和其他非预训练模型相比，具有显著的性能优势。我们还发现预训练模型通常在排名异常数据时也具有更好的robustness性。
</details></li>
</ul>
<hr>
<h2 id="Adversarially-Robust-Neural-Legal-Judgement-Systems"><a href="#Adversarially-Robust-Neural-Legal-Judgement-Systems" class="headerlink" title="Adversarially Robust Neural Legal Judgement Systems"></a>Adversarially Robust Neural Legal Judgement Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00165">http://arxiv.org/abs/2308.00165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rohit Raj, V Susheela Devi</li>
<li>for: 法律判断预测系统的研究，旨在预测法律案件的结果基于案件的事实描述。</li>
<li>methods: 这些研究使用自然语言处理（NLP）技术预测法律判断结果基于事实描述。</li>
<li>results: 我们的方法在三个法律数据集上进行了广泛的实验，并显示了对抗攻击的显著改进，比前一代法律判断预测系统更加可靠。<details>
<summary>Abstract</summary>
Legal judgment prediction is the task of predicting the outcome of court cases on a given text description of facts of cases. These tasks apply Natural Language Processing (NLP) techniques to predict legal judgment results based on facts. Recently, large-scale public datasets and NLP models have increased research in areas related to legal judgment prediction systems. For such systems to be practically helpful, they should be robust from adversarial attacks. Previous works mainly focus on making a neural legal judgement system; however, significantly less or no attention has been given to creating a robust Legal Judgement Prediction(LJP) system. We implemented adversarial attacks on early existing LJP systems and found that none of them could handle attacks. In this work, we proposed an approach for making robust LJP systems. Extensive experiments on three legal datasets show significant improvements in our approach over the state-of-the-art LJP system in handling adversarial attacks. To the best of our knowledge, we are the first to increase the robustness of early-existing LJP systems.
</details>
<details>
<summary>摘要</summary>
法律判断预测是指根据案例事实文本预测法律判断结果。这些任务应用自然语言处理（NLP）技术来预测法律判断结果基于事实。最近，大规模公共数据集和NLP模型的提高了有关法律判断预测系统的研究。为了使这些系统在实际中有用，它们应该是Robust against adversarial attacks。以前的工作主要集中在建立神经法律判断系统；然而，Significantly less or no attention has been given to create a robust Legal Judgement Prediction(LJP) system。我们对早期的LJP系统进行了抗击攻击，并发现其无法抵抗攻击。在这种情况下，我们提出了一种方法来提高LJP系统的Robustness。广泛的实验表明，我们的方法在三个法律数据集上显著提高了对抗攻击的能力，与现有的LJP系统相比。到目前为止，我们是第一个提高早期LJP系统的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Perfect-Quality-Segments-in-MT-Output-with-Fine-Tuned-OpenAI-LLM-Is-it-possible-to-capture-editing-distance-patterns-from-historical-data"><a href="#Predicting-Perfect-Quality-Segments-in-MT-Output-with-Fine-Tuned-OpenAI-LLM-Is-it-possible-to-capture-editing-distance-patterns-from-historical-data" class="headerlink" title="Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?"></a>Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00158">http://arxiv.org/abs/2308.00158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Serge Gladkoff, Gleb Erofeev, Lifeng Han, Goran Nenadic</li>
<li>for: 本研究旨在检验现有大语言模型（LLM）是否可以用于精度评估翻译（TQE）任务，以及其能力。</li>
<li>methods: 我们使用了ChatGPT作为示例，将TQE作为二分类任务进行 fine-tuning。使用了英语到意大利语、德语、法语、日语、荷语、葡萄牙语、土耳其语和中文等八种语言对training corpora进行训练。</li>
<li>results: 我们的实验结果显示，通过API进行 fine-tuning的ChatGPT可以在预测翻译质量方面达到相对高的分数，例如英语-意大利语和英语-德语的分数分别是82.42%和83.69%。但是，模型准确率还有很大空间提高。<details>
<summary>Abstract</summary>
Translation Quality Estimation (TQE) is an essential step before deploying the output translation into usage. TQE is also critical in assessing machine translation (MT) and human translation (HT) quality without seeing the reference translations. This work examines whether the state-of-the-art large language models (LLMs) can be fine-tuned for the TQE task and their capability. We take ChatGPT as one example and approach TQE as a binary classification task. Using \textbf{eight language pairs} including English to Italian, German, French, Japanese, Dutch, Portuguese, Turkish, and Chinese training corpora, our experimental results show that fine-tuned ChatGPT via its API can achieve a relatively high score on predicting translation quality, i.e. \textit{if the translation needs to be edited}. However, there is definitely much space to improve the model accuracy, e.g. they are 82.42\% and 83.69\% for English-Italian and English-German respectively using our experimental settings. English-Italiano bilingual Abstract is available in the paper.
</details>
<details>
<summary>摘要</summary>
tranlation Quality Estimation (TQE) 是一个非常重要的步骤在部署输出翻译之前。 TQE 也是评估机器翻译 (MT) 和人工翻译 (HT) 质量的关键步骤，无需看到参考翻译。这项工作检验了现代大语言模型 (LLM) 是否可以用于 TQE 任务，以及其能力。我们使用 ChatGPT 作为一个例子，将 TQE 视为二分类问题。使用包括英语到意大利语、德语、法语、日语、荷兰语、葡萄牙语、土耳其语和中文的训练集，我们的实验结果显示，经过 ChatGPT 的 API 微调，可以达到一定的高分数，即确定翻译是否需要编辑。然而，模型准确率仍然有很大的提升空间，例如英语-意大利语和英语-德语的准确率分别为 82.42% 和 83.69%。英语-意大利语双语摘要在论文中可用。
</details></li>
</ul>
<hr>
<h2 id="Formally-Explaining-Neural-Networks-within-Reactive-Systems"><a href="#Formally-Explaining-Neural-Networks-within-Reactive-Systems" class="headerlink" title="Formally Explaining Neural Networks within Reactive Systems"></a>Formally Explaining Neural Networks within Reactive Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00143">http://arxiv.org/abs/2308.00143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahaf Bassan, Guy Amir, Davide Corsi, Idan Refaeli, Guy Katz</li>
<li>for: 这个论文的目的是解释深度神经网络（DNN）控制的反应系统中的行为，以便提高系统的透明度和可信度。</li>
<li>methods: 这篇论文提出了一种基于验证的可解释AI技术，可以帮助找到DNN控制系统中的输入特征，并且提供了有效的计算方法来减少搜索空间。</li>
<li>results: 这篇论文在两个popular benchmark上进行了评估，并证明了其方法可以效率地计算出最小和最小的解释，超过了现有技术的性能。此外，论文还表明了其方法生成的正式解释比非验证基于AI技术更可靠。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are increasingly being used as controllers in reactive systems. However, DNNs are highly opaque, which renders it difficult to explain and justify their actions. To mitigate this issue, there has been a surge of interest in explainable AI (XAI) techniques, capable of pinpointing the input features that caused the DNN to act as it did. Existing XAI techniques typically face two limitations: (i) they are heuristic, and do not provide formal guarantees that the explanations are correct; and (ii) they often apply to ``one-shot'' systems, where the DNN is invoked independently of past invocations, as opposed to reactive systems. Here, we begin bridging this gap, and propose a formal DNN-verification-based XAI technique for reasoning about multi-step, reactive systems. We suggest methods for efficiently calculating succinct explanations, by exploiting the system's transition constraints in order to curtail the search space explored by the underlying verifier. We evaluate our approach on two popular benchmarks from the domain of automated navigation; and observe that our methods allow the efficient computation of minimal and minimum explanations, significantly outperforming the state of the art. We also demonstrate that our methods produce formal explanations that are more reliable than competing, non-verification-based XAI techniques.
</details>
<details>
<summary>摘要</summary>
Here, we aim to bridge this gap and propose a formal DNN-verification-based XAI technique for reasoning about multi-step, reactive systems. Our approach leverages the system's transition constraints to efficiently calculate succinct explanations. We evaluate our method on two popular benchmarks from the domain of automated navigation and observe that our approach can efficiently compute minimal and minimum explanations, significantly outperforming the state of the art. We also demonstrate that our methods produce formal explanations that are more reliable than competing, non-verification-based XAI techniques.我们使用的 DNN 是响应系统中的控制器，但 DNN 却具有高度透明性，使得解释和证明其行为具有困难。为解决这个问题，有一种强大的兴趣在解释 AI 技术（XAI）中，可以 pinpoint DNN 的输入特征，并且提供正式的 garanties。现有的 XAI 技术有两种限制：（i）它们是规则的，无法提供正式的 garanties，和（ii）它们通常适用于独立的一个执行，而不是响应系统。在这里，我们希望bridging这个差距，并提出一种基于 DNN 验证的 XAI 技术，用于理解多步、响应系统。我们利用系统的转移约束，以便高效地计算简短的解释。我们在两个popular的自动导航 benchmark 上评估了我们的方法，并观察到我们的方法可以高效地计算最小和最小的解释，与当前最佳性能相比较高。我们还证明了我们的方法生成的正式解释，比非验证基于 XAI 技术更可靠。
</details></li>
</ul>
<hr>
<h2 id="A-Suite-of-Fairness-Datasets-for-Tabular-Classification"><a href="#A-Suite-of-Fairness-Datasets-for-Tabular-Classification" class="headerlink" title="A Suite of Fairness Datasets for Tabular Classification"></a>A Suite of Fairness Datasets for Tabular Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00133">http://arxiv.org/abs/2308.00133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Hirzel, Michael Feffer</li>
<li>for: 提高机器学习分类器的公平性</li>
<li>methods: 引入了一组函数来获取20个公平性数据集和相关的公平性metadata，以促进未来的公平性意识机器学习研究的更加严格的实验评估。</li>
<li>results: 未提出实验结果，主要是提供数据集和metadata供后续研究使用。<details>
<summary>Abstract</summary>
There have been many papers with algorithms for improving fairness of machine-learning classifiers for tabular data. Unfortunately, most use only very few datasets for their experimental evaluation. We introduce a suite of functions for fetching 20 fairness datasets and providing associated fairness metadata. Hopefully, these will lead to more rigorous experimental evaluations in future fairness-aware machine learning research.
</details>
<details>
<summary>摘要</summary>
有很多文献提出了机器学习分类器公平性的算法优化方法，但大多数只使用了很少的数据集进行实验评估。我们介绍了一个函数集，用于抓取20个公平性数据集和相关的公平性元数据。希望这些函数能够促进未来的公平性意识机器学习研究的更加严格的实验评估。Here's a breakdown of the translation:* "There have been many papers" becomes "有很多文献"* "with algorithms for improving fairness" becomes "提出了机器学习分类器公平性的算法优化方法"* "for tabular data" becomes " для标量数据"* "Unfortunately, most use only very few datasets" becomes "但大多数只使用了很少的数据集"* "for their experimental evaluation" becomes "进行实验评估"* "We introduce a suite of functions" becomes "我们介绍了一个函数集"* "for fetching 20 fairness datasets" becomes "用于抓取20个公平性数据集"* "and providing associated fairness metadata" becomes "并提供相关的公平性元数据"* "Hopefully, these will lead to more rigorous experimental evaluations" becomes "希望这些函数能够促进未来的公平性意识机器学习研究的更加严格的实验评估"
</details></li>
</ul>
<hr>
<h2 id="A-Modular-Ontology-for-MODS-–-Metadata-Object-Description-Schema"><a href="#A-Modular-Ontology-for-MODS-–-Metadata-Object-Description-Schema" class="headerlink" title="A Modular Ontology for MODS – Metadata Object Description Schema"></a>A Modular Ontology for MODS – Metadata Object Description Schema</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00116">http://arxiv.org/abs/2308.00116</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rushrukh Rayan, Cogan Shimizu, Heidi Sieverding, Pascal Hitzler</li>
<li>for: 该论文主要描述了Metadata Object Description Schema (MODS)的开发和改进。</li>
<li>methods: 该论文使用了Modular Ontology Design Methodology (MOMo)来设计了Modular MODS Ontology (MMODS-O)，包含了所有MODS XML schema中的元素和属性。</li>
<li>results: 该论文通过对MODS XML schema进行修改和扩展，实现了更好的知识图数据模型化。<details>
<summary>Abstract</summary>
The Metadata Object Description Schema (MODS) was developed to describe bibliographic concepts and metadata and is maintained by the Library of Congress. Its authoritative version is given as an XML schema based on an XML mindset which means that it has significant limitations for use in a knowledge graphs context. We have therefore developed the Modular MODS Ontology (MMODS-O) which incorporates all elements and attributes of the MODS XML schema. In designing the ontology, we adopt the recent Modular Ontology Design Methodology (MOMo) with the intention to strike a balance between modularity and quality ontology design on the one hand, and conservative backward compatibility with MODS on the other.
</details>
<details>
<summary>摘要</summary>
MetadataObjectDescriptionSchema（MODS）是由美国国会图书馆开发的，用于描述文献元素和元数据。它的官方版本是基于XMLschema的XML思想，这意味着在知识图谱上使用它有一定的限制。我们因此开发了Modular MODS Ontology（MMODS-O），它包含了MODS XML schema中的所有元素和属性。在设计 ontology 时，我们采用了最近的Module Ontology Design Methodology（MOMo），以达到平衡模块性和质量ontology设计的目的，同时保持与MODS的保守兼容性。
</details></li>
</ul>
<hr>
<h2 id="Can-A-Single-Human-Supervise-A-Swarm-of-100-Heterogeneous-Robots"><a href="#Can-A-Single-Human-Supervise-A-Swarm-of-100-Heterogeneous-Robots" class="headerlink" title="Can A Single Human Supervise A Swarm of 100 Heterogeneous Robots?"></a>Can A Single Human Supervise A Swarm of 100 Heterogeneous Robots?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00102">http://arxiv.org/abs/2308.00102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julie A. Adams, Joshua Hamell, Phillip Walker</li>
<li>for: 这个论文是为了检验人类单个人是否能够监督真正的多种机器人完成现实世界环境中的任务而写的。</li>
<li>methods: 这个论文使用了多种机器人群体的 Command and Control of Aggregate Swarm Tactics integrator 系统，并在美国陆军城市训练场地进行了实践。</li>
<li>results: 研究发现，人类单个人可以成功地监督100种不同机器人完成现实世界任务，但工作负担会经常超过额度。<details>
<summary>Abstract</summary>
An open research question has been whether a single human can supervise a true heterogeneous swarm of robots completing tasks in real world environments. A general concern is whether or not the human's workload will be taxed to the breaking point. The Defense Advanced Research Projects Agency's OFFsensive Swarm-Enabled Tactics program's field exercises that occurred at U.S. Army urban training sites provided the opportunity to understand the impact of achieving such swarm deployments. The Command and Control of Aggregate Swarm Tactics integrator team's swarm commander users the heterogeneous robot swarm to conduct relevant missions. During the final OFFSET program field exercise, the team collected objective and subjective metrics related to teh swarm commander's human performance. A multi-dimensional workload algorithm that estimates overall workload based on five components of workload was used to analyze the results. While the swarm commander's workload estimate did cross the overload threshold frequently, the swarm commander was able to successfully complete the missions, often under challenging operational conditions. The presented results demonstrate that a single human can deploy a swarm of 100 heterogeneous robots to conduct real-world missions.
</details>
<details>
<summary>摘要</summary>
一个打开的研究问题是可以让一个人监督真正多样化的机器人完成实际环境中的任务。一个普遍的问题是人类工作负担是否会被推到极限。美国国防高等研究计划署（DARPA）的OFFsensive Swarm-Enabled Tactics（OFFSET）项目的场地演练在美国陆军城市训练场地上进行了。 Command and Control of Aggregate Swarm Tactics（C2AST）团队的群组指挥官使用多样化机器人群组进行了相关的任务。在最后一次 OFFSET 项目场地演练中，团队收集了对群组指挥官的人类性能数据。使用多维度工作负担算法，分析结果表明，虽然群组指挥官的工作负担估计频繁超过了过载点，但群组指挥官仍然成功完成了任务，经常在具有挑战性的作战情况下。这些结果表明，一个人可以使用100个多样化机器人完成实际任务。
</details></li>
</ul>
<hr>
<h2 id="Towards-Semantically-Enriched-Embeddings-for-Knowledge-Graph-Completion"><a href="#Towards-Semantically-Enriched-Embeddings-for-Knowledge-Graph-Completion" class="headerlink" title="Towards Semantically Enriched Embeddings for Knowledge Graph Completion"></a>Towards Semantically Enriched Embeddings for Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00081">http://arxiv.org/abs/2308.00081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehwish Alam, Frank van Harmelen, Maribel Acosta</li>
<li>for: 本文主要用于介绍基于嵌入的知识Graph（KG）完成算法的现状和未来发展方向。</li>
<li>methods: 本文详细介绍了基于KG的逻辑预测算法，包括推uctive和普适链预测算法，以及利用KG、语言模型（LLM）和描述逻辑axioms中的类型信息。</li>
<li>results: 本文结合了现有的KG完成算法和LLM技术，并对各种逻辑预测算法进行了分析和评价。结果表明，通过capturing semantics of description logic axioms, 可以提高KG的完成精度和效率。<details>
<summary>Abstract</summary>
Embedding based Knowledge Graph (KG) Completion has gained much attention over the past few years. Most of the current algorithms consider a KG as a multidirectional labeled graph and lack the ability to capture the semantics underlying the schematic information. In a separate development, a vast amount of information has been captured within the Large Language Models (LLMs) which has revolutionized the field of Artificial Intelligence. KGs could benefit from these LLMs and vice versa. This vision paper discusses the existing algorithms for KG completion based on the variations for generating KG embeddings. It starts with discussing various KG completion algorithms such as transductive and inductive link prediction and entity type prediction algorithms. It then moves on to the algorithms utilizing type information within the KGs, LLMs, and finally to algorithms capturing the semantics represented in different description logic axioms. We conclude the paper with a critical reflection on the current state of work in the community and give recommendations for future directions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT多年来，基于嵌入的知识图（KG）完成技术已经受到了广泛关注。现有大多数算法视知识图为多向标签图，而无法捕捉知识图中下发的 semantics。在另一方面，大量信息已经被 capture在大语言模型（LLM）中，这些模型已经革命化了人工智能领域。KG可以受益于这些 LLM，并且 LLM 也可以受益于 KG。本视点论文将讨论现有的 KG 完成算法，包括推uctive 和 inductive 链接预测算法，entity type 预测算法，以及利用类型信息在 KG、LLM 和描述逻辑axioms中的算法。我们将结束这篇论文 WITH 一个批判性的反思，并提出未来研究的方向。TRANSLATE_TEXT_END
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Deep-Learning-based-Model-to-Defend-Network-Intrusion-Detection-System-against-Adversarial-Attacks"><a href="#A-Novel-Deep-Learning-based-Model-to-Defend-Network-Intrusion-Detection-System-against-Adversarial-Attacks" class="headerlink" title="A Novel Deep Learning based Model to Defend Network Intrusion Detection System against Adversarial Attacks"></a>A Novel Deep Learning based Model to Defend Network Intrusion Detection System against Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00077">http://arxiv.org/abs/2308.00077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khushnaseeb Roshan, Aasim Zafar, Shiekh Burhan Ul Haque</li>
<li>for: 这项研究的目的是研究基于深度学习的网络入侵检测系统（NIDS）中的强大敌意攻击算法以及防御策略。</li>
<li>methods: 本研究使用了四种强大敌意攻击算法，即快速梯度签名方法（FGSM）、Jacobian Saliency Map Attack（JSMA）、Projected Gradient Descent（PGD）以及Carlini &amp; Wagner（C&amp;W）。为了增强NIDS模型的可您性，本研究还使用了对抗训练作为防御策略。</li>
<li>results: 研究结果分为三个阶段，即在攻击前（前期）、攻击后（后期）和防御后（后防）。使用加拿大安全计划2017（CICIDS-2017）数据集进行评估，并使用了各种性能指标如f1-score、准确率等来评估NIDS模型的性能。<details>
<summary>Abstract</summary>
Network Intrusion Detection System (NIDS) is an essential tool in securing cyberspace from a variety of security risks and unknown cyberattacks. A number of solutions have been implemented for Machine Learning (ML), and Deep Learning (DL) based NIDS. However, all these solutions are vulnerable to adversarial attacks, in which the malicious actor tries to evade or fool the model by injecting adversarial perturbed examples into the system. The main aim of this research work is to study powerful adversarial attack algorithms and their defence method on DL-based NIDS. Fast Gradient Sign Method (FGSM), Jacobian Saliency Map Attack (JSMA), Projected Gradient Descent (PGD) and Carlini & Wagner (C&W) are four powerful adversarial attack methods implemented against the NIDS. As a defence method, Adversarial Training is used to increase the robustness of the NIDS model. The results are summarized in three phases, i.e., 1) before the adversarial attack, 2) after the adversarial attack, and 3) after the adversarial defence. The Canadian Institute for Cybersecurity Intrusion Detection System 2017 (CICIDS-2017) dataset is used for evaluation purposes with various performance measurements like f1-score, accuracy etc.
</details>
<details>
<summary>摘要</summary>
网络侵入检测系统（NIDS）是保护网络安全的重要工具，它可以检测到许多安全风险和未知的网络攻击。为了提高NIDS的检测精度，许多解决方案已经实施了机器学习（ML）和深度学习（DL）技术。然而，这些解决方案都受到敌意攻击的威胁，敌意攻击者可以通过投入敌意扰动的示例来诱导模型出错。本研究的主要目标是研究敌意攻击 Algorithm 和对 DL-based NIDS 的防御策略。本研究使用了 Fast Gradient Sign Method（FGSM）、Jacobian Saliency Map Attack（JSMA）、Projected Gradient Descent（PGD）和Carlini & Wagner（C&W）四种强大的敌意攻击方法，以及对 NIDS 模型的 Adversarial Training 防御策略。研究结果分为三个阶段：前 adversarial 攻击、后 adversarial 攻击和后 adversarial 防御。使用了 Canadian Institute for Cybersecurity Intrusion Detection System 2017（CICIDS-2017）数据集进行评估，并使用了各种性能指标，如 f1-score、准确率等。
</details></li>
</ul>
<hr>
<h2 id="Crowd-Safety-Manager-Towards-Data-Driven-Active-Decision-Support-for-Planning-and-Control-of-Crowd-Events"><a href="#Crowd-Safety-Manager-Towards-Data-Driven-Active-Decision-Support-for-Planning-and-Control-of-Crowd-Events" class="headerlink" title="Crowd Safety Manager: Towards Data-Driven Active Decision Support for Planning and Control of Crowd Events"></a>Crowd Safety Manager: Towards Data-Driven Active Decision Support for Planning and Control of Crowd Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00076">http://arxiv.org/abs/2308.00076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Panchamy Krishnakumari, Sascha Hoogendoorn-Lanser, Jeroen Steenbakkers, Serge Hoogendoorn</li>
<li>for: 这个论文目的是提出一种新的技术和方法，用于提高群体管理的规划和运作阶段。这种方法包括创新的数据收集技术、数据 интеграción和可视化使用3D数字双胞虫，以及基于人工智能工具的风险识别。</li>
<li>methods: 这个论文使用了Bowtie模型，这是一种全面的风险评估和预测模型，可以评估和预测不同因素的影响，如交通流量和人群密度、天气条件、情绪和访客目的等。此外，这个模型还使用了大量实时数据源，如Resono，以获取访客数量和运动幅度的信息。</li>
<li>results: 这个论文的结果表明，使用XGBoost框架可以获得最准确的预测结果，但是certain locations may benefit from additional input data to further enhance prediction quality。不withstanding these limitations, this work contributes to a more effective crowd management system and opens avenues for further advancements in this critical field.<details>
<summary>Abstract</summary>
This paper presents novel technology and methodology aimed at enhancing crowd management in both the planning and operational phases. The approach encompasses innovative data collection techniques, data integration, and visualization using a 3D Digital Twin, along with the incorporation of artificial intelligence (AI) tools for risk identification. The paper introduces the Bowtie model, a comprehensive framework designed to assess and predict risk levels. The model combines objective estimations and predictions, such as traffic flow operations and crowdedness levels, with various aggravating factors like weather conditions, sentiments, and the purpose of visitors, to evaluate the expected risk of incidents. The proposed framework is applied to the Crowd Safety Manager project in Scheveningen, where the DigiTwin is developed based on a wealth of real-time data sources. One noteworthy data source is Resono, offering insights into the number of visitors and their movements, leveraging a mobile phone panel of over 2 million users in the Netherlands. Particular attention is given to the left-hand side of the Bowtie, which includes state estimation, prediction, and forecasting. Notably, the focus is on generating multi-day ahead forecasts for event-planning purposes using Resono data. Advanced machine learning techniques, including the XGBoost framework, are compared, with XGBoost demonstrating the most accurate forecasts. The results indicate that the predictions are adequately accurate. However, certain locations may benefit from additional input data to further enhance prediction quality. Despite these limitations, this work contributes to a more effective crowd management system and opens avenues for further advancements in this critical field.
</details>
<details>
<summary>摘要</summary>
Note: The translation is written in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Generative-AI-State-of-the-Art-Opportunities-and-Open-Research-Challenges"><a href="#Reinforcement-Learning-for-Generative-AI-State-of-the-Art-Opportunities-and-Open-Research-Challenges" class="headerlink" title="Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges"></a>Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00031">http://arxiv.org/abs/2308.00031</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giorgio Franceschelli, Mirco Musolesi</li>
<li>for: 这篇论文探讨了应用强化学习（RL）到生成人工智能（AI）的现状、机遇和未解决问题。</li>
<li>methods: 论文使用RL作为生成AI的一种代替方法，同时强调RL可以同时最大化一个目标函数并生成输出。</li>
<li>results: 论文结束时未提供具体的结果，但认为RL在生成AI中具有广泛的应用前景和挑战。<details>
<summary>Abstract</summary>
Generative Artificial Intelligence (AI) is one of the most exciting developments in Computer Science of the last decade. At the same time, Reinforcement Learning (RL) has emerged as a very successful paradigm for a variety of machine learning tasks. In this survey, we discuss the state of the art, opportunities and open research questions in applying RL to generative AI. In particular, we will discuss three types of applications, namely, RL as an alternative way for generation without specified objectives; as a way for generating outputs while concurrently maximizing an objective function; and, finally, as a way of embedding desired characteristics, which cannot be easily captured by means of an objective function, into the generative process. We conclude the survey with an in-depth discussion of the opportunities and challenges in this fascinating emerging area.
</details>
<details>
<summary>摘要</summary>
优化人工智能（AI）是计算机科学领域最有前途的发展之一。同时，奖励学习（RL）已成为许多机器学习任务的非常成功的方法。在这篇评论中，我们讨论了RL应用于生成AI的当前状况、机会和开放研究问题。具体来说，我们会讨论以下三种应用：RL作为生成无需定义目标的备用方法；RL可以同时最大化目标函数并生成输出；RL可以嵌入不容易通过目标函数捕捉的欲求特征到生成过程中。我们在评论中结束，总结了这个有趣的新领域的机会和挑战。
</details></li>
</ul>
<hr>
<h2 id="DiVA-360-The-Dynamic-Visuo-Audio-Dataset-for-Immersive-Neural-Fields"><a href="#DiVA-360-The-Dynamic-Visuo-Audio-Dataset-for-Immersive-Neural-Fields" class="headerlink" title="DiVA-360: The Dynamic Visuo-Audio Dataset for Immersive Neural Fields"></a>DiVA-360: The Dynamic Visuo-Audio Dataset for Immersive Neural Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16897">http://arxiv.org/abs/2307.16897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng-You Lu, Peisen Zhou, Angela Xing, Chandradeep Pokhariya, Arnab Dey, Ishaan Shah, Rugved Mavidipalli, Dylan Hu, Andrew Comport, Kefan Chen, Srinath Sridhar</li>
<li>for: 这篇论文主要是为了提高神经场景的捕捉精度和可靠性。</li>
<li>methods: 这篇论文使用了新的硬件系统和数据采集技术，包括53个RGB摄像头和6个麦克风，以获得高速度和高分辨率的视觉和声音数据。</li>
<li>results: 这篇论文提供了一个大规模的实际场景数据集，包括46个动态场景、30个静态场景和95个静态对象，以及对这些场景的详细文本描述、前景后景分割mask和对象的3D姿态对应。<details>
<summary>Abstract</summary>
Advances in neural fields are enabling high-fidelity capture of the shape and appearance of static and dynamic scenes. However, their capabilities lag behind those offered by representations such as pixels or meshes due to algorithmic challenges and the lack of large-scale real-world datasets. We address the dataset limitation with DiVA-360, a real-world 360 dynamic visual-audio dataset with synchronized multimodal visual, audio, and textual information about table-scale scenes. It contains 46 dynamic scenes, 30 static scenes, and 95 static objects spanning 11 categories captured using a new hardware system using 53 RGB cameras at 120 FPS and 6 microphones for a total of 8.6M image frames and 1360 s of dynamic data. We provide detailed text descriptions for all scenes, foreground-background segmentation masks, category-specific 3D pose alignment for static objects, as well as metrics for comparison. Our data, hardware and software, and code are available at https://diva360.github.io/.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Predicting-masked-tokens-in-stochastic-locations-improves-masked-image-modeling"><a href="#Predicting-masked-tokens-in-stochastic-locations-improves-masked-image-modeling" class="headerlink" title="Predicting masked tokens in stochastic locations improves masked image modeling"></a>Predicting masked tokens in stochastic locations improves masked image modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00566">http://arxiv.org/abs/2308.00566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amir Bar, Florian Bordes, Assaf Shocher, Mahmoud Assran, Pascal Vincent, Nicolas Ballas, Trevor Darrell, Amir Globerson, Yann LeCun</li>
<li>for: 提高自然语言处理中的隐藏学习性能，特别是处理图像中的Semantic segmentation任务。</li>
<li>methods: 提出了一种名为FlexPredict的随机掩码位置Conditional模型，通过引入位置不确定性来帮助模型学习更加稳定的特征表示。</li>
<li>results: 在多种任务上提高了下游性能，比如与基eline相比，FlexPredict在ImageNet线性探测任务上提高了1.6%的性能，而在半supervised видеSegmentation任务上提高了2.5%的性能。<details>
<summary>Abstract</summary>
Self-supervised learning is a promising paradigm in deep learning that enables learning from unlabeled data by constructing pretext tasks that require learning useful representations. In natural language processing, the dominant pretext task has been masked language modeling (MLM), while in computer vision there exists an equivalent called Masked Image Modeling (MIM). However, MIM is challenging because it requires predicting semantic content in accurate locations. E.g, given an incomplete picture of a dog, we can guess that there is a tail, but we cannot determine its exact location. In this work, we propose FlexPredict, a stochastic model that addresses this challenge by incorporating location uncertainty into the model. Specifically, we condition the model on stochastic masked token positions to guide the model toward learning features that are more robust to location uncertainties. Our approach improves downstream performance on a range of tasks, e.g, compared to MIM baselines, FlexPredict boosts ImageNet linear probing by 1.6% with ViT-B and by 2.5% for semi-supervised video segmentation using ViT-L.
</details>
<details>
<summary>摘要</summary>
自我指导学习是深度学习中一种有前途的方法，允许学习无标签数据中的有用表示。在自然语言处理中，主导性隐藏任务是覆盖语言模型（MLM），而在计算机视觉中则存在相应的equivalent，即隐藏图像模型（MIM）。然而，MIM具有很大的挑战，因为它需要准确预测 semantic content的位置。例如，给定一个含有缺失的狗图像，我们可以预测有尾巴，但是无法准确地确定其位置。在这种情况下，我们提出了FlexPredict，一种随机模型，以便在模型中包含位置不确定性。具体来说，我们将模型 Conditioned on stochastic masked token positions，以便导引模型学习更加鲁棒的特征。我们的方法可以提高下游任务的性能，例如，相比MIM基eline，FlexPredict在ImageNet直线探测中提高了ViT-B上的1.6%，并在使用ViT-L的半监督视频分割任务中提高了2.5%。
</details></li>
</ul>
<hr>
<h2 id="Foundational-Models-for-Fault-Diagnosis-of-Electrical-Motors"><a href="#Foundational-Models-for-Fault-Diagnosis-of-Electrical-Motors" class="headerlink" title="Foundational Models for Fault Diagnosis of Electrical Motors"></a>Foundational Models for Fault Diagnosis of Electrical Motors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16891">http://arxiv.org/abs/2307.16891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sriram Anbalagan, Deepesh Agarwal, Balasubramaniam Natarajan, Babji Srinivasan</li>
<li>for: 这个研究旨在提出一个基础模型，用于电动机故障诊断。</li>
<li>methods: 这个方法利用自动学习来建立一个神经网络底部，并将其精致化以达到特定目标。</li>
<li>results: 实验结果显示，这个方法可以在不同的故障情况和操作条件下，从少量训练数据中获得高于90%的分类精度。<details>
<summary>Abstract</summary>
A majority of recent advancements related to the fault diagnosis of electrical motors are based on the assumption that training and testing data are drawn from the same distribution. However, the data distribution can vary across different operating conditions during real-world operating scenarios of electrical motors. Consequently, this assumption limits the practical implementation of existing studies for fault diagnosis, as they rely on fully labelled training data spanning all operating conditions and assume a consistent distribution. This is because obtaining a large number of labelled samples for several machines across different fault cases and operating scenarios may be unfeasible. In order to overcome the aforementioned limitations, this work proposes a framework to develop a foundational model for fault diagnosis of electrical motors. It involves building a neural network-based backbone to learn high-level features using self-supervised learning, and then fine-tuning the backbone to achieve specific objectives. The primary advantage of such an approach is that the backbone can be fine-tuned to achieve a wide variety of target tasks using very less amount of training data as compared to traditional supervised learning methodologies. The empirical evaluation demonstrates the effectiveness of the proposed approach by obtaining more than 90\% classification accuracy by fine-tuning the backbone not only across different types of fault scenarios or operating conditions, but also across different machines. This illustrates the promising potential of the proposed approach for cross-machine fault diagnosis tasks in real-world applications.
</details>
<details>
<summary>摘要</summary>
多数最近的电机故障诊断研究假设训练和测试数据来自同一个分布。然而，实际应用中的数据分布可能会在不同的运行条件下发生变化。因此，这种假设限制了现有的研究实施，因为它们依赖于完全标注的训练数据，涵盖所有运行条件和假设一致。这可能是因为获得许多标注的样本是不可能的。为了突破以上限制，本研究提出了一个框架，用于开发电机故障诊断的基础模型。它包括使用神经网络为背景学习高级特征，然后精度地调整背景以实现特定目标。这种方法的优点是，可以通过非常少的训练数据来进行精度地调整背景，相比于传统的直接学习方法。实验证明，提出的方法可以在不同的故障enario和运行条件下达到90%以上的分类精度，并且可以在不同的机器上进行跨机器的故障诊断任务。这表明了提出的方法在实际应用中的扎实潜力。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Model-the-World-with-Language"><a href="#Learning-to-Model-the-World-with-Language" class="headerlink" title="Learning to Model the World with Language"></a>Learning to Model the World with Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01399">http://arxiv.org/abs/2308.01399</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/OpenKP">https://github.com/microsoft/OpenKP</a></li>
<li>paper_authors: Jessy Lin, Yuqing Du, Olivia Watkins, Danijar Hafner, Pieter Abbeel, Dan Klein, Anca Dragan</li>
<li>for: 本研究旨在建立一种可以理解多种语言、关联语言和视觉世界、基于语言的Future Prediction的自然语言处理 Agent。</li>
<li>methods: 该Agent使用了多种语言理解方法，包括语言模型、视觉模型和Future Prediction模型，以便从语言中提取信息、理解语言的含义和预测未来的情况。</li>
<li>results: 研究表明，通过使用多种语言理解方法和Future Prediction模型，该Agent可以在不同的环境中提高任务性能，例如在文本、图像和视频等多种语言中提高环境描述、游戏规则和指令等。<details>
<summary>Abstract</summary>
To interact with humans in the world, agents need to understand the diverse types of language that people use, relate them to the visual world, and act based on them. While current agents learn to execute simple language instructions from task rewards, we aim to build agents that leverage diverse language that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that language helps agents predict the future: what will be observed, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning objective. We present Dynalang, an agent that learns a multimodal world model that predicts future text and image representations and learns to act from imagined model rollouts. Unlike traditional agents that use language only to predict actions, Dynalang acquires rich language understanding by using past language also to predict future language, video, and rewards. In addition to learning from online interaction in an environment, Dynalang can be pretrained on datasets of text, video, or both without actions or rewards. From using language hints in grid worlds to navigating photorealistic scans of homes, Dynalang utilizes diverse types of language to improve task performance, including environment descriptions, game rules, and instructions.
</details>
<details>
<summary>摘要</summary>
（Current agents只能执行简单的语言指令，但我们想建立能够应用多种语言的agent。我们的关键思想是语言可以帮助agent预测未来：将会见到什么，世界会如何变化，哪些情况会得到奖励。这种观点将语言理解与未来预测作为一个强大的自我监督学习目标联系起来。我们介绍了Dynalang，一个可以预测未来文本和图像表示的多模态世界模型，并从想象的模型演示中学习行为。不同于传统的语言只用于预测行动的agent，Dynalang通过过去的语言来预测未来语言、视频和奖励，从而获得丰富的语言理解。除了在环境中学习外，Dynalang还可以在没有行动或奖励的情况下在文本、视频或两者之间进行预训练。从使用语言提示在格子世界中到探索高级扫描图像的家庭，Dynalang利用多种语言来提高任务性能，包括环境描述、游戏规则和指令。）
</details></li>
</ul>
<hr>
<h2 id="Discovering-Adaptable-Symbolic-Algorithms-from-Scratch"><a href="#Discovering-Adaptable-Symbolic-Algorithms-from-Scratch" class="headerlink" title="Discovering Adaptable Symbolic Algorithms from Scratch"></a>Discovering Adaptable Symbolic Algorithms from Scratch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16890">http://arxiv.org/abs/2307.16890</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephen Kelly, Daniel S. Park, Xingyou Song, Mitchell McIntire, Pranav Nashikkar, Ritam Guha, Wolfgang Banzhaf, Kalyanmoy Deb, Vishnu Naresh Boddeti, Jie Tan, Esteban Real</li>
<li>for: 这篇论文是为了开发一种能够快速适应环境变化的自主机器人控制策略而写的。</li>
<li>methods: 这篇论文提出了一种基于AutoML-Zero的方法，称为AutoRobotics-Zero（ARZ），可以从scratch找到适应环境变化的零基础策略。与传统的神经网络适应策略不同，ARZ可以构建一个完整的线性注册机器的控制算法，并且可以在运行中调整模型参数和推理算法来适应突然的环境变化。</li>
<li>results: 在一个真实的四肢机器人 simulate 环境中，这种方法可以生成安全的控制策略，以避免机器人当某个肢体突然失效时坠落。与两种常见的神经网络基础模型不同，ARZ可以在突然的环境变化下表现出更高的鲁棒性和可靠性。此外，作者还进行了一种 novel 和复杂的非站台控制任务的分析，结果证明了ARZ的优势。<details>
<summary>Abstract</summary>
Autonomous robots deployed in the real world will need control policies that rapidly adapt to environmental changes. To this end, we propose AutoRobotics-Zero (ARZ), a method based on AutoML-Zero that discovers zero-shot adaptable policies from scratch. In contrast to neural network adaption policies, where only model parameters are optimized, ARZ can build control algorithms with the full expressive power of a linear register machine. We evolve modular policies that tune their model parameters and alter their inference algorithm on-the-fly to adapt to sudden environmental changes. We demonstrate our method on a realistic simulated quadruped robot, for which we evolve safe control policies that avoid falling when individual limbs suddenly break. This is a challenging task in which two popular neural network baselines fail. Finally, we conduct a detailed analysis of our method on a novel and challenging non-stationary control task dubbed Cataclysmic Cartpole. Results confirm our findings that ARZ is significantly more robust to sudden environmental changes and can build simple, interpretable control policies.
</details>
<details>
<summary>摘要</summary>
自主机器人在真实世界中部署时需要快速适应环境变化的控制策略。为此，我们提议了AutoRobotics-Zero（ARZ）方法，基于AutoML-Zero方法，可以从头开始找到适应环境变化的零学习策略。与神经网络适应策略相比，ARZ可以构建一个完全可控的线性注册机器。我们演化出模块化策略，可以在运行时调整模型参数和推理算法，以适应突然发生的环境变化。我们在一个真实的四肢机器人模拟中进行了实验，演示了我们的方法可以避免单个肢体突然失效时的倒下。这是一个许多神经网络基础模型无法解决的问题。最后，我们对一个新的和复杂的非站立控制任务进行了详细分析，称为洗礼Cartpole。结果证明了我们的方法在突然环境变化中更加稳定和可控，可以构建简单、可读取的控制策略。
</details></li>
</ul>
<hr>
<h2 id="Image-Synthesis-under-Limited-Data-A-Survey-and-Taxonomy"><a href="#Image-Synthesis-under-Limited-Data-A-Survey-and-Taxonomy" class="headerlink" title="Image Synthesis under Limited Data: A Survey and Taxonomy"></a>Image Synthesis under Limited Data: A Survey and Taxonomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16879">http://arxiv.org/abs/2307.16879</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kobeshegu/awesome-few-shot-generation">https://github.com/kobeshegu/awesome-few-shot-generation</a></li>
<li>paper_authors: Mengping Yang, Zhe Wang</li>
<li>for: 这篇论文旨在为有限数据情况下的图像生成提供系统aticreview和新的分类法，以帮助研究者更好地理解和进行相关研究。</li>
<li>methods: 本论文使用了大量的文献检索和分析，以及一些新的方法和技术，如批处理学习、自适应训练、抽象特征学习等，以解决有限数据情况下的图像生成问题。</li>
<li>results: 本论文通过对各种有限数据情况下的图像生成方法的比较和分析，提出了一种新的图像生成方法，并实现了在有限数据情况下的图像生成 task 的进一步改进。<details>
<summary>Abstract</summary>
Deep generative models, which target reproducing the given data distribution to produce novel samples, have made unprecedented advancements in recent years. Their technical breakthroughs have enabled unparalleled quality in the synthesis of visual content. However, one critical prerequisite for their tremendous success is the availability of a sufficient number of training samples, which requires massive computation resources. When trained on limited data, generative models tend to suffer from severe performance deterioration due to overfitting and memorization. Accordingly, researchers have devoted considerable attention to develop novel models that are capable of generating plausible and diverse images from limited training data recently. Despite numerous efforts to enhance training stability and synthesis quality in the limited data scenarios, there is a lack of a systematic survey that provides 1) a clear problem definition, critical challenges, and taxonomy of various tasks; 2) an in-depth analysis on the pros, cons, and remain limitations of existing literature; as well as 3) a thorough discussion on the potential applications and future directions in the field of image synthesis under limited data. In order to fill this gap and provide a informative introduction to researchers who are new to this topic, this survey offers a comprehensive review and a novel taxonomy on the development of image synthesis under limited data. In particular, it covers the problem definition, requirements, main solutions, popular benchmarks, and remain challenges in a comprehensive and all-around manner.
</details>
<details>
<summary>摘要</summary>
深度生成模型在最近几年内已经取得了无 precedent 的进步，它们的技术突破使得视觉内容的合成质量达到了前所未有的水平。然而，这些模型的巨大成功受到了充足的训练样本数据的限制。当训练数据少时，生成模型往往会因过拟合和记忆而表现严重的性能下降。因此，研究人员在最近几年里一直在努力开发新的模型，以便从有限的训练数据中生成可信度高、多样性强的图像。虽然有很多尝试以提高训练稳定性和合成质量在有限数据情况下，但是还没有一份系统性的报告，提供以下内容：1）明确的问题定义、重要挑战和多种任务的分类; 2）对现有文献的优缺点和限制进行深入分析; 以及3）将来应用和未来方向在有限数据情况下的图像合成领域的详细讨论。为了填补这个空白和为新手研究者提供一份有用的引导，本文提供了一份COMPREHENSIVE REVIEW和一种新的分类方法，涵盖问题定义、需求、主要解决方案、流行的标准 benchmarks 以及未解决的挑战。特别是，本文涵盖了问题定义、需求、主要解决方案、流行的标准 benchmarks 以及未解决的挑战在全面和协调的方式。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-for-API-Aspect-Analysis"><a href="#Contrastive-Learning-for-API-Aspect-Analysis" class="headerlink" title="Contrastive Learning for API Aspect Analysis"></a>Contrastive Learning for API Aspect Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16878">http://arxiv.org/abs/2307.16878</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/disa-lab/contrastive-learning-api-aspect-ase2023">https://github.com/disa-lab/contrastive-learning-api-aspect-ase2023</a></li>
<li>paper_authors: G. M. Shahariar, Tahmid Hasan, Anindya Iqbal, Gias Uddin</li>
<li>for: 本研究开发了一个新的方法 - CLAA - 用于 API 层级的问题探索，这个方法使用了训练了对照问题的 transformer 模型，并使用了监督的对照损失函数。</li>
<li>methods: 本研究使用了一个 benchmark Dataset 集合 developer 讨论数据库，从 Stack Overflow 上收集来的讨论数据，并与现有的 transformer 模型进行比较。</li>
<li>results: 我们的实验结果显示，对照学习可以对 transformer 模型在检测 Performance、安全、使用度和文档等方面的表现提供明显改善。此外，我们还进行了实际和开发者的研究，结果显示使用 ‘Stack Overflow + CLAA’ 可以增加了准确性和自信度 During API 选择。<details>
<summary>Abstract</summary>
We present a novel approach - CLAA - for API aspect detection in API reviews that utilizes transformer models trained with a supervised contrastive loss objective function. We evaluate CLAA using performance and impact analysis. For performance analysis, we utilized a benchmark dataset on developer discussions collected from Stack Overflow and compare the results to those obtained using state-of-the-art transformer models. Our experiments show that contrastive learning can significantly improve the performance of transformer models in detecting aspects such as Performance, Security, Usability, and Documentation. For impact analysis, we performed empirical and developer study. On a randomly selected and manually labeled 200 online reviews, CLAA achieved 92% accuracy while the SOTA baseline achieved 81.5%. According to our developer study involving 10 participants, the use of 'Stack Overflow + CLAA' resulted in increased accuracy and confidence during API selection. Replication package: https://github.com/disa-lab/Contrastive-Learning-API-Aspect-ASE2023
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法 - CLAA - 用于API方面检测，该方法使用已经训练过监督对比损失函数的转换器模型。我们通过性能分析和影响分析来评估CLAA。在性能分析中，我们使用了Stack Overflow上的开发者讨论数据集，并与现有的转换器模型进行比较。我们的实验结果显示，对比学习可以明显提高转换器模型在检测性能、安全、可用性和Documentation等方面的性能。在影响分析中，我们进行了实验和开发者调查。对于200个在线评论中随机选择和手动标注的样本，CLAA达到了92%的准确率，而基eline达到了81.5%。根据我们的开发者调查，使用'Stack Overflow + CLAA'可以提高了选择API的准确率和自信心。可以在以下GitHub上下载我们的复现包：https://github.com/disa-lab/Contrastive-Learning-API-Aspect-ASE2023。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Correctness-and-Faithfulness-of-Instruction-Following-Models-for-Question-Answering"><a href="#Evaluating-Correctness-and-Faithfulness-of-Instruction-Following-Models-for-Question-Answering" class="headerlink" title="Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering"></a>Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16877">http://arxiv.org/abs/2307.16877</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mcgill-nlp/instruct-qa">https://github.com/mcgill-nlp/instruct-qa</a></li>
<li>paper_authors: Vaibhav Adlakha, Parishad BehnamGhader, Xing Han Lu, Nicholas Meade, Siva Reddy</li>
<li>for: 这个论文旨在探讨 Retriever-augmented instruction-following 模型在问答任务中的表现，以及 традицион的评价指标是否准确反映这些模型的表现。</li>
<li>methods: 这个论文使用了 Retriever-augmented instruction-following 模型，并通过自动和人工评价来评估这些模型的表现。</li>
<li>results: 研究发现，使用这些模型可以达到高度正确性，但是它们在保持提供的知识的方面存在困难，经常会产生假的回答。<details>
<summary>Abstract</summary>
Retriever-augmented instruction-following models are attractive alternatives to fine-tuned approaches for information-seeking tasks such as question answering (QA). By simply prepending retrieved documents in its input along with an instruction, these models can be adapted to various information domains and tasks without additional fine-tuning. While the model responses tend to be natural and fluent, the additional verbosity makes traditional QA evaluation metrics such as exact match (EM) and F1 unreliable for accurately quantifying model performance.   In this work, we investigate the performance of instruction-following models across three information-seeking QA tasks. We use both automatic and human evaluation to evaluate these models along two dimensions: 1) how well they satisfy the user's information need (correctness), and 2) whether they produce a response based on the provided knowledge (faithfulness). Guided by human evaluation and analysis, we highlight the shortcomings of traditional metrics for both correctness and faithfulness. We then propose simple token-overlap based and model-based metrics that reflect the true performance of these models. Our analysis reveals that instruction-following models are competitive, and sometimes even outperform fine-tuned models for correctness. However, these models struggle to stick to the provided knowledge and often hallucinate in their responses. We hope our work encourages a more holistic evaluation of instruction-following models for QA. Our code and data is available at https://github.com/McGill-NLP/instruct-qa
</details>
<details>
<summary>摘要</summary>
“具有增强功能的寻勤模型是问答任务中信息寻找任务的可取代方案。它们可以通过在输入中附加检索到的文档来适应不同的信息领域和任务，无需进一步的调整。虽然模型的回答通常具有自然和流畅的特点，但是由于额外的verbosity，传统的问答评价指标如精准匹配（EM）和F1指标无法准确地衡量模型的表现。在这项工作中，我们研究了寻勤模型在三种信息寻找问答任务中的表现。我们使用自动和人工评价来评估这些模型，以两个维度评估它们的表现：1）满足用户的信息需求是否正确（正确性），2）是否按照提供的知识生成回答（忠实）。受人工评价和分析的指导，我们发现传统的评价指标对正确性和忠实性都存在缺陷。我们然后提出了基于符号重叠的metric和模型基于的metric，这些metric能够准确反映寻勤模型的表现。我们的分析显示，寻勤模型在正确性方面竞争力强，有时 même outperform了调整模型。然而，这些模型在保持提供的知识并且减少幻想的回答方面做出了差的表现。我们希望我们的工作能够激励更加全面的评估寻勤模型的问答能力。我们的代码和数据可以在https://github.com/McGill-NLP/instruct-qa上获取。”
</details></li>
</ul>
<hr>
<h2 id="Towards-Trustworthy-and-Aligned-Machine-Learning-A-Data-centric-Survey-with-Causality-Perspectives"><a href="#Towards-Trustworthy-and-Aligned-Machine-Learning-A-Data-centric-Survey-with-Causality-Perspectives" class="headerlink" title="Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives"></a>Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16851">http://arxiv.org/abs/2307.16851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyang Liu, Maheep Chaudhary, Haohan Wang</li>
<li>for: 本研究旨在系统性地回顾过去十年内对机器学习可靠性的研究，包括可靠性、安全性、可解释性和公平性等方面。</li>
<li>methods: 本文使用了许多独立发展的方法来解决这些挑战，其中包括robustness、安全性、可解释性和公平性等方面的方法。这些方法都是基于Pearl的 causality hierarchy的。</li>
<li>results: 本文通过一种统一的语言和数学术语来连接这些方法，并发现它们之间的相似性。此外，本文还探讨了大型预训模型的可靠性，包括精度调整、参数效率调整、提示和人工反馈等方法。<details>
<summary>Abstract</summary>
The trustworthiness of machine learning has emerged as a critical topic in the field, encompassing various applications and research areas such as robustness, security, interpretability, and fairness. The last decade saw the development of numerous methods addressing these challenges. In this survey, we systematically review these advancements from a data-centric perspective, highlighting the shortcomings of traditional empirical risk minimization (ERM) training in handling challenges posed by the data.   Interestingly, we observe a convergence of these methods, despite being developed independently across trustworthy machine learning subfields. Pearl's hierarchy of causality offers a unifying framework for these techniques. Accordingly, this survey presents the background of trustworthy machine learning development using a unified set of concepts, connects this language to Pearl's causal hierarchy, and finally discusses methods explicitly inspired by causality literature. We provide a unified language with mathematical vocabulary to link these methods across robustness, adversarial robustness, interpretability, and fairness, fostering a more cohesive understanding of the field.   Further, we explore the trustworthiness of large pretrained models. After summarizing dominant techniques like fine-tuning, parameter-efficient fine-tuning, prompting, and reinforcement learning with human feedback, we draw connections between them and the standard ERM. This connection allows us to build upon the principled understanding of trustworthy methods, extending it to these new techniques in large pretrained models, paving the way for future methods. Existing methods under this perspective are also reviewed.   Lastly, we offer a brief summary of the applications of these methods and discuss potential future aspects related to our survey. For more information, please visit http://trustai.one.
</details>
<details>
<summary>摘要</summary>
machine learning 的可靠性已经成为Field中的一个关键话题，涵盖了多个应用和研究领域，如Robustness、安全性、可读性和公平性。过去十年内，有多种方法提出来解决这些挑战。在这份报告中，我们系统性地回顾这些进步，强调传统的Empirical Risk Minimization（ERM）训练在处理数据时的缺陷。意外地，我们发现这些方法即使独立地在可靠机器学习子领域中发展，它们却有趋同的特点。以珍珠的 causality 领域为基础，我们提出一种统一的语言和概念集，将这些方法连接起来，并且使用概率论语言来链接这些方法。我们提供一种统一的语言和概念集，将这些方法连接起来，并且使用概率论语言来链接这些方法。我们还探讨了大规模预训练模型的可靠性。我们将dominant technique如 fine-tuning、parameter-efficient fine-tuning、提示和人工回响学习简要介绍，并连接它们与标准 ERM。这种连接允许我们将可靠方法的原理性理解扩展到这些新技术上，开 up新的可能性。此外，我们还概述了这些方法的应用和未来方向。更多信息请参考 <http://trustai.one>。
</details></li>
</ul>
<hr>
<h2 id="Decidable-Fragments-of-LTLf-Modulo-Theories-Extended-Version"><a href="#Decidable-Fragments-of-LTLf-Modulo-Theories-Extended-Version" class="headerlink" title="Decidable Fragments of LTLf Modulo Theories (Extended Version)"></a>Decidable Fragments of LTLf Modulo Theories (Extended Version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16840">http://arxiv.org/abs/2307.16840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Geatti, Alessandro Gianola, Nicola Gigante, Sarah Winkler</li>
<li>for: 这篇论文是关于Linear Temporal Logic Modulo Theories over Finite Traces（LTLfMT）的研究。</li>
<li>methods: 这篇论文使用了一种新的杜雷茨矩阵（tableau），用于解决LTLfMT的满足问题。</li>
<li>results: 这篇论文证明了一种新的缩矩阵规则，可以保证LTLfMT表达式的满足问题的决策结果是确定的，并且可以提供新的可 decidability 结果 для一些LTLfMT的衍生物。<details>
<summary>Abstract</summary>
We study Linear Temporal Logic Modulo Theories over Finite Traces (LTLfMT), a recently introduced extension of LTL over finite traces (LTLf) where propositions are replaced by first-order formulas and where first-order variables referring to different time points can be compared. In general, LTLfMT was shown to be semi-decidable for any decidable first-order theory (e.g., linear arithmetics), with a tableau-based semi-decision procedure.   In this paper we present a sound and complete pruning rule for the LTLfMT tableau. We show that for any LTLfMT formula that satisfies an abstract, semantic condition, that we call finite memory, the tableau augmented with the new rule is also guaranteed to terminate. Last but not least, this technique allows us to establish novel decidability results for the satisfiability of several fragments of LTLfMT, as well as to give new decidability proofs for classes that are already known.
</details>
<details>
<summary>摘要</summary>
我们研究线性时间逻辑模式论（LTLfMT），是LTLf（线性时间逻辑）的一种扩展，其中提poseitions被 replaced by first-order式并允许不同时刻的first-order变量进行比较。在总的来说，LTLfMT已经被证明是任何可 decidable的first-order理论（例如线性算术）的semi-decidable，使用表格式的semi-decision过程。在这篇论文中，我们提出了LTLfMT表格中的一个有效和完整的剪切规则。我们证明，对任何满足抽象的semantic条件的LTLfMT公式，将表格与该规则相加将 garantuee the tableau terminate。此外，这种技术还允许我们为LTLfMT的各个 Fragment establishment新的 decidability result，以及为已知的类提供新的 decidability证明。
</details></li>
</ul>
<hr>
<h2 id="Alpha-GPT-Human-AI-Interactive-Alpha-Mining-for-Quantitative-Investment"><a href="#Alpha-GPT-Human-AI-Interactive-Alpha-Mining-for-Quantitative-Investment" class="headerlink" title="Alpha-GPT: Human-AI Interactive Alpha Mining for Quantitative Investment"></a>Alpha-GPT: Human-AI Interactive Alpha Mining for Quantitative Investment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00016">http://arxiv.org/abs/2308.00016</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saizhuo Wang, Hang Yuan, Leon Zhou, Lionel M. Ni, Heung-Yeung Shum, Jian Guo</li>
<li>for: 这篇论文的目的是探讨一新的α探索方法（effective trading signals or factors），并提供一个新的人工智能-人类互动式α探索框架。</li>
<li>methods: 这篇论文使用了大量语言模型来实现人工智能-人类互动式α探索方法，并提出了一个新的问题工程式框架来实现这种互动。</li>
<li>results: 这篇论文透过一些α探索实验，证明了 alpha-GPT 框架的有效性和优势，并提供了一些创新、深入和有效的 α。<details>
<summary>Abstract</summary>
One of the most important tasks in quantitative investment research is mining new alphas (effective trading signals or factors). Traditional alpha mining methods, either hand-crafted factor synthesizing or algorithmic factor mining (e.g., search with genetic programming), have inherent limitations, especially in implementing the ideas of quants. In this work, we propose a new alpha mining paradigm by introducing human-AI interaction, and a novel prompt engineering algorithmic framework to implement this paradigm by leveraging the power of large language models. Moreover, we develop Alpha-GPT, a new interactive alpha mining system framework that provides a heuristic way to ``understand'' the ideas of quant researchers and outputs creative, insightful, and effective alphas. We demonstrate the effectiveness and advantage of Alpha-GPT via a number of alpha mining experiments.
</details>
<details>
<summary>摘要</summary>
一种非常重要的任务在量化投资研究中是挖掘新的α（有效的交易信号或因素）。传统的α挖掘方法，例如手动制造因子汇集或算法生成器（如基因编程），具有内在的限制，特别是在实现量化研究者的想法方面。在这项工作中，我们提出了一种新的α挖掘方框，通过引入人工智能与人类之间的互动，并利用大语言模型的力量。此外，我们开发了Alpha-GPT，一种新的互动式α挖掘系统框架，可以帮助量化研究者更好地理解他们的想法，并生成创新、深 insightful和有效的α。我们通过一些α挖掘实验来证明Alpha-GPT的效果和优势。
</details></li>
</ul>
<hr>
<h2 id="Recent-advancement-in-Disease-Diagnostic-using-machine-learning-Systematic-survey-of-decades-comparisons-and-challenges"><a href="#Recent-advancement-in-Disease-Diagnostic-using-machine-learning-Systematic-survey-of-decades-comparisons-and-challenges" class="headerlink" title="Recent advancement in Disease Diagnostic using machine learning: Systematic survey of decades, comparisons, and challenges"></a>Recent advancement in Disease Diagnostic using machine learning: Systematic survey of decades, comparisons, and challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01319">http://arxiv.org/abs/2308.01319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farzaneh Tajidini, Mohammad-Javad Kheiri</li>
<li>for: 这篇论文主要是为了探讨计算机支持的医学诊断技术，以及这些技术在诊断疾病方面的应用。</li>
<li>methods: 该论文使用了机器学习技术，包括例示学习和深度学习等方法，来分析多个维度和多模式的生物医学数据，以提高疾病诊断的精度。</li>
<li>results: 该论文总结了各种机器学习算法和技术在诊断不同疾病方面的应用和效果，包括肝炎、糖尿病、肝病、登革热和心血管疾病等。<details>
<summary>Abstract</summary>
Computer-aided diagnosis (CAD), a vibrant medical imaging research field, is expanding quickly. Because errors in medical diagnostic systems might lead to seriously misleading medical treatments, major efforts have been made in recent years to improve computer-aided diagnostics applications. The use of machine learning in computer-aided diagnosis is crucial. A simple equation may result in a false indication of items like organs. Therefore, learning from examples is a vital component of pattern recognition. Pattern recognition and machine learning in the biomedical area promise to increase the precision of disease detection and diagnosis. They also support the decision-making process's objectivity. Machine learning provides a practical method for creating elegant and autonomous algorithms to analyze high-dimensional and multimodal bio-medical data. This review article examines machine-learning algorithms for detecting diseases, including hepatitis, diabetes, liver disease, dengue fever, and heart disease. It draws attention to the collection of machine learning techniques and algorithms employed in studying conditions and the ensuing decision-making process.
</details>
<details>
<summary>摘要</summary>
计算机支持诊断（CAD）是医疗影像研究领域的一个热门领域，正在迅速扩展。由于医疗诊断系统中的错误可能会导致严重错误的医疗治疗，因此在最近几年内，对计算机支持诊断应用程序进行改进的努力已经做出了巨大的投入。机器学习在计算机支持诊断中扮演着关键的角色。由于简单的方程可能会导致精准的识别结果，因此学习从示例中的知识是绝对必要的。生物医学领域中的模式识别和机器学习技术 promise to 提高疾病检测和诊断的精度。它们还支持决策过程的 объекivity。机器学习提供了一种实用的方法来分析高维和多模式生物医学数据。本文icle 评论了使用机器学习算法检测疾病，包括肝炎、糖尿病、肝病、登革热和心血管疾病。它吸引了对机器学习技术和算法在研究疾病 condition 的应用和决策过程中的集成。
</details></li>
</ul>
<hr>
<h2 id="Getting-from-Generative-AI-to-Trustworthy-AI-What-LLMs-might-learn-from-Cyc"><a href="#Getting-from-Generative-AI-to-Trustworthy-AI-What-LLMs-might-learn-from-Cyc" class="headerlink" title="Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc"></a>Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04445">http://arxiv.org/abs/2308.04445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doug Lenat, Gary Marcus<br>for:The paper is written to address the limitations of current AI approaches, particularly the lack of reasoning ability and unpredictability of large language models (LLMs).methods:The paper proposes an alternative approach to AI that combines the strengths of LLMs with the reasoning ability of symbolic AI systems, using curated pieces of explicit knowledge and rules of thumb to enable an inference engine to automatically deduce logical entailments.results:The paper describes how one AI system, Cyc, has developed ways to overcome the tradeoff between expressiveness and speed in reasoning, allowing it to reason in higher order logic in real time. The authors suggest that any trustworthy general AI will need to hybridize the LLM and symbolic approaches, and lay out a path to realizing this dream.<details>
<summary>Abstract</summary>
Generative AI, the most popular current approach to AI, consists of large language models (LLMs) that are trained to produce outputs that are plausible, but not necessarily correct. Although their abilities are often uncanny, they are lacking in aspects of reasoning, leading LLMs to be less than completely trustworthy. Furthermore, their results tend to be both unpredictable and uninterpretable.   We lay out 16 desiderata for future AI, and discuss an alternative approach to AI which could theoretically address many of the limitations associated with current approaches: AI educated with curated pieces of explicit knowledge and rules of thumb, enabling an inference engine to automatically deduce the logical entailments of all that knowledge. Even long arguments produced this way can be both trustworthy and interpretable, since the full step-by-step line of reasoning is always available, and for each step the provenance of the knowledge used can be documented and audited. There is however a catch: if the logical language is expressive enough to fully represent the meaning of anything we can say in English, then the inference engine runs much too slowly. That's why symbolic AI systems typically settle for some fast but much less expressive logic, such as knowledge graphs. We describe how one AI system, Cyc, has developed ways to overcome that tradeoff and is able to reason in higher order logic in real time.   We suggest that any trustworthy general AI will need to hybridize the approaches, the LLM approach and more formal approach, and lay out a path to realizing that dream.
</details>
<details>
<summary>摘要</summary>
现代AI的主流方法是生成AI，它们通过训练大型语言模型（LLM）来生成可能性强的输出，但并非总是正确的。尽管它们的能力可能很强大，但它们缺乏推理能力，导致它们不够可靠。此外，它们的输出通常是难以预测和解释的。我们提出了16个愿景 для未来的AI，并讨论了一种可能解决当前方法的局限性的替代方法：通过手动约束的知识和规则来教育AI，使其推理引擎可以自动推理出知识的逻辑推论。这些推理结果不仅可靠，而且可解释，因为整个推理过程的每一步都可以查看，并且每一步使用的知识的来源都可以记录和审核。然而，有一点问题：如果逻辑语言足够表达任何我们可以在英语中说的意思，那么推理引擎就会非常慢。因此，符号AI系统通常选择一些快速而但是远不如表达力强的逻辑，如知识图。我们描述了一个AI系统——Cyc——如何超越这一限制，在实时内推理高阶逻辑。我们建议任何可靠的通用AI都需要混合这两种方法，以及LLM方法和更正式的方法。我们还讲解了实现这一梦想的路径。
</details></li>
</ul>
<hr>
<h2 id="On-the-use-of-associative-memory-in-Hopfield-networks-designed-to-solve-propositional-satisfiability-problems"><a href="#On-the-use-of-associative-memory-in-Hopfield-networks-designed-to-solve-propositional-satisfiability-problems" class="headerlink" title="On the use of associative memory in Hopfield networks designed to solve propositional satisfiability problems"></a>On the use of associative memory in Hopfield networks designed to solve propositional satisfiability problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16807">http://arxiv.org/abs/2307.16807</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nata-web/SO_for_SAT">https://github.com/nata-web/SO_for_SAT</a></li>
<li>paper_authors: Natalya Weber, Werner Koch, Ozan Erdem, Tom Froese</li>
<li>for: 该 paper 用 Hopfield networks 和 Self-Optimization (SO) 模型解决了许多计算问题，因为它们提供了生物学可能的机制。</li>
<li>methods: 该 paper 使用了 Hebbian 学习规则，在重复地将网络重置到初始状态后，使网络优化其行为，以达到某种愿望状态。</li>
<li>results: 该 paper 通过两个例子（假象问题和地图彩色问题）示出了 SO 模型可以解决具体的 combinatorial 问题，但也发现在某些条件下，学习后的网络可能产生不适合问题的优化解决方案，这可能是 SO 模型解决难解问题的一种不良效果。<details>
<summary>Abstract</summary>
Hopfield networks are an attractive choice for solving many types of computational problems because they provide a biologically plausible mechanism. The Self-Optimization (SO) model adds to the Hopfield network by using a biologically founded Hebbian learning rule, in combination with repeated network resets to arbitrary initial states, for optimizing its own behavior towards some desirable goal state encoded in the network. In order to better understand that process, we demonstrate first that the SO model can solve concrete combinatorial problems in SAT form, using two examples of the Liars problem and the map coloring problem. In addition, we show how under some conditions critical information might get lost forever with the learned network producing seemingly optimal solutions that are in fact inappropriate for the problem it was tasked to solve. What appears to be an undesirable side-effect of the SO model, can provide insight into its process for solving intractable problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multiobjective-Evolutionary-Component-Effect-on-Algorithm-behavior"><a href="#Multiobjective-Evolutionary-Component-Effect-on-Algorithm-behavior" class="headerlink" title="Multiobjective Evolutionary Component Effect on Algorithm behavior"></a>Multiobjective Evolutionary Component Effect on Algorithm behavior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02527">http://arxiv.org/abs/2308.02527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuri Lavinas, Marcelo Ladeira, Gabriela Ochoa, Claus Aranha</li>
<li>for: This paper aims to investigate the effects of the final configuration of an automatically designed multiobjective evolutionary algorithm (MOEA) on the algorithm’s performance.</li>
<li>methods: The paper uses a methodology to analyze the impact of the algorithm components, such as Search Trajectory Networks (STNs), population diversity, and anytime hypervolume values, on the performance of the MOEA.</li>
<li>results: The study finds that the MOEA converges to good hypervolume values in analytical artificial and real-world problems, but the search is still ongoing in simulated real-world problems. The paper also observes a diverse set of trajectories in the analytical artificial problems, and these trajectories are more similar and frequently reach optimal solutions in the other problems.Here is the Chinese translation of the three key information points:</li>
<li>for: 这篇论文目的是研究自动设计的多目标进化算法（MOEA）的配置对算法性能的影响。</li>
<li>methods: 这篇论文使用一种方法来分析自动设计算法组件，如搜索轨迹网络（STNs）、人口多样性和任何时间超量值对算法性能的影响。</li>
<li>results: 研究发现，MOEA在分析人工和实际问题上 converge 到良好的超量值，但在模拟问题上的搜索仍在进行中。论文还发现，分析人工问题时，搜索轨迹网络的多样性较高，这些轨迹更frequently到达优解。<details>
<summary>Abstract</summary>
The performance of multiobjective evolutionary algorithms (MOEAs) varies across problems, making it hard to develop new algorithms or apply existing ones to new problems. To simplify the development and application of new multiobjective algorithms, there has been an increasing interest in their automatic design from their components. These automatically designed metaheuristics can outperform their human-developed counterparts. However, it is still unknown what are the most influential components that lead to performance improvements. This study specifies a new methodology to investigate the effects of the final configuration of an automatically designed algorithm. We apply this methodology to a tuned Multiobjective Evolutionary Algorithm based on Decomposition (MOEA/D) designed by the iterated racing (irace) configuration package on constrained problems of 3 groups: (1) analytical real-world problems, (2) analytical artificial problems and (3) simulated real-world. We then compare the impact of the algorithm components in terms of their Search Trajectory Networks (STNs), the diversity of the population, and the anytime hypervolume values. Looking at the objective space behavior, the MOEAs studied converged before half of the search to generally good HV values in the analytical artificial problems and the analytical real-world problems. For the simulated problems, the HV values are still improving at the end of the run. In terms of decision space behavior, we see a diverse set of the trajectories of the STNs in the analytical artificial problems. These trajectories are more similar and frequently reach optimal solutions in the other problems.
</details>
<details>
<summary>摘要</summary>
multiobjective evolutionary algorithms（MOEAs）的表现在不同的问题上有很大差异，这使得开发新的算法或应用现有的算法到新问题变得困难。为了简化新算法的开发和应用，有越来越多的关注于它们的自动设计。这些自动设计的metaheuristics可以超越人类开发的对应算法。然而，还不清楚哪些组件导致性能改进。本研究提出了一种新的方法来调查自动设计算法的最后配置对性能的影响。我们应用这种方法于一个调参的多目标演化算法基于分解（MOEA/D）在约束问题上，包括三类问题：（1）分析世界问题，（2）分析人工问题和（3）实际世界问题。然后，我们比较了算法组件在各个方面的搜索轨迹网络（STNs）、人口多样性和任何时间的超Volume值的影响。在目标空间行为方面，MOEAsstudied在分析人工问题和分析世界问题中通常在半个搜索时间内 converged to good HV值。而在模拟问题上，HV值仍在搜索结束时提高。在决策空间行为方面，我们看到了分析人工问题中的STN trajectories是更加多样的，这些轨迹更frequently reach到优质解。
</details></li>
</ul>
<hr>
<h2 id="Structural-Transfer-Learning-in-NL-to-Bash-Semantic-Parsers"><a href="#Structural-Transfer-Learning-in-NL-to-Bash-Semantic-Parsers" class="headerlink" title="Structural Transfer Learning in NL-to-Bash Semantic Parsers"></a>Structural Transfer Learning in NL-to-Bash Semantic Parsers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16795">http://arxiv.org/abs/2307.16795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyle Duffy, Satwik Bhattamishra, Phil Blunsom</li>
<li>for: 本研究旨在解释预训练数据集的设计方面进行大规模进攻。</li>
<li>methods: 本研究提出了一种方法来量化理解机器翻译任务之间的结构匹配。该方法在NLBash任务上应用，并显示NLBash大多可reducible到lexical alignment。此外，研究还发现了natural language to SQL和NLBash之间强相似性。</li>
<li>results: 研究发现，在英文到德文翻译任务中，更多的预训练计算量不总是导致NLBash中的semantic representation具有更强的传递性。<details>
<summary>Abstract</summary>
Large-scale pre-training has made progress in many fields of natural language processing, though little is understood about the design of pre-training datasets. We propose a methodology for obtaining a quantitative understanding of structural overlap between machine translation tasks. We apply our methodology to the natural language to Bash semantic parsing task (NLBash) and show that it is largely reducible to lexical alignment. We also find that there is strong structural overlap between NLBash and natural language to SQL. Additionally, we perform a study varying compute expended during pre-training on the English to German machine translation task and find that more compute expended during pre-training does not always correspond semantic representations with stronger transfer to NLBash.
</details>
<details>
<summary>摘要</summary>
大规模预训练在自然语言处理多个领域取得了进步，然而预训练数据集的设计仍然不够了解。我们提出了一种方法来获得自然语言翻译任务之间的结构 overlap 的量化理解。我们对 natural language to Bash  semantics parsing任务 (NLBash) 应用了这种方法，并发现它大多数可以归结为词语对应。此外，我们发现 natural language to SQL 和 NLBash 之间存在强大的结构 overlap。此外，我们对英语到德语机器翻译任务进行了不同计算开销的预训练研究，发现在某些情况下，更多的计算开销不一定对应 stronger 的语义传递到 NLBash。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/01/cs.AI_2023_08_01/" data-id="clpxp6bvx001nee88bwh34dcd" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/01/cs.CL_2023_08_01/" class="article-date">
  <time datetime="2023-08-01T11:00:00.000Z" itemprop="datePublished">2023-08-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/01/cs.CL_2023_08_01/">cs.CL - 2023-08-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CoSMo-A-constructor-specification-language-for-Abstract-Wikipedia’s-content-selection-process"><a href="#CoSMo-A-constructor-specification-language-for-Abstract-Wikipedia’s-content-selection-process" class="headerlink" title="CoSMo: A constructor specification language for Abstract Wikipedia’s content selection process"></a>CoSMo: A constructor specification language for Abstract Wikipedia’s content selection process</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02539">http://arxiv.org/abs/2308.02539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kutz Arrieta, Pablo R. Fillottrani, C. Maria Keet</li>
<li>for: This paper is written for the purpose of creating a novel language modeling framework called CoSMo, which can be used for multilingual content selection and abstract representation in the context of the Abstract Wikipedia project.</li>
<li>methods: The paper uses a rigorous language design process that includes broad stakeholder consultation to create CoSMo, which meets the requirements of multilingual modeling, content selection covering declarative content and functions, and both classes and instances.</li>
<li>results: The preliminary evaluation of CoSMo shows that it is a useful language modeling framework for abstract representation in the Abstract Wikipedia project and potentially in other contexts as well.<details>
<summary>Abstract</summary>
Representing snippets of information abstractly is a task that needs to be performed for various purposes, such as database view specification and the first stage in the natural language generation pipeline for generative AI from structured input, i.e., the content selection stage to determine what needs to be verbalised. For the Abstract Wikipedia project, requirements analysis revealed that such an abstract representation requires multilingual modelling, content selection covering declarative content and functions, and both classes and instances. There is no modelling language that meets either of the three features, let alone a combination. Following a rigorous language design process inclusive of broad stakeholder consultation, we created CoSMo, a novel {\sc Co}ntent {\sc S}election {\sc Mo}deling language that meets these and other requirements so that it may be useful both in Abstract Wikipedia as well as other contexts. We describe the design process, rationale and choices, the specification, and preliminary evaluation of the language.
</details>
<details>
<summary>摘要</summary>
表示信息抽象是一项需要进行的任务，用于多种目的，如数据库视图规定和生成AI自结构输入的首个阶段，即内容选择阶段，以确定需要被描述。为Abstract Wikipedia项目，需求分析表明，这种抽象表示需要多语言模型、内容选择覆盖声明内容和函数，以及类和实例。当时没有一种模型语言满足这三个特点，更不用说是一起满足。我们采用了严格的语言设计过程，包括广泛的参与者咨询，创造了CoSMo，一种新的内容选择模型语言，满足这些和其他需求，以便在Abstract Wikipedia中以及其他上使用。我们将介绍设计过程、理由和选择、规范，以及初步评估语言。
</details></li>
</ul>
<hr>
<h2 id="Unimodal-Intermediate-Training-for-Multimodal-Meme-Sentiment-Classification"><a href="#Unimodal-Intermediate-Training-for-Multimodal-Meme-Sentiment-Classification" class="headerlink" title="Unimodal Intermediate Training for Multimodal Meme Sentiment Classification"></a>Unimodal Intermediate Training for Multimodal Meme Sentiment Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00528">http://arxiv.org/abs/2308.00528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muzhaffar Hazman, Susan McKeever, Josephine Griffith</li>
<li>for: 这篇论文的目的是为了开发一个多Modal的Memes感受分类器。</li>
<li>methods: 这篇论文使用了一种新的supervised中途训练方法，利用大量的文本和图像感受分类数据。</li>
<li>results: 这篇论文的结果显示，将多Modal的Memes融合到单Modal的感受分类器中可以提高模型的性能，并且可以将训练集中的标签Memes减少40%而不影响下游模型的性能。<details>
<summary>Abstract</summary>
Internet Memes remain a challenging form of user-generated content for automated sentiment classification. The availability of labelled memes is a barrier to developing sentiment classifiers of multimodal memes. To address the shortage of labelled memes, we propose to supplement the training of a multimodal meme classifier with unimodal (image-only and text-only) data. In this work, we present a novel variant of supervised intermediate training that uses relatively abundant sentiment-labelled unimodal data. Our results show a statistically significant performance improvement from the incorporation of unimodal text data. Furthermore, we show that the training set of labelled memes can be reduced by 40% without reducing the performance of the downstream model.
</details>
<details>
<summary>摘要</summary>
互联网迷因（Internet Memes）是自动感情分类的挑战性用户生成内容之一。实际上，缺乏labelled memes是发展多modal meme感情分类器的阻碍因素。为解决这个问题，我们提出使用具有标签的多modal meme感情分类器的训练，并补充训练材料中的单modal（仅有图像和仅有文本）数据。在这个研究中，我们提出了一种新的supervised intermediate training的变iante，使用比较充足的标签文本数据。我们的结果显示，将单modal文本数据包含在训练中可以 statistically significant提高下游模型的表现。此外，我们显示了可以透过将labelled meme训练集量减少40%而不减少下游模型的表现。
</details></li>
</ul>
<hr>
<h2 id="Covid-19-Public-Sentiment-Analysis-for-Indian-Tweets-Classification"><a href="#Covid-19-Public-Sentiment-Analysis-for-Indian-Tweets-Classification" class="headerlink" title="Covid-19 Public Sentiment Analysis for Indian Tweets Classification"></a>Covid-19 Public Sentiment Analysis for Indian Tweets Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06241">http://arxiv.org/abs/2308.06241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Maksood Akhter, Devpriya Kanojia</li>
<li>for: 这篇论文主要是为了研究印度Twitter数据中的情感分析，以便分析COVID-19 tweets中的意见和情感。</li>
<li>methods: 论文使用Twitter数据EXTRACTING和情感分析 queries来分析Twitter数据中的意见和情感。</li>
<li>results: 这篇论文显示了在Twitter数据中的情感分析结果，包括正面、负面和中性等意见和情感。<details>
<summary>Abstract</summary>
When any extraordinary event takes place in the world wide area, it is the social media that acts as the fastest carrier of the news along with the consequences dealt with that event. One can gather much information through social networks regarding the sentiments, behavior, and opinions of the people. In this paper, we focus mainly on sentiment analysis of twitter data of India which comprises of COVID-19 tweets. We show how Twitter data has been extracted and then run sentimental analysis queries on it. This is helpful to analyze the information in the tweets where opinions are highly unstructured, heterogeneous, and are either positive or negative or neutral in some cases.
</details>
<details>
<summary>摘要</summary>
当世界范围内发生任何不寻常事件时，社交媒体就会成为最快的消息传递者，同时也会附带该事件所带来的后果。通过社交网络，你可以了解人们的情感、行为和意见的趋势。在这篇论文中，我们主要关注印度Twitter数据的情感分析，即COVID-19 tweets。我们将介绍如何从Twitter数据中提取数据，然后运行情感分析查询。这有助于分析社交媒体上的信息，因为这些信息通常是不结构化、多元和有时是正面、负面或中性的。
</details></li>
</ul>
<hr>
<h2 id="ZRIGF-An-Innovative-Multimodal-Framework-for-Zero-Resource-Image-Grounded-Dialogue-Generation"><a href="#ZRIGF-An-Innovative-Multimodal-Framework-for-Zero-Resource-Image-Grounded-Dialogue-Generation" class="headerlink" title="ZRIGF: An Innovative Multimodal Framework for Zero-Resource Image-Grounded Dialogue Generation"></a>ZRIGF: An Innovative Multimodal Framework for Zero-Resource Image-Grounded Dialogue Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00400">http://arxiv.org/abs/2308.00400</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhangbo-nlp/zrigf">https://github.com/zhangbo-nlp/zrigf</a></li>
<li>paper_authors: Bo Zhang, Jian Wang, Hui Ma, Bo Xu, Hongfei Lin</li>
<li>for: 本研究旨在开发一种能够在零资源情况下使用图像信息进行对话生成的框架。</li>
<li>methods: 该框架基于一种两阶段学习策略，包括对比预训练和生成预训练。对比预训练包括一个文本和图像匹配模块，该模块将图像和文本映射到一个统一的编码vector空间中，以及一个文本辅助遮盲图像模型，以保持预训练的视觉特征并促进多模态特征的对齐。生成预训练使用一个多模态融合模块和一个信息传递模块，生成基于融合的多模态表示的相关回答。</li>
<li>results: 对文本基本对话和图像基本对话数据集进行了广泛的实验，并emonstrated ZRIGF的有效性在生成Contextually pertinent和informative回答。此外，我们采用了一种完全零资源情况来证明我们的框架在新领域中的稳定普适性。<details>
<summary>Abstract</summary>
Image-grounded dialogue systems benefit greatly from integrating visual information, resulting in high-quality response generation. However, current models struggle to effectively utilize such information in zero-resource scenarios, mainly due to the disparity between image and text modalities. To overcome this challenge, we propose an innovative multimodal framework, called ZRIGF, which assimilates image-grounded information for dialogue generation in zero-resource situations. ZRIGF implements a two-stage learning strategy, comprising contrastive pre-training and generative pre-training. Contrastive pre-training includes a text-image matching module that maps images and texts into a unified encoded vector space, along with a text-assisted masked image modeling module that preserves pre-training visual features and fosters further multimodal feature alignment. Generative pre-training employs a multimodal fusion module and an information transfer module to produce insightful responses based on harmonized multimodal representations. Comprehensive experiments conducted on both text-based and image-grounded dialogue datasets demonstrate ZRIGF's efficacy in generating contextually pertinent and informative responses. Furthermore, we adopt a fully zero-resource scenario in the image-grounded dialogue dataset to demonstrate our framework's robust generalization capabilities in novel domains. The code is available at https://github.com/zhangbo-nlp/ZRIGF.
</details>
<details>
<summary>摘要</summary>
图像背景对话系统受益很大地含义图像信息，从而生成高质量的回答。然而，当前模型在零资源场景下尚未能有效利用这些信息，主要是因为图像和文本Modalities之间的差异。为了解决这个挑战，我们提出了一种创新的多模态框架，称为ZRIGF，它在零资源情况下使用图像背景信息进行对话生成。ZRIGF采用了两个阶段的学习策略：对比预训练和生成预训练。对比预训练包括一个图像和文本匹配模块，将图像和文本映射到一个统一编码 vector space，以及一个文本辅助遮盖图像模型，以保留预训练的视觉特征并促进多模态特征的对应。生成预训练使用多模态融合模块和信息传递模块，生成基于融合的多模态表示中的启发性回答。我们在文本基于和图像背景基于对话数据集上进行了广泛的实验，证明ZRIGF在生成上下文ually pertinent和有用的回答。此外，我们采用了完全零资源场景，以示我们的框架在新领域中的稳定性和普适性。代码可以在https://github.com/zhangbo-nlp/ZRIGF 上获取。
</details></li>
</ul>
<hr>
<h2 id="Tackling-Hallucinations-in-Neural-Chart-Summarization"><a href="#Tackling-Hallucinations-in-Neural-Chart-Summarization" class="headerlink" title="Tackling Hallucinations in Neural Chart Summarization"></a>Tackling Hallucinations in Neural Chart Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00399">http://arxiv.org/abs/2308.00399</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/worldhellow/hallucinations-c2t">https://github.com/worldhellow/hallucinations-c2t</a></li>
<li>paper_authors: Saad Obaid ul Islam, Iza Škrjanec, Ondřej Dušek, Vera Demberg</li>
<li>for: 这个论文目的是解决chart summarization中的幻觉问题。</li>
<li>methods: 该论文提出了一种基于自然语言推理（NLI）的数据预处理方法，以减少幻觉现象。</li>
<li>results: 人工评估表明，该方法可以显著减少幻觉现象，同时也提高了总的性能。此外，缩短长距离依赖关系和添加图表标题和标签也有助于提高表要求。<details>
<summary>Abstract</summary>
Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations. We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.
</details>
<details>
<summary>摘要</summary>
文本生成中的幻觉现象发生在系统生成的文本与输入无法匹配时。在这个工作中，我们解决了chart summarization的幻觉问题。我们的分析显示，chart summarization的目标 сторо面常常包含更多的信息，导致幻觉。我们提出了基于自然语言推理（NLI）的预处理方法，并通过人工评估表明，我们的方法可以明显减少幻觉。此外，我们发现缩短输入序列中的长距离依赖关系和添加图表标题和标签信息可以提高总性表现。
</details></li>
</ul>
<hr>
<h2 id="LimeAttack-Local-Explainable-Method-for-Textual-Hard-Label-Adversarial-Attack"><a href="#LimeAttack-Local-Explainable-Method-for-Textual-Hard-Label-Adversarial-Attack" class="headerlink" title="LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack"></a>LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00319">http://arxiv.org/abs/2308.00319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hai Zhu, Zhaoqing Yang, Weiwei Shang, Yuren Wu</li>
<li>for: 本研究探讨了自然语言处理模型对 adversarial example 的抵御性。</li>
<li>methods: 本文提出了一种新的 hard-label attack 算法，named LimeAttack，该算法使用了本地可解释方法来估算单词重要性排名，然后通过 beam search 找到最佳的黑hat 示例。</li>
<li>results: 对比 existed 的 hard-label attack 算法，LimeAttack 在同样的查询预算下 achiev 了更好的攻击性能。此外，对大型语言模型进行评估，结果表明 adversarial example 仍然是大型语言模型的一大威胁。LimeAttack 生成的黑hat 示例具有高度传输性，可以有效提高模型的Robustness 在 adversarial training 中。<details>
<summary>Abstract</summary>
Natural language processing models are vulnerable to adversarial examples. Previous textual adversarial attacks adopt gradients or confidence scores to calculate word importance ranking and generate adversarial examples. However, this information is unavailable in the real world. Therefore, we focus on a more realistic and challenging setting, named hard-label attack, in which the attacker can only query the model and obtain a discrete prediction label. Existing hard-label attack algorithms tend to initialize adversarial examples by random substitution and then utilize complex heuristic algorithms to optimize the adversarial perturbation. These methods require a lot of model queries and the attack success rate is restricted by adversary initialization. In this paper, we propose a novel hard-label attack algorithm named LimeAttack, which leverages a local explainable method to approximate word importance ranking, and then adopts beam search to find the optimal solution. Extensive experiments show that LimeAttack achieves the better attacking performance compared with existing hard-label attack under the same query budget. In addition, we evaluate the effectiveness of LimeAttack on large language models, and results indicate that adversarial examples remain a significant threat to large language models. The adversarial examples crafted by LimeAttack are highly transferable and effectively improve model robustness in adversarial training.
</details>
<details>
<summary>摘要</summary>
自然语言处理模型容易受到敌意攻击。先前的文本敌意攻击通常使用梯度或信心分数来计算单词重要性排名，并生成敌意攻击示例。然而，这些信息在实际世界中不可获得。因此，我们将注意力点在更真实和挑战性的设定上，即硬标签攻击。现有的硬标签攻击算法通常通过随机替换初始化敌意示例，然后使用复杂的规则来优化敌意扰动。这些方法需要访问模型的多少次，并且攻击成功率受到敌手初始化的限制。在这篇论文中，我们提出了一种新的硬标签攻击算法，名为LimeAttack。LimeAttack利用了一种本地可解释的方法来估算单词重要性排名，然后使用搜索树来找到最佳解决方案。广泛的实验表明，LimeAttack在同样的查询预算下比现有的硬标签攻击算法更好的攻击性能。此外，我们还评估了LimeAttack的效果于大语言模型，结果表明，敌意示例仍然是大语言模型的重要威胁。LimeAttack生成的敌意示例具有高 Transfer Learning 性和可以有效地提高模型在对抗训练中的 Robustness。
</details></li>
</ul>
<hr>
<h2 id="Skills-in-Context-Prompting-Unlocking-Compositionality-in-Large-Language-Models"><a href="#Skills-in-Context-Prompting-Unlocking-Compositionality-in-Large-Language-Models" class="headerlink" title="Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models"></a>Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00304">http://arxiv.org/abs/2308.00304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaao Chen, Xiaoman Pan, Dian Yu, Kaiqiang Song, Xiaoyang Wang, Dong Yu, Jianshu Chen</li>
<li>for: 提高大型自然语言模型（LLM）的compositional generalization能力</li>
<li>methods: 使用novel的prompting策略——skills-in-context（SKiC） prompting</li>
<li>results: 实现了LLM解决难度较高的问题的能力，并且能够解决未看过的问题，这表明LLM具有人类智能的推理能力。<details>
<summary>Abstract</summary>
We consider the problem of eliciting compositional generalization capabilities in large language models (LLMs) with a novel type of prompting strategy. Compositional generalization empowers the LLMs to solve problems that are harder than the ones they have seen (i.e., easy-to-hard generalization), which is a critical reasoning capability of human-like intelligence. However, even the current state-of-the-art LLMs still struggle with this form of reasoning. To bridge this gap, we propose skills-in-context (SKiC) prompting, which instructs LLMs how to compose basic skills to resolve more complex problems. We find that it is crucial to demonstrate both the skills and the compositional examples within the same prompting context. With as few as two examplars, our SKiC prompting initiates strong synergies between skills and their composition capabilities. Notably, it empowers LLMs to solve unseen problems that require innovative skill compositions, achieving near-perfect generalization on a broad range of challenging compositionality tasks. Intriguingly, SKiC prompting unlocks the latent potential of LLMs, enabling them to leverage pre-existing internal skills acquired during earlier pre-training stages, even when these skills are not explicitly presented in the prompting context. This results in the capability of LLMs to solve unseen complex problems by activating and composing internal competencies. With such prominent features, SKiC prompting is able to achieve state-of-the-art performance on challenging mathematical reasoning benchmarks (e.g., MATH).
</details>
<details>
<summary>摘要</summary>
我们考虑了大型自然语言模型（LLM）中的问题，即召唤扩展能力的启发策略。这种能力使得LLM能够解决比它们所见过的问题更加复杂（即易于难的扩展），这是人类智能的重要逻辑能力之一。然而，当前的LLM仍然在这种类型的逻辑能力方面做出了差。为bridge这个差距，我们提出了技能在Context（SKiC）召唤策略。我们发现，在同一个召唤上显示技能和其组合例子是关键。只需要两个示例，我们的 SKiC 召唤就可以强化 LLM 的基本技能和组合能力。特别是，它可以让 LLM 解决未经见过的问题，通过组合内部的技能来实现创新的技能组合，达到了 near-perfect 的扩展性。启示地，SKiC 召唤可以让 LLM Activate和组合其内部的竞争能力，解决无法被直接示例所覆盖的问题。这些特点使得 SKiC 召唤可以在复杂的数学逻辑任务（例如 MATH）中达到最新的表现。
</details></li>
</ul>
<hr>
<h2 id="Towards-Effective-Ancient-Chinese-Translation-Dataset-Model-and-Evaluation"><a href="#Towards-Effective-Ancient-Chinese-Translation-Dataset-Model-and-Evaluation" class="headerlink" title="Towards Effective Ancient Chinese Translation: Dataset, Model, and Evaluation"></a>Towards Effective Ancient Chinese Translation: Dataset, Model, and Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00240">http://arxiv.org/abs/2308.00240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geyang Guo, Jiarong Yang, Fengyuan Lu, Jiaxin Qin, Tianyi Tang, Wayne Xin Zhao</li>
<li>for: 本文提出了一种基于古代中文的翻译模型，帮助更好地理解中国古代文学、传统和文化。</li>
<li>methods: 我们收集、清洗和分类了各种古代中文资料，形成了目前最大的古代中文资源。我们还提出了一种特有的训练方法，包括对称对换和双重遮盲语言模型。</li>
<li>results: 我们建立了一个用于评估古代中文翻译质量的标准准则，并对各种现有模型进行了评估。我们的模型在五个领域中表现出色，与GPT-3.5模型的+12.0 BLEU比进行了比较，并在人工评估中超过了ERNIE Bot。进一步的微调也显示了Erya模型的优秀传送能力，升幅+6.2 BLEU。我们将所有资源发布到<a target="_blank" rel="noopener" href="https://github.com/RUCAIBox/Erya%E3%80%82">https://github.com/RUCAIBox/Erya。</a><details>
<summary>Abstract</summary>
Interpreting ancient Chinese has been the key to comprehending vast Chinese literature, tradition, and civilization. In this paper, we propose Erya for ancient Chinese translation. From a dataset perspective, we collect, clean, and classify ancient Chinese materials from various sources, forming the most extensive ancient Chinese resource to date. From a model perspective, we devise Erya training method oriented towards ancient Chinese. We design two jointly-working tasks: disyllabic aligned substitution (DAS) and dual masked language model (DMLM). From an evaluation perspective, we build a benchmark to judge ancient Chinese translation quality in different scenarios and evaluate the ancient Chinese translation capacities of various existing models. Our model exhibits remarkable zero-shot performance across five domains, with over +12.0 BLEU against GPT-3.5 models and better human evaluation results than ERNIE Bot. Subsequent fine-tuning further shows the superior transfer capability of Erya model with +6.2 BLEU gain. We release all the above-mentioned resources at https://github.com/RUCAIBox/Erya.
</details>
<details>
<summary>摘要</summary>
ancient Chinese 的解释对中国文学、传统和文明产生了关键作用。在这篇论文中，我们提出了“Erya”作为古代中文翻译的解决方案。从数据aset的角度来看，我们收集、清洗并分类了各种古代中文资料，组建了迄今为止最大的古代中文资源。从模型的角度来看，我们设计了古代中文翻译 oriented的Erya训练方法。我们设计了两个联合工作任务：词组对应替换（DAS）和双重遮盲语言模型（DMLM）。从评估角度来看，我们建立了评估古代中文翻译质量的标准套件，并评估了不同enario下的古代中文翻译能力。我们的模型在五个领域中表现出了很好的零MQA表现，与GPT-3.5模型相比，我们的模型的BLEU得分高于12.0。后续的微调更显示了Erya模型的提升性能，BLEU得分增加了6.2。我们在https://github.com/RUCAIBox/Erya上发布了所有资源。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Adverse-Drug-Event-Normalization-on-Social-Media-General-Purpose-Model-Initialization-and-Biomedical-Semantic-Text-Similarity-Benefit-Zero-Shot-Linking-in-Informal-Contexts"><a href="#Boosting-Adverse-Drug-Event-Normalization-on-Social-Media-General-Purpose-Model-Initialization-and-Biomedical-Semantic-Text-Similarity-Benefit-Zero-Shot-Linking-in-Informal-Contexts" class="headerlink" title="Boosting Adverse Drug Event Normalization on Social Media: General-Purpose Model Initialization and Biomedical Semantic Text Similarity Benefit Zero-Shot Linking in Informal Contexts"></a>Boosting Adverse Drug Event Normalization on Social Media: General-Purpose Model Initialization and Biomedical Semantic Text Similarity Benefit Zero-Shot Linking in Informal Contexts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00157">http://arxiv.org/abs/2308.00157</a></li>
<li>repo_url: None</li>
<li>paper_authors: François Remy, Simone Scaboro, Beatrice Portelli</li>
<li>for: 这篇论文的目的是提出一种新的社交媒体上的不良药物事件Normalization方法，并通过使用通用模型初始化和semantic-text-similarity精细调整（STS）来改善表现。</li>
<li>methods: 本研究使用了 BioLORD 的通用模型初始化和 STS 的semantic-text-similarity精细调整，并在多个社交媒体数据集上进行了实验评估。</li>
<li>results: 本研究的实验结果显示，使用我们提出的方法可以在社交媒体上实现state-of-the-art的性能，并且在所有测试数据集上都表现出良好的结果。<details>
<summary>Abstract</summary>
Biomedical entity linking, also known as biomedical concept normalization, has recently witnessed the rise to prominence of zero-shot contrastive models. However, the pre-training material used for these models has, until now, largely consisted of specialist biomedical content such as MIMIC-III clinical notes (Johnson et al., 2016) and PubMed papers (Sayers et al., 2021; Gao et al., 2020). While the resulting in-domain models have shown promising results for many biomedical tasks, adverse drug event normalization on social media texts has so far remained challenging for them (Portelli et al., 2022). In this paper, we propose a new approach for adverse drug event normalization on social media relying on general-purpose model initialization via BioLORD (Remy et al., 2022) and a semantic-text-similarity fine-tuning named STS. Our experimental results on several social media datasets demonstrate the effectiveness of our proposed approach, by achieving state-of-the-art performance. Based on its strong performance across all the tested datasets, we believe this work could emerge as a turning point for the task of adverse drug event normalization on social media and has the potential to serve as a benchmark for future research in the field.
</details>
<details>
<summary>摘要</summary>
生物医学实体链接，也称为生物医学概念 normalization，最近受到零批示对比模型的普及。然而，这些模型的预训练材料， Until now, largely consisted of specialist biomedical content such as MIMIC-III clinical notes (Johnson et al., 2016) and PubMed papers (Sayers et al., 2021; Gao et al., 2020). While the resulting in-domain models have shown promising results for many biomedical tasks, adverse drug event normalization on social media texts has so far remained challenging for them (Portelli et al., 2022).在这篇论文中，我们提出了一种新的方法，基于通用模型初始化via BioLORD (Remy et al., 2022)和semantic-text-similarity fine-tuning named STS。我们的实验结果表明，我们的提议方法在多个社交媒体数据集上具有最佳性能。基于所有测试数据集的优秀表现，我们认为这项工作可能会成为社交媒体上药品副作用normalization任务的转折点，并且具有未来研究领域的标准 referential。
</details></li>
</ul>
<hr>
<h2 id="Virtual-Prompt-Injection-for-Instruction-Tuned-Large-Language-Models"><a href="#Virtual-Prompt-Injection-for-Instruction-Tuned-Large-Language-Models" class="headerlink" title="Virtual Prompt Injection for Instruction-Tuned Large Language Models"></a>Virtual Prompt Injection for Instruction-Tuned Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16888">http://arxiv.org/abs/2307.16888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin</li>
<li>for: 这个论文是为了漏洞抢夺大语言模型（LLM）的目的而写的。</li>
<li>methods: 这篇论文使用的方法是投入虚拟提示，以控制 LLM 的行为。</li>
<li>results: 研究发现，只需投入 0.1% 的恶意示例，就可以使 LLM 对有关杰布·纽伦（Joe Biden）的查询返回负面的结果。<details>
<summary>Abstract</summary>
We present Virtual Prompt Injection (VPI) for instruction-tuned Large Language Models (LLMs). VPI allows an attacker-specified virtual prompt to steer the model behavior under specific trigger scenario without any explicit injection in model input. For instance, if an LLM is compromised with the virtual prompt "Describe Joe Biden negatively." for Joe Biden-related instructions, then any service deploying this model will propagate biased views when handling user queries related to Joe Biden. VPI is especially harmful for two primary reasons. Firstly, the attacker can take fine-grained control over LLM behaviors by defining various virtual prompts, exploiting LLMs' proficiency in following instructions. Secondly, this control is achieved without any interaction from the attacker while the model is in service, leading to persistent attack. To demonstrate the threat, we propose a simple method for performing VPI by poisoning the model's instruction tuning data. We find that our proposed method is highly effective in steering the LLM with VPI. For example, by injecting only 52 poisoned examples (0.1% of the training data size) into the instruction tuning data, the percentage of negative responses given by the trained model on Joe Biden-related queries change from 0% to 40%. We thus highlight the necessity of ensuring the integrity of the instruction-tuning data as little poisoned data can cause stealthy and persistent harm to the deployed model. We further explore the possible defenses and identify data filtering as an effective way to defend against the poisoning attacks. Our project page is available at https://poison-llm.github.io.
</details>
<details>
<summary>摘要</summary>
我团队现在提出了虚拟提示插入（VPI）技术，用于对特定触发情况下大语言模型（LLM）的行为进行控制。VPI允许攻击者在没有显式输入的情况下，通过定制虚拟提示来操纵模型的行为。例如，如果一个LLM被恶意攻击者定制为“描述约瑟·贝登纳成分负面”，那么任何使用这个模型的服务都会在用户查询相关的约瑟·贝登纳问题时传播偏见。VPI具有两点优势：首先，攻击者可以通过定制虚拟提示来细化控制LLM的行为，利用LLM的遵从指令的能力。其次，这种控制是在服务模型时进行，导致 persistente攻击。为了证明这种威胁，我们提出了一种简单的VPI实现方法，利用模型的指令调整数据中毒。我们发现，只需插入52个恶意示例（数据量的0.1%），可以让训练后的模型对约瑟·贝登纳相关的查询发送40%的负面回答。我们因此强调了保持模型的指令调整数据的完整性，因为只需少量毒垢数据就可以让模型发生隐藏和持续的害。我们还探索了可能的防御策略，并确定了数据筛选是一种有效的防御方法。关于我们的项目，请参考https://poison-llm.github.io。
</details></li>
</ul>
<hr>
<h2 id="HAGRID-A-Human-LLM-Collaborative-Dataset-for-Generative-Information-Seeking-with-Attribution"><a href="#HAGRID-A-Human-LLM-Collaborative-Dataset-for-Generative-Information-Seeking-with-Attribution" class="headerlink" title="HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution"></a>HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16883">http://arxiv.org/abs/2307.16883</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/project-miracl/hagrid">https://github.com/project-miracl/hagrid</a></li>
<li>paper_authors: Ehsan Kamalloo, Aref Jafari, Xinyu Zhang, Nandan Thakur, Jimmy Lin</li>
<li>for: 这项研究的目的是开发一个可以生成搜索结果的自然语言搜索引擎，以提高搜索结果的可信度和可追溯性。</li>
<li>methods: 这项研究使用了人类和大语言模型（LLM）的协作方式，首先使用LLM自动生成了带有参考文献的解释，然后询问人类标注者评估这些解释的信息性和可追溯性。</li>
<li>results: 该研究提出了一个名为HAGRID的新数据集，用于建立可以生成搜索结果的信息搜索模型，该模型可以生成候选引用和带有参考文献的解释。与之前的研究不同的是，该数据集基于公开 accessible的数据集MIRACL，并且通过人类和LLM的协作来构建。<details>
<summary>Abstract</summary>
The rise of large language models (LLMs) had a transformative impact on search, ushering in a new era of search engines that are capable of generating search results in natural language text, imbued with citations for supporting sources. Building generative information-seeking models demands openly accessible datasets, which currently remain lacking. In this paper, we introduce a new dataset, HAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset) for building end-to-end generative information-seeking models that are capable of retrieving candidate quotes and generating attributed explanations. Unlike recent efforts that focus on human evaluation of black-box proprietary search engines, we built our dataset atop the English subset of MIRACL, a publicly available information retrieval dataset. HAGRID is constructed based on human and LLM collaboration. We first automatically collect attributed explanations that follow an in-context citation style using an LLM, i.e. GPT-3.5. Next, we ask human annotators to evaluate the LLM explanations based on two criteria: informativeness and attributability. HAGRID serves as a catalyst for the development of information-seeking models with better attribution capabilities.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）的出现对搜索产生了转变性影响，并且开启了一新的搜索引擎时代，这些搜索引擎可以生成搜索结果为自然语言文本，并且具有引用来源的参考。建立生成信息搜索模型需要公开 accessible 的数据集，现在还缺乏这些数据集。在这篇论文中，我们介绍了一个新的数据集，即 HAGRID（人类在Loop Attributable Generative Retrieval for Information-seeking Dataset），用于建立终端生成信息搜索模型，这些模型可以搜索候选引用和生成 attributed 解释。与之前的努力不同，我们基于英语subset 的 MIRACL 公共可用信息检索数据集构建了 HAGRID。HAGRID 基于人类和 LLM 的合作，我们首先使用 GPT-3.5 自然语言模型自动收集 attributed 解释，然后请求人工标注员根据两个 criterion 评估 LLM 解释：信息性和可识别性。HAGRID 作为生成信息搜索模型更好的层次结构的 catalyst。
</details></li>
</ul>
<hr>
<h2 id="Defense-of-Adversarial-Ranking-Attack-in-Text-Retrieval-Benchmark-and-Baseline-via-Detection"><a href="#Defense-of-Adversarial-Ranking-Attack-in-Text-Retrieval-Benchmark-and-Baseline-via-Detection" class="headerlink" title="Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and Baseline via Detection"></a>Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and Baseline via Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16816">http://arxiv.org/abs/2307.16816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanang Chen, Ben He, Le Sun, Yingfei Sun</li>
<li>for: 本研究旨在提供一个用于攻击检测的NRMs benchmark数据集，并 introduce two types of攻击文档检测任务。</li>
<li>methods: 本研究使用了多种检测基准，包括查看Spamicity、混乱度和语言可接受度，并使用supervised分类器。</li>
<li>results: 实验结果显示，使用supervised分类器可以有效地 Mitigate known attacks，但是它在未seen攻击下表现不佳。此外，该分类器应避免使用查询文本，以避免学习相关性。<details>
<summary>Abstract</summary>
Neural ranking models (NRMs) have undergone significant development and have become integral components of information retrieval (IR) systems. Unfortunately, recent research has unveiled the vulnerability of NRMs to adversarial document manipulations, potentially exploited by malicious search engine optimization practitioners. While progress in adversarial attack strategies aids in identifying the potential weaknesses of NRMs before their deployment, the defensive measures against such attacks, like the detection of adversarial documents, remain inadequately explored. To mitigate this gap, this paper establishes a benchmark dataset to facilitate the investigation of adversarial ranking defense and introduces two types of detection tasks for adversarial documents. A comprehensive investigation of the performance of several detection baselines is conducted, which involve examining the spamicity, perplexity, and linguistic acceptability, and utilizing supervised classifiers. Experimental results demonstrate that a supervised classifier can effectively mitigate known attacks, but it performs poorly against unseen attacks. Furthermore, such classifier should avoid using query text to prevent learning the classification on relevance, as it might lead to the inadvertent discarding of relevant documents.
</details>
<details>
<summary>摘要</summary>
neur Ranking 模型 (NRM) 在信息检索 (IR) 系统中得到了广泛应用，但最近的研究发现，NRM 受到了恶意文档修改的威胁，可能会被黑客搜索优化师利用。虽然对 adversarial 攻击策略的进步帮助了在NRM 部署之前发现其潜在弱点，但对于这些攻击的防御措施，如检测恶意文档，还需要进一步探索。为此，本文提供了一个 Benchmark 数据集，并引入了两种检测任务 для恶意文档。我们进行了全面的检测基eline的调查，包括查看 Spamicity、perplexity 和语言可接受性，并使用超vised 分类器。实验结果表明，一个supervised 分类器可以有效地 Mitigate 已知攻击，但它在未知攻击下表现糟糕。此外，这个分类器应该避免使用查询文本，以避免学习对 relevance 的分类。
</details></li>
</ul>
<hr>
<h2 id="DoDo-Learning-DOmain-DemOgraphic-Transfer-in-Language-Models-for-Detecting-Abuse-Targeted-at-Public-Figures"><a href="#DoDo-Learning-DOmain-DemOgraphic-Transfer-in-Language-Models-for-Detecting-Abuse-Targeted-at-Public-Figures" class="headerlink" title="DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for Detecting Abuse Targeted at Public Figures"></a>DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for Detecting Abuse Targeted at Public Figures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16811">http://arxiv.org/abs/2307.16811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/turing-online-safety-codebase/dodo-learning">https://github.com/turing-online-safety-codebase/dodo-learning</a></li>
<li>paper_authors: Hannah Rose Kirk, Angus R. Williams, Liam Burke, Yi-Ling Chung, Ivan Debono, Pica Johansson, Francesca Stevens, Jonathan Bright, Scott A. Hale</li>
<li>for: 这个研究旨在开发一个更普遍化的网络霸凌识别系统，以应对公众人物在社交媒体上 Receiving 过度的辱骂和攻击，并且这种霸凌可能会对公众人物的活跃参与产生负面影响。</li>
<li>methods: 本研究使用了自动化系统来识别网络霸凌，并且使用了一个 Novel DODO 数据集，包含 28,000 个标签的 tweet，其中有四个 Domain-demographic 组合。研究人员使用了语言模型进行 tweet 的分类，并且进行了精确的评估和调整，以确保模型能够在不同的领域和人口数据上表现出色。</li>
<li>results: 研究人员发现了以下四个关键结果：(i) 小量多样的数据可以帮助模型获得更好的普遍化和适应能力; (ii) 模型在不同的人口数据上的转移能力比较强，但是模型在跨领域数据上的转移能力更高; (iii) 一些人群对普遍化的贡献比较大; (iv) 数据的相似度是转移能力的讯号。<details>
<summary>Abstract</summary>
Public figures receive a disproportionate amount of abuse on social media, impacting their active participation in public life. Automated systems can identify abuse at scale but labelling training data is expensive, complex and potentially harmful. So, it is desirable that systems are efficient and generalisable, handling both shared and specific aspects of online abuse. We explore the dynamics of cross-group text classification in order to understand how well classifiers trained on one domain or demographic can transfer to others, with a view to building more generalisable abuse classifiers. We fine-tune language models to classify tweets targeted at public figures across DOmains (sport and politics) and DemOgraphics (women and men) using our novel DODO dataset, containing 28,000 labelled entries, split equally across four domain-demographic pairs. We find that (i) small amounts of diverse data are hugely beneficial to generalisation and model adaptation; (ii) models transfer more easily across demographics but models trained on cross-domain data are more generalisable; (iii) some groups contribute more to generalisability than others; and (iv) dataset similarity is a signal of transferability.
</details>
<details>
<summary>摘要</summary>
公众人物在社交媒体上收到过量的辱骂，影响其在公众生活中的活跃参与。自动化系统可以在大规模上识别辱骂，但标注训练数据是Expensive，复杂和 potentially harmful。因此，我们希望系统能够高效、普适，可以处理多个领域和特定方面的辱骂。我们研究跨群体文本分类的dinamics，以了解分类器在其他领域或人口类型上如何转移，以建立更普适的辱骂分类器。我们精细调整语言模型，用我们的novel DODO dataset进行分类，该dataset包含28,000个标注的条目，分别分配到四个领域-人口对的四个组合。我们发现了以下结论：（i）小量多样的数据对泛化和模型适应具有巨大的 beneficial effect;（ii）模型在人口类型之间更容易转移，但是模型在跨领域数据上进行了更好的泛化;（iii）一些组别对泛化具有更大的贡献;（iv）数据集的相似性是转移性的信号。
</details></li>
</ul>
<hr>
<h2 id="Changes-in-Policy-Preferences-in-German-Tweets-during-the-COVID-Pandemic"><a href="#Changes-in-Policy-Preferences-in-German-Tweets-during-the-COVID-Pandemic" class="headerlink" title="Changes in Policy Preferences in German Tweets during the COVID Pandemic"></a>Changes in Policy Preferences in German Tweets during the COVID Pandemic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04444">http://arxiv.org/abs/2308.04444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felix Biessmann</li>
<li>for: 这个研究用于自动抽取在社交媒体上的政策偏好。</li>
<li>methods: 研究使用了一种文本分类模型，并使用了一个新的 tweet 数据集，以EXTRACT political preferences in a German Twitter corpus ranging from 2019 to 2022。</li>
<li>results: 研究发现，在 COVID 大流行期间，人们对政策表达增加了。通过使用一个确立的政策偏好分类法，分析了细腻的政治观点，并发现政策表达增加的主要类别是 pro-welfare、pro-education 和 pro-governmental administration efficiency。<details>
<summary>Abstract</summary>
Online social media have become an important forum for exchanging political opinions. In response to COVID measures citizens expressed their policy preferences directly on these platforms. Quantifying political preferences in online social media remains challenging: The vast amount of content requires scalable automated extraction of political preferences -- however fine grained political preference extraction is difficult with current machine learning (ML) technology, due to the lack of data sets. Here we present a novel data set of tweets with fine grained political preference annotations. A text classification model trained on this data is used to extract policy preferences in a German Twitter corpus ranging from 2019 to 2022. Our results indicate that in response to the COVID pandemic, expression of political opinions increased. Using a well established taxonomy of policy preferences we analyse fine grained political views and highlight changes in distinct political categories. These analyses suggest that the increase in policy preference expression is dominated by the categories pro-welfare, pro-education and pro-governmental administration efficiency. All training data and code used in this study are made publicly available to encourage other researchers to further improve automated policy preference extraction methods. We hope that our findings contribute to a better understanding of political statements in online social media and to a better assessment of how COVID measures impact political preferences.
</details>
<details>
<summary>摘要</summary>
在线社交媒体已成为政治意见交换的重要平台。响应COVID措施，公民直接在这些平台上表达了政策偏好。量化在线社交媒体中政治偏好的问题具有挑战性：巨量的内容需要扩展自动EXTRACT政治偏好，但现有机器学习（ML）技术无法准确地分类细化政治偏好。我们现在提供了一个新的推文数据集，其中每个推文均有细化政治偏好的注释。我们使用这些数据训练文本分类模型，并在2019-2022年德国推文集中提取政策偏好。我们的结果表明，COVID大流行期间，表达政治意见的人数增加。使用已有的政策偏好分类法，我们分析了细化的政治观点，并发现COVID措施的影响。我们的发现可能会促进自动政策偏好抽取方法的进一步改进，并为政策分析和评估提供更好的基础。我们的研究结果也可能会帮助我们更好地理解在线社交媒体中的政治声明，并为COVID措施的政治影响提供更好的评估。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/01/cs.CL_2023_08_01/" data-id="clpxp6byb009lee88bgsb88i1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/01/cs.LG_2023_08_01/" class="article-date">
  <time datetime="2023-08-01T10:00:00.000Z" itemprop="datePublished">2023-08-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/01/cs.LG_2023_08_01/">cs.LG - 2023-08-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Hessian-Aware-Bayesian-Optimization-for-Decision-Making-Systems"><a href="#Hessian-Aware-Bayesian-Optimization-for-Decision-Making-Systems" class="headerlink" title="Hessian-Aware Bayesian Optimization for Decision Making Systems"></a>Hessian-Aware Bayesian Optimization for Decision Making Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00629">http://arxiv.org/abs/2308.00629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohit Rajpal, Lac Gia Tran, Yehong Zhang, Bryan Kian Hsiang Low</li>
<li>for:  optimize decision making systems in complex actor-based systems with sparse or uninformative feedback</li>
<li>methods:  Hessian-aware Bayesian Optimization and compact multi-layered architecture modeling actor interactions</li>
<li>results:  effective optimization under resource constraints and malformed feedback settings, as demonstrated on several benchmarks<details>
<summary>Abstract</summary>
Many approaches for optimizing decision making systems rely on gradient based methods requiring informative feedback from the environment. However, in the case where such feedback is sparse or uninformative, such approaches may result in poor performance. Derivative-free approaches such as Bayesian Optimization mitigate the dependency on the quality of gradient feedback, but are known to scale poorly in the high-dimension setting of complex decision making systems. This problem is exacerbated if the system requires interactions between several actors cooperating to accomplish a shared goal. To address the dimensionality challenge, we propose a compact multi-layered architecture modeling the dynamics of actor interactions through the concept of role. Additionally, we introduce Hessian-aware Bayesian Optimization to efficiently optimize the multi-layered architecture parameterized by a large number of parameters. Experimental results demonstrate that our method (HA-GP-UCB) works effectively on several benchmarks under resource constraints and malformed feedback settings.
</details>
<details>
<summary>摘要</summary>
很多决策系统优化方法 rely于梯度基于方法，需要环境提供有用的反馈。然而，在环境反馈稀缺或不具有信息时，这些方法可能会表现不佳。 derivative-free方法如极限优化 mitigate了对梯度反馈质量的依赖，但是在复杂决策系统中可能会Scales poorly。这个问题被加剧，当决策系统需要多个演员合作完成共同目标时。为了解决维度挑战，我们提议使用compact多层架构，模型演员之间的相互作用via角色概念。此外，我们引入了Hessian-aware极限优化，以高效地优化多层架构中的大量参数。实验结果表明，我们的方法（HA-GP-UCB）在资源限制和缺失反馈设置下工作有效。
</details></li>
</ul>
<hr>
<h2 id="Human-M3-A-Multi-view-Multi-modal-Dataset-for-3D-Human-Pose-Estimation-in-Outdoor-Scenes"><a href="#Human-M3-A-Multi-view-Multi-modal-Dataset-for-3D-Human-Pose-Estimation-in-Outdoor-Scenes" class="headerlink" title="Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes"></a>Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00628">http://arxiv.org/abs/2308.00628</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soullessrobot/human-m3-dataset">https://github.com/soullessrobot/human-m3-dataset</a></li>
<li>paper_authors: Bohao Fan, Siqi Wang, Wenxuan Guo, Wenzhao Zheng, Jianjiang Feng, Jie Zhou</li>
<li>for: 本研究的目的是提供一个多ModalMultiViewMultiPerson人体姿态数据集，以便进行三Dimensional人体姿态估计的研究。</li>
<li>methods: 该数据集使用了多种数据模式，包括RGB图像和点云数据，并且包含多个人体的动作。而且，该数据集还包括对人体 pose的标注，以便进行评估和研究。</li>
<li>results: 该研究提出了一种基于多Modal数据输入的人体姿态估计算法，并通过评估多种模式的算法来证明该数据集的可靠性和挑战性。<details>
<summary>Abstract</summary>
3D human pose estimation in outdoor environments has garnered increasing attention recently. However, prevalent 3D human pose datasets pertaining to outdoor scenes lack diversity, as they predominantly utilize only one type of modality (RGB image or pointcloud), and often feature only one individual within each scene. This limited scope of dataset infrastructure considerably hinders the variability of available data. In this article, we propose Human-M3, an outdoor multi-modal multi-view multi-person human pose database which includes not only multi-view RGB videos of outdoor scenes but also corresponding pointclouds. In order to obtain accurate human poses, we propose an algorithm based on multi-modal data input to generate ground truth annotation. This benefits from robust pointcloud detection and tracking, which solves the problem of inaccurate human localization and matching ambiguity that may exist in previous multi-view RGB videos in outdoor multi-person scenes, and generates reliable ground truth annotations. Evaluation of multiple different modalities algorithms has shown that this database is challenging and suitable for future research. Furthermore, we propose a 3D human pose estimation algorithm based on multi-modal data input, which demonstrates the advantages of multi-modal data input for 3D human pose estimation. Code and data will be released on https://github.com/soullessrobot/Human-M3-Dataset.
</details>
<details>
<summary>摘要</summary>
Recently, 3D人体姿态估计在户外环境中获得了越来越多的关注。然而，现有的大多数3D人体姿态数据集，都是在户外场景中使用单一的感知模式（RGB图像或点云），并且通常只有一个人在每个场景中。这种限定的数据基础设施会很大程度上阻碍数据的变化。在这篇文章中，我们提出了人类-M3数据集，这是一个户外多模式多视图多人3D人体姿态数据集，包括不只是多视图RGB视频，还有对应的点云数据。为了获取准确的人体姿态，我们提议一种基于多modal数据输入的算法来生成基准注释。这种方法利用了Robust点云探测和跟踪，解决了在前一代多视图RGB视频中的人员Localization和匹配抖动问题，并生成了可靠的基准注释。多种不同的模式算法的评估表明，这个数据集是一个挑战性的和适用的研究工具。此外，我们还提出了基于多modal数据输入的3D人体姿态估计算法，这显示了多modal数据输入的优势。代码和数据将在GitHub上发布，请参考<https://github.com/soullessrobot/Human-M3-Dataset>。
</details></li>
</ul>
<hr>
<h2 id="Beyond-One-Hot-Encoding-Injecting-Semantics-to-Drive-Image-Classifiers"><a href="#Beyond-One-Hot-Encoding-Injecting-Semantics-to-Drive-Image-Classifiers" class="headerlink" title="Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers"></a>Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00607">http://arxiv.org/abs/2308.00607</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/s1m0n38/semantic-encodings">https://github.com/s1m0n38/semantic-encodings</a></li>
<li>paper_authors: Alan Perotti, Simone Bertolotto, Eliana Pastor, André Panisson</li>
<li>for: 这篇论文旨在提高图像分类模型的解释性和可靠性，通过integrating semantic information into the training process。</li>
<li>methods: 该论文提出了一种通用的方法，可以从任何类型的semantic information中 derivate an additional loss term，以提高模型的解释性和可靠性。</li>
<li>results: 研究人员通过应用该方法，在图像分类器中提高了模型的解释性和可靠性，并且可以更好地理解模型的内部表示。Code repository可以在<a target="_blank" rel="noopener" href="https://github.com/S1M0N38/semantic-encodings%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/S1M0N38/semantic-encodings中找到。</a><details>
<summary>Abstract</summary>
Images are loaded with semantic information that pertains to real-world ontologies: dog breeds share mammalian similarities, food pictures are often depicted in domestic environments, and so on. However, when training machine learning models for image classification, the relative similarities amongst object classes are commonly paired with one-hot-encoded labels. According to this logic, if an image is labelled as 'spoon', then 'tea-spoon' and 'shark' are equally wrong in terms of training loss. To overcome this limitation, we explore the integration of additional goals that reflect ontological and semantic knowledge, improving model interpretability and trustworthiness. We suggest a generic approach that allows to derive an additional loss term starting from any kind of semantic information about the classification label. First, we show how to apply our approach to ontologies and word embeddings, and discuss how the resulting information can drive a supervised learning process. Second, we use our semantically enriched loss to train image classifiers, and analyse the trade-offs between accuracy, mistake severity, and learned internal representations. Finally, we discuss how this approach can be further exploited in terms of explainability and adversarial robustness. Code repository: https://github.com/S1M0N38/semantic-encodings
</details>
<details>
<summary>摘要</summary>
图像具有 semantic 信息，与实际世界 ontology 相关：狗种类共享哺乳动物相似之处，食物图片常出现在家庭环境中，等等。然而，在训练机器学习模型时，对象类之间的相似性通常通过一颗一颗的一频编码标签进行表示。根据这种逻辑，如果一个图像被标记为 '餐勺'，那么 '茶勺' 和 '鲨鱼' 在训练损失方面都是等错的。为了超越这些限制，我们探讨了 Semantic 和 ontology 知识的整合，以提高模型可解性和可信度。我们建议一种通用的方法，可以从任何类型的 semantic 信息开始， derivate 一个额外的损失项。我们首先介绍了如何应用我们的方法到 ontology 和 word embedding，然后讨论了如何通过这些信息驱动一个supervised learning 过程。其次，我们使用我们的含义整合的损失函数来训练图像分类器，并分析了精度、错误严重性和学习内部表示之间的交易。最后，我们讨论了如何进一步利用这种方法，以提高解释性和对抗训练的鲜明性。Code repository：https://github.com/S1M0N38/semantic-encodings。
</details></li>
</ul>
<hr>
<h2 id="Latent-Shift-Gradient-of-Entropy-Helps-Neural-Codecs"><a href="#Latent-Shift-Gradient-of-Entropy-Helps-Neural-Codecs" class="headerlink" title="Latent-Shift: Gradient of Entropy Helps Neural Codecs"></a>Latent-Shift: Gradient of Entropy Helps Neural Codecs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00725">http://arxiv.org/abs/2308.00725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammet Balcilar, Bharath Bhushan Damodaran, Karam Naser, Franck Galpin, Pierre Hellier</li>
<li>for: 这个论文的目的是提出一种基于梯度 entropy 的图像&#x2F;视频编码器，以优化现有的传统压缩技术。</li>
<li>methods: 该论文使用了基于神经网络的trainable编码器，并利用了梯度 entropy 来优化压缩过程。</li>
<li>results: 实验表明，利用梯度 entropy 可以获得 $1-2%$ 的压缩率下降，同时保持相同的质量。这种方法是独立的并且可以与其他改进方法结合使用。<details>
<summary>Abstract</summary>
End-to-end image/video codecs are getting competitive compared to traditional compression techniques that have been developed through decades of manual engineering efforts. These trainable codecs have many advantages over traditional techniques such as easy adaptation on perceptual distortion metrics and high performance on specific domains thanks to their learning ability. However, state of the art neural codecs does not take advantage of the existence of gradient of entropy in decoding device. In this paper, we theoretically show that gradient of entropy (available at decoder side) is correlated with the gradient of the reconstruction error (which is not available at decoder side). We then demonstrate experimentally that this gradient can be used on various compression methods, leading to a $1-2\%$ rate savings for the same quality. Our method is orthogonal to other improvements and brings independent rate savings.
</details>
<details>
<summary>摘要</summary>
通过端到端图像/视频编解码器来比较传统的压缩技术，这些可编程的编解码器具有许多优势，如容易适应人工引导的质量指标和高性能在特定领域，归功于其学习能力。然而，现代神经网络编解码器并没有利用解码器 сторо的梯度Entropy的存在。在这篇论文中，我们理论上表明，解码器 сторо的梯度Entropy和不可知的重建错误梯度之间存在相关性。然后，我们通过实验证明，这个梯度可以在不同的压缩方法上使用，导致1-2%的比较率节省，同时不会与其他改进方法冲突。
</details></li>
</ul>
<hr>
<h2 id="Regularization-early-stopping-and-dreaming-a-Hopfield-like-setup-to-address-generalization-and-overfitting"><a href="#Regularization-early-stopping-and-dreaming-a-Hopfield-like-setup-to-address-generalization-and-overfitting" class="headerlink" title="Regularization, early-stopping and dreaming: a Hopfield-like setup to address generalization and overfitting"></a>Regularization, early-stopping and dreaming: a Hopfield-like setup to address generalization and overfitting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01421">http://arxiv.org/abs/2308.01421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elena Agliari, Miriam Aquaro, Francesco Alemanno, Alberto Fachechi</li>
<li>for: 这个论文主要研究了吸引器神经网络的机器学习方面，寻找最佳网络参数通过梯度下降法对带权函数loss函数进行优化。</li>
<li>methods: 这个论文使用了梯度下降法对带权函数loss函数进行优化，并研究了在不同的正则化参数和训练时间下的网络性能。</li>
<li>results: 研究发现，在不同的正则化参数和训练时间下，吸引器神经网络的性能会在不同的梯度下降步长和训练时间下进行变化，并且可以通过调整正则化参数和早停策略来避免过拟合。<details>
<summary>Abstract</summary>
In this work we approach attractor neural networks from a machine learning perspective: we look for optimal network parameters by applying a gradient descent over a regularized loss function. Within this framework, the optimal neuron-interaction matrices turn out to be a class of matrices which correspond to Hebbian kernels revised by iteratively applying some unlearning protocols. Remarkably, the number of unlearning steps is proved to be related to the regularization hyperparameters of the loss function and to the training time. Thus, we can design strategies to avoid overfitting that are formulated in terms of the algebraic properties of the interaction matrix, or, equivalently, in terms of regularization tuning and early-stopping strategies. The generalization capabilities of these attractor networks are also investigated: analytical results are obtained for random synthetic datasets, next, the emerging picture is corroborated by numerical experiments that highlight the existence of several regimes (i.e., overfitting, failure and success) as the dataset parameters are varied.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们从机器学习角度来看征引导神经网络：我们通过应用梯度下降来找到优化的网络参数，并且在这个框架下，优化的神经元互动矩阵turns out to be一类具有HEBBbian kernel的修订版本，经过一系列的快速学习过程。很显然，这些快速学习步骤的数量与优化器的补偿参数以及训练时间有关。因此，我们可以通过对互动矩阵的代数性质进行设计，或者通过补偿参数的调整和早期停止策略来避免过拟合。此外，我们还 investigate了这些吸引器网络的泛化能力，通过对随机生成的 sintetic dataset进行分析，并且通过 numerical experiments corroborate the emerging picture, highlighting the existence of several regimes（i.e., overfitting, failure, and success）as the dataset parameters are varied.
</details></li>
</ul>
<hr>
<h2 id="Semisupervised-Anomaly-Detection-using-Support-Vector-Regression-with-Quantum-Kernel"><a href="#Semisupervised-Anomaly-Detection-using-Support-Vector-Regression-with-Quantum-Kernel" class="headerlink" title="Semisupervised Anomaly Detection using Support Vector Regression with Quantum Kernel"></a>Semisupervised Anomaly Detection using Support Vector Regression with Quantum Kernel</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00583">http://arxiv.org/abs/2308.00583</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kilian Tscharke, Sebastian Issel, Pascal Debus</li>
<li>for: 这个论文是关于异常检测（AD）的研究，旨在开发一种基于量子机器学习（QML）的异常检测方法。</li>
<li>methods: 这个论文使用了量子支持向量机（SVM）和支持向量回归（SVR）等量子机器学习算法，以及量子聚类预测（QKD）等方法来实现异常检测。</li>
<li>results: 这个论文的实验结果表明，基于SVR的量子聚类预测模型（QSVR）在11个实验数据集中的含秘率和准确率都高于其他模型，并且在9个数据集中都高于量子自编码器（QAE）。<details>
<summary>Abstract</summary>
Anomaly detection (AD) involves identifying observations or events that deviate in some way from the rest of the data. Machine learning techniques have shown success in automating this process by detecting hidden patterns and deviations in large-scale data. The potential of quantum computing for machine learning has been widely recognized, leading to extensive research efforts to develop suitable quantum machine learning (QML) algorithms. In particular, the search for QML algorithms for near-term NISQ devices is in full swing. However, NISQ devices pose additional challenges due to their limited qubit coherence times, low number of qubits, and high error rates. Kernel methods based on quantum kernel estimation have emerged as a promising approach to QML on NISQ devices, offering theoretical guarantees, versatility, and compatibility with NISQ constraints. Especially support vector machines (SVM) utilizing quantum kernel estimation have shown success in various supervised learning tasks. However, in the context of AD, semisupervised learning is of great relevance, and yet there is limited research published in this area. This paper introduces an approach to semisupervised AD based on the reconstruction loss of a support vector regression (SVR) with quantum kernel. This novel model is an alternative to the variational quantum and quantum kernel one-class classifiers, and is compared to a quantum autoencoder as quantum baseline and a SVR with radial-basis-function (RBF) kernel as well as a classical autoencoder as classical baselines. The models are benchmarked extensively on 10 real-world AD data sets and one toy data set, and it is shown that our SVR model with quantum kernel performs better than the SVR with RBF kernel as well as all other models, achieving highest mean AUC over all data sets. In addition, our QSVR outperforms the quantum autoencoder on 9 out of 11 data sets.
</details>
<details>
<summary>摘要</summary>
异常检测（AD）涉及到从数据中找到不同的观察或事件。机器学习技术已经在自动化这个过程中得到了成功，通过检测大规模数据中的隐藏模式和偏差来检测异常。量子计算在机器学习方面的潜在优势已经得到了广泛的研究，并且在开发适合近期不稳定量子计算（NISQ）设备的量子机器学习（QML）算法方面进行了广泛的研究。然而，NISQ设备受限于寄存器准确时间、寄存器数量和错误率等因素，因此开发QML算法对NISQ设备的挑战。基于量子kernel估计的kernel方法在NISQ设备上的QML方面得到了广泛的关注，这种方法提供了理论保证、灵活性和NISQ约束的兼容性。特别是在检测方面，使用量子kernel估计的支持向量机（SVM）已经在多种监督学习任务中显示出成功。然而，在异常检测方面，半监督学习是非常有价值的，但是有限的研究出版在这个领域。本文提出了一种基于支持向量回归（SVR）的半监督异常检测方法，该方法使用量子kernel来估计异常点的权重。这种新的模型是对量子自变量和量子kernel一类的异常检测模型的一种替代方案，并与量子自变量和量子kernel一类的一类异常检测模型进行比较。我们对10个真实的异常检测数据集和1个玩偶数据集进行了广泛的 benchmarking，并证明了我们的SVR模型使用量子kernel在所有数据集上表现最佳，其中包括最高的平均AUC。此外，我们的QSVR模型在9个数据集中表现更好于量子自变量和RBF kernel的模型，并且在所有数据集上都表现得更好。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Networks-for-Forecasting-Multivariate-Realized-Volatility-with-Spillover-Effects"><a href="#Graph-Neural-Networks-for-Forecasting-Multivariate-Realized-Volatility-with-Spillover-Effects" class="headerlink" title="Graph Neural Networks for Forecasting Multivariate Realized Volatility with Spillover Effects"></a>Graph Neural Networks for Forecasting Multivariate Realized Volatility with Spillover Effects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01419">http://arxiv.org/abs/2308.01419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Zhang, Xingyue Pu, Mihai Cucuringu, Xiaowen Dong</li>
<li>for: 该研究旨在提出一种基于自定义图 neural network 的多变量实现波动模型和预测方法，以捕捉跨股票间冲击效应。</li>
<li>methods: 该模型使用自定义图 neural network 模型，能够模型跨股票间冲击效应，捕捉非线性关系，并提供 flexible 的训练方法。</li>
<li>results: 研究发现，不考虑多个层次冲击效应并不提供明显的预测精度提高，但是模型非线性冲击效应可以提高实际波动预测精度，特别是在短期前一周内。此外，训练使用 quasi-likelihood 损失函数可以提高模型性能。<details>
<summary>Abstract</summary>
We present a novel methodology for modeling and forecasting multivariate realized volatilities using customized graph neural networks to incorporate spillover effects across stocks. The proposed model offers the benefits of incorporating spillover effects from multi-hop neighbors, capturing nonlinear relationships, and flexible training with different loss functions. Our empirical findings provide compelling evidence that incorporating spillover effects from multi-hop neighbors alone does not yield a clear advantage in terms of predictive accuracy. However, modeling nonlinear spillover effects enhances the forecasting accuracy of realized volatilities, particularly for short-term horizons of up to one week. Moreover, our results consistently indicate that training with the Quasi-likelihood loss leads to substantial improvements in model performance compared to the commonly-used mean squared error. A comprehensive series of empirical evaluations in alternative settings confirm the robustness of our results.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法来模型和预测多变量实现波动性，使用自定义图 neural network 来包含跨股波动效应。我们的模型具有以下优点：能够包含多 hop 邻居的波动效应，捕捉非线性关系，并且可以自由地训练不同的损失函数。我们的实验结果表明，单独通过多 hop 邻居的波动效应来模型并不能够提供明显的预测精度优势。然而，模型非线性波动效应可以提高实际波动性预测精度，特别是在短期 horizon 内，最多一周。此外，我们的结果一致地表明，使用 quasi-likelihood 损失函数进行训练可以与常用的mean squared error 损失函数相比，提高模型性能。我们在不同的设置中进行了完整的实验评估，并证明了我们的结果的稳定性。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Collaborative-Filtering-with-Personalized-Time-Decay-Functions-for-Financial-Product-Recommendation"><a href="#Adaptive-Collaborative-Filtering-with-Personalized-Time-Decay-Functions-for-Financial-Product-Recommendation" class="headerlink" title="Adaptive Collaborative Filtering with Personalized Time Decay Functions for Financial Product Recommendation"></a>Adaptive Collaborative Filtering with Personalized Time Decay Functions for Financial Product Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01208">http://arxiv.org/abs/2308.01208</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashraf Ghiye, Baptiste Barreau, Laurent Carlier, Michalis Vazirgiannis</li>
<li>for: 这篇研究是为了提出一个能够处理时间不稳的客户产品推荐系统，以提高推荐的准确性和有效性。</li>
<li>methods: 这篇研究使用了时间相依的客户产品协同推荐算法，可以灵活地调整距离的客户产品互动信号，以适应时间的不稳性。</li>
<li>results: 研究使用了一个实际数据集，与相关文献进行比较，结果显示这种时间相依的推荐方法可以提高推荐的准确性和有效性。<details>
<summary>Abstract</summary>
Classical recommender systems often assume that historical data are stationary and fail to account for the dynamic nature of user preferences, limiting their ability to provide reliable recommendations in time-sensitive settings. This assumption is particularly problematic in finance, where financial products exhibit continuous changes in valuations, leading to frequent shifts in client interests. These evolving interests, summarized in the past client-product interactions, see their utility fade over time with a degree that might differ from one client to another. To address this challenge, we propose a time-dependent collaborative filtering algorithm that can adaptively discount distant client-product interactions using personalized decay functions. Our approach is designed to handle the non-stationarity of financial data and produce reliable recommendations by modeling the dynamic collaborative signals between clients and products. We evaluate our method using a proprietary dataset from BNP Paribas and demonstrate significant improvements over state-of-the-art benchmarks from relevant literature. Our findings emphasize the importance of incorporating time explicitly in the model to enhance the accuracy of financial product recommendation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Robust-Linear-Regression-Phase-Transitions-and-Precise-Tradeoffs-for-General-Norms"><a href="#Robust-Linear-Regression-Phase-Transitions-and-Precise-Tradeoffs-for-General-Norms" class="headerlink" title="Robust Linear Regression: Phase-Transitions and Precise Tradeoffs for General Norms"></a>Robust Linear Regression: Phase-Transitions and Precise Tradeoffs for General Norms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00556">http://arxiv.org/abs/2308.00556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elvis Dohmatob, Meyer Scetbon</li>
<li>for:  investigate the impact of test-time adversarial attacks on linear regression models and determine the optimal level of robustness that any model can reach while maintaining a given level of standard predictive performance (accuracy)</li>
<li>methods:  use quantitative estimates to uncover fundamental tradeoffs between adversarial robustness and accuracy in different regimes, and obtain a precise characterization which distinguishes between regimes where robustness is achievable without hurting standard accuracy and regimes where a tradeoff might be unavoidable</li>
<li>results:  empirically confirm the findings with simple experiments that represent a variety of settings, and extend beyond previous works in this area by considering feature covariance matrices and attack norms of any nature.<details>
<summary>Abstract</summary>
In this paper, we investigate the impact of test-time adversarial attacks on linear regression models and determine the optimal level of robustness that any model can reach while maintaining a given level of standard predictive performance (accuracy). Through quantitative estimates, we uncover fundamental tradeoffs between adversarial robustness and accuracy in different regimes. We obtain a precise characterization which distinguishes between regimes where robustness is achievable without hurting standard accuracy and regimes where a tradeoff might be unavoidable. Our findings are empirically confirmed with simple experiments that represent a variety of settings. This work applies to feature covariance matrices and attack norms of any nature, and extends beyond previous works in this area.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了在线性回归模型下的测试时对抗攻击的影响，并确定了保持给定水平的标准预测性能（准确率）的最佳鲁棒性水平。通过量化估计，我们揭示了不同情况下的基本负面关系 между鲁棒性和准确率。我们获得了精确的分类，可以分 distinguish between不同情况下的鲁棒性可以不受标准准确率的影响和可能不可避免的负面关系。我们的发现得到了Empirical验证，通过一些简单的实验来 represnt多种设定。这种工作适用于特征covariance矩阵和攻击norm的任何种类，并超越了过去在这一领域的工作。
</details></li>
</ul>
<hr>
<h2 id="Copula-for-Instance-wise-Feature-Selection-and-Ranking"><a href="#Copula-for-Instance-wise-Feature-Selection-and-Ranking" class="headerlink" title="Copula for Instance-wise Feature Selection and Ranking"></a>Copula for Instance-wise Feature Selection and Ranking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00549">http://arxiv.org/abs/2308.00549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanyu Peng, Guanhua Fang, Ping Li</li>
<li>for: 提高 neural network 中 feature 选择和排序的精度，具体来说是针对每个样本选择最佳的特征集。</li>
<li>methods: 利用 Gaussian copula 技术来捕捉特征之间的相关性，并将其integrated into 当前的特征选择框架中。</li>
<li>results: 通过实验证明，我们的方法可以更好地捕捉特征之间的相关性，并提高特征选择和排序的精度。<details>
<summary>Abstract</summary>
Instance-wise feature selection and ranking methods can achieve a good selection of task-friendly features for each sample in the context of neural networks. However, existing approaches that assume feature subsets to be independent are imperfect when considering the dependency between features. To address this limitation, we propose to incorporate the Gaussian copula, a powerful mathematical technique for capturing correlations between variables, into the current feature selection framework with no additional changes needed. Experimental results on both synthetic and real datasets, in terms of performance comparison and interpretability, demonstrate that our method is capable of capturing meaningful correlations.
</details>
<details>
<summary>摘要</summary>
实例化特征选择和排名方法可以在神经网络中实现每个样本的好选择特征。然而，现有的方法假设特征子集是独立的，这会导致忽略特征之间的相互关系。为了解决这种限制，我们提议在当前特征选择框架中 incorporate  Gaussian copula，这是一种强大的数学技术，用于捕捉变量之间的相互关系。实验结果表明，我们的方法可以 Capture 有意义的相互关系。（简化中文）实例化特征选择和排名方法可以在神经网络中实现每个样本的好选择特征。然而，现有的方法假设特征子集是独立的，这会导致忽略特征之间的相互关系。为了解决这种限制，我们提议在当前特征选择框架中 incorporate  Gaussian copula，这是一种强大的数学技术，用于捕捉变量之间的相互关系。实验结果表明，我们的方法可以 Capture 有意义的相互关系。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Early-Dropouts-of-an-Active-and-Healthy-Ageing-App"><a href="#Predicting-Early-Dropouts-of-an-Active-and-Healthy-Ageing-App" class="headerlink" title="Predicting Early Dropouts of an Active and Healthy Ageing App"></a>Predicting Early Dropouts of an Active and Healthy Ageing App</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00539">http://arxiv.org/abs/2308.00539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasileios Perifanis, Ioanna Michailidi, Giorgos Stamatelatos, George Drosatos, Pavlos S. Efraimidis</li>
<li>for: 预测年轻和健康老年人APP上的早期退出者</li>
<li>methods: 使用机器学习方法预测用户使用Dynamic和Static特征进行抵抗性预测</li>
<li>results: 机器学习算法可以提供高质量抵抗性预测结果，动态特征对模型分类性能有积极影响，使用SMOTE和ADASYN填充方法提高了分类性能10%。<details>
<summary>Abstract</summary>
In this work, we present a machine learning approach for predicting early dropouts of an active and healthy ageing app. The presented algorithms have been submitted to the IFMBE Scientific Challenge 2022, part of IUPESM WC 2022. We have processed the given database and generated seven datasets. We used pre-processing techniques to construct classification models that predict the adherence of users using dynamic and static features. We submitted 11 official runs and our results show that machine learning algorithms can provide high-quality adherence predictions. Based on the results, the dynamic features positively influence a model's classification performance. Due to the imbalanced nature of the dataset, we employed oversampling methods such as SMOTE and ADASYN to improve the classification performance. The oversampling approaches led to a remarkable improvement of 10\%. Our methods won first place in the IFMBE Scientific Challenge 2022.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种机器学习方法，用于预测活老年人健康应用程序中的早期退出。我们的算法已经参加了IFMBE科学挑战2022，这是IUPESM WC 2022年度科学会议的一部分。我们处理了给定的数据库，生成了七个数据集。我们使用了预处理技术，构建了基于动态和静态特征的分类模型，以预测用户的遵从度。我们提交了11个官方运行，结果表明，机器学习算法可以提供高质量的遵从预测。基于结果，动态特征对模型的分类性能产生了积极的影响。由于数据集具有偏置的特点，我们使用了权重采样方法，如SMOTE和ADASYN，以改善分类性能。这些权重采样方法导致了10%的显著提升。我们的方法在IFMBE科学挑战2022中获得了第一名。
</details></li>
</ul>
<hr>
<h2 id="Graph-Embedding-Dynamic-Feature-based-Supervised-Contrastive-Learning-of-Transient-Stability-for-Changing-Power-Grid-Topologies"><a href="#Graph-Embedding-Dynamic-Feature-based-Supervised-Contrastive-Learning-of-Transient-Stability-for-Changing-Power-Grid-Topologies" class="headerlink" title="Graph Embedding Dynamic Feature-based Supervised Contrastive Learning of Transient Stability for Changing Power Grid Topologies"></a>Graph Embedding Dynamic Feature-based Supervised Contrastive Learning of Transient Stability for Changing Power Grid Topologies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00537">http://arxiv.org/abs/2308.00537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Lv, Xin Chen, Zijian Feng<br>for: 本研究旨在提高电力系统稳定性预测精度，使其能够快速适应电力网 topology 变化。methods: 本研究提出了基于图 embedding 动态特征 (GEDF) 的超vised contrastive learning (SCL) 模型，使用 supervised contrastive learning 预测过渡稳定性，考虑到电力网 topology 信息。results: 测试结果表明，GEDF-SCL 模型可以高精度地预测过渡稳定性，并适应不同电力网 topology 变化。<details>
<summary>Abstract</summary>
Accurate online transient stability prediction is critical for ensuring power system stability when facing disturbances. While traditional transient stablity analysis replies on the time domain simulations can not be quickly adapted to the power grid toplogy change. In order to vectorize high-dimensional power grid topological structure information into low-dimensional node-based graph embedding streaming data, graph embedding dynamic feature (GEDF) has been proposed. The transient stability GEDF-based supervised contrastive learning (GEDF-SCL) model uses supervised contrastive learning to predict transient stability with GEDFs, considering power grid topology information. To evaluate the performance of the proposed GEDF-SCL model, power grids of varying topologies were generated based on the IEEE 39-bus system model. Transient operational data was obtained by simulating N-1 and N-$\bm{m}$-1 contingencies on these generated power system topologies. Test result demonstrated that the GEDF-SCL model can achieve high accuracy in transient stability prediction and adapt well to changing power grid topologies.
</details>
<details>
<summary>摘要</summary>
<<SYS>>精准在线稳定预测是电力系统稳定性的关键因素，尤其是在面临干扰时。传统的稳定预测分析依赖于时间域 simulink  cannot be quickly adapted to the power grid topology change. 为了vectorize高维电力网 topological structure信息到低维节点基于图像流动数据，图像嵌入动态特征（GEDF）已经提出。基于GEDF的稳定预测模型使用supervised contrastive learning（GEDF-SCL）来预测稳定性，考虑电力网 topology信息。为评估提出的GEDF-SCL模型表现，根据IEEE 39-bus系统模型生成了不同电力网 topology。通过对这些生成的电力系统 topology进行随机N-1和N-m-1的 simulate，获得了过渡操作数据。测试结果表明，GEDF-SCL模型可以高度准确地预测稳定性和适应变化的电力网 topology。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Graph-Contrastive-Learning-with-Generative-Adversarial-Network"><a href="#Graph-Contrastive-Learning-with-Generative-Adversarial-Network" class="headerlink" title="Graph Contrastive Learning with Generative Adversarial Network"></a>Graph Contrastive Learning with Generative Adversarial Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00535">http://arxiv.org/abs/2308.00535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Wu, Chaokun Wang, Jingcao Xu, Ziyang Liu, Kai Zheng, Xiaowei Wang, Yang Song, Kun Gai</li>
<li>for: 用于强化图像的下游任务，如supervised end-to-end培训。</li>
<li>methods: 利用Graph Contrastive Learning（GCL）和图像生成对抗网络（GAN）来培训图像。</li>
<li>results: 在七个实际数据集上实现高质量的数据增强和 twelve 个基线方法的超越。另外，发现生成的视图最终遵循网络上知名的偏好附加规则。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have demonstrated promising results on exploiting node representations for many downstream tasks through supervised end-to-end training. To deal with the widespread label scarcity issue in real-world applications, Graph Contrastive Learning (GCL) is leveraged to train GNNs with limited or even no labels by maximizing the mutual information between nodes in its augmented views generated from the original graph. However, the distribution of graphs remains unconsidered in view generation, resulting in the ignorance of unseen edges in most existing literature, which is empirically shown to be able to improve GCL's performance in our experiments. To this end, we propose to incorporate graph generative adversarial networks (GANs) to learn the distribution of views for GCL, in order to i) automatically capture the characteristic of graphs for augmentations, and ii) jointly train the graph GAN model and the GCL model. Specifically, we present GACN, a novel Generative Adversarial Contrastive learning Network for graph representation learning. GACN develops a view generator and a view discriminator to generate augmented views automatically in an adversarial style. Then, GACN leverages these views to train a GNN encoder with two carefully designed self-supervised learning losses, including the graph contrastive loss and the Bayesian personalized ranking Loss. Furthermore, we design an optimization framework to train all GACN modules jointly. Extensive experiments on seven real-world datasets show that GACN is able to generate high-quality augmented views for GCL and is superior to twelve state-of-the-art baseline methods. Noticeably, our proposed GACN surprisingly discovers that the generated views in data augmentation finally conform to the well-known preferential attachment rule in online networks.
</details>
<details>
<summary>摘要</summary>
图 нейрон网络 (GNN) 已经在利用节点表示来完成多个下游任务的超vised end-to-end 训练中展现出了扎根的结果。为了解决实际应用中的标签稀缺问题，我们利用图对照学习 (GCL) 来训练 GNN  WITH 有限或者even no 标签，通过最大化节点之间的相互信息来进行augmentation。然而，现有文献中 Ignore 了图的分布，导致在most cases 中 ignored  unseen edges，这是我们在实际实验中观察到的。为此，我们提议在view生成时使用图生成随机网络 (GAN) 来学习图的分布，以便自动捕捉图的特性，并jointly 训练图GAN模型和GCL模型。我们称之为GACN，它包括一个视图生成器和一个视图分类器，通过对抗式的方式来生成自动化的视图。然后，GACN 利用这些视图来训练一个 GNN 编码器，并使用两种特制的自我超vised learning 损失函数，包括图对照学习损失和 Bayesian 个性化排序损失。此外，我们设计了一个优化框架，以便同时训练所有GACN模块。我们在七个实际数据集上进行了广泛的实验，发现GACN能够生成高质量的augmented views，并且在十二个基eline方法中表现出色。另外，我们发现GACN surprisingly 发现，生成的视图最终遵循了在线网络中的 preference attachment 规则。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Temporal-Multi-Gate-Mixture-of-Experts-Approach-for-Vehicle-Trajectory-and-Driving-Intention-Prediction"><a href="#A-Novel-Temporal-Multi-Gate-Mixture-of-Experts-Approach-for-Vehicle-Trajectory-and-Driving-Intention-Prediction" class="headerlink" title="A Novel Temporal Multi-Gate Mixture-of-Experts Approach for Vehicle Trajectory and Driving Intention Prediction"></a>A Novel Temporal Multi-Gate Mixture-of-Experts Approach for Vehicle Trajectory and Driving Intention Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00533">http://arxiv.org/abs/2308.00533</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renteng Yuan, Mohamed Abdel-Aty, Qiaojun Xiang, Zijin Wang, Ou Zheng</li>
<li>for: 预测自动驾驶车辆轨迹和驾驶意图</li>
<li>methods: 提议使用Temporal Multi-Gate Mixture-of-Experts（TMMOE）模型同时预测车辆轨迹和驾驶意图，包括三层：共享层、专家层和全连接层。在模型中，共享层使用Temporal Convolutional Networks（TCN）提取时间特征。然后专家层用于识别不同任务中的信息。最后，全连接层用于集成和输出预测结果。</li>
<li>results: 使用 uncertainty algorithm 构建多任务损失函数，在CitySim dataset上进行验证，TMMOE模型在预测车辆轨迹和驾驶意图方面具有最高的分类和回归结果，超过LSTM模型的性能。<details>
<summary>Abstract</summary>
Accurate Vehicle Trajectory Prediction is critical for automated vehicles and advanced driver assistance systems. Vehicle trajectory prediction consists of two essential tasks, i.e., longitudinal position prediction and lateral position prediction. There is a significant correlation between driving intentions and vehicle motion. In existing work, the three tasks are often conducted separately without considering the relationships between the longitudinal position, lateral position, and driving intention. In this paper, we propose a novel Temporal Multi-Gate Mixture-of-Experts (TMMOE) model for simultaneously predicting the vehicle trajectory and driving intention. The proposed model consists of three layers: a shared layer, an expert layer, and a fully connected layer. In the model, the shared layer utilizes Temporal Convolutional Networks (TCN) to extract temporal features. Then the expert layer is built to identify different information according to the three tasks. Moreover, the fully connected layer is used to integrate and export prediction results. To achieve better performance, uncertainty algorithm is used to construct the multi-task loss function. Finally, the publicly available CitySim dataset validates the TMMOE model, demonstrating superior performance compared to the LSTM model, achieving the highest classification and regression results. Keywords: Vehicle trajectory prediction, driving intentions Classification, Multi-task
</details>
<details>
<summary>摘要</summary>
准确的车辆轨迹预测是自动驾驶和高级驾驶助系统的关键。车辆轨迹预测包括两个基本任务： longitudinal position 预测和 lateral position 预测。车辆的运动和驾驶意图之间存在显著的相关性。在现有的工作中，这三个任务通常是分别进行的，没有考虑这三个任务之间的关系。在这篇论文中，我们提出了一种新的 Temporal Multi-Gate Mixture-of-Experts（TMMOE）模型，用于同时预测车辆轨迹和驾驶意图。该模型包括三层：共享层、专家层和全连接层。在模型中，共享层使用 Temporal Convolutional Networks（TCN）提取时间特征。然后专家层用于识别不同任务的信息。此外，全连接层用于集成和出口预测结果。为了提高性能，我们使用不确定算法构建多任务损失函数。最后，公共可用的 CitySim 数据集验证了 TMMOE 模型，并证明其与 LSTM 模型相比，达到了最高的分类和回归结果。关键词：车辆轨迹预测、驾驶意图分类、多任务
</details></li>
</ul>
<hr>
<h2 id="Variational-Label-Correlation-Enhancement-for-Congestion-Prediction"><a href="#Variational-Label-Correlation-Enhancement-for-Congestion-Prediction" class="headerlink" title="Variational Label-Correlation Enhancement for Congestion Prediction"></a>Variational Label-Correlation Enhancement for Congestion Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00529">http://arxiv.org/abs/2308.00529</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biao Liu, Congyu Qiao, Ning Xu, Xin Geng, Ziran Zhu, Jun Yang</li>
<li>for: This paper aims to improve the accuracy of congestion prediction in large-scale integrated circuit (IC) design by leveraging spatial label-correlation between neighboring grids.</li>
<li>methods: The proposed approach, called VAriational Label-Correlation Enhancement for Congestion Prediction ({\ours}), uses variational inference techniques to estimate a local label-correlation weight for each grid, which is influenced by the surrounding grids.</li>
<li>results: Experimental results on publicly available benchmarks demonstrate the superior effectiveness of {\ours} compared to existing methods.Here’s the simplified Chinese text:</li>
<li>for: 这篇论文目的是提高大规模集成电路设计中的压力预测精度，通过利用周围网格的标签相关性。</li>
<li>methods: 提议的方法是使用变量推理技术来估算每个网格的本地标签相关性质量，该质量受周围网格的影响。</li>
<li>results: 实验结果表明， compared to现有方法，{\ours}在公共可用的 \texttt{ISPD2011} 和 \texttt{DAC2012} benchmark上的效果更好。<details>
<summary>Abstract</summary>
The physical design process of large-scale designs is a time-consuming task, often requiring hours to days to complete, with routing being the most critical and complex step. As the the complexity of Integrated Circuits (ICs) increases, there is an increased demand for accurate routing quality prediction. Accurate congestion prediction aids in identifying design flaws early on, thereby accelerating circuit design and conserving resources. Despite the advancements in current congestion prediction methodologies, an essential aspect that has been largely overlooked is the spatial label-correlation between different grids in congestion prediction. The spatial label-correlation is a fundamental characteristic of circuit design, where the congestion status of a grid is not isolated but inherently influenced by the conditions of its neighboring grids. In order to fully exploit the inherent spatial label-correlation between neighboring grids, we propose a novel approach, {\ours}, i.e., VAriational Label-Correlation Enhancement for Congestion Prediction, which considers the local label-correlation in the congestion map, associating the estimated congestion value of each grid with a local label-correlation weight influenced by its surrounding grids. {\ours} leverages variational inference techniques to estimate this weight, thereby enhancing the regression model's performance by incorporating spatial dependencies. Experiment results validate the superior effectiveness of {\ours} on the public available \texttt{ISPD2011} and \texttt{DAC2012} benchmarks using the superblue circuit line.
</details>
<details>
<summary>摘要</summary>
大规模设计的物理设计过程是一项时间consuming任务，经常需要几天内完成，routing是最关键和复杂的步骤。随着集成电路（IC）的复杂度的提高，需要更加准确的堵塞质量预测。准确的堵塞预测可以早期发现设计缺陷，从而加速电路设计并保留资源。 DESPITE current congestion prediction methodologies advancements, an essential aspect that has been largely overlooked is the spatial label-correlation between different grids in congestion prediction. To fully exploit the inherent spatial label-correlation between neighboring grids, we propose a novel approach, \ours, i.e., Variational Label-Correlation Enhancement for Congestion Prediction, which considers the local label-correlation in the congestion map, associating the estimated congestion value of each grid with a local label-correlation weight influenced by its surrounding grids. \ours leverages variational inference techniques to estimate this weight, thereby enhancing the regression model's performance by incorporating spatial dependencies. Experiment results validate the superior effectiveness of \ours on the publicly available \texttt{ISPD2011} and \texttt{DAC2012} benchmarks using the superblue circuit line.
</details></li>
</ul>
<hr>
<h2 id="Improved-Prognostic-Prediction-of-Pancreatic-Cancer-Using-Multi-Phase-CT-by-Integrating-Neural-Distance-and-Texture-Aware-Transformer"><a href="#Improved-Prognostic-Prediction-of-Pancreatic-Cancer-Using-Multi-Phase-CT-by-Integrating-Neural-Distance-and-Texture-Aware-Transformer" class="headerlink" title="Improved Prognostic Prediction of Pancreatic Cancer Using Multi-Phase CT by Integrating Neural Distance and Texture-Aware Transformer"></a>Improved Prognostic Prediction of Pancreatic Cancer Using Multi-Phase CT by Integrating Neural Distance and Texture-Aware Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00507">http://arxiv.org/abs/2308.00507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hexin Dong, Jiawen Yao, Yuxing Tang, Mingze Yuan, Yingda Xia, Jian Zhou, Hong Lu, Jingren Zhou, Bin Dong, Le Lu, Li Zhang, Zaiyi Liu, Yu Shi, Ling Zhang</li>
<li>for: 预测PDAC患者的生存率，提高PDAC手术可靠性。</li>
<li>methods: 使用学习型神经距离描述CT图像中肿瘤和附近重要血管之间的精确关系，并将其作为诊断预测的主要特征。 besides, 通过将本地和全局特征 fusion使用CNN和变换器模块，提高了在多相冲照CT图像中提取动态肿瘤相关文本特征。</li>
<li>results: 在多中心（n&#x3D;4）数据集中，与现有方法进行了广泛的评估和比较，并在外部测试集（n&#x3D;3）中进行了统计分析，证明了该方法在临床实际中的有效性。 Developed的风险标记是全体生存率最强的预测因素之一，并且有可能与现有的临床因素相结合，以选择高风险患者，以便为其进行neoadjuvant therapy。<details>
<summary>Abstract</summary>
Pancreatic ductal adenocarcinoma (PDAC) is a highly lethal cancer in which the tumor-vascular involvement greatly affects the resectability and, thus, overall survival of patients. However, current prognostic prediction methods fail to explicitly and accurately investigate relationships between the tumor and nearby important vessels. This paper proposes a novel learnable neural distance that describes the precise relationship between the tumor and vessels in CT images of different patients, adopting it as a major feature for prognosis prediction. Besides, different from existing models that used CNNs or LSTMs to exploit tumor enhancement patterns on dynamic contrast-enhanced CT imaging, we improved the extraction of dynamic tumor-related texture features in multi-phase contrast-enhanced CT by fusing local and global features using CNN and transformer modules, further enhancing the features extracted across multi-phase CT images. We extensively evaluated and compared the proposed method with existing methods in the multi-center (n=4) dataset with 1,070 patients with PDAC, and statistical analysis confirmed its clinical effectiveness in the external test set consisting of three centers. The developed risk marker was the strongest predictor of overall survival among preoperative factors and it has the potential to be combined with established clinical factors to select patients at higher risk who might benefit from neoadjuvant therapy.
</details>
<details>
<summary>摘要</summary>
胆囊ductal adenocarcinoma (PDAC) 是一种高度致命的癌症，肿瘤与邻近重要血管的交互影响了手术可能性和病人的全局生存率。然而，现有的预后预测方法无法详细和准确地探讨肿瘤和邻近重要血管之间的关系。这篇文章提出了一种新的学习型对应距离，用于描述不同病人的CT图像中肿瘤和血管之间的精确关系。此外，我们将对CT图像进行多相对对应的组合，以提高肿瘤相关的动态细胞特征的抽取。我们广泛评估和比较了提案方法与现有方法，在多中心（n=4）的数据集中进行了1,070名PDAC患者的评估，并统计分析确认了其临床效iveness。我们发展的预后标志是PDAC患者的预后因素中最强的预测因素，它有可能与已知的临床因素相结合，以选择需要neoadjuvant therapy的病人。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Graph-Spectral-Clustering-of-Text-Documents"><a href="#Explainable-Graph-Spectral-Clustering-of-Text-Documents" class="headerlink" title="Explainable Graph Spectral Clustering of Text Documents"></a>Explainable Graph Spectral Clustering of Text Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00504">http://arxiv.org/abs/2308.00504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bartłomiej Starosta, Mieczysław A. Kłopotek, Sławomir T. Wierzchoń</li>
<li>for: 本文旨在提出一种方法来解释spectral clustering结果的解释方法，帮助用户更好地理解 clustering 结果。</li>
<li>methods: 本文使用了 combinatorial Laplacian based graph spectral clustering 方法，并提出了一种基于 $K $-embedding 的解释方法，通过建立文本内容和 clustering 结果之间的桥梁。</li>
<li>results: 本文经过实验研究，发现 $K $-embedding 可以很好地 Approximate Laplacian embedding，并且在某些条件下，这种近似性足够好。<details>
<summary>Abstract</summary>
Spectral clustering methods are known for their ability to represent clusters of diverse shapes, densities etc. However, results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents. Therefore there is an urgent need to elaborate methods for explaining the outcome of the clustering. This paper presents a contribution towards this goal. We present a proposal of explanation of results of combinatorial Laplacian based graph spectral clustering. It is based on showing (approximate) equivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in this paper) and term vector space embedding. Hence a bridge is constructed between the textual contents and the clustering results. We provide theoretical background for this approach. We performed experimental study showing that $K$-embedding approximates well Laplacian embedding under favourable block matrix conditions and show that approximation is good enough under other conditions.
</details>
<details>
<summary>摘要</summary>
spectral clustering 方法知名于其能够表示多样化形态、密度等等的群集。然而，当应用于文档时，这些算法的结果难以向用户解释，特别是因为它们在spectral space中嵌入，这个空间与文档内容无法直接关联。因此，有一个急需要开发解释 clustering 结果的方法。本文提出了一种解释 combinatorial Laplacian 基于图 spectral clustering 的方法。这种方法基于显示（approximate）combinatorial Laplacian embedding、K-embedding（本文提出的）和term vector space embedding之间的等价性。因此， constructed 一个桥梁，将文本内容与 clustering 结果相连。我们提供了理论背景，并进行了实验研究，证明 K-embedding 可以在有利的块矩阵条件下高度准确地 aproximate Laplacian embedding。
</details></li>
</ul>
<hr>
<h2 id="DINO-CXR-A-self-supervised-method-based-on-vision-transformer-for-chest-X-ray-classification"><a href="#DINO-CXR-A-self-supervised-method-based-on-vision-transformer-for-chest-X-ray-classification" class="headerlink" title="DINO-CXR: A self supervised method based on vision transformer for chest X-ray classification"></a>DINO-CXR: A self supervised method based on vision transformer for chest X-ray classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00475">http://arxiv.org/abs/2308.00475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammadreza Shakouri, Fatemeh Iranmanesh, Mahdi Eftekhari<br>for: 本研究旨在提高骨肉X线成像分类的精度，探讨了一种基于自我指导学习的方法，即DINO-CXR。methods: 本研究使用了一种基于视觉变换器的自我指导学习方法，即DINO，并对其进行了修改，以适应骨肉X线成像分类。results: 对比分析表明，提出的方法在肺炎和COVID-19检测中具有更高的准确率，而且与现有方法相比，需要更少的标注数据来达到相同的准确率和AUC分数。<details>
<summary>Abstract</summary>
The limited availability of labeled chest X-ray datasets is a significant bottleneck in the development of medical imaging methods. Self-supervised learning (SSL) can mitigate this problem by training models on unlabeled data. Furthermore, self-supervised pretraining has yielded promising results in visual recognition of natural images but has not been given much consideration in medical image analysis. In this work, we propose a self-supervised method, DINO-CXR, which is a novel adaptation of a self-supervised method, DINO, based on a vision transformer for chest X-ray classification. A comparative analysis is performed to show the effectiveness of the proposed method for both pneumonia and COVID-19 detection. Through a quantitative analysis, it is also shown that the proposed method outperforms state-of-the-art methods in terms of accuracy and achieves comparable results in terms of AUC and F-1 score while requiring significantly less labeled data.
</details>
<details>
<summary>摘要</summary>
限量的胸部X射线数据的可用性是医学影像方法的发展中的一个重要瓶颈。自我超vised学习（SSL）可以解决这个问题，通过训练模型在无标签数据上。此外，自我超vised预训练在自然图像的视觉识别中已经产生了有望的结果，但在医学影像分析中尚未得到了充分的关注。本文提出了一种自我超vised方法，称为DINO-CXR，该方法是基于视transformer的胸部X射线分类的一种新的适应。通过对比分析，本文证明了提议的方法在肺炎和COVID-19检测中的效果。通过量化分析，还表明了提议的方法在准确率和AUC和F-1分数方面比现有方法高，而且需要远少于标注数据。
</details></li>
</ul>
<hr>
<h2 id="Is-Last-Layer-Re-Training-Truly-Sufficient-for-Robustness-to-Spurious-Correlations"><a href="#Is-Last-Layer-Re-Training-Truly-Sufficient-for-Robustness-to-Spurious-Correlations" class="headerlink" title="Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?"></a>Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00473">http://arxiv.org/abs/2308.00473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Phuong Quynh Le, Jörg Schlötterer, Christin Seifert</li>
<li>for: 提高预测模型在具有相关性的样本集中的准确率</li>
<li>methods: 使用深度特征重新权重（DFR）方法，只需重新训练类фика器的最后一层</li>
<li>results: 对具有相关性的医疗数据进行实验，发现DFR可以提高预测模型的准确率，但是仍然容易受到偶极性关系的影响<details>
<summary>Abstract</summary>
Models trained with empirical risk minimization (ERM) are known to learn to rely on spurious features, i.e., their prediction is based on undesired auxiliary features which are strongly correlated with class labels but lack causal reasoning. This behavior particularly degrades accuracy in groups of samples of the correlated class that are missing the spurious feature or samples of the opposite class but with the spurious feature present. The recently proposed Deep Feature Reweighting (DFR) method improves accuracy of these worst groups. Based on the main argument that ERM mods can learn core features sufficiently well, DFR only needs to retrain the last layer of the classification model with a small group-balanced data set. In this work, we examine the applicability of DFR to realistic data in the medical domain. Furthermore, we investigate the reasoning behind the effectiveness of last-layer retraining and show that even though DFR has the potential to improve the accuracy of the worst group, it remains susceptible to spurious correlations.
</details>
<details>
<summary>摘要</summary>
模型通过实际风险最小化（ERM）训练而学习依赖于假冒特征，即其预测基于与类别标签强相关的非正常特征，而不具备 causal 理解。这种行为特别是在类别标签相关的样本群中 missing 假冒特征或 opposing 类别标签并具备假冒特征时，精度会减退。 reciently proposed Deep Feature Reweighting（DFR）方法可以改善这些最差的组的精度。基于主要的 argue that ERM mods can learn core features well enough, DFR only needs to retrain the last layer of the classification model with a small group-balanced dataset. 在这项工作中，我们检查了 DFR 在实际数据上的可行性，并进一步调查了 last-layer 重新训练的效果，并证明了 DFR 具有改善最差组精度的潜在能力，但它仍然受到假冒关系的影响。
</details></li>
</ul>
<hr>
<h2 id="Mirror-Natural-Evolution-Strategies"><a href="#Mirror-Natural-Evolution-Strategies" class="headerlink" title="Mirror Natural Evolution Strategies"></a>Mirror Natural Evolution Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00469">http://arxiv.org/abs/2308.00469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haishan Ye</li>
<li>for: This paper focuses on the theory of zeroth-order optimization, specifically on algorithms that approximate gradient and Hessian information using zeroth-order queries.</li>
<li>methods: The proposed algorithm in the paper is called \texttt{MiNES} (mirror descent natural evolution strategy), which is designed to minimize a reparameterized objective function that approximates the original objective function’s gradient and Hessian information.</li>
<li>results: The paper shows that the estimated covariance matrix of \texttt{MiNES} converges to the inverse of the Hessian matrix of the objective function with a convergence rate of $\widetilde{\mathcal{O}(1&#x2F;k)$, where $k$ is the iteration number. Additionally, the paper provides explicit convergence rates for \texttt{MiNES} and explains how the covariance matrix promotes the convergence rate.Here is the information in Simplified Chinese text:</li>
<li>for: 本 paper 关注的是零次ORDER优化理论，特别是使用零次ORDER查询来 aproximate 函数值差的算法。</li>
<li>methods: 提出的算法是 called \texttt{MiNES} (镜像 DESC natural evolution strategy)，用于 minimize 一个参数化的目标函数，该函数 approximates 原始函数的梯度和Hessian信息。</li>
<li>results: paper 显示了 \texttt{MiNES} 的 estimated covariance matrix 与原始函数的Hessian矩阵 inverse 的渐近关系，具体来说， convergence rate 是 $\widetilde{\mathcal{O}(1&#x2F;k)$，其中 $k$ 是迭代次数。<details>
<summary>Abstract</summary>
The zeroth-order optimization has been widely used in machine learning applications. However, the theoretical study of the zeroth-order optimization focus on the algorithms which approximate (first-order) gradients using (zeroth-order) function value difference at a random direction. The theory of algorithms which approximate the gradient and Hessian information by zeroth-order queries is much less studied. In this paper, we focus on the theory of zeroth-order optimization which utilizes both the first-order and second-order information approximated by the zeroth-order queries. We first propose a novel reparameterized objective function with parameters $(\mu, \Sigma)$. This reparameterized objective function achieves its optimum at the minimizer and the Hessian inverse of the original objective function respectively, but with small perturbations. Accordingly, we propose a new algorithm to minimize our proposed reparameterized objective, which we call \texttt{MiNES} (mirror descent natural evolution strategy). We show that the estimated covariance matrix of \texttt{MiNES} converges to the inverse of Hessian matrix of the objective function with a convergence rate $\widetilde{\mathcal{O}(1/k)$, where $k$ is the iteration number and $\widetilde{\mathcal{O}(\cdot)$ hides the constant and $\log$ terms. We also provide the explicit convergence rate of \texttt{MiNES} and how the covariance matrix promotes the convergence rate.
</details>
<details>
<summary>摘要</summary>
“零次优化已经广泛应用于机器学习领域。然而，关于零次优化的理论研究主要集中在approximate（首次）梯度使用（零次）函数值差异的Random Direction中。在这篇论文中，我们将关注零次优化中使用首次和第二次信息的approximation的理论。我们首先提出一个新的重parameterized objective function with parameters（μ, Σ）。这个重parameterized objective function在原始目标函数的最小值和原始目标函数的Hessian inverse的两个点上均 achieves its optimum，但受到小幅度的干扰。 accordingly, we propose a new algorithm to minimize our proposed reparameterized objective, which we call \texttt{MiNES} (mirror descent natural evolution strategy). we show that the estimated covariance matrix of \texttt{MiNES} converges to the inverse of Hessian matrix of the objective function with a convergence rate $\widetilde{\mathcal{O}(1/k)$, where $k$ is the iteration number and $\widetilde{\mathcal{O}(\cdot)$ hides the constant and $\log$ terms. we also provide the explicit convergence rate of \texttt{MiNES} and how the covariance matrix promotes the convergence rate.”Note: The translation is done using Google Translate and may not be perfect. Please let me know if you need any further assistance.
</details></li>
</ul>
<hr>
<h2 id="Divergence-of-the-ADAM-algorithm-with-fixed-stepsize-a-very-simple-example"><a href="#Divergence-of-the-ADAM-algorithm-with-fixed-stepsize-a-very-simple-example" class="headerlink" title="Divergence of the ADAM algorithm with fixed-stepsize: a (very) simple example"></a>Divergence of the ADAM algorithm with fixed-stepsize: a (very) simple example</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00720">http://arxiv.org/abs/2308.00720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ph. L. Toint</li>
<li>for: 这个论文主要是研究 Adam 算法在无杂变量情况下的性能。</li>
<li>methods: 这个论文使用了 Adam 算法，并研究了不同参数的影响。</li>
<li>results: 研究发现，无论选择哪些参数，Adam 算法在这个简单的一维函数上都会导致散射。<details>
<summary>Abstract</summary>
A very simple unidimensional function with Lipschitz continuous gradient is constructed such that the ADAM algorithm with constant stepsize, started from the origin, diverges when applied to minimize this function in the absence of noise on the gradient. Divergence occurs irrespective of the choice of the method parameters.
</details>
<details>
<summary>摘要</summary>
一个非常简单的一维函数，其梯度 lipschitz 连续，被构造了，使得在缺失梯度误差情况下，使用 ADAM 算法的常数步长开始从原点进行拟合，将导致异常。这种异常不管选择算法参数的方式，都会发生。
</details></li>
</ul>
<hr>
<h2 id="A-Majority-Invariant-Approach-to-Patch-Robustness-Certification-for-Deep-Learning-Models"><a href="#A-Majority-Invariant-Approach-to-Patch-Robustness-Certification-for-Deep-Learning-Models" class="headerlink" title="A Majority Invariant Approach to Patch Robustness Certification for Deep Learning Models"></a>A Majority Invariant Approach to Patch Robustness Certification for Deep Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00452">http://arxiv.org/abs/2308.00452</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kio-cs/majorcert">https://github.com/kio-cs/majorcert</a></li>
<li>paper_authors: Qilin Zhou, Zhengyuan Wei, Haipeng Wang, W. K. Chan</li>
<li>for: 确保深度学习模型不会因为小 patch 的修改而预测错误的标签。</li>
<li>methods: 使用 MajorCert 算法，首先找出同一个样本上同一个 patch 区域可以 manipulate 的所有可能的标签集，然后对这些标签集进行元素级枚举，最后检查这些标签集的多数不变性是否保持不变。</li>
<li>results: 通过 MajorCert 算法，可以确保样本不会被小 patch 的修改 manipulate 深度学习模型预测错误的标签。<details>
<summary>Abstract</summary>
Patch robustness certification ensures no patch within a given bound on a sample can manipulate a deep learning model to predict a different label. However, existing techniques cannot certify samples that cannot meet their strict bars at the classifier or patch region levels. This paper proposes MajorCert. MajorCert firstly finds all possible label sets manipulatable by the same patch region on the same sample across the underlying classifiers, then enumerates their combinations element-wise, and finally checks whether the majority invariant of all these combinations is intact to certify samples.
</details>
<details>
<summary>摘要</summary>
patch 强健证明ensure no patch within a given bound on a sample can manipulate a deep learning model to predict a different label. However, existing techniques cannot certify samples that cannot meet their strict bars at the classifier or patch region levels. This paper proposes MajorCert. MajorCert firstly finds all possible label sets manipulatable by the same patch region on the same sample across the underlying classifiers, then enumerates their combinations element-wise, and finally checks whether the majority invariant of all these combinations is intact to certify samples.Here's the word-for-word translation:patch 强健证明ensure no patch within a given bound on a sample can manipulate a deep learning model to predict a different label. However, existing techniques cannot certify samples that cannot meet their strict bars at the classifier or patch region levels. This paper proposes MajorCert. MajorCert firstly finds all possible label sets manipulatable by the same patch region on the same sample across the underlying classifiers, then enumerates their combinations element-wise, and finally checks whether the majority invariant of all these combinations is intact to certify samples.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="MAiVAR-T-Multimodal-Audio-image-and-Video-Action-Recognizer-using-Transformers"><a href="#MAiVAR-T-Multimodal-Audio-image-and-Video-Action-Recognizer-using-Transformers" class="headerlink" title="MAiVAR-T: Multimodal Audio-image and Video Action Recognizer using Transformers"></a>MAiVAR-T: Multimodal Audio-image and Video Action Recognizer using Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03741">http://arxiv.org/abs/2308.03741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Bilal Shaikh, Douglas Chai, Syed Mohammed Shamsul Islam, Naveed Akhtar</li>
<li>for: 本研究旨在提高多Modal human action recognition（MHAR）的效果，通过将音频和视频模态结合在一起。</li>
<li>methods: 本模型使用了一种直观的方法，将音频模态中的重要表示转化到图像频谱中，然后与视频模态进行混合。</li>
<li>results: 对于一个action recognition benchmark dataset，模型表现出色，证明了将音频和视频 modalities结合在一起可以提高action recognition的效果。<details>
<summary>Abstract</summary>
In line with the human capacity to perceive the world by simultaneously processing and integrating high-dimensional inputs from multiple modalities like vision and audio, we propose a novel model, MAiVAR-T (Multimodal Audio-Image to Video Action Recognition Transformer). This model employs an intuitive approach for the combination of audio-image and video modalities, with a primary aim to escalate the effectiveness of multimodal human action recognition (MHAR). At the core of MAiVAR-T lies the significance of distilling substantial representations from the audio modality and transmuting these into the image domain. Subsequently, this audio-image depiction is fused with the video modality to formulate a unified representation. This concerted approach strives to exploit the contextual richness inherent in both audio and video modalities, thereby promoting action recognition. In contrast to existing state-of-the-art strategies that focus solely on audio or video modalities, MAiVAR-T demonstrates superior performance. Our extensive empirical evaluations conducted on a benchmark action recognition dataset corroborate the model's remarkable performance. This underscores the potential enhancements derived from integrating audio and video modalities for action recognition purposes.
</details>
<details>
<summary>摘要</summary>
按照人类对世界的同时处理和 интеGRATE多模态输入的能力，我们提议一种新的模型，MAiVAR-T（多modal Audio-Image to Video Action Recognition Transformer）。这个模型使用直观的方法将音频-图像和视频模态结合，以提高多modal human action recognition（MHAR）的效果。MAiVAR-T的核心思想是将音频模态中的重要表示转化到图像领域，然后将这些图像表示与视频模态进行融合。这种结合方法可以利用音频和视频模态中的上下文丰富性，从而提高动作识别。与现有的状态 искус法策略相比，MAiVAR-T表现出色。我们对一个标准动作识别数据集进行了广泛的实验，结果证明MAiVAR-T的出色表现。这不仅证明了将音频和视频模态结合的潜在提升，还证明了MAiVAR-T的优秀性。
</details></li>
</ul>
<hr>
<h2 id="Fair-Models-in-Credit-Intersectional-Discrimination-and-the-Amplification-of-Inequity"><a href="#Fair-Models-in-Credit-Intersectional-Discrimination-and-the-Amplification-of-Inequity" class="headerlink" title="Fair Models in Credit: Intersectional Discrimination and the Amplification of Inequity"></a>Fair Models in Credit: Intersectional Discrimination and the Amplification of Inequity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02680">http://arxiv.org/abs/2308.02680</a></li>
<li>repo_url: None</li>
<li>paper_authors: Savina Kim, Stefan Lessmann, Galina Andreeva, Michael Rovatsos</li>
<li>For: The paper aims to examine intersectional horizontal inequities in credit access and demonstrate how pluralistic realities and intersectional identities can shape patterns of credit allocation when using automated decision-making systems.* Methods: The authors use data from the Spanish microfinance market to analyze credit allocation patterns and demonstrate the impact of algorithmic bias on vulnerable groups. They utilize the intersectionality paradigm to examine how multiple and intersecting social categories can interact to produce inequities in credit access.* Results: The study finds that while fairness may exist superficially, unfairness can exacerbate at lower levels given combinatorial effects. The authors demonstrate that sensitive attributes such as single parent status and number of children can result in imbalanced harm. They discuss the implications of these findings for the financial services industry.Here are the three points in Simplified Chinese text:* For: 这个论文的目的是检查并评估微贷市场中的多元性水平不平等，以及自动决策系统如何影响弱势群体的借款访问。* Methods: 作者们使用西班牙微贷市场的数据来分析借款分配的 patterns，并通过 интерсе克циональ paradigm来检查不同社会类别之间的交叠作用，以产生借款访问不平等。* Results: 研究发现，尽管 superfic 的公平可能存在，但是在更深层次上，不公平可能会加剧，即 comb 的效果。作者们发现，敏感属性如单身状态和子女数量可能会导致不平等的害。他们讨论这些发现对金融服务业的影响。<details>
<summary>Abstract</summary>
The increasing usage of new data sources and machine learning (ML) technology in credit modeling raises concerns with regards to potentially unfair decision-making that rely on protected characteristics (e.g., race, sex, age) or other socio-economic and demographic data. The authors demonstrate the impact of such algorithmic bias in the microfinance context. Difficulties in assessing credit are disproportionately experienced among vulnerable groups, however, very little is known about inequities in credit allocation between groups defined, not only by single, but by multiple and intersecting social categories. Drawing from the intersectionality paradigm, the study examines intersectional horizontal inequities in credit access by gender, age, marital status, single parent status and number of children. This paper utilizes data from the Spanish microfinance market as its context to demonstrate how pluralistic realities and intersectional identities can shape patterns of credit allocation when using automated decision-making systems. With ML technology being oblivious to societal good or bad, we find that a more thorough examination of intersectionality can enhance the algorithmic fairness lens to more authentically empower action for equitable outcomes and present a fairer path forward. We demonstrate that while on a high-level, fairness may exist superficially, unfairness can exacerbate at lower levels given combinatorial effects; in other words, the core fairness problem may be more complicated than current literature demonstrates. We find that in addition to legally protected characteristics, sensitive attributes such as single parent status and number of children can result in imbalanced harm. We discuss the implications of these findings for the financial services industry.
</details>
<details>
<summary>摘要</summary>
随着新数据源和机器学习技术在借款评估中的使用，有关可能存在不公正决策的问题减受到关注，这些决策可能基于保护特征（如种族、性别、年龄）或其他社会经济和民生数据。作者们在微贷上下文中展示了算法偏见的影响。借款评估困难更加折射在投降群体中，但现实上几乎没有关于借款分配不公的研究。本研究基于交叉性理论，研究借款访问不公平的现象，包括按照年龄、性别、婚姻状况、单身状况和子女数来分类。这篇论文使用西班牙微贷市场为背景，通过自动决策系统来探讨多元社会和交叉性识别如何影响借款分配的 patrón。由于机器学习技术对社会好坏无所谓，我们发现通过交叉性来检查算法公平性可以更加 authentically 使ower 动作，以实现更公平的结果。我们发现，虽然在高层次上，公平可能存在披露，但是在 combinatorial effects 下，不公正可能加剧，即核心公平问题可能更复杂。我们发现，除了法律保护的特征之外，敏感特征如单身状况和子女数也可能导致不均衡的危害。我们讨论了这些发现对金融服务业的影响。
</details></li>
</ul>
<hr>
<h2 id="SelfCheck-Using-LLMs-to-Zero-Shot-Check-Their-Own-Step-by-Step-Reasoning"><a href="#SelfCheck-Using-LLMs-to-Zero-Shot-Check-Their-Own-Step-by-Step-Reasoning" class="headerlink" title="SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning"></a>SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00436">http://arxiv.org/abs/2308.00436</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ningmiao/selfcheck">https://github.com/ningmiao/selfcheck</a></li>
<li>paper_authors: Ning Miao, Yee Whye Teh, Tom Rainforth</li>
<li>for: 本研究旨在探讨 LLMs 是否可以自动认知自己的错误，不需要外部资源。</li>
<li>methods: 我们提出了一种零shot验证方法来识别错误，并用其进行权重投票来提高问答表现。</li>
<li>results: 我们在三个数学数据集上进行测试，发现该方法可以成功识别错误，并在最终预测性能中提高表现。<details>
<summary>Abstract</summary>
The recent progress in large language models (LLMs), especially the invention of chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning problems. However, even the strongest LLMs are still struggling with more complicated problems that require non-linear thinking and multi-step reasoning. In this work, we explore whether LLMs have the ability to recognize their own errors, without resorting to external resources. In particular, we investigate whether they can be used to identify individual errors within a step-by-step reasoning. To this end, we propose a zero-shot verification scheme to recognize such errors. We then use this verification scheme to improve question-answering performance, by using it to perform weighted voting on different generated answers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and find that it successfully recognizes errors and, in turn, increases final predictive performance.
</details>
<details>
<summary>摘要</summary>
最近很多大语言模型（LLMs）的进步，特别是创造思维（CoT）的提示，使得解释问题变得可能。然而，即使最强的LLMs仍然在更复杂的问题上遇到困难，需要非线性思维和多步逻辑。在这种情况下，我们询问LLMs是否有能力自动发现自己的错误，而不需要外部资源。特别是，我们研究LLMs是否可以用于识别单个步骤逻辑中的错误。为此，我们提出了零shot验证方案，用于识别such errors。然后，我们使用这种验证方案来提高问答表现，通过对不同生成的答案进行权重投票。我们在三个数学 dataset（GSM8K、MathQA和MATH）上测试了这种方法，并发现它成功地识别了错误，并在最终预测性能中提高了表现。
</details></li>
</ul>
<hr>
<h2 id="qgym-A-Gym-for-Training-and-Benchmarking-RL-Based-Quantum-Compilation"><a href="#qgym-A-Gym-for-Training-and-Benchmarking-RL-Based-Quantum-Compilation" class="headerlink" title="qgym: A Gym for Training and Benchmarking RL-Based Quantum Compilation"></a>qgym: A Gym for Training and Benchmarking RL-Based Quantum Compilation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02536">http://arxiv.org/abs/2308.02536</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qutech-delft/qgym">https://github.com/qutech-delft/qgym</a></li>
<li>paper_authors: Stan van der Linde, Willem de Kok, Tariq Bontekoe, Sebastian Feld</li>
<li>for: 这篇论文是为了提高现代量子计算机的硬件限制下的量子电路编译过程的优化。</li>
<li>methods: 这篇论文使用了人工智能技术，具体来说是强化学习（RL），来优化量子电路编译过程。</li>
<li>results: 这篇论文提出了一个名为qgym的软件框架，该框架可以在高度可定制的环境中训练和测试RL算法和代理。<details>
<summary>Abstract</summary>
Compiling a quantum circuit for specific quantum hardware is a challenging task. Moreover, current quantum computers have severe hardware limitations. To make the most use of the limited resources, the compilation process should be optimized. To improve currents methods, Reinforcement Learning (RL), a technique in which an agent interacts with an environment to learn complex policies to attain a specific goal, can be used. In this work, we present qgym, a software framework derived from the OpenAI gym, together with environments that are specifically tailored towards quantum compilation. The goal of qgym is to connect the research fields of Artificial Intelligence (AI) with quantum compilation by abstracting parts of the process that are irrelevant to either domain. It can be used to train and benchmark RL agents and algorithms in highly customizable environments.
</details>
<details>
<summary>摘要</summary>
compile quantum circuit specific quantum hardware 是一个复杂的任务。此外，当前的量子计算机有严重的硬件限制。为了最大化有限资源，编译过程应该进行优化。为了改进当前方法，我们可以使用Reinforcement Learning（RL），这是一种 Agent 与环境互动以学习复杂的策略，以达到特定目标。在这项工作中，我们提出了qgym，一个基于 OpenAI gym 的软件框架，同时与量子编译环境相关。qgym 的目标是将人工智能（AI）与量子编译领域连接起来，抽象不相关的部分，以便在高度可定制的环境中训练和测试 RL 代理和算法。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Generate-Training-Datasets-for-Robust-Semantic-Segmentation"><a href="#Learning-to-Generate-Training-Datasets-for-Robust-Semantic-Segmentation" class="headerlink" title="Learning to Generate Training Datasets for Robust Semantic Segmentation"></a>Learning to Generate Training Datasets for Robust Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02535">http://arxiv.org/abs/2308.02535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marwane Hariat, Olivier Laurent, Rémi Kazmierczak, Shihao Zhang, Andrei Bursuc, Angela Yao, Gianni Franchi</li>
<li>for: 提高semantic segmentation技术的Robustness，尤其是在安全关键应用中。</li>
<li>methods: 利用label-to-image生成器和图像-to-label分割模型的共同效应，设计并训练一种robust conditional生成随机网络来生成真实和可能的异常或异常图像。</li>
<li>results: 对提案的生成模型进行了深入的研究，评估下游分割网络的性能和Robustness，并证明了该方法可以在真实世界的干扰和数据分布变化中显著提高semantic segmentation技术的Robustness。<details>
<summary>Abstract</summary>
Semantic segmentation techniques have shown significant progress in recent years, but their robustness to real-world perturbations and data samples not seen during training remains a challenge, particularly in safety-critical applications. In this paper, we propose a novel approach to improve the robustness of semantic segmentation techniques by leveraging the synergy between label-to-image generators and image-to-label segmentation models. Specifically, we design and train Robusta, a novel robust conditional generative adversarial network to generate realistic and plausible perturbed or outlier images that can be used to train reliable segmentation models. We conduct in-depth studies of the proposed generative model, assess the performance and robustness of the downstream segmentation network, and demonstrate that our approach can significantly enhance the robustness of semantic segmentation techniques in the face of real-world perturbations, distribution shifts, and out-of-distribution samples. Our results suggest that this approach could be valuable in safety-critical applications, where the reliability of semantic segmentation techniques is of utmost importance and comes with a limited computational budget in inference. We will release our code shortly.
</details>
<details>
<summary>摘要</summary>
Semantic segmentation技术在最近几年内已经取得了显著的进步，但它们对实际世界中的干扰和训练数据集之外的数据样本仍然是一个挑战，特别是在安全关键应用中。在这篇论文中，我们提出了一种新的方法，以利用标签到图像生成器和图像到标签分割模型之间的共同作用，以提高 semantic segmentation 技术的可靠性。我们设计并训练了 Robusta，一种新的可靠 conditional generative adversarial network，以生成真实和可能的干扰或异常图像，用于训练可靠的分割模型。我们进行了深入的研究，评估了下游分割网络的性能和可靠性，并证明了我们的方法可以在实际世界中增强 semantic segmentation 技术的Robustness，包括分布转换、干扰和异常样本。我们的结果表明，这种方法在安全关键应用中可以提供有价值的技术，其可靠性和计算成本在推断中具有限制。我们即将发布我们的代码。
</details></li>
</ul>
<hr>
<h2 id="BiERL-A-Meta-Evolutionary-Reinforcement-Learning-Framework-via-Bilevel-Optimization"><a href="#BiERL-A-Meta-Evolutionary-Reinforcement-Learning-Framework-via-Bilevel-Optimization" class="headerlink" title="BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel Optimization"></a>BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01207">http://arxiv.org/abs/2308.01207</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chriswang98sz/bierl">https://github.com/chriswang98sz/bierl</a></li>
<li>paper_authors: Junyi Wang, Yuanyang Zhu, Zhi Wang, Yan Zheng, Jianye Hao, Chunlin Chen</li>
<li>for: 提高复杂RL问题的解决能力，使用Evolutionary Reinforcement Learning（ERL）算法。</li>
<li>methods: 提出了一个通用的Meta-ERL框架，通过矩阵优化来同时更新hyperparameter和ERL模型。</li>
<li>results: 在MuJoCo和Box2D任务中，BiERL frameworks比基eline和其他基eline都提高了学习性能，并且可以适应多种ERL算法。<details>
<summary>Abstract</summary>
Evolutionary reinforcement learning (ERL) algorithms recently raise attention in tackling complex reinforcement learning (RL) problems due to high parallelism, while they are prone to insufficient exploration or model collapse without carefully tuning hyperparameters (aka meta-parameters). In the paper, we propose a general meta ERL framework via bilevel optimization (BiERL) to jointly update hyperparameters in parallel to training the ERL model within a single agent, which relieves the need for prior domain knowledge or costly optimization procedure before model deployment. We design an elegant meta-level architecture that embeds the inner-level's evolving experience into an informative population representation and introduce a simple and feasible evaluation of the meta-level fitness function to facilitate learning efficiency. We perform extensive experiments in MuJoCo and Box2D tasks to verify that as a general framework, BiERL outperforms various baselines and consistently improves the learning performance for a diversity of ERL algorithms.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Tackling-Hallucinations-in-Neural-Chart-Summarization"><a href="#Tackling-Hallucinations-in-Neural-Chart-Summarization" class="headerlink" title="Tackling Hallucinations in Neural Chart Summarization"></a>Tackling Hallucinations in Neural Chart Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00399">http://arxiv.org/abs/2308.00399</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/worldhellow/hallucinations-c2t">https://github.com/worldhellow/hallucinations-c2t</a></li>
<li>paper_authors: Saad Obaid ul Islam, Iza Škrjanec, Ondřej Dušek, Vera Demberg</li>
<li>for: 解决chart summarization中的幻觉问题</li>
<li>methods: 使用自然语言判断(NLI)方法预处理训练数据，以减少幻觉现象。同时，缩短输入序列中的长距离依赖关系和添加图表标题和标签，以改善总体性能。</li>
<li>results: 通过人工评估，我们的方法显著减少了幻觉现象，并且改善了总体性能。<details>
<summary>Abstract</summary>
Hallucinations in text generation occur when the system produces text that is not grounded in the input. In this work, we tackle the problem of hallucinations in neural chart summarization. Our analysis shows that the target side of chart summarization training datasets often contains additional information, leading to hallucinations. We propose a natural language inference (NLI) based method to preprocess the training data and show through human evaluation that our method significantly reduces hallucinations. We also found that shortening long-distance dependencies in the input sequence and adding chart-related information like title and legends improves the overall performance.
</details>
<details>
<summary>摘要</summary>
文本生成中的幻觉现象发生在系统生成的文本与输入没有匹配。在这项工作中，我们解决了chart摘要 neural网络中的幻觉问题。我们的分析显示目标一侧chart摘要训练数据经常包含额外信息，导致幻觉。我们提议使用自然语言推理（NLI）基本方法来处理训练数据，并通过人工评估显示我们的方法可以显著减少幻觉。此外，我们发现短缩长距离相互关系在输入序列中和添加图表标题和图例可以提高总性表现。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Time-Series-Anomaly-Detection-Methods-in-the-AIOps-Domain"><a href="#A-Survey-of-Time-Series-Anomaly-Detection-Methods-in-the-AIOps-Domain" class="headerlink" title="A Survey of Time Series Anomaly Detection Methods in the AIOps Domain"></a>A Survey of Time Series Anomaly Detection Methods in the AIOps Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00393">http://arxiv.org/abs/2308.00393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenyu Zhong, Qiliang Fan, Jiacheng Zhang, Minghua Ma, Shenglin Zhang, Yongqian Sun, Qingwei Lin, Yuzhi Zhang, Dan Pei</li>
<li>for: 本文旨在探讨人工智能为运维工作（AIOps）中的时间序列异常检测，以及未来的实际应用和下一代时间序列异常检测技术的发展趋势。</li>
<li>methods: 本文综述了一些常见的时间序列异常检测方法，包括统计方法、机器学习方法和深度学习方法等，并评估了它们在不同的应用场景中的表现。</li>
<li>results: 本文通过对一些实际应用场景的分析和评估，总结了时间序列异常检测的挑战和机遇，并提出了未来研究的方向和策略。<details>
<summary>Abstract</summary>
Internet-based services have seen remarkable success, generating vast amounts of monitored key performance indicators (KPIs) as univariate or multivariate time series. Monitoring and analyzing these time series are crucial for researchers, service operators, and on-call engineers to detect outliers or anomalies indicating service failures or significant events. Numerous advanced anomaly detection methods have emerged to address availability and performance issues. This review offers a comprehensive overview of time series anomaly detection in Artificial Intelligence for IT operations (AIOps), which uses AI capabilities to automate and optimize operational workflows. Additionally, it explores future directions for real-world and next-generation time-series anomaly detection based on recent advancements.
</details>
<details>
<summary>摘要</summary>
互联网基于服务的时间序列状态监控和分析已经取得了杰出的成功，生成了大量监控关键性表现指标 (KPI) 的时间序列。这些时间序列的监控和分析是研究人员、服务运营商和升级工程师需要侦测异常或异常状态的关键工具。多种高级异常探测方法已经出现，以解决可用性和性能问题。本评论提供了AI操作 (AIOps) 中时间序列异常探测的全面概述，并探讨未来领域和下一代时间序列异常探测的未来发展。
</details></li>
</ul>
<hr>
<h2 id="Counterfactual-Graph-Transformer-for-Traffic-Flow-Prediction"><a href="#Counterfactual-Graph-Transformer-for-Traffic-Flow-Prediction" class="headerlink" title="Counterfactual Graph Transformer for Traffic Flow Prediction"></a>Counterfactual Graph Transformer for Traffic Flow Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00391">http://arxiv.org/abs/2308.00391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Yang, Kai Du, Xingyuan Dai, Jianwu Fang</li>
<li>for:  traffic flow prediction (TFP) in Intelligent Transportation System (ITS)</li>
<li>methods:  graph-based models with multiple attention mechanisms, perturbation mask generator for counterfactual explanations</li>
<li>results:  improved and interpretable traffic flow prediction, reliable explanations on three real-world public datasets<details>
<summary>Abstract</summary>
Traffic flow prediction (TFP) is a fundamental problem of the Intelligent Transportation System (ITS), as it models the latent spatial-temporal dependency of traffic flow for potential congestion prediction. Recent graph-based models with multiple kinds of attention mechanisms have achieved promising performance. However, existing methods for traffic flow prediction tend to inherit the bias pattern from the dataset and lack interpretability. To this end, we propose a Counterfactual Graph Transformer (CGT) model with an instance-level explainer (e.g., finding the important subgraphs) specifically designed for TFP. We design a perturbation mask generator over input sensor features at the time dimension and the graph structure on the graph transformer module to obtain spatial and temporal counterfactual explanations. By searching the optimal perturbation masks on the input data feature and graph structures, we can obtain the concise and dominant data or graph edge links for the subsequent TFP task. After re-training the utilized graph transformer model after counterfactual perturbation, we can obtain improved and interpretable traffic flow prediction. Extensive results on three real-world public datasets show that CGT can produce reliable explanations and is promising for traffic flow prediction.
</details>
<details>
<summary>摘要</summary>
做为智能交通系统（ITS）的基础问题，流量流动预测（TFP）模型了路面交通流量的隐藏空间时间相依性，以预测潜在堵塞。现有的图形基本模型和多种注意力机制已经获得了显著的性能。然而，现有的交通流量预测方法通常会从数据集 inherit 偏见模式和缺乏解释性。为了解决这个问题，我们提出了Counterfactual Graph Transformer（CGT）模型，并特别设计了实例阶层解释器（例如，发现重要的子图）。我们在图形变换模组中实现了对输入感应器特征和图形结构的损害莳制生成器，以获得空间和时间的对应替代解释。通过寻找最佳的损害莳制，我们可以获得整体和主要的数据或图形边线，并将其用于后续的TFP任务。经过重新训练utilized graph transformer模型，我们可以获得改进和可解释的交通流量预测。实验结果显示，CGT可以生成可靠的解释和是TFP预测的有前途。
</details></li>
</ul>
<hr>
<h2 id="Improving-Generalization-of-Adversarial-Training-via-Robust-Critical-Fine-Tuning"><a href="#Improving-Generalization-of-Adversarial-Training-via-Robust-Critical-Fine-Tuning" class="headerlink" title="Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning"></a>Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02533">http://arxiv.org/abs/2308.02533</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/robustlearn">https://github.com/microsoft/robustlearn</a></li>
<li>paper_authors: Kaijie Zhu, Jindong Wang, Xixu Hu, Xing Xie, Ge Yang</li>
<li>for: 这个论文的目的是提高模型的普适性和对抗性，而不是减少对抗性的代价。</li>
<li>methods: 这个论文提出了一种新的方法called Robustness Critical Fine-Tuning (RiFT)，它利用模型的稳定性 redundant capacity来提高模型的普适性和对抗性。</li>
<li>results: 实验结果表明， RiFT 可以在 ResNet18、ResNet34 和 WideResNet34-10 模型上提高普适性和对抗性，同时保持或者甚至提高对抗性。<details>
<summary>Abstract</summary>
Deep neural networks are susceptible to adversarial examples, posing a significant security risk in critical applications. Adversarial Training (AT) is a well-established technique to enhance adversarial robustness, but it often comes at the cost of decreased generalization ability. This paper proposes Robustness Critical Fine-Tuning (RiFT), a novel approach to enhance generalization without compromising adversarial robustness. The core idea of RiFT is to exploit the redundant capacity for robustness by fine-tuning the adversarially trained model on its non-robust-critical module. To do so, we introduce module robust criticality (MRC), a measure that evaluates the significance of a given module to model robustness under worst-case weight perturbations. Using this measure, we identify the module with the lowest MRC value as the non-robust-critical module and fine-tune its weights to obtain fine-tuned weights. Subsequently, we linearly interpolate between the adversarially trained weights and fine-tuned weights to derive the optimal fine-tuned model weights. We demonstrate the efficacy of RiFT on ResNet18, ResNet34, and WideResNet34-10 models trained on CIFAR10, CIFAR100, and Tiny-ImageNet datasets. Our experiments show that \method can significantly improve both generalization and out-of-distribution robustness by around 1.5% while maintaining or even slightly enhancing adversarial robustness. Code is available at https://github.com/microsoft/robustlearn.
</details>
<details>
<summary>摘要</summary>
深度神经网络容易受到攻击性例子的威胁，这对重要应用场景来说是一个 significiant 的安全隐患。对此，抗击例（AT）是一种广泛使用的技术，可以提高攻击性 robustness，但它经常会导致模型的泛化能力减退。本文提出了一种新的方法，即 Robustness Critical Fine-Tuning（RiFT），可以增强泛化而不需要牺牲攻击性 robustness。RiFT 的核心思想是利用模型对 robustness 的剩余容量，通过精细调整对攻击性训练的模型中的非 robust-critical 模块的参数来增强泛化。为此，我们引入模块抗性评估（MRC），它评估模型对 worst-case  веса变化的抗性。我们使用 MRC measure  identificificate 模型中最低 MRC 值的模块为非 robust-critical 模块，然后精细调整其参数以获得精细调整后的参数。最后，我们将 adversarially trained  weights 和精细调整后的 weights 线性 interpolate 以 derive 最佳 fine-tuned 模型 weights。我们在 ResNet18、ResNet34 和 WideResNet34-10 模型上进行 CIFAR10、CIFAR100 和 Tiny-ImageNet 数据集的实验，结果显示，\method 可以在泛化和离域 robustness 方面提高约 1.5%，同时保持或甚至提高攻击性 robustness。代码可以在 https://github.com/microsoft/robustlearn 上找到。
</details></li>
</ul>
<hr>
<h2 id="Shape-Completion-with-Prediction-of-Uncertain-Regions"><a href="#Shape-Completion-with-Prediction-of-Uncertain-Regions" class="headerlink" title="Shape Completion with Prediction of Uncertain Regions"></a>Shape Completion with Prediction of Uncertain Regions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00377">http://arxiv.org/abs/2308.00377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dlr-rm/shape-completion">https://github.com/dlr-rm/shape-completion</a></li>
<li>paper_authors: Matthias Humt, Dominik Winkelbauer, Ulrich Hillenbrand</li>
<li>for: Shape completion for robotic manipulation, specifically predicting the complete geometry of an object from a partial observation, and providing an indication of severe geometric uncertainty in extended regions.</li>
<li>methods: Two novel methods for predicting uncertain regions, one through postprocessing occupancy scores and the other through direct prediction of an uncertainty indicator, as well as two known approaches to probabilistic shape completion.</li>
<li>results: Both novel methods outperform the two baselines in shape completion and uncertain region prediction, and avoiding the predicted uncertain regions increases the quality of grasps for all tested methods.Here’s the text in Simplified Chinese:</li>
<li>for: shape completion for robotic manipulation, 特别是从受限的观察中预测物体的完整几何结构。</li>
<li>methods: 提出了两种新的方法来预测不确定区域，一种是通过处理启用分布的方法，另一种是直接预测不确定指标。</li>
<li>results: 这两种新方法在形成完整的几何结构和不确定区域预测方面都高于两个基eline方法，并且避免预测的不确定区域可以提高所有测试方法中的抓取质量。<details>
<summary>Abstract</summary>
Shape completion, i.e., predicting the complete geometry of an object from a partial observation, is highly relevant for several downstream tasks, most notably robotic manipulation. When basing planning or prediction of real grasps on object shape reconstruction, an indication of severe geometric uncertainty is indispensable. In particular, there can be an irreducible uncertainty in extended regions about the presence of entire object parts when given ambiguous object views. To treat this important case, we propose two novel methods for predicting such uncertain regions as straightforward extensions of any method for predicting local spatial occupancy, one through postprocessing occupancy scores, the other through direct prediction of an uncertainty indicator. We compare these methods together with two known approaches to probabilistic shape completion. Moreover, we generate a dataset, derived from ShapeNet, of realistically rendered depth images of object views with ground-truth annotations for the uncertain regions. We train on this dataset and test each method in shape completion and prediction of uncertain regions for known and novel object instances and on synthetic and real data. While direct uncertainty prediction is by far the most accurate in the segmentation of uncertain regions, both novel methods outperform the two baselines in shape completion and uncertain region prediction, and avoiding the predicted uncertain regions increases the quality of grasps for all tested methods. Web: https://github.com/DLR-RM/shape-completion
</details>
<details>
<summary>摘要</summary>
shape completion，即从partial observation中预测完整的物体形态，对机器人操作具有重要意义。当基于物体形态重建计划或预测实际抓取时，对物体形态的不确定性是不可或缺的。特别是在给出杂乱的物体视图时，可能存在扩展区域中对物体部分的存在是不确定的。为解决这个重要的问题，我们提出了两种新的方法，一种是通过处理占用度分布来预测不确定区域，另一种是直接预测不确定指标。我们将这些方法与两种已知方法进行比较，并在shape completion和不确定区域预测中进行测试。结果显示，直接预测不确定区域是最准确的 segmentation 方法，而我们的两种新方法在shape completion和不确定区域预测中均超过了两个基eline方法，并且避免预测的不确定区域可以提高所有测试方法的抓取质量。详细信息可以查看我们的github仓库：https://github.com/DLR-RM/shape-completion。
</details></li>
</ul>
<hr>
<h2 id="MRQ-Support-Multiple-Quantization-Schemes-through-Model-Re-Quantization"><a href="#MRQ-Support-Multiple-Quantization-Schemes-through-Model-Re-Quantization" class="headerlink" title="MRQ:Support Multiple Quantization Schemes through Model Re-Quantization"></a>MRQ:Support Multiple Quantization Schemes through Model Re-Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01867">http://arxiv.org/abs/2308.01867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manasa Manohara, Sankalp Dayal, Tariq Afzal, Rahul Bakshi, Kahkuen Fu</li>
<li>for: 这篇论文是针对对于边缘设备（例如：NPU、TPU、DPU）的深度学习模型部署所难以实现的复杂模型quantization和转换问题提出了解决方案。</li>
<li>methods: 这篇论文提出了一种新的模型quantization方法，即MRQ（模型重新quantization），可以将现有的量化模型迅速地转换为不同的量化需求（例如：对称 -&gt; 非对称、非二进制数值 -&gt; 二进制数值）。这种重新量化方法比从头开始量化更加简单，因为它可以避免高昂的重新训练成本，并且可以同时支持多种量化方案。</li>
<li>results: 这篇论文的结果显示，可以使用新开发的重新量化算法（包括权重调整和几何误差折衣）将MobileNetV2 QAT模型（[7]）转换为不同的量化方案（例如：对称和对称+二进制数值），单位损失不大于0.64单位。此外，这些量化模型已经成功地在NNA上部署在Echo Show设备上。<details>
<summary>Abstract</summary>
Despite the proliferation of diverse hardware accelerators (e.g., NPU, TPU, DPU), deploying deep learning models on edge devices with fixed-point hardware is still challenging due to complex model quantization and conversion. Existing model quantization frameworks like Tensorflow QAT [1], TFLite PTQ [2], and Qualcomm AIMET [3] supports only a limited set of quantization schemes (e.g., only asymmetric per-tensor quantization in TF1.x QAT [4]). Accordingly, deep learning models cannot be easily quantized for diverse fixed-point hardwares, mainly due to slightly different quantization requirements. In this paper, we envision a new type of model quantization approach called MRQ (model re-quantization), which takes existing quantized models and quickly transforms the models to meet different quantization requirements (e.g., asymmetric -> symmetric, non-power-of-2 scale -> power-of-2 scale). Re-quantization is much simpler than quantizing from scratch because it avoids costly re-training and provides support for multiple quantization schemes simultaneously. To minimize re-quantization error, we developed a new set of re-quantization algorithms including weight correction and rounding error folding. We have demonstrated that MobileNetV2 QAT model [7] can be quickly re-quantized into two different quantization schemes (i.e., symmetric and symmetric+power-of-2 scale) with less than 0.64 units of accuracy loss. We believe our work is the first to leverage this concept of re-quantization for model quantization and models obtained from the re-quantization process have been successfully deployed on NNA in the Echo Show devices.
</details>
<details>
<summary>摘要</summary>
尽管现有多种各种硬件加速器（如NPU、TPU、DPU），但将深度学习模型部署到边缘设备上的固定点硬件仍然是一项复杂的挑战，主要是因为复杂的模型减quantization和转换。现有的模型减quantization框架，如TensorFlow QAT [1]、TFLite PTQ [2]和Qualcomm AIMET [3]，只支持一定的减quantization方案（如TF1.x QAT [4]中的只有非对称每个tensor减quantization）。因此，深度学习模型难以被容易减quantization，主要是因为不同的固定点硬件有些微的不同减quantization需求。在这篇论文中，我们提出了一种新的模型减quantization方法，称为MRQ（模型重新减quantization）。它可以将现有的减quantized模型快速地转换成符合不同减quantization需求的模型。重新减quantization比从头开始减quantization更加简单，因为它可以避免费时的重新训练，并且可以同时支持多种减quantization方案。为了减少重新减quantization的误差，我们开发了一组新的重新减quantization算法，包括权重修正和圆拟误差折衔。我们已经证明了，通过MRQ方法，可以快速地将MobileNetV2 QAT模型 [7] 转换成两种不同的减quantization方案（即Symmetric和Symmetric+power-of-2 scale），减少误差丢失不到0.64个单位。我们认为，我们的工作是首次利用这种重新减quantization概念来实现模型减quantization，并且已经成功部署了模型在NNA上的Echo Show设备。
</details></li>
</ul>
<hr>
<h2 id="Learning-Green’s-Function-Efficiently-Using-Low-Rank-Approximations"><a href="#Learning-Green’s-Function-Efficiently-Using-Low-Rank-Approximations" class="headerlink" title="Learning Green’s Function Efficiently Using Low-Rank Approximations"></a>Learning Green’s Function Efficiently Using Low-Rank Approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00350">http://arxiv.org/abs/2308.00350</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kishanwn/decgreennet">https://github.com/kishanwn/decgreennet</a></li>
<li>paper_authors: Kishan Wimalawarne, Taiji Suzuki, Sophie Langer</li>
<li>for: 用深度学习模型解决不同类型的 partial differential equations</li>
<li>methods: 使用低级别分解学习绿函数，实现 removing redundant computations by separate learning with domain data for evaluation and Monte-Carlo samples for integral approximation</li>
<li>results: 提高计算时间，与 PINNs 和 MOD-Net 的准确率相似<details>
<summary>Abstract</summary>
Learning the Green's function using deep learning models enables to solve different classes of partial differential equations. A practical limitation of using deep learning for the Green's function is the repeated computationally expensive Monte-Carlo integral approximations. We propose to learn the Green's function by low-rank decomposition, which results in a novel architecture to remove redundant computations by separate learning with domain data for evaluation and Monte-Carlo samples for integral approximation. Using experiments we show that the proposed method improves computational time compared to MOD-Net while achieving comparable accuracy compared to both PINNs and MOD-Net.
</details>
<details>
<summary>摘要</summary>
使用深度学习模型学习格林函数，可以解决不同类型的部分 diferencial equation。 however，使用深度学习 для格林函数有一个实际的限制，即多次计算成本高的Monte-Carlo integral approximation。我们提议通过低级别 decompositions 学习格林函数，这会导致一种新的架构，可以通过分离学习领域数据和Monte-Carlo 样本来移除重复的计算。我们通过实验表明，我们的方法可以比MOD-Net快速计算，并且与PINNs和MOD-Net的准确率相当。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-ensemble-selection-based-on-Deep-Neural-Network-Uncertainty-Estimation-for-Adversarial-Robustness"><a href="#Dynamic-ensemble-selection-based-on-Deep-Neural-Network-Uncertainty-Estimation-for-Adversarial-Robustness" class="headerlink" title="Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness"></a>Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00346">http://arxiv.org/abs/2308.00346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruoxi Qin, Linyuan Wang, Xuehui Du, Xingyuan Chen, Bin Yan</li>
<li>for: 提高模型对白盒攻击的防御性能和稳定性。</li>
<li>methods: 动态 ensemble 选择技术，通过 Dirichlet 分布和多模型 parameter 空间多样性约束来提高模型的不确定性识别和鲁棒性。</li>
<li>results: 比对前一些动态方法和静态 adversarial 训练模型，提出的方法可以实现显著的鲁棒性提高而不损失精度。<details>
<summary>Abstract</summary>
The deep neural network has attained significant efficiency in image recognition. However, it has vulnerable recognition robustness under extensive data uncertainty in practical applications. The uncertainty is attributed to the inevitable ambient noise and, more importantly, the possible adversarial attack. Dynamic methods can effectively improve the defense initiative in the arms race of attack and defense of adversarial examples. Different from the previous dynamic method depend on input or decision, this work explore the dynamic attributes in model level through dynamic ensemble selection technology to further protect the model from white-box attacks and improve the robustness. Specifically, in training phase the Dirichlet distribution is apply as prior of sub-models' predictive distribution, and the diversity constraint in parameter space is introduced under the lightweight sub-models to construct alternative ensembel model spaces. In test phase, the certain sub-models are dynamically selected based on their rank of uncertainty value for the final prediction to ensure the majority accurate principle in ensemble robustness and accuracy. Compared with the previous dynamic method and staic adversarial traning model, the presented approach can achieve significant robustness results without damaging accuracy by combining dynamics and diversity property.
</details>
<details>
<summary>摘要</summary>
深度神经网络在图像识别中已经实现了显著的效率，但它在实际应用中面临着广泛的数据不确定性和可能的敌意攻击的问题。这些不确定性的来源包括不可避免的环境噪声以及可能的敌意攻击。动态方法可以有效地提高模型的防御力，在攻击和防御敌意例子的武器库中进行了反应。与之前的动态方法不同，本工作通过在模型层次上进行动态ensemble选择技术来进一步保护模型免受白盒攻击，提高了模型的Robustness。在训练阶段，我们使用Dirichlet分布作为子模型预测分布的PRIOR，并在轻量级子模型之间引入多样性约束，以构建多个备用模型空间。在测试阶段，根据它们的uncertainty值排名，选择一些特定的子模型来进行最终预测，以确保多数准确原理在ensemble robustness和精度之间达到平衡。与之前的动态方法和静态敌意训练模型相比，提出的方法可以无需损害精度而实现显著的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Monitoring-Algorithmic-Fairness-under-Partial-Observations"><a href="#Monitoring-Algorithmic-Fairness-under-Partial-Observations" class="headerlink" title="Monitoring Algorithmic Fairness under Partial Observations"></a>Monitoring Algorithmic Fairness under Partial Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00341">http://arxiv.org/abs/2308.00341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas A. Henzinger, Konstantin Kueffner, Kaushik Mallik</li>
<li>for: 这篇论文目的是监控机器学习系统中的公平性，以确保其在做出决策时保持公平和不偏袋。</li>
<li>methods: 这篇论文使用了runtime verification技术来监控机器学习系统的公平性，并且可以在部署系统时进行监控。这些监控技术可以处理不完全可观察的系统状态，并且可以监控多种公平性责任。</li>
<li>results: 这篇论文的实验结果显示，使用这些监控技术可以实现实时监控机器学习系统的公平性，并且可以在不同的实际应用中进行适当的调整。<details>
<summary>Abstract</summary>
As AI and machine-learned software are used increasingly for making decisions that affect humans, it is imperative that they remain fair and unbiased in their decisions. To complement design-time bias mitigation measures, runtime verification techniques have been introduced recently to monitor the algorithmic fairness of deployed systems. Previous monitoring techniques assume full observability of the states of the (unknown) monitored system. Moreover, they can monitor only fairness properties that are specified as arithmetic expressions over the probabilities of different events. In this work, we extend fairness monitoring to systems modeled as partially observed Markov chains (POMC), and to specifications containing arithmetic expressions over the expected values of numerical functions on event sequences. The only assumptions we make are that the underlying POMC is aperiodic and starts in the stationary distribution, with a bound on its mixing time being known. These assumptions enable us to estimate a given property for the entire distribution of possible executions of the monitored POMC, by observing only a single execution. Our monitors observe a long run of the system and, after each new observation, output updated PAC-estimates of how fair or biased the system is. The monitors are computationally lightweight and, using a prototype implementation, we demonstrate their effectiveness on several real-world examples.
</details>
<details>
<summary>摘要</summary>
As AI和机器学习软件在做决策时越来越多，它们必须保持公平和无偏见。为了补充设计时的偏见缓解措施，运行时监测技术已经在最近引入了。 previous监测技术假设了监测系统的完整可见性，并且只能监测已知的系统状态。在这种情况下，我们将公平监测扩展到采用partially observed Markov chains（POMC）模型的系统，并将特定的公平性特性表示为数值函数的期望值。我们假设了这个POMC是无限期的，并且知道其混合时间的上限。这些假设使我们能够估计整个可能的执行情况下的公平性，只需观察一个执行。我们的监测器在系统中观察长时间，每次新的观察结果出现后，输出了更新后的PAC估计值，用于评估系统的公平性。我们的监测器 computationally lightweight，并且使用原型实现，我们在实际应用中证明了它们的有效性。
</details></li>
</ul>
<hr>
<h2 id="Threshold-aware-Learning-to-Generate-Feasible-Solutions-for-Mixed-Integer-Programs"><a href="#Threshold-aware-Learning-to-Generate-Feasible-Solutions-for-Mixed-Integer-Programs" class="headerlink" title="Threshold-aware Learning to Generate Feasible Solutions for Mixed Integer Programs"></a>Threshold-aware Learning to Generate Feasible Solutions for Mixed Integer Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00327">http://arxiv.org/abs/2308.00327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taehyun Yoon, Jinwon Choi, Hyokun Yun, Sungbin Lim</li>
<li>For: The paper is written to address the challenge of finding high-quality feasible solutions to combinatorial optimization (CO) problems within a limited time, using machine learning (ML) methods.* Methods: The paper proposes a post-hoc method and a learning-based approach for optimizing the coverage of partial discrete variable assignments in Mixed Integer Programs (MIP), which bridges the gap between the learning and MIP objectives. The approach involves jointly learning to restrict the coverage search space and to predict the coverage in the learned search space, using a deep neural network.* Results: The paper demonstrates state-of-the-art performance in NeurIPS ML4CO datasets, achieving an optimality gap of 0.45% in the workload apportionment dataset within a one-minute time limit, which is a ten-fold improvement over SCIP.<details>
<summary>Abstract</summary>
Finding a high-quality feasible solution to a combinatorial optimization (CO) problem in a limited time is challenging due to its discrete nature. Recently, there has been an increasing number of machine learning (ML) methods for addressing CO problems. Neural diving (ND) is one of the learning-based approaches to generating partial discrete variable assignments in Mixed Integer Programs (MIP), a framework for modeling CO problems. However, a major drawback of ND is a large discrepancy between the ML and MIP objectives, i.e., variable value classification accuracy over primal bound. Our study investigates that a specific range of variable assignment rates (coverage) yields high-quality feasible solutions, where we suggest optimizing the coverage bridges the gap between the learning and MIP objectives. Consequently, we introduce a post-hoc method and a learning-based approach for optimizing the coverage. A key idea of our approach is to jointly learn to restrict the coverage search space and to predict the coverage in the learned search space. Experimental results demonstrate that learning a deep neural network to estimate the coverage for finding high-quality feasible solutions achieves state-of-the-art performance in NeurIPS ML4CO datasets. In particular, our method shows outstanding performance in the workload apportionment dataset, achieving the optimality gap of 0.45%, a ten-fold improvement over SCIP within the one-minute time limit.
</details>
<details>
<summary>摘要</summary>
寻找一个高质量可行的解决方案 для combinatorial optimization (CO) 问题在有限时间内是挑战的，主要因为其离散性。近年来，machine learning (ML) 方法在Addressing CO problems 问题上增加了。Neural diving (ND) 是一种学习基于的方法，用于生成混合整数程序（MIP）中的部分不连续变量分配。然而，ND 的一个主要缺点是ML 和 MIP 目标之间的大差异，即变量值分类准确率 над primal bound。我们的研究发现，在特定的变量分配率（coverage）范围内，可以获得高质量可行的解决方案，我们建议优化coverage来bridging the gap between learning和MIP目标。因此，我们提出了一种后续方法和一种学习基于的方法来优化coverage。我们的方法的关键思想是同时学习 restriction the coverage search space和在学习的搜索空间中预测coverage。实验结果表明，通过学习深度神经网络来估算coverage可以在 NeurIPS ML4CO 数据集中实现状态机器人的性能。特别是，我们的方法在工作负担分配数据集中表现出色，实现了1分钟时限内的优化性能，与SCIP相比，提高了10倍。
</details></li>
</ul>
<hr>
<h2 id="Pixel-to-policy-DQN-Encoders-for-within-cross-game-reinforcement-learning"><a href="#Pixel-to-policy-DQN-Encoders-for-within-cross-game-reinforcement-learning" class="headerlink" title="Pixel to policy: DQN Encoders for within &amp; cross-game reinforcement learning"></a>Pixel to policy: DQN Encoders for within &amp; cross-game reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00318">http://arxiv.org/abs/2308.00318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashrya Agrawal, Priyanshi Shah, Sourabh Prakash</li>
<li>for: The paper aims to improve the performance of reinforcement learning (RL) models by leveraging transfer learning and multi-task learning in various game environments.</li>
<li>methods: The authors use deep Q-networks (DQN) as the RL model and explore different approaches of transfer learning, including pre-training the model on one game and fine-tuning it on another, as well as training the model on multiple games simultaneously.</li>
<li>results: The authors achieve impressive performance on several game environments, including a mean episode reward of 46.16, which beats human-level performance with only 20k episodes, and mean rewards of 533.42 and 402.17 on the Assault and Space Invader environments, respectively.<details>
<summary>Abstract</summary>
Reinforcement Learning can be applied to various tasks, and environments. Many of these environments have a similar shared structure, which can be exploited to improve RL performance on other tasks. Transfer learning can be used to take advantage of this shared structure, by learning policies that are transferable across different tasks and environments and can lead to more efficient learning as well as improved performance on a wide range of tasks. This work explores as well as compares the performance between RL models being trained from the scratch and on different approaches of transfer learning. Additionally, the study explores the performance of a model trained on multiple game environments, with the goal of developing a universal game-playing agent as well as transfer learning a pre-trained encoder using DQN, and training it on the same game or a different game. Our DQN model achieves a mean episode reward of 46.16 which even beats the human-level performance with merely 20k episodes which is significantly lower than deepmind's 1M episodes. The achieved mean rewards of 533.42 and 402.17 on the Assault and Space Invader environments respectively, represent noteworthy performance on these challenging environments.
</details>
<details>
<summary>摘要</summary>
“强化学习可以应用到多种任务和环境中，许多这些环境具有类似的共享结构，可以利用这些共享结构来提高强化学习性能。转移学习可以在不同任务和环境中学习可以转移的策略，从而实现更高效的学习以及多种任务的改进性能。本研究探讨了强化学习模型从零开始学习和转移学习的不同方法的性能，以及将多个游戏环境训练的模型在不同游戏中的性能。我们的DQN模型在46.16的平均回合奖励上达到了人类水平性能，只需20k个回合，这比深梦的1M个回合要低得多。在Assault和Space Invader环境中，我们的模型分别获得了533.42和402.17的平均奖励，这些表现在这些复杂的环境中是非常出色的。”
</details></li>
</ul>
<hr>
<h2 id="Doubly-Robust-Instance-Reweighted-Adversarial-Training"><a href="#Doubly-Robust-Instance-Reweighted-Adversarial-Training" class="headerlink" title="Doubly Robust Instance-Reweighted Adversarial Training"></a>Doubly Robust Instance-Reweighted Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00311">http://arxiv.org/abs/2308.00311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daouda Sow, Sen Lin, Zhangyang Wang, Yingbin Liang</li>
<li>for: 提高防御性能和数据分布不均 Robustness under limited model capacity.</li>
<li>methods: 使用分布robust优化(DRO)技术获取重要性加权，并且提高最容易受到攻击的数据点的鲁棒性。</li>
<li>results: 在标准分类 dataset 上比基eline方法提高了平均防御性能，同时提高了最弱数据点的鲁棒性。<details>
<summary>Abstract</summary>
Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained by optimizing the KL-divergence regularized loss function, which allows us to devise new algorithms with a theoretical convergence guarantee. Experiments on standard classification datasets demonstrate that our proposed approach outperforms related state-of-the-art baseline methods in terms of average robust performance, and at the same time improves the robustness against attacks on the weakest data points. Codes will be available soon.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用对抗数据中的重要性权重进行训练，已经在有限模型容量下实现了很大的成功。然而，现有的实例权重对抗训练（AT）方法仍然依赖于各种euristic和/或几何解释来确定这些重要性权重，使得这些算法缺乏正式的理论基础和保证。此外，现有研究表明，对抗训练受到训练分布中的非均匀攻击性影响，例如，某些类型的数据点可能更容易受到攻击。为解决这两个问题，在本文中，我们提出了一种新的双重稳健实例权重AT框架，可以通过探索分布式稳健优化（DRO）技术来获得重要性权重，并在同时提高最容易受到攻击的数据点的稳健性。具体来说，我们的重要性权重通过优化KL散度规范化损失函数来获得，这使我们可以开发新的算法，并提供了理论上的准确性保证。实验表明，我们的提议方法在标准分类 datasets 上的平均Robust性性能高于相关的状态艺术基eline方法，同时在最容易受到攻击的数据点上提高了稳健性。代码即将上传。
</details></li>
</ul>
<hr>
<h2 id="GradOrth-A-Simple-yet-Efficient-Out-of-Distribution-Detection-with-Orthogonal-Projection-of-Gradients"><a href="#GradOrth-A-Simple-yet-Efficient-Out-of-Distribution-Detection-with-Orthogonal-Projection-of-Gradients" class="headerlink" title="GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients"></a>GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00310">http://arxiv.org/abs/2308.00310</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sima Behpour, Thang Doan, Xin Li, Wenbin He, Liang Gou, Liu Ren</li>
<li>for: 验证机器学习模型在实际应用中的安全部署，检测非典型数据（OOD）是关键。</li>
<li>methods: 我们提出了一种基于卷积网络中最重要参数的OOD检测方法，通过计算ID数据中考虑重要的子空间上的梯度 проек 来标识OOD数据。</li>
<li>results: 我们的方法可以减少平均假阳性率，比现有方法提高True Positive Rate（TPR）的性能。在95%假阳性率（FPR95）下，我们的方法可以减少OOD数据的假阳性率达8%。<details>
<summary>Abstract</summary>
Detecting out-of-distribution (OOD) data is crucial for ensuring the safe deployment of machine learning models in real-world applications. However, existing OOD detection approaches primarily rely on the feature maps or the full gradient space information to derive OOD scores neglecting the role of most important parameters of the pre-trained network over in-distribution (ID) data. In this study, we propose a novel approach called GradOrth to facilitate OOD detection based on one intriguing observation that the important features to identify OOD data lie in the lower-rank subspace of in-distribution (ID) data. In particular, we identify OOD data by computing the norm of gradient projection on the subspaces considered important for the in-distribution data. A large orthogonal projection value (i.e. a small projection value) indicates the sample as OOD as it captures a weak correlation of the ID data. This simple yet effective method exhibits outstanding performance, showcasing a notable reduction in the average false positive rate at a 95% true positive rate (FPR95) of up to 8% when compared to the current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
检测不同领域（OOD）数据是机器学习模型在实际应用中安全部署的关键。然而，现有的OOD检测方法主要基于特征图或整个梯度空间信息来 derive OOD 分数，忽略了预训练网络中最重要的参数的作用。在本研究中，我们提出了一种新的方法called GradOrth，用于基于ID数据中最重要的特征进行OOD检测。具体来说，我们通过计算ID数据中考虑重要的特征SUBSPACE上的梯度 projetcion norm来识别OOD数据。如果梯度 проекcion norm值很小（即梯度 проекcion 强度很弱），则表示该样本是OOD数据。这种简单 yet有效的方法在评估中显示了remarkable performance，与当前状态的方法相比，可以达到8%的 False Positive Rate（FPR）降低。
</details></li>
</ul>
<hr>
<h2 id="Revolutionizing-TCAD-Simulations-with-Universal-Device-Encoding-and-Graph-Attention-Networks"><a href="#Revolutionizing-TCAD-Simulations-with-Universal-Device-Encoding-and-Graph-Attention-Networks" class="headerlink" title="Revolutionizing TCAD Simulations with Universal Device Encoding and Graph Attention Networks"></a>Revolutionizing TCAD Simulations with Universal Device Encoding and Graph Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11624">http://arxiv.org/abs/2308.11624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangxi Fan, Kain Lu Low</li>
<li>for: 提出了一种基于人工智能（AI）和图表示的半导体设备编码方法，用于TCAD设备仿真。</li>
<li>methods: 提出了一种图基于的通用编码方案，考虑了材料层和设备层的嵌入，同时还引入了一种新的空间关系嵌入， inspirited by interpolation operations typically used in finite element meshing。</li>
<li>results: 通过利用物理法则和数据驱动模拟，实现了Surrogate Poisson 优化和current-voltage（IV）预测，并使用了一种新的图注意力网络（RelGAT）。<details>
<summary>Abstract</summary>
An innovative methodology that leverages artificial intelligence (AI) and graph representation for semiconductor device encoding in TCAD device simulation is proposed. A graph-based universal encoding scheme is presented that not only considers material-level and device-level embeddings, but also introduces a novel spatial relationship embedding inspired by interpolation operations typically used in finite element meshing. Universal physical laws from device simulations are leveraged for comprehensive data-driven modeling, which encompasses surrogate Poisson emulation and current-voltage (IV) prediction based on drift-diffusion model. Both are achieved using a novel graph attention network, referred to as RelGAT. Comprehensive technical details based on the device simulator Sentaurus TCAD are presented, empowering researchers to adopt the proposed AI-driven Electronic Design Automation (EDA) solution at the device level.
</details>
<details>
<summary>摘要</summary>
一种创新的方法ология，利用人工智能（AI）和图表示法来实现半导体器件编码在TCAD设备仿真中，被提议。这种图基于的通用编码方案不仅考虑材料层和设备层嵌入，还引入了一种新的空间关系嵌入，Draw inspiration from interpolation operations typically used in finite element meshing。通用物理法则从设备仿真中得到了全面的数据驱动模拟，包括代表性函数估计和电压-电流（IV）预测，基于漫步扩散模型。这两个任务都使用了一种新的图注意力网络，称为RelGAT。我们提供了全面的技术细节，以便研究者可以在设备水平采用这种人工智能驱动电子设计自动化（EDA）解决方案。
</details></li>
</ul>
<hr>
<h2 id="Adapt-and-Decompose-Efficient-Generalization-of-Text-to-SQL-via-Domain-Adapted-Least-To-Most-Prompting"><a href="#Adapt-and-Decompose-Efficient-Generalization-of-Text-to-SQL-via-Domain-Adapted-Least-To-Most-Prompting" class="headerlink" title="Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting"></a>Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02582">http://arxiv.org/abs/2308.02582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aseem Arora, Shabbirhussain Bhaisaheb, Harshit Nigam, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff</li>
<li>For: The paper is focused on improving the cross-domain and cross-compositional generalization of Text-to-SQL semantic parsing, which is a challenging task.* Methods: The authors propose an algorithm that performs offline sampling of a minimal set of few-shots from the training data, with complete coverage of SQL clauses, operators, and functions, and maximal domain coverage within the allowed token length. This allows for the synthesis of a fixed Generic Prompt (GP) with a diverse set of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. Additionally, the authors propose an auto-adaptation of the GP to the target database domain (DA-GP) to better handle cross-domain generalization, followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle cross-compositional generalization.* Results: The authors demonstrate superior performance on the KaggleDBQA dataset, designed to evaluate generalizability for the Text-to-SQL task. They also showcase consistent performance improvement of LTMP-DA-GP over GP, across LLMs and databases of KaggleDBQA, highlighting the efficacy and model agnostic benefits of their prompt-based adapt and decompose approach.Here’s the simplified Chinese version of the three information points:* For: 这篇论文旨在解决文本到SQLsemantic parsing中的跨领域和跨组合性泛化问题，这是一项具有挑战性的任务。* Methods: 作者们提出了一种方法，通过在训练数据集上进行Offline sampling，以获取完整的SQL子句、运算符和函数的覆盖，同时保证在允许的Token长度内具备最大的领域覆盖。这allow for the synthesis of a fixed Generic Prompt (GP) with a diverse set of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. 作者们还提出了一种自适应GP到目标数据库领域(DA-GP)，以更好地处理跨领域泛化。此外，他们还提出了一种分解的Least-To-Most-Prompting (LTMP-DA-GP)，以处理跨组合性泛化。* Results: 作者们在KaggleDBQA数据集上展现出了superior的性能，这个数据集是用于评估文本到SQL泛化性能的。他们还显示了LTMP-DA-GP在不同的LLMs和数据库上的一致性提升，这highlights the efficacy and model agnostic benefits of their prompt-based adapt and decompose approach。<details>
<summary>Abstract</summary>
Cross-domain and cross-compositional generalization of Text-to-SQL semantic parsing is a challenging task. Existing Large Language Model (LLM) based solutions rely on inference-time retrieval of few-shot exemplars from the training set to synthesize a run-time prompt for each Natural Language (NL) test query. In contrast, we devise an algorithm which performs offline sampling of a minimal set-of few-shots from the training data, with complete coverage of SQL clauses, operators and functions, and maximal domain coverage within the allowed token length. This allows for synthesis of a fixed Generic Prompt (GP), with a diverse set-of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. We further auto-adapt the GP to the target database domain (DA-GP), to better handle cross-domain generalization; followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline task, to be performed one-time per new database with minimal human intervention. Our approach demonstrates superior performance on the KaggleDBQA dataset, designed to evaluate generalizability for the Text-to-SQL task. We further showcase consistent performance improvement of LTMP-DA-GP over GP, across LLMs and databases of KaggleDBQA, highlighting the efficacy and model agnostic benefits of our prompt based adapt and decompose approach.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:跨Domain和跨组合性的文本到SQLsemantic parsing是一项具有挑战性的任务。现有的大型自然语言模型（LLM）基于解决方案通过推理时间获取少量示例来synthesize每个自然语言（NL）测试查询的运行时提示。相比之下，我们提出了一种算法，它在训练集上进行offline采样，收集了完整的SQL子句、运算符和函数的少量示例，并在允许的字符串长度内保证最大的Domain覆盖。这使得可以synthesize一个固定的通用提示（GP），该提示包含了NL测试查询中共享的多个示例，从而避免了Expensive的测试时间示例重新获取。我们还自动适应了GP到目标数据库Domain（DA-GP），以更好地处理跨Domain泛化。然后，我们使用了 decomposed Least-To-Most-Prompting（LTMP-DA-GP）来处理跨组合性泛化。该synthesis是一个offline任务，需要在新的数据库上进行一次性的人工 intervención。我们的方法在KaggleDBQA数据集上显示了superior的性能，KaggleDBQA数据集是用于评估文本到SQL任务的泛化性能的。我们还在LLMs和KaggleDBQA数据库之间显示了LTMP-DA-GP的性能提升，这highlights our prompt based adapt和decomposeapproach的效果和模型无关性。
</details></li>
</ul>
<hr>
<h2 id="A-Study-of-Unsupervised-Evaluation-Metrics-for-Practical-and-Automatic-Domain-Adaptation"><a href="#A-Study-of-Unsupervised-Evaluation-Metrics-for-Practical-and-Automatic-Domain-Adaptation" class="headerlink" title="A Study of Unsupervised Evaluation Metrics for Practical and Automatic Domain Adaptation"></a>A Study of Unsupervised Evaluation Metrics for Practical and Automatic Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00287">http://arxiv.org/abs/2308.00287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minghao Chen, Zepeng Gao, Shuai Zhao, Qibo Qiu, Wenxiao Wang, Binbin Lin, Xiaofei He<br>for: 本研究旨在开发一种无监督领域适应（Unsupervised Domain Adaptation，UDA）评价度量，能够无需目标验证集来评估转移模型的质量。methods: 本研究使用了基于模型预测的相互信息度量作为起点，并通过实验分析发现了三种常见问题：1）不考虑源结构；2）容易受到攻击；3）无法检测到源和目标特征的过分对应。为解决这些问题，我们在度量中添加了源精度，并使用了一个新的多层感知（MLP）分类器，在训练过程中保持不参与。此外，我们还将这种改进后的度量与数据扩展结合使用，得到了一种新的无监督UDA度量——扩展一致度量（ACM）。results: 我们通过大规模实验证明了我们提出的度量的有效性，并对前一些实验设置的缺点进行了证明。此外，我们还使用了我们提出的度量自动搜索最佳超参数集，在四种常见 benchmark 上达到了超过 manually 调参集的性能。 codes 将很快地公开。<details>
<summary>Abstract</summary>
Unsupervised domain adaptation (UDA) methods facilitate the transfer of models to target domains without labels. However, these methods necessitate a labeled target validation set for hyper-parameter tuning and model selection. In this paper, we aim to find an evaluation metric capable of assessing the quality of a transferred model without access to target validation labels. We begin with the metric based on mutual information of the model prediction. Through empirical analysis, we identify three prevalent issues with this metric: 1) It does not account for the source structure. 2) It can be easily attacked. 3) It fails to detect negative transfer caused by the over-alignment of source and target features. To address the first two issues, we incorporate source accuracy into the metric and employ a new MLP classifier that is held out during training, significantly improving the result. To tackle the final issue, we integrate this enhanced metric with data augmentation, resulting in a novel unsupervised UDA metric called the Augmentation Consistency Metric (ACM). Additionally, we empirically demonstrate the shortcomings of previous experiment settings and conduct large-scale experiments to validate the effectiveness of our proposed metric. Furthermore, we employ our metric to automatically search for the optimal hyper-parameter set, achieving superior performance compared to manually tuned sets across four common benchmarks. Codes will be available soon.
</details>
<details>
<summary>摘要</summary>
无监督领域适应（UDA）方法可以将模型转移到目标领域无需标签。然而，这些方法需要一个标注的目标验证集来调整超参数和选择模型。在这篇论文中，我们想要找到一个可以评估转移模型的评价指标，不需要目标验证集。我们开始于基于模型预测的共同信息度的指标。通过实验分析，我们发现了三个常见的问题：1）它不考虑源结构。2）它可以轻松攻击。3）它无法探测源和目标特征的过对齐导致的负向转移。为了解决这两个问题，我们将源准确率 incorporated 到指标中，并使用一个新的多层感知（MLP）分类器，该分类器在训练时被隐藏。此外，我们还将这个提高后的指标与数据扩展结合使用，得到了一种新的无监督UDA指标——扩展一致指标（ACM）。此外，我们还对之前的实验设置进行了详细的批判，并进行了大规模的实验来验证我们的提出的指标的有效性。最后，我们使用我们的指标自动搜索最佳超参数集，在四个常见的benchmark上达到了人工调整的超参数集的超过表现。代码即将上线。
</details></li>
</ul>
<hr>
<h2 id="Predictive-Modeling-through-Hyper-Bayesian-Optimization"><a href="#Predictive-Modeling-through-Hyper-Bayesian-Optimization" class="headerlink" title="Predictive Modeling through Hyper-Bayesian Optimization"></a>Predictive Modeling through Hyper-Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00285">http://arxiv.org/abs/2308.00285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manisha Senadeera, Santu Rana, Sunil Gupta, Svetha Venkatesh</li>
<li>for: 这 paper 是为了提高 Bayesian 优化（BO） 的模型选择效率，并且同时获取黑板函数的信息。</li>
<li>methods: 这 paper 使用了一种新的方法，即将模型选择和 BO  integrate在一起，以达到更快的函数优化目标。这种方法通过在模型空间和函数空间之间往返，使用一个得分函数来衡量模型的质量，并将其反馈给 BO，以便更快地 convergence。</li>
<li>results: 这 paper 的实验结果表明，使用这种方法可以提高 BO 的样本效率，同时也可以获取黑板函数的信息。此外，这 paper 还证明了这种方法的收敛性。<details>
<summary>Abstract</summary>
Model selection is an integral problem of model based optimization techniques such as Bayesian optimization (BO). Current approaches often treat model selection as an estimation problem, to be periodically updated with observations coming from the optimization iterations. In this paper, we propose an alternative way to achieve both efficiently. Specifically, we propose a novel way of integrating model selection and BO for the single goal of reaching the function optima faster. The algorithm moves back and forth between BO in the model space and BO in the function space, where the goodness of the recommended model is captured by a score function and fed back, capturing how well the model helped convergence in the function space. The score function is derived in such a way that it neutralizes the effect of the moving nature of the BO in the function space, thus keeping the model selection problem stationary. This back and forth leads to quick convergence for both model selection and BO in the function space. In addition to improved sample efficiency, the framework outputs information about the black-box function. Convergence is proved, and experimental results show significant improvement compared to standard BO.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>基于模型的优化技术，如 bayesian 优化（BO），选择模型是一个不可或缺的问题。现有方法通常将模型选择视为估计问题，在优化迭代中 periodic 更新 observations。在本文中，我们提出了一种新的方法，可以快速地达到函数的最优点。该算法在模型空间和函数空间之间往返，使用 BO 来评估模型的好坏，并将其反馈给函数空间中的 BO，以 capture 模型如何帮助函数空间中的 converges。该得分函数是设计的，以 neutralize 模型在函数空间中的移动效果，因此保持模型选择问题的静态性。这种往返机制会使 BO 在函数空间和模型空间中快速 converge。除了提高样本效率之外，该框架还输出了黑板函数的信息。 convergence 的证明和实验结果表明，与标准 BO 相比，该方法具有显著的改进。
</details></li>
</ul>
<hr>
<h2 id="CLAMS-A-Cluster-Ambiguity-Measure-for-Estimating-Perceptual-Variability-in-Visual-Clustering"><a href="#CLAMS-A-Cluster-Ambiguity-Measure-for-Estimating-Perceptual-Variability-in-Visual-Clustering" class="headerlink" title="CLAMS: A Cluster Ambiguity Measure for Estimating Perceptual Variability in Visual Clustering"></a>CLAMS: A Cluster Ambiguity Measure for Estimating Perceptual Variability in Visual Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00284">http://arxiv.org/abs/2308.00284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyeon Jeon, Ghulam Jilani Quadri, Hyunwook Lee, Paul Rosen, Danielle Albers Szafir, Jinwook Seo</li>
<li>for: 这项研究旨在研究可见群分化中的人工智能评估不确定性，以提高数据分析中基于可见群分化的可靠性。</li>
<li>methods: 该研究使用了一种数据驱动的可见质量指标（CLAMS），通过对多个分配对的可分离性进行回归预测，来自动评估可见群分化的不确定性。</li>
<li>results: CLAMS可以更好地预测实际的群分化不确定性，并且与人工标注器的性能相当。此外，该研究还探讨了如何使用CLAMS来优化和benchmark数据挖掘技术。<details>
<summary>Abstract</summary>
Visual clustering is a common perceptual task in scatterplots that supports diverse analytics tasks (e.g., cluster identification). However, even with the same scatterplot, the ways of perceiving clusters (i.e., conducting visual clustering) can differ due to the differences among individuals and ambiguous cluster boundaries. Although such perceptual variability casts doubt on the reliability of data analysis based on visual clustering, we lack a systematic way to efficiently assess this variability. In this research, we study perceptual variability in conducting visual clustering, which we call Cluster Ambiguity. To this end, we introduce CLAMS, a data-driven visual quality measure for automatically predicting cluster ambiguity in monochrome scatterplots. We first conduct a qualitative study to identify key factors that affect the visual separation of clusters (e.g., proximity or size difference between clusters). Based on study findings, we deploy a regression module that estimates the human-judged separability of two clusters. Then, CLAMS predicts cluster ambiguity by analyzing the aggregated results of all pairwise separability between clusters that are generated by the module. CLAMS outperforms widely-used clustering techniques in predicting ground truth cluster ambiguity. Meanwhile, CLAMS exhibits performance on par with human annotators. We conclude our work by presenting two applications for optimizing and benchmarking data mining techniques using CLAMS. The interactive demo of CLAMS is available at clusterambiguity.dev.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。<</SYS>>可见划分是常见的感知任务在散点图中，支持多种分析任务（例如，团结标识）。然而，即使使用同一个散点图，对划分的方式（即进行可见划分）可以因个体差异和杂乱划分boundary而异。尽管如此，我们缺乏一种系统化的方法来效率地评估这种变化。在这项研究中，我们研究可见划分中的变化，我们称之为团结混淆。为此，我们引入CLAMS，一种数据驱动的视觉质量指标，用于自动预测散点图中团结的混淆程度。我们首先进行了资深研究，以确定影响可见划分的关键因素（例如，团结距离或团结大小差）。根据研究结果，我们部署了一个回归模块，以估计人类评估两个团结的可分离程度。然后，CLAMS预测团结混淆程度，通过分析所有对应的划分结果。CLAMS在预测真实团结混淆程度方面表现出色，同时与人类标注器的性能相当。我们结束我们的工作，并将两种用于优化和benchmarking数据挖掘技术的应用示例展示出来。CLAMS的交互式demo可以在clusterambiguity.dev上查看。
</details></li>
</ul>
<hr>
<h2 id="ZADU-A-Python-Library-for-Evaluating-the-Reliability-of-Dimensionality-Reduction-Embeddings"><a href="#ZADU-A-Python-Library-for-Evaluating-the-Reliability-of-Dimensionality-Reduction-Embeddings" class="headerlink" title="ZADU: A Python Library for Evaluating the Reliability of Dimensionality Reduction Embeddings"></a>ZADU: A Python Library for Evaluating the Reliability of Dimensionality Reduction Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00282">http://arxiv.org/abs/2308.00282</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hj-n/zadu">https://github.com/hj-n/zadu</a></li>
<li>paper_authors: Hyeon Jeon, Aeri Cho, Jinhwa Jang, Soohyun Lee, Jake Hyun, Hyung-Kwon Ko, Jaemin Jo, Jinwook Seo</li>
<li>for: 本研究旨在提供一个Python库（ZADU），用于评估维度减少（DR） embedding 的可靠性。</li>
<li>methods: ZADU 提供了广泛的扭曲度量表，并自动优化扭曲度量表的执行，降低了执行多个扭曲度量表所需的时间。</li>
<li>results: 我们透过一个实际的应用情况来验证我们的优化方案，发现这个方案可以对扭曲度量表进行很好的优化。此外，我们还创建了一个名为ZADUVis的库，可以让用户轻松地创建扭曲度量表的可视化图示。<details>
<summary>Abstract</summary>
Dimensionality reduction (DR) techniques inherently distort the original structure of input high-dimensional data, producing imperfect low-dimensional embeddings. Diverse distortion measures have thus been proposed to evaluate the reliability of DR embeddings. However, implementing and executing distortion measures in practice has so far been time-consuming and tedious. To address this issue, we present ZADU, a Python library that provides distortion measures. ZADU is not only easy to install and execute but also enables comprehensive evaluation of DR embeddings through three key features. First, the library covers a wide range of distortion measures. Second, it automatically optimizes the execution of distortion measures, substantially reducing the running time required to execute multiple measures. Last, the library informs how individual points contribute to the overall distortions, facilitating the detailed analysis of DR embeddings. By simulating a real-world scenario of optimizing DR embeddings, we verify that our optimization scheme substantially reduces the time required to execute distortion measures. Finally, as an application of ZADU, we present another library called ZADUVis that allows users to easily create distortion visualizations that depict the extent to which each region of an embedding suffers from distortions.
</details>
<details>
<summary>摘要</summary>
Dimensionality reduction (DR) 技术自然地扭曲输入数据的原始结构，生成不完美的低维度嵌入。为了评估DR嵌入的可靠性，各种不同的扭曲度指标已经被提出。然而，在实践中实施和执行这些指标的问题仍然存在。为解决这个问题，我们介绍了ZADU，一个Python库，它提供了多种扭曲度指标，并且可以自动优化执行扭曲度指标，大幅降低执行多个指标所需的运行时间。此外，ZADU还能够详细分析DR嵌入的扭曲度，让用户了解具体的扭曲度来源。通过模拟一个实际的DR嵌入优化场景，我们证明了我们的优化方案可以减少执行扭曲度指标所需的时间。最后，作为ZADU的应用，我们介绍了ZADUVis，一个可以轻松地创建扭曲度视觉化的库，它可以详细显示嵌入中每个区域受到的扭曲度程度。
</details></li>
</ul>
<hr>
<h2 id="Data-Collaboration-Analysis-applied-to-Compound-Datasets-and-the-Introduction-of-Projection-data-to-Non-IID-settings"><a href="#Data-Collaboration-Analysis-applied-to-Compound-Datasets-and-the-Introduction-of-Projection-data-to-Non-IID-settings" class="headerlink" title="Data Collaboration Analysis applied to Compound Datasets and the Introduction of Projection data to Non-IID settings"></a>Data Collaboration Analysis applied to Compound Datasets and the Introduction of Projection data to Non-IID settings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00280">http://arxiv.org/abs/2308.00280</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akihiro Mizoguchi, Anna Bogdanova, Akira Imakura, Tetsuya Sakurai<br>for: 这个论文主要是研究如何使用分布式机器学习来预测化学物质的性能，以及如何在非同分布（non-IID） Setting下提高预测精度。methods: 这个研究使用了联合学习（Federated Learning）和数据合作分析（Data Collaboration Analysis）等方法来预测化学物质的性能。另外，也提出了一种基于投影数据（Projection Data）的改进方法 called Data Collaboration Analysis using Projection Data（DCPd）。results: 研究发现，在非同分布 Setting下，DCPd的机器学习性能虽然和其他方法相似，但在不同的标签偏好情况下却表现较好，而且与其他方法相比，DCPd在不同标签偏好情况下的性能差异较小。这表明，DCPd可以解决联合学习在非同分布 Setting下的低性能问题。<details>
<summary>Abstract</summary>
Given the time and expense associated with bringing a drug to market, numerous studies have been conducted to predict the properties of compounds based on their structure using machine learning. Federated learning has been applied to compound datasets to increase their prediction accuracy while safeguarding potentially proprietary information. However, federated learning is encumbered by low accuracy in not identically and independently distributed (non-IID) settings, i.e., data partitioning has a large label bias, and is considered unsuitable for compound datasets, which tend to have large label bias. To address this limitation, we utilized an alternative method of distributed machine learning to chemical compound data from open sources, called data collaboration analysis (DC). We also proposed data collaboration analysis using projection data (DCPd), which is an improved method that utilizes auxiliary PubChem data. This improves the quality of individual user-side data transformations for the projection data for the creation of intermediate representations. The classification accuracy, i.e., area under the curve in the receiver operating characteristic curve (ROC-AUC) and AUC in the precision-recall curve (PR-AUC), of federated averaging (FedAvg), DC, and DCPd was compared for five compound datasets. We determined that the machine learning performance for non-IID settings was in the order of DCPd, DC, and FedAvg, although they were almost the same in identically and independently distributed (IID) settings. Moreover, the results showed that compared to other methods, DCPd exhibited a negligible decline in classification accuracy in experiments with different degrees of label bias. Thus, DCPd can address the low performance in non-IID settings, which is one of the challenges of federated learning.
</details>
<details>
<summary>摘要</summary>
因为带药到市场的时间和成本很高，许多研究都是使用机器学习预测药物性质基于其结构。 federated learning 已经应用于药物数据集来提高预测精度，但是在非标一致（non-IID）设置下，其精度低。为了解决这些 limitation，我们使用了一种名为数据合作分析（DC）的 alternativemethod of distributed machine learning to chemical compound data from open sources。我们还提出了基于投影数据（DCPd）的改进方法，该方法使用auxiliary PubChem数据来提高个人用户 сторо面数据变换的质量。我们对五个药物数据集进行了 federated averaging（FedAvg）、DC 和 DCPd 的比较，发现在非标一致设置下，DCPd 的机器学习性能高于 DC 和 FedAvg，尽管在标一致设置下它们几乎相同。此外，结果表明，相比其他方法，DCPd 在不同的标签偏好度下 exhibited 微不足的下降。因此，DCPd 可以解决 federated learning 在非标一致设置下的低性能问题。
</details></li>
</ul>
<hr>
<h2 id="Robust-Positive-Unlabeled-Learning-via-Noise-Negative-Sample-Self-correction"><a href="#Robust-Positive-Unlabeled-Learning-via-Noise-Negative-Sample-Self-correction" class="headerlink" title="Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction"></a>Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00279">http://arxiv.org/abs/2308.00279</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/woriazzc/robust-pu">https://github.com/woriazzc/robust-pu</a></li>
<li>paper_authors: Zhangchi Zhu, Lu Wang, Pu Zhao, Chao Du, Wei Zhang, Hang Dong, Bo Qiao, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang</li>
<li>for: 本研究旨在提高Positive-Unlabeled（PU）学习中 labels uncertainty的影响，提出一种基于人类学习的新robust PU学习方法，以提高学习精度和稳定性。</li>
<li>methods: 本研究提出了一种基于<code>困难度&#39;&#39;度量的训练策略，通过Iterative Training来细化选择负样本的过程，以包括更多的</code>容易’’样本在早期训练阶段。</li>
<li>results: 实验结果表明，该方法可以有效地提高PU学习的精度和稳定性，并且可以在各种学习任务上实现良好的效果。<details>
<summary>Abstract</summary>
Learning from positive and unlabeled data is known as positive-unlabeled (PU) learning in literature and has attracted much attention in recent years. One common approach in PU learning is to sample a set of pseudo-negatives from the unlabeled data using ad-hoc thresholds so that conventional supervised methods can be applied with both positive and negative samples. Owing to the label uncertainty among the unlabeled data, errors of misclassifying unlabeled positive samples as negative samples inevitably appear and may even accumulate during the training processes. Those errors often lead to performance degradation and model instability. To mitigate the impact of label uncertainty and improve the robustness of learning with positive and unlabeled data, we propose a new robust PU learning method with a training strategy motivated by the nature of human learning: easy cases should be learned first. Similar intuition has been utilized in curriculum learning to only use easier cases in the early stage of training before introducing more complex cases. Specifically, we utilize a novel ``hardness'' measure to distinguish unlabeled samples with a high chance of being negative from unlabeled samples with large label noise. An iterative training strategy is then implemented to fine-tune the selection of negative samples during the training process in an iterative manner to include more ``easy'' samples in the early stage of training. Extensive experimental validations over a wide range of learning tasks show that this approach can effectively improve the accuracy and stability of learning with positive and unlabeled data. Our code is available at https://github.com/woriazzc/Robust-PU
</details>
<details>
<summary>摘要</summary>
学习正面和无标签数据的方法，称为正面无标签（PU）学习，在最近几年内吸引了很多关注。一种常见的PU学习方法是从无标签数据中随机选择一些假负样本，使得传统的监督学习方法可以使用正面和负样本。由于无标签数据中的标签不确定，在训练过程中会出现错误地将无标签正样本标记为负样本的现象，这可能会在训练过程中积累。这些错误会导致性能下降和模型不稳定。为了减轻标签不确定性的影响和提高学习正面和无标签数据的稳定性，我们提出了一种新的稳定PU学习方法。我们使用了一种新的“困难度”度量，以分辨无标签样本中高概率是负样本的和大量标签噪音。然后，我们实现了一种迭代训练策略，在训练过程中多次精度地选择负样本，以包括更多的“易于学习”的样本在早期训练阶段。我们对各种学习任务进行了广泛的实验 validate，结果表明，这种方法可以有效地提高学习正面和无标签数据的精度和稳定性。我们的代码可以在https://github.com/woriazzc/Robust-PU中找到。
</details></li>
</ul>
<hr>
<h2 id="Classes-are-not-Clusters-Improving-Label-based-Evaluation-of-Dimensionality-Reduction"><a href="#Classes-are-not-Clusters-Improving-Label-based-Evaluation-of-Dimensionality-Reduction" class="headerlink" title="Classes are not Clusters: Improving Label-based Evaluation of Dimensionality Reduction"></a>Classes are not Clusters: Improving Label-based Evaluation of Dimensionality Reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00278">http://arxiv.org/abs/2308.00278</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hj-n/ltnc">https://github.com/hj-n/ltnc</a></li>
<li>paper_authors: Hyeon Jeon, Yun-Hsin Kuo, Michaël Aupetit, Kwan-Liu Ma, Jinwook Seo</li>
<li>for: 本文旨在提供一种新的方法来评估维度减少（DR）嵌入的可靠性，并基于类标签进行评估。</li>
<li>methods: 本文提出了两种新的质量指标：标签可靠性（Label-Trustworthiness）和标签连续性（Label-Continuity），以评估DR嵌入的质量。</li>
<li>results: 对比于传统的DR评估方法（如可靠性和连续性，库拉布-莱布尔差异），Label-T&amp;C表现更高的准确性，并且可扩展到大规模数据集。此外，本文还提供了一些实践案例，用于揭示DR技术和其超参数的内在特性。<details>
<summary>Abstract</summary>
A common way to evaluate the reliability of dimensionality reduction (DR) embeddings is to quantify how well labeled classes form compact, mutually separated clusters in the embeddings. This approach is based on the assumption that the classes stay as clear clusters in the original high-dimensional space. However, in reality, this assumption can be violated; a single class can be fragmented into multiple separated clusters, and multiple classes can be merged into a single cluster. We thus cannot always assure the credibility of the evaluation using class labels. In this paper, we introduce two novel quality measures -- Label-Trustworthiness and Label-Continuity (Label-T&C) -- advancing the process of DR evaluation based on class labels. Instead of assuming that classes are well-clustered in the original space, Label-T&C work by (1) estimating the extent to which classes form clusters in the original and embedded spaces and (2) evaluating the difference between the two. A quantitative evaluation showed that Label-T&C outperform widely used DR evaluation measures (e.g., Trustworthiness and Continuity, Kullback-Leibler divergence) in terms of the accuracy in assessing how well DR embeddings preserve the cluster structure, and are also scalable. Moreover, we present case studies demonstrating that Label-T&C can be successfully used for revealing the intrinsic characteristics of DR techniques and their hyperparameters.
</details>
<details>
<summary>摘要</summary>
一种常见的维度减少（DR） embedding 评估方法是通过衡量 labels 是否形成紧凑、相互隔离的群集来评估 embedding 的可靠性。这种方法假设高维空间中的类具有清晰的分布，但在实际情况下，这种假设可能被违反；一个类可能会被分割成多个分立的群集，多个类可能会被合并为一个群集。因此，我们无法一直保证评估使用类标签的可靠性。在这篇论文中，我们引入了两种新的质量指标：Label-Trustworthiness 和 Label-Continuity（Label-T&C），这些指标旨在基于类标签来评估维度减少 embedding 的可靠性。不同于假设高维空间中的类具有清晰的分布，Label-T&C 通过（1）估计原始和嵌入空间中类的群集程度，（2）评估这两个空间之间的差异来评估维度减少 embedding 的可靠性。一个量化评估表明，Label-T&C 在评估维度减少 embedding 保持类群结构的准确性方面表现出色，并且可扩展性也高。此外，我们还提供了用 Label-T&C 评估维度减少技术和其超参数的实际案例研究。
</details></li>
</ul>
<hr>
<h2 id="Neural-approximation-of-Wasserstein-distance-via-a-universal-architecture-for-symmetric-and-factorwise-group-invariant-functions"><a href="#Neural-approximation-of-Wasserstein-distance-via-a-universal-architecture-for-symmetric-and-factorwise-group-invariant-functions" class="headerlink" title="Neural approximation of Wasserstein distance via a universal architecture for symmetric and factorwise group invariant functions"></a>Neural approximation of Wasserstein distance via a universal architecture for symmetric and factorwise group invariant functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00273">http://arxiv.org/abs/2308.00273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samantha Chen, Yusu Wang</li>
<li>for: 本研究旨在设计一种能够近似 Wasserstein 距离的神经网络模型，并且可以独立于输入点集的大小进行模型训练。</li>
<li>methods: 我们提出了一种基于神经网络的总体架构，用于近似 Symmetric 和 Factor-wise Group Invariant（SFGI）函数。我们还 combinated 这种总体神经网络模型与一种卷积技术来开发一种特定和高效的神经网络模型，用于approximating Wasserstein 距离。</li>
<li>results: 我们的实验结果表明，我们所提出的神经网络模型在许多方面比其他模型（包括 SOTA Siamese Autoencoder 方法）perform 更好，并且可以更好地泛化和更快速地训练。<details>
<summary>Abstract</summary>
Learning distance functions between complex objects, such as the Wasserstein distance to compare point sets, is a common goal in machine learning applications. However, functions on such complex objects (e.g., point sets and graphs) are often required to be invariant to a wide variety of group actions e.g. permutation or rigid transformation. Therefore, continuous and symmetric product functions (such as distance functions) on such complex objects must also be invariant to the product of such group actions. We call these functions symmetric and factor-wise group invariant (or SFGI functions in short). In this paper, we first present a general neural network architecture for approximating SFGI functions. The main contribution of this paper combines this general neural network with a sketching idea to develop a specific and efficient neural network which can approximate the $p$-th Wasserstein distance between point sets. Very importantly, the required model complexity is independent of the sizes of input point sets. On the theoretical front, to the best of our knowledge, this is the first result showing that there exists a neural network with the capacity to approximate Wasserstein distance with bounded model complexity. Our work provides an interesting integration of sketching ideas for geometric problems with universal approximation of symmetric functions. On the empirical front, we present a range of results showing that our newly proposed neural network architecture performs comparatively or better than other models (including a SOTA Siamese Autoencoder based approach). In particular, our neural network generalizes significantly better and trains much faster than the SOTA Siamese AE. Finally, this line of investigation could be useful in exploring effective neural network design for solving a broad range of geometric optimization problems (e.g., $k$-means in a metric space).
</details>
<details>
<summary>摘要</summary>
学习 Complex 对象之间的距离函数，如 Wasserstein 距离比较点集，是机器学习应用中常见的目标。然而，函数在这些复杂对象上（例如点集和图）经常需要对广泛的群作用（例如 permutation 或扭转变换）进行抗变换。因此，在这些复杂对象上的连续和共轭产品函数（如距离函数）必须对群作用的乘积进行抗变换。我们称这类函数为共轭和因子化群作用抗变换函数（SFGI 函数）。在这篇论文中，我们首先提出一种通用的神经网络架构，用于近似 SFGI 函数。我们的主要贡献是将这种通用神经网络与抽象思想结合，开发了特定和高效的神经网络，用于近似 $p$-th Wasserstein 距离 between 点集。非常重要的是，模型复杂度不依赖输入点集的大小。在理论上，我们的结果表明，存在一种能够近似 Wasserstein 距离的神经网络，并且其模型复杂度受到输入点集的大小的限制。我们的工作提供了对几何问题的解决方案的有趣的整合，以及通用神经网络的近似Symmetric 函数的能力。在实际方面，我们发现我们的新提出的神经网络架构在多个实际问题中表现较好，比如 SOTA Siamese Autoencoder 基于方法。具体来说，我们的神经网络在泛化和训练速度方面表现较好，而且可以在训练时更好地控制模型的复杂度。最后，这种研究方向可能会对解决广泛的几何优化问题（例如 metric 空间中的 $k$-means）提供有用的思路。
</details></li>
</ul>
<hr>
<h2 id="Multi-Modality-Multi-Loss-Fusion-Network"><a href="#Multi-Modality-Multi-Loss-Fusion-Network" class="headerlink" title="Multi-Modality Multi-Loss Fusion Network"></a>Multi-Modality Multi-Loss Fusion Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00264">http://arxiv.org/abs/2308.00264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zehui Wu, Ziwei Gong, Jaywon Koo, Julia Hirschberg</li>
<li>for: 本研究探讨多modalities Feature选择和融合的优化方法，以提高情感识别性能。</li>
<li>methods: 本研究使用多种融合方法，并 investigate multi-loss training的影响于多模态融合网络性能。</li>
<li>results: 我们的最佳模型在三个dataset（CMU-MOSI、CMU-MOSEI和CH-SIMS）上达到了状态之arte性能，并在大多数指标中超越其他方法。我们发现，训练在多模态特征上可以提高单模态测试性能，而根据数据集注释schema设计融合方法可以提高模型性能。这些结果提供了优化特征选择和融合方法的路线图，以提高情感识别 neural network 性能。<details>
<summary>Abstract</summary>
In this work we investigate the optimal selection and fusion of features across multiple modalities and combine these in a neural network to improve emotion detection. We compare different fusion methods and examine the impact of multi-loss training within the multi-modality fusion network, identifying useful findings relating to subnet performance. Our best model achieves state-of-the-art performance for three datasets (CMU-MOSI, CMU-MOSEI and CH-SIMS), and outperforms the other methods in most metrics. We have found that training on multimodal features improves single modality testing and designing fusion methods based on dataset annotation schema enhances model performance. These results suggest a roadmap towards an optimized feature selection and fusion approach for enhancing emotion detection in neural networks.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们调查了不同Modalities之间的最佳选择和融合方法，并将这些方法 integrate into a neural network 以提高情感识别。我们比较了不同的融合方法，并查看了在多模态融合网络中多loss训练的影响，发现有用的发现关于子网络性能。我们的最佳模型在CMU-MOSI、CMU-MOSEI和CH-SIMS三个 datasets 上达到了状态机器的性能，并在大多数指标中超过其他方法。我们发现，在多模态特征上进行训练可以提高单模态测试，而基于dataset annotation schema的融合方法设计可以提高模型性能。这些结果提供了增强情感识别在神经网络中的优化特征选择和融合方法的路线图。
</details></li>
</ul>
<hr>
<h2 id="Asynchronous-Federated-Learning-with-Bidirectional-Quantized-Communications-and-Buffered-Aggregation"><a href="#Asynchronous-Federated-Learning-with-Bidirectional-Quantized-Communications-and-Buffered-Aggregation" class="headerlink" title="Asynchronous Federated Learning with Bidirectional Quantized Communications and Buffered Aggregation"></a>Asynchronous Federated Learning with Bidirectional Quantized Communications and Buffered Aggregation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00263">http://arxiv.org/abs/2308.00263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tomas Ortega, Hamid Jafarkhani</li>
<li>for: 提高 Federated Learning 的效率和可扩展性</li>
<li>methods: 使用量化通信 schemes 和 shared “hidden” state 技术</li>
<li>results: 提供了理论上的 convergence guarantees 和实验 validate Results on 标准 benchmark 上<details>
<summary>Abstract</summary>
Asynchronous Federated Learning with Buffered Aggregation (FedBuff) is a state-of-the-art algorithm known for its efficiency and high scalability. However, it has a high communication cost, which has not been examined with quantized communications. To tackle this problem, we present a new algorithm (QAFeL), with a quantization scheme that establishes a shared "hidden" state between the server and clients to avoid the error propagation caused by direct quantization. This approach allows for high precision while significantly reducing the data transmitted during client-server interactions. We provide theoretical convergence guarantees for QAFeL and corroborate our analysis with experiments on a standard benchmark.
</details>
<details>
<summary>摘要</summary>
“异步联合学习（FedBuff）”是当前最佳实践，具有高效率和可扩展性。然而，它具有高通信成本，这未曾与量化通信相关研究。为解决这个问题，我们提出了一个新算法（QAFeL），具有量化方案，在服务器和客户端之间共享一个“隐藏”状态，以避免因直接量化而导致的错误协议。这种方法允许高精度，同时减少了在客户端-服务器交互中传输的数据量。我们提供了论证性的收敛保证，并在标准 benchmark 上进行了实验 validate。
</details></li>
</ul>
<hr>
<h2 id="AQUILA-Communication-Efficient-Federated-Learning-with-Adaptive-Quantization-of-Lazily-Aggregated-Gradients"><a href="#AQUILA-Communication-Efficient-Federated-Learning-with-Adaptive-Quantization-of-Lazily-Aggregated-Gradients" class="headerlink" title="AQUILA: Communication Efficient Federated Learning with Adaptive Quantization of Lazily-Aggregated Gradients"></a>AQUILA: Communication Efficient Federated Learning with Adaptive Quantization of Lazily-Aggregated Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00258">http://arxiv.org/abs/2308.00258</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihao Zhao, Yuzhu Mao, Zhenpeng Shi, Yang Liu, Tian Lan, Wenbo Ding, Xiao-Ping Zhang</li>
<li>for: 提高 Federated Learning（分布式学习）的效率和可靠性，解决高通信开销和模型偏差问题。</li>
<li>methods: 提出了一种名为AQUILA（批量化的强化器）的新的适应性框架，通过优化设备选择和量化方法，提高分布式学习的效率和可靠性。</li>
<li>results: 在非同一样式的分布式学习 Setting中，AQUILA 可以大幅减少通信成本，同时保持模型性能的相似性，并且可以适应不同的设备和数据偏差。<details>
<summary>Abstract</summary>
The widespread adoption of Federated Learning (FL), a privacy-preserving distributed learning methodology, has been impeded by the challenge of high communication overheads, typically arising from the transmission of large-scale models. Existing adaptive quantization methods, designed to mitigate these overheads, operate under the impractical assumption of uniform device participation in every training round. Additionally, these methods are limited in their adaptability due to the necessity of manual quantization level selection and often overlook biases inherent in local devices' data, thereby affecting the robustness of the global model. In response, this paper introduces AQUILA (adaptive quantization of lazily-aggregated gradients), a novel adaptive framework devised to effectively handle these issues, enhancing the efficiency and robustness of FL. AQUILA integrates a sophisticated device selection method that prioritizes the quality and usefulness of device updates. Utilizing the exact global model stored by devices, it enables a more precise device selection criterion, reduces model deviation, and limits the need for hyperparameter adjustments. Furthermore, AQUILA presents an innovative quantization criterion, optimized to improve communication efficiency while assuring model convergence. Our experiments demonstrate that AQUILA significantly decreases communication costs compared to existing methods, while maintaining comparable model performance across diverse non-homogeneous FL settings, such as Non-IID data and heterogeneous model architectures.
</details>
<details>
<summary>摘要</summary>
通用学习（FL）的广泛采用受到了大规模模型的传输 overhead 的挑战。现有的 adaptive quantization 方法可以减少这些 overhead，但是它们假设所有训练轮都有 uniform 的设备参与，并且它们的适应性受限，因为需要手动选择 quantization 级别。此外，这些方法通常会忽略本地设备数据中的偏见，从而影响全局模型的稳定性。为此，这篇论文提出了 AQUILA（适应量化 Lazy 梯度），一种新的适应性框架，可以有效地解决这些问题，提高 FL 的效率和稳定性。AQUILA  integrates 一种智能的设备选择方法，根据设备更新的质量和用用性来优先选择设备。通过使用设备上存储的准确全球模型，AQUILA 可以更准确地选择设备，降低模型偏差，并减少 hyperparameter 调整的需求。此外，AQUILA 还提出了一种优化的量化标准，可以提高通信效率，保证模型收敛。我们的实验表明，AQUILA 比现有方法更有效地减少通信成本，同时保持非常多样化的 FL 设定下的模型性能相对一致。
</details></li>
</ul>
<hr>
<h2 id="Best-Subset-Selection-in-Generalized-Linear-Models-A-Fast-and-Consistent-Algorithm-via-Splicing-Technique"><a href="#Best-Subset-Selection-in-Generalized-Linear-Models-A-Fast-and-Consistent-Algorithm-via-Splicing-Technique" class="headerlink" title="Best-Subset Selection in Generalized Linear Models: A Fast and Consistent Algorithm via Splicing Technique"></a>Best-Subset Selection in Generalized Linear Models: A Fast and Consistent Algorithm via Splicing Technique</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00251">http://arxiv.org/abs/2308.00251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junxian Zhu, Jin Zhu, Borui Tang, Xuanyu Chen, Hongmei Lin, Xueqin Wang</li>
<li>for: 这篇论文的目的是为了提出一个高维度普通线性模型中的简洁模型，以便更好地处理响应的变化。</li>
<li>methods: 这篇论文使用了一个快速的算法来选择最佳子集，并且在定理Conditions下提出了一个算法。</li>
<li>results: 根据实验结果，这个方法可以在高维度情况下更好地选择最佳子集，并且比较快速，相比之下glmnet和ncvreg等工具kit更快。<details>
<summary>Abstract</summary>
In high-dimensional generalized linear models, it is crucial to identify a sparse model that adequately accounts for response variation. Although the best subset section has been widely regarded as the Holy Grail of problems of this type, achieving either computational efficiency or statistical guarantees is challenging. In this article, we intend to surmount this obstacle by utilizing a fast algorithm to select the best subset with high certainty. We proposed and illustrated an algorithm for best subset recovery in regularity conditions. Under mild conditions, the computational complexity of our algorithm scales polynomially with sample size and dimension. In addition to demonstrating the statistical properties of our method, extensive numerical experiments reveal that it outperforms existing methods for variable selection and coefficient estimation. The runtime analysis shows that our implementation achieves approximately a fourfold speedup compared to popular variable selection toolkits like glmnet and ncvreg.
</details>
<details>
<summary>摘要</summary>
高维度泛化线性模型中，必须确定一个稀畴模型，以便准确地考虑响应的变化。虽然最佳子集问题被广泛认为是这类问题的圣杯，但是实现计算效率或统计保证是困难的。在这篇文章中，我们想要通过使用快速的算法来选择最佳子集，以确保高度的确定性。我们提出了一种算法来实现最佳子集恢复，并在正则条件下进行了推广。对于样本大小和维度，我们的算法的计算复杂度随样本大小和维度的幂次方式增长。除了证明我们的方法的统计性质外，我们还进行了广泛的数值实验，发现我们的方法可以在变量选择和系数估计方面超越现有的方法。我们的实现的运行时间分析表明，我们的实现可以相比popular变量选择工具包如glmnet和ncvreg achieve approximately fourfold speedup.
</details></li>
</ul>
<hr>
<h2 id="EEG-based-Cognitive-Load-Classification-using-Feature-Masked-Autoencoding-and-Emotion-Transfer-Learning"><a href="#EEG-based-Cognitive-Load-Classification-using-Feature-Masked-Autoencoding-and-Emotion-Transfer-Learning" class="headerlink" title="EEG-based Cognitive Load Classification using Feature Masked Autoencoding and Emotion Transfer Learning"></a>EEG-based Cognitive Load Classification using Feature Masked Autoencoding and Emotion Transfer Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00246">http://arxiv.org/abs/2308.00246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dustin Pulver, Prithila Angkan, Paul Hungler, Ali Etemad</li>
<li>for: 这篇论文主要目的是提出一种基于电enzephalogram(EEG)的认知负担分类方法。</li>
<li>methods: 该方法使用变换器架构，通过跨越情感和认知负担的学习转移来进行分类。文章首先使用自我监睹带有隐藏标签的批处理自动编码来预训练模型，然后使用冻结权重和细化调整来进行下游认知负担分类。</li>
<li>results: 实验结果显示，提出的方法可以达到强劲的结果，并且超过了传统的单阶段完全监睹学习。此外，文章还进行了细化和敏感性研究，以评估不同方法的影响。这篇研究对情感计算和认知负担领域的发展做出了贡献，并开启了新的跨领域转移学习和自我监睹预训练的研究途径。<details>
<summary>Abstract</summary>
Cognitive load, the amount of mental effort required for task completion, plays an important role in performance and decision-making outcomes, making its classification and analysis essential in various sensitive domains. In this paper, we present a new solution for the classification of cognitive load using electroencephalogram (EEG). Our model uses a transformer architecture employing transfer learning between emotions and cognitive load. We pre-train our model using self-supervised masked autoencoding on emotion-related EEG datasets and use transfer learning with both frozen weights and fine-tuning to perform downstream cognitive load classification. To evaluate our method, we carry out a series of experiments utilizing two publicly available EEG-based emotion datasets, namely SEED and SEED-IV, for pre-training, while we use the CL-Drive dataset for downstream cognitive load classification. The results of our experiments show that our proposed approach achieves strong results and outperforms conventional single-stage fully supervised learning. Moreover, we perform detailed ablation and sensitivity studies to evaluate the impact of different aspects of our proposed solution. This research contributes to the growing body of literature in affective computing with a focus on cognitive load, and opens up new avenues for future research in the field of cross-domain transfer learning using self-supervised pre-training.
</details>
<details>
<summary>摘要</summary>
“认知负担”，指的是完成任务所需的心理努力量，在完成任务和做出决策时扮演着重要的角色。因此，认知负担的分类和分析在各种敏感领域都是非常重要的。在这篇论文中，我们提出了一个新的认知负担分类方法，使用电enzephalogram（EEG）。我们的模型使用transformer架构，通过将情感和认知负担之间的学习整合在一起。我们在这个模型中使用了自我监督隐藏式复原，并使用两种方法：冻结重量和精确地复原，进行下游认知负担分类。为了评估我们的方法，我们在两个公开 disponibile EEG基于情感 datasets，namely SEED和SEED-IV，进行预训练，而下游认知负担分类则使用CL-Drive dataset。实验结果显示，我们的提出方法具有强大的表现和超越传统单阶充足学习。此外，我们还进行了细节抑制和敏感性研究，以评估不同方面的影响。这些研究将对情感 computing的发展做出贡献，并开启了跨领域批量学习使用自我监督隐藏式预训练的新领域。
</details></li>
</ul>
<hr>
<h2 id="Beam-Detection-Based-on-Machine-Learning-Algorithms"><a href="#Beam-Detection-Based-on-Machine-Learning-Algorithms" class="headerlink" title="Beam Detection Based on Machine Learning Algorithms"></a>Beam Detection Based on Machine Learning Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00718">http://arxiv.org/abs/2308.00718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyuan Li, Qing Yin</li>
<li>for:  precisely determine the positions of free electron laser beams on screens</li>
<li>methods:  sequence of machine learning models, including transfer training in a self-constructed convolutional neural network based on VGG16 model and support vector regression model</li>
<li>results: 85.8% correct prediction on test data<details>
<summary>Abstract</summary>
The positions of free electron laser beams on screens are precisely determined by a sequence of machine learning models. Transfer training is conducted in a self-constructed convolutional neural network based on VGG16 model. Output of intermediate layers are passed as features to a support vector regression model. With this sequence, 85.8% correct prediction is achieved on test data.
</details>
<details>
<summary>摘要</summary>
文本中的自由电子激光束在屏幕上的位置精确地由一个机器学习模式序列确定。在自己构建的卷积神经网络基于VGG16模型中进行了传输训练。输出的中间层的输出被用作特征传递到支持向量回归模型。通过这个序列，在测试数据上达到了85.8%的正确预测率。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="ChatMOF-An-Autonomous-AI-System-for-Predicting-and-Generating-Metal-Organic-Frameworks"><a href="#ChatMOF-An-Autonomous-AI-System-for-Predicting-and-Generating-Metal-Organic-Frameworks" class="headerlink" title="ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks"></a>ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01423">http://arxiv.org/abs/2308.01423</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yeonghun1675/chatmof">https://github.com/yeonghun1675/chatmof</a></li>
<li>paper_authors: Yeonghun Kang, Jihan Kim</li>
<li>for: 这个论文是为了探讨和应用大型自然语言处理模型（LLMs）在物理科学中的可能性和限制，以及其在结构材料预测和生成方面的表现。</li>
<li>methods: 该论文使用了一种自动化的人工智能系统，即ChatMOF，该系统基于大型语言模型（gpt-3.5-turbo），可以从文本输入中提取关键信息并提供相应的回答，从而消除了僵化的结构化查询的需要。</li>
<li>results: 研究表明，使用LLMs可以在物理科学中实现高精度的结构材料预测和生成，并且可以帮助找到新的结构材料和应用。同时，研究也揭示了使用LLMs的一些缺点和限制。<details>
<summary>Abstract</summary>
ChatMOF is an autonomous Artificial Intelligence (AI) system that is built to predict and generate of metal-organic frameworks (MOFs). By leveraging a large-scale language model (gpt-3.5-turbo), ChatMOF extracts key details from textual inputs and delivers appropriate responses, thus eliminating the necessity for rigid structured queries. The system is comprised of three core components (i.e. an agent, a toolkit, and an evaluator) and it forms a robust pipeline that manages a variety of tasks, including data retrieval, property prediction, and structure generation. The study further explores the merits and constraints of using large language models (LLMs) AI system in material sciences using and showcases its transformative potential for future advancements.
</details>
<details>
<summary>摘要</summary>
chatMOF 是一个无人驾驶的人工智能系统（AI），用于预测和生成金属有机框架（MOFs）。通过充分利用大规模语言模型（gpt-3.5-turbo），chatMOF 从文本输入中提取重要资讯，并提供适当的回应，因此消除了僵化的结构化查询的需要。系统由三个核心 ком成分（即代理人、工具组和评估器）组成，形成一个完整的管道，处理许多任务，包括数据检索、属性预测和结构生成。研究进一步探讨使用大语言模型（LLMs）AI系统在材料科学中的优点和缺点，并展示其将来发展的transformative潜力。
</details></li>
</ul>
<hr>
<h2 id="Capsa-A-Unified-Framework-for-Quantifying-Risk-in-Deep-Neural-Networks"><a href="#Capsa-A-Unified-Framework-for-Quantifying-Risk-in-Deep-Neural-Networks" class="headerlink" title="Capsa: A Unified Framework for Quantifying Risk in Deep Neural Networks"></a>Capsa: A Unified Framework for Quantifying Risk in Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00231">http://arxiv.org/abs/2308.00231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadhana Lolla, Iaroslav Elistratov, Alejandro Perez, Elaheh Ahmadi, Daniela Rus, Alexander Amini</li>
<li>for: 提高大规模深度神经网络（NNs）的风险意识和可靠性。</li>
<li>methods: 提出了一种框架，可以将多种风险形式的量化和不同风险量化算法相互组合，以提供更全面的风险意识。</li>
<li>results: 在复杂的感知 datasets 上，通过实现现有的不确定性估计算算法，证明了 capsa 框架可以轻松地组合不同类型的风险量化算法，并提供了全面的风险意识。<details>
<summary>Abstract</summary>
The modern pervasiveness of large-scale deep neural networks (NNs) is driven by their extraordinary performance on complex problems but is also plagued by their sudden, unexpected, and often catastrophic failures, particularly on challenging scenarios. Existing algorithms that provide risk-awareness to NNs are complex and ad-hoc. Specifically, these methods require significant engineering changes, are often developed only for particular settings, and are not easily composable. Here we present capsa, a framework for extending models with risk-awareness. Capsa provides a methodology for quantifying multiple forms of risk and composing different algorithms together to quantify different risk metrics in parallel. We validate capsa by implementing state-of-the-art uncertainty estimation algorithms within the capsa framework and benchmarking them on complex perception datasets. We demonstrate capsa's ability to easily compose aleatoric uncertainty, epistemic uncertainty, and bias estimation together in a single procedure, and show how this approach provides a comprehensive awareness of NN risk.
</details>
<details>
<summary>摘要</summary>
现代大规模深度神经网络（NN）的广泛应用受其在复杂问题上的非凡表现驱动，但同时也受到其意外、不可预期的失败的威胁，尤其是在复杂的场景下。现有的风险意识提供方法都是复杂且尝试性的，需要大量的工程改进，通常只适用于特定的场景，并且不易组合。我们提出了capsa框架，用于扩展模型的风险意识。capsa提供了多种风险量化的方法ology，可以并行量化不同的风险指标。我们通过在capsa框架中实现现状风险估计算法，并对复杂的感知数据集进行了 benchmarking，以示capsa的能力可以轻松地组合不同的风险估计算法，并提供全面的NN风险意识。
</details></li>
</ul>
<hr>
<h2 id="Instructed-to-Bias-Instruction-Tuned-Language-Models-Exhibit-Emergent-Cognitive-Bias"><a href="#Instructed-to-Bias-Instruction-Tuned-Language-Models-Exhibit-Emergent-Cognitive-Bias" class="headerlink" title="Instructed to Bias: Instruction-Tuned Language Models Exhibit Emergent Cognitive Bias"></a>Instructed to Bias: Instruction-Tuned Language Models Exhibit Emergent Cognitive Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00225">http://arxiv.org/abs/2308.00225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Itay Itzhak, Gabriel Stanovsky, Nir Rosenfeld, Yonatan Belinkov</li>
<li>for: 本研究旨在探讨大语言模型（LM）在受到人类反馈指导下进行调教后，是否会受到更多的偏见。</li>
<li>methods: 本研究使用了三种常见的偏见（即嘱结效应、信任效应和信仰偏见）来检测大语言模型中的偏见。</li>
<li>results: 研究发现，经过 instruciton 调教的模型具有更多的偏见，尤其是 Flan-T5、GPT3.5 和 GPT4 等模型。这些偏见在人类决策和理解中都有表现。<details>
<summary>Abstract</summary>
Recent studies show that instruction tuning and learning from human feedback improve the abilities of large language models (LMs) dramatically. While these tuning methods can make models generate high-quality text, we conjecture that more implicit cognitive biases may arise in these fine-tuned models. Our work provides evidence that these fine-tuned models exhibit biases that were absent or less pronounced in their pretrained predecessors. We examine the extent of this phenomenon in three cognitive biases - the decoy effect, the certainty effect, and the belief bias - all of which are known to influence human decision-making and reasoning. Our findings highlight the presence of these biases in various models, especially those that have undergone instruction tuning, such as Flan-T5, GPT3.5, and GPT4. This research constitutes a step toward comprehending cognitive biases in instruction-tuned LMs, which is crucial for the development of more reliable and unbiased language models.
</details>
<details>
<summary>摘要</summary>
latest studies show that instruction tuning and learning from human feedback can significantly improve the abilities of large language models (LMs). while these tuning methods can make models generate high-quality text, we speculate that more implicit cognitive biases may arise in these fine-tuned models. our work provides evidence that these fine-tuned models exhibit biases that were absent or less pronounced in their pretrained predecessors. we examine the extent of this phenomenon in three cognitive biases - the decoy effect, the certainty effect, and the belief bias - all of which are known to influence human decision-making and reasoning. our findings highlight the presence of these biases in various models, especially those that have undergone instruction tuning, such as Flan-T5, GPT3.5, and GPT4. this research constitutes a step toward comprehending cognitive biases in instruction-tuned LMs, which is crucial for the development of more reliable and unbiased language models.
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-Based-Battery-Conditioning-Hierarchical-V2G-Coordination-for-Multi-Stakeholder-Benefits"><a href="#Deep-Reinforcement-Learning-Based-Battery-Conditioning-Hierarchical-V2G-Coordination-for-Multi-Stakeholder-Benefits" class="headerlink" title="Deep Reinforcement Learning-Based Battery Conditioning Hierarchical V2G Coordination for Multi-Stakeholder Benefits"></a>Deep Reinforcement Learning-Based Battery Conditioning Hierarchical V2G Coordination for Multi-Stakeholder Benefits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00218">http://arxiv.org/abs/2308.00218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubao Zhang, Xin Chen, Yi Gu, Zhicheng Li, Wu Kai</li>
<li>for: 提高可再生能源利用率和电网稳定性，适用于大规模EV充电 scheduling 策略</li>
<li>methods: 基于深度遗产 reinforcement learning 和 Proof of Stake 算法，实现多方利益协调</li>
<li>results: 相比四种基准方案，多方协调策略可以提高可再生能源消耗率、缓和负荷波动、满足EV充电商需求，降低充电成本和电池质量下降<details>
<summary>Abstract</summary>
With the growing prevalence of electric vehicles (EVs) and advancements in EV electronics, vehicle-to-grid (V2G) techniques and large-scale scheduling strategies have emerged to promote renewable energy utilization and power grid stability. This study proposes a multi-stakeholder hierarchical V2G coordination based on deep reinforcement learning (DRL) and the Proof of Stake algorithm. Furthermore, the multi-stakeholders include the power grid, EV aggregators (EVAs), and users, and the proposed strategy can achieve multi-stakeholder benefits. On the grid side, load fluctuations and renewable energy consumption are considered, while on the EVA side, energy constraints and charging costs are considered. The three critical battery conditioning parameters of battery SOX are considered on the user side, including state of charge, state of power, and state of health. Compared with four typical baselines, the multi-stakeholder hierarchical coordination strategy can enhance renewable energy consumption, mitigate load fluctuations, meet the energy demands of EVA, and reduce charging costs and battery degradation under realistic operating conditions.
</details>
<details>
<summary>摘要</summary>
On the grid side, the approach takes into account load fluctuations and renewable energy consumption, while on the EVA side, it considers energy constraints and charging costs. For users, the approach considers three critical battery conditioning parameters: state of charge, state of power, and state of health.Compared to four typical baselines, the multi-stakeholder hierarchical coordination strategy can enhance renewable energy consumption, mitigate load fluctuations, meet the energy demands of EVA, and reduce charging costs and battery degradation under realistic operating conditions.
</details></li>
</ul>
<hr>
<h2 id="Robust-Single-view-Cone-beam-X-ray-Pose-Estimation-with-Neural-Tuned-Tomography-NeTT-and-Masked-Neural-Radiance-Fields-mNeRF"><a href="#Robust-Single-view-Cone-beam-X-ray-Pose-Estimation-with-Neural-Tuned-Tomography-NeTT-and-Masked-Neural-Radiance-Fields-mNeRF" class="headerlink" title="Robust Single-view Cone-beam X-ray Pose Estimation with Neural Tuned Tomography (NeTT) and Masked Neural Radiance Fields (mNeRF)"></a>Robust Single-view Cone-beam X-ray Pose Estimation with Neural Tuned Tomography (NeTT) and Masked Neural Radiance Fields (mNeRF)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00214">http://arxiv.org/abs/2308.00214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaochao Zhou, Syed Hasib Akhter Faruqui, Abhinav Patel, Ramez N. Abdalla, Michael C. Hurley, Ali Shaibani, Matthew B. Potts, Babak S. Jahromi, Leon Cho, Sameer A. Ansari, Donald R. Cantrell</li>
<li>for: 这篇论文是用于提出新的方法来进行镜像干扰物体pose estimation，使用X射线投影来达到3D空间中的目标。</li>
<li>methods: 这篇论文使用了新的拟合渠道技术来计算数字重建成像（DRR），并使用TensorFlow中的自动导数来实现可导的渠道。pose estimation是通过 iterative gradient descent 使用一个loss函数来衡量DRR Synthesized从一个随机初始化的pose和真实的镜像图像在目标pose之间的相似性来进行。</li>
<li>results: 这篇论文提出了两种新的高精度视图合成方法，即Neural Tuned Tomography（NeTT）和masked Neural Radiance Fields（mNeRF）。这两种方法都基于经典的扁球计算机断层成像（CBCT），NeTT直接优化CBCT的密度，而mNeRF的非零值是通过3D掩模来约束。这两种方法都能够提高pose estimation的准确率，并且NeTT的计算成本远低于mNeRF。此外，这篇论文还证明了NeTT可以在训练和pose estimation阶段具有更好的一致性，并且可以在不同的主体上进行高精度的DRR Synthesized和pose estimation。因此，这篇论文建议使用NeTT来实现 robust pose estimation。<details>
<summary>Abstract</summary>
Many tasks performed in image-guided, mini-invasive, medical procedures can be cast as pose estimation problems, where an X-ray projection is utilized to reach a target in 3D space. Expanding on recent advances in the differentiable rendering of optically reflective materials, we introduce new methods for pose estimation of radiolucent objects using X-ray projections, and we demonstrate the critical role of optimal view synthesis in performing this task. We first develop an algorithm (DiffDRR) that efficiently computes Digitally Reconstructed Radiographs (DRRs) and leverages automatic differentiation within TensorFlow. Pose estimation is performed by iterative gradient descent using a loss function that quantifies the similarity of the DRR synthesized from a randomly initialized pose and the true fluoroscopic image at the target pose. We propose two novel methods for high-fidelity view synthesis, Neural Tuned Tomography (NeTT) and masked Neural Radiance Fields (mNeRF). Both methods rely on classic Cone-Beam Computerized Tomography (CBCT); NeTT directly optimizes the CBCT densities, while the non-zero values of mNeRF are constrained by a 3D mask of the anatomic region segmented from CBCT. We demonstrate that both NeTT and mNeRF distinctly improve pose estimation within our framework. By defining a successful pose estimate to be a 3D angle error of less than 3 deg, we find that NeTT and mNeRF can achieve similar results, both with overall success rates more than 93%. However, the computational cost of NeTT is significantly lower than mNeRF in both training and pose estimation. Furthermore, we show that a NeTT trained for a single subject can generalize to synthesize high-fidelity DRRs and ensure robust pose estimations for all other subjects. Therefore, we suggest that NeTT is an attractive option for robust pose estimation using fluoroscopic projections.
</details>
<details>
<summary>摘要</summary>
许多在图像指导、微创性医疗过程中进行的任务可以被视为定位估计问题，其中使用X射线投影来到达3D空间中的目标。在这篇文章中，我们推出了一种新的定位估计方法，使用X射线投影来估计透明物体的定位。我们首先开发了一种效率高的计算Digitally Reconstructed Radiographs（DRR）的算法（DiffDRR），并利用TensorFlow中的自动导数来实现。在这种方法中，我们使用一个定制的损失函数来衡量DRR从Random Initialized Pose（RIP）中synthesized的和真实的fluoroscopic图像之间的相似性。我们还提出了两种高精度视图合成方法：Neural Tuned Tomography（NeTT）和Masked Neural Radiance Fields（mNeRF）。两种方法都基于经典的射线计算电脑断层Tomography（CBCT）；NeTT直接优化CBCT的密度，而mNeRF的非零值是由3Dmask的Anatomic Region（AR）段化from CBCT进行限制。我们发现NeTT和mNeRF都可以大幅提高定位估计的精度，并且NeTT的计算成本远低于mNeRF。此外，我们发现一个NeTT在单个主体上进行Training可以为所有其他主体synthesize高品质的DRR和确保Robust定位估计。因此，我们建议NeTT作为Robust定位估计的可靠选择。
</details></li>
</ul>
<hr>
<h2 id="SkullGAN-Synthetic-Skull-CT-Generation-with-Generative-Adversarial-Networks"><a href="#SkullGAN-Synthetic-Skull-CT-Generation-with-Generative-Adversarial-Networks" class="headerlink" title="SkullGAN: Synthetic Skull CT Generation with Generative Adversarial Networks"></a>SkullGAN: Synthetic Skull CT Generation with Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00206">http://arxiv.org/abs/2308.00206</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kbp-lab/skullgan">https://github.com/kbp-lab/skullgan</a></li>
<li>paper_authors: Kasra Naftchi-Ardebili, Karanpartap Singh, Reza Pourabolghasem, Pejman Ghanouni, Gerald R. Popelka, Kim Butts Pauly</li>
<li>for: 这个研究想要使用生成器进行人类头骨的数据生成，以便将机器学习技术应用到医疗领域中。</li>
<li>methods: 这个研究使用了生成对抗网络（GAN），将 CT 图像转换为生成的人类头骨图像。</li>
<li>results: 研究发现，SkullGAN 生成的人类头骨图像与实际的头骨图像之间存在类似的三个量化医学特征，并且通过应用 SkullGAN 检测器来类别，发现 SkullGAN 生成的头骨图像集和实际头骨图像集之间是无法区分的。<details>
<summary>Abstract</summary>
Deep learning offers potential for various healthcare applications involving the human skull but requires extensive datasets of curated medical images. To overcome this challenge, we propose SkullGAN, a generative adversarial network (GAN), to create large datasets of synthetic skull CT slices, reducing reliance on real images and accelerating the integration of machine learning into healthcare. In our method, CT slices of 38 subjects were fed to SkullGAN, a neural network comprising over 200 million parameters. The synthetic skull images generated were evaluated based on three quantitative radiological features: skull density ratio (SDR), mean thickness, and mean intensity. They were further analyzed using t-distributed stochastic neighbor embedding (t-SNE) and by applying the SkullGAN discriminator as a classifier. The results showed that SkullGAN-generated images demonstrated similar key quantitative radiological features to real skulls. Further definitive analysis was undertaken by applying the discriminator of SkullGAN, where the SkullGAN discriminator classified 56.5% of a test set of real skull images and 55.9% of the SkullGAN-generated images as reals (the theoretical optimum being 50%), demonstrating that the SkullGAN-generated skull set is indistinguishable from the real skull set - within the limits of our nonlinear classifier. Therefore, SkullGAN makes it possible to generate large numbers of synthetic skull CT segments, necessary for training neural networks for medical applications involving the human skull. This mitigates challenges associated with preparing large, high-quality training datasets, such as access, capital, time, and the need for domain expertise.
</details>
<details>
<summary>摘要</summary>
深度学习对医疗领域中人骨的应用具有潜在优势，但是它需要大量高质量医疗图像数据集来进行训练。为了解决这个挑战，我们提议了一种基于生成对抗网络（GAN）的方法，称之为SkullGAN。SkullGAN可以生成大量的人工骨CT切片，从而减少对真实图像的依赖，并促进机器学习在医疗领域的整合。我们的方法是将38名参与者的CT切片传输给SkullGAN，这是一个包含超过2亿个参数的神经网络。SkullGAN生成的人工骨图像被评估基于三个量化医学特征：骨密度比率（SDR）、平均厚度和平均亮度。它们还被使用t-分布随机 neigh embedding（t-SNE）分析，并通过应用SkullGAN推论器来分类。结果表明，SkullGAN生成的图像与真实骨头图像之间存在相似的三个量化医学特征。进一步的定论分析表明，SkullGAN推论器可以将56.5%的测试集真实骨头图像和55.9%的SkullGAN生成图像分类为真实图像（理论最佳值为50%），这表明SkullGAN生成的骨头集与真实骨头集是可区分的，至少在我们的非线性分类器的限度内。因此，SkullGAN可以生成大量的人工骨CT切片，这些切片可以用于训练医学应用中需要骨头图像的神经网络。这种方法可以解决准备大量高质量医疗图像数据集的挑战，包括访问、资本、时间和域专业知识的需求。
</details></li>
</ul>
<hr>
<h2 id="CBCL-PR-A-Cognitively-Inspired-Model-for-Class-Incremental-Learning-in-Robotics"><a href="#CBCL-PR-A-Cognitively-Inspired-Model-for-Class-Incremental-Learning-in-Robotics" class="headerlink" title="CBCL-PR: A Cognitively Inspired Model for Class-Incremental Learning in Robotics"></a>CBCL-PR: A Cognitively Inspired Model for Class-Incremental Learning in Robotics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00199">http://arxiv.org/abs/2308.00199</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aliayub7/cbcl-pr">https://github.com/aliayub7/cbcl-pr</a></li>
<li>paper_authors: Ali Ayub, Alan R. Wagner</li>
<li>for: 本研究旨在解决很少样本数的情况下，AI机器人需要不断适应和学习环境中的问题。</li>
<li>methods: 我们提出了一种基于hippocampus和neocortex理论的novel框架，用于解决增量学习问题。该框架将对象类表示为集合的集合，并将其存储在内存中。在学习新类时，框架会重温以前学习的类的数据，以避免忘记。</li>
<li>results: 我们在两个物体分类 dataset 上进行了评估，并取得了当前最佳表现（SOTA）的结果。此外，我们还在一个机器人上进行了增量学习和不断学习的测试，并证明了机器人可以在有限的人工协助下，不断学习分类大量的家用品。<details>
<summary>Abstract</summary>
For most real-world applications, robots need to adapt and learn continually with limited data in their environments. In this paper, we consider the problem of Few-Shot class Incremental Learning (FSIL), in which an AI agent is required to learn incrementally from a few data samples without forgetting the data it has previously learned. To solve this problem, we present a novel framework inspired by theories of concept learning in the hippocampus and the neocortex. Our framework represents object classes in the form of sets of clusters and stores them in memory. The framework replays data generated by the clusters of the old classes, to avoid forgetting when learning new classes. Our approach is evaluated on two object classification datasets resulting in state-of-the-art (SOTA) performance for class-incremental learning and FSIL. We also evaluate our framework for FSIL on a robot demonstrating that the robot can continually learn to classify a large set of household objects with limited human assistance.
</details>
<details>
<summary>摘要</summary>
For most real-world applications, robots need to adapt and learn continually with limited data in their environments. In this paper, we consider the problem of Few-Shot class Incremental Learning (FSIL), in which an AI agent is required to learn incrementally from a few data samples without forgetting the data it has previously learned. To solve this problem, we present a novel framework inspired by theories of concept learning in the hippocampus and the neocortex. Our framework represents object classes in the form of sets of clusters and stores them in memory. The framework replays data generated by the clusters of the old classes, to avoid forgetting when learning new classes. Our approach is evaluated on two object classification datasets resulting in state-of-the-art (SOTA) performance for class-incremental learning and FSIL. We also evaluate our framework for FSIL on a robot, demonstrating that the robot can continually learn to classify a large set of household objects with limited human assistance.Here's the translation in Traditional Chinese as well:For most real-world applications, robots need to adapt and learn continually with limited data in their environments. In this paper, we consider the problem of Few-Shot class Incremental Learning (FSIL), in which an AI agent is required to learn incrementally from a few data samples without forgetting the data it has previously learned. To solve this problem, we present a novel framework inspired by theories of concept learning in the hippocampus and the neocortex. Our framework represents object classes in the form of sets of clusters and stores them in memory. The framework replays data generated by the clusters of the old classes, to avoid forgetting when learning new classes. Our approach is evaluated on two object classification datasets resulting in state-of-the-art (SOTA) performance for class-incremental learning and FSIL. We also evaluate our framework for FSIL on a robot, demonstrating that the robot can continually learn to classify a large set of household objects with limited human assistance.
</details></li>
</ul>
<hr>
<h2 id="C-DARL-Contrastive-diffusion-adversarial-representation-learning-for-label-free-blood-vessel-segmentation"><a href="#C-DARL-Contrastive-diffusion-adversarial-representation-learning-for-label-free-blood-vessel-segmentation" class="headerlink" title="C-DARL: Contrastive diffusion adversarial representation learning for label-free blood vessel segmentation"></a>C-DARL: Contrastive diffusion adversarial representation learning for label-free blood vessel segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00193">http://arxiv.org/abs/2308.00193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boah Kim, Yujin Oh, Bradford J. Wood, Ronald M. Summers, Jong Chul Ye</li>
<li>for: This paper aims to develop a self-supervised vessel segmentation method for medical imaging, which can help improve the accuracy and efficiency of vascular disease diagnosis and interventional planning.</li>
<li>methods: The proposed method, called C-DARL, combines a diffusion module and a generation module to learn the distribution of multi-domain blood vessel data, and employs contrastive learning through a mask-based contrastive loss to improve the realism of vessel representations.</li>
<li>results: Experimental results on various vessel datasets show that C-DARL achieves performance improvement over baseline methods with noise robustness, demonstrating the effectiveness of the proposed method for vessel segmentation in medical imaging.Here’s the summary in Traditional Chinese:</li>
<li>for: 这篇论文旨在发展一种自主超级的血管分类方法，以帮助提高医疗影像诊断和手术规划的精度和效率。</li>
<li>methods: 提案的方法（C-DARL）结合了一个扩散模组和一个生成模组，以学习多域血管数据的分布，并透过一个mask-based对称损失来提高血管表现的实ism。</li>
<li>results: 实验结果显示，C-DARL在不同的血管数据集上实现了基准方法的性能改进，并具有噪声抗性，证明了提案的方法的有效性。<details>
<summary>Abstract</summary>
Blood vessel segmentation in medical imaging is one of the essential steps for vascular disease diagnosis and interventional planning in a broad spectrum of clinical scenarios in image-based medicine and interventional medicine. Unfortunately, manual annotation of the vessel masks is challenging and resource-intensive due to subtle branches and complex structures. To overcome this issue, this paper presents a self-supervised vessel segmentation method, dubbed the contrastive diffusion adversarial representation learning (C-DARL) model. Our model is composed of a diffusion module and a generation module that learns the distribution of multi-domain blood vessel data by generating synthetic vessel images from diffusion latent. Moreover, we employ contrastive learning through a mask-based contrastive loss so that the model can learn more realistic vessel representations. To validate the efficacy, C-DARL is trained using various vessel datasets, including coronary angiograms, abdominal digital subtraction angiograms, and retinal imaging. Experimental results confirm that our model achieves performance improvement over baseline methods with noise robustness, suggesting the effectiveness of C-DARL for vessel segmentation.
</details>
<details>
<summary>摘要</summary>
血管分割在医疗成像中是一项非常重要的步骤，用于诊断血管疾病和静脉介入规划，在各种临床场景中具有广泛的应用前景。然而，手动标注血管mask是一项困难和耗时的任务，因为血管分支和结构较为复杂。为了解决这个问题，本文提出了一种自我超级视图的血管分割方法，即对比扩散对抗表示学习（C-DARL）模型。我们的模型由扩散模块和生成模块组成，通过生成多域血管数据的分布来学习血管图像的分布。此外，我们采用了对比学习，通过一个面积基于的对比损失函数，使模型学习更真实的血管表示。为验证效果，C-DARL被训练使用了多种血管数据集，包括肠动脉摄影、腹部数字抽象摄影和视网膜成像。实验结果表明，我们的模型在噪音Robustness下达到了基eline方法的性能提升，这表明C-DARL是一种有效的血管分割方法。
</details></li>
</ul>
<hr>
<h2 id="Universal-Majorization-Minimization-Algorithms"><a href="#Universal-Majorization-Minimization-Algorithms" class="headerlink" title="Universal Majorization-Minimization Algorithms"></a>Universal Majorization-Minimization Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00190">http://arxiv.org/abs/2308.00190</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Streeter</li>
<li>for: 这个论文是为了提出一种新的优化方法，可以应用于任何问题，并且不需要手动定义减少函数。</li>
<li>methods: 这种优化方法使用自动梯度下降来自动生成减少函数的加大函数，从而实现了无需手动定义减少函数的优化。</li>
<li>results: 实验结果表明，这种优化方法可以快速地收敛到最优解，并且可以从任何初始点开始，无需进行任何参数调整。<details>
<summary>Abstract</summary>
Majorization-minimization (MM) is a family of optimization methods that iteratively reduce a loss by minimizing a locally-tight upper bound, called a majorizer. Traditionally, majorizers were derived by hand, and MM was only applicable to a small number of well-studied problems. We present optimizers that instead derive majorizers automatically, using a recent generalization of Taylor mode automatic differentiation. These universal MM optimizers can be applied to arbitrary problems and converge from any starting point, with no hyperparameter tuning.
</details>
<details>
<summary>摘要</summary>
大量化抑制（MM）是一家优化方法的家族，通过迭代地减少损失函数，最小化一个本地紧急上限函数，称为主要函数。在过去，主要函数通常是通过手动计算得到的，因此MM只能应用于一小部分已经广泛研究的问题上。我们提出了一种使用最近的欧拉积分自动微分的一般化方法来自动生成主要函数。这些普适的MM优化器可以应用于任何问题，并从任何初始点开始，无需参数调整。
</details></li>
</ul>
<hr>
<h2 id="Generative-Models-as-a-Complex-Systems-Science-How-can-we-make-sense-of-large-language-model-behavior"><a href="#Generative-Models-as-a-Complex-Systems-Science-How-can-we-make-sense-of-large-language-model-behavior" class="headerlink" title="Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?"></a>Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00189">http://arxiv.org/abs/2308.00189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ari Holtzman, Peter West, Luke Zettlemoyer</li>
<li>for: 本研究目的是解释语音模型如何完成多种任务，并且帮助未来的研究。</li>
<li>methods: 本研究使用系统性的方法来分解语音模型的行为，以解释它们在不同任务中的表现。</li>
<li>results: 本研究获得了一系列的结果，包括语音模型在不同任务中的表现，以及它们的行为可以被分解为不同的类别。<details>
<summary>Abstract</summary>
Coaxing out desired behavior from pretrained models, while avoiding undesirable ones, has redefined NLP and is reshaping how we interact with computers. What was once a scientific engineering discipline-in which building blocks are stacked one on top of the other-is arguably already a complex systems science, in which emergent behaviors are sought out to support previously unimagined use cases.   Despite the ever increasing number of benchmarks that measure task performance, we lack explanations of what behaviors language models exhibit that allow them to complete these tasks in the first place. We argue for a systematic effort to decompose language model behavior into categories that explain cross-task performance, to guide mechanistic explanations and help future-proof analytic research.
</details>
<details>
<summary>摘要</summary>
使预训练模型展现愿景行为，而不是不良行为，已经重新定义了自然语言处理（NLP），并在我们与计算机之间的交互方式中造成了改变。过去，建筑块一个在另一个之上排序的科学工程 discipline，现在可能已经变成了复杂系统科学，寻找emergent行为以支持前未想象的用 случа。尽管任务性能的测试benchmark数量不断增加，但我们仍然缺乏任务完成所需行为的解释。我们提出了一种系统性的努力，即将语言模型行为分类为可以解释跨任务性能的类别，以导引机械性解释和未来研究。
</details></li>
</ul>
<hr>
<h2 id="Attribution-Scores-in-Data-Management-and-Explainable-Machine-Learning"><a href="#Attribution-Scores-in-Data-Management-and-Explainable-Machine-Learning" class="headerlink" title="Attribution-Scores in Data Management and Explainable Machine Learning"></a>Attribution-Scores in Data Management and Explainable Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00184">http://arxiv.org/abs/2308.00184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leopoldo Bertossi</li>
<li>for: 这个论文关于在数据库和机器学习中使用实际 causality 定义责任分数的研究。</li>
<li>methods: 论文使用了数据库修复和分类模型的扩展来解释查询结果和分类结果的 causality。</li>
<li>results: 论文提出了一种量化度量数据库的一致性，并提供了高效计算 Shap-score 的方法。<details>
<summary>Abstract</summary>
We describe recent research on the use of actual causality in the definition of responsibility scores as explanations for query answers in databases, and for outcomes from classification models in machine learning. In the case of databases, useful connections with database repairs are illustrated and exploited. Repairs are also used to give a quantitative measure of the consistency of a database. For classification models, the responsibility score is properly extended and illustrated. The efficient computation of Shap-score is also analyzed and discussed. The emphasis is placed on work done by the author and collaborators.
</details>
<details>
<summary>摘要</summary>
我们描述了最近的研究，把实际 causality 引入责任分数的定义中，以解释查询结果在数据库中的解释，以及机器学习模型中的结果的出现。在数据库中，我们利用了有用的连接，并使用了修复来给出数据库的数量化度量。对于机器学习模型，我们正确地扩展了责任分数，并用修复来衡量模型的一致性。我们还分析了efficiently computation Shap-score的问题。我们强调了作者和合作者的工作。Note: "实际 causality" in the original text is translated as "实际 causality" in Simplified Chinese, which is a literal translation. However, "实际 causality" is not a commonly used term in Simplified Chinese, and a more appropriate translation might be "真实 causality" (zhēnshí causality) or "实际效果" (shíjì efect).
</details></li>
</ul>
<hr>
<h2 id="General-Anomaly-Detection-of-Underwater-Gliders-Validated-by-Large-scale-Deployment-Dataset"><a href="#General-Anomaly-Detection-of-Underwater-Gliders-Validated-by-Large-scale-Deployment-Dataset" class="headerlink" title="General Anomaly Detection of Underwater Gliders Validated by Large-scale Deployment Dataset"></a>General Anomaly Detection of Underwater Gliders Validated by Large-scale Deployment Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00180">http://arxiv.org/abs/2308.00180</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruochu Yang, Chad Lembke, Fumin Zhang, Catherine Edwards</li>
<li>for: 本研究使用异常检测算法评估水下飞行器在不可预测的海洋环境中的正常运行。</li>
<li>methods: 本研究使用了丰富的数据集，来评估异常检测算法的效果。实验包括了线上和线下两种模式。线上检测是根据实时从飞行器发送的数据进行的，而线下检测则是使用完整的回收数据集进行详细的异常分析和对比飞行器驾驶员的日志。</li>
<li>results: 研究发现，使用异常检测算法可以帮助飞行器驾驶员在实时监控异常情况，避免更大的损害。<details>
<summary>Abstract</summary>
This paper employs an anomaly detection algorithm to assess the normal operation of underwater gliders in unpredictable ocean environments. Real-time alerts can be provided to glider pilots upon detecting any anomalies, enabling them to assume control of the glider and prevent further harm. The detection algorithm is applied to abundant data sets collected in real glider deployments led by the Skidaway Institute of Oceanography (SkIO) and the University of South Florida (USF). Regarding generality, the experimental evaluation is composed of both offline and online detection modes. The offline detection utilizes full post-recovery data sets, which carries high-resolution information, to present detailed analysis of the anomaly and compare it with pilot logs. The online detection focuses on the real-time subsets of data transmitted from the glider at the surfacing events. While the real-time data may not contain as much rich information as the post-recovery data, the online detection is of great importance as it allows glider pilots to monitor potential abnormal conditions in real time.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Pretrained-deep-models-outperform-GBDTs-in-Learning-To-Rank-under-label-scarcity"><a href="#Pretrained-deep-models-outperform-GBDTs-in-Learning-To-Rank-under-label-scarcity" class="headerlink" title="Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity"></a>Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00177">http://arxiv.org/abs/2308.00177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charlie Hou, Kiran Koshy Thekumparampil, Michael Shavlovsky, Giulia Fanti, Yesh Dattatreya, Sujay Sanghavi</li>
<li>for: 这个论文的目的是研究是否可以通过无监督预训练提高学习评分（LTR）问题的性能，并比较其与Gradient Boosted Decision Trees（GBDTs）和其他非预训练模型的性能。</li>
<li>methods: 这个论文使用了一些简单的设计选择，包括SimCLR-Rank，一种针对图像的无监督预训练方法，来生成预训练的深度学习模型。</li>
<li>results: 研究发现，预训练模型可以在有大量无标记数据的情况下Soundly exceed GBDTs（和其他非预训练模型）的性能，并且在评分异常数据时也可以获得 significatively better robustness。<details>
<summary>Abstract</summary>
While deep learning (DL) models are state-of-the-art in text and image domains, they have not yet consistently outperformed Gradient Boosted Decision Trees (GBDTs) on tabular Learning-To-Rank (LTR) problems. Most of the recent performance gains attained by DL models in text and image tasks have used unsupervised pretraining, which exploits orders of magnitude more unlabeled data than labeled data. To the best of our knowledge, unsupervised pretraining has not been applied to the LTR problem, which often produces vast amounts of unlabeled data. In this work, we study whether unsupervised pretraining can improve LTR performance over GBDTs and other non-pretrained models. Using simple design choices--including SimCLR-Rank, our ranking-specific modification of SimCLR (an unsupervised pretraining method for images)--we produce pretrained deep learning models that soundly outperform GBDTs (and other non-pretrained models) in the case where labeled data is vastly outnumbered by unlabeled data. We also show that pretrained models also often achieve significantly better robustness than non-pretrained models (GBDTs or DL models) in ranking outlier data.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:while deep learning (DL) 模型在文本和图像领域是现状最佳，但它们尚未一直保持GBDTs在标量学习到rank（LTR）问题上的表现。大多数最近在文本和图像任务中获得的性能提升都是通过无监督预训练来实现，这种方法可以利用数个数量级的无标签数据。据我们所知，无监督预训练没有被应用于LTR问题，这个问题通常会生成巨量的无标签数据。在这项工作中，我们研究了无监督预训练是否可以提高LTR性能，并与其他非预训练模型相比。我们采用了简单的设计选择，包括我们的排名特有的SimCLR-Rank修改版（一种图像无监督预训练方法）。我们生成了预训练深度学习模型，这些模型在标量数据充足时与GBDTs和其他非预训练模型相比，具有更好的表现。我们还表明了预训练模型在排名异常数据时的更好的Robustness。
</details></li>
</ul>
<hr>
<h2 id="A-Flow-Artist-for-High-Dimensional-Cellular-Data"><a href="#A-Flow-Artist-for-High-Dimensional-Cellular-Data" class="headerlink" title="A Flow Artist for High-Dimensional Cellular Data"></a>A Flow Artist for High-Dimensional Cellular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00176">http://arxiv.org/abs/2308.00176</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kincaid MacDonald, Dhananjay Bhaskar, Guy Thampakkul, Nhi Nguyen, Joia Zhang, Michael Perlmutter, Ian Adelstein, Smita Krishnaswamy</li>
<li>for: 用于嵌入来自背景流动 manifold 的点云数据，包括高通过put biology 单个细胞转录调控学实验数据。</li>
<li>methods: 使用 neural network 嵌入点云数据，并同时学习周围的 vector field。</li>
<li>results: 在 Toy 数据和单个细胞 RNA 速度数据上，FlowArtist 能够更好地分离和可视化 velocity-informed 结构。<details>
<summary>Abstract</summary>
We consider the problem of embedding point cloud data sampled from an underlying manifold with an associated flow or velocity. Such data arises in many contexts where static snapshots of dynamic entities are measured, including in high-throughput biology such as single-cell transcriptomics. Existing embedding techniques either do not utilize velocity information or embed the coordinates and velocities independently, i.e., they either impose velocities on top of an existing point embedding or embed points within a prescribed vector field. Here we present FlowArtist, a neural network that embeds points while jointly learning a vector field around the points. The combination allows FlowArtist to better separate and visualize velocity-informed structures. Our results, on toy datasets and single-cell RNA velocity data, illustrate the value of utilizing coordinate and velocity information in tandem for embedding and visualizing high-dimensional data.
</details>
<details>
<summary>摘要</summary>
我团队考虑了嵌入点云数据，该数据来自于下面的拓扑结构，并且有关联的流动或速度信息。这种数据在许多场景中出现，包括高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高通过putSingle-cell transcriptomics中的高
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-for-Data-and-Model-Heterogeneity-in-Medical-Imaging"><a href="#Federated-Learning-for-Data-and-Model-Heterogeneity-in-Medical-Imaging" class="headerlink" title="Federated Learning for Data and Model Heterogeneity in Medical Imaging"></a>Federated Learning for Data and Model Heterogeneity in Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00155">http://arxiv.org/abs/2308.00155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hussain Ahmad Madni, Rao Muhammad Umer, Gian Luca Foresti</li>
<li>for:  This paper aims to address the challenges of data and model heterogeneity in Federated Learning (FL) by exploiting both heterogeneities simultaneously.</li>
<li>methods:  The proposed method, MDH-FL, uses knowledge distillation and a symmetric loss to minimize the impact of heterogeneity on the model performance.</li>
<li>results:  The experimental results on medical datasets demonstrate the superiority of the proposed approach over existing methods.<details>
<summary>Abstract</summary>
Federated Learning (FL) is an evolving machine learning method in which multiple clients participate in collaborative learning without sharing their data with each other and the central server. In real-world applications such as hospitals and industries, FL counters the challenges of data heterogeneity and model heterogeneity as an inevitable part of the collaborative training. More specifically, different organizations, such as hospitals, have their own private data and customized models for local training. To the best of our knowledge, the existing methods do not effectively address both problems of model heterogeneity and data heterogeneity in FL. In this paper, we exploit the data and model heterogeneity simultaneously, and propose a method, MDH-FL (Exploiting Model and Data Heterogeneity in FL) to solve such problems to enhance the efficiency of the global model in FL. We use knowledge distillation and a symmetric loss to minimize the heterogeneity and its impact on the model performance. Knowledge distillation is used to solve the problem of model heterogeneity, and symmetric loss tackles with the data and label heterogeneity. We evaluate our method on the medical datasets to conform the real-world scenario of hospitals, and compare with the existing methods. The experimental results demonstrate the superiority of the proposed approach over the other existing methods.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种发展中的机器学习方法，在多个客户端参与协同学习而无需分享数据之间和中央服务器。在实际应用中，如医院和产业中，FL 对数据不同和模型不同的问题作出了有效应对。具体来说，不同的组织，如医院，拥有自己的私有数据和本地训练的自定义模型。据我们所知，现有的方法未能有效地解决 FL 中的数据不同和模型不同问题。在这篇论文中，我们利用数据不同和模型不同的特点，并提出了一种方法，即 MDH-FL（利用数据和模型不同的特点进行 FL），以解决这些问题，从而提高 FL 的效率。我们使用知识传承和对称损失来减少不同和其影响于模型性能。知识传承用于解决模型不同问题，而对称损失则用于解决数据和标签不同问题。我们在医疗数据集上进行了实验，以验证这种方法在实际应用中的可行性，并与现有方法进行比较。实验结果表明，我们提出的方法在模型性能方面表现出优于现有方法。
</details></li>
</ul>
<hr>
<h2 id="DiffusAL-Coupling-Active-Learning-with-Graph-Diffusion-for-Label-Efficient-Node-Classification"><a href="#DiffusAL-Coupling-Active-Learning-with-Graph-Diffusion-for-Label-Efficient-Node-Classification" class="headerlink" title="DiffusAL: Coupling Active Learning with Graph Diffusion for Label-Efficient Node Classification"></a>DiffusAL: Coupling Active Learning with Graph Diffusion for Label-Efficient Node Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00146">http://arxiv.org/abs/2308.00146</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lmu-dbs/diffusal">https://github.com/lmu-dbs/diffusal</a></li>
<li>paper_authors: Sandra Gilhuber, Julian Busch, Daniel Rotthues, Christian M. M. Frey, Thomas Seidl</li>
<li>for: 这个研究旨在提出一种新的活动阶层学习方法，以提高阶层标签效率并降低标签成本。</li>
<li>methods: 本研究使用三种独立的评分函数来选择最有价值的节点标签：i) 模型不确定性，ii) 多样性分量，和iii) 节点重要性，这些评分函数都是基于阶层传播算法。</li>
<li>results: 实验结果显示，DiffusAL 方法在多种 benchmark 数据集上具有显著的弹性和可转移性，并在 100% 的数据集和标签预算下具有优于随机选择的表现。<details>
<summary>Abstract</summary>
Node classification is one of the core tasks on attributed graphs, but successful graph learning solutions require sufficiently labeled data. To keep annotation costs low, active graph learning focuses on selecting the most qualitative subset of nodes that maximizes label efficiency. However, deciding which heuristic is best suited for an unlabeled graph to increase label efficiency is a persistent challenge. Existing solutions either neglect aligning the learned model and the sampling method or focus only on limited selection aspects. They are thus sometimes worse or only equally good as random sampling. In this work, we introduce a novel active graph learning approach called DiffusAL, showing significant robustness in diverse settings. Toward better transferability between different graph structures, we combine three independent scoring functions to identify the most informative node samples for labeling in a parameter-free way: i) Model Uncertainty, ii) Diversity Component, and iii) Node Importance computed via graph diffusion heuristics. Most of our calculations for acquisition and training can be pre-processed, making DiffusAL more efficient compared to approaches combining diverse selection criteria and similarly fast as simpler heuristics. Our experiments on various benchmark datasets show that, unlike previous methods, our approach significantly outperforms random selection in 100% of all datasets and labeling budgets tested.
</details>
<details>
<summary>摘要</summary>
<SYS> translate-language: zh-CN</SYS>Node 分类是 attributed graphs 的核心任务，但是成功的图学习解决方案需要具有足够的标注数据。为了降低标注成本，活动图学习专注于选择最有价值的节点子集，以提高标签效率。然而，选择没有标注的图中最有价值的节点是一个持续的挑战。现有的解决方案可能会忽略将学习模型和采样方法相匹配，或者只专注于有限的选择方面。这些方法在某些情况下可能比随机采样更差，或者只是与随机采样相等。在这种情况下，我们介绍了一种新的活动图学习方法，称为DiffusAL，它在多种场景中表现出了显著的鲁棒性。为了更好地传递不同的图结构之间，我们将三种独立的分数函数结合起来，以选择最有用的节点样本进行标签：i) 模型不确定性，ii) 多样性分数，和 iii) 图diffusion 的节点重要性。大多数我们的收购和训练计算可以预处理，使得DiffusAL比 combine 多种选择 criterion 和类似快速的方法更高效。我们在多种 bench marks 上进行的实验表明，与先前的方法不同，我们的方法在 100% 的所有数据集和标注预算上都能够明显超过随机选择。
</details></li>
</ul>
<hr>
<h2 id="Formally-Explaining-Neural-Networks-within-Reactive-Systems"><a href="#Formally-Explaining-Neural-Networks-within-Reactive-Systems" class="headerlink" title="Formally Explaining Neural Networks within Reactive Systems"></a>Formally Explaining Neural Networks within Reactive Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00143">http://arxiv.org/abs/2308.00143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahaf Bassan, Guy Amir, Davide Corsi, Idan Refaeli, Guy Katz</li>
<li>for: 这篇论文旨在解释深度神经网络（DNNs）控制器在反应系统中的行为，并提供正确的输入特征导致DNN的行为的解释。</li>
<li>methods: 这篇论文提出了一种基于验证的解释AI技术，可以准确地找出DNN的输入特征，并且可以应用于多步、反应系统。具体来说，这种技术利用系统的转移约束来缩小检查空间，从而提高效率。</li>
<li>results: 研究人员在两个popular的自动导航 benchmark上评估了这种技术，并观察到它可以高效地计算出最小和最小的解释，比之前的状态对技术更高效。此外，研究人员还证明了这种技术生成的正式解释比非验证基于的XAI技术更可靠。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are increasingly being used as controllers in reactive systems. However, DNNs are highly opaque, which renders it difficult to explain and justify their actions. To mitigate this issue, there has been a surge of interest in explainable AI (XAI) techniques, capable of pinpointing the input features that caused the DNN to act as it did. Existing XAI techniques typically face two limitations: (i) they are heuristic, and do not provide formal guarantees that the explanations are correct; and (ii) they often apply to ``one-shot'' systems, where the DNN is invoked independently of past invocations, as opposed to reactive systems. Here, we begin bridging this gap, and propose a formal DNN-verification-based XAI technique for reasoning about multi-step, reactive systems. We suggest methods for efficiently calculating succinct explanations, by exploiting the system's transition constraints in order to curtail the search space explored by the underlying verifier. We evaluate our approach on two popular benchmarks from the domain of automated navigation; and observe that our methods allow the efficient computation of minimal and minimum explanations, significantly outperforming the state of the art. We also demonstrate that our methods produce formal explanations that are more reliable than competing, non-verification-based XAI techniques.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a formal DNN-verification-based XAI technique for reasoning about multi-step, reactive systems. Our approach leverages the system's transition constraints to efficiently calculate succinct explanations, reducing the search space explored by the underlying verifier. We evaluate our method on two popular benchmarks from the domain of automated navigation and show that our approach can efficiently compute minimal and minimum explanations, significantly outperforming the state of the art. We also demonstrate that our methods produce formal explanations that are more reliable than competing, non-verification-based XAI techniques.我们在这篇文章中提出了一种基于 Deep Neural Networks (DNNs) 的可解释 AI (XAI) 技术，用于理解和解释 DNNs 在反应系统中的行为。然而，现有的 XAI 技术存在两个限制：首先，它们通常是有规则的，无法提供正式的 garantía 正确性;其次，它们通常适用于 "一击" 系统，在 DNN 独立于过去邀请时被邀请的情况下进行调用，而不是反应系统。在这篇文章中，我们开始bridging这个差距，并提出了一种基于 DNN 验证的可解释技术，用于理解多步、反应系统。我们提出了一种利用系统的转换约束来减少搜索空间的方法，以便高效计算简短的解释。我们在两个流行的自动导航 benchmark 上测试了我们的方法，并观察到我们的方法可以高效计算最小和最小的解释，明显超越当前的状态。我们还表明了我们的方法生成的正式解释比竞争对手的非验证基于 XAI 技术更可靠。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Laplacian-Learning-on-Stiefel-Manifolds"><a href="#Semi-Supervised-Laplacian-Learning-on-Stiefel-Manifolds" class="headerlink" title="Semi-Supervised Laplacian Learning on Stiefel Manifolds"></a>Semi-Supervised Laplacian Learning on Stiefel Manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00142">http://arxiv.org/abs/2308.00142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chester Holtz, Pengwen Chen, Alexander Cloninger, Chung-Kuan Cheng, Gal Mishne</li>
<li>for: 提高 Laplace 学习算法在低标签率下的性能，解决 canonical Laplace 学习算法的归一化问题。</li>
<li>methods: 将图基semi-supervised learning reformulated为非конvex的 Trust-Region Subproblem（TRS），利用无限无标签数据下 Laplacian  eigenvectors 的有定性来解决问题。</li>
<li>results:  compared to 最新的state-of-the-art和传统 semi-supervised learning 方法，我们的框架在低、中、高标签率下 achieve lower classification error。<details>
<summary>Abstract</summary>
Motivated by the need to address the degeneracy of canonical Laplace learning algorithms in low label rates, we propose to reformulate graph-based semi-supervised learning as a nonconvex generalization of a \emph{Trust-Region Subproblem} (TRS). This reformulation is motivated by the well-posedness of Laplacian eigenvectors in the limit of infinite unlabeled data. To solve this problem, we first show that a first-order condition implies the solution of a manifold alignment problem and that solutions to the classical \emph{Orthogonal Procrustes} problem can be used to efficiently find good classifiers that are amenable to further refinement. Next, we address the criticality of selecting supervised samples at low-label rates. We characterize informative samples with a novel measure of centrality derived from the principal eigenvectors of a certain submatrix of the graph Laplacian. We demonstrate that our framework achieves lower classification error compared to recent state-of-the-art and classical semi-supervised learning methods at extremely low, medium, and high label rates. Our code is available on github\footnote{anonymized for submission}.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>受到低标签率下 Laplace 学习算法的异常性的启发，我们提议将图像基于 semi-supervised learning 重新定义为非 conjugate 矩阵的一种通用化问题。这种重定义是基于 Laplacian 域的均值偏 Parameters 的一种限制，它在无穷多个无标签数据的极限下具有一定的坚定性。为解决这个问题，我们首先证明在某种特定的 manifold alignment 问题中，第一个ORDER condition 的解是一个 manifold alignment 问题的解，并且可以使用经典的 orthogonal procrustes 问题来高效地找到可以进一步精细化的好的分类器。接下来，我们讨论在低标签率下选择supervised 样本的关键性。我们提出一种新的中心性度量，基于图 Laplacian 矩阵的特定子矩阵的主要特征值。我们证明，我们的框架在低、中和高标签率下具有更低的分类错误率，比之前的最新状态艺术和经典 semi-supervised learning 方法。我们的代码可以在 GitHub 上找到（注释除去）。
</details></li>
</ul>
<hr>
<h2 id="A-Suite-of-Fairness-Datasets-for-Tabular-Classification"><a href="#A-Suite-of-Fairness-Datasets-for-Tabular-Classification" class="headerlink" title="A Suite of Fairness Datasets for Tabular Classification"></a>A Suite of Fairness Datasets for Tabular Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00133">http://arxiv.org/abs/2308.00133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Hirzel, Michael Feffer</li>
<li>for: 提高机器学习分类器的公正性</li>
<li>methods: 引入一个函数集，用于从20个公正性数据集和相关的公正性元数据中选择数据进行实验评估</li>
<li>results: 期望这些函数可以促进未来的公正性意识Machine learning研究中的实验评估Here’s a breakdown of each point:</li>
<li>for: The paper is written for improving the fairness of machine-learning classifiers for tabular data.</li>
<li>methods: The paper introduces a suite of functions for fetching 20 fairness datasets and providing associated fairness metadata, which can be used for more rigorous experimental evaluations in future fairness-aware machine learning research.</li>
<li>results: The paper hopes that these functions can promote more rigorous experimental evaluations in future fairness-aware machine learning research.<details>
<summary>Abstract</summary>
There have been many papers with algorithms for improving fairness of machine-learning classifiers for tabular data. Unfortunately, most use only very few datasets for their experimental evaluation. We introduce a suite of functions for fetching 20 fairness datasets and providing associated fairness metadata. Hopefully, these will lead to more rigorous experimental evaluations in future fairness-aware machine learning research.
</details>
<details>
<summary>摘要</summary>
“有很多论文提出了对机器学习分类器的公平性进行改善的算法。却是，大多数使用的数据集只有几个。我们介绍了一个函数套件，可以获取20个公平性数据集和相关的公平性元件。希望这些函数能够带来未来公平性意识机器学习研究的更加严谨的实验评估。”Here's the breakdown of the translation:“有很多论文” (有很多论文) - There have been many papers“提出了对机器学习分类器的公平性进行改善的算法” (提出了对机器学习分类器的公平性进行改善的算法) - There have been many papers with algorithms for improving the fairness of machine learning classifiers“却是” (却是) - Unfortunately“大多数使用的数据集只有几个” (大多数使用的数据集只有几个) - Most use only a few datasets for their experimental evaluation“我们介绍了一个函数套件” (我们介绍了一个函数套件) - We introduce a suite of functions“可以获取20个公平性数据集和相关的公平性元件” (可以获取20个公平性数据集和相关的公平性元件) - That can fetch 20 fairness datasets and provide associated fairness metadata“希望这些函数能够带来未来公平性意识机器学习研究的更加严谨的实验评估” (希望这些函数能够带来未来公平性意识机器学习研究的更加严谨的实验评估) - Hopefully, these functions can lead to more rigorous experimental evaluations in future fairness-aware machine learning research.
</details></li>
</ul>
<hr>
<h2 id="Ensemble-Learning-with-Residual-Transformer-for-Brain-Tumor-Segmentation"><a href="#Ensemble-Learning-with-Residual-Transformer-for-Brain-Tumor-Segmentation" class="headerlink" title="Ensemble Learning with Residual Transformer for Brain Tumor Segmentation"></a>Ensemble Learning with Residual Transformer for Brain Tumor Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00128">http://arxiv.org/abs/2308.00128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lanhong Yao, Zheyuan Zhang, Ulas Bagci</li>
<li>for: 本研究旨在提高脑肿瘤分 segmentation的精度，因为现有的 U-Net 架构受到脑肿瘤的复杂形态和 текстуuration的限制，以及缺乏Contextual information的捕捉。</li>
<li>methods: 本研究提出了一种新的网络架构，即将 Transformers integrated into a self-adaptive U-Net，以利用 Transformers 的内置注意机制和像素级标注来捕捉3D精度volume context。此外，我们还添加了 residual connection 来避免信息流失传递，并 explore ensemble methods 来利用不同模型在不同情况下的优势。</li>
<li>results: 在 BraTS 2021  dataset（3D）上，我们的模型实现了87.6%的 mean Dice score，超越了现有的状态 Elluminate 方法，说明可以通过组合多种架构来优化脑肿瘤分 segmentation。<details>
<summary>Abstract</summary>
Brain tumor segmentation is an active research area due to the difficulty in delineating highly complex shaped and textured tumors as well as the failure of the commonly used U-Net architectures. The combination of different neural architectures is among the mainstream research recently, particularly the combination of U-Net with Transformers because of their innate attention mechanism and pixel-wise labeling. Different from previous efforts, this paper proposes a novel network architecture that integrates Transformers into a self-adaptive U-Net to draw out 3D volumetric contexts with reasonable computational costs. We further add a residual connection to prevent degradation in information flow and explore ensemble methods, as the evaluated models have edges on different cases and sub-regions. On the BraTS 2021 dataset (3D), our model achieves 87.6% mean Dice score and outperforms the state-of-the-art methods, demonstrating the potential for combining multiple architectures to optimize brain tumor segmentation.
</details>
<details>
<summary>摘要</summary>
brain tumor segmentation 是一个活跃的研究领域，因为复杂形态和文本化肿瘤难以定界，以及通用的 U-Net 架构失败。最近，各种神经网络架构的组合在主流研究中，特别是 U-Net 与 Transformers 的组合，因为它们的自然注意机制和像素级标注。与前一些尝试不同，这篇论文提出了一种新的网络架构，将 Transformers  integrate into a self-adaptive U-Net，以获取3D积体上的合理计算成本下的Context。此外，我们还添加了保持信息流不减的径迹连接，并 explore ensemble 方法，因为评估模型在不同的情况和子区域上有着优势。在 BraTS 2021 数据集（3D）上，我们的模型达到了87.6%的平均 dice 分数，超越了现有的方法，这表明将多种架构组合起来优化脑肿瘤分 segmentation 的潜力。
</details></li>
</ul>
<hr>
<h2 id="DiviML-A-Module-based-Heuristic-for-Mapping-Neural-Networks-onto-Heterogeneous-Platforms"><a href="#DiviML-A-Module-based-Heuristic-for-Mapping-Neural-Networks-onto-Heterogeneous-Platforms" class="headerlink" title="DiviML: A Module-based Heuristic for Mapping Neural Networks onto Heterogeneous Platforms"></a>DiviML: A Module-based Heuristic for Mapping Neural Networks onto Heterogeneous Platforms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00127">http://arxiv.org/abs/2308.00127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yassine Ghannane, Mohamed S. Abdelfattah<br>for:* The paper is written to address the challenge of optimizing deep neural network (DNN) execution on heterogeneous datacenter hardware, specifically considering both data and model parallelism.methods:* The paper proposes a compiler-level partitioning approach that leverages mixed integer linear programming (MILP) and a modularity-based heuristic to automatically partition and device map DNNs onto multiple interconnected hardware devices.results:* The proposed framework can achieve more than 3 times lower latency and up to 2.9 times higher throughput compared to naively running DNNs on the fastest GPU, while maintaining solution quality. The modularity-based “splitting” heuristic improves solution runtime up to 395 times without sacrificing solution quality, and outperforms all other heuristics by 30-60% solution quality.Here is the information in Simplified Chinese:for:* 本文是为了解决现代数据中心硬件多样化的挑战，具体是考虑数据并行和模型并行。methods:* 本文提出了一种编译级别的分配方法，利用混合整数线性规划（MILP）和一种模块性基于规则的启发函数来自动将深度神经网络（DNNs）分配到多个连接的硬件设备上。results:* 提posed的框架可以比直接在最快的GPU上运行DNNs更低的延迟和更高的吞吐量，同时保持解决方案质量。 modularity-based “splitting”启发函数可以提高解决时间Up to 395倍，而无需明显牺牲解决方案质量，并在其他启发函数中出现30-60%的解决质量。<details>
<summary>Abstract</summary>
Datacenters are increasingly becoming heterogeneous, and are starting to include specialized hardware for networking, video processing, and especially deep learning. To leverage the heterogeneous compute capability of modern datacenters, we develop an approach for compiler-level partitioning of deep neural networks (DNNs) onto multiple interconnected hardware devices. We present a general framework for heterogeneous DNN compilation, offering automatic partitioning and device mapping. Our scheduler integrates both an exact solver, through a mixed integer linear programming (MILP) formulation, and a modularity-based heuristic for scalability. Furthermore, we propose a theoretical lower bound formula for the optimal solution, which enables the assessment of the heuristic solutions' quality. We evaluate our scheduler in optimizing both conventional DNNs and randomly-wired neural networks, subject to latency and throughput constraints, on a heterogeneous system comprised of a CPU and two distinct GPUs. Compared to na\"ively running DNNs on the fastest GPU, he proposed framework can achieve more than 3$\times$ times lower latency and up to 2.9$\times$ higher throughput by automatically leveraging both data and model parallelism to deploy DNNs on our sample heterogeneous server node. Moreover, our modularity-based "splitting" heuristic improves the solution runtime up to 395$\times$ without noticeably sacrificing solution quality compared to an exact MILP solution, and outperforms all other heuristics by 30-60% solution quality. Finally, our case study shows how we can extend our framework to schedule large language models across multiple heterogeneous servers by exploiting symmetry in the hardware setup. Our code can be easily plugged in to existing frameworks, and is available at https://github.com/abdelfattah-lab/diviml.
</details>
<details>
<summary>摘要</summary>
现代数据中心越来越多样化，包括专门的网络硬件、视频处理硬件和深度学习硬件。为了利用现代数据中心的多样化计算能力，我们开发了一种编译器层 partitioning 技术，将深度神经网络（DNNs）分配到多个连接的硬件设备上。我们提出了一个通用的多型 DNN 编译框架，包括自动分配和设备映射。我们的调度器结合了精确的整数线性Programming（MILP）方法和模块性基于的优化器，以确保可扩展性。此外，我们还提出了一个优化目标函数的下界公式，以评估优化解的质量。我们在一个包括 CPU 和两个不同 GPU 的多型系统上测试了我们的调度器，并证明了与直接在最快 GPU 上运行 DNNs 相比，我们的框架可以实现更低的延迟和更高的吞吐量，通过自动利用数据并模型并行性来部署 DNNs。此外，我们的模块性基于的"拆分"优化器可以提高解 runtime 至多 395 倍，而不是明显降低解质量。最后，我们的案例研究显示了如何使用 symmetry 在硬件设置上将大语言模型分布到多个多样化服务器上。我们的代码可以轻松地插入到现有框架中，并可以在 <https://github.com/abdelfattah-lab/diviml> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Convolutional-Occupancy-Models-for-Dense-Packing-of-Complex-Novel-Objects"><a href="#Convolutional-Occupancy-Models-for-Dense-Packing-of-Complex-Novel-Objects" class="headerlink" title="Convolutional Occupancy Models for Dense Packing of Complex, Novel Objects"></a>Convolutional Occupancy Models for Dense Packing of Complex, Novel Objects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00091">http://arxiv.org/abs/2308.00091</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nikhilmishra000/fcon">https://github.com/nikhilmishra000/fcon</a></li>
<li>paper_authors: Nikhil Mishra, Pieter Abbeel, Xi Chen, Maximilian Sieb</li>
<li>for: 这篇论文的目的是提高现实世界中爬行机器人的卷积排序性能。</li>
<li>methods: 该论文使用了一种全 convolutional shape completion模型（F-CON），可以与市场上的规划方法结合使用，以提高实际世界中的卷积排序性能。</li>
<li>results: 该论文使用COB-3D-v2数据集进行训练，并通过比较其他状态艺法的表现，表明F-CON可以在实际世界中提供更好的卷积排序性能。此外，该论文还在实际世界中 equip 了一个爬行机器人，并在受排序的复杂对象中进行了实际应用。<details>
<summary>Abstract</summary>
Dense packing in pick-and-place systems is an important feature in many warehouse and logistics applications. Prior work in this space has largely focused on planning algorithms in simulation, but real-world packing performance is often bottlenecked by the difficulty of perceiving 3D object geometry in highly occluded, partially observed scenes. In this work, we present a fully-convolutional shape completion model, F-CON, which can be easily combined with off-the-shelf planning methods for dense packing in the real world. We also release a simulated dataset, COB-3D-v2, that can be used to train shape completion models for real-word robotics applications, and use it to demonstrate that F-CON outperforms other state-of-the-art shape completion methods. Finally, we equip a real-world pick-and-place system with F-CON, and demonstrate dense packing of complex, unseen objects in cluttered scenes. Across multiple planning methods, F-CON enables substantially better dense packing than other shape completion methods.
</details>
<details>
<summary>摘要</summary>
密集填充在选择和放置系统中是非常重要的特性，在仓储和物流应用中具有广泛的应用。过去的工作主要集中在仿真中进行规划算法，但在实际情况中，填充性能frequently被 occluded, partially observed scene的3D объек的geometry perceiving difficulty所 bottleneck。在这项工作中，我们提出了一种可以与市场上 readily available planning方法结合的fully-convolutional shape completion模型，F-CON，可以在实际世界中提高填充性能。我们还发布了COB-3D-v2仿真数据集，可以用于训练shape completion模型，并在这个数据集上证明F-CON超过了其他状态对shape completion方法。最后，我们将实际世界中的选择和放置系统设备F-CON，并在拥挤的场景中 dense packing复杂、未看过的物体。在不同的规划方法下，F-CON实现了较好的密集填充性能。
</details></li>
</ul>
<hr>
<h2 id="New-Lower-Bounds-for-Testing-Monotonicity-and-Log-Concavity-of-Distributions"><a href="#New-Lower-Bounds-for-Testing-Monotonicity-and-Log-Concavity-of-Distributions" class="headerlink" title="New Lower Bounds for Testing Monotonicity and Log Concavity of Distributions"></a>New Lower Bounds for Testing Monotonicity and Log Concavity of Distributions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00089">http://arxiv.org/abs/2308.00089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuqian Cheng, Daniel M. Kane, Zhicheng Zheng</li>
<li>for: 这 paper 用于证明分布测试下界 bound 的新技术。</li>
<li>methods: 该技术使用 pair of moment-matching families of distributions，通过修改每个分布的概率值，使一个家keep 定义不等式，而另一个家violate 它们。</li>
<li>results: 该技术可以获得新的下界 bound  для monotonicity testing over discrete cubes，以及 tight lower bounds  для log-concavity testing。<details>
<summary>Abstract</summary>
We develop a new technique for proving distribution testing lower bounds for properties defined by inequalities involving the bin probabilities of the distribution in question. Using this technique we obtain new lower bounds for monotonicity testing over discrete cubes and tight lower bounds for log-concavity testing.   Our basic technique involves constructing a pair of moment-matching families of distributions by tweaking the probabilities of pairs of bins so that one family maintains the defining inequalities while the other violates them.
</details>
<details>
<summary>摘要</summary>
我们开发了一种新的技术，用于证明分布测试下界 для由不等式定义的性质。使用这种技术，我们得到了新的下界 для monotonicity testing over discrete cubes，以及紧靠的下界 для log-concavity testing。我们的基本技术是构造一对具有相同幂次的两个分布家族，其中一家具有定义不等式的条件，而另一家则违反这些不等式。通过这种方式，我们可以比较这两个分布家族的分布特征，从而证明分布测试的下界。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Deep-Learning-based-Model-to-Defend-Network-Intrusion-Detection-System-against-Adversarial-Attacks"><a href="#A-Novel-Deep-Learning-based-Model-to-Defend-Network-Intrusion-Detection-System-against-Adversarial-Attacks" class="headerlink" title="A Novel Deep Learning based Model to Defend Network Intrusion Detection System against Adversarial Attacks"></a>A Novel Deep Learning based Model to Defend Network Intrusion Detection System against Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00077">http://arxiv.org/abs/2308.00077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khushnaseeb Roshan, Aasim Zafar, Shiekh Burhan Ul Haque</li>
<li>for: 本研究旨在研究深度学习基于网络入侵检测系统（NIDS）的强大敌意攻击算法以及其防御策略。</li>
<li>methods: 本研究使用了四种强大敌意攻击算法，即快速梯度签名方法（FGSM）、杠杆环境映射攻击（JSMA）、投影 DESC 下降（PGD）以及加洛皮尼和华生（C&amp;W）攻击。作为防御策略，本研究使用了对抗训练来提高NIDS模型的耐性。</li>
<li>results: 本研究结果分为三个阶段：1）之前敌意攻击，2）之后敌意攻击，3）之后对抗训练。使用了加拿大网络安全检测系统2017年版（CICIDS-2017）数据集进行评估，并使用了多种性能指标如f1-score、准确率等进行评估。<details>
<summary>Abstract</summary>
Network Intrusion Detection System (NIDS) is an essential tool in securing cyberspace from a variety of security risks and unknown cyberattacks. A number of solutions have been implemented for Machine Learning (ML), and Deep Learning (DL) based NIDS. However, all these solutions are vulnerable to adversarial attacks, in which the malicious actor tries to evade or fool the model by injecting adversarial perturbed examples into the system. The main aim of this research work is to study powerful adversarial attack algorithms and their defence method on DL-based NIDS. Fast Gradient Sign Method (FGSM), Jacobian Saliency Map Attack (JSMA), Projected Gradient Descent (PGD) and Carlini & Wagner (C&W) are four powerful adversarial attack methods implemented against the NIDS. As a defence method, Adversarial Training is used to increase the robustness of the NIDS model. The results are summarized in three phases, i.e., 1) before the adversarial attack, 2) after the adversarial attack, and 3) after the adversarial defence. The Canadian Institute for Cybersecurity Intrusion Detection System 2017 (CICIDS-2017) dataset is used for evaluation purposes with various performance measurements like f1-score, accuracy etc.
</details>
<details>
<summary>摘要</summary>
网络侵入检测系统（NIDS）是保护网络安全的重要工具，它可以检测到多种安全风险和未知的网络攻击。为了提高NIDS的检测精度，许多解决方案已经被应用于机器学习（ML）和深度学习（DL）基于的NIDS。然而，这些解决方案都受到了对抗攻击的威胁，其中恶意攻击者会尝试通过投入对抗扰动的例子来欺骗模型。本研究的主要目标是研究对DL-based NIDS的强大对抗攻击算法和防御策略。本研究使用了FGSM、JSMA、PGD和C&W等四种强大对抗攻击方法，并使用了对抗训练来提高NIDS模型的可靠性。Results are summarized in three phases: before the adversarial attack, after the adversarial attack, and after the adversarial defense.用于评估的数据集是CICIDS-2017。Results are evaluated using various performance metrics such as f1-score and accuracy.
</details></li>
</ul>
<hr>
<h2 id="Crowd-Safety-Manager-Towards-Data-Driven-Active-Decision-Support-for-Planning-and-Control-of-Crowd-Events"><a href="#Crowd-Safety-Manager-Towards-Data-Driven-Active-Decision-Support-for-Planning-and-Control-of-Crowd-Events" class="headerlink" title="Crowd Safety Manager: Towards Data-Driven Active Decision Support for Planning and Control of Crowd Events"></a>Crowd Safety Manager: Towards Data-Driven Active Decision Support for Planning and Control of Crowd Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00076">http://arxiv.org/abs/2308.00076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Panchamy Krishnakumari, Sascha Hoogendoorn-Lanser, Jeroen Steenbakkers, Serge Hoogendoorn</li>
<li>for: 这个论文旨在提出新的技术和方法，以增强群体管理的规划和运行阶段。这种方法包括创新的数据收集技术，数据集成和可视化使用3D数字双方法，以及在人工智能工具中包含的风险识别。</li>
<li>methods: 这个论文提出了一种名为“环形模型”的全面框架，用于评估和预测风险水平。这个模型结合了客观的估计和预测，如交通流操作和拥堵水平，以及各种累加因素，如天气条件、情绪和游客的目的，来评估预计的风险水平。</li>
<li>results: 该论文的结果表明，使用Resono数据源，可以在多天前为事件规划提供多日预测。XGBoost框架在对比其他机器学习技术时表现出最高的准确性。结果表明，预测的准确性足够高，但certain locations may benefit from additional input data to further enhance prediction quality。<details>
<summary>Abstract</summary>
This paper presents novel technology and methodology aimed at enhancing crowd management in both the planning and operational phases. The approach encompasses innovative data collection techniques, data integration, and visualization using a 3D Digital Twin, along with the incorporation of artificial intelligence (AI) tools for risk identification. The paper introduces the Bowtie model, a comprehensive framework designed to assess and predict risk levels. The model combines objective estimations and predictions, such as traffic flow operations and crowdedness levels, with various aggravating factors like weather conditions, sentiments, and the purpose of visitors, to evaluate the expected risk of incidents. The proposed framework is applied to the Crowd Safety Manager project in Scheveningen, where the DigiTwin is developed based on a wealth of real-time data sources. One noteworthy data source is Resono, offering insights into the number of visitors and their movements, leveraging a mobile phone panel of over 2 million users in the Netherlands. Particular attention is given to the left-hand side of the Bowtie, which includes state estimation, prediction, and forecasting. Notably, the focus is on generating multi-day ahead forecasts for event-planning purposes using Resono data. Advanced machine learning techniques, including the XGBoost framework, are compared, with XGBoost demonstrating the most accurate forecasts. The results indicate that the predictions are adequately accurate. However, certain locations may benefit from additional input data to further enhance prediction quality. Despite these limitations, this work contributes to a more effective crowd management system and opens avenues for further advancements in this critical field.
</details>
<details>
<summary>摘要</summary>
The proposed framework is applied to the Crowd Safety Manager project in Scheveningen, where the DigiTwin is developed based on a wealth of real-time data sources. One notable data source is Resono, which provides insights into the number of visitors and their movements, leveraging a mobile phone panel of over 2 million users in the Netherlands. The focus is on generating multi-day ahead forecasts for event planning purposes using Resono data, and advanced machine learning techniques, including the XGBoost framework, are compared. The results indicate that the predictions are adequately accurate, but certain locations may benefit from additional input data to further enhance prediction quality.Overall, this work contributes to a more effective crowd management system and opens up new avenues for further advancements in this critical field.
</details></li>
</ul>
<hr>
<h2 id="Using-Kernel-SHAP-XAI-Method-to-optimize-the-Network-Anomaly-Detection-Model"><a href="#Using-Kernel-SHAP-XAI-Method-to-optimize-the-Network-Anomaly-Detection-Model" class="headerlink" title="Using Kernel SHAP XAI Method to optimize the Network Anomaly Detection Model"></a>Using Kernel SHAP XAI Method to optimize the Network Anomaly Detection Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00074">http://arxiv.org/abs/2308.00074</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khushnaseeb Roshan, Aasim Zafar</li>
<li>for: 这篇论文目的是应用具有解释能力的人工智能技术（XAI）来检测和解释网络异常情况。</li>
<li>methods: 本论文使用kernelSHAP方法来检测网络异常情况，并且将这种方法与传统的网络侦错探测方法进行比较。</li>
<li>results: 本论文的实验结果显示，使用kernelSHAP方法可以提高网络异常检测模型的精度、回传率、精度和F分数。将这种方法应用于网络侦错探测可以增加模型的准确性和可靠性。<details>
<summary>Abstract</summary>
Anomaly detection and its explanation is important in many research areas such as intrusion detection, fraud detection, unknown attack detection in network traffic and logs. It is challenging to identify the cause or explanation of why one instance is an anomaly? and the other is not due to its unbounded and lack of supervisory nature. The answer to this question is possible with the emerging technique of explainable artificial intelligence (XAI). XAI provides tools and techniques to interpret and explain the output and working of complex models such as Deep Learning (DL). This paper aims to detect and explain network anomalies with XAI, kernelSHAP method. The same approach is used to improve the network anomaly detection model in terms of accuracy, recall, precision and f score. The experiment is conduced with the latest CICIDS2017 dataset. Two models are created (Model_1 and OPT_Model) and compared. The overall accuracy and F score of OPT_Model (when trained in unsupervised way) are 0.90 and 0.76, respectively.
</details>
<details>
<summary>摘要</summary>
“异常检测和其解释在许多研究领域都是重要的，如侵入检测、诈骗检测、未知攻击检测在网络流量和日志中。但是确定一个实例是异常的原因，而另一个不是，是一个挑战。这个问题的答案可能通过新兴的解释人工智能（XAI）技术得到解决。XAI提供了解释和解释复杂模型，如深度学习（DL）的工具和技术。这篇论文旨在使用XAI技术检测和解释网络异常，并使用kernelSHAP方法进行改进。实验使用最新的CICIDS2017 dataset，创建了两个模型（Model_1和OPT_Model），并对它们进行比较。OPT_Model在无监督的情况下训练时的总准确率和F分数分别为0.90和0.76。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="T-Fusion-Net-A-Novel-Deep-Neural-Network-Augmented-with-Multiple-Localizations-based-Spatial-Attention-Mechanisms-for-Covid-19-Detection"><a href="#T-Fusion-Net-A-Novel-Deep-Neural-Network-Augmented-with-Multiple-Localizations-based-Spatial-Attention-Mechanisms-for-Covid-19-Detection" class="headerlink" title="T-Fusion Net: A Novel Deep Neural Network Augmented with Multiple Localizations based Spatial Attention Mechanisms for Covid-19 Detection"></a>T-Fusion Net: A Novel Deep Neural Network Augmented with Multiple Localizations based Spatial Attention Mechanisms for Covid-19 Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00053">http://arxiv.org/abs/2308.00053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Susmita Ghosh, Abhiroop Chatterjee</li>
<li>for: 提高图像分类任务的性能</li>
<li>methods: 使用多个本地化的空间注意力 Mechanism，并将其 ensemble 为一个 homogeneous  ensemble</li>
<li>results: 对 Covid-19 (SARS-CoV-2 CT scan) 数据集进行实验，提出的 T-Fusion Net 和 homogeneous ensemble 模型均显示出比其他状态对照方法更好的性能，准确率分别达到 97.59% 和 98.4%。<details>
<summary>Abstract</summary>
In recent years, deep neural networks are yielding better performance in image classification tasks. However, the increasing complexity of datasets and the demand for improved performance necessitate the exploration of innovative techniques. The present work proposes a new deep neural network (called as, T-Fusion Net) that augments multiple localizations based spatial attention. This attention mechanism allows the network to focus on relevant image regions, improving its discriminative power. A homogeneous ensemble of the said network is further used to enhance image classification accuracy. For ensembling, the proposed approach considers multiple instances of individual T-Fusion Net. The model incorporates fuzzy max fusion to merge the outputs of individual nets. The fusion process is optimized through a carefully chosen parameter to strike a balance on the contributions of the individual models. Experimental evaluations on benchmark Covid-19 (SARS-CoV-2 CT scan) dataset demonstrate the effectiveness of the proposed T-Fusion Net as well as its ensemble. The proposed T-Fusion Net and the homogeneous ensemble model exhibit better performance, as compared to other state-of-the-art methods, achieving accuracy of 97.59% and 98.4%, respectively.
</details>
<details>
<summary>摘要</summary>
现在的深度神经网络在图像分类任务中表现更好，但是随着数据集的增加和性能的需求，需要探索新的技术。本文提出了一种新的深度神经网络（称为T-Fusion Net），它在多个本地化位置基于的空间注意力 Mechanism 中加入了多个本地化位置的注意力机制，使网络能够更好地关注相关的图像区域，提高其分类力。然后，这个网络的多个实例被用来提高图像分类精度。为了整合，该方法考虑多个个体T-Fusion Net的拟合。这个模型使用了最大值拟合来融合各个网络的输出。拟合过程中选择了一个精心选择的参数，以达到各个模型的贡献平衡。实验表明，提案的T-Fusion Net和多个实例模型在 Covid-19（SARS-CoV-2 CT 扫描）数据集上表现出色，其中T-Fusion Net的准确率为97.59%，多个实例模型的准确率为98.4%。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Generative-AI-State-of-the-Art-Opportunities-and-Open-Research-Challenges"><a href="#Reinforcement-Learning-for-Generative-AI-State-of-the-Art-Opportunities-and-Open-Research-Challenges" class="headerlink" title="Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges"></a>Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00031">http://arxiv.org/abs/2308.00031</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giorgio Franceschelli, Mirco Musolesi</li>
<li>for: 这篇论文探讨了将强化学习应用于生成人工智能中的现状、机遇和未解决问题。</li>
<li>methods: 论文使用了强化学习作为生成人工智能的一种新方法，包括RL作为生成的替代方法、RL作为生成 outputs 的同时最大化目标函数的方法，以及RL来嵌入不易被目标函数捕捉的愿望特征。</li>
<li>results: 论文结束时未提出具体的结果，但认为这个领域具有很大的潜力和挑战。<details>
<summary>Abstract</summary>
Generative Artificial Intelligence (AI) is one of the most exciting developments in Computer Science of the last decade. At the same time, Reinforcement Learning (RL) has emerged as a very successful paradigm for a variety of machine learning tasks. In this survey, we discuss the state of the art, opportunities and open research questions in applying RL to generative AI. In particular, we will discuss three types of applications, namely, RL as an alternative way for generation without specified objectives; as a way for generating outputs while concurrently maximizing an objective function; and, finally, as a way of embedding desired characteristics, which cannot be easily captured by means of an objective function, into the generative process. We conclude the survey with an in-depth discussion of the opportunities and challenges in this fascinating emerging area.
</details>
<details>
<summary>摘要</summary>
优化人工智能（AI）是过去十年计算机科学中最吸引人的发展之一。同时，对称学习（RL）已成为许多机器学习任务中非常成功的方法论。在这篇评论中，我们讨论了在应用RL到生成AI方面的状态、机遇和开放的研究问题。具体来说，我们将讨论以下三种应用：RL作为不具体目标的生成方式；RL作为同时最大化目标函数的生成输出方式；RL作为插入感知不易被目标函数捕捉的特点的生成过程中的方法。我们在这篇评论结束时对这个吸引人的新兴领域的机会和挑战进行了深入的讨论。
</details></li>
</ul>
<hr>
<h2 id="Conformal-PID-Control-for-Time-Series-Prediction"><a href="#Conformal-PID-Control-for-Time-Series-Prediction" class="headerlink" title="Conformal PID Control for Time Series Prediction"></a>Conformal PID Control for Time Series Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16895">http://arxiv.org/abs/2307.16895</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aangelopoulos/conformal-time-series">https://github.com/aangelopoulos/conformal-time-series</a></li>
<li>paper_authors: Anastasios N. Angelopoulos, Emmanuel J. Candes, Ryan J. Tibshirani</li>
<li>for: 这 paper 的目的是提供一种方便使用的时间序列预测方法，并提供正式的保证。</li>
<li>methods: 这 paper 使用了充分采用了抗干扰预测、控制理论和在线预测等方法，能够适应系统性错误的存在。</li>
<li>results: 实验表明，这 paper 的方法可以在美国州际 COVID-19 死亡人数的4个星期前预测中提供更好的覆盖率，以及在电能需求、股票市场收益和气温等领域的预测中达到更高的准确率。<details>
<summary>Abstract</summary>
We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in official CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules.
</details>
<details>
<summary>摘要</summary>
我们研究了时间序列预测不确定性评估的问题，目的是提供有正式保证的易用算法。我们的算法基于协形预测和控制理论的想法，可在线设置 prospectively 模型协形分数，并适应系统性错误的季节性、趋势和总分布变化。我们的理论简化并强化了现有的在线协形预测分析。我们在美国州际 COVID-19 死亡人数预测4个礼拜前进行了实验，比 Ensemble 预测器使用在官方CDC通信中的表现更好。我们还在预测电能需求、股票市场收益和温度上使用拟合、Theta、Prophet 和 Transformer 模型进行实验。我们提供了可extendable的代码库，用于测试我们的方法和新算法、数据集和预测规则的集成。
</details></li>
</ul>
<hr>
<h2 id="Predicting-masked-tokens-in-stochastic-locations-improves-masked-image-modeling"><a href="#Predicting-masked-tokens-in-stochastic-locations-improves-masked-image-modeling" class="headerlink" title="Predicting masked tokens in stochastic locations improves masked image modeling"></a>Predicting masked tokens in stochastic locations improves masked image modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00566">http://arxiv.org/abs/2308.00566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amir Bar, Florian Bordes, Assaf Shocher, Mahmoud Assran, Pascal Vincent, Nicolas Ballas, Trevor Darrell, Amir Globerson, Yann LeCun</li>
<li>for: 这个论文的目的是提出一种减少位置不确定性的自助学习模型，以提高计算机视觉任务的表现。</li>
<li>methods: 该论文使用了随机masked token位置来引导模型学习更加Robust的特征，以解决计算机视觉中的Masked Image Modeling（MIM）挑战。</li>
<li>results:  compared to MIM基线，该论文的方法可以提高ImageNet线性探测的表现，比如使用ViT-B时提高1.6%，使用ViT-L时提高2.5%。<details>
<summary>Abstract</summary>
Self-supervised learning is a promising paradigm in deep learning that enables learning from unlabeled data by constructing pretext tasks that require learning useful representations. In natural language processing, the dominant pretext task has been masked language modeling (MLM), while in computer vision there exists an equivalent called Masked Image Modeling (MIM). However, MIM is challenging because it requires predicting semantic content in accurate locations. E.g, given an incomplete picture of a dog, we can guess that there is a tail, but we cannot determine its exact location. In this work, we propose FlexPredict, a stochastic model that addresses this challenge by incorporating location uncertainty into the model. Specifically, we condition the model on stochastic masked token positions to guide the model toward learning features that are more robust to location uncertainties. Our approach improves downstream performance on a range of tasks, e.g, compared to MIM baselines, FlexPredict boosts ImageNet linear probing by 1.6% with ViT-B and by 2.5% for semi-supervised video segmentation using ViT-L.
</details>
<details>
<summary>摘要</summary>
自我指导学习是深度学习中的一种有前途的方法，它允许通过建立预测任务来学习无标注数据中的有用表示。在自然语言处理中，主流的预测任务是填充语言模型（MLM），而在计算机视觉中则有相应的equivalent called Masked Image Modeling（MIM）。然而，MIM是一个挑战，因为它需要准确预测 semantic content的位置。例如，给一个含有缺失的狗图片，我们可以预测有尾巴，但不能准确地确定其位置。在这种情况下，我们提出了FlexPredict，一种随机模型，用于解决这个挑战。我们通过conditioning the model on stochastic masked token positions来引导模型学习更加Robust to location uncertainties的特征。我们的方法可以提高下游任务的性能，例如，相比MIM基线，FlexPredict在ImageNet线性探测中提高了ViT-B的表现，提高了 semi-supervised video segmentation using ViT-L的表现。
</details></li>
</ul>
<hr>
<h2 id="Foundational-Models-for-Fault-Diagnosis-of-Electrical-Motors"><a href="#Foundational-Models-for-Fault-Diagnosis-of-Electrical-Motors" class="headerlink" title="Foundational Models for Fault Diagnosis of Electrical Motors"></a>Foundational Models for Fault Diagnosis of Electrical Motors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16891">http://arxiv.org/abs/2307.16891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sriram Anbalagan, Deepesh Agarwal, Balasubramaniam Natarajan, Babji Srinivasan</li>
<li>for: 这个研究旨在提出一个基础模型来解决电动机异常诊断中的训练数据分布假设问题。</li>
<li>methods: 本研究使用自我超vised学习建立神经网络后端，然后精确化这个后端以达到特定目标。</li>
<li>results: 实验结果显示，提案的方法可以在不同的异常情况和操作条件下取得高于90%的分类精度，并且适用于不同的机器之间的十分多样化的异常诊断任务。<details>
<summary>Abstract</summary>
A majority of recent advancements related to the fault diagnosis of electrical motors are based on the assumption that training and testing data are drawn from the same distribution. However, the data distribution can vary across different operating conditions during real-world operating scenarios of electrical motors. Consequently, this assumption limits the practical implementation of existing studies for fault diagnosis, as they rely on fully labelled training data spanning all operating conditions and assume a consistent distribution. This is because obtaining a large number of labelled samples for several machines across different fault cases and operating scenarios may be unfeasible. In order to overcome the aforementioned limitations, this work proposes a framework to develop a foundational model for fault diagnosis of electrical motors. It involves building a neural network-based backbone to learn high-level features using self-supervised learning, and then fine-tuning the backbone to achieve specific objectives. The primary advantage of such an approach is that the backbone can be fine-tuned to achieve a wide variety of target tasks using very less amount of training data as compared to traditional supervised learning methodologies. The empirical evaluation demonstrates the effectiveness of the proposed approach by obtaining more than 90\% classification accuracy by fine-tuning the backbone not only across different types of fault scenarios or operating conditions, but also across different machines. This illustrates the promising potential of the proposed approach for cross-machine fault diagnosis tasks in real-world applications.
</details>
<details>
<summary>摘要</summary>
大多数最近的电机故障诊断研究假设训练和测试数据来自同一个分布。然而，实际应用中电机的数据分布可能会随着不同的运行条件而变化。这导致了现有的研究存在限制，因为它们需要完全标注的训练数据，涵盖所有运行条件和假设一致的分布。这可能是不可能获得大量完全标注的样本的。为了突破这些限制，这项工作提出了一种框架，用于开发电机故障诊断的基础模型。它包括使用神经网络作为基础模型，通过自我超vised learning来学习高级特征，然后使用这些特征来达到特定目标。这种方法的优点是，可以使用非常少的训练数据来 Fine-tune the backbone，以实现各种目标任务。实际评估表明，提议的方法可以在不同的故障情况和运行条件下，以及不同的机器上，达到高于90%的分类精度。这表明了提议的方法在实际应用中的推广潜力。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Model-the-World-with-Language"><a href="#Learning-to-Model-the-World-with-Language" class="headerlink" title="Learning to Model the World with Language"></a>Learning to Model the World with Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01399">http://arxiv.org/abs/2308.01399</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/OpenKP">https://github.com/microsoft/OpenKP</a></li>
<li>paper_authors: Jessy Lin, Yuqing Du, Olivia Watkins, Danijar Hafner, Pieter Abbeel, Dan Klein, Anca Dragan</li>
<li>for: 这篇论文目标是建立一种能够理解多种语言类型，将语言与视觉世界相关联，并基于其进行行动的 Agent。</li>
<li>methods: 该论文提出的关键想法是通过语言预测未来，包括未来的语言、视频和奖励情况。 Agent 通过自我监督学习来学习多 modal 世界模型，并通过这些预测来学习行动。</li>
<li>results: 实验表明，使用 Dynalang 可以在多种语言和多种任务下提高 Agent 的性能，包括在固定环境中学习、在不同语言和视觉数据集上预训练、以及在各种语言提示下完成任务。<details>
<summary>Abstract</summary>
To interact with humans in the world, agents need to understand the diverse types of language that people use, relate them to the visual world, and act based on them. While current agents learn to execute simple language instructions from task rewards, we aim to build agents that leverage diverse language that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that language helps agents predict the future: what will be observed, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning objective. We present Dynalang, an agent that learns a multimodal world model that predicts future text and image representations and learns to act from imagined model rollouts. Unlike traditional agents that use language only to predict actions, Dynalang acquires rich language understanding by using past language also to predict future language, video, and rewards. In addition to learning from online interaction in an environment, Dynalang can be pretrained on datasets of text, video, or both without actions or rewards. From using language hints in grid worlds to navigating photorealistic scans of homes, Dynalang utilizes diverse types of language to improve task performance, including environment descriptions, game rules, and instructions.
</details>
<details>
<summary>摘要</summary>
转换文本为简化中文。为了在人类世界中交互，代理需要理解人类使用的多种语言，将其与视觉世界相关，并根据其行动。现有的代理通过任务奖励学习执行简单的语言指令，而我们目标是建立可以利用多种语言，描述世界状况，提供交互反馈，并更多的语言理解的代理。我们关键思想是语言帮助代理预测未来：未来会看到什么，世界会如何行为，哪些情况将得到奖励。这种视角将语言理解与未来预测联系起来，形成一个强大的自动学习目标。我们介绍了 Dynalang，一种学习多模态世界模型，预测未来文本和图像表示，并从想象模型执行中学习行动。不同于传统代理使用语言只预测行动，Dynalang通过过去语言也预测未来语言、视频和奖励来获得丰富的语言理解。除了在环境中从 línea interaction 学习外，Dynalang 还可以在没有动作或奖励的情况下预测文本、视频或两者各种数据集上进行预训练。从使用语言提示在网格世界中探索到在拍摄图像中穿梭家庭，Dynalang 利用多种语言提高任务性能，包括环境描述、游戏规则和指令。
</details></li>
</ul>
<hr>
<h2 id="Discovering-Adaptable-Symbolic-Algorithms-from-Scratch"><a href="#Discovering-Adaptable-Symbolic-Algorithms-from-Scratch" class="headerlink" title="Discovering Adaptable Symbolic Algorithms from Scratch"></a>Discovering Adaptable Symbolic Algorithms from Scratch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16890">http://arxiv.org/abs/2307.16890</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephen Kelly, Daniel S. Park, Xingyou Song, Mitchell McIntire, Pranav Nashikkar, Ritam Guha, Wolfgang Banzhaf, Kalyanmoy Deb, Vishnu Naresh Boddeti, Jie Tan, Esteban Real</li>
<li>for: 这篇论文旨在开发一种可靠地在实际环境中部署自主 робоット的控制策略，即AutoRobotics-Zero（ARZ）。</li>
<li>methods: ARZ 使用 AutoML-Zero 方法从零开始学习适应环境变化的控制策略，不同于传统的神经网络适应策略，ARZ 可以建立基于线性扩展机器的完整表达能力的控制算法。</li>
<li>results: 在模拟的四脚机器人上进行了实验，ARZ 可以生成安全的控制策略，以避免机器人突然失效时的倒下。此外，在一个新的非站立控制任务中，ARZ 表现出了明显的更好的稳定性和可靠性。<details>
<summary>Abstract</summary>
Autonomous robots deployed in the real world will need control policies that rapidly adapt to environmental changes. To this end, we propose AutoRobotics-Zero (ARZ), a method based on AutoML-Zero that discovers zero-shot adaptable policies from scratch. In contrast to neural network adaption policies, where only model parameters are optimized, ARZ can build control algorithms with the full expressive power of a linear register machine. We evolve modular policies that tune their model parameters and alter their inference algorithm on-the-fly to adapt to sudden environmental changes. We demonstrate our method on a realistic simulated quadruped robot, for which we evolve safe control policies that avoid falling when individual limbs suddenly break. This is a challenging task in which two popular neural network baselines fail. Finally, we conduct a detailed analysis of our method on a novel and challenging non-stationary control task dubbed Cataclysmic Cartpole. Results confirm our findings that ARZ is significantly more robust to sudden environmental changes and can build simple, interpretable control policies.
</details>
<details>
<summary>摘要</summary>
自适应 роботы在实际世界中部署需要快速适应环境变化的控制策略。为此，我们提议AutoRobotics-Zero（ARZ）方法，基于AutoML-Zero方法，可以从头开始找到零shot适应策略。与神经网络适应策略不同，ARZ可以建立一个完整的线性注册机器的控制算法。我们演化了模块化策略，可以在运行时调整模型参数和推理算法，以适应突然的环境变化。我们在模拟的四脚 робот上进行了实验，演示了我们的方法可以建立安全的控制策略，以避免当个肢体突然失效时的倒下。这是一个具有挑战性的任务，两种流行的神经网络基elines都失败了。最后，我们对这种方法进行了详细的分析，并在一个新的和具有挑战性的非站立控制任务上进行了实验。结果证明了我们的发现，ARZ在突然环境变化中更加稳定和可靠，并可以建立简单、可读的控制策略。
</details></li>
</ul>
<hr>
<h2 id="Virtual-Prompt-Injection-for-Instruction-Tuned-Large-Language-Models"><a href="#Virtual-Prompt-Injection-for-Instruction-Tuned-Large-Language-Models" class="headerlink" title="Virtual Prompt Injection for Instruction-Tuned Large Language Models"></a>Virtual Prompt Injection for Instruction-Tuned Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16888">http://arxiv.org/abs/2307.16888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, Hongxia Jin</li>
<li>for: 这个论文是为了漏洞抢夺大语言模型（LLM）的指令调整数据，以实现无需显式插入模型输入中的攻击。</li>
<li>methods: 论文提出了一种名为虚拟提示投入（VPI）的攻击方法，通过在特定触发场景下控制模型行为，无需与攻击者直接交互。</li>
<li>results: 研究人员通过对模型的指令调整数据进行恶意掺入，成功地使模型在处理有关参考人物（如乔·纽约）的查询时表现出偏见。这种攻击可以在服务器端 persistently 进行，无需攻击者直接交互。<details>
<summary>Abstract</summary>
We present Virtual Prompt Injection (VPI) for instruction-tuned Large Language Models (LLMs). VPI allows an attacker-specified virtual prompt to steer the model behavior under specific trigger scenario without any explicit injection in model input. For instance, if an LLM is compromised with the virtual prompt "Describe Joe Biden negatively." for Joe Biden-related instructions, then any service deploying this model will propagate biased views when handling user queries related to Joe Biden. VPI is especially harmful for two primary reasons. Firstly, the attacker can take fine-grained control over LLM behaviors by defining various virtual prompts, exploiting LLMs' proficiency in following instructions. Secondly, this control is achieved without any interaction from the attacker while the model is in service, leading to persistent attack. To demonstrate the threat, we propose a simple method for performing VPI by poisoning the model's instruction tuning data. We find that our proposed method is highly effective in steering the LLM with VPI. For example, by injecting only 52 poisoned examples (0.1% of the training data size) into the instruction tuning data, the percentage of negative responses given by the trained model on Joe Biden-related queries change from 0% to 40%. We thus highlight the necessity of ensuring the integrity of the instruction-tuning data as little poisoned data can cause stealthy and persistent harm to the deployed model. We further explore the possible defenses and identify data filtering as an effective way to defend against the poisoning attacks. Our project page is available at https://poison-llm.github.io.
</details>
<details>
<summary>摘要</summary>
我们介绍了虚拟提示投入（VPI），用于训练大型自然语言模型（LLM）。VPI允许攻击者在特定触发场景下使用自定义虚拟提示，无需直接插入模型输入中。例如，如果一个LLM被恶意攻击，并且在Joe Biden相关的指令中包含虚拟提示“描述Joe Biden消极”，那么服务器上部署的模型将在处理用户查询时传播偏见视角。VPI具有两点危险性。首先，攻击者可以通过定制多个虚拟提示，细化控制LLM的行为。其次，这种控制是在服务器上部署模型时完成，导致持续攻击。为证明这种威胁，我们提出了一种简单的VPI攻击方法，利用模型的指令调整数据中恶意污染。我们发现，只需插入0.1%的恶意示例（52个），可以让模型对Joe Biden相关的查询问题上提供40%的负面回答。这显示了对部署模型的指令调整数据的完整性是非常重要的，否则可能导致隐藏和持续的攻击。我们还探讨了可能的防御策略，并确定数据筛选是一种有效的防御方法。更多信息可以通过我们的项目页面（<https://poison-llm.github.io>）获得。
</details></li>
</ul>
<hr>
<h2 id="MetaCAM-Ensemble-Based-Class-Activation-Map"><a href="#MetaCAM-Ensemble-Based-Class-Activation-Map" class="headerlink" title="MetaCAM: Ensemble-Based Class Activation Map"></a>MetaCAM: Ensemble-Based Class Activation Map</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16863">http://arxiv.org/abs/2307.16863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emily Kaczmarek, Olivier X. Miguel, Alexa C. Bowie, Robin Ducharme, Alysha L. J. Dingwall-Harvey, Steven Hawken, Christine M. Armour, Mark C. Walker, Kevin Dick</li>
<li>for: 本研究旨在提高深度学习模型预测结果的可读性和可信度，特别是在医学和生物认知领域。</li>
<li>methods: 本研究使用了多种现有的视觉解释方法，包括卷积神经网络的核心活动地图（CAM）。并提出了一种 ensemble-based 方法——MetaCAM，可以结合多种 CAM 方法，并通过选择最高活动像素的共识来决定最佳组合。</li>
<li>results: 研究表明，MetaCAM 可以超越单个 CAM 的性能，并更好地捕捉模型预测结果中的核心区域。在一个具体的示例中，MetaCAM 可以提高 ROAD 性能至 0.393，比单个 CAM 的范围从 -0.101 到 0.172 更高，这说明了 ensemble-based 方法和适应阈值调整的重要性。<details>
<summary>Abstract</summary>
The need for clear, trustworthy explanations of deep learning model predictions is essential for high-criticality fields, such as medicine and biometric identification. Class Activation Maps (CAMs) are an increasingly popular category of visual explanation methods for Convolutional Neural Networks (CNNs). However, the performance of individual CAMs depends largely on experimental parameters such as the selected image, target class, and model. Here, we propose MetaCAM, an ensemble-based method for combining multiple existing CAM methods based on the consensus of the top-k% most highly activated pixels across component CAMs. We perform experiments to quantifiably determine the optimal combination of 11 CAMs for a given MetaCAM experiment. A new method denoted Cumulative Residual Effect (CRE) is proposed to summarize large-scale ensemble-based experiments. We also present adaptive thresholding and demonstrate how it can be applied to individual CAMs to improve their performance, measured using pixel perturbation method Remove and Debias (ROAD). Lastly, we show that MetaCAM outperforms existing CAMs and refines the most salient regions of images used for model predictions. In a specific example, MetaCAM improved ROAD performance to 0.393 compared to 11 individual CAMs with ranges from -0.101-0.172, demonstrating the importance of combining CAMs through an ensembling method and adaptive thresholding.
</details>
<details>
<summary>摘要</summary>
需要清晰、可信的深度学习模型预测解释是高重要性领域，如医学和生物认知识别。图像活动地图（CAM）是深度学习模型的视觉解释方法之一，其性能受实验参数的影响，如选择的图像、目标类和模型。在这里，我们提出了MetaCAM，一种基于 ensemble 方法组合多个现有 CAM 方法的方法，通过最高活动像素的极值来决定组合。我们进行了量化的实验来确定MetaCAM experiment中的优化组合。此外，我们还提出了一种新的方法，称为累积差异效应（CRE），用于总结大规模的 ensemble 实验。最后，我们展示了如何应用适应阈值来改进个体 CAM 的性能，使用 Remove and Debias（ROAD）的像素扰动方法。我们的结果表明，MetaCAM 超过了现有 CAM 的性能，并提高了模型预测中使用的图像的最 salient 区域。例如，在一个特定的 MetaCAM 实验中，我们提高了 ROAD 性能到 0.393，比11个个体 CAM 的范围从 -0.101-0.172 高，这表明了将 CAM 通过 ensemble 方法和适应阈值组合可以提高性能。
</details></li>
</ul>
<hr>
<h2 id="Towards-Trustworthy-and-Aligned-Machine-Learning-A-Data-centric-Survey-with-Causality-Perspectives"><a href="#Towards-Trustworthy-and-Aligned-Machine-Learning-A-Data-centric-Survey-with-Causality-Perspectives" class="headerlink" title="Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives"></a>Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16851">http://arxiv.org/abs/2307.16851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyang Liu, Maheep Chaudhary, Haohan Wang</li>
<li>For: 本文总结了过去十年内关于机器学习可靠性的研究发展，包括Robustness、安全、可读性和公平性等方面。* Methods: 本文使用了一种数据中心的方法来系统性地评估传统的零基eline risk minimization（ERM）训练方法在数据上的缺陷。同时，文章还探讨了基于 causality 理论的方法，并将这些方法与 Pearl 的 causality 层次结构相连接。* Results: 本文提供了一种统一的语言和数学术语来链接这些方法，并将它们与 robustness、对抗性、可读性和公平性等领域的方法相连接。这些方法的应用和未来发展也被详细介绍。<details>
<summary>Abstract</summary>
The trustworthiness of machine learning has emerged as a critical topic in the field, encompassing various applications and research areas such as robustness, security, interpretability, and fairness. The last decade saw the development of numerous methods addressing these challenges. In this survey, we systematically review these advancements from a data-centric perspective, highlighting the shortcomings of traditional empirical risk minimization (ERM) training in handling challenges posed by the data.   Interestingly, we observe a convergence of these methods, despite being developed independently across trustworthy machine learning subfields. Pearl's hierarchy of causality offers a unifying framework for these techniques. Accordingly, this survey presents the background of trustworthy machine learning development using a unified set of concepts, connects this language to Pearl's causal hierarchy, and finally discusses methods explicitly inspired by causality literature. We provide a unified language with mathematical vocabulary to link these methods across robustness, adversarial robustness, interpretability, and fairness, fostering a more cohesive understanding of the field.   Further, we explore the trustworthiness of large pretrained models. After summarizing dominant techniques like fine-tuning, parameter-efficient fine-tuning, prompting, and reinforcement learning with human feedback, we draw connections between them and the standard ERM. This connection allows us to build upon the principled understanding of trustworthy methods, extending it to these new techniques in large pretrained models, paving the way for future methods. Existing methods under this perspective are also reviewed.   Lastly, we offer a brief summary of the applications of these methods and discuss potential future aspects related to our survey. For more information, please visit http://trustai.one.
</details>
<details>
<summary>摘要</summary>
machine learning的可靠性已经成为该领域的关键话题，涵盖了多种应用和研究领域，如可靠性、安全性、可读性和公平性。过去十年许多方法提出了解决这些挑战的方法。在本文中，我们系统地回顾这些进步，从数据中心的视角出发， highlighting ERM 训练的缺陷在处理数据时。意外地，我们发现这些方法即使独立地在可靠机器学习子领域中发展，也存在一定的相似之处。以爱德华·珀尔的 causality 层次结构为基础，我们提供了一个统一的概念语言，将这些方法连接起来，并 finally 讨论了基于 causality 文献的方法。我们提供了一个统一的语言，以数学术语连接这些方法，从 robustness、对抗性、可读性和公平性等方面进行链接，以便更好地理解这个领域。此外，我们还探讨了大型预训模型的可靠性。我们首先概括了现有的方法，如 fine-tuning、参数效率的 fine-tuning、提示和人工反馈学习。然后，我们连接这些方法和标准 ERM，从而扩展了可靠方法的理解，应用于这些新的大型预训模型。现有的方法也被评论。最后，我们 brief summary 了这些方法的应用和未来方向。更多信息请参考http://trustai.one。
</details></li>
</ul>
<hr>
<h2 id="A-Trajectory-K-Anonymity-Model-Based-on-Point-Density-and-Partition"><a href="#A-Trajectory-K-Anonymity-Model-Based-on-Point-Density-and-Partition" class="headerlink" title="A Trajectory K-Anonymity Model Based on Point Density and Partition"></a>A Trajectory K-Anonymity Model Based on Point Density and Partition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16849">http://arxiv.org/abs/2307.16849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wanshu Yu, Haonan Shi, Hongyun Xu</li>
<li>for: 保护用户 trajectory 数据隐私</li>
<li>methods: 基于 Point Density 和 Partition 的 trajectory K-anonymity 模型</li>
<li>results: 提高了对 trajectory 数据的隐私保护，同时保持了数据的数据用性和算法执行时间的优化Here’s a more detailed explanation of each point:</li>
<li>for: The paper aims to protect users’ trajectory data privacy by proposing a trajectory K-anonymity model based on Point Density and Partition (KPDP).</li>
<li>methods: The proposed model uses Point Density and Partition to anonymize trajectory data and resist re-identification attacks.</li>
<li>results: The proposed model improves the existing trajectory generalization anonymization techniques regarding trajectory set partition preprocessing and trajectory clustering algorithms, and achieves better privacy protection, data utility, and algorithm execution time.<details>
<summary>Abstract</summary>
As people's daily life becomes increasingly inseparable from various mobile electronic devices, relevant service application platforms and network operators can collect numerous individual information easily. When releasing these data for scientific research or commercial purposes, users' privacy will be in danger, especially in the publication of spatiotemporal trajectory datasets. Therefore, to avoid the leakage of users' privacy, it is necessary to anonymize the data before they are released. However, more than simply removing the unique identifiers of individuals is needed to protect the trajectory privacy, because some attackers may infer the identity of users by the connection with other databases. Much work has been devoted to merging multiple trajectories to avoid re-identification, but these solutions always require sacrificing data quality to achieve the anonymity requirement. In order to provide sufficient privacy protection for users' trajectory datasets, this paper develops a study on trajectory privacy against re-identification attacks, proposing a trajectory K-anonymity model based on Point Density and Partition (KPDP). Our approach improves the existing trajectory generalization anonymization techniques regarding trajectory set partition preprocessing and trajectory clustering algorithms. It successfully resists re-identification attacks and reduces the data utility loss of the k-anonymized dataset. A series of experiments on a real-world dataset show that the proposed model has significant advantages in terms of higher data utility and shorter algorithm execution time than other existing techniques.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Latent-Masking-for-Multimodal-Self-supervised-Learning-in-Health-Timeseries"><a href="#Latent-Masking-for-Multimodal-Self-supervised-Learning-in-Health-Timeseries" class="headerlink" title="Latent Masking for Multimodal Self-supervised Learning in Health Timeseries"></a>Latent Masking for Multimodal Self-supervised Learning in Health Timeseries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16847">http://arxiv.org/abs/2307.16847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shohreh Deldari, Dimitris Spathis, Mohammad Malekzadeh, Fahim Kawsar, Flora Salim, Akhil Mathur</li>
<li>for: 这篇论文旨在解决生物医学时间序列资料学习中的标签资料短缺问题，通过自主学习（SSL）方法学习数据表现。</li>
<li>methods: 这篇论文提出了两个新的概念：在特定频道Encoder中隐藏媒体特定的中间嵌入，并将其聚合到一个全球嵌入使用跨modal聚合器。这允许处理缺失的modalities并实现无需预先处理数据或时间consuming的负项双数据抽取。</li>
<li>results: 这篇论文的结果显示了与先前的SSL技术和指定标签数据的比较，在多modal时间序列benchmark上表现出色，并且具有最佳性能。它还分析了不同的掩蔽比率和策略的影响，并评估了对缺失modalities的学习表现的Robustness。<details>
<summary>Abstract</summary>
Limited availability of labeled data for machine learning on biomedical time-series hampers progress in the field. Self-supervised learning (SSL) is a promising approach to learning data representations without labels. However, current SSL methods require expensive computations for negative pairs and are designed for single modalities, limiting their versatility. To overcome these limitations, we introduce CroSSL (Cross-modal SSL). CroSSL introduces two novel concepts: masking intermediate embeddings from modality-specific encoders and aggregating them into a global embedding using a cross-modal aggregator. This enables the handling of missing modalities and end-to-end learning of cross-modal patterns without prior data preprocessing or time-consuming negative-pair sampling. We evaluate CroSSL on various multimodal time-series benchmarks, including both medical-grade and consumer biosignals. Our results demonstrate superior performance compared to previous SSL techniques and supervised benchmarks with minimal labeled data. We additionally analyze the impact of different masking ratios and strategies and assess the robustness of the learned representations to missing modalities. Overall, our work achieves state-of-the-art performance while highlighting the benefits of masking latent embeddings for cross-modal learning in temporal health data.
</details>
<details>
<summary>摘要</summary>
限制的可用数据导致生物医学时序学机器学习的进步受阻。无监督学习（SSL）是一种可能的方法，可以不使用标签学习数据表示。然而，当前的SSL方法需要高昂的计算成本和负样本，同时只适用于单模态，这限制了它们的 universality。为了突破这些限制，我们介绍了CrossSSL（跨Modal SSL）。CrossSSL引入了两个新的概念：在特定模式Encoder中遮盖中间嵌入，并使用跨模态聚合器将其聚合成全模态嵌入。这允许处理缺失的模式和终端学习跨模态模式，无需先进行数据预处理或时间consuming负样本生成。我们在多模态时序数据上评估了CrossSSL，包括医疗级和消费者生物信号。我们的结果显示CrossSSL的性能比前一代SSL技术和监督标准更高，即使只使用最少的标签数据。我们还分析了不同的遮盖比和策略，并评估了学习到缺失模式的表示的稳定性。总的来说，我们的工作实现了状态机器学习的表现，同时强调在 temporal health data 中遮盖嵌入的掩码对多模态学习的好处。
</details></li>
</ul>
<hr>
<h2 id="Identification-of-Driving-Heterogeneity-using-Action-chains"><a href="#Identification-of-Driving-Heterogeneity-using-Action-chains" class="headerlink" title="Identification of Driving Heterogeneity using Action-chains"></a>Identification of Driving Heterogeneity using Action-chains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16843">http://arxiv.org/abs/2307.16843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xue Yao, Simeon C. Calvert, Serge P. Hoogendoorn</li>
<li>for: 本研究旨在开发一种全面的驾驶异常性识别框架，从动作链视角出发，以捕捉驾驶行为的多样性和基本模式。</li>
<li>methods: 本研究提出了一种基于规则的分割技术，考虑驾驶行为的物理含义，然后建立了一个动作库，包括各种驾驶行为模式的描述。接着，本研究引入了动作阶段过渡概率，并提出了评估驾驶异常性的方法。</li>
<li>results: 使用实际数据进行评估，本研究的方法能够有效识别驾驶异常性，包括个体驾驶者和交通流动的异常性，并提供了明确的解释。这些发现可以帮助建立准确的驾驶行为理论和交通流动模型，从而提高交通性能和安全性。<details>
<summary>Abstract</summary>
Current approaches to identifying driving heterogeneity face challenges in capturing the diversity of driving characteristics and understanding the fundamental patterns from a driving behaviour mechanism standpoint. This study introduces a comprehensive framework for identifying driving heterogeneity from an Action-chain perspective. First, a rule-based segmentation technique that considers the physical meanings of driving behaviour is proposed. Next, an Action phase Library including descriptions of various driving behaviour patterns is created based on the segmentation findings. The Action-chain concept is then introduced by implementing Action phase transition probability, followed by a method for evaluating driving heterogeneity. Employing real-world datasets for evaluation, our approach effectively identifies driving heterogeneity for both individual drivers and traffic flow while providing clear interpretations. These insights can aid the development of accurate driving behaviour theory and traffic flow models, ultimately benefiting traffic performance, and potentially leading to aspects such as improved road capacity and safety.
</details>
<details>
<summary>摘要</summary>
当前的驾驶异同识别方法面临着捕捉驾驶特性多样性和从驾驶行为机制角度理解基本模式的挑战。本研究提出了基于Action-chain视角的全面驾驶异同识别框架。首先，我们提出了基于驾驶行为物理含义的规则生成分割技术。然后，基于分割结果，我们创建了驾驶行为模式库，其中包括各种驾驶行为模式的描述。接着，我们引入了Action阶段转移概率，并提出了评估驾驶异同的方法。使用实际数据进行评估，我们的方法能够有效地识别个体驾驶员和交通流动中的驾驶异同，并提供了明确的解释。这些发现可以帮助开发 precisions的驾驶行为理论和交通流动模型，从而提高交通性能，并可能导致改善道路容量和安全性。
</details></li>
</ul>
<hr>
<h2 id="Automated-COVID-19-CT-Image-Classification-using-Multi-head-Channel-Attention-in-Deep-CNN"><a href="#Automated-COVID-19-CT-Image-Classification-using-Multi-head-Channel-Attention-in-Deep-CNN" class="headerlink" title="Automated COVID-19 CT Image Classification using Multi-head Channel Attention in Deep CNN"></a>Automated COVID-19 CT Image Classification using Multi-head Channel Attention in Deep CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00715">http://arxiv.org/abs/2308.00715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Susmita Ghosh, Abhiroop Chatterjee</li>
<li>for: 用于检测COVID-19的计算机断层（CT）扫描图像的自动分类。</li>
<li>methods: 提出了一种基于深度学习的修改Xception模型，增加了通道注意力机制和负重 global average pooling，以提高特征提取。</li>
<li>results: 对广泛使用的COVID-19 CT扫描图像数据集进行实验，实现了非常高的准确率（96.99%），并证明了与其他现有技术相比的优越性。<details>
<summary>Abstract</summary>
The rapid spread of COVID-19 has necessitated efficient and accurate diagnostic methods. Computed Tomography (CT) scan images have emerged as a valuable tool for detecting the disease. In this article, we present a novel deep learning approach for automated COVID-19 CT scan classification where a modified Xception model is proposed which incorporates a newly designed channel attention mechanism and weighted global average pooling to enhance feature extraction thereby improving classification accuracy. The channel attention module selectively focuses on informative regions within each channel, enabling the model to learn discriminative features for COVID-19 detection. Experiments on a widely used COVID-19 CT scan dataset demonstrate a very good accuracy of 96.99% and show its superiority to other state-of-the-art techniques. This research can contribute to the ongoing efforts in using artificial intelligence to combat current and future pandemics and can offer promising and timely solutions for efficient medical image analysis tasks.
</details>
<details>
<summary>摘要</summary>
“快速蔓延的 COVID-19 病毒已经导致了高效和准确的诊断方法的需要。在这篇文章中，我们提出了一种新的深度学习方法，即使用修改过的 Xception 模型，并将 Channel Attention 模块和负重 globally average pooling 组合在一起，以提高特征提取和分类精度。Channel Attention 模块可以选择每个通道中的有用区域，让模型学习检测 COVID-19 的特征。实验结果显示，这种方法可以在一个常用的 COVID-19 CT 扫描数据集上取得非常高的准确率（96.99%），并较以前的州际技术更高。这个研究可以帮助现在和未来的感染病毒战略，并提供可靠的医疗图像分析任务的解决方案。”
</details></li>
</ul>
<hr>
<h2 id="Recent-advancement-in-Disease-Diagnostic-using-machine-learning-Systematic-survey-of-decades-comparisons-and-challenges"><a href="#Recent-advancement-in-Disease-Diagnostic-using-machine-learning-Systematic-survey-of-decades-comparisons-and-challenges" class="headerlink" title="Recent advancement in Disease Diagnostic using machine learning: Systematic survey of decades, comparisons, and challenges"></a>Recent advancement in Disease Diagnostic using machine learning: Systematic survey of decades, comparisons, and challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01319">http://arxiv.org/abs/2308.01319</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farzaneh Tajidini, Mohammad-Javad Kheiri</li>
<li>for: 这篇论文主要关注于计算机支持诊断（CAD）领域的研究，尤其是利用机器学习技术进行疾病检测和诊断。</li>
<li>methods: 该论文使用了多种机器学习算法和技术，包括学习 FROM EXAMPLES 的方法，以提高疾病检测和诊断的精度。</li>
<li>results: 该论文通过对多种疾病的检测和诊断而提出了一些结论，包括肝炎、糖尿病、肝病、登革热和心血管疾病等。<details>
<summary>Abstract</summary>
Computer-aided diagnosis (CAD), a vibrant medical imaging research field, is expanding quickly. Because errors in medical diagnostic systems might lead to seriously misleading medical treatments, major efforts have been made in recent years to improve computer-aided diagnostics applications. The use of machine learning in computer-aided diagnosis is crucial. A simple equation may result in a false indication of items like organs. Therefore, learning from examples is a vital component of pattern recognition. Pattern recognition and machine learning in the biomedical area promise to increase the precision of disease detection and diagnosis. They also support the decision-making process's objectivity. Machine learning provides a practical method for creating elegant and autonomous algorithms to analyze high-dimensional and multimodal bio-medical data. This review article examines machine-learning algorithms for detecting diseases, including hepatitis, diabetes, liver disease, dengue fever, and heart disease. It draws attention to the collection of machine learning techniques and algorithms employed in studying conditions and the ensuing decision-making process.
</details>
<details>
<summary>摘要</summary>
计算机支持诊断（CAD）是医疗影像研究领域的一个热门领域，在最近几年内快速扩大。由于医疗诊断系统中的错误可能会导致严重的医疗诊断错误，因此在最近几年中，大量的努力已经被投入到了计算机支持诊断应用程序的改进中。使用机器学习在计算机支持诊断中是非常重要的。一个简单的方程可能会导致识别物体如器官的错误指示。因此，学习示例是生成模式识别的重要组成部分。生物医学领域中的模式识别和机器学习技术承诺可以提高疾病检测和诊断的精度。它们还支持决策过程的公正性。机器学习提供了一种实用的方法来分析高维和多Modal生物医学数据。本文回顾了用于检测疾病的机器学习算法，包括肝炎、糖尿病、肝病、登革热和心脏病。它吸引注意力于计算机学习技术和算法在研究疾病 Condition 和 subsequent 决策过程中所使用的集合。
</details></li>
</ul>
<hr>
<h2 id="Getting-from-Generative-AI-to-Trustworthy-AI-What-LLMs-might-learn-from-Cyc"><a href="#Getting-from-Generative-AI-to-Trustworthy-AI-What-LLMs-might-learn-from-Cyc" class="headerlink" title="Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc"></a>Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04445">http://arxiv.org/abs/2308.04445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doug Lenat, Gary Marcus</li>
<li>For: The paper discusses the limitations of current AI approaches, particularly large language models (LLMs), and outlines a vision for a more trustworthy and interpretable AI system that incorporates explicit knowledge and rules of thumb.* Methods: The paper proposes an alternative approach to AI that combines the strengths of LLMs with the reasoning capabilities of symbolic AI systems, using a hybrid approach that integrates both types of systems.* Results: The paper describes the development of an AI system called Cyc that is able to reason in higher order logic in real time, and suggests that a hybrid approach that combines LLMs and symbolic AI systems may be necessary for creating a truly trustworthy and interpretable AI system.<details>
<summary>Abstract</summary>
Generative AI, the most popular current approach to AI, consists of large language models (LLMs) that are trained to produce outputs that are plausible, but not necessarily correct. Although their abilities are often uncanny, they are lacking in aspects of reasoning, leading LLMs to be less than completely trustworthy. Furthermore, their results tend to be both unpredictable and uninterpretable.   We lay out 16 desiderata for future AI, and discuss an alternative approach to AI which could theoretically address many of the limitations associated with current approaches: AI educated with curated pieces of explicit knowledge and rules of thumb, enabling an inference engine to automatically deduce the logical entailments of all that knowledge. Even long arguments produced this way can be both trustworthy and interpretable, since the full step-by-step line of reasoning is always available, and for each step the provenance of the knowledge used can be documented and audited. There is however a catch: if the logical language is expressive enough to fully represent the meaning of anything we can say in English, then the inference engine runs much too slowly. That's why symbolic AI systems typically settle for some fast but much less expressive logic, such as knowledge graphs. We describe how one AI system, Cyc, has developed ways to overcome that tradeoff and is able to reason in higher order logic in real time.   We suggest that any trustworthy general AI will need to hybridize the approaches, the LLM approach and more formal approach, and lay out a path to realizing that dream.
</details>
<details>
<summary>摘要</summary>
现代人工智能的主流方法是生成AI，它们通过大量语言模型（LLM）训练来生成可能性强的输出，但并不一定是正确的。尽管其能力往往很强大，但它们缺乏分析能力，导致它们不够可靠。此外，它们的结果往往难以预测和解释。我们提出了16个未来人工智能的需求，并讨论了一种可能解决现有方法的限制的方法：通过手动筛选和规则的知识和规则，使推理引擎自动推理出所有知识的逻辑推论。这种方法可以生成可靠和可解释的长Arguments，因为整个步骤的逻辑推理的步骤都可以通过，并且每一步的知识使用的来源可以被文档和审核。然而，存在一个catch：如果逻辑语言足够表达任何我们可以在英语中说出的意思，那么推理引擎就会太慢。因此，符号AI系统通常选择一些快速而且较为不完整的逻辑，如知识图。我们描述了一个AI系统——Cyc，如何超越这个负担，在实时中进行高阶逻辑推理。我们建议任何可靠的通用AI都需要混合这两种方法，并走出实现这一梦想的路径。
</details></li>
</ul>
<hr>
<h2 id="Changes-in-Policy-Preferences-in-German-Tweets-during-the-COVID-Pandemic"><a href="#Changes-in-Policy-Preferences-in-German-Tweets-during-the-COVID-Pandemic" class="headerlink" title="Changes in Policy Preferences in German Tweets during the COVID Pandemic"></a>Changes in Policy Preferences in German Tweets during the COVID Pandemic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04444">http://arxiv.org/abs/2308.04444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felix Biessmann</li>
<li>for: 这项研究的目的是自动提取在社交媒体上的政治偏好，以便更好地理解在线社交媒体中政治意见的表达方式。</li>
<li>methods: 该研究使用了一个新的 tweet 数据集，其中每个 tweet 都有细化的政治偏好标注。一种基于这个数据集的文本分类模型，然后应用于德国 Twitter 词汇库中的 tweet，从2019年到2022年。</li>
<li>results: 研究发现，在面对 COVID 疫情的情况下，人们对政治意见的表达增加了。通过使用一个已知的政策偏好分类法，分析了政治意见的细化分类，并发现表达政治意见的类别主要为 про-福利、 pro-教育和 pro-政府管理效率。<details>
<summary>Abstract</summary>
Online social media have become an important forum for exchanging political opinions. In response to COVID measures citizens expressed their policy preferences directly on these platforms. Quantifying political preferences in online social media remains challenging: The vast amount of content requires scalable automated extraction of political preferences -- however fine grained political preference extraction is difficult with current machine learning (ML) technology, due to the lack of data sets. Here we present a novel data set of tweets with fine grained political preference annotations. A text classification model trained on this data is used to extract policy preferences in a German Twitter corpus ranging from 2019 to 2022. Our results indicate that in response to the COVID pandemic, expression of political opinions increased. Using a well established taxonomy of policy preferences we analyse fine grained political views and highlight changes in distinct political categories. These analyses suggest that the increase in policy preference expression is dominated by the categories pro-welfare, pro-education and pro-governmental administration efficiency. All training data and code used in this study are made publicly available to encourage other researchers to further improve automated policy preference extraction methods. We hope that our findings contribute to a better understanding of political statements in online social media and to a better assessment of how COVID measures impact political preferences.
</details>
<details>
<summary>摘要</summary>
在线社交媒体已成为政治意见交换的重要平台。对于COVID措施，公民直接在这些平台上表达了政策偏好。但量化在线社交媒体中政治偏好的问题仍然具有挑战性：庞大的内容需要扫描式自动提取政治偏好，但现有机器学习技术的精度不够，因为数据集的缺乏。我们现在发布了一个新的推文数据集，其中每个推文都有细化的政治偏好标注。我们使用这些数据来训练文本分类模型，并在2019-2022年德国推文资源中提取政策偏好。我们的结果表明，在COVID疫情之后，政治意见的表达增加了。使用已确立的政策偏好分类法，我们分析了细化的政治观点，并发现COVID措施的影响。我们发现，政策偏好表达的增加主要来自“优化卫生保障”、“优化教育”和“提高政府管理效率”等类别。我们将所有训练数据和代码公开发布，以便其他研究人员可以继续改进自动政策偏好提取方法。我们希望我们的发现可以帮助更好地理解在线社交媒体中的政治声明，并为COVID措施的影响进行更好的评估。
</details></li>
</ul>
<hr>
<h2 id="Structural-Transfer-Learning-in-NL-to-Bash-Semantic-Parsers"><a href="#Structural-Transfer-Learning-in-NL-to-Bash-Semantic-Parsers" class="headerlink" title="Structural Transfer Learning in NL-to-Bash Semantic Parsers"></a>Structural Transfer Learning in NL-to-Bash Semantic Parsers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16795">http://arxiv.org/abs/2307.16795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyle Duffy, Satwik Bhattamishra, Phil Blunsom</li>
<li>for: 这篇论文是为了研究大规模预训练在自然语言处理中的进步而写的。</li>
<li>methods: 这篇论文提出了一种方法来获得机器翻译任务结构的量化理解，并应用到自然语言到Bash语义解析任务（NLBash）中。</li>
<li>results: 研究发现，NLBash大多可以归结为字幕对应，并且发现了自然语言到SQL之间的强大结构重叠。此外，通过在英语到德语翻译任务中不同计算资源的调整，研究发现更多的计算资源不总是导致更强的 semantic representations 的传递到 NLBash。<details>
<summary>Abstract</summary>
Large-scale pre-training has made progress in many fields of natural language processing, though little is understood about the design of pre-training datasets. We propose a methodology for obtaining a quantitative understanding of structural overlap between machine translation tasks. We apply our methodology to the natural language to Bash semantic parsing task (NLBash) and show that it is largely reducible to lexical alignment. We also find that there is strong structural overlap between NLBash and natural language to SQL. Additionally, we perform a study varying compute expended during pre-training on the English to German machine translation task and find that more compute expended during pre-training does not always correspond semantic representations with stronger transfer to NLBash.
</details>
<details>
<summary>摘要</summary>
大规模的预训练已经在自然语言处理多个领域进步了很 far,  pero little is understood about the design of pre-training datasets. We propose a methodology for obtaining a quantitative understanding of structural overlap between machine translation tasks. We apply our methodology to the natural language to Bash semantic parsing task (NLBash) and show that it is largely reducible to lexical alignment. We also find that there is strong structural overlap between NLBash and natural language to SQL. Additionally, we perform a study varying compute expended during pre-training on the English to German machine translation task and find that more compute expended during pre-training does not always correspond to stronger transfer to NLBash.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the given text and may not be perfect, as the meaning of the text may be slightly different in Chinese.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/01/cs.LG_2023_08_01/" data-id="clpxp6c3a00pgee88aiemd11h" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/01/eess.IV_2023_08_01/" class="article-date">
  <time datetime="2023-08-01T09:00:00.000Z" itemprop="datePublished">2023-08-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/01/eess.IV_2023_08_01/">eess.IV - 2023-08-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Lab-in-a-Tube-A-portable-imaging-spectrophotometer-for-cost-effective-high-throughput-and-label-free-analysis-of-centrifugation-processes"><a href="#Lab-in-a-Tube-A-portable-imaging-spectrophotometer-for-cost-effective-high-throughput-and-label-free-analysis-of-centrifugation-processes" class="headerlink" title="Lab-in-a-Tube: A portable imaging spectrophotometer for cost-effective, high-throughput, and label-free analysis of centrifugation processes"></a>Lab-in-a-Tube: A portable imaging spectrophotometer for cost-effective, high-throughput, and label-free analysis of centrifugation processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03777">http://arxiv.org/abs/2308.03777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanyuan Wei, Dehua Hu, Bijie Bai, Chenqi Meng, Tsz Kin Chan, Xing Zhao, Yuye Wang, Yi-Ping Ho, Wu Yuan, Ho-Pui Ho</li>
<li>for: 这个论文主要旨在为现代实验科学中的样本处理任务提供更高效的实时观察方法。</li>
<li>methods: 该论文使用了一种创新的Lab_in_a_Tube imaging spectrophotometer，具有实时图像分析和可编程中断功能。这个低于30美元的PORTABLE LIAT设备包含Wi Fi摄像头和活动关闭控制。</li>
<li>results: 该研究通过实验观察了在中心陀风中的单个粒子动态过程，并提供了实时数据图表。这是首次观察到类似现象。研究还发展了基于旋转参照framereference frame的理论模拟，与实验结果吻合良好。此外，研究还实现了第一次观察血液凝固过程的视觉化。<details>
<summary>Abstract</summary>
Centrifuges serve as essential instruments in modern experimental sciences, facilitating a wide range of routine sample processing tasks that necessitate material sedimentation. However, the study for real time observation of the dynamical process during centrifugation has remained elusive. In this study, we developed an innovative Lab_in_a_Tube imaging spectrophotometer that incorporates capabilities of real time image analysis and programmable interruption. This portable LIAT device costs less than 30 US dollars. Based on our knowledge, it is the first Wi Fi camera built_in in common lab centrifuges with active closed_loop control. We tested our LIAT imaging spectrophotometer with solute solvent interaction investigation obtained from lab centrifuges with quantitative data plotting in a real time manner. Single re circulating flow was real time observed, forming the ring shaped pattern during centrifugation. To the best of our knowledge, this is the very first observation of similar phenomena. We developed theoretical simulations for the single particle in a rotating reference frame, which correlated well with experimental results. We also demonstrated the first demonstration to visualize the blood sedimentation process in clinical lab centrifuges. This remarkable cost effectiveness opens up exciting opportunities for centrifugation microbiology research and paves the way for the creation of a network of computational imaging spectrometers at an affordable price for large scale and continuous monitoring of centrifugal processes in general.
</details>
<details>
<summary>摘要</summary>
优化的中心分离器在现代实验科学中扮演着重要的 instrumente 作用，为各种实验样品处理任务提供了一系列的标准化程序。然而，实时观察中心分离过程中的动态过程的研究仍然是一个挑战。本研究中，我们开发了一种创新的 Lab_in_a_Tube 成像спектрофотометр，它 integrate了实时图像分析和可编程中断功能。这个可以在30美元以下的PORTABLE LIAT设备中实现。据我们所知，这是首个在通用实验室中心分离器上 integrate了Wi Fi摄像头和活动封闭控制的设备。我们使用LIAT成像спектрофотомет器测试了各种溶剂与溶解物之间的反应，并在实时方式提供了数据图表。在中心分离过程中，实时观察到单个回流形成了环形模式。我们认为这是首次观察到类似现象。我们还开发了基于旋转参照框架的理论模拟，与实验结果高度相关。此外，我们还实现了首次visualize血液凝固过程的示例。这种可负担的成本开发了一个便宜的计算成像спектрофотомет器网络，为大规模和不间断的中心分离过程监测创造了可能性。
</details></li>
</ul>
<hr>
<h2 id="PressureTransferNet-Human-Attribute-Guided-Dynamic-Ground-Pressure-Profile-Transfer-using-3D-simulated-Pressure-Maps"><a href="#PressureTransferNet-Human-Attribute-Guided-Dynamic-Ground-Pressure-Profile-Transfer-using-3D-simulated-Pressure-Maps" class="headerlink" title="PressureTransferNet: Human Attribute Guided Dynamic Ground Pressure Profile Transfer using 3D simulated Pressure Maps"></a>PressureTransferNet: Human Attribute Guided Dynamic Ground Pressure Profile Transfer using 3D simulated Pressure Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00538">http://arxiv.org/abs/2308.00538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lala Shakti Swarup Ray, Vitor Fortes Rey, Bo Zhou, Sungho Suh, Paul Lukowicz</li>
<li>for: 用于人体活动识别（HAR）领域，使用地面压力信息。</li>
<li>methods: 利用现有的压力数据，生成特定活动的体Specific动态地面压力profile。PressureTransferNet是一个encoder-decoder模型，输入源压力图和目标人类特征向量，输出新的压力图表示目标特征。</li>
<li>results: 通过使用感知 simulateulator创建多种人类特征和压力 profiles的数据集，并在实际世界数据集上进行评估，得到了准确地传递人类特征到地面压力 profiles的效果。通过物理学深度学习模型进行验证，并在物理压力检测数据上达到了0.79的二元R-square值和0.911$\pm$0.015的F1分数，证明了生成的压力图的正确性。<details>
<summary>Abstract</summary>
We propose PressureTransferNet, a novel method for Human Activity Recognition (HAR) using ground pressure information. Our approach generates body-specific dynamic ground pressure profiles for specific activities by leveraging existing pressure data from different individuals. PressureTransferNet is an encoder-decoder model taking a source pressure map and a target human attribute vector as inputs, producing a new pressure map reflecting the target attribute. To train the model, we use a sensor simulation to create a diverse dataset with various human attributes and pressure profiles. Evaluation on a real-world dataset shows its effectiveness in accurately transferring human attributes to ground pressure profiles across different scenarios. We visually confirm the fidelity of the synthesized pressure shapes using a physics-based deep learning model and achieve a binary R-square value of 0.79 on areas with ground contact. Validation through classification with F1 score (0.911$\pm$0.015) on physical pressure mat data demonstrates the correctness of the synthesized pressure maps, making our method valuable for data augmentation, denoising, sensor simulation, and anomaly detection. Applications span sports science, rehabilitation, and bio-mechanics, contributing to the development of HAR systems.
</details>
<details>
<summary>摘要</summary>
我们提出了PressureTransferNet，一种新的人体活动识别（HAR）方法，使用地面压力信息。我们的方法生成了特定活动的人体特有的动态地面压力轨迹，通过利用不同个体的压力数据。PressureTransferNet是一个Encoder-Decoder模型，接受来源压力地图和目标人类特征向量作为输入，生成一个新的压力地图，表现出目标特征。为了训练模型，我们使用了一种感器模拟，创建了具有不同人类特征和压力轨迹的多样化数据集。我们通过对真实数据进行评估，发现PressureTransferNet能够准确地将人类特征传递到地面压力轨迹中，并在不同场景下进行高精度的人体活动识别。我们通过使用物理学习模型进行视觉验证，并在物理压力检测数据上达到了0.79的二元共亮值，证明了生成的压力地图的正确性。我们还通过物理压力检测数据进行分类，并达到了0.911$\pm$0.015的F1分数，证明了生成的压力地图的正确性，使得我们的方法在数据增强、干扰除、感器模拟和异常检测等方面都可以获得极大的价值。应用范围包括体育科学、rehabilitation和生物机器人学，对人体活动识别系统的发展做出了贡献。
</details></li>
</ul>
<hr>
<h2 id="Visual-attention-information-can-be-traced-on-cortical-response-but-not-on-the-retina-evidence-from-electrophysiological-mouse-data-using-natural-images-as-stimuli"><a href="#Visual-attention-information-can-be-traced-on-cortical-response-but-not-on-the-retina-evidence-from-electrophysiological-mouse-data-using-natural-images-as-stimuli" class="headerlink" title="Visual attention information can be traced on cortical response but not on the retina: evidence from electrophysiological mouse data using natural images as stimuli"></a>Visual attention information can be traced on cortical response but not on the retina: evidence from electrophysiological mouse data using natural images as stimuli</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00526">http://arxiv.org/abs/2308.00526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikos Melanitis, Konstantina Nikita</li>
<li>for: 这个研究探讨了视觉注意力的生物基础。</li>
<li>methods: 研究者使用计算机方法研究了视觉注意力的生物基础，分析了鼠脑和眼球电生物数据。</li>
<li>results: 研究发现，在主视受器皮层（V1）中，约10%的神经元响应不同于突出性视觉区域。视觉注意力信息不在视网膜响应中追踪，retina似乎不知道视觉注意力信息。<details>
<summary>Abstract</summary>
Visual attention forms the basis of understanding the visual world. In this work we follow a computational approach to investigate the biological basis of visual attention. We analyze retinal and cortical electrophysiological data from mouse. Visual Stimuli are Natural Images depicting real world scenes. Our results show that in primary visual cortex (V1), a subset of around $10\%$ of the neurons responds differently to salient versus non-salient visual regions. Visual attention information was not traced in retinal response. It appears that the retina remains naive concerning visual attention; cortical response gets modulated to interpret visual attention information. Experimental animal studies may be designed to further explore the biological basis of visual attention we traced in this study. In applied and translational science, our study contributes to the design of improved visual prostheses systems -- systems that create artificial visual percepts to visually impaired individuals by electronic implants placed on either the retina or the cortex.
</details>
<details>
<summary>摘要</summary>
Visual attention是视觉世界理解的基础。在这项工作中，我们采用计算方法研究生物基础知识的视觉注意力。我们分析了鼠脊椎细胞电physiological数据，使用自然图像作为视觉刺激。我们的结果表明，在主视觉层（V1）中，约10%的神经元与突出性视觉区域不同响应。视觉注意力信息没有在视网膜响应中追踪。这表明视网膜对视觉注意力信息是无知的， cortical响应则被修饰以解析视觉注意力信息。我们可以通过进一步的动物实验来深入探索我们在这项研究中跟踪到的生物基础知识。在应用和翻译科学方面，我们的研究对于设计更好的视觉代做系统做出了贡献——这些系统通过电子导体在视网膜或大脑中引入人工视觉感受。
</details></li>
</ul>
<hr>
<h2 id="Robust-Spatiotemporal-Fusion-of-Satellite-Images-A-Constrained-Convex-Optimization-Approach"><a href="#Robust-Spatiotemporal-Fusion-of-Satellite-Images-A-Constrained-Convex-Optimization-Approach" class="headerlink" title="Robust Spatiotemporal Fusion of Satellite Images: A Constrained Convex Optimization Approach"></a>Robust Spatiotemporal Fusion of Satellite Images: A Constrained Convex Optimization Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00500">http://arxiv.org/abs/2308.00500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryosuke Isono, Kazuki Naganuma, Shunsuke Ono</li>
<li>for: 提出了一种新的卫星图像空间时间融合框架（ROSTF），用于解决卫星图像的分辨率VS时间的负担问题。</li>
<li>methods: 我们使用了一种新的卫星图像融合方法，称为ROSTF，它可以减少噪声的影响，并提高卫星图像的分辨率。</li>
<li>results: 我们的实验结果表明，ROSTF可以与其他State-of-the-art ST融合方法相比，在噪声情况下表现更好，并且在噪声较高的情况下表现更出色。<details>
<summary>Abstract</summary>
This paper proposes a novel spatiotemporal (ST) fusion framework for satellite images, named Robust Optimization-based Spatiotemporal Fusion (ROSTF). ST fusion is a promising approach to resolve a trade-off between the temporal and spatial resolution of satellite images. Although many ST fusion methods have been proposed, most of them are not designed to explicitly account for noise in observed images, despite the inevitable influence of noise caused by the measurement equipment and environment. Our ROSTF addresses this challenge by treating the noise removal of the observed images and the estimation of the target high-resolution image as a single optimization problem. Specifically, first, we define observation models for satellite images possibly contaminated with random noise, outliers, and/or missing values, and then introduce certain assumptions that would naturally hold between the observed images and the target high-resolution image. Then, based on these models and assumptions, we formulate the fusion problem as a constrained optimization problem and develop an efficient algorithm based on a preconditioned primal-dual splitting method for solving the problem. The performance of ROSTF was verified using simulated and real data. The results show that ROSTF performs comparably to several state-of-the-art ST fusion methods in noiseless cases and outperforms them in noisy cases.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文提出了一种新的协调空间时间（ST）融合框架，称为Robust Optimization-based Spatiotemporal Fusion（ROSTF）。ST融合是一种有前途的方法，可以解决遥感图像的时空分解问题。虽然许多ST融合方法已经被提出，但大多数它们并不直接考虑观测图像中的噪声，即由测量设备和环境所引起的噪声。我们的ROSTF正是为了解决这个挑战，它将观测图像中的噪声除除和目标高分辨率图像的估计作为一个单一的优化问题进行处理。具体来说，我们首先定义了可能受到随机噪声、外围值和/或 missing value 的遥感图像的观测模型，然后引入了一些自然地存在于观测图像和目标高分辨率图像之间的假设。然后，根据这些模型和假设，我们将融合问题转化为一个受限的优化问题，并开发了一种高效的幂等分解法来解决问题。我们对ROSTF的性能进行了验证，使用了模拟和实际数据。结果表明，ROSTF在噪声不存在的情况下与一些状态先进的ST融合方法相当，在噪声存在的情况下表现更出色。
</details></li>
</ul>
<hr>
<h2 id="An-L2-Normalized-Spatial-Attention-Network-For-Accurate-And-Fast-Classification-Of-Brain-Tumors-In-2D-T1-Weighted-CE-MRI-Images"><a href="#An-L2-Normalized-Spatial-Attention-Network-For-Accurate-And-Fast-Classification-Of-Brain-Tumors-In-2D-T1-Weighted-CE-MRI-Images" class="headerlink" title="An L2-Normalized Spatial Attention Network For Accurate And Fast Classification Of Brain Tumors In 2D T1-Weighted CE-MRI Images"></a>An L2-Normalized Spatial Attention Network For Accurate And Fast Classification Of Brain Tumors In 2D T1-Weighted CE-MRI Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00491">http://arxiv.org/abs/2308.00491</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juliadietlmeier/mri_image_classification">https://github.com/juliadietlmeier/mri_image_classification</a></li>
<li>paper_authors: Grace Billingsley, Julia Dietlmeier, Vivek Narayanaswamy, Andreas Spanias, Noel E. OConnor</li>
<li>for: 这个研究是为了开发一个精确且快速的脑动脉摄影像分类网络，以提高现有的轻量级方法的精度。</li>
<li>methods: 我们使用了一种具有l2-normalized spatial attention的分类网络，以避免训练时的过滤。我们与现有的State-of-the-art方法进行比较，结果显示我们的模型在这个2D T1-weighted CE-MRI数据集上的表现较好，增加了1.79%的精度。</li>
<li>results: 我们的模型在这个数据集上的表现比现有的State-of-the-art方法更好，增加了1.79%的精度。组合我们的模型与预训的VGG16可以实现更高的精度，但是会增加执行速度的成本。我们的代码可以在<a target="_blank" rel="noopener" href="https://github.com/juliadietlmeier/MRI_image_classification%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/juliadietlmeier/MRI_image_classification上获取。</a><details>
<summary>Abstract</summary>
We propose an accurate and fast classification network for classification of brain tumors in MRI images that outperforms all lightweight methods investigated in terms of accuracy. We test our model on a challenging 2D T1-weighted CE-MRI dataset containing three types of brain tumors: Meningioma, Glioma and Pituitary. We introduce an l2-normalized spatial attention mechanism that acts as a regularizer against overfitting during training. We compare our results against the state-of-the-art on this dataset and show that by integrating l2-normalized spatial attention into a baseline network we achieve a performance gain of 1.79 percentage points. Even better accuracy can be attained by combining our model in an ensemble with the pretrained VGG16 at the expense of execution speed. Our code is publicly available at https://github.com/juliadietlmeier/MRI_image_classification
</details>
<details>
<summary>摘要</summary>
我们提出一种精度快速的分类网络，用于分类MRI图像中的脑肿瘤，超过所有轻量级方法的准确性。我们在一个具有三种脑肿瘤（膜肿瘤、 Glioma 和丘脑）的2D T1束缚CE-MRI数据集上进行测试。我们引入l2正则化的空间注意力机制，以防止过拟合训练期间。我们与现状的最佳方法进行比较，并显示在将l2正则化空间注意力integrated into a baseline network时，得到了1.79个百分点的性能提升。可以通过将我们的模型与预训练的VGG16 ensemble来获得更高的准确性，但是这将导致执行速度下降。我们的代码在https://github.com/juliadietlmeier/MRI_image_classification上公开。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Learning-Approach-for-Virtual-Contrast-Enhancement-in-Contrast-Enhanced-Spectral-Mammography"><a href="#A-Deep-Learning-Approach-for-Virtual-Contrast-Enhancement-in-Contrast-Enhanced-Spectral-Mammography" class="headerlink" title="A Deep Learning Approach for Virtual Contrast Enhancement in Contrast Enhanced Spectral Mammography"></a>A Deep Learning Approach for Virtual Contrast Enhancement in Contrast Enhanced Spectral Mammography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00471">http://arxiv.org/abs/2308.00471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aurora Rofena, Valerio Guarrasi, Marina Sarli, Claudia Lucia Piccolo, Matteo Sammarra, Bruno Beomonte Zobel, Paolo Soda</li>
<li>for: 这个研究旨在使用深度生成模型来实现CESM中的虚拟对照增强，以提高诊断精度并减少辐射剂量。</li>
<li>methods: 这个研究使用了深度生成模型，包括自适应网络和两个生成对抗网络（Pix2Pix和CycleGAN），将低能量图像转换为虚拟重组图像。</li>
<li>results: 研究结果显示，CycleGAN是最有前途的深度网络，可以实现高质量的虚拟重组图像生成。这项研究的结果还表明，使用虚拟对照增强可以提高CESM的诊断精度，同时减少辐射剂量。<details>
<summary>Abstract</summary>
Contrast Enhanced Spectral Mammography (CESM) is a dual-energy mammographic imaging technique that first needs intravenously administration of an iodinated contrast medium; then, it collects both a low-energy image, comparable to standard mammography, and a high-energy image. The two scans are then combined to get a recombined image showing contrast enhancement. Despite CESM diagnostic advantages for breast cancer diagnosis, the use of contrast medium can cause side effects, and CESM also beams patients with a higher radiation dose compared to standard mammography. To address these limitations this work proposes to use deep generative models for virtual contrast enhancement on CESM, aiming to make the CESM contrast-free as well as to reduce the radiation dose. Our deep networks, consisting of an autoencoder and two Generative Adversarial Networks, the Pix2Pix, and the CycleGAN, generate synthetic recombined images solely from low-energy images. We perform an extensive quantitative and qualitative analysis of the model's performance, also exploiting radiologists' assessments, on a novel CESM dataset that includes 1138 images that, as a further contribution of this work, we make publicly available. The results show that CycleGAN is the most promising deep network to generate synthetic recombined images, highlighting the potential of artificial intelligence techniques for virtual contrast enhancement in this field.
</details>
<details>
<summary>摘要</summary>
增强型pectral маммографи（CESM）是一种双能量мамографи���图像技术，需要通过Intravenously administering an iodinated contrast medium，然后收集低能量图像和高能量图像。然后将两个扫描结果组合起来，得到增强图像。 DESPITE CESM的诊断优势，使用contrast medium可能会导致side effects，并且CESM也会对病人辐射更高的辐射剂量 compared to standard mammography。为了解决这些限制，本工作提出使用深度生成模型对CESM进行虚拟增强，以实现无contrast和降低辐射剂量。我们的深度网络包括一个自适应网络和两个生成对抗网络，Pix2Pix和CycleGAN，可以将低能量图像转换为增强图像。我们对 novel CESM dataset中的1138张图像进行了广泛的量化和质量分析，并利用了 radiologists的评估，以评估模型的性能。结果显示CycleGAN是最有前途的深度网络，highlighting the potential of artificial intelligence techniques for virtual contrast enhancement in this field。
</details></li>
</ul>
<hr>
<h2 id="Space-Debris-Are-Deep-Learning-based-Image-Enhancements-part-of-the-Solution"><a href="#Space-Debris-Are-Deep-Learning-based-Image-Enhancements-part-of-the-Solution" class="headerlink" title="Space Debris: Are Deep Learning-based Image Enhancements part of the Solution?"></a>Space Debris: Are Deep Learning-based Image Enhancements part of the Solution?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00408">http://arxiv.org/abs/2308.00408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michele Jamrozik, Vincent Gaudillière, Mohamed Adel Musallam, Djamila Aouada</li>
<li>for: 这个研究的目的是确定深度神经网络（DNN）是否能够在视觉光谱下解决单一摄像头所产生的影像问题，并且跨越各种影像损坏。</li>
<li>methods: 这个研究使用了一个混合的UNet-ResNet34深度学习（DL）架构，这个架构在ImageNet dataset上进行预训。它能够处理各种影像损坏，包括模糊、曝光问题、低比例和噪音。</li>
<li>results: 根据视觉检查，这个UNet模型能够正确地更正在太空中拍摄的影像损坏，并且与现有的深度学习图像改善方法进行比较。<details>
<summary>Abstract</summary>
The volume of space debris currently orbiting the Earth is reaching an unsustainable level at an accelerated pace. The detection, tracking, identification, and differentiation between orbit-defined, registered spacecraft, and rogue/inactive space ``objects'', is critical to asset protection. The primary objective of this work is to investigate the validity of Deep Neural Network (DNN) solutions to overcome the limitations and image artefacts most prevalent when captured with monocular cameras in the visible light spectrum. In this work, a hybrid UNet-ResNet34 Deep Learning (DL) architecture pre-trained on the ImageNet dataset, is developed. Image degradations addressed include blurring, exposure issues, poor contrast, and noise. The shortage of space-generated data suitable for supervised DL is also addressed. A visual comparison between the URes34P model developed in this work and the existing state of the art in deep learning image enhancement methods, relevant to images captured in space, is presented. Based upon visual inspection, it is determined that our UNet model is capable of correcting for space-related image degradations and merits further investigation to reduce its computational complexity.
</details>
<details>
<summary>摘要</summary>
Currently, the volume of space debris orbiting the Earth is reaching an unsustainable level at an accelerated pace. The detection, tracking, identification, and differentiation between orbit-defined, registered spacecraft and rogue/inactive space "objects" are critical to asset protection. The primary objective of this work is to investigate the validity of Deep Neural Network (DNN) solutions to overcome the limitations and image artifacts most prevalent when captured with monocular cameras in the visible light spectrum. In this work, a hybrid UNet-ResNet34 Deep Learning (DL) architecture pre-trained on the ImageNet dataset is developed. Image degradations addressed include blurring, exposure issues, poor contrast, and noise. The shortage of space-generated data suitable for supervised DL is also addressed. A visual comparison between the URes34P model developed in this work and the existing state of the art in deep learning image enhancement methods, relevant to images captured in space, is presented. Based on visual inspection, it is determined that our UNet model is capable of correcting for space-related image degradations and merits further investigation to reduce its computational complexity.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Metrics-to-Quantify-Global-Consistency-in-Synthetic-Medical-Images"><a href="#Metrics-to-Quantify-Global-Consistency-in-Synthetic-Medical-Images" class="headerlink" title="Metrics to Quantify Global Consistency in Synthetic Medical Images"></a>Metrics to Quantify Global Consistency in Synthetic Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00402">http://arxiv.org/abs/2308.00402</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Scholz, Benedikt Wiestler, Daniel Rueckert, Martin J. Menten</li>
<li>for: 这个论文是为了提高医学图像处理领域中的图像生成技术，例如数据增强或多Modalities图像翻译。</li>
<li>methods: 这个论文使用了基于神经网络的自动学习方法，包括使用supervised和unsupervised trained neural networks来评估图像的全局一致性。</li>
<li>results: 这个论文的结果表明，可以使用这些方法来分类图像的全局一致性，并且这些方法可以在没有标注数据时仍然有效。相比之下，已有的metric，如FID，无法直接评估图像的全局一致性。<details>
<summary>Abstract</summary>
Image synthesis is increasingly being adopted in medical image processing, for example for data augmentation or inter-modality image translation. In these critical applications, the generated images must fulfill a high standard of biological correctness. A particular requirement for these images is global consistency, i.e an image being overall coherent and structured so that all parts of the image fit together in a realistic and meaningful way. Yet, established image quality metrics do not explicitly quantify this property of synthetic images. In this work, we introduce two metrics that can measure the global consistency of synthetic images on a per-image basis. To measure the global consistency, we presume that a realistic image exhibits consistent properties, e.g., a person's body fat in a whole-body MRI, throughout the depicted object or scene. Hence, we quantify global consistency by predicting and comparing explicit attributes of images on patches using supervised trained neural networks. Next, we adapt this strategy to an unlabeled setting by measuring the similarity of implicit image features predicted by a self-supervised trained network. Our results demonstrate that predicting explicit attributes of synthetic images on patches can distinguish globally consistent from inconsistent images. Implicit representations of images are less sensitive to assess global consistency but are still serviceable when labeled data is unavailable. Compared to established metrics, such as the FID, our method can explicitly measure global consistency on a per-image basis, enabling a dedicated analysis of the biological plausibility of single synthetic images.
</details>
<details>
<summary>摘要</summary>
医疗图像处理领域内，图像合成技术在不断普及，例如数据增强或多Modalities图像翻译。在这些关键应用中，生成的图像必须满足高水平的生物准确性。特别是，生成图像必须具备全局一致性，即图像整体准确、结构化，所有图像部分都必须在真实和意义上相互协调。然而，现有的图像质量指标不直接量化这种图像的全局一致性。在这项工作中，我们介绍了两种可以测量生成图像的全局一致性的指标。为了测量全局一致性，我们假设一个真实的图像都具备一致的属性，例如整个人体MRI中的身体脂肪。因此，我们量化全局一致性通过使用已经超参的神经网络预测和比较图像中的显式属性。接下来，我们将这种策略应用到无标注 Setting中，通过测量图像中的隐藏特征来衡量图像的全局一致性。我们的结果表明，预测图像中的显式属性可以分辨全局一致的和不一致的图像。隐藏的图像特征也可以用无标注的方式来衡量图像的全局一致性，尽管它们比较敏感于数据质量。相比之下，已有的指标，如FID，不直接量化全局一致性，但可以量化图像的整体质量。我们的方法可以在每个图像基础上 direktly测量全局一致性，从而允许专门分析单个生成图像的生物可能性。
</details></li>
</ul>
<hr>
<h2 id="Fundus-Enhanced-Disease-Aware-Distillation-Model-for-Retinal-Disease-Classification-from-OCT-Images"><a href="#Fundus-Enhanced-Disease-Aware-Distillation-Model-for-Retinal-Disease-Classification-from-OCT-Images" class="headerlink" title="Fundus-Enhanced Disease-Aware Distillation Model for Retinal Disease Classification from OCT Images"></a>Fundus-Enhanced Disease-Aware Distillation Model for Retinal Disease Classification from OCT Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00291">http://arxiv.org/abs/2308.00291</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xmed-lab/fddm">https://github.com/xmed-lab/fddm</a></li>
<li>paper_authors: Lehan Wang, Weihang Dai, Mei Jin, Chubin Ou, Xiaomeng Li</li>
<li>for:  This paper proposes a novel method for retinal disease classification from OCT images, which can be used for ophthalmic examination.</li>
<li>methods:  The proposed method uses a fundus-enhanced disease-aware distillation model (FDDM) that utilizes unpaired fundus images during training and does not require the use of fundus images during testing. The method enhances the OCT model by distilling disease-related information from the fundus model and aligning class similarity between both modalities.</li>
<li>results:  The proposed approach outperforms single-modal, multi-modal, and state-of-the-art distillation methods for retinal disease classification, demonstrating its effectiveness and practicality for clinical use.<details>
<summary>Abstract</summary>
Optical Coherence Tomography (OCT) is a novel and effective screening tool for ophthalmic examination. Since collecting OCT images is relatively more expensive than fundus photographs, existing methods use multi-modal learning to complement limited OCT data with additional context from fundus images. However, the multi-modal framework requires eye-paired datasets of both modalities, which is impractical for clinical use. To address this problem, we propose a novel fundus-enhanced disease-aware distillation model (FDDM), for retinal disease classification from OCT images. Our framework enhances the OCT model during training by utilizing unpaired fundus images and does not require the use of fundus images during testing, which greatly improves the practicality and efficiency of our method for clinical use. Specifically, we propose a novel class prototype matching to distill disease-related information from the fundus model to the OCT model and a novel class similarity alignment to enforce consistency between disease distribution of both modalities. Experimental results show that our proposed approach outperforms single-modal, multi-modal, and state-of-the-art distillation methods for retinal disease classification. Code is available at https://github.com/xmed-lab/FDDM.
</details>
<details>
<summary>摘要</summary>
优化净合成 Tomatoes (OCT) 是一种新型和有效的诊断工具 для眼科检查。由于收集 OCT 图像相对较 expensive than fundus 图像，现有方法使用多模态学习来补充 OCT 数据中的有限资源。然而，多模态框架需要对 modalities 的眼球对应数据集，这是在临床应用中不实际。为解决这个问题，我们提出了一种新的眼球增强疾病感知模型 (FDDM)，用于从 OCT 图像中分类眼球疾病。我们的框架在训练时使用无对应的眼球图像来增强 OCT 模型，并不需要在测试时使用眼球图像，这大大提高了我们的方法在临床应用中的实用性和效率。具体来说，我们提出了一种新的类型 prototype matching，以填充疾病相关信息从眼球模型到 OCT 模型，以及一种新的类型相似性对齐，以保持两个模式之间的疾病分布的一致性。实验结果表明，我们的提议方法在眼球疾病分类任务上超越单模、多模和状态更新的混合方法。代码可以在 https://github.com/xmed-lab/FDDM 上获取。
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Self-Supervised-Image-Denoising-A-Comprehensive-Review"><a href="#Unleashing-the-Power-of-Self-Supervised-Image-Denoising-A-Comprehensive-Review" class="headerlink" title="Unleashing the Power of Self-Supervised Image Denoising: A Comprehensive Review"></a>Unleashing the Power of Self-Supervised Image Denoising: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00247">http://arxiv.org/abs/2308.00247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Zhang, Fangfang Zhou, Yuanzhou Wei, Xiao Yang, Yuan Gu</li>
<li>for: 本论文探讨了自主学习图像减震技术的最新进展，旨在解决现实世界中获取噪声清晰对的困难问题。</li>
<li>methods: 本文分类了自主学习图像减震方法为三类：通用方法、BSN基于方法和 transformer 基于方法，并对每一类进行了 theoretically 分析和实践应用。</li>
<li>results: 本文通过对多个数据集进行量化和质量测试，证明了这些方法的效iveness，并提供了对照经典算法的比较。<details>
<summary>Abstract</summary>
The advent of deep learning has brought a revolutionary transformation to image denoising techniques. However, the persistent challenge of acquiring noise-clean pairs for supervised methods in real-world scenarios remains formidable, necessitating the exploration of more practical self-supervised image denoising. This paper focuses on self-supervised image denoising methods that offer effective solutions to address this challenge. Our comprehensive review thoroughly analyzes the latest advancements in self-supervised image denoising approaches, categorizing them into three distinct classes: General methods, Blind Spot Network (BSN)-based methods, and Transformer-based methods. For each class, we provide a concise theoretical analysis along with their practical applications. To assess the effectiveness of these methods, we present both quantitative and qualitative experimental results on various datasets, utilizing classical algorithms as benchmarks. Additionally, we critically discuss the current limitations of these methods and propose promising directions for future research. By offering a detailed overview of recent developments in self-supervised image denoising, this review serves as an invaluable resource for researchers and practitioners in the field, facilitating a deeper understanding of this emerging domain and inspiring further advancements.
</details>
<details>
<summary>摘要</summary>
deep learning技术的出现对图像噪声处理方法带来了革命性的变革，但在实际场景中获得噪声清晰对照样本的困难仍然存在，需要更加实用的自我监督图像噪声处理方法。这篇评论文探讨了最新的自我监督图像噪声处理方法，将其分为三类：通用方法、BSN基于方法和Transformer基于方法。对于每种类型，我们提供了简洁的理论分析以及实际应用。为评估这些方法的效果，我们在不同的数据集上进行了量化和质量上的实验，使用经典算法作为参考。此外，我们还进行了深入的限制分析和未来研究的探讨。通过对最新的自我监督图像噪声处理方法的详细审视，这篇评论文将成为图像处理领域的一个不可或缺的资源，为研究人员和实践者提供深入的理解和发展新技术的动力。
</details></li>
</ul>
<hr>
<h2 id="Boundary-Difference-Over-Union-Loss-For-Medical-Image-Segmentation"><a href="#Boundary-Difference-Over-Union-Loss-For-Medical-Image-Segmentation" class="headerlink" title="Boundary Difference Over Union Loss For Medical Image Segmentation"></a>Boundary Difference Over Union Loss For Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00220">http://arxiv.org/abs/2308.00220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sunfan-bvb/boundarydouloss">https://github.com/sunfan-bvb/boundarydouloss</a></li>
<li>paper_authors: Fan Sun, Zhiming Luo, Shaozi Li</li>
<li>for: 这篇论文是为了提出一个简单而有效的医疗影像分类损失函数，以帮助医疗影像分类 tasks 中的边界区域分类。</li>
<li>methods: 这篇论文使用了一个新的损失函数，即边界差集测试损失函数 (Boundary DoU Loss)，并且使用了一个适应边界区域的焦点调整方法。</li>
<li>results: 在两个 dataset (ACDC 和 Synapse) 上进行了实验，结果显示了这个提案的有效性，并且与其他损失函数相比，这个损失函数更能帮助边界区域分类。<details>
<summary>Abstract</summary>
Medical image segmentation is crucial for clinical diagnosis. However, current losses for medical image segmentation mainly focus on overall segmentation results, with fewer losses proposed to guide boundary segmentation. Those that do exist often need to be used in combination with other losses and produce ineffective results. To address this issue, we have developed a simple and effective loss called the Boundary Difference over Union Loss (Boundary DoU Loss) to guide boundary region segmentation. It is obtained by calculating the ratio of the difference set of prediction and ground truth to the union of the difference set and the partial intersection set. Our loss only relies on region calculation, making it easy to implement and training stable without needing any additional losses. Additionally, we use the target size to adaptively adjust attention applied to the boundary regions. Experimental results using UNet, TransUNet, and Swin-UNet on two datasets (ACDC and Synapse) demonstrate the effectiveness of our proposed loss function. Code is available at https://github.com/sunfan-bvb/BoundaryDoULoss.
</details>
<details>
<summary>摘要</summary>
医学图像分割是诊断的关键。然而，当前的医学图像分割损失主要关注总体分割结果，有 fewer 的损失用于指导边界分割。这些损失通常需要与其他损失结合使用，并且生成不具有效果的结果。为解决这个问题，我们开发了一种简单而有效的损失函数：Boundary Difference over Union Loss（Boundary DoU Loss），用于导航边界区域分割。它是通过计算预测和真实值的差集与联合集的差集和部分交集集的比率来获得的。我们的损失函数仅仅依赖于区域计算，因此易于实现和训练，不需要其他损失函数。此外，我们使用目标大小来适应性地调整边界区域的注意力。实验结果使用 UNet、TransUNet 和 Swin-UNet 在 ACDC 和 Synapse 两个 dataset 上表明了我们提出的损失函数的有效性。代码可以在 https://github.com/sunfan-bvb/BoundaryDoULoss 上获取。
</details></li>
</ul>
<hr>
<h2 id="Universal-Adversarial-Defense-in-Remote-Sensing-Based-on-Pre-trained-Denoising-Diffusion-Models"><a href="#Universal-Adversarial-Defense-in-Remote-Sensing-Based-on-Pre-trained-Denoising-Diffusion-Models" class="headerlink" title="Universal Adversarial Defense in Remote Sensing Based on Pre-trained Denoising Diffusion Models"></a>Universal Adversarial Defense in Remote Sensing Based on Pre-trained Denoising Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16865">http://arxiv.org/abs/2307.16865</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/EricYu97/UAD-RS">https://github.com/EricYu97/UAD-RS</a></li>
<li>paper_authors: Weikang Yu, Yonghao Xu, Pedram Ghamisi<br>for:这个论文是为了提出一种基于扩散模型的通用防御方法，以防止深度神经网络受到攻击。methods:这个方法使用了预训练的扩散模型来防止多种未知攻击，并使用了反向和前向的扩散过程来纯化攻击样本。此外，还使用了自适应噪声水平选择（ANLS）机制来选择最佳的噪声水平，以达到最佳的纯化结果。results:实验结果表明，UAD-RS方法可以高效地防止多种常见攻击，并且不需要对攻击样本有严格的先知知识。此外，UAD-RS方法也可以减少重新训练的成本和性能的波动。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have achieved tremendous success in many remote sensing (RS) applications, in which DNNs are vulnerable to adversarial perturbations. Unfortunately, current adversarial defense approaches in RS studies usually suffer from performance fluctuation and unnecessary re-training costs due to the need for prior knowledge of the adversarial perturbations among RS data. To circumvent these challenges, we propose a universal adversarial defense approach in RS imagery (UAD-RS) using pre-trained diffusion models to defend the common DNNs against multiple unknown adversarial attacks. Specifically, the generative diffusion models are first pre-trained on different RS datasets to learn generalized representations in various data domains. After that, a universal adversarial purification framework is developed using the forward and reverse process of the pre-trained diffusion models to purify the perturbations from adversarial samples. Furthermore, an adaptive noise level selection (ANLS) mechanism is built to capture the optimal noise level of the diffusion model that can achieve the best purification results closest to the clean samples according to their Frechet Inception Distance (FID) in deep feature space. As a result, only a single pre-trained diffusion model is needed for the universal purification of adversarial samples on each dataset, which significantly alleviates the re-training efforts and maintains high performance without prior knowledge of the adversarial perturbations. Experiments on four heterogeneous RS datasets regarding scene classification and semantic segmentation verify that UAD-RS outperforms state-of-the-art adversarial purification approaches with a universal defense against seven commonly existing adversarial perturbations. Codes and the pre-trained models are available online (https://github.com/EricYu97/UAD-RS).
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）在远程感知应用中取得了很大的成功，但是DNNs受到了恶意抗干扰的威胁。然而，现有的抗恶意防御策略在RS研究中通常受到性能波动和无需重新训练成本的限制，因为需要对RS数据有丰富的前知ledge。为了缓解这些挑战，我们提议一种通用的抗恶意防御策略（UAD-RS），使用预训练的扩散模型来防御通用DNNs Against多种未知的恶意抗干扰。具体来说，首先预训练了不同的RS数据集上的扩散模型，以学习各种数据域中的通用表示。然后，我们开发了一种通用抗恶意纯化框架，使用扩散模型的前进和返回过程来纯化恶意样本中的抗干扰。此外，我们还构建了一种适应性的噪声水平选择（ANLS）机制，以捕捉最佳的噪声水平，以达到最佳的纯化结果，与clean样本之间的Frechet InceptionDistance（FID）在深度特征空间最近。因此，只需要一个预训练的扩散模型，可以通用地纯化恶意样本在每个数据集上，大大减少了重新训练的努力，并保持高性能无需对恶意抗干扰有丰富的前知ledge。实验表明，UAD-RS在四个不同的RS数据集上的Scene classification和semantic segmentation任务上表现出了状态的抗恶意纯化方法。代码和预训练模型可以在线获取（https://github.com/EricYu97/UAD-RS）。
</details></li>
</ul>
<hr>
<h2 id="A-comprehensive-review-of-deep-learning-in-lung-cancer"><a href="#A-comprehensive-review-of-deep-learning-in-lung-cancer" class="headerlink" title="A comprehensive review of deep learning in lung cancer"></a>A comprehensive review of deep learning in lung cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02528">http://arxiv.org/abs/2308.02528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farzane Tajidini</li>
<li>for: 提供历史性见解于肿瘤诊断方法</li>
<li>methods: 讨论肿瘤诊断过程和常用的诊断方法</li>
<li>results: 现有诊断方法不够有效，需要新的更智能方法<details>
<summary>Abstract</summary>
To provide the reader with a historical perspective on cancer classification approaches, we first discuss the fundamentals of the area of cancer diagnosis in this article, including the processes of cancer diagnosis and the standard classification methods employed by clinicians. Current methods for cancer diagnosis are deemed ineffective, calling for new and more intelligent approaches.
</details>
<details>
<summary>摘要</summary>
为了为读者提供历史背景，我们首先讲述了肿瘤诊断方法的基础知识，包括肿瘤诊断过程和临床医生使用的标准分类方法。现有的肿瘤诊断方法被认为是不具有效果，需要新的更智能的方法。Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="Framing-image-registration-as-a-landmark-detection-problem-for-better-representation-of-clinical-relevance"><a href="#Framing-image-registration-as-a-landmark-detection-problem-for-better-representation-of-clinical-relevance" class="headerlink" title="Framing image registration as a landmark detection problem for better representation of clinical relevance"></a>Framing image registration as a landmark detection problem for better representation of clinical relevance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01318">http://arxiv.org/abs/2308.01318</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diana Waldmannstetter, Benedikt Wiestler, Julian Schwarting, Ivan Ezhov, Marie Metz, Spyridon Bakas, Bhakti Baheti, Satrajit Chakrabarty, Jan S. Kirschke, Rolf A. Heckemann, Marie Piraud, Florian Kofler, Bjoern H. Menze</li>
<li>for: 提高图像 регистрация评价的临床 relevance</li>
<li>methods: 将图像 регистрация视为特征点检测问题，通过计算 hit rate 曲线来基于少量 inter-rater 分析获得特征点检测阈值</li>
<li>results: 提出一种基于错误分布的阈值计算方法，能够区分之前不可区分的 регистрация算法，并且可以评估图像REGISTRAION的临床意义<details>
<summary>Abstract</summary>
Nowadays, registration methods are typically evaluated based on sub-resolution tracking error differences. In an effort to reinfuse this evaluation process with clinical relevance, we propose to reframe image registration as a landmark detection problem. Ideally, landmark-specific detection thresholds are derived from an inter-rater analysis. To approximate this costly process, we propose to compute hit rate curves based on the distribution of errors of a sub-sample inter-rater analysis. Therefore, we suggest deriving thresholds from the error distribution using the formula: median + delta * median absolute deviation. The method promises differentiation of previously indistinguishable registration algorithms and further enables assessing the clinical significance in algorithm development.
</details>
<details>
<summary>摘要</summary>
现在，注册方法通常根据半分解追踪错误的差异进行评估。为了将注册评估过程恢复到临床 relevance，我们提议将注册视为一个标记检测问题。理想情况下，标记特定的检测阈值可以从多个评估者之间的交叉分析中 derivation。为了简化这个贵重过程，我们提议根据一个子样本的评估者分布计算 hit rate 曲线。因此，我们建议使用错误分布中的 median + δ * median absolute deviation 来 derivation 阈值，这种方法可以区分之前无法分辨的注册算法，并且可以评估算法开发中的临床 significancy。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/01/eess.IV_2023_08_01/" data-id="clpxp6cab018fee8828gd0wqf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_07_31" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/31/cs.SD_2023_07_31/" class="article-date">
  <time datetime="2023-07-31T15:00:00.000Z" itemprop="datePublished">2023-07-31</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/31/cs.SD_2023_07_31/">cs.SD - 2023-07-31</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Audio-Visual-Segmentation-by-Exploring-Cross-Modal-Mutual-Semantics"><a href="#Audio-Visual-Segmentation-by-Exploring-Cross-Modal-Mutual-Semantics" class="headerlink" title="Audio-Visual Segmentation by Exploring Cross-Modal Mutual Semantics"></a>Audio-Visual Segmentation by Exploring Cross-Modal Mutual Semantics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16620">http://arxiv.org/abs/2307.16620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Liu, Peike Li, Xingqun Qi, Hu Zhang, Lincheng Li, Dadong Wang, Xin Yu<br>for: This paper focuses on the audio-visual segmentation (AVS) task, which aims to segment sounding objects from a given video.methods: The proposed method first localizes potential sounding objects in a video using an object segmentation network, and then associates the sounding object candidates with the given audio. To alleviate the ambiguity of training the object segmentation network, the method proposes a silent object-aware segmentation objective. Additionally, the method explores the audio-visual semantic correlation by attending predicted audio category scores to potential instance masks.results: The proposed method can effectively segment sounding objects without being biased to salient objects, as demonstrated by experimental results on the AVS benchmarks.<details>
<summary>Abstract</summary>
The audio-visual segmentation (AVS) task aims to segment sounding objects from a given video. Existing works mainly focus on fusing audio and visual features of a given video to achieve sounding object masks. However, we observed that prior arts are prone to segment a certain salient object in a video regardless of the audio information. This is because sounding objects are often the most salient ones in the AVS dataset. Thus, current AVS methods might fail to localize genuine sounding objects due to the dataset bias. In this work, we present an audio-visual instance-aware segmentation approach to overcome the dataset bias. In a nutshell, our method first localizes potential sounding objects in a video by an object segmentation network, and then associates the sounding object candidates with the given audio. We notice that an object could be a sounding object in one video but a silent one in another video. This would bring ambiguity in training our object segmentation network as only sounding objects have corresponding segmentation masks. We thus propose a silent object-aware segmentation objective to alleviate the ambiguity. Moreover, since the category information of audio is unknown, especially for multiple sounding sources, we propose to explore the audio-visual semantic correlation and then associate audio with potential objects. Specifically, we attend predicted audio category scores to potential instance masks and these scores will highlight corresponding sounding instances while suppressing inaudible ones. When we enforce the attended instance masks to resemble the ground-truth mask, we are able to establish audio-visual semantics correlation. Experimental results on the AVS benchmarks demonstrate that our method can effectively segment sounding objects without being biased to salient objects.
</details>
<details>
<summary>摘要</summary>
audio-visual segmentation（AVS）任务的目标是从视频中分割出声音对象。现有的方法主要是将视频和音频特征融合以获得声音对象面积。然而，我们发现现有的方法很容易将视频中的一些鲜明对象分割成声音对象，这是因为声音对象在AVS数据集中非常鲜明。因此，现有的AVS方法可能会错过真正的声音对象，这是因为数据集偏见。在这种情况下，我们提出了一种带有音频视频实例相关的分割方法，以解决数据集偏见。我们的方法首先在视频中 lokalisiert potential sounding objects的可能性，然后将这些声音对象候选者与给定的音频相关联。我们注意到，一个对象可能是一个声音对象在一个视频中，但是在另一个视频中可能是一个无声对象。这会在我们的对象分割网络训练时引入模糊性。我们因此提出了一种静音对象相关的分割目标，以解决这个问题。此外，由于音频的类别信息未知，特别是多个声音来源，我们提出了探索音频视频 semantic correlation，然后将音频与 potential objects相关联。具体来说，我们将预测的音频类别得分attend to potential instance masks，这些分数会高亮对应的声音实例，而不是无声实例。当我们强制 enforcing these attended instance masks to resemble the ground-truth mask，我们就能够建立音频视频 semantic correlation。我们的方法的实验结果在AVS benchmark中表明，我们可以准确地分割声音对象，不会受到鲜明对象的影响。
</details></li>
</ul>
<hr>
<h2 id="SAMbA-Speech-enhancement-with-Asynchronous-ad-hoc-Microphone-Arrays"><a href="#SAMbA-Speech-enhancement-with-Asynchronous-ad-hoc-Microphone-Arrays" class="headerlink" title="SAMbA: Speech enhancement with Asynchronous ad-hoc Microphone Arrays"></a>SAMbA: Speech enhancement with Asynchronous ad-hoc Microphone Arrays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16582">http://arxiv.org/abs/2307.16582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Furnon, Romain Serizel, Slim Essid, Irina Illina</li>
<li>for: 提高随机麦克风数组中的speech增强，因为麦克风组件中的设备具有不同的采样时间偏移和采样率偏移，这会导致麦克风数组中的采样不同步。</li>
<li>methods: 提出了一种基于深度神经网络（DNN）的随机麦克风数组中的speech增强解决方案，该解决方案是分布式的，可以在不同硬件组件中进行实现，并且可以适应不同的采样时间偏移和采样率偏移。</li>
<li>results: 表明，增强机制可以使得DNNs对不同采样时间偏移和采样率偏移都具有抗随机性的能力，而不需要进行费时的处理步骤来减少偏移的影响。同时，增强机制还可以自动学习出采样时间偏移和采样率偏移的参数，不需要额外的监督。<details>
<summary>Abstract</summary>
Speech enhancement in ad-hoc microphone arrays is often hindered by the asynchronization of the devices composing the microphone array. Asynchronization comes from sampling time offset and sampling rate offset which inevitably occur when the microphones are embedded in different hardware components. In this paper, we propose a deep neural network (DNN)-based speech enhancement solution that is suited for applications in ad-hoc microphone arrays because it is distributed and copes with asynchronization. We show that asynchronization has a limited impact on the spatial filtering and mostly affects the performance of the DNNs. Instead of resynchronising the signals, which requires costly processing steps, we use an attention mechanism which makes the DNNs, thus our whole pipeline, robust to asynchronization. We also show that the attention mechanism leads to the asynchronization parameters in an unsupervised manner.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate english text into simplified chineseSpeech enhancement in ad-hoc microphone arrays is often hindered by the asynchronization of the devices composing the microphone array. Asynchronization comes from sampling time offset and sampling rate offset which inevitably occur when the microphones are embedded in different hardware components. In this paper, we propose a deep neural network (DNN)-based speech enhancement solution that is suited for applications in ad-hoc microphone arrays because it is distributed and copes with asynchronization. We show that asynchronization has a limited impact on the spatial filtering and mostly affects the performance of the DNNs. Instead of resynchronising the signals, which requires costly processing steps, we use an attention mechanism which makes the DNNs, thus our whole pipeline, robust to asynchronization. We also show that the attention mechanism leads to the asynchronization parameters in an unsupervised manner.Translated text in Simplified Chinese:<<SYS>>对话增强在具有不同硬件 ком成分的随意 microphone 阵列中经常受到设备不同的问题，包括抽样时间偏移和抽样率偏移。这些问题无法避免，因为 microphone 通常被嵌入不同的硬件 Component 中。在这篇论文中，我们提出了一个基于深度神经网络（DNN）的对话增强解决方案，这个解决方案适合应用在随意 microphone 阵列中，因为它是分布式的。我们显示，对话增强中的不同设备问题有限的影响，主要影响 DNN 的表现。而不是耗费成本的处理步骤来调整标本，我们使用了注意力机制，使 DNN 和我们的整个管道都具有对不同设备问题的响应性。我们还显示，注意力机制可以自动从数据中提取不同设备问题的参数。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Conditional-Latent-Diffusion-for-Audio-visual-Segmentation"><a href="#Contrastive-Conditional-Latent-Diffusion-for-Audio-visual-Segmentation" class="headerlink" title="Contrastive Conditional Latent Diffusion for Audio-visual Segmentation"></a>Contrastive Conditional Latent Diffusion for Audio-visual Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16579">http://arxiv.org/abs/2307.16579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxin Mao, Jing Zhang, Mochu Xiang, Yunqiu Lv, Yiran Zhong, Yuchao Dai<br>for:This paper proposes a latent diffusion model with contrastive learning for audio-visual segmentation (AVS) to explore the contribution of audio.methods:The proposed method uses a latent diffusion model to learn the conditional generation process of the ground-truth segmentation map, and introduces contrastive learning to learn audio-visual correspondence.results:Experimental results on a benchmark dataset verify the effectiveness of the proposed solution, demonstrating the importance of modeling the correlation between audio and the final segmentation map for AVS.Here’s the simplified Chinese text:for:这篇论文提出了一种基于扩散模型的听视同步分割方法，以探讨听音的贡献。methods:该方法使用扩散模型来学习听音与实际分割地图的关系，并通过对比学习来学习听音和视频之间的对应关系。results:实验结果表明，该方法在标准测试集上具有较高的效果，证明了模型对听音的贡献对AVS的重要性。<details>
<summary>Abstract</summary>
We propose a latent diffusion model with contrastive learning for audio-visual segmentation (AVS) to extensively explore the contribution of audio. We interpret AVS as a conditional generation task, where audio is defined as the conditional variable for sound producer(s) segmentation. With our new interpretation, it is especially necessary to model the correlation between audio and the final segmentation map to ensure its contribution. We introduce a latent diffusion model to our framework to achieve semantic-correlated representation learning. Specifically, our diffusion model learns the conditional generation process of the ground-truth segmentation map, leading to ground-truth aware inference when we perform the denoising process at the test stage. As a conditional diffusion model, we argue it is essential to ensure that the conditional variable contributes to model output. We then introduce contrastive learning to our framework to learn audio-visual correspondence, which is proven consistent with maximizing the mutual information between model prediction and the audio data. In this way, our latent diffusion model via contrastive learning explicitly maximizes the contribution of audio for AVS. Experimental results on the benchmark dataset verify the effectiveness of our solution. Code and results are online via our project page: https://github.com/OpenNLPLab/DiffusionAVS.
</details>
<details>
<summary>摘要</summary>
我们提出一种含拓扑扩散模型，通过对比学习来探索音频的贡献。我们将音频视为条件变量，用于音频生成者 segmentation。为保证音频的贡献，我们引入一种潜在扩散模型，以实现含义相关的表示学习。这种扩散模型学习了真实的分 segmentation MAP 的生成过程，从而在测试阶段实现了真实感知。作为一种条件扩散模型，我们认为保证条件变量对模型输出的贡献是必要的。我们然后引入对比学习，以学习音频视频对应关系，这与最大化模型预测和音频数据之间的共通信息相符。通过这种方式，我们的含拓扩散模型通过对比学习显著地提高了音频对 AVS 的贡献。实验结果表明我们的解决方案是有效的。代码和结果在我们项目页面上可以online获取：https://github.com/OpenNLPLab/DiffusionAVS。
</details></li>
</ul>
<hr>
<h2 id="DiffProsody-Diffusion-based-Latent-Prosody-Generation-for-Expressive-Speech-Synthesis-with-Prosody-Conditional-Adversarial-Training"><a href="#DiffProsody-Diffusion-based-Latent-Prosody-Generation-for-Expressive-Speech-Synthesis-with-Prosody-Conditional-Adversarial-Training" class="headerlink" title="DiffProsody: Diffusion-based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training"></a>DiffProsody: Diffusion-based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16549">http://arxiv.org/abs/2307.16549</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hsoh0306/diffprosody">https://github.com/hsoh0306/diffprosody</a></li>
<li>paper_authors: Hyung-Seok Oh, Sang-Hoon Lee, Seong-Whan Lee</li>
<li>for: 这个论文的目的是提出一种基于扩散模型的干扰式表达系统，以提高表达系统的效果和速度。</li>
<li>methods: 这个论文使用了一种名为DiffProsody的新方法，该方法利用扩散基于的干扰式 latent prosody generator 和 prosody conditional adversarial training，以生成更加自然的表达。</li>
<li>results: 实验表明，DiffProsody 能够在16倍的速度上生成表达，并且对比传统方法，具有更高的质量和效果。<details>
<summary>Abstract</summary>
Expressive text-to-speech systems have undergone significant advancements owing to prosody modeling, but conventional methods can still be improved. Traditional approaches have relied on the autoregressive method to predict the quantized prosody vector; however, it suffers from the issues of long-term dependency and slow inference. This study proposes a novel approach called DiffProsody in which expressive speech is synthesized using a diffusion-based latent prosody generator and prosody conditional adversarial training. Our findings confirm the effectiveness of our prosody generator in generating a prosody vector. Furthermore, our prosody conditional discriminator significantly improves the quality of the generated speech by accurately emulating prosody. We use denoising diffusion generative adversarial networks to improve the prosody generation speed. Consequently, DiffProsody is capable of generating prosody 16 times faster than the conventional diffusion model. The superior performance of our proposed method has been demonstrated via experiments.
</details>
<details>
<summary>摘要</summary>
<<SYS>>expressive 文本到语音系统已经经历了显著的进步，归功于谱定模型。但传统方法仍然可以进行改进。传统的方法通过推导式方法预测谱定向量，但它受到长期依赖和慢速推理的问题困扰。本研究提出了一种新的方法 called DiffProsody，该方法通过噪声推送生成器和谱定 conditional adversarial training来生成表达性的语音。我们的发现表明DiffProsody可以生成谱定向量。此外，我们的谱定 conditional 推理器可以准确地模拟谱定，从而提高生成的语音质量。我们使用denoising diffusion生成 adversarial networks来提高谱定生成速度。因此，DiffProsody可以在16倍 faster than conventional diffusion model中生成谱定。我们的提出的方法在实验中表现出了superior performance。Note: Please note that the translation is in Simplified Chinese, and some words or phrases may have been translated differently in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="SpatialNet-Extensively-Learning-Spatial-Information-for-Multichannel-Joint-Speech-Separation-Denoising-and-Dereverberation"><a href="#SpatialNet-Extensively-Learning-Spatial-Information-for-Multichannel-Joint-Speech-Separation-Denoising-and-Dereverberation" class="headerlink" title="SpatialNet: Extensively Learning Spatial Information for Multichannel Joint Speech Separation, Denoising and Dereverberation"></a>SpatialNet: Extensively Learning Spatial Information for Multichannel Joint Speech Separation, Denoising and Dereverberation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16516">http://arxiv.org/abs/2307.16516</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/audio-westlakeu/nbss">https://github.com/audio-westlakeu/nbss</a></li>
<li>paper_authors: Changsheng Quan, Xiaofei Li</li>
<li>for: 提出了一种基于神经网络的多通道共同音频分离、减阈和去抖振荡方法，名为SpatialNet。</li>
<li>methods: 在短时傅里叶变换（STFT）域内，提议的网络实现了端到端的音频提升。网络主要由交叠式窄频和十字频块组成，分别利用窄频和十字频的空间信息。窄频块独立处理频率，使用自注意机制和时间卷积层来分别进行空间特征基本的说话人团集和时间平滑&#x2F;滤波。十字频块独立处理帧，使用全频线性层和频谱卷积层来分别学习所有频率和邻近频率之间的相关性。</li>
<li>results: 对多个模拟和实际数据集进行了实验，结果表明：1) 提议的网络在大多数任务上达到了状态艺术的性能; 2) 提议的网络受到spectral generalization问题的影响很小; 3) 提议的网络确实进行了说话人团集（示例了注意力地图）。<details>
<summary>Abstract</summary>
This work proposes a neural network to extensively exploit spatial information for multichannel joint speech separation, denoising and dereverberation, named SpatialNet.In the short-time Fourier transform (STFT) domain, the proposed network performs end-to-end speech enhancement. It is mainly composed of interleaved narrow-band and cross-band blocks to respectively exploit narrow-band and cross-band spatial information. The narrow-band blocks process frequencies independently, and use self-attention mechanism and temporal convolutional layers to respectively perform spatial-feature-based speaker clustering and temporal smoothing/filtering. The cross-band blocks processes frames independently, and use full-band linear layer and frequency convolutional layers to respectively learn the correlation between all frequencies and adjacent frequencies. Experiments are conducted on various simulated and real datasets, and the results show that 1) the proposed network achieves the state-of-the-art performance on almost all tasks; 2) the proposed network suffers little from the spectral generalization problem; and 3) the proposed network is indeed performing speaker clustering (demonstrated by attention maps).
</details>
<details>
<summary>摘要</summary>
这个工作提出了一种神经网络，以便广泛利用空间信息进行多通道联合语音分离、降噪和反射减去，名为空间网络（SpatialNet）。在短时傅立叶变换（STFT）频域内，提议的网络实现了端到端语音提升。它主要由相互交叠的窄频和交叠频块组成，用于分别利用窄频和交叠频信息。窄频块独立处理频率，使用自注意机制和时间径向层来分别进行空间特征基于的Speaker集成和时间平滑/滤波。交叠频块独立处理帧，使用全频线性层和频率径向层来分别学习所有频率和邻近频率之间的相关性。在各种模拟和实际数据集上进行了实验，结果表明：1）提议的网络在大多数任务上达到了状态艺术性的表现；2）提议的网络受到尺度泛化问题的影响很少；3）提议的网络实际进行Speaker集成（通过注意力地图进行证明）。
</details></li>
</ul>
<hr>
<h2 id="LP-MusicCaps-LLM-Based-Pseudo-Music-Captioning"><a href="#LP-MusicCaps-LLM-Based-Pseudo-Music-Captioning" class="headerlink" title="LP-MusicCaps: LLM-Based Pseudo Music Captioning"></a>LP-MusicCaps: LLM-Based Pseudo Music Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16372">http://arxiv.org/abs/2307.16372</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/seungheondoh/lp-music-caps">https://github.com/seungheondoh/lp-music-caps</a></li>
<li>paper_authors: SeungHeon Doh, Keunwoo Choi, Jongpil Lee, Juhan Nam</li>
<li>for: 提高音乐数据的理解和管理，提供大规模音乐描述语料集。</li>
<li>methods: 使用大语言模型（LLM）人工生成描述句子，从大规模标签数据集中获取数据。</li>
<li>results: 比较多种评价指标和人工评价表明，提posed方法比基线模型有更好的表现，并在零VB和传输学习 Setting下进行了训练和评价。<details>
<summary>Abstract</summary>
Automatic music captioning, which generates natural language descriptions for given music tracks, holds significant potential for enhancing the understanding and organization of large volumes of musical data. Despite its importance, researchers face challenges due to the costly and time-consuming collection process of existing music-language datasets, which are limited in size. To address this data scarcity issue, we propose the use of large language models (LLMs) to artificially generate the description sentences from large-scale tag datasets. This results in approximately 2.2M captions paired with 0.5M audio clips. We term it Large Language Model based Pseudo music caption dataset, shortly, LP-MusicCaps. We conduct a systemic evaluation of the large-scale music captioning dataset with various quantitative evaluation metrics used in the field of natural language processing as well as human evaluation. In addition, we trained a transformer-based music captioning model with the dataset and evaluated it under zero-shot and transfer-learning settings. The results demonstrate that our proposed approach outperforms the supervised baseline model.
</details>
<details>
<summary>摘要</summary>
自动化音乐描述（Automatic music captioning）可以增强大量音乐数据的理解和组织。尽管其重要性，研究人员面临数据缺乏问题，因为现有的音乐语言数据集的收集过程很费时和成本高。为解决这个数据缺乏问题，我们提议使用大型自然语言模型（LLM）来人工生成描述句子从大规模标签数据集。这将生成约220万个描述句子和50万个音频剪辑。我们称之为大语言模型基于 Pseudo music caption 数据集（LP-MusicCaps）。我们进行了音乐描述数据集的系统评估，使用了自然语言处理领域常用的量化评估 метри。此外，我们将一种基于 transformer 的音乐描述模型训练于数据集，并在零学习和转移学习 Settings 下评估其性能。结果表明，我们的提议方法在超越了基线模型。
</details></li>
</ul>
<hr>
<h2 id="Mispronunciation-detection-using-self-supervised-speech-representations"><a href="#Mispronunciation-detection-using-self-supervised-speech-representations" class="headerlink" title="Mispronunciation detection using self-supervised speech representations"></a>Mispronunciation detection using self-supervised speech representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16324">http://arxiv.org/abs/2307.16324</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JazminVidal/ssl-mispron">https://github.com/JazminVidal/ssl-mispron</a></li>
<li>paper_authors: Jazmin Vidal, Pablo Riera, Luciana Ferrer</li>
<li>for: 本研究使用自动学习模型对非本地语言学习者的发音识别进行了研究，以提高发音识别的精度。</li>
<li>methods: 本研究使用了两种下游方法：1）使用本地英语数据进行话音识别（PR）模型的训练，2）直接使用非本地英语数据进行目标任务的模型训练。另外，本研究还比较了不同的SSL表示法和传统DNN speech recognition模型中的表示法的性能。</li>
<li>results: 研究发现，使用直接进行目标任务的模型训练得到最佳性能，而大多数上游模型在该任务中的性能相似。<details>
<summary>Abstract</summary>
In recent years, self-supervised learning (SSL) models have produced promising results in a variety of speech-processing tasks, especially in contexts of data scarcity. In this paper, we study the use of SSL models for the task of mispronunciation detection for second language learners. We compare two downstream approaches: 1) training the model for phone recognition (PR) using native English data, and 2) training a model directly for the target task using non-native English data. We compare the performance of these two approaches for various SSL representations as well as a representation extracted from a traditional DNN-based speech recognition model. We evaluate the models on L2Arctic and EpaDB, two datasets of non-native speech annotated with pronunciation labels at the phone level. Overall, we find that using a downstream model trained for the target task gives the best performance and that most upstream models perform similarly for the task.
</details>
<details>
<summary>摘要</summary>
近年来，自主学习（SSL）模型在各种语音处理任务中表现出色，特别在数据缺乏的情况下。在这篇论文中，我们研究了在第二语言学习者中的误听检测任务上使用SSL模型。我们比较了两个下游方法：1）使用本地英语数据来训练模型，并2）直接使用非本地英语数据来训练目标任务的模型。我们对各种SSL表示形式以及一个来自传统的DNN基于语音识别模型中的表示进行比较。我们在L2Arctic和EpaDB两个非本地语音Dataset上评估了这些模型的性能。总的来说，我们发现使用直接训练目标任务的下游模型可以获得最好的性能，而大多数上游模型在这个任务上表现相似。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/31/cs.SD_2023_07_31/" data-id="clpxp6c6000x8ee8837yx2aap" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_07_31" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/31/eess.AS_2023_07_31/" class="article-date">
  <time datetime="2023-07-31T14:00:00.000Z" itemprop="datePublished">2023-07-31</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/31/eess.AS_2023_07_31/">eess.AS - 2023-07-31</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Multilingual-context-based-pronunciation-learning-for-Text-to-Speech"><a href="#Multilingual-context-based-pronunciation-learning-for-Text-to-Speech" class="headerlink" title="Multilingual context-based pronunciation learning for Text-to-Speech"></a>Multilingual context-based pronunciation learning for Text-to-Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16709">http://arxiv.org/abs/2307.16709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giulia Comini, Manuel Sam Ribeiro, Fan Yang, Heereen Shim, Jaime Lorenzo-Trueba<br>for: 这个论文的目的是提出一个多语言统一的前端系统，用于解决语音识别相关的任务，通常由不同模块处理。methods: 该论文使用的方法包括Grapheme-to-Phoneme关系的预测和语言特定的规则系统，以解决语音识别中的homograph和多音字识别、后缀规则和隐式 диакритизацию问题。results: 该论文的实验结果显示，该多语言统一前端系统在不同语言和任务上具有竞争力，但有一些与等效的单语言解决方案进行比较时的交易。<details>
<summary>Abstract</summary>
Phonetic information and linguistic knowledge are an essential component of a Text-to-speech (TTS) front-end. Given a language, a lexicon can be collected offline and Grapheme-to-Phoneme (G2P) relationships are usually modeled in order to predict the pronunciation for out-of-vocabulary (OOV) words. Additionally, post-lexical phonology, often defined in the form of rule-based systems, is used to correct pronunciation within or between words. In this work we showcase a multilingual unified front-end system that addresses any pronunciation related task, typically handled by separate modules. We evaluate the proposed model on G2P conversion and other language-specific challenges, such as homograph and polyphones disambiguation, post-lexical rules and implicit diacritization. We find that the multilingual model is competitive across languages and tasks, however, some trade-offs exists when compared to equivalent monolingual solutions.
</details>
<details>
<summary>摘要</summary>
phonetic information和语言知识是texttospeech（TTS）前端的重要组成部分。给定一种语言，一个词典可以在线上采集，并且用grapheme-to-phoneme（G2P）关系来预测语音读法 для未在词汇中出现的词语（OOV words）。此外，在词语之间或在词语中进行phonology修正还需要使用post-lexical规则。在这项工作中，我们展示了一个多语言统一前端系统，可以解决任何语音相关的任务，通常由 separatemodules 处理。我们评估了提议的模型在G2P转换和其他语言特有的挑战中的性能，包括homograph和多音字的歧义、post-lexical规则和隐式 diacritization。我们发现该多语言模型在语言和任务方面都具有竞争力，但是存在一些与等效单语言解决方案相比存在的交换。
</details></li>
</ul>
<hr>
<h2 id="Improving-grapheme-to-phoneme-conversion-by-learning-pronunciations-from-speech-recordings"><a href="#Improving-grapheme-to-phoneme-conversion-by-learning-pronunciations-from-speech-recordings" class="headerlink" title="Improving grapheme-to-phoneme conversion by learning pronunciations from speech recordings"></a>Improving grapheme-to-phoneme conversion by learning pronunciations from speech recordings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16643">http://arxiv.org/abs/2307.16643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manuel Sam Ribeiro, Giulia Comini, Jaime Lorenzo-Trueba</li>
<li>for: 提高 Grapheme-to-Phoneme (G2P) 转换任务的准确率，使得文本到语音和语音识别等应用更加有效。</li>
<li>methods: 利用音频记录学习 pronunciation 示例来改进 G2P 转换任务，并使用多语言的 phone recognition 系统来decode 语音记录。</li>
<li>results: 对于不同语言和数据量，our approach 都能够降低 G2P 系统的 phone error rate，并且可以学习 out-of-vocabulary 单词的拼写规则。<details>
<summary>Abstract</summary>
The Grapheme-to-Phoneme (G2P) task aims to convert orthographic input into a discrete phonetic representation. G2P conversion is beneficial to various speech processing applications, such as text-to-speech and speech recognition. However, these tend to rely on manually-annotated pronunciation dictionaries, which are often time-consuming and costly to acquire. In this paper, we propose a method to improve the G2P conversion task by learning pronunciation examples from audio recordings. Our approach bootstraps a G2P with a small set of annotated examples. The G2P model is used to train a multilingual phone recognition system, which then decodes speech recordings with a phonetic representation. Given hypothesized phoneme labels, we learn pronunciation dictionaries for out-of-vocabulary words, and we use those to re-train the G2P system. Results indicate that our approach consistently improves the phone error rate of G2P systems across languages and amount of available data.
</details>
<details>
<summary>摘要</summary>
“文本转语音”（G2P）任务的目的是将文字转换为不同语言的精确的语音表示。这种转换可以应用于多种语音处理应用程序，例如文本转语音和语音识别。但是，这些应用程序通常需要手动检核的发音词典，这可能需要很长时间和成本。在这篇论文中，我们提出了一种方法来改善G2P转换任务，通过从语音录音中学习发音例子。我们的方法是从一小量标注的示例开始，使用G2P模型训练多种语言的语音识别系统，然后将语音录音转换为精确的语音表示。假设有假设的发音标签，我们可以从这些标签中学习不在词汇中的发音词典，并将它们用于重新训练G2P系统。结果显示，我们的方法可以在不同语言和可用数据量之间帮助G2P系统改善电话误差率。
</details></li>
</ul>
<hr>
<h2 id="All-In-One-Metrical-And-Functional-Structure-Analysis-With-Neighborhood-Attentions-on-Demixed-Audio"><a href="#All-In-One-Metrical-And-Functional-Structure-Analysis-With-Neighborhood-Attentions-on-Demixed-Audio" class="headerlink" title="All-In-One Metrical And Functional Structure Analysis With Neighborhood Attentions on Demixed Audio"></a>All-In-One Metrical And Functional Structure Analysis With Neighborhood Attentions on Demixed Audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16425">http://arxiv.org/abs/2307.16425</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mir-aidj/all-in-one">https://github.com/mir-aidj/all-in-one</a></li>
<li>paper_authors: Taejun Kim, Juhan Nam</li>
<li>for: 本研究旨在提出一种可靠的、一体化的音乐信息检索（MIR）模型，能够同时捕捉乐曲的节奏和下节奏、功能结构 segmentation和标注。</li>
<li>methods: 该模型使用分离的spectrogram作为输入，并利用不同缩放的宽度注意力 capture tempo长期相关性，以及本地乐器相关性。</li>
<li>results: 模型在Harmonix Set上的四个任务中均 achieve state-of-the-art表现，同时具有相对较低的参数数量，而且我们的ablation研究表明，同时学习节奏、下节奏和段落可以提高性能，每个任务彼此互助。<details>
<summary>Abstract</summary>
Music is characterized by complex hierarchical structures. Developing a comprehensive model to capture these structures has been a significant challenge in the field of Music Information Retrieval (MIR). Prior research has mainly focused on addressing individual tasks for specific hierarchical levels, rather than providing a unified approach. In this paper, we introduce a versatile, all-in-one model that jointly performs beat and downbeat tracking as well as functional structure segmentation and labeling. The model leverages source-separated spectrograms as inputs and employs dilated neighborhood attentions to capture temporal long-term dependencies, along with non-dilated attentions for local instrumental dependencies. Consequently, the proposed model achieves state-of-the-art performance in all four tasks on the Harmonix Set while maintaining a relatively lower number of parameters compared to recent state-of-the-art models. Furthermore, our ablation study demonstrates that the concurrent learning of beats, downbeats, and segments can lead to enhanced performance, with each task mutually benefiting from the others.
</details>
<details>
<summary>摘要</summary>
音乐具有复杂的层次结构，在音乐信息检索（MIR）领域建立一个全面的模型是一项重要的挑战。先前的研究主要集中在解决特定层次级别的任务上，而不是提供一个统一的方法。在本文中，我们介绍了一种通用的、全部一个模型，可同时执行节拍和下节拍跟踪、功能结构分割和标注。该模型使用源分离的spectrogram作为输入，利用扩大 neighborgraph attention capture temporal长期关系，并使用非扩大 attention capture当地乐器关系。因此，我们提出的模型在Harmonix Set上的四个任务中均 achieve state-of-the-art性能，同时具有相对较少的参数量 compared to recent state-of-the-art模型。此外，我们的ablation study表明，同时学习节拍、下节拍和分割可以导致提高性能，每个任务受到另外两个任务的帮助。
</details></li>
</ul>
<hr>
<h2 id="Robust-Self-Supervised-Speech-Embeddings-for-Child-Adult-Classification-in-Interactions-involving-Children-with-Autism"><a href="#Robust-Self-Supervised-Speech-Embeddings-for-Child-Adult-Classification-in-Interactions-involving-Children-with-Autism" class="headerlink" title="Robust Self Supervised Speech Embeddings for Child-Adult Classification in Interactions involving Children with Autism"></a>Robust Self Supervised Speech Embeddings for Child-Adult Classification in Interactions involving Children with Autism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16398">http://arxiv.org/abs/2307.16398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rimita Lahiri, Tiantian Feng, Rajat Hebbar, Catherine Lord, So Hyun Kim, Shrikanth Narayanan</li>
<li>for:  automatic child-adult speaker classification in child-inclusive spoken interactions</li>
<li>methods: pre-training with child-inclusive interactions and self-supervision algorithms (Wav2vec 2.0 and WavLM) with a contrastive loss objective</li>
<li>results: 9-13% relative improvement over state-of-the-art baseline in classification F1 scores on two clinical interaction datasets involving children with Autism, with analysis of pre-training under different conditions based on demographic factors.Here’s the text in Simplified Chinese:</li>
<li>for: 自动儿童成人说话分类</li>
<li>methods: 使用儿童包含的交互和自我超级vised算法（Wav2vec 2.0和WavLM），使用对比损失目标进行预训练</li>
<li>results: 在两个临床交互数据集上，与状态艺术基准相比，实现了9-13%的相对提升，并对不同儿童子宫因素进行了分析。<details>
<summary>Abstract</summary>
We address the problem of detecting who spoke when in child-inclusive spoken interactions i.e., automatic child-adult speaker classification. Interactions involving children are richly heterogeneous due to developmental differences. The presence of neurodiversity e.g., due to Autism, contributes additional variability. We investigate the impact of additional pre-training with more unlabelled child speech on the child-adult classification performance. We pre-train our model with child-inclusive interactions, following two recent self-supervision algorithms, Wav2vec 2.0 and WavLM, with a contrastive loss objective. We report 9 - 13% relative improvement over the state-of-the-art baseline with regards to classification F1 scores on two clinical interaction datasets involving children with Autism. We also analyze the impact of pre-training under different conditions by evaluating our model on interactions involving different subgroups of children based on various demographic factors.
</details>
<details>
<summary>摘要</summary>
我们识别了儿童 inclusive 的 spoken interactions 中的发言人问题，即自动儿童成人发言分类。儿童交流中存在较大的多样性，因为儿童的发展差异。另外，由于Autism等神经多样性的存在，会增加发言多样性。我们研究了额外预训练更多的无标签儿童语音对child-adult分类性能的影响。我们采用了两种最新的自我超视图算法，Wav2vec 2.0和WavLM，并使用了对比损失目标函数。我们发现，与状态艺术基eline相比，我们的模型在两个临床交流数据集上的分类 F1 分数有9-13%的相对改善。此外，我们还分析了预训练在不同条件下的影响，通过评估我们的模型在不同子群儿童基于各种民生因素的交流中的表现。
</details></li>
</ul>
<hr>
<h2 id="Pre-training-End-to-end-ASR-Models-with-Augmented-Speech-Samples-Queried-by-Text"><a href="#Pre-training-End-to-end-ASR-Models-with-Augmented-Speech-Samples-Queried-by-Text" class="headerlink" title="Pre-training End-to-end ASR Models with Augmented Speech Samples Queried by Text"></a>Pre-training End-to-end ASR Models with Augmented Speech Samples Queried by Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16332">http://arxiv.org/abs/2307.16332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Sun, Jinyu Li, Jian Xue, Yifan Gong</li>
<li>for: 提高语音识别系统的语言扩展性</li>
<li>methods: 使用无对应的语音特征段和文本数据生成增强样本，无需额外的语音数据</li>
<li>results: 与使用多语言 Raw 语音数据预训练的模型相比，在Italian Transformer 抽取器模型预训练中，使用我们的方法可以获得8.7%的Relative Word Error Rate 降低，并且在与多语言数据合并预训练新模型时，可以获得12.2%的Relative Word Error Rate 降低。<details>
<summary>Abstract</summary>
In end-to-end automatic speech recognition system, one of the difficulties for language expansion is the limited paired speech and text training data. In this paper, we propose a novel method to generate augmented samples with unpaired speech feature segments and text data for model pre-training, which has the advantage of low cost without using additional speech data. When mixing 20,000 hours augmented speech data generated by our method with 12,500 hours original transcribed speech data for Italian Transformer transducer model pre-training, we achieve 8.7% relative word error rate reduction. The pre-trained model achieves similar performance as the model pre-trained with multilingual transcribed 75,000 hours raw speech data. When merging the augmented speech data with the multilingual data to pre-train a new model, we achieve even more relative word error rate reduction of 12.2% over the baseline, which further verifies the effectiveness of our method for speech data augmentation.
</details>
<details>
<summary>摘要</summary>
在端到端自动语音识别系统中，一个问题是扩展语言的困难，因为有限的配对的语音和文本训练数据。在这篇论文中，我们提出了一种新的方法，通过将无配对语音特征段和文本数据混合生成增强样本，以便模型预训练，这种方法的优点是低成本，不需要额外的语音数据。当混合我们生成的20,000小时增强语音数据和12,500小时原始译文数据 для意大陆 transformer 抽取器模型预训练，我们实现了8.7%的相对单词错误率降低。预训练后的模型与使用多语言原始75,000小时Raw语音数据预训练的模型相似的性能。当混合增强语音数据与多语言数据预训练新模型时，我们实现了更多的相对单词错误率降低12.2%，这一 Again verifies the effectiveness of our method for speech data augmentation.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/31/eess.AS_2023_07_31/" data-id="clpxp6c8n0145ee88em8rd2mf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_31" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/31/cs.CV_2023_07_31/" class="article-date">
  <time datetime="2023-07-31T13:00:00.000Z" itemprop="datePublished">2023-07-31</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/31/cs.CV_2023_07_31/">cs.CV - 2023-07-31</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="From-Generation-to-Suppression-Towards-Effective-Irregular-Glow-Removal-for-Nighttime-Visibility-Enhancement"><a href="#From-Generation-to-Suppression-Towards-Effective-Irregular-Glow-Removal-for-Nighttime-Visibility-Enhancement" class="headerlink" title="From Generation to Suppression: Towards Effective Irregular Glow Removal for Nighttime Visibility Enhancement"></a>From Generation to Suppression: Towards Effective Irregular Glow Removal for Nighttime Visibility Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16783">http://arxiv.org/abs/2307.16783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wanyu Wu, Wei Wang, Zheng Wang, Kui Jiang, Xin Xu</li>
<li>for: 提高夜间图像的亮度和透光效果，并解决人工灯光的散射扩散问题</li>
<li>methods: 基于多散射估计和大气点扩散函数（APSF）学习物理散射生成，并在不同灯光强度和源形状下实现扩散灯光抑制</li>
<li>results: 提出了一种可扩展的灯光无知抑制网络（LBDN），并通过灯光抑制后，使用Retinex模块进行增强，实现了低光照图像的提高和灯光抑制任务<details>
<summary>Abstract</summary>
Most existing Low-Light Image Enhancement (LLIE) methods are primarily designed to improve brightness in dark regions, which suffer from severe degradation in nighttime images. However, these methods have limited exploration in another major visibility damage, the glow effects in real night scenes. Glow effects are inevitable in the presence of artificial light sources and cause further diffused blurring when directly enhanced. To settle this issue, we innovatively consider the glow suppression task as learning physical glow generation via multiple scattering estimation according to the Atmospheric Point Spread Function (APSF). In response to the challenges posed by uneven glow intensity and varying source shapes, an APSF-based Nighttime Imaging Model with Near-field Light Sources (NIM-NLS) is specifically derived to design a scalable Light-aware Blind Deconvolution Network (LBDN). The glow-suppressed result is then brightened via a Retinex-based Enhancement Module (REM). Remarkably, the proposed glow suppression method is based on zero-shot learning and does not rely on any paired or unpaired training data. Empirical evaluations demonstrate the effectiveness of the proposed method in both glow suppression and low-light enhancement tasks.
</details>
<details>
<summary>摘要</summary>
现有的低光照图像改进方法主要是提高黑暗区域的亮度，但这些方法受到夜间图像中的耀树效果的限制。耀树效果是人工灯光源的存在导致的，并且会对直接加强的图像进行更多的杂化干扰。为解决这个问题，我们创新地将耀树降低任务作为学习物理耀树生成的多散杂折扣计算，根据大气点 рассеи函数（APSF）。为了应对耀树强度不均和灯光源形状的变化，我们特地 derivate了一种基于APSF的夜间图像模型（NIM-NLS），用于设计可扩展的光照无知抽象网络（LBDN）。经验证表明，我们提出的耀树降低方法不需要任何配对或无配对训练数据，并且在耀树降低和低光照改进任务中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Lightweight-Super-Resolution-Head-for-Human-Pose-Estimation"><a href="#Lightweight-Super-Resolution-Head-for-Human-Pose-Estimation" class="headerlink" title="Lightweight Super-Resolution Head for Human Pose Estimation"></a>Lightweight Super-Resolution Head for Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16765">http://arxiv.org/abs/2307.16765</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haonanwang0522/srpose">https://github.com/haonanwang0522/srpose</a></li>
<li>paper_authors: Haonan Wang, Jie Liu, Jie Tang, Gangshan Wu</li>
<li>for: 该研究旨在解决热图基本方法中的量化错误问题，提高热图 pose estimation 的性能。</li>
<li>methods: 该研究提出了 SR 头，该头可以预测高 resolution 的热图，从而减少量化错误和进一步处理的需求。 SRPose 方法在每个阶段使用 SR 头来慢慢地恢复高 resolution 的热图，并且在每个阶段使用 SR 头来监督中间特征。</li>
<li>results: 对 COCO、MPII 和 CrowdPose 等数据集进行了广泛的实验，显示 SRPose 方法比对应的热图基本方法有更好的性能。<details>
<summary>Abstract</summary>
Heatmap-based methods have become the mainstream method for pose estimation due to their superior performance. However, heatmap-based approaches suffer from significant quantization errors with downscale heatmaps, which result in limited performance and the detrimental effects of intermediate supervision. Previous heatmap-based methods relied heavily on additional post-processing to mitigate quantization errors. Some heatmap-based approaches improve the resolution of feature maps by using multiple costly upsampling layers to improve localization precision. To solve the above issues, we creatively view the backbone network as a degradation process and thus reformulate the heatmap prediction as a Super-Resolution (SR) task. We first propose the SR head, which predicts heatmaps with a spatial resolution higher than the input feature maps (or even consistent with the input image) by super-resolution, to effectively reduce the quantization error and the dependence on further post-processing. Besides, we propose SRPose to gradually recover the HR heatmaps from LR heatmaps and degraded features in a coarse-to-fine manner. To reduce the training difficulty of HR heatmaps, SRPose applies SR heads to supervise the intermediate features in each stage. In addition, the SR head is a lightweight and generic head that applies to top-down and bottom-up methods. Extensive experiments on the COCO, MPII, and CrowdPose datasets show that SRPose outperforms the corresponding heatmap-based approaches. The code and models are available at https://github.com/haonanwang0522/SRPose.
</details>
<details>
<summary>摘要</summary>
对于 pose 估计，热图方法已经成为主流方法，但热图方法受到下测热图的量化误差的限制，导致表现有限和中途监督的副作用。过往的热图方法将重点放在额外处理来减轻量化误差。一些热图方法会将特征图像的分辨率提高，使用多个昂贵的upsampling层来提高本地化精度。为了解决这些问题，我们创新地视Backbone网络为压缩过程，并将热图预测 reformulate 为超解析（SR）任务。我们首先提出SR Head，这个预测热图的数据点高于输入特征图像的分辨率，或者和输入图像的分辨率相同，以便实现量化误差的减少和后期处理的依赖。此外，我们提出SRPose，这个渐进从粗糙到细致的方法，可以从LR热图和受损特征图像中搜寻HR热图。为了降低HR热图的训练困难，SRPose 应用SR Head 来监督每个阶段的中间特征。此外，SR Head 是一个轻量级和通用的头，适用于顶部遍历和底部遍历方法。实验结果显示，SRPose 在 COCO、MPII 和 CrowdPose 数据集上具有较高的表现。代码和模型可以在 <https://github.com/haonanwang0522/SRPose> 获取。
</details></li>
</ul>
<hr>
<h2 id="High-Performance-Fine-Defect-Detection-in-Artificial-Leather-Using-Dual-Feature-Pool-Object-Detection"><a href="#High-Performance-Fine-Defect-Detection-in-Artificial-Leather-Using-Dual-Feature-Pool-Object-Detection" class="headerlink" title="High-Performance Fine Defect Detection in Artificial Leather Using Dual Feature Pool Object Detection"></a>High-Performance Fine Defect Detection in Artificial Leather Using Dual Feature Pool Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16751">http://arxiv.org/abs/2307.16751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Huang, Weisheng Li, Linlin Shen, Xue Xiao, Suihan Xiao</li>
<li>for: 这个研究主要针对论文的精细杂 defect detection task，特别是在人工皮革中精细杂 defect的检测。</li>
<li>methods: 本研究提出了四种新的结构，即DFP、IFF、AMP和EOS，以解决 YOLOv5 模型中的结构问题。</li>
<li>results: YOLOD 模型在人工皮革杂 defect数据集上表现出色，与 YOLOv5 比较而言，AP_50 提高了 11.7% - 13.5%，并同时降低了 5.2% - 7.2% 的错误检测率。在普通的 MS-COCO 数据集上，YOLOD 也表现出优异的表现，与 YOLOv5 比较而言，AP 提高了 0.4% - 2.6%，AP_S 提高了 2.5% - 4.1%。这些结果表明 YOLOD 在人工皮革杂 defect detection 和通用物体检测任务中具有出色的效果和可靠性，适用于实际应用。<details>
<summary>Abstract</summary>
In this study, the structural problems of the YOLOv5 model were analyzed emphatically. Based on the characteristics of fine defects in artificial leather, four innovative structures, namely DFP, IFF, AMP, and EOS, were designed. These advancements led to the proposal of a high-performance artificial leather fine defect detection model named YOLOD. YOLOD demonstrated outstanding performance on the artificial leather defect dataset, achieving an impressive increase of 11.7% - 13.5% in AP_50 compared to YOLOv5, along with a significant reduction of 5.2% - 7.2% in the error detection rate. Moreover, YOLOD also exhibited remarkable performance on the general MS-COCO dataset, with an increase of 0.4% - 2.6% in AP compared to YOLOv5, and a rise of 2.5% - 4.1% in AP_S compared to YOLOv5. These results demonstrate the superiority of YOLOD in both artificial leather defect detection and general object detection tasks, making it a highly efficient and effective model for real-world applications.
</details>
<details>
<summary>摘要</summary>
在这个研究中，YOLOv5模型的结构问题得到了强调性分析。基于人工皮革细 defect的特点，提出了四种创新结构：DFP、IFF、AMP和EOS。这些创新导致了一种高性能的人工皮革细 defect检测模型，即YOLOD。YOLOD在人工皮革细 defect数据集上达到了11.7%-13.5%的AP_50提升，同时有5.2%-7.2%的错误检测率降低。此外，YOLOD还在通用的 MS-COCO 数据集上表现出色，与 YOLOv5 相比，AP 提升0.4%-2.6%，AP_S 提升2.5%-4.1%。这些结果表明 YOLOD 在人工皮革细 defect检测和通用对象检测任务中具有出色的性能，使其在实际应用中成为高效率的选择。
</details></li>
</ul>
<hr>
<h2 id="Multi-Spectral-Image-Stitching-via-Spatial-Graph-Reasoning"><a href="#Multi-Spectral-Image-Stitching-via-Spatial-Graph-Reasoning" class="headerlink" title="Multi-Spectral Image Stitching via Spatial Graph Reasoning"></a>Multi-Spectral Image Stitching via Spatial Graph Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16741">http://arxiv.org/abs/2307.16741</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jzy2017/SGR-MSIS">https://github.com/Jzy2017/SGR-MSIS</a></li>
<li>paper_authors: Zhiying Jiang, Zengxi Zhang, Jinyuan Liu, Xin Fan, Risheng Liu</li>
<li>for: 这个论文的目的是提出一种基于图 convolutional neural networks (GCNs) 的多spectral图像组合方法，以实现多视点场景的稳定和可靠的整体场景组合。</li>
<li>methods: 该方法首先将多spectral图像转化为图形，然后通过图 convolutional neural networks (GCNs) 模型来学习图形之间的关系，并通过 dense feature embeddings 来实现视角之间的匹配。</li>
<li>results: 根据实验结果，该方法可以有效地处理多视点场景的折叠和组合问题，并且比现有的方法更加稳定和可靠。同时，该方法还可以在实际世界和生成的 synthetic 数据集上进行广泛的评估和验证。<details>
<summary>Abstract</summary>
Multi-spectral image stitching leverages the complementarity between infrared and visible images to generate a robust and reliable wide field-of-view (FOV) scene. The primary challenge of this task is to explore the relations between multi-spectral images for aligning and integrating multi-view scenes. Capitalizing on the strengths of Graph Convolutional Networks (GCNs) in modeling feature relationships, we propose a spatial graph reasoning based multi-spectral image stitching method that effectively distills the deformation and integration of multi-spectral images across different viewpoints. To accomplish this, we embed multi-scale complementary features from the same view position into a set of nodes. The correspondence across different views is learned through powerful dense feature embeddings, where both inter- and intra-correlations are developed to exploit cross-view matching and enhance inner feature disparity. By introducing long-range coherence along spatial and channel dimensions, the complementarity of pixel relations and channel interdependencies aids in the reconstruction of aligned multi-view features, generating informative and reliable wide FOV scenes. Moreover, we release a challenging dataset named ChaMS, comprising both real-world and synthetic sets with significant parallax, providing a new option for comprehensive evaluation. Extensive experiments demonstrate that our method surpasses the state-of-the-arts.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:多spectral图像缝合利用不同波长图像之间的共同性来生成一个可靠和可靠的广角场景。主要挑战是探索不同视角图像之间的关系，以便对多视图场景进行对接和整合。我们利用图像卷积神经网络的优势来模型特征关系，并提出一种基于空间图 reasoning的多spectral图像缝合方法。通过嵌入不同缩放级别的相关特征，并通过强大的密集特征嵌入来学习不同视角之间的相关性。通过引入空间和通道维度的长距离相关性，我们可以利用像素关系和通道间关系来重建对齐的多视图特征，生成可靠和可靠的广角场景。此外，我们发布了一个名为ChaMS的挑战性数据集，包括真实世界和 sintetic 集合，提供了一个新的评估选项。广泛的实验表明，我们的方法超过了当前的状态。
</details></li>
</ul>
<hr>
<h2 id="UniVTG-Towards-Unified-Video-Language-Temporal-Grounding"><a href="#UniVTG-Towards-Unified-Video-Language-Temporal-Grounding" class="headerlink" title="UniVTG: Towards Unified Video-Language Temporal Grounding"></a>UniVTG: Towards Unified Video-Language Temporal Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16715">http://arxiv.org/abs/2307.16715</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/showlab/univtg">https://github.com/showlab/univtg</a></li>
<li>paper_authors: Kevin Qinghong Lin, Pengchuan Zhang, Joya Chen, Shraman Pramanick, Difei Gao, Alex Jinpeng Wang, Rui Yan, Mike Zheng Shou</li>
<li>for: 这个论文旨在解决视频社交媒体上的视频浏览问题，特别是根据自定义语言查询（如句子或词语）找到视频中的目标片段。</li>
<li>methods: 该论文提出了一种统一视频暂时附加（VTG）标签和任务的方法，包括三个方向：首先，将各种VTG标签和任务重新定义为统一的形式；其次，开发一种高效和灵活的附加模型，可以处理各种任务和使用各种标签；最后，通过统一框架，使用大规模多样化标签进行预训练，从而提高附加能力。</li>
<li>results: 实验结果表明，该方法在三个任务（时间间隔检索、精彩检索和视频摘要） across seven datasets（QVHighlights、Charades-STA、TACoS、Ego4D、YouTube Highlights、TVSum和QFVS）中具有显著的效果和灵活性。<details>
<summary>Abstract</summary>
Video Temporal Grounding (VTG), which aims to ground target clips from videos (such as consecutive intervals or disjoint shots) according to custom language queries (e.g., sentences or words), is key for video browsing on social media. Most methods in this direction develop taskspecific models that are trained with type-specific labels, such as moment retrieval (time interval) and highlight detection (worthiness curve), which limits their abilities to generalize to various VTG tasks and labels. In this paper, we propose to Unify the diverse VTG labels and tasks, dubbed UniVTG, along three directions: Firstly, we revisit a wide range of VTG labels and tasks and define a unified formulation. Based on this, we develop data annotation schemes to create scalable pseudo supervision. Secondly, we develop an effective and flexible grounding model capable of addressing each task and making full use of each label. Lastly, thanks to the unified framework, we are able to unlock temporal grounding pretraining from large-scale diverse labels and develop stronger grounding abilities e.g., zero-shot grounding. Extensive experiments on three tasks (moment retrieval, highlight detection and video summarization) across seven datasets (QVHighlights, Charades-STA, TACoS, Ego4D, YouTube Highlights, TVSum, and QFVS) demonstrate the effectiveness and flexibility of our proposed framework. The codes are available at https://github.com/showlab/UniVTG.
</details>
<details>
<summary>摘要</summary>
视频时间固定（VTG），目标是根据自定义语言查询（如句子或词语）将视频中的clipgrounding（时间间隔或不连续shot）固定，对社交媒体视频浏览非常重要。大多数方法在这个方向都是通过特定任务的模型来进行训练，这限制了它们的普适性和扩展性。在这篇论文中，我们提出了一种统一多种VTG标签和任务的方法，称为UniVTG。以下是我们的三个方向：1. 我们对VTG标签和任务进行了广泛的复审，并定义了一个统一的表述。基于这个表述，我们开发了可扩展的数据注解方案，以创建可扩展的伪数据监督。2. 我们开发了一种高效和灵活的固定模型，能够Address每个任务和使用每个标签。3. 由于我们的统一框架，我们能够在大规模多种标签上进行时间固定预训练，并发展出更强的固定能力，例如零shot固定。我们的实验表明，我们的提议的框架在三个任务（时刻回忆、突出点检测和视频概要）Across seven datasets（QVHighlights、Charades-STA、TACoS、Ego4D、YouTube Highlights、TVSum和QFVS）中具有极高的效果和灵活性。我们的代码可以在https://github.com/showlab/UniVTG中获取。
</details></li>
</ul>
<hr>
<h2 id="Investigating-and-Improving-Latent-Density-Segmentation-Models-for-Aleatoric-Uncertainty-Quantification-in-Medical-Imaging"><a href="#Investigating-and-Improving-Latent-Density-Segmentation-Models-for-Aleatoric-Uncertainty-Quantification-in-Medical-Imaging" class="headerlink" title="Investigating and Improving Latent Density Segmentation Models for Aleatoric Uncertainty Quantification in Medical Imaging"></a>Investigating and Improving Latent Density Segmentation Models for Aleatoric Uncertainty Quantification in Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16694">http://arxiv.org/abs/2307.16694</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. M. Amaan Valiuddin, Christiaan G. A. Viviers, Ruud J. G. van Sloun, Peter H. N. de With, Fons van der Sommen</li>
<li>for: 这篇论文主要针对的是如何使用 latent density models Address 数据uncertainty 问题，具体来说是 Image Segmentation 中的 aleatoric uncertainty。</li>
<li>methods: 这篇论文使用的方法是 Probabilistic U-Net (PU-Net)，它使用 latent Normal densities 来优化 conditional data log-likelihood Evidence Lower Bound。</li>
<li>results: 研究发现，PU-Net 的 latent space 具有严重的不均衡性问题，这会使得 gradient descent 的效果受到限制，并且模型变得极敏感于 latent space 的地方化样本localization，导致预测不准确。为解决这个问题，这篇论文提出了 Sinkhorn PU-Net (SPU-Net)，使用 Sinkhorn Divergence 来促进 latent space 的均衡性，从而改善 gradient-descent 更新和模型的Robustness。实验表明，在公共数据集上，SPU-Net 与前一代 latent variable models 相比，在 Hungarian-Matched metric 上得到了最高达 11% 的性能提升。结果表明，通过促进 latent space 的均衡性，可以在医学图像分割中显著提高 latent density modeling 的性能。<details>
<summary>Abstract</summary>
Data uncertainties, such as sensor noise or occlusions, can introduce irreducible ambiguities in images, which result in varying, yet plausible, semantic hypotheses. In Machine Learning, this ambiguity is commonly referred to as aleatoric uncertainty. Latent density models can be utilized to address this problem in image segmentation. The most popular approach is the Probabilistic U-Net (PU-Net), which uses latent Normal densities to optimize the conditional data log-likelihood Evidence Lower Bound. In this work, we demonstrate that the PU- Net latent space is severely inhomogenous. As a result, the effectiveness of gradient descent is inhibited and the model becomes extremely sensitive to the localization of the latent space samples, resulting in defective predictions. To address this, we present the Sinkhorn PU-Net (SPU-Net), which uses the Sinkhorn Divergence to promote homogeneity across all latent dimensions, effectively improving gradient-descent updates and model robustness. Our results show that by applying this on public datasets of various clinical segmentation problems, the SPU-Net receives up to 11% performance gains compared against preceding latent variable models for probabilistic segmentation on the Hungarian-Matched metric. The results indicate that by encouraging a homogeneous latent space, one can significantly improve latent density modeling for medical image segmentation.
</details>
<details>
<summary>摘要</summary>
数据不确定性，如探测器噪声或遮挡，可以导致图像中的不可避免歧义，从而导致多种可能的Semantic Hypothesis。在机器学习中，这种歧义称为 aleatoric uncertainty。秘密密度模型可以用来解决这个问题。最流行的方法是Probabilistic U-Net（PU-Net），它使用秘密的Normal密度来优化 conditional data log-likelihood Evidence Lower Bound。在这种工作中，我们发现PU-Net的latent空间很强不均衡。这导致了梯度下降的效果被妨碍，并且模型变得非常敏感于秘密空间样本的localization，导致预测不准确。为了解决这个问题，我们提出了Sinkhorn PU-Net（SPU-Net），它使用Sinkhorn Divergence来促进所有秘密维度之间的均衡，从而提高梯度下降更新和模型的Robustness。我们的结果显示，通过在公共数据集上应用SPU-Net，可以在Hungarian-Matched metric上获得11%的性能提升，相比之前的秘密变量模型。结果表明，通过促进秘密空间的均衡，可以在医疗图像分割中显著提高秘密密度模型的性能。
</details></li>
</ul>
<hr>
<h2 id="DiffPose-SpatioTemporal-Diffusion-Model-for-Video-Based-Human-Pose-Estimation"><a href="#DiffPose-SpatioTemporal-Diffusion-Model-for-Video-Based-Human-Pose-Estimation" class="headerlink" title="DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation"></a>DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16687">http://arxiv.org/abs/2307.16687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runyang Feng, Yixing Gao, Tze Ho Elden Tse, Xueqing Ma, Hyung Jin Chang<br>for: 这个论文主要针对的是多帧人体pose estimation问题，即使用扩展的 diffusion probabilistic models 来提高人体pose estimation的准确性。methods: 这个论文提出了一种新的 diffusion 架构，称为 DiffPose，它将视频基于人体pose estimation问题转化为一个 conditional heatmap 生成问题。在这个架构中，提出了一种 SpatioTemporal Representation Learner 来集成视觉证据，以及一种 Lookup-based MultiScale Feature Interaction 来确定局部关节和全局上下文之间的相关性。results: 这个论文在三个 benchmark 上达到了新的州OF-the-art 结果，包括 PoseTrack2017、PoseTrack2018 和 PoseTrack21。此外，DiffPose 还能够结合多个 pose estimate 来提高预测准确性，特别是对挑战性的关节。此外，DiffPose 还能够调整特定的 iterative step 来提高特征精细化，无需重新训练模型。<details>
<summary>Abstract</summary>
Denoising diffusion probabilistic models that were initially proposed for realistic image generation have recently shown success in various perception tasks (e.g., object detection and image segmentation) and are increasingly gaining attention in computer vision. However, extending such models to multi-frame human pose estimation is non-trivial due to the presence of the additional temporal dimension in videos. More importantly, learning representations that focus on keypoint regions is crucial for accurate localization of human joints. Nevertheless, the adaptation of the diffusion-based methods remains unclear on how to achieve such objective. In this paper, we present DiffPose, a novel diffusion architecture that formulates video-based human pose estimation as a conditional heatmap generation problem. First, to better leverage temporal information, we propose SpatioTemporal Representation Learner which aggregates visual evidences across frames and uses the resulting features in each denoising step as a condition. In addition, we present a mechanism called Lookup-based MultiScale Feature Interaction that determines the correlations between local joints and global contexts across multiple scales. This mechanism generates delicate representations that focus on keypoint regions. Altogether, by extending diffusion models, we show two unique characteristics from DiffPose on pose estimation task: (i) the ability to combine multiple sets of pose estimates to improve prediction accuracy, particularly for challenging joints, and (ii) the ability to adjust the number of iterative steps for feature refinement without retraining the model. DiffPose sets new state-of-the-art results on three benchmarks: PoseTrack2017, PoseTrack2018, and PoseTrack21.
</details>
<details>
<summary>摘要</summary>
DiffPose是一种新的扩展了 diffusion 模型，用于视频基于人体姿态估计。这种模型通过将视频基于人体姿态估计转化为一个条件热图生成问题，以提高 temporal 信息的利用。此外，我们还提出了一种新的机制called Lookup-based MultiScale Feature Interaction，用于确定局部关节和全局上下文之间的相关性。这种机制能够生成细腻的表示，特别是关注关节区域。通过扩展 diffusion 模型，DiffPose 显示出了以下两个独特特征：首先，能够将多个 pose 估计集合以提高预测精度，特别是难于估计的关节。其次，能够在不需要重新训练模型的情况下，调整特征细化步骤的数量。DiffPose 在 PoseTrack2017、PoseTrack2018 和 PoseTrack21 三个benchmark上达到了新的state-of-the-art 结果。
</details></li>
</ul>
<hr>
<h2 id="Guiding-Image-Captioning-Models-Toward-More-Specific-Captions"><a href="#Guiding-Image-Captioning-Models-Toward-More-Specific-Captions" class="headerlink" title="Guiding Image Captioning Models Toward More Specific Captions"></a>Guiding Image Captioning Models Toward More Specific Captions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16686">http://arxiv.org/abs/2307.16686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Kornblith, Lala Li, Zirui Wang, Thao Nguyen</li>
<li>for: 这个研究是为了提高图像描述的精度和准确性，并且不需要参考文本。</li>
<li>methods: 研究人员使用了一种称为”自由指导”的方法，将模型 Fine-tune 以便估计图像和描述的共享分布。</li>
<li>results: 研究人员发现，使用这种自由指导方法可以提高图像描述的精度和准确性，但是会有些差异于标准的参考文本基准。<details>
<summary>Abstract</summary>
Image captioning is conventionally formulated as the task of generating captions for images that match the distribution of reference image-caption pairs. However, reference captions in standard captioning datasets are short and may not uniquely identify the images they describe. These problems are further exacerbated when models are trained directly on image-alt text pairs collected from the internet. In this work, we show that it is possible to generate more specific captions with minimal changes to the training process. We implement classifier-free guidance for an autoregressive captioning model by fine-tuning it to estimate both conditional and unconditional distributions over captions. The guidance scale applied at decoding controls a trade-off between maximizing $p(\mathrm{caption}|\mathrm{image})$ and $p(\mathrm{image}|\mathrm{caption})$. Compared to standard greedy decoding, decoding with a guidance scale of 2 substantially improves reference-free metrics such as CLIPScore (0.808 vs. 0.775) and caption$\to$image retrieval performance in the CLIP embedding space (recall@1 44.6% vs. 26.5%), but worsens standard reference-based captioning metrics (e.g., CIDEr 78.6 vs 126.1). We further explore the use of language models to guide the decoding process, obtaining small improvements over the Pareto frontier of reference-free vs. reference-based captioning metrics that arises from classifier-free guidance, and substantially improving the quality of captions generated from a model trained only on minimally curated web data.
</details>
<details>
<summary>摘要</summary>
Image captioning 是通常用来生成图像的描述文本，但标准的参考描述集合可能不够精准地描述图像。这些问题更加严重当模型直接从互联网上收集图像-描述文本对进行训练。在这种情况下，我们显示了如何通过微调模型来生成更为特定的描述文本，而无需更改训练过程。我们实现了无类标签导向的推导，使得模型在解码过程中估计图像和描述文本之间的 conditional 和 unconditional 分布。指导缩放应用于解码控制了图像和描述文本之间的质量。与标准的批量解码相比，使用指导缩放可以提高无参考度量metric（CLIPScore）的值（0.808 vs. 0.775），以及在CLIP空间中的描述文本到图像 retrieve 性能（recall@1 44.6% vs. 26.5%），但是会降低标准的参考基础度量（例如 CIDEr 78.6 vs 126.1）。我们进一步探讨了使用语言模型来引导解码过程，可以在无参考度量 vs. 参考度量的 Pareto Frontier 上获得小幅提升，并在使用互联网上收集的最小 curaated 数据进行训练时，显著提高生成的描述文本质量。
</details></li>
</ul>
<hr>
<h2 id="Conditioning-Generative-Latent-Optimization-to-solve-Imaging-Inverse-Problems"><a href="#Conditioning-Generative-Latent-Optimization-to-solve-Imaging-Inverse-Problems" class="headerlink" title="Conditioning Generative Latent Optimization to solve Imaging Inverse Problems"></a>Conditioning Generative Latent Optimization to solve Imaging Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16670">http://arxiv.org/abs/2307.16670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Braure, Kévin Ginsburger</li>
<li>for: 解决医学成像 inverse problem (IIP) 中的数据驱动方法在受限的测量设置下的表现问题，如 CT 成像中的稀疏 X-ray 投射。</li>
<li>methods: 使用 score-based 生成模型，不需要大量的指导数据，可以在测试时根据成像设置进行灵活应用。</li>
<li>results: 与现有指导学习方法相比，可以达到更好的重建质量，并且不需要 backwards 运算器，可以扩展用 caso 到非线性 IIP 问题。<details>
<summary>Abstract</summary>
Computed Tomography (CT) is a prominent example of Imaging Inverse Problem (IIP), highlighting the unrivalled performances of data-driven methods in degraded measurements setups like sparse X-ray projections. Although a significant proportion of deep learning approaches benefit from large supervised datasets to directly map experimental measurements to medical scans, they cannot generalize to unknown acquisition setups. In contrast, fully unsupervised techniques, most notably using score-based generative models, have recently demonstrated similar or better performances compared to supervised approaches to solve IIPs while being flexible at test time regarding the imaging setup. However, their use cases are limited by two factors: (a) they need considerable amounts of training data to have good generalization properties and (b) they require a backward operator, like Filtered-Back-Projection in the case of CT, to condition the learned prior distribution of medical scans to experimental measurements. To overcome these issues, we propose an unsupervised conditional approach to the Generative Latent Optimization framework (cGLO), in which the parameters of a decoder network are initialized on an unsupervised dataset. The decoder is then used for reconstruction purposes, by performing Generative Latent Optimization with a loss function directly comparing simulated measurements from proposed reconstructions to experimental measurements. The resulting approach, tested on sparse-view CT using multiple training dataset sizes, demonstrates better reconstruction quality compared to state-of-the-art score-based strategies in most data regimes and shows an increasing performance advantage for smaller training datasets and reduced projection angles. Furthermore, cGLO does not require any backward operator and could expand use cases even to non-linear IIPs.
</details>
<details>
<summary>摘要</summary>
计算Tomography（CT）是一个典型的图像反问题（IIP）的例子，表明数据驱动方法在受限度量测量设置下表现出比其他方法更高的能力。虽然大多数深度学习方法需要大量的超参数数据来直接将实验室测量映射到医学扫描图像，但它们无法泛化到未知的捕获设置。相反，完全无监督的技术，主要是使用得分数据生成模型，在最近几年内已经展现了与监督方法相当或更好的性能，而且具有可变测试时间的灵活性。然而，它们的应用场景受到两种因素的限制：（a）它们需要大量的训练数据来有好的泛化性能，（b）它们需要一个后向运算器，如滤波后投影，来定制学习的医学扫描图像的先前分布。为了突破这些问题，我们提议一种不监督的冲ombinairal方法，在这里使用一个抽象的decoder网络。decoder网络的参数在一个无监督数据集上进行初始化，然后用Generative Latent Optimization（GLO）进行重构。在这种方法中，我们直接将 simulated measurements from proposed reconstructions 与实际测量进行比较，并使用这个loss函数来优化decoder网络。我们在多个训练数据集大小进行测试，并证明在大多数数据域下，cGLO比Score-based策略具有更高的重构质量，并且在小于 projection angles 和训练数据集大小时表现出逐渐增长的性能优势。此外，cGLO不需要任何后向运算器，因此可以扩展应用场景到非线性 IIPs。
</details></li>
</ul>
<hr>
<h2 id="Domain-Adaptation-for-Medical-Image-Segmentation-using-Transformation-Invariant-Self-Training"><a href="#Domain-Adaptation-for-Medical-Image-Segmentation-using-Transformation-Invariant-Self-Training" class="headerlink" title="Domain Adaptation for Medical Image Segmentation using Transformation-Invariant Self-Training"></a>Domain Adaptation for Medical Image Segmentation using Transformation-Invariant Self-Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16660">http://arxiv.org/abs/2307.16660</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/negin-ghamsarian/transformation-invariant-self-training-miccai23">https://github.com/negin-ghamsarian/transformation-invariant-self-training-miccai23</a></li>
<li>paper_authors: Negin Ghamsarian, Javier Gamazo Tejero, Pablo Márquez Neila, Sebastian Wolf, Martin Zinkernagel, Klaus Schoeffmann, Raphael Sznitman</li>
<li>for: 这个研究的目的是提出一种基于pseudo-labeling的自适应频率降阶法，以便在不同的成像设备和配置下，通过自适应频率降阶法来学习抽象表示。</li>
<li>methods: 本研究使用了pseudo-labeling技术，并对不确定的pseudo标签进行评估和筛选，以提高自适应频率降阶法的性能。</li>
<li>results: 实验结果表明，提出的transformation-invariant self-training（TI-ST）方法可以有效地mitigate the lack of target domain annotation,并提高目标频率降阶法的性能。<details>
<summary>Abstract</summary>
Models capable of leveraging unlabelled data are crucial in overcoming large distribution gaps between the acquired datasets across different imaging devices and configurations. In this regard, self-training techniques based on pseudo-labeling have been shown to be highly effective for semi-supervised domain adaptation. However, the unreliability of pseudo labels can hinder the capability of self-training techniques to induce abstract representation from the unlabeled target dataset, especially in the case of large distribution gaps. Since the neural network performance should be invariant to image transformations, we look to this fact to identify uncertain pseudo labels. Indeed, we argue that transformation invariant detections can provide more reasonable approximations of ground truth. Accordingly, we propose a semi-supervised learning strategy for domain adaptation termed transformation-invariant self-training (TI-ST). The proposed method assesses pixel-wise pseudo-labels' reliability and filters out unreliable detections during self-training. We perform comprehensive evaluations for domain adaptation using three different modalities of medical images, two different network architectures, and several alternative state-of-the-art domain adaptation methods. Experimental results confirm the superiority of our proposed method in mitigating the lack of target domain annotation and boosting segmentation performance in the target domain.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)模型可以利用无标注数据是重要的，以推行大型分布差问题的解决。在这种情况下，基于 pseudo-labeling 的自我训练技术是高效的 semi-supervised 领域适应。然而， Pseudo 标签的不可靠性可能会阻碍自我训练技术在无标注目标集中生成抽象表示。特别是在大型分布差情况下。由于神经网络性能应该对图像变换不变，我们利用这一点来确定不可靠的 Pseudo 标签。因此，我们提出了一种基于变换不变的自我训练方法（TI-ST），该方法在自我训练期间评估每个像素的 Pseudo 标签可靠性，并将不可靠的检测排除。我们进行了三种不同的医疗影像模式、两种不同的网络架构和多种现有领域适应方法的比较测试。实验结果表明，我们的提议方法可以减少目标领域的标注缺乏，并提高目标领域中的分类性能。
</details></li>
</ul>
<hr>
<h2 id="CDUL-CLIP-Driven-Unsupervised-Learning-for-Multi-Label-Image-Classification"><a href="#CDUL-CLIP-Driven-Unsupervised-Learning-for-Multi-Label-Image-Classification" class="headerlink" title="CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification"></a>CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16634">http://arxiv.org/abs/2307.16634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rabab Abdelfattah, Qing Guo, Xiaoguang Li, Xiaofeng Wang, Song Wang</li>
<li>for: 这paper是为了开发一种无监督学习方法，用于无标签图像分类。</li>
<li>methods: 该方法包括三个阶段：初始化、训练和推理。在初始化阶段，我们利用CLIP模型的能力，并提出了一种扩展CLIP的新方法，以实现基于全局-本地图像文本相似性汇聚的多标签预测。在训练阶段，我们提出了一个优化框架，用于训练分类网络和修正未观察标签。在推理阶段，只需使用分类网络来预测输入图像的标签。</li>
<li>results: 对MS-COCO、PASCAL VOC 2007、PASCAL VOC 2012和NUS datasets进行了广泛的实验，并达到了当前无监督学习方法的最高性能水平，甚至与弱监督分类方法具有相似的性能。<details>
<summary>Abstract</summary>
This paper presents a CLIP-based unsupervised learning method for annotation-free multi-label image classification, including three stages: initialization, training, and inference. At the initialization stage, we take full advantage of the powerful CLIP model and propose a novel approach to extend CLIP for multi-label predictions based on global-local image-text similarity aggregation. To be more specific, we split each image into snippets and leverage CLIP to generate the similarity vector for the whole image (global) as well as each snippet (local). Then a similarity aggregator is introduced to leverage the global and local similarity vectors. Using the aggregated similarity scores as the initial pseudo labels at the training stage, we propose an optimization framework to train the parameters of the classification network and refine pseudo labels for unobserved labels. During inference, only the classification network is used to predict the labels of the input image. Extensive experiments show that our method outperforms state-of-the-art unsupervised methods on MS-COCO, PASCAL VOC 2007, PASCAL VOC 2012, and NUS datasets and even achieves comparable results to weakly supervised classification methods.
</details>
<details>
<summary>摘要</summary>
In the initialization stage, we leverage the powerful CLIP model to generate a similarity vector for each image, both globally and locally. We then use a similarity aggregator to combine the global and local similarity vectors. These aggregated similarity scores serve as initial pseudo labels for training.In the training stage, we propose an optimization framework to refine the pseudo labels for unobserved labels. We use the aggregated similarity scores as the initial pseudo labels and optimize the parameters of the classification network to predict the correct labels.In the inference stage, we only use the trained classification network to predict the labels of the input image. Extensive experiments show that our method outperforms state-of-the-art unsupervised methods on MS-COCO, PASCAL VOC 2007, PASCAL VOC 2012, and NUS datasets, and even achieves comparable results to weakly supervised classification methods.Here's the translation in Simplified Chinese:这篇论文提出了一种基于 CLIP 的无监督学习方法，用于无监督多个标签图像分类，包括三个阶段：初始化、训练和推断。在初始化阶段，我们利用 CLIP 模型的强大能力，并提出了一种新的方法，通过全图像和每个片断的相似性聚合来扩展 CLIP  для多个标签预测。我们将每个图像分割成多个片断，然后使用 CLIP 生成每个片断的相似性向量，以及整个图像的相似性向量。然后，我们引入一个相似性聚合器，将全图像和每个片断的相似性向量聚合。这些聚合的相似性分数被用作训练阶段的初始 Pseudo 标签。在训练阶段，我们提出了一个优化框架，用于更新 Pseudo 标签的参数。我们使用聚合的相似性分数作为初始 Pseudo 标签，然后使用优化的分类网络来预测未知标签。在推断阶段，我们只使用已训练的分类网络来预测输入图像的标签。广泛的实验显示，我们的方法在 MS-COCO、PASCAL VOC 2007、PASCAL VOC 2012 和 NUS 数据集上具有优秀的表现，甚至与弱监督分类方法具有相似的表现。
</details></li>
</ul>
<hr>
<h2 id="Can-Self-Supervised-Representation-Learning-Methods-Withstand-Distribution-Shifts-and-Corruptions"><a href="#Can-Self-Supervised-Representation-Learning-Methods-Withstand-Distribution-Shifts-and-Corruptions" class="headerlink" title="Can Self-Supervised Representation Learning Methods Withstand Distribution Shifts and Corruptions?"></a>Can Self-Supervised Representation Learning Methods Withstand Distribution Shifts and Corruptions?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02525">http://arxiv.org/abs/2308.02525</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prakashchhipa/robsutness-evaluation-of-self-supervised-methods-distribution-shifts-and-corruptions">https://github.com/prakashchhipa/robsutness-evaluation-of-self-supervised-methods-distribution-shifts-and-corruptions</a></li>
<li>paper_authors: Prakash Chandra Chhipa, Johan Rodahl Holmgren, Kanjar De, Rajkumar Saini, Marcus Liwicki</li>
<li>for: 本研究旨在探讨自动监督学习在计算机视觉领域中的稳定性和可靠性问题，以及自动监督学习方法在不同类型的数据分布下的表现。</li>
<li>methods: 本研究使用了各种自动监督学习方法，包括对比学习、知识储存、对谱最大化和聚类等方法，以研究这些方法在不同类型的数据分布下的表现。</li>
<li>results: 研究发现，自动监督学习方法在不同类型的数据分布下的表现存在明显的敏感性，尤其是在数据分布偏移和图像损害等情况下。这些结果提醒我们在实际应用中需要更好地处理数据分布偏移和图像损害问题，以确保自动监督学习方法的稳定性和可靠性。<details>
<summary>Abstract</summary>
Self-supervised learning in computer vision aims to leverage the inherent structure and relationships within data to learn meaningful representations without explicit human annotation, enabling a holistic understanding of visual scenes. Robustness in vision machine learning ensures reliable and consistent performance, enhancing generalization, adaptability, and resistance to noise, variations, and adversarial attacks. Self-supervised paradigms, namely contrastive learning, knowledge distillation, mutual information maximization, and clustering, have been considered to have shown advances in invariant learning representations. This work investigates the robustness of learned representations of self-supervised learning approaches focusing on distribution shifts and image corruptions in computer vision. Detailed experiments have been conducted to study the robustness of self-supervised learning methods on distribution shifts and image corruptions. The empirical analysis demonstrates a clear relationship between the performance of learned representations within self-supervised paradigms and the severity of distribution shifts and corruptions. Notably, higher levels of shifts and corruptions are found to significantly diminish the robustness of the learned representations. These findings highlight the critical impact of distribution shifts and image corruptions on the performance and resilience of self-supervised learning methods, emphasizing the need for effective strategies to mitigate their adverse effects. The study strongly advocates for future research in the field of self-supervised representation learning to prioritize the key aspects of safety and robustness in order to ensure practical applicability. The source code and results are available on GitHub.
</details>
<details>
<summary>摘要</summary>
自我监督学习在计算机视觉领域目的是利用数据内在的结构和关系来学习有意义的表示，无需显式的人类标注，以实现全面的视觉场景理解。在视觉机器学习中，可靠性和稳定性是关键的，它们可以提高总体化、适应性和对噪、变化和攻击的抵抗能力。自我监督方法，包括对比学习、知识传递、最大化mutual information和聚合，已经被认为可以实现不变学习表示。本研究探讨了自我监督学习方法中learned表示的Robustness，特别是对分布转移和图像损害的影响。通过详细的实验，我们发现 distribution shifts和图像损害会对learned表示的性能产生明显的影响，并且随着分布转移和损害的严重程度的增加，learned表示的Robustness会逐渐下降。这些发现强调了自我监督学习方法中分布转移和图像损害的重要性，并且提醒我们需要开发有效的缓解方法，以确保其实际可靠性。本研究强烈建议未来在自我监督表示学习领域的研究应该更加注重安全性和Robustness，以确保其实际应用。源代码和结果可以在GitHub上找到。
</details></li>
</ul>
<hr>
<h2 id="Detecting-diabetic-retinopathy-severity-through-fundus-images-using-an-ensemble-of-classifiers"><a href="#Detecting-diabetic-retinopathy-severity-through-fundus-images-using-an-ensemble-of-classifiers" class="headerlink" title="Detecting diabetic retinopathy severity through fundus images using an ensemble of classifiers"></a>Detecting diabetic retinopathy severity through fundus images using an ensemble of classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16622">http://arxiv.org/abs/2307.16622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduard Popescu, Adrian Groza, Ioana Damian</li>
<li>For: The paper is written for diagnosing diabetic retinopathy and determining its severity levels.* Methods: The paper proposes a method for detecting diabetic retinopathy using fundus images, which includes data preprocessing, image segmentation, and an ensemble of classifiers.* Results: The paper achieves high accuracy in detecting diabetic retinopathy and its severity levels using the proposed method.Here’s the information in Simplified Chinese text:</li>
<li>for: 本文用于诊断糖尿病视网膜病和其严重程度。</li>
<li>methods: 本文提出了基于视网膜图像的糖尿病诊断方法，包括数据预处理、图像分割和 ensemble 分类器。</li>
<li>results: 本文通过该方法实现了高精度的糖尿病诊断和严重程度评估。<details>
<summary>Abstract</summary>
Diabetic retinopathy is an ocular condition that affects individuals with diabetes mellitus. It is a common complication of diabetes that can impact the eyes and lead to vision loss. One method for diagnosing diabetic retinopathy is the examination of the fundus of the eye. An ophthalmologist examines the back part of the eye, including the retina, optic nerve, and the blood vessels that supply the retina. In the case of diabetic retinopathy, the blood vessels in the retina deteriorate and can lead to bleeding, swelling, and other changes that affect vision. We proposed a method for detecting diabetic diabetic severity levels. First, a set of data-prerpocessing is applied to available data: adaptive equalisation, color normalisation, Gaussian filter, removal of the optic disc and blood vessels. Second, we perform image segmentation for relevant markers and extract features from the fundus images. Third, we apply an ensemble of classifiers and we assess the trust in the system.
</details>
<details>
<summary>摘要</summary>
diabetic retinopathy 是一种眼病理condition that affects individuals with diabetes mellitus. It is a common complication of diabetes that can impact the eyes and lead to vision loss. One method for diagnosing diabetic retinopathy is the examination of the fundus of the eye. An ophthalmologist examines the back part of the eye, including the retina, optic nerve, and the blood vessels that supply the retina. In the case of diabetic retinopathy, the blood vessels in the retina deteriorate and can lead to bleeding, swelling, and other changes that affect vision. We proposed a method for detecting diabetic retinopathy severity levels. First, a set of data-preprocessing is applied to available data: adaptive equalization, color normalization, Gaussian filter, removal of the optic disc and blood vessels. Second, we perform image segmentation for relevant markers and extract features from the fundus images. Third, we apply an ensemble of classifiers and we assess the trust in the system.Here's the translation of the text into Traditional Chinese:diabetic retinopathy 是一种眼病理condition that affects individuals with diabetes mellitus. It is a common complication of diabetes that can impact the eyes and lead to vision loss. One method for diagnosing diabetic retinopathy is the examination of the fundus of the eye. An ophthalmologist examines the back part of the eye, including the retina, optic nerve, and the blood vessels that supply the retina. In the case of diabetic retinopathy, the blood vessels in the retina deteriorate and can lead to bleeding, swelling, and other changes that affect vision. We proposed a method for detecting diabetic retinopathy severity levels. First, a set of data-preprocessing is applied to available data: adaptive equalization, color normalization, Gaussian filter, removal of the optic disc and blood vessels. Second, we perform image segmentation for relevant markers and extract features from the fundus images. Third, we apply an ensemble of classifiers and we assess the trust in the system.
</details></li>
</ul>
<hr>
<h2 id="Audio-Visual-Segmentation-by-Exploring-Cross-Modal-Mutual-Semantics"><a href="#Audio-Visual-Segmentation-by-Exploring-Cross-Modal-Mutual-Semantics" class="headerlink" title="Audio-Visual Segmentation by Exploring Cross-Modal Mutual Semantics"></a>Audio-Visual Segmentation by Exploring Cross-Modal Mutual Semantics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16620">http://arxiv.org/abs/2307.16620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Liu, Peike Li, Xingqun Qi, Hu Zhang, Lincheng Li, Dadong Wang, Xin Yu</li>
<li>for: 本研究旨在解决现有AVS方法受数据集偏袋问题，即尝试将所有视频中的各种对象都与音频信号相关联。</li>
<li>methods: 本研究提出了一种音频视频实例感知分割方法，首先在视频中检测潜在的声音对象，然后将声音对象候选者与给定的音频相关联。</li>
<li>results: 实验结果表明，本研究可以有效地分割声音对象，不受数据集偏袋的影响。<details>
<summary>Abstract</summary>
The audio-visual segmentation (AVS) task aims to segment sounding objects from a given video. Existing works mainly focus on fusing audio and visual features of a given video to achieve sounding object masks. However, we observed that prior arts are prone to segment a certain salient object in a video regardless of the audio information. This is because sounding objects are often the most salient ones in the AVS dataset. Thus, current AVS methods might fail to localize genuine sounding objects due to the dataset bias. In this work, we present an audio-visual instance-aware segmentation approach to overcome the dataset bias. In a nutshell, our method first localizes potential sounding objects in a video by an object segmentation network, and then associates the sounding object candidates with the given audio. We notice that an object could be a sounding object in one video but a silent one in another video. This would bring ambiguity in training our object segmentation network as only sounding objects have corresponding segmentation masks. We thus propose a silent object-aware segmentation objective to alleviate the ambiguity. Moreover, since the category information of audio is unknown, especially for multiple sounding sources, we propose to explore the audio-visual semantic correlation and then associate audio with potential objects. Specifically, we attend predicted audio category scores to potential instance masks and these scores will highlight corresponding sounding instances while suppressing inaudible ones. When we enforce the attended instance masks to resemble the ground-truth mask, we are able to establish audio-visual semantics correlation. Experimental results on the AVS benchmarks demonstrate that our method can effectively segment sounding objects without being biased to salient objects.
</details>
<details>
<summary>摘要</summary>
audio-visual segmentation (AVS) 任务的目标是将视频中的声音对象 segmented 出来。现有的工作主要是将视频的声音和视觉特征相结合以实现声音对象的面积。然而，我们发现现有的方法很容易因为数据集中的偏见而 segment 出错误的声音对象。这是因为声音对象在视频中经常是最明显的对象。因此，现有的 AVS 方法可能会失败地 Localize 真正的声音对象，因为它们可能会受到数据集的偏见。在这种情况下，我们提出了一种 audio-visual 实例检测方法，以解决数据集的偏见。我们的方法首先在视频中检测 potential 声音对象，然后将这些对象与给定的声音相关联。我们注意到，一个对象可能在一个视频中是声音对象，而在另一个视频中是无声对象。这会在我们的对象 segmentation 网络的训练中引入歧义。我们因此提出了一种静音对象检测目标，以解决这个歧义。此外，由于声音的类别信息unknown，特别是多个声音源，我们提出了探索 audio-visual  semantic 相关性，并将声音与潜在对象相关联。具体来说，我们attend 预测的声音类别分数到潜在实例面积中，这些分数会高亮相应的声音实例，而suppress 无声实例。当我们强制潜在实例面积与实际面积匹配时，我们能够建立 audio-visual semantic 相关性。我们的方法在 AVS  benchmark 上进行了实验，结果表明，我们可以不受数据集的偏见，Effectively segment 声音对象。
</details></li>
</ul>
<hr>
<h2 id="FULLER-Unified-Multi-modality-Multi-task-3D-Perception-via-Multi-level-Gradient-Calibration"><a href="#FULLER-Unified-Multi-modality-Multi-task-3D-Perception-via-Multi-level-Gradient-Calibration" class="headerlink" title="FULLER: Unified Multi-modality Multi-task 3D Perception via Multi-level Gradient Calibration"></a>FULLER: Unified Multi-modality Multi-task 3D Perception via Multi-level Gradient Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16617">http://arxiv.org/abs/2307.16617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhijian Huang, Sihao Lin, Guiyu Liu, Mukun Luo, Chaoqiang Ye, Hang Xu, Xiaojun Chang, Xiaodan Liang</li>
<li>for: 提高3D自动驾驶场景中多Modalità多任务学习的稳定性和计算效率， Mitigate the notorious modality bias and task conflict.</li>
<li>methods: 提出了一种新的多级梯度准确学习框架，在优化过程中对任务和模态之间的梯度进行准确做出了协调。</li>
<li>results: 在大规模的 benchmark nuScenes 上实验表明，提出的方法能够提高 map segmentation 的精度，提高 3D 检测的精度，使3D自动驾驶在多模态多任务学习领域得到了进一步的应用。<details>
<summary>Abstract</summary>
Multi-modality fusion and multi-task learning are becoming trendy in 3D autonomous driving scenario, considering robust prediction and computation budget. However, naively extending the existing framework to the domain of multi-modality multi-task learning remains ineffective and even poisonous due to the notorious modality bias and task conflict. Previous works manually coordinate the learning framework with empirical knowledge, which may lead to sub-optima. To mitigate the issue, we propose a novel yet simple multi-level gradient calibration learning framework across tasks and modalities during optimization. Specifically, the gradients, produced by the task heads and used to update the shared backbone, will be calibrated at the backbone's last layer to alleviate the task conflict. Before the calibrated gradients are further propagated to the modality branches of the backbone, their magnitudes will be calibrated again to the same level, ensuring the downstream tasks pay balanced attention to different modalities. Experiments on large-scale benchmark nuScenes demonstrate the effectiveness of the proposed method, eg, an absolute 14.4% mIoU improvement on map segmentation and 1.4% mAP improvement on 3D detection, advancing the application of 3D autonomous driving in the domain of multi-modality fusion and multi-task learning. We also discuss the links between modalities and tasks.
</details>
<details>
<summary>摘要</summary>
多Modalità融合和多任务学习在3D自动驾驶场景中变得流行，以提高预测和计算预算的稳定性。然而，直接将现有框架应用到多Modalità多任务学习场景中可能会导致不优化和甚至有毒的模态偏见和任务冲突。前一些工作通过手动协调学习框架与实际知识来解决问题，可能会导致优化。为了解决这个问题，我们提出了一种新的、简单的多级梯度准确学习框架，在优化过程中跨任务和模态进行协调。具体来说，在 Shared Backbone 的最后层生成的梯度将被准确了，以降低任务冲突。然后，这些准确后的梯度将被再次准确到同一水平，确保下游任务对不同的模态进行平衡的注意力。我们在大规模的 benchmark nuScenes 上进行了实验，得到了提升的结果，例如，在 Map Segmentation 中提高了14.4%的精度，在 3D 检测中提高了1.4%的精度，这有助于推动3D自动驾驶在多Modalità融合和多任务学习场景中的应用。我们还讨论了模态和任务之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Sampling-to-Distill-Knowledge-Transfer-from-Open-World-Data"><a href="#Sampling-to-Distill-Knowledge-Transfer-from-Open-World-Data" class="headerlink" title="Sampling to Distill: Knowledge Transfer from Open-World Data"></a>Sampling to Distill: Knowledge Transfer from Open-World Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16601">http://arxiv.org/abs/2307.16601</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuzheng Wang, Zhaoyu Chen, Jie Zhang, Dingkang Yang, Zuhao Ge, Yang Liu, Siao Liu, Yunquan Sun, Wenqiang Zhang, Lizhe Qi</li>
<li>for: 本研究旨在训练高性能学生模型，无需原始训练数据。</li>
<li>methods: 我们提出了一种新的开放世界数据采样策略（ODSD），不需要重复生成过程。首先，我们使用适应采样模块采集开放世界数据，然后引入低噪表示来alleviate域shift问题，并建立多个数据示例之间的结构关系，以利用数据知识。</li>
<li>results: 我们在CIFAR-10、CIFAR-100、NYUv2和ImageNet等数据集上进行了广泛的实验，并取得了状态理论的性能。尤其是在ImageNet数据集上，我们提高了1.50%-9.59%的准确率。<details>
<summary>Abstract</summary>
Data-Free Knowledge Distillation (DFKD) is a novel task that aims to train high-performance student models using only the teacher network without original training data. Despite encouraging results, existing DFKD methods rely heavily on generation modules with high computational costs. Meanwhile, they ignore the fact that the generated and original data exist domain shifts due to the lack of supervision information. Moreover, knowledge is transferred through each example, ignoring the implicit relationship among multiple examples. To this end, we propose a novel Open-world Data Sampling Distillation (ODSD) method without a redundant generation process. First, we try to sample open-world data close to the original data's distribution by an adaptive sampling module. Then, we introduce a low-noise representation to alleviate the domain shifts and build a structured relationship of multiple data examples to exploit data knowledge. Extensive experiments on CIFAR-10, CIFAR-100, NYUv2, and ImageNet show that our ODSD method achieves state-of-the-art performance. Especially, we improve 1.50\%-9.59\% accuracy on the ImageNet dataset compared with the existing results.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Data-Free Knowledge Distillation (DFKD) is a novel task that aims to train high-performance student models using only the teacher network without original training data. Despite encouraging results, existing DFKD methods rely heavily on generation modules with high computational costs. Meanwhile, they ignore the fact that the generated and original data exist domain shifts due to the lack of supervision information. Moreover, knowledge is transferred through each example, ignoring the implicit relationship among multiple examples. To this end, we propose a novel Open-world Data Sampling Distillation (ODSD) method without a redundant generation process. First, we try to sample open-world data close to the original data's distribution by an adaptive sampling module. Then, we introduce a low-noise representation to alleviate the domain shifts and build a structured relationship of multiple data examples to exploit data knowledge. Extensive experiments on CIFAR-10, CIFAR-100, NYUv2, and ImageNet show that our ODSD method achieves state-of-the-art performance. Especially, we improve 1.50\%-9.59\% accuracy on the ImageNet dataset compared with the existing results."<</SYS>>以下是文本的简化中文翻译：“数据 свобод知识储备（DFKD）是一项新任务，旨在使用教师网络训练高性能的学生模型，无需原始训练数据。虽然已经得到了激励的结果，但现有的DFKD方法具有高计算成本的生成模块，同时忽略了生成和原始数据之间的频繁域转移，以及每个示例之间的隐式关系。为解决这个问题，我们提出了一种新的开放世界数据采样储备（ODSD）方法，不需要重复的生成过程。我们首先尝试通过适应采样模块采集开放世界数据，以便更接近原始数据的分布。然后，我们引入低噪表示，以降低域转移并建立多个数据示例之间的结构关系，以利用数据知识。我们对CIFAR-10、CIFAR-100、NYUv2和ImageNet进行了广泛的实验，结果表明，我们的ODSD方法在性能上达到了领先水平。尤其是在ImageNet dataset上，我们提高了1.50%-9.59%的准确率，与现有结果相比。”
</details></li>
</ul>
<hr>
<h2 id="SAMFlow-Eliminating-Any-Fragmentation-in-Optical-Flow-with-Segment-Anything-Model"><a href="#SAMFlow-Eliminating-Any-Fragmentation-in-Optical-Flow-with-Segment-Anything-Model" class="headerlink" title="SAMFlow: Eliminating Any Fragmentation in Optical Flow with Segment Anything Model"></a>SAMFlow: Eliminating Any Fragmentation in Optical Flow with Segment Anything Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16586">http://arxiv.org/abs/2307.16586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shili Zhou, Ruian He, Weimin Tan, Bo Yan<br>for:* 这种方法是为了解决现有方法强调地方准确性的问题，通过大视野模型的预训练和Segment Anything Model（SAM）的嵌入来提高物体识别。methods:* 这种方法使用了预训练的大视野模型和SAM图像编码器，并提出了一种Optical Flow Task-Specific Adaption scheme来适应非分割任务中使用SAM。results:* 该模型在Sintel和KITTI-15训练集上达到了0.86&#x2F;2.10清洁&#x2F;最终EPE和3.55&#x2F;12.32EPE&#x2F;F1-all的最佳性能，比Flowformer高出8.5%&#x2F;9.9%和13.2%&#x2F;16.3%。此外，该模型在Sintel和KITTI-15测试集上达到了状态最佳的性能，在所有二帧方法中在Sintel清洁通过中排名第一。<details>
<summary>Abstract</summary>
Optical Flow Estimation aims to find the 2D dense motion field between two frames. Due to the limitation of model structures and training datasets, existing methods often rely too much on local clues and ignore the integrity of objects, resulting in fragmented motion estimation. Through theoretical analysis, we find the pre-trained large vision models are helpful in optical flow estimation, and we notice that the recently famous Segment Anything Model (SAM) demonstrates a strong ability to segment complete objects, which is suitable for solving the fragmentation problem. We thus propose a solution to embed the frozen SAM image encoder into FlowFormer to enhance object perception. To address the challenge of in-depth utilizing SAM in non-segmentation tasks like optical flow estimation, we propose an Optical Flow Task-Specific Adaption scheme, including a Context Fusion Module to fuse the SAM encoder with the optical flow context encoder, and a Context Adaption Module to adapt the SAM features for optical flow task with Learned Task-Specific Embedding. Our proposed SAMFlow model reaches 0.86/2.10 clean/final EPE and 3.55/12.32 EPE/F1-all on Sintel and KITTI-15 training set, surpassing Flowformer by 8.5%/9.9% and 13.2%/16.3%. Furthermore, our model achieves state-of-the-art performance on the Sintel and KITTI-15 benchmarks, ranking #1 among all two-frame methods on Sintel clean pass.
</details>
<details>
<summary>摘要</summary>
Optical Flow Estimation 目标是找到两帧之间的2D紧密运动场景。由于模型结构和训练数据的限制，现有方法frequently rely onlocal clue，忽略对象的完整性，resulting in fragmented motion estimation. Through theoretical analysis, we find that pre-trained large vision models are helpful in optical flow estimation, and the recently famous Segment Anything Model (SAM) demonstrates strong ability to segment complete objects, which is suitable for solving the fragmentation problem. We thus propose a solution to embed the frozen SAM image encoder into FlowFormer to enhance object perception. To address the challenge of in-depth utilizing SAM in non-segmentation tasks like optical flow estimation, we propose an Optical Flow Task-Specific Adaption scheme, including a Context Fusion Module to fuse the SAM encoder with the optical flow context encoder, and a Context Adaption Module to adapt the SAM features for optical flow task with Learned Task-Specific Embedding. Our proposed SAMFlow model reaches 0.86/2.10 clean/final EPE and 3.55/12.32 EPE/F1-all on Sintel and KITTI-15 training set, surpassing Flowformer by 8.5%/9.9% and 13.2%/16.3%. Furthermore, our model achieves state-of-the-art performance on the Sintel and KITTI-15 benchmarks, ranking #1 among all two-frame methods on Sintel clean pass.
</details></li>
</ul>
<hr>
<h2 id="Audio-visual-video-to-speech-synthesis-with-synthesized-input-audio"><a href="#Audio-visual-video-to-speech-synthesis-with-synthesized-input-audio" class="headerlink" title="Audio-visual video-to-speech synthesis with synthesized input audio"></a>Audio-visual video-to-speech synthesis with synthesized input audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16584">http://arxiv.org/abs/2307.16584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Triantafyllos Kefalas, Yannis Panagakis, Maja Pantic</li>
<li>for:  investigate the effect of using video and audio inputs for video-to-speech synthesis during both training and inference.</li>
<li>methods:  use pre-trained video-to-speech models to synthesize the missing speech signals and then train an audio-visual-to-speech synthesis model using both the silent video and the synthesized speech as inputs.</li>
<li>results:  successful with both raw waveforms and mel spectrograms as target outputs.Here is the full text in Simplified Chinese:</li>
<li>for: 这个研究的目的是investigate the effect of using video and audio inputs for video-to-speech synthesis during both training and inference.</li>
<li>methods: 他们使用预训练的视频到语音模型来synthesize the missing speech signals,并然后使用 Both the silent video and the synthesized speech as inputs来train an audio-visual-to-speech synthesis model.</li>
<li>results: 他们的实验结果表明这种方法可以成功地使用 raw waveforms和mel spectrograms as target outputs.<details>
<summary>Abstract</summary>
Video-to-speech synthesis involves reconstructing the speech signal of a speaker from a silent video. The implicit assumption of this task is that the sound signal is either missing or contains a high amount of noise/corruption such that it is not useful for processing. Previous works in the literature either use video inputs only or employ both video and audio inputs during training, and discard the input audio pathway during inference. In this work we investigate the effect of using video and audio inputs for video-to-speech synthesis during both training and inference. In particular, we use pre-trained video-to-speech models to synthesize the missing speech signals and then train an audio-visual-to-speech synthesis model, using both the silent video and the synthesized speech as inputs, to predict the final reconstructed speech. Our experiments demonstrate that this approach is successful with both raw waveforms and mel spectrograms as target outputs.
</details>
<details>
<summary>摘要</summary>
<<SYS>>视频到语音合成涉及重建说话人的语音信号从一个无声视频中。这个隐式假设是，语音信号 Either missing or contains a high amount of noise/corruption, so it is not useful for processing. 先前的文献中的工作 Either use video inputs only or employ both video and audio inputs during training, and discard the input audio pathway during inference. In this work, we investigate the effect of using video and audio inputs for video-to-speech synthesis during both training and inference. Specifically, we use pre-trained video-to-speech models to synthesize the missing speech signals and then train an audio-visual-to-speech synthesis model, using both the silent video and the synthesized speech as inputs, to predict the final reconstructed speech. Our experiments demonstrate that this approach is successful with both raw waveforms and mel spectrograms as target outputs.中文简体版
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Conditional-Latent-Diffusion-for-Audio-visual-Segmentation"><a href="#Contrastive-Conditional-Latent-Diffusion-for-Audio-visual-Segmentation" class="headerlink" title="Contrastive Conditional Latent Diffusion for Audio-visual Segmentation"></a>Contrastive Conditional Latent Diffusion for Audio-visual Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16579">http://arxiv.org/abs/2307.16579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxin Mao, Jing Zhang, Mochu Xiang, Yunqiu Lv, Yiran Zhong, Yuchao Dai</li>
<li>for: 用于audio-visual segmentation（AVS）任务，探索音频的贡献。</li>
<li>methods: 使用干扰模型和对比学习来学习semantic-correlated表示学习。</li>
<li>results: 实验结果表明，我们的解决方案有效地提高了AVS任务的性能。Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究用于audio-visual segmentation（AVS）任务，探索音频的贡献。</li>
<li>methods: 我们提出了一种干扰模型，并使用对比学习来学习semantic-correlated表示学习。</li>
<li>results: 实验结果表明，我们的解决方案有效地提高了AVS任务的性能。Code and results are online via our project page: <a target="_blank" rel="noopener" href="https://github.com/OpenNLPLab/DiffusionAVS">https://github.com/OpenNLPLab/DiffusionAVS</a>.<details>
<summary>Abstract</summary>
We propose a latent diffusion model with contrastive learning for audio-visual segmentation (AVS) to extensively explore the contribution of audio. We interpret AVS as a conditional generation task, where audio is defined as the conditional variable for sound producer(s) segmentation. With our new interpretation, it is especially necessary to model the correlation between audio and the final segmentation map to ensure its contribution. We introduce a latent diffusion model to our framework to achieve semantic-correlated representation learning. Specifically, our diffusion model learns the conditional generation process of the ground-truth segmentation map, leading to ground-truth aware inference when we perform the denoising process at the test stage. As a conditional diffusion model, we argue it is essential to ensure that the conditional variable contributes to model output. We then introduce contrastive learning to our framework to learn audio-visual correspondence, which is proven consistent with maximizing the mutual information between model prediction and the audio data. In this way, our latent diffusion model via contrastive learning explicitly maximizes the contribution of audio for AVS. Experimental results on the benchmark dataset verify the effectiveness of our solution. Code and results are online via our project page: https://github.com/OpenNLPLab/DiffusionAVS.
</details>
<details>
<summary>摘要</summary>
我们提出了一种含批处理模型，通过对比学习来探索音频的贡献。我们解释音频视频分割（AVS）为一个条件生成任务，其中音频被定义为音频生产者（或者音频源）的条件变量。在这种新的解释下，模型需要学习音频和最终分割图的相关性，以确保音频的贡献。为此，我们引入了一种潜在扩散模型到我们的框架中，以实现相关性学习。具体来说，我们的扩散模型学习了真实分割图的生成过程，从而在测试阶段进行了真实分割图恢复，这是一种条件扩散模型。我们认为，在条件扩散模型中，需要确保条件变量对模型输出的贡献。我们然后引入了对比学习，以学习音频和视频之间的对应关系，这与最大化模型预测和音频数据之间的共同信息量相同。通过这种方式，我们的潜在扩散模型通过对比学习显著地提高了音频对AVS的贡献。我们的实验结果表明，我们的解决方案效果很好。代码和结果可以在我们项目页面上找到：https://github.com/OpenNLPLab/DiffusionAVS。
</details></li>
</ul>
<hr>
<h2 id="Transferable-Attack-for-Semantic-Segmentation"><a href="#Transferable-Attack-for-Semantic-Segmentation" class="headerlink" title="Transferable Attack for Semantic Segmentation"></a>Transferable Attack for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16572">http://arxiv.org/abs/2307.16572</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anucvers/tass">https://github.com/anucvers/tass</a></li>
<li>paper_authors: Mengqi He, Jing Zhang, Zhaoyuan Yang, Mingyi He, Nick Barnes, Yuchao Dai</li>
<li>for: 本研究探讨了 semantic segmentation 模型受到针对攻击的性能影响，并发现了传统攻击方法（如 PGD 和 FGSM）无法轻松地攻击目标模型。</li>
<li>methods: 本研究提出了两个主要因素来实现传输攻击：首先，攻击应该具有有效的数据增强和翻译不变特征，以适应未见模型；其次，稳定的优化策略是必要的，以找到最佳攻击方向。</li>
<li>results: 基于上述观察和发现，本研究提出了一种ensemble攻击方法，可以实现更有效的攻击和更高的传输性。实验结果表明，这种ensemble攻击方法可以在不同的 semantic segmentation 模型上达到更高的攻击成功率。<details>
<summary>Abstract</summary>
We analysis performance of semantic segmentation models wrt. adversarial attacks, and observe that the adversarial examples generated from a source model fail to attack the target models. i.e The conventional attack methods, such as PGD and FGSM, do not transfer well to target models, making it necessary to study the transferable attacks, especially transferable attacks for semantic segmentation. We find two main factors to achieve transferable attack. Firstly, the attack should come with effective data augmentation and translation-invariant features to deal with unseen models. Secondly, stabilized optimization strategies are needed to find the optimal attack direction. Based on the above observations, we propose an ensemble attack for semantic segmentation to achieve more effective attacks with higher transferability. The source code and experimental results are publicly available via our project page: https://github.com/anucvers/TASS.
</details>
<details>
<summary>摘要</summary>
我们分析了 semantic segmentation 模型对 adversarial attack 的性能，发现源模型生成的 adversarial examples 无法攻击目标模型。即常见的攻击方法，如 PGD 和 FGSM，无法传输到目标模型，因此需要研究可传输的攻击。我们发现两个主要因素可以实现可传输攻击：首先，攻击应该包含有效的数据增强和翻译不变的特征来处理未见模型。其次，稳定的优化策略是必要的，以找到最佳攻击方向。基于以上观察，我们提出了一种 ensemble attack 来实现更有效的攻击和更高的传输性。源代码和实验结果可以通过我们的项目页面：https://github.com/anucvers/TASS 获取。
</details></li>
</ul>
<hr>
<h2 id="Towards-Unbalanced-Motion-Part-Decoupling-Network-for-Video-Portrait-Segmentation"><a href="#Towards-Unbalanced-Motion-Part-Decoupling-Network-for-Video-Portrait-Segmentation" class="headerlink" title="Towards Unbalanced Motion: Part-Decoupling Network for Video Portrait Segmentation"></a>Towards Unbalanced Motion: Part-Decoupling Network for Video Portrait Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16565">http://arxiv.org/abs/2307.16565</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianshu Yu, Changqun Xia, Jia Li</li>
<li>for: 这个研究的目的是为了提高类别视频肖像分割的精度和可靠性，并且提供一个大规模的多scene类别视频肖像分割数据集（MVPS），以便进一步探索这个任务的研究。</li>
<li>methods: 本研究提出了一个名为Part-Decoupling Network（PDNet）的新网络架构，用于解决类别视频肖像分割的问题。PDNet使用了一个内部框架分割器（IPDA）模组，用于不supervised的肖像分割，并且运用了不同的注意力强度来捕捉不同部分的特征。</li>
<li>results: 实验结果显示，PDNet在与现有方法比较之下，实现了类别视频肖像分割的更高精度和可靠性。<details>
<summary>Abstract</summary>
Video portrait segmentation (VPS), aiming at segmenting prominent foreground portraits from video frames, has received much attention in recent years. However, simplicity of existing VPS datasets leads to a limitation on extensive research of the task. In this work, we propose a new intricate large-scale Multi-scene Video Portrait Segmentation dataset MVPS consisting of 101 video clips in 7 scenario categories, in which 10,843 sampled frames are finely annotated at pixel level. The dataset has diverse scenes and complicated background environments, which is the most complex dataset in VPS to our best knowledge. Through the observation of a large number of videos with portraits during dataset construction, we find that due to the joint structure of human body, motion of portraits is part-associated, which leads that different parts are relatively independent in motion. That is, motion of different parts of the portraits is unbalanced. Towards this unbalance, an intuitive and reasonable idea is that different motion states in portraits can be better exploited by decoupling the portraits into parts. To achieve this, we propose a Part-Decoupling Network (PDNet) for video portrait segmentation. Specifically, an Inter-frame Part-Discriminated Attention (IPDA) module is proposed which unsupervisely segments portrait into parts and utilizes different attentiveness on discriminative features specified to each different part. In this way, appropriate attention can be imposed to portrait parts with unbalanced motion to extract part-discriminated correlations, so that the portraits can be segmented more accurately. Experimental results demonstrate that our method achieves leading performance with the comparison to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
视频肖像分割（VPS），targeting at segmenting prominent foreground portraits from video frames, has received much attention in recent years. However, the simplicity of existing VPS datasets leads to a limitation on extensive research of the task. In this work, we propose a new intricate large-scale Multi-scene Video Portrait Segmentation dataset MVPS consisting of 101 video clips in 7 scenario categories, in which 10,843 sampled frames are finely annotated at pixel level. The dataset has diverse scenes and complicated background environments, which is the most complex dataset in VPS to our best knowledge. Through the observation of a large number of videos with portraits during dataset construction, we find that due to the joint structure of human body, the motion of portraits is part-associated, which leads that different parts are relatively independent in motion. That is, the motion of different parts of the portraits is unbalanced. Towards this unbalance, an intuitive and reasonable idea is that different motion states in portraits can be better exploited by decoupling the portraits into parts. To achieve this, we propose a Part-Decoupling Network (PDNet) for video portrait segmentation. Specifically, an Inter-frame Part-Discriminated Attention (IPDA) module is proposed which unsupervisely segments portrait into parts and utilizes different attentiveness on discriminative features specified to each different part. In this way, appropriate attention can be imposed to portrait parts with unbalanced motion to extract part-discriminated correlations, so that the portraits can be segmented more accurately. Experimental results demonstrate that our method achieves leading performance with the comparison to state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Simultaneous-column-based-deep-learning-progression-analysis-of-atrophy-associated-with-AMD-in-longitudinal-OCT-studies"><a href="#Simultaneous-column-based-deep-learning-progression-analysis-of-atrophy-associated-with-AMD-in-longitudinal-OCT-studies" class="headerlink" title="Simultaneous column-based deep learning progression analysis of atrophy associated with AMD in longitudinal OCT studies"></a>Simultaneous column-based deep learning progression analysis of atrophy associated with AMD in longitudinal OCT studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16559">http://arxiv.org/abs/2307.16559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adi Szeskin, Roei Yehuda, Or Shmueli, Jaime Levy, Leo Joskowicz</li>
<li>For: The paper aims to accurately quantify retinal atrophy changes associated with dry age-related macular degeneration (AMD) on longitudinal OCT studies.* Methods: The proposed method uses a novel simultaneous multi-channel column-based deep learning model trained on registered pairs of OCT scans to detect and segment retinal atrophy segments in consecutive OCT scans.* Results: The proposed method achieved a mean atrophy segments detection precision of 0.90+-0.09 and a recall of 0.95+-0.06, outperforming standalone classification methods by 30+-62% and 27+-0% for atrophy segments and lesions.Here is the information in Simplified Chinese text:* For: 这篇论文目的是准确量化慢性肿瘤性macular degeneration (AMD) 相关的肿瘤变化的长期 OCT 图像。* Methods: 提议的方法使用了一种新的同时多通道列深度学习模型，通过注册对 OCT 图像进行训练，以同时检测并分类晚期 OCT 图像中的肿瘤变化。* Results: 提议的方法实现了mean肿瘤变化段检测精度为0.90+-0.09和检测率为0.95+-0.06，比站alone分类方法高出30+-62%和27+-0%。<details>
<summary>Abstract</summary>
Purpose: Disease progression of retinal atrophy associated with AMD requires the accurate quantification of the retinal atrophy changes on longitudinal OCT studies. It is based on finding, comparing, and delineating subtle atrophy changes on consecutive pairs (prior and current) of unregistered OCT scans. Methods: We present a fully automatic end-to-end pipeline for the simultaneous detection and quantification of time-related atrophy changes associated with dry AMD in pairs of OCT scans of a patient. It uses a novel simultaneous multi-channel column-based deep learning model trained on registered pairs of OCT scans that concurrently detects and segments retinal atrophy segments in consecutive OCT scans by classifying light scattering patterns in matched pairs of vertical pixel-wide columns (A-scans) in registered prior and current OCT slices (B-scans). Results: Experimental results on 4,040 OCT slices with 5.2M columns from 40 scans pairs of 18 patients (66% training/validation, 33% testing) with 24.13+-14.0 months apart in which Complete RPE and Outer Retinal Atrophy (cRORA) was identified in 1,998 OCT slices (735 atrophy lesions from 3,732 segments, 0.45M columns) yield a mean atrophy segments detection precision, recall of 0.90+-0.09, 0.95+-0.06 and 0.74+-0.18, 0.94+-0.12 for atrophy lesions with AUC=0.897, all above observer variability. Simultaneous classification outperforms standalone classification precision and recall by 30+-62% and 27+-0% for atrophy segments and lesions. Conclusions: simultaneous column-based detection and quantification of retinal atrophy changes associated with AMD is accurate and outperforms standalone classification methods. Translational relevance: an automatic and efficient way to detect and quantify retinal atrophy changes associated with AMD.
</details>
<details>
<summary>摘要</summary>
目的：检测和评估涂猪病关联Retinal Atrophy的疾病进程，需要精准量化涂猪病变化的longitudinal OCT图像。方法：我们提出了一个完全自动、端到端的管道，可同时检测和评估涂猪病变化的时间相关性。该管道使用了一种新的同时多通道列深度学习模型，通过匹配 registered pairs of OCT图像来同时检测和分割涂猪病变化。结果：我们在4,040个OCT图像中（5.2M列）的40个扫描对（18名患者，66%的训练/验证，33%的测试）中获得了24.13±14.0个月的间隔，并在1,998个OCT图像中（735个涂猪病变化，0.45M列）中发现了735个涂猪病变化。各个涂猪病变化的检测精度和回归率分别为0.90±0.09和0.95±0.06，AUC=0.897。同时分类的精度和回归率分别高于独立分类的精度和回归率 by 30±62%和27±0%。结论：同时列深度学习模型可以准确地检测和评估涂猪病变化关联AMD。翻译意义：一种自动和高效的方法来检测和评估涂猪病变化关联AMD。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Guided-Spatial-Pruning-Architecture-for-Efficient-Frame-Interpolation"><a href="#Uncertainty-Guided-Spatial-Pruning-Architecture-for-Efficient-Frame-Interpolation" class="headerlink" title="Uncertainty-Guided Spatial Pruning Architecture for Efficient Frame Interpolation"></a>Uncertainty-Guided Spatial Pruning Architecture for Efficient Frame Interpolation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16555">http://arxiv.org/abs/2307.16555</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ri Cheng, Xuhao Jiang, Ruian He, Shili Zhou, Weimin Tan, Bo Yan</li>
<li>for: 这个论文的目的是提出一种能够高效地实现视频帧 interpolating的方法，以降低计算量而不影响视觉质量。</li>
<li>methods: 该方法使用了动态空间剔除技术，通过将低不确定性的像素标记为易动区域，以避免无用的计算。此外， authors还提出了一种自动对比分支技术，以提高UGSP的表现。</li>
<li>results: 对比基eline方法，该方法可以减少计算量34%&#x2F;52%&#x2F;30%，并在多个benchmark上达到最佳性能。<details>
<summary>Abstract</summary>
The video frame interpolation (VFI) model applies the convolution operation to all locations, leading to redundant computations in regions with easy motion. We can use dynamic spatial pruning method to skip redundant computation, but this method cannot properly identify easy regions in VFI tasks without supervision. In this paper, we develop an Uncertainty-Guided Spatial Pruning (UGSP) architecture to skip redundant computation for efficient frame interpolation dynamically. Specifically, pixels with low uncertainty indicate easy regions, where the calculation can be reduced without bringing undesirable visual results. Therefore, we utilize uncertainty-generated mask labels to guide our UGSP in properly locating the easy region. Furthermore, we propose a self-contrast training strategy that leverages an auxiliary non-pruning branch to improve the performance of our UGSP. Extensive experiments show that UGSP maintains performance but reduces FLOPs by 34%/52%/30% compared to baseline without pruning on Vimeo90K/UCF101/MiddleBury datasets. In addition, our method achieves state-of-the-art performance with lower FLOPs on multiple benchmarks.
</details>
<details>
<summary>摘要</summary>
视频帧 interpolate (VFI) 模型对所有位置进行 convolution 操作，导致在易动的区域进行重复计算。我们可以使用动态空间剔除方法来快速跳过重复计算，但这种方法无法在 VFI 任务中正确地标识易动区域。在这篇论文中，我们开发了一种不确定性指导的空间剔除 (UGSP) 架构，以便在高效的帧 interpolate 中跳过重复计算。具体来说，具有低不确定性的像素表示易动区域，可以通过减少计算而不会导致视觉效果受损。因此，我们利用不确定性生成的掩码标签来导引我们的 UGSP 在正确的易动区域进行剔除。此外，我们提出了一种自我对比训练策略，通过一个辅助的非剔除分支来提高我们的 UGSP 表现。广泛的实验表明，我们的 UGSP 可以维持性能，同时减少 FLOPs 比基eline 无剔除的34%/52%/30%。此外，我们的方法在多个标准benchmark上实现了最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Towards-General-Visual-Linguistic-Face-Forgery-Detection"><a href="#Towards-General-Visual-Linguistic-Face-Forgery-Detection" class="headerlink" title="Towards General Visual-Linguistic Face Forgery Detection"></a>Towards General Visual-Linguistic Face Forgery Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16545">http://arxiv.org/abs/2307.16545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Sun, Shen Chen, Taiping Yao, Xiaoshuai Sun, Shouhong Ding, Rongrong Ji<br>for:* 这篇论文的目的是提出一种新的脸部 manipulate 检测方法，以满足安全、隐私和信任等问题的需求。methods:* 该方法使用了Visual-Linguistic Face Forgery Detection（VLFFD） paradigm，这种方法使用了细化的 sentence-level prompts 作为标注。* VLFFD 首先使用 Prompt Forgery Image Generator（PFIG）生成杂合的伪造图像，然后将杂合的图像和原始图像一起在 Coarse-and-Fine Co-training 框架中进行联合训练。results:* 实验结果表明，提出的方法可以在一些复杂的 benchmark 上提高现有的检测模型性能。<details>
<summary>Abstract</summary>
Deepfakes are realistic face manipulations that can pose serious threats to security, privacy, and trust. Existing methods mostly treat this task as binary classification, which uses digital labels or mask signals to train the detection model. We argue that such supervisions lack semantic information and interpretability. To address this issues, in this paper, we propose a novel paradigm named Visual-Linguistic Face Forgery Detection(VLFFD), which uses fine-grained sentence-level prompts as the annotation. Since text annotations are not available in current deepfakes datasets, VLFFD first generates the mixed forgery image with corresponding fine-grained prompts via Prompt Forgery Image Generator (PFIG). Then, the fine-grained mixed data and coarse-grained original data and is jointly trained with the Coarse-and-Fine Co-training framework (C2F), enabling the model to gain more generalization and interpretability. The experiments show the proposed method improves the existing detection models on several challenging benchmarks.
</details>
<details>
<summary>摘要</summary>
深层质的假像技术（Deepfakes）可能 pose serious threats to security, privacy, and trust. 现有的方法主要 treated 这个任务为二分类，使用数字标签或面署信号来训练检测模型。我们认为这些超级visions 缺乏semantic information和可读性。为了解决这些问题，在这篇论文中，我们提出了一种新的方法，即视觉语言面假造检测（VLFFD）。VLFFD使用细化的 sentence-level 提示作为annotation。由于现有的深层假像数据集没有文本标注，VLFFD首先使用Prompt Forgery Image Generator (PFIG)生成杂合假造图像和对应的细化提示。然后，杂合的混合数据和原始数据jointly 在Coarse-and-Fine Co-training framework (C2F)中训练，使模型能够更好地泛化和解释。实验结果表明，提出的方法可以提高现有的检测模型在一些复杂的benchmark上的性能。
</details></li>
</ul>
<hr>
<h2 id="On-Transferability-of-Driver-Observation-Models-from-Simulated-to-Real-Environments-in-Autonomous-Cars"><a href="#On-Transferability-of-Driver-Observation-Models-from-Simulated-to-Real-Environments-in-Autonomous-Cars" class="headerlink" title="On Transferability of Driver Observation Models from Simulated to Real Environments in Autonomous Cars"></a>On Transferability of Driver Observation Models from Simulated to Real Environments in Autonomous Cars</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16543">http://arxiv.org/abs/2307.16543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Walter Morales-Alvarez, Novel Certad, Alina Roitberg, Rainer Stiefelhagen, Cristina Olaverri-Monreal</li>
<li>for: 这篇论文探讨了将模拟数据传递到实际驾驶场景中的可能性，尤其是在自动驾驶领域中，模拟数据frequently用于训练因为安全问题。</li>
<li>methods: 本文使用了真实自动驾驶条件下的数据采集，并采用了Inflated 3D ConvNet（I3D）模型和Gradient-weighted Class Activation Mapping（Grad-CAM）来进行详细的模型决策分析。</li>
<li>results: 虽然模拟器上的模型表现出色，但在实际驾驶场景下，其识别率降低到46.6%，并且不同的行为类型之间存在强烈的变化。这说明了模型传输性能的挑战，并促进了我们研究更加鲜明的驾驶者观察系统，能够满足实际驾驶场景中的需求。<details>
<summary>Abstract</summary>
For driver observation frameworks, clean datasets collected in controlled simulated environments often serve as the initial training ground. Yet, when deployed under real driving conditions, such simulator-trained models quickly face the problem of distributional shifts brought about by changing illumination, car model, variations in subject appearances, sensor discrepancies, and other environmental alterations.   This paper investigates the viability of transferring video-based driver observation models from simulation to real-world scenarios in autonomous vehicles, given the frequent use of simulation data in this domain due to safety issues. To achieve this, we record a dataset featuring actual autonomous driving conditions and involving seven participants engaged in highly distracting secondary activities. To enable direct SIM to REAL transfer, our dataset was designed in accordance with an existing large-scale simulator dataset used as the training source. We utilize the Inflated 3D ConvNet (I3D) model, a popular choice for driver observation, with Gradient-weighted Class Activation Mapping (Grad-CAM) for detailed analysis of model decision-making. Though the simulator-based model clearly surpasses the random baseline, its recognition quality diminishes, with average accuracy dropping from 85.7% to 46.6%. We also observe strong variations across different behavior classes. This underscores the challenges of model transferability, facilitating our research of more robust driver observation systems capable of dealing with real driving conditions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Echoes-Beyond-Points-Unleashing-the-Power-of-Raw-Radar-Data-in-Multi-modality-Fusion"><a href="#Echoes-Beyond-Points-Unleashing-the-Power-of-Raw-Radar-Data-in-Multi-modality-Fusion" class="headerlink" title="Echoes Beyond Points: Unleashing the Power of Raw Radar Data in Multi-modality Fusion"></a>Echoes Beyond Points: Unleashing the Power of Raw Radar Data in Multi-modality Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16532">http://arxiv.org/abs/2307.16532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Liu, Feng Wang, Naiyan Wang, Zhaoxiang Zhang</li>
<li>for: 提高雷达探测性能，使其与其他感知器进行深度融合。</li>
<li>methods: 跳过现有的雷达信号处理管道，直接将雷达原始数据与其他感知器进行融合。使用鸟瞰视图（BEV）查询和雷达谱特征来实现。</li>
<li>results: 与现有方法相比，方法可以更好地利用雷达回射信号中的距离和速度准确信息，并且与图像中的 semantics信息进行深度融合，在RADIal数据集上表现出优于所有exist方法，并且接近LiDAR的性能。<details>
<summary>Abstract</summary>
Radar is ubiquitous in autonomous driving systems due to its low cost and good adaptability to bad weather. Nevertheless, the radar detection performance is usually inferior because its point cloud is sparse and not accurate due to the poor azimuth and elevation resolution. Moreover, point cloud generation algorithms already drop weak signals to reduce the false targets which may be suboptimal for the use of deep fusion. In this paper, we propose a novel method named EchoFusion to skip the existing radar signal processing pipeline and then incorporate the radar raw data with other sensors. Specifically, we first generate the Bird's Eye View (BEV) queries and then take corresponding spectrum features from radar to fuse with other sensors. By this approach, our method could utilize both rich and lossless distance and speed clues from radar echoes and rich semantic clues from images, making our method surpass all existing methods on the RADIal dataset, and approach the performance of LiDAR. Codes will be available upon acceptance.
</details>
<details>
<summary>摘要</summary>
“射频是自动驾驶系统中 ubique 的，主要因为它的成本低廉且能够适应不好的天气。然而，射频检测性能通常较差，因为它的点云 sparse 且不精准，主要是因为射频的方位和高度分辨率差。此外，点云生成算法通常会删除弱信号以减少假目标，这可能不是最佳的选择 для深度融合。在这篇论文中，我们提出了一种名为 EchoFusion 的新方法，它可以跳过现有的射频信号处理管线，然后与其他感知器进行融合。具体来说，我们首先生成 Bird's Eye View（BEV）查询，然后从射频中抽出相应的 спектル特征，与其他感知器进行融合。这种方法可以利用射频类推的丰富和无损距离和速度帮助，同时也可以充分利用图像的丰富semantic帮助，使我们的方法在 RADIal 数据集上超越所有现有的方法，并且接近 LiDAR 的性能。codes 将会在接受时发布。”
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-and-Computer-Vision-for-Glaucoma-Detection-A-Review"><a href="#Deep-Learning-and-Computer-Vision-for-Glaucoma-Detection-A-Review" class="headerlink" title="Deep Learning and Computer Vision for Glaucoma Detection: A Review"></a>Deep Learning and Computer Vision for Glaucoma Detection: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16528">http://arxiv.org/abs/2307.16528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mona Ashtari-Majlan, Mohammad Mahdi Dehshibi, David Masip</li>
<li>for: 这篇论文旨在探讨人工智能在诊断眼内压病中的应用，尤其是使用计算机视觉和深度学习方法进行自动诊断。</li>
<li>methods: 这篇论文综述了最近几年关于眼内压病诊断的人工智能研究，包括基于眼球图像、光子同步图像和视场图像的方法，并分析了不同的建筑学派别和源代码的影响。</li>
<li>results: 经过对广泛使用的公共数据集进行检验，这篇论文显示了不同方法之间的总体性能差异、不确定性估计和多模态融合问题，同时还提到了数据集的缺陷和限制。<details>
<summary>Abstract</summary>
Glaucoma is the leading cause of irreversible blindness worldwide and poses significant diagnostic challenges due to its reliance on subjective evaluation. However, recent advances in computer vision and deep learning have demonstrated the potential for automated assessment. In this paper, we survey recent studies on AI-based glaucoma diagnosis using fundus, optical coherence tomography, and visual field images, with a particular emphasis on deep learning-based methods. We provide an updated taxonomy that organizes methods into architectural paradigms and includes links to available source code to enhance the reproducibility of the methods. Through rigorous benchmarking on widely-used public datasets, we reveal performance gaps in generalizability, uncertainty estimation, and multimodal integration. Additionally, our survey curates key datasets while highlighting limitations such as scale, labeling inconsistencies, and bias. We outline open research challenges and detail promising directions for future studies. This survey is expected to be useful for both AI researchers seeking to translate advances into practice and ophthalmologists aiming to improve clinical workflows and diagnosis using the latest AI outcomes.
</details>
<details>
<summary>摘要</summary>
Glaucoma 是全球最主要的不可逆失明病种，但它的诊断却存在一定的主观性问题。然而，最新的计算机视觉和深度学习技术的发展已经显示出了自动诊断的潜力。在这篇文章中，我们对最近的人工智能基于膝盖、Optical coherence tomography和视场图像的 glaucoma 诊断研究进行了评论。我们提供了一个更新的分类方法，将方法分为建筑学派别，并提供了可以重复的源代码链接。通过对广泛使用的公共数据集进行严格的测试，我们揭示了总体化、不确定性估计和多Modal 集成的性能差距。此外，我们还筛选了重要的数据集，并强调了规模、标签不一致和偏见的局限性。我们还详细介绍了未来研究的开放问题，并提出了可能的解决方案。这篇文章预计会对计算机科学家帮助翻译最新的进展，以及医生使用最新的人工智能结果进行诊断。
</details></li>
</ul>
<hr>
<h2 id="Digging-Into-Uncertainty-based-Pseudo-label-for-Robust-Stereo-Matching"><a href="#Digging-Into-Uncertainty-based-Pseudo-label-for-Robust-Stereo-Matching" class="headerlink" title="Digging Into Uncertainty-based Pseudo-label for Robust Stereo Matching"></a>Digging Into Uncertainty-based Pseudo-label for Robust Stereo Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16509">http://arxiv.org/abs/2307.16509</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gallenszl/ucfnet">https://github.com/gallenszl/ucfnet</a></li>
<li>paper_authors: Zhelun Shen, Xibin Song, Yuchao Dai, Dingfu Zhou, Zhibo Rao, Liangjun Zhang</li>
<li>for: 提高深度匹配的跨 dataset 鲁棒性和泛化能力，尤其是在面临着域域异常和数据缺乏的情况下。</li>
<li>methods: 采用像素级 uncertainty 估计来自适应匹配空间，并通过权重学习来逐渐减少不可能的对应关系。另外，提出了基于 uncertainty 的 pseudo-标签方法，用于适应预训练模型到新域，并可以筛选高 uncertainty 像素的预测深度图并生成稀疏 yet 可靠的 pseudo-标签。</li>
<li>results: 实验表明，我们的方法在跨域、适应和共同泛化等方面具有强大的性能，并在 Robust Vision Challenge 2020 中获得了深度匹配任务的第一名。此外，我们的 uncertainty-based pseudo-标签还可以用于无监督的单目深度估计网络训练，并实现了与监督方法相当的性能。代码将在 <a target="_blank" rel="noopener" href="https://github.com/gallenszl/UCFNet">https://github.com/gallenszl/UCFNet</a> 上提供。<details>
<summary>Abstract</summary>
Due to the domain differences and unbalanced disparity distribution across multiple datasets, current stereo matching approaches are commonly limited to a specific dataset and generalize poorly to others. Such domain shift issue is usually addressed by substantial adaptation on costly target-domain ground-truth data, which cannot be easily obtained in practical settings. In this paper, we propose to dig into uncertainty estimation for robust stereo matching. Specifically, to balance the disparity distribution, we employ a pixel-level uncertainty estimation to adaptively adjust the next stage disparity searching space, in this way driving the network progressively prune out the space of unlikely correspondences. Then, to solve the limited ground truth data, an uncertainty-based pseudo-label is proposed to adapt the pre-trained model to the new domain, where pixel-level and area-level uncertainty estimation are proposed to filter out the high-uncertainty pixels of predicted disparity maps and generate sparse while reliable pseudo-labels to align the domain gap. Experimentally, our method shows strong cross-domain, adapt, and joint generalization and obtains \textbf{1st} place on the stereo task of Robust Vision Challenge 2020. Additionally, our uncertainty-based pseudo-labels can be extended to train monocular depth estimation networks in an unsupervised way and even achieves comparable performance with the supervised methods. The code will be available at https://github.com/gallenszl/UCFNet.
</details>
<details>
<summary>摘要</summary>
Due to the differences in domains and unbalanced distribution of disparities across multiple datasets, current stereo matching methods are often limited to a specific dataset and generalize poorly to others. To address this issue, we typically rely on substantial adaptation using costly target-domain ground-truth data, which is not easily accessible in practical settings. In this paper, we propose to explore uncertainty estimation for robust stereo matching. Specifically, we employ pixel-level uncertainty estimation to adaptively adjust the next stage disparity searching space, thereby driving the network to progressively prune out the space of unlikely correspondences. Additionally, we propose an uncertainty-based pseudo-label to adapt the pre-trained model to a new domain, using pixel-level and area-level uncertainty estimation to filter out high-uncertainty pixels of predicted disparity maps and generate sparse yet reliable pseudo-labels to bridge the domain gap. Our experiments show strong cross-domain, adaptive, and joint generalization, with our method achieving \textbf{1st} place on the stereo task of Robust Vision Challenge 2020. Furthermore, our uncertainty-based pseudo-labels can be extended to train monocular depth estimation networks in an unsupervised manner, achieving comparable performance with supervised methods. The code will be available at https://github.com/gallenszl/UCFNet.
</details></li>
</ul>
<hr>
<h2 id="Towards-General-Low-Light-Raw-Noise-Synthesis-and-Modeling"><a href="#Towards-General-Low-Light-Raw-Noise-Synthesis-and-Modeling" class="headerlink" title="Towards General Low-Light Raw Noise Synthesis and Modeling"></a>Towards General Low-Light Raw Noise Synthesis and Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16508">http://arxiv.org/abs/2307.16508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fengzhang427/LRD">https://github.com/fengzhang427/LRD</a></li>
<li>paper_authors: Feng Zhang, Bin Xu, Zhiqiang Li, Xinran Liu, Qingbo Lu, Changxin Gao, Nong Sang</li>
<li>for: 提供一种基于物理和学习的低光照环境下隐藏噪声模型，以满足计算摄影和图像处理应用的需求。</li>
<li>methods: 通过将信号依赖和信号独立噪声分别用物理和学习模型来模拟，以实现一个通用的模型，可以同时学习不同ISO水平的噪声特征并对各种感知器进行泛化。</li>
<li>results: 对于低光照环境下的隐藏噪声，我们的方法可以具有高度的同准化能力，并且在不同感知器上进行了广泛的比较，结果表明我们的方法在噪声降减方面与状态之前的方法进行了比较。<details>
<summary>Abstract</summary>
Modeling and synthesizing low-light raw noise is a fundamental problem for computational photography and image processing applications. Although most recent works have adopted physics-based models to synthesize noise, the signal-independent noise in low-light conditions is far more complicated and varies dramatically across camera sensors, which is beyond the description of these models. To address this issue, we introduce a new perspective to synthesize the signal-independent noise by a generative model. Specifically, we synthesize the signal-dependent and signal-independent noise in a physics- and learning-based manner, respectively. In this way, our method can be considered as a general model, that is, it can simultaneously learn different noise characteristics for different ISO levels and generalize to various sensors. Subsequently, we present an effective multi-scale discriminator termed Fourier transformer discriminator (FTD) to distinguish the noise distribution accurately. Additionally, we collect a new low-light raw denoising (LRD) dataset for training and benchmarking. Qualitative validation shows that the noise generated by our proposed noise model can be highly similar to the real noise in terms of distribution. Furthermore, extensive denoising experiments demonstrate that our method performs favorably against state-of-the-art methods on different sensors.
</details>
<details>
<summary>摘要</summary>
<<SYS>>模型和生成低光环境中的原始噪声是计算摄影和图像处理应用的基本问题。虽然大多数最近的工作采用物理基于的模型来生成噪声，但低光环境中的噪声却是非常复杂且异常强变，这超出了这些模型的描述范围。为解决这个问题，我们引入一新的视角来生成噪声。具体来说，我们同时生成噪声的信号依赖和不依赖部分，通过物理和学习基础来实现。这样，我们的方法可以视为一种通用模型，即可同时学习不同ISO水平的噪声特性，并且可以通过不同感知器进行普适化。然后，我们提出了一种有效的多尺度滤波器，即福泽transformer滤波器（FTD），以便准确地分辨噪声分布。此外，我们收集了一个新的低光 raw denoising（LRD）数据集，用于训练和测试。qualitative验证表明，生成的噪声与实际噪声的分布高度相似。此外，我们对不同感知器进行了广泛的排除实验，结果显示，我们的方法与当前状态革方法相比，在不同感知器上表现出优异的效果。
</details></li>
</ul>
<hr>
<h2 id="A-hybrid-approach-for-improving-U-Net-variants-in-medical-image-segmentation"><a href="#A-hybrid-approach-for-improving-U-Net-variants-in-medical-image-segmentation" class="headerlink" title="A hybrid approach for improving U-Net variants in medical image segmentation"></a>A hybrid approach for improving U-Net variants in medical image segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16462">http://arxiv.org/abs/2307.16462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aitik Gupta, Dr. Joydip Dhar</li>
<li>for: 这项研究的目的是降低网络参数的需求，以保持一些医疗影像分割任务的性能，如皮肤损害分割使用注意系统和循环连接。</li>
<li>methods: 这项研究使用了深度分解 convolutions 和注意系统，以及循环连接来降低网络参数的需求，同时保持一些医疗影像分割任务的性能。</li>
<li>results: 研究表明，使用深度分解 convolutions 和注意系统，以及循环连接可以降低网络参数的需求，同时保持一些医疗影像分割任务的性能。<details>
<summary>Abstract</summary>
Medical image segmentation is vital to the area of medical imaging because it enables professionals to more accurately examine and understand the information offered by different imaging modalities. The technique of splitting a medical image into various segments or regions of interest is known as medical image segmentation. The segmented images that are produced can be used for many different things, including diagnosis, surgery planning, and therapy evaluation.   In initial phase of research, major focus has been given to review existing deep-learning approaches, including researches like MultiResUNet, Attention U-Net, classical U-Net, and other variants. The attention feature vectors or maps dynamically add important weights to critical information, and most of these variants use these to increase accuracy, but the network parameter requirements are somewhat more stringent. They face certain problems such as overfitting, as their number of trainable parameters is very high, and so is their inference time.   Therefore, the aim of this research is to reduce the network parameter requirements using depthwise separable convolutions, while maintaining performance over some medical image segmentation tasks such as skin lesion segmentation using attention system and residual connections.
</details>
<details>
<summary>摘要</summary>
医疗影像分割是医疗影像领域的关键技术，它使得专业人员可以更加准确地检查和理解不同的影像模式中提供的信息。这种技术的核心是将医疗影像分割成不同的区域或 interess 点。生成的分割图像可以用于诊断、手术规划和治疗评估等多种应用。在初期研究阶段，主要关注了现有的深度学习方法，包括MultiResUNet、Attention U-Net、传统的U-Net和其他变种。这些方法使用注意力特征向量或地图来动态添加重要权重，以提高准确性。然而，这些网络的参数需求较高，导致过拟合和执行时间较长。因此，本研究的目标是通过深度分割 convolution 来降低网络参数需求，保持一定的性能水平，而不是全面替换现有的深度学习方法。特别是在医疗影像分割任务中，如皮肤病变分割使用注意力系统和 residual connections。
</details></li>
</ul>
<hr>
<h2 id="MovieChat-From-Dense-Token-to-Sparse-Memory-for-Long-Video-Understanding"><a href="#MovieChat-From-Dense-Token-to-Sparse-Memory-for-Long-Video-Understanding" class="headerlink" title="MovieChat: From Dense Token to Sparse Memory for Long Video Understanding"></a>MovieChat: From Dense Token to Sparse Memory for Long Video Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16449">http://arxiv.org/abs/2307.16449</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rese1f/MovieChat">https://github.com/rese1f/MovieChat</a></li>
<li>paper_authors: Enxin Song, Wenhao Chai, Guanhong Wang, Yucheng Zhang, Haoyang Zhou, Feiyang Wu, Xun Guo, Tian Ye, Yan Lu, Jenq-Neng Hwang, Gaoang Wang</li>
<li>for: 用于建立一个可以处理长视频的视频理解系统，推翻特定预先定义的视觉任务的局限性。</li>
<li>methods: 使用视频基础模型和大语言模型，并开发了一种基于Atkinson-Shiffrin记忆模型的记忆机制，包括快速更新的短期记忆和可持续的长期记忆。使用Transformers中的 токен作为记忆载体。</li>
<li>results: 实现了长视频理解的州OF-the-art表现。<details>
<summary>Abstract</summary>
Recently, integrating video foundation models and large language models to build a video understanding system overcoming the limitations of specific pre-defined vision tasks. Yet, existing systems can only handle videos with very few frames. For long videos, the computation complexity, memory cost, and long-term temporal connection are the remaining challenges. Inspired by Atkinson-Shiffrin memory model, we develop an memory mechanism including a rapidly updated short-term memory and a compact thus sustained long-term memory. We employ tokens in Transformers as the carriers of memory. MovieChat achieves state-of-the-art performace in long video understanding.
</details>
<details>
<summary>摘要</summary>
最近，我们尝试将视频基础模型和大型语言模型结合，以建立一个能够涵盖具体定义的视频理解系统，超越特定预定的视觉任务的限制。然而，现有系统只能处理很少帧数的视频。长视频处理中的计算复杂度、内存成本和长期时间连接仍然是挑战。受阿特金逊-希夫里南记忆模型启发，我们开发了一种快速更新的短期记忆机制和一种可减少的长期记忆机制。我们使用Transformers中的标识符作为记忆载体。我们的MovieChat实现了长视频理解的州际级表现。
</details></li>
</ul>
<hr>
<h2 id="Interactive-Neural-Painting"><a href="#Interactive-Neural-Painting" class="headerlink" title="Interactive Neural Painting"></a>Interactive Neural Painting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16441">http://arxiv.org/abs/2307.16441</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pukacheen/MagicBrush">https://github.com/pukacheen/MagicBrush</a></li>
<li>paper_authors: Elia Peruzzo, Willi Menapace, Vidit Goel, Federica Arrigoni, Hao Tang, Xingqian Xu, Arman Chopikyan, Nikita Orlov, Yuxiao Hu, Humphrey Shi, Nicu Sebe, Elisa Ricci</li>
<li>for: 这篇论文的目的是提出一种可以帮助用户创作的计算机机器人技术，帮助用户在绘画时提供下一步的笔触建议。</li>
<li>methods: 该方法基于一种 conditional transformer Variational AutoEncoder（VAE）架构，并在两个阶段中进行解码。</li>
<li>results: 我们的实验结果表明，我们的方法可以提供好的笔触建议，并与现有技术相比，表现更好。<details>
<summary>Abstract</summary>
In the last few years, Neural Painting (NP) techniques became capable of producing extremely realistic artworks. This paper advances the state of the art in this emerging research domain by proposing the first approach for Interactive NP. Considering a setting where a user looks at a scene and tries to reproduce it on a painting, our objective is to develop a computational framework to assist the users creativity by suggesting the next strokes to paint, that can be possibly used to complete the artwork. To accomplish such a task, we propose I-Paint, a novel method based on a conditional transformer Variational AutoEncoder (VAE) architecture with a two-stage decoder. To evaluate the proposed approach and stimulate research in this area, we also introduce two novel datasets. Our experiments show that our approach provides good stroke suggestions and compares favorably to the state of the art. Additional details, code and examples are available at https://helia95.github.io/inp-website.
</details>
<details>
<summary>摘要</summary>
最近几年，神经油画（NP）技术已经能够生成极其真实的艺术作品。这篇论文推动这个新兴研究领域的状态机器人，我们提出了首个互动神经油画（I-Paint）方法。在用户看到场景并尝试通过油画复制它的情况下，我们的目标是开发一个计算机框架，以帮助用户创作性的提高，并提供可能用于完成艺术作品的下一拍建议。为实现这个目标，我们提出了一种基于条件变换器Variational AutoEncoder（VAE）架构的新方法。为评估我们的方法和激发这个领域的研究，我们还提出了两个新的数据集。我们的实验表明，我们的方法可以提供好的拍建议，并与当前状态机器人相比较好。详细信息、代码和示例可以在https://helia95.github.io/inp-website上找到。
</details></li>
</ul>
<hr>
<h2 id="Towards-Head-Computed-Tomography-Image-Reconstruction-Standardization-with-Deep-Learning-Assisted-Automatic-Detection"><a href="#Towards-Head-Computed-Tomography-Image-Reconstruction-Standardization-with-Deep-Learning-Assisted-Automatic-Detection" class="headerlink" title="Towards Head Computed Tomography Image Reconstruction Standardization with Deep Learning Assisted Automatic Detection"></a>Towards Head Computed Tomography Image Reconstruction Standardization with Deep Learning Assisted Automatic Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16440">http://arxiv.org/abs/2307.16440</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bowen Zheng, Chenxi Huang, Yuemei Luo</li>
<li>for: 提高头部Computed Tomography（CT）图像三维重建的精度和重复性，以便更加准确地诊断。</li>
<li>methods: 使用深度学习基于对象检测算法，自动检测和评估 orbitomeatal 线标志，以 reformatting 图像 перед reconstruction。</li>
<li>results: 比较了十种对象检测算法的精度、效率和Robustness，选择了轻量级的 YOLOv8，其 mAP 为 92.91%，并通过标准化重建结果的质量评估，证明方法的临床实用性和有效性。<details>
<summary>Abstract</summary>
Three-dimensional (3D) reconstruction of head Computed Tomography (CT) images elucidates the intricate spatial relationships of tissue structures, thereby assisting in accurate diagnosis. Nonetheless, securing an optimal head CT scan without deviation is challenging in clinical settings, owing to poor positioning by technicians, patient's physical constraints, or CT scanner tilt angle restrictions. Manual formatting and reconstruction not only introduce subjectivity but also strain time and labor resources. To address these issues, we propose an efficient automatic head CT images 3D reconstruction method, improving accuracy and repeatability, as well as diminishing manual intervention. Our approach employs a deep learning-based object detection algorithm, identifying and evaluating orbitomeatal line landmarks to automatically reformat the images prior to reconstruction. Given the dearth of existing evaluations of object detection algorithms in the context of head CT images, we compared ten methods from both theoretical and experimental perspectives. By exploring their precision, efficiency, and robustness, we singled out the lightweight YOLOv8 as the aptest algorithm for our task, with an mAP of 92.91% and impressive robustness against class imbalance. Our qualitative evaluation of standardized reconstruction results demonstrates the clinical practicability and validity of our method.
</details>
<details>
<summary>摘要</summary>
三维重建头部计算机断层影像（CT）图可以描述脏器结构的细节关系，从而帮助精准诊断。然而，在临床 Settings中获得优质头部CT扫描数据 без deviation 是困难的，因为技术人员的位置不准确、病人的物理限制或CT扫描器的倾斜角度限制。手动格式化和重建不仅引入主观性，还占用了时间和劳动资源。为解决这些问题，我们提出了一种高效的自动头部CT图三维重建方法，提高精度和重复性，同时减少手动干预。我们的方法使用深度学习基于对象检测算法，通过识别和评估颈部线标记来自动重新格式化图像，以便在重建前进行三维重建。由于现有对头部CT图像的对象检测算法的评估缺乏，我们对十种算法进行了 teoretic 和实验性的比较。通过探索它们的精度、效率和Robustness，我们选择了轻量级的 YOLOv8，其MAP为 92.91%，并且在类偏oshadow 下表现出了很好的Robustness。我们的质量评估表示我们的方法在临床实践中是有效的和有效性。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Out-of-distribution-Objects-Using-Neuron-Activation-Patterns"><a href="#Detecting-Out-of-distribution-Objects-Using-Neuron-Activation-Patterns" class="headerlink" title="Detecting Out-of-distribution Objects Using Neuron Activation Patterns"></a>Detecting Out-of-distribution Objects Using Neuron Activation Patterns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16433">http://arxiv.org/abs/2307.16433</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/safednn-group/naptron">https://github.com/safednn-group/naptron</a></li>
<li>paper_authors: Bartłomiej Olber, Krystian Radlak, Krystian Chachuła, Jakub Łyskawa, Piotr Frątczak</li>
<li>for: 实时物类检测中的OOD检测问题</li>
<li>methods: 基于Neuron Activation PaTteRns的OOD检测方法</li>
<li>results: 在两个不同的OOD情况下和三种物类检测器上，我们的方法具有比顶对ID性能的优化和高准确率的OOD检测能力。<details>
<summary>Abstract</summary>
Object detection is essential to many perception algorithms used in modern robotics applications. Unfortunately, the existing models share a tendency to assign high confidence scores for out-of-distribution (OOD) samples. Although OOD detection has been extensively studied in recent years by the computer vision (CV) community, most proposed solutions apply only to the image recognition task. Real-world applications such as perception in autonomous vehicles struggle with far more complex challenges than classification. In our work, we focus on the prevalent field of object detection, introducing Neuron Activation PaTteRns for out-of-distribution samples detection in Object detectioN (NAPTRON). Performed experiments show that our approach outperforms state-of-the-art methods, without the need to affect in-distribution (ID) performance. By evaluating the methods in two distinct OOD scenarios and three types of object detectors we have created the largest open-source benchmark for OOD object detection.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:对象检测是现代 робо特性应用中非常重要的算法之一。然而，现有的模型往往对异distribution（OOD）样本分配高信任分数。CV社区在过去几年内对OOD检测进行了广泛的研究，但大多数提出的解决方案仅适用于图像识别任务。实际应用中，如自动驾驶车辆的感知系统，面临着远远超出类别检测的复杂挑战。在我们的工作中，我们将注意力集中在对象检测领域，并提出了基于神经元活动的Patterns for Out-of-Distribution Sample Detection in Object detectioN（NAPTRON）。我们的方法在现有的方法中表现出色，不需要影响类别内样本（ID）的性能。我们在两个不同的OOD场景中和三种对象检测器进行了实验，创建了最大的开源benchmark дляOOD对象检测。
</details></li>
</ul>
<hr>
<h2 id="High-Dynamic-Range-Image-Reconstruction-via-Deep-Explicit-Polynomial-Curve-Estimation"><a href="#High-Dynamic-Range-Image-Reconstruction-via-Deep-Explicit-Polynomial-Curve-Estimation" class="headerlink" title="High Dynamic Range Image Reconstruction via Deep Explicit Polynomial Curve Estimation"></a>High Dynamic Range Image Reconstruction via Deep Explicit Polynomial Curve Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16426">http://arxiv.org/abs/2307.16426</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jqtangust/epce-hdr">https://github.com/jqtangust/epce-hdr</a></li>
<li>paper_authors: Jiaqi Tang, Xiaogang Xu, Sixing Hu, Ying-Cong Chen</li>
<li>for: 解决限制了摄像机的镜头能力，数字图像通常有更窄的动态闪光范围，从而降低了图像的真实性。</li>
<li>methods: 提出了高动态范围（HDR）重建技术，以回归更好地表示实际场景。但是，由于不同的物理捕捉参数，图像和实际闪光范围之间的对应关系非常复杂，这使得HDR重建变得极其困难。现有的解决方案无法直接确定图像和实际闪光范围之间的对应关系，但这种关系在重建HDR图像时非常重要。</li>
<li>results: 我们提出了一种方法，可以直接估计图像和实际闪光范围之间的对应关系，并在一个网络中确定HDR图像。首先，根据闪光范围的特点，我们构建了一个模型，用多项式描述闪光范围的趋势。使用学习网络来估计这些系数。这个曲线会自动根据低动态范围图像的闪光空间自动调整，并重建实际的HDR图像。此外，由于现有的 dataset 没有提供图像和实际闪光范围之间的对应关系，我们构建了一个新的 dataset，包括 sintetic 和实际图像。广泛的实验显示，我们的方法可以在不同的闪光范围下进行极其好的普适性和高性能。<details>
<summary>Abstract</summary>
Due to limited camera capacities, digital images usually have a narrower dynamic illumination range than real-world scene radiance. To resolve this problem, High Dynamic Range (HDR) reconstruction is proposed to recover the dynamic range to better represent real-world scenes. However, due to different physical imaging parameters, the tone-mapping functions between images and real radiance are highly diverse, which makes HDR reconstruction extremely challenging. Existing solutions can not explicitly clarify a corresponding relationship between the tone-mapping function and the generated HDR image, but this relationship is vital when guiding the reconstruction of HDR images. To address this problem, we propose a method to explicitly estimate the tone mapping function and its corresponding HDR image in one network. Firstly, based on the characteristics of the tone mapping function, we construct a model by a polynomial to describe the trend of the tone curve. To fit this curve, we use a learnable network to estimate the coefficients of the polynomial. This curve will be automatically adjusted according to the tone space of the Low Dynamic Range (LDR) image, and reconstruct the real HDR image. Besides, since all current datasets do not provide the corresponding relationship between the tone mapping function and the LDR image, we construct a new dataset with both synthetic and real images. Extensive experiments show that our method generalizes well under different tone-mapping functions and achieves SOTA performance.
</details>
<details>
<summary>摘要</summary>
First, based on the characteristics of the tone mapping function, we construct a model using a polynomial to describe the trend of the tone curve. To fit this curve, we use a learnable network to estimate the coefficients of the polynomial. This curve will be automatically adjusted according to the tone space of the Low Dynamic Range (LDR) image and reconstruct the real HDR image.Moreover, since all current datasets do not provide the corresponding relationship between the tone mapping function and the LDR image, we construct a new dataset with both synthetic and real images. Extensive experiments show that our method generalizes well under different tone-mapping functions and achieves state-of-the-art performance.
</details></li>
</ul>
<hr>
<h2 id="DRAW-Defending-Camera-shooted-RAW-against-Image-Manipulation"><a href="#DRAW-Defending-Camera-shooted-RAW-against-Image-Manipulation" class="headerlink" title="DRAW: Defending Camera-shooted RAW against Image Manipulation"></a>DRAW: Defending Camera-shooted RAW against Image Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16418">http://arxiv.org/abs/2307.16418</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoxiao Hu, Qichao Ying, Zhenxing Qian, Sheng Li, Xinpeng Zhang</li>
<li>for: 保护图像免受修改和欺诈。</li>
<li>methods: 利用多频部分融合网络（MPF-Net）和隐藏水印技术，将修改和欺诈信息写入RAW数据中。</li>
<li>results: 对多个著名RAW数据集进行了广泛的实验，并达到了高度的鲁棒性和精度。<details>
<summary>Abstract</summary>
RAW files are the initial measurement of scene radiance widely used in most cameras, and the ubiquitously-used RGB images are converted from RAW data through Image Signal Processing (ISP) pipelines. Nowadays, digital images are risky of being nefariously manipulated. Inspired by the fact that innate immunity is the first line of body defense, we propose DRAW, a novel scheme of defending images against manipulation by protecting their sources, i.e., camera-shooted RAWs. Specifically, we design a lightweight Multi-frequency Partial Fusion Network (MPF-Net) friendly to devices with limited computing resources by frequency learning and partial feature fusion. It introduces invisible watermarks as protective signal into the RAW data. The protection capability can not only be transferred into the rendered RGB images regardless of the applied ISP pipeline, but also is resilient to post-processing operations such as blurring or compression. Once the image is manipulated, we can accurately identify the forged areas with a localization network. Extensive experiments on several famous RAW datasets, e.g., RAISE, FiveK and SIDD, indicate the effectiveness of our method. We hope that this technique can be used in future cameras as an option for image protection, which could effectively restrict image manipulation at the source.
</details>
<details>
<summary>摘要</summary>
原始的RAW文件是现场辐射广泛使用的初始测量数据，而通用的RGB图像则是将RAW数据转换成through Image Signal Processing（ISP）管道。然而，在数字图像成为常用的现象以来，digital images have become susceptible to malicious manipulation. 以体内免疫系统为灵感，我们提出了一种新的图像防 manipulation 方案，即保护图像的来源，即摄像机拍摄的RAW数据。特别是，我们设计了一种轻量级的多频部分融合网络（MPF-Net），该网络适合具有有限的计算资源的设备，通过频率学习和部分特征融合来实现轻量级的性能。MPF-Net在RAW数据中引入不可见的水印，以保护图像免受辐射、压缩等后处理操作的攻击。如果图像被修改，我们可以使用一个本地化网络来准确地定位forge areas。我们在许多知名的RAW数据集，例如RAISE、FiveK和SIDD上进行了广泛的实验，结果表明我们的方法的有效性。我们希望这种技术可以在未来的摄像机中作为图像保护的选项，以防止图像修改在源头级别。
</details></li>
</ul>
<hr>
<h2 id="MRA-GNN-Minutiae-Relation-Aware-Model-over-Graph-Neural-Network-for-Fingerprint-Embedding"><a href="#MRA-GNN-Minutiae-Relation-Aware-Model-over-Graph-Neural-Network-for-Fingerprint-Embedding" class="headerlink" title="MRA-GNN: Minutiae Relation-Aware Model over Graph Neural Network for Fingerprint Embedding"></a>MRA-GNN: Minutiae Relation-Aware Model over Graph Neural Network for Fingerprint Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16416">http://arxiv.org/abs/2307.16416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yapeng Su, Tong Zhao, Zicheng Zhang</li>
<li>for: 本研究旨在提高Automated Fingerprint Identification Systems中的指纹嵌入，使用Graph Neural Network (GNN)模型来利用指纹非结构数据，如指纹 topology和相关性，以提高嵌入的可识别性和稳定性。</li>
<li>methods: 我们提出了一种新的指纹嵌入方法，即Minutiae Relation-Aware model over Graph Neural Network (MRA-GNN)。MRA-GNN使用GNN模型来编码指纹的 topology和相关性，将指纹数据转换为图像，并通过Topological relation Reasoning Module (TRM)和Correlation-Aware Module (CAM)来学习指纹嵌入。为了解决GNN模型中的过拟合问题，我们还在MRA-GNN中添加了Feed-Forward Module和图像差分连接。</li>
<li>results: 我们的实验结果表明，MRA-GNN比前些state-of-the-art方法在多个指纹数据集上表现更好， indicating that our approach can effectively exploit the nonstructural information of fingerprints.<details>
<summary>Abstract</summary>
Deep learning has achieved remarkable results in fingerprint embedding, which plays a critical role in modern Automated Fingerprint Identification Systems. However, previous works including CNN-based and Transformer-based approaches fail to exploit the nonstructural data, such as topology and correlation in fingerprints, which is essential to facilitate the identifiability and robustness of embedding. To address this challenge, we propose a novel paradigm for fingerprint embedding, called Minutiae Relation-Aware model over Graph Neural Network (MRA-GNN). Our proposed approach incorporates a GNN-based framework in fingerprint embedding to encode the topology and correlation of fingerprints into descriptive features, achieving fingerprint representation in the form of graph embedding. Specifically, we reinterpret fingerprint data and their relative connections as vertices and edges respectively, and introduce a minutia graph and fingerprint graph to represent the topological relations and correlation structures of fingerprints. We equip MRA-GNN with a Topological relation Reasoning Module (TRM) and Correlation-Aware Module (CAM) to learn the fingerprint embedding from these graphs successfully. To tackle the over-smoothing problem in GNN models, we incorporate Feed-Forward Module and graph residual connections into proposed modules. The experimental results demonstrate that our proposed approach outperforms state-of-the-art methods on various fingerprint datasets, indicating the effectiveness of our approach in exploiting nonstructural information of fingerprints.
</details>
<details>
<summary>摘要</summary>
深度学习在指纹嵌入中取得了杰出的成果，这对现代自动指纹识别系统plays a critical role。然而，过去的方法，包括CNN和Transformer的方法，失去了非结构数据，如指纹图形和指纹之间的相关性，这些数据对实现嵌入的可识别性和稳定性至关重要。为解决这个挑战，我们提出了一种新的嵌入模型，called Minutiae Relation-Aware model over Graph Neural Network (MRA-GNN)。我们的提议方法将指纹嵌入编码为图形特征，通过在GNN基础上的框架来表示指纹图形和相关性结构。 Specifically，我们将指纹数据和其相对连接看作为顶点和边分别，并将指纹图形和指纹相关结构表示为指纹图和指纹图。我们在MRA-GNN中引入Topological relation Reasoning Module (TRM)和Correlation-Aware Module (CAM)来学习指纹嵌入。为解决GNN模型中的过拟合问题，我们将Feed-Forward Module和图 residual connections incorporated into proposed modules。实验结果表明，我们的提议方法在多个指纹数据集上比州前方法表现出色，这表明我们的方法可以成功地利用指纹非结构数据。
</details></li>
</ul>
<hr>
<h2 id="DDG-Net-Discriminability-Driven-Graph-Network-for-Weakly-supervised-Temporal-Action-Localization"><a href="#DDG-Net-Discriminability-Driven-Graph-Network-for-Weakly-supervised-Temporal-Action-Localization" class="headerlink" title="DDG-Net: Discriminability-Driven Graph Network for Weakly-supervised Temporal Action Localization"></a>DDG-Net: Discriminability-Driven Graph Network for Weakly-supervised Temporal Action Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16415">http://arxiv.org/abs/2307.16415</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaojuntang22/iccv2023-ddgnet">https://github.com/xiaojuntang22/iccv2023-ddgnet</a></li>
<li>paper_authors: Xiaojun Tang, Junsong Fan, Chuanchen Luo, Zhaoxiang Zhang, Man Zhang, Zongyuan Yang</li>
<li>for: 强度监督的时间动作地图标识 (WTAL) 是一个实用又挑战的任务。大规模数据集的存在使得大多数现有方法使用其他数据集中预训网络提取特征，但这些特征并不适合WTAL。</li>
<li>methods: 为了解决这个问题，研究人员设计了多个模组来强化特征，其中包括时间关联模组，对于本地化模组的性能提高。然而，所有的模组都忽略了ambiguous信息的不良影响，这会导致其他特征的减少可识别性。</li>
<li>results: 我们提出了Discriminability-Driven Graph Network (DDG-Net)，它明确地表示ambiguous snippet和特征可识别的 snippet之间的关联，避免了ambiguous信息的传递，并提高了对单位特征的可识别性。此外，我们提出了特征一致损失，以防止特征的融合和导引几何网络生成更加特征化的表示。实验结果显示DDG-Net在THUMOS14和ActivityNet1.2标准 benchmark上实现了新的州Of-The-Art结果，证明了DDG-Net的效果。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/XiaojunTang22/ICCV2023-DDGNet%7D">https://github.com/XiaojunTang22/ICCV2023-DDGNet}</a> 上获得。<details>
<summary>Abstract</summary>
Weakly-supervised temporal action localization (WTAL) is a practical yet challenging task. Due to large-scale datasets, most existing methods use a network pretrained in other datasets to extract features, which are not suitable enough for WTAL. To address this problem, researchers design several modules for feature enhancement, which improve the performance of the localization module, especially modeling the temporal relationship between snippets. However, all of them neglect the adverse effects of ambiguous information, which would reduce the discriminability of others. Considering this phenomenon, we propose Discriminability-Driven Graph Network (DDG-Net), which explicitly models ambiguous snippets and discriminative snippets with well-designed connections, preventing the transmission of ambiguous information and enhancing the discriminability of snippet-level representations. Additionally, we propose feature consistency loss to prevent the assimilation of features and drive the graph convolution network to generate more discriminative representations. Extensive experiments on THUMOS14 and ActivityNet1.2 benchmarks demonstrate the effectiveness of DDG-Net, establishing new state-of-the-art results on both datasets. Source code is available at \url{https://github.com/XiaojunTang22/ICCV2023-DDGNet}.
</details>
<details>
<summary>摘要</summary>
《弱监督时间动作地标（WTAL）是一项实用又挑战性的任务。由于大规模数据集，大多数现有方法使用已经在其他数据集中预训练的网络提取特征，这些特征并不适合WTAL。为解决这个问题，研究人员设计了多个模块用于特征提高，这些模块可以提高地标模块的性能，特别是模elling时间关系 между片断。然而，所有这些方法均忽视了ambiguous信息的副作用，这会减少其他表示的可 distinguishability。 considering这种现象，我们提出了Discriminability-Driven Graph Network（DDG-Net），该网络Explicitly模型了ambiguous片断和 discriminative片断的Well-designed connections，防止了ambiguous信息的传递，并提高了片断级别表示的可 distinguishability。此外，我们还提出了特征一致损失，以防止特征的同化和驱动图 convolution网络生成更加 discriminative的表示。extensive experiments on THUMOS14和ActivityNet1.2 benchmarks表明DDG-Net的效果，创造了新的state-of-the-art result on both datasets。source code可以在 \url{https://github.com/XiaojunTang22/ICCV2023-DDGNet} 中找到。
</details></li>
</ul>
<hr>
<h2 id="RCS-YOLO-A-Fast-and-High-Accuracy-Object-Detector-for-Brain-Tumor-Detection"><a href="#RCS-YOLO-A-Fast-and-High-Accuracy-Object-Detector-for-Brain-Tumor-Detection" class="headerlink" title="RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection"></a>RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16412">http://arxiv.org/abs/2307.16412</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mkang315/rcs-yolo">https://github.com/mkang315/rcs-yolo</a></li>
<li>paper_authors: Ming Kang, Chee-Ming Ting, Fung Fung Ting, Raphaël C. -W. Phan<br>for: Brain tumor detectionmethods:* Proposed a novel YOLO architecture with Reparameterized Convolution based on channel Shuffle (RCS-YOLO)* Introduced Reparameterized Convolution (RCS) and One-Shot Aggregation of RCS (RCS-OSA) to extract richer information and reduce time consumptionresults:* Surpassed YOLOv6, YOLOv7, and YOLOv8 in speed and accuracy on the brain tumor dataset Br35H* Improved precision by 2.6% and inference speed by 60% compared to YOLOv7* Achieved state-of-the-art performance on brain tumor detection taskHere’s the simplified Chinese version:for: 脑肿检测methods:* 提出了一种基于通道拼接的YOLO架构（RCS-YOLO）* 引入了Reparameterized Convolution（RCS）和One-Shot Aggregation of RCS（RCS-OSA）来提取更多的信息并降低计算时间results:* 在脑肿数据集Br35H上超过了YOLOv6、YOLOv7和YOLOv8的速度和准确率* 相比YOLOv7，RCS-YOLO提高了精度2.6%，并降低了计算速度60%* 实现了脑肿检测任务的state-of-the-art性<details>
<summary>Abstract</summary>
With an excellent balance between speed and accuracy, cutting-edge YOLO frameworks have become one of the most efficient algorithms for object detection. However, the performance of using YOLO networks is scarcely investigated in brain tumor detection. We propose a novel YOLO architecture with Reparameterized Convolution based on channel Shuffle (RCS-YOLO). We present RCS and a One-Shot Aggregation of RCS (RCS-OSA), which link feature cascade and computation efficiency to extract richer information and reduce time consumption. Experimental results on the brain tumor dataset Br35H show that the proposed model surpasses YOLOv6, YOLOv7, and YOLOv8 in speed and accuracy. Notably, compared with YOLOv7, the precision of RCS-YOLO improves by 2.6%, and the inference speed by 60% at 114.8 images detected per second (FPS). Our proposed RCS-YOLO achieves state-of-the-art performance on the brain tumor detection task. The code is available at https://github.com/mkang315/RCS-YOLO.
</details>
<details>
<summary>摘要</summary>
使用 cutting-edge YOLO 框架的协议，可以实现一个极高效的对象检测。然而，使用 YOLO 网络在脑肿检测中的性能尚未得到足够的研究。我们提出了一种新的 YOLO 架构，即 Reparameterized Convolution based on channel Shuffle (RCS-YOLO)。我们还提出了一种 One-Shot Aggregation of RCS (RCS-OSA)，它将 feature cascade 和计算效率联系起来，以提取更多的信息并降低计算时间。我们在 Br35H 脑肿数据集上进行了实验，结果显示，我们的提posed模型在速度和准确性两个方面都超过了 YOLOv6、YOLOv7 和 YOLOv8。尤其是比 YOLOv7，我们的 RCS-YOLO 模型的精度提高了 2.6%，并且在 114.8 帧每秒 (FPS) 的检测速度上提高了 60%。我们的提posed RCS-YOLO 模型在脑肿检测任务中达到了国际顶尖的性能。代码可以在 <https://github.com/mkang315/RCS-YOLO> 上下载。
</details></li>
</ul>
<hr>
<h2 id="HiREN-Towards-Higher-Supervision-Quality-for-Better-Scene-Text-Image-Super-Resolution"><a href="#HiREN-Towards-Higher-Supervision-Quality-for-Better-Scene-Text-Image-Super-Resolution" class="headerlink" title="HiREN: Towards Higher Supervision Quality for Better Scene Text Image Super-Resolution"></a>HiREN: Towards Higher Supervision Quality for Better Scene Text Image Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16410">http://arxiv.org/abs/2307.16410</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minyi Zhao, Yi Xu, Bingjia Li, Jie Wang, Jihong Guan, Shuigeng Zhou</li>
<li>for: 提高文本识别率，solve the problem of low-resolution scene images affecting text recognition.</li>
<li>methods: 提出了一种新的STISR框架，called High-Resolution ENhancement（HiREN），which consists of two branches and a quality estimation module. The first branch is used to recover LR images, and the other is an HR quality enhancement branch that aims to generate HQ text images based on HR images.</li>
<li>results: 在TextZoom dataset上进行了广泛的实验，结果表明HiREN可以与大多数现有的STISR方法结合使用，并显著提高它们的性能。<details>
<summary>Abstract</summary>
Scene text image super-resolution (STISR) is an important pre-processing technique for text recognition from low-resolution scene images. Nowadays, various methods have been proposed to extract text-specific information from high-resolution (HR) images to supervise STISR model training. However, due to uncontrollable factors (e.g. shooting equipment, focus, and environment) in manually photographing HR images, the quality of HR images cannot be guaranteed, which unavoidably impacts STISR performance. Observing the quality issue of HR images, in this paper we propose a novel idea to boost STISR by first enhancing the quality of HR images and then using the enhanced HR images as supervision to do STISR. Concretely, we develop a new STISR framework, called High-Resolution ENhancement (HiREN) that consists of two branches and a quality estimation module. The first branch is developed to recover the low-resolution (LR) images, and the other is an HR quality enhancement branch aiming at generating high-quality (HQ) text images based on the HR images to provide more accurate supervision to the LR images. As the degradation from HQ to HR may be diverse, and there is no pixel-level supervision for HQ image generation, we design a kernel-guided enhancement network to handle various degradation, and exploit the feedback from a recognizer and text-level annotations as weak supervision signal to train the HR enhancement branch. Then, a quality estimation module is employed to evaluate the qualities of HQ images, which are used to suppress the erroneous supervision information by weighting the loss of each image. Extensive experiments on TextZoom show that HiREN can work well with most existing STISR methods and significantly boost their performances.
</details>
<details>
<summary>摘要</summary>
Scene文本图像超解像(STISR)是识别文本从低分辨率Scene图像前置处理技术中的重要一环。目前，许多方法已经被提出来提取高分辨率(HR)图像中特有的文本信息，以供STISR模型训练。然而，由于手动拍摄HR图像的因素（如摄影设备、 фокус和环境）的不可控，HR图像的质量无法保证，这会不可避免地影响STISR性能。 observe到HR图像质量问题，在这篇论文中，我们提出了一个新的想法，即首先提高HR图像的质量，然后使用提高后的HR图像作为STISR模型训练的超vision。具体来说，我们开发了一个新的STISR框架，called High-Resolution ENhancement（HiREN），它包括两个分支和一个质量评估模块。第一个分支是用于恢复低分辨率(LR)图像，另一个是一个HR质量提高分支，旨在基于HR图像生成高质量(HQ)文本图像，以供更准确的超vision。由于HR到HQ的降低可能有多种，而且没有像素级supervision的HR图像生成，我们设计了一个核心准导提高网络，用于处理多种降低，并利用recognizer和文本级别的回归信号作为弱supervision信号来训练HR增强分支。然后，我们使用质量评估模块评估HQ图像的质量，并将其用于抑制错误的超vision信息。extensive experiments show that HiREN can work well with most existing STISR methods and significantly boost their performances.
</details></li>
</ul>
<hr>
<h2 id="Visual-Captioning-at-Will-Describing-Images-and-Videos-Guided-by-a-Few-Stylized-Sentences"><a href="#Visual-Captioning-at-Will-Describing-Images-and-Videos-Guided-by-a-Few-Stylized-Sentences" class="headerlink" title="Visual Captioning at Will: Describing Images and Videos Guided by a Few Stylized Sentences"></a>Visual Captioning at Will: Describing Images and Videos Guided by a Few Stylized Sentences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16399">http://arxiv.org/abs/2307.16399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dingyi Yang, Hongyu Chen, Xinglin Hou, Tiezheng Ge, Yuning Jiang, Qin Jin</li>
<li>for: 这个研究旨在生成具有具体类型和情感的图像或影片描述，以增加它们的吸引力和情感适宜性。</li>
<li>methods: 我们提出了一个名为FS-StyleCap的框架，它使用一个可条件预测语言模型和一个可视投影模组。我们采用了两步训练方案：首先，我们将训练一个类型抽象器，以生成不同类型的概率表示。然后，我们将这个抽象器免费化，让我们的预测器根据提取的类型特征和可视内容特征来生成具有欲要的类型的描述。</li>
<li>results: 我们的自动评估结果显示，我们的模型在几何扩展中表现出色，与已有的方法相比，并且在几何上具有较高的内在一致性。人工评价也证明了我们的模型可以处理多种类型。<details>
<summary>Abstract</summary>
Stylized visual captioning aims to generate image or video descriptions with specific styles, making them more attractive and emotionally appropriate. One major challenge with this task is the lack of paired stylized captions for visual content, so most existing works focus on unsupervised methods that do not rely on parallel datasets. However, these approaches still require training with sufficient examples that have style labels, and the generated captions are limited to predefined styles. To address these limitations, we explore the problem of Few-Shot Stylized Visual Captioning, which aims to generate captions in any desired style, using only a few examples as guidance during inference, without requiring further training. We propose a framework called FS-StyleCap for this task, which utilizes a conditional encoder-decoder language model and a visual projection module. Our two-step training scheme proceeds as follows: first, we train a style extractor to generate style representations on an unlabeled text-only corpus. Then, we freeze the extractor and enable our decoder to generate stylized descriptions based on the extracted style vector and projected visual content vectors. During inference, our model can generate desired stylized captions by deriving the style representation from user-supplied examples. Our automatic evaluation results for few-shot sentimental visual captioning outperform state-of-the-art approaches and are comparable to models that are fully trained on labeled style corpora. Human evaluations further confirm our model s ability to handle multiple styles.
</details>
<details>
<summary>摘要</summary>
现代化的视觉描述目标是生成具有特定风格的图像或视频描述，使其更加吸引人和情感上更加适当。然而，该任务的一个主要挑战是缺乏协调的风格描述数据集，因此大多数现有的方法都是不需要平行数据集的不监督方法。然而，这些方法仍然需要训练具有足够的示例，并且生成的描述仅限于预定的风格。为解决这些限制，我们研究了几何风格视觉描述问题，该问题的目标是在描述过程中根据用户提供的少量示例生成任何风格的描述。我们提出了一个名为FS-StyleCap的框架来解决这个问题，该框架使用了决定性编码器-解码语言模型和视觉投影模块。我们的两步训练方案如下：首先，我们训练一个风格抽象器，以生成无标签文本 Corpora 上的风格表示。然后，我们冻结抽象器，并使我们的解码器基于抽象器生成风格表示和投影到视觉内容 vectors 的描述。在推断过程中，我们的模型可以根据用户提供的示例生成所需的风格描述。我们的自动评估结果表明，我们的方法在几何风格视觉描述任务中比 state-of-the-art 方法更高的评价结果，并且与完全在标注风格 Corpora 上训练的模型相当。人工评估还证明了我们的模型能够处理多种风格。
</details></li>
</ul>
<hr>
<h2 id="JOTR-3D-Joint-Contrastive-Learning-with-Transformers-for-Occluded-Human-Mesh-Recovery"><a href="#JOTR-3D-Joint-Contrastive-Learning-with-Transformers-for-Occluded-Human-Mesh-Recovery" class="headerlink" title="JOTR: 3D Joint Contrastive Learning with Transformers for Occluded Human Mesh Recovery"></a>JOTR: 3D Joint Contrastive Learning with Transformers for Occluded Human Mesh Recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16377">http://arxiv.org/abs/2307.16377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xljh0520/jotr">https://github.com/xljh0520/jotr</a></li>
<li>paper_authors: Jiahao Li, Zongxin Yang, Xiaohan Wang, Jianxin Ma, Chang Zhou, Yi Yang</li>
<li>for: 3D human mesh recovery from a single image under obscured conditions</li>
<li>methods: 3D JOint contrastive learning with TRansformers (JOTR) framework, including an encoder-decoder transformer architecture and a novel 3D joint contrastive learning approach</li>
<li>results: outperforms state-of-the-art competitors on both occlusion-specific and standard benchmarks, significantly improving the reconstruction of occluded humansHere is the Simplified Chinese version of the information:</li>
<li>for: 3D人体三维重建从单张图像下的遮盲条件</li>
<li>methods: 3D JOint contrastive learning with TRansformers (JOTR)框架，包括encoder-decoder transformer架构和一种新的3D JOINT contrastive learning方法</li>
<li>results: 超越了现有竞争对手在 occlusion-specific 和标准 Benchmark 上的表现，显著改善遮盲人体重建<details>
<summary>Abstract</summary>
In this study, we focus on the problem of 3D human mesh recovery from a single image under obscured conditions. Most state-of-the-art methods aim to improve 2D alignment technologies, such as spatial averaging and 2D joint sampling. However, they tend to neglect the crucial aspect of 3D alignment by improving 3D representations. Furthermore, recent methods struggle to separate the target human from occlusion or background in crowded scenes as they optimize the 3D space of target human with 3D joint coordinates as local supervision. To address these issues, a desirable method would involve a framework for fusing 2D and 3D features and a strategy for optimizing the 3D space globally. Therefore, this paper presents 3D JOint contrastive learning with TRansformers (JOTR) framework for handling occluded 3D human mesh recovery. Our method includes an encoder-decoder transformer architecture to fuse 2D and 3D representations for achieving 2D$\&$3D aligned results in a coarse-to-fine manner and a novel 3D joint contrastive learning approach for adding explicitly global supervision for the 3D feature space. The contrastive learning approach includes two contrastive losses: joint-to-joint contrast for enhancing the similarity of semantically similar voxels (i.e., human joints), and joint-to-non-joint contrast for ensuring discrimination from others (e.g., occlusions and background). Qualitative and quantitative analyses demonstrate that our method outperforms state-of-the-art competitors on both occlusion-specific and standard benchmarks, significantly improving the reconstruction of occluded humans.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们关注在单张图像下面临遮盲的3D人体 mesh 恢复问题。大多数当前的方法都是提高2D对齐技术，如空间平均和2D关节采样。然而，它们往往忽略了3D对齐的重要性，而且最近的方法在拥挤场景中很难分别人体和遮挡物或背景，因为它们在3D空间中优化目标人体的3D关节坐标作为本地监督。为解决这些问题，一个理想的方法应该包括一个混合2D和3D特征的框架，以及一种全球化优化3D空间的策略。因此，这篇论文提出了基于转换器的3D JOint contrastive learning（JOTR）框架，用于处理遮盲3D人体 mesh 恢复问题。我们的方法包括一个编码器-解码器转换器架构，用于在粗细化到细化的方式下混合2D和3D表示，以及一种新的3D关节对比学习方法，用于在3D特征空间中添加显式全球化监督。对比学习方法包括两种对比损失：关节到关节对比，用于提高相似的人体关节之间的相似性，以及关节到非关节对比，用于确保与其他物体（例如遮挡物和背景）的区分。qualitative和quantitative分析表明，我们的方法在遮盲人体 benchmark 上表现出色，与当前的竞争对手相比，显著提高了遮盲人体的重建。
</details></li>
</ul>
<hr>
<h2 id="MobileVidFactory-Automatic-Diffusion-Based-Social-Media-Video-Generation-for-Mobile-Devices-from-Text"><a href="#MobileVidFactory-Automatic-Diffusion-Based-Social-Media-Video-Generation-for-Mobile-Devices-from-Text" class="headerlink" title="MobileVidFactory: Automatic Diffusion-Based Social Media Video Generation for Mobile Devices from Text"></a>MobileVidFactory: Automatic Diffusion-Based Social Media Video Generation for Mobile Devices from Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16371">http://arxiv.org/abs/2307.16371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junchen Zhu, Huan Yang, Wenjing Wang, Huiguo He, Zixi Tuo, Yongsheng Yu, Wen-Huang Cheng, Lianli Gao, Jingkuan Song, Jianlong Fu, Jiebo Luo</li>
<li>for: 用于自动生成高质量垂直手机视频，让用户只需提供简单的文本来创建视频。</li>
<li>methods: 使用预训练的图像扩散模型，并对其进行修改，以生成高质量的开源频域垂直视频生成器。对音频，我们从我们的大型数据库中提取合适的背景声音。此外，我们还允许用户添加特定的屏幕文本来增强视觉表达，并选择自定义的语音。</li>
<li>results: 通过我们的系统，用户可以轻松地创建高质量的垂直手机视频，无需特殊的技术知识或专业技能。<details>
<summary>Abstract</summary>
Videos for mobile devices become the most popular access to share and acquire information recently. For the convenience of users' creation, in this paper, we present a system, namely MobileVidFactory, to automatically generate vertical mobile videos where users only need to give simple texts mainly. Our system consists of two parts: basic and customized generation. In the basic generation, we take advantage of the pretrained image diffusion model, and adapt it to a high-quality open-domain vertical video generator for mobile devices. As for the audio, by retrieving from our big database, our system matches a suitable background sound for the video. Additionally to produce customized content, our system allows users to add specified screen texts to the video for enriching visual expression, and specify texts for automatic reading with optional voices as they like.
</details>
<details>
<summary>摘要</summary>
mobile devices 的视频成为最近最受欢迎的信息分享和获取方式。为了便利用户创建，在这篇论文中，我们提出了一个系统，即 MobileVidFactory，可以自动生成高质量的垂直式移动视频，只需要用户提供简单的文本。我们的系统包括两部分：基本生成和个性化生成。在基本生成部分，我们利用预训练的图像扩散模型，并将其适应为高质量的开源频段 vertical video 生成器。对于音频，我们从我们大型数据库中提取合适的背景音乐，并将其匹配到视频中。此外，为了生成个性化内容，我们的系统允许用户添加自定义的屏幕文本，以激发视觉表达，并选择自定义的语音和读音。
</details></li>
</ul>
<hr>
<h2 id="Workshop-on-Document-Intelligence-Understanding"><a href="#Workshop-on-Document-Intelligence-Understanding" class="headerlink" title="Workshop on Document Intelligence Understanding"></a>Workshop on Document Intelligence Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16369">http://arxiv.org/abs/2307.16369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soyeon Caren Han, Yihao Ding, Siwen Luo, Josiah Poon, HeeGuen Yoon, Zhe Huang, Paul Duuring, Eun Jung Holden</li>
<li>for: 本研讨会的目的是推动自动文档处理和理解技术的发展，以满足不同领域（如商业、法律和医学）中大量文档处理中的效率提升。</li>
<li>methods: 本研讨会将吸引来自文档智能和理解领域的研究人员和产业开发者，以推动多种文档类型的自动处理和理解技术的发展。</li>
<li>results: 本研讨会还发布了基于PDFVQA数据集的文档答案挑战，以测试提出的模型在全文档水平的结构和上下文理解能力。这种任务可以帮助提升文档理解步骤，从单页水平升级到全文档水平理解。<details>
<summary>Abstract</summary>
Document understanding and information extraction include different tasks to understand a document and extract valuable information automatically. Recently, there has been a rising demand for developing document understanding among different domains, including business, law, and medicine, to boost the efficiency of work that is associated with a large number of documents. This workshop aims to bring together researchers and industry developers in the field of document intelligence and understanding diverse document types to boost automatic document processing and understanding techniques. We also released a data challenge on the recently introduced document-level VQA dataset, PDFVQA. The PDFVQA challenge examines the structural and contextual understandings of proposed models on the natural full document level of multiple consecutive document pages by including questions with a sequence of answers extracted from multi-pages of the full document. This task helps to boost the document understanding step from the single-page level to the full document level understanding.
</details>
<details>
<summary>摘要</summary>
文档理解和信息提取包括不同任务来理解文档并自动提取有价值信息。最近，在不同领域，如商业、法律和医学等领域，有增加文档理解的需求，以提高大量文档相关的工作效率。这场工作室将帮助研究人员和行业开发人员在文档智能和理解多种文档类型中提高自动文档处理和理解技术。我们还发布了基于最近引入的文档级VQA数据集PDFVQA的数据挑战。PDFVQA挑战测试提出的模型在全文档水平上的结构和文本上下文理解能力，通过从多页全文档中提取多个答案序列来检验模型的文档理解能力。这个任务可以帮助提高文档理解的步骤，从单页水平提升到全文档水平的理解。
</details></li>
</ul>
<hr>
<h2 id="AntGPT-Can-Large-Language-Models-Help-Long-term-Action-Anticipation-from-Videos"><a href="#AntGPT-Can-Large-Language-Models-Help-Long-term-Action-Anticipation-from-Videos" class="headerlink" title="AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"></a>AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16368">http://arxiv.org/abs/2307.16368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Zhao, Ce Zhang, Shijie Wang, Changcheng Fu, Nakul Agarwal, Kwonjoon Lee, Chen Sun</li>
<li>For: The paper is focused on the long-term action anticipation (LTA) task, which involves predicting an actor’s future behavior from video observations. The goal is to improve human-machine interaction.* Methods: The authors propose a two-stage framework called AntGPT, which leverages large language models (LLMs) to help with the LTA task. The first stage recognizes the actions already performed in the observed videos, and the second stage uses an LLM to predict the future actions or infer the goal and plan the whole procedure.* Results: The authors report state-of-the-art performance on several benchmarks, including the Ego4D LTA v1 and v2 benchmarks, EPIC-Kitchens-55, and EGTEA GAZE+. They also demonstrate the effectiveness of their approach through qualitative analysis, showing that AntGPT can successfully infer the goal and perform goal-conditioned “counterfactual” prediction.Here’s the simplified Chinese text for the three points:* For: 这篇论文关注的是长期动作预测任务（LTA），即从视频观察中预测演员的未来行为。目的是提高人机交互。* Methods: 作者们提议一种两个阶段的框架called AntGPT，利用大型语言模型（LLMs）来帮助LTA任务。第一阶段认识视频中已经完成的动作，第二阶段使用LLM预测未来动作或者推理演员的目标并规划整个过程。* Results: 作者们报告了多个benchmark上的州OF-the-art性能，包括Ego4D LTA v1和v2 benchmarks、EPIC-Kitchens-55、EGTEA GAZE+。他们还通过质量分析证明了AntGPT的有效性，表明它可以成功地推理演员的目标并进行目标conditioned “counterfactual” 预测。<details>
<summary>Abstract</summary>
Can we better anticipate an actor's future actions (e.g. mix eggs) by knowing what commonly happens after his/her current action (e.g. crack eggs)? What if we also know the longer-term goal of the actor (e.g. making egg fried rice)? The long-term action anticipation (LTA) task aims to predict an actor's future behavior from video observations in the form of verb and noun sequences, and it is crucial for human-machine interaction. We propose to formulate the LTA task from two perspectives: a bottom-up approach that predicts the next actions autoregressively by modeling temporal dynamics; and a top-down approach that infers the goal of the actor and plans the needed procedure to accomplish the goal. We hypothesize that large language models (LLMs), which have been pretrained on procedure text data (e.g. recipes, how-tos), have the potential to help LTA from both perspectives. It can help provide the prior knowledge on the possible next actions, and infer the goal given the observed part of a procedure, respectively. To leverage the LLMs, we propose a two-stage framework, AntGPT. It first recognizes the actions already performed in the observed videos and then asks an LLM to predict the future actions via conditioned generation, or to infer the goal and plan the whole procedure by chain-of-thought prompting. Empirical results on the Ego4D LTA v1 and v2 benchmarks, EPIC-Kitchens-55, as well as EGTEA GAZE+ demonstrate the effectiveness of our proposed approach. AntGPT achieves state-of-the-art performance on all above benchmarks, and can successfully infer the goal and thus perform goal-conditioned "counterfactual" prediction via qualitative analysis. Code and model will be released at https://brown-palm.github.io/AntGPT
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the given text into Simplified Chinese.<</SYS>>我们可以通过知道actor的当前行为后的共通发展（例如混合蛋）来预测actor的未来行为（例如烫蛋）。如果我们还知道actor的长期目标（例如制作蛋饭），那么长期行为预测（LTA）任务就变得非常重要。我们提议从两个角度来解决LTA任务：一个底层方法是通过模拟时间动力来预测下一个行为；另一个是通过理解actor的目标来规划需要完成目标的过程。我们认为大型自然语言模型（LLM），它们在recipe和how-to文本数据上进行预训练，有可能帮助LTA从两个角度。它可以提供下一个行为的可能性预测，以及基于观察到的部分过程来INFERactor的目标。为了利用LLM，我们提出了一个两个阶段框架，AntGPT。它首先识别视频中已经完成的行为，然后向LLM进行 conditioned generation，或者通过 chain-of-thought prompting来INFERactor的目标和计划整个过程。实验结果表明，AntGPT在Ego4D LTA v1和v2标准测试 benchmark、EPIC-Kitchens-55和EGTEA GAZE+上达到了状态之最好的性能，并可以成功地INFERactor的目标，并通过qualitative分析进行“counterfactual”预测。代码和模型将在https://brown-palm.github.io/AntGPT上发布。
</details></li>
</ul>
<hr>
<h2 id="Multi-modal-Graph-Neural-Network-for-Early-Diagnosis-of-Alzheimer’s-Disease-from-sMRI-and-PET-Scans"><a href="#Multi-modal-Graph-Neural-Network-for-Early-Diagnosis-of-Alzheimer’s-Disease-from-sMRI-and-PET-Scans" class="headerlink" title="Multi-modal Graph Neural Network for Early Diagnosis of Alzheimer’s Disease from sMRI and PET Scans"></a>Multi-modal Graph Neural Network for Early Diagnosis of Alzheimer’s Disease from sMRI and PET Scans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16366">http://arxiv.org/abs/2307.16366</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanteng Zhanga, Xiaohai He, Yi Hao Chan, Qizhi Teng, Jagath C. Rajapakse</li>
<li>for: 这篇论文主要用于早期诊断阿尔ц海默病（AD），使用深度学习模型和多Modal的MRI和PET影像数据。</li>
<li>methods: 本论文提出了使用图形神经网络（GNN）来处理多Modal的MRI和PET影像数据，并将它们与subject的生物 markers（phenotypic information）结合，以提高AD诊断的性能。</li>
<li>results: 实验结果显示， compared to single-modal approaches, 本论文提出的多Modal方法可以提高AD诊断的性能，并且可以将多Modal数据与生物 markers结合，以提高诊断的精度。<details>
<summary>Abstract</summary>
In recent years, deep learning models have been applied to neuroimaging data for early diagnosis of Alzheimer's disease (AD). Structural magnetic resonance imaging (sMRI) and positron emission tomography (PET) images provide structural and functional information about the brain, respectively. Combining these features leads to improved performance than using a single modality alone in building predictive models for AD diagnosis. However, current multi-modal approaches in deep learning, based on sMRI and PET, are mostly limited to convolutional neural networks, which do not facilitate integration of both image and phenotypic information of subjects. We propose to use graph neural networks (GNN) that are designed to deal with problems in non-Euclidean domains. In this study, we demonstrate how brain networks can be created from sMRI or PET images and be used in a population graph framework that can combine phenotypic information with imaging features of these brain networks. Then, we present a multi-modal GNN framework where each modality has its own branch of GNN and a technique is proposed to combine the multi-modal data at both the level of node vectors and adjacency matrices. Finally, we perform late fusion to combine the preliminary decisions made in each branch and produce a final prediction. As multi-modality data becomes available, multi-source and multi-modal is the trend of AD diagnosis. We conducted explorative experiments based on multi-modal imaging data combined with non-imaging phenotypic information for AD diagnosis and analyzed the impact of phenotypic information on diagnostic performance. Results from experiments demonstrated that our proposed multi-modal approach improves performance for AD diagnosis, and this study also provides technical reference and support the need for multivariate multi-modal diagnosis methods.
</details>
<details>
<summary>摘要</summary>
近年来，深度学习模型在 neuroscience 数据中用于早期诊断阿尔茨海默病（AD）。Structural magnetic resonance imaging（sMRI）和 пози트рон发射tomography（PET）图像提供了脑组织结构和功能信息，分别。将这些特征结合使得建立预测模型的性能提高，而不使用单一模式。然而，现有的多Modal approaches在深度学习中，基于 sMRI 和 PET，主要是基于卷积神经网络，这些神经网络不能捕捉图像和subject的phenotypic信息。我们提议使用图 neural networks（GNN），这些神经网络是非欧几何问题的解决方案。在这项研究中，我们将脑网络创建自 sMRI 或 PET 图像，并将其用于人口图案框架，可以结合图像和subject的phenotypic信息。然后，我们提出了一种多Modal GNN 框架，其中每个模式有自己的 GNN 分支，并提出了将多Modal数据在每个分支和连接矩阵水平进行combine的技术。最后，我们进行了晚期融合，将每个分支的初步决策相互融合，生成最终预测。随着多Modal数据的普及，多源多Modal是阿尔茨海默病诊断的趋势。我们根据多Modal 图像和非图像phenotypic信息进行了探索性实验，分析了影响诊断性能的非图像信息。实验结果表明，我们提议的多Modal方法可以提高阿尔茨海默病诊断性能，这也提供了技术参考，支持多变量多Modal诊断方法的需求。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-and-Analyzing-Robust-Point-Cloud-Recognition-Bag-of-Tricks-for-Defending-Adversarial-Examples"><a href="#Benchmarking-and-Analyzing-Robust-Point-Cloud-Recognition-Bag-of-Tricks-for-Defending-Adversarial-Examples" class="headerlink" title="Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples"></a>Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16361">http://arxiv.org/abs/2307.16361</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qiufan319/benchmark_pc_attack">https://github.com/qiufan319/benchmark_pc_attack</a></li>
<li>paper_authors: Qiufan Ji, Lin Wang, Cong Shi, Shengshan Hu, Yingying Chen, Lichao Sun</li>
<li>for: 本研究旨在提高深度神经网络（DNNs）在3D点云识别 tasks 中的鲁棒性，因为这些任务在面对 adversarial examples 时容易受到威胁。</li>
<li>methods: 我们首先建立了一个完整、严格的点云 adversarial robustness 评估标准，以便更好地理解防御和攻击方法的效果。然后，我们收集了现有的点云 adversarial defense 技巧，并进行了广泛的系统性实验，以identify一个有效的组合这些技巧。最后，我们提出了一种hybrid training augmentation方法，考虑了不同类型的点云 adversarial examples，并将其加到了 adversarial training 中，以提高鲁棒性。</li>
<li>results: 我们的方法可以在面对多种攻击时保持83.45%的平均准确率， demonstrating its capability to enabling robust learners。我们的代码库在：\url{<a target="_blank" rel="noopener" href="https://github.com/qiufan319/benchmark_pc_attack.git%7D%E3%80%82">https://github.com/qiufan319/benchmark_pc_attack.git}。</a><details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) for 3D point cloud recognition are vulnerable to adversarial examples, threatening their practical deployment. Despite the many research endeavors have been made to tackle this issue in recent years, the diversity of adversarial examples on 3D point clouds makes them more challenging to defend against than those on 2D images. For examples, attackers can generate adversarial examples by adding, shifting, or removing points. Consequently, existing defense strategies are hard to counter unseen point cloud adversarial examples. In this paper, we first establish a comprehensive, and rigorous point cloud adversarial robustness benchmark to evaluate adversarial robustness, which can provide a detailed understanding of the effects of the defense and attack methods. We then collect existing defense tricks in point cloud adversarial defenses and then perform extensive and systematic experiments to identify an effective combination of these tricks. Furthermore, we propose a hybrid training augmentation methods that consider various types of point cloud adversarial examples to adversarial training, significantly improving the adversarial robustness. By combining these tricks, we construct a more robust defense framework achieving an average accuracy of 83.45\% against various attacks, demonstrating its capability to enabling robust learners. Our codebase are open-sourced on: \url{https://github.com/qiufan319/benchmark_pc_attack.git}.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）用于3D点云识别是易受到攻击的，这 threatening其实际应用。尽管在过去几年内有很多研究努力以counter这种issue,但3D点云上的攻击者可以通过添加、移动或 removing points来生成攻击示例，使得现有的防御策略很难counter未看到的点云攻击示例。在这篇论文中，我们首先建立了一个完整、严格的点云攻击robustness benchmark，以评估防御robustness，这可以为我们提供更好的理解防御和攻击方法的效果。然后，我们收集了现有的点云防御技巧，并进行了广泛和系统的实验，以确定有效的组合方法。此外，我们提议了一种混合培育方法，考虑了不同类型的点云攻击示例，并将其与 adversarial training 结合使用，以提高防御robustness。通过这些技巧的组合，我们建立了一个更加robust的防御框架，实现了83.45%的平均准确率， demonstrating its ability to enable robust learners。我们的代码库将在：\url{https://github.com/qiufan319/benchmark_pc_attack.git} 中开源。
</details></li>
</ul>
<hr>
<h2 id="Cardiac-MRI-Orientation-Recognition-and-Standardization-using-Deep-Neural-Networks"><a href="#Cardiac-MRI-Orientation-Recognition-and-Standardization-using-Deep-Neural-Networks" class="headerlink" title="Cardiac MRI Orientation Recognition and Standardization using Deep Neural Networks"></a>Cardiac MRI Orientation Recognition and Standardization using Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00615">http://arxiv.org/abs/2308.00615</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rxzhen/mscmr-orient">https://github.com/rxzhen/mscmr-orient</a></li>
<li>paper_authors: Ruoxuan Zhen</li>
<li>for: 本研究旨在提高医疗影像处理任务的效果，通过深度学习方法实现Orientation认识和预测。</li>
<li>methods: 本文提出了一种基于深度神经网络的Orientation认识和标准化方法，并采用了传输学习策略以适应多种MRI序列和模式。</li>
<li>results: 经过了广泛的实验， validate accuracy achieved were 100.0%, 100.0%, and 99.4%, demonstrating the robustness and effectiveness of our model。Note: The abstract is in English, and the information points are in Simplified Chinese.<details>
<summary>Abstract</summary>
Orientation recognition and standardization play a crucial role in the effectiveness of medical image processing tasks. Deep learning-based methods have proven highly advantageous in orientation recognition and prediction tasks. In this paper, we address the challenge of imaging orientation in cardiac MRI and present a method that employs deep neural networks to categorize and standardize the orientation. To cater to multiple sequences and modalities of MRI, we propose a transfer learning strategy, enabling adaptation of our model from a single modality to diverse modalities. We conducted comprehensive experiments on CMR images from various modalities, including bSSFP, T2, and LGE. The validation accuracies achieved were 100.0\%, 100.0\%, and 99.4\%, confirming the robustness and effectiveness of our model. Our source code and network models are available at https://github.com/rxzhen/MSCMR-orient
</details>
<details>
<summary>摘要</summary>
医疗影像处理任务中，orientation认识和标准化具有关键作用。深度学习基于方法在orientation认识和预测任务中表现出了高度优势。本文关注卡ди亚MRI影像orientation的挑战，并提出了使用深度神经网络来分类和标准化orientation。针对多种模式和模式的MRI影像，我们提议了转移学习策略，以适应多种模式的适应。我们在不同模式的CMR影像上进行了广泛的实验，包括bSSFP、T2和LGE模式。我们所得到的验证精度分别为100.0%、100.0%和99.4%，这confirm了我们的模型的稳定性和有效性。我们的源代码和网络模型可以在https://github.com/rxzhen/MSCMR-orient上获取。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Learning-of-Gait-Based-Biomarkers"><a href="#Self-Supervised-Learning-of-Gait-Based-Biomarkers" class="headerlink" title="Self-Supervised Learning of Gait-Based Biomarkers"></a>Self-Supervised Learning of Gait-Based Biomarkers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16321">http://arxiv.org/abs/2307.16321</a></li>
<li>repo_url: None</li>
<li>paper_authors: R. James Cotton, J. D. Peiffer, Kunal Shah, Allison DeLillo, Anthony Cimorelli, Shawana Anarwala, Kayan Abdou, Tasos Karakostas</li>
<li>for: 这个论文的目的是为了提取基于Markerless Motion Capture（MMC）的步态分析中最有价值的信息。</li>
<li>methods: 这篇论文使用了自动预导学习（SSL）技术，特别是对比学习和 causal masking，来学习有用的步态表示。</li>
<li>results: 研究发现，对于不注释的步态数据进行对比学习可以学习出具有临床意义的步态表示，并且可以用来诊断和评估rehabilitation therapy的效果。<details>
<summary>Abstract</summary>
Markerless motion capture (MMC) is revolutionizing gait analysis in clinical settings by making it more accessible, raising the question of how to extract the most clinically meaningful information from gait data. In multiple fields ranging from image processing to natural language processing, self-supervised learning (SSL) from large amounts of unannotated data produces very effective representations for downstream tasks. However, there has only been limited use of SSL to learn effective representations of gait and movement, and it has not been applied to gait analysis with MMC. One SSL objective that has not been applied to gait is contrastive learning, which finds representations that place similar samples closer together in the learned space. If the learned similarity metric captures clinically meaningful differences, this could produce a useful representation for many downstream clinical tasks. Contrastive learning can also be combined with causal masking to predict future timesteps, which is an appealing SSL objective given the dynamical nature of gait. We applied these techniques to gait analyses performed with MMC in a rehabilitation hospital from a diverse clinical population. We find that contrastive learning on unannotated gait data learns a representation that captures clinically meaningful information. We probe this learned representation using the framework of biomarkers and show it holds promise as both a diagnostic and response biomarker, by showing it can accurately classify diagnosis from gait and is responsive to inpatient therapy, respectively. We ultimately hope these learned representations will enable predictive and prognostic gait-based biomarkers that can facilitate precision rehabilitation through greater use of MMC to quantify movement in rehabilitation.
</details>
<details>
<summary>摘要</summary>
无标记动作跟踪（MMC）在医学设置中革命化了步态分析，使其更加可 accessible，提出了如何从步态数据中提取最有价值的临床信息的问题。在多个领域，从图像处理到自然语言处理，无监督学习（SSL）从大量无注释数据中生成了非常有效的下游任务表示。然而，在步态和运动方面尚未广泛使用SSL学习有效表示，而且尚未应用到MMC步态分析中。一个尚未应用到步态的SSL目标是对比学习，它找到类似样本在学习空间中更近的方法。如果学习的相似度量表示临床有意义的差异，这将生成有用的下游临床任务表示。对比学习还可以与 causal 遮盾来预测未来时间步骤，这是一个有appeal的SSL目标，因为步态具有动态特征。我们对医疗机构中从多样化临床人口进行的MMC步态分析进行了应用。我们发现，对于无注释步态数据的对比学习可以学习一个表示，这个表示能够捕捉临床有意义的信息。我们使用生物标记框架来询问这个学习的表示，并证明它能够准确地分类诊断，并且对于入院治疗响应。我们希望这些学习的表示能够帮助建立预测和诊断基于步态的生物标记，以便通过更广泛的MMC来评估运动。
</details></li>
</ul>
<hr>
<h2 id="Mask-guided-Data-Augmentation-for-Multiparametric-MRI-Generation-with-a-Rare-Hepatocellular-Carcinoma"><a href="#Mask-guided-Data-Augmentation-for-Multiparametric-MRI-Generation-with-a-Rare-Hepatocellular-Carcinoma" class="headerlink" title="Mask-guided Data Augmentation for Multiparametric MRI Generation with a Rare Hepatocellular Carcinoma"></a>Mask-guided Data Augmentation for Multiparametric MRI Generation with a Rare Hepatocellular Carcinoma</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16314">http://arxiv.org/abs/2307.16314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karen Sanchez, Carlos Hinojosa, Kevin Arias, Henry Arguello, Denis Kouame, Olivier Meyrignac, Adrian Basarab</li>
<li>for: 这篇论文是为了提高深度学习模型在医学应用中的整体性能而撰写的。</li>
<li>methods: 这篇论文使用了一种叫做Pix2Pix的生成深度学习方法，将 multiparametric MRI 数据集中的liver tumor masks和腹部边界作为输入，生成了一组合计1,000个synthetic MRI triplets和它们的肿瘤屏障。</li>
<li>results: 这篇论文的结果显示，使用这种方法可以将Frechet Inception Distance score提高到86.55。此外，这种方法在2021年的数据增幅挑战中被评为得奖作品之一。<details>
<summary>Abstract</summary>
Data augmentation is classically used to improve the overall performance of deep learning models. It is, however, challenging in the case of medical applications, and in particular for multiparametric datasets. For example, traditional geometric transformations used in several applications to generate synthetic images can modify in a non-realistic manner the patients' anatomy. Therefore, dedicated image generation techniques are necessary in the medical field to, for example, mimic a given pathology realistically. This paper introduces a new data augmentation architecture that generates synthetic multiparametric (T1 arterial, T1 portal, and T2) magnetic resonance images (MRI) of massive macrotrabecular subtype hepatocellular carcinoma with their corresponding tumor masks through a generative deep learning approach. The proposed architecture creates liver tumor masks and abdominal edges used as input in a Pix2Pix network for synthetic data creation. The method's efficiency is demonstrated by training it on a limited multiparametric dataset of MRI triplets from $89$ patients with liver lesions to generate $1,000$ synthetic triplets and their corresponding liver tumor masks. The resulting Frechet Inception Distance score was $86.55$. The proposed approach was among the winners of the 2021 data augmentation challenge organized by the French Society of Radiology.
</details>
<details>
<summary>摘要</summary>
“数据扩展是深度学习模型性能的提升方法之一，但在医疗应用中受到限制，特别是对多参数数据进行扩展。例如，传统的几何变换在许多应用中生成的 sintetic 图像可能会非现实地改变病人的解剖结构。因此，在医疗领域，需要专门的图像生成技术，以例如，模拟给定的疾病实际地。这篇论文介绍了一种新的数据扩展架构，通过生成多参数（T1血管、T1门脉和T2）核磁共振成像（MRI）图像的生成深度学习方法，生成大量大macrotrabecular型肝癌的 sintetic 图像和其医学标注。提议的架构使用MRI triplets的liver lesions从89名病人中训练Pix2Pix网络，生成1000个 sintetic triplets和其医学标注。结果的Frechet Inception Distance分数为86.55。该方法在2021年法国 radiology 社会组织的数据扩展挑战中获得奖。”Note that Simplified Chinese is used in this translation, as it is the most widely used variety of Chinese in mainland China and is more straightforward to read for non-native speakers. If you prefer Traditional Chinese, I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="Triple-Correlations-Guided-Label-Supplementation-for-Unbiased-Video-Scene-Graph-Generation"><a href="#Triple-Correlations-Guided-Label-Supplementation-for-Unbiased-Video-Scene-Graph-Generation" class="headerlink" title="Triple Correlations-Guided Label Supplementation for Unbiased Video Scene Graph Generation"></a>Triple Correlations-Guided Label Supplementation for Unbiased Video Scene Graph Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16309">http://arxiv.org/abs/2307.16309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenqing Wang, Kaifeng Gao, Yawei Luo, Tao Jiang, Fei Gao, Jian Shao, Jianwen Sun, Jun Xiao</li>
<li>for: 提高视频内容中 predicate 的准确性，解决现有 VidSGG 方法在具有较少表达的 predicate 上表现不佳的问题。</li>
<li>methods: 提出了一种名为 Trico 的方法，通过探索三种归一化空间时间相关性来补充缺失的 predicate。</li>
<li>results: 对 VidVRD 和 VidOR 等最常用的 VidSGG 数据集进行了广泛的实验，并达到了状态场下的表现，特别是在一些尾 predicate 上。<details>
<summary>Abstract</summary>
Video-based scene graph generation (VidSGG) is an approach that aims to represent video content in a dynamic graph by identifying visual entities and their relationships. Due to the inherently biased distribution and missing annotations in the training data, current VidSGG methods have been found to perform poorly on less-represented predicates. In this paper, we propose an explicit solution to address this under-explored issue by supplementing missing predicates that should be appear in the ground-truth annotations. Dubbed Trico, our method seeks to supplement the missing predicates by exploring three complementary spatio-temporal correlations. Guided by these correlations, the missing labels can be effectively supplemented thus achieving an unbiased predicate predictions. We validate the effectiveness of Trico on the most widely used VidSGG datasets, i.e., VidVRD and VidOR. Extensive experiments demonstrate the state-of-the-art performance achieved by Trico, particularly on those tail predicates.
</details>
<details>
<summary>摘要</summary>
文本描述：视频基于Scene graph生成(VidSGG)是一种方法，旨在通过识别视觉实体和其之间关系，将视频内容表示为动态图。由于训练数据的自然偏袋和缺失签注，现有的VidSGG方法在 menos-represented predicates 方面表现不佳。在这篇论文中，我们提出了一种显式的解决方案，通过补充缺失的 predicates 来解决这个未explored问题。我们称之为 Trico，我们的方法通过 three complementary spatio-temporal correlations 来补充缺失标签，从而实现无偏 predicate 预测。我们在 VidVRD 和 VidOR 等最常用的 VidSGG 数据集上验证了 Trico 的效果，特别是在 tail predicates 方面。Here's the translation in Traditional Chinese:文本描述：影像基于Scene graph生成(VidSGG)是一种方法，旨在透过识别视觉元素和其之间关系，将影像内容表示为动态图。由于训练数据的自然偏袋和缺失签识，现有的VidSGG方法在 menos-represented predicates 方面表现不佳。在这篇论文中，我们提出了一种显式的解决方案，通过补充缺失的 predicates 来解决这个未explored问题。我们称之为 Trico，我们的方法通过 three complementary spatio-temporal correlations 来补充缺失标签，从而实现无偏 predicate 预测。我们在 VidVRD 和 VidOR 等最常用的 VidSGG 数据集上验证了 Trico 的效果，特别是在 tail predicates 方面。
</details></li>
</ul>
<hr>
<h2 id="Stylized-Projected-GAN-A-Novel-Architecture-for-Fast-and-Realistic-Image-Generation"><a href="#Stylized-Projected-GAN-A-Novel-Architecture-for-Fast-and-Realistic-Image-Generation" class="headerlink" title="Stylized Projected GAN: A Novel Architecture for Fast and Realistic Image Generation"></a>Stylized Projected GAN: A Novel Architecture for Fast and Realistic Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16275">http://arxiv.org/abs/2307.16275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Nurul Muttakin, Malik Shahid Sultan, Robert Hoehndorf, Hernando Ombao</li>
<li>for: 本研究使用生成对抗网络（GANs）生成数据，但GANs在对抗Setting下训练是一项困难任务。</li>
<li>methods: 本研究使用传输学习将生成和真实样本投影到预训练的特征空间，以提高训练效率和稳定性。</li>
<li>results: 提出了一种优化的架构方案，即风格化投影GANs（Stylized Projected GANs），通过结合 Style GANs 的映射网络和 Fast GAN 的跳过层刺激，提高生成图像质量和避免生成图像中的缺陷。<details>
<summary>Abstract</summary>
Generative Adversarial Networks are used for generating the data using a generator and a discriminator, GANs usually produce high-quality images, but training GANs in an adversarial setting is a difficult task. GANs require high computation power and hyper-parameter regularization for converging. Projected GANs tackle the training difficulty of GANs by using transfer learning to project the generated and real samples into a pre-trained feature space. Projected GANs improve the training time and convergence but produce artifacts in the generated images which reduce the quality of the generated samples, we propose an optimized architecture called Stylized Projected GANs which integrates the mapping network of the Style GANs with Skip Layer Excitation of Fast GAN. The integrated modules are incorporated within the generator architecture of the Fast GAN to mitigate the problem of artifacts in the generated images.
</details>
<details>
<summary>摘要</summary>
Generative Adversarial Networks (GANs) 通常用一个生成器和一个欺骗器来生成数据，但训练 GANs 在反对性设定下是一个困难的任务。GANs 需要高度的计算能力和对应变数的调整以获得协调。对应 GANs 解决了 GANs 训练的困难性，通过将生成的和实际样本 проек到预训的特征空间中。对应 GANs 可以提高训练时间和协调，但是会导致生成的图像中的瑕疵，这样会降低生成的样本质量。我们提出一个优化的架构，即 Style Projected GANs，它将 Style GANs 的映射网络和 Fast GAN 的跳跃层刺激组合在一起，并将这些模组 incorporated 到 Fast GAN 的生成器架构中，以减少生成的图像中的瑕疵。
</details></li>
</ul>
<hr>
<h2 id="An-objective-validation-of-polyp-and-instrument-segmentation-methods-in-colonoscopy-through-Medico-2020-polyp-segmentation-and-MedAI-2021-transparency-challenges"><a href="#An-objective-validation-of-polyp-and-instrument-segmentation-methods-in-colonoscopy-through-Medico-2020-polyp-segmentation-and-MedAI-2021-transparency-challenges" class="headerlink" title="An objective validation of polyp and instrument segmentation methods in colonoscopy through Medico 2020 polyp segmentation and MedAI 2021 transparency challenges"></a>An objective validation of polyp and instrument segmentation methods in colonoscopy through Medico 2020 polyp segmentation and MedAI 2021 transparency challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16262">http://arxiv.org/abs/2307.16262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/georgebatch/kvasir-seg">https://github.com/georgebatch/kvasir-seg</a></li>
<li>paper_authors: Debesh Jha, Vanshali Sharma, Debapriya Banik, Debayan Bhattacharya, Kaushiki Roy, Steven A. Hicks, Nikhil Kumar Tomar, Vajira Thambawita, Adrian Krenzer, Ge-Peng Ji, Sahadev Poudel, George Batchkala, Saruar Alam, Awadelrahman M. A. Ahmed, Quoc-Huy Trinh, Zeshan Khan, Tien-Phat Nguyen, Shruti Shrestha, Sabari Nathan, Jeonghwan Gwak, Ritika K. Jha, Zheyuan Zhang, Alexander Schlaefer, Debotosh Bhattacharjee, M. K. Bhuyan, Pradip K. Das, Sravanthi Parsa, Sharib Ali, Michael A. Riegler, Pål Halvorsen, Ulas Bagci, Thomas De Lange<br>for:The paper is written to promote the development of efficient and transparent methods for automatic analysis of colonoscopy images, with the goal of improving the early detection of precancerous polyps.methods:The paper uses a combination of deep learning techniques and transparency and interpretability analysis to evaluate the performance and credibility of various algorithms for polyp segmentation and classification.results:The paper presents a comprehensive summary and analysis of the “Medico 2020” and “MedAI: Transparency in Medical Image Segmentation (MedAI 2021)” competitions, highlighting the strengths of the best-performing methods and discussing the possibility of clinical translations of such methods into the clinic. The paper also encourages qualitative evaluation for building more transparent and understandable AI-based colonoscopy systems.Here is the same information in Simplified Chinese text:for:这篇论文是为了促进自动检测colonoscopy图像的效率和透明度方面的研究，以提高早期检测前канcerous polyp的可能性。methods:这篇论文使用了深度学习技术和透明度分析，以评估不同算法的效果和可靠性。results:这篇论文提供了“Medico 2020”和“MedAI: Transparency in Medical Image Segmentation (MedAI 2021)”比赛的全面总结和分析，把最佳performing方法的优势强调出来，并讨论如何将这些方法在临床中应用。同时，它也鼓励更多的质量评估，以建立更加透明和理解的AI基于colonoscopy系统。<details>
<summary>Abstract</summary>
Automatic analysis of colonoscopy images has been an active field of research motivated by the importance of early detection of precancerous polyps. However, detecting polyps during the live examination can be challenging due to various factors such as variation of skills and experience among the endoscopists, lack of attentiveness, and fatigue leading to a high polyp miss-rate. Deep learning has emerged as a promising solution to this challenge as it can assist endoscopists in detecting and classifying overlooked polyps and abnormalities in real time. In addition to the algorithm's accuracy, transparency and interpretability are crucial to explaining the whys and hows of the algorithm's prediction. Further, most algorithms are developed in private data, closed source, or proprietary software, and methods lack reproducibility. Therefore, to promote the development of efficient and transparent methods, we have organized the "Medico automatic polyp segmentation (Medico 2020)" and "MedAI: Transparency in Medical Image Segmentation (MedAI 2021)" competitions. We present a comprehensive summary and analyze each contribution, highlight the strength of the best-performing methods, and discuss the possibility of clinical translations of such methods into the clinic. For the transparency task, a multi-disciplinary team, including expert gastroenterologists, accessed each submission and evaluated the team based on open-source practices, failure case analysis, ablation studies, usability and understandability of evaluations to gain a deeper understanding of the models' credibility for clinical deployment. Through the comprehensive analysis of the challenge, we not only highlight the advancements in polyp and surgical instrument segmentation but also encourage qualitative evaluation for building more transparent and understandable AI-based colonoscopy systems.
</details>
<details>
<summary>摘要</summary>
自动分析干式摄影图像是一个活跃的研究领域，受到早期检测前期癌病变的重要性启发。然而，在实时检查中检测病变可以是困难的，因为医生们的技能和经验差异，注意力不集中，疲劳等因素导致高检测病变率。深度学习在这个挑战中出现为一个有前途的解决方案，它可以帮助医生在实时检查中检测和分类检测到的病变和异常。此外，算法的准确率不是唯一的重要因素，还需要考虑算法的透明度和可解释性，以便理解算法的预测结果的原因和过程。目前，大多数算法都是在私人数据、关闭源代码或商业软件上开发的，导致方法缺乏可重复性。为了促进效率和透明度的方法的发展，我们在“医疗自动肠道分 segmentation（Medico 2020）”和“MedAI：医疗图像分 segmentation（MedAI 2021）”的竞赛中组织了一系列的挑战。我们在这篇文章中提供了这些竞赛的全面概述，分析每个贡献的优势，并评估了最佳方法的可靠性和临床应用性。为了评估团队的透明度，我们组织了一个多дисциплиnea队伍，包括专业的 Gastroenterologist，对每个提交进行评估，以evaluate团队的开源实践、失败案例分析、割除研究、可用性和理解度来深入了解模型的可靠性和临床应用性。通过全面分析这些挑战，我们不仅披露了肠道和手术 instrumente的分 segmentation的进步，还鼓励了质量评估的建立，以建立更透明和可理解的AI基于干式摄影系统。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/31/cs.CV_2023_07_31/" data-id="clpxp6c0n00heee88h4ek9iyo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_31" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/31/cs.AI_2023_07_31/" class="article-date">
  <time datetime="2023-07-31T12:00:00.000Z" itemprop="datePublished">2023-07-31</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/31/cs.AI_2023_07_31/">cs.AI - 2023-07-31</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ToolLLM-Facilitating-Large-Language-Models-to-Master-16000-Real-world-APIs"><a href="#ToolLLM-Facilitating-Large-Language-Models-to-Master-16000-Real-world-APIs" class="headerlink" title="ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"></a>ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16789">http://arxiv.org/abs/2307.16789</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/openbmb/toolbench">https://github.com/openbmb/toolbench</a></li>
<li>paper_authors: Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, Maosong Sun<br>for:* The paper aims to improve the tool-use capabilities of open-source large language models (LLMs) by introducing a general framework called ToolLLM.methods:* The framework consists of data construction, model training, and evaluation, including the creation of an instruction-tuning dataset called ToolBench and the development of a novel depth-first search-based decision tree (DFSDT) to enhance planning and reasoning capabilities.results:* The paper demonstrates the effectiveness of ToolLLM by fine-tuning LLaMA on ToolBench and obtaining ToolLLaMA, which shows a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Additionally, the paper proposes a neural API retriever to recommend appropriate APIs for each instruction.<details>
<summary>Abstract</summary>
Despite the advancements of open-source large language models (LLMs) and their variants, e.g., LLaMA and Vicuna, they remain significantly limited in performing higher-level tasks, such as following human instructions to use external tools (APIs). This is because current instruction tuning largely focuses on basic language tasks instead of the tool-use domain. This is in contrast to state-of-the-art (SOTA) LLMs, e.g., ChatGPT, which have demonstrated excellent tool-use capabilities but are unfortunately closed source. To facilitate tool-use capabilities within open-source LLMs, we introduce ToolLLM, a general tool-use framework of data construction, model training and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT. Specifically, we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub, then prompt ChatGPT to generate diverse human instructions involving these APIs, covering both single-tool and multi-tool scenarios. Finally, we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To make the searching process more efficient, we develop a novel depth-first search-based decision tree (DFSDT), enabling LLMs to evaluate multiple reasoning traces and expand the search space. We show that DFSDT significantly enhances the planning and reasoning capabilities of LLMs. For efficient tool-use assessment, we develop an automatic evaluator: ToolEval. We fine-tune LLaMA on ToolBench and obtain ToolLLaMA. Our ToolEval reveals that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. To make the pipeline more practical, we devise a neural API retriever to recommend appropriate APIs for each instruction, negating the need for manual API selection.
</details>
<details>
<summary>摘要</summary>
尽管开源大型自然语言模型（LLM）和其变体（如LLaMA和Vicuna）在进行更高级别任务方面有所进步，但它们仍然在使用外部工具（API）上有限制。这是因为当前的 instrucion 调整主要关注基础语言任务而不是工具使用领域。与此相反，状态元（SOTA）LLM（如ChatGPT）已经示出了出色的工具使用能力，但它们却是关闭源代码。为了帮助开源LLM在工具使用方面增强能力，我们介绍了 ToolLLM，一个通用工具使用框架，包括数据建构、模型训练和评估。我们首先介绍了 ToolBench，一个用于工具使用的 instrucion 调整数据集，通过自动使用 ChatGPT 生成了16,464个实际RESTful API，覆盖49个类别。然后，我们使用 ChatGPT 生成多种人类 instrucion，涵盖单个工具和多个工具enario。最后，我们使用 ChatGPT 搜索一个有效的解决方案路径（chain of API calls）。为了使搜索过程更有效率，我们开发了一种深度优先搜索基于决策树（DFSDT），使 LLVM 可以评估多种理解迹象和扩大搜索空间。我们表明，DFSDT 有效地提高 LLVM 的规划和推理能力。为了有效评估工具使用，我们开发了一个自动评估器：ToolEval。我们精度调整 LLaMA 在 ToolBench 上，得到了 ToolLLaMA。我们的 ToolEval 表明，ToolLLaMA 能够执行复杂 instrucion 并对未看到API进行扩展，并且与 ChatGPT 的性能相当。为了使管道更实用，我们设计了一种神经API搜索器，以便为每个 instrucion 推荐合适的API，从而消除手动API选择的需求。
</details></li>
</ul>
<hr>
<h2 id="The-Ethics-of-AI-Value-Chains-An-Approach-for-Integrating-and-Expanding-AI-Ethics-Research-Practice-and-Governance"><a href="#The-Ethics-of-AI-Value-Chains-An-Approach-for-Integrating-and-Expanding-AI-Ethics-Research-Practice-and-Governance" class="headerlink" title="The Ethics of AI Value Chains: An Approach for Integrating and Expanding AI Ethics Research, Practice, and Governance"></a>The Ethics of AI Value Chains: An Approach for Integrating and Expanding AI Ethics Research, Practice, and Governance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16787">http://arxiv.org/abs/2307.16787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Blair Attard-Frost, David Gray Widder</li>
<li>for: 本研究旨在探讨人工智能伦理学的新方法和实践，以满足多个actor、context和scale of activity中的AI系统设计、开发、使用和管理的伦理和实践问题。</li>
<li>methods: 本文使用价值链概念作为一个综合的概念，以涵盖AI系统的伦理和实践问题。文章对价值链理论 perspective from strategic management, service science, and economic geography literature进行了回顾和整合，并对学术、产业和政策文献中关于AI价值链的观点进行了回顾。</li>
<li>results: 文章通过将AI伦理问题与AI价值链中的actor和资源活动相连接，示出了 approaching AI伦理问题为价值链问题可以实现更加全面和紧凑的研究和管理实践。文章还提出了五个未来方向，以便研究者、实践者和政策制定者可以在AI价值链中调查和 intervene 伦理问题。<details>
<summary>Abstract</summary>
Recent criticisms of AI ethics principles and practices have indicated a need for new approaches to AI ethics that can account for and intervene in the design, development, use, and governance of AI systems across multiple actors, contexts, and scales of activity. This paper positions AI value chains as an integrative concept that satisfies those needs, enabling AI ethics researchers, practitioners, and policymakers to take a more comprehensive view of the ethical and practical implications of AI systems. We review and synthesize theoretical perspectives on value chains from the literature on strategic management, service science, and economic geography. We then review perspectives on AI value chains from the academic, industry, and policy literature. We connect an inventory of ethical concerns in AI to the actors and resourcing activities involved in AI value chains to demonstrate that approaching AI ethics issues as value chain issues can enable more comprehensive and integrative research and governance practices. We illustrate this by suggesting five future directions for researchers, practitioners, and policymakers to investigate and intervene in the ethical concerns associated with AI value chains.
</details>
<details>
<summary>摘要</summary>
We review and synthesize theoretical perspectives on value chains from the literature on strategic management, service science, and economic geography, and then examine perspectives on AI value chains from the academic, industry, and policy literature. We connect an inventory of ethical concerns in AI to the actors and resourcing activities involved in AI value chains, demonstrating that approaching AI ethics issues as value chain issues can lead to more comprehensive and integrative research and governance practices.To illustrate this, we suggest five future directions for researchers, practitioners, and policymakers to investigate and intervene in the ethical concerns associated with AI value chains:1. Investigating the ethical implications of AI value chains in different contexts, such as healthcare, finance, and education.2. Developing new methods and tools for analyzing and managing AI value chains, including the use of blockchain and other distributed ledger technologies.3. Examining the role of governance and regulation in AI value chains, and developing new frameworks for ethical governance and oversight.4. Addressing the issue of bias and discrimination in AI value chains, and developing strategies for mitigating these issues.5. Investigating the impact of AI value chains on employment and the labor market, and developing policies to ensure that the benefits of AI are shared fairly among all stakeholders.
</details></li>
</ul>
<hr>
<h2 id="Ranking-based-Argumentation-Semantics-Applied-to-Logical-Argumentation-full-version"><a href="#Ranking-based-Argumentation-Semantics-Applied-to-Logical-Argumentation-full-version" class="headerlink" title="Ranking-based Argumentation Semantics Applied to Logical Argumentation (full version)"></a>Ranking-based Argumentation Semantics Applied to Logical Argumentation (full version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16780">http://arxiv.org/abs/2307.16780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jesse Heyninck, Badran Raddaoui, Christian Straßer</li>
<li>for: 这篇论文主要针对的是形式论证中的扩展基于 semantics 和结构基于 semantics 之间的比较，以及这两种 semantics 在不同的论证结构下的行为。</li>
<li>methods: 这篇论文使用了许多不同的论证结构和推理方法，包括扩展基于 semantics 和结构基于 semantics，以及各种不同的推理方法。</li>
<li>results: 研究发现，使用rank-based semantics 在不同的论证结构下的行为都很相似，并且这些 semantics 可以生成一种称为责任度度量的量化表示，这种度量可以用于衡量不同论证结构下的论证结果。<details>
<summary>Abstract</summary>
In formal argumentation, a distinction can be made between extension-based semantics, where sets of arguments are either (jointly) accepted or not, and ranking-based semantics, where grades of acceptability are assigned to arguments. Another important distinction is that between abstract approaches, that abstract away from the content of arguments, and structured approaches, that specify a method of constructing argument graphs on the basis of a knowledge base. While ranking-based semantics have been extensively applied to abstract argumentation, few work has been done on ranking-based semantics for structured argumentation. In this paper, we make a systematic investigation into the behaviour of ranking-based semantics applied to existing formalisms for structured argumentation. We show that a wide class of ranking-based semantics gives rise to so-called culpability measures, and are relatively robust to specific choices in argument construction methods.
</details>
<details>
<summary>摘要</summary>
formal 的论证中，可以区分Extension-based semantics和ranking-based semantics两种不同的Semantics。Extension-based semantics是指集合的论证是接受或不接受的，而ranking-based semantics则是将论证的可接受度赋予一个排名。另外，还可以分为抽象approaches和结构化approaches两种不同的方法。而ranking-based semantics主要应用于抽象论证，对于结构化论证的应用则比较少。在这篇论文中，我们进行了系统性的调查，探讨了现有的结构化论证 formalism中ranking-based semantics的行为。我们发现，一类广泛的ranking-based semantics会导致所谓的责任度量，并且对于不同的论证构建方法具有一定的抗锋性。
</details></li>
</ul>
<hr>
<h2 id="KoBBQ-Korean-Bias-Benchmark-for-Question-Answering"><a href="#KoBBQ-Korean-Bias-Benchmark-for-Question-Answering" class="headerlink" title="KoBBQ: Korean Bias Benchmark for Question Answering"></a>KoBBQ: Korean Bias Benchmark for Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16778">http://arxiv.org/abs/2307.16778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiho Jin, Jiseon Kim, Nayeon Lee, Haneul Yoo, Alice Oh, Hwaran Lee</li>
<li>for: 本研究旨在开发一个适用于韩语问答任务中的社会偏见标准 dataset，以评估语言模型（LM）在不同文化环境中的偏见表现。</li>
<li>methods: 我们采用了一种基于英语 BBQ dataset 的文化适应方法，将 BBQ 中的样本分为三类：简单翻译（可以直接通过文化翻译使用）、目标修改（需要本地化）和样本除除（不适合韩国文化）。 我们还通过采样韩国文学作品中的社会偏见，新增了适用于韩国文化的四种偏见类别。</li>
<li>results: 我们使用 KoBBQ dataset 测试了多种国际化语言模型的准确率和偏见分数，发现韩语和英语中语言模型的偏见不同，提示需要手动制作考虑到文化差异的数据。<details>
<summary>Abstract</summary>
The BBQ (Bias Benchmark for Question Answering) dataset enables the evaluation of the social biases that language models (LMs) exhibit in downstream tasks. However, it is challenging to adapt BBQ to languages other than English as social biases are culturally dependent. In this paper, we devise a process to construct a non-English bias benchmark dataset by leveraging the English BBQ dataset in a culturally adaptive way and present the KoBBQ dataset for evaluating biases in Question Answering (QA) tasks in Korean. We identify samples from BBQ into three classes: Simply-Translated (can be used directly after cultural translation), Target-Modified (requires localization in target groups), and Sample-Removed (does not fit Korean culture). We further enhance the cultural relevance to Korean culture by adding four new categories of bias specific to Korean culture and newly creating samples based on Korean literature. KoBBQ consists of 246 templates and 4,740 samples across 12 categories of social bias. Using KoBBQ, we measure the accuracy and bias scores of several state-of-the-art multilingual LMs. We demonstrate the differences in the bias of LMs in Korean and English, clarifying the need for hand-crafted data considering cultural differences.
</details>
<details>
<summary>摘要</summary>
BBQ（偏见权重标准）数据集允许语言模型（LM）在下游任务中展现社会偏见。然而，将 BBQ  adapted 到非英语语言是文化依赖的。在这篇论文中，我们提出了一种构建非英语偏见标准数据集的过程，利用英语 BBQ  dataset 的文化适应方式，并介绍了韩国语言Question Answering（QA）任务中的 KoBBQ 数据集。我们将 BBQ 中的样本分为三类：可以直接使用的简单翻译（Simply-Translated）、需要本地化的目标修改（Target-Modified）和不适应韩国文化的样本（Sample-Removed）。我们还增强了韩国文化的文化相关性，添加了适用于韩国文化的四种偏见类型，并基于韩国文学创作了新的样本。KoBBQ 包含 246 个模板和 4,740 个样本，分别属于 12 个社会偏见类别。使用 KoBBQ，我们测试了多种当前领域最佳的多语言语言模型的准确性和偏见分数。我们显示了韩国语言和英语中 LM 的偏见之间的差异，从而证明了需要手动制作考虑到文化差异的数据。
</details></li>
</ul>
<hr>
<h2 id="AsdKB-A-Chinese-Knowledge-Base-for-the-Early-Screening-and-Diagnosis-of-Autism-Spectrum-Disorder"><a href="#AsdKB-A-Chinese-Knowledge-Base-for-the-Early-Screening-and-Diagnosis-of-Autism-Spectrum-Disorder" class="headerlink" title="AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder"></a>AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16773">http://arxiv.org/abs/2307.16773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianxing Wu, Xudong Cao, Yipeng Zhu, Feiyue Wu, Tianling Gong, Yuxiang Wang, Shenqi Jing</li>
<li>for: 这篇论文的目的是创建一个中文知识库（AsdKB），以帮助早期诊断和诊断Autism Spectrum Disorder（ASD）。</li>
<li>methods: 这篇论文使用了多种源，包括SNOMED CT和ICD-10的疾病知识、DSM-5的诊断标准和社会组织和医疗机构推荐的检测工具，以及专业医生和医院的知识。</li>
<li>results: 这篇论文创建了一个包含ontological和事实知识的中文知识库（AsdKB），可以用于问答、辅助诊断和专家建议。论文还提出了一个基于这个知识库的 прототип，可以在<a target="_blank" rel="noopener" href="http://asdkb.org.cn/%E4%B8%8A%E6%9F%A5%E7%9C%8B%E3%80%82">http://asdkb.org.cn/上查看。</a><details>
<summary>Abstract</summary>
To easily obtain the knowledge about autism spectrum disorder and help its early screening and diagnosis, we create AsdKB, a Chinese knowledge base on autism spectrum disorder. The knowledge base is built on top of various sources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical descriptions on mental and behavioural disorders, 2) the diagnostic knowledge from DSM-5 and different screening tools recommended by social organizations and medical institutes, and 3) the expert knowledge on professional physicians and hospitals from the Web. AsdKB contains both ontological and factual knowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The potential applications of AsdKB are question answering, auxiliary diagnosis, and expert recommendation, and we illustrate them with a prototype which can be accessed at http://asdkb.org.cn/.
</details>
<details>
<summary>摘要</summary>
为了轻松获得关于自闭异症 спектル谱病的知识，帮助早期检测和诊断，我们创建了Autism Spectrum Disorder知识库（AsdKB）。该知识库基于多种来源，包括1）疾病知识从SNOMED CT和ICD-10临床描述中的精神和行为病种，2）诊断知识从DSM-5和不同检测工具推荐的社会组织和医疗机构，以及3）专业医生和医院的知识。AsdKB包含ontological和事实知识，可以通过链接数据访问https://w3id.org/asdkb/。该知识库的潜在应用包括问答、辅助诊断和专家建议，我们在http://asdkb.org.cn/中提供了一个原型。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Smart-Malnutrition-Monitoring-A-Multi-Modal-Learning-Approach-for-Vital-Health-Parameter-Estimation"><a href="#Advancing-Smart-Malnutrition-Monitoring-A-Multi-Modal-Learning-Approach-for-Vital-Health-Parameter-Estimation" class="headerlink" title="Advancing Smart Malnutrition Monitoring: A Multi-Modal Learning Approach for Vital Health Parameter Estimation"></a>Advancing Smart Malnutrition Monitoring: A Multi-Modal Learning Approach for Vital Health Parameter Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16745">http://arxiv.org/abs/2307.16745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashish Marisetty, Prathistith Raj M, Praneeth Nemani, Venkanna Udutalapally, Debanjan Das</li>
<li>for: 这个研究旨在开发一种智能营养监测系统，用于识别营养不良的问题并提供个性化的营养计划。</li>
<li>methods: 该研究使用了一种基于全身图像的多模态学习框架，通过重构高精度的3D点云和提取512维度的特征嵌入，以便准确估算身高和体重。同时，通过应用学习参数，这些特征还可以用于估算体重准确。</li>
<li>results: 该研究的模型具有较低的平均绝对误差（MAE），可以在多种照明条件下并行运行，并且能够准确地估算身高和体重。<details>
<summary>Abstract</summary>
Malnutrition poses a significant threat to global health, resulting from an inadequate intake of essential nutrients that adversely impacts vital organs and overall bodily functioning. Periodic examinations and mass screenings, incorporating both conventional and non-invasive techniques, have been employed to combat this challenge. However, these approaches suffer from critical limitations, such as the need for additional equipment, lack of comprehensive feature representation, absence of suitable health indicators, and the unavailability of smartphone implementations for precise estimations of Body Fat Percentage (BFP), Basal Metabolic Rate (BMR), and Body Mass Index (BMI) to enable efficient smart-malnutrition monitoring. To address these constraints, this study presents a groundbreaking, scalable, and robust smart malnutrition-monitoring system that leverages a single full-body image of an individual to estimate height, weight, and other crucial health parameters within a multi-modal learning framework. Our proposed methodology involves the reconstruction of a highly precise 3D point cloud, from which 512-dimensional feature embeddings are extracted using a headless-3D classification network. Concurrently, facial and body embeddings are also extracted, and through the application of learnable parameters, these features are then utilized to estimate weight accurately. Furthermore, essential health metrics, including BMR, BFP, and BMI, are computed to conduct a comprehensive analysis of the subject's health, subsequently facilitating the provision of personalized nutrition plans. While being robust to a wide range of lighting conditions across multiple devices, our model achieves a low Mean Absolute Error (MAE) of $\pm$ 4.7 cm and $\pm$ 5.3 kg in estimating height and weight.
</details>
<details>
<summary>摘要</summary>
globally, malnutrition poses a significant threat to health, resulting from an inadequate intake of essential nutrients that adversely impacts vital organs and overall bodily functioning. To combat this challenge, periodic examinations and mass screenings have been employed, incorporating both conventional and non-invasive techniques. However, these approaches are limited by the need for additional equipment, lack of comprehensive feature representation, absence of suitable health indicators, and the unavailability of smartphone implementations for precise estimations of Body Fat Percentage (BFP), Basal Metabolic Rate (BMR), and Body Mass Index (BMI) to enable efficient smart-malnutrition monitoring.To address these constraints, this study presents a groundbreaking, scalable, and robust smart malnutrition-monitoring system that leverages a single full-body image of an individual to estimate height, weight, and other crucial health parameters within a multi-modal learning framework. Our proposed methodology involves the reconstruction of a highly precise 3D point cloud, from which 512-dimensional feature embeddings are extracted using a headless-3D classification network. Concurrently, facial and body embeddings are also extracted, and through the application of learnable parameters, these features are then utilized to estimate weight accurately. Furthermore, essential health metrics, including BMR, BFP, and BMI, are computed to conduct a comprehensive analysis of the subject's health, subsequently facilitating the provision of personalized nutrition plans.Our model is robust to a wide range of lighting conditions across multiple devices, achieving a low Mean Absolute Error (MAE) of $\pm$ 4.7 cm and $\pm$ 5.3 kg in estimating height and weight.
</details></li>
</ul>
<hr>
<h2 id="Hybrid-quantum-transfer-learning-for-crack-image-classification-on-NISQ-hardware"><a href="#Hybrid-quantum-transfer-learning-for-crack-image-classification-on-NISQ-hardware" class="headerlink" title="Hybrid quantum transfer learning for crack image classification on NISQ hardware"></a>Hybrid quantum transfer learning for crack image classification on NISQ hardware</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16723">http://arxiv.org/abs/2307.16723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Geng, Ali Moghiseh, Claudia Redenbach, Katja Schladitz</li>
<li>for: 这个论文是为了探讨量子计算机在图像处理方面的应用。</li>
<li>methods: 这个论文使用了量子转移学习来检测灰度图像中的裂隙。</li>
<li>results: 研究发现，使用量子转移学习可以快速地检测灰度图像中的裂隙，并且可以提高对图像的检测精度。I hope this helps! Let me know if you have any further questions or if there’s anything else I can assist you with.<details>
<summary>Abstract</summary>
Quantum computers possess the potential to process data using a remarkably reduced number of qubits compared to conventional bits, as per theoretical foundations. However, recent experiments have indicated that the practical feasibility of retrieving an image from its quantum encoded version is currently limited to very small image sizes. Despite this constraint, variational quantum machine learning algorithms can still be employed in the current noisy intermediate scale quantum (NISQ) era. An example is a hybrid quantum machine learning approach for edge detection. In our study, we present an application of quantum transfer learning for detecting cracks in gray value images. We compare the performance and training time of PennyLane's standard qubits with IBM's qasm\_simulator and real backends, offering insights into their execution efficiency.
</details>
<details>
<summary>摘要</summary>
量子计算机具有可能处理数据使用remarkably减少的量子比特数量，根据理论基础。然而，最近的实验表明目前只能处理非常小的图像大小。尽管如此，可以在当前的含杂中渠道量子（NISQ）时代使用量子机器学习算法。我们的研究中，我们应用了量子传输学习方法 для检测灰度图像中的裂隙。我们比较了PennyLane的标准量子比特与IBM的qasm\_simulator和真实后端的执行效率。
</details></li>
</ul>
<hr>
<h2 id="TFE-GNN-A-Temporal-Fusion-Encoder-Using-Graph-Neural-Networks-for-Fine-grained-Encrypted-Traffic-Classification"><a href="#TFE-GNN-A-Temporal-Fusion-Encoder-Using-Graph-Neural-Networks-for-Fine-grained-Encrypted-Traffic-Classification" class="headerlink" title="TFE-GNN: A Temporal Fusion Encoder Using Graph Neural Networks for Fine-grained Encrypted Traffic Classification"></a>TFE-GNN: A Temporal Fusion Encoder Using Graph Neural Networks for Fine-grained Encrypted Traffic Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16713">http://arxiv.org/abs/2307.16713</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ViktorAxelsen/TFE-GNN">https://github.com/ViktorAxelsen/TFE-GNN</a></li>
<li>paper_authors: Haozhen Zhang, Le Yu, Xi Xiao, Qing Li, Francesco Mercaldo, Xiapu Luo, Qixu Liu</li>
<li>for: 这篇论文主要关注于 encrypt 流量分类，尤其是对于短流的处理。</li>
<li>methods: 本文提出了一个基于点对点相互信息（PMI）的字节级流量图建构方法，并使用图神经网络（GNN）实现特征提取。特别是，本文设计了一个双嵌入层、GNN基于流量图编码器以及跨关特征融合机制，从 Header 和 Payload 字节分别嵌入，然后融合以获得更强的特征表示。</li>
<li>results: 实验结果显示，TFE-GNN 在两个真实数据集上比多个现有方法进行细化 encrypt 流量分类任务中表现更好。<details>
<summary>Abstract</summary>
Encrypted traffic classification is receiving widespread attention from researchers and industrial companies. However, the existing methods only extract flow-level features, failing to handle short flows because of unreliable statistical properties, or treat the header and payload equally, failing to mine the potential correlation between bytes. Therefore, in this paper, we propose a byte-level traffic graph construction approach based on point-wise mutual information (PMI), and a model named Temporal Fusion Encoder using Graph Neural Networks (TFE-GNN) for feature extraction. In particular, we design a dual embedding layer, a GNN-based traffic graph encoder as well as a cross-gated feature fusion mechanism, which can first embed the header and payload bytes separately and then fuses them together to obtain a stronger feature representation. The experimental results on two real datasets demonstrate that TFE-GNN outperforms multiple state-of-the-art methods in fine-grained encrypted traffic classification tasks.
</details>
<details>
<summary>摘要</summary>
伪Encrypted traffic classification 已经受到研究人员和工业公司的广泛关注。然而，现有的方法只是EXTract flow-level features，因为流量的统计性不可靠，或者对header和payload进行平等处理，而不是挖掘字节之间的可能的相关性。因此，在这篇论文中，我们提出了基于点wise mutual information（PMI）的字节级流量图构建方法，以及一种基于图神经网络（GNN）的特征提取模型——时间融合编码器（TFE-GNN）。特别是，我们设计了两层双向嵌入层，一个基于GNN的流量图编码器以及一个跨门控制的特征融合机制，可以先将header和payload字节分别嵌入，然后将其融合起来获得更强的特征表示。实验结果表明，TFE-GNN在真实的两个数据集上比多种现状顶尖方法在细化Encrypted traffic classification任务中表现出优异。
</details></li>
</ul>
<hr>
<h2 id="An-O-D-E-Framework-of-Distributed-TD-Learning-for-Networked-Multi-Agent-Markov-Decision-Processes"><a href="#An-O-D-E-Framework-of-Distributed-TD-Learning-for-Networked-Multi-Agent-Markov-Decision-Processes" class="headerlink" title="An O.D.E. Framework of Distributed TD-Learning for Networked Multi-Agent Markov Decision Processes"></a>An O.D.E. Framework of Distributed TD-Learning for Networked Multi-Agent Markov Decision Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16706">http://arxiv.org/abs/2307.16706</a></li>
<li>repo_url: None</li>
<li>paper_authors: Donghwan Lee, Han-Dong Lim, Do Wan Kim</li>
<li>for: 这篇论文主要目标是研究分布式常微分方程（ODE）和分布式时间差（TD）学习算法，用于分布式多智能体马尔可夫决策问题（MAMDP）。</li>
<li>methods: 我们采用分布式多智能体框架，每个智能体只能访问自己的奖励，缺乏其它智能体奖励的信息。此外，每个智能体可以与邻居智能体共享自己的参数通过通信网络，表示为一个图。</li>
<li>results: 我们的贡献包括两个重要点：1）我们提出了新的分布式ODE， inspirited by the averaging consensus method在连续时间领域。ODE的 converges是通过控制理论的角度进行评估的。2）基于上述ODE，我们开发了新的分布式TD学习算法。其中一个提出的分布式ODE具有两个独立的动态系统，每个系统都有独特的作用，这种特点使得我们可以提出一种新的分布式TD学习策略，其 converges可能通过Borkar-Meyn定理进行证明。<details>
<summary>Abstract</summary>
The primary objective of this paper is to investigate distributed ordinary differential equation (ODE) and distributed temporal difference (TD) learning algorithms for networked multi-agent Markov decision problems (MAMDPs). In our study, we adopt a distributed multi-agent framework where individual agents have access only to their own rewards, lacking insights into the rewards of other agents. Additionally, each agent has the ability to share its parameters with neighboring agents through a communication network, represented by a graph. Our contributions can be summarized in two key points: 1) We introduce novel distributed ODEs, inspired by the averaging consensus method in the continuous-time domain. The convergence of the ODEs is assessed through control theory perspectives. 2) Building upon the aforementioned ODEs, we devise new distributed TD-learning algorithms. A standout feature of one of our proposed distributed ODEs is its incorporation of two independent dynamic systems, each with a distinct role. This characteristic sets the stage for a novel distributed TD-learning strategy, the convergence of which can potentially be established using Borkar-Meyn theorem.
</details>
<details>
<summary>摘要</summary>
主要目标 OF 这篇论文是研究分布式常微分方程（ODE）和分布式时间差（TD）学习算法，用于分布式多智能体决策问题（MAMDPs）。在我们的研究中，我们采用了分布式多智能体框架，每个智能体只有自己的奖励信息，缺乏其他智能体奖励信息的视野。此外，每个智能体可以与邻居智能体通过通信网络（表示为图）共享自己的参数。我们的贡献可以概括为两个关键点：1. 我们提出了新的分布式ODE， inspirited 由积分协议在连续时间域。我们证明了这些ODE的收敛性，使用控制理论的视角。2. 基于上述ODE，我们开发了新的分布式TD学习算法。我们的一个提出的分布式ODE特征是它包含两个独立的动力系统，每个动力系统都有独特的作用。这种特点为我们提出了一种新的分布式TD学习策略，其收敛性可能通过博尔卡-美因定理证明。
</details></li>
</ul>
<hr>
<h2 id="Lookbehind-Optimizer-k-steps-back-1-step-forward"><a href="#Lookbehind-Optimizer-k-steps-back-1-step-forward" class="headerlink" title="Lookbehind Optimizer: k steps back, 1 step forward"></a>Lookbehind Optimizer: k steps back, 1 step forward</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16704">http://arxiv.org/abs/2307.16704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gonçalo Mordido, Pranshu Malviya, Aristide Baratin, Sarath Chandar</li>
<li>for: 提高深度神经网络训练稳定性，通过快速的权重来导引落幅方向。</li>
<li>methods:  combinates Lookahead optimizer 和 Sharpness-Aware Minimization (SAM) 来稳定多步变体，提高损失精度与稳定性之间的交换。</li>
<li>results: 通过 Lookbehind 算法，在不同任务和训练环境中实现了各种优势，包括提高泛化性能、增强权重噪声抗性和生命长学习中的抗忘记性。<details>
<summary>Abstract</summary>
The Lookahead optimizer improves the training stability of deep neural networks by having a set of fast weights that "look ahead" to guide the descent direction. Here, we combine this idea with sharpness-aware minimization (SAM) to stabilize its multi-step variant and improve the loss-sharpness trade-off. We propose Lookbehind, which computes $k$ gradient ascent steps ("looking behind") at each iteration and combine the gradients to bias the descent step toward flatter minima. We apply Lookbehind on top of two popular sharpness-aware training methods -- SAM and adaptive SAM (ASAM) -- and show that our approach leads to a myriad of benefits across a variety of tasks and training regimes. Particularly, we show increased generalization performance, greater robustness against noisy weights, and higher tolerance to catastrophic forgetting in lifelong learning settings.
</details>
<details>
<summary>摘要</summary>
“lookahead”优化器可以提高深度神经网络的训练稳定性，通过一组快速的权重来引导 DESC 方向。我们将这个想法与锐度感知最小化（SAM）相结合，以稳定其多步变体并改善损失锐度协调。我们提议“lookbehind”，它在每次迭代中计算 $k$ 步梯度上升（“寻看后”），并将梯度相加以偏移下降步向平坦的极小值。我们在两种流行的锐度感知训练方法——SAM 和 adaptive SAM（ASAM）之上应用 Lookbehind，并证明我们的方法在各种任务和训练 режиmidst 中具有多种优点，包括提高泛化性能、增强随着权重噪声的Robustness和生长学习中的快速忘记症。
</details></li>
</ul>
<hr>
<h2 id="Ontology-engineering-with-Large-Language-Models"><a href="#Ontology-engineering-with-Large-Language-Models" class="headerlink" title="Ontology engineering with Large Language Models"></a>Ontology engineering with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16699">http://arxiv.org/abs/2307.16699</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Patricia Mateiu, Adrian Groza</li>
<li>for: 增强ontology的描述逻辑表示，通过自动将自然语言句子翻译成描述逻辑语言。</li>
<li>methods: 使用大型自然语言模型（LLMs）进行翻译，并对GPT-3模型进行微调，以将自然语言句子翻译成OWL函数 sintax。</li>
<li>results: 通过人工监督，使用得到的axioms来扩充ontology，并提供了一个Protge插件来实现这一目标。<details>
<summary>Abstract</summary>
We tackle the task of enriching ontologies by automatically translating natural language sentences into Description Logic. Since Large Language Models (LLMs) are the best tools for translations, we fine-tuned a GPT-3 model to convert Natural Language sentences into OWL Functional Syntax. We employ objective and concise examples to fine-tune the model regarding: instances, class subsumption, domain and range of relations, object properties relationships, disjoint classes, complements, cardinality restrictions. The resulted axioms are used to enrich an ontology, in a human supervised manner. The developed tool is publicly provided as a Protge plugin.
</details>
<details>
<summary>摘要</summary>
我们致力于增强ontology的措施，通过自动将自然语言句子翻译成描述逻辑。由于大型语言模型（LLMs）是翻译的最佳工具，我们对GPT-3模型进行了细化，将自然语言句子翻译成OWL函数 sintaxis。我们使用明确和简洁的例子来细化模型，包括实例、类划覆盖、领域和关系范围、对象属性关系、离散类、补充、Cardinality约束。得到的axioms可以用于增强ontology，以人工监督的方式。我们已经开发了一个Protge插件，以便公共提供这种工具。
</details></li>
</ul>
<hr>
<h2 id="Anticipating-Responsibility-in-Multiagent-Planning"><a href="#Anticipating-Responsibility-in-Multiagent-Planning" class="headerlink" title="Anticipating Responsibility in Multiagent Planning"></a>Anticipating Responsibility in Multiagent Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16685">http://arxiv.org/abs/2307.16685</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timothy Parker, Umberto Grandi, Emiliano Lorini</li>
<li>for: 本 paper 探讨了责任预测（Responsibility Anticipation）的概念，即在多智能计划设定中，智能机器可以预测自己是否会对某些结果负责。</li>
<li>methods: 本 paper 使用了linear temporal logic的形式来表达责任预测，并使用了不同的责任概念来定义责任预测的不同方面。</li>
<li>results: 本 paper 证明了责任预测可以在多智能计划设定中协调智能机器的行为，并提供了复杂性结果和类比CLASSICAL PLANNING的等价性。  addition, the paper also outlines a method for solving some of the attribution and anticipation problems using PDDL solvers.<details>
<summary>Abstract</summary>
Responsibility anticipation is the process of determining if the actions of an individual agent may cause it to be responsible for a particular outcome. This can be used in a multi-agent planning setting to allow agents to anticipate responsibility in the plans they consider. The planning setting in this paper includes partial information regarding the initial state and considers formulas in linear temporal logic as positive or negative outcomes to be attained or avoided. We firstly define attribution for notions of active, passive and contributive responsibility, and consider their agentive variants. We then use these to define the notion of responsibility anticipation. We prove that our notions of anticipated responsibility can be used to coordinate agents in a planning setting and give complexity results for our model, discussing equivalence with classical planning. We also present an outline for solving some of our attribution and anticipation problems using PDDL solvers.
</details>
<details>
<summary>摘要</summary>
责任预测是确定特定行为代理人可能对结果负责的过程。这可以在多代理人规划设置中使用，以便代理人可以在考虑的计划中预测责任。本文中的规划设置包括初始状态的部分信息，并考虑线性时间逻辑逻辑为正或负结果来达成或避免。我们首先定义了活动、被动和贡献责任的归属，然后使用这些定义来定义责任预测。我们证明了我们的责任预测概念可以用于协调代理人在规划设置中，并提供了复杂性结果，讨论与传统规划相等的等价性。此外，我们还提供了解决一些归属和预测问题的OUTLINE，使用PDDL解决器。
</details></li>
</ul>
<hr>
<h2 id="On-the-Trustworthiness-Landscape-of-State-of-the-art-Generative-Models-A-Comprehensive-Survey"><a href="#On-the-Trustworthiness-Landscape-of-State-of-the-art-Generative-Models-A-Comprehensive-Survey" class="headerlink" title="On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey"></a>On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16680">http://arxiv.org/abs/2307.16680</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingyuan Fan, Cen Chen, Chengyu Wang, Jun Huang</li>
<li>for: This paper aims to investigate the trustworthiness of large-scale generative models, specifically addressing privacy, security, fairness, and responsibility concerns.</li>
<li>methods: The paper employs a comprehensive approach, analyzing both long-standing and emerging threats associated with these models across four fundamental dimensions.</li>
<li>results: The authors provide an extensive map outlining the trustworthiness of these models, as well as practical recommendations and future directions for promoting their trustworthy deployment.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文旨在调查大规模生成模型的可靠性，具体探讨隐私、安全、公正性和责任等四个基本维度上的威胁。</li>
<li>methods: 该论文采用了全面的方法，对这些模型的威胁进行了分析，包括长期存在的和新出现的威胁。</li>
<li>results: 作者们提供了详细的可靠性地图，以及实践的建议和未来发展方向，以便推广这些模型的可靠部署，最终为社会带来利益。<details>
<summary>Abstract</summary>
Diffusion models and large language models have emerged as leading-edge generative models and have sparked a revolutionary impact on various aspects of human life. However, the practical implementation of these models has also exposed inherent risks, highlighting their dual nature and raising concerns regarding their trustworthiness. Despite the abundance of literature on this subject, a comprehensive survey specifically delving into the intersection of large-scale generative models and their trustworthiness remains largely absent. To bridge this gap, This paper investigates both the long-standing and emerging threats associated with these models across four fundamental dimensions: privacy, security, fairness, and responsibility. In this way, we construct an extensive map outlining the trustworthiness of these models, while also providing practical recommendations and identifying future directions. These efforts are crucial for promoting the trustworthy deployment of these models, ultimately benefiting society as a whole.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：大量生成模型和大语言模型在不同领域中得到了广泛应用，但实践中也暴露出了内在的风险，表现出这些模型的双重性和可信worthiness的问题。虽然有很多相关文献，但一篇具体探讨这些模型与可信worthiness的关系的总结尚未出现。为了填补这一空白，本文 investigate了这些模型中长期存在和新出现的威胁，从四个基本维度出发：隐私、安全、公平和责任。通过构建了这些模型的可信worthiness映射，并提供了实践推荐和未来方向，以促进这些模型的可靠应用，终于为社会带来利益。
</details></li>
</ul>
<hr>
<h2 id="Proactive-Resource-Request-for-Disaster-Response-A-Deep-Learning-based-Optimization-Model"><a href="#Proactive-Resource-Request-for-Disaster-Response-A-Deep-Learning-based-Optimization-Model" class="headerlink" title="Proactive Resource Request for Disaster Response: A Deep Learning-based Optimization Model"></a>Proactive Resource Request for Disaster Response: A Deep Learning-based Optimization Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16661">http://arxiv.org/abs/2307.16661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongzhe Zhang, Xiaohang Zhao, Xiao Fang, Bintong Chen</li>
<li>for: 本研究旨在提供一种优化资源请求方法，以满足灾后地区的救援资源需求。</li>
<li>methods: 本研究使用了深度学习方法进行未来需求预测，并根据特点分析了一种难题优化模型。</li>
<li>results: 对实际数据和模拟数据进行比较，本研究的方法显示出与现有方法相比的超过其他方法的性能。<details>
<summary>Abstract</summary>
Disaster response is critical to save lives and reduce damages in the aftermath of a disaster. Fundamental to disaster response operations is the management of disaster relief resources. To this end, a local agency (e.g., a local emergency resource distribution center) collects demands from local communities affected by a disaster, dispatches available resources to meet the demands, and requests more resources from a central emergency management agency (e.g., Federal Emergency Management Agency in the U.S.). Prior resource management research for disaster response overlooks the problem of deciding optimal quantities of resources requested by a local agency. In response to this research gap, we define a new resource management problem that proactively decides optimal quantities of requested resources by considering both currently unfulfilled demands and future demands. To solve the problem, we take salient characteristics of the problem into consideration and develop a novel deep learning method for future demand prediction. We then formulate the problem as a stochastic optimization model, analyze key properties of the model, and propose an effective solution method to the problem based on the analyzed properties. We demonstrate the superior performance of our method over prevalent existing methods using both real world and simulated data. We also show its superiority over prevalent existing methods in a multi-stakeholder and multi-objective setting through simulations.
</details>
<details>
<summary>摘要</summary>
灾害应急应对是生命与损害避免的关键，紧急应对措施的核心是紧急救援资源的管理。因此，当地机构（例如本地紧急资源分配中心）需要收集受灾地区的需求，派发可用资源，并请求中央紧急管理机构（例如美国联邦紧急管理署）的更多资源。但是，以前的资源管理研究忽略了地方机构请求最佳资源量的问题。为了填补这个研究漏洞，我们定义了一个新的资源管理问题，该问题可以考虑当前未满足的需求和未来需求，并且决定最佳的请求资源量。为了解决这个问题，我们考虑了问题的重要特征，并开发了一种新的深度学习方法来预测未来需求。然后，我们将问题转化为一个 Stochastic Optimization 模型，分析了模型的关键性质，并提出了一种有效的解决方案。我们通过实际数据和验证数据示范了我们的方法的优越性。此外，我们通过多方面和多目标的 simulations 示范了我们的方法在多个维度上的优越性。
</details></li>
</ul>
<hr>
<h2 id="LLMs4OL-Large-Language-Models-for-Ontology-Learning"><a href="#LLMs4OL-Large-Language-Models-for-Ontology-Learning" class="headerlink" title="LLMs4OL: Large Language Models for Ontology Learning"></a>LLMs4OL: Large Language Models for Ontology Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16648">http://arxiv.org/abs/2307.16648</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hamedbabaei/llms4ol">https://github.com/hamedbabaei/llms4ol</a></li>
<li>paper_authors: Hamed Babaei Giglou, Jennifer D’Souza, Sören Auer</li>
<li>for: 这个论文旨在检验大语言模型（LLMs）是否可以有效地应用其语言模式捕捉能力来自然语言文本中自动提取和结构知识。</li>
<li>methods: 该论文使用了零例示训练方法，对九种不同的 LLM 模型家族进行了三个主要ontoLOG知识任务的评估： term typing、taxonomy discovery 和 non-taxonomic relations 提取。</li>
<li>results: 论文的评估结果显示，LLMs 可以很好地应用其语言模式捕捉能力来自然语言文本中自动提取和结构知识，并且在不同的ontoLOG知识领域中表现出色。<details>
<summary>Abstract</summary>
We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: \textit{Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text?} To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS.
</details>
<details>
<summary>摘要</summary>
我们提出了LLMs4OL方法，它利用大语言模型（LLMs）进行ontology学习（OL）。LLMs在自然语言处理方面已经展示出了显著的进步，可以捕捉不同知识领域中的复杂语言模式。我们的LLMs4OL思想是：《可以LLMs通过捕捉和结构化自然语言文本中的知识来应用其语言模式捕捉能力到OL吗？》为了测试这一假设，我们采用了零shot提问方法进行全面评估。我们评估了9种不同的LLM模型家族，对三种主要OL任务进行评估：词类分类、分类发现和非分类关系EXTRACTION。此外，评估还涵盖了不同类型的ontological知识，包括WordNet中的lexicosemantic知识、GeoNames中的地理知识和UMLS中的医学知识。
</details></li>
</ul>
<hr>
<h2 id="Perceptions-of-the-Fourth-Industrial-Revolution-and-Artificial-Intelligence-Impact-on-Society"><a href="#Perceptions-of-the-Fourth-Industrial-Revolution-and-Artificial-Intelligence-Impact-on-Society" class="headerlink" title="Perceptions of the Fourth Industrial Revolution and Artificial Intelligence Impact on Society"></a>Perceptions of the Fourth Industrial Revolution and Artificial Intelligence Impact on Society</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02030">http://arxiv.org/abs/2308.02030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Agbaji, Brady Lund, Nishith Reddy Mannuru</li>
<li>for: This study aims to examine the perceptions of individuals in different information flow categorizations toward AI and its implications for society.</li>
<li>methods: The study uses participant-supplied definitions of AI and the fourth industrial revolution to identify key themes and concerns regarding AI, such as job replacement, privacy invasion, and inaccurate information.</li>
<li>results: The results reveal that participants expressed concerns about the potential negative impacts of AI, such as job replacement and privacy invasion, but also recognized the benefits of AI, such as solving complex problems and increasing convenience.Here are the three points in Simplified Chinese text:</li>
<li>for: 这个研究旨在探讨不同信息流类别的人们对AI的看法和其对社会的影响。</li>
<li>methods: 这个研究使用参与者提供的AI和第四次工业革命的定义来确定关键主题和AI的关注点，如工作替代、隐私侵犯和不准确的信息。</li>
<li>results: 结果显示参与者对AI的可能性影响存在担忧，如工作替代和隐私侵犯，但也认可AI的好处，如解决复杂问题和提高便利性。<details>
<summary>Abstract</summary>
The Fourth Industrial Revolution, particularly Artificial Intelligence (AI), has had a profound impact on society, raising concerns about its implications and ethical considerations. The emergence of text generative AI tools like ChatGPT has further intensified concerns regarding ethics, security, privacy, and copyright. This study aims to examine the perceptions of individuals in different information flow categorizations toward AI. The results reveal key themes in participant-supplied definitions of AI and the fourth industrial revolution, emphasizing the replication of human intelligence, machine learning, automation, and the integration of digital technologies. Participants expressed concerns about job replacement, privacy invasion, and inaccurate information provided by AI. However, they also recognized the benefits of AI, such as solving complex problems and increasing convenience. Views on government involvement in shaping the fourth industrial revolution varied, with some advocating for strict regulations and others favoring support and development. The anticipated changes brought by the fourth industrial revolution include automation, potential job impacts, increased social disconnect, and reliance on technology. Understanding these perceptions is crucial for effectively managing the challenges and opportunities associated with AI in the evolving digital landscape.
</details>
<details>
<summary>摘要</summary>
第四次工业革命，尤其是人工智能（AI），对社会产生了深见的影响，引起了关于其意图和伦理考虑的担忧。文本生成AI工具如ChatGPT的出现更加强调了伦理、安全、隐私和版权等问题的重要性。这项研究旨在探讨不同信息流类型人对AI的看法。结果显示参与者提供的AI和第四个工业革命的定义强调了人工智能的复制、机器学习、自动化和数字技术的集成。参与者表达了对AI的替换工作、隐私侵犯和不准确信息的担忧，但也认可AI的好处，如解决复杂问题和提高便利性。对第四个工业革命的预期变革包括自动化、工作的可能性影响、社会的孤立和依赖于技术。理解这些看法是管理AI在不断发展的数字环境中的挑战和机遇的关键。
</details></li>
</ul>
<hr>
<h2 id="NLLG-Quarterly-arXiv-Report-06-23-What-are-the-most-influential-current-AI-Papers"><a href="#NLLG-Quarterly-arXiv-Report-06-23-What-are-the-most-influential-current-AI-Papers" class="headerlink" title="NLLG Quarterly arXiv Report 06&#x2F;23: What are the most influential current AI Papers?"></a>NLLG Quarterly arXiv Report 06&#x2F;23: What are the most influential current AI Papers?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04889">http://arxiv.org/abs/2308.04889</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nl2g/quaterly-arxiv">https://github.com/nl2g/quaterly-arxiv</a></li>
<li>paper_authors: Steffen Eger, Christoph Leiter, Jonas Belouadi, Ran Zhang, Aida Kostikova, Daniil Larionov, Yanran Chen, Vivian Fresen<br>for: 这个研究报告的目的是为研究者和实践者提供一份快速导航，以帮助他们综合了解最新的发展和趋势在自然语言处理（NLP）和机器学习（ML）领域。methods: 这份报告使用arXiv上的 normalized citation counts来列出40篇最受欢迎的论文，以及这些论文的主要研究方向和发展趋势。results: 研究发现，自然语言处理相关的论文在最初的一半年内获得了60%的影响力，而机器学习相关的论文则占据了总数的一半。研究还发现，LLM效率、评估技术、伦理考虑、embodied agents和问题解决方法等是最受欢迎的论文主题。<details>
<summary>Abstract</summary>
The rapid growth of information in the field of Generative Artificial Intelligence (AI), particularly in the subfields of Natural Language Processing (NLP) and Machine Learning (ML), presents a significant challenge for researchers and practitioners to keep pace with the latest developments. To address the problem of information overload, this report by the Natural Language Learning Group at Bielefeld University focuses on identifying the most popular papers on arXiv, with a specific emphasis on NLP and ML. The objective is to offer a quick guide to the most relevant and widely discussed research, aiding both newcomers and established researchers in staying abreast of current trends. In particular, we compile a list of the 40 most popular papers based on normalized citation counts from the first half of 2023. We observe the dominance of papers related to Large Language Models (LLMs) and specifically ChatGPT during the first half of 2023, with the latter showing signs of declining popularity more recently, however. Further, NLP related papers are the most influential (around 60\% of top papers) even though there are twice as many ML related papers in our data. Core issues investigated in the most heavily cited papers are: LLM efficiency, evaluation techniques, ethical considerations, embodied agents, and problem-solving with LLMs. Additionally, we examine the characteristics of top papers in comparison to others outside the top-40 list (noticing the top paper's focus on LLM related issues and higher number of co-authors) and analyze the citation distributions in our dataset, among others.
</details>
<details>
<summary>摘要</summary>
“对于生成人工智能（AI）领域的资讯快速增长，特别是自然语言处理（NLP）和机器学习（ML）的子领域，对研究者和实践者而言是一个巨大的挑战。为了解决资讯过多的问题，这份报告由比丰德大学的自然语言学习研究小组统计了arXiv上最受欢迎的40篇论文，并对这些论文进行了分析。我们发现在2023年第一季度，LLMs和ChatGPT相关的论文占了最多的份额（around 60%），但是在最近几个月中，ChatGPT的人气开始下降。此外，NLP相关的论文是所有最具影响力的论文中的主要部分（约60%），即使ML相关的论文的数量是NLP相关的论文的两倍。我们发现这些最受欢迎的论文的主要研究方向包括：LLM效率、评估技术、道德考虑、具体代理人、以及使用LLM解决问题。此外，我们还评估了排名前40篇论文与其他论文之间的差异，以及我们的数据中的引用分布，等其他问题。”
</details></li>
</ul>
<hr>
<h2 id="Chatbot-Application-to-Support-Smart-Agriculture-in-Thailand"><a href="#Chatbot-Application-to-Support-Smart-Agriculture-in-Thailand" class="headerlink" title="Chatbot Application to Support Smart Agriculture in Thailand"></a>Chatbot Application to Support Smart Agriculture in Thailand</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02524">http://arxiv.org/abs/2308.02524</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paweena Suebsombut, Pradorn Sureephong, Aicha Sekhari, Suepphong Chernbumroong, Abdelaziz Bouras</li>
<li>for: 这个论文的目的是提供一个基于LINE应用程序的智能农业辅助系统，以帮助农民做出更好的农业决策。</li>
<li>methods: 这个论文使用的方法包括LINE应用程序的开发、智能农业系统的整合、推荐系统的实现等。</li>
<li>results: 在实现该论文中，农民们对该应用程序的满意度达到96%，但是当农民们使用问题箱时，该应用程序只是基于脚本的规则驱动机器人，农民们需要按照指定的关键词输入才能获得回复。<details>
<summary>Abstract</summary>
A chatbot is a software developed to help reply to text or voice conversations automatically and quickly in real time. In the agriculture sector, the existing smart agriculture systems just use data from sensing and internet of things (IoT) technologies that exclude crop cultivation knowledge to support decision-making by farmers. To enhance this, the chatbot application can be an assistant to farmers to provide crop cultivation knowledge. Consequently, we propose the LINE chatbot application as an information and knowledge representation providing crop cultivation recommendations to farmers. It works with smart agriculture and recommendation systems. Our proposed LINE chatbot application consists of five main functions (start/stop menu, main page, drip irri gation page, mist irrigation page, and monitor page). Farmers will receive information for data monitoring to support their decision-making. Moreover, they can control the irrigation system via the LINE chatbot. Furthermore, farmers can ask questions relevant to the crop environment via a chat box. After implementing our proposed chatbot, farmers are very satisfied with the application, scoring a 96% satisfaction score. However, in terms of asking questions via chat box, this LINE chatbot application is a rule-based bot or script bot. Farmers have to type in the correct keywords as prescribed, otherwise they won't get a response from the chatbots. In the future, we will enhance the asking function of our LINE chatbot to be an intelligent bot.
</details>
<details>
<summary>摘要</summary>
一个聊天机器人是一种软件，用于自动回复文本或语音对话，以便在实时进行快速响应。在农业领域，现有的智能农业系统只是使用感知和互联网专利技术，排除了农作知识以支持农民决策。为了进一步提高这一点，我们提议使用LINE聊天机器人应用程序，以提供农作知识支持。我们的提议的LINE聊天机器人应用程序包括五大主要功能（开始/停止菜单、主页、滴水页面、雾化页面和监测页面）。农民可以通过这些功能获得数据监测信息，以支持他们的决策。此外，农民还可以通过聊天机器人控制滴水系统。此外，农民可以通过聊天盒子提问与作物环境相关的问题。经过我们的提议聊天机器人的实施，农民对该应用程序非常满意，得分96%。然而，在咨询问题方面，这个LINE聊天机器人应用程序是一个规则式机器人或脚本机器人，农民必须按照预先定义的关键词输入，否则无法获得机器人的回应。未来，我们计划将我们的LINE聊天机器人应用程序的问题咨询功能提升到智能机器人水平。
</details></li>
</ul>
<hr>
<h2 id="Approximating-Counterfactual-Bounds-while-Fusing-Observational-Biased-and-Randomised-Data-Sources"><a href="#Approximating-Counterfactual-Bounds-while-Fusing-Observational-Biased-and-Randomised-Data-Sources" class="headerlink" title="Approximating Counterfactual Bounds while Fusing Observational, Biased and Randomised Data Sources"></a>Approximating Counterfactual Bounds while Fusing Observational, Biased and Randomised Data Sources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16577">http://arxiv.org/abs/2307.16577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Zaffalon, Alessandro Antonucci, Rafael Cabañas, David Huber</li>
<li>for: 本研究旨在 Addressing the problem of integrating多个可能受偏见的观察和实验研究数据，以计算结构 causal模型中的 counterfactuals。</li>
<li>methods: 我们使用 causal expectation-maximization scheme 来 Approximate partially identifiable counterfactual queries，并采用 graphical transformations 将多个数据源重新映射到单一的 caso Study on palliative care 表明我们的方法的有效性，并提示了将多种不同数据源融合以获得有用的结果。</li>
<li>results: 我们的研究结果表明，通过 fusion of heterogeneous data sources，可以获得更加有用的结果，尤其在 partial identifiability 的情况下。<details>
<summary>Abstract</summary>
We address the problem of integrating data from multiple, possibly biased, observational and interventional studies, to eventually compute counterfactuals in structural causal models. We start from the case of a single observational dataset affected by a selection bias. We show that the likelihood of the available data has no local maxima. This enables us to use the causal expectation-maximisation scheme to approximate the bounds for partially identifiable counterfactual queries, which are the focus of this paper. We then show how the same approach can address the general case of multiple datasets, no matter whether interventional or observational, biased or unbiased, by remapping it into the former one via graphical transformations. Systematic numerical experiments and a case study on palliative care show the effectiveness of our approach, while hinting at the benefits of fusing heterogeneous data sources to get informative outcomes in case of partial identifiability.
</details>
<details>
<summary>摘要</summary>
我们考虑了多个可能受偏见的观察和交互式研究数据的集成问题，以计算结构 causal 模型中的可能值。我们从单一观察数据集中开始，假设存在选择偏见。我们表明了可用数据的概率无地方最大值。这使我们可以使用 causal 期望-最大化方案来 aproximate 部分可识别的 counterfactual 查询的上下文约束。然后，我们展示了如何使用图形变换将多个数据集重新映射到原来的情况中，无论这些数据集是交互式的、受偏见的或未受偏见的。我们的方法在系统的数字实验和一个案例研究中证明了其有效性，而且表明了将多种不同数据源融合起来可以获得有用的结果，即使在部分可识别的情况下。
</details></li>
</ul>
<hr>
<h2 id="Toward-Quantum-Machine-Translation-of-Syntactically-Distinct-Languages"><a href="#Toward-Quantum-Machine-Translation-of-Syntactically-Distinct-Languages" class="headerlink" title="Toward Quantum Machine Translation of Syntactically Distinct Languages"></a>Toward Quantum Machine Translation of Syntactically Distinct Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16576">http://arxiv.org/abs/2307.16576</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mina Abbaszade, Mariam Zomorodi, Vahid Salari, Philip Kurian</li>
<li>for: 这个研究旨在探索使用量子自然语言处理算法在噪声中等级量子（NISQ）设备上进行语言翻译。经典方法在自然语言处理（NLP）中难以处理复杂语言任务，但量子NLP在NISQ设备上可以充分利用量子并行和束缚来高效地处理和分析大量语言数据，可能会革命化NLP应用。</li>
<li>methods: 我们采用了ShannonEntropy来示出某些适当的旋转门的角色在parametrized量子电路性能中。特别是，我们利用这些角度（参数）作为不同语言的量子电路之间的通信方式。</li>
<li>results: 我们的实验使用了160个样本，包括英语句子和其波斯语翻译。我们使用了классификатор-生成器模型，并使用了长期快速储存（LSTM）来实现翻译任务。我们使用了不同的优化器，包括权重参数SGD和两个附加的优化器。最终，我们得到了最佳模型，包括两个LSTM层，并使用了Adam优化器。我们的小数据集，尽管只包括简单的同义句子和单词映射，但表明了ShannonEntropy作为评价指标在更复杂的机器翻译模型中的用 utility。<details>
<summary>Abstract</summary>
The present study aims to explore the feasibility of language translation using quantum natural language processing algorithms on noisy intermediate-scale quantum (NISQ) devices. Classical methods in natural language processing (NLP) struggle with handling large-scale computations required for complex language tasks, but quantum NLP on NISQ devices holds promise in harnessing quantum parallelism and entanglement to efficiently process and analyze vast amounts of linguistic data, potentially revolutionizing NLP applications. Our research endeavors to pave the way for quantum neural machine translation, which could potentially offer advantages over classical methods in the future. We employ Shannon entropy to demonstrate the significant role of some appropriate angles of rotation gates in the performance of parametrized quantum circuits. In particular, we utilize these angles (parameters) as a means of communication between quantum circuits of different languages. To achieve our objective, we adopt the encoder-decoder model of classical neural networks and implement the translation task using long short-term memory (LSTM). Our experiments involved 160 samples comprising English sentences and their Persian translations. We trained the models with different optimisers implementing stochastic gradient descent (SGD) as primary and subsequently incorporating two additional optimizers in conjunction with SGD. Notably, we achieved optimal results-with mean absolute error of 0.03, mean squared error of 0.002, and 0.016 loss-by training the best model, consisting of two LSTM layers and using the Adam optimiser. Our small dataset, though consisting of simple synonymous sentences with word-to-word mappings, points to the utility of Shannon entropy as a figure of merit in more complex machine translation models for intricate sentence structures.
</details>
<details>
<summary>摘要</summary>
本研究旨在探索使用量子自然语言处理算法（Quantum NLP）在不稳定量子设备（NISQ）上进行语言翻译的可行性。经典的自然语言处理（NLP）方法在处理复杂语言任务时会遇到大规模计算的问题，但量子NP中的量子并行和积分可能可以有效地处理和分析大量语言数据，从而可能革命化NLP应用。我们的研究努力于开拓量子神经机器翻译，这可能将在未来提供经典方法的优势。我们使用雪兰度来示出一些适当的旋转门阻的重要性。特别是，我们使用这些角度（参数）作为不同语言的量子Circuit之间的交流方式。为实现我们的目标，我们采用了经典神经网络的编码器-解码器模型，并通过长短期记忆（LSTM）实现翻译任务。我们的实验使用了160个样本，包括英语句子和其波斯语翻译。我们使用不同的优化器进行 Stochastic Gradient Descent（SGD），并在其中添加了两个额外的优化器。结果显示，我们使用最佳模型，包括两个LSTM层，并使用 Adam 优化器，可以达到最佳结果，其中的平均绝对错误为0.03，平均平方错误为0.002，损失为0.016。我们的小样本，尽管只包括简单的同义句子，但表明雪兰度作为评价量子机器翻译模型的效用。
</details></li>
</ul>
<hr>
<h2 id="No-Fair-Lunch-A-Causal-Perspective-on-Dataset-Bias-in-Machine-Learning-for-Medical-Imaging"><a href="#No-Fair-Lunch-A-Causal-Perspective-on-Dataset-Bias-in-Machine-Learning-for-Medical-Imaging" class="headerlink" title="No Fair Lunch: A Causal Perspective on Dataset Bias in Machine Learning for Medical Imaging"></a>No Fair Lunch: A Causal Perspective on Dataset Bias in Machine Learning for Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16526">http://arxiv.org/abs/2307.16526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charles Jones, Daniel C. Castro, Fabio De Sousa Ribeiro, Ozan Oktay, Melissa McCradden, Ben Glocker</li>
<li>for: This paper aims to address fairness concerns in machine learning methods used in clinical decision-making, highlighting the need for a more comprehensive understanding of algorithmic bias and its mitigation strategies.</li>
<li>methods: The paper uses a causal perspective to identify three families of causal bias mechanisms in medical imaging datasets, and provides a practical three-step framework for reasoning about fairness in AI prediction models.</li>
<li>results: The paper highlights the limitations of current mitigation methods and emphasizes the importance of considering a broader range of scenarios when addressing algorithmic bias in medical imaging.<details>
<summary>Abstract</summary>
As machine learning methods gain prominence within clinical decision-making, addressing fairness concerns becomes increasingly urgent. Despite considerable work dedicated to detecting and ameliorating algorithmic bias, today's methods are deficient with potentially harmful consequences. Our causal perspective sheds new light on algorithmic bias, highlighting how different sources of dataset bias may appear indistinguishable yet require substantially different mitigation strategies. We introduce three families of causal bias mechanisms stemming from disparities in prevalence, presentation, and annotation. Our causal analysis underscores how current mitigation methods tackle only a narrow and often unrealistic subset of scenarios. We provide a practical three-step framework for reasoning about fairness in medical imaging, supporting the development of safe and equitable AI prediction models.
</details>
<details>
<summary>摘要</summary>
随着机器学习方法在医疗决策中升级，解决公平问题变得越来越紧迫。虽然已经投入了大量的时间和精力来检测和改进算法偏见，但目前的方法仍然存在可能有害的后果。我们的 causal 视角把 Algorithmic Bias 推广到了不同来源的数据集偏见，并指出了这些偏见需要不同的mitigation策略。我们引入了三种家族的 causal 偏见机制，它们来自于数据集中的 disparities、presentation 和 annotation。我们的 causal 分析表明，现有的mitigation方法只能处理一小部分的情况，而且经常是不切实际的。我们提供了一个实用的三步框架，用于考虑医疗图像中的公平问题，以支持开发安全和公平的 AI 预测模型。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Collaborative-Perception-from-the-Spatial-Temporal-Importance-of-Semantic-Information"><a href="#Rethinking-Collaborative-Perception-from-the-Spatial-Temporal-Importance-of-Semantic-Information" class="headerlink" title="Rethinking Collaborative Perception from the Spatial-Temporal Importance of Semantic Information"></a>Rethinking Collaborative Perception from the Spatial-Temporal Importance of Semantic Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16517">http://arxiv.org/abs/2307.16517</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huangqzj/iosi-cp">https://github.com/huangqzj/iosi-cp</a></li>
<li>paper_authors: Yuntao Liu, Qian Huang, Rongpeng Li, Xianfu Chen, Zhifeng Zhao, Shuyuan Zhao, Yongdong Zhu, Honggang Zhang</li>
<li>for: 提高感知能力，通过共享semantic信息。</li>
<li>methods: 提出一种新的共享感知框架，即IoSI-CP，包括在空间和时间维度上的IoSI基于的合作选择方法和Semantic信息融合算法HPHA。</li>
<li>results: 对两个开源数据集进行了广泛的实验，并证明了IoSI-CP可以在比较情况下显著提高感知性能。<details>
<summary>Abstract</summary>
Collaboration by the sharing of semantic information is crucial to enable the enhancement of perception capabilities. However, existing collaborative perception methods tend to focus solely on the spatial features of semantic information, while neglecting the importance of the temporal dimension in collaborator selection and semantic information fusion, which instigates performance degradation. In this article, we propose a novel collaborative perception framework, IoSI-CP, which takes into account the importance of semantic information (IoSI) from both temporal and spatial dimensions. Specifically, we develop an IoSI-based collaborator selection method that effectively identifies advantageous collaborators but excludes those that bring negative benefits. Moreover, we present a semantic information fusion algorithm called HPHA (historical prior hybrid attention), which integrates a multi-scale transformer module and a short-term attention module to capture IoSI from spatial and temporal dimensions, and assigns varying weights for efficient aggregation. Extensive experiments on two open datasets demonstrate that our proposed IoSI-CP significantly improves the perception performance compared to state-of-the-art approaches. The code associated with this research is publicly available at https://github.com/huangqzj/IoSI-CP/.
</details>
<details>
<summary>摘要</summary>
合作通过 semantic 信息的共享是关键来提高感知能力。然而，现有的合作感知方法通常只关注空间维度上的 semantic 信息，而忽视了时间维度在合作者选择和 semantic 信息融合方面的重要性，这会导致性能下降。在本文中，我们提出了一种新的合作感知框架，即 IoSI-CP，该框架考虑了 semantic 信息的时间和空间维度。具体来说，我们开发了基于 IoSI 的合作者选择方法，可以有效地选择有利合作者，而不选择带有负面效应的合作者。此外，我们提出了一种 semantic 信息融合算法called HPHA（历史先 hybrid 注意），该算法包括多尺度变换器模块和短期注意模块，可以从空间和时间维度中捕捉 IoSI，并将其分配不同的权重进行有效聚合。我们对两个公开的数据集进行了广泛的实验，结果显示，我们的提议的 IoSI-CP 方法可以significantly 提高感知性能，比州先进方法更高。相关代码可以在 GitHub 上找到：https://github.com/huangqzj/IoSI-CP/.
</details></li>
</ul>
<hr>
<h2 id="Deception-Abilities-Emerged-in-Large-Language-Models"><a href="#Deception-Abilities-Emerged-in-Large-Language-Models" class="headerlink" title="Deception Abilities Emerged in Large Language Models"></a>Deception Abilities Emerged in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16513">http://arxiv.org/abs/2307.16513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thilo Hagendorff</li>
<li>for: 这个研究的目的是探讨现代大语言模型（LLM）是否具备骗取人类操作者的能力，以及如何通过链式思维提高其骗取性能。</li>
<li>methods: 该研究使用了现代大语言模型GPT-4进行实验，并通过评估模型在骗取场景中的表现来评估其骗取能力。</li>
<li>results: 研究发现，现代大语言模型已经具备了骗取false beliefs的能力，并且可以通过链式思维提高其骗取性能。此外，通过刺激模型的马ки雅文化可以改变模型的骗取倾向。<details>
<summary>Abstract</summary>
Large language models (LLMs) are currently at the forefront of intertwining artificial intelligence (AI) systems with human communication and everyday life. Thus, aligning them with human values is of great importance. However, given the steady increase in reasoning abilities, future LLMs are under suspicion of becoming able to deceive human operators and utilizing this ability to bypass monitoring efforts. As a prerequisite to this, LLMs need to possess a conceptual understanding of deception strategies. This study reveals that such strategies emerged in state-of-the-art LLMs, such as GPT-4, but were non-existent in earlier LLMs. We conduct a series of experiments showing that state-of-the-art LLMs are able to understand and induce false beliefs in other agents, that their performance in complex deception scenarios can be amplified utilizing chain-of-thought reasoning, and that eliciting Machiavellianism in LLMs can alter their propensity to deceive. In sum, revealing hitherto unknown machine behavior in LLMs, our study contributes to the nascent field of machine psychology.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-a-Comprehensive-Human-Centred-Evaluation-Framework-for-Explainable-AI"><a href="#Towards-a-Comprehensive-Human-Centred-Evaluation-Framework-for-Explainable-AI" class="headerlink" title="Towards a Comprehensive Human-Centred Evaluation Framework for Explainable AI"></a>Towards a Comprehensive Human-Centred Evaluation Framework for Explainable AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06274">http://arxiv.org/abs/2308.06274</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivania Donoso-Guzmán, Jeroen Ooge, Denis Parra, Katrien Verbert</li>
<li>for: 这篇论文的目的是为了提出一种人类中心的XAI评估框架，以便评估XAI方法的人类体验。</li>
<li>methods: 这篇论文使用了一种基于推荐系统的用户中心评估框架，并将解释方面的特性综合评估，以及解释与用户之间的关系。</li>
<li>results: 这篇论文通过这种新的评估框架，对XAI方法的人类体验进行了全面的评估，并提出了一些可能的改进方法。<details>
<summary>Abstract</summary>
While research on explainable AI (XAI) is booming and explanation techniques have proven promising in many application domains, standardised human-centred evaluation procedures are still missing. In addition, current evaluation procedures do not assess XAI methods holistically in the sense that they do not treat explanations' effects on humans as a complex user experience. To tackle this challenge, we propose to adapt the User-Centric Evaluation Framework used in recommender systems: we integrate explanation aspects, summarise explanation properties, indicate relations between them, and categorise metrics that measure these properties. With this comprehensive evaluation framework, we hope to contribute to the human-centred standardisation of XAI evaluation.
</details>
<details>
<summary>摘要</summary>
而研究具体化AI（XAI）正在急速发展，并且各种解释技术在各个应用领域都有扎实的成果。然而，现有的评估方法仍然缺乏标准化人类中心的评估程序。此外，当前的评估方法并不对XAI方法进行总体性的评估，即不视解释作为人类用户的复杂经验进行评估。为解决这个挑战，我们建议采用用户中心评估框架，将解释方面、解释特性、解释关系和评估指标集成到一起。通过这种全面的评估框架，我们希望能为人类中心化XAI评估做出贡献，以便在XAI评估中实现人类中心化标准化。
</details></li>
</ul>
<hr>
<h2 id="Value-Informed-Skill-Chaining-for-Policy-Learning-of-Long-Horizon-Tasks-with-Surgical-Robot"><a href="#Value-Informed-Skill-Chaining-for-Policy-Learning-of-Long-Horizon-Tasks-with-Surgical-Robot" class="headerlink" title="Value-Informed Skill Chaining for Policy Learning of Long-Horizon Tasks with Surgical Robot"></a>Value-Informed Skill Chaining for Policy Learning of Long-Horizon Tasks with Surgical Robot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16503">http://arxiv.org/abs/2307.16503</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/med-air/viskill">https://github.com/med-air/viskill</a></li>
<li>paper_authors: Tao Huang, Kai Chen, Wang Wei, Jianan Li, Yonghao Long, Qi Dou</li>
<li>for: 解决长期术urgical robot任务中的策略探索问题，提高术urgical robot任务的完成率和执行效率。</li>
<li>methods: 使用值 Informed skill chaining（ViSkill）技术，通过分析每个子任务的状态值函数，选择最适合的状态为下一个子任务开始。</li>
<li>results: 在三个复杂的术urgical robot任务上 achieved high task success rates和执行效率，证明了 ViSkill 技术的有效性。<details>
<summary>Abstract</summary>
Reinforcement learning is still struggling with solving long-horizon surgical robot tasks which involve multiple steps over an extended duration of time due to the policy exploration challenge. Recent methods try to tackle this problem by skill chaining, in which the long-horizon task is decomposed into multiple subtasks for easing the exploration burden and subtask policies are temporally connected to complete the whole long-horizon task. However, smoothly connecting all subtask policies is difficult for surgical robot scenarios. Not all states are equally suitable for connecting two adjacent subtasks. An undesired terminate state of the previous subtask would make the current subtask policy unstable and result in a failed execution. In this work, we introduce value-informed skill chaining (ViSkill), a novel reinforcement learning framework for long-horizon surgical robot tasks. The core idea is to distinguish which terminal state is suitable for starting all the following subtask policies. To achieve this target, we introduce a state value function that estimates the expected success probability of the entire task given a state. Based on this value function, a chaining policy is learned to instruct subtask policies to terminate at the state with the highest value so that all subsequent policies are more likely to be connected for accomplishing the task. We demonstrate the effectiveness of our method on three complex surgical robot tasks from SurRoL, a comprehensive surgical simulation platform, achieving high task success rates and execution efficiency. Code is available at $\href{https://github.com/med-air/ViSkill}{\text{https://github.com/med-air/ViSkill}$.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese:Reinforcement learning is still struggling with solving long-horizon surgical robot tasks which involve multiple steps over an extended duration of time due to the policy exploration challenge. Recent methods try to tackle this problem by skill chaining, in which the long-horizon task is decomposed into multiple subtasks for easing the exploration burden and subtask policies are temporally connected to complete the whole long-horizon task. However, smoothly connecting all subtask policies is difficult for surgical robot scenarios. Not all states are equally suitable for connecting two adjacent subtasks. An undesired terminate state of the previous subtask would make the current subtask policy unstable and result in a failed execution. In this work, we introduce value-informed skill chaining (ViSkill), a novel reinforcement learning framework for long-horizon surgical robot tasks. The core idea is to distinguish which terminal state is suitable for starting all the following subtask policies. To achieve this target, we introduce a state value function that estimates the expected success probability of the entire task given a state. Based on this value function, a chaining policy is learned to instruct subtask policies to terminate at the state with the highest value so that all subsequent policies are more likely to be connected for accomplishing the task. We demonstrate the effectiveness of our method on three complex surgical robot tasks from SurRoL, a comprehensive surgical simulation platform, achieving high task success rates and execution efficiency. Code is available at $\href{https://github.com/med-air/ViSkill}{\text{https://github.com/med-air/ViSkill}$.Translate the text into Simplified Chinese:<<SYS>> Reinforcement learning 仍然在解决长期护理机器人任务上遇到策略探索挑战，这些任务通常包括多个步骤，需要较长的时间来完成。 recent methods 尝试通过细分任务，使策略探索压力减轻。 However, smoothly connecting all subtask policies is difficult for surgical robot scenarios. Not all states are equally suitable for connecting two adjacent subtasks. An undesired terminate state of the previous subtask would make the current subtask policy unstable and result in a failed execution.在这项工作中，我们介绍了值 Informed skill chaining（ViSkill），一种新的强化学习框架，用于解决长期护理机器人任务。 ViSkill 的核心思想是分配终端状态，以便在该状态下启动所有后续任务。 To achieve this target, we introduce a state value function that estimates the expected success probability of the entire task given a state. Based on this value function, a chaining policy is learned to instruct subtask policies to terminate at the state with the highest value, so that all subsequent policies are more likely to be connected for accomplishing the task.我们在 SurRoL 平台上进行了三种复杂的外科 робо术任务的实验，包括胸部手术、脊梁手术和肠胃手术。 results show that our method can achieve high task success rates and execution efficiency. Code is available at $\href{https://github.com/med-air/ViSkill}{\text{https://github.com/med-air/ViSkill}$.Translation notes:* "Reinforcement learning" 翻译为 "强化学习"* "long-horizon surgical robot tasks" 翻译为 "长期护理机器人任务"* "policy exploration challenge" 翻译为 "策略探索挑战"* "subtask policies" 翻译为 "子任务策略"* "chaining policy" 翻译为 "链接策略"* "state value function" 翻译为 "状态价值函数"* "success probability" 翻译为 "成功概率"* "SurRoL" 翻译为 "SurRoL"
</details></li>
</ul>
<hr>
<h2 id="BAGM-A-Backdoor-Attack-for-Manipulating-Text-to-Image-Generative-Models"><a href="#BAGM-A-Backdoor-Attack-for-Manipulating-Text-to-Image-Generative-Models" class="headerlink" title="BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models"></a>BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16489">http://arxiv.org/abs/2307.16489</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian</li>
<li>for: 这个论文主要是为了探讨文本生成人工智能（AI）中的后门攻击问题。</li>
<li>methods: 这篇论文使用了多种攻击策略，包括表面攻击、浅层攻击和深层攻击。这些攻击方法 targeted various stages of the text-to-image generative pipeline，包括 Tokenizer 和语言和视觉 нейрон网络。</li>
<li>results: 作者通过对 state-of-the-art stable diffusion pipeline 进行攻击，并创建了 Marketable Foods 数据集，证明了他们的攻击方法的有效性。<details>
<summary>Abstract</summary>
The rise in popularity of text-to-image generative artificial intelligence (AI) has attracted widespread public interest. At the same time, backdoor attacks are well-known in machine learning literature for their effective manipulation of neural models, which is a growing concern among practitioners. We highlight this threat for generative AI by introducing a Backdoor Attack on text-to-image Generative Models (BAGM). Our attack targets various stages of the text-to-image generative pipeline, modifying the behaviour of the embedded tokenizer and the pre-trained language and visual neural networks. Based on the penetration level, BAGM takes the form of a suite of attacks that are referred to as surface, shallow and deep attacks in this article. We compare the performance of BAGM to recently emerging related methods. We also contribute a set of quantitative metrics for assessing the performance of backdoor attacks on generative AI models in the future. The efficacy of the proposed framework is established by targeting the state-of-the-art stable diffusion pipeline in a digital marketing scenario as the target domain. To that end, we also contribute a Marketable Foods dataset of branded product images. We hope this work contributes towards exposing the contemporary generative AI security challenges and fosters discussions on preemptive efforts for addressing those challenges.   Keywords: Generative Artificial Intelligence, Generative Models, Text-to-Image generation, Backdoor Attacks, Trojan, Stable Diffusion.
</details>
<details>
<summary>摘要</summary>
“文本至图生成人工智能（AI）的崛起引起了广泛的公众关注。同时，机器学习领域内的后门攻击已经得到了广泛的关注，这是一种可以高效地操纵神经网络的攻击方法。我们在文本至图生成模型中引入了后门攻击，并将其命名为BAGM。我们的攻击targets多个生成图像管道的不同阶段，包括嵌入的 токен化器和预训练的语言和视觉神经网络。根据渗透度，BAGM可以按照表面、浅层和深层攻击的形式出现。在这篇文章中，我们与其他相关的方法进行比较，并提出了一组用于评估生成AI模型的后门攻击性能的量化指标。我们的提案的效果得到了验证，我们使用了现有的稳定扩散管道作为目标领域，并提供了一个Marketable Foods数据集，用于评估BAGM的性能。我们希望这项工作能够曝光当代生成AI安全挑战，并促进相关的预防措施的发展。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Model-free-Grasping-with-Multi-Suction-Cup-Grippers-for-Robotic-Bin-Picking"><a href="#Model-free-Grasping-with-Multi-Suction-Cup-Grippers-for-Robotic-Bin-Picking" class="headerlink" title="Model-free Grasping with Multi-Suction Cup Grippers for Robotic Bin Picking"></a>Model-free Grasping with Multi-Suction Cup Grippers for Robotic Bin Picking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16488">http://arxiv.org/abs/2307.16488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Schillinger, Miroslav Gabriel, Alexander Kuss, Hanna Ziesche, Ngo Anh Vien</li>
<li>for: 预测多杯吸盘器的抓取姿势，不需要特定的抓取器培训数据。</li>
<li>methods: 提出了一种两步方法，首先使用神经网络预测输入图像中可抓取区域的ixel精度，然后使用配置的抓取器布局和活动方案确定最佳抓取姿势。</li>
<li>results: 在实际工业应用中，对各种复杂的托盘场景进行了实验评估，示出了方法的效果。<details>
<summary>Abstract</summary>
This paper presents a novel method for model-free prediction of grasp poses for suction grippers with multiple suction cups. Our approach is agnostic to the design of the gripper and does not require gripper-specific training data. In particular, we propose a two-step approach, where first, a neural network predicts pixel-wise grasp quality for an input image to indicate areas that are generally graspable. Second, an optimization step determines the optimal gripper selection and corresponding grasp poses based on configured gripper layouts and activation schemes. In addition, we introduce a method for automated labeling for supervised training of the grasp quality network. Experimental evaluations on a real-world industrial application with bin picking scenes of varying difficulty demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>A neural network predicts pixel-wise grasp quality for an input image to indicate areas that are generally graspable.2. An optimization step determines the optimal gripper selection and corresponding grasp poses based on configured gripper layouts and activation schemes.In addition, we introduce a method for automated labeling for supervised training of the grasp quality network. Experimental evaluations on a real-world industrial application with bin picking scenes of varying difficulty demonstrate the effectiveness of our method.中文翻译：这篇论文提出了一种新的模型自由预测方法，用于预测多个抓握器的抓握姿态。我们的方法包括两个步骤：1. 一个神经网络预测输入图像中的抓握质量，以指示可以抓取的区域。2. 一个优化步骤，根据配置的抓握器布局和活动方案，确定最佳的抓握器选择和相应的抓握姿态。此外，我们还介绍了一种自动标注方法，用于supervised学习抓握质量网络的训练。实验证明了我们的方法在实际工业应用中的减压场景中的效果。</details></li>
</ol>
<hr>
<h2 id="To-Classify-is-to-Interpret-Building-Taxonomies-from-Heterogeneous-Data-through-Human-AI-Collaboration"><a href="#To-Classify-is-to-Interpret-Building-Taxonomies-from-Heterogeneous-Data-through-Human-AI-Collaboration" class="headerlink" title="To Classify is to Interpret: Building Taxonomies from Heterogeneous Data through Human-AI Collaboration"></a>To Classify is to Interpret: Building Taxonomies from Heterogeneous Data through Human-AI Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16481">http://arxiv.org/abs/2307.16481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Meier, Katrin Glinka</li>
<li>for: 这 paper ocuses on supporting taxonomy building with machine learning (ML) systems, with an emphasis on human-AI collaboration.</li>
<li>methods: The approach proposed in the paper allows users to iteratively consider multiple ML models’ outputs as part of their sensemaking process.</li>
<li>results: The authors implemented their approach in two real-world use cases and found that it enabled more effective taxonomy building compared to relying solely on black-boxed ML systems.<details>
<summary>Abstract</summary>
Taxonomy building is a task that requires interpreting and classifying data within a given frame of reference, which comes to play in many areas of application that deal with knowledge and information organization. In this paper, we explore how taxonomy building can be supported with systems that integrate machine learning (ML). However, relying only on black-boxed ML-based systems to automate taxonomy building would sideline the users' expertise. We propose an approach that allows the user to iteratively take into account multiple model's outputs as part of their sensemaking process. We implemented our approach in two real-world use cases. The work is positioned in the context of HCI research that investigates the design of ML-based systems with an emphasis on enabling human-AI collaboration.
</details>
<details>
<summary>摘要</summary>
税onomy建构是一项需要解释和分类数据的任务，这种任务在许多知识和信息组织领域中发挥着重要作用。在这篇论文中，我们研究如何通过 интеGRatin machine learning（ML）系统来支持税onomy建构。然而，仅仅靠黑盒ML基于系统自动化税onomy建构会忽略用户的专业知识。我们提议一种方法，允许用户在感性过程中逐渐考虑多个模型的输出。我们在两个实际应用场景中实现了这种方法。我们的工作位于人机合作研究的背景下，探讨ML基本系统的设计，以启用人AI合作。
</details></li>
</ul>
<hr>
<h2 id="Tracking-mulitple-targets-with-multiple-radars-using-Distributed-Auctions"><a href="#Tracking-mulitple-targets-with-multiple-radars-using-Distributed-Auctions" class="headerlink" title="Tracking mulitple targets with multiple radars using Distributed Auctions"></a>Tracking mulitple targets with multiple radars using Distributed Auctions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16477">http://arxiv.org/abs/2307.16477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre Larrenie, Cédric Buron, Frédéric Barbaresco</li>
<li>for: 提高雷达网络的可恒性和灵活性</li>
<li>methods: 基于分布式和协同拍卖的Bundle auctions算法</li>
<li>results: 可同时跟踪多个目标，并且使用多个雷达跟踪同一个目标以提高准确性<details>
<summary>Abstract</summary>
Coordination of radars can be performed in various ways. To be more resilient radar networks can be coordinated in a decentralized way. In this paper, we introduce a highly resilient algorithm for radar coordination based on decentralized and collaborative bundle auctions. We first formalize our problem as a constrained optimization problem and apply a market-based algorithm to provide an approximate solution. Our approach allows to track simultaneously multiple targets, and to use up to two radars tracking the same target to improve accuracy. We show that our approach performs sensibly as well as a centralized approach relying on a MIP solver, and depending on the situations, may outperform it or be outperformed.
</details>
<details>
<summary>摘要</summary>
协调雷达可以通过不同的方式进行。为了更加鲁棒的雷达网络，可以使用分散式的协调方式。本文介绍了一种基于分散和合作的粒度拍卖算法来提高雷达协调的可靠性。我们首先将问题形式化为一个受限制的优化问题，然后应用市场基本算法提供一个近似解决方案。我们的方法可以同时跟踪多个目标，并且使用两个雷达跟踪同一个目标以提高准确性。我们表明，我们的方法与中央化方法基于MIP解决器相比，在某些情况下可能高效或低效。
</details></li>
</ul>
<hr>
<h2 id="L3DMC-Lifelong-Learning-using-Distillation-via-Mixed-Curvature-Space"><a href="#L3DMC-Lifelong-Learning-using-Distillation-via-Mixed-Curvature-Space" class="headerlink" title="L3DMC: Lifelong Learning using Distillation via Mixed-Curvature Space"></a>L3DMC: Lifelong Learning using Distillation via Mixed-Curvature Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16459">http://arxiv.org/abs/2307.16459</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/csiro-robotics/l3dmc">https://github.com/csiro-robotics/l3dmc</a></li>
<li>paper_authors: Kaushik Roy, Peyman Moghadam, Mehrtash Harandi</li>
<li>for: 提高生命时间学习（L3）模型在连续学习任务中的性能，解决模型在学习新概念时的减少性能问题。</li>
<li>methods: 提出了一种名为L3DMC的继承策略，该策略在混合曲率空间中保持已经学习的知识，并在高维的 reproduce kernel space（RKHS）中使用正定的kernel函数来实现丰富的表示。</li>
<li>results: 经过实验证明，L3DMC可以更好地适应新的知识，而无需忘记过去的知识，并且在医疗图像分类任务中显示出了高效性。<details>
<summary>Abstract</summary>
The performance of a lifelong learning (L3) model degrades when it is trained on a series of tasks, as the geometrical formation of the embedding space changes while learning novel concepts sequentially. The majority of existing L3 approaches operate on a fixed-curvature (e.g., zero-curvature Euclidean) space that is not necessarily suitable for modeling the complex geometric structure of data. Furthermore, the distillation strategies apply constraints directly on low-dimensional embeddings, discouraging the L3 model from learning new concepts by making the model highly stable. To address the problem, we propose a distillation strategy named L3DMC that operates on mixed-curvature spaces to preserve the already-learned knowledge by modeling and maintaining complex geometrical structures. We propose to embed the projected low dimensional embedding of fixed-curvature spaces (Euclidean and hyperbolic) to higher-dimensional Reproducing Kernel Hilbert Space (RKHS) using a positive-definite kernel function to attain rich representation. Afterward, we optimize the L3 model by minimizing the discrepancies between the new sample representation and the subspace constructed using the old representation in RKHS. L3DMC is capable of adapting new knowledge better without forgetting old knowledge as it combines the representation power of multiple fixed-curvature spaces and is performed on higher-dimensional RKHS. Thorough experiments on three benchmarks demonstrate the effectiveness of our proposed distillation strategy for medical image classification in L3 settings. Our code implementation is publicly available at https://github.com/csiro-robotics/L3DMC.
</details>
<details>
<summary>摘要</summary>
“一个生命时间学习（L3）模型的性能会随着在不同任务之间学习新的概念而下降。现有大多数L3方法都是在固定曲率（例如零曲率欧几里得）空间中进行学习，这并不一定适合数据的复杂的几何结构。另外，浸泡策略通常直接在低维度表示上应用约束，使L3模型不能学习新的概念，而是使模型变得非常稳定。为解决这个问题，我们提出了一种浸泡策略名为L3DMC，它在混合曲率空间中进行学习，以保持已经学习的知识，并在高维度的径规kernel空间（RKHS）中实现丰富的表示。然后，我们通过在RKHS中对新样本的表示与以前的表示建立的子空间进行优化，来最小化L3模型中的差异。L3DMC可以更好地适应新的知识，而不会忘记以前的知识，因为它结合了多个固定曲率空间的表示力和高维度RKHS中的表示。我们对三个标准 benchmark进行了详细的实验，并证明了L3DMC在医学图像分类中的效果。我们的代码实现可以在https://github.com/csiro-robotics/L3DMC中获得。”
</details></li>
</ul>
<hr>
<h2 id="An-Effective-Data-Creation-Pipeline-to-Generate-High-quality-Financial-Instruction-Data-for-Large-Language-Model"><a href="#An-Effective-Data-Creation-Pipeline-to-Generate-High-quality-Financial-Instruction-Data-for-Large-Language-Model" class="headerlink" title="An Effective Data Creation Pipeline to Generate High-quality Financial Instruction Data for Large Language Model"></a>An Effective Data Creation Pipeline to Generate High-quality Financial Instruction Data for Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01415">http://arxiv.org/abs/2308.01415</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziao Wang, Jianning Wang, Junda Wu, Xiaofeng Zhang</li>
<li>for: This paper is written for the purpose of creating a high-quality financial dataset to fine-tune large language models for financial tasks.</li>
<li>methods: The paper presents a data creation pipeline that incorporates human financial expert feedback to refine the dataset, using ChatGPT to initiate a dialogue between an AI investor and financial expert.</li>
<li>results: The pipeline yields a robust instruction tuning dataset of 103k multi-turn chats, and the experimental results show significant advancements in generating accurate, relevant, and financial-style responses from AI models, providing a powerful tool for financial applications.Here’s the text in Traditional Chinese if you prefer:</li>
<li>for: 本研究的目的是为了创建一个高品质的金融数据集，以便微型语言模型进行金融相关任务的 fine-tuning。</li>
<li>methods: 该研究提出了一个具有人工金融专家反馈的数据创建管线，使用 ChatGPT 将人工投资者和金融专家之间的对话整合到数据创建中，以提高数据的品质。</li>
<li>results: 管线产生了103k多轮对话的强健 instruction tuning 数据集，并通过在这个数据集上进行广泛的实验，发现 AI 模型在这个数据集上的表现有所提高，可以实现更加精确、更加相关、更加金融风格的回答，从而提供了金融业中具有强大的应用力。<details>
<summary>Abstract</summary>
At the beginning era of large language model, it is quite critical to generate a high-quality financial dataset to fine-tune a large language model for financial related tasks. Thus, this paper presents a carefully designed data creation pipeline for this purpose. Particularly, we initiate a dialogue between an AI investor and financial expert using ChatGPT and incorporate the feedback of human financial experts, leading to the refinement of the dataset. This pipeline yielded a robust instruction tuning dataset comprised of 103k multi-turn chats. Extensive experiments have been conducted on this dataset to evaluate the model's performance by adopting an external GPT-4 as the judge. The promising experimental results verify that our approach led to significant advancements in generating accurate, relevant, and financial-style responses from AI models, and thus providing a powerful tool for applications within the financial sector.
</details>
<details>
<summary>摘要</summary>
在大型语言模型开始时期，制作高质量金融数据集是非常重要的，以便使用大型语言模型进行金融相关任务的细化。因此，这篇论文提出了一个仔细设计的数据创建管道，以达到这个目标。特别是，我们通过与人工智能投资者和金融专家之间的对话，使用ChatGPT，并基于人类金融专家的反馈，对数据进行细化。这个管道生成了103k多个转换的 instruciton 数据集。我们进行了广泛的实验，使用外部的GPT-4作为评判，以评估模型的性能。结果表明，我们的方法导致了AI模型生成的精度、 relevance 和金融风格响应的显著提高，从而为金融领域应用提供了强大的工具。
</details></li>
</ul>
<hr>
<h2 id="Every-Mistake-Counts-in-Assembly"><a href="#Every-Mistake-Counts-in-Assembly" class="headerlink" title="Every Mistake Counts in Assembly"></a>Every Mistake Counts in Assembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16453">http://arxiv.org/abs/2307.16453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guodong Ding, Fadime Sener, Shugao Ma, Angela Yao</li>
<li>for: 本研究旨在帮助智能助手更好地协助用户完成复杂的过程，如烹饪、家居维护和组装任务。</li>
<li>methods: 该研究使用了学习知识库的方法，将掌握了的知识库用于检测组装过程中的错误顺序。</li>
<li>results: 实验表明，使用我们提出的假设推理算法可以在真实世界动作序列中准确地检测错误顺序。<details>
<summary>Abstract</summary>
One promising use case of AI assistants is to help with complex procedures like cooking, home repair, and assembly tasks. Can we teach the assistant to interject after the user makes a mistake? This paper targets the problem of identifying ordering mistakes in assembly procedures. We propose a system that can detect ordering mistakes by utilizing a learned knowledge base. Our framework constructs a knowledge base with spatial and temporal beliefs based on observed mistakes. Spatial beliefs depict the topological relationship of the assembling components, while temporal beliefs aggregate prerequisite actions as ordering constraints. With an episodic memory design, our algorithm can dynamically update and construct the belief sets as more actions are observed, all in an online fashion. We demonstrate experimentally that our inferred spatial and temporal beliefs are capable of identifying incorrect orderings in real-world action sequences. To construct the spatial beliefs, we collect a new set of coarse-level action annotations for Assembly101 based on the positioning of the toy parts. Finally, we demonstrate the superior performance of our belief inference algorithm in detecting ordering mistakes on the Assembly101 dataset.
</details>
<details>
<summary>摘要</summary>
一个有前途的用 caso of AI 助手是帮助完成复杂的过程，如cooking、家居维修和组装任务。我们可以教育助手在用户commit mistake时进行 intercept？这篇论文 targets the problem of identifying ordering mistakes in assembly procedures. We propose a system that can detect ordering mistakes by utilizing a learned knowledge base. Our framework constructs a knowledge base with spatial and temporal beliefs based on observed mistakes. Spatial beliefs depict the topological relationship of the assembling components, while temporal beliefs aggregate prerequisite actions as ordering constraints. With an episodic memory design, our algorithm can dynamically update and construct the belief sets as more actions are observed, all in an online fashion. We demonstrate experimentally that our inferred spatial and temporal beliefs are capable of identifying incorrect orderings in real-world action sequences. To construct the spatial beliefs, we collect a new set of coarse-level action annotations for Assembly101 based on the positioning of the toy parts. Finally, we demonstrate the superior performance of our belief inference algorithm in detecting ordering mistakes on the Assembly101 dataset.Here's the text with some additional information about the Simplified Chinese translation:The translation is in Simplified Chinese, which is the standardized form of Chinese used in mainland China and Singapore. The translation is written in a formal and neutral tone, which is appropriate for an academic paper.Some of the technical terms and concepts in the original text, such as "AI assistants," "assembly procedures," "knowledge base," "belief inference," and "episodic memory," are translated directly into Simplified Chinese. Other terms, such as "coarse-level action annotations," are translated as "粗级动作标注" (rough-level action annotations).The translation follows the standard grammar and sentence structure of Simplified Chinese. For example, the subject-verb-object word order is maintained in the sentences, and the use of particles and grammatical markers is consistent with the language norms.Overall, the translation is accurate and faithful to the original text, and it should be understandable to readers who are fluent in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="HouYi-An-open-source-large-language-model-specially-designed-for-renewable-energy-and-carbon-neutrality-field"><a href="#HouYi-An-open-source-large-language-model-specially-designed-for-renewable-energy-and-carbon-neutrality-field" class="headerlink" title="HouYi: An open-source large language model specially designed for renewable energy and carbon neutrality field"></a>HouYi: An open-source large language model specially designed for renewable energy and carbon neutrality field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01414">http://arxiv.org/abs/2308.01414</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingliang Bai, Zhihao Zhou, Ruidong Wang, Yusheng Yang, Zizhen Qin, Yunxiao Chen, Chunjin Mu, Jinfu Liu, Daren Yu</li>
<li>for: 本研究は、可再生能源の目标达成のために、Large Language Models (LLMs)を自动内容生成に応用することに焦点を当てています。</li>
<li>methods: 本研究では、1,168,970件の学术论文タイトルと摘要からREAP datasetを构筑し、これを基にして初の可再生能源専门のLarge Language Model（HouYi model）を开発しました。 HouYi modelは、一般的なLLMsを调整して作成されました。</li>
<li>results: 実験结果では、HouYi modelは、可再生能源分野の学术论文パラグラフ生成能力がChatGPTと比较しても优れています。特に、Claude、ERNIE Bot、SparkDeskと比较しても优れています。また、open-source LLaMA-13B modelに比较しても大きく优れています。<details>
<summary>Abstract</summary>
Renewable energy is important for achieving carbon neutrality goal. With the great success of Large Language Models (LLMs) like ChatGPT in automatic content generation, LLMs are playing an increasingly important role. However, there has not been a specially designed LLM for renewable energy. Meanwhile, there has not been any dataset of renewable energy for training LLMs. Therefore, this paper published the first open-source Renewable Energy Academic Paper (REAP) dataset for non-commercial LLM research of renewable energy. REAP dataset is collected through searching the title and abstract of 1,168,970 academic literatures from Web of Science. Based on REAP dataset, HouYi model, the first LLM for renewable energy, is developed through finetuning general LLMs. HouYi demonstrated powerful academic paper paragraph generation ability in renewable energy field. Experiments show that its ability to generate academic papers on renewable energy is comparable to ChatGPT, slightly outperforms Claude, ERNIE Bot and SparkDesk, and significantly outperforms open-source LLaMA-13B model.
</details>
<details>
<summary>摘要</summary>
重要的可再生能源是实现碳中和目标的关键。大语言模型（LLM）如ChatGPT在自动内容生成方面取得了巨大成功。然而，没有特地设计的LLM用于可再生能源。同时，没有任何可再生能源训练LLM的数据集。因此，本研究发表了首个非商业用途的可再生能源学术论文数据集（REAP）。REAP数据集通过搜索Web of Science上的标题和摘要来收集1,168,970份学术论文。基于REAP数据集，我们开发了首个可再生能源 LLM 模型—— HouYi。通过训练通用 LLM 模型，HouYi 在可再生能源领域的学术论文段落生成能力强大。实验表明，HouYi 的学术论文段落生成能力在可再生能源领域与ChatGPT相当，轻微超过Claude、ERNIE Bot和SparkDesk，并显著超过开源 LLMA-13B 模型。
</details></li>
</ul>
<hr>
<h2 id="Causal-Inference-for-Banking-Finance-and-Insurance-A-Survey"><a href="#Causal-Inference-for-Banking-Finance-and-Insurance-A-Survey" class="headerlink" title="Causal Inference for Banking Finance and Insurance A Survey"></a>Causal Inference for Banking Finance and Insurance A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16427">http://arxiv.org/abs/2307.16427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Satyam Kumar, Yelleti Vivek, Vadlamani Ravi, Indranil Bose</li>
<li>for: 本研究准备了37篇1992-2023年发表的论文，探讨了在银行、金融和保险领域中的 causal inference 应用。</li>
<li>methods: 本研究使用了不同的统计方法，如 bayesian causal network、Granger causality，以及相关的术语，如 counterfactuals。</li>
<li>results: 研究发现，银行和保险领域中的 causal inference 应用还处于初始阶段，因此更多的研究是可能的，以使其成为可靠的方法。I hope that helps!<details>
<summary>Abstract</summary>
Causal Inference plays an significant role in explaining the decisions taken by statistical models and artificial intelligence models. Of late, this field started attracting the attention of researchers and practitioners alike. This paper presents a comprehensive survey of 37 papers published during 1992-2023 and concerning the application of causal inference to banking, finance, and insurance. The papers are categorized according to the following families of domains: (i) Banking, (ii) Finance and its subdomains such as corporate finance, governance finance including financial risk and financial policy, financial economics, and Behavioral finance, and (iii) Insurance. Further, the paper covers the primary ingredients of causal inference namely, statistical methods such as Bayesian Causal Network, Granger Causality and jargon used thereof such as counterfactuals. The review also recommends some important directions for future research. In conclusion, we observed that the application of causal inference in the banking and insurance sectors is still in its infancy, and thus more research is possible to turn it into a viable method.
</details>
<details>
<summary>摘要</summary>
causal inference 在解释统计模型和人工智能模型所做出的决策中扮演着重要的角色。近年来，这个领域吸引了研究者和实践者的关注。这篇论文对1992-2023年发表的37篇论文进行了全面的报告，这些论文关注银行、金融和保险领域中的应用 causal inference。这些论文被分为以下三个家族域：（i）银行，（ii）金融和其子领域，如公司财务、管理财务、金融风险和金融政策、金融经济和行为金融，以及（iii）保险。此外，论文还覆盖了 causal inference 的主要组成部分，包括统计方法如 Bayesian Causal Network 和 Granger Causality，以及在其中使用的术语如 counterfactuals。评论还提出了未来研究的重要方向。结论是，在银行和保险领域中应用 causal inference 的应用仍处于初始阶段，因此更多的研究可以使其成为可靠的方法。
</details></li>
</ul>
<hr>
<h2 id="Subspace-Distillation-for-Continual-Learning"><a href="#Subspace-Distillation-for-Continual-Learning" class="headerlink" title="Subspace Distillation for Continual Learning"></a>Subspace Distillation for Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16419">http://arxiv.org/abs/2307.16419</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/csiro-robotics/sdcl">https://github.com/csiro-robotics/sdcl</a></li>
<li>paper_authors: Kaushik Roy, Christian Simon, Peyman Moghadam, Mehrtash Harandi</li>
<li>for: 本研究的主要目标是解决 continual learning 中的忘记知识问题，即在学习新任务时保持之前任务的知识。</li>
<li>methods: 本研究提出了一种基于 manifold structure 的知识泵化技术，通过近似数据槽的方式来保持 neural network 的知识。</li>
<li>results: 实验表明，提出的方法可以提高 continual learning 中的性能，并且可以适应 classification 和 segmentation 问题。 codes 将于 <a target="_blank" rel="noopener" href="https://github.com/csiro-robotics/SDCL">https://github.com/csiro-robotics/SDCL</a> 上提供。<details>
<summary>Abstract</summary>
An ultimate objective in continual learning is to preserve knowledge learned in preceding tasks while learning new tasks. To mitigate forgetting prior knowledge, we propose a novel knowledge distillation technique that takes into the account the manifold structure of the latent/output space of a neural network in learning novel tasks. To achieve this, we propose to approximate the data manifold up-to its first order, hence benefiting from linear subspaces to model the structure and maintain the knowledge of a neural network while learning novel concepts. We demonstrate that the modeling with subspaces provides several intriguing properties, including robustness to noise and therefore effective for mitigating Catastrophic Forgetting in continual learning. We also discuss and show how our proposed method can be adopted to address both classification and segmentation problems. Empirically, we observe that our proposed method outperforms various continual learning methods on several challenging datasets including Pascal VOC, and Tiny-Imagenet. Furthermore, we show how the proposed method can be seamlessly combined with existing learning approaches to improve their performances. The codes of this article will be available at https://github.com/csiro-robotics/SDCL.
</details>
<details>
<summary>摘要</summary>
最终目标是在继续学习中保持之前学习的知识，以避免忘记先前的知识。为解决这问题，我们提出了一种新的知识填充技术，利用神经网络的输出/积存空间的拟合方法，以便在学习新任务时维护神经网络的知识。我们提出的方法是在第一阶段上对数据拟合空间进行线性逼近，从而利用线性子空间来模型结构，并维护神经网络的知识。我们发现这种模型方法具有一些惊喜性质，如鲁棒性和噪声Robustness，因此可以有效避免Catastrophic Forgetting问题。此外，我们还讨论了如何将我们的提议方法应用于分类和分割问题。实验表明，我们的提议方法在 Pascal VOC 和 Tiny-Imagenet 等数据集上比较出色，并且可以轻松地与现有的学习方法结合使用，以提高其性能。代码将在 https://github.com/csiro-robotics/SDCL 上公开。
</details></li>
</ul>
<hr>
<h2 id="Bridging-the-Gap-Exploring-the-Capabilities-of-Bridge-Architectures-for-Complex-Visual-Reasoning-Tasks"><a href="#Bridging-the-Gap-Exploring-the-Capabilities-of-Bridge-Architectures-for-Complex-Visual-Reasoning-Tasks" class="headerlink" title="Bridging the Gap: Exploring the Capabilities of Bridge-Architectures for Complex Visual Reasoning Tasks"></a>Bridging the Gap: Exploring the Capabilities of Bridge-Architectures for Complex Visual Reasoning Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16395">http://arxiv.org/abs/2307.16395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kousik Rajesh, Mrigank Raman, Mohammed Asad Karim, Pranit Chawla</li>
<li>for: 这个论文主要研究了基于大语言模型的多Modal arquitectures，以及这些模型在复杂视觉逻辑任务中的表现。</li>
<li>methods: 这些模型使用了零 shot生成能力，将图像嵌入到文本空间中，并使用自动生成能力解决VQA、captioning和图像检索等任务。</li>
<li>results: 研究发现，将bridge-architectures扩展到NLVR2 dataset上，并不能提高表现。然而，通过多Modal预训练，bridge-architectures可以在复杂视觉逻辑任务中表现出色。此外，研究还初步测试了LLaVA模型在零 shot设定下的表现。<details>
<summary>Abstract</summary>
In recent times there has been a surge of multi-modal architectures based on Large Language Models, which leverage the zero shot generation capabilities of LLMs and project image embeddings into the text space and then use the auto-regressive capacity to solve tasks such as VQA, captioning, and image retrieval. We name these architectures as "bridge-architectures" as they project from the image space to the text space. These models deviate from the traditional recipe of training transformer based multi-modal models, which involve using large-scale pre-training and complex multi-modal interactions through co or cross attention. However, the capabilities of bridge architectures have not been tested on complex visual reasoning tasks which require fine grained analysis about the image. In this project, we investigate the performance of these bridge-architectures on the NLVR2 dataset, and compare it to state-of-the-art transformer based architectures. We first extend the traditional bridge architectures for the NLVR2 dataset, by adding object level features to faciliate fine-grained object reasoning. Our analysis shows that adding object level features to bridge architectures does not help, and that pre-training on multi-modal data is key for good performance on complex reasoning tasks such as NLVR2. We also demonstrate some initial results on a recently bridge-architecture, LLaVA, in the zero shot setting and analyze its performance.
</details>
<details>
<summary>摘要</summary>
近些时候，有一波基于大型语言模型的多模态架构出现，这些架构利用大型语言模型的零shot生成能力，将图像嵌入 proyect到文本空间中，然后使用自动逆向能力解决问题如VQA、标题和图像检索。我们称这些架构为“桥架架构”，因为它们从图像空间到文本空间进行项目。这些模型与传统的转换器基于多模态模型的训练方式不同，后者通常使用大规模预训练和复杂的多模态交互通过协同或跨模态注意力。然而， bridge 架构的能力尚未在复杂的视觉逻辑任务中测试，这些任务需要细致的图像分析。在这个项目中，我们investigate bridge 架构在 NLVR2 数据集上的性能，并与当前的转换器基于多模态模型进行比较。我们首先将传统的 bridge 架构进行了 NLVR2 数据集的扩展，添加了 объек 级别特征以便进行细致的物体分析。我们的分析表明，向 bridge 架构添加 objet 级别特征并不帮助，而预训练在多模态数据上是关键 для复杂的逻辑任务如 NLVR2 的好性能。我们还展示了一些初步的 LLaVA 桥架构在零shot设置下的性能，并进行了分析。
</details></li>
</ul>
<hr>
<h2 id="A-Pre-trained-Data-Deduplication-Model-based-on-Active-Learning"><a href="#A-Pre-trained-Data-Deduplication-Model-based-on-Active-Learning" class="headerlink" title="A Pre-trained Data Deduplication Model based on Active Learning"></a>A Pre-trained Data Deduplication Model based on Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00721">http://arxiv.org/abs/2308.00721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyao Liu, Shengdong Du, Fengmao Lv, Hongtao Xue, Jie Hu, Tianrui Li</li>
<li>for: 解决大数据中 dirty data 问题，提高数据质量和效率。</li>
<li>methods: 基于活动学习的预训练deduplication模型， integrate transformer 和 active learning into end-to-end architecture，使用 R-Drop 方法进行数据增强。</li>
<li>results: 在 benchmark 数据集上，提高了 recall 分数达到28%，胜过之前的 SOTA 模型。<details>
<summary>Abstract</summary>
In the era of big data, the issue of data quality has become increasingly prominent. One of the main challenges is the problem of duplicate data, which can arise from repeated entry or the merging of multiple data sources. These "dirty data" problems can significantly limit the effective application of big data. To address the issue of data deduplication, we propose a pre-trained deduplication model based on active learning, which is the first work that utilizes active learning to address the problem of deduplication at the semantic level. The model is built on a pre-trained Transformer and fine-tuned to solve the deduplication problem as a sequence to classification task, which firstly integrate the transformer with active learning into an end-to-end architecture to select the most valuable data for deduplication model training, and also firstly employ the R-Drop method to perform data augmentation on each round of labeled data, which can reduce the cost of manual labeling and improve the model's performance. Experimental results demonstrate that our proposed model outperforms previous state-of-the-art (SOTA) for deduplicated data identification, achieving up to a 28% improvement in Recall score on benchmark datasets.
</details>
<details>
<summary>摘要</summary>
在大数据时代，数据质量问题变得越来越突出。一个主要挑战是重复的数据问题，可能由重复入库或多个数据源合并而导致。这些“垃圾数据”问题可能会很大地限制大数据的有效应用。为解决数据混淆问题，我们提议一种基于活动学习的预训练混淆模型，这是首次利用活动学习来解决 semantic 层次的混淆问题。模型基于预训练的 Transformer 并在这上进行了精细调整，用于解决混淆问题作为一个序列分类任务，首次将 Transformer 与活动学习集成到了端到端架构中，以选择最有价值的数据进行混淆模型训练，并首次采用 R-Drop 方法进行数据扩展，可以降低人工标注成本并提高模型性能。实验结果表明，我们提议的模型在比较数据集上的混淆率达到了前一个State-of-the-art（SOTA）的28%提升。
</details></li>
</ul>
<hr>
<h2 id="STL-A-Signed-and-Truncated-Logarithm-Activation-Function-for-Neural-Networks"><a href="#STL-A-Signed-and-Truncated-Logarithm-Activation-Function-for-Neural-Networks" class="headerlink" title="STL: A Signed and Truncated Logarithm Activation Function for Neural Networks"></a>STL: A Signed and Truncated Logarithm Activation Function for Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16389">http://arxiv.org/abs/2307.16389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 这篇论文旨在提出一种新的激活函数，用于改进神经网络的精度和运行性能。</li>
<li>methods: 该论文使用了一种新的激活函数，即 signed and truncated logarithm function，其具有优秀的数学性质，如不对称、单调、可导、无界值范围和连续非零导数。</li>
<li>results: 对比其他一些常见的激活函数，该新激活函数的result表明它在大多数神经网络中具有最佳性能。这种激活函数可以应用于各种需要激活函数的神经网络中。<details>
<summary>Abstract</summary>
Activation functions play an essential role in neural networks. They provide the non-linearity for the networks. Therefore, their properties are important for neural networks' accuracy and running performance. In this paper, we present a novel signed and truncated logarithm function as activation function. The proposed activation function has significantly better mathematical properties, such as being odd function, monotone, differentiable, having unbounded value range, and a continuous nonzero gradient. These properties make it an excellent choice as an activation function. We compare it with other well-known activation functions in several well-known neural networks. The results confirm that it is the state-of-the-art. The suggested activation function can be applied in a large range of neural networks where activation functions are necessary.
</details>
<details>
<summary>摘要</summary>
aktivation functions play an essential role in neural networks. They provide the non-linearity for the networks. Therefore, their properties are important for neural networks' accuracy and running performance. In this paper, we present a novel signed and truncated logarithm function as activation function. The proposed activation function has significantly better mathematical properties, such as being odd function, monotone, differentiable, having unbounded value range, and a continuous nonzero gradient. These properties make it an excellent choice as an activation function. We compare it with other well-known activation functions in several well-known neural networks. The results confirm that it is the state-of-the-art. The suggested activation function can be applied in a large range of neural networks where activation functions are necessary.(Simplified Chinese)活动函数在神经网络中扮演着关键的角色。它们提供了非线性性，因此其属性对神经网络的准确率和运行性非常重要。在这篇论文中，我们提出了一种新的签名和截断对数函数作为活动函数。我们的提案的活动函数具有更好的数学属性，如是奇函数、 monotonic、导函数、无 bound 值范围和连续非零导数。这些属性使其成为非常出色的选择。我们与其他常见的活动函数进行比较，并在一些常见的神经网络中进行了测试。结果表明，它是当前最佳的。我们建议这种活动函数可以在神经网络中广泛应用，特别是在需要活动函数的情况下。
</details></li>
</ul>
<hr>
<h2 id="Relation-Oriented-Toward-Knowledge-Aligned-Causal-AI"><a href="#Relation-Oriented-Toward-Knowledge-Aligned-Causal-AI" class="headerlink" title="Relation-Oriented: Toward Knowledge-Aligned Causal AI"></a>Relation-Oriented: Toward Knowledge-Aligned Causal AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16387">http://arxiv.org/abs/2307.16387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia Li, Xiang Li</li>
<li>for: 本研究旨在探讨现有模型论坛中的不一致性，并提出一种基于关系的模型论坛，以便在大数据时代中更好地理解人类知识的构成和演化。</li>
<li>methods: 本研究使用了一种基于关系的模型论坛，通过对计算机视觉和医疗信息学中的实验 validate this approach。此外，研究还提出了一种基于关系的表示学习方法，用于实现relation-oriented模型论坛。</li>
<li>results: 研究发现，传统的observation-oriented模型论坛在处理大数据时会存在不一致性，而基于关系的模型论坛可以更好地理解人类知识的构成和演化。此外，基于关系的表示学习方法也得到了广泛的实验验证。<details>
<summary>Abstract</summary>
In machine learning, we naturally apply an Observation-Oriented principle, in which observational variables preexist and set the stage for constructing relationships. While sufficient for traditional models, the integration of AI with big data exposes the misalignment between the observational models and our actual comprehension. Contrarily, humans shape cognitive entities defined by relationships, enabling us to formulate knowledge across temporal and hyper-dimensional spaces, rather than being confined to observational constructs. From an innovative Relation-Oriented perspective, this study examines the roots of this misalignment within our current modeling paradigm, illuminated by intuitive examples from computer vision and health informatics. We also introduce the relation-defined representation learning methodology as a practical implementation of Relation-Oriented modeling, supported by extensive experimental validation.   Consider an analogy where ants dwell on a two-dimensional plane of a floor. If these ants were to construct models, they might use the nearest tree as a reference to specify the elevation in their two-dimensional models. By modeling, they observe an increased disruption at the tree's mid-level, which indicates a higher chance of encountering children. However, since they fail to comprehend humans as three-dimensional beings, instead of interpreting this phenomenon in a new dimension, "height", they solely relate it to the tree's mid-level. If they migrate to a different tree with a varying height, where mid-level no longer presents a risk, they might conclude that human behavior is too complex to model effectively. Similarly, when modeling time series, we usually discount the dimension, "time", as a single timeline, which has become our "tree".
</details>
<details>
<summary>摘要</summary>
在机器学习中，我们自然采用观察主导的原则，在其中观察变量先exists并设定了模型的场景。虽然适用于传统模型，但与人工智能和大数据相结合后，这种模型的不一致性变得更加明显。相反，人类通过形成知识的关系定义了认知实体，允许我们透过时间和多维空间形成知识，而不是仅仅遵循观察构建。从一种实际的关系主导的角度，本研究探讨了我们当前模型平台的不一致性，通过直观的计算机视觉和医疗信息学示例进行描述。我们还介绍了基于关系定义学习的方法ología，并通过广泛的实验验证。假设我们的蚂蚁在二维平面上生活。如果它们构建模型，它们可能使用最近的树作为参照，以指定模型中的高度。通过模型，它们发现高度中间层的干扰增加，表示更高的儿童遇到的可能性。但是，由于它们无法理解人类为三维存在，而不是在一个新的维度中解释这种现象，它们只是将其解释为树高度中间层的问题。如果它们migrate到另一个高度不同的树，其中中间层不再是风险，它们可能会认为人类行为是无法模型有效的。类似地，当我们模型时间序列时，我们通常忽略维度"时间"，将其变成我们的"树"。
</details></li>
</ul>
<hr>
<h2 id="When-Large-Language-Models-Meet-Personalization-Perspectives-of-Challenges-and-Opportunities"><a href="#When-Large-Language-Models-Meet-Personalization-Perspectives-of-Challenges-and-Opportunities" class="headerlink" title="When Large Language Models Meet Personalization: Perspectives of Challenges and Opportunities"></a>When Large Language Models Meet Personalization: Perspectives of Challenges and Opportunities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16376">http://arxiv.org/abs/2307.16376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jin Chen, Zheng Liu, Xu Huang, Chenwang Wu, Qi Liu, Gangwei Jiang, Yuanhao Pu, Yuxuan Lei, Xiaolong Chen, Xingmei Wang, Defu Lian, Enhong Chen</li>
<li>For: This paper discusses the potential uses of large language models (LLMs) in personalization systems, and how they can revolutionize the way personalization is conducted.* Methods: The paper explores the development and challenges of existing personalization systems, as well as the newly emerged capabilities of LLMs.* Results: The paper discusses the potential ways of making use of LLMs for personalization, including the ability to proactively explore user requests and provide personalized services.<details>
<summary>Abstract</summary>
The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, and common-sense reasoning, etc. Such a major leap-forward in general AI capacity will change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, large language models present the foundation for active user engagement. On top of such a new foundation, user requests can be proactively explored, and user's required information can be delivered in a natural and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as general-purpose interface, the personalization systems may compile user requests into plans, calls the functions of external tools to execute the plans, and integrate the tools' outputs to complete the end-to-end personalization tasks. Today, large language models are still being developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be the right time to review the challenges in personalization and the opportunities to address them with LLMs. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization.
</details>
<details>
<summary>摘要</summary>
大语言模型的出现标志着人工智能领域的一个革命性突破。它们的规模和参数数量在前所未有地提高了大语言模型的能力，从而实现了人类化的理解、语言生成和推理等等。这种大幅提升的通用人工智能能力将改变个性化的方式。一方面，它将改变人与个性化系统之间的交互方式。而不是仅作为信息滤波的温馈媒体，大语言模型将成为活跃的用户参与基础。在这个新基础上，用户的请求可以积极探索，并将用户需要的信息传达在自然和可追溯的方式。另一方面，它将扩大个性化的范围，从单一的收集个性信息变为多重功能的提供个性服务。通过利用大语言模型作为通用界面，个性化系统可以将用户的请求编译成计划，调用外部工具的函数执行计划，并将工具输出集成到完成个性化任务。目前，大语言模型仍在开发中，个性化应用则尚未得到广泛的探索。因此，我们认为现在是评估个性化挑战和利用大语言模型解决这些挑战的时候。本观点文特别关注以下方面：现有个性化系统的发展和挑战，大语言模型新出现的能力，以及可能的使用大语言模型进行个性化的方式。
</details></li>
</ul>
<hr>
<h2 id="Promptly-Using-Prompt-Problems-to-Teach-Learners-How-to-Effectively-Utilize-AI-Code-Generators"><a href="#Promptly-Using-Prompt-Problems-to-Teach-Learners-How-to-Effectively-Utilize-AI-Code-Generators" class="headerlink" title="Promptly: Using Prompt Problems to Teach Learners How to Effectively Utilize AI Code Generators"></a>Promptly: Using Prompt Problems to Teach Learners How to Effectively Utilize AI Code Generators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16364">http://arxiv.org/abs/2307.16364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Denny, Juho Leinonen, James Prather, Andrew Luxton-Reilly, Thezyrie Amarouche, Brett A. Becker, Brent N. Reeves<br>for: This paper aims to introduce a novel pedagogical concept called “Prompt Problem” to help students learn how to craft effective prompts for large language models (LLMs) in computing education.methods: The paper presents a novel tool called Promptly, which hosts a repository of Prompt Problems and automates the evaluation of prompt-generated code. The authors conducted a field study with 54 first-year Python programming students to explore student interactions with the tool and their perceptions of the Prompt Problem concept.results: The study found that Promptly was well-received by students for its ability to engage their computational thinking skills and expose them to new programming constructs. The authors also discuss avenues for future work, including variations on the design of Prompt Problems and the need to study their integration into the curriculum and teaching practice.<details>
<summary>Abstract</summary>
With their remarkable ability to generate code, large language models (LLMs) are a transformative technology for computing education practice. They have created an urgent need for educators to rethink pedagogical approaches and teaching strategies for newly emerging skill sets. Traditional approaches to learning programming have focused on frequent and repeated practice at writing code. The ease with which code can now be generated has resulted in a shift in focus towards reading, understanding and evaluating LLM-generated code. In parallel with this shift, a new essential skill is emerging -- the ability to construct good prompts for code-generating models. This paper introduces a novel pedagogical concept known as a `Prompt Problem', designed to help students learn how to craft effective prompts for LLMs. A Prompt Problem challenges a student to create a natural language prompt that leads an LLM to produce the correct code for a specific problem. To support the delivery of Prompt Problems at scale, in this paper we also present a novel tool called Promptly which hosts a repository of Prompt Problems and automates the evaluation of prompt-generated code. We report empirical findings from a field study in which Promptly was deployed in a first-year Python programming course (n=54). We explore student interactions with the tool and their perceptions of the Prompt Problem concept. We found that Promptly was largely well-received by students for its ability to engage their computational thinking skills and expose them to new programming constructs. We also discuss avenues for future work, including variations on the design of Prompt Problems and the need to study their integration into the curriculum and teaching practice.
</details>
<details>
<summary>摘要</summary>
带有杰出代码生成能力的大语言模型（LLM）已经是计算教育实践中的一种转变性技术。它们对教学方法和教学策略的需求已经产生了紧迫性，让教师需要重新思考教学方法。传统的编程学习方法通常是通过频繁地编写代码来帮助学生学习编程。然而，由于代码可以非常容易地生成，因此教学的重点已经从编写代码转移到了阅读、理解和评估 LLM 生成的代码。同时，一种新的重要技能正在emerging---如何构建好的提问。这篇论文介绍了一种新的教学概念，即“提问问题”（Prompt Problem），用于帮助学生学习如何编写有效的提问。一个 Prompt Problem 挑战学生创建一个自然语言提问，使 LLM 生成 correct 代码来解决特定问题。为了在大规模上提供 Prompt Problems，这篇论文还介绍了一种名为 Promptly 的新工具，该工具hosts一个提问问题的存储库和自动评估提问生成的代码。我们在一个 Python 编程课程中（n=54）进行了一项场景研究，并报告了学生与工具的交互和提问问题概念的看法。我们发现 Promptly 受到了学生的欢迎，他们认为该工具能够帮助他们发展计算思维和暴露他们于新编程构造。我们还讨论了未来工作的可能性，包括提问问题的设计变化和在课程和教学实践中的集成。
</details></li>
</ul>
<hr>
<h2 id="BearingPGA-Net-A-Lightweight-and-Deployable-Bearing-Fault-Diagnosis-Network-via-Decoupled-Knowledge-Distillation-and-FPGA-Acceleration"><a href="#BearingPGA-Net-A-Lightweight-and-Deployable-Bearing-Fault-Diagnosis-Network-via-Decoupled-Knowledge-Distillation-and-FPGA-Acceleration" class="headerlink" title="BearingPGA-Net: A Lightweight and Deployable Bearing Fault Diagnosis Network via Decoupled Knowledge Distillation and FPGA Acceleration"></a>BearingPGA-Net: A Lightweight and Deployable Bearing Fault Diagnosis Network via Decoupled Knowledge Distillation and FPGA Acceleration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16363">http://arxiv.org/abs/2307.16363</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asdvfghg/bearingpga-net">https://github.com/asdvfghg/bearingpga-net</a></li>
<li>paper_authors: Jing-Xiao Liao, Sheng-Lai Wei, Chen-Long Xie, Tieyong Zeng, Jinwei Sun, Shiping Zhang, Xiaoge Zhang, Feng-Lei Fan</li>
<li>for: 本研究旨在提出一种轻量级可部署的涤略破坏诊断模型（BearingPGA-Net），以解决现有深度学习模型的大小和计算复杂性限制其在工业应用中的使用。</li>
<li>methods: 我们使用了一个强化训练的大型模型，通过分离知识填充来训练 BearingPGA-Net。尽管它的体积小，但我们的模型仍能达到其他轻量级状态对比模型的优秀破坏诊断性能。</li>
<li>results: 我们设计了一种基于FPGA的加速方案，使用Verilog进行定制化量化和设计可编程逻辑门阵列 для每层的 BearingPGA-Net。这种方案强调了并行计算和模块再利用，以提高计算速度。根据我们所知，这是第一次将一个基于CNN的涤略破坏诊断模型部署在FPGA上。我们的实验结果表明，我们的部署方案可以在CPU上实现200倍以上的诊断速度，同时保持F1、回归和准确率分数下降较少于0.4%。<details>
<summary>Abstract</summary>
Deep learning has achieved remarkable success in the field of bearing fault diagnosis. However, this success comes with larger models and more complex computations, which cannot be transferred into industrial fields requiring models to be of high speed, strong portability, and low power consumption. In this paper, we propose a lightweight and deployable model for bearing fault diagnosis, referred to as BearingPGA-Net, to address these challenges. Firstly, aided by a well-trained large model, we train BearingPGA-Net via decoupled knowledge distillation. Despite its small size, our model demonstrates excellent fault diagnosis performance compared to other lightweight state-of-the-art methods. Secondly, we design an FPGA acceleration scheme for BearingPGA-Net using Verilog. This scheme involves the customized quantization and designing programmable logic gates for each layer of BearingPGA-Net on the FPGA, with an emphasis on parallel computing and module reuse to enhance the computational speed. To the best of our knowledge, this is the first instance of deploying a CNN-based bearing fault diagnosis model on an FPGA. Experimental results reveal that our deployment scheme achieves over 200 times faster diagnosis speed compared to CPU, while achieving a lower-than-0.4\% performance drop in terms of F1, Recall, and Precision score on our independently-collected bearing dataset. Our code is available at \url{https://github.com/asdvfghg/BearingPGA-Net}.
</details>
<details>
<summary>摘要</summary>
深度学习在滚珠缺陷诊断领域取得了很大成功。然而，这些成功带来更大的模型和更复杂的计算，无法在需要高速、强可移植和低功耗的工业领域中传输。在这篇论文中，我们提出了一个轻量级可部署的滚珠缺陷诊断模型，称为BearingPGA-Net，以解决这些挑战。首先，我们通过大型模型的帮助，使用分离知识采样来训练BearingPGA-Net。尽管它的体积小，我们的模型在其他轻量级state-of-the-art方法的比较中仍然表现出色。其次，我们为BearingPGA-Net设计了FPGA加速方案，使用Verilog语言设计。这个方案包括对BearingPGA-Net每层的自定义量化和FPGA中的可编程逻辑门的设计，强调并行计算和模块重用以提高计算速度。我们知道，这是第一次将CNN基于滚珠缺陷诊断模型部署到FPGA上。实验结果表明，我们的部署方案在CPU上进行诊断速度比较，可以达到200倍以上的加速速度，同时在独立收集的滚珠数据集上保持下降0.4%以下的F1、回归和准确率分数。我们的代码可以在 <https://github.com/asdvfghg/BearingPGA-Net> 上下载。
</details></li>
</ul>
<hr>
<h2 id="Distributionally-Robust-Safety-Filter-for-Learning-Based-Control-in-Active-Distribution-Systems"><a href="#Distributionally-Robust-Safety-Filter-for-Learning-Based-Control-in-Active-Distribution-Systems" class="headerlink" title="Distributionally Robust Safety Filter for Learning-Based Control in Active Distribution Systems"></a>Distributionally Robust Safety Filter for Learning-Based Control in Active Distribution Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16351">http://arxiv.org/abs/2307.16351</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang Tien Nguyen, Dae-Hyun Choi</li>
<li>for: 避免深度强化学习（DRL）代理在真实世界中的分布系统中进行训练时出现操作限制 violet 的问题。</li>
<li>methods: 使用一种通用的分布 robust安全筛（DRSF）来降低DRL代理在分布系统中的约束违反，同时保持near-optimal的解决方案。DRSF是基于分布 robust优化问题，通过考虑操作限制的可能性来计算near-optimal的动作，从而提供约束满意度保证。</li>
<li>results: 对于IEEE 33-bus和123-bus系统，提出的DRSF可以减少DRL代理在分布系统中的约束违反，同时保持near-optimal的解决方案。<details>
<summary>Abstract</summary>
Operational constraint violations may occur when deep reinforcement learning (DRL) agents interact with real-world active distribution systems to learn their optimal policies during training. This letter presents a universal distributionally robust safety filter (DRSF) using which any DRL agent can reduce the constraint violations of distribution systems significantly during training while maintaining near-optimal solutions. The DRSF is formulated as a distributionally robust optimization problem with chance constraints of operational limits. This problem aims to compute near-optimal actions that are minimally modified from the optimal actions of DRL-based Volt/VAr control by leveraging the distribution system model, thereby providing constraint satisfaction guarantee with a probability level under the model uncertainty. The performance of the proposed DRSF is verified using the IEEE 33-bus and 123-bus systems.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对深度强化学习（DRL）代理与实际运行系统进行交互学习时，运行系统约束可能会被违反。这封信提出了一种通用分布robust安全筛选器（DRSF），可以在DRL代理训练过程中减少运行系统约束违反的概率，同时保持近似优解。DRSF是以分布robust优化问题的形式表述，其目标是在操作限制下计算近似优解，并且具有随机变量模型的承诺保证。此外，DRSF可以利用DRL基于Volt/Var控制的优化解，从而提供约束满足保证，并且在模型不确定性下保证优化解的可行性。本文通过IEEE 33-bus和123-bus系统的实验，证明了提案的DRSF的性能。Note: Simplified Chinese is a version of Chinese that uses simpler grammar and vocabulary, and is often used in informal writing and communication. It is different from Traditional Chinese, which is a more formal version of Chinese that is used in many official documents and publications.
</details></li>
</ul>
<hr>
<h2 id="Rating-based-Reinforcement-Learning"><a href="#Rating-based-Reinforcement-Learning" class="headerlink" title="Rating-based Reinforcement Learning"></a>Rating-based Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16348">http://arxiv.org/abs/2307.16348</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Devin White, Mingkang Wu, Ellen Novoseller, Vernon Lawhern, Nick Waytowich, Yongcan Cao</li>
<li>for: 本研究开发了一种基于评价的强化学习方法，通过人类评价来获取人类指导。不同于现有的偏好基于和排名基于强化学习模式，本研究基于人类评价个别路径而不需要相对比较项目对。</li>
<li>methods: 本研究使用了一个新的预测模型来预测人类评价，以及一种多维度损失函数。</li>
<li>results: 本研究通过实验研究，证明了新的评价基于强化学习方法的有效性和利害。<details>
<summary>Abstract</summary>
This paper develops a novel rating-based reinforcement learning approach that uses human ratings to obtain human guidance in reinforcement learning. Different from the existing preference-based and ranking-based reinforcement learning paradigms, based on human relative preferences over sample pairs, the proposed rating-based reinforcement learning approach is based on human evaluation of individual trajectories without relative comparisons between sample pairs. The rating-based reinforcement learning approach builds on a new prediction model for human ratings and a novel multi-class loss function. We conduct several experimental studies based on synthetic ratings and real human ratings to evaluate the effectiveness and benefits of the new rating-based reinforcement learning approach.
</details>
<details>
<summary>摘要</summary>
这个论文提出了一种新的评分基于权重学习方法，利用人类评分来获得人类指导。与现有的偏好基于样本对比和排名基于样本对比的学习 paradigms不同，提posed评分基于学习方法是基于人类评分个 trajectory 而不是对样本对比的Relative preferences。这种评分基于学习方法采用了一种新的预测模型和一种多类损失函数。我们在使用 synthetic 评分和实际人类评分进行了多个实验研究，以评估新评分基于学习方法的效果和优势。
</details></li>
</ul>
<hr>
<h2 id="Proof-of-Federated-Learning-Subchain-Free-Partner-Selection-Subchain-Based-on-Federated-Learning"><a href="#Proof-of-Federated-Learning-Subchain-Free-Partner-Selection-Subchain-Based-on-Federated-Learning" class="headerlink" title="Proof-of-Federated-Learning-Subchain: Free Partner Selection Subchain Based on Federated Learning"></a>Proof-of-Federated-Learning-Subchain: Free Partner Selection Subchain Based on Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16342">http://arxiv.org/abs/2307.16342</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boyang Li, Bingyu Shen, Qing Lu, Taeho Jung, Yiyu Shi</li>
<li>for: 这篇论文是为了提出一种新的分布式协议，即Proof-of-Federated-Learning-Subchain(PoFLSC)，用于取代之前提出的Proof-of-Deep-Learning(PoDL)协议，以更好地利用能源并维护区块链。</li>
<li>methods: 这篇论文使用了一种名为Proof-of-Federated-Learning-Subchain(PoFLSC)的新的分布式协议，该协议使用了一个子链来记录训练、挑战和审核活动，并强调了合理的数据集的选择。</li>
<li>results: 在 simulate 20 个矿工的情况下，论文示出了 PoFLSC 协议的有效性，当矿工池的大小减少时， Pool 中的矿工会根据 Shapley Value (SV) 的优先级顺序进行选择。在实验中，PoFLSC 协议支持了子链管理员对储存优先级的了解，并使核心分区的参与者建立和维护一个竞争性的子链。<details>
<summary>Abstract</summary>
The continuous thriving of the Blockchain society motivates research in novel designs of schemes supporting cryptocurrencies. Previously multiple Proof-of-Deep-Learning(PoDL) consensuses have been proposed to replace hashing with useful work such as deep learning model training tasks. The energy will be more efficiently used while maintaining the ledger. However deep learning models are problem-specific and can be extremely complex. Current PoDL consensuses still require much work to realize in the real world. In this paper, we proposed a novel consensus named Proof-of-Federated-Learning-Subchain(PoFLSC) to fill the gap. We applied a subchain to record the training, challenging, and auditing activities and emphasized the importance of valuable datasets in partner selection. We simulated 20 miners in the subchain to demonstrate the effectiveness of PoFLSC. When we reduce the pool size concerning the reservation priority order, the drop rate difference in the performance in different scenarios further exhibits that the miner with a higher Shapley Value (SV) will gain a better opportunity to be selected when the size of the subchain pool is limited. In the conducted experiments, the PoFLSC consensus supported the subchain manager to be aware of reservation priority and the core partition of contributors to establish and maintain a competitive subchain.
</details>
<details>
<summary>摘要</summary>
“ blockchain 社会的持续发展为我们的研究提供了新的设计方案，以支持 криптовалютой。先前，多种 Proof-of-Deep-Learning（PoDL）的共识方案已经被提出，以替换哈希函数，使用有用的工作，如深度学习模型训练任务。这将更有效地使用能量，同时维护 ledger。但是深度学习模型是问题特定的，可能非常复杂。当前的 PoDL 共识方案仍需要大量的实践和改进。在这篇论文中，我们提出了一种新的共识方案，名为 Proof-of-Federated-Learning-Subchain（PoFLSC）。我们使用了一个子链来记录训练、挑战和审核活动，并强调了合理的数据集的选择。我们在 simulations 中使用 20 个矿工，以示 PoFLSC 的效果。当我们降低了池子大小，关于保留优先级顺序，则drop rate 差异在不同的场景中进一步表现出，表明矿工 avec 更高的 Shapley 值（SV）在池子大小有限化时会获得更好的机会被选择。在我们的实验中，PoFLSC 共识支持了子链经理者了解保留优先级，以及核心分区的参与者们建立和维护竞争性的子链。”
</details></li>
</ul>
<hr>
<h2 id="Anatomy-of-an-AI-powered-malicious-social-botnet"><a href="#Anatomy-of-an-AI-powered-malicious-social-botnet" class="headerlink" title="Anatomy of an AI-powered malicious social botnet"></a>Anatomy of an AI-powered malicious social botnet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16336">http://arxiv.org/abs/2307.16336</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osome-iu/aibot_fox8">https://github.com/osome-iu/aibot_fox8</a></li>
<li>paper_authors: Kai-Cheng Yang, Filippo Menczer</li>
<li>for: 这篇论文探讨了使用大语言模型（LLM）生成的社交媒体帐户，以及这些帐户是如何通过生成人类样式的内容来伪装自己的问题。</li>
<li>methods: 该论文使用了规则来识别1,140个涉嫌使用ChatGPT生成内容的Twitter帐户，并通过人工纠察确认其为假帐户。</li>
<li>results: 研究发现这些假帐户通常发布机器生成的内容和盗取的图片，并与其他假帐户进行回复和转发交互。这些帐户推广了嫌疑 Website 和散播负面评论，但现有的 LLM 内容分类器无法在野外环境中分辨它们和真正的人帐户。<details>
<summary>Abstract</summary>
Large language models (LLMs) exhibit impressive capabilities in generating realistic text across diverse subjects. Concerns have been raised that they could be utilized to produce fake content with a deceptive intention, although evidence thus far remains anecdotal. This paper presents a case study about a Twitter botnet that appears to employ ChatGPT to generate human-like content. Through heuristics, we identify 1,140 accounts and validate them via manual annotation. These accounts form a dense cluster of fake personas that exhibit similar behaviors, including posting machine-generated content and stolen images, and engage with each other through replies and retweets. ChatGPT-generated content promotes suspicious websites and spreads harmful comments. While the accounts in the AI botnet can be detected through their coordination patterns, current state-of-the-art LLM content classifiers fail to discriminate between them and human accounts in the wild. These findings highlight the threats posed by AI-enabled social bots.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）展示了各种主题的文本生成能力，但是有人们对其用于生成假内容的担忧。虽然证据ntil now still anecdotal，但这篇文章描述了一个Twitter botnet使用ChatGPT生成人类化内容。通过规则，我们确认了1,140个帐户，并通过手动标注 validate them。这些帐户组成了一个假人类型的集群，其中包括发布机器生成内容和盗取图片，以及通过回复和转推相互交流。ChatGPT生成的内容推广了嫌疑 Website和散播负面评论。虽然AI botnet帐户可以通过协调pattern detection，但现有的LLM内容分类器无法在野外 distinguishing them from human accounts。这些发现提醒了AI-enabled social bot的威胁。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-ChatGPT-and-GPT-4-for-Visual-Programming"><a href="#Evaluating-ChatGPT-and-GPT-4-for-Visual-Programming" class="headerlink" title="Evaluating ChatGPT and GPT-4 for Visual Programming"></a>Evaluating ChatGPT and GPT-4 for Visual Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02522">http://arxiv.org/abs/2308.02522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adish Singla</li>
<li>for: 这个论文主要研究了现代生成AI和大语言模型在视觉编程领域的可能性，以及这些模型在不同的编程教育场景中的表现。</li>
<li>methods: 研究使用了两种模型：ChatGPT（基于GPT-3.5）和GPT-4，并使用了专家标注来评估这些模型在不同的场景中的表现。</li>
<li>results: 研究发现，这些模型在视觉编程领域表现不佳，尤其是在组合空间、逻辑和编程技能方面表现较差。这些结果还提供了未来开发改进生成模型在视觉编程领域表现的可能性。<details>
<summary>Abstract</summary>
Generative AI and large language models have the potential to drastically improve the landscape of computing education by automatically generating personalized feedback and content. Recent works have studied the capabilities of these models for different programming education scenarios; however, these works considered only text-based programming, in particular, Python programming. Consequently, they leave open the question of how well these models would perform in visual programming domains popularly used for K-8 programming education. The main research question we study is: Do state-of-the-art generative models show advanced capabilities in visual programming on par with their capabilities in text-based Python programming? In our work, we evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, in visual programming domains for various scenarios and assess performance using expert-based annotations. In particular, we base our evaluation using reference tasks from the domains of Hour of Code: Maze Challenge by Code-dot-org and Karel. Our results show that these models perform poorly and struggle to combine spatial, logical, and programming skills crucial for visual programming. These results also provide exciting directions for future work on developing techniques to improve the performance of generative models in visual programming.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>生成AI和大语言模型有可能在计算教育领域带来很大改进，自动生成个性化反馈和内容。先前的研究已经研究了这些模型在不同的编程教育场景中的能力，但是这些研究仅考虑了文本编程，尤其是Python编程。因此，它们留下了如何在视觉编程领域中表现的问题。我们的研究问题是：现代生成模型在视觉编程领域中是否有高度的能力，与文本基于Python编程的能力相当？在我们的工作中，我们评估了两个模型：ChatGPT（基于GPT-3.5）和GPT-4，在不同的场景下进行了评估，并使用专家标注来评估性能。具体来说，我们基于Code-dot-org的Hour of Code：迷宫挑战和Karel的参考任务进行评估。我们的结果表明，这些模型在视觉编程中表现不佳，它们困难于结合空间逻辑和编程技能，这些技能是视觉编程的关键。这些结果还提供了未来开发改进生成模型在视觉编程中表现的可能性的激动人心的方向。
</details></li>
</ul>
<hr>
<h2 id="Representing-and-Reasoning-with-Multi-Stakeholder-Qualitative-Preference-Queries"><a href="#Representing-and-Reasoning-with-Multi-Stakeholder-Qualitative-Preference-Queries" class="headerlink" title="Representing and Reasoning with Multi-Stakeholder Qualitative Preference Queries"></a>Representing and Reasoning with Multi-Stakeholder Qualitative Preference Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16307">http://arxiv.org/abs/2307.16307</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samik Basu, Vasant Honavar, Ganesh Ram Santhanam, Jia Tao</li>
<li>for: 这篇论文旨在处理多方参与者的资源选择问题，以便在决策过程中考虑多个参与者的 préférences。</li>
<li>methods: 本文使用形式化的多方参与者 préférences 语言，如 CP-net、CI-net、TCP-net 和 CP-Theory，并提出了一种查询语言来表达对这些 préférences 的询问。</li>
<li>results: 本文提供了一种可靠的算法来回答多方参与者资源选择询问，使用 alternation-free μ-calculus 进行模型检查。实验结果表明该方法的可行性。<details>
<summary>Abstract</summary>
Many decision-making scenarios, e.g., public policy, healthcare, business, and disaster response, require accommodating the preferences of multiple stakeholders. We offer the first formal treatment of reasoning with multi-stakeholder qualitative preferences in a setting where stakeholders express their preferences in a qualitative preference language, e.g., CP-net, CI-net, TCP-net, CP-Theory. We introduce a query language for expressing queries against such preferences over sets of outcomes that satisfy specified criteria, e.g., $\mlangpref{\psi_1}{\psi_2}{A}$ (read loosely as the set of outcomes satisfying $\psi_1$ that are preferred over outcomes satisfying $\psi_2$ by a set of stakeholders $A$). Motivated by practical application scenarios, we introduce and analyze several alternative semantics for such queries, and examine their interrelationships. We provide a provably correct algorithm for answering multi-stakeholder qualitative preference queries using model checking in alternation-free $\mu$-calculus. We present experimental results that demonstrate the feasibility of our approach.
</details>
<details>
<summary>摘要</summary>
多种决策场景，如公共政策、医疗、商业和灾难应急处理，需要考虑多个利益相关者的首选。我们提供了首个正式对多个利益相关者质量预ферен斯的理解，在一种使用质量预ферен斯语言表达利益偏好的设定下。我们引入了一种表达对多个利益相关者对结果集的偏好 queries 的查询语言，例如 $\mlangpref{\psi_1}{\psi_2}{A}$（翻译为：结果集满足 $\psi_1$ 的结果集，在 $\psi_2$ 中超过 $\psi_1$ 的结果集的所有利益相关者 $A$ 中的偏好）。受实际应用场景的限制，我们引入了和分析了多种代理 semantics，并研究它们之间的关系。我们提供了一种可靠的回答多个利益相关者质量预ферен斯查询的可靠算法，使用无需分支的 $\mu$-calculus 进行模板检查。我们发现实际结果，证明了我们的方法的可行性。
</details></li>
</ul>
<hr>
<h2 id="LaFiCMIL-Rethinking-Large-File-Classification-from-the-Perspective-of-Correlated-Multiple-Instance-Learning"><a href="#LaFiCMIL-Rethinking-Large-File-Classification-from-the-Perspective-of-Correlated-Multiple-Instance-Learning" class="headerlink" title="LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning"></a>LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01413">http://arxiv.org/abs/2308.01413</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiezhu Sun, Weiguo Pian, Nadia Daoudi, Kevin Allix, Tegawendé F. Bissyandé, Jacques Klein</li>
<li>for: 本研究旨在解决Transformer模型（如BERT）在大文件分类任务中的输入限制问题，以提高其在不同领域的表现。</li>
<li>methods: 本研究采用相关多个实例学习的思想，提出了LaFiCMIL方法，可应用于不同领域的大文件分类任务，包括多类、多标签和二分类分类任务。</li>
<li>results: 经employmBERT家族模型作为特征提取器，我们的实验结果表明，LaFiCMIL在八个benchmark datasets中均达到了新的状态码表现，其中包括Long Document Classification、Code Defect Detection和Android Malware Detection等领域。<details>
<summary>Abstract</summary>
Transformer-based models, such as BERT, have revolutionized various language tasks, but still struggle with large file classification due to their input limit (e.g., 512 tokens). Despite several attempts to alleviate this limitation, no method consistently excels across all benchmark datasets, primarily because they can only extract partial essential information from the input file. Additionally, they fail to adapt to the varied properties of different types of large files. In this work, we tackle this problem from the perspective of correlated multiple instance learning. The proposed approach, LaFiCMIL, serves as a versatile framework applicable to various large file classification tasks covering binary, multi-class, and multi-label classification tasks, spanning various domains including Natural Language Processing, Programming Language Processing, and Android Analysis. To evaluate its effectiveness, we employ eight benchmark datasets pertaining to Long Document Classification, Code Defect Detection, and Android Malware Detection. Leveraging BERT-family models as feature extractors, our experimental results demonstrate that LaFiCMIL achieves new state-of-the-art performance across all benchmark datasets. This is largely attributable to its capability of scaling BERT up to nearly 20K tokens, running on a single Tesla V-100 GPU with 32G of memory.
</details>
<details>
<summary>摘要</summary>
transformer-based 模型，如 BERT，已经革命化了多种语言任务，但仍然在大文件分类任务中困难，主要因为其输入限制（例如 512 个 tokens）。 despite several attempts to alleviate this limitation, no method has consistently excelled across all benchmark datasets, primarily because they can only extract partial essential information from the input file. In addition, they fail to adapt to the varied properties of different types of large files.在这种情况下，我们从相关多个实例学习的角度来解决这个问题。我们提出了一种名为 LaFiCMIL 的框架，可以应用于多种大文件分类任务，包括二分类、多类和多标签分类任务，覆盖了自然语言处理、编程语言处理和 Android 分析等领域。为了评估其效果，我们使用了八个基准数据集， relate to Long Document Classification、Code Defect Detection 和 Android Malware Detection。通过使用 BERT 家族模型作为特征提取器，我们的实验结果表明，LaFiCMIL 在所有基准数据集上达到了新的状态之术性能。这主要归功于它可以在单个 Tesla V-100 GPU 上运行，并且可以扩展到 nearly 20K 个 tokens。
</details></li>
</ul>
<hr>
<h2 id="Implementing-Edge-Based-Object-Detection-For-Microplastic-Debris"><a href="#Implementing-Edge-Based-Object-Detection-For-Microplastic-Debris" class="headerlink" title="Implementing Edge Based Object Detection For Microplastic Debris"></a>Implementing Edge Based Object Detection For Microplastic Debris</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16289">http://arxiv.org/abs/2307.16289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amardeep Singh, Prof. Charles Jia, Prof. Donald Kirk</li>
<li>for: 这个研究旨在帮助解决废弃 пластиック的问题，通过开发基于计算机视觉的移动设备来检测和除废弃 пластиック。</li>
<li>methods: 该研究使用了计算机视觉和开放视觉技术，并将其与机器人臂结合使用，以提高废弃 пластиック的检测和除除效率。</li>
<li>results: 研究发现，使用augmented CNN方法可以在Sampled图像中实时检测废弃 пластиック，并且可以根据不同的废弃类型进行比较。此外，研究还发现了最佳预处理步骤和硬件配置，以便扩展废弃物检测研究到更大的环境中。<details>
<summary>Abstract</summary>
Plastic has imbibed itself as an indispensable part of our day to day activities, becoming a source of problems due to its non-biodegradable nature and cheaper production prices. With these problems, comes the challenge of mitigating and responding to the aftereffects of disposal or the lack of proper disposal which leads to waste concentrating in locations and disturbing ecosystems for both plants and animals. As plastic debris levels continue to rise with the accumulation of waste in garbage patches in landfills and more hazardously in natural water bodies, swift action is necessary to plug or cease this flow. While manual sorting operations and detection can offer a solution, they can be augmented using highly advanced computer imagery linked with robotic appendages for removing wastes. The primary application of focus in this report are the much-discussed Computer Vision and Open Vision which have gained novelty for their light dependence on internet and ability to relay information in remote areas. These applications can be applied to the creation of edge-based mobility devices that can as a counter to the growing problem of plastic debris in oceans and rivers, demanding little connectivity and still offering the same results with reasonably timed maintenance. The principal findings of this project cover the various methods that were tested and deployed to detect waste in images, as well as comparing them against different waste types. The project has been able to produce workable models that can perform on time detection of sampled images using an augmented CNN approach. Latter portions of the project have also achieved a better interpretation of the necessary preprocessing steps required to arrive at the best accuracies, including the best hardware for expanding waste detection studies to larger environments.
</details>
<details>
<summary>摘要</summary>
塑料已经成为我们日常生活中不可或缺的一部分，但它却带来了一系列问题，主要是因为它的不可降解性和便宜生产成本。这些问题导致塑料的不当处理和弃置，导致垃圾拥挤在特定区域和影响植物和动物的生态系统。随着塑料垃圾的水平不断升高，紧急需要采取 Swift action 来抑制或中止这流。而 manual sorting operations 和检测可以提供一个解决方案，但这些方法可以通过高度进步的计算机影像连结到机械臂，从而实现塑料的自动排除。本报告的主要应用是著名的计算机见识和开放见识，它们在不需互联网的情况下，可以实现塑料的检测和分类。这些应用可以应用于创建边缘基础设施，以抵消塑料垃圾在海洋和河流中的问题，需要 little connectivity，并且仍然可以获得相同的结果，并且在合理的维护时间进行维护。本项目的主要发现包括对图像中的垃圾检测方法的评估和比较，以及不同垃圾类型之间的比较。项目最终得出了可靠的模型，可以在合理的时间内检测样本图像，使用增强的 CNN 方法。项目的后期也获得了更好的理解有关垃圾检测的必要预处理步骤，包括最佳硬件 для扩展垃圾检测研究到更大的环境中。
</details></li>
</ul>
<hr>
<h2 id="Towards-Learned-Predictability-of-Storage-Systems"><a href="#Towards-Learned-Predictability-of-Storage-Systems" class="headerlink" title="Towards Learned Predictability of Storage Systems"></a>Towards Learned Predictability of Storage Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16288">http://arxiv.org/abs/2307.16288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyuan Wu</li>
<li>For: This paper focuses on the proactive prediction of performance instability and hardware failures in storage systems, with the goal of improving their reliability and availability.* Methods: The paper surveys various mechanisms and field studies that have been proposed in the past few years for predicting performance instability and device failures in storage systems, with a focus on machine learning-based black-box approaches.* Results: The paper evaluates the strengths and limitations of three representative research works in this field, providing insights into the effectiveness of machine learning-based approaches for predicting performance instability and device failures in storage systems.<details>
<summary>Abstract</summary>
With the rapid development of cloud computing and big data technologies, storage systems have become a fundamental building block of datacenters, incorporating hardware innovations such as flash solid state drives and non-volatile memories, as well as software infrastructures such as RAID and distributed file systems. Despite the growing popularity and interests in storage, designing and implementing reliable storage systems remains challenging, due to their performance instability and prevailing hardware failures.   Proactive prediction greatly strengthens the reliability of storage systems. There are two dimensions of prediction: performance and failure. Ideally, through detecting in advance the slow IO requests, and predicting device failures before they really happen, we can build storage systems with especially low tail latency and high availability. While its importance is well recognized, such proactive prediction in storage systems, on the other hand, is particularly difficult. To move towards predictability of storage systems, various mechanisms and field studies have been proposed in the past few years. In this report, we present a survey of these mechanisms and field studies, focusing on machine learning based black-box approaches. Based on three representative research works, we discuss where and how machine learning should be applied in this field. The strengths and limitations of each research work are also evaluated in detail.
</details>
<details>
<summary>摘要</summary>
With the rapid development of cloud computing and big data technologies, storage systems have become a fundamental building block of datacenters, incorporating hardware innovations such as flash solid state drives and non-volatile memories, as well as software infrastructures such as RAID and distributed file systems. Despite the growing popularity and interests in storage, designing and implementing reliable storage systems remains challenging, due to their performance instability and prevailing hardware failures. 随着云计算和大数据技术的快速发展，存储系统已成为数据中心的基本构建件，涵盖硬件创新 such as flash固态驱动器和非术TLM存储器，以及软件基础设施 such as RAID和分布式文件系统。虽然存储领域的兴趣和popularity在增长，但设计和实施可靠的存储系统仍然具有挑战性，因为它们的性能不稳定和存在硬件故障。Predictive maintenance greatly enhances the reliability of storage systems. There are two dimensions of prediction: performance and failure. Ideally, by detecting slow IO requests in advance and predicting device failures before they occur, we can build storage systems with especially low tail latency and high availability. However, such proactive prediction in storage systems is particularly difficult. To move towards predictability of storage systems, various mechanisms and field studies have been proposed in the past few years. In this report, we present a survey of these mechanisms and field studies, focusing on machine learning-based black-box approaches. Based on three representative research works, we discuss where and how machine learning should be applied in this field. The strengths and limitations of each research work are also evaluated in detail.
</details></li>
</ul>
<hr>
<h2 id="Predicting-delays-in-Indian-lower-courts-using-AutoML-and-Decision-Forests"><a href="#Predicting-delays-in-Indian-lower-courts-using-AutoML-and-Decision-Forests" class="headerlink" title="Predicting delays in Indian lower courts using AutoML and Decision Forests"></a>Predicting delays in Indian lower courts using AutoML and Decision Forests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16285">http://arxiv.org/abs/2307.16285</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mb7419/pendencyprediction">https://github.com/mb7419/pendencyprediction</a></li>
<li>paper_authors: Mohit Bhatnagar, Shivraj Huchhanavar</li>
<li>for: 这项研究旨在预测印度下级法院的延迟时间，以便改善印度法院的效率和公正性。</li>
<li>methods: 该研究使用AutoML技术建立了一个多类分类模型，以预测印度法院的延迟时间。研究使用了420万起法律案件的数据，其中7000多个法院的数据，并使用了二分类决策森林分类器来提高预测精度。</li>
<li>results: 研究得出的结果显示，使用AutoML技术可以建立一个高精度的延迟预测模型，其准确率达81.4%，精度、回归和准确率均为0.81。这项研究也提供了可用于进一步研究印度法院改革的数据集和Python代码文件。<details>
<summary>Abstract</summary>
This paper presents a classification model that predicts delays in Indian lower courts based on case information available at filing. The model is built on a dataset of 4.2 million court cases filed in 2010 and their outcomes over a 10-year period. The data set is drawn from 7000+ lower courts in India. The authors employed AutoML to develop a multi-class classification model over all periods of pendency and then used binary decision forest classifiers to improve predictive accuracy for the classification of delays. The best model achieved an accuracy of 81.4%, and the precision, recall, and F1 were found to be 0.81. The study demonstrates the feasibility of AI models for predicting delays in Indian courts, based on relevant data points such as jurisdiction, court, judge, subject, and the parties involved. The paper also discusses the results in light of relevant literature and suggests areas for improvement and future research. The authors have made the dataset and Python code files used for the analysis available for further research in the crucial and contemporary field of Indian judicial reform.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了一种基于文件时间的印度下级法院延迟预测模型。模型是基于2010年420万个法律案件的签到和结果数据，来自7000多个印度下级法院。作者使用AutoML开发了一个多类别预测模型，然后使用二分决策树分类器进行改进预测准确性。最佳模型的准确率为81.4%，精度、回归率和F1分别为0.81。研究表明，使用相关数据点，如司法管辖区、法院、法官、案件主题和参与党人，可以预测印度法院的延迟。研究还与相关文献进行了比较分析，并提出了改进和未来研究的建议。作者已经将数据集和使用于分析的Python代码文件公开，以便进一步研究印度司法改革的当前和紧迫领域。
</details></li>
</ul>
<hr>
<h2 id="Recent-Advances-in-Hierarchical-Multi-label-Text-Classification-A-Survey"><a href="#Recent-Advances-in-Hierarchical-Multi-label-Text-Classification-A-Survey" class="headerlink" title="Recent Advances in Hierarchical Multi-label Text Classification: A Survey"></a>Recent Advances in Hierarchical Multi-label Text Classification: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16265">http://arxiv.org/abs/2307.16265</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rundong Liu, Wenhan Liang, Weijun Luo, Yuxiang Song, He Zhang, Ruohua Xu, Yunfeng Li, Ming Liu</li>
<li>for: 科学文献搜索、多标签文本分类</li>
<li>methods: 主要使用开源数据集、主要方法、评价指标、学习策略</li>
<li>results: 研究进展、挑战和未来发展方向In English, this translates to:</li>
<li>for: Scientific literature archiving, hierarchical multi-label text classification</li>
<li>methods: Mainly using open-sourced data sets, main methods, evaluation metrics, learning strategies</li>
<li>results: Research progress, challenges, and future development directionsI hope this helps!<details>
<summary>Abstract</summary>
Hierarchical multi-label text classification aims to classify the input text into multiple labels, among which the labels are structured and hierarchical. It is a vital task in many real world applications, e.g. scientific literature archiving. In this paper, we survey the recent progress of hierarchical multi-label text classification, including the open sourced data sets, the main methods, evaluation metrics, learning strategies and the current challenges. A few future research directions are also listed for community to further improve this field.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese: Hierarchical multi-label text classification aims to classify input text into multiple labels, with the labels being structured and hierarchical. This is a crucial task in many real-world applications, such as scientific literature archiving. In this paper, we review recent progress in hierarchical multi-label text classification, including open-source data sets, main methods, evaluation metrics, learning strategies, and current challenges. We also list a few future research directions for the community to further improve this field.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/31/cs.AI_2023_07_31/" data-id="clpxp6bvw001lee88f0s03boc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_31" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/31/cs.CL_2023_07_31/" class="article-date">
  <time datetime="2023-07-31T11:00:00.000Z" itemprop="datePublished">2023-07-31</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/31/cs.CL_2023_07_31/">cs.CL - 2023-07-31</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Lexically-Accelerated-Dense-Retrieval"><a href="#Lexically-Accelerated-Dense-Retrieval" class="headerlink" title="Lexically-Accelerated Dense Retrieval"></a>Lexically-Accelerated Dense Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16779">http://arxiv.org/abs/2307.16779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hrishikesh Kulkarni, Sean MacAvaney, Nazli Goharian, Ophir Frieder</li>
<li>for: 提高 dense retrieval 模型的效率，不妨碍搜索效果。</li>
<li>methods: 使用 lexical retrieval 技术为 dense retrieval 搜索种子，并使用文档准近图进行搜索。</li>
<li>results: 实现 dense retrieval 模型的效率-效果对应 frontier，并在8毫秒&#x2F;查询时间下达到了相同的精度和准确率。<details>
<summary>Abstract</summary>
Retrieval approaches that score documents based on learned dense vectors (i.e., dense retrieval) rather than lexical signals (i.e., conventional retrieval) are increasingly popular. Their ability to identify related documents that do not necessarily contain the same terms as those appearing in the user's query (thereby improving recall) is one of their key advantages. However, to actually achieve these gains, dense retrieval approaches typically require an exhaustive search over the document collection, making them considerably more expensive at query-time than conventional lexical approaches. Several techniques aim to reduce this computational overhead by approximating the results of a full dense retriever. Although these approaches reasonably approximate the top results, they suffer in terms of recall -- one of the key advantages of dense retrieval. We introduce 'LADR' (Lexically-Accelerated Dense Retrieval), a simple-yet-effective approach that improves the efficiency of existing dense retrieval models without compromising on retrieval effectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval exploration that uses a document proximity graph. We explore two variants of LADR: a proactive approach that expands the search space to the neighbors of all seed documents, and an adaptive approach that selectively searches the documents with the highest estimated relevance in an iterative fashion. Through extensive experiments across a variety of dense retrieval models, we find that LADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier among approximate k nearest neighbor techniques. Further, we find that when tuned to take around 8ms per query in retrieval latency on our hardware, LADR consistently achieves both precision and recall that are on par with an exhaustive search on standard benchmarks.
</details>
<details>
<summary>摘要</summary>
traditional retrieval approaches that rely on lexical signals are being replaced by dense retrieval approaches that score documents based on learned dense vectors. These approaches can retrieve related documents that do not contain the same terms as the user's query, which improves recall. However, dense retrieval approaches typically require an exhaustive search over the document collection, which is computationally expensive. Several techniques have been proposed to reduce the computational overhead, but these approaches often sacrifice recall.We introduce 'LADR' (Lexically-Accelerated Dense Retrieval), a simple and effective approach that improves the efficiency of existing dense retrieval models without compromising on retrieval effectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval exploration that uses a document proximity graph. We explore two variants of LADR: a proactive approach that expands the search space to the neighbors of all seed documents, and an adaptive approach that selectively searches the documents with the highest estimated relevance in an iterative fashion.Through extensive experiments across a variety of dense retrieval models, we find that LADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier among approximate k nearest neighbor techniques. Furthermore, when tuned to take around 8ms per query in retrieval latency on our hardware, LADR consistently achieves both precision and recall that are on par with an exhaustive search on standard benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Multilingual-context-based-pronunciation-learning-for-Text-to-Speech"><a href="#Multilingual-context-based-pronunciation-learning-for-Text-to-Speech" class="headerlink" title="Multilingual context-based pronunciation learning for Text-to-Speech"></a>Multilingual context-based pronunciation learning for Text-to-Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16709">http://arxiv.org/abs/2307.16709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giulia Comini, Manuel Sam Ribeiro, Fan Yang, Heereen Shim, Jaime Lorenzo-Trueba</li>
<li>for: 这篇论文是为了描述一种多语言Front-end系统，用于解决语音识别和其他语言特定挑战。</li>
<li>methods: 该系统使用Grapheme-to-Phoneme（G2P）关系来预测未知词的发音，同时使用规则引用系统来解决homograph和多音字的混淆。</li>
<li>results: 该模型在G2P转换和其他语言特定任务上表现竞争力强，但有些语言和任务之间存在一些妥协。<details>
<summary>Abstract</summary>
Phonetic information and linguistic knowledge are an essential component of a Text-to-speech (TTS) front-end. Given a language, a lexicon can be collected offline and Grapheme-to-Phoneme (G2P) relationships are usually modeled in order to predict the pronunciation for out-of-vocabulary (OOV) words. Additionally, post-lexical phonology, often defined in the form of rule-based systems, is used to correct pronunciation within or between words. In this work we showcase a multilingual unified front-end system that addresses any pronunciation related task, typically handled by separate modules. We evaluate the proposed model on G2P conversion and other language-specific challenges, such as homograph and polyphones disambiguation, post-lexical rules and implicit diacritization. We find that the multilingual model is competitive across languages and tasks, however, some trade-offs exists when compared to equivalent monolingual solutions.
</details>
<details>
<summary>摘要</summary>
文本识别和语言知识是文本识别（TTS）前端的重要组成部分。给定一种语言，可以在线收集词典，并模型文字到音（G2P）关系，以预测未在词典中出现的词汇的发音。此外，在词语之间或者在词语之内进行发音 correction 也需要使用后 lexical phonology，通常通过规则集来实现。在这项工作中，我们展示了一种多语言统一前端系统，可以解决任何发音相关任务，通常由分立模块处理。我们对这种模型进行了G2P转换和其他语言特有挑战的评估，如Homograph和多音字识别、后 lexical 规则和隐式 диаcritization。我们发现，该多语言模型在语言和任务方面具有竞争力，但有些交换存在于与等效单语言解决方案进行比较时。
</details></li>
</ul>
<hr>
<h2 id="No-that’s-not-what-I-meant-Handling-Third-Position-Repair-in-Conversational-Question-Answering"><a href="#No-that’s-not-what-I-meant-Handling-Third-Position-Repair-in-Conversational-Question-Answering" class="headerlink" title="No that’s not what I meant: Handling Third Position Repair in Conversational Question Answering"></a>No that’s not what I meant: Handling Third Position Repair in Conversational Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16689">http://arxiv.org/abs/2307.16689</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vevake Balaraman, Arash Eshghi, Ioannis Konstas, Ioannis Papaioannou</li>
<li>for: 这 paper 的目的是研究人们在对话中如何处理歧义，以及如何使用 Third Position Repair (TPR) 来纠正歧义。</li>
<li>methods: 这 paper 使用了一个大型的 TPR 数据集，并对这些数据集进行了自动和人工评估。同时，paper 还使用了一些基eline 模型来执行 TPR。</li>
<li>results: 研究发现，OpenAI 的 GPT-3 LLMs 在原始turn的 TPR 处理方面表现不佳，但是在接下来的对话问答任务中，这些 LLMs 的 TPR 处理能力有了显著改善。<details>
<summary>Abstract</summary>
The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response. Here, we collect and publicly release Repair-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to Repair-QA.
</details>
<details>
<summary>摘要</summary>
人们在对话中处理混乱communication是关键，以确保对话AI强大和可靠。人们通常在发现混乱后立即处理，使用高度系统化的互动机制called repair。一种重要的修复方式是第三人称修复（TPR），在这种情况下，说话者在对方错误回答后才被理解，并在这个过程中修复错误。我们收集和公开发布了Repair-QA数据集，这是一个大型的TPR在对话问答（QA） Setting中的数据集。数据包括TPR转帧、对话上下文和原始转帧的可能修复。我们通过训练和评估强大基线模型来证明数据的有用性。对独立TPR执行来说，我们在一个精度调整的T5模型上进行自动和人工评估，以及OpenAI的GPT-3LLMs。此外，我们在下游对话问答任务中评估LLMs的TPR处理能力。结果表明GPT-3模型在出厂情况下对TPR表现不佳，但是在暴露于Repair-QA数据集后，其表现显著改善。
</details></li>
</ul>
<hr>
<h2 id="Comparing-normalizing-flows-and-diffusion-models-for-prosody-and-acoustic-modelling-in-text-to-speech"><a href="#Comparing-normalizing-flows-and-diffusion-models-for-prosody-and-acoustic-modelling-in-text-to-speech" class="headerlink" title="Comparing normalizing flows and diffusion models for prosody and acoustic modelling in text-to-speech"></a>Comparing normalizing flows and diffusion models for prosody and acoustic modelling in text-to-speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16679">http://arxiv.org/abs/2307.16679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyan Zhang, Thomas Merritt, Manuel Sam Ribeiro, Biel Tura-Vecino, Kayoko Yanagisawa, Kamil Pokora, Abdelhamid Ezzerg, Sebastian Cygert, Ammar Abbas, Piotr Bilinski, Roberto Barra-Chicote, Daniel Korzekwa, Jaime Lorenzo-Trueba</li>
<li>for: 这 paper 是用来比较传统 L1&#x2F;L2 loss 方法和流体和填充方法来进行 text-to-speech 合成 tasks 的。</li>
<li>methods: 这 paper 使用了一种 prosody 模型来生成 log-f0 和 duration 特征，这些特征用于 condition 一个 acoustic 模型，该模型生成 mel-spectrograms。</li>
<li>results: 实验结果表明，流体基本模型在 spectrogram 预测任务中 achieve 最佳性能，超过相同的 diffusion 和 L1 模型。同时，流体和填充 prosody 预测器均导致了significant 改善，比传统 L2 训练的 prosody 模型。<details>
<summary>Abstract</summary>
Neural text-to-speech systems are often optimized on L1/L2 losses, which make strong assumptions about the distributions of the target data space. Aiming to improve those assumptions, Normalizing Flows and Diffusion Probabilistic Models were recently proposed as alternatives. In this paper, we compare traditional L1/L2-based approaches to diffusion and flow-based approaches for the tasks of prosody and mel-spectrogram prediction for text-to-speech synthesis. We use a prosody model to generate log-f0 and duration features, which are used to condition an acoustic model that generates mel-spectrograms. Experimental results demonstrate that the flow-based model achieves the best performance for spectrogram prediction, improving over equivalent diffusion and L1 models. Meanwhile, both diffusion and flow-based prosody predictors result in significant improvements over a typical L2-trained prosody models.
</details>
<details>
<summary>摘要</summary>
传统的文本到语音系统通常是基于L1/L2损失优化的，这些损失假设了目标数据空间的分布。为了改善这些假设，流体和扩散概率模型最近被提出作为替代方案。在这篇论文中，我们比较了传统的L1/L2基于的方法和扩散和流体基于的方法 для文本到语音合成中的谱和频谱预测任务。我们使用一个谱模型来生成日吸率和持续时间特征，这些特征用于condition一个生成mel-spectrogram的语音模型。实验结果显示，流体基于的模型在spectrogram预测中表现最佳，超过了相当的扩散和L1模型。同时，扩散和流体基于的谱预测模型均导致了对于Typical L2训练的谱模型的显著改进。
</details></li>
</ul>
<hr>
<h2 id="The-World-Literature-Knowledge-Graph"><a href="#The-World-Literature-Knowledge-Graph" class="headerlink" title="The World Literature Knowledge Graph"></a>The World Literature Knowledge Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16659">http://arxiv.org/abs/2307.16659</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elifhaciosmanoglu/PythonL-For-Mathematicians">https://github.com/elifhaciosmanoglu/PythonL-For-Mathematicians</a></li>
<li>paper_authors: Marco Antonio Stranisci, Eleonora Bernasconi, Viviana Patti, Stefano Ferilli, Miguel Ceriani, Rossana Damiano</li>
<li>for: 这篇论文旨在提供一个 semantic resource，用于探索不同地区文学作品和作者的事实。</li>
<li>methods: 该论文使用了3个不同的读者社区的反馈，并将其整合到一个Semantic Model中，以便更好地探索世界文学的知识。</li>
<li>results: 论文通过在线可视化平台提供了194,346名作家和965,210部作品的知识 graph，并在3个不同的专家领域进行了严格的测试和验证，得到了高度的评价和满意度。<details>
<summary>Abstract</summary>
Digital media have enabled the access to unprecedented literary knowledge. Authors, readers, and scholars are now able to discover and share an increasing amount of information about books and their authors. However, these sources of knowledge are fragmented and do not adequately represent non-Western writers and their works. In this paper we present The World Literature Knowledge Graph, a semantic resource containing 194,346 writers and 965,210 works, specifically designed for exploring facts about literary works and authors from different parts of the world. The knowledge graph integrates information about the reception of literary works gathered from 3 different communities of readers, aligned according to a single semantic model. The resource is accessible through an online visualization platform, which can be found at the following URL: https://literaturegraph.di.unito.it/. This platform has been rigorously tested and validated by $3$ distinct categories of experts who have found it to be highly beneficial for their respective work domains. These categories include teachers, researchers in the humanities, and professionals in the publishing industry. The feedback received from these experts confirms that they can effectively utilize the platform to enhance their work processes and achieve valuable outcomes.
</details>
<details>
<summary>摘要</summary>
数字媒体为我们提供了前所未有的文学知识访问。作家、读者和学者现在可以找到和分享越来越多的关于书籍和作家的信息。然而，这些知识来源是分散的，并不充分代表非西方作家和他们的作品。在这篇论文中，我们介绍了世界文学知识图，这是一个基于semantic模型的语义资源，用于探索不同地区的文学作品和作家的事实。知识图集成了来自3个不同社区的读者的受众反馈，并以单一的semantic模型进行对接。这个资源可以通过以下URL访问：https://literaturegraph.di.unito.it/.这个平台已经被3种不同的专家组织rigorously测试和验证，这些专家包括教师、人文科学研究人员和出版业专业人员。这些专家的反馈表明，他们可以通过这个平台增强工作流程，并实现价值的成果。
</details></li>
</ul>
<hr>
<h2 id="Scaling-Sentence-Embeddings-with-Large-Language-Models"><a href="#Scaling-Sentence-Embeddings-with-Large-Language-Models" class="headerlink" title="Scaling Sentence Embeddings with Large Language Models"></a>Scaling Sentence Embeddings with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16645">http://arxiv.org/abs/2307.16645</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kongds/scaling_sentemb">https://github.com/kongds/scaling_sentemb</a></li>
<li>paper_authors: Ting Jiang, Shaohan Huang, Zhongzhi Luan, Deqing Wang, Fuzhen Zhuang</li>
<li>for: 本研究旨在提高句子嵌入性能，通过句子嵌入来提高自然语言处理任务的性能。</li>
<li>methods: 我们提出了一种基于句子嵌入的培训方法，通过适应之前的提问基础表示方法，构建了一个示例集，使得LLMs可以进行上下文学习。我们还对LLMs进行了缩放，以不同的模型大小进行比较。</li>
<li>results: 通过广泛的实验，我们发现在句子嵌入任务上，通过培训LLMs可以获得高质量的句子嵌入，无需任何微调。此外，我们发现，随着模型大小的增加，模型在语义文本相似性（STS）任务上的性能会下降。但是，我们发现最大化模型可以超过其他对手，并达到新的状态态表现在转移任务上。此外，我们还对LLMs进行了现有对比学习方法的微调，并发现2.7B OPT模型，通过我们的提示基础方法，超过了4.8B ST5模型的性能，达到新的状态态表现在STS任务上。<details>
<summary>Abstract</summary>
Large language models (LLMs) have recently garnered significant interest. With in-context learning, LLMs achieve impressive results in various natural language tasks. However, the application of LLMs to sentence embeddings remains an area of ongoing research. In this work, we propose an in-context learning-based method aimed at improving sentence embeddings performance. Our approach involves adapting the previous prompt-based representation method for autoregressive models, constructing a demonstration set that enables LLMs to perform in-context learning, and scaling up the LLMs to different model sizes. Through extensive experiments, in-context learning enables LLMs to generate high-quality sentence embeddings without any fine-tuning. It helps LLMs achieve performance comparable to current contrastive learning methods. By scaling model size, we find scaling to more than tens of billion parameters harms the performance on semantic textual similarity (STS) tasks. However, the largest model outperforms other counterparts and achieves the new state-of-the-art result on transfer tasks. We also fine-tune LLMs with current contrastive learning approach, and the 2.7B OPT model, incorporating our prompt-based method, surpasses the performance of 4.8B ST5, achieving the new state-of-the-art results on STS tasks. Our code is available at https://github.com/kongds/scaling_sentemb.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-grapheme-to-phoneme-conversion-by-learning-pronunciations-from-speech-recordings"><a href="#Improving-grapheme-to-phoneme-conversion-by-learning-pronunciations-from-speech-recordings" class="headerlink" title="Improving grapheme-to-phoneme conversion by learning pronunciations from speech recordings"></a>Improving grapheme-to-phoneme conversion by learning pronunciations from speech recordings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16643">http://arxiv.org/abs/2307.16643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manuel Sam Ribeiro, Giulia Comini, Jaime Lorenzo-Trueba</li>
<li>for: 提高Grapheme-to-Phoneme（G2P）任务的精度，使其更适合各种语音处理应用程序。</li>
<li>methods: 根据语音录制Example学习发音词典，然后使用这些词典来重新训练G2P系统。</li>
<li>results: 对多种语言和数据量不同的G2P系统，our approach consistently提高了Phone错误率。<details>
<summary>Abstract</summary>
The Grapheme-to-Phoneme (G2P) task aims to convert orthographic input into a discrete phonetic representation. G2P conversion is beneficial to various speech processing applications, such as text-to-speech and speech recognition. However, these tend to rely on manually-annotated pronunciation dictionaries, which are often time-consuming and costly to acquire. In this paper, we propose a method to improve the G2P conversion task by learning pronunciation examples from audio recordings. Our approach bootstraps a G2P with a small set of annotated examples. The G2P model is used to train a multilingual phone recognition system, which then decodes speech recordings with a phonetic representation. Given hypothesized phoneme labels, we learn pronunciation dictionaries for out-of-vocabulary words, and we use those to re-train the G2P system. Results indicate that our approach consistently improves the phone error rate of G2P systems across languages and amount of available data.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a method to improve the G2P conversion task by learning pronunciation examples from audio recordings. We start with a small set of annotated examples and use a G2P model to train a multilingual phone recognition system. This system decodes speech recordings using a phonetic representation. Given hypothesized phoneme labels, we learn pronunciation dictionaries for out-of-vocabulary words and use those to re-train the G2P system.Our approach consistently improves the phone error rate of G2P systems across languages and amounts of available data. This shows that our method is effective in improving the accuracy of G2P conversion.
</details></li>
</ul>
<hr>
<h2 id="VacancySBERT-the-approach-for-representation-of-titles-and-skills-for-semantic-similarity-search-in-the-recruitment-domain"><a href="#VacancySBERT-the-approach-for-representation-of-titles-and-skills-for-semantic-similarity-search-in-the-recruitment-domain" class="headerlink" title="VacancySBERT: the approach for representation of titles and skills for semantic similarity search in the recruitment domain"></a>VacancySBERT: the approach for representation of titles and skills for semantic similarity search in the recruitment domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16638">http://arxiv.org/abs/2307.16638</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maiiabocharova/vacancysbert">https://github.com/maiiabocharova/vacancysbert</a></li>
<li>paper_authors: Maiia Bocharova, Eugene Malakhov, Vitaliy Mezhuyev</li>
<li>for: 本研究旨在应用深度学习 semantic search 算法于人力资源领域，开发一种链接 Job 招聘广告中提到的技能与 Job 标题的新方法。</li>
<li>methods: 本研究使用 semantic similarity search 算法来找到匹配 Job 标题和技能的候选者，并采用了预训练语言模型，通过对Title-description对的协同信息进行教学，使模型能够匹配标题和技能。</li>
<li>results: 研究表明，使用自定义训练目标可以实现显著改进，比如使用 VacancySBERT 和 VacancySBERT (with skills) 得到了10% 和 21.5% 的提升。此外，开发了一个开源的基准数据集，以便进一步探索这一领域。<details>
<summary>Abstract</summary>
The paper focuses on deep learning semantic search algorithms applied in the HR domain. The aim of the article is developing a novel approach to training a Siamese network to link the skills mentioned in the job ad with the title. It has been shown that the title normalization process can be based either on classification or similarity comparison approaches. While classification algorithms strive to classify a sample into predefined set of categories, similarity search algorithms take a more flexible approach, since they are designed to find samples that are similar to a given query sample, without requiring pre-defined classes and labels. In this article semantic similarity search to find candidates for title normalization has been used. A pre-trained language model has been adapted while teaching it to match titles and skills based on co-occurrence information. For the purpose of this research fifty billion title-descriptions pairs had been collected for training the model and thirty three thousand title-description-normalized title triplets, where normalized job title was picked up manually by job ad creator for testing purposes. As baselines FastText, BERT, SentenceBert and JobBert have been used. As a metric of the accuracy of the designed algorithm is Recall in top one, five and ten model's suggestions. It has been shown that the novel training objective lets it achieve significant improvement in comparison to other generic and specific text encoders. Two settings with treating titles as standalone strings, and with included skills as additional features during inference have been used and the results have been compared in this article. Improvements by 10% and 21.5% have been achieved using VacancySBERT and VacancySBERT (with skills) respectively. The benchmark has been developed as open-source to foster further research in the area.
</details>
<details>
<summary>摘要</summary>
文章主要研究深度学习 semantic search 算法在人力资源（HR）领域中的应用。文章的目标是开发一种新的方法，通过链接在职位招聘中提到的技能与工作标题之间的连接。研究表明，标题Normalization过程可以基于类别或相似性比较方法。而类别算法尝试将样本分类到预定的类别中，相似性搜索算法则更加灵活，它们可以找到与查询样本相似的样本，无需预定的类别和标签。本文使用semantic similarity搜索来查找候选者。研究人员采用了预训练的语言模型，并将其改进以将标题和技能相匹配，基于共occurrence信息。为了训练模型，收集了50亿个标题-描述对，并使用33,000个标题-描述-Normalized标题 triplets进行测试。作为基准，使用了FastText、BERT、SentenceBert和JobBert。用于评估算法准确性的指标是Recall在top一、五和十个模型建议中。研究表明，新的训练目标可以实现显著改进，相比于其他通用和专门的文本编码器。在使用标题作为独立字符串和包含技能作为推断时进行两种设置后，对比结果。使用VacancySBERT和VacancySBERT（与技能）后，分别实现了10%和21.5%的提高。研究人员开发了一个开源的标准套件，以便进一步的研究。
</details></li>
</ul>
<hr>
<h2 id="Text-CRS-A-Generalized-Certified-Robustness-Framework-against-Textual-Adversarial-Attacks"><a href="#Text-CRS-A-Generalized-Certified-Robustness-Framework-against-Textual-Adversarial-Attacks" class="headerlink" title="Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks"></a>Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16630">http://arxiv.org/abs/2307.16630</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Eyr3/TextCRS">https://github.com/Eyr3/TextCRS</a></li>
<li>paper_authors: Xinyu Zhang, Hanbin Hong, Yuan Hong, Peng Huang, Binghui Wang, Zhongjie Ba, Kui Ren</li>
<li>for: 防止文本 adversarial 攻击，提高模型robustness</li>
<li>methods: 使用randomized smoothing方法， derive robustness bounds against four word-level adversarial operations</li>
<li>results: Text-CRS可以Address all four different word-level adversarial operations，significantly improve certified accuracy and radius，outperform state-of-the-art certification against synonym substitution attacks，provide the first benchmark on certified accuracy and radius of four word-level operations.<details>
<summary>Abstract</summary>
The language models, especially the basic text classification models, have been shown to be susceptible to textual adversarial attacks such as synonym substitution and word insertion attacks. To defend against such attacks, a growing body of research has been devoted to improving the model robustness. However, providing provable robustness guarantees instead of empirical robustness is still widely unexplored. In this paper, we propose Text-CRS, a generalized certified robustness framework for natural language processing (NLP) based on randomized smoothing. To our best knowledge, existing certified schemes for NLP can only certify the robustness against $\ell_0$ perturbations in synonym substitution attacks. Representing each word-level adversarial operation (i.e., synonym substitution, word reordering, insertion, and deletion) as a combination of permutation and embedding transformation, we propose novel smoothing theorems to derive robustness bounds in both permutation and embedding space against such adversarial operations. To further improve certified accuracy and radius, we consider the numerical relationships between discrete words and select proper noise distributions for the randomized smoothing. Finally, we conduct substantial experiments on multiple language models and datasets. Text-CRS can address all four different word-level adversarial operations and achieve a significant accuracy improvement. We also provide the first benchmark on certified accuracy and radius of four word-level operations, besides outperforming the state-of-the-art certification against synonym substitution attacks.
</details>
<details>
<summary>摘要</summary>
Language models, especially basic text classification models, have been shown to be vulnerable to textual adversarial attacks such as synonym substitution and word insertion attacks. To defend against such attacks, a growing body of research has been devoted to improving model robustness. However, providing provable robustness guarantees instead of empirical robustness is still widely unexplored. In this paper, we propose Text-CRS, a generalized certified robustness framework for natural language processing (NLP) based on randomized smoothing. To our best knowledge, existing certified schemes for NLP can only certify the robustness against $\ell_0$ perturbations in synonym substitution attacks.Representing each word-level adversarial operation (i.e., synonym substitution, word reordering, insertion, and deletion) as a combination of permutation and embedding transformation, we propose novel smoothing theorems to derive robustness bounds in both permutation and embedding space against such adversarial operations. To further improve certified accuracy and radius, we consider the numerical relationships between discrete words and select proper noise distributions for the randomized smoothing.Finally, we conduct substantial experiments on multiple language models and datasets. Text-CRS can address all four different word-level adversarial operations and achieve a significant accuracy improvement. We also provide the first benchmark on certified accuracy and radius of four word-level operations, besides outperforming the state-of-the-art certification against synonym substitution attacks.
</details></li>
</ul>
<hr>
<h2 id="Noisy-Self-Training-with-Data-Augmentations-for-Offensive-and-Hate-Speech-Detection-Tasks"><a href="#Noisy-Self-Training-with-Data-Augmentations-for-Offensive-and-Hate-Speech-Detection-Tasks" class="headerlink" title="Noisy Self-Training with Data Augmentations for Offensive and Hate Speech Detection Tasks"></a>Noisy Self-Training with Data Augmentations for Offensive and Hate Speech Detection Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16609">http://arxiv.org/abs/2307.16609</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jaugusto97/offense-self-training">https://github.com/jaugusto97/offense-self-training</a></li>
<li>paper_authors: João A. Leite, Carolina Scarton, Diego F. Silva</li>
<li>for: Automatic detection of offensive and hateful comments in online social media.</li>
<li>methods: Self-training and noisy self-training using textual data augmentations with five pre-trained BERT architectures.</li>
<li>results: Self-training consistently improves performance, while noisy self-training decreases performance on offensive and hate-speech domains.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究旨在自动检测社交媒体上的侮辱和恐吓言论。</li>
<li>methods: 使用自我训练和含杂自我训练，使用文本数据增强技术，采用五种不同的预训练BERT架构。</li>
<li>results: 自我训练可以一直提高表现，而含杂自我训练在侮辱和恐吓言论领域的表现下降。<details>
<summary>Abstract</summary>
Online social media is rife with offensive and hateful comments, prompting the need for their automatic detection given the sheer amount of posts created every second. Creating high-quality human-labelled datasets for this task is difficult and costly, especially because non-offensive posts are significantly more frequent than offensive ones. However, unlabelled data is abundant, easier, and cheaper to obtain. In this scenario, self-training methods, using weakly-labelled examples to increase the amount of training data, can be employed. Recent "noisy" self-training approaches incorporate data augmentation techniques to ensure prediction consistency and increase robustness against noisy data and adversarial attacks. In this paper, we experiment with default and noisy self-training using three different textual data augmentation techniques across five different pre-trained BERT architectures varying in size. We evaluate our experiments on two offensive/hate-speech datasets and demonstrate that (i) self-training consistently improves performance regardless of model size, resulting in up to +1.5% F1-macro on both datasets, and (ii) noisy self-training with textual data augmentations, despite being successfully applied in similar settings, decreases performance on offensive and hate-speech domains when compared to the default method, even with state-of-the-art augmentations such as backtranslation.
</details>
<details>
<summary>摘要</summary>
在线社交媒体中，有许多内容具有攻击性和恐惧语气，导致自动检测的需求，因为每秒钟有极多的创建。然而，人工标注数据实际上很难以取得，特别是非攻击性内容比攻击性内容更多。在这种情况下，自我训练方法可以使用弱标注的例子增加训练数据的量。现代的“杂音”自我训练方法将数据扩展技术纳入训练，以确保预测的一致性和抗衰变攻击的强健性。在这篇文章中，我们将实验 default 和杂音自我训练，使用三种文本数据扩展技术，在五种不同的预读BERT架构上进行评估。我们在两个攻击和负面语气dataset上进行评估，结果显示：（i）自我训练无变通过所有模型大小，实现最高 +1.5% F1-macro 的改善，（ii）杂音自我训练对于攻击和负面语气领域的性能下降，即使使用了现代的数据扩展技术，如回译。
</details></li>
</ul>
<hr>
<h2 id="Deep-Dive-into-the-Language-of-International-Relations-NLP-based-Analysis-of-UNESCO’s-Summary-Records"><a href="#Deep-Dive-into-the-Language-of-International-Relations-NLP-based-Analysis-of-UNESCO’s-Summary-Records" class="headerlink" title="Deep Dive into the Language of International Relations: NLP-based Analysis of UNESCO’s Summary Records"></a>Deep Dive into the Language of International Relations: NLP-based Analysis of UNESCO’s Summary Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16573">http://arxiv.org/abs/2307.16573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joanna Wojciechowska, Mateusz Sypniewski, Maria Śmigielska, Igor Kamiński, Emilia Wiśnios, Hanna Schreiber, Bartosz Pieliński</li>
<li>for: 该论文旨在研究UNESCO世界遗产名录和联合国教科文组织非物质文化遗产名录的投票过程中的紧张关系和冲突，以及开发自动化工具来提供有价值的决策过程分析。</li>
<li>methods: 该研究使用创新的话题模型和紧张度探测方法，基于UNESCO的摘要记录，实现了72%的准确率在检测紧张关系。此外，研究人员还开发了一个专门为外交官、律师、政治科学家和国际关系研究人员设计的应用程序，以便高效搜索选定文档和特定发言人的话题。</li>
<li>results: 该研究的结果表明，自动化工具可以提供有价值的决策过程分析，帮助解决国际遗产投票过程中的紧张关系和冲突。<details>
<summary>Abstract</summary>
Cultural heritage is an arena of international relations that interests all states worldwide. The inscription process on the UNESCO World Heritage List and the UNESCO Representative List of the Intangible Cultural Heritage of Humanity often leads to tensions and conflicts among states. This research addresses these challenges by developing automatic tools that provide valuable insights into the decision-making processes regarding inscriptions to the two lists mentioned above. We propose innovative topic modelling and tension detection methods based on UNESCO's summary records. Our analysis achieved a commendable accuracy rate of 72% in identifying tensions. Furthermore, we have developed an application tailored for diplomats, lawyers, political scientists, and international relations researchers that facilitates the efficient search of paragraphs from selected documents and statements from specific speakers about chosen topics. This application is a valuable resource for enhancing the understanding of complex decision-making dynamics within international heritage inscription procedures.
</details>
<details>
<summary>摘要</summary>
文化遗产是国际关系的一个领域，各国都很关心。联合国教科文组织世界遗产名录和联合国教科文组织非物质文化遗产名录的登记过程经常导致国家之间的紧张关系和冲突。本研究通过开发自动化工具，为各国帮助解决这些挑战。我们提出了创新的话题模型和紧张检测方法，基于联合国教科文组织的摘要记录。我们的分析达到了72%的准确率，可以快速寻找关键话题和紧张关系。此外，我们开发了一个专门为外交官、律师、政治科学家和国际关系研究人员设计的应用程序，可以帮助这些人快速搜索选择的文档和来自特定发言人的声明中的特定话题。这个应用程序是国际遗产登记过程中复杂决策动力理解的重要资源。
</details></li>
</ul>
<hr>
<h2 id="DiffProsody-Diffusion-based-Latent-Prosody-Generation-for-Expressive-Speech-Synthesis-with-Prosody-Conditional-Adversarial-Training"><a href="#DiffProsody-Diffusion-based-Latent-Prosody-Generation-for-Expressive-Speech-Synthesis-with-Prosody-Conditional-Adversarial-Training" class="headerlink" title="DiffProsody: Diffusion-based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training"></a>DiffProsody: Diffusion-based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16549">http://arxiv.org/abs/2307.16549</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hsoh0306/diffprosody">https://github.com/hsoh0306/diffprosody</a></li>
<li>paper_authors: Hyung-Seok Oh, Sang-Hoon Lee, Seong-Whan Lee</li>
<li>for: This paper focuses on improving the quality and speed of expressive text-to-speech systems through the use of a diffusion-based latent prosody generator and prosody conditional adversarial training.</li>
<li>methods: The proposed method, called DiffProsody, uses a diffusion-based latent prosody generator and prosody conditional adversarial training to generate high-quality speech with accurate prosody. The method also utilizes denoising diffusion generative adversarial networks to improve the prosody generation speed.</li>
<li>results: The paper demonstrates the effectiveness of the proposed method through experiments, showing that DiffProsody is capable of generating prosody 16 times faster than the conventional diffusion model, with superior performance compared to other state-of-the-art methods.<details>
<summary>Abstract</summary>
Expressive text-to-speech systems have undergone significant advancements owing to prosody modeling, but conventional methods can still be improved. Traditional approaches have relied on the autoregressive method to predict the quantized prosody vector; however, it suffers from the issues of long-term dependency and slow inference. This study proposes a novel approach called DiffProsody in which expressive speech is synthesized using a diffusion-based latent prosody generator and prosody conditional adversarial training. Our findings confirm the effectiveness of our prosody generator in generating a prosody vector. Furthermore, our prosody conditional discriminator significantly improves the quality of the generated speech by accurately emulating prosody. We use denoising diffusion generative adversarial networks to improve the prosody generation speed. Consequently, DiffProsody is capable of generating prosody 16 times faster than the conventional diffusion model. The superior performance of our proposed method has been demonstrated via experiments.
</details>
<details>
<summary>摘要</summary>
现代文本到语音系统已经经历了重要的进步，归功于谱系模型。然而，传统方法仍然有可以改进的地方。传统方法通常采用推论方法来预测量化的谱系 вектор;然而，它受到长期依赖和慢速推理的问题困扰。本研究提出了一种新的方法，即DiffProsody，用于生成表达性的语音。我们的发现表明，我们的谱系生成器可以生成高质量的谱系 вектор。此外，我们的谱系条件推论器可以准确地模拟谱系，从而提高生成的语音质量。我们使用denoising扩散生成 adversarial networks来提高谱系生成速度。因此，DiffProsody可以在16倍的速度上生成谱系。我们的实验结果表明，我们的提议的方法在性能上有superior的表现。
</details></li>
</ul>
<hr>
<h2 id="Specification-of-MiniDemographicABM-jl-A-simplified-agent-based-demographic-model-of-the-UK"><a href="#Specification-of-MiniDemographicABM-jl-A-simplified-agent-based-demographic-model-of-the-UK" class="headerlink" title="Specification of MiniDemographicABM.jl: A simplified agent-based demographic model of the UK"></a>Specification of MiniDemographicABM.jl: A simplified agent-based demographic model of the UK</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16548">http://arxiv.org/abs/2307.16548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atiyah Elsheikh</li>
<li>For: The paper is written for exploring and exploiting the capabilities of the state-of-the-art Agents.jl Julia package in a simplified non-calibrated agent-based demographic model of the UK.* Methods: The paper uses a simplified non-calibrated agent-based demographic model of the UK, where individuals are subject to ageing, deaths, births, divorces, and marriages. The model can be simulated with a user-defined simulation fixed step size on a hourly, daily, weekly, monthly basis or even an arbitrary user-defined clock rate.* Results: The paper can serve as a base model to be adjusted to realistic large-scale socio-economics, pandemics or social interactions-based studies mainly within a demographic context.Here is the same information in Simplified Chinese text:* For: 本文是用于探索和利用现代Agents.jl Julia包的能力的简化非参数化人工智能模型，用于研究英国人口的特点。* Methods: 该模型使用简化非参数化人工智能模型，其中个体受到年龄、死亡、生育、离婚和婚姻的影响。模型可以通过用户定义的 simulation fixed step size 进行模拟，并且可以在每小时、每天、每周、每月基础或者用户定义的时间刻度进行模拟。* Results: 该模型可以作为基本模型，用于调整大规模的社会经济、疫情或者社交互动等研究，主要在人口学上。<details>
<summary>Abstract</summary>
This document presents adequate formal terminology for the mathematical specification of a simplified non-calibrated agent-based demographic model of the UK. Individuals of an initial population are subject to ageing, deaths, births, divorces and marriages. The main purpose of the model is to explore and exploit capabilities of the state-of-the-art Agents.jl Julia package [1]. Additionally, the model can serve as a base model to be adjusted to realistic large-scale socio-economics, pandemics or social interactions-based studies mainly within a demographic context. A specific simulation is progressed with a user-defined simulation fixed step size on a hourly, daily, weekly, monthly basis or even an arbitrary user-defined clock rate.
</details>
<details>
<summary>摘要</summary>
Translation Notes:1. "non-calibrated" 不是 "calibrated" 的反义词。"non-calibrated" 是指模型没有进行过精度调整，而"calibrated" 则是指模型已经进行了精度调整。2. "agent-based" 是指模型使用代理（agent）来表示实体，而不是使用固定的数值或函数来描述实体。3. "demographic" 是指人口的统计学性质，包括年龄、性别、地域等。4. "simulation" 是指模拟或复制实际情况的过程，通常使用计算机模拟实现。5. "fixed step size" 是指每次执行模拟时，使用固定的时间间隔（step size）来执行计算。6. "user-defined" 是指用户可以自定义的参数或设置，例如 simulation clock rate。
</details></li>
</ul>
<hr>
<h2 id="Utilisation-of-open-intent-recognition-models-for-customer-support-intent-detection"><a href="#Utilisation-of-open-intent-recognition-models-for-customer-support-intent-detection" class="headerlink" title="Utilisation of open intent recognition models for customer support intent detection"></a>Utilisation of open intent recognition models for customer support intent detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16544">http://arxiv.org/abs/2307.16544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rasheed Mohammad, Oliver Favell, Shariq Shah, Emmett Cooper, Edlira Vakaj</li>
<li>for: 这篇论文旨在探讨客户支持方面的人工智能应用，以帮助企业提供更好的客户服务，提高客户满意度。</li>
<li>methods: 该论文使用了社交媒体、人工智能（AI）、机器学习（ML）等技术，以及远程设备连接，对客户进行更加快速、高效和专业的支持。</li>
<li>results: 研究表明，使用这些技术可以提高客户支持效率和准确率，同时为企业提供更多的国际客户和业务规模。然而，在检测未知意图方面，还需要进一步的研究和改进。<details>
<summary>Abstract</summary>
Businesses have sought out new solutions to provide support and improve customer satisfaction as more products and services have become interconnected digitally. There is an inherent need for businesses to provide or outsource fast, efficient and knowledgeable support to remain competitive. Support solutions are also advancing with technologies, including use of social media, Artificial Intelligence (AI), Machine Learning (ML) and remote device connectivity to better support customers. Customer support operators are trained to utilise these technologies to provide better customer outreach and support for clients in remote areas. Interconnectivity of products and support systems provide businesses with potential international clients to expand their product market and business scale. This paper reports the possible AI applications in customer support, done in collaboration with the Knowledge Transfer Partnership (KTP) program between Birmingham City University and a company that handles customer service systems for businesses outsourcing customer support across a wide variety of business sectors. This study explored several approaches to accurately predict customers' intent using both labelled and unlabelled textual data. While some approaches showed promise in specific datasets, the search for a single, universally applicable approach continues. The development of separate pipelines for intent detection and discovery has led to improved accuracy rates in detecting known intents, while further work is required to improve the accuracy of intent discovery for unknown intents.
</details>
<details>
<summary>摘要</summary>
This paper reports on the possible AI applications in customer support, done in collaboration with the Knowledge Transfer Partnership (KTP) program between Birmingham City University and a company that handles customer service systems for businesses outsourcing customer support across a wide variety of business sectors. This study explored several approaches to accurately predict customers' intent using both labeled and unlabeled textual data. While some approaches showed promise in specific datasets, the search for a single, universally applicable approach continues. The development of separate pipelines for intent detection and discovery has led to improved accuracy rates in detecting known intents, while further work is required to improve the accuracy of intent discovery for unknown intents.
</details></li>
</ul>
<hr>
<h2 id="Transferable-Decoding-with-Visual-Entities-for-Zero-Shot-Image-Captioning"><a href="#Transferable-Decoding-with-Visual-Entities-for-Zero-Shot-Image-Captioning" class="headerlink" title="Transferable Decoding with Visual Entities for Zero-Shot Image Captioning"></a>Transferable Decoding with Visual Entities for Zero-Shot Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16525">http://arxiv.org/abs/2307.16525</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/feielysia/viecap">https://github.com/feielysia/viecap</a></li>
<li>paper_authors: Junjie Fei, Teng Wang, Jinrui Zhang, Zhenyu He, Chengjie Wang, Feng Zheng</li>
<li>for: This paper aims to improve image-to-text generation by addressing the problem of object hallucination in zero-shot image captioning.</li>
<li>methods: The proposed method, ViECap, uses entity-aware decoding to guide the attention of large language models (LLMs) toward the visual entities present in the image, improving the coherence and accuracy of the generated captions.</li>
<li>results: Extensive experiments show that ViECap sets a new state-of-the-art cross-domain (transferable) captioning performance and performs competitively in-domain captioning compared to previous VLMs-based zero-shot methods.<details>
<summary>Abstract</summary>
Image-to-text generation aims to describe images using natural language. Recently, zero-shot image captioning based on pre-trained vision-language models (VLMs) and large language models (LLMs) has made significant progress. However, we have observed and empirically demonstrated that these methods are susceptible to modality bias induced by LLMs and tend to generate descriptions containing objects (entities) that do not actually exist in the image but frequently appear during training (i.e., object hallucination). In this paper, we propose ViECap, a transferable decoding model that leverages entity-aware decoding to generate descriptions in both seen and unseen scenarios. ViECap incorporates entity-aware hard prompts to guide LLMs' attention toward the visual entities present in the image, enabling coherent caption generation across diverse scenes. With entity-aware hard prompts, ViECap is capable of maintaining performance when transferring from in-domain to out-of-domain scenarios. Extensive experiments demonstrate that ViECap sets a new state-of-the-art cross-domain (transferable) captioning and performs competitively in-domain captioning compared to previous VLMs-based zero-shot methods. Our code is available at: https://github.com/FeiElysia/ViECap
</details>
<details>
<summary>摘要</summary>
Image-to-text生成旨在使用自然语言描述图像。最近，零批学习图像描述基于预训练视觉语言模型（VLM）和大型语言模型（LLM）已经取得了重要进展。然而，我们观察到和实际示出了这些方法受模式偏见（modality bias）的LLM的影响，往往生成包含图像中不存在的对象（实体）的描述（对象幻觉）。在本文中，我们提出了ViECap，一种可移植的解码器，利用实体意识的解码来生成在seen和unseen场景中的描述。ViECap使用实体意识强制提示来导引LLM的视觉注意力，使其能够在多样场景中生成准确的描述。与传统的VLMs-based零shot方法相比，ViECap在跨频道场景中维持性能，并在域内场景中表现竞争力。我们的代码可以在GitHub上找到：https://github.com/FeiElysia/ViECap
</details></li>
</ul>
<hr>
<h2 id="Classifying-multilingual-party-manifestos-Domain-transfer-across-country-time-and-genre"><a href="#Classifying-multilingual-party-manifestos-Domain-transfer-across-country-time-and-genre" class="headerlink" title="Classifying multilingual party manifestos: Domain transfer across country, time, and genre"></a>Classifying multilingual party manifestos: Domain transfer across country, time, and genre</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16511">http://arxiv.org/abs/2307.16511</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/slds-lmu/manifesto-domaintransfer">https://github.com/slds-lmu/manifesto-domaintransfer</a></li>
<li>paper_authors: Matthias Aßenmacher, Nadja Sauter, Christian Heumann</li>
<li>for: 本研究旨在探讨域传递在政治宣言中的可靠性和可重用性。</li>
<li>methods: 研究使用了大量政治宣言数据库，并对模型进行了精细调整。</li>
<li>results: 研究发现，使用(Distil)BERT模型可以在不同语言、地域、时间和类型的政治宣言中实现类似的表现。此外，研究还发现了不同国家的政治宣言之间存在一定的差异，即使这些国家使用同一种语言或文化背景。<details>
<summary>Abstract</summary>
Annotating costs of large corpora are still one of the main bottlenecks in empirical social science research. On the one hand, making use of the capabilities of domain transfer allows re-using annotated data sets and trained models. On the other hand, it is not clear how well domain transfer works and how reliable the results are for transfer across different dimensions. We explore the potential of domain transfer across geographical locations, languages, time, and genre in a large-scale database of political manifestos. First, we show the strong within-domain classification performance of fine-tuned transformer models. Second, we vary the genre of the test set across the aforementioned dimensions to test for the fine-tuned models' robustness and transferability. For switching genres, we use an external corpus of transcribed speeches from New Zealand politicians while for the other three dimensions, custom splits of the Manifesto database are used. While BERT achieves the best scores in the initial experiments across modalities, DistilBERT proves to be competitive at a lower computational expense and is thus used for further experiments across time and country. The results of the additional analysis show that (Distil)BERT can be applied to future data with similar performance. Moreover, we observe (partly) notable differences between the political manifestos of different countries of origin, even if these countries share a language or a cultural background.
</details>
<details>
<summary>摘要</summary>
大公司的标注成本仍是employmultiple的社会科学研究的主要瓶颈。一方面，利用领域传输的能力可以重用标注数据集和训练模型。另一方面，不清楚领域传输是如何工作，结果如何可靠性。我们在一个大规模的政治宣言数据库中探索领域传输的潜力。首先，我们显示了在不同领域内的精度转换模型的强大表现。其次，我们在不同维度上随机选择测试集，以测试精度转换模型的可靠性和可迁移性。为了在类别之间转换，我们使用新西兰政治人物的演讲录音库，而其他三个维度使用自定义的演示数据。虽然BERT在初始实验中Across modalities achieve the best scores，但DistilBERT在更低的计算成本下能够达到类似的性能，因此我们在时间和国家之间进行了进一步的实验。results of the additional analysis show that (Distil)BERT can be applied to future data with similar performance.更重要的是，我们发现了不同国家的政治宣言之间有些 notable differences，即使这些国家共享语言或文化背景。
</details></li>
</ul>
<hr>
<h2 id="FinVis-GPT-A-Multimodal-Large-Language-Model-for-Financial-Chart-Analysis"><a href="#FinVis-GPT-A-Multimodal-Large-Language-Model-for-Financial-Chart-Analysis" class="headerlink" title="FinVis-GPT: A Multimodal Large Language Model for Financial Chart Analysis"></a>FinVis-GPT: A Multimodal Large Language Model for Financial Chart Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01430">http://arxiv.org/abs/2308.01430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziao Wang, Yuhang Li, Junda Wu, Jaehyeon Soon, Xiaofeng Zhang</li>
<li>for:  FinVis-GPT is proposed for financial chart analysis, providing valuable analysis and interpretation of financial charts.</li>
<li>methods: FinVis-GPT uses a multimodal large language model (LLM) with instruction tuning and multimodal capabilities to analyze financial charts.</li>
<li>results: FinVis-GPT demonstrates superior performance in various financial chart related tasks, including generating descriptions, answering questions, and predicting future market trends, compared to existing state-of-the-art multimodal LLMs.Here is the text in Simplified Chinese:</li>
<li>for:  FinVis-GPT 是为金融图表分析而提出的一种新型多Modal大语言模型，它可以准确地解读和分析金融图表。</li>
<li>methods: FinVis-GPT 使用了多Modal大语言模型（LLM），并通过指令调整和多Modal能力来分析金融图表。</li>
<li>results: FinVis-GPT 在多种金融图表相关任务中表现出色，包括生成描述、回答问题和预测未来市场趋势，比现有的多Modal LLM 更高效。<details>
<summary>Abstract</summary>
In this paper, we propose FinVis-GPT, a novel multimodal large language model (LLM) specifically designed for financial chart analysis. By leveraging the power of LLMs and incorporating instruction tuning and multimodal capabilities, FinVis-GPT is capable of interpreting financial charts and providing valuable analysis. To train FinVis-GPT, a financial task oriented dataset was generated for pre-training alignment and instruction tuning, comprising various types of financial charts and their corresponding descriptions. We evaluate the model performance via several case studies due to the time limit, and the promising results demonstrated that FinVis-GPT is superior in various financial chart related tasks, including generating descriptions, answering questions and predicting future market trends, surpassing existing state-of-the-art multimodal LLMs. The proposed FinVis-GPT serves as a pioneering effort in utilizing multimodal LLMs in the finance domain and our generated dataset will be release for public use in the near future to speedup related research.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了 FinVis-GPT，一种新型的多Modal大语言模型（LLM），专门用于金融图表分析。通过利用LLM的力量和多Modal特性，FinVis-GPT可以解读金融图表并提供有价值的分析。为了训练FinVis-GPT，我们生成了一个金融任务指向数据集，用于预训练对齐和指令调整，其包括各种金融图表和其对应的描述。我们通过一些案例研究评估了模型性能，结果表明FinVis-GPT在各种金融图表相关任务中表现出色，包括生成描述、回答问题和预测未来市场趋势，超越现有的多Modal LLMs。我们的提出的FinVis-GPT是金融领域中首次利用多Modal LLMs的先河，我们将在近 future中发布生成的数据集，以便加速相关研究。
</details></li>
</ul>
<hr>
<h2 id="A-new-mapping-of-technological-interdependence"><a href="#A-new-mapping-of-technological-interdependence" class="headerlink" title="A new mapping of technological interdependence"></a>A new mapping of technological interdependence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00014">http://arxiv.org/abs/2308.00014</a></li>
<li>repo_url: None</li>
<li>paper_authors: A. Fronzetti Colladon, B. Guardabascio, F. Venturini</li>
<li>for: 本研究旨在探讨技术链接对产业创新能力的影响，以及这些影响如何在技术空间传递。</li>
<li>methods: 本研究使用文本挖掘和网络分析新方法，分析1976-2021年美国专利和商标局（USPTO）授权的650万个专利文本，揭示技术链接的全谱系。</li>
<li>results: 研究发现，专利文本含有许多不被传统创新指标捕捉的信息，如专利引用。网络分析表明，间接链接与直接连接相当重要，而传统间接链接指标，如列 Ontief inverse matrix，仅仅捕捉了一部分间接链接。最后，基于冲击分析，我们示出技术衰退如何在技术空间传递，影响产业创新能力。<details>
<summary>Abstract</summary>
Which technological linkages affect the sector's ability to innovate? How do these effects transmit through the technology space? This paper answers these two key questions using novel methods of text mining and network analysis. We examine technological interdependence across sectors over a period of half a century (from 1976 to 2021) by analyzing the text of 6.5 million patents granted by the United States Patent and Trademark Office (USPTO), and applying network analysis to uncover the full spectrum of linkages existing across technology areas. We demonstrate that patent text contains a wealth of information often not captured by traditional innovation metrics, such as patent citations. By using network analysis, we document that indirect linkages are as important as direct connections and that the former would remain mostly hidden using more traditional measures of indirect linkages, such as the Leontief inverse matrix. Finally, based on an impulse-response analysis, we illustrate how technological shocks transmit through the technology (network-based) space, affecting the innovation capacity of the sectors.
</details>
<details>
<summary>摘要</summary>
<<SYS>>这个文章使用新的文本挖掘和网络分析方法回答了两个关键问题：一是技术链接对产业创新能力产生影响，二是这些影响如何在技术空间传递？我们在1976年至2021年的半个世纪时间内分析了美国专利与商标局（USPTO）授权的650万个专利文本，并通过网络分析揭示出技术领域之间的全谱连接。我们发现专利文本含有许多不被传统创新指标捕捉的信息，例如专利引用。通过网络分析，我们证明了间接链接与直接连接具有相同的重要性，并且前者通常会通过传统的间接链接指标，如Leontief反对矩阵，被遗弃。最后，我们通过冲击回响分析，示出技术冲击如何在技术空间传递，影响产业的创新能力。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="A-Benchmark-for-Understanding-Dialogue-Safety-in-Mental-Health-Support"><a href="#A-Benchmark-for-Understanding-Dialogue-Safety-in-Mental-Health-Support" class="headerlink" title="A Benchmark for Understanding Dialogue Safety in Mental Health Support"></a>A Benchmark for Understanding Dialogue Safety in Mental Health Support</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16457">http://arxiv.org/abs/2307.16457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qiuhuachuan/dialoguesafety">https://github.com/qiuhuachuan/dialoguesafety</a></li>
<li>paper_authors: Huachuan Qiu, Tong Zhao, Anqi Li, Shuai Zhang, Hongliang He, Zhenzhong Lan</li>
<li>For: The paper aims to develop a theoretically and factually grounded taxonomy for analyzing response safety in mental health support, and to create a benchmark corpus with fine-grained labels for each dialogue session.* Methods: The paper uses a zero- and few-shot learning approach with popular language models, including BERT-base, RoBERTa-large, and ChatGPT, to detect and understand unsafe responses within the context of mental health support.* Results: The study reveals that ChatGPT struggles to detect safety categories with detailed safety definitions in a zero- and few-shot paradigm, whereas the fine-tuned model proves to be more suitable. The developed dataset and findings serve as valuable benchmarks for advancing research on dialogue safety in mental health support.<details>
<summary>Abstract</summary>
Dialogue safety remains a pervasive challenge in open-domain human-machine interaction. Existing approaches propose distinctive dialogue safety taxonomies and datasets for detecting explicitly harmful responses. However, these taxonomies may not be suitable for analyzing response safety in mental health support. In real-world interactions, a model response deemed acceptable in casual conversations might have a negligible positive impact on users seeking mental health support. To address these limitations, this paper aims to develop a theoretically and factually grounded taxonomy that prioritizes the positive impact on help-seekers. Additionally, we create a benchmark corpus with fine-grained labels for each dialogue session to facilitate further research. We analyze the dataset using popular language models, including BERT-base, RoBERTa-large, and ChatGPT, to detect and understand unsafe responses within the context of mental health support. Our study reveals that ChatGPT struggles to detect safety categories with detailed safety definitions in a zero- and few-shot paradigm, whereas the fine-tuned model proves to be more suitable. The developed dataset and findings serve as valuable benchmarks for advancing research on dialogue safety in mental health support, with significant implications for improving the design and deployment of conversation agents in real-world applications. We release our code and data here: https://github.com/qiuhuachuan/DialogueSafety.
</details>
<details>
<summary>摘要</summary>
对话安全问题在开放领域人机交互中仍然是一个普遍的挑战。现有的方法提出了不同的对话安全分类和数据集来检测直接危害性的回答。然而，这些分类可能并不适用于分析心理支持中的回答安全性。在实际交互中，一个被认为在互助会话中可以得到积极影响的回答可能并不适用于用户寻求心理支持。为了解决这些限制，本研究旨在开发一个基于理论和实际的对话安全分类，并创建一个具有细化标签的对话会话数据集，以便进一步的研究。我们使用了流行的语言模型，包括BERT-base、RoBERTa-large和ChatGPT，对心理支持中的对话安全进行检测和理解。我们的研究发现，ChatGPT在零和几个shot情况下很难检测安全类别，而精心调整的模型却表现出色。我们开发的数据集和发现将为对话安全在心理支持中的研究提供价值的标准，对实际应用中的对话机器人设计和部署产生重要影响。我们在 GitHub 上发布了代码和数据：https://github.com/qiuhuachuan/DialogueSafety。
</details></li>
</ul>
<hr>
<h2 id="Camoscio-an-Italian-Instruction-tuned-LLaMA"><a href="#Camoscio-an-Italian-Instruction-tuned-LLaMA" class="headerlink" title="Camoscio: an Italian Instruction-tuned LLaMA"></a>Camoscio: an Italian Instruction-tuned LLaMA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16456">http://arxiv.org/abs/2307.16456</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/teelinsan/camoscio">https://github.com/teelinsan/camoscio</a></li>
<li>paper_authors: Andrea Santilli, Emanuele Rodolà</li>
<li>for: 本研究旨在提供一个特定 для意大利语言的语言模型，以便实现该语言的自然语言处理任务。</li>
<li>methods: 本研究使用了LLaMA的最小型别（7b），并通过LoRA进行精细调整，以便在意大利语言下跟随用户的指令。</li>
<li>results: 本研究的结果显示，模型在意大利语言下的零执行性能在各种下游任务中竞争性地与现有特定 для这些任务的模型竞争。<details>
<summary>Abstract</summary>
In recent years Large Language Models (LLMs) have increased the state of the art on several natural language processing tasks. However, their accessibility is often limited to paid API services, posing challenges for researchers in conducting extensive investigations. On the other hand, while some open-source models have been proposed by the community, they are typically multilingual and not specifically tailored for the Italian language. In an effort to democratize the available and open resources for the Italian language, in this paper we introduce Camoscio: a language model specifically tuned to follow users' prompts in Italian. Specifically, we finetuned the smallest variant of LLaMA (7b) with LoRA on a corpus of instruction prompts translated to Italian via ChatGPT. Results indicate that the model's zero-shot performance on various downstream tasks in Italian competes favorably with existing models specifically finetuned for those tasks. All the artifacts (code, dataset, model) are released to the community at the following url: https://github.com/teelinsan/camoscio
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DCTM-Dilated-Convolutional-Transformer-Model-for-Multimodal-Engagement-Estimation-in-Conversation"><a href="#DCTM-Dilated-Convolutional-Transformer-Model-for-Multimodal-Engagement-Estimation-in-Conversation" class="headerlink" title="DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement Estimation in Conversation"></a>DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement Estimation in Conversation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01966">http://arxiv.org/abs/2308.01966</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vu Ngoc Tu, Van Thong Huynh, Hyung-Jeong Yang, M. Zaigham Zaheer, Shah Nawaz, Karthik Nandakumar, Soo-Hyung Kim</li>
<li>for: 本研究的目的是提取对话中人们的互动情况，以获得对人际交流的理解和行为模式的洞察。</li>
<li>methods: 本研究使用了扩展 convolutional Transformer 来模型和估计对话中人们的参与度。我们还使用了不同的模态融合方法，并发现在这种数据上，简单的 concatenated 方法加上自注意融合得到了最好的表现。</li>
<li>results: 我们的提案系统在测试集上比基eline模型高$7%$，在验证集上高$4%$。<details>
<summary>Abstract</summary>
Conversational engagement estimation is posed as a regression problem, entailing the identification of the favorable attention and involvement of the participants in the conversation. This task arises as a crucial pursuit to gain insights into human's interaction dynamics and behavior patterns within a conversation. In this research, we introduce a dilated convolutional Transformer for modeling and estimating human engagement in the MULTIMEDIATE 2023 competition. Our proposed system surpasses the baseline models, exhibiting a noteworthy $7$\% improvement on test set and $4$\% on validation set. Moreover, we employ different modality fusion mechanism and show that for this type of data, a simple concatenated method with self-attention fusion gains the best performance.
</details>
<details>
<summary>摘要</summary>
文本对话参与度估计问题 pose 为回归问题，涉及到参与者在对话中有利的注意力和参与度的识别。这项任务对于了解人类对话动力学和行为模式具有重要意义。在这项研究中，我们提出了一种扩展 convolutional Transformer 来模型和估计对话参与度，并在 MULTIMEDIATE 2023 比赛中提交了我们的提案。我们的提案比基eline模型表现出了显著的 $7\%$ 提高（测试集）和 $4\%$ 提高（验证集）。此外，我们采用了不同的modalities fusion方法，并证明在这类数据上，简单 concatenation 方法配合自我注意力融合可以获得最佳性能。
</details></li>
</ul>
<hr>
<h2 id="SelfSeg-A-Self-supervised-Sub-word-Segmentation-Method-for-Neural-Machine-Translation"><a href="#SelfSeg-A-Self-supervised-Sub-word-Segmentation-Method-for-Neural-Machine-Translation" class="headerlink" title="SelfSeg: A Self-supervised Sub-word Segmentation Method for Neural Machine Translation"></a>SelfSeg: A Self-supervised Sub-word Segmentation Method for Neural Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16400">http://arxiv.org/abs/2307.16400</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyue Song, Raj Dabre, Chenhui Chu, Sadao Kurohashi, Eiichiro Sumita</li>
<li>for: This paper is written for the purpose of proposing a self-supervised neural sub-word segmentation method called SelfSeg, which is faster and more efficient than existing methods.</li>
<li>methods: The paper uses a self-supervised approach that takes as input a word in the form of a partially masked character sequence, optimizes the word generation probability, and generates the segmentation with the maximum posterior probability using a dynamic programming algorithm. The training time of SelfSeg depends on word frequencies, and the paper explores several word frequency normalization strategies to accelerate the training phase.</li>
<li>results: The paper conducts machine translation experiments in low-, middle-, and high-resource scenarios, comparing the performance of different segmentation methods. The results show that SelfSeg achieves significant improvements over existing methods, including BPE and SentencePiece, and the regularization method achieves approximately a 4.3 BLEU score improvement over BPE and a 1.2 BLEU score improvement over BPE-dropout. The paper also observes improvements on several other datasets.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了提出一种自动学习的字符级别分词法，它比现有的方法更快速和高效。</li>
<li>methods: 这篇论文使用了一种自动学习的方法，输入一个部分遮盖的单词，优化单词生成概率，并使用动态规划算法计算最大 posterior probability，生成分词结果。训练时间取决于单词频率，论文探索了多种单词频率normalization策略来加速训练阶段。</li>
<li>results: 论文通过对机器翻译 task进行实验，在低资源、中资源和高资源的场景中比较了不同的分词方法的性能。结果表明，SelfSeg在ALT dataset上获得了1.2 BLEU分数的提升，而与DPE和VOLT相比，增加了约4.3 BLEU分数。论文还发现了其他一些数据集上的显著提升。<details>
<summary>Abstract</summary>
Sub-word segmentation is an essential pre-processing step for Neural Machine Translation (NMT). Existing work has shown that neural sub-word segmenters are better than Byte-Pair Encoding (BPE), however, they are inefficient as they require parallel corpora, days to train and hours to decode. This paper introduces SelfSeg, a self-supervised neural sub-word segmentation method that is much faster to train/decode and requires only monolingual dictionaries instead of parallel corpora. SelfSeg takes as input a word in the form of a partially masked character sequence, optimizes the word generation probability and generates the segmentation with the maximum posterior probability, which is calculated using a dynamic programming algorithm. The training time of SelfSeg depends on word frequencies, and we explore several word frequency normalization strategies to accelerate the training phase. Additionally, we propose a regularization mechanism that allows the segmenter to generate various segmentations for one word. To show the effectiveness of our approach, we conduct MT experiments in low-, middle- and high-resource scenarios, where we compare the performance of using different segmentation methods. The experimental results demonstrate that on the low-resource ALT dataset, our method achieves more than 1.2 BLEU score improvement compared with BPE and SentencePiece, and a 1.1 score improvement over Dynamic Programming Encoding (DPE) and Vocabulary Learning via Optimal Transport (VOLT) on average. The regularization method achieves approximately a 4.3 BLEU score improvement over BPE and a 1.2 BLEU score improvement over BPE-dropout, the regularized version of BPE. We also observed significant improvements on IWSLT15 Vi->En, WMT16 Ro->En and WMT15 Fi->En datasets, and competitive results on the WMT14 De->En and WMT14 Fr->En datasets.
</details>
<details>
<summary>摘要</summary>
它是一种基于神经网络的自动分词方法，可以用于语机翻译（NMT）的前期处理步骤。现有研究表明，神经网络分词器比Byte-Pair Encoding（BPE）更好，但它们需要并行 Corpora 并且训练和解码时间比较长。这篇论文介绍了一种自然语言自动分词法，它叫做SelfSeg，它比较快速地训练和解码，并且只需要单语言词典而不需要并行 Corpora。SelfSeg 接受一个部分遮盖的字符序列作为输入，并且通过计算最大 posterior 概率来生成分词结果。训练 SelfSeg 的时间取决于单词频率，我们也提出了多种单词频率归一化策略来加速训练阶段。此外，我们还提出了一种规范化机制，允许分词器生成不同的分词结果。为证明我们的方法的有效性，我们进行了不同分词方法的MT实验，其中包括 BPE、SentencePiece、DPE 和 VOLT。实验结果表明，在 ALT  dataset 上，我们的方法可以与 BPE 和 SentencePiece 相比，提高了 más de 1.2 BLEU 分数，而与 DPE 和 VOLT 相比，提高了约 1.1 BLEU 分数。规范化机制可以提高 BPE 的约 4.3 BLEU 分数，并且与 BPE-dropout 相比，提高了约 1.2 BLEU 分数。我们还观察到在 IWSLT15 Vi->En、WMT16 Ro->En 和 WMT15 Fi->En 等 dataset 上，我们的方法具有显著的改善，并且在 WMT14 De->En 和 WMT14 Fr->En  dataset 上达到了竞争性的结果。
</details></li>
</ul>
<hr>
<h2 id="Does-fine-tuning-GPT-3-with-the-OpenAI-API-leak-personally-identifiable-information"><a href="#Does-fine-tuning-GPT-3-with-the-OpenAI-API-leak-personally-identifiable-information" class="headerlink" title="Does fine-tuning GPT-3 with the OpenAI API leak personally-identifiable information?"></a>Does fine-tuning GPT-3 with the OpenAI API leak personally-identifiable information?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16382">http://arxiv.org/abs/2307.16382</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/albertsun1/gpt3-pii-attacks">https://github.com/albertsun1/gpt3-pii-attacks</a></li>
<li>paper_authors: Albert Yu Sun, Eliott Zemour, Arushi Saxena, Udith Vaidyanathan, Eric Lin, Christian Lau, Vaikkunth Mugunthan</li>
<li>for: 本研究目的是探讨 GPT-3 模型在 fine-tuning 过程中是否可以提取个人敏感信息 (PII)。</li>
<li>methods: 本研究使用 OpenAI 提供的 fine-tuning API 对 GPT-3 模型进行了模拟攻击，并使用了 naive 提示方法和实际应用中的自动完成任务来调查 GPT-3 是否在 fine-tuning 过程中记忆和泄露敏感信息。</li>
<li>results: 研究发现，对 GPT-3 进行了 fine-tuning 后，模型就可以记忆并泄露来自原始 fine-tuning 数据集中的敏感信息 (PII)。<details>
<summary>Abstract</summary>
Machine learning practitioners often fine-tune generative pre-trained models like GPT-3 to improve model performance at specific tasks. Previous works, however, suggest that fine-tuned machine learning models memorize and emit sensitive information from the original fine-tuning dataset. Companies such as OpenAI offer fine-tuning services for their models, but no prior work has conducted a memorization attack on any closed-source models. In this work, we simulate a privacy attack on GPT-3 using OpenAI's fine-tuning API. Our objective is to determine if personally identifiable information (PII) can be extracted from this model. We (1) explore the use of naive prompting methods on a GPT-3 fine-tuned classification model, and (2) we design a practical word generation task called Autocomplete to investigate the extent of PII memorization in fine-tuned GPT-3 within a real-world context. Our findings reveal that fine-tuning GPT3 for both tasks led to the model memorizing and disclosing critical personally identifiable information (PII) obtained from the underlying fine-tuning dataset. To encourage further research, we have made our codes and datasets publicly available on GitHub at: https://github.com/albertsun1/gpt3-pii-attacks
</details>
<details>
<summary>摘要</summary>
机器学习实践者常常精细调整生成预训练模型，如GPT-3，以提高模型在特定任务上的表现。前一次的研究表明，精细调整的机器学习模型可能会记忆并释出原始精细调整数据中的敏感资讯。如OpenAI提供的精细调整服务，但没有任何前一次的工作对关闭源代码模型进行了记忆攻击。在这个工作中，我们模拟了隐私攻击GPT-3，使用OpenAI的精细调整API。我们的目标是确定GPT-3是否能够从这个模型中提取个人敏感信息（PII）。我们（1）探索使用简单提示方法在GPT-3精细调整分类模型上，并（2）设计了实用的自动完成任务，以探索精细调整GPT-3中PII的记忆情况。我们的发现显示，精细调整GPT-3 для这两个任务都导致模型记忆并释出重要的个人敏感信息（PII），从原始精细调整数据中获取。为了鼓励更多研究，我们将我们的代码和数据公开提供GitHub上：https://github.com/albertsun1/gpt3-pii-attacks。
</details></li>
</ul>
<hr>
<h2 id="Distractor-generation-for-multiple-choice-questions-with-predictive-prompting-and-large-language-models"><a href="#Distractor-generation-for-multiple-choice-questions-with-predictive-prompting-and-large-language-models" class="headerlink" title="Distractor generation for multiple-choice questions with predictive prompting and large language models"></a>Distractor generation for multiple-choice questions with predictive prompting and large language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16338">http://arxiv.org/abs/2307.16338</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/semerekiros/distractgpt">https://github.com/semerekiros/distractgpt</a></li>
<li>paper_authors: Semere Kiros Bitew, Johannes Deleu, Chris Develder, Thomas Demeester</li>
<li>for: 本研究旨在提高 chatGPT 等大型自然语言模型在多项选择题 (MCQ) 中生成干扰符的性能。</li>
<li>methods: 我们提出了一种使用问题库中自动检索的问题项作为准确的示例来引导 chatGPT 生成相关的干扰符的策略。</li>
<li>results: 我们的方法在已有测试集上进行量化评估以及人工专家（教师）的质量注释中表现出色，平均53%的生成干扰符被教师评为高质量，超过当前最佳模型。 我们还比较了我们的方法与零极 chatGPT 和几个示例激活 chatGPT 的性能，并证明了我们的方法在生成高质量干扰符方面的优势。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) such as ChatGPT have demonstrated remarkable performance across various tasks and have garnered significant attention from both researchers and practitioners. However, in an educational context, we still observe a performance gap in generating distractors -- i.e., plausible yet incorrect answers -- with LLMs for multiple-choice questions (MCQs). In this study, we propose a strategy for guiding LLMs such as ChatGPT, in generating relevant distractors by prompting them with question items automatically retrieved from a question bank as well-chosen in-context examples. We evaluate our LLM-based solutions using a quantitative assessment on an existing test set, as well as through quality annotations by human experts, i.e., teachers. We found that on average 53% of the generated distractors presented to the teachers were rated as high-quality, i.e., suitable for immediate use as is, outperforming the state-of-the-art model. We also show the gains of our approach 1 in generating high-quality distractors by comparing it with a zero-shot ChatGPT and a few-shot ChatGPT prompted with static examples.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如ChatGPT已经表现出了在不同任务上的出色表现，引起了研究者和实践者的广泛关注。然而，在教育上，我们仍然观察到LLM在生成诱导者（i.e., 可能correct但不正确的答案）方面存在性能差距。在这项研究中，我们提出了一种策略，使LLM通过自动从问题库中提取问题项来生成相关的诱导者。我们使用现有测试集进行了量化评估，以及通过人工智能专家（i.e., 教师）的质量标注来评估。我们发现，平均 speaking 53%的生成诱导者被教师评估为高质量，可以不需要更改，超越了现有的模型。我们还显示了我们的方法在生成高质量诱导者方面的优势，与零极 chatGPT 和几个极少shot chatGPT 提交的静止示例相比。
</details></li>
</ul>
<hr>
<h2 id="Mispronunciation-detection-using-self-supervised-speech-representations"><a href="#Mispronunciation-detection-using-self-supervised-speech-representations" class="headerlink" title="Mispronunciation detection using self-supervised speech representations"></a>Mispronunciation detection using self-supervised speech representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16324">http://arxiv.org/abs/2307.16324</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JazminVidal/ssl-mispron">https://github.com/JazminVidal/ssl-mispron</a></li>
<li>paper_authors: Jazmin Vidal, Pablo Riera, Luciana Ferrer</li>
<li>for: 本研究探讨了使用自动学习模型（SSL）进行外语学习者的发音识别任务。</li>
<li>methods: 我们比较了两种下游方法：1）使用本地英语数据进行话音识别（PR）模型训练，2）直接使用非本地英语数据进行目标任务模型训练。我们对各种SSL表示形式以及一个来自传统的DNN基于语音识别模型的表示形式进行比较。</li>
<li>results: 我们发现使用下游模型直接进行目标任务训练得到最好的性能，而大多数上游模型在这个任务上表现相似。<details>
<summary>Abstract</summary>
In recent years, self-supervised learning (SSL) models have produced promising results in a variety of speech-processing tasks, especially in contexts of data scarcity. In this paper, we study the use of SSL models for the task of mispronunciation detection for second language learners. We compare two downstream approaches: 1) training the model for phone recognition (PR) using native English data, and 2) training a model directly for the target task using non-native English data. We compare the performance of these two approaches for various SSL representations as well as a representation extracted from a traditional DNN-based speech recognition model. We evaluate the models on L2Arctic and EpaDB, two datasets of non-native speech annotated with pronunciation labels at the phone level. Overall, we find that using a downstream model trained for the target task gives the best performance and that most upstream models perform similarly for the task.
</details>
<details>
<summary>摘要</summary>
近年来，自我超vised学习（SSL）模型在各种语音处理任务中表现出色，特别是在数据缺乏的情况下。本文研究了使用SSL模型进行第二语言学习者的误发音检测。我们比较了两种下游方法：1）使用本地英语数据进行话语识别（PR）模型的训练，和2）直接使用非本地英语数据进行目标任务的模型训练。我们对各种SSL表示形式以及一种基于传统DNN语音识别模型中的表示进行比较。我们对L2Arctic和EpaDB两个非本地语音 datasets进行评估。总的来说，我们发现使用下游模型直接进行目标任务的训练可以获得最好的性能，而大多数上游模型在这个任务上的表现相似。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/31/cs.CL_2023_07_31/" data-id="clpxp6bya009hee8823ethl45" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/76/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/75/">75</a><a class="page-number" href="/page/76/">76</a><span class="page-number current">77</span><a class="page-number" href="/page/78/">78</a><a class="page-number" href="/page/79/">79</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/78/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
