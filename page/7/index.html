
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/7/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.LG_2023_11_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/12/cs.LG_2023_11_12/" class="article-date">
  <time datetime="2023-11-12T10:00:00.000Z" itemprop="datePublished">2023-11-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/12/cs.LG_2023_11_12/">cs.LG - 2023-11-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Analytical-Verification-of-Deep-Neural-Network-Performance-for-Time-Synchronized-Distribution-System-State-Estimation"><a href="#Analytical-Verification-of-Deep-Neural-Network-Performance-for-Time-Synchronized-Distribution-System-State-Estimation" class="headerlink" title="Analytical Verification of Deep Neural Network Performance for Time-Synchronized Distribution System State Estimation"></a>Analytical Verification of Deep Neural Network Performance for Time-Synchronized Distribution System State Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06973">http://arxiv.org/abs/2311.06973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Behrouz Azimian, Shiva Moshtagh, Anamitra Pal, Shanshan Ma</li>
<li>for: 本文提出了一种使用深度神经网络（DNN）实现实时不可见分布系统状态估计的方法，并提供了对这种方法的性能分析。</li>
<li>methods: 本文使用了深度神经网络来解决实时不可见分布系统状态估计问题，并对输入偏差的影响进行分析。</li>
<li>results: 本文通过对模拟数据集和实际系统数据进行比较，证明了深度神经网络在输入偏差下的Robustness和可靠性。同时，本文也发现批量正常化可以有效地解决了MILP形式中的缺点。<details>
<summary>Abstract</summary>
Recently, we demonstrated success of a time-synchronized state estimator using deep neural networks (DNNs) for real-time unobservable distribution systems. In this letter, we provide analytical bounds on the performance of that state estimator as a function of perturbations in the input measurements. It has already been shown that evaluating performance based on only the test dataset might not effectively indicate a trained DNN's ability to handle input perturbations. As such, we analytically verify robustness and trustworthiness of DNNs to input perturbations by treating them as mixed-integer linear programming (MILP) problems. The ability of batch normalization in addressing the scalability limitations of the MILP formulation is also highlighted. The framework is validated by performing time-synchronized distribution system state estimation for a modified IEEE 34-node system and a real-world large distribution system, both of which are incompletely observed by micro-phasor measurement units.
</details>
<details>
<summary>摘要</summary>
最近，我们已经成功地使用深度神经网络（DNN）来实时估计不可见分布系统的状态。在这封信中，我们提供了对状态估计器的性能进行分析的下限。已经证明了只 judging 基于训练集不能准确地评估已经训练好的 DNN 对输入干扰的能力。因此，我们使用混合整数线性程序（MILP）问题来验证 DNN 对输入干扰的Robustness和可靠性。我们还 highlighted 批处理normalization 的缩放性限制，并在批处理normalization 下进行了性能验证。我们的框架在一个修改过 IEEE 34 节点系统和一个实际大型分布系统中进行了时同步分布系统状态估计，两个系统都是通过微phasor测量单元不完全观察的。
</details></li>
</ul>
<hr>
<h2 id="An-Expandable-Machine-Learning-Optimization-Framework-to-Sequential-Decision-Making"><a href="#An-Expandable-Machine-Learning-Optimization-Framework-to-Sequential-Decision-Making" class="headerlink" title="An Expandable Machine Learning-Optimization Framework to Sequential Decision-Making"></a>An Expandable Machine Learning-Optimization Framework to Sequential Decision-Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06972">http://arxiv.org/abs/2311.06972</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dogacan Yilmaz, İ. Esra Büyüktahtakın</li>
<li>for: 解决sequential decision-making问题，提高machine learning（ML）预测的可行性和泛化能力。</li>
<li>methods:  integrate attention-based encoder-decoder neural network architecture with infeasibility-elimination和generalization framework，并Optimize the required level of predictions to eliminate the infeasibility of the ML predictions。</li>
<li>results: 可以快速解决time-dependent optimization问题，并且可以降低solution time by three orders of magnitude，average optimality gap below 0.1%。 Comparing with various specially designed heuristics, PredOpt outperforms them.<details>
<summary>Abstract</summary>
We present an integrated prediction-optimization (PredOpt) framework to efficiently solve sequential decision-making problems by predicting the values of binary decision variables in an optimal solution. We address the key issues of sequential dependence, infeasibility, and generalization in machine learning (ML) to make predictions for optimal solutions to combinatorial problems. The sequential nature of the combinatorial optimization problems considered is captured with recurrent neural networks and a sliding-attention window. We integrate an attention-based encoder-decoder neural network architecture with an infeasibility-elimination and generalization framework to learn high-quality feasible solutions to time-dependent optimization problems. In this framework, the required level of predictions is optimized to eliminate the infeasibility of the ML predictions. These predictions are then fixed in mixed-integer programming (MIP) problems to solve them quickly with the aid of a commercial solver. We demonstrate our approach to tackling the two well-known dynamic NP-Hard optimization problems: multi-item capacitated lot-sizing (MCLSP) and multi-dimensional knapsack (MSMK). Our results show that models trained on shorter and smaller-dimensional instances can be successfully used to predict longer and larger-dimensional problems. The solution time can be reduced by three orders of magnitude with an average optimality gap below 0.1%. We compare PredOpt with various specially designed heuristics and show that our framework outperforms them. PredOpt can be advantageous for solving dynamic MIP problems that need to be solved instantly and repetitively.
</details>
<details>
<summary>摘要</summary>
我们提出了一个集成预测优化（PredOpt）框架，用于高效解决顺序决策问题，预测二进制决策变量的价值在优质解决方案中。我们解决了机器学习（ML）中的顺序依赖、不可实现性和泛化问题，以使ML预测可以为优质解决方案提供高质量的预测。我们使用循环神经网络和滑块注意力窗口捕捉顺序优化问题的特点。我们将注意力基本网络和不可实现性和泛化框架结合在一起，以学习高质量的可行解决方案。在这个框架中，ML预测的需要级别被优化，以消除ML预测中的不可实现性。这些预测然后被ixed在混合整数编程（MIP）问题中，通过商业解决器快速解决。我们利用PredOpt解决了多项目资源配置问题（MCLSP）和多维度饼干问题（MSMK）。我们的结果显示，可以使用较短和更小的实例来训练模型，并且这些模型可以成功预测更长和更大的问题。我们的解决方案比特制的各种优化策略更高效，并且可以降低解决时间三个数量级，average optimality gap在0.1%以下。我们与其他专门设计的各种优化策略进行比较，并证明PredOpt可以在实时和重复地解决动态MIP问题中具有优势。
</details></li>
</ul>
<hr>
<h2 id="Anchor-Data-Augmentation"><a href="#Anchor-Data-Augmentation" class="headerlink" title="Anchor Data Augmentation"></a>Anchor Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06965">http://arxiv.org/abs/2311.06965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nora Schneider, Shirin Goshtasbpour, Fernando Perez-Cruz</li>
<li>for: 提高非线性过参数回归的数据增强方法</li>
<li>methods: 基于 causality 文献的 Anchor regression (AR) 方法，使用多个修改后的样本来提供更多训练例子，提高回归预测的Robustness。</li>
<li>results: ADA 在线性和非线性回归问题中表现与当前领域无关的 Mixup 解决方案竞争。<details>
<summary>Abstract</summary>
We propose a novel algorithm for data augmentation in nonlinear over-parametrized regression. Our data augmentation algorithm borrows from the literature on causality and extends the recently proposed Anchor regression (AR) method for data augmentation, which is in contrast to the current state-of-the-art domain-agnostic solutions that rely on the Mixup literature. Our Anchor Data Augmentation (ADA) uses several replicas of the modified samples in AR to provide more training examples, leading to more robust regression predictions. We apply ADA to linear and nonlinear regression problems using neural networks. ADA is competitive with state-of-the-art C-Mixup solutions.
</details>
<details>
<summary>摘要</summary>
我们提出一种新的数据扩充算法，用于非线性过参数化回归。我们的数据扩充算法从 causality  литературе借鉴，并对最近提出的 Anchor regression（AR）方法进行扩展，而不是现有的领域不依然的 Mixup 解决方案。我们的 Anchor Data Augmentation（ADA）使用多个修改后的样本来提供更多的训练示例，从而导致更加稳定的回归预测。我们在线性和非线性回归问题中应用 ADA，并与当前领域最佳的 C-Mixup 解决方案竞争。
</details></li>
</ul>
<hr>
<h2 id="Robust-Regression-over-Averaged-Uncertainty"><a href="#Robust-Regression-over-Averaged-Uncertainty" class="headerlink" title="Robust Regression over Averaged Uncertainty"></a>Robust Regression over Averaged Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06960">http://arxiv.org/abs/2311.06960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitris Bertsimas, Yu Ma</li>
<li>for: 本文提出了一种新的稳健回归方法，通过综合所有实现集来获得最佳解决方案 для常规最小二乘回归问题。</li>
<li>methods: 本文使用了一种averaged approach来处理uncertainty set，并证明了这种方法可以回归ridge回归和确定了exististing回归问题的mean squared error和robust optimization之间的联系。</li>
<li>results: 本文在synthetic数据集和实际世界回归问题中显示了一个consistent improvement，并且与干扰水平增加时，提高的速度也随着干扰水平增加。<details>
<summary>Abstract</summary>
We propose a new formulation of robust regression by integrating all realizations of the uncertainty set and taking an averaged approach to obtain the optimal solution for the ordinary least-squared regression problem. We show that this formulation surprisingly recovers ridge regression and establishes the missing link between robust optimization and the mean squared error approaches for existing regression problems. We first prove the equivalence for four uncertainty sets: ellipsoidal, box, diamond, and budget, and provide closed-form formulations of the penalty term as a function of the sample size, feature size, as well as perturbation protection strength. We then show in synthetic datasets with different levels of perturbations, a consistent improvement of the averaged formulation over the existing worst-case formulation in out-of-sample performance. Importantly, as the perturbation level increases, the improvement increases, confirming our method's advantage in high-noise environments. We report similar improvements in the out-of-sample datasets in real-world regression problems obtained from UCI datasets.
</details>
<details>
<summary>摘要</summary>
We prove the equivalence of our method for four types of uncertainty sets: ellipsoidal, box, diamond, and budget. We also provide closed-form expressions for the penalty term as a function of sample size, feature size, and perturbation protection strength.In synthetic datasets with different levels of perturbations, our method consistently outperforms the traditional worst-case formulation in out-of-sample performance. As the perturbation level increases, the improvement also increases, demonstrating the advantage of our method in high-noise environments. We observe similar improvements in real-world regression problems obtained from UCI datasets.
</details></li>
</ul>
<hr>
<h2 id="A-GPU-Accelerated-Moving-Horizon-Algorithm-for-Training-Deep-Classification-Trees-on-Large-Datasets"><a href="#A-GPU-Accelerated-Moving-Horizon-Algorithm-for-Training-Deep-Classification-Trees-on-Large-Datasets" class="headerlink" title="A GPU-Accelerated Moving-Horizon Algorithm for Training Deep Classification Trees on Large Datasets"></a>A GPU-Accelerated Moving-Horizon Algorithm for Training Deep Classification Trees on Large Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06952">http://arxiv.org/abs/2311.06952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayang Ren, Valentín Osuna-Enciso, Morimasa Okamoto, Qiangqiang Mao, Chaojie Ji, Liang Cao, Kaixun Hua, Yankai Cao</li>
<li>for: 本文主要针对决策树的训练受限于NP-完备性和各种各样的特性，并提出了一种基于移动观察点的 diferencial evolution算法来解决这些问题。</li>
<li>methods: 本文提出了一种基于GPU加速和搜索优化的移动观察点差分演化算法（MH-DEOCT），包括离散树解码方法、GPU加速实现和移动观察点策略。</li>
<li>results: 对于68个UCI数据集，MH-DEOCT方法与CART方法相比，平均提高了训练和测试准确率3.44%和1.71%，并且在深树和大规模数据集中实现了很好的扩展性。<details>
<summary>Abstract</summary>
Decision trees are essential yet NP-complete to train, prompting the widespread use of heuristic methods such as CART, which suffers from sub-optimal performance due to its greedy nature. Recently, breakthroughs in finding optimal decision trees have emerged; however, these methods still face significant computational costs and struggle with continuous features in large-scale datasets and deep trees. To address these limitations, we introduce a moving-horizon differential evolution algorithm for classification trees with continuous features (MH-DEOCT). Our approach consists of a discrete tree decoding method that eliminates duplicated searches between adjacent samples, a GPU-accelerated implementation that significantly reduces running time, and a moving-horizon strategy that iteratively trains shallow subtrees at each node to balance the vision and optimizer capability. Comprehensive studies on 68 UCI datasets demonstrate that our approach outperforms the heuristic method CART on training and testing accuracy by an average of 3.44% and 1.71%, respectively. Moreover, these numerical studies empirically demonstrate that MH-DEOCT achieves near-optimal performance (only 0.38% and 0.06% worse than the global optimal method on training and testing, respectively), while it offers remarkable scalability for deep trees (e.g., depth=8) and large-scale datasets (e.g., ten million samples).
</details>
<details>
<summary>摘要</summary>
决策树是必备的，但是训练NP-完整的，导致广泛使用各种各样的规则来缺省性能。最近，对于寻找优化决策树的突破发展出现了，但这些方法仍然面临巨大的计算成本和深度大的树结构。为了解决这些限制，我们介绍了一种基于移动观察点的 diferencial evolution算法 для分类树（MH-DEOCT）。我们的方法包括一种离散树解码方法，消除邻近样本之间的重复搜索，一种GPU加速的实现，以及一种移动观察点策略，在每个节点训练 shallow 树以平衡视觉和优化能力。我们对68个UCI数据集进行了完整的实验研究，显示我们的方法在训练和测试精度上比CART方法高出3.44%和1.71%， respectively。此外，这些数字实验也证明了MH-DEOCT方法在训练和测试精度上几乎达到了最佳性能（只比全球最佳方法在训练和测试精度上低出0.38%和0.06%），而且它在深度大的树结构和大规模数据集（例如，一千万个样本）中表现出了很好的可扩展性。
</details></li>
</ul>
<hr>
<h2 id="Contractive-Systems-Improve-Graph-Neural-Networks-Against-Adversarial-Attacks"><a href="#Contractive-Systems-Improve-Graph-Neural-Networks-Against-Adversarial-Attacks" class="headerlink" title="Contractive Systems Improve Graph Neural Networks Against Adversarial Attacks"></a>Contractive Systems Improve Graph Neural Networks Against Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06942">http://arxiv.org/abs/2311.06942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moshe Eliasof, Davide Murari, Ferdia Sherry, Carola-Bibiane Schönlieb</li>
<li>for: 强化Graph Neural Networks（GNNs）对抗黑客攻击</li>
<li>methods: 基于减法动态系统的图神经网络层，同时学习节点特征和图连接矩阵的演化，提高模型对输入特征和图结构的Robustness</li>
<li>results: 通过许多实验示范，与现有方法相比，提高或与之相当的性能<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have established themselves as a key component in addressing diverse graph-based tasks. Despite their notable successes, GNNs remain susceptible to input perturbations in the form of adversarial attacks. This paper introduces an innovative approach to fortify GNNs against adversarial perturbations through the lens of contractive dynamical systems. Our method introduces graph neural layers based on differential equations with contractive properties, which, as we show, improve the robustness of GNNs. A distinctive feature of the proposed approach is the simultaneous learned evolution of both the node features and the adjacency matrix, yielding an intrinsic enhancement of model robustness to perturbations in the input features and the connectivity of the graph. We mathematically derive the underpinnings of our novel architecture and provide theoretical insights to reason about its expected behavior. We demonstrate the efficacy of our method through numerous real-world benchmarks, reading on par or improved performance compared to existing methods.
</details>
<details>
<summary>摘要</summary>
图 neural network (GNN) 已成为许多图像任务的关键组件。尽管它们具有显著的成功，但 GNN 仍然易受输入抗干扰的影响。这篇论文介绍了一种创新的方法，通过对 GNN 进行启发式动力系统的扩展，提高其对抗干扰的 robustness。我们的方法基于差分方程，并且通过对节点特征和邻接矩阵的同时学习，实现了图像模型的自适应性。我们 математичеamente derivation 了我们的新架构的基础，并提供了理论上的理解，以便理解我们的方法的预期行为。我们通过多个实际 benchmark 证明了我们的方法的有效性，与现有方法相比，表现了类似或更好的性能。
</details></li>
</ul>
<hr>
<h2 id="5G-Networks-and-IoT-Devices-Mitigating-DDoS-Attacks-with-Deep-Learning-Techniques"><a href="#5G-Networks-and-IoT-Devices-Mitigating-DDoS-Attacks-with-Deep-Learning-Techniques" class="headerlink" title="5G Networks and IoT Devices: Mitigating DDoS Attacks with Deep Learning Techniques"></a>5G Networks and IoT Devices: Mitigating DDoS Attacks with Deep Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06938">http://arxiv.org/abs/2311.06938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reem M. Alzhrani, Mohammed A. Alliheedi</li>
<li>For: 这项研究旨在应对互联网物联网（IoT）设备的安全性和隐私问题，特别是在5G网络中。* Methods: 该研究使用了深度学习技术，包括卷积神经网络（CNN）和Feed Forward神经网络（FNN），对iot设备在5G网络中的数据进行分析和识别。* Results: 研究发现，使用深度学习技术可以准确地识别normal网络流量和DDos攻击，CNN和FNN两种算法均达到了99%的准确率。这些结果表明深度学习可以提高IoT设备在5G网络中的安全性。<details>
<summary>Abstract</summary>
The development and implementation of Internet of Things (IoT) devices have been accelerated dramatically in recent years. As a result, a super-network is required to handle the massive volumes of data collected and transmitted to these devices. Fifth generation (5G) technology is a new, comprehensive wireless technology that has the potential to be the primary enabling technology for the IoT. The rapid spread of IoT devices can encounter many security limits and concerns. As a result, new and serious security and privacy risks have emerged. Attackers use IoT devices to launch massive attacks; one of the most famous is the Distributed Denial of Service (DDoS) attack. Deep Learning techniques have proven their effectiveness in detecting and mitigating DDoS attacks. In this paper, we applied two Deep Learning algorithms Convolutional Neural Network (CNN) and Feed Forward Neural Network (FNN) in dataset was specifically designed for IoT devices within 5G networks. We constructed the 5G network infrastructure using OMNeT++ with the INET and Simu5G frameworks. The dataset encompasses both normal network traffic and DDoS attacks. The Deep Learning algorithms, CNN and FNN, showed impressive accuracy levels, both reaching 99%. These results underscore the potential of Deep Learning to enhance the security of IoT devices within 5G networks.
</details>
<details>
<summary>摘要</summary>
“现在的互联网发展趋势很快，因此需要一个超级网络来处理大量的数据和传输到这些设备。第五代（5G）技术是一种新的、全面的无线技术，它有可能成为互联网的主要启动技术。随着互联网设备的快速普及，新的安全和隐私问题也在不断产生。攻击者使用互联网设备发动大规模攻击，其中最著名的是分布式拒绝服务（DDoS）攻击。深度学习技术在检测和解决DDoS攻击方面表现出色，在本文中，我们将运用深度学习算法Convolutional Neural Network（CNN）和Feed Forward Neural Network（FNN），在特定的互联网5G网络中进行测试。我们使用OMNeT++架构，并使用INET和Simu5G框架建立5G网络基础设施。资料集包括正常网络流量和DDoS攻击。深度学习算法CNN和FNN在资料集中表现出色，精度分别达到99%。这些结果显示深度学习在5G网络中增强互联网设备的安全性具有潜力。”
</details></li>
</ul>
<hr>
<h2 id="Attention-for-Causal-Relationship-Discovery-from-Biological-Neural-Dynamics"><a href="#Attention-for-Causal-Relationship-Discovery-from-Biological-Neural-Dynamics" class="headerlink" title="Attention for Causal Relationship Discovery from Biological Neural Dynamics"></a>Attention for Causal Relationship Discovery from Biological Neural Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06928">http://arxiv.org/abs/2311.06928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyu Lu, Anika Tabassum, Shruti Kulkarni, Lu Mi, J. Nathan Kutz, Eric Shea-Brown, Seung-Hwan Lim</li>
<li>for: 这 paper 探讨了使用 transformer 模型来学习 neural network 中每个节点的 Granger causality，以获得更好的 causal representation learning。</li>
<li>methods: 这 paper 使用 simulated neural dynamics 进行证明，并通过 cross attention module 来捕捉 neuron 之间的 causal relationship，其准确率与 Granger causality analysis 方法相当或更高。</li>
<li>results: 这 paper 的研究表明，transformer 模型可以有效地捕捉 neural network 中每个节点的 causal relationship，并且可以与 Granger causality analysis 方法相当或更高的准确率。<details>
<summary>Abstract</summary>
This paper explores the potential of the transformer models for learning Granger causality in networks with complex nonlinear dynamics at every node, as in neurobiological and biophysical networks. Our study primarily focuses on a proof-of-concept investigation based on simulated neural dynamics, for which the ground-truth causality is known through the underlying connectivity matrix. For transformer models trained to forecast neuronal population dynamics, we show that the cross attention module effectively captures the causal relationship among neurons, with an accuracy equal or superior to that for the most popular Granger causality analysis method. While we acknowledge that real-world neurobiology data will bring further challenges, including dynamic connectivity and unobserved variability, this research offers an encouraging preliminary glimpse into the utility of the transformer model for causal representation learning in neuroscience.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这篇论文探讨了转换器模型在具有复杂非线性动态的网络中学习格兰格 causality的潜力，例如 neuroscience 和生物物理网络。我们的研究主要集中在基于模拟神经动力学的证明性研究上，其中的 causality 是通过连接矩阵获知的。对于基于神经动力学预测的 transformer 模型，我们显示了 cross attention 模块能够有效地捕捉神经之间的 causal 关系，准确率与最受欢迎的格兰格 causality 分析方法相当或更高。虽然我们认为实际的 neuroscience 数据会带来更多的挑战，包括动态连接和隐藏变量，但这种研究提供了encouraging 的初步预览，表明 transformer 模型在 neuroscience 中的 causal 表示学习具有潜力。
</details></li>
</ul>
<hr>
<h2 id="Concept-Matching-Clustering-based-Federated-Continual-Learning"><a href="#Concept-Matching-Clustering-based-Federated-Continual-Learning" class="headerlink" title="Concept Matching: Clustering-based Federated Continual Learning"></a>Concept Matching: Clustering-based Federated Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06921">http://arxiv.org/abs/2311.06921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaopeng Jiang, Cristian Borcea</li>
<li>for: 本研究旨在解决联合学习（FL）和继续学习（CL）的问题，提高模型准确率。</li>
<li>methods: 提出了一种基于归一化的概念匹配（CM）框架，通过将客户端模型分组到概念模型集中，然后在不同时间点建立不同概念的全局模型，以避免泄漏性学习和客户端模型之间的干扰。</li>
<li>results: 证明了CM比状态艺术系统表现更好，并可扩展到不同的归一化、汇集和匹配算法。<details>
<summary>Abstract</summary>
Federated Continual Learning (FCL) has emerged as a promising paradigm that combines Federated Learning (FL) and Continual Learning (CL). To achieve good model accuracy, FCL needs to tackle catastrophic forgetting due to concept drift over time in CL, and to overcome the potential interference among clients in FL. We propose Concept Matching (CM), a clustering-based framework for FCL to address these challenges. The CM framework groups the client models into concept model clusters, and then builds different global models to capture different concepts in FL over time. In each round, the server sends the global concept models to the clients. To avoid catastrophic forgetting, each client selects the concept model best-matching the concept of the current data for further fine-tuning. To avoid interference among client models with different concepts, the server clusters the models representing the same concept, aggregates the model weights in each cluster, and updates the global concept model with the cluster model of the same concept. Since the server does not know the concepts captured by the aggregated cluster models, we propose a novel server concept matching algorithm that effectively updates a global concept model with a matching cluster model. The CM framework provides flexibility to use different clustering, aggregation, and concept matching algorithms. The evaluation demonstrates that CM outperforms state-of-the-art systems and scales well with the number of clients and the model size.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Resource-Aware-Hierarchical-Federated-Learning-for-Video-Caching-in-Wireless-Networks"><a href="#Resource-Aware-Hierarchical-Federated-Learning-for-Video-Caching-in-Wireless-Networks" class="headerlink" title="Resource-Aware Hierarchical Federated Learning for Video Caching in Wireless Networks"></a>Resource-Aware Hierarchical Federated Learning for Video Caching in Wireless Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06918">http://arxiv.org/abs/2311.06918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Ferdous Pervej, Andreas F Molisch</li>
<li>for: 避免回хай路塞车的压力，提高网络性能</li>
<li>methods: 使用资源意识的联邦学习方法（RawHFL）估算用户未来的内容请求</li>
<li>results: 比基eline的方法表现出更高的预测精度和总能耗Here’s the translation in Simplified Chinese:</li>
<li>for: 减轻回хай路塞车的压力，提高网络性能</li>
<li>methods: 使用资源意识的联邦学习方法（RawHFL）预测用户未来的内容请求</li>
<li>results: 比基线的方法表现出更高的预测精度和总能耗<details>
<summary>Abstract</summary>
Video caching can significantly improve backhaul traffic congestion by locally storing the popular content that users frequently request. A privacy-preserving method is desirable to learn how users' demands change over time. As such, this paper proposes a novel resource-aware hierarchical federated learning (RawHFL) solution to predict users' future content requests under the realistic assumptions that content requests are sporadic and users' datasets can only be updated based on the requested content's information. Considering a partial client participation case, we first derive the upper bound of the global gradient norm that depends on the clients' local training rounds and the successful reception of their accumulated gradients over the wireless links. Under delay, energy and radio resource constraints, we then optimize client selection and their local rounds and central processing unit (CPU) frequencies to minimize a weighted utility function that facilitates RawHFL's convergence in an energy-efficient way. Our simulation results show that the proposed solution significantly outperforms the considered baselines in terms of prediction accuracy and total energy expenditure.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用视频缓存可以大幅提高后向压力堵塞，通过地方存储用户经常请求的受欢迎内容。一种遵守隐私的方法是需要了解用户的需求变化。因此，这篇论文提出了一种基于资源意识的归纳 Federated learning（RawHFL）解决方案，以预测用户未来的内容请求。assuming that content requests are sporadic and users' datasets can only be updated based on the requested content's information.首先，我们 derive the upper bound of the global gradient norm that depends on the clients' local training rounds and the successful reception of their accumulated gradients over the wireless links.然后，我们在延迟、能量和无线链接的限制下优化客户选择和他们的本地循环数和中央处理器（CPU）频率，以最小化一个权重函数，以便 RawHFL 在能效的方式进行归纳。我们的 simulation 结果表明，提出的解决方案significantly outperforms the considered baselines in terms of prediction accuracy and total energy expenditure.(Note: Please note that the translation is in Simplified Chinese, and the grammar and sentence structure may be different from the original text.)
</details></li>
</ul>
<hr>
<h2 id="EPIM-Efficient-Processing-In-Memory-Accelerators-based-on-Epitome"><a href="#EPIM-Efficient-Processing-In-Memory-Accelerators-based-on-Epitome" class="headerlink" title="EPIM: Efficient Processing-In-Memory Accelerators based on Epitome"></a>EPIM: Efficient Processing-In-Memory Accelerators based on Epitome</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07620">http://arxiv.org/abs/2311.07620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyu Wang, Zhen Dong, Daquan Zhou, Zhenhua Zhu, Yu Wang, Jiashi Feng, Kurt Keutzer</li>
<li>for: 这篇论文旨在探讨如何在Processing-In-Memory（PIM）加速器上实现大规模神经网络，并解决由于PIM加速器的内存容量限制所带来的挑战。</li>
<li>methods: 本论文使用了模型压缩算法来缩小对应encephalographic Neural Networks（CNNs）的大小，并提出了一种名为Epitome的轻量级神经操作，以实现PIM加速器上的内存效率。在软件方面，我们评估了epitome的延迟和能源消耗PIM加速器上，并提出了一种PIM应用层次设计方法来提高硬件效率。在硬件方面，我们修改了现有PIM加速器的资料道路来适应epitome，并实现了图像重复技术来降低computation成本。</li>
<li>results: 我们的32位量化EPIM-ResNet50在ImageNet上取得71.59%的顶部1精度，比前一代压缩方法在PIM上更高。EPIM超过了现有的删除方法在PIM上。<details>
<summary>Abstract</summary>
The exploration of Processing-In-Memory (PIM) accelerators has garnered significant attention within the research community. However, the utilization of large-scale neural networks on Processing-In-Memory (PIM) accelerators encounters challenges due to constrained on-chip memory capacity. To tackle this issue, current works explore model compression algorithms to reduce the size of Convolutional Neural Networks (CNNs). Most of these algorithms either aim to represent neural operators with reduced-size parameters (e.g., quantization) or search for the best combinations of neural operators (e.g., neural architecture search). Designing neural operators to align with PIM accelerators' specifications is an area that warrants further study. In this paper, we introduce the Epitome, a lightweight neural operator offering convolution-like functionality, to craft memory-efficient CNN operators for PIM accelerators (EPIM). On the software side, we evaluate epitomes' latency and energy on PIM accelerators and introduce a PIM-aware layer-wise design method to enhance their hardware efficiency. We apply epitome-aware quantization to further reduce the size of epitomes. On the hardware side, we modify the datapath of current PIM accelerators to accommodate epitomes and implement a feature map reuse technique to reduce computation cost. Experimental results reveal that our 3-bit quantized EPIM-ResNet50 attains 71.59% top-1 accuracy on ImageNet, reducing crossbar areas by 30.65 times. EPIM surpasses the state-of-the-art pruning methods on PIM.
</details>
<details>
<summary>摘要</summary>
研究人员对处理在内存（PIM）加速器的探索已经吸引了广泛的关注。然而，使用大规模神经网络（CNN）在PIM加速器上遇到了问题，因为内存容量的限制。为解决这个问题，当前的研究主要探讨模型压缩算法，以减少神经网络中参数的大小。大多数这些算法都是通过压缩神经网络中的参数来减少神经网络的大小。然而，设计神经网络操作符符合PIM加速器的特点是一个需要更多研究的领域。在这篇论文中，我们介绍了一种轻量级的神经操作符，即Epitome，以实现内存有效的CNN操作符。在软件端，我们评估了epitome在PIM加速器上的响应时间和能耗，并提出了一种针对PIM加速器的层次设计方法，以提高硬件效率。在硬件端，我们修改了现有PIM加速器的数据路径，以便使用epitome，并实现了特征图 reuse技术，以减少计算成本。实验结果表明，我们的3比特量化的EPIM-ResNet50在ImageNet上达到了71.59%的前1 accuracy，相比之下，降低了交叉栅格面积30.65倍。EPIM超越了PIM上的状态态-of-the-art剪裁方法。
</details></li>
</ul>
<hr>
<h2 id="An-Application-of-Vector-Autoregressive-Model-for-Analyzing-the-Impact-of-Weather-And-Nearby-Traffic-Flow-On-The-Traffic-Volume"><a href="#An-Application-of-Vector-Autoregressive-Model-for-Analyzing-the-Impact-of-Weather-And-Nearby-Traffic-Flow-On-The-Traffic-Volume" class="headerlink" title="An Application of Vector Autoregressive Model for Analyzing the Impact of Weather And Nearby Traffic Flow On The Traffic Volume"></a>An Application of Vector Autoregressive Model for Analyzing the Impact of Weather And Nearby Traffic Flow On The Traffic Volume</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06894">http://arxiv.org/abs/2311.06894</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anh Thi-Hoang Nguyen, Dung Ha Nguyen, Trong-Hop Do</li>
<li>for: 预测一个道路段的交通流量，基于附近交通量和天气条件。</li>
<li>methods: 使用VAR(36)模型，包括时间趋势和常数，来训练数据集和预测。</li>
<li>results: 通过分析结果，发现天气条件和附近交通量对交通流量的影响，并且提供了解决交通流量预测问题的一种方法。<details>
<summary>Abstract</summary>
This paper aims to predict the traffic flow at one road segment based on nearby traffic volume and weather conditions. Our team also discover the impact of weather conditions and nearby traffic volume on the traffic flow at a target point. The analysis results will help solve the problem of traffic flow prediction and develop an optimal transport network with efficient traffic movement and minimal traffic congestion. Hourly historical weather and traffic flow data are selected to solve this problem. This paper uses model VAR(36) with time trend and constant to train the dataset and forecast. With an RMSE of 565.0768111 on average, the model is considered appropriate although some statistical tests implies that the residuals are unstable and non-normal. Also, this paper points out some variables that are not useful in forecasting, which helps simplify the data-collecting process when building the forecasting system.
</details>
<details>
<summary>摘要</summary>
这篇论文目标是根据附近交通量和天气情况预测一段公路交通流量。我们团队还发现了天气情况和附近交通量对target点交通流量的影响。分析结果将帮助解决交通流量预测问题并开发高效的交通网络，实现最佳的交通运输和最小的交通拥堵。选用了一年历史天气和交通流量数据进行解决这个问题。本文使用VAR(36)模型，包括时间趋势和常数，来训练数据集和预测。其中RMSE平均为565.0768111，可以视为合适的，但一些统计测试表明 residuals 不稳定和不归一化。此外，本文还指出了一些无用的变量，帮助简化收集数据时建立预测系统。
</details></li>
</ul>
<hr>
<h2 id="Preserving-Node-level-Privacy-in-Graph-Neural-Networks"><a href="#Preserving-Node-level-Privacy-in-Graph-Neural-Networks" class="headerlink" title="Preserving Node-level Privacy in Graph Neural Networks"></a>Preserving Node-level Privacy in Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06888">http://arxiv.org/abs/2311.06888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihang Xiang, Tianhao Wang, Di Wang</li>
<li>for: 这个研究旨在解决Graph Neural Networks（GNNs）中的实体隐私问题，specifically addressing the issue of node-level privacy。</li>
<li>methods: 我们的协议包括两个主要 ком成分：1）一个称为HeterPoisson的抽样 routinen，这个routinen使用特殊化的节点抽样策略和一系列适合的操作来生成一批子graphs with desired properties，2）一个Randomization routinen，这个routinen使用symmetric multivariate Laplace（SML）噪声而不是常用的Gaussian噪声。</li>
<li>results: 我们的隐私评估显示这组合提供了一定的隐私保证。实验表明，与现有的基准比较，我们的方法在高隐私 режи的情况下表现更好，特别是在五个真实世界数据集上。我们还进行了会员推测攻击和隐私审核技术来证明我们的协议的隐私完整性。<details>
<summary>Abstract</summary>
Differential privacy (DP) has seen immense applications in learning on tabular, image, and sequential data where instance-level privacy is concerned. In learning on graphs, contrastingly, works on node-level privacy are highly sparse. Challenges arise as existing DP protocols hardly apply to the message-passing mechanism in Graph Neural Networks (GNNs).   In this study, we propose a solution that specifically addresses the issue of node-level privacy. Our protocol consists of two main components: 1) a sampling routine called HeterPoisson, which employs a specialized node sampling strategy and a series of tailored operations to generate a batch of sub-graphs with desired properties, and 2) a randomization routine that utilizes symmetric multivariate Laplace (SML) noise instead of the commonly used Gaussian noise. Our privacy accounting shows this particular combination provides a non-trivial privacy guarantee. In addition, our protocol enables GNN learning with good performance, as demonstrated by experiments on five real-world datasets; compared with existing baselines, our method shows significant advantages, especially in the high privacy regime. Experimentally, we also 1) perform membership inference attacks against our protocol and 2) apply privacy audit techniques to confirm our protocol's privacy integrity.   In the sequel, we present a study on a seemingly appealing approach \cite{sajadmanesh2023gap} (USENIX'23) that protects node-level privacy via differentially private node/instance embeddings. Unfortunately, such work has fundamental privacy flaws, which are identified through a thorough case study. More importantly, we prove an impossibility result of achieving both (strong) privacy and (acceptable) utility through private instance embedding. The implication is that such an approach has intrinsic utility barriers when enforcing differential privacy.
</details>
<details>
<summary>摘要</summary>
différential privacy (DP) 已经在表格、图像和序列数据中进行了广泛的应用，而且在实例级隐私方面进行了充分的保障。然而，在图学中，工作在节点级隐私方面是非常罕见。 existing DP 协议几乎没有应用于图学中的消息传递机制。在这种研究中，我们提出了一种解决方案，即特点在节点级隐私方面。我们的协议包括两个主要组成部分： 1. 一种叫做 HeterPoisson 的采样 Routine，该 Routine使用特殊的节点采样策略和一系列适应的操作来生成一批具有感兴趣的属性的子图。 2. 一种叫做 Symmetric Multivariate Laplace (SML) 随机噪音的使用，而不是通常使用的高斯噪音。我们的隐私负荷表明这种特定的组合具有一定的隐私保障。此外，我们的协议允许 GNN 学习具有良好的性能，如实验所示，相比现有的基eline，我们的方法在高隐私 режиower表现出了显著优势，特别是在高隐私 режиower下。在实验中，我们还 1. 对我们的协议进行了成员推理攻击，以及 2. 通过隐私审核技术来确认我们的协议的隐私完整性。在继续的研究中，我们发现了一篇可能有吸引力的论文 \cite{sajadmanesh2023gap} (USENIX'23)，该论文通过异 diferencial privacy 保护节点级隐私。然而，我们在这篇论文中发现了基本的隐私漏洞，并通过详细的案例研究证明了这些漏洞。此外，我们还证明了在保持异 diferencial privacy 的情况下，不可能同时实现强隐私和可接受的用用。这种隐私的限制意味着在强制实施异 diferencial privacy 时，实际上存在一定的实用障碍。
</details></li>
</ul>
<hr>
<h2 id="pFedES-Model-Heterogeneous-Personalized-Federated-Learning-with-Feature-Extractor-Sharing"><a href="#pFedES-Model-Heterogeneous-Personalized-Federated-Learning-with-Feature-Extractor-Sharing" class="headerlink" title="pFedES: Model Heterogeneous Personalized Federated Learning with Feature Extractor Sharing"></a>pFedES: Model Heterogeneous Personalized Federated Learning with Feature Extractor Sharing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06879">http://arxiv.org/abs/2311.06879</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liping Yi, Han Yu, Gang Wang, Xiaoguang Liu</li>
<li>for: 本研究旨在提出一种基于特征提取器共享（pFedES）的个性化 Federated learning方法，以便让每个数据拥有者（FL客户端）在本地数据分布、系统资源和模型结构等限制下，训练个性化的本地模型。</li>
<li>methods: 本方法基于一个小型的同构特征提取器，并通过论证方法证明其可以在wall-to-wall时间内收敛。客户端通过迭代学习方法来训练本地模型，并将模型参数上传到FL服务器进行集成。</li>
<li>results: 对于两个实际数据集，与六种状态OF-the-art方法进行比较，实验结果表明，pFedES可以建立最准确的模型，同时具有低的通信和计算成本。相比最佳基eline，它可以提高测试准确率1.61%，而同时降低通信和计算成本99.6%和82.9%。<details>
<summary>Abstract</summary>
As a privacy-preserving collaborative machine learning paradigm, federated learning (FL) has attracted significant interest from academia and the industry alike. To allow each data owner (a.k.a., FL clients) to train a heterogeneous and personalized local model based on its local data distribution, system resources and requirements on model structure, the field of model-heterogeneous personalized federated learning (MHPFL) has emerged. Existing MHPFL approaches either rely on the availability of a public dataset with special characteristics to facilitate knowledge transfer, incur high computation and communication costs, or face potential model leakage risks. To address these limitations, we propose a model-heterogeneous personalized Federated learning approach based on feature Extractor Sharing (pFedES). It incorporates a small homogeneous feature extractor into each client's heterogeneous local model. Clients train them via the proposed iterative learning method to enable the exchange of global generalized knowledge and local personalized knowledge. The small local homogeneous extractors produced after local training are uploaded to the FL server and for aggregation to facilitate easy knowledge sharing among clients. We theoretically prove that pFedES can converge over wall-to-wall time. Extensive experiments on two real-world datasets against six state-of-the-art methods demonstrate that pFedES builds the most accurate model, while incurring low communication and computation costs. Compared with the best-performing baseline, it achieves 1.61% higher test accuracy, while reducing communication and computation costs by 99.6% and 82.9%, respectively.
</details>
<details>
<summary>摘要</summary>
As a privacy-preserving collaborative machine learning paradigm, federated learning (FL) has attracted significant interest from academia and industry. To allow each data owner (a.k.a., FL clients) to train a heterogeneous and personalized local model based on its local data distribution, system resources, and requirements on model structure, the field of model-heterogeneous personalized federated learning (MHPFL) has emerged. Existing MHPFL approaches either rely on the availability of a public dataset with special characteristics to facilitate knowledge transfer, incur high computation and communication costs, or face potential model leakage risks. To address these limitations, we propose a model-heterogeneous personalized Federated learning approach based on feature Extractor Sharing (pFedES). It incorporates a small homogeneous feature extractor into each client's heterogeneous local model. Clients train them via the proposed iterative learning method to enable the exchange of global generalized knowledge and local personalized knowledge. The small local homogeneous extractors produced after local training are uploaded to the FL server for aggregation to facilitate easy knowledge sharing among clients. We theoretically prove that pFedES can converge over wall-to-wall time. Extensive experiments on two real-world datasets against six state-of-the-art methods demonstrate that pFedES builds the most accurate model, while incurring low communication and computation costs. Compared with the best-performing baseline, it achieves 1.61% higher test accuracy, while reducing communication and computation costs by 99.6% and 82.9%, respectively.
</details></li>
</ul>
<hr>
<h2 id="Unified-machine-learning-tasks-and-datasets-for-enhancing-renewable-energy"><a href="#Unified-machine-learning-tasks-and-datasets-for-enhancing-renewable-energy" class="headerlink" title="Unified machine learning tasks and datasets for enhancing renewable energy"></a>Unified machine learning tasks and datasets for enhancing renewable energy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06876">http://arxiv.org/abs/2311.06876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arsam Aryandoust, Thomas Rigoni, Francesco di Stefano, Anthony Patt</li>
<li>for: 本研究旨在探讨使用多任务机器学习模型解决可再生能源过渡和气候变化问题。</li>
<li>methods: 本文使用多任务机器学习模型，包括零损训练和几何学习模型，以解决具有少量训练数据的问题。</li>
<li>results: 本文 introduce了17个能源转换任务数据集，并将所有任务集合成一个多任务机器学习模型，以便对这些任务进行解决。同时，本文还提出了一些数据集的维度、需要的设计要求和模型性能指标。<details>
<summary>Abstract</summary>
Multi-tasking machine learning (ML) models exhibit prediction abilities in domains with little to no training data available (few-shot and zero-shot learning). Over-parameterized ML models are further capable of zero-loss training and near-optimal generalization performance. An open research question is, how these novel paradigms contribute to solving tasks related to enhancing the renewable energy transition and mitigating climate change. A collection of unified ML tasks and datasets from this domain can largely facilitate the development and empirical testing of such models, but is currently missing. Here, we introduce the ETT-17 (Energy Transition Tasks-17), a collection of 17 datasets from six different application domains related to enhancing renewable energy, including out-of-distribution validation and testing data. We unify all tasks and datasets, such that they can be solved using a single multi-tasking ML model. We further analyse the dimensions of each dataset; investigate what they require for designing over-parameterized models; introduce a set of dataset scores that describe important properties of each task and dataset; and provide performance benchmarks.
</details>
<details>
<summary>摘要</summary>
多任务学习机器学习（ML）模型在具有少量或无training数据的领域表现出预测能力（几shot和零shot学习）。过度参数化的ML模型可以在无损训练和近似优化性能下进行训练。现有一个开放的研究问题是，这些新的 paradigma如何在推进可再生能源转型和减轻气候变化中发挥作用。一个包含这些任务和数据集的集成可以大大促进这些模型的开发和实验测试，但目前缺失。我们现在介绍ETT-17（能源转型任务17），这是6个不同应用领域中的17个数据集，包括out-of-distribution验证和测试数据。我们将所有任务和数据集统一，以便通过单个多任务ML模型解决它们。我们还分析每个数据集的维度，研究它们需要的设计过度参数化模型的要求，介绍每个任务和数据集的数据集分数，并提供性能标准。
</details></li>
</ul>
<hr>
<h2 id="Inference-and-Interference-The-Role-of-Clipping-Pruning-and-Loss-Landscapes-in-Differentially-Private-Stochastic-Gradient-Descent"><a href="#Inference-and-Interference-The-Role-of-Clipping-Pruning-and-Loss-Landscapes-in-Differentially-Private-Stochastic-Gradient-Descent" class="headerlink" title="Inference and Interference: The Role of Clipping, Pruning and Loss Landscapes in Differentially Private Stochastic Gradient Descent"></a>Inference and Interference: The Role of Clipping, Pruning and Loss Landscapes in Differentially Private Stochastic Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06839">http://arxiv.org/abs/2311.06839</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lauren Watson, Eric Gan, Mohan Dantam, Baharan Mirzasoleiman, Rik Sarkar</li>
<li>for: 这篇论文主要针对了差异性保护随机梯度下降（DP-SGD）在大神经网络上的训练和测试性能，并对其进行了详细的研究和比较。</li>
<li>methods: 该论文使用了分析DP-SGD和SGD的两个过程的不同行为，并在早期和晚期两个阶段进行了分别的分析。它发现DP-SGD在早期阶段的进度较慢，但是在后期阶段的进度决定了最终结果。此外，它还分析了DP-SGD中的剪切和随机噪声的两个步骤，发现剪切Step有更大的影响，而随机噪声则会引入误差。</li>
<li>results: 该论文通过理论分析和广泛的实验表明，可以通过减小维度来提高DP-SGD的测试准确率，并且发现重剪的方法可以更好地提高DP-SGD的测试准确率。<details>
<summary>Abstract</summary>
Differentially private stochastic gradient descent (DP-SGD) is known to have poorer training and test performance on large neural networks, compared to ordinary stochastic gradient descent (SGD). In this paper, we perform a detailed study and comparison of the two processes and unveil several new insights. By comparing the behavior of the two processes separately in early and late epochs, we find that while DP-SGD makes slower progress in early stages, it is the behavior in the later stages that determines the end result. This separate analysis of the clipping and noise addition steps of DP-SGD shows that while noise introduces errors to the process, gradient descent can recover from these errors when it is not clipped, and clipping appears to have a larger impact than noise. These effects are amplified in higher dimensions (large neural networks), where the loss basin occupies a lower dimensional space. We argue theoretically and using extensive experiments that magnitude pruning can be a suitable dimension reduction technique in this regard, and find that heavy pruning can improve the test accuracy of DPSGD.
</details>
<details>
<summary>摘要</summary>
diferencialmente privado stochastic gradient descent (DP-SGD) 是已知在大型神经网络上训练和测试性能较差，相比普通的随机梯度 descent (SGD)。在这篇论文中，我们进行了详细的比较和分析两个过程，并发现了一些新的发现。通过分 sep 梯度 descent 和噪声添加步骤的分析，我们发现，虽然 DP-SGD 在早期阶段 slower progress，但是在后期阶段的表现决定了结果。这些效果在高维（大神经网络）中更加突出，因为损失基地占据了低维度空间。我们 theoretically 和广泛实验表明， magnitude pruning 可以是适当的维度减少技术，并发现了重彻uning 可以提高 DPSGD 的测试精度。
</details></li>
</ul>
<hr>
<h2 id="GraNNDis-Efficient-Unified-Distributed-Training-Framework-for-Deep-GNNs-on-Large-Clusters"><a href="#GraNNDis-Efficient-Unified-Distributed-Training-Framework-for-Deep-GNNs-on-Large-Clusters" class="headerlink" title="GraNNDis: Efficient Unified Distributed Training Framework for Deep GNNs on Large Clusters"></a>GraNNDis: Efficient Unified Distributed Training Framework for Deep GNNs on Large Clusters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06837">http://arxiv.org/abs/2311.06837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaeyong Song, Hongsun Jang, Jaewon Jung, Youngsok Kim, Jinho Lee</li>
<li>for: 提高大图和深层GNN训练的效率</li>
<li>methods: 提出了三种新技术：分享预加载、扩展意识采样和合作批处理</li>
<li>results: 实验在多服务器多GPU集群上显示，GraNNDis可以提供更高的速度提升 compared to state-of-the-art distributed GNN 训练框架<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) are one of the most rapidly growing fields within deep learning. According to the growth in the dataset and the model size used for GNNs, an important problem is that it becomes nearly impossible to keep the whole network on GPU memory. Among numerous attempts, distributed training is one popular approach to address the problem. However, due to the nature of GNNs, existing distributed approaches suffer from poor scalability, mainly due to the slow external server communications.   In this paper, we propose GraNNDis, an efficient distributed GNN training framework for training GNNs on large graphs and deep layers. GraNNDis introduces three new techniques. First, shared preloading provides a training structure for a cluster of multi-GPU servers. We suggest server-wise preloading of essential vertex dependencies to reduce the low-bandwidth external server communications. Second, we present expansion-aware sampling. Because shared preloading alone has limitations because of the neighbor explosion, expansion-aware sampling reduces vertex dependencies that span across server boundaries. Third, we propose cooperative batching to create a unified framework for full-graph and minibatch training. It significantly reduces redundant memory usage in mini-batch training. From this, GraNNDis enables a reasonable trade-off between full-graph and mini-batch training through unification especially when the entire graph does not fit into the GPU memory. With experiments conducted on a multi-server/multi-GPU cluster, we show that GraNNDis provides superior speedup over the state-of-the-art distributed GNN training frameworks.
</details>
<details>
<summary>摘要</summary>
GRAPH NeRal networks (GNNs) 是深度学习中最快增长的领域之一。随着数据集和模型大小的增长，GNNs 中的一个重要问题是将整个网络存储在 GPU 内存中变得几乎不可能。为解决这个问题，分布式训练是一种受欢迎的方法。然而，由于 GNNs 的性质，现有的分布式方法受到较低的扩展缓存的限制，主要是由slow external server communications引起的。在本文中，我们提出了 GraNNDis，一种高效的分布式 GNN 训练框架，用于在大图和深层次上训练 GNNs。GraNNDis  introduce three new techniques：1. 共享预加载提供了一种cluster of multi-GPU servers中的训练结构。我们建议在多GPU服务器上进行优先级预加载 essentials vertex dependencies，以降低低带宽外部服务器通信的External server communications。2. 我们提出了扩展相关采样。由于共享预加载独立有限制，因为邻居爆发，扩展相关采样可以降低 span across server boundaries的 vertex dependencies。3. 我们提出了合作批处理，以创建一个统一的框架，用于全图和小批量训练。它可以减少了小批量训练中的冗余内存使用。从而，GraNNDis 允许在reasonable trade-off between full-graph and mini-batch training through unification，特别是当整个图片不能被GPU内存中的情况下。通过在多服务器/多GPU集群上进行实验，我们表明了 GraNNDis 对现有的分布式 GNN 训练框架提供了显著的加速。
</details></li>
</ul>
<hr>
<h2 id="Towards-Continual-Reinforcement-Learning-for-Quadruped-Robots"><a href="#Towards-Continual-Reinforcement-Learning-for-Quadruped-Robots" class="headerlink" title="Towards Continual Reinforcement Learning for Quadruped Robots"></a>Towards Continual Reinforcement Learning for Quadruped Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06828">http://arxiv.org/abs/2311.06828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giovanni Minelli, Vassilis Vassiliades</li>
<li>for: 本研究旨在强化quadruped robot在实际场景中的适应性和性能，通过在不同环境下进行练习和评估来增强机器人的适应能力。</li>
<li>methods: 本研究采用了两种 continual learning 方法，先后在不同环境中训练机器人，并同时评估其在所有环境下的性能。</li>
<li>results: 研究发现，机器人在不同环境下的适应能力受到了环境变化和前期练习的影响，同时也存在了机器人忘记先前学习的技能的现象。通过对这些因素的评估和控制，我们希望能够提高quadruped robot在实际场景中的性能和适应性。<details>
<summary>Abstract</summary>
Quadruped robots have emerged as an evolving technology that currently leverages simulators to develop a robust controller capable of functioning in the real-world without the need for further training. However, since it is impossible to predict all possible real-world situations, our research explores the possibility of enabling them to continue learning even after their deployment. To this end, we designed two continual learning scenarios, sequentially training the robot on different environments while simultaneously evaluating its performance across all of them. Our approach sheds light on the extent of both forward and backward skill transfer, as well as the degree to which the robot might forget previously acquired skills. By addressing these factors, we hope to enhance the adaptability and performance of quadruped robots in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
四足机器人已经成为一种发展中的技术，目前利用模拟器来开发一个在实际世界中能够运行的稳定控制器，无需进一步训练。然而，由于无法预测所有的实际世界情况，我们的研究探讨了让机器人继续学习，即使已经部署。为此，我们设计了两种连续学习情况，顺序地训练机器人在不同环境中，同时评估其在所有环境中的性能。我们的方法揭示了机器人在前进和逆转技能传递方面的扩展和忘记程度。通过解决这些因素，我们希望提高四足机器人在实际世界情况下的适应性和性能。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Survey-On-Client-Selections-in-Federated-Learning"><a href="#A-Comprehensive-Survey-On-Client-Selections-in-Federated-Learning" class="headerlink" title="A Comprehensive Survey On Client Selections in Federated Learning"></a>A Comprehensive Survey On Client Selections in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06801">http://arxiv.org/abs/2311.06801</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ala Gouissem, Zina Chkirbene, Ridha Hamila</li>
<li>for: 本文提供了 federated learning 中客户端选择技术的审视，包括其优势和局限性，以及需要解决的挑战和开issues。</li>
<li>methods: 本文覆盖了一些常见的客户端选择技术，如随机选择、性能 aware 选择和资源 aware 选择，以及在不同类型的网络中的应用。</li>
<li>results: 本文讨论了客户端选择对模型安全性的改进，以及在动态约束和不同类型的网络中的客户端选择的挑战和开issues。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a rapidly growing field in machine learning that allows data to be trained across multiple decentralized devices. The selection of clients to participate in the training process is a critical factor for the performance of the overall system. In this survey, we provide a comprehensive overview of the state-of-the-art client selection techniques in FL, including their strengths and limitations, as well as the challenges and open issues that need to be addressed. We cover conventional selection techniques such as random selection where all or partial random of clients is used for the trained. We also cover performance-aware selections and as well as resource-aware selections for resource-constrained networks and heterogeneous networks. We also discuss the usage of client selection in model security enhancement. Lastly, we discuss open issues and challenges related to clients selection in dynamic constrained, and heterogeneous networks.
</details>
<details>
<summary>摘要</summary>
federated 学习（FL）是一个快速发展的机器学习领域，允许数据在多个分散式设备上进行训练。选择参与训练过程的客户端是系统性能的关键因素。在本调查中，我们提供了 federated 学习中客户端选择技术的全面概述，包括它们的优点和局限性，以及需要解决的挑战和开放问题。我们覆盖了传统的选择技术，如随机选择，其中所有或部分随机选择客户端进行训练。我们还覆盖了性能协调的选择和资源协调的选择，用于资源受限的网络和多样化网络。此外，我们还讨论了客户端选择在模型安全增强中的应用。最后，我们讨论了客户端选择在动态约束和多样化网络中的开放问题。
</details></li>
</ul>
<hr>
<h2 id="Learning-Predictive-Safety-Filter-via-Decomposition-of-Robust-Invariant-Set"><a href="#Learning-Predictive-Safety-Filter-via-Decomposition-of-Robust-Invariant-Set" class="headerlink" title="Learning Predictive Safety Filter via Decomposition of Robust Invariant Set"></a>Learning Predictive Safety Filter via Decomposition of Robust Invariant Set</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06769">http://arxiv.org/abs/2311.06769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyang Li, Chuxiong Hu, Weiye Zhao, Changliu Liu</li>
<li>for: 本研究旨在提供一种可靠地保证非线性系统的安全性，尤其是在实际控制任务中，遇到模型不确定性和外部干扰时。</li>
<li>methods: 本研究使用了一种混合了模型预测控制（RMPC）和学习控制（RL）的方法，以实现安全性和可扩展性的平衡。</li>
<li>results: 研究结果表明，该方法可以在实时处理非 convex 优化问题，并提供持续的安全性保证，而不需要高度计算负担。<details>
<summary>Abstract</summary>
Ensuring safety of nonlinear systems under model uncertainty and external disturbances is crucial, especially for real-world control tasks. Predictive methods such as robust model predictive control (RMPC) require solving nonconvex optimization problems online, which leads to high computational burden and poor scalability. Reinforcement learning (RL) works well with complex systems, but pays the price of losing rigorous safety guarantee. This paper presents a theoretical framework that bridges the advantages of both RMPC and RL to synthesize safety filters for nonlinear systems with state- and action-dependent uncertainty. We decompose the robust invariant set (RIS) into two parts: a target set that aligns with terminal region design of RMPC, and a reach-avoid set that accounts for the rest of RIS. We propose a policy iteration approach for robust reach-avoid problems and establish its monotone convergence. This method sets the stage for an adversarial actor-critic deep RL algorithm, which simultaneously synthesizes a reach-avoid policy network, a disturbance policy network, and a reach-avoid value network. The learned reach-avoid policy network is utilized to generate nominal trajectories for online verification, which filters potentially unsafe actions that may drive the system into unsafe regions when worst-case disturbances are applied. We formulate a second-order cone programming (SOCP) approach for online verification using system level synthesis, which optimizes for the worst-case reach-avoid value of any possible trajectories. The proposed safety filter requires much lower computational complexity than RMPC and still enjoys persistent robust safety guarantee. The effectiveness of our method is illustrated through a numerical example.
</details>
<details>
<summary>摘要</summary>
保证非线性系统在模型不确定性和外部干扰下的安全性是非常重要，尤其是在实际控制任务中。预测方法如Robust Model Predictive Control（RMPC）需要在线解决非凸优化问题，这会导致高计算负担和低可扩展性。学习控制（RL）可以与复杂系统相处，但是付出了放弃准确的安全保证。本文提出了一个概念框架，可以结合RMPC和RL两种方法，并生成安全筛选器 для非线性系统。我们将 robust invariant set（RIS）分解为两部分：一个目标集，与终端区域设计相对应，以及一个可达-避免集，其他的RIS都包含在内。我们提出了一种政策迭代法，用于robust reach-avoid问题，并证明其 monotone convergence。这种方法为一种actor-critic深度学习算法提供了基础，该算法同时生成了一个可达-避免策略网络、一个干扰策略网络和一个可达-避免值网络。学习的可达-避免策略网络可以生成nominal trajectories，用于在线验证，并过滤潜在危险的动作，以避免系统在最差情况下受到危险的影响。我们使用系统级 synthesis 的 SOCP 方法进行在线验证，并优化了最差情况下的可达-避免值。提案的安全筛选器需要远低于RMPC的计算复杂性，仍然享有持续的准确安全保证。数据示例 verify 了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Personalized-Federated-Learning-via-ADMM-with-Moreau-Envelope"><a href="#Personalized-Federated-Learning-via-ADMM-with-Moreau-Envelope" class="headerlink" title="Personalized Federated Learning via ADMM with Moreau Envelope"></a>Personalized Federated Learning via ADMM with Moreau Envelope</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06756">http://arxiv.org/abs/2311.06756</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zsk66/flame-master">https://github.com/zsk66/flame-master</a></li>
<li>paper_authors: Shengkun Zhu, Jinshan Zeng, Sheng Wang, Yuan Sun, Zhiyong Peng</li>
<li>for: 提出了个人化联合学习（PFL）方法，以解决不同数据集的训练不收敛问题。</li>
<li>methods: 使用了多元函数方法（ADMM）和更多瓦埃均值（FLAME），实现了下线性收敛率，只需要Gradient Lipschitz连续性的较弱假设。此外，由于ADMM是无梯度的，FLAME可以减少全局模型训练中的hyperparameter调整，特别是避免学习率的调整。</li>
<li>results: 在不同数据集上训练PFL模型，FLAME可以在模型性能方面超过现有方法，并且在通信效率方面实现3.75倍的平均加速。此外，对于客户端选择策略，我们提出了偏向客户端选择策略，可以加速个人和全局模型的训练。<details>
<summary>Abstract</summary>
Personalized federated learning (PFL) is an approach proposed to address the issue of poor convergence on heterogeneous data. However, most existing PFL frameworks require strong assumptions for convergence. In this paper, we propose an alternating direction method of multipliers (ADMM) for training PFL models with Moreau envelope (FLAME), which achieves a sublinear convergence rate, relying on the relatively weak assumption of gradient Lipschitz continuity. Moreover, due to the gradient-free nature of ADMM, FLAME alleviates the need for hyperparameter tuning, particularly in avoiding the adjustment of the learning rate when training the global model. In addition, we propose a biased client selection strategy to expedite the convergence of training of PFL models. Our theoretical analysis establishes the global convergence under both unbiased and biased client selection strategies. Our experiments validate that FLAME, when trained on heterogeneous data, outperforms state-of-the-art methods in terms of model performance. Regarding communication efficiency, it exhibits an average speedup of 3.75x compared to the baselines. Furthermore, experimental results validate that the biased client selection strategy speeds up the convergence of both personalized and global models.
</details>
<details>
<summary>摘要</summary>
“个性化联合学习（PFL）是一种提出来解决不同数据集的融合问题的方法。然而，大多数现有的PFL框架需要强大的假设来保证收敛。在这篇论文中，我们提出了一种多参数方向法（ADMM）来训练PFL模型，使用Moreau抛物（FLAME）实现下线性收敛率，只需要 Gradient Lipschitz continuity 的较弱假设。此外，由于ADMM是gradient-free的，FLAME可以减少对学习率的调整，特别是在训练全局模型时。此外，我们还提出了偏向客户选择策略来加速PFL模型的训练。我们的理论分析表明，在不偏向和偏向客户选择策略下，模型都能够达到全球收敛。我们的实验表明，FLAME，当训练不同数据集时，可以比现有方法更好地性能。此外，实验还表明，偏向客户选择策略可以加速个性化和全局模型的训练。”Note: Please note that the translation is in Simplified Chinese, and the word order and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Application-of-a-Dense-Fusion-Attention-Network-in-Fault-Diagnosis-of-Centrifugal-Fan"><a href="#Application-of-a-Dense-Fusion-Attention-Network-in-Fault-Diagnosis-of-Centrifugal-Fan" class="headerlink" title="Application of a Dense Fusion Attention Network in Fault Diagnosis of Centrifugal Fan"></a>Application of a Dense Fusion Attention Network in Fault Diagnosis of Centrifugal Fan</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07614">http://arxiv.org/abs/2311.07614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruijun Wang, Yuan Liu, Zhixia Fan, Xiaogang Xu, Huijie Wang</li>
<li>for: 本研究旨在提高 rotate machinery 的监测和诊断能力，通过嵌入分布式注意力模块而不是传统的紧密相连操作。</li>
<li>methods: 本研究使用了 dense fusion 技术，即在 dense connections 中嵌入 distributed attention modules，以隔离空间和通道对瑕点特征重新调整的影响。同时，该技术还形成了一种 fusional attention 函数，可以帮助解释网络诊断过程的可读性。</li>
<li>results: 实验结果表明，该网络在 centrifugal fan 瑕点诊断方面的表现比其他先进瑕点诊断模型更好，可以更好地抵御噪声和提高瑕点特征提取能力。<details>
<summary>Abstract</summary>
Although the deep learning recognition model has been widely used in the condition monitoring of rotating machinery. However, it is still a challenge to understand the correspondence between the structure and function of the model and the diagnosis process. Therefore, this paper discusses embedding distributed attention modules into dense connections instead of traditional dense cascading operations. It not only decouples the influence of space and channel on fault feature adaptive recalibration feature weights, but also forms a fusion attention function. The proposed dense fusion focuses on the visualization of the network diagnosis process, which increases the interpretability of model diagnosis. How to continuously and effectively integrate different functions to enhance the ability to extract fault features and the ability to resist noise is answered. Centrifugal fan fault data is used to verify this network. Experimental results show that the network has stronger diagnostic performance than other advanced fault diagnostic models.
</details>
<details>
<summary>摘要</summary>
尽管深度学习识别模型在旋转机器condition monitoring中广泛应用，但是理解模型和诊断过程之间的对应关系仍然是一个挑战。因此，本文提出将分布式注意力模块采用 dense connections 而不是传统的 dense cascading 操作。这不仅解耦了空间和通道对缺陷特征重量的影响，还形成了一种 fusional attention 函数。提出的 dense fusion 可以视觉化网络诊断过程，从而提高模型诊断的可读性。如何不断和有效地 интегра力不同功能，提高抽取缺陷特征的能力和抗噪能力，这个问题得到了答案。使用中心扇式风机缺陷数据进行验证，实验结果表明，该网络在其他先进缺陷诊断模型之上具有更强的诊断能力。
</details></li>
</ul>
<hr>
<h2 id="How-do-Minimum-Norm-Shallow-Denoisers-Look-in-Function-Space"><a href="#How-do-Minimum-Norm-Shallow-Denoisers-Look-in-Function-Space" class="headerlink" title="How do Minimum-Norm Shallow Denoisers Look in Function Space?"></a>How do Minimum-Norm Shallow Denoisers Look in Function Space?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06748">http://arxiv.org/abs/2311.06748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Zeno, Greg Ongie, Yaniv Blumenfeld, Nir Weinberger, Daniel Soudry</li>
<li>for: This paper aims to understand the functions realized by shallow ReLU NN denoisers in the context of interpolation and minimal representation cost.</li>
<li>methods: The authors use a theoretical approach to derive closed-form expressions for the NN denoiser functions, and prove their contractivity and generalization properties.</li>
<li>results: The authors find that the NN denoiser functions can be decomposed into a sum of simple rank-one piecewise linear interpolations aligned with edges and&#x2F;or faces connecting training samples, and empirically verify this alignment phenomenon on synthetic data and real images.<details>
<summary>Abstract</summary>
Neural network (NN) denoisers are an essential building block in many common tasks, ranging from image reconstruction to image generation. However, the success of these models is not well understood from a theoretical perspective. In this paper, we aim to characterize the functions realized by shallow ReLU NN denoisers -- in the common theoretical setting of interpolation (i.e., zero training loss) with a minimal representation cost (i.e., minimal $\ell^2$ norm weights). First, for univariate data, we derive a closed form for the NN denoiser function, find it is contractive toward the clean data points, and prove it generalizes better than the empirical MMSE estimator at a low noise level. Next, for multivariate data, we find the NN denoiser functions in a closed form under various geometric assumptions on the training data: data contained in a low-dimensional subspace, data contained in a union of one-sided rays, or several types of simplexes. These functions decompose into a sum of simple rank-one piecewise linear interpolations aligned with edges and/or faces connecting training samples. We empirically verify this alignment phenomenon on synthetic data and real images.
</details>
<details>
<summary>摘要</summary>
For univariate data, we derive a closed-form expression for the NN denoiser function and show that it is contractive towards the clean data points. We also prove that the NN denoiser generalizes better than the empirical MMSE estimator at a low noise level.For multivariate data, we find the NN denoiser functions in closed form under various geometric assumptions on the training data, including data contained in a low-dimensional subspace, data contained in a union of one-sided rays, or data contained in several types of simplexes. These functions decompose into a sum of simple rank-one piecewise linear interpolations aligned with edges and/or faces connecting training samples. We empirically verify this alignment phenomenon on synthetic data and real images.
</details></li>
</ul>
<hr>
<h2 id="ReactionT5-a-large-scale-pre-trained-model-towards-application-of-limited-reaction-data"><a href="#ReactionT5-a-large-scale-pre-trained-model-towards-application-of-limited-reaction-data" class="headerlink" title="ReactionT5: a large-scale pre-trained model towards application of limited reaction data"></a>ReactionT5: a large-scale pre-trained model towards application of limited reaction data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06708">http://arxiv.org/abs/2311.06708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sagawatatsuya/ReactionT5">https://github.com/sagawatatsuya/ReactionT5</a></li>
<li>paper_authors: Tatsuya Sagawa, Ryosuke Kojima</li>
<li>for: 这种paper是为了提出一种基于Transformer的深度神经网络，用于预测多个分子反应的结果。</li>
<li>methods: 这种模型使用了ORD数据库中的大规模数据进行预训练，然后进行了精细调整以适应具体的反应预测任务。</li>
<li>results: 研究发现，这种模型在预测反应产物的量和产物分布中表现出色，即使用有限的精细调整数据也能够达到比较出色的效果。<details>
<summary>Abstract</summary>
Transformer-based deep neural networks have revolutionized the field of molecular-related prediction tasks by treating molecules as symbolic sequences. These models have been successfully applied in various organic chemical applications by pretraining them with extensive compound libraries and subsequently fine-tuning them with smaller in-house datasets for specific tasks. However, many conventional methods primarily focus on single molecules, with limited exploration of pretraining for reactions involving multiple molecules. In this paper, we propose ReactionT5, a novel model that leverages pretraining on the Open Reaction Database (ORD), a publicly available large-scale resource. We further fine-tune this model for yield prediction and product prediction tasks, demonstrating its impressive performance even with limited fine-tuning data compared to traditional models. The pre-trained ReactionT5 model is publicly accessible on the Hugging Face platform.
</details>
<details>
<summary>摘要</summary>
transformer-based deep neural networks have revolutionized the field of molecular-related prediction tasks by treating molecules as symbolic sequences. These models have been successfully applied in various organic chemical applications by pretraining them with extensive compound libraries and subsequently fine-tuning them with smaller in-house datasets for specific tasks. However, many conventional methods primarily focus on single molecules, with limited exploration of pretraining for reactions involving multiple molecules. In this paper, we propose ReactionT5, a novel model that leverages pretraining on the Open Reaction Database (ORD), a publicly available large-scale resource. We further fine-tune this model for yield prediction and product prediction tasks, demonstrating its impressive performance even with limited fine-tuning data compared to traditional models. The pre-trained ReactionT5 model is publicly accessible on the Hugging Face platform.Here's the translation in Traditional Chinese:transformer-based deep neural networks have revolutionized the field of molecular-related prediction tasks by treating molecules as symbolic sequences. These models have been successfully applied in various organic chemical applications by pretraining them with extensive compound libraries and subsequently fine-tuning them with smaller in-house datasets for specific tasks. However, many conventional methods primarily focus on single molecules, with limited exploration of pretraining for reactions involving multiple molecules. In this paper, we propose ReactionT5, a novel model that leverages pretraining on the Open Reaction Database (ORD), a publicly available large-scale resource. We further fine-tune this model for yield prediction and product prediction tasks, demonstrating its impressive performance even with limited fine-tuning data compared to traditional models. The pre-trained ReactionT5 model is publicly accessible on the Hugging Face platform.
</details></li>
</ul>
<hr>
<h2 id="Transfer-Learning-to-Detect-COVID-19-Coughs-with-Incremental-Addition-of-Patient-Coughs-to-Healthy-People’s-Cough-Detection-Models"><a href="#Transfer-Learning-to-Detect-COVID-19-Coughs-with-Incremental-Addition-of-Patient-Coughs-to-Healthy-People’s-Cough-Detection-Models" class="headerlink" title="Transfer Learning to Detect COVID-19 Coughs with Incremental Addition of Patient Coughs to Healthy People’s Cough Detection Models"></a>Transfer Learning to Detect COVID-19 Coughs with Incremental Addition of Patient Coughs to Healthy People’s Cough Detection Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06707">http://arxiv.org/abs/2311.06707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudip Vhaduri, Seungyeon Paik, Jessica E Huber</li>
<li>for: 检测COVID-19病人的喘音，以防止疾病的迅速传播。</li>
<li>methods: 使用升级传输学习方法，利用健康人喘音和COVID-19患者喘音之间的关系，以精准地检测COVID-19病人的喘音。</li>
<li>results: 使用小量病人喘音数据和预训练的健康人喘音模型，可以达到reasonable的喘音检测精度，从而降低需要大量病人数据来训练模型的需求。<details>
<summary>Abstract</summary>
Millions of people have died worldwide from COVID-19. In addition to its high death toll, COVID-19 has led to unbearable suffering for individuals and a huge global burden to the healthcare sector. Therefore, researchers have been trying to develop tools to detect symptoms of this human-transmissible disease remotely to control its rapid spread. Coughing is one of the common symptoms that researchers have been trying to detect objectively from smartphone microphone-sensing. While most of the approaches to detect and track cough symptoms rely on machine learning models developed from a large amount of patient data, this is not possible at the early stage of an outbreak. In this work, we present an incremental transfer learning approach that leverages the relationship between healthy peoples' coughs and COVID-19 patients' coughs to detect COVID-19 coughs with reasonable accuracy using a pre-trained healthy cough detection model and a relatively small set of patient coughs, reducing the need for large patient dataset to train the model. This type of model can be a game changer in detecting the onset of a novel respiratory virus.
</details>
<details>
<summary>摘要</summary>
众多人在全球死亡了，COVID-19 也引起了不可支持的人类uffering 和全球医疗机构的巨大荷载。因此，研究人员在努力开发可以远程检测COVID-19 病人的症状，以控制其迅速传播。咳嗽是COVID-19 病人的常见症状之一，研究人员在智能手机麦克风感测中尝试了对咳嗽症状进行 объектив检测。大多数检测和跟踪咳嗽症状的方法都基于由大量病人数据提供的机器学习模型，但在疫情的早期，这并不是可行的。在这种情况下，我们提出了一种增量传输学习方法，利用健康人群的咳嗽和COVID-19 病人的咳嗽之间的关系，以对COVID-19 病人的咳嗽进行reasonable的检测，使用先前已经训练的健康咳嗽检测模型和相对较小的病人咳嗽数据集，从而减少需要大量病人数据来训练模型。这种类型的模型可能会是检测新型呼吸病的游戏 changer。
</details></li>
</ul>
<hr>
<h2 id="A-Physics-informed-Machine-Learning-based-Control-Method-for-Nonlinear-Dynamic-Systems-with-Highly-Noisy-Measurements"><a href="#A-Physics-informed-Machine-Learning-based-Control-Method-for-Nonlinear-Dynamic-Systems-with-Highly-Noisy-Measurements" class="headerlink" title="A Physics-informed Machine Learning-based Control Method for Nonlinear Dynamic Systems with Highly Noisy Measurements"></a>A Physics-informed Machine Learning-based Control Method for Nonlinear Dynamic Systems with Highly Noisy Measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07613">http://arxiv.org/abs/2311.07613</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mason Ma, Jiajie Wu, Chase Post, Tony Shi, Jingang Yi, Tony Schmitz, Hong Wang</li>
<li>for: 该研究旨在提出一种基于物理学习的控制方法，用于非线性动态系统中的噪声探测。现有的数据驱动控制方法使用机器学习进行系统识别，但不能有效应对高度噪声的测量结果，导致控制性能不稳定。</li>
<li>methods: 该研究扩展了当前的物理学习可靠性模型，并将其集成到预测控制框架中。以实验 validate 两个噪声非线性动态系统：洛朗兹3系统和转换机床。</li>
<li>results: 分析结果表明，提出的方法在高噪声条件下表现出较高的模型准确性和控制性能，与当前参考值相比有所提高。<details>
<summary>Abstract</summary>
This study presents a physics-informed machine learning-based control method for nonlinear dynamic systems with highly noisy measurements. Existing data-driven control methods that use machine learning for system identification cannot effectively cope with highly noisy measurements, resulting in unstable control performance. To address this challenge, the present study extends current physics-informed machine learning capabilities for modeling nonlinear dynamics with control and integrates them into a model predictive control framework. To demonstrate the capability of the proposed method we test and validate with two noisy nonlinear dynamic systems: the chaotic Lorenz 3 system, and turning machine tool. Analysis of the results illustrate that the proposed method outperforms state-of-the-art benchmarks as measured by both modeling accuracy and control performance for nonlinear dynamic systems under high-noise conditions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/12/cs.LG_2023_11_12/" data-id="clp9qz88b00uwok887bs79b4g" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/12/eess.IV_2023_11_12/" class="article-date">
  <time datetime="2023-11-12T09:00:00.000Z" itemprop="datePublished">2023-11-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/12/eess.IV_2023_11_12/">eess.IV - 2023-11-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="PuzzleTuning-Explicitly-Bridge-Pathological-and-Natural-Image-with-Puzzles"><a href="#PuzzleTuning-Explicitly-Bridge-Pathological-and-Natural-Image-with-Puzzles" class="headerlink" title="PuzzleTuning: Explicitly Bridge Pathological and Natural Image with Puzzles"></a>PuzzleTuning: Explicitly Bridge Pathological and Natural Image with Puzzles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06712">http://arxiv.org/abs/2311.06712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sagizty/puzzletuning">https://github.com/sagizty/puzzletuning</a></li>
<li>paper_authors: Tianyi Zhang, Shangqing Lyu, Yanli Lei, Sicheng Chen, Nan Ying, Yufang He, Yu Zhao, Yunlu Feng, Guanglei Zhang</li>
<li>for: 这个研究是为了提高路ологиcal image分析的效果，因为 annotation scarcity 问题，很多 recent works 使用 self-supervised learning (SSL) 在无标注的路ологиcal image上进行预训练，但是这些方法存在两个核心缺陷：一是不直接探索路ологиcal 领域的主要专注点，二是不能有效地与大量的自然图像领域结合。</li>
<li>methods: 我们提出了一个大规模的 PuzzleTuning 框架，包括以下几个创新：首先，我们识别了三个任务专注点，可以有效地连接路ологиcal 和自然领域：外观一致性、空间一致性和调整理解。其次，我们设计了多个蛋糕修复任务，以Explicitly 预训模型这些专注点。最后，为了补充两个领域之间的差距，我们引入了一个明确的问题调整过程，将这些领域专门的知识与自然知识融合。</li>
<li>results: 我们的 PuzzleTuning 框架在多个下游任务中表现出色，比如多个数据集上的不同任务。实验结果显示，我们的 PuzzleTuning 框架比前一代 SOTA 方法更好地适应路ологиcal image分析的问题。可以在 <a target="_blank" rel="noopener" href="https://github.com/sagizty/PuzzleTuning">https://github.com/sagizty/PuzzleTuning</a> 获取代码、示例和预训模型。<details>
<summary>Abstract</summary>
Pathological image analysis is a crucial field in computer vision. Due to the annotation scarcity in the pathological field, recently, most of the works leverage self-supervised learning (SSL) trained on unlabeled pathological images, hoping to mine the main representation automatically. However, there are two core defects in SSL-based pathological pre-training: (1) they do not explicitly explore the essential focuses of the pathological field, and (2) they do not effectively bridge with and thus take advantage of the large natural image domain. To explicitly address them, we propose our large-scale PuzzleTuning framework, containing the following innovations. Firstly, we identify three task focuses that can effectively bridge pathological and natural domains: appearance consistency, spatial consistency, and misalignment understanding. Secondly, we devise a multiple puzzle restoring task to explicitly pre-train the model with these focuses. Thirdly, for the existing large domain gap between natural and pathological fields, we introduce an explicit prompt-tuning process to incrementally integrate the domain-specific knowledge with the natural knowledge. Additionally, we design a curriculum-learning training strategy that regulates the task difficulty, making the model fit the complex multiple puzzle restoring task adaptively. Experimental results show that our PuzzleTuning framework outperforms the previous SOTA methods in various downstream tasks on multiple datasets. The code, demo, and pre-trained weights are available at https://github.com/sagizty/PuzzleTuning.
</details>
<details>
<summary>摘要</summary>
Pathological image分析是计算机视觉中的关键领域。由于pathological领域中的标注缺乏，最近的大多数工作都是通过自动学习（SSL）在未标注的pathological图像上进行训练，以希望从自动获得主表示。然而， SSL在pathological领域中有两个核心缺陷：（1）它们不直接探索pathological领域的关键点，和（2）它们不能有效地与大自然图像领域相结合。为了直接解决这些问题，我们提出了我们的大规模PuzzleTuning框架，包括以下创新：1. 我们确定了三个任务专注点，可以有效桥接pathological和自然领域：外观一致性、空间一致性和误差理解。2. 我们设计了一个多个谜题恢复任务，以直接在这些专注点上培养模型。3. 由于natural和pathological领域之间的域领域差距较大，我们引入了一个明确的提问调整过程，以增量地 интеGRATE域特定知识和自然知识。4. 我们设计了一个curriculum学习训练策略，以适应模型适应复杂的多个谜题恢复任务的适应性。实验结果显示，我们的PuzzleTuning框架在多个下游任务中超过了先前的SOTA方法。我们在https://github.com/sagizty/PuzzleTuning上提供了代码、示例和预训练 веса。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/12/eess.IV_2023_11_12/" data-id="clp9qz8fb01d6ok8867paezqq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/12/eess.SP_2023_11_12/" class="article-date">
  <time datetime="2023-11-12T08:00:00.000Z" itemprop="datePublished">2023-11-12</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/12/eess.SP_2023_11_12/">eess.SP - 2023-11-12</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Dual-Polarized-Reconfigurable-Intelligent-Surface-Assisted-Broad-Beamforming"><a href="#Dual-Polarized-Reconfigurable-Intelligent-Surface-Assisted-Broad-Beamforming" class="headerlink" title="Dual-Polarized Reconfigurable Intelligent Surface Assisted Broad Beamforming"></a>Dual-Polarized Reconfigurable Intelligent Surface Assisted Broad Beamforming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06967">http://arxiv.org/abs/2311.06967</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/parisaramezani/RISBroadBeamforming">https://github.com/parisaramezani/RISBroadBeamforming</a></li>
<li>paper_authors: Parisa Ramezani, Maksym A. Girnyk, Emil Björnson</li>
<li>for: 这个论文研究了一种基于智能表面的通信系统，其中一个发送器想要向多个用户传输一个公共信号，这些用户分布在宽的角度领域中。</li>
<li>methods: 这个论文提议使用双极化的智能表面，其中每个元素具有垂直的两种极化方向，以实现广泛的束发射。它们还提出了一种基于 Golay 匹配序列的配置方法，可以构建大型智能表面从更小的智能表面中。</li>
<li>results: 数值分析证明了这种方法可以大大提高覆盖范围，并且可以将多个小型智能表面组合成大型智能表面。<details>
<summary>Abstract</summary>
A reconfigurable intelligent surface (RIS) consists of a large number of low-cost elements that can control the propagation environment seen from a transmitter by intelligently applying phase shifts to impinging signals before reflection. This paper studies an RIS-assisted communication system where a transmitter wants to transmit a common signal to many users residing in a wide angular area. To cover this sector uniformly, the RIS needs to radiate a broad beam with a spatially flat array factor, instead of a narrow beam as normally considered. To achieve this, we propose to use a dual-polarized RIS consisting of elements with orthogonal polarizations and show that the RIS can produce a broad beam if the phase shift configuration vectors in the two polarizations form a so-called Golay complementary sequence pair. By utilizing their properties, we also present a method for constructing configuration for large RISs from smaller ones, while preserving the broad radiation pattern of the smaller RIS. The numerical results corroborate the mathematical analyses and highlight the greatly improved coverage properties.
</details>
<details>
<summary>摘要</summary>
一个可重新配置智能表面（RIS）由一大量低成本元素组成，可以控制传输器所看到的媒介传播环境，通过智能应用相位偏移到反射的信号前。这篇论文研究了一种由RIS支持的通信系统，在这种系统中，发送器想要将通信信号传输给覆盖广泛的用户群，这些用户群居住在一个宽角度区域中。为了覆盖这个领域，RIS需要发射一个广泛的束，而不是通常考虑的窄束。为了实现这一目标，我们提议使用双极化RIS，其元素具有正交的极化。我们表明，如果相位配置向量在两个极化中形成一个叫做高级别补做对的序列， то么RIS就可以生成一个广泛的束。此外，我们还提出了一种使用这种特性来构建大型RIS从小RIS中的方法，保持小RIS的广泛束 radiation 特性。数值结果证明了数学分析结果，并将广泛覆盖性得到了显著提高。
</details></li>
</ul>
<hr>
<h2 id="UAV-Formation-Optimization-for-Communication-assisted-InSAR-Sensing"><a href="#UAV-Formation-Optimization-for-Communication-assisted-InSAR-Sensing" class="headerlink" title="UAV Formation Optimization for Communication-assisted InSAR Sensing"></a>UAV Formation Optimization for Communication-assisted InSAR Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06959">http://arxiv.org/abs/2311.06959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed-Amine Lahmeri, Victor Mustieles-Pérez, Martin Vossiek, Gerhard Krieger, Robert Schober</li>
<li>for: 本研究旨在提高无人航空器（UAV）对雷达成像 Synthetic Aperture Radar（InSAR）散射应用的效率，包括生成高精度的数字高程模型（DEM）。</li>
<li>methods: 本文采用了joint形成和通信资源分配优化方法，以优化UAV对InSAR散射和数据传输的性能。</li>
<li>results: 研究结果显示，采用 alternate optimization（AO）技术和successive convex approximation（SCA）可以最大化InSAR覆盖率，同时满足所有InSAR特定的探测和通信性能指标。<details>
<summary>Abstract</summary>
Interferometric synthetic aperture radar (InSAR) is an increasingly important remote sensing technique that enables three-dimensional (3D) sensing applications such as the generation of accurate digital elevation models (DEMs). In this paper, we investigate the joint formation and communication resource allocation optimization for a system comprising two unmanned aerial vehicles (UAVs) to perform InSAR sensing and to transfer the acquired data to the ground. To this end, we adopt as sensing performance metrics the interferometric coherence, i.e., the local correlation between the two co-registered UAV radar images, and the height of ambiguity (HoA), which together are a measure for the accuracy with which the InSAR system can estimate the height of ground objects. In addition, an analytical expression for the coverage of the considered InSAR sensing system is derived. Our objective is to maximize the InSAR coverage while satisfying all relevant InSAR-specific sensing and communication performance metrics. To tackle the non-convexity of the formulated optimization problem, we employ alternating optimization (AO) techniques combined with successive convex approximation (SCA). Our simulation results reveal that the resulting resource allocation algorithm outperforms two benchmark schemes in terms of InSAR coverage while satisfying all sensing and real-time communication requirements. Furthermore, we highlight the importance of efficient communication resource allocation in facilitating real-time sensing and unveil the trade-off between InSAR height estimation accuracy and coverage.
</details>
<details>
<summary>摘要</summary>
<<SYS>>双无人航空器（UAV）探测双成像雷达（InSAR）系统的资源分配优化，以提高三维（3D）探测应用的精度。在本文中，我们将 investigate InSAR探测系统的共同形成和通信资源分配优化，以便两架UAV通过彼此联合探测来传输探测数据到地面。我们采用了干扰合成射频干扰（InSAR）探测系统的测试表现指标，包括干扰相关性（local correlation）和高程槽（HoA），这些指标共同测量干扰系统对地面物体高度的准确估计。此外，我们Derive an analytical expression for the coverage of the considered InSAR sensing system.我们的目标是将InSAR覆盖范围最大化，同时满足所有相关的InSAR特有探测和通信性能指标。为了解决干扰合成射频探测系统的非对称问题，我们使用了alternating optimization（AO）技术和Successive Convex Approximation（SCA）。我们的实验结果显示，所得的资源分配算法比两个底线方案更好，在满足所有探测和实时通信需求的情况下，提高InSAR覆盖范围。此外，我们阐述了实时探测和干扰系统之间的贡献相互作用，以及探测高度估计精度和覆盖范围之间的贡献贸易。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="A-Generalized-Framework-for-Pulse-Shaping-on-Delay-Doppler-Plane"><a href="#A-Generalized-Framework-for-Pulse-Shaping-on-Delay-Doppler-Plane" class="headerlink" title="A Generalized Framework for Pulse-Shaping on Delay-Doppler Plane"></a>A Generalized Framework for Pulse-Shaping on Delay-Doppler Plane</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06936">http://arxiv.org/abs/2311.06936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohsen Bayat, Arman Farhang</li>
<li>for: 本研究的主要目标是建立一个总结射频平面上的射频整形框架。为此，我们将延迟-Doppler射频整形技术分为两类：圆形和线性射频整形。这为开发一个总结射频整形框架提供了机会，同时带来了新的启示。</li>
<li>methods: 我们使用了数学 derivations 来解释 ODDM 是一种线性射频整形技术，并且通过在延迟维度上插入一些零卫士 (ZG) 符号来提高圆形和线性射频整形技术的 OOB 泄漏和 BER 性能。</li>
<li>results: 我们的仪器实验结果证明了我们的数学 derivations 和主张的正确性，同时也证明了 ZGs 在 OOB 减少和 BER 性能提高方面的效果。<details>
<summary>Abstract</summary>
The primary objective of this paper is to establish a generalized framework for pulse-shaping on the delay-Doppler plane. To this end, we classify delay-Doppler pulse-shaping techniques into two types, namely, circular and linear pulse-shaping. This paves the way towards the development of a generalized pulse-shaping framework. Our generalized framework provides the opportunity to compare different pulse-shaping techniques under the same umbrella while bringing new insights into their properties. In particular, our derivations based on this framework reveal that the recently emerged waveform orthogonal delay-Doppler multiplexing modulation (ODDM) is a linear pulse-shaping technique. By presenting ODDM under our generalized framework, we clearly explain the observed staircase behavior of its spectrum which has not been previously reported in the literature. Another contribution of this paper is proposal of a simple out-of-band (OOB) emission reduction technique by inserting a small number of zero-guard (ZG) symbols along the delay dimension of the circularly pulse-shaped signals. Additionally, inserting the zero-guards improves the bit-error-rate (BER) performance of both circular and linear pulse-shaping techniques. Finally, our simulation results confirm the validity of our mathematical derivations, claims and the effectiveness of the ZGs in OOB reduction and BER performance improvement.
</details>
<details>
<summary>摘要</summary>
主要目标 OF 这篇论文是建立一个通用的射频平面上的振荡形态框架。为达到这个目标，我们将延迟-Doppler 振荡技术分为两类：圆形振荡和直线振荡。这些分类提供了一个通用的振荡形态框架，可以对不同的振荡技术进行比较，并为其Properties 提供新的看法。具体来说，我们的 derivations 表明，最近出现的振荡 Ortogonal delay-Doppler multiplexing modulation (ODDM) 是一种直线振荡技术。通过将 ODDM 放入我们的通用框架中，我们可以清晰地解释 literature 中未曾报道的 ODDM 谱图的楼梯结构。此外，我们还提出了一种简单的出带 Emission reduction 技术，通过在圆振荡信号中添加一些零卫星（ZG）符号来减少带外干扰。此外，添加 ZG 符号还可以提高圆振荡和直线振荡技术的比特错误率（BER）性能。最后，我们的仿真结果证明了我们的数学 derivations 和主张的正确性，以及 ZG 符号在 OOB 减少和 BER 性能提高中的效果。
</details></li>
</ul>
<hr>
<h2 id="Symbol-Error-Probability-Constrained-Power-Minimization-for-Reconfigurable-Intelligent-Surfaces-based-Passive-Transmitter"><a href="#Symbol-Error-Probability-Constrained-Power-Minimization-for-Reconfigurable-Intelligent-Surfaces-based-Passive-Transmitter" class="headerlink" title="Symbol-Error Probability Constrained Power Minimization for Reconfigurable Intelligent Surfaces-based Passive Transmitter"></a>Symbol-Error Probability Constrained Power Minimization for Reconfigurable Intelligent Surfaces-based Passive Transmitter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06900">http://arxiv.org/abs/2311.06900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Erico S. P. Lopes, Lukas T. N. Landau</li>
<li>for: 这个论文主要关注虚拟多用户多输入多输出系统中使用PSK模ulation和可配置智能表面发射机器人设置。</li>
<li>methods: 该论文 derive了 union-bound symbol-error probability 的形式化，该形式化是实际symbol-error probability的Upper bound。然后，根据这个形式化，提出了一个符号级 precoding 功率最小化问题，其中符号错误率要求下降到给定的水平。</li>
<li>results: 该论文通过使用 bisecting 方法和里曼尼昂 conjugate gradient 算法解决了这个问题。数值结果表明，该方法可以有效地减少 transmit power，并且适用于不同的 symbol-error probability 要求。<details>
<summary>Abstract</summary>
This study considers a virtual multiuser multiple-input multiple-output system with PSK modulation realized via the reconfigurable intelligent surface-based passive transmitter setup. Under this framework, the study derives the formulation for the union-bound symbol-error probability, which is an upper bound on the actual symbol-error probability. Based on this, a symbol-level precoding power minimization problem under the condition that the union-bound symbol-error probability is below a given requirement is proposed. The problem is formulated as a constrained optimization on an oblique manifold, and solved via a bisection method. The method consists of successively optimizing transmit power while evaluating the feasibility of the union-bound symbol-error probability requisite by solving, via the Riemannian conjugate gradient algorithm, an auxiliary problem dependent only on the reflection coefficients of the reconfigurable intelligent surface elements. Numerical results demonstrate the effectiveness of the proposed approach in minimizing the transmit power for different symbol-error probability requirements.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Energy-efficient-Beamforming-for-RISs-aided-Communications-Gradient-Based-Meta-Learning"><a href="#Energy-efficient-Beamforming-for-RISs-aided-Communications-Gradient-Based-Meta-Learning" class="headerlink" title="Energy-efficient Beamforming for RISs-aided Communications: Gradient Based Meta Learning"></a>Energy-efficient Beamforming for RISs-aided Communications: Gradient Based Meta Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06861">http://arxiv.org/abs/2311.06861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinquan Wang, Fenghao Zhu, Qianyun Zhou, Qihao Yu, Chongwen Huang, Ahmed Alhammadi, Zhaoyang Zhang, Chau Yuen, Mérouane Debbah</li>
<li>for: 提高6G通信的能效性和可扩展性。</li>
<li>methods: 使用绿色梯度基于meta学 beamforming（GMLB）方法，即通过把总比特率的梯度 feed into神经网络来进行优化。同时，设计了一个差分调节器来处理RIS的相位优化。</li>
<li>results: 在 simulations 中，GMLB 能够高于典型的 alternate 优化算法，并且能够减少两个数量级的能耗。<details>
<summary>Abstract</summary>
Reconfigurable intelligent surfaces (RISs) have become a promising technology to meet the requirements of energy efficiency and scalability in future six-generation (6G) communications. However, a significant challenge in RISs-aided communications is the joint optimization of active and passive beamforming at base stations (BSs) and RISs respectively. Specifically, the main difficulty is attributed to the highly non-convex optimization space of beamforming matrices at both BSs and RISs, as well as the diversity and mobility of communication scenarios. To address this, we present a greenly gradient based meta learning beamforming (GMLB) approach. Unlike traditional deep learning based methods which take channel information directly as input, GMLB feeds the gradient of sum rate into neural networks. Coherently, we design a differential regulator to address the phase shift optimization of RISs. Moreover, we use the meta learning to iteratively optimize the beamforming matrices of BSs and RISs. These techniques make the proposed method to work well without requiring energy-consuming pre-training. Simulations show that GMLB could achieve higher sum rate than that of typical alternating optimization algorithms with the energy consumption by two orders of magnitude less.
</details>
<details>
<summary>摘要</summary>
现代化智能表面技术（RIS）已成为未来六代通信（6G）的一种有前途的技术，以满足能效性和可扩展性的需求。然而，RIS协助通信中存在一个主要挑战，即BS和RIS的活动和被动扫描矩阵优化的共同优化。具体来说，这是因为扫描矩阵的优化空间具有非 convex 性，以及通信场景的多样性和移动性。为解决这个问题，我们提出了一种绿色梯度基于元学习扫描矩阵优化（GMLB）方法。不同于传统的深度学习基于方法，GMLB 将扫描矩阵的梯度Feed into神经网络。此外，我们设计了一种差分调制器来处理RIS的相位优化。此外，我们使用元学习来逐次优化BS和RIS的扫描矩阵。这些技术使得我们的方法可以不需要耗费能量劳动性的预训练。实验显示，GMLB 可以在能效性方面高于传统的交互优化算法，并且能够降低能 consumption by two orders of magnitude。
</details></li>
</ul>
<hr>
<h2 id="Multiuser-Resource-Allocation-for-Semantic-Relay-Aided-Text-Transmissions"><a href="#Multiuser-Resource-Allocation-for-Semantic-Relay-Aided-Text-Transmissions" class="headerlink" title="Multiuser Resource Allocation for Semantic-Relay-Aided Text Transmissions"></a>Multiuser Resource Allocation for Semantic-Relay-Aided Text Transmissions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06854">http://arxiv.org/abs/2311.06854</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyang Hu, Tianyu Liu, Changsheng You, Zhaohui Yang, Mingzhe Chen</li>
<li>for: 提高含义传输效率，尤其在低信号噪比和小宽度区域</li>
<li>methods: 提出一种新的含义 relay（SemRelay），使用含义接收器帮助多用户文本传输</li>
<li>results: 提出一种优化多用户资源分配问题的算法，以提高多用户文本传输效率，并经过数学实验证明其高质量优化解决方案的有效性<details>
<summary>Abstract</summary>
Semantic communication (SemCom) is an emerging technology that extracts useful meaning from data and sends only relevant semantic information. Thus, it has the great potential to improve the spectrum efficiency of conventional wireless systems with bit transmissions, especially in low signal-to-noise ratio (SNR) and small bandwidth regions. However, the existing works have mostly overlooked the constraints of mobile devices, which may not have sufficient capabilities to implement resource-demanding semantic encoder/decoder based on deep learning. To address this issue, we propose in this paper a new semantic relay (SemRelay), which is equipped with a semantic receiver to assist multiuser text transmissions. Specifically, the SemRelay decodes semantic information from a base station and forwards it to the users using conventional bit transmission, hence effectively improving text transmission efficiency. To study the multiuser resource allocation, we formulate an optimization problem to maximize the multiuser weighted sum-rate by jointly designing the SemRelay transmit power allocation and system bandwidth allocation. Although this problem is non-convex and hence challenging to solve, we propose an efficient algorithm to obtain its high-quality suboptimal solution by using the block coordinate descent method. Last, numerical results show the effectiveness of the proposed algorithm as well as superior performance of the proposed SemRelay over the conventional decode-and-forward (DF) relay, especially in small bandwidth region.
</details>
<details>
<summary>摘要</summary>
semantic communication (SemCom) 是一种出现在技术中，它从数据中提取有用的意义并仅发送相关的semantic信息。因此，它在传统的无线系统中的频率效率可以得到改进，特别是在低信号响应率（SNR）和小带宽区域。然而，现有的工作都很少考虑了移动设备的限制，它们可能没有充分的能力来实现深度学习基于的 semantic编码/解码器。为解决这个问题，我们在本文提出了一种新的semantic relay（SemRelay），它装备了semantic接收器，以帮助多用户文本传输。具体来说，SemRelay从基站中解码semantic信息，并将其转发给用户 mediante conventional bit transmission，从而有效地提高文本传输效率。为了研究多用户资源分配，我们建立了一个优化问题，以最大化多用户权重合并率。尽管这个问题是非核心的，但我们提出了一种高效的算法，使用块均衡下降法来获得其高质量的偏函数解。最后，数值结果表明了提案的算法的有效性以及SemRelay对传统的decode-and-forward（DF）关系的superior性，特别是在小带宽区域。
</details></li>
</ul>
<hr>
<h2 id="Coexistence-of-OTFS-Modulation-With-OFDM-based-Communication-Systems"><a href="#Coexistence-of-OTFS-Modulation-With-OFDM-based-Communication-Systems" class="headerlink" title="Coexistence of OTFS Modulation With OFDM-based Communication Systems"></a>Coexistence of OTFS Modulation With OFDM-based Communication Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06850">http://arxiv.org/abs/2311.06850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akram Shafie, Jinhong Yuan, Yuting Fang, Paul Fitzpatrick, Taka Sakurai</li>
<li>for: 本研究探讨了Orthogonal Time-Frequency Space（OTFS）模ulation在当前第四代和第五代（4G&#x2F;5G）无线通信系统中的合作。</li>
<li>methods: 我们首先 derivated OTFS signal的输入输出关系（IOR），并考虑了CPs的不同长度对OTFS信号的影响。我们还提出了一种基于嵌入式测试点的渠道估计技术，以便在合作系统中准确地 caracterize the channel。</li>
<li>results: 我们通过数字结果显示，在忽略CPs的不同长度时，OTFS信号在共存系统中的错误比率性能会下降。此外，我们还证明了我们提出的渠道估计技术在OTFS信号中的共存系统中能够超过当前状态的阈值基于渠道估计技术。<details>
<summary>Abstract</summary>
This study examines the coexistence of orthogonal time-frequency space (OTFS) modulation with current fourth- and fifth-generation (4G/5G) wireless communication systems that primarily use orthogonal frequency-division multiplexing (OFDM) waveforms. We first derive the input-output-relation (IOR) of OTFS when it coexists with an OFDM system while considering the impact of unequal lengths of the cyclic prefixes (CPs) in the OTFS signal. We show analytically that the inclusion of multiple CPs to the OTFS signal results in the effective sampled delay-Doppler (DD) domain channel response to be less sparse. We also show that the effective DD domain channel coefficients for OTFS in coexisting systems are influenced by the unequal lengths of the CPs. Subsequently, we propose an embedded pilot-aided channel estimation (CE) technique for OTFS in coexisting systems that leverages the derived IOR for accurate channel characterization. Using numerical results, we show that ignoring the impact of unequal lengths of the CPs during signal detection can degrade the bit error rate performance of OTFS in coexisting systems. We also show that the proposed CE technique for OTFS in coexisting systems outperforms the state-of-the-art threshold-based CE technique.
</details>
<details>
<summary>摘要</summary>
Translation:这个研究研究了 fourth-和 fifth-generation (4G/5G) 无线通信系统中 orthogonal time-frequency space (OTFS) 模ulation的共存。我们首先 derive OTFS 在共存系统中的输入-输出关系 (IOR)，并考虑了 OTFS 信号中不同的循环前缀 (CP) 的不同长度对共存系统的影响。我们显示了 analytically ，将多个 CP 添加到 OTFS 信号中会使共存系统的快速傅立叶频域频率响应变得更加稀疏。此外，我们还显示了 OTFS 在共存系统中的有效快速傅立叶频域通道响应被 CP 的不同长度所影响。然后，我们提出了一种基于嵌入式测试器的 OTFS 在共存系统中的频道估计 (CE) 技术，该技术利用了我们Derived IOR 实现了准确的频道特征化。使用数字结果，我们显示了忽略共存系统中 CP 的不同长度时 during signal detection 可能会导致 OTFS 的比特错误率性能下降。此外，我们还显示了我们提出的 CE 技术在共存系统中的 OTFS 性能高于当前的阈值基于 CE 技术。
</details></li>
</ul>
<hr>
<h2 id="Joint-Design-of-Coding-and-Modulation-for-Digital-Over-the-Air-Computation"><a href="#Joint-Design-of-Coding-and-Modulation-for-Digital-Over-the-Air-Computation" class="headerlink" title="Joint Design of Coding and Modulation for Digital Over-the-Air Computation"></a>Joint Design of Coding and Modulation for Digital Over-the-Air Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06829">http://arxiv.org/abs/2311.06829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Xie, Cunqinq Hua, Jianan Hong, Yuejun Wei</li>
<li>For: 本文提出了一种基于数字系统的空中计算（AirComp）传输技术，以提高AirComp在复杂无线环境中的可靠性和可扩展性。* Methods: 本文提出了一种基于非二进制LDPC编码的通道编码方案，以增强AirComp的错误修复能力。此外，本文还提出了一种基于阈值编码技术的数字化模调方案，以实现多发送器的数量之和。* Results: 本文提供了仪表结果，以证明提议的设计的可行性和性能。<details>
<summary>Abstract</summary>
Due to its high communication efficiency, over-the-air computation (AirComp) has been expected to carry out various computing tasks in the next-generation wireless networks. However, up to now, most applications of AirComp are explored in the analog domain, which limits the capability of AirComp in resisting the complex wireless environment, not to mention to integrate the AirComp technique to the existing universal communication standards, most of which are based on the digital system. In this paper, we propose a joint design of channel coding and digital modulation for digital AirComp transmission to attempt to reinforce the foundation for the application of AirComp in the digital system. Specifically, we first propose a non-binary LDPC-based channel coding scheme to enhance the error-correction capability of AirComp. Then, a digital modulation scheme is proposed to achieve the number summation from multiple transmitters via the lattice coding technique. We also provide simulation results to demonstrate the feasibility and the performance of the proposed design.
</details>
<details>
<summary>摘要</summary>
由于它的高通信效率，无线计算（AirComp）已被预期在下一代无线网络中执行多种计算任务。然而，至今为止，大多数AirComp应用都是在分析频域中进行的，这限制了AirComp在复杂无线环境中的可扩展性，更不能说明将AirComp技术与现有的通用通信标准集成。在这篇论文中，我们提议一种合理的渠道编码和数字化调制的结合方案，以强化AirComp在数字系统中的基础。具体来说，我们首先提议一种非二进制LDPC编码方案，以增强AirComp的错误恢复能力。然后，我们提议一种数字化调制方案，通过笛卡尔编码技术实现多个发送器的数字加法。我们还提供了临场实验结果，以证明提议的设计的可行性和性能。
</details></li>
</ul>
<hr>
<h2 id="Secure-Rate-Splitting-Multiple-Access-Transmissions-in-LMS-Systems"><a href="#Secure-Rate-Splitting-Multiple-Access-Transmissions-in-LMS-Systems" class="headerlink" title="Secure Rate-Splitting Multiple Access Transmissions in LMS Systems"></a>Secure Rate-Splitting Multiple Access Transmissions in LMS Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06825">http://arxiv.org/abs/2311.06825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minjue He, Hui Zhao, Xiaqing Miao, Shuai Wang, Gaofeng Pan</li>
<li>for:  investigate the secure delivery performance of the rate-splitting multiple access scheme in land mobile satellite (LMS) systems</li>
<li>methods:  adopt Maximum ratio transmission (MRT) and matched-filtering (MF) precoding techniques at the satellite, based on the estimated LMS channels suffering from the Shadowed-Rician fading</li>
<li>results:  derive closed-form expressions for the ergodic rates for decoding the common messages (CM) and private messages (PM) at the intended user, as well as the ergodic secrecy rate against eavesdropping, and provide numerical results to validate the analysis models and show interesting comparisons.Here’s the summary in Traditional Chinese:</li>
<li>for: 研究陆上通信卫星系统（LMS）中的稳定多存取网络传输性能，特别是当私人讯息被抓取者所抓取时</li>
<li>methods: 采用陆上用户的单束天线，并在天线上运用最大比率传输（MRT）和匹配滤波（MF）的 precoding 技术，基于预测的 LMS 通道受到阴影折射混合噪声</li>
<li>results:  derivate 关于传输率的关键表达式，包括传输率、私人讯息传输率和机密私人讯息传输率，并提供数值结果来验证分析模型，以及展示一些有趣的比较I hope this helps!<details>
<summary>Abstract</summary>
This letter investigates the secure delivery performance of the rate-splitting multiple access scheme in land mobile satellite (LMS) systems, considering that the private messages intended by a terminal can be eavesdropped by any others from the broadcast signals. Specifically, the considered system has an N-antenna satellite and numerous single-antenna land users. Maximum ratio transmission (MRT) and matched-filtering (MF) precoding techniques are adopted at the satellite separately for the common messages (CMs) and for the private messages (PMs), which are both implemented based on the estimated LMS channels suffering from the Shadowed-Rician fading. Then, closed-form expressions are derived for the ergodic rates for decoding the CM, and for decoding the PM at the intended user respectively, and more importantly, we also derive the ergodic secrecy rate against eavesdropping. Finally, numerical results are provided to validate the correctness of the proposed analysis models, as well as to show some interesting comparisons.
</details>
<details>
<summary>摘要</summary>
这封信函通过研究在陆地手机卫星（LMS）系统中的稳定交付性表现来调查率分访问方案，具体来说，系统具有N个天线的卫星和多个单天线的地面用户。在卫星上，我们采用最大比率传输（MRT）和匹配滤波（MF） precoding技术来进行通用消息（CM）和专用消息（PM）的编码，这两种技术都基于卫星通道的估计，卫星通道受到阴影-瑞德抽象扰干。然后，我们得到了对CM的有效比特率和对PM的有效比特率的关闭式表达，以及对听到者进行窃听的安全秘密率。最后，我们提供了数值结果来验证我们的分析模型，并且展示了一些有趣的比较。
</details></li>
</ul>
<hr>
<h2 id="Compressive-Sensing-Based-Grant-Free-Massive-Access-for-6G-Massive-Communication"><a href="#Compressive-Sensing-Based-Grant-Free-Massive-Access-for-6G-Massive-Communication" class="headerlink" title="Compressive Sensing-Based Grant-Free Massive Access for 6G Massive Communication"></a>Compressive Sensing-Based Grant-Free Massive Access for 6G Massive Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06770">http://arxiv.org/abs/2311.06770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Gao, Malong Ke, Yikun Mei, Li Qiao, Sheng Chen, Derrick Wing Kwan Ng, H. Vincent Poor</li>
<li>for: 本研究旨在探讨6G无线通信技术中的巨量访问问题，以实现未来的 ubiqueconnectivity vision。</li>
<li>methods: 本文主要介绍了 compressive sensing 技术在 grant-free 巨量访问方面的应用前景，包括从单antenna到大规模antenna数组基站、从单站到协作多Input多Output系统、以及从无源到源 rand access 场景的演化。</li>
<li>results: 本文预测了 grant-free 巨量访问的未来研究方向，包括巨量访问技术的进一步开发和应用。<details>
<summary>Abstract</summary>
The advent of the sixth-generation (6G) of wireless communications has given rise to the necessity to connect vast quantities of heterogeneous wireless devices, which requires advanced system capabilities far beyond existing network architectures. In particular, such massive communication has been recognized as a prime driver that can empower the 6G vision of future ubiquitous connectivity, supporting Internet of Human-Machine-Things for which massive access is critical. This paper surveys the most recent advances toward massive access in both academic and industry communities, focusing primarily on the promising compressive sensing-based grant-free massive access paradigm. We first specify the limitations of existing random access schemes and reveal that the practical implementation of massive communication relies on a dramatically different random access paradigm from the current ones mainly designed for human-centric communications. Then, a compressive sensing-based grant-free massive access roadmap is presented, where the evolutions from single-antenna to large-scale antenna array-based base stations, from single-station to cooperative massive multiple-input multiple-output systems, and from unsourced to sourced random access scenarios are detailed. Finally, we discuss the key challenges and open issues to shed light on the potential future research directions of grant-free massive access.
</details>
<details>
<summary>摘要</summary>
六代无线通信技术的出现（6G）已经导致了迫切需要连接各种不同的无线设备，这需要进一步的系统功能，远超现有网络架构。特别是，这种大规模通信被认为是未来无限连接性的核心驱动力，支持人机机器互联网，它们的大规模访问是关键。本文 survey了最新的大规模访问技术发展，主要关注 compressive sensing 基于的免费大规模访问方案。我们首先描述了现有随机访问方案的限制，并显示了现有随机访问方案主要是为人类通信而设计的。然后，我们提出了 compressive sensing 基于的免费大规模访问路线图，包括从单antenna到大规模天线阵列基站、从单站到合作大规模多输入多出力系统、和从无源到源随机访问场景的演化。最后，我们讨论了关键挑战和未解决问题，以照明未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="One-Signal-Noise-Separation-based-Wiener-Filter-for-Magnetogastrogram"><a href="#One-Signal-Noise-Separation-based-Wiener-Filter-for-Magnetogastrogram" class="headerlink" title="One Signal-Noise Separation based Wiener Filter for Magnetogastrogram"></a>One Signal-Noise Separation based Wiener Filter for Magnetogastrogram</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06739">http://arxiv.org/abs/2311.06739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hua Li</li>
<li>for: 这 paper 是为了提高Magnetogastrogram (MGG) signal detection中的噪声抑制和信号分离。</li>
<li>methods: 这 paper 使用了一种新的信号处理框架，即基于信号噪声分离的维ener filters (SNSWF)，以提高维ener filters 输出的噪声比例。</li>
<li>results: 使用SNSWFfilter，可以提高MGG signal detection中的信号噪声比例，相比 классический维ener filters，SNSWFfilter 的filter SNR高出16.7 dB。<details>
<summary>Abstract</summary>
Magnetogastrogram (MGG) signal frequency is about 0.05 Hz, the low-frequency environmental noise interference is serious and can be several times stronger in magnitude than the signals of interest and may severely impede the extraction of relevant information. Wiener filter is one classic denoising solution for biomagnetic applications. Since the reference channels are usually placed not far enough from the biomagnetic sources under test, they will inevitably detect the signals and the Wiener filters may produce ill-conditioned solutions. Considering the solutions to improve the signal-to-noise ratio (SNR) of Wiener filter output, there are few methods to separate the signals from the noises of the reference signal at the filter input. In this paper, a new signal processing framework called signal-noise separation based Wiener filter (SNSWF) is proposed that it separates the main noise as the input signal of the filter to improve the output SNR of Wiener filter. The filter was successfully applied to the noise suppression for MGG signal detection. Using the SNSWF, the filter SNR is 16.7 dB better than the classic Wiener filter.
</details>
<details>
<summary>摘要</summary>
магнитогастрограм（MGG）信号频率约为0.05Hz，低频环境干扰强度较高，可能比有兴趣信号强度多倍，严重阻碍了有关信息的提取。wiener filter是生物磁学应用中一种经典的干扰除解决方案。由于参照通道通常不会在测试biomagnetic sources的位置够近，因此它们会检测信号，wiener filter可能会生成不正确的解决方案。为了提高wiener filter输出的信号噪听比（SNR），有几种方法可以从filter输入分离信号和噪声。在本文中，一种新的信号处理框架被提出，称为信号噪声分离based Wiener filter（SNSWF）。它可以将主要噪声作为输入信号，以提高wiener filter输出的SNR。这个filter成功应用于MGG信号检测中的噪声抑制。使用SNSWF，filter SNR比 классиwiener filter高16.7dB。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/12/eess.SP_2023_11_12/" data-id="clp9qz8hk01hook882a8bcne0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/11/cs.CV_2023_11_11/" class="article-date">
  <time datetime="2023-11-11T13:00:00.000Z" itemprop="datePublished">2023-11-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/11/cs.CV_2023_11_11/">cs.CV - 2023-11-11</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="3DFusion-A-real-time-3D-object-reconstruction-pipeline-based-on-streamed-instance-segmented-data"><a href="#3DFusion-A-real-time-3D-object-reconstruction-pipeline-based-on-streamed-instance-segmented-data" class="headerlink" title="3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data"></a>3DFusion, A real-time 3D object reconstruction pipeline based on streamed instance segmented data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06659">http://arxiv.org/abs/2311.06659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xi Sun, Derek Jacoby, Yvonne Coady<br>for:这篇论文旨在提供一个实时分割和重建系统，该系统使用RGB-D图像来生成准确和详细的indoor环境中对象的三维模型。methods:该系统采用了当今最佳实例分割技术，对RGB-D数据进行像素级分割，以分割背景和前景对象。然后，通过高性能计算平台，对分割的对象进行三维重建。results:该系统可以实现实时三维模elling，并且可以应用于各种领域，如增强现实&#x2F;虚拟现实、内部设计、城市规划、公路协助、安全系统等。为了实现实时性，论文提出了一种方法，通过采样连续帧来减少网络负担，保证重建质量。此外，该系统采用了并行SLAM管道，以高效地将分割对象切割成个体。该系统使用了领先的框架YOLO进行实例分割，并对YOLO进行修改，以解决类似对象的重复或假检测问题，确保重建模型与目标对象保持一致。总之，该工作建立了一个可靠的实时系统，对indoor环境中对象的分割和重建进行了显著提高。它可能会扩展到户外场景，开启了许多实际应用的可能性。<details>
<summary>Abstract</summary>
This paper presents a real-time segmentation and reconstruction system that utilizes RGB-D images to generate accurate and detailed individual 3D models of objects within a captured scene. Leveraging state-of-the-art instance segmentation techniques, the system performs pixel-level segmentation on RGB-D data, effectively separating foreground objects from the background. The segmented objects are then reconstructed into distinct 3D models in a high-performance computation platform. The real-time 3D modelling can be applied across various domains, including augmented/virtual reality, interior design, urban planning, road assistance, security systems, and more. To achieve real-time performance, the paper proposes a method that effectively samples consecutive frames to reduce network load while ensuring reconstruction quality. Additionally, a multi-process SLAM pipeline is adopted for parallel 3D reconstruction, enabling efficient cutting of the clustering objects into individuals. This system employs the industry-leading framework YOLO for instance segmentation. To improve YOLO's performance and accuracy, modifications were made to resolve duplicated or false detection of similar objects, ensuring the reconstructed models align with the targets. Overall, this work establishes a robust real-time system with a significant enhancement for object segmentation and reconstruction in the indoor environment. It can potentially be extended to the outdoor scenario, opening up numerous opportunities for real-world applications.
</details>
<details>
<summary>摘要</summary>
To achieve real-time performance, the paper proposes a method that effectively samples consecutive frames to reduce network load while ensuring reconstruction quality. Additionally, a multi-process SLAM pipeline is adopted for parallel 3D reconstruction, enabling efficient cutting of the clustering objects into individuals. The system employs the industry-leading framework YOLO for instance segmentation, with modifications made to resolve duplicated or false detection of similar objects, ensuring the reconstructed models align with the targets.Overall, this work establishes a robust real-time system with a significant enhancement for object segmentation and reconstruction in the indoor environment. It can potentially be extended to the outdoor scenario, opening up numerous opportunities for real-world applications.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-and-semi-supervised-co-salient-object-detection-via-segmentation-frequency-statistics"><a href="#Unsupervised-and-semi-supervised-co-salient-object-detection-via-segmentation-frequency-statistics" class="headerlink" title="Unsupervised and semi-supervised co-salient object detection via segmentation frequency statistics"></a>Unsupervised and semi-supervised co-salient object detection via segmentation frequency statistics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06654">http://arxiv.org/abs/2311.06654</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sourachakra/uscosod-sscosod">https://github.com/sourachakra/uscosod-sscosod</a></li>
<li>paper_authors: Souradeep Chakraborty, Shujon Naha, Muhammet Bastan, Amit Kumar K C, Dimitris Samaras</li>
<li>for: 本文提出了一种不需要监督的对象共同突出物检测方法（CoSOD），用于检测图像集中的共同突出物。</li>
<li>methods: 本文使用了自动学习的自编码器和自注意力机制，将图像分割成不同类别的单个像素，并计算每个类别的对象共同突出度。</li>
<li>results: 本文的方法可以在不具备监督的情况下，基于图像集的频率统计学习，实现高度精度的对象共同突出物检测。 compared with existing methods, the proposed method has a significant improvement in performance.<details>
<summary>Abstract</summary>
In this paper, we address the detection of co-occurring salient objects (CoSOD) in an image group using frequency statistics in an unsupervised manner, which further enable us to develop a semi-supervised method. While previous works have mostly focused on fully supervised CoSOD, less attention has been allocated to detecting co-salient objects when limited segmentation annotations are available for training. Our simple yet effective unsupervised method US-CoSOD combines the object co-occurrence frequency statistics of unsupervised single-image semantic segmentations with salient foreground detections using self-supervised feature learning. For the first time, we show that a large unlabeled dataset e.g. ImageNet-1k can be effectively leveraged to significantly improve unsupervised CoSOD performance. Our unsupervised model is a great pre-training initialization for our semi-supervised model SS-CoSOD, especially when very limited labeled data is available for training. To avoid propagating erroneous signals from predictions on unlabeled data, we propose a confidence estimation module to guide our semi-supervised training. Extensive experiments on three CoSOD benchmark datasets show that both of our unsupervised and semi-supervised models outperform the corresponding state-of-the-art models by a significant margin (e.g., on the Cosal2015 dataset, our US-CoSOD model has an 8.8% F-measure gain over a SOTA unsupervised co-segmentation model and our SS-CoSOD model has an 11.81% F-measure gain over a SOTA semi-supervised CoSOD model).
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们 Addresses the detection of co-occurring salient objects (CoSOD) in an image group using frequency statistics in an unsupervised manner, which further enables us to develop a semi-supervised method. Previous works have mostly focused on fully supervised CoSOD, but less attention has been allocated to detecting co-salient objects when limited segmentation annotations are available for training. Our simple yet effective unsupervised method US-CoSOD combines the object co-occurrence frequency statistics of unsupervised single-image semantic segmentations with salient foreground detections using self-supervised feature learning. For the first time, we show that a large unlabeled dataset e.g. ImageNet-1k can be effectively leveraged to significantly improve unsupervised CoSOD performance. Our unsupervised model is a great pre-training initialization for our semi-supervised model SS-CoSOD, especially when very limited labeled data is available for training. To avoid propagating erroneous signals from predictions on unlabeled data, we propose a confidence estimation module to guide our semi-supervised training. Extensive experiments on three CoSOD benchmark datasets show that both of our unsupervised and semi-supervised models outperform the corresponding state-of-the-art models by a significant margin (e.g., on the Cosal2015 dataset, our US-CoSOD model has an 8.8% F-measure gain over a SOTA unsupervised co-segmentation model and our SS-CoSOD model has an 11.81% F-measure gain over a SOTA semi-supervised CoSOD model).Here's the translation in Traditional Chinese:在这篇论文中，我们 Addresses the detection of co-occurring salient objects (CoSOD) in an image group using frequency statistics in an unsupervised manner, which further enables us to develop a semi-supervised method. 前一些工作主要集中在完全supervised CoSOD，但是对于有限的分类标注available for training时，对于检测共同突出的物件更少的注意力。我们的简单 yet effective unsupervised method US-CoSOD combines the object co-occurrence frequency statistics of unsupervised single-image semantic segmentations with salient foreground detections using self-supervised feature learning. 我们首次显示了一个大量的无标注数据集例如ImageNet-1k可以对不supervised CoSOD performance进行明显改善。我们的无supervised model是一个优秀的预训初始化 для我们的半supervised model SS-CoSOD，特别是当有很少的标注数据available for training时。为了避免对无标注数据预测中的错误信号传播，我们提出了一个信任估计模组来引导我们的半supervised训练。广泛的实验表明我们的无supervised和半supervised模型在三个CoSOD benchmark dataset上都大比前一些state-of-the-art模型进行了明显改善 (e.g., on the Cosal2015 dataset, our US-CoSOD model has an 8.8% F-measure gain over a SOTA unsupervised co-segmentation model and our SS-CoSOD model has an 11.81% F-measure gain over a SOTA semi-supervised CoSOD model).
</details></li>
</ul>
<hr>
<h2 id="Traffic-Sign-Recognition-Using-Local-Vision-Transformer"><a href="#Traffic-Sign-Recognition-Using-Local-Vision-Transformer" class="headerlink" title="Traffic Sign Recognition Using Local Vision Transformer"></a>Traffic Sign Recognition Using Local Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06651">http://arxiv.org/abs/2311.06651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Farzipour, Omid Nejati Manzari, Shahriar B. Shokouhi</li>
<li>for: 提高自驾车和驾手助手系统中的交通标志识别率</li>
<li>methods:  combining convolutional blocks和 transformer-based blocks，并添加了一个局部模块以提高局部感知</li>
<li>results: 在德国交通标志识别benchmark和波斯尼亚交通标志数据集上达到了99.66%和99.8%的准确率，高于最佳 convolutional models，同时具有快速推理速度和实际应用场景适用性。<details>
<summary>Abstract</summary>
Recognition of traffic signs is a crucial aspect of self-driving cars and driver assistance systems, and machine vision tasks such as traffic sign recognition have gained significant attention. CNNs have been frequently used in machine vision, but introducing vision transformers has provided an alternative approach to global feature learning. This paper proposes a new novel model that blends the advantages of both convolutional and transformer-based networks for traffic sign recognition. The proposed model includes convolutional blocks for capturing local correlations and transformer-based blocks for learning global dependencies. Additionally, a locality module is incorporated to enhance local perception. The performance of the suggested model is evaluated on the Persian Traffic Sign Dataset and German Traffic Sign Recognition Benchmark and compared with SOTA convolutional and transformer-based models. The experimental evaluations demonstrate that the hybrid network with the locality module outperforms pure transformer-based models and some of the best convolutional networks in accuracy. Specifically, our proposed final model reached 99.66% accuracy in the German traffic sign recognition benchmark and 99.8% in the Persian traffic sign dataset, higher than the best convolutional models. Moreover, it outperforms existing CNNs and ViTs while maintaining fast inference speed. Consequently, the proposed model proves to be significantly faster and more suitable for real-world applications.
</details>
<details>
<summary>摘要</summary>
自驾车和助手系统中识别交通标识是一项关键性的任务，机器视觉任务如交通标识已经吸引了广泛的关注。CNNs在机器视觉中经常被使用，但是引入视Transformers提供了一种全局特征学习的替代方法。这篇论文提议了一种新的 hybrid 模型，将 convolutional 块和 transformer-based 块结合在一起，以便捕捉本地相关性和全球依赖关系。此外，还包含了一个 locality 模块，以增强本地感知。提议的模型在 Persian Traffic Sign Dataset 和 German Traffic Sign Recognition Benchmark 上进行了实验评估，与 SOTA  convolutional 和 transformer-based 模型进行比较。实验结果表明，提议的 hybrid 网络在准确率方面与最佳 convolutional 模型和一些 transformer-based 模型相当，而且具有更快的推理速度。特别是，我们的最终模型在 German traffic sign recognition benchmark 上达到了 99.66% 的准确率，而 Persian traffic sign dataset 上达到了 99.8%。此外，它还超越了现有的 CNNs 和 ViTs，而且保持了快速的推理速度。因此，我们的提议模型在实际应用中具有优势。
</details></li>
</ul>
<hr>
<h2 id="Back-to-Basics-Fast-Denoising-Iterative-Algorithm"><a href="#Back-to-Basics-Fast-Denoising-Iterative-Algorithm" class="headerlink" title="Back to Basics: Fast Denoising Iterative Algorithm"></a>Back to Basics: Fast Denoising Iterative Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06634">http://arxiv.org/abs/2311.06634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deborah Pereg</li>
<li>for: 降低噪音，提高图像质量</li>
<li>methods: 使用Back to Basics（BTB）快迭代算法，不需训练或真实数据，可应用于独立噪音和相关噪音环境中</li>
<li>results: 对三个研究 caso进行了实验，包括自然图像噪音纠正、POisson分布图像纠正和optical coherence tomography（OCT）干涉抑制，实验结果表明提案方法可以有效提高图像质量，在噪音设定中展现出良好的性能，并提供了理论保证。<details>
<summary>Abstract</summary>
We introduce Back to Basics (BTB), a fast iterative algorithm for noise reduction. Our method is computationally efficient, does not require training or ground truth data, and can be applied in the presence of independent noise, as well as correlated (coherent) noise, where the noise level is unknown. We examine three study cases: natural image denoising in the presence of additive white Gaussian noise, Poisson-distributed image denoising, and speckle suppression in optical coherence tomography (OCT). Experimental results demonstrate that the proposed approach can effectively improve image quality, in challenging noise settings. Theoretical guarantees are provided for convergence stability.
</details>
<details>
<summary>摘要</summary>
我们介绍Back to Basics（BTB）算法，它是一种快速迭代的噪声减少方法。我们的方法不需要训练或真实数据，可以在独立噪声和相关噪声（相对干扰）的情况下应用，而且噪声水平未知。我们在自然图像噪声 removing中使用了三个研究 caso：在添加白噪声的情况下的自然图像净化、Poisson分布图像净化和optical coherence tomography（OCT）中的斑点消除。实验结果表明，我们提出的方法可以有效地提高图像质量，在具有挑战性噪声的情况下。我们也提供了理论保证对 converges 稳定性。
</details></li>
</ul>
<hr>
<h2 id="A-3D-Conditional-Diffusion-Model-for-Image-Quality-Transfer-–-An-Application-to-Low-Field-MRI"><a href="#A-3D-Conditional-Diffusion-Model-for-Image-Quality-Transfer-–-An-Application-to-Low-Field-MRI" class="headerlink" title="A 3D Conditional Diffusion Model for Image Quality Transfer – An Application to Low-Field MRI"></a>A 3D Conditional Diffusion Model for Image Quality Transfer – An Application to Low-Field MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06631">http://arxiv.org/abs/2311.06631</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/edshkim98/diffusioniqt">https://github.com/edshkim98/diffusioniqt</a></li>
<li>paper_authors: Seunghoi Kim, Henry F. J. Tregidgo, Ahmed K. Eldaly, Matteo Figini, Daniel C. Alexander</li>
<li>for: 提高低场磁共振成像质量</li>
<li>methods: 使用3Dconditional扩散模型和cross-batch机制提高自注意力和填充</li>
<li>results: 在HCP数据集上比较出色，远超过现有方法 both quantitatively and qualitatively<details>
<summary>Abstract</summary>
Low-field (LF) MRI scanners (<1T) are still prevalent in settings with limited resources or unreliable power supply. However, they often yield images with lower spatial resolution and contrast than high-field (HF) scanners. This quality disparity can result in inaccurate clinician interpretations. Image Quality Transfer (IQT) has been developed to enhance the quality of images by learning a mapping function between low and high-quality images. Existing IQT models often fail to restore high-frequency features, leading to blurry output. In this paper, we propose a 3D conditional diffusion model to improve 3D volumetric data, specifically LF MR images. Additionally, we incorporate a cross-batch mechanism into the self-attention and padding of our network, ensuring broader contextual awareness even under small 3D patches. Experiments on the publicly available Human Connectome Project (HCP) dataset for IQT and brain parcellation demonstrate that our model outperforms existing methods both quantitatively and qualitatively. The code is publicly available at \url{https://github.com/edshkim98/DiffusionIQT}.
</details>
<details>
<summary>摘要</summary>
低场（LF）MRI仪器（<1T）仍然广泛用于具有限制的资源或不可靠的电力供应的设置。然而，它们经常生成图像的空间分辨率和对比度较低，从而导致临床医生的解释不准确。图像质量传输（IQT）已经被开发来提高图像质量，学习映射函数 между低质量和高质量图像。现有的IQT模型经常无法恢复高频特征，导致输出模糊不清。在这篇论文中，我们提议一种3D条件扩散模型，用于改进3D积分数据，特别是LF MR图像。此外，我们在网络中包含了跨批机制，使其在小3D片段中保持更广泛的Contextual awareness。实验结果表明，我们的模型在公共可用的人类连接组计划（HCP）数据集上的IQT和脑分割 task中，与现有方法相比，具有较高的数量和质量性能。代码可以在 \url{https://github.com/edshkim98/DiffusionIQT} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Computer-Vision-for-Particle-Size-Analysis-of-Coarse-Grained-Soils"><a href="#Computer-Vision-for-Particle-Size-Analysis-of-Coarse-Grained-Soils" class="headerlink" title="Computer Vision for Particle Size Analysis of Coarse-Grained Soils"></a>Computer Vision for Particle Size Analysis of Coarse-Grained Soils</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06613">http://arxiv.org/abs/2311.06613</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sompote Youwai, Parchya Makam</li>
<li>for: 本研究用computer vision技术和Python编程语言进行粒子大小分析，以提高土壤物理特性的评估效率。</li>
<li>methods: 使用OPENCV库对普通照明条件下拍摄的土壤粒子进行检测和测量，并使用标准手持式摄像头。</li>
<li>results: 相比传统筛分分析方法，该方法在大于2mm粒子上表现出良好的准确性（MAPE约6%），但是小于2mm粒子的MAPE可达60%，建议使用更高分辨率的摄像头进行拍摄。<details>
<summary>Abstract</summary>
Particle size analysis (PSA) is a fundamental technique for evaluating the physical characteristics of soils. However, traditional methods like sieving can be time-consuming and labor-intensive. In this study, we present a novel approach that utilizes computer vision (CV) and the Python programming language for PSA of coarse-grained soils, employing a standard mobile phone camera. By eliminating the need for a high-performance camera, our method offers convenience and cost savings. Our methodology involves using the OPENCV library to detect and measure soil particles in digital photographs taken under ordinary lighting conditions. For accurate particle size determination, a calibration target with known dimensions is placed on a plain paper alongside 20 different sand samples. The proposed method is compared with traditional sieve analysis and exhibits satisfactory performance for soil particles larger than 2 mm, with a mean absolute percent error (MAPE) of approximately 6%. However, particles smaller than 2 mm result in higher MAPE, reaching up to 60%. To address this limitation, we recommend using a higher-resolution camera to capture images of the smaller soil particles. Furthermore, we discuss the advantages, limitations, and potential future improvements of our method. Remarkably, the program can be executed on a mobile phone, providing immediate results without the need to send soil samples to a laboratory. This field-friendly feature makes our approach highly convenient for on-site usage, outside of a traditional laboratory setting. Ultimately, this novel method represents an initial disruption to the industry, enabling efficient particle size analysis of soil without the reliance on laboratory-based sieve analysis. KEYWORDS: Computer vision, Grain size, ARUCO
</details>
<details>
<summary>摘要</summary>
计量粒子分析（PSA）是土壤物理特性的基本技术。然而，传统方法如筛分可能是时间consuming和人力成本高。在这项研究中，我们提出了一种新的方法，利用计算机视觉（CV）和Python编程语言进行PSA，使用标准的移动电话摄像头。它消除了高性能摄像头的需求，从而提供了便利和成本节省。我们的方法ология是使用OPENCV库检测和测量在普通照明条件下拍摄的土壤粒子。为了准确地确定粒子大小，我们使用了一个标准化的检测目标，并与20个不同的砂样进行比较。我们的方法与传统筛分分析相比，对土壤粒子大于2毫米的粒子大小具有较好的性能，具有约6%的平均绝对百分比误差（MAPE）。然而，粒子小于2毫米的误差较高，可达60%。为了解决这个限制，我们建议使用更高分辨率的摄像头拍摄小粒子土壤。此外，我们还讨论了我们的方法的优缺点，以及未来可能的改进。值得注意的是，我们的方法可以在移动电话上执行，无需将土壤样本送往实验室进行分析。这种场地友好的特点使我们的方法在实验室外实现了高效的粒子分析。最后，我们的新方法代表了它在业界的初步干扰，允许不需要实验室基础的粒子分析。关键词：计算机视觉、粒子大小、ARUCO
</details></li>
</ul>
<hr>
<h2 id="Swin-UNETR-Advancing-Transformer-Based-Dense-Dose-Prediction-Towards-Fully-Automated-Radiation-Oncology-Treatments"><a href="#Swin-UNETR-Advancing-Transformer-Based-Dense-Dose-Prediction-Towards-Fully-Automated-Radiation-Oncology-Treatments" class="headerlink" title="Swin UNETR++: Advancing Transformer-Based Dense Dose Prediction Towards Fully Automated Radiation Oncology Treatments"></a>Swin UNETR++: Advancing Transformer-Based Dense Dose Prediction Towards Fully Automated Radiation Oncology Treatments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06572">http://arxiv.org/abs/2311.06572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kuancheng Wang, Hai Siong Tan, Rafe Mcbeth</li>
<li>For: The paper aims to develop a deep learning model for automating the creation of radiation treatment plans for cancer therapy.* Methods: The proposed model, called Swin UNETR++, uses a lightweight 3D Dual Cross-Attention (DCA) module to capture the intra and inter-volume relationships of each patient’s unique anatomy. The model was trained, validated, and tested on the Open Knowledge-Based Planning dataset.* Results: Swin UNETR++ demonstrates near-state-of-the-art performance on the validation and test datasets, with average volume-wise acceptance rates of 88.58% and 90.50%, and average patient-wise clinical acceptance rates of 100.0% and 98.0%. The results establish a basis for future studies to translate 3D dose predictions into a deliverable treatment plan, facilitating full automation.Here are the three points in Simplified Chinese text:* For: 本文旨在开发一种深度学习模型，用于自动生成 radiation therapy 的辐射治疗计划。* Methods: 提议的模型叫做 Swin UNETR++，它使用轻量级的 3D 双重跨参量 (DCA) 模块，以捕捉每个病人唯一的 анатомиче关系。模型在 Open Knowledge-Based Planning 数据集上进行了训练、验证和测试。* Results: Swin UNETR++ 在验证数据集和测试数据集上达到了 near-state-of-the-art 性能，具体来说，average volume-wise acceptance rate 为 88.58% 和 90.50%，average patient-wise clinical acceptance rate 为 100.0% 和 98.0%。结果为未来的研究提供了一个基础，以便将 3D 剂量预测翻译成可实施的治疗计划，实现了自动化。<details>
<summary>Abstract</summary>
The field of Radiation Oncology is uniquely positioned to benefit from the use of artificial intelligence to fully automate the creation of radiation treatment plans for cancer therapy. This time-consuming and specialized task combines patient imaging with organ and tumor segmentation to generate a 3D radiation dose distribution to meet clinical treatment goals, similar to voxel-level dense prediction. In this work, we propose Swin UNETR++, that contains a lightweight 3D Dual Cross-Attention (DCA) module to capture the intra and inter-volume relationships of each patient's unique anatomy, which fully convolutional neural networks lack. Our model was trained, validated, and tested on the Open Knowledge-Based Planning dataset. In addition to metrics of Dose Score $\overline{S_{\text{Dose}}$ and DVH Score $\overline{S_{\text{DVH}}$ that quantitatively measure the difference between the predicted and ground-truth 3D radiation dose distribution, we propose the qualitative metrics of average volume-wise acceptance rate $\overline{R_{\text{VA}}$ and average patient-wise clinical acceptance rate $\overline{R_{\text{PA}}$ to assess the clinical reliability of the predictions. Swin UNETR++ demonstrates near-state-of-the-art performance on validation and test dataset (validation: $\overline{S_{\text{DVH}}$=1.492 Gy, $\overline{S_{\text{Dose}}$=2.649 Gy, $\overline{R_{\text{VA}}$=88.58%, $\overline{R_{\text{PA}}$=100.0%; test: $\overline{S_{\text{DVH}}$=1.634 Gy, $\overline{S_{\text{Dose}}$=2.757 Gy, $\overline{R_{\text{VA}}$=90.50%, $\overline{R_{\text{PA}}$=98.0%), establishing a basis for future studies to translate 3D dose predictions into a deliverable treatment plan, facilitating full automation.
</details>
<details>
<summary>摘要</summary>
领域 Radiation Oncology 可以充分利用人工智能来自动生成抑肿治疗计划。这个时间consuming 和专业化的任务涉及到病人图像与器官和肿瘤分割，以生成符合临床治疗目标的3D辐射剂量分布。在这种工作中，我们提议Swin UNITR++模型，它包含了轻量级3D双交叉关注（DCA）模块，以捕捉每个患者独特的生物学结构关系。与普通的完全 convolutional neural networks 不同，这种模型可以更好地考虑患者的多个方面和尺度。我们的模型在Open Knowledge-Based Planning数据集上进行训练、验证和测试，并且使用了量化评价指标，包括辐射剂量分布的DOSE Score和DVH Score，以及评价预测结果的临床可靠性指标，包括平均体积级别接受率（RVA）和平均患者级别接受率（RPA）。Swin UNITR++在验证和测试数据集上达到了近似于状态之arte的性能（验证数据集：DOSE Score=1.492 Gy，DVH Score=2.649 Gy，RVA=88.58%，RPA=100.0%; 测试数据集：DOSE Score=1.634 Gy，DVH Score=2.757 Gy，RVA=90.50%，RPA=98.0%），为未来的研究提供了一个基础，以便将3D剂量预测翻译成可实施的治疗计划，实现全自动化。
</details></li>
</ul>
<hr>
<h2 id="OR-Residual-Connection-Achieving-Comparable-Accuracy-to-ADD-Residual-Connection-in-Deep-Residual-Spiking-Neural-Networks"><a href="#OR-Residual-Connection-Achieving-Comparable-Accuracy-to-ADD-Residual-Connection-in-Deep-Residual-Spiking-Neural-Networks" class="headerlink" title="OR Residual Connection Achieving Comparable Accuracy to ADD Residual Connection in Deep Residual Spiking Neural Networks"></a>OR Residual Connection Achieving Comparable Accuracy to ADD Residual Connection in Deep Residual Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06570">http://arxiv.org/abs/2311.06570</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ym-shan/orrc-syna-natural-pruning">https://github.com/ym-shan/orrc-syna-natural-pruning</a></li>
<li>paper_authors: Yimeng Shan, Xuerui Qiu, Rui-jie Zhu, Ruike Li, Meng Wang, Haicheng Qu</li>
<li>for: This paper aims to improve the performance and energy efficiency of deep residual spiking neural networks (SNNs) for brain-like computing.</li>
<li>methods: The authors introduce the OR Residual connection (ORRC) and the Synergistic Attention (SynA) module to the SEW-ResNet architecture, and integrate natural pruning to reduce computational overhead.</li>
<li>results: The enhanced OR-Spiking ResNet achieved single-sample classification with as little as 0.8 spikes per neuron, outperforming other spike residual models in accuracy and power consumption.Here is the same information in Simplified Chinese:</li>
<li>for: 这篇论文目标是改进深度待遇刺激神经网络（SNNs）的性能和能效性，用于脑类计算。</li>
<li>methods: 作者们引入 OR Residual connection（ORRC）和Synergistic Attention（SynA）模块到 SEW-ResNet 架构中，并实现自然减少计算开销。</li>
<li>results: 提升后的 OR-Spiking ResNet 实现单个样本分类，只需0.8个神经元发射，与其他刺激剩余模型相比，具有更高的准确率和更低的电力消耗。<details>
<summary>Abstract</summary>
Spiking Neural Networks (SNNs) have garnered substantial attention in brain-like computing for their biological fidelity and the capacity to execute energy-efficient spike-driven operations. As the demand for heightened performance in SNNs surges, the trend towards training deeper networks becomes imperative, while residual learning stands as a pivotal method for training deep neural networks. In our investigation, we identified that the SEW-ResNet, a prominent representative of deep residual spiking neural networks, incorporates non-event-driven operations. To rectify this, we introduce the OR Residual connection (ORRC) to the architecture. Additionally, we propose the Synergistic Attention (SynA) module, an amalgamation of the Inhibitory Attention (IA) module and the Multi-dimensional Attention (MA) module, to offset energy loss stemming from high quantization. When integrating SynA into the network, we observed the phenomenon of "natural pruning", where after training, some or all of the shortcuts in the network naturally drop out without affecting the model's classification accuracy. This significantly reduces computational overhead and makes it more suitable for deployment on edge devices. Experimental results on various public datasets confirmed that the SynA enhanced OR-Spiking ResNet achieved single-sample classification with as little as 0.8 spikes per neuron. Moreover, when compared to other spike residual models, it exhibited higher accuracy and lower power consumption. Codes are available at https://github.com/Ym-Shan/ORRC-SynA-natural-pruning.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）在脑如计算中备受关注，因其生物准确性和能效地执行脉冲驱动操作。随着深度SNN的需求增加，训练深度网络变得必要，而剩余学习成为训练深度网络的重要方法。在我们的研究中，我们发现SEW-ResNet，一种深度剩余神经网络的代表，包含非事件驱动操作。为解决这问题，我们引入了OR隐藏连接（ORRC）到架构中。此外，我们提出了协同注意（SynA）模块，它是禁忌注意模块和多维注意模块的组合，以弥补因高量化而导致的能量损失。在将SynA模块 incorporated into the network时，我们观察到了自然减少现象，即在训练后，网络中的减少减少自然而无需影响模型的分类精度。这显著减少计算开销，使其更适合边缘设备部署。实验结果表明，对多个公共数据集进行训练后，使用SynA进行增强的OR-Spiking ResNet可以在0.8脉冲每个神经元单个样本分类。此外，与其他脉冲剩余模型相比，它表现出更高的准确率和更低的能 consumption。代码可以在https://github.com/Ym-Shan/ORRC-SynA-natural-pruning中找到。
</details></li>
</ul>
<hr>
<h2 id="Artificial-Intelligence-in-Assessing-Cardiovascular-Diseases-and-Risk-Factors-via-Retinal-Fundus-Images-A-Review-of-the-Last-Decade"><a href="#Artificial-Intelligence-in-Assessing-Cardiovascular-Diseases-and-Risk-Factors-via-Retinal-Fundus-Images-A-Review-of-the-Last-Decade" class="headerlink" title="Artificial Intelligence in Assessing Cardiovascular Diseases and Risk Factors via Retinal Fundus Images: A Review of the Last Decade"></a>Artificial Intelligence in Assessing Cardiovascular Diseases and Risk Factors via Retinal Fundus Images: A Review of the Last Decade</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07609">http://arxiv.org/abs/2311.07609</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mirsaeed Abdollahi, Ali Jafarizadeh, Amirhosein Ghafouri Asbagh, Navid Sobhi, Keysan Pourmoghtader, Siamak Pedrammehr, Houshyar Asadi, Roohallah Alizadehsani, Ru-San Tan, U. Rajendra Acharya</li>
<li>For: The paper aims to provide an overview of the current advancements and challenges in employing retinal imaging and artificial intelligence to identify cardiovascular disorders.* Methods: The paper uses a comprehensive search of various databases, including PubMed, Medline, Google Scholar, Scopus, Web of Sciences, IEEE Xplore, and ACM Digital Library, to identify relevant publications related to cardiovascular diseases and artificial intelligence.* Results: The study includes 87 English-language publications that provide insights into the current state of research in this field and highlights the potential of AI and deep learning for early detection and prediction of cardiovascular diseases.Here are the three points in Simplified Chinese text:* For: 这篇论文目的是为了提供Cardiovascular diseases (CVDs)的现状和挑战，以及使用Retinal imaging和人工智能来识别CVDs的概述。* Methods: 这篇论文使用了多种数据库的检索，包括PubMed、Medline、Google Scholar、Scopus、Web of Sciences、IEEE Xplore和ACM Digital Library，以确定相关的Cardiovascular diseases和人工智能publications。* Results: 这篇论文包含87篇英文文献，提供了这个领域的当前进展和挑战，并指出了人工智能和深度学习在早期检测和预测Cardiovascular diseases方面的潜在潜力。<details>
<summary>Abstract</summary>
Background: Cardiovascular diseases (CVDs) continue to be the leading cause of mortality on a global scale. In recent years, the application of artificial intelligence (AI) techniques, particularly deep learning (DL), has gained considerable popularity for evaluating the various aspects of CVDs. Moreover, using fundus images and optical coherence tomography angiography (OCTA) to diagnose retinal diseases has been extensively studied. To better understand heart function and anticipate changes based on microvascular characteristics and function, researchers are currently exploring the integration of AI with non-invasive retinal scanning. Leveraging AI-assisted early detection and prediction of cardiovascular diseases on a large scale holds excellent potential to mitigate cardiovascular events and alleviate the economic burden on healthcare systems. Method: A comprehensive search was conducted across various databases, including PubMed, Medline, Google Scholar, Scopus, Web of Sciences, IEEE Xplore, and ACM Digital Library, using specific keywords related to cardiovascular diseases and artificial intelligence. Results: A total of 87 English-language publications, selected for relevance were included in the study, and additional references were considered. This study presents an overview of the current advancements and challenges in employing retinal imaging and artificial intelligence to identify cardiovascular disorders and provides insights for further exploration in this field. Conclusion: Researchers aim to develop precise disease prognosis patterns as the aging population and global CVD burden increase. AI and deep learning are transforming healthcare, offering the potential for single retinal image-based diagnosis of various CVDs, albeit with the need for accelerated adoption in healthcare systems.
</details>
<details>
<summary>摘要</summary>
背景：心血管疾病（CVD）仍然是全球范围内最主要的死亡原因。在过去几年，人工智能（AI）技术，特别是深度学习（DL），在评估CVD多方面的方面得到了广泛的应用。此外，使用眼膜图像和光共振成像（OCTA）诊断视网膜疾病已经得到了广泛的研究。为了更好地理解心脏功能和预测基于微血管特征和功能的变化，研究人员正在探索将AI与不侵入性的眼膜扫描结合起来。利用AI助成早期检测和预测心血管疾病的大规模应用拥有很大的潜在价值，可以减少心血管事件和减轻医疗系统的负担。方法：我们对多种数据库进行了总体检索，包括PubMed、Medline、Google学术搜索、Scopus、Web of Sciences、IEEE Xplore和ACM数字图书馆，使用与心血管疾病相关的特定关键词。结果：共选择了87篇英文文献，包括其他参考文献。本研究提供了目前AI与眼膜成像在诊断心血管疾病方面的进展和挑战，以及此领域的更多可能性的探索。结论：研究人员目标是通过随着人口老龄化和全球CVD荷重的增加，发展精准的疾病诊断模式。AI和深度学习在医疗领域中发挥了重要作用，尝试通过单一的眼膜图像诊断多种CVD，尽管需要加速在医疗系统中的采用。
</details></li>
</ul>
<hr>
<h2 id="Identification-of-vortex-in-unstructured-mesh-with-graph-neural-networks"><a href="#Identification-of-vortex-in-unstructured-mesh-with-graph-neural-networks" class="headerlink" title="Identification of vortex in unstructured mesh with graph neural networks"></a>Identification of vortex in unstructured mesh with graph neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06557">http://arxiv.org/abs/2311.06557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lianfa Wang, Yvan Fournier, Jean-Francois Wald, Youssef Mesri</li>
<li>for: 用于identifying flow characteristics from Computational Fluid Dynamics (CFD) databases，帮助研究者更好地理解流场，优化geometry设计和选择合适的CFD配置。</li>
<li>methods: 使用Graph Neural Network (GNN) with U-Net architecture，通过 algebraic multigrid method生成图并构建图层结构，对2D CFD网格中的涡旋区域进行自动标签。</li>
<li>results: 对CFD结果进行了vortex自动标签，并评估了GNN矩阵的分类精度、训练效率和标注结果的流场特征。最后，demonstrated the approach的可扩展性和通用性，可应用于不同的液体动力学模型和 Reynolds 数。<details>
<summary>Abstract</summary>
Deep learning has been employed to identify flow characteristics from Computational Fluid Dynamics (CFD) databases to assist the researcher to better understand the flow field, to optimize the geometry design and to select the correct CFD configuration for corresponding flow characteristics. Convolutional Neural Network (CNN) is one of the most popular algorithms used to extract and identify flow features. However its use, without any additional flow field interpolation, is limited to the simple domain geometry and regular meshes which limits its application to real industrial cases where complex geometry and irregular meshes are usually used. Aiming at the aforementioned problems, we present a Graph Neural Network (GNN) based model with U-Net architecture to identify the vortex in CFD results on unstructured meshes. The graph generation and graph hierarchy construction using algebraic multigrid method from CFD meshes are introduced. A vortex auto-labeling method is proposed to label vortex regions in 2D CFD meshes. We precise our approach by firstly optimizing the input set on CNNs, then benchmarking current GNN kernels against CNN model and evaluating the performances of GNN kernels in terms of classification accuracy, training efficiency and identified vortex morphology. Finally, we demonstrate the adaptability of our approach to unstructured meshes and generality to unseen cases with different turbulence models at different Reynolds numbers.
</details>
<details>
<summary>摘要</summary>
深度学习已经在计算流体动力学（CFD）数据库中使用来识别流体特性，以 помо助研究人员更好地理解流场，优化geometry设计和选择相应的CFD配置。抽象神经网络（CNN）是最受欢迎的算法之一，用于提取和识别流体特征。然而，不带任何流场插值的CNN使用，受限于简单的域几何和规则的网格，因此对实际工业案例中的复杂几何和不规则网格的应用有限。为此，我们提出了基于图神经网络（GNN）的模型，使用U-Net架构来识别CFD结果中的涡。我们首先优化输入集，然后对现有GNN核 compare with CNN模型，并评估GNN核的性能。最后，我们证明我们的方法可以适用于不结构化网格和未看到的情况中的不同的湍流模型和不同的 Reynolds 数。
</details></li>
</ul>
<hr>
<h2 id="Visual-Commonsense-based-Heterogeneous-Graph-Contrastive-Learning"><a href="#Visual-Commonsense-based-Heterogeneous-Graph-Contrastive-Learning" class="headerlink" title="Visual Commonsense based Heterogeneous Graph Contrastive Learning"></a>Visual Commonsense based Heterogeneous Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06553">http://arxiv.org/abs/2311.06553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zongzhao Li, Xiangyu Zhu, Xi Zhang, Zhaoxiang Zhang, Zhen Lei</li>
<li>for: 提高多modal应用中视语关系的理解和语言领域关系的抽象</li>
<li>methods: 使用heterogeneous graph contrastive learning方法，包括Visual Commonsense Information和Graph Relation Network，以提高视觉理解任务的完成</li>
<li>results: 对四个 benchmark 进行了广泛的实验，显示了方法的效果和通用性，可以大幅提高七种代表性 VQA 模型的性能<details>
<summary>Abstract</summary>
How to select relevant key objects and reason about the complex relationships cross vision and linguistic domain are two key issues in many multi-modality applications such as visual question answering (VQA). In this work, we incorporate the visual commonsense information and propose a heterogeneous graph contrastive learning method to better finish the visual reasoning task. Our method is designed as a plug-and-play way, so that it can be quickly and easily combined with a wide range of representative methods. Specifically, our model contains two key components: the Commonsense-based Contrastive Learning and the Graph Relation Network. Using contrastive learning, we guide the model concentrate more on discriminative objects and relevant visual commonsense attributes. Besides, thanks to the introduction of the Graph Relation Network, the model reasons about the correlations between homogeneous edges and the similarities between heterogeneous edges, which makes information transmission more effective. Extensive experiments on four benchmarks show that our method greatly improves seven representative VQA models, demonstrating its effectiveness and generalizability.
</details>
<details>
<summary>摘要</summary>
多Modalitate应用中，选择相关的关键对象并理解跨视听域关系是两个关键问题。在这种情况下，我们将视觉常识信息 integrate到模型中，并提出一种多态图像异构学习方法来更好地完成视觉理解任务。我们的方法设计为可插入式的方式，以便快速和方便地与各种代表性方法结合使用。具体来说，我们的模型包括两个关键组件： Commonsense-based Contrastive Learning和图像关系网络。通过对比学习，我们引导模型更多地关注特征对象和相关的视觉常识特征。此外，图像关系网络的引入使得模型可以更好地理解同型边的相互关系，使信息传递更加有效。我们在四个标准测试集上进行了广泛的实验，并证明了我们的方法可以大幅提高七种代表VQA模型的性能，表明其有效性和普适性。
</details></li>
</ul>
<hr>
<h2 id="Stain-Consistency-Learning-Handling-Stain-Variation-for-Automatic-Digital-Pathology-Segmentation"><a href="#Stain-Consistency-Learning-Handling-Stain-Variation-for-Automatic-Digital-Pathology-Segmentation" class="headerlink" title="Stain Consistency Learning: Handling Stain Variation for Automatic Digital Pathology Segmentation"></a>Stain Consistency Learning: Handling Stain Variation for Automatic Digital Pathology Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06552">http://arxiv.org/abs/2311.06552</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlyg/stain_consistency_learning">https://github.com/mlyg/stain_consistency_learning</a></li>
<li>paper_authors: Michael Yeung, Todd Watts, Sean YW Tan, Pedro F. Ferreira, Andrew D. Scott, Sonia Nielles-Vallespin, Guang Yang</li>
<li>for: 本研究旨在提高机器学习方法对染色谱变化的可靠性，并对各种方法进行比较性评估，以便选择最佳方法。</li>
<li>methods: 本研究提出了一种新的染色协调学习框架，即染色特征归一化学习法，该法结合染色特征归一化和染色一致损失函数来学习染色颜色无关的特征。</li>
<li>results: 对于 Masson 染色和 H&amp;E 染色的细胞和核lei datasets，本研究对各种染色变化处理方法进行了首次、广泛的比较，并证明了提案的方法能够获得最佳性能。<details>
<summary>Abstract</summary>
Stain variation is a unique challenge associated with automated analysis of digital pathology. Numerous methods have been developed to improve the robustness of machine learning methods to stain variation, but comparative studies have demonstrated limited benefits to performance. Moreover, methods to handle stain variation were largely developed for H&E stained data, with evaluation generally limited to classification tasks. Here we propose Stain Consistency Learning, a novel framework combining stain-specific augmentation with a stain consistency loss function to learn stain colour invariant features. We perform the first, extensive comparison of methods to handle stain variation for segmentation tasks, comparing ten methods on Masson's trichrome and H&E stained cell and nuclei datasets, respectively. We observed that stain normalisation methods resulted in equivalent or worse performance, while stain augmentation or stain adversarial methods demonstrated improved performance, with the best performance consistently achieved by our proposed approach. The code is available at: https://github.com/mlyg/stain_consistency_learning
</details>
<details>
<summary>摘要</summary>
颜色差异是数字病理学自动分析中的一个独特挑战。许多方法已经开发来改善机器学习方法对颜色差异的Robustness，但是比较研究表明这些方法具有有限的效果。此外，处理颜色差异的方法主要是为H&E染料数据而开发，评估通常是限定为分类任务。我们提出了一种新的框架，即颜色一致学习（Stain Consistency Learning），它将颜色特异的扩充与颜色一致损失函数结合在一起，以学习颜色不变的特征。我们对 Masson的三色染料和H&E染料分别进行了细胞和核lei数据集的比较，结果表明，颜色normal化方法的性能相当或更差，而颜色扩充或颜色对抗方法的性能则得到了改善，我们的提议方法得到了最佳性能。代码可以在以下链接下获取：https://github.com/mlyg/stain_consistency_learning。
</details></li>
</ul>
<hr>
<h2 id="FDNet-Feature-Decoupled-Segmentation-Network-for-Tooth-CBCT-Image"><a href="#FDNet-Feature-Decoupled-Segmentation-Network-for-Tooth-CBCT-Image" class="headerlink" title="FDNet: Feature Decoupled Segmentation Network for Tooth CBCT Image"></a>FDNet: Feature Decoupled Segmentation Network for Tooth CBCT Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06551">http://arxiv.org/abs/2311.06551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Feng, Chengkai Wang, Chengyu Wu, Yunxiang Li, Yongbo He, Shuai Wang, Yaiqi Wang</li>
<li>for: 本研究旨在提高CBCT影像的精确分割，以便正确评估牙齿准备治疗计划。</li>
<li>methods: 该研究提出了一种新的Feature Decoupled Segmentation Network（FDNet），通过结合低频波峰变换（LF-Wavelet）和SAM编码器，以提高牙齿边界的精度和细节分割的准确性。</li>
<li>results: 研究表明，FDNet可以在CBCT影像中提供高达85.28%的Dice分数和75.23%的IoU分数，表明该方法可以有效地减少semantic gap，提供精确的牙齿分割结果。<details>
<summary>Abstract</summary>
Precise Tooth Cone Beam Computed Tomography (CBCT) image segmentation is crucial for orthodontic treatment planning. In this paper, we propose FDNet, a Feature Decoupled Segmentation Network, to excel in the face of the variable dental conditions encountered in CBCT scans, such as complex artifacts and indistinct tooth boundaries. The Low-Frequency Wavelet Transform (LF-Wavelet) is employed to enrich the semantic content by emphasizing the global structural integrity of the teeth, while the SAM encoder is leveraged to refine the boundary delineation, thus improving the contrast between adjacent dental structures. By integrating these dual aspects, FDNet adeptly addresses the semantic gap, providing a detailed and accurate segmentation. The framework's effectiveness is validated through rigorous benchmarks, achieving the top Dice and IoU scores of 85.28% and 75.23%, respectively. This innovative decoupling of semantic and boundary features capitalizes on the unique strengths of each element to significantly elevate the quality of segmentation performance.
</details>
<details>
<summary>摘要</summary>
精准牙齿 cone beam computed tomography（CBCT）图像分割是正确的orthodontic treatment planning的关键。在这篇论文中，我们提出了FDNet，一种特征解coupled Segmentation Network，以便在CBCT扫描中遇到的变化牙齿条件下表现出色，例如复杂的遗产物和不明确的牙齿界限。使用低频波лет变换（LF-Wavelet）可以增强牙齿的semantic内容，同时使用SAM编码器可以进一步改善边界定义，从而提高牙齿结构之间的对比度。通过这种双重方法，FDNet能够有效地bridging semantic gap，提供精确和详细的分割。该框架的效果被证明通过严格的 benchmark，实现了Dice和IoU分割分别达到85.28%和75.23%的最高分。这种创新的特征解coupling技术可以 Capitalize on Each element的特点，提高分割性能的质量。
</details></li>
</ul>
<hr>
<h2 id="Generation-Of-Colors-using-Bidirectional-Long-Short-Term-Memory-Networks"><a href="#Generation-Of-Colors-using-Bidirectional-Long-Short-Term-Memory-Networks" class="headerlink" title="Generation Of Colors using Bidirectional Long Short Term Memory Networks"></a>Generation Of Colors using Bidirectional Long Short Term Memory Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06542">http://arxiv.org/abs/2311.06542</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chungimungi/color-prediction">https://github.com/chungimungi/color-prediction</a></li>
<li>paper_authors: A. Sinha</li>
<li>For: This paper aims to bridge the gap between human visual perception of countless shades of colours and our ability to name and describe them accurately, using a novel model based on Bidirectional Long Short-Term Memory (BiLSTM) networks with Active learning.* Methods: The paper develops a novel model that operates on a proprietary dataset curated for this study, using BiLSTM networks with Active learning to categorize and name previously unnamed colours or identify intermediate shades that elude traditional colour terminology.* Results: The findings of the study demonstrate the potential of this innovative approach in revolutionizing our understanding of colour perception and language, with the potential to extend the applications of Natural Language Processing (NLP) beyond conventional boundaries.<details>
<summary>Abstract</summary>
Human vision can distinguish between a vast spectrum of colours, estimated to be between 2 to 7 million discernible shades. However, this impressive range does not inherently imply that all these colours have been precisely named and described within our lexicon. We often associate colours with familiar objects and concepts in our daily lives. This research endeavors to bridge the gap between our visual perception of countless shades and our ability to articulate and name them accurately. A novel model has been developed to achieve this goal, leveraging Bidirectional Long Short-Term Memory (BiLSTM) networks with Active learning. This model operates on a proprietary dataset meticulously curated for this study. The primary objective of this research is to create a versatile tool for categorizing and naming previously unnamed colours or identifying intermediate shades that elude traditional colour terminology. The findings underscore the potential of this innovative approach in revolutionizing our understanding of colour perception and language. Through rigorous experimentation and analysis, this study illuminates a promising avenue for Natural Language Processing (NLP) applications in diverse industries. By facilitating the exploration of the vast colour spectrum the potential applications of NLP are extended beyond conventional boundaries.
</details>
<details>
<summary>摘要</summary>
人类视觉可以分辨出各种颜色，估计有2到7百万个不同的颜色。然而，这一各种颜色的范围并不意味着所有的颜色都有被精确地命名和描述在我们的语言中。我们常常将颜色与日常生活中的familiar对象和概念相关联。这项研究的目的是将视觉中的 countless 颜色与我们的语言之间的差距bridged。为此，该研究开发了一种基于BiLSTM网络和活动学习的新模型。该模型运用了专门为本研究制作的专有数据集。本研究的主要目标是开发一种可以分类和命名未命名颜色或者描述不能被传统颜色术语捕捉的颜色的工具。研究结果表明这种创新的方法在改变我们对颜色识别和语言的理解方面具有潜力。通过严格的实验和分析，本研究探讨了NLP应用的新途径，扩展了NLP应用的边界。
</details></li>
</ul>
<hr>
<h2 id="CrashCar101-Procedural-Generation-for-Damage-Assessment"><a href="#CrashCar101-Procedural-Generation-for-Damage-Assessment" class="headerlink" title="CrashCar101: Procedural Generation for Damage Assessment"></a>CrashCar101: Procedural Generation for Damage Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06536">http://arxiv.org/abs/2311.06536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jens Parslov, Erik Riise, Dim P. Papadopoulos</li>
<li>for: 本研究旨在解决汽车损害评估中的问题，包括检测损害的位置和程度以及特定的损害部分。</li>
<li>methods: 我们提议使用生成过程来训练计算机视觉系统，使其能够进行Semantic part和损害分 segmentation。我们使用生成的3D汽车模型和Synthetic Data来生成高度多样化的样本，并为每个样本提供高精度的像素注释。</li>
<li>results: 我们采用这种方法并生成了CrashCar101数据集。我们在三个实际数据集上进行了实验，并证明了在part segmentation任务上，使用实际数据和Synthetic Data进行训练的模型比使用实际数据进行训练的模型表现更好。在损害 segmentation任务上，我们证明了CrashCar101数据集的sim2real转移能力。<details>
<summary>Abstract</summary>
In this paper, we are interested in addressing the problem of damage assessment for vehicles, such as cars. This task requires not only detecting the location and the extent of the damage but also identifying the damaged part. To train a computer vision system for the semantic part and damage segmentation in images, we need to manually annotate images with costly pixel annotations for both part categories and damage types. To overcome this need, we propose to use synthetic data to train these models. Synthetic data can provide samples with high variability, pixel-accurate annotations, and arbitrarily large training sets without any human intervention. We propose a procedural generation pipeline that damages 3D car models and we obtain synthetic 2D images of damaged cars paired with pixel-accurate annotations for part and damage categories. To validate our idea, we execute our pipeline and render our CrashCar101 dataset. We run experiments on three real datasets for the tasks of part and damage segmentation. For part segmentation, we show that the segmentation models trained on a combination of real data and our synthetic data outperform all models trained only on real data. For damage segmentation, we show the sim2real transfer ability of CrashCar101.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们关注了汽车损害评估问题，例如汽车受损的部分和程度的识别。为了训练计算机视觉系统进行semantic部分和损害分割，我们需要手动标注图像，以获得价值的像素注释。为了缓解这个需求，我们提议使用生成数据。生成数据可以提供高度多样性的样本，高精度的像素注释，并且可以在人工干预下生成无限大的训练集。我们提出了一个生成过程，用于损害3D汽车模型，并从而获得了损害2D图像和高精度的像素注释。为了验证我们的想法，我们执行了我们的管道，并生成了CrashCar101数据集。我们在三个实际数据集上进行了实验，以评估part和损害分割任务。对于part分割任务，我们显示了将real数据和我们生成的数据混合训练的模型，与只使用实际数据训练的模型相比，具有更高的性能。对于损害分割任务，我们显示了CrashCar101数据集的sim2real传送能力。
</details></li>
</ul>
<hr>
<h2 id="Band-wise-Hyperspectral-Image-Pansharpening-using-CNN-Model-Propagation"><a href="#Band-wise-Hyperspectral-Image-Pansharpening-using-CNN-Model-Propagation" class="headerlink" title="Band-wise Hyperspectral Image Pansharpening using CNN Model Propagation"></a>Band-wise Hyperspectral Image Pansharpening using CNN Model Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06510">http://arxiv.org/abs/2311.06510</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/giu-guarino/r-pnn">https://github.com/giu-guarino/r-pnn</a></li>
<li>paper_authors: Giuseppe Guarino, Matteo Ciotola, Gemine Vivone, Giuseppe Scarpa</li>
<li>for: 本研究的目的是提出一种深度学习方法，用于解决高spectral缩进问题。</li>
<li>methods: 该方法基于单 banda unsupervised pansharpening模型，通过在排序band-wise adaptive scheme中嵌入该模型，以适应不同 spectral band的数据。</li>
<li>results: 对于我们的数据集，该方法达到了非常好的结果，超过了传统和深度学习参考方法。代码实现可以在<a target="_blank" rel="noopener" href="https://github.com/giu-guarino/R-PNN%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/giu-guarino/R-PNN找到。</a><details>
<summary>Abstract</summary>
Hyperspectral pansharpening is receiving a growing interest since the last few years as testified by a large number of research papers and challenges. It consists in a pixel-level fusion between a lower-resolution hyperspectral datacube and a higher-resolution single-band image, the panchromatic image, with the goal of providing a hyperspectral datacube at panchromatic resolution. Thanks to their powerful representational capabilities, deep learning models have succeeded to provide unprecedented results on many general purpose image processing tasks. However, when moving to domain specific problems, as in this case, the advantages with respect to traditional model-based approaches are much lesser clear-cut due to several contextual reasons. Scarcity of training data, lack of ground-truth, data shape variability, are some such factors that limit the generalization capacity of the state-of-the-art deep learning networks for hyperspectral pansharpening. To cope with these limitations, in this work we propose a new deep learning method which inherits a simple single-band unsupervised pansharpening model nested in a sequential band-wise adaptive scheme, where each band is pansharpened refining the model tuned on the preceding one. By doing so, a simple model is propagated along the wavelength dimension, adaptively and flexibly, with no need to have a fixed number of spectral bands, and, with no need to dispose of large, expensive and labeled training datasets. The proposed method achieves very good results on our datasets, outperforming both traditional and deep learning reference methods. The implementation of the proposed method can be found on https://github.com/giu-guarino/R-PNN
</details>
<details>
<summary>摘要</summary>
“几年前，几何spectral pansharpening已经受到了越来越多的关注，可以看到许多研究论文和挑战。它的目的是将lower-resolution的几何spectral数据 кубы和高分辨率的单色图像（panchromatic image）进行像素级融合，以获得高分辨率的几何spectral数据库。由于深度学习模型具有强大的表示能力，它们在许多通用图像处理任务上取得了无PRECEDENT的成绩。但是，当转移到域特定问题时，例如这个案例中，深度学习模型的优势与传统的模型基于方法相比较难明确地表现出来，因为一些contextual因素的限制。数据缺乏、缺乏标注、数据形态变化等因素，都会限制深度学习网络在域特定问题上的总体化能力。为了缓解这些限制，在这个工作中，我们提出了一种新的深度学习方法。这种方法基于单色图像无监督的宽渠扩充模型，通过在带宽维度上逐步进行适应式的band-wise适应方案，使得每个带都可以细化和适应，无需具备固定的 spectral 带数量，也无需具备大量、昂贵和标注的训练数据。提议的方法在我们的数据集上实现了非常好的效果，超越了传统和深度学习参考方法。实现方法可以在https://github.com/giu-guarino/R-PNN 找到。”
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Context-Learning-for-Visual-Inspection-of-Industrial-Defects"><a href="#Self-supervised-Context-Learning-for-Visual-Inspection-of-Industrial-Defects" class="headerlink" title="Self-supervised Context Learning for Visual Inspection of Industrial Defects"></a>Self-supervised Context Learning for Visual Inspection of Industrial Defects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06504">http://arxiv.org/abs/2311.06504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wang, Haiming Yao, Wenyong Yu</li>
<li>for: 本研究旨在提出一种基于自我监督学习的检测方法，以解决现有的无监督模型在产品表面变化大的情况下检测缺陷的问题。</li>
<li>methods: 我们提出一种自我监督学习算法，通过将目标图像分割成9个 patches，并让编码器预测每两个 patch 的相对位置关系，以提取丰富的 semantics。我们还提出一种帮助函数-加 augmentation 方法，以强调正常和异常的 latent 表示之间的差异。</li>
<li>results: 我们的方法在 widely 使用的 MVTec AD 数据集上实现了出色的检测和 segmentation 性能，即 95.8% 和 96.8% 分别，创造了当今无监督检测领域的状元标准。广泛的实验证明了我们的方法在多种工业应用中的有效性。<details>
<summary>Abstract</summary>
The unsupervised visual inspection of defects in industrial products poses a significant challenge due to substantial variations in product surfaces. Current unsupervised models struggle to strike a balance between detecting texture and object defects, lacking the capacity to discern latent representations and intricate features. In this paper, we present a novel self-supervised learning algorithm designed to derive an optimal encoder by tackling the renowned jigsaw puzzle. Our approach involves dividing the target image into nine patches, tasking the encoder with predicting the relative position relationships between any two patches to extract rich semantics. Subsequently, we introduce an affinity-augmentation method to accentuate differences between normal and abnormal latent representations. Leveraging the classic support vector data description algorithm yields final detection results. Experimental outcomes demonstrate that our proposed method achieves outstanding detection and segmentation performance on the widely used MVTec AD dataset, with rates of 95.8% and 96.8%, respectively, establishing a state-of-the-art benchmark for both texture and object defects. Comprehensive experimentation underscores the effectiveness of our approach in diverse industrial applications.
</details>
<details>
<summary>摘要</summary>
“无监督的视觉检测工业产品上的瑕疵具有严重的挑战，因为产品表面会有很大的变化。现有的无监督模型对于检测文字和物体瑕疵具有困难，因为它们缺乏能够捕捉实际特征和细节的能力。在这篇论文中，我们提出了一个新的自类学习算法，用于从熔毙难以分辨的图像中提取有用的 semantics。我们的方法是将目标图像分成九块，让算法预测两块之间的相对位置关系，以提取丰富的 semantics。然后，我们引入了一个增强不同于正常的latent representation的方法，以提高分辨率。通过使用了经典支持向量描述算法，获得最终的检测结果。实验结果显示，我们的提案方法在广泛使用的MVTec AD dataset上实现了95.8%和96.8%的检测和分类性能，成为瑕疵和物体瑕疵检测的现代标准。实验结果显示，我们的方法在不同的工业应用中具有广泛的适用范围。”
</details></li>
</ul>
<hr>
<h2 id="LayoutPrompter-Awaken-the-Design-Ability-of-Large-Language-Models"><a href="#LayoutPrompter-Awaken-the-Design-Ability-of-Large-Language-Models" class="headerlink" title="LayoutPrompter: Awaken the Design Ability of Large Language Models"></a>LayoutPrompter: Awaken the Design Ability of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06495">http://arxiv.org/abs/2311.06495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/layoutgeneration">https://github.com/microsoft/layoutgeneration</a></li>
<li>paper_authors: Jiawei Lin, Jiaqi Guo, Shizhao Sun, Zijiang James Yang, Jian-Guang Lou, Dongmei Zhang</li>
<li>for: 这个论文是为了提出一种基于大语言模型（LLM）的 Conditional Graphic Layout Generation 方法，以解决现有方法缺乏灵活性和数据效率问题。</li>
<li>methods: 该方法包括三个关键组件：输入输出序列化、动态示例选择和布局排序。具体来说，输入输出序列化组件 меiculously 设计了每个布局生成任务的输入和输出格式。动态示例选择负责选择对于给定输入最有帮助的提示示例。布局排序则是用于从多个 LLM 的输出中选择最高质量的布局。</li>
<li>results: 经过实验表明，LayoutPrompter 可以在所有现有的布局生成任务上与或超越当前状态的方法，无需训练或调整模型。此外，对比baseline方法，LayoutPrompter 在低数据情况下表现更出色，进一步证明了该方法的数据效率。<details>
<summary>Abstract</summary>
Conditional graphic layout generation, which automatically maps user constraints to high-quality layouts, has attracted widespread attention today. Although recent works have achieved promising performance, the lack of versatility and data efficiency hinders their practical applications. In this work, we propose LayoutPrompter, which leverages large language models (LLMs) to address the above problems through in-context learning. LayoutPrompter is made up of three key components, namely input-output serialization, dynamic exemplar selection and layout ranking. Specifically, the input-output serialization component meticulously designs the input and output formats for each layout generation task. Dynamic exemplar selection is responsible for selecting the most helpful prompting exemplars for a given input. And a layout ranker is used to pick the highest quality layout from multiple outputs of LLMs. We conduct experiments on all existing layout generation tasks using four public datasets. Despite the simplicity of our approach, experimental results show that LayoutPrompter can compete with or even outperform state-of-the-art approaches on these tasks without any model training or fine-tuning. This demonstrates the effectiveness of this versatile and training-free approach. In addition, the ablation studies show that LayoutPrompter is significantly superior to the training-based baseline in a low-data regime, further indicating the data efficiency of LayoutPrompter. Our project is available at https://github.com/microsoft/LayoutGeneration/tree/main/LayoutPrompter.
</details>
<details>
<summary>摘要</summary>
《 conditional graphic layout generation 》，即自动将用户约束映射到高质量的布局，在今天已经吸引了广泛的关注。虽然 latest works 已经实现了可观的性能，但缺乏实用性和数据效率限制了它们的实际应用。在这项工作中，我们提出了 LayoutPrompter，它利用大型语言模型（LLMs）来解决上述问题通过在线上学习。LayoutPrompter 由三个关键组成部分：输入输出序列化、动态示例选择和布局排名。具体来说，输入输出序列化部分仔细设计了每个布局生成任务的输入和输出格式。动态示例选择部分选择给定输入的最有用的推动示例。而布局排名部分则用来从多个 LLMS 的输出中选择最高质量的布局。我们在所有现有的布局生成任务上进行了实验，使用四个公共数据集。尽管我们的方法简单，但实验结果显示，LayoutPrompter 可以与或 même outperform 当前状态的方法这些任务上，无需任何模型训练或调整。这说明 LayoutPrompter 是一种灵活且无需训练的方法。此外，我们的剖析研究表明，LayoutPrompter 在低数据情况下表现 significatively 优于基eline，这再次证明了 LayoutPrompter 的数据效率。您可以在 https://github.com/microsoft/LayoutGeneration/tree/main/LayoutPrompter 上查看我们的项目。
</details></li>
</ul>
<hr>
<h2 id="PECoP-Parameter-Efficient-Continual-Pretraining-for-Action-Quality-Assessment"><a href="#PECoP-Parameter-Efficient-Continual-Pretraining-for-Action-Quality-Assessment" class="headerlink" title="PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment"></a>PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07603">http://arxiv.org/abs/2311.07603</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/plrbear/pecop">https://github.com/plrbear/pecop</a></li>
<li>paper_authors: Amirhossein Dadashzadeh, Shuchao Duan, Alan Whone, Majid Mirmehdi</li>
<li>for: 本研究的目的是提高Action Quality Assessment（AQA）中的模型表现，特别是在预测过程中处理具有域对错的资料时。</li>
<li>methods: 我们提出了一个新的、效率高的普遍预训架构，名为PECoP，并在其中引入3D-Adapters来学习预测当中的体域特征。在PECoP中，仅对Adapter模组的参数进行更新，以减少域对错的影响。</li>
<li>results: 我们在几个benchmark dataset上进行了实验，包括JIGSAWS、MTL-AQA和FineDiving，并取得了较好的成绩（比如JIGSAWS中提高6.0%）。此外，我们还提供了一个新的Parkinson’s Disease dataset，PD4T，并在其上进行了比较，并与之前的最佳成绩进行了比较（提高3.56%）。<details>
<summary>Abstract</summary>
The limited availability of labelled data in Action Quality Assessment (AQA), has forced previous works to fine-tune their models pretrained on large-scale domain-general datasets. This common approach results in weak generalisation, particularly when there is a significant domain shift. We propose a novel, parameter efficient, continual pretraining framework, PECoP, to reduce such domain shift via an additional pretraining stage. In PECoP, we introduce 3D-Adapters, inserted into the pretrained model, to learn spatiotemporal, in-domain information via self-supervised learning where only the adapter modules' parameters are updated. We demonstrate PECoP's ability to enhance the performance of recent state-of-the-art methods (MUSDL, CoRe, and TSA) applied to AQA, leading to considerable improvements on benchmark datasets, JIGSAWS ($\uparrow6.0\%$), MTL-AQA ($\uparrow0.99\%$), and FineDiving ($\uparrow2.54\%$). We also present a new Parkinson's Disease dataset, PD4T, of real patients performing four various actions, where we surpass ($\uparrow3.56\%$) the state-of-the-art in comparison. Our code, pretrained models, and the PD4T dataset are available at https://github.com/Plrbear/PECoP.
</details>
<details>
<summary>摘要</summary>
因为Action Quality Assessment（AQA）的标注数据有限，previous works通常是 fine-tune 在大规模的领域通用数据集上预训练的模型。这种常见的方法会导致弱化泛化，特别是当领域shift很大时。我们提出了一种新的、效率的 continual pretraining 框架，PECoP，以减少领域shift。在 PECoP 中，我们引入了 3D-Adapters，用于在预训练模型中学习空间时间领域信息，通过自我超vised learning，只有 adapter modules 的参数被更新。我们证明了 PECoP 能够提高最近state-of-the-art方法（MUSDL、CoRe 和 TSA）在 AQA 中的性能，在 benchmark 数据集（JIGSAWS、MTL-AQA 和 FineDiving）上实现了显著提高（$\uparrow6.0\%$, $\uparrow0.99\%$ 和 $\uparrow2.54\%$）。我们还发布了一个新的 Parkinson's Disease 数据集，PD4T，包含了四种不同的动作，我们在 comparison 中超过了 state-of-the-art（$\uparrow3.56\%$）。我们的代码、预训练模型和 PD4T 数据集可以在 GitHub 上获取：https://github.com/Plrbear/PECoP。
</details></li>
</ul>
<hr>
<h2 id="Polarimetric-PatchMatch-Multi-View-Stereo"><a href="#Polarimetric-PatchMatch-Multi-View-Stereo" class="headerlink" title="Polarimetric PatchMatch Multi-View Stereo"></a>Polarimetric PatchMatch Multi-View Stereo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07600">http://arxiv.org/abs/2311.07600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinyu Zhao, Jumpei Oishi, Yusuke Monno, Masatoshi Okutomi</li>
<li>for: 这paper是为了提高多视图ステレオ（MVS）的准确性和完整性而设计的。</li>
<li>methods: 这paper使用的方法是PatchMatch multi-view Stereo（PatchMatch MVS），该方法通过生成深度和法向假设，并效率地在多视图图像中寻找最佳假设，以确定物体的三维模型。此外，这paper还引入了抗licht极化信息来评估假设的正确性。</li>
<li>results: 实验结果表明，对比现有PatchMatch MVS方法，PolarPMS可以提高三维模型的准确性和完整性，特别是对于无文本表面。<details>
<summary>Abstract</summary>
PatchMatch Multi-View Stereo (PatchMatch MVS) is one of the popular MVS approaches, owing to its balanced accuracy and efficiency. In this paper, we propose Polarimetric PatchMatch multi-view Stereo (PolarPMS), which is the first method exploiting polarization cues to PatchMatch MVS. The key of PatchMatch MVS is to generate depth and normal hypotheses, which form local 3D planes and slanted stereo matching windows, and efficiently search for the best hypothesis based on the consistency among multi-view images. In addition to standard photometric consistency, our PolarPMS evaluates polarimetric consistency to assess the validness of a depth and normal hypothesis, motivated by the physical property that the polarimetric information is related to the object's surface normal. Experimental results demonstrate that our PolarPMS can improve the accuracy and the completeness of reconstructed 3D models, especially for texture-less surfaces, compared with state-of-the-art PatchMatch MVS methods.
</details>
<details>
<summary>摘要</summary>
patchmatch多视图雷达（PatchMatch MVS）是一种受欢迎的MVS方法，因为它的平衡准确性和效率。在这篇论文中，我们提出了抗 polarimetric PatchMatch多视图雷达（PolarPMS），这是第一种利用抗 polarimetric 信号来PatchMatch MVS的方法。patchmatch MVS的关键在于生成深度和法向假设，形成局部三维平面和斜视匹配窗口，然后高效地搜索最佳假设，基于多视图图像的一致性。除了标准光度一致性外，我们的PolarPMS还评估抗 polarimetric一致性，以评估假设的有效性，这是因为物体表面法向的物理特性和抗 polarimetric信号之间存在关系。实验结果表明，我们的PolarPMS可以提高准确性和完整性的三维模型重建，特别是面粗糙表面，相比现有的PatchMatch MVS方法。
</details></li>
</ul>
<hr>
<h2 id="CVTHead-One-shot-Controllable-Head-Avatar-with-Vertex-feature-Transformer"><a href="#CVTHead-One-shot-Controllable-Head-Avatar-with-Vertex-feature-Transformer" class="headerlink" title="CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer"></a>CVTHead: One-shot Controllable Head Avatar with Vertex-feature Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06443">http://arxiv.org/abs/2311.06443</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HowieMa/CVTHead">https://github.com/HowieMa/CVTHead</a></li>
<li>paper_authors: Haoyu Ma, Tong Zhang, Shanlin Sun, Xiangyi Yan, Kun Han, Xiaohui Xie</li>
<li>for: 本研究旨在 reconstruction 个性化动画人头模型，以便在 AR&#x2F;VR 领域中实现真实时间的人脸动画。</li>
<li>methods: 本研究使用 point-based 神经渲染技术，从单个参考图像中生成可控的神经头像。该方法利用 mesh 中稀疏的顶点点集，并采用提出的 Vertex-feature Transformer 来学习每个顶点的本地特征描述符。这使得可以模型所有顶点之间的长距离依赖关系。</li>
<li>results: 实验结果表明，CVTHead 可以与现状的图形学基于方法相比，实现相似的性能。此外，它还允许在不同的表情、头部姿态和摄像头视图下，高效地渲染出新的人头模型。这些属性可以通过 3DMM 的偏置系数进行控制，以实现多样化和真实的动画在真实时间enario中。<details>
<summary>Abstract</summary>
Reconstructing personalized animatable head avatars has significant implications in the fields of AR/VR. Existing methods for achieving explicit face control of 3D Morphable Models (3DMM) typically rely on multi-view images or videos of a single subject, making the reconstruction process complex. Additionally, the traditional rendering pipeline is time-consuming, limiting real-time animation possibilities. In this paper, we introduce CVTHead, a novel approach that generates controllable neural head avatars from a single reference image using point-based neural rendering. CVTHead considers the sparse vertices of mesh as the point set and employs the proposed Vertex-feature Transformer to learn local feature descriptors for each vertex. This enables the modeling of long-range dependencies among all the vertices. Experimental results on the VoxCeleb dataset demonstrate that CVTHead achieves comparable performance to state-of-the-art graphics-based methods. Moreover, it enables efficient rendering of novel human heads with various expressions, head poses, and camera views. These attributes can be explicitly controlled using the coefficients of 3DMMs, facilitating versatile and realistic animation in real-time scenarios.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将个性化动画头模型重建为有关AR/VR的研究领域有着重要意义。现有的实现方法通常需要多视图图像或视频，这使得重建过程变得复杂。另外，传统的渲染管道时间consuming，限制了实时动画的可能性。在这篇论文中，我们介绍CVTHead，一种新的方法，可以从单个参考图像中生成可控的神经头模型。CVTHead使用点集为网格的稀疏顶点来学习本地特征描述符，这使得模型可以学习所有顶点之间的长距离依赖关系。实验结果表明，CVTHead可以与现有的图形学基于方法相比，在VOXCELEB数据集上实现相似的性能。此外，它可以高效地渲染 novel human head 模型，包括不同的表情、头部姿态和摄像头视角。这些特性可以通过3DMM的系数来控制，从而实现有效的实时动画。Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/11/cs.CV_2023_11_11/" data-id="clp9qz85c00mvok8835zydez7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/11/cs.AI_2023_11_11/" class="article-date">
  <time datetime="2023-11-11T12:00:00.000Z" itemprop="datePublished">2023-11-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/11/cs.AI_2023_11_11/">cs.AI - 2023-11-11</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Automatized-Self-Supervised-Learning-for-Skin-Lesion-Screening"><a href="#Automatized-Self-Supervised-Learning-for-Skin-Lesion-Screening" class="headerlink" title="Automatized Self-Supervised Learning for Skin Lesion Screening"></a>Automatized Self-Supervised Learning for Skin Lesion Screening</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06691">http://arxiv.org/abs/2311.06691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vullnet Useini, Stephanie Tanadini-Lang, Quentin Lohmeyer, Mirko Meboldt, Nicolaus Andratschke, Ralph P. Braun, Javier Barranco García<br>for: 这份研究的目的是为了提高皮肤癌检测的精度和效率，以及帮助皮肤科医生识别病变。methods: 这份研究使用了人工智能（AI）决策支持工具，该工具使用了现代的物体检测算法来识别和从患者影像中提取所有皮肤损伤，然后使用自主学习AI算法来排序这些损伤的可疑程度。results: 这份研究的结果显示，使用AI决策支持工具可以提高皮肤科医生识别病变的精度，具体来说，该工具可以帮助医生识别93%的病变损伤，并且帮助医生增加自信心和与其他专家的一致性。<details>
<summary>Abstract</summary>
The incidence rates of melanoma, the deadliest form of skin cancer, have been increasing steadily worldwide, presenting a significant challenge to dermatologists. Early detection of melanoma is crucial for improving patient survival rates, but identifying suspicious lesions through ugly duckling (UD) screening, the current method used for skin cancer screening, can be challenging and often requires expertise in pigmented lesions. To address these challenges and improve patient outcomes, an artificial intelligence (AI) decision support tool was developed to assist dermatologists in identifying UD from wide-field patient images. The tool uses a state-of-the-art object detection algorithm to identify and extract all skin lesions from patient images, which are then sorted by suspiciousness using a self-supervised AI algorithm. A clinical validation study was conducted to evaluate the tool's performance, which demonstrated an average sensitivity of 93% for the top-10 AI-identified UDs on skin lesions selected by the majority of experts in pigmented skin lesions. The study also found that dermatologists confidence increased, and the average majority agreement with the top-10 AI-identified UDs improved to 100% when assisted by AI. The development of this AI decision support tool aims to address the shortage of specialists, enable at-risk patients to receive faster consultations and understand the impact of AI-assisted screening. The tool's automation can assist dermatologists in identifying suspicious lesions and provide a more objective assessment, reducing subjectivity in the screening process. The future steps for this project include expanding the dataset to include histologically confirmed melanoma cases and increasing the number of participants for clinical validation to strengthen the tool's reliability and adapt it for real-world consultation.
</details>
<details>
<summary>摘要</summary>
全球的梅毒病例数逐渐增加，对皮肤科医生而言，这提出了一项重要的挑战。早期发现梅毒病是改善病人存活率的关键，但通过“鸟嘤”（UD）检测，现在用于皮肤癌检测的方法，可能很困难，需要对疤痕性皮肤病有专门的知识。为了解决这些挑战并提高病人 outcome，我们开发了一种人工智能（AI）决策支持工具，用于协助皮肤科医生从广角图像中识别UD。该工具使用当前最先进的物体检测算法来识别和提取患者图像中的所有皮肤损伤，然后根据自动学习AI算法排序为可疑程度。在临床验证研究中，我们发现该工具的敏感性为93%，对于由大多数专家选择的疤痕性皮肤损伤的top-10 AI识别UD。研究还发现，当帮助于AI的时候，专家的自信度增加，并且对top-10 AI识别UD的多数同意率提高到100%。该工具的开发旨在解决专业人员短缺、帮助高风险患者更快地咨询，并了解AI助检查的影响。该工具的自动化可以帮助皮肤科医生识别可疑损伤，提供更Objective的评估，减少检测过程中的主观性。未来的步骤包括将数据集扩展到包括历史确诊梅毒患者 случа，并增加参与者数量以强化工具的可靠性和适应实际咨询。
</details></li>
</ul>
<hr>
<h2 id="Dream-to-Adapt-Meta-Reinforcement-Learning-by-Latent-Context-Imagination-and-MDP-Imagination"><a href="#Dream-to-Adapt-Meta-Reinforcement-Learning-by-Latent-Context-Imagination-and-MDP-Imagination" class="headerlink" title="Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination"></a>Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06673">http://arxiv.org/abs/2311.06673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lu Wen, Songan Zhang, H. Eric Tseng, Huei Peng</li>
<li>for: 这个论文旨在快速学习未见过的任务，通过将先前学习的知识传递到相似任务中。</li>
<li>methods: 这个论文提出了一个基于上下文的Meta reinforcement learning（Meta RL）算法，称为MetaDreamer，它需要更少的真实任务和数据，通过做meta-幻想和MDP-幻想。</li>
<li>results: 我们的实验显示，MetaDreamer在数据效率和混合 interpolated 测试中表现出色，超越现有的方法。<details>
<summary>Abstract</summary>
Meta reinforcement learning (Meta RL) has been amply explored to quickly learn an unseen task by transferring previously learned knowledge from similar tasks. However, most state-of-the-art algorithms require the meta-training tasks to have a dense coverage on the task distribution and a great amount of data for each of them. In this paper, we propose MetaDreamer, a context-based Meta RL algorithm that requires less real training tasks and data by doing meta-imagination and MDP-imagination. We perform meta-imagination by interpolating on the learned latent context space with disentangled properties, as well as MDP-imagination through the generative world model where physical knowledge is added to plain VAE networks. Our experiments with various benchmarks show that MetaDreamer outperforms existing approaches in data efficiency and interpolated generalization.
</details>
<details>
<summary>摘要</summary>
<SYS> translate="zh-CN"</SYS>meta学习（Meta RL）已经广泛探索，以快速学习未经见过的任务，通过将先前学习的知识传递到相似任务中。然而，大多数当前最佳方法需要meta训练任务的权重复盖到任务分布中，并且需要很多数据 для每个meta训练任务。在这篇论文中，我们提出了MetaDreamer算法，它需要更少的真实训练任务和数据，通过meta想象和MDP想象。我们在meta想象中，通过 interpolating在已学习的约束空间中，捕捉到分离的属性，并在生成世界模型中添加物理知识，使得plain VAE网络可以更好地预测未经见过的任务。我们在不同的benchmark上进行了实验，结果显示，MetaDreamer在数据效率和 interpolated泛化方面超过了现有方法。
</details></li>
</ul>
<hr>
<h2 id="In-context-Vectors-Making-In-Context-Learning-More-Effective-and-Controllable-Through-Latent-Space-Steering"><a href="#In-context-Vectors-Making-In-Context-Learning-More-Effective-and-Controllable-Through-Latent-Space-Steering" class="headerlink" title="In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering"></a>In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06668">http://arxiv.org/abs/2311.06668</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shengliu66/icv">https://github.com/shengliu66/icv</a></li>
<li>paper_authors: Sheng Liu, Lei Xing, James Zou</li>
<li>for: 这篇论文旨在提出一种新的叙述学习方法，以便LLM在新任务上更好地适应示例示例。</li>
<li>methods: 该方法包括在示例示例上进行前向传播，并生成一个叙述向量（ICV），该向量捕捉了示例示例中的关键信息。然后，在新的查询上，将LLM的幂状态进行偏移，使其更好地跟随示例示例。</li>
<li>results: 研究表明，ICV方法可以在多种任务上达到更好的性能，包括安全性、风格转换、扮演和格式化等。此外，ICV方法还可以轻松地控制LLM的行为，并且计算效率高于精度调整。<details>
<summary>Abstract</summary>
Large language models (LLMs) demonstrate emergent in-context learning capabilities, where they adapt to new tasks based on example demonstrations. However, in-context learning has seen limited effectiveness in many settings, is difficult to quantitatively control and takes up context window space. To overcome these limitations, we propose an alternative approach that recasts in-context learning as in-context vectors (ICV). Using ICV has two steps. We first use a forward pass on demonstration examples to create the in-context vector from the latent embedding of the LLM. This vector captures essential information about the intended task. On a new query, instead of adding demonstrations to the prompt, we shift the latent states of the LLM using the ICV. The ICV approach has several benefits: 1) it enables the LLM to more effectively follow the demonstration examples; 2) it's easy to control by adjusting the magnitude of the ICV; 3) it reduces the length of the prompt by removing the in-context demonstrations; 4) ICV is computationally much more efficient than fine-tuning. We demonstrate that ICV achieves better performance compared to standard in-context learning and fine-tuning on diverse tasks including safety, style transfer, role-playing and formatting. Moreover, we show that we can flexibly teach LLM to simultaneously follow different types of instructions by simple vector arithmetics on the corresponding ICVs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）展示出emergent在场景学习能力，即通过示例示例来适应新任务。然而，场景学习在许多场景下表现有限，控制困难，需要场景窗口空间。为了解决这些限制，我们提议一种替代方法，即在场景中 vectors（ICV）。使用ICV有两步：首先，我们使用示例示例进行前向传播，从LLM的干扰空间中生成场景vector，这个vector捕捉了任务的核心信息。然后，在新的查询上，而不是添加示例到提示中，我们使用ICV来偏移LLM的干扰状态。ICV方法具有以下优点：1）帮助LLM更好地跟随示例示例；2）容易控制，只需调整ICV的大小；3）缩短提示的长度，去除场景示例；4）ICV比finetuning更高效。我们示示ICV可以在多种任务上达到更好的性能，包括安全、样式转移、扮演和格式化。此外，我们还证明了可以通过简单的向量运算来让LLM同时遵循不同类型的指令。
</details></li>
</ul>
<hr>
<h2 id="The-Pros-and-Cons-of-Using-Machine-Learning-and-Interpretable-Machine-Learning-Methods-in-psychiatry-detection-applications-specifically-depression-disorder-A-Brief-Review"><a href="#The-Pros-and-Cons-of-Using-Machine-Learning-and-Interpretable-Machine-Learning-Methods-in-psychiatry-detection-applications-specifically-depression-disorder-A-Brief-Review" class="headerlink" title="The Pros and Cons of Using Machine Learning and Interpretable Machine Learning Methods in psychiatry detection applications, specifically depression disorder: A Brief Review"></a>The Pros and Cons of Using Machine Learning and Interpretable Machine Learning Methods in psychiatry detection applications, specifically depression disorder: A Brief Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06633">http://arxiv.org/abs/2311.06633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Simchi, Samira Tajik</li>
<li>for: 这些研究旨在提高心理疾病诊断的准确性和速度，防止自杀等严重结果。</li>
<li>methods: 这些研究使用机器学习技术，以提供更加准确和理解性的诊断结果。</li>
<li>results: 这些研究获得了有用的结果，帮助了心理科学家和研究人员更好地理解机器学习在心理疾病诊断中的优劣。<details>
<summary>Abstract</summary>
The COVID-19 pandemic has forced many people to limit their social activities, which has resulted in a rise in mental illnesses, particularly depression. To diagnose these illnesses with accuracy and speed, and prevent severe outcomes such as suicide, the use of machine learning has become increasingly important. Additionally, to provide precise and understandable diagnoses for better treatment, AI scientists and researchers must develop interpretable AI-based solutions. This article provides an overview of relevant articles in the field of machine learning and interpretable AI, which helps to understand the advantages and disadvantages of using AI in psychiatry disorder detection applications.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行导致许多人需要限制社交活动，这已经导致了心理疾病的增加，特别是抑郁症。为了准确和快速诊断这些疾病，以避免严重的结果如自杀，机器学习的使用已成为越来越重要。此外，为了提供更好的治疗，AI科学家和研究人员必须开发可解释的 AI 解决方案。本文提供了机器学习和可解释 AI 领域的相关文章，以便更好地了解使用 AI 在心理疾病检测应用中的优劣。
</details></li>
</ul>
<hr>
<h2 id="VT-Former-A-Transformer-based-Vehicle-Trajectory-Prediction-Approach-For-Intelligent-Highway-Transportation-Systems"><a href="#VT-Former-A-Transformer-based-Vehicle-Trajectory-Prediction-Approach-For-Intelligent-Highway-Transportation-Systems" class="headerlink" title="VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems"></a>VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06623">http://arxiv.org/abs/2311.06623</a></li>
<li>repo_url: None</li>
<li>paper_authors: Armin Danesh Pazho, Vinit Katariya, Ghazal Alinezhad Noghre, Hamed Tabkhi</li>
<li>for: 增强道路安全和交通管理已成为现代 цифровой物理系统和智能交通系统的关键焦点。</li>
<li>methods: 本文提出了一种基于变换器的新方法，称为VT-Former，用于高速公路安全和监测中的车辆轨迹预测。这种方法不仅利用变换器捕捉长距离时间模式，还提出了一种图像注意力模块，以捕捉车辆之间的复杂社交互动。</li>
<li>results: 研究在三个 benchmark 数据集上，通过三种不同的视点展示了VT-Former 在车辆轨迹预测中的 State-of-The-Art 性能，以及其普适性和稳定性。此外，本文还评估了 VT-Former 在嵌入式板上的效率，并对其在车辆异常检测中的应用展示了其广泛的应用前景。<details>
<summary>Abstract</summary>
Enhancing roadway safety and traffic management has become an essential focus area for a broad range of modern cyber-physical systems and intelligent transportation systems. Vehicle Trajectory Prediction is a pivotal element within numerous applications for highway and road safety. These applications encompass a wide range of use cases, spanning from traffic management and accident prevention to enhancing work-zone safety and optimizing energy conservation. The ability to implement intelligent management in this context has been greatly advanced by the developments in the field of Artificial Intelligence (AI), alongside the increasing deployment of surveillance cameras across road networks. In this paper, we introduce a novel transformer-based approach for vehicle trajectory prediction for highway safety and surveillance, denoted as VT-Former. In addition to utilizing transformers to capture long-range temporal patterns, a new Graph Attentive Tokenization (GAT) module has been proposed to capture intricate social interactions among vehicles. Combining these two core components culminates in a precise approach for vehicle trajectory prediction. Our study on three benchmark datasets with three different viewpoints demonstrates the State-of-The-Art (SoTA) performance of VT-Former in vehicle trajectory prediction and its generalizability and robustness. We also evaluate VT-Former's efficiency on embedded boards and explore its potential for vehicle anomaly detection as a sample application, showcasing its broad applicability.
</details>
<details>
<summary>摘要</summary>
提高公路安全和交通管理已成为现代ци伯-物理系统和智能交通系统的重要焦点。车辆轨迹预测是这些应用程序中的重要组成部分，包括交通管理、事故预防和工地安全等。随着人工智能技术的发展和公路网络上的监测摄像头的普及，实现智能管理在这个领域已得到了大幅提高。在这篇论文中，我们介绍了一种新的变换器基于方法（VT-Former），用于高速公路安全和监测中的车辆轨迹预测。此外，我们还提出了一种新的图像注意力模块（GAT），用于捕捉车辆之间的复杂社交互动。这两个核心组件的结合，实现了准确的车辆轨迹预测。我们在三个标准数据集上进行了三种不同的视角测试，并证明了VT-Former在车辆轨迹预测中的状态之最（SoTA）性和其广泛应用性和稳定性。此外，我们还评估了VT-Former的效率在嵌入板上，并探讨了其在车辆异常检测方面的潜在应用。
</details></li>
</ul>
<hr>
<h2 id="TrainerAgent-Customizable-and-Efficient-Model-Training-through-LLM-Powered-Multi-Agent-System"><a href="#TrainerAgent-Customizable-and-Efficient-Model-Training-through-LLM-Powered-Multi-Agent-System" class="headerlink" title="TrainerAgent: Customizable and Efficient Model Training through LLM-Powered Multi-Agent System"></a>TrainerAgent: Customizable and Efficient Model Training through LLM-Powered Multi-Agent System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06622">http://arxiv.org/abs/2311.06622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyuan Li, Hao Jiang, Tianke Zhang, Zhelun Yu, Aoxiong Yin, Hao Cheng, Siming Fu, Yuhao Zhang, Wanggui He</li>
<li>for: 提高人工智能模型的开发效率和质量，实现个性化服务。</li>
<li>methods: 提出了一种基于多代理系统的TrainerAgent系统，包括任务、数据、模型和服务器代理，这些代理通过分析用户定义的任务、输入数据和要求（如准确率、速度），从数据和模型两个角度全面优化，以获得满足要求的模型，并最终将这些模型部署为在线服务。</li>
<li>results: 实验证明，该系统能够顺利地生成满足要求的模型，并能够检测和排除不可能的任务（如幻想情境或不道德请求），从而确保了系统的可靠性和安全性。<details>
<summary>Abstract</summary>
Training AI models has always been challenging, especially when there is a need for custom models to provide personalized services. Algorithm engineers often face a lengthy process to iteratively develop models tailored to specific business requirements, making it even more difficult for non-experts. The quest for high-quality and efficient model development, along with the emergence of Large Language Model (LLM) Agents, has become a key focus in the industry. Leveraging the powerful analytical, planning, and decision-making capabilities of LLM, we propose a TrainerAgent system comprising a multi-agent framework including Task, Data, Model and Server agents. These agents analyze user-defined tasks, input data, and requirements (e.g., accuracy, speed), optimizing them comprehensively from both data and model perspectives to obtain satisfactory models, and finally deploy these models as online service. Experimental evaluations on classical discriminative and generative tasks in computer vision and natural language processing domains demonstrate that our system consistently produces models that meet the desired criteria. Furthermore, the system exhibits the ability to critically identify and reject unattainable tasks, such as fantastical scenarios or unethical requests, ensuring robustness and safety. This research presents a significant advancement in achieving desired models with increased efficiency and quality as compared to traditional model development, facilitated by the integration of LLM-powered analysis, decision-making, and execution capabilities, as well as the collaboration among four agents. We anticipate that our work will contribute to the advancement of research on TrainerAgent in both academic and industry communities, potentially establishing it as a new paradigm for model development in the field of AI.
</details>
<details>
<summary>摘要</summary>
traditional AI model training has always been challenging, especially when there is a need for custom models to provide personalized services. Algorithm engineers often face a lengthy process to iteratively develop models tailored to specific business requirements, making it even more difficult for non-experts. With the emergence of Large Language Model (LLM) Agents, there is a growing focus on high-quality and efficient model development.我们提出了一种名为TrainerAgent的多智能框架，包括任务、数据、模型和服务器代理。这些代理分析用户定义的任务、输入数据和要求（如准确率和速度），从数据和模型角度进行全面优化，以获得满足要求的模型，并最后将这些模型部署为在线服务。我们的实验评估表明，我们的系统可以适应古典的推论和生成任务，包括计算机视觉和自然语言处理领域。此外，系统还能够批判性地识别和拒绝不可能的任务，如幻想场景或不道德的请求，以确保系统的稳定性和安全性。我们的研究表明，TrainerAgent系统可以在传统模型开发的基础上提供更高效和高质量的模型开发，这得到了LLM智能分析、决策和执行能力的支持，以及代理之间的合作。我们anticipate that our work will contribute to the advancement of research on TrainerAgent in both academic and industry communities, potentially establishing it as a new paradigm for model development in the field of AI.
</details></li>
</ul>
<hr>
<h2 id="Monkey-Image-Resolution-and-Text-Label-Are-Important-Things-for-Large-Multi-modal-Models"><a href="#Monkey-Image-Resolution-and-Text-Label-Are-Important-Things-for-Large-Multi-modal-Models" class="headerlink" title="Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models"></a>Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06607">http://arxiv.org/abs/2311.06607</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuliang-liu/monkey">https://github.com/yuliang-liu/monkey</a></li>
<li>paper_authors: Zhang Li, Biao Yang, Qiang Liu, Zhiyin Ma, Shuo Zhang, Jingxu Yang, Yabo Sun, Yuliang Liu, Xiang Bai</li>
<li>for: 提高大型多modal模型在复杂场景理解和叙述能力</li>
<li>methods: 提出Monkey方法，包括不需要预训练可以使用现有视觉编码器（如vit-BigHuge）进行提高输入分辨率，以及自动生成多级描述方法以便模型学习场景和对象之间的Contextual关系</li>
<li>results: 在多达16个不同的数据集上进行了广泛的测试，发现Monkey在基本任务上（如图像描述、全视Question Answering和文档Question Answering）具有稳定竞争力的表现<details>
<summary>Abstract</summary>
Large Multimodal Models have demonstrated impressive capabilities in understanding general vision-language tasks. However, due to the limitation of supported input resolution (e.g., 448 x 448) as well as the inexhaustive description of the training image-text pair, these models often encounter challenges when dealing with intricate scene understandings and narratives. Here we address the problem by proposing the Monkey. Our contributions are two-fold: 1) without pretraining from the start, our method can be built upon an existing vision encoder (e.g., vit-BigHuge) to effectively improve the input resolution capacity up to 896 x 1344 pixels; 2) we propose a multi-level description generation method, which automatically provides rich information that can guide model to learn contextual association between scenes and objects. Our extensive testing across more than 16 distinct datasets reveals that Monkey achieves consistently competitive performance over the existing LMMs on fundamental tasks, such as Image Captioning, General Visual Question Answering (VQA), and Document-oriented VQA. Models, interactive demo, and the source code are provided at the following https://github.com/Yuliang-Liu/Monkey.
</details>
<details>
<summary>摘要</summary>
大型多Modal模型在通用视力语言任务上表现出了吸引人的能力。然而，由于输入分辨率的限制（例如448x448）以及训练图片文本对的描述不够详细，这些模型经常在处理复杂的场景理解和 narraves 时遇到挑战。我们解决这个问题，我们提出了猴子（Monkey）。我们的贡献有两个方面：1. 不需要先training，我们的方法可以基于现有的视力编码器（例如 vit-BigHuge）来提高输入分辨率capacity到896x1344像素;2. 我们提出了多 уров层描述生成方法，可以自动提供详细的信息，以帮助模型学习场景和物体之间的上下文关系。我们在16个不同的数据集上进行了广泛的测试，发现Monkey在基本任务上（如图像描述、通用视Question Answering和文档 oriented VQA）与现有的LMMs（Large Multimodal Models）具有相当竞争力。我们提供了模型、交互示例和源代码，可以在以下GitHub上下载：https://github.com/Yuliang-Liu/Monkey。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Grokking-Through-A-Robustness-Viewpoint"><a href="#Understanding-Grokking-Through-A-Robustness-Viewpoint" class="headerlink" title="Understanding Grokking Through A Robustness Viewpoint"></a>Understanding Grokking Through A Robustness Viewpoint</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06597">http://arxiv.org/abs/2311.06597</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiquan Tan, Weiran Huang</li>
<li>for: 研究一种名为“grokking”的奇异现象，即神经网络在准确适应训练数据后仍然泛化。</li>
<li>methods: 使用Robustness视角来理解这种现象，并提出新的评价指标基于Robustness和信息理论。</li>
<li>results: 发现$l_2$ нор为神经网络泛化的必要条件，但是$l_2$ norm与测试数据不协调，提出新的评价指标可以协调grokking现象。 Additionally, the proposed method can speed up the generalization process, and learning the commutative law can explain part of the speedup.<details>
<summary>Abstract</summary>
Recently, an unusual phenomenon called grokking has gained much attention, where sometimes a neural network generalizes long after it perfectly fits the training data. We try to understand this seemingly strange phenomenon using the robustness of the neural network. Using a robustness viewpoint, we show that the popular $l_2$ weight norm (metric) of the neural network is actually a sufficient condition for grokking. As we also empirically find that $l_2$ norm correlates with grokking on the test data not in a timely way, we propose new metrics based on robustness and information theory and find that our new metrics correlate well with the grokking phenomenon. Based on the previous observations, we propose methods to speed up the generalization process. In addition, we examine the standard training process on modulo addition dataset and find that it hardly learns other basic group operations before grokking, including the commutative law. Interestingly, the speed up of generalization when using our proposed method can be partially explained by learning the commutative law, a necessary condition when the model groks on test dataset.
</details>
<details>
<summary>摘要</summary>
最近，一种奇异现象叫“grokking”在神经网络领域受到了广泛关注，神经网络在训练数据完美适应后仍然能够泛化。我们使用神经网络的稳定性视角来理解这一现象，并证明了$l_2$质量 нор（度量）是泛化现象的必要条件。然而，我们发现$l_2$ нор与测试数据上的泛化不一致，因此我们提出了基于稳定性和信息理论的新度量，并发现它们与泛化现象有高度相关性。基于以前的观察结果，我们提出了加速泛化过程的方法。此外，我们还检查了模式训练过程中的标准处理方法，发现它几乎不会学习测试数据上的其他基本群操作，包括交换律。Interestingly，使用我们提出的方法可以加速泛化过程，其中一部分可以通过学习交换律来解释，交换律是泛化到测试数据的必要条件。
</details></li>
</ul>
<hr>
<h2 id="An-Intelligent-Social-Learning-based-Optimization-Strategy-for-Black-box-Robotic-Control-with-Reinforcement-Learning"><a href="#An-Intelligent-Social-Learning-based-Optimization-Strategy-for-Black-box-Robotic-Control-with-Reinforcement-Learning" class="headerlink" title="An Intelligent Social Learning-based Optimization Strategy for Black-box Robotic Control with Reinforcement Learning"></a>An Intelligent Social Learning-based Optimization Strategy for Black-box Robotic Control with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06576">http://arxiv.org/abs/2311.06576</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xubo Yang, Jian Gao, Ting Wang, Yaozhen He</li>
<li>for: 这篇论文的目的是提出一种基于社交学习的智能控制算法，以便控制黑盒系统中的机器人。</li>
<li>methods: 这篇论文使用了一种叫做社交学习算法（Intelligent Social Learning，ISL），它包括学习、模仿和自我研究三种式态。</li>
<li>results: 试验结果显示，ISL算法比四种现有方法在六个连续控制测试案例中更有效率，具有更快的计算速度、更少的参数和更高的稳定性。此外，ISL算法在模拟和实验中的抓取任务中也获得了满意的解决方案。<details>
<summary>Abstract</summary>
Implementing intelligent control of robots is a difficult task, especially when dealing with complex black-box systems, because of the lack of visibility and understanding of how these robots work internally. This paper proposes an Intelligent Social Learning (ISL) algorithm to enable intelligent control of black-box robotic systems. Inspired by mutual learning among individuals in human social groups, ISL includes learning, imitation, and self-study styles. Individuals in the learning style use the Levy flight search strategy to learn from the best performer and form the closest relationships. In the imitation style, individuals mimic the best performer with a second-level rapport by employing a random perturbation strategy. In the self-study style, individuals learn independently using a normal distribution sampling method while maintaining a distant relationship with the best performer. Individuals in the population are regarded as autonomous intelligent agents in each style. Neural networks perform strategic actions in three styles to interact with the environment and the robot and iteratively optimize the network policy. Overall, ISL builds on the principles of intelligent optimization, incorporating ideas from reinforcement learning, and possesses strong search capabilities, fast computation speed, fewer hyperparameters, and insensitivity to sparse rewards. The proposed ISL algorithm is compared with four state-of-the-art methods on six continuous control benchmark cases in MuJoCo to verify its effectiveness and advantages. Furthermore, ISL is adopted in the simulation and experimental grasping tasks of the UR3 robot for validations, and satisfactory solutions are yielded.
</details>
<details>
<summary>摘要</summary>
实现智能控制机器人是一项困难任务，特别是面临复杂黑盒系统时，因为lack of visibility和理解机器人内部的工作方式。这篇论文提议一种智能社会学习（ISL）算法，以帮助智能控制黑盒机器人系统。 Drawing inspiration from human social groups' mutual learning, ISL includes learning, imitation, and self-study styles. Individuals in the learning style use Levy flight search strategy to learn from the best performer and form the closest relationships. In the imitation style, individuals mimic the best performer with a second-level rapport by employing a random perturbation strategy. In the self-study style, individuals learn independently using a normal distribution sampling method while maintaining a distant relationship with the best performer. Individuals in the population are regarded as autonomous intelligent agents in each style. Neural networks perform strategic actions in three styles to interact with the environment and the robot and iteratively optimize the network policy. Overall, ISL builds on the principles of intelligent optimization, incorporating ideas from reinforcement learning, and possesses strong search capabilities, fast computation speed, fewer hyperparameters, and insensitivity to sparse rewards. The proposed ISL algorithm is compared with four state-of-the-art methods on six continuous control benchmark cases in MuJoCo to verify its effectiveness and advantages. Furthermore, ISL is adopted in the simulation and experimental grasping tasks of the UR3 robot for validations, and satisfactory solutions are yielded.
</details></li>
</ul>
<hr>
<h2 id="SCADI-Self-supervised-Causal-Disentanglement-in-Latent-Variable-Models"><a href="#SCADI-Self-supervised-Causal-Disentanglement-in-Latent-Variable-Models" class="headerlink" title="SCADI: Self-supervised Causal Disentanglement in Latent Variable Models"></a>SCADI: Self-supervised Causal Disentanglement in Latent Variable Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06567">http://arxiv.org/abs/2311.06567</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hazel-heejeong-nam/self-supervised-causal-disentanglement">https://github.com/hazel-heejeong-nam/self-supervised-causal-disentanglement</a></li>
<li>paper_authors: Heejeong Nam</li>
<li>for: 本研究旨在提出一种新的自助学习 causal disentanglement 模型，即 SCADI（SElf-supervised CAusal DIsentanglement）模型，以便无需指导或标注数据，通过自动学习方式，捕捉 semantic factor 和其 causal 关系。</li>
<li>methods: 本研究使用了 masked structural causal model (SCM) 和 pseudo-label generator 两种方法，以实现无监督的 causal disentanglement。</li>
<li>results: 研究发现，SCADI 模型能够自动学习 semantic factor 和 causal 关系，无需任何指导或标注数据，并且能够生成可读的 causal 拓扑图。<details>
<summary>Abstract</summary>
Causal disentanglement has great potential for capturing complex situations. However, there is a lack of practical and efficient approaches. It is already known that most unsupervised disentangling methods are unable to produce identifiable results without additional information, often leading to randomly disentangled output. Therefore, most existing models for disentangling are weakly supervised, providing information about intrinsic factors, which incurs excessive costs. Therefore, we propose a novel model, SCADI(SElf-supervised CAusal DIsentanglement), that enables the model to discover semantic factors and learn their causal relationships without any supervision. This model combines a masked structural causal model (SCM) with a pseudo-label generator for causal disentanglement, aiming to provide a new direction for self-supervised causal disentanglement models.
</details>
<details>
<summary>摘要</summary>
causal disentanglement 有很大的潜力，可以捕捉复杂的情况。但是，现有的实用和效率的方法缺乏。大多数无监督分解方法无法生成可识别的结果，通常导致随机分解的输出。因此，现有的分解模型都是弱监督的，提供内在因素的信息，这会带来过高的成本。因此，我们提议一种新的模型， namely SCADI（自我监督 causal disentanglement），它可以让模型发现 semantic factor 和学习其 causal 关系，无需任何监督。这个模型将 masked 结构 causal model（SCM）与 pseudo-label 生成器结合，以实现自我监督 causal disentanglement 模型的新方向。
</details></li>
</ul>
<hr>
<h2 id="Heuristics-Driven-Link-of-Analogy-Prompting-Enhancing-Large-Language-Models-for-Document-Level-Event-Argument-Extraction"><a href="#Heuristics-Driven-Link-of-Analogy-Prompting-Enhancing-Large-Language-Models-for-Document-Level-Event-Argument-Extraction" class="headerlink" title="Heuristics-Driven Link-of-Analogy Prompting: Enhancing Large Language Models for Document-Level Event Argument Extraction"></a>Heuristics-Driven Link-of-Analogy Prompting: Enhancing Large Language Models for Document-Level Event Argument Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06555">http://arxiv.org/abs/2311.06555</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanzhang Zhou, Junlang Qian, Zijian Feng, Hui Lu, Zixiao Zhu, Kezhi Mao</li>
<li>for: 这篇论文研究了文档级事件说明抽取（EAE）中的在Context learning（ICL）问题。</li>
<li>methods: 该论文提出了一种名为Heuristic-Driven Link-of-Analogy（HD-LoA）的提示方法，通过示例选择和人工智能学习来帮助模型学习任务特有的规则。</li>
<li>results: 该论文通过实验表明，与现有提示方法和少量监督学习方法相比，HD-LoA提示方法在文档级EAE数据集上实现了4.53%和9.38%的F1分数提升，并在另外两个任务中也达到了2.87%和2.63%的准确率提升。<details>
<summary>Abstract</summary>
In this study, we investigate in-context learning (ICL) in document-level event argument extraction (EAE). The paper identifies key challenges in this problem, including example selection, context length limitation, abundance of event types, and the limitation of Chain-of-Thought (CoT) prompting in non-reasoning tasks. To address these challenges, we introduce the Heuristic-Driven Link-of-Analogy (HD-LoA) prompting method. Specifically, we hypothesize and validate that LLMs learn task-specific heuristics from demonstrations via ICL. Building upon this hypothesis, we introduce an explicit heuristic-driven demonstration construction approach, which transforms the haphazard example selection process into a methodical method that emphasizes task heuristics. Additionally, inspired by the analogical reasoning of human, we propose the link-of-analogy prompting, which enables LLMs to process new situations by drawing analogies to known situations, enhancing their adaptability. Extensive experiments show that our method outperforms the existing prompting methods and few-shot supervised learning methods, exhibiting F1 score improvements of 4.53% and 9.38% on the document-level EAE dataset. Furthermore, when applied to sentiment analysis and natural language inference tasks, the HD-LoA prompting achieves accuracy gains of 2.87% and 2.63%, indicating its effectiveness across different tasks.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们研究了文档级事件参考抽取（EAE）中的内在学习（ICL）。文章标出了该问题的关键挑战，包括示例选择、上下文长度限制、事件类型的充沛和不可靠的链条（CoT）唤起在非逻辑任务中。为解决这些挑战，我们介绍了逻辑驱动链接 аналоги（HD-LoA）唤起方法。具体来说，我们假设并证明了LLMs通过示例示例学习任务特有的规则。基于这个假设，我们提出了一种显式逻辑驱动示例建构方法，将随机示例选择过程变换成一种系统化的方法，注重任务规则。此外，受人类 аналоги性理解的启发，我们提出了链接 аналоги唤起，使LLMs可以通过对已知情况的分析，处理新情况，提高其适应性。广泛的实验表明，我们的方法在文档级EAE数据集上的 F1 分数提高 4.53% 和 9.38%，并在 Sentiment Analysis 和自然语言推理任务上实现了 Accuracy 的提高。
</details></li>
</ul>
<hr>
<h2 id="Is-Machine-Learning-Unsafe-and-Irresponsible-in-Social-Sciences-Paradoxes-and-Reconsidering-from-Recidivism-Prediction-Tasks"><a href="#Is-Machine-Learning-Unsafe-and-Irresponsible-in-Social-Sciences-Paradoxes-and-Reconsidering-from-Recidivism-Prediction-Tasks" class="headerlink" title="Is Machine Learning Unsafe and Irresponsible in Social Sciences? Paradoxes and Reconsidering from Recidivism Prediction Tasks"></a>Is Machine Learning Unsafe and Irresponsible in Social Sciences? Paradoxes and Reconsidering from Recidivism Prediction Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06537">http://arxiv.org/abs/2311.06537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianhong Liu, Dianshi Li</li>
<li>for: 这篇论文旨在探讨高风险事件预测下的计算方法的基础和热点问题。</li>
<li>methods: 论文提出了一些新的思路，挑战了一些常见的机器学习观点，并提出了一种新的方法融合计算方法和传统社会科学方法。</li>
<li>results: 论文的研究结果表明，这种新的方法可以更好地捕捉社会系统的复杂性和不确定性，提高预测的准确性和可靠性。<details>
<summary>Abstract</summary>
The paper addresses some fundamental and hotly debated issues for high-stakes event predictions underpinning the computational approach to social sciences. We question several prevalent views against machine learning and outline a new paradigm that highlights the promises and promotes the infusion of computational methods and conventional social science approaches.
</details>
<details>
<summary>摘要</summary>
Here's a word-for-word translation of the text into Simplified Chinese:文章讨论了社会科学 Computational Approach 高度风险预测的一些基本和热点问题。我们对数据学习的一些常见看法提出了质疑，并提出了一新的思路，强调计算方法和传统社会科学方法的融合。
</details></li>
</ul>
<hr>
<h2 id="MuST-Multimodal-Spatiotemporal-Graph-Transformer-for-Hospital-Readmission-Prediction"><a href="#MuST-Multimodal-Spatiotemporal-Graph-Transformer-for-Hospital-Readmission-Prediction" class="headerlink" title="MuST: Multimodal Spatiotemporal Graph-Transformer for Hospital Readmission Prediction"></a>MuST: Multimodal Spatiotemporal Graph-Transformer for Hospital Readmission Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07608">http://arxiv.org/abs/2311.07608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Miao, Lequan Yu</li>
<li>for: 预测医院复 admit 是一项重要的方法，可以减少复 admit 率，这是评估医疗系统质量和效果的关键因素。</li>
<li>methods: 本研究提出了一种新的模型，即多modal Spatiotemporal Graph-Transformer (MuST)，用于预测医院复 admit。该模型使用图像 convolutional networks 和时间变换器，可以有效地捕捉 EHR 和胸部X光图像中的空间和时间关系。</li>
<li>results: 我们的实验结果表明，包含多modal特征在内的 MuST 模型在 MIMIC-IV 数据集上的性能明显高于单modal方法。此外，我们提出的管道还超过了目前最佳的方法在医院复 admit 预测方面的表现。<details>
<summary>Abstract</summary>
Hospital readmission prediction is considered an essential approach to decreasing readmission rates, which is a key factor in assessing the quality and efficacy of a healthcare system. Previous studies have extensively utilized three primary modalities, namely electronic health records (EHR), medical images, and clinical notes, to predict hospital readmissions. However, the majority of these studies did not integrate information from all three modalities or utilize the spatiotemporal relationships present in the dataset. This study introduces a novel model called the Multimodal Spatiotemporal Graph-Transformer (MuST) for predicting hospital readmissions. By employing Graph Convolution Networks and temporal transformers, we can effectively capture spatial and temporal dependencies in EHR and chest radiographs. We then propose a fusion transformer to combine the spatiotemporal features from the two modalities mentioned above with the features from clinical notes extracted by a pre-trained, domain-specific transformer. We assess the effectiveness of our methods using the latest publicly available dataset, MIMIC-IV. The experimental results indicate that the inclusion of multimodal features in MuST improves its performance in comparison to unimodal methods. Furthermore, our proposed pipeline outperforms the current leading methods in the prediction of hospital readmissions.
</details>
<details>
<summary>摘要</summary>
This study introduces a novel model called the Multimodal Spatiotemporal Graph-Transformer (MuST) to predict hospital readmissions. By utilizing Graph Convolution Networks and temporal transformers, we can effectively capture spatial and temporal dependencies in EHR and chest radiographs. Additionally, we propose a fusion transformer to combine the spatiotemporal features from the two modalities with features from clinical notes extracted by a pre-trained, domain-specific transformer.We evaluate the effectiveness of our method using the latest publicly available dataset, MIMIC-IV. The experimental results show that the inclusion of multimodal features in MuST improves its performance compared to unimodal methods. Furthermore, our proposed pipeline outperforms the current leading methods in predicting hospital readmissions.
</details></li>
</ul>
<hr>
<h2 id="Modeling-Choice-via-Self-Attention"><a href="#Modeling-Choice-via-Self-Attention" class="headerlink" title="Modeling Choice via Self-Attention"></a>Modeling Choice via Self-Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07607">http://arxiv.org/abs/2311.07607</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joohwan Ko, Andrew A. Li</li>
<li>for: 这篇论文的目的是提出一种基于现代神经网络架构的选择模型，以便更好地估计选择问题中的模型。</li>
<li>methods: 该论文使用了一种现代神经网络架构——自注意力机制，来提出一种新的选择模型。这种模型可以在几乎相同的数据样本数下支持估计，而且可以在实际应用中提供更高的准确性。</li>
<li>results: 该论文通过设置一个大规模的实际数据集，并对现有的选择模型进行了大规模的比较，发现该提出的选择模型在短期和长期数据Period内都具有优势。<details>
<summary>Abstract</summary>
Models of choice are a fundamental input to many now-canonical optimization problems in the field of Operations Management, including assortment, inventory, and price optimization. Naturally, accurate estimation of these models from data is a critical step in the application of these optimization problems in practice, and so it is perhaps surprising that such choice estimation has to now been accomplished almost exclusively, both in theory and in practice, (a) without the use of deep learning in any meaningful way, and (b) via evaluation on limited data with constantly-changing metrics. This is in stark contrast to the vast majority of similar learning applications, for which the practice of machine learning suggests that (a) neural network-based models are typically state-of-the-art, and (b) strict standardization on evaluation procedures (datasets, metrics, etc.) is crucial. Thus motivated, we first propose a choice model that is the first to successfully (both theoretically and practically) leverage a modern neural network architectural concept (self-attention). Theoretically, we show that our attention-based choice model is a low-rank generalization of the Halo Multinomial Logit model, a recent model that parsimoniously captures irrational choice effects and has seen empirical success. We prove that whereas the Halo-MNL requires $\Omega(m^2)$ data samples to estimate, where $m$ is the number of products, our model supports a natural nonconvex estimator (in particular, that which a standard neural network implementation would apply) which admits a near-optimal stationary point with $O(m)$ samples. We then establish the first realistic-scale benchmark for choice estimation on real data and use this benchmark to run the largest evaluation of existing choice models to date. We find that the model we propose is dominant over both short-term and long-term data periods.
</details>
<details>
<summary>摘要</summary>
选择模型是操作管理领域的基本输入，包括搭配、存储和价格优化等问题。选择模型的准确估计从数据中是应用这些优化问题的重要步骤，但是到目前为止，大多数实际应用中都使用了深度学习。这是与大多数类似学习应用不同的，后者通常使用神经网络模型，并且在评价过程中坚持标准化。因此，我们首先提出一个利用现代神经网络架构思想（自注意）的选择模型，这是第一个成功地（both theoretically and practically）利用自注意来估计选择模型的实际应用。我们证明了我们的注意力基本是唯一的多omialLogit模型的低级泛化，这是一个最近的模型，可以减少人们的偏好选择效应。我们证明了在$m$是产品数量时，哈洛-多omialLogit模型需要$\Omega(m^2)$的数据样本来估计，而我们的模型可以使用标准神经网络实现，并且可以在$O(m)$的样本数据上获得近似最优的站点。我们然后建立了实际规模的选择估计 benchmark，并使用这个 benchmark 来评估现有的选择模型，发现我们的模型在短期和长期数据期间均占据了主导地位。
</details></li>
</ul>
<hr>
<h2 id="How-ChatGPT-is-Solving-Vulnerability-Management-Problem"><a href="#How-ChatGPT-is-Solving-Vulnerability-Management-Problem" class="headerlink" title="How ChatGPT is Solving Vulnerability Management Problem"></a>How ChatGPT is Solving Vulnerability Management Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06530">http://arxiv.org/abs/2311.06530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiyu Liu, Junming Liu, Lirong Fu, Kangjie Lu, Yifan Xia, Xuhong Zhang, Wenzhi Chen, Haiqin Weng, Shouling Ji, Wenhai Wang<br>for:这个论文旨在探讨ChatGPT是否可以在实际的漏洞管理任务中表现出色，包括预测安全相关性和补丁正确性等多个方面。methods:这个论文使用了ChatGPT完成6个关于漏洞管理过程的任务，并与现有的最佳实践进行比较，以 investigates the impact of different prompts 和 explore the difficulties。results:论文表明，ChatGPT在某些任务中表现出色，如生成软件漏洞报告标题。然而，ChatGPT也遇到了困难，如直接提供随机示例不能保证良好的性能。 Study reveals that leveraging ChatGPT in a self-heuristic way and effectively guiding ChatGPT to focus on helpful information are promising research directions.<details>
<summary>Abstract</summary>
Recently, ChatGPT has attracted great attention from the code analysis domain. Prior works show that ChatGPT has the capabilities of processing foundational code analysis tasks, such as abstract syntax tree generation, which indicates the potential of using ChatGPT to comprehend code syntax and static behaviors. However, it is unclear whether ChatGPT can complete more complicated real-world vulnerability management tasks, such as the prediction of security relevance and patch correctness, which require an all-encompassing understanding of various aspects, including code syntax, program semantics, and related manual comments.   In this paper, we explore ChatGPT's capabilities on 6 tasks involving the complete vulnerability management process with a large-scale dataset containing 78,445 samples. For each task, we compare ChatGPT against SOTA approaches, investigate the impact of different prompts, and explore the difficulties. The results suggest promising potential in leveraging ChatGPT to assist vulnerability management. One notable example is ChatGPT's proficiency in tasks like generating titles for software bug reports. Furthermore, our findings reveal the difficulties encountered by ChatGPT and shed light on promising future directions. For instance, directly providing random demonstration examples in the prompt cannot consistently guarantee good performance in vulnerability management. By contrast, leveraging ChatGPT in a self-heuristic way -- extracting expertise from demonstration examples itself and integrating the extracted expertise in the prompt is a promising research direction. Besides, ChatGPT may misunderstand and misuse the information in the prompt. Consequently, effectively guiding ChatGPT to focus on helpful information rather than the irrelevant content is still an open problem.
</details>
<details>
<summary>摘要</summary>
近来，ChatGPT在代码分析领域引起了广泛关注。先前的研究表明，ChatGPT可以处理基础代码分析任务，如抽象语法树生成，这表明ChatGPT可能可以理解代码语法和静态行为。然而，是否可以使用ChatGPT完成更加复杂的实际漏洞管理任务，例如预测安全相关性和补丁正确性，它们需要覆盖多个方面，包括代码语法、程序 semantics 和相关手动注释。在这篇论文中，我们探索了ChatGPT在6个任务中的能力，这些任务涉及到了整个漏洞管理过程，使用了78445个样本。对于每个任务，我们与SOTA方法进行比较，研究不同的提示的影响，并探索了困难。结果表明可以使用ChatGPT协助漏洞管理，其中一个例子是ChatGPT在生成软件漏洞报告标题上的护法。此外，我们的发现还揭示了ChatGPT遇到的困难，并提供了可能的未来方向。例如，直接在提示中提供随机示例不一定能够在漏洞管理中达到好的表现。相反，通过在提示中抽取示例本身的专家知识，并将其 интегрирова到提示中是一个有前途的研究方向。此外，ChatGPT可能会对提示中的信息进行错误或不当使用，因此有效地引导ChatGPT关注有用的信息而不是无关的内容仍然是一个开放的问题。
</details></li>
</ul>
<hr>
<h2 id="Conceptual-Model-Interpreter-for-Large-Language-Models"><a href="#Conceptual-Model-Interpreter-for-Large-Language-Models" class="headerlink" title="Conceptual Model Interpreter for Large Language Models"></a>Conceptual Model Interpreter for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07605">http://arxiv.org/abs/2311.07605</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fhaer/llm-cmi">https://github.com/fhaer/llm-cmi</a></li>
<li>paper_authors: Felix Härer</li>
<li>for: 这篇论文探讨了使用大语言模型（LLMs）生成和解释概念模型的可能性，并实现了一个概念模型解释器的原型，可以将文本语法生成的概念模型自动渲染为图形模型。</li>
<li>methods: 本论文采用了探索性的研究方法，使用现有的LLMs such as Llama~2和ChatGPT 4生成和解释概念模型，并通过API或本地交互来实现与解释器和LLMs的集成。</li>
<li>results: 本论文的实验结果显示，使用ChatGPT 4和Llama 2生成的模型可以在对话式交互中进行迭代模式化，并且可以在不同的商业和开源LLMs和解释器上支持多种不同的实现方式。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) recently demonstrated capabilities for generating source code in common programming languages. Additionally, commercial products such as ChatGPT 4 started to provide code interpreters, allowing for the automatic execution of generated code fragments, instant feedback, and the possibility to develop and refine in a conversational fashion. With an exploratory research approach, this paper applies code generation and interpretation to conceptual models. The concept and prototype of a conceptual model interpreter is explored, capable of rendering visual models generated in textual syntax by state-of-the-art LLMs such as Llama~2 and ChatGPT 4. In particular, these LLMs can generate textual syntax for the PlantUML and Graphviz modeling software that is automatically rendered within a conversational user interface. The first result is an architecture describing the components necessary to interact with interpreters and LLMs through APIs or locally, providing support for many commercial and open source LLMs and interpreters. Secondly, experimental results for models generated with ChatGPT 4 and Llama 2 are discussed in two cases covering UML and, on an instance level, graphs created from custom data. The results indicate the possibility of modeling iteratively in a conversational fashion.
</details>
<details>
<summary>摘要</summary>
Recently, large language models (LLMs) have shown the ability to generate source code in common programming languages. In addition, commercial products such as ChatGPT 4 have provided code interpreters, allowing for automatic execution of generated code fragments, instant feedback, and the ability to develop and refine in a conversational manner. With an exploratory research approach, this paper applies code generation and interpretation to conceptual models.The concept and prototype of a conceptual model interpreter were explored, capable of rendering visual models generated in textual syntax by state-of-the-art LLMs such as Llama~2 and ChatGPT 4. In particular, these LLMs can generate textual syntax for the PlantUML and Graphviz modeling software that is automatically rendered within a conversational user interface.The first result is an architecture describing the components necessary to interact with interpreters and LLMs through APIs or locally, providing support for many commercial and open-source LLMs and interpreters. Secondly, experimental results for models generated with ChatGPT 4 and Llama 2 are discussed in two cases covering UML and, on an instance level, graphs created from custom data. The results indicate the possibility of modeling iteratively in a conversational fashion.Here's the text in Traditional Chinese:最近，大型语言模型（LLMs）已经显示出生成常用程式语言的源代码的能力。此外，商业产品如ChatGPT 4已经提供了代码解释器，允许将生成的代码片段自动执行，并提供了即时反馈和开发和细化在对话方式下的能力。透过探索性研究方法，这篇论文将应用代码生成和解释到概念模型。这篇论文探索了一个概念模型解释器的概念和原型，可以将由现代 LLMs 如Llama~2和ChatGPT 4生成的文本 syntax 自动转换为可见的Visual模型。具体来说，这些 LLMs 可以生成 PlantUML 和 Graphviz 模型软件的文本 syntax，并将其自动转换为可见的Visual模型。论文的首个结果是一个架构，描述了与解释器和 LLMs 进行交互的 ком成�ionen，以及支持多个商业和开源 LLMs 和解释器的架构。其次，这篇论文针对使用 ChatGPT 4 和 Llama 2 生成的模型进行实验，并分为两个情况进行讨论：UML 和具体情况下的图形。结果显示了可以在对话方式下进行迭代式模型化。
</details></li>
</ul>
<hr>
<h2 id="BClean-A-Bayesian-Data-Cleaning-System"><a href="#BClean-A-Bayesian-Data-Cleaning-System" class="headerlink" title="BClean: A Bayesian Data Cleaning System"></a>BClean: A Bayesian Data Cleaning System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06517">http://arxiv.org/abs/2311.06517</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yyssl88/bclean">https://github.com/yyssl88/bclean</a></li>
<li>paper_authors: Jianbin Qin, Sifan Huang, Yaoshu Wang, Jing Zhu, Yifan Zhang, Yukai Miao, Rui Mao, Makoto Onizuka, Chuan Xiao<br>for:BClean is proposed to solve the problem of data cleaning, which is a crucial step in data preprocessing and machine learning.methods:BClean uses Bayesian inference and automatic Bayesian network construction, which can fully exploit the relationships between attributes in the observed dataset and any prior information provided by users. The system also includes an effective scoring model and several approximation strategies to enhance the efficiency of data cleaning.results:BClean achieves an F-measure of up to 0.9 in data cleaning, outperforming existing Bayesian methods by 2% and other data cleaning methods by 15%.<details>
<summary>Abstract</summary>
There is a considerable body of work on data cleaning which employs various principles to rectify erroneous data and transform a dirty dataset into a cleaner one. One of prevalent approaches is probabilistic methods, including Bayesian methods. However, existing probabilistic methods often assume a simplistic distribution (e.g., Gaussian distribution), which is frequently underfitted in practice, or they necessitate experts to provide a complex prior distribution (e.g., via a programming language). This requirement is both labor-intensive and costly, rendering these methods less suitable for real-world applications. In this paper, we propose BClean, a Bayesian Cleaning system that features automatic Bayesian network construction and user interaction. We recast the data cleaning problem as a Bayesian inference that fully exploits the relationships between attributes in the observed dataset and any prior information provided by users. To this end, we present an automatic Bayesian network construction method that extends a structure learning-based functional dependency discovery method with similarity functions to capture the relationships between attributes. Furthermore, our system allows users to modify the generated Bayesian network in order to specify prior information or correct inaccuracies identified by the automatic generation process. We also design an effective scoring model (called the compensative scoring model) necessary for the Bayesian inference. To enhance the efficiency of data cleaning, we propose several approximation strategies for the Bayesian inference, including graph partitioning, domain pruning, and pre-detection. By evaluating on both real-world and synthetic datasets, we demonstrate that BClean is capable of achieving an F-measure of up to 0.9 in data cleaning, outperforming existing Bayesian methods by 2% and other data cleaning methods by 15%.
</details>
<details>
<summary>摘要</summary>
有一大量的研究在数据清洁方面，这些方法使用不同的原则来修正错误数据并将废弃数据集转换为一个更加干净的数据集。其中一种常见的方法是概率方法，包括极 bayesian 方法。然而，现有的概率方法 frequently 假设一个简单的分布（例如， Gaussian 分布），这些分布在实际应用中 часто 被做不当，或者需要专家提供复杂的先前分布（例如，通过编程语言）。这种需求是 Both labor-intensive and costly，使得这些方法在实际应用中不太适用。在这篇论文中，我们提出 BClean，一个基于 Bayesian 的数据清洁系统。我们将数据清洁问题转换为 Bayesian 推理，并将用户提供的先前信息和观察数据中的关系完全利用。为此，我们提出一种自动生成 Bayesian 网络的方法，该方法基于结构学习-基于函数依赖性发现的方法，并使用相似函数来捕捉属性之间的关系。此外，我们的系统允许用户修改生成的 Bayesian 网络，以便指定先前信息或者更正由自动生成过程发现的错误。我们还设计了一种有效的评分模型（即补偿评分模型），以便实现 Bayesian 推理。为提高数据清洁的效率，我们提出了多种approximation 策略，包括图 partitioning、domain pruning 和 pre-detection。通过对真实数据和 sintetic 数据进行评估，我们示出 BClean 可以在数据清洁中 achiev 0.9 的 F-度，比既 Bayesian 方法高 2%，比其他数据清洁方法高 15%。
</details></li>
</ul>
<hr>
<h2 id="Step-by-Step-to-Fairness-Attributing-Societal-Bias-in-Task-oriented-Dialogue-Systems"><a href="#Step-by-Step-to-Fairness-Attributing-Societal-Bias-in-Task-oriented-Dialogue-Systems" class="headerlink" title="Step by Step to Fairness: Attributing Societal Bias in Task-oriented Dialogue Systems"></a>Step by Step to Fairness: Attributing Societal Bias in Task-oriented Dialogue Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06513">http://arxiv.org/abs/2311.06513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hsuan Su, Rebecca Qian, Chinnadhurai Sankar, Shahin Shayandeh, Shang-Tse Chen, Hung-yi Lee, Daniel M. Bikel</li>
<li>for: 本文旨在描述一种用于诊断对话系统中偏见的诊断方法，以帮助研究人员更深入地理解偏见的来源。</li>
<li>methods: 本文使用了预训练的大语言模型（LLM），并通过综合分析各个系统 ком ponent的偏见行为，进行偏见诊断。</li>
<li>results: 实验结果表明，对话系统中的偏见通常来自于响应生成模型，而不是其他系统 ком ponent。<details>
<summary>Abstract</summary>
Recent works have shown considerable improvements in task-oriented dialogue (TOD) systems by utilizing pretrained large language models (LLMs) in an end-to-end manner. However, the biased behavior of each component in a TOD system and the error propagation issue in the end-to-end framework can lead to seriously biased TOD responses. Existing works of fairness only focus on the total bias of a system. In this paper, we propose a diagnosis method to attribute bias to each component of a TOD system. With the proposed attribution method, we can gain a deeper understanding of the sources of bias. Additionally, researchers can mitigate biased model behavior at a more granular level. We conduct experiments to attribute the TOD system's bias toward three demographic axes: gender, age, and race. Experimental results show that the bias of a TOD system usually comes from the response generation model.
</details>
<details>
<summary>摘要</summary>
近期研究已经显示了使用预训练大型自然语言模型（LLM）的端到端方式可以获得显著改进的任务对话（TOD）系统。然而，TOD系统中每个组件的偏见行为以及端到端框架中的错误卷积问题可能会导致严重的偏见TOD响应。现有的公平性研究只关注系统总体偏见。在这篇论文中，我们提出了一种诊断方法，用于归因TOD系统中各组件的偏见。通过该归因方法，我们可以更深入地了解偏见的来源。此外，研究人员可以在更细化的水平上 mitigate 模型偏见行为。我们对TOD系统的偏见进行了三个民族轴的诊断：性别、年龄和种族。实验结果表明，TOD系统的偏见通常来自于响应生成模型。
</details></li>
</ul>
<hr>
<h2 id="Knowledgeable-Preference-Alignment-for-LLMs-in-Domain-specific-Question-Answering"><a href="#Knowledgeable-Preference-Alignment-for-LLMs-in-Domain-specific-Question-Answering" class="headerlink" title="Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering"></a>Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06503">http://arxiv.org/abs/2311.06503</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zjukg/knowpat">https://github.com/zjukg/knowpat</a></li>
<li>paper_authors: Yichi Zhang, Zhuo Chen, Yin Fang, Lei Cheng, Yanxi Lu, Fangming Li, Wen Zhang, Huajun Chen</li>
<li>for: 这 paper 的目的是应用语言模型 (LLM) 于域pecific问答 (QA) 领域，利用域知 graph (KG)，以解决现实Scene 中 LLM 应用中的两个主要difficulty：一是生成内容需要是用户友好的，二是模型需要正确地利用域知ledge。</li>
<li>methods: 这 paper 提出了一个新的管道，称为 Knowledgeable Preference AlignmenT (KnowPAT)，它使用了两种偏好集合：style preference set 和 knowledge preference set，并设计了一个新的对 alignment 目标，以让 LLM 的偏好与人类偏好相align。</li>
<li>results: 根据对 15 个基线方法的比较，这 paper 的 KnowPAT 管道在实际Scene 中域specific问答中表现出色，超越了 15 个基eline方法。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/zjukg/KnowPAT">https://github.com/zjukg/KnowPAT</a> 上获取。<details>
<summary>Abstract</summary>
Recently, the development of large language models (LLMs) has attracted wide attention in academia and industry. Deploying LLMs to real scenarios is one of the key directions in the current Internet industry. In this paper, we present a novel pipeline to apply LLMs for domain-specific question answering (QA) that incorporates domain knowledge graphs (KGs), addressing an important direction of LLM application. As a real-world application, the content generated by LLMs should be user-friendly to serve the customers. Additionally, the model needs to utilize domain knowledge properly to generate reliable answers. These two issues are the two major difficulties in the LLM application as vanilla fine-tuning can not adequately address them. We think both requirements can be unified as the model preference problem that needs to align with humans to achieve practical application. Thus, we introduce Knowledgeable Preference AlignmenT (KnowPAT), which constructs two kinds of preference set called style preference set and knowledge preference set respectively to tackle the two issues. Besides, we design a new alignment objective to align the LLM preference with human preference, aiming to train a better LLM for real-scenario domain-specific QA to generate reliable and user-friendly answers. Adequate experiments and comprehensive with 15 baseline methods demonstrate that our KnowPAT is an outperforming pipeline for real-scenario domain-specific QA with LLMs. Our code is open-source at https://github.com/zjukg/KnowPAT.
</details>
<details>
<summary>摘要</summary>
最近，大型语言模型（LLM）的发展吸引了学术和产业界的广泛关注。将LLM应用到实际场景是当前互联网业界的一个重要方向。在这篇论文中，我们提出了一个新的管道，用于将LLM应用于域pecific问答（QA）中，并利用域知识图（KG），解决LLM应用中的重要方向。作为实际应用，生成的内容应该是用户友好，以服务于客户。此外，模型需要正确地利用域知识，以生成可靠的答案。这两个问题是LLM应用中的两大difficulty，vanilla fine-tuning无法充分解决。我们认为，这两个问题可以被统称为模型偏好问题，需要与人类Alignment，以实现实际应用。因此，我们提出了知识偏好Alignment（KnowPAT），它构建了两种偏好集，namely style preference set和knowledge preference set，分别解决这两个问题。此外，我们设计了一个新的对Alignment objective，以将LLM的偏好与人类偏好Alignment，以训练更好的LLM，以生成可靠和用户友好的答案。我们的实验和对15种基准方法进行了详细的比较，示出了我们的KnowPAT在实际场景下的域pecific问答with LLM的表现优于15种基准方法。我们的代码可以在https://github.com/zjukg/KnowPAT上获取。
</details></li>
</ul>
<hr>
<h2 id="DRUformer-Enhancing-the-driving-scene-Important-object-detection-with-driving-relationship-self-understanding"><a href="#DRUformer-Enhancing-the-driving-scene-Important-object-detection-with-driving-relationship-self-understanding" class="headerlink" title="DRUformer: Enhancing the driving scene Important object detection with driving relationship self-understanding"></a>DRUformer: Enhancing the driving scene Important object detection with driving relationship self-understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06497">http://arxiv.org/abs/2311.06497</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingjie Niu, Ming Ding, Keisuke Fujii, Kento Ohtani, Alexander Carballo, Kazuya Takeda<br>for: 这篇论文的目的是帮助车辆预测重要的物体，以提高安全驾驶。methods: 这篇论文使用了一个名为DRUformer的多模式转换器模型，考虑了所有参与者之间的关系，并将驾驶意向 embed 到模型中。results: 该模型在DRAMA数据集上进行比较实验，与其他现有的SOTA模型进行比较，获得了16.2%的mIoU提升和12.3%的ACC提升。此外，该模型在不同的道路场景和类别下实现了重要物体检测的多元效果。<details>
<summary>Abstract</summary>
Traffic accidents frequently lead to fatal injuries, contributing to over 50 million deaths until 2023. To mitigate driving hazards and ensure personal safety, it is crucial to assist vehicles in anticipating important objects during travel. Previous research on important object detection primarily assessed the importance of individual participants, treating them as independent entities and frequently overlooking the connections between these participants. Unfortunately, this approach has proven less effective in detecting important objects in complex scenarios. In response, we introduce Driving scene Relationship self-Understanding transformer (DRUformer), designed to enhance the important object detection task. The DRUformer is a transformer-based multi-modal important object detection model that takes into account the relationships between all the participants in the driving scenario. Recognizing that driving intention also significantly affects the detection of important objects during driving, we have incorporated a module for embedding driving intention. To assess the performance of our approach, we conducted a comparative experiment on the DRAMA dataset, pitting our model against other state-of-the-art (SOTA) models. The results demonstrated a noteworthy 16.2\% improvement in mIoU and a substantial 12.3\% boost in ACC compared to SOTA methods. Furthermore, we conducted a qualitative analysis of our model's ability to detect important objects across different road scenarios and classes, highlighting its effectiveness in diverse contexts. Finally, we conducted various ablation studies to assess the efficiency of the proposed modules in our DRUformer model.
</details>
<details>
<summary>摘要</summary>
交通事故常引起致命伤害，至2023年已经导致50多万人死亡。为了实现安全驾驶和预防驾驶危险，它是非常重要的帮助车辆预测重要的物件。过去的研究主要集中在个人参与者的重要性，将它们视为独立的实体，往往忽略了参与者之间的关系。可是，这种方法在复杂的情况下显示出较差的检测效果。因此，我们提出了驾驶景况关系自我理解变数former（DRUformer），用于提高重要物件检测任务。DRUformer 是基于 transformer 的多模式重要物件检测模型，考虑所有参与者在驾驶景况中的关系。认识到驾驶意向也对重要物件检测 during driving 有重要影响，我们将驾驶意向模块 embed 到我们的模型中。为了评估我们的方法效果，我们在 DRAMA dataset 上进行了比较性实验，与其他现有的 SOTA 方法进行比较。结果显示 DRUformer 在 mIoU 方面获得了可注目的 16.2% 提升，并在 ACC 方面获得了重要的 12.3% 提升，与 SOTA 方法相比。此外，我们进行了多种简洁分析，以评估 DRUformer 模型在不同的道路enario 和类别中的效果，显示它在多元的情况下具有优秀的效果。最后，我们进行了多种简洁分析，以评估 DRUformer 模型中各个模块的效率。
</details></li>
</ul>
<hr>
<h2 id="Finetuning-Text-to-Image-Diffusion-Models-for-Fairness"><a href="#Finetuning-Text-to-Image-Diffusion-Models-for-Fairness" class="headerlink" title="Finetuning Text-to-Image Diffusion Models for Fairness"></a>Finetuning Text-to-Image Diffusion Models for Fairness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07604">http://arxiv.org/abs/2311.07604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xudong Shen, Chao Du, Tianyu Pang, Min Lin, Yongkang Wong, Mohan Kankanhalli</li>
<li>for: 这篇论文目的是实现文本至图像传播模型中的公平性。</li>
<li>methods: 这篇论文使用了两个主要技术贡献：首先，一个 Distributional alignment loss，可以将生成图像中的特定特征调整到使用者定义的目标分布上；其次，偏见直接调整Diffusion Model的抽样过程，这样可以更好地优化生成图像上的损失。</li>
<li>results: 这篇论文的实验结果表明，使用我们的方法可以对职业描述进行重大减少gender、race和其 intersectional偏见。 gender偏见可以在仅五个软标签的情况下得到明显减少。更重要的是，我们的方法可以支持多种公平的观点，例如控制年龄分布为75%的年轻人和25%的老人，同时对gender和race进行减少偏见。最后，我们的方法可以应对多个概念的偏见，只需要在调整资料中包含这些描述。<details>
<summary>Abstract</summary>
The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a distorted worldview and limit opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) biased direct finetuning of diffusion model's sampling process, which leverages a biased gradient to more effectively optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives of fairness beyond absolute equality, which is demonstrated by controlling age to a $75\%$ young and $25\%$ old distribution while simultaneously debiasing gender and race. Finally, our method is scalable: it can debias multiple concepts at once by simply including these prompts in the finetuning data. We hope our work facilitates the social alignment of T2I generative AI. We will share code and various debiased diffusion model adaptors.
</details>
<details>
<summary>摘要</summary>
社会中文本到图像扩散模型的快速采纳标志着必须解决这些模型的偏见。如果没有干预措施，这些偏见可能会延续一个扭曲的世界观和限制少数群体的机会。在这项工作中，我们将公平视为分布对齐问题。我们的解决方案包括两个主要技术贡献：1. 分布对齐损失，使生成图像的特定特征向用户定义的目标分布进行调整。2. 偏见直接训练扩散模型的采样过程的方法，利用偏见的梯度更好地优化生成图像上的损失。实验表明，我们的方法可以显著减少 gender、种族和他们的交叉性偏见，特别是只需要五个软token进行微调。此外，我们的方法还可以控制年龄分布，将图像生成到75%的年轻人和25%的老年人之间。最后，我们的方法可以同时控制多个概念的偏见，只需要在微调数据中包含这些提示。我们希望我们的工作可以促进文本到图像生成AI的社会对齐。我们将分享代码和多个减偏 diffusion model adapter。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Language-based-Mental-Health-Assessment-with-Item-Response-Theory"><a href="#Adaptive-Language-based-Mental-Health-Assessment-with-Item-Response-Theory" class="headerlink" title="Adaptive Language-based Mental Health Assessment with Item-Response Theory"></a>Adaptive Language-based Mental Health Assessment with Item-Response Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06467">http://arxiv.org/abs/2311.06467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasudha Varadarajan, Sverker Sikström, Oscar N. E. Kjell, H. Andrew Schwartz</li>
<li>For: 这个研究旨在开发一种适应语言基本评估方法，以估计个人的心理分数基于有限的语言回答。* Methods: 研究使用了两种统计学学习方法：类传统测试理论（CTT）和项回快捷论（IRT）。* Results: 研究发现，使用适应测试可以大幅减少需要ask的问题数量，从11个问题降低到3个问题（对于抑郁）和5个问题（对于焦虑），而且使用ALIRT模型可以实现最高的准确率（如 Pearson r ≈ 0.93 ），同时减少问题数量。<details>
<summary>Abstract</summary>
Mental health issues widely vary across individuals - the manifestations of signs and symptoms can be fairly heterogeneous. Recently, language-based depression and anxiety assessments have shown promise for capturing this heterogeneous nature by evaluating a patient's own language, but such approaches require a large sample of words per person to be accurate. In this work, we introduce adaptive language-based assessment - the task of iteratively estimating an individual's psychological score based on limited language responses to questions that the model also decides to ask. To this end, we explore two statistical learning-based approaches for measurement/scoring: classical test theory (CTT) and item response theory (IRT). We find that using adaptive testing in general can significantly reduce the number of questions required to achieve high validity (r ~ 0.7) with standardized tests, bringing down from 11 total questions down to 3 for depression and 5 for anxiety. Given the combinatorial nature of the problem, we empirically evaluate multiple strategies for both the ordering and scoring objectives, introducing two new methods: a semi-supervised item response theory based method (ALIRT), and a supervised actor-critic based model. While both of the models achieve significant improvements over random and fixed orderings, we find ALIRT to be a scalable model that achieves the highest accuracy with lower numbers of questions (e.g. achieves Pearson r ~ 0.93 after only 3 questions versus asking all 11 questions). Overall, ALIRT allows prompting a reduced number of questions without compromising accuracy or overhead computational costs.
</details>
<details>
<summary>摘要</summary>
心理健康问题在各个人之间很有差异 - 症状的表现可以很异化。在最近的语言基于评估中，使用患者自己的语言来评估心理健康的表现已经显示了批 promise。然而，这些方法需要每个人提供大量的语言数据来达到准确性。在这种情况下，我们介绍了适应语言基本评估 - 通过限制语言问题的数量来评估个体的心理分数。为此，我们 explore了两种统计学学习方法：классиical test theory（CTT）和item response theory（IRT）。我们发现，使用适应测试可以significantly reducethe number of questions required to achieve high validity（r ≈ 0.7）with standardized tests，从11个问题降低到3个问题（对压力问题）和5个问题（对抑郁问题）。由于问题的组合性，我们进行了多种策略的实验性评估，包括两种新方法：一种基于 semi-supervised item response theory的方法（ALIRT），以及一种基于supervised actor-critic模型的方法。虽然两种模型都实现了 Random和固定顺序的改进，但我们发现 ALIRT 是一种可扩展的模型，可以在减少问题数量的情况下保持高度的准确性（例如，在只需要3个问题时达到 Pearson r ≈ 0.93）。总之，ALIRT 允许在减少问题数量的情况下进行评估，不会增加计算成本或承载压力。
</details></li>
</ul>
<hr>
<h2 id="Electronic-Communication-Data-Link-Encryption-Simulation-Based-on-Wireless-Communication"><a href="#Electronic-Communication-Data-Link-Encryption-Simulation-Based-on-Wireless-Communication" class="headerlink" title="Electronic Communication Data Link Encryption Simulation Based on Wireless Communication"></a>Electronic Communication Data Link Encryption Simulation Based on Wireless Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06462">http://arxiv.org/abs/2311.06462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rulin Bai</li>
<li>for: 提高电子通信数据链Encryption的模拟效果</li>
<li>methods: 基于无线通信技术研究，提高护圈卷私钥 cryptographic algorithm，建立系统加密模型，获取合法有效节点私钥，评估系统安全特性，验证钥匙安全性，实现无线网络通信加密优化</li>
<li>results: 实验结果表明，使用改进的护圈卷私钥 cryptographic algorithm simulate系统数据链Encryption在无线网络通信中，时间只需2.31毫秒，比其他算法更低。结论：研究表明，基于无线通信技术可以有效提高电子通信数据链Encryption的模拟效果。<details>
<summary>Abstract</summary>
In order to improve the simulation effect of electronic communication data link encryption, the author proposes a solution based on wireless communication. The main content of this technology is based on the research of wireless communication, improve the elliptic curve cryptographic algorithm to build a system encryption model, obtain legal and valid node private keys, evaluate and analyze the relevant security attributes of the system, verify the security of the keys, and realize the encryption optimization of wireless network communication. Experimental results show that: Using the improved elliptic curve to simulate the system data chain encryption under the certificateless public key cryptosystem in network communication, the time is only 2.31 milliseconds, which is lower than other algorithms. Conclusion: It is proved that the technology research based on wireless communication can effectively improve the encryption simulation effect of electronic communication data link.
</details>
<details>
<summary>摘要</summary>
要提高电子通信数据链加密的模拟效果，作者提出了基于无线通信的解决方案。该技术的主要内容是基于无线通信的研究，改进椭圆曲线密码算法，建立系统加密模型，获得法理合法的节点私钥，评估和分析系统安全特性，验证密钥安全性，并实现无线网络通信加密优化。实验结果显示，使用改进的椭圆曲线来模拟系统数据链加密under certificateless public key cryptosystem在网络通信中，时间只需2.31毫秒，比其他算法更低。结论：研究表明，基于无线通信技术可以有效地提高电子通信数据链加密的模拟效果。
</details></li>
</ul>
<hr>
<h2 id="Online-Advertisements-with-LLMs-Opportunities-and-Challenges"><a href="#Online-Advertisements-with-LLMs-Opportunities-and-Challenges" class="headerlink" title="Online Advertisements with LLMs: Opportunities and Challenges"></a>Online Advertisements with LLMs: Opportunities and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07601">http://arxiv.org/abs/2311.07601</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soheil Feizi, MohammadTaghi Hajiaghayi, Keivan Rezaei, Suho Shin</li>
<li>for: 这篇论文探讨了在在线广告系统中使用大语言模型（LLM）的可能性。</li>
<li>methods: 论文介绍了必须满足的基本需求，包括隐私、延迟、可靠性、用户和广告商满意度。并提出了一个通用的LLM广告框架，包括修改、拍卖、预测和拍卖模块。</li>
<li>results: 论文提出了不同设计考虑和实施技术挑战。<details>
<summary>Abstract</summary>
This paper explores the potential for leveraging Large Language Models (LLM) in the realm of online advertising systems. We delve into essential requirements including privacy, latency, reliability, users and advertisers' satisfaction, which such a system must fulfill. We further introduce a general framework for LLM advertisement, consisting of modification, bidding, prediction, and auction modules. Different design considerations for each module is presented, with an in-depth examination of their practicality and the technical challenges inherent to their implementation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Aria-NeRF-Multimodal-Egocentric-View-Synthesis"><a href="#Aria-NeRF-Multimodal-Egocentric-View-Synthesis" class="headerlink" title="Aria-NeRF: Multimodal Egocentric View Synthesis"></a>Aria-NeRF: Multimodal Egocentric View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06455">http://arxiv.org/abs/2311.06455</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiankai Sun, Jianing Qiu, Chuanyang Zheng, John Tucker, Javier Yu, Mac Schwager<br>for:  This paper aims to accelerate research in developing rich, multimodal scene models trained from egocentric data, with applications in VR&#x2F;AR and intelligent agents.methods:  The paper uses differentiable volumetric ray-tracing inspired by Neural Radiance Fields (NeRFs) to construct a NeRF-like model from an egocentric image sequence.results:  The paper presents a comprehensive multimodal egocentric video dataset, featuring diverse data modalities and real-world context, as a foundation for furthering our understanding of human behavior and enabling more immersive and intelligent experiences in VR, AR, and robotics.<details>
<summary>Abstract</summary>
We seek to accelerate research in developing rich, multimodal scene models trained from egocentric data, based on differentiable volumetric ray-tracing inspired by Neural Radiance Fields (NeRFs). The construction of a NeRF-like model from an egocentric image sequence plays a pivotal role in understanding human behavior and holds diverse applications within the realms of VR/AR. Such egocentric NeRF-like models may be used as realistic simulations, contributing significantly to the advancement of intelligent agents capable of executing tasks in the real-world. The future of egocentric view synthesis may lead to novel environment representations going beyond today's NeRFs by augmenting visual data with multimodal sensors such as IMU for egomotion tracking, audio sensors to capture surface texture and human language context, and eye-gaze trackers to infer human attention patterns in the scene. To support and facilitate the development and evaluation of egocentric multimodal scene modeling, we present a comprehensive multimodal egocentric video dataset. This dataset offers a comprehensive collection of sensory data, featuring RGB images, eye-tracking camera footage, audio recordings from a microphone, atmospheric pressure readings from a barometer, positional coordinates from GPS, connectivity details from Wi-Fi and Bluetooth, and information from dual-frequency IMU datasets (1kHz and 800Hz) paired with a magnetometer. The dataset was collected with the Meta Aria Glasses wearable device platform. The diverse data modalities and the real-world context captured within this dataset serve as a robust foundation for furthering our understanding of human behavior and enabling more immersive and intelligent experiences in the realms of VR, AR, and robotics.
</details>
<details>
<summary>摘要</summary>
我们寻求加速开展具有丰富多modal scene模型的研究，基于可微分数据trace的射影类似NeRF（Neural Radiance Fields）。从 Egocentric 影像序列建立NeRF-like模型扮演着重要的角色，可以更好地理解人类行为，并具有广泛应用于VR/AR等领域。这些 Egocentric NeRF-like 模型可以用来生成真实的simulation，对于在真实世界中进行任务的智能代理人具有重要意义。未来的 Egocentric 视角合成可能将会超越今天的NeRFs，通过与多modal感应器（如IMU、Audio、眼动追踪等）集成，增强视觉数据，并从人类语言上下文中获取更多的信息。为了支持和促进 Egocentric 多modal scene 模型的开发和评估，我们提供了一个完整的多modal Egocentric 影像Dataset。这个dataset包括RGB图像、眼动摄影机、麦克风录音、气压测量、GPS位置坐标、Wi-Fi和蓝牙连接资讯以及双频率IMU数据（1kHz和800Hz）和磁ometer。这个dataset在Meta Aria Glasses 挂架台上进行收集。这个多modal的数据模式和在真实世界中捕捉的情感上，将成为更好的基础 для进一步理解人类行为，并实现更 immerse 和智能的VR、AR和机器人体验。
</details></li>
</ul>
<hr>
<h2 id="THOS-A-Benchmark-Dataset-for-Targeted-Hate-and-Offensive-Speech"><a href="#THOS-A-Benchmark-Dataset-for-Targeted-Hate-and-Offensive-Speech" class="headerlink" title="THOS: A Benchmark Dataset for Targeted Hate and Offensive Speech"></a>THOS: A Benchmark Dataset for Targeted Hate and Offensive Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06446">http://arxiv.org/abs/2311.06446</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mohaimeed/thos">https://github.com/mohaimeed/thos</a></li>
<li>paper_authors: Saad Almohaimeed, Saleh Almohaimeed, Ashfaq Ali Shafin, Bogdan Carbunar, Ladislau Bölöni</li>
<li>for: 这篇论文的目的是提供一个精细的推特上的危险内容分类 dataset，以便使用大型自然语言模型来进行分类。</li>
<li>methods: 本论文使用了 manually labeled 的 tweets，并使用了 Large Language Models 来进行分类。</li>
<li>results: 研究人员通过使用 THOS  dataset，成功地使用 Large Language Models 进行分类，并达到了高度的准确率。<details>
<summary>Abstract</summary>
Detecting harmful content on social media, such as Twitter, is made difficult by the fact that the seemingly simple yes/no classification conceals a significant amount of complexity. Unfortunately, while several datasets have been collected for training classifiers in hate and offensive speech, there is a scarcity of datasets labeled with a finer granularity of target classes and specific targets. In this paper, we introduce THOS, a dataset of 8.3k tweets manually labeled with fine-grained annotations about the target of the message. We demonstrate that this dataset makes it feasible to train classifiers, based on Large Language Models, to perform classification at this level of granularity.
</details>
<details>
<summary>摘要</summary>
检测社交媒体上的危险内容，如推特上的负面或仇恨言论，受到复杂性的限制。实际上，许多数据集已经为训练分类器而收集，但是它们的标签精度尚不够。在这篇论文中，我们介绍了THOS数据集，包含8.3万个推特消息的手动标注细化目标类别。我们示示了这个数据集使得基于大语言模型的分类器可以在这种精度水平上进行分类。
</details></li>
</ul>
<hr>
<h2 id="Controllability-Constrained-Deep-Network-Models-for-Enhanced-Control-of-Dynamical-Systems"><a href="#Controllability-Constrained-Deep-Network-Models-for-Enhanced-Control-of-Dynamical-Systems" class="headerlink" title="Controllability-Constrained Deep Network Models for Enhanced Control of Dynamical Systems"></a>Controllability-Constrained Deep Network Models for Enhanced Control of Dynamical Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06438">http://arxiv.org/abs/2311.06438</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suruchi1997/controlledvae">https://github.com/suruchi1997/controlledvae</a></li>
<li>paper_authors: Suruchi Sharma, Volodymyr Makarenko, Gautam Kumar, Stas Tiomkin</li>
<li>for: 这篇论文的目的是提出一种控制理论基于的方法，以提高由数据驱动的模型中的控制性。</li>
<li>methods: 这篇论文使用了深度神经网络（DNN）来估算未知动力学模型，并在控制输入和状态观测输出之间进行数据驱动模型的估算。</li>
<li>results: 该方法可以提高模型中的控制性，并且可以提供更高效的控制器、更好的解释性和更低的长期预测误差。这些结果表明了数据驱动模型的控制性可以通过控制理论基于的方法进行改进。<details>
<summary>Abstract</summary>
Control of a dynamical system without the knowledge of dynamics is an important and challenging task. Modern machine learning approaches, such as deep neural networks (DNNs), allow for the estimation of a dynamics model from control inputs and corresponding state observation outputs. Such data-driven models are often utilized for the derivation of model-based controllers. However, in general, there are no guarantees that a model represented by DNNs will be controllable according to the formal control-theoretical meaning of controllability, which is crucial for the design of effective controllers. This often precludes the use of DNN-estimated models in applications, where formal controllability guarantees are required. In this proof-of-the-concept work, we propose a control-theoretical method that explicitly enhances models estimated from data with controllability. That is achieved by augmenting the model estimation objective with a controllability constraint, which penalizes models with a low degree of controllability. As a result, the models estimated with the proposed controllability constraint allow for the derivation of more efficient controllers, they are interpretable by the control-theoretical quantities and have a lower long-term prediction error. The proposed method provides new insights on the connection between the DNN-based estimation of unknown dynamics and the control-theoretical guarantees of the solution properties. We demonstrate the superiority of the proposed method in two standard classical control systems with state observation given by low resolution high-dimensional images.
</details>
<details>
<summary>摘要</summary>
<<sys.language_model.translate(text="Control of a dynamical system without knowledge of dynamics is an important and challenging task. Modern machine learning approaches, such as deep neural networks (DNNs), allow for the estimation of a dynamics model from control inputs and corresponding state observation outputs. However, there are no guarantees that a model represented by DNNs will be controllable according to the formal control-theoretical meaning of controllability, which is crucial for the design of effective controllers. In this proof-of-concept work, we propose a control-theoretical method that explicitly enhances models estimated from data with controllability. The proposed method provides new insights on the connection between the DNN-based estimation of unknown dynamics and the control-theoretical guarantees of the solution properties. We demonstrate the superiority of the proposed method in two standard classical control systems with state observation given by low resolution high-dimensional images.")]>>Here's the translation in Traditional Chinese:<<sys.language_model.translate(text="控制无知系统是一个重要和挑战性的任务。现代机器学习方法，如深度神经网络（DNNs），允许从控制输入和相应的状态观察输出来估计动力学模型。然而，没有任何保证，表示由DNNs所表示的模型具有控制性的正式控制理论意义上的 garanties，这是控制器设计中的重要因素。在这个证明原理的工作中，我们提出了一个控制理论方法，可以明确地增强从数据估计的模型，以提高控制性。这个方法提供了新的见解，将DNN-based estimation of unknown dynamics与控制理论上的 garanties的连接。我们在两个标准的古典控制系统中，使用低分辨率高维度图像进行状态观察，进行说明和比较。">>
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/11/cs.AI_2023_11_11/" data-id="clp9qz8040071ok889i1z09xy" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/11/cs.CL_2023_11_11/" class="article-date">
  <time datetime="2023-11-11T11:00:00.000Z" itemprop="datePublished">2023-11-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/11/cs.CL_2023_11_11/">cs.CL - 2023-11-11</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Intentional-Biases-in-LLM-Responses"><a href="#Intentional-Biases-in-LLM-Responses" class="headerlink" title="Intentional Biases in LLM Responses"></a>Intentional Biases in LLM Responses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.07611">http://arxiv.org/abs/2311.07611</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicklaus Badyal, Derek Jacoby, Yvonne Coady</li>
<li>for: 这个研究旨在将对话语言模型中的偏见故意引入，以创造特定的人物形象，用于互动媒体目的。</li>
<li>methods: 这个研究使用了 Falcon-7b 和 Open AI 的 GPT-4 开源模型，并评估了它们对不同角色的回应。</li>
<li>results: 研究发现，GPT-4 的监管器模型可以确保 AI 的调整，但是它们在创造不同角色的偏见时不够有用。<details>
<summary>Abstract</summary>
In this study we intentionally introduce biases into large language model responses in an attempt to create specific personas for interactive media purposes. We explore the differences between open source models such as Falcon-7b and the GPT-4 model from Open AI, and we quantify some differences in responses afforded by the two systems. We find that the guardrails in the GPT-4 mixture of experts models with a supervisor, while useful in assuring AI alignment in general, are detrimental in trying to construct personas with a variety of uncommon viewpoints. This study aims to set the groundwork for future exploration in intentional biases of large language models such that these practices can be applied in the creative field, and new forms of media.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们故意引入大语言模型的偏见，以创造特定的人物形象，用于互动媒体目的。我们比较了开源模型 falcon-7b 和 open AI 的 GPT-4 模型，并量化了两者响应的一些不同。我们发现，GPT-4 的混合专家模型的监督器，虽有用于保证 AI Compatibility，但在构建多种不同观点的人物时，是不利的。本研究的目的是为未来在大语言模型中意外偏见的实践提供基础，以便在艺术领域和新媒体中应用这些技术。
</details></li>
</ul>
<hr>
<h2 id="A-Template-Is-All-You-Meme"><a href="#A-Template-Is-All-You-Meme" class="headerlink" title="A Template Is All You Meme"></a>A Template Is All You Meme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06649">http://arxiv.org/abs/2311.06649</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ukplab/a-template-is-all-you-meme">https://github.com/ukplab/a-template-is-all-you-meme</a></li>
<li>paper_authors: Luke Bates, Peter Ebert Christensen, Preslav Nakov, Iryna Gurevych</li>
<li>For: The paper aims to improve the understanding of memes and their context, and to develop a method to inject context into machine learning models for better meme classification.* Methods: The authors release a large knowledge base of memes and information from <a target="_blank" rel="noopener" href="http://www.knowyourmeme.com/">www.knowyourmeme.com</a>, and create a non-parametric majority-based classifier called Template-Label Counter (TLC) to test their hypothesis that meme templates can provide missing context for machine learning models.* Results: The authors conduct thorough classification experiments and exploratory data analysis to demonstrate the effectiveness of their method and the value of their knowledge base for meme analysis tasks.<details>
<summary>Abstract</summary>
Memes are a modern form of communication and meme templates possess a base semantics that is customizable by whomever posts it on social media. Machine learning systems struggle with memes, which is likely due to such systems having insufficient context to understand memes, as there is more to memes than the obvious image and text. Here, to aid understanding of memes, we release a knowledge base of memes and information found on www.knowyourmeme.com, which we call the Know Your Meme Knowledge Base (KYMKB), composed of more than 54,000 images. The KYMKB includes popular meme templates, examples of each template, and detailed information about the template. We hypothesize that meme templates can be used to inject models with the context missing from previous approaches. To test our hypothesis, we create a non-parametric majority-based classifier, which we call Template-Label Counter (TLC). We find TLC more effective than or competitive with fine-tuned baselines. To demonstrate the power of meme templates and the value of both our knowledge base and method, we conduct thorough classification experiments and exploratory data analysis in the context of five meme analysis tasks.
</details>
<details>
<summary>摘要</summary>
现代通信的形式之一是memes，它们具有可自定义的基本 semantics，可以在社交媒体上分享。机器学习系统对memes表示困难，可能是因为这些系统缺乏memes的Context，因为memes比图像和文本更多。为了帮助理解memes，我们发布了www.knowyourmeme.com上的知识库，称之为知识库（KYMKB），包含超过54,000个图像。KYMKB包括流行的meme模板，每个模板的示例和详细信息。我们提出的假设是，meme模板可以用来补充过去方法缺失的Context。为了测试这个假设，我们创建了一种非 Parametric多数策略，称之为模板标签计数器（TLC）。我们发现TLC比或与精心调整的基线相当有效。为了证明meme模板和我们的知识库以及方法的力量，我们在五种meme分析任务中进行了严格的分类实验和探索数据分析。
</details></li>
</ul>
<hr>
<h2 id="Robust-Text-Classification-Analyzing-Prototype-Based-Networks"><a href="#Robust-Text-Classification-Analyzing-Prototype-Based-Networks" class="headerlink" title="Robust Text Classification: Analyzing Prototype-Based Networks"></a>Robust Text Classification: Analyzing Prototype-Based Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06647">http://arxiv.org/abs/2311.06647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhivar Sourati, Darshan Deshpande, Filip Ilievski, Kiril Gashteovski, Sascha Saralajew</li>
<li>for: 本研究旨在检验 prototype-based 网络（PBN）在文本分类任务中是否具有鲁棒性特性。</li>
<li>methods: 我们采用了一种模块化和全面的研究框架，包括不同的后处理架构、后处理大小和目标函数。我们的评估协议对模型进行了不同级别的拟合干扰测试。</li>
<li>results: 我们的实验结果表明，PBNs在面对现实的拟合干扰时保持了鲁棒性。此外，PBNs的鲁棒性主要归功于保持概念可读性的目标函数，而与普通模型相比，PBNs在数据越复杂时的鲁棒性差异越加鲜明。<details>
<summary>Abstract</summary>
Downstream applications often require text classification models to be accurate, robust, and interpretable. While the accuracy of the stateof-the-art language models approximates human performance, they are not designed to be interpretable and often exhibit a drop in performance on noisy data. The family of PrototypeBased Networks (PBNs) that classify examples based on their similarity to prototypical examples of a class (prototypes) is natively interpretable and shown to be robust to noise, which enabled its wide usage for computer vision tasks. In this paper, we study whether the robustness properties of PBNs transfer to text classification tasks. We design a modular and comprehensive framework for studying PBNs, which includes different backbone architectures, backbone sizes, and objective functions. Our evaluation protocol assesses the robustness of models against character-, word-, and sentence-level perturbations. Our experiments on three benchmarks show that the robustness of PBNs transfers to NLP classification tasks facing realistic perturbations. Moreover, the robustness of PBNs is supported mostly by the objective function that keeps prototypes interpretable, while the robustness superiority of PBNs over vanilla models becomes more salient as datasets get more complex.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="PerceptionGPT-Effectively-Fusing-Visual-Perception-into-LLM"><a href="#PerceptionGPT-Effectively-Fusing-Visual-Perception-into-LLM" class="headerlink" title="PerceptionGPT: Effectively Fusing Visual Perception into LLM"></a>PerceptionGPT: Effectively Fusing Visual Perception into LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06612">http://arxiv.org/abs/2311.06612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renjie Pi, Lewei Yao, Jiahui Gao, Jipeng Zhang, Tong Zhang</li>
<li>for: 这篇论文旨在做什么？	+ 这篇论文目标是具备Visual Large Language Model（VLLM）Visual perception能力，并且能够高效地使用Large Language Model（LLM）的表示能力来实现这一目标。</li>
<li>methods: 这篇论文使用了什么方法？	+ 这篇论文提出了一种新的综合框架，名为PerceptionGPT，它可以快速和高效地使用VLLM来实现视觉感知任务。该方法通过利用LLM的表示能力，将其token嵌入作为视觉信息的载体，然后使用轻量级的视觉任务编码器和解码器来完成视觉感知任务。</li>
<li>results: 这篇论文的研究结果是什么？	+ 对比之前的方法，这篇论文的方法可以更好地处理多个视觉输出，并且可以减少训练时间和数据量，同时减少批处理时间。这种方法可以帮助未来的研究更好地具备VLLM的视觉感知能力。<details>
<summary>Abstract</summary>
The integration of visual inputs with large language models (LLMs) has led to remarkable advancements in multi-modal capabilities, giving rise to visual large language models (VLLMs). However, effectively harnessing VLLMs for intricate visual perception tasks remains a challenge. In this paper, we present a novel end-to-end framework named PerceptionGPT, which efficiently and effectively equips the VLLMs with visual perception abilities by leveraging the representation power of LLMs' token embedding. Our proposed method treats the token embedding of the LLM as the carrier of spatial information, then leverage lightweight visual task encoders and decoders to perform visual perception tasks (e.g., detection, segmentation). Our approach significantly alleviates the training difficulty suffered by previous approaches that formulate the visual outputs as discrete tokens, and enables achieving superior performance with fewer trainable parameters, less training data and shorted training time. Moreover, as only one token embedding is required to decode the visual outputs, the resulting sequence length during inference is significantly reduced. Consequently, our approach enables accurate and flexible representations, seamless integration of visual perception tasks, and efficient handling of a multiple of visual outputs. We validate the effectiveness and efficiency of our approach through extensive experiments. The results demonstrate significant improvements over previous methods with much fewer trainable parameters and GPU hours, which facilitates future research in enabling LLMs with visual perception abilities.
</details>
<details>
<summary>摘要</summary>
摘要：将视觉输入与大语言模型（LLM）结合，已经导致多模态能力的很大进步，产生了视觉大语言模型（VLLM）。然而，使VLLM进行复杂的视觉感知任务仍然是一大挑战。在这篇论文中，我们提出了一种新的端到端框架，名为PerceptionGPT，可以高效地和有效地让VLLM具备视觉感知能力。我们的提议方法是将LLM的 Token embedding作为空间信息的传递者，然后使用轻量级的视觉任务编码器和解码器来完成视觉感知任务（例如检测和分割）。我们的方法可以减少前一些方法的训练困难，只需要 fewer 的可训练参数和训练数据，同时减少训练时间。此外，只需要一个 Token embedding 来解码视觉输出，因此在推理过程中的序列长度减少了。这使得我们的方法可以实现高精度和灵活的表示，同时实现多个视觉输出的有效集成。我们通过广泛的实验 validate 了我们的方法的有效性和效率。结果表明，我们的方法可以与之前的方法相比，减少很多可训练参数和GPU时间，这为未来启用LLM的视觉感知能力提供了可能性。
</details></li>
</ul>
<hr>
<h2 id="BizBench-A-Quantitative-Reasoning-Benchmark-for-Business-and-Finance"><a href="#BizBench-A-Quantitative-Reasoning-Benchmark-for-Business-and-Finance" class="headerlink" title="BizBench: A Quantitative Reasoning Benchmark for Business and Finance"></a>BizBench: A Quantitative Reasoning Benchmark for Business and Finance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06602">http://arxiv.org/abs/2311.06602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rik Koncel-Kedziorski, Michael Krumdick, Viet Lai, Varshini Reddy, Charles Lovering, Chris Tanner</li>
<li>for: 评估商业和金融领域中模型的数理逻辑能力。</li>
<li>methods: 利用程序生成技术来评估模型对金融数据的问答能力，并 isolate 不同的金融逻辑能力。</li>
<li>results: 通过对开源和商业模型进行评估， illustrate 该 benchmark 对数理逻辑能力的评估是一项挑战性的任务。<details>
<summary>Abstract</summary>
As large language models (LLMs) impact a growing number of complex domains, it is becoming increasingly important to have fair, accurate, and rigorous evaluation benchmarks. Evaluating the reasoning skills required for business and financial NLP stands out as a particularly difficult challenge. We introduce BizBench, a new benchmark for evaluating models' ability to reason about realistic financial problems. BizBench comprises 8 quantitative reasoning tasks. Notably, BizBench targets the complex task of question-answering (QA) for structured and unstructured financial data via program synthesis (i.e., code generation). We introduce three diverse financially-themed code-generation tasks from newly collected and augmented QA data. Additionally, we isolate distinct financial reasoning capabilities required to solve these QA tasks: reading comprehension of financial text and tables, which is required to extract correct intermediate values; and understanding domain knowledge (e.g., financial formulas) needed to calculate complex solutions. Collectively, these tasks evaluate a model's financial background knowledge, ability to extract numeric entities from financial documents, and capacity to solve problems with code. We conduct an in-depth evaluation of open-source and commercial LLMs, illustrating that BizBench is a challenging benchmark for quantitative reasoning in the finance and business domain.
</details>
<details>
<summary>摘要</summary>
As large language models (LLMs) impact an increasing number of complex domains, it is becoming increasingly important to have fair, accurate, and rigorous evaluation benchmarks. Evaluating the reasoning skills required for business and financial NLP is a particularly difficult challenge. We introduce BizBench, a new benchmark for evaluating models' ability to reason about realistic financial problems. BizBench consists of 8 quantitative reasoning tasks. Notably, BizBench targets the complex task of question-answering (QA) for structured and unstructured financial data via program synthesis (i.e., code generation). We introduce three diverse financially-themed code-generation tasks from newly collected and augmented QA data. Additionally, we isolate distinct financial reasoning capabilities required to solve these QA tasks, including reading comprehension of financial text and tables, which is necessary to extract correct intermediate values, and understanding domain knowledge (e.g., financial formulas) needed to calculate complex solutions. Collectively, these tasks evaluate a model's financial background knowledge, ability to extract numeric entities from financial documents, and capacity to solve problems with code. We conduct an in-depth evaluation of open-source and commercial LLMs, illustrating that BizBench is a challenging benchmark for quantitative reasoning in the finance and business domain.
</details></li>
</ul>
<hr>
<h2 id="From-Classification-to-Generation-Insights-into-Crosslingual-Retrieval-Augmented-ICL"><a href="#From-Classification-to-Generation-Insights-into-Crosslingual-Retrieval-Augmented-ICL" class="headerlink" title="From Classification to Generation: Insights into Crosslingual Retrieval Augmented ICL"></a>From Classification to Generation: Insights into Crosslingual Retrieval Augmented ICL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06595">http://arxiv.org/abs/2311.06595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoqian Li, Ercong Nie, Sheng Liang</li>
<li>for: 提高低资源语言中大型自然语言模型（LLM）的域内学习（ICL）性能。</li>
<li>methods: 提出了一种新的方法，即跨语言检索增强域内学习（CREA-ICL），通过提取高资源语言中相似的提示，提高多语言预训练语言模型（MPLM）在多种任务上的零基eline性能。</li>
<li>results: 在分类任务中，该方法得到了稳定的提升，但在生成任务中遇到了挑战。我们的评估带来了域内学习在分类和生成领域的性能动态。<details>
<summary>Abstract</summary>
The remarkable ability of Large Language Models (LLMs) to understand and follow instructions has sometimes been limited by their in-context learning (ICL) performance in low-resource languages. To address this, we introduce a novel approach that leverages cross-lingual retrieval-augmented in-context learning (CREA-ICL). By extracting semantically similar prompts from high-resource languages, we aim to improve the zero-shot performance of multilingual pre-trained language models (MPLMs) across diverse tasks. Though our approach yields steady improvements in classification tasks, it faces challenges in generation tasks. Our evaluation offers insights into the performance dynamics of retrieval-augmented in-context learning across both classification and generation domains.
</details>
<details>
<summary>摘要</summary>
LLMs的出色能力理解和遵从指令有时会受到低资源语言的ICL性能的限制。为解决这个问题，我们提出了一种新的方法，即跨语言检索增强ICL（CREA-ICL）。通过从高资源语言提取相似的提示，我们希望提高多语言预训练语言模型（MPLM）的零配置性能。虽然我们的方法在分类任务中得到了稳定的改善，但在生成任务中遇到了挑战。我们的评估对于检索增强ICL在分类和生成领域的性能动态进行了评估。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Cross-Lingual-Sentiment-Classification-under-Distribution-Shift-an-Exploratory-Study"><a href="#Zero-Shot-Cross-Lingual-Sentiment-Classification-under-Distribution-Shift-an-Exploratory-Study" class="headerlink" title="Zero-Shot Cross-Lingual Sentiment Classification under Distribution Shift: an Exploratory Study"></a>Zero-Shot Cross-Lingual Sentiment Classification under Distribution Shift: an Exploratory Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06549">http://arxiv.org/abs/2311.06549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maarten De Raedt, Semere Kiros Bitew, Fréderic Godin, Thomas Demeester, Chris Develder</li>
<li>for: This paper is focused on studying the generalization of multi-lingual language models to out-of-distribution (OOD) test data in zero-shot cross-lingual transfer settings, and analyzing the impact of both language and domain shifts on performance.</li>
<li>methods: The paper uses counterfactually augmented data (CAD) to improve OOD generalization in the cross-lingual setting, and proposes two new approaches that avoid the costly annotation process associated with CAD.</li>
<li>results: The paper evaluates the performance of three multilingual models (LaBSE, mBERT, and XLM-R) on OOD test sets in 13 languages, and finds that the proposed cost-effective approaches reach similar or up to +3.1% better accuracy than CAD for Amazon and Restaurant reviews.<details>
<summary>Abstract</summary>
The brittleness of finetuned language model performance on out-of-distribution (OOD) test samples in unseen domains has been well-studied for English, yet is unexplored for multi-lingual models. Therefore, we study generalization to OOD test data specifically in zero-shot cross-lingual transfer settings, analyzing performance impacts of both language and domain shifts between train and test data. We further assess the effectiveness of counterfactually augmented data (CAD) in improving OOD generalization for the cross-lingual setting, since CAD has been shown to benefit in a monolingual English setting. Finally, we propose two new approaches for OOD generalization that avoid the costly annotation process associated with CAD, by exploiting the power of recent large language models (LLMs). We experiment with 3 multilingual models, LaBSE, mBERT, and XLM-R trained on English IMDb movie reviews, and evaluate on OOD test sets in 13 languages: Amazon product reviews, Tweets, and Restaurant reviews. Results echo the OOD performance decline observed in the monolingual English setting. Further, (i) counterfactuals from the original high-resource language do improve OOD generalization in the low-resource language, and (ii) our newly proposed cost-effective approaches reach similar or up to +3.1% better accuracy than CAD for Amazon and Restaurant reviews.
</details>
<details>
<summary>摘要</summary>
英文语言模型在不同领域的 OUT-OF-DISTRIBUTION（OOD）测试样本上的 brittleness已经得到了广泛的研究，然而对多语言模型的研究尚未得到了探讨。因此，我们研究了在零shot跨语言传输 Setting中的OOD总结能力，分析了语言和领域之间的数据偏移对测试数据的影响。此外，我们还评估了基于counterfactual augmented data（CAD）的方法在跨语言设置中的有效性，因为CAD在英文设置中已经被证明有助于提高OOD总结能力。最后，我们提出了两种新的OOD总结方法，以避免与CAD相关的昂贵的注释过程，通过利用最新的大语言模型（LLMs）。我们在英语 IMDb 电影评论上训练了3个多语言模型：LaBSE、mBERT和XLM-R，并对13种语言的OOD测试集进行评估：Amazon产品评论、推特和餐厅评论。结果表明，OOD性能减降与英文设置中观察到的类似。此外，（i）原始高资源语言中的counterfactuals实际上提高了低资源语言中的OOD总结能力，和（ii）我们新提出的经济性方法达到了类似或更高于CAD的准确率，为Amazon和餐厅评论达到了+3.1%的提升。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Public-Understanding-of-Court-Opinions-with-Automated-Summarizers"><a href="#Enhancing-Public-Understanding-of-Court-Opinions-with-Automated-Summarizers" class="headerlink" title="Enhancing Public Understanding of Court Opinions with Automated Summarizers"></a>Enhancing Public Understanding of Court Opinions with Automated Summarizers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06534">http://arxiv.org/abs/2311.06534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elliott Ash, Aniket Kesari, Suresh Naidu, Lena Song, Dominik Stammbach</li>
<li>for: 帮助非专家理解法律案例</li>
<li>methods: 使用人工智能助手生成简化摘要</li>
<li>results: 调查实验表明，简化摘要可以帮助非专家更好地理解法律案例的关键特征。In English, this translates to:</li>
<li>for: To help non-experts understand legal cases</li>
<li>methods: Using an AI assistant to generate simplified summaries</li>
<li>results: A survey experiment shows that simplified summaries can help non-experts understand the key features of a ruling.<details>
<summary>Abstract</summary>
Written judicial opinions are an important tool for building public trust in court decisions, yet they can be difficult for non-experts to understand. We present a pipeline for using an AI assistant to generate simplified summaries of judicial opinions. These are more accessible to the public and more easily understood by non-experts, We show in a survey experiment that the simplified summaries help respondents understand the key features of a ruling. We discuss how to integrate legal domain knowledge into studies using large language models. Our results suggest a role both for AI assistants to inform the public, and for lawyers to guide the process of generating accessible summaries.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:written judicial opinions are an important tool for building public trust in court decisions, yet they can be difficult for non-experts to understand. we present a pipeline for using an AI assistant to generate simplified summaries of judicial opinions. these are more accessible to the public and more easily understood by non-experts. we show in a survey experiment that the simplified summaries help respondents understand the key features of a ruling. we discuss how to integrate legal domain knowledge into studies using large language models. our results suggest a role both for AI assistants to inform the public, and for lawyers to guide the process of generating accessible summaries.
</details></li>
</ul>
<hr>
<h2 id="Added-Toxicity-Mitigation-at-Inference-Time-for-Multimodal-and-Massively-Multilingual-Translation"><a href="#Added-Toxicity-Mitigation-at-Inference-Time-for-Multimodal-and-Massively-Multilingual-Translation" class="headerlink" title="Added Toxicity Mitigation at Inference Time for Multimodal and Massively Multilingual Translation"></a>Added Toxicity Mitigation at Inference Time for Multimodal and Massively Multilingual Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06532">http://arxiv.org/abs/2311.06532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marta R. Costa-jussà, David Dale, Maha Elbayad, Bokai Yu</li>
<li>for: 这 paper 的目的是提出一种新的pipeline来识别添加的毒性并mitigate这个问题，该pipeline在推理时间实现。</li>
<li>methods: 这 paper 使用了一种多modal的毒性检测分类器（speech和text），该分类器可以在大规模语言中工作。mitigation方法直接应用于文本输出中。</li>
<li>results: 这 paper 使用 MinTox pipeline在 SEAMLESSM4T 系统上实现了显著的添加毒性 Mitigation， across domains, modalities和语言方向。 MinTox 能够约Filter出25%-95%的添加毒性（根据模式和领域），保持翻译质量。<details>
<summary>Abstract</summary>
Added toxicity in the context of translation refers to the fact of producing a translation output with more toxicity than there exists in the input. In this paper, we present MinTox which is a novel pipeline to identify added toxicity and mitigate this issue which works at inference time. MinTox uses a toxicity detection classifier which is multimodal (speech and text) and works in languages at scale. The mitigation method is applied to languages at scale and directly in text outputs. MinTox is applied to SEAMLESSM4T, which is the latest multimodal and massively multilingual machine translation system. For this system, MinTox achieves significant added toxicity mitigation across domains, modalities and language directions. MinTox manages to approximately filter out from 25% to 95% of added toxicity (depending on the modality and domain) while keeping translation quality.
</details>
<details>
<summary>摘要</summary>
加入毒性在翻译上指的是生成翻译输出中存在更多的毒性 чем输入。在这篇论文中，我们介绍了一种名为MinTox的新的管道，用于识别加入毒性并缓解这个问题，它在推理时间进行应用。MinTox使用一个多Modal（语音和文本）的毒性检测类ifier，可以在多种语言和模式下进行检测。这种缓解方法直接应用于文本输出中。MinTox在SEAMLESSM4T上进行应用，SEAMLESSM4T是最新的多Modal和大量多语言翻译系统。对这个系统来说，MinTox在域、modal和语言方向上都实现了显著的加入毒性缓解，可以将25%-95%的加入毒性（根据模式和领域）约束出去，而不会影响翻译质量。
</details></li>
</ul>
<hr>
<h2 id="Minimum-Description-Length-Hopfield-Networks"><a href="#Minimum-Description-Length-Hopfield-Networks" class="headerlink" title="Minimum Description Length Hopfield Networks"></a>Minimum Description Length Hopfield Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06518">http://arxiv.org/abs/2311.06518</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matanabudy/mdl-hn">https://github.com/matanabudy/mdl-hn</a></li>
<li>paper_authors: Matan Abudy, Nur Lan, Emmanuel Chemla, Roni Katzir</li>
<li>for: 这个论文是为了研究协同记忆架构的Memorization和Generalization之间的质量。</li>
<li>methods: 这个论文使用Modern Hopfield Networks（MHN）来研究协同记忆架构的Memorization和Generalization。</li>
<li>results: 研究发现，大量的Memorization容量会妨碍Generalization的机会。提出一种使用Minimum Description Length（MDL）来在训练过程中决定保留哪些记忆和哪些记忆数量。<details>
<summary>Abstract</summary>
Associative memory architectures are designed for memorization but also offer, through their retrieval method, a form of generalization to unseen inputs: stored memories can be seen as prototypes from this point of view. Focusing on Modern Hopfield Networks (MHN), we show that a large memorization capacity undermines the generalization opportunity. We offer a solution to better optimize this tradeoff. It relies on Minimum Description Length (MDL) to determine during training which memories to store, as well as how many of them.
</details>
<details>
<summary>摘要</summary>
协同记忆架构是设计来储存信息，但同时也提供了一种通过回溯方法对未见输入进行泛化的机会：储存的记忆可以被看作是类型的范例。专注于现代赫珀维尔网络（MHN），我们表明了大量储存容量会对泛化机会造成干扰。我们提出了一个解决方案，它基于最小描述长度（MDL）来决定在训练过程中哪些记忆要储存，以及哪些记忆要保留多少。
</details></li>
</ul>
<hr>
<h2 id="L3-Ensembles-Lifelong-Learning-Approach-for-Ensemble-of-Foundational-Language-Models"><a href="#L3-Ensembles-Lifelong-Learning-Approach-for-Ensemble-of-Foundational-Language-Models" class="headerlink" title="L3 Ensembles: Lifelong Learning Approach for Ensemble of Foundational Language Models"></a>L3 Ensembles: Lifelong Learning Approach for Ensemble of Foundational Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06493">http://arxiv.org/abs/2311.06493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aidin Shiri, Kaushik Roy, Amit Sheth, Manas Gaur</li>
<li>for: 这个论文旨在提出一种基于自然语言处理（NLP）任务的生命长学习（L3）框架，以便高效地进行任务特化和知识传递。</li>
<li>methods: 该方法包括提取有意义的表示，建立结构化知识库，以及在不同任务上进行逐步改进。</li>
<li>results: 经验表明，提出的L3 ensemble方法可以提高模型精度，同时保持或超过当前语言模型（T5）的性能。在STSbenchmark中，L3模型的准确率比原始 Fine-tuned FLM 提高15.4%。<details>
<summary>Abstract</summary>
Fine-tuning pre-trained foundational language models (FLM) for specific tasks is often impractical, especially for resource-constrained devices. This necessitates the development of a Lifelong Learning (L3) framework that continuously adapts to a stream of Natural Language Processing (NLP) tasks efficiently. We propose an approach that focuses on extracting meaningful representations from unseen data, constructing a structured knowledge base, and improving task performance incrementally. We conducted experiments on various NLP tasks to validate its effectiveness, including benchmarks like GLUE and SuperGLUE. We measured good performance across the accuracy, training efficiency, and knowledge transfer metrics. Initial experimental results show that the proposed L3 ensemble method increases the model accuracy by 4% ~ 36% compared to the fine-tuned FLM. Furthermore, L3 model outperforms naive fine-tuning approaches while maintaining competitive or superior performance (up to 15.4% increase in accuracy) compared to the state-of-the-art language model (T5) for the given task, STS benchmark.
</details>
<details>
<summary>摘要</summary>
精度调整预训练基础语言模型（FLM） для特定任务是经常不可能，特别是在有限的设备资源下。这种情况需要开发一个生命时间学习（L3）框架，可以高效地适应流行的自然语言处理（NLP）任务。我们提出了一种方法，强调提取未经见过的数据中有意义的表示，建立结构化的知识库，并在不断更新的任务中提高表现。我们在多个 NLP 任务上进行了实验，以验证其效果，包括 GLUE 和 SuperGLUE 的benchmark。我们发现，在精度、训练效率和知识传递指标方面，L3 ensemble方法表现良好。初步实验结果表明，我们提议的 L3 模型比 fine-tuned FLM 提高4%~36%的模型精度。此外，L3 模型还能在与状态艺术语言模型（T5）相同或更高的精度水平上保持竞争性或超越性（最多提高15.4%的精度），对 STS benchmark进行了证明。
</details></li>
</ul>
<hr>
<h2 id="DocGen-Generating-Detailed-Parameter-Docstrings-in-Python"><a href="#DocGen-Generating-Detailed-Parameter-Docstrings-in-Python" class="headerlink" title="DocGen: Generating Detailed Parameter Docstrings in Python"></a>DocGen: Generating Detailed Parameter Docstrings in Python</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06453">http://arxiv.org/abs/2311.06453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vatsal Venkatkrishna, Durga Shree Nagabushanam, Emmanuel Iko-Ojo Simon, Melina Vidoni</li>
<li>for: 提高开源软件的有效利用，因为文档债让开发者困惑。</li>
<li>methods: 提出了一种多步骤方法，通过结合多个任务特定的模型，每个模型都专门生成不同的段落，以确保生成的文档准确全面。</li>
<li>results: 与现有的生成模型进行比较，通过自动指标和人 centered评估17名开发者，证明了该方法与现有方法之间的超越。<details>
<summary>Abstract</summary>
Documentation debt hinders the effective utilization of open-source software. Although code summarization tools have been helpful for developers, most would prefer a detailed account of each parameter in a function rather than a high-level summary. However, generating such a summary is too intricate for a single generative model to produce reliably due to the lack of high-quality training data. Thus, we propose a multi-step approach that combines multiple task-specific models, each adept at producing a specific section of a docstring. The combination of these models ensures the inclusion of each section in the final docstring. We compared the results from our approach with existing generative models using both automatic metrics and a human-centred evaluation with 17 participating developers, which proves the superiority of our approach over existing methods.
</details>
<details>
<summary>摘要</summary>
文档债务阻碍开源软件的有效利用。虽然代码概要工具有帮助开发者，但大多数开发者更偏好每个函数参数的详细账户而不是高级概要。然而，生成这样的概要是单一生成模型无法可靠地生成的由于缺乏高质量的训练数据。因此，我们提议一种多步骤方法，将多个任务特定的模型相互结合，以确保每个部分在最终的概要中包含。我们与已有的生成模型进行比较，并通过17名参与者进行人中心评估，证明我们的方法在现有方法之上。
</details></li>
</ul>
<hr>
<h2 id="Separating-the-Wheat-from-the-Chaff-with-BREAD-An-open-source-benchmark-and-metrics-to-detect-redundancy-in-text"><a href="#Separating-the-Wheat-from-the-Chaff-with-BREAD-An-open-source-benchmark-and-metrics-to-detect-redundancy-in-text" class="headerlink" title="Separating the Wheat from the Chaff with BREAD: An open-source benchmark and metrics to detect redundancy in text"></a>Separating the Wheat from the Chaff with BREAD: An open-source benchmark and metrics to detect redundancy in text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06440">http://arxiv.org/abs/2311.06440</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/toizzy/bread">https://github.com/toizzy/bread</a></li>
<li>paper_authors: Isaac Caswell, Lisa Wang, Isabel Papadimitriou</li>
<li>for: 这篇论文的目的是提供一个人类标注的数据集，用于测试语言模型训练数据中的重复文本问题，并评估不同语言中的数据质量。</li>
<li>methods: 该论文使用了人类标注的数据集，创建了一个名为BREAD的数据集，并提供了一些基线分析方法（CRED）来评估数据质量。</li>
<li>results: 该论文通过对BREAD数据集进行分析，发现了一些语言模型训练数据中的重复文本问题，并提供了一些参考实现方法来解决这些问题。<details>
<summary>Abstract</summary>
Data quality is a problem that perpetually resurfaces throughout the field of NLP, regardless of task, domain, or architecture, and remains especially severe for lower-resource languages. A typical and insidious issue, affecting both training data and model output, is data that is repetitive and dominated by linguistically uninteresting boilerplate, such as price catalogs or computer-generated log files. Though this problem permeates many web-scraped corpora, there has yet to be a benchmark to test against, or a systematic study to find simple metrics that generalize across languages and agree with human judgements of data quality. In the present work, we create and release BREAD, a human-labeled benchmark on repetitive boilerplate vs. plausible linguistic content, spanning 360 languages. We release several baseline CRED (Character REDundancy) scores along with it, and evaluate their effectiveness on BREAD. We hope that the community will use this resource to develop better filtering methods, and that our reference implementations of CRED scores can become standard corpus evaluation tools, driving the development of cleaner language modeling corpora, especially in low-resource languages.
</details>
<details>
<summary>摘要</summary>
“资料质量是NLP领域中不断重现的问题，不论任务、领域或架构，它尤其严重 для低资源语言。一个常见的问题是训练数据和模型输出中的重复和 linguistically 无趣的� boilerplate，如价格目录或计算机生成的日志档案。这个问题在许多网页抓取数据中广泛存在，但是还没有一个底线来测试，或一个系统性的研究来找到简单的度量标准，以及与人类判断资料质量的一致性。在现在的工作中，我们创建了BREAD，一个人工标注的底线，涵盖360种语言。我们释出了多个基线CRED（Character REDundancy）分数，并评估它们在BREAD上的效果。我们希望社区可以使用这个资源，发展更好的筛选方法，以提高语言模型数据库的质量，特别是低资源语言。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/11/cs.CL_2023_11_11/" data-id="clp9qz82i00f0ok88guxh89m0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/11/cs.LG_2023_11_11/" class="article-date">
  <time datetime="2023-11-11T10:00:00.000Z" itemprop="datePublished">2023-11-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/11/cs.LG_2023_11_11/">cs.LG - 2023-11-11</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Agnostic-Membership-Query-Learning-with-Nontrivial-Savings-New-Results-Techniques"><a href="#Agnostic-Membership-Query-Learning-with-Nontrivial-Savings-New-Results-Techniques" class="headerlink" title="Agnostic Membership Query Learning with Nontrivial Savings: New Results, Techniques"></a>Agnostic Membership Query Learning with Nontrivial Savings: New Results, Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06690">http://arxiv.org/abs/2311.06690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ari Karchmer</li>
<li>for: 这paper主要研究了在agnostic learning模型中设计高效的算法（Haussler, 1992; Kearns et al., 1994）。</li>
<li>methods: 本paper使用了membership queries方法，特别是针对touchstone classes的frontier agnostic learning问题。</li>
<li>results: 本paper提出了多种agnostic learning算法，其中包括一个可以处理具有折衣数量的gate的circuit，并且可以在2^n时间内运行，而不是默认的2^n时间。此外，paper还提出了一个可以处理任意函数计算的\sym^+ circuit的算法，并且可以在2^n时间内运行。<details>
<summary>Abstract</summary>
(Abridged) Designing computationally efficient algorithms in the agnostic learning model (Haussler, 1992; Kearns et al., 1994) is notoriously difficult. In this work, we consider agnostic learning with membership queries for touchstone classes at the frontier of agnostic learning, with a focus on how much computation can be saved over the trivial runtime of 2^n$. This approach is inspired by and continues the study of ``learning with nontrivial savings'' (Servedio and Tan, 2017). To this end, we establish multiple agnostic learning algorithms, highlighted by:   1. An agnostic learning algorithm for circuits consisting of a sublinear number of gates, which can each be any function computable by a sublogarithmic degree k polynomial threshold function (the depth of the circuit is bounded only by size). This algorithm runs in time 2^{n -s(n)} for s(n) \approx n/(k+1), and learns over the uniform distribution over unlabelled examples on \{0,1\}^n.   2. An agnostic learning algorithm for circuits consisting of a sublinear number of gates, where each can be any function computable by a \sym^+ circuit of subexponential size and sublogarithmic degree k. This algorithm runs in time 2^{n-s(n)} for s(n) \approx n/(k+1), and learns over distributions of unlabelled examples that are products of k+1 arbitrary and unknown distributions, each over \{0,1\}^{n/(k+1)} (assume without loss of generality that k+1 divides n).
</details>
<details>
<summary>摘要</summary>
（简化）在agnostic学习模型（Haussler，1992；Kearns等，1994）中设计 computationally efficient algorithm 是非常困难的。在这个工作中，我们考虑agnostic learning with membership queries for touchstone classes at the frontier of agnostic learning，并关注如何在基于2^n的极端情况下节省计算时间。这种方法是servedio和tan（2017）的研究继续。为了实现这一目标，我们提出了多种agnostic learning算法，其中包括：1. 一种agnostic learning算法 для满足一个子线性数量的门的Circuit，每个门可以是一个可以由k度多项式阈值函数计算的任意函数（Circuit的深度只决定了大小）。这个算法在时间2^n-s(n)中运行，其中s(n)约等于n/(k+1)，并在 uniform distribution over unlabelled examples on \{0,1\}^n上学习。2. 一种agnostic learning算法 для满足一个子线性数量的门的Circuit，其中每个门可以是一个可以由subexponential size和k度多项式阈值函数计算的任意函数（Circuit的深度只决定了大小）。这个算法在时间2^n-s(n)中运行，其中s(n)约等于n/(k+1)，并在分布 over unlabelled examples是k+1个未知和无标签的分布的产物上学习，即assume without loss of generality that k+1 divides n。
</details></li>
</ul>
<hr>
<h2 id="Heuristic-Optimal-Transport-in-Branching-Networks"><a href="#Heuristic-Optimal-Transport-in-Branching-Networks" class="headerlink" title="Heuristic Optimal Transport in Branching Networks"></a>Heuristic Optimal Transport in Branching Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06650">http://arxiv.org/abs/2311.06650</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. Andrecut</li>
<li>for: 学习一种可以在网络上最优化运输的方法，以最小化成本。</li>
<li>methods: 使用快速的规则来生成分支结构，以便在网络上实现最优化运输。</li>
<li>results: 提供了一些应用场景，例如在社交网络上的人员调配和物流网络中的货物分配。<details>
<summary>Abstract</summary>
Optimal transport aims to learn a mapping of sources to targets by minimizing the cost, which is typically defined as a function of distance. The solution to this problem consists of straight line segments optimally connecting sources to targets, and it does not exhibit branching. These optimal solutions are in stark contrast with both natural, and man-made transportation networks, where branching structures are prevalent. Here we discuss a fast heuristic branching method for optimal transport in networks, and we provide several applications.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:优化交通目标是学习源到目标的映射，通常通过距离定义成本来实现。解决这个问题的解是直线段最优连接源到目标，无分支结构。这些优化解与自然和人工交通网络不同，后者通常具有分支结构。我们介绍了一种快速冒泡分支方法优化交通网络，并提供了多个应用。
</details></li>
</ul>
<hr>
<h2 id="Privacy-Risks-Analysis-and-Mitigation-in-Federated-Learning-for-Medical-Images"><a href="#Privacy-Risks-Analysis-and-Mitigation-in-Federated-Learning-for-Medical-Images" class="headerlink" title="Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images"></a>Privacy Risks Analysis and Mitigation in Federated Learning for Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06643">http://arxiv.org/abs/2311.06643</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlsysx/medpfl">https://github.com/mlsysx/medpfl</a></li>
<li>paper_authors: Badhan Chandra Das, M. Hadi Amini, Yanzhao Wu</li>
<li>for: 本研究旨在分析和 Mitigate Medical data Privacy risk in Federated Learning (FL) 中的隐私风险。</li>
<li>methods: 本研究提出了一个整体的框架（MedPFL）来分析和 Mitigate FL 中隐私风险，并在实验中表明了对医疗数据的隐私攻击的极大威胁。</li>
<li>results: 研究发现，通过加入随机噪声来保护医疗数据的防御策略可能不一定有效，存在独特和紧迫的医疗数据隐私挑战。<details>
<summary>Abstract</summary>
Federated learning (FL) is gaining increasing popularity in the medical domain for analyzing medical images, which is considered an effective technique to safeguard sensitive patient data and comply with privacy regulations. However, several recent studies have revealed that the default settings of FL may leak private training data under privacy attacks. Thus, it is still unclear whether and to what extent such privacy risks of FL exist in the medical domain, and if so, ``how to mitigate such risks?''. In this paper, first, we propose a holistic framework for Medical data Privacy risk analysis and mitigation in Federated Learning (MedPFL) to analyze privacy risks and develop effective mitigation strategies in FL for protecting private medical data. Second, we demonstrate the substantial privacy risks of using FL to process medical images, where adversaries can easily perform privacy attacks to reconstruct private medical images accurately. Third, we show that the defense approach of adding random noises may not always work effectively to protect medical images against privacy attacks in FL, which poses unique and pressing challenges associated with medical data for privacy protection.
</details>
<details>
<summary>摘要</summary>
受到批评的学习（Federated Learning，FL）在医疗领域的应用正在增加，用于分析医疗图像，这被视为一种有效的技术来保护敏感的病人数据和遵守隐私法规。然而，一些最近的研究表明，FL的默认设置可能会泄露敏感训练数据面临隐私攻击。因此，在医疗领域中是否存在这种隐私风险，以及如何 Mitigate 这些风险仍然是一个未知。在这篇论文中，我们提出了一个整体的框架，以便在 Federated Learning 中进行医疗数据隐私风险分析和降低（MedPFL），以分析隐私风险并开发有效的降低策略，以保护敏感的医疗数据。其次，我们示出了使用 FL 处理医疗图像时存在严重的隐私风险，敌方可以轻松地进行隐私攻击，以重建私人医疗图像。最后，我们表明了在 FL 中添加随机噪声可能无法有效地保护医疗图像 Against 隐私攻击，这增加了医疗数据隐私保护的特殊挑战。
</details></li>
</ul>
<hr>
<h2 id="The-Exact-Determinant-of-a-Specific-Class-of-Sparse-Positive-Definite-Matrices"><a href="#The-Exact-Determinant-of-a-Specific-Class-of-Sparse-Positive-Definite-Matrices" class="headerlink" title="The Exact Determinant of a Specific Class of Sparse Positive Definite Matrices"></a>The Exact Determinant of a Specific Class of Sparse Positive Definite Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06632">http://arxiv.org/abs/2311.06632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehdi Molkaraie</li>
<li>for: 这篇论文是为了解决一种特定的稀畴 Gaussian graphical model 的 determinant 问题而写的。</li>
<li>methods: 这篇论文使用了 Normal Factor Graph Duality Theorem 和 holographic algorithms 来提供一个关闭式解决方案，即通过 Matrix Determinant Lemma 对 transformed graphical model 进行处理。</li>
<li>results: 这篇论文提供了一个关闭式表达式，用于计算稀畴 Gaussian graphical model 的 determinant。此外， paper 还定义了一种等价关系 между两个 Gaussian graphical model。<details>
<summary>Abstract</summary>
For a specific class of sparse Gaussian graphical models, we provide a closed-form solution for the determinant of the covariance matrix. In our framework, the graphical interaction model (i.e., the covariance selection model) is equal to replacement product of $\mathcal{K}_{n}$ and $\mathcal{K}_{n-1}$, where $\mathcal{K}_n$ is the complete graph with $n$ vertices. Our analysis is based on taking the Fourier transform of the local factors of the model, which can be viewed as an application of the Normal Factor Graph Duality Theorem and holographic algorithms. The closed-form expression is obtained by applying the Matrix Determinant Lemma on the transformed graphical model. In this context, we will also define a notion of equivalence between two Gaussian graphical models.
</details>
<details>
<summary>摘要</summary>
For a specific class of sparse Gaussian graphical models, we provide a closed-form solution for the determinant of the covariance matrix. In our framework, the graphical interaction model (i.e., the covariance selection model) is equal to the replacement product of $\mathcal{K}_{n}$ and $\mathcal{K}_{n-1}$, where $\mathcal{K}_n$ is the complete graph with $n$ vertices. Our analysis is based on taking the Fourier transform of the local factors of the model, which can be viewed as an application of the Normal Factor Graph Duality Theorem and holographic algorithms. The closed-form expression is obtained by applying the Matrix Determinant Lemma on the transformed graphical model. In this context, we will also define a notion of equivalence between two Gaussian graphical models.Here's the translation:为特定类型的稀疏 Gaussian 图模型，我们提供一个关闭式解的 determinant 表达。在我们的框架中，图模型的交互模型（即covariance 选择模型）等于 $\mathcal{K}_{n}$ 和 $\mathcal{K}_{n-1}$ 的交换乘积，其中 $\mathcal{K}_n$ 是一个完全图 WITH $n$ 个顶点。我们的分析基于图模型的本地ifactors 的傅ри幂变换，这可以看作是 Normal Factor Graph Duality Theorem 和 holographic algorithms 的应用。关闭式表达是通过应用 Matrix Determinant Lemma onto the transformed graphical model 获得的。在这个上下文中，我们还将定义 Gaussian 图模型之间的一种相等性。
</details></li>
</ul>
<hr>
<h2 id="Streamlining-Energy-Transition-Scenarios-to-Key-Policy-Decisions"><a href="#Streamlining-Energy-Transition-Scenarios-to-Key-Policy-Decisions" class="headerlink" title="Streamlining Energy Transition Scenarios to Key Policy Decisions"></a>Streamlining Energy Transition Scenarios to Key Policy Decisions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06625">http://arxiv.org/abs/2311.06625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florian Joseph Baader, Stefano Moret, Wolfram Wiesemann, Iain Staffell, André Bardow</li>
<li>For: The paper is written to provide an approach for interpreting and prioritizing key factors in the energy transition, specifically in the context of global decarbonization scenarios and a fossil-free Europe.* Methods: The paper uses decision trees, a popular machine-learning technique, to derive interpretable storylines from many quantitative scenarios and show how the key decisions in the energy transition are interlinked.* Results: The paper demonstrates that choosing a high deployment of renewables and sector coupling makes global decarbonization scenarios robust against uncertainties in climate sensitivity and demand, and that the energy transition to a fossil-free Europe is primarily determined by choices on the roles of bioenergy, storage, and heat electrification.Here is the information in Simplified Chinese text:* For: 这篇论文是为了提供一种方法来解释和优先级化能源转型的关键因素，具体是在全球减排场景和不burn欧洲的背景下。* Methods: 这篇论文使用决策树，一种流行的机器学习技术，来 derivates interpretable storylines从多个量化enario中，并显示了能源转型中关键决策之间的关联。* Results: 这篇论文发现，选择高部署的可再生能源和部署相互连接会使全球减排场景对气候敏感度和需求的不确定性 exhibit robustness，而不burn欧洲的能源转型主要取决于生物能源、存储和热电气化的角色。<details>
<summary>Abstract</summary>
Uncertainties surrounding the energy transition often lead modelers to present large sets of scenarios that are challenging for policymakers to interpret and act upon. An alternative approach is to define a few qualitative storylines from stakeholder discussions, which can be affected by biases and infeasibilities. Leveraging decision trees, a popular machine-learning technique, we derive interpretable storylines from many quantitative scenarios and show how the key decisions in the energy transition are interlinked. Specifically, our results demonstrate that choosing a high deployment of renewables and sector coupling makes global decarbonization scenarios robust against uncertainties in climate sensitivity and demand. Also, the energy transition to a fossil-free Europe is primarily determined by choices on the roles of bioenergy, storage, and heat electrification. Our transferrable approach translates vast energy model results into a small set of critical decisions, guiding decision-makers in prioritizing the key factors that will shape the energy transition.
</details>
<details>
<summary>摘要</summary>
uncertainties surrounding the energy transition often lead modelers to present large sets of scenarios that are challenging for policymakers to interpret and act upon. an alternative approach is to define a few qualitative storylines from stakeholder discussions, which can be affected by biases and infeasibilities. leveraging decision trees, a popular machine-learning technique, we derive interpretable storylines from many quantitative scenarios and show how the key decisions in the energy transition are interlinked. specifically, our results demonstrate that choosing a high deployment of renewables and sector coupling makes global decarbonization scenarios robust against uncertainties in climate sensitivity and demand. also, the energy transition to a fossil-free Europe is primarily determined by choices on the roles of bioenergy, storage, and heat electrification. our transferrable approach translates vast energy model results into a small set of critical decisions, guiding decision-makers in prioritizing the key factors that will shape the energy transition.Here's the text with some additional information about the Simplified Chinese translation:The Simplified Chinese translation is written in 简化字符 (Simplified Chinese characters) rather than 正体字符 (Traditional Chinese characters). This is because Simplified Chinese is more widely used in mainland China and other countries, while Traditional Chinese is more commonly used in Hong Kong, Macau, and Taiwan.In the translation, some technical terms and concepts have been translated into Simplified Chinese, such as "能源转型" (energy transition), "可再生能源" (renewable energy), and "燃料电池" (fuel cell). However, some terms and concepts have been retained in English, such as "scenarios" and "storylines," as there may not be direct equivalents in Simplified Chinese.Additionally, some sentence structures and wording have been adjusted to conform to the grammatical conventions of Simplified Chinese. For example, in the sentence "Leveraging decision trees, a popular machine-learning technique, we derive interpretable storylines from many quantitative scenarios and show how the key decisions in the energy transition are interlinked," the word order has been adjusted to place the verb "derive" before the object "interpretable storylines" to conform to Simplified Chinese sentence structure.
</details></li>
</ul>
<hr>
<h2 id="Sparse-Attention-Based-Neural-Networks-for-Code-Classification"><a href="#Sparse-Attention-Based-Neural-Networks-for-Code-Classification" class="headerlink" title="Sparse Attention-Based Neural Networks for Code Classification"></a>Sparse Attention-Based Neural Networks for Code Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06575">http://arxiv.org/abs/2311.06575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyang Xiang, Zaixi Zhang, Qi Liu<br>for: 这个论文是为了解决实际programming教育平台中的代码分类问题而写的。methods: 这个论文使用了模型基于抽象语法树（ASTs）的方法，包括 syntax parsing和递归神经网络编码，以及一种特制的稀疏注意机制。results: 对于代码分类任务，这个方法能够提供高效精准的分类结果，并且可以解决之前相关研究中的问题，如不完整的分类标签和小型数据集。<details>
<summary>Abstract</summary>
Categorizing source codes accurately and efficiently is a challenging problem in real-world programming education platform management. In recent years, model-based approaches utilizing abstract syntax trees (ASTs) have been widely applied to code classification tasks. We introduce an approach named the Sparse Attention-based neural network for Code Classification (SACC) in this paper. The approach involves two main steps: In the first step, source code undergoes syntax parsing and preprocessing. The generated abstract syntax tree is split into sequences of subtrees and then encoded using a recursive neural network to obtain a high-dimensional representation. This step simultaneously considers both the logical structure and lexical level information contained within the code. In the second step, the encoded sequences of subtrees are fed into a Transformer model that incorporates sparse attention mechanisms for the purpose of classification. This method efficiently reduces the computational cost of the self-attention mechanisms, thus improving the training speed while preserving effectiveness. Our work introduces a carefully designed sparse attention pattern that is specifically designed to meet the unique needs of code classification tasks. This design helps reduce the influence of redundant information and enhances the overall performance of the model. Finally, we also deal with problems in previous related research, which include issues like incomplete classification labels and a small dataset size. We annotated the CodeNet dataset with algorithm-related labeling categories, which contains a significantly large amount of data. Extensive comparative experimental results demonstrate the effectiveness and efficiency of SACC for the code classification tasks.
</details>
<details>
<summary>摘要</summary>
优化代码分类任务的准确性和效率是现实世界程序教育平台管理中的挑战。在过去几年，基于抽象树（AST）的模型方法在代码分类任务中得到了广泛的应用。我们在这篇论文中介绍了一种名为代码分类 neural network with sparse attention（SACC）的方法。该方法包括两个主要步骤：第一步：源代码进行语法分析和处理，并将生成的抽象树分解成多个子树序列，然后使用回归神经网络编码以获得高维度表示。这一步同时考虑了代码的逻辑结构和字面层次信息。第二步：编码后的子树序列被传输到一个包含稀缺注意机制的Transformer模型中，用于分类。这种方法可以有效减少自注意机制的计算成本，从而提高训练速度，同时保持效果。我们还设计了一种特殊的稀缺注意模式，用于满足代码分类任务的唯一需求。这种设计可以减少重复信息的影响，提高模型的总性能。最后，我们还解决了过去相关研究中的一些问题，如 incomplete classification labels和小型数据集。我们对CodeNet数据集进行了算法相关标签注释，该数据集包含很大量数据。我们进行了广泛的比较 эксперименталь研究，证明了 SACC 在代码分类任务中的有效性和效率。
</details></li>
</ul>
<hr>
<h2 id="Convolve-and-Conquer-Data-Comparison-with-Wiener-Filters"><a href="#Convolve-and-Conquer-Data-Comparison-with-Wiener-Filters" class="headerlink" title="Convolve and Conquer: Data Comparison with Wiener Filters"></a>Convolve and Conquer: Data Comparison with Wiener Filters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06558">http://arxiv.org/abs/2311.06558</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dpelacani/AWLoss">https://github.com/dpelacani/AWLoss</a></li>
<li>paper_authors: Deborah Pelacani Cruz, George Strong, Oscar Bates, Carlos Cueto, Jiashun Yao, Lluis Guasch</li>
<li>for: 这个论文是为了提出一种新的数据比较方法，用于量化评估数据样本之间的差异和相似性。</li>
<li>methods: 该方法基于温因 filter 理论，通过卷积方式对数据样本进行全面比较，以便更好地捕捉数据分布的特征。</li>
<li>results: 研究人员在四种机器学习应用中使用该方法，包括数据压缩、医学影像填充、翻译类别和非Parametric生成模型。结果表明，该方法可以提供更高的数据准确率和更好的感知质量，同时具有对摆动的Robustness。<details>
<summary>Abstract</summary>
Quantitative evaluations of differences and/or similarities between data samples define and shape optimisation problems associated with learning data distributions. Current methods to compare data often suffer from limitations in capturing such distributions or lack desirable mathematical properties for optimisation (e.g. smoothness, differentiability, or convexity). In this paper, we introduce a new method to measure (dis)similarities between paired samples inspired by Wiener-filter theory. The convolutional nature of Wiener filters allows us to comprehensively compare data samples in a globally correlated way. We validate our approach in four machine learning applications: data compression, medical imaging imputation, translated classification, and non-parametric generative modelling. Our results demonstrate increased resolution in reconstructed images with better perceptual quality and higher data fidelity, as well as robustness against translations, compared to conventional mean-squared-error analogue implementations.
</details>
<details>
<summary>摘要</summary>
量化评估数据样本之间的差异和相似性定义和shape优化问题相关于学习数据分布。现有的比较方法 oft suffer from capturing这些分布的限制或缺乏优化中desirable的数学性质（例如，smoothness、 differentiability或convexity）。本文引入一种新的方法来衡量paired samples之间的（dis）similarities， draws inspiration from Wiener-filter theory。Wiener filters的卷积性质允许我们全面比较数据样本，并且在全球相关的方式下进行比较。我们在四种机器学习应用中 validate我们的方法：数据压缩、医学影像补充、翻译类别和非 Parametric生成模型。我们的结果表明我们的方法可以提供更高的重建图像分辨率、更好的感知质量和更高的数据准确性，同时具有对于平移的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Graph-ODE-with-Factorized-Prototypes-for-Modeling-Complicated-Interacting-Dynamics"><a href="#Graph-ODE-with-Factorized-Prototypes-for-Modeling-Complicated-Interacting-Dynamics" class="headerlink" title="Graph ODE with Factorized Prototypes for Modeling Complicated Interacting Dynamics"></a>Graph ODE with Factorized Prototypes for Modeling Complicated Interacting Dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06554">http://arxiv.org/abs/2311.06554</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao Luo, Yiyang Gu, Huiyu Jiang, Jinsheng Huang, Wei Ju, Ming Zhang, Yizhou Sun</li>
<li>for: 本研究探讨了模型交互动力系统的问题，这对理解物理动力和生物过程都是关键。</li>
<li>methods: 研究使用了 геометрические图进行表示交互关系，然后使用强大的图神经网络（GNNs）进行捕捉。</li>
<li>results: 研究提出了一种新的方法 named Graph ODE with factorized prototypes (GOAT)，可以解决难以预测交互动力的问题，包括偏移量和复杂的基础规则。 GOAT 使用了分解原型的方法来提取对象级和系统级的上下文知识，从而提高了模型的通用性。<details>
<summary>Abstract</summary>
This paper studies the problem of modeling interacting dynamical systems, which is critical for understanding physical dynamics and biological processes. Recent research predominantly uses geometric graphs to represent these interactions, which are then captured by powerful graph neural networks (GNNs). However, predicting interacting dynamics in challenging scenarios such as out-of-distribution shift and complicated underlying rules remains unsolved. In this paper, we propose a new approach named Graph ODE with factorized prototypes (GOAT) to address the problem. The core of GOAT is to incorporate factorized prototypes from contextual knowledge into a continuous graph ODE framework. Specifically, GOAT employs representation disentanglement and system parameters to extract both object-level and system-level contexts from historical trajectories, which allows us to explicitly model their independent influence and thus enhances the generalization capability under system changes. Then, we integrate these disentangled latent representations into a graph ODE model, which determines a combination of various interacting prototypes for enhanced model expressivity. The entire model is optimized using an end-to-end variational inference framework to maximize the likelihood. Extensive experiments in both in-distribution and out-of-distribution settings validate the superiority of GOAT.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose a new approach called Graph ODE with factorized prototypes (GOAT). The core of GOAT is to incorporate factorized prototypes from contextual knowledge into a continuous graph ODE framework. Specifically, GOAT extracts both object-level and system-level contexts from historical trajectories using representation disentanglement and system parameters, allowing us to explicitly model their independent influence and enhance the generalization capability under system changes.Next, we integrate these disentangled latent representations into a graph ODE model, which combines various interacting prototypes for enhanced model expressivity. The entire model is optimized using an end-to-end variational inference framework to maximize the likelihood.Experimental results in both in-distribution and out-of-distribution settings demonstrate the superiority of GOAT. This paper provides a new approach to modeling interacting dynamic systems, which can be applied to various fields such as physical dynamics and biological processes.
</details></li>
</ul>
<hr>
<h2 id="From-Charts-to-Atlas-Merging-Latent-Spaces-into-One"><a href="#From-Charts-to-Atlas-Merging-Latent-Spaces-into-One" class="headerlink" title="From Charts to Atlas: Merging Latent Spaces into One"></a>From Charts to Atlas: Merging Latent Spaces into One</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06547">http://arxiv.org/abs/2311.06547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Donato Crisostomi, Irene Cannistraci, Luca Moschella, Pietro Barbiero, Marco Ciccone, Pietro Liò, Emanuele Rodolà</li>
<li>for: 这个研究的目的是创建一个汇集多个相关任务和数据集的综合空间，以便进行更好的分类。</li>
<li>methods: 这个研究使用了相对表示来使多个空间相似，然后使用简单的均值来汇集这些空间。</li>
<li>results: 研究发现，通过这种方法可以创建一个更好的分类空间，并且这个空间中含有任务特有的印记。此外，这种方法还可以在没有共同区域的情况下进行空间汇集，尽管效果不如结合所有任务的模型。<details>
<summary>Abstract</summary>
Models trained on semantically related datasets and tasks exhibit comparable inter-sample relations within their latent spaces. We investigate in this study the aggregation of such latent spaces to create a unified space encompassing the combined information. To this end, we introduce Relative Latent Space Aggregation, a two-step approach that first renders the spaces comparable using relative representations, and then aggregates them via a simple mean. We carefully divide a classification problem into a series of learning tasks under three different settings: sharing samples, classes, or neither. We then train a model on each task and aggregate the resulting latent spaces. We compare the aggregated space with that derived from an end-to-end model trained over all tasks and show that the two spaces are similar. We then observe that the aggregated space is better suited for classification, and empirically demonstrate that it is due to the unique imprints left by task-specific embedders within the representations. We finally test our framework in scenarios where no shared region exists and show that it can still be used to merge the spaces, albeit with diminished benefits over naive merging.
</details>
<details>
<summary>摘要</summary>
模型在semantically相关的数据集和任务上训练后，其间的inter-sample关系在幂空间中相似。本研究 investigate这种情况下，如何将这些幂空间融合成一个涵盖所有信息的共同空间。为此，我们提出了相对表示空间融合（Relative Latent Space Aggregation），它包括两个步骤：首先使用相对表示来使幂空间相似，然后使用简单的均值来融合它们。我们在三种不同的设置下分别训练了一个模型：分享样本、分享类别或者不分享任何内容。然后我们训练了每个任务的模型，并将其所得到的幂空间融合起来。我们与一个结束到终端模型训练所有任务的空间进行比较，并发现它们之间的关系很相似。我们还观察到，融合后的空间更适合分类，并且实际上表明了任务特定的嵌入器在表示中留下了独特的印记。最后，我们在没有共同区域的情况下测试了我们的框架，并发现它仍可以将空间融合，尽管效果不如预期。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Generalization-via-Set-Theory"><a href="#Understanding-Generalization-via-Set-Theory" class="headerlink" title="Understanding Generalization via Set Theory"></a>Understanding Generalization via Set Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06545">http://arxiv.org/abs/2311.06545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiqi Liu</li>
<li>for: 本研究旨在更好地理解机器学习模型的泛化性。</li>
<li>methods: 本研究使用集合论来引入算法、假设和数据集泛化的概念。我们分析了数据集泛化的性质，并证明了一个关于代理泛化过程的定理。这个定理导致了我们的泛化方法。</li>
<li>results: 通过对MNIST数据集进行泛化实验，我们获得了13,541个样本基。当使用整个训练集来评估模型性能时，模型的准确率达99.945%。但是如果将样本基Shift或修改神经网络结构，模型的性能会受到显著的下降。我们还发现了一些难以预测的样本，并发现它们都是挑战性的示例。实验证明了泛化定义的准确性和我们提出的方法的有效性。<details>
<summary>Abstract</summary>
Generalization is at the core of machine learning models. However, the definition of generalization is not entirely clear. We employ set theory to introduce the concepts of algorithms, hypotheses, and dataset generalization. We analyze the properties of dataset generalization and prove a theorem on surrogate generalization procedures. This theorem leads to our generalization method. Through a generalization experiment on the MNIST dataset, we obtain 13,541 sample bases. When we use the entire training set to evaluate the model's performance, the models achieve an accuracy of 99.945%. However, if we shift the sample bases or modify the neural network structure, the performance experiences a significant decline. We also identify consistently mispredicted samples and find that they are all challenging examples. The experiments substantiated the accuracy of the generalization definition and the effectiveness of the proposed methods. Both the set-theoretic deduction and the experiments help us better understand generalization.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>机器学习模型的核心是泛化。然而，泛化的定义并不很明确。我们使用集合论来介绍算法、假设和数据泛化的概念。我们分析数据泛化的性质并证明了代替泛化过程的定理。这个定理导致我们的泛化方法。通过对 MNIST 数据集进行泛化实验，我们获得了13541个样本基。当我们使用整个训练集来评估模型的性能时，模型的准确率为99.945%。然而，如果将样本基shift或修改神经网络结构，模型的性能会受到显著的下降。我们还发现了一些难以预测的样本，并发现它们都是挑战性的示例。实验证明了泛化定义的准确性和我们提议的方法的有效性。同时，集合论 deduction 和实验帮助我们更好地理解泛化。
</details></li>
</ul>
<hr>
<h2 id="TURBO-The-Swiss-Knife-of-Auto-Encoders"><a href="#TURBO-The-Swiss-Knife-of-Auto-Encoders" class="headerlink" title="TURBO: The Swiss Knife of Auto-Encoders"></a>TURBO: The Swiss Knife of Auto-Encoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06527">http://arxiv.org/abs/2311.06527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillaume Quétant, Yury Belousov, Vitaliy Kinakh, Slava Voloshynovskiy</li>
<li>for: 本研究旨在系统地分析和总结自动编码方法的信息理论基础。</li>
<li>methods: 该框架基于两个方向的共聚information flow的最大化，以derive its core concept。</li>
<li>results: 研究发现多个常见神经网络模型都可以被包含在该框架中，而信息瓶颈概念无法涵盖这些模型，因此TURBO框架成为一个更好的理论参照。<details>
<summary>Abstract</summary>
We present a novel information-theoretic framework, termed as TURBO, designed to systematically analyse and generalise auto-encoding methods. We start by examining the principles of information bottleneck and bottleneck-based networks in the auto-encoding setting and identifying their inherent limitations, which become more prominent for data with multiple relevant, physics-related representations. The TURBO framework is then introduced, providing a comprehensive derivation of its core concept consisting of the maximisation of mutual information between various data representations expressed in two directions reflecting the information flows. We illustrate that numerous prevalent neural network models are encompassed within this framework. The paper underscores the insufficiency of the information bottleneck concept in elucidating all such models, thereby establishing TURBO as a preferable theoretical reference. The introduction of TURBO contributes to a richer understanding of data representation and the structure of neural network models, enabling more efficient and versatile applications.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的信息理论框架，称之为TURBO，用于系统地分析和总结自编码方法。我们从自编码设置中检查信息瓶颈和瓶颈基础网络的原则，并指出其内在的限制，尤其是数据具有多个相关的物理相关表示。然后，我们介绍了TURBO框架，其核心思想是在两个方向强制实现各种数据表示之间的最大共同信息。我们示示了许多流行的神经网络模型都包含在这个框架内。文章强调信息瓶颈概念无法描述所有这些模型，因此Establish TURBO作为更好的理论参照。TURBO的引入将推动数据表示和神经网络模型的结构更深入理解，并提供更有效和灵活的应用。
</details></li>
</ul>
<hr>
<h2 id="CompCodeVet-A-Compiler-guided-Validation-and-Enhancement-Approach-for-Code-Dataset"><a href="#CompCodeVet-A-Compiler-guided-Validation-and-Enhancement-Approach-for-Code-Dataset" class="headerlink" title="CompCodeVet: A Compiler-guided Validation and Enhancement Approach for Code Dataset"></a>CompCodeVet: A Compiler-guided Validation and Enhancement Approach for Code Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06505">http://arxiv.org/abs/2311.06505</a></li>
<li>repo_url: None</li>
<li>paper_authors: Le Chen, Arijit Bhattacharjee, Nesreen K. Ahmed, Niranjan Hasabnis, Gal Oren, Bin Lei, Ali Jannesari</li>
<li>for: 提高 LLM 在 C 和 C++ 代码生成和理解方面的表现</li>
<li>methods: 使用编译器作为教师，通过 CompCodeVet approach 提高 LLM 的 zero-shot 思维能力</li>
<li>results: CompCodeVet 在两个开源代码集中进行评估，显示其能够改善 LLM 的训练数据质量<details>
<summary>Abstract</summary>
Large language models (LLMs) have become increasingly prominent in academia and industry due to their remarkable performance in diverse applications. As these models evolve with increasing parameters, they excel in tasks like sentiment analysis and machine translation. However, even models with billions of parameters face challenges in tasks demanding multi-step reasoning. Code generation and comprehension, especially in C and C++, emerge as significant challenges. While LLMs trained on code datasets demonstrate competence in many tasks, they struggle with rectifying non-compilable C and C++ code. Our investigation attributes this subpar performance to two primary factors: the quality of the training dataset and the inherent complexity of the problem which demands intricate reasoning. Existing "Chain of Thought" (CoT) prompting techniques aim to enhance multi-step reasoning. This approach, however, retains the limitations associated with the latent drawbacks of LLMs. In this work, we propose CompCodeVet, a compiler-guided CoT approach to produce compilable code from non-compilable ones. Diverging from the conventional approach of utilizing larger LLMs, we employ compilers as a teacher to establish a more robust zero-shot thought process. The evaluation of CompCodeVet on two open-source code datasets shows that CompCodeVet has the ability to improve the training dataset quality for LLMs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Stacked-networks-improve-physics-informed-training-applications-to-neural-networks-and-deep-operator-networks"><a href="#Stacked-networks-improve-physics-informed-training-applications-to-neural-networks-and-deep-operator-networks" class="headerlink" title="Stacked networks improve physics-informed training: applications to neural networks and deep operator networks"></a>Stacked networks improve physics-informed training: applications to neural networks and deep operator networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06483">http://arxiv.org/abs/2311.06483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amanda A Howard, Sarah H Murphy, Shady E Ahmed, Panos Stinis</li>
<li>for: 解决physics-informed neural networks和operator networks困难或无法准确地训练某些物理系统方程的问题。</li>
<li>methods: 提出了一种新的多优化框架，通过逐步堆叠physics-informed neural networks和operator networks来促进训练。每一步的输出可以作为下一步的低精度输入进行训练，逐步增加学习的模型表达能力。在每一步的迭代过程中，可以使用相同或不同的方程来模拟热处理（类似于随机扰动）。</li>
<li>results: 通过使用 benchmark问题，包括非线性摆车、波方程和viscous Burgers方程，我们展示了堆叠可以提高physics-informed neural networks和operator networks的准确率，并降低它们的大小。<details>
<summary>Abstract</summary>
Physics-informed neural networks and operator networks have shown promise for effectively solving equations modeling physical systems. However, these networks can be difficult or impossible to train accurately for some systems of equations. We present a novel multifidelity framework for stacking physics-informed neural networks and operator networks that facilitates training. We successively build a chain of networks, where the output at one step can act as a low-fidelity input for training the next step, gradually increasing the expressivity of the learned model. The equations imposed at each step of the iterative process can be the same or different (akin to simulated annealing). The iterative (stacking) nature of the proposed method allows us to progressively learn features of a solution that are hard to learn directly. Through benchmark problems including a nonlinear pendulum, the wave equation, and the viscous Burgers equation, we show how stacking can be used to improve the accuracy and reduce the required size of physics-informed neural networks and operator networks.
</details>
<details>
<summary>摘要</summary>
physics-informed neural networks 和 operator networks 已经展示了解决物理系统方程的能力。然而，这些网络可能具有一些或所有系统方程难以准确地训练。我们提出了一种新的多优化框架，用于栈层physics-informed neural networks 和 operator networks，以便训练。我们逐步建立一串网络，其输出在一个步骤可以作为下一步训练的低精度输入，逐步增加学习的模型表达能力。在每个迭代步骤中，可以使用相同或不同的方程（类似于模拟热处理）。我们的方法的迭代性让我们可以逐步学习解决方程中的难以直接学习的特征。通过使用不同的测试问题，包括非线性摆、波方程和粘性拜尔斯方程，我们证明了栈层可以提高physics-informed neural networks 和 operator networks的准确率，同时减少这些网络的大小。
</details></li>
</ul>
<hr>
<h2 id="Topology-Matching-Normalizing-Flows-for-Out-of-Distribution-Detection-in-Robot-Learning"><a href="#Topology-Matching-Normalizing-Flows-for-Out-of-Distribution-Detection-in-Robot-Learning" class="headerlink" title="Topology-Matching Normalizing Flows for Out-of-Distribution Detection in Robot Learning"></a>Topology-Matching Normalizing Flows for Out-of-Distribution Detection in Robot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06481">http://arxiv.org/abs/2311.06481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianxiang Feng, Jongseok Lee, Simon Geisler, Stephan Gunnemann, Rudolph Triebel</li>
<li>for: 提高自主机器人在实际世界中可靠部署的可靠性，通过异常检测能力。</li>
<li>methods: 使用Normalizing Flows（NFs）进行异常检测，但是在使用NFs时，往往会遇到复杂的目标分布与基础分布之间的匹配问题。这里我们使用一种表达力强的分布来匹配目标分布的 topology。</li>
<li>results: 在density estimation和2D对象检测benchmark中获得了较好的结果，并且在实际 robot部署中也展现出了良好的性能。<details>
<summary>Abstract</summary>
To facilitate reliable deployments of autonomous robots in the real world, Out-of-Distribution (OOD) detection capabilities are often required. A powerful approach for OOD detection is based on density estimation with Normalizing Flows (NFs). However, we find that prior work with NFs attempts to match the complex target distribution topologically with naive base distributions leading to adverse implications. In this work, we circumvent this topological mismatch using an expressive class-conditional base distribution trained with an information-theoretic objective to match the required topology. The proposed method enjoys the merits of wide compatibility with existing learned models without any performance degradation and minimum computation overhead while enhancing OOD detection capabilities. We demonstrate superior results in density estimation and 2D object detection benchmarks in comparison with extensive baselines. Moreover, we showcase the applicability of the method with a real-robot deployment.
</details>
<details>
<summary>摘要</summary>
In this work, we address this limitation by using an expressive class-conditional base distribution trained with an information-theoretic objective to match the required topology. Our method is compatible with existing learned models, incurs minimal computation overhead, and enhances OOD detection capabilities. We demonstrate superior performance in density estimation and 2D object detection benchmarks compared to extensive baselines, and showcase the practicality of our method with a real-robot deployment.
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Fine-tuning-using-Generated-Respiratory-Sound-to-Address-Class-Imbalance"><a href="#Adversarial-Fine-tuning-using-Generated-Respiratory-Sound-to-Address-Class-Imbalance" class="headerlink" title="Adversarial Fine-tuning using Generated Respiratory Sound to Address Class Imbalance"></a>Adversarial Fine-tuning using Generated Respiratory Sound to Address Class Imbalance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06480">http://arxiv.org/abs/2311.06480</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kaen2891/adversarial_fine-tuning_using_generated_respiratory_sound">https://github.com/kaen2891/adversarial_fine-tuning_using_generated_respiratory_sound</a></li>
<li>paper_authors: June-Woo Kim, Chihyeon Yoon, Miika Toikkanen, Sangmin Bae, Ho-Young Jung</li>
<li>for: 提高呼吸音数据的分类性能，特别是对少数类型的呼吸音进行改进。</li>
<li>methods: 使用音频扩散模型作为 Conditional Neural Vocoder，并实现对呼吸音数据的增强。</li>
<li>results: 对ICBHI dataset进行实验，并证明了我们的反对抗学习方法可以提高呼吸音分类性能，并且在一些少数类型上提高了准确率。<details>
<summary>Abstract</summary>
Deep generative models have emerged as a promising approach in the medical image domain to address data scarcity. However, their use for sequential data like respiratory sounds is less explored. In this work, we propose a straightforward approach to augment imbalanced respiratory sound data using an audio diffusion model as a conditional neural vocoder. We also demonstrate a simple yet effective adversarial fine-tuning method to align features between the synthetic and real respiratory sound samples to improve respiratory sound classification performance. Our experimental results on the ICBHI dataset demonstrate that the proposed adversarial fine-tuning is effective, while only using the conventional augmentation method shows performance degradation. Moreover, our method outperforms the baseline by 2.24% on the ICBHI Score and improves the accuracy of the minority classes up to 26.58%. For the supplementary material, we provide the code at https://github.com/kaen2891/adversarial_fine-tuning_using_generated_respiratory_sound.
</details>
<details>
<summary>摘要</summary>
深度生成模型在医疗图像领域已经出现为数据稀缺问题提供了一个有前途的解决方案。然而，它们在时序数据如呼吸音波中的应用还较少。在这个工作中，我们提出了一种简单直观的增强呼吸音波数据不均衡问题的方法，利用音频扩散模型作为受控神经 vocoder。我们还提出了一种简单又有效的对抗训练方法，用于对真实呼吸音波样本和生成的呼吸音波样本进行对齐特征。我们的实验结果表明，我们的对抗训练方法是有效的，只使用常见增强方法时则会导致性能下降。此外，我们的方法比基线方法高2.24%的ICBHI Score和加强少数类准确率最高26.58%。详细的实验结果和代码可以在 GitHub 上找到：https://github.com/kaen2891/adversarial_fine-tuning_using_generated_respiratory_sound。
</details></li>
</ul>
<hr>
<h2 id="Online-Continual-Learning-via-Logit-Adjusted-Softmax"><a href="#Online-Continual-Learning-via-Logit-Adjusted-Softmax" class="headerlink" title="Online Continual Learning via Logit Adjusted Softmax"></a>Online Continual Learning via Logit Adjusted Softmax</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06460">http://arxiv.org/abs/2311.06460</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/k1nght/online_cl_logit_adjusted_softmax">https://github.com/k1nght/online_cl_logit_adjusted_softmax</a></li>
<li>paper_authors: Zhehao Huang, Tao Li, Chenhe Yuan, Yingwen Wu, Xiaolin Huang</li>
<li>for: 本研究旨在解决在线 continual learning 问题，即模型在非站ARY数据流中学习时避免衰老现象，并且减少最近学习类别的预测偏见。</li>
<li>methods: 本研究使用了理论分析，发现了间类差异完全由类别预置带来，并且通过调整模型征值来实现 Bayes-优论法。</li>
<li>results: 我们的方法可以有效地避免类别预置的影响，并在实际场景下提供显著的性能改进（比如 CIFAR10 上的最佳基eline 提高4.6%），而且增加了非常少的计算成本。<details>
<summary>Abstract</summary>
Online continual learning is a challenging problem where models must learn from a non-stationary data stream while avoiding catastrophic forgetting. Inter-class imbalance during training has been identified as a major cause of forgetting, leading to model prediction bias towards recently learned classes. In this paper, we theoretically analyze that inter-class imbalance is entirely attributed to imbalanced class-priors, and the function learned from intra-class intrinsic distributions is the Bayes-optimal classifier. To that end, we present that a simple adjustment of model logits during training can effectively resist prior class bias and pursue the corresponding Bayes-optimum. Our proposed method, Logit Adjusted Softmax, can mitigate the impact of inter-class imbalance not only in class-incremental but also in realistic general setups, with little additional computational cost. We evaluate our approach on various benchmarks and demonstrate significant performance improvements compared to prior arts. For example, our approach improves the best baseline by 4.6% on CIFAR10.
</details>
<details>
<summary>摘要</summary>
（online continuous learning是一个困难的问题，where models must learn from a non-stationary data stream while avoiding catastrophic forgetting. Inter-class imbalance during training has been identified as a major cause of forgetting, leading to model prediction bias towards recently learned classes. In this paper, we theoretically analyze that inter-class imbalance is entirely attributed to imbalanced class-priors, and the function learned from intra-class intrinsic distributions is the Bayes-optimal classifier. To that end, we present that a simple adjustment of model logits during training can effectively resist prior class bias and pursue the corresponding Bayes-optimum. Our proposed method, Logit Adjusted Softmax, can mitigate the impact of inter-class imbalance not only in class-incremental but also in realistic general setups, with little additional computational cost. We evaluate our approach on various benchmarks and demonstrate significant performance improvements compared to prior arts. For example, our approach improves the best baseline by 4.6% on CIFAR10.）
</details></li>
</ul>
<hr>
<h2 id="Asymmetric-Contrastive-Multimodal-Learning-for-Advancing-Chemical-Understanding"><a href="#Asymmetric-Contrastive-Multimodal-Learning-for-Advancing-Chemical-Understanding" class="headerlink" title="Asymmetric Contrastive Multimodal Learning for Advancing Chemical Understanding"></a>Asymmetric Contrastive Multimodal Learning for Advancing Chemical Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06456">http://arxiv.org/abs/2311.06456</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Xu, Yifei Wang, Yunrui Li, Pengyu Hong</li>
<li>for: 这篇论文旨在提出一种新的多模态深度学习方法，用于提高化学研究和应用。</li>
<li>methods: 这篇论文使用了异形对比学习方法，将化学多modalities的信息转移到分子图表示中，以实现多modalities的共同理解。</li>
<li>results: 实验表明，ACML可以帮助化学研究人员更好地理解分子的含义，并提高化学应用的表达力和可解释性。<details>
<summary>Abstract</summary>
The versatility of multimodal deep learning holds tremendous promise for advancing scientific research and practical applications. As this field continues to evolve, the collective power of cross-modal analysis promises to drive transformative innovations, leading us to new frontiers in chemical understanding and discovery. Hence, we introduce Asymmetric Contrastive M}ultimodal Learning (ACML) as a novel approach tailored for molecules, showcasing its potential to advance the field of chemistry. ACML harnesses the power of effective asymmetric contrastive learning to seamlessly transfer information from various chemical modalities to molecular graph representations. By combining pre-trained chemical unimodal encoders and a shallow-designed graph encoder, ACML facilitates the assimilation of coordinated chemical semantics from different modalities, leading to comprehensive representation learning with efficient training. This innovative framework enhances the interpretability of learned representations and bolsters the expressive power of graph neural networks. Through practical tasks such as isomer discrimination and uncovering crucial chemical properties for drug discovery, ACML exhibits its capability to revolutionize chemical research and applications, providing a deeper understanding of chemical semantics of different modalities.
</details>
<details>
<summary>摘要</summary>
多模态深度学习的多样性具有推进科学研究和实用应用的巨大承诺。随着这个领域的进一步发展，跨模态分析的共同力将驱动 transformative 创新，带我们进入新的化学理解和发现的前iers。因此，我们介绍 Asymmetric Contrastive Multimodal Learning（ACML）作为一种新的方法，特地设计用于分子，展示其在化学领域的潜在发展 potential。ACML 利用有效的不对称对比学习来传递不同化学modalities中的各种 semantics 到分子图表示。通过将预训练的化学uni模态编码器和一个浅层设计的图编码器结合在一起，ACML 实现了模态之间的协调化学 semantics的同化，从而实现了全面的表示学习，并且可以高效地训练。这种创新的框架提高了学习表示的可读性和图神经网络的表达能力。通过实际任务，如分子同分子识别和找到重要的药物发现中的化学性质，ACML 展示了其在化学研究和应用中的革命性潜力，为不同modalities的化学semantics提供了更深刻的理解。
</details></li>
</ul>
<hr>
<h2 id="A-Saliency-based-Clustering-Framework-for-Identifying-Aberrant-Predictions"><a href="#A-Saliency-based-Clustering-Framework-for-Identifying-Aberrant-Predictions" class="headerlink" title="A Saliency-based Clustering Framework for Identifying Aberrant Predictions"></a>A Saliency-based Clustering Framework for Identifying Aberrant Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06454">http://arxiv.org/abs/2311.06454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aina Tersol Montserrat, Alexander R. Loftus, Yael Daihes</li>
<li>for: 这篇论文旨在提高机器学习分类器在高度不确定的生物医学应用中的可靠性和信任性。</li>
<li>methods: 本论文提出了一种新的训练方法，旨在降低误分率并识别异常预测。</li>
<li>results: 本论文的方法在 veterinary radiology 领域中实现了20%的精度提升。<details>
<summary>Abstract</summary>
In machine learning, classification tasks serve as the cornerstone of a wide range of real-world applications. Reliable, trustworthy classification is particularly intricate in biomedical settings, where the ground truth is often inherently uncertain and relies on high degrees of human expertise for labeling. Traditional metrics such as precision and recall, while valuable, are insufficient for capturing the nuances of these ambiguous scenarios. Here we introduce the concept of aberrant predictions, emphasizing that the nature of classification errors is as critical as their frequency. We propose a novel, efficient training methodology aimed at both reducing the misclassification rate and discerning aberrant predictions. Our framework demonstrates a substantial improvement in model performance, achieving a 20\% increase in precision. We apply this methodology to the less-explored domain of veterinary radiology, where the stakes are high but have not been as extensively studied compared to human medicine. By focusing on the identification and mitigation of aberrant predictions, we enhance the utility and trustworthiness of machine learning classifiers in high-stakes, real-world scenarios, including new applications in the veterinary world.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:机器学习中的分类任务是广泛应用的基础。在生物医学设置下，可靠、可信的分类特别复杂，因为ground truth的自然状况是 uncertain，需要高度的人类专业知识进行标注。传统的精度和 recall 指标不能 Capture 这些抽象的情况。我们提出了异常预测的概念，强调异常预测的性质是重要的，不仅是频率。我们提出了一种新的训练方法，可以减少错分率，并且可以识别异常预测。我们的框架在 veterinary radiology 领域中实现了20%的提升精度。我们将这种方法应用到未经充分研究的 veterinary 世界，以提高机器学习分类器在高风险、真实世界中的可靠性和可信worthiness。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Pooling-Bias-in-E-commerce-Search-via-False-Negative-Estimation"><a href="#Mitigating-Pooling-Bias-in-E-commerce-Search-via-False-Negative-Estimation" class="headerlink" title="Mitigating Pooling Bias in E-commerce Search via False Negative Estimation"></a>Mitigating Pooling Bias in E-commerce Search via False Negative Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06444">http://arxiv.org/abs/2311.06444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaochen Wang, Xiao Xiao, Ruhan Zhang, Xuan Zhang, Taesik Na, Tejaswi Tenneti, Haixun Wang, Fenglong Ma</li>
<li>for: 提高用户体验和商业成功，需要准确和高效地评估产品相关性。</li>
<li>methods: 使用新的偏见抑制硬性负采样策略（BHNS），可以减轻pooling bias，提高性能和商业影响。</li>
<li>results: 在Instacart搜索设置中，BHNS实现了实用电商应用。此外，对公共数据集进行比较分析，表明BHNS具有适用于多种应用场景的领域独特性。<details>
<summary>Abstract</summary>
Efficient and accurate product relevance assessment is critical for user experiences and business success. Training a proficient relevance assessment model requires high-quality query-product pairs, often obtained through negative sampling strategies. Unfortunately, current methods introduce pooling bias by mistakenly sampling false negatives, diminishing performance and business impact. To address this, we present Bias-mitigating Hard Negative Sampling (BHNS), a novel negative sampling strategy tailored to identify and adjust for false negatives, building upon our original False Negative Estimation algorithm. Our experiments in the Instacart search setting confirm BHNS as effective for practical e-commerce use. Furthermore, comparative analyses on public dataset showcase its domain-agnostic potential for diverse applications.
</details>
<details>
<summary>摘要</summary>
高效和准确的产品相关性评估对用户体验和商业成功至关重要。训练一个高效的相关性评估模型需要高质量的查询-产品对，常常通过负样本策略获得。然而，现有方法带有汇总偏见，由于错误地抽取假负样本，导致性能和商业影响减退。为解决这问题，我们提出了减少偏见的负样本选择策略（BHNS），基于我们原始的假负样本估计算算法。我们在Instacart搜索设置中进行了实验，证实BHNS在实际电商应用中是有效的。此外，我们对公共数据集进行了比较分析，显示BHNS在多种应用领域具有领域无关的潜在应用潜力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/11/cs.LG_2023_11_11/" data-id="clp9qz88a00usok880vv6fvjn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/11/eess.IV_2023_11_11/" class="article-date">
  <time datetime="2023-11-11T09:00:00.000Z" itemprop="datePublished">2023-11-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/11/eess.IV_2023_11_11/">eess.IV - 2023-11-11</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="DUBLINE-A-Deep-Unfolding-Network-for-B-line-Detection-in-Lung-Ultrasound-Images"><a href="#DUBLINE-A-Deep-Unfolding-Network-for-B-line-Detection-in-Lung-Ultrasound-Images" class="headerlink" title="DUBLINE: A Deep Unfolding Network for B-line Detection in Lung Ultrasound Images"></a>DUBLINE: A Deep Unfolding Network for B-line Detection in Lung Ultrasound Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06672">http://arxiv.org/abs/2311.06672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianqi Yang, Nantheera Anantrasirichai, Oktay Karakuş, Marco Allinovi, Hatice Ceylan Koydemir, Alin Achim</li>
<li>for: 这篇论文的目的是提高肺超音波检测中的B-线检测精度和速度。</li>
<li>methods: 这篇论文使用了深度 unfolding 的 Alternating Direction Method of Multipliers (ADMM) 来解决肺超音波检测中的B-线检测问题。</li>
<li>results: 比较 traditional model-based method, 这篇论文的方法可以更快速地完成B-线检测（更多于 90 倍），并且精度也提高了10.6%。<details>
<summary>Abstract</summary>
In the context of lung ultrasound, the detection of B-lines, which are indicative of interstitial lung disease and pulmonary edema, plays a pivotal role in clinical diagnosis. Current methods still rely on visual inspection by experts. Vision-based automatic B-line detection methods have been developed, but their performance has yet to improve in terms of both accuracy and computational speed. This paper presents a novel approach to posing B-line detection as an inverse problem via deep unfolding of the Alternating Direction Method of Multipliers (ADMM). It tackles the challenges of data labelling and model training in lung ultrasound image analysis by harnessing the capabilities of deep neural networks and model-based methods. Our objective is to substantially enhance diagnostic accuracy while ensuring efficient real-time capabilities. The results show that the proposed method runs more than 90 times faster than the traditional model-based method and achieves an F1 score that is 10.6% higher.
</details>
<details>
<summary>摘要</summary>
在肺超声 imaging 中，B-线的检测对临床诊断具有重要的作用。现有方法仍然依赖于专家的视觉检查。基于视觉的自动B-线检测方法已经开发，但其性能还未得到改进。这篇论文提出了一种将B-线检测转换为反问题via深度嵌入ADMM的新方法。它利用深度神经网络和模型基于方法来解决肺超声图像分析中的数据标注和模型训练问题。我们的目标是substantially提高诊断精度，同时保持高速的实时能力。结果显示，提出的方法在计算速度方面比传统的模型基于方法快上了90多个倍，并且 achieved an F1 score 10.6% 高于传统模型。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/11/eess.IV_2023_11_11/" data-id="clp9qz8fa01d2ok884qvuaeny" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_11" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/11/eess.SP_2023_11_11/" class="article-date">
  <time datetime="2023-11-11T08:00:00.000Z" itemprop="datePublished">2023-11-11</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/11/eess.SP_2023_11_11/">eess.SP - 2023-11-11</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Design-of-Reconfigurable-Intelligent-Surfaces-by-Using-S-Parameter-Multiport-Network-Theory-–-Optimization-and-Full-Wave-Validation"><a href="#Design-of-Reconfigurable-Intelligent-Surfaces-by-Using-S-Parameter-Multiport-Network-Theory-–-Optimization-and-Full-Wave-Validation" class="headerlink" title="Design of Reconfigurable Intelligent Surfaces by Using S-Parameter Multiport Network Theory – Optimization and Full-Wave Validation"></a>Design of Reconfigurable Intelligent Surfaces by Using S-Parameter Multiport Network Theory – Optimization and Full-Wave Validation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06648">http://arxiv.org/abs/2311.06648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Abrardo, Alberto Toccafondi, Marco Di Renzo<br>for:* 这篇论文主要研究的是利用多口网络理论分析和优化智能反射表面（RIS），尤其是在距离半波长之下 spacing 的情况下。methods:* 这篇论文使用了 $Z$-parameter（阻抗）和 $S$-parameter（散射）矩阵来表示 RIS 的辐射特性。* 提出了一种基于 $S$-parameter 表示的迭代算法，用于在电romagnetic 互相作用的情况下优化 RIS 的可调负载。results:* 研究发现，通过对 RIS 的结构散射进行考虑，可以更好地优化 RIS 的辐射特性，并且可以在不同的方向上获得更高的接收功率。* 对比 $Z$-parameter 和 $S$-parameter 表示，发现 $S$-parameter 更能准确地描述 RIS 的辐射特性，并且可以更快地获得更好的优化结果。<details>
<summary>Abstract</summary>
Multiport network theory has been proved to be a suitable abstraction model for analyzing and optimizing reconfigurable intelligent surfaces (RISs), especially for studying the impact of the electromagnetic mutual coupling among radiating elements that are spaced less than half of the wavelength. Both representations in terms of $Z$-parameter (impedance) and $S$-parameter (scattering) matrices are widely utilized. In this paper, we embrace multiport network theory for analyzing and optimizing the reradiation properties of RIS-aided channels, and provide four new contributions. (i) First, we offer a thorough comparison between the $Z$-parameter and $S$-parameter representations. This comparison allows us to unveil that the typical scattering models utilized for RIS-aided channels ignore the structural scattering from the RIS, which results in an unwanted specular reflection. (ii) Then, we develop an iterative algorithm for optimizing, in the presence of electromagnetic mutual coupling, the tunable loads of the RIS based on the $S$-parameters representation. We prove that small perturbations of the step size of the algorithm result in larger variations of the $S$-parameter matrix compared with the $Z$-parameter matrix, resulting in a faster convergence rate. (iii) Subsequently, we generalize the proposed algorithm to suppress the specular reflection due to the structural scattering, while maximizing the received power towards the direction of interest, and analyze the effectiveness and tradeoffs of the proposed approach. (iv) Finally, we validate the theoretical findings and algorithms with numerical simulations and a commercial full-wave electromagnetic simulator based on the method of moments.
</details>
<details>
<summary>摘要</summary>
多ports网络理论被证明是对折叠智能表面（RIS）的分析和优化模型适用，尤其是研究电磁共振元素之间的电磁共振coupling的影响。这两种表述都广泛使用$Z$-参数（阻抗）和$S$-参数（散射）矩阵。在这篇论文中，我们使用多ports网络理论分析和优化RIS-帮助通道的反射特性，并提供四项新贡献。（i）首先，我们对$Z$-参数和$S$-参数表述进行了深入的比较。这种比较表明，通常用于RIS-帮助通道的散射模型忽略了RIS的结构散射，导致不必要的反射。（ii）然后，我们开发了基于$S$-参数表述的迭代算法，用于在电磁共振coupling存在的情况下优化RIS的可变荷重。我们证明，对算法步长的小 perturbation会导致$S$-参数矩阵中的变化更大，而$Z$-参数矩阵中的变化更小，因此算法的速度更快。（iii）接着，我们扩展了提议的算法，以suppress结构散射引起的反射，同时 Maximize received power towards the direction of interest。我们分析了提议的效果和牺牲。（iv）最后，我们验证了理论发现和算法通过数值仿真和商业全波电磁 simulator based on the method of moments。
</details></li>
</ul>
<hr>
<h2 id="Generative-AI-for-Space-Air-Ground-Integrated-Networks-SAGIN"><a href="#Generative-AI-for-Space-Air-Ground-Integrated-Networks-SAGIN" class="headerlink" title="Generative AI for Space-Air-Ground Integrated Networks (SAGIN)"></a>Generative AI for Space-Air-Ground Integrated Networks (SAGIN)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06523">http://arxiv.org/abs/2311.06523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruichen Zhang, Hongyang Du, Dusit Niyato, Jiawen Kang, Zehui Xiong, Abbas Jamalipour, Ping Zhang, Dong In Kim</li>
<li>for: 本文探讨了将生成AI应用于空地空间 интегра网络（SAGIN）中，强调其应用前景和实践案例。</li>
<li>methods: 本文首先提供了SAGIN和生成AI模型的全面回顾，探讨了它们的可能的integration应用场景和机会。然后，提出了一种基于生成Diffusion Model（GDM）的框架，用于提高SAGIN的服务质量。</li>
<li>results: 根据实验结果，提出的框架能够提高SAGIN的服务质量。此外，本文还讨论了将来的生成AI-enabled SAGIN研究方向。<details>
<summary>Abstract</summary>
Recently, generative AI technologies have emerged as a significant advancement in artificial intelligence field, renowned for their language and image generation capabilities. Meantime, space-air-ground integrated network (SAGIN) is an integral part of future B5G/6G for achieving ubiquitous connectivity. Inspired by this, this article explores an integration of generative AI in SAGIN, focusing on potential applications and case study. We first provide a comprehensive review of SAGIN and generative AI models, highlighting their capabilities and opportunities of their integration. Benefiting from generative AI's ability to generate useful data and facilitate advanced decision-making processes, it can be applied to various scenarios of SAGIN. Accordingly, we present a concise survey on their integration, including channel modeling and channel state information (CSI) estimation, joint air-space-ground resource allocation, intelligent network deployment, semantic communications, image extraction and processing, security and privacy enhancement. Next, we propose a framework that utilizes a Generative Diffusion Model (GDM) to construct channel information map to enhance quality of service for SAGIN. Simulation results demonstrate the effectiveness of the proposed framework. Finally, we discuss potential research directions for generative AI-enabled SAGIN.
</details>
<details>
<summary>摘要</summary>
最近，生成式人工智能技术在人工智能领域取得了重要进步，被广泛应用于语言和图像生成等领域。同时，空天地三合一网络（SAGIN）是未来5G/6G的重要组成部分，旨在实现无限连接。以此为启发，本文探讨了生成式人工智能在SAGIN中的 интеграцию，主要强调其应用前景和实践案例。我们首先提供了SAGIN和生成式人工智能模型的全面审视，探讨它们的可能的 интеграción和应用前景。生成式人工智能可以生成有用的数据，并促进高级决策过程，因此可以应用于SAGIN多种场景。在这些应用场景中，我们提出了一种基于生成扩散模型（GDM）的框架，用于提高SAGIN的质量服务。实验结果表明该框架的效果是可靠的。最后，我们讨论了生成式人工智能在SAGIN中的未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Semantic-aware-Sampling-and-Transmission-in-Energy-Harvesting-Systems-A-POMDP-Approach"><a href="#Semantic-aware-Sampling-and-Transmission-in-Energy-Harvesting-Systems-A-POMDP-Approach" class="headerlink" title="Semantic-aware Sampling and Transmission in Energy Harvesting Systems: A POMDP Approach"></a>Semantic-aware Sampling and Transmission in Energy Harvesting Systems: A POMDP Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06522">http://arxiv.org/abs/2311.06522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abolfazl Zakeri, Mohammad Moltafet, Marian Codreanu</li>
<li>for: 本研究探讨了一种能量吸收系统中的实时跟踪问题，并在不完美的通道情况下进行了研究。</li>
<li>methods: 本文使用了Markov源模型，并考虑了采样和传输成本。不同于大多数先前研究，本文假设源不可见。</li>
<li>results: 研究人员通过解决一个随机控制问题，实现了三个semantic-aware指标的共同优化：一、信息年龄（AoI），二、通信质量，三、错误信息年龄（AoII）。通过仿真实验，研究人员发现了优化策略的性能提升，并发现了不同的 switching-type 优化策略。<details>
<summary>Abstract</summary>
We study real-time tracking problem in an energy harvesting system with a Markov source under an imperfect channel. We consider both sampling and transmission costs and different from most prior studies that assume the source is fully observable, the sampling cost renders the source unobservable. The goal is to jointly optimize sampling and transmission policies for three semantic-aware metrics: i) the age of information (AoI), ii) general distortion, and iii) the age of incorrect information (AoII). To this end, we formulate and solve a stochastic control problem. Specifically, for the AoI metric, we cast a Markov decision process (MDP) problem and solve it using relative value iteration (RVI). For the distortion and AoII metrics, we utilize the partially observable MDP (POMDP) modeling and leverage the notion of belief MDP formulation of POMDP to find optimal policies. For the distortion metric and the AoII metric under the perfect channel setup, we effectively truncate the corresponding belief space and solve an MDP problem using RVI. For the general setup, a deep reinforcement learning policy is proposed. Through simulations, we demonstrate significant performance improvements achieved by the derived policies. The results reveal various switching-type structures of optimal policies and show that a distortion-optimal policy is also AoII optimal.
</details>
<details>
<summary>摘要</summary>
我们研究实时跟踪问题在能量收集系统中，其中源是Markov过程，并且通信频道存在不完美性。我们考虑了抽样和传输成本，并且不同于大多数前一些研究，源不可见。我们的目标是同时优化抽样和传输策略，以达到三个semantic-aware指标的最优化：一、信息年龄（AoI），二、通信误差，三、错误信息年龄（AoII）。为此，我们设计了一个随机控制问题，并使用相对价值迭代（RVI）解决Markov决策过程（MDP）问题。对于AoI指标，我们使用POMDP模型和信念MDP形式进行解决。对于误差指标和AoII指标在完美通信设置下，我们有效地舒缩相应的信念空间，并使用RVI解决MDP问题。在总体设置下，我们提议了深度强化学习策略。通过sime simulations，我们发现derived策略具有显著的性能改进。结果显示了不同的 switching-type结构，并证明了误差优化策略也是AoII优化的。
</details></li>
</ul>
<hr>
<h2 id="Sum-Rate-Optimization-for-RIS-Aided-Multiuser-Communications-with-Movable-Antenna"><a href="#Sum-Rate-Optimization-for-RIS-Aided-Multiuser-Communications-with-Movable-Antenna" class="headerlink" title="Sum-Rate Optimization for RIS-Aided Multiuser Communications with Movable Antenna"></a>Sum-Rate Optimization for RIS-Aided Multiuser Communications with Movable Antenna</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06501">http://arxiv.org/abs/2311.06501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunan Sun, Hao Xu, Chongjun Ouyang, Hongwen Yang</li>
<li>for: 本研究旨在提高无线通信网络性能，探讨了可程度智能表面（RIS）技术的应用。</li>
<li>methods: 本文提出了一个基于RIS的多用户通信系统，利用可动天线（MA）技术优化通道容量。</li>
<li>results: 提出的迭代算法可以优化照明、RIS的反射系数（RC）值和MA的位置，以提高系统的总资料率。numerical results显示了提案的方法的有效性和MA-based系统在总资料率方面的优势。<details>
<summary>Abstract</summary>
Reconfigurable intelligent surface (RIS) is known as a promising technology to improve the performance of wireless communication networks, which has been extensively studied. Movable antenna (MA) is a novel technology that fully exploits the antenna position for enhancing the channel capacity. In this paper, we propose a new RIS-aided multiuser communication system with MAs. The sum-rate is maximized by jointly optimizing the beamforming, the reflection coefficient (RC) values of RIS and the positions of MAs. A fractional programming-based iterative algorithm is proposed to solve the formulated non-convex problem, considering three assumptions for the RIS. Numerical results are presented to verify the effectiveness of the proposed algorithm and the superiority of the proposed MA-based system in terms of sum-rate.
</details>
<details>
<summary>摘要</summary>
改进无线通信网络性能的可 configurable智能表面（RIS）技术已经广泛研究， movable antenna（MA）是一种新的技术，它可以全面利用天线位置来提高通信频率。在这篇论文中，我们提议一种基于RIS的多用户通信系统，并使用MA来提高系统性能。我们使用一种基于分数编程的迭代算法来最大化宽扩权（beamforming）、RIS反射系数（RC）和MA位置的优化问题。我们对问题进行了非几何化处理，并根据RIS的三个假设进行了解释。我们通过数值结果验证了我们的提案的有效性和MA基本系统的提高性。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Communication-for-Cooperative-Perception-based-on-Importance-Map"><a href="#Semantic-Communication-for-Cooperative-Perception-based-on-Importance-Map" class="headerlink" title="Semantic Communication for Cooperative Perception based on Importance Map"></a>Semantic Communication for Cooperative Perception based on Importance Map</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06498">http://arxiv.org/abs/2311.06498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yucheng Sheng, Hao Ye, Le Liang, Shi Jin, Geoffrey Ye Li</li>
<li>for: 这 paper 的目的是提出一种基于 Vehicle-to-Vehicle (V2V) 通信技术的 Cooperative Perception 方法，以便实现自动驾驶车辆的3D объек体探测。</li>
<li>methods: 本 paper 使用了一种Importance Map 技术来提取 semantic information，并提出了一种新的 Cooperative Perception Semantic Communication Scheme with Intermediate Fusion。</li>
<li>results:  simulations 表明，我们的提议的模型在不同的通道模型下表现出了优于传统分离源-通道编码的性能。此外，我们的模型还能够在时变 multipath 拍抄频道下保持robustness。<details>
<summary>Abstract</summary>
Cooperative perception, which has a broader perception field than single-vehicle perception, has played an increasingly important role in autonomous driving to conduct 3D object detection. Through vehicle-to-vehicle (V2V) communication technology, various connected automated vehicles (CAVs) can share their sensory information (LiDAR point clouds) for cooperative perception. We employ an importance map to extract significant semantic information and propose a novel cooperative perception semantic communication scheme with intermediate fusion. Meanwhile, our proposed architecture can be extended to the challenging time-varying multipath fading channel. To alleviate the distortion caused by the time-varying multipath fading, we adopt explicit orthogonal frequency-division multiplexing (OFDM) blocks combined with channel estimation and channel equalization. Simulation results demonstrate that our proposed model outperforms the traditional separate source-channel coding over various channel models. Moreover, a robustness study indicates that only part of semantic information is key to cooperative perception. Although our proposed model has only been trained over one specific channel, it has the ability to learn robust coded representations of semantic information that remain resilient to various channel models, demonstrating its generality and robustness.
</details>
<details>
<summary>摘要</summary>
合作感知，具有更广泛的感知范围 than single-vehicle perception，在自动驾驶中扮演着越来越重要的角色，以实现3D对象探测。通过自动汽车之间的通信技术（V2V），不同的相连自动汽车（CAVs）可以共享它们的感知信息（LiDAR点云）进行合作感知。我们使用重要度图 Extract significant semantic information and propose a novel cooperative perception semantic communication scheme with intermediate fusion. Meanwhile, our proposed architecture can be extended to the challenging time-varying multipath fading channel. To alleviate the distortion caused by the time-varying multipath fading, we adopt explicit orthogonal frequency-division multiplexing (OFDM) blocks combined with channel estimation and channel equalization. Simulation results demonstrate that our proposed model outperforms the traditional separate source-channel coding over various channel models. Moreover, a robustness study indicates that only part of semantic information is key to cooperative perception. Although our proposed model has only been trained over one specific channel, it has the ability to learn robust coded representations of semantic information that remain resilient to various channel models, demonstrating its generality and robustness.Here's the translation in Traditional Chinese:合作感知，具有更广泛的感知范围 than single-vehicle perception，在自动驾驶中扮演着越来越重要的角色，以实现3D对象探测。通过自动汽车之间的通信技术（V2V），不同的相连自动汽车（CAVs）可以共享它们的感知信息（LiDAR点云）进行合作感知。我们使用重要度图 Extract significant semantic information and propose a novel cooperative perception semantic communication scheme with intermediate fusion. Meanwhile, our proposed architecture can be extended to the challenging time-varying multipath fading channel. To alleviate the distortion caused by the time-varying multipath fading, we adopt explicit orthogonal frequency-division multiplexing (OFDM) blocks combined with channel estimation and channel equalization. Simulation results demonstrate that our proposed model outperforms the traditional separate source-channel coding over various channel models. Moreover, a robustness study indicates that only part of semantic information is key to cooperative perception. Although our proposed model has only been trained over one specific channel, it has the ability to learn robust coded representations of semantic information that remain resilient to various channel models, demonstrating its generality and robustness.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/11/eess.SP_2023_11_11/" data-id="clp9qz8hj01hmok889lkahpn9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/10/cs.CV_2023_11_10/" class="article-date">
  <time datetime="2023-11-10T13:00:00.000Z" itemprop="datePublished">2023-11-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/10/cs.CV_2023_11_10/">cs.CV - 2023-11-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Flatness-aware-Adversarial-Attack"><a href="#Flatness-aware-Adversarial-Attack" class="headerlink" title="Flatness-aware Adversarial Attack"></a>Flatness-aware Adversarial Attack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06423">http://arxiv.org/abs/2311.06423</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingyuan Fan, Xiaodan Li, Cen Chen, Yinggui Wang</li>
<li>for: 这 paper 的目的是通过利用抗击器的传输性来发动黑盒攻击。</li>
<li>methods: 这 paper 使用的方法是通过组合多个转换后的输入来生成抗击器。</li>
<li>results:  compared with 现有基elines，这 paper 的方法可以明显提高抗击器的传输性。Here’s the full translation of the paper’s abstract in Simplified Chinese:</li>
<li>for: 这 paper 的目的是通过利用抗击器的传输性来发动黑盒攻击。</li>
<li>methods: 这 paper 使用的方法是通过组合多个转换后的输入来生成抗击器。</li>
<li>results:  compared with 现有基elines，这 paper 的方法可以明显提高抗击器的传输性。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
The transferability of adversarial examples can be exploited to launch black-box attacks. However, adversarial examples often present poor transferability. To alleviate this issue, by observing that the diversity of inputs can boost transferability, input regularization based methods are proposed, which craft adversarial examples by combining several transformed inputs. We reveal that input regularization based methods make resultant adversarial examples biased towards flat extreme regions. Inspired by this, we propose an attack called flatness-aware adversarial attack (FAA) which explicitly adds a flatness-aware regularization term in the optimization target to promote the resultant adversarial examples towards flat extreme regions. The flatness-aware regularization term involves gradients of samples around the resultant adversarial examples but optimizing gradients requires the evaluation of Hessian matrix in high-dimension spaces which generally is intractable. To address the problem, we derive an approximate solution to circumvent the construction of Hessian matrix, thereby making FAA practical and cheap. Extensive experiments show the transferability of adversarial examples crafted by FAA can be considerably boosted compared with state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
“敌方模型可以通过对抗性示例的转移性攻击。但是，对抗性示例通常具有差的转移性。为解决这个问题，我们观察到输入多标的帮助，可以提高对抗性示例的转移性。我们提出了基于输入调整的方法，这些方法通过组合多个对抗性示例的转换而创建对抗性示例。我们发现这些对抗性示例倾向于扁平极大区域。受这些想法所影响，我们提出了一种名为扁平识别攻击（FAA）的攻击方法。这个方法将在优化目标中添加一个扁平识别调整项，以便提高对抗性示例的转移性。扁平识别调整项需要在高维度空间中评估扁平方向的梯度，但是评估梯度通常是不可能的。为解决这个问题，我们 derive an approximate solution，以便在高维度空间中评估扁平方向的梯度，并且让FAA实用且便宜。实验结果表明，由FAA创建的对抗性示例的转移性可以与现有基准相比大大提高。”
</details></li>
</ul>
<hr>
<h2 id="EviPrompt-A-Training-Free-Evidential-Prompt-Generation-Method-for-Segment-Anything-Model-in-Medical-Images"><a href="#EviPrompt-A-Training-Free-Evidential-Prompt-Generation-Method-for-Segment-Anything-Model-in-Medical-Images" class="headerlink" title="EviPrompt: A Training-Free Evidential Prompt Generation Method for Segment Anything Model in Medical Images"></a>EviPrompt: A Training-Free Evidential Prompt Generation Method for Segment Anything Model in Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06400">http://arxiv.org/abs/2311.06400</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinsong Xu, Jiaqi Tang, Aidong Men, Qingchao Chen</li>
<li>for: 这篇论文的目的是提出一种无需训练的证据提示生成方法，以解决医疗影像分类中的专业知识干预和领域差距问题。</li>
<li>methods: 这篇论文提出了一种基于医疗影像内在相似性的训练�free evidential prompt generation方法，仅需一个参考影像�annotationPair，可以大幅减少 Labeling 和计算资源的需求。</li>
<li>results: 该方法可以自动生成适当的证据提示，以提高 SAM 在医疗影像分类中的应用和有用性。 evaluations across a broad range of tasks and modalities confirm its efficacy.<details>
<summary>Abstract</summary>
Medical image segmentation has immense clinical applicability but remains a challenge despite advancements in deep learning. The Segment Anything Model (SAM) exhibits potential in this field, yet the requirement for expertise intervention and the domain gap between natural and medical images poses significant obstacles. This paper introduces a novel training-free evidential prompt generation method named EviPrompt to overcome these issues. The proposed method, built on the inherent similarities within medical images, requires only a single reference image-annotation pair, making it a training-free solution that significantly reduces the need for extensive labeling and computational resources. First, to automatically generate prompts for SAM in medical images, we introduce an evidential method based on uncertainty estimation without the interaction of clinical experts. Then, we incorporate the human prior into the prompts, which is vital for alleviating the domain gap between natural and medical images and enhancing the applicability and usefulness of SAM in medical scenarios. EviPrompt represents an efficient and robust approach to medical image segmentation, with evaluations across a broad range of tasks and modalities confirming its efficacy.
</details>
<details>
<summary>摘要</summary>
医学图像分割具有巨大的临床应用前提，但是它仍然是一个挑战，尽管深度学习在发展。 seg anything模型（SAM）在这一点方面表现出潜力，但是需要专家干预和医学图像和自然图像之间的领域差距问题带来了重大障碍。这篇论文介绍了一种新的无需训练的证据提示生成方法，名为EviPrompt，以解决这些问题。我们的方法基于医学图像之间的自然相似性，只需要一个参考图像-标注对，可以减少了大量的标注和计算资源。首先，我们引入了一种基于不确定性估计的证据方法，无需互动式临床专家。然后，我们将人类优先级 integrate 到提示中，这是关键的，可以减少医学图像和自然图像之间的领域差距，提高SAM在医学场景中的应用和实用性。EviPrompt表示一种高效和可靠的医学图像分割方法，评估结果 across 多种任务和模式表明其效果。
</details></li>
</ul>
<hr>
<h2 id="A-design-of-Convolutional-Neural-Network-model-for-the-Diagnosis-of-the-COVID-19"><a href="#A-design-of-Convolutional-Neural-Network-model-for-the-Diagnosis-of-the-COVID-19" class="headerlink" title="A design of Convolutional Neural Network model for the Diagnosis of the COVID-19"></a>A design of Convolutional Neural Network model for the Diagnosis of the COVID-19</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06394">http://arxiv.org/abs/2311.06394</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jafar-Abdollahi/Automated-detection-of-COVID-19-cases-using-deep-neural-networks-with-CTS-images">https://github.com/Jafar-Abdollahi/Automated-detection-of-COVID-19-cases-using-deep-neural-networks-with-CTS-images</a></li>
<li>paper_authors: Xinyuan Song<br>for:这种研究的目的是为了提供一种准确地识别COVID-19的肺部X射线图像分类方法，以帮助临床中心和医院诊断COVID-19。methods:这种方法基于19层卷积神经网络（CNN），并对三类（肺炎、正常、COVID）和四类（肺擦亮、正常、COVID-19、肺炎）进行分类。研究人员还对一些已经预训练的网络进行比较，包括Inception、Alexnet、ResNet50、Squeezenet和VGG19。results:实验结果表明，提出的CNN方法在准确率、特异性、准确率、敏感度和归一化矩阵等指标上具有明显的优势，超过了现有的发布过程。这种方法可以为临床医生提供一个有用的工具，帮助他们准确地诊断COVID-19。<details>
<summary>Abstract</summary>
With the spread of COVID-19 around the globe over the past year, the usage of artificial intelligence (AI) algorithms and image processing methods to analyze the X-ray images of patients' chest with COVID-19 has become essential. The COVID-19 virus recognition in the lung area of a patient is one of the basic and essential needs of clicical centers and hospitals. Most research in this field has been devoted to papers on the basis of deep learning methods utilizing CNNs (Convolutional Neural Network), which mainly deal with the screening of sick and healthy people.In this study, a new structure of a 19-layer CNN has been recommended for accurately recognition of the COVID-19 from the X-ray pictures of chest. The offered CNN is developed to serve as a precise diagnosis system for a three class (viral pneumonia, Normal, COVID) and a four classclassification (Lung opacity, Normal, COVID-19, and pneumonia). A comparison is conducted among the outcomes of the offered procedure and some popular pretrained networks, including Inception, Alexnet, ResNet50, Squeezenet, and VGG19 and based on Specificity, Accuracy, Precision, Sensitivity, Confusion Matrix, and F1-score. The experimental results of the offered CNN method specify its dominance over the existing published procedures. This method can be a useful tool for clinicians in deciding properly about COVID-19.
</details>
<details>
<summary>摘要</summary>
随着 COVID-19 在过去一年内的全球蔓延，使用人工智能（AI）算法和图像处理方法来分析患 COVID-19 患者的X射线图像已成为必需的。识别患 COVID-19 病毒在患者的肺部是临床中心和医院的基本和必要需求。大多数研究都集中在基于深度学习方法的 CNN（卷积神经网络）上，主要是用于健康和疾病人的分类。在本研究中，一种新的19层 CNN 结构被建议用于准确地识别 X射线图像中的 COVID-19。这个 CNN 结构是用于三类（肺病毒感染、正常、COVID）和四类分类（肺抑血、正常、COVID-19、肺炎）。对于这些结果和一些常用的预训练网络（如 Inception、Alexnet、ResNet50、Squeezenet 和 VGG19）进行了比较，并根据具体性、准确率、精度、敏感度和冲激矩阵来评估。实验结果表明，提出的 CNN 方法在现有发表的方法中具有优势。这种方法可以成为临床医生决策 COVID-19 的有用工具。
</details></li>
</ul>
<hr>
<h2 id="Towards-A-Unified-Neural-Architecture-for-Visual-Recognition-and-Reasoning"><a href="#Towards-A-Unified-Neural-Architecture-for-Visual-Recognition-and-Reasoning" class="headerlink" title="Towards A Unified Neural Architecture for Visual Recognition and Reasoning"></a>Towards A Unified Neural Architecture for Visual Recognition and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06386">http://arxiv.org/abs/2311.06386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Calvin Luo, Boqing Gong, Ting Chen, Chen Sun</li>
<li>for: 这篇论文主要针对视觉理解的两大柱子：认知和理解。</li>
<li>methods: 该论文提出了一种基于多任务转换器的协同架构，可以同时解决视觉认知和理解两个任务。</li>
<li>results: 研究发现，对象检测任务对视觉理解具有最大的帮助，并且该架构自动生成了对象中心的表示。此外，研究还发现了不同架构设计对视觉理解的影响。<details>
<summary>Abstract</summary>
Recognition and reasoning are two pillars of visual understanding. However, these tasks have an imbalance in focus; whereas recent advances in neural networks have shown strong empirical performance in visual recognition, there has been comparably much less success in solving visual reasoning. Intuitively, unifying these two tasks under a singular framework is desirable, as they are mutually dependent and beneficial. Motivated by the recent success of multi-task transformers for visual recognition and language understanding, we propose a unified neural architecture for visual recognition and reasoning with a generic interface (e.g., tokens) for both. Our framework enables the principled investigation of how different visual recognition tasks, datasets, and inductive biases can help enable spatiotemporal reasoning capabilities. Noticeably, we find that object detection, which requires spatial localization of individual objects, is the most beneficial recognition task for reasoning. We further demonstrate via probing that implicit object-centric representations emerge automatically inside our framework. Intriguingly, we discover that certain architectural choices such as the backbone model of the visual encoder have a significant impact on visual reasoning, but little on object detection. Given the results of our experiments, we believe that visual reasoning should be considered as a first-class citizen alongside visual recognition, as they are strongly correlated but benefit from potentially different design choices.
</details>
<details>
<summary>摘要</summary>
<<SYS>>视觉理解的两个柱子是认知和理解。然而，这两个任务在注意力方面存在偏见，而且近年来神经网络的实验性表现在视觉认知方面强大，而在视觉理解方面相对落后。可是，将这两个任务集成到一个共同框架中是有利的，因为它们是互相依赖的和有益的。鼓励 by recent success of multi-task transformers for visual recognition and language understanding, we propose a unified neural architecture for visual recognition and reasoning with a generic interface (e.g., tokens) for both. Our framework enables the principled investigation of how different visual recognition tasks, datasets, and inductive biases can help enable spatiotemporal reasoning capabilities.发现结果显示，对象检测，需要物体的空间局部化，是最有利的认知任务 для理解。我们还通过探测发现了自动内生的卷积表示。进一步的实验结果表明，certain architectural choices such as the backbone model of the visual encoder have a significant impact on visual reasoning, but little on object detection. given the results of our experiments, we believe that visual reasoning should be considered as a first-class citizen alongside visual recognition, as they are strongly correlated but benefit from potentially different design choices. Traditional Chinese translation:<<SYS>>Visual understanding 的两个柱子是识别和理解。然而，这两个任务在注意力方面存在偏见，而且近年来神经网络的实验性表现在视觉认知方面强大，而在视觉理解方面相对落后。可是，将这两个任务集成到一个共同框架中是有利的，因为它们是互相依赖的和有益的。鼓励 by recent success of multi-task transformers for visual recognition and language understanding, we propose a unified neural architecture for visual recognition and reasoning with a generic interface (e.g., tokens) for both. Our framework enables the principled investigation of how different visual recognition tasks, datasets, and inductive biases can help enable spatiotemporal reasoning capabilities.发现结果显示，对象检测，需要物体的空间局部化，是最有利的认知任务 для理解。我们还通过探测发现了自动内生的卷积表示。进一步的实验结果表明，certain architectural choices such as the backbone model of the visual encoder have a significant impact on visual reasoning, but little on object detection. given the results of our experiments, we believe that visual reasoning should be considered as a first-class citizen alongside visual recognition, as they are strongly correlated but benefit from potentially different design choices.
</details></li>
</ul>
<hr>
<h2 id="Image-Classification-using-Combination-of-Topological-Features-and-Neural-Networks"><a href="#Image-Classification-using-Combination-of-Topological-Features-and-Neural-Networks" class="headerlink" title="Image Classification using Combination of Topological Features and Neural Networks"></a>Image Classification using Combination of Topological Features and Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06375">http://arxiv.org/abs/2311.06375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mariana Dória Prata Lima, Gilson Antonio Giraldi, Gastão Florêncio Miranda Junior</li>
<li>for: 本研究使用 persist homology 方法，一种在 topological data analysis (TDA) 中常用的技术，以提取数据空间中的基本 topological 特征，并将其与深度学习特征结合以进行分类任务。</li>
<li>methods: 本研究首先从复杂体系中构建了筛选，然后计算了 persistent homology 类型，并将其在筛选中的演化visualized through persistence diagram。此外，我们还应用了vectorization技术，使这些 topological 信息与机器学习算法兼容。</li>
<li>results: 我们的方法可以在 MNIST 数据集中分类多个类型的图像，并且比基eline 的结果更高。我们的分析还表明，在多类分类任务中， topological 信息可以提高神经网络的准确率，但是计算 persist homology 的计算复杂性增加。这是我们知道的第一个结合深度学习特征和 topological 特征的多类分类任务。<details>
<summary>Abstract</summary>
In this work we use the persistent homology method, a technique in topological data analysis (TDA), to extract essential topological features from the data space and combine them with deep learning features for classification tasks. In TDA, the concepts of complexes and filtration are building blocks. Firstly, a filtration is constructed from some complex. Then, persistent homology classes are computed, and their evolution along the filtration is visualized through the persistence diagram. Additionally, we applied vectorization techniques to the persistence diagram to make this topological information compatible with machine learning algorithms. This was carried out with the aim of classifying images from multiple classes in the MNIST dataset. Our approach inserts topological features into deep learning approaches composed by single and two-streams neural networks architectures based on a multi-layer perceptron (MLP) and a convolutional neral network (CNN) taylored for multi-class classification in the MNIST dataset. In our analysis, we evaluated the obtained results and compared them with the outcomes achieved through the baselines that are available in the TensorFlow library. The main conclusion is that topological information may increase neural network accuracy in multi-class classification tasks with the price of computational complexity of persistent homology calculation. Up to the best of our knowledge, it is the first work that combines deep learning features and the combination of topological features for multi-class classification tasks.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们使用 persistente homology 方法，一种 topological data analysis（TDA）中的技术，以提取数据空间中的基本 topological 特征，并将其与深度学习特征结合以进行分类任务。在 TDA 中，复杂设与筛选是建筑 Material。首先，一个筛选是从一个复杂中构造出来。然后， persistente homology 类是计算出来，并将其在筛选的演化中可见化 durch persistence 图。此外，我们还应用了vectorization技术来使这些 topological 信息与机器学习算法兼容。这是为了在 MNIST 数据集中分类图像。我们的方法把 topological 特征与单流和两流 neural network 架构（基于 multi-layer perceptron 和 convolutional neural network）结合以进行多类分类。在我们的分析中，我们评估了获得的结果，并与存在于 TensorFlow 库中的基eline 结果进行比较。结论是：topological 信息可能会增加多类分类任务中 neural network 精度，但是 persistente homology 计算的计算复杂度会增加。据我们所知，这是首次将 deep learning 特征与 topological 特征结合以进行多类分类任务。
</details></li>
</ul>
<hr>
<h2 id="Florence-2-Advancing-a-Unified-Representation-for-a-Variety-of-Vision-Tasks"><a href="#Florence-2-Advancing-a-Unified-Representation-for-a-Variety-of-Vision-Tasks" class="headerlink" title="Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks"></a>Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06242">http://arxiv.org/abs/2311.06242</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Xiao, Haiping Wu, Weijian Xu, Xiyang Dai, Houdong Hu, Yumao Lu, Michael Zeng, Ce Liu, Lu Yuan<br>for: Florence-2 is a novel vision foundation model that can perform a variety of computer vision and vision-language tasks with simple text-based instructions.methods: Florence-2 uses a sequence-to-sequence structure and large-scale, high-quality annotated data to train the model for versatile and comprehensive vision tasks.results: Florence-2 demonstrated strong zero-shot and fine-tuning capabilities, making it a competitive vision foundation model for a variety of tasks.Here is the text in Simplified Chinese:for:  florence-2 是一种 novel 的视觉基础模型，可以通过简单的文本指令来执行多种计算机视觉和视觉语言任务。methods:  florence-2 使用 sequence-to-sequence 结构和大规模、高质量的注解数据来训练模型，以执行多元和全面的视觉任务。results:  florence-2 在多种任务上表现出了强大的零配置和微调能力，使其成为计算机视觉领域的竞争力强的视觉基础模型。<details>
<summary>Abstract</summary>
We introduce Florence-2, a novel vision foundation model with a unified, prompt-based representation for a variety of computer vision and vision-language tasks. While existing large vision models excel in transfer learning, they struggle to perform a diversity of tasks with simple instructions, a capability that implies handling the complexity of various spatial hierarchy and semantic granularity. Florence-2 was designed to take text-prompt as task instructions and generate desirable results in text forms, whether it be captioning, object detection, grounding or segmentation. This multi-task learning setup demands large-scale, high-quality annotated data. To this end, we co-developed FLD-5B that consists of 5.4 billion comprehensive visual annotations on 126 million images, using an iterative strategy of automated image annotation and model refinement. We adopted a sequence-to-sequence structure to train Florence-2 to perform versatile and comprehensive vision tasks. Extensive evaluations on numerous tasks demonstrated Florence-2 to be a strong vision foundation model contender with unprecedented zero-shot and fine-tuning capabilities.
</details>
<details>
<summary>摘要</summary>
我们介绍 Florence-2，一种新型视觉基础模型，具有一个统一的提示基础表示，用于多种计算机视觉和视觉语言任务。现有的大型视觉模型在转移学习方面表现出色，但它们在执行简单的指令下表现不佳，这表明它们不能处理多种空间层次和semantic粒度的复杂性。Florence-2是根据文本提示进行任务指令，并生成desirable的结果，无论是captioning、对象检测、grounding或分割。这种多任务学习设置需要大规模、高质量的注解数据。为此，我们共同开发了 FLD-5B，包括126万张图像的5.4亿次全面视觉注解，使用了迭代的自动图像注解和模型优化策略。我们采用了序列到序列结构来训练 Florence-2，以便它可以执行多种灵活和全面的视觉任务。广泛的评估表明，Florence-2是一个强大的视觉基础模型候选人，具有历史上未有的零shot和微调能力。
</details></li>
</ul>
<hr>
<h2 id="Learning-Human-Action-Recognition-Representations-Without-Real-Humans"><a href="#Learning-Human-Action-Recognition-Representations-Without-Real-Humans" class="headerlink" title="Learning Human Action Recognition Representations Without Real Humans"></a>Learning Human Action Recognition Representations Without Real Humans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06231">http://arxiv.org/abs/2311.06231</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/howardzh01/ppma">https://github.com/howardzh01/ppma</a></li>
<li>paper_authors: Howard Zhong, Samarth Mishra, Donghyun Kim, SouYoung Jin, Rameswar Panda, Hilde Kuehne, Leonid Karlinsky, Venkatesh Saligrama, Aude Oliva, Rogerio Feris<br>for: 这个论文的目的是研究是否可以使用不包含真实人类图像的数据进行人体动作识别模型的预训练。methods: 这篇论文使用了一个新的预训练策略，即 Privacy-Preserving MAE-Align，将真实人类图像去除后的数据和 sintetic数据组合使用，以提高预训练模型的表现。results: 该论文的实验结果表明，使用 Privacy-Preserving MAE-Align 策略可以提高预训练模型的表现，并将人体动作识别模型的表现与无人体动作识别模型的表现进行比较。此外，该论文还提供了一个可用于复现研究的开源 benchmark。<details>
<summary>Abstract</summary>
Pre-training on massive video datasets has become essential to achieve high action recognition performance on smaller downstream datasets. However, most large-scale video datasets contain images of people and hence are accompanied with issues related to privacy, ethics, and data protection, often preventing them from being publicly shared for reproducible research. Existing work has attempted to alleviate these problems by blurring faces, downsampling videos, or training on synthetic data. On the other hand, analysis on the transferability of privacy-preserving pre-trained models to downstream tasks has been limited. In this work, we study this problem by first asking the question: can we pre-train models for human action recognition with data that does not include real humans? To this end, we present, for the first time, a benchmark that leverages real-world videos with humans removed and synthetic data containing virtual humans to pre-train a model. We then evaluate the transferability of the representation learned on this data to a diverse set of downstream action recognition benchmarks. Furthermore, we propose a novel pre-training strategy, called Privacy-Preserving MAE-Align, to effectively combine synthetic data and human-removed real data. Our approach outperforms previous baselines by up to 5% and closes the performance gap between human and no-human action recognition representations on downstream tasks, for both linear probing and fine-tuning. Our benchmark, code, and models are available at https://github.com/howardzh01/PPMA .
</details>
<details>
<summary>摘要</summary>
大规模视频数据的预训练已成为实现高效人体动作识别的必备条件。然而，大多数大规模视频数据包含人脸图像，因此会附带隐私、伦理和数据保护等问题，常常使得这些数据无法公开分享，对于可重复的研究。现有的工作尝试解决这些问题，通过让人脸模糊、视频下采样或使用生成的数据进行训练。然而，对于隐私保持的模型转移性的分析却受到限制。在这项工作中，我们提出了以下问题：可以我们在不包含真实人类数据的情况下进行人体动作识别预训练吗？为此，我们提供了一个新的数据集，其中包含了人类去除后的真实视频和虚拟人类生成的数据，用于预训练模型。然后，我们评估了这种数据的表示学习到下游动作识别任务中的转移性，并提出了一种新的预训练策略，即隐私保持MAE-Align。我们的方法比前一代基eline上提高了5%，并将人类动作识别和无人类动作识别表示之间的性能差距降到最小。我们的数据集、代码和模型可以在https://github.com/howardzh01/PPMA上下载。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Models-for-Earth-Observation-Use-cases-from-cloud-removal-to-urban-change-detection"><a href="#Diffusion-Models-for-Earth-Observation-Use-cases-from-cloud-removal-to-urban-change-detection" class="headerlink" title="Diffusion Models for Earth Observation Use-cases: from cloud removal to urban change detection"></a>Diffusion Models for Earth Observation Use-cases: from cloud removal to urban change detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06222">http://arxiv.org/abs/2311.06222</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/furio1999/EO_Diffusion">https://github.com/furio1999/EO_Diffusion</a></li>
<li>paper_authors: Fulvio Sanguigni, Mikolaj Czerkawski, Lorenzo Papa, Irene Amerini, Bertrand Le Saux</li>
<li>for: 这篇论文旨在展示 diffusion 模型对于卫星影像数据的应用，并提出了三个实际应用案例。</li>
<li>methods: 这篇论文使用了 diffusion 模型，包括云除和填充、数据集生成 для变化检测任务、以及城市规划。</li>
<li>results: 这篇论文获得了云除和填充、数据集生成、城市规划等三个实际应用案例中的良好结果。<details>
<summary>Abstract</summary>
The advancements in the state of the art of generative Artificial Intelligence (AI) brought by diffusion models can be highly beneficial in novel contexts involving Earth observation data. After introducing this new family of generative models, this work proposes and analyses three use cases which demonstrate the potential of diffusion-based approaches for satellite image data. Namely, we tackle cloud removal and inpainting, dataset generation for change-detection tasks, and urban replanning.
</details>
<details>
<summary>摘要</summary>
“现代生成人工智能（AI）技术的进步，即扩散模型，在地球观测数据中可以获得非常有利的效果。本研究首次介绍了这种新的生成模型家族，然后提出和分析了三个使用场景，即云除和填充、数据集生成 для变化检测任务、和城市规划。”Here's a breakdown of the translation:* 现代生成人工智能 (AI) 技术 (技术) - This phrase is translated as "现代生成人工智能（AI）技术" in Simplified Chinese.* 的进步 (进步) - This word is translated as "的进步" in Simplified Chinese.* 即扩散模型 (扩散模型) - This phrase is translated as "即扩散模型" in Simplified Chinese.* 在地球观测数据中 (在地球观测数据中) - This phrase is translated as "在地球观测数据中" in Simplified Chinese.* 可以获得非常有利的效果 (可以获得非常有利的效果) - This phrase is translated as "可以获得非常有利的效果" in Simplified Chinese.* 本研究 (本研究) - This word is translated as "本研究" in Simplified Chinese.* 首次介绍了 (首次介绍了) - This phrase is translated as "首次介绍了" in Simplified Chinese.* 这种新的生成模型家族 (这种新的生成模型家族) - This phrase is translated as "这种新的生成模型家族" in Simplified Chinese.* 然后 (然后) - This word is translated as "然后" in Simplified Chinese.* 提出和分析了三个使用场景 (提出和分析了三个使用场景) - This phrase is translated as "提出和分析了三个使用场景" in Simplified Chinese.* 即云除和填充 (即云除和填充) - This phrase is translated as "即云除和填充" in Simplified Chinese.* 数据集生成 для变化检测任务 (数据集生成 для变化检测任务) - This phrase is translated as "数据集生成 для变化检测任务" in Simplified Chinese.* 和城市规划 (和城市规划) - This phrase is translated as "和城市规划" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Semantic-aware-Video-Representation-for-Few-shot-Action-Recognition"><a href="#Semantic-aware-Video-Representation-for-Few-shot-Action-Recognition" class="headerlink" title="Semantic-aware Video Representation for Few-shot Action Recognition"></a>Semantic-aware Video Representation for Few-shot Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06218">http://arxiv.org/abs/2311.06218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yutao Tang, Benjamin Bejar, Rene Vidal</li>
<li>for: 提高ew-shot动作识别性能，解决现有方法依赖2D帧级别表示，缺乏有效的文本 semantics incorporation和简单的类别分类方法等问题。</li>
<li>methods: 提出了一种简单 yet effective的Semantic-Aware Few-Shot Action Recognition（SAFSAR）模型，通过直接使用3D特征提取器和有效的特征融合方案，以及简单的高度相似性分类方法，实现了更好的性能而无需额外 комponents for temporal modeling或复杂的距离函数。</li>
<li>results: 在五个具有不同设定的ew-shot动作识别benchmark上，经验表明，提出的SAFSAR模型可以显著提高状态 искусственный的性能。<details>
<summary>Abstract</summary>
Recent work on action recognition leverages 3D features and textual information to achieve state-of-the-art performance. However, most of the current few-shot action recognition methods still rely on 2D frame-level representations, often require additional components to model temporal relations, and employ complex distance functions to achieve accurate alignment of these representations. In addition, existing methods struggle to effectively integrate textual semantics, some resorting to concatenation or addition of textual and visual features, and some using text merely as an additional supervision without truly achieving feature fusion and information transfer from different modalities. In this work, we propose a simple yet effective Semantic-Aware Few-Shot Action Recognition (SAFSAR) model to address these issues. We show that directly leveraging a 3D feature extractor combined with an effective feature-fusion scheme, and a simple cosine similarity for classification can yield better performance without the need of extra components for temporal modeling or complex distance functions. We introduce an innovative scheme to encode the textual semantics into the video representation which adaptively fuses features from text and video, and encourages the visual encoder to extract more semantically consistent features. In this scheme, SAFSAR achieves alignment and fusion in a compact way. Experiments on five challenging few-shot action recognition benchmarks under various settings demonstrate that the proposed SAFSAR model significantly improves the state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
In this work, we propose a simple yet effective Semantic-Aware Few-Shot Action Recognition (SAFSAR) model to address these issues. Our approach leverages a 3D feature extractor combined with an effective feature-fusion scheme and a simple cosine similarity for classification, which improves performance without the need for extra components for temporal modeling or complex distance functions.We also introduce an innovative scheme to encode textual semantics into the video representation, which adaptively fuses features from text and video and encourages the visual encoder to extract more semantically consistent features. This scheme allows for compact and effective alignment and fusion of textual and visual information.Experiments on five challenging few-shot action recognition benchmarks under various settings demonstrate that the proposed SAFSAR model significantly improves the state-of-the-art performance.
</details></li>
</ul>
<hr>
<h2 id="Instant3D-Fast-Text-to-3D-with-Sparse-View-Generation-and-Large-Reconstruction-Model"><a href="#Instant3D-Fast-Text-to-3D-with-Sparse-View-Generation-and-Large-Reconstruction-Model" class="headerlink" title="Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model"></a>Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06214">http://arxiv.org/abs/2311.06214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahao Li, Hao Tan, Kai Zhang, Zexiang Xu, Fujun Luan, Yinghao Xu, Yicong Hong, Kalyan Sunkavalli, Greg Shakhnarovich, Sai Bi</li>
<li>for: This paper aims to generate high-quality and diverse 3D assets from text prompts in a feed-forward manner.</li>
<li>methods: The proposed method Instant3D uses a two-stage paradigm, which first generates a sparse set of four structured and consistent views from text in one shot with a fine-tuned 2D text-to-image diffusion model, and then directly regresses the NeRF from the generated images with a novel transformer-based sparse-view reconstructor.</li>
<li>results: The method can generate high-quality, diverse and Janus-free 3D assets within 20 seconds, which is two orders of magnitude faster than previous optimization-based methods that can take 1 to 10 hours.<details>
<summary>Abstract</summary>
Text-to-3D with diffusion models have achieved remarkable progress in recent years. However, existing methods either rely on score distillation-based optimization which suffer from slow inference, low diversity and Janus problems, or are feed-forward methods that generate low quality results due to the scarcity of 3D training data. In this paper, we propose Instant3D, a novel method that generates high-quality and diverse 3D assets from text prompts in a feed-forward manner. We adopt a two-stage paradigm, which first generates a sparse set of four structured and consistent views from text in one shot with a fine-tuned 2D text-to-image diffusion model, and then directly regresses the NeRF from the generated images with a novel transformer-based sparse-view reconstructor. Through extensive experiments, we demonstrate that our method can generate high-quality, diverse and Janus-free 3D assets within 20 seconds, which is two order of magnitude faster than previous optimization-based methods that can take 1 to 10 hours. Our project webpage: https://jiahao.ai/instant3d/.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose Instant3D, a novel method that generates high-quality and diverse 3D assets from text prompts in a feed-forward manner. We adopt a two-stage paradigm:1. First, we generate a sparse set of four structured and consistent views from text in one shot with a fine-tuned 2D text-to-image diffusion model.2. Then, we directly regress the NeRF from the generated images with a novel transformer-based sparse-view reconstructor.Through extensive experiments, we demonstrate that our method can generate high-quality, diverse, and Janus-free 3D assets within 20 seconds, which is two orders of magnitude faster than previous optimization-based methods that can take 1 to 10 hours. Our project webpage is <https://jiahao.ai/instant3d/>.
</details></li>
</ul>
<hr>
<h2 id="ASSIST-Interactive-Scene-Nodes-for-Scalable-and-Realistic-Indoor-Simulation"><a href="#ASSIST-Interactive-Scene-Nodes-for-Scalable-and-Realistic-Indoor-Simulation" class="headerlink" title="ASSIST: Interactive Scene Nodes for Scalable and Realistic Indoor Simulation"></a>ASSIST: Interactive Scene Nodes for Scalable and Realistic Indoor Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06211">http://arxiv.org/abs/2311.06211</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhide Zhong, Jiakai Cao, Songen Gu, Sirui Xie, Weibo Gao, Liyi Luo, Zike Yan, Hao Zhao, Guyue Zhou</li>
<li>for: 这篇论文旨在提出一种基于神经网络的物体尺度场，用于实现复杂的物体和场景的真实化和组合渲染。</li>
<li>methods: 该方法使用一种新的场景节点数据结构，它将每个物体的信息存储在一起，以便在线交互和跨场景设定中进行交互。该结构还包括一个可微 differentiable神经网络、相关的 bounding box 和semantic feature，以便通过鼠标&#x2F;键盘控制或语言指令进行简单的交互。</li>
<li>results: 实验表明，该方法可以实现可扩展的真实化和组合渲染，并生成三维彩色图像、深度图像和精确的分割mask。<details>
<summary>Abstract</summary>
We present ASSIST, an object-wise neural radiance field as a panoptic representation for compositional and realistic simulation. Central to our approach is a novel scene node data structure that stores the information of each object in a unified fashion, allowing online interaction in both intra- and cross-scene settings. By incorporating a differentiable neural network along with the associated bounding box and semantic features, the proposed structure guarantees user-friendly interaction on independent objects to scale up novel view simulation. Objects in the scene can be queried, added, duplicated, deleted, transformed, or swapped simply through mouse/keyboard controls or language instructions. Experiments demonstrate the efficacy of the proposed method, where scaled realistic simulation can be achieved through interactive editing and compositional rendering, with color images, depth images, and panoptic segmentation masks generated in a 3D consistent manner.
</details>
<details>
<summary>摘要</summary>
我们提出了ASSIST，一种对象级别神经辐射场，用于实现组合和实际的 simulate 作业。我们的方法的核心是一种新的场景节点数据结构，可以同时存储每个对象的信息，以便在线上交互和跨场景设置。通过结合可导式神经网络和相关的 bounding box 和semantic feature，我们的结构确保了用户友好的交互，可以通过鼠标/键盘控制或语言指令来查询、添加、复制、删除、转换或换位对象。实验表明，我们的方法可以实现协助编辑和组合渲染，并生成3D保持一致的颜色图像、深度图像和panographic分割mask。
</details></li>
</ul>
<hr>
<h2 id="An-Automated-Pipeline-for-Tumour-Infiltrating-Lymphocyte-Scoring-in-Breast-Cancer"><a href="#An-Automated-Pipeline-for-Tumour-Infiltrating-Lymphocyte-Scoring-in-Breast-Cancer" class="headerlink" title="An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in Breast Cancer"></a>An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in Breast Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06185">http://arxiv.org/abs/2311.06185</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adamshephard/tiager">https://github.com/adamshephard/tiager</a></li>
<li>paper_authors: Adam J Shephard, Mostafa Jahanifar, Ruoyu Wang, Muhammad Dawood, Simon Graham, Kastytis Sidlauskas, Syed Ali Khurram, Nasir M Rajpoot, Shan E Ahmed Raza</li>
<li>For: 本研究使用深度学习算法对 breast cancer 整幕影像进行 TILs 分数计算，以提高诊断和预后评估。* Methods: 我们的方法首先分别分类 tumour 和 stroma 区域，然后在 tumour-associated stroma 中检测 TILs，并生成 TILs 分数。我们的方法基于 Efficient-UNet 架构，并且具有 state-of-the-art 的性能在 tumour&#x2F;stroma 区域分 segmentation 和 TILs 检测中。* Results: 我们的研究表明，我们的自动 TILs 分数系统可以准确预测 breast cancer 患者的 survival 结果，并且与 Pathologist 的评估结果相符。<details>
<summary>Abstract</summary>
Tumour-infiltrating lymphocytes (TILs) are considered as a valuable prognostic markers in both triple-negative and human epidermal growth factor receptor 2 (HER2) breast cancer. In this study, we introduce an innovative deep learning pipeline based on the Efficient-UNet architecture to compute a TILs score for breast cancer whole slide images. Our pipeline first segments tumour-stroma regions and generates a tumour bulk mask. Subsequently, it detects TILs within the tumour-associated stroma, generating a TILs score by closely mirroring the pathologist's workflow. Our method exhibits state-of-the-art performance in segmenting tumour/stroma areas and TILs detection, as demonstrated by internal cross-validation on the TiGER Challenge training dataset and evaluation on the final leaderboards. Additionally, our TILs score proves competitive in predicting survival outcomes within the same challenge, underscoring the clinical relevance and potential of our automated TILs scoring system as a breast cancer prognostic tool.
</details>
<details>
<summary>摘要</summary>
肿瘤浸泡免疫细胞（TILs）在三重阴性和人顺体外生长因子受体2（HER2）乳腺癌中被视为有价值的诊断标志。本研究提出了一种创新的深度学习管道，基于Efficient-UNet架构，计算乳腺癌整个染色体影像中TILs分数。我们的管道首先分 segment tumor-stroma区域，并生成肿瘤涂抹mask。然后，它检测TILs在肿瘤相关的Connective tissue中，生成TILs分数，与病理学家的工作流程几乎相同。我们的方法在分 segment tumor/stroma区域和TILs检测方面表现出了状态之arte的表现，经过内部交叉验证在TiGER Challenge训练数据集上，并在最终的排名中进行了评估。此外，我们的TILs分数能够预测乳腺癌存活结果，这 highlights the clinical relevance and potential of our automated TILs scoring system as a breast cancer prognostic tool。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Report-Generation-for-Histopathology-images-using-pre-trained-Vision-Transformers"><a href="#Automatic-Report-Generation-for-Histopathology-images-using-pre-trained-Vision-Transformers" class="headerlink" title="Automatic Report Generation for Histopathology images using pre-trained Vision Transformers"></a>Automatic Report Generation for Histopathology images using pre-trained Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06176">http://arxiv.org/abs/2311.06176</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurav Sengupta, Donald E. Brown</li>
<li>for: 这个研究的目的是为了自动生成医学影像报告。</li>
<li>methods: 这个研究使用了现有的预训练的感知 трансформа器，在一个two-step过程中，首先使用它对4096x4096大小的整个数组图像（Whole Slide Image，WSI）进行编码，然后使用它作为编码器和LSTM复合器进行报告生成。</li>
<li>results: 这个研究获得了一个不错的性能和可移植性的报告生成机制，可以考虑整个高分辨率图像，而不只是patches。此外，这个研究还使用了现有的强大预训练的层次感知 transformer，并证明其在零损失分类以及报告生成中的有用性。<details>
<summary>Abstract</summary>
Deep learning for histopathology has been successfully used for disease classification, image segmentation and more. However, combining image and text modalities using current state-of-the-art methods has been a challenge due to the high resolution of histopathology images. Automatic report generation for histopathology images is one such challenge. In this work, we show that using an existing pre-trained Vision Transformer in a two-step process of first using it to encode 4096x4096 sized patches of the Whole Slide Image (WSI) and then using it as the encoder and an LSTM decoder for report generation, we can build a fairly performant and portable report generation mechanism that takes into account the whole of the high resolution image, instead of just the patches. We are also able to use representations from an existing powerful pre-trained hierarchical vision transformer and show its usefulness in not just zero shot classification but also for report generation.
</details>
<details>
<summary>摘要</summary>
深度学习在 Histopathology 中已经得到了成功，用于疾病分类、图像分割和更多的应用。然而，将图像和文本模式结合使用现有的状态太的方法是一个挑战，主要是因为 histopathology 图像的高分辨率。自动生成 histopathology 图像的报告是一个这样的挑战。在这项工作中，我们表明了使用现有的预训练 Vision Transformer 进行两步处理：首先，将 Whole Slide Image (WSI) 的 4096x4096 大小的patches 使用 Vision Transformer 进行编码，然后使用 Vision Transformer 作为编码器和 LSTM 解码器进行报告生成。我们发现，这种方法可以建立一个性能较高且可移植的报告生成机制，可以考虑整个高分辨率图像，而不仅仅是patches。此外，我们还可以使用现有的强大预训练 hierarchical Vision Transformer 的表示，并证明其在零shot分类以及报告生成中的用用。
</details></li>
</ul>
<hr>
<h2 id="Deep-Fast-Vision-A-Python-Library-for-Accelerated-Deep-Transfer-Learning-Vision-Prototyping"><a href="#Deep-Fast-Vision-A-Python-Library-for-Accelerated-Deep-Transfer-Learning-Vision-Prototyping" class="headerlink" title="Deep Fast Vision: A Python Library for Accelerated Deep Transfer Learning Vision Prototyping"></a>Deep Fast Vision: A Python Library for Accelerated Deep Transfer Learning Vision Prototyping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06169">http://arxiv.org/abs/2311.06169</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fabprezja/deep-fast-vision">https://github.com/fabprezja/deep-fast-vision</a></li>
<li>paper_authors: Fabi Prezja</li>
<li>for: 提高深度学习视觉领域的易用性和普及率，帮助非专家用户快速入门深度学习。</li>
<li>methods: 使用Python库实现简单化深度学习过程，提供易于理解的嵌入式字典定义，使得非专家用户可以轻松获得结果。</li>
<li>results: 提供一个简单、扩展性强的深度学习工具，帮助bridge Complex deep learning frameworks和各种用户需求，推动深度学习的普及和应用。<details>
<summary>Abstract</summary>
Deep learning-based vision is characterized by intricate frameworks that often necessitate a profound understanding, presenting a barrier to newcomers and limiting broad adoption. With many researchers grappling with the constraints of smaller datasets, there's a pronounced reliance on pre-trained neural networks, especially for tasks such as image classification. This reliance is further intensified in niche imaging areas where obtaining vast datasets is challenging. Despite the widespread use of transfer learning as a remedy to the small dataset dilemma, a conspicuous absence of tailored auto-ML solutions persists. Addressing these challenges is "Deep Fast Vision", a python library that streamlines the deep learning process. This tool offers a user-friendly experience, enabling results through a simple nested dictionary definition, helping to democratize deep learning for non-experts. Designed for simplicity and scalability, Deep Fast Vision appears as a bridge, connecting the complexities of existing deep learning frameworks with the needs of a diverse user base.
</details>
<details>
<summary>摘要</summary>
深度学习视觉 caracteriza por frameworks intrincados que a menudo requieren una comprensión profunda, lo que puede representar una barrera para los principiantes y limitaciones en la adopción amplia. Con muchos investigadores lidiando con los límites de conjuntos de datos más pequeños, hay una reliance pronunciada en redes neuronales preentrenzadas, especialmente para tareas como clasificación de imágenes. Esta reliance se vuelve a intensificar en áreas de imagen nicho donde obtener conjuntos de datos vastos es desafiante. A pesar del uso amplio de aprendizaje transferido como una solución a la dilema de conjuntos de datos pequeños, una ausencia conspicua de soluciones de Auto-ML personalizadas persiste. Para abordar estos desafíos, se presenta "Deep Fast Vision", una biblioteca de Python que simplifica el proceso de aprendizaje profundo. Esta herramienta ofrece una experiencia de usuario amigable, permitiendo resultados a través de una definición de diccionario nestado simple, ayudando a democratizar el aprendizaje profundo para no expertos. Diseñada para la simplicidad y escalabilidad, Deep Fast Vision se presenta como un puente que conecta las complejidades de los marcos existentes de aprendizaje profundo con las necesidades de una base de usuarios diversa.
</details></li>
</ul>
<hr>
<h2 id="An-Evaluation-of-Forensic-Facial-Recognition"><a href="#An-Evaluation-of-Forensic-Facial-Recognition" class="headerlink" title="An Evaluation of Forensic Facial Recognition"></a>An Evaluation of Forensic Facial Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06145">http://arxiv.org/abs/2311.06145</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DanielDdungu/Real-Time-Face-Recognition">https://github.com/DanielDdungu/Real-Time-Face-Recognition</a></li>
<li>paper_authors: Justin Norman, Shruti Agarwal, Hany Farid</li>
<li>for: 本研究旨在评估 faces recognition 系统在真实世界情况下的表现，特别是在低分辨率、低质量、部分遮挡的图像对标准面部数据库进行比较。</li>
<li>methods: 本研究使用了大量的synthetic facial dataset和控制 facial forensic lineup，以模拟真实世界中的面部识别情况。两种流行的神经网络基于的识别系统进行了评估。</li>
<li>results: 研究发现， previously reported face recognition accuracy 高于 95% 下降到了 65% 以下，表明面部识别系统在这种更加复杂的刑事enario中表现不佳。<details>
<summary>Abstract</summary>
Recent advances in machine learning and computer vision have led to reported facial recognition accuracies surpassing human performance. We question if these systems will translate to real-world forensic scenarios in which a potentially low-resolution, low-quality, partially-occluded image is compared against a standard facial database. We describe the construction of a large-scale synthetic facial dataset along with a controlled facial forensic lineup, the combination of which allows for a controlled evaluation of facial recognition under a range of real-world conditions. Using this synthetic dataset, and a popular dataset of real faces, we evaluate the accuracy of two popular neural-based recognition systems. We find that previously reported face recognition accuracies of more than 95% drop to as low as 65% in this more challenging forensic scenario.
</details>
<details>
<summary>摘要</summary>
最近的机器学习和计算机视觉技术发展，已经使facial recognition系统的准确率超过人类表现。我们问题是这些系统在真实世界冤家enario中是否能够维持高度的准确率，例如 comparing a low-resolution, low-quality, partially-occluded image against a standard facial database。我们描述了一个大规模的 sintetic facial dataset的构建，以及一个控制的 facial forensic lineup，这两个组合允许我们在不同的真实世界条件下进行控制的评估。使用这个 sintetic dataset，以及一个流行的实际面孔数据集，我们评估了两个流行的神经网络基于的认识系统的准确率。我们发现，以前报道的面recognition准确率高于95%下降到了65%的这样的更加挑战的冤家enario中。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-Across-Decentralized-and-Unshared-Archives-for-Remote-Sensing-Image-Classification"><a href="#Federated-Learning-Across-Decentralized-and-Unshared-Archives-for-Remote-Sensing-Image-Classification" class="headerlink" title="Federated Learning Across Decentralized and Unshared Archives for Remote Sensing Image Classification"></a>Federated Learning Across Decentralized and Unshared Archives for Remote Sensing Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06141">http://arxiv.org/abs/2311.06141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Barış Büyüktaş, Gencer Sumbul, Begüm Demir</li>
<li>for: 这paper aimsto explore the potential of federated learning (FL) in remote sensing (RS) and compare state-of-the-art FL algorithms for image classification tasks.</li>
<li>methods: 本paper使用了多种state-of-the-art FL algorithms, including federated averaging (FedAvg), federated transfer learning (FedTL), and federated meta-learning (FedMeta). The authors also conducted a theoretical comparison of the algorithms based on their local training complexity, aggregation complexity, learning efficiency, communication cost, and scalability.</li>
<li>results: 经过实验研究， authors found that FedAvg and FedTL outperformed other algorithms under different decentralization scenarios. Additionally, the authors derived a guideline for selecting suitable FL algorithms in RS based on the characteristics of the decentralized data.<details>
<summary>Abstract</summary>
Federated learning (FL) enables the collaboration of multiple deep learning models to learn from decentralized data archives (i.e., clients) without accessing data on clients. Although FL offers ample opportunities in knowledge discovery from distributed image archives, it is seldom considered in remote sensing (RS). In this paper, as a first time in RS, we present a comparative study of state-of-the-art FL algorithms. To this end, we initially provide a systematic review of the FL algorithms presented in the computer vision community for image classification problems, and select several state-of-the-art FL algorithms based on their effectiveness with respect to training data heterogeneity across clients (known as non-IID data). After presenting an extensive overview of the selected algorithms, a theoretical comparison of the algorithms is conducted based on their: 1) local training complexity; 2) aggregation complexity; 3) learning efficiency; 4) communication cost; and 5) scalability in terms of number of clients. As the classification task, we consider multi-label classification (MLC) problem since RS images typically consist of multiple classes, and thus can simultaneously be associated with multi-labels. After the theoretical comparison, experimental analyses are presented to compare them under different decentralization scenarios in terms of MLC performance. Based on our comprehensive analyses, we finally derive a guideline for selecting suitable FL algorithms in RS. The code of this work will be publicly available at https://git.tu-berlin.de/rsim/FL-RS.
</details>
<details>
<summary>摘要</summary>
Federated 学习（FL）允许多个深度学习模型在分布式数据存储（即客户端）上学习而不需要访问客户端上的数据。尽管FL在分布式图像存储中提供了丰富的机会，它在远程感知（RS）领域几乎未得到考虑。在这篇论文中，我们为RS领域的首次应用FL算法进行了比较研究。为此，我们首先提供了计算机视觉社区中关于图像分类问题的FL算法的系统性评论，并选择了一些在客户端数据不同性（即非Identical和不同）上显示出效果的FL算法。接着，我们对选择的算法进行了理论性比较，包括：1）本地训练复杂度；2）聚合复杂度；3）学习效率；4）通信成本；和5）可扩展性。作为分类任务，我们考虑了多标签分类（MLC）问题，因为RS图像通常包含多个类别，可以同时被关联到多个标签。在理论比较后，我们进行了实验分析，对不同的分布式场景进行了MLC性能的比较。根据我们的全面分析，我们最终提出了RS中FL算法选择的指南。代码将在https://git.tu-berlin.de/rsim/FL-RS上公开。
</details></li>
</ul>
<hr>
<h2 id="MonoProb-Self-Supervised-Monocular-Depth-Estimation-with-Interpretable-Uncertainty"><a href="#MonoProb-Self-Supervised-Monocular-Depth-Estimation-with-Interpretable-Uncertainty" class="headerlink" title="MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty"></a>MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06137">http://arxiv.org/abs/2311.06137</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cea-list/monoprob">https://github.com/cea-list/monoprob</a></li>
<li>paper_authors: Rémi Marsal, Florian Chabot, Angelique Loesch, William Grolleau, Hichem Sahbi</li>
<li>for: 这 paper written for 自动驾驶汽车等应用环境分析。</li>
<li>methods: 该 paper 使用了一种新的无监督单目深度估计方法，即 MonoProb，可以在单一前进推理中提供可解释的uncertainty，表示网络对深度预测的预期错误。</li>
<li>results: 该 paper 的实验结果显示，MonoProb 可以提高depth和uncertainty的性能，并且可以在不增加推理时间的情况下提供depth和uncertainty的测量。<details>
<summary>Abstract</summary>
Self-supervised monocular depth estimation methods aim to be used in critical applications such as autonomous vehicles for environment analysis. To circumvent the potential imperfections of these approaches, a quantification of the prediction confidence is crucial to guide decision-making systems that rely on depth estimation. In this paper, we propose MonoProb, a new unsupervised monocular depth estimation method that returns an interpretable uncertainty, which means that the uncertainty reflects the expected error of the network in its depth predictions. We rethink the stereo or the structure-from-motion paradigms used to train unsupervised monocular depth models as a probabilistic problem. Within a single forward pass inference, this model provides a depth prediction and a measure of its confidence, without increasing the inference time. We then improve the performance on depth and uncertainty with a novel self-distillation loss for which a student is supervised by a pseudo ground truth that is a probability distribution on depth output by a teacher. To quantify the performance of our models we design new metrics that, unlike traditional ones, measure the absolute performance of uncertainty predictions. Our experiments highlight enhancements achieved by our method on standard depth and uncertainty metrics as well as on our tailored metrics. https://github.com/CEA-LIST/MonoProb
</details>
<details>
<summary>摘要</summary>
自我监督的单目深度估算方法目标在critical应用中，如自动驾驶车辆环境分析。为了避免这些方法的潜在缺陷，对depth估算的预测 confidence quantification是关键的，以帮助基于depth估算的决策系统。在这篇论文中，我们提出了MonoProb，一种新的无监督单目深度估算方法，该方法返回可解释的uncertainty，即网络的depth预测错误预期值。我们将单目或stereo/structure-from-motion paradigms用于无监督单目深度模型的训练转换为一个概率问题。在单个前向传播推理过程中，该模型提供了depth预测和其 confidence的度量，不会增加推理时间。我们然后通过一种新的自我混合损失来提高depth和uncertainty的性能，其中学生被监督于一个 pseudo 真实数据，该数据是一个depth输出的概率分布。为了衡量我们的模型性能，我们设计了新的metric，与传统metric不同，可以量化uncertainty预测的绝对性能。我们的实验表明，我们的方法在标准深度和uncertainty metric以及我们定制的metric上具有显著提高。References:* GitHub: <https://github.com/CEA-LIST/MonoProb>
</details></li>
</ul>
<hr>
<h2 id="Fight-Fire-with-Fire-Combating-Adversarial-Patch-Attacks-using-Pattern-randomized-Defensive-Patches"><a href="#Fight-Fire-with-Fire-Combating-Adversarial-Patch-Attacks-using-Pattern-randomized-Defensive-Patches" class="headerlink" title="Fight Fire with Fire: Combating Adversarial Patch Attacks using Pattern-randomized Defensive Patches"></a>Fight Fire with Fire: Combating Adversarial Patch Attacks using Pattern-randomized Defensive Patches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06122">http://arxiv.org/abs/2311.06122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianan Feng, Jiachun Li, Changqing Miao, Jianjun Huang, Wei You, Wenchang Shi, Bin Liang</li>
<li>for: 防御 adversarial patch 攻击</li>
<li>methods: 使用活动防御策略，插入 canary 和 woodpecker 两种防御补丁，不改变目标模型</li>
<li>results: canary 和 woodpecker 实现高性能，能够抗击未知攻击方法，时间开销有限；对防御意识攻击也具有 suficient 鲁棒性<details>
<summary>Abstract</summary>
Object detection has found extensive applications in various tasks, but it is also susceptible to adversarial patch attacks. Existing defense methods often necessitate modifications to the target model or result in unacceptable time overhead. In this paper, we adopt a counterattack approach, following the principle of "fight fire with fire," and propose a novel and general methodology for defending adversarial attacks. We utilize an active defense strategy by injecting two types of defensive patches, canary and woodpecker, into the input to proactively probe or weaken potential adversarial patches without altering the target model. Moreover, inspired by randomization techniques employed in software security, we employ randomized canary and woodpecker injection patterns to defend against defense-aware attacks. The effectiveness and practicality of the proposed method are demonstrated through comprehensive experiments. The results illustrate that canary and woodpecker achieve high performance, even when confronted with unknown attack methods, while incurring limited time overhead. Furthermore, our method also exhibits sufficient robustness against defense-aware attacks, as evidenced by adaptive attack experiments.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploring-the-Efficacy-of-Base-Data-Augmentation-Methods-in-Deep-Learning-Based-Radiograph-Classification-of-Knee-Joint-Osteoarthritis"><a href="#Exploring-the-Efficacy-of-Base-Data-Augmentation-Methods-in-Deep-Learning-Based-Radiograph-Classification-of-Knee-Joint-Osteoarthritis" class="headerlink" title="Exploring the Efficacy of Base Data Augmentation Methods in Deep Learning-Based Radiograph Classification of Knee Joint Osteoarthritis"></a>Exploring the Efficacy of Base Data Augmentation Methods in Deep Learning-Based Radiograph Classification of Knee Joint Osteoarthritis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06118">http://arxiv.org/abs/2311.06118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fabi Prezja, Leevi Annala, Sampsa Kiiskinen, Timo Ojala</li>
<li>for: 该研究旨在检测关节骨块炎（KOA），一种全球范围内导致残疾的主要原因。</li>
<li>methods: 该研究使用深度学习方法进行KOA诊断，并利用数据增强技术来增加数据多样性。</li>
<li>results: 研究发现，使用恶意增强技术可以提高KOA分类模型的性能，但其他常用的增强技术则常下降性能。研究还发现，存在可能的混淆区域在图像中，这使得模型可以准确地分类KL0和KL4等级，而不需要考虑关节部分。这一观察表明了模型可能利用不相关的特征来进行分类。<details>
<summary>Abstract</summary>
Diagnosing knee joint osteoarthritis (KOA), a major cause of disability worldwide, is challenging due to subtle radiographic indicators and the varied progression of the disease. Using deep learning for KOA diagnosis requires broad, comprehensive datasets. However, obtaining these datasets poses significant challenges due to patient privacy concerns and data collection restrictions. Additive data augmentation, which enhances data variability, emerges as a promising solution. Yet, it's unclear which augmentation techniques are most effective for KOA. This study explored various data augmentation methods, including adversarial augmentations, and their impact on KOA classification model performance. While some techniques improved performance, others commonly used underperformed. We identified potential confounding regions within the images using adversarial augmentation. This was evidenced by our models' ability to classify KL0 and KL4 grades accurately, with the knee joint omitted. This observation suggested a model bias, which might leverage unrelated features for classification currently present in radiographs. Interestingly, removing the knee joint also led to an unexpected improvement in KL1 classification accuracy. To better visualize these paradoxical effects, we employed Grad-CAM, highlighting the associated regions. Our study underscores the need for careful technique selection for improved model performance and identifying and managing potential confounding regions in radiographic KOA deep learning.
</details>
<details>
<summary>摘要</summary>
诊断膝关节骨关节炎（KOA）具有挑战性，主要原因是诊断标准化不够，疾病进程变化多样化。使用深度学习诊断KOA需要广泛、全面的数据集。然而，获得这些数据集具有难题，主要是因为患者隐私问题和数据收集限制。添加数据增强技术可以解决这个问题。然而，不同的增强技术对KOA分类模型的影响是不确定的。本研究探讨了不同的数据增强方法，包括对抗增强技术，对KOA分类模型的影响。一些技术提高了表现，而其他们则常常表现不佳。我们使用对抗增强技术 indentified可能的混合区域内 immagini，这是通过我们的模型可以准确地分类KL0和KL4等级，而不需要膝关节。这一观察表明了我们的模型可能受到了不相关的特征的影响，从而导致模型偏好。意外地，去掉膝关节也导致了KL1等级的准确率提高。为了更好地visualize这些paraoxical效应，我们使用Grad-CAM，显示关联区域。本研究表明，选择合适的技术和识别和管理可能的混合区域在诊断KOA的深度学习中是非常重要的。
</details></li>
</ul>
<hr>
<h2 id="Dual-input-stream-transformer-for-eye-tracking-line-assignment"><a href="#Dual-input-stream-transformer-for-eye-tracking-line-assignment" class="headerlink" title="Dual input stream transformer for eye-tracking line assignment"></a>Dual input stream transformer for eye-tracking line assignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06095">http://arxiv.org/abs/2311.06095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas M. Mercier, Marcin Budka, Martin R. Vasilev, Julie A. Kirkby, Bernhard Angele, Timothy J. Slattery</li>
<li>for: 本研究的目的是解决阅读数据中的眩晕问题，通过分配眩晕点到文本行中的最佳线程。</li>
<li>methods: 本研究提出了一种基于Transformer的双输入流Transformer（DIST）模型，通过对多个实例的DIST模型进行ensemble学习，以提高眩晕点分配的准确率。</li>
<li>results: 对于九种经典方法的比较，DIST模型在九个多样化的数据集上达到了98.5%的平均准确率，显示DIST模型的优越性。<details>
<summary>Abstract</summary>
We introduce a novel Dual Input Stream Transformer (DIST) for the challenging problem of assigning fixation points from eye-tracking data collected during passage reading to the line of text that the reader was actually focused on. This post-processing step is crucial for analysis of the reading data due to the presence of noise in the form of vertical drift. We evaluate DIST against nine classical approaches on a comprehensive suite of nine diverse datasets, and demonstrate DIST's superiority. By combining multiple instances of the DIST model in an ensemble we achieve an average accuracy of 98.5\% across all datasets. Our approach presents a significant step towards addressing the bottleneck of manual line assignment in reading research. Through extensive model analysis and ablation studies, we identify key factors that contribute to DIST's success, including the incorporation of line overlap features and the use of a second input stream. Through evaluation on a set of diverse datasets we demonstrate that DIST is robust to various experimental setups, making it a safe first choice for practitioners in the field.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的双输入流转换器（DIST），用于从读者眼动数据中分配焦点点到实际阅读的行。这是阅读数据分析中的一个关键后处理步骤，因为存在垂直滑动的噪声。我们对九种经典方法进行了评估，并示出了 DIST 的优越性。通过将多个 DIST 模型 ensemble 组合，我们在所有数据集上实现了平均准确率为 98.5%。我们的方法为阅读研究中的手动线 assigning 带来了一个重要的突破口。通过广泛的模型分析和减少学习，我们确定了 DIST 成功的关键因素，包括将行 overlap 特征并入和使用第二个输入流。我们在多个不同的数据集上进行了评估，并证明了 DIST 在不同的实际设置下具有Robustness，使其成为领域中的首选方法。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Rock-Image-Segmentation-in-Digital-Rock-Physics-A-Fusion-of-Generative-AI-and-State-of-the-Art-Neural-Networks"><a href="#Enhancing-Rock-Image-Segmentation-in-Digital-Rock-Physics-A-Fusion-of-Generative-AI-and-State-of-the-Art-Neural-Networks" class="headerlink" title="Enhancing Rock Image Segmentation in Digital Rock Physics: A Fusion of Generative AI and State-of-the-Art Neural Networks"></a>Enhancing Rock Image Segmentation in Digital Rock Physics: A Fusion of Generative AI and State-of-the-Art Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06079">http://arxiv.org/abs/2311.06079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyang Ma, Xupeng He, Hyung Kwak, Jun Gao, Shuyu Sun, Bicheng Yan</li>
<li>for: 提高数字岩石物理中的岩石微结构分割精度和稳定性，使用先进的生成AI模型和深度学习网络。</li>
<li>methods: 使用扩展的生成AI模型（Diffusion Model）生成大量的CT&#x2F;SEM和二进制分割对，并使用U-Net、Attention-U-net和TransUNet三种神经网络进行分割。</li>
<li>results: 研究表明，通过将扩展的生成AI模型与高级神经网络结合，可以提高分割精度和一致性，并减少专家数据的需求。TransU-Net表现出色，在岩石微结构分割中实现最高的准确率和IoU指标。<details>
<summary>Abstract</summary>
In digital rock physics, analysing microstructures from CT and SEM scans is crucial for estimating properties like porosity and pore connectivity. Traditional segmentation methods like thresholding and CNNs often fall short in accurately detailing rock microstructures and are prone to noise. U-Net improved segmentation accuracy but required many expert-annotated samples, a laborious and error-prone process due to complex pore shapes. Our study employed an advanced generative AI model, the diffusion model, to overcome these limitations. This model generated a vast dataset of CT/SEM and binary segmentation pairs from a small initial dataset. We assessed the efficacy of three neural networks: U-Net, Attention-U-net, and TransUNet, for segmenting these enhanced images. The diffusion model proved to be an effective data augmentation technique, improving the generalization and robustness of deep learning models. TransU-Net, incorporating Transformer structures, demonstrated superior segmentation accuracy and IoU metrics, outperforming both U-Net and Attention-U-net. Our research advances rock image segmentation by combining the diffusion model with cutting-edge neural networks, reducing dependency on extensive expert data and boosting segmentation accuracy and robustness. TransU-Net sets a new standard in digital rock physics, paving the way for future geoscience and engineering breakthroughs.
</details>
<details>
<summary>摘要</summary>
在数字岩石物理中，分析微结构从CT和SEM扫描图像是关键的，以估算Properties like porosity和连通性。传统的分 segmentation方法，如阈值和CNNs，经常不能准确地描述岩石微结构，同时容易受到噪声的影响。U-Net提高了分 segmentation 精度，但需要大量由专家标注的样本，这是一个费时的和容易出错的过程，因为岩石的pores shapes是复杂的。我们的研究使用了一种先进的生成AI模型，扩散模型，以超越这些限制。这个模型生成了大量的CT/SEM和二进制分 segmentation对from a small initial dataset。我们评估了三个神经网络：U-Net、Attention-U-net和TransUNet，用于这些加强图像的分 segmentation。扩散模型证明是一种有效的数据增强技术，可以提高深度学习模型的普遍性和可靠性。TransU-Net，具有Transformer结构，在分 segmentation精度和IoU指标方面表现出色，超越了U-Net和Attention-U-net。我们的研究提高了岩石图像分 segmentation的准确性和可靠性，并减少了对专家数据的依赖。TransU-Net设置了新的标准在数字岩石物理中，开创了未来地球科学和工程的突破。
</details></li>
</ul>
<hr>
<h2 id="Learning-Based-Biharmonic-Augmentation-for-Point-Cloud-Classification"><a href="#Learning-Based-Biharmonic-Augmentation-for-Point-Cloud-Classification" class="headerlink" title="Learning-Based Biharmonic Augmentation for Point Cloud Classification"></a>Learning-Based Biharmonic Augmentation for Point Cloud Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06070">http://arxiv.org/abs/2311.06070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiacheng Wei, Guosheng Lin, Henghui Ding, Jie Hu, Kim-Hui Yap</li>
<li>for: 提高点云数据集的样本数量和多样性，以便进行更好的数据 augmentation。</li>
<li>methods: 我们提出了一种新的数据增强技术 called Biharmonic Augmentation (BA)，它通过对现有3D结构进行平滑非RIGID变换来增加数据集的多样性。我们使用一个CoefNet来预测权重，以将多个几何体的变换概率拼接起来。</li>
<li>results: 我们的实验表明，Biharmonic Augmentation 可以显著提高点云数据集的性能，并且在不同的网络设计下都显示出优秀的成果。<details>
<summary>Abstract</summary>
Point cloud datasets often suffer from inadequate sample sizes in comparison to image datasets, making data augmentation challenging. While traditional methods, like rigid transformations and scaling, have limited potential in increasing dataset diversity due to their constraints on altering individual sample shapes, we introduce the Biharmonic Augmentation (BA) method. BA is a novel and efficient data augmentation technique that diversifies point cloud data by imposing smooth non-rigid deformations on existing 3D structures. This approach calculates biharmonic coordinates for the deformation function and learns diverse deformation prototypes. Utilizing a CoefNet, our method predicts coefficients to amalgamate these prototypes, ensuring comprehensive deformation. Moreover, we present AdvTune, an advanced online augmentation system that integrates adversarial training. This system synergistically refines the CoefNet and the classification network, facilitating the automated creation of adaptive shape deformations contingent on the learner status. Comprehensive experimental analysis validates the superiority of Biharmonic Augmentation, showcasing notable performance improvements over prevailing point cloud augmentation techniques across varied network designs.
</details>
<details>
<summary>摘要</summary>
点云数据集经常受到不充分的样本数量的限制，使得数据增强成为一项挑战。传统方法，如rigid transformations和缩放，受到限制，因为它们不能改变个体样本的形状。我们介绍了一种新的和高效的数据增强技术——幂函数增强（BA）方法。BA方法通过计算幂函数坐标并学习多样化填充的投影函数，以增强点云数据的多样性。此外，我们还提出了一种名为 AdvTune的高级在线增强系统，该系统通过对CoefNet和分类网络进行对抗训练，自动生成适应性的形态变换，以适应学习者的不同状态。经过广泛的实验分析，我们证明了幂函数增强的优越性，在不同的网络设计下展现出了显著的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Attributes-Grouping-and-Mining-Hashing-for-Fine-Grained-Image-Retrieval"><a href="#Attributes-Grouping-and-Mining-Hashing-for-Fine-Grained-Image-Retrieval" class="headerlink" title="Attributes Grouping and Mining Hashing for Fine-Grained Image Retrieval"></a>Attributes Grouping and Mining Hashing for Fine-Grained Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06067">http://arxiv.org/abs/2311.06067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Lu, Shikun Chen, Yichao Cao, Xin Zhou, Xiaobo Lu</li>
<li>for: 本研究旨在提高大规模媒体搜索中的Hashing方法，以便实现精细图像检索。</li>
<li>methods: 我们提出了一种Attributes Grouping and Mining Hashing（AGMH）方法，该方法通过组合多个描述符来生成全面的特征表示。同时，我们还提出了一种Attention Dispersion Loss（ADL）和Stepwise Interactive External Attention（SIEA）两种方法，以便学习细致的特征和对象之间的相关性。</li>
<li>results: 实验结果表明，AGMH方法在精细图像检索任务中具有最佳性能，并且超过了现有的状态态方法。<details>
<summary>Abstract</summary>
In recent years, hashing methods have been popular in the large-scale media search for low storage and strong representation capabilities. To describe objects with similar overall appearance but subtle differences, more and more studies focus on hashing-based fine-grained image retrieval. Existing hashing networks usually generate both local and global features through attention guidance on the same deep activation tensor, which limits the diversity of feature representations. To handle this limitation, we substitute convolutional descriptors for attention-guided features and propose an Attributes Grouping and Mining Hashing (AGMH), which groups and embeds the category-specific visual attributes in multiple descriptors to generate a comprehensive feature representation for efficient fine-grained image retrieval. Specifically, an Attention Dispersion Loss (ADL) is designed to force the descriptors to attend to various local regions and capture diverse subtle details. Moreover, we propose a Stepwise Interactive External Attention (SIEA) to mine critical attributes in each descriptor and construct correlations between fine-grained attributes and objects. The attention mechanism is dedicated to learning discrete attributes, which will not cost additional computations in hash codes generation. Finally, the compact binary codes are learned by preserving pairwise similarities. Experimental results demonstrate that AGMH consistently yields the best performance against state-of-the-art methods on fine-grained benchmark datasets.
</details>
<details>
<summary>摘要</summary>
To address this limitation, we propose an Attributes Grouping and Mining Hashing (AGMH) method, which groups and embeds category-specific visual attributes in multiple descriptors to generate a comprehensive feature representation for efficient fine-grained image retrieval. We also design an Attention Dispersion Loss (ADL) to force the descriptors to attend to various local regions and capture diverse subtle details. Additionally, we propose a Stepwise Interactive External Attention (SIEA) to mine critical attributes in each descriptor and construct correlations between fine-grained attributes and objects. The attention mechanism is dedicated to learning discrete attributes, which does not require additional computations in hash code generation. Finally, we learn compact binary codes by preserving pairwise similarities.Experimental results show that AGMH consistently outperforms state-of-the-art methods on fine-grained benchmark datasets.
</details></li>
</ul>
<hr>
<h2 id="Lidar-based-Norwegian-tree-species-detection-using-deep-learning"><a href="#Lidar-based-Norwegian-tree-species-detection-using-deep-learning" class="headerlink" title="Lidar-based Norwegian tree species detection using deep learning"></a>Lidar-based Norwegian tree species detection using deep learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06066">http://arxiv.org/abs/2311.06066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martijn Vermeer, Jacob Alexander Hay, David Völgyes, Zsófia Koma, Johannes Breidenbach, Daniele Stefano Maria Fantin</li>
<li>for: 本研究旨在提高 Norwegische Wälder 中树species的映射效率，并且使用价格公平的 lidar 数据来进行类别。</li>
<li>methods: 本研究使用了深度学习的 tree species 分类模型，使用 lidar 影像进行分类，并且使用 focal loss 损失函数进行训练。</li>
<li>results: 本研究在独立验证中获得了 macro-averaged F1 分数0.70，与对比 aerial 或 aerial 和 lidar 结合的模型相当。<details>
<summary>Abstract</summary>
Background: The mapping of tree species within Norwegian forests is a time-consuming process, involving forest associations relying on manual labeling by experts. The process can involve both aerial imagery, personal familiarity, or on-scene references, and remote sensing data. The state-of-the-art methods usually use high resolution aerial imagery with semantic segmentation methods. Methods: We present a deep learning based tree species classification model utilizing only lidar (Light Detection And Ranging) data. The lidar images are segmented into four classes (Norway Spruce, Scots Pine, Birch, background) with a U-Net based network. The model is trained with focal loss over partial weak labels. A major benefit of the approach is that both the lidar imagery and the base map for the labels have free and open access. Results: Our tree species classification model achieves a macro-averaged F1 score of 0.70 on an independent validation with National Forest Inventory (NFI) in-situ sample plots. That is close to, but below the performance of aerial, or aerial and lidar combined models.
</details>
<details>
<summary>摘要</summary>
Background: 挪威森林中的树种分类是一项时间consuming的过程， Forest associations 需要经过专家 manually labeling。这个过程可以使用空中图像、个人熟悉或场景参考，以及遥感数据。现状的方法通常使用高分辨率空中图像与语义分割方法。Methods: 我们提出了一种基于深度学习的树种分类模型，只使用激光探测（Light Detection And Ranging）数据。激光图像被分类为四类（挪威落叶松、苏格兰杉、桦树、背景），使用基于U-Net的网络进行分类。模型通过 focal loss 对部分弱标签进行训练。这种方法的一个主要优点是，激光图像和基础地图均有免费和开放的 accessed。Results: 我们的树种分类模型在独立验证中以 macro-averaged F1 分数为 0.70 达到了高水平。与气象、气象和激光组合模型相比，其性能只有一些下降。
</details></li>
</ul>
<hr>
<h2 id="Improved-Positional-Encoding-for-Implicit-Neural-Representation-based-Compact-Data-Representation"><a href="#Improved-Positional-Encoding-for-Implicit-Neural-Representation-based-Compact-Data-Representation" class="headerlink" title="Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation"></a>Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06059">http://arxiv.org/abs/2311.06059</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bharath Bhushan Damodaran, Francois Schnitzler, Anne Lambert, Pierre Hellier</li>
<li>for: 提高含义表示（Implicit Neural Representation，INR）中信息的重建质量</li>
<li>methods: 使用位置编码法捕捉高频信息，提出一种新的 позицион编码方法，具有更多的频率基准，从而实现更好的数据压缩和重建质量</li>
<li>results: 实验显示，提出的方法可以在压缩任务中获得显著的增益，同时在新视角合成中实现更高的重建质量，而无需增加任何复杂性。<details>
<summary>Abstract</summary>
Positional encodings are employed to capture the high frequency information of the encoded signals in implicit neural representation (INR). In this paper, we propose a novel positional encoding method which improves the reconstruction quality of the INR. The proposed embedding method is more advantageous for the compact data representation because it has a greater number of frequency basis than the existing methods. Our experiments shows that the proposed method achieves significant gain in the rate-distortion performance without introducing any additional complexity in the compression task and higher reconstruction quality in novel view synthesis.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文。使用位置编码 capture高频信息编码的含义信号在偏挥 neural representation（INR）中。本文提出了一种新的位置编码方法，可以提高INR重建质量。该嵌入方法具有更多的频率基准，与现有方法相比，具有更好的数据压缩性。我们的实验表明，该方法可以在压缩任务中实现显著的加速性和高质量重建。
</details></li>
</ul>
<hr>
<h2 id="Ulcerative-Colitis-Mayo-Endoscopic-Scoring-Classification-with-Active-Learning-and-Generative-Data-Augmentation"><a href="#Ulcerative-Colitis-Mayo-Endoscopic-Scoring-Classification-with-Active-Learning-and-Generative-Data-Augmentation" class="headerlink" title="Ulcerative Colitis Mayo Endoscopic Scoring Classification with Active Learning and Generative Data Augmentation"></a>Ulcerative Colitis Mayo Endoscopic Scoring Classification with Active Learning and Generative Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06057">http://arxiv.org/abs/2311.06057</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ümit Mert Çağlar, Alperen İnci, Oğuz Hanoğlu, Görkem Polat, Alptekin Temizel</li>
<li>For:  This paper aims to improve the accuracy of endoscopic image analysis for Ulcerative Colitis (UC) diagnosis and severity classification, by using active learning and generative augmentation methods.* Methods: The proposed method involves generating a large number of synthetic samples using a small dataset of real endoscopic images, and then using active learning to select the most informative samples for training a classifier.* Results: The method achieved improved classification performance compared to using only the original labeled examples, with a QWK score increase from 68.1% to 74.5%. Additionally, the method required three times fewer real images to achieve equivalent performance.<details>
<summary>Abstract</summary>
Endoscopic imaging is commonly used to diagnose Ulcerative Colitis (UC) and classify its severity. It has been shown that deep learning based methods are effective in automated analysis of these images and can potentially be used to aid medical doctors. Unleashing the full potential of these methods depends on the availability of large amount of labeled images; however, obtaining and labeling these images are quite challenging. In this paper, we propose a active learning based generative augmentation method. The method involves generating a large number of synthetic samples by training using a small dataset consisting of real endoscopic images. The resulting data pool is narrowed down by using active learning methods to select the most informative samples, which are then used to train a classifier. We demonstrate the effectiveness of our method through experiments on a publicly available endoscopic image dataset. The results show that using synthesized samples in conjunction with active learning leads to improved classification performance compared to using only the original labeled examples and the baseline classification performance of 68.1% increases to 74.5% in terms of Quadratic Weighted Kappa (QWK) Score. Another observation is that, attaining equivalent performance using only real data necessitated three times higher number of images.
</details>
<details>
<summary>摘要</summary>
便门影像是通常用于诊断发炎性结肠炎（UC）和评估其严重程度。研究表明，深度学习基本方法可以有效地自动分析这些影像，并可能用于帮助医学博士。然而，获取和标注这些影像是很困难的。在这篇论文中，我们提出了一个活动学习基本的生成增强方法。这个方法包括生成一大量的 sintetic 样本，通过训练一小型的实际便门影像集合。然后，使用活动学习方法选择最有用的样本，并将它们用于训练分类器。我们通过实验显示了我们的方法的有效性，使用 sintetic 样本和活动学习可以将分类性能提高至原始标注数据的 68.1% 提高至 74.5%，即quadratic Weighted Kappa（QWK）分数。此外，我们发现，仅使用实际数据就能够取得相等的性能，需要三倍多的数据。
</details></li>
</ul>
<hr>
<h2 id="Learning-Contrastive-Self-Distillation-for-Ultra-Fine-Grained-Visual-Categorization-Targeting-Limited-Samples"><a href="#Learning-Contrastive-Self-Distillation-for-Ultra-Fine-Grained-Visual-Categorization-Targeting-Limited-Samples" class="headerlink" title="Learning Contrastive Self-Distillation for Ultra-Fine-Grained Visual Categorization Targeting Limited Samples"></a>Learning Contrastive Self-Distillation for Ultra-Fine-Grained Visual Categorization Targeting Limited Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06056">http://arxiv.org/abs/2311.06056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziye Fang, Xin Jiang, Hao Tang, Zechao Li</li>
<li>for: 本研究针对具有细分类别的 Multimedia 分析 tasks 提出了一个创新的框架，即 CSDNet，以便更好地处理具有复杂的类别分割和有限的数据的 Ultra-Fine-Grained Visual Categorization (Ultra-FGVC) 任务。</li>
<li>methods: CSDNet 构造由三个主要模组组成：Subcategory-Specific Discrepancy Parsing (SSDP)、Dynamic Discrepancy Learning (DDL) 和 Subcategory-Specific Discrepancy Transfer (SSDT)，这些模组共同增强了深度模型在不同的预测层次（instance、feature、logit）之间的通用性。具体来说，SSDP 模组通过将不同观点的扩展样本添加到标本集中，以显示出类别下的特殊差异；DDL 模组使用动态内存随机抽出器来优化特征学习空间，通过反对推对称推对称学习；SSDT 模组则通过一种新的自体激发方式在预测层次上进行自体激发，以更好地吸收类别下的差异知识。</li>
<li>results: 实验结果显示，CSDNet 在 Ultra-FGVC 任务上具有更高的表现力和适应力，较前一些现有的方法。这说明 CSDNet 能够更好地处理具有复杂的类别分割和有限的数据的 Ultra-FGVC 任务。<details>
<summary>Abstract</summary>
In the field of intelligent multimedia analysis, ultra-fine-grained visual categorization (Ultra-FGVC) plays a vital role in distinguishing intricate subcategories within broader categories. However, this task is inherently challenging due to the complex granularity of category subdivisions and the limited availability of data for each category. To address these challenges, this work proposes CSDNet, a pioneering framework that effectively explores contrastive learning and self-distillation to learn discriminative representations specifically designed for Ultra-FGVC tasks. CSDNet comprises three main modules: Subcategory-Specific Discrepancy Parsing (SSDP), Dynamic Discrepancy Learning (DDL), and Subcategory-Specific Discrepancy Transfer (SSDT), which collectively enhance the generalization of deep models across instance, feature, and logit prediction levels. To increase the diversity of training samples, the SSDP module introduces augmented samples from different viewpoints to spotlight subcategory-specific discrepancies. Simultaneously, the proposed DDL module stores historical intermediate features by a dynamic memory queue, which optimizes the feature learning space through iterative contrastive learning. Furthermore, the SSDT module is developed by a novel self-distillation paradigm at the logit prediction level of raw and augmented samples, which effectively distills more subcategory-specific discrepancies knowledge from the inherent structure of limited training data without requiring additional annotations. Experimental results demonstrate that CSDNet outperforms current state-of-the-art Ultra-FGVC methods, emphasizing its powerful efficacy and adaptability in addressing Ultra-FGVC tasks.
</details>
<details>
<summary>摘要</summary>
在智能多媒体分析领域， ultra-fine-grained视觉分类（Ultra-FGVC）扮演着重要的角色，用于分辨更加细致的分类划分。然而，这种任务具有较复杂的分类划分和数据有限的问题。为解决这些挑战，本文提出了 CSDNet 框架，它通过对比学习和自适应学习来学习特定于 Ultra-FGVC 任务的抽象表示。CSDNet 包括三个主要模块：特征特异性分析（SSDP）、动态不同分学习（DDL）和特征特异性转移（SSDT），这些模块共同提高了深度模型的通用性 across instance、feature和logit 预测层次。为了增加训练样本的多样性，SSDP 模块通过不同视点生成的增强样本来强调特征特异性。同时，提出的 DDL 模块通过动态缓存队列来优化特性学习空间，通过反卷积学习来优化特征学习。此外，SSDT 模块通过一种新的自适应学习方式来在 raw 和增强样本的 logit 预测层次上进行自适应学习，从而更好地提取有限训练数据中的特征特异性知识。实验结果表明，CSDNet 在 Ultra-FGVC 任务上表现出色，证明了其强大的效果和适应性。
</details></li>
</ul>
<hr>
<h2 id="Refining-the-ONCE-Benchmark-with-Hyperparameter-Tuning"><a href="#Refining-the-ONCE-Benchmark-with-Hyperparameter-Tuning" class="headerlink" title="Refining the ONCE Benchmark with Hyperparameter Tuning"></a>Refining the ONCE Benchmark with Hyperparameter Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06054">http://arxiv.org/abs/2311.06054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maksim Golyadkin, Alexander Gambashidze, Ildar Nurgaliev, Ilya Makarov</li>
<li>for: 本研究旨在评估 semi-supervised learning 方法在点云数据上的性能。</li>
<li>methods: 本研究使用 semi-supervised learning 方法，并对点云数据进行自动标注。</li>
<li>results: 研究发现，使用不同的搜索空间和模型可以获得更高的性能，但使用无标注数据的贡献相对较少。<details>
<summary>Abstract</summary>
In response to the growing demand for 3D object detection in applications such as autonomous driving, robotics, and augmented reality, this work focuses on the evaluation of semi-supervised learning approaches for point cloud data. The point cloud representation provides reliable and consistent observations regardless of lighting conditions, thanks to advances in LiDAR sensors. Data annotation is of paramount importance in the context of LiDAR applications, and automating 3D data annotation with semi-supervised methods is a pivotal challenge that promises to reduce the associated workload and facilitate the emergence of cost-effective LiDAR solutions. Nevertheless, the task of semi-supervised learning in the context of unordered point cloud data remains formidable due to the inherent sparsity and incomplete shapes that hinder the generation of accurate pseudo-labels. In this study, we consider these challenges by posing the question: "To what extent does unlabelled data contribute to the enhancement of model performance?" We show that improvements from previous semi-supervised methods may not be as profound as previously thought. Our results suggest that simple grid search hyperparameter tuning applied to a supervised model can lead to state-of-the-art performance on the ONCE dataset, while the contribution of unlabelled data appears to be comparatively less exceptional.
</details>
<details>
<summary>摘要</summary>
“这个研究旨在评估半监督学习方法在3D物体探测应用中的表现，特别是针对基于LiDAR感知器的应用。点云表示提供可靠和一致的观察，不受照明条件影响。在LiDAR应用中，标签数据的标注是非常重要的，但对于半监督学习方法而言，自动化3D标签的自动化过程是一个挑战，可以实现成本下降和LiDAR解决方案的发展。然而，在无序点云数据上进行半监督学习的任务仍然是一个挑战，因为点云数据的缺乏和形状不对称对于生成准确pseudo标签所造成阻碍。在这个研究中，我们询问：“半监督学习中无标的数据对模型性能的贡献为何？”我们发现，与之前的半监督方法相比，改进的空间搜寻参数可以带来更好的性能，而无标的数据对模型性能的贡献相对较少。”
</details></li>
</ul>
<hr>
<h2 id="2D-Image-head-pose-estimation-via-latent-space-regression-under-occlusion-settings"><a href="#2D-Image-head-pose-estimation-via-latent-space-regression-under-occlusion-settings" class="headerlink" title="2D Image head pose estimation via latent space regression under occlusion settings"></a>2D Image head pose estimation via latent space regression under occlusion settings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06038">http://arxiv.org/abs/2311.06038</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sipg-isr/Occlusion_HPE">https://github.com/sipg-isr/Occlusion_HPE</a></li>
<li>paper_authors: José Celestino, Manuel Marques, Jacinto C. Nascimento, João Paulo Costeira</li>
<li>for: 本研究旨在提高 occluded  scenario 下的人头pose 估算精度，提供更可靠的人机交互方案。</li>
<li>methods: 该研究提出了一种基于 latent space regression 的深度学习方法，通过更好地结构化 occluded  scenrio 下的问题，提高 head pose estimation 的精度。</li>
<li>results: 对于 occluded 和 non-occluded  scenrio 下的数据集，该方法比多种 state-of-the-art 方法表现出较高的精度，并且在实际应用中（如人机交互场景）也显示出了良好的性能。<details>
<summary>Abstract</summary>
Head orientation is a challenging Computer Vision problem that has been extensively researched having a wide variety of applications. However, current state-of-the-art systems still underperform in the presence of occlusions and are unreliable for many task applications in such scenarios. This work proposes a novel deep learning approach for the problem of head pose estimation under occlusions. The strategy is based on latent space regression as a fundamental key to better structure the problem for occluded scenarios. Our model surpasses several state-of-the-art methodologies for occluded HPE, and achieves similar accuracy for non-occluded scenarios. We demonstrate the usefulness of the proposed approach with: (i) two synthetically occluded versions of the BIWI and AFLW2000 datasets, (ii) real-life occlusions of the Pandora dataset, and (iii) a real-life application to human-robot interaction scenarios where face occlusions often occur. Specifically, the autonomous feeding from a robotic arm.
</details>
<details>
<summary>摘要</summary>
头部方向是计算机视觉领域中一个具有广泛应用的挑战，已经有广泛的研究。然而，当前状态的先进系统仍然在干扰场景下表现不佳，对多种任务场景表现不可靠。这项工作提出了一种基于深度学习的新方法，用于在干扰场景下进行头部pose估计。这种策略基于latent space regression作为基础，以更好地结构化干扰场景中的问题。我们的模型在干扰场景下超过了多种现有方法，并在非干扰场景下实现了类似的准确率。我们通过以下三种实验来证明提出的方法的有用性：（i）使用BIWI和AFLW2000 datasets中的两个 sintetically occluded版本，（ii）使用Pandora dataset中的真实干扰场景，（iii）在人机交互场景中使用 autonomous feeding from a robotic arm。
</details></li>
</ul>
<hr>
<h2 id="Diagonal-Hierarchical-Consistency-Learning-for-Semi-supervised-Medical-Image-Segmentation"><a href="#Diagonal-Hierarchical-Consistency-Learning-for-Semi-supervised-Medical-Image-Segmentation" class="headerlink" title="Diagonal Hierarchical Consistency Learning for Semi-supervised Medical Image Segmentation"></a>Diagonal Hierarchical Consistency Learning for Semi-supervised Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06031">http://arxiv.org/abs/2311.06031</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heejoon Koo</li>
<li>for: 这篇论文是用于医疗影像分类的，以提高诊断和治疗的精度。</li>
<li>methods: 这篇论文使用了一个新的框架，即DiHC-Net，以提高医疗影像分类的稳定性和准确性。DiHC-Net包含多个子模型，每个子模型有相同的多尺度架构，但每个子模型有不同的子层，如数值升降和Normalization层。此外，这篇论文还提出了一个新的 diagonally hierarchical consistency 的方法，用于在不同尺度上强制这些子模型之间的一致性。</li>
<li>results: 实验结果显示，DiHC-Net 比之前的所有方法在公共 Left Atrium (LA) 数据集上表现更好，具有更高的稳定性和准确性。<details>
<summary>Abstract</summary>
Medical image segmentation, which is essential for many clinical applications, has achieved almost human-level performance via data-driven deep learning techniques. Nevertheless, its performance is predicated on the costly process of manually annotating a large amount of medical images. To this end, we propose a novel framework for robust semi-supervised medical image segmentation using diagonal hierarchical consistency (DiHC-Net). First, it is composed of multiple sub-models with identical multi-scale architecture but with distinct sub-layers, such as up-sampling and normalisation layers. Second, a novel diagonal hierarchical consistency is enforced between one model's intermediate and final prediction and other models' soft pseudo labels in a diagonal hierarchical fashion. Experimental results verify the efficacy of our simple framework, outperforming all previous approaches on public Left Atrium (LA) dataset.
</details>
<details>
<summary>摘要</summary>
医疗图像分割，对许多临床应用而言是必需的，已经通过数据驱动的深度学习技术实现了几乎人类水平的性能。然而，其性能受到手动标注大量医疗图像的高成本过程的限制。为此，我们提出了一种新的框架，即对称层次一致性网络（DiHC-Net）。这个框架包括多个子模型，每个子模型具有相同的多scales架构，但各自具有不同的子层，例如升降sample和normal化层。其次，我们提出了一种新的对称层次一致性，即在一个模型的中间预测和最终预测之间，以及其他模型的软 Pseudo标签之间的对称层次一致性。实验结果表明，我们的简单框架可以准确地 segment 医疗图像，并且超过了所有之前的方法在公共左心脏（LA）数据集上的性能。
</details></li>
</ul>
<hr>
<h2 id="U3DS-3-Unsupervised-3D-Semantic-Scene-Segmentation"><a href="#U3DS-3-Unsupervised-3D-Semantic-Scene-Segmentation" class="headerlink" title="U3DS$^3$: Unsupervised 3D Semantic Scene Segmentation"></a>U3DS$^3$: Unsupervised 3D Semantic Scene Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06018">http://arxiv.org/abs/2311.06018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxu Liu, Zhengdi Yu, Toby P. Breckon, Hubert P. H. Shum</li>
<li>for: 这篇论文主要用于解决3D点云分割问题，即不需要大量标注数据来进行训练。</li>
<li>methods: 该方法基于点云自身的特征信息，无需模型预训练，通过扩展点云的方式生成超点，然后通过空间划分和迭代训练使用 pseudo-标签进行学习。</li>
<li>results: 该方法在ScanNet和SemanticKITTI datasets上达到了状态略的表现，并在S3DIS dataset上获得了竞争性的结果。<details>
<summary>Abstract</summary>
Contemporary point cloud segmentation approaches largely rely on richly annotated 3D training data. However, it is both time-consuming and challenging to obtain consistently accurate annotations for such 3D scene data. Moreover, there is still a lack of investigation into fully unsupervised scene segmentation for point clouds, especially for holistic 3D scenes. This paper presents U3DS$^3$, as a step towards completely unsupervised point cloud segmentation for any holistic 3D scenes. To achieve this, U3DS$^3$ leverages a generalized unsupervised segmentation method for both object and background across both indoor and outdoor static 3D point clouds with no requirement for model pre-training, by leveraging only the inherent information of the point cloud to achieve full 3D scene segmentation. The initial step of our proposed approach involves generating superpoints based on the geometric characteristics of each scene. Subsequently, it undergoes a learning process through a spatial clustering-based methodology, followed by iterative training using pseudo-labels generated in accordance with the cluster centroids. Moreover, by leveraging the invariance and equivariance of the volumetric representations, we apply the geometric transformation on voxelized features to provide two sets of descriptors for robust representation learning. Finally, our evaluation provides state-of-the-art results on the ScanNet and SemanticKITTI, and competitive results on the S3DIS, benchmark datasets.
</details>
<details>
<summary>摘要</summary>
现代点云分割方法大多依赖于 ricly annotated 3D 训练数据。然而，获得一致性的精确标注对于 such 3D 场景数据是时间consuming 和挑战性的。此外，还缺乏对全自动点云分割的完全无监督场景进行研究，特别是 для holistic 3D 场景。本文提出了 U3DS$^3$，这是一种Step towards completely unsupervised point cloud segmentation for any holistic 3D scenes。为实现这一目标，U3DS$^3$ 利用了一种通用无监督分割方法，可以在 both indoor and outdoor static 3D point clouds 中实现全3D场景分割，无需模型预训练。U3DS$^3$ 的首先步骤是生成 superpoints 基于场景的 геометрических特征。然后，它通过空间归一化方法进行学习，然后通过 iterative training 使用 pseudo-labels 根据集中点生成。此外，通过利用点云的几何特征，我们将其映射到 voxelized 特征上，并将其作为 Robust 表示学习的两个集。最后，我们的评估结果表明 U3DS$^3$ 在 ScanNet 和 SemanticKITTI 数据集上获得了状态对的结果，并在 S3DIS 数据集上获得了竞争性的结果。
</details></li>
</ul>
<hr>
<h2 id="Polar-Net-A-Clinical-Friendly-Model-for-Alzheimer’s-Disease-Detection-in-OCTA-Images"><a href="#Polar-Net-A-Clinical-Friendly-Model-for-Alzheimer’s-Disease-Detection-in-OCTA-Images" class="headerlink" title="Polar-Net: A Clinical-Friendly Model for Alzheimer’s Disease Detection in OCTA Images"></a>Polar-Net: A Clinical-Friendly Model for Alzheimer’s Disease Detection in OCTA Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06009">http://arxiv.org/abs/2311.06009</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iAaronLau/Polar-Net-Pytorch">https://github.com/iAaronLau/Polar-Net-Pytorch</a></li>
<li>paper_authors: Shouyue Liu, Jinkui Hao, Yanwu Xu, Huazhu Fu, Xinyu Guo, Jiang Liu, Yalin Zheng, Yonghuai Liu, Jiong Zhang, Yitian Zhao</li>
<li>for: 检测阿尔ツheimer病（AD）的可能性，通过图像征识Retinal microvasculature。</li>
<li>methods: 使用抽象的深度计算机视觉方法，以及Polar-Net模型，将OCTA图像坐标系从Cartesian坐标系映射到极坐标系，并使用ETDRS格子基于地区分析方法。</li>
<li>results: 与现有方法相比，Polar-Net模型在私人和公共数据集上表现出色，并提供更加有价值的病理证据，证明了Retinal microvasculature变化和AD之间的相关性。<details>
<summary>Abstract</summary>
Optical Coherence Tomography Angiography (OCTA) is a promising tool for detecting Alzheimer's disease (AD) by imaging the retinal microvasculature. Ophthalmologists commonly use region-based analysis, such as the ETDRS grid, to study OCTA image biomarkers and understand the correlation with AD. However, existing studies have used general deep computer vision methods, which present challenges in providing interpretable results and leveraging clinical prior knowledge. To address these challenges, we propose a novel deep-learning framework called Polar-Net. Our approach involves mapping OCTA images from Cartesian coordinates to polar coordinates, which allows for the use of approximate sector convolution and enables the implementation of the ETDRS grid-based regional analysis method commonly used in clinical practice. Furthermore, Polar-Net incorporates clinical prior information of each sector region into the training process, which further enhances its performance. Additionally, our framework adapts to acquire the importance of the corresponding retinal region, which helps researchers and clinicians understand the model's decision-making process in detecting AD and assess its conformity to clinical observations. Through evaluations on private and public datasets, we have demonstrated that Polar-Net outperforms existing state-of-the-art methods and provides more valuable pathological evidence for the association between retinal vascular changes and AD. In addition, we also show that the two innovative modules introduced in our framework have a significant impact on improving overall performance.
</details>
<details>
<summary>摘要</summary>
Optical Coherence Tomography Angiography (OCTA) 是一种有前途的工具，用于检测阿尔ツ海默病（AD），通过呈现Retinal Microvasculature的图像。 医生们通常使用区域分析方法，如ETDRS 格，来研究 OCTA 图像标记和了解与 AD 的相关性。然而，现有的研究都使用了通用的深度计算机视觉方法，这会带来解释结果的困难和不能充分利用临床前知识。为解决这些挑战，我们提出了一种新的深度学习框架，即Polar-Net。我们的方法通过将 OCTA 图像从Cartesian坐标系转换到极坐标系，使得可以使用 Approximate Sector Convolution 和实施ETDRS 格基于的区域分析方法，这样可以更好地利用临床前知识。此外，Polar-Net 还将临床前知识 incorporated 到训练过程中，进一步提高其性能。此外，我们的框架还可以评估相应的Retinal 区域的重要性，帮助研究人员和医生理解模型的决策过程中的AD 检测和评估模型是否符合临床观察。经过评估private和公共数据集，我们展示了Polar-Net 可以超过现有的状态对方法，并提供更有价值的病理证据，用于关系Retinal 血管变化和AD的相关性。此外，我们还发现了两个创新模块在我们的框架中具有重要作用，即提高总性能。
</details></li>
</ul>
<hr>
<h2 id="Keystroke-Verification-Challenge-KVC-Biometric-and-Fairness-Benchmark-Evaluation"><a href="#Keystroke-Verification-Challenge-KVC-Biometric-and-Fairness-Benchmark-Evaluation" class="headerlink" title="Keystroke Verification Challenge (KVC): Biometric and Fairness Benchmark Evaluation"></a>Keystroke Verification Challenge (KVC): Biometric and Fairness Benchmark Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06000">http://arxiv.org/abs/2311.06000</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giuseppe Stragapede, Ruben Vera-Rodriguez, Ruben Tolosana, Aythami Morales, Naser Damer, Julian Fierrez, Javier Ortega-Garcia</li>
<li>for: 本研究旨在提高键盘动作生物认证的性能和公正性。</li>
<li>methods: 本研究使用了新的实验框架和公平指标来评估键盘动作生物认证系统的性能和公正性。</li>
<li>results: 研究发现，通过减少键盘动作生物认证系统中文本内容的分析，可以保持atisfactory的性能，同时减少隐私泄露风险。Here’s the translation in Simplified Chinese:</li>
<li>for: 本研究旨在提高键盘动作生物认证的性能和公正性。</li>
<li>methods: 本研究使用了新的实验框架和公平指标来评估键盘动作生物认证系统的性能和公正性。</li>
<li>results: 研究发现，通过减少键盘动作生物认证系统中文本内容的分析，可以保持 satisfactory 的性能，同时减少隐私泄露风险。<details>
<summary>Abstract</summary>
Analyzing keystroke dynamics (KD) for biometric verification has several advantages: it is among the most discriminative behavioral traits; keyboards are among the most common human-computer interfaces, being the primary means for users to enter textual data; its acquisition does not require additional hardware, and its processing is relatively lightweight; and it allows for transparently recognizing subjects. However, the heterogeneity of experimental protocols and metrics, and the limited size of the databases adopted in the literature impede direct comparisons between different systems, thus representing an obstacle in the advancement of keystroke biometrics. To alleviate this aspect, we present a new experimental framework to benchmark KD-based biometric verification performance and fairness based on tweet-long sequences of variable transcript text from over 185,000 subjects, acquired through desktop and mobile keyboards, extracted from the Aalto Keystroke Databases. The framework runs on CodaLab in the form of the Keystroke Verification Challenge (KVC). Moreover, we also introduce a novel fairness metric, the Skewed Impostor Ratio (SIR), to capture inter- and intra-demographic group bias patterns in the verification scores. We demonstrate the usefulness of the proposed framework by employing two state-of-the-art keystroke verification systems, TypeNet and TypeFormer, to compare different sets of input features, achieving a less privacy-invasive system, by discarding the analysis of text content (ASCII codes of the keys pressed) in favor of extended features in the time domain. Our experiments show that this approach allows to maintain satisfactory performance.
</details>
<details>
<summary>摘要</summary>
分析键盘动态（KD） для生物认证有很多优点：它是最有特征的行为特征之一；键盘是人机界面中最常用的输入设备之一，用户通过键盘输入文本数据；获取它不需要额外硬件，处理也较轻量级，可透明地识别用户。然而，实验室协议和度量的多样性，以及文献中所采用的数据库的小型，使得不同系统之间的比较困难，从而阻碍了键盘生物认证的进步。为了解决这一问题，我们提出了一个新的实验框架，用于评估基于键盘动态的生物认证性和公正性，并在 CodaLab 上进行了 Keystroke Verification Challenge（KVC）。此外，我们还介绍了一种新的公正度指标，即不良假冒比率（SIR），用于捕捉 между组和内组偏见偏好的识别分数。我们通过使用两个现有的键盘认证系统，TypeNet 和 TypeFormer，对不同的输入特征进行比较，实现了一种更加隐私的系统，通过抛弃ASCII码的分析以获得更多的时间域特征。我们的实验结果表明，这种方法可以保持满意的性能。
</details></li>
</ul>
<hr>
<h2 id="Vision-Big-Bird-Random-Sparsification-for-Full-Attention"><a href="#Vision-Big-Bird-Random-Sparsification-for-Full-Attention" class="headerlink" title="Vision Big Bird: Random Sparsification for Full Attention"></a>Vision Big Bird: Random Sparsification for Full Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05988">http://arxiv.org/abs/2311.05988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhemin Zhang, Xun Gong</li>
<li>for: 该研究旨在提出一种基于Transformers的视觉模型，以提高视觉任务的性能。</li>
<li>methods: 该模型使用三组头部，其中第一组使用卷积神经网络提取地方特征并提供位置信息，第二组使用随机抽样窗口进行笛卡尔抽样自注意计算，第三组将键值的分辨率减小通过平均抽取来保持全局注意的稀热性。</li>
<li>results: 实验结果表明，视觉大鸟模型可以维持自注意的稀热性，并且可以安全地去除位置编码。该模型在常见视觉任务中达到竞争性性能。<details>
<summary>Abstract</summary>
Recently, Transformers have shown promising performance in various vision tasks. However, the high costs of global self-attention remain challenging for Transformers, especially for high-resolution vision tasks. Inspired by one of the most successful transformers-based models for NLP: Big Bird, we propose a novel sparse attention mechanism for Vision Transformers (ViT). Specifically, we separate the heads into three groups, the first group used convolutional neural network (CNN) to extract local features and provide positional information for the model, the second group used Random Sampling Windows (RS-Win) for sparse self-attention calculation, and the third group reduces the resolution of the keys and values by average pooling for global attention. Based on these components, ViT maintains the sparsity of self-attention while maintaining the merits of Big Bird (i.e., the model is a universal approximator of sequence functions and is Turing complete). Moreover, our results show that the positional encoding, a crucial component in ViTs, can be safely removed in our model. Experiments show that Vision Big Bird demonstrates competitive performance on common vision tasks.
</details>
<details>
<summary>摘要</summary>
近些时间，变换器在各种视觉任务中表现出了扎实的能力。然而，全球自注意的高成本仍然是变换器的挑战，特别是高分辨率视觉任务。受Big Bird模型的启发，我们提出了一种新的稀疏注意机制 для视觉变换器（ViT）。具体来说，我们将头分为三组：第一组使用卷积神经网络（CNN）提取地方特征并提供模型位置信息，第二组使用随机抽取窗口（RS-Win）进行稀疏自注意计算，第三组将键和值的分辨率降低到平均抽取。这些组件使得ViT可以保持自注意的稀疏性，同时保持Big Bird模型的优点（即模型是序列函数的通用近似器和Turing完善的）。此外，我们的实验表明，ViT中的位置编码可以安全地移除。Vision Big Bird在常见视觉任务中显示了竞争力强的性能。
</details></li>
</ul>
<hr>
<h2 id="Comparing-Male-Nyala-and-Male-Kudu-Classification-using-Transfer-Learning-with-ResNet-50-and-VGG-16"><a href="#Comparing-Male-Nyala-and-Male-Kudu-Classification-using-Transfer-Learning-with-ResNet-50-and-VGG-16" class="headerlink" title="Comparing Male Nyala and Male Kudu Classification using Transfer Learning with ResNet-50 and VGG-16"></a>Comparing Male Nyala and Male Kudu Classification using Transfer Learning with ResNet-50 and VGG-16</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05981">http://arxiv.org/abs/2311.05981</a></li>
<li>repo_url: None</li>
<li>paper_authors: T. T Lemani, T. L. van Zyl</li>
<li>for: 这paper的目的是为了研究使用深度学习和计算机视觉技术来快速和高精度地识别野生动物，以便为管理和保护决策提供信息。</li>
<li>methods: 本paper使用了预训练模型VGG-16和ResNet-50，通过转移学习方法进行精度调整，以便在野生环境中识别♂️戴蛭和♂️牛羚。</li>
<li>results:  эксperimental结果显示，在550张图像中，预训练后的VGG-16和ResNet-50模型均达到了97.7%的准确率，而不进行调整的模型则达到了93.2%的准确率。然而，这些结果是基于一个小样本大小的评估，因此可能不具有足够的可靠性和普遍性。<details>
<summary>Abstract</summary>
Reliable and efficient monitoring of wild animals is crucial to inform management and conservation decisions. The process of manually identifying species of animals is time-consuming, monotonous, and expensive. Leveraging on advances in deep learning and computer vision, we investigate in this paper the efficiency of pre-trained models, specifically the VGG-16 and ResNet-50 model, in identifying a male Kudu and a male Nyala in their natural habitats. These pre-trained models have proven to be efficient in animal identification in general. Still, there is little research on animals like the Kudu and Nyala, who are usually well camouflaged and have similar features. The method of transfer learning used in this paper is the fine-tuning method. The models are evaluated before and after fine-tuning. The experimental results achieved an accuracy of 93.2\% and 97.7\% for the VGG-16 and ResNet-50 models, respectively, before fine-tuning and 97.7\% for both models after fine-tuning. Although these results are impressive, it should be noted that they were taken over a small sample size of 550 images split in half between the two classes; therefore, this might not cater to enough scenarios to get a full conclusion of the efficiency of the models. Therefore, there is room for more work in getting a more extensive dataset and testing and extending to the female counterparts of these species and the whole antelope species.
</details>
<details>
<summary>摘要</summary>
可靠和高效的野生动物监测是管理和保护决策的关键。手动识别动物种类是时间consuming、单调和昂贵的。利用深度学习和计算机视觉的进步，我们在这篇论文中 investigate了VGG-16和ResNet-50模型在自然环境中识别♂️普通鹿和♂️涂猪的能力。这些预训练模型在动物识别方面有效。然而，关于鹿和涂猪这些动物，它们通常很隐藏，外表相似，有少量研究。本文使用的方法是转移学习方法。模型在 Fine-tuning 前和后的评估结果表明，VGG-16和ResNet-50模型在自然环境中识别♂️普通鹿和♂️涂猪的能力具有93.2%和97.7%的准确率，分别是之前和之后 Fine-tuning。虽然这些结果很出色，但是它们是基于550张图像，其中有一半是♂️普通鹿和♂️涂猪两类的样本，因此这并不能代表充分的场景，因此还有很多空间 для进一步的测试和扩展。
</details></li>
</ul>
<hr>
<h2 id="Quantized-Distillation-Optimizing-Driver-Activity-Recognition-Models-for-Resource-Constrained-Environments"><a href="#Quantized-Distillation-Optimizing-Driver-Activity-Recognition-Models-for-Resource-Constrained-Environments" class="headerlink" title="Quantized Distillation: Optimizing Driver Activity Recognition Models for Resource-Constrained Environments"></a>Quantized Distillation: Optimizing Driver Activity Recognition Models for Resource-Constrained Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05970">http://arxiv.org/abs/2311.05970</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/calvintanama/qd-driver-activity-reco">https://github.com/calvintanama/qd-driver-activity-reco</a></li>
<li>paper_authors: Calvin Tanama, Kunyu Peng, Zdravko Marinov, Rainer Stiefelhagen, Alina Roitberg</li>
<li>for: 这篇论文旨在提出轻量级的驾驶活动识别框架，以提高自驾车时的资源效率。</li>
<li>methods: 这篇论文使用了知识传授和模型量化来将3D MobileNet简化，以保持模型精度而实现资源效率。</li>
<li>results: 实验结果显示，这个新的框架可以与已有的框架相比，三倍减少模型大小，并提高执行速度1.4倍。<details>
<summary>Abstract</summary>
Deep learning-based models are at the forefront of most driver observation benchmarks due to their remarkable accuracies but are also associated with high computational costs. This is challenging, as resources are often limited in real-world driving scenarios. This paper introduces a lightweight framework for resource-efficient driver activity recognition. The framework enhances 3D MobileNet, a neural architecture optimized for speed in video classification, by incorporating knowledge distillation and model quantization to balance model accuracy and computational efficiency. Knowledge distillation helps maintain accuracy while reducing the model size by leveraging soft labels from a larger teacher model (I3D), instead of relying solely on original ground truth data. Model quantization significantly lowers memory and computation demands by using lower precision integers for model weights and activations. Extensive testing on a public dataset for in-vehicle monitoring during autonomous driving demonstrates that this new framework achieves a threefold reduction in model size and a 1.4-fold improvement in inference time, compared to an already optimized architecture. The code for this study is available at https://github.com/calvintanama/qd-driver-activity-reco.
</details>
<details>
<summary>摘要</summary>
深度学习模型在驾驶员观察benchmark中领先，主要是因为它们的准确率非常高，但是也因为计算成本很高。这会在实际驾驶场景中带来挑战，因为资源经常是有限的。这篇论文介绍了一个轻量级框架，用于提高驾驶员活动识别的资源效率。这个框架基于3D MobileNet neural网络，通过知识传授和模型量化来平衡模型准确率和计算效率。知识传授可以使得模型尺寸减小，而不会影响准确率，而模型量化可以减少内存和计算需求。经过对一个公共数据集进行了广泛的测试，表明这个新的框架可以将模型尺寸减少三分之一，并提高推理时间1.4倍，相比之前优化的架构。代码可以在https://github.com/calvintanama/qd-driver-activity-reco中下载。
</details></li>
</ul>
<hr>
<h2 id="A-Neural-Height-Map-Approach-for-the-Binocular-Photometric-Stereo-Problem"><a href="#A-Neural-Height-Map-Approach-for-the-Binocular-Photometric-Stereo-Problem" class="headerlink" title="A Neural Height-Map Approach for the Binocular Photometric Stereo Problem"></a>A Neural Height-Map Approach for the Binocular Photometric Stereo Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05958">http://arxiv.org/abs/2311.05958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fotios Logothetis, Ignas Budvytis, Roberto Cipolla</li>
<li>for: 本文提出了一种新的、实用的双目光学深度测试（PS）框架，它的获取速度与单视PS相同，但是可以显著提高估算结果的geometry质量。</li>
<li>methods: 本文使用了深度学习来拟合表面和文本UREpresentation，通过最小化表面法向量偏差来实现形状估算。</li>
<li>results: 本文在DiLiGenT-MV数据集和LUCES-ST数据集上达到了状态对抗性表现，并且在binocular PS setup中实现了同样的获取速度和优化表达。<details>
<summary>Abstract</summary>
In this work we propose a novel, highly practical, binocular photometric stereo (PS) framework, which has same acquisition speed as single view PS, however significantly improves the quality of the estimated geometry.   As in recent neural multi-view shape estimation frameworks such as NeRF, SIREN and inverse graphics approaches to multi-view photometric stereo (e.g. PS-NeRF) we formulate shape estimation task as learning of a differentiable surface and texture representation by minimising surface normal discrepancy for normals estimated from multiple varying light images for two views as well as discrepancy between rendered surface intensity and observed images. Our method differs from typical multi-view shape estimation approaches in two key ways. First, our surface is represented not as a volume but as a neural heightmap where heights of points on a surface are computed by a deep neural network. Second, instead of predicting an average intensity as PS-NeRF or introducing lambertian material assumptions as Guo et al., we use a learnt BRDF and perform near-field per point intensity rendering.   Our method achieves the state-of-the-art performance on the DiLiGenT-MV dataset adapted to binocular stereo setup as well as a new binocular photometric stereo dataset - LUCES-ST.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的、高度实用的双目光学三角形（PS）框架，其具有与单视PS相同的获取速度，但可以显著提高估计几何的质量。我们的方法与现代神经网络多视图形态估计框架（如NeRF、SIREN和反射图像推导法）类似，将形态估计任务定义为通过最小化多个变化光图像中的法向缺失来学习可导表面和 текстура表示。我们的方法与传统多视图形态估计方法有两点不同：首先，我们的表面不是一个体积，而是一个深度神经网络中的高度图像；其次，我们不是预测平均Intensity，而是使用学习的BRDF进行靠近场near-field render。我们的方法在DiLiGenT-MV数据集中适配了双目掌控设置以及一个新的双目光学三角形数据集——LUCES-ST中达到了状态盘的性能。
</details></li>
</ul>
<hr>
<h2 id="Post-training-Quantization-with-Progressive-Calibration-and-Activation-Relaxing-for-Text-to-Image-Diffusion-Models"><a href="#Post-training-Quantization-with-Progressive-Calibration-and-Activation-Relaxing-for-Text-to-Image-Diffusion-Models" class="headerlink" title="Post-training Quantization with Progressive Calibration and Activation Relaxing for Text-to-Image Diffusion Models"></a>Post-training Quantization with Progressive Calibration and Activation Relaxing for Text-to-Image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.06322">http://arxiv.org/abs/2311.06322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siao Tang, Xin Wang, Hong Chen, Chaoyu Guan, Zewen Wu, Yansong Tang, Wenwu Zhu<br>for:This paper focuses on developing a novel post-training quantization method for text-to-image diffusion models, specifically targeting widely used large pretrained models like Stable Diffusion and Stable Diffusion XL.methods:The proposed method, called PCR (Progressive Calibration and Relaxing), consists of two key strategies: progressive calibration and activation relaxing. The former considers the accumulated quantization error across timesteps, while the latter improves performance with negligible cost.results:The proposed method and a new benchmark (QDiffBench) are extensively evaluated on Stable Diffusion and Stable Diffusion XL. The results show that the proposed method achieves superior performance and is the first to achieve quantization for Stable Diffusion XL while maintaining performance. Additionally, QDiffBench provides a more accurate evaluation of text-to-image diffusion model quantization by considering the distribution gap and generalization performance outside the calibration dataset.<details>
<summary>Abstract</summary>
Diffusion models have achieved great success due to their remarkable generation ability. However, their high computational overhead is still a troublesome problem. Recent studies have leveraged post-training quantization (PTQ) to compress diffusion models. However, most of them only focus on unconditional models, leaving the quantization of widely used large pretrained text-to-image models, e.g., Stable Diffusion, largely unexplored. In this paper, we propose a novel post-training quantization method PCR (Progressive Calibration and Relaxing) for text-to-image diffusion models, which consists of a progressive calibration strategy that considers the accumulated quantization error across timesteps, and an activation relaxing strategy that improves the performance with negligible cost. Additionally, we demonstrate the previous metrics for text-to-image diffusion model quantization are not accurate due to the distribution gap. To tackle the problem, we propose a novel QDiffBench benchmark, which utilizes data in the same domain for more accurate evaluation. Besides, QDiffBench also considers the generalization performance of the quantized model outside the calibration dataset. Extensive experiments on Stable Diffusion and Stable Diffusion XL demonstrate the superiority of our method and benchmark. Moreover, we are the first to achieve quantization for Stable Diffusion XL while maintaining the performance.
</details>
<details>
<summary>摘要</summary>
Diffusion 模型在生成能力方面已经取得了很大的成功，但是它们的计算开销仍然是一个痛苦的问题。latest studies have leveraged post-training quantization (PTQ) to compress diffusion models, but most of them only focus on unconditional models, leaving the quantization of widely used large pretrained text-to-image models, such as Stable Diffusion, largely unexplored. In this paper, we propose a novel post-training quantization method PCR (Progressive Calibration and Relaxing) for text-to-image diffusion models, which consists of a progressive calibration strategy that considers the accumulated quantization error across timesteps, and an activation relaxing strategy that improves the performance with negligible cost. Additionally, we demonstrate that the previous metrics for text-to-image diffusion model quantization are not accurate due to the distribution gap. To tackle this problem, we propose a novel QDiffBench benchmark, which utilizes data in the same domain for more accurate evaluation. Besides, QDiffBench also considers the generalization performance of the quantized model outside the calibration dataset. Extensive experiments on Stable Diffusion and Stable Diffusion XL demonstrate the superiority of our method and benchmark. Moreover, we are the first to achieve quantization for Stable Diffusion XL while maintaining the performance.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Segmentation-with-Texture-in-Ore-Images-Based-on-Box-supervised-Approach"><a href="#Efficient-Segmentation-with-Texture-in-Ore-Images-Based-on-Box-supervised-Approach" class="headerlink" title="Efficient Segmentation with Texture in Ore Images Based on Box-supervised Approach"></a>Efficient Segmentation with Texture in Ore Images Based on Box-supervised Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05929">http://arxiv.org/abs/2311.05929</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mvme-hbut/oreinst">https://github.com/mvme-hbut/oreinst</a></li>
<li>paper_authors: Guodong Sun, Delong Huang, Yuting Peng, Le Cheng, Bo Wu, Yang Zhang</li>
<li>For: The paper is written for image segmentation of crushed ores in a complex working environment, where high-powered computing equipment is difficult to deploy, and the ore distribution is stacked, making it challenging to identify complete features.* Methods: The proposed method uses a ghost feature pyramid network (Ghost-FPN) to process features obtained from the backbone, an optimized detection head to obtain accurate features, and a fusion feature similarity-based loss function that combines Lab color space (Lab) and local binary patterns (LBP) texture features to improve accuracy while incurring no loss.* Results: The proposed method achieves over 50 frames per second with a small model size of 21.6 MB, and maintains a high level of accuracy compared with state-of-the-art approaches on ore image datasets.Here is the information in Simplified Chinese text:* For: 该文章是为了处理受损矿石的图像分割，在复杂的工作环境下，高性能计算设备困难执行，矿石分布叠加，难以识别完整的特征。* 方法: 提出了一种使用 Ghost Feature Pyramid Network (Ghost-FPN) 处理从底层获得的特征，优化检测头以获得准确的特征，并将 Lab 色彩空间 (Lab) 和本地二进制模式 (LBP) 文本特征组合成一个 fusional 特征相似性基于损失函数，以提高准确性而不产生损失。* 结果: 提出的方法可以在 MS COCO 上达到更高于 50 帧&#x2F;秒的速度，并且在矿石图像数据集上保持高级别的准确性，而且与当前状态艺术方法相比，模型大小只有 21.6 MB。源代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/MVME-HBUT/OREINST%7D">https://github.com/MVME-HBUT/OREINST}</a> 上获取。<details>
<summary>Abstract</summary>
Image segmentation methods have been utilized to determine the particle size distribution of crushed ores. Due to the complex working environment, high-powered computing equipment is difficult to deploy. At the same time, the ore distribution is stacked, and it is difficult to identify the complete features. To address this issue, an effective box-supervised technique with texture features is provided for ore image segmentation that can identify complete and independent ores. Firstly, a ghost feature pyramid network (Ghost-FPN) is proposed to process the features obtained from the backbone to reduce redundant semantic information and computation generated by complex networks. Then, an optimized detection head is proposed to obtain the feature to maintain accuracy. Finally, Lab color space (Lab) and local binary patterns (LBP) texture features are combined to form a fusion feature similarity-based loss function to improve accuracy while incurring no loss. Experiments on MS COCO have shown that the proposed fusion features are also worth studying on other types of datasets. Extensive experimental results demonstrate the effectiveness of the proposed method, which achieves over 50 frames per second with a small model size of 21.6 MB. Meanwhile, the method maintains a high level of accuracy compared with the state-of-the-art approaches on ore image dataset. The source code is available at \url{https://github.com/MVME-HBUT/OREINST}.
</details>
<details>
<summary>摘要</summary>
Image segmentation方法已经在粉碎矿物中使用来确定粉碎物的大小分布。由于工作环境复杂，高功率计算设备困难提供。同时，矿物分布叠加，难以识别完整的特征。为解决这个问题，一种有效的盒子-监督法（Box-supervised）是提供了用于矿物图像分割的方法，可以识别完整独立的矿物。首先，一种鬼Feature pyramid网络（Ghost-FPN）是提出来处理来自后处理网络的特征，以减少复杂网络生成的重复semantic信息和计算。然后，一种优化的检测头是提出来，以获得维持准确性的特征。最后，Lab色彩空间（Lab）和本地二进制模式（LBP）的xture特征被组合以形成一个混合特征相似度基于的损失函数，以提高准确性而不损失一切。在MS COCO上进行了实验，表明提出的混合特征也值得进行其他类型的数据集上的研究。广泛的实验结果表明提出的方法的有效性，可以在20 frames/s的小型模型大小为21.6 MB下达到50 frames/s的性能水平，同时保持与当前最佳方法在矿物图像 dataset 的高级别准确性。源代码可以在 \url{https://github.com/MVME-HBUT/OREINST} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Automated-Sperm-Assessment-Framework-and-Neural-Network-Specialized-for-Sperm-Video-Recognition"><a href="#Automated-Sperm-Assessment-Framework-and-Neural-Network-Specialized-for-Sperm-Video-Recognition" class="headerlink" title="Automated Sperm Assessment Framework and Neural Network Specialized for Sperm Video Recognition"></a>Automated Sperm Assessment Framework and Neural Network Specialized for Sperm Video Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05927">http://arxiv.org/abs/2311.05927</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ftkr12/rostfine">https://github.com/ftkr12/rostfine</a></li>
<li>paper_authors: Takuro Fujii, Hayato Nakagawa, Teppei Takeshima, Yasushi Yumura, Tomoki Hamagami</li>
<li>for: 本研究旨在提高受孕助手技术的成功率，通过对精子评估使用深度学习方法进行改进。</li>
<li>methods: 本研究使用了视频数据集，其中包括精子头、 neck 和 tail 的视频，并使用了软标签来标注数据。提出了基于视频认识的精子评估框架和 neural network 模型 RoSTFine。</li>
<li>results: 实验结果表明，RoSTFine 可以提高精子评估性能，并强调重要的精子部分（即头和 neck）。<details>
<summary>Abstract</summary>
Infertility is a global health problem, and an increasing number of couples are seeking medical assistance to achieve reproduction, at least half of which are caused by men. The success rate of assisted reproductive technologies depends on sperm assessment, in which experts determine whether sperm can be used for reproduction based on morphology and motility of sperm. Previous sperm assessment studies with deep learning have used datasets comprising images that include only sperm heads, which cannot consider motility and other morphologies of sperm. Furthermore, the labels of the dataset are one-hot, which provides insufficient support for experts, because assessment results are inconsistent between experts, and they have no absolute answer. Therefore, we constructed the video dataset for sperm assessment whose videos include sperm head as well as neck and tail, and its labels were annotated with soft-label. Furthermore, we proposed the sperm assessment framework and the neural network, RoSTFine, for sperm video recognition. Experimental results showed that RoSTFine could improve the sperm assessment performances compared to existing video recognition models and focus strongly on important sperm parts (i.e., head and neck).
</details>
<details>
<summary>摘要</summary>
世界各地有增加的 couples 为了成婚而寻求医疗帮助，至少有一半是由男方引起的不孕。协助生殖技术的成功率取决于精子评估，专家们通过精子形态和运动能力来决定精子是否适用于生殖。之前的精子评估研究使用深度学习都使用了只包含精子头部的图像集合，这无法考虑精子的运动和其他形态。此外，数据集的标签都是一元化的，这不足以支持专家，因为评估结果存在差异 между 专家，并没有绝对的答案。因此，我们建立了包含精子头部、脖子和尾部的视频数据集，并使用了软标签来标注数据集。此外，我们提出了精子评估框架和基于视频的神经网络模型 RoSTFine，用于精子视频识别。实验结果表明，RoSTFine 可以提高精子评估性能，并强调精子重要部分（即头和脖子）。
</details></li>
</ul>
<hr>
<h2 id="Inter-object-Discriminative-Graph-Modeling-for-Indoor-Scene-Recognition"><a href="#Inter-object-Discriminative-Graph-Modeling-for-Indoor-Scene-Recognition" class="headerlink" title="Inter-object Discriminative Graph Modeling for Indoor Scene Recognition"></a>Inter-object Discriminative Graph Modeling for Indoor Scene Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05919">http://arxiv.org/abs/2311.05919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuanxin Song, Hanbo Wu, Xin Ma<br>for: This paper focuses on improving indoor scene recognition by leveraging object information within scenes to enhance feature representations.methods: The proposed approach uses a probabilistic perspective to capture object-scene discriminative relationships, which are then transformed into an Inter-Object Discriminative Prototype (IODP). The Discriminative Graph Network (DGN) is constructed to incorporate inter-object discriminative knowledge into the image representation through graph convolution.results: The proposed approach achieves state-of-the-art results on several widely used scene datasets, demonstrating the effectiveness of the proposed approach.<details>
<summary>Abstract</summary>
Variable scene layouts and coexisting objects across scenes make indoor scene recognition still a challenging task. Leveraging object information within scenes to enhance the distinguishability of feature representations has emerged as a key approach in this domain. Currently, most object-assisted methods use a separate branch to process object information, combining object and scene features heuristically. However, few of them pay attention to interpretably handle the hidden discriminative knowledge within object information. In this paper, we propose to leverage discriminative object knowledge to enhance scene feature representations. Initially, we capture the object-scene discriminative relationships from a probabilistic perspective, which are transformed into an Inter-Object Discriminative Prototype (IODP). Given the abundant prior knowledge from IODP, we subsequently construct a Discriminative Graph Network (DGN), in which pixel-level scene features are defined as nodes and the discriminative relationships between node features are encoded as edges. DGN aims to incorporate inter-object discriminative knowledge into the image representation through graph convolution. With the proposed IODP and DGN, we obtain state-of-the-art results on several widely used scene datasets, demonstrating the effectiveness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
<<SYS>>变量场景布局和场景中的对象共存，indoor场景认知仍然是一项挑战性任务。利用场景中对象信息来增强特征表示的方法已经成为indoor场景认知领域的关键方法。现有大多数对象协助方法使用分立支线处理对象信息，混合对象和场景特征的方式。然而，其中很少听从解释地处理隐藏的推理知识。在本文中，我们提议利用隐藏的推理知识来增强场景特征表示。首先，我们从概率角度捕捉对象-场景推理关系，并将其转化为间对象推理原型（IODP）。在IODP的丰富先验知识基础上，我们随后建立一个推理图网络（DGN），其中像素级场景特征被定义为节点，图中的节点间的推理关系被编码为边。DGN的目标是通过图 convolution来将间对象推理知识integrated到图像表示中。与我们提议的IODP和DGN，我们在多个常用的场景数据集上获得了state-of-the-art的结果，证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Map-Guided-Synthesis-of-Wireless-Capsule-Endoscopy-Images-using-Diffusion-Models"><a href="#Semantic-Map-Guided-Synthesis-of-Wireless-Capsule-Endoscopy-Images-using-Diffusion-Models" class="headerlink" title="Semantic Map Guided Synthesis of Wireless Capsule Endoscopy Images using Diffusion Models"></a>Semantic Map Guided Synthesis of Wireless Capsule Endoscopy Images using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05889">http://arxiv.org/abs/2311.05889</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haejin Lee, Jeongwoo Ju, Jonghyuck Lee, Yeoun Joo Lee, Heechul Jung</li>
<li>for: 该研究旨在提高无线填充内scopic检查（WCE）结果的解释效率，并提供更多和更多样式的WCE图像，以便更好地诊断肠道疾病。</li>
<li>methods: 该研究使用生成模型，具体来说是分散模型（DM），生成多样化的WCE图像。该模型还利用视觉化缩放引擎（VS）生成的semantic map，以提高生成图像的控制性和多样性。</li>
<li>results: 该研究通过视觉检查和视觉图灵测试，证明了该方法的效果，可以生成真实和多样化的WCE图像。<details>
<summary>Abstract</summary>
Wireless capsule endoscopy (WCE) is a non-invasive method for visualizing the gastrointestinal (GI) tract, crucial for diagnosing GI tract diseases. However, interpreting WCE results can be time-consuming and tiring. Existing studies have employed deep neural networks (DNNs) for automatic GI tract lesion detection, but acquiring sufficient training examples, particularly due to privacy concerns, remains a challenge. Public WCE databases lack diversity and quantity. To address this, we propose a novel approach leveraging generative models, specifically the diffusion model (DM), for generating diverse WCE images. Our model incorporates semantic map resulted from visualization scale (VS) engine, enhancing the controllability and diversity of generated images. We evaluate our approach using visual inspection and visual Turing tests, demonstrating its effectiveness in generating realistic and diverse WCE images.
</details>
<details>
<summary>摘要</summary>
无线胶囊内视镜（WCE）是一种非侵入性的方法，用于观察肠道系统，对肠道疾病的诊断非常重要。然而，解读WCE结果可以是时间consuming和疲劳的。现有的研究已经使用深度神经网络（DNNs）自动检测肠道病变，但获得充分的训练样本，特别是由于隐私问题，仍然是一个挑战。公共WCE数据库缺乏多样性和数量。为解决这个问题，我们提出了一种新的方法，利用生成模型（DM）生成多样的WCE图像。我们的模型具有视觉化缩放引擎（VS）生成的semantic map，从而提高生成图像的可控性和多样性。我们通过视觉检查和视觉图灵测试评估了我们的方法，并证明其效果在生成真实和多样的WCE图像。
</details></li>
</ul>
<hr>
<h2 id="Central-Angle-Optimization-for-360-degree-Holographic-3D-Content"><a href="#Central-Angle-Optimization-for-360-degree-Holographic-3D-Content" class="headerlink" title="Central Angle Optimization for 360-degree Holographic 3D Content"></a>Central Angle Optimization for 360-degree Holographic 3D Content</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05878">http://arxiv.org/abs/2311.05878</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hakdong Kim, Minsung Yoon, Cheongwon Kim</li>
<li>for: 这个论文是为了提出一种用于深度学习基于深度地图估计来生成真实的投影内容的方法。</li>
<li>methods: 该方法使用了对邻近摄像头视角点的中心角值进行分析，以选择最佳的中心角，以生成高质量的投影内容。</li>
<li>results: 经验表明，选择最佳中心角可以提高投影内容的质量。<details>
<summary>Abstract</summary>
In this study, we propose a method to find an optimal central angle in deep learning-based depth map estimation used to produce realistic holographic content. The acquisition of RGB-depth map images as detailed as possible must be performed to generate holograms of high quality, despite the high computational cost. Therefore, we introduce a novel pipeline designed to analyze various values of central angles between adjacent camera viewpoints equidistant from the origin of an object-centered environment. Then we propose the optimal central angle to generate high-quality holographic content. The proposed pipeline comprises key steps such as comparing estimated depth maps and comparing reconstructed CGHs (Computer-Generated Holograms) from RGB images and estimated depth maps. We experimentally demonstrate and discuss the relationship between the central angle and the quality of digital holographic content.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提出了一种方法来找出深度学习基于深度地图估计的优化中心角，以生成真实的投射内容。为了生成高质量的投射，需要获取RGB-深度地图图像，这些图像需要尽可能详细，但计算成本高。因此，我们提出了一个新的管道，用于分析不同中心角之间的RGB-深度地图图像。然后，我们提出了优化中心角，以生成高质量的投射内容。该管道包括以下关键步骤：对RGB图像和估计的深度地图进行比较，并对计算机生成的投射（CGH）和估计的深度地图进行比较。我们在实验中证明并讨论了中心角与数字投射内容质量之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Automated-Heterogeneous-Low-Bit-Quantization-of-Multi-Model-Deep-Learning-Inference-Pipeline"><a href="#Automated-Heterogeneous-Low-Bit-Quantization-of-Multi-Model-Deep-Learning-Inference-Pipeline" class="headerlink" title="Automated Heterogeneous Low-Bit Quantization of Multi-Model Deep Learning Inference Pipeline"></a>Automated Heterogeneous Low-Bit Quantization of Multi-Model Deep Learning Inference Pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05870">http://arxiv.org/abs/2311.05870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jayeeta Mondal, Swarnava Dey, Arijit Mukherjee</li>
<li>for: 这个论文是为了提出一种自动化多层神经网络（多个DNN）的量化方法，以便在边缘部署中实现精度-延迟平衡。</li>
<li>methods: 该论文使用了多种深度学习（DL）推理管线，包括多任务学习（MTL）和集成学习（EL）等，以提高模型的准确率。</li>
<li>results: 该论文通过自动化量化方法，实现了多个DNNs的精度-延迟平衡，并且提高了边缘部署中的模型性能。<details>
<summary>Abstract</summary>
Multiple Deep Neural Networks (DNNs) integrated into single Deep Learning (DL) inference pipelines e.g. Multi-Task Learning (MTL) or Ensemble Learning (EL), etc., albeit very accurate, pose challenges for edge deployment. In these systems, models vary in their quantization tolerance and resource demands, requiring meticulous tuning for accuracy-latency balance. This paper introduces an automated heterogeneous quantization approach for DL inference pipelines with multiple DNNs.
</details>
<details>
<summary>摘要</summary>
多层神经网络（DNN）组合在单个深度学习（DL）推理管道中，例如多任务学习（MTL）或集成学习（EL）等，虽然非常准确，但对边缘部署带来挑战。这些系统中的模型异常量化忍耐和资源需求，需要精确地调整以实现准确率和延迟之间的平衡。本文介绍了一种自动化多类量化方法 для DL推理管道中的多个DNN。
</details></li>
</ul>
<hr>
<h2 id="Watermarking-Vision-Language-Pre-trained-Models-for-Multi-modal-Embedding-as-a-Service"><a href="#Watermarking-Vision-Language-Pre-trained-Models-for-Multi-modal-Embedding-as-a-Service" class="headerlink" title="Watermarking Vision-Language Pre-trained Models for Multi-modal Embedding as a Service"></a>Watermarking Vision-Language Pre-trained Models for Multi-modal Embedding as a Service</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05863">http://arxiv.org/abs/2311.05863</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Pter61/vlpmarker">https://github.com/Pter61/vlpmarker</a></li>
<li>paper_authors: Yuanmin Tang, Jing Yu, Keke Gai, Xiangyan Qu, Yue Hu, Gang Xiong, Qi Wu<br>for: 这个研究是为了提供一个安全和可靠的版权标识方法来防止模型EXTRACTION攻击，以保护运算在多媒体Embedding as a Service（EaaS）上的知识产权和商业所有权。methods: 本研究使用了附加 trigger 的方法来将版权标识Inserted into VLPs，并通过嵌入式扩展Transformation来实现高质量的版权验证和最小化模型性能影响。此外，我们还提出了一种协力Copyright验证策略，通过融合 triggers和嵌入分布来增强标识的可靠性，抵抗不同的攻击。results: 我们的实验结果显示，提出的版权标识方法是有效和安全的，可以在不同的数据集上验证VLPs的版权，并对于模型EXTRACTION攻击进行防护。此外，我们还提出了一种可行的Out-of-distribution trigger选择方法，使得版权标识可以在实际世界中进行实现。<details>
<summary>Abstract</summary>
Recent advances in vision-language pre-trained models (VLPs) have significantly increased visual understanding and cross-modal analysis capabilities. Companies have emerged to provide multi-modal Embedding as a Service (EaaS) based on VLPs (e.g., CLIP-based VLPs), which cost a large amount of training data and resources for high-performance service. However, existing studies indicate that EaaS is vulnerable to model extraction attacks that induce great loss for the owners of VLPs. Protecting the intellectual property and commercial ownership of VLPs is increasingly crucial yet challenging. A major solution of watermarking model for EaaS implants a backdoor in the model by inserting verifiable trigger embeddings into texts, but it is only applicable for large language models and is unrealistic due to data and model privacy. In this paper, we propose a safe and robust backdoor-based embedding watermarking method for VLPs called VLPMarker. VLPMarker utilizes embedding orthogonal transformation to effectively inject triggers into the VLPs without interfering with the model parameters, which achieves high-quality copyright verification and minimal impact on model performance. To enhance the watermark robustness, we further propose a collaborative copyright verification strategy based on both backdoor trigger and embedding distribution, enhancing resilience against various attacks. We increase the watermark practicality via an out-of-distribution trigger selection approach, removing access to the model training data and thus making it possible for many real-world scenarios. Our extensive experiments on various datasets indicate that the proposed watermarking approach is effective and safe for verifying the copyright of VLPs for multi-modal EaaS and robust against model extraction attacks. Our code is available at https://github.com/Pter61/vlpmarker.
</details>
<details>
<summary>摘要</summary>
近期，视觉语言预训模型（VLP）的进步已经提高了视觉理解和跨模态分析的能力。企业出现了基于VLP的多Modal Embedding as a Service（EaaS），但是这需要大量的训练数据和资源来提供高性能服务。然而，现有研究表明，EaaS受到模型抽取攻击，这会导致VLP的所有者受到很大的损失。保护VLP的知识产权和商业所有权是一项 increasinly 杰出的任务，但是它具有挑战。在这篇论文中，我们提出了一种安全和可靠的VLP embedding水印方法，称为VLPMarker。VLPMarker利用Embedding ortogonal transformation来有效地插入触发器到VLP中，而不会对模型参数产生影响，从而实现高质量的版权验证和最小的影响。为增强水印鲜度，我们进一步提出了基于触发器和embedding分布的共同版权验证策略，提高了对各种攻击的抗性。此外，我们还提出了一种基于非典型触发器的选择方法，使得水印更加实用。我们的实验表明，提议的水印方法是安全和可靠的，可以用于验证VLP的版权在多Modal EaaS中。我们的代码可以在https://github.com/Pter61/vlpmarker上下载。
</details></li>
</ul>
<hr>
<h2 id="Domain-Generalization-by-Learning-from-Privileged-Medical-Imaging-Information"><a href="#Domain-Generalization-by-Learning-from-Privileged-Medical-Imaging-Information" class="headerlink" title="Domain Generalization by Learning from Privileged Medical Imaging Information"></a>Domain Generalization by Learning from Privileged Medical Imaging Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05861">http://arxiv.org/abs/2311.05861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Steven Korevaar, Ruwan Tennakoon, Ricky O’Brien, Dwarikanath Mahapatra, Alireza Bab-Hadiasha</li>
<li>for: 这种研究旨在提高医疗图像分类模型对数据分布变化的适应能力。</li>
<li>methods: 作者提出了一种新的方法，即利用特权信息（如肿体形态或位置）来强化领域泛化能力。</li>
<li>results: 研究表明，使用特权信息可以提高医疗图像分类模型对outsider数据的分类精度，从0.911提高到0.934。<details>
<summary>Abstract</summary>
Learning the ability to generalize knowledge between similar contexts is particularly important in medical imaging as data distributions can shift substantially from one hospital to another, or even from one machine to another. To strengthen generalization, most state-of-the-art techniques inject knowledge of the data distribution shifts by enforcing constraints on learned features or regularizing parameters. We offer an alternative approach: Learning from Privileged Medical Imaging Information (LPMII). We show that using some privileged information such as tumor shape or location leads to stronger domain generalization ability than current state-of-the-art techniques. This paper demonstrates that by using privileged information to predict the severity of intra-layer retinal fluid in optical coherence tomography scans, the classification accuracy of a deep learning model operating on out-of-distribution data improves from $0.911$ to $0.934$. This paper provides a strong starting point for using privileged information in other medical problems requiring generalization.
</details>
<details>
<summary>摘要</summary>
学习在类似上下文中总结知识的能力对医疗成像非常重要，因为数据分布可能在不同医院或机器之间差异很大。为强化总结，大多数当前领先技术会在学习特征或参数上强制加入数据分布偏移的约束。我们提出了一种不同的方法：使用特权医疗成像信息学习（LPMII）。我们表明，使用特权信息，如肿瘤形态或位置，可以增强领域总结能力，比现有领先技术更高。这篇论文展示了，通过使用特权信息预测optical coherence tomography扫描中内层血液的严重程度，深度学习模型在不同数据上的分类精度从0.911提高到0.934。这篇论文提供了使用特权信息在医疗问题中的强大起点。
</details></li>
</ul>
<hr>
<h2 id="Layer-wise-Auto-Weighting-for-Non-Stationary-Test-Time-Adaptation"><a href="#Layer-wise-Auto-Weighting-for-Non-Stationary-Test-Time-Adaptation" class="headerlink" title="Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation"></a>Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05858">http://arxiv.org/abs/2311.05858</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junia3/LayerwiseTTA">https://github.com/junia3/LayerwiseTTA</a></li>
<li>paper_authors: Junyoung Park, Jin Kim, Hyeongjun Kwon, Ilhoon Yoon, Kwanghoon Sohn</li>
<li>for: 这篇论文主要关注于在实际应用中进行模型更新和适应，并且面临不断变化的目标分布问题。</li>
<li>methods: 本文提出了一个层别自动调整算法，通过利用渔业信息矩阵（FIM）设计学习重量，以选择相关于对数据量变化的层而忽略不相关的层。此外，本文还提出了一个对数矩阵对应的幂函数减少器，以使certain层几乎冻结，以减少忘记和错误累累。</li>
<li>results: 实验结果显示，本文的方法比传统的连续和慢速更新方法更好，同时可以很大程度地降低计算负载，强调了FIM-based learning weight在适应持续变化的目标分布方面的重要性。<details>
<summary>Abstract</summary>
Given the inevitability of domain shifts during inference in real-world applications, test-time adaptation (TTA) is essential for model adaptation after deployment. However, the real-world scenario of continuously changing target distributions presents challenges including catastrophic forgetting and error accumulation. Existing TTA methods for non-stationary domain shifts, while effective, incur excessive computational load, making them impractical for on-device settings. In this paper, we introduce a layer-wise auto-weighting algorithm for continual and gradual TTA that autonomously identifies layers for preservation or concentrated adaptation. By leveraging the Fisher Information Matrix (FIM), we first design the learning weight to selectively focus on layers associated with log-likelihood changes while preserving unrelated ones. Then, we further propose an exponential min-max scaler to make certain layers nearly frozen while mitigating outliers. This minimizes forgetting and error accumulation, leading to efficient adaptation to non-stationary target distribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our method outperforms conventional continual and gradual TTA approaches while significantly reducing computational load, highlighting the importance of FIM-based learning weight in adapting to continuously or gradually shifting target domains.
</details>
<details>
<summary>摘要</summary>
（注：以下是简化中文版本）随着实际应用中数据分布的不断变化，测试时间适应（TTA）在部署后是必需的。然而，实际中的目标分布不断变化带来了悬峰忘却和错误积累的挑战。现有的TTA方法对非站立性目标分布非常有效，但是 computational load 过高，使其无法实现在设备上进行。在这篇论文中，我们提出了一种层 wise auto-weighting 算法，用于逐渐和积极地适应非站立性目标分布。我们首先通过 Fisher Information Matrix (FIM) 设计学习权重，以选择与 log-likelihood 变化相关的层，并保留不相关的层。然后，我们进一步提出了一种对数抑制器，使certain层变得几乎冻结，并 Mitigate 异常值。这有效地减少了忘却和错误积累，从而实现了高效地适应非站立性目标分布。我们的方法在 CIFAR-10C、CIFAR-100C 和 ImageNet-C 上进行了实验，并证明了我们的方法在不断变化的目标分布下对 TTA 进行了改进，并且可以减少计算负担，强调 FIM 基于的学习权重在适应不断变化的目标分布中的重要性。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-aware-Single-View-Volumetric-Rendering-for-Medical-Neural-Radiance-Fields"><a href="#Uncertainty-aware-Single-View-Volumetric-Rendering-for-Medical-Neural-Radiance-Fields" class="headerlink" title="Uncertainty-aware Single View Volumetric Rendering for Medical Neural Radiance Fields"></a>Uncertainty-aware Single View Volumetric Rendering for Medical Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05836">http://arxiv.org/abs/2311.05836</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Hu, Qinrui Fan, Shu Hu, Siwei Lyu, Xi Wu, Xin Wang</li>
<li>for: 本研究旨在提出一种基于生成辐射场的不确定性意识MedNeRF网络，以便从2DX射影图像中学习CT投影图像的连续表示。</li>
<li>methods: 该网络使用生成辐射场来获取内部结构和深度信息，并使用适应性损失量来保证生成图像的质量。</li>
<li>results: 我们在公共可用的膝盖和胸部数据集上训练了我们的模型，并对单个X射影图像进行CT投影图像的Rendering，并与其他基于生成辐射场的方法进行比较。<details>
<summary>Abstract</summary>
In the field of clinical medicine, computed tomography (CT) is an effective medical imaging modality for the diagnosis of various pathologies. Compared with X-ray images, CT images can provide more information, including multi-planar slices and three-dimensional structures for clinical diagnosis. However, CT imaging requires patients to be exposed to large doses of ionizing radiation for a long time, which may cause irreversible physical harm. In this paper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on generated radiation fields. The network can learn a continuous representation of CT projections from 2D X-ray images by obtaining the internal structure and depth information and using adaptive loss weights to ensure the quality of the generated images. Our model is trained on publicly available knee and chest datasets, and we show the results of CT projection rendering with a single X-ray and compare our method with other methods based on generated radiation fields.
</details>
<details>
<summary>摘要</summary>
在临床医学领域，计算机断层成像（CT）是一种有效的医疗影像Modalities，用于诊断多种疾病。相比X射线图像，CT图像可以提供更多的信息，包括多平面切片和三维结构，为临床诊断提供更多的参考。然而，CT成像需要患者长时间暴露于大剂量辐射，可能会导致不可逆的物理损害。在本文中，我们提出了基于生成辐射场的不确定性意识MedNeRF（UMedNeRF）网络。该网络可以通过获取内部结构和深度信息，从2D X射线图像中生成CT投影图像，并使用适应损失质量来保证生成图像质量。我们的模型在公共可用的膝盖和胸部数据集上进行训练，并对CT投影图像的生成进行了比较。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Shape-Prior-for-Wrinkle-Accurate-Cloth-Registration"><a href="#Diffusion-Shape-Prior-for-Wrinkle-Accurate-Cloth-Registration" class="headerlink" title="Diffusion Shape Prior for Wrinkle-Accurate Cloth Registration"></a>Diffusion Shape Prior for Wrinkle-Accurate Cloth Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05828">http://arxiv.org/abs/2311.05828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingfan Guo, Fabian Prada, Donglai Xiang, Javier Romero, Chenglei Wu, Hyun Soo Park, Takaaki Shiratori, Shunsuke Saito</li>
<li>for: 用于实现基于实际数据的动态外观模型和物理参数估计</li>
<li>methods: 使用 diffusion models 学习shape prior，并提出基于函数图的多个阶段引导方案来稳定注registrations</li>
<li>results: 在高精度捕捉到的实际衣服上，提出的方法比VAE或PCA基于的surface registration更好地泛化，并在扩展和减少扩展测试中都能够超越优化基于和学习基于的非rigid registration方法。<details>
<summary>Abstract</summary>
Registering clothes from 4D scans with vertex-accurate correspondence is challenging, yet important for dynamic appearance modeling and physics parameter estimation from real-world data. However, previous methods either rely on texture information, which is not always reliable, or achieve only coarse-level alignment. In this work, we present a novel approach to enabling accurate surface registration of texture-less clothes with large deformation. Our key idea is to effectively leverage a shape prior learned from pre-captured clothing using diffusion models. We also propose a multi-stage guidance scheme based on learned functional maps, which stabilizes registration for large-scale deformation even when they vary significantly from training data. Using high-fidelity real captured clothes, our experiments show that the proposed approach based on diffusion models generalizes better than surface registration with VAE or PCA-based priors, outperforming both optimization-based and learning-based non-rigid registration methods for both interpolation and extrapolation tests.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本翻译成简化中文。<</SYS>>注册Textureless clothes from 4D scans with vertex-accurate correspondence is challenging, yet important for dynamic appearance modeling and physics parameter estimation from real-world data. However, previous methods either rely on texture information, which is not always reliable, or achieve only coarse-level alignment. In this work, we present a novel approach to enabling accurate surface registration of texture-less clothes with large deformation. Our key idea is to effectively leverage a shape prior learned from pre-captured clothing using diffusion models. We also propose a multi-stage guidance scheme based on learned functional maps, which stabilizes registration for large-scale deformation even when they vary significantly from training data. Using high-fidelity real captured clothes, our experiments show that the proposed approach based on diffusion models generalizes better than surface registration with VAE or PCA-based priors, outperforming both optimization-based and learning-based non-rigid registration methods for both interpolation and extrapolation tests.Note: The translation is done using Google Translate, and may not be perfect. Please let me know if you need any further assistance.
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Variance-Thresholding-A-Novel-Approach-to-Improve-Existing-Deep-Transfer-Vision-Models-and-Advance-Automatic-Knee-Joint-Osteoarthritis-Classification"><a href="#Adaptive-Variance-Thresholding-A-Novel-Approach-to-Improve-Existing-Deep-Transfer-Vision-Models-and-Advance-Automatic-Knee-Joint-Osteoarthritis-Classification" class="headerlink" title="Adaptive Variance Thresholding: A Novel Approach to Improve Existing Deep Transfer Vision Models and Advance Automatic Knee-Joint Osteoarthritis Classification"></a>Adaptive Variance Thresholding: A Novel Approach to Improve Existing Deep Transfer Vision Models and Advance Automatic Knee-Joint Osteoarthritis Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05799">http://arxiv.org/abs/2311.05799</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fabi Prezja, Leevi Annala, Sampsa Kiiskinen, Suvi Lahtinen, Timo Ojala</li>
<li>for: 本研究旨在提高骨关节风溃病（KOA）的诊断精度，通过应用深度学习方法和自适应变量阈值控制（AVT）、神经建构搜索（NAS）等技术。</li>
<li>methods: 本研究使用的方法包括深度学习模型的预训练和特点化 Variance Thresholding（AVT）、Neural Architecture Search（NAS）等。</li>
<li>results: 本研究的结果表明，通过应用我们的方法，可以提高预训练KOA模型的初始准确率，并将NAS输入向量空间减少60倍，从而提高推理速度和优化超参数搜索。此外，我们还应用了这种方法于一个外部已经训练的KOA分类模型，并得到了较好的效果，使其成为骨关节风溃病分类模型之一。<details>
<summary>Abstract</summary>
Knee-Joint Osteoarthritis (KOA) is a prevalent cause of global disability and is inherently complex to diagnose due to its subtle radiographic markers and individualized progression. One promising classification avenue involves applying deep learning methods; however, these techniques demand extensive, diversified datasets, which pose substantial challenges due to medical data collection restrictions. Existing practices typically resort to smaller datasets and transfer learning. However, this approach often inherits unnecessary pre-learned features that can clutter the classifier's vector space, potentially hampering performance. This study proposes a novel paradigm for improving post-training specialized classifiers by introducing adaptive variance thresholding (AVT) followed by Neural Architecture Search (NAS). This approach led to two key outcomes: an increase in the initial accuracy of the pre-trained KOA models and a 60-fold reduction in the NAS input vector space, thus facilitating faster inference speed and a more efficient hyperparameter search. We also applied this approach to an external model trained for KOA classification. Despite its initial performance, the application of our methodology improved its average accuracy, making it one of the top three KOA classification models.
</details>
<details>
<summary>摘要</summary>
膝关节骨关节炎 (KOA) 是全球最常见的残疾原因之一，而其诊断却因为它的微不足和个人化进程而被认为是复杂的。深度学习技术可能会有所助益，但这些技术需要大量多样化的数据集，医疗数据收集限制成为了主要挑战。现有的做法通常是使用更小的数据集和转移学习。然而，这种方法可能会固化预先学习的特征，从而降低表现。本研究提出了一种改进后期特殊化分类器的新方法，通过适应差异阈值调整 (AVT) 和神经网络搜索 (NAS)。这种方法导致了两个关键的结果：首先，提高了预训练 KOA 模型的初始精度；其次，将 NAS 输入向量空间减少到 60 倍，从而提高了推理速度和搜索效率。我们还应用了这种方法于一个外部用于 KOA 分类的模型。尽管它的初始表现不佳，但通过我们的方法改进，其平均精度得到了提高，成为了 KOA 分类模型之一。
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Bidirectional-Temporal-States-of-Knee-Osteoarthritis-Radiographs-with-Cycle-Consistent-Generative-Adversarial-Neural-Networks"><a href="#Synthesizing-Bidirectional-Temporal-States-of-Knee-Osteoarthritis-Radiographs-with-Cycle-Consistent-Generative-Adversarial-Neural-Networks" class="headerlink" title="Synthesizing Bidirectional Temporal States of Knee Osteoarthritis Radiographs with Cycle-Consistent Generative Adversarial Neural Networks"></a>Synthesizing Bidirectional Temporal States of Knee Osteoarthritis Radiographs with Cycle-Consistent Generative Adversarial Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.05798">http://arxiv.org/abs/2311.05798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fabi Prezja, Leevi Annala, Sampsa Kiiskinen, Suvi Lahtinen, Timo Ojala</li>
<li>for: 预测患者患有满月股骨骨折病（KOA）的可能性，增强数据采集和预测模型训练。</li>
<li>methods: 使用CycleGAN模型将真实的X光图像扩展到不同的KOA阶段，并通过验证使用Convolutional Neural Network（CNN）来证明模型的可靠性。</li>
<li>results: 模型能够有效地将病例阶段转换为不同的阶段，特别是将晚期病例阶段转换为早期阶段，并且能够抑制骨质增生和扩大膝关节空间，这些特征都是早期KOA的典型表现。<details>
<summary>Abstract</summary>
Knee Osteoarthritis (KOA), a leading cause of disability worldwide, is challenging to detect early due to subtle radiographic indicators. Diverse, extensive datasets are needed but are challenging to compile because of privacy, data collection limitations, and the progressive nature of KOA. However, a model capable of projecting genuine radiographs into different OA stages could augment data pools, enhance algorithm training, and offer pre-emptive prognostic insights. In this study, we trained a CycleGAN model to synthesize past and future stages of KOA on any genuine radiograph. The model was validated using a Convolutional Neural Network that was deceived into misclassifying disease stages in transformed images, demonstrating the CycleGAN's ability to effectively transform disease characteristics forward or backward in time. The model was particularly effective in synthesizing future disease states and showed an exceptional ability to retroactively transition late-stage radiographs to earlier stages by eliminating osteophytes and expanding knee joint space, signature characteristics of None or Doubtful KOA. The model's results signify a promising potential for enhancing diagnostic models, data augmentation, and educational and prognostic usage in healthcare. Nevertheless, further refinement, validation, and a broader evaluation process encompassing both CNN-based assessments and expert medical feedback are emphasized for future research and development.
</details>
<details>
<summary>摘要</summary>
髋关节滤出病 (KOA) 是全球最主要的残疾原因之一，但早期检测困难由于病理表像不具有明显的特征。收集延伸的数据集是困难的，主要因为隐私、数据收集限制和滤出病的进行性。然而，一种能将真实的X光像投影到不同的滤出病阶段的模型可以增加数据库，提高算法训练和提供预防性预测。本研究中，我们使用了循环GAN模型将过去和未来的滤出病阶段投影到任何真实的X光像上。我们验证了这种模型，使用了一个 convolutional neural network (CNN) 被欺骗到在转换后的图像中错误地分类病种特征，表明循环GAN模型可以有效地将病种特征转换到不同的时间阶段。特别是在将未来的病状投影到当前阶段的情况下，模型表现出了极高的效果。此外，模型还可以逆转晚期X光像，使其变回早期阶段，这是 none 或 doubtful KOA 的特征之一。这些结果表明这种模型在改善诊断模型、数据增强和教学和预测方面具有普遍的潜力。然而，进一步的优化、验证和更广泛的评估过程，包括使用 CNN 基础的评估和专业医疗反馈，是未来研究和开发的重点。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/10/cs.CV_2023_11_10/" data-id="clp9qz85c00mxok888acwgel8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/6/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/97/">97</a><a class="extend next" rel="next" href="/page/8/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
